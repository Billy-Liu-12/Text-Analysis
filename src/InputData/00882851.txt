Data Mining Algorithms for Web Pre-Fetching

Abstract To speed up fetching web pages, this paper gives a n intelligent technology of web pre-fetching. We use a simplified WWW data model to represent the data in the cache of web browser to mine the association rules. We store these rules in a knowledge base so as  to predict the user?s actions. Intelligent agents are responsible f o r mining the users? interest and pre-fetching web pages, based on the interest association repository. In this way, user browsing ,time has been reduced transparently.

Keywords: WnrCt: Internet, Data Model, Data Mining, Pre-fetching, Cache  1. Introduction With the r,apid development of Internet, WWW is  popular for i1:s multimedia transmission and friendly interactivity. Although the speed of network has been improved considerably in recent years, the rapid expansion of using the Internet, the inherited character of delay in the network and the RequestJResponse working mode of WWW [12] still make the internet traffic very slow and give no guarantee on the Quality of Service (QoS). Because HTTP has no states, the web server cannot know the users? demand and the users? requests cannot be predicted. Taking advantage of a cache mechanism and the time locality of WWW access, the browser can preserve the documents ever accessed in the local machine. By this means, for the documents in the local cache, the browser does not need to send the requests to the remote server or to receive the whole response from ]:he remote one. Pre-fetching uses the space locality of access. First, the users? access requests are predicted according to the users? current request. Second, the expected pages are fetched into the local cache when the user is browsing the current page[ll] .  Finally, the users can access these pages downloaded from the local  cache. And thus this can reduce the access delay to some degrees. Pre-fetching is one kind of active caches that can cache the pages which are still not requested by the user.

The application of pre-fetching technology in the web can greatly reduce the waiting time after users have sent their requests.

Pre-fetching technology is based on prediction algorithms. Data mining is a technique, with which a lot of unknown, implicit but potentially useful information (such as knowledge, rules and regularities) for decision-making are mined. Based on the historic data and the current data accessed by the user, users activities in the future are predicted through data mining and relevant web pages are pre-fetched. The data in the users? local cache can be taken as the data sources of data mining.

This paper concentrates on the above issues and discusses the application of data mining techniques in the pre-fetching of web pages. First, a WWW data model is given. Second, we put forward an interest association repository and a predicting method. And then an algorithm of transforming the simple WWW data model to the interest association repository is introduced. Finally, we present an agent-based web pre-fetching system.

2. A Simple WWW Data Model The web pages are defined in HTML language. By  using MIME, a web page can contain different types of elements. A hyper media system [l] is made up of web pages linked by hyper links among each other. To  predict a user?s activities, a data model is needed to describe the interest association rules in the web pages. Several data models [2, 31 have described the WWW. In order to meet the demand of data mining and represent the characteristic of the cache, this paper proposes a simple WWW data model. Some concepts and definitions of this model are presented below.

0-7695-0577-5/00 $10.00 0 2000 IEEE    Definition 1: Let triple (Id, P, time) be a page node, where each page node is associated with an Id, time the latest time when the page node is accessed, and P a collection of properties, P = {property p ,  I i = I  , 2 . .  ..}. The property can be the relative URL, the type, the collection of linking nodes, the container, the content, the updated time, and so on.

According to whether the links exist and the pointing direction of the links in the web pages, the page nodes can be classified into isolated page nodes, source page nodes and target page nodes. A page node, which does not contain any links, is the isolated page node. A page node, which contains links, is called the source page node of such links. While a page node, which is pointed by some other links, is called the target page node of such links.

Apparently, according to different links, one page node can be a source page node or a target page node of such links.

Definition 2: Let triple (Id, string, target-node-id) be a linking node, where each Id identifies only one linking node; string describes the presenting information of this linking node, and target-node-id is the id of the target page node.

Definition 3: Let triple (source-node, L, target-node) be a link, where source-node is the source page node; L is the linking node; and target-node is the target page node; L E collection of links in the source-node, L.turget-node-id = target-node.

Figurel: A simple WWW data model  Figure 1 shows the proposed simple WWW data model.

In this model, each node represents one web page; these nodes are inter-linked by the links that clearly represent the association of these web pages.

The web browsers now use the cache technology, which preserves the latest web pages accessed by the users. When the users want to access these web pages again, the browser first examines whether these web pages are cached locally. If so, the browser will then check whether the corresponding web pages are updated. If updated, these web pages can be achieved from the corresponding web servers. Otherwise, the pages are fetched from the local cache. That is to say, it is a passive mechanism in current browsers. The historic data in the  cache reflect the users? interest in browsing information and the associating information among the users? interest is useful to foresee the users? activities. The associations among the web pages in the cache can be described easily in the simple WWW data model in Figure 1. But unfortunately, such a model can not visually represent the associating information of users? interests. In order to predict users? activities and implement the active cache, certain measures must be taken to transform the data in the cache from the simple WWW data model to another data model, so that they become more suitable for predicting. This approach will be introduced in the data mining section below.

3. Interest Association Repository and User Action Prediction  When a user is accessing a web page, normally she or he will follow the links in the web page to access other web pages. Based on the current web page, we can predict the links to be accessed by the user, and then can pre-fetch these web pages which will speed up browsing. It is supposed that the browser can pre-fetch all the pages pointed by the links in the current web page. It works better when there are only a few links that point to the different web servers. But such method is not advisable.

The first reason is that it is generally not possible that the user accesses all the links in the web page. Another reason is, if the fee is charged by network stream, the user may pay much more overhead. Further more, the streams of the Internet system should be balanced. So in this paper, we sort the links in the web page according to certain policy and pre-fetch a few web pages, which are more possible to be accessed. Considering the response time of the system and the difficult level in the realization of the different systems, we apply the simple association rules to predict the users? activities. The interest association repository is made up of some interest association rules. The interest set (dictionary) T is represented as { t ,  , t 2  ... t ,  1, where t ,  , t 2  . . . t ,  are lemmas. Here are more definitions.

Definition 4: The interest node is defined as a pair: Node ( t  )=( t , weight), where t is the lemma in the interest set T and weight is the weight of t .

Definition 5: The interest association rule is a triple:  Rule(Node ( t ,  ),Node ( t, ))=(Node ( t s  ), weight, Node ( t ,  ))  where weight is the probability from the interest node Node( I ,  ). t ,  linking to the interest node Node( t,  ). t ,  , O< weight 51.

Definition 6: The interest association repository is a set of interest association rules, where RULE = {Rule (Node ( t ,  ), Node ( t ,  )) I Rule(Node( t.? ), Node( f, )) is a rule] is a     rule). The interest association rules in the interest association repository must satisfy:  Rule( Node(t,s), Node(t,)).weight =1 P ( Node(, ,  ))  where P(Node( t ,  )) =  { t ,  It, E T ,  Rule(Node( t,s ), Node( rt )) E RULE} The interest association rules in the interest association  repository point out the probability from one lemma (interest) to another. From the interest association repository, the user?s browsing tracks and the current web page, we can predict the most possible accessed links in the current web page. The interest association rules in the interest associal.ion repository are based on the analysis of the great amourit of historic data.

We now introduce the construction of the interest association repository in details. The repository can be constructed every certain time. When the user browses a web page, quite often she or he only accesses some web pages of her or his current interests. Such web pages are more valuable than the historic data. Considering the response speed of accessing the web pages, we can not reconstruct the interest association repository completely.

But considering the user?s browsing tracks, we use a certain method that can modify the interest association repository step by step. Therefore the fault of the data in pre-fetching period is avoided.

Users? browsing tracks are made up of the users? current accessing web pages. If all the n previous pages must be processed when the user accesses the n+lth web page, the response time cannot be assured when n is big.

So an incremental algorithm which modifies the interest association repository every time works well when the user accesses one web page.

Algorithm 1: incremental algorithm of adjusting the interest association repository. Assume that the user is accessing the nth web page Y,, . A few steps are taken as follows to mod:ify the interest association repository.

Step 1 Calculate the frequency of lemmas of T in the web page Y,, (the slicing, stemming and thesaurus  technologies [ 6 ] )  are taken and a set K ( Y,, ) = ( (  t,:, f j  ) I  t,: E T is obtained, where f, is the frequency of tl appearing in Y,, , f j  >O,iE N}.

Each Node ( t )  in the interest association repository is adjusted as follows:  Step 2  if Node ( t  ). t = t,: and ( r ; ? ,  f ,  ) E K( Y,, ) then No,de( t ).weight = Node ( t  ).weight + fj x F(n),  where, F(n), a monotonous and non-degressive function, represents the freshness.

It is easily proved that the function F(n)  ensures that the more recently the web pages are accessed, the more favorable is to predict these web pages. F(n)  can be n, n2 and so on. During this process, the weight of the node in the interest association repository increases gradually according to the user?s accessing sequence, so that the sequence of the user?s accessing tracks has been embodied in the interest association repository. We can use the following steps to predict the links that will be chosen by the user.

Algorithm 2: using the interest association repository to predict the user?s activities.

Step 1 Use the Algorithm1 to process the current web page.

Step 2 Let L = ( I ,  , 1,  . . . I ,  ) be the all links that are in the current web page.

for each 1, in L do Slice the lemmas in the string in the I ,  and get C ( I ,  .string)=( t, I t, is in 1, .string, j E  N ) .

Step 3 Score all rhe links in L  Value( I ,  )=  xNode(i) .weighbc Rule(Nodefk), Node(;.?)).weight J Q  where Q = ( ( t i ,  t,?>l ( t i ,  f k  )E K(Y,, ), and t ;  E c ( I ,  .string),  RuIe(Node( t i  ), Node(r,?)) E RULE) .

Step 4 Sort Value ( 1 ; )  in descending sequence. The  more advanced the links are, the more possibly the users access.

Select s foregoing links (If s > k then let s = k .

Generally s is not more than 5) .  If the web pages pointed by such links do not exist in the local cache, they will be pre-fetched.

The reliability is an important factor in pre-fetching technology. From the Step 3 above, we can get the reliability of link 1, :  c Nod4t i  ).weighn< RuI4 NodLjti ), N o d 4  ?:)).weight 1 Q 1 .  =  Nod4t; ).weight Q  where Q = { ( t i  , t i  ) I ( t i  , f k  )E K( Y,, ), t i  E c ( I ,  .string),  Rule (Node( t ;  ), Node( t i  )) E RULE) .

Now, we can get the reliability of the pre-fetching algorithm:     Node(t; ).weightx Rule(Node(t; ), Node(t ;)).weight S c Node(t;).weight  S  where  S = { t i , t i O l ( t ; ,  f k )  E K(Y , ) , r ; ?  E U C ( l . s t r i n g ) :  Rule (Node ( t i  ), Node ( t i  )) E RULE) .

laL  4. The Proposed Data Mining Technique Data mining has been well-known as a database  technology developed in recent years [ 131. It can mine the implicit, unknown, and potentially useful knowledge and rules for predicting. Using these rules, we can predict the user?s impending activities with the algorithms above.

The interest association rules directly represent the relations of reasoning between interests. But the data in the cache shown in the simple WWW data model directly represent the link relations in the web pages, which cannot directly reflect the association degree between interests.

Therefore certain measures are taken to transform the data in the cache shown in the simple WWW data model. The associations, the sequence patterns and the sequence of same time can benefit from the association analysis in the data mining technology. In convenience, we do not consider the transferable relations among the rules when we build the interest association rules. Hence it  is suitable to apply the method of discovering relations by the model of the simple interest association rules.

Because mining information from the abundant historical data may take more time, it is not proper to predict the user?s activities online. The solution is to use genetic algorithm to mine the user?s browsing interest association rules every certain time, based on the historical information in the cache (see Algorithm 1 ) .  Now we represent the algorithm for mining the association rules.

Algorithm 3: mine the interest association rules from the data in the cache.

for each page Y, in the set C do  /* for1 *I  for  each link l , , ,  in the set L ( Y ;  ) do /* for2*/  assume I,,, .target-node = Y j  ; if Y j  E C then  foreachlemma(tb, fp) in these tK(Yi)do  /*for3*1  for each lemma ( t ;  , f ) in the set K( Yj ) do I* for4*/  Rule (Node ( t i  ), Node ( t ;  )).weight  t Rule (Node ( t i ) ,  Node ( t i ) ) .weight  + g( f, , fq , Y i  .time, Y, .time)  where ( t ,  , f, )E K( Y, ) , ( tq  , f, ) E K( Y, >; end for  /* for4*1  end for  /* for3*1 else  for  each lemma ( t i ,  f,) in the set K (  Y, )do /*  fors*/  for each lemma t i  in the set Q ( l , , r  .string) do /*for6*/  Rule (Node ( t i  ), Node ( t i  )).weight  Rule (Node ( t ,  ), Node ( t i  )).weight  + h ( f , ,  Y, .rime) where ( t ,  , fp)E Y, , r ,  E Q ( I ,  .string);  end for  /* for6*/ end for /* for5*1  end if end for I* for2*/  end for I* for 1 */ Rule (Node ( t ,  ),Node( t ,  )).weight  Rule(Node(t, ), Node(t , )).weight -~  C R u l e ( N o d e ( t ,  ), Node(t ,)).weight Q(Nodr(r, 1)  Q (Node ( t i  )) = where  { t j l r j  E T,Rule(Node(t i ) ,Node(t  .))E R U L E )  /* normalize the weight of interest association rules */.

In the loopfor4 of the above algorithm, the influence  of the web pages in the cache, their links and linked web pages on the interest association rules in the interest association repository is defined as the function g ( f, , f ,  ,  Y ,  .time, Y ,  .time), where f, and fq are the appearance  frequency of lemma t ,  in the page Y, and lemma tq  in the  Y, , respectively, and Y, .time and Y, .time are the accessed  time of pages Y, and Y j  , respectively. In the loopfur6, the influence of the web pages in the cache and their links on the interest association is defined as the function h ( f, , Y j  .time), where t ,  is the appearance frequency of  lemma t ,  in the page Y, and Y, .time is the accessed  time of page Y .

The supporting rate is a very important guideline in  data mining. The Rule (Node( t i  ), Node( t )).weight from  the Algorithm 3 is the supporting rate of the interest association rule, Rule (Node ( t i  ), Node( t j  )).

J  5. Agent-Based Web Pre-fetching System     An agent [5,9, IO] based web pre-fetching system implementing the approach described in previous sections is shown in the Figure 2. In this system, the Interest Association Repository, the Mining Agent and the Decision Agent are attached to the Browser side. The Interest Association Repository uses SQL Server7.0 to save the pre-fetching rules. The Mining Agent and the Decision Agent are implemented by WIRPL [4]. A mining agent runs at the client side and updates the interest association rules periodically (the refresh rate can be set by users). According to Algorithm 3, the data in the local cache represented by the simple WWW data model above are transforme:d into the interest association rules which are then stored. in the Interest Association Repository. The Decision Agent running at the client side can detect the user?s activities in real time and can provide the abilities of predicting the user?s activities online. It should take charge of the tasks such as getting the current web page in the browser, analyzing the current web page using Algorithm 2, interacting with the interest association repository, pre-fetching the web pages and saving them into the local cache. The interest association repository, the mining agent and the decision agent are transparent to the users. Therefore the users can use the browsers as usual.

Local Cache Browser E?; Mining Agent ecision Agent Interest A.ssociation Repository  WWW Service  I Figure 2: An agent based web pre-fetching system  6. Conclusion This paper first presents a simple WWW data model,  and then introduces some technologies with which the data in the cache of the browser can be mined, the knowledge is saved into the interest association repository, and the users? impending activities can be predicted. Integrated with the data mining technique, the agent technology and the web technology, better quality of web service for the users is provided. The design ideas of the agent based web pre-fetching reflect the development tendency of intelligent web browsers.

7. References [ I ]  Berners-Lee, Tim .et al, Hypertext Markup Language  2.0, Internet Network Working Group RFCl866, MIT/W3C( 1995). ftp://ds.internic.net/rfc/rfc 1866.txt.

[2] Leggett J., et al., ?Special issues on hypertext?, Communications of ACM, 1994, 37(2), pp. 26-108.

[3] Chen Ying, Xu Hongbin and Wang Nengbin, ?Towards Globalization of Distributed Data Sources over WWW --- Data Model and Query Language?, Journal of Software, 1998,9(8), pp. 566-573.

[4] Zhang Weifeng and Xu Baowen, ?Research on Framework Supporting Web Search Engine?, Journal of Computer Research & Development, 2000,37.

[5] Genesereth M R. and Ketch S P., ?Software Agents?, Communication of the ACM, 1994, 37(7), pp. 48-53.

[6] Zou Tao, et al., ?The Technology Implementation of Information Mining on WWW?, Journal of Computer Research & Development, 1999, 36(8), pp. 1021-1024.

[7] Zhang Weifeng, Xu Baowen and Zhou Xiaoyu, ?Counting Techniques in Web Pages?, Mini-Micro Systems, in preparation.

[8] Zhang Weifeng, Xu Baowen and Zhou Xiaoyu, ?Web Page Techniques for Interacting between Elements?, Computer Enginering, in preparation.

[9] Robert Armstrong, Dayne Freitag, Thorsten Joachims and Tom Mitchell, ?Web-Watcher: A Learning Apprentice for the World Wide Web?, Proceedings of the AAAI Spring Symposium on Information Gathering from Heterogenous, Distributed Resources, Stanford, CA, March 1995.

[ 101 Marko Balabanovic and Yoav Shoham, ?Learning Information Retrieval Agents: Experiments with Automated Web Browsing?, Proceedings of the AAAI Spring Symposium on Information Gathering from Heterogenous, Distributed Resources, Stanford, CA, March 1995.

[ 1 I ]  Peter W. Foltz and Susan T. Dumais, ?Personalized Information Delivery: An Analysis of Information Filtering Methods?, Communications of the ACM, 35( 12), pp. 51-60, December 1992.

[ 121 Gudivada V. N., ?Informaiton Retrieval on the World Wide Web?, IEEE Internet Computing, 1997, 1(5), pp.

[13]Chen M. S., et al., ?Data Mining for Path Traversal Patterns in A Web Environment?, Proceedings of the Computing System, 1996, pp. 385-392.

58-68.

