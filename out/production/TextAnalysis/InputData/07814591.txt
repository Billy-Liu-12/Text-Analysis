Representative Itemset Mining

Abstract?Frequent itemset mining is one of the most com- mon of data mining tasks. In its simplest form one is given a table of data in which the columns represent attributes and each row specifies a value for each attribute, each attribute- value pair being referred to as an item. The task is to find sets of these items that occur frequently in the data, where frequency is specified as a minimum occurrence threshold. Such frequent sets of items are referred to as ?frequent itemsets?. Many efficient techniques have been developed for finding all frequent itemsets. However, a practical problem is that the results sets can be exponentially large in the number of items. In this paper we propose representative frequent itemset mining in which the set of itemsets returned provide examples of the space of all possible frequent itemsets. Specifically, every item that appears in a frequent itemset at least once is shown in at least one representative itemset. If there are frequent itemsets without a particular item, one such example will be presented.

One can generalise our framework to seek representative sets in which pairs, triples, etc. of frequent itemsets are presented.

One can see the representative frequent itemset framework as a generalisation of traditional frequent itemset mining that provides an additional parameter for controlling the size of the result set. Specifically, one has access to the traditional frequency threshold, but also the maximum arity of the tuples of itemsets being exemplified. We propose a dedicated algorithm that significantly outperforms using a state-of-the-art itemset miner in generating representative itemsets.



I. INTRODUCTION  Frequent itemset mining is one of the most ubiquitous problems in data mining [1]. The problem has its origins in the analysis of transaction data in supermarkets; specifically trying to discover which items appear frequently in customer purchases [2]. Each transaction is defined by a set of items, e.g. a transaction might define a set of products that were purchased together. The classic itemset mining problem involves identifying sets of items that appear frequently with each other. Many algorithms have been developed for efficiently enumerating the set of all itemsets that occur more frequently than a specified number of times, e.g. LCM [3] and ECLAT [4], to name two specific examples.

Example 1. Consider the simple transaction database pre- sented in Table I. This database contains five transactions involving five items. Assume we are interested in items that appear together at least three times, i.e. we are looking for itemsets that have a frequency of at least three. Two  Table I AN EXAMPLE DATASET CONTAINING FIVE TRANSACTIONS (ROWS)  INVOLVING FIVE ITEMSETS (COLUMNS). A 0 (OR 1) IN A CELL OF THIS TABLE INDICATES THAT THE CORRESPONDING ITEM DOES NOT (RESP.

DOES) APPEAR IN THE CORRESPONDING TRANSACTION.

Items Transaction i1 i2 i3 i4 i5  t1 0 1 0 0 1 t2 1 1 0 0 1 t3 1 0 1 1 0 t4 1 1 1 1 0 t5 0 1 1 1 1  examples of itemsets that have a frequency of at least three are {i2, i5} and {i3, i4}. The former appears in transactions t1, t2, and t5, while the latter appears in transactions t3, t4, and t5. ?  While one might be interested in counting the number of such itemsets, there is little value in viewing them all, even if this were possible. There would simply be too many of them to consider. Even in the small example we?re considering here, for a minimum frequency of two, we can find 14 non- empty frequent itemsets. These are listed in Table II.

A standard approach to reducing the number of frequent itemsets to be computed is to consider only those that are maximal. A maximal frequent itemset is one such that no extension of it is also frequent. By focusing on maximal itemsets we can avoid computing all subsets of a frequent itemsets which, by definition, will also be frequent. How- ever, we will see in the experimental results section of this paper that the number of maximal frequent itemsets for a given transaction database can also be impractically large.

In this paper we propose an alternative approach to com- puting a compact but representative subset of the maximal frequent itemsets from a transaction database. Specifically, we propose that one considers representative frequent item- set mining in which a very significantly reduced set of itemsets is computed that provides examples of the space of all possible frequent itemsets. Our approach is inspired by the notion of representativeness of explanations [5]. Specif- ically, every item that appears in a frequent itemset at least once is shown in at least one representative itemset. If there   DOI 10.1109/ICTAI.2016.28    DOI 10.1109/ICTAI.2016.28    DOI 10.1109/ICTAI.2016.28     Table II THE SET OF NON-EMPTY FREQUENT ITEMSETS FROM OUR EXAMPLE  DATA.

Items Itemset i1 i2 i3 i4 i5 I1 1 0 0 0 0 I2 0 1 0 0 0 I3 0 0 1 0 0 I4 0 0 0 1 0 I5 0 0 0 0 1 I12 1 1 0 0 0 I13 1 0 1 0 0 I14 1 0 0 1 0 I23 0 1 1 0 0 I24 0 1 0 1 0 I25 0 1 0 0 1 I34 0 0 1 1 0 I134 1 0 1 1 0 I234 0 1 1 1 0  are frequent itemsets without a particular item, one such example will be presented. In this way our representative approach gives a sense of how items occur in frequent itemsets.

We can generalise our approach to representativeness of k-tuples of itemsets that co-occur in the set of frequent itemsets, e.g. rather than seeing examples of how singleton itemsets appear, we might be interested in seeing a repre- sentative set that shows how all pairs of itemsets occur or do not occur in the set of frequent itemsets. We can generalise even further and view traditional itemset mining in which we see examples of every tuple of itemsets occuring together.

One can see the representative frequent itemset framework as a generalisation of traditional frequent itemset mining that provides an additional parameter for controlling the size of the result set. Specifically, one has access to the traditional frequency threshold, but also the maximum arity of the tuples of itemsets being exemplified. We propose a dedicated algorithm that significantly outperforms using a state-of-the- art itemset miner in generating representative itemsets.



II. THE CONCEPT OF REPRESENTATIVENESS  We present a set of examples, based on Example 1, that demonstrate the notion of representatives as it relates to frequent itemset mining. Consider Table III. This table presents four of the frequent itemsets taken from Table II that are representative of how itemsets of size one appear in frequent itemsets. We see examples of each of the items in at least one itemset. However, this table gives the sense that item i2 always appears in all frequent itemsets, which is not true of course. Focusing only on representativeness based on the inclusion of items can be misleading: there are, of course, frequent itemsets in which i2 is not included.

A similar situation arises if we focus on choosing a set of frequent itemsets that exemplify how items are excluded  Table III REPRESENTATIVE FREQUENT ITEMSETS BASED ON INCLUSION.

Items Itemset i1 i2 i3 i4 i5 I12 1 1 0 0 0 I23 0 1 1 0 0 I24 0 1 0 1 0 I25 0 1 0 0 1  from itemsets. An example is presented in Table IV. Here, while we see a representative sample of all possible frequent itemsets that show how items are excluded. However, it gives the sense that items i3, i4, and i5, are always excluded, which is again misleading.

Table IV REPRESENTATIVE FREQUENT ITEMSETS BASED ON EXCLUSION  Items Itemset i1 i2 i3 i4 i5 I1 1 0 0 0 0 I2 0 1 0 0 0  Figure V presents a fully representative set of itemsets.

This set shows an example of every item that appears in at least one frequent itemset, as well as showing an example of every item that is absent from at least one itemset. Since none of the items are always included or excluded in all frequent itemsets, we never observe this in the set of representative itemsets. While this example is representative of singleton items, one can easily compute a set of representative itemsets for tuples or items of any maximum cardinality, allowing us to view the full set of frequent itemsets as a special case of this appraoch.

Table V A FULLY REPRESENTATIVE SET OF ITEMSETS.

Items Itemset i1 i2 i3 i4 i5 I25 0 1 0 0 1 I134 1 0 1 1 0

III. REPRESENTATIVE FREQUENT ITEMSET MINING  We formally define representative frequent itemset min- ing, basing our notation on that used in [6].

Definition 1 (Itemset Database). A transaction database is defined by a set of transactions. Each transaction is defined by a set of items. Let I be a set of m items and T be a set of n transactions. An itemset database D is an m?n table in which each Dij ? 0, 1, such that Dij = 1 iff item i is included in transaction j.

Definition 2 (Coverage of an Itemset). Given an itemset database D and an itemset I , the coverage ?D(I) of itemset     I in D is the set of transactions in which I appears, i.e.:  ?D(I) = {t ? D|?i ? I : Dij = 1}.

Definition 3 (Support of an Itemset). The support of an itemset I in D is the number of transactions in which I occurs, i.e.:  supportD(I) = |?D(I)|.

Definition 4 (Frequent Itemsets). Given an itemset database D, an itemset I , and an integer frequency threshold ?, an itemset I is ?-frequent, or frequent for short, if it appears in at least ? transactions in D, i.e. supportD(I) ? ?.

The frequent itemset mining problem is the task of finding all frequent itemsets in a database. In this paper, our algorithm and experiments will consider the specific case of maximal frequent itemsets.

Definition 5 (Maximal Frequent Itemset). Given a ?- frequent itemset I in an itemset database D, I is maximal if for all itemsets I ? ? I , I ? is not ?-frequent in D.

Informally a representative set of maximal frequent item- sets is a subset of all maximal frequent itemsets that exem- plifies which items appear in frequent itemsets and which do not.

Definition 6 (Representative Set of Frequent Itemsets).

Given the set F of maximal frequent itemsets for itemset database D, R is a representative set of frequent itemsets for F iff ?i ? ?{{i|i ? I : Dij = 1}|I ? F} there exists an itemset in R such that Ri = 1, and ?i ?  ?{{i|i ? I : Dij = 0}|I ? F} there exists an itemset in R such that Ri = 0.

We are often interested in finding representative itemsets that satisfy some notion of optimality. While finding repre- sentative sets of minimum cardinality might appear natural, they are intractable to compute. We will, therefore, concern ourselves with finding representative sets that are minimal with respect to set inclusion.

Definition 7 (Minimal Representative Set of Frequent Item- sets). Given the set F of maximal frequent itemsets for itemset database D, R is a minimal representative set of frequent itemsets for F iff for any proper subset F ? of F , F ? is not representative.

As in the case of representative explanations, we can state a similar result from [5] to give us a tight bound on the cardinality of a minimal representative set of itemsets.

Theorem 1 (Cardinality of a Minimal Representative Set of Itemsets). The size of any minimal representative set of explanations is at most m, the number of items, and this bound is tight.

Proof: Equivalent to the proof of Theorem 2 in [5].

We can generalise the above definition to the case of k-ary representative itemsets where we compute a representative set that exemplifies how tuples of items of size up to k are included and excluded from the set of itemsets. For example, in Table VI we present a set of of 2-ary representative itemsets that shows how all pairs of frequent items are included or excluded from the set of itemsets to present a higher level notion of representativeness.

Table VI A FULLY REPRESENTATIVE SET OF 2-ARY ITEMSETS.

Items Itemset i1 i2 i3 i4 i5 I5 0 0 0 0 1 I12 1 1 0 0 0 I13 1 0 1 0 0 I14 1 0 0 1 0 I25 0 1 0 0 1 I134 1 0 1 1 0 I234 0 1 1 1 0  Note that in the extreme case where k is maximum we have the set of all maximal frequent itemsets. Therefore, k is a parameter can allows the user to specify how to compactly present the set of all frequent itemsets. However, for the remainder of this paper we will consider the basic case in which we are exemplifying single items.



IV. THE ALGORITHM  Yang has reported that the problem of mining maximal frequent itemsets is NP-hard [7]. Therefore, we cannot expect to find an efficient algorithm for computing a rep- resentative set of itemsets. We propose an algorithm, REP- RESENTATIVEITEMSET, presented as Algorithm 1, inspired by that for computing representation explanations of over- constraint CSPs [5].

The frequent predicate in the algorithm is satisfied when an itemset is ?-frequent in the dataset. The grow function takes two sets of items and tries to greedily add items from the second set into the first set, providing a way of generating maximal itemsets when used in conjunction with the frequent predicate.

The algorithm relies on two sets of items, RS and ES, to ensure representativeness. RS maintains the items that need to be included in at least one frequent maximal itemset, while ES maintains the set of items that must be excluded by at least one frequent maximal itemset.

The algorithm then comprises two phases. The first phase (lines 1?12) greedily searches for maximal frequent itemsets that contain the items that need to be included based on RS.

For every item i in I , while there are items to be covered in our set of itemsets, the algorithm greedily searching for a maximal itemset containing i. In order to find a maximal itemset which contains as many items in RS as possible, grow takes i and greedily adds items from RS while still     Algorithm 1: REPRESENTATIVEITEMSET Data: D an itemset database; I a set of items; ? a minimum  frequency threshold.

Result: X a minimal representative set of maximal frequent  itemsets.

1 X ? ?; 2 RS ? I; 3 ES ? I; 4 foreach i ? I do 5 if RS = ? then 6 break;  7 if i ? RS ? frequent({i}, ?,D) then 8 R? grow({i}, RS); 9 R? grow(R, I);  10 X ? X ? {R}; 11 RS ? RS \ (RS ?R); 12 ES ? ES \ (ES ? (I \R)); 13 TSESI? findExTrans(ES,D); 14 foreach t ? TSESI do 15 if ES = ? then 16 break;  17 if (ES ? t) ? ES then 18 D? ? portionData(t,D); 19 R? findExcluLCM(ES \ (ES ? t), D?); 20 if R 	= ? then 21 R? grow(R, I \ t); 22 X ? X ? {R}; 23 ES ? ES \ (ES ? (I \R)); 24 break;  25 minimize(X ); 26 return X ; 27 function grow(S,G) 28 foreach c ? G \ (G ? S) do 29 if frequent(S ? {c}, ?,D) then 30 S ? S ? {c}; 31 return S;  ensuring that the itemset is frequent. It then tries adding items from the whole set of items I to guarantee R is a maximal itemset. When a maximal itemset is found, it is added to the set of representative itemsets X . We update RS by removing items that appear in both RS and R. We also update ES by removing items in ES but not in R.

The second phase (lines 13?24) searches for maximal itemsets that exclude items from ES. In some cases in which there is no item occurring in the dataset sufficiently frequently, all the maximal itemsets to construct a repre- sentative itemset are found in the first phase. The minimize operation in line 25 guarantees the result is minimal by re- moving redundant itemsets from the minimal representative set. X is the representative maximal itemset.

I is the set of all the items. In the k-representative  itemset, when k = 1, it is the set of all single items.

When k > 1, it is the set of all the tuples of items up to  cardinality k. R is the current maximal itemset. TSESI is a transaction set that excludes the items in ES computed using the function findExTrans. The portionData function returns a smaller dataset focused on the occurrences of specific items; the subset of the data is stored as D?.

The findExcluLCM function uses the LCM algorithm to return a maximal itemset from the portion of the data under consideration.



V. EXPERIMENTS  The objective of our experiments was to demonstrate the following two features of our representative itemset mining approach. Firstly, we sought to evaluate the size of the representative itemsets one can find in practice.

Secondly, we investigated whether one can benefit from the significantly smaller size of a representative set of itemsets from a computational perspective. Our experiments show that the size of a representative itemset can be five orders of magnitude smaller than the number of maximal frequent itemsets, and that they can be computed significantly faster than a state-of-the-art itemset miner.

We based our experiments on a set of benchmarks taken from the CP4IM project database.1 Our results are presented in Table VII. We list the datasets studied, specifying in each case the number of transactions (#trans) and number of items (#items) for each. Using a 10% frequency threshold (we list the corresponding frequency used in each case as ?thres?) we compute the full set of maximal itemsets (#maximal) using the state-of-the-art itemset miner, LCM [3]. Table VII clearly shows that the size of the set of maximal frequent itemsets can be extremely large, e.g. in excess of 2.5 million in the case of the australian-credit dataset.

In column ?Minimum Rep? we list the minimum size of the set of representative itemsets for each dataset. This col- umn was computed using a constraint program that took as input the set of all maximal frequent itemsets and computed the smallest subset that satisfies the definition of representa- tiveness. While these data points take a significant amount of time to compute, we use them only as a benchmark to evaluate our proposed method. In some cases we record a ??? for ?Minimum Rep? which indicates that the the optimal solution could not be found within one hour. Clearly, the minimum size of the representative set of maximal frequent itemsets can be orders of magnitude smaller than the full set, and much smaller than the total number of items in the dataset.

Against these baselines we compared two efficient meth- ods for generating good representative maximal frequent itemsets. Firstly we used a ?generate and filter? approach that involved using LCM to generate the set of all maximal frequent itemsets and then filtering these to obtain a minimal subset of itemsets that are representative; the minimal set,  1https://dtai.cs.kuleuven.be/CP4IM/     Table VII SUMMARY OF OUR EXPERIMENTS. REPRESENTATIVE ITEMSETS ARE SIGNIFICANTLY SMALLER THAN THE SET OF MAXIMAL FREQUENT ITEMSETS - IN FACT THEY ARE USUALLY SIGNIFICANTLY SMALLER THAN THE NUMBER OF ITEMS IN THE DATASET, CONSISTENT WITH THE THEORY. THEY CAN  ALSO BE FOUND CONSISTENTLY FASTER USING OUR PROPOSED ALGORITHM THAN THE ALTERNATIVE GENERATE-AND-FILTER APPROACH. ALL TIMES REPORTED ARE IN SECONDS.

Benchmark Details Minimum Generate & Filter REPRESENTATIVEITEMSET Dataset #trans #items thres #maximal Rep size time size time zoo-1 101 36 10 230 5 5 0.0092 6 0.0004 vote 435 48 44 2,636 7 8 0.0419 9 0.0026 tic-tac-toe 958 27 96 165 16 18 0.0073 16 0.0047 splice-1 3.190 287 319 988 214 221 0.9850 215 1.3887 soybean 630 50 63 331 18 20 0.0173 21 0.0072 primary-tumor 336 31 34 2,043 7 9 0.0485 8 0.0015 mushroom 8,124 119 812 453 19 24 0.0765 21 0.1564 lymph 148 68 15 5,191 14 18 0.2127 16 0.0023 kr-vs-kp 3,196 73 320 1,984,963 ? 17 158.8402 17 0.0345 hypothyroid 3,247 88 325 2,925,833 ? 16 413.4975 13 0.0353 hepatitis 137 68 14 189,205 ? 18 6.7921 16 0.0023 heart-cleveland 296 95 30 1,647,364 ? 22 88.2854 18 0.0058 german-credit 1,000 112 100 232,107 ? 38 20.4248 35 0.0343 australian-credit 653 125 65 2,580,684 ? 23 213.6676 18 0.0146 anneal 812 93 81 15,977 ? 12 2.5915 9 0.1079  with respect to set inclusion, can be easily computed by iteratively removing any itemset that is not required in order to preserve representativeness. For this approach we record both the size of the minimal representative set and the time taken, in seconds, to compute it.

Finally we use the REPRESENTATIVEITEMSET algorithm proposed in this paper to compute a set of representative maximal frequent itemsets. In Table VII we highlight in bold the cases where our algorithm outperformed the generate and filter approach on either size or time. Clearly our method generates significantly smaller representative itemsets in significantly less time than the generate-and-filter approach, demonstrating the efficacy of our proposed method. In the two cases where our algorithm was outperformed by the generate and filter approach the margin between the methods was less than a factor of two. However, our algorithm is almost always better, with performance that is three orders of magnitude better.

The size of the representative sets generated by the two methods is close to the size of the minimum representative itemset generated by constraint programming model. When comparing the size of representative itemset generated by our algorithm to the one generated by LCM and filtering, the result of our algorithm is as compact as the result of LCM and filtering. The generate and filter method runs faster when the dataset is sparse since the fewer maximal itemsets will take less time to generate, and therefore to filter. Our algorithm works well when the dataset is dense since it only needs to generate candidates that can be used to compose a representative itemset. The runtime performance advantage of our algorithm is related to the density of the dataset.

For example, for the splice-1 dataset, our algorithm takes much more time to run. In this dataset there are 3190 transactions and 287 items, which is quite sparse. The  size of the minimum representative itemset is 214 which is very close to 287, the number of items. This implies that the number of item differences between two different maximal itemsets in the splice-1 dataset is very small.

Also the size of the minimum representative itemset is 214 which means that our algorithm needs to take at least 214 iterations to find the representative itemset. For finding every maximal itemset it needs to try to grow 286 items in this dataset. Sparsity, a high number of items, and a high number of transactions, are the reasons our algorithm takes more time to run in this setting. When the dataset is dense, even with a high number of transaction and items, our algorithm performs significantly better than the generate and filter method.



VI. RELATED WORK  Itemset mining has received a significant amount of atten- tion in the data mining and knowledge discovery communi- ties. While the classic task is frequent itemset mining, there are many other variations including closed frequent itemset mining, maximal frequent itemset mining, and discrimina- tive itemset mining, to name but a few [6]. Both maximal and closed frequent itemsets can be regarded as a condensed representation of the frequent itemset [8]. However, their number is still intractably large in general.

The Apriori algorithm is one of the classic algorithms for frequent itemset mining, and was also the first algorithm written for association rule mining [9], [10]. It is a breadth- first search algorithm. The Apriori algorithm suffers from many drawbacks, e.g. it tends to generate too many candidate subsets and must fully explore a subset before it gets a result.

Direct Hashing and Pruning is a variation of Apriori algorithm [11], [12]. While it also generates a large set of candidate itemsets, it uses a hash structure to store and     manipulate the itemsets allowing it to prune the itemsets it has computed. It, therefore, can filter unnecessary itemsets making the algorithm more efficient than the original Apriori algorithm.

There are many other frequent itemset mining algorithms, e.g. dynamic itemset counting [13], continuous associa- tion rule mining [14], FP-Growth Algorithm [15], FP- Growth* [16], Eclat [4], transaction mapping [17]. One of the best known frequent itemset mining methods is LCM, which essentially a depth-first efficient algorithm [3].

All of these algorithms attempt to improve the runtime performance of frequent itemset mining, but they all suffer from the problem of finding very large sets of itemsets.

This contrasts with the work we present here, which can be regarded as a principled basis for reducing the set of frequent itemsets produced.

Constraint programming-based approaches have also been proposed [6]. The primary objective of these approaches is to introduce a declarative approach to itemset mining in which arbitrary side constraints can be incorporated into the itemset mining process.



VII. CONCLUSIONS AND FUTURE WORK Frequent itemset mining is one of the most common  of data mining tasks. However, while many algorithms for computing a set of all frequent itemsets have been developed, they do not directly tackle the challenge posed by the size of the resulting set of itemsets.

In this paper we proposed a novel approach to computing a compact representation of a set of maximal frequent itemsets based on the notion of representativeness. We exemplified the principles behind our approach, presented a novel algorithm for computing a representative set of itemsets, and demonstrated the effectiveness of the approach on a suite of well-known benchmarks.

Our framework can be generalised so that we compute pairs, triples, etc. of frequent itemsets. In this respect our approach can be regarded as a parameterised version of tra- ditional frequent itemset mining that provides a mechanism for controlling the size of the result set. Specifically, one has access to the traditional frequency threshold, but also the maximum arity of the tuples of itemsets being exemplified.

As future work we would like to consider alternative forms of representiveness, and develop more efficient algo- rithms for enumerating them.

