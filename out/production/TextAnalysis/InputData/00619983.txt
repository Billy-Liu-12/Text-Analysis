

ABSTRACT: It is too difficult t o  discover useful documents on web without rich background knowledge. In this paper, with applying techniques of the textual data mining to  the web resource discovery, we try to  derive effective association rules in order t o  submit more effective queries. From 1995, we have been developing the resource discovery system, Mon- dou, which derives associative keywords from collected and parsed Japanese web pages. This paper includes a brief eval- uation of our system and java applet in order t o  visualize search results with multi-dimensional measurements.

1 Introduction  The volume of web documents is increasing exponentially, it makes difficult to find cool URLs for various users. Es- pecially, increasing of web documents makes it difficult to find out the adequate URLs including invaluable informa- tion, and to  discover the relationship among world wide web sites[3].

Many search engines, Lycos, AltaVista and many others in the web, make it possible to  retrieve web documents by the technology of textual database as a legacy system using typ- ical boolean expressions. However, without rich background knowledge about the relations or structures of keywords, it is impossible to  judge whether interesting documents really include the combination of several keywords. Therefore, in order to describe effective queries, it is important t o  grasp the suitable combination or descriptions of keywords, which exist in the web as textual database.

We develop the search engine with applying techniques of textual data mining to the web resource discovery[7]. Our developed search engine provides the search results including associative keywords, users are easily able to modify initial query with boolean expressions of keywords.

In this paper, we explain the ability of our developing search system, which is named as Mondou, with applying our proposed mining algorithm to the collected Japanese HTML documents. RCAAU means the ?retrieval location by weighted association rule? in the digital ?monde?, and R-C-A-A-U also spells Mondou. Using RCAAU, we may gain insight into one of the methods of Zen. The URL? is also referred from many search pages in Japan.

Our Mondou executed more than one million queries re- quired by anonymous users from February in 1996. We an-  ? h t t p :  //www . kuamp. kyoto-u.  ac . jp/labs/inf ocom/mondou/ index-e . html  alyze the part of log, and evaluate the effectiveness of our developed search strategies.

2 Approach to web mining  2.1 Structure of web space We consider web space as a typical hyper graph, we try to analyze the structure of web space by following two types of links.

Inside link: t o  another page on the same web server.

Outside link: to pages on other web servers  ............. +..

..*+ 0 ........ : ................ .,,?.. ........ .; . .  y ?- ..+.

i 0 0 ; :  ......... ......

. .  . .

: *. . .  : *. ..f .............

- inside links ............ * outside links  ..........

.*.., site  .-._. ...........

Figure 1: Inside links and outside links  We estimate the hyper links in the web by the values of ( s p , i p ,  o p ) ,  which is the combination of the document size, the number of inside links, and the number of outside links for the parent document P in Figure 1. Then, each child documents CI, are referred by parent P ,  we can also describe (sk,Zk,ok) for C k .

We define the following cost function p k  in order t o  evalu- ate the quality of contents C k .

p ,  = (s, - ik ? w, - Ok . W O ) / S k .

We define W, and WO,  as the weighted values for inside  and outside links respectively. Thus, we could evaluate p k as the approximate cost of the several attributes for wek documents. Figure 2 shows average utilized points p k  for thc part of the web space, that  are evaluated for 6,621 parenl documents including 18,397 links in jp-domain with W, = 1( and WO = 30. From these figures, it must be too difficult foi us t o  discover the interesting contents ck by the function o (sp,ip, o p )  based on only links.

0-7803-3905-3/97/$10.00@1997 IEEE     Therefore, in this paper, we regard the web space as a simple textual database with hyper links, which doesn?t have strongly integrated data model. documents.

by the following equations, where K includes any combina- tion of keywords from all keywords K: related with retrieving  ?i: 100 1 I ?5 80 ft 60  0 2000 4000 6000 8000 10000  Document size (Bytes)  E 100   0 5 10 15 20 25 30 35 40  Number of inside links  ,? 60  0 5 10 15 20 25 30 35 40 45 50  Number of outside links  Figure 2: Utilized point vs. size, inside links, outside links  2.2 Textual data mining  At present, data mining is noteworthy field to  be studied based on various kinds of researches, such a.s machine learn- ing, inductive learning and knowledge representation, with considering characteristic features of database[4, 2, 6, 51.

[n order to make it possible to  retrieve web documents more sophisticatedly by derived keywords, We extend the typical mining algorithm to  derive association rule[l].

Weighted association rule We have a brief sketch for mining weighted association  rule[7]. Basically, we extend the original mining algorithm to handle weighted keywords for markup language, especially for tags in HTML.

For example, the rule of ?program + database? from the sets of { program } and { program, database } will be found in databases by satisfying of the threshold values.

We create all rules whose confidence is equal t o  or greater than minconf. If rules, { program } and { program, database }, are derived from the set of keywords, we discover the rule ?program 3 database,? where the values of support and confidence are important measurement for the strongness of rules.

In addition to the conditions of threshold values, in the case of retrieving keyword k;, if IC; appears wtJ times in doc- uments T,, we consider that kJ has the weight of w i j ,  and define aij = (kJ, w , ~ ) .

Thus, we select documents T,(i E I )  including set of key- words K = { k j l j  E J }  from all documents set 7. Given T, including atJ = ( k J , w y ) ,  sup(K) = Nu N ( K )  can be defined  3 Mondou  3.1 Structure of Mondou Mondou consists of the following three main modules, (1) agent, (2) database, (3) query server, which are shown in Figure 3.

WWW Resources  CGI i  Daitabase LA Figure 3: The structure of Mondou  Generally, the first module is called as the robot, spider or agent[9], and the robot collects web documents in the net and store them into the textual database. In addition to the stan- dard functions of the robot, our intelligent agent parses col- lected documents by several methods including natural lan- guage processing[lO] for Japanese documents. Moreover, in order t o  collect more interesting documents, our agent often visits t o  special URLs as interesting web pages, if they (chil- dren) are referred many times from other web pages (outside parent pages).

The database stores huge numbers of attribute values not only about keywords, but also date, size of documents and the number of links from other URLs.

The CGI (Common Gate Interface) module of query server is the search program, ancl it provides search results and mining association rules.

The input form of Mondou is shown in Figure 4, it is possi- ble to enter combination of search keywords using AND and NOT boolean expressions in each empty box.

When one submitted initial keyword knowledge, Mondou provided several keywords of association, ?engineering, sys- tems, $U;% (knowledge in .Japanese), acquisition? and so on, which is shown in Figure 5 .  Consequently, even by apply- ing our proposed algorithm without taxonomies, conceptual trees or ontologies, we are .able to  grasp the association of important keywords in their interesting URLs.

Figure 4: Input form of Mondou  3.2 Quality of associative keywords  At present, we have been operating Mondou in the net, and we try to examine the quality of search queries, patterns of combination of keywords and so on.

Table 1 shows typical examples of derived keywords, the number of URLs and related keywords derived by our algo- rithm.

Thus, we can easily get interesting combination of the key- words that can be treated as several meanings in web docu- ments. Most of beginners could easily grasp the structure of web documents via association of keywords.

Moreover, from February to October in 1996, Mondou ex- ecuted 931,537 queries submitted from the netters. Surpris- ingly, there are only 20,734 queries (2.23%) with NOT ex- pression, it is too difficult for most of users to describe the query with adequate NOT keywords.

The number of query patterns is 338,535, and 51,510 pat- terns (15.2%) are described by only one keyword, 287,025 (84.8%) patterns are described using more than two key- words. Most of users can submit various queries using the derived keywords. Furthermore, keywords including all ex- ecuted queries covers 129,445 words (40.5%) for all 319,426 keywords] which are stored in our database. Thus, our Mon- dou can provide the rich combination of keywords in order to modify initial submitted query.

As a result, by using textual data  mining algorithm in Mondou, web surfers could get much more information about the relationship of keywords in the natural way. Even if users don't know well about web documents to be find out, it is possible to  discover the interesting URLs quickly.

Figure 5: Output results from Mondou  3.3  It is also necessary to  develop a visual interface that can express information with multi-dimensional metric including network environment on client side, and we can focus on interesting sets with derived association rule. Then, we have been developing an interactive search interface by Java in Figure 6, we show one example of search results with the attributes as shape, area size, brink interval and so on.

In current implementation, we represent the cost of access time from users t o  the web server, and relevance of the URLs including given keywords. Moreover, the size of documents as area, support sets by derived keywords as color, and struc- ture of URLs as arrows with quantity are also presented.

Visualization: results of web mining  4 Conclusions and future works  In order to retrieve efficiently web documents by suitablc queries, we applied the algorithm of mining association rules which is extended to  handle weighted keywords in HTML documents, which are collected by agents. Many users car easily focus on interesting web resources without the knowl- edge of taxonomy, or intelligent data  dictionary given bj data.base administrators. We can conclude that our proposec algorithm works very effectively in searching textual data  ir the web.

