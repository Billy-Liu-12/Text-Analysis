A FAST ALGORITHM OF MINING ASSOCIATION RULES IN NETWORK  MANAGEMENT

Abstract: This paper presents nowadays study and research of KDD,  points out the shortcoming of classical Apriori's algorithm.

Our research has put forward the AprioriNEW algorithm based on reducing database,' and analyses and appraises to this algorithm in progress. This algorithm has been applied to mine the Trap's information in the network management.

Keywords: Data mining; Association rule; Network; Frequent itemset; Transaction database  0 In-efficient utilization of data mining result in each cycle.

These lead to a serious decrease to the algorithm efficiency.

Many optimized methods of Apriori's algorithm have been put forward recently, most of the algorithms are based on memory optimization, this is the limitation of the algorithm. This paper puts forward an improved algorithm on the basis of the database reducing. It can reduce the searching space and composing branch. It can also improve the efficiency of mining.

1 Introduction 2 Basic concept and theory  With the fast growing of network technology, especially the techniques in Internet fields, the network infer-structure becomes more and more complicated, this leads to an urgent demand of efficient management solution to network.

Many study and research have been carried out in network  , management field recent years, i.e. Neural Networks, Artificial Intelligence, of which Expert System has been testified as an efficient solution. The Knowledge acquisition is the key problem in Expert System. We need a method that can mine knowledge from the Trap's information automatically and effectively. KDD (Knowledge Discovery in Database) in network management is new technology, various methods, theories and tools have been put forward in the data processing fields. For example, classification, clustering, sequence pattern mining and association rule, etc, of which association rule is a very important and active mining method.

The association rule firstly puts forward by R.Agrawal in 1993"I. It was used to mine association rule in the customer business transaction database, and to discover relationship between the different items. The nucleus of R.Agrawal's method is Apriori's algorithm. It can find out frequent item set in the power sets on the principle of statistics. This algorithm can be divided into two parts, first, Apriori's algorithm search frequent item sets in database, and then it creates association rules from those frequent item sets. The major shortcomings of this algorithm are: 0 power sets of items generation is needed  cycling search of database occurred  In the data mining, the database can be transaction databases or relational databases. Relational databases can work as transaction databases by using the predicate logic.

The mining method of association rule in the transaction databases is suitable for relational databases. Here are some narration and definitions of conceptions [*I which will be used in this article later.

Definition 1: Let I={il ,i, ,..., i m  ) be a set of items, then D={ c Tid, TA T c I )  is a transaction database, where Tid is an identifier which be associated with each transaction..

Definition 2: Let X E I, Y C_ I, and X n Y= 4 ,  we called X 3 Y as association rule.

Definition 3: Suppose c is the percentage of transactions in D containing A that also contain B, then the rule X J Y has confidence c in D. I f s  is percentage of transactions in D that contain A U B, then the rule X j Y has support s in D.

Definition 4: Hypothesis X E I, minsup is the smallest support. If the frequency of X is greater than or equal to minsup, then X is called as frequent itemset, otherwise X is called non-frequent itemset.

Our purpose is searching for association rules with the smallest support degree and the smallest confidence degree.

The classical algorithms can mine those rules by scanning D repeatedly. Its efficiency is very low if the D is a huge database. Analyzing the process of mining rules, we find out many properties of transactions and many transactions which can be deleted from D. Those properties, included property 13] of Apriori, can be described as below:  0-7803-7508-4/02/$17.00 02002 IEEE  91 5  http://163.com    Theorem 1: Supposed X c T,Y frequent itemset, then X must be a frequent itemset. That is (VX)(VY)((Y E T A  X + ( X m u n t  2 mincount))  Where X.count and Y.count stands for X's count and Y's count in the database, and mincount is the minimum support degree count.

Proof: Let T= {tl , t, , -. e, tn }be records of D. According to the definition of the minimum support degree, we get the formulation mincount=minsup*IDI. Since Y is a frequent itemset, there are at least mincount records included Y.

Since X E Y, there are at least mincount records included X from the transitivity of the inclusive relationship.So , X.counter2mincount.

Theorem 2: Given X E T ,  Y c T ,  and X E Y .  If X is a non-frequent itemset, then Y muse be a non-frequent itemset. That is (VX)(VY)( (Y c T A X  c Y A X.count e min count) + (Y.count < min count)) Proof: This theorem can be proved using disproof. Suppose Y is a frequent itemset, that is, Y.count 3 mincount.

Because of X Y, X must be a frequent itemset by theorem 1, that is X.count2mincount. This is contradictory with X.count < mincount. Therefore, if X were a non- frequent itemset, Y must be non-frequent itemsets.

Theorem 3: Suppose we have got Lk and Lk is a set of k- itemset. If T C I and ITI=k, then we can delete T from database.

Proof: The conclusion can be founded obviously. Because the transactions, in which the cardinal number is smaller than or equal to k , do not include in c, (i>k), the transaction T is not used for data mining when i is greater than k. Therefore, we can delete T from database.

Theorem 4: Suppose X c T, Y C T, X E Y, and IYI=IXI+l.

If X is a non-frequent itemset, Y is also a non-frequent itemset and can be delete from database.

Proof: The proof can be divided into two steps.

First, Let's prove Y is a non-frequent itemset. Because X is a non-frequent itemset and X C Y ,  Y must be a non- frequent itemset by theorem 2.

Next, proves that Y does not have any unknown frequent itemsets. Suppose X= {til, t,, , . , t,k } and IXI=k. We can get Y=XU {trm}, where {t,,)is any set, IYI=k+l. The k- itemsets of Y are:  T, and X C Y. If Y is a  Y A Y.count 2 mincount)  That is,X must be a frequent set.

bll, t,2, - . , tlk 1, {t,l, tr2,  -. , t,k-, , t ,  X k l ,  4 2  9 . . . 9 q k - 2 ,  t l k  7 t ,  x * . . 9 -b12 9 t 13  1 * * * 9 l1k 9 tIrn 1  Because frequency of Y's subsets has been known in mining Lk , Y does not have any unknown subsets.

Therefor, we can delete itemset Y and its subsets from database.

Theorem 5 : Let X C T and Y C T, where IYI=2 and IXI 3 2 .

If X and Y are non-frequent, XUY and its subsets can be deleted form database.

Proof: '.* X and Y are non-frequent itemsets.

.*. X U Y is a non-frequent itemsets by theorem 2.

Let X={tml,tm2,..-,tmk} and Y={tnl,tn2},where IXI=k(k 32) .  We can get  xu Y={tm1 ,tm2 ,"',t, ,t,l , tn2} Where IX U YI=k+2. The k+l-itemsets of X U Y are:  {tml 7 t m ,  9 . ' .  9tmk 9 tn1}9 {tml 9 tm2 9  {tml,  t m ,  t d - 1 ,  t , , ,  t u , } , {t,l, t,, ,-.., tmk-2 9 t ,  9 t,, , t,, 1,  9 tmk 9 t n 2 } ,  {tm19 tm2 9 ' . ' 9  ' d - 3  9 t&-l 9 tmk 9 tnl  9 tn2},.'*9  i t m 2  9 tm3 9 . ' .  9 tmk 9 tn l  9 tn2 1 Because those itemsets are supersets of X or Y.

According to theorem 2, they are non-frequent itemsets, their k-itemsets are known after X has been mined.

Therefore X U Y and its subsets can delete from database.

For example, suppose (a,b,c} and (d,e) are a non- frequent itemsets. We can get that la,b,c,d,e) is a. non- frequent itemset and can erase [a,b,c,d,e), (a,b,c,dJ,Ia,b,c,e),Ia,b,d,e),{a,c,d,eJ and {b,c,d,eJ from database.

Theorem 6: Suppose X G T ,  Y G T ,  X and Y are non- frequent itemsets. If all subsets of X (or Y) are non-frequent itemsets, we can delete X U Y and its subsets from database.

Proof: '.* X is a non-frequent itemset.

.*. X U Y is also a non-frequent itemset Let (VW) (W C X), (VZ) (Z E Y). All subsets of XU  Y belong to one of following circumstances: W U Y, Z U X or W U Z. Because X, Y, W, and Z are non-frequent itemsets, we can get that all subsets of X U Y are non- frequent itemsets according to theorem 2. Therefore, they can be deleted from database.

When we want to delete records from database by this theorem, we always judge a element of tree which root is X U Y and high is min{lXl,lYl)-1. For example, suppose (a,b,c,d}, [ e,f,g} and all subsets of {e,f,g} are non-frequent itemsets. We can get that following subsets are non- frequent itemsets: (a,b,c,d,e,f,gJ [a,b,c,d,e,f),Ia,b,c,d,e,gl,[a,b,c,d,f,g),[a,b,c,e,f,g),(a,b,d,e  (a,b,c,d,e),Ia,b,c,d,fJ,Ia,b,c,e,f),[a,b,d,e,f),[a,c,d,e,f),{b,c, d,e,f) .....

Ib,c,d,e,f),{b,c,d,e,g},{b,c,d,f,g),{b,c,e,f,g),(b,d,e,f,g),(c, d,e,f,g I  Because subsets frequency, of which the cardinal numbers is equal to 4 ,is known after {a,b,c,d} has been mined, it has no influence on the data mining when we  ,f,g),ia,c,d,e,f,g},(b,c,d,e,f,g)  91 6     delete them form database. So, we can delete [ a,b,c,d,e,f,g} and its subsets from database.

Theorems above are the foundation of the new algorithm.

Taking into consideration of the complicated nature of construction algorithm, we implement above theorems exclusive of theorems 6 in this article.

3 The algorithm of mining association rules  Because Apriori algorithm Scan database repeatedly, its efficiency is very low. In recent years, some optimization algorithms have been put forward by some scholar. For example, Savaseres etc 14] has designed the algorithm based on Divides, Parks etc ['I has put forward to the algorithm of the Hash, Toivonen etc ['I has designed the algorithm based on Sampling. This article put forward a algorithm by reducing redundancy records of database. The reducing norms are based on the theorem 3, theorem 4 and theorem 5,here is a list of the norms: Norm 1: The k-itemsets can be deleted from database after L k  has been mined; Norm 2: The (k+l)-itemsets which it include non-frequcnt k-itensets can be deleted from database after L k  has been mined Norm 3: The (k+2)-itemsets which include a non-frequcnt k-itenset and a non-frequcnt 2-itenset can be deleted from database after L k  has been mined  According to above norms, we design a algorithm which is similar to algorithm designed by R.Agrawa1 etc. This algorithm can be divided into two parts: 0 !Find all frequent itemsets; 0 Generate strong association rules from the frequent  itemsets.

Because second part is simpler then first one, we only give the AprioriNEWs algorithm to find all frequent itemsets.

The AprioriNEWs algorithm is listed as below: Algorithm: AprioriNEW Input: DB, minsup Output: Result Result:=[ } k:=l; c k  = [large 1-itemsets} While( Ck ) do Begin  Created a counter for all itemsets; for (i= 1 ;k=IDB I;i++) begin  if I Ti I=k-1, 2;: can be deleted from database; f (x  C S k - 1 ,  2;: C DB,I 2;: I=k+l, q.-X c S2), can be deleted; if( c DB,X C Sk-, ,I 2;: I-IXI=O),  q. can be deleted;  if( Ti DB, q. c c k  ), Ti .counter++; end Lk = [ t k  ck and t.counter>minsup}; s k  =(tit? ck and t.counteruninsup}; If (k==2) s2 = s k  ; The support degree of Lk has no change; Result: = Result U Lk k=k+ 1 ;  End Where ck is candidate itemsets, 2;: is i-th record of  database, S, is non-frequent k-itemsets, S2 is non-frequent 2-itemsets.

4 The algorithm performance analysis and evaluation  Algorithm AprioriNEW can find all frequent itemsets and reduce database with non-frequent itemsets. Suppose:   The number of records of database is n The minimum support degree is s The algorithm finished after circulation k times Average cardinal number of candidate items is p Average cardinal number of non-frequent itemsets is m Average cardinal number of frequent itemsets is 1 Average number of records which it reduces is r.

The complexity of time of Apriori is :  where pkn is the complexity of time of mining database in k  times; - k is the complexity of time of creating all '(' +  candidate items.

can get the complexity of time is: When we use AprioriNEW to mine same database, we  k c i=l p [ n  - r(i -11, + &,n i=l - r(i - l)] +- 2 k  Where C p [ n  - r(i -I)] is the complexity of time of scanning itemsets, the complexity of time of reducing  database with non-frequent itemsets is m[n - r(i - I)] .

Obviously, algorithm AprioriNEW can effectively reduce records and Yo's frequency when T is a very large number.

It can also loading the fairly large database into memory.

In order to explain the merit of algorithm AprioriNEW, we realize it with Visual C++6.0 on a Pentium 4 PC. We have mined 10 transaction databases respectively in the test.

The record number of databases ranged from 1000,2000,to 10000. In order to compare mining process of the database,  i=l  k  i=l      we used the identical the minimum support degree (15%) in itemsets and transaction database, set forth 3 theorems of the figure 1 reducing the database and then put forward the  A~rioriNEW algorithm. In our test, the alaorithmNEW is go aa  qa  i o    n  Fig. 1. Compares AprioriNEW with Apriori  Figure 1 shows that the AprioriNEW algorithm is more efficient than Apriori in mining 10 databases, the horizontal axle shows 10 different databases and the vertical axle shows the time of mining (the unit is second). Figure 2 shows mining of a database with 10000 records by the AprioriNEW with different minimum support degree, the vertical axle shows the number of reducing records in same database. The unit is thousand. The horizontal axle shows 10 differentsupportdegrees(in percentage).

W V I V W t -  L n Q o K l m a  - I -  . -  . -  n - c d m .-I I?- 4 W m d  d  Fig. 2. Reduced database by AprioriNEW  superior to the ilassical algorithm -if transaction database can be reduced. According to the running result of the algorithm, the efficiency of mining is directly connected with the structure of record. In case of database reducing records nature getting into worse, that is, it does not satisfied the condition in theorem 3,4,5, the efficiency of AprioriNEW descend quickly. Therefore, we still need to improve algorithm AprioriNEW in the feature.

