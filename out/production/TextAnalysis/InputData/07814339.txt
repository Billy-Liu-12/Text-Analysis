0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Abstract?We introduce a family of Newton-type greedy selection methods for ?0-constrained minimization problems. The basic idea is to construct a quadratic function to approximate the original objective function around the current iterate and solve the constructed quadratic program over the cardinality constraint. The next iterate is then estimated via a line search operation between the current iterate and the solution of the sparse quadratic program. This iterative procedure can be interpreted as an extension of the constrained Newton methods from convex minimization to non-convex ?0-constrained minimization. We show that the proposed algorithms converge asymptotically and the rate of local convergence is superlinear up to certain estimation precision. Our methods compare favorably against several state-of-the-art alternatives when applied to sparse logistic regression and sparse support vector machines.

Index Terms?Sparsity, Newton methods, greedy selection, optimization, M-estimation.

F  1 INTRODUCTION  Sparsity models have received broad interests in high- dimensional statistical learning and signal processing with significant success achieved in theory and practice. Such models are usually formulated as the following sparsity- constrained minimization problem:  min x?Rp  f(x), s.t. ?x?0 ? k, (1)  where f : Rp 7? R is a smooth convex objective function and ?x?0 denotes the number of nonzero entries in x. For example, the special case of (1) in linear regression mod- els has gained significant attention in Compressed Sensing (CS) [12]. In supervised sparse learning, loss functions such as logistic loss, hinge loss and exponential loss are often employed for classifier training. Unfortunately, due to the cardinality constraint, Problem (1) is not only non-convex, but also NP-hard in general even for quadratic loss [20].

Thus, it is desirable to develop efficient computational pro- cedures to approximately solve this problem.

Inspired by the efficiency of constrained Newton-type methods for convex optimization, we introduce a class of Newton-type greedy pursuit methods for the non-convex problem in (1). The proposed iterative methods are based on a two-level strategy to find descent directions: at the outer level, a sequence of quadratic functions are constructed to approximate the original objective function; at the inner level, an iterative hard-thresholding algorithm is used to solve a subproblem of ?0-constrained quadratic program.

The intermediate estimators are obtained via performing line search along the descent directions. We have analyzed the convergence and parameter estimation performance of  ? The authors are with the Jiangsu Province Key Laboratory of Big Data Analysis Technology, Nanjing University of Information Science and Technology, Nanjing, 210044, China.

E-mail: xtyuan@nuist.edu.cn, qsliu@nuist.edu.cn  ? A preliminary version of the this article has appeared in the Proceedings Recognition (CVPR 2014).

Manuscript received September 02, 2014; revised November 12, 2015 and December 18, 2016.

the proposed Newton-type greedy selection methods. Our main results are summarized in below:  1) The estimation error of the asymptotic output to any target k-sparse solution x? is upper bounded by the multiplication of the norm of the top 3k (in magnitude) entries of ?f(x?).

2) The main algorithm converges asymptotically. Its local estimation error vanishes at a superlinear rate before the above error bound is reached. This con- trasts our method from existing first-order greedy selection methods with linear or sublinear conver- gence rate.

The numerical performances of the proposed algorithms are evaluated on several learning tasks of sparse logistic regres- sion and sparse support vector machines. Both theoretical and numerical results confirm that our methods are able to gain substantial improvement in computational efficiency without sacrificing accuracy.

This article is an extended version of our preliminary work [34] which investigates a family of exact Newton greedy selection methods (i.e., the quadratic approxima- tion is constructed using second-order Taylor expansion).

Comparing to the short version, the current paper makes the following changes: i) it presents a broader class of Newton-type greedy selection methods which allow quasi- Newton-type construction of quadratic approximation; ii) a line search step is introduced in the main algorithm to guarantee asymptotic convergence; and iii) the theoretical analysis is improved with stronger results established.

The organization of this paper is as follows: We review some related work and introduce notation in the remaining subsections of ?1. The Newton-type greedy pursuit algo- rithms are presented in ?2 and then analyzed in ?3. The specializations of our methods to sparse logistic regression and sparse support vector machines are presented in ?4.

Monte-Carlo simulations and experimental results on real data are reported in ?5. Finally, we conclude this article in ?6.

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   1.1 First-order greedy selection methods  A large body of greedy algorithms for CS have been pro- posed including Matching Pursuit [19], Orthogonal Match- ing Pursuit (OMP) [23], Compressive Sampling Match- ing Pursuit (CoSaMP) [21], Iterative Hard Thresholding (IHT) [5], and subspace pursuit [10] to name a few. The main theme of these iterative algorithms is to use the residual error from the previous iteration to successively approxi- mate the positions of non-zero entries and estimate their values. While the measure of discrepancy, least square error, used in CS models is often desirable for signal processing applications, it is not the appropriate choice for a variety of other applications. For example, in statistical machine learning the log likelihood function is commonly used in logistic regression and graphical models learning. Thus, it is desirable to develop theory and algorithms that apply to a broader class of sparsity-constrained learning problems as given in (1). To this end forward greedy selection algorithms have been proposed to select out the non-zero entries in a sequential way [27], [35]. To make the greedy selection pro- cedure more adaptive, [37] proposed a forward-backward algorithm which takes backward steps adaptively when- ever beneficial. The forward-backward-type method has also been investigated in [16] for sparse graphical models learning tasks. Recently, Bahmani et al.proposed the Gradi- ent Support Pursuit Method (GraSP) which selects multiple entries in the current iteration and update their values based on the gradient vector in the previous iteration [1]. More recently, several nonlinear variants of IHT were presented and analyzed in [4], [15], [32].

The algorithms just mentioned all belong to the category of first-order methods which select the supporting sets via only accessing the gradient information. Given the selected non-zero entries, there are two conventional strategies to update their values: 1) by doing line search as done in [27], [36], or 2) by minimizing the objective function over the selected supporting set as done in [35], [37]. The former strategy is extremely cheap in per-iteration cost but often requires a substantial number of iterations to reach an accurate solution; whereas the latter converges faster (e.g., usually in a geometric rate) but tends to have much more expensive per-iteration cost especially when the objective function is complex.

1.2 Constrained Newton-type methods  In traditional convex optimization, the constrained Newton- type method (also known as scaled gradient projection) [3, ?2.3] iteratively minimizes a smooth convex objective f over a convex set ?, i.e.,  min x  f(x), s.t. x ? ?. (2)  Typically, function f is assumed to be twice continuously differentiable over ?. At iteration t, this method approxi- mates the objective around the current iterate x(t) with a local quadratic model:  Qf (y;x (t)) :=f(x(t)) +?f(x(t))?(y ? x(t))  +  (y ? x(t))?H(t)(y ? x(t)),  (3)  where H(t) ? 0 is an approximation to the Hessian matrix ?2f(x(t)). To generate the next iterate that decreases the objective while remaining feasible, the method minimizes the quadratic model Qf (y;x(t)) over the original feasible set ?:  x?(t) = argmin y??  Qf (y;x (t)).

The new iterate is then obtained by simply setting  x(t+1) = x(t) + ?(x?(t) ? x(t)),  where ? ? [0, 1] is the step-size selected via backtracking line search under Armijo condition. Constrained Newton- type methods share many of the appealing properties of their unconstrained counterparts. For example, if H(t) = ?2f(x(t)) and the backtracking line search accepts the step- size ? = 1, then this method achieves a superlinear rate of convergence in the neighborhood of any point that satisfies the second-order sufficiency conditions for a minimizer [3, ?2.3]. In general, convergence to a stationary point can be guaranteed under the assumption that the eigenvalues of H(t) are bounded between positive constants, and the rate of convergence can be superlinear under certain additional conditions.

Constrained Newton method and its variants have re- ceived wide interests in machine learning [25], [26]. In [25], Schmidt et al.proposed to construct the quadratic approxi- mation using a limited-memory Broyden-Fletcher-Goldfarb- Shanno (L-BFGS) update [7]. The resulting method has been shown to frequently beat first-order methods in ?1- constrained minimization tasks where evaluation of the function is substantially more expensive than projection onto the ?1-norm ball [25]. Constrained Newton-type meth- ods can also be extended as proximal Newton-type methods in the scenario where the objective function f admits a de- composition into a smooth term and a non-smooth term [2], [24], [30]. The computational efficiency of proximal Newton- type methods has also been demonstrated in extensive machine learning applications [13], [14], [22].

The appealing theoretical and computational properties of the constrained Newton-type methods inspire us to ask a natural question: can the Newton-type methods be extended from convex constrained minimization to non- convex ?0-constrained minimization? In this paper, we will affirmatively answer the question by developing tractable algorithms along with concrete analysis. Although the an- swer is positive, such an extension is highly non-trivial as Problem (1) is simultaneously non-convex and NP-hard.

1.3 Notation  The notation used in this paper is summarized in Table 1.

2 NEWTON-TYPE GREEDY PURSUIT METHODS  In this section, we introduce Newton-type greedy pursuit method as an adaption of the constrained Newton-type method to Problem (1).

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   TABLE 1 Notation used in this paper.

Symbol Description x a column vector in Rp [x]i the ith entry of vector x xF the restriction of x to index set F , i.e., [xF ]i = [x]i  if i ? F , and [xF ]i = 0 otherwise supp(x, k) the indices of x with the largest k absolute values xFk the restriction of x to the top k (in magnitude)  entries. We will simplify xFk to xk without causing ambiguity in the context  ?x? the Euclidean norm of vector x which is equal to? x?x  ?x?1 the ?1-norm of vector x which is equal to ?d  i=1 |xi| ?x?? the ??-norm of vector x which is equal to maxi |xi| A a square matrix in Rp?p [A]ij the element on the ith row and jth column of matrix  A  A?F the principal submatrix of A with rows and columns indexed in set F  AF the restriction of A to index set F , i.e., [AF ]ij = [A]ij if i, j ? F , and [AF ]ij = 0 otherwise  A?1F provided that A?F is invertible, [A ?1 F ]i,j = [A?  ?1 F ]ij  if i, j ? F , and [A?1F ]ij = 0 otherwise AF? (A?F ) the rows (columns) of matrix A indexed in F |A|? the element-wise ??-norm of A which is equal to  max1?i?p,1?j?q |Aij | ?A?Frob the Frobenius norm of matrix A which is equal to??p  i=1  ?p j=1 A  ij  ?A? the spectral norm of matrix A which is equal to sup?x??1 ?Ax?  vect(A) the vectorization of matrix A I the identity matrix of compatible size  2.1 The algorithm  Newton-type greedy pursuit procedure generates a se- quence of intermediate k-sparse vectors x(0), x(1), . . . from an initial sparse approximation x(0). A high level summary of its procedure is described in Algorithm 1. At the time instance t, assume we have a matrix H(t) ? 0 which is an approximation to the Hessian matrix {?2f(x(t))}. In Step (a), we compute y?(t) as an approximate solution (up to a precision ?) to the quadratic model Qf (y;x(t?1)) (see (3) for its definition) over the constraint ?y?0 ? k. In Step (b), x?(t) is obtained via greedy line search between x(t?1) and y?(t)  with respect to Qf (y;x(t?1)). In Step (c), x(t) is estimated via proper line search between x(t?1) and x?(t) with respect to the original objective.

There are several strategies for choosing the positive semi-definite matrix H(t) ? ?2f(x(t)) for building the quadratic model Qf (y;x(t)). When a positive-definite Hes- sian is readily available, we can simply set H(t) = ?2f(x(t)) and thus obtain a NewTon Greedy Pursuit (NTGP) method. By doing so, the quadratic model Qf (y;x(t)) becomes merely the approximation obtained via second-order Taylor expan- sion of f . When an exact estimation of Hessian is expensive, we may use certain quasi-Newton strategy (e.g., Davidson- Fletcher-Powell (DFP), Powell-Symmetric-Broyden (PSB), or the Broyden-Fletcher-Goldfarb-Shanno (BFGS)) to build H(t) as an approximation of ?2f(x(t)) and obtain a Quasi- NewTon Greedy Pursuit (QNTGP) method. For large scale problems, limited memory quasi-Newton updates such as L-BFGS can be used to reduce memory consumption. Gen- erally speaking, most strategies for choosing Hessian ap-  proximations in Newton-type methods can be adapted to choosing H(t) in Newton-type greedy pursuit methods.

Algorithm 1: Newton-type Greedy Pursuit  1 Initialization: x(0) with ?x(0)?0 ? k, e.g., x(0) = 0 typically.

2 for t = 1, 2, ... do 3 (a) Find any y?(t) with ?y?(t)?0 ? k such that for all  y? with ?y??0 ? k,  Qf (y? (t);x(t?1)) ? Qf (y?;x(t?1)) + ?, (4)  where ? ? 0 represents the sub-optimality of the approximate solution;  4 (b) Let x?(t) = (1? ??)x(t?1) + ??y?(t) where ?? = argmin??[0,1] Qf ((1??)x(t?1)+?y?(t);x(t?1));  5 (c) Update x(t) = (1? ?t)x(t?1) + ?tx?(t) in which ?t satisfies the following sufficient descent condition for some ? ? (0, 0.5):  f(x(t)) ? f(x(t?1))? ??t(??(t))?H(t?1)??(t), (5)  where ??(t) := x?(t) ? x(t?1).

6 end  Output: x(t)k or x? (t) k = argminsupp(x)?supp(x(t),k) f(x).

Particularly, in the step (c) of Algorithm 1, we use a line search procedure to select a step length ?t that satisfies a sufficient descent condition in (5) in which ? ? (0, 0.5] is an user specific parameter controlling the fraction of the decrease in f predicted by linear extrapolation that we will accept. A simple example is a backtracking line search strategy which backtracks along the search direction until a suitable step length is selected. Such a procedure performs admirably in practice.

The algorithm optionally outputs x(t)k or x? (t) k =  argminsupp(x)?supp(x(t),k) f(x) as the final solution. The fol- lowing proposition indicates that such top-k truncation operations will not much hurt the estimation performance of x(t) towards a sparse target solution.

Proposition 1. Let x? be k?-sparse vector. For any vector x and k ? k?, it holds that  ?xk ? x?? ? 1.62?x? x??. (6)  Assume that f is M2k-smooth and m2k-strongly convex (see the definition in (9)). Let x?k = argminsupp(x?)?supp(x,k) f(x  ?). Then the following inequality holds:  ?x?k ? x?? ? 1.62?x? x??  1? ? +  m2k ? 2k??f(x?)??  M22k(1? ?) , (7)  where ? = ? 1?m22k/M22k.

Proof: The inequality (6) uses the truncation error bound in [28, Theorem 1]. By applying the result of [33,    0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   Lemma 4] and (6), we obtain  ?x?k ? x?? ? ?x?supp(x?)\supp(x,k)?  1? ? +  m2k ? 2k??f(x?)??  M22k(1? ?)  ??xk ? x?? 1? ?  + m2k  ? 2k??f(x?)??  M22k(1? ?)  ?1.62?x? x?? 1? ?  + m2k  ? 2k??f(x?)??  M22k(1? ?) .

This proves the desired bound in (7).

Based on this proposition, if the estimation error ?x(t) ?  x?? is well bounded, so will be ?x(t)k ? x?? and ?x? (t) k ? x??.

Therefore, we will focus on bounding the term ?x(t) ? x?? in our theoretical analysis.

2.2 The ?0-constrained quadratic model At the t-th iteration, with the quadratic approximation Qf (y;x  (t?1)) in hand, we need to approximately minimize the following sparsity-constrained quadratic program:  min y  Qf (y;x (t?1)), s.t. ?y?0 ? k. (8)  This subroutine is a standard CS problem which is still NP- hard. There exist several efficient greedy pursuit methods for CS including OMP [23], [29], CoSaMP [21], and IHT [5].

Here we resort to the well studied IHT method, as described in Algorithm 2, to approximately solve such an inner loop subroutine.

Algorithm 2: Iterative Hard Thresholding (IHT) for solving the subproblem in (8).

1 Initialization: y(0) = x(t?1).

2 for ? = 1, 2, ... do 3 (S1) Compute gradient descent:  y?(?) = y(??1) ? ??Qf (y(??1);x(t?1)); 4 (S2) Identify support: T (?) = supp(y?(?), k); 5 (S3) Minimizer over support:  y(?) = argminsupp(y)?T (?) Qf (y;x (t?1));  6 end Output: y(?).

The computational cost at each iteration of Algorithm 2 is dominated by the steps (S1) and (S3). Since vector y(??1)? x(t?1) is at most 2k-sparse, the computational complexity of evaluating ?Qf (y(??1)) = ?f(x(t?1)) + H(t?1)(y(??1) ? x(t?1)) in (S1) is O(kp). In (S3), y(?) is given by the solution of the following linear system  ?2T (?)f(x (t?1))y = ??T (?)f(x(t?1)) + [H(t?1)x(t?1)]T (?) .

Therefore, to estimate y(?) it is sufficient to compute the principle submatrix ?2  T (?) f(x(t?1)) restricted on the index  set T (?) and then solve a linear system. As |T (?)| = k, a direct solution leads to O(k3) complexity1. When k is relatively large, the step (S3) can be iteratively solved via generic convex solvers.

One may compare Algorithm 1 with GraSP [1] as a state- of-the-art greedy selection method. At time stamp t, GraSP  1. We consider here that solving linear systems takes cubic time. This time complexity however can be improved.

first minimizes the objective function over the union of the top k entries of x(t?1) and the top 2k entries of ?f(x(t?1)), then it selects the top k entries of the resultant vector and updates their values via objective minimization, which becomes x(t). The operation of objective minimization over the selected support, often referred to as debiasing, has been shown to improve the performance in other algorithms too. Different from GraSP and others, NTGP implements the debiasing steps with respect to Newton-type quadratic approximations. It is different to compare the complexity of these two strategies of debiasing in general settings. In practice, as we will show in ?5 that Newton-type greedy pursuit methods are frequently more efficient than GraSP in the considered learning tasks.

3 THEORETICAL ANALYSIS This section is devoted to analyzing the convergence behav- ior and parameter estimation performance of Algorithm 1.

In ?3.1, we introduce several core technical conditions on which our analysis relies. Then we show in ?3.2 that Al- gorithm 1 converges asymptotically subject to standard assumptions imposed on the objective function. In ?3.3 and ?3.4, we show that analogue to traditional Newton-type methods, NTGP and QNTGP possess superlinear/quadratic rate of convergence after sufficient iteration. In ?3.5, we establish some guarantees on the accuracy of IHT (i.e., Algorithm 2) for solving the ?0-constrained quadratic sub- problem.

3.1 Preliminaries The following concept of restricted condition number of a positive semi-definite matrix H is key to our analysis.

Definition 1 (Restricted Condition Number). Let H be a  positive semi-definite matrix. For all s-sparse vectors x, let  Ms(H) = sup u  { u?Hu | ?u?0 ? s, ?u? = 1  } and  ms(H) = inf u  { u?Hu | ?u?0 ? s, ?u? = 1  } .

Then we say H has a Restricted Condition Number (RCN) ?s, or in short ?s-RCN, if 1 ? Ms(H)/ms(H) ? ?s.

Based on RCN, we further introduce the following con- cept of stable restricted Hessian [1] which characterizes the curvature of a cost function over sparse subspaces.

Definition 2 (Stable Restricted Hessian). Suppose that f is  twice continuously differentiable. Then we say f has a Stable Restricted Hessian (SRH) with constant ?s, or in short ?s-SRH, if ?2f(x) has ?s-RCN for all s-sparse x.

The SRH property is analogue to the restricted isometry property [9] in standard CS analysis. It basically requires that the curvature of the cost function over the sparse subspaces can be bounded locally from above and below such that the corresponding bounds have the same order.

We next introduce the concept of restricted Lipschitz Hessian which characterizes the continuity of the Hessian    0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   matrix over sparse subspaces. To simplify the notation, we will abbreviate in the following analysis ?F f := (?f)F , ?sf := (?f)s and ?2F f := (?2f)F .

Definition 3 (Restricted Lipschitz Hessian). Suppose that  f is twice continuously differentiable. We say f has Restricted Lipschitz Hessian with constant ?s (or ?s- RLH), if  ??2F f(x)??2F f(y)? ? ?s?x? y?  for all index set F with cardinality |F | ? s and all x, y with supp(x) ? supp(y) ? F .

In the remaining parts of this section, we will abbreviate ms(x) = ms(?2f(x)) (Ms(x) = Ms(?2f(x))) and m(t)s = ms(H  (t)) (M (t)s = Ms(H(t))). It is reasonable to assume that there exists some Ms > 0 (ms > 0) such that Ms(x) ? Ms (ms(x) ? ms) for all s-sparse vector x. The definitions of Ms and ms imply that f is Ms-smooth and ms-strongly convex, i.e., for any x, y satisfying ?x? y?0 ? s,  ms  ?x? y?2 ? ?f(x; y) ? Ms  ?x? y?2, (9)  where ?f(x; y) := f(x)? f(y)??f(y)?(x? y).

3.2 Asymptotic convergence analysis  We establish here several asymptotic convergence properties of Algorithm 1, which are crucial to the local non-asymptotic analysis to be given shortly in the next subsection. In the following analysis, we denote ??(t) := x?(t) ? x(t?1).

Lemma 1. At any time instance t, ??(t) satisfies  ?f(x(t?1))???(t) + (??(t))?H(t?1)??(t) ? 0.

Proof: By the definition of x?(t) we know that for any ? ? [0, 1],  Qf (x? (t);x(t?1)) = Qf ((1? ??)x(t?1) + ??y?(t);x(t?1))  ? Qf ((1? ???)x(t?1) + ???y?(t);x(t?1)).

That is, the following holds for any ? ? [0, 1]:  ?f(x(t?1))???(t) + 1 (??(t))?H(t?1)??(t)  ???f(x(t?1))???(t) + ?  (??(t))?H(t?1)??(t).

After rearrangement and simplification,  ?f(x(t?1))???(t) + 1 + ?  (??(t))?H(t?1)??(t) ? 0.

The claim follows by letting ? ? 1 in the above inequality.

Lemma 2. Assume that ???(t)?0 ? s. For any ? ? [0, 1], if  ?t ? min { 1,  2(1? ?)ms Ms  } ,  then we  f(x(t)) ? f(x(t?1))? ?t?(??(t))?H(t?1)??(t).

Proof: From the update rule for x(t) and the smooth- ness of f we have  f(x(t)) ?f(x(t?1)) + ?t?f(x(t?1))?(x?(t) ? x(t?1))  + ?2tMs  ?x?(t) ? x(t?1)?2  ?f(x(t?1)) + ?t(?f(x(t?1))?(x?(t) ? x(t?1))  + ?2tMs 2ms  (x?(t) ? x(t?1))?H(t?1)(x?(t) ? x(t?1))) ?1 ?f(x(t?1)) + ?t(?f(x(t?1))?(x?(t) ? x(t?1))  + ?t(1? ?)(x?(t) ? x(t?1))?H(t?1)(x?(t) ? x(t?1))) ?2 ?f(x(t?1))  ? ?t?(x?(t) ? x(t?1))?H(t?1)(x?(t) ? x(t?1)), where ??1? follows the selection of ?t and ??2? follows from Lemma 1. This proves the desired bound.

Theorem 1. The sequence {f(x(t))} generated by Algo-  rithm 1 converges. Moreover the sequence {???(t)?} converges to zero.

Proof: From Lemma 2 we know that with proper line search, the sequence {f(x(t))} is decreasing whenever x?(t) ?= x(t?1). If x?(t) = x(t?1) occurs, then we have x(t) = x(t?1) and thus the algorithm terminates. Therefore the sequence {f(x(t))} must converge. Also, from Lemma 2 we have  ?t?m (t?1) s ???(t)?2  ? ?t?(??(t))?H(t?1)??(t) ? f(x(t?1))? f(x(t)),  which implies ???(t)? ? 0 as t increases.

The monotonicity of NTGP, as shown by Theorem 1,  makes it possible to use simple stopping criteria such as sub-optimality |f(x(t))? f(x(t?1))| or ???(t)? to control the termination of algorithm.

3.3 Local estimation error analysis for NTGP We further analyze the local convergence behavior of NTGP.

The following lemma shows that the unit length eventually satisfies the sufficient descent condition in (5).

Lemma 3. Assume that ?x?(t)?0 ? s for all t and f has ?s-  RLH. If H(t) = ?2f(x(t)), then the unit length satisfies the sufficient descent condition (5) with ? ? 1/3 for sufficiently large t.

Proof: Since the function f has ?s-RLH,  f(x?(t)) ?f(x(t?1)) +?f(x(t?1))???(t)  +  (??(t))??2f(x(t?1))??(t) + ?s  ???(t)?3.

From Lemma 1 and (??(t))??2f(x(t?1))??(t) ? ms???(t)?2, we further get  f(x?(t)) ?f(x(t?1))? 1 (??(t))??2f(x(t?1))??(t)  + ?s 6ms  ???(t)?(??(t))??2f(x(t?1))??(t)  =f(x(t?1))  ? (  ? ?s  6ms ???(t)?  ) (??(t))??2f(x(t?1))??(t).

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   When t is large enough, from Theorem 1 we know that ???(t)? ? ms/?s and thus  f(x?(t)) ? f(x(t?1))? 1 (??(t))??2f(x(t?1))??(t),  which implies that the sufficient descent condition in (5) holds for ?t = 1 and ? ? 1/3.

Lemma 3 tells that if the line search is conducted under the sufficient descent condition (5) with ? ? 1/3, then the unit length is admissible, i.e., x(t) = x?(t) when t is sufficiently large. Our next mission is to bound the local estimation error ?x?(t) ? x?? between x?(t) and an arbitrary k?- sparse vector x?. The following lemma shows the progress of exact Newton step carried out in a sparse subspace spanned over an index set F .

Lemma 4. Assume that f is twice continuously differen-  tiable. Consider an index set F with |F | ? s and an vector x satisfies supp(x) ? F . Assume that ?2F f(x) is invertible. Let y = x ? [?2F f(x)]?1?F f(x). Consider any x? with supp(x?) ? supp(x) ? F .

(a) It holds that  ?y ? x?? ? o(?x? x??) +m?1s ??sf(x?)?.

(b) Furthermore if f has ?s-RLH, then we have  ?y ? x?? ? 0.5?sm?1s ?x? x??2 +m?1s ??sf(x?)?.

Proof: Part (a): From the definition of y we have  y ? x? =x? x?? [?2F f(x)]?1?F f(x) =[?2F f(x)]?1[?2F f(x)(x? x?)??F f(x) +?F f(x?)]  ? [?2F f(x)]?1?F f(x?).

Since Taylor?s theorem tells us that  ?F f(x)??F f(x?) = ? 1  ?2F f(x+ t(x?? x))(x? x?)dt,  we have???2F f(x)(x? x?)??F f(x) +?F f(x?)?? =  ????? 1 [?2F f(x)??2F f(x+ t(x?? x))](x? x?)dt  ???? ? ?x? x??  ? 1  ??2F f(x)??2F f(x+ t(x?? x))?dt.

By substituting the preceding inequality to (10) we obtain  ?y ? x?? ? ??[?2F f(x)]?1?? ???2F f(x)(x? x?)??F f(x) +?F f(x?)?? + ??[?2F f(x)]?1?? ??F f(x?)?  ?m?1s ?x? x?? ? 1  ??2F f(x)??2F f(x+ t(x?? x))?dt  +m?1s ??sf(x?)?.

Since f is twice continuously differentiable, we have that ?2F f is continuous. It follows that ?y ? x?? ? o(?x ? x??) + m?1s ??sf(x?)?.

Part(b): If f has ?s-RLH, then the proceeding relation yields  ?y ? x?? ? m?1s ?x? x??2 ? 1  ?stdt+m ?1 s ??sf(x?)?  = 0.5?sm ?1 s ?x? x??22 +m?1s ??sf(x?)?.

This proves the desired result.

Let us denote Ft := supp(x(t)). We now present our  main result on the local estimation error of NTGP.

Theorem 2. Let x? be a k?-sparse vector and k ? k?. Let F? = supp(x?) and s = | ?t Ft ? F? |. Assume that f is a twice continuously differentiable function that has ?s- SRH. Given that t is sufficiently large and ? ? 1/3.

(a) It holds that  ?x(t) ? x?? ? o(?x(t?1) ? x??) + ?s(x?, ?), (10)  where ?s(x?, ?) := m?1s (1 + ? 1/2 s )??sf(x?)? +  m ?1/2 s ?1/2.

(b) Furthermore if f has ?s-RLH, then  ?x(t) ? x?? ? ?s?x(t?1) ? x??22 + ?s(x?, ?), (11)  where ?s := 0.5?sm?1s (1 + ? 1/2 s ).

Proof: Part (a): Let F := Ft?1 ? Ft ? F? . Obviously |F | ? s. Consider the following vector  x?t = x (t?1) ? [?2F f(x(t?1))]?1?F f(x(t?1)).

It is easy to verify that for any y with supp(y) ? F ,  Qf (y;x (t?1))  =f(x(t?1)) +?f(x(t?1))?(y ? x(t?1))  +  (y ? x(t?1))??2f(x(t?1))(y ? x(t?1))  =f(x(t?1)) +?F f(x(t?1))?(y ? x(t?1))  +  (y ? x(t?1))??2F f(x(t?1))(y ? x(t?1))  =  (y ? x?t)??2F f(x(t?1))(y ? x?t) + constant,  (12)  where the constant is not dependent on y(t?1). By invoking the part (a) in Lemma 4, we have that  ?x?t ? x?? ? o(?x(t?1) ? x??) +m?1s ??sf(x?)?. (13)  It follows from triangle inequality and (12) that  ?x?(t) ? x?? ??x?(t) ? x?t?+ ?x?t ? x??  ?ms(x(t?1))?1/2 ? (x?(t) ? x?t)??2F f(x(t?1))(x?(t) ? x?t)  + ?x?t ? x?? ?1 ?ms(x(t?1))?1/2  ? (y?(t) ? x?t)??2F f(x(t?1))(y?(t) ? x?t)  + ?x?t ? x?? ?2 ?ms(x(t?1))?1/2  ? (x?? x?t)??2F f(x(t?1))(x?? x?t) + ?  + ?x?t ? x??  ?ms(x(t?1))?1/2 ? (x?? x?t)??2F f(x(t?1))(x?? x?t)  +ms(x (t?1))?1/2?1/2 + ?x?t ? x??  ?((Ms(x(t?1))/ms(x(t?1)))1/2 + 1)?x?t ? x?? +ms(x  (t?1))?1/2?1/2  ?(?1/2s + 1)?x?t ? x??+m?1/2s ?1/2, (14)    0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   where ??1? is due to the step (b) of Algorithm 1 and ??2? follows from (4) and (12). By combing (13) and (14) we obtain  ?x?(t) ? x?? ?o(?x(t?1) ? x??) +m?1s (1 + ?1/2s ) ??sf(x?)? +m?1/2s ?  1/2.

By invoking Lemma 3 we have x(t) = x?(t) for sufficiently large t, and thus the inequality (10) is valid.

Part (b): By using the part (b) in Lemma 4, we obtain  ?x?t ? x?? ? 0.5?sm?1s ?x(t?1) ? x??22 +m?1s ??sf(x?)?. (15)  By combing (15) and (14) we obtain  ?x?(t) ? x?? ?0.5?sm?1s (1 + ?1/2s )?x(t?1) ? x??22 +m?1s (1 + ?  1/2 s )??sf(x?)?+m?1/2s ?1/2.

Since x(t) = x?(t) when t is sufficiently large, the inequal- ity (11) holds.

Remark 1. The main message Theorem 2 conveys is that  under proper conditions, up to a precision ?s(x?, ?), the sequence {x(t)} generated by NTGP converges locally towards any k?-sparse vector x? at superlinear rate. If we further assume that f has ?s-RLH, then the part (b) of Theorem 2 shows that the rate of convergence is at least quadratic. The estimation error term ?s(x?, ?) indicates how accurate the estimate can be. It is controlled by the norm ??sf(x?)? and the precision ? for minimiz- ing the ?0-constrained quadratic model. Particularly, if ?f(x?) = 0 (i.e. x? is the stationary point of (1)) and ? = 0, then ?s(x?, ?) = 0. In this case, provided that x(0)  is close enough to x?, NTGP is able to exactly recover x? asymptotically at superlinear rate. This result is analo- gous to accuracy guarantees for estimation from noisy measurements in CS [9], [21], but with improved order of local convergence rate.

Remark 2. The two key conditions used in our analysis are: (i) f is twice continuously differentiable; and (ii) f has ?s-SRH. These two conditions are also key to the analysis of GraSP [1] as a gradient support pur- suit method. Roughly speaking, the main result in [1, Theorem 1] shows that GraSP needs to impose a con- dition ?s ? (1 +  ? 3)/2 to guarantee an estimation  error (6 + 2 ? 3)??sf(x?)?/ms. In contrast, our Theo-  rem 2 does not require ?s to be upper bounded by a constant. In particular, when ? = 0, Theorem 2 says that the estimation error of our algorithm is bounded by (1 +  ? ?s)??sf(x?)?/ms which is dependent on ?s.

Clearly, when ?s ? (1 + ? 3)/2, 1 +  ? ?s ? 6 + 2  ? 3.

That is, our estimation error bound is tighter than that of GraSP in terms of the factor before ??sf(x?)?/ms.

Remark 3. The local superlinear rate of convergence con- trasts NTGP from first-order greedy selection methods which can only be shown to converge linearly. By using a slightly stronger assumption that f has RLH, we fur- ther derived the local quadratic rate of convergence for NTGP.

The following result is a direct consequence of Lemma 3 and Theorem 2(b). This result more precisely shows the con- ditions under which the local quadratic rate of convergence and the estimation error bound can be guaranteed.

Corollary 1. Let T be a time instance such that for all t ? T the unit length satisfies the sufficient descent con- dition (5) with ? ? 1/3. Assume that ?x(t0)?x?? ? ??1s /4 for some t0 ? T and ?s(x?, ?) ? ??1s /8. Then under the assumptions in the part (b) of Theorem 2, the following holds for all t ? t0:  ?x(t) ? x?? ? ??1s (1/4? 2?s?s(x?, ?)) 2t?t0  + 2?s(x?, ?).

(16)  Proof: This can be proved by induction. Obviously, inequality (16) holds for t = t0. Assume that (16) holds for t ? 1 ? t0. Since t ? t0 + 1 > T , the unit length can be accepted to satisfy the sufficient descent condition (5) with ? ? 1/3. From the part (b) of Theorem 2 we obtain  ?x(t) ? x?? ??s?x(t?1) ? x??22 + ?s(x?, ?) ?1 ??s[??1s (1/4? 2?s?s(x?, ?))2  t?1?t0 + 2?s(x?, ?)]  2 + ?s(x?, ?)  =??1s (1/4? 2?s?s(x?, ?))2 t?t0  + 4(1/4? 2?s?s(x?, ?))2 t?1?t0  ?s(x?, ?)  + 4?s? s(x?, ?) + ?s(x?, ?)  ???1s (1/4? 2?s?s(x?, ?))2 t?t0  + 4(1/4? 2?s?s(x?, ?))?s(x?, ?) + 4?s?  s(x?, ?) + ?s(x?, ?)  ???1s (1/4? 2?s?s(x?, ?))2 t?t0  + 2?s(x?, ?),  where ??1? follows from the assumption ?s(x?, ?) ? ??1s /8.

This completes the induction.

3.4 Local estimation error analysis for QNTGP  We further investigate the local approximation performance of QNTGP. Our analysis relies on the following key assump- tion made on the objective function f and the positive semi- definite scaling matrix H(t):  Assumption 1. Suppose that f is a twice continuously differ- entiable function. Given an integer s, assume that there exists some ?s > 0 such that f has ?s-SRH and H(t)  has ?s-RCN for all t. For any index F with cardinality |F | ? s and supp(xt) ? F ,???(H(t)F ??2F f(x(t)))p(t)F ??? = o(???p(t)F ???)+O(?s(x?, ?)), where p(t)F = ?(H  (t) F )  ?1?F f(x(t)) and ?s(x?, ?) is de- fined in Theorem 2.

This assumption is analogous to the Dennis-More? crite- rion [11] essential to the analysis of unconstrained quasi- Newton methods.

The following is our main result on the local estimation error of QNTGP.

Theorem 3. Let x? be a k?-sparse vector and k ? k?. Let F? = supp(x?) and s = |?tFt? F? |. Assume that Assumption 1 holds. When t is sufficiently large and ? ? 1/3, we have  ?x(t) ? x?? ? o(?x(t?1) ? x??) +O(?s(x?, ?)). (17)  Proof: Let F = Ft?1?Ft?supp(x?). Obviously |F | ? s.

Consider the following vector:  x?t = x (t?1) ? (H(t?1)F )  ?1?F f(x(t?1)) = x(t?1) + p(t?1)F .

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   It is easy to verify that for any y with supp(y) ? F ,  Q?f (y;x (t?1)) = (y ? x?t)?H  (t?1) F (y ? x  ? t) + constant. (18)  Also let us define  x??t = x (t?1) ? [?2F f(x(t?1))]?1?F f(x(t?1)).

By using Lemma 4, we have that  ?x??t ? x?? ? o(?x(t?1) ? x??) +m?1s ??sf(x?)?.

It follows from triangle inequality that  ?x?t ? x?? ??x??t ? x??+ ?x?t ? x??t ? =?x??t ? x??  + ?[?2F f(x(t?1))]?1(?2F f(x(t?1))?H (t?1) F )p  (t?1) F ?  ??x??t ? x??+m?1s ?(?2F f(x(t?1))?H (t?1) F )p  (t?1) F ?  ?o(?x(t?1) ? x??) +m?1s ??sf(x?)? +m?1s ?(?2F f(x(t?1))?H  (t?1) F )p  (t?1) F ?  ?o(?x(t?1) ? x??) +m?1s ??sf(x?)? + o(?p(t?1)F ?) +O(?s(x?, ?)).

Since x?t = x (t?1) + p  (t?1) F , a simple manipulation of the  preceding inequality reveals that ?p(t?1)F ? ? O(?x(t?1) ? x??) +m?1s ??sf(x?)?+O(?s(x?, ?)). Therefore we obtain  ?x?t?x?? ? o(?x(t?1)?x??)+O(m?1s ??sf(x?)?)+O(?s(x?, ?)).

(19)  It follows from triangle inequality and (18) that  ?x?(t) ? x?? ??x?(t) ? x?t?+ ?x?t ? x??  ?(m(t?1)s )?1/2 ? (x?(t) ? x?t)?H  (t?1) F (x?  (t) ? x?t) + ?x?t ? x??  ?(m(t?1)s )?1/2 ? (x?? x?t)?H  (t?1) F (x?? x?t) + ?+ ?x  ? t ? x??  ?(m(t?1)s )?1/2 ? (x?? x?t)?H  (t?1) F (x?? x?t) +m  ?1/2 s ?  1/2  + ?x?t ? x?? ?((M (t?1)s /m(t?1)s )1/2 + 1)?x?t ? x??+m?1/2s ?1/2  ?(?1/2s + 1)?x?t ? x??+m?1/2s ?1/2, By combing (19) and (20) we obtain  ?x?t ? x?? ? o(?xt?1 ? x??) +O(?s(x?, ?)).

According to Lemma 3, x(t) = x?(t) when t is sufficiently large and ? ? 1/3. This proves the desired inequality (17).

3.5 On the convergence of Algorithm 2 Recall that in Algorithm 1, the ?0-constrained quadratic subproblem is assumed to be approximately optimized by Algorithm 2. The following result guarantees the conver- gence of Algorithm 2.

Theorem 4. Let y? be any k-sparse vector. If ? ?  (0, 1/M (t?1) 2k ), then at time instance ? Algorithm 2 either  terminates with T (?) = T (??1) or outputs y(?) satisfying  Qf (y (?);x(t?1)) ? Qf (y?;x(t?1)) + (1? ?)??0,  where ? = 2(??? 2M  (t?1) 2k )m  (t?1) 2k  k ? 0.5 and ?0 = Qf (y  (0);x(t?1))?Qf (y?;x(t?1)).

Proof: If T (?) = T (??1), then Algorithm 2 terminates and the theorem is valid. We now focus on the case of T (?) ?= T (??1). Let F = T (??1) ? supp(y?). For the sake of notation simplicity, we abbreviate Qf (y;x(t?1)) as Qf (y), ?Qf (y(?)) as ?Q(?)f . From the Definition 1 we have  m (t?1) 2k  ?y? ? y(??1)?22  ?Qf (y?)?Qf (y(??1))? (y? ? y(??1))??Q(??1)f ?1 ?Qf (y?)?Qf (y(??1)) +  m (t?1) 2k  ?y? ? y(??1)?22  +  2m (t?1) 2k  ??FQ(??1)f ? 2,  where ??1? follows from Cauchy-Schwartz inequality and ma2/2 + b2/(2m) ? ab for any m > 0. Therefore,  ??FQ(??1)f ? 2 ? 2m  (t?1) 2k  ( Qf (y  (??1))?Qf (y?) ) . (20)  From the step S3 we know that ?T (??1)Q (??1) f = 0. By defi-  nition of T (?) we may decompose T (?) = G1?(T (??1)?G2) with G1 ? supp(?Q(??1)f ), G2 ? T (??1) and |G1| = |G2| = k? ? k. That is, G1 contains the top k? (in magnitude) entries in ?Q(??1)f while G2 contains the bottom k? entries in y(??1). Since T (?) ?= T (??1), we have k? ? 1. From S2 we know that  ?y(??1)G2 ? ? ???G1Q (??1) f ?. (21)  By combing these facts and the preceding inequality we get  ??G1Q (??1) f ?  2 ? (k?/k)??FQ  (??1) f ?   ? 2k ?m  (t?1) 2k  k  ( Qf (y  (??1))?Qf (y?) )  ? 2m (t?1) 2k  k  ( Qf (y  (??1))?Qf (y?) ) ,  (22)  where in the last inequality we have used the fact k? ? 1.

Now let z(?) := y(?)  T (?) = y(??1) +?(??1) where  ?(??1) = ???G1Q (??1) f ? y  (??1) G2  .

From the step S3 in Algorithm 2 and the strong smoothness of Qf we have that  Qf (y (?)) ? Qf (z(?))  ?Qf (y(??1)) + ??Q(??1)f ,? (??1)?+ M  (t?1) 2k  ??(??1)?22  ?Qf (y(??1))? ???G1Q (??1) f ?  2 + M  (t?1) 2k  ?y(??1)G2 ?   + ?2M  (t?1) 2k  ??G1Q  (??1) f ?   ?1 ?Qf (y(??1))? (? ?M (t?1)2k ?  2))??G1Q (??1) f ?   ?2 ?Qf (y(??1))  ? 2(? ?M (t?1) 2k ?  2))m (t?1) 2k  k  ( Qf (y  (??1))?Qf (y?) ) ,    0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   where ??1? is according to (21) and ??2? follows from (22).

By subtracting Qf (y?) from both sides of the above inequal- ity we get  Qf (y (?))?Qf (y?) ? (1? ?)(Qf (y(??1))?Qf (y?)),  where  ? = 2(? ? ?2M (t?1)2k )m  (t?1) 2k  k .

Since k ? 1 and M (t?1)2k ? m (t?1) 2k , it can be verified that  ? ? 0.5. This proves the desired result.

Remark 4. It is interesting to compare Theorem 4 to those  relevant results obtained in [15] for IHT-type methods.

On one hand, our result in Theorem 4 requires a weaker condition on the sparsity level k: in [15], k ? ck? is required for some c relying on the sparse condi- tional number, whilst our result is valid under k ? k?.

On the other hand, the convergence rate parameter ? = O(m2k/M2k) achieved in [15] is superior to the rate ? = O(m2k/(M2kk)) obtained here. It remains an interesting open problem for us to remove from ? the dependency on k. Since the analysis of IHT is by no means the main focus of this paper, we will leave this open problem for future investigation.

4 APPLICATIONS In this section, we will specialize NTGP to sparse logistic regression (in which the Hessian matrix is accessible) and specialize QNTGP to sparse support vector machines (in which the Hessian matrix is unaccessible).

4.1 NTGP for sparse logistic regression  The sparse logistic regression problem is one of the most popular models in pattern recognition and machine learn- ing. Let u ? Rp be a random feature vector and v ? {?1,+1} be its associated random binary label. We assume that the joint density of the feature-label vector (u, v) ? Rp+1 is given by an exponential family distribution:  P(u, v; w?) = exp ( vw??u+B(u)?A(w?)  ) , (23)  where  A(w?) := log ?  v={?1,1}  ? Rp  exp ( vw??u+B(u)  ) du  is the log-partition function. The term B(u) characterizes the marginal behavior of u. Then the logistic model can be interpreted as the following conditional distribution of v given u:  P(v|u; w?) = exp(2vw? ?u)  1 + exp(2vw??u) . (24)  Given a set of n independently drawn data samples {(ui, vi)}ni=1 from the distribution (23), logistic regression learns parameters w via minimizing the following negative of the conditional log-likelihood function:  l(w) :=  n  n? i=1  log(1 + exp(?2viw?ui)).

We consider the following ?0-constrained ?2-regularized logistic regression which is conventionally used in high- dimensional analysis [1]:  min w  f(w) = l(w) + ?  ?w?22, s.t. ?w?0 ? k, (25)  where ? > 0 is the regularization strength parameter. Ob- vious f(w) is ?-strongly convex. The cardinality constraint enforces sparse solution.

To apply NTGP, we need to access the gradient and Hessian of the ?2-regularized logistic loss f(w). Let ?(z) = 1/(1 + exp(?z)) be the sigmoid function. It is easy to show that the gradient ?f(w) = Ua(w)/n + ?w where a(w) ? Rn with [a(w)]i = ?2vi(1 ? ?(2viw?ui)); and the Hessian ?2f(w) = U?(w)U?/n + ?I where ?(w) is an n ? n diagonal matrix whose diagonal entries [?(w)]ii = 4?(2viw  ?ui)(1? ?(2viw?ui)).

4.1.1 On the SRH and RLH properties  We now verify that f(w) has SRH and RLH. The continuity of ?(z) implies the continuity of ?2f(w), i.e., f(w) is twice continuously differentiable. It has been shown in [1, Corollary 1] that under mild conditions, f(w) has SRH with overwhelming probability. The following result further verifies that f has RLH.

Proposition 2. Assume that for any index set F with |F | ? s we have ?i, ?(ui)F ? ? Rs. Then the ?2-regularized logistic loss has ?s-RLH with ?s ? 24sR2s .

Proof: Consider an index set F with cardinality |F | ? s and all w,w? with supp(w) ? supp(w?) ? F . Since ?(z) is Lipschitz continuous with constant 1, we have that  |?(2viw?ui)? ?(2viw??ui)| ?|2(w ? w?)?viui| ? 2?(ui)F ??w ? w?? ? 2Rs?w ? w??.

Using this above inequality and the fact that ?(z) ? 1 we obtain  |?(2viw?ui)(1? ?(2viw?ui)) ? ?(2viw??ui)(1? ?(2viw??ui))|  ?|?(2viw?ui)? ?(2viw??ui)| (1 + ?(2viw  ?ui) + ?(2viw ??ui))  ?3|?(2viw?ui)? ?(2viw??ui)| ? 6Rs?w ? w??.

This yields ??(w)? ?(w?)? ? 24Rs?w ? w??. Therefore,  ??2F f(w)??2F f(w?)?  ? 1 n ?UF??2??(w)? ?(w?)?  ?24 n ?UF??22Rs?w ? w?? ? 24sR2s?w ? w??,  where the last ??? follows from ?UF?? ?? snmaxi ?(ui)F ? ?  ? snRs. This proves the desired  result.

Remark 5. One implication of this result is that when Rs is bounded, then ?s = O(s). This is desirable when the sparsity level s is small whilst the dimensionality p could be huge.

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   4.1.2 On the estimation error bound Concerning the estimation error bound ?s(x?, ?), if the preci- sion level ? = 0, then ?s(x?, ?) is proportional to the restricted norm ??sf(w)?. Therefore, it is desirable to estimate a bound on ??sf(w?)?. The following result establishes a bound on ??sf(w?)?.

Proposition 3. Assume for all j that [u]j ? N (0, ?2). Then  with probability at least 1? 4p?1,  ??sf(w?)? ? 4? ? s ln p/n+ ??w?s?.

Proof: For any index set F with |F | ? s, we can deduce  ??F f(w?)? ???F l(w?)?+ ??w?F ? ?  ? s??l(w?)?? + ??w?s?.

(26)  We next bound the term ??l(w?)??. It is easy to verify that the first derivative of the logistic log-likelihood l(w) yields the cumulants of the random variables v[u]j :  ?l  ?[w]j =   n  n? i=1  {?vi[ui]j + Ev[v[ui]j | ui]} . (27)  Here the expectation Ev[? | u] is taken over the conditional distribution (24). From (27) we have???? ?l?[w?]j  ???? =  ????? 1n n?  i=1  ?vi[ui]j + Ev[v[ui]j | ui] ?????  ? ????? 1n  n? i=1  vi[ui]j ? E[v[u]j ] ?????+  ????? 1n n?  i=1  Ev[v[ui]j | ui]? E[v[u]j ] ????? ,  where E[] is taken over the distribution (23). Since [u]j are zero mean Gaussian variables with variance ?2 and v ? {?1,+1}, it can be shown that  E[exp(?v[u]j)] ? exp ( ?2?2/2  ) .

That is, v[u]j) are sub-Gaussian random variables. There- fore, for any ? > 0,  P (???? ?l?[w?]j  ???? > ?) ?P  (????? 1n n?  i=1  vi[ui]j ? E[v[u]j ] ????? > ?2  )  + P  (????? 1n n?  i=1  Ev[v[ui]j | ui]? E[v[u]j ] ????? > ?2  )  ?4 exp { ?n?   8?2  } ,  where the last ??? follows from the standard large deviation inequality of sub-Gaussian random variables [31]. By the union bound we have  P(??l(w?)?? > ?) ? 4p exp { ?n?   8?2  } .

By letting ? = 4? ? ln p/n, we know that with probability at  least 1? 4p?1,  ??l(w?)?? ? 4? ? ln p/n.

Combing the above inequality with (26) yields the desired result.

Remark 6. If we choose ? = O( ? ln p/n), then with over-  whelming probability ??sf(w?)? vanishes at the rate of O( ? s ln p/n). This bound is superior to the one pro-  vided by [1, Section 4.2] which is non-vanishing.

4.2 QNTGP for sparse L2-SVMs  We further apply QNTGP to estimating parameters of the following sparsity-constrained L2-SVMs with squared hinge loss:  min w  f(w) =  2n  n? i=1  ( max  { 0, 1? viw?ui  })2 +  ?  ?w?2,  subject to ?w?0 ? k.

(28)  For this class of SVMs, the objective f(w) is ?-strongly convex and the cardinality constraint enforces the solution to be k-sparse. Although f(w) is first-order smooth, it is not second-order smooth, and thus NTGP is not directly applicable to this formulation. Alternatively, we can use QNTGP to build quadratic approximations by only access- ing the gradient vectors. In our implementation, L-BFGS is adopted to construct H(t) for QNTGP as it has been witnessed to offer the fastest and most scalable solutions in many cases [3], [6], [25]. At each iteration of Algorithm 1, we first compute the gradient  ?f(w) = ? 1 n  n? i=1  max { 0, 1? viw?ui  } viui + ?w,  and define the quantities  s(t) := w(t+1) ? w(t), g(t) := ?f(w(t+1))??f(w(t)).

Then we use these quantities to update H(t) with the following compact representation  H(t) = ?(t)I ?NM?1N?,  where matrices N ? Rp?m, M ? Rm?m, and ?(t) is a positive scalar given in [8]. Conveniently, we use ?(t) = ((g(t))?s(t))/((g(t))?s(t)). With such an approxima- tion strategy, the required storage to maintain H(t) reduces to O(pm+m2). The updated H(t) is then used to construct the quadratic approximation Qf at w(t). The IHT Algo- rithm 2 for solving the subroutine (4) requires computing ?Qf at each iteration, and hence requires k-sparse matrix- vector products with H(t). With the compact representation, these products can be computed with O(mk) complexity.

5 EXPERIMENTS  In this section, we report some numerical results to demon- strate the accuracy and efficiency of NTGP/QNTGP when applied to sparse logistic regression and sparse SVMs tasks.

All the considered algorithms are implemented in Matlab 7.12 running on a desktop with Core i7 CPU@3.40GHz.

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   5.1 Simulation study We start by evaluating NTGP and QNTGP on a simulated sparse logistical regression task. Let w? be a p = 10000 dimensional vector that has k? = 1000 nonzero entries drawn independently from the standard Gaussian distribu- tion. Each data sample u is normally distributed. The data labels, v ? {?1, 1}, are then generated randomly according to the Bernoulli distribution  P(v = 1|u; w?) = exp(2w? ?u)  1 + exp(2w??u) .

We test with the following two configurations of n and k:  1) Cardinality k is fixed and sample size n is varying: we test with k = k? and n/p ? {0.1, 0.2, ..., 1}.

2) Sample size n is fixed and cardinality k is varying: we test with n = 10000 and k/k? ? {1, 2, ..., 5}.

In both of the above configurations, we set the regular- ization parameter ? = 10?5 in (25). We compare NTGP and QNTGP with three first-order greedy selection meth- ods: the GraSP [1], the FCFGS (Fully Corrective Forward Greedy Selection) [27] and the FoBa (Forward-Backward selection) [37]. All these methods are designed to solve the sparsity-constrained optimization problem (1). GraSP is a hard-thresholding-type method which simultaneously selects at each iteration k nonzero entries and update their values via debiasing over the top k entries in the previous iterate as well as the top 2k entries in the previous gradient.

FCFGS is a forward greedy selection method which itera- tively selects the largest absolute entry of the previous gra- dient, and does the debiasing over all the currently selected coordinates to update the next iterate. FoBa is an adaptive forward-backward greedy selection algorithm which allows elimination of selected variables when the objective does not increase significantly. We initialize w(0) = 0 and set the stopping criterion as |f(w(t)) ? f(w(t?1))| ? 10?5 for all these considered algorithms. The debiasing steps in GraSP/FCFGS/FoBa are all implemented using the Pro- jected Quasi-Newton (PQN) method [25] which, according to our numerical experience, is very efficient in most cases we have tested. The stopping criterion of PQN is set to termination the iteration either when the sub-optimality is below a moderate precision 10?3 or the iteration number exceeds 100. This criterion has been evidenced to lead to the best trade-off between accuracy and efficiency for the considered algorithms.

Figure 1 shows the objective function value (left panel) and CPU running time (right panel) achieved by the con- sidered algorithms under the two experimental protocols.

These results confirm the superiority of NTGP and QNTGP to the three considered first-order greedy selection methods in both accuracy and efficiency. More precisely, from this figure we can observe that:  ? On accuracy: In most cases, NTGP outputs the lowest objective value; NTGP and QNTGP tend to find more optimal solution than the competitive methods. The gap appears to be more apparent as sample size n becomes larger. The FCFGS and FoBa are quite accurate when k is relatively small but deteriorate rapidly as k increase. This is probably because for- ward/backward selection methods are less adaptive  in removing the wrongly selected coordinates from the intermediate support.

? On efficiency: NTGP and QNTGP are comparable to each other and they are significantly faster than the other algorithms. This is as expected because NTGP/QNTGP tend to have cheaper iteration cost than the other methods: at each iteration, the former two optimize a sparse quadratic program while the latter three all need to minimize the original objective function over the selected support so far, which could be expensive when f is highly nonlinear. The gap is more obvious when n is relatively large or k is relatively small.

Concerning convergence speed, we further plot in Fig- ure 2 the objective value evolving curves as functions of CPU running time for fixed sample size n = 5000 and varying sparsity level k ? {1000, 2000, 4000, 5000}. It can be apparently seen from this group of curves that NTGP and QNTGP converge much faster (in running time) than the other considered algorithms. We also notice that QNTGP is slightly more efficient than NTGP in decreasing the objective value, which is mostly attributed to the former?s cheaper per-iteration computational cost.

5.2 Real experiment I: Sparse logistic regression We further evaluate the performance of NTGP for sparse logistic regression on the rcv1.binary (p = 47, 236) [18] and news20.binary (p = 1, 355, 191) [17] which are two popular datasets for binary classification on sparse data. For rcv1.binary, a training subset of size 20,242 and a testing subset of size 20,000 are used, and the algorithms are tested with sparsity parameter k ranging from 100 to 1000 with interval 100. For news20.binary, a training subset of size 10,000 and a testing subset of size 9,996 are used, and the algorithms are tested with sparsity parameter k ranging from 1000 to 10000 with interval 1000. For both datasets, we set the regularization strength ? = 10?5 in (25). The initial parameter vector is set to be w(0) = 0 for all the considered algorithms.

The curves of objective value, testing error and CPU run- ning time are plot in Figure 3. It can be observed commonly from these two datasets that:  ? On optimality and testing accuracy: NTGP achieves competitive performance to GraSP. QNTGP is slightly inferior to NTGP and GraSP, but is signifi- cantly superior to FCFGS and FoBa.

? On efficiency: NTGP is the most efficient one among all the considered algorithms. In many cases, NTGP is ?5 ? ?10 faster than GraSP, FCFGS and FoBa.

QNTGP is as fast as NTGP on rcv1.binary, but slower than NTGP and GraSP on news20.binary. This is probably because when data dimensionality is very high, the L-BFGS construction of quadratic approx- imation to logistic regression could be less accurate in early stage, thus more iterations are needed before converging to a reasonable sub-optimality.

Overall, this group results show that the proposed Newton- type greedy selection methods are able to achieve much better trade-off between accuracy and efficiency than the existing first-order greedy selection methods.

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   0.2 0.4 0.6 0.8 1  0.005  0.01  0.015  0.02  0.025  0.03  n/p  L og  is tic  lo ss      NTGP QNTGP GraSP FCFGS FoBa  0.2 0.4 0.6 0.8 1       n/p  C PU  ti m  e (i  n se  co nd  )      NTGP QNTGP GraSP FCFGS FoBa  (a) Case 1: k = 1000 is fixed and n is varying.

1 2 3 4 5  0.005  0.01  0.015  0.02  0.025  0.03  k/1000  L og  is tic  lo ss      NTGP QNTGP GraSP FCFGS FoBa  1 2 3 4 5       k/1000  C PU  ti m  e (i  n se  co nd  )      NTGP QNTGP GraSP FCFGS FoBa  (b) Case 2: n = 10000 is fixed and k is varying.

Fig. 1. Sparse logistic regression on simulated data: objective value and CPU running time curves of the considered methods.

0 2 4 6 8 10  0.2  0.4  0.6  0.8  CPU time (in second)  L og  is tic  lo ss      NTGP QNTGP GraSP FCFGS FoBa  (a) k = 1000  0 2 4 6 8 10  0.2  0.4  0.6  0.8  CPU time (in second)  L og  is tic  lo ss      NTGP QNTGP GraSP FCFGS FoBa  (b) k = 2000  0 2 4 6 8 10  0.2  0.4  0.6  0.8  CPU time (in second)  L og  is tic  lo ss      NTGP QNTGP GraSP FCFGS FoBa  (c) k = 4000  0 2 4 6 8 10  0.2  0.4  0.6  0.8  CPU time (in second)  L og  is tic  lo ss      NTGP QNTGP GraSP FCFGS FoBa  (d) k = 5000  Fig. 2. Sparse logistic regression on simulated data: objective value versus CPU running time curves of the considered methods. The sample size n = 5000 is fixed and the sparsity level k is allowed to be varying in {1000, 2000, 4000, 5000}.

200 400 600 800 1000  0.1  0.15  0.2  0.25  k  L og  is tic  L os  s      NTGP QNTGP GraSP FCFGS FoBa  200 400 600 800 1000 0.04  0.05  0.06  0.07  0.08  0.09  0.1  k  C la  ss if  ic at  io n  er ro  r      NTGP QNTGP GraSP FCFGS FoBa  200 400 600 800 1000      k  C PU  ti m  e (i  n se  co nd  )      NTGP QNTGP GraSP FCFGS FoBa  (a) rcv1.binary  2000 4000 6000 8000 10000 0.1  0.15  0.2  0.25  0.3  0.35  0.4  k  L og  is tic  L os  s      NTGP QNTGP GraSP FCFGS FoBa  2000 4000 6000 8000 10000 0.04  0.06  0.08  0.1  0.12  0.14  0.16  k  C la  ss if  ic at  io n  er ro  r      NTGP QNTGP GraSP FCFGS FoBa  2000 4000 6000 8000 10000      k  C PU  ti m  e (i  n se  co nd  )      NTGP QNTGP GraSP FCFGS FoBa  (b) news20.binary  Fig. 3. Sparse logistic regression on real data: objective value, classification error and CPU running time curves of the considered methods.

0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2651813, IEEE Transactions on Pattern Analysis and Machine Intelligence   5.3 Real experiment II: Sparse L2-SVMs In this experiment, we evaluate the performance of QNTGP and the considered three first-order methods for sparse L2-SVMs using the same datasets and experimental proto- cols as used in the previous experiment. The reason that NTGP not being involved in comparison is because, as aforementioned, the objective function of L2-SVMs is not second-order smooth. We fix the regularization parameter ? = 10?4 in (28) and set the initial vector w(0) = 0 for all the considered algorithms. Figure 4 shows the curves of objective value, testing errors and CPU running time of the considered algorithms. From this group of results, we observe that: 1) QNTGP and GraSP are comparable in objective value optimality and testing error, and they out- perform FCFGS and FoBa on both datasets; 2) QNTGP is the fastest one among the considered methods on both datasets.

This experiment confirms that QNTGP is an efficient and accurate second-order greedy selection method for sparse SVMs.

6 CONCLUSIONS We proposed NTGP and QNTGP as Newton-type greedy selection methods for sparsity-constrained minimization problems. The main idea is to construct at each iteration a quadratic approximation to the objective function and generate the next iterate via solving the resultant sparsity- constrained quadratic model, followed by proper line search operations. Theoretically we have proved that the pro- posed NTGP and QNTGP algorithms converge asymptot- ically, and up to certain estimation error, they converge superlinearly in a vicinity of a target sparse solution. The estimation error is controlled by the norm of gradient at the target sparse solution and the solution accuracy of the sparse quadratic program. We demonstrated the advantage of NTGP and QNTGP over several first-order greedy pur- suit methods when applied to sparse logistic regression and sparse SVMs learning tasks. To conclude, Newton-type greedy support pursuit methods are not only theoretically sound, but also computationally attractive for sparsity- constrained minimization problems.

