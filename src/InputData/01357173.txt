A Novel Algorithm for Associative Classification of Image Blocks

Abstract  Because of its accurate and robust performance, association rule-based approach is recently used for image classification. However, the existing algorithms for associative classification suffer from inefficiency.

Addressing this problem, a novel algorithm based on atomic association rules is presented and successfully used in image block classification. Mining only the atomic association rules achieves fast image block classification. Using the strong atomic association rules, extracted under a high confidence threshold, can accurately differentiate instances from the image dataset. Furthermore, multi-passes of partial classifications can classify the whole dataset. This algorithm uses a self-adaptive confidence threshold and a dynamic support threshold, both of which are important for good classification performance. The experiments were performed on a standard dataset of image segmentation. The results show the proposed algorithm can classify the image blocks faster, more accurate and robust than the typical associative classification algorithm.

1. Introduction  In recent years, with the rapid development of multimedia and computer networks, the volume of digital images has dramatically increased.

Undoubtedly, there are large amounts of valuable information in these image resources. Image understanding and content-based image retrieval have become hot topics among image processing researchers.

Image segmentation is one of the most important technologies in image processing. For block-based segmentation, it divides an image into its constituent parts. A feature vector is formed for each block by using the color and textural characteristics. The sub- images or image blocks can be classified by supervised or unsupervised learning algorithms.

There exist many classification approaches such as decision tree, support vector machine, genetic algorithm, neural network, and so on. Associative classification is a relatively new approach. Because of its accurate and robust performance, it has drawn much attention in many areas such as that of artificial intelligence, pattern recognition and detection of computer system intrusions.

Associative classification as a new classification approach has drawn the attention of researchers in data mining community [1]-[2], it also finds application in digital image processing [3]-[5].

In this work, we propose a novel approach CAAR, that is, Classification based on Atomic Association Rules. CAAR is different from the typical algorithm for associative classification. Our approach has three obviously characteristics, (1) CAAR only extracts atomic rules under high and self-adaptive confidence thresholds for partial classification, (2) Its classification is completed by multi-passes of partial classifications, and (3) It uses a dynamic support threshold instead of a fixed one.

Because it mines only atomic rules, the algorithm is very fast, although multi-passes classifications are required. CAAR can achieve high accuracy by using strong atomic rules with a high confidence for classifier construction.

The rest of this paper is arranged as follows.

Section 2 introduces associative classification of image blocks and the related definitions. Section 3 describes the image block classification using CAAR approach.

Section 4 presents experiment results. Finally, section 5 draws our conclusions.

2. Associative classification of image blocks  The image block classification is an important step in block-based image segmentation. It consists of three main steps: (1) dividing the whole image into r ? r pixel regions (or blocks), (2) extracting the features from the      image blocks, and (3) applying the algorithm in order to cluster or classify the blocks.

2.1. Feature extraction  To construct an image dataset for image block classification, it is required to extract the color and/or textural features of each block. The image dataset consists of n ? (m+1) cells where n stands for the number of regions, m for the number of features. An additional column is used for storing the class label of that region.

Although our paper focuses on classification, it is necessary to introduce the approach of features extraction for the dataset on which our experiments were performed. It is a UCI standard dataset image segmentation whose instances were drawn randomly from a database of 7 outdoor images. The images were hand segmented. The class of each instance was manually labeled. This dataset contains 210 training instances and 2100 test instances, each of which is relevant to a 3 ? 3 pixel image region. The 19 features (called attributes) are extracted from the sub-image.

Details can be found in the original dataset?s description. For image block classification purpose, the first three attributes which were found to be useless were removed.

The summary to this feature set is given below.

1) short-line-density-5: the results of a line  extraction algorithm that counts how many lines of length 5 (of any orientation) with low contrast (less than or equal to 5 ) go through the region.

2) short-line-density-2: same as short-line-density-5 but counts lines of high contrast, greater than 5.

3) features that measures the contrast of horizontally and vertically adjacent pixels in the region.

These attributes are used as a vertical edge detector and horizontal line detector, respectively.

4) intensity-mean: the average over the region of (R + G + B)/3 where R, B and G refer to the amount of red, green, and blue in the pixel, respectively.

5) raw color?means: the average over the region of the R, G and B value.

6) excess color-means: measure the excess red: (2R - (G + B)), excess blue: (2B - (G + R)) and excess green: (2G - (R + B)).

7) the rest: value-mean based on 3-d nonlinear transformation of RGB, saturation-mean and hue-mean.

In this dataset, there are 7 classes of image blocks including brickface, sky, foliage, cement, window, path and grass.

2.2. Association classification  In order to perform classification on the image dataset, it?s necessary to clarify various terms. Let U={F, D, C} be the problem discussed where F={F1, F2,..., Fm| Fi ? Fj= ? , i ? j} stands for the discretized feature set of cardinality m (m=|F|) , D for the dataset, each instance of which corresponds to a r ? r pixel image block or region. C for a class variable related to the block?s class labels. Let V[X] be the value domain of variable X. In the associative classification of image blocks, the related terms are given below.

Definition 2.1 An item means a feature variable taking a value like F2=3.

Definition 2.2 An itemset denotes the conjunction of multiple items. For example, a 2-itemset can be given as Fi=a ? Fj=b where " ? " symbol represents the logical AND operator, a? V[Fi], b? V[Fj] and Fi , Fj ? F.

Definition 2.3 An association rule consists of two parts, one is the left hand side (LHS) and the other is the right hand side (RHS). The form of a rule is represented as LHS? RHS.

Definition 2.4 For a rule r, the support (called sup) refers to the statistical significance. The confidence (called conf) measures the strength of the rule.

RHS)r.p(r.LHS=r.sup ? (1) HS)RHS)/p(r.L.rp(r.LHS=r.conf ? (2)  p(x) represents the probability of an item or itemset x?s occurrence in dataset D.

Definition 2.5 The strong rules are those satisfying the minimum support (called minsup) and minimum confidence (called minconf) thresholds.

A typical associative classification algorithm is CBA [1] (i.e., classification based on association rules).

CBA uses the Apriori algorithm [6] to generate the class association rules at minsup=1% and minconf=50%. The classifier is constructed by pruning the redundant rules from the set of extracted class association rules. To avoid running out of memory, CBA sets a hard limit of 80000 on the total number of mined rules. Although CBA is declared to have higher classification accuracy than traditional decision tree classification algorithm C4.5 [7], it consumes much system resources and generates many classification rules.

3. Image block classification using CAAR  Classification based on atomic rules (CAAR) is proposed in our study and proves to be very effective for most classification problems in the real world. We tested CAAR on 26 UCI standard datasets and found that CAAR could be successfully used to classify 20 of these datasets despite its selectivity to the other 6.

In this work, for the purpose of classification, only the class association rule is extracted. That is, the RHS of a rule is an item C=c where c? V[C]. An atomic class association rule has the form of Fi=a ? C=c where a? V[Fi] and Fi ? F, i ? j. For short, the atomic class association rules are called atomic rules.

For human beings, there are two important ways of identifying things. One is using a single outstanding feature with an easy-first strategy for step-by-step classification. The other is classification based on a combination of multiple features. CAAR imitates a human adopting multiple passes of partial classifications. This approach can overcome the over- fitting of the classification mode to the training data.

3.1. Introduction to CAAR  CAAR generates a classifier in six steps.

1) Scan the dataset and count the LHS items and the  LHS-RHS 2-itemsets relevant to atomic rules through hash table hash1 and hash2, respectively.

2) If the class labels of the valid (non-deleted) instances in the dataset are the same, the algorithm generates a special rule which indicates the default class, and the flow goes to step 6.

3) Generation of strong atomic rule: It generates strong atomic rules satisfying r.sup ? minsup and r.conf ? minconf. The supports and confidences of the atomic rule candidates can be readily computed through hash1 and hash2. After generation of strong atomic rules, the contents of hash1 and hash2 are cleared in order to consider the next pass classification.

4) Pruning: Sort the strong atomic rules with confidence as first key and support as second key. All keys are sorted in descending order. Test the strong atomic rules in sequence on each instance of the dataset.

If an instance contains the LHS item, it is deleted logically (not physically for the sake of disk-resident data mining) and the match_count of the tested rule increases by 1; otherwise, test the next rule until a rule matches the instance or until all rules are tested. If no rule matches this instance, it is regarded as a valid instance and is counted through hash1 and hash2 for the next pass. The algorithm continues to test the next instance until all instances are tested.

5) Select all rules with match_count ? 0 as a subset of classifier rule set. If the |D| is zero, the flow goes to step 6; otherwise it goes to step 2 for the next pass of partial classification.

6) Combine all classification rule subset in sequence to form the final classifier.

CAAR use a self-adaptive confidence for strong atomic rule extraction.

minconf=COEF? maxconf (3)  In equation (3), COEF is a user-specified coefficient and maxconf is the maximum confidence of all atomic rule candidates in each pass.

Moreover, if the support of a rule is computed relative to D0, CAAR will have a dynamic support threshold.

0D D  supminsupmin ii ?= (4)  In (4), D0 and Di stand for the numbers of valid instances in datasets at the first pass and at the i-th pass, respectively. The minsupi is the relative minimum support threshold at the i-th pass of classification.

When i >1, Di<D0.

3.2. CAAR-based classification of image blocks  CAAR is demonstrated by classifying the dataset discussed in this paper. Image segmentation dataset containing 210 and 2100 instances in training set and test set, respectively. We combine both into one and delete the first three features which are useless to image block classification. To inspect whether this dataset can be classified by CAAR, the key problem is to observe if there are some strong atomic rules with high confidences in each passes of partial classification.

Figure 1 shows the spectrum of confidences for 695 candidate atomic rules in the first pass classification.

There are 8 rules with confidence 1.

???????? ????????????????????????????? ????????????????????????????? ????????????????????????????? ?????????????????????  ?  ?	?  ?	?  ?	?  ?	?  ?  ? ?? ??? ??? ??? ??? ??? ??? ??? ???  ??????????????????????   ? ? ?? ? ? ? ? ?  ????????	??!"?????#?	??!??????????	??!"?????#?	??!??????????	??!"?????#?	??!??????????	??!"?????#?	??!??  ?  ?	?  ?	?  ?	?  ?	?  ?  ? ? ? ? ? ? ?!??  ? !

" ? ? ? ?  Figure 2 indicates that in all passes of partial      classifications, the maxconf is 1.0. For some other datasets, at the late passes, the valid instances can be regarded as difficult to be classified. In this case, the maxconf may be less than 1.

????????	?$%$?#?	??!??????????	?$%$?#?	??!??????????	?$%$?#?	??!??????????	?$%$?#?	??!??  ????  ???  ???? ?  ????  ?  ???  ????  ????  ????  ????  ? ? ? ? ? ? ?!??  $% $  Figure 3 gives the number of valid instances |D| at different passes. On this dataset, CAAR requires 6 passes to classify all instances. On the first pass, 1009 instances can be differentiated. So there are 1301 instances left for the second pass. From the fourth pass, the number of valid instances is far smaller than |D0|, so CAAR is very fast, even though multiple passes of partial classification are required.

3.3. Theoretic analysis  3.3.1. Convergence: To assure that CAAR converges, the strong atomic rules are generated in three steps: (1) extracting the strong atomic rules with r.conf ? COEF? maxconf and r.sup ? minsup, (2) if step 1 fails, change support constraint r.sup ? minsup to r.count ? 2, and (3) if step 2 fails, extract all the rules satisfying r.conf ? COEF? maxconf. So at each pass of partial classification, theoretically, there is at least one instance is classified and logically deleted from the dataset. At last, |D| converges to zero.

3.3.2. Complexity: Let n=|D0| and Na stand for the mean size of attribute value lists, and Nc for the number of class labels. In CAAR, let p be the number of passes of partial classifications. In each pass of CAAR, counting the atomic rule related 2-itemsets requires O(n ? m) time where m=|A|, and selecting the classification rules from the strong atomic rules requires O(n ? |R1|) time where R1 is the set of strong atomic rules. The total time complexity is as follows.

TCAAR(p,m,n,|R1|)= O(p ? n ? m+ p ? n ? |R1|) (5) It?s very important that p is determined by the  inherent model in the dataset and has no direct relationship with n.

In CBA, let l be the maximum number of the rule?s LHS items. The cost of CBA is a function of the time  for mining the strong class rules plus the time for testing the strong rules to build a classifier. The total time complexity is below.

TCBA(m,n,l,|Rk|)= )|R|nCn(O l  k k  l  k |R| k  ??+?? == ? 11   (6)  where Rk represents the set of strong class rules containing k items in LHS. R0 is the set of atomic-rule candidates, and its size is m? Na ? Nc. The |R1| of CBA is far greater than that of CAAR because the CAAR?s minconf is much higher than 50% of CBA. In addition, in CBA, the total number of mined rules increases exponentially as k becomes large.

4. Further experimental results  The experiments were done on a 1.5 GHz Pentium- 4 PC with 256MB main memory. The prototype of CAAR was implemented in Java. CAAR was compared with a typical associative classification algorithm in data mining. That is CBA (Classification Based on Association rules) which was implemented in C++ by its authors. All parameters in CBA took the default values as mentioned in [1]. The image segmentation dataset was selected from the UCI ML repository (http://www.ics.uci.edu/~mlearn/ MLRepository.html).

The experimental dataset is obtained by combining the original training and test datasets of image segmentation. The first three attributes of the dataset (row, column of the center pixel of the region and the number of pixels in a region) were removed. Before associative classification, all the continuous attributes were discretized.

4.1. Parameter selection of CAAR  In association classification, the two important parameters are minsup and minconf. For CAAR, minconf =COEF ? maxconf where COEF is a coefficient and maxconf is the maximum confidence of all atomic rule candidates. In parameter selection experiments, the training and evaluation were all performed on the whole dataset.

Table 1 shows the influence of COEF on the classification performance of CAAR with a fixed minsup 1%. Acc represents the accuracy and the time shows how many seconds that CAAR takes to build the model. It?s clear that as COEF increases, the accuracy and execution time also rises. In each pass of classification, if only the atomic rules with the highest confidence (i.e., COEF=1) are extracted for partial classification, CAAR achieves the highest accuracy at the cost of the longest execution time. So a tradeoff between accuracy and other performance parameters is      necessary. For this dataset, the COEF was chosen as 0.92 because of the relatively high accuracy and the acceptable execution time for model building.

With COEF fixed at 0.92, the influence of minsup on the performance of CAAR was observed. Table 2 shows the results. When minsup varies from 0.1% to 5%, the accuracy decreases. At minsup ? 0.5%, the execution time is significantly larger than those in the other cases. On the other hand, at higher minsup, rules with coarse granularity reduce the classification time, but also lower the accuracy. At minsup=5%, the number of frequent LHS-RHS 2-itemsets decreases and results in less classification rules at each pass; so it takes more time to complete the classification. As a whole, the minsup for this dataset can be chosen in the range of 0.1% to 2%. In the following experiments, minsup is set to 1% as default.

4.2. Performance evaluation  In order to evaluate the classification accuracy of the algorithms, we used the standard stratified 10-fold Cross-Validation Test (10-fold CV) which is widely accepted in the machine learning community. The image block classification was evaluated in terms of the mean accuracy, the mean execution time of ten runs in 10-fold CV and the size of classifier. CAAR was closely compared with CBA, and it was also compared with the decision tree algorithm C4.5 under the same running environment. All algorithms were implemented by their authors.

Figure 4 shows the influence of minsup on the mean classification accuracies of 10 runs in 10-fold CV. The parameters were set as follows: COEF=0.92 for CAAR and minconf=50% for CBA.

It?s obvious that CAAR is less dependent on the influence of minsup than CBA. When minsup varies from 0.1 to 5%, the accuracy of CAAR is between 88.4% and 83.9%. But the accuracy of CBA varies in a wide range from 86.3% to 21.9%. The reason why CBA is so sensitive to minsup is that the k-itemset (k ? 2) candidates are generated based on k-1 frequent itemsets. If minsup is relatively high, there will be less  frequent itemsets generated. A small number of coarsely granular rules can?t make fine classifications.

But for CAAR, it?s different because CAAR uses a dynamic support threshold for strong atomic rule extraction in multipasses of partial classifications.

????????	?&????!?'?#?	???????????????	?&????!?'?#?	???????????????	?&????!?'?#?	???????????????	?&????!?'?#?	???????  ??	?  ??	? ??	? ??	? ??	? ??	? ??	?  ??  ??	???	? ??	???	???	???	? ?? ??	?  ??  ??  ??  ??  ???  ?	? ?	? ?	? ? ?	? ? ? ? ???????()*  & ? ? ? ?!

? ' ?( ) *  +&  &&,  ????????	?,???????#?	???????????????	?,???????#?	???????????????	?,???????#?	???????????????	?,???????#?	???????  ??  ??  ??  ?? ??  ????  ?? ??	??	? ?	? ?	? ?	? ? ?	?  ?  ??  ??  ??  ?	? ?	? ?	? ? ?	? ? ? ?  ???????()*  , ? ? ? ?? ? ?( ? ? ? *  +&  &&,  Figure 5 shows the total run time for 10-fold CV at different minsups under the conditions of minconf=50% for CBA and COEF=0.92 for CAAR.

The results show that CBA takes much more time than CAAR to complete the 10-fold CV. At minsup=1%, the time for CBA is 13.8 times more than that of CAAR.

At a very low minsup, CBA generates a lot of strong rules satisfying minsup and minconf. Because of the hard limit of 80000 on the number of mined rules, association rule mining of CBA will be forced to stop when the total number of rules reaches 80000. So the k-condition rule will have small values of k at very low minsups. As minsup increases, k becomes large, so the number of k-condition rules increases exponentially,  -!?????	?-.??????????????? /0?????.?????????!??????? &&,?  /0?? ?	?? ?	?? ?	?? ?	??? ?	?? ?	??? ?	??? ?	??? ?	??  &??()*? ??	?? ??	?? ??	?? ??	?? ??	?? ??	?? ??	?? ??	?? ??	??  -????(???* ?	??? ?	??? ?	??? ?	??? ?	??? ?	??? ?	??? ?	??? ?	???  -!?????	?-.?????????????????????????.?????????!??????? &&,? ??????()*? ?	?? ?	?? ?	?? ?	?? ?	?? ?	?? ?	?? ?	??  &??()*? ??	?? ??	?? ??	?? ??	?? ??	?? ??	?? ??	?? ??	??  -???(???*? ?	??? ?	??? ?	??? ?	??? ?	??? ?	??? ?	??? ?	???      which takes much execution time for strong rule generation and rule pruning operations. At high minsup, the number of frequent itemsets decreases, which results in a small number of rules (#Rule) as showed in Figure 6, so in this case, the algorithm becomes faster.

????????	?1,????#?	???????????????	?1,????#?	???????????????	?1,????#?	???????????????	?1,????#?	???????  ??? ??? ???  ???  ???  ?? ??  ?????? ???? ?? ??  ?  ???  ???  ???  ?	? ?	? ?	? ? ? ? ?  ???????()*  , ? ??  +&  &&,  Figure 6 indicates that the number of rules generated by CBA is 3.2 times more than that of CAAR at minsup=1%. At minsup=5%, the numbers of mined rules for CBA and CAAR are 20 and 56, respectively, and the accuracies for CBA and CAAR are 21.9% and 83.9% (as showed in Figure 4). The self-adaptive confidence and dynamic minsup of CAAR account for this big difference in accuracy.

Even at high minsup, CAAR?s dynamic minsup prevents the number of rules from dramatic decreasing and the self-adaptive confidence threshold always ensures rules of high equality for classifier construction.

Table 3 shows the overall comparison of classification results among three algorithms for classifying the image blocks. #Rule denotes the number of rules in the generated classifier. For C4.5, the number of rules equals to the number of tree nodes after pruning. It is clear that CAAR uses the least rules and achieves the highest accuracy 88.4% for this dataset. C4.5 is far faster than CAAR and CBA, and CAAR is much faster than CBA.

Furthermore, CBA uses far more memory than CAAR. In the experiment, we observed that CBA generates 80000 class association rules on this image dataset while CAAR generates at most 695 atomic rules because there are only 695 possible atomic rules.

0.79MB memory space is required to store 695 instances of ?Rule? class in a vector. However, for 80000 rules, the memory consumption is up to 92.3MB.

5. Conclusion  In this work, a new associative classification algorithm called CAAR is introduced to classify the image blocks. CAAR only mining the atomic rules provides fast and concise classifier for block-based image segmentation. Using a self-adaptive confidences threshold 0.92? maxconf can extract the strong atomic association rules with high confidences for classifier construction. CAAR takes an easy-first strategy for multiple passes of partial classifications. A dynamic support threshold can also automatically adapt the rule?s granularity for fine classification which can improve the accuracy. The experimental were performed on a UCI dataset image segmentation. The results show the proposed algorithm provides a fast, accurate and robust classifier for block-based image segmentation.

6. Acknowledgement  This paper was supported by the National Natural Science Foundation of China (NSFC grant No.

10171033) and the Natural Science Foundation of Guangdong Province of China (grant No. 31340).

7. References  [1] B. Liu, W. Hsu, and Y. Ma, ?Integrating classification and association rule mining?, Proceedings of 4th ACM Int.

Conf. on KDD, New York, pp. 80-86, August, 1998.

[2] Elena Baralis, Silvia Chiusano and Paolo Garza, ?On support thresholds in associative classification?, In: Proc. of the 19th ACM symposium on Applied computing, Nicosia, pp 553-558, 2004.

[3] Maria-Luiza Antonie and etc, ?Associative Classifiers for Medical Images?, Lecture Notes in Artificial Intelligence Vol.2797, Mining Multimedia and Complex Data, pp 68-83, Springer-Verlag, 2003.

[4] Rushing, J.A. Ranganath, H. Hinke, T.H. Graves, S.J., Huntsville, AL, ?Image segmentation using association rule 11, pp.558- 567, 2002.

[5]Maria-Luiza Antonie, Osmar R. Za??ane, Alexandru Coman, ?Application of Data Mining Techniques for Medical Image classification?, Proc. of the 2nd International Workshop on Multimedia Data Mining. San Francisco, pp 94-101, August 26, 2001.

[6] R. Agrawal, and R. Srikant, ?Fast algorithms for mining association rules?, Proceedings of the 20th Int. Conf. on VLDB, Santiago, pp. 487-499, September, 1994.

[7]J. R. Quinlan, C4.5: Programs for machine learning.

Morgan Kaufmann, San Francisco, 1993.

