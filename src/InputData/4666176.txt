A Hybrid Method for Discovering Maximal Frequent Itemsets

Abstract A novel hybrid method included two phases for  discovering maximal frequent itemsets is proposed. A flexible hybrid search method is given, which exploits key advantages of both the top-down strategy and the bottom- up strategy. Information gathered in the bottom-up can be used to prune in the other top-down direction. Some efficient decomposition and pruning strategies are implied, which can reduce the original search space rapidly in the iterations. The compressed bitmap technique is employed in the counting of itemsets support.

According to the big space requirement for the saving of intact bitmap, each bit vector is partitioned into some blocks, and hence every bit block is encoded as a shorter symbol. Therefore the original bitmap is impacted efficiently. Experimental and analytical results are presented in the end.

1. Introduction   Frequent itemsets mining was first proposed by Agrawal[1] for market basket analysis in the form of association rule mining. A major challenge in mining frequent itemsets from a large data set is the fact that such mining often generates a huge number of patterns satisfying the min_sup threshold, especially when min_sup is set low. This is because if a pattern is frequent, each of its subsets is frequent as well. A large pattern will contain an exponential number of smaller, frequent sub- patterns. To overcome this problem, closed frequent itemsets(CFI) and maximal frequent itemsets(MFI) mining were proposed[2]. An itemset ? is a maximal frequent itemset (or max-itemset) in set D if ? is frequent, and there exists no super-pattern ? such that ? ? ? ? and ? is frequent in D. For the same min_sup threshold, the set of max-itemsets, which is more compact, contains the complete information regarding to its corresponding frequent itemsets.

1.1 Related Works   Mining max-itemsets was first studied by Bayardo[3], where an Apriori-based, level-wise, breadth- first search method was proposed to find max-itemset by performing superset frequency pruning and subset  infrequency pruning for search space reduction. Pincer- Search[4] uses horizontal data format. It not only constructs the candidates in a bottom-up manner like Apriori, but also starts a top-down search at the same time, maintaining a candidate set of maximal patterns.

DepthProject [5] finds long itemsets using a depth first search of a lexicographic tree of itemsets, and uses a counting method based on transaction projections along its branches. Mafia [6] is another efficient method for mining the MFI, which uses three pruning strategies to remove non-maximal sets and a vertical bit-vector data format to improve performance. Both DepthProject and Mafia mine a superset of the MFI, and require a post- pruning to eliminate non-maximal patterns. FP-Growth[7] uses the novel frequent pattern tree (FP-tree)structure, which is a compressed representation of all the transactions in the database, and a recursive divide-and- conquer and database projection approach to mine long patterns. Guizhen Yang[8] provided theoretical analysis of the (worst-case) complexity of mining max-patterns.

The complexity of enumerating maximal itemsets is shown to be NP-hard. Ramesh et al.[9] characterized the length distribution of frequent and maximal frequent itemset collections.

1.2 Contributions   Firstly, support counting is a confessed bottleneck in the association rules mining, which requires a great I/O and computing cost. A novel compressed bitmap index technique to speed up the counting process is employed.

The presented algorithm could reduce both the number of times the database is scanned and the search space rapidly.

Secondly, a flexible hybrid search method is given, which exploits key advantages of both top-down and  bottom-up strategies.

The rest of this paper is organized as follows.

Section 2 discusses the problem of itemset support counting based on compressed bitmap technology.

Section 3 introduces the description and decomposition strategies of search space. Section 4 presents the algorithm and some pruning strategies. The feasible optimizations and experimental results are presented Section 5. Finally, we conclude this paper in Section 6.

DOI 10.1109/FSKD.2008.347     2.  Itemset Support Counting The bitmap technique was proposed in the 1960?s,  and has been used by a variety of products. A typical context is the modern relational DBMS[10]. It also has been applied in association mining. The key idea of the approach is to use a bitmap index to determine which transactions contain which itemsets. Each transaction has one unique offset position in the bitmap. A bit vector  ),,,(. 21 nbbbBitX ??  is associated to each itemset X.

In BitX . the ith bit ib  is set to 1 if the transaction i contains the itemset X, and otherwise ib  is set to 0. It should be noted that ib  is set to null if itemsets or transaction does not exist. The ordered collection of these bit vectors composes the bitmap. In a bitmap, a line represents a transaction, while a column corresponds to a given k-itemset.

During the supports counting, Intensively manipulates bit vectors requires a lot of disk space and main memory. So, it is necessary to compress the bitmap in advance. A new block strategy is proposed to encode and decode the bitmap, which is similar to the pagination technology in operating systems. In this approach, every bit vector is partitioned into fractions, called blocks, that can be encoded respectively, so that a bitmap is divided into granules. Each block should have an appropriate size, if the size is too small, the impact is not remarkable; otherwise the encoding is not straightforward. In order to take full advantage of Logical Calculation Units, the block size should be an exponential to 2. Each block is represented as ):( Wp , p is the number of the block, and W is the block bit vector. Let l be the block size, m the number of transactions in database D. In this way each bit vector ),,,,( 21 mi bbbbB ???  can be partitioned into  )(INT l mp ?  blocks ( INT  is the integer function). The  kth block vector ),,,,,( 21 ljk wwwwW ??? , )l*(kilij 1),MOD( ???? ( MOD  is the mode  function) Encoding each block as a shorter code can reduce  the space demanding. The encoding principle which should be conformed is that each block can be represented uniquely. As a part of the initial bit vector B, each block vector W is also a binary bit vector. The conversion between binary, octal, decimal and hexadecimal can be implemented conveniently, hereby every block can be represented a binary, octal, decimal or hexadecimal code. We use a hexadecimal code, i.e. every four bits in a block encode a hexadecimal code.

As each itemset is associated to a binary bit vector, the support of a given itemset is the total number of 1 in the vector. For the sake of efficient counting the number of 1, we previously store the binary block in a bit array  ]1[ lBit ? (l is the block size), and the hexadecimal  blocks in an array ]1[ pABit ? (p is the number of blocks). The value in ][iABit  is the hexadecimal code of the ith block. Implementation of this support counting algorithm follows.

Algorithm 1  Itemsets Support Counting Algorithm Countsupport(X1, X2) Begin  Support=0; For (i=1; i=p; i++) do  If X1.ABit[i]?0 and X2.ABit[i]?0 then For (j=1; j=l; j++) do

X.Bit[j]= X1. Bit[j]& X2. Bit[j]; Support+= X.Bit[j]; Endfor;

X.ABit[i]= X1. ABit[i]& X2. ABit[i]; Else

X.ABit[i]=0; endif; end;   3.  Description of the Search Space   Definition1 Let YXT ??  be an itemset in database D, where IYX ?, and ???YX . And let P(Y) be the power set of Y, denoted by }{)( YZZYP ?? . For this itemset T, then set of all the itemsets obtained by concatenating X with the elements in P(Y) is called the search space of T. That is })({]:[ YPZZXYX ??? , denoted by XYS  or S. We call X is an ancestor element of S, denoted by S.anc, Y is a child element of S, denoted by S.chi, and YX ?  is the border of S, denoted by S.bor.

Definition2 Let S and Si? ? ki 		1 ? ?be the search spaces. Iff kSSSS ???? ?21  and ??? ji SS , we call ),,,( 21 kSSS ?  is partition of S, denoted by  kSSSS   ? ?21 .

Theorem1 Let IRYX ?,, be the distinct itemset  and ]:[ RYXS ?  be a search space. For itemset },,,{ 21 kiiiR ?? (where Ii j ? and YXi j ,? ), the  search space S can be partitioned into the following subspaces ? ?    k j kjj YiiXiYX 1 1 ]:[]:[ ? by R. That is ? ?  ?  k  j kjjk YiiXiYXYiiiX  1 121 ]:[]:[]:[ ?? .

Proof:  Let V be a itemset,  Iw? , the power set of  wV is }{)( wVZZwVP ?? = },{}{ wVwVZZ ?? . It follows from the definition1 and definition2, that the search space ]:[]:[]:[ VXwVXwVX ? . The above search space [X:RY] can be partitioned via item Ri j ? sequentially. The result follows.

With only a limited amount of main memory in practice, we should decompose the original search space into some smaller pieces, such that each one can be solved independently in main memory. Following the above description and partition mechanisms, the original enormous search space could be partitioned into some     little ones as flexibly as possible. Furthermore, theorem1 can be used to prune the search space.

The search space for item set I={a,b,c,d} is S=[:I]. It can be partitioned into some little ones step by step. The iterative results of a hierarchy of search space are shown in figure 1.

For a given item set I in database D and the minimum support threshold min_sup, the task of mining FI or MFI is in the follow: finding the set  })(    ][:{ minsupXSuppandIXX ??  in the search space S=[:I].

4.   Discovering Max-itemsets 4.1 Search and Pruning Strategy  In general, it is possible to search for the max- itemsets either top-down or bottom-up. The bottom-up approach is good for the case when all max-itemsets are short, and the top-down approach is good when all max- itemsets are long. If some max-itemsets are long and some are short in the mining database, then both search approaches will not be efficient. A key idea of our hybrid approach is the use of information gathered in the search in the bottom-up to prune search space during the top- down search. It uses infrequent itemsets found in the search in the bottom-up to prune search space during the top-down search. Some efficient prune technologies will be discussed later.

Lemma1: Let IYX ?,  and Iu? , and ]:[ uYXS ?  be a search space on X. If the itemset R=Xu  is infrequent, the space S can be pruned by R. And the remained space is ]:[ YXS ?? .

The theorem2 shows how to prune the search space [X:Y] by the infrequent itemset R.

Theorem2: Let X and Y be distinct itemsets, and ]:[ YXS ?  be a search space. If there exists an item  Yu?  satisfied that itemset XuR ?  if infrequent, the partition of })]{(:[})]{(:[ uYXuYXu ? ?  is the most efficient ones.

Proof: For such search space ]:[ YXS ? , the size of S lies on value Y . Let },,,{ 21 kiiiY ?? , there are 2k subsets in S, that is S =2k. The original search space S can be decomposed into ? ?   k j kjj iiXi1 1 ]:[ ?  by  theorem1. For the jth subspace ]:[ 1 kjjj iiXiS ? ? , if the assumable infrequent itemset is Xij, then Sj can be pruned entirely by lemma1. Obviously, when j=1(i.e. i1=u), the value of jS  comes to the top. The result follows by theorem1.

Theorem3: Let ]:[ YXS ?  be a search space, and X be a (k-1)-itemset. Let kL~  be the set of all infrequent k- itemsets. If there exists such a itemset kLZ ~?  satisfied with XZ ? , search space S can be pruned by kL~ . And the resulting space )](:[ RYXS ??? ? ? ? }~    { kLZandXZXZR ???? .

Proof:  Yu? , there exists  })]{(:[})]{(:[]:[ uYXuYXuYX ? ??  by Corollary1.

If there has no kLZ ~?  satisfied with XZ ? , .i.e.

kLXu ~? , the search space S can not be pruned any part by Z.

Let },,,{ 21 MiiiR ?? , the result follows by pruning S via Ri j ? ( Mj 		1 ) sequentially as in Corollary1.

Theorem4: Let ]:[ YXS ?  be a search space, and X be a (k-1)-itemset. Let kL~  be the set of all infrequent k- itemsets, and }~{ kLZZXM ??? ? . The pruned search space S ?  is only 2-M of its original search space S.

Proof: When M=0(2-M=1), any itemset in kL~  can not used to pruned the original search space S. When M>0, assume ? }~    { kLZandXZXZR ???? , RYU ?? , and JU ? , then ]:[]:[ RUXYXS ?? . As we have known MR ? , and JMS ? 2  holds. By theorem3, we  conclude that S can be pruned by kL~  to ]:[ UXS ?? , i.e. JS 2?? , MSS ??? 2 .

For search space S=[X:Y], if the number of infrequent itemsets containing X is large, the scale of S will be reduced rapidly.

4.2 The Hybrid Max-Itemsets Search Algorithm   There are two phases in this hybrid approach: the search in bottom-up direction and the other in top-down direction for every pass. Max-itemsets are enumerated in both bottom-up and top-down directions.

Consider a pass k, the set of frequent k-itemsets Lk and the set of infrequent k-itemsets ~Lk are to be classified in the bottom-up direction. This procedure repeatedly uses Apriori-gen algorithm to generate candidates like the Apriori[1]. During the kth pass, every search space S? ?[X:Y] where X is an itemset of size k-1 can be decomposed into some little pieces, whose ancestors are k-itemsets. For search space S? ?[X:Y], the top-down procedure check whether the border element    [ac:d] [a:d] [bc:d] [b:d] [ab:cd]  [:abcd]  [a:bcd] [c:d] [d:]  [abc:d] [ab:d]  [b:cd]  Figure 1.  Hierarchy of search space on I? ?{a,b,c,d}  K=0  K=2  K=1  K=3     (i.e. YX ? ) of S is frequent firstly, if not, S is decomposed. Implementation of this hybrid approach is shown in algorithm2.

Algorithm2. Algorithm for Max-itemsets Mining Procedure: MFI Search (Transaction Set: D, Item Set: I)  Begin ??TMFI ; ??BMFI ; k=1; ]}{[:1 I?? ;  Ck=I; Lk= Partition (Ck, min_sup); ~Lk= Partition (Ck, min_sup); While ???k  do //Top-Down Search  ??? 1k ; Forall kS ??  do  B=S.bor; If countsupport(B)<min_sup then  If ???? }    { TMFIRandBRR  then ? = Decompose(S, k, Lk, ~Lk); ?????  11 kk ; Endif;  Else BMFIMFI TT ?? ;  Endif; Endfor;  //Bottom-Up Search Ck+1= Apriori-gen(Lk); Lk+1= Partition (C k+1, min_sup); ~L k+1= Partition (C k+1, min_sup); Forall kLX ? do  If ???? }~{ 1kLYYX  then XMFIMFI BB ?? ;  Endfor; k++;  End; Return BT MFIMFI ? ;  End; Procedure: Partition (Ck, min_sup) //classify Lk and ~Lk from set of candidate k-itemsets Ck  Begin ??kL ; ??kL~ ;  Forall kj CX ? do if CountSupport(Xj)? min_sup then  jkk XLL ?? ; else  jkk XLL ??~~ ; Endif;  Endfor; End;  Procedure: Decompose (S=[X:Y], k, Lk, ~Lk) Begin  ??? ; }~  Z  {~ kk LandXZZP ??? ;  }  U  { kk LandXUUP ??? ; }~{ kPVVYR ???? ; }{ kPTTRR ??? ;  Rn ? ; Forall (i=1; i=n-1; i++) do If ki PXu ?  and kuuXu kii ? ?1 then  ]:[ 1 kii uuXu ? ???? ; Endfor; Return ? ;  End;   5.  Experimental and Analytical Results   The test databases are generated synthetically by an algorithm designed by the IBM Quest project in IBM Almaden Recearch Center, referring to Http://www.almaden.ibm.com/cs/quest/syndata#AssocSynData.

In this algorithm bitmap technology is used to count the support of every itemset instead of scanning the entire transaction database. Figure 2 shows the relative times at varying numbers of transactions for databases where the average size of transactions is 10 and the average size of potential max-itemsets is 4.

When the average size of transactions or the average  size of max-itemsets increase, there has much more itemsets (or search spaces) to be tested. therefore the total time will increase. Figure 3 shows the relative times of this hybrid algorithm at varying minimal supports on the datasets of T15.I8.D10K.

To illustrate expandability of this algorithm, we  performed an experiment varying the database size from 5K to 20K. The average size of transactions is 10, and the average size of potential max-itemsets is 6. For the experiment we fixed a minimum support of 4%. Figure 4 shows the result for the datasets.

1 0 0 0  3 0 0 0  5 0 0 0  7 0 0 0  9 0 0 0  7 .0 % 6 .0 % 5 .5 % 5 .0 % 4 .5 %  M in im a l Sup p o r t (T 1 5 I8 D 1 0 K )  Re sp  on se  T im  e( se  c.

)  T w o-W ay  Figure 3. Times varying support thresholds  Figure 2. Relative times varying databases    50K 100K 150K 200K  Number of Transactions  R es  po ns  ed ti  m es  (S ec  .)  List BM 2-BMC                As we have shown, there are three search strategies  for discovery MFI. Figure 5 shows the relative times of the three approaches for the tests at varying minimal supports on T10.I6.D10K. From the experiments, we could see that when minimal support is greater than 2%, the performances of the bottom-up is little better than the hybrid. The main reason is that the number of itemsets generated is small with the increasing of minimal support.

As the minimal support decreases, MFI becomes longer, which results in an increase in the number of counting itemsets. In such a case, the hybrid has performances. We can also see performance of the bottom-up approach is lower than the others. The most primary factor is almost all the max-itemsets are expected to not be long in this T10.I6.D10K dataset. The experiment illustrates the fact that top-down search might be efficient for the long max- itemsets.

6.  Conclusions   We use an improved compacting bitmaps database format. Support of itemset can be counted by means of binary bit vectors intersections, which minimizes the I/O and computing cost. To reduce the disk and main memory space demanding, we break the bitmap down into some little blocks, which can be encoded as a shorter code. The blocks of bitmaps are fairly adaptable. Hence the additional space decreases rapidly.

The hybrid approach exploits key advantages of both the top-down strategy and the bottom-up ones, which can discovery both longer max-itemsets and the shorter ones in earlier passes. And the infrequent (or frequent) itemsets discovered in the bottom-up can also be used to prune the  search space in the other top-down direction. Furthermore, this algorithm can be parallelized easily on this hierarchical search space organization. We note that using ~Lk to prune the search space is not the only technique. If  kk LL ~?? , it would be more efficient to decompose and prune the search space using Lk rather than ~Lk.

