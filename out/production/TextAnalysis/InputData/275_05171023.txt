Consumption Psychoanalysis and Customer Relationship Management Based  on Association Rules Mining

Abstract   Consumption psychoanalysis is very important for  enterprises to improve production and develop economy. Customer satisfaction index is an important part of consumption psychology. Structural equation model is required to calculate customer satisfaction index, however, the current algorithms of structural equation model have some deficiencies which need to be improved. In this paper, we improve the algorithm of structural equation model, we figure out a suitable iterative initial value of partial least squares to enhance the convergence rate greatly, in addition, we give it?s definite algorithm.

Customer relationship management system is an important management software for enterprises, in this paper, we band data mining together with customer relationship management by dint of an instance. To help to find business developmental trend, to find meaningful rules or patterns, which provide the basis for enterprises to make decision, so that enterprises in a better competitive position. Our algorithm has been developed into calculating software, the production has already been in use.

Keywords: Psychoanalysis, Customer satisfaction index, Structural equation model, Data mining, Association rules  1. Introduction   At present, the research on consumption psychology is regarded unprecedented by economists and marketing managers at home and abroad. In China, the study of consumption psychology started very late, but it develops very rapidly.

Customer satisfaction index (CSI) is an important part of consumption psychology. Based on causal  relationship, Fornell proposed a CSI model[6] which is the most influential CSI model in the last 20 years. The CSI model is mainstream of present research on CSI model and it has become an universal model.

2. CSI based on structural equation model   The mathematical theory of Fornell? CSI is structural equation model (SEM). SEM has become a very popular data-analytic technique, and has been widely applied in Psychology and Sociology as well as other fields, especially in CSI model. Many papers focus on the improving of SEM algorithm, including using EM algorithm and ML algorithm, but partial least square (PLS)[8] is the most important algorithm in practice, in spite of its convergence of iteration can not be ensured, or its convergence rate may be very slow. Because the iterative initial value of PLS is arbitrary in papers or in software so far, it is possible to improve it.

2.1. SEM and PLS   There are two systems of equations in a SEM. One is a structural system of equations among structural variables, the another is an observation system of equations between structural variables and observed variables. The Chinese Customer Satisfaction Index (CCSI) model is a typical SEM, its structural system of equations is:  0 0 0 0 0  0 0 0 0  0 0 0  0 0  0 0 0 0 0  11 1 11  22 21 2 21  313 31 32 3 31  44 41 42 43 4 41  55 54 5  ?? ? ?  ?? ? ? ?  ??? ? ? ? ?  ?? ? ? ? ? ?  ?? ? ?  ?  ?  ?  ?  ?  + +=  ? ?? ? ? ?? ? ? ? ? ?? ? ? ?? ? ? ? ? ?? ? ? ?? ? ? ? ? ?? ? ? ?? ? ? ? ? ?? ? ? ?? ? ? ?  ? ? ? ?? ? ? ?? ? ? ?? ? ? ?? ? ? ?  (1)  2009 World Congress on Computer Science and Information Engineering  DOI 10.1109/CSIE.2009.897   2009 World Congress on Computer Science and Information Engineering  DOI 10.1109/CSIE.2009.897         where ,i i? ?  are structural variables, i j?  is the path  coefficients from independent variable j?  to i? , i j?  is the path coefficients from dependent variable j?  to  independent variable i? .

In general, suppose that there are m  independent  variables 1 ~ m? ? , arranging them as a vector ?  by column; and there are k  dependent variables 1 ~ k? ? , arranging them as a vector ?  by column also. The m m?  square matrix B  is the coefficient matrix of ? , the m k?  matrix ?  is the coefficient matrix of ? ,  ??  is the residual vector, then SEM (1) may be extended as:  B ?? ? ? ?= + ? +                              (2) The structural variables are implicit and cannot be  observed directly. Each structural variable is corresponding to many observed variables. Suppose that there are M observed variables and each one has N  observed values, then we will get an N M? matrix.

The relationships between the structural variables and the observed variables can also be expressed in equations by two ways of path causality. Let  , 1, , ( )t jx j S t=  be the observed variables  corresponding to t? , and , 1, , ( )i jy j L i=  be the  observed variables corresponding to i? , then the observation systems of equations from observed variables to structural variables are:  ( )   S t  t t j t j t j  x ?? ? ? =  = +?  , 1, ,t k=                 (3) ( )   L i  i i j i j i j  y ?? ? ? =  = +?  , 1, ,i m=                (4) Contrarily, the observation systems of equations  from structural variables to observed variables is:  1 1 1  ( ) ( ) ( )  t t xt  t  t S t tS t xtS t  x  x  ? ?  ?  ? ?  = +  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  ? ? ? ?? ? ? ? ? ?? ?  , 1, ,t k=      (5)  1 1 1  ( ) ( ) ( )  i i y i  i  iL i i L i y i L i  y  y  ? ?  ?  ? ?  = +  ? ? ? ?? ? ? ? ? ?? ? ? ? ? ?? ?  ? ? ? ? ? ?? ? ? ? ? ?  , 1, ,i m=    (6)  where t j? , i j? are load items.

We call (2)(3)(4) (or(2)(5)(6)) is a SEM, sometimes we call it a path analysis model.

At present, the path causality in popular PLS algorithm for SEM is from observed variables to structural variables as(3)(4), and the iterative initial value is arbitrary such as (1,0,0,?,0). The iterative process can be described as follows:  (0)( , )t j i j? ? (3) (4)???? (exogenous ) (exogenous ) (0)? ?( , )t i? ?  (2)??? (0)( , )t j i j? ? (2)???  (endogenous ) (endogenous) (0)? ?( , )t i? ? (3) (4)???? (1)( , )t j i j? ?  Where endogenous means the parameter estimation is obtained from structural equation, and exogenous means the parameter estimation is obtained from observed equation. As mentioned above, the convergence of the PLS has not been proved well, and its convergence rate may be very slow.

2.1. The PLS solution of SEM with constraint of unit vector   We find that arbitrary initial value is not necessary and we can calculate PLS by a suitable iterative initial value based on least square estimation in the observation equations. First of all, let's specify some essential properties of SEM.

(1) The solution of model consisting of Eq. (2), Eq.

(3) and Eq. (4) is not unique. If ,? ?  are the solutions of the model, ,t ic c? ?  are solutions of the model too, where c  is a constant. So we can solve the model in the constraint condition of unit vector.

(2) Zero is the solution of Eq. (2), and also there exists zero solution in Eq. (3), Eq. (4), but Eq. (5) and Eq. (6) do not have either.

(3) Eq. (4) is equivalent to Eq. (6) if ( )   L i  i j i j j  ? ? =  =? .

So the solution of Eq. (4) is also the solution of Eq. (6).

In the past, the PLS algorithm is not proceeded based on Eq. (6) but Eq. (4). Whereas in this paper we deduce the iterative initial value based on Eq. (5) and Eq. (6).

Mark the left vector in (6) as iy , similarly we get  i?  and i? , then (6) can be written as i i i iy ?? ?= + .

Make the product 'i i i i i i i i i iy y ?? ? ? ? ? ? ?? ? ? ?? = . If the structural variable is a unit vector, i.e. 1i i? ?? = ,then we get i i i iy y ? ?? ?? . This is a approximate equivalent         between two ( ) ( )L i L i?  matrixes,which can be written in details:    1 1 1 2 1 ( )  2 1 2 2 2 ( )  ( ) 1 ( ) 2 ( ) ( )  1 1 2 1 ( )  2 1 2 2 ( )  1 2( ) ( ) ( )  y y y y y y  y y y y y y  y y y y y y  i i i i i iL i  i i i i i iL i  i L i i iL i i iL i iL i  i i i i iL i  i i i i iL i  i iiL i iL i iL i  ? ? ? ? ?  ? ? ? ? ?  ? ? ? ? ?  ? ? ?  ? ? ?  ? ? ?  ? ? ? ? ? ? ? ? ? ? ? ? ?  ? ? ? ? ? ? ? ? ? ?? ? ? ?  (7)  Note that the left elements are products of two vectors, while the right ones are products of two numbers. We take diagonal elements to be equal and get the estimation:  i j i j i jy y? ?= , 1, , ( )j L i=                   (8)  So we get the estimation of 1 ( )? ?, ,i iL i? ? .

Then we estimate the structural variable i? . Let  1 2( , , , )i i i i N? ? ? ? ?= , we estimate its components  one by one. For the s th?  component of i? ,  i j s i j i sy ? ?? , 1, , ( )j L i= , 1, ,s N=      (9) Its matrix form is    1 1  ( ) ( )  i s i  is  iL i s iL i  y  y  ? ?  ? ?  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  , 1, ,s N=         (10)  Mark the vectors 1 ( )( , , )s i s iL i sY y y ?= , it is the cross  vector of the matrix iy . According to OLS principle,  we can obtain the estimate of is? :   ( )  1( , , ) i s  iL i s  i i i s i i s i s  y  y  Y? ?? ? ? ?? ?? = ? ? ? ? ? ? ? ? ? ?  (11)  ? ? ? ?  i s is  i i  Y? ?  ? ? ?  = ?  , 1, ,s N=                     (12)  where i??  has been estimated above. In this way we obtain the estimation of all structural variables. They satisfy  ( )   | || min| L i  i i j i j j  y? ? =  ? ??                     (13) whose geometric significance is to find the distance between a unit spherical surface and a linear subspace.

Its solution is unique if there are not linear correlations among ijy .

It is necessary that the unit spherical surface and the linear subspace have no common point. Otherwise the left of Eq. (13) may be zero, namely Eq. (4) has a  precise solution or satisfies ( )   L i  i ij ij j  y? ? =  =? , this means  that there are linear correlations among ijy .

Return to SEM, we can get the unique solution of  path coefficient B and ? . The transpose of (2) is: ( )I B ?? ? ?? = ? +                           (14)  For CCSI model, matrix B  is always a lower triangular matrix whose elements in main diagonal line are zero in a structural equation. So IB I B= ?  is also a lower triangular matrix whose determinant is 1.

Therefore it is reversible, then  I B BB B? ? ? ? ? ?  ?= ? + = +          (15)  where 1IB B ?  ? = ? . So for given ?  and ? , the solution based on LS in structural equations exist. If column vectors of matrix ?  are linearly independent, then the solution based on LS is still unique.

Above iterative process may be expressed as:  ( , )t j i jx y (5) (6), || || 1, || || 1? ?= =????????  ( exogenous ) (exogenous ) ( 0)? ?( , )t i? ? ( exogenous ) (exogenous ) ( 0)? ?( , )t i? ?  ( 2 )??? ( 0 )( , )t j i j? ?  ( 2 )??? ( endogenous ) (endogenous ) ( 0)? ?( , )t i? ? (3) ( 4)????  (1)( , )t j i j? ? (3) (4)????  (exogenous ) ( exogenous) (1)? ?( , )t i? ?  The simultaneous equations model is transformed into an ordinary regression analysis model in Eq. (15), and it is beneficial for us to analyze and illuminate the convergency of PLS algorithm. However, we can not adopt Eq. (15) in practical calculation, because matrix B?  estimated based on OLS does not always meet the requirement for matrix B and ? on element zero in Eq.

(1)(2), namely the requirement on path relationship.

We still adopt Two-stage LS of the general simultaneous equations model to improve the convergence of estimation, just as we have done in DASC software.

We want to explain that the iterative initial value given by us is the best in the meaning of LSE. The last         solution of a SEM must satisfy two systems of equations. Both the variables and coefficients in the structural system of equations are unknown in the beginning of calculation, so we can not calculate any initial value. The iterative initial value based on the observed system of equations has satisfied this system of equations in the meaning of LS, which of course is the best value in the meaning of LS. When the path coefficients are obtained in the structural system of equations based on the initial value, the structural system of equations is satisfied too. Why still need to continue the PLS iterative process? That is iterative process may set internal balance for all structural variables in the SEM.

Conveniently what to explain is that the last formulae of the CSI need to improve. The formulae in the reference paper [1] are short of statistical robustness. (The maximum value and minimum value of the data as a single item are to participate calculation)  ( ) min( ) CSI  max( ) min( )  E ? ?  ? ?  ?  ? = ,   max( ) max( ) n  i i  i  X? ? =  = ? ,    min( ) min( ) n  i i  i  X? ? =  = ?                                     (16)  We suggest the last formula of CSI  is: ( ) 0 ( 0 ) ( 0 )  0 0 0 0  1 1 1 1 1  ( ) 0 ( 0 ) ( 0 )  0 0 0  1 1 1 1 1  CSI  k S t i L i L i  t j i t t j i j i i i j i j i j  t j i j j  k S t i L i L i  t j i t i j i i i j  t j i j j  x y y? ? ? ? ?  ? ? ? ? ?  = = = = =  = = = = =  + +  =  + +  ?? ?? ?  ?? ?? ? (17)  The definite algorithm of SEM lays the foundation of contrast of CSI that cross-industry and inter- regional. Consequently, it will help enterprises to improve customers? satisfaction, to minimize the loss of customers, to maintain a relatively high market competitiveness and profitability preferably, that is an important part of customer relationship management (CRM) we will study in the following chapter.

3. Application of association rule in CRM  3.1. Introduction of CRM   CRM is a method of management which is customer-focused, to provide products and services timely, to improve customers? satisfaction, to minimize the loss of customers, to maintain a relatively high market competitiveness and profitability and to achieve the profit of both customers and enterprises.

In operating activities, by means of association analysis, enterprises can assort existing customers to provide scientific basis for customer subsection and the  precision positioning of target market, to find associate relationship between individuals by multi-dimensional data analysis and knowledge mining on product lines and the character of customers to help enterprises institute the strategies of market combinatorial analysis, cross-sellingand advertising drive. CRM can help enterprises find and locate the best customers, provide the right products or services with the correct price, at the right time, through the correct channels in order to meet the needs and aspirations of customers effectively.

3.2. Introduction of association rule   Association analysis, that is, using association rules for data mining with the aim of digging out the inter- relationship hidden between data and detecting the hidden patterns never found before automatically.

Market analysts are to find the relationship between different commodities that customers put into their shopping baskets from large amount of data. For example, 80% of customers that bought milk bought bread and 70% of customers bought a hammer bought nails at the same time, and this is association rules extracted from the data of shopping baskets.

3.3. Example of application   We will show the application of associate rule mining in CRM by the example of shopping baskets.

Filtering and analyzing the database of sales, we can find that the purchase situation of breads, milks and sausages is as follow:  Record No. Breads Milks Sausages 1 1 1 0 2 0 1 0 3 1 1 0 4 1 0 1 5 0 1 0  Here 1 means purchase, 0 means not, suppose the least support is 20%,  Apriori algorithmsteps are as follow:  Generate first frequency 1L Itemset X        Support / %  Breads             60(3/5) Milks               80(4/5)  Sausages            20(1/5)   Meet the demand of least support, finally 1L Itemset X              Support / %  Breads                    60(3/5) Milks                      80(4/5)  Sausages                   20(1/5)          Arrive at candidate set 2L  Itemset X          Support / % Breads, Milks              ?

Breads, Sausages           ?

Milks, Sausages            ?

Arrive at candidate set 2L  Itemset X            Support / % Breads, Milks         40(2/5)  Breads, Sausages      20(1/5)   Similarly, we got candidate set 3L  (Breads, Milks, Sausages), but its support is 0, dissatisfied condition.

At the same time, we calculated:  ( )  ( , ) ( ) 40% / 60% 67%/  Conf Breads Milks  Breads Milks BreadsP P  ? =  = =   ( )  ( , ) ( ) 20% / 60% 33%/  Conf Breads Milks  Breads Sausages BreadsP P  ? =  = =   We can find some interesting regularity that customers that bought breads and milks are more than that bought sausages and customers that bought milks are more than that bought sausages after they having bought breads. Based on the analysis, we can put breads and milks on the prominent position together with each other to facilitate customers.

We can find that the band of data mining and CRM can help enterprises to find business developmental trend,to find meaningful  rules or patterns, which provide the basis for enterprises to make decision, so that enterprises in a better competitive position.

4. Acknowledgement   We thank the anonymous reviewers for their constructive remarks and comments. The project was supported by the National Natural Science Foundation of China (30570611, 60773210).

5. References  [1] Claes Fornell, Michael D. Johnson, Eugene W. Anderson, Jaesung Cha, Barbara Everitt Bryant, The American Customer Satisfaction Index: Nature, Purpose, and Findings, Journal of Marketing, Vol. 60, No. 4 (Oct., 1996).

[2] AQSIQ Quality Management Department, Tsinghua University Research Center for Chinese enterprises, China Customer Satisfaction Index Guide, published by Chinese standards, the first edition in June 2003.

[3] Michel Tenenhaus,PLS Regression and PLS path modeling for multiple table analysis, COMPSTAT? 2004 Symposium, Physica-Verlag, Springer, 1-12.

[4] Fornell.Claes.A National Customer Satisfaction Barometer:The Swedish Experience [J].Journal of Marketing,Vol. 56, (1992), 6-21.

[5] Wold.H?Estimation of principal components and related models by iterative least squares?Multivariate Analysis [M] ? Edited by P.R. Krishnaiah,Academic Press,New York,(1966)?  [6] Joreskog K?G?A general approach to confirmatory maximum likelihood factor analysis[M] Psychometrika,Vol.

34,(1969) , 183-202?  [7] Gang Ma,Xin Li,Xingkai Yang.Customer relationship management. Dalian: Northeast University of Finance and Economics Press, 2005.537 ~ 41.

[8] I??n, F.A., Llario, R. et al., Development of a PLS based method for determination of the quality of beers by use of NIR: spectral ranges and sample-introduction considerations.

Analytical and Bioanalytical Chemistry, Springer Berlin Heidelberg, Vol. 382, No. 7, (2005) 1549-1561.

[9]Hengqing Tong, Li Xiong, Hui Peng, Self-organized Path Constraint Neural Network Structure and Algorithm, Neural Information Proceding, (Oct, 2006) Part I, 457?466.

[10]Chuanmei Wang, Hengqing Tong, Best iterative initial values for PLS in a CSI model, Mathematical and Computer Modelling, (2007) (To be appeared).

