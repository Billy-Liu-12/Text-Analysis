An Extractive Text Summarization Technique for  Bengali Document(s) using K-means Clustering

Abstract? Text summarization, a field of data mining, is very  important for developing various real-life applications. Many techniques have been developed for summarizing English text(s).

But, a few attempts have been made for Bengali text because of its some multifaceted structure. This paper presents a method for text summarization which extracts important sentences from a single or multiple Bengali documents.  The input document(s) should be pre-processed by tokenization, stemming operation etc.

Then, word score is calculated by Term- Frequency/Inverse Document Frequency (TF/IDF) and sentence score is determined by summing up its constituent words? scores with its position.

Cue and skeleton words have also been considered to calculate the sentence score. For single or multiple documents, K-means clustering algorithm has been applied to produce the final summary. The experimental result shows satisfactory outputs in comparison to the existing approaches possessing linear run time complexity.

Keywords? data mining; text summarization; extractive summarization; bengali document(s) summarization; TF*IDF; K- means clustering algorithm

I.  INTRODUCTION Nowadays, the use of Internet has caused a rapid growth of electronic data which needed to process, store, and manage.

Sometimes, it is difficult to find the exact information from large amount of data or big data. Big data [1] has the potential to be mined for information and data mining is essential to find out the proper information what we need. When data are being accessed from such a huge repository of e-documents, hundreds and thousands documents are retrieved through data mining. It also finds the correlations or the patterns among dozens of fields in large relational databases [2]-[3]. Data mining?s roots are traced back along three family lines: classical statistics, artificial intelligence, and machine learning [4]. Data  mining  is  thus the  process  used  to  describe knowledge  in  databases which  is very much useful  for extracting  and  identifying  useful information and subsequent knowledge from databases. The extracted patterns from the database are then used to build data mining models, and can be used to predict performance and behavior with high accuracy. It utilizes descriptive (e.g. summarization, clustering, sequence discovery etc.) and predictive (e.g.

classification, regression, time series analysis etc.) data mining approaches in order to discover hidden information [5]. As a field of data mining, text summarization is one of the most  popular research areas to extract main theme from large volume of data. It is generally used to denote any system that analyzes large quantities of natural language text and detects lexical or linguistic usage patterns in an attempt to extract probably useful information. Essentially, text summarization techniques are classified as extractive and abstractive.

Extractive techniques perform text summarization by selecting sentences of documents according to some criteria.

Abstractive techniques attempt to improve the coherence among sentences by eliminating redundancies and clarifying the contest of sentences. Sentence scoring is the most used technique for extractive text summarization. So, extractive summarization  involves assigning  saliency  measure  to some  units  (e.g. sentences,  paragraphs)  of  the  documents and extracting  those  with  highest  scores  to  include  in  the summary [6]. Moreover, people want to know any information in a precise way. Thus, they don?t like to read big size of document with redundant data to gather information. Thus, the technique of summarizing any text document helps to find informative sentences in order to save precious time.

A.  General Procedure of Text Summarization A general procedure for extractive methods that are usually performed in three steps is discussed below [7]: Step 1: First step creates a representation of the document.

Some preprocessing such as tokenization, stop word removal, noise removal, stemming, sentence splitting, frequency computation etc. is applied here.

Step 2: In this step, sentence scoring are performed. In general, three approaches are followed:  ? Word scoring?assigning scores to the most important words  ? Sentence scoring?verifying sentences features such as its position in the document, similarity to the title, etc.

and  ? Graph scoring?analyzing the relationship between sentences.

The general methods for calculating the score of any word are word frequency, TF/IDF, upper case, proper noun, word co-occurrence, lexical similarity, etc.

The common phenomena used for scoring any sentences are Cue-phrases (??in summary??, ??in conclusion??, ??our investigation??, ??the paper describes?? and  emphasizes such     as ??the best??, ??the most important??, ??according to the study??, ??significantly??, ??important??, ??in particular??, ??hardly??, ??impossible?), sentence inclusion of numerical data, sentence length, sentence centrality, sentence resemblance to the title, etc.

Also the popular graph scoring methods are text rank, bushy path of the node, aggregate similarity etc.

Step 3: In this step, high score sentences using a specific sorting order for extracting the contents are select and then final summary is generated if it is a single document summarization. For multi document summarization, the process needs to extend. Each document produces one summary and then any clustering algorithm is applied to cluster the relevant sentences of each summary to generate the final summary.

B. General Approaches for Extractive Text Summarization Extractive summarizers [8] find out the most relevant sentences in the document. These also remove the redundant data. Extractive summarization is easier than abstractive summarization to bring out the summary. The common methods for extractive are TF/IDF method, cluster based method, graph theoretic approach, machine learning approach, LSA (Latent Semantic Analysis) method, text summarization with neural networks, automatic text summarization based on fuzzy logic, query based extractive text summarization, concept-obtained text summarization, text summarization using regression for estimating feature weights, multilingual extractive text summarization, topic-driven summarization MMR (Maximal Marginal Relevance) and centroid-based summarization, etc.



II. RELATED WORK The previous works on single document or multi-document summarization are trying different directions to show the best result. Till now, various generic multi-document extraction based summarization techniques are already present. Most of them are for English rather than other natural languages like Bengali. In this section, we discussed some previous works on extractive text summarization. J. Zhang [9] presented an approach for multi-document text summarization using Cue- based hub-authority. It is a graph base summarization and detecting sub-topics by sentence clustering using K-nearest neighbor (KNN). Y. Ouyang [10] presented an integrated multi-document summarization approach which is based on hierarchical representation. In this paper, query relevancy and topic specificity are used for filtering process. Also it has calculated point-wise mutual information (PMI) for identifying the sub-sumption between words and high PMI is regarded as co-related. Then, hierarchical tree is constructed to produce the summarization. X. Li, J. Zhang and M. Xing [11] proposed an automatic summarization technique for Chinese text which is based on sub topic partition and sentence features. In this process, the sentence weight is calculated by LexRank algorithm combining with the score of its own features such as its length, position, cue words and structure.

When applying LexRank algorithm some problems are found so automatic summarization is proposed based on maximum spanning tree and sentence features to overcome the same. P.

Hu, T. S. He and H. Wang [12] proposed a multi-view sentence ranking for query biased summarization. The proposed approach first constructs two base rankers to rank all the sentences in a document-set from two independent but complementary views (i.e. query-dependent view and query- independent view), and then aggregates them into a consensus one. K. Sarkar [13] presented a summarization approach based on sentence clustering for multi-documents text in which sentences  are clustered  using  a  similarity histogram based sentence-clustering algorithm to identify multiple sub-topics from the input set of related documents  and  selects  the representative  sentences from the appropriate  clusters to form the final summary. A. Kogilavani [14] presented multi- document summarization using clustering and feature specific sentence extraction. V. K. Gupta [15] proposed a query focused extractive summarization approach for English text where single document summaries are combined using sentence clustering method to generate multi document summary. For clustering, semantic and syntactic similarity between sentences are used. A. R. Deshpande [16] presented another multi-document English text summarization technique using clustering method where documents are clustered using cosine similarity. A. Agrawal and U. Gupta [17] proposed an extractive clustering based technique for single document summarization. This clustering approach summarizes English text by using K-means clustering algorithm. M. A. Uddin [18] presented a multi-document text summarization for Bengali text where TF-based technology is used for extracting the most significant contents from a set of Bengali documents.

Another work proposed by M. Ibrahim [19] for Bengali document summarization which is based on sentence scoring and ranking.



III. PROPOSED TECHNIQUE The Bengali document summarizer is a natural language processing (NLP) application of data mining which is proposed to extract the most important information of the document(s). We are using sentence clustering approach to generate summary from both single and multi-documents. The proposed technique is used for summarizing Bengali document(s). In this technique, the common preprocessing steps including noise removal, tokenization, stop word removal, stemming [20] are used. TF*IDF [21] is used for calculating each word score. Then, score of each sentence is calculated by the total sum of the words with its position [19].

If the sentence contains any Cue word or skeleton word, then the score is increased by 1[19]. Next, the document is stored in a separate file with its corresponding sentences? scores. Again for multi documents, for each document, one by one, preprocessing, word scoring and sentence scoring operations are repeated as mentioned above and also the documents are stored in the same file that is all the documents are merged.

After that, the sentences are sorted in descending order and it has been considered that the highest score as the centroid 1 and the lowest score as the centroid 2 to apply the K-means clustering algorithm [1], [22]. Then, top K sentences are extracted from each cluster and the final summary is generated. Here, K sentences can be measured as 30% of sentences of the original merged document.

A.  Flow Chart of the  Proposed Technique The proposed extractive technique of summarizing Bengali document(s) is illustrated with the following flow chart representation in Fig. 1.

TF/IDF:  Term Frequency/Inverse Document Frequency SC:          Sentence Score PV:          Position Value   Figure 1. Extractive Bengali document(s) summarization technique  B. Pseudo-code of the  Proposed Technique TEXTSUM ( ) is the caller function that calls two procedures Stemming ( ) & k-means_algorithm ( ) to generate the final summary.

Procedure: TEXTSUM (SC, COUNT, K, N, TotS, CHECK)  i. [Start with COUNT ] For single document summarization, set COUNT:=1.

and for multi-documents summarization,  set COUNT:=N,  N is the no. of documents.

ii. [For the current document]  Count the total number of sentences, TotS.

iii. Set CHECK:=1.

iv. Repeat step (v) to (xvi) while CHECK<= TotS.

v.       Remove noise from sentence, S.

vi.       Tokenize each sentence S.

vii.       Optionally remove stop word from S.

viii.       Call procedure Stemming ( ).

ix.       [Calculate the score TF of each word using TF/IDF ]  TF= , ? = log	( + 1)  x.   [Calculate the score (SC) of each sentence,  = Position of the sentences.]  = ?  + PV = ?  xi.  [Check S for cue words] If S contains Cue words, then increase, SC:=SC+1.

xii.  [Check S for skeleton word] If S contains skeleton word, then increase, SC:=SC+1.

xiii.  CHECK: = CHECK+1, goto step (iv) xiv.  Store the document in a file with scores.

xv.      COUNT:=COUNT-1  xvi.  [Check  for another document to calculate sentence score]  If COUNT! = 0, then goto step (ii) Else, go to step (xvii).

xvii.      Sort the stored sentence scores in decreasing order.

xviii.       [Cluster the document using k-means algorithm] Call procedure k-means_algorithm () xix.       Extract top K sentences from each cluster to get the  final summary of the document(s).

xx.       END.

Procedure: Stemming () i. Read token from the line.

ii. Load suffix lists from the stored file.

iii. [Check suffix list with the input token ]  If the token matches with any suffix, then discard the suffix and  mark token as a root word.

iv. Repeat step (i) until all token is processed.

Procedure: k-means_algorithm (m1 & m2, C1&C2, d1&d2, , av1,av2 )  i. [ Initialize centroid m1 &  m2 ] m1:= Highest score & m2:= Lowest score.

ii.  [ Measure distance from the centroids to each sentence S ] d1:= m1- , d2:= m2-  iii. [Check the distance either negative or not] If d1<0 then d1:= -d1 If d2<0 then d2:= -d2  vi. [Create cluster] If d1<d2 then C1:=  Else C2:= v. [Calculating new mean]  Find average value (av1, av2) of clusters C1 & C2.

vi.  [Assign the average value to the mean]  m1:= av1 & m2:= av2 vii. Repeat the steps (ii) to (vi) until the values of m1 and  m2 in two consecutive iterations remain unchanged.

viii. Return.

1) Explanation of the Pseudo-code The steps of the proposed method are discussed here in detail:  i. Preprocessing The actions performed in this step are: ? Noise removal is concerned with removing header, footer,  etc. from the document.

? Tokenization separates each word into lexical form. Words  are separated by ???, ????? etc.

? The stop words are function words like e??, a???, ??n,  a??????, ?????,??t etc. and they may be removed.

? Stemming ? A word in different forms in the same document need to be converted to their original form for simplicity like ?????????, ??????????, ??????????, ?????????o etc. should be converted to their original form ????????		. In the proposed technique, we used the rules for stemming any word that are illustrated in [20].

Let?s consider an example: ???? ????? ????. After stemming it will be ???? ??? ??. Some examples of word stemming are shown in Table I.

TABLE I.  SOME WORD STEMMING EXAMPLES Suffix Original words After Stemming  i           # e??i, ????i # e??, ???? ???      # ?????, ?????? # ??, ??? ??       # e????, ????? # e??, ??? ??.?? -> ??.     # ????, ????, # ????, ????, ??.??????? ->  ??. # ?????????, ????????? # ????, ????  ii.    Scoring Process ? Word scoring technique (TF/IDF): This approach is used for counting the words. If there are more unique words in a given sentence, then the sentence is relatively more important [23]. The TF/IDF score is calculated as follows:  = , ? = log	( + 1)  where, TF=Term Frequency  =Number of occurrence of the word  in the sentence S =Inverse document frequency N=Total number of the sentences in the text =Number of sentences in which word  occurs  ? Sentence scoring (SC): = ?  + PV  = ? Here,  = Position of the sentences & PV =Position value. For  example =1, if it is the first sentence of a document.

? Cue Words - If we found any cue word (e.g.,  ???????,a?????, i???????, ?????? etc.) in any sentence, then the score of the sentence is incremented by 1.

? Skeleton word ? If we found any skeleton word (e.g., headline of any document), then again the score of the sentence incremented by 1.

? Store the document in a separate file with the corresponding sentences? scores for further processing. For multi-documents, all the previous processes are applied for each document and stored in the same file where they are then merged. So for further processing, scores are sorted according to decreasing order.

iii.     Applying K-means clustering algorithm After sorting the scores the lowest and the highest scores are assigned as two centroids for the K-means algorithms and the distance from each centroid to each sentence is measured. Nearest distance from one centroid defines that cluster. Thus, two clusters are created and for next iteration, centroid values are updated. For this, the average value of each cluster is calculated and assigned them as new centroids respectively. This process is repeated until two consecutive iterations produce same result. Al last, top K sentences are extracted from each cluster to produce the final summary.



IV.  EXPLANATION WITH AN EXAMPLE Let?s consider there are two Bengali documents to be summarized. The first document contains 10 sentences and 131 words is [24]: ?????????? ? ? ?p?g???? o p???k?? ????? ??????? ???????????????? ???? ?????? ????i p???? ????? ???????? ???? ???? e???? ???c p???k?? u???????? ????? e????? ??k?? o ? ? p?n ??j?? o ??j?? ????? ? ???????? ???? a??? ???? ?????? ????? ??i ei ?kt???? ???? ?? e??? p???????? ?????? ????? ????? ??????j?? o p???k ???? ???? ???  ?????, ???? ?? ?i ??????? ?????? ????? ???? ????? ???? ????? ??????? o??l??  2016 e?? ????? 19-21 a?k??? 2016 ???n?? ??????? ?????? a??? ? ??? ????? ?????? ?? ?i???? i??n ??????? o??l??  2016? e???? ????? ???? ???? ud??? o p???k?? ???? ???????o ????? ei ???????? ei a?? ??? ???? ud??? ??????????? s??, ???? o ?? ?????????? ??j????  ??k?? ?? ????? p?l u?s????? ?????? ????? ???? ?????? ei p???????? ???? ??? ??? ??c, ?i??????? ?????? ei ????t o ?tt?????? ????? ?? ???????? g?? ??????  The second document on the same topic contains 14 sentences and 219 words is [25]:  ???s? ????????? ?s?????? ????? ???? ?????????  ?? ??? ????????? ???? o ????????? p???k ????? ????? ?????? ?? ???? ???????? o??l?? -2016?? ?????? ??????? ????? in?????????? ??????? ???? ???n??? (?i??????) e ????? u?d??? ???? p????nt? ??? ??????? ??? ????????? ei ???? ????? k??? ????n p?? ??? ???? 10?? ???? ??? 8?? ????n ????? ???? ????? ??????u?d???? a?? ??? p??? a????? ????? p????nt? ??? ?????? ??????, ??i???? ???????? ? ? ????? ? ???? ???? ???????? a???n ??????? p?l ???? ?????? p??l? ?o??? 50 ????? ? ?-? ??? p??k??? ????s? ??? ?????????????? ????u???? a???k-2016 ??? ??c ?????? ??? ?????? ????, ??o???? ??? ????? ????? s????? a??? ???? ??? ???????? ?????? ??????? ??k ?????? ???? ??k? ????s? un? ???? ???? ???? 30 ????? ???l?????? k?? ???? ?????? 2018 ????? ????? ??o ?? ????? ??? ????? ??????? ????? ???? ??? ????? i????????? ????? p?? ?? u?-??????i ? -?? ?????? ??????? ????? 2017 ????? ????? ????-?? ???? ??? ???? ???o ????? p????nt?????????? ????? ??s? (????) ????????, ??????? ????? ??? p???k o a????t ????? ????? o ???? ????p????? ???? ei ????? 40?? ?nt???? ??????? ???????? ?????? ?? ?? ??????? ???c ??? ????????? ???? ??? ??? ei ?????? e?? ?????? ???????? p?? ?? ????? ??????? ?????k? ???? ????? ??? ????????? ????? ??i?k?????, ??????, e????????, ?? ???? , ?????i, ??o??-?? ??  p?? ???? 43 ?? ?????? ?k?-?? i ?????? ?k? 18?? ????? a?? ??????  The score calculation of the words for the first sentence  of the first document is shown in Table II.

TABLE II.  WORD SCORE OF THE FIRST SENTENCE  Words Stemming Number of occurrence of words  in sentence(s) ( , )  Number of sentence in which  occurs ( )  Score of each word,  TF= , * log( +1)  ?????????? ???????? 1 1 1.04 ? ? ? ? 1 2 0.78 ?p?g???? ?p?g?? 1 1 1.04 o o 1 6 0.43 p???k?? p???k 1 3 0.64 ????? ???? 1 1 1.04 ??????? ????? 1 1 1.04 ???????????????? ?????? 1 1 1.04 ???? ???? 1 3 0.64 ?????? ?????? 1 1 1.04 ????i ???? 1 1 1.04 p???? p???? 1 1 1.04 ???? ?? 1 1 1.04  Similarly, using TF/IDF all the word scores are calculated. Then, the score of every sentence is calculated by summing up the constituent words? scores with their position using the mentioned formula. Also, the score of  a sentence is increased when it contains any cue word or skeleton word or both. After getting the sentences? score of all documents, they have been sorted  in a merged file which is shown in Table III for the considered example of two documents having 24 sentences in total.

TABLE III.  MERGED FILE WITH SENTENCE SCORES  Sentence score  notation Score Sentence  SC(1) 28.36  ? ??????? ????u???? a???k-2016 ??? ??c ?????? ??? ?????? ????, ??o???? ??? ????? ????? s????? a??? ???? ??? ???????? ?????? ??????? ??k ??????  SC(2) 26.14  ??? ????????? ????? ??i?k?? , ??????, e????????, ?? ???? , ?????i, ??o??-?? ??  p?? ???? 43 ?? ?????? ?k?-?? i ?????? ?k? 18?? ????? a?? ??????  SC(3) 24.77  ??s? ????????? ?s?????? ????? ???? ????????? ?? ??? ????????? ???? o ????????? p???k ????? ????? ?????? ?? ???? ???????? o??l?? -2016??  SC(4) 24.68 ??? ????????? ei ???? ????? k??? ????n p?? ??? ???? 10?? ???? ??? 8?? ????n ????? ???? ????? ??????  SC(5) 24.50  u?d???? a?? ??? p??? a????? ????? p????nt? ??? ?????? ??????, ??i???? ???????? ? ? ????? ? ???? ???? ???????? a???n ??????? p?l ???? ??????  SC(6) 21.52 ???????? ????? ??s? (????) ????????, ??????? ????? ??? p???k o a????t ????? ????? o ???? ????p????? ???? ei ?????  SC(7) 20.59 40?? ?nt???? ??????? ???????? ?????? ?? ?? ??????? ???c ??? ????????? ???? ??? ??? ei ??????  SC(8) 20.26 ??j?? o p???k ???? ???? ??? ?????, ???? ?? ?i ??????? ?????? ????? ???? ????? ???? ????? ??????? o??l??  2016 e??  SC(9) 19.39 ????? 19-21 a?k??? 2016 ???n?? ??????? ?????? a??? ? ??? ????? ?????? ?? ?i???? i??n ? ??????? o??l??  2016?  SC(10) 17.75 ?????? ??????? ????? in?????????? ??????? ???? ???n??? (?i??????) e ????? u?d??? ???? p????nt? ??? ???????  SC(11) 15.67 ???? ??k? ????s? un? ???? ???? ???? 30 ????? ???l?????? k?? ???? ??????  SC(12) 15.37 2018 ????? ????? ??o ?? ????? ??? ????? ??????? ????? ???? ??? ????  SC(13) 14.87 e????? ??k??  o ? ? p?n ??j?? o ??j?? ????? ? ???????? ???? a??? ???? ??????  SC(14) 14.55  ei a?? ??? ???? ud??? ??????????? s??, ???? o ?? ?????????? ??j????  ??k?? ?? ????? p?l u?s????? ?????? ?????  SC(15) 13.25 ????? 2017 ????? ????? ????-?? ???? ??? ???? ???o ????? p????nt??  SC(16) 12.85 ?????????? ? ? ?p?g???? o p???k?? ????? ??????? ???????????????? ???? ?????? ????i p???? ?????  SC(17) 11.67 ????? ??i ei ?kt???? ???? ?? e??? p???????? ?????? ????? ????? ????  SC(18) 11.53 e???? ????? ???? ???? ud??? o p???k?? ???? ???????o ????? ei ????????  SC(19) 11.03 p??l? ?o??? 50 ????? ? ?-? ??? p??k??? ????s? ??? ??????  SC(20) 10.45 ???????? ???? ???? e???? ???c p???k?? u???????? ?????  SC(21) 9.74 ? i????????? ????? p?? ?? u?-??????i ? -?? ?????? ???????  SC(22) 9.68 ???? ?????? ei p???????? ???? ??? ??? ??c, ?i??????? ??????  SC(23) 9.47 e?? ?????? ???????? p?? ?? ????? ??????? ?????k? ???? ?????  SC(24) 8.25 ei ????t o ?tt?????? ????? ?? ???????? g?? ??????  Then, K-means clustering algorithm has been applied with m1=28.36 and m2=8.25 as the centroids. As discussed above, the final iteration is shown in Table IV.

TABLE IV.  FINAL ITERATION  After extracting top 5 (K) sentences from each cluster, the finally produced summary, which contains 10 sentences and 173 words, is shown below: ? ??????? ????u???? a???k-2016 ??? ??c ?????? ??? ?????? ????, ??o???? ??? ????? ????? s????? a??? ???? ??? ???????? ?????? ??????? ??k ?????? ??? ????????? ????? ??i?k?????, ??????, e????????, ?? ???? , ?????i, ??o??-?? ??  p?? ???? 43 ?? ?????? ?k?-?? i ?????? ?k? 18?? ????? a?? ?????? ???s? ????????? ?s?????? ????? ???? ?????????  ?? ??? ????????? ???? o ????????? p???k ????? ????? ?????? ?? ???? ???????? o??l?? -2016?? ??? ????????? ei ???? ????? k??? ????n p?? ??? ???? 10?? ???? ??? 8?? ????n ????? ???? ????? ??????u?d???? a?? ??? p??? a????? ????? p????nt? ??? ?????? ??????, ??i???? ???????? ? ? ????? ? ???? ???? ???????? a???n ??????? p?l ???? ?????????? ??k? ????s? un? ???? ???? ???? 30 ????? ???l?????? k?? ???? ??????2018 ????? ????? ??o ?? ????? ??? ????? ??????? ????? ???? ??? ???? e????? ??k??  o ? ? p?n ??j?? o ??j?? ????? ? ???????? ???? a??? ???? ??????ei a?? ??? ???? ud??? ??????????? s??, ???? o ?? ?????????? ??j????  ??k?? ?? ????? p?l u?s????? ?????? ????? ????? 2017 ????? ????? ????-?? ???? ??? ???? ???o ????? p????nt??

V. EXPERIMENTAL RESULT AND DISCUSSION The proposed extractive Bengali document(s) summarization technique is implemented using the IDE for Java application,  Centroid Cluster Score Sentence  m1 = 23.25  C lu  st er  -1   29.03 ? ??????? ????u???? a???k-2016 ??? ??c ?????? ??? ?????? ????, ??o???? ??? ????? ????? s????? a??? ???? ??? ???????? ?????? ??????? ??k ??????  26.78 ??? ????????? ????? ??i?k?????, ??????, e????????, ?? ???? , ?????i, ??o??-?? ??  p?? ???? 43 ?? ?????? ?k?-?? i ?????? ?k? 18??  ????? a?? ??????  25.35 ???s? ????????? ?s?????? ????? ???? ?????????  ?? ??? ????????? ???? o ????????? p???k ????? ????? ?????? ?? ???? ???????? o??l?? -2016??  25.26 ??? ????????? ei ???? ????? k??? ????n p?? ??? ???? 10?? ???? ??? 8?? ????n ????? ???? ????? ??????  25.09 u?d???? a?? ??? p??? a????? ????? p????nt? ??? ?????? ??????, ??i???? ???????? ? ? ????? ? ???? ???? ???????? a???n ??????? p?l ???? ??????  22.07 ???????? ????? ??s? (????) ????????, ??????? ????? ??? p???k o a????t ????? ????? o ???? ????p????? ???? ei ?????  21.08 40?? ?nt???? ??????? ???????? ?????? ?? ?? ??????? ???c ??? ????????? ???? ??? ??? ei ??????  20.26 ??j?? o p???k ???? ???? ??? ?????, ???? ?? ?i ??????? ?????? ????? ???? ????? ???? ????? ??????? o??l??  2016 e??  19.39 ????? 19-21 a?k??? 2016 ???n?? ??????? ?????? a??? ? ??? ????? ?????? ?? ?i???? i??n ? ??????? o??l??  2016?  18.16 ?????? ??????? ????? in?????????? ??????? ???? ???n??? (?i??????) e ????? u?d??? ???? p????nt? ??? ???????  m2 = 11.36  C lu  st er  -2   16.03 ???? ??k? ????s? un? ???? ???? ???? 30 ????? ???l?????? k?? ???? ??????  15.73 2018 ????? ????? ??o ?? ????? ??? ????? ??????? ????? ???? ??? ????  14.87 e????? ??k??  o ? ? p?n ??j?? o ??j?? ????? ? ???????? ???? a??? ???? ??????  14.55 ei a?? ??? ???? ud??? ??????????? s??, ???? o ?? ?????????? ??j????  ??k?? ?? ????? p?l u?s????? ?????? ?????  13.56 ????? 2017 ????? ????? ????-?? ???? ??? ???? ???o ????? p????nt??  12.85 ?????????? ? ? ?p?g???? o p???k?? ????? ??????? ???????????????? ???? ?????? ????i p???? ?????  11.67 ????? ??i ei ?kt???? ???? ?? e??? p???????? ?????? ????? ????? ????  11.53 e???? ????? ???? ???? ud??? o p???k?? ???? ???????o ????? ei ????????  11.28 p??l? ?o??? 50 ????? ? ?-? ??? p??k??? ????s? ??? ?????? 10.45 ???????? ???? ???? e???? ???c p???k?? u???????? ????? 9.97  ? i????????? ????? p?? ?? u?-??????i ? -?? ?????? ??????? 9.71 e?? ?????? ???????? p?? ?? ????? ??????? ?????k? ???? ????? 9.69 ???? ?????? ei p???????? ???? ??? ??? ??c, ?i??????? ?????? 8.25 ei ????t o ?tt?????? ????? ?? ???????? g?? ??????    ?Netbeans IDE 8.0?, The performance analysis is performed in a 2.50 GHz Intel? core? i5 CPU with 4GB RAM running Windows 7 ultimate operating system. The comparison of the proposed technique with the existing approaches is shown in Table V. So, the proposed technique summarizes both single and multiple Bengali documents though noise removing, tokenizing and stemming, scoring each word by TF/IDF and then each sentence for applying the K-means clustering algorithm.

TABLE V.  COMPARISON WITH EXISTING METHODS  Author name/ Technique  Langua ge type  Docume nt type  Major Operations  K. Sarkar [13]   English   Multiple   Preprocessing, Clustering using cosine similarity, Cluster ordering  T.J. Siddiqui [15]  English   Multiple   Preprocessing, Sentence scoring (Feature based), Clustering using syntactic & semantic similarity  A. R. Deshpand [21]  English   Multiple (Query based)  Preprocessing (TF*IDF), Sentence scoring (Feature based), Clustering using cosine similarity  A. Agrawal [17]  English   Single   Word score (TF*IDF), Sentence scoring, K-means clustering  M. A. Uddin [18]  Bengali   Multiple   Preprocessing, Sentence scoring (TTF), Cosine Similarity measure, A* algorithm  M. I. A. Efat [19]   Bengali Single Preprocessing, Sentence scoring (Feature based), Sentence ranking  Proposed Technique  Bengali Single or Multiple  Preprocessing (Noise removal, Tokenization, Stemming), Word scoring (TF/IDF), Sentence Scoring, K-means clustering algorithm  Several experiments have been conducted to evaluate the proposed technique.  Some experiments are evaluated on single document and some are on multi-documents summarization. The proposed technique produced final summary from single or multiple documents which has 30% sentences of the original merged document. The proposed technique simply gives expected performance in comparison to the existing approaches. The time complexity of the proposed technique is ( ), which offers linearity. The main pitfall is that sometimes, the sequence of summarized sentences is not synchronized. However, the technique can be applied in various summarizing fields like summarizing similar articles from different newspapers, blogs, books etc.



VI. CONCLUTION In this paper, an extractive-based Bengali text summarization technique has been proposed both for single or multiple documents. In this summarization, some important sentences are extracted from the original document(s). We have compared the results with different extractive techniques and also measured the run-time complexity that shows the performance of the proposed technique is improved. According to the result of the proposed technique, we can conclude that it reduces the redundancy and provides better summarization. How to measure similarities is also a crucial issue in sentence clustering based summarization approach. The better similarity measure will improve the clustering performance and this may improve the summarization performance. We can measure the relevancy of the sentences using syntactic and semantic similarity in future.

