Insight and Reduction of Map Reduce Stragglers in  Heterogeneous Environment

Abstract- Speculative and clone execution are existing techniques to overcome the problems of task stragglers and  performance degradation in heterogeneous clusters for big data  processing. In this paper, we propose an alternative approach to  solving the problems based on analysis results of profiling and  the relations of the system parameters. Our approach adjusts the amount of task slots of nodes dynamically to match the  processing power of the nodes, according to current task progress  rate and resource utilization. It contrasts with the existing  techniques by attempting to prevent task stragglers from  occurring in the first place through maintaining a balance  between resource supply and demand. We have implemented this  method in the Hadoop MapReduce platform, and the TPC-H  benchmark results show that it achieves 20-30% performance improvement and 35-88% less stragglers than existing techniques.

Keywords-Hadoop; Map Reduce; Task Assigllmellt; Heterogelleous Cluster; Slots adjustillg; Resource Aware

I. INTRODUCTION  Hadoop is an open-source implementation of MapReduce and has been widely applied in large-scale data parallel processing. It divides a computation into small tasks and assigns them to multiple computational nodes running in parallel. It scales easily to very large clusters of inexpensive commodity computers, automatically handles failures, and hides the complexity of fault-tolerance from the programmer.

Hadoop was originally designed for homogeneous cluster environments, but it is used widely in various heterogeneous environments now. Because of the heterogeneous nature of both machines and workloads, Hadoop performs poorly, and some severe performance degradation and resource inefficiency of the Hadoop scheduler is observed [2-5].

Stragglers are one of the failure scenarios in which the tasks on a node perform poorly and the job executions lag.

Hadoop has a mechanism of speculative execution to handle stragglers. If a task's progress score is less than the average progress score of the tasks in the cluster, it is judged as a straggler. Hadoop starts a speculative copy of this task on another machine hoping that the computation will finish faster.

This approach improves job response times by 44% as noted by Google [I].

.

But under some cases, incorrect speculations can lead to a variety of failure modes, and large amounts of resources  This study is sponsored by the Open Programs by State Key Laboratory of Computer Architecture, the 863 Program of China under Grant No. 2012AAOl1003,  2013AAOIA212, the NSFC under Grant No,60921002, 912183001. 61202060, the Funding Project for Innovation on Science, Technology and Graduate Education in  Institutions of Higher Leaming Under the Jurisdiction of Beijing Municipality PXM2013_014213_000030_00042300, the Key Laboratory of High Confidence  Software Technologies (Ministry of Education) Peking University, and the Funding Project for Academic Human Resources Development in Institutions of Higher Learning  Under the Jurisdiction of Beijing Municipality,   occupied by stragglers and speculative executions are wasted, and the performance is degraded. In Amazon's Elastic Compute Cloud (EC2) clusters, which use virtualization to simplifY management and consolidate servers, experiments show that up to 80% of reducer tasks can be judged as stragglers and speculatively executed [2]. The 110 performance can be reduced by a factor of 2.5. In this case, task's progress score is approximately equal to its percent completion, and the average progress score can be increased very sharply when the disk 110 operations of some tasks finish, and other tasks can be judged as stragglers incorrectly.

Zaharia et al. [2] proposed a Longest Approximate Time to End (LATE) scheduling algorithm that shortens the response time of the jobs by a factor of 2 by identifYing the straggler sooner and improving speculative executions. Dolly [3]  improves the performance of the cluster by cloning the small tasks and discarding the lagging tasks. These approaches improve the performance of the speculative execution and shorten the cluster response times, but they don't answer why stragglers occur and how to reduce the stragglers before they occur.

A TSA [6] partially resolves the problems of stragglers caused by fixed task slots in the Hadoop cluster, by dynamically adjusting the task slots during the task assignment based on CPU utilization. It estimates the CPU utilization for single CPU-bound job scenario by using the user time, the system time, and the I/O-wait time as the metrics for resource utilization. A TSA works well for CPU-intensive applications.

However, for machines with low CPU capacities or high memory intensive or I/O intensive workloads, adjusting the task slots based on CPU utilization can cause more resource contentions and stragglers on the nodes.

Our work demonstrates that, besides the physical failures, most of the stragglers are caused by resource contention, which itself is caused by inappropriate task assignment. In any given time, the resource supply of a node is the subset of its resources that are available to the new tasks. The job tracker (task assigner) may assign an excessive number of tasks to a node, if it is not aware of the nodes' resource supplies and the tasks' resource demands. This leads to resource contentions and stragglers. On the other hand, assigning tasks insufficiently causes resource under-utilization and low efficiency. This basic principle is fundamental for a high performance and resource efficient heterogeneous Hadoop clusters.

In this work, we have explored the concealed reasons and symptoms of the stragglers from the perspective of the balance between resource supplies and demands. We have done large amount of profiling and analysis, and found out this balance.

We then developed a task progress rate-based (TPR) approach to adjust the task slots to improve the task assignment on the nodes. Our work improves performance and reduces straggler occurrences in heterogeneous Hadoop clusters. The main contributions of our work are:  (1) We explore the concealed reasons of the stragglers, and show that for each node with various resource supplies, an optimal task slot number exists. Assigning tasks according to the optimal slots can archive better performance and less resource contentions.

(2) We examine the relations among resource utilization, task progress rate, and task slots for a job on a node, and show that the task progress rate and the resource utilization can be a set of good indicators and metrics for adjusting the task slots.

The experimental results verify this idea strongly.

(3) We develop a task progress rate-based approach to adjust the task slots of a node. We also optimize the adjusting process to ensure they converge faster and fluctuate less. The experimental results show that this approach can improve performance and resource efficiency, and reduce stragglers, by balancing resource supplies and demands.

The paper is organized as follows. Section 2 describes the motivation of our work. Section 3 shows the profiling and analysis on the stragglers and the slots in a heterogeneous cluster. Section 4 examines the relations among the resource utilization, slots, and the task progress rate. Section 5 describes the task progress rate-based slots adjusting algorithm and the implementation. Section 6 introduces the experiments, the evaluations, and the discussion. Section 7 presents related work.

Finally, we conclude in Section 8.



II. MOTIVATION  A Hadoop MapReduce cluster consists of a master node and a number of slave nodes. The job tracker runs on a master node and assigns the tasks to the slave nodes (also named computational nodes). The task tracker runs on each slave node, and manages the task execution on it. For a given job submitted to the MapReduce cluster, the job tracker creates tasks for this job. The task tracker reports task progress to the job tracker at each heartbeat time (the default interval is 3 seconds). The job tracker assigns a new task to a slave node when the task tracker reports that a task is finished and that there is an empty task slot on that node.

The current task assignment algorithm of Hadoop MapReduce is a task slot-based algorithm. The number of task slots is the maximum number of concurrently running tasks on a slave node. Hadoop runs Map tasks and Reduce tasks concurrently on each node, with Map slots and Reduce slots separately. The default slot numbers are static, configured manually before the system starts running. Usually, Map slots are 1-2 times the number of the CPU cores, and Reduce slots are 2 or 4 by default.

By the default assumption in a homogeneous cluster, a task slot means one of the uniform resource quotas subdivided for tasks on a node. Each task occupies one slot and can get the same quota of computational power in the cluster, theoretically.

But in a heterogeneous cluster, the quotas on different nodes are various, and the tasks can't get the same quota of resources.

Further more, there is no mechanism to adjust the resource quota assigned to a task to meet its demand. At the same time, more and more stragglers and severe performance degradations [2-6] are observed. These phenomena motivate our works.

We analyze the resources of the cluster. We can get the physical parameters of the machines, such as the CPU core numbers, the memory capacities, and the maximum bandwidth of the Disk I/O or Ethernet. All of these parameters are different for each node and static, and are not adequate to accurately determine how many tasks can be assigned to the machines before the tasks execution. We need an approach to identify proper slot numbers of nodes and assign the tasks to nodes dynamically. By this approach, we can fundamentally mitigate stragglers and resolve the resource inefficiency problems, which are still not resolved by the existing approaches.

We examine task execution on the nodes, especially the Map task execution, and investigate how the task slots affect the performance and resource utilization of the nodes. We engage in building a resource-aware mechanism to adjust task slots and task assignment dynamically. This mechanism can maintain system balance between the resource supply and demand, with high resource efficiency and high performance.



III. PROFILING AND ANAL YSIS ON THE HETEROGENEITY AND STRAGGLERS  The heterogeneity of a cluster has three aspects: 1) each node has different physical parameters and resource supplies; 2) The tasks of each j ob have different resource demands; 3) For a balanced system, the numbers of tasks assigned to each node and the performance of tasks are different. So, we first quantitatively profile and analyze the heterogeneity by examining how performance and resource utilization change according to the various slots.

We build a prototype of a heterogeneous Hadoop cluster with 22 nodes, and run TPC-H benchmark [8] on it. We build a system state-monitoring tool to collect the resource utilization and performance information during the query job execution.

We run Query 18 of the TPC-H benchmark on the cluster 10 times, and configure the Map task slots from I to lOon each node. For each Map task slot number, we run the same query with the same configuration 3 times. The resource utilization information includes CPU utilization, memory utilization, disk I/O wait time, disk read/write volumes, swapping pages, and effective disk !Ethernet bandwidth etc. The performance information includes task slot number, successful task number, task progress rate, query response time, job execution time, and task execution time etc. In our work, the task progress rate is the ratio of the difference of the task process scores at two sequential time points to the time interval of one heartbeat.

TABLE!. TYPICAL CONFIGURATION OF SOME NODES OF THE CLUSTER  Node CPU Memory Disk  N13 AMD 4-Core 2.2GHZ 4GB SICI-60.48GB  N86 AMD 2-Core 2.2GHZ 2GB SICI-78.98GB  N201 AMD 8-Core 2.4GHZ 8GB SICI-127.2GB  N203 AMD 8-Core O.8GHZ 16GB SICI-4O.56GB  We choose four typical nodes from the cluster, which parameters are listed in Table I.

Our profiling and analysis results show that heterogeneity and task slots affect performance and resource utilization of nodes regularly and extremely. The following subsections give the details.

A. Slots and Task Execution Times Fig. 1 shows that task execution times vary according to  different slots on different nodes. First, when the slot is I on a node, a task can run without any resource contention. We treat this task execution time as the minimal execution time of a task on a node. Second, with a same task slot number, the average task execution times on different nodes are quite different. The heterogeneity of nodes makes it necessary to identify straggler occurrence by comparing the task progress rate of a task with the average task progress rate on the node other than the whole cluster. Third, on the node with low-level resource supply, the larger slots can cause more delays of the task execution. N86 is an example, on which the task execution times increase obviously. When the delays become severe, the stragglers occur.

B. Stragglers and Resource Contentions  The changes of resource utilizations of CPU and memory in Fig. 2 explain the reasons of the task execution times increase so fast on N86 when the slots increase. Fig. 2 shows that when more than two tasks concurrently running on N86, CPU becomes over-utilized resource. When the slot number is 7, the memory becomes bottleneck. We also observe an average 40MB memory pages are swapped to the swapping storage, and the swap space in disk storage increases to 500MB when the slots increase to 7. In the resource over-utilized scenarios, the tasks execution times are prolonged. When the tasks' resource demands are more than the nodes' resource supplies, some tasks can't make progress, and then the straggler occurs.

C. Do the Optimal Slots for the Job Exist?

Since the task slots affect the task execution time and the  resource utilization, do the optimal slots for a job on the node exist? The optimal slots means the job execution time are minimal and the resource utilization are not over-utilized and under-utilized.

Average task execution time of the 1st job  Fig. 1. Task average execution time on four nodes with different slots  CPU Utilization and Memory Utilization on NBG  Fig. 2. CPU utilization and memory utilization of the tasks on N86  The job execution time is not the sim ply sum of the tasks execution times of this job on the node. There is a turn point in the job execution time curve, which is con'esponding to the optimal slots for the job is on this point. Because when the task slots increase, the number of the concurrent tasks can increase also. The more task execution times can be overlapped, which can shorten the job execution time to some degree. On the other hand, the larger number of task slots can also introduce more resource contentions and extra delays, which can prolong the job execution time to some degree. Fig. 3 shows that N20 1,  N203, and N86 have the same optimal task slots of 3, and N13 has the optimal task slots of 5.

Comparing the average task execution time in Fig. I and the job execution times in Fig. 3, we can observe that when the slots are 5, the task execution time on N86 is 3.2 times larger than that of on N203, while the job execution time on N86 is nearly the same with that on N203. The reason is that because  N203 has higher processing power than N86, so it can execute more tasks than N86. Fig. 4 shows that when the slots are 5, the successful task numbers on N203 is 1.8 times larger than that on N86. More tasks are running on N203 than on N86, which ensuring the workload is uniformly assigned to the nodes.



IV. ANALYSIS ON RESOURCE UTILIZATION AND SLOTS  From the perspective of perfonnance, the profiling results show that the optimal slots for a job on a node exist. But, how can we adjust the slots dynamically to the optimal number?

What metrics and indicators can be used to identifY the balance state of a running system?

A. Metrics of Resource Utilization Based on the prior analysis results, we focus on the task  progress rate and the resource utilization, and examine the relations among the slots, the resource utilization and the task progress rate. First, we define two metrics to describe the intensity of the CPU utilization, memory utilization of the Map tasks. CPU utilization is the ratio of CPU busy time and the time interval, denoted as cpu util = .

cpu_idle -  ttme_lnterval  hh:mm:ss Job execution time on the nodes 0:02:18 ,------------ 0:02:01 h".-------------?-=- 0:01:44 ????i:;?????? 0:01:09 ? ...

0:00:52 1------------ 0:00:35 1------------ 0:00:17 1------------  1 2 3 4 5 6 7 8 9 10  Fig. 3. Job execution time on the four nodes  ?N86 -N203 -'-N201 ?N13    Successful Map task numbers ofJobl  J Fig. 4. Successful tasks nwnber with different slots  Memory utilization is the ratio of the maximum memory accessed by the tasks during the time interval and the physical  . . max mem accessed memory size, denoted as mem_utll = h  - . I - . .

p ycw _mem_SLze  Second, we define another two metrics to describe the intensity of the disk I/O utilization and the Ethernet bandwidth utilization of the Reduce tasks. Disk I/O utilization is the radio of the disk reading/writing volumes by the tasks during the time interval and the effective maximum Disk I/O bandwidth, denoted as disk util = read_vol+write_vol ? Ethernet bandwidth - max drsk bandwLdth utilization is the radio of the Ethernet receiving/sending volumes by the tasks during the time interval and the effective  ? . ? . . . rec vol+send vol maxImum bandwIdth, denoted as eth_utll = max _eth_bandwidth ?  These four metrics describe how many resources have been used by the tasks in the past heartbeat interval period. We use heuristic method to obtain the four resource thresholds. We set up workloads to exhaust the resource increasingly, and monitor the utilization when the most of task progress rates decrease.

Based on the distribution of the utilization, we can get the threshold of each resource. When one or more resources' utilization exceeds the thresholds, the resource contentions cause the task stragglers. For disk I/O resource, we use average I/O request queue length (denoted as avgqu) to assist to identifY the resource exhaustion. When the avgqu exceeds 2, the I/O resource contention occurs. As shown in Fig. 5, when  N20 I and N203 have 3 Map slots and 2 Reduce slots, the I/O resource becomes bottleneck and the avgqu are more than 4.

The experimental results show that the low disk I/O capacities limit the optimal slots on these nodes.

B. Slots and the Task Progress Rates From the perspective of the balance between the resource  supplies and the demands, the changes of task progress rates can illustrate whether the resource supplies can satisfY the tasks' demands a node. When the task progress rates increase or keep in positive, which means the tasks can get the resource quotas that they need; when the task progress rates decrease, which means the tasks are waiting for some resources or going to end.

In Fig. 6, there are 2 Map slots on N86, and 4 tasks are running in sequent in each slot. When a task is end, another task is assigned at the next heartbeat. At the beginning and the end of the tasks, the progress rates are zero. In Fig. 6, the rates of the tasks are all increase, which means the slots are reasonable.

In Fig. 7, there are 4 Map slots on N86. At the time 8, two tasks are end, and the other two tasks' progress rates decrease.

By comparing the changes of the task's progress rates between  the adjacent times during the task execution, we can identifY whether the tasks are keeping forward, blocked or delayed.

This result shows that 4 task slots are too much and need to be decrease.

The results of profiling and analysis show that the inappropriate task slots can introduce resource over-utilization and resource under-utilization. At the same time, the positive or negative changes of the task progress rates can be a good indicator for the improperly value of the task slots. By identifYing the changes of the task progress rates, we can deduce whether the slots are proper for the balance of the nodes' resource supplies and demands. We propose a resource? aware task progress rate-based task slots adjusting algorithm, to make the system keeping around the balance, and archive a high performance and resource efficient cluster.

v . TASK PROGRESS RATE-BASED TASK SLOTS ADJUSTING ALGORITHM  A. The main idea a/the Algorithm We adjust the task slots based on a combination of the task  progress rate and the resource utilization. Based on the changes of task progress rate and the resource thresholds, we can identifY whether the slots are close to the optimal numbers or not. We present the main idea by Algorithm 1 as following.

We statistic the task progress rates changes of each task in the running task set on the node. The new starting task and the ending task are not considered in this statistics. And then, we calculate the proportions of the rate-decreasing tasks and the rate-increasing tasks. If the task number is bigger than 2, and the decreasing task proportion is bigger than 40%, than we decrease the slots. On the other hand, if the task number is bigger than 2, and the increasing task proportion is bigger than 60%, than we increase the slots.

Average disk I/O request queue of the 1st Job  2S  20 ?--------------------?-- IS ?------------------.. ?-- 10 ?---------.r-------???  ? 10  Fig. 5. Average Disk I/O request queue of 1 ,( job 1  Map task progress rate of the 1st Job on N86  ? J J111 11 II I I ? 1\ 'm 1"\\ I J I \ \ \ ,1 \\ I \ I \ II \ \ 1/ ? I \  j ? J ?J. 1.1 J. .L.LLi  Fig. 6. Map task progress rates of .lob 1 on N86 (slot ?2)  _N203 N201  "-11011  ??1012    Map task progress rate of Jobl on N86  Fig 7. Map task progress rates of Jablon N86 (slot ?4)  _ Algorithm 1 A Simple Task Slots Adjusting Algorithm Require: task set N has n running tasks, task slots s, counter dec_c, inc_c, task progress rate tpr; Begin:  For each task in the task set N : { if (task_is_ new==1 I task_is_e nd ==1) then continue;  Get the current task process rate tPIj a nd the last task process rate tPIj_1 dlff = tPIj - tPIj_1; if (ditr, < 0) then dec_c ++; if (ditr, >= 0) then inc_c ++;  if (dec_c > n * Thres_dec) && (n >2) then s = s --; else if (inc_c > n * Thres_inc) && (n >2) then  if (cpu _util < Thres_cpu) && (mem _util < Thres_mem) then End  s ++ ;  In this algorithm, there are four values used as the thresholds. Thres _dec is the propOliion of the lagging task, which is 40% as the default in this work. The larger Thres dec makes the slot number decreasing slower, and the smaller Thres _dec makes the slot number decreasing faster. Thres inc is the proportion of the rate-increasing tasks, which is 60% as the default. The larger Thres inc makes the slot number increasing slower, and the smafler Thres inc makes the slot number increasing faster. These two parameters can make the slot number larger or smaller than the optimal value. In our experiments, when Thres dec is 60% and Thres inc is 40% the slot number of N203 is adjusted to 8, which is larger tha? the optimal value 5. When Thres _dec is 30% and Thres inc is 70%, the slot number ofN203 is adjusted to 3. Thres cpu and Thres _ mem are the thresholds of the CPU and -memory resource utilization, which are used to ensure the high resource utilization and avoid resource over-utilization. In this work, the average CPU utilization and memory utilization of a task is about 10% and 20%, so Thres Jpu and Thres mem are 90% and 80% separately as default. -  B. The Features a/the Slot Adjusting There are two features in the task slots adjusting, dynamic  adaption and asymptotic property.

It is a dynamic adaptive process to identify the optimal task slots for each job on each node, because of three reasons. I) The tasks' resource demands of jobs are varying; 2) The resource utilization of the same tasks on different nodes are varying; 3) The task progress rates of the Map and Reduce tasks are not uniform, depending on the multiple factors, such as OS's task scheduling, 10 scheduling and resource contentions. So, these features introduce three demands: 1) The adjusting need to be invoked when the first task of a new job stmis running on the node; 2) The task slots need to be adjusted to the optimal value as soon as possible, which is  called quick convergence; c) The task slots need to be adjacent to the optimal value as stable as possible, which is called minimal fluctuation.

We abstract this process as an asymptotical adjusting process shown in Fig. 8. Suppose that the Sopt is the optimal slot number, and the So is the initial slot number when the first task of a job starts. The tstart is the start time of the adjusting process, and the topt is the time when the slot number keeps around the optimal value. So the convergence time of the adjusting process is the difference between the time topt and tstarb denoted as Tconv = Topt - Tstart  The fluctuation of the adjusting process is the maximum difference between the slots number and the optimal slots number after the slots have reached the optimal slots, denoted as V = max {CSt - Sopt), t > Topel.

In Fig. 8, the convergence time is topctstarb and the fluctuation is SrSopt. These two parameters can be used to evaluate the efficiency of the slots adjusting algorithm. A good algorithm should have the ShOli convergence time and small fluctuation.

slot number  \ 1"  S2 \ \" /\  \ / time  I_start II 12  Fig. 8. The t1uctuation and convergence of the slot adjusting process  C. Fluctuation Reduction by Gear Shifting In order to reduce the fluctuation of the slots caused by the  brief and temporal resource over-utilization or under? utilization, we introduce a gear shifting mechanism. The function of the gear is to decrease the intensity of the fluctuation of the slots, delaying the update of the slots. The gear has three values: -1, 0, and 1. The initial value is 0 which means the slots need not be changed. The value -I m;ans the slots can be decreased, while the value 1 means the slots can be increased. When the conditions of decreasing are satisfied, while the gear is not -1, we just decrease the gear rather than decrease slots. When the conditions of increasing are satisfied, while the gear is not 1, we increase the gear rather than increase slots. We change the slots only when the gear is -lor 1, and the conditions are satisfied. After the slots are changed, the gear is set to O.

We calculate the conditions of slots adjusting by using the task progress rate and the resource utilization at each heartbeat and shift the gear accordingly. But we update the slots only at the heartbeat when there is at least one ending task. Even there is a temporal delay makes gear decreasing during a heartbeat time; but if the tasks' progresses accelerate subsequently, the gear can be shifted to the initial state, and the slots need not to be changed. So the gear shifting mechanism can reduce slots fluctuation.

D. Convergence Acceleration by Pace Scaling In order to obtain a short convergence time, we introduce  the pace of the slots adjusting. The default increasing pace is 1.

It is reasonable because the initial slots number is the double of CPU cores, and the job inherits the initial slots from the upstream job. The initial slots are ordinarily higher than the optimal slots, so the chances of increasing slots are slim. More over, the conservative increasing pace can reduce stragglers effectively. The decreasing pace are scaled, which is the maximum of the lagging task numbers during the past heartbeat period. If the slots are too large at the beginning of the job execution, some tasks can be delayed. The number of the delayed tasks is the decreasing pace of the slots adjusting at the next heartbeat. When the slots are close the optimal value, the delayed task number will decrease, so the adjusting pace decreases accordingly. By this mechanism, our approach can accelerate the convergence and reduce fluctuation of the adjusting process. The improved algorithm is shown in Algorithm 2.

Algorithm 2 Improved Task Slots Adjusting Algorithm Require: task set N has n running tasks, task slots s, counter dec_c, inc_c, task progress rate tpr, integer step =0, integer gear =0; Begin  For each task in the task set N : { if ( task_is_new==1 I task_is_end ==1) then continue;  }  Get the current task process rate tp0 and the last task process rate tPIj.l diff = tp0 - tP0." if ( dirt; < 0) then dec_c ++; if ( dirt; >= 0) then inc_c ++;  if ( dec_c > n * Thres_dec) && (n >2) then { step = max (step, decJ);  }  if (gear == -1) && (slack_slots_exist ==1) then s = s - step; else if (gear == 1) then gear = 0;  if ( inc_c > n * Thres_inc) && (n >2) then { if (cpu_uti! < Thres_cpu) && (mem_util < Thres_mem) then  if (gear == 1) then s ++ ; if (gear == -1) then gear = 0;  } end

VI. EXPERIMENTS AND EVALUATION  We build up a prototype of a heterogeneous Hadoop cluster with 22 nodes (21 slave nodes and 1 master node). The slave nodes have more than 10 different machine types with various CPU, memory, and disk capacity. The CPUs cores are from 2 to 32, and the frequencies are from 0. 8GHZ to 2.4GHZ. The memory capacities are from 2GB to 32G. We use Hadoop 0.20-2 and conduct a benchmark of TPC-H, with 40G data deployed on the 21 slave nodes. There are average 30 data blocks on a node, and each block size is 64MB or 128MB.

Hive and MapReduce create 6 jobs for the Query 18. Job 1 has 471 Map tasks and 32 Reduce tasks. Job 2 has 121 Map tasks and 9 Reduce tasks. Job 3 has 577 Map tasks and 37 Reduce tasks. The number of the tasks is determined according to the number of the data blocks.

We implement our task adjusting algorithm (denoted as TPR) and Wang's approach (denoted as ATSA) on the Job  Tracker and the Task Tracker, and compare these approaches with the original MapReduce task assignment algorithm (denoted as ORI).

A. Effectiveness on Performance We evaluate the effectiveness of the approaches by  comparing the query response time, the job execution time, and the average task execution time of the job under the three approaches.

The Fig. 9 (a) shows the query response time of the three approaches for 10 times execution. The query response time of TPR is the shortest, and is very stable through the multiple executions. It demonstrates that TPR can find the balance point between the resource demands of the tasks and the resource supply of the nodes, and can maintain the system running around the balance state.

The Fig. 9 (b) presents the ratio of the query response time of TPR to ATSA and ORI separately. In the best case, TPR is 24% shorter than OR! and 22% shorter than AT SA. In the worst case, TPR is 18% shorter than ORI and 29% shorter than A TSA. In the average case, TPR is 22% shorter than ORI and 23% shorter than ATSA.

Fig. 9 (c) shows the stragglers of TPR, AST A and ORion different nodes. On N86, TPR's stragglers occurs 35% less than ASTA's, and 80% less than ORr's. On N203, TPR's stragglers occur 87% less than ASTA's, and 88% less than ORl's. The results show TPR can dramatically reduce stragglers.

B. Improvement of Resource Efficiency Table II shows the CPU utilization and memory utilization  of the I st job on N86. TPR assigns 7 Map tasks and 2 Reduce tasks to N86, and the job execution time is 102s. Its average CPU utilization is 47%, and the maximum memory utilization is 49%. ASTA assigns the same amount of Map tasks and less Reduce tasks, but consumes 78% CPU utilization and 93% memory utilization, which are much more than that of TPR.

Even more, the job execution time of ASTA is I I I  % longer than that of TPR. OR! assigns 1 less Map tasks than TPR, and consumes 33% CPU utilization, which is 29% less than that TPR, but the job execution time of ORI is lSI % longer than that of TPR. The results show that TPR archives relatively the highest performance and resource efficiency.

TABLE!L RESOURCE EFFICIENCY OF THREE APPROACHES  Metrics TPR ASTA ORI  map_task_llum 7 7 6  reduce task num 2 2  job_exe_time(s) 102 215 256  cpu_util(%) 47% 78% 33%  mem_util(%) 49% 93% 57%  C. Stability of the Slot Adjusting Algorithm In order to verify the effectiveness of the optimization of  the slots adjusting algorithm, we collect and analyze the task progress rate, the slots number, and the task number on the    time(s) Query Response Time for 10 Times Comparison of TPR with ATSA and ORI Comparison of Stragglers on Different Nodes -  1200 -     t  (a)  ,-  7 8 9 10  ?ORI  35% ? 32%- '0%  25%  5%  ___?1--1 ..

60%  ?ORI  '0%  (b) (c)  Fig. 9. Query Response Times(a) , ratio of TPR to ATSA and ORI (b), Stragglers on different Nodes (c).

TPR: map slots and map task number on N8G AlTA: map slots and map task number on N8G TPR: Map task progress rate, slots and task number on N13 , ,-------------------------  " I (a) (b)  \ " __ "'12 I--------Ib----..-.-.-.-.-? __ lIotl "'-, - __ "'t?  I-----??--------?---???\-- -w" 1-------fR1I'I'l:71-------,/-;\-;!-<?\ ,; --..,,,  -..,,,, ...

(c)  Fig 10. The Map slots and map task nwnber of 1" job on N86 of IPR Ca) and ASIA (b). (c) is an illustration for slots adjusting process with initial slots of 8.

nodes. We compare the slots adjusting results of TPR and ATSA, to examine the detailed reasons effectiveness of TPR.

In Fig 10, the solid line is the Map slot number and the dashed line is the map task number. AT SA adjusts the task slots based on the CPU utilization, and it increases the task slots larger more than the optimal slots, and has some fluctuation as shown in Fig 10 (b). It assigns too many tasks at first, which delays the job execution and degrades the performance,  TPR adjusts the slots around the optimal slots stably, as shown in Fig. 10 (a). It assigns proper amount of tasks, and enables the tasks executing efficiently. Fig. 10 (c) illustrates the slots adjusting process on N13 in details. The initial Map slots are 8, and 8 tasks are assigned at first At the 6th time point, three tasks' rates increase, but five tasks' rate decrease, so the slots are decreased to 6.

D. Discussion By profiling and analysis the reasons of the stragglers, we  find out that there should be a balance between the resource supply of the nodes and the resource demands of tasks during the task assignment. We propose an approach of task progress rate-based slots adjusting. It monitors the task progress rate and the resource utilization, and adjusting the task slots to the balance point dynamically and asymptotically. There are two questions need to be discussed.

J) Whether this approach isjust for Map tasks?

In this paper, we use Map tasks as the example to illustrate  the approach, but it is available for Reduce tasks after being improved in details, while following the key idea of resource-  aware and balance keeping. The improved details are as following.

The Map task's progress rate is mainly dependent on CPU and memory resource, But the Reduce task's progress dependents on Map task's outputs as well as CPU, memory, disk 1/0, and Ethernet bandwidth. So when the task progress rates decrease, we need check not only the CPU and memory utilization, but also the disk I/O and Ethernet utilization, to identify whether the slots exceed the balance point.

When the resource over-utilized or under-utilized occurs, which task slots should be decrease or increase? Based on the logical relationship between Map tasks and Reduce tasks, we give Map tasks higher priority for increasing, and Reduce tasks higher priority for decreasing on one node.

Considering the different resource demands of the Map tasks and Reduce tasks, they can be treated as different kinds of tasks. We need distinguish the resource supply capabilities of different nodes, and assign Reduce tasks with higher I/O capacity nodes.

2) What's the value of the gear introduced in slot adjusting?

In this work, we have an innovation idea of treating the slots adjusting mechanism as a physical system. We use the concepts of balance point, gear, pace, convergence, and fluctuation to abstract our slot adjusting process. The experiment results show that it is reasonable and effective, Our work imply that there are uniform rules implied in the computing system as that of in the physical system, which we can abstract and exploit in the future work.



VII. RELATED WORK  In this section, we briefly overview existing studies on task assignment and resource utilization in the Hadoop cluster.

In order to improve the performance of MapReduce on the heterogeneous Hadoop cluster, there are some tasks scheduling optimization studies. LATE [2] is a significant effort to optimize MapReduce. It focuses on improving the correctness of stragglers identification and launching speculative execution as soon as possible. LATE uses estimated finish times to speculatively execute the tasks, and uses progress rate-based algorithm to identify stragglers. We both aim to improve the performance, but our work focuses on the reasons of stragglers and mitigating stragglers in the first place. The main idea of our work is to adjust the amount of the tasks assigned to the node, to balance between the resource supply and the resource demands. We improve the performance as well as the resource efficiency of the cluster.

Dolly [3] aims to effective straggler mitigation for interactive data analyses in datacenters. Their work has the similar goal with ours, which is to reduce the occurrence of straggler and improve the performance of the cluster. But their approach focuses on cloning the small tasks and discarding the lagging tasks. They try to reduce the cost of the clones, but the resource wastage is evident. Our work avoids the unnecessary resource dissipation. Our work aware the heterogeneity of resource supplies of each node and exploit it appropriately by dynamically adjusting the number of tasks to the node.

Tarazu [5] analyzes the key factors of poor performance of heterogeneous Hadoop cluster, and optimizes the network communication during the Map phase and the load balance during the Reduce computation. Our work concerns different resources from this work. We profile the resource utilization of the CPU, memory, and I/O on the nodes of heterogeneous Hadoop cluster, and investigate the reasons of the stragglers.

We optimize the task assignment by dynamically adjusting the slots of the nodes.

Some researchers observe the correlation between the resource utilization/contention and the performance, and engage in improving resource efficiency as well as the performance. Zhang et al. [9] study the distributed workload performance and job migration policies by considering both CPU and memory resources for distributed systems. Their studies indicate that a strategy selection in load sharing is depending on the CPU and the amount of memory demand of jobs, which supports our analysis of correlation between the straggler occurrence and the resource utilization. Ghodsi et al.

[10] study the problem of fair resource allocation in a system containing different resources. They focus on a system on one node, while we consider the whole cluster across the nodes with various resource supplies in a heterogeneous environment.

HARMONY [4] analyzes the heterogeneity of the workload and the physical machines of a heterogeneous cluster, and presents a heterogeneity-aware resource management system for dynamic capacity provisioning. Its goal is to minimize the energy consumption of the cluster and the performance penalty. It schedules the tasks to the proper nodes and shut down the idle nodes to reduce the energy consumption of the  cluster. Our work has different perspectives. We consider the heterogeneity of the workload and the slave nodes in terms of resource demand and supply. Our goal is to improve the resource efficiency and the performance.



VIII. CONCLUSION AND FUTURE WORK  In our work, we profile and analyze the stragglers in the heterogeneous Hadoop cluster, and find out that the imbalance between resource supply and demand introduces the stragglers as well as resource under/over-utilization. We consider the multiple resource supply of the various nodes, and propose a task progress rate-based task slot-adjusting algorithm. By this approach, we identify the balance point between the nodes' resource supplies and the tasks' resource demands. By adjusting the slot dynamically and asymptotically, our approach can assign the tasks to the nodes to keep the system running around the balanced state. The experimental results show that this approach improves performance and resource efficiency, and reduce stragglers. Our work demonstrates that, in a heterogeneous environment, in order to archive a high performance and high resource efficient cluster, being aware of the balance between the nodes' resource supplies and the tasks' resource demands is an effective strategy ..

