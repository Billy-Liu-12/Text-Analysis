<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Performance  Prediction for Association Rule Mining Algorithms

Abstract - Execution time prediction is very important issue in job scheduling and resource allocation. Association rule mining algorithms are complex and their execution time depends on both the properties of the input data sources and on the mining parameters. In this paper an analytical model of the Apriori algorithm is introduced, which is based on statistical parameters of the input dataset (average size of the transactions, number of transactions in the dataset) and on the minimum support threshold. The developed analytical model has only few parameters therefore the predicted execution time can be calculated in a simple way. The investigated domain of the input parameters covers the most commonly used datasets, therefore the introduced model can be used widely in field of association rule mining. The constant parameters of the model can be identified in small npmber of test executions. The developed model allows predicting the execution time of the Apriori algorithm in a wide range of parameters. The suggested model was validated by several different datasets and the experimental results show that the overall average error rate of the model is less than 15%.



I. INTRODUCTION The execution time estimation is an important objective in many applications, and this is especially true for long running, resource intensive, costly data mining algoritluns.

Performance prediction not only allows estimating the execution time, but also helps to adjust the parameters the execution time is particularly sensitive to. It allows balancing the associated costs and the expected benefits of the execution. Good estimation of resource requirements is also important in distributed systems, where the balance of the running time and the amount of processing resources can be fine tuned.

The main purpose of data mining is to fmd hidden relationships in large datasets. The association rule mining [I] is one of the most important fields in data mining. The  process has two separate phases; the first is to find the frequent itemsets, and the second is to detennine the rules from these itemsets. Because the first step works with the original dataset, which can be terabytes in size, its computation cost is much higher, than that of the second step. So most improvements ofthe association rule mining    step. So most improvements ofthe association rule mining algorithms focus on finding the frequent itemsets. The basic algoritlun for this purpose is the Apriori algorithm suggested by Agrawal et al in 1994 [2]. Several other methods where developed since that time [3], [4], [5], [6], but most of them are the enhancement of the Apriori algorithm.

0-7803-8588-8/04/$20.00 ?2004 IEEE.

The estimation of execution time of an association rule mining algorithm can be essential when choosing the parameters because of the huge amount of data that is processed by the algorithm.

The organization of the rest of this paper is as follows.

Section 2 and 3 introduce association rules and basic mining algorithms respectively. Section 4 describes the general idea of performance modelling based on complexity analysis. In Section 5 we suggest a model for the Apriori algorithm and in Section 6 and 7 the introduced model is identified and validated by experimental results comparing the measured and the predicted data. Our work is summarized in Section 8.



II. ASSOCIA nON RULES First we elaborate on some basic concepts of association rules using the formalism presented in [1]. Let I={iJ,i2 ?...? imJ be set of literals, called items. Let D={t"tz ? . . . ?  t,,} be set of transactions, where each transaction t is a set of items such that t ?;;;1. The item set X has support s in the transaction set D if s% of transactions contains X, here we denote s=support(X). An association rule is an expression in the form of X -7 y.

whereX,Y?;;;I, andXnY=0. Each rule has two measures of value, support and confidence. The support of the rule X -7 Y is support(X U V). The confidence c of the rule X 7 Y in the transaction set D means that c"10 of transactions in D that contain X also contain Y, which can be written in c '" S (X U Y) I S (X) form. The problem of mining association rules is to find all the rules that satisfy a user specified minimum support and minimum confidence.

If support(X) is larger than a user defined minimum support then the itemset X is called frequent item set.



III. BASIC ALGORITHMS The Apriori algorithm [2] uses the following theorem to reduce the search space: if an itemset is frequent then all of its subsets are frequent as welL This means it is possible to generate the potentially frequent i+ 1 itemset using frequent i item set. Each subset of candidate i+ 1 item set must be frequent. Hereby it is possible to find all frequent item set using database scan repeatedly. During the ith database scan the Apriori algorithm counts the occurrence of the i itemset and the end of the pass i, it generates the candidates containing i+ 1 item. Figure 1 shows the pseudo code of the Apriori algorithm.

The Apriori algorithm is a level-wise algorithm thus it accesses the database as many times as the length of the longest frequent itemset is.

If the dataset is huge, the mUltiple database scan makes the execution of the Apriori algorithm very long. Therefore several algorithms were developed to speed up the Apriori algorithm. These improved algorithms reduce the I/O cost  in different ways.

The Apriori-TID algorithm [2] prunes the dataset during the later steps. It deletes the items from a basket if they cannot be part of a frequent itemset. In this case it can reduce extremely the I/O cost of the algorithm, because it has to handle smaller and smaller datasets.

The Dynamic Itemset Counting (Die) [4] algorithm works in a different way. It tries to reduce the I/O cost via early candidate generation. The basic idea ofthis algorithm is to generate new candidates as early as possible. It scans the database and increments the counters of the candidates    the database and increments the counters of the candidates when an itemset became frequent so it is possible to generate new candidates based on the new frequent itemset. The candidate generation is a complex task; therefore the new candidates are generated only at checkpoints. The distance of the checkpoints is an important issue in this algorithm; the optimum is reached at about 10,000 read transactions as described in [4].

The Direct Hashing and PIUning algorithm (DHP) [3l collects some information about i+ 1 itemset during the i database scan. It does not generate i+ I itemset candidates in the ith step, but it keeps an extra counter array in the memory and an possible itemset is assigned to a counter by a hash function. In this manner multiple i+ 1 itemsets have the same counter. This counter can be used during the candidate generation step. An i+ 1 itemset cannot be a candidate if its counter value is not frequent. This technique heavily reduces the number of candidates hereby it is able to speed up the itemset counting phase.

The FP-growth (Frequent Pattern-growth) [6] is a basic two-phase mining algorithm. The FP-growth algorithm fITst reads the database and counts the occurrences of the items. Regarding the I-frequent items by the second database read it builds a so-called FP-tree in the memory.

LI ? {I f requ e n t  i te m s e ts} C2 ? GenerateCandidate (II) i +-- 2 while (Lj_1 *- 0) { foreach ( t ED) { Increm entCounter (Cj, t) } L, +-- {c e C, IcoC1;I'" &gt; min_,upp} i+-- i+l Ci ? GenerateCandidate(L;) } L +-- U Li Figure 1. Apriori algorithm After that it recursively generates conditional FP-trees and generates the frequent patterns without generating candidates. The FP-tree contains all market basket in the memory, but it can handle some itemset overlapping among the baskets, hereby it can compress the entire dataset. The main disadvantage of this algorithm is that it needs a large amount of memory. Hence it can handle limited size of datasets, but it works faster than the level wise algorithms.



IV. PERFORMANCE MODELLING The complexity of an algorithm is handled by setting up a computational model. The constants in the complexity formula can be calculated with regression analysis using a small number of test execution data. After this the formula can provide the execution times for a wide range of parameters.

A number of performance evaluation and prediction methods exist including iterative algorithms, analytical approaches of asymptotical analysis of the communication and computation complexity [7], adaptive sampling statistics techniques [8] and queuing network models [9].

In case of the analytical computational model: the relation between the problem size and computational time can be determined either based on the number of operations to complete or on the memory access pattern [\0]. The former is applied in the domain of processing-intensive problems (heavy use of floating point arithmetic), the latter is used in case of applications that deal with lots of data, on which they usually do limited amount of simple processing steps. Frequent itemset counting is the member of the second group where the overall performance is dominated by memory access time rather than computational power.

by memory access time rather than computational power.

By many association rule mining algorithms an additional relevant parameter can be the I/O access time.

The formula given for the execution times of the frequent itemset counting in Section 5 is based on counting the average number of memory accesses in function of the statistical parameters of the processed dataset.



V. PERFORMANCE MODEL FOR THE APRIORI ALGORITHM Due to the extremely high memory requirements of the FP-growth based algorithms, the level-wise association rule mining algorithms were in the focus of the execution time modelling. The Apriori algorithm is basis of all the level-wise algorithms therefore its analytical perfonnance model is a very important issue.

Association rule mining is an NP-complete problem [5] therefore the introduced execution time approximation is valid only for a part of the parameter space. During the parameter identification it is important to choose a parameter domain that covers the commonly used datasets.

The main parameters of the processed dataset, which can be identified before the association rule mining, are the number of the transactions (N) and the average size of the transactions (1). The execution time depends not only on the dataset parameters but also on the specified minimum support threshold. The minimum support threshold (8) is used for filtering out the significant itemsets therefore the minimum support value is independent of the dataset.

To develop an analytical model capturing the performance of the Apriori algorithm a detailed investigation of its operation is needed. The main features of its execution time behaviour are to be detennined. The investigated parameters are independent of each other thus their effects on the response time can be observed separately.

The evaluation of the ApTiori algorithm took place in a PC laboratory of our department. The algorithm was implemented in C#. The simulations were executed on a computer with Pentium 4 CPU, 2.40 GHz, and 1024MB of RAM. The datasets used by the algorithm are synthetic from [2]. The naming conventions of the datasets are described in Table 1.

Figure 2 illustrates the relation between the execution time and the number of transactions in the database. This relation can be well approximated by a linear function.

The smaller the minimum support threshold is the more itemsets fulfil the minimum support condition, and the more time is needed to discover them. The execution time dependence on the minimum support threshold is shown in Figure 3. The relationship between the two parameters is an inverse proportionality.

The time as a function of the average size of the transactions can be calculated considering the following facts. The distribution of the transaction lengths can be described by Gaussian distribution with T as expected value. When the 2-candidates are counted, all the two sized subset of the transactions is generated, and its occurrence is counted. This means that processing one transaction generate ti choose two subsets, which are to be counted, where 1;. is the size of the given transaction. In the t, level the j-sized subsets are to be generated. The number of these subsets depends on the number of the (jol)-frequent itemsets - and through this - also on the minimum support.

Experimental results show that the Apriori algorithm uses more than 40% of its time to discover the two frequent itemsets.

The reason for that is that the number of the candidates in the second level is more orders of magnitude higher than in the further levels. It is shown in Figure 4. In this way the execution time dependence from the average size of the transactions can be modelled with a polynomial of the degree three. The constants in the polynomial can be    degree three. The constants in the polynomial can be calculated by least squares method. The general form of the formula describing the model is shown in Equation 1.

'U' 3000 ;, 2500 .. 2CJOO :S 1500 lCJOO o "...- ?

V-- V ?

(1) ./ -' -- / ......- .--' ---' lOOK 200K 300K 400K SOOK 600K 700K 800K 900K l000K number of transactions IN) \ __ minsup?o.7% ...-min&amp;up:l% \ Figure 2. Execution time of the Apriori algorithm by the number of transactions o ?

? t--..

?

?

0.5% 0.6% 0.7% 0.8% 0.9% 1.0% 1.1% 1.2% 1.3% 1.4% 1.5% minimum wpport (%I I--Measured ....... Predicted I Figure 3. The execution time It&lt;; a function of the minimwn support using Tl817DIOK 300000 ..

.; 250000 ." :g 200000 .. ?150000 " ? 100a00 .., E 50000 " n c 0 0.5% 0.6% 0.7% o.S% 13.9% 1.11% minimum support {sl 11I1-candidate ils..camlidate II 2-candidato [] 3-:andidste [] 4-candidat&amp; II 5-candidate 01 II 7-cand',dat" olH:andidate II 9-candidatb .10-candidale Figure 4. The number of candidates in each level using the dataset T1817DIOK Table 1. Meaning oftlte synthetic dataset parameters T Average transaction length I Average size of frequent itemsets D Number of transactions

VI. PARAMETER IDENTIFICATION The measurements for parameter identification were made by different dataset parameters and support thresholds. The plIliill\eter T varied from 10 to 25 by 5, the parameter I was in the range of 2 to 8. The performance model does not contain the parameter I, because this parameter cannot be identified before the mining process.

Earlier experiences showed that there is a liner relationship between the response time and number of transaction hence this pllliill\eter was fixed to 100.000. The maximal number of the hems that can occur in a transaction was 1000.

The parameter of the performance model (Equation 1) can be calculated by least square method. Table 2 contains the identified parameters ofthe modeL    Table 2. Identified parameter of the model C1 2.62274E-05 C;! -0.001015643 C3 0.01436588 C4 -0.065519084 i - 1500 ? ,..

i 1000 o _Measured __ Predicted 9 17 25 33 41 49 57 65 73 81 89 97 105 113 121 129 137 numer Of measurements Figure 5. The calculated and the measured time by different database parameter settings To calculate the error of the model the following function was defmed (also used in [9]): e= ?i: lfi - l i , n i=1 !.

(2) where n is the number of the measurements, fi is the measured time and!;" is the calculated time.

Figure 5 shows the calculated and the measured execution times by all the different parameter settings, where the minimum support threshold changes from 0.5% tom 1 %. It is clearly visible in Figure 5 that the prediction function follows well the behaviour characteristics of the real execution times when varying the different parameters. The average relative error of the model calculated according to Equation 2 was: 1 n If; -ll e=-L I I =0.123445 n i=1 f.

(3)

VII. MODEL V ALIDA nON After the model identification process several measurements were taken to validate the model. Table 3 contains the synthetic database parameters that were used during the model validation.

Figure 6 shows the measured mining time and the predicted mining time by the different datasets. It is possible to realise that the model follows well the measured execution time.

In some cases, especially in case of low support values, the relative error of the model can be the double (max.

30%) than the average error ratio.

Table 3. Synthetic dataset parameters during the model validation T 18,22 [ 7,8 D 50K, lOOK, 250K The average relative error of the model calculated according to Equation 2 was: e=? tlh -ll n 1=4 h 0.133185 (4) The average error ratio is not significantly different from the error ratio of the identified model. Therefore the introduced performance model can be used for predicting the execution time of the Apriori algorithm in the investigated dataset parameter and support value intervals.



VIII. CONCLUSION In this paper a basic level-wise association rule mining algorithm, the Apriori algorithm was developed and its analytical performance model was introduced. Three input parameters were taken into the consideration in this model.

Two parameters, namely the number of transactions and average size of transactions describes the input dataset.

The third parameter, the minimum support threshold is the input parameter of the mining process. The constant    input parameter of the mining process. The constant parameters of the model can be identified by few measurements using least square method.

A simple formula was given to anticipate the performance of the algorithm, described welI the behaviour of the data mining algorithm for a wide range of parameters. The main contribution of the paper was predicting the behaviour of a complex probability based data mining algorithm in a relatively simple, closed numerical form allowing a good estimation of execution times.

The model was validated by comparing the calculated and measured performance. Experimental results showed that the suggested model is reasonably accurate in a wide domain having an average error below 15 percent.

1 2 3 4 5- 6 1 S 9 10 11 12 13 14 15 16 17 1$ 19 2(121 22 23 204 25 :?16 27 2S 29 30 I ....... M88$urai - p,.:lided I Figure 6_ Model validation: the C11lculated and the measured time The introduced model can be used not only for predicting execution times of the Apriori algorithm, but also for predicting the response time of the other level-wise association rule mining algorithms. The reason behind this is that these algorithms are based on the Apriori algorithm thus they inherit several properties from it. Of course the identification of the constants in the formula must be repeated when moving to different algorithm in the same way as when moving to different hardware environments.



IX. ACKNOWLEDGEMENTS This work was supported by IBM Hungary and the fund of the Hungarian Academy of Sciences for control research and the Hungarian National Research Fund (grant number: T042741).



X.REFERENCES [1] R. Agrawal, T. Imielinski and A.Swami, "Mining  association rules between sets of items of large databases" in Proc. of the ACM SIGMOD Int/'/ Conf On Management of Data, Washington, D.C.,USA, 1993, pp 207-216 [2] R. Agrawal and R. Srikant, "Fast algorithms for mining association rules" in Proc. 20'h Very Large Databases Conference, Santiago, Chile, 1994, pp.

487-499 [3] J. S. Park, M. Chen, and P. S. Yu, "An effective hash based algorithm for mining association rules" in Proc.

of the 1995 ACM Int. Con/. on Management of Data, San Jose, California, USA, 1995, pp. 175-186 [4] S.Brin, R. Motawani, J.D. Ullman and S. Tsur, "Dynamic Item set counting and implication rules for market basket data" in Froc. of the ACM SIGMOD Inti '1 Con/. On Management of Data, Tucson, Arizona, USA, 1997, pp. 255-264 [5] M. J. Zaki, "Scalable algorithms for association mining", IEEE Transaction on Knowledge and Data Engineering, Vol 12. No 3. May/June 2000, pp. 372- [6] J.Han, J. Pei and Y. Yin, "Mining frequent patterns without candidate generation" in Proc. of the 2000 ACM-SIGMOD Int'l Conf. On Management of Data, Dallas, Texas, USA, 2000, pp. 1-12 [71 David R. Helman, David A. Bader, and Joseph Jara: "A randomized parallel sorting algorithm with an experimental study", Journal of Parallel and Distributed Computing, 52(1):1-23, 10 July 1998 [8] J. Landrum, J. Hardwick, and Q.F. Stout, "Predicting algorithm performance", Computing Science and Statistics, 30, 1998, pp. 309?314 [9] P. Cremonesi and C. Gennaro, "Integrated Performance Models for SPMD Applications and and Distributed Systems, Vol. 13, No.7., 2002, pp.

745-757    745-757 [10] U. Meyer et aI., Algorithms for Memory Hierarchies, LNCS 2625, Springer-Verlag, Berlin, 2003, pp. 320- 35 4.

