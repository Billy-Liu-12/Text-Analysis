Mining  Interest Association Rules in Website Based

Abstract?Generally, a user will access a website with a certain  interest. Mining web users? interest access patterns has been an  important research direction in web usage mining. These  patterns are a kind of the special interest association rules  essentially. In this paper, we propose a new approach for mining  such rules based on Hidden Markov Model (HMM). In our approach, pages? contents and web server?s log need to be  preprocessed firstly. Next we present some definitions of users?  access interest in a website. In addition, a new incremental  algorithm Hmm_R is given to discover the interest association  rules. Finally, we report on experiments conducted with  simulative and real data and then testify that the algorithm can  find all interest association rules efficiently.

Keywords- Data ming; Web Usage Mining; Hidden Markov  Model;  Interest Association Rules

I. INTRODUCTION  In recently years, The World Wide Web is an immense source of data that can come either from the Web content, represented by the billions of pages publicly available, or from the Web usage, represented by the log information daily collected by all the servers around the world. Web usage mining as a branch of web data mining which aims at discovering web users? access patterns has become very active in academic and application domain [1].

When a user plans to access a web site, he must have a certain interest. From the other side, the designers of a website will make the web pages confirm some kind of interest classification structure. Understanding the way users navigate the web helps in formulating guidelines for web site reorganization, in providing the user data needed to build adaptive web sites, in making available statistics for effective placement of web advertising [2, 3].

Currently, there are some methods to discovery web users? navigation patterns: PageGather [4] approach proposed the idea of optimizing the structure of Web sites based co-occurrence patterns of pages within usage data for the site. But the approach will flat the web site?s structure and when there are a large numbers of web pages, the number of the index page will become overabundant. The idea of ??footprints?? [5] is: when a user accesses a website, he must leave footprints in the website.

After a period of time, the areas accessed most frequently by user will come into being paths. Therefore new comers will access website according to these paths. The literature [6] applies hypertext probabilistic grammar to discover the user navigation patterns and then uses the entropy of grammar to evaluate these patterns. WebWatcher[7] process the log in a  web site, organize the log data into the transactions and use the classical data mining approaches to mine the data. But the result can?t be used to adjust the web site?s content automatically.

As a whole, these methods above have not take the user?s  access interests into account. In this paper, we propose a new  method based on HMM [8] for mining the user?s interest access  patterns. In this method, we combine the technologies of web content and usage mining to find a path accessed most frequently by group users with a certain interest. These patterns can be broadly used in analyzing paths, recommendation, and reconstructing the web site.



II. DATA PREPARATION  A. Web Server Log Preprocessing  Web server log file records the properties of every access request e.g.: access time, IP address, URL or script. The aim of log preprocessing is to transform the requests submitted consecutively by users into user transactions. To be specific, the steps of web server log preprocessing are:  ?  Remove all the data tracked in Web logs that are useless for mining purposes [9,10] e.g.: requests for graphical page content ; or even requests performed by robots and Web spiders.

? According to user?s IP address, divide the whole log into independent access record sets.

? Sort the requests in every access record set according to the time submitted and then set the threshold tw for time windows to separate the access record set. If the time between a user?s adjacent page requests is shorter than tw, the two requests are defined to be in a same user session. In the end, every session of a user makes up an access transaction.

B. Keywords Extraction in Web Page Content  Some important keywords in a page can be extracted as a brief description of its content. When a user is visiting a website, all contents in the pages he has browsed can be characterized by the keyword set extracted from these pages.

Specific steps of keywords extraction in a page are:  ? In order to extract page contents efficiently, several cleaning procedures are needed: Removing HTML, XML or SGML tags; Filtering out all punctuations in contents like comma, full stop, quotation mark, etc.,  Supported by the National Natural Science Foundation of China under  Grant No.70671016     only except the underscore in-between words; Deleting all blank lines; Segmenting the terms; Term= {t1,t2, ..,tm} is a definition of characteristic terms set in a page after cleaning, in which ti is defined as a characteristic term and m is the number of terms.

? The characteristic terms do not necessarily have higher appearance frequency in a page?s content, but they may often appear in the tags of page such as: title, anchor text, url, key, etc. Therefore the frequency of  a characteristic term ti can be calculated by the following formula :  )()()()()()( 4321 ianchoriurlikeyititleiotheri ttfAttfAttfAttfAttfttf ?+?+?+?+=  (1)  In (1), A1,A2,A3,A4 represent adjustment coefficients. Then, weight of ti in the page is calculated as in (2).

,  )(  )(  )(    max  max  =  = m  j  j  i  ip  tf  ttf  tf  ttf  tw  (2)  In (2), maxtf  is maximum frequency in all characteristic terms.

The weight of a characteristic term can reflect its capability to represent the page?s content. Because Term={t1,t2, ..,tm} may be enormous, finally we choose some characteristic terms whose weight are greater than the pre-defined threshold to make up of the keywords set of a page: K={k1,k2,?,kn},K T. finally, the page p can simply be represented, as in (3):  })(,{ Kkkwkp iipi ?=                     (3)

III. USERS? INTEREST ASSOCIATION RULES (IAR)  A. Hidden Markov Model  Hidden Markov Model has been widely used in speech  recognition. In this paper, we adopt the discretization output.

The one-step Hidden Markov Model is presented as follows:  1. One state set Q which have a initial state qs and final state qf.

2. One state transition set in which every element is:  )'( qq ? .

3. One discrete output symbol set: = m??? ..., 21 .

Started from qs, one state transits to the next state in Q, and then an output symbol can be attended. When the transitions in  Q arrive at qf, a symbol string lxxxX ,...,, 21=  is generated.

The transition probability can be represented: )'( qqP ? . The attention probability of a special symbol on a state is: )( qP ?  . In this way, the attend probability of a symbol string X is  equal to the sum of probabilities in all possible paths  calculated by (4):  ? ?  +  = ? ?=  Qqq  l  k kkkk  fs  qxPqqPMXP ,...

1 )()()(  (4)  The common aim of building up a HMM is to find a state  sequence )( MXV , which has the maximum probability of  attention sequence. The equation is shown as in (5):  ? +  = ?  ? ?=    ,...,  )()()( maxarg  l  k kkkk  Qqq  qxPqqPMXV l  l  (5)  B. Definitions of users access interests  Generally, the web designers will layout a website according to a distributed model of keywords in the site. We proposal a distributed model of keywords shown as follows:  Given a distributed keywords model shown in the Fig.1.: CG=(W,E,K) .where CG is a directed graph. We let W be set of web pages; E be set of hyperlinks between pages; K be set of keywords placed in every page.

In order to characterize a user?s interest in a website, some definitions are given as follows:  Definition 1: the access transaction of a user u uT is made  up of all accessed pages, as in (6).

},...,,{ 21 m u pppT =                            (6)  Definition 2: every page p can be characterized by the  keywords set K according to (3), so the access keywords  transaction of a user u uTk is represented in (7):  },....,,{ 21 m u KKKTk =                            (7)  Definition 3: let ep be the No. e visited page in the uT .

Then the access transaction of a user coming through ep can  be expressed as in (8):  meppppT meee u ??= + 1},,...,,{)( 1                    (8)  Figure 1. The keywords model extracted from a website     According to (7), )( ep uT can be transformed into  )( ep u  Tk  which represents the access keywords transaction of  a user coming through pe:  meKKKpTk meee u ??= + 1},,....,,{)( 1                 (9)  Definition 4: Let ),( je u kplength  represent the time a  user u spends in accessing a keyword passing through ep .for a  web user, if he has interests in some topics, he must strive to  seek such pages with the topics and spend a lot of time on  those pages. Set )( e u plength  be the time a user u spending on  the page pe. If pe has keywords: k1 k2,?,kf (f is the number of  keywords), then ),( je u kplength can be calculated as follows:  ej  ej e  u  je  u  pinnotiskif  piniskif f  plength  kplength =  )(  ),( (10)  In this way, the total length of time ),( je u kpsum  that a  user u spends on a keyword kj in a Tk u can be expressed as  follows:  = = u e  u e  m  ei ji  u  je u  Tinnotispif  Tinispifkplength kpsum   ),( ),(  (11)  C.  Hidden Markov Model with users? Interests  ? In a state set Q, giving a virtual start node qstart and final node qend can be regarded as a state node in HMM. All users? navigations start with qstart and end with qend.

? There exists a symbol set: ={k1, k2,? kM}.The transition probability )'( qqP ? of two adjacent pages can be expressed as follows:   )(  )( )'(  '  qcount  qqcount qqP  ?=?                     (12)  Where 'qq ? represents q and q? are linked directly by  hyperlink and )( 'qqcount ?  is the number of transactions, in which users access the web site from q to q? in Q. The count (q) is the number of the transactions in Q, each of which has q.

? On the every node q?, users will have a probability distribution of the interests on the keywords set  )( 'qkP i , as in (13) That is the  in HMM.

= =  == N  1u  M   '   '  '  )),(  ),(  )(  m  m  u  N  u  i  u  i  kqsum  kqsum  qkP (13)  The interests of users passing q? meet a constraint as in (14).

1)(  ' = =  M  j  j qkP                                   (14)  D. Discovery of the users? interest association rules  For a access sequence Sl (here l represents the length of  S) and users? a interest k, its association rule: )( lSkR  is:  )()(  ...)()()()(()(    kkk  start  l  qkPqqP  qkPqqPqkPqqPSkR  ???  ??????=  ?  If CSkR l ?)(  (C is a given confidence threshold), then  )( lSkR  can be considered as an interest association rule.

IAN has a combination of two characteristics of the  number of hits and the duration of access, so )( lSkR  based  on IAN can perfectly reflect the users? access paths with a  certain interest topic. To discover these rules, we give an  incremental discovery algorithm for )( lSkR  as follows:  Algorithm: Hmm_ )( lSkR  Input: Q,S,C Begin:  k:=1; j:=1; S l:=S; While =1 do  :=0; For each s S l  q  If ),( qskR C then S l+1 :=  S l+1 + ( , q Rl+1:= Rl+1+ ),( qskR ;  j:=1;  End if;  End for;  End For;  k:=k+1; End While;  End.

Output:  Rk , k=1,?, n

IV. EXPERIMENTS FOR IAN  A. Experiment with simulation data  For a given simple website, its part structure is shown as  Fig.2:  Figure 2. A Web Site Example(A,B,C,D represent 4 different key, the  number of the directed line represent transition probability)     In this website, the number of users? access for are 4. The  specific paths are shown in Tab. 1.

TABLE I. A WEB SITE EXAMPLE (THE TIME LENGTH'S UNIT IS SECOND)  User Access Transaction  page time page time page Time  u1 N1 3 N2 3 N4 3  u2 N1 3 N2 3 N5 2  u3 N1 2 N3 2 N4 2  u4 N1  2 N3 2 N5 3  According to the access time on the nodes and the  distribution of keywords, the attention probability )( qkP can  be calculated as Tab. 2.

TABLE II. THE ATTENTION PROBABILITY IN EACH NODE FOR EACH KEY  A B C D  N1 23/180 65/180 27/180 65/180  N2 0 5/11 2/11 4/11  N3 4/27 10/27 0 13/27  N4 0 1 0 0  N5 0 0 0 1  Set confidence threshold be zero. According to algorithm presented above, we can obtain four interest association rules  for B shown as in Tab. 3.

TABLE III. THE FOUR INTEREST ACCESS PATTERNS FOR B  Access Sequence S l )( lSBR  S21= N1,N2 R(B  S  1)= 1*(65/180)*(1/2)*(5/11)  S22= N1,N3 R(B  S  2)= 1*(65/180)*(1/2)*(10/27)  S33= N1,N2,N4 R(B  S  3)= 1*(65/180)*(1/2)*(5/11) (1/2)*1  S34= N1,N3,N4 R(B  S  4)= 1*(65/180)*(1/2)*(10/27) (1/2)*1  Through the result of calculation in the above table:  R(B S21)>R(B S22)>R(B S33)>R(B S34), we can  draw a conclusion  that R(B S21)is the best path for interest B.

B. Experiment with real data  We choose the web server log file in a certain college as experimental subject. Experimental data includes the access logs in the website from Sept.2007 to Nov.2007. The total pages in the website are 227 and the log file is 45Mb including 47221 items. Through the procession of transaction identification, we obtain 2443 users? access transactions.

We define four keywords in the website: = {Research,  HR, Teaching, and Organization}. Mark the subset of  on  the every page. According to the log file, discover the interest association rules. In our experiment, we choose ?Teaching? as interest keyword. The association rules obtained are shown in Tab. 4.

TABLE IV. THE THREE INTEREST ASSOCIATION RULES FOR ?TEACHING?(CONFIDENCE THRESHOLD IS 10-10)  Access Sequence  S l )10( 10??lSteachingR  (/, /kyc/jb25.htm, /cjc/cjc. Html) 3.576 10-9  (/, /kyc/nn.htm, /kyc/jb25. htm  /cjc/cjc. Html) 6.456 10-9  (/, /kkk/nnl.htm, /kkk/jb25.htm,  /cjc/cjc.html) 2.156 10-10  The time experiment about generating rules for  )( lSteachingR  (confidence threshold is 10 -10  ) is also conducted.

The specific results are shown in Fig.3.

Figure 3.  The Time Experiment about Generating Rules for )( lSteachingR

V. CONCLUSIONS AND FUTURE WORK  In the paper, we firstly apply HMM to the discovery of users? frequent interest access association rules with a certain interest. There are some characteristics in our approach: 1) it is a kind of optimizing approach. 2) The mining object is the interactive action and the common interest, and the mining result faces up to the total users. 3) The discovered rules have not always direct hyperlinks with each other.

The next step of our work is to apply our approaches to predict users? access behaviors for the real-time personalized recommendations.

