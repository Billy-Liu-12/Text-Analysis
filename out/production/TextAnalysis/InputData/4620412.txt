DTGC-TREE: A NEW STRATEGY OF ASSOCIATION RULES MINING

Abstract: Efficient algorithms for mining frequent itemsets are  crucial for mining association rules. As a condensed and complete representation of all the frequent itemsets, closed frequent itemsets mining has arisen a lot of interests in the data mining community. However, most of the studies haven?t addressed the effects of noise in the data sets on the algorithms, and there has been limited attention to the development of noise tolerant algorithms.

In this paper, we represent a noise tolerant algorithm, DTGC-Tree, which based on an intuitive idea: applying association rules as soon as possible. By this way, the new algorithm could prune a lot of duplicated closed itemsets in the transactional data base. The performance evaluation demonstrates that the proposed algorithm could stand against noise and is both time and space efficient.

Keywords: Frequent Itemsets; Closed Itemsets; Association Rule;  Data Mining  1. Introduction  Frequent closed itemsets is a complete and condensed representation for all the frequent itemsets. It is an application of the FCA(Formal Concept Analysis) in data mining. We give a brief introduction about FCA here.

A triple ( , ,T )I R  is called a Formal Context if and  are sets and  is a binary  relation. We call the elements of  Transactions, those of  T I ? ?R T I T  I  Items, and  the Incidence of the context ( )  R , ,T I R . For , we define  T ? T ( ) ( )f T { i t i t T= ? , ? ,? ? I?  R }  and dually, for I ? I , ( ) ( )h I { t t i i I}= ? , ? ,? ? T  R  A pair  is called a Formal Concept if and only if it satisfies  (T I, ) ( ) ( )f T I h I T= , = .   is called the  Extent and  T  I  is called the Intent.

Definition 1   An itemset  X  is said to be closed if and only if , where the composite function  is called a Galois operator or a closure operator.

( ) ( ( )) ( )C X f h X f h X X= = = C f h=  Closed frequent itemsets are proved to be a condensed representation of all the frequent itemsets which guarantees no information lose. There?re extensive researches which have been carried out in this field, in the following they are split to four categories :  Both A-Close [11] and TITANIC [7] exploit a level-wise process to discover closed itemsets through a breadth-first search strategy. In each iteration, they try to search for candidates of MGs (Minimum Generators) with the help of search space pruning technique, and then verify them. Finally the MGs are used to generate all the closed itesmsets . Usually these algorithms are required to scan the whole dataset many times.

For CLOSET [12] and CLOSET+ [5]. With the help of high compact data structure FP-Tree, they try to project the global extraction context to some smaller sub-contexts, and then apply FCI mining process recursively on these sub-context. Better performance can be achieved than the adoption of A-close and TITANIC algorithms.

CHARM [6] and DCI-Closed [3] exploit hybrid techniques which try to use the properties of both previous mentioned techniques. Due to a data structure called IT-Tree, CHARM simultaneously explores both the closed itemset space and transaction space, with the depth-first search strategy, and generates one candidate each time, then with tidset intersection and subsumption checking, it will see whether the candidate is closed. DCI-Closed could be considered as an improvement of CHARM.

FCI Stream [2], GC-Tree [14] and TGC-Tree [15] are online algorithms which performs the closure checking over a data stream sliding window. FCI Stream uses a in memory data structure called DIU-tree to store all the Closed Itemsets discovered so far. With a specific search space pruning technique, it tries to perform the time consuming      closure checking operation only when it?s really needed.

GC-Tree and TGC-Tree are the bases of DTGC-Tree, we will describe them in details in section 2.

The rest of this paper is organized as follows. Section 2 introduces the GC-Tree and TGC-Tree, on which DTGC-Tree is build. Section 3 gives a simple example .

Section 4 presents the proposed DTGC-Tree algorithm. The performance evaluation is depicted in Section 5. Finally, comes conclusion of this paper, Section 6.

2. GC-Tree and TGC-Tree  2.1  GC-Tree  GC-Tree [14] is a tree that maintains all the closed itemsets in the data stream as nodes. The idea of GC-Tree is based on the following theorem which is introduced by Claudio Lucchese et al [3]: Theorem 1    For each closed itemset  Y ? C(?), there exists one and only one sequence of  items ( 1n n ? )   n n? ?  0 1 ? ni i i ?? ? ?  such that  0 1 1 0 0 1 1 1 1? ?n{gen gen gen } {Y i Y i Y i }?, , , = ? , ? , , ? where the various  are order preserving generators,  with  and  .

igen  0 1( ) ( ) [0 1]j j jY C Y C Y i j n+= ? , = ? ? ? , ?  nY Y= When we say a generator is order preserving, we mean: Definition 2    A generator X Y i= ? , where  is a closed itemset and  , is said to be order preserving one i  Y i Y?  iff ( ( ) )C X X?? The concepts of "preset" and "posset" are defined as: Definition 3  Let  be a generator of a closed itemset where Y  is a closed itemset and .

preset(gen) is defined as  gen Y i= ? i Y?  {j i j gen}| ?? . posset(gen) is defined as{j I j? | ?  preset(gen) . ( )and j C gen }?  GC-Tree works under the data stream environment.

This algorithm uses an in memory data structure called GC-Tree (Generator and frequent Closed itemsets Tree) to store all the frequent closed itemsets. Each element in The GC-Tree has the following format: .

Where  is the closure generator,  is the extension item with which  used to extend another closed itemset,  is the corresponding closed itemset.

gen eitem clo< , , > gen eitem  gen clo  GC-Tree is lexicographically ordered. For each closed itemset, there exists a path in GC-Tree from the root to the specific node, all the elements in this path compose the  order preserving generator sequence mentioned in Theorem 1. 0 1 1? n{gen gen gen }?, , ,  2.2. TGC-Tree  TGC-Tree [15] is a variant of GC-Tree which trying to trace the closed itemsets and closed transaction sets simultaneously. Actually, it maintains two GC-Trees, one of them keeps all the closed itemsets, called I-Tree, and the other keeps all the closed transaction sets(see Definition 4), called T-Tree. There?re links between I-Tree and T-Tree. A pair of nodes linked together represents a formal concept.

The node in the I-Tree represents the Intent of the concept, and the node in the T-Tree represents the Extent of the concept.

Definition 4     Transaction set  is said to be closed if and only if  A ( ( )) ( )h f A h f A A= =  3. A Simple Example  In the synthetic database in table 1, there?re two types of movies: sci-fi and action. "Die Hard(D.H.)", "007" and "Indiana Johns(I.J.)" are assumed to be purely action movies, "A.I." and "E.T." are purely sci-fi movies, "Matrix" and "Star War(S.W.)" are action and sci-fi movies.

If we gives ids("1~7") to the movies respectively. Then, by the definition, there?re 10 formal concepts in the synthetic database. Figure 1 shows them as the result of TGC-Tree algorithm.

The tree on the top is the I-Tree, the nodes of which are the Intents of the formal concepts. The tree on the bottom is the T-Tree, the nodes of which are the Extents.

The dash lines denote the one to one mapping between the nodes in I-Tree and T-Tree. If we accept association rules with support 4 and confidence 75%, then we have the following association rules:  ?If a user likes movies (2, 3, 4, 5) then he/she would also like movie (1)  ?If a user likes movies (4) then he/she would also like movie (5)  ?If a user likes movies (4, 5, 7) then he/she would also like movie (6)  The DTGC-Tree Algorithm tries to apply these association rules. As a result, there?re only 4 formal concepts left(See Figure 2):          Table 1: Movie Database      Figure 1: Result of TGC-Tree        Figure 2: Result of DTGC-Tree  The missing data could be treated as noise, which is shown in Figure 3 as circles. This figure demonstrates that in the presence of even low levels of noise, large number of unnecessary formal concepts could be generated.

Figure 3: Scatter Plot       4.  The DTGC-Tree Algorithm  4.1. The new strategy  The new strategy adopted in this paper is a heuristic method, which suggests that by applying the association rules found so far in the data stream to the TGC-Tree, the performance of the algorithm could be improved dramatically.

If we assume that the transactions come randomly, and treat the endless data stream as a whole population, then the following lemma could derived from Bernoulli?s Law of Large Number directly.

Lemma 1  If there?re  transactions already received from the data stream. Let  m 1?  and 2?  be the  supports of itemsets  and  (where ) in the received transactions respectively, then we have: the confidence  1? 2? 1? ?? 2    ? ?  converges to the conditional probability  1 2( 1P ? ?= 1)| = According to Lemma 1, we could say that if the  number of received transactions is big enough, then, the association rules found in the received data set are valid association rules in the whole data stream. So that it is reasonable to adopt the new strategy of applying the already found association rules to TGC-Tree.

4.2. Find association rules  DTGC-Tree is an algorithm based on TGC-Tree [15], with an additional component to apply the new strategy.

The new component will iterate through every node in the I-Tree to find the association rules, then applying them. So, firstly, the new algorithm needs to find the association rules.

We give the pseudo code in Table 2:  Table 2: Find association rules 1:  procedure findAssociationRules(I-free) 2:    for each  in I-Tree; node 3:       superNodes node superNodes= .

4:        for each  supNode superNodes? 5:     if ( )( )( ( . ) & )  s node clo s supNode clos supNode clo S C  .

.? ?  6.        return ( node ) clo supNode clo. ? .

Explanations: ?   :  contains  all the super sets of the current node.

node superNodes. superNodes  ?   : this is the threshold of the support of association rules, which is set beforehand.

S  ?    : this is the threshold of the confidence of association rules, which is set beforehand.

C  4.3. Updating the DTGC-Tree  Now, we have rules in the following format: ( ).  subNode clo supNode clo. ? .

Let  denotes the corresponding node in the T-Tree, and let  subNode tNode.

is supNode clo subNode clo ts subNode tNode clo supNode tNode clo  ? ?  = . ? .

= . . ? . .

?  .

( ( )) ( )  denote the delta itemset and delta transaction set respectively, then we have: Rule 1  Applying the rule( ) subNodeclo supNodeclo. ? .

is equivalent to add itemset  to all the transactions in transaction set  is? ts?  Now we could apply this rule to every node in the I-Tree to update it.

In the following discussion, we denote  as the data  set before applying the association rule,  as the data set  after applying the association rule,  and  as the  transaction  in  and ,  denote the current node in I-Tree the algorithm is checking.

1T  2T  1T t  2T t  t 1T 2T curNode  Lemma 2 shows how to find nodes need to be updated: Lemma 2   If , then the  remains the same.

curNode tNode clo ts?. . ? = curNode clo.

Proof: Let    is c u rN o d e c lo= .

and  ts . curNode tNode clo= .

Since  is closed itemset in , then is 1T f h is f ts is= =  in . And in , we have  and 1T 2T  ( )h is ts? ( )f ts is=  since there?s no transaction in  is changed. So that ts ( ( )) ( )f h is f ts is? =  in .

On the other hand, we have  2T ( ( ))f h is is? . Hence,  ( ( ))f h is is= , that is, remains closed in .  is 2T Lemma 3 shows how to update a node in I-Tree:  Lemma 3  Let  and . Then, we have , we  have  . .ts curNode tNode clo= 2 1( ) ( )T Tis f ts f ts? = ? i i? ? ? s  s  s s  i i?? Proof:  If   and . We could infer i i? ? ? i i??      that , . Hence  in ,  however  which means  is not closed itemset in . Contradiction.

t ts? ? 1Ti t? ( ( ))i f h is? 1T i is i i? ? ? ? s is  1T According to Lemma 2, 3, we have the following  pseudo code of finding the expanded itemset for the current node in I-Tree. See Table 3:  Table 3: Find expanded itemset 1:  procedure findExpandedItemset(curNode); 2:  if ; . .curNode tNode clo ts? = ?? 3.   return ; ? 4. ; expandSet is= ? 5. for each ; . .tran curNode tNode clo? 6.   ; expandSet expandSet tran= ? 7.   if ex ; pandSet = ? 8.        return ? ; 9. return expandSet;   Once the expanded itemset is found, we set  . Then we need to find and delete any node in the I-Tree which has the same closed itemset. After that, we will try to relocate it if it?s necessary, the relocation algorithm is described in [15].

. .curNode clo curNode clo expandSet= ?  To improve the performance of finding the node which contains the same closed itemset, we keep all the nodes in the I-Tree in a hashtable, so that this kind of operation will be completed in  (1)O  Another kind of operations need to perform is to update the T-Tree, these are just the dual operations of updating the I-Tree.

4.4. Adding new nodes to the DTGC-Tree  The process of applying the association rules may introduce new closed itemsets. According to paper [14], if there?re two closed itemsets ? and ? in I-Tree and ? ? ? ??  then, ? ??  is closed itemset too. So, in our case, it is possible that in 1, T ? ? ? ?? , and in , or  2T ? ?  is expanded so that ? ? ? ?? , hence there?s a  new closed itemset introduced.

The following pseudo code in Table 4 is used to deal  with this kind of situation: Table 4: Insert New ClosedItemset  1:  Procedure insertNewClosedItemset? ? ts? 2:    for each I-Tree node? 3:       for each t t  s  )  )  ??  4:           _ .new clo t node clo= ? 4:          if  ( _ )findNode new clo = ? 5:              ; ( _addNewNode new clo Explanations:  ?  the function ( _findNode new clo  is used to find node in the I-Tree which contains the same closed itemset as the input, if there?s no such node found, it will return  since we keep all the nodes in I-Tree in a hashtable, this function returns in  ?  (1)O ?  the function  is used  to add a new node to I-Tree with closed itemset , the details could be found in [15].

( _addNewNode new clo)  _new clo ?  the corresponding transaction node of  should be generated and inserted to T-Tree, the details could be found in [15].

_new clo  5 Performance Evaluation  We compared our algorithm with TGC-Tree[15], the result shows that in the data stream environment, DTGC-Tree is several orders of magnitude faster than TGC-Tree. A series of synthetic datasets are used. They are generated by the method as described in [14], the name of a dataset looks like T10.I6.D100K, where the three numbers denote the average transaction size (T), the average maximal potential frequent itemset size (I) and the total number of transactions (D), respectively.

The DTGC-Tree algorithm uses the following parameters:  ?  : the threshold of the support. S ?  C : the threshold of the confidence.

The algorithm applies all the association rules which  has support greater than  and confidence greater than . In the performance evaluation, we set and  .

S C 30S =  85%C = Figure 4 shows the average processing time for the  algorithms with the increment of the number of transactions processed. From Figure 4, we could conclude that the more number of transactions processed, the more DTGC-Tree outperforms TGC-Tree.

Figure 5 shows the memory usage of DTGC-Tree and TGC-Tree according to the number of transaction processed.

DTGC-Tree requires much less memory than TGC-Tree.

It?s because the size of the trees maintained by DTGC-Tree is much smaller than TGC-Tree.

6 Conclusions and Future Work  In this paper we proposed a noise tolerant algorithm of mining frequent closed itemsets in data streams. It adopts a new strategy of applying found association rules so far in the data stream. It is theoritically appropriate if the transactions in the data stream come randomly. By using this heuristic method, the new algorithm could generate more reasonable and useful itemsets than normal frequent closed itemsets mining algorithms, meanwhile is more   Figure 4: Runtime Performace   Figure 5: Memory Usage   efficient computationally. The performance evaluation shows that the new algorithm is empirically several orders of magnitude faster than the state-of-arts algorithm, TGC-Tree.

