Privacy preserving similarity detection for data analysis

Abstract?Current applications tend to use personal sensitive information to achieve better quality with respect to their services.

Since the third parties are not trusted the data must be protected such that individual data privacy is not compromised but at the same time operations on it would be compatible. A wide range of data analysis operations entails a similarity detection algorithm between user data. For instance clustering on big data groups together objects based on the heuristic that similar objects are likely to be put under the same cluster. Similarity decisions are important for numerous applications such as: online social net- works, recommendations systems and behavioral advertisement.

In this paper we propose a mechanism that protects user privacy and preserves data similarity results although encrypted. We analyze the security of the scheme and we further demonstrate its correctness and feasibility through a real life experiment where ?personality traits? by users are collected for a 4square application.

Keywords?Information security, privacy, data analysis, similar- ity detection

I. INTRODUCTION  Most of today?s ICT applications tend to leverage user information more and more to achieve better content delivery.

In particular recommendation systems collect data about users and their interactions with their environment in order to deliver the most appropriate and personalized content to them. The leveraged information spanning users? social relations and personal interests consist of highly sensitive data and hence raises the problem of privacy; a naive solution on the afore- mentioned problem could be to encrypt data before analyzing them. This would not solve the problem as operations after encryption would not be feasible. A more suitable solution could be to encrypt data homomorphically thus statistical properties on data after encryption are preserved. Even though this solution seems approachable the current homomorphic encryption schemes fall short of giving a solution for a global analysis system applied to some large scale dataset. Moreover anonymization techniques do not offer the appropriate security guarantees for individual data privacy and also have been vulnerable to attacks [1].

One of the basic building blocks in the vast majority of data analysis scenarios is similarity detection. By analyzing users? dataset, a recommendation engine can discover similar profiles and thus recommend a newly arrived user some content that was already consumed by other existing ?similar users?. Online advertisers sought to increase their revenues by inspecting the online behavior of users. That implies an outsourcing  of personal sensitive information by online retailers to the advertisers.

The aforementioned applications imply a privacy violation risk. Since the input to the data analysis operations is personal sensitive private information and operations performed over them violate user privacy. As such, users and companies either tend not to submit their data for further analysis to untrusted parties or they give limited access on it due to individual privacy violation risks [1], [2], [3], [4]. Radical solutions include a restriction either on the available data analysis operations from the analyzer perspective or an outsource of aggregate information instead of individual data. But this will degrade very much the accuracy on data analysis and also this method is not always feasible.

We analyze a well-known similarity detection algorithm, namely the cosine similarity and combine it with some obfus- cation mechanisms in order to achieve a privacy preserving similarity computation solution.

In this paper we present a privacy preserving protocol for similarity detection. Cosine similarity can recognize similar vectors based on the formed angle between the vectors.This new privacy preserving mechanism first maps users? data into vectors and applies some geometrical transformations that on the one hand preserve the angle between any pair of vectors and assures the confidentiality of the content of their coordinates. The accuracy of the proposed solution is then evaluated with the study on users? personality characteristics.

In section II we present related work in the area of privacy preserving data analysis. In III there is the problem description.

We give our solution in section IV and in section V we argue for the security of the scheme. The evaluation of solution with real world data is analyzed in VI.



II. RELATED WORK  We proceed into a taxonomy of previous solutions in the area of privacy preserving data analysis. We start with more generic solutions and we further describe previous work in the context of specific privacy preserving similarity detection algorithms for clustering.

Data perturbation Several techniques have been proposed in order to obfuscate data such that when users submit their data to the data analyzer individual data privacy is being protected but specific data mining algorithms can be applied on it.

Privacy preserving data mining by adding noise on data has been first proposed in [5], [6]. The solution has been proposed   DOI 10.1109/CGC.2013.92    DOI 10.1109/CGC.2013.92    DOI 10.1109/CGC.2013.92     for privacy preserving decision trees as a solution to derive association rules from databases. In [7] the authors proposed geometrical transformation for data clustering. Transformation though are data dependent and do not scale for multidimen- sional data.

Anonymization Data anonymization asks for unlinkability on data records and users. K-anonymity [8] has been proposed as a solution to protect the release of data to an untrusted party such that the personal private information for each data record cannot be distinguished from k?1 other users. Suppression and generalization are two techniques to achieve k-anonymity. By generalization [9] specific attributes are generalized in order to protect user anonymity. For instance instead of releasing the exact data of birth only the month and the year is released.

With suppression [10] no data is released. Solutions for data anonymity imply an information loss through out the described techniques and operation after the release of the data are inconsistent.

Data separation In [11] cryptographic tools are being used to protect user data privacy when the id3 tree is constructed for association rules. The id3 tree is a widely known technique for data classification. The categorical data of a set of records is being constructed by choosing the attributes than containing the higher information gain. Information gain is expressed as conditional entropy and the problem of id3 construction is approximated by finding the attributes that information gain is maximized. The authors assume that data are split horizontally, thus the data analyzer in order to compute the conditional entropy of two users should separately and privately obtain the data from both. It turns out that information gain for an attribute between two users is expressed as (u1+u2)?log(u1+ u2). The problem has been addressed as a secure multi-party computation of this expression for two users.

Privacy preserving data classification on horizontally par- titioned data has been addressed in [12], [13] as well. The solution is based on a privacy preserving protocol for sum computation based on randomization and privacy preserving union set computation. Those two functionalities can securely be used by an untrusted party to infer the global confidence of an attribute in order to infer the association rules that will classify the data. In [14] privacy preserving clustering on vertically partitioned data is addressed by submitting only the similarities on objects and not the real data. However how the users are computing the similarities while at the same time preserving their privacy is not clearly addressed. Vaidya et al. tackle this issue by constructing a protocol for secure dot product computation without the use of a trusted party.

However the communication cost for computing all the dot products between users is high [15]  Our Contributions As opposed to previous solutions we pro- pose a scheme that is data independent and assures higher level of privacy. Previous solutions that are based on geometrical transformations do not scale for multidimensional data [7] and also there is no concrete security analysis with respect to the leakages of the protocol for example. We did not tackle our similarity problem with respect to data anonymization as anonymization does not fully assure data confidentiality.

Moreover, data separation techniques in which data are split in between different sites are not always a real world scenario in which each user holds its data in its entire form.



III. PROBLEM STATEMENT  A. Similarity and privacy  We assume a set of n users. Each user Ui holds its personal sensitive private data Di. An untrusted data analyzer A seeks to obtain Di from each user Ui, where 0 ? i ? N . We consider each Di as a multidimensional vector of size m: Di = (d1, d2, d3, ? ? ? , dm). After the data collection, A is applying a similarity detection algorithm F over any pair of data vectors in order to identify similarities between them in order to further form clusters. During the detection of similarities in between data the privacy of users should not be compromised. As such we are looking for an obfuscation mechanism ? : Rm ? Rm such that for any two vectors x,y:  F(Di, Dj) = F(?(Di), ?(Dj)) where ? will preserve the privacy of individual data and at the same time similarity detection through cosine computation will be compatible.

B. Cosine similarity  Cosine similarity is a widely used distance metric for numerical data. Cosine similarity[16] depicts the geometrical similarity of two objects in an Euclidean space by measuring the angle ? formed by their vector representation in a n dimensional Euclidean space. The dot product < a ? b > of two vectors a,b is < a ? b >= ||a|| ? ||b|| cos ? , where ||a|| = ??ni=0 ai2 is the norm of vector a and ai denotes the coefficients of this vector. Thus,  cos ? = < a ? b > ||a|| ? ||b||  and the more similar the data the closer the angle between their corresponding vectors is and the closer to 1 their cosine.

The cosine similarity is our similarity detection function F .

C. Correctness and Privacy  Definition 1 (Privacy Preserving Data Analysis(PPDA)) In a Privacy preserving data analysis scheme a set of n users Ui are perturbating their data and afterwards the data are sent to the data analyzer A for analysis. PPDA consists of 2 polynomial time algorithms PPDA = Encrypt,Analyze:  Encrypt(Di) ? D?i: It takes as input user data and it outputs the encryption of it.

Analyze(D?i, D?j) ? F(D?i, D?j): It takes as input two encrypted data vectors and it outputs the result of a data analysis algorithm F(D?i, D?j).

Definition 2 (Correctness) A PPDA scheme is correct if for all pairwise combinations of data Di, Dj the analyzer executes Analyze(Encrypt(Di)) and it obtains F(D?i, D?j) = F(Di,Dj), Definition 3 (Confidentiality) Let ? = (Encrypt,Analyze) be a PPDA scheme. ? is defined as confidential if any adversary cannot recover Di from D?i  Intuitively, the security guarantee we require from a PPDA scheme is that given encrypted vectors D?i an adversary cannot learn any information about the plaintext Di although it may learn the outpu of the function F .



IV. SOLUTION  A. Idea of Solution  The idea of the solution is to apply some transformations to original vectors which on the one hand preserve the angle between any pair of them and on the other hand assure privacy. Since rotation in a two dimensional space preserves angles, we apply this transformation to two-dimension vectors named as sub-vectors which originate from the data vector.

Additionally, these sub-vectors are further randomly scaled and thus obfuscated while still not having an impact on the angle.

The reason why rotation and scaling are combined is that random scaling alone raises some security problems. Indeed, if only random scaling is applied then an adversary can discover whether the coordinates of that vector are similar or not.

Hence thanks to the rotation, the adversary cannot discover similarities between one vector?s coordinates. The mapping of vectors into subvectors also decreases the probability of discovering the original vector since the scaling factor differs from subvector to subvector.

B. Preliminaries  Vector scaling  Vector scaling with a scaling factor s is defined by a multiplication operation between the vector v and the identity matrix S in which the main diagonal has been substituted with the scale factor s.

v ? S = v? [ s 0 0 s  ]  Vector Rotation Vector rotation with an angle ? is defined by a matrix multiplication between the vector v and the rotation  matrix R?: v ?R = v? [ cos(?) ? sin(?) sin(?) cos(?)  ]  C. Protocol description  We now describe the details of the protocol with respect to Definition 1.

Encryption During the encryption phase each user Ui holds a vector Di = (d1, d2, d3, . . . , dm) of size m. It generates subvectors of 2 dimensions d(k,l)i =  ( dk dl  ) . If m is odd then  (m + 1)/2 are constructed, otherwise if m is even then we have m/2 subvectors. In general we have ?m/2? subvectors.

Afterwards each user choses a random scaling factor for each subvector and it scales each subvector d(k,l)i with the random scaling factor si: S  j i = s  j i ? d(k,l)i , if k and l are new  coefficients of the subvector. That is, if any of the coefficients of the subvector d(k,l)i has been previously selected to form a vector then the old random scale factor si must be used for d(k,l)i . Then the intermediate vector Si is further rotated with a rotation matrix R? , where ? is the rotation angle: d?k,li = S  j i ? R? = Sji ?  [ cos(?) ? sin(?) sin(?) cos(?)  ] .

In the end each user Ui sends D?i = (d?  (1,2) i , d?  (2,3) i , ? ? ? , d?(k,l)i ), ?k, l ? [0 ? ? ?m]s.t : ?{k, l}? = m  to the data analyzer A. In hereafter we will write dji to denote  the jth subvector of user Ui and d?ji for the jth encrypted subvector of user Ui. As such the obfuscated mechanism ? consists of random scalings and rotations by an angle ?: ?(di) = s  j i ? dk,li ? R?.

Analyze The analyzer then performs the similarity detection function F over the encrypted data: ?Ui,Uj , i 	= j :  F(d?i, d?j) =  ??? ??  cos(d?1,2i , d? 1,2 j )  ...

cos(d?  ?m/2? i , d?  ?m/2? j )  D. Correctness  Theorem 2 The PPDA scheme presented above is correct.

Proof: It is known that cos(a, b) = <a?b>?a???b? = aT ?b ?a???b? . For  the proof of the theorem we need to prove the following three lemmas:  Lemma 1 The transpose of an orthogonal matrix A, AT is equal to its inverse A?1  Proof: It is known that:  A ?A?1 = IA (1) where IA it?s the identity matrix of A. Also we obtain:  A ?AT =[ AT1,1 ?A1,1 ? ? ? AT1,m ?A1,m ATn,1 ?An,1 ? ? ? ATn,m ?An,m  ] =  ? ?? 1 ? ? ? 0 ...

...

...

0 ? ? ? 1  ? ?? = IA (2)  From (1), (2) we have that for any orthogonal matrix A, AT = A?1  Lemma 2 The multiplication two vectors a, b with a rotation matrix R preserves its cosine similarity.

Proof: cos(Ra,Rb) = <Ra?Rb>?Ra???Rb? = (Ra)T ?Rb ?Ra???Rb? =  aTRT ?Rb ?a???b? =  aTR?1?Rb ?Ra???Rb? =  aT ?b ?a???b? = cos(a, b) where  ?Ra?= [ cos(?) ? sin(?) sin(?) cos(?)  ] [ a1 a2  ] = ?a? and ?Rb?=[  cos(?) ? sin(?) sin(?) cos(?)  ] [ b1 b2  ] = ?b?  Lemma 3 The random scaling of two vectors a, b with different random scaling factors r1 and r2 preserves its cosine similarity  Proof: cos(r1a, r2b) = <r1a?r2b>?r1a???r2b? = (r1a)  T ?r2b r1?a??r2?b? =  r1a T ?r2b  r1?a??r2?b? = aT ?b ?a???b? = cos(a, b)  From lemma 1,2 and 3 we have that multiplication of a random vector and random scaling is a correct encryption mechanism. The proof of lemma 2 is based on lemma 1: the rotation matrix R is orthogonal and as such R?1 = RT .

Furthermore the rotation doesn?t change the vector norms.



V. SECURITY  Theorem 1 The PPDA scheme presented above is secure according to definition 3.

Proof: The security of the scheme is based on the ran- domness of the scale factor Si and on the rotation matrix R?.

The data analyzer cannot recover the original vector Di of a user U unless it performs brute force guesses for the scaling factor and the Rotation matrix.

We observe security leakages when the obfuscated mech- anism does not entail both random scalings and rotations.

If each user only selects random scaling as the encryption mechanism then an attacker by obtaining a good guess for a coefficient of a user?s vector it can recover the specific two dimensional vector by computing the inverse of the guessed element and multiplying it by the encrypted coefficient.

On the other hand, thanks to rotations the aforementioned problem is mitigated but the following one is appearing if used alone: if two users with secret vectors Di, Dj respectively have the same value at the same position of their vectors then only by encrypting with a rotation matrix R? of angle ? , the corresponding encrypted vectors would have the same value at this position. This violates the security definition 3. So in order for the cosine similarity to be securely preserved after the encryption of the vectors, both random scaling and rotations must by applied.

To be more precise with our security analysis, we consider two categories of adversaries: we define external adversaries as data analyzers and internal adversaries as users themselves.

External adversaries Data analyzers do not know the rotation matrix and as such the aforementioned attacks cannot happen as long as the angle ? of the rotation matrix is kept secret. The data analyzers cannot identify common values in a specific data vector because the rotation with an unknown angle adds an additional security level for the vectors.

Internal adversaries We consider as internal adversaries the users that know the rotation matrix R?. In such a scenario the user that has a good guess for the coefficient of another user can reveal only the coefficients that are involved in a common random scaling factor per vector. That is if Ui has 5 coefficients and it defines cosine similarity in between the ((1,2),(3,4),(1,5)) coefficients then an adversary with a good guess for the first coefficient can recover only the second and fifth coefficient and nothing more, since for the second subvector the user would choose different a random scaling factor.



VI. EVALUATION  We demonstrate the correctness of our protocol through an experimental evaluation setup. We obtain data originating from a personality experiment. We first cluster the data based on cosine similarity using a well known clustering algorithm.

The same clustering algorithm is further applied over the encryption of the same data using ? which as already described combines rotation and random scaling. We proceed into an analysis of the data and next on the clustering algorithms that we use.

A. Data Set  The dataset contains an extract of the results from the Foursquare Personality Experiment1 which uses the mobile so- cial network Foursquare2 combined with a standard personality test to allow the link between personality (as defined by the five-factor model [17]) and the places that people visit to be examined. To the best of our knowledge, this is the first time that it has been possible to correlate personality with place on such a granular level.

When accessing the experiment, users sign in using their Foursquare account, allowing us to access the list of venues which they have ?checked in? to on the Foursquare service.

We access only this list, storing the venues that the user has been to and the number of times they have visited each venue, but without accessing or storing the information about the individual checkins - we do not store when each visit to the venue occurred, nor the order in which venues were visited. Once users have accessed the system they then take a 44-item personality test [18], [19], revealing their five-factor personality scores. The five-factor model gives each person a score between 1 and 5 for each of the five personality traits: Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism.

The users participating in the study are a self-selecting group comprised of 173 people who both use Foursquare online location based tagging system and are willing to take part in a personality-based experiment.

B. Clustering  Clustering algorithms seek to group similar objects to- gether. Similarity is measured with a distance metric which in our case is cosine similarity. Hierarchical clustering is a widely known approach for clustering. It constructs a binary tree of clustering objects that successively are merged under the same cluster with respect to the linkage metric. The linkage metric links clusters and objects together. It acts as an intergroup similarity measure. Two most popular linkage metrics are the complete metric which defines the maximum similarity between two objects as a verification to whether or not one object would be merged under the same cluster with another one and the single metric in which the minimum similarity is treated as the intergroup similarity metric. At the first step of the algorithm each object belongs to each own cluster.

Then all the possible pairwise similarities between objects with respect to the defined distance metric are defined. Afterwards the algorithm iteratively merge clusters with respect to the linkage metric until there would be one cluster with the all the examined objects.

C. Simulation Setup and Results  We apply the hierarchical algorithm over the personality dataset with the complete linkage metric and based on cosine similarity.

The data consists of 173 different 5 dimensional vectors describing users? personality with respect to the 5 personality traits as previously described. We did not include venue  1http://www.cs.cf.ac.uk/recognition/foursqexp 2http://www.foursquare.com                          4 1        3 2              8 8              4 6     3 5                        3 7        6 9                               3 0                      4 4     0 3                  00.0  0.2  0.4  0.6  0.8  1.0  Plaintext data                      4 1        3 2              8 8              4 6     3 5                        3 7        6 9                               3 0                      4 4     0 3                  00.0  0.2  0.4  0.6  0.8  1.0  Encrypted data  Fig. 1. Hierarchical Clustering  visits frequency since we believe that personality traits are considered much more sensitive data compared to location information and that users would be more interested in hid- ing such information. We consider similarity on 3 subvec- tors per user data: the subvectors are constructed with the (1st, 2nd), (3rd, 4th) and (1st, 5th) coordinates of the original vector respectively. Any pairwise subvector could be have chosen such that the union of the set of subvectors entail all the coefficients. The main similarity metric is computed as the average of the similarities between subvectors.

In order to protect their privacy, every user chooses a random scaling factor per two dimensions. After the random scaling process users apply the rotation operation to their partially obfuscated subvectors.

In figure 1 we plot the two dendograms of hierarchical clustering before and after the operation ? applied on data. The horizontal axis corresponds to cluster indexes that are formed by the algorithm and the vertical axis to the linkage similarity based on cosines. Clusters are connected with upside-down U-shaped lines. The clusters are exactly the same due to the correctness of the algorithm as has been previously proved.

All the cosines between all the binomial coefficients of 2 over 173 elements has been computed. That results into a set of 14878 distances. For the linkage function we chose the complete option. Thus, two clusters will be merged together according to the maximum distance between their elements.

Results shown in figure 1 demonstrate the correctness of our protocol: Geometrical transformation on data based on random scaling and rotation is compatible with cosine similarity for clustering and in addition preserves individuals? privacy.

D. Discussion  In our experiments we use as a single point of similarity an aggregate output of each three per user similarities. This is the average of cosine similarities. As such during the clustering the similarity between points depicts similarities between the averages. We could have demonstrated three different scenarios during the clustering process one for each subvector in order to check the correctness of our obfuscation mechanism but since this has been demonstrated once the other experiments wouldn?t add extra knowledge to us. We also want to state that the aggregate function should not always be used for every case. This would imply an inconsistency on correctness since many inputs could evaluate the same average similarity.

Suppose for instance that data consist of user interests on m items and for each user n similarities per two dimensions are computed. Then a single aggregate function on user n similarities might group together during clustering dissimilar objects that average the same similarities but on different inputs.



VII. CONCLUSION  The interplay between data analysis and privacy is emerg- ing rapidly. Researchers from machine learning area have highlighted the merit of data analysis operations. However this exposure of personal sensitive data, facilitates privacy viola- tions. Adversaries by gaining access to personal information can learn the real identity of users and overcome data legal regulations and restrictions. That postulates a mechanism that would shield individual data confidentiality. This would not be of significant value since data encryption to protect data confidentiality is more mature and well analyzed than 30 years before. The tricky approach is to allow operations on data by the security mechanism while at the same time personal sensitive information is not exposure to third parties.

In this paper we have presented a mechanism for privacy preserving clustering that is based on geometrical transfor- mation of objects. Data are encrypted appropriately such that operations with respect to cosine similarity detection are compatible. We proceed into an analysis of the security risks of each operation and we conclude that the most secure way is a combination of random scalings and rotations. The rotation angle even if its known to the users it can only be used to reveal some coordinates of the vector only if the user has a good guess for one of the coordinates. Still this weakness is not of crucial importance for external adversaries (data analyzer) since they don?t know the rotation matrix. Without scaling and only with rotation, similarities on the same position coordinates are possible to occur by both internal and external adversaries.

This is mitigated by a random scaling factor, which is different per user and per subvectors with no common coefficients. We proceed into an experimental evaluation of a scheme in order to demonstrate its correctness. Personality traits have been obtained by 173 users and identical clustering results have been observed before and after the obfuscation proposed solution.

Acknowledgement This research has been funded by RECOGNITION grant 257756, an EC - FP7 Future Emerging Technologies project concerning Self-Awareness in Autonomic Systems.

