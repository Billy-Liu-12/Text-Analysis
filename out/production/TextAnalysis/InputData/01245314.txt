

Mining Sequential Patterns Using Graph Search Techniques *  Yin-Fu Huang and Shao-Yuan Lin  Institute of Electronic and Information Engineering National Yunlin University of Science and Technology  huangyf@el.yuntech.edu.tw  * This work was supported by National Science Council of R.O.C. under  Grant NSC91-2213-E-224-017  Absrtact  Sequential patterns discovery has emerged as an  important problem in data mining. In this paper, we propose an effective GST algorithm for mining sequential  patterns in a large transaction database. Different from the Apriori-like algorithms, the GST algorithm can out of  order find large k-sequences (k >= 3); i.e., we can find large k-sequences not directly through large  (k-1)-sequences. This leads to that our algorithm has much better performance than the Apriori-like algorithms.

Besides, we also propose the method to find new sequential patterns by scanning only new transactions  since the database was increased. Through several comprehensive experiments, the GST algorithm gains a  significant performance improvement over the Apriori-like algorithms. Also we found as long as the ratio of the items  purchased in new transactions is not close to 100%, scanning only new transactions is always much better than  scanning the entire database.

1. Introduction  Recently data mining has been recognized as a new area  and been growing at a rapid pace. It extracts desirable  knowledge with useful patterns for some purposes from the  existing large databases. Due to the rapid growth in the size  and number of databases, the new techniques of data mining  is urgently requested and developed in the recent years. Data  mining is a very application-dependent issue and different  applications might require different mining techniques to deal  with. Especially, data mining has high applicability in retail  organizations that collect and store mass amounts of sales data.

Analysis of mass amounts of sales data can provide very  valuable information on customer purchasing behaviors with  which we can improve the quality of business decisions, such  as catalog design, store layout, customer segmentation, cross  marketing strategies across products, effectiveness of  promotional campaigns, shed light on more effective  management of workgroup communication and organization  infrastructure, and so on.

Many kinds of knowledge could be mined from a database,  such as association rules [1, 5, 6, 8, 10, 12], sequential patterns  [2, 3, 7, 11], and et al. The association rules show that  attribute-value conditions occur frequently together in a given  set of data. For example, when customers purchase some items,  how will they tend to purchase some other items too? The  sequential patterns proposed by R. Agrawal and R. Srikant [2]  are another useful knowledge that refer to frequently occurring  patterns related to time or other sequences. For example, a  customer who bought the book ?The basic C language? six  months ago is likely to buy the book ?The reference dictionary  of C language? next month. Thus the major difference between  association rules and sequential patterns is the temporal  relationship; i.e., temporal relationships do not exist in  association rules, but exist in sequential patterns. In this paper,  we will focus on how to find sequential patterns.

Most of the previous researches such as AprioriAll and  AprioriSome [2], DSG algorithm [11], fuzzy algorithm [7],  and the algorithm mining path traversal patterns [3], adopted  an Apriori-like method to find sequential patterns. However,  it is very costly to generate candidate sets since it tediously and  repeatedly scans the database. Many discussions have shown  that the bottleneck of the Apriori-like method is the generation  of candidate sets and the scan of the database. Rather than  generating a huge set of candidates and re-scanning the  database, must improve the performance of mining sequential  patterns, we propose a novel algorithm using graph search  techniques (GST) to find sequential patterns. The GST  algorithm can out of order find large k-sequences (k >= 3); i.e., we can find large k-sequences not directly through large  (k-1)-sequences. This leads to that our algorithm has much  Proceedings of the 27th Annual International Computer Software and Applications Conference (COMPSAC?03)    better performance than the Apriori-like algorithm [2, 11].

Besides the GST algorithm is very suitable for mining new  sequential patterns since the database was increased. We  merely process those new transactions occurring after mining  to find out new sequential patterns.

The remainder of the paper is organized as follows. In  Section 2, the mining problem for sequential patterns is  defined. We propose a GST algorithm using graph search  techniques to find sequential patterns in Section 3. In Section  4, several experiments are undertaken and the results show the  superiority of the GST algorithm over the Apriori-like  algorithm. Finally, we make a conclusion in Section 5.

2. Problem descriptions  The problem of discovering sequential patterns is to find  inter-transaction patterns such that the presence of a set of  items is followed by another item in the time-stamp ordered  transaction set. Let {i1, i2, i3 , ?, im} be an itemset i where an  itemset is a non-empty set of items and ik is an item. A sequence s is denoted as <s1, s2, s3, ?, sn> where s is an order list of  itemsets and sj is an itemset whose items are purchased by a customer at the same transaction-time. For an item ik, it can  appear only once in sj, but can appear multiple times in si and sj with different transaction-time. A sequence s is maximal if  s is not contained in any other sequence. A sequence <a1, a2, a3, ?, an> is contained in another sequence <b1, b2, b3, ?,  bm> if there exist integers i1 < i2 < ? in, 1 ik m, such that  a1 bi1, a2 bi2, ?, an bin. For example, sequence <(A), (BC)> is contained in sequence <(A), (BC), (D)>, but  sequence <(A), (B), (C)> is not since B and C must be bought  together. Sequence <(A), (D)> is also contained in sequence  <(A), (BC), (D)>, even though there exists an itemset (BC)  between (A) and (D). A sequence with k items is called a  k-sequence, and it may have three types, such as ordered, non-ordered, and hybrid. For example, <(A), (B)> is a  2-sequence of ordered, <(AB)> a 2-sequence of non-ordered,  and <(AB), (C)> a 3-sequence of hybrid. Besides we do not  consider the relative order of the items in an itemset; we  pre-sorted them alphabetically. All the transactions of a  customer, ordered by increasing transaction-time, is a  customer-sequence. The support count for a  customer-sequence is defined as the fraction of total customers  who support this sequence. Each sequence satisfying a certain  minimum support threshold (user-specified) is called a large  sequence.

Given a transaction database D and a minimum support  threshold , we can define the problem of mining sequential  patterns as finding the maximal large sequences among all the  sequences with support count greater than or equal to . Each  found maximal large sequence represents a sequential pattern.

In addition, we will consider time constraints when finding  sequential patterns, and this makes the found sequence  patterns more useful. Finally, we also propose the method to  find new sequential patterns by scanning only new  transactions since the database was increased.

1. When time constraints are considered: If a sequential  pattern is found, but the time interval of sequential pattern may  be so long, for example over one month, the information will  be not so useful. Most previous researches did not consider the  time interval, so they could find some garbage information.

Thus in our paper we take care of time constraints when finding  the sequential patterns. Time constraints restrict the time  interval among a set of transactions for a custom. Given the  specified maximal interval, a sequence s = <s1, s2, ?, sn> is  hold for a customer sequence d = <d1, d2, ?, dm> where n  m such that  (a) s is the subsequence of d, and (b) transaction-time(si) ? transaction-time(si-1)  max-interval where 1 i n.

For the transaction database shown in Figure 1, a sequence  <(C), (I)> exists in customer 1 and customer 4. If max-interval  = 10 (days) are given, respectively, then the time interval of  the sequence in customer 4 is greater than max-interval, we  will prune the sequence from customer 4.

Customer  ID Transaction  Time  Items  Bought     1/25  1/30  3/1  C  I  A, B     1/10  1/15  1/20  A, B  C  D, F, G     1/25  1/30  2/25  C, G  F  E      1/25  1/30  2/25  2/28  C  D, F, G  I  A, B     1/12  3/2  3/3  I  A  B  Figure 1. The transaction database  2. Since the database was increased: Since the size of  the database can be huge, if we scan the database to find new  sequential patterns each time when the database is increased,  it will be costly. Thus the key issue to improve the performance  of finding new sequential patterns is to just scan the new  transactions since last time, instead of scanning the entire  database once more. Doing so, we not only reduce the times  to scan the database, but also reduce the size of data required  to process.

Proceedings of the 27th Annual International Computer Software and Applications Conference (COMPSAC?03)    3. Mining sequential patterns  3.1. The GST algorithm  In the section, we propose a novel algorithm using graph  search techniques (GST) to find sequential patterns. At first,  it finds large 2-sequences (L2), and then employs L2 to  construct the item relation graph (IRG). Afterwards, through  searching the graph, we can find all other large k-sequences  (k >= 3) since the relation information about items are all in the graph. Different from the Apriori-like algorithms, it can  out of order find large k-sequences (k >= 3); i.e., we can find large k-sequences not directly through large (k-1)-sequences.

This leads to that our algorithm has much better performance  than the Apriori-like algorithms. The GST algorithm has four  phases to mine the sequential patterns as follows:  1. Scan the database to produce large 1-sequences  (L1): First we scan the database to construct table C1 that will  be also used in the postprocessinng discussed in Section 3.2.

The only one scan throughout the database in our algorithm  is executed here. For each 1-sequence in table C1, calculate its support count. If its support count is greater than or equal to  the minimum support, we insert it into L1; otherwise discard it. The associated structure of C1 and L1 is shown in Figure 2.

Item CID Time  Figure 2. The structure of C1 and L1  2. Join L1 with itself to produce large 2-sequences (L2):  Then we join L1 with itself by CID and Time to produce L2.

The join performed here can be classified into two types. The  first type is denoted as (AB) such that item A and B are  purchased by the same CID at the same Time. The second type  is denoted as (A)(B) such that item A and B are purchased by  the same CID, but item A occurs before item B. For example,  if we have three large 1-sequences A, B, and C, after the join  we can generate 2-sequences such as (A)(B), (AB), (A)(C),  (AC), (B)(A), (B)(C), (BC), (C)(A), and (C)(B), as shown in  Figure 3. Then calculate their support counts and discard the  sequences with the support counts less than the minimum  support. The associated structure of L2 is shown in Figure 4.

In this phase, we also check time constraints that prune the  sequences with long time interval. The procedure in term of  SQL statements can be specified as follows:  INSERT INTO L2 SELECT (p.Item, q.Item), p.CID, p.Time, q.Time FROM L1  p, L1  q  WHERE p.CID = q.CID AND p.Time = q.Time  AND p.Item < q.Item UNION  SELECT ((p.Item), (q.Item)), p.CID, p.Time, q.Time FROM L1  p, L1  q  WHERE p.CID = q.CID AND p.Time < q.Time  AND (q.Time ? p.Time  max-interval)  Next, discard all 2-sequences with the support counts less than  the minimum support. The corresponding SQL is specified as  follows:  DELETE * FROM L2 WHERE Sequence NOT IN  (SELECT Sequence FROM L2 GROUP BY Sequence  HAVING COUNT(*)  the minimum support)  A B C  (A)(B) (AB) (AC)(A)(C) (BC)(B)(C)(B)(A) (C)(A) (C)(B)  Figure 3. Join results  Sequence CID STime ETime  Figure 4. The structure of L2  3. Construct an IRG (Item Relation Graph): Next, we  use table L2 to construct an IRG as follows. The nodes in an  IRG are the items appearing in the 2-sequence in table L2. The two different edge types in an IRG represent different  relationships between the items. If a 2-sequence is equal to  <(A)(B)>, we draw the directional edge from A to B, such as  A B. If a 2-sequence is equal to <(AB)>, we draw the dotted  edge between A and B, such as A-- B. Besides, an edge is  labeled with a group of associating (CID, STime, ETime)'s.

An IRG example and the structure of an IRG edge are shown  in Figure 5 and Figure 6, respectively. The procedure to  construct an IRG is described as follows where two functions  can be applied to the 2-sequences in table L2; i.e.,  Tail(Sequence) returns the last item appearing in the Sequence,  and Type(Sequence) the edge type.

For each distinct large 2-sequence l2 L2 Create a new edge e for l2  such that e.To_vertex = Tail(l2.Sequence), e.Edge_type = Type(l2.Sequence), and  e.(CID, STime, ETime)'s = (l2.CID, l2.STime, l2.ETime)'s;  A  B  C  Proceedings of the 27th Annual International Computer Software and Applications Conference (COMPSAC?03)    Figure 5. An IRG with (AB), (A)(C), and (B)(C)  To_vertex Edge_type (CID, STime, ETime)'s  Figure 6. The structure of an IRG edge  4. Search the IRG to produce the large sequences and  sequential patterns: For each vertex in the IRG, we search  all the large sequences rooted from it, and then find the  maximal large sequences. When going forward, we check the  concatenation conditions of neighboring edges as well. In  other words, following an edge e to the next edge w, we  compare their CIDs, STime, and ETime. If e.CID is equal to w.CID, e.ETime is equal to w.STime, and the support count  the minimum support, then we go forward; otherwise, go  back. Thus, each path is a large n-sequence if n vertices are  successfully visited. The procedure to search the IRG is  described as follows:  1. LS = ; /* initialize the set of large sequences and one  working stack  LS_Stack = ;  2. For each vertex v in the IRG  Push v to LS_Stack;  Search_Sequence(v, );  3. Find the maximal large sequences from LS;  Search_Sequence(v, result) {  /* ever_output: local variable indicating whether a  distinct path ending at v is got */  ever_output = no;  For each outgoing edge e from v  If (result = )  result = e.(CID, STime, ETime)'s; else result = { (cid, stime, etime) |  cid=result.CID=e.CID  stime=result.STime  result.ETime=e.Stime  etime=e.ETime};  If (count(result)  the minimum support)  Push e.To_vertex to LS_Stack; ever_output = yes;  Search_Sequence(e.To_vertex, result); else If (ever_output = no)  ever_output = yes;  Copy the path in LS_Stack to LS;  If (ever_output = no)  Copy the path in LS_Stack to LS;  Pop one vertex from LS_Stack;  }  3.2. Postprocessing since the database was  increased  If the database is increased after mining, we do not need  to re-scan the database to find all the sequential patterns. We  merely process those new transactions occurring after mining  to find out new sequential patterns. The procedure works as  follows:  1. Insert all new transactions into C1.

2. For each item i purchased by new transactions  If its support count  the minimum support  Search all the customers who ever purchased  i from C1, and then insert the transactions made by those customers into another partial  table C1; 3. For each item i in the partial table C1  If its support count  the minimum support  prune i to get the partial table L1; 4. Do the same procedure from phase 2 to phase 4;  4. Performance evaluations  4.1. Simulation model  To evaluate the performance of the GST algorithm, we  undertake several experiments on a PC with AMD Athlon  750MHz, 128M PC-133 SDRAM, 40G IBM HD (Ultra 100)  to compare the GST algorithm with the Apriori algorithm and  the DSG algorithm. The generation of the synthetic data in the  transaction database is based on a normal distribution; i.e., the  purchases made by customers are concentrated on some items.

In these experiments, we have 1000 items to be purchased by  customers, and use the notations C for average number of  transactions per customer, T for average number of items per  transaction, and D for number of transactions. For example,  the experiment labeled with C10.T5.D6000 represents the  simulation environment with 10 transactions on the average  per customer, 5 items on the average per transaction, and 6000  transactions in total.

4.2. Experimental results  Experiment 1: In the experiment, we explore the execution  time of the Apriori algorithm, the DSG algorithm, and the GST  algorithm under different simulation environments and  minimum supports, as shown in Figure 7. As a result, we found  that the GST algorithm always reveals its superiority over the  other two algorithms, regardless of what simulation  environment. The inefficiency of the Apriori algorithm is  resulted from generating candidate itemsets and checking  whether they are really large itemsets each pass, especially  when there are a huge amount of candidate 2-itemsets  generated in the second pass. Although the DSG algorithm,  like the Apriori algorithm, generates large itemsets  step-by-step, it uses the association graph to find large  sequences directly, instead of generating candidate sequences.

Thus the DSG algorithm outperforms the Apriori algorithm.

Proceedings of the 27th Annual International Computer Software and Applications Conference (COMPSAC?03)    Besides we observed that the GST algorithm is less sensitive  to the variance of the minimum support under the  environments of more data, such as C10.T10.D6000 and  C10.T5.D6000. Finally, we also found that the curves of all  three algorithms become smooth for the lower minimum  support under the environments of less data, such as  C10.T2.D6000 and C5.T5.D6000. The reason is that the  number of generated candidate sequences is always not  beyond some threshold.

15 12.5 10 7.5 5  minimum support (%)  ex ec  u ti  o n  t im  e (s  ec o  n d  )  Apriori  DSG  GST  Figure 7.(a) The environment C10.T10.D6000         15 12.5 10 7.5 5  minimum support (%)  ex ec  ut io  n tim  e (s  ec on  d)  Apriori  DSG  GST  Figure 7.(b) The environment C10.T5.D6000    15 12.5 10 7.5 5  minimum support (%)  ex ec  u ti  o n  t im  e (s  ec o  n d  )  Apriori  DSG  GST  Figure 7.(c) The environment C10.T2.D6000       15 12.5 10 7.5 5  minimum support (%)  e x  e c u  ti o  n t  im e (  se c o  n d  )  Apriori  DSG GST  Figure 7.(d) The environment C5.T5.D6000  Experiment 2: In the experiment, we explore the scalability  of the GST algorithm under different simulation environments,  as shown in Figure 8. Here the number of transactions is varied  from 60000 to 350000 and the minimum support = 10%. When  the number of transactions (or the average number of items  per transaction) increases, the execution time increases as  well.

1 0 0  2 0 0  3 0 0  4 0 0  5 0 0  6 0 0  7 0 0            n u m b e r  o f  t ra n s a c t io n s  ex ec  u ti  o n  t im  e (m  in u  te ) C 1 0 . T 5  C 1 0 . T 2  C 5 . T 5  Figure 8. The scalability of the GST algorithm  Experiment 3: In the experiment, we explore the execution  time of the same GST algorithm under different scanning  methods since the database was increased, as shown in Figure  9; i.e., scanning only new transactions and the entire database.

Here the experiment is under the environment C10.T5.D6000  and the minimum support = 5%. As shown in Figure 9.(a), the  rates of the items purchased in the new transactions (i.e., total  items purchased in the new transactions over total items ever  purchased in the original database) are varied with 0%, 20%,  40%, 60%, 80%, and 100%. Here we found as long as the ratio  is not close to 100%, scanning only new transactions is always  much better than scanning the entire database. Besides, as  shown in Figure 9.(b), the rate of the items purchased in the  new transactions is fixed at 50% and the growth rates of the  transactions are varied with 25%, 50%, 75%, and 100%. We  found that scanning only new transactions is still better than  scanning the entire database.

Proceedings of the 27th Annual International Computer Software and Applications Conference (COMPSAC?03)         0 20 40 60 80 100  rates of purchased items (%)  ex ec  u ti  o n t  im e  (s ec  o n d )  scanning the entire database scanning new transactions  Figure 9.(a) Postprocessing with the rates of purchased items      25 50 75 100  growth rates of transactions (%)  e x  e c u  ti o  n t  im e  (s e c o  n d  )  Scanning the entire database Scanning new transactions  Figure 9.(b) Postprocessing with the growth rates of transactions  5. Conclusions and future works  In the paper, we propose the GST algorithm to find  sequential patterns from a transaction database. Through the  experiments, we find that the GST algorithm is superior to the  Apriori-like algorithms. The advantage of the GST algorithm  over the Apriori-like algorithms is that it can 1) generate large  sequences without constructing candidate sequences and 2)  generate large k-sequences without following from large  (k-1)-sequences step-by-step. Besides, we consider time constraints as well when finding sequential patterns, and this  makes the found sequence patterns more useful. Finally, we  also propose the method to find new sequential patterns by  scanning only new transactions since the database was  increased, and compare it with the rough method of scanning  the entire database.

In the GST algorithm, we search the IRG to find the large  sequences rooted from each node. Since some redundant paths  might be generated, the GST algorithm can be tried to avoid  the sub-path generation when a path is found. Besides, in the  future, we shall extend our algorithm to Web usage mining to  mine the Web access logs [4, 9], which can be used to predict  user visit patterns and then help in targeting the advertisements  at groups of users based on these patterns.

6. References  [1] R. Agrawal and R. Srikant, ?Fast algorithms for mining   Data Bases, 1994, pp. 487-499.

[2] R. Agrawal and R. Srikant, ?Mining sequential patterns,? Proc.

[3] Ming-Syan Chen, Jong-Soo Park, and P. S. Yu, ?Efficient data   Knowledge and Data Engineering, Vol. 10, No. 2, 1998, pp. 209-221.

