<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Data Mining  Application for Predictive Learning from Visiting Nurse

Abstract - In the following paper the process of knowledge generation from the Visiting Nurse Association database for elderly care is explored. This inquiry is concerned with predicting falls. Predicting which patients are likely to fall can assist the clinician in the identification of high-risk patients and suggest the need for early falls prevention programs. The entire data mining process is described beginning with data gathering followed by cleaning, aggregation, and integration. Issues faced while conducting the research are discussed Results of decision trees and decision rules, and artificial neural networks used to predict falls are presented Keywords - falls, community, gerontology, fall prevention, predictive data mining, and health informatics.

1. Introduction Knowledge Discovery and Data mining (KDD) is a rapidly growing interdisciplinary field which merges together database management, statistics, machine learning and related areas the ultimate goal of which is to extract useful knowledge from large data sets in order to improve clinical outcomes. Knowledge discovery in databases is the process of identifying valid, novel, potentially useful, and ultimately understandable patterns/models in data. Data mining is a step in the knowledge discovery process consisting of developing particular data mining algorithms that, under some acceptable computational efficiency limitations, finds patterns or models in data. In other words, the goal of knowledge discovery and data mining is to find clinical relevant patterns and/or models that exist in databases but are hidden among the volumes of data.

Data comprises a set of facts F (e.g., cases in a database).

. Pattern is an expression E in some language L describing a subset FE of the data F (or a model applicable to that subset). The term pattern goes beyond its traditional sense to include models or 1. CECS Department - Speed School of Engineering 2. Nursing Research - School of Nursing structure in data (relations between facts), e.g., "If (IF Medicationsscore EQUALS 5) and (Ambulationscore EQUALS 4) and (4.5 LESS THAN OR EQUALS SafetyScore LESS THAN 9) and (LevelScore EQUALS 4) Then (Prediction EQUALS Fallers)".

. Process: Usually in KDD process is a multi-step process, which involves data preparation, search for patterns, knowledge evaluation, and refinement involving iteration after modification. The process is assumed to be non-trivial, that is, to have some degree of search autonomy.

. Validity: The discovered patterns should be valid on new data with some degree of certainty. A measure of certainty is a function C mapping expressions in L to a partially or totally ordered measurement space Me.

An expression E in L about a subset FE of set F can be assigned a certainty measure c = C(E, F).

Novel: The patterns are novel (at least to the system). Novelty can be measured with respect to changes in data (by comparing current values to previous or expected values) or knowledge (how a new finding is related to old ones). In general, we assume this can be measured by a function N(E, F), which can    this can be measured by a function N(E, F), which can be a Boolean function or a measure of degree of novelty or unexpectedness.

Potentially Useful: The patterns should potentially lead to some useful actions, as measured by some utility function. Such a function U maps expressions in L to a partially or totally ordered measure space Mu: hence, u = U(E, F) Ultimately Understandable: A goal of KDD is to make patterns understandable to humans in order to facilitate a better understanding of the underlying data.

While this is difficult to measure precisely, one frequent substitute is the simplicity measure. Several measures of simplicity exist, and they range from the purely syntactic (e.g., the size of a pattern in bits) to the semantic (e.g., easy for humans to comprehend in some setting). We assume this is measured, if possible, by a function S mapping expressions E in L to a partially or totally ordered measure space Ms: hence, s =S(E,F).

Typical problems that data mining addresses are how to classify data, cluster data, find associations between data items, and perform time series analysis.

Numerous data mining techniques have been invented for each type of problem [1,2]. Each problem requires data mining techniques to analyze large quantities of data. Knowledge discovery in databases using data mining techniques is an approach to extracting patterns from large data sets and deducing knowledge insights from those patterns [2]. This knowledge discovery process has several distinct steps or sub processes that begin with data gathering, followed by data cleaning, then aggregation and integration. At this point the data is ready to be utilized for data visualization and finally data mining. Rather than being sequential, sub? processes in the data mining process are iterative i.e.

movement from data visualization back to data cleaning if irregularities are discovered in the data set [2,3].

2. Knowledge Discovery in Databases With the advent and proliferation of on-line data collection, truly massive databases are now available to health care researchers. In that situation, data? mining methods yield some unique opportunities to researchers who wish to develop prediction models and to establish associations [13]. Data mining and knowledge discovery in Databases relate to the process of extracting valid, previously unknown and potentially useful patterns and information from raw data in large databases. "The analogy of "mining" suggests the sifting through of large amounts of low grade ore (data) to find something valuable. It is a multi- step, iterative inductive process [3]. It includes such tasks as problem analysis, data extraction, data preparation and cleaning, data reduction, rule development, output analysis and review. Generally, data mining and knowledge discovery in databases are treated as synonyms and refer to the whole process in moving from data to knowledge [2]. A small number of published studies address the value of data mining  within the healthcare industry (see [1] for a survey).

Other popular data mining techniques applied to healthcare are Bayesian models, association rules, case-based reasoning, genetic algorithms, and fuzzy systems (see [1,2] for applications).

For the purpose of this study, the knowledge Discovery process is viewed in multiple stages.

Ramaprasad's [3] staged model that consisted of data acquisition, integration, mining, and revisions of requirements is expanded to a model that consists of the following: acquisition, validation, aggregation and    the following: acquisition, validation, aggregation and integration, visualization, mining, and revision of objectives (see figure 1). A knowledge discovery assignment must begin with clear objectives in mind.

These objectives will not be in the form of preconceived hypothesis, but must state clearly the scope of the study and potential goals. The process begins with data gathering in which relevant data is sought after for analysis, followed by cleaning and validation. Next disparate data sources will need to be aggregated and visualized to gain preliminary insights.

Following this we apply algorithms to mine the data and extract or deduce relevant patterns - knowledge.

At each stage of the data mining process questions and goals may be revised.

Figure 1: Stage Model for Knowledge Discovery in Databases 3. Problem Definition Clinical databases have accumulated large quantities of information about patients and their medical conditions. The healthcare field faces strong pressures to reduce costs while increasing quality of services delivered [5,6,7,8,9,10]. Storing patient's records in electronic format and the development in medical-information systems cause a large amount of clinical data to be available online [4]. Relationships and patterns within this data could provide new medical knowledge. Unfortunately, few methodologies have been developed and applied to discover this hidden knowledge. In this study, the techniques of data mining (also known as Knowledge Discovery in Databases) were used to search for relationships in a large clinical database [12]. Predictive modeling is a fundamental data-mining task. It's an approach that reads training data composed of multiple input variables and a target variable. It then builds a model that attempts to predict the target on the basis of the inputs. After this model is developed, it can be applied to new data that is similar to the training data, but which doesn't contain the target. If the model is successful it will predict the values of the missing target from the values of the new inputs [15].

Falls are a significant cause of morbidity and mortality among the older adult population. In community-dwelling individuals age 65 and older, approximately one-third fall every year (King and Tinetti, 1995). Although less than one fall in 10 results in a fracture, a fifth of fall incidents require medical attention [11]. Older adults who experience an injury as a result of a fall substantially increase their risk of death in the 12 months following the fall. A number of investigators have identified risk factors for falls among the older adult population. Many preventive intervention programs based on these risk factors have been established and evaluated. These have included exercise program designed to improve strength or balance, education programs, medication optimization, environmental modification in homes or institutions and nutritional or hormonal supplementation [11]: Risk factors have been grouped into individual characteristics including polypharamacy, difficulty with ambulation and performing functional tasks, poor vision, declines in muscle strength and postural control and increasing numbers of co-morbidities [18]. Risk factors for a fall have also been categorized into environmental factors including a poorly lit cluttered environment, reduced social support and living alone.

Each of these risk factors in isolation has been shown to be significantly associated with increased falls/injury risk among older people. However, individuals with multiple falls risk factors have an increased rate of falls compared to individuals with    increased rate of falls compared to individuals with one falls risk factor [14]. Several studies have been performed to predict falls but no investigator has yet examined predictors of falls among community dwelling older adults who are under the care of the VNA [17]. This population exhibits a number of the previously mentioned risk factors for falls and experience a disproportionate frequency of falls compared to age matched community dwelling adults not being cared for by the VNA.

The purpose of the study was to discriminate individuals being cared for by the Visiting Nurse Association (VNA) who are age 65 or older who have experienced a fall within the previous months (Fallers) from individuals being cared for by the Visiting Nurse Association (VNA) who are age 65 or older who have not experienced a fall (Non Fallers). In this study, the techniques of data mining (also known as Knowledge Discovery in Databases) were used to distinguish fallers from non-fallers by using data from a large clinical database. Specifically, data accumulated on 63,000 VNA patients were evaluated for factors potentially contributing to differences between fallers and non-fallers using decision trees and decision rules, artificial neural network. This paper describes the processes involved in mining a clinical database including data warehousing, data query and cleaning, and data analysis.

Research Question ? Does the Fall Risk Screening Tool predict falls among VNA patients who are age 65 and older?

4. Methodology Records were identified from 63,000 VNA patient visits records obtained during the 12 months of 2003.

To be included in the target for the study the individual must have received ongoing VNA care during 2003, be age 65 and older and community dwelling. Individuals were excluded from the study if their VNA record indicated they did not ambulate. This sample was then dichotomized into two groups, Fallers and Non? fallers. 146 Fallers were identified from this group and included those individuals in the target who had at least one fall documented on their VNA patient record.

These individual Fallers were matched by age, gender, admission date and zip code with 1847 individuals in the target who had no documented fall on their VNA record. A random sample (arithmetic mean = 12) of 146 individuals was then drawn from this group of Non-fallers. This methodology resulted in 146 Fallers and 146 Non-fallers being identified for the study.

Data for the Fallers were extracted from an incident report describing the fall and information collected during the most recent VNA visit with the patient prior to the fall. Data for the Non-fallers were collected from their most recent VNA visit. Data collected during the VNA visit included demographic information as well as information documented on a fall risk-screening tool. This tool assessed level of consciousness, history of falls, ambulation capacity, vision status, medication and safety and environmental hazards. These variables acted as the inputs i.e. the predictor variables and the target (response variable) was a binary variable which classified patients into the category of Fallers and Non-Fallers.

5. Results and Discussion Two data mining techniques were employed to determine the optimal model in discriminating Fallers from Non-fallers including Decision Trees and Decision Rules and Artificial Neural Network. The statistical tool employed for this study was SAS Enterprise Miner. Based on SAS software, Enterprise    Enterprise Miner. Based on SAS software, Enterprise Miner combines the data mining process with graphical ease of use. In order to build an effective model, Enterprise Miner does not process all the data at once. It divides the data into three subsets of training, validation and testing. The training subset is used for preliminary model fitting; the validation subset is used to tune model weights during estimation; the test subset is used for model assessment [15]. The Data Partition Node provides several options to partition data.

For this data it partitioned with a percentage of 75, 15 &amp; 10 into Training, Validation and test and the method used was Simple Random. Method gives a choice of three data partition methods. Simple Random method relies on a random seed which can be used to duplicate the partitions. Stratified enables us to select the strata. User Defined enables us to specify the variables that defme the partitions. The target value was binary, either category 0- Fallers or Category 1- Non-Fallers. The target can have any of the four values: Binary, Nominal, ordinal and Interval. The first three have there missing values replaced with the most commonly occurring level. Interval variables have there missing values replaced with the mean of the sample.

Decision Tree used Entropy Reduction as the splitting criteria with mmlmum number of observations in a leaf as 1 and maximum depth of tree as 6. Entropy reduction performs measures of nude impurity. Missing values were treated as unacceptable and the measure used for model assessment was Proportion correctly classified. For assessment of the model validation data set was used. The Decision Tree method generated a model with 70% sensitivity, 70.83% specificity using medication, history, and safety and environmental hazards. The decision tree states that "IF SafetyScore IS LESS THAN 2.068627451 AND Medicationsscore EQUALS 5 THEN patients belong to the category of Fallers". A sample of the diagnostic chart (Figure 2.a) and the decision tree (Figure 2.b) using SAS Enterprise Miner demonstrates visually the sensitivity versus specificity of the dataset mining results. Decision Tree summary is illustrated in tabular format (Figure 2.c). The sub?  tree has the best classification rate for the validation data. The decision tree rules (Figure 2.d) classify the patients into category 0 with a percentage of 100.

Category 0 belongs to Fallers.

T arge!=CATEGORY Mod.1 Name=T &lt;Be Pelcent Actual T (lfget Pr?dicted T .3rget Percent---------------, 291651;66657 7O.B33333333 Figure 2a: Diaguostic Chart for Decision Tree Figure 2.b: Decision Tree /a 27 105 TRAIN N 52 62 114 TfltilH N ? llJ ffi 219    TfltilH N ? llJ ffi 219 TRAlIl Rt&gt;;\&lt;% I) i'* ':&amp;; 100 mAitl Rt&gt;;\&lt;}; 4'b ? 100 TRAIH RQ\?:? ? ? 41 100 TRt!JJH C$'&gt;;; 0 WJ 11 48 1RA1tl C11\'&gt;;; 4jJ 70 52 TflAlti [:$,%: ? roo 11)) lt11:l tRAJN 0 :is liB TRAIN 24 2e ?2 1RA1tl % ? 59 4' ? 100 \{?J..ID ?? 0 14 S 2IJ \0.lID tl 17 24 \0.lID N 21 lJ 44 \(.!;u? Ro\'?% I) 70 ;II 100 '(?J..ID RI);I'% 29 71 100 ,(AUD RI);'14 4B 52 100 ?:4iID Ce\\: 0 ?l lJ ?5 ,(,;UD C{)1'&gt;;; 33 74 S5 \(&gt;\UD Cill';%: 100 100 100 \i:?J..ID 0 32 14 45 ?:4iID ?" 1? ,:{3 55 \':AtID '&gt;, ,'* + 43 52 100 Figure 2.c: Summary of Decision Tree IF Historyscore EQUALS 6 AND Medicationsscore IS ONE OF: 2 3 4 THEN NODE: N: 0: 1: 78,6% 21.4% IF SafetyScore &lt; 2,068627451 AND Medicationsscore EQUALS 5 THEN NODE: 6 N: 6 0: 100.0%  1: 0.0% IF Medicationsscore IS ONE OF: 2 3 AND Historyscore EQUALS 2 THEN NODE: N: 0: 1: 31.0% 69.0% IF 2.068627451 &lt;= SafetyScore &lt; 4.068627451 AND Medicationsscore EQUALS 5 THEN NODE: N: 0: 1 : 25.0% 75.0% IF 4.068627451 &lt;= SafetyScore AND Medicationsscore EQUALS 5 THEN NODE: N: 0: 1 : IF SafetyScore &lt; 1.5    76.9% 23.1% AND Medicationsscore EQUALS 4 AND Historyscore EQUALS 2 THEN NODE: N: 0: 1 : 30.4% 69.6% IF 1.5 &lt;= SafetyScore AND Medicationsscore EQUALS 4 AND Historyscore EQUALS 2 THEN NODE: N: 0: 1 : Figure 2.d: 52.6% 47.4% Decision Tree Rules Additionally, using the Artificial Neural Network method resulted in a model with 85% sensitivity, 38% specificity. The most prominent variables in this model included medication, and vision. A sample of the diagnostic chart is shown in Figure 3.a using SAS Enterprise Miner. Figure 3.b and Figure 3.c gives the fit statistics and weights chart for the Artificial Neural Network. An Artificial Neural Network (ANN) is an information-processing paradigm that is inspired by the way biological nervous systems, such as the brain, process information. The key element of this paradigm is the novel structure of the information processing system. It is composed of a large number of highly interconnected processing elements (neurons) working in unison to solve specific problems. ANNs, like people, learn by example. An ANN is configured for a specific application, such as pattern recognition or data classification, through a learning process. Learning in biological systems involves adjustments to the synaptic connections that exist between the neurons.

This is true of ANN s as well. An artificial neuron is a device with many inputs and one output [16]. A neuron has two modes of operation; the training mode and the using mode. In the training mode, the neuron can be trained to fire (or not), for particular input patterns. In the using mode, when a taught input pattern is detected at the input, its associated output becomes the current output. If the input pattern does not belong in the taught list of input patterns, the firing rule is used to determine whether to fire or not.

The accuracy of the result is measured by the ROC Chart. Receiver Operating Characteristics (ROC) Analysis originated from signal detection theory, as a model of how well a receiver is able to detect a signal in the presence of noise. Its key feature is the distinction between hit rate (or true positive rate) and false alarm rate (or false positive rate) as two separate performance measures.

T orgel=CATEGORY Model Name=ANN Percirl Predicted T argel Actual T algel Percerl---------------,    Percerl---------------, Figure 3.a: Diagnostic Chart for Artificial Neural Networks I [TARGET =CATEGORY [ ?

2 I Aver age Prolil ?

Misclassilicalion Rate , 4 I Average Error ?

5 I Aver age Squared Error : 6 I Sum 01 Squared Errors LU Rool Average Squared Error --W Rool Final Prediction Error . 9 I Root Mean Squared Error ?

10. I Error Funclion 11 Mean Squared Error Maximum AbsJule Error Final Prediction Error D ivisor lor AS E Model Degrees 01 Freedom Degrees 01 Freedom lor Error T olal Degrees 01 Freedom 0.4794520548 0..4545454545 0.724137931 0.4337899543 0..40.90.90.90.91 0..37931 0.3448 0..6723174873 0..6943438379 0..710.851940.6 0.23964110.88 0..250.20.46559 0.2561184377 10.4,96280.48 220.180.0.9718 14,854869387 0..4895315177 0.,50.0.20.4614 0.50.60.814536 0.5171320.75 0..50.3520.9478 0.50.0.20.4614 0..50.60.814536 294.4750.5945 61.1 0.2257735 41.229412553 0,2535333449 0,250.20.46559 0,2561184377 0..7457752369 0.7469569154 0..739877480.7 0.267425583 20.7 88 58 Sum 01 F reqlJencies 219 44 58 Sum Case Weights' Frequencies 438 Akaike's Inlormalion Crilerion 318.4750.5945 Schwarz's Baysian Crilerion 359,14392021 Figure 3.b: Fit Statistics for Artificial Neural Network Figure 3.e: Weights Chart for Artificial Neural Network ROC analysis has also widely been used in medical data analysis to study the effect of varying the threshold on the numerical outcome of a diagnostic test. It has been introduced to machine learning relatively recently, in response to classification tasks with varying class distributions or misclassification costs. ROC analysis is set to cause a paradigm shift in machine learning [19]. ROC curve is a plot of the true positive rate against the false positive rate for the different possible cut points of a diagnostic test.

A ROC curve demonstrates several things: 1. It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).

2. The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.

3. The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.

4. The slope of the tangent line at a cut point gives    4. The slope of the tangent line at a cut point gives the likelihood ratio (LR) for that value of the test.

5. The area under the curve is a measure of test accuracy.

Figure 4 demonstrates the area under the curve of the decision tree and artificial neural network. Decision Tree curve follows the left-hand border and then the top border of the ROC space more accurately then the Artificial neural network so decision tree has a better area under the curve and hence a more accurate test.

6. Conclusion Two data mining modeling techniques resulted in models with varying degrees of sensitivity and specificity. Based upon examination of these models the Decision Tree approach produced a superior predictive model. This model employed medication, history, and safety and environmental hazards to discriminate Fallers from Non-Fallers with a high degree of sensitivity, and specificity. The model predicted safety score and medication score as the two most important factors in predicting falls. Clinicians may evaluate these characteristics of their VNA patients when attempting to identify patients who have a high likelihood of falling in the future.

? ? ? U M U V M U 1 ?SpeclO:iW ?OOI I!I!Tree I!I!Neurai Figure 4: ROC Chart for Decision Tree and Artificial Neural Network 7. Acknowledgements This project was supported by Visiting Nurse Association, Louisville, KY.

