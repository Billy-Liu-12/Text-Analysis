A Hybrid Approach for Mining Frequent Itemsets

Abstract ? Frequent itemset mining is a fundamental element with respect to many data mining problems. Recently, the PrePost algorithm has been proposed, a new algorithm for mining frequent itemsets based on the idea of N-lists. PrePost in most cases outperforms other current state-of-the-art algorithms.

In this paper, we present an improved version of PrePost that uses a hash table to enhance the process of creating the N-lists associated with 1-itemsets and an improved N-list intersection algorithm. Furthermore, two new theorems are proposed for determining the ?subsume index? of frequent 1-itemsets based on the N-list concept. The experimental results show that the performance of the proposed algorithm improves on that of PrePost.

Keywords - frequent itemset, PPC-tree, N-list, data mining

I.  INTRODUCTION Frequent itemset mining was first introduced in 1993 [1] and plays an important role in the mining of associate rules [1, 2, 7, 10]. Currently, there are a large number of algorithms which effectively mine frequent itemsets. They may be divided into three main groups:  (1) Methods that use a candidate generate-and-test strategy of which Apriori [2] and BitTableFI [4] are exemplar algorithms.

(2) Methods that adopt a divide-and-conquer strategy and a compressed data structure of which FP-Growth [6] and FP-Growth* [5] are exemplar algorithms.

(3) Methods that use a hybrid approach of which Eclat [11], dEclat [12] and Index-BitTableFI [8] are all examples.

Although many solutions have been proposed, the complexity of the frequent itemset mining problem remains a challenge. Therefore more computationally efficient solutions are desirable. Recently, Deng et al. [3] introduced the PrePost algorithm for mining frequent itemsets based on the idea of PPC-trees (Pre-order Post-order Code trees), an FP-tree like structure. PrePost operates as follows. First a tree construction algorithm is used to build a PPC-tree. Then N-lists are generated, each associated with a 1-itemset contained in the tree. A N-list of k-itemset is a list describing its features, it is compact form of transaction ID list (TID list). A divide-and- conquer strategy is then used for mining frequent itemsets.

Unlike FP-tree-based approaches, this approach does not build additional trees on each iteration, it mines frequent itemsets  directly using the N-list concept. The efficiency of PrePost is achieved because: (i) N-lists are much more compact than previously proposed vertical structures, (ii) the support of a candidate frequent itemset can be determined through N-list intersection operations which are O(m+n+k), where m, n are the cardinalities of the two N-lists and k is the cardinalities of the resulting N-list. This process is more efficient than finding the intersection of TID lists because it avoids unnecessary comparisons. The experimental results in [3] shows that the PrePost is more efficient than FP-Growth [6], FP-Growth* [5] and dEclat [12]. In this paper, we propose an algorithm based on PrePost, which features the following improvements: (1) using a hash table to speed up the process of creating the N- lists associated with frequent 1-itemsets. (2) Improving the N- list intersection procedure to determine the intersection between two N-lists.

Song et al. [8] proposed the concept of the ?subsume index?. Broadly the subsume index of a frequent 1-itemset is the list of frequent 1-itemsets that co-occur with it. This idea and the N-list concept have also been incorporated into the proposed hybrid algorithm. In this paper, first, two new theorems associated with the generation of subsume indexes are proposed. Then, the usage of the two theorems proposed in [8] in the proposed algorithm to reduce the runtime and memory usage.

The rest of the paper is organized as follows. Section 2 presents the basic concepts. The proposed algorithm is proposed in Section 3. Section 4 shows the results of experiments. Finally, the paper is concluded in Section 5 with a summary and some future research issues.



II. BASIC CONCEPTS  A. Frequent itemsets We assume a dataset DB comprised of n transactions such that each transaction contains a number of items belong to ? where ? is the set of all items in DB. An example transaction dataset is presented in Table 1 (the meaning of the third column will become clear later in this paper), this dataset will be used for illustrative purposes throughout the remainder of this paper.

The support of an itemset X, denoted by ?(X), where X???I, is the number of transactions in DB which contain all the items in

X. An itemset X is a ?frequent itemset? if ?(X) ? ?minSup ? n?,   DOI    DOI 10.1109/SMC.2013.791     where minSup is a given threshold. Note that a frequent itemset with k elements is called a frequent k-itemset and I1 is the set of frequent 1-itemsets sorted in frequency descending order.

TABLE I.  AN EXAMPLE TRANSACTION DATASET  Transaction Items Ordered frequent items 1 a, b a, b 2 a, b, c, d c, a, b, d 3 a, c, e c, a, e 4 a, b, c, e c, a, b, e 5 c, d, e, f c, d, e 6 c, d c, d  B. PPC-tree Deng et al. [3] presented the PPC-tree (an FP-tree like structure) and the PPC-tree construction algorithm as follows:  Definition 1 (The PPC-tree). A PPC-tree, ? , is a tree where each node holds five values: Ni.name, Ni.frequency, Ni.childnodes, Ni.pre and Ni.post which are the frequent 1- itemset in I1, the frequency of this node, the set of children node associated with this node, the order of this node when traversing this tree in Left-Right order and the order of this node when traversing this tree in Right-Left order respectively.

Note that the root of the tree, ?  ? , has ?  ? .name = ?null? and ?  ? .frequency = 0.

procedure Construct_PPC_tree(?, ??????) 1.scan ? to find ?? and their frequency 2.sort ?? in frequency descending order 3.create ??, the hash table of ?? 4.create the root of a PP-tree, ?, and label it as ?null? 5.let threshold = ??????? ? ?? 6.for each transaction ? ? ? do 7.  remove the items that their supports do not satisfy the threshold 8.  sort its 1-itemsets in frequency descending order 9.  Insert_Tree(?, ?) 10.traverse PP-tree to generate pre and post values associate with each node 11.return ?, ??, ?? and threshold  procedure Insert_Tree(?, ?) 1. while (? is not null) do 2.  ? ? the first item of ? and ? ? ? \ ? 3.  if ? has a child ? such that ?.name = ? then 4.   ?.frequency++ 5.  else 6.   create a new node N with N.name = ? , N.frequency = 1 and ?.childnodes = ? 7.  Insert_Tree(?, ?)  Figure 1.  The PPC-tree construction  The PPC-tree construction algorithm is presented in Figure 1.

The example transaction dataset from Table 1 will be used with minSup = 30% to illustrate the operation of this algorithm. First the algorithm removes all items whose frequency does not satisfy the minSup threshold and sorts the remaining items in descending order of frequency (see column three in Table 1).

The algorithm then inserts, in turn, the remaining items in each  transaction into the PPC-tree as shown in Figure 2 with respect to our example dataset.

Figure 2.  Illustration of the creation of a PPC-tree using the example  transaction dataset with minSup = 30%  Finally the algorithm traverses the full tree (Figure 2 (f)) to generate the required pre and post values associated with each node. The final PPC-tree is presented in Figure 3.

Figure 3.  The final PPC-tree created from the example transaction dataset  with minSup = 30%  C. N-list Deng et al. [3] presented the definition of the N-list concept and three theorems associated with it. We summarize these as follows:  Definition 2 (The PP-code). The PP-code, Ci, of each node Ni in a PPC-tree has a tuple as follows:  Ci = ?Ni.pre, Ni.post, Ni.frequency? (1)  Example 1. The highlighted nodes N1 and N2 (for example) in Figure 3 have the PP-codes C1 = ?1,7,5? and C2 = ?5,4,2? respectively.

d, 2  e, 1  a, 1(9,9) (1,7) c, 5  (2,1) a, 3 (4,6)  (3,0) b, 2 (5,4) e, 1 (8,5)  e, 1 (6,2) (7,3) d, 1  null (0,10)  N1  N2  b, 1(10,8)  c, 5  null  d, 2  e, 1  a, 3  b, 2  e, 1  e, 1  d, 1  c, 5  null  d, 2  e, 1  a, 3  b, 2  e, 1  e, 1  d, 1  a, 1  b, 1  c, 1  null  d, 1  c, 2  null  d, 2  e, 1  c, 3  null  d, 2  e, 1  a, 1  b, 1  e, 1  (a) (b) (c)  c, 4  null  d, 2  e, 1  a, 2  b, 1  e, 1  e, 1  (d)  (e) (f)     Theorem 1 [3]. A PP-code Ci is an ancestor of another PP- code Cj if and only if Ci.pre ? Cj.pre and Ci.post ? Cj.post.

Note that any PP-code is also considered to be its own ancestor.

Example 2. According to Example 1, we have C1= ?1,7,5? and C2= ?5,4,2?. Based on Theorem 1, C1 is an ancestor of C2 because C1.pre = 1 < C2.pre = 5 and C1.post = 7 > C2.post = 4.

Definition 3 (The N-list of a frequent 1-itemset). The N-list associated with an item A, denoted by NL(A), is the set of PP- codes associated with nodes in the PPC-tree whose name is equal to A. Thus:  ???? ?! ? " #$ %&'?????(?&')*+,-./0  (2)  where #$ is the PP-code associated with ?$.

Example 3. Let A = {c} and B = {e}. According to the PPC-tree in Figure 3, NL(A) = {?1,7,5?} and NL(B) = {?6,2,1?,?8,5,1?}.

Theorem 2 [3]. Let A be a 1-itemset with the associated N-list NL(A). The support for A, ?(A), is calculated by: ??? ?! ? 1 #$) 2345?4?67  #??????? (3)  Example 4. According to Example 3 we have NL(A) = {?1,7,5?} and NL(B) = {?6,2,1?, ?8,5,1?}. Therefore, ???  = 5 and ??  = 1 + 1 = 2.

Definition 4 (The N-list of a k-itemset). Let XA and XB be two (k-1)-itemsets with the same prefix X (X can be an empty set) such that A is before B according to the I1 ordering. NL(XA) and NL(XB) are two N-lists associated with XA and XB respectively. The N-list associated with XAB is determined as follows:  (1) For each PP-code Ci ? NL(XA) and Cj ? NL(XB), if Ci is an ancestor of Cj, the algorithm will add ?Ci.pre, Ci.post, Cj.frequency? to NL(XAB).

(2) Traversing NL(XAB) to combine the PP-codes which has the same pre and post values.

Example 5. According to Example 4 we have NL(A) = {?1,7,5?} and NL(B) = {?6,2,1?, ?8,5,1?}. Therefore NL(AB) = {?1,7,1?, ?1,7,1?} = {?1,7,2?}.

Theorem 3 (The support of a k-itemset) [3]. Let X be an itemset and NL(X) be N-list associated with X. The support of X denoted by ?(X) is calculated as follows: ??8 ?! ? 1 #$) 2345?4?67  #??????8 (4)  Example 6. According to Example 5 we have NL(AB) = {?1,7,2?}, therefore ?(AB) = 2.

D. The subsume index of frequent 1-itemsets To reduce the search space, the concept of the subsume index was proposed in [8] which is based on the following function:  g(X) = {T.ID ? DB | X 9?T} (5) where T.ID is the ID of the transaction T, and g(X) is the set of IDs of the transactions which include all items i ? X.

Example 7. Let A={c}, we have g(A) = {2, 3, 4, 5, 6} because A exists in the transactions 2, 3, 4, 5, 6.

Definition 5 [8]. The subsume index of a frequent 1-itemset, A, denoted by subsume(A) is defined as follows:  subsume(A) = {B ? I1 | g(A) 9 g(B)} (6) Example 8. Let A = {e} and B = {c}, we have g(A) = {3, 4, 5} and g(B) = {2, 3, 4, 5, 6}. Because g(A) 9 g(B), thus B ? subsume(A). In other words, {c} ? subsume({e})  In [8] the following two theorems concerning the subsume index idea were also presented, which in turn can be used to speed up the frequent itemset mining process.

Theorem 4 [8]. Let A be a frequent 1-itemset. If the support associated with A is equal to ?minSup ? n?, then there exists no item B which has ?? : ???  and B ; subsume(A) such that A?B is a frequent itemset.

Theorem 5 [8]. Let the subsume index of an item A be {a1, a2,?, am}. The support of each of the 2m-1 nonempty subsets of {a1, a2,?, am} is equal to the support of A.

Example 9. Let A = {e} and B = {c} and according to Example 8, we have subsume(A) = {B}. Therefore 2m-1 nonempty subsets of subsume(A) is only {B}. Based on Theorem 5, the support of 2m-1 itemset which are combined 2m-1 nonempty subsets of subsume(A) with A is equal to ?(A). In this case, we have ?(AB) = ?(A) = 3. Besides, the support of the frequent itemset XA is also equal to the support of frequent itemset XAB.

For detail, ae is a frequent itemset with ?(ae) = 2. So, aec is also a frequent itemset and ?(aec) = 2.



III. THE PROPOSED ALGORITHM  A. The N-list intersection function Deng et al. [3] proposed a N-list intersection function for determining the intersection of two N-lists which was O(n+m+k) where n, m and k is the length of the first, the second and the resulting N-lists (the function traverses the resulting N- list so as to merge the same PP-codes). In this section we present an improved N-list intersection function to give O(n+m). This improved function offers the advantage that it does not traverse the resulting N-list to merge the same PP- codes. Furthermore, we also propose an early abandoning strategy comprised of three steps: (i) determine the total frequency of the first and the second N-list denoted by sF, (ii) for each PP-code Ci, that does not belong to the result N-list, update sF = sF - Ci.frequency, and (iii) if sF falls below ?minSup ? n? stop (the itemset currently being considered is not frequent). Given the above the improved N-list intersection function is presented in Figure 4.

function NL_intersection(PS1, PS2) 1. PS3 ? ? 2.let sF be the sum of frequency of PS1 and PS2 3.let i = 0, j = 0 and frequency = 0 4. while i < PS1.size and j < PS2.size do     5.  if PS1[i].pre < PS2[j].pre then 6.   if PS1[i].post > PS2[j].post then 7.    if PS3.size > 0 and PS3[PS3.size-1].Pre = PS1[i].pre then 8.     PS3[PS3.size-1].frequency += PS2[j].frequency 9.    else 10.    add the tuple ?PS1[i].pre, PS1[i].post, PS2[j].frequency? to PS3 11.   frequency += PS2[j++].frequency 12.  else 13.   sF = sF - PS1[i++].frequency 14. else 15.  sF = sF - PS2[j++].frequency 16 . if sF < threshold then // using early abandoning strategy 17.  return null // stop the procedure 18.return PS3 and frequency  Figure 4.  The improved N-list intersection function  B. The subsume index associated with each frequent 1-itemset Theorem 6. Let A be a frequent 1-itemset. We have:  subsume(A) = {B ? I1 | ?Ci ? NL(A), ?Cj ? NL(B) and Cj is an ancestor?<=?Ci} (7)  Proof. This theorem can be proven as follows: all PP-codes in NL(A) have a PP-code ancestor in NL(B), this means that all transactions that contain A also contain B. This, g(A)? 9 g(B), which implies that B? ? subsume(A))? Therefore, this theorem is proven.

Example. Let A = {e}, B = {c}. We have NL(B) = {?1,7,5?} and NL(A) = { ?3,0,1?, ?6,2,1?, ?8,5,1?}. According to Theorem 6, ?3,0,1?, ?6,2,1? and ?8,5,1? ? NL(A) are descendants of ?1,7,5? ?? NL(B). Therefore, B ? subsume(A).

Theorem 7. Let A, B, C ? I1 be three frequent 1-itemsets. If A ??subsume(B) and B ??subsume(C) then A ??subsume(C).

Proof. We have A ?? subsume(B) and B ?? subsume(C) therefore g(B)? 9 g(A) and g(C)? 9 g(B). So g(C)? 9? g(A) and thus this theorems is proven.

To find all frequent 1-itemset associated with the subsume index of each A ?? I1, I1 should be sorted in ascending order of frequency. However, I1 has already been sorted in descending order of frequency with respect to the PPC-tree constructed previously. Therefore, with respect to the generate subsume index procedure, we propose a different traverse (see Figure 5) to avoid the cost of this reordering process and also facilitate the use of Theorem 7.

procedure Find_Subsume(??) 1. for i ? 1 to ??.size - 1 do 2.  for j ? i - 1 to > do 3.   if j ????[i].Subsumes then continue 4.   if checkSubsume(??[i].N-list, ??[j].N-list) = true then // using Theorem 6 5.    add ??[j].name and its index, j, to ??[i].Subsumes 6.    add all elements in ??[j].Subsumes to ??[i].Subsumes // using Theorem 7 function checkSubsume(N-list a, N-list b) 1. let i=0 and j=0 2.while j < a.size and i < b.size do  3.  if b[i].pre < a[j].pre and b[i].post > a[j].post then 4.   j++ 5.  else 6.   i++ 7.if j = a.size then 8.  return true 9. return false  Figure 5.  The generating subsume index proceduce  C. Algorithm The two theorems proposed in [8] and re-presented in section 2.4 were also adopted in the proposed algorithm to speed up the runtime (Figure 6). Besides, these theorems also helped reduce the memory usage because it is not necessary to determine and store the N-lists associated with a number of frequent itemsets to determine their supports.

Input: A dataset ? and ?????? Output: ??@, the set of all frequent itemsets 1.Construct_PPC_tree(?, ??????) to generate ?, ??, H1 and threshold 2.Generate_NList(?, ??) 3.Find_Subsume(??) 4.??@ ? ?? 5.Subsume ? {} 6.Find_FIs(??, Subsumes) 7.return ??@ procedure Generate_NList(?, ??) 1. # ? ??.pre,?.post, ?.frequency? 2. H1[?.name].N-list.add(#) 3. H1[?.name].frequency += #.frequency 4. for each child in ?.children 5.  Generate_NList(child) procedure Find_FIs(?@, ?) 1.for i ? ?@.size - 1 to > do 2.  ??@ABCD ? ? 3.  if ?@[i].Subsumes.size > 0 then 4.   let ? be the set of subset generated from all elements of ?@[i].Subsumes 5.   for each subset in ? 6.    add ?subset, ?@[i].frequency? to ??@ // using theorem 5 7.  else if ?@[i].size = 1 then 8.   S ? {} 9.  if??@[i].size = 1 and ?@[i].frequency = threshold then // using Theorem 4 10.  continue 11. indexS = ?@[i].Subsumes.size - 1 12. for j ? ? - 1 to 0 do 13.  if indexS >= 0 and the index of ?@[i].Subsumes[indexS] equals than j then 14.   indexS = indexS - 1 15.   continue 16.  let efirst be the first item of ?@EFG 17.  FI ? {efirst} + ?@[i] 18.  (FI.N-list and frequency) ? NL_intersection(?@[j].N-list, ?@[i].N-list) 19.  if FI.N-list = null then 20.   continue // using early abandoning strategy 21.  FI.frequency = frequency 22.  if(FI.frequency ? threshold) then 23.   add FI to ??@ 24.   insert FI at position 0 in ??@ABCD 25.   for each subsume in ? do 26.     let f = FI + subsume 27.     f.frequency = FI.frequency     28.     add f to ??@ // using theor 29. Find_FIs(??@ABCD, ?)  Figure 6.  The proposed algorithm

IV. EXPERIMENTAL RESULT All experiments presented in this section were ASUS laptop with Intel core i3-3110M 2.4G RAM. The operating system was Microsoft W programs were coded in C# on MS/Visual stu on Microsoft .Net Framework Version experiments were conducted using the followin Accidents, Mushroom and Retail (Table 2) runtime (total execution time) of the propose compare it to the runtime of PrePost.

TABLE II.  STATISTICAL SUMMARY OF THE EXPERI  Dataset #Trans  Accidents 340,183 Mushroom 8,124  Retail 88,162  Figure 7.  The runtime of the proposed and PrePost alg datasets: (a) Accidents, (b) Mushroom, (c) Reta  The experimental results are presented in Fig figure it can be observed that given a sparse Retail, the proposed algorithm is a little slow Because generating the subsume index in However, the subsume index associated w frequent 1-itemsets in a sparse datasets us elements. Therefore, using the subsume inde effective in this case. Fortunately, this cost is u       80 60  PrePost Proposed algorithm  Ru nt  im e  (s ec  on ds  )     15 10  PrePost Proposed algorithm  Ru nt  im e  (s ec  on ds  )      0.3 0.2  PrePost Proposed algorithm  Ru nt  im e  (s ec  on ds  )  em 5  TS performed on an  GHz and 4GBs of Windows 8. All the udio 2012 and run  4.5.50709. The ng UCL datasets: ). We report the ed algorithm and  IMENTAL DATASETS  #Items   16,470       gorithms using UCL ail datasets  gure 7. From the datasets such as  wer than PrePost.

nvolves a cost.

with each of the sually have few  ex concept is not usually relatively  low, about 4 seconds for the Retail (0.072% of the runtime) (see Figur dense datasets, the performance of better than PrePost (see Figure 7(a low thresholds. The proposed outperforms than the PrePost.



V. CONCLUSIONS AN In this paper we have proposed a h frequent itemsets. First, we propose the PrePost algorithm: (i) use of a process of creating the N-lists asso itemsets and (ii) an improved inter intersection between two N-lists.

proposed for application with respe the subsume index of frequent 1-ite the proposed algorithm for imp proposed algorithm does not impr respect to sparse datasets but the t With respect to dense datasets the p than PrePost. We therefore con algorithm generally outperforms th we will initially focus on applying hybrid approach for mining frequent  ACKNOWLEDG This research was funded by Vietna Science and Technology Developm grant number 102.01-2012.17.

REFERENC [1] Agrawal, R., Imielinski, T., Swami,  between sets of items in large database [2] Agrawal, R., Srikant, R.: Fast algorith  VLDB'94, 487-499, 1994.

[3] Deng Z., Wang Z., Jiang J.J.: A new a  itemsets using N-lists. SCIENCE CHI 2008-2030, 2012.

[4] Dong, J., Han, M.: BitTableFI: An algorithm. Knowledge-Based Systems,  [5] Grahne, G., Zhu, J.: Fast algorithms f 1347?1362, 2005.

[6] Han, J., Pei, J., Yin, Y.: Mining fre generation. SIGMODKDD?00, 1?12, 2  [7] Pasquier, N., Bastide, Y., Taouil, R., Association Rules using Closed Items 24 (1), 25-46, 1999.

[8] Song, W., Yang, B., Xu, Z.: Index-Bi for mining frequent itemsets. Knowle 2008.

[9] Vo, B., Hong, T.P., Le, B.: Dynamic b for mining frequent itemsets. Scienti 5358-5368, 2011.

[10] Vo B., Hong T.P., Le B.: A Lattice-b Generalization Association Rules. Kn 30, 2013.

[11] Zaki, M.J., Parthasarathy, S., Ogihara fast discovery of association rules. KDD  [12] Zaki, M.J., Hsiao, C.J.: Efficient algor and their lattice structure. IEEE Tran Engineering, 17(4), 462-478, 2005.

(a)   (b)  0.1minSup(%)  (c)  l dataset with minSup = 0.1 re 7(c)). However, given a  f the proposed algorithm is a) and (b)), especially with algorithm thus generally  ND FUTURE WORK hybrid algorithm for mining ed several improvements on a hash table to enhance the ociated with the frequent 1- section function to find the Then, two theorems were ect to the determination of emsets which were used in  proving the runtime. The rove over the PrePost with time gap is not significant.

proposed algorithm is faster nclude that the proposed e PrePost. For future work the N-list concept and the  t closed/maximal itemsets.

GMENT am National Foundation for ment (NAFOSTED) under  ES A.N.: Mining association rules  s. SIGMOD?93, 207-216, 1993.

hms for mining association rules.

algorithm for fast mining frequent INA Information Sciences, 55(9),  efficientmining frequent itemsets , 20, 329?335, 2007.

for frequent itemset mining using  wledge and Data Engineering, 17,  equent patterns without candidate 2000.

, Lakhal, L.: Efficient Mining of set Lattices. Information Systems  itTableFI: An improved algorithm edge-Based Systems, 21, 507-13,  bit vectors: An efficient approach ific Research and Essays, 6(25),  based Approach for Mining Most nowledge-Based Systems, 45, 20-  , M., Li, W.: New algorithms for D?97, 283-286, 1997.

