ARC-UI: A Visualization Tool for Associative Classifiers

Abstract The classification of an unknown item based on a train-  ing data set is a key data mining task. An important part of this process that is often overlooked is the user?s compre- hension of the classifier and the results it produces. Asso- ciative classifiers begin to address this issue by using sets of simple rules to classify items. However, the size of these rule sets can be an obstacle to understandability. In this work, we present an interactive visualization system that allows the user to visualize various aspects of the classi- fier?s decision process. This system shows the rules that are relevant to the classification of an item, the ways in which the item?s characteristics relate to these rules, and connec- tions between the item and the classifier?s training data set.

The system also contains a speculation component, which allows the user to modify rules within the classifier, and see the impact of these changes. Thus, this component allows the user to contribute domain expertise to the classifica- tion process, consequently improving the accuracy of the classifier.

Keywords? visualization, associative classifiers, classifica- tion result analysis  1 Introduction The classification of items based on previously classi-  fied training data is an important area within data mining, and has many real-world applications. However, one draw- back to many classification techniques, such as those based on neural networks or support vector machines (SVM), is that it is difficult for the user to understand the reasoning behind a classification result, or interpret the learned clas- sification model. This is particularly important in a context where an expert user could make use of domain knowledge to either confirm or correct a dubious classification result.

Rule-based classifiers address this shortcoming by us- ing a collection of simple rules to perform classification.

Each rule is made up of one or more attribute/value pairs and a class, and is thus quite easy to understand. Most rule-based classifiers perform a heuristic search to discover classification rules, often missing important ones. Asso- ciative classifiers [12, 11], on the other hand, use associ-  ation rule mining [1] to perform an exhaustive search to find classification rules. However, the set of rules gener- ated by an associative classifier may contain hundreds of thousands of rules, and thus it is difficult for the user to ascertain which rules are relevant to the classification of an item, and to what extent the relevant rules influence a classification decision.

This paper presents ARC-UI, a tool that allows the user to understand the reasoning behind an associative classi- fication result via a graphical, interactive interface. Al- though other rule visualizers exist [6, 9], ARC-UI is unique in that the user is able to modify the rules that are used and immediately see the results of this modification, thus al- lowing the user to improve the accuracy of the classifier through the application of domain expertise. This capabil- ity has the added benefit of increasing the user?s confidence in the classifier.

2 Related Work Research related to visualizing associative classification  results can be divided into three areas: visualizing classifi- cation results, visualizing association rule sets, and visual classification. Each of these areas contributes important ideas and techniques to the aims of this research.

2.1 Visualizing Classification Results One of the main goals of this research is to allow users  to understand the result of classifying an item. Poulin, Szafron and others have investigated this issue of classifi- cation result analysis [13, 15]. Although their work focuses on additive, rather than rule-based, classifiers, the concerns that are identified are equally applicable to this research.

An additive classifier uses a sum of terms to classify an item, where each term represents the likelihood of an at- tribute belonging to a given class, and the sum indicates the likelihood of the item belonging to that class. Each term in the equation has a weight associated with it, indicating its relevance to the classification decision [13]. Classifiers which fall into this category include Bayesian classifiers, SVM-based classifiers, and linear regression classifiers [8].

Their work is quite relevant, in that they present a system which allows users to analyze classification results. The   DOI 10.1109/IV.2008.35     authors propose five desired areas for analysis:  ? Classification: Show the classification decision made by the classifier, and show the alternatives.

? Decision evidence: Show the evidence that was used by the classifier to arrive at its result.

? Decision speculation: Show the effect of changing the item that is being classified.

? Ranks of evidence: Show the relative importance of the evidence used by the classifier.

? Source of evidence: Show the data that was used by the classifier to create the classification model.

The authors also present a system, ExplainD, which ful- fills these requirements for additive classifiers. For each of these classifiers, the authors show how ExplainD imple- ments the five analysis areas described above.

This paper was followed by work by Szafron et al.

which applied the ideas of ExplainD to the problem of pro- teome analysis [15]. This system was able to provide good prediction results in a variety of proteins, and make ?every prediction transparent to its users? through its explana- tory features. In their decision speculation component, they only change the attribute value of the object being classified, and do not edit any part of the learned model.

Although this system still relies on additive classifiers, its success provides real-world evidence that classification re- sult analysis is a useful capability, and well worth pursuing.

2.2 Visualizing Association Rule Sets A major drawback of associative classifiers is that they  use very large rule sets to perform classification. Thus, un- derstanding of the classification result is hampered by the need to make sense of sets of hundreds or thousands of rules. This issue is particularly relevant to this research be- cause of the decision evidence component which, in an as- sociative classification context, relies on the visualization of the rules which are used in classifying an item. Sev- eral researchers have addressed this issue in the context of association rule mining.

One method of dealing with large associative rule sets was developed recently by Tuzhilin and Adomavicius within the context of microarray data. They developed post-processing techniques, such as grouping and filtering, which made the analysis of very large numbers of associ- ation rules a more manageable task [16]. As this work is focused more on processing methods than visualization, it is not directly applicable to this research. However, the grouping techniques may be useful in implementing vi- sualization techniques, especially when considered along with the work of Couturier, which is described below.

Another step in this direction was taken by Rahal et al.

Their solution, however, focuses on querying this rule set in order to find ?the subset of associations that are of in- terest [in an] interactive mode? [14]. The idea of allowing the user to interactively analyze association rules is sim- ilar in spirit to the visual classification work by Ankerst, described in the following section. However, the need to iteratively refine the rule set conflicts with the need, in the context of this research, to quickly present the user with a summary of a large rule set.

Fukuda and Morimoto developed an interesting visual- ization technique for optimized two-dimensional rules [7].

Their work focuses on rules where the domains of the at- tributes form a planar region. For these rules, the authors represent the region as a pixel map, where each pixel is as- signed a colour and brightness level which convey informa- tion about that point in the plane. This work is intriguing in its use of visual elements such as position, brightness and colour to represent association rules. However, it is limited to rules of a particular form, and thus is not practical for general-purpose analysis.

Couturier et al. have also investigated visualizing large sets of association rules [5]. Rather than trying to repre- sent each rule individually, the authors propose clustering the rules, and then using a fish-eye view (FEV) technique to view the details of a particular cluster while viewing coarse-grained representations of other clusters.

Leung et al., in developing a visualization system for frequent itemsets, analyzed a couple of creative methods for visualizing association rules [10]. One of these, AViz, uses a planar representation method similar to that devel- oped by Fukuda and Morimoto. The other, by Yang, uses a Bezier curve to represent a rule, thus allowing multiple rules, each represented by a Bezier curve, to be shown on the same graph. These techniques would not be effective for large rule sets, but could be helpful for visualizing small subsets of association rules.

2.3 Visual Classification Ankerst et al. investigated the concept of having the  user assist in the process of creating the classifier through visual inspection of the data, and evaluation of the classi- fier as it is created [2]. This research is based on the idea that the user can contribute domain knowledge and pattern recognition abilities to the classifier creation process, both of which are valuable contributions.

While the work focuses on decision tree-based classi- fiers, the visualization techniques presented offer innova- tive ways of effectively presenting large quantities of data.

Furthermore, the research emphasizes the importance of collaboration between the user and the classification sys- tem in creating an effective classification model, which     Figure 1: Classification component Figure 2: Decision evidence component (truncated)  echoes the goals of our research.

3 System Features The initial development of the system was guided by the  five analysis components described by Poulin et al. in their work on the ExplainD system [13]. Through testing and user feedback, other requirements were identified, which led to further development. These components had already been implemented in a linear classification context, but our focus on associative classification meant that some of the components had to be significantly revised.

The screenshots that follow were taken from system?s use in the context of classifying mushrooms. The well- known ?mushroom? data set, downloaded from the UCI data repository, contains over 8,000 mushrooms that have been classified as either poisionous or edible [4]. Each item in the data set contains twenty-two characteristics, such as gills-attached, colour and odor, that help deter- mine the item?s classification. The Weka data analysis tool [17] was used to generate classification rules (1,275 in to- tal), which were then imported into the system. Thus, the screenshots show the system analyzing the classification of an unknown mushroom using these rules.

The classification component shows the result of classi- fying the item, as well as all other possible classifications, as shown in Figure 1. This allows the user to compare the result with other possibilities, and thus assess the likeli- hood of an alternative result. The classification possibili- ties are listed in decreasing order of likelihood, to facilitate comparison between the various possibilities.

The decision evidence component shows the rules that were used to classify an item. This gives the user an initial understanding of the reasoning used by the classifier. If the relevant rule set is small enough, these rules are shown in a bar graph, as in Figure 2. However, if the rule set is too large for this to be feasible (i.e., more than a few dozen rules), the bar graph is compressed in order to present the rule set characteristics in a meaningful, visual manner. Us- ing this ?compressed? format, hundreds of rules may be viewed in a summarized form. In either case, the bar graph is colour-coded according to the class labels, to facilitate  comparison among the rules shown. As well, the compo- nent presents a summary of the rules influencing each clas- sification possibility. This summary, which is generated by sorting the relevant rules according to their classification labels, includes the confidence value for each rules and the overall confidence for each class. The overall confidence is calculated using either the best rule [12] or average rule method [3], as specified by the user.

The decision speculation component allows the user to modify the item being classified, the method used to cal- culate the confidence for each class, and the rules used in classification. The user is shown a list of all relevant rules, and can click on any rule to view a simple editing menu for that rule, shown in Figure 3. This allows the user to deal with a large set of potentially relevant rules, while provid- ing fine-grained editing capabilities where they are needed.

After performing the desired modifications, the user is im- mediately shown the results of this modification. This al- lows the user to experiment with the classification engine, thus offering insight into the process behind item classifi- cation. In selecting the confidence calculation method, the user may choose between the best rule [12] and average rule methods [3]. When editing the rules used in classifi- cation, the user can:  ? edit the classification or confidence for a rule  ? add, modify or delete clauses within a rule  ? remove a rule entirely (causing it to be ignored)  ? create a new rule  Thus, the user can draw on expert knowledge to edit the computationally-generated rule set. Moreover, the user is shown immediately whether this modification improved the accuracy of the classifier. It should be noted that the speculative changes made by the user are not immediately made permanent. However, the user has the option of mak- ing the speculative changes permanent in the classification model, once the results of these changes have been pre- sented, and accepted by the user. Thus, the tool offers the ability to interactively analyze and improve the classifier.

Figure 3: Decision speculation component Figure 4: Ranks of evidence component  The ranks of evidence component shows the relation- ships between characteristics, association rules and classi- fications. This provides the user with further information about the way the classifier works, independent of any par- ticular item or rule set. The system uses a colour-coded bar chart-based visualization scheme, as shown in Figure 4. The length of each bar indicates the total number of times a characteristic appears in the rule set. The colour- coded segments show the number of rules containing a given characteristic that result in a particular classification.

By moving the mouse over each segment, the use is shown a more detailed summary of the rules that contain a given characteristic and result in the selected classification. This approach is both visually appealing and scalable, which is quite beneficial when dealing with very large rule sets. In Figure 4, we see that the ?cap-shape? characteristic appears in three rules, two of which have the class ?poisonous?, and one with the class ?edible? (represented by green and red segments, respectively). By placing the mouse over the ?poisonous? segment of the bar for the ?cap-shape? char- acteristic, we are shown more information about the rules containing the ?cap-shape? characteristic where the class is ?poisonous?.

Finally, the source of evidence component allows the user to make connections between the item being classi- fied and the entries in the data set that were used to gener- ate the associative classification rules. This may be useful when investigating a dubious classification result - the user can check the data used in training the classifier to see if there were any anomalies in that original data. Specifi- cally, the component shows the entries in the training set in a colour-coded list using shades of red and green, as shown in Figure 5. A green entry indicates that the en- try has the same class as the item being analyzed, while a red entry indicates that they have different classes. The in- tensity of the colour indicates the proximity of the entry to the current item, in terms of matching attribute-value pairs.

Finally, the user is able to specify a variety of further anal-  ysis options to restrict the list of entries to those matching certain classification or characteristic criteria. In particu- lar, when filtering by attribute, the user is shown a chart of the distribution of that attribute among the possible classi- fications, divided by the possible attribute values. Figure 6 shows the class breakdown for the possible values of the ?cap-shape? attribute. For example, in 81% of the 535 items containing the ?cap-shape=convex? attribute-value pair, the class was ?edible?. The table also shows that there were no items which contained ?cap-shape=conical?, and thus this attribute-value pair had no impact on the classifi- cation model.

4 Evaluation As described in the methodology section, the system  was evaluated by testing it with several real-world data sets, and assessing the system?s ability to analyze classi- fication results, deal with large sets of association rules, and provide the user with interactive rule set editing capa- bilities.

Furthermore, one of the goals of the system is to allow the user to use their expertise to interactively modify the rule set used by the classifier, and thus improve the over- all accuracy of the classifier. Showing that this is indeed possible is another form of validation for the system as a whole.

To perform the first part of the validation, several data sets were obtained from the UCI machine learning repos- itory mushroom, car evaluation, and nursery [4]. These data sets were then fed into Weka [17], a data analysis pro- gram, and the resulting rules were then pruned for rele- vance. For a data set with n classes, rules with a confi- dence value less than 1n were pruned, since they indicated less certainty than would be provided by random selection.

Finally, the relevant rules, along with the original data sets, were loaded into our system. The data sets had varying numbers of items and attributes, and the rule sets were sim- ilarly varied, thus providing a good test of the system?s ca-     Figure 5: Source of evidence component Figure 6: Source of evidence chart  pabilities (see Table 1 for details).

In order to test the utility of the interactive classifier  modification component, each data set was analyzed and iteratively improved using the decision speculation com- ponent. In a scheme similar to the k-fold cross-validation method of classifier validation, 90% of the items in each data set were used to train a classifier, while the remaining 10% of the items were set aside for use with the ARC- UI system. For each of these items, the ARC-UI system was used to classify the item, and the result was compared to the correct class, as recorded in the original data set.

The speculation component of the system was then used to modify the classifier and test the modified classifier, with the aim of fixing the errors made originally. Finally, after modifications were made so that the incorrectly classified items were classified correctly, all of the items were re- classified using the modified classifier, to assess the over- all impact of the modifications and ensure that the changes had not adversely affected the accuracy of the classifier.

The results of classification using the initial and modified classifiers are presented in Table 2.

As shown in this table, the system was used to improve the accuracy of each classifier, using the speculation and classification tools. Furthermore, it is worth noting that, in each case, the increased accuracy was caused by a very small change in the rule set. This indicates that, by iden- tifying the appropriate rules to modify, the user can im- prove the accuracy of the classifier with a minimal amount of time and effort.

5 Future Work There are several promising areas for further work on  this project. Three of these are empirical validation, rule set visualization, and the improvement of the source of ev- idence component.

The validation for the system has, thus far, consisted of ensuring that the system met its functional requirements, and offered users the ability to interactively improve the classifier they are working with. However, a key non- functional requirement of the system is that users from a  broad range of backgrounds - that is, beyond computer sci- ence and data analysis - should find the system intuitive and easy to use. To find out whether this is, in fact, the case, it would be beneficial to conduct a study to investigate the system?s usability. Participants could be drawn from a range of subject areas, and thus the experiment could mea- sure the system?s applicability to specific contexts, as well as its general usability.

Effective rule set visualization becomes challenging when the size of the relevant rule set exceeds a few dozen rules. Currently, the system presents a compressed bar graph visualization if the rule set is larger than a certain threshold. However, it may be more effective to use a clus- tering approach, similar to that proposed by Couturier et al.

[5], or a visualization scheme inspired by those presented by Ankerst et al [2]. Thus, several visualization options could be implemented and then tested with users drawn from the participant pool described previously.

Currently, the source of evidence helps the user identify anomalous entries in the original data set. It would be even more beneficial if the user could, after identifying such en- tries, modify or even remove them entirely. This, along with an integrated classification rule generator, would al- low the user to interactively fix errors in the training data.

The analysis techniques currently implemented are based on those developed for the linear classifier-oriented system by Poulin. However, there may be other analysis techniques which would be particularly useful for an asso- ciative classification context or other rule-based models.

Conclusions In this paper, we present ARC-UI, an interactive sys-  tem for analyzing the results of an associative classifier.

Associative classifiers have the advantage of easily under- standable classification rules, but often use very large rule sets. The system offers a variety of tools to help the user understand the classification engine?s result, including vi- sualizations of relevant rule sets; the relationships between characteristics, rules and classes; and connections between training data and the item being classified.

Name Items Attrs All rules Pruned rules Car 1,728 6 1,057 28 Mushroom 8,124 22 1,275 71 Nursery 12,960 8 2,418 10  Table 1: Data set characteristics  Car Mushroom Nursery Number of items 173 813 130 Rules modified 2 1 1 Accuracy (before) 80.9% 93.5% 70.4% Accuracy (after) 82.1% 94.8% 73.8%  Table 2: Initial vs. modified classifier accuracy  Perhaps most important, however, is the speculation component, which allows the user to modify the rules used to classify an item, and then immediately see the results of classifying the item using the modified rule set. Thus, the user can contribute domain knowledge to the classification process, improving the classifier?s accuracy and increasing the user?s confidence in the reasoning behind the classi- fier?s decision-making process.

The system was validated by assessing its effectiveness with several data sets drawn from a variety of contexts, and also by testing the utility of the speculation component described previously. Thus, it was shown that the system could be used to understand the results of classifying items in various real-world contexts, and that the speculation tool could be used to improve the classifier?s accuracy.

Acknowledgements This research has been funded by a grant from the Natu-  ral Sciences and Engineering Research Council of Canada.

