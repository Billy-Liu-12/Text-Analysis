Mining Market Value Functions for Targeted Marketing

Abstract  Targeted marketing typically involves the ident$cation of customers or products having potential market values.

We propose a linear model for solving this problem by draw- ing and extending results from information retrieval. It  is assumed that each object is represented by values of aJinite set of attributes. A market value function, which is a linear combination of utility functions on attribute values, is used to rank objects. Several methods are examined for mining market value functions. The main advantage of the model is that one can rank objects of interest according to their market values, instead of classifying the objects. The the- oretical results reported in this paper establish a basis on which further studies and experimental evaluation can be carried out.

1. Introduction  The problem of targeted marketing typically involves the identification of customers or products having poten- tial market values. It is an important area of applications for data mining [6]. Standard data mining techniques may be applied for the purpose of targeted marketing. For ex- ample, one may use association rules mined from a large transaction dataset for targeted marketing [ 11. If a strong association between two sets of items A and B is observed, i.e., a customer buying A tends to buy B,  it may be bene- ficial to send advertisement of B, or recommend items B, to customers buying A. In fact, using association rule to promote related products is a common practice of targeted marketing.

Consider now another type of targeted marketing prob- lem. Suppose there is a health club that needs to expand its operation by attracting more members. Assume that each existing member is described by a finite set of attributes.

It is natural to examine existing members in order to iden- tify their common features. Information about the health  Ning Zhong Department of Information Engineering  Maebashi Institute of Technology Maebashi-City 371-08 16, Japan  zhong @maebashi-it.ac.jp  club may be sent to non-members who share the same fea- tures of members or similar to members. Other examples include promotion of special types of phone services, and marketing of different classes of credit cards. In this case, we explore the relationships (similarities) between people (objects) based on their attribute values. The underlying assumption is that similar type of people tend to make sim- ilar decisions and to choose similar services. Techniques for mining association rules may not be directly applicable to this type of targeted marketing. Other techniques from machine learning and data mining, such as learning char- acteristic rules, classification rules, discriminant rules, and peculiarity rules, may be applied [3, 8, 20, 21, 221. The mined rules characterizing members can be used to decide if a non-member is likely to join the club, and thus war- rant sending soliciting materials. However, there may be some difficulties with these techniques. One may produce too many or too few rules. The selection of a good set of rules may not be an easy task. Furthermore, the use of the derived rules may produce too many or too few potential new members.

In this paper, we present an alternative solution for the above targeted marketing problem by extending results from information retrieval [ 12, 131. The main task of an in- formation retrieval system is to identify useful information items. The ideas developed for information retrieval can be used to identify objects having potential market value. In contract to commonly used data mining approaches for dis- covering rules, one may attempt to discover market value functions, or discriminant functions. For the health club example, a market value function measures the degree to which a potential new member is similar to a typical exist- ing member. The idea is very similar to cased-based reason- ing [SI. Existing members are considered as cases against which potential members are compared. Based on the val- ues of the market value function, one may rank all potential members according to their likelihood of joining the club. A cut-off point of the ranked list may be chosen based on var- ious criteria such as financial constraints. To some extent,  0-7695-1372-7/01 $10.00 0 2001 IEEE 517  mailto:maebashi-it.ac.jp   the use of market value function resolves some of the dif- ficulties with rule-based approaches. Moreover, the market value function can be easily updated when new information is available.

Some of the advantages of the proposed method are sum- marized below. The parlicular targeted marketing problem is formulated as a modified classical information retrieval problem. Many results from information retrieval can be immediately applied. The use of market value functions en- ables us to produce a ranked list, which may provide more flexibilities in some targeted marketing problems. A clear interpretation of the linear market value functions is pre- sented. Practical estimation methods for the needed param- eters are suggested. Results (feedback) from earlier targeted marketing may also be used to modify the market value function.

The rest of the paper is organized as follows. In Sec- tion 2,  we formally state the problem and investigate the form and interpretation of the proposed market value func- tion. A market value function is a linear (weighted) com- bination of a set of utility functions, one for each attribute.

Each attribute is considered to be one piece of information, and the utility of a particular attribute value states the con- tribution made by that attribute. The weight of an attribute represents its relative importance. The market value func- tion therefore provides it weighted summation of contribu- tion. In Section 3, we discuss the problem of estimating utility functions and weights of attributes. The utility of an attribute value is determined by the number of existing members having the value. The weight of an attribute de- pends on the distribution of attribute values among exist- ing members. An information-theoretic measure is used to compute the weights. With these initial estimations, one may produce a ranked list and select some top ranked ele- ments for a test run. For example, invitation letter may be sent to top ranked non-members. Based on the response, one may modify the weights of the market value function and utility functions.

2. A Linear Model for Targeted Marketing  We describe the proposed model for targeted marketing by focusing on the issues of knowledge representation and computation of market values. More specifically, we as- sume that each object is represented by its values on a finite set of attributes. We further assume that market values of objects can be computed using a linear market value func- tion. Thus, we may consider the proposed model to be a linear model, which is related to, but different from, the lin- ear model for information retrieval.

Let U be a finite universe of objects. Elements of U may be customers or products we are interested in market oriented decision making. The universe U is divided into  three pair-wise disjoint classes, i.e., U = P U N U D. The sets P,  N and D are called positive, negative, and don't know instances, respectively. Take the earlier health club example, P is the set of current members, N is the set of people who had previously refused to join the club, and D is the set of the rest. The set N may be empty. A targeted marketing problem may be defined as finding elements from D ,  and possitdy from N ,  that are similar to elements in P, and possibly dissimilar to elements in N .  In other words, we want to identify elements from D and N that are more likely to become new members of P. We are interested in finding a market value function so that elements of D can be ranked acc.ordingly.

Information about objects in a finite universe is given by an information table [7, 191. The rows of the table corre- spond to objects of the universe, the columns correspond to attributes, and each cell is the value of an object with respect to an attribute. Formally, an information table is a quadruple:  S = (:U,At, { V a  I U E At}, { I ,  1 a E At}) ,  where  U is a finite nonempty set of objects, At is a finite nonempty set of attributes, V, is a nonempty set of values for a E At, I ,  : U -+ V, is an  information function for a E At.

Each information function I ,  is a total function that maps an object of (U to exactly one value in V,. An information table represents all available information and knowledge.

Objects are only perceived, observed, or measured by using a finite number of properties [7].

A straightforward solution for the targeted marketing problem is the mining of characteristic rules for both P and N ,  or discriminant rules for differentiating elements of P and N .  The mined rules can then be used to classify ele- ments of D.  'There are extensive studies on such techniques.

Some of the difficulties with this straightforward solution have been mentioned in the Introduction. We therefore fo- cus our attention on an alternative approach.

A market value function is a real-valued function from the universe to the set of real numbers, T : U --+ 9. In the context of information retrieval, the values of T represent the potential usefulness or relevance of documents with respect to a query. According to the values of T ,  documents are ranked. For the targeted marketing problem, a market value function ranks objects according to their potential market values. For the health club example, a market value function ranks people according to their likelihood of becoming a member of the health club. The likelihood may be estimated based on its similarity to a typical member of P.

In this paper, we study the simplest form of market value functions, i.e., the linear discriminant functions. Let U ,  : V, --+ 8 be a utility function defined on V, for an attribute a E At. The utility U,(.)  may be positive, negative, or zero.

For v E V,, if u,(v) > 0 and I,(z) = v, i.e., ua( Ia ( z ) )  > 0, then attribute a has a positive contribution to the overall market value of z. If U ,  ( I ,  (z)) < 0, then a has a negative contribution. If u,(I,(z)) = 0, then a has no contribution.

The pool of contributions from all attributes is computed by a linear market value function of the following form:  .(.) = Wa%(Ia(.)) ,  (1) , ? A t  where w, is the weight of attribute a. Similarly, the weight w, may be positive, negative and zero. Attributes with larger weights (absolute value) are more important, and at- tributes with weights close to zero are not important. The overall market value of z is a weighted combination of util- ities of all attributes. By using a linear market value func- tion, we have implicitly assumed that contributions made by individual attributes are independent. Such an assumption is commonly known as utility independence assumption. Im- plications of utility independence assumption can be found in literature of multi-criteria decision making [2].

3. Mining Market Value Functions  The potential usefulness and effectiveness of the pro- posed model depends on, to a large extent, the estimation of the individual utility functions and the attribute weights, i.e., the coefficients of the linear market value function.

This section investigates various methods for estimating and mining market value functions. The estimation of utility functions draws from probabilistic models of information retrieval [lo, 11, 161. The estimation of attribute weights is based on information-theoretic measures of attribute impor- tance [9, 14, 15, 17, 181.

3.1 Utility functions  Utility functions can be defined based on either the pos- itive instances or both positive and negative instances.

3.1.1 Estimation from positive instances  There are several situations that require the estimation of market value function from only positive examples. It may happen that the negative examples are not available. Al- though negative examples may be available, they should be used very cautiously. For example, people who are not in a health club, or previous refused to join, perhaps will join the club. Thus one should not rule out the possibility that people similar to them may join the club. In other words, we  use positive examples for including potential new members, and we do not use negative examples to exclude potential new members. It may also happen that one can easily find a regularity (structure) explaining why an element belongs to P,  and cannot find a structure explaining why an element does not belong to P ,  as there may be a great diversity of reasons for the latter.

Consider an attribute a E At taking its value from V,.

For v E V,, let m(a = 1 P )  = m(v 1 P )  be the subset of P defined by:  m(v I P )  = {z E U J 2 E P,I,(z) = U } .  (2) It consists of elements from P whose value on a is v. Let (m(v 1 P)I denotes the cardinality of the set m(v I P) .  For two values v,v? E V,, if Im(w 1 P ) (  > Im(v? I P)l ,  then more elements from P having v as their value than those having U? as their value. Intuitively, one may say that an ob- ject having v as its value is more likely to belong to P than another element having w? as its value. Based on merely attribute a,  for two elements, z,y E U ,  with I,(z) = v, l,(y) = v?, and Jm(v 1 P)J > 1m(v? I P)l, we may say that the market value of z is more than that of y. This sug- gests that the value of the utility function U ,  : V, -+ ?Fz at v E V, should be propositional to the size of the set m(v I P) .  We therefore choose the following utility func- tion:  The values of U,(.) are between 0 and ]PI, which is based on a simple counting of elements having the value v in P. The set of elements P may be considered to be a sub- population of U .  One may also use a probabilistic version of the utility function:  .?,U) = Pr(a = ?U I P )  = Pr(v 1 P )  (4)  IPI P I  .

Im(v I P)I - - - -  Since /PI is a constant independent of any attribute, U: and U: will produce the same result in the linear model.

In general, one would expect an attribute to contribute more towards the market value of an element if its value is concentrated in the sub-population P. This can be done by comparing the conditional probability Pr(v 1 P )  and the unconditional probability:  Pr(a = v) = Pr(,) = - Im(v) I VI ?  where  m(v) = {z E U 1 I,(z) = U } .  (6)     For simplicity, we assume that m(v) # 8; otherwise, we can delete v from V,. The corresponding utility can be defined by:  If U:(.) > 1, the value 'U is concentrated more on the sub- population P ;  if U",IJ) <: 1, the value 'U is not concentrated on P. One would expect a positive contribution for the for- mer case and a negative contribution for the latter case. To achieve this, we use the logarithm transformation of as follows:  It follows that U:(.) > 0 if and only if uz(w) > 1, u",w) < 0 if and only if U",(.) < 1, and .",U) = 0 if and only if U:(.) = 1. In practical situation, it may happen that m(w I P )  = 0. The utility function is not defined. In this case, we may use the point-5 formula as was done in information retrieval [ 101:  This implicitly assumed that there is a notional sample of size one divided equally into P and N .

The quantity lUl/lPl is a constant independent of any attribute and will not effect the ranking. It can there- fore be removed from the utility function, and the value Im(v I P)l/lm(~)I can be used.

3.1.2  With both positive and negative instances, we have two sub- populations P and N .  The estimation methods presented earlier can be modified to take into consideration of the dis- tribution of attribute values in both P and N .

For an attribute value w E V,, it contributes more, or pos- itively, to the market value of an object if w appears more in the sub-population P than in the sub-population N, other- wise, it contributes less, negatively, to the market value of the object. Similar to utility functions and U:, we define two new utility functions:  Estimation from positive and negative instances  where  m(w 1 N) = {z E U I z E N, I , ( z )  = w}. (12)  The point-5 formula of U: is given by:  (13) (Im(w I P)I + 0.5)(INI + 0.5) (Im(v I N)I + 0.5)()PI + 0.5)' 4 1 3 2 ) )  = log  Since P and N are disjoint subsets of U ,  the new utility functions are not a simple replacement of U by N in U: and U:. The ratio INI/IPI is a constant independent of any attribute, it can be removed from the utility functions.

3.2 Attribute weighting  For the computation of attribute weights, we adopt information-theoretic measures [ 17, 181. For an attribute a, its Shannon entropy N p ( a )  in the population P is defined by :  where Pr( .  1 P )  denotes the probability distribution of at- tribute values in P. We define 0 log 0 to be 0 by extending function z log z to the origin by continuity. The entropy is a nonnegative function, i.e., H p ( u )  2 0. It may be inter- preted as a measure of the information content of, or the uncertainty about, a random variable a taking values from V,. The entropy reaches the maximum value log IV, I for the uniform distribution, i.e., Pr(w) = l/IVal for all w E V,.

The minimum entropy value 0 is obtained when the distribu- tion focuses o n  a particular vaIue vo, i.e., Pr(v0 1 P) = 1 and Pr(w 1 P )  = 0 for all v E V, and II # IIO. One may also interpret the entropy value as representing the de- gree of structuredness or diversity of a probability distribu- tion [9, 141.

A lower entropy value indicates a higher degree of struc- turedness. If an attribute has a lower entropy value, we can say that the distribution of its values is uneven in the pop- ulation P.  'Thus, the attribute may be more informative in predicating if an object belongs to P.  On the other hand, an attribute with a larger entropy is less informative, as the values of the attribute a are distributed more evenly in P.  A measure for weighting attributes can be designed so that it is inversely proportional to the entropy value. An attribute weighting formula, adopted from information retrieval [ 171, is given below:  Clearly, 0 :I wk 5 1. We have also assumed that IV,l > 1.

Otherwise, every object would have the same value on the attribute a,  and there is no point in using this attribute.

5 20    The entropy of attribute a in the entire population U is  H ( a )  = H(Pr( . ) )  = - Pr(v)  log Pr(w). (16) V?Va  It reflects the structuredness of the distribution of a's values in U .  For a more informative attribute, we would expect that it shows less structuredness in U than in the subpopulation P. We may use another weighting formula involving both H p ( a )  and H ( a ) :  given by:  The weight, -1 5 wi 5 1 gives the change of entropy values as we move from the entire population to a sub- population. A positive value suggests that attribute a shows more structuredness in P than in U ,  and a negative value suggests the reverse. It can also be seen that wi is a spe- cial case of w:, where H ( a )  takes the maximum value of  The well known Kullback Leibler divergence measure 1% V a l .

offers another attribute weighting formula [4]:  w: = D(Pr(. I P)IIPr(.)) (18)  It measures the degree of deviation of the probability dis- tribution Pr(. I P )  from the distribution Pr(.). From an information-theoretic point of view, the divergence can be interpreted as the difference between the information con- tained in distribution Pr(.  I P )  and that contained in Pr(.) about Pr(. I P).  The measure is nonnegative, i.e., > 0.

This quantity becomes minimum 0 if Pr(v I P )  = Pr(w) for all w E V,. The maximum value is realized when Pr(w0 I P )  = 1 for a particular WO for which Pr(w0) is the smallest [ 141.

We can also use both positive and negative instances for attribute weighting. An attribute is informative if sub- populations P and N are different from each other from the view point of the attribute. In this case, we have three sub-populations P,  N ,  and P U N .  Let H p ( a ) ,  " ( a ) , and H p u ~ ( a )  denote the entropy values of attribute a in the three sub-populations, respectively. If distributions of attribute values in P and N are similar, then both of them should be similar to the distribution in PUN. We would ex- pect a small difference of entropy values of a in P,  N ,  and PUN.  On the other hand, if distributions of attribute values in P and N are different, we would expect a large differ- ence. For this purpose, we adopt the following weighting formula:  where X p  + AN .= 1. The second term in the formula is the average of entropy values in two sub-populations P and N .

For any attribute value v, we have:  Pr(w I P U N )  = XpPr(?J I P )  + XNPr(v 1 N ) .  (20) Since -x log x is a concave function, the Jensen inequal- ity immediately implies that the lower bound of w: is 0, i.e., w: 2 0. It reaches the minimum value 0 when the two distributions in P and N are identical. It can also be shown that wt reaches the maximum value, -[A,  log Xp + AN log A,], if the distributions are totally direrent, namely, Pr(w I P )  # 0 whenever Pr(v I N )  = 0 and Pr(w I P )  = 0 whenever Pr(v 1 N )  # 0.

In terms of Kullback Leibler divergence, tu$ can be ex- pressed by [ 151:  W t  = XpD(Pr(. I P)l /Pr( . ) )  (21) +&vD(Pr(. I N)IIPr(.)).

The weighting formula w: uses the first term of tu:.

Thus, w$ is an expected divergence considering two sub- populations. It may be considered as a more generalized version of w:.

The entropy function is determined by only probability values in a probability distribution. It is independent of how these probability values are assigned to different attributes.

Different probability distribution may produce the same en- tropy value. For instance, the following distributions pro- duce the same entropy value, although they are totally dif- ferent distributions:  Pr(v1 I P )  = 0.5, PT( 'u~  I P )  = 0.5, Pr(vg I P )  = 0.0, Pr(7J4 I P )  = 0.0;  Pr(V1 I N )  = 0.0, PT(VQ I N )  = 0.5,  PT(Q I N )  = 0.0, P T ( w ~  I N )  = 0.5.

The difference between Hp(a) and " ( U )  cannot tell us if P and N are similar based on attribute a. This mainly stems from the fact that there is no inherent relationships between probability distributions Pr( .  I P )  and Pr( .  I N ) .  On the other hand, the proposed measures wi and wt do not suffer from this problem. In those formulas, we use probability distributions from related populations.

4. Conclusion  Targeted marketing is a potentially important area of ap- plications for data mining. There are different types of targeted marketing problems. While standard data mining techniques are useful for some, new techniques are needed for others. In this paper, we focused on a targeted mar- keting problem characterized by identifying potential new  J L  1    members based on the characteristics of existing members.

For this type of targeted marketing problems, approaches for mining characteristic rules or classification rules may not be entirely suitable. A linear model has been proposed, in which the market values of potential new members is computed by a linear combination of utility functions on at- tribute values. Our approach is obtained by adopting results from disciplines such as information retrieval, case-based reasoning, and multi-criteria decision making.

We have focused our attention on the formal develop- ment of the proposed linear model. The interpretation of linear market value functions was given based on intuitive arguments. Various methods for estimating parameters of market value functions were suggested. They are based on probability related interpretations of utility functions, and information-theoretic measures for attributes weight- ing. Each of the suggested methods seems intuitively ap- pealing, and captures different aspects of our perception of the utilities of attribute values and importance of attributes.

Many market value functions can be obtained by using dif- ferent combinations of utility functions and weighting for- mula. The theoretical investigation is only the first step to- wards the specific type of targeted marketing. It may be dif- ficult to judge which of them are better based solely on the- oretical argument. The effectiveness of the proposed model and various methods for estimating parameters need to be evaluated using real world examples.

The approach presented in this paper is different from, and complementary to, commonly used data mining ap- proaches for mining rules. It is important to realize that data mining is much application oriented, and different ap- proaches need to be explored for different problems.

