Computing Frequent Graph Patterns from Semistructured Data

Abstract Whereas dara mining in structured data focuses on fre-  quent data values, in semi-structured and gmph data the emphasis is on frequent labels and common topologies.

Here, the structure of the data is just as important as  ifs con- rent. We study the problem of discovering typicalpattems of graph data. The discoven-d panems can be useful for  many applications, including: compacr representation of source informarion and a mad-map f o r  browsing and querying in- formarion sources. Dificulties arise in the discovery task from the complexity of some of the required sub-tasks. suck as  sub-graph isomorphism. This paper proposes a new al- gorithm for  mining graph data, based on a novel definition of support. Empirical evidence shows practical, as well as theoretical, advanrages of our approach.

1. Introduction Due to increasing amounts of data collected by various  companies and institutes, the importance of data mining has grown significantly over the last several years. Tradi- tional data mining is applied mainly to structured data and Rat files. Lately. there has been growing interest in min- ing semi-structureddata, such as web data, XML data, large object databases, etc. {[31,[101,[191}. Discovery and under- standing of patterns that statistically represent a sufficiently large part of the database can be helpful in the following ar- eas: improving database design [5],  efficient indexing [7], user preference based applications [6], user behavior pre- dictions, database storage and archival [4J.

In structured data-mining, frequent data values and their common appearances are of interest. For mining semi- structured and graph data, the focus is on frequent labels and common appearances of sub-sets of such labels (in terms of XML [2], one looks for frequent occurrences of structures of elements or attributes - see section 6.1.) Most of the work done so far has dealt with either single path pat- terns [31 or tree-like patterns [10],[19]. However, much of the data on the web is graph-like, both acyclic and cyclic.

We found only one graph mining paper, [91, but its con- structing algorithm and support definitions are too simple to handle the general case. In this paper we present an algo- rithm for mining frequent patterns in semi-structured data, where the data is modeled as a labeled graph - either di-  rected or undirected, depending on the mining goals. In our scheme, unlike related work, topology of permissible pat- terns is not restricted. Frequent patterns may or may not be labeled (or partially labeled). Unlabeled patterns can be handled as a special case of our approach.

In any data-mining algorithm which uses an analog of Apriori [ l ]  (our algorithm belongs to this general category), two issues arise: (1) the basic building block from which frequent patterns are composed; (2) making sure that at each step of the algorithm all frequent patterns for that step are found. As long as correctness is maintained, it is beneficial to make the building blocks as large as possible. in order to minimize the number of candidate patterns. Our idea is to use edge-disjoint paths as building blocks. A major issue in this work was proving that our edge-disjoint based algo- rithm is complete. This is the first major contribution of this  In attempting to find frequently occumng subgraph pat- terns within a graph, computing the Frequency of occur- rence of the pattern in the larger graph (the database), also called supporr compurarion, is a major issue. Even for sim- ple cases, such as association rules, it is desirable to min- i m i x  tbe number of candidates, as support computation is expensive (see section 6.1.) For graph patterns, minimizing the number of candidates is even more critical - as we show that in the worst case computing support of a graph pattern is NP-hard! In order to decrease the number of extremely expensive support computations, we must discard, as early as possible, as many candidate patterns as possible.

As the Apriori algorithm does a good job of dismiss- ing unlikely candidates by avoiding their creation entirely, we believe its adaptation to graph patterns should be ex- tremely useful, even if it entails considerable overhead over the naive methods of generating and testing patterns.

Despite the fact that several algorithms for finding tree- like frequent patterns in semi-structured data were proposed during the last years ([101,[191), no general definition of support for frequent pattern in a semi-structured database exists. A second contribution of the paper is our approach to support measures for frequent graph patterns in a graph database, and the refined definition of support.

To prove the feasibility of our scheme we imple- mented the proposed algorithms, tested them on some XML  paper.

0-7695-1754402 $17.00 Q 2002 IEEE 458    databases and synthetic graphs, and compared them to the naive approach for counting graphs patterns.

The rest of this paper is organized as follows. Sec- tion 2 reviews formal definitions of data mining and graph- theoretic terms and introduces new definitions used in spec- ifying the algorithm. Section 3 discusses the issue of sup- port. Section 4 describes the graph mining algorithm. Ex- perimental results appear in Section 5. An evaluation of our scheme and its comparison to other work is discussed in section 6.

2. Background  This section reviews terms from prior work, including graph theory, and data mining literature.

An Apriori-based algorithm is an algorithm [hat finds frequent item sets in a database using the following prin- ciples: (1) frequent single items are found by scanning the database, and storing them in the set called the 1st item set; (2) the i + 1st item set is constructed from pairs of items from the ith item set; (3) after the ith set has been con- structed, all non-frequent items are removed.

2.1. Graph facts  A labeled graph is a graph that has a label associated with each node v, denoted by label(v). Given two graphs G? = (VI, E?) and G? = (V?, E?), a labeled isomorphism G? E.+ G? between them is any isomorphism : V? + V? such that for any i E V? label(i) = label($(i)). P is a graph panern in graph G if it is isomorphic to a connected subgraph of G. The set ofinstances of pattern P in graph G is the set of all subgraphs of G that are isomorphic (if G is not labeled) or label isomorphic (if G is labeled) to P.

A path numberp(G) of a graph G is the minimal number of edge-disjoint paths into which G can be decomposed. A set of p ( G )  edge-disjoint paths covering all edges of G ex- actly once is called a minimal path cover of G. Removing path P from graph G, denoted by G \ P, consists of remov- ing all edges of P from G and later removing all stand-alone nodes. For computation of a path number we rely on well- known graph-theoretic facts:  1. A connected undirected graph G = (V, E) is Eulerian (can be covered by a single cyclic path) iff for every v E V, d ( v )  is even. A connected digraph G = (V, E) is Eulerian (can be covered by a single directed cyclic path) iff forevery U E V,  d + ( v )  = d - ( v ) .

2. For any connected undirected graph G = (V, E) the size of its minimal path cover is 1 if G is Eulerian and I{v I v E V,d(v) isodd}l/2othenvise.

For any connected directed graph G = (V, E )  , p ( G )  = 1 if G is Eulerian and p ( G )  = ( C u C v l d + ( v )  - d-(v)1) /2  otherwise.

The path number of a graph can be computed in linear time since only node degrees are required. In our data mining  algorithm iteration, we keep in the kth frequent item set only graphs with path number k. We produce members of the (k + 1)th frequent item set from the kth item set. We need to show that the above is always feasible: Theorem 2.1 If G is a connected graph and its minimal path cover P ={PI, ..., p k }  has size k, then G? = G \ Pi has a minimal path cover of size k - 1 for all i E 11, k] .

our scheme from two smaller graphs.

Theorem 2.2 Let G = (V, E) be a connected graph with p ( G )  = n , n >  2andP1, ..., P,itsminimalpath decomposition. Then there exist j, k E [l, n] ,j # k such that graphs G \ Pi and G \ P k  are connected.

These two theorems together are needed to assure that using path number as an item set parameter is correct (see Section 4.) The proofs can be found in [IS].

2.2. Lexicographical ordering  In most Apriori-based algorithms (k - 1)-itemsets are combined into k-itemsets in a lexicographical order which assures completeness. A similar method is applied here in combining graphs. For this purpose, we use a canonical representation of paths and path sequences. We thus define a lexicographical ordering (see [18] for details) over path pairs, using node labels and degrees of nodes within paths.

Based on the above ordering, an ordering between path se- quences is defined and sub-sequentially a notion of mini- mality. called P-minimal is defined over paths sequences.

This minimum is not necessarily unique.

2.3. Graph merger  During the ?merge? phase we need to combine graphs, each composed of paths. The next set of definitions de- scribes composition of graphs and operations necessary for removing a path from a graph. joining two graphs with com- mon paths, and adding additional ?intersections? (common nodes) to a pair of paths within a graph.

We define a new structure, called a cornpasifion rela- tion, for the purpose of representing a graph as a union of edge-disjoint paths. This structure is a table (a two- dimensional array) with graph nodes as rows and paths as columns. A cell in row i and column j contains a non- null value if and only if the j-th path contains the i-th node of a graph. Nodes of the paths can be namedienumerated differently from the nodes of a graph. Figure 1 shows a graph consisting of 3 paths: PI, Pz, P3 and Table 1 presents a corresponding composition relation (1 symbolizes a null value). A composition relation on paths PI, ..., P,, is de- noted by C(P1, ..., P,) or. C i f  paths are known unambigu- ously. The order of rows in a relation is insignificant, i.e.

two composition relations are considered to be equal (=) if their tables contain the same rows, regardless of their order.

Given a proper composition relation C on n paths, one can construct a corresponding graph in a unique way by treating rows of the table as graph nodes and defining edges  We show that a graph with k paths can be constructed by     Figure 1: Graph consisting of 3 edgedisjoint paths  Table 1: Composition relation C(Pl, Pz, P3)  (i, j )  when two nodes of the same path P appearing in rows i and j ,  have an edge between them. This operation is called agraph realization on composition relation and is denoted by n ( P l ,  ..., P,, C) or n(C) for short.

An operation of subtraction of a path P; from composi- tion relation consists of eliminating the i-th column from a composition relation table followed by subsequent removal of all rows that contained only null values. This operation is denoted by C(P1, ..., P,)\P; or. shorthand, C \i. If sev- eral paths P;, i E I are to be subtracted, we write C \ I or C I f j l j g r )  (aprojection of ContopathsP,,  j $ I).

Next we describe operations of "joining" two IC-path graphs that have k - 1 paths in common and adding nodes common to two paths within the graph. Let C1 and CZ he composition relations, and let I ,  and I ,  be sets of indices such that CI Ill= CZ A bijective sum BS(C1, Cz, I1,IZ) is a composition relation that is obtained from the table of Cl by adding columns for all the paths that are in CZ but not in Cl (taking into ac- count a possibly different order of rows in Cl 1 1 ,  and CZ 1 1 ~ ) .  Tables 2 demonstrates a bijective sum C3 = BS(C1, CZ, {1,2}, {l, 2)) of two composition relations CI(PI,PZ,P~) and C2(Pl ,Pz,P4)  and Figure 2 shows graph realizations GI = ~ ( C I ) ,  Gz = n(Cz) and G3 = O(C3).  Null values were omitted from the tables.

A splice @;,j of two composition relations CI(PI ,... ?Pn) and Cz(Pi ,Pj) ,  1 5 i , j  5 n, is a composition relation that turns every node common to P; and Pj in CZ, into the node common to Pi and Pi in Cl as well. A splice is a merger of two nodes belonging to two different paths in a graph into a single node. It is achieved by copying the table of Cl and merging the rows of U E Pi, U E Pj in C1, for every u,u appearing in a single row of C Z .  Table 3 describes composition relations CI (P I ,PZ ,P~) ,CZ(PZ,P , )  andC3 = CI $2,3CZ.  Figure  Table 2: Bijective sum  U4 U5 b3 ~3 215 b3 U6 c1 U6 dz U7 cz U7 d3  t  Figure 2: Graph realization of a bijective s u m  3 shows corresponding graph realizations GI = 0(C,), Gz = O(Cz)  and G3 = 0(C3).

Figure 3: Graph realization of a splice Bijective sum and splice operations are used in our min-  ing algorithm to construct larger graphs from smaller ones.

The standard measure of support in the literature is as follows. Let 0 5 U 5 1 and let D be a set of transactions.

A n i t e m s e t I = < i l ,  ..., ir >iscalledfrequentifS(I)  =  3. Support measures     2 U .  Here, S is called the support of item set I.

This definition of support does not suit structured databases very well. When trying to define support in terms of fraction of the information represented by all instances of a pattern in the database, the following issues arise: (1) a ?frequent? pattern should obviously appear more than once in the database - otherwise, the database graph itself would be considered a frequent pattern; (2) instances of a frequent pattern that have common edges should have less ?weight? in a support measure than instances that are disjoint. (See Figure 4); (3) the number of pattern instances can be greater than the database size, the standard support measure may result in a support greater than 1, which is undesirable.

A - a p p -  3 ,tm% b?, 001 indrpe*?llY  Dam- graph  Figure4: Graph pattern support  Suppon of pattern P in graph G is a measure of fre- quency of instances of P in G. A support measure is a function that, for each pattern P i n  graph G, returns a num- ber in range [0,1]. A pattern P i s  calledfrequenr if its sup- port measure S ( P )  is higher than a support threshold TS.

Our support measure uses the following constraint.

Definition 3.1 A support measure S is admissible if for every P, S ( P )  2 0 and for all PI ,  P2 such that PI Pz we haveS(P1) 2 S(P2).

Let D be a (not necessarily connected) database graph.

Let G = (V, E )  be the pattern for which we compute sup- port. Let A,, ..., A, be all instances of G in database D  (i.e. subgraphs of D that are label isomorphic to G). This set of instances is denoted by AG. Two instances A;,Aj are said to be intersecting, A, A A3, if they have a com- mon edge. The instance graph IC is an undirected graph whose nodes are instances from AG and edges are all pairs (Ai,Aj) whereAiAAj.

We use here an operation of clique contraction, which is a replacement of a clique GI in a graph Gz by a sin- gle new node vncnew and (optionally) adding some of the edges (u,vnew) where U E GI \ Gz such that Vu E GI, (u,v) E E(G) .  We also use an opposite operation of node expansion, which is a replacement of a node v in graph G, by a new graph Gz (disjoint from GI) and a re- placement some of the edges (U, v), U ? V(G1) by a set of edges {(U, U?) I U? E V(Cz)}. An operation of node ad- dition, which is defined as adding a new node v to a graph, where v may or may not be connected by edges to any of the previously existing nodes, is also used here. Using these operations we can characterize all admissible support mea- sures using the following theorem: Theorem 3.2 A positive valued function on IG is an admissible support measure if it is a non-decreasing under the following operations on IG: clique contraction. node addition, edge removal, and node expansion.

Due to space limitations the proof is given in [18]. It can be shown that the maximum independent set computed over the instance graph is an admissible support measure according to this theorem, since all the above operations do not reduce the size of a maximum independent set of an instance graph. This measure is in fact the maximal number of edge-disjoint instances of a graph pattern in the database. We denote by sire(D) the number of edges in the database graph D and define support of pattern G as S(G)  = where MIS denotes the maximum in- dependent set size of a graph. This measure reduces to the standard support measure for transaction databases.

4. Frequent graph-pattern algorithm This section presents algorithm pseudocode for mining  frequent graph patterns, which works for both directed and undirected graphs. We use following notation: (a) Il de- notes a path sequence PI ,  ..., 9; (b) II\i denotes a path sequence PI, ..., Pi-l,Pi+l, _.., 9; (c) x - { i , j }  denotes the sequence 1, ..,i - 1, i + 1, . . , j  - 1 , j  + 1, .., k; (c) L, is a set containing frequent i-path graph patterns, C, is a corresponding candidate set.

4.1.

In a preprocessing phase, we find all frequent edge-  disjoint paths (including paths with cycles), starting with frequent edges. In phase 1 we find all frequent single path graphs. In phase 2, we find all graphs composed of two paths, i.e. all possible intersections between pairs of paths from phase 1. In phase 3 we try to merge all pairs of graphs  The intuition behind  the algorithm     with n - 1 paths in an attempt to produce graphs with n paths. We assume that some admissible support measure is used, for example the one described in section 3.

Phase 1 constructs the frequent paths by adding one edge at a time. Phase 2 constructs the frequent graphs with path number 2. It does it by uniting one-path graphs. The non- trivial steps are steps 2,3 and 4, where in step 2 all possible compositions of the two paths are considered, and in step 3 both the path number and the support measure are calcu- lated; step 4 removes all non-minimal isomorphic graphs.

Phase 3 constructs the frequent graphs with path number k from graphs with path number k - 1. The non-trivial step is step 3. In case 3(a) the graph is constructed by finding the common k - 1 subgraph structure in a pair of frequent k-path graphs and joining them, using the bijective sum op- eration, into a single (k+ 1)-path pattern. In case 3(b), Lz is scanned and for any combination of P; and P, which is fre- quent, the nodes common to P, and Pj in this combination are set to be common in the candidate graph as well. Since joining two patterns directly (using BS) may overlook sev- eral common vertices of P, and Pj,  we need to ?add? miss- ing common vertices to the candidate pattern using splice.

Again, steps 4 and 5 are the isomorphic graph removal and support computation as in phases 1 and 2. The final step of the algorithm (not shown here) is removing all frequent suh-graphs which are not maximal, i.e. contained in larger frequent graphs (this step must be done last to avoid over- looking the larger frequent graphs.) The proof of correct- ness (given in [IS]) of this algorithm shows that each of the 3 phases abovc IS sound and complste Aleorithm 1 I:rr.auenl Ddlhs - Phase # I  ~lcx1u31 descnotion)  1.  Scan the database and find all frequent labeled edges.

Store them in the first frequent set.

2. Build the k-th candidate set in the following manner: try adding frequent edges to every frequent path of length (k - 1) (stored in (k - 1)-th frequent set) in such a way that a path is obtained. Add this path to the candidate set. Once the candidate set is constructed.

evaluate support for every pattern, and store frequent ones in the k-th frequent set.

3. If the k-th frequent set is empty, output the set L1 of all frequent paths obtained so far and stop.

5. Experimental results An empirical evaluation of our algorithm, compared to  two ?naive? algorithms, is provided below. Two types of databases were used: synthetic, where we can control both the topology and labeling of graphs, and a real-life XML ?movies? database [151.

5.1. Experimental setting  The experimental environment is a Sun Ultra-30 work- station running at 247 MHz and 128 MB of main memory.

Algorithm 2 Frequent path pairs - Phase #2 1. Compute frequent paths using algorithm I ,  and store  these paths in the set L1. Let C, = 0, Lz = 0.

2. For every pair of frequent paths PI, P2 E L1 and  every possible label preserving edge-disjoint composition relation C on V(Pl) ,  V ( P Z )  add tuple < PI, Pz, c > to CZ.

3. For every tuple < P, Q, C >E CI, if G = Q(P, Q, C) has path number 2 and is frequent, add { < P, Q, C >} to Lz.

4. Remove all non P-minimal tuples from Lz  S. Output{R(P,Q,C) I<P,&,C>ELz) .

We use two software products: (1) for graph isomorphism computations we use [8]; (2) for maximal independent set size, we use wcclique (see Ill]) on a a reverse of graph is built to obtain maximum independent set size. We use graph generation schemes described in [ 121 in order to produce all non-isomorphic graphs of a certain size.

The real XML file we used is a portion of the ?movies? database. XML elements are treated as nodes, and inheri- tance relationships and references - as edges. The detailed procedure can be found in [181.

5.2. The implemented algorithms  We implemented our mining algorithm for fully labeled graphs described in section 4, as well as the two types of ?naive? algorithms discussed below. The latter were used in order to compare run-time and number of generated can- didate patterns with our algorithm, due to lack of compet- ing algorithms for general pattern-mining algorithms in the literature. The same admissible support measure (a maxi- mum independent set of an instance graph) was used for all algorithms. Tests were conducted multiple times and time averages were taken to eliminate factors of system load.

The first naive algorithm is based on generation of all non-isomorphic graphs of a certain size. The main idea is to produce connected graphs one by one, find all pos- sible legal labelings for it and compute the support of all resulting graphs until no frequent graph of size K can be found. However, after a graph size exceeds 10 the number of graphs generated is very large, which made using this al- gorithm on large graphs somewhat unrealistic. The second algorithm is based on finding all frequent graphs with K edges and later extending them to graphs with K + 1 edges by either adding a new node and an edge to a frequent graph or by adding an edge between two existing nodes of the fre- quent graph with K edges. This algorithm is more efficient than exhaustive generation, but can produce many isomor-     Algorithm 3 Frequent graphs - Phase #3  N, E, L  C, Fp I, SC  ST N#2 naive edge addition algorithm  #of nodes, edges and labels in the database  #of candidate and frequent patterns # of isomorphism and support computations total time (seconds) spent on data mining time in sec. of support computations  S support threshold in %  -  A ouralgorithm # serial number of a database graph  1. Set k = 3.

2. Set Ck =0, Lk =0,  3. For every sequence of k paths Il such that  = 0  (a)Let CBS = BS(Cl, Cz,k - { i , j }  ,E -  {i ,j}) If G = O(n, CBS)  has path number k, add  (b)Forevery<P,,P,,C>ELZ,if G = O(n, (CBS e,,, C) has path number k, add  t =< n , c B S  > t o c h .

t = < n , c B S @ , , , c > t O c k .

4. Remove non P-minimal tuples from Ck.

5 .  For every t E C k  add t to L k  if n(t) is frequent.

6. If Lk = 0, output U:=;' { O ( t )  I t E L,} U L1 Otherwise, set k := k + 1 and go to step 3.

phic copies of each graph.

5.3. Experimental results We investigated behavior of the algorithms using the fol-  lowing performance parameters: ( I )  number of candidare patterns produced by an algorithm during data mining; (2) number of isomorphism compurarions during data mining, and overall number of support computations; (3) total rime spend on data mining ( not a CPU time) and on support computations.

Table 5 presents results of testing on trees and Table 6 on sparse graphs. The notation used in all three tables are explained in Table 4. For our algorithm the number of can- didate patterns can sometimes he less than the number of frequent patterns since frequent nodes and edges are com- puted directly without generating candidate patterns.

Table 4: Notations  Since the run time of all algorithms depends mainly on support computations, and the support computation time of a single pattern G i n  its turn depends on the number of sub- graphs in a database graph that are of the same size as G,  the time spent on suppon computation increases drastically as the database graph becomes dense.

Since our implementation needs to generate all appropri- ate subgraphs of a database graph, find among them all sub- graphs that are isomorphic to the pattern in question, build an instance graph and find its maximum independent size, testing our algorithm on dense graphs seems to be extremely time consuming. An additional consideration was the fact that most real-life databases represent sparse graphs rather than dense ones. Therefore, we decided to limit our tests to trees and sparse graphs and to choose a support tbresh- old that, on the one hand, will not limit the output to trivial graphs (nodes and edges) and on the other hand, will not turn eve  ?able 5: Exoerimental results for trees connected subgraph of a database to frequent.

# I a I 6  Fro]  N.L,S,FP Alg 11 C.I. SC I ST 4 0 4 7 1 1 5  N#Z 11 I002492 I 41  A 5 0 4 7 8 1 6  NW  A 5 0 6 3 8 3 7  N#Z  A 5 0 8 3 8 2 7  N#Z  A 6 0 4 5 8 1 5  N#Z  A  6 0 6 5 8 4 4  N#Z A  6085% 14 N#2 A  6: Experiment  12698 110  - s' I' I .

I  I2 I f  -  -  - TT    -  mi - Tr  -  - 'abies 5 and 6 we conclude that our algorithm runs  faster even though it conducts more isomorphism checks than naive edge addition algorithm. It happens because our algorithm produces fewer candidate patterns, and thus less time is wasted on support computation.

Table 7 contains the number of frequent patterns found in six different subsets of movie database with different sup-     port values. It shows that the structure of the database (a tree as in set #6 or a sparse graph) has more impact on the number of fre uent atterns than the support value.

Table 7: %vie bB support vs frequent patterns Data set Properlies  12656nodes. 13878 edges. 112 labels  2757 nodes, 2794 edges. 76 labels 1293 nodes, 1292 edges, 91 labels  ~  suppan 90%  80% 70% 60% 50% 4 0 8 30% 20% 10%  - #I  -  3 3  T 3 3 4 4  5 4 6 5 12 I O   7% 84  As seen from Table 7, for the same values of support, the number of frequent patterns is smaller, and thus the ex- ecution time is much smaller in the movie database than in the synthetic one. This indicates the feasibility of our algo- rithm in real-life cases. As the graph becomes larger, the number of frequent patterns for the same support value de- creases since a larger amount of edge-disjoint instances is required for each pattern in order to pass the support thresh- old. Finally, Figure 5 shows some of the frequent patterns we found in the movies database. Note that the patterns do not contain titles of movies or names of directors, since these are present only as artributes and not as tags in the XML database. Related research [131 attempts to treat at- tnbutes and values of an XML database  movie =tor rnwx dimtor a i  fihhsel  movie movie  Figure 5: Pattern examples  6. Discussion and related work 6.1. Evaluation  In most semi-structured data, there is no distinction be- tween values and labels. Usually, the 'label' of a leaf node is its value, using our approach. In XML, one can have  attribute values in internal nodes. One can then either in- clude values as a separate two-node branch (attribute, value) and apply our approach, or filter out attributes with non- interesting values (e.g. identifiers) [13]. Another approach is to find the structures first, and then build a separate table containing attribute values as in [131.

Another issue is complexity. The complexity of our algo- rithm is exponential in the size of the pattern. This complex- ity is inherent to apriori-like algorithms. The complexity of Apriori is due to the fact that the number of frequent pat- terns can be exponential, and the complexity of any graph mining algorithm is bounded by the need to find all sub- graphs of a database isomorphic to a given pattern in order to evaluate its support. Therefore isomorphism computa- tions done by our algorithm do not affect the complexity, as the graph isomorphism problem is at worst exponential on a size of a pattern, not the database size. The main goal of a mining algorithm should thus be to decrease the number of candidate patterns, and by doing so decrease the number of support computations. Our approach is feasible, because the number of patterns remaining from one phase to the next is reduced considerably, according to our experiments.

6.2. Related work As mentioned in the introduction, there is little related  work on mining frequent sub-graphs in a graph database.

Since we assume the reader is familiar with the basic al- gorithms for mining association rules, e.g. Apriori [l]. we only review here the most relevant papers, [31,[10l,[191,~91.

131 presents two algorithms for mining frequent directed simple path patterns in a web environment. Both algorithms are based on an algorithm called MF, that finds all maxi- mal forward references in a set of traversal sequences con- tained in the database. The MF algorithm is a DFS algo- rithm which eliminates backward references, and outputs a set of linear paths. The goal of the two mining algorithms is to find frequent sequences in these paths. The support measure here is equivalent to the one used for association rule support ([I]) and equals the number of maximal for- ward references containing some pattern, divided by a total number of maximal forward references in the database. The main differences between the algorithm of [31 and ours is that the former handles only linear paths, making its sup- port measure computationally trivial.

Paper [ 101 also discusses the problem in the context of a web environment - finding frequent patterns in logs of web accesses. Rather than dealing with linear paths, it exam- ines tree-like structures. Furthermore, the number of times a user visits a web page within a single navigation path is ignored. One important restriction in this paper is that only mored trees are considered, i.e. trees whose root is the same as the root of the entire web database! Naturally, this limits the complexity of the problem and the algorithm.

The problem is discussed in a wider context in [19l.

That paper describes an algorithm for finding maximal fre- quent tree-like patterns in semi-structured documents, rep- resented in the standard OEM model. Although this algo- rithm searches only for tree-like patterns, it can also handle patterns containing cycles by transforming them into trees.

The differences between [I91 and our work are: ( I )  fre- quent patterns produced by [I91 must contain the docu- ment's root whereas our algorithm finds arbitrary patterns; (2) our support denotes the fraction of the database repre- sented by a certain pattern, and not simply the number of its instances; (3) with arbitrary patterns, replacing a cycle- causing edge by an edge to a leaf node will not work.

Finally, algorithm [9], as in our paper, finds frequent graph patterns hut uses edges as building blocks. Our a p proach, for real-world databases, generally provides faster convergence of the algorithm. Additionally, [9] handles transaction databases only, thus avoiding the problem of support measure definition addressed in our work.

In summary, the ideas presented in the above papers, have influenced our work considerably. However, the ex- tensions of these ideas to general graphs are not obvious and are the major contributions of this paper.

7. Summary  An apriori-like algorithm for retrieving frequent graph patterns from a given set of graphs is the central issue in this paper. In contrast with most existing work, the pattern can be either a directed or an undirected graph, and may contain cycles. The added functionality can support data mining on the increasing fraction of on-line documents, which consist of blocks connected by references. Knowledge ahout typi- cal structure of documents is helpful in analyzing complex repositories of semistructured data (e.g. XML databases, the web), and is potentially useful for querying data, index- ing it and storing it efficiently.

In a general topology, the issue of support becomes non- trivial - meeting intuitive desiderata such as monotonicity of the support measure, while being consistent with sup- port measures defined for existing data-mining schemes, is important. We defined a notion of support-measure admis- sibility, and presented one such measure, based on indepen- dence of pattern instances.

In searching for frequent patterns, candidates are con- structed using frequent paths. The scheme is evaluated em- pirically and is promising, as it shows a decided advantage over competing algorithms.

The scheme proposed here can be extended in several ways: (a) using more complex building blocks; (h) adapting extend the algorithm to the dynamic database model; (c) treating similar patterns equivalent, for example, by using hisimulation [I41 as a criterion of pattern resemblance; (d) exploring additional admissible support measures.

