On Reconfigurable Association Rule Mining

Abstract-As one of the most important techniques for knowledge discovery, association rule mining is known to be  very computational intensive. Many hardware architectures  were proposed to speed up association rule mining. Generally,  theses methods are based on the usage of systolic arrays with  preserved hardware resources. In this paper, we propose a  reconfigurable hardware architecture which is designed to use  the hardware resources more efficiently than existing methods.

Explicitly, our platform can dynamically allocate cell resources  according to the number of items of a candidate itemset. At the  same time, our platform is able to deal with the generation of  initial frequent itemsets. Note that the number of frequent  item sets with fewer items is much larger than that of frequent  item sets with more items. In view of this, our platform is  designed to use less hardware resources to deal with frequent  item sets with fewer items and reconfigure the hardware with  more resources to handle frequent itemsets with more items.

As such, we can process more frequent itemsets than those  employing the architecture with preserved resources. In view  of the growing complexity of graph mining, it has become  essential to explore the approach of hardware assisted mining  for better mining efficiency.

Keywords-hardware; reconfigurable; graph; mining

I. INTRODUCTION  There are an increasing number of applications for data mining nowadays. The applications fall into many areas, including Web applications, telecomm, finance, grocery, to name a few. Association rule is one of the most important techniques used by data mining. Apriori is one of the most popular methods for association rule mining. It is known that Apriori-based [1] method is very computational intensive. In addition, the transaction database gets larger and larger significantly. As a consequence, how to speed up the processing time is of increasing importance. Among others, hardware-enhanced data mining is one solution to handle such intensive database processing [2], [3], [4].

There has been a growing interest in developing data mining algorithms on graphs [9], [10], [11]. In view of the growing complexity of graph mining, it has become essential to explore the approach of hardware assisted mining for better mining efficiency. In this paper, we propose a reconfIgurable hardware architecture which is able to use the hardware resources more efficiently. Our platform is in   essence based on systolic array [7], and is unique in that instead of preserving cell resources, our platform can dynamically reconfigure whole hardware resources to cell units according to the length of a candidate item set. In general, it will be more efficient to allocate cell resources based on the item number of a candidate itemset, since, as such, we can handle more candidate itemsets as compared to the preserved architecture that was previously used. It is noted that the number of candidate item sets is much larger than the number of processing cell units, especially for candidate item sets with two or three items. Hence we usually need to rescan transaction database several times for loading candidate item sets one part at a time. Such rescanning consumes lots of time and is considered the performance bottleneck for association rule mining. Our platform can speed up the processing time a lot by significantly reducing the rescan time.

In addition to the saving of rescanning, the other unique advantage of our platform is that it is able to derive frequent item sets with one item. As will be seen in this paper, our platform just takes one pass of the transaction database to generate the results, as opposed to much more overhead that is required by previous methods. By properly reconfIguring the whole hardware resources when so necessary, our platform outperforms previously proposed hardware? enhanced mining methods. To make the mining of large graph feasible, we consider a hardware assisted mining, like the one we discussed in this paper, a direction worth of our attention.

The paper is organized as follows. Section II surveys related work in association rule mining. Section III describes the system architecture of our platform. Section IV explains how to implement "Frequent Itemset Generation Unit".

Section V describes "Candidate Itemset Generation Unit".

and Section VI concludes this work

II. RELATED WORK  In this section, we discuss two previous hardware? enhanced mining methods proposed in [3] and [4]. In [3], the authors speed up the Apriori algorithm based on a systolic array with several hardware cells. Each cell can perform an ALU ( i.e., item larger than, smaller than, or equal to) operation. Since all the cells can operate simultaneously, the performance can be improved with respect to a single    processor. Note, however, the nwnber of cells in the systolic array is fixed. If the number of candidate itemsets is larger than the number of hardware cells, the pattern matching procedure has to be separated into many rounds. Hence, the improvement could be limited.

In [4], the authors proposed a faster architecture, based on systolic array, to speed up the Apriori algorithm using the concept of DHP [5], [6]. DHP improves Apriori algorithm by filtering out infrequent candidate itemsets with hash table scheme. DHP also employs a pruning scheme to eliminate infrequent items in transactions with trimming information.

Both of these two works adapt fixed hardware resources to a cell unit. In addition, they did not address the generation of initial frequent item sets with one item. Hence, we address these issues in this paper.



III. DESCRIPTION OF OUR PLATFORM  The block diagram of the entire hardware architecture is illustrated in Fig. l. The transaction database is read out from DRAM (Dynamic Random Access Memory) and shifted into frequent itemset generation unit. The frequent itemset generation unit is responsible for self-generation of initial candidate itemsets, support count of candidate itemsets and frequent item set generation. The output of the generation unit, i.e., the frequent itemset, is then stored in SRAM ( Static Random Access Memory) for further candidate generation.

The candidate itemset generation unit is dedicated to the access of SRAM and generation of candidate itemsets. The output of the candidate itemset generation unit, i.e., the candidate itemset, is fed to the frequent itemset generation unit for the generation of frequent itemsets.

The processing procedure of our platform is as follows.

1. Self generate the candidate itemsets with one item by  shifting in the transaction database item-by-item.

2. At the same time, we build up the 2-item hash counts.

3. We count the occurrence of each candidate item set.

4. Hash table of2-item is built for the input transaction.

5. Frequent itemsets are shifted out and stored into  SRAM.

Frequent Itemset Generation Unit  Figure 1. The block diagram of our platform  6. Frequent itemsets are fetched out from SRAM to generate candidate itemsets with 2-item; if the hash value of the candidate itemset is greater than a threshold, we shift this candidate itemset into the candidate item chains.

7. Shift in the transaction database and count the occurrence of each candidate itemset.

8. Frequent item sets are shift out and store into SRAM.

9. Frequent item sets are fetched out from SRAM to  generate candidate itemsets; if the new candidate itemset is a valid one, we shift this candidate itemset into the candidate item chains.

10. Repeat 7 ?9 until the counting is completed.



IV. FREQUENT ITEMSET GENERATION UNIT  The frequent item set generation unit is responsible for (1) self-generation of initial candidate itemsets, (2) support count of candidate item sets and (3) frequent itemset generation. Fig. 2 depicts the self-generation of initial candidate itemsets. It is an example demonstrating how the transaction database is processed to generate the initial candidate itemsets. The transaction database is read out and shifted into the frequent itemset generation unit item by item.

At first, the array of candidate itemsets is empty. Hence the first transaction item 'a' will be forwarded to the array of transaction item sets and moved downward to the array of candidate item sets at the same time. Second, the transaction item 'b' is shifted in. The beginning of the array of candidate items is no longer empty. Hence we will not move it downward to the array of candidate itemsets. We will just forward it to the array of transaction itemsets. Third, we find the second location of the array of candidate itemsets is empty and 'b' is never seen by the previous candidate itemsets. Again we will forward the item 'b' to the array of transaction itemsets and move it downward to the array of candidate itemsets. As the transaction items are passed through the array of candidate item sets, we can count the number of occurrence for each of the candidate itemsets. At the end of all transaction items being passed through, we have generated the candidate itemsets and the occurrence count of each of them. Based on these results we can derive the frequent itemsets .

??????? ? ??? Transaction database Self-len initial candidates  I?  ????  ???? ???? 6 7  ???? ????  .. ..: . .... 2 ???? 5 ?? ? a ???? I 1 1 1 1 1  .: . ....... : 30 ?? 4 ???? g ??? I 1 1 1 1 1  Figure 2. The demonstration of frequent l-itemset generation    The occurrence of a candidate itemset in a transaction itemset is necessary from the occurrence of each item of the candidate item set in the transaction itemset. Based on all of the items occurring in a transaction itemset, we can detennine that the candidate itemset occurs in the transaction itemset. Also, we need to know the boundary of every transaction itemset to do support count. We label the end of a transaction as ';' in Fig. 3. We will reset the occurrence memory of each item as we encounter the transaction end label ';' .  For the last item of a candidate itemset, we will record the combined result of all items. Fig. 3 shows how we do support count for candidate itemsets with more than one item. Consider the candidate itemsets with two items as an example. The occurrence of itemset 'ac' is the "AND" combination of the results of item 'a' and item 'c' . So we will pass the result of item 'a' to item 'c' . At step 1, item 'a' gets occurrence and the result will be stored. At step 4, item 'c' has occurrence. The combined result of item set 'ac' is true. We find the occurrence of itemset 'ac' . At step 5, the occurrence result of item 'c' will be reset as encountering the transaction end label ';' .  At the same time the occurrence of item set 'ac' will be recorded for support count. As such, we can obtain candidate itemsets 'ac' and 'bd' which both have support count 1.

In this work, we develop a prototype to implement two jobs mentioned above using the same hardware resources.

Job one is the self-generation of initial candidate itemsets.

The other is support count for candidate itemsets with more than one item. The hardware prototype to implement frequent item set generation unit is illustrated in Fig. 5. The transaction item queue is used to pass transaction database item by item. It is made of several DFFs (D Flip Flops) depending on the bit width of the transaction item. In the same way, the candidate item queue is used to store and pass candidate itemsets.

e  eo  eoo  eooe  2 eooee  leoeeeo  , ,H ; b  ,',HH ; b d  t HH? ? ; b d ;  HH? ?H b d ; c  H? ?HH d ; c b  HHH ; c b a '  HHH" ..

c b  HH" ..

b a  H" ..

a  . ..

oeoe  Figure 3. Support count for candidate itemset with 2 items.

The DFF bellow candidate item queue is used to remember the status if this candidate item queue has been stored. It will be locked to one as the incoming transaction item was never seen and current candidate item queue was never used. The "post match" DFF is used to store the combined matching results from the beginning of candidate itemset queues to current one. The combinative and sequential logics below the "post match" DFF are used to do support count for candidate itemsets with more than one item. Of course, the two pairs of OR gates and DFFs can be shared and reduced to one pair.



V. CANDIDATE ITEMSET GENERATION UNIT  The candidate itemset generation unit is dedicated to the access of SRAM and generation of candidate item sets. The frequent itemset generation unit derives the frequent itemsets. So we need to store these frequent itemsets in SRAM. Also, we need to use these frequent item sets to generate candidate itemsets with more than one item and feed the generated candidate itemsets to the frequent itemset generation unit for frequent itemset generation again. The basic idea we used to do candidate generation is described as follows. A candidate 3-item itemset is generated from three frequent 2-item itemsets. Explicitly, we can detennine a candidate 3-item itemset if there exist three frequent 2-item itemsets which constitute an itemset with exact three items.

In addition, there is exactly one 3-item item set generated from pre-decided two of three frequent 2-item itemsets. So we design a methodology to generate candidate itemsets. As illustrated in Fig. 4, we first scan the entire frequent item sets from SRAM to check if the beginning two item sets 'ab' and 'ac' can generate a candidate 3-item item set. Reading out itemset 'bc' , we get the candidate 3-item itemset 'abc'. Then we will rescan SRAM in the order as 'ab' , 'ad' , 'ae' ... 'ef to check if itemsets 'ab' and 'ad' can generate a candidate 3- item itemset. As we can see from Fig. 4, the item sets 'bf and 'ce' cannot generate a candidate 3-item item set, because they have constituted to an itemset with four items.

In the same way, we use the hardware prototype shown in Fig. 5 to do candidate generation. We treat the frequent item sets as transaction itemsets and do self-generation of initial candidate itemsets. If we get four items after passing two frequent itemsets 'bf and 'ce' as illustrated in Fig. 4, we know that 'bf and 'ce' cannot constitute a candidate item set with three items. After passing two frequent itemsets 'ab' and 'ac' as depicted in Fig. 4, we only know that the item set 'abc' is possibly a candidate itemset. Furthermore, we need to check the existence of frequent item set 'bc' which does not introduce the fourth item in our candidate generation unit.

The rule used by our candidate item set generation unit to determine a candidate itemset with n + 1 items is as follows.

1. Initially, pass two frequent n-item itemsets and introduce n + 1 items exactly.

2. Pass other frequent n-item item sets and exist n - 1 frequent item sets which do not introduce the (n  + 2) item.

A candidate itemset is generated as both of the above two conditions are met at the same time. Of course, to speed up the candidate generation time, we can quickly bypass the check of condition 2 if condition 1 does not hold.

Figure 4. Rule of generating candidate itemsets.



VI. CONCLUSION  In this paper, we propose a reconfigurable hardware architecture that leads improvement, by order of magnitude, over previously hardware enhanced mining methods. Our platform is advantageous by its flexibility in dynamic cell arrangement, and is able to handle candidate item sets with any item. This is infeasible for previous methods to the best of our knowledge. From perfonnance analysis, our platform is shown to be able to significantly outperform prior mining methods. To make the mining of large graph feasible, we consider a hardware assisted mining, like the one we discussed in this paper, a direction worth of our attention.

