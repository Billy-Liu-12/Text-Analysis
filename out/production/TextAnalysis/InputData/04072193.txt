Identifying Vital/Protect Patterns for Classification in Multiple Phenotypes Medical Data?

Abstract  Previous work on medical data only focus on bi- phenotypes medical data. However, with the fast develop- ment of medical technique, it is invitable to classify multiple medical data. In this paper, we first define two patterns (adapting an interestingness measure by statics method) and then propose a new algorithm called MVP that is spe- cially designed to discover such two patterns. At last, ap- plies the discovered optimal rule sets to classify multiple medical data. The key advantage of MVP, as compared to other techniques for pattern discovery, is that MVP directly finds the interesting patterns which are non-redundancy and sense in a specific domain. The experiment results demon- strate the proposed method enables the user to focus on fewer rules and to be assured that the survival rules are all medical domain interesting. The classifier build on the rules generated by our method outperforms existing classifiers.

1. Introduction  The latest advances in biomedical technology results in a new type of dataset, which contains multiple phenotypes and potentially even more subtypes. For example, there are over a hundred types of cancer in [3] and potentially even more subtypes. However, current techniques are only lim- ited in their ability to distinguish several pairs of pheno- types, such as abnormal and normal [1]. Many medical data are incorrectly classified due to their ability to classification.

For any practical applications, it is essential to develop an algorithm for multiple phenotype medical data.

Previous studies have developed heuristic/greedy search techniques for building classifiers, such as decision trees [5, 6, 12], naive-Bayes classification [10], and statistical ap-  ?The work was supported by the ?fifteen? tackle key problem project of National Science and Technology Department under grant no.2004BA721A05.

proaches [11]. These techniques induces a representative subset of rules (e.g., a decision tree or a set of rules) from training data sets for quality prediction.

Recent studies propose the extraction of a set of high quality association rules from the training data set which satisfy certain user-specified frequency and confidence thresholds. Effective and efficient classifiers have been built by careful selection of rules, e.g., CBA [2], CAEP [4]. Such a method takes the most effective rule(s) from among all the rules mined for classification. Since association rules explore highly confident associations among multiple vari- ables, it may overcome some constraints introduced by a decision-tree induction method which examines one vari- able at a time. Some research and extensive performance studies [4] show that association based classification may have better accuracy in general. However, this approach may also suffer some weakness as shown below.

On one hand, it is not easy to identify the most effec- tive rule in a specific domain. Some method, such as [2, 4], simply selects a rule with a maximal user-defined measure, such as confidence. However, such a selection may not al- ways be the right choice in many cases. There are a lot of proposed interestingness criteria for association rule min- ing, and a comprehensive comparison has been conducted in [9]. Some evaluation work on medical data sets has been reported in [8]. However, most criteria do not make sense to medical practitioners. So selecting the most interestingness measurewe in a specific domain is important and necessary.

On the other hand, a training data set often generates a huge set of rules. The outcome results [7] in too many trivial and similar patterns which is also a problem for classifica- tion. However, it is important to select the right measure for a given application domain. Utilizing the measure, some uninteresting rule will be prune efficiently. Hence, in order to achieve high accuracy, a classifier may have to handle a large set of rules, including storing, pruning and sorting a large number of rules.

The main contributions of this work are as follows: First, we define the interesting measure based on statis-     tic method, and proposed two new patterns: vital pattern and protect pattern based the interesting measure which de- rives a good measure on how strong the rule is under both interestingness and class distribution.

Second, We proposed a new algorithm named MVP based prefix tree to discover vital patterns and protect pat- terns from multiple phenotypes disease, reducing the re- dundant rules and obtaining the maximal interesting rules in medical application, which break though the limitation of previous work that only contrast abnormal with normal samples to obtain the disease patterns [1]. Instead of relying on a single rule for classification, we construct a classifier with optimal patterns for classification multiple phenotypes medical data. An extensive performance study shows that the classifier in general has higher classification accuracy than CBA [2] and C4.5 [5].

Third, Utilizing the vital patterns and protect patterns discovered to perform a causal analysis of a medical data set, which are more clear than association rules. From the viewpoint of biomedical researcher, it is more suitable to analysis the medical data set.

The remainder of this paper is organized as follows: Sec- tion 2 give some preliminary and problem definition. In section 3, we present the efficient mining VP and PP based prefix tree and propose an algorithm for implement it. Ex- perimental results are described in Section 4. We summa- rize our research and discuss some future work directions in Section 5.

2. PROBLEM DEFINITION  In this section, we introduce some basic concepts and give the problem definition.

2.1. The Basics  A multiple phenotype medical dataset D consists of a set of rows S={S1, S2, ..., Sm}, and a set of columns A={P1,P2,...,Pn,T}, where the rows denote patients, the first n columns denote attributes(i.e. symptoms), and the final column T = {T1, T2, ..., Tk} is the complete set of class labels of D.

As an example, table 1 shows a three phenotypes med- ical dataset with 12 patients and 4 symptoms, each patient Si?S consists of one or more attributes from A and a class label from T. Note that every attributes have different ex- pression values, which can evaluate the degree of the symp- tom. The footnotes 1, 2, 3 and 4 denote different values of the symptoms respectively. Below, we first give some definitions used consistently throughout this paper.

Definition 1. P denoted a pattern. N denote the records of the dataset. The support of pattern P is the ratio of the  Table 1: An example of a three phenotypes medical data A B C D CLASS  A0 B1 C2 D1 T1 A0 B1 C2 D3 T1 A0 B1 C2 D1 T1 A1 B1 C2 D1 T1 A0 B0 C2 D1 T2 A0 B0 C2 D1 T2 A1 B1 C0 D1 T2 A1 B1 C2 D1 T2 A1 B1 C2 D2 T3 A2 B0 C2 D1 T3 A2 B0 C2 D1 T3 A2 B0 C2 D1 T3  number of records containing P to the number of all records in the data set, denoted by supp(P).

Supp(P ) = Count(P )  N  For example, The number of data set is N, there are x records contain the pattern P, than supp(P)=x/N. A pattern P is usually called frequent if supp(P)?? (? is a give thresh- old).

Definition 2. Let D be a dataset with attribute A, A={P1, P2, ..., Pn}. Let P = {P1P2...Pl} ?A(l=1,2,...,n) be an attribute or a subset of attributes. We called an at- tribute value or a set of attribute-value pairs a Pattern.

Definition 3. Let P be a pattern and Tk ? T be a pheno- type. The intra-class support of pattern P in phenotype Tk is the ratio of the number of records containing P with the phenotype Tk to the number of phenotype Tk in the data set, Intra Supp is an abbreviation of Intra Support.

Intra Supp(P ? Tk) = Support(P ?  Tk) Support(Tk)  Definition 4. The Prefix Rule Sets I={Pa, Pab,..., Pabcde} satisfy Pa?Tk, Pab?Tk,..., Pabcde?Tk, if there not ex- ist pattern P? ?P, and P? ?Tk, then we called pattern P the General Pattern which induce Tk. If there not exist Pabcde?P??, and P???Tk, then we called pattern Pabcde the Specific Pattern which induce Tk.

Lemma 1. If P be a Pattern where P "= ?, Pa is a super pattern of P and Tk(k=1,2,3...) be a class, then Supp(Pa)? Supp(P).

Proof. Omitted.

Theorem 1. If P be a Pattern where P"= ?, Pa is a su- per pattern of P and Tk(k=1,2,3...) be a class, then In- tra Supp(Pa ? Tk)? Intra Supp(P ? Tk).

Corollary 1. Let P be a Pattern where P "= ?, Px is a super pattern of P and Ti(i=1,2,3...) be a class. We called the     Pattern Px are frequent in class Ti if SCSupp(px Ti)> ?. If 0? SCSupp(px Ti)? ? (? is a give threshold, ?=2 in this paper), Pattern Px is infrequent in class Ti, we can draw the conclusion that the class Ti and its Pattern Px will not appear in the candidate itemsets.

2.2. Vital/Protect Patterns  We present Vital/Pretect patterns for identifying the dif- ferent multiple phenotypes medical data. At first, we present the definition of interestingness measure.

Definition 5. Interestingness Measure Odd Ratio is ab- breviated to OR. The Odd Ratio evaluate the relative like- lihood of pattern P occurring in different phenotypes. That is say, it estimate the correlation about the pattern with the disease. The OR value lies in the range [0,?].

A pattern?OR for specific Tk is defined as:  OR(P ? Tk) = Supp(P ? Tk)Supp(?P ? ?Tk) Supp(?P ? Tk)Supp(P ? ?Tk)  Supp is abbreviation of Support. Supp(P ? Tk) denote the support of pattern P and Tk emerging simultaneity, Supp(P ? ?Tk)=Supp(P )-Supp(P ? Tk), Supp(?P ? Tk)=Supp(Tk)-Supp(P ? Tk), and Supp(?P ? ?Tk)=1- Supp(P )-Supp(Tk)+Supp(P ? Tk).

Based on the given measurement OR, we can find some interesting patterns hidden in multiple phenotype data which are missed by previous methods. Some of them are positively related to phenotype Tk(Tk?T), that is, a per- son with pattern P catches the phenotype Tk with higher possibility. Some of them are negatively related to pheno- type Tk(Tk ? T ), that is, a person with pattern P gets the phenotype Tk with lower possibility. Mining such patterns, namely vital pattern and protect pattern, are important for medical researcher, which can aid in diagnosis and thus can enrich the expert system knowledge.

Definition 6. Let P?A, Tk ? T denote one of the phe- notype disease. We say P is Vital Pattern if and only if OR(P? Tk)?? (? is a given threshold by user). VP is an abbreviation of Vital Pattern. Some vital pattern combina- tion as Vital Pattern Sets. We say P is Protect Pattern if and only if OR(P? Tk)?? (? is a given threshold by user).

PP is an abbreviation of Protect Pattern. Some protect pat- tern combination as Protect Pattern Sets.

Corollary 2. For a given pattern, when OR>10, we say pattern p is positive relativity strongly to the outcome phe- notypes( i.e.class labels). We called pattern p must be a vital pattern to the disease. It shows that the pattern?s ap- pearance make high fatalness for the patient to infect the disease. When OR<1,we say pattern p is negative relativity  to the outcome phenotypes. We called pattern p is Protect Pattern to the disease. It shows that the pattern?s appear- ance make high security for the patient to infect the disease.

When 1 < OR < 3, we say pattern p is correlation to the disease, but it may be not a vital factor for the disease.

3 MVP Algorithm  We present our algorithm, called MVP1, to find all vital patterns and protect patterns satisfying thresholds ? and ? respectively in section 3.1 and the effective pruning strate- gies in section 3.2.

3.1 The Description of MVP Algorithm  We discuss the detail of MVP algorithm below, taking Table 1 as the example, where the minimum intra-class sup- port threshold ?=2.

The mining process is conducted on a prefix tree as shown in Figure 1, which is build on Table 1. Limited by space, we omit the description of constructing such a prefix tree structure.

A0 (4) T 1 T 2 T 3  A1(5) A2(3) B0(5) B1(7) D1(8) D2(3) D3(1)C0(1) C2(11) T 1 T 2 T 3 T 1 T 2 T 3 T 1 T 2 T 3 T 1 T 2 T 3 T 1 T 2 T 3 T 1 T 2 T 3T 1 T 2 T 3 T 1 T 2 T 3  A0B0(4 ) T 1T 2  A0B1(2 ) T 1T 2  A0C2(4 ) T 1T 2  A0D1(3 ) T 1T 2  A0D2(0 ) T 1T 2  A1B0(0 ) T 1T 2  A1B1(5 ) T 1T 2  A1C2(4 ) T 1T 2  A1D1(4 ) T 1T 2  A1D2(0 ) T 1T 2  A2B0(3 ) T 3  A2B1(0 ) T 3  A2C2(3 ) T 3  A2D1(1 ) T 3  A2D2(2 ) T 3  B0C2(5 ) T 2T 3  B0D1(3 ) T 2T 3  B0D2(2 ) T 3  B1C2(6 ) T 1T 2  B1D2(6 ) T 1T 2   B1D1(5 ) T 1T 2  C2D1(7 ) T 1T 2T 3  C2D2(3 ) T 1T 2T 3  T 1 T 2 T 3   A0B0D1(2 ) T 2  A0B0D2(0 )  A0B1C2(2 ) T 1  A0B1D1(1 )  A1C2D1(2 ) T 1  A1C2D2(0 )             1-Pattern  2-Pattern  3-Pattern  null  Figure 1: The MVP algorithm  From Figure 1, we can see 10 candidate 1-patterns at level 1, where the number within brackets denote the count of pattern. For example, A0(4) denotes the total count of A0 is 4. We only use the support-based pruning 1(see the details in section3.2) to generate these candidate pat- terns(line 2-5). Tk with solid box represents the corre- sponding rule pruned. For example, T3 with solid box un- der A0(4) means the rule A0?T3 can be cut by pruning rule 1. Further, if all Tk under some pattern are pruned, then rules containing this pattern will be pruned. For ex- ample, the removal of all Tk under C0 induces 46 rules  1MVP stands for Mining Vital and Protect Patterns     Algorithm 1 Mining the VP and PP algorithm Input: data set D, minimum Inter Class Support ? Output: Pattern sets R 1: Set R = ? 2: Count support of 1-patterns in every phenotype 3: Generate 1-pattern set 4: Count supports of 1-pattern in different phenotype 5: Select 1-pattern respectively and add them to R 6: new pattern set ? Generate(2-pattern set) 7: while new pattern set is not empty do 8: Count Intra Supp(P,Tk) of candidates in new pattern set 9: For each pattern P in (l+1)-pattern set  10: Applying pruning 1: IF Intra Supp(P? Tk)< ? 11: remove pattern S; 12: Else if there is a sub pattern P? in l-pattern set 13: Applying pruning 2: that Supp(P?)= Supp(P) or 14: Applying pruning 2: Supp(P?,?Tk)=Supp(P,?Tk) 15: Then remove pattern P; 16: Count the OR value; 17: Select VP and PP to R; 18: ENDIF 19: new pattern set ? Generate(next level pattern sets) 20: Return R;  Function 1 Generate(l+1)-pattern Set 1: Let (l + 1)-pattern set be empty set 2: (Note: Obey by the CIk?1 * CIk?1 Method to Merge) 3: for each pair of patterns pPl?1 and Pl?1q in l-pattern set do 4: Insert candidate Pl?1.pq in (l + 1)-pattern set ; 5: for all Pl ? Pl?1pq do 6: if Pl does not exist in l-pattern set then 7: Then remove candidate Pl?1pq 8: Return (l+1)-pattern set  in the prefix rule set of C0 pruned, such as A0C0?Tk, A1C0?Tk,...,A0B0C0?Tk,..., and A2B1C0D3?Tk will not be generated, and the similar case to D3. Next, we generate the candidate patterns for the second level. At first, we can pruning some redundancy rules by apply- ing pruning rule 1(line 8?10), such as candidate A0D2, A1B0, A1D2 are remove since Intra Supp(A0D2)=0< ?, Intra Supp(A1B0)=0< ?, Intra Supp(A1D2)=0< ?. It is marked by red 1? where the prune rule 1 is applied. Then, we perform the confidence-based pruning rule 2(line 13), which will also be explained in subsection 3.2. For in- stance, (T1T2) in candidate(A0C2; T1T2) is terminated be- cause of Supp(A0)=Supp(A0C2). It is marked by red 2? where the prune rule 2 is applied. At last, OR-based prun- ing rule 3 is very important but not difficult understand (see subsection 3.2). For example, T1 in candidate (A0D1; T1T2) is removed by line 14 because Supp(A0D1??T1) = Supp(A0??T1) hold. It is marked by red 3? where the prune rule 3 is applied. A complete pseudo-code for mining optimal VP and PP sets is presented in Algorithm 1.

The algorithm 1 discuss the support-based pruning, confidence-based pruning, and OR-based pruning. Existing algorithms to find an interesting rule sets are to post-prune an association rule set but this may be very inefficient when the minimum support is low and it will be generate a mount of redundancy rules. Our MVP algorithm makes use of the interestingness measure property to efficiently prune unin- teresting rules and save only the maximal interesting rules instead of all ones, and this distinguishes it from an associ-  ation rule mining algorithm.

Function 1 as function for generate candidate itemsets.

All candidate generation are build on the prefix tree struc- ture. We adopt the CIk?1*CIk?1 Merge to obtained the candidate itemset. After rules have been formed, we can prune many redundancy rules, limited by space, we don?t explain the function in details.

3.2 Pruning Strategies  We next look at the pruning techniques that are used in MVP, which are essential for the efficiency. Our emphasis here is to show that our pruning steps prevent unnecessary rules generation and only preserve interesting rules, the cor- rectness of our algorithm will be obvious.

Pruning Rule 1. Given Intra Support, denoted Intra Supp, Pattern P and all its possible proper supersets denoted Pa, phenotype Tk ? T (k=1,2,3,...) denoted one types of the diseases. If 0? Intra Supp(P?Tk)? ?, then pattern P and its supersets for their?s corresponding phenotype Tk will not be the optimal rule.

Proof. Once 0? Intra Supp(P?Tk) ? ? is observe, it is not necessary to search for more specific rule Pa?Tk. Bea- cuse Intra Supp(Pa ? Tk) ?Intra Supp(P?Tk) ? ?. So, target Tk ?T will be terminate in candidate rule P ? Tk.

Note: The presentation of pruning 1 describe the intra-class support of pattern in the corresponding phenotype, not gen- eral support. Because in a medical data set, pattern P in the phenotype Tk would hardly be frequent since the phe- notype Tk cases are rare, which can reduce the redundancy rules greatly. This is difference with association rules.

Pruning Rule 2. If pattern P satisfy Supp(P)= Supp(Pa), Pa denote its proper superset, then pattern Pa and all its possible proper supersets will not be useful for VP and PP.

Proof. In the proof, we show confidence(P?Tk)> confidence(Pa?Tk).

Conf(P ? Tk) = Supp(P ? Tk) Supp(P )  = Supp(P ? Tk)  Supp(Pa) >  Supp(Pa ? Tk) Supp(Pa)  = Conf(Pa ? Tk)  Consider Supp(P?Tk)? Supp(Pa?Tk) > 0. Therefor, the rule (Pa?Tk) will be prune during mining VP and PP.

Pruning Rule 3. If pattern P satisfy Supp(P??Tk)=Supp(Pa??Tk), Pa denote its proper superset, then pattern Pa and all its possible proper supersets will not be useful for VP and PP.

Proof. In the proof, in order to show Interestingness(P ? Tk)> Interestingness(Pa ? Tk), we only proof the OR(P?Tk)>OR(Pa?Tk).

OR(P ? Tk)  = Supp(P ? Tk)Supp(?P ? ?Tk) Supp(?P ? Tk)Supp(P ? ?Tk)  = Supp(P ? Tk)(Supp(?Tk)? Supp(P ? ?Tk)) (Supp(Tk)? Supp(P ? Tk))Supp(P ? ?Tk)  = Supp(P ? Tk)(Supp(?Tk)? Supp(Pa ? ?Tk)) (Supp(Tk)? Supp(P ? Tk))Supp(Pa ? ?Tk)  = Supp(P ? Tk)(Supp(?(Pa) ? ?Tk))  (Supp(Tk)? Supp(P ? Tk))Supp(Pa ? ?Tk) ? Supp(Pa ? Tk)(Supp(?Tk)? Supp(Pa ? ?Tk))  (Supp(Tk)? Supp(Pa ? Tk))Supp(Pa ? ?Tk) =  Supp(Pa ? Tk)Supp(?Pa ? ?Tk) Supp(?Pa ? Tk)Supp(Pa ? ?Tk)  = OR(Pa? Tk)  Consider f(y) = y/(?-y) monotonically increases with y when constant ? > 0 and Supp(P)? Supp(Pa) > 0, There- for, the rule (Pa?Tk) will be prune during mining VP and PP.

The above pruning rules are very efficient since it only generates a subset of frequent patterns with maximal inter- estingness instead of all ones.

Finally, the optimal VP and PP sets are significantly smaller than an association rule set, but is still too big for medical practitioners to review them all. We may only re- turn top-k vital patterns or protect patterns, but they may all come from a section of the data set and lack the represen- tation for all phenotypes. In order to account for all known phenotypes, we aim to retain one vital pattern sets and pro- tect pattern sets for each phenotype Tk. Limited by space, we don?t list the top-k algorithm in details.

4 Experiments  The task was support by national nature fund. The pneu- monia data come from eight hospitals. The data set con- tains 20000 cases, where belong to six different pneumo- nia. Patients are described by 112 attributes, but not all the attributes are useful to mining vital pattern and protect pat- tern. Some information including age, sex, address, phone number are excluded during the preprocessing. Our goal is to identify VP and PP from multiple pneumonia pheno- types. We set the Intra Supp as 0.01. It returned 6 pheno- types and corresponding VP and PP. The following are the  representative patterns with the highest VP and lowest PP.

For phenotype Tk, the VP list is : Pattern1: OR=3.06 , Significance Testing : ?2 = 14.08, P<0.05, it illuminate the pattern is relevant to phenotype Tk.

Fever = 380C ? 390C Breath = 30?40 times/minute X ray = ?thick and weight?  Pattern2: OR=18.52, Significance test: ?2 = 6.24, P<0.05, it illuminate the pattern is relevant to phenotype Tk.

High Fever = 38.50C ? 400C Cough = ?frequency? Moist Rales = ?short?  The PP list is : Pattern: OR=1.102  Fever = 36.50C ? 370C Moist Rales = ?normal? Limited by space, we don?t list all the experiment re-  sults. We evaluate the performance of MVP algorithm from effectiveness and the classification accuracy. In all experi- ments, we use Intra Supp=0.01, unless otherwise specified.

Figure 2 presents the comparison of classification accura- cies. Figure 2 (a) compare the classification accuracy with the same support by different algorithms(CBA, C4.5, and MVP). Figure 2(b) present the classification accuracy of different pattern selection(range from 5 to 35) with differ- ent Intra-Supp. Obviously, the classification accuracy are different with different Intra-Supp. Our MVP algorithm al- ways effective by different parameter. The best classifica- tion accuracy is above percent 92 if we setting the optimal parameter, which illuminate our algorithm is efficient for classification.

In figure 3, we compute the pattern?OR value in differ- ent phenotypes. We clearly see that each pattern?OR value is different in different phenotypes, for example, pattern FN?OR value is great differentiation in different phenotype, FN is vital pattern in phenotype 1 but protect pattern in phe- notype 3, which illuminate the different signification of the same pattern in different outcome phenotypes and the im- portance of interesting measure.

0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   5 10 15 20 25 30 35  l -pattern  A cc  ur ac  y  C4.5 CBA MVP  (a) Accuracy vs. algorithms   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   5 10 15 20 25 30 35 l -pattern  A cc  ur ac  y  Inter_Supp=0.03 Inter_Supp=0.02 Inter_Supp=0.01  (b) Accuracy vs. support  Figure 2: Classification accuracy comparison      0.5   1.5   2.5   3.5   TFW RT HF FN SPP LF  Pattern  O R  V al  ue Phenotype1 Phenotype2 Phenotype3  Figure 3: OR value of pat- tern vs. phenotypes      1 2 3 4 5 6 7  the layer th  N um  be rs  o f  R ul  es  association rule set non-redundanct association set Vital and Protect pattern set  Figure 4: The numbers of rules vs. algorithms  In comparison with MVP in figure 4, the non-redundant rules and association rules is very inefficient. We can draw a conclusion that MVP only generate the maximal interest- ing rules which reduce the redundant rules dramaticlly. The experiment results demonstrate that the proposed method enables the user to focus on fewer rules and assures that the survival rules are all interesting from the viewpoint of medical domain.

From a series of experiment above, we can prove that our algorithm can discover vital patterns and protect patterns which are important for domain expert and most found pat- terns are of great interest to domain experts and verified by them and our MVP algorithm is efficient for classification.

5 Conclusions  In this paper, we discuss the vital pattern and protect pat- tern which are important for medical researcher, and pro- pose an interestingness measure in order to decide whether the rules are interesting for the biomedical domain. Based on the interestingness measure and its properties, we pro- pose a new algorithm with efficient pruning rules to mine all optimal VP and PP rules. Our experimental results con- firm that our approach is effective and efficient for optimal VP and PP rules generating. Our experiments on real med- ical databases show that our classifier is highly effective at classification of medical databases and has better classifi- cation accuracy in comparison with CBA and C4.5, and is more efficient and scalable than other associative classifica- tion methods.

