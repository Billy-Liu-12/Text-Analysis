Dynamic Load Balancing of Large-Scale Distributed  Association Rule Mining

Abstract? The focus of this paper is to propose a dynamic load balancing strategy for parallel association rule mining algorithms in the context of a Grid computing environment.

This strategy is built upon a distributed model which necessitates small overheads in the communication costs for load updates and for both data and work transfers. It also supports the heterogeneity of the system and it is fault tolerant.

Keywords? Association rules, Performance, Parallel association mining, Grid computing, Dynamic load balancing.



I. INTRODUCTION  With the advances in data acquisition and storage technologies, the problem of how to turn large volumes of raw data into useful information becomes a significant one. In order to decrease the gap between data and useful information, a group of architectures and utilities, some of them are new and others exist since a long time, are grouped under the term data mining. Association rule mining which trends to find interesting correlation relationships between items in a large database of sales transactions has become one of the most important data mining techniques [3, 11]. Although algorithms of this technique have a simple statement, they are computationally and input/output intensive. High performance parallel and distributed computing can relieve current association rule mining algorithms from the sequential bottleneck, providing scalability to massive data sets and improving response time.

Grid computing is recently regarded as one of the most promising platform for data and computation-intensive applications like data mining. A Grid can be envisioned as a collection of geographically dispersed computing and storage resources interconnected with high speed networks and effectively utilized in order to achieve performances not ordinarily attainable on a single computational resource [2].  In such computing environments, heterogeneity is inevitable due to their distributed nature. Almost all current parallel algorithms assume the homogeneity and use static load balancing strategies. Thus applying them to grid systems will degrade their performance .

In this paper, we develop and evaluate a run time load balancing strategy for mining association rule algorithms under a grid computing environment. The rest of the  paper is organized as follows: Section 2 introduces association rule mining technique. Section 3 describes the load balancing problem. Section 4 presents the system model of a Grid and the proposed dynamic load balancing strategy. Experimental results obtained from implementing this strategy are shown in section 5.

Finally, the paper concludes with section 6.



II. MINING ASSOCIATION RULES  Association rules mining finds interesting correlation relationships among a large set of data items.

A typical example of this technique is market basket analysis. This process analyses customer buying habits by finding associations between different items that customers place in their ?shopping baskets?. Such information may be used to to plan marketing or advertising strategies, as well as catalog design [3]. Each basket represents a different transaction in the transactional database, associated to this transaction the items bought by a customer. Given a transactional database D, an association rule has the form A=>B, where A and B are two itemsets, and A?B=?. The rule?s support is the joint probability of a transaction containing both A and B at the same time, and is given as ?(AUB).

The confidence of the rule is the conditional probability that a transaction contains B given that it contains A and is given as ?(AUB)/?(A). A rule is frequent if its support is greater than or equal to a pre-determined minimum support and strong if the confidence is more than or equal to a user specified minimum confidence.

Association rule mining is a two-step process: 1) The first step consists of finding all frequent  itemsets that occur at least as frequently as the fixed minimum support;  2) The second step consists of generating strong implication rules from these frequent itemsets.

The overall performance of mining association rules is determined by the first step which is known as the frequent set counting problem [3].

Many sequential algorithms for solving the frequent set counting problem have been proposed in the literature. We can define two main methods for determining frequent itemsets supports: with candidate itemsets generation [11, 13] and without candidate itemsets generation [5].

Apriori [11] was the first effective algorithm proposed.

This algorithm uses a generate-and-test approach which depends on generating candidate itemsets and testing if they are frequent. It uses an iterative approach known as a level-wise search, where k-itemsets are used to explore (k+1)-itemsets. During the initial pass over the database the support of all 1-itemsets is counted. Frequent 1- itemsets are used to generate all possible candidate 2- itemsets. Then the database is scanned again to obtain the number of occurrences of these candidates, and the frequent 2-itemsets are selected for the next iteration.

DCI algorithm proposed by Orlando and others [13] is also  based on candidate itemsets generation. It adopts a hybrid approach to compute itemsets supports, by exploiting a counting-based method (with a horizontal database layout) during its first iterations and an intersection-based technique (with a vertical database layout) when the pruned dataset can fit into the main memory.

FP-growth algorithm [5] allows frequent itemsets discovery without candidate itemsets generation. First it builds from the transactional database a compact data structure called the FP-tree then extracts frequent itemsets directly from the FP-tree.

Association rule mining algorithms suffer from a high computational complexity which derives from the size of its search space and the high demands of data access.  Parallelism is expected to relieve these algorithms from the sequential bottleneck, providing the ability to scale the massive datasets, and improving the response time. However, parallelizing these algorithms is not trivial and is facing many challenges including the workload balancing problem. Many parallel algorithms for solving the frequent set counting problem have been proposed. Most of them use Apriori algorithm [11] as fundamental algorithm, because of its success on the sequential setting. The reader could refer to the survey of Zaki on association rules mining algorithms and relative parallelization schemas [7]. Agrawal et al. proposed a broad taxonomy of parallelization strategies that can be adopted for Apriori in [10].

There also exist many grid data mining projects, like Discovery Net, GridMiner, DMGA [9] which provide mechanisms for integration and deployment of classical algorithms on grid. Also the DisDaMin project that deals with data mining issues (as association rules, clustering, etc.) using distributed computing [15].

Load Balancing: Problem Description Work load balancing is the assignment of work to  processors in a way that maximizes application performance [4]. A typical distributed system will have a number of processors working independently with each other. Each processor possesses an initial load, which represents an amount of work to be performed, and each may have a different processing capacity (i.e. different architecture, operating system, CPU speed, memory size and available disk space). To minimize the time needed to perform all tasks, the workload has to be evenly distributed over all processors in a way that minimizes both processor idle time and inter-processor communication.

Static load balancing can be used in applications with constant workloads, as a pre-processor to the computation [4]. Other applications require dynamic load  balancers that adjust the decomposition as the computation proceeds [4, 6]. This is due to their nature which is characterized by workloads that are unpredictable and change during execution. Data mining is one of these applications.

Parallel association rule mining algorithms have a dynamic nature because of their dependency on the degree of correlation between itemsets in the transactional database which cannot be predictable before execution. Basically, current algorithms assume the homogeneity and stability of the whole system, and new methodologies are needed to handle the previously mentioned issues.

Although intensive works have been done in load balancing, the different nature of a Grid computing environment from the traditional distributed system, prevent existing static load balancing schemes from benefiting large-scale applications.  An excellent survey from Y. Li et al. [17], displays the existing solutions and the new efforts in dynamic load balancing that aim to address the new challenges in Grid. The work done so far to cope with one or more challenges brought by Grid: heterogeneity, resource sharing, high latency and dynamic system state, can be identified by three categories as mentioned in [17]: (1) Repartition methods focus on calculating data distribution in a heterogeneous way, but don?t pay much attention to the data movement in Grid; (2) Divisible load theory based schemes well model both the computation and communication, but loose validity in case of adaptive application; (3) Prediction based schemes need further investigation in case of long-term applications.



III. PROPOSED LOAD BALANCING APPROACH  A. The Hierarchical Grid System Model In our study we model a Grid as a collection of T sites  with different computational facilities and storage subsystem.     Let G = (S1, S2,?, ST) denotes a set of sites, where each site Si is defined as a vector with three parameters Si = (Mi , Coord(Si) , Li), where Mi is the total number of clusters in Si, Coord(Si)   is the workload manager, named the coordinator of Si, which is responsible of detecting the  workload imbalance and the transfer of the appropriate amount of work from an overloaded cluster to another lightly loaded cluster within the same site (intra-site) or if it is necessary to another remote site (inter-sites). This transfer takes into account the transmission speed between clusters which is denoted ?ijj? (if the transmission is from cluster clij  to cluster clij?).

And Li is the computational load of Si.

Each cluster is characterized by a vector of four parameters clij =(Nij , Coord(clij) , Lij, ?ij), where Nij is the total number of nodes in clij , Coord(clij) is the coordinator node of clij which ensures a dynamic smart distribution of candidates to its own nodes, Lij is the computational load of cluster clij  and ?ij is its processing time which is the mean of processing times of cluster's nodes.

Fig. 1 shows the Grid system model. To avoid keeping global state information in a large-scale system (where this information would be very huge), the proposed load balancing model is distributed in both intra-site and inter- sites. Each site in the Grid has a workload manager, called the coordinator, which accommodates submitted     transactional database partitions and the list of candidates of the previous iteration of the association rules mining algorithm. Each coordinator aims at tracking the global workload status by periodically exchanging a ?state vector? with other coordinators in the system. Depending on the workload state of each node, the frequency of candidate itemsets may be calculated in its local node or will be transferred to another lightly loaded node within the same site.

Figure 1. The hierarchical model of a Grid   If the coordinator cannot fix the workload imbalance  locally, it selects part of transactions to be sent to a remote site through the network. The destination of migrated work is chosen according to the following hierarchy: First The coordinator of the cluster Coord(clij) selects the available node within the same cluster; If the workload imbalance still persists then Coord(clij) searches for an available node in another cluster but within the same site; Finally, in extreme cases, work will be send to a remote site. The coordinator of the site Coord(Si) will look for the nearest site available to receive this workload (i.e. least communication cost). If the coordinator node does not give response within a fixed period of time, an election policy is invoked to choose another coordinator node.

B. The Dynamic Load Balancing Strategy Our strategy could be adopted by any association rule  mining algorithm that depends on candidate itemsets generation. It combines between static and dynamic load  balancing and this by interfering before execution (i.e.

static) and during execution (i.e. dynamic).

To respond to the heterogeneity of the computing system we are using (Grid) the database is not just partitioned into equal partitions in a random manner.

Rather than that, the transactional database is partitioned according to the characteristics of different sites, where the size of each partition is determined according to the site processing capacity (i.e., different architecture, operating system, CPU speed, etc.). It?s the responsibility of the coordinator of the site Coord(Si) to allocate to its site the appropriate database portion according to the site processing capacity parameters stored in its information system.

Our load balancing strategy acts on three levels: 1) level one is the migration of work between nodes of the same cluster. If the skew in workload still persists the coordinator of the cluster Coord(clij) moves to the next level;  2) level two depends on the migration of work between clusters within the same site;  3) and finally if  work migration of the previous two levels is not sufficient then the coordinator of the overloaded cluster Coord(clij) asks from the coordinator of the site Coord(Si) to move to the third level which searches for the possibility of migrating work between sites. Communication between the coordinators of different sites is done in a unidirectional ring topology via a token passing mechanism.

The following workload balancing process is invoked when needed. It is the responsibility of distributed coordinators to detect that need dynamically according to the charge status of their relative nodes:  1) From the intra-site level, coordinators of each cluster update their global workload vector by acquiring workload information from their local nodes. From the Grid level, coordinators of different sites periodically calculate their average workload in order to detect their workload state (overloaded or underloaded). If an imbalance is detected, coordinators proceed to the following steps.

2) The coordinator of the overloaded cluster makes a plan for candidates migration intra-site (between nodes of the same site). If the imbalance still persists, it creates another plan for transactions migration inter-sites (between clusters of the Grid).

3) The concerned coordinator (the coordinator of the overloaded cluster or the coordinator of the overloaded site) sends migration plan to all processing nodes and instructs them to reallocate the work load.

In what follows we present the dynamic load balancing algorithms:          ndijk : Node k of clij  Coord(clij): Cluster  Coordinator  DB2  DB1 DB2  DB3  Coord(Si): Site  Coordinator    ?.

clij : Cluster j of Si  Si : Site i  DB1  DB3  DB3  ndijk : node k of clij  coordinato     Node (ndijk) Loop : ? Receives a group of candidates from the coordinator of  the cluster.

? Calculates their supports.

? Sends local supports to cluster?s coordinator which  performs the global supports reduction.

Cluster coordinator (coord (clij))  Loop : ? Distributes candidate itemsets between nodes  according to their  capacities. Candidates are distributed by their (k-1) commun prefix.

? Performs the global reduction of supports to obtain global frequencies.

? Constructs frequent itemsets (Lk step).

? Constructs  candidates  itemsets of the following  iteration (Ck+1 step).

? Every  n steps :  o Save the local state; o Update if necessary Ck+1 step.

Site coordinator (Coord (Si)) Loop : ? Updates the global state vector of the site  Average(chi)).

? Finds the Max overloaded cluster and the max  underloaded cluster: o Clijmax    (chij)  moy(chi)  o Clijmin    (chij)  moy(chi)  ? Finds the Max  xc (with the same prefix) on clijmax : 1. Chijmin +  xc . ijmin  moy(chi)  //To find the best number of candidates to migrate in order to not overload the destination cluster  AND 2. xc . ijmax  - ( xc . ijmin + long(xc). ijmaxjmin ) > Seuilmc  ? If xc exists Then informs the overloaded clijmax and the underloaded clijmin and updates (chi).

? Asks from the overloaded cluster to send the family of candidates having the same prefix.

With : T : Total number of  sites; Mi : Total number of clusters of the site Si ; Nij : Total number of nodes of the cluster clij ; Coord(clij) : Coordinator node of clij ; coord(Si) : Coordinator of Si ; ?ijj? : Transmission speed between clusters clij and clij? ; ?ijk : Cycle time of  ndijk ;  chi : Charge of Si (where chi = ); chij : Charge of clij ; ?ij : Average( ?ijk ); seuilmc : Significant time limit to trigger candidate itemsets migration between clusters; seuilmt : Significant time limit to trigger task migration between sites.

xc : Number of candidates to migrate from one cluster to another  These load balancing algorithms are executed in parallel with the association rule mining algorithm without necessitating an extra time (i.e. computing nodes continue working even during work or data migration).

The two main advantages of this strategy are:  ? The priority is given to local workload balancing (i.e. intra-cluster). The objective of that is to privilege local communications (LAN network) in order to reduce the overhead caused by the transfer of work or data.

? The strategy is totally distributed but the decision is taken locally. Actually, we can execute in parallel as much intra-cluster load balancing as much we have clusters in the grid.



IV. PERFORMANCE EVALUATION  The specific characteristics of the problem of frequent set counting associated with those of the computing environment (Grid) must be taken into account. While association rule mining method is based on global criteria (support, frequencies), we are only disposed by local (partial) data views due to the fact of distribution.

The treatment must be done on the entire database, comparing each partition of the base with all the others must be possible in order to be able to obtain global information.

Our goal is to limit the number of communications and synchronizations, and to be benefit as much as possible from the available computing power. This could be done by exploiting all possible ways of parallelism and if necessary by using a pipeline approach between dependent tasks in order to be able to parallelize the various stages of the frequent set counting algorithm.

In order to evaluate the performance of our workload balancing strategy we parallelized the sequential Apriori algorithm which is the fundamental algorithm for frequent set counting algorithms with candidate itemsets generation.

Data parallelism is not sufficient to improve the performance of association rule mining algorithms. Subsets of extremely large data sets may also be very large. So, in order to extract the maximum of parallelism, we applied a hybrid parallelisation technique (i.e. the combination of data and task parallelism). Where we aimed to study parallelism inside the program code This could be done through searching inside the algorithm procedures for independent segments and analyzing the loops to detect tasks (or instructions) that could be executed simultaneously.

A hybrid approach between candidate duplication and candidate partitioning is used. The candidate itemsets are duplicated all over the sites of the Grid, but they are     partitioned between the nodes of each site. The reason for partitioning the candidate itemsets is that when the minimum support threshold is low they overflow the memory space and incur a lot of disk I/O. So, the candidate itemsets are partitioned into equivalence classes based on their common (k-2) length prefixes. A detailed explanation of candidate itemsets clustering could be found in [8].

We can resume the important basic concepts of our parallelization method in what follows:   Site:  ? The transactional database is partitioned between sites according to the capacity of treatment of each site.

? Candidate itemsets are duplicated between sites (in order to reduce the communication cost between sites).

Cluster: ? Every database partition is shared between nodes of  the same site if they have the same storage subsystem, otherwise it will be duplicated.

? Candidates are partitioned between site?s clusters (according to the capacity of treatment of the cluster)  Node : ? Receives a group of candidates from the coordinator  of the cluster.

? Calculates their supports.

? Sends local supports to cluster?s coordinator which  performs the global supports reduction.

Cluster?s coordinator: ? Distributes candidate itemsets between nodes  according to their capacities.  Candidates are distributed by their (k-1) commun prefix.

? Performs the global reduction of supports to obtain global frequencies.

? Responsible for workload balancing operation of his cluster  Site?s  coordinator : ? Search for the maximum loaded cluster (or site) and  the minimum loaded cluster (or site).

? Migration of the necessary amount of work  (candidates or transactions or both) from the maximum to the minimum loaded clusters or sites.

A. Experimental Platform The performance evaluations presented in this section were  conducted on Grid?5000 [1], a dedicated reconfigurable and controllable experimental platform featuring 13 clusters, each with 58 to 342 PCs, interconnected through Renater (the French Educational and Research wide area Network). It gathers roughly 5000 CPU cores featuring four architectures (Itanium, Xeon, G5 and Opteron) distributed into 13 clusters over 9 cities in France (Bordeaux, Grenoble, Lille, Lyon, Nancy, Orsay, Rennes, Sophia-Antipolis, and Toulouse).

We used heterogeneous clusters in order to generate the maximum workload imbalance. Nodes are interconnected within each cluster by a Gigabit Ethernet switch. All the  nodes were booted under Linux on Grid?5000. Nodes were reserved by the reservation system which ensures that no other user could log on them during the experiments.

We conducted several experiments, by varying the number of sites, clusters and computational nodes. We will present in what follows the results obtained by using three sites, each site containing two clusters and with 40 computational nodes distributed as follows: 4 nodes/cluster1, 3 nodes/cluster2, 6 nodes/cluster3, 7 nodes/cluster4,   11 nodes/cluster5 and  9 nodes/cluster6. We allocated clusters with different sizes to show the effectiveness of our approach in dealing with the heterogeneity of the system. The datasets used in tests are synthetic, and are generated using the IBM-generator [12].

Table 1 shows the datasets characteristics.

The first iteration of association rule mining algorithm is a phase of initiation for workload balancing (i.e. creating state vectors and processing time estimates, etc). For the first dataset (DB100T13M) the algorithm performed 11 iterations in order to generate all possible frequent itemsets. Candidate itemsets migration (intra-site) is initiated two times during the second iteration, and once during the third and fourth iterations.

TABLE 1  TRANSACTIONAL DATABASES CHARACTERISTICS  DB400T54M DB800T113M Database size 400 MB 800 MB Transactions number 5400000 11300000 Items number 6500 9000 Average transaction size 40 50    Fig. 2 displays the execution time obtained from running  the parallel version of Apriori without the work load balancing strategy and the time obtained when the strategy is embedded in the parallel implementation. We can clearly see that the parallel execution time with work load balancing outperforms the time needed for the parallel execution without taking care to the load imbalance that may occur during the execution of the association rule mining algorithm.

Fig. 3 illustrates the speedup obtained as a function of the number of processors used in execution.  For the different datasets we achieved better speed up with the load balancing approach. The drop in speedup for relatively higher support values is due to the fact that when the support threshold increases the number of candidate itemsets generated decreases (i.e. less computation to be performed). In this case it would be better to decrease the number of nodes incorporated in execution so that the communication cost will not be higher than the computation cost. In fact, there is not a fixed optimal number of processors that could be used for execution. The number of processors used should be proportional to the size of data sets to be mined. The easiest way to determine that optimal number is via experiments.

Figure 2. Run time with and without load balancing for different support values.

Figure 3.  Run time, communication time and workload balancing time for dataSet1.



V. CONCLUSION  Data mining algorithms have a dynamic nature during execution time which causes load-imbalance between the  different processing nodes. Such algorithms require dynamic load balancers that adjust the decomposition as the computation proceeds. Numerous static load balancing strategies have been developed where dynamic load balancing still an open and challenging research area.  In this article we developed a dynamic load balancing strategy for association rule mining algorithms, with candidate itemsets generation, under a Grid computing environment.

Experimentations showed that our strategy succeeded in achieving better use of the Grid architecture assuming load balancing and this for large sized datasets. In the future, we aim to adopt our strategy to association rule mining algorithms without candidate itemsets generation.

