Using Sensitivity of a Bayesian Network to Discover Interesting Patterns

Abstract  In this paper, we present a new measure of interestingness to discover interesting patterns based on the user?s background knowledge, represented by a Bayesian network. The new measure (Sensitivity measure) captures the sensitivity of the Bayesian network to the patterns discovered by assessing the uncertainty- increasing potential of a pattern on the beliefs of the Bayesian network. Patterns that attain the highest sensitivity scores are deemed interesting. In our approach, mutual information (from information theory) came in handy as a measure of uncertainty. The Sensitivity of a pattern is computed by summing up the mutual information increases incurred by a pattern when entered as evidence/findings to the Bayesian network. We demonstrate the strength of our approach experimentally using the KSL dataset of Danish 70 year olds as a case study. The results were verified by consulting two doctors (internists).

1. Introduction  A major problem faced by all association rule mining algorithms is their production of a large number of rules which incurred a secondary mining problem; namely, mining interesting association rules. The problem is compounded by the fact that `common knowledge' discovered rules are not interesting, but they are usually strong rules with high support and confidence levels ? the classical measures in [1].

The main objective of this paper is to develop an Interestingness Filtering Engine (IFE) that leverages background knowledge, represented by a Bayesian network, to discover interesting patterns in datasets. A pattern is considered interesting if it is unexpected or surprising to the user [17, 18]. A new interestingness measure is defined to capture the sensitivity of the Bayesian network (beliefs) to the patterns discovered.

Patterns that attain the highest sensitivity scores are  deemed interesting. For this reason, the new Interestingness Measure is called Sensitivity.

The IFE utilizes Bayesian networks in two perspectives: as a causality/dependence representation of the joint probability distribution of all attributes involved in the user's preliminary set of beliefs (background knowledge); and as a probabilistic inference engine that can infer the global effect of a frequent itemset on the belief network with the aid of the Sensitivity measure.

The Sensitivity measure should measure the uncertainty-increasing potential of a pattern; that is the extent to which a pattern alters the beliefs of the Bayesian network to more uncertain (unexpected) probabilities, when that pattern is entered as new evidence/finding to the Bayesian network. Mutual Information from information theory came in handy as a measure of uncertainty or unexpectedness. Leveraging the symmetry property inherent in Mutual Information (i.e. I(X;Y) = I(Y;X), where I(X;Y) is the Mutual Information between two random variables X and Y), the Sensitivity (interestingness) of a pattern is computed by summing up the mutual information increases incurred by a pattern when entered as finding(s) to the Bayesian network. Only increases in mutual information are considered because we are in pursuit of patterns that increase the degree of variation (i.e. unexpectedness/uncertainty) in the posterior probabilities (beliefs) of the nodes in the Bayesian network.

A case study -the KSL dataset of Danish 70 year olds- was used to analyze and verify the experimental results obtained when applying the IFE and its sensitivity measure, which exhibited a strong capability in discovering interesting (unexpected) patterns that are not 'common knowledge' patterns.

2. Related work and motivation  Since the inception of the classical Apriori algorithm [1] for mining association rules, development of interestingness measures has been a vigilant area of research.  Some approaches used objective measures of interestingness, while others used subjective measures.

Objective measures are those that depend on the structure of the rule/pattern discovered and the underlying data used in the discovery process [18]; such measures include: support, confidence, correlation, chi square, lift ... etc.  Subjective measures, on the other hand, rely mainly on the user who examines the patterns, where his/her prior knowledge/beliefs can adversely affect the discovery process.  Most approaches using subjective measures also used some objective measures.

According to [17,18], subjective measures were classified into two categories; namely, unexpectedness and actionability. A pattern/rule is unexpected, if it is 'surprising' to the user; and it is actionable if the user can act on it to his/her advantage.

Approaches using objective measures are not within the intended scope of this paper. As the focus of this paper is on discovering interesting patterns based on background knowledge, only related work within this context is discussed. Three main approaches that use background knowledge in their discovery schemes were identified.

The first approach is syntax-based as in [3,4,11,16];   the second is logic-based as in [14,15]; and the third is probability-based as in [10,17,18,19]; noting that in [17,18], the Bayesian probabilistic approach was one among other proposed approaches, such as the Dempster- Shafer approach and the ?frequentist'' probabilistic approach.

The syntax-based approach necessitates defining some kind of language for knowledge representation governed by a set of syntax rules, so that pair wise comparison of rules can be conducted in the discovery process;  one from the set of knowledge rules and the other from the data rules. If a syntax difference is captured by the comparison- i.e. a similar rule body but a dissimilar rule head or vice versa- a data rule is considered unexpected, and hence interesting.

The logic-based approach is similar to the syntax- based approach since it also adopts pair wise comparison of rules; but with the difference that the comparison process looks for logical contradictions and not syntax differences between prior knowledge rules and data rules.

The probability-based approach, basically, uses a belief system for background knowledge representation to introduce uncertainty through assigning some degree or confidence factor to each belief. Although in [17,18] (1995 and 1996), Silberschatz and Tuzhilin laid the ground for using a Bayesian or a Dempster-Shafer approach (reasoning under uncertainty), their algorithms in [14,15] leveraged logical reasoning based on the user?s precise (certain) knowledge! Two recent papers; the first by Jaroszewicz and Simovici [10] and the second by Jaroszewicz and Scheffer [19] were the first to pick what Silberschatz and Tuzhilin have seeded in [14,15] by adopting a discovery scheme that used Bayesian networks to represent background knowledge. They differed in the  definition of their interestingness measures. In [17,18], the proposed definition of interestingness should measure how much a pattern affects the degrees of the beliefs in a belief system; i.e. the more a pattern disagrees with the belief system the more unexpected (interesting) it is.  No formal algorithm was proposed in either paper.

Alternatively, in [10,19] the measure of interestingness of an itemset was defined as the absolute difference between its support estimated from the dataset and the Bayesian network. Itemsets with strongly diverging supports are considered interesting. We have implemented the above two inspiring definitions of interestingness [10,18] and tested them using the KSL dataset of Danish 70 year olds.

The interestingness measure in [10,19] did discover relatively interesting itemsets. But, a drawback of this measure was that it only captured the partial effect of an itemset on the Bayesian network, because the measure is estimating the joint probability (i.e. support) of the itemset itself, and not the posterior probabilities conditioned on this itemset when entered to the network as new evidence (findings).

Moreover, the measure of interestingness in [18] could not discover unexpected (interesting) patterns. The most interesting pattern discovered when applying this measure on the KSL dataset was expected in the sense that it was suggesting an association between two attributes that were assumed to be dependent in the Bayesian network.

Nevertheless, both papers motivated the work in this paper and shaped the rationale behind our newly introduced Sensitivity measure.

3. Definitions and notation  Using database notation: Let A1, A2, A3,...,Ai be the attributes of a dataset. The domain of an attribute Ak is donated by Dom(Ak). Only categorical and discrete attributes with finite domains are considered.

Let I ,J, K,? ? (uppercase letters) be the  attribute sets,  where  an  attribute  set I={A1, A2, A3,...,Ak}. The domain of an attribute set I is:  Dom(I)=Dom(A1) ? Dom(A2) ? ... ? Dom(Ak).

Let i,j,... (lowercase letters) be the values from the domains of attributes and attribute sets, where i?Dom(I) is a value from the domain of the attribute set I.

PI denote the joint probability distribution of the attribute set I, where PI(i)=Pr(I=i) is the probability that I=i. Note that  ?i?Dom(I) PI = 1.

Let the pair (I,i) be an itemset, where I is an attribute set and i?Dom(I).

The support of an itemset (I,i) in a dataset is defined as suppData(I,i) = )(iPI .                     (3.1)     An itemset (I,i) is frequent if its support is greater or equal to some user specified minimum support.

Let BN be a Bayesian network over a set of attributes H = A1, A2, ...,An.  The Bayesian network is a directed acyclic graph BN = (V,E) with the set of vertices  V = VA1,VA2,...,VAn, and a set of edges E ? V ? V. Each vertix VA has a conditional probability distribution  ii parA P | , where pari ={Aj : (VAj, VAi) ? E} is  the set of attributes corresponding to the parents of VAi.

A Bayesian network BN over H encodes a joint probability distribution of H represented by  ? =  = n  i parA  BN H iiPP  |                       (3.2)  The support of an itemset (I,i) in a Bayesian network BN is defined as  suppBN(I,i) = )(iP BNI                         (3.3) where the probability is estimated from the joint probability encoded in the BN. An itemset is considered frequent if its support is greater than or equal to some user specified minimum support.

A belief in a Bayesian network BN is the posterior probability (i.e. conditioned on all findings currently entered to the BN).

Shanon?s mutual information, which is based on entropy, is a measure of how much information can be obtained about one random variable by observing another. According to Pearl [20], the residual uncertainty regarding the true value of a target variable X, given that Y is instantiated to y,  can be expressed as ;),(log),()|( ??=  x  yxPyxPyXH           (3.4)  and the average residual uncertainty in X, summed over all possible outcomes of y, is given by    ?  ??  =  ?=  ),( )(log),(  )|(log),()()|(  yxP yPyxP  yxPyxPyPYXH xy  (3.5)  Hence the total uncertainty-reducing potential of Y (or mutual information) is given by  )|()();( YXHXHYXI ?=           (3.6)  3.1 Sensitivity of an itemset relative to a Bayesian network  Let BN be a Bayesian network over an attribute set H, and let the pair (I,i) be an itemset, such that I ? H and i?Dom(I). Also, let Q be a query node such that Q?H, and F be a finding node such that F?H.

The sensitivity S of the itemset (I,i) with respect to the Bayesian network BN is given by  )|()(  );(),(    nmnewm  N  n new  N  m  nm  N  n new  N  m  FQHQH  FQIiIS  ?=  =  ??  ??  ==  ==    (3.7)  such that Iold(Qm;Fn) < Inew(Qm;Fn), where N is the total number of nodes, Iold(Qm;Fn) is the mutual information between any two nodes in the BN before entering any finding and Inew(Qm;Fn) is the mutual information between any two nodes after the itemset (I,i) is entered to the BN as evidence (findings). Also Hnew(Qm) is the entropy of the query node Qm, and Hnew(Qm|Fn) is the conditional entropy of the query node Qm given the finding node Fn .

The above condition is important so that only increases in mutual information are considered in the sum. As mentioned earlier, an increase designates a more uncertain belief (posterior probability).

3.2 Sensitivity of an attribute set relative to a Bayesian network  Since Bayesian network dependencies are modeled using attributes not itemsets, it is logical to think in terms of discovering interesting attribute sets rather than itemsets. The latter being usually orders of magnitude larger in number than attribute sets. Consequently, introducing a definition for the interestingness of an attribute set has the added advantage of greatly reducing the number of discovered patterns. The sensitivity of the attribute set I, is given by [10] ),(max)( )( iISIS IDomi?=                  (3.8) The IFE ranks the discovered patterns (attribute sets) in descending order by their sensitivity scores S(I). The top ranked patterns are deemed the most interesting.

Alternatively, IFE can use a user-specified threshold ? to prune attribute sets with S(I)??.

4. Algorithms  The IFE (IFEMiner Java class below) uses the two definitions of sensitivity presented in sections 3.1 and 3.2.

The IFE takes as input the Bayesian network representing the background knowledge, which is learned from the dataset. The IFE outputs the top interesting attribute sets ranked by their sensitivity scores. We present the pseudo code of the IFEMiner algorithm in Figure 1.

The IFE starts by finding the frequent itemsets in the dataset using a classical Apriori algorithm. Only frequent itemsets with supports greater than or equal to a user- specified minSupport are generated. Frequent itemsets are then passed to the ItemSetSensitivity algorithm (Figure 2 in next section) to compute their sensitivity scores. The itemsets along with their sensitivity scores are in turn     passed to the AttributeSetSensitivity algorithm (Figure 3 in section 4.2), to extract the most interesting attribute sets relative to a Bayesian network.

Figure 1. IFEMiner (IFE)   4.1 Algorithm for finding interesting itemsets  The ItemSetSensitivity algorithm (Figure 2) starts by compiling the Bayesian network BN in line 9 using compile() procedure from Netica (an application for belief networks)  to conduct a belief updating for all nodes in the BN. In lines 10-11 a sensitivity measuring object svObjectsQ[N] is created for each node in the BN; the sensitivity measuring object from Netica along with its getMutualInfo() method are used. In general, getMutualInfo() measures the mutual information between two nodes, which is how much the beliefs at one node (called the `query node') will change if a finding (pattern) is entered at another node (called the `findings node')[13]. Hence, in lines 13-20, the method is used to measure the mutual information between each and every node in the BN. The term `round' refers to the computation of mutual information between each and every node (including self). In line 20, the results of round0 are stored in the array Iold(Qm;Fn) as a snapshot of the mutual information among the nodes of the BN, before entering any evidence (itemset) to it; round0 serves as a benchmark against which successive rounds of mutual information computations are compared to.

Figure 2. ItemsetSensitivity algorithm   A new roundr is initiated in line 26 for each itemset entered to the BN as findings in line 24; this line encapsulates a loop among the items of the itemset at hand, where the state value of each item is entered to the corresponding node in the BN using the procedure     enterFinding(). For each itemset entered to the BN, the algorithm (line 33) re-computes the mutual information among the nodes of the BN using getMutualInfo() given all the findings entered so far. An itemset may constitute two items (each corresponding to a finding node) and above, up to the total number of nodes N.

To capture the effect of each itemset on the beliefs in isolation of the other itemsets, a retract operation is done using retractFindings() procedure (line 33) before starting a new round. The mutual information computations of each round are stored in the array Inew(Qm;Fn)  (line 33). During each roundr, the sensitivity score of the respective itemset is computed by summing the mutual information increases in line 35; and storing it in S(I,i) (line 36). The condition Iold(Qm;Fn) < Inew(Qm;Fn), is imposed in line 34 to capture the implicit alteration to the beliefs of the query node Qm, such that those beliefs are more uncertain.

4.2 Algorithm for finding interesting attribute sets  The AttributSetSensitivity algorithm (Figure 3) takes the interesting itemsets and their respective sensitivity scores as input. Each itemset is converted to an attribute set by applying an encoding that generates a `keyOrder', which is an integer sequence reflecting the attributes in each itemset. Thus clusters of attribute sets are formed by sorting the attribute sets by their keyOrder.

Figure 3. AttributeSetSensitivity algorithm   The algorithm proceeds by finding the attribute set with the maximum sensitivity score to represent each cluster.

Attribute sets with sensitivity scores less than or equal to the user specified ? can be pruned as an optional step.

Finally, the attribute sets are sorted again, but this time by  their sensitivity (interestingness) scores. Top ranking attribute sets are deemed the most interesting.

The computational complexity of IFEMiner is governed by several factors: 1) the number of frequent itemsets |L| generated by the Apriori, which is highly dependent on the minSupp parameter and the maximum size allowed for an itemset/attribute set; 2) size of the Bayesian network (i.e. the number of nodes N in the net); 3) size of the dataset; and 4) the order in which findings (itemsets) are entered to the BN. Netica automatically optimizes this ordering before conducting probabilistic inference.

Probabilistic inference (belief updating) in Netica is carried out using the join tree algorithm [5], whose computational complexity is exponential in the worst case. It is exponential in a graph parameter called the induced-width, which describes the largest cluster in a tree-embedding of the Bayesian network. The size of the induced width varies with various variable orderings.

Hence, the most costly part of the algorithm is reflected in lines 23-33 in Figure 2 for the following reasons: 1) The procedure enterFinding()  in line 24 is costly  because it triggers belief updating (probabilistic inference).

2) The procedure getMutualInfo() in line 33 is also time consuming when called for the first time after an itemset is entered as findings, because it also can trigger belief updating. Successive executions of this method to compute the mutual information among all the nodes in the net are much faster until the next itemset is entered to the net.

3) The cost escalates with larger values of |L| (number of itemsets) and N (number of nodes); but with |L| being the major overhead even for small values of N.

For this reason, the minSupport parameter shouldn't be very low so as not to generate thousands of frequent itemsets worthlessly.

5. Experimental results  Our emphasis in this section is on the usefulness of the IFE in discovering genuinely interesting unexpected patterns. The KSL dataset of Danish 70-year olds (1083 records - distributed with the DEAL Bayesian network package [2]) was chosen as a case study to test our approach and the quality of the attribute sets discovered.

The KSL dataset has 9 attributes (described in Table 1).

The corresponding Bayesian network presented in Figure 4 was constructed using the Netica application. We have used the same structure designed in [10]. The conditional probabilities were learned from the dataset. The discovered interesting patterns were then used to guide the update of the network's structure.

Table 1: The KSL dataset     Attribute Description FEV Forced ejection volume of the lungs Kol Cholesterol Hyp Hypertension (No/Yes) BMI Body Mass Index Smok Smoking (No/Yes) Alc Alcohol consumption (seldom/frequently) Work Working (Yes/No) Sex Male/Female Year Survey Year (1967/1984)     Figure 4. The KSL original network BN0   The IFE (IFEMiner) was applied three times, with different minSupport values, to find interesting attribute sets relative to the KSL Bayesian network (BN0). The minSupport values assigned were 0.1, 0.05 and 0.01 in the first, second and third trials, respectively. In all three trials, the same top three interesting attribute sets were discovered; but with a significant difference in computation time. Figure 5 shows that the computational complexity of the algorithm grows almost linearly for relatively small numbers of frequent itemsets (i.e. for larger minSupport values), but exponentially for large numbers of frequent itemsets (i.e. for small minSupport values). When minSupport was set to 0.1, computation time consumed 0.961 seconds (961 ms), but when minSupport was set to 0.01  the computation time jumped to 9.404 seconds (9404 ms); about 90.0% increase! This is attributed to the influx in the number of frequent itemsets from 691 to 7940 that IFEMiner had to process.

In section 4.3, we discussed how the number of frequent itemsets is a major overhead on the computational complexity of our algorithm. Table 2 presents the top 8 discovered attribute sets per trial.

Computation Time as a Function of Itemsets Number             691 1136 2148 4587 7940  No. of Frequent Itemsets  T im  e in  S ec  on ds   Figure 5. Computational complexity as a  function of time   Table 2. Top interesting attribute sets discovered in BN0  R a n k  Trial1 (minSupp =.1) Time [ms] = 961 |L| = 691 Max size = 5  Trial2 (minSupp = .05) Time [ms] = 2744 |L| = 2148 Max size = 5  1.

2.

3.

{FEV,Kol} = 5.850 {FEV,Hyp,Kol} = 5.688 {FEV,Hyp} = 5.688  {FEV, Kol} = 5.850 {FEV, Hyp,  Kol} =5.688 {FEV, Hyp} = 5.688  4.

5.

6.

7.

8.

9.

{Smok,Alc,Year} = 5.205 {Smok,Alc,Kol} = 5.198 {Smok,Alc} = 5.198 {Sex,Smok, Kol} = 5.113 {Sex,Smok} = 5.113 ?  {Smok,Alc,Year}= 5.205 {Smok,Alc,Kol} = 5.198 {Smok,Alc} = 5.198 {Sex,Smok,Kol} = 5.113 {Sex, Smok} = 5.113 ?   To further verify the capability of IFEMiner in discovering interesting (unexpected) patterns, 866 records of the KSL dataset (80%), drawn randomly, were used for learning, and the remaining 20% (217 records) for testing.

IFEMiner was applied two times with minSupport values of 0.1 and 0.05, respectively. In both trials, the attribute set {FEV, Kol} was again discovered as the top most interesting pattern, with a sensitivity score of 4.97.

5.1 Quantitative and qualitative analysis of results  The three top interesting attributes discovered were: {FEV,Kol} with a sensitivity score of 5.850, followed by {FEV,Hyp,Kol} and {FEV,Hyp} with an equal sensitivity score of 5.688. In Figure 4, since the Kol node is the only node without edges to any other node in the network (i.e. not enough background knowledge encoded about it), the IFE was expected to discover an interesting (unexpected) attribute set containing the cholesterol (Kol)     node. Quantitatively analyzing this result, the high sensitivity score attained by {FEV, Kol} suggests that this attribute set didn't comply with the beliefs (probabilities) of the Bayesain network. Thus, it lowered the certainty in those beliefs by pushing them more to uncertainty (i.e.

unexpectedness).

Qualitative wise, the discovery is suggesting a dependence relation between the forced ejection volume of the lungs (FEV) and the level of cholesterol (Kol) in the blood. We have researched the medical literature using the Internet but couldn't find a link between the two attributes. We resorted to consulting two doctors (internists). Both doctors affirmed the possibility of a relation between the two. A low forced ejection volume could affect the oxygen intake, which might in turn affect the efficiency of the metabolism in the body causing higher cholesterol levels.

We proceeded by adding a link between the FEV node and the Kol node. But which direction of dependence should we assume? We opted to update the Bayesian network in two ways. In the first modification we added the link FEV Kol as shown in Figure 6, while in the second modification we added the link Kol FEV as shown in Figure 7. For ease of reference we shall name the modified networks as BNFEV Kol and BNKol FEV, respectively.

Figure 6.  Modified KSL Bayesian network  BNFEV Kol    Figure 7. Modified KSL Bayesian network  BNKol FEV  Both networks were allowed to learn from the dataset.

The inverse relation between the two attributes was verified quantitatively by exploring the conditional probability tables (CPTs) of the Kol node in BNFEV Kol and the FEV node in BNKol FEV after learning. Tables 3 and 4 exhibit the learned conditional probability tables (CPTs) for the Kol node and FEV node, respectively. The probability P(Kol=High |FEV=Low)= 38.90% in Table 3 is relatively high in comparison to the other probabilities.

Likewise, the probability P(FEV=Low|Kol=High, Smok=No)=40.65%  in Table 4 is also relatively high.

Both probabilities do suggest that there is an association between cholesterol and the forced ejection volume of the lungs.

Table 3. CPT of node Kol in BNFEV?Kol  FEV Low Average High Low  Avg  High  22.19  18.85  32.59  38.90  48.83  47.32  38.90  32.32  20.09   Table 4. CPT of node FEV in BNKol?FEV  Smok Kol Low Average High  No No No  Low Avg High  25.46 22.62 40.65  47.27 62.78 51.22  27.27 14.60 8.13  Yes Yes Yes  Low Avg High  28.72 24.93 31.86  41.03 51.23 52.21  30.26 23.84 15.93   The process of discovering patterns, analyzing them and updating the Bayesian network accordingly can continue until no further unexpected attribute sets are discovered. Human intervention is still needed to decide     on the direction of association/dependence between attributes.

5.2 Direction of dependence  The following discussion lays the ground for the possibility of using the sensitivity measure and the discovered attribute sets in guiding the update process of the Bayesian network. To be more specific, we need to decide which modified network is better in representing the direction of dependence between the Kol node and the FEV node; BNFEV?Kol  or  BNKol?FEV?

First we need to apply IFEMiner on the two modified Bayesian networks BNFEV?Kol  and BNKol?FEV and analyze the results obtained by each, before deciding which network is better. Table 5 and Table 6 present the results obtained. After analyzing the differences in the results obtained, we were able to decide with confidence which network is better.

5.2.1 Analysis of results relative to BNFEV?Kol. The results obtained with minSupport=0.1 (Trial1) and minSupport=0.05 (Trial2) were the same for the top interesting attributes as shown in Table 5; {Smoke,Alc,Year} was the most interesting attribute set followed by {Smoke,Alc,Year} and {Sex,Smok}, respectively. If we compare these results with that of Trial1-minSupport=0.1 relative to BN0 (Table 2, 2nd column), we notice a very important observation: Attribute sets that included the node Kol; namely {FEV,Kol}, {FEV,Hyp,Kol} and {Smok,Alc,Kol}, were excluded from the newly discovered attribute sets because they are no longer unexpected. Thus, they were not profiled as interesting by IFEMiner because they are coherent with the knowledge encoded in the modified Bayesian network.

Table 5. Top interesting attribute sets discovered in BNFEV Kol  Rank Trail1 (minSupp=.1) Time [ms] = 952 |L| = 691 Max size = 5  Trial2 (minSupp = .05) Time [ms] = 2694 |L|= 2148 Max size = 5  1.

2.

3.

4.

5.

6.

{Smok,Alc,Year}=6.780 {Smok,Alc}=6.772 {Sex,Smok}=6.687 {Sex,Smok,Alc}=6.566 ? ?  {Smok,Alc,Year}=6.780 {Smok,Alc}=6.772 {Sex,Smok}=6.687 {Sex,Smok,Alc}=6.566 {Year,FEV,Hyp}=6.261 ?..

5.2.2 Analysis of results relative to BNKol?FEV. Table 6 shows the results obtained with minSupport=0.1 (Trial1) and minSupport=0.05 (Trial2). Focusing on the results of Trial1 in Table 6, the top most interesting attribute sets discovered were: {Work, FEV} followed by  {Year,Kol,Hyp}, {Work,Kol}, {Year, FEV} and {Kol,FEV}, respectively.

Table 6. Top interesting attribute sets discovered in BNKol FEV  Rank Trail1 (minSupp=.1) Time [ms] = 851 |L| = 691 Max size = 5  Trial2 (minSupp = .05) Time [ms] = 2444 |L|= 2148 Max size = 5  1.

2.

3.

4.

5.

6.

7.

{Work,FEV}=6.370 {Year,Kol,Hyp}=6.257 {Work,Kol}=6.230 {Year,FEV}=5.920 {Kol,FEV}=5.889 {Year,Work,FEV}=5.774 ?  {Work,FEV}=6.370 {Year,FEV,Hyp}=6.257 {Year,Kol,Hyp}=6.250 {Work,Kol}=6.230 {Year,FEV}=5.920 {Kol,FEV}=5.889 ?..

There are two important observations to note when comparing the above results with the results of Table 2: 1) Some of the attribute sets discovered relative to  BNKol FEV still include node Kol. This observation suggests that the network BNKol FEV is still profiling such attribute sets as unexpected because they affect the network negatively; pushing their beliefs to more uncertainty. This is ascertained by the next observation.

2) Not only was the attribute set {Kol,FEV}=5.889 still profiled as interesting (unexpected) by IFEMiner; it has actually attained a higher sensitivity score (5.889) than the previous sensitivity score (5.850) attained relative to BN0 as shown in Table 2. The persistence of the {Kol,FEV} attribute set suggests that adding the link Kol FEV is not adding accurate information regarding the relation (association) between the nodes Kol and FEV.

5.2.3 Which Network Won? The above mentioned observations provide sufficient evidence that the modified network BNFEV Kol is a better model in representing the direction of dependence between FEV and Kol. The forced ejection volume of the lungs seems to be one of the factors affecting the cholesterol levels in the blood.

This finding suggests that the sensitivity measure might have a potential to be used as a guiding tool in updating a Bayesian network's structure based on the discovered patterns.

To further experiment with the sensitivity measure and its newly discovered potential, IFEMiner was applied on BN2 - the Bayesian network in Figure 8. BN2 has the same nodes and structure of BN0 but with the following two differences: the Smok-FEV edge was removed and the Kol node was linked to the BMI (body mass index) node, because it is usually associated with cholesterol in the medical literature. This has left the node FEV free with no links to any other node. The objectives of this     experiment are: 1) to verify if the link BMI-Kol is a viable one; 2) to verify if IFEMiner can suggest a node to which the `FEV' node should be linked to; 3) and to verify if IFEMiner can still discover the attribute set {FEV, Kol} as interesting, using a different version of the net BN0; namely, BN2.

Figure 8. Modified KSL Bayesian network BN2     Figure 9. Modified KSL Bayesian network BN3   Applying IFEMiner on BN2 with minSupport values of 0.1, 0.05 and 0.01, rendered the attribute set {Hyp, Kol} as the most interesting with sensitivity score of 7.14.

Accordingly, BN2 was modified by removing the edge BMI-Kol and replacing it with Hyp-Kol; noting that the nodes BMI and Kol have a path between them through the Hyp node; indicating a conditional dependence or independence relation - the resulting network is BN3 as shown in Figure 9. With the discovery of {Hyp,Kol}, IFEMiner has fulfilled the first objective mentioned above by suggesting the link Hyp-Kol (or path BMI-Hyp- Kol) instead of BMI-Kol as a better way to link the Kol  node. IFEMiner was then applied on BN3 where it also discovered the attribute set {FEV,Kol} as the second most interesting with a sensitivity score of 5.59. It also discovered {Year,Work,FEV} in third place and {Sex,Smok,FEV} in fifth place, as suggestions for linking the FEV node. Thus, IFEMiner did fulfill both, the second and third above mentioned objectives by still discovering {FEV,Kol} and also suggesting ways to link the FEV node. Actually, IFEMiner has suggested the path Sex-Smok-FEV (i.e. by discovering the attribute set {Sex,Smok,FEV}) to link the `FEV' node in the same way as in the original Bayesian network BN0!

The above experiments showed that the IFE (or IFEMiner) did not only discover interesting unexpected attribute sets relative to a Bayesian network, but it also exhibited a potential in guiding the update process of this network. An interesting future research path would be to verify if the sensitivity measure can be used systematically to automate this process.

6. Conclusion and future work  A new measure of interestingness was presented to discover interesting (unexpected) patterns based on background knowledge represented by a Bayesian network. The new measure was devised to capture the sensitivity of the beliefs in a Bayesian network to the patterns discovered. Patterns that attain the highest sensitivity scores were deemed interesting. The discovered patterns were then used to update the Bayesian network. Netica, a powerful application for Bayesian networks was integrated with our algorithms through its Java API (NeticaJ).

The strength of the sensitivity measure in discovering genuinely unexpected patterns relative to the user?s background knowledge was verified by applying it on the KSL dataset as a case study. Two doctors (internists) were consulted regarding the attribute set {FEV,Kol} that was profiled as the most interesting by the IFE. Both doctors affirmed the possibility of a relation between the forced ejection volume of a person's lungs and the level of cholesterol in the blood; a low forced ejection volume could affect the oxygen intake, which might in turn affect the efficiency of the metabolism in the body causing higher cholesterol levels.

The direction of association/dependence between the attributes of an interesting pattern was an important concern to guide the update process of the Bayesian network. Astonishingly, the sensitivity measure exhibited experimentally, its potential in deciding the direction of dependence/association.

As for future work, we intend to work on enhancing the scalability and performance of the IFEMiner algorithm by finding a sensitivity set for each itemset based on the d- separation property inherent in Bayesian networks; so as     to minimize the number of times the mutual information computation is conducted.

The experimental results obtained have triggered a series of good questions that pose as interesting future research paths: Could the sensitivity measure be used in automating the process of modifying Bayesian networks based on the discovered interesting patterns? Could it be used to evaluate the quality of a Bayesian network's structure?  Which is more intelligent, the sensitivity measure or the entropy-based `gain' measure used in the ID3 algorithm for induction of decision trees [21]? ?  6. References  [1] R. Agrawal, T. Imielinski, and A. Swami, ?Mining  Association Rules between Sets of Items in Large Databases?, Proc. ACM SIGMOD Conference on Management of Data, 1993, pages 207-216.

[2] S. G. Bottcher, and Claus Dethlefsen,  Deal: A package for learning bayesian networks, 2003.

www.math.auc.dk/novo/Publications/bottcher:dethlefsen:03.

ps  [3] S. Chen, W. Hsu. and B. Liu, ?Using General Impressions to Analyze Discovered Classification Rules?,  in Proceedings Discovery and Data Mining (KDD-1997), 1997, page 31.

[4] S. Chen, W. Hsu, B. Liu , and Y. Ma,  ?Analyzing the Subjective Interestingness of Association Rules?, IEEE Intelligent Systems, 2000, v.5: pages 47-55.

[5] R.G. Cowell, A.P. Dawid, S.L. Lauritzen, and D.J.

Spiegelhalter, ?Bayesian Analysis in Expert Systems?, in Statistical Science, 1993, v.8, no.3: pages 219-283.

[6] L. Cristofer, and D. Simovici. ?Generating an Informative Cover for Association Rules?, Dept. of Computer Science, Massachusetts University, Boston, MA, USA, 2002.

[7] R. Dechter, ?Bucket Elimination: A Unifying Framework for Reasoning?, Artificial Intelligence,  1999, v.113, no.1&2: pages 41-85.

[8] Dunham, M.H.  Data Mining: Introductory and Advanced Topics, Princeton Hall, 2003.

[9] R. Hilderman, and H. Hamilton, ?Knowledge Discovery and Interestingness Measures: A Survey?,   Technical Report CS 99-04, Department of Computer Science - University of Regina, 1999.

[10] S. Jaroszewicz, and D. Simovici, ?Interestingness of Frequent Itemsets Using Bayesian Networks as Background Knowledge, in Proc. Of the 2004 ACM  Discovery and Data Mining (KDD-2004), 2004, pages 178- 186.

[11] M. Klemettinen, H. Mannila, P. Ronkainen, and A.I.

Verkamo, ?Finding Interesting Rules from Large Sets of Discovered Association Rules?, in Proceedings of the 3rd Management, 1994, pages 401-407.

[12] V. Kumar, J. Srivastava, and P. Tan, ?Selecting the Right Interestingness Measure for Association Patterns?, in Proc.

of the 8th ACM SIGKDD Int'l Conf. on Knowledge Discovery and Data Mining (KDD-2002), 2002, pages 32- 41.

[13] Netica from Norsys Software Corp.  Netica-J, API for Programming Bayesian Networks in Java.

http://www.norsys.com/netica-j.html  [14] B. Padmanabhan, and A. Tuzhilin, ?A Belief-Driven Method for Discovering Unexpected Patterns?, in Proceedings of the 4th Int'l Conference on Knowledge Discovery and Data Mining, 1998.

[15] B. Padmanabhan, and A. Tuzhilin, ?Small is Beautiful: Discovering the Minimal Set of Unexpected Patterns?, in Proceedings of the 6th ACM SIGKDD Int?l Conference on Knowledge Discovery and Data Mining (KDD-2000), 2000, pages 54-63.

[16] S. Sahar, ?Interestingness Via What is Not Interesting?, in and Data Mining, 1999, pages 332-336.

[17] A. Silberschatz , and A. Tuzhilin, ?On Subjective Measures of Interestingness in Knowledge Discovery?, in Knowledge Discovery and Data Mining, 1995, pages 275-281.

[18] A. Silberschatz , and A. Tuzhilin, ?What Makes Patterns Interesting in Knowledge Discovery Systems?, IEEE Trans. on Knowledge and Data Engineering.  Special Issue on Data Mining, 1996, v.5, no.6: pages 970-974.

[19] S. Jaroszewicz, and T. Scheffer, ?Fast Discovery of Unexpected Patterns in Data, Relative to a Bayesian Network?, in Proc. of the 2005 ACM SIGKDD Data Mining (KDD-2005), 2005.

[20] Pear, J., Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, Morgan Kaufmann, 1988.

[21] Quinlan, J.R., Induction of Decision Trees: Readings in Machine Learning, Morgan Kaufmann, 1990. Originally published in Machine Learning 1:81--106, 1986.

