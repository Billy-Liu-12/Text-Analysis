Paper id 63

Abstract?The mentioned system is designed to find the most  frequent combinations of items. It is based on developing an efficient algorithm that outperforms the best available frequent pattern algorithms on a number of typical data sets. This will help in marketing and sales. The technique can be used to uncover interesting cross-sells and related products. Three different algorithms from association mining have been implanted and then best combination method is utilized to find more interesting results. The analyst then can perform the data mining and extraction and finally conclude the result and make appropriate decision.

Index Terms? association rule mining, data mining,  maximal frequent pattern, mining evolution

I. INTRODUCTION This system is a useful tool for discovering customer  purchasing patterns by extracting associations or co- occurrences from transactional databases. It also tracks the sales using the clustering technique, it generally clusters up the data in the timely fashion know as Time Series [1] where it works and merges the revenue thus collected in different seasons. It analyses the combinations of products the customers buy frequently.

The idea behind this system is to examine the orders for products that have been purchased together. For example using a tracking system you might uncover the fact that customers tend to buy hot dogs and buns together. Using this information you might organize the store so that hot dogs and buns are next to each other. In an e-commerce environment you might create a cross-sell rule [2] to offer the shopper buns whenever they place hot dogs in their shopping cart.

The better we analyze the use of customer purchasing behavior, better will be profit and sales to the enterprises [3].

Knowing what products people purchase as a group can be very helpful to a retailer or to any other company. A store   This research work was supported by Thadomal Shahani Engineering  College, Bandra(West), Mumbai-400050, Maharashtra, India. This paper presents a significantly improved design, construction and a complete rewrite and evaluation of our mining method implementation. The views, ideas and conclusions do not necessarily reflect the views of the sponsors.

Saurabh Malgaonkar, Sakshi Surve and Tejas Hirave are with the Department of Computer Engineering, Thadomal Shahani Engineering College, Mumbai University, Mumbai, India. (e-mails: saurabhmalgaonkar@gmail.com, geetams24@rediffmail.com, tejas1mumbai@gmail.com)  Manuscript received September 10, 2012.

could use this information to place products frequently sold together into the same area, while a catalog or World Wide Web merchant could use it to determine the layout of their catalog and order form. Direct marketers could use the sales tracking results to determine what new products to offer to their prior customers.

The strength of this system is that by using computer data mining tools, it?s not necessary for a person to think of what products consumers would logically buy together, instead the customers? sales data is allowed to speak for itself. This is a good example of data-driven marketing.

The system satisfies the following objectives:- ? To make more informed decisions about product placement, pricing, promotion and profitability.

? To learn more about customer behavior.

? To find out which products perform similarly to each other.

? To determine which products should be placed near each other.

? To find out which products should be cross-sold.

? To find out if there are any successful products that  have no significant related elements.

This system identifies customers purchasing habits. It  provides insight into the combination of products within a customer?s 'basket' [2]. The term 'basket' normally applies to a single order. However, the analysis [4] can be applied to other variations. We often compare all orders associated with a single customer. Ultimately, the purchasing insights provide the potential to create cross sell propositions. Some of the main algorithms [1][7] of mining (APRIORI, ECLAT and FP- Growth) are studied and tested for performance.



II. ALGORITHMS  A. Apriori Algorithm Apriori is designed to operate on databases containing  transactions for example, collections of items bought by customers or details of a website frequentation.

As is common in association rule mining, given a set of itemsets (for instance, sets of retail transactions, each listing individual items purchased), the algorithm attempts to find subsets which are common to at least a minimum number C of the itemsets. Apriori uses a "bottom up" approach, where frequent subsets are extended one item at a time (a step known as candidate generation) and groups of candidates are tested against the data. Apriori uses breadth-first search and a tree  Use of Mining Techniques To Improve The Effectiveness of Marketing and Sales  Saurabh Malgaonkar, Sakshi Surve and Tejas Hirave    Paper id 63    structure to count candidate item sets efficie candidate item sets of length k from item set Then it prunes the candidates which have a pattern. According to the downward clos candidate set contains all frequent k-length that, it scans the transaction database to de item sets among the candidates.

Apriori, suffers from a number of ineffic offs. Candidate generation generates large nu (the algorithm attempts to load up the cand many as possible before each scan). B exploration (essentially a breadth-first traver lattice) finds any maximal subset S only after proper subsets.

B. FP Growth Algorithm This algorithm tends to find the combinatio  on the pattern that frequently occurs, hence th Pattern Algorithm. It allows frequent it without candidate itemset generation. How different from Apriori:  APRIORI:  It uses a generate-and-test approach gen itemsets and tests if they are frequent an candidate itemsets is expensive (in both space  FP-GROWTH:  Allows frequent itemset discovery without generation.

Two step approach:  Step 1: Build a compact data structure called t  Built using 2 passes over the data-set.

Step 2: Extracts frequent itemsets directly from  It thus improves over Apriori due to following  ? Reduce passes of transactio  ? Shrink number of candidate  ? Facilitate support counting o  ? Multiple scans of transactio  ? Huge number of candidates  ? Tedious workload of supp candidates.

The Advantages of FP-Growth are as follows  COMPLETENESS: Preserve complete frequent pattern mining. Never break a lon transaction.

COMPACTNESS: Reduce irrelevant info? are gone. Items in frequency descending frequently occurring, the more likely to be sha  Never be larger than the original database links and the count field).

ently. It generates s of length k ? 1.

an infrequent sub sure lemma, the  h item sets. After etermine frequent  ciencies or trade- umbers of subsets didate set with as Bottom-up subset rsal of the subset all 2 | S | ? 1 of its  on of items based he name Frequent temset discovery w FP-Growth is  nerates candidate nd generation of e and time).

candidate itemset  the FP-tree.

m the FP-tree.

g:  n database scans.

es.

of candidates.

on database.

s.

port counting for  :  information for ng pattern of any  ?infrequent items order: the more  ared.

(not count node-  There exist examples of databases, could be over 100.

The size of the FP-trees bounded by the frequent items in the database.

The height of the tree is bound by frequent items in a transaction.

C. Eclat Algorithm The Eclat algorithm is used to  Itemset mining lets us find frequen consumer buys milk, he also buys b is called an association rule and is domains. The basic idea for the ec tidset intersections to compute th itemset avoiding the generation of in the prefix tree.

ALGORITHM:  The Eclat algorithm is defined r use all the single items with their call, the function Intersect Tidsets v pair  with all the others pair candidates  . If the new candid to the set  . Then, recursively, itemsets in the  branch. The algo manner to find all the frequent sets.

IMPLEMANTATION:  The eclat algorithm can be found in system.

? R package: arule  ? Method: eclat  ? Documentation : a  USAGE:  eclat(data, parameter = NULL, contr  ARGUMENTS:  Data, Parameter, Control, Value.



III. DESIG A data storage which attempts to  existing architecture will most proba performance problems. Those per cause a data storage program to de bad fit for the existing architecture abandon the system.

For the itemsets/items tracking s recursive table. A recursive table Basket to on itself.

The analyst has to perform data information sources(warehouses, databases etc.) from which the inter extracted. After which the analyst conditions as per the requirements, t   , where compression ratio  y the overall occurrences of  y the maximal number of  o perform itemset mining.

nt patterns in data like if a bread. This type of pattern used in many application  lat algorithm is the use of e support of a candidate subsets that does not exist  recursively. The initial call tidsets. In each recursive  verifies each itemset-tidset rs  to generate new  date is frequent, it is added , it finds all the frequent orithm searches in a DFS  the arule package of R  arules package  rol = NULL).

GN o perform tracking using its ably experience significant rformance problems may eem the tracking system a e and therefore causing to  system the data storage is a [4] allows each Market  abase connectivity with the data mart, distributed  resting patterns have to be can mention the specific  then check the transactions    Paper id 63     and view the best combination. Many transactions that occur may contain the same sets of items. Even if items of different transactions are originally distinct, removing of the infrequent items could make their item sets identical. Moreover, two transactions that do not contain an identical set of items may have a subset of the items in common among them. The transaction tree groups such transactions.

The transaction tree is further truncated by discarding the number of nodes using a logical reduction scheme. A complete prefix tree has many identical subtrees in it and building a complete prefix tree requires more memory and so the tree is reduced by storing the information of the identical subtrees together. This process makes it a completely optimized transaction tree. In this way the traversals of the transactions are reduced thus improving the performance and efficiency of the mining mechanism. During the construction of the tree the counts at each node are stored in an array so that the level for an entry is the array index which is not stored.

The designed method consists of constructing and maintaining an item table 'ITable' along with the various transactions  'TLink'  linked to it described as:  1. ITable: It stores all individually frequent items and the support of each item.

2. TLink: It indicates all the transactions of the database containing the frequent items.

Fig. 1.  Basic Processing Cycle. The data needs to be cleaned before it is actually to be mined.

Entries in ITable and TLink are added or modified by scanning the database. After which the 1-freq items are identified in the ITable from their support counts. The infrequent items are then removed from the TLink as they are not useful in the next step because of the anti-monotone property. The unwanted transactions that contain the entire set of items which fall below the mentioned support level are removed in the start itself. After this stage is complete and all the data is cleaned as required then the actual mining process takes place where the all the frequent item sets of two or more items are mined.

In order to get the best combination a new method of mining is designed and implemented which is as follows: The process  involves the following steps :  1. The database is scanned to identify all 1-freq items, which are then stored in ITable. All entries in the ITable are sorted in the frequency of their ascending order and then the items are mapped to new identifiers that are the ascending sequence of integers.

2. Using the results of step 1, only 1-freq items are extracted from the database. They are then mapped to the new item identifiers and the transactions are inserted into the reduced transaction tree. A pointer is maintained to the  subset of each itemset. This pointer is used as a starting point to mine all frequent itemsets corresponding to the paths ending at nodes of the corresponding subset.

3. Mining Process: All the frequent itemsets of two or more items are mined in a recursive manner.

Actual Mining Working Procedure:  1. Construct the ITable and the reduced tree based upon the mentioned support threshold.

2. Construct the newly mapped entries.

3. Scan the newly mapped indexed entries.

3.1 For each newly formed entries:  3.1.1 Scan the itemset/item entry in each of the table entries.

3.1.2 Utilize the corresponding node pointer of the reduced tree.

3.1.3 Traverse the corresponding tree levels (Root - Left - Right/Root - Right - Left) depending upon the itemset/item position.

3.1.3.1 If itemset/item found -> Record and increment its count by its frequency of occurrence; Reset search for next entry; goto step 3.1.1  3.1.3.2 Else -> Shrink itemset area by 1 item count from   left ; Reset search for this new entry; Goto step 3.1.1  3.1.4 If all entries traversed, no entries left to scan; Goto step 4.

4. Stop.

After all the entries have been covered then  they are remapped into their original values and the frequency of per itemset or items is derived as per the entry.



IV. IMPLEMENTATION The system was successfully deployed and tested on  Pentium dual core system with 2GB RAM and a 250GB of HDD.

The front end was developed using JAVA [5] and mySQL [6] was used as the back end for the purpose of data storage.



V. RESULTS Datasets which  were used to test the performance were of  two types: Dense Dataset and Sparse Dataset. Dense Dataset is a thick dataset that produces many long patterns of frequent item sets for very high values of support. Sparse Dataset, contains infrequent data which is very less opaque compared to the Dense Dataset.

All the algorithms were evaluated on their runtime(seconds) basis where their respective results were noted for the particular values of thresholds.

Paper id 63     A. Dense  Dataset Tests   TABLE I.

RUNTIME EVALUATION OF APRIORI, ECLAT &  FP GROWTH ON DENSE  DATASET SUPPORT LEVELS        Fig. 2.  Dense Dataset Performance Evaluation    TABLE II.

RUNTIME EVALUATION OF BEST COMBINATION ON DENSE DATASET SUPPORT LEVELS      Fig. 3.  Dense Dataset Performance Evaluation For Best Combination Method        B. Sparse  Dataset Tests   TABLE III.

RUNTIME EVALUATION OF APRIORI, ECLAT &  FP GROWTH ON SPARSE  DATASET SUPPORT LEVELS          Fig. 4.  Sparse Dataset Performance Evaluation    TABLE IV.

RUNTIME EVALUATION OF BEST COMBINATION ON SPARSE DATASET SUPPORT LEVELS        Fig. 5. Sparse Dataset Performance Evaluation For Best Combination Method  From the above tests it was observed that the best combination method outperforms the other algorithms at most support levels. On Dense Dataset, it performs better than other algorithms as the number of  TLink entries are very low compared to the number of transactions in the database. On Sparse Dataset, the reduction in number of TLink entries by    Paper id 63     removing the unwanted transactions enables the developed method to perform better than the other algorithms.

At lower support levels on relatively infrequent data sets, the optimizing scheme does not provide the same degree of deduction in the cost of traversing the transactions. Therefore, the other algorithms perform relatively same or slightly better.



VI. CONCLUSION The influence of a relatively compact method boosts the  performance of frequent pattern mining. This method presented the sequence of design changes and their impact on the performance of corresponding algorithms.

The method was utilized with algorithms Apriori, Eclat and FP-Growth on different datasets and the results show that our method gave a better performance than all others on various support levels.

Application Extension:-  ? Opportunity Tracking  ? Opportunity Analysis  ? Sales Tracking  ? Product Tracking  ? Discount/Pricing Calculation

VII. FUTURE WORK This method is applicable for very large databases where  the available memory space is valuable and requires optimization. It can be further tuned for better performance and efficiency.

It can be applied in applications that deal in mining on live data on daily timely basis such as stock markets, financial statistics collection, weather forecasting etc.

It's application can be utilized for industrial usage where precise pattern study is required with a large data sets to work on and so it can be modified according to their requirements.

The method can be slightly improved so that it can give better performance and more fast results for sparse datasets.

