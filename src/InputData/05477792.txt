Research on Privacy Preserving Association Rule Mining A Survey

AbstractAssociation rule mining is one of the hottest  research areas that investigate the automatic extraction of  previously unknown patterns or rules from large amounts of  data. Recently, there has been growing concern over the  privacy implications of association rule mining. This paper  described the basic concepts related to association rule mining,  and analyzed and summarized the general principles and  methods of privacy preserving association rule mining, and  pointed out the drawback of the these methods . It also  introduced an effective metrics for measuring side-effects  resulted from privacy preserving process. Finally the present  problems and directions for future research are discussed.

Keywords-privacy preserving; association rule mining;  randomization; secure multi-party computation

I. INTRODUCTION  In recent years, with the explosive development in  Internet, storage and data processing technologies, privacy  preserving association rule mining has been paid increasing  attention in business fields. The association rule mining  problem was first proposed by Agrawal et al.[1]. In order to  make a publicly available system secure, we must ensure not  only that private sensitive data have been trimmed out, but  also to make sure that certain inference channels have been  blocked as well. Under privacy constraints, the association  rule mining problem was extensive researched. Many  effective methods for privacy preserving association rule  mining have been proposed[4-15]. But most of those  methods may result in information loss and side-effects in  some extent, such as non-sensitive rules falsely hidden and  spurious rules falsely generated, may be produced in the  sensitive rule hiding process. That is, an essential problem  under the context is trade-off between the data utility and the  disclosure risk.

TKe rest of this paper is organized as follows. In sectioQ  ?, we will review the basic concepts of the association rule    mining. In sectioQ? , we will analyze the methods for  privacy preserving on original transaction data. Methods for  privacy preserving on sensitive rules hidden will be  discussed in sectioQ ? . Issues in distributed privacy-  preserving association rule mining will be discussed in  sectioQ?. In sectioQ?, we will describe an effective metric  for measuring side-effects resulted from privacy preserving  process. Section?? contains the conclusions and discussions.



II. BASIC CONCEPTS  Let }I,,I,I{I m?21? be a set of items[2]. Let D be a  database of transactions where each transaction T is a set of  items such that IT ? . Each transaction is associated to an  identifier, call TID. A transaction T  is said to contain A if  and only if TA ? . An association rule is an implication of  the form BA ? , where IA ? , IB ? , and ??? BA . The  rule BA ? holds in the transaction set D with support s ,  where s is the percentage of transactions in D that  contain BA ? . The rule BA ? has confidence c  in the  transaction set D . That is,  D  BA  )BA(P)BAsup(  ?  ????                 (1)  A  BA  ABPBAconf  ?  ??? )|()(                   (2)  Where A is named as the support count of the set of  items A in the set of transactions D , as denoted  by )A(countsup_ . A  occurs in a transaction T, if and only  if TA ? . Rules that satisfy both a minimum support  threshold ( supmin_ ) and a minimum confidence threshold  ( confmin_ ) are called strong. A set of items referred to as  an itemset. An itemset that contains k items is a k -itemset.

Itemsets that satisfy supmin_ is named as frequent itemsets.

All strong association rules result from frequent itemsets.



III. METHODS FOR PROTECTING THE ORIGINAL  TRANSACTION DATA  To prevent personal true records being disclosed, Warner  proposed the randomized response method for survey    results[3]. The method deals with a single boolean attribute.

The value of the attribute is retained with probability p  and  flipped with probability p?1 . Based on Warners method  idea, reference [4] developed a method called uniform  randomization. Before sending a transaction to the data  mining server, the client takes each item and with  probability p  replaces it by a new item not originally present  in this transaction. In the following, we will describe the  basic principle of the uniform randomization method, which  contains two main randomization operator as select-a-size  and cut-and-paste.

_____________________________________  978-1-4244-5265-1/10/$26.00 2010 IEEE  Definition 1 (select-a-size) A select-a-size randomization  operator has the following parameters, for each possible  input transaction size m :  Default probability of an item (also called randomization  level) ),(m 10  ;  Transaction subset size selection  probabilities ]m[p,],[p],[p mmm ?10 , such that  every 0][ ?jpm and 110 ???? ]m[p,,][p][p mmm ? .

Given a sequence of transactions }t,,t,t{T n?21? , the  operator takes each transaction it independently and proceeds  as follows to obtain transaction 'it ( mti ? ).

1) The operator selects an integer j at random from the  set }m,,,{ ?10 so that ]j[p]j[P m?selected is .

2) It selects j items from it , uniformly at random  (without replacement). These items, and no other items  of it are placed into  '  it .

3) It considers each item ita  in turn and tosses a coin  with probability m  of heads and m  ?1 of tails. All those  items for which the coin faces heads are added to 'it .

Definition 2 (cut-and-paste) A cut-and-paste  randomization operator is a special case of a select-a-size  operator. For each possible input transaction size m , it has  two parameters: ),(m 10    (randomization level) and an  integer 0?mK (the cutoff). The operator takes each input  transaction it independently and proceeds as follows to obtain  transaction 'it ( mti ? ).

1) It chooses an integer j uniformly at random between  0 and mK ; if mj ? , it sets mj ? .

2) The operator selects j items out of it uniformly at  random (without replacement). These items are placed  into  '  it .

3) Each other item (including the rest of it ) is placed  into  '  it with probability m  independently.

Since the above two randomization operators are the  easiest and safest to implement in practice (illustrated by  extensive experiments), so we only need to focus mostly on  optimization of the two parameters, m  and mK . The above  randomization method not only provides privacy guarantee,  but satisfies the requirement of association rule mining.

Except for the above methods for privacy preserving,  many other methods are also widely used. For example,  itemset graph-based method[5], which goes through the list  of itemsets, and applies a bottom-up followed by a top-down  traversal of the itemset graph. In each traversal, the support  of the currently scanned frequent itemset decreases by one  until the support count of the frequent itemset below  the supmin_ threshold. Exchange-based method, which  through exchanging two transaction data item by item to  confuse the personal true records to achieve the purpose of  preserving privacy.



IV. METHODS FOR PROTECTING THE SENSITIVE RULES  Privacy preserving association rule mining needs to  prevent disclosure not only of confidential personal  information from original or aggregated data, but also to  prevent data mining techniques from discovering sensitive  knowledge. In this section, we will discuss the purposed  methods for privacy preserving on sensitive rules. It is  known that each strong rule extracts from frequent itemsets.

To prevent sensitive rules (determined by the experts) being  mined in the process of association rule mining, many  methods are developed[5-13], all of which are based on  reducing the support and confidence of rules that specify  how significant they are. In order to achieve this goal,  transactions are modified by removing some items, or  inserting new items depending on the hiding strategy. In the  following, we will discuss some general methods for hiding  sensitive rules.

Let R be a set of rules extracted from the transaction  database with the supmin_ and the confmin_ . Let hR be a  set of sensitive rules determined by the experts. In order to  hide a rule BA ? , on the basis of (1) and (2), we can either  decrease the support of the itemset BA ? below  the supmin_ threshold, or decrease the confidence below  the confmin_ threshold while giving as little harm as  possible to the remaining non-sensitive rules to keep the data  quality as high as possible. That is, either we turn to 0 the  value of a non-zero item in a specific transaction, or we turn  to 1 all the zero items in a transaction that partially supports  an itemset.

A. Support-based Algorithms  Incorporating (1) and (2), we can decrease the support of  the itemset BA ?  below the supmin_ threshold or decrease  the confidence below the confmin_ threshold by decreasing  the support of either the rule antecedent A , or the rule  consequent B . The following is the specific algorithm  process[6].

? Algorithm 1  INPUT: a set of rules to hide hR , the source database D ,  the supmin_ threshold, the confmin_  threshold  OUTPUT: the database D transformed so that the rules  in hR cannot be mined  FOREACH rule r  IN hR  DO  {  WHILE ( )r(conf ? confmin_ AND )rsup( ? supmin_ )  {  T = { Dt   | t  supports r }  // sort T in ascending order of size of the transactions and  choose the one with the lowest size  t = choose_transaction(T )  // choose the item of r with the minimum impact on the    (| r | ? 1)-itemsets  j = choose_item( r )  // set to 0 the bit of items_of_list.t that represents item  j  set to 0( j , items_of_list.t )  1?? )rsup()rsup(  ))r(presup(/)rsup()r(conf ?  }  rRR hh ??  }  B. Confidence-based Algorithms  We decrease the confidence of the rule (a) by increasing  the support of the rule antecedent A , through transactions  that partially support both A and B , (b) or by decreasing the  support of the rule consequent B , in transactions that support  both A and B . The following is the specific algorithm  process.

? Algorithm 2a  INPUT and OUTPUT is same as Algorithm 1  FOREACH rule r  IN hR  DO  {  WHILE ( )r(conf ? confmin_ )  {  T = { Dt   | t  partially supports )r(pre }  // count how many items of )r(pre are in each  transaction of T  FOREACH transaction t  IN T  DO  {  items_num.t = | I |?Hamming_dist( )r(pre ,  items_of_list.t )  }  // sort transactions of T  in descending order of number  of items of )r(pre  contained  sort(T )  // pick the transaction of T  with the highest number of  items  ][Tt 1?  // set to 1 all the bits of t  that represent items in )r(pre  set all 1( items_of_list.t , )r(pre )  1?? ))r(presup())r(presup(  ))r(leftsup(/)rsup()r(conf ?  }    rRR hh ??  }  ? Algorithm 2b  INPUT and OUTPUT is same as Algorithm 1  FOREACH rule r  IN hR  DO  {  WHILE ( )r(conf ? confmin_ )  {  T = { Dt   | t  supports r }  // sort T in ascending order of size of the transactions and  choose the one with the lowest size  t = choose_transaction( T )  // choose the item of )r(pre with the minimum impact  on the (| )r(pre | ? 1)-itemsets  j = choose_item( )r(pre )  // set to 0 the bit of items_of_list.t that represents item  j  set to 0( j , items_of_list.t )  1?? )rsup()rsup(  ))r(presup(/)rsup()r(conf ?  }  rRR hh ??  }  C. Unknown-based Algorithms  The algorithms in Section 4.1 and section 4.2 all use the  same principle of inserting or deleting items (inverse  between 0 and 1) to decrease the support or the confidence  such that sensitive rules are hidden. In this section, we will  discuss an algorithm of using unknowns to prevent discovery  of association rules, which is purposed by Saygin Y, et al[13].

The goal of the algorithm is to obscure a given set of  sensitive rules by replacing known values with unknowns (?),  while minimizing the side-effects on non-sensitive rules.

Since it has a degree of uncertainty, the support equation and  the confidence equation are modified from a single value to  an interval. Such as, ( supmin_ , supmax_ ) and  ( confmin_ , confmax_ ). Hence, the algorithm has higher  computational complexity. In addition, Saygin Y, et al only  give arguments as to the difficulty of recovering sensitive  rules, and test the side-effects on non-sensitive rules by  experiments. The safety of the algorithm needs to be  formally proven yet. Please refer to [13] for the specific    algorithm process. In practice, the adversary may achieve  part sensitive rules by greedily replacing unknown values(?)  with knowns(0 or 1).



V. DISTRIBUTED PRIVACY PRESERVING ASSOCIATION  RULE MINING  The growth of Internet has triggered tremendous  opportunities for distributed data mining, where people  jointly conducting mining tasks based on the private inputs  they supplies. These mining tasks could occur between  mutual un-trusted parties, or even between competitors. So  privacy will become a primary concern. In distributed setting,  privacy-preserving association rule mining algorithms  require collaboration between parties to compute the results  or share no-sensitive mining results, while provably leading  to the disclosure of any sensitive information.

In general, data distribution has two kinds of forms,  horizontally partitioned and vertically partitioned.

Horizontally partitioned data: each site has complete  information on a distinct set of entities, and an integrated  dataset consists of the union of these datasets. In contrast,  vertically partitioned data has different types of information  at each site; each has partial information on the same set of  entities.

In [14], the authors have studied the privacy-preserving  association rule mining problem over horizontally partitioned  data. Their methods incorporate cryptographic techniques to  minimize the information shared, while adding little  overhead to the mining task. The problem of privately  mining association rules in vertically partitioned data was  addressed in [15-16]. All these methods are almost based on  Secure Multiparty Computation (SMC) technology.

In distributed privacy preserving association rule mining  areas, SMC technology is mainly consist of a set of secure  sub-protocols, such as, Secure Sum, Secure Comparison, Dot  Product Protocol, Secure Intersection, Secure Set Union and  so on. In the following, we will briefly describe the basic  idea of two kinds of secure sub-protocols used in  horizontally partitioned and vertically partitioned setting.

A. Secure Sum  Secure Sum can securely calculate the sum of values  from different sites. Assume that each site i  has some  value iv  and all sites want to securely    compute nv,,vvS ???? ?21 , where iv is known to be in the  range [0..m]. In horizontally partitioned setting, we can  securely calculate the global support count of an itenset by  the secure sum sub-protocol.

B. Dot Product Protocol  Many secure dot product protocols have been proposed  in the past. The problem is defined as follows: Alice has a n-  dimensional vector )x,,x,x(X n?21?  while Bob has a n-  dimensional vector )y,,y,y(Y n?21? . At the end of the  protocol, Alice should get ba rYXr ???  where br is a  random number chosen from uniform distribution that is  known only to Bob, and nn yx,,yxyxYX ????? ?2211 .

Through the dot product protocol we can securely calculate  the global support count of an itemset whose items are  located at different sites in vertically partitioned setting.



VI.  METRICS FOR MEASURING SIDE-EFFECTS  Let R be the set of rules mined from D and sR be the set  of sensitive rules that must be protected according to some  privacy policies. The goal is to transform D into 'D so that  sensitive rules are hidden. Let 'R be the set of rules mined  from 'D .

Ideally, s  ' RRR ?? . Nevertheless, undesired side-effects,  e.g., non-sensitive rules falsely hidden and spurious rules  falsely generated, may be produced in the sensitive rule  hiding process. So in reality, s  ' RRR ?? . To measure the  amount of side-effects resulted from privacy preserving  process, we introduce one related metric named as Side-  effects Factor (SEF) in follows[10].

)RR(  ))RR(R(  SEF  s  s  '  ?  ??  ?                  (3)  Where R  is the size of the set R . It is obvious  that SEF equals to 0 when s  ' RRR ?? holds. The bigger the    distance between SEF and 0, the larger the side-effects.

Hence, we should try to decrease the side-effects through  optimizing the privacy preserving algorithm.



VII.   CONCLUSIONS AND FUTURE WORK  In this paper, we carried out a wide survey of the  different approaches for privacy-preserving association rule  mining, and analyzed the major algorithms available for each  method and pointed out the existing drawback. However, it  was proved that Optimal Sanitization Is NP-hard[5]. All the  purposed methods are only approximate to our goal of  privacy preserving. We need to further perfect those  approaches or develop some new methods for achieving the  trade-off: privacy and accuracy. Hence, we recognize that the  following problems should be concentrated on.

1) Most approaches are based on some strict  assumptions. We should generalize these algorithms so that  they can be more widely used in practice.

2) In distributed privacy preserving association rule  mining areas, we should explore more effective algorithms  and look for a balance between disclosure cost, computation  cost and communication cost.

3) Privacy and accuracy is a pair of contradiction;  improving one usually incurs a cost in the other. How to  apply various optimizations to achieve a trade-off should  also be paid more attention.

4) Side-effects is unavoidable in data sanitization  process. How to measure and decrease its impact on privacy  preserving needs to be considered carefully. We also need to  define some metrics for measuring.

5) Can we extend the ideas of the privacy preserving  association rule mining to other data mining contexts? such  as classification, clustering, etc.

ACKNOWLEDGEMENTS  This paper was supported by the Natural Science  Foundation of Education Department of Anhui Province in  China (KJ2009B075Z, KJ2009B128Z).

