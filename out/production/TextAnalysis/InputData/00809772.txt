Mining Fuzzy Quantitative Association Rules

Abstract  Given a relational database and a set of fuzzy terms de- fined for some attributes, we consider the problem of min- ing fuzzy quantitative association rules that may contain crisp values, intervals, and fuzzy terms in both antecedent and consequent. We present an algorithm extended from the equi?depth partition (EDP) algorithm for solving this problem. Our approach combines interval partition with pre?defined fuzzy terms and is more general.

1. Introduction  An association rule [1], expressed as Y ! X , indicates a pattern in a transaction database that transactions containing items Y also contain items X . The significance of such a rule is measured by its support and confidence. The support is the proportion of transactions that contain both X and Y , and the confidence is the proportion of transactions con- taining Y that also contain X . The problem is to find all as- sociation rules that satisfy user?specified minimum support and confidence. Many algorithms [1, 2, 5, 3] have been pro- posed for solving the problem. Association rules are useful for marketing, document clustering, Web management, etc..

The quantitative association rule [4, 6] mining views records in a relational database as transactions that con- tain attribute?value pairs (or attribute?interval pairs, if the attribute is numerical) as items. A quantitative associa- tion rule may have attribute?value/interval pairs in both an- tecedent and consequent. For example, a quantitative as- sociation rule may be Age 2 [40; 45] and FastT rack = no ! Married = yes. The main reason for quantitative association rule mining is that numerical attributes typically contains many distinct values. The support for any particu- lar value is likely to be low, while that for intervals are much higher.

?This research was partially supported by a research grant of the Natu- ral Science and Engineering Research Council of Canada.

For many applications, an association rule may be more interesting if it reveals relationship among some useful con- cepts, such as ?high income?, ?new car?, and ?frequent cus- tomer?. These concepts are often imprecise or uncertain.

In this paper, we consider the problem of mining fuzzy quantitative association rules in relational databases. In- teresting concepts are defined using fuzzy terms and inter- preted based on fuzzy set [7]. We refer association rules in- volving fuzzy terms as fuzzy quantitative association rules.

For example, Age = young and Income = high !

RiskLevel = mediumHigh is a fuzzy quantitative asso- ciation rule, where ?young?, ?high? and ?mediumHigh? are fuzzy terms. We define the problem of mining fuzzy quan- titative association rules and present an algorithm extend from the EDP algorithm [4] to solve the problem. Our ap- proach is able to discover association rules that have crisp values, intervals, and fuzzy terms in both the antecedent and the consequent, thus, is more general than previous ap- proaches. To the best of our knowledge, this problem has not been studied elsewhere.

The remainder of this paper is organized as the follow- ing. In Section 2, we present some background on how fuzzy terms are interpreted. In Section 3, we define the problem of mining fuzzy quantitative association rules. In Section 4, we present an algorithm for solving the problem.

Section 5 concludes the paper.

2. Interpretation of Fuzzy Terms  A fuzzy data has an uncertain or imprecise value. We as- sociate each fuzzy data v with a fuzzy term and a member- ship function (of a fuzzy set [7]). A fuzzy term is a linguistic term, such as, ?young? and ?high income?. The member- ship function, denoted by ?v , maps each crisp value x in the universe of v to a membership degree ?v(x) in [0; 1] to indicate the possibility of v = x.

A membership function can be defined in a number of ways. Over a numerical universe, a membership functions is typically convex (with a convex curve) and normal (at least one member has degree 1). As in [9, 8] we con-    0 20 30 40 50 60 70 100  A  F1 F3 F4F2    5 15 25 30 40 45 55  B  G1 G2 G3  Figure 1. Fuzzy Terms  sider membership functions of a trapezoidal shape, and de- note them by MF (a; b; c; d), where the parameters mark the endpoints of the shape. For example, the membership function defining fuzzy term F2 in Figure 1 is denoted by MF (20; 30; 40; 50). If a value v has a membership function defined by MF (a; b; c; d), the interval [a; d] is called the supporting interval of v. As special cases, MF (l; l; u; u) defines an interval [l; u], MF (v; v; v; v) defines a crisp value v, and MF (a; b; b; d) is a triangular function.

Over a categorical universe, membership function is de- fined by ?v = x1=m1 + x2=m2 + ? ? ? + xk=mk, where xi is a value in the universe and mi is the membership degree of xi. The membership function of a single crisp value v is ?v = v=1.

3. Problem Statement  LetA = fA1; A2; : : : ; Amg be a set of attributes, U(Ai) be the universe of Ai, that is, the set of crisp values in Ai, FT (Ai) be a set of fuzzy terms (pre?)defined over U(Ai), In(Ai) = f[a; b] j a; b 2 U(Ai); a < bg be the set of all intervals over U(Ai) (In(Ai) = ; if Ai is categorical), Dom(Ai) = U(Ai)[ In(Ai)[ FT (Ai) be the domain of Ai, and I = f< a; v >j a 2 A; v 2 Dom(a)g. We refer < a; v >2 I as an item. An item is fuzzy if v is a fuzzy term. Thus, an item may represent a crisp value, an interval (if the attribute is numerical), or a fuzzy term.

For each X ? I, the set of attributes in X is denoted by attr(X) = faj < a; v >2 Xg.

A data record is a set of attribute?value pairs, where all attributes are distinct and all values are crisp. A data record r supports an item < a; v >2 I with a degree d, if there is an item < a; v0 >2 r, such that, d = ?v(v0). A data record supports an itemset X ? I with a degree d if it supports every item in X with degree d or higher, and at least one of them with degree d. Notice that, the degree with which a data record supports an itemset is in the range of [0; 1].

If the database contains N records, and the total degree of support to an itemset is M , M=N gives the support of the itemset.

A fuzzy quantitative association rule is am implication Y ! X , whereX ? I, Y ? I, and attr(X)\ attr(Y ) = ;. The support of the association rule is the support of X[ Y . The confidence is the ratio of the support of X[ Y and the support of Y .

Given a set of data records with a set of attributes, and a set of fuzzy terms defined for the attributes, the problem is to find all fuzzy quantitative association rules that satisfy user?specified minimum support and confidence.

Example 3.1 With fuzzy terms defined on attributes A and B in Figure 1, data records in Figure 2, a minimum support 20% and a minimum confidence 70%, Figure 2 shows some of the intervals, frequent itemsets, and fuzzy quantitative association rules that may be discovered. 2  4. The Algorithm  We use an EDPFT (equal?depth partition with fuzzy terms) algorithm to discover fuzzy quantitative association rules. The algorithm consists of the following steps.

1. Use equal?depth partition to determine intervals for numerical attributes.

2. Map crisp values and fuzzy terms of each categorical attribute into consecutive integers.

3. Use an extended Apriori Algorithm to discover fre- quent itemsets.

4. Generate all association rules from the frequent item- sets, and keep only those satisfying the minimum con- fidence.

5. Remove association rules that are less interesting.

Except for Steps 1 and 4, this algorithm extends the EDP al- gorithm to account for the inclusion of fuzzy terms in items.

The extensions are discussed in following subsections.

4.1. Candidate Itemset Generation  We extend the Apriori algorithm, by incorporating an or- der of intervals, for the join operation in candidate genera- tion.

Items in an itemset are ordered first by the lexicograph- ical order of their attributes. For items that have an iden- tical numerical attribute, we associate them with the sup- porting intervals (see Section 2) of their values, and order them based on these intervals. We adopt the partial order of intervals in [8]. Basically, the order of two intervals is determined by first comparing their left ends, and then, if necessary, their right ends. For items that have identical categorical attribute, the order is given by the integers that    Data Records Rid A B C  101 18 20 4 102 27 37 2 103 32 43 2 104 32 46 2 105 38 43 2 106 38 46 2 107 45 6 1 108 45 25 3 109 55 28 3 110 65 28 3  Base Intervals A B  [0; 4] [0; 2] [5; 9] [3; 5]  [10; 14] [6; 8] [15; 19] [9; 11] ? ? ? ? ? ?  [95; 100] [57; 60]  Frequent Item Support  < A; [0; 29] > 0.2 < A; [30; 34] > 0.2 < A; [35; 39] > 0.2 < A; [45; 49] > 0.2 < A;F2 > 0.57  ? ? ? ? ? ? < B; [0; 20] > 0.2 < B; [9; 26] > 0.2 < B; [27; 29] > 0.2 < B; [42; 44] > 0.2 < B;G2 > 0.38  ? ? ? ? ? ?  Fuzzy Quantitative Association Rules support confidence  f< A;F2 >;< C; 2 >g ! < B;G3 > 45% 95.7% f< A;F3 >;< C; 3 >g ! < B;G2 > 20% 100%  f< A;F3 >;< C; 3 >g ! < B; [27; 29] > 20% 75% f< A; [55; 100] >;< C; 3 >g ! < B; [27; 29] > 20% 100%  ? ? ?  Figure 2. Example  crisp values and fuzzy terms of the attribute are mapped to (fuzzy terms are mapped to large integers).

With such an ordering, the (k)?itemsets can be obtained from the frequent (k ? 1)?itemsets with a join process sim- ilar to that of Apriori.

Example 4.1 If f< A; [0; 29] >;< B;G1 >g and f< A; [0; 29] >;< B;G2 >g are both in the frequent (2)? itemsets, the join will create a (3)?itemset f< A; [0; 29] > ;< B;G1 >;< B;G2 >g, because the supporting interval of < B;G1 > is [0; 25] and that of < B;G2 > is [15; 40].

Thus< B;G1 > will precede< B;G2 >. Base on the join condition, this (3)?itemset will be generated only once. 2  4.2. Counting Support  The degree with which a data record t supports an itemset X is calculated as follows. For each attribute A 2 attr(X), let < A; v >2 t and < A; u >2 X .

The degree with which t supports < A; u > is given by dsA(t;X) = ?u(v), that is, the possibility for v to be the value represented by u. Since crisp values, intervals, and fuzzy terms are all interpreted by membership functions, the degree of support can be calculated in the same way for all items. The degree with which t supports X is given by minA2attr(X)(dsA(t;X)), which is consistent with the semantics of fuzzy logic AND. It is obvious that the support counted in the Apriori is a special case.

Example 4.2 In Example 3.1, data record f< A; 32 > ;< B; 46 >;< C; 2 >g supports itemset f< A;F2 >;< B;G3 >;< C; 2 >g with degree min(1; 0:9; 1) = 0:9. 2  When counting supports, we read each data record, find each candidate itemset that is supported by the data record with a non?zero degree, and increment the counter of that itemset by the degree of support.

To find all candidate itemsets (partially) supported by a data record, We extend the ?super?candidate? technique of the EDP algorithm to account for items that have an identical attribute and overlapping intervals. Basically, can- didate itemsets are partitioned into groups, called ?super? candidate?, so that, itemsets of the same ?super?candidate? have an identical set of items with categorical attributes, and an identical number of items with each distinct numerical attribute. The items with categorical attributes are referred to as the categorical items of the ?super?candidate?.

To find a ?super?candidate? supported by a data record, we use a hash?tree to store the categorical items of ?super? candidates?. The leave nodes of the hash?tree contain cat- egorical items of ?super?candidates? and pointers to multi? dimensional data structures containing the remaining items of the itemsets in ?super?candidates?. Assume that each itemset of a ?super?candidate? has n numerical items. Each of these numerical items corresponds to an interval (defined by the membership function of its attribute value) on a di- mension in an n?dimensional space. Thus, each itemset in the ?super?candidate? represents an n?dimensional rect-    angle. We can map a data record into a point in this n? dimensional space, thus reduce the problem of finding all itemsets supported by the data record to that of finding all rectangles that contain the point. We store numerical items of itemsets of a ?super?candidate? in a multi?dimensional data structure, such as a R??tree or an n?dimensional array.

It is possible for a data record to support itemsets in mul- tiple ?super?candidates?. We use a linked list structure to determine which ?super?candidate? needs to be searched.

The detail is omitted due to the space limit.

Once a ?super?candidate? is found, we use the multi? dimensional data structure of the ?super?candidate? to search for itemsets. To do so, we map the remaining items of the data record into a point in the multi?dimensional space of the ?super?candidate?. Let the ?super?candidate? have n numerical items. If each of the n items has a distinct attribute, the mapping is straightforward. If, however, some items have an identical attribute, say A, then the item with A in the data record must be duplicated before the mapping is done.

Once an itemset is identified, the counting of support is done as described previously.

4.3. Interestingness Measures  In Steps 3 and 5 of the EDPFT algorithm, we prune (k)? itemsets and association rules using both the R?interesting measure of EDP algorithm and a new measure for certainty.

Among association rules that describe the same associ- ation, we prefer the one that is more precise, accurate, and certain. Since items with numerical attributes are associ- ated with intervals defined by their membership functions, we can talk about the overlap and containment of items in terms of their associated intervals.

Example 4.3 Consider items < A;F2 >, < A;F3 >, < A; [45; 49] >, where F2 and F3 are fuzzy terms shown in Figure 1. The three items are pairwise overlapping. The intersection of < A;F2 > and < A;F3 > is [40; 50]. Item < A; [45; 49] > is contained in < A;F2 >, < A;F3 >, and f< A;F2 >;< A;F3 >g. 2  Definition 4.1 Let X and X? be itemsets. We say that X is more certain than X? if they have the same support, attr(X) = attr(X?), and for every attribute A 2 attr(X), the intersection of items with A in X is contained in the intersection of items with A in X?.

Let Y ! X and Y? ! X? be two fuzzy quantitative association rules. We say that Y ! X is more certain than Y? ! X? if they have the same confidence, and X[ Y is more certain than X?[ Y? . 2  Example 4.4 Consider itemsets f< A;F2 >;< A;F3 >g and f< A; [45; 47] >g, where F2 and F3 are fuzzy terms  shown in Figure 1. If they have the identical support, then f< A; [45; 47] >g is more certain than f< A;F2 >;< A;F3 >g.

Consider following fuzzy quantitative association rules.

f< A;F3 >;< A; [55; 100] >g ! < B; [42; 44] > f< A;F3 >;< A; [55; 100] >g ! < B;G3 >  f< A;F3 >g ! < B; [42; 44] >  If they have the same support and confidence, the first rule is more certain than others. 2  5. Conclusion  In this paper, we defined the problem of mining fuzzy quantitative association rules in relational databases. We present an EDPFT algorithm for solving this problem. Our approach is able to discover association rules that have crisp values, intervals, and fuzzy terms in both the antecedent and the consequent, thus, is more general.

