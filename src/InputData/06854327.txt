ONLINE DICTIONARY LEARNING OVER DISTRIBUTED MODELS

ABSTRACT In this paper, we consider learning dictionary models over a network of agents, where each agent is only in charge of a portion of the dic- tionary elements. This formulation is relevant in big data scenarios where multiple large dictionary models may be spread over different spatial locations and it is not feasible to aggregate all dictionaries in one location due to communication and privacy considerations. We first show that the dual function of the inference problem is an aggre- gation of individual cost functions associated with different agents, which can then be minimized efficiently by means of diffusion strate- gies. The collaborative inference step generates local error measures that are used by the agents to update their dictionaries without the need to share these dictionaries or even the coefficient models for the training data. This is a useful property that leads to an efficient distributed procedure for learning dictionaries over large networks.

Index Terms? Dictionary learning, distributed model, diffu- sion strategies, dual decomposition.

1. INTRODUCTION AND RELATED WORK  Dictionary learning is a useful procedure by which dependencies among input features can be represented in terms of suitable bases. It has found applications in many machine learning and inference tasks including image denoising [1,2], dimensionality-reduction [3,4], bi- clustering [5], feature-extraction and classification [6], and novel document detection [7]. Dictionary learning usually alternates be- tween two steps: (i) an inference (sparse coding) step and (ii) a dictionary update step. The first step finds a sparse representation for the input data using the existing dictionary by solving an ?1- regularized regression problem, and the second step usually employs gradient descent to update the dictionary entries.

With the increasing complexity of various learning tasks, it is natural that the size of the learning dictionaries is becoming increas- ingly demanding in terms of memory and computing requirements.

It is therefore important to study scenarios where the dictionary need not be available in a single location but is instead spread out over multiple locations. This is particularly true in big data scenarios where multiple large dictionary models may be already available at separate locations and it is not feasible to aggregate all dictionaries in one location due to communication and privacy considerations.

This observation motivates us to examine how to learn a dictionary model that is stored over a network of agents, where each agent is in charge of only a portion of the dictionary elements. Compared with other works, the problem we solve in this article is how to learn a distributed dictionary model, which is, for example, different from the useful work in [8] where it is assumed instead that each agent maintains the entire dictionary model.

This work was supported in part by NSF grant CCF-1011918. Emails: {cjs09, ztowfic, sayed}@ucla.edu  In this paper, we will first formulate a modified version of the sparse coding problem, where we add an additional ?2 regulariza- tion term besides the ?1 term (also known as elastic net regulariza- tion [3]). This modified problem is not in a form that is directly amenable to a distributed implementation. However, we will show that the modified problem has a dual function that can be solved in a distributed manner using diffusion strategies [9?13]. Useful consen- sus strategies [14, 15] can also be used. However, since it has been noted that diffusion strategies have enhanced stability and learning abilities over consensus strategies [16], we continue our presentation by focusing on diffusion strategies.

The inference algorithm that we develop is fully distributed in the sense that each agent only needs to apply a local gradient descent step followed by an information exchange step of the dual variable within its neighborhood. We will show that this dual variable has a useful interpretation, namely, it corresponds to the representation error for the input data sample relative to all dictionary elements.

Therefore, the agents do not need to share their (private) dictionary elements but only this representation error, which is computed in a distributed manner through local interactions. We test our algorithm on a typical image denoising task. The dictionary is learned from a collection of patches arising from natural scenes and the learned dic- tionary is used to reconstruct a noisy image not included in the train- ing set. The denoised image?s peak-signal-to-noise-ratio (PSNR) is found to rival that of a centralized dictionary learning algorithm [2].

In other words, our results show that the distributed solution does not limit performance. On the contrary, it can perform as well as a fully centralized solution. This observation has useful ramifications for dealing with large dictionaries and large data sets.

2. PROBLEM FORMULATION  We seek to solve the following global dictionary learning problem over a network of N agents connected by a topology:  min W  E  [  ?xt ?Wyot ?22 + ??yot ?1 +  ?  ?yot ?22  ] (1)  s.t. ?wk?22 ? 1, k = 1, . . . , N (2)  where Ex denotes the expectation operator, xt is the M ? 1 input data vector at time t (we use boldface letters to represent random quantities), W is an M ? N dictionary matrix, wk is the k-th col- umn of W (also known as the k-th dictionary element, or atom), ? and ? are positive regularization factors for the ?1 and ?2 terms, respectively, and yot is the solution to the following sparse coding problem for each input data sample xt at time t (the regular font xt      denotes a realization for xt):  yot = argmin y  [  ?xt ?Wy?22 + ??y?1 +  ?  ?y?22  ] ? ?? ?  ?Q(W,y;xt)  (3)  Note that dictionary learning consists of two steps: the sparse coding step (inference) for the realization xt at each time t in (3), and the dictionary update step (learning) in (1)?(2). Let yk denote the k-th entry of the N ? 1 vector y. Then, the objective function of the inference step (3) can be written as  Q(W, y;xt) ?   ????xt? N? k=1  wkyk  ????2  +  N? k=1  ( ? ? |yk|+  ?  ?y2k  ) (4)  The dictionary elements {wk} are linearly combined to represent each input data sample, and the first term in the cost function (4) re- quires the representation error to be small. In this paper, we focus on using quadratic costs to measure the representation error. In [17], we generalize the results to any differentiable strictly convex costs. The second and third terms in (4), which correspond to the ?1 and ?2 reg- ularizations in (3), are meant to ensure that the resulting combination coefficients {yk} are sparse and small. The ?2 term makes the reg- ularization strongly convex, which will allow us to develop a fully decentralized strategy that enables the dictionary elements {wk} and the corresponding coefficients {yk} to be stored and learned in a distributed manner over the network. That is, each agent k will in- fer its own yk and update its own dictionary element, wk, by rely- ing solely on limited interactions with its neighboring agents. Fur- thermore, as explained in [17], such strongly convex regularization terms help transform the non-differentiable primal cost (4) into a better-conditioned smooth optimization problem ? see (16) further ahead. Figure 1 shows the configuration of the knowledge and data distribution over the network. The dictionary elements {wk} can be interpreted as the ?wisdom? that is distributed over the network, and which we wish to combine in a distributed manner to form a greater ?intelligence? for interpreting the data sample xt. By being distributed, we would like the networked agents to find the global solutions to both the inference problem (3) and the learning problem (1)?(2) with interactions that are limited to their neighborhoods.

Note that the problem we are solving in this paper is different from [8] and the traditional distributed learning setting [9, 10, 12, 18,19], where the entire set of model parameters (the dictionary ele- ments {wk} in this case) are maintained at each agent in the network, whereas the data samples are collected and processed over the net- work, i.e., these previous scenarios correspond to data distributed formulations. What we are studying in this paper is to find a dis- tributed solution where each agent is only in charge of a portion of the model (e.g., wk for each agent k). This scenario corresponds to a model distributed formulation. This case is important because each agent may be limited in its memory and computing power and may not be able to store large dictionaries. By having many agents coop- erate with each other, a larger model that is beyond the ability of any single agent can be stored and analyzed in a distributed manner.

3. LEARNING OVER DISTRIBUTED MODELS  3.1. Inference over distributed models  Observe that solving the cost function (4) directly requires knowl- edge of all dictionary elements {wk} and coefficients {yk} from the other agents due to the sum inside the ? ? ?22 that runs from k = 1 up  Fig. 1. Each agent is in charge of one dictionary element, wk, and the corresponding coefficient, yk, and the data sample xt at each time t is available to all agents in the network. The results in this paper are generalized to the case where the data sample xt is only available to a subset of the agents, and where each agent is responsible for a sub- matrix of W consisting of multiple columns and not only a single atom, wk ? see the extended work [17].

to N . Therefore, this formulation is not directly amenable to a dis- tributed solution. However, we can arrive at an efficient distributed strategy by transforming the original optimization problem into a dual problem. To begin with, we first transform the minimization of (4) into the following equivalent constrained optimization problem:  min {yk},z    ??xt ? z??22 + N?  k=1  ( ? ? |yk|+  ?  ? y2k  ) (5)  s.t. z = N?  k=1  wkyk (6)  Note that the above problem is convex over both {yk} and z since the objective is convex and the equality constraint is linear. By strong duality [20, p.514], it follows that the optimal solution to (5)?(6) can be found by solving its corresponding dual problem and then recovering the optimal {yk} and z. To arrive at the dual problem, we introduce the Lagrangian of (5)?(6) for each input realization xt as  L({yk}, z, ?;xt)  =   ??xt ? z??22+ N?  k=1  ( ?|yk|+  ?  ? y2k  ) +?T  ( z?  N? k=1  wkyk )  (7)  where {yk} and z are the primal variables and ? is the Lagrange mul- tiplier (also known as the dual variable). The dual function g(?;xt) is defined as the minimization of L({yk}, z, ?;xt) over the primal variables {yk} and z for each given ?:  g(?;xt) ? min{yk},z L({yk}, z, ?;xt) (8)  Given that strong duality holds, it is known that the optimal solution of (5)?(6) can be found by solving the following dual problem:  ?ot = argmax ?  g(?;xt) (9)  and then recovering the optimal primal variables yok,t and z o t via  ({yok,t}, zot ) = argmin {yk},z  L({yk}, z, ?ot ;xt) (10)     Notice from (7) that the minimization in (10) over the variables {yk} and z for a given ? is decoupled, and the minimization over each yk is also decoupled for different k. Therefore, the minimization over the primal variables can be done independently. Computing the derivative of L({yk}, z, ?;xt) with respect to z and setting it to zero, we obtain, for each given ?, the optimal solution of z satisfies  ?(xt ? z) + ? = 0 ? z = xt ? ? (11)  Furthermore, since L({yk}, z, ?;xt) is not differentiable in yk, the condition for minimizing L({yk}, z, ?;xt) with respect to yk is given by [21, p.133]:  0 ? ?ykL({yk}, z, ?;xt) = ? ? yk + ? ? ?yk |yk| ? ?Twk (12)  where ?yk denotes the sub-differential (the set of all subgradients) with respect to yk, and the sub-differential for |yk| is  ?k|yk| = { sign(yk), yk ?= 0 [?1, 1], yk = 0  (13)  Applying an argument similar to the one used in [22] to Eq. (12), we can express the optimal yk as  yk = T ? ?  ( ?Twk ?  ) (14)  where T?(?) denotes the following soft-thresholding scalar-valued operator of x ? R:  T?(x) ? (|x| ? ?)+sgn(x) (15)  where (x)+ = max{0, x}. Observe that the solutions obtained in (11) and (14) are optimal for a given ?. Only when we have the opti- mal ?ot to the dual problem (9), the corresponding z and yk acquired from (11) and (14) become the optimal solution to the original prob- lem (5)?(6); the notation zot and yok,t will be used to represent the z and yk solutions corresponding to ?ot . Substituting (11) and (14) into (7), we obtain the dual function as  g(?;xt) = ?1 ???2 + ?Txt ?  N? k=1  S ? ?  ( ?Twk ?  )  = ? N?  k=1  {  2N ???2 ? 1  N ?Txt + S ?  ?  ( ?Twk ?  )} ? ?? ?  ?Jk(?; xt)  (16)  where we introduced the following scalar-valued function of x ? R, which is a differentiable convex function:  S ? ? (x) ? ? ?  ? T 2?  ? (x)? ? ?  ???T ? ? (x)  ???+ ? ? x ? T ? ? (x) (17)  The functions T?(x) and S?(x) are illustrated in Fig. 2. Therefore, the maximization of the dual problem (9) is equivalent to the follow- ing minimization problem  min ?  N? k=1  Jk(?;xt) (18)  Note that the new equivalent form (18) is an aggregation of individ- ual costs associated with different agents; each agent k is associated with cost Jk(?;xt), which only requires knowledge of wk and xt.

?? 0 ?   x  A m pl itu de      T?(x) S?(x)  Fig. 2. Illustration of the functions T?(x) and S?(x).

Therefore, we can now directly apply the diffusion strategies devel- oped in [11, 12] to solve the above problem in a fully distributed manner over the network:  ?k,i = ?k,i?1 ? ?? ? ??Jk(?k,i?1;xt) (19) ?k,i =  ? ??Nk  a?k ? ??,i (20)  where ?k,i denotes the estimate of the optimal ?ot at each agent k at iteration i (we will use i to denote the i-th iteration of the inference, and use t to denote the t-th data sample), ?k,i is an intermediate variable, ?? is the step-size parameter chosen to be a small positive number, and a?k is the combination coefficient that agent k assigns to the information shared from agent ? and it satisfies?  ??Nk a?k = 1, a?k > 0 if ? ? Nk, a?k = 0 if ? /? Nk (21)  Let A denote the matrix that collects a?k as its (?, k)-th entry. Then, it is shown in [11, 12] that as long as the matrix A is primitive, doubly-stochastic and the step-size is sufficiently small, then the al- gorithm (19)?(20) converges to the optimal solution of (18) with a small bias on the order of O(?2?) in squared Euclidean norm. Fi- nally, after ?ot is estimated at each agent k, the optimal z and yk can be recovered from ? by substituting ?ot into (11) and (14), respec- tively:  zot = xt ? ?ot (22)  yok,t = T ? ?  ( wTk ?  o t  ?  ) (23)  Note that (23) only requires local knowledge of wk. An important remark we have is a physical interpretation for the optimal dual vari- able ?ot . Since zot and yok,t are the optimal solutions to problem (5)? (6), then zot and yok,t also need to satisfy constraint (6) so that  zot =  N? k=1  wky o k,t (24)  Expressions (22) and (24) imply that  ?ot = xt ? N?  k=1  wky o k,t (25)  In other words, ?ot admits the interpretation of corresponding to the optimal prediction error of the input data sample xt using all the dictionary {wk}. In this way, the diffusion algorithm (19)?(20) is able to estimate the prediction error in a distributed manner for all agents.

3.2. Distributed dictionary updates  We now derive the strategy that updates the local dictionary element wk at each agent k. Specifically, we need to solve the constrained stochastic optimization problem (1)?(2), which can be rewritten as  min W  EQ(W,yot ;xt) (26)  s.t. ?wk?2 ? 1, k = 1, . . . , N (27)  where yot ? col{yo1,t, . . . ,yoN,t} and Q(W,yot ;xt) is defined in (4). Our strategy is to apply stochastic gradient descent to the cost function (26) with respect to each wk followed by a projection onto the constraint set {wk : ?wk? ? 1}. The stochastic gradient of the cost function (26) with respect to wk is the gradient of Q(W,yot ;xt) with respect to wk. Therefore, the algorithm can be described as  wk,t = ?B ( wk,t?1 ? ?w ? ?wkQ(W, yot ;xt)  ) (28)  where ?B(x) is the projection operator onto {wk : ?wk? ? 1}.

From (4), the stochastic gradient can be computed as  ?wkQ(W, yot ;xt) = ? ( xt ?  N? k=1  wky o k,t  ) yok,t (29)  On the face of it, expression (29) requires global knowledge of all dictionary elements {wk} across the network, which would prevent the distributed implementation. However, recalling (25), the expres- sion inside the parenthesis on the right-hand side of (29) is nothing but ?ot , which is estimated locally by each agent by means of the distributed inference algorithm (19)?(20). Therefore, the dictionary learning update (28) can be expressed as  wk,t = ?B ( wk,t?1 + ?w ? ?ot yok,t  ) (30)  where each agent k replaces the above ?ot by the estimate ?k,i af- ter a sufficient number of inference iterations (large enough i). The rightmost update term in (30) for dictionary element k is effectively the correlation between the global prediction error, ?ot , and the coef- ficient yok,t (the activation).

4. EXPERIMENT  We consider learning a 100 ? 196 dictionary W over a network of N = 196 agents. The network is generated according to a random graph, where the probability that any agent is connected to another agent is 0.2. The network connectivity is checked by inspecting the algebraic connectivity of the graph Laplacian matrix, and we will repeat this random graph generation until we find a connected topol- ogy. Each agent in the network is in charge of one dictionary ele- ment. We extract a total of 1 million 10 ? 10 patches from images 101-200 of the the non-calibrated natural image dataset [23]. Each image is originally 1536?1024 pixels in size, but the border two pix- els were discarded around each image and the top-left 1019? 1019 pixels were then used for patch extraction. With each data sample being a 10 ? 10 patch from a certain image, the dimension of the input data sample is M = 100 (vertically stacked columns). In each experiment, we randomly initialize each entry of the dictionary ma- trix W with a zero mean unit variance Gaussian random variable.

The columns are then scaled to guarantee that the sub-unit-norm constraint (2) is satisfied. Furthermore, in the combination step (20) of the distributed inference, we use the Metropolis rule [9, 24, 25],  Fig. 3. Application of dictionary learning to image denoising. (a) Original image; (b) denoised image by using the centralized method from [2]; (c) dictionary obtained by the centralized method from [2]; (d) image corrupted by additive white Gaussian noise; (e) denoised image by our proposed distributed method at agent 1; (f) dictionary obtained by our proposed distributed method.

which is known to be doubly-stochastic. The patch extraction, pre- processing, and image reconstruction code utilized (excluding dic- tionary learning and patch inference steps) is borrowed from [26].

For the dictionary learning, we utilize ? = 45, ? = 0.1, and ?? = 0.7. Computer code from the SPAMS toolbox was used to compare the algorithm from [2] using its default parameters except where otherwise stated. A step-size of ?w = 5 ? 10?5 was uti- lized for adapting the dictionary atoms. The number of iterations for the diffusion algorithm to optimize (3) was chosen to be 300 it- erations. The data were presented in minibatches [27] of size four samples/minibatch and the dictionary update gradients ?ot yok,t were averaged over the four samples at each step1.

In the far right of Fig. 3, we show the dictionary learned over the 196 agents in the network (bottom) as well as the one learned by us- ing the centralized method in [2] as a benchmark (top). The learned dictionary can be used to denoise an image corrupted by noise as shown in the left four images of Fig. 3. Observe that since the dic- tionaries were trained on patches arising from natural scenes, these dictionaries are capable of denoising other natural scenes since they are expected to share the same statistics. In denoising Fig. 3, the step-size for our algorithm?s inference was increased to be ?? = 1 to increase the quality of the inference result (?o). The number of iterations of the inference step increased to 500 iterations to ensure convergence and ? = 45 and ? = 0.1 remained constant for all algo- rithms. The corrupted image?s PSNR2 is 14.056dB, while the PSNR for the recovered images using the centralized solution of [2] and our proposed distributed solution were found to be 21.771dB and 21.976dB (at agent 1), respectively. Furthermore, the average de- noising PSNR performance across the distributed network was found to be 21.979dB with a standard deviation of 0.00340dB. We observe that the performance is relatively uniform across the network.

1We perform the inference for four samples (x1, . . . , x4) at a time to obtain {?ok,1, . . . , ?ok,4} (all using the same dictionary W ). Then, we update W by averaging the gradient listed in (30) for those four samples.

2PSNR is the peak-signal-to-noise ratio defined as PSNR ? 10 log10(I  max/MSE), where Imax is the maximum pixel intensity in the  image and MSE is the mean-square-error over all image pixels.

5. REFERENCES  [1] M. Elad and M. Aharon, ?Image denoising via sparse and redundant representations over learned dictionaries,? IEEE Trans. Image Process., vol. 15, no. 12, pp. 3736?3745, Dec.

2006.

[2] J. Mairal, F. Bach, J. Ponce, and G. Sapiro, ?Online learning for matrix factorization and sparse coding,? The Journal of Machine Learning Research, vol. 11, pp. 19?60, Mar. 2010.

[3] H. Zou, T. Hastie, and R. Tibshirani, ?Sparse principal com- ponent analysis,? Journal of Computational and Graphical Statistics, vol. 15, no. 2, pp. 265?286, Jan. 2006.

[4] H. Shen and J. Z. Huang, ?Sparse principal component analysis via regularized low rank matrix approximation,? Journal of Multivariate Analysis, vol. 99, no. 6, pp. 1015?1034, Jul. 2008.

[5] M. Lee, H. Shen, J. Z. Huang, and J. S. Marron, ?Biclustering via sparse singular value decomposition,? Biometrics, vol. 66, no. 4, pp. 1087?1095, Dec. 2010.

[6] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman, ?Supervised dictionary learning,? in Proc. NIPS, Lake Tahoe, Nevada, Dec. 2008, pp. 1033?1040.

[7] S. P. Kasiviswanathan, H. Wangy, A. Banerjeey, and P. Melville, ?Online ?1-dictionary learning with application to novel document detection,? in Proc. NIPS, Lake Tahoe, Nevada, Dec. 2012, pp. 2267?2275.

[8] P. Chainais and C. Richard, ?Learning a common dictionary over a sensor network.,? in Proc. IEEE CAMSAP, St Martin, French West Indies, Dec. 2013.

[9] F. S. Cattivelli and A. H. Sayed, ?Diffusion LMS strategies for distributed estimation,? IEEE Trans. Signal Process., vol. 58, no. 3, pp. 1035?1048, Mar. 2010.

[10] A. H. Sayed, S.-Y. Tu, J. Chen, X. Zhao, and Z. J. Towfic, ?Dif- fusion strategies for adaptation and learning over networks,? IEEE Signal Process. Mag., vol. 30, no. 3, pp. 155?171, May 2013.

[11] J. Chen and A. H. Sayed, ?On the limiting behavior of dis- tributed optimization strategies,? in Proc. Allerton Conf., Mon- ticello, IL, Oct. 2012, pp. 1535?1542.

[12] J. Chen and A. H. Sayed, ?Distributed Pareto optimization via diffusion adaptation,? IEEE J. Sel. Topics Signal Process., vol.

7, no. 2, pp. 205?220, Apr. 2013.

[13] J. Chen and A. H. Sayed, ?On the learning behavior of adaptive networks ? Part I: Transient analysis,? submitted for publica- tion [also available as arXiv:1312.7581], 2013.

[14] S. Kar, J. M. F. Moura, and K. Ramanan, ?Distributed parame- ter estimation in sensor networks: Nonlinear observation mod- els and imperfect communication,? IEEE Trans. Inf. Theory, vol. 58, no. 6, pp. 3575?3605, Jun. 2012.

[15] S. Lee and A. Nedic, ?Distributed random projection algorithm for convex optimization,? IEEE Journal Sel. Topics Signal Pro- cess., vol. 7, no. 2, pp. 221?229, Apr. 2013.

[16] S.-Y. Tu and A. H. Sayed, ?Diffusion strategies outperform consensus strategies for distributed estimation over adaptive networks,? IEEE Trans. Signal Process., vol. 60, no. 12, pp.

6217?6234, Dec. 2012.

[17] J. Chen, Z. J. Towfic, and A. H. Sayed, ?Dictionary learn- ing over distributed models,? submitted for publication, [also available as arXiv: 1402.1515], Feb. 2014.

[18] S. Chouvardas, K. Slavakis, and S. Theodoridis, ?Adaptive robust distributed learning in diffusion sensor networks,? IEEE Trans. Signal Process., vol. 59, no. 10, pp. 4692?4707, Oct.

2011.

[19] P. Di Lorenzo, S. Barbarossa, and A. H. Sayed, ?Sparse dis- tributed learning based on diffusion adaptation,? IEEE Trans.

Signal Process., vol. 61, no. 6, pp. 1419?1433, Mar. 2013.

[20] D. P. Bertsekas, Nonlinear Programming, Athena Scientific, 2nd edition, 1999.

[21] B. Polyak, Introduction to Optimization, Optimization Soft- ware, NY, 1987.

[22] A. Beck and M. Teboulle, ?A fast iterative shrinkage- thresholding algorithm for linear inverse problems,? SIAM Journal on Imaging Sciences, vol. 2, no. 1, pp. 183?202, 2009.

[23] J. H. van Hateren and A. van der Schaaf, ?Independent com- ponent filters of natural images compared with simple cells in primary visual cortex,? Proc. Biological Sciences, vol. 265, no.

1394, pp. 359?366, Mar. 1998.

[24] A. H. Sayed, ?Diffusion adaptation over networks,? in Aca- demic Press Library in Signal Processing, vol. 3, R. Chellapa and S. Theodoridis, editors, pp. 323?454, Elsevier, 2014 [also available online as arXiv:1205.4220v2, May 2012].

[25] X. Zhao and A. H. Sayed, ?Performance limits for distributed estimation over LMS adaptive networks,? IEEE Trans. Signal Process., vol. 60, no. 10, pp. 5107?5124, Oct. 2012.

[26] G. Peyre?, ?The numerical tours of signal processing - advanced computational signal and image processing,? IEEE Comput- ing in Science and Engineering, vol. 13, no. 4, pp. 94?97, Jul.

2011.

[27] O. Dekel, R. Gilad-Bachrach, O. Shamir, and L. Xiao, ?Op- timal distributed online prediction using mini-batches,? The Journal of Machine Learning Research, vol. 13, pp. 165?202, Jan. 2012.

