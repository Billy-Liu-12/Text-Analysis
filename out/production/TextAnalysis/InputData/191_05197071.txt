Mining Short Association Rules from Large Database

Abstract?Discovering association rules from existing large databases is an important technique. In this paper, we propose an effective algorithm for mining short association rules on large database. It is experimentally demonstrated presented algorithm has an advantage over existing algorithm for mining association rule, it has better performance and flexibility. By verifying the real transaction data from a supermarket, the short for mining association rules is effective too.

Keywords-data mining;association rule;frequent pattern

I. INTRODUCTION Mining association rules is one of the important issues of  data mining. There have been many algorithms developed for fast mining of frequent patterns, such as Apriori[1] and its enhanced algorithm[2], as well as FP-Growth[3,5] and CT- ITL[4] etc algorithm. The main trouble of the Apriori is that when there exist a large number of frequent patterns and/or long patterns, candidate generation and test methods may still suffer from generating huge numbers of candidates and taking many scans of large databases for frequency checking in this category algorithm. FP-growth is a pattern- growth method using the Apriori property. It avoids candidate generation by compressing the transaction database into an FP-tree and pursuing partition-based mining recursively. However, if the database is huge and sparse, the FP-tree will be large and the space requirement for recursion is a challenge. None is superior in all the cases.

Second, real databases contain all the cases. Real data sets can be sparse and/or dense in different applications. So it is necessary that designs the algorithm for mining some characteristic data sources.



II.    PRELIMINARIES  A. Definition In this section, Hyper-Structure is constructed. We first  define the problem of 1-frequent itemset projected database.

Definition 1 The transaction TDB is a set of transaction  nT )1( Nn ,itemsets B are a subset of itemsets I, IB ,follow the transaction amount of containing itemsets  B is entitled support in TDB , denoted by )sup(B .given a transaction and the support threshold min_sup, if sup(B) min_sup then itemset B is frequent.

Definition 2 Let },,,{ 21 miiiI  be a set of all item in transaction database 0D that there are N transactions, kX is the transaction itemsets of the k -th transaction, IX k ,i.e., },,,{ 21 nkkkk iiiX ,where  mkknj jj 11,1 . )(nX denotes that the set X contains n items. The number of transactions in 0D containing itemset X is called the support of X ,denoted as )X(sup0 .Given a minimum support threshold s, if s0 )X(sup ,then X is frequent in 0D .Let jpi be a frequent item in 0D , called as 1-frequent item, where mp1 j ,and Let I = },,,{  21 mppp iii be the set of all 1-frequent item,  where mm1 and II .Thus the projection between I and kX is kA , and },,,{ kkkk 21 nqqqi iiiXIA , and then the transaction database that consists of NA,,A,A 21 is called 1-frequent itemset projected database A .

Definition 3 Let X(m) denote itemset X containing n item, follow mX m)( .

B.  Data Structure and Hash function  1. Structure of Hyper-Structure Head Table Based on Multi- Hash Chain  The hyper-structure head table based on multi-hash chain contains two fields: item number field and pointer field. The pointer in pointer field points to a hash chain structure with the same number of items. The hyper- structure head table is created dynamically. The hyper- structure is illustrated in Figure1[6].

2.  Constructing the Hash Function of the Multi-Itemsets  The hash funcation of the item jk  i  (where kj is item number) in 1-frequent itemsets is given below:  h(kj)=kj 1  Let the item number of n-itemsets be X=i1i2?in be B={1,2,?,n}, again let X?=ik1ik2?ikm be one of the subset of  2009 Asia-Pacific Conference on Information Processing  DOI 10.1109/APCIP.2009.98   2009 Asia-Pacific Conference on Information Processing  DOI 10.1109/APCIP.2009.98     item X , the set of item number of X? be B?={k1,k2,?,km}, it is obvious that there are XX and BB' ,then The hash function of  multi-item itemsets of X? is given below:  pkkkkh m  i im mod))((),,,(    Where )( ik  may be select from 12 ik and 12 ik  and  110 ik , P is a prime number.



III. THE ALGORITHM OF CONSTRUCTING HYPER-STRUCTURE The algorithm is consist of two step. First, the hyper-  structure of the projection transaction of frequent 1-itemsets is constructed, and then the projection transaction of frequent 1-itemsets is recursively process to again its subsets and the its count. The algorithm of constructing hyper-structure is given below:  Algorithm 1: the algorithm of constructing the hyper- structure Input: the transaction database D0 Output: Hyper-structure Method: 1. Scanning the transaction database D0 a time to obtain the frequent 1-itemsets and the support of every 1-frequent item, and constructing the 1-item hash chain.

2. N=0.

3.while the scanning for transaction database is unfinished  { scanning a record to a itemset },,,{  21 nkkk iiiX .

obtaining the projection transation of frequent 1- itemsets },,,{  21 nqqq iiiXIA .

n2= A if n2>N then N=n2 Trying the hash address of itemset A  according to formula (2) If  A is not null then { if  there is A  the chain table node pointing by the pointer point.

{ Count1n2= Count1 n2+1.} else {constructing a new chain table node and saving  A to corresponding n2-hash chain by way of X(n2) and saving n2 to memory .

Count1n2=1.}}  } 4 For (i=N;i<=3;i--)  { for all  the itemsets X(i)  for Count1i>0  {reducing X(i) into 2-itemset to (N-1)-itemset recursively and calculating the ?chain address?of every reduced itemset An ,and then searching An the itemset in n-item hash chain, if there is itemset An, then adding Count1i of itemset Ai to Count2n, otherwise constructing a new node and saving the itemset An and Count2n.} Note: Count1i is original count.



IV. MINING ASSOCIATION RULES Definition 4  an association rule r is denoted by ?X1 X2  with caveat c?, where X1 X  and X2 X, and X1 X2= , c is support and confidence.

Definition 5  Let min_sup be a minimum support threshold, min_conf  be a minimum confidence threshold, if r satisfies both support(X1 X2)  min_sup and confidence(X1 X2), then r is called strong rule. R denotes the set of rule r.

Algorithm of mining association rules is given below: Algorithm 2: mining association rules Input: the transaction database TDB Output: Hyper-structure  For (i=1;i<=N;i++) {  scanning i-item hash chain structure, totalcount=Count1i+Count2i,  If  totalcount min_sup then obtain X(i) and totalcount Form association rules and output it  }

V. PERFORMANCE STUDY  The experiment environment All experiments are performed on a 1.2 MHz  Celeron  notebook PC machine with 256 megabytes main memory and 20G hard disk, running Microsoft Windows 2000. The algorithm is implemented by using Visual C++6.0. While the version of Apriori and FP-growth that we used is available at http://fuzzy.cs.uni-magdeburg.de/~borgelt/. All reports of the runtime of these algorithms include both the time of constructing corresponding structure and mining frequent-itemsets. They also include both CPU time and I/O time. We use two kinds dataset in the experiment, this is, the dataset generated by data generator and a real-life dataset.

The characteristic of the dataset generated by data generator is decided by parameter T, D, P and I. The T, D, P and I stands for average long of transaction, Parameter of transaction, parameter of pattern, and total item respectively(As below). The real-life dataset was from a supermarket in 1990?.

The experiment study of the hyper-structure efficiency  To evaluate the efficiency of the hyper-structure, we have performed some performance experiments. Figure 2   Figure 1 Hyper-structure based on multi-hash chain     shows the experiment result of the relation between compressibility of the hyper-structure and support threshold on dataset T5D100kP1000I1. Figure 3 shows the experiment result of the relation between compressibility of  the hyper-structure and transaction on dataset T5D*00kP1000I1(the ?*? is from 1 to 5).  We can discover the compressibility is high, it is over 90%, and it is increased along with the increase of the support threshold and the number of transaction, so the hyper-structure has goods compressibility on the given dataset.

Experiment of mining frequent pattern on Data Sets Generated by Data Generator  Figure 4 shows the runtime of the three algorithms on data set T5D100kP1000I1. When the support threshold is high, Apriori and FP-growth and MHSC-Mine(here we name our algorithm for mining frequent pattern as MHSC- Mine) have similar performance. When the support threshold becomes low, FP-growth and MHSC-Mine is much faster than Apriori. In all cases, MHSC-Mine is the fastest one.

Figure5 shows the runtime of the three algorithms on data set T5D100kP1000I5. Whether the support threshold is high or low, the MHSC-Mine has more advantage over FP- growth and Apriori.

Figure 6 shows the scalability of the three algorithms on T5D500kP500I1,T5D1000kP500I1,T5D1500kP500I1,T5D2  000kP500I1 and T5D2500kP500I1 respectively. Various support threshold settings are tested, three algorithms have linear scalability and MHSC-Mine is a clear winner.

Experiment of mining frequent pattern on a Practical Data Set  We use a real-life data set ms2.dat in this experiment.

Figure 7 shows the runtime of the three algorithms on this data set. When the support threshold is high, Apriori and FP-growth have similar performance. When the support     Figure 4  Runtime on data set T5D100kP1000I1   Figure 5 Runtime on data set T5D100kP1000I5   Figure 3 the experiment of compressibility under different transaction number   Figure 2 the experiment of compressibility under different support   Figure 6 Scalability with respect to numberof transactions.

threshold becomes low, Apriori is much faster than FP- growth. In all cases, MHSC-Mine is the fastest one.

Experiment of mining association rules This experiment is made on dataset T5D4000kP1000I1  and a practical data set ms2.dat respectively. In Figure 8 and Figure 9, the MHCS-Mine stands for algorithm for mining  frequent pattern and the MHCS-Mine(R) stands for algorithm for mining association rules, the experiment result shows MHCS-Mine(R) is effective, this is, the time spending for forming association rules from the hyper- structure is not excessive.



VI.    CONCLUSION This paper presents the algorithm for mining association  rules, the algorithm adopts a hyper-structure that has high compressibility about short transaction data set. Experiment results show that MHSC-mine is an effective algorithm for mining association in database which transaction is shorter.

It is especially suitable for mining the association rules from databases such as the chain supermarket transaction database.

Acknowledgements This work was supported in part by the Jiangsu Teachers University of Technology Science Foundation.

