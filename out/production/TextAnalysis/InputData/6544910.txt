Pipe Failure Prediction: A Data Mining Method Rui Wang #1, Weishan Dong ?2, Yu Wang ?3, Ke Tang #4, Xin Yao #&5

Abstract?Pipe breaks in urban water distribution network lead to significant economical and social costs, putting the service quality as well as the profit of water utilities at risk. To cope with such a situation, scheduled preventive maintenance is desired, which aims to predict and fix potential break pipes proactively.

Physical models developed for understanding and predicting the failure of pipes are usually expensive, thus can only be used on a limited number of trunk pipes. As an alternative, statistical models that try to predict pipe breaks based on historical data are far less expensive, and therefore have attracted a lot of interests from water utilities recently. In this paper, we report a novel data mining prediction system that has been built for a water utility in a big Chinese city. Various aspects of how to build such a system are described, including problem formulation, data cleaning, model construction, as well as evaluating the importance of attributes according to the requirements of end users in water utilities. Satisfactory results have been achieved by our prediction system. For example, with the system trained on the available dataset at the end of 2010, the water utility would avoid 50% of pipe breaks in 2011 by examining only 6.98% of its pipes in advance. During the construction of the system, we find that the extremely skew distribution of break and non-break pipes, interestingly, is not an obstacle. This lesson could serve as a practical reference for both academical studies on imbalanced learning as well as future explorations on pipe failure prediction problems.



I. INTRODUCTION  Structural deterioration of pipes in urban water distribution network has presented great challenges to water utilities all over the world. When the deterioration of a pipe exceeds its resiliency, the pipe will leak or burst (also called as a break or a failure), leading to both significant economical and social costs. For example, it is estimated that 32 billion cubic meters of treated water is lost through water distribution networks all over the world [1]. The New York City has spent $54.6 million to manage its break pipes from 1997 to 2011 [2]. Some severe accidents caused by pipe breaks even led to deaths and heavy casualties [3], [4]. Misiunas [5] summarized four aspects of direct costs related to pipe breaks, (1) lost water, (2)  interrupted supply, (3) structural damages, and (4) repair costs.

Unfortunately, since there are typically tens of thousands of pipes in a modern city, it is almost impossible to check all pipes in the network routinely in reality, not to mention the high consequential costs of checking a single pipe (e.g., the costs of digging the ground, the traffic jam caused during that time, and the inconvenience to the neighborhood). As a result, most water utilities in practice are reactive to these breaks of pipes [6]. Moreover, the situation becomes worse in recent decades, because (1) pipes installed after World War II are getting old, thus break more frequently [7], and (2) more and more pipes are being added into the network in the process of urbanization [8], resulting more and more breaks. This leads to unaffordable operating costs for water utilities.

To handle this situation, scheduled preventive maintenance is needed [9], which aims to renew or rehabilitate pipes before their failures. However, randomly digging on the street is not cost effective, nor replacing all pipes that have serviced over certain years. In other words, we need to know which pipes are more probable to break before digging them out. In the literature, there are generally two categories of methods for modeling pipes? statuses [10], [11], [6]. The first category consist of physical models which are developed to understand the physical process of pipe deterioration [11]. The second category consists of statistical methods that aim to model the statuses of pipes based on historical data [6].

In the physical models, one or more components of physical processes that may affect the statuses of pipes are considered.

Typical components include: current pipe and environmental conditions, quality of manufacturing and installation, internal and external loads exerted by operational pressure, surrounding soil, and ground traffic, etc. Although knowing the underling physical mechanism of pipe deterioration is helpful and de- sired, it is usually excessively complicated, and it usually requires input data that are only available from expensive equipments and/or with manpower [11]. Hence, these methods     are only affordable for big companies on a limited number of trunk pipes.

Rather than struggling to reveal the underling physical mechanism of pipe deterioration, the statistical methods pre- dict pipe breaks based only on available historical data. The as- sumption is that pipes with similar characteristics and working environment will experience similar deterioration pattern [12].

Because lots of historical data have already been collected routinely in water utilities for decades (e.g., pipe material, length, diameter, and failure events in history), statistical methods based on these data are far less expensive, and easy (if not ready) to apply. Moreover, so long as the historical data is available, the prediction system can also operate on both the trunk pipes and the many distributive pipes without any additional effort. Therefore, statistical prediction models are favorable to many water utilities [6]. In this study, we report a novel statistical prediction system that has been built for a water utility in a big Chinese city.

Kleiner and Rajani [6] presented a comprehensive review of traditional statistical methods used for predicting pipe breaks. They classified those methods into three categories: (1) deterministic models, (2) probabilistic single-variate group- processing models, and (3) probabilistic multi-variate models.

Generally speaking, models of the first two categories firstly partition pipes into homogeneous groups with regard to various factors (e.g., material, diameter), and then apply mathematical formulations on the rest few factors to capture the failure pattern deterministically or probabilistically. Despite of the simplicity, their usefulness is limited by their heavy reliance on how to partition the dataset in advance. On the other hand, probabilistic multi-variate models can handle multiple factors altogether, thus reducing the need of partition. Nevertheless, to deal with multiple factors, probabilistic multi-variate models typically require significant technical expertise and data [6].

One representative and widely used model in this category is the Cox model [13], which is discussed and included in the experiments later (Section IV).

In general, all of the traditional statistical methods reviewed in [6] were designed to predict the failure of pipes. Nev- ertheless, they addressed different problems in specific. The prediction system proposed by Kleiner and Rajani [14] tries to predict the total number of failures in the whole water distribution network. Clark et al. [15] concerned with how many years from the installation of a pipe to the its first break and how many times that pipe will break in total. Shamir and Howard [16] focused on the the number of breaks per unit length per year for pipes. In practice, however, water utilities are more (sometimes only) interested in the necessary and sufficient information to conduct preventive maintenance, such as ?Tell us, with given budget, which specific pipes should be checked with high priorities?? To this end, we propose to formulate the prediction task as a ranking problem [17] directly in this study. That is, we build a system that can rank pipes according to their break risks in the next year. Based on the output of this prediction system, water utilities can then arrange their preventive maintenance plan.

Note that in previous literature on pipe break prediction, the task was usually formulated as a classification problem or a regression problem. We argue in this paper that these two formulations are not appropriate: classification is not sufficient, and regression is not necessary.

Various aspects of how to build such a system are reported, including problem formulation, data cleaning, model construc- tion, as well as evaluating the importance of every attribute according to the requirements of practical users. Satisfactory results are achieved by our prediction system. For example, with the prediction system trained on the available dataset at the end of 2010, the water utility would avoid 50% of pipe breaks in 2011 by examining only 6.98% of its pipes in advance. Since usually only a minority of pipes in the network would break each year, the prediction task can be considered as an imbalanced learning problem [18] naturally. Contrary to this intuition, we find that the extreme skew between the number of break and non-break pipes is, interestingly, not an obstacle. This finding could serve as a practical reference for both academical studies on imbalanced learning and future explorations on pipe break prediction problems.

The rest of the paper is organized as follows. Section II de- scribes the dataset provided by the water utility as well as our problem formulation. Section III gives the detail algorithms and performance metric we adopted in building the prediction system. Experiments are reported in Section IV, and Section V discusses the related work. Conclusions are given in Section VI.



II. PIPE BREAK PREDICTION PROBLEM  In this section, we firstly introduce the raw dataset provided by the water utility. Then the specific problem formulation as well as the data cleaning procedure we conducted are described.

A. Raw Dataset  The raw dataset provided by the water utility consists of records of over 500,000 water pipes, adding up to almost 6,000 kilometers in length. The records were collected during 1931-2011 (80 years in total), and the average age of these pipes is over 10 years. Each pipe is associated with a batch of attributes collected by the water utility in the last decades.

Generally, these attributes can be categorized into three groups.

The first group includes the physical characteristics of the pipe, including its material, diameter, length, number of joint points, and number of cross points. The second group includes the attributes of environmental as well as the operational conditions, such as the working pressure, the average rainfall over the last 30 years at the region of the pipe, the times of digging near the pipe over the last 10 years, the impact from land reclamation, the impact from highway nearby, the type of the soil around the pipe, the type of varnish coat, whether the pipe is deeply buried, and whether the pipe is exposed. The third group of attributes are the work logs related to that pipe, i.e., which department the pipe belongs to, which region the pipe locates at, pipe id, break id, date of installation, date of     abandon, and date of each break in history. Table I lists these raw attributes.

TABLE I RAW ATTRIBUTES PROVIDED BY THE WATER UTILITY  Attrs. Description  System which department the pipe belongs to Region which region the pipe locates at Pid pipe id number Material pipe material Diameter pipe diameter Length pipe length JNum number of joint points CNum number of cross points Pressure working pressure Rain average rainfall over the last 30 years near the pipe NDig times of digging over the last 10 years near the pipe Recl impact from land reclamation Hway impact from highway Soil whether the soil is in industry area Coat varnish coat type Bury whether the pipe is deeply buried Expose whether the pipe is exposed Complete date of pipe installation Abandon date of abandon Break date of each break Bid id of each break  B. Problem Formulation  As mentioned above, we focus on the necessary and suf- ficient information that a water utility needs for preventive maintenance planning. Classification formulation [19] aims to assign a discrete class label for each testing pipe (i.e., whether or not the pipe is predicted as break), but not distinguish pipes that are categorized into the same classes. In consequence, for all these pipes that have been predicted as break, the water utility with limited budget does not have the necessary information to decide which pipes need to be maintained with high priorities. On the other hand, regression formulation [20] aims to estimate the true break risk. But they actually try to solve a problem that is more difficult than what is sufficient for the water utility. Because it is the relative risk that matters for deciding which pipes need to be checked first, not the exact break risk. Therefore, in this study, we propose to formulate the pipe break prediction task as a ranking problem [17], which tries to rank pipes according to their break risks, without estimating the true risks. Fig. 1 illustrates the scopes of these three formulations.

Because the labels of pipes in the dataset are binary values (i.e., 0 for non-break, and 1 for break), the ranking problem in this study is different from a common ranking problem that aims to find a global rank of all instances [17]. It reduces to a particular form of ranking problem called bipartite ranking problem [21]. Generally speaking, the learning target of a bipartite ranking problem is to rank positive instances (i.e., break pipes) above negative instances (i.e., non-break pipes). In other words, given a well-trained bipartite ranker, these instances that are ranked in the front are more likely  Regression  Ranking  Classification  Fig. 1. Scope of each formulation. Ranking is the necessary and sufficient formulation for this study  to be positive (i.e., more likely to be break in our case).

Formally, let us denote a dataset consist of n instances by S = {(xxx1, y1), (xxx2, y2), . . . , (xxxn, yn)}, where xxxi ? Rm is the attribute vector of the i-th instance, and yi ? {0, 1} is its class label. Besides, we further assume that the number of instances in class 0 is N , and the rest P = n?N instances are in class 1. The objective of bipartite ranking is to find a real-value function H , such that?  xxx?class 1 x?x?x??class 0  I(H(xxx) > H(x?x?x?))  P ?N (1)  is maximized, where I(?) is the indicator function  I(expr) =  { 1, if expr is true; 0, if expr is false.

Given a pipe break prediction model that maximizes (1), a water utility with limited budget can focus on the front of the predicted rank-list, without guessing which pipes should be checked first as in classification formulation. Notice that some models designed for classification problems (e.g., Artificial Neural Network [33]) can also output numerical scores for testing instances, but these scores are for a different purpose.

Consider a simple example from [21], f1 and f2 are two  Fig. 2. Rank-list of two models on 8 instances  models that can output scores for instances. The best clas- sification error that each model can obtained is the same (i.e., 8 by moving the threshold over the rank-list). Therefore, they are equally good from the classification perspective. However, according to the objective of bipartite ranking, f1 is better than f2 (i.e., 1216 vs.

16 ). That is, a more useful model would be  selected with the bipartite ranking formulation.

In conventional learning problems, instances appeared in  training and testing are (or assumed to be) independently and identically distributed. However, for our application, most pipes used in training would also be included in testing.

Therefore, if all attributes used to describe a pipe are time- independent (such as the physical characteristics listed above), an instance with the same attribute values can have conflicting labels in training and testing, making a learning algorithm     confused to make predictions. To solve this problem, we need extra time-dependent attributes that can capture the aging process of a pipe as suggested by [22]. Given the dataset in our study, three available time-dependent attributes were extracted: (1) age of the pipe (Age), (2) number of breaks so far (BNum) of that pipe, and (3) number of years since the last break (Last).

In practice, the water utility is supposed to update the prediction system once at the end of the current year (e.g., 2010) based on all the available data, and then uses the system to rank all pipes according to their break risks in the next year (e.g., 2011). Note that in this procedure, the prediction on a pipe in testing is based on its attributes available at the end the current year. Correspondingly, a pipe used in training would consist of its attributes available at the end of the last year (e.g., 2009), plus its status (i.e., break or non-break) in the current year (e.g., 2010). Since the data available at the end of a particular year consist of all pipes that were installed until then, both the training and testing dataset would become larger and larger over years. Fig. 3 illustrates the framework of the prediction system. We can see that the testing set for the last year is exactly the training set for the current year. And this prediction system would not consider new pipes installed in the next year, which is reasonable since one could not predict whether a pipe will break before it is actually installed.

Pipes with attributes in the last year  (e.g., 2009)  Status of pipes in the current year (e.g., 2010)  Prediction system  Pipes with attributes in the current year  (e.g., 2010)  Status of pipes in the next year  (e.g., 2011)  training testing  Learning algorithm  Fig. 3. Framework of the prediction system  C. Data Pre-processing  Given the raw dataset and the specific problem formulation, we then clean and partition the dataset accordingly. Firstly, we removed the attributes with too many missing values and the attributes that are considered to be irrelevant to the prediction task. In particular, System, Region, Pid, Bid are removed as irrelevant attributes, and Pressure, Coat are removed for too many missing values. Note that some attributes with many empty but not missing values are not removed in this step. For example, a majority of pipes do not have break date, which means they have not failed so far. Secondly, all instances with non-empty abandon date and instances with missing values on the rest attributes are removed. At last, we partition the dataset into training and testing set by year for the recent 5 years (i.e., 2006-2011). For each year, the dataset consists of all pipes that are available by the end of that year. Besides, the three time-dependent attributes as well as the statuses of the pipes are extracted and appended to the corresponding training  and testing sets accordingly. The final attributes adopted are listed in Table II. The number of break and non-break pipes in each training and testing set can be found in Table III.

TABLE II ATTRIBUTES ADOPTED IN THE PREDICTION SYSTEM  Attrs. Type  Material categorical Diameter numerical Length numerical JNum numerical CNum numerical Rain numerical NDig numerical Recl ordinal Hway ordinal Soil boolean Bury boolean Expose boolean Age numerical BNum numerical Last numerical  TABLE III NUMBER OF NON-BREAK AND BREAK PIPES IN EACH TRAINING AND  TESTING DATASET  Training Testing  Current year non-break break non-break break  2006 263267 1041 283107 2593 2007 283107 2593 314031 3040 2008 314031 3040 364006 2441 2009 364006 2441 400968 2488 2010 400968 2488 424864 2681

III. DATA MINING METHODS FOR PIPE BREAK PREDICTION  In this section, we firstly describe the algorithm used to solving the bipartite ranking problem, and then introduce the metric for measuring the performance of the prediction system.

At the request of practical users in the water utility, we further estimate the importance of each attribute with respect to pipe breaks. The method for this purpose is also introduced in this section.

A. RankBoost.B  We adopted RankBoost.B [23], a state-of-the-art algorithm for the bipartite ranking problem in our prediction system.

Like any other boosting-type algorithms, RankBoost.B builds a strong model in an iterative manner. Within each iteration, it finds a weak learner to rank the weighted instances at first, and then updates the weight of each instance according to the performance of the weak learner. Finally, these weak learners are linearly combined to form a strong ranking model.

Algorithm 1 presents the pseudo-code of the RankBoost.B algorithm.

Algorithm 1 RankBoost.B Input: dataset S, number of iterations T Output: a ranker H  Initialize:  v1(xxx) =  { 1/P, if xxx ? class 1; 1/N, if xxx ? class 0.

for t = 1 to T do train weak learner ht using updated weight v(xxx) choose ?t ? R update instance weights:  vt+1(xxx) =  { vt(xxx) exp(??tht(xxx))  Zt , if xxx ? class 1;  vt(xxx) exp(?tht(xxx))  Z ? t  , if xxx ? class 0.

where: Zt =  ? xxx?class 1 vt(x) exp(??tht(xxx))  Z ?  t = ? xxx?class 0 vt(x) exp(?tht(xxx))  end for H(xxx) =  ?T t=1 ?tht(xxx)  In principle, any model that can assign scores to instances in S could be employed as the weak learner. In our system, decision stump [24] is employed for this purpose as in many other boosting algorithms. That is, in each iteration, the weak learner simply marks every instance with 0 and 1. The final score that RankBoost.B assigns to each pipe is the weighted average of these binary values, which turns out to be a real- valued score. Readers interested in the details of training a weak learner as well as setting ? in each iteration please refer to [23]. The superiority of RankBoost.B has also been reported from other real-world applications [25].

B. Measuring Performance  In building the prediction system, we need a numerical indicator to tell whether the system performs well, i.e., a performance metric. A natural metric for bipartite ranking problems is the Area Under the receiver operating character- istic Curve (AUC) [26].

For the n instances in S, suppose the score assigned by H for instance xi is s(xi), then the AUC for this ranker H can be calculated as follows,  AUC =  ? xxx?class 1 x?x?x??class 0  ?(xxx,x?x?x?)  P ?N , (2)  where  ?(xxx,x?x?x?) =  ??? 1, if s(x xx) > s(x?x?x?);  0.5, if s(xxx) = s(x?x?x?); 0, if s(xxx) < s(x?x?x?).

From (2), we can see that the AUC value is actually the probability that a randomly selected class 1 instance will be assigned higher score than a randomly class 0 instance by H .

If all instances in class 1 are ranked higher than instances  from class 0, the AUC would be 1. If the ranker has no discriminative power, leading randomly assigned scores, the AUC would be 0.5. For AUC less than 0.5, one can just reverse the rank-list to get better result.

Comparing (1) with (2), we can see that the only difference between them is how to deal with equal scores for instances from different classes. In principle, one can assume that a refined ranker would assign each instance with different score, then the AUC matric matches the objective of bipartite ranking problem exactly. However, in practice, ties among scores may exist for some rankers. Therefore, as a performance metric, AUC takes this situation into consideration. In Section IV, we will compare RankBoost.B with four other methods in AUC.

C. Evaluating Attributes? Relevance  In addition to predicting which pipes are more probable to break in the next year for preventive maintenance planning, water utility also wants to understand the relevance of each factor with regard to pipe breaks. Such knowledge would help them to avoid potential pipe breaks. At the request of the water utility, we implemented this component in our prediction system.

Unlike the physical models that aim to explain the mecha- nism of pipe break by considering various physical processes, the statistical models evaluate the relevance based only on statistics. In the literature, the topic attribute selection (or feature selection) [27] focuses on measuring the relevance of attributes in prediction problems has been extensively studied.

In this study, we adopt a simple and newly proposed attribute selection method named as Feature Assessment by Sliding Thresholds (FAST) [28]. Briefly speaking, FAST leverages the ability of AUC in measuring the performance of a ranker into measuring the relevance of an attribute. That is, in evaluating the relevance of an attribute, FAST treats the values of that attribute as the scores for instances in S, and then calculates the AUC with these scores and the class labels according to (2). The empirical studies reported in [28] has demonstrated the efficacy and efficiency of FAST.



IV. EXPERIMENTS  To demonstrate the superiority of our prediction system, we compare it to four other methods on the real-world dataset. The results as well as the analysis are presented in this section.

A. Candidate Prediction Methods  Besides RankBoost.B, four other models are chosen as candidate prediction methods. They are Cox?s proportional hazard model, Naive Bayes, Logistic Regression, and Artificial Neural Network. Cox model is a method designed for survival analysis [13], and has been used in the pipe break prediction problem in the literature [29], [30]. Naive Bayes [31] is a simple and widely used classification model which serves as a baseline in our comparison. The Logistic Regression [32] and Artificial Neural Network [33] have also been used on problems relating to the pipe break prediction [20], [34]. Note that the underling formulation for these compared models are     different. While the RankBoost.B tries to solve a bipartite rak- ing problem, the Cox model is designed for survival analysis problems, and the remaining three (i.e., Naive Bayes, Logistic Regression, and Artificial Neural Network) are methods for classification formulation. Therefore, the following results also suggest the relative superiority among different problem formulations for solving our pipe break prediction problem.

1) Cox?s Proportional Hazard Model: Cox model [13] is a classic method in survival analysis. It was firstly proposed to analysis the relationship between survival of patients and various explanatory factors, and has been widely used in engineering to model the aging process of mechanical objects [35]. Formally, Cox model estimates the failure risk of an object based on an equation of the following form  h(t, zzzi) = h0(t)e bbbTzzzi  where h(t, zzzi) is hazard function (i.e., the failure risk of an object zzzi at time t), and h0(t) is an arbitrary baseline hazard function, which is to capture the underling aging process for all objects without considering the specific characteristics of any particular object. The second term ebbb  Tzzzi in the equation differentiates the failure risk of different objects, where zzzi is the attributes vector of that object, and bbb is the vector of parameters that needs to be fitted for the equation. Note that we use zzzi instead of xxxi in the equation as the attribute vector for the i-th instance. This is because the target of Cox model is to find the relationship between failure risk of objects to time-independent attributes. Thus, BNum and Last in xxxi are discarded. Besides, a new attribute ST that measures the number of years form the installation year to its first break year (or current year if no previous break) of a pipe is extracted as the survival time used in Cox model. The implementation of Cox model used in this study is from the survival package in R [36].

2) Naive Bayes: Naive Bayes [31] is a simple and widely used classification model in machine learning. It tries to estimate the posterior probabilities of classes based on the Bayesian theorem with the assumption that all the attributes are independent with each other. That is,  p(ck|xxxi) = p(xi1, . . . , xim|ck)p(ck)  p(xxxi) =  ?m j=1 p(xij |ck)p(ck)  p(xxxi) ,  where p(ck|xxxi) is the posterior probability that xxxi belongs to the k-th class, xij is the value of the xxxi on the j-th attribute, and p(xxxi) is the probability that xxxi appears in the whole sampling space, which is irrelevant for the prediction, thus can be treated as a constant. Although the assumption made by Naive Bayes is rarely hold in real-world applications, its performance is usually good. Therefore, it is adopted in this study to set up a baseline for the classification formulation on the pipe break prediction problem.

3) Logistic Regression: Logistic Regression [32] is a classic regression analysis method for binary classification problem.

It estimates the posterior probability that instance xxxi belongs  to class 1 based on the following equation,  p(class 1|xxxi) = exp(a+ bbbTxxxi)  1 + exp(a+ bbbTxxxi) ,  where a and bbb are the parameters to be fitted in the training process.

4) Artificial Neural Network: Artificial Neural Network (ANN) [33] is a well-acknowledged learning method in var- ious fields. Briefly speaking, a neural network consists of multiple layers of neurons and the weighted links connecting these neurons. The first layer of a neural network takes the raw input from the dataset, transforms and then inputs them into the next layer through weighted links. At last, the outputs of the final layer are taken as the predictions for the raw input instances. In principle, an ANN consisting of multiple layers of neurons has been proved to be able to fit any discriminate function of arbitrary complexity [33].

Therefore, for sophisticated real-world applications, ANN has been extensively used.

The Naive Bayes, Logisitc Regression and Artificial Neural Network are ready-to-use from WEKA [37]. The RankBoost.B algorithm is implemented in Java.

B. Results  We present the experimental results in this section. As mentioned above, we examine the performance of all the candidate methods for the last 5 years, from 2006 to 2010.

Note that the prediction would be on 2007, 2008, . . . , 2011.

Table IV and Table V are the training and testing AUC score of each candidate method for each year. The best performance in each case is highlighted in boldface.

TABLE IV TRAINING AUC OF EACH METHOD  2006 2007 2008 2009 2010  Cox 0.7699 0.7962 0.7654 0.7485 0.7607 NaiveBayes 0.8381 0.8025 0.8174 0.8192 0.8320 Logistic 0.8520 0.8431 0.8416 0.8450 0.8546 ANN 0.7980 0.8211 0.8398 0.8388 0.8282 RankBoost.B 0.88500.88500.8850 0.86950.86950.8695 0.86670.86670.8667 0.86790.86790.8679 0.87700.87700.8770  TABLE V TESTING AUC OF EACH METHOD  2007 2008 2009 2010 2011  Cox 0.7797 0.7929 0.7543 0.7540 0.7659 NaiveBayes 0.7960 0.8172 0.8192 0.8325 0.8236 Logistic 0.8181 0.8414 0.8413 0.8529 0.8460 ANN 0.7579 0.8046 0.8291 0.8460 0.8166 RankBoost.B 0.85400.85400.8540 0.85940.85940.8594 0.86160.86160.8616 0.87070.87070.8707 0.86360.86360.8636  As shown by these two tables, the AUC scores obtained by RankBoost.B are satisfactory (above 0.85 though all 5 years) and consistently higher than that of all other candidate methods throughout training and testing. Among the other four methods, the logistic regression is best, which is consistent with the conclusion made by Yamijala et al. in [20]. Naive     Bayes and Artificial Neural Network are comparable with each other. Cox model is less satisfactory (below 0.8 for all five years), which is outperformed by all other methods. Table VI lists the average ranking of each methods based on its performance on the testing datasets.

TABLE VI AVERAGE RANKINGS OF EACH METHOD  Method Ranking RankBoost.B 1.0  Logistic Regression 2.0 NaiveBayes 3.4  Artifical Neural Network 3.8 Cox 4.8  On the other hand, we can observe from the two tables that the AUC scores sometimes suffer from fluctuation during training and testing. For example, the training AUC of all models but Cox in 2006 is always higher than corresponding testing AUC in 2007 by at least 0.03, and the training AUC in 2009 is always lower than the corresponding testing AUC in 2010. Considering that the datasets we used to train and test are fairly large, and the fluctuation is in both directions, we conjecture that this fluctuation is not caused by the modeling methods, but by the intrinsic uncertainty in the pipe prediction problem that is not captured by our descriptive attributes listed in Table II. For example, factors such as temperature and working pressure are considered to be important by domain experts, but are not collected by the water utility. Therefore, to further improve the performance of our prediction system, relevant attributes need to be collected as many as possible.

In addition to reporting the AUC of our prediction system to the water utility, we also illustrate the prediction results in a more intuitive manner in Fig. 4. Specifically, we plot the number of pipe breaks that would have been prevented versus the number of pipes proactively maintained in each year during 2007 to 2011. Given a fixed point in the x-axis, a curve with larger y-axis value means that the corresponding method is of higher capability in preventing pipe breaks in the next year.

From these figures, we can see that the curves of RankBoost.B are always above that of all the other methods as expected in all the 5 years. This means that a preventive maintenance plan guided by our prediction system will be more likely to prevent more pipe breaks in the next year with limited budget. For example, the water utility would have prevented 50% (i.e., 1340) of its pipe breaks in 2011 if they have proactively maintained 6.98% (i.e., 29852) of all pipes at the end of 2010.

C. Is Imbalance a Problem?

In recent machine learning and data mining studies, the topic named as imbalanced learning [18] has drawn many attentions. It focuses on a widely observed phenomenon that a standard classification model would not perform well when the instances in one class is significantly outnumbered by that in the other class. Typically, when the ratio between two classes exceeds 1:10, the learning task would be considered as an imbalanced learning problem. In this study, the ratio between  break pipes and non-break pipes is over 1:100 (see Table III).

Therefore, it can be taken as an imbalanced learning problem naturally. During building our prediction system, we applied two widely used techniques designed for imbalanced learning problem to our datasets. Interestingly, the results suggest that taking the prediction task as an imbalanced learning problem in our problem does little help.

In imbalanced learning, the most widely acknowledged and adopted technique is sampling, which tries to balance the original class distribution by increasing minority class instances or decreasing majority class instances [18]. In this study, we apply two representative sampling techniques to the datasets, i.e., the random under sampling (RUS) method [38] and the Synthetic Minority Over-sampling Technique (SMOTE) [39]. Generally speaking, RUS randomly deletes some instances from the majority class, while SMOTE works by generating new instances which are linearly combinations of raw minority class instances. Table VII and Table VIII are the training and testing AUC of each method on the new datasets generated by RUS. Table IX and Table X are the results of SMOTE. Note that the Cox model is not included.

This is because the class label is of different meaning in the survival analysis, making sampling techniques not applicable.

TABLE VII TRAINING AUC OF EACH METHOD WITH RUS  2006 2007 2008 2009 2010  NaiveBayes 0.8377 0.8006 0.8185 0.8201 0.8332 Logistic 0.8599 0.8480 0.8501 0.8498 0.8623 ANN 0.8674 0.8617 0.8632 0.8201 0.8649 RankBoost.B 0.88510.88510.8851 0.87010.87010.8701 0.86910.86910.8691 0.86770.86770.8677 0.87770.87770.8777  TABLE VIII TESTING AUC OF EACH METHOD WITH RUS  2007 2008 2009 2010 2011  NaiveBayes 0.7944 0.8162 0.8193 0.8329 0.8246 Logistic 0.8254 0.8480 0.8478 0.8568 0.8524 ANN 0.7925 0.8359 0.8414 0.8504 0.8422 RankBoost.B 0.85430.85430.8543 0.85970.85970.8597 0.86150.86150.8615 0.87030.87030.8703 0.86350.86350.8635  TABLE IX TRAINING AUC OF EACH METHOD WITH SMOTE  2006 2007 2008 2009 2010  NaiveBayes 0.8100 0.8192 0.8187 0.8325 0.8240 Logistic 0.8260 0.8114 0.8227 0.8289 0.8184 ANN 0.8198 0.8257 0.8196 0.8158 0.8385 RankBoost.B 0.87270.87270.8727 0.85620.85620.8562 0.82390.82390.8239 0.86710.86710.8671 0.87380.87380.8738  Comparing these four tables to Table IV and V, we can see that both RUS and SMOTE exert little influence to the performance of every method throughout training and testing.

Considering the extreme imbalanced class distribution in the datasets, this finding is a strong real-world supporting evidence for previous observations made by researchers on synthetic     Fig. 4. Number of pipe breaks that would have been prevented versus number of pipes need to be proactively maintained     TABLE X TESTING AUC OF EACH METHOD WITH SMOTE  2007 2008 2009 2010 2011  NaiveBayes 0.7961 0.8154 0.8173 0.8352 0.8253 Logistic 0.8194 0.8325 0.8366 0.8501 0.8421 ANN 0.7711 0.8060 0.8082 0.8125 0.8210 RankBoost.B 0.85370.85370.8537 0.85420.85420.8542 0.85740.85740.8574 0.86830.86830.8683 0.86200.86200.8620  datasets [40], [41]. That is, imbalance in a dataset does not always lead to performance deterioration, it indeed depends on the specific problem/dataset as well as the learning model you working with. This lesson we learned in this study could serve as a practical reference for future studies on imbalance learning as well as for new explorations on pipe break prediction problems.

D. Importance of Each Attribute  As mentioned above, we also estimate the importance of each attribute listed in Table II using the FAST attribute se- lection method [28]. In particular, we calculate the importance of an attribute based on the training datasets, and then averaged it over 5 years as the attribute?s final importance index. Since categorical values are not comparable to each other, they can not be treated as scores in AUC calculation. Hence, the Mate in Table II is factorized into a batch of binary attributes at first, and then we measure the importance of each binary material sub-attribute. Table XI shows these importance indices.

TABLE XI AVERAGE IMPORTANCE OF EACH ATTRIBUTE OVER 2006-2010  Attrs. Importance index Attrs. Importance index  Age 0.653 Soil 0.499 Leng 0.651 Expo 0.497 Mate-GI 0.632 CNum 0.493 JNum 0.627 Rain 0.475 BNum 0.614 Mate-S 0.471 Mate-GIL 0.585 Mate-PE100 0.469 Hway 0.550 Mate-PE80 0.467 Last 0.519 NDig 0.459 Mate-AC 0.514 Bury 0.441 Mate-UPVC 0.506 Mate-DI 0.354 Mate-CI 0.501 Diam 0.277 Recl 0.499  Note that an index greater than 0.5 means positive corre- lation between the attribute and pipe breaks, an index less than 0.5 means negative correlation, and an index equals with 0.5 means that the attribute is irrelevant to the pipe breaks.

From Table XI we can have several interesting observations.

Firstly, Diam is strongly negative correlated with pipe breaks, meaning pipes with smaller diameter are more likely to break.

The positive correlation between Leng and class label suggests that longer pipes are more likely to break than shorter ones.

Besides, pipes made of ductile iron (Mate-DI) are usually not likely to break, while pipes made of galvanized iron (Mate- GI) fails more frequently. At last, as expected, old pipes and pipes which have broken before are also positive correlated to future breaks. On the other hand, some attributes that were  considered to be important by the water utility are found not that relevant. For example, the importance index of Soil is 0.499, which means the chance of break would not altered much whether or not a pipe is laid in industrial area.



V. RELATED WORK  In addition to the traditional statistical methods that have been reviewed in [6], several recent case studies that adopted data mining methods can be found in the literature.

Artificial Neural Network was used to estimate the exact number of breaks for each pipe in the water distribution networks of Benghazi city [42] and Wattrelos city [34].

Nevertheless, the datasets these two case studies considered are relatively small, i.e., 419 pipes for [42] and 4,862 pipes for [34] (the raw dataset consists of over 500,000 pipes in our study).

Babovic et al. [43] considered a similar problem formulation as we do in this study. They also aimed to find a good ranking of pipes according to their risks of break. They, however, employed Genetic Algorithm (GA) for this purpose. Despite the potential global search ability, GA is rarely used as a learning method directly. Therefore, the unsatisfactory results reported in [43] is not unanticipated. Besides, they also noticed the extreme imbalance in class distribution of break and non- break pipes in the practical problem. Yet, rather than resorting to existing imbalanced learning techniques, they adopted an ad hoc hierarchical learning structure, which firstly distinguished most non-break pipes, and then refined the discrimination on the rest pipes.

Yamijala et al. compared four different kinds of regression models for pipe break prediction in a recent paper [20], includ- ing time linear model, time exponential model, generalized linear model and logistic regression model. They found that logistic regression is the best among these compared models.

This conclusion is consistent with the result reported by Debon et al. [44]. However, the results presented in this study indicate that more satisfactory results can be achieved if we formulate the pipe break prediction task as a bipartite ranking problem and solve it with RankBoost.B algorithm.



VI. CONCLUSION  Pipe breaks in water distribution network due to structural deterioration lead to social and economical costs. However, because of the maintenance costs, most water utilities in prac- tice have no choice but be reactive to these breaks. Physical methods for detecting pipe breaks in advance are usually expensive, thus can only be applied on a small number of trunk pipes in practice. On the other hand, statistical methods that try to predict breaks based on historical data are far less expensive, therefore can be applied to both trunk and distributive pipes.

In this study, we focused on building a statistical prediction system for the water utility in a big Chinese city.

In particular, we proposed to formulate the prediction task as a learning-to-rank problem. That is, ranking pipes according to their break risks in the next year. We adopted RankBoost.B for the ranking purpose, the empirical studies compared to other     four different statistical models as well as the feedback of the water utility confirmed the efficacy of our prediction system.

On the other hand, we also evaluated the importance of each attribute, which helped the water utility to better understand the underling mechanism of pipe deterioration.

In summary, the contributions of the paper are in four folds.

? Rather than considering the pipe break prediction prob-  lem as a regression or standard classification problem, we formulated it as a bipartite ranking problem. This formulation is driven from the practical requirements of the water utility. Moreover, the formulation as well as the methods adopted in this study is not limited to water pipe break prediction problems. They can also be helpful in preventive maintenance on many other industrial assets (e.g., gas, oil pipes).

? We adopted RankBoost.B algorithm to solve the ranking problem. The results obtained by our prediction system are satisfactory. For example, with the prediction system trained on the real dataset at the end of 2010, the water utility would avoid 50% of its pipe breaks in 2011 by examining only 6.98% of its pipes in advance. This is best result among all candidate methods.

? We empirically demonstrated that the imbalanced dis- tribution between break and non-break pipes is not an obstacle in building the prediction system. This finding provides a supporting evidence for previous observations that researchers made on synthetic datasets in imbalanced learning studies [40], [41]. It can also serve as a practical reference for future studies on pipe break prediction problems.

? To the best of our knowledge, the dataset involved in our study is the largest real dataset in the literature on pipe break prediction. This makes the results and conclusions reported in the paper more statistically reliable.

There are two directions that can be explored in the future.

On one hand, some important attributes that are considered to be important by domain experts are not available in this study (e.g., temperature, working pressure). It is probable that these additional attributes can further improve the prediction performance and help the water utilities better understand the deterioration mechanism of pipes. On the other hand, we have not considered the costs of pipe breaks and the costs involved in maintaining pipes. With the help of the prediction system built in this study, we can further combine these information to build a more cost-efficient system for water utilities in this industry.

ACKNOWLEDGEMENTS This work was partially supported by the 2012 IBM PhD  Fellowship Programme, the 973 Program of China (Grant No. 2011CB707006), National Natural Science Foundation of China (Grant No. 60802036, No. 61028009, and No.

61175065), the National Natural Science Foundation of Anhui Province (No. 1108085J16), and the European Union Seventh Framework Programme under grant agreements No. 247619 and No. 270428.

