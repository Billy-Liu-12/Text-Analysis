<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">On Closed  Constrained Frequent Pattern Mining

Abstract Constrained frequent patterns and closed frequent pat- terns are two paradigms aimed at reducing the set of ex- tracted patterns to a smaller, more interesting, subset.

Although a lot of work has been done with both these paradigms, there is still confusion around the mining problem obtained by joining closed and constrained fre- quent patterns in a unique framework. In this paper we shed light on this problem by providing a formal de?ni- tion and a thorough characterization.We also study com- putational issues and show how to combine the most re- cent results in both paradigms, providing a very e?cient algorithm which exploits the two requirements (satisfy- ing constraints and being closed) together at mining time in order to reduce the computation as much as possible.

1. Introduction Frequent itemsets play an essential role in many data mining tasks that try to ?nd interesting patterns from databases, such as association rules, correlations, sequences, episodes, classi?ers, clusters. Although the collection of all frequent itemsets is typically very large, the subset that is really interesting for the user usu- ally contains only a small number of itemsets. There- fore, the paradigm of constraint-based mining was in- troduced. Constraints provide focus on the interesting knowledge, thus reducing the number of patterns ex- tracted to those of potential interest. Additionally, they can be pushed deep inside the mining algorithm in or- der to achieve better performance. For these reasons the problem of how to push di?erent types of con- straints into the frequent itemsets computation has been extensively studied [13, 15, 19].

Extracting too many uninteresting frequent pat- terns, with large requirements both in terms of time and space, is an even harder problem when mining dense datasets containing strongly related transactions.

Such datasets are much harder to mine since only a few itemsets can be pruned by the anti-monotonicity of frequency, and the number of frequent itemsets grows very quickly while the minimum support thresh- old decreases. As a consequence, the mining task be- comes rapidly intractable by traditional mining algo- rithms, which try to extract all the frequent itemsets.

Closed itemsets mining is a solution to this problem.

Closed itemsets are a small subset of frequent item- sets, but they represent exactly the same knowledge in a more succinct way. From the set of closed item- sets it is straightforward to derive both the identities and supports of all frequent itemsets. Mining the closed itemsets is thus semantically equivalent to mining all frequent itemsets, but with the great advantage that closed itemsets are orders of magnitude fewer than fre- quent ones.

How to integrate the two paradigms of constrained frequent itemsets and closed frequent itemsets is clearly an interesting issue.

Following the constraints framework, one could wrongly express the property of being closed as just an- other constraint Cclose. Consider the following induc-    other constraint Cclose. Consider the following induc- tive query: Q : Cfreq(X) ? Cclose(X) ? sum(X.price) ? 22 which requires to mine itemsets which are frequent, are closed and have a sum of prices less than 22. Such a query has ambiguous semantics. In fact there are two possible di?erent interpretations for query Q: ? I1 : mine all frequent closed itemsets which have the additional property of having sum of prices less than 22; ? I2 : mine all frequent itemsets having sum of prices less than 22 and which have the additional prop- erty of being closed (w.r.t. the other two con- straints).

In this paper we shed light on this problem showing that these two possible interpretations produce di?er- ent solution sets: this is due to the fact that being closed is not a property which an itemset satis?es or not for its own characteristics, but it is a property of an itemset in the context of a collection of itemsets.

Then we show that the interpretation I2 is the mean- ingful one and, according to it, we de?ne the closed 0-7695-2142-8/04 $ 20.00 IEEE constrained frequent itemsetmining problem. Finally, we study computational issues and we provide a very ef- ?cient algorithm which exploits the two requirements (satisfying constraints and being closed) at mining time in order to reduce the computation as much as possi- ble.

1.1. Problem Definition and Notation Let I = {x1, ..., xn} be a set of distinct literals, called items, where an item is an object with some attributes (e.g., price, type, etc.). An itemset X is a non-empty subset of I. If |X| = k then X is called a k-itemset. A constraint on itemsets is a function C : 2I ? {true, false}. We say that an itemset I satis- ?es a constraint if and only if C(I) = true. We de?ne the theory of a constraint as the set of itemsets which satisfy the constraint: Th(C) = {X ? 2I | C(X)}.

A transaction database D is a bag of itemsets t ? 2I , called transactions. The support of an itemset X in database D, denoted supD(X), is the cardinality of the set of transactions in D which are superset of X.

Given a user-de?ned minimum support ?, an itemset X is called frequent in D if supD(X) ? ?. This de?nes the minimum frequency constraint: Cfreq[D,?](X) ?

supD(X) ? ?. When the dataset and the minimum support threshold are clear from the context, we ad- dress the frequency constraint simply Cfreq . Thus with this notation, the set of frequent itemsets can be de- noted Th(Cfreq).

Since we are usually interested in mining problems which requires to output the support of each solution itemset, we de?ne a special frequency-theory which is a set of couples itemset-support.

Definition 1 (F -Theory) Given a non-empty con- junction of constraints C and a transaction database D, we de?ne: FThD(C) = {?X, supD(X)? | X ? Th(C)}.

In the following, we de?ne the concepts of closures and  borders of theories, which will be useful to characterize the solutions spaces of our mining problems.

Definition 2 (Closure of a F -Theory) The clo- sure of a F-Theory is a function Cl : FThD ? FThD which restricts the F-Theory to those itemsets which do not have a superset in the F-theory with the same sup- port: Cl(FThD(C)) = {?X, supD(X)? ? FThD(C) | ?Y ? X : ?Y, supD(Y )? ? FThD(C) ? supD(Y ) = supD(X)} Definition 3 (CAM and CM constraints) Let X be an itemset, a constraint CAM is anti-monotone if ?Y ?

an itemset, a constraint CAM is anti-monotone if ?Y ?

X : CAM (X) ? CAM (Y ).

A constraint CM is monotone if ?Y ? X : CM (X) ?

CM (Y ).

Definition 4 (Borders of theories) Given a CAM constraint and a CM constraint we de?ne the bor- ders of their theories respectively as: B(Th(CAM )) = {X|?Y ? X. CAM (Y )??Z ? X.? CAM (Z)} B(Th(CM )) = {X|?Y ? X. CM (Y ) ? ?Z ? X.? CM (Z)} Moreover, we distinguish between positive and negative borders. Given a general constraint C we de?ne: B+(Th(C)) = B(Th(C)) ? Th(C) B?(Th(C)) = B(Th(C)) \ Th(C) Analogously we can de?ne the borders of a F-Theory.

With this notation, given a transaction database D, a minimum support threshold ? and a general conjunc- tion of constraints C we have the following classical mining problems: - MP1: the frequent itemset mining problem requires to compute FThD(Cfreq[D,?]) [1]; - MP2: the maximal frequent itemset mining problem requires to compute B+(FThD(Cfreq[D,?])) [3]; - MP3: the constrained frequent itemsets mining prob- lem requires to compute FThD(Cfreq[D,?] ?C) [13]; - MP4: the closed frequent itemset mining problem re- quires to compute Cl(FThD(Cfreq[D,?])) [14].

The problem which we address in this paper is the con- junction of problemsMP3 andMP4. According to the interpretation I2, discussed in the Introduction, we pro- vide the following de?nition.

- MP5: the closed constrained frequent itemset mining problem requires to compute: Cl(FThD(Cfreq[D,?] ? C)) This de?nition will be proven to be the only reasonable in Section 3.

1.2. Related Work Even if a lot of work has been done with closed item- sets and with constrained itemsets, there are only a few approaches analyzing the conjunction of these two frameworks. The ?rst approach is [8] where instead of mining closed itemsets, it is proposed to mine free item- sets, i.e. the minimal elements of each equivalence class of frequency (closed itemsets are the maximal elements of such classes). The output of the algorithm is made with all the free itemsets satisfying a given set of mono- tone and anti-monotone constraints. The authors pro- pose a variation of the A-CLOSE [14] algorithm, with constraints pushed into the computation. Free item- sets representation is concise, though the number of 0-7695-2142-8/04 $ 20.00 IEEE D a,b,c,d,e b,c b,c,d,e  a,b,c,d a,b,c,e b,c,d,e item price a 15 b 18 c 2 d 4 e 14 Borders of theories B+(Th(Cfreq[D,3])) = {abc, bcde} B?(Th(Cfreq[D,3])) = {ad, ae} B+(Th(CM )) = {ab, bce, bde} B?(Th(CM )) = {acd, ace, bcd, cde} ab abc    abc bcde bdebce4 xyz3 Itemset SUPPORT abcd abce abcde abde acde abd abe ade 2 2 cb ? a bdbc ce de bcd cde d e4 4 4 4 4 3 6 6 acd ace2 2 2 Cfreq CM Figure 1. A transaction database D, an item-price table, the borders of theories of Cfreq[D,3], and CM ? sum(X.prices) ? 33. In this case we have that FThD(Cfreq[D,3] ? CM ) = {?ab, 3?, ?abc, 3?, ?bcde, 3?, ?bce, 4?, ?bde, 3?}.

free sets is greater than the number of closed ones, but it is not lossless. In fact, it is not possible to re- construct the whole Th(Cfreq) unless additional scans through the dataset are performed. Moreover we will see how this representation retains the same ambiguity in mining constrained free sets. Since this kind of rep- resentation is itself problematic (i.e. it is not lossless), and since it does not bring any advantage in mining the constrained solution space, we will focus on closed  itemsets in this paper instead of free itemsets.

In [11], hard constraints are pushed into the fre- quent closed itemsets mining process. The output of the algorithm is the same of a post-processing one, i.e.

?rst closed itemsets are discovered and then they are tested against a given set of constraints. Both these works exploit the interpretation I1, without address- ing the problem of the information loss it produces.

This choice is explicitly made in order to simplify the mining process. In this paper we quantify such infor- mation loss given by the post-processing approach and give a new accurate de?nition of the problem of con- strained closed itemset mining, which provides a con- cise and lossless condensed representation of the solu- tion space.

2. Preliminaries In this Section we review and deeply characterize the constrained frequent itemsets mining problem MP3 and the closed frequent itemset mining problem MP4.

The provided characterization will then be useful to characterize the new problem MP5.

characterize the new problem MP5.

2.1. Constrained Frequent Itemsets A na??ve solution to the constrained frequent item- set mining problem (MP3), is to ?rst ?nd all frequent itemsets and then test them for constraints satisfac- tion. However more e?cient solutions can be found by analyzing the property of constraints comprehen- sively, and exploiting such properties in order to push constraints in the frequent pattern computation. Fol- lowing this methodology, some classes of constraints which exhibit nice properties (and the relative compu- tational strategies) have been de?ned in literature (e.g.

anti-monotonicity, monotonicity, succinctness, convert- ibility) [13, 15, 6]. In this paper we focus on the two basic classes of constraints: anti-monotone and mono- tone constraints (see De?nition 3).

The most studied anti-monotone constraint is the frequency one. The anti-monotonicity of Cfreq is used by the Apriori [2] algorithm with the fol- lowing heuristic: if an itemset X does not satisfy Cfreq , then no superset of X can satisfy Cfreq , and hence they can be pruned. Another typical exam- ple of CAM constraint is sum(X.price) ? m, while, symmetrically, sum(X.price) ? m is a CM con- straint. In the rest of this paper we will consider these two constraints as prototypical CAM and CM con- straints without loss of generality.

We now characterize the solutions spaces of the two problems Th(Cfreq ? CAM ) and Th(Cfreq ? CM ).

Since any conjunction of CAM constraints is still a CAM constraint, and since Cfreq is a CAM constraint, the solutions space Th(Cfreq ? CAM ) is a downward closed theory, i.e. if an itemset X is a solution, all subsets of X will be solutions as well. In other words, solution item- sets are those one that lie under both borders (the bor- der of frequency and the border of CAM ).

Proposition 1 X ? Th(Cfreq ? CAM ) ? ?Y ? B+(Th(Cfreq)), ?Z ? B+(Th(CAM )) : X ? Y ?X ? Z In order to characterize the other problem Th(Cfreq ?

CM ) we use a graphical example. In Figure 1 we have a transaction database D and a item-price table, 0-7695-2142-8/04 $ 20.00 IEEE and we show the borders of theories of the frequency  constraint Cfreq[D,3], and of the monotone constraint CM ? sum(X.prices) ? 33. The solutions to the prob- lem Th(Cfreq[D,3] ? CM ) are the itemsets that lie in be- tween the two borders: under the border of frequency and over the monotone border. The next Proposition states algebraically what we have just seen graphically.

Proposition 2 X ? Th(Cfreq ? CM ) ? ?Y ? B+(Th(Cfreq)), ?Z ? B+(Th(CM )) : Z ? X ? Y 2.2. Closed Frequent Itemsets The set of frequent closed itemsets is a condensed representation of frequent itemsets. Condensed repre- sentation is a term ?rst introduced in [12], which we use to indicate a representation of a theory, which is both: concise: the size of the representation is signi?cantly smaller than the original theory; lossless: from the representation it should be possi- ble to reconstruct all the information present in the original theory without mining the database again.

According to this de?nition, the set of maximal fre- quent itemsets, B+(Th(Cfreq)), is a condensed repre- sentation (concise and lossless) of Th(Cfreq), while for FThD(Cfreq) is just concise but not lossless: in fact from maximal frequent itemsets we can reconstruct the full    set of frequent itemsets but not their supports.

On the other hand the set of closed itemsets Cl(FThD(Cfreq)) is a condensed representation of FThD(Cfreq), since closed itemsets are orders of mag- nitude fewer than the frequent ones and from them is possible to reconstruct all frequent itemsets and their supports without accessing the transaction database any more. Moreover, association rules ex- tracted from closed sets have been proved to be more concise and meaningful, because all redundan- cies are discarded.

The problem of mining closed frequent itemsets (MP4) was ?rst introduced in [14] and since then it has received a great deal of attention especially by an algorithmic point of view [16, 20, 17].

Formally, given the functions: f(T ) = {i ? I | ?t ?

T, i ? t}, which returns all the items included in the set of transactions T , and g(X) = {t ? D | ?i ? X, i ? t} which returns the set of transactions supporting a given itemset X, the composite function f ? g is called Ga- lois operator or closure operator. We have the following de?nition: cb ? a acab be de abc bcde cdebce d e4 4 4 3 3  6 6 xyz3 Itemset SUPPORT xyz3Closed Itemset Equivalence Class ae abcd abce abcde abde acde Cfreq Figure 2. Equivalence classes of itemsets for the dataset D defined in Figure 1.

Definition 5 An itemset I is said to be closed if and only if c(I) = f(g(I)) = f ? g(I) = I Now we can de?ne a set of equivalence classes over the lattice of frequent itemsets, where two item- sets X,Y belong to the same class if and only if c(X) = c(Y ), i.e. they have the same closure. Closed itemsets are exactly the maximal elements of these    itemsets are exactly the maximal elements of these equivalence classes. Figure 2 shows the lattice of fre- quent itemsets derived from the same simple dataset of Figure 1. Each equivalence class contains ele- ments sharing the same supporting transactions, and closed itemsets are their maximal elements. In this situation we have that Cl(FThD(Cfreq[D,3])) = {?abc, 3?, ?bc, 6?, ?bcd, 4?, ?bcde, 3?, ?bce, 4?}. Note that the number of closed frequent itemsets (5) is much less than the number of frequent itemsets (19).

It trivially holds that these equivalence classes of frequency are never cut by the border of frequency (as shown in Figure 2); but what happens to these equiv- alence classes when they are cut by some CAM or CM constraints? In the next Section by giving an answer to this question, we provide a characterization of MP5.

3. Closing Theories of Constraints Recall the mining query discussed in the Introduction: Q : Cfreq(X) ? Cclose(X) ? sum(X.price) ? 22 The two di?erent interpretations of Q are as follows (where CAM ? sum(X.price) ? 22): ? I1 : Cl(FThD(Cfreq[D,?])) ? FThD(CAM ) ? I2 : Cl(FThD(Cfreq[D,?] ? CAM )) We now prove that these two di?erent interpretations lead to di?erent results sets.

0-7695-2142-8/04 $ 20.00 IEEE cb ? a ac cd de cde d e4 4 4 4 3  6 6 xyz3 Itemset SUPPORT xyz3Closed Itemset Equivalence Class 2ab abc3 bcde bce4 abcd abce abcde abde acde 2 2 Cfreq CAM ab abc bcde bdebce4    xyz3 Itemset SUPPORT xyz3Closed Itemset Equivalence Class abcd abce abcde abde acde abd abe ade 2 2 cb ? a bdbc de bcd cde d e4 4 4 4 4 3  6 6 acd ace2 2 2 Cfreq CM (a) (b) Figure 3. Equivalence classes of frequency when intersected by a CAM (a), and by a CM (b) constraint.

Example 1 In Figure 3(a) we show the usual itemsets lattice with the frequency equiva- lence classes and the border of the theory of CAM ? sum(X.price) ? 22. In this situation we have that I1 = {?bc, 6?} while on the other hand I2 = {?ac, 3?, ?bc, 6?, ?bd, 4?, ?cd, 4?, ?ce, 4? ?cde, 3?}.

What has happened is that some equivalence classes have been cut by the CAM constraint. With interpreta- tion I1 we mine closed frequent itemsets and then we remove those ones which do not satisfy the CAM con- straint: this way we lose the whole information con- tained in those equivalence classes cut by the CAM con- straint. On the other hand, according to interpretation I2, we mine the set of itemsets which satisfy the CAM constraint and then we compute the closure of such itemsets collection: thus, by de?nition, the itemsets bd and cd are solutions because they satisfy CAM and they have not a superset in the result set with the same sup- port and satisfying the constraint.

Which one of the two di?erent interpretations is the most reasonable? It is straightforward to see that interpretation I1 is not a condensed representation since it loses a lot of information. In extreme cases it could output an empty solutions set even if there are many frequent itemsets which satisfy the given set of user-de?ned constraints. On the other hand, in- terpretation I2, which corresponds to the de?nition Cl(FThD(Cfreq[D,?] ? CAM )), is a concise and lossless representation of FThD(Cfreq[D,?] ? CAM ).

Observe that I2 is a superset of I1: it contains all    Observe that I2 is a superset of I1: it contains all closed itemsets which are under the CAM border (as I1), plus those itemsets which arise in equivalence classes which are cut by the CAM border (such as for instance ce and cde in Figure 3(a)).

Proposition 3 Cl(FThD(Cfreq ? CAM )) ? Cl(FThD(Cfreq)) ? FThD(CAM ) Let us move to the dual problem. In Figure 3(b) we show the usual equivalence classes and how they are cut by CM ? sum(X.prices) ? 33. Since CM constraints are upward closed, we have no problems with classes which are cut: the maximal element of the equivalence class will be in the alive part of the class. In other words when we have a CM constraint, the two interpre- tations I1 and I2 correspond.

Proposition 4 Cl(FThD(Cfreq ? CM )) = Cl(FThD(Cfreq)) ? FThD(CM ) The unique problem that we have with this con- densed representation, is that, when reconstruct- ing FThD(Cfreq[D,?] ? CM ) from it we must take care of testing itemsets which are subsets of ele- ments in Cl(FThD(Cfreq ? CM )) against CM , in order not to produce itemsets which are below the mono- tone border B+(Th(CM )). Note that, however, we do not need to access the transaction dataset D any- more.

Since we mine maximal itemsets of the equivalence classes it is impossible to avoid this problem, unless we store, together with our condensed representation, the border B+(Th(CM )) even if it does not contain any closed itemset. This could be an alternative. However, since closed itemsets provide a much more meaning- ful set of association rules, we consider a good trade- o? among performance, conciseness and meaningful- ness the use of Cl(FThD(Cfreq?CM )) as condensed rep- resentation.

Finally, if we use free sets instead of closed, we only shift the problem leading to a symmetric situation. Us- ing free sets interpretations I1 and I2 coincide when dealing with anti-monotone constraints because mini- mal elements are not cut o? by the constraint (e.g. de in Fig. 3(a)), but I1 is lossy when dealing with monotone constraints (e.g. no free solution itemsets in Fig. 3(b)).

0-7695-2142-8/04 $ 20.00 IEEE 4. Algorithms In this Section we study algorithms for the compu- tation of MP5. We ?rst discuss separately how mono- tone and anti-monotone constraints can be pushed in the computation, then we show how they can be ex- ploited together by introducing the CCIMiner algo- rithm.

4.1. Pushing Monotone Constraints Pushing CAM constraints deep into the fre- quent itemset mining algorithm (attacking the prob- lem FThD(Cfreq[D,?] ? CAM )) is easy and e?ective [13], since they behave exactly as Cfreq . The case is di?erent for CM constraints, since they behave exactly the oppo- site of frequency. Indeed, CAM constraints can be used to e?ectively prune the search space to a small down- ward closed collection, while the upward closed collection of the search space satisfying the CM con- straints cannot be exploited at the same time. This tradeo? holding on the search space of the compu- tational problem FThD(Cfreq[D,?] ? CM ) has been extensively studied [18, 9, 4], but all these stud- ies have failed to ?nd the real synergy of these two opposite types of constraints, until the recent pro- posal of ExAnte [6]. In that work it has been shown that a real synergy of the two opposites exists and can be exploited by reasoning on both the item- set search space and the transactions input database    set search space and the transactions input database together.

According to this approach each transaction can be analyzed to understand whether it can support any so- lution itemset, and if it is not the case, it can be pruned.

In this way we prune the dataset, and we get the fruit- ful side e?ect to lower the support of many useless itemsets, that in this way will be pruned because of the frequency constraint, strongly reducing the search space. Such approach is performed with two successive reductions: ?-reduction (based on monotonicity) and ?-reduction (based on anti-monotonicity). According to ?-reduction we can delete transactions which do not satisfy CM , in fact no subset of such transactions sat- is?es CM and therefore such transactions cannot sup- port any solution itemsets. After such reduction, a sin- gleton item may happen to become infrequent in the pruned dataset, an thus it can be deleted by the ?- reductions. Of course, these two step can be repeated  until a ?xed point is reached, i.e. no more pruning is possible. This simple yet very e?ective idea has been generalized in an Apriori-like breadth-?rst computa- tion in ExAMiner [5], and in a FP-growth [10] based depth-?rst computation in FP-Bonsai [7].

Since in general depth-?rst approaches are much more e?cient when mining closed itemsets, and since FP-Bonsai has proven to be more e?cient than ExAM- iner, we decide here to use a FP-growth based depth- ?rst strategy for the mining problem MP5. Thus we combine Closet [16], which is the FP-growth based al- gorithm for mining closed frequent itemset, with FP- Bonsai, which is the FP-growth based algorithm for mining frequent itemset with CM constraints.

4.2. Pushing Anti-monotone Constraints Anti-monotone constraints CAM can be eas- ily pushed in a Closet computation by using them in the exact same way as the frequency constraint, ex- ploiting the downward closure property of anti- monotone constraints. During the computation, as soon as a closed itemset X s.t. ? CAM (X) is discov- ered, we can prune X and all its supersets by halting the depth ?rst visit. But whenever, such closed item- set X s.t. ? CAM (X) is met (e.g. bcd in Figure 3(a)), some itemsets Y ? X belonging to the same equiva- lence class and satisfying the constraint may exist (e.g.

bd and cd in Figure 3(a)). For this reason we store ev- ery such X in a separate list, named Edge, and after the mining we can reconstruct such item- sets Y by means of a simple top-down process, named Backward-Mining, described in Algorithm 1.

Algorithm 1 Backward-Mining Input: Edge, C, CAM , CM // C is the set of frequent closed itemsets // CAM is the antimonotone constraint // CM is a monotone constraint (if present) Output: MP5 1: MP5 = C; // split Edge by cardinality 2: k = 0; 3: for all c ? Edge s.t. CM (c) do 4: E|c| = E|c| ? {c}; 5: if (k &lt; |c|) then 6: k=c; // generate and test subsets 7: for (i = k; i &gt; 1; i??) do 8: for all c ? E|i| s.t. CM (c) do 9: for all (i? 1)-subset s of c do 10: if (??Y ?MP5 | s ? Y ) then 11: if CAM (s) then 12: MP5 = MP5 ? s; 13: else    13: else 14: E|i?1| = E|i?1| ? s; The backward process in Algorithm 1, generates level-wise every possible subset starting from the bor- 0-7695-2142-8/04 $ 20.00 IEEE der de?ned by Edge without getting into equivalence classes which have been already mined (Line 10). If such subset satis?es the constraint then it can be added to the output (Line 12), otherwise, it will be reused later to generate new subsets (Line 14). If we have a monotone constraint in conjunction, the back- ward process is stopped whenever the monotone bor- der B+(Th(CM )) is reached (Lines 3 and 8).

4.3. Closed Constrained Itemsets Miner The two techniques which have been discussed above are independent. We push monotone constraints work- ing on the dataset, and anti-monotone constraints working on the search space. It?s clear that these two can coexist consistently. In Algorithm 2 we merge them in a Closet-like computation obtaining CCIMiner.

Algorithm 2 CCIMiner Input: X,D |X , C, Edge,MP5, CAM , CM // X is a closed itemset // D |X is the conditional dataset // C is the set of closed itemsets visited so far // Edge set of itemsets to be used in the Backward- Mining // MP5 solution itemsets discovered so far // CAM , CM constraints Output: MP5 1: C = C ?X 2: if ?CAM (X) then 3: Edge = Edge ?X 4: else 5: if CM (X) then 6: MP5 = MP5 ?X 7: for all i ? flist(D |X) do 8: I = X ? {i} // new itemset // avoid duplicates 9: if ??Y ? C | I ? Y ? supp(I) = supp(Y ) then 10: D |I= ? // create conditional fp-tree 11: for all t ? D |X do 12: if CM (X ? t) then 13: D |I= D |I ?{t |I} // ?-reduction 14: for all items i occurring in D |I do 15: if i /? flist(D |I) then 16: D |I= D |I \i // ?-reduction 17: for all j ? flist(D |I) do 18: if supD|I (j) = sup(I) then 19: I = I ? {j} // accumulate closure 20: D |I= D |I \{j} 21: CCIMiner(I,D |I , C,B,MP5, CAM , CM ) 22: MP5 = Backward-Mining(Edge,MP5, CAM , CM ) For the details about FP-Growth and Closet see [10, 16]. Here we want to outline three basic steps: 1. the recursion is stopped whenever an itemset is found to violate the anti-monotone constraint CAM (Line 2); 2. ? and ? reductions are merged in to the compu- tation by pruning every projected conditional FP- Tree (as done in FP-Bonsai [7]) (Lines 11-16); 3. the Backward-Mining has to be performed to re- trieve closed itemsets of those equivalence classes which have been cut by CAM (Line 22).

5. Experimental Results The aim of our experimentation is to measure per- formance bene?ts given by our framework, and to quantify the information gained w.r.t. the other lossy approaches.

approaches.

All the tests were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory, within the cygwin environment. The datasets used in our tests are those ones of the FIMI repository1, and the constraints were applied on at- tribute values (e.g. price) randomly generated with a gaussian distribution within the range [0, 150000].

In order to asses the information loss of the post-  processing approach followed by previous works, in Fig- ure 4(a) we plot the di?erence in cardinality of the so- lution sets given by two interpretations, i.e. |I2 \ I1|.

On both datasets PUMBS and CHESS this di?erence rises up to 105 itemsets, which means about the 30% of the solution space cardinality. It is interesting to ob- serve that the di?erence is larger for medium selective constraints. This seems quite natural since such con- straints probably cut a larger number of equivalence classes of frequency.

In Figure 4(b) the number of FP-tree data structures built during the mining is reported. On every dataset tested, the number of FP-trees decrease of about four orders of magnitude with the increasing of the selectiv- ity of the constraint. This means that the technique is quite e?ective independently of the dataset.

Finally, in Figure 4(c) we plot run-time comparison of our algorithm CCIMiner w.r.t. Closet at di?erent selectivity of the constraint. Since the post-processing approach must ?rst compute all closed frequent item- sets, we can consider Closet execution-time as a lower- bound on the post-processing approach performance.

Recall that CCIMiner exploits both requirements (sat- isfying constraints and being closed) together at min- ing time. This exploitation can give a speed up of about to two orders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously the performance improve- ments become stronger as the constraint become more selective.

1 http://fimi.cs.helsinki.fi/data/ 0-7695-2142-8/04 $ 20.00 IEEE Information loss Number of FP-trees generated Run time performance 0 2 4 6 8 10 12 14 x 10 m !I \I | PUMSB@29000 CHESS @ 1200 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10     m n u m b e r o f fp -t re e s PUMSB @ 29000 CHESS @ 1200 CONNECT@11000 0 2 4 6 8 10 12 14 x 10 m e x e c u ti o n  ti m e  (s e c .) CCI Miner  (PUMSB @ 29000) closet         (PUMSB @ 29000) CCI Miner  (CHESS @ 1200) closet         (CHESS @ 1200) CCI Miner  (CONNECT @ 11000) closet         (CONNECT @ 11000) (a) (b) (c) Figure 4. Experimental results with CAM ? sum(X.price) ? m.

6. Conclusions    6. Conclusions In this paper we have addressed the problem of min- ing frequent constrained closed patterns from a qualita- tive point of view. We have shown how previous works in literature overlooked this problem by using a post- processing approach which is not lossless, in the sense that the whole set of constrained frequent patterns can- not be derived. Thus we have provided an accurate de?nition of constrained closed itemsets w.r.t the con- ciseness and losslessness of this constrained represen- tation, and we have deeply characterized the computa- tional problem. Finally we have shown how it is possi- ble to quantitative push deep both requirements (sat- isfying constraints and being closed) into the mining process gaining performance bene?ts with the increas- ing of the constraint selectivity.

