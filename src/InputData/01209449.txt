Linguistic Summarization of Data  Association Rules

Abstract-We discuss linguistic summaries of databases introduced by Yager [28,29]. Starting with our previous work [7,8,9,13,14-161 we propose some extensions to the form of a liiguistic sannnary. The new form still fits the scheme of an assochlion rule [1,24,25]. However, in comparison to the previous approaches, the use of a range of linguistic values as items and their linguistically quantified aggregation is allowed. An algorithm for mining such association rules within this framework, via the authors' FQUERY for Access package, is presented. Moreover, we show that Zadeh's [311 idea of protofom, and their hierarchies, can be employed to represent various types of linguistic summaries.

Index Terms-Data mining, linguistic database summary, association rule, fuzzy querying, protoform  1. INTROOUCTION  Collections of data gathered either in "regular" databases or data warehouses are now too voluminous to be comprehensible and manageable by humans, and intelligent techniques for their handling are needed. The approach we advocate here refers to linguistic summaries of data, introduced by Yager [281, exemplified by "Most expensive real-estate properties possess large land area". Thus, linguistic summaries provide us with the highly aggregated information o n  the data in question. The use of linguistic terms makes the summaries more human Consistent.

The point of departure is our add-in to Microsoft Access DBMS, FQUERY for Access, which makes possible the use of flexible (fuzzy) queries Kacprzyk and Zadroiny [11-12]. The use of linguistic terms in queries provides for some form of information aggregation. Our fuzzy querying interface inherently supports some features required for an efficient implementation of linguistic summaries due to Yager [28,29].

In Kacprzyk and Zadroiny [7,8,9.13,14-16] we described a preliminary implementation of linguistic summaries within our FQUERY for Access. So far, only a limited subset of possible types of summaries was implemented. The most sophisticated form of the summary is computationally very difficult. We proposed to employ well-known, efficient association rules mining algorithms for that purpose. It makes it possible to  mine more sophisticated, although still rather simplified, forms of linguistic summaries. Here we investigate the possibility of further advancing in this direction. . Moreover, we show that Zadehs [31] recent idea of a (hierarchy of) protofom of linguistic summaries may provide a convenient theoretical framework.

The association rules were originally meant for binary data mining, and efficient algorithms have been devised to generate them. Moreover, the concept is easily extensible to more complex data, including real valued and scalar data as well as taxonomies of values. Our approach consists in adapting rules discovery algorithm for the use of linguistic terms so that either fuzzy querying or data mining can be set up on the same vocabulary of linguistic terms. Here, we proceed further, employing the same algorithm for mining summaries of an enriched structure.

We outline the idea of linguistic summaries, their classification and relation to Zadehs [31] concept of a (hierarchy of) protoforms. We discussed proposed here extended forms of summaries and how they can be generated using association rules mining algorithm.

11. DATA MINING VIA LINGUISTIC DATABASE SUMMARIES  Data mining is meant for finding interesting pattems, dependencies, regularities etc. in data stored in databases.

Yager [28,29] proposed to use linguistically quantified propositions, due to Zadeh [301, to summarize the content of a database (table). For example, it may be interesting for a manager to get the following summary of the table EMPLOYEES holding information on the staff of his company: "Most of the employees are of medium age and eam a high salary" or "Most of the newly hired employees with a high salary are young". Such linguistically expressed statements may be of a great value, but we have some means to assess their validity (mth).

Zadehs [30] calculus of linguistically quantified propositions makes it possible to calculate the truth-value of such propositions, which may be put in a more general form:  (1) "Most elements of set X satisfy s" and formally expressed as follows:  Q S(x) E X  The authors are with the Systems Research hstifute. Polish Academy of Sciences, 01447 Warsaw, "I. Newelska 6, Poland; e-mails: kacp~yk@ihspan.waw.pI, mdromy@ibrpan.waw.pl     where Q i s  a fuzzy linguistic quantifier (e.g., "most"), x ={.Y, ,... x,,,} i s  a universe of discourse, and~( . ) i s  a fuzzy  predicate.

The second example exemplifies another form o f  a  proposition:  "Most elentents o f  set X satisfying F satisfy also property s" (3)  that may bc formally expressed as follows:  QFS(.r) (4) .A? x  where F i s  another fuzzy predicate  Both F and S are fuzzy, equated with fuzzy sets Fand S, so that truth(S(.v,)) =.us(.ri) and truth(F(.r)) =,u,c(.r).

In  fact, wherever a predicate i s  mentioned there may appear just a predicate (an atomic formula: "s i s  newly hired") or a combination o f  predicates (a formula: 'Ir i s  newly hired and .r has got a high salary"). I n  the context of database (table) the set X i s  identified with the set o f  rows o f  this table and the formula S inay be uiiderstood as a query. Then, ( I )  states that niost o f  tlie rows satisfy the query (formula) S. The more complex i s  the query involved, the less trivial i s  the suminary obtained. 111 large data sets it may relatively seldom happen that most rows satisfy a given noli-trivial query. Then, a proposition of type (3) may be helpful. Namely, i t  states that a subset o f  rows satisfies specified query. I n  the database terminology, formula F may be understood as apIter and (3) asserts that iiiosr of  the rows passing through F match query S.

Moreover, since F may be fuzzy. a row may pass through i t  to a degree from {0,1].

I n  Yager's approach 128, 291 the truth-value of ( I )  or (3) is the primary measure o f  quality of the obtained summary.

Practically, such a basic quality indicator has to be supplemented with some measure of "interestingness" ("non- triviality", "unexpectedness". ...) - cf. Kacprzyk and Yager (91 or Kacprryk, Yager and Zadroiny [IO]. I n  what follows, we wil l  discuss different types of linguistic data summaries based on the gcneral scheme given by (3).

Thus, the generation of a linguistic summary consists in finding propositions of type (3) that have a high truth-value.

Basically. a proposition sought consists o f  three elements: a fuzzy filter F (optional). a query S, and a linguistic quantifier Q. There are two limit cases, where we: (1) do not assume anything about the form o f  any of these elements, or (2) fix al l the elements of a summary. I n  case 1 data summarization wil l be extremely time-consuming, but may produce interesting results. I n  case 2 the user has to guess a good candidate for summarization but the evaluation i s  fairly simple, equivalent to the answering of a (fuzzy) query. In-between there are different types o f  summaries, with various assumptions on what i s  given and what i s  sought. I t  may be noticed the concept of a protoform i n  the sense of Zadeh [31] may be valuable for tlie study o f  all possible types o f  summaries. First of  all, a protoform i s  defined as an abstracted prototype that is, in our context, is given by (2) and (4). Protoforms may form a  hierarchy, i.e., we can define higher or  lower level (more or less abstract) protoforins, e.g. replacing Q with IJIOSI in (2) and (4) we obtain (I) and (3). respectively. Therefore, the more abstract forms correspond to cases in which we assume less on what we know. I n  our previous work [ l O , l 5 ]  we proposed 5 types of summaries corresponding to different levels of abstraction in the hierarchy of  the protoforms.

Here we are interested in a simplified version of  the summaries of  type 5, that correspond to the most abstract protoform (4). I t  i s  worth noticing that i t  may be interpreted as a classical IF-THEN rule stating that i n  case of  niost rows if they satisfy fi l ter F then they satisfy also query S. For a general form of such a rule i t  i s  difficult to devise an effective and efficient generation algorithm. Generic al&orithm based approaches may be employed [61. I n  order to alleviate the computational complexity, additional assumptions may also be made. For example. some sets of relevant (interesting, promising. etc.) attributes for the query and the filter may be selected i n  advance. Some constraints may also be put on the structure o f  S and F. I n  the next section we pursue this idea and discuss in more detail a special case of- this type of summaries that correspond to the well-known concept o f  the association rule. Then, computationally efficient algorithms known in the literature may be employed for mining the summaries.

111. ASSOCIATION RULES AN0 LINGUISTIC SlIhlMAKIES  Originally, the association rules were defined for transactional data and binary valued attributes in the following form:  A I d 2 ~ . . . d , ~  +A,,,,  (5 )  An association rule states that if in a datahase row a11 the attributes from { A l ,  A2,. . ,  A , , }  take on value 1, then also attribute A,,,, i s  expected to take on value 1.

A row in a database (table) i s  said to srippoi-t a set o f attributes ( A i l t E ,  if all attributes from the set take on in this row value 1. There are ~ W O  measures of the quality o f  an a~~ocint ion rule ( 5 ) :  (1) the sirpporl i s  the fraction of  the number of  rows supporting the set of attributes ( A , \ , iE { I,.. ,n+l } in a database (table), and (2) the coiifideiice i s  the fraction of the rows supporting { A , ] ,  ic { I ,  ... i1+1} among a l l rows supporting ( A ; ] ,  ie { I , . . , i i } .

Thus, while the support determines a statistical significance of a rule, the confidence measures its strength. Usually, we are interested in rules having values of the support above some minimal threshold and a high value o f  the confidence. This form o f  association rules was motivated by their early applications for a so-called customer's basket analysis.

Some efficient algorithms for finding all association rules possessing a required support measure were devised. see, e.g.

[1,20], and association rules have become a very popular tool for data mining.

The original concept of an association rule evolved over time but s t i l l  the same algorithms are applicable. The     extensions to the initial form of the association rule include the following:  (I) the right-hand side, like the left-hand side, may contain a conjunction of the attributes instead of just one attribute, (2) many-valued scalar values and their hierarchies may be used 1241, (3) numerical, real-valued attributes may be used [25] leading to the quantitative association rules, and  iv. (4) some constraints may be imposed on combinations of attributes in rules [26].

In view of (i) and (iii) the initial scheme of an association  AI=alA2-~A. . .AA.=a .  3 A.+I=a,+lA...AA.+,=a,+, (6) where ai represents a value or a range of values of an attribute  Clearly, association rules may be interpreted as a special case of summaries. Namely, the antecedent and consequent of (6) correspond to filter F and query S of (41, respectively.

Confidence of a rule is related to the combination of the linguistic quantifier and truth degree of (4). General concept of the linguistic summary assumes a query S to be a formula, atomic or complex. Thus, the structure of the filter and the query available in case of association rules is rather limited but this simplicity secures the existence of efficient algorithms for rule generation.

In our previous work we implemented mining of the linguistic summaries corresponding to the association rule (6) within the framework of our fuzzy querying package (cf. the next section). For that purpose we generalized (6) to the following form:  (7)  This boils down to the use of fuzzy valuesf, instead of crisp values (or their ranges) as in (6). Here we propose two extensions to this form offurzy association rule. First, a minor one, enriches the structure of an atomic condition:  1.

ii.

111.

...

rule (5) may be rewritten as follows:  Ai.

A I  I s f 1 ~ . . . 4 1 S f ~  3 A,+* I S f n + ~ ~ . . . 4 + , , , I S f n + , , ,  Ai lSf, (8)  (an item in the terminology of the association rules) by allowing it to take the following form:  A i  IS It;lv...vJk) (9)  where Ji are all fuzzy values defined over the domain of the attribute A;. Thus, we propose to make it possible to use a range of fuzzy values what corresponds to the case of quantitative crisp association rule [25]. In practical cases it is often enough to consider just three fuzzy values for a numerical attribute: low, medium, high. Then, the atomic condition (9) may be identified with a negation as in the following example:  salary IS low or medium I salary IS NOT high  The second extension of (9) consists in using a flexible aggregation operator in query andlor filter formula. This leads to the following form of the atomic condition:  where Q is a linguistic quantifier, e.g., most. In practical cases this will be most often the only atomic formula in an antecedent or consequent of an association rule. However, it may be just a part of a compound formula. Please observe, that f i  in (9) refer to the same attribute, while f l s  in (10) to different attributes.

The idea of such an extension of the fuzzy association rules is rooted in the capabilities of our fuzzy querying package FQUERY for Access. The next section presents it briefly providing also some details of the implementation of the above extensions to the fuzzy association rules syntax.



IV. ASSOCIATION RULE MINING VIA FQLiERY FOR ACCESS  Fuzzy querying consists in a direct use of linguistic terms in queries. Our implementation, FQUERY for Access package, supports the following types of linguistic terms: (1 )  numericalfuq values, exemplified by low in "salary is  ( 2 )  scalar furzy values, exemplified by Central Europe in  (3) fuzzy relations, exemplified by much greater than in  (4) linguistic quantifiers, exemplified by most in "most  In our description of fuzzy linguistic summaries we will be concerned only with type ( I )  and (4) linguistic terms.

Fuzzy linguistic quantifiers are handled using Zadehs [30] calculus of linguistically quantified propositions, cf. (1)-(4).

Usually, a query consists of a number of simple conditions combined using the classical AND and OR. In our approach, linguistic quantifiers provide for a more flexible aggregation of simple conditions in queries. For example, instead of requiring that all simple conditions be met, using a linguistic quantifier we may indicate that most of them are to be met.

The definitions of all linguistic terms, including representing them fuzzy sets, are maintained in dictionaries of linguistic terms defined by users as well as predefined in the system.

Thus, in fact all building blocks of the fuzzy linguistic summaries, as defined with (7), are available within our fuzzy querying environment. Moreover, it may be assumed that the linguistic terms defined by a user have a clear interpretation for him or her. Thus, a fuzzy querying interface offers a practical solution to some problems the "classical" [ l ,  25, 261 search for the association rules faces. Namely, the quantitative association rules (i.e., including also non-binary attributes) usually require discretization of the attributes obtained via a panition of its domain into a number of intervals. Then, each interval is treated as an additional binary attribute and known algorithms for the generation of classical association rules may be employed. It is not obvious how such a partition should be arrived at. Having a domain covered by a number of overlapping fuzzy values (defined and tested for the purposes of fuzzy querying) makes the partition available "for free".

Combining querying and mining within the same interface seems to yield a synergetic effect. Also, from the viewpoint of  low",  "country is in Central Europe",  "income is much greater than spending", and  conditions have to be met".

software engineering it is advantageous as we can employ some of the modules to support both functions. Thus, we extended our package with the capability of producing linguistic summaries of a database. Here, we consider only those corresponding to fuzzy association rules, notably as illustrated with (9) and (IO). The user interface is the same as for fuzzy querying. However, for computational efficiency reasons, the very algorithm of fuzzy association rules mining is implemented as a separate executable implemented using Delphi.

Our implementation of association rules is based on the Agrawal and Srikant?s AprioriTID algorithm [I]. Basically, the algorithm works in two steps: first it finds frequent itemsets and then produces rules from each itemset. The second step is relatively easy, hence we will focus on the first one. An itemset is a conjunction of the items of the form (9) or (IO). A row in the database (table) is said to support an itemset if the corresponding conjunction ?is true? for this row. An itemset containing k items is called a k-itemset. The algorithm starts with the evaluation of 1-itemsets. These itemsets which are not supported by sufficient number (minsup) of rows are deleted.

Previously, we assumed 1-itemsets only in the form (8). In order to implement items of the form (9) and (IO) we have to extend this step. Namely, we treat as I-itemsets also items of the formAi IS (J1v...vJJ and Q of(Al ISf,.. Az Ish, , A .  IS f?). More precisely, first only ?regular? I-itemsets (8) are counted, i.e., a full scan of the database (table) is done and frequency of appearance of all items is calculated. Then, 1- itemsets (9) are constructed, however only such f, are taken into account that have support greater than some value (another parameter of the method, besides minsup and minconf) higher than 0 and less than minsup. For example, if a regular l-itemset ?salary IS high? gets very low support we will not construct neither ?salary IS medium or high? nor ??salary IS low or high? 1-itemsets. This helps to reduce the time and memory complexity of the algorithm. Such reduction is even more important in case of the implementation of (10) 1-itemsets. Basically, we should take into account all subsets of regular 1-itemsets and all possible quantifiers Q. This would he computationally intractable and in fact, require a kind of recursive use of Apriori in the first step. Thus, in the current implementation we limit ourselves to just one, fixed quantifier (by default it is a counterpart of the ?more than 50%? phrase).

Moreover, for obvious reasons, we take into account only such subsets of regular items that:  all refer to different attributes, and there is enough number of them to make quantification  Thus, we will, e.g., neither construct a 1-itemset of the form ?most (salary IS high, salary IS  low, ...r nor ?most (salary IS high, age IS  high).

Having the 1-itemsets of the form (9) constructed we calculate their support. We assume that, informally speaking, no row supports two different fuzzy values for the same attribute. Then, the support for Ai IS (t;lv...v&) is just the sum of supports for Ai IS Ai, /=I, ..., k; that we calculated earlier.

Now I-itemsets of the form (10) are constructed. They may use both regular l-itemsets as well as (9) 1-itemsets, e.g.,  meaningful  ?Most (AI IS (filv...vfiJ, A2 Ish, ...)? are allowed. Now, the support for (10) I-itemsets is calculated. However, due to the use of AprioriTID version of the algorithm another full scan of the database is not needed. During the first scan we have recorded in some data structures the IDS of rows supporting particular regular l-itemsets and now it is enough to operate on this structures. Obviously, it does increase memory complexity of the algorithm.

Then, the algorithm proceeds as usual [I]  generating and evaluating k-itemsets for k=2,3,. . .. The only additional effort is needed to guarantee that no itemset produced twice refers to the same attribute, e.g., a 2-itemset ?salary IS high AND salary IS medium?? have to be excluded. Finally, all found frequent itemsets are taken into account when producing association rules of the confidence at least equal to the required value (minconf).

We deal with real valued attributes. Thus, following previously mentioned approaches, for each such an attribute and each defined for it fuzzy value we introduce a new items which may be treated as binary, i.e., appearing in a row or not..

Thus, practically only a limited number of fuzzy values per attribute (say 3) leads to computationally tractable mining tasks. For example, taking into account the attribute SALARY may yield the following items: SALARY IS low, SALARY IS medium and SALARY IS high., A row supports such an item, e.g.,, SALARY IS low, if the value of the attribute SALARY in this row best matches the fuzzy value ?low? or, in other words, this value?s membership degree is highest for a fuzzy set representing ?low? in comparison to fuzzy sets representing ?medium? and ?high?. In our current approach we use crisp support, i.e., we select (exactly one) best matching fuzzy value (we possibly use random tie breaking mechanism) and say it is fully supported by given row. Another option is to allow ?support to a degree? from [0, 11.

The implementation of the linguistic summaries mining via extended fuzzy association rules may be summed up as follows:  -Selection of the attributes and fuzzy values Normally, the use of all attributes for rules construction  is not recommended. Thus, the user has to choose the attributes to be used. Moreover, they should he accompanied with some meaningful description to be used in the rule presentation. In the current implementation, the user simply builds a query referring to all attributes, which should be taken into account. The same applies to the selection of fuzzy values.

Then. the user initiates the data summarization, sets the parameters (minsup, minconf and other discussed above) and the system automatically performs the rest of steps.

Construction of the items For each pair - of selected attributes and fuzzy values -  the system creates an item, as described earlier.

&p-& Creation of the data set and starting external application for fuzzy linguistic rules mining  The items constructed in the previous step are numbered. Then, the data set is produced describing each     row with numbers of items supported by it. As discussed earlier an attribute value in a row may supports exactly one item. The calculations are supported by fuzzy querying module. When the data set is ready an extemal application is started with this data set given on input.

&J& Calculation of the support for the regular 1- itemsets  Extemal application reads input data set and immediately calculates support for the regular 1-itemsets.

It also records for each I-itemset numbers (Ds) of rows supporting it.

Construction of 1-itemsets of type (9) and calculation of their support  Only regular 1-itemsets of the support higher than a user-specified threshold are taken into account. Number of produced I-itemsets of this type for given attribute depends on the number of fuzzy values defined for it. The support is obtained by summing up the support of constituent reular I-itemsets. All new 1-itemsets are numbered according to a specific convention.

Pruning of the set of 1-itemsets All itemsets with the support lower than the support  threshold (minsup) are discarded. Additionally, also itemsets with the support higher than another threshold, an item omit threshold are discarded since items present in almost all records contribute nothing interesting to the produced rules.

Construction of 1-itemsets of type (lo), calculation of their support and pruning  Both regular and l-itemsets added in the Step 5 are considered; we refer to them jointly as simple 1-itemsets.

Produced I-itemsets are identified with lists of constituent simple 1-itemsets. The lists are ordered lexicographically what makes the process of generation more efficient. Support is computed for generated itemsets and those below minsup threshold are dropped.

All itemsets produced so far and passing pruning form now the collection of l-itemsets.

SETk=2  Generate k-itemsets  They are generated from frequent (k-1)-itemsets as in AprioriTid. Pairs of frequent (k-1) itemsets of the form A I / \ A A Z ~ . . . / \ A ~ ~ ~  and BlhB>~. . .hBk . , .  where A,=& for i=l,..,k-2 are sought. Then, the new k-itemset of the form A I / \ A Z ~ . . . / \ A ~ . I ~ ~ . l  is generated. In the original algorithm, the rules so generated are additionally tested and possibly eliminated before Step 7. On the other hand, we add another k-itemset generation limitation, namely items Abl and have to correspond to different original attributes. This requirement is obvious if items Atl and Bk., are regular. Otherwise, identifying an item (9) or (IO) with a list (set) of attributes referred to within it we require that the intersection of these sets is empty.

&@Calculate support for all k-itemsets  The calculation is based on the recorded numbers (ID?S) of rows supporting particular (k-1)-itemsets. The similar data on the supporting rows is produced for k-itemsets.

Pruning of the set of k-itemsets (as in Step 6)  As the result we obtain the frequent k-itemsets.

IF the set of k-itemsets is void THEN GOT0 Step 11.

SET k =  k +  1; GOTO Step 8.

Generate rules from frequent I-itemsets, l=l,..,k-1 and output them to the file. An external application completes its work.

&&2 Display the results The module of FQUERY for Access regains control, reads the results of the external application, decodes numbers of the items comprising produced rules and displays results in a form readable for the user.

The number of produced rules is usually huge. Some counter-measures have to be undertaken as, e.g., approaches to concise association rules representation, see, e.g.. [IS]. We adopted the following pruning scheme. A rule R1 is pruned if there exists another rule R2 such that the three conditions are met simultaneously: (1) the antecedent of R2 is a subset of the antecedent of R1, (2) the consequent of R1 is a subset of the consequent R2, (3) the confidence of R2 is not less than the confidence of R1. This leads to a substantial, lossless reduction of the number of rules.



V. CONCLUDING REMARKS  We presented the use of fuzzy linguistic summaries as a natural and human consistent tool for data mining. We indicated that Zadehs [31] concept of a protoform, and a hierarchy of protoforms, may conveniently be used to present various linguistic summaries.

We extended our previous work on the application of association rules mining technique for generation of linguistic summaries. We proposed more sophisticated forms of fuzzy association rules. Their mining becomes even more complex.

These applies especially to the concept of linguistically aggregated elementary items (10). Similar concept has been recently proposed by other authors [27]. Their AND-OR taxonomies share some expressive power as well as computational complexity with our proposal. The latter is addressed in [27] with a strong restrictions on the allowed combinations of items in itemsets. Both approaches are also in some sense ?opposite?: in [27] a sophisticated taxonomy is assumed (as in other classical approaches to linguistic association rules mining, cf. [24]) while in our it may be to some, limited, extent, recovered.

We show that data mining tools dealt with in the paper, based on linguistic summaries, can be implemented through     our FQUERY for Access, a fuzzy querying interface (cf.

Kacprzyk and Zadroiny [ l l ,  161).

