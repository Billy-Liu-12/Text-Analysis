A Realtime Interactive Visualization System for Knowledge Transfer from

Abstract?This work demonstrates a system for visualizing the intra-user and inter-user social media from a big data. By integrating a projector as the output, a depth camera and mobile devices as the input, analyzing the social media information belonging to the login users, the proposed visualization system displays the intra/inter-user data in a social network, providing by a community-contributed media. The contribution of this paper is trifold: (a) a realtime analyzing and visualization system from a social media, (b) a user is allowed to interact with the system using a Kinect camera and a mobile device, and (c) the intra/inter user media with knowledge transfer concept is generated based on the analysis for the social media in a big data.



I. INTRODUCTION  Social media has become more and more popular nowadays, since mobile devices, e.g. smart phones and tablet PCs, can access social network easily from many places. Therefore, social media has become an important research topic in many fields. To name a few, a journalist can determine the value of a news according to the information provided social members [1]. In addition, the future trend of a market can be predicted based on the data provided by social members [2]. When a disaster happened, the survivors can be relieved by texts provided the social members [3]. Therefore, the knowledge is transferred from the knowledge devoting by the social members.

When the mobile devices involve into the social media, the location of each individual in a social network can be obtained, due to the built-in geolocation sensor on the mobile devices, causing the location-based service (LBS) more and more popular. To name a few, GeoLife Zheng et al. [4] used location and trajectories among users to share the preferred location spots to the members in a social network, and the most visited locations would be automatically recommended by the system, according to the knowledge transferring result from the data analyzed from the social network. On the other hand, So- cialTelescope [5] analyzed the preferences, recommendations, and member interactions for a geolocation of a spot, based on the discussion from a social network. Besides analyzing textual data from Twitter or Facebook, the image data analyzed  from Flickr or Picasa can reveal the most famous place and give travel suggestions, according to the data provided by social members [6], [7], [8]. Therefore, the textual/visual data knowledge can be transferred from analyzing the data provided by the members in a social network.

Despite the knowledge transferring from the social media is developed in different fields, to our knowledge, it is lack of a realtime social media integrating and visualization system for a public usage. Therefore, in this paper, we propose a realtime visualization system for knowledge transfer from social media in a big data, providing a virtual reality environment for users to interact with the big data in a social network. The contributions of this paper is trifold: (a) a realtime social media analyzing and visualization system, (b) a user can interactively select a metaphor using a Kinect camera and the user identity can be revealed according to the login from a mobile device to reveal the user-centric media, e.g., photos, videos, and (c) the inter-user social media generating, e.g., panorama image from different places to the same target, and weather/geolocation/route suggestions from social members, according to the knowledge transfer concept.

The organization of the paper is described as follows. In Section II, our system architecture with three main components is described; in Section IV, the user interface of the proposed system is shown; in Section V, the intra/intra-user social media visualization is given; Section VI shows the experimental results, and the conclusion is drawn in Section VII.



II. SYSTEM ARCHITECTURE  The proposed realtime interactive visualization system con- sists of three major parts, as depicted in Fig. 1. First, analy- sis/visualization, as shown in the right-bottom part, to execute the realtime social media analyzing and visualization from the server and display to a user. The data collected from the cloud and the social media are sent into the server for analyzing. In addition, the realtime rendering for the 3D visual effect is also implemented at the server. Second, the user interaction to the sensor is depicted in the left-bottom part, allowing users to use the gestures of his/her body to control the metaphors or avatars     Fig. 1. System architecture  in the virtual reality environment using a Kinect camera. In addition, a user can login into our system using a mobile device to reveal the user identity. Finally, the intra/inter-user social media data is shown in the top of Fig. 1. The cloud service, e.g., weather/geolocation/route, and social media, e.g., the photo/video of a user in Facebook and the community contributed media collections are distributed in the cloud. The proposed system can connect to the cloud to crawl the data and analyze the social media data for further visualization.

The details about the three parts of the proposed system will be describe in the following sections.



III. ANALYSIS/VISUALIZATION  In the proposed visualization system, on the server end, once a user login into a social media service, e.g., Facebook, the connection from the user to the members in the social media will be automatically analyzed by the server. The the graph of the partnership of a social media is analyzed by the algorithm provided by [9]. In addition, to visualize the partnership of the links and nodes in a graph of a social media, NodeXL [10] is adopted in the proposed system to generate the visual effect.

Based on the results provided by NodeXL, in the proposed system, the visualized connections among the partnership of a social media can be shown on the proposed intra/inter social media applications.



IV. USER INTERACTION  A. A Kinect Camera for Human Subject Tracking  A Kinect [11] camera is utilized to track a user in the proposed system. The body, skeletons, and joints of a user in a 3D space can be tracked using Kinect software development kit (sdk)[12] in realtime, as shown in Fig. 3. The positions in a 3D space including: a user, a Kinect camera, a projector, and a screen, are shown in Fig. 4 (a). An avatar of the detected human subject is displayed on a screen in the visualization system, according to the joint tracking results. When a user moves in the space, the corresponding avatar of the members in the social network move with the detected user position in the VR 3D space on the screen. When there are multiple users using the system in the same field of view, as shown in Fig.

Fig. 2. The displayed virtual reality (VR) content.

Fig. 3. The obtained skeleton from Kinect sdk (top-left) and the displayed metaphor (bottom-right) in the proposed system.

2, the connections in the social network are displayed in the VR environment. For example, the users with purple skeleton (Mary Chen) and green skeleton (Joe Yang) in Fig. 2 have one common friend, named Mimi Tsai.

B. Mobile Device for User Identity Obtaining  In the proposed system, a user is allowed to login our system to reveal the identity of a user, as shown in Fig. 4 (b). Once a user login the system, the user identity can be recorded on the server. However, when there are multiple users login, the multiple user matching from the system to the user becomes a critical issue. In the system, we propose to fuse the signals from the sensor of the accelerator on a mobile device and the trigged signal of the hand joint from the Kinect camera for people identification in the system.

C. Signal Fusion from Heterogeneous Sensors  Given a user?s joint jt belonging to the holding hand for a mobile device at time t, tracked by Kinect sdk, and the signal from a mobile device?s accelerator at, according to the signal analysis both of the signals in a period of time, the dramatic changing for both of the signals represent that a user is shaking    Fig. 4. The user interactive devices: (a) Kinect depth camera, and (b) a mobile device.

the hand holding the mobile device. Therefore, a matching flag is determined by:  mt =  { 1, if both jt and at have local peaks ; 0, otherwise . (1)  According to Eq. (1), the user ID matching between the Kinect camera and the mobile device can be achieved in a multiple users situation.



V. INTRA/INTER-USER SOCIAL MEDIA DATA APPLICATIONS  In the proposed system, based on the social media analysis result and the signal fusion from heterogeneous sensors, a user in a field of view, holding a mobile device, the visualized results can be interactively displayed on a screen to a user, showing the inter/intra-user social media relationship and the related multimedia content at the same time.

A. Intra-User Social Media Data Visualization: User-centric Information  For the intra-user social media data visualization, in this paper, the Facebook API [13] is utilized to crawl the data in a social network belonging to a login user from the mobile device. The representative photos and recent posted videos of the user in the social network are grabbed and displayed on the screen, as shown in Fig. 5, representing the the user-centric information. The user in the system is allowed to switch to browse the photo/video belong to another member in the social network, and the meta data about a photo/video, as shown in the upper-right part of Fig. 5.

B. Inter-User Social Media Data Visualization  Based on the inter-user social media data crawled from Facebook API [13] providing the social media member list, the graph of a social network is visualized according to NodeXL [10]. According to Google map API [14], the geolocation captured from a mobile device belonging to a member in the social network can be displayed on the screen, and shows the way to a member of interest. In addition, the community contributed media can be generated according to the media provided by the members in a social network.

Fig. 5. The user-centric information: the photo and video of one of the member in a social network; the meta data of a video can be enlarged and displayed.

Fig. 6. The graph of a social network with corresponding weather and geolocation on the same map.

1) Geolocation/Weather of Social Members: When the member list can be obtained from a social network, e.g.

Facebook API [13], the geolocation can be obtained from the mobile devices of the members in the social network.

With the geolocation revealed by a GPS/AGPS services, the latitude/longitude values of a member can be sent from a member to the server. On the server side, by collecting the latitude/longitude values belonging to members, according to the Google Maps API [14], the relative positions of the mem- ber can be marked on the map. Meanwhile, the representative photos and the graph/links/nodes of the social network can be displayed on the screen, as shown in Fig. 6. Besides, according to the weather layer cloud service provided by Weather layer of Google Maps API [15], the corresponding weather at the position of a member in the social network can be displayed with the name of a member.

2) Route Suggestion to a Social Member: In the proposed system, when a users is willing to know the way to the member of interest in the social network, the user can select the member and switch to the route displaying mode. The    Fig. 7. The route planning results (the purple line) from one of the member to another, displaying the graph of a social network (pink lines) at the same time.

Google direction API [16] is applied to plan the route from the current user to the member of interest in the social network.

As shown in Fig. 7, the current user (Mary Chen) is located at point A in the bottom side, the member of interest (S.W.

Sun) is located at point B in the upper side, the proposed system can plan the route the path from point A to point B, according to Google direction API. In the visualization part, on the left hand side, the route and the turns information, can be displayed on the screen. Meanwhile, the graph of a social network is displayed at the same time. In addition, based on the representative photo and the name tag showing on the screen, a user can observe that a common friend (J.C. Lu, in the middle) of the both sides stays near the planned path.

The user (at point A) can make a choice to pick the friend up and keep going to meet the target friend (at point B) in the social network. The route suggestion of the proposed system transferred the knowledge from the geolocation analyzed from the social network.

3) Community-Contributed Media: A Panorama Image : By analyzing the photos provided by the member of a social network, a possible application is to generate a new media that the stand alone user?s media cannot provide. As shown in Fig. 8, when a user is capturing a photo to a building, the user cannot move to another position to capture the same building due to physical limitation, e.g., the new year?s eve of Time Square in New York with more than a million people, a community contributed photo can be generated according to the proposed system. In the proposed system, based on the image stitching algorithm provided by OpenCV [17], the panorama image can be generated by the images provided by the members in the social network. Therefore, the knowledge is transferred from the social media from analyzing a big data in a social network.



VI. EXPERIMENTAL RESULTS  In this paper, a realtime demo system is developed as a pro- totype, as shown in Fig. 9. The demo system is setup in a tech- art gallery for public usage in our university. The users are sat-  Fig. 8. The community-contributed photos to generate a panorama image to the same targeted object with a nearby geolocation.

Fig. 9. The realtime demo system as the prototype of the proposed system.

isfied with the proposed system, with the interesting, reliable, and interactive experiences. A demo video of the proposed system can be obtained from: http://youtu.be/HptLgn6hEMI  The property comparison among the proposed system and the representative existing popular social media services can be categoried into three perspectives, as described below. (1) social network relationship: Most of the existing social media services have the function to recommend friend lists to a user, but the only the proposed system can visualize the connection among users as a graph relationship in the user interface, as shown in Table 1. (2) location-based services: including the proposed system, the existing social media services utilize the GPS/APGS sensors of a device to reveal the location of a user to draw the location of a user on a map and the corre- sponding trajectories. However, only the proposed system can visualize the geolocation of a user with the weather and route information at the same time, as shown in Table 2. (3) social media data visualization, similar to Facebook and Google+, the proposed system can display the post/image/video/link in the user interface. However, the proposed system shows the map/weather/route suggestion in the same intergrated system.

In addition, the panorama image contributed by the users in the social network can be generated in the proposed system, as shown in Table 3.

TABLE I COMPARISONS FOR SOCIAL NETWORK RELATIONSHIP  Social network relationship Friend Recommendation Partnership Visualization  Proposed System No Yes Facebook Yes No Google+ Yes No Twitter Yes No Flickr Yes No Picasa No No GeoLife Yes No Social- Telescope No No  TABLE II COMPARISONS FOR LOCATION-BASED SERVICES (LBS)  Location-based service GPS/AGPS Content  Proposed System Yes Geolocation with map/weather/route sug- gestion  Facebook Yes Geolocation Google+ Yes Geolocation Twitter Yes Geolocation Flickr Yes Geolocation Picasa Yes Geolocation GeoLife Yes Geolocation with map/trajectories Social- Telescope Yes Geolocation with map/trajectories

VII. CONCLUSION  In this paper, we proposed an interactive visualization sys- tem for social media in a big data. We developed a prototype system for a realtime demo. There are three contribution points: (a) a realtime prototype system for user interaction and visualization, (b) a heterogeneous signal fusion from Kinect camera and mobile device to allow users to login the system to reveal the user-centric media, e.g., photos, videos, and (c) the knowledge transfer from the social media in a big data, pro- viding weather/geolocation/route suggestions/panorama image generating. In the future, the proposed system can adopt more media information provided by the members in the social network in the cloud.



VIII. ACKNOWLEDGEMENT  We would like to thank the National Science Council of the Republic of China (Taiwan) for financial support of this research under contract numbers NSC 101-2218-E-119-001 and NSC 102-2221-E-119-002.

