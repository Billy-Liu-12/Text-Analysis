MINING FREQUENT ITEMSETS WITH TOUGH CONSTRAINTS

Abstract: In order to efficiently sift the useful ones through a large  number of mined rules, the constraint-based mining is introduced. Two large clssses of constraints-monotone constraints and succinct constraints have been investigated.

However, the problem of frequent itemsets mining with tough constraints has not been solved because of the complexity of the constraints. In this paper, we propose two methods which use the order as the pre-proeess to solve this problem. The first method is to push the tough constraints deeply inside the candidate generation-and-test approach such as Apriori. The second is to combine the constraints with the the pattern- growth methods such as FP-tree.

Keywords: Data mining; Association rules; Frequent item-sets; Tough constraints  1 Introduction  Data mining is to efficiently discover interesting rules from large collections of data. The problem of mining association rules [1,2.31 have been the subject of numerous studies.

The standard frame of mining association rules is S - C(Support-Confidence). Firstly, we have to find the frequent item sets whose support is above preset min- support, then we calculate the ratio of the confidence. If the ratio is above the preset min-confidence, the rule is what we want to find. After determining the frequent item sets, the solution to calculate the confidence ratio is rather straightforward. So we focus on how to find the frequent itemsets efficiently.

However, frequent pattern mining often generates a very large number of frequent itemsets and rules. We have to sift through them to find the rules we are interested in. This is complicated and difficult work.

Recently, some researchers have proposed the frequent itemsets mining with constraints 14'. Using the constraints, we can put our focus on the part of the database where we want to mine, then find the useful rules.

The constraints that we often use can be sorted into three kinds through the assemble function: Distributive such as count, mount, max, min; Algebraic such as average, standard-deviation; Holistic such as median, mode.

From the property, the constraints can also be classified  into three kinds: Monotone include monotone and Anti- monotone, Succinct and Neither monotone nor succinct (Tough Constraint).

Monotone constraints have the property if the itemsets at the level m satisfy the constraints, the superset of the itemsets at the level m+l also satisfy the constraints. Anti- monotone constraints have the property if the itemsets at the level m don't satisfy the constraints, the superset of the itemsets at the level m+l also don't satisfy the constraints.

If we can explicitly and precisely generate all the itemsets satisfying the constraints, we call the constraints succinct constraints. However for the neither monotone nor succinct constraints, it i s  difficult to be put it into the usual algorithms, so we call it Tough constraints.

In paper [51, the researchers have already studied the frequent itemsets mining with monotone and succinct constraints. However toward the Tough constraints, he propose to convert it to weaker constraints. It cannot solve the problem completely.

In paper [61, the researchers have brought forward the notion: Convertible Constraints. They convert the tough constraints to monotone and succinct constraints through ordering the data at first. Let us introduce the concept of prefix. E.g., a is the prefix of ad and ad is the p ~ f i x  of adg.

Suppose we have the items <a,d,g,s,j,l> and set a=30, d=10, g=15, s=O, j=20,1=5, choose avg ( S )  25 as the constraint.

We can easily find the constraint is tough if the items are placed in this order.'But if we re-order the items in descendent order, the constraint has been converted to monotone. So we conclude that after careful pre-process such as re-order the items, tough constraints can he converted to monotone constraint.

There have been many algorithms developed for fast mining of frequent patterns, which can be classified into two categories. The first category is"candidate generation- and-test approach such as Apriori. The second category is pattern-growth methods such as FI-tree. In this paper, we will study how to use the algorithms that belongs to the two categories to solve the problem of mining frequent itemsets with Tough constraints.

2 Using the generation-and-test approach to mine frequent itemsets with Tough constraints  0-7803-7508-4/02/$17.00 a 0 0 2  IEEE   mailto:jialei7829@hotmail.com mailto:prq44@botmail.com mailto:zhangsongqian2002@hotmail.com    new=Generate( I-item seed.db):Select(new)  I  I Return target  Fig.].

new=Generate( Litem  filter and Select(new)  target+=Select(seed)+new  Return target 0 Figure 2 The classical gertcLauuLl-a,u-Lest approach is Apriori  Algorithm. When we use it to mine frequent itemsets with Tough constraints, we have two choice. Firstly, we can use the original Apriori Algorithm to mine the fresuent itemsets, then test,them with the constraints (Figurel). The other is to push the' Tough' constraints deeply into the Apriori Algorithm (Figure2). Beacause the Apriori Algorithm satisfies the @i-monotone property, we can convert the  Tough constraints at first, then it can combine with the Apriori Algorithm. If we use the first choice, we will mine a lot of useless frequent itemsets. In order to decrease the waste ratio and increase the efficiency, we choose the second one in this paper.

Suppose we have an m a y  of items: I=[a,b,c,d,e,f,g,h) and transaction databases (Table 2). .we assume the minSup=2 and set the number to the item (Table I ) .

Table 1 Item l a  / b  I C  I d  l e  I f  l g  I h Val 140 10 1-20 1 10 1-30 130 120 1-10  Table 2.

Transaction I Items in transaction 1  After ordering the item in value-descending order and test it with the minSup, we get the table 3. Suppose the Tough constraint is avg ( S I  3 2 5 .  After the order we find it has been converted to anti-monotone.

Table 3.

in transaction a,f,d,b,c   Level- 1 : The candidate 1-itemset satisfies avg ( S )  3 2 5  is a and  f. After the minSup test, we conclude the frequent itemsets satisfy the constraints at level-1 is are and f.

Level-2  According the Apriori Algorithm, af  must be the frequent itemsets. We also have to add the intersection of the frequent itemsets and the unfrequent itemsets at the previous level. Although g,d,b,c and e are not frequent itemset at level-I, the intersection between them and a or f may be the frequent one at level-2. After generating the intersection, we can use the anti-monotone property when we test them with the constraint.

We find ag and ad satisfy the constraint, but ab doesn't.

So we don't need to consider ac and ae, they cannot be frequent one according the anti-monotone property. We also find fg satisfies and fd doesn't, so we stop the generation.

After the minSnp test, We conclude the frequent itemsets satisfy the constraints at level-2 are ad and fg.

Level-3:     According to the method we propose when we find the frequent itemsets at level-2, we can find afd is what we want to find.

Finally, we elicit the frequent itemsets in table 3 which satisfy the constraints and pre-set minSup are a,f,af,ad,fg and afd.

This idea can also be used on the Tough constraints can be converted to monotone constraint.

Thus we propose the TCA Algorithm (Tough Constraint based Apriori Algorithm).

Input: T[l](After order), MinSup, Tough Constraint.

Output: frequent itemsets.

1) Ll=[large 1-itemsets);  2 )  L1=l L1 n Constraintl:  TCA Algorithm: - -  4 )  T[Z]=get_filtered(T[l], L1); 5 )  for(k=Z;Lk-l# Q;k++)  Ck'=apriori_gen(Lk- 1); 6) 7) c k = ( L k - i ) n ( L i ) ;  if(Tough Constraint is anti-monotone after order)  -  8) 9) Ck=test C k  according to the anti-monotone  IO) 9) IO) Ck=Ck'+Ck; 13) forall transactions tE T[21 14) Ct=subset(Ck,t); 15) forall candidates CE Ct do 16) c.count++; 17) end 18) Lk=(c? Cklc.count2MinSup); 19) end  propew if(Tougb Constraint is monotone after order)  Ck=test C k  according to the monotone property;  AosweF U kLk;  3 Using the pattern-growth approach to mine frequent itemsets with Tough constraints  The principle of the pattern-growth approach is that we don't have to generate the candidate itemsets. We can use structure such as tree '71 or some hyper-structure to mine the frequent itemsets. We can also push the constraint deep into this approach. This method is efficient not only because we don't generate the candidate frequent itemstes but also that we can make full use of the anti-monotone property when we generate the frequent itemsets with the constraints. But we need more pre-process.

We also use the same data array and constraints that we use in section 2. After re-order, we can find b cannot be in the frequent itemsets because the average between it and the max one a doesn't satisfy the constraints. Accordint to the anti-monotone property, c and e are all be deleted when we constmct the pattern-growth stmcture.

According to FP-tree Algorithm 17], we can get the frequent itemsets through the FP-tree (figure3).

n  zI( g , , , , ,z f 2  g:2    g,,,g--g,,,g , c:l _ _  c: 1 e: 1 e: 1  N. I  We use the real line if they are in the same embranchment and the broken line for the same item in the different embranchment. We need not to consider the pattern under the bold real line.

We can get the conditional FP-tree (Table 4) and the frequent itemsets (Table 5).

Table 4.

I Item I conditional pattern I conditional FP- I  base tree d ( (  a:2,f2),( f l,g: I]') ( ( a:2,f3) )Id  f { [a:2))lf f2J) ( ( f 2 )  Jlg  m  Table 5.

I length [ Frequent-itemsets ,. I  A m  At last, we can test with the constraint avg (2.) 2 2 5 .

We get the frequent itemsets satisfy the Tough constraint and the minSup are a,f,af,ad,afd,fg. We can find after the careful pre-process, the Waste ratio is small.

4 Concksions  It is a complicated and difficult work to sift the useful knowledge through a very large number of frequent itemsets and rules. So we introduce to mine the frequent itemsets with constraints. It will help us to focus on the part of the databases where we are interested. Some researchers have studied the frequent itemsets mining with monotone and succinct constraints. However toward the Tough constraints, they haven't solved it completely. In this paper, we use the generation-and-test approach and the pattern- growth approach to solve the puzzle.

