Vertical Fragmentation of Data warehouses   using the FP-Max Algorithm

Abstract?Vertical partitioning is a technique used to reduce disk access, when executing a given set of queries, by minimizing the access to irrelevant instance variables. In this paper we use the FP- Max data mining algorithm, for extracting frequent item set attributes. The frequently accessed instance variables are, then, grouped as vertical class fragments. We study the application of this approach to sets of queries on large databases and data warehouses. We used two benchmarks with various minimum support levels and we compare our results with the results of the approach using the Apriori data mining technique. The partitioning solution obtained produces an improvement of 14% for large data bases and 19% for data warehouse compared to a solution without partitioning.

Keywords- database; data warehouse; vertical partitioning; frequent item set; data mining;

I. INTRODUCTION Vertical partitioning (or fragmentation) is a design  technique for reducing the number of disk accesses needed to execute a query by minimizing the number of irrelevant instance variables accessed. This can be achieved by using a data mining technique for extracting frequent item sets of attributes which are then grouped in vertical class fragments.

The complexity of large database models makes the problem of vertical partitioning in large DBs very challenging. Gorla and Betty have used the Apriori algorithm [1] to extract frequently used attributes to obtain vertical partitioning schemas. We chose in our work to use the FP-Max algorithm as it produces less frequent item sets, in general, since it focuses on the maximal ones only. To compare the two approaches, we used standard database workload on large database and on data warehouses. We will start by a brief overview of related work to vertical database partitioning, in general, and to the use of data mining in vertical partitioning in particular.



II. RELATED WORK Vertical partitioning is the process that divides a relation  into sub-relations containing subsets of the original attributes.

The preliminary ideas of vertical class partitioning for large DBs were developed in [2] [5] [11] [13] [14], for Data Warehouse Design, in [7] [10], and for Object Oriented Database design, in [10].

Most of the vertical fragmentation algorithms start with the construction of an attribute affinity matrix, from the attribute usage matrix, in which the element (i,j) represents the total number of accesses of transactions referencing both attributes i and j. An iterative binary partitioning method has been used in [10], which is based on clustering the attributes, first, and then applying empirical objective functions or mathematical cost functions to perform the fragmentation.

Cornell and Yu in [5] exploit an optimal binary-partitioning algorithm to achieve vertical partitioning, which is iteratively applied to obtain more partitions. The study uses the number of data accesses to evaluate partitions. Song and Gorla in [14] apply genetic algorithms to obtain solutions for vertical partitions and access paths simultaneously. They also use the number of disk accesses as the partitioning evaluation criterion. Ng et al in [13] propose genetic-algorithm based solution to the combined problem of vertical partitioning and tuple clustering in relational databases.

Partitioning has been applied in data warehouses in order to optimize OLAP queries by designing parallel database clusters [8] and to generate ROLAP data cubes based on optimized data partitioning techniques [3]. Methods for selecting and materializing horizontally partitioned data warehouse views have been achieved in order to speed up the query response time and reduce data warehouse maintenance costs [6].

A. Related work using data mining technics Data mining is a process of extracting implicit information  from databases [11]. Data mining techniques have proven effective for the selection of data structures that help to improve the performance of a management system databases, such as materialized views and index selection. but, few studies exploit data mining techniques for vertical fragmentation.

Darabant and Campan in [6] proposed a method of horizontal partitioning of a distributed object-oriented database based on a k-means classification [12]. This technique classes instance objects in fragments, taking into account the relationships among classes (aggregation, associations and links between methods) and similar objects groups based on conditions extracted from user queries. For this, the authors propose a similarity function between objects calculated according to different metrics and methods for the selection of an initial distribution of classes according to the semantics of queries.

Fiolet in [8] proposed a classification algorithm for parallel requests to gradually break down a database and distribute the fragments on a grid. This algorithm is inspired by the sequential clustering algorithm CLIQUE which classifies the data by projection. The fragments obtained by classification can improve the treatment of parallel requests and minimize the cost of data exchange.

Gorla and Betty in [11] analyzed the association rules for the vertical fragmentation of a relational database. They argue that the system performance can be optimized by reducing the number of accesses to relevant data for a query. For this, they adapted the Apriori algorithm [1] to search for frequent attributes in databases workloads.

The literature on fragmentation approaches based on data mining suggest that search techniques can be used for vertical and horizontal fragmentation, using association rules [11] and algorithms for classification [6], respectively. In this paper we expose an approach base on the FP-Max algorithm, for extracting frequent Itemsets of attributes to devise a partitioning schema.



III. THE PROPOSED APPROACH Our approach adapts the algorithm proposed in [11] in  which the APRIORI algorithm is replaced by the  FP-max which proves to be more efficient in reducing the number of partitioning schemes. the approach consists of extracting frequent itemsets, then generating data partitions, and finally, selecting the most promising partitioning schema. The approach was tested with large databases in [18] and will be tested in this paper with both a large database and a data warehouse.

A. Extracting frequent Item sets frequent itemsets are the combinations of attributes that  have a support greater than a predefined minimum support.

This frequent itemsets can be discovered by using the FP-Max algorithm [17]. The support of candidate represents the frequency of queries that contain the candidate set. The inputs for this step are sets of database transactions (retrievals and updates) T1...Tm, the transaction frequencies, Freq1...Freqm, and a predetermined support level min_supp. The outputs of this module are Itemsets F1... Fi.

B. Generating Vertical Partitions The generated itemsets F1?Fi, are used to determine all the  possible partition schemas. A partitioning schema is constructed so as its partitions are disjoint. This module uses the frequent Itemsets F1?Fi as input and returns partitioning schemes P1...Ps.

C. Selecting  the  optimal  partitioning  scheme The  database  operating  cost  for  a partitioning schema P  is computed for each transaction, using the formula in (1). The partitioning scheme with the lowest database operating cost is then selected. The inputs for this module are partitioning schemes P1...Ps and transaction sets T1...Tm and the output is the optimal partitioning schema.



IV. COST FORMULA The amount of data transferred and the number of disk  accesses are used in the most commonly used methods of evaluating partitioning schemas [4] [5] [9] [11]. In our case, we do not include cost of index access and storage cost. We use the blocks estimate used in [11]   as the basis for cost of query processing, in line with previous studies. If there are n records divided into m blocks and if k records, satisfying a query, are distributed uniformly among the m blocks, then  the  number of blocks accessed for  the query is equal to  m(1 ? (1 - 1/m)k). In the partitioned database, we apply this formula for each Segmentq accessed by the query q. Thus, the cost of processing a (retrieval) query q is estimated by:  ( )( )( ) ( )( )( )?? ?  ? ? ? ?  ? ??+???  ?  ? ? ? ?  ? ??? ?  =  11.01/111  q  Segment  i  k iiq SegmentMMfreq  q q        (1)  Where: freqq = Frequency of query q Segmentqj = Number of partition j required by the query.

Mi = Number of blocks to be accessed in partition i.

Mi= (T*Li/BS) kq=  Number of tuples satisfying a query q.

T =  Total number of tuples Li = Size of a partition i in bytes BS= Block Size

V. EXPERIMENTAL TESTS In this experiment, we aim at comparing our approach  using maximal frequent itemsets (denoted FPMAX-VP)  with the approach using Apriori (denoted APRIORI-VP) [11]. The algorithms, mentioned earlier, were implemented in JAVA and run on an Intel Core 2 Duo PC with 2.00 Go of RAM. The frequent itemsets were generated by the implementation of the FP-max algorithm used in [17]. Experiments have been conducted using the proposed approach with two benchmarks.

The first experiment uses ADULT database with 15 attributes and 48842 tuples[16]. The second experiment uses TPC-H data warehouse with 15 attributes and 6000000 tuples [15].

A. First Experiment (with ADULT Dataset) The ADULT database description is given in Table I. The  block size of Adults DB [16] is assumed to be 4K. For ease of presentation, the attributes are labelled as A through to O.

TABLE I.  ADULT DATABASE DESCRIPTION  Attribute Size (Bytes) A Age 1 B WorkClass 16 C Final-weight 4 D Education 12 E Education-num 1 F Marital-Sta-tus 21 G Occupation 17 H Relationship 14 I Race 18 J Sex 6 K Capital-gain 3     L Capital-loss 2 M Hours-per-week 1 N Native-coun-try 26 O Class 5  The results of partitioning schemas for minimum support levels of 20%, 30%, 40%, 50% and 60% are presented in Table II and Table IV. As  can  be  seen in  Table 4,  FPMAX-VP yields a better partitioning schema in almost all cases (Figure 1). The best schema is obtained for a minimum support level of 40%, which produces an improvement of 13,60% compared to a non partitioned solution where as APRIORI-VP achieves only 11,80%.

TABLE II.  NUMBER OF GENERATED PARTITIONING SCHEMA  Number of generated partitioning schema Threshold FPMAX-VP APRIORI-VP  20 % 35 83 30 % 17 37 40 % 4 8 50 % 1 2 60 % 1 2  TABLE III.  COST REDUCING FOR VARIOUS THRESHOLD  Reduction of best partitioning schema Threshold FPMAX-VP APRIORI-VP  20 % 8,97 5,34 30 % 11,70 9,50 40 % 13,60 11,80 50 % 9,50 9,50 60 % 9,50 8,22      Figure 1.  Cost reduction ADULT database  B. Second Experiment (with TPC-H Data warehouse) The TPC-H data warehouse description is given in Table

IV. The block size of TPC-H is assumed to be 5Mo [15]. For ease of presentation, the attributes are labelled as A through to O.

TABLE IV.  TPC-H DATA WAREHOUSE DESCRIPTION  Attribute Type A ORDER_KEY Char B PART_KEY Char  C SUPP_KEY Char D LINENUMBER Integer E QUANTITY Integer F EXTENDEDPRICE Integer G DISCOUNT Integer H RETURNFLAG Integer I LINESTATUS Integer J SHIPDATE Date K COMMITDATE Date L RECEIPTDATE Date M SHIPNSTRUCT Char N SHIPMODE Char O COMMENT Char  The results of partitioning schemas for minimum support levels of 20%, 30%, 40%, 50% and 60% are presented in Table V and Table VI. As  in the first experiment,  FPMAX-VP yields a better partitioning schema in almost all cases (Figure 2). The best schema is also obtained for a minimum support level of 40%, which produces an improvement of 19% compared to a non partitioned solution where as APRIORI-VP achieves only 16,96%.

TABLE V.  NUMBER OF GENERATED PARTITIONING SCHEMA  Number of generated partitioning schema Threshold FPMAX-VP APRIORI-VP  20 % 5 8 30 % 3 3 40 % 2 3 50 % 1 2 60 % 1 1  TABLE VI.  COST REDUCING FOR VARIOUS THRESHOLD  Reduction of best partitioning schema Threshold FPMAX-VP APRIORI-VP  20 % 13.72 11.92 30 % 15.24 13.09 40 % 19.00 16,96 50 % 10.85 10.85 60 % 10,85 8,33      Figure 2.  Cost reduction ADULT database

VI. DISCUSSION The cost reduction obtained for different values of the  threshold for ADULT database and TPC-H data warehouse are plotted, respectively, in Figure 1 and Figure 2. The results we obtained show that the approach based on the FP-MAX algorithm yields better performances then that based on the APRIORI algorithm in all almost all cases.  As we can see in Figures 1 and 2 the best reduction in the cost is obtained for a threshold   of   40% in for both  datasets.  The FPMAX-VP approach yields better cost reductions than APRIORI-VP because these latter produces more fragments.  Hence, at workload execution, queries must access many fragments which increases reconstruction costs.



VII. CONCLUSION We have presented, in this paper, an approach that handles  the vertical fragmentation problem using the FP-max algorithm for extracting frequent itemsets which are then used to generate partitioning schemas. Implementation results have shown that our approach FPMAX-VP produces good performance in terms of the number of disk accesses as compared with APRIORI- VP. The approach exposed in this paper can be extended in several directions. It can be extended to the case of other physical design techniques, such as mixed fragmentation. On the other hand, the selection of the best partitioning schema depends on the cost function used. Other cost functions incorporating more parameters can be explored. Finally, our aim is to compare different approaches using the same cost model to evaluate the generated partitioning schema, and then integrate these approaches in one tool that will enable administrators in their management task of large datasets.

