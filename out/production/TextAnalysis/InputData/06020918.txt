Hiding Sequential Patterns Using FP Growth  Technique

Abstract--Data mining deak with discovering useful and  unknown information from databases. Databases may contain  some sensitive information. This information need to be hidden from outside world, i.e. when we extract useful information, sensitive information should not be leaked. To deal with such situation, privacy preservation data mining comes into play. The aim of privacy preservation is to hide sensitive information while extracting information from databases. Privacy preservation data mining has been applied in the context of association rules and mining frequent item  sets. In this paper we propose a scheme to hide sensitive sequential patterns. Our approach is based on FP Growth technique. We then apply anti-monotone and monotone constraints on FP tree to hide sensitive sequential patterns.

Kqwords------data mining; privacy preserving data mining  (PPDM); sequential pattern mining (SPM); FP growth; anti? monotone; monotone.



I. INTRODUCTION  Data mining is the process which is used to extract information from large databases. The authors in [1-2] also refer to different terms used for data mining e.g.

knowledge extraction, data archaeology and pattern analysis etc. Some people view data mining as knowledge discovery from databases while the others consider it as an essential step for the process of knowledge discovery. Data mining tasks can be divided into (1) Predictive; (2) Descriptive. In predictive tasks we predict the class label of the new instance. Descriptive tasks specifY the general characteristics of the instances. The applications include in it are medical data, spatial and multimedia databases, time stream data, temporal databases and sequence databases etc.

When we extract useful information from large repositories of data, there is a privacy threat concerned with it. Therefore the importance of privacy preservation becomes prominent. Clifton et. al [3] has shown the importance of privacy preservation with a simple example.

The authors have taken the example of a super market. The super market has two milk suppliers A and B. Suppose the super market releases the transaction database. There is good enough chance that supplier B could come to know about the association rules of supplier A. Supplier B could run a discount scheme on A's association rules. Gradually the sales of A would decrease and than of B. This scenario clearly states that sensitive information should not be leaked out to the outer world.

The work carried out in [3-4] also highlights the importance of privacy preservation. The authors in their work state, with the increase in network data the privacy   of data becomes an undeniable fact. In [4] the primary question was raised, "since the primary task of data mining is the development of models about aggregated data, can we develop accurate models without access to precise information of individual records?"  Sequential pattern mining deals with sequence data The problem of mining sequential patterns was first introduced by Agrawal et.al [5]. An example of sequential pattern is that a customer first buys computer, then printer and then scanner. It is obvious that the items bought have some sequence. The sequence is not simple items but a set of items. The sequence data has events that took place at different times. These events have order as shown in sequence S (ele2e3 ..... t;,). Sequence S represents that el took place before e2; ? takes place e3 and so on. An item set represents non empty set of items.

Sequential patterns are closely related to association rule mining. The difference between sequential patterns and association rule is that the former has order while the later does not. In association rules, we find which products are bought together while in sequential pattern mining we find out subsequent purchases made after the purchase of a particular item. Sequential patterns have its applications in web usage mining (WUM), customer purchases, gene and DNA sequences, and earthquake etc.

Privacy preservation of sequential patterns is equally as important as association rules. Sensitive sequential patterns should be hidden from the outer world so that businesses can grow and the gain trust among their customers. The area of privacy preservation in sequential patterns is largely unexplored. Therefore, we propose a scheme which is based on FP growth approach [6]. We would apply anti monotone and monotone constraints for hiding sensitive sequential patterns. In this paper, we surmount the problems faced in [7] where matching set technique is used.

To overcome those problems, we propose FP growth technique and apply anti- monotone and monotone constraint to hide sensitive sequential patterns.

The rest of the paper is organized as follows: Section II presents the related work. Section III describes the problem statement. Section IV describes the proposed approach.

Section V presents the conclusion and future work.



II. RELATED WORK  There are many approaches for preserving privacy of sequential patterns. Osman Abul et.al [7] gave a formal definition to sequence hiding problem. They provided two contributions: (1) they shifted the attention of people from the typical association rules mining to sequence data;     (2) they provided the NP-hardness of hiding sequential patterns.

Their approach for hiding sensitive sequential patterns is based on matching set. From matching set size they identify the position in transaction for sanitization. They first compute the matching set size for every transaction of the database then sort the database in decreasing order of matching set size. The transactions which satisfy the threshold are considered for sanitization. They repeat this process until there are no matches found i.e. matching set size become empty. They also discussed possible extensions of their work e.g. to frequent item sets and saptio-temporal sequential patterns.

The main problem with the approach of the authors [7], is the computation of matching set size. This computation takes exponential time in worst case scenario. For large datasets the main problem encountered by this approach is efficiency.

Osman Abul et.al extended their idea to sanitize the spatio-temporal locations in [8]. They have used the same concept of matching set to hide sensitive trajectories which are also presented in [8]. The problem is formulated as background network. In a background network, nodes represent the spatio-temporal locations and edges represent the paths. Basically, they hide these paths or trajectories.

A multi objective scheme is presented for hiding sensitive sequential pattern in [9]. The authors analyze the sequences by constructing candidate tree. The candidate tree contains the sensitive items which are found in transaction. The first level of the tree contains length-l candidate solutions, and subsequent levels contain length-2, length-3 etc. candidate solutions. For generating candidate solutions, the authors suggest that most of the sensitive patterns should be hidden with less distortions and little effect on non-sensitive patterns. To achieve the above mentioned situations, they provide a weighted summation called objective function. For every node in the candidate tree, an objective function is calculated. The purpose of this function is to choose the best candidate solution for a transaction. In the same way the authors calculate the best solutions for every transaction, and at the end an overall best solution is determined. The overall best solution is then applied on the whole database for sanitizing the database. The authors state that the original database and released database should be as similar as possible.

Amruta Mhatre et.al [10], presented an approach of inserting fake elements into transactions for hiding sequential patterns. The technique used by authors is somewhat similar to data perturbation. They applied this approach at pre-processing level i.e. before data is available for data miner for mining purposes. For implementing the approach, authors maintain element bank and inserting elements in transactions. This element bank consists of fake elements which are to be inserted into transactions. To recover the original patterns back there has to be a balance between the numbers of fake elements being inserted. To achieve sanitization, the authors maintain a counter which increment by one when  a fake element is inserted However, no comparison with other techniques has been discussed in this paper.

Another set of approaches for hiding sequential patterns is secure two party computations [11-12]. In [11] approach is applied on two party scenarios while in [12] it is applied on multi party scenario. The authors have used homomorphic key encryption technique to achieve privacy of sequential patterns. The problem addressed is collaborative sequential pattern mining of two parties.

Both parties have vertically partitioned datasets Dl and D2. The approach first sorts the databases, find sequential patterns by using apriori algorithm and then applying homomorphic encryption. Homomorphic encryption generates a key pair for encrypting and decrypting of the data One site generates the key pair which encrypts the data and then sends the key pair to other site. The second site then encrypts and decrypts its data There is no need for the involvement of the third site for privacy preserving. Both the parties can keep their private data hidden from the outside world by using homomorhpic encryption key. However the authors have not given any example of dataset on which they have applied the approach. No results have been discussed regarding the effectiveness of the approach.

To achieve privacy preservation of sequential patterns, some data modification techniques have been used. The major techniques include data swapping, data randomization and data perturbation. In [13] data randomization technique is used for hiding sensitive patterns. Data randomization refers to adding some fake items to patterns in transactions. The authors have used h as a factor to keep track of the number of items inserted in transactions. The authors state that the bigger the value of h the better results of hiding would be produced. They have adapted the Prefix Span algorithm and proposed privacy preserving sequential mining (PPSpan) algorithm.

The algorithm is given database, minimum support and the factor h as input. The output is the released database with sensitive information hidden. Another approach from data modification category is used in [14]. The authors used data perturbation technique for achieving privacy preservation of sequential patterns. Data perturbation is somewhat similar to data randomization technique. In this technique the data is distorted i.e. noisy items are added to sequential patterns. In randomization the order of items in transaction is changed while in data perturbation noisy items are added to transactions. To be able to retrieve the original patterns from the noisy data, there should be a mechanism which would keep track of the number of items inserted in transaction. The authors in [14] have used a factor h for keeping the track of the noisy items. They insert noisy items by the h factor in transactions to make the data perturbed and to retrieve the original patterns back. They have adopted the PrefixSpan algorithm and propose privacy preserving sequential patterns (PPSpan).



III. PROBLEM STATEMENT  A sequence is an ordered list S = SI,S2,S3, ... Sn, where each Sj (1 ::; I ::; n) is an itemset, and is called an element     which is denoted as (XI,XL Xm) such that each Xk (1 ::s k::S m) EL and L is a finite set of distinct items. A sequence (l = ai, a2, . . . . .  ,lIn is called a subsequence of another sequence ? = bl,b2, . . . . .  bm, if there exists integers 1 ::Sjl <j2 < . . . . .  < jn ::s m such that al ? bil, a2 ? bi2, . . . . .  , lin ? bin' A sequence database contains D contains a set of sequences.

Given a sequence database D and constraints the sequential pattern mining problem requires to find the complete set of sequential patterns in the database. The sequential patterns hiding problem is defined as follows:  Let Sp = {SI, S2, ........ , Sn} be the set of sensitive sequential patterns that need to be sanitized in D. Let \Jf be the threshold. We need to transform the D into D' such that:  1. V SPi ESp, supp D'(SPi <= \Jf) 2. LSpiESplsuPPD(Sp) - sUPPo  '(Sp) is minimum.

In the above problem D is the original database and D' is the released database. The problem highlights two requirements for hiding sequential patterns. First one is to modify database D in such a way that sensitive sequential patterns are hidden. The second requirement says to reduce the effects of sanitization on all those sequentiaIB.

patterns that are not sensitive.



IV. PROPOSED METHODOLOGY  We use FP growth technique along with anti-monotone and monotone constraints for hiding sensitive sequential patterns.

Fig. L Proposed model for hiding sensitive sequential patterns. c.

Anti-monotone constraint fall under constraint based mining. The anti-monotone and monotone constraint is described below.

A. Anti-monotone Constraint  A constraint C is anti-monotone if and only if an item set X violates C, then so does any superset of X i.e. if C holds for an item set S then it holds for any subset of S.

Many constraints fall within anti-monotone category.

The minimum support threshold is a typical anti-  monotone constraint. As an example, sum(S) ::s v (\fa E S, a 2: 0) is an anti-monotone constraint [15].

TABLE!

ANTI-MONOTONE CONSTRAINT EXAMPLE  Item Profit a 40 b 0 c -20 d 10 e -30 f 30  g 20 h -10  Min (Profit) > = 50 Max (Profit) < = 30  Let the transaction for Table I be (a, b, c, d, and e).

Now if we apply Min (Profit) > = 50 on the transaction, we see that item a does not satisfy this constraint. There is no need to check the rest of the transaction items as it would not satisfy this constraint as well. The same condition will hold for Max (Profit) < = 30.

Monotone Constraint  A constraint C is monotone if and only if an item set X holds for C, so does any superset of X. That is, if C is violated for an item set S then it is violated for any subset of S. An example of monotone constraint is sum(S) 2: v (\fa E S, a 2: 0) [15].

TABLE II MONOTONE CONSlRAINT EXAMPLE  Item Profit a 40 b 0 c -20 d 10 e -30 f 30  g 20 h -10  Min (Profit) < = 15 Max (Profit) > = 30  Let the transaction for Table II is (a, b, c, d, e). Now if we apply Min (Profit) < = 15 on the transaction, we see that item a does not satisfy this constraint but item b does.

Therefore whole transaction will satisfy this constraint.

The same condition will hold for Max (Profit) > = 30.

Proposed Algorithm  Algorithm 1:  1. Input: D, Sh, Il 2. Output: d 3. Dj+-- 121 4. Scan transaction database once. Then collect set of  frequent items F along with their support.

5. Sort F in support decreasing order as L, list of  frequent items.

6. Create the root of FP-tree, T, and label it as "null".

7. For all Tr ?: D do     a. Select and sort frequent items in Tr according to the order of L. Let the sorted frequent item list in Tr be [piP], p is the first element and P is the remaining list. Call insert_tree ([piP], T).

b. Insert_tree ([piP], T) is performed as follows. If T has a child N such that N. item-name = p.item? name, increment count of N by 1; else create a new node N, and let its count be 1, its parent link be linked to T, and its node-link be linked to the nodes with the same item-name via the node? link structure. If P is nonempty, call insert tree (P,N) re cursively.

-  8. Apply anti-monotone constraint on T 9. 0 ? All Tr that satisfY anti-monotone  constraint 10. If(supp(Sh >= Il)  For all Tr e 0 oj ? Replace the Sh items with? in T  In this algorithm 1, 0 represents original database, Sh represents the sensitive patterns that need to be hidden, d represents released database and Il represents the threshold. First we construct a FP tree from the database given as input. Steps 4-7 in algorithm 1 construct the FP tree. These steps are also described in [6]. The FP tree would have sequences from all the transactions. Each node in the tree would represent the item in a transaction and its count in the database. On the tree, we apply anti? monotone property to prune the candidates which do not satisfY the sensitive pattern. Then we apply monotone property to hide the sensitive sequential patterns.

Table III shows a part of sequence database. This table contains sequence id and the items bought in a particular sequence. The sequences represent the purchases that a customer made during his visits to market.

In FP tree the root node is given a null value. Each transaction is scanned and the nodes are added to the tree.

The nodes in the tree represent items of sequential patterns. If an item appears more than once in database its frequency is updated and written alongside the node.

In the given example the sensitive pattern is abe. To eradicate large candidate generation we apply anti- monotone  TABLE III SEQUENTIAL P A TIERNS  Seq.ID Sequence I (a)(be)(c)(d) 2 (aXbXgde) 3 (b)(cXde) 4 (a)(be)(cXd) 5 (ce)(dXf)(g) 6 (a)(be)(cXd) 7 (a)(be)(cXd) 8 (bXcXd)(e) 9 (a)(be)(cXd)  10 (cd)(t)(gX e)  Fig. 2 represents the FP tree constructed from Table III.

constraint on the tree. First we would compare the children of the root with the first element of the sensitive pattern i.e. a.

Null  Fig. 2 FP tree for Table III.

Any node after the root which does not hold this constraint would be pruned. We do not have to check the whole branch of the tree, as stated in definition of anti? monotone constraint. If the first element does not satisfY the condition then the rest of the pattern would also not satisfY that condition. There is no need to check the rest of the nodes in that branch. This was the major problem in [7] who was matching each element of the transaction with the elements of the sensitive set. They had to do a lot of matching for finding the position in database for hiding.

After pruning the branches of the tree which does not hold anti-monotone constraint, we would apply monotone property to check the frequency of the sensitive pattern.

We would first add the frequency of the first two elements in sensitive patterns. If the frequency satisfies the threshold then there is no need to check it for the third element as it would increase the frequency because it would be added to the existing frequency.

TABLE IV RELEASED DATABASE     Then we find the transactions of the database which contain the pattern abe. All the transactions containing this pattern would be replaced with a symbol (?). Hence all the sensitive information would be hidden. Table IV represents the released database. We have reduced the number of database scans by using the FP growth technique. We scan the database two times, one for constructing the tree and the other for hiding sensitive patterns.

In this paper, we proposed a technique which is based on FP growth technique. We criticized the matching set technique proposed by [7]. Their matching set technique requires a database scan for every transaction, and then they match each element with every element in sensitive pattern set. The position involved in most matches is chosen for hiding. This approach works well if the dataset is small but as the size of dataset increases the size of matching set also increases and hence requires more time to hide sensitive sequential patterns.

Our approach has minimized the database scans by constructing FP tree. Then we apply anti-monotone and monotone constraint on FP tree. At the end, we hide all those sequential patterns that support sensitive patterns.

Our approach requires only two database scans as compared to [7].



V. CONCLUSION AND FUTURE WORK  Privacy preservation of sequential patterns still is not explored in depth. We looked at different techniques proposed by people to address the issue of privacy preservation in sequential patterns. The work proposed in this paper is also another step towards addressing this problern by providing a solution. We have not developed any prototype for this approach. We have just presented a conceptual idea of the proposed approach. In future we would implement the proposed approach and compare our results with others. We would use network dataset for our experiments.

