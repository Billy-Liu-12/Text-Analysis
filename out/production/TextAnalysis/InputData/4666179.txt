An Efficient  Algorithm for Mining Large Item Sets

Abstract.

It propose Online Mining  Algorithm ( OMA) which online discover large item sets. Without pre- setting a default threshold, the OMA algorithm achieves its efficiency and threshold-flexibility by calculating item-sets? counts. It is unnecessary and independent of the default threshold and can flexibly adapt to any user?s input threshold. In addition, we propose Cluster-Based Association Rule Algorithm (CARA) creates cluster tables to aid discovery of large item sets. It only requires a single scan of the database, followed by contrasts with the partial cluster tables. It  not only prunes considerable amounts of data reducing the time needed to perform data scans and requiring less contrast, but also ensures the correctness of the mined results. By using the CARA algorithm to create cluster tables in advance, each CPU can be utilized to process a cluster table; thus large item sets can be immediately mined even when the database is very large.

Keywords:  Large item sets; Data mining; Association rules.

PACS:  03.50.-z  1. Introduction   This Association rules are used to discover the  relationships, and potential associations, of items or attributes among huge data. These rules can be effective in uncovering unknown relationships, providing results that can be the basis of forecast and decision .Association rules mining  has become a major type of data mining skills that help the user extract association rules or large itemsets from a vast amount of database transactions for decision-making.

By that, an itemset  is regarded as large if the number of co-occurrences of these attributes in each transaction exceeds a threshold, minimum support value. Many mining algorithms for association rules have been proposed, such as Apriori [1] and DHP [2]. Although  powerful, the skill is not easy to determine an appropriate threshold so that useful or important rules and large itemsets can be discovered. Since the appropriate threshold is relatively application- dependent, the user may instead exercise the mining algorithm with different thresholds until important hidden rules and large itemsets are discovered.

Agrawal and Srikant proposed the Apriori association rule algorithm [1][3]. It can discover meaningful itemsets and construct association rules within large databases, but a large number of the candidate itemsets are generated from single itemsets and this method also needs to perform contrasts against the whole database, in the process of creating association rules. Performance is dramatically affected, as the database is repeatedly scanned to contrast each candidate itemsets with the database.

Most association rules researchers have used Apriori-like candidate generated approaches, all of these methods focus on reducing the number of candidate itemsets, and therefore reducing the number of database scans. In this paper, we present a new algorithm called cluster-based association rule (CARAA) and an efficient and flexible online mining algorithm (OMA) to fit these need. Savasere et al.

proposed the partition algorithm to further improve efficiency, it does so by effectively reducing the number of database scans, however, considerable time is still wasted scanning infrequent candidate itemsets [4].

Pork et al. proposed an effective algorithm DHP (direct hashing and pruning) for the initial candidate set generation. This method efficiently controls the number of candidate 2-itemsets, pruning the size of database [5].

Agrawal et al. proposed computing was first proposed the mining sequential patterns algorithm that included time attributes to discover sequential patterns [6]. Brin et al. proposed the dynamic itemsets count (DIC) algorithm  for finding large itemsets, which uses fewer passes over the data than classic algorithms, and yet uses fewer candidate item sets than methods based on sampling [7]. In addition, the column-wise Apriori algorithm [8] and the tree-based association rule algorithm, transformed the storage structure of the data, to reduce the time needed for database scans,   DOI 10.1109/FSKD.2008.679     improving overall efficiency.

2. Background  2.1Apriori Algorithm  The most influential algorithm Apriori developed by Rakesh etc. generates the k-candidate by combining two (k-1)-itemsets that have the first k-2 attribute values in the two (k-1)-itemsets the same the last pair does not. A new K-candidate becomes a k large itemsets if every (k-1)-subset of the k-candidate is a large itemsets otherwise it is removed. This algorithm need to do table scan of the whole data set and examine the itemsets multiple times, the process is very time consuming. The algorithm Apriori is follow:   L1={large 1-itemset}; For (k=2; ??? k;L 1-k ? ) { Ck=apriori (Lk-1); For all transactions Dt? { Ct=subset(Ck,t); For all candidates tCc? c.count++;  ???? count.c|Cc{L kk minsup} } Return( kk L? ) }  The Aprior-gen function takes as an argumentLk-1, the set of all large (k-1)- itemsets. It returns a superset of the set of all large k-itemsets.

2.2 Combinatorial approximation of itemsets  counts  The Principle of Inclusion and Exclusion [9] in Combinatory is expressed as follows:  |A1  A2 ??? An|= i  iA -    ? ji  ji AA  +       ?? kji  kji AAA + ?+(?1) n+1|A1 ? A2 ????An|     (1)  In general, by scanning the database only once for counting 1-itemsets and repeatedly applying Eq. (1).

This theory can be used to count item sets in the data- mining domain as well, if each transaction item is considered as a set and the number of its occurrences in transactions as its count.

Assuming that all items occur with the same probability, [9] proposed the theory of Approximate Inclusion?Exclusion to approximate the value of the  union term in Eq. (1) while some sub-terms are missing.

Considering an itemset S consisting of m attributes (of length m), a subset of k elements of S is called a k- subset and the set of all subsets of S is called its power set. The following equation is obtained in[9].

|A1  A2 ? Am|= ? ?kS Si  i m,k  S A?               (2)  we can first calculate by Eq.(2)the approximate value of m-union term |Ai1 Ai2 Aim|   for Eq.

(1), and then use Eq. (1) to compute the value of m- intersection term |Ai1 Ai2   Aim|, which is just the approximate count for the m-item set Ai1Ai2 Aim. Based on this concept, we propose Online Mining  Algorithm (OMA) in the next section.

3 Online Mining  Algorithm  The mining procedure may be invoked repeatedly with different input threshold values during online mining of large item sets . To improve mining performance, we scan the database in advance and store in main memory the counts of all 1-itemsets(L1) and 2- itemsets(L2). This pre-stored information is used for approximating the counts of higher order item sets, and further access of the database for verifying large item sets is thus unnecessary.

Since both L1 and L2 contain the counts of item sets (rather than the counts of large item sets), they are independent of any minimum support value and allow our algorithm to flexibly adapt to any input threshold value. The online mining algorithm (OMA) as below.

Algorithm OMA Input: L1,L2 (1- and 2-itemsets with their counts),minimum support (minsup) Output: Large item sets table (L) Online Mining Algorithm:  { {for (k = 1; k<= 2; k++) do  for each itemsets C in Lk if c.count<= minsup then insert c into table Lk ; }  { for (k = 3; Lk?1 ??; k++) Generate candidate k-itemsets into table Ck from  large itemsets in Lk-1; { for each itemsets c  Ck  Calculate the k-union term of C  by Eq. (2) with n = 2;  Calculate the k-intersection term (the count) of c by Eq. (1); if c. count >= minsup then  Insert C  into Lk; }     } }  The OMA algorithm in general follows the paradigm of Apriori algorithm, but instead of scanning the database to count item sets, it approximates item sets? count to determine large item sets.

The OMA algorithm calculates their counts through the combinatorial approximation technique instead of accessing the database to count item sets.

By this technique, large item sets can be discovered quickly and the use of default threshold to trade memory for runtime efficiency is unnecessary.

As a result, the OMA algorithm is independent of the default threshold and can flexibly adapt to any user?s input threshold.

In addition, its performance is stable and relatively independent of input threshold. The efficiency and threshold-flexibility make it very suitable for online mining applications.

4 Cluster-Based  Association Rule Algorithms   Many association rule algorithms? performance is dramatically decreased in the process of mining association rules, which repeatedly scanned to contrast each candidate item sets with the whole database level by level. If an alternative method can decrease the number of database scans, and reduce the number of contrasts, efficiency will be improved.

In this section, we propose an efficient CARA method for discovering the large item sets. CARA only requires a single scan of the transaction database, followed by contrasts with the partial cluster tables.

This not only prunes considerable amounts of data reducing the time needed to perform data scans and requiring less contrast, but also ensures the correctness of the mined results.

//  Algorithm CARA(D,minsup) Main( ) { ? Create_cluster_table(D,minsup); /*database D*/ for (k=2;Lk-1???;k++) { Ck=Gen_candidate-itemsets(Lk-1); Lk=Gen_large_itemsets(Ck); } return Lk; } procedure 1:Create_cluster_table(D,minsup) /* gets a set of large 1-itemsets and creates M cluster tables*/ {for (item=1;item?itemmax;item++)  Sitem=0 /*The support of  item*/ for (all T D) { if (length>max_length) /*lengthe=the item number of t*/ max_length=length put T into Cluster_table(length); /*creat cluster tables*/ for (all item T) Sitem++;  } for (item=1;item?itemmax;item++)  { Sitem= Sitem/ D ; if (Sitem minsup)// minimum support(minsup) L1= L1  item; } } procedure 2:Gen_candidate-itemsets(Lk-1) /*generates the set of candidate k-itemsets Ck*/ { ? for (all pair p_itemset, q_itemset Lk-1) for(i=1;i<k-1;i++) { if(ith item of p_itemset=ith item of q_itemset) Cand[i]=ith item of p_itemset; count++ else   break; } if(count=k-2)  {  Cand[k-1]=Min{(k-1)th item of p_itemset, (k- 1)th item of q_itemset }  Cand[k]=Max{(k-1)th item of p_itemset,  (k-1)th item of q_itemset }  Put Cand into Ck;}   procedure 3:Gen_large_itemsets(Ck) /*determines the set of large k-itemsets Lk */ {?  for(i=k;i max_length;i++) {  Support(c)=count(c)+times /*times is the times of appearance in the cluster_table(i)*/  Support(c)=Support(c)/ D ; if Support(c) minsup Lk= Lk c;  } }  In procedure 1,Scan the database once and cluster the transaction data. If the length of transaction record is k, the transaction record will be stored in the Cluster_Table(k), 1 k M. where M is the length of     the longest transaction record in database. It generated L1(the set of large 1-itemsets).

In procedure 2, it generates the set of candidate k- itemsets Ck. The procedure is similar to the candidate generation of Apriori algorithm [2].

In procedure 3, When the length of candidate itemsets is k, the support is calculated with reference to the Cluster_Table(k).If the support is greater than or equal to the user specified minimum support (MinSup), the candidate k-itemsets automatically becomes the large k-itemsets Lk. Otherwise, it is contrasted with the Cluster_ Table(k+1). The algorithm terminates when the calculated support is greater than or equal to the user specified minimum support or the end of the Cluster_Table(M) has been reached.

5 Conclusions  In this paper, we  propose Online Mining Algorithm ( OMA) and Cluster-Based Association Rule Algorithm (CARA) creates cluster tables to aid discovery of large item sets.

OMA can  help the user online discover large item sets. Instead of accessing the database to count item sets. The algorithm calculates their counts through the combinatorial approximation technique and can discover large item sets quickly . OMA algorithm is independent of the default threshold and can flexibly adapt to any user?s input threshold. In addition, its performance is stable and relatively independent of input threshold. The efficiency and threshold flexibility make it very suitable for online mining applications.

The CARA method is to create cluster tables by scanning the database once, and then clustering the transaction records to the k-th cluster table, where the length of a record is k. Moreover, the large itemsets are generated by contrasts with the partial cluster tables. It only requires a single scan of the database, followed by contrasts with the partial cluster tables. This not only prunes considerable amounts of data reducing the time needed to perform data scans and requiring less contrast, but also ensures the correctness of the mined results. Moreover, a parallel version of our algorithm will be implemented. By using the CARA algorithm to create cluster tables in advance, each CPU can be utilized to process a cluster table; thus large item sets can be immediately mined even when the database is very large.

