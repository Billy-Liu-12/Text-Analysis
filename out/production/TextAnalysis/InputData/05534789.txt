Stduy On An Improved Apriori Algorithm And Its

AbstractApriori algorithm is a classical mining algorithm uses  the association rules. After analyzing the Apriori algorithm, this  algorithm is inefficient due to it scans the database many times.

Based on the strategy of accessing to database once, a new  improved algorithm founded on the Apriori is put forward in this  paper. Experiments show that it can significantly improve  computation efficiency, i.e. reduce the calculatin time and space.

This algorithm has been widely used for supermarkets in customer  consumer knowledge mining.

Keywords-Apriori; Association rules; Frequent itemsets

I. BASIC CONCEPTION  With the practical application data increases sharply, many  professionals are more and more interested in the knowledge  about data mining[1], especially the association rule mining.

Association rules mining discovers interesting strong rules  between affairs. Let I=(i1, i2, . . . , in) is an itemset, D=(T1,  T2, . . . , Tn) is a transaction database(DB), Ti is a transaction,  min_sup and min_conf are minimum support-degree and  minimum confidence-degree. For a given itemset A and  transaction T, if: A?T, then T contains itemset A. A is a  frequent itemset if P(A)?min_sup in the DB. For any itemset  A=X Y? ,if X?I,Y?I,X?Y=?,Support (X?Y)= P(X?Y)?

min_sup, Confidence (X?Y)= P(X|Y)?min_conf. Then X?Y  is a strong association rule[2]. Apriori algorithm is a classical  algorithm mining association rule. It contains two steps:  Find all frequent itemsets by scanning DB;  Create strong association rules in the frequent itemsets.

Step one needs to scan DB many times, which takes a lot of    time and space. As a result, what needs to be improved is the  mining efficiency of frequent itemsets in DB.



II. ANALYSIS OF TRADITIONAL APRIORI ALGORITHM  Apriori algorithm uses the iterative method of layer-by-  layer search[3, 4], and k-itemset is used to explore for (k +1)-  itemset. Firstly, compute all the candidate 1-itemset C1, find all  the frequent 1-itemset L1; then confirm candidate 2-itemset C2  by L1, and find frequent 2-itemset L2. Repeat the processes  until frequent k-item cant be found. Getting each Lk needs to  scan DB once and it wastes a lot of  time.

In many cases, the candidate produce-check method of the  Apriori algorithm reduces the size of candidate itemsets in a  large extent and produces good performance. However, it will  produce a great number of candidate sets while computing. It  needs to scan DB many times although some pruning strategies  are applied, which costs a lot of time. These are its major  disadvantages [5]. So, we designs a new algorithm which scans  database only Once and deals with data One by One(OOO) to  improve the performance of Apriori by reducing numbers of  candidate sets and scanning times.



III. DESIGN AND ANALYSIS OF OOO ALGORITHM  A. OOO algorithm design  For traditional algorithm, if any subset of k-itemset x is  unfrequent, x must be unfrequent, and if x is frequent, its  subsets are also frequent. When producing candidate sets, if  item ab in record i is a frequent set, its  the same to all records  after i. However, with the items compared become fewer, the  number of Ck(k>1) decreases sharply, and everytime producing  a Ck needs scanning DB once. Scanning DB frequently  influences the mining efficiency seriously, moreover, most  information is discarded. So we can get and note all  information after scanning to avoid repeated actions. Above  properties of traditional algorithm are basic ideas for the new  improved algorithm. 10 OOOs detail process is following:  S1: open DB, set i=1, candidate set C=?, frequent set L=?

S2: if i>|DB|, go to S10  S3: set t=Ri, compute j=|t|  S4: if j=0, go to S9  S5: Cj={x|x?t?|x|=j}. If x?Cj?x?L, Cj=Cjx  S6: C=C C? j?x. count=x. count+1  S7: if x?C?x. count=min_sup, L=L {y|y? ?x }?C=Cx  S8: j=j-1, go to S4    S9: i=i+1, go to S2  S10: close the database and produce association rules  Ri is record i, and x. count is the support-degree of item x.

OOO only needs to scan the database once, and reduces the  cost of accessing the database frequently. It wont produce the  Natural Scientific Foundation of Provincial Department of Education,  Shaanxi (No. : 08JK318); Talent Fund Project of Xian university of  architecture and technology: "The research on uncertain reasoning  mechanism of fuzzy concept map" (No. : RC0618).

candidate item whose support-degree is 0 and will reduce the  number of candidate items. Besides, its time cost has almost  noting to do with the level of frequent itemsets.

B.  Analysis of algorithm complexity  1) Time complexity  Apriori algorithms time complexity primarily represents  the process of searching affair itemsets. When applying the  bottom-up method, the complexity of accessing affair itemsets  is:f(k)=|DB|?k i=1Ci+L2 1 +?k-1 j=2 L3 j-1, the time complexity is F(k)=  O(k3). While for OOO, the complexity f(k) of accessing affair  itemsets includes:  Produce k-items of candidate sets ?k i=1Ci and frequent  sets ?k j=1Lj for the first item of R1. It only needs to scan  the first item of data, scan times M1=1;  Produce new round items of candidate sets. While  scanning the second item of data R2, all of the old k-  items of candidate sets and frequent sets should also be  scanned, M2=1+|R1|?k i=1|Ci|+|R1|?k j=1|Lj|;  Produce the third round items of candidate sets. M3=1+  |R2|?k i=1|Ci|+|R2|?k j=1|Lj|;  Produce the last candidate sets, and get all Lk.

M|DB|=1+|Rj|?k i=1|Ci|+|Rj|?k j=1|Lj| by min_sup.

f(k)=|DB|+(|R1|?|R2|??+|Rj|)?k i=1(|Ci|+|Li|)  |R1|?|R2|??+|Rj| is the sum of scanning j items of data record,  and every item of data record is scanned only once and j=|DB|-  1, then |R1|?|R2|??+|Rj|=|DB|-1 from the illation processes. So  f(k)=|DB|+(|DB|-1)? k i=1 (|Ci|+|Li|), its time complexity is  F(k)=O(k), F(k)<F(k).

2) Space complexity  Apriori algorithm needs |DB| temporary variables to deposit  database records every time produces a level of candidate sets.

When producing the first level candidate and frequent sets,  M1=|DB|+2? k i=1 (|Ci|+|Li|) storage spaces are needed. When  producing the i-th level of candidate and frequent sets,  Mn=|DB|+2? k i=1 (|Ci|+|Li|) storage spaces are needed. So the  traditional algorithms space complexity is:  S(k)=|DB|+2Maxn j=1?k i=1(|Ci|+|Li|)  =|DB|+2?k i=1(|Ci|+|Li|).

Ci is the i-th level of candidate set, Li  is the i-th level of  frequent set. While to OOO,  S(k) includes:  Produce k items of candidate sets |R1|.? k i=1 |Ci| and  frequent sets |R1|.? k j=1 |Lj| for the first record R1: A  temporary variable t is used to deposit the current  record  R1, |R1|[?k i=1(|Ci|+|Li|)] storage variables are used  to deposit the candidate sets and frequent sets of the  first item of data, |R1|[?k i=1(|Ci|+|Li|)] storage variables  are used to deposit the support degree of the candidate  sets and frequent sets of the first item of data. So  N1=1+2 |R1|[?k i=1(|Ci|+|Li|)];  Produce a new round items of candidate sets: still use t  to deposit the current record R2, use |R2|[?k i=1(|Ci|+|Li|)]  storage variables to deposit the candidate sets and  frequent sets of the second item of data, use |R2|[?k i=1  (|Ci|+|Li|)] storage variables to deposit the support  degree of the candidate sets and frequent sets of the  first item of data. N2=1+2|R2|[?k i=1(|Ci|+|Li|)];  Produce the third round items of candidate sets.

N3=1+2|R3|[?k i=1(|Ci|+|Li|)];  Produce the last candidate sets, and get all of the  frequent itemsets Lk. N|DB|=1+2|R|DB||[?k i=1(|Ci|+|Li|)].

S(k)=max{N1, N2, N3, ?N|DB|}  =1+2Max|DB| j=1 [|Rj|?k i=1(|Ci |+?k i=1|Li|)]  =1+ 2?k j=1(|Cj|+|Lj|)  Both of the algorithms produce the same frequent items, i.e.

max(? k i=1 |Li|)=max(? k j=1 |Lj|), but OOO wont need to delete  candidate items whose support degree are 0 by scanning DB  repeatedly actually. Besides, the more records read from the  database, the less candidate items are product. So max(?k j=1|Cj|)  is far less than max(? k i=1 |Ci|),and S(k)=max{1+2? k j=1 (|Cj|+  |Lj|)}<max{|DB|+2?k i=1(|Ci|+|Li|)}= S(k).

As above, to traditional algorithm, OOO not only has  fewer times of scanning DB and comparing, but also reduces  the time and space complexity. It can significantly reduce the    number of candidate items when DBs records and field values  included in each record  are many.



IV. A SIMPLE INSTANCE  Suppose there is a simple affair database includes 4 records:  abc, bce, abcd, be. Table 1 shows the detailed processes  executed by OOO algorithm when min_sup is 50%.

TABLE I.  THE EXECUTION PROCESSES OF OOO ALGORITHM

V. EXPERIMENTAL ANALYSIS AND APPLICATION  Association rules mining is applicated widely in the  supermarket DB. The policy-makers can not only take  promotions to attract customers, but also to optimize the trade  by finding the contact between customers and their trades. We  have implemented the traditional algorithm and the OOO  algorithm in dealing with a large amount of supermarket data,  and compared the time costs.

The experiment data set test.csv is an excel table includes  10800 items of shopping data, whose basic items are bread,  milk, earthnut, egg, butter. 0 means having not been bought and  1 means having been bought. Table 2 shows a part of data.

TABLE II.  A PART OF EXPERIMENT DATA  Num Bread Milk Peanut Cream Egg  1 1 1 0 0 1  2 0 1 0 1 0  3 0 1 1 0 0  4 1 1 0 1 0  5 1 0 1 0 0  6 0 1 1 0 0  7 1 0 1 0 0  8 1 1 1 0 1  9 1 1 1 0 0  10 1 1 0 0 1  As follows, Figure 1 shows the result when the min_sup is  constant but DB capacity is changed, and Figure 2 shows the  execution result when DB capacity is constant but the min_sup  is changed. Its very clear that OOO shortens the  implementation time, improves the treatment efficiency and  has stronger stability.

1 2 3 4 5 6 7 8 9 10 11  Min_sup(unit:100)  R  un  ni  ng  ti  m  e(  un  it:  m  s  Apriori algorithm OOO algorithm    Figure 1.  The time graph of algorithm preserve min_sup           1 2 3 4 5 6 7 8 9 10 11  Min_sup(unit:100)  Ru  nn  in  g  tim  e(  un  it:    m  s  Apriori algorithm OOO algorithm    Figure 2.  The time graph of algorithm preserve DB capacity  Table 3 shows that the most things what the supermarket  sales are bread, earthnut and milk, and most customers will buy  bread and milk, milk and earthnut or bread and earthnut at the  same time. These rules are interesting. They have some guiding  significance on improving the supermarkets sales levels, the  capital turnover rate and the supermarkets management.

TABLE III.  STRONG ASSOCIATION RULES MINING

VI. SUMMARY  This paper has studied the classic association rules mining  algorithm and discussed shortcomings of the Apriori algorithm.

It has designed and implemented the OOO algorithm, and  taken the supermarkets consumer knowledge mining for  example to compare. OOO algorithm is more stable and  efficient because it only needs to scan DB once, has no  additional candidate items, and does not need pruning. Its  advantages are especially apparent when the database record  and the field values each record includes are many.

