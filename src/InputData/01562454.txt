A Web-Programming Agent

Abstract - This paper presents an application for a web- programming agent. This paper presents an intelligent agent that assists the user to retrieve, review, and learn knowledge about web programming. The agent has the ability to update its knowledge while searching for new information. The agent utilizes two methodology for learning, evaluates the importance of each term or piece of knowledge it knew, and can learn association rules to associate pieces of knowledge together. The learned associations is used to improve text evaluation.

Key words: intelligent agent, information retrieval, web- programming  1. Introduction These days, technology is progressing very fast.

Researchers and Engineers are trying to utilize the discovered technology to maximize the ease and comfort of our life. Since the discovery of the field of intelligence agents, many applications are aimed for information retrieval. These application raniges from mail handler and organizer to planet discoverer.

This paper presents an agent that can provide the user with daily news or information about a given field or subject. The agent can learns new knowledge and provide it to the user as well. This agent is very useful in many applications including but not limited to news, education, economy, sports, etc. For example, the agent can be used as a sport mediator. The agent can searches the internet every day to retrieve updated sport information.

2. Related Work In the past, information was an expensive thing to get or find. Today, information is vast and available to almost everyone to the limit that no one can comprehend one tenth of the information available over the internet. The problem now becomes how to handle this information, utilize it for interesting tasks, and how to find relevant information. The internet provides information about almost every aspect in our life. Even though we are discovering more and more knowledge every day, the intemet makes it easier to get information about new discovery in no time. Researchers are working since the 1 980s on developing systems that Information retrieval has been the concern of many researches since the 1960s ([61, [9], [51 & [10]). The development of information retrival systems requires   knowledge and research on topic identifications (8] and (3], search algorithms [1] and [31, and semantic and syntax analysis [4]. Topic identification is to identify the topic of a given text based on background knowledge.

Search algorithms for information retrival are quite different from search algorithms for data. Algorithms ranges from very simple which searches for predefined key words, to complex with searches for different words with the same meaning.

3. The IIRA-01 Agent The paper presents an agent for retrieving information and learns while accomplishing its task. Figure 1 shows a brief description of the different phases of the agent.

The first phase is concerned with teaching the agent about a certain subject. The teaching is done through a set of key words related to the subject. In the second ph)ase, the agent connects to the internet and starts searching for sites related to the subject of interest. A site may not be directly relevant, however, a link inside this site could lead to a very relevant site (e.g., www.yahoo.com). Therefore, the agent should search for all sub-links in each site. The agent evaluates the sites and saves the related links in a file (called DNS file). This phase can be substituted with a pre-defined DNS or by using a search engine (e.g., Google, Insite, Yahoo, MSN, etc.) to speed up the process. In the third phase, the text at each link in the DNS list is evaluated thoroughly to classify the links into relevant and irrelevant. The irrelevant links are removed.

While retrieving and evaluating texts, the agent learns in three different ways. The agent updates its knowledge by learning the importance of each key word. The agent learns new associations among its key words and evaluates the strength of these associations. These associations are also used to evaluate every new text.

The agent can present the user with the information it retrieved about the subject of interest.

Teaching the Agent Traditional ways of teaching the agent the basic knowledge of its task require complex learning systems that can cope with different disciplines of learning (7].

Initially, we teach the agent a specific subject. The agent should be aware of extensive set of vocabulary that covers the main terms and key words of the given subject. In this paper, we taught our agent the subject of     Web-Programming. To avoid the problem of parsing prefixes and postfixes of words related to Web- Programming, the vocabulary included many related words with possible prefixes and/or postfixes. The list of key words is ordered ascendingly and stored in a text file. Each key word is given an initial weight of 0.5.

These weights are updated by the agent to reflect the  importance of each key word to Web-Programming.

This file is called the knowvlecke file. The knowledge file is stored in a known folder to the agent to be used daily or as frequently as the agent runs. The domain of the subject can be simply changed by removing the old knowledge file and inserting a new knowledge file with key words for a new subject.

Teaching the agent new knowledge  Pages with related text i  Figure 1: Illustration of the different phases of the retrieval agent.

4. Experiments In this paper, we selected the domain of web programming to illustrate the functions of the agent. The agent started with 83 key words. The agent searched the intemet for relevant sites to web programming. We stopped the agent after two days of search. It was clear that an exhaustive search requires many days, and may be weeks. The agent ran in automatic search mode, which performs the initial search through a search engine. The agent is guided to use Google. In every run, Google retrieved tens of pages, each page contains about 10 links to sites related to web programming. The use of Google saved a significant amount of time. The agent evaluates each link and saves the relevant ones into a DNS file. The DNS file shall contain all links to relevant sites for future use. The user may bypass this process and creates his/her own DNS file. The agent can also work as a search engine.

4.1. Learning Relationship of Classified Key Words When the training phase is done, the association rules reflects relationships exists im many relevant texts to the agent domain. We classified the key words into four distinct groups, and labeled each group (coding, client/server, networking, and other). The result shows that most Web-programming report focuses on coding key words, Figure 2. The experiment can be repeated with different classifications.

4.2. Relationship Between Retrieved and Relevant Sites The agent utilizes one of Lycos, Goggle, or Alta vista to retrieve sites relevant to its domain (assuming no DNS   is given). We ran an experiment to show the relationship between the links Google retrieves for the web programming subject and the links evaluated by the agent as relevant. The agent searched for different words related to web programnmiig. Table 1 shows 9 experimenits. In eacih expcrimitent, the total liniks is the number of links retrieved by Google, the related links is the number of links evaluated by the agent as relevant to the subject, and the percentage of relevant to retrieved links.

Word category | Word category  Average of Frequencyin 1 *:  final association 4  Networkbi Coding  Key word category  Figure 2: Key words categories and the sum of their frequency in final associations  Table 1: Ex erments of links retrieval No Total Related % No. 'otal lin Related %  links links links 1 9 2 22% 6 77 35 45% 2 27 12 44% 7 153 71 46% 3 37 18 48% 8 216 93 43% 4 45 23 51% 9 480 1 72 35% 5 54 27 50%    This result illustrates the performance of the agent algorithm for evaluating texts. The irrelevant links appear due to the existence of common terms between different fields. For example, many terms are common among web programming, networking, and programming in general. A word like proxy may be found in a text that handles networks design or programming a proxy server.

The agent overcomes this problem by evaluating each text using the weights of the key words and how many strong associations the text contains.

For example, an association between two words as web and XML with a high weight will indicate that this page is related to the domain. But if the word XML appears in the text alone its occurrence will increase which will affect the overall weight of the text.

5. Conclusion Tllis paper introduced an application of information retrieval agent. The application is concerned with web programming, however, the agent can perform the same task for any other subject. The agents learned a set of key words related to web programming. The agent can connect to the interent and search for relevant sites, retrieves web pages related to the subject of interest, and learns how to improve its finctionalities. The agent creates its own Domain Name Server (DNS). The agent utilizes its DNS in all future usage. The agent learns weights for the initial key words, and utilizes these weights for evaluating new texts. The domain of the agent can simply change by changing the knowledge file of the agent. The paper presented an experiment and analysis of the performance of the agent. We should, in the future, build more applications and improve the performance of the agent.

Environments. Proceedings of the 21st International ACM SIGIR Conference on Research and Development in Information Retrieval, Melbourne, Australia.

[2] Brin S. and Page L. (1998). The Anatomy of a Large-Scale Hypertextual Web Search Engine.

Proceedings of the. Seventh World Wide Web Conference (WWW7), Brisbane. Also in a special issue of the journal Computer Networks and ISDN Systems, Volume 30, issues 1-7.

[3] Chakrabarti S., van der Berg M., Dom B. (1999).

Focused crawling: a new approach to topic-specific Web resource discovery. In Proceedings of 8th International World Wide Web Conference (WWW8). Also in Computer Networks & ISDN Systems 31(1 l-16):1623- 1640.

[4] Kleinberg J. (1998). Authoritative Sources in a Hyperlinked Environment. Proceedings of the ACM- SIAM Symposium on Discrete Algorithms.

[5] Garfield E. (1972).Citation analysis as a tool in journal evaluation. Science, 178(4060):471479, 1972.

[6] Garfield E. (1955). Citation Indexes for Science: A New Dimension in Documentation through Association of Ideas. Science, 122(3159): 108-111, 1955.

[7] Gordon, D.F. (2000) "Asimovian Adaptive Agents", Journal of Artificial Intelligence Research, Volume 13, pages 95-153.

[8] Imam, I.F. & Kodratoff, Y., (1996) "Intelligent Adaptive Agents", Al Magazine, Al press, September.

[9] Kessler M.M. (1963). Bibliographic Coupling betwden Scientific Papers. American Documentation, 14(1):10-25, 1963.

[1'0] Small 1-1. (1973). Co-citation in scicentific literature: A new measure of the relationslhip between two documents. Journal of the American Society for Information Science (JASIS), 24(4):265-269, 1973.

