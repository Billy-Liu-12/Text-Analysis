Evaluating Association Rules by Quantitative Pairwise Property Comparisons

Abstract?Evaluating association rules is an integral post process in association rule mining. Association rules are ex- amined by measures for their interestingness. Different in- terestingness measures have been proposed. Given an asso- ciation rule mining task, measures are assessed and selected against a set of user-specified properties. However, in prac- tice, due to the subjectivity and imperfection in property specifications, it is a non-trivial task to make appropriate measure selection. In this work, we propose a novel measure selection approach that makes use of the Analytic Hierar- chy Process (AHP), a scheme for making complex decisions.

Our approach captures a user?s desired requirements quan- titatively in an application domain to assess interestingness measures. It detects inconsistencies in property specifica- tions, and is invariant to the number of association rules to be evaluated. The effectiveness of our approach is shown through case studies.

Index Terms?Association rules, Interestingness mea- sures, The Analytic Hierarchy Process, Interestingness property.



I. Introduction  DATA mining aims at discovering interesting patternsfrom large-volume data [1]. Association mining is one of the many data mining tasks that has attracted more and more attention. It discovers the inherent re- lationships among objects in an application domain. A good application example of these application domains is basket analysis in supermarkets, where one tries to dis- cover the relationships among commodities in baskets. In association mining, interesting patterns are represented as association rules. For example, in basket analysis, {milk, eggs} ? {bread} is an association rule, implying that if milk and eggs are bought together, bread is likely to be bought as well [2].

One of the non-trivial issues in association mining con- sidered in literature [3], [4], [5], [6], [7], [8], [9] is the large number of association rules discovered. While many of the rules convey non-trivial and interesting information, some of them are trivial or even irrelevant [5], [7], [10]. Thus, they are too difficult to be interpreted and comprehended by users. Generally, two types of users are considered to be involved in the association mining process. An end user is an expert of the data to be mined in a particular ap- plication domain, while an analyst is a specialist in data mining. The end user should provide the analyst with sufficient domain knowledge, represented as requirements, in the domain, in order to extract interesting association  E.Delpisheh is with the Department of Mathematics and Com- puter Science, University of Lethbridge, AB, Canada. e-mail: elnaz.delpisheh@uleth.ca  J. Z. Zhang (Corresponding author) is with the Department of Mathematics and Computer Science, University of Lethbridge, AB, Canada. e-mail: john.zhang@uleth.ca  rules [11]. Throughout this paper, the term user is meant to be end user.

To deal with the large number of association rules, a variety of interestingness measures to assess them as how beneficial and interesting they are have been proposed [3], [6], [10], [12]. These measures rank association rules ac- cording to a set of criteria, some of which are as follows.

Reliability asks whether the relationship the association rule reveals occurs frequently. Peculiarity checks whether an association rule largely differs from other discovered as- sociation rules. Other criteria include diversity, novelty, surprisingness, utility, and comprehensibility [6], [9], [10], [13].

It is easy to see that some of the above criteria such as novelty and surprisingness are dependent on each other, while some others such as conciseness and reliability are contradictory [10]. Requiring them by the user at the same time introduces inconsistency in measuring associ- ation rules [9], [10], [14]. In addition, the user?s require- ments could be multi-facet, desiring multiple-criteria to be put into consideration when measuring association rules.

Moreover, the user?s requirements may change, reflecting the current preferences of them in an application domain and as a result in association rule evaluations. In our work, we attempt to capture, from preferences in an application domain, the importance of different properties in assessing interestingness measures. In Section II, we briefly review interestingness measures for evaluating association rules.

In Section III we discuss the properties against which a measure is assessed and selected. In Section IV we present measure selection strategies proposed so far. Sections V and VI introduce our measure assessment method, which makes use of the Analytic Hierarchy Process to capture the user?s subjective requirements and uses them in assess- ing measures. Section VII applies our proposed approach on two cases. Section VIII discusses the characteristics of measure selection approaches and compares our approach to the previous ones. Finally, Section IX summarizes our discussions.



II. Interestingness measures  This paper focuses on different interestingness measures for evaluating association rules, a post process of an as- sociation mining task. Let I = {i1, i2, i3, ? ? ? , il} be a set of items and let D = {t1, t2, t3, ? ? ? , tn} be a transactional database, where each transaction ti ? D is a subset of I.

An association rule is an implication of the form A ? B, where A? I, B ? I, and A?B = ? [15].

Usually a large number of association rules are resulted  from an association mining process, such as Apriori [15].

DOI 10.1109/ICDMW.2010.145    DOI 10.1109/ICDMW.2010.145     Many measures have been proposed and studied to eval- uate and rank them based on their interestingness. De- pending on the extent of the user?s involvement and the criteria they intend to pursue, measures are divided into two groups?objective and subjective. An objective mea- sure depends only on the structural nature, such as the statistical properties of association rules and underlying data. On the other hand, a subjective measure considers data itself and its users. Criteria including conciseness, re- liability, peculiarity, and diversity are considered objective, while novelty, utility, surprisingness, and comprehensibil- ity are considered subjective. For instance, given a rule, A? B, for database D, the support s and the confidence c are two objective measures to respectively assess the fre- quency and coverage of an association rule. These mea- sures state that s% of transactions in D contain A?B and c% of transactions that contain A also contain B. An- other example refers to subjective measures. Given an association rule, the more it contradicts the user?s prior knowledge, the more novel, thus the more interesting it is.

This paper focuses on objective measures summarized in Table I. More discussions can be found in [3], [5], [6], [7], [8], [9], [10], [11], [12], [13], [16], [17], [18], [19].

Due to the overwhelming number of interestingness mea-  sures and their variety in pursuing the criteria, which are often contradictory by nature, interestingness measures highly differ in ranking association rules. For instance, Support, an objective measure, assesses the reliability of association rules, while Specificity, another objective mea- sure, focuses on the peculiarity of association rules. Since reliability and peculiarity are two conflicting criteria, mea- sures using them provide conflicting results. Thus, an as- sociation rule may be ranked the best based on the first measure but the worst based on the other. Consequently, selecting an appropriate measure to evaluate association rules is highly application-domain dependent. In order to assess objective interestingness measures and select an appropriate one for a given application domain, a set of properties is proposed. These properties represent the re- quirements from an application domain. The appropriate measure for a given application domain is selected based on how it fulfills various properties. The next section ex- plains these properties and illustrates the measures pursu- ing them.



III. Properties for assessing measures  Given an application domain and an association rule of the form A ? B, appropriate objective measures are se- lected to evaluate association rules for an association min- ing task based on a set of properties as follows.

? P1. This property represents that a rule occurred by chance has no interestingness value [4], [10].

? P2. This property states that, when the support for A and B are fixed, the larger the value of support for A and B, the larger their interestingness value is [4], [10].

? P3. This property states that, when the support for AB and B (A, respectively) are fixed, the smaller the  support for A (B, respectively), the more interesting the association rule is [4], [10].

? P4. This property makes a distinction between mea- sures evaluating rules A ? B from those evaluating B ?A, resulting in different interestingness values [4], [6], [10], [12], [14].

? P5. This property states that, if there is no counterex- ample to the rule, interestingness stays constant.

? P6. This property states that the growth of a database does not influence interestingness value if the rate of A, A?B, or B is constant [4], [6], [10], [12], [14].

? P7. This property states that having a slow decrease in the neighborhood of a logical rule rather than a fast or even linear decrease is desirable. It reflects the tolerability of a few counterexamples without the loss of interest [4], [10].

? P8. This property states that the threshold to identify interesting measures from uninteresting ones should be easy to choose and change [4], [10].

? P9. This property states that a measure is able to express a comprehensive idea of rule interestingness according to three following factors: easiness in its definition, value interpretation, and comprehensibility for the user [4], [6], [10], [14].

? P10. This property refers to the interestingness value that changes its sign if either the rows or the columns of the contingency table of a rule are permuted [6], [10], [12], [14].

? P11. This property states that the interestingness value remains the same if both the rows and columns of the contingency table of the rule are permuted. In fact, this property is a special case of P10 because per- muting the rows (columns) causes the sign to change once and permuting the columns (rows) causes it to change back [6], [10], [12].

? P12. This property states that interestingness has no relationship with the number of the records that do not contain A and B [10].

Interestingness measures differ in pursuing the afore- mentioned properties, as listed in Table I. Value 1 or 0 in each cell in the table is to show if an interestingness mea- sure fulfills the respective property or not [4], [10], [18], [20]. For the sake of space, the list in Table I is only par- tial. Other measures and their fulfillments, such as Accu- racy, Leverage, Jaccard, etc., are discussed in detail in [4], [10], [18], [20]. On the other hand, each application do- main requires its own characteristics and accordingly its own requirements on properties. Thus, it has been always a challenge to select a measure that well suits a given ap- plication domain [21]. The following section discusses the strategies proposed in the literature to select appropriate interestingness measures.



IV. Selecting interestingness measures  The current approaches to assess and select appropriate measures take the following considerations into account.

(1) The measure assessment and selection are highly sub- jective. They depend on the user?s preferences, her/his     TABLE I  Interestingness properties fulfilled by measures.

Interestingness measure P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 P12  Support 0 1 0 1 0 0 1 1 1 0 0 0 Confidence 0 1 0 0 1 0 1 1 1 0 0 0 Coverage 0 0 0 0 0 0 0 1 1 0 0 0 Prevalence 0 0 0 0 1 0 1 1 0 0 0 0 Recall 0 1 0 0 1 0 0 1 1 0 0 1 Specificity 0 0 0 0 0 0 0 1 1 0 0 0 Odds ratio 0 1 1 1 1 1 0 1 0 1 1 0 Yule?s Q 1 1 1 1 1 1 0 1 1 1 1 0 Yule?s Y 1 1 1 1 1 1 0 1 1 1 1 0 Piatetsky-Shapiro 1 1 1 1 0 0 1 1 1 1 1 1  domain knowledge, and the application domain; (2) The assessment and selection are driven by the user, who might have various contradictory rational requirements, resulting in inconsistencies in her/his specifications; (3) The user?s requirements may change over time, and accordingly, the result of assessing and selecting measures may change as well; and (4) The number of association rules grows given the growing volume of data. An interestingness measure needs to be general enough to handle this growth.

The techniques proposed so far to select an appropriate interestingness measure fall into three categories based on the approach applied, namely, clustering methods, ranking methods, and multiple-criteria decision aid methods.

Clustering methods. Clustering methods [9], [11] cluster measures based on their similar properties. For instance, Tan et al. [14], [18] state that the higher the correlation be- tween the properties of two measures, the stronger the con- sistency between the measures. As a result, they are clas- sified into one single class. Clustering methods are objec- tive since they categorize association rules based on their properties. However, there exist a few shortcomings about them. These methods do not take the user?s requirements into account and thus do not capture all the complexities that exist in her/his views in assessing measures. For ex- ample, although two measures might be clustered into a same class, the user may consider that one measure is of more importance than the other.

Ranking methods. Ranking methods proposed by Sa- har [12] and Tan et al. [14], provide the user with a small subset of discovered rules for ranking. Then, this sub- set is assessed by objective measures. Finally, a measure, whose ranking is the most similar to the user?s ranking is selected as the appropriate measure. These methods per- form well on taking the user?s requirements into account but they fail to avoid the user?s incomplete and growing domain knowledge that may cause some inconsistencies in evaluating association rules. In addition, if the number of association rules is large, selecting a suitable measure for a small subset may not be generalizable to the entire set of association rules.

Multiple-criteria decision aid methods. Multiple-criteria decision aid methods proposed by Lenca et al. [11], select appropriate interestingness measures based on the user?s objectives. To take important criteria into account, a few  MCDA procedures have been used. A preference func- tion is presented to rank the desired properties and some weights are decided and assigned to them, which are fur- ther used to assess the relative measures. In this method, the consistency and dynamic behavior of the user?s require- ments are not checked.

To remedy the shortcomings of the above methods, we  propose an assessment approach that not only consid- ers the user?s requirements represented by interestingness properties but also checks her/his consistency in property specifications. Moreover, the approach is invariant to the growth of data volume and the number of association rules to be evaluated, as shall be seen shortly.



V. A revised Analytic Hierarchy Process  The Analytic Hierarchy Process (AHP, for short) is a multi-criterion decision making technique that was origi- nally developed by Saaty [22]. Given an application do- main, to achieve maximally a goal that has multiple prop- erties, the user needs to prioritize, i.e., assigns importance to properties, under a set of requirements. This is essen- tially an optimization problem. In practice, the assign- ment process of preferences may introduce inconsistencies in property importance, given, for instance, incomplete do- main knowledge, inconsistent requirements, etc. Moreover, it is usually hard to conduct the importance assignment to individual properties given the requirements. AHP pro- vides a systematic and effective way to tackle this com- plicated prioritization by quantifying subjective require- ments.

A. AHP details  The first step in AHP is to conduct pair-wise com- parisons among properties. For a set of n properties, {P1,P2,P3, ? ? ? ,Pn}, of a given domain, there are  ( n  ) com-  parisons. For each comparison between two properties, the user chooses a quantitative ratio value between them based on her/his qualitative requirements. This way, we encode qualitative domain-dependent requirements on the two properties into a quantitative value.

Since it is costly to conduct as many as  ( n  ) compar-  isons, our work chooses a revised version of AHP, in which properties are engaged in a chain-wise paired comparison (CPC, for short) requiring only n? 1 property compar-     TABLE II  The importance values in CPC  Scale Importance  1 Equal importance 3 Moderate importance 5 Essential or strong importance 7 Very strong importance 9 Extreme importance  2,4,6 Intermediate values  TABLE III  The CPC algorithm.

i Ri Di Ii R?i Mi Vi  1 W1 W2  D1 D1? Di  D1 n ??  Dj  n?1? i=1  R?i M1? Mj  2 W2 W3  D2 D2? Di  D2 n ??  Dj  n?1? i=2  R?i M2? Mj  ? ? ? ? ? ? ? ? ? ? ? ? ? ?  n? 1 Wn?1 Wn  Dn?1 Dn?1?  Di  Dn?1 n ??  Dj  ?Rn?1 Mn?1?  Mj  n Wn W1  Dn Dn? Di  Dn n ??  Dj 1 Mn?  Mj  isons [23]. The majority of the following discussions can also be found in [23]. But we have adapted it to fit into our problem context.

The revised AHP starts from the user-specified impor-  tance value (denoted as weight (Wi)) for each property Pi, where i = 1, 2, ? ? ? , n. The user is invited, based on her/his requirements on these properties, to compare them in pairs and assign them importance ratio values. A set of typical ratio values, as suggested in [23], is illustrated in Table II. Note that, seemingly arbitrary, those values rep- resent the relative importance among properties. For in- stance, if judged from a given application domain, property Pi is much more important than property Pi+1 in select- ing measures, we would then assign their ratio as 7/1. As the user uses the approach more and more, s/he would be more comfortable in deciding those relative ratios.

Let Ri denote the ratio of the ith property to its succes-  sor. We close the comparison chain with the ratio of the nth property to the 1st property. This is represented in the following equation.

Ri =  { Wi  Wi+1 i= 1, . . . ,n? 1  Wn W1  i= n (1)  The value of Ri between two properties is specified by the user based on her/his domain requirements. It is easy to see that, under perfect consistency of the specifications, the product of Ri for all i should equal 1.

n? i=1  Ri =  ( W1 W2  )( W2 W3  ) . . .

( Wn W1  ) = 1 (2)  Otherwise, there is a certain degree of inconsistency. This is exactly the situation where our approach needs to cap-  ture when the user tries to specify which properties are im- portant and which are not based on her/his requirements for the given association mining task.

In order to do this, two different values of Ri are ob- tained: direct or indirect. The direct value, Di, is the value of Wi that is directly expressed by the user, whereas the indirect value, Ii, is the value computed relative to the other direct values, i.e., the reciprocal of the product of other Dis.

Ii = Di?n  j=1 Dj (3)  Obviously, Ii is equal to Wi  Wi+1 if a perfect consistency is  achieved, i.e., ?n  j=1Dj = 1.

A better estimation of Ri, denoted by R?i, using the two different values Di and Ii, is proposed [23] using the weighted geometric mean of Di and Ii. Calculation for R?i is shown by Equation 4.

R?i = D (n?1)/n i ?I  1/n i = D  (n?1)/n i ?(  Di? Dj  )1/n = Di?  n ??  Dj (4)  The rationale behind Equation 4 is that, since direct values are more important than indirect values, each Di weighs (n?1) times more than Ii. Also the geometric mean is used since we expect that the ratio changes occur in a relative way. Note that we compare a pair of properties relatively, i.e., the importance of the property on the numerator rel- ative to the one of the property on the denominator (we can consider this ratio as a percentage).

After introducing R?i, every direct value Di is treated equally in the derivation process. It is noted that, whileRis are inconsistent in practice, R?is are perfectly consistent, i.e.,  ?n i=1 R?i = 1.

Since R?is are perfectly consistent, the weight for each interestingness property relative to the nth property, Mi = Wi/Mn, can be determined from R?i. The weight of the nth property relative to itself is 1, i.e., Mn = 1. The following recursion represents this calculation.

Mi =  ????? n?1? i  R?i i= n? 1, . . . ,1  1 i= n  (5)  Finally, the normalized relative weights, Vi, for each of the interestingness properties Pi, are obtained by Equation 6.

The values of Vis represent the priority of the relative prop- erty.

Vi = Mi?n j=1 Mj  (6)  The whole CPC algorithm is summarized in Table III [23], [24].

B. Measure of consistency  Consistency for chain-wise comparisons can be measured by the quantity,  ? Ri, which, when not equal to 1, shows  a certain degree of inconsistency. In practice, some degree of inconsistency is unavoidable.

As pointed out in [23], there are two types of consisten-  cies: ordinal and cardinal. Ordinal consistency is main- tained as long as the correct order of the interestingness properties is maintained. Cardinal consistency is more strict and requires that the importance values for all com- parisons, assigned by the user, be correct [23]. We will discuss more on the cardinal consistency after the ordinal consistency.

The ordinal consistency is easily checked by comparing  the magnitude of Ii to its corresponding Di, i.e., the pair (Ii,Di). The ordinal consistency is achieved if both Ii and Di are of the same magnitude, i.e., both Ii and Di are larger than or equal to 1 or both are smaller or equal to 1.

The cardinal consistency of the estimations is checked  using the following equation, as introduced before.

n? i=1  Ri = 1 (7)  Full consistency is achieved if Equation 7 is satisfied. How- ever, it is hard to achieve full consistency given the un- certainty in the user?s requirements for a given association rule mining task. Practically, a consistency level more than 90% is acceptable [23].

During the above process, if any consistency violation  occurs, the user should be notified to reevaluate the entire property pair-wise comparisons.



VI. AHP-based measure assessment method  Our AHP-based measure assessment (AHPMA, for short) approach quantitatively prioritizes the user?s sub- jective requirements. It includes the following four basic steps: (1) Present properties to the user; (2) Invite the user to rate the properties; (3) Assess the ratings and pri- oritize the properties; (4) Assess property fulfillment by each interestingness measure.

A. Presenting properties  The set of 12 properties, P1, P2, ? ? ? , P12 are presented to the user.

B. Rating properties  Using chain-wise paired comparisons, discussed in Sec- tion V, the user assigns weights to the above properties in pairs based on their importance in her/his requirements for the given association mining task. For instance, based on the requirements, if the ratio of P1 to P2 is 4/3, it states that P1 is 4/3 more important than P2.

C. Assessing and prioritizing properties  The algorithm in Table III is employed to calculate the relative weight vector. This vector represents the priori- tized properties. The most important property gains the  maximum weight and the least important property gains the minimum weight. Since some properties gain extremely small weights in comparison to other properties, the effect of leaving them out (setting them to zero) from further consideration is negligible. Thus, the weights, Vj , of the remaining properties are adjusted to obtain the adjusted weights, denoted as AW (Vj).

AW (Vj) = Vj?n i=1 Vi  , 1 ? j ? n (8)  where n is the number of interestingness properties.

D. Assessing property fulfillment  Considering the prioritized properties, the measures are assessed. For each measure (Mi), its overall composite weight, denoted as CW (Mi), is computed based on the adjusted weights, AW (Pj), discussed in the previous step, using CW (Mi) =  ? j AW (Pj) ?C(i, j), where C(i, j) rep-  resents whether measure i fulfills property j (as indicated by 1) or not (as indicated by 0).



VII. Case studies  It would be beneficial to apply our approach to a given association mining task in a real-life application to assess interestingness measures. However, this would entail con- siderable organizing and expenses. Under the current cir- cumstances of the limited resources available to us, we fol- low the same experiment scheme designed and used in [4], [11] for measure selection approaches.

In our experiments, we have designed two case studies to  simulate measure selections using our approach. Each case involves a set of properties that the user desires to have when assessing interestingness measures, reflecting her/his domain-specific requirements for a given association min- ing task. It should be noted that, though we are conduct- ing simulations in our work, the application process of our approach should be readily generalized and made use of in reality.

A. Case one  This case is presented to illustrate the application of our approach in assessing interestingness measures, where the user provides consistent specifications on interestingness properties. The following scenarios are required in this case.

Scenario 1: Reliability of results is required. Thus, less  counterexamples to an association rule are desired.

Scenario 2: A selected measure should be easily com-  prehensible by the user.

Scenario 3: The number of the transactions including  neither A nor B should not affect the interestingness of an association rule.

Scenario 4: Given the reliability requirement, associa-  tion rules happening by accident should be avoided.

Scenario 5: Rules of the form A?B and B ?A should  differ in their interestingness values.

Not all the interestingness measures are useful to pursue  these requirements. Using our method, the 12 properties     TABLE IV  Consistent property specifications for the scenarios of case  one.

i Ri Di Ii R?i Mi Vi  1 W1/W2 9/2 = 4.500 4.821 4.527 0.623 0.136 2 W2/W3 3/2 = 1.500 1.608 1.509 0.138 0.030 3 W3/W4 2/8 = 0.250 0.268 0.252 0.091 0.020 4 W4/W5 8/3 = 2.667 2.858 2.683 0.363 0.079 5 W5/W6 2/2 = 1.000 1.072 1.006 0.135 0.030 6 W6/W7 2/8 = 0.250 0.268 0.252 0.134 0.029 7 W7/W8 8/3 = 2.667 2.858 2.683 0.534 0.117 8 W8/W9 2/8 = 0.250 0.268 0.252 0.199 0.044 9 W9/W10 7/2 = 3.500 3.751 3.521 0.792 0.173 10 W10/W11 2/3 = 0.667 0.715 0.671 0.225 0.049 11 W11/W12 3/9 = 0.333 0.357 0.335 0.335 0.073 12 W12/W1 8/5 = 1.600 1.715 1.610 1.000 0.219  are prioritized and weighed based on the above scenarios.

For example, the ratio of P1 to P2 is set to be 9 to 2, given the importance of P1 based on Scenario 4. Moreover, the ratio of P7 to P8 is set to be 8 to 3, given the importance of P7 based on Scenario 1. The rest of the weights are assigned according to the above scenarios. Table IV illus- trates the results. Column Di represents the ratio values specified by the user according to the scenarios.

Both the ordinal and cardinal consistency, as explained in Section B, for this prioritization are calculated. Ordi- nal consistency is checked by pairs (Ii,Di). It is seen that the two corresponding columns all have the same magni- tude. Thus, ordinal consistency is achieved. Then cardinal consistency is checked using Equation 7 and the result is 0.933, which is acceptable.

The last column shows the priority vector of the 12 properties. Since the weights for P2, P3, P5, P6, P8, and P10 are very small, we will not include them for fur- ther calculation. Thus, only the properties P1, P4, P7, P9, P11, and P12 are considered and, using Equation 8, their corresponding weights are adjusted.

?12 i=1 Vi =  0.798. As a result, AW (P1) = 0.171, AW (P4) = 0.099, AW (P7) = 0.147, AW (P9) = 0.217, AW (P11) = 0.092, and AW (P12) = 0.274,  Under the seven selected properties with their adjusted weights, the objective measures are examined with the aim to choose the most appropriate one, as illustrated in Ta- ble V. The rows represent the candidate measures while the columns represent the selected properties. For in- stance, the composite weight for Support is computed as follows: CW (Support) = 0.463.

As shown in Table V, the measure Piatetsky?Shapiro, which is of the highest composite weight, is chosen.

B. Case two  This case is presented aiming at explaining occurrence of inconsistency in the user?s property importance speci- fication. Taking the following scenarios into account, the user is asked to rank the properties.

Scenario 1: Accidental rules have no interestingness value.

TABLE VI  Inconsistent property specifications for the scenarios of  case two.

i Ri Di Ii  1 W1/W2 4/2 = 2.000 0.056 2 W2/W3 8/2 = 4.000 0.112 3 W3/W4 5/2 = 2.500 0.070 4 W4/W5 4/6 = 0.667 0.019 5 W5/W6 3/2 = 1.500 0.042 6 W6/W7 8/7 = 1.143 0.032 7 W7/W8 4/7 = 0.571 0.016 8 W8/W9 7/3 = 2.333 0.066 9 W9/W10 1/2 = 0.500 0.014 10 W10/W11 3/2 = 1.500 0.042 11 W11/W12 6/3 = 2.000 0.056 12 W12/W1 7/9 = 0.778 0.022  Scenario 2: Since novelty is an important property, as- sociation rules with less frequent items in the antecedent and consequent are considered more interesting.

Scenario 3: The size of the database may enlarge over  time. Interestingness of a rule should be invariant to this change.

Scenario 4: Interestingness criteria may change over  time, thus interestingness threshold should easily change considering new criteria.

Scenario 5: Interestingness value changes upon row or  column permutations.

Scenario 6: Interestingness value stays the same upon  both row and column permutation.

Considering the ratios provided by the user in Table VI,  for i= 1,2,3,5,6,8,10 and 11, one finds that the magnitude of Ii differs from the one of the corresponding Di. Thus, the ordinal consistency is violated. Moreover, the value of cardinal consistency is calculated using Equation 7 with a value of 35.56, which is not acceptable. As a result, the ranking is cardinally inconsistent too. This inconsistency has occurred due to violating the transitivity in ?is greater than? relation1 in the user?s property preferences. The specifications state that P6 is more preferred than P7, P7 is more preferred than P5, and P5 is more important than P6, which contradicts the transitivity in the user?s preferences.

Consequently, the user is asked to reevaluate the prop-  erties for their importance values. It should be noted that this process may need to repeat several times until both types of consistency are passed. We show one set of con- sistent specifications on the twelve properties in Table VII.

Given the same magnitudes of all the pairs (Ii,Di), the  ordinal consistency is met. In addition, the cardinal con- sistency, which is equal to 0.957 according to Equation 7, is obtained. Column Vi shows the priority of the properties.

Only P1, P2, P3, P5, P6, P8, P10, and P11 are taken into account in this case. Since the weights for P4, P7, P9 and P12 are very small, they are neglected for further consid- erations. The adjusted weights of the other properties are computed, as follows.

?12 i=1 Vi = 0.822, AW (P1) = 0.196,  1 A relation ?? is called transitive if, for P , Q, and R, P ?? Q and Q ?? R, then P ?? R; otherwise, it is intransitive.

TABLE V  Composite weights for measures based on property importance for case one.

Interestingness Measures P1 P4 P7 P9 P11 P12 CW 0.171 0.099 0.147 0.217 0.092 0.274  Support 0 1 1 1 0 0 0.463 Confidence 0 0 1 1 0 0 0.364 Coverage 0 0 0 1 0 0 0.217 Prevalence 0 0 1 0 0 0 0.147 Recall 0 0 0 1 0 1 0.491 Specificity 0 0 0 1 0 0 0.217 Odds ratio 0 1 0 0 1 0 0.191 Yule?s Q 1 1 0 1 1 0 0.579 Yule?s Y 1 1 0 1 1 0 0.579 Piatetsky-Shapiro 1 1 1 1 1 1 1.000  TABLE VII  Consistent property specifications for the scenarios of case  two.

i Ri Di Ii R?i Mi Vi  1 W1/W2 8/3 = 2.667 2.788 2.678 3.496 0.161 2 W2/W3 3/8 = 0.375 0.392 0.377 1.305 0.060 3 W3/W4 7/2 = 3.500 3.657 3.514 3.467 0.159 4 W4/W5 2/3 = 0.667 0.697 0.670 0.987 0.045 5 W5/W6 4/6 = 0.667 0.697 0.670 1.473 0.068 6 W6/W7 8/3 = 2.667 2.787 2.678 2.200 0.101 7 W7/W8 3/7 = 0.429 0.448 0.431 0.822 0.038 8 W8/W9 7/4 = 1.750 1.829 1.757 1.908 0.088 9 W9/W10 3/7 = 0.429 0.448 0.431 1.086 0.050 10 W10/W11 5/3 = 1.667 1.742 1.674 2.521 0.116 11 W11/W12 3/2 = 1.500 1.567 1.506 1.506 0.069 12 W12/W1 2/7 = 0.286 0.299 0.287 1.000 0.046  AW (P2) = 0.073, AW (P3) = 0.193, AW (P5) = 0.083, AW (P6) = 0.123, AW (P8) = 0.107, AW (P10) = 0.141, and AW (P11) = 0.084.

Under the eight selected properties with their adjusted  weights, the objective measures and their properties are examined.

As shown in Table VIII, the measures Y ule?s Q and  Y ule?s Y are chosen, since they fulfill the majority of the properties with the highest composite weight.



VIII. Different measure assessment methods  The other measure selection approaches proposed so far, namely the clustering methods (CM), the ranking meth- ods (RM), and the multiple-criteria decision aid methods (MCDA), as discussed in Section IV, aim at pursuing the following characteristics [4], [9], [11], [12], [14]: C1: Taking the user?s preferences into account [6], [7],  [8], [10], [11], [12]. The user should provide enough infor- mation on what rules are considered interesting.

C2: Avoiding inconsistencies in the user?s decisions [22].

The user may be inconsistent in providing inputs. A selec- tion strategy should deal with those inconsistencies.

C3: Adapting to the varying user?s requirements [5], [8],  [11]. A selection strategy should be able to adapt itself with the user?s dynamic requirements.

C4: Invariant to the number of association rules [9], [11].

An appropriate selection strategy should not be affected by  TABLE IX  Measure assessment approaches and their characteristics.

Characteristics CM RM MCDA AHPMA  C1 ? ? ? C2 ? C3 C4 ? ? ?  the number of association rules.

These approaches differ in fulfilling the above charac- teristics, as shown in Table IX. A symbol (?) is used to represent the satisfaction of the characteristics by the re- spective measures.

Since clustering methods (CM) classify measures based on either their properties or association rules, they do not take the user?s preferences into account and accordingly do not conduct consistency checking. Furthermore, because they focus on properties, they are invariant to the number of association rules [9], [11]. Thus, they are only marked on C4.

Ranking methods (RM) provide the user with a small subset of discovered rules for ranking. Thus, it is marked on C1. However, if the number of association rules is large, selecting a suitable interestingness measure for them may be problematic. To make it worse, given the user?s incom- plete and growing domain knowledge, there might be some inconsistencies in ranking association rules [12], [14].

Multiple-criteria decision aid methods (MCDA) perform the selection based on the user?s objectives and a few MCDA procedures. The consistency of the user?s require- ments is not checked. Moreover, it does not pay attention to dynamic changes in the user?s requirements [4], [11].

Our proposed method, (AHPMA), takes the user?s re- quirements into account and detects any inconsistencies in her/his specifications. In addition, it is not influenced by the number of association rules, i.e., the time complexity of our method only depends on the number of properties under consideration and is invariant to the size of the data set and the number of association rules mined. But, like the other three methods, it is not able to adapt itself to the user?s dynamic requirements.

TABLE VIII  Composite weights for measures based on property importance of case two.

Interestingness Measures P1 P2 P3 P5 P6 P8 P10 P11 CW 0.196 0.073 0.193 0.083 0.123 0.107 0.141 0.084  Support 0 1 0 0 0 1 0 0 0.180 Confidence 0 1 0 1 0 1 0 0 0.263 Coverage 0 0 0 0 0 1 0 0 0.107 Prevalence 0 0 0 1 0 1 0 0 0.190 Recall 0 1 0 1 0 1 0 0 0.263 Specificity 0 0 0 0 0 1 0 0 0.107 Odds ratio 0 1 1 1 1 1 1 1 0.804 Yule?s Q 1 1 1 1 1 1 1 1 1.000 Yule?s Y 1 1 1 1 1 1 1 1 1.000 Piatetsky-Shapiro 1 1 1 0 0 1 1 1 0.794

IX. Conclusions  Our main contribution in this paper is a novel approach to assess interestingness measures for association rules.

Our approach is independent to the number of association rules and assesses the measures based on a set of user?s requirements. We attribute this to the analytic hierarchi- cal process (AHP). Some initial case studies are presented to show the effectiveness of our approach. It is also noted that none of the measure assessment methods so far deals with the dynamic behavior of the user?s requirements. In other words, these methods must be reapplied in case of changes in the user?s behavior. In our future work, we will attempt to dynamically evaluate association rules accord- ing to a collective effect of multiple measures while taking the user?s requirements and feedbacks into consideration.

