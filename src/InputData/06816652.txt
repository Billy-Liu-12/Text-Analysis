Contract & Expand: I/O Efficient SCCs Computing Zhiwei Zhang1, Lu Qin3, Jeffrey Xu Yu1,2

Abstract?As an important branch of big data processing, big graph processing is becoming increasingly popular in recent years. Strongly connected component (SCC) computation is a fundamental graph operation on directed graphs, where an SCC is a maximal subgraph S of a directed graph G in which every pair of nodes is reachable from each other in S. By contracting each SCC into a node, a large general directed graph can be represented by a small directed acyclic graph (DAG). In the literature, there are I/O efficient semi-external algorithms to compute all SCCs of a graph G, by assuming that all nodes of a graph G can fit in the main memory. However, many real graphs are large and even the nodes cannot reside entirely in the main memory. In this paper, we study new I/O efficient external algorithms to find all SCCs for a directed graph G whose nodes cannot fit entirely in the main memory. To overcome the deficiency of the existing external graph contraction based approach that usually cannot stop in finite iterations, and the external DFS based approach that will generate a large number of random I/Os, we explore a new contraction-expansion based approach. In the graph contraction phase, instead of contracting the whole graph as the contraction based approach, we only contract the nodes of a graph, which are much more selective. The contraction phase stops when all nodes of the graph can fit in the main memory, such that the semi-external algorithm can be used in SCC computation. In the graph expansion phase, as the graph is expanded in the reverse order as it is contracted, the SCCs of all nodes in the graph are computed. Both graph contraction phase and graph expansion phase use only I/O efficient sequential scans and external sorts of nodes/edges in the graph. Our algorithm leverages the efficiency of the semi-external SCC computation algorithm and usually stops in a small number of iterations. We further optimize our approach by reducing the size of nodes and edges of the contracted graph in each iteration. We conduct extensive experimental studies using both real and synthetic web- scale graphs to confirm the I/O efficiency of our approaches.



I. INTRODUCTION Graph is an important data structure to model complex  relationships among entities. A road network, a social network, and the entire WWW can be modelled as graphs, and all such graphs are huge. In this paper, we study the problem of strongly connected component (SCC) computation, which is a fundamental graph operation on directed graphs. Here, an SCC is a maximal subgraph S for a given directed graph G, such that for every pair of nodes u and v in S, there is a directed path from u to v in S and there is also a directed path from v to u in S.

Computing SCCs on large graphs is highly demanded by  many real applications that need topological sort, reachability  query processing, and graph pattern matching in graph pro- cessing. (1) Topological sort is widely used in many applica- tions especially in planning and scheduling. In a topological sort, nodes in a directed graph are ranked according to a partial order specified by the edges. If there are cycles in the graph, all nodes in a cycle are considered as equal rank and are merged into one node. This is done by finding all SCCs in the graph. In [16], Hellings et al. propose an efficient algorithm for external bisimulation on graphs, where all nodes are assumed to be in the reverse topological order and stored on disk. This needs to find all SCCs in a preprocessing step. (2) Reachability query is a widely studied query to ask whether a node u can reach another node v through a directed path in a directed graph. There are many applications in social networks, biological networks, software analysis, and semantic web.

Because two nodes in an SCC are reachable from each other, in the literature, almost all algorithms to process reachability queries over a general directed graph G first convert G into a directed acyclic graph (DAG) by contracting an SCC into a node, which needs to find all SCCs in a prepossessing step, such as [25]. (3) Pattern matching in XML data and graph data has been widely studied. Computing SCCs is an optimization technique to compress a large graph for processing pattern matching queries [15].

In the literature, there are efficient in-memory and I/O  efficient semi-external algorithms to compute all SCCs of a directed graph G. An in-memory algorithm requires G to reside entirely in memory and a semi-external algorithm requires all nodes of G to reside entirely in memory. For the in-memory algorithm, the Kosaraju-Sharir algorithm [3] can find all SCCs for a directed graph in linear time w.r.t. the size of the graph, by depth first searching the graph twice in memory. For the semi-external algorithm, Zhang et al. [26] propose an I/O efficient algorithm to compute all SCCs by constructing a special in-memory spanning tree of G using sequential scans of the graph on disk. However, due to the fact that the sizes of many real large graphs keep growing rapidly, even the nodes of a graph cannot reside entirely in the main memory. For example, the social network graph in Facebook contains 1.11 billion active nodes and more than 150 billion edges.1 As a small part of the entire web graph, WEBSPAM-  1http://newsroom.fb.com/     UK20072 contains 105,896,555 pages and 4 billion edges in 114,529 hosts in the .UK domain in May 2007.

In order to handle a graph G(V,E) where V cannot fit  entirely in memory M , a naive way to externalize the in- memory DFS requires O(|E|) I/Os. Chiang et al. [10] propose an algorithm with I/O complexity O(|V |+ |V |  M ? scan(|E|) +  sort(|E|)). Later, Kumar and Schwabe [17] and Buchsbaum et al. [8] improve the I/O complexity to O((|V |+ |E|  B )?log2 |V |B  +sort(|E|)) by maintaining the nodes that should not be traversed using tournament trees [17] and buffered repository trees [8] respectively, where B is the disk block size. Despite their theoretical guarantees, these algorithms are considered impractical for general directed graphs that encountered in real applications, due to the large number of random I/Os generated. Cosgaya-Lozano et al. [13] study a heuristic ex- ternal algorithm to compute all SCCs for a directed algorithm based on contraction used by Chiang et al. [10] which is for undirected graphs. But, for directed graphs, the algorithm may end up an infinite loop and cannot compute all SCCs.

In this paper, we study external algorithms for SCC com-  putation. The main contributions of this work are summarized below. Firstly, we analyze the deficiency of the existing DFS based algorithm [8] that consumes a large number of random I/Os and the contraction based algorithm [13] that needs large number of iterations and may end up an infinite loop.

Secondly, we propose a new two-phase algorithm with graph contraction followed by graph expansion. In graph contraction, we only contract the number of nodes of the graph with bounded number of new edges generated. We stop when all nodes can fit in the main memory and process the contracted graph using an I/O efficient semi-external algorithm. Using nodes contraction, the number of iterations can be significantly reduced comparing to [13]. In graph expansion, the removed nodes are put back into the graph in a reverse order of their removal, while the SCCs of all nodes are computed.

We analyze the I/O cost of our approach and show that our algorithm can significantly reduce the number of random I/Os comparing to [8]. Thirdly, we introduce techniques to further reduce the I/O cost of our algorithm by reducing the number of nodes and edges generated in each iteration of graph contraction. Finally, we conduct extensive experimental studies using both real and synthetic web-scale graphs to confirm the I/O efficiency of our approaches.

The remainder of this paper is organized as follows. In  Section II, we discuss the preliminaries and give the problem statement for computing SCCs. In Section III, we discuss ex- isting solutions on both external and semi-external algorithms for computing SCCs. In Section IV, we analyze the deficiency of existing external approaches and outline our two-phase approach with graph contraction followed by graph expansion.

We introduce the graph contraction phase in Section V and discuss the graph expansion phase in Section VI. We study optimization techniques to further reduce the I/O cost of our algorithm in Section VII. In Section VIII, we report our  2http://barcelona.research.yahoo.net/webspam/datasets/uk2007/  a b  c  d g  e f h  l  i k  j  mscc1 scc2  Fig. 1. A Graph G with 2 SCCs  experimental results. We discuss the related work in Section IX and conclude the paper in Section X.



II. PROBLEM DEFINITION  We model a directed graph as G(V,E), where V (G) represents the set of nodes and E(G) represents the set of directed edges in G. For simplicity, we also use V and E to denote V (G) and E(G) respectively, when it is obvious. Each node v ? V (G) has a unique identity in G, denoted by id(v), which specifies a unique total order among all nodes in G.

For each node v ? V (G), we use nbrin(v,G) to denote  the set of in-neighbors of v in G, and we use nbrout(v,G) to denote the set of out-neighbors of v in G. We use nbr(v,G) to denote the set of in-neighbors and out-neighbors of v in graph G. We have nbrin(v,G) = {u|(u, v) ? E(G)}, nbrout(v,G) = {u|(v, u) ? E(G)} and nbr(v,G) = nbrin(v,G)?nbrout(v,G). We use degin(v,G), degout(v,G), and deg(v,G) to denote the in-degree, out-degree and to- tal degree of a node v ? V (G) respectively. We have degin(v,G) = |nbrin(v,G)|, degout(v,G) = |nbrout(v,G)| and deg(v,G) = |nbr(v,G)|.

Given a graph G(V,E), a vertex cover of G is a subset  V ? ? V such that if (u, v) ? E, then either u ? V ? or v ? V ?.

In other words, each vertex covers its incident edges and a vertex cover of G is a set of vertices that covers all E(G) [12]. It is trivial that any superset for a vertex cover is still a vertex cover. A minimum vertex cover is a vertex that has the minimum set cardinality among all the vertex covers of G.

Given a graph G, a path p = (v1, v2, ? ? ? , vk) is a sequence  of k nodes in V such that, for each vi(1 ? i < k), (vi, vi+1) ? E. A node vi can reach a node vj in G, denoted vi ? vj , iff there exists a path from vi to vj in G. A node vi cannot reach a node vj in G, denoted vi ? vj , iff there exists no path from vi to vj in G. A node vi is strongly connected to a node vj , denoted as vi ? vj , iff vi ? vj and vj ? vi in G. Here, ? is an equivalence relation, which is reflexive, symmetric, and transitive. We use vi ? vj to denote that node vi is not strongly connected to node vj . A strongly connected component (SCC) of G is the maximal set of nodes Vs (? V ) such that, for every pair of nodes vi and vj in Vs, vi ? vj , and for every pair of nodes vi and vk where vi ? Vs and vk ?? Vs, vi ? vk. Each SCC of G has a unique identity. For each node v ? V (G), we use SCC(v,G) to denote the SCC that v belongs to. For any two nodes u ? V (G) and v ? V (G), u ? v ? SCC(u,G) = SCC(v,G). For any set of nodes S ? V (G), we use SCC(S,G) to denote the set of SCCs that     Algorithm 1 DFS-SCC(G) Input: a directed graph G(V,E).

Output: all the SCCs in G.

1: T ? DFS-Tree(G); 2: sort V (G) in decreasing postorder by traversing T ; 3: construct a graph G from G by reversing every edge in G, where V (G) = V (G) (with the same postorder);  4: TS ? DFS-Tree(G); 5: output that all nodes in a subtree of the virtual node v0 of TS forms an SCC;  nodes in S belong to, i.e., SCC(S,G) = {SCC(v,G)|v ? S}.

Example 2.1: Fig. 1 shows a graph G with 13 nodes and 20 edges. For nodes b and e, b ? e since b ? e through path (b, c, d, e) and e ? b through path (e, f, g, b). There are 2 SCCs, SCC1 and SCC2, where SCC1 = {b, c, d, e, f, g} and SCC2 = {i, j, k, l}. ? In this paper, we assume that the graph G cannot reside  entirely in the main memory. For all I/O operations, we follow the standard I/O model in [2]. We use M to denote the size of the main memory and use B to denote the size of each block on disk. All data are read/written in blocks. We assume M ? 2?B. We use sort(m) to denote the I/O cost of external sorting m elements on disk and we use scan(m) to denote the I/O cost of sequentially scanning all m elements once on disk. In the I/O model [2], we have scan(m) = ?(m  B ), and  sort(m) = ?(m B ? logM  B  m B ).

Problem Statement: compute all strongly connected compo- nents (SCCs) for a large directed graph G(V,E) with limited memory M . Here 2 ? B ? M < ?G? where B is the block size and ?G? is the space for the entire graph G.



III. EXISTING SOLUTIONS In the literature, there are two external algorithms and two  semi-external algorithms to compute all SCCs for a directed graph G. A semi-external algorithm assumes that all nodes of the graph can reside entirely in the main memory, i.e., M ? c ? |V | for a constant c, and an external algorithm only assumes that at least two disk blocks can fit in the main memory, i.e., M ? 2?B. The two external algorithms are based on contraction [13] and external depth first search (DFS) [8] respectively, and the two semi-external algorithms are based on semi-external DFS [23] and a special spanning tree BR-Tree of G respectively [26].

Contraction Based EM-SCC: Cosgaya-Lozano et al. [13] provide a heuristic algorithm, called EM-SCC, to compute all SCCs for a large directed graph. The idea is taken from the contraction-based algorithm to compute all connected compo- nents for an undirected graph [10]. Given limited memoryM , EM-SCC compresses a graph iteratively by contraction until the graph can fit in M . In brief, it processes G in iterations, G = G0, G1, G2, ? ? ? , Gf . In the i-th iteration, EM-SCC contracts some partial SCCs into a node and compresses Gi to be a smaller Gi+1. The last Gf must fit in M . In the i-th iteration (i < f ), Gi cannot fit in M . EM-SCC partitions Gi into smaller partitions, Gi1 , Gi2 , ? ? ? where Gij can fit in M .

EM-SCC computes SCCs using an in-memory algorithm for Gij , and compresses Gi by contracting an SCC in Gij into a node.

Unlike the algorithm [10] which ensures an undirected graph G can fit into main memory in a log number of iterations, EM-SCC cannot stop in a finite number of iterations for directed graphs in the following cases to compute all SCCs.

(Case-1) An SCC of Gi appears across a number of partitions, and the partitions cannot be further compressed by contraction.

(Case-2) Gi is a directed acyclic graph, but cannot fit in M .

When G contains a large SCC or a large number of small/mid sized SCCs, the probability of Case-1 to happen is high. When G is a DAG-liked graph, the probability of Case-2 to happen is high. Either case happens frequently in real world graphs.

Depth First Search Based DFS-SCC: DFS-SCC computes all SCCs by simulating the in-memory Kosaraju-Sharir algorithm [3] which traverses the graph G twice using depth first search.

The framework of DFS-SCC is shown in Algorihtm 1. In the first time traversal, it obtains a decreasing postorder of nodes over the DFS tree obtained by DFS-Tree(G) (lines 1-2). It then constructs a graph G by reversing every edge in G (line 3).

Because V (G) = V (G), with the same decreasing postorder, it calls DFS-Tree(G) again to obtain a new DFS tree TS (line 4).

Here, all nodes in a subtree rooted at a child of the virtual node v0 of TS are in the same SCC. The key operation of DFS-SCC is DFS-Tree which constructs a DFS tree for a graph G.3 Thus, we introduce existing external DFS algorithms below.

In the literature, external DFS algorithms are proposed by  Kumar et al. [17] and Buchsbaum et al. [8]. [8] is an improve- ment for [17]. The basic idea of [8] is to simulate the internal memory DFS algorithm by maintaining the visited nodes using an augmented external (2,4)-tree, called buffer repository tree (BRT). The I/O complexity for DFS using the algorithm in [8] is O((|V |+ |E|  B ) log2  |V | B  + sort(|E|)). Comparing to the trivial external memory DFS which consumes O(|E|) I/Os, the algorithm in [8] does not improve significantly especially on sparse graphs [5], and a large number of random I/Os are generated by the algorithm in [8]. Thus, computing SCCs based on external DFS is not I/O efficient.

Example 3.1: Consider G in Fig. 1. The first DFS tra- verses G in abcdefgijklmh, and its decreasing postorder is abcdefhgijmkl. With the decreasing postorder, in the second DFS, the root v0 of the DFS tree has 5 subtrees representing 5 SCCs {a},{b, c, d, e, f, g},{h},{i, j, k, l}, and {m}. ? Semi-External Approach Semi-SCC: Since there is no ef- ficient external algorithm to compute all SCCs for a graph G in the literature, some papers focus on semi-external al- gorithms by relaxing the condition 2 ? B ? M < ?G? to c ? |V | ? M < ?G?, where c is a constant. Following the framework in Algorithm 1, a semi-external algorithm can be designed by applying semi-external DFS [23] when generating the DFS tree (line 1 and line 4). In [23], given a graph G, a spanning tree T of G is maintained in memory using O(|V |) space. The algorithm iteratively scans the edges of G on disk and updates T until T becomes a DFS tree. The semi-external  3We do not need to construct a DFS tree explicitly. We only need to obtain the DFS order of all nodes in the graph.

Graph Contration  Graph Expansion  G1 G2 G3 G4  G4G3G2G1  Fig. 2. A Solution Overview  DFS algorithm in [23] is much more efficient than the external DFS algorithm in [8]. However, it is not optimized for SCC computation using the Kosaraju-Sharir algorithm (Algorithm 1). This is because Algorithm 1 needs to maintain a total order (decreasing postorder) of nodes in the first DFS (line 1-2), to be used in the second DFS (line 4). As a result, in the first DFS, nodes cannot be contracted or removed even if partial SCCs have been found.

In order to improve the semi-external DFS based approach  using Algorithm 1, Zhang et al. [26] develop a more efficient semi-external algorithm to compute all SCCs, by defining a weaker order based on the depth of a node in a spanning tree (BR-Tree) of G. Using the weaker order, only one BR-Tree needs to be constructed in memory. The algorithm iteratively scans the edges of G on disk and updates the BR-Tree until no new SCC can be found. When updating the BR-Tree, each partial SCC can be contracted into one node, and nodes that will not contribute to any new SCCs can be removed from G.

The I/O cost to compute all SCCs is largely reduced.

Although Semi-SCC is much more efficient than external  DFS and external contraction based approaches, it assumes that M ? c? |V |. In this paper, we aim to design an efficient external algorithm to compute SCCs when M < c? |V |.



IV. A NEW CONTRACTION-EXPANSION APPROACH  Given that the contraction based EM-SCC may end up infinite iterations, and the DFS based DFS-SCC can generate a large number of random I/Os. In this paper, we propose a novel contraction-expansion based external algorithm to compute all SCCs for a graphG. Instead of accessing each node one by one in EM-SCC, our algorithm computes the SCCs of all nodes in batches in order to reduce the number of random I/Os used to access each node. Our algorithm is processed in two phases, namely, graph contraction and graph expansion.

In the graph contraction phase, a list of graphs G1, G2, ? ? ? ,  Gl are generated, where G1 = G, and for each 1 ? i < l, Gi+1 is generated by removing a batch of nodes from Gi, i.e., V (Gi+1) ? V (Gi). It stops until all nodes of the graph can fit in memory, i.e., c?|V (Gl)| ?M for a constant c. In other words, SCCs of Gl can be computed using Semi-SCC.

In the graph expansion phase, after computing all SCCs  of Gl using Semi-SCC, the removed nodes are added back to the graph in the reverse order of their removal in the graph contraction phase, i.e., the lastly removed nodes in the graph contraction phase are firstly added back in the graph expansion phase. When a node is added back, the SCC it belongs to is computed. More specifically, given that all  Algorithm 2 Ext-SCC(G) Input: a directed graph G(V,E).

Output: all the SCCs in G.

1: G1(V1, E1)? G(V,E); i? 1; 2: while Vi can not fit in memory do 3: contract Gi(Vi, Ei) to Gi+1(Vi+1, Ei+1) with Vi+1 ? Vi; 4: i? i + 1; 5: compute all SCCs in Gi(Vi, Ei) using Semi-SCC; 6: while i > 1 do 7: i? i? 1; 8: compute SCCs for all nodes in Vi ? Vi+1; 9: combine SCCs in Vi ? Vi+1 with SCCs in Vi+1; 10: output all SCCs in V1;  SCCs of Gl are computed using Semi-SCC, we compute the SCCs for nodes V (Gl?1) ? V (Gl), V (Gl?2) ? V (Gl?1), ? ? ? , V (G1) ? V (G2) in order. Since V (G) = V (G1) = V (Gl) ? (V (Gl?1)?V (Gl)) ? (V (Gl?2)?V (Gl?1)) ? ? ? ? (V (G1)?V (G2)), the SCCs for all nodes are computed after graph expansion.

The two phases are illustrated in Fig. 2 where gray parts  represent the nodes whose SCCs are computed. Our algorithm Ext-SCC to compute all SCCs in a graph G is shown in Algorithm 2. Initially, G1 = G and i = 1 (line 1). The graph contraction phase is shown in line 2-4. It iteratively generates a new graph Gi+1 based on Gi with a smaller number of nodes and stops when the nodes of the graph can fit in the main memory. The graph expansion phase is shown in line 5- 9. It first computes all SCCs of V (Gi) using the semi-external algorithm Semi-SCC (line 5). Then it iteratively computes all SCCs for nodes V (Gi)?V (Gi+1) with decreasing order of i (line 6-9). Finally, all SCCs of V (G1) are output sinceG1 = G (line 10).

Below, we analyze the deficiencies of the existing external  DFS based DFS-SCC algorithm and external contraction based EM-SCC algorithm, comparing to our Ext-SCC algorithm.

For DFS-SCC, as introduced in Section III, the I/O com-  plexity of the algorithm is O((|V |+ |E| B ) log2  |V | B  +sort(|E|)), which is higher than O(|V |). The high I/O cost is produced by the large number of random accesses when visiting nodes one by one on disk, and it is costly to access each node using one random disk access. In our algorithm, instead of processing nodes one by one, we process the nodes of G in batches. As shown in Algorithm 2, we contract the graphGi by removing a batch of nodes V (Gi)?V (Gi+1) with increasing i in the graph contraction phase, and add the removed nodes back to compute the SCCs for each batch of removed nodes in a reverse order in the graph expansion phase. As we will show later, both the graph contraction phase and the graph expansion phase are processed using only sequential scans and external sorts. In such a way, all nodes/edges of the graph can be processed in blocks and the number of random accesses is minimized.

For EM-SCC, it is a contraction based algorithm with some  critical problems as introduced in Section III. Our contraction- expansion based algorithm Ext-SCC can solve the problems.

Firstly, EM-SCC may not be able to terminate. In our Ext-SCC algorithm, when generating Gi+1 from Gi, we make sure that V (Gi+1) is a proper subset of V (Gi) by removing a batch of nodes from V (Gi). Thus, our algorithm can always terminate.

Furthermore, our stop condition only requires that all nodes V (Gi) can fit in the main memory, which is usually much smaller than the size of the whole graphGi. Our stop condition is easier to be satisfied comparing to EM-SCC which requires the whole graph Gi to fit in the main memory. Secondly, even if EM-SCC can terminate in a finite number of iterations, the contraction is unstable since it relies largely on the order of edges stored on disk. It is possible that only a small number of nodes are contracted in each iteration. In our Ext- SCC algorithm, the selection of nodes to be removed in each iteration does not rely on the order of edges stored on disk, and thus our algorithm is much more stable than EM-SCC.

As confirmed in our experiments, our algorithm can usually terminate in a small number of iterations.

In the following, we discuss the two phases, and propose  techniques to further minimize the I/O cost.



V. GRAPH CONTRACTION  In this section, we introduce how to contract a graph Gi+1 from graphGi. As introduced before, when constructingGi+1, we should make sure that the nodes of Gi+1 is a proper subset of Gi by removing at least one node from Gi, i.e., V (Gi+1) ? V (Gi). In order to reduce the number of iterations, the number of nodes to be removed in each iteration should be as large as possible. However, the nodes to be removed in each iteration i cannot be arbitrarily selected. In order to make sure that all SCCs can be computed correctly, for each graph Gi, the newly contracted graphGi+1 should satisfy the following three properties.

? (Contractible): The number of nodes in the contracted graph Gi+1 should be smaller than the number of nodes in Gi, i.e., V (Gi+1) ? V (Gi).

? (SCC-preservable): For any two nodes u ? V (Gi+1) and v ? V (Gi+1), u and v are in the same SCC in Gi+1 iff u and v are in the same SCC in Gi, i.e., SCC(u,Gi+1) = SCC(v,Gi+1)? SCC(u,Gi) = SCC(v,Gi).

? (Recoverable): If a node v ? V (Gi) is removed when constructing Gi+1 from Gi, the connectivity of v to other nodes in Gi+1 can be recovered using only v?s neighbors in Gi+1. In other words, if v is absent in V (Gi+1), all v?s neighbors should be in V (Gi+1), i.e., v ? V (Gi) ? V (Gi+1)? nbr(v,Gi) ? V (Gi+1).

In the following, given a graph Gi(Vi, Ei), we introduce how to construct the nodes Vi+1 of Gi+1 and edges Ei+1 of Gi+1 respectively. We will show that by constructing Vi+1, the contractible and recoverable properties are satisfied, and by constructing Ei+1, the SCC-preservable property is satisfied.

To construct Vi+1: Given Gi(Vi, Ei), we first investigate the properties of Vi+1. We start from the recoverable property, i.e., for any v ? Vi ? Vi+1, nbr(v,Gi) ? Vi+1. Consider an arbitrary edge (u, v) ? Ei, if v /? Vi+1, i.e., v ? Vi ? Vi+1, then u ? Vi+1, since u ? nbr(v,Gi). Similarity, if u /? Vi+1 then v ? Vi+1. In other words, for any edge (u, v) ? Ei, either v ? Vi+1 or u ? Vi+1. We have the following lemma.

Lemma 5.1:Gi+1 is recoverable if and only if Vi+1 is a vertex cover of Gi. ?  Algorithm 3 Get-V(Gi) Input: a directed graph Gi(Vi, Ei) to be contracted.

Output: the nodes of the contracted graph Vi+1 sorted by node ids.

1: Vi+1 ? ?; 2: Ein ? edges (u, v) ? Ei order by (id(v), id(u)); 3: Eout ? edges (u, v) ? Ei order by (id(u), id(v)); 4: Vd ? nodes (v, deg(v, Gi)) for all v ? Vi order by id(v) by Ein ? Eout; 5: Ed ? edges (u, deg(u,Gi), v) order by id(u) by Eout ? Vd; 6: Ed ? edges (u, deg(u,Gi), v) order by id(v) by sorting Ed; 7: Ed ? edges (u, deg(u,Gi), v, deg(v, Gi)) order by id(v) by Ed ? Vd ; 8: for all (u, deg(u,Gi), v, deg(v,Gi)) ? Ed do 9: Vi+1 ? Vi+1 ? {u > v?u : v} 10: sort nodes in Vi+1 and eliminate duplicate nodes; 11: return Vi+1;  Proof Sketch: The lemma can be derived easily from the above discussion. ? In order to reduce the number of iterations in the Ext-  SCC algorithm, the cardinality of Vi+1 should be as small as possible. This leads to the minimum vertex cover problem which is NP-hard [3]. In the literature, a lot of approximate algorithms have been developed to find the vertex cover of a graph G. When the graph G cannot fit in the main memory, there are semi-external and external algorithms to find an ap- proximate minimum vertex cover for a graph G. For the semi- external algorithm, in [9], James et al. develop a streaming algorithm to find a vertex cover with the approximation ratio 2, by maintaining an in-memory hash table H . However, since |H | = O(|V (G)|) in the worst case, the algorithm cannot be used directly in constructing Vi+1. For the external algorithm, in [7], an algorithm is introduced to find a vertex cover with an approximation ratio  ? ?(G)  2 + 2 , where ?(G) is the maximum  degree of nodes in G, i.e., ?(G) = max{deg(v)|v ? V (G)}.

In the algorithm, an operator > is defined among all nodes in G as follows.

Definition 5.1: (Operator >): For any u ? V (G) and v ? V (G), u > v iff either of the following two conditions holds.

(1) deg(u,G) > deg(v,G). (2) deg(u,G) = deg(v,G) and id(u) > id(v). The > operator specifies a unique total order among all nodes in the graph G. ?  Using the > operator, given a graph G, the algorithm in [7] scans all edges of G on disk sequentially. For each edge (u, v) scanned, if u > v, then u is added to the vertex cover, otherwise, v is added to the vertex cover.

In this paper, given Gi(Vi, Ei), we adapt the external  algorithm in [7] to construct Vi+1. We will further reduce the size of Vi+1 in Section VII. The basic algorithm to compute Vi+1 is shown in Algorithm 3. After initializing Vi+1 to be ? (line 1), two edge lists are created on disk, Ein and Eout, by grouping incoming edges and out-going edges for each node in Gi respectively using external sort (line 2-3). Since all edges are sorted in Ein and Eout, the degrees of all nodes in Gi can be computed in Vd by joining Ein and Eout using a single sequential scan of Ein and Eout (line 4). Next, we create another edge list Ed with degree information of both nodes augmented on each edge, for the ease of comparison of nodes using the > operator. Ed can be created in three steps.

Firstly, by joining Eout and Vd using a sequential scan, the degree of node u can be augmented into each edge (u, v) in Ed     (line 5). Secondly, Ed is sorted by the non-augmented node of each edge (line 6). Thirdly, by joining Ed and Vd using a sequential scan, the degree of node v can be augmented into each edge (u, v) in Ed (line 7). After creating Ed, we only need to scan edges in Ed sequentially once, and for each edge scanned, add the larger node compared by the > operator into Vi+1 (line 8-9). Since Vi+1 may contain duplicate nodes, we sort Vi+1 by node ids and eliminate duplicate nodes by scanning Vi+1 once sequentially (line 10).

Lemma 5.2: The set Vi+1 computed in Algorithm 3 is recov- erable and contractible. ?  Proof Sketch: Since Algorithm 3 computes a vertex cover Vi+1 of Gi, from Lemma 5.1, Vi+1 computed in Algorithm 3 is recoverable. Next, we prove that Vi+1 is contractible. We only need to prove that there exists a node v such that v ? Vi and v /? Vi+1. By Definition 5.1, the operator > specifies a unique total order among all nodes in Gi. Let v be the smallest node in the total order defined by the operator >, v cannot be added into Vi+1, because there does not exits an edge (u, v) or an edge (v, u) with u > v. Thus the lemma holds. ?  Theorem 5.1: The I/O complexity of Algorithm 3 is O(sort(|Ei|) + sort(|Vi|)). ? Proof Sketch: Omitted due to lack of space. ?  To construct Ei+1: Given a graph Gi(Vi, Ei) and the node set Vi+1 of the contracted graph Gi+1, we construct the edges Ei+1 of the contracted graph Gi+1. Since Vi+1 is constructed in a way such that the contractible and recoverable properties are satisfied, Ei+1 needs to be constructed that maintains the SCC-preservable property. In other words, after constructing Ei+1, for any two nodes u ? Vi+1 and v ? Vi+1, if u and v are in the same SCC in Gi, then u and v should be in the same SCC in Gi+1, and vice versa. Note that by removing a node v from Gi, for any two nodes u and w in Vi+1, if u can only reach w through v in Gi, then the connectivity of u and w is destroyed after the removal of node v. In order to maintain such connectivity in Gi+1, new edges need to be added after the removal of v. Suppose u can reach w through a path (u ? ? ? vin, v, vout, ? ? ?w) in Gi, where vin ? nbrin(v,Gi) and vout ? nbrout(v,Gi), after the removal of v, we can add a new edge (vin, vout) in Ei+1, such that u can still reach w through a path (u ? ? ? vin, vout, ? ? ?w) in Gi+1. In order to do this, we need to make sure that both vin and vout are in Gi+1.

It is true because Vi+1 maintains the recoverable property such that for each removed node v, i.e., v ? Vi ? Vi+1, all its neighbors in Gi are in Vi+1, i.e., nbr(v,Gi) ? Vi+1.

An algorithm to construct Ei+1 can be designed as follows.

For each node v ? Vi ? Vi+1, and each pair of nodes vin ? nbrin(v,Gi) and vout ? nbrout(v,Gi), remove the edge (vin, v) and (v, vout), and add a new edge (vin, vout) in Ei+1.

By doing this, for any pair of nodes u ? Vi+1 and w ? Vi+1, if u can reach w in Gi, u can still reach w in Gi+1. The edges are constructed to ensure that no connectivity of node pairs will be destroyed. We will prove it that the construction will introduce no new connectivity information among all nodes in  Algorithm 4 Get-E(Gi, Vi+1) Input: a directed graph Gi(Vi, Ei) to be contracted,  the nodes of the contracted graph Vi+1 sorted by node ids.

Output: the edges of the contracted graph Ei+1.

1: Ein ? edges (u, v) ? Ei order by (id(v), id(u)); 2: Eout ? edges (u, v) ? Ei order by (id(u), id(v)); 3: Edel ? edges (u, v) ? Ei for v ? Vi?Vi+1 order by id(v) by Vi+1 ? Ein; 4: Edel ? edges (u, v, nbrout(v,Gi)) for v ? Vi ? Vi+1 ordered by id(v) by  Edel ? Eout; 5: Eadd ? ?; 6: for all edge (u, v) ? Edel do 7: for all w ? nbrout(v,Gi) by sequential scan of Edel do 8: Eadd ? Eadd ? (u, w); 9: Epre ? edges (u, v) ? Ei for u ? Vi+1 order by id(u) by Vi+1 ? Eout; 10: Epre ? edges (u, v) ? Ei for u ? Vi+1 order by id(v) by sorting Epre; 11: Epre ? edges (u, v) ? Ei for u ? Vi+1 and v ? Vi+1 order by id(v) by  Vi+1 ? Epre; 12: Ei+1 ? Epre ? Eadd; 13: return Ei+1;  Vi+1.

Algorithm 4 shows how to construct Ei+1 externally, given  Gi(Vi, Ei) and Vi+1. As discussed above, Ei+1 consists of two parts, namely, the preserved edges in Gi with both ends in Vi+1, denoted Epre, and the newly added edges by removing nodes from Gi, denoted Eadd. Let Ein and Eout be the edges of Gi by grouping incoming and out-going edges for each node in Gi respectively, which are the same as those used in Algorithm 3 (line 1-2), Algorithm 4 constructs Eadd in line 3- 8 and constructs Epre in line 9-11, and union Eadd and Epre to construct Ei+1 (line 12-13).

In order to construct Eadd, the algorithm first identifies the  set of incoming edges to be removed, denoted Edel, by joining Vi+1 and Ein using a single sequential scan of Vi+1 and Ein on disk (line 3). When scanning Vi+1 and Ein, for each edge (u, v) ? Ein, if v /? Vi+1, then (u, v) is added to Edel. After constructing the removed incoming edges, we augment the out-neighbors of v into each incoming edge (u, v) ? Edel.

This can be done using a single sequential scan of Edel and Eout (line 4). Line 5-8 constructEadd using a single sequential scan of all edges in Edel. In Edel, for each node v that is removed from Gi, each of its in-neighbors u in Gi is stored as an edge (u, v), and its out-neighbors nbrout(v,Gi) is also augmented in the edge (u, v) with form (u, v, nbrout(v,Gi)).

When accessing each removed incoming edge (u, v) of v (line 6), the removed out-going edge (v, w) of v can be accessed in the same sequential scan of Edel (line 7), and a new edge (u,w) is added into Eadd (line 8).

The preserved edges Epre can be constructed in three steps.

Firstly, by joining Vi+1 and Eout using a sequential scan, all edges (u, v) with u ? Vi+1 can be preserved in Epre (line 9).

Secondly, we sort Epre such that all edges (u, v) ? Epre are sorted by id(v) (line 10). Thirdly, by joining Vi+1 and Epre using a sequential scan, all edges (u, v) with u ? Vi+1 and v ? Vi+1 can be preserved in Epre (line 11).

Lemma 5.3: The edge set Ei+1 constructed by Algorithm 4 is SCC-preservable. ? Proof Sketch: We only need to prove for any nodes u ? Vi+1 and w ? Vi+1, u? w in Gi ? u? w in Gi+1.

To prove?, for any path p from u to w in Gi, we can find  a path from u to w in Gi+1 as follows. For each node v on     f i  g c  b a l  ki  j hf  d g  f  g  i  c k  m e  c  ki  f e  b l  j  G3 G4G2G1  g  Fig. 4. Graph Contraction Example  ...

...

...

...

u  u  vin v vout w  vin  v  vout w  Gi ? Gi+1  Gi+1 ? Gi  Fig. 3. Paths in Gi and Gi+1  path p with v /? Vi+1, let vin and vout be the predecessor and successor of v on path p, remove edge (vin, v) and (v, vout) from path p and add a new edge (vin, vout) on p. From the construction of Ei+1, we have (vin, vout) ? Ei+1. The new path p is a path onGi+1. The construction process is illustrated in the upper part of Fig. 3.

To prove ?, for any path p from u to w in Gi+1, we  can find a path from u to w in Gi as follows. For each edge (vin, vout) on path p, if (vin, vout) is a newly added edge, from the construction of Ei+1, there exists a node v ? Vi such that (vin, v) ? Ei and (v, vout) ? Ei. We remove (vin, vout) from p and add two new edges (vin, v) and (v, vout) on p. The new path p is a path on Gi. The construction process is illustrated in the lower part of Fig. 3. ?  Theorem 5.2: The I/O complexity of Algorithm 4 is O(sort(|Ei|) + scan(Vi+1) + scan(|Ei+1|)). ? Proof Sketch: Omitted due to lack of space. ?  Bounding Edge Size |Ei+1|: From the above discussion, when a node v is removed from Gi when constructing Gi+1, degin(v,Gi)?degout(v,Gi) new edges are added into Ei+1. When deg(v,Gi) is large, the number of newly added edges can be very large. However, from the construction of Vi+1, a node v is removed only if for all u ? nbr(v,Gi), deg(u,Gi) ? deg(v,Gi). Thus, the degree of any removed node cannot be too large. The following two theorems give an upper bound of the degree for any removed node v, and an upper bound of the number of new edges in Ei+1 respectively.

Theorem 5.3: ?v ? Vi ? Vi+1, deg(v,Gi) ? ? 2? |Ei|. ?  Proof Sketch: For any v ? Vi ? Vi+1 and u ? nbr(v,Gi), we have deg(u,Gi) ? deg(v,Gi). The total degrees of all nodes in nbr(v,Gi) is  ? u?nbr(v,Gi)  deg(u,Gi) ? 2 ? |Ei|, since each edge in Ei is counted at most twice in the summation. We also have  ? u?nbr(v,Gi)  deg(u,Gi) ?? u?nbr(v,Gi)  deg(v,Gi) = deg(v,Gi) 2. Thus deg(v,Gi)2 ?  2? |Ei|. Theorem 5.3 holds. ? Theorem 5.4: The number of new edges in Ei+1 is bounded by ?i ? |Ei|, where ?i is the arboricity [11] of graph Gi. ?  Proof Sketch: By the construction of Ei+1, the number of new edges in Ei+1 is  ?v?Vi?Vi+1degin(v,Gi)? degout(v,Gi)  ? ?v?Vi?Vi+1degin(v,Gi)? deg(v,Gi)  = ?v?Vi?Vi+1?u?nbrin(v,Gi)deg(v,Gi)  = ?v?Vi?Vi+1?u?nbrin(v,Gi) min{deg(v,Gi), deg(u,Gi)}  ? ?v?Vi?u?nbrin(v,Gi) min{deg(v,Gi), deg(u,Gi)}  = ?(u,v)?Ei min{deg(v,Gi), deg(u,Gi)}.

(1)  According to [11], ?  (u,v)?Ei min{deg(v,Gi), deg(u,Gi)} ?  ?i ? |Ei| for any graph Gi. ? As proved in [11], ?i ? min{?  ?|Ei|?, degmax} for any graph Gi, where degmax is the maximum degree for all nodes in Gi. In practice, ?i is usually small. For example, ?i = O(1) if Gi is a planar graph. Note that in Theorem 5.4, the upper bound ?i ? |Ei| is very loose, since it ampli- fies ?v?Vi?Vi+1?u?nbrin(v,Gi) min{deg(v,Gi), deg(u,Gi)} to ?v?Vi?u?nbrin(v,Gi) min{deg(v,Gi), deg(u,Gi)} in the second ? of Eq. (1), and as analyzed in Theorem 5.3, the set Vi ? Vi+1 only contains nodes with small degrees in Gi. In section VII, we propose techniques to further reduce |Ei+1|, and in our experiments, it is even possible that |Ei+1| < |Ei| for a certain graph Gi.

Example 5.1: Fig. 4 shows the graph contraction phase for G in Fig. 1. The grey nodes in each Gi are the set of nodes preserved in Gi+1, and the dashed edges in each Gi are the newly added edges when constructingGi fromGi?1. InG1 (= G), node b is preserved in V2, since there is an edge (a, b) with deg(b,G1) > deg(a,G1), thus b > a by operator > defined in Definition 5.1. d ? V1 ? V2 because for its two neighbors c and e, c > d and e > d. After removing d, a new edge (c, e) is added in G2 since c ? nbrin(d,G1) and e ? nbrout(d,G1). Using such a way, the newly constructed G2 has 9 nodes and 14 edges by removing parallel edges and self circles. In a similar way, G3 can be constructed from G2 with |V3| = 5 and |E3| = 8. G4 can be constructed from G3 with |V4| = 3 and |E4| = 4. Suppose the main memory can only keep three nodes. The graph contraction phase stops after G4 is constructed, since G4 can be processed using Semi-SCC.

?

VI. GRAPH EXPANSION The graph contraction phase stops when all nodes of the  contracted graph Gi+1 can fit in memory, such that the SCCs of Gi+1 can be computed using the semi-external algorithm Semi-SCC. The graph expansion phase computes all SCCs of Gi using the information computed in Gi+1 with decreasing i iteratively. Given graph Gi(Vi, Ei) and Gi+1(Vi+1, Ei+1),     suppose all SCCs of nodes in Vi+1 are computed, denoted as SCCi+1, we discuss computing SCCi, the set of all SCCs of nodes in Vi. According to the SCC-preservable property of Gi+1 in Lemma 5.3, we only need to compute SCC(v,Gi) for each v ? Vi ? Vi+1, since SCC(v,Gi) = SCC(v,Gi+1) for each v ? Vi+1 according to Lemma 5.3. We start with the following lemma.

Lemma 6.1: Given any two nodes u ? Vi+1 and w ? Vi+1 (possibly u = w) with SCC(u,Gi) = SCC(w,Gi) in graph Gi, for any node v ? Vi?Vi+1, SCC(u,Gi) = SCC(w,Gi) = SCC(v,Gi) ? u? v and v ? w in Gi. ? Proof Sketch: ? is trivial. We prove ?. Because SCC(u,Gi) = SCC(w,Gi), we have u ? w in Gi. Since u? v and v ? w in Gi, we can derive that v ? w ? u? v in Gi. Thus SCC(u,Gi) = SCC(w,Gi) = SCC(v,Gi). ? Lemma 6.1 suggests a way to compute SCC(v,Gi) for a  node v ? Vi ? Vi+1: to find two nodes u and w (possibly the same) in Vi+1 with SCC(u,Gi) = SCC(w,Gi) and u ? v and v ? w in Gi. However, u and w are not easy to find, and u? v and v ? w are not easy to compute. In the following, we show that it is enough to find u from nbrin(v,Gi) and find w from nbrout(v,Gi). We first investigate some properties of SCCs in nbrin(v,Gi) and nbrout(v,Gi) in Lemma 6.2 and Lemma 6.3.

Lemma 6.2: For any node v ? Vi?Vi+1, if SCC(nbrin(v,Gi), Gi) ? SCC(nbrout(v,Gi), Gi) ?= ?, then SCC(nbrin(v,Gi), Gi) ? SCC(nbrout(v,Gi), Gi) = {SCC(v,Gi)}. ? Proof Sketch: Suppose there exists vin ? nbrin(v,Gi) and vout ? nbrout(v,Gi) with SCC(vin, Gi) = SCC(vout, Gi), since vin ? v and v ? vout, from Lemma 6.1, we have SCC(vin, Gi) = SCC(vout, Gi) = SCC(v,Gi) in graph Gi.

As a result, SCC(nbrin(v,Gi), Gi) ? SCC(nbrout(v,Gi), Gi) = {SCC(v,Gi)} ? Lemma 6.3: For any node v ? Vi ? Vi+1, if there exists another node u ? Vi with SCC(v,Gi) = SCC(u,Gi), then SCC(v,Gi) ? SCC(nbrin(v,Gi), Gi) and SCC(v,Gi) ? SCC(nbrout(v,Gi), Gi). ? Proof Sketch: Since u ?= v and SCC(v,Gi) = SCC(u,Gi), there exists vin and vout, such that u ? v through a path (u, ? ? ? , vin, v) with vin ? nbrin(v,Gi), and v ? u through a path (v, vout, ? ? ? , u) with vout ? nbrout(v,Gi).

Thus SCC(v,Gi) = SCC(vin, Gi) = SCC(vout, Gi). As a re- sult, SCC(v,Gi) ? SCC(nbrin(v,Gi), Gi) and SCC(v,Gi) ? SCC(nbrout(v,Gi), Gi). ? According to the recoverable property of Gi+1 in Lemma  5.2, for any node v ? Vi ? Vi+1, nbrin(v,Gi) ? Vi+1 and nbrout(v,Gi) ? Vi+1. As a result, both SCC(nbrin(v,Gi), Gi) and SCC(nbrout(v,Gi), Gi) are computed in Gi+1. The fol- lowing lemma shows that SCC(v) can be computed using SCC(nbrin(v,Gi), Gi) and SCC(nbrout(v,Gi), Gi) only.

Lemma 6.4: For any node v ? Vi?Vi+1, SCC(v,Gi) can be computed using nbrin(v,Gi) and nbrout(v,Gi) only. ? Proof Sketch: There are two situations: 1) If SCC(nbrin(v,  Algorithm 5 Expansion(Gi, Gi+1, SCCi+1) Input: graph Gi(Vi, Ei) and its extracted graph Gi+1(Vi+1, Ei+1),  the SCCs of all nodes in Gi+1 sorted by node ids SCCi+1.

Output: the SCCs of all nodes in Gi sorted by node ids SCCi.

1: Ei ? reverse all edges in Ei; 2: E?in ? augment(Ei); 3: E?out ? augment(Ei); 4: SCCdel ? nodes (v, SCC(v,Gi)) for v ? Vi ? Vi+1 by E?in ? E?out; 5: SCCi ? SCCi+1 ? SCCdel; 6: sort SCCi by node ids; 7: return SCCi; 8: Procedure augment(E) 9: E ? edges (u, v) ? E order by (id(v), id(u)); 10: E? ? edges (u, v) ? E for v ? Vi ? Vi+1 order by id(v) by Vi+1 ? E; 11: E? ? edges (u, v) ? E for v ? Vi ? Vi+1 order by id(u) by sorting E?; 12: E? ? edges (u, v, SCC(u,Gi+1)) for v ? Vi ? Vi+1 order by id(u) by  E? ? SCCi+1; 13: E? ? edges (u, v, SCC(u,Gi+1)) for v ? Vi?Vi+1 order by (id(v), SCC(u,  Gi+1), id(u)) by sorting E?; 14: return E?  Gi), Gi) ? SCC(nbrout(v,Gi), Gi) ?= ?, according to Lemma 6.2, SCC(v,Gi) can be calculated using SCC(nbrin(v,Gi), Gi) ? SCC(nbrout(v,Gi), Gi). 2) If SCC(nbrin(v,Gi), Gi)? SCC(nbrout(v,Gi), Gi) = ?, according to Lemma 6.3, there does not exist another node u ? Gi with SCC(v,Gi) = SCC( u,Gi). As a result, v is an SCC with a single node in Gi. ? Given Gi(Vi, Ei), Gi+1(Vi+1, Ei+1), and SCCi+1, our ex-  ternal algorithm to compute SCCi is shown in Algorithm 5. In order to join nbrin(v,Gi) and nbrout(v,Gi) for each removed node v, the algorithm augments the SCC information into the in-neighbors of the removed nodes using augment(Ei) (line 2), and augments the SCC information into the out- neighbors of the removed nodes using augment(Ei) (line 3), where Ei is generated by reversing every edge in Ei. Note that in-neighbors in Ei become out-neighbors in Ei. The procedure to augment the SCC into the in-neighbors of Ei/Ei of each removed node is shown in line 8-14. In the procedure, a new edge set E? that keeps the incoming edges of only the removed nodes Vi ? Vi+1 is created by joining E and Vi+1 (line 10). In line 11, edges (u, v) in E? are sorted by id(u) in order to augment SCC(u). In line 12, SCC(u) is augmented in each edge (u, v) in E? by sequential scan of E? and SCCi+1. In line 13, edges (u, v, SCC(u)) in E? are sorted by (id(v), SCC(u), id(u)) to put the in-neighbors of each node in Vi ? Vi+1 together in order to compute nbrin(v,Gi) ? nbrout(v,Gi) efficiently. After augmenting the SCCs into the in-neighbors and out-neighbors of the removed nodes, in line 4, the SCCs of all nodes v ? Vi ? Vi+1 can be computed using nbrin(v,Gi) ? nbrout(v,Gi) by a sequential scan of E?in and E?out. In line 5, by combining SCCs in Vi?Vi+1 and SCCs in Vi+1 computed in Gi+1, the SCCs for all nodes in Gi can be computed as SCCi. Finally, all nodes in SCCi are sorted (line 6) and SCCi is returned (line 7).

Theorem 6.1: The I/O complexity of Algorithm 5 is O(scan(|Vi+1|) + sort(|Ei|) + sort(|Vi|)). ? Proof Sketch: Omitted due to lack of space. ? Theorem 6.2: Algorithm 5 computes all SCCs of Gi. ? Proof Sketch: For node v ? Vi+1, SCC(v,Gi) = SCC(v,Gi+1) according to the SCC-preservable property in Lemma 5.3. For node v ? Vi ? Vi+1, SCC(v,Gi) is correctly     G4 G3 G2  g  g  f i i  c k b l  ki j  G1  c d e  b a l  g  f h  i k  j m SCC1 SCC2  f  g e  c  f  c  e f  g b  i l  j kd  Fig. 5. Graph Expansion Example  computed according to Lemma 6.4. ?  Example 6.1: Fig. 5 shows the process of the graph expansion phase, to expand the graphs in order of G4, G3, G2, and G1 generated in the graph contraction phase in Fig. 4. The dashed circles in each graph Gi are the removed nodes when constructing Gi+1 from Gi. By applying the Semi-SCC algo- rithm on G4, two SCCs are computed, namely, SCC1 denoted by light gray nodes, and SCC2 denoted by dark gray nodes.

In G3, for node c ? V3 ? V4, we have g ? nbrin(c,G3) and f ? nbrout(c,G3) with SCC(g,G3) = SCC(f,G3) = SCC1.

Thus SCC(c,G3) = SCC1. Similarly, the SCCs of node k in G3, and nodes b, e, l, j in G2 can be computed. In G1, for node h, SCC(nbrin(h,G1), G1) = {SCC1} and SCC(nbrout(h, G1), G1) = {SCC2}, SCC(nbrin(h,G1), G1) ? SCC(nbrout(h, G1), G1) = ?. Thus node h in G1 is an SCC with a single node. Finally, there are two SCCs SCC1 and SCC2 with 6 and 4 nodes respectively. ?

VII. I/O COST MINIMIZATION In this section, we show how to optimize our contraction-  expansion based Ext-SCC approach by further reducing the I/O cost. The I/O cost can be reduced in two ways: (1) to reduce the number of graphs constructed in the graph contraction phase, and (2) to reduce the number of nodes and edges for each graph Gi constructed in the i-th iteration. According to the stop condition of graph contraction, reducing the number of graphs is equivalent to reducing the number of nodes |Vi| in each graph Gi. Thus, the key point to reduce the I/O cost of the Ext-SCC algorithm is to reduce the number of nodes |Vi| and number of edges |Ei| in each graph Gi. In the following, we introduce techniques to reduce the nodes and edges when constructing Gi+1 from Gi.

Node Reduction: Given graph Gi, when constructing Gi+1, suppose Vi+1 has already been computed using Algorithm 3, the following two types of nodes can be removed from Vi+1.

? (Type-1): For a node v ? Vi+1, if there does not exit another node u ? Vi such that SCC(v,Gi) = SCC(u,Gi), v can be removed from Vi+1.

? (Type-2): For a node v ? Vi+1, if nbr(v,Gi) ? Vi+1, v can be removed from Vi+1.

A Type-1 node v can be removed because v itself is an SCC with a single node in Gi, and there is no need to include v in later iterations as v cannot be combined with other nodes to form new SCCs in later iterations. A Type-2 node v can be removed because when nbr(v,Gi) ? Vi+1, Vi+1 ? {v} is still a vertex cover of Gi. According to the node selection condition in Lemma 5.1, Vi+1 ? {v} is a valid node set of Gi+1. Type-2 nodes are order sensitive, i.e., if node u and v  are Type-2 nodes, after u is removed, v may not be a Type-2 node. Note that our aim is to reduce nodes in Vi+1 without introducing new I/O cost, thus we only reduce those Type-1 and Type-2 nodes that are easy to be identified. The following lemma can be used to reduce Type-1 nodes.

Lemma 7.1: Any node v with degin(v,Gi) = 0 or degout(v,Gi) = 0 is a Type-1 node. ?  Proof Sketch: Omitted due to lack of space. ? To remove Type-1 node v from Vi+1 with degin(v,Gi) = 0  or degout(v,Gi) = 0, when generating Vd in line 4 of Algorithm 3, by joining Ein and Eout, we only keep the nodes with both degin(v,Gi) > 0 and degout(v,Gi) > 0 in Vd.

Since Vi+1 is generated from Ed which is computed using Vd, all nodes v with degin(v,Gi) = 0 or degout(v,Gi) = 0 will be removed in Vi+1 in Algorithm 3. Such an operation does not generate any extra I/O cost in Algorithm 3.

In order to reduce Type-2 nodes, when scanning all edges  in Ed in line 8-9 of Algorithm 3, for each edge (u, v) scanned, suppose v > u, before adding v into Vi+1, we check whether u has been added into Vi+1. If so, edge (u, v) has been covered by node u and there is no need to add v into Vi+1 to cover the edge (u, v) again. The situation for u > v can be handled similarly. In such a way, Type-2 nodes can be effectively reduced in Vi+1. However, such a solution needs to check whether u ? Vi+1 using a dictionary T which many not reside entirely in the main memory. Suppose T can only hold s nodes in memory, since a node with higher degree are less possible to be removed from Vi+1, when adding nodes into T , we only maintain the top s smallest nodes using operator > in T , to make sure that T can reside entirely in the main memory. By doing so, we can reduce the number of Type-2 nodes in Vi+1 without generating any extra I/O cost in Algorithm 3.

Edge Reduction: Given Gi(Vi, Ei), we introduce two ways to reduce the number of edges when generating Gi+1 in the i-th graph contraction phase without increasing the I/O complexity.

Although |Vi| < |Vi?1|, it is possible that |Ei| > |Ei?1|. We develop two methods to reduce the edge size in order to reduce the intermediate results. We will discuss the efficiency in our performance studies.

Firstly, for parallel edges with the same form (u, v), only  one of them needs to be kept in Ei+1. Such edges can be reduced in a lazy way, when generating Ein in the next iteration of Get-E (line 2 of Algorithm 3). A sequential scan of Ein needs to be added after line 2 of Algorithm 3 to eliminate parallel edges in Ein. In addition, it is straightforward that each edge (u,w) with u = w can be removed from Ei+1. This can be done in line 8 of Algorithm 4, by checking whether     TABLE I RANGE AND DEFAULT VALUE FOR PARAMETERS  Parameter Range Default Size of |V | 25M,50M,100M,150M,200M 100M Average Degree D 2,3,4,5,6 4 Memory Size M 200M,300M,400M,500M,600M 400M Size of Massive-SCC 200K,300K,400K,500K,600K 400K Size of Large-SCC 4K,6K,8K,10K,12K 8K Size of Small-SCC 20,30,40,50,60 40 Number of Massive-SCCs 1 1 Number of Large-SCCs 30,40,50,60,70 50 Number of Small-SCCs 6K,8K,10K,12K,14K 10K  u = w before adding (u,w) to Eadd.

Secondly, using operator >, according to Theorem 5.3,  nodes with small degrees are removed when constructing Vi+1, and for each removed node v ? Vi ? Vi+1, degin(v,Gi) ? degout(v,Gi) new edges are added into Ei+1. By considering degin(v,Gi)?degout(v,Gi) in the operator >, |Ei+1| can be further reduced. We redefine the operator > as follows.

Definition 7.1: (Operator >): For any u ? V (G) and v ? V (G), u > v iff one of the following three conditions holds.

(1) deg(u,G) > deg(v,G). (2) deg(u,G) = deg(v,G) and degin(u,G) ? degout(u,G) > degin(v,G) ? degout(v,G).

(3) deg(u,G) = deg(v,G) and degin(u,G) ? degout(u,G) = degin(v,G) ? degout(v,G) and id(u) > id(v). The> operator specifies a unique total order among all nodes in the graph G.

?  In Algorithm 3, in order to make use of the new > operator in line 9, when generating Vd in line 4, both deg(v,Gi) and degin(v,Gi) ? degout(v,Gi) need to be computed in Vd in line 4, and augmented in all nodes in Ed in line 5-7.



VIII. PERFORMANCE STUDIES In this section, we conduct experimental studies by com-  paring four external algorithms for SCC computation, namely, the external contraction based EM-SCC [13], the external DFS based DFS-SCC [8], our external contraction-expansion based algorithm Ext-SCC (Algorithm 2), and our algorithm Ext- SCC-Op by applying the optimization techniques introduced in Section VII in Ext-SCC. All the algorithms are implemented using Visual C++ 2005 and tested on a PC with Intel Core2 Quar 2.66GHz CPU and 3.5GB memory running Windows XP. The disk block size is 256KB. The default memory size is 400M . For the semi-external algorithm Semi-SCC used in Ext-SCC, we apply the algorithm 1PB-SCC introduced in [26], which is currently the most I/O efficient semi-external algorithm for SCC computation. The 1PB-SCC algorithm needs to hold 2 ? |V (G)| plus one disk block in the main memory, that is M = 4 ? (2 ? |V (G)|) + 256K where 4 is the number of bytes to keep a node in memory. We set the max time cost to be 24 hours. If a test does not stop in the time limit, we will denote it using INF. In our experiments, we do not show the results of EM-SCC since it cannot stop in all cases.

Datasets: In our experiments, we use a real large web graph and several synthetic datasets. The real web graph is WEBSPAM-UK20074, which consists of 105,896,555 web-  4barcelona.research.yahoo.net/webspam/datasets/uk2007/links/  4H  8H  12H  16H  20H  24H  INF  20 40 60 80 100  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (a) Time (Vary Graph Size)  1M  2M  3M  4M  5M  6M  7M  8M  INF  20 40 60 80 100  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (b) I/Os (Vary Graph Size)  Fig. 6. WEBSPAM-UK2007: Varying Graph Size (Percent)  4H  8H  12H  16H  20H  24H  INF  400M 600M 800M 1G  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (a) Time (Vary Memory)  1M  2M  3M  4M  5M  6M  7M  8M  INF  400M 600M 800M 1G  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (b) I/Os (Vary Memory)  Fig. 7. WEBSPAM-UK2007: Varying Memory Size  pages in 114,529 hosts in the .UK domain. The graph contains 105,895,908 nodes and 3,738,733,568 edges, with the average degree 35 per node. For synthetic data, we generate 3 different kinds of datasets, denoted Massive-SCC, Large-SCC, and Small-SCC, containing different sizes of SCCs. The graphs contain nodes from 25M to 200M with average degree varying from 2 to 6. A synthetic graph is generated as follows. We construct a graph G by randomly selecting all nodes in SCCs first. Then we add edges among the nodes in an SCC until all nodes form an SCC. Finally, additional random nodes and edges are added to the graph. The parameters for synthetic datasets and their default values are shown in Table VIII.

Exp-1 (Performance on WEBSPAM-UK2007): Fig. 6(a) and Fig. 6(b) show the time and I/O costs when varying the number of edges of WEBSPAM-UK2007 from 20% to 100% respectively. DFS-SCC cannot stop in the time limit even if the graph contains only 20% of the edges. When |E| increases, the time and I/O consumptions for both Ext-SCC and Ext-SCC-Op increase. The reasons are twofold. Firstly, when |E| increases, the number of iterations in graph contraction increases. This is because when number of edges |E| increases, according to the node selection scheme to construct Vi+1 in Algorithm 3, more nodes will be selected in Vi+1, thus more iterations are needed according to the stop condition of graph contraction in Ext-SCC. Secondly, when |E| increases, the cost to sort and scan edges in each iteration increases, thus more time and I/Os are consumed in each iteration. Ext-SCC-Op outperforms Ext-SCC in all cases since more nodes/edges are removed in each iteration in Ext-SCC-Op.

We vary the memory size from 400M to 1G. The results  are shown in Fig. 7(a) and Fig. 7(b) for time and I/O costs respectively. When the memory size increases, the time and I/O costs for both Ext-SCC and Ext-SCC-Op decrease. There are two reasons. Firstly, when the memory size increases, the stop condition for graph contraction is easier to be satisfied since more nodes can fit in memory. Secondly, when the mem- ory size increases, the costs of the external sorts in both graph contraction and graph expansion phases decrease. Ext-SCC-Op     1H  2H  3H  4H  5H  INF  200M 300M 400M 500M 600M  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (a) Time (Massive-SCC)  200K  400K  600K  800K  1M  1.2M  INF  200M 300M 400M 500M 600M  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (b) I/Os (Massive-SCC)  1H  2H  3H  4H  5H  INF  200M 300M 400M 500M 600M  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (c) Time (Large-SCC)  200K  400K  600K  800K  1M  1.2M  INF  200M 300M 400M 500M 600M N  um be  r of  I /O  s  Ext-SCC-Op Ext-SCC  DFS-SCC  (d) I/Os (Large-SCC)  1H  2H  3H  4H  5H  INF  200M 300M 400M 500M 600M  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (e) Time (Small-SCC)  200K  400K  600K  800K  1M  1.2M  INF  200M 300M 400M 500M 600M  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (f) I/Os (Small-SCC) Fig. 8. Synthetic Data: Vary Memory Size  outperforms Ext-SCC in all cases. When the memory increases from 800M to 1G, the costs for both Ext-SCC and Ext-SCC- Op decrease sharply. The reason is that, in order to process the graph using Semi-SCC, 105, 895, 908? 8 + 256K = 847.4M memory is needed, thus when the memory size is 1G, no iteration is needed and Semi-SCC can be directly applied on the original graph to output all SCCs.

Exp-2 (Vary Memory Size M in Synthetic Data): To test the synthetic data, we vary the memory size M from 200M to 600M . The time and I/O costs on Massive-SCC dataset are shown in Fig. 8(a) and Fig. 8(b) respectively.DFS-SCC cannot stop in limited time in all cases. Similar to the results on the real dataset in Fig. 7, when M increases, the time and I/O costs for both Ext-SCC and Ext-SCC-Op decrease. WhenM is smaller, the decrease rate is larger. This is because whenM is smaller, more iterations are needed for both Ext-SCC and Ext- SCC-Op, and in the graph contraction phase, the contraction rate decreases when the number of iterations increases, since the graph becomes denser with larger number of iterations.

Ext-SCC-Op outperforms Ext-SCC by 20% on average for both time and I/O consumptions. Fig. 8(c) and Fig. 8(d) show the results on Large-SCC dataset, and Fig. 8(e) and Fig. 8(f) show the results on Small-SCC dataset. The results for both Large-SCC and Small-SCC datasets are similar to those in the Massive-SCC dataset, and this is true for all the remaining test cases when varying other parameters in synthetic data. In the following, due to the lack of space, we only show the test results on the Large-SCC dataset.

Exp-3 (Vary Node Size |V | in Synthetic Data): We vary the node size |V | from 25M to 200M , and the time and I/O costs are shown in Fig. 9(a) and Fig. 9(b) respectively.

When |V | increases, the time and I/O consumptions for both Ext-SCC and Ext-SCC-Op increase. This is because the stop condition for graph contraction is harder to be satisfied when |V | is larger, and the cost on each iteration to scan and  4H  8H  12H  16H  20H  INF  25M 50M 100M 150M 200M  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (a) Time (Vary |V |)  1M  2M  3M  4M  5M  INF  25M 50M 100M 150M 200M  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (b) I/Os (Vary |V |)  2H  4H  6H  8H  10H  INF  2  3  4  5  6  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (c) Time (Vary Degree)  200K  400K  600K  800K  1M  1.2M  INF  2 3 4 5 6  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (d) I/Os (Vary Degree)  1H  2H  3H  4H  5H  INF  4K 6K 8K 10K 12K  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (e) Time (Vary SCC Size)  200K  400K  600K  800K  1M  INF  4K 6K 8K 10K 12K  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (f) I/Os (Vary SCC Size)  1H  2H  3H  4H  5H  INF  30 40 50 60 70  T im  e( ho  ur )  Ext-SCC-Op Ext-SCC  DFS-SCC  (g) Time (Vary SCC Num)  200K  400K  600K  800K  1M  INF  30 40 50 60 70  N um  be r  of I  /O s  Ext-SCC-Op Ext-SCC  DFS-SCC  (h) I/Os (Vary SCC Num) Fig. 9. Synthetic Data (Large-SCC)  sort nodes/edges is larger when |V | is larger. Ext-SCC-Op outperforms Ext-SCC in all test cases. DFS-SCC cannot stop within the time limit when |V | ? 50M . When |V | = 25M , DFS-SCC consumes more than 20 hours while both Ext-SCC and Ext-SCC-Op consume less than 1 hour.

Exp-4 (Vary Average Degree in Synthetic Data): We vary the average degree D of nodes from 2 to 6. The time and I/O costs on Large-SCC are shown in Fig. 9(c) and Fig. 9(d) re- spectively. When D increases, the time and I/O consumptions for both Ext-SCC and Ext-SCC-Op increase. This is because when D increases, the number of edges increases. As a result, more iterations are needed and larger cost is consumed in each iteration as analyzed in Exp-1 when varying the graph size. Ext-SCC-Op outperforms Ext-SCC, and whenD is larger, the gap between Ext-SCC-Op and Ext-SCC is larger. This is because when number of edges is larger, more edges can be pruned by the edge reduction techniques used in Ext-SCC-Op.

Exp-5 (Vary SCC Size and SCC Number in Synthetic Data): Fig. 9(e) and Fig. 9(f) show the time and I/O costs when varying the average SCC size from 4K to 12K respectively.

Fig. 9(g) and Fig. 9(h) show the time and I/O costs when varying the number of SCCs from 30 to 70. When either the average SCC size increases, or the number of SCCs increases, the time and I/O costs for both Ext-SCC and Ext-SCC-Op are not influenced much. As analyzed in Section VII, the key factors that influence the cost of Ext-SCC are the number of nodes and the number of edges of the graph. As a result, the size of SCCs and the number of SCCs do not have significant impact on the efficiency of our algorithms as long as |E(G)|     and |V (G)| are fixed. This also explains why the results in the three datasets Massive-SCC, Large-SCC, and Small-SCC are similar as stated in Exp-2.



IX. RELATED WORK Finding strongly connected components of a directed graph  G is a primitive operation in directed graph exploration, which has been studied for both internal memory model and external memory model. In the internal memory model, strongly connected components of a directed graph can be computed in O(|V (G)|+ |E(G)|) time based on DFS [12].

A naive way to externalize the internal DFS algorithm  requires O(|E|) I/Os. Chiang et al. [10] propose an algorithm with I/O complexity O(|V | + |V |  M ? scan(|E|) + sort(|E|)).

Later, Kumar and Schwabe [17] and Buchsbaum et al. [8] im- prove the I/O complexity to O((|V |+ |E|  B ) log2  |V | B +sort(|E|))  by maintaining the list of nodes that should not be traversed using tournament trees [17] and buffered repository trees [8], respectively. Despite their theoretical guarantees, these algo- rithms are considered impractical for general directed graphs that encountered in real applications. Cosgaya-Lozano and Zeh [13] present a contraction based algorithm which contracts SCCs repeatedly until the graph fits in memory, then an internal memory algorithm is used to find the final SCCs. Such an algorithm may end up an infinite loop and cannot compute all SCCs. Both DFS based algorithm [8] and contraction based algorithm [13] are introduced in details in Section III.

In addition to external algorithms, there are semi-external  algorithms for SCC computation which assume that all nodes of the graph can fit in the main memory. Sibeyn et al. [23] propose a semi-external DFS, which can be used to find all SCCs of a graph. Zhang et al. [26] improve such an algorithm by constructing and maintaining a special in-memory spanning tree of the graph. The semi-external algorithms [23] and [26] are introduced in details in Section III.

Other than the problem of finding SCCs or DFS tree on  external directed graphs, several problems in the external memory model are studied in the literature. Dementiev et al. [14] provide an implementation of an external memory minimum spanning tree algorithm based on the ideas of [22], which performs extremely well in practice, even though the- oretically inferior to the algorithms of [1], [10]. Ajwani et al. [4], [6] propose implementations of external undirected breadth-first search algorithm with the idea from [18]. Ulrich Meyer et al. [20], [21], [19] design and implement practical I/O-efficient single source shortest paths algorithm on general undirected sparse graphs. Surveys about designing I/O efficient algorithms for massive graphs can be found at [24], [5].



X. CONCLUSIONS In this paper, we study I/O efficient algorithms to find all  SCCs for a directed graph, with the assumption that the nodes of the graph cannot reside entirely in memory. We overcome the deficiencies of the existing external SCC computation algorithms, and propose a new two-phase algorithm with graph contraction followed by graph expansion. We analyze the I/O cost of our approach and show that our algorithm can  significantly reduce the number of random I/Os. We propose techniques to further reduce the I/O cost of our algorithm and confirm the I/O efficiency of our approaches using extensive experiments on both real and synthetic web scale graphs.

The work was supported by grant of the Research Grants Council of the Hong Kong SAR, China No. 418512.

