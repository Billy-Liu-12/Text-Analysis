

Proceedings of the 5? World Congress on Intelligent Control and Automation, June 15-19. 2004. Hangzhou. P.R. China  An Efficient Algorithm for Mining Frequent Closed Itemset  Lei Wen Deparimeni of Economy and Managemeni  North China Electric Power Universiij  wenlei03 12@sohu.com Bao Ding, HeBei Province, China posi code: 071003  Abstracf- Association rules mining was an important fields of data mining research. Discovering the potential frequent itemset was a key step of it. The existed frequent itemset discovery algorithms could discover all the frequent itemset or maximal frequent itemset. N. Pasquier proposed a new task of mining frequent closed itemset. The size of frequent closed itemset was much smaller than all the frequent itemset and did not lose any information. In this paper a new frequent closed itemset algorithms base on the Directed Itemset Graph was given. This algorithms .can discover all the frequent closed itemset effciently by using depth first search strategy. The experiment showed that it was eKicient for mining frequent closed itemsets.

Index Terms- Association Rule: Concept Lattice; Frequent closed Itemset: Directed Itemset Graph

I. INTRODUCTION  Data mining which was also referred as knowledge discovery in databases, means a process of finding nontrivial, extraction of implicit, pervious unknown and potential useful information from data in database[ I]. Among discovering many kinds of knowledge in database, Association rules mining was a form of data mining to discover interesting relationships among attributes in those data. The problem of finding association rules was introduced by aggrawal[4] and has been attracted great intention in database research communities in recent years. The discovered rules might help marketing, decision making, and business management. An example of association rules was 90% of customers that purchase bread also purchase milk.

Mining association tules can be decomposed into two steps: the first was Generate frequent itemsets. The second was generated association rules. Because the solution of second subproblem was rather straightforward, so most research had focus on how to generate frequent itemsets.

The most famous algorithms was Apriori[4]. The algorithms employed a breath-first and downward closure strategy and used ?any subset of a large itemsets must he large and any superset of a small itemsets must be small? to prune the search space.

? Most of the other algorithms were the variant of Apriori.

Such as Partiiion[S], DHf[6] and DIc[7] etc. They all need scan the database multiple times. The Apriori-inspiries algorithm showed good performance with sparse dataset, but was not suitable for dense dataset. Now more works focused on how to construct a special structure to replace the original  database for mining frequent itemsets. FP-growfh[8] and Tree frojecfion[9] were samples ofthem. They used a tree structure to save the information of original database. Paper[lO] construct a Directed Itemsets Graph to search the frequent itemsets. They all had a good performance than Apriori-inspiries algorithms for mining dense datasets.

The algorithms above could find all the frequent itemsets and had a good performance with sparse dataset. But when we dealed with a dense dataset, the size of maximal frequent itemsets was long, the size of all frequent itemset would be very large. So the performance of such algorithms decreased largely. There was two solution to solve this problem: the first was finding maximal frequent itemset; the second was finding frequent closed itemset. The maximal frequent itemset mining could reduce the result largely, hut the result could not represent all the information of original database. So the better choose was finding all the frequent close itemset.

In this paper, a new algorithm named MFCIBD(Mining Frequent Closed Itemset Based on DISG) was introduced. This algorithm stored all the related information of frequent itemset with a novelty data structure DISG(Directed ItemSet Graph) , based on DISG, algorithm MFCIBD could discover all the frequent close itemset efficiently.

The paper organized as follow: The second part introduced the problem of association rule mining and theory foundation of it; the third part introduced the MFCIBD algorithm; At last we performed an experiment on a real dataset to test the performance of MFCIBD. The experiment showed that it was efficient for mining frequent closed itemsets.

11. THEORY FOUNDATION AND THE PROBLEM REPRESENT  A. Theoryfoundation The formal concept analysis( FCA ) which was  proposed by professor Wille was a method to discover, index and indicate concept knowledge [3].

In FCA , A Formal Context K = (0, A, R) consisted of two sets 0 and A and of a binary relation R G O X A .

The elements of 0 were called the objects, those ofA the attributes of K = { O , A , R }  , oRa meaned object 0 has attribute a .

Galois connection: let K = {O, A, R} was a Formal  0-7803-8273-0/04/$20.00 02004 IEEE  mailto:12@sohu.com   Context, for o c 0  and a c A  ,we defined two function f and g between the power set of 0 and the powerset of A :  f(0): 2' + 2" f(0) = { a  E AI Vo sO,(o, a )  E R) g(A):2* -2' g ( A ) = { o s O I V a E A , ( o , a ) e R } (f, g) called Galoisconnection.

Formal Concept: if 0, = g ( A , )  , A ,  = f(0,) , we called ( O , , A , )  fromP(O)xP(A)a formal concept of K .  0 , w a s  called extension of (0, , A , )  and A, was called the intension of it.

Galois closure operation: the operator h = f og in power set of A and h'= g 0 f i n  power set of Owere called Galois closure operator[2].

For each Galois connection (f, g) , the following property holded for all A , ,  A,  A and 0, , 0, U :  h ' ( 0 , )  1)extension: A, c h(A,), 0, 2)indempotency h(h(A,))= h(A,),h'(h'(O,))=h'(U,) 3)monotonity: A, r A , = h ( A , ) c h ( A , )  0, c02*h'(0,)ch'(02) The set of all the formal concept in K was  called CS(K)  , in C S ( K )  if 0, c 0, , then (0,, A , )  was a subconcept of ( O , , A , )  , noted as (O,, A , )  I (O , ,A , )  .By using this relation, we could received an order set CS(K) = (CS(K),s) . This was a complete lattice called concept lattice( CL ).

B. The Problem ofAssociation Rule Mining  The task of association rules mining was discover the relation between different item in database. This problem was first introduced by R.Agrawalin 1993 [4]. I = {i, ,i2 ,._., i n )  was a set of item, given a transaction database D , each transaction t i n  D was a set of items such that t c I and had an unique mark Tid ,The transaction database D could be thought as a third tuple D = ( T ,  I ,  R )  , T and I was the tidlist and itemset. R was a binary relation between tidset and itemset: R i_ T x I .we called D = (T,I> R )  as association rule mining context. each(t,i) ( t  c T, i  L I )  means f was relation with i .

Support: Give an itemset I ,  I in D =' ( T ,  I ,  R )  , defined thesupport of itemsetl, as Support(/,) = 1 g ( 1 , )  I/l TI ,  Confidence: Give an implication r : X + Y in association rule mining context D = ( T , I , R )  ,we defined the confidence of implication r as Conjdence(X + Y )  =I g(X U Y )  I 1 I g ( X )  I ,  Frequent itemset: In association rule mining context D = (T , I ,R)  , if Support(1,) ( I ,  I ) was bigger than  given minimum support threshold, we called I ,  frequent itemset. the set of frequent itemset  X , Y ? I ,  XnY#@,.

FIS = { I ,  c I 1 Support(/,) 2 s) .

Association rule: in association rule mining  contextD=(T,I,R), the association rule was defined as an  implication with this fom:  X + Y  , X, Y c I ,  X n Y # @ . S was the support of association rule satisfied S = I g ( X  U Y )  l/l T I 2 s , C was the confidence of association rule C =/ g ( X  U Y )  I / 1 g ( X )  I> Minconjdence .

Closed itemset: in association rule mining context D = (T , I ,R)  , for itemset I ,  if there was not such itemset I ,  satisfied g(1,) = g(1,) and I ,  c I ,  ( I , ,  I ,  c I )  , that means h(I,) = I ,  ,we called I ,  closed itemset. the set of closed itemset markedcl = { I ;  5 11 h( I ; )  = I ; ) .

Frequent closed itemset: if the support of closed itemset I ,  sup port(/,) t s we called I ,  frequent closed itemset. the set of all frequent closed itemset marked as FCI = { I ;  G I  I h(1,) = I ; , /  g(1,) It s} .

Mining frequent closed itemset was to discover all the  111. THE ALGORITHMS OF MINING FREQUENT  s.c  closed itemset satisfied the support constrain.

CLOSED ITEMSET  A .  Related Work In paper[2] author proposed an algorithm for mining  frequent closed itemset named A-close. A-close discovered the frequent closed itemset as follow: based on closed itemset properties, it determined a set of generator that will give us all frequent closed itemsets by application of Galois closure operator h .  An itemset p was a generator of an closed itemset c if it was one of the smallest itemset that will determine c using galois closure operator h(p) = c . The i + l  -generators were created by i -generators, then the support of i + 1 -generators was counted. According to their support and the i-subset in i-generators, infrequent generators and generators that their support is same as one of their subsets are deleted. Once all frequent useful generators were found, by passing database, their closure were determined. All the frequent closed itemset were discovered. This algorithms needed pass dataset n+ltimes, n times was use to count the support of generators( n is thesize of maximal frequent generator), the other one pass was used to discover all the frequent closed itemset.

In this paper, we proposed a new mining frequent itemset algorithm MFCIBD based on DISG.

B. Directed Itemset Graph  DISG(Directed itemset Graph): R was a relation between frequent 1-itemset of  association rule mining context D = ( T , I , R )  , R = {(FI; ,Flj 1 I/ g(FI; ,Flj  1 I2 sal g(F1;) />I g(Flj) 1, lFIi j=1, 1 F I j  I= I} , We defined the relation graph of R as DISG. The vertex set ofDISG V = (Fl; 11 FI,  I= I ) ,  the arc set was A . Each vertex V. had three attribute: the first  . .  . .

was Item ; The second was Tidlist ; The third was Adjacenfverfex of Vi .

From the definition of DISG, we can draw an conclusion that the number of vertex was equal to the number of frequent and each arc < Vi, V, > means that {Vi, V,}  was a frequent 2-itemset.

In this paper we used vertical database to count the support of frequent itemset, the support was counted by using the join of Tidlist of each item. This method can avoid passing database multiple and showed a better performance than the first.

An DISG was showed in figure 1.

C(O11011) D (110101) Figure1 DISG  C. Frequent closed itemset mining algorithm: MFCIBD The step of algorithm MFCIBD was introduced with  dataset in tablel. there were 6 transaction in this dataset. The DISG generated from this dataset was showed infigurel. The minimum support was 0.5 which means the itemset which was supported by at least 3 transaction was frequent itemset.

The First step: selected vertex B from DISG by support descending order, selected unvisited vertex E from adjacentlist of B by support descending order, from the property of DISG we know that itemset { B ,  E }  is a frequent 2-itemset, store the transaction support itemset { B ,  E } (B,E}.Tid/ist = {1,2,3,4,5} and Supporf{B,E} =0.83, because Support(B,} # Supporf{B,E} ,so itemset (&E}  is a base of frequent closed itemset , add itemset {B,  E )  into the candidate set of frequent closed itemset.;  The Second step: select unvisited vertex A from adjacentlist of E by support descending order, count the support of itemset ( B ,  E, A }  S(B,  E ,  A )  =/ ( B ,  E }  .Tidlist n A.Tidlist I / I  T I =4/6= 0.67>minsup, itemset {B,E,  A }  is a base of frequent closed itemset, add itemset ( B , E , A }  into the candidate set of frequent closed itemset.

The Third step: select unvisited vertex ' D from adjacentlist of A by support descending order, count the support of itemset {B,E,A,DI S(B,E,  A, D) 4 {&E,  A}.Tidlist nD.Tidlist 1 / I T  I =0.5=Minsup, for there is not adjacentvertex of D , so add {&E, A , D }  into the set of frequent closed itemset;  The Fourth step: retum to last vertex A ,  because there was not unvisited adjacentvertex of A ,so { B , E , A }  was a  frequent closed itemset, add { B ,  E ,  A )  into the set of frequent closed itemset Delete { B , E , A }  from the candidate set of frequent closed itemset ;  The fifth step: selected unvisited vertex D from adjacentlist of E by support descending order, counted the support of itemset {B ,E ,D}  S(B,E,D)=I{B,E).TidlistnD.Tidlisf l / l T l  = OS=minsup, for there was not adjacentvertex of D ,  check whether there were a super set of ( B , E , D )  in the set of frequent closed iyemset and with the same support. Because there were a super set ( B , E , A , D )  of (B ,E ,D}  and S(B, E ,  A ,D)  = S{B, E ,D}  , itemset {B, E,D} was not a frequent closed itemset.

Repeated 2-5 step above until discover all the frequent closed itemset with B, then deleted B from DISG repeated above step to discover all the frequent close itemset.

Algorithms: W C I B D : V={ Vili=l,2,..,n} is vertex set ofDISG List( Vi) is the adjacent table of Vi S( V,)is the support of the item V, S(Vi ,  5 ) i s  the support ofthe itemsets { V, , 5} CFClS is the candidate set of frequent closed itemset FCIS is the set of all the frequent closed itemset Input: DISG Output: FCIS Begin While V # @ do  Select V, from V by support descending order FIS= Vi, S(FIq=S( V,); Add FIS into CFCIS Select unvisited 5 from List( V,); Call Candidategmne( FIS, Vj  ) Call DFS(4)  end; Procedure DFS(5) Begin  I f  List(?.) # @ do Select Vk with highest support fromList(V,)  IfS(FIS,V,) 2 Minsup do Call Candidategtune( FIS, V, ) Call DFS( V,  )  Delete Vk from List(V,) Call DFS( V, ) Endif  Else  Else Closed-check(itemset of CFCIS with V, )  Retum to its parent vertex v.

Call DFS( v. )  Endif End;     Procedure Candidategrune( FIS, V i ) Begin  If S(F1S) f S(FIS,V,) then.

Add FISUV, to CFCIS  Else Delete FIS from CFCIS  Endif FIS = FIS U Vi  End Procedure Closed-check(F1S) Begin  While F C I S t a  do For each FCISj E FCIS  If FIS c FCIS? and S(F1S) = S(FCIS,) then  Else  Endif  Delete FIS  Add FIS to FCIS  End

IV. THE EXPERIMENT OF ALGORITHM  To assess the performance of algorithm MFCIBD, we performed some experiments on a PC with windows2000. All the programs were writed by Visual c++ 6.0. An real data ~ mushroom (taken from the UC Imine Machine Lean Database Repository) was used in this experiment .The mil time was showed in figure 2.

180 I t  i 6 0  40 30 2 0  I D  suppor t  (%)  Figure 2 Run Time of Algorithm MFCIBD

V.CONCLUSION  In this paper, we defined the task of frequent close itemset mining and introduce a new frequent closed itemset algorithm MFCIBD based on directed itemset graph. An experiment was done with a real database and it show that this algorithm had a good performance to discover all the frequent closed itemset. It was important to help user to understand the mining result.

