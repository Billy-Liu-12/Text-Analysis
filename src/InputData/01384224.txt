

on Intelligent Mechatronics and Automation  Chengdu,China.August 2004  An improved parallel algorithm item-sets  Chundong She, Lei Li, Hongbing Wang Institute of Software  Chinese Academy of Sciences Beijing 100080, China shurcd@vip.sina.com  Absfracf - Discovery of associations from large-sets becomes increasingly useful in data-mining field. Several sequential and parallel algorithms for discovery of association rules are analyzed in this paper. And based on the efficient FP-growth algorithm without candidacy, its implementation method of constructing the frequent pattern tree and mining frequent item sets is given for the shared memory parallel formulation.

However, it becomes less effective due to the imbalance.

Therefore, a dynamic mechanism is proposed in this paper to solve the problem successfully.

Keywords - data mining , parallel processing, association rules, load balance, shared memory

I. INTRODUCTION  One of the important problems in data mining [ I ]  is discovering associations present in the data. Such problems arise in the data collected from scientific experiments, or monitoring of physical system such as telecommunications networks, or from transactions ' at a supermarket. The prototypical application is the analysis of sales or basket data .Basket data consists of items bought by a customer along with the transaction identifier. Besides these, association rules have also shown to be useful in domain such as decision support, university enrollments, etc.

Many practical applications of association rule involve huge transaction databases which contain a large number of distinct items. In such situations, the serial algorithms like apriori running on single -processor machines may take unacceptably large times. The primary reasons are the memory, CPU speed, and 110 bandwidth limitations faced by single-processor machines. This is true of most of other serial algorithms as well. This motivates the development of parallel formulations.

Computational work in association rule discovery consists of candidate generation and counting occurrences. In order to extract concurrency, the computational work needs to be distributed among the available processors.

11. RELATEDWORK  In spite of the significance of the association rule mining and in particular in generation of frequent item sets, few advances have made on parallelizing association rule mining algorithms[ 13,141.Most of the work on parallelizing association rules mining on whether Shared-memory Multi- Processor(SMP) architecture or * distributed-memory  for finding frequent  BO Gao and HongQin Deng Department of Technology  Xichang Satellite Launch Center Xichang, Sichuan 615000, China  wahobi@etang.com  architecture was based on apriori-like algorithms.

IDD(inte1ligent data distribution) were proposed in [ 161,which improved the DD[ 131 by eliminating the redundant work of it.

The HPA(Hash Partitioned Apriori) algorithm, given in [ 171,is similar in spirit to the IDD algorithm. It tries to reduce the communication overhead of sending each transaction to every processor.

Along with the parallel formulations of apriori based algorithms, some other schemes for distributed system have been proposed in the literature so far[l1,15],Parallel formulation, DMA, designed specifically for distributed databases is described in [ 17].It uses an idea of pruning based on local count.. However, the trimming and the pruning properties caused some problems that made it impractical in many cases.

An excellent recent survey is given[7] on parallel association rule mining with shared-memory architecture covering most trends, challenges and approaches adopted for parallel data mining. All approaches spelled out and compared in this extensive survey are apriori-based. These methods not only require repeated scans of the datasets, they also generate extremely large numbers of candidate sets. Therefore, it is urgent to find new solutions.

111. BASIC CONCEPT FOR RULE MINING '  Let T be the set of transactions where each transaction is a subset of the item set 1. Let C be a subset of I, then we define the support count of C with respect to T to be:  o(C) = I{t 1 t E T ,  C c r ] Thus a(C) is the number of transactions that contain C.

An association rule is an expression of the form X a  Y , where X c I ,  Y c I .The support s of the rule X 2 Y is defined as a(x U Y )  /[TI ,and the confidence a is defined as o(x U Y )  / ~ ( x )  .A rule that has a very high confidence (i.e., close to 1.0) is often very important, because it provides an accurate prediction on the association of the items in the rule. The support of a rule is also important, since they do not describe significantly large populations. This is one of the reasons why most algorithms disregard any rules that do not satisfy the minimum support condition specified by the users.

s,a  S P  0-7803-8748-1/04/$20.00 02004 IEEE. 383  mailto:shurcd@vip.sina.com mailto:wahobi@etang.com   This filtering due to the minimum required support is also critical in reducing the number of derived rules to a manageable size.

The task of discovering an association rule is to find all  rules X Y ,such that s is greater than or equal to a given minimum support threshold and a is greater than or equal to a given minimum confidence threshold. The first step is to discover all the frequent item sets (candidate sets that have more support than the minimum support threshold specified).

The second,step is to generate association rules from these frequent ,item-sets. The computation of finding the frequent item-sets is much more expensive than findling the rules from these frequent item sets. Therefore, we only focus on the first step.

S P  w. PARALLEL FORMULATIONS BASED ON THE FP-GROWTH The parallel algorithm of FP-growth includes two steps.

Step one is the construction of the frequent pattem trees and step two is the actual mining from these trees. - A. Datastructure  The data structure defined below consists of a global header table and local frequent pattern trees for all processors.

1) The global header table consists of global counts for each frequent item and entries corresponding to each processor. Each entry consists of two fields,( 1) item-name and (2) head of node-link, which points to the first node in the local frequent pattern tree carrying the item-name.

2) Each node in the local frequent pattern trees , consists of three fields: item-name, count, and  node-link, where item-name registers which item this node represents, count registers the number of mnsactions represented by the portion of the path reaching this node, and node-link links to the next node in the FP-tree carrying the same item-name, or null if there is none.

B.

. The parallel formulation based on the 1"-growth woks as  follows. If p is the total number of processors, the original database is initially partitioned into p parts of equal size, each one is assigned to a different processor, and stored in its local disk. A first initial scan of the database identifies the frequent 1 -itemsets.Each processor locally numerates the items appearing in the transactions at hand. Afl:er enumeration of local occurrences, a global count is necessary to identify the frequent items. This count is done in pruallel where each processoi is allocated an equal number of items to sum their local supports into global count. Finally, in a sequential phase infrequent items with a support threshold are weeded out and the remaining frequent items are sorted by their frequency.

This list is organized in a table, called header table, where the i t e d  and their respective global support are stored along with pointers to the first occurrence of the item in each frequent pattern tree.

Construction of the local parallel trees  The second scan of the database constructs a frequent pattern tree for each available processor. For each transaction read by a processor only the set of frequent items present in the head table is collected and sorted in descending order according to their frequency. These sorted transaction items are used in constructing the local trees as follows: for the first item on the sorted transactional dataset, check if it exists as one of the children of the root. If it exists then increment the support for this node. Otherwise, add a new node for this item as a child for the root node with 1 as support. Then, consider the current item node as the newly temporary root and repeat the same procedure with the next item on the sorted transaction. During the process of adding any new item-node to a given local FP-tree of a processor p, a link is maintained between this item node in the tree and its entry in the global header table corresponding to processor p .  The header table holds as many pointers per item as there are available processors.

C. Parallel mining frequent item-sets  Building the local frequent pattem trees is not final goal but a means with the purpose uncovering all frequent pattems without resorting to additional scans of the data. The mining process starts with a bottom up traversal of the nodes on the local FP trees, where each processor mines fairly equal amounts of nodes. The distribution of this traversal work is predefined by a relatively small sequential step that precedes ihe mining process This step sums the global supports for all items and divides them by the number of processors to find the average number of occurrences that ought to be traversed by each processor. If A is this found average, this sequential step goes over the sorted list of items by their respective support and assigns items consecutively for each processors until the cumulated support is equal or greater than the average A. At this stage all frequent pattern trees are shared by all processors. The task of the processors, once assigned some items, is to generate what is called a conditional pattern base starting from their respective items in the header table. A conditional pattern base is a list of items that occur before a ' certain item in the frequent pattern tree up to the root of that tree in addition to the minimum support of all the item supports along the list. Since an item can not only occur in many trees but also in many branches as in [6]. If the suppsrt of an item is less than the,minimum support threshold, it is not added in the frequent string.

v. DYNAMIC LOAD BALANCING IN DATA MINING It is pointed out in paper [6] the overhead spent on  constructing tree is much more that spent on mining the FP tree. So the efficiency of the algorithm much depends on the overhead of the process of constructing the FP-tree. In the first phase of that process, the transaction data is equally distributed among the processors and the computation of .the local support in each processor is independent of other processors, therefore, 'that would not result in load imbalance due to task distribution. However, in the second phase of construction of the local trees, although the size of data-sets     distributed to each processor is the same, the sum of occurrences of frequent items that each processors process is much different. Therefore, the size of the constructed local parallel tree is not the same. Moreover, the overhead of maintaining the link between the items is much different.fiom others due to the differences of tree structure. Only applying the static distributing strategy will result in load imbalance dramatically and deficiency of the algorithm.

The dynamic distributing strategy must be taken to achieve the goal of load balance. We use a improved method based on random pooling scheme [12]. In this scheme, as a processor becomes idle (that is it finishes its portion of allocated work), it randomly selects a donor processor and sends it a request. The donor processor sends a response indicating whether or not it has additional work. If a response indicating that a donor has additional work, it will receive a certain amount of transactions from the donor processor. The amount of time required by' the two parallel Otherwise, the processor selects another donor and sends a formulations will decrease as the number of processor work request to that donor. The time-point that the donor increases and good speedup was achieved. Comparing the gives response to the processor sent the request affect the various instances of PFP against DPFP we can see that for result of balancing. The request processor could he blocked each one of the different experiments DPFP achieves long when waiting the response from the donor. The simple comparable or substantially lower run-times. In particular, the way is the donor processor responds immediately after dynamic improvement is due to the fact that the number of processing the current transaction. However, it will reduce the frequent items in the transactions distributed to each processor benefits obtained from the balancing when interrupted is not the same and leads to highly unbalanced computations, frequently. which the DPFP can balance by dynamically moving work  To address the problem, an improved method is defined between the processors. When the size of transaction database as follow: the donor processor gives response after changes from lOOK to IM, the performance of PFP decreases, accomplishing Up (p is the number of processors) of its rest while better speedups were achieved while using DPFP work and informs the request processor how long it should algorithm as the number of processors increases. This wait. If the request processor can still be blocked for a long improvement is due to the fact that the capability of balancing time, it will send a request to the other processor. Another the work of DPFP becomes better when the size of transaction important factor that affects the result of the balancing is size database increases.

of workload that assigned to the request processor. If it is too small, the request processor will becomes idle very quickly..

On the other hand, it cannot give respond when another processor sends it a request. Worse, the donor processor will be blocked after redistributing the workload. A wise way is that the donor Processor assigns of its workload to the processor that sends request. This can maintain the relative balance after redistributing the task.

If the request Processor does not receive any Work after a circle request, it will send a request which has more priority.

The donor processor that receives the request will give a response upon dealing with the current transaction.

'Table I .  the amount of time ( in seconds) and required by the parallel formulations and the speedup that was achieved  VI]. CONCLUSIONS In this paper we implement the shared-memory parallel  algorithm based on ~ p - ~ ~ ~ ~ t h .  The formulation is the number bf process&  increase. However, as number of processors increases, the accuracy by which the workload can be estimated decrease and the computation became increasingly un-balanced. To overcome that problem, we developed a new dynamic load- balancing algorithm, which was able to achieve speedups as the number ofprocessors increase.

able to achieve good speedup

VI. EXPERIMENT EVALUATION  ,We evaluated the parallel formulations based on the FP- growth algorithm on a 16-processor intel MEYER STL2 cluster consisting of 4 nodes .Each node consist of 4 processors, 1GB memory and 72GB HD. OS is Microsofl windows 2000 and the parallel computational environment is MPI. The minimum support is 1%. The experiment was designed to evaluate and compare the performance of the parallel FP-growth and the algorithm using our dynamic balance mechanism.

