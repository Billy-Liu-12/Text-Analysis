

Abstract: It is well-recognized that the main factor that hinders the  applications of Association Rules (ARs) is the huge number of ARs returned by the mining process. To solve this problem, an algorithm for mining concise association rules based on generators and closed itemsets is proposed. Firstly, the concept of concise association rule is proposed, and the rationality of the definition is explained based on conviction. Then, the definitions of concise min-max precise rule basis and concise min-max approximate rule basis are proposed, and the corresponding pruning strategies are discussed. Finally, the characteristics and connection strategies of generator are presented, and based on subsume index, a breadth-first algorithm for mining concise association rule is proposed.

Experimental results show that the concise rules with smaller sizes can be discovered. Thus, the understandability of mining result is improved.

Keywords: Data mining; Concise association rule; Generator; Closed  itemset; Subsume index  1. Introduction  Association Rule (AR) mining [1] is recognized as one of the fundamental data mining tasks and has a wide range of applications [2, 3]. Over the last decade, many efficient algorithms have been proposed for mining ARs [4].

However, an intrinsic problem of mining ARs is that a prohibitively large number of rules can be easily generated, even in the case of a relatively high minimum support threshold. The massive size of the mining result makes further analysis very difficult, thus severely restricting the practical usage of ARs.

Many efforts have been made on solving this problem including defining various interest measures, incorporating constraints into mining process, or designing specific templates to mine for restricted rules [5, 6]. Especially, from late 1990s, a new trend emerges which adopts frequent closed itemsets [7] to extract association rules. The use of frequent closed itemsets presents a clear promise to  reduce the number of extracted rules and also provides a concise and lossless representation of association rules such as the non-redundant association rules [8, 9] and the representative association rules [10]. However, the redundancy still remains in the extracted rules using the closure based approaches.

In this paper, an algorithm for mining concise association rules based on generator and closed itemset is proposed. Firstly, the concept of concise association rule is proposed, and the rationality of the definition is explained based on conviction [11]. Then, the definitions of concise min-max precise rule basis and concise min-max approximate rule basis are proposed, and the corresponding pruning strategies are discussed. Finally, the characteristics and connection strategies of generator are presented, and based on subsume index [12, 13], a breadth-first algorithm for mining concise association rule is proposed.

Experimental results show that the concise rules with smaller sizes can be discovered. Thus, the understandability of mining result is improved.

2. Problem statement  Association rule is a kind of co-occurrence information on items [1]. Let I = {i1, i2, ?, iM} be a finite set of items and D be a dataset containing N transactions, where each transaction t?D is a list of distinct items. A set X?I is called an itemset. The support of an itemset X, denoted as sup(X), is the percentage of transactions in D containing X. That is:   sup(X)=|X(t)|/|D|               (1)   where X(t)={ t?D | X?t}.

Namely, the support of itemset X is the probability  P(X). Let min_sup be the threshold minimum support value specified by user. If sup(X)?min_sup, itemset X is called a frequent itemset.

An association rule is an implication of the form X?Y,        where X?I, Y?I and X?Y=?. Besides the above-mentioned support, the rule X?Y has confidence, denoted by conf(X?Y), is the percentage of transactions in D containing X which also contain Y, i.e.:   conf(X?Y)= sup(X?Y)/ sup(X)           (2)   That is the confidence of itemset X is the conditional  probability P(Y|X). Rules that satisfy both a minimum support threshold (min_sup) and a minimum confidence threshold (min_conf) are called strong rules. The problem of association rule mining is to discover all strong rules.

Let T and X, T?D and X?I, be subsets of all the transactions and items appearing in D, respectively. The concepts of generator and closed itemset are based on the two following functions, f and g:   f (T)={i?I | ??t?T, i?t}             (3)   g (X)={t?D | ??i?X, i?t}            (4)   Function f associates with T the items common to all  objects t?T and g associates with X the objects related to all items i?X.

Definition 1. An itemset X is said to be closed if and only if   c (X)=f (g(X))=f g(X)=X            (5)   where the composite function c = f g is called the  Galois operator or closure operator.

Definition 2. Let G be a itemset, C be a closed itemset,  if h(G)=C, and A?G, such that h(A)=C, then G is a generator.

The closure operator defines a set of equivalence classes over the lattice of frequent itemsets. In each equivalence class, generators and closed itemsets are minimal and maximal itemsets respectively.

As we can see from Eq. (2), confidence has the flaw that it ignores P(Y). For example, P(X?Y)/P(X) could equal P(Y) (i.e. the occurrence of Y is unrelated to X) and could still be high enough to make the rule hold. To solve this problem, the concept conviction is defined in [11].

Definition 3. The conviction of rule X?Y is defined as:   conv(X?Y)=P(X)P(?Y)/P(X??Y)        (6)   Comparably, conviction is a better measure of  implication because it is directional, it is maximal for  perfect implications, and it properly takes into account both P(X) and P(Y).

3. Concise association rules based on generators and closed itemsets  3.1 Concise association rules  In [9], Pasquier et al have proposed the following non-redundant association rules based on closed itemset.

Definition 4. Let Close be the set of frequent closed itemsets and, for each frequent closed itemset c, let?s denote Gc the set of generators of c, The min-max exact basis is:   MinMaxER={g?(c\g)| c?Close, g?Gc, g?c}  (7)  Definition 5. We denote G the set of generators of the  frequent closed itemsets in Close. The min-max approximate basis is:   MinMaxAR={g?(c\g)|c? Close, g?G, h(g)?c}  (8)  However, the set of ARs returned by their proposals is  still large and inefficient for more advanced analysis. Thus, the following concise association rule is defined.

Definition 6. Given association rule r: X?Y, if there  exists rule r?: X??Y?, such that conf(r)=conf(r?), Y?Y?, X??X, then r is redundant rule to r?, else r is a concise association rule.

Theorem 1. Let r: X ? Y and r?: X??Y? be two association rules which have the same confidence, if Y??Y, then conv(r)? conv(r?).

Proof. According to Definition 3, we have: ( ) ( )  ( ) ( )  P X P Y conv r  P X Y  ? =  ? ?   ( )(1 ( ))  ( ) ( )  P X P Y  P X P X Y  ? =  ? ?    1 ( )  ( ( ) ( )) / ( )  P Y  P X P X Y P X  ? =  ? ?   1 ( )  1 ( )  sup Y  conf r  ? =  ?   As conf(r)=conf(r?), So  conv(r)? conv(r?)= ( ') ( )  1 ( )  sup Y sup Y  conf r  ?  ?   Because Y??Y, we have sup(Y?)? sup(Y). Besides,        1?conf(r) ?0, consequently, conv(r)?conv(r?).

We can learn from Theorem 1 that, the conviction of  concise association rule is no lower than the conviction of its redundant rules.

3.2. Concise association rule basis and the pruning strategies  By introducing the concise association rule to Definition 4 and Definition 5, the following concise association rule bases are proposed.

Definition 7. Let Close be the set of frequent closed itemsets and, for each frequent closed itemset c, let?s denote Gc the set of generators of c, The concise min-max exact basis is: CSMinMaxER={g?(c\g)| c?Close, g?Gc,  g?c, g?(c\g) is a concise association rule}.

Definition 8. We denote G the set of generators of the  frequent closed itemsets in Close. The concise min-max approximate basis is: CSMinMaxAR={g?(c\g)|c?  Close, g?G, h(g)?c, g?(c\g) is a concise  association rule}.

To discover the concise association rule basis  efficiently, the following theorems are proposed.

Theorem 2. Let r: X?Y, r?: X??Y?, r,  r??MinMaxER, if X??Y?? X?Y, and Y?Y?, then r?  CSMinMaxER.

Proof. As r, r??MinMaxER, according to Definition 4, we have:  conf(r)= conf(r?)=1?P(Y|X)=P(Y?|X?) ?P(X?)P(X?Y)=P(X)P(X??Y?) Since X??Y??X?Y, we have P(X??Y?)?P(X?Y), so  P(X?)?P(X), that is X??X. According to Definition 6, r is redundant to r?.

Theorem 3. Let r: X?Y, r?: X??Y?, r, r??  MinMaxAR, if X??Y?? X?Y, Y?Y?, and conf(r)=conf(r?),  then r? CSMinMaxAR.

Theorem 3 can be proved by the way similar to  the proof of Theorem 2.

During the discovery of concise min-max  association rule bases, the Theorem 2 and  Theorem 3 can be used for pruning.

4. Algorithm for mining concise association rules  4.1. Pruning strategies for generators  From Definition 7 and Definition 8, we can see that, generator and closed itemset are two important factors for the efficiency of concise rule discovery. As various closed itemset mining algorithms have been proposed [13, 14], the pruning strategies of generators is the key issue that really count for the discovery efficiency. Thus, the following theorems are proposed.

Theorem 4. gen is a generator, if and only if for ?s?gen, sup(gen)<sup(s) holds.

Proof: If for ?s?gen, sup(gen)<sup(s) holds: Suppose gen is not a generator, then there exists  itemset A?gen, such that sup(A)=sup(gen), it contradicts with hypothesis, so gen is a generator.

If gen is a generator: For ?s?gen, we have sup(gen)?sup(s). According to  Definition 2, sup(gen)?sup(s), so sup(gen)<sup(s).

Theorem 5. If P is a generator, and Q?P, then Q is  also a generator; If P is not a generator, and P?Q, then Q is not a generator either.

Proof: Suppose P is a generator, Q?P, and Q is not a  generator, then there exists itemset X?Q, such that  h(X)=h(Q). Assume P=Q?Y, Q?Y=?, then sup(X?Y)=  g(X?Y)/N=(g(X)?g(Y))/N=(g(Q)?g(Y))/N=  g(Q?Y)/N= g(P)/N=sup(P). Meanwhile,  X?Y?Q?Y=P, it contradicts with P is a generator.

If P is not a generator, and P?Q, According to  Definition 2, there exists P??P, such that g(P?)=g(P).

g(Q)=g((Q\(P\P?))?(P\P?))=g(Q\(P\P?))?g(P\P  ?). Since g(P?)=g(P)?g(P\P?), we have  g(Q\(P\P?))?g(P?)?g(Q\(P\P?))?g(P\P?)=g(Q),  that is g((Q\(P\P?))?P?))?g(Q). Because P??  Q\(P\P?), g((Q\(P\P?))?P?))=g(Q\(P\P?))?g(Q)  holds. Furthermore, Q\(P\P?)?Q, so we have  g(Q)?g(Q\(P\P?)). That is g(Q)=g(Q\(P\P?)), so Q is not a generator.

Based on the above two theorems, we give the following algorithm for the connection of generators.

Algorithm 1. Function Candidate-Gen(FK-1)        Input: frequent (k?1)-itemset  Output: candidate k-generator  1) Ck? FK-1  FK-1;  2) flag?TRUE;  3) for each c?Ck do 4)  for ?s?c and |s|=(k?1) do //|s| denotes the  length of s is k?1  5)    if (s?Gk-1 || sup(c)==sup(s)) then  6)      flag?FALSE;  7)  end for  8)  if ((flag)&&(sup(c)?min_sup)) then  9)    Gk?c;  10)end for  11)return Gk;  In Algorithm 1, the connection operator  introduced in Apriroi [1] is used for connection  (Step 1). Step 2 set the value of flag TRUE.

k-generator is selected in the main loop (Steps  3-10), in which Theorem 4 and Theorem 5 are  used for pruning.

4.2. Computing of subsume index  According to Definition 7 and Definition 8, concise min-max association rules are composed of generator g, and the subtraction of closed itemset c and g. To compute g and c\g efficiently, the subsume index [12, 13] proposed by us is used.

Definition 9. The subsume index of item i is subsume(item)={j?IS | j?item?g(item)?g(j)}.

Furthermore, the following properties are used for pruning.

Theorem 6. Let X be an itemset, X?subsume(X) is a closed itemset [13].

Based on bitmap representation, we have proposed the algorithm for computing subsume index in [12, 13]. The basic idea is: for item i, intersecting all transactions in g(i), items corresponding to 1 (except i) in the result constitutes subsume(i).

4.3. Algorithm for generating concise rules  Algorithm 2. CS-Apriori  Input: dataset, minimum support threshold  Output: concise association rules  1) for each p?F1 do  2)  if (|g(p)|!=N) then //N is the number of  transactions in dataset  3)     G1?p;  4)     subsume(p)=Gen-Subsume(p);   //computing subsume index of p  5)    determine whether p? subsume(p) belongs  to CSMinMaxER according to Theorem 2;  6)  end if  7) end for  8) for (k=2; FK-1??; k++) do  9)  Gk=Candidate-Gen(FK-1);  10)  for each gen?Gk do  11)   subsume(gen)=Gen-Subsume(gen);  12)    determine whether gen? subsume(gen)  belongs to CSMinMaxER according to Theorem 2;  13)   Approx(gen, subsume(gen), k);  14)  end for  15)end for  Procedure Approx(gen, subsume, level)  16) for (k=1; k<level; k++) do  17)  for each g?Gk do  18)   determine whether g? subsume(gen)  belongs to CSMinMaxAR according to Theorem 3; 19) end for In Algorithm 2, frequent 1-generators are dealt  separately in Step 1 to Step 7. It should be mentioned that, if the support of certain item is 1, the item is definitely not a generator, because the support of its subset ? is also 1. For each 1-generator, subsume index is calculated in Step 4.

According to Theorem 6, for generator p, p?subsume(p) is a closed itemset, Step 5 determines whether p? subsume(p) belongs to CSMinMaxER according to Theorem 2.

Similar procedure is executed in the loop (Steps 8 to 15).

The function of Procedure Approx is to generate concise min-max approximate rules according to Theorem 3.

5. Performance Evaluation  We chose two real datasets for testing the performance of CS-Apriori. All datasets are taken from the FIMI repository page http://fimi.cs.helsinki.fi, Table 1 shows the characteristics of these datasets. The source code of Apriori is downloaded from the home page of Bart Goethals http://www.adrem.ua.ac.be/~goethals/. The experiments were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory.

Table 1 Characteristics of datasets  Datasets # Items # Records Avg. Length  Mushroom 119 8,124 23  Pumsb* 2088 49,046 50.5       (a) Mushroom    (b)Pumb*  Figure 1. Comparison of exact rules discovered by CS-Apriori and Apriori   Figure 1 shows the result of comparing exact rules  discovered by CS-Apriori and Apriori. On Mushroom dataset, the number of rules discovered by Apriori is about 4.6 to 13.2 times than the number of rules discovered by CS-Apriori; On Pumsb*, the number of rules discovered by Apriori is about 4.2 to 10.7 times than the number of rules discovered by CS-Apriori.

(a) Mushroom         (b)Pumb*  Figure 2. Comparison of approximate rules discovered by CS-Apriori and Apriori   Figure 2 shows the result of comparing approximate rules discovered by CS-Apriori and Apriori under different confidence thresholds. On Mushroom dataset, when minimum support threshold is set to 30%, the number of approximate rules discovered by Apriori is about 8.5 to 14.3 times than the number of approximate rules discovered by CS-Apriori; On Pumsb*, when minimum support threshold is set to 50%, the number of approximate rules discovered by Apriori is about 6.1 to 8.2 times than the number of approximate rules discovered by CS-Apriori.

6. Conclusions  In this paper, we have presented the new concepts of concise association rule based on generators and closed itemsets, discussed the rationality of the definition, proposed the corresponding pruning strategies, designed the mining algorithm. Experimental results show that the concise rules with smaller sizes can be discovered. Thus, the understandability of mining result is improved.

Acknowledgements  This work is supported by Key Youth Research Project of North China University of Technology.

