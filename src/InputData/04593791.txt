Mind Evolutionary Algorithms Based on Knowledge*

abstracting and analysis are used in this paper to discover the knowledge of the data in the evolution process and guide the action of the evolutionary algorithm through the knowledge discovered. So Mind Evolutionary Algorithm has taken a step in imitating human thinking, and its performance has been effectively improved.



II.  BASIC CONCEPTION Rough Set Theory is a mathematics theory of analyzing the data. While analyzing the data, it only needs the data set that correlate with the question without any transcendent information, and it can analyze and deal with the information which is inaccurate, inconsistent or incomplete effectively.

From the information above, it can find hidden knowledge and reveal its potential rule.

A. Knowledge Representation System?KRS[7] Knowledge representation is achieved through knowledge expression system. It is composed of object sets whose knowledge is described by the target attributes and themselves. A knowledge representation system can be expressed by  , , , ,S U C D V f=                          (1)  Where, U is the universe; C?D=R are attribute sets (equivalence relation set), subsets C and D are respectively condition attribute and decision attribute. V=?r?RVr is the set of attribute value. Vr is the range of r?R. f:U?R?V is an information function, it appoints the attribute value of each object in the universe. The definition (1) makes it possible to express knowledge in form of decision table.

B. Indiscernibility relation In rough set theory, knowledge is connected with classification while knowledge is regarded as an ability to classify the objects represented by the attribute set. The module of knowledge is composed of the concept that is generated by classification. The classification is substituted by equivalence relation in rough set theory.

Let K=(U,R) be an information system, then in any B?R there is an associated equivalence relation INDR(B):  ( ){ }( ) , : ( ) ( )RIND B x x U U a B a x a x? ?= ? ? ? ? =     (2) INDR(B) is called the B-indiscernibility relation. The equivalence relation in the universe and the equivalence classes which formed by the universe have revealed the   Proceedings of the 7th World Congress on Intelligent Control and Automation  June 25 - 27, 2008, Chongqing, China    granular structure of the knowledge. The equivalence classes formed by equivalence relation are denoted by [x]B.

{ }[ ]Bx y U yBx= ?                             (3) U/B stands for all of the equivalence classes in the universe lead out by R, forming a cluster of partition to U.

This partition of the universe is denoted by U/B.

[ ]{ }BU B x x U= ?                            (4) C. Space partition of searching space based on indiscernibility relation The data in the evolution process can be regarded as a knowledge system. Based on the indiscernibility relation in RST, the solution space of MEA can be divided into different regions by partitioning fitness function or object function.

Suppose that a multi-optimal problem is given a non- empty set S as the solution space of MEA. Let S be a bounded set in the n-dimension Euclidean space Rn, as [ ]1 ,ni i iS a b== ? , where ai<bi, i=1,2,?n. Marking any individual in MEA  operation as X, X={x1,x2,?,xn}, xi?[ai,bi], xi is called variable phenotype, in order to explain conveniently, it is called individual variable here, and n is the number of the variable.

The corresponding fitness function or each object function is  1 2{ , , , }v v vhF f f f= ? , h is the number of the object function. X and its corresponding fitness function F constitute an ordered pair {X,F}, hence consisting the universe U.

If the interval [ai,bi] of each variable xi is divided probably, for instance, by m-division method, that is, the solution space S of MEA can be divided into a series of solution subspace S? where S??S.

1 1 *( 1), *n m i i i ii ii k  b a b a S a k a k  m m= = ? ?? ?? = + ? +? ?? ?  ? ?     (5) S? or the union of S? is called optimum-searching subspace.

Suppose the bigger the value of the object function is better, and the minimum of the object function can be changed into the maximum of the object function through the proper transformation. Therefore, adopting a set of thresholds ?j,?j(0<?j<?j) where j is the number of the object function, j=1,2,?,h, we define the following equivalent relation.

Relation 1: In the evolution process, the solutions in some searching spaces are excellent, that is, the index of each object function is greater than the corresponding threshold ?j:  1 1 ( )  j  h  v jj R f ?  = = ? ?                             (6)  Relation 2: In the evolution process, the object functions in some solution space are very bad and can not be accepted, that is, the index of all the object functions are less than the corresponding threshold ?j:  2 1 ( )  j  h  v jj R f ?  = = ? <                             (7)  There are other searching spaces which have the good solutions. The solutions are between relation 1 and relation 2.

Therefore, the whole solution space can be divided into three parts as follows:  ( ),  j  h  POS v jj S S f S S?  =  ? 	? ?= ? ? ? ? ?  ?                  (8)  ( ),  j  h  NEG v jj S S f S S?  =  ? 	? ?= ? < ? ? ?  ?                  (9)  BON POS NEGS S S S= ? ?                            (10) Where SPOS is the subset of solution space where exist the excellent solutions, SNEG is the subset of the bad solution space, SBON is the subset of the solution space which has the optimum solution potentially. It can be seen in Fig. 1. It can be evolved directionally in the different areas based on the real situation.

Fig. 1. Solution space partition base on equivalence relation  D. Granular extension of RST Let K=(U,R) be an information system, where U={u1,u2,???,un} is the universe, R={r1, r2,???,rm} is the attribute set. If P?R, and P??, then ?P is the indiscernibility relation of P, marked as IND(P). The independent equivalent classification can be divided by any subset P?R, and the equivalent classification is denoted as granule[12].

The equivalence classification of Uind(P) is called the granule with knowledge P. Elements in the same granule is indiscernibility. To any element in the granule, its position in the universe can be marked with its subscript. In this paper, each granule with knowledge P is denoted by binary string with length L.

Suppose there are L elements: u1,u2,?,ul,?,uL(1?l?L) in universe U, for the subset [Y]i in Uind(P), the coding space is defined as a mapping function from integer domain to binary space f:Z+?{0,1}L, and the binary string of granule [Y]i can be respectively expressed as:  1 2{ , , , }  i l LY a a a a= ? ?                          (11)   l i  l l i  if u Y a l L  if u Y ??  = ? ? ??                  (12)  E. Binary matrix between condition attribute and decision attribute[13] Given granule Xi with knowledge P in its condition attribute set, where the value of i can change from number 1 to n, and given granule Yi with knowledge Q in its decision attribute, where j can change from number 1 to m. Then the dependent relationship that decision attribute Y on condition attribute X can be determined by doing the operation of Xi?Yi.

In order to make the calculation convenient, matrix AX and AY are adopted to denote the binary granule with condition attribute and decision attribute respectively. Binary logic operation based on matrix is introduced to pursuit the relation between fitness function and the variable of individual.

11 1  1 2    ( , , )    l  Y i i il  n nl  a a A Y Y Y  a a  ? ? ?? ? ? ?= ??? = ?? ? ? ? ? ? ? ?? ? ? ?? ? ?? ?  (13)  11 1  1 2    ( , , )    l  X j j jl  m ml  b b A X X X  b b  ? ? ?? ? ? ?= ??? = ?? ? ? ? ? ? ? ?? ? ? ?? ? ?? ?  (14)  X Y X YT A A? ?= ?                                (15)    1    ( ) 0 1, 2, , ; 1,2, ,  0   ( ) 0  L  il jl l  jk L  il jl l  if a b t i n j m  if a b  =  =  ? ? >??= = =  ? ? = ??  ?  ? ? ?   (16)  Where, ??? is the ?and? operation in logic, ??? is the traditional Cartesian product, tjk shows the subordinative relation between [xi]j and [f]k.



III. KNOWLEDGE BASED MIND EVOLUTIONARY ALGORITHM  A. Algorithm description To an evolutionary optimal searching problem, the distribution of the optimal solution in the solution space is unknown, and to some complicated problems, such as multi- peak function or deceptive function, the optimal solution may be distribute in different areas of the solution space. So, in the algorithm of KMEA, it produces bigger initial groups in the solution space at random, then, it makes the initial group similartaxis to search the whole solution space in order to get data as much as possible. The knowledge of the initial group can be discovered by dissimilation process. Then, a new generation of optimal searching subspace is generated under the guidance of the knowledge discovered. Now, each subspace obtained can do the similartaxis process. The dissimilation process can be done when the population in each group is mature. At last, adjust the evolution subspace again according to the knowledge discovered. The algorithm is showed as ALG.1.

__________________________________________________ ALG.1 Knowledge based Mind Evolutionary Algorithm input: The desired question and parameter of KMEA output: Optimum results begin  t?0; 1 2(0) { (0), (0), , (0)}nPOP = ?x x x ; //Produce the initial  group at random (0) ( (0))B similartaxis POP= ; // make the initial group  similartaxis 0 0 0 1 2{ , , , , } ( (0), , , , )NsS S S S dissimilation B M N? ?=? ; //  Confirm Ns superior solution subspaces, and regard the whole solution space S as a subspace too  while (not termination-condition) do t?t+1 for (all subspace) do  // similartaxis in each group  ( ) ( , , , , )ti i G s mB t similartaxis S N P P?= end  1 2 1 2   { , , , , } ({ ( ), ( ), , ( ), ( )}, , , , )  t t t Ns  Ns Ns  S S S S dissimilation B t B t B t B t M N? ?+  =? ? ; //  Dissimilation process: adjust the evolution subspace according to the knowledge discovered  end end __________________________________________________  B. Procedure similartaxis The pseudocode in the similartaxis process is shown as ALG.2. Firstly, spread NG individuals into the subspace  t iS  at  random. Secondly, calculate the individual's score and sort them in order. Then, select NG?Ps superior individuals according to the proportion Ps. Finally, make mutation to these superior individuals based on the probability Pm of mutation, forming the new group and doing iterative operation to the new group formed. This process is similar to the similartaxis operator of MEA in the aspect of study, and the difference is that MEA regards the superior individual with the highest score as the centre to spread while the similartaxis process chooses lots of superior individuals and spreads the new generation by these superior individuals. So the later is better in the aspect of keeping the group?s diversity than the former, at the same time, the similartaxis process adopted the iterative operation and select mechanism, so that it is propitious to the evolution of the group, and it can improve the ability of local searching and optimal searching effectively.

__________________________________________________ ALG.2 Procedure similartaxis input: , , , ,ti G s mS N P P? output: ( )iB t begin  1 2( ) { ( ), ( ), , ( )} t  i n iPOP t t t t S= ??x x x ( ( ))i iscore f POP t=  while ( ( ( )) ) doiT POP t true? ( ) ( ( ), )i i sPOP t s POP t P? = ; // Rank Selection ( ) ( ) ( ( ), )i i i mPOP t POP t m POP t P?? ? ?= + ; // Learning from  the superior individuals ( ( ))i iscore f POP t??= ; // Evaluating individuals  ( ) ( ( ))i iB t Update B t? = ; // Update the information on the local billboard  end end  C. Procedure dissimilation In the process of dissimilation, the knowledge discovered is used to confirm the subspace to be used by the similartaxis process next time. When the similartaxis process of the group is over, the evolutionary information of each group is memorized on its billboard, and the information on the billboard is gathered by the function of Gather() to form information base. Then the individual and score are discretized into N grades and M grades respectively by function Discretize() to form the discretized information table (DIB, for short). When the redundancy information is eliminated,     calculate the relation matrix TX?Y, where the matrix reflects the relation between individual variable and object function. Then base on the matrix TX?Y, the eigenvector can be gained, and the type of the desired question and the optimal searching subspace of next step can be confirmed. The pseudocode of dissimilation process is shown as ALG.3.

_______________________________________________ ALG.3 Procedure dissimilation input: 1 2 1{ ( ), ( ), , ( ), ( )}Ns NsB t B t B t B t+? , , , ,M N? ? ; // The information on the billboard and relevant parameter output: 1 2{ , , , , }  t t t NsS S S S? ; // subspace  begin 1 2 1({ ( ), ( ), , ( ), ( )})Ns NsIB Gather B t B t B t B t+= ? ; // Gather  information about evolution, forming information base ( , , )DIB Discretize IB N M= ; // Discretization of the  information Base ( )RDIB Reduct DIB= ; // Eliminate redundancy  information in the information base ( , ) ( , , )X YA A Gtran RDIB N M= ; // Transform into a binary granular matrix X Y X YT A A? ?= ? ;// Calculate the connection matrix of individual variable and object function.

1 2{ ( ), ( ), , ( )} ( )n X YG x G x G x Getg T ?=? ; // Calculate the eigenvector.

1 2( ( ), ( ), , ( ))nPT Getpt G x G x G x= ? ; //Confirm the type of the question according to the eigenvector.

1 2{ , , , , } ( , , , ) t t t t  Ns X YS S S S Getspace T PT ? ?? ?=? ; // Adjust the evolutionary subspace based on the knowledge discovered.

end __________________________________________________  D. Binary relation of individual variable and fitness function Discretize individual X and its fitness function Y into N grades and M grades respectively, where N and M are integer and they are bigger than number one. The corresponding value region after discretization are VX ={0,1,?,N-1} and VF={0,1,?,M-1}. The discretization of individual variable is equivalent to divide the solution space of the individual variable into N independent subspaces. Base on RST, the phenotype xi of the individual variable is regarded as condition attribute, and the fitness function is regarded as decision attribute. After discretization, a series of equivalence classification [xi]j and [f]k are formed, where the range of j is from number 1 to N while k is from number 1 to M, and then transform it into binary granule.

The function max f1(x1,x2) in Table 2, which is shown in Fig. 2 is a representative multi-optimal function. It has multi global maximum and minimum as well as local extremum. In this paper, we take global maximum as the example to explain the algorithm.

Fig. 2. The figure of max f1(x1,x2)  This function has two variables x1 and x2, when the simulartaxis process of the initial group is over, a series of data{Xt,Ft} can be obtained, here, the range of ?t? is from number 1 to Q, and Q is the quantity of the individuals produced in the simulartaxis process. Discretize the variable x1 and x2 into 21 grades, and the discretization of fitness function is also 21 grades. After that, the matrix  1 2 ,x f x fT T? ? can be  computed and expressed as Fig. 3. It reflects the relation between each subspace of individual variables x1 and x2 and its fitness function. Therefore, the panorama of the problem can be found out by the relation of individual variable and its fitness function, and the binary granule computing is used to find the relation. The type of the question can be confirmed, and the direction of searching can be selected when the relation of variable subspace and its fitness function has been mastered efficiently. This process is similar to human beings, and with the finer classification, more details will be extracted.

Fig. 3. Relation graphic of individual subspace and fitness of max f1(x1,x2)  E. Eigenvector of the optimization problem In order to judge the type of the questions optimized by the data that generated in the former evolution process, the contribution of each subspace of some variable to the fitness function should be measured first, and the variable comes from individual. Define the following function:  ( ) { ( 1), 1,2, , }j i k k jkG x MAX g g t k k M= = ? ? = ?          (17)  Where, j=1,2,?,N, stands for different subspace, xi stands for the ith variable of the individual. Calculate the individual variable xi and the contributions that different subspaces to their fitness function respectively, forming the eigenvector which will be used to judge the type of the optimal problem:  ( ) { }1( ), , ( ), , ( ) , 1,2, ,i i j i N iG x G x G x G x j N= =? ? ?  (18) Calculate the eigenvectors G(x1) and G(x2) of max f1(x1,x2), and plot them in Fig. 4.

Fig. 4. eigenvectors of max f1(x1,x2) After some generations evolution, no matter the optimal solution of the problem has been obtained or not, review the eigenvector G(xi) of each variable of individual based on the knowledge discovered. If the eigenvector is monotone, it is a single-model problem; if it is non-monotone and with only one maximum, it also can be regard as a single-model problem; if there are more than one maximum in the eigenvector, it is a multi-model problem and maybe it is a deceptive problem.

The function max f1(x1,x2) is a typical multi-model problem, it can be find out by the eigenvectors G(x1) and G(x2).

After getting the type of the desired question, the searching speed can be improved by confirming a subspace which is used for optimal searching to a single-model problem. However, to a multi-model problem, many optimal searching spaces can be confirmed based on the information offered by the binary matrix. Thus, the algorithm?s optimal searching efficiency can be enhanced and the deceptive problem can be avoided.

F. Confirming the evolutionary subspace The choice of superior group is based on ranking method in the algorithm of MEA at present, and the quantity NS of the superior group chosen is decided. When NS  is smaller, the task of the algorithm is light, but to a multi-model problem, it may leak the global optimal point; when NS  is greater, the task is too heavy to a single-model problem, and the efficiency of optimal searching will be reduced.

Using the threshold value ?,?(0<?<?<M) defined above, the algorithm divide the subspace into superior solution region S  POS, boundary region SBON , and negative solution region SNEG.

according to expressions (8) and (9). The individual subspace in the SPOS is corresponding with good fitness function and in the SBON, the individual of the subspace in the boundary region is likely to be the potential excellent solution. For example, the function max f1(x1,x2) is a difficult multi-optimal problem, and the threshold value is choice as ?=6, ?=14. If the fitness value ?F? of the function is greater than or equal to the number of ? after discretization, the corresponding individual subspace was denoted as superior solution region.

Fig. 5. The distribution of superior solution region of function max f1(x1,x2) The subspace with potential optimal solution of function max f1(x1,x2) can be clearly seen in Fig. 5. Choose nine subspaces showed in the picture above. Then, expand them  appropriately with expand coefficient ?(??1), and take these  subspaces as the evolution space, so that we can find out lots of optimal solution of the function in the space. The subspaces confirmed have been shown in Table 1. The groups and their quantity which confirmed by this means is based on the knowledge produced in the process of evolution. In this way, it can prevent the influence to the efficiency of the calculation, and it also can prevent the influence to the result of optimal searching when the value of NS which has been chosen is too big or too small.

Table 1. Optimal searching subspace of function max f1(x1,x2) Subspace  Index x1 x2  1 [-8.5,-6.5] [-8.5,-6.5] 2 [-8.5,-6.5] [-2.5,-0.5] 3 [-8.5,-6.5] [4.5,6.5] 4 [-1.5,-0.5] [-8.5,-6.5] 5 [-1.5,-0.5] [-2.5,-0.5] 6 [-1.5,-0.5] [4.5,6.5] 7 [4.5,6.5] [-8.5,-6.5] 8 [4.5,6.5] [-2.5,-0.5] 9 [4.5,6.5] [4.5,6.5]  After determining the subspace in Table 1, the algorithm takes the whole solution space as an independent subspace to do the iteration process in order to get further optimum of the function. The evolution process of every subspace shows as Fig. 6(a). The optimum solution of the function has been found out in each superior solution region. The blue broken line stands for the result searched which taking the whole solution space as an independent searching space. Fig. 6(b) shows the records when MEA adopts the same tactics to restrain the population, and the records include the evolution process of the former nine superior groups in each generation.

Contrast the two methods, it is easy to find out that the algorithm of KMEA which based on the guidance of knowledge can find out all of the nine optimal solutions of the function maxf1(x1,x2), and the convergent speed of KMEA is faster than the speed of common algorithm of MEA.

(a)                                                               (b)  Fig. 6. Contrast between KMEA and MEA, (a)The evolution process of every subspace of function max f1(x1,x2) in KMEA, (b) The evolution process of the  former nine superior populations in MEA  ?.  SIMULATION EXPERIMENT In order to test the efficiency of the algorithm which has been brought forward in this paper, the functions in Table 2 are taken for simulation. The parameters of KMEA in the simulation process are set as follows: the initial population is 200, the group NG in the similartaxis process is 100, the probability of choice Ps is 0.4, the probability of variation Pm is 0.1, and the iteration times in the process of similartaxis are 100. While the parameters of MEA in the simulation process are set as follows: the group is 100, the superior group NS is 20     and the temporary group NT is 80. Each function has been tested for thirty times, and the results are shown in Table 3.

Table 2. Test function  Function  f1 ( ) ( )  5 5  1 1 2 1 2 1 1  max ( , ) cos 1 cos 1 i i  f x x i i x i i i x i = =  = + + ? + +? ? ? ?? ? ? ?? ?  x1, x 2?[-10 , 10], fmax=210.482  f2 2 2 2  2 1 2 1 2 1max ( , ) 100( ) (1 )f x x x x x= ? + + x?[-2.048,2.048], fmax =3905.926  f3  2 2 2 21  3 1 2 1 1 1 2 2 2min ( , ) (4 2.1 ) ( 4 4 )3 x  f x x x x x x x x= ? + + + ? +  x?[-1 , 1], fmin =-1.0316284  f4 2 2  4 1 2 2 1 1 12  5.1 5 1min ( , ) ( 6) 10(1 ) cos 10  f x x x x x x ? ??  = ? + ? + ? +  x1?[-5,10], x2?[0.15], fmin= 0.3979  f5 2 2 0.25 2 2 2 0.1  5 1 2 1 2 1 2min ( , ) ( ) (sin (50( ) ) 1)f x x x x x x= + + + x?[-10 , 10], fmin =0.0    Table 3. Test Result  Calculation time of the object function  optimal value (average value?  Convergence time Function  MEA KMEA MEA KMEA MEA KMEA f1 103591 56851 210.48176 210.482 23 30 f2 16307 15722 3905.9262 3905.9262 30 30 f3 70300 18639 -1.0316263 -1.0316281 30 30 f4 59568 21506 0.397908 0.3979 26 30 f5 76533 19622 0.025376 0.01012 26 30  The mode of multi-group evolution is adopted by both MEA and KMEA. To a function with multi-optimal points, they ought to find out all of the optimal points, so the standard of convergence is to find out the whole optimal points of every function. The data in Table 3 are the mean values after the convergence of the algorithm, and the calculation time of object function is the calculation time before all the optimal solutions are found. The result in Table 3 shows that the KMEA algorithm is convergent in the thirty times test, while the MEA algorithm is partly convergent. The precision of searching of KMEA is higher than MEA, and the calculation time of object function is obviously less than MEA algorithm.

?. CONCLUSION In the course of human thinking, the main content which is also regarded as the basic of human thought is that people analyze the thing and its course, obtain the knowledge and use it to infer or make decision.

In this paper, a huge amount of data is regarded as a knowledge base in the evolution process. The rough set is used to reduce and classify the data and the KMEA is used to divide the individual variable into the different subspaces which are expressed by the binary granule. Based on it, the matrix-based binary granule calculation is introduced to find the relation between the variables and their fitness functions.

The relation reflects the dependence of fitness function on the different subspaces of variables, and shows the whole outline of the problem as well. This paper defines the eigenvector of  the optimization problem, and judges whether the problem belongs to the multi-modal problem by each eigenvector in order to make decision. With the reference of the multi- population evolution, the whole solution space can be divided into multi optimum searching subspaces with the obtained knowledge. It can form the multi-subpopulation evolution.

The test function shows that the proposed algorithm is good to increase the convergent speed of the MEA. The proposed algorithm shows the good performance for the multi-modal function and multi-objective optimization. Therefore the knowledge-based algorithm is effective.

Because the research of combination of RST and evolution algorithm is inchoate, there are still a lot of questions to be further study. For example, the synthetic and reasoning of knowledge, the expression of the relation of high- dimension parameter space, etc. At the same time, the parameter in the algorithm, including the degrees of the data discretization and the size of the granule as well as the problem of how to confirm the threshold value are all need for further study and discussion. All the above will be author's research direction in the future.

