Password Strength Prediction using Supervised   Machine Learning Techniques

Abstract?Passwords are a vital component of system security. Though there are many alternatives to passwords for access control, password is the more compellingly authenticating the identity in many applications.  They provide a simple, direct means of protecting a system and they represent the identity of an individual for a system. The big vulnerability of passwords lies in their nature. Users are consistently told that a strong password is essential these days to protect private data as there are so many ways for an unauthorized person with little technical knowledge or skill to learn the passwords of legitimate users. Thus it is important for organizations to recognize the vulnerabilities to which passwords are subjected, and develop strong policies governing the creation and use of passwords to ensure that those vulnerabilities are not exploited. In this work password strength prediction is modeled as classification task and supervised machine learning techniques were employed.  Widely used supervised machine learning techniques namely C 4.5 Decision tree classifier, Multilayer Perceptron, Na?ve Bayes Classifier and Support Vector Machine were used for learning the model.  The results of the models were compared and observed that SVM performs well.  The results of the models were also compared with the existing password strength checking tools.  The findings show that machine learning approach has substantial capability to classify the extreme cases ? Strong and weak passwords.

Keywords? Password Strength, Machine Learning, Support Vector Machine, Classification, Feature Extraction

I.  INTRODUCTION Life these days have become largely dependent on  passwords. A typical computer user may require passwords for many purposes: logging in to computer accounts, retrieving e- mail from servers, transferring funds, shopping online, accessing programs, databases, networks, web sites, and even  reading the morning newspaper online.   The problem of selecting and using good passwords is becoming more important every day. The number and the importance of services that are provided through computers and networks increase dramatically and in many cases such services require passwords or other forms of user identification. For different reasons, including obvious security concerns, users have to use different passwords for different systems or services, making it more difficult to remember and protect one?s password.

Passwords are not only critical for login identification, but also in more sophisticated service-granting systems, such as Kerberos. Finally, passwords are needed for protecting secret information that cannot be remembered by the user (e.g. private keys) in authentication and encryption software that is becoming essential to many applications.

The average user chooses a simple, guessable, memorable password and cares less about choosing a strong password.

Nowadays there is a real and growing threat of data thieves, hackers and other criminals taking advantage of people who aren't security conscious.  Thus it is important for organizations to recognize the vulnerabilities to which passwords are subjected, and develop strong policies governing the creation and use of passwords to ensure that those vulnerabilities are not exploited.



II.  PASSWORD STRENGTH A password is a secret word or string of characters that is  used for authentication, to prove identity or gain access to a resource [1]. Password strength is a measurement of the effectiveness of a password in resisting guessing and brute- force attacks. The key to a strong password is length and complexity. Length is simply the number of individual   DOI 10.1109/ACT.2009.105     characters used in the creation of the password, while complexity refers to the number of characters that could potentially be used in the creation of the password. Using strong passwords lowers overall risk of a security breach.

Most of the password strength checking tools rates the password as very weak, weak, moderate/medium/good, strong and very strong. A password standard describes that a password should satisfy the following criteria: they should have at least eight characters, including a mixture of upper- and lower-case and some numbers and special characters; the password should also not use personal information, the account name, or dictionary words in any language.

For a password of a given length, the number of permitted symbols determines its maximum possible strength. Users rarely make full use of larger character sets in forming passwords. Most of the survey results reveal that 10% to 15% of the users? passwords used mixed case, numbers, and symbols. Though there are many alternatives to passwords for access control, password is the more compellingly authenticating the identity in many applications. Hence the requirement of an effective password policy and proactive password checking system of an organization increases, that helps in selecting strong passwords and managing them, to protect the identity and the resources.

Commercial tools available for password strength checking include Google Password Meter (Google, 2008), Microsoft Password Checker (Microsoft, 2008) and The Password Meter (Password Meter, 2008). These tools adopt different principles and methodologies.  All these password meters use lexical rules.  Decision trees were also used to check the strength of the password [2]. Enfilter is a Windows based tool that employs decision tree classifier, lexical analysis to proactively assess the strength of the password [3].

Passwords are highly prone to brute force attacks that are something actual and have to be addressed in a proper manner.

Hence analyzing the strength of the password has been modeled as a classification problem and  had been dealt using supervised machine learning approach.



III.  MACHINE LEARNING ALGORITHMS Four machine learning algorithms,  C 4.5 Decision tree  classifier, Multilayer perceptron, Na?ve bayes classifier and Support Vector Machine were used for learning the classification model.

A. Multilayer Perceptron Multilayer Perceptron (MLP) network is the most widely used neural network classifier.  MLP networks are general- purpose, flexible, nonlinear models consisting of a number of units organised into multiple layers. The complexity of the MLP network can be changed by varying the number of layers and the number of units in each layer. Given enough hidden units and enough data, it has been shown that MLPs can approximate virtually any function to any desired accuracy. In other words, MLPs are universal approximators. MLPs are valuable tools in problems when one has little or no knowledge  about the form of the relationship between input vectors and their corresponding outputs.

B. C4.5 Decision tree induction Decision Tree Classification generates the output as a  binary tree like structure called a decision tree, in which each branch node represents a choice between a number of alternatives, and each leaf node represents a classification or decision.  A Decision Tree model contains rules to predict the target variable. This algorithm scales well, even where there are varying numbers of training examples and considerable numbers of attributes in large databases.

J48 algorithm is an implementation of the C4.5 decision tree learner. This implementation produces decision tree models. The algorithm uses the greedy technique to induce decision trees for classification. A decision-tree model is built by analyzing training data and the model is used to classify unseen data. J48 generates decision trees, the nodes of which evaluate the existence or significance of individual features.

C. Na?ve Bayes Classification The Naive Bayes Classifier (NB) is a simple but effective  classifier which has been used in numerous applications of information processing including, natural language processing, information retrieval, etc. The Naive Bayes Classifier technique is based on Bayesian theorem and is particularly suited when the dimensionality of the inputs is high. Na?ve Bayes classifiers assume that the effect of a variable value on a given class is independent of the values of other variable.  The Naive-Bayes inducer computes conditional probabilities of the classes given the instance and picks the class with the highest posterior. Depending on the precise nature of the probability model, Naive Bayes classifiers can be trained very efficiently in a supervised learning setting.

D. Support Vector Machine Support Vector Machine a new approach to supervised  pattern classification that has been successfully applied to a wide range of pattern recognition problems. Support vector machine is a training algorithm for learning classification and regression rules from data. SVM is most suitable for working accurately and efficiently with high dimensionality feature spaces. SVM is based on strong mathematical foundations and results in simple yet very powerful algorithms [6-9].

The standard SVM algorithm builds a binary classifier. A simple way to build a binary classifier is to construct a hyperplane separating class member from non-members in the input space. SVM also finds a nonlinear decision function in the input space by mapping the data into a higher dimensional feature space and separating it there by means of a maximum margin hyperplane. The system automatically identifies a subset of informative points called support vectors and uses them to represent the separating hyperplane, which is sparsely a linear combination of these points. Finally SVM solves a simple convex optimization problem.

The machine is presented with a set of training examples, (xi,yi) where the xi are the real world data instances and the yi are the labels indicating which class the instance belongs to.

For the two class pattern recognition problem, yi = +1 or yi = - 1. A training example (xi,yi) is called positive if yi = +1 and negative otherwise. SVMs construct a hyperplane that separates two classes and tries to achieve maximum separation between the classes. Separating the classes with a large margin minimizes a bound on the expected generalization error.

The simplest model of SVM called Maximal Margin classifier, constructs a linear separator (an optimal hyperplane) given by w T x - ? = 0 between two classes of examples. The free parameters are a vector of weights w that is orthogonal to the hyperplane and a threshold value ?. These parameters are obtained by solving the following optimization problem using Lagrangian duality    where Dii corresponds to class labels, which assumes value +1 and ?1.  The instances with non null weights are called support vectors.

In the presence of outliers and wrongly classified training examples it may be useful to allow some training errors in order to avoid overfitting. A vector of slack variables ?i that measure the amount of violation of the constraints is introduced and the optimization problem referred to as soft margin is given below    ?i ?0  The minimization of the objective function causes maximum separation between two classes with minimum number of points crossing their respective bounding planes.

The parameter C is a regularisation parameter that controls the trade-off between the two terms in the objective function. The proper choice of C is crucial for good generalization power of the classifier. The following decision rule is used to correctly predict the class of new instance with a minimum error.

The advantage of the dual formulation is that it permits an efficient learning of non?linear SVM separators, by introducing kernel functions. Technically, a kernel function calculates a dot product between two vectors that have been (nonlinearly) mapped into a high dimensional feature space. Since there is no need to perform this mapping explicitly, the training is still feasible although the dimension of the real feature space can be very high or even infinite. The parameters are obtained by  solving the following non linear SVM dual formulation (in Matrix form),  Minimize DL ( ) =u T T1  u u - e uQ  Td u =0 , C? ?0 u e   where Q=DKD and  K is kernel matrix. The kernel function K(AAT) may be polynomial or RBF (Radial Basis Function) is used to construct hyperplane in the feature space, which separates two classes linearly, by performing computations in the input space. The decision function in this nonlinear case is given by    When the number of classes is more than two, then the problem is called multiclass SVM. There are two types of approaches for multiclass SVM. In the first method called indirect method, several binary SVM?s are constructed and the classifier?s output are combined for finding the final class. In the second method called direct method, a single optimization formulation is considered. The formulation of one of the direct methods called Crammer and Singer Method [9] is  Minimize  1 1   N n T k k i  k i C ?  = = +? ?w w    subject to the constraints  i( ) ( )   , k ki T T i i k i k i ke? ? ?? ? ? ? ?w x w x  where ki  is the class to which the training data xi  is given by  1i ik ke c= ?  ,  i  i  1 if k 0 if k  i k  k c  k =?  = ? ??  The decision function for a new input data xi  is given by  { } k  ? arg  max ( )j k jd f= x ,  where  .,,1,1)(       subject to 1    Minimize 2  liD i T  ii ?=?? ?xw  w  .,,1,1)(    subject to 1    Minimize 2  1,  liyD  c  ii T  ii  l  i i  ?=?+?  +? =  ?  ? ?  xw  w w  ]sgn[)( ??= xwf Tx  ( )??= uxxKf Ti *),(sgn)(x     ( ) ( )Tk j k j kf ? ?= ?x w x

IV. FEATURE EXTRACTION  Feature selection plays an important role in improving classification effectiveness, computational efficiency or both.

Distinctive features describing the characteristics of the password were extracted from a set of 10,000 passwords.

These passwords were generated using PC Tools Password Generator.  A weight was assigned to each relevant feature.

The twenty-seven descriptive features were created as a fixed length vector for password analysis.

Features include the  Length of the password, Weight of the password, Number of lowercase characters, Lowercase character weightage, Number of uppercase characters, Uppercase character weightage, Number of digits, Digits weightage, Number of symbols, Weightage of symbols, Number of middle number and symbols, Middle number/symbol weightage, Password contains characters only [case insensitive], Characters  only weightage, Password contains digits only, Digits only weightage, Number of repeat characters, Repeat characters weightage, Number of consecutive uppercase characters, Consecutive uppercase characters weightage, Number of consecutive lowercase characters, Consecutive lowercase characters weightage, Number of sequential characters, Sequential characters weightage, Number of sequential digits, Sequential digits weightage and  Password requirement weightage. The categorical attributes were converted into numeric data for SVM training.

A weighting method was adopted for computing the strength of the password.  The strength was decided based on the overall score.   Positive and negative weightages based on a predetermined scheme was used to determine the overall score.

Final score is capped with a minimum of zero and a maximum of 100.  The features that make the password strong were given more weightage and the features that weaken the password were given negative weightage.  Final score is the cumulative result of all bonuses and deductions.

The password classification scheme was designed based on the cumulative score that is given in TABLE I.

TABLE I.      PASSWORD CLASSIFICATION   Class     Score  Very Weak Less than 20  Weak 20 - 39  Good 40 - 59  Strong 60 - 79  Very Strong Greater than 80

V. EXPERIMENT AND RESULTS The password strength analysis has been carried out using  WEKA [5] and SVM Light   [6].

The Weka, Open Source, Portable, GUI-based workbench is a collection of state-of-the-art machine learning algorithms and data pre processing tools.

SVM Light [10] is an open source tool for multi class SVM which uses Crammer and Singer Method.  Passwords with length 8 were considered for classification.

In the experiments, the passwords for the training data set were generated using PC tools password generator[11]. The password dataset consists of 10000 passwords of varying strengths : Very weak, Weak, Good, Strong and Very strong.

The features were extracted from the password dataset and the respective training set was created for constructing the appropriate model.

The training set consists of equal number of instances of password of different categories.  The class labels were designated as 1, 2, 3, 4 and 5 to represent password strength as Very weak, Weak, Good, Strong and Very strong respectively.

The machine learning techniques - Na?ve Bayes Classifier, C 4.5 Decision tree classifier, Multilayer Perceptron were used for training the dataset in WEKA environment.

The same dataset was used for constructing the classifier based on Support Vector Machine using    SVM Light with kernels linear, polynomial and RBF.   In case of polynomial and RBF kernels, the default settings for d (Degree of polynomial) and gamma are used.

The performances of the trained models were evaluated using 10-fold cross validation for its predictive accuracy.

Predictive accuracy was used as a performance measure for password classification.  The prediction accuracy is measured as the ratio of number of correctly classified instances in the test dataset and the total number of test cases. The performances of the linear and non-linear SVM classifiers were evaluated based on the two criteria, the prediction accuracy and the training time.

Regularization parameter C was assigned different values in the range of 1 to 20 and found that the model performs better and reaches a stable state for the value  C = 15. The performance of the classifiers are summarized in TABLE II and shown in Fig.1 and Fig.2.

TABLE II.            COMPARATIVE RESULTS OF THE CLASSIFIERS Evaluation  Criteria Na?ve Bayes J48 MLP SVM  Training time (secs) 0.03 0.16 101.83 10.24  Correctly Classified Instances  7360 8720 8980 9830  Prediction Accuracy ( % ) 73.6 87.2 89.8 98.3        73.6 87.2 89.8  98.3         Na?ve Bayes J48 MLP SVM   A  cc ur  ac y  %   Fig. 1.      Classification Accuracy     0.03 0.16  101.83  10.24          B  ui ld  T im  e (S  ec on  ds )  Na?ve Bayes J48 MLP SVM   Fig.2.       Learning time of the models   The results indicate SVM with RBF kernel outperforms in  prediction than Na?ve bayes, decision tree and multilayer perceptron.

A randomly generated set of 1000 passwords were tested using the tools ? Google Password Meter, Microsoft Password Checker,  Password Meter, Beta version of Yetanother Password Meter  and the proposed SVM password strength checker.  The performance of the tools is shown in Fig.3.

100 160 180 230 240  240 220 170   160 160 210 190300  150 190 150 160  380 290 250 240 230         Google Microsoft password meter Yet Another Password Meter  Proposed SVM Checker   N  o.

o  f p as  sw or  ds  Very Strong  Strong  Good  Weak  Very Weak  Fig. 3.       Comparison of Password Strength Checking Tools  Fig.3 shows that the proposed SVM password strength checker identifies the extreme cases accurately.  This is the essential characteristic that is required for the organization to launch an authentication system that permits only strong passwords and filters weak passwords.



VI. CONCLUSION  This work models the password strength prediction as classification task and describes the machine learning approach for determining the strength of the password.  Na?ve Bayes classifier, Decision tree classifier, Multilayer perceptron, Support Vector Machine has been applied for training the password strength analysis model.  Features were extracted from the set of 10,000 passwords of different categories to facilitate training and implementation.  The performance of the model was evaluated using 10-fold cross validation and observed that SVM classifier trained with RBF kernel performs well.  Machine learning technique automatically learns by taking intelligent hints from the training data and make prediction accurately.

The results obtained by testing the human generated passwords using various popular password strength checking tools also confirms that the proposed SVM password checker can be employed for providing a highly secure environment.

