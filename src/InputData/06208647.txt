Novel Cloud Subset Preserving Mining (CSPM)  Algorithm for Association Rule Mining in

Abstract? The recent advancement in data mining technology to analyze vast amount of data has played an important role in several areas of Business processing. Data mining also opens new threats to privacy and information security if not done or used properly. The main problem is that from non-sensitive data, one is able to infer sensitive information, including personal information, fact or even patterns which are generated by any algorithm of data mining.  In order to focusing on privacy preserving association rule mining, the simplistic solution to address the problem of privacy is presented. The solution is to survey different aspects which are discussed in the several research papers and after analyzing those research papers conclude a new solution which is best in efficiency and performance. In this paper we propose a novel algorithm named Cloud Subset Preserving Mining (CSPM). The entire system architecture consists of three phases: 1) Check for Authentication. 2) Reading the database.  3) Perform Pruning.

Our algorithm is a good way to apply data mining techniques with security that hides our logical instances from others. The all the operations are performed in cloud computing environment.

Keywords ? Data Mining, Association Rule Mining, Privacy Preserving, CSPM

I. INTRODUCTION   In 1993[1], the association rule mining has received a great deal of attention. It is still one of most popular pattern- discovery methods in the field of data mining. Various proposals and algorithms have been designed for it in recent years. Simultaneity, Data mining algorithms are analyzed for the side-effects which incur in data privacy. Thus, several privacy-preserving techniques for association rule mining have also been proposed in the past few years. Various proposals and algorithms have been developed for centralized data, while others refer to a distributed data scenario.

Distributed data scenarios can also be classified as horizontal data distribution and vertical data distribution. Data mining technology can analyze massive data. Although it plays vital role in many domains, if it is used improperly it can also cause some new problem of information security. There are some new problems in the application of data mining recently. By studying deep in some special algorithms with association rule  mining, some techniques also can be applied to other data mining computations, such as decision tree inducers, association rule mining algorithms, clustering algorithms, rough sets and Bayesian networks etc.

Fast increasing of a series of digitized data causes people of the world attend the privacy problem of information more and more. Because the data mining technology of traditional centralized database must collect all the data together to process, it will cause the individual information abused or misused easily. Therefore more and more people will not to provide individual privacy data and suspect the using of data mining. Some people mine the privacy information pattern of the database owner from the original data. It has harmed the database owner's benefit. In order to solve the privacy preserving problem of association rule in centralized database, before publishing database we should hide the privacy or the sensitive information pattern of the database owner including the sensitive association rule information [2, 3].

Usually we use disturbing data method to change the data of original database to hide association rule. But the data disturbance may generate some information pattern that is not existed at all or reduce the accuracy of the original database. Before executing the privacy preserving algorithm, we should analyze the information pattern of association rule and the data structure of the database and find the preferred plan to keep the balance between the accuracy of database information and the privacy of sensitive information.

However, data mining also brings some problems. For example, credit card centres may intentionally or unconsciously make sensitive information of clients leak while mining relating information of clients. With the Internet popularity, because more and more information can be obtained in electronic form, that people have their own privacy confidential is becoming increasingly urgent.

According to statistics, even if privacy protection measures, about one-fifth of Internet users don?t like to provide their own information to the Web site and more than the half investigators only in good privacy-preserving measures are willing to provide their own information to the Web site. Among the potential consumers shopping in    internet browser, there are almost half who gave up the hope for internet shopping because of worrying about no protection of their privacy. Therefore, how to ensure personal privacy in data mining has become a need to be addressed. The service overview is shown in fig1.

Fig1 Service Overview  We provide here an overview of privacy preserving association rule mining. The rest of this paper is arranged as follows: Section 2 introduces Association rule mining strategies; Section 3 describes about Privacy Preserving Algorithm; Section 4 shows the evolution; Section 5 describes the proposed method. Section 6 describes Conclusions.



II. ASSOCIATION RULE MINING   The association rule mining can be conceptualized as follows [4]: Let I= {i1,i2,?,im} be the set of all items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T is subset of I. Each transaction is associated with an identifier, called TID. Let X be a set of items. A transaction is said to contain X if and only if X is subset of T. An association rule is an implication of the form X is subset of Y, where X is subset of T, Y is subset of T, X?Y=NULL, the support s and confidence c of the rule X is subset of Y are defined as: s=Count(X)/|D|,c= Count(X is subset of Y)/ Count(X).

A set of items is referred as an item set. An item set that contains k items is a k-item set. The support count of an item set is the number of transactions containing the item set. An item set is frequent if its support count is not less than the minimum support count. Rules with the support more than a minimum support threshold (smin) and the confidence more than a minimum confidence threshold (cmin) are called strong.

Association rule mining is a two-step process: (1) Finding all frequent item sets; (2) Generating strong association rules from the frequent item sets.

The purpose of privacy preserving is to discover accurate patterns without precise access to the original data. The algorithm of association rule mining is to mine the association rule based on the given minimal support and minimal confidence. Therefore, the most direct method to hide association rule is to reduce the support or confidence of the  association rule below the minimal support of minimal confidence. With regard to association rule mining, the proposed methodology that is effective at hiding sensitive rules is implemented mainly by depressing the support and confidence. The existing tree algorithms, D_CONF1, D_CONF2 and D_SUPP, are simply introduced in [5], which are to hide the sensitive association rule all by reducing the support or confidence.



III. PRIVACY PRESERVING ALGORITHM   A lot of implementations of the confidentiality of data and knowledge are applied in association rule mining process.

According to privacy protection technologies, at present, privacy preserving association rule mining algorithms commonly can be divided into three categories [6].

Heuristic-Based Techniques Heuristic-based techniques are to resolve how to select the appropriate data sets for data modification. Since the optimal selective data modification or sanitization is an NP-Hard problem, heuristics can be used to address the complexity issues.

The methods of Heuristic-based modification include perturbation, which is accomplished by the alteration of an attribute value by a new value (i.e., changing a 1-value to a 0-value, or adding noise), and blocking, which is the replacement of an existing attribute value with a ???.

There is a basic principle of choosing the transaction or the item of item set to be modified that we should reduce the influence of the original database as far as possible.

Those related works are given below.

1) Data Perturbation-Based Association Rule   The algorithms can be described as the following one. Let D be the source database, R be a set of significant association rules that can be mined from D, and let Rh be a set of rules in R. How can we transform database D into a database D', the released database, so that all rules in R can still be mined from D', except for the rules in Rh. The heuristic proposed for the modification of the data was based on data perturbation, and in particular the procedure was to change a selected set of 1-values to 0-values, so that the support of sensitive rules is lowered in such a way that the utility of the released database is kept to some maximum value. Therefore, the key question of this algorithm is how to put D into D' with the use of heuristic thought.

A subsequent work described in [7] extends the sanitization of sensitive large item sets to the sanitization of sensitive rules. The work in [8] aims at balancing between privacy and disclosure of information by trying to minimize the impact on sanitized transactions or else to minimize the accidentally hidden and ghost rules. The utility in this work is measured as the number of non- sensitive rules that were hidden based on the side-effects of the data modification process. Wang et al. propose a matrix based sanitization approach to hide the sensitive patterns in [9]. It is the first paper to involve the    consideration of avoiding the Forward-Inference Attacks [10], which can also be avoided in the sanitized database generated by our sanitization process. Oliveira et al. propose a novel method to modify databases for hiding sensitive patterns in [11]. Multiplying the original database by a sanitization matrix yields a sanitized database with private content. The method can avoid the question of the Forward-Inference Attacks.

This paper in [12] describes a technique that uses a queue and a random number generator to generate the items so that each item has an approximately equal frequency of being added to transactions. And the work avoids the question that it is hard for [13, 14] to utilize existing tools for association rule mining.

2) Data Blocking-Based Association Rule   The approach of blocking is implemented by reducing the degree of support and confidence of the sensitive association rules. That is by replacing certain attributes of some data items with a question mark or a true value. In this regard, the minimum support and minimum confidence will be altered into a minimum support interval and a minimum confidence interval correspondingly. As long as the support and/or the confidence of a sensitive rule lies below the middle in these two ranges of values, then we expect that the confidentiality of data is not violated. Yucel Saygin et al. first apply blocking to the association rule confusion, which has been presented in [15, 16].

a) Replacement-Based Techniques After original data is replaced the value of some data with the unknown value, the support and confidence of sensitive association rules will not be able to determine, which may be a range of arbitrary values. The paper in [17] discusses specific examples with the use of an uncertain symbol used in association rule mining, in which case the support and confidence interval are used to support and confidence interval to replace.

b) Anonymity Techniques Agrawal et al. improve on the distribution reconstruction technique presented in [18] by using the Expectation Maximization (EM) method. The authors claim that EM is more effective than the currently available technique in terms of the level of information loss. Finally, they propose novel metrics for the quantication and measurement of privacy preserving data mining algorithms.

The paper in [19] presents a new generalization framework on the concept of personalized anonymity in order to perform the minimum generalization for satisfying everybody?s requirements, the core of personalized anonymity is the concept of personalized anonymity. It provides privacy protection of different size for the records of data table. The paper in [20] proposes a personalized anonymity model on the base of (?, k) anonymization model in order to resolve the problem of privacy self management and proposes corresponding anonymity method by using local recoding and sensitive attribute generalization. Although these personalized generalization approaches are flexible, the definitions of sensitive attributes are the same with other approaches. Thus,  dynamic specifying sensitive information needs be future researched.

We should choose the algorithm according to the different situation that can reduce the influence for the original database as far as possible. D_CONF1 algorithm will increase one transaction item when it circulates one time.

Usually there are much data and many association rules while it processing the problem of privacy preserving.

Frequent using of D_CONF1 algorithm will increase the quantity of data and generate some association rules that do not exist. It has influenced the accuracy of database. If there are some important items that cannot be modified or deleted, D_CONF1 algorithm is suitable for this situation.

The front parts of D_CONF2 and D_SUPP are same.

D_CONF2 algorithm can only select sacrifice item in back-end item set and D_SUPP algorithm can select sacrifice item in whole generated item set. So if the influences for the original database of selecting sacrifice item in front-end is smallest we can choose D_CONF2 algorithm. If the influence for the original database of selecting sacrifice item in back-end is smaller, we can choose algorithm through comparing the efficiency, the quantity and importance of selected sacrifice item and support of D_CONF2 and D_SUPP algorithm.



IV. EVOLUTION  Data mining with preserving data privacy only concerns mining from distributed data. In case of association rule mining, data can be partitioned and distributed horizontally and vertically. For horizontally partitioned data, HPSU algorithm was introduced. It uses secure sum of sets, secure sum. For vertically partitioned data, VPSI algorithm can be used, which utilizes secure sum of sets and secure size of set intersection.

In 2008, Christopher Moretti et al. [21] proposed an abstraction for scalable data mining that allows us to explore these tradeoffs. Data and computation are distributed to a computing cloud with minimal effort from the user, and multiple models for data management are available depending on the workload and system configuration. They demonstrate the performance and scalability characteristics of our ensembles using a wide variety of datasets and algorithms on a Condor-based pool with Chirp to handle the storage.

In 2010, Yi feng ET al. [22] observes the virtual organization of knowledge discovery in Semantic Era, and introduce five roles in this environment. Moreover, they emphasize four distinguishing characteristics of knowledge discovery in Semantic era: 1) the dynamic semantic extension and self description of algorithm; 2) the semantic integration of heterogeneous data; 3) the enablement of high-level semantic reasoning and knowledge discovery; 4) the circular refinement of knowledge and semantics. Considering the approaching era of Semantic Web and Cloud Computing, the walking towards knowledge discovery in Semantic era could be expected.

In 2010, Kawuu W. Lin et al. [23] proposed about a set of strategies for many-task frequent pattern mining. Through empirical evaluations on various simulation conditions, the proposed strategies deliver excellent performance in terms of execution time.

In 2010, Hong-qing Gao et al. [24] analyze that now a day?s users choose to use Cloud computing is the development of Distributed mobile phones for Mobile Learning, but the existing issues of bad computing ability, small storage space in mobile phones hinder the future promotion of Mobile Learning. To solve these problems, the concept of cloud computing is introduced, the model of mobile learning based on hadoop is proposed and its functional modules is analyzed.

In 2010, Jianzong Wang et al. [25] proposed that Cloud computing is elastic computing model that the users can lease the resources from the rentable infrastructure. Cloud computing is gaining popularity due to its lower cost, high reliability and huge availability. To utilize the powerful and huge capability of cloud computing, they states that cloud computing import it into data mining and machine learning field.



V. PROPOSED WORK  In this section, we describe the proposed method. We propose a novel algorithm named Cloud Subset Preserving Mining (CSPM). The entire system architecture consists of three phases: 1) Check for Authentication. 2) Reading the database.

3) Perform Pruning. Our algorithm is a good way to apply data mining techniques with security that hides our logical instances from others.

In First phase of algorithm we check the authentication that the user is authorized or not. In second phase we start reading the database, and in the final phase apply the pruning strategy.

Our algorithm shows good performance in different operating environment.

Algorithm:  CSPM (Sensitive Information Preserving Mining)  Input:  ? Set of rules to hide the data values ? The source database ? A Key for visualizing the authentication  Output: ? The database (DB) transformed so that the set of  rules are properly applied and produce the result with security.

CSPM(R, DB, Key) Step 1: [Check for Authentication]  1 a. Enter a number 1 b. Enter the password 1 c. if(number==ndb && password==pdb) { Welcome in the database CSPM(DB)  } 1 d. else { Not an authorized user }  Step 2: CSPM (DB) 2 a. While (object. read ()! =-1) { [Start Reading] } 2.b [compute the occurences] For i=1 to n iterations do { Itemset[i]=count; Count++; } 2 c. [Enter the minimum support] Check for authentication again Enter the min-sup key If(min-sup==msdb) { Prune(db,key) } Else   { [enter the value again] } Step 3: Prune(db,key) 3a enter the min-sup For i=1 to n do If(count[i]>min-sup) List=itemset[i];  Else Remove from the list  Step 4 Add the final result   The goal of data mining is to discover the hidden useful information from large databases. Mining frequent patterns from transaction databases is an important problem in data mining field. As the size of database increases, the computation time and the required memory increase severely. Parallel and distributed computing techniques have attracted extensive attentions on the ability to manage and compute the significant amount of data in the past decades.

The difficulty of mining large database launched the research of designing parallel and distributed algorithms to solve the problem. In cloud computing environments, application is provided as service like Google search engine, meaning that it will be used by many users at the same time. So if the above algorithm is applied on cloud computing environment then space is not a worry constraint and we also apply security concern. Software as a Service (SAAS) is a type of cloud services. All the    application services such as office, video demand, their learning software, Frequent Subset will be stored in the cloud, and the user can select as they need

VI. CONCLUSIONS  In order to focusing on privacy preserving association rule mining, the simplistic solution to address the problem of privacy is presented. The solution is to survey different aspects which are discussed in the several research papers and after analyzing those research papers conclude a new solution which is best in efficiency and performance. In this paper we propose a novel algorithm named Cloud Subset Preserving Mining (CSPM). The entire system architecture consists of three phases: 1) Check for Authentication. 2) Reading the database.  3) Perform Pruning. Our algorithm is a good way to apply data mining techniques with security that hides our logical instances from others. The all the operations are performed in cloud computing environment.

