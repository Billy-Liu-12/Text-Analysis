OWL Reasoning over Big Biomedical Data

Abstract?Recently, the emerging accumulation of biomedi- cal data on the Web (e.g. vast amounts of protein sequences, genes, gene products, drugs, diseases and chemical compound- s, etc.) has shaped a big network of isolated professional knowledge. Embedded with domain knowledge from different disciplines all regarding to human biological systems, the decentralized data repositories are implicitly connected by human expert knowledge. Lots of biomedical data sources are published separately in the form of semantic ontologies represented by Web Ontology Language (OWL) syntax, which is naturally based on linked graphs. When we are faced with such massive, disparate and interlinked data, biomedical data analysis becomes a challenge. In this paper, we present a general OWL reasoning framework for the analysis of big biomedical data and implement a MapReduce-based property chain reasoning prototype system. OWL reasoning method is ideally suitable for problems involved complex semantic associations because it is able to infer logical consequences based on a set of asserted rules or axioms. MapReduce framework is used to solve the problem of scalability. In our experiment, we focus on the discovery of associations between Traditional Chinese Medicine (TCM) and Western Medicine (WM). The results show the system achieves high performance, accuracy and scalability.

Keywords-OWL Reasoning, Big Biomedical Data, MapRe- duce, Property Chain

I. INTRODUCTION  With the rapid development of biological data acquisition technologies, such as Next Generation Sequencing System (NGS) [16], large volume datasets are generated rapidly in the field of biomedicine. Up to now, Linked Life Data (LLD) ?a data integration platform in the biomedical do- main1, has 10,192,505,364 statements. UniProt Knowledge- base (UniProtKB/Swiss-Prot) contains 34,535,400 sequence entries, comprising about 10 billion amino acids2. On the other hand, biomedical data has a wide coverage including proteins, pathways, diseases, targets, genes and Chinese Medical herbs, which usually come from multiple sources and have different formats and taxonomies.

Biomedical data is also interlinked with complex semantic associations. Every biomedical entity (e.g. a gene, a disease, a drug, a herb, etc.) links to many other biomedical entities with different attributes. A protein, for example, has a num- ber of attributes that must be included in its representation as shown in Figure 1. These include inherent properties of  1http://linkedlifedata.com/sources.html 2ftp://ftp.uniprot.org/pub/databases/uniprot/relnotes.txt  Figure 1. Linked Knowledge Graph Related to Protein  a protein, such as ?full name?, ?short name?, ?sequence?, as well as ?synonyms?, ?accession numbers? and ?biological process?, which can link to other proteins and gene products in various resources.

Traditional biomedical data analysis tools and methods have difficulty in processing such large-scale, heterogeneous and linked biomedical data. An urgent need to present a new solution for big biomedical data analysis is imperative.

Semantic web technologies [4], most especially the OWL, are widely used in the life science and healthcare, pro- vide us with an efficient way to integrate heterogeneous data and define specific semantic relationships among data [8]. In OWL, resources are identified with triple patterns < s, p, o >, representing a property p between subject s and object o [6]. RDF provides a simple graph data model for encoding networked data on the Web using nodes and binary relations. The connections (e.g. treatment, possibleDrug and hasTarget) between biomedical entities are expressed as cer- tain semantic rules. For example, triple (DrugA, treatment, DiseaseB) represents a statement or a fact that a drug DrugA has the ability to treat some disease DiseaseB. Semantic rule ?treatment? from the example can represent a association between drug database and disease database. Semantic Web technology provides us with a good way to model the complicated and large-scale realms of biomedical knowledge network by defining an unified biomedical ontology.

Since we have created a well-designed biomedical on-      tology, we have the ability to define some specific entities and declare common semantic association rules between existing entities. As a result, we construct a big biomedical knowledge graph by interconnecting many heterogeneous biomedical data sources based on semantic rules. OWL reasoning technology is quite applicable to data analysis problems especially knowledge discovery problems involv- ing complex semantic associations because it is able to infer logical consequences based on a set of asserted rules or axioms [3]. In rule-based reasoners, the OWL ontology definitions are first compiled into a set of rules. This rule-set is then applied on the presented data-set to generate the new inferred triples.

However, OWL reasoning over big ontologies is very complex and cannot be performed efficiently or is even impossible [20], leaving it hard to make further data analysis on the big biomedical knowledge graph. OWL reasoning on single machine including popular reasoners such as Pellet [18] and Racer [11] works only on small or simple ontologies because the reasoning algorithms are not scalable and are usually main memory oriented. As to the large biomedical data analysis, we have to devise an efficient and scalable reasoning algorithm. MapReduce is a popular parallel programming model for large scale data processing on commodity computer cluster [9]. Applying distributed computing method to big biomedical OWL reasoning be- comes an ideal choice.

In this paper, we utilize the OWL reasoning technology with MapReduce to deal with the problem of massive biomedical data analysis. More specifically, our contribu- tions are as follows:  (i) We summarize several basic requirements to support challenging big biomedical data analysis efforts, and present a general OWL reasoning framework for the analysis of big biomedical data.

(ii) We propose two MapReduce-based property chain reasoning algorithms and implement a reasoning pro- totype system based on this framework and algorithms.

(iii) We present an implementation based on our prototype system and real biomedical datasets. The results show the system achieves high performance, accuracy and scalability.

The remaining of this paper is organized as follows. Sect.

2 describes the related work, including OWL reasoning over biomedical data and applications in the field of bioinformat- ics based on MapReduce. In Sect. 3, we give the overall OWL reasoning framework and detailed implementation of the distributed reasoning system. Sect. 4 introduces the experiment and the result analysis. Sect. 5 gives conclusion.



II. RELATED WORK A. Reasoning over Biomedical Data  Based on biomedical formal ontologies, we are able to make use of reasoning method from description logic to im-  plement many biomedical applications, such as the discovery of new associations, consistency checking, classification, practical querying and so on. Here are some examples which use OWL reasoning over biomedical data.

Matthew et al. [12] uses semantic web rules to reason on an ontology of pseudogenes to discover information about human pseudogene evolution. ZHANG makes use of existing reasoners Racer [11] to support reasoning [10] with the foundational model of anatomy in OWL DL. Ward Blonde et al. [5] applies relational closure rules to reason with bio-ontologies to enable practical querying.

So far, however, most of these applications only apply to relatively small data. when it comes to big integrated biomedical data analysis, OWL reasoning faces the problems of low efficiency and out of memory [22].

B. Applications in the Field of Bioinformatics Based on MapReduce  Presently, some work of applying cloud computing to biomedical data analysis and mining has been done to accelerate the speed of processing computational biology problems. There are several representative biomedical ap- plications based on MapReduce as follows.

CloudBurst [17] is a new MapReduce-based parallel read- mapping algorithm optimized for mapping next-generation sequence data to genomes. Crossbow [14] uses Hadoop to whole genome resequencing analysis and SNP geno- typing from short reads. Andrea Matsunaga has created CloudBLAST [15] algorithm using MapReduce to efficiently search for similar regions between sequences.

From the above descriptions, we can find present applica- tions based on MapReduce mainly focus on big data process- ing problems from a specific biomedical domain. However, in most cases of biomedical data analysis, there are many problems across multiple biomedical domains. At this time, digging out meaningful knowledge from the big biomedical data can not be easily achieved using MapReduce due to the complex relationships among biomedical data.



III. OWL REASONING FRAMEWORK OVER BIOMEDICAL DATA CLOUD  The overall OWL reasoning framework over biomedical data cloud is shown in Figure 2. The framework consists of two subsystems: distributed reasoning system and biomedi- cal data cloud system. In this paper, we mainly focus on the implementation of distributed reasoning system. The work of semantic modeling and integration over biomedical data cloud has been finished in our BioTCMCloud platform3.

The rest of this section gives the detail information of the OWL reasoning framework. In the first subsection, we introduce the BioTCMCloud briefly. The second subsection shows the detailed realization of the distributed reasoning  3http://www.biotcm.org     Figure 2. OWL Reasoning Framework over Biomedical Data Cloud  system: Firstly, we describe a typical biomedical reasoning problem and redefine it formally. Then we present a general reasoning algorithm framework and subsequently introduce a naive OWL reasoning algorithm based on MapReduce.

We call this implementation ?naive? because it is easy to understand but performs poorly. Therefore, in the last part, an improved algorithm is presented to deal with the conflict between the parallel mechanism of MapReduce and the sequential demands of a reasoning rule set.

A. BioTCMCloud  BioTCMCloud is a semantic data integration platform for the biomedical domain. It integrates most of the typi- cal biomedical ontologies across WM and TCM including Gene Ontology, Disease Ontology, Diseasome Ontology, DrugBank, TCMGeneDit, Uniprot, NCBI Gene and so on.

BioTCMCloud is also a data-as-a-service platform which allows complex data analytical queries across linked ontolo- gies, mapping search, TCM inference search and so on. The knowledge base provides us with an ideal linked knowledge graph model which represents the big biomedical data cloud.

B. Biomedical Reasoning Example  As described previously, one key characteristic of biomed- ical data is that there exist complex association relationships between them. These association information is useful in understanding the mechanisms of action of biomedical enti- ties, especially those entities biomedical researchers are still not familiar with. For example, TCM, which has existed for thousands of years in China, yet to become an integral part of the standard healthcare system in Western countries due to a lack of scientific evidence for its efficacy and safety [2]. Can we utilize the OWL reasoning system to derive some implicit and meaningful relationships between TCM and WM to explain the scientific evidence of TCM? Problem 1 describes a typical biomedical reasoning example.

PROBLEM 1. In recent years, several Chinese herbs were found to exhibit a variety of effects through regulating a wide range of gene expressions or protein activities [7] [13].

Biomedical researchers are eager to discover associations  Figure 3. OWL Transitive Property Rule Between Herb and Gene  between gene and herb to help understand the possible therapeutic mechanisms of TCMs via gene regulations.

We are able to get association information between herb and gene based on the OWL transitive property closure rule as Figure 3. In our reasoning system, relationships between two kinds of biomedical entities are expressed as reasoning rules. Typically, as is shown in Figure 3, some basic reasoning rules have been given directly by the biomedical knowledge graph. But there does not exist a direct association rule between herb and gene. On this occasion, the transitive relationship can be derived step by step along with the property chain and shared intermediates.

C. Formal Definition of Biomedical Reasoning Problem  To address the problem efficiently, we define following several concepts:  Definition 1: Reasoning Rule Chain (RRC). A Rea- soning Rule Chain is a set of sequential basic reasoning rules. Every basic reasoning rule is given in advance which is formalized as a rule triple. The Reasoning Rule Chain of Problem 1 can be described as RRC0={(herb, treatment, Disease), (Disease, possibleDrug, Drug), (Drug, hasTarget, Target), (Target, hasAccession, Protein), (Protein, classified- With, EntrezID), (EntrezID, symbol, Gene)}.

Definition 2: OWL Property Chain (OPC). A OPC is made up of one or more sequential properties from the Reasoning Rule Chain. Given a Reasoning Rule Chain such as RRC0, Pk refers to the property of the kth rule triple.

Initially, OPCk equals to Pk. Therefore, OPC of Problem 1 can be computed as followings: OPC0= treatment, OPC1= possibleDrug, ... ,OPC5= symbol. Then several consecutive sequential OPCs will form a new OPC with operation?  if they meet merging condition. For example, if there exist some triples: (Herb0, treatment, Disease0), (Disease0, possibleDrug, Drug0), then we can derive a new triple (Herb0, P, Drug0) where P is expressed as (OPC0  ? OPC1).

To some extent, the reasoning process can be regarded as the iterated merging operations of OPCs.

Definition 3: Property Chain Set (PCS). As the name suggests, the PCS is a set of sequential OPCs in a given Rea- soning Rule Chain. For RRC0, the Initial PCS is expressed as PCS0={treatment, possibleDrug, hasTarget, hasAccession, classifiedWith, symbol}. In the process of reasoning, the PCS will vary with OPCs.

Definition 4: Property ID (PID). We allocate an ID called PID to every OPC in the PCS. PID of the first OPC in the PCS0 is set as 0, the second is 1, ... , PID of the last OPC is 5 (the length of PCS0 is 6). Correspondingly, every instance     Figure 4. Sequential Reasoning Process Based on Property Chain  triple also owns a PID because its predicate maps some OPC.

For those triples whose OPCs are not included in the PCS, the PID is assigned as -1. These triples should be ignored in the process of reasoning.

Based on above definitions, Problem 1 can be redefined formally as Problem 2:  PROBLEM 2. Input a quad (G, PCS0, Herb, Gene), the goal of our reasoning system is to compute the solution domain S={(O0,OPC,O5)|O0?Herb,OPC=(treatment  ? possibleDrug?  hasTarget...

?  symbol), O5?Gene}.G is the instance triple graph. (Xk, Pk, Yk) represents a typical triple in G. Xk represents a entity belonging to biomedical class X. Pk is the property of the kth rule triple. Yk is an entity of class Y. The PCS0 is the Property Chain Set of G. Herb and Gene represent the two classes needed to explore implicit relationship.

Consider the following instance triple graph: G0= {T0(Herb0,treatment,Disease0),T1(Disease0,possibleDrug,D- rug0), T2(Drug0, hasTarget,Target0),T3(Target0,hasAccession, Protein0),T4(Protein0,classifiedWith,EntrezID0),T5(EntrezID0 ,symbol,Gene0),T6(Herb1,treatment,Disease0),T7(Target0,ge- neSequence,Sequence0)}.According to above definitions, we can calculate the PID for every instance triple. For example, T0?s PID is 0 because its predicate ?treatment? is the first OPC in PCS0. T7?s PID is -1 because its predicate ?geneSequence? is not included in PCS0.

D. Framework of OWL Reasoning Algorithm  Given a input quad (G0, PCS0, Herb, Gene), to compute solution domain, we need to keep applying the rules to reason until we deriving the desired triples (fixpoint). This process will involve multiple iterations. The number of iter- ations depends on the complexity of the input and efficiency of the algorithm.

In the workflow of the algorithm as shown in Algorithm 1, we firstly complete initialization by inputting a quad (G0, PCS0, Herb, Gene) and setting a global variable to check fixpoint condition. Then the algorithm comes into the procedure of iterating. In every iteration, we load the triple graph and PCS. Then we perform a join with a MapReduce job. At last, new input triple graph and PCS are calculated for next iteration.

Algorithm 1 Framework of OWL Reasoning Algorithm.

Initialization: instance triple graph, G0; Property Chain  Set, PCS0; two classes required to explore implicit semantic associations, Herb and Gene; number that has been iterated, I = 0; number needed to be iterated, M ;  Iteration: while I < M do  Step 1) Load triple graph and PCS on the current iteration, GI , PCSI ;  Step 2) Group instance triples based on join key; Step 3) Derive new instance triples; Step 4) Update input instance triple graph, GI+1; Step 5) Update PCS, PCSI+1; Step 6) I ? I + 1;  end while  E. Naive OWL Reasoning Algorithm  It is quite natural and straightforward to connect Herb with other biomedical entities from the RRC0 by sequential joining: In the first iteration, we connect Herb with Drug through intermediate Disease. In the second iteration, Herb connects with Target by intermediate Drug. In the last iteration, we finish reasoning by connecting Herb with Gene.

The entire reasoning process is shown as Figure 4. After every iteration, the first two OPCs (P0 and P1) in the PCS will merge to a new OPC (P0  ? P1) whose PID is set to  0. Meanwhile, the PID of all other OPCs reduce by 1.

Length of the PCS will also reduce by 1. When length of the PCS becomes 1, the algorithm ends. So the total number of iterations is 5 (n-1) for Problem 2.

In every iteration we have been processing the instance triples whose PID is 0 or 1. Based on the principle, we can specify the join condition: the objects of triples whose PID equals 0 must match the subjects of other triples whose PID is 1. For the sake of description, we define the concept of Join Candidate Set.

Definition 5: Join Candidate Set. Join Candidate Set is a binary set of the instance triples that meet join condi- tion. Once there exists two instance triples satisfied with above join condition such as T0(Herb0, P0, Disease0) and T1(Disease0, P1, Drug0), we should add the element (T0, T1) to the Join Candidate Set. Therefore, we only need to perform joins over elements from the Join Candidate Set in every iteration.

Let us consider the same input quad QUAD0=(G0, PCS0, Herb, Gene) as above. In the first iteration, we derive two triples by computing the Join Candidate Set {(T0, T1), (T6, T1)}: T8(Herb0, P0  ? P1, Drug0) and T9(Herb1, P0  ? P1,  Drug0). Then {T0, T1, T6} will be deleted from the input data. T7 is also removed because its OPC (geneSequence) is not included in the PCS0. So the new input quad becomes QUAD1(G1, PCS1, Herb, Gene). G1={T8, T9, T2, T3, T4,     Figure 5. Workflow of the First Iteration Based on Sequential Property Chain Reasoning Algorithm  T5}. PCS1={P0 ?  P1, P2, P3, P4}. Then we continue to apply same method to perform joins until we get the final results: (Herb0, P0  ? P1  ? P2  ? P3  ? P4, Gene0) and (Herb1,  P0 ?  P1 ?  P2 ?  P3 ?  P4, Gene0). As the length of PCS0 is 6, the total number of iterations is 5. The first iteration process is shown in Figure 5.

When deployed in MapReduce, every MapReduce job corresponds to an iteration procedure which performs a join.

Mappers are used to separate all input triples into three groups based on PID: triples needed to be joined imme- diately, triples needed to be processed later and irrelevant triples. Reducers are responsible for implementing joins to recalculate new input triple graph for next iteration. At last, PCS is updated. Another similar MapReduce job continues to be executed until the length of PCS becomes 1.

F. Efficient OWL Reasoning Algorithm  The previously presented implementation is straightfor- ward, but is inefficient because it involves too many it- erations and wastes lots of valuable computing resources in an iteration. Previous naive algorithm only implements joins on these instance triples whose PID is 0 or 1 in every iteration, while other instance triples are not processed concurrently. In fact, we can perform more joins in an iteration if we set more flexible join conditions. Specifically, the join conditions contain two parts: (1) the PIDs of two triples are adjacent strictly.

(2) the object of triple owning a smaller PID matches the  other triple?s subject.

For example, there are three instance triples as followings:  T0(Herb0, treatment, Disease0), T1(Disease0, possibleDrug, Drug0),T2(Drug0, hasTarget, Target0). As T1 meets join con- ditions both with T0 and T2, the Join Candidate Set should be {(T0, T1), (T1, T2)}. So we derive two triples: T3(Herb0, P0  ? P1, Drug0) and T4(Disease0, P1  ? P2, Target0). As T3  Figure 6. Parallel Reasoning Process Based on Property Chain  and T4 do not meet join conditions in next iteration, we can not derive the right result (Herb0, P0  ? P1  ? P2, Target0).

We are able to solve the problem if we add another restricted condition called Parity Judgment Rule to join conditions.

Rule 1:Parity Checking Rule. We regard the Parity Checking Rule as the third join condition. It is based on this principle: For a triple Tk (k represents its PID), if k is odd, Tk only performs joins with triples whose PID is (k- 1); Otherwise, Tk performs joins with triples whose PID is (k+1). As to above three triples, the join condition guarantees that T1 only connects with T0 in the first iteration. Then we can derive the right result in the second iteration.

As is shown in Figure 6, based on the above three join conditions, we can divide all biomedical entities except irrelevant contents (Sequence) into 3 (?N/2?) groups where N represents the length of PCS0. Then we perform joins between the triples from the same group in an iteration. As a result, the derived triples will be the new input graph for next iteration. Meanwhile, we halve the PCS by merging the two adjacent OPCs to one new OPC with the operation  ? .

Subsequently, we continue to apply similar method to reason until the length of PCS becomes 1. Obviously, this algorithm makes full use of the computing capacity of cluster nodes to limit the number of total iterations to 3 (logN ) which will greatly improve the efficiency of reasoning, compared to 5 (N-1) iterations in the previous naive algorithm.

Consider the same input quad Quad0=(G0, PCS0, Herb, Gene). In the first iteration, the Join Candidate Set is calculated as {(T0, T1), (T1, T6), (T2, T3), (T4, T5)} based on join conditions. Then new triples are derived as followings: {T8(Herb0, P0  ? P1, Drug0),  T9(Herb1, P0 ?  P1, Drug0), T10(Drug0, P2 ?  P3, Protein0), T11(Protein0, P4  ? P5, Gene0)}. So we get a new graph  G1={T8, T9, T10, T11}. The PCS is also updated as PCS1= {P0  ? P1, P2  ? P3, P4  ? P5}. The first iteration  ends up with a new smaller input quad Quad1=(G1, PCS1, Herb, Gene). Similarly, in the second iteration, we work out the new Join Candidate Set which is expressed as {(T8, T10), (T9, T10)} and another new graph is calculated as G2={T11(Protein0, P4  ? P5, Gene0),  T12(Herb0, P0 ?  P1 ?  P2 ?  P3 ?  P4, Protein0), T13(Herb1, P0  ? P1  ? P2  ? P3  ? P4, Protein0)}. The new PCS is al-  so updated as {P0 ?  P1 ?  P2 ?  P3, P4 ?  P5}. Then we implement the last iteration. The Join Candidate Set is {(T12, T11), (T13, T11)}. The desired triples are de-     Figure 7. Workflow of the First Iteration Based on Parallel Property Chain Reasoning Algorithm  Figure 8. the Linked Biomedical Knowledge Graph  rived {T14(Herb0, P0 ?  P1 ?  P2 ?  P3 ?  P4 ?  P5, Gene0), T15(Herb1, P0  ? P1  ? P2  ? P3  ? P4  ? P5, Gene0)}. As the  length of PCS0 is 5. So the algorithm ends after 3 iterations.

The first iteration scenario is shown in Figure 7.

When implemented in MapReduce, Mappers split all triples into ?N/2? ( N represents the length of current PCS) Reducers based on above three join conditions. Reducers are responsible for computing the Join Candidate Set and deriving new input triples for next iteration. At last, the PCS is updated by merging the two adjacent OPCs to one new OPC. Then another similar MapReduce job is launched until the length of PCS becomes 1. The algorithm is demonstrated in Algorithm 2.

Speedup = computing time on 1 computer  computing time on cluster (1)  Algorithm 2 Efficient OWL Reasoning Algorithm Based on MapReduce Map(key, value)  PID = PCS.getPID(triple.predicate); if PID == ?1 then  return; end if if PID%2 == 1 then  key=(PID-1)+? ?+triple.getSubject(); else  key=PID+? ?+triple.getObject(); end if emit(key, value);  Reduce(key, value) subjectList = empty; objectList = empty; len=PCS.length; for each triple ? value do  PID = PCS.getPID(triple.predicate); if PID == (len? 1)&len%2 == 1 then  emit(null, triple); return;  end if if PID%2 == 1 then  subjectList.add(triple.subject); else  objectList.add(triple.object); end if  end for new OPC=ComputeOPC(); for each s ? subjectList do  for each o ? objectList do emit(null, triple(s,new OPC, o));  end for end for  Sizeup = computing time for processing m? data  computing time for processing data (2)  Precision = TP  TP + FP (3)

IV. EXPERIMENT EVALUATION  We implemented the reasoning prototype system based on the Hadoop framework. Our experiment aims at discovering the implicit associations between Chinese Medical herbs and genes systematically based on the prototype system to achieve some meaningful results for biomedical researchers.

The reasoning rules are shown as Figure 3.

The experiment was conducted both in single node and several Hadoop clusters with the scale of 2 nodes, 4 n- odes, 6 nodes and 8 nodes. Each node is visualized by VisualBox with the same configuration, including Linux     OS, 1G RAM, 10G disk capacity, one core of Intel(R) Xeon(R) CPU E5620 with 2.4GHz. The nodes are connected by the network with the bandwith of 1000M/s. One node in cluster acts as master and the left ones act as slaves.

In experiment, as Reducer is responsible for the major computation, Reducer is dynamically set by the length of PCS in a MapReduce job. Each test is executed 5 times and the average computing time is recorded. Performance evaluation is conducted by comparing the running time of single node and the distributed reasoning system. According to formula (1) and formula (2), speedup and sizeup are calculated for scalability evaluation. Accuracy evaluation is based on Random Sampling Inspection.

A. Data Preparation  We use these data sources provided by the big linked biomedical knowledge graph as is shown in Figure 8. The knowledge graph is constructed based on the Linking Open Data4 for the biomedical domain. In addition, we also manually add some ontologies into the knowledge graph.

The dashed ovals in Figure 8 indicate the input data sets required by Problem 1. Every oval is marked up by a number which represents the number of statements in the dataset.

B. Experimental Results and Discussion  Table I EVALUATION OF THE ASSOCIATIONS BETWEEN TCMS AND GENES  Gene Symbol Sample Size TP Precision TNF 30 28 93.3% PEP4 30 22 73.3% HK1 30 24 80% IL6 30 26 86.7%  NQO1 30 26 86.7% Sum up 150 126 84%  Table II SCALABILITY OVER NUMBER OF NODES  Number of nodes Time (minutes) Speedup 1 node out of memory 2 nodes 34.65 1 4 nodes 16.28 2.08 6 nodes 11.63 3.17 8 nodes 8.81 3.93  Table III SCALABILITY OVER INPUT DATA  Input Data (times) Time (minutes) Sizeup 1 time 8.81 1 2 times 16.70 1.90 3 times 22.36 2.54 4 times 30.51 3.46 5 times 46.39 5.26  4http://www.ontotext.com/LinkedDataManagement  Performance: Table II shows that reasoning on a single node leads to out-of-memory problem. When implemented in the distributed reasoning system, we are able to complete reasoning within a short time. Especially when the scale of Hadoop cluster becomes bigger, the performance is im- proved significantly.

Accuracy: There is not a standard mapping relationship between genes and herbs available, making it impossible to evaluate all association information discovered by the rea- soning system. We focused on several major reported genes related to herbs in recent years. Then we randomly selected 30 herbs (samples) for every gene from the reasoning results, and used precision measurement to estimate the accuracy.

The mined results manually confirmed as correctness were considered true positives. Precision is defined according to formula (3), where TP and FP are the numbers of true positives and false positives, respectively. Table I shows that our results achieve high precision.

The reasoning results could be used to explain the poten- tial therapeutic mechanisms of herbs via gene regulations.

Take gene Tumour necrosis factor (TNF) for example. TNF is an important proinflammatory cytokine, plays a role in the regulation of cell differentiation, proliferation and death which is closely correlated with tumour disease5.

The results reveal that TNF gene is associated with 32 herbs including Ganoderma lucidum, Salvia miltiorrhiza, Hypericum perforatum and so on [21] [19] [1]. On the other hand, according to analysis of the chemical components in the Chinese herbs, most of the derived herbs (94%) contain anti-cancer compounds. The compounds can cause cancer cells to round up and die, inhibit tumor-induced blood sup- ply development and prevent tumor growth. These derived associations suggest the possible therapeutic mechanisms involved by herbs, genes and herb ingredients. It provides some useful information for TCM and modern biomedical researchers.

Scalability: Table II shows how our approach scales with an increasing number of computing nodes. We use the running time on the 2-node configuration as baseline because a single node can not process all the data due to out of memory. Table III shows how our approach scales with increasing input size by doubling the original data (reasoning rules not changed), using a fixed configuration of 8 nodes. Speedup and sizeup are shown in Table 2 and Table 3, respectively.

From Table II we can see that the speedup is nearly linear to the number of nodes. The processing time is significantly reduced by adding more computing nodes. Table III shows that except for 5 times input on 8 nodes cluster, sizeup of m times input is less than or equal m. The sizeup of 5 times input is greater than 5 because of the bottleneck of cluster disk capacity. The results mean that execution time increases  5http://www.ncbi.nlm.nih.gov/pubmed/21790707     more slowly than input data size and our system works better in processing larger input set. To sum up, considering the effects of the platform overhead, we conclude that the results show linear scalability regarding the size of the input and number of nodes. Our reasoning system shows excellent scalability.



V. CONCLUSION  In this paper, we present a general biomedical data reason- ing framework and implement a MapReduce-based property chain reasoning prototype system to deal with data analysis problems in the massive, disparate and interlinked biomedi- cal data cloud. We firstly summarize the requirements for a feasible biomedical data analysis framework. Then we present an ideal biomedical data reasoning framework and implement a reasoning prototype system which makes full use of the advantages of MapReduce parallel programming model and OWL property chain reasoning method. Finally, we evaluate the reasoning prototype system on real-world data. The results demonstrate that our prototype system achieves high performance, accuracy and scalability.

ACKNOWLEDGEMENTS  This work is supported by National High Technology Re- search863 Major Program of China (No. 2011AA01A207).

