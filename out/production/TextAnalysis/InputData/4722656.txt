The Research about the Application of Data Mining  Technology Based on SLIG in the CRM

Abstract?First ,this paper introduces Relation Regulation in data mining ,then an efficient algorithm SLIG ( Single-Level Large Itemsets Generation) based on relation theory and "AND" operation on recognizable vectors was proposed. SLIG transforms the production process of  frequent itemset  to  the vector calculation process with relationship matrix but only needs to scan the database once . We optimize the algorithm farther ,and acquire favorable results. According to this algorithm , combining CRM-instance in the insurance company , we present a detailed  process for the solution and analysis of instance, by that we elicit an important conclusion that can bring competition and profit for the company ,and also it is a credible gist for reducing risk, at last we analyze the performance among the algorithm of SLIG,#SLIG(optimized SLIG) and Apriori.

Key words: Customer Relation Management?SLIG algorithm; recognizable vectors; association rule;

I.  INTRODUCTION The amount of customer masters the destiny and  development of enterprise. Therefore, customer has been the focus of every enterprise. CRM (Customer Relation Management)is a kind of practice that enterprises need to find out the requirement of customer, know their value, develop the effective market stratagem, improve the product and service, enlarge the sale, improve the efficiency and effect and seek the most benefit. Data mining technology based on SLIG provides well help for enterprises to make better managing decision.

CRM is a foreground for managing enterprise especially.

With relation theory and recognizable vectors, the paper raises SLIG that transforms the producing process of frequent itemsets into calculating process of  vector in the relation matrix. The algorithm only needs to scan the database for one time, it can overcome the fault of FP-tree, Apriori and  other algorithm which can produce a lot of candidate itemsets . SLIG scans the database for only one time, and transforms the database to the matrix which only includes number ?0? and ?1?. Thereby the algorithm can save the calculating time. SLIG inducts the recognizable vectors and its ?AND? calculation.

For example, for an itemsets which includes n items, it only need ?AND? calculating for Cn2 times to get the frequent 2- itemsets satisfying min_sup.



II. THE CONCEPT OF CRM CRM[1][2] is a way of communicating between enterprises  and their customers. It acts on the fields such as market selling , service and technology support that related to the customers . It is a managing idea, and also is a kind of new management mechanism which aims to improve the relationship between the enterprises and customers. It combines the best commerce practice, data mining , data warehouse, face to face selling , automatic selling with information technology. This provides the enterprises with a foreground which is based on electronic commerce, it can make the enterprises achieve the conversion from traditional mode to modern mode based on electronic commerce. The characteristics of CRM are as follows: ?face to face selling; ?high integrated communion channel; ?shared information resource; ?intelligent data analyzing and managing; ?the function support based on Web.



III.  DATA MINING TECHNOLOGY OF ASSOCIATIONS RULES  A. Ttypical methods of associations rules Some typical methods of associations rules are as  follows[3]: ? association analysis; ? sequential pattern analysis; ? classification analysis; ? cluster analysis; ? decision tree; ?bionic technology; ?inductive learning; ? statistic analysis. Here the association rules analysis is mainly introduced.

B. Basis concept of associations rules[4] (1) support ,confidence  Support means the given association appearing frequency in the transaction database. support?A?B?=P(A?B)=the number of given affairs/total number of affairs in the database.

(2) min_support , min_confidence  When an transaction database is given, users can seek the right association rules according to min_support and min_confidence.



IV.  SLIG  ALGORITHM  A. Correlative definition[5]  Definition 1:Assuming I = { 1, 2, ., n }, the definition of cognizable distribution vector Di of item i is:   DOI 10.1109/CSSE.2008.1151     T i 1i 2i ji niD = ( d  , d  , ..., d  , ..., d  ) ,  ??  ? ? ?  ?  ? =  j  j ji Taffairiitemif  Taffairiitemif d  ,0  ,1    Definition 2: ? =  = n  j jii dD   )sup( ,Vector  ikiii DDDD ???? ?321 is also a vector. Symbol ? ? ? stands for ?AND?. Assuming  T nsjssss ddddD ),,,,,( 21= ,that ?  =  = n  j jii dD   )sup( ,  that means the number of ?1?among Ds.

B. Algorithm step  (1) Generating of frequent 1-itemsets. When SLIG scan the transaction database for one time, it can set up a position vector Di. The length of position vector is the number of the relation item in the database. If  item i appears at the jth transaction, that the jth of Di is placed 1, or else, it is placed 0.The number of ?1? among Di is equal to the support number of item i. If supmin_)sup( ?iD (defined by user), then { i} is frequent 1-itemsets.Accordingly, the total frequent 1- itemsets can be confirmed.

(2) Generating of frequent 2-itemsets. When the frequent 1-itemsets is confirmed by the first stage, the item L1 is assumed as }}{,},{,},{{ snm .The total number of frequent 1-itemsets, then the relation matrix of itemsets is defined as TTR ? :  11 1 1n T  mn mT T T  TT  r r r  r r R  r  ?  ? ? ? ? ? ? ? ?  = ? ? ? ? ? ? ? ? ? ?? ?    1, sup( ) min_ sup 0, sup( ) min_ sup  0,  m n  mn m n  m n D D r m n D D  m n  ? ? ?? ?= ? ? <? ? =?  ?  ?    mmr  stands for the support when the item m and n appears at the same time. So TTnnmm rrr ,, have no meaning, its value is 0. It is obvious that TTR is a symmetrical matrix. If  1=mmr ,then itemset{m,n}is frequent 2-itemsets.Contrarily, if 0=mmr ,then itemset{m,n}is certainly not frequent 2-  itemsets.

(3) Generating of (k+1)-itemsets(k ? 2). When the frequent 2-itemsets is achieved, the last item of frequent 2-  itemsets is Ik. If Ij is from Ik+1 to T and if ),,(,1 1 TIjr kkj +?= and  supmin_)sup( 321 ?????? jikiii DDDDD ? ,then },,,{ 1 jk iii is frequent (k+1)-itemsets until there is no  longer frequent (k+1)-itemsets Generated.

C. Optimization of algorithm   11 1 1j j  ii ij i j  jj  r r r  r r R  r  ?  ? ? ? ? ? ? ? ?  = ? ? ? ? ? ? ? ? ? ?? ?    Definition 1:Let nI  be the summation of data for the n?th in  relation matrix,  j  n in i  I r =  =? , inr  be the binary value of the i?th row in the n?th line.

Definition 2:For any frequent 2- itemsets { , }s tI I ,extend 3- itemsets { , , }s t kI I I (s<t<k) only operate the item that more than t.

Definition 3: Extend any of frequent k- itemsets 1 2{ , ,..., }kI I I ,chalk up the candidate (k+1)-itemsets  1 2 1{ , ,..., , }k kI I I I + , 1 2 1{ , ,..., , }k kT I I I I += , where T is the number of the elements in the set  1 2 1{ , ,..., , }k kI I I I + .

Detailed Optimization of algorithm as follows: (1) choose the items need to extend from frequent 1-itemsets L1..

(2) for any frequent 2-sets{ , }s tI I ,only extend the itemsets kI  that more than t.

(3) generate the relation matrix i jR ?  with position vectors.

(4)scan all lines of the matrix ,extend the items where  1nI T> ? ,else scan the next line.

(5)if 1nI T> ? ,under this condition ,if inr ?0 then switch  the next row in the n?th line; if inr ?1 then put it into the itemsets.

(6) generate k-itemsets (k=1,2,?)satisfy the condition  continually until no item appears, end algorithm.

Implement for algorithm min_sup=constant, L1=? for all items i in database D do if i.count ? min_sup  then L1=L1?{i} L2=?,L2=,Is?I1 Select one item It of frequent 1-item L1 if t>s  then  L2= {Is,It } Generation k kR ? if (s?t)and sup(Ds,Dt) ? min_sup then Rst=1     if (s?t)and sup(Ds,Dt) ? min_sup then Rst=0 if (s=t)  then Rst=0 In=0 ,T=the number of Lk for (j=1;j++;j<=k)  In= In+rij for all itemsets {i1,i2,?,ik}?Lk for ( M=1;M++;M<=k) if R[iM][i]=1 if (In>T-1) then Lk+1=Lk?{iM} end end k=k+1 end

V. SLIG ALGORITHM EXAMPLE ANALYSIS Along with the process of economy incorporation boosting  and the development of electronic business, the opening speed of insurance market is also accelerating. Overseas insurance companies infiltrate Chinese insurance market gradually by kinds of methods. Most of businessman realize that customers are the base for insurance company existing and developing.

And the key of improving the competition power is to attract customer, keep customer, avoid the customer leaving[6].

Certain insurance company in Yangzhou city has built the individual information database of a great deal of customers by informational management for several years. The example analyzes the basic data of customer, and know the effect caused by the customers? age, educational level, income and so on. Some customers individual information are in the table ?.

TABLE I.  INFORMATION OF CUSTOMERS                       The age and salary data in the chart are consecutive  numerical data. But association rules need discrete data, so the consecutive data should be discreted. The data is grouped according to the expert experience(sup ? 25%): ?Age1: ?30?  Age2:31 ? 45 ? Age3: 46 ? 60 ? Age4: ?61; ?Salary1: ?10000?Salary2: 10001?20000?Salary3: 20001?40000? Salary4: 40001 ? 60000 ? Salary5: ? 60001; ?kind of insurance: enfant education type A, saving guarantee type B, medicare C, casualty by accident D, investment and financing E.

Then by association rules data mining of customers? individual information, the inner association rules of how customers buy insurance can be found, and at the same time, well market strategy can be achieved. A1?A4 stand for I1? I4, S1?S5 stand for I5~I9, A?E stand for I10?I14.The details are as follow table ?.

TABLE II.  TRANSACTIONAL DATA                 min_sup=5, Sup(D2) =8, Sup(D3)=8 , Sup(D7)=7 , Sup(D8)=7 ,Sup(D11)=6 , Sup(D12)=8.

Frequent 1-itemsets L1={{I2},{I3},{I7},{I8},{I11},{I12}}.The corresponding transaction database position vector is as follow table ?.

TABLE III.  POSITION VECTOR  item Position vector D2 00000101111100101000  D3 00110000000011010111 D7 00010000000011010111 D8 00000101011100101000 D11 00000101010100011000 D12 10010000001011000111  The relation matrix 66?R is achieved.

6 6  0 0 0 1 1 0 0 1 0 0 1  0 0 0 1 0 1 0  0 0  R ?  ? ? ? ? ? ? ? ?  = ? ? ? ? ? ? ? ? ? ?? ?  num sex age salary Kind of insurance address  1 man 25 9700 C Yangzhou 2 man 24 17000 D Yangzhou 3 woman 55 15000 A Jiangdu 4 man 60 25000 C Yizheng 5 woman 25 12000 E Jiangdu 6 woman 34 43000 B Yizheng 7 man 62 70000 D Gaoyou 8 woman 40 50000 B Yangzhou 9 man 43 19000 A Yangzhou 10 woman 45 42000 B Jiangdu 11 man 36 54000 C Yizheng 12 man 36 43000 B Gaoyou 13 woman 46 25000 C Yangzhou 14 man 58 35000 C Jiangdu 15 woman 38 45000 D Yizheng 16 man 50 26000 B Gaoyou 17 woman 42 50000 B Yangzhou 18 woman 54 35000 C Jiangdu 19 woman 49 28000 C Yizheng 20 man 51 27000 C Gaoyou  ID List of item_IDs  ID List of item_IDs  1 I1?I5?I12 11 I2?I8?I12 2 I1?I6?I13 12 I2?I8?I11 3 I3?I6?I10 13 I3?I7?I12 4 I3?I7?I12 14 I3?I7?I12 5 I1?I6?I14 15 I2?I8?I13 6 I2?I8?I11 16 I3?I7?I11 7 I4?I9?I13 17 I2?I8?I11 8 I2?I8?I11 18 I3?I7?I12 9 I2?I6?I10 19 I3?I7?I12  10 I2?I8?I11 20 I3?I7?I12     Frequent 2-itemsets L2={{ I2, I8},{ I2, I11 },{ I3, I7},{ I3, I12 },{ I7, I12},{I8, I11 }}. And this result is the same as the result L2?{{ A2, S4},{ A2, B },{ A3, S3},{ A3, C },{ S3, C },{ S4, B }}which is calculated by Apriori algorithm.

Candidate 3-itemsets is based on frequent 2-itemsets. For frequent 2-itemsets, its last item is I8,and because of r45 = 1,so there exists the candidate item { I2, I8, I11}. In the same way, we can get the candidate item { I3, I7, I12}?that is { A2, S4, C}?{ A2, S4, B}. For every candidate item, we use ?AND?, Frequent 3-itemsets L3={{ I2, I8, I11},{ I3, I7, I12}}.

Candidate 4-itemsets is {{ I2, I8, I11,I12}}. When the ?AND? is used for the corresponding position vector, there is no 4- itemsets, here the algorithm is over. L3={{ A3, S3,C},{ A2, S4,B}}. For generating frequent k-itemsets ,optimized SLIG- algorithm reduce the time of running with the binary relation number of the relation matrix.



VI. CONCLUSIONS  Here the data mining analysis can be given by frequent 2- itemsets and frequent 3-itemsets.

(1)age and kind of insurance: A2+B: 5?20=25%,A2+C: 1?20=5%,A3+B: 1?20=5%,A3+C: 6?20=30%.

(2)age and kind of insurance and salary (A2,S4)+B?5?7?71.4%?(A2,S4)+C?1?7?14.3%,  (A3,S3)+B?1?7?14.3%,(A3,S3)+C?6?7?85.7%.

This result is very useful for insurance company decision  making. Similarly, we can mine the individual compensation information by using association rules and data mining tools.

We can gain the characteristic of those who will claim for compensation or not.



VII.  THE CAPABILITY COMPARISON AMONG SLIG??SLIG AND APRIORI  The capability comparison among SLIG ,# SLIG and Apriori is realized by the computer with memory 256M,CPU pentium?R?2.4GHz,operational system windows XP. The test data is the customer database of Chinese life insurance company(Yangzhou). It has 28653 records. The experiment result is as follow figure 1.

1 2 3 4 5 6 7 8 9 10 11 12  min_sup(%)  E x e cu t i on  T i me  Apriori  SLIG  #SLIG   Figure 1.  the operating time comparison among  SLIG??SLIG and Apriori  By comparison, we can see that when frequent 1-itemsets generate, Apriori and SLIG need scan the transaction database for one time to calculate the support of every item, the time for calculating is almost same. By Apriori, 1 1k k kC L L? ?= ? ( k ? 2). When Ck is gained, it starts to scan every affair in the transaction database to calculate the support of candidate k- itemsets and then generate Lk. So the operating time of Apriori is mainly according to the number of candidate itemsets and the size of data. But SLIG mainly uses position vector and relation matrix to find out total frequent k-itemsets[7][8]. This method is fast and simple. When the value of min_sup is small and the itemsets which satisfy the condition are many ,the time for scanning is longer. When the value of min_sup increases, the itemsets that satisfy the condition will reduce , Apriori need to get  Ck by Lk-1,and then scan the database, calculate the candidate sup of Ck. But SLIG only need to scan the position vector, the working time reduces obviously. SLIG transforms the complex frequent itemsets to vector, and it only needs once for scanning. So SLIG is more efficient than Apriori[9][10].For the optimized algorithm based on SLIG,.the time for scanning the database become shorter, it only scan the matrix after the generation of the relation matrix, then do some simple transformation, in addition, it doesn?t scan all the elements in the matrix, only scan the lines that contain ?1?.

We can deal them with modularization and reduce the execution time dramatically. Empirical evaluation and experiments show that optimized SLIG-algorithm generate less candidate itemset  than the SLIG, cut down the amount for computing and improve the efficiency of mining.

