Cohesion-based Space-time Optimized Framework for Confident Association  Mining in Microarray Data

Abstract   Numerous confident and interesting associations in  datasets from diverse domains remain undiscovered for the constraint of classical minimal frequency. A lower choice for threshold frequency not only incurs huge cost of pattern explosion but also cuts reliability of discovered knowledge.

Goal of the present paper is to devise a new framework addressing two necessities. First is discovery of confident associations that are not constrained by classical minimal frequency. Second is ensuring quality of the discovered rules as higher confidence does not necessarily imply better knowledge discovery. We propose a new property among items, terming it cohesion, and develop a cohesion-based scalable algorithm for pattern discovery. In addition to confidences of discovered associations, we compute average lift and DIR measure to assess their quality. Experiments with real and synthetic datasets as well as with microarray dataset prove superiority of the technique.

1. Introduction   DNA microarray technology produces expression profiles of a large number of genes or even the complete genome of a sample cell in a single experiment. Result of sequence of experiments is a two-dimensional array, widely known as gene expression data. It provides ample scope for studying collective behavior of genes. Identification of the groups of genes that are co-expressed can be instrumental in revealing common biological functions and temporal behavior of genes activity, collectively or individual. Series of experiments on same cell type but under different physical or biological conditions, like heat treatment or diseased state, are valuable to study their effect on genes? function or regulation mechanism. Moreover, comparison of genes? function in different cellular states can help in identifying genes that deviate from common biological function under normal conditions. Thus, analysis of gene expression  data can provide important insight in molecular biology and biomedical researches.

Association Rule Discovery(ARD) [1] is an unsupervised data mining technique that discovers association rules of the form A ???? ?? , C, where A and C are frequent itemsets with respect to a pre-defined support threshold and A?C=?. Support ? of the rule is given by the percentage of transaction records containing the itemset A?C. Confidence ? of the rule is the conditional probability that a record, containing A, also contains C and is given as ?=?(A?C)/?(A).

Classical ARD task concerns discovery of every such rule with both support and confidence greater than or equal to pre-defined thresholds. ARD can be an efficient tool in mining gene expression data. A rule with genes X, Y, and Z may be of the form: X [+] ???? ?? , Y [+] and Z [-]. This means when gene X is expressed, gene Y is expressed and gene Z is repressed with a certainty factor of ?%. However, preprocessing of dataset is required for asserting expression levels of genes.

Though, satisfying minimal frequency constraint of rules is an effective idea from efficiency perspective, but not from the perspective of better knowledge discovery as is not an essential criterion for a rule to be interesting. The rule {Down?s syndrome} ? {trisomy 21} (chromosomal defect) is almost 100% confident but with only around 0.1% frequency and hence may not meet the criteria. A lower choice for minimal frequency would entrap an algorithm in combinatorial explosion of patterns. Furthermore, in a set of millions of rules, finding the really interesting ones poses another challenge. Second, every application domain has its own natural properties that bind the associated items into several affinity groups. Items in such a group tend to appear mostly united rather being scattered. It matters less how many times they appear together. What really matters is how confidently they appear together. From this point of view, we introduce the notion of cohesion of itemsets.

DOI 10.1109/ICETET.2008.181     2. Related Work   The concept of uniform support threshold is first argued in [7] with decreasing support threshold level- by-level. The notion is strengthened further in [9] by assigning different thresholds for different data items considering their frequency patterns in the dataset. But the issue of assigning variable thresholds to data items has come up. Literatures [13] and [6] propose a novel row-enumeration technique for mining closed patterns in microarray data. Still, there is possibility of losing low-support associations. This shortcoming is addressed in [11] with introduction of a new algorithm MAXCONF dependent only on confidence pruning. It aims at mining confident single-antecedent rules not constrained by their support.

Literature [8] suggests dataset partitioning technique and border-based algorithm as an alternative for high confidence rule mining. However, such an algorithm is restricted to discover all top rules (confidence = 100%) with the consequent being specified. Literature [5] proposes a measure called similarity, as a substitute for support. However, the phenomenon has been studied only for two-itemsets for its computationally prohibitive nature in higher order itemsets. It has been generalized in [12] with different nomenclatures, bond.

But the technique consumes unaffordable space-time in mining microarray data.

While support pruning has limitation of not reporting infrequent important associations, simply confidence pruning does also have limitations of reporting huge unimportant associations. Only higher confidence does not necessarily imply better knowledge discovery. Pattern explosion problem is additionally there. We therefore like to go midway by choosing cohesion as a measure of interestingness of an itemset. It successfully addresses all three necessities viz. avoiding pattern explosion, mining support-independent important rules and finally enriching quality of discovered rules.

3. Some Terminology  Let I = {1, 2,?, m} be a set of items and T = {1, 2,?,n} be a set of transactions identifiers or tids. For an itemset X, let t(X) denote the set of all tids containing X as a subset.

Definition 1. (Cohesion) Cohesion of an itemset X is a property prevailing among its items that can mathematically be defined as the ratio of cardinalities of two sets viz. the set all of tids containing X as a subset and the set of all tids containing at least one item x of X  as a subset and is given by,   )()()( xtxtX XxXx ??= ??? . (1)  Definition 2. (Cohesive itemset) An itemset X is called a cohesive, if ?(X) is no less than pre-specified threshold. As the name suggests, expression (1) gives the measure of a set of items to stick together.

Lemma 1. Cohesive itemsets retain downward closure property [2].

Proof. For all X such that X?Y, |)( | xtXx?? ?  |)( | ytYy?? and |)( | xtXx?? ? |)( | ytYy?? . So, ?(X)=  |)( | xtXx?? / |)( | xtXx?? ? |)( | ytYy?? / |)( | xtXx?? ?  |)( | ytYy?? / |)( | ytYy?? =?(Y). So, given a threshold for cohesion, if an itemset Y is cohesive, then so are all its subsets.

4. Algorithm   We propose dCARDIAC1 algorithm for cohesive itemset discovery incorporating the tidset and diffset concepts in [14] and [15] respectively. Consider X ={x1, x2,?, xn} be an itemset. We follow the notation X? for {x1?, x2?,?, xn?}. If t(X) is the set of tids containing X as a subset, t(X?) is the set of tids containing X? as a subset i.e. the set of tids containing none of x?X as a subset. For an itemset X,   )(xtXx?? = )( \ ''' xtT Xx ?? . (2)  |)( | xtXx?? = |)'( |-n '' xtXx ?? . (3)  Proof. The two sets )(xtXx?? and )( ''' xtXx ?? are mutually disjoint while their union is the entire dataset T. Therefore equation (2) follows directly. As,  )( ''' xtXx ?? ?T, |)( \| ''' xtT Xx ?? =?T?? |)( | ''' xtXx ??  = |)'( |-n '' xtXx ?? . Hence equation (3) follows.

Diffset of a k-itemset is the set of tids, obtained by  deference of its tidset from the tidset of its (k-1)-length prefix. So if P be a prefix and x be an item, with t(P) and t(x) being the tidsets respectively, diffset of the itemset Px, d(Px) = t(P) \ t(x). If P is null set, t(?) is simply T. Diffset of an item X, d(x) = T \ t(x) which is simply the set of tids not containing x as a subset.

In a diffset-based algorithm, all that are maintained, are only the diffsets of cohesive itemsets instead of tidsets. So how is to compute diffset of an itemset from   1dCARDIAC stands for diffset-based Confident Association Rule Discovery using Itemset Cohesion; the second ?A? is gratuitous.

the diffsets of the two generating itemsets? Equations (4)-(7) answer that. Choosing ?(X)= |)( | xtXx?? and  ?(X)= |)( | xtXx?? for the sake of clarity,   d(Pxy) = d(Py) \ d(Px) . (4) ?(Pxy) = ?(Px) - ?d(Pxy) ?. (5)  d(P ?x?y?) = d(P ?y?) \ d(P ?x?) . (6) ?(Pxy) = ?(Px) + ?d(P ?x?y?) ?. (7)   Proof. Let tid be a transaction identifier. By definition, d(Pxy) = {tid: Px?tid and Py?tid} = {tid: Px?tid} \ {tid: Py?tid} = t(Px) \ t(Py) = {tid: P?tid and Py?tid}\{tid: P?tid and Px?tid} = {t(P) \ t(Py)} \ {t(P) \ t(Px)} = d(Py) \ d(Px)      [Eq. (4) follows].

?(Pxy) = ?{tid: Pxy?tid}? = ?{tid: Px?tid}?? ?{tid: Px?tid and Py?tid}? = ?(Px) ? ?d(Pxy) ?                       [Eq. (5) follows].

Eq. (6) can be proved in the same way as that of Eq.

(4) only by replacing the prefix and items by their complements.

?(Pxy) = n ? ?(P?x?y?)         [from eq. (3)] = n ? {?(P?x?) ? ?d(P?x?y?)?}                 [from eq. (5)] = n ? ?(P?x?) + ?d(P?x?y?)? = ?(Px) +?d(P?x?y?)?                  [Eq. (7) follows].

dCARDIAC ([P ], mincohesion) for all Xi ? [P ] do for all Xj ? [P ] ?  j >i do X = Xi ?Xj d(X) = d(Xj) \ d(Xi) ; ?(X) = ?(Xi) ? ?d(X)? ; d(X ?) = d(Xj ?) \ d(Xi ?) ; ?(X) = ?(Xi) + ?d(X ?)? ; ?(X) = ?(X) / ?(X) ; if ?(X) ? mincohesion S = S ?X ;            // S initialized to ? if S ? ? then call dCARDIAC (S, mincohesion)   Figure 1. dCARDIAC Algorithm   Figure 1 presents dCARDIAC algorithm for cohesive itemset mining. The dCARDIAC algorithm presented above is depth-first, with [P] denoting a cohesive prefix. For each newly discovered candidate, the algorithm needs to compute to different diffsets. The first is to compute support of the itemset PXiXj. The second is to compute support of the itemset P?Xi?Xj?.

The second one is required actually to compute ?(PXiXj) as illustrated earlier. These two diffsets are maintained for all cohesive itemsets determined by a cohesive prefix. A recursive call returns when no more cohesive prefix is added to the list S.

Lemma 2. Let P be a prefix and x and y be two itemsets. If items are sorted in descending order of their diffset cardinality, ?d(Pxy)???d(Px)?.

Proof. Since items are sorted in descending order of their diffset cardinality, Px appears before Py means ?d(Py)???d(Px)?. So ?d(Pxy)?=?d(Py)  \ d(Px)?? ?d(Px)?. This completes the proof.

Thus cardinality of the itemset Pxy is less than that its prefix Px. So with increase in the number of items in the cohesive prefix, diffset cardinality is monotonic decreasing.

If a dataset is sparse, the corresponding complement dataset is dense and vice-versa. Also, for sparse datasets, a tid-based vertical mining algorithm is memory efficient while for dense datasets, a diffset- based vertical mining algorithm is superior [15]. Gene expression data are normally sparse in the sense that average number of elements in the tidset of each gene is not that much significant compared to the total number of records. Consequently, the complement dataset is dense. Therefore we adopt a tid-based approach for computing the set )(xtXx?? and a diffset-based approach for computing the set )( ''' xtXx ?? . At this point we have to make a trade- off whether to optimize the problem of mining the original dataset or the complement dataset.

Significance of space-time optimization is much in a dense dataset compared to a sparse one. Hence, the genes at the onset of mining are sorted in descending order of their tidset cardinality.

Lemma 3. Under equal thresholds for cohesion and support, all frequent itemsets are cohesive but not the reverse.

Proof For an itemset X, ?(X) = |)( | xtXx?? /  |)( | xtXx?? ? |)( | xtXx?? /|T | = ?(X) as ?(X) is upper bounded by |T|. So, with same threshold for cohesion and support, all frequent itemsets are cohesive. But there possibly exists cohesive itemsets that are not frequent. For a dataset, count of such itemsets can be large enough as will be shown in the experimental section. The additional itemsets that come to the picture actually contribute to the low support high confidence rules.

5. Experiment and Analysis   All experiments have been conducted on a 2GHz AMD Athlon PC with 1GB primary memory.

Algorithms are implemented in C++ and run on Debian Linux platform. The ALL-AML leukemia (ALL) dataset contains 72 tissue samples each described by the activity level of 7129 genes. The Central Nervous     System (CNS) dataset contains 60 tissue samples each described by the activity level of 7130 genes. Finally, the Cell-cycle (CC) data of yeast contains the activity level of 6601 genes. For each gene, there are 17 data that are normalized fluorescence between 0 and 160 minutes after cell cycle reinitiating. Dataset characteristics have been tabulated in Figure 4.

Dataset x #items Avg.

length #Representative  genes ALL 40 12009 981.28 8280 CNS 50 12777 1137.42 8342 CC 25 6870 2269.82 3906   Fig 4. Dataset Characteristics   The ?max minus x%? technique [2] is adopted to  convert each quantitative expression in microarray data either of the two categories of a gene, up-regulated and down-regulated. The fourth column contains average record length of different datasets after normalization.

Figure 5 presents execution time of dCARDIAC algorithm, cohesion threshold being decremented stepwise. In ALL dataset, time requirement is below 30 seconds when threshold cohesion is above 60%. In CNS, time requirement is below 20 seconds when threshold cohesion is above 45%. In Cell-cycle, time requirement is below 10 seconds when threshold cohesion is above 75%. Further decrease in cohesion introduces millions of cohesive genesets and a steep increase in run-time is expected. In fact we favor cohesion threshold to be set at the higher end because it would increase average reliability of discovered knowledge.

We implemented the algorithm in [12] for comparative study, as often desired. But both of them cannot proceed to completion due to excessive space- time requirement.

Figure 6 presents storage requirement for maintaining the two sets for each cohesive itemsets.

First is the tidset for mining original dataset (computing |)( | xtXx?? ) while the second is the diffset for mining the complement dataset (computing |)( | xtXx?? ). Storage for maintaining the diffset is negligible compared to that of tidset. Since we are mining at high cohesion, tidsets for different itemsets will contain almost similar items. Therefore their difference will be smaller and diffset storage is small.

Figure 7 presents a comparative study on number of itemsets generated by a support-based technique  with that of generated by the dCARDIAC algorithm, threshold being decreased step by step. Before dCARDIAC takes over, the 100% cohesive patterns are identified and they are taken aside. Each of them is considered as a single pattern. In ALL dataset, number frequent and cohesive itemsets do not have much difference. But in CNS and Cell-cycle data, count of cohesive itemsets is orders of magnitude higher than the count of frequent itemsets. The additional itemsets are actually the low support ones which classical ARD techniques overlook. Furthermore, higher cohesion indicates higher average confidence of the rules generated from them. So, dCARDIAC not only performs better regarding processing time, it is also superior in knowledge discovery.

Figure 8 depicts a comparative study on count of rules generated from frequent and cohesive itemsets, threshold for support or cohesion being decreased step by step. In ALL dataset, number of frequent and cohesive rules is nearly equal. But, as expected in CNS and Cell-cycle datasets, number of informative rules generated from the set of cohesive itemsets is orders of thousands. On the other hand, number of rules generate from frequent itemsets are comparative lesser. The additional rules are the low support ones which remained unexplored in classical techniques.

Figure 9 presents a comparative experimental study on quality of discovered associations from microarray data. We have chosen two well-known measures, lift [3] and Directed Information Ratio (DIR) [4]. We computed both average lift and average DIR for all associations discovered both by support and cohesion measure. Result shows that cohesion-based associations, in most of the cases, have higher average lift and DIR compared to its support-based counterpart.

So, the experiments together, prove superiority of cohesion both in terms of amount and quality of discovered knowledge.

6. Conclusion and Future Plan  Coherent behavior of a set of items or entities in natural domain indicates presence of some common properties prevailing among them or they respond alike under influence of external stimulant that may be a disease or physical treatment on a cell or symptoms for medical diagnosis. We coin the term ?cohesion? to generalize such inherent binding properties or criteria that make a set of items to behave in coherence. The concept of cohesion has the scope of being instrumental for knowledge discovery to unearth     ALL-AML Leukemia         85 80 75 70 65 60  Cohesion threshold (%)  R un  T im  e (s  ec )  Central Nervous System         70 65 60 55 50 45  Cohesion threshold (%)  R un  T im  e (s  ec )  Cell-cycle-yeast        90 87 84 81 78 75  Cohesion threshold (%)  R un  T im  e (s  ec )   Figure 5. Performance of dCARDIAC algorithm   ALL-AML Leukemia  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  85 80 75 70 65 60  Cohesion threshold (%)  St or  ag e  (B )  t idset sto rage diffset sto rage  Central Nervous System  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  70 65 60 55 50 45  Cohesion threshold (%)  St or  ag e  (B )  t idset sto rage diffset sto rage  Cell-cycle-yeast  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  90 87 84 81 78 75  Cohesion threshold (%)  St or  ag e  (B )  t idset sto rage diffset sto rage   Figure 6. Comparison of storage required for maintaining the two sets   ALL-AML Leukemia  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  85 80 75 70 65 60  Threshold (%)  # Ite  m se  ts  f requent itemset cohesive itemset    Central Nervous System  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  70 65 60 55 50 45  Threshold (%)  # Ite  m se  ts  f requent itemset cohesive itemset    Cell-cycle-yeast  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  90 87 84 81 78 75  Threshold (%)  # Ite  m se  ts  f requent itemset cohesive itemset   Figure 7. Comparison on count of frequent and cohesive itemsets under varying threshold    ALL-AML Leukemia  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  85 80 75 70  Threshold (%)  # R  ul es  support cohesion  Central Nervous System  1.E+00  1.E+02  1.E+04  1.E+06  1.E+08  70 65 60 55  Threshold (%)  # R  ul es  support cohesion   Figure 8. Comparison on count of rules under support and cohesion measure      Figure 9. Quality analysis of discovered associations in terms of lift and DIR   crucial unknown knowledge prevailing in the domain.

We have formalized cohesion and developed a methodology with supporting algorithm for cohesive itemset mining in a large dataset. High support constraint avoids combinatorial explosion in discovering frequent itemsets, but at the expense of missing interesting patterns of low support. However, most rules with high support are obvious and well- known, and it is the rules with low-support that provide interesting new insight, such as deviations or exceptions.

In future we wish to extend this concept toward mining closed patterns. We also look for biological implication of some of the discovered associations to strengthen further the concept of cohesion and reliability study.

8. References  [1] R. Aggarwal, T. Imielinski and A. Swamy, ?Mining Association Rules between Sets of Items in Large Databases?, Proc. ACM Int?l Conf. on Management of Data (SIGMOD), Washington DC, May (1993) 207-216.

[2] C. Becquet, S. Blachon, B. Jeudy, JF. Boulicaut and O.

Gandrillon, ?Strong association-rule mining for large scale gene expression data analysis: a case study on human SAGE data?, Genome Biology, vol. 3, no. 12, (2002) 1-16.

[3] J. A. Berry, G. S. Linoff, ?Data Mining Techniques for Marketing, Sales and Customer Support?, John Wiley & Sons, Inc. (1997).

[4] J. Blanchard, F. Guillet, R. Gras, and H. Briand, ?Using Information-theoretic Measures to Assess Association Rule Interestingness?, Proc. Fifth IEEE Int?l Conf. on Data Mining, ICDM, 2005.

[5] E. Cohen, M. Datar, S. Fujiwara, A. Gionis, P. Indyk, R.

Motwani, J.D. Ullman and C. Yang, ?Finding Interesting Associations without Support Pruning?, Proc. IEEE ICDE, (2000) 489-500.

[6] G. Cong, K.-L. Tan, A. Tung, and F. Pan, ?Mining frequent closed patterns in microarray data.? in Fourth IEEE Int?l Conf. on Data Mining (ICDM), vol. 4, pp. 363?366, 2004.

[7] J. Han and Y. Fu, ?Discovery of multiple-level association rules from large databases?, Proc. 21st Int. Conf.

Very Large Data Bases (VLDB). Zurich, Swizerland (1995) 420-431.

[8] L. Jinyan, Z. Xiuzhen, D. Guozhu, R. Kotagiri, and S.

Qun, ?Efficient Mining of High Confidence Association Rules without Support Thresholds?, Proc. 3rd European Conference, PKDD (1999) 406-411.

[9] B. Liu, W. Hsu and Y. Ma, ?Mining association rules with multiple minimum supports?, Proc. 1999 ACM- SIGKDD, San Deigo, CA (1999) 337-341.

[11] T. McIntosh, and S. Chawla, ?High Confidence Rule Mining for Microarray Analysis?, IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB), 4(4): 611-623 (2007)  [12] E. Omiecinski, ?Alternative Interest Measures for Mining Associations in Databases?, IEEE Trans. on Knowledge and Data Engineering, 15(1): 57-69 (2003)  [13] F. Pan, G. Cong, K. Tung, J. Yang, and M. Zaki, ?CARPENTER: Finding closed patterns in long biological datasets?, ACM SIGKDD Int?l Conf. on Knowledge Discovery and Data Mining (KDD), pp. 637?642, 2003.

[14] M. J. Zaki, ?Scalable Algorithms for Association Rule Mining? IEEE Trans. on Knowledge and Data Engineering, 12(3), (2000) 372-390.

[15] M. J. Zaki and C. Gouda, ?Fast vertical mining using diffsets?, Proc. ACM SIGKDD, Washington DC, (2003).

