Genetic Network Programming with Acquisition Mechanisms of Association Rules in Dense Database

Abstract  A method of association rule mining using Genetic Net- work Programming (GNP) is proposed to improve the performance of association rule extraction from dense database. Rule extraction is done without identifying fre- quent itemsets used in Apriori-like methods. Association rules are represented as the connections of nodes in GNP.

The proposed mechanisms calculate measurements of asso- ciation rules directly from a database using GNP, and mea- sure the significance of the association via the chi-squared test. The proposed system evolves itself by an evolutionary method and obtains candidates of association rules by ge- netic operations. Extracted association rules are stored in a pool all together through generations and reflected in ge- netic operators as acquired information. In this paper, we describe an algorithm capable of finding important associ- ation rules using GNP with sophisticated rule acquisition mechanisms and present some experimental results.

1. Introduction  Association rule mining is the discovery of associa- tion relationships or correlations among a set of attributes (items) in a database [1]. Association rule in the form of ?If then ( )? is interpreted as ?database tuples satisfying that are likely to satisfy ?. Association rules are widely used in marketing, decision making and business management. The most popular model for mining associa- tion rules from databases is Apriori algorithm, the support- confidence framework proposed by Agrawal et al. [2]. This model measures the uncertainty of an association rule with two factors: support and confidence. An association rule is expected to capture a certain type of dependence among items in a database. Brin et al. made the suggestion to mea- sure the significance of association via the chi-squared test for correlation used in classical statistics [3]. There have  been published numerous papers showing improvements on mining itemsets of interest [4, 5, 6, 7].

A method of association rule mining using Genetic Net- work Programming (GNP) has already been proposed [8].

GNP is one of the evolutionary optimization techniques, which uses directed graph structures as genes [9, 10]. GNP is composed of two kinds of nodes: judgement node and processing node. Attributes in database correspond to judgement nodes in GNP. Association rules are represented by the connections of nodes. The proposed method calcu- lates support and confidence of association rules directly using GNP. Candidates of important rules are obtained by genetic operations. The algorithm extracts the important as- sociation rules in the case of both free consequent and fixed consequent using GNP. The features of the method are as follows:  Rule extraction is done without identifying frequent itemsets used in Apriori-like methods. The method can be applied to rule extraction from dense database, where many frequently occurring items are found in each tuple [5].

Conditions of important association rules are defined flexibly. The definition can include the minimum threshold chi-squared value, which is measured by the feature of GNP?s structure.

Extracted rules are stored in a pool through genera- tions. GNP evolves in order to store new interesting rules in a pool, not to obtain the individual with high fitness value.

In this paper, we extend the algorithm and propose so- phisticated association rule acquisition mechanisms as fol- lows:  In [8], GNP including all functions of judgement node and the number of each function was fixed. In this paper, node functions of judgement nodes can be  Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC?05)    Figure 1. The basic structure of GNP individ- ual.

Figure 2. Gene structure of GNP (node ).

changed. As a result, we can easily extend the method to the one applicable to large and dense databases.

GNP uses an additional genetic operation, which changes the function of each judgement node by a given rate. Candidates of important rules can be ob- tained effectively by this operation.

Extracted important association rules in a pool are re- flected in genetic operators as acquired information.

Mutation and crossover change the contents of the nodes using the knowledge of interesting association rules acquired in a pool.

The proposed method can easily extract positive and negative association rules just by defining the judge- ment nodes including negative attributes.

Our method cannot extract all the rules meeting given definitions of importance, but extracts important association rules sufficiently enough for user?s purpose.

2. Genetic network programming (GNP)  In this section, the outline of conventional Genetic Net- work Programming (GNP) [9, 10] is explained. GNP is one of the evolutionary optimization techniques, which uses di- rected graph structures as solutions. The basic structure of GNP is shown in Fig.1. GNP is composed of two kinds of nodes: judgement node and processing node. Judge- ment nodes correspond nearly to elementary functions of Genetic Programming (GP). Judgement nodes are the set of  , ,. . . , , which work as if-then type decision mak- ing functions. On the other hand, processing nodes are the set of , ,. . . , , which work as some kind of action/processing functions. The practical roles of these nodes are predefined and stored in the library by supervi- sors. Once GNP is booted up, firstly the execution starts from the start node, secondly the next node to be executed is determined according to the connection from the current activated node. GNP is useful because it can not only form the optimal structure effectively, but it can also avoid the premature convergence.

The genotype expression of GNP node is shown in Fig.2.

This describes the gene of node , then the set of these genes represents the genotype of GNP individuals. describes the node type, when node is start node, when node is judgement node and when node  is processing node. is an identification number, for example, and mean node is . ,  ,. . . , denote the nodes which are connected from node firstly, secondly,. . . , and so on depending on the arguments of node . All programs in a population have the same num- ber of nodes. The following genetic operators are used in GNP. Crossover operator affects two parent individuals. All the connections or contents of the uniformly selected corre- sponding nodes in two parents are swapped each other by crossover rate . Mutation operator affects one individual.

All the connections of each node are changed randomly by mutation rate of .

3. Association rules  The following is a formal statement of the problem of mining association rules. Let be a set of literals, called items or attributes. Let be a set of trans- actions, where each transaction is a set of items such that  . Associated with each transaction is a unique iden- tifier whose set is called . We say that a transaction contains , a set of some items in , if . An asso- ciation rule is an implication of the form , where  , , and . is called antecedent and is called consequent of the rule. In general, a set of items is called an itemset. Each itemset has an associ- ated measure of statistical significance called support. If the fraction of transactions containing in equals t, then we say that . The rule has a mea- sure of its strength called confidence defined as the ratio of  . An example is shown be- low using Table 1. Let item universe be and transaction universe be . In order to extend our research not only to market basket problems but also to dense databases, we indicate the items of the trans- action by 1 or 0 as shown in Table 1. In Table 1, itemset  occurs in two transactions of 1 and 3 in . So, its  Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC?05)    Table 1. An example of database.

1 1 0 1 0 2 0 1 1 1 3 1 1 1 1 4 0 1 0 1  frequency is 2, therefore, its support, that is, becomes 0.5. Itemset occurs in the  transaction of 3 in . Its frequency is 1, so its support, i.e., becomes 0.25.

Therefore, , and .

The Apriori algorithm searches large (frequent) item- sets in databases [2]. This algorithm finds all rules meet- ing user-specified constraints such as minimum support or minimum confidence. However, this algorithm may suffer from large computational overheads when the number of frequent itemsets is very large. Many variations of this ap- proach, such as the hash-based algorithm have been studied for efficiency [4]. There has been a recent trend in applying the rule mining to dense databases [5], such as census data analysis [3], where any or all of the following properties are found: many frequently occurring items; strong correlations between several items; many items in each tuple.

On the other hand, calculation of value of the rule is described as follows. Let ,  , and the number of database tuples equal . If events and are independent then . Table 2 is the contingency of  and : the upper parts are the expectation values under the assumption of their independence, and the lower parts are observational. Now, let denote the value of the ex- pectation under the assumption of independence and the value of the observation. Then the chi-squared statistic is defined as follows:  (1)  We can calculate using , , and of Table 2 as fol- lows:  (2)  This has 1 degree of freedom. If it is higher than a cut- off value (3.84 at the 95% significance level, or 6.63 at the 99% significance level), we should reject the independence assumption.

Table 2. The contingency of and .

( : the number of tuples )  4. Association rule mining using GNP  In this section, an extended method of association rule mining using Genetic Network Programming (GNP) is pro- posed. Let be an attribute (item) in a database and its value be 1 or 0. The method extracts the following associa- tion rules:  (briefly, ).

Attributes and their values correspond to the functions of judgement nodes in GNP. The connections of nodes are represented as association rules. Fig.3 shows a basic struc- ture of GNP for association rule mining. is a processing node and is a starting point of association rules. ? ?, ? ?, ? ? and ? ? in Fig.3 denote the func- tions of judgement nodes. The connections of these nodes represent association rules, for example, ,  and . The details of it are described in the next subsection.

GNP examines the attribute values of database tuples us- ing judgement nodes and calculates the measurements of as- sociation rules using processing nodes. Judgement node de- termines the next node by a judgement result of Yes or No, and has Yes-side and No-side. Yes-side of the judgement node is connected to another judgement node. Judgement nodes can be reused and shared with some other association rules because of GNP?s feature. As a result, candidates of rules are obtained effectively.

Each processing node has an inherent numeric order ( , ,. . . , ) and is connected to a judgement node. Start  node is connects to . Examinations of attribute values start at each processing node. No-side of the judgement node is connected to the next numbered processing node.

For example, in Table 1, the tuple satisfies and , therefore, the node transition from to occurs in Fig.3 in this case. If the examination of the con- nection from the starting point ends, then GNP exam- ines the tuple from likewise. Thus, all tu- ples in database will be examined. If Yes-side connection  Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC?05)    Figure 3. GNP for association rule mining.

of judgement nodes continues and the number of the judge- ment nodes becomes a cutoff value (maximum number of attributes in extracted association rules), then Yes-side con- nection is transferred to the next processing node obligato- rily.

Incidentally, the connections of the nodes and the func- tions of the judgement nodes at an initial generation are de- termined randomly for each of the GNP individual. GNP needs not include all functions of judgement node and the number of each function is not fixed unlike a conventional method [8].

The total number of tuples moving to Yes-side at each judgement node is calculated for every processing node, which is a starting point for calculating association rules. In Fig.3, N is the number of total tuples, and a, b, c and d are the numbers of tuples moving to Yes-side at each Judgement node. The measurements are calculated by these numbers.

Table 3 shows the measurements of the support and confi- dence of association rules. The proposed method measure the significance of associations via the chi-squared test for correlation used in classical statistics. For example, if we change the connection of node from ? ? node to ? ? node in Fig.3, we are able to calculate the support of and in next examination. As a result we will obtain value of and so on. Proposed method repeats this like a chain operation at each genera- tion.

Now, we define important association rules as the ones which satisfy the following:  (3)  (4)  and are the minimum threshold chi-squared and support value given by supervisors. If required, we can also add confidence to the definition of important associa- tion rules.

When an important rule is extracted by GNP, the overlap of the attributes is checked and it is also checked whether an  Table 3. Measurements of association rules.

association rules support confidence  b/N b/a c/N c/a d/N d/a c/N c/b d/N d/b d/N d/c  important rule is new or not, i.e., whether it is in the pool or not. The extracted important association rules are stored in a pool all together through generations in order to find new important rules.

Fitness of GNP is defined as  (5)  The items in Eq.(5) are as follows: : set of suffixes of important association rules which sat-  isfy Eq.(3) and Eq.(4) in a GNP (individual) : chi-squared value of rule .

: the number of attributes in the antecedent of rule .

: the number of attributes in the consequent of rule .

: additional constant defined as  (rule is new)  (rule has been already extracted) (6)  , , and are concerned with the importance, complexity and novelty of rule , respectively.

At each generation, individuals are replaced with new ones by the selection rule and genetic operations. GNP in- dividuals evolve in order to store new interesting rules in a pool, not to obtain the individuals with high fitness value.

Therefore, the proposed method is fundamentally differ- ent from other evolutionary algorithms in its evolutionary way. When an important association rule is extracted, the rule changing an attribute to another one or the rule adding some attributes can be candidates of important rules. We obtain these rules effectively by genetic operations of GNP, because mutation and crossover change the connections or contents of the nodes. We use three kinds of genetic opera- tors;  Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC?05)    Crossover: Crossover we used is the uniform crossover. Judgement nodes are selected as crossover nodes with the probability of . Two parents ex- change the gene of the corresponding crossover nodes.

Mutation-1: Mutation-1 operator affects one individ- ual. The connection of the judgement nodes is changed randomly by mutation rate of .

Mutation-2: Mutation-2 operator is an additional ge- netic operation and affects one individual. This oper- ator changes the function of the judgement nodes by a given mutation rate . All programs in a population have the same number of nodes, but the node with the same node number needs not have the same function due to mutation-2.

The individuals are ranked by their fitnesses and upper 1/3 individuals are selected. After that, they are reproduced three times, then three kinds of genetic operators are exe- cuted to them. These operators are executed for the gene of judgement nodes of GNP. All the connections of the pro- cessing nodes are changed randomly in order to extract rules efficiently.

As one of the features of our new method, we can select the new functions by the mutated judgement nodes using the frequency of attributes in the extracted rules of the pool, that could be all the extracted rules, or rules extracted in some of the latest generations. We define the probability of selecting the attribute for judgement nodes as the following or , when mutation-2 is carried out:  (7)  where : the set of suffixes of attributes.

is the probability of selecting using the informa-  tion on all the extracted association rules. is the fre- quency of the attribute in all the extracted rules in the pool.

(8)  is the probability of also selecting using the restricted information on the association rules extracted in the latest generations. is the frequency of the attribute in the rules extracted in the latest generations. If no rules are extracted in the recent generations, then is equal to the inverse of the number of attributes.

0  200  400  600  800  1000  A ss  oc ia  tio n  ru le  s  Generation  Pj0 Pjall Pj5 *C  Random  Figure 4. Averaged number of association rules over 10 trials in the pool (Simulation 1).

5. Simulation results  We have performed experiments and estimated the per- formance of our algorithm. All the experiments were run on synthetic data DB1, DB2 and DB3. The synthetic database DB1 includes 26 attributes ( , . The number of tuples are 200,  and .

DB2 was compounded by random numbers, and includes 26 attributes ( , . The number of tuples are 200, . DB3 is the join of DB1 and DB2. DB3 includes 52 attributes and 200 tuples. The average number of attributes whose value equal 1 in a tuple is 14 in DB1, 27 in DB3, respectively.

Evaluations are studied in the following three cases  Use of acquired information (Simulation 1)  Apply to the large and dense database (Simulation 2)  Extract negative association rules (Simulation 3)  The population size is 120. The number of processing nodes and judgement nodes are 10 and 78, respectively.

We use (3) ( ), (4) ( ), (5) and (6) ( ). In addition, the added conditions of ex- tracting association rules in the simulations are as follows:  , , The conditions of crossover and mutation are ,  and (78 corresponds to the number of Judgement nodes). The number of changing the con- nections of the processing nodes at each generation we dis- cussed in subsection 4.2 is 5. All algorithms were coded in C. Experiments were done on a 1.50GHz Pentium M with 504MB RAM. For the comparison of the proposed method with others, we consider the Random GNP model, which does not evolve but just repeats random initialization every generation.

Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC?05)             0  20  40  60  80  100  120  A ss  oc ia  tio n  ru le  s  Time (sec)  Pj0 Pjall Pj5 *C  Random  Figure 5. Averaged number of association rules in the pool versus run-time (Simulation 1).

0  200  400  600  800  1000  A ss  oc ia  tio n  ru le  s  Generation  Pj0 Pjall Pj5 *C  Random  Figure 6. Averaged number of association rules over 10 trials in the pool (  , Simulation 1).

We have estimated the performance of the use of ac- quired information using DB1. In Simulation 1, the fol- lowing rules are extracted:  .

We have performed three cases, using three different prob- abilities of , and for selecting the attributes of judgement nodes at mutation-2. means the probability of selecting each attribute is equal.

Fig.4 shows the number of important association rules obtained in the pool. It shows the mean value over ten simulations. Random denotes Random GNP model and *C shows the result obtained in [8] under the same conditions.

*C only changes the connections of nodes. DB1 is a dense database, so several thousands of rules that satisfied the defi- nition of importance are obtained. Fig.5 shows the averaged number of association rules versus run-time in the same ex- periment as Fig.4. These show that the method using ac- quired information extracts the important association rules in the database effectively.

0  500  1000  1500  2000  A ss  oc ia  tio n  ru le  s  Generation  Figure 7. Number of association rules in the pool in ten simulations ( , Simulation 2).

0  500  1000  1500  2000 A  ss oc  ia tio  n ru  le s  Generation  Figure 8. Number of association rules in the pool in ten simulations ( , Simulation 2).

Fig.6 shows the averaged number of important associa- tion rules made up of 7 attributes ( ) in the pool. Through an additional condition of the important rules, it is clear that the number of important rules acquired is decreased, although the proposed method is still better than the conventional ones. Random model is not able to extract such rules.

In Simulation 2, the proposed method is applied to the large and dense database DB3. The conditions are the same as Simulation 1. Incidentally, important rules cannot be ex- tracted from DB2 under the same condition as Simulation 1.

Fig.7 and Fig.8 show the number of important associa- tion rules obtained in the pool in ten simulations under and , respectively. When the number of attributes in- creases, for example, from 26 to 52, the number of combi- nations of rules with 6 attributes swells about 88 times and 7 attributes swells about 203 times, respectively. Therefore, as can be seen from Fig.7 and Fig.8, this causes to extend the breakthrough generation of starting rule extractions ef-  Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC?05)             0  100  200  300  400  500  600  A ss  oc ia  tio n  ru le  s  Time (sec)  Figure 9. Number of association rules in the pool versus run-time ( , Simulation 2).

0  500  1000  1500  2000  A ss  oc ia  tio n  ru le  s  Generation  Figure 10. Number of positive and negative association rules in the pool in ten simula- tions ( , Simulation 3).

fectively. But, it is clear that, if we do not use the acquired information, then it is difficult to extract the rules from large database even at the extended generation of 2000. Fig.9 shows the number of association rules versus run-time in the same experiment as Fig.8. This shows that our method can extract most of the rules in DB3 within 120 seconds, which is almost the same time as Simulation 1. Therefore, we can see that our proposed method is applicable to dense databases effectively. The execution time required by our method does not explode even in the case of mining dense and large database.

We have estimated the performance of extracting pos- itive and negative association rules. Positive association rules are conventional ones. Negative association rules are defined as the rules that contain negation of attributes (i.e.

attributes value equals 0). Then, for example, the following rule  is extracted. It is not easy for conventional         0  500  1000  1500  2000  A ss  oc ia  tio n  ru le  s  Generation  Figure 11. Number of positive association rules in ten simulations in the pool ( ,  , Simulation 3).

methods to acquire such type of associations. However, our method executes this by setting node functions includ- ing negative attributes. In this simulation, DB1 was used, but here the attribute values of judgement nodes include not only 1 but also 0. GNP individual includes conflict- ing judgement nodes such as ? ? and ? ? in the node connections. Therefore, the kind of the judgement nodes becomes twice compared with Simulation 1. The ex- periment was performed using .

Fig.10 shows ten simulation results on the number of im- portant positive and negative association rules in the pool.

From simulations, it is clear that GNP with acquisition mechanisms can extract important positive and negative rules, whose number is more than just extracting only pos- itive association rules (compare Fig.10 and Fig.4). Fig.11 shows the number of obtained positive association rules in the pool, which are made up of 7 attributes in ten simula- tions of DB1. Comparing the result of Fig.11 with Fig.6, it is found that the breakthrough generation at each trial is spread over, but the proposed method extracts such rules at a stretch.

6. Conclusions  In this paper, a method of association rule mining from dense database using Genetic Network Programming has been proposed. The proposed system evolves itself by an evolutionary method and measures the significance of as- sociations via the chi-squared value. Extracted association rules are stored in a pool all together through generations in order to find new rules. These rules are reflected in ge- netic operators as acquired information. We have performed three experiments and estimated the performance of our al- gorithm. The results showed that proposed method extracts the important association rules in the dense database effec- tively. We are currently studying the applications of our method to real world databases.

