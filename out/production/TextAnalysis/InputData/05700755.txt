Stock Trading Rule Discovery Based on   Temporal Data Mining

Abstract? One of the major tasks in stock market analysis is the discovery of specific events that give rise to a particular event. In this research we emphasize on temporal data mining with a time dimensional approach. This has led us to the discovery of sequential continuous patterns. The patterns serve as rules that enable us to determine the occurrence of an event on a particular stock-transaction day. In our paper, we have proposed and implemented the STRDTM (Stock Trading Rule Discovery by Temporal Mining) algorithm with real life data from Dhaka Stock Exchange as input.

Keywords? Datamining, temporal datamining sequential pattern discovery, frequent sets, association rule mining.



I. INTRODUCTION The Dhaka stock exchange (DSE) [5] is the central stock  exchange in Bangladesh with 448 companies (as of 2009). All of these corporations are categorized according to their market capitalization in the DSE.

The stock market gives rise to an environment of fluctuating stock prices and generates a huge amount of data collected in the form of event time sequences.  The stock market, given its pestering and confusing environment, serves as an apt and ample problem to which the concept and techniques of temporal data mining could be applied. The outcome from this procedure can again be verified with the statistical suggestions to determine how effective temporal data mining on DSE could serve as an indicator.

The stock market gives rise to time sequences, so it would be quite interesting to take note of the various events that progress with time and then concentrate on specific events at particular time periods or analyse the frequency of the occurrence of events for a detailed and informative monitoring process for the prediction of future behaviour. We are interested in the sequence of actions or events that leads to such particular action (let?s note them basic events and target event, respectively). So, we intend to mine the target rules (rules ending with a target event) on the basis of the training set taken into consideration. Thereafter, all the high confidence rules shall be implemented to determine suitable suggestions on the basis of certain events occurring on that day. This is our main objective of research.

A. Statistical Analysis Shareholders use a number of indicators to determine how  much a stock is worth. These might include both fundamental  and technical analysis. Fundamental analysis includes the observance of historical behaviour of a stock, rumour, broker?s claim whereas technical analysis includes well educated guesses on stock behaviour. One simple indicator is the price/earnings ratio. This is the price of the stock divided by the earnings per share. Other indicators include analysis of graphs such as MACD (moving average convergence- divergence) and PPO (percentage price oscillator).

Because of the unpredictability of the stock trading nature of DSE, a survey was undertaken amongst the experienced stockholders to understand the individual point of discretion of whether to buy or sell a share. On the other hand all modes of technical analysis were prepared to verify the extent of coherency of stockholder?s opinion to statistical approach. As a consequence of this integration and matching scheme, MACD turned out to be the most effective indicator in identifying a bullish or bearish market with a 66.23% superposition.

B. Related Work Mining of sequential patterns was introduced by R.

Agrawal and R. Srikant in [1]. They attempted to discover sequential patterns from a database of sequences, where each sequence was a list of transactions ordered by transaction time, and each transaction was a set of items.

The research idea described in this paper was inspired by the idea proposed by E. Gudes and L. Marina [3]. In their paper, the authors proposed two algorithms, CTSPD (Continuous Target Sequential Pattern Discovery) and CSPADE (Continuous Sequential Patterns Discovery using Equivalent Classes), to discover the customers interested to take the upgraded products of a telecommunication company based on the previous usage data of those customers. The basic idea behind STRDTM comes from the CTSPD algorithm. However, we have made substantial modifications to represent our own datasets of stock prices, the sequence database, and above all incorporating the object oriented concept to existing algorithm. Besides, the system could trigger trading rules automatically if regular stock prices from DSE are fed to the system.



II. ALGORITHM DESCRIPTION  A. Definition and Problem Statement A dataset D is collected from the DSE and filtered  according to particular companies as shown in Table 1. As observed, transaction encountered are usually of the type   ICECE 2010, 18-20 December 2010, Dhaka, Bangladesh     ?tradecode, startd, endd, event1, event2, ?, eventn, target?, where eventi is the basic event occurring at [startd, endd] as shown in Table 2, and an aggregation of those events is referred to as itemset. Each basic event is associated with the period between startd and endd, and each target event is associated with outcomes of the MACD graph as shown in Figure 1.

Furthermore, an ordered list of itemsets denoted by l1 ? target1 ? l2 ? target2 ? ? ? ln ? targetn is called a sequence (denoted by s), where li is an itemset of basic events and targeti is an event with the boolean feature buy/sell.

Hence more formally li denotes the ith basic event and  targeti is the ith target level. Now a sequence may not necessarily begin with a basic event or end with a target event so in those cases the following sequence may be observed target1 ? l1 ? target2 ? l2 ? ? ? targetn ? ln.

The filtered data from dataset D has been sorted by the timestamp in order to generate a single sequence as shown in Table I and is referred to as stock-sequence, SD.

For a sequence s as mentioned earlier a level is defined as an itemset giving a target event (li?targeti where i is the ith level). In the absence of a target event or an itemset at any particular level it is then represented as NULL. For example, a sequence targeti?li+1 is segregated in the following manner NULL?targeti and li+1? NULL.

Definition 1: The length of a sequence is the number of levels in the sequence so for the previous sequence targeti?li+1 the length is 2.

Definition 2: The size of a sequence is the number of events in the sequence. For instance, the sequence (li ?targeti?li+1) can be represented as AB ?U?C where length equal to 2 and size equal to 4.

Definition 3: Provided s? is a subset of a sequence s, support count ? indicates the number of occurrences of s? in s.

Consequently support of sequence s? is defined as fraction of transaction (which in this case is the sequence s), that contains a sequence s?. Support = ?(s?)/n where is n is number of levels in sequence s.

Definition 4: Target rule is a sequence trailed with any target event.

Definition 5: The confidence for target rule, denoted by conf ( ) is defined as the fraction of how often the items in the consequent appears in transactions that contain the antecedent.

A rule with minimum support and minimum confidence is called a frequent rule. For instance if s?=A?U?B?U? then Confidence(s?) = ?(s?)/? (A?U?B).

Given a transaction dataset as defined above, the problem of mining target events rules using continuous sequential mining is to find all frequent target rules.

B. Algorithm 1) Event Generation: The frequent events  corresponding to certain happenings in regard to the stock database such as increase or decrease of attribute values are stored in a database, as partly shown in Table VII. Thereafter, the events are mapped to certain integers which serve as positions or indices which are made in 1 in a bit string. For example, the event A in a 4-bit string would be specified as 1000 whereas C would become 0010.

2) Getting the Transformed Database: Here our prime focus is to generate the single sequences, as mentioned earlier, corresponding to an individual company. The events including the target events found earlier are integrated to form the single sequences. However, an infrequent event shall not be utilised  in the formation. Moreover, the concept of an individual level is hereafter transformed to that of a pair-level (i.e. li ? targeti , where i is the ith pair-level). Now the mapping of a pair-level is as follows: AB ? U is represented by 1100?1. We use single bit for target level, that is set to 1 if the target = true and to 0 otherwise.

3) Frequent Sequence Generation: Plevels and Plevelsd of the form itemset?target and target?itemset respectively, are extensively used to determine the frequent sequences of size 2. These 2-sequences are used later to generate the k-sequences using appropriate joins. As an attempt to determine all the frequent sequences we carry out multiple passes over the database. In each pass, the k- sequence is used to generate the next probable k+1 sequences, which are considered as candidates. The candidates then undergo a pruning process as shown in Algorithm 1. The frequent candidates now serve as the frequent sequences for the next sequence generation.

4) Rule Generation: This is the ultimate part where all the frequent sequences which end with a target event are filtered. The sequences then are subjected to a pruning process, which is the removal of sequences that fail to satisfy the minimum confidence set by the programmer.

5) Explanation of Joins used in our program: We have currently implemented two different kinds of joins in order to generate the next possible frequently occurring sequences.

First we have implemented the ExpJoin()[2] which takes in two sequences S1 and S2 as parameters. The sequences s1 and s2 are of the same length i.e. must have the same number of pair-level. Considering S1 and S2 to be k-sequences, the expjoin() will generate k+1 sequence. Then a suitable pair- level is selected for performing the expansion join provided that all other pair-levels are the same. For example, two sequences U? ? AC ? U and U? ? AE ? U form the candidate U? ? ACE ? U. The join used works in a similar fashion as that of the itemset generation of the Apriori algorithm[1].

The ConcatJoin()[2] works in a similar fashion by taking in two inputs, s1 and s2 where s1 is k-sequence and s2 is a 2- sequence. The procedure performs a join only if the last level of sequence s1 superposes with the first level of s2 or vice versa. As a result we generate a maximum of two new candidates from a single pair. For example, two sequences U? ? AC ? U and U?C. The new candidate is U? ? AC ? U?C.

6) Explanation of Target Event Generation: As mentioned earlier, an integration and comparison of the stockholder?s discretion with the statistical analysis assured us in using the traditional MACD graph, to analyse stock in DSE.

The MACD [3] is a trend following momentum indicator that shows the relationship between two moving averages. The MACD is calculated by considering the difference between a 26-day and 12-day period exponential moving average (EMA) of closing prices. Subsequently we generated the EMA for a 9-day period of the MACD itself. This produces the signal which can trail the MACD and makes it easier to spot turns in MACD as shown in figure I. A bullish crossover occurs when MACD turns up and crosses above the signal line i.e.

targeti?buy. A bearish crossover occurs when MACD turns down and crosses below the signal line i.e. targeti?sell. More details about MACD could be found elsewhere [6].

Figure 1: MACD Graph  Algorithm1: L2 Generation GenerateL2() { Plevels : Contains sequence of type basic event ?target event Plevelsd : Contains sequence of type target event ?basic event for each element in Plevels generate sequence of size 2 prune infrequent sequences using Prune() for each element in Plevelsd generate sequence of size 2 prune infrequent sequence using  Pruned() }   Algorithm2: Lk Generation & Rule Generation  Main(){ Result = null; while(Lk!=null){ Result = Result U Lk; for (int i=0 ; i<Lk_index ; i++) for (int j=i+1 ; j<Lk_index ; j++) ExpansionJoin(Lk[i], Lk[j]); Candidate[cand_index++] = frequent sequences generated by ExpansionJoin() after pruning for (int k=0 ; k<L2_index ; k++) ConcatenationJoin(Lk[i], L2[k]); Candidate[cand_index++] = frequent sequences generated by ConcatenationJoin() after pruning using ConcatPrune() for (int i=0 ; i<cand_index ; i++) Result = Result U Candidate[i]; } for (int i=0 ; i<Result_index ; i++){ if (Result[i] ends with target event) calculate confidence as per formula if (confidence ? min_conf) Rules[Rules_index++] = Result[i];  } }   Algorithm3: Pruning  Prune(String s1, String s2){ if (sequence s1 subset_of sequence s2) calculate support of sequence s1 if (support ? min_supp) return false; else  return true; }  Algorithm4: ExpansionJoin ExpansionJoin(String s1, String s2){ lev = -1; if (length of seq s1 == length of seq s2) for (int i=0 ; i<length_s1 ; i++) if (plevel_s1i != plevel_s2i) if (target level of s1 == target level of s2) if (lev == -1) lev = I; else return as more than one plevel has been matched else return as targets mismatch if (lev == i) return as no plevels have been matched Temp = Expand s1 and s2 at lev Candidate = !Prune(Temp);  }   Algorithm5: ConcatenationJoin ConcatenationJoin(String s1, String s2){ if (s1.firstLevel == s2.lastLevel) Temp = Concatenate s2 and s1; Candidate = !ConcatPrune(Temp); If (s1.lastLevel == s2.firstLevel) Temp = Concatenate s1 and s2 Candidate = !ConcatPrune(Temp);  }

III. RESULTS AND FINDINGS On the basis of the stock market data available to us we  utilized three months data of a particular company (AB Bank with trade code 100) to generate the transformed dataset TD (shown partly in Table VII & VIII), along with the frequent basic events and target events. The rules generated on the sequential patterns comply with min_support = 9 and min_conf = 89. In the testing phase we look for the occurrence of certain basic events on a particular day of testing, we thereafter scan for a high confidence rule such that the set of basic events in the rule is a subset of the of the basic events occurring on that day. In the case of similar confidence, we look for the rule with the highest support.

TABLE I: DATASET D  Training Trade Code  Dat e  LTP High Low Close Price  Volume  100 3/1 1170 1188 1135 1140 445105  TABLE II: FREQUENT BASIC EVENTS  Description Alpha Support Number Binary high u A 42 0 10000000 high d B 55 1 01000000 low u C 48 2 00100000 low d D 50 3 00010000 closeprice u E 40 4 00001000 closeprice d F 57 5 00000100 volume u G 45 6 00000010 volume d H 55 7 00000001           TABLE III: FREQUENT TARGET EVENTS  Description Alpha Support Binary buy y 40 1 sell n 60 0  TABLE IV: 2-SEQUENCE CANDIDATES  Pattern Sequence Supp Count 10000000;0 A?U? 12 10000000;1 A?U 13 01000000;0 B?U? 22 0-10000000 U??A 13  1-10000000 U?A 12 0-01000000 U??B 21  TABLE V: A FRACTION OF THE FREQUENT SEQUENCES  Pattern Sequence Supp Cou nt  01010000;0 0-01000000;0 01000000;0-01000000 0-00100001  BD?U? U??B?U? B?U??B U??CH   0-01000001;0 01000000;0-01000000;0 0-00000010;0-01000000  U??BH?U? B?U??B?U? U??G?U??B   0-01000000;0-01000000;0  U? ?B?U??B?U? 13  TABLE VI: RULES PATTERN  Pattern Sequence Sup p  Cou nt  Conf  0-00000010;0 0-00010000;0 0-01010000;0 01000000;0-01000000;0 01000000;0-00000001;0 0-01000000;0-1000000;0  0-01000000;0- 00000001;0 1-10000000;1 0-01000000;0 0-10000000;0 1-00010000;1 1-00000001;1 0-01000001;0 00010000;0-01000000;0 0-00100000;0 0-00000001;0  U??G?U? U??D?U?  U??BD?U? B?U??B?U? B?U??H?U? U??B?U??B  ?U? U??B?U??H  ?U? U?A?U  U??B?U? U??A?U? U?D?U U?D?U  U??BH?U? D?U??B?U?  U??C?U? U??H?U?

IV. PERFORMANCE EVALUATIONS TABLE VII: TEST SET 1  TEST SET 1 trade code  star tdat e  end date  high low clos e pric e  Vol ume  sugg estio n  outc ome  100 19/1 20/1 u u u u sell sell 100 20/1 21/1 u u u u sell sell 100 21/1 24/1 u u u u sell sell 100 24/1 25/1 d u d d sell sell 100 25/1 26/1 s u d d sell sell 100 26/1 27/1 u u u u sell sell 100 27/1 28/1 u u d d buy sell  100 28/1 31/1 u d U u buy sell 100 31/1 1/2 u u U u buy sell 100 1/2/ 2/2 u u U d buy sell  Using the rules obtained (Table VI) the outcomes for the test data shown in table VII were generated. On comparing the results with the graph we can successfully infer the accuracy of the rules to be 60% (in this case). If we notice the graph for the month of January we notice that the small avg is lower than the long avg. So, we can clearly state that this would be a suitable ?sell? situation and our rules imply just that, but fail to identify the change or transition from the ?sell? state to the ?buy? state. Hence, the discrepancies are observed. The bolded outcome refers to an incorrect output.

Let us consider another test set presented in Table VII.

TABLE VIII: TEST SET 2  TEST SET 2 trade code  star tdat e  End date  hi gh  lo w  clos e pric e  Vol ume  sugg estio n  outco me  100 15/2 16/2 D d d u buy buy 100 16/2 17/2 D d d d buy buy 100 17/2 18/2 D d u d buy buy 100 18/2 22/2 U u d d buy buy 100 22/2 23/2 D d d d buy buy 100 23/2 24/2 D d d d sell buy 100 24/2 25/2 D s d u sell sell 100 25/2 28/2 D d d u sell sell 100 28/2 1/3 D d d d sell sell 100 1/3 2/3 D d s d sell sell  The suggestions made on the second test dataset were quite efficient in comparison to the first, the rules misjudged the outcome on 23rd of Feb (it was supposed to be ?sell?).

Thereby for the second test data we achieve an efficiency of 90%.



V. CONCLUSION The rules generated by our algorithm are accurate to a  certain extent compared to MACD approach. The rules suggest investors on the basis of prior data related to a particular stock. With the two test datasets used, we find accuracy of 60% and 90%, respectively. On an average the rules were found to be 70% accurate with tests conducted on various test datasets. Though the results are not 100% complied with the results found by MACD approach, we believe our current attempt reveals the importance of using and further investigating temporal and sequential pattern mining strategies on DSE. As a future work, we would like to test our algorithm with different timing windows rather than a fixed one and derive the rules that will change dynamically with respect to stock market behaviour.

