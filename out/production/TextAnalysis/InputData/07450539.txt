Improvement and research of FP-growth algorithm  based on distributed spark

Abstract?FP-growth algorithm as the representatives of non- pruning algorithms is widely used in mining transaction datasets.

But it is sensitive to the calculation and the scale of datasets.

When building FP-tree, the search operation as the major time- consuming operation has a higher complexity. And when the horizontal or vertical dimension of data set is larger, the mining efficiency will be reduced or even failed. To solve the above problems, reducing the complexity of search time and applying distributed computing are the widely used strategies. This paper presents a distributed SPFP algorithm based on Spark framework and improved FP-growth algorithm. The results of tests show that, compared to the PFP algorithm based on MapReduce, the OPFP algorithm based on Spark and original FP-growth algorithm, SPFP has high efficiency, cluster and flexibility.

Keywords?Frequent item sets; FP-growth; Spark; Complexity; Efficiency

I. INTRODUCTION Association rule reflects the connections and dependence  between things. The mining of association rule [1], trying to find some hidden or interesting association rules in the data set. It is one of the important research directions in the field of data mining. FP-growth algorithm [2] is a no-pruning algorithm. The structured FP-tree is decomposed into several conditional model sub-trees, which corresponds to a frequent itemsets for each and these trees can be mined recursively to get frequent itemsets of transaction databases. But the algorithm still has many defects: First, when the horizontal or vertical dimension of a transaction is very large, which leads to the failure of frequent itemsets mining; second, building conditions pattern frequently makes the space complexity too high to fail; thirdly, the time complexity of scanning head table or FP-tree node is too high to reduce the efficiency. The open source distributed computing framework Spark designed by UC Berkeley AMP lab can be applied to data mining and machine learning or other required iterative algorithms. This paper proposes a distributed SPFP algorithm based on Spark to solve these problems.



II. RELATED WORK Many scholars proposed optimizations or improvements.

Literatures [8, 9] mentioned to decompose original database to support mining. But it can?t realize the parallelization, when  the transaction chains are too large to be loaded in RAM.

Literatures [11, 12] constructed schema matrix to mining frequent item sets. But it will be failed when the matrix can?t fix in the memory. Literature [7] proposed to use MFP tree replace FP- tree to reduce scanning times. But it produced a large number of candidate items. Literatures [3, 8] proposed different ways based on MapReduce. Most were based on the thought of PFP.

But PFP algorithm has a serious disadvantage that is operating transaction data between different places. The scalability of PFP algorithm is low.

In summary, in the environment of big data, these ways are still not good enough. This paper presents a SPFP algorithm. It can reduce time complexity by optimizing header table and data structure, supports fine-grained local data by Spark, improves the operational efficiency. The paper uses UCI and Frequent ItemSet Mining DataSet Repository datasets to test.

Results show that, SPFP algorithm is more effective.



III. ANALYSIS AND IMPROVEMENT OF FP-GROWTH When constructing FP-tree, insert a transaction each time  should sort transactions according to the items in the head table.

The time complexity is O (n2). And the projects compare with sub-nodes in turn. For these limitations, it gives a new revised algorithm-IFP. Uses transactional database D in Table I  TABLE I        TRANSACTIONAL DATABASE D  TID  Original Itemsets Sorted Itemsets  T1 f, a, c, d, g, i, m, p f, c, a, m, p  T2 a, b, c, f, l, m, o f, c, a, b, m  T3 b, f , h , j , o f, b  T4 b, c, k, s, p c, b, p  T5 a, f, c, e, l, p, m, n f, c, a, m, p  The most right column of data has sorted, which is according to the frequency of items appearing in the entire database. The threshold is 3 (less than 3 will be excluded). FP- growth algorithm uses two data structures: Header Table and FP-tree. And the structure of Header Table affects the performance of FP-growth algorithm directly. This paper modifies the original data structure in Figure I (use the transaction database D in Table I as the sample data):   DOI 10.1109/CCBD.2015.15       FIGURE I MODIFIED DATA STRUCTURE OF HEADER TABLE  The reflected improvements show in the following aspects:  1) Change the original array into the one Array label shows. Alter the second element of original into Boolean type.

2) Add an element of HashMap type. Key is project name.

Value is a triple: first element is subscript of project name; the second is the address of head pointer of node chain, the third is of tail pointer.

3) Add an indicator variable as Flag tag shows. It is used to identify whether the corresponding FP-tree is a single path.

In the space complexity, assuming the unit storage is 1, the number of projects is m. The capacity of the left figure occupies 2m, while the right is 6m+1, three times than before.

But m is small usually, so the improvement is acceptable.

In the time complexity, assume that a transaction contains k elements, according to the left figure, the sorting times are k m? .

In the worst case, the searching time is m, the comparing time is m m? , and the total complexity time is 2(( ) ) ( )O k m m O m? ? ? .

In the right figure, find the index of project when sorting and make the Boolean variable True. The time complexity is ( )O k .

In worst case, the time complexity is ( )O m  insert it into the FP- tree. Traversal Value data to determine whether the head and tag of the chain are coincident. The time complexity is ( )O m .

Totally, the time complexity is ( ) ( ) ( ) ( )O k O m O m O m? ? ? .

Similarly, this paper modifies the structure of FP-tree in Figure II(use transaction database D in Table I as example):    FIGURE II MODIFIED DATA STRUCTURE OF FP-TREE  Before, the time complexity of searching the child node list is ( )O m . Now, the paper modifies every child nodes to a HashMap type. The time complexity becomes (1)O .

The time complexity reduced 3( )O m to ( )O m , so the improved structure can advance the efficiency.

Recursion needs to complete switching context, so reducing the recursion can improve the efficiency. In the FP-growth algorithm, if the flag ?flag? is true in figure I, this FP-tree will be a single path tree and can get frequent items through permutations and combinations without recursive operations.

From the improvements of FP-growth algorithm above, the improvements of data structure reduce the time complexity and the judgments of a single path reduce the cost of space-time, which results from recursive operation. For the following description, this paper named the improved algorithm as IPF.



IV. RESEARCH OF SPFP ALGORITHM When compressing the whole date base into FP-tree can  cause memory out. So put IPF algorithm run in a distributed environment. Operate the distributed data fragmentations and combine partial frequent item sets to do the global pre-pruning.

It improves the efficiency of data analysis and solves the large amounts of data efficiently that single computer can?t handle.

This paper uses "Move- algorithm" to parallelize the IPF algorithm--SPFP. To improve the performance, make IPF algorithm run in the data node and divide the operation of calculating frequent items into the following two phases:  1) Produce local frequent item sets. Run IFP algorithm in m nodes in a distributed cluster, and obtain local frequent item sets for each node.

2) Build the global candidate sets. According to Spark operator to collect and union all local frequent item sets as a candidate set, then distribute it into each node. Rebuild FP-tree based on node-data blocks, statistic the occurred times of each candidate. Based on times the set name merges and the minimum support min_sup to get global frequent item sets.

The first step of SPFP is to call IPF algorithm on each data; the second is to calculate the frequency of candidates on each     fragmentation. The paper builds FP-tree on each data node, and statistics the local frequency of item sets. The next describes the implementations of the frequency statistics that the major candidate frequent item sets appear in the local fragmentation.

Take the FP-tree in transaction database D of table I as example, assume that the collection of candidate sets have a candidate set, if find out all paths containing a = {c, p}, the effective paths are the marked part in red in Figure III:    FIGURE III EFFECTIVE QUERY PATH  Usually use traversal scheme from top to down. But it needs to coverage all nodes to determine the appearing times of ?  on the date block. Efficiency is lower. But according to the characteristics of FP-tree, each node has the only one parent node unless the root node. If use bottom-up approach, just make sure the smallest frequency project is p in ? . According to Header Table and p to locate all the nodes named p, and then do up search.

Take the left marked path in bold in Figure III as an example, the process is shown as the following in Figure IV:    FIGURE IV JUDGE THE FREQUENT ITEM SETS  The process of pattern matching can be converted to the longest common subsequence problem. So the time complexity of matching a candidate set and a path is (| | | |)O path? ? . | |? is the length of candidate set, | |path is the number of all the nodes, the time complexity is linear.

Use pseudo-code to describe process of SPFP as following:  Input: filePath of HDFS of D, minimum support ?min_sup? Output: global frequent itemsets ?L?; (1) Initializeval sc SparkContext?? ? ?? ; (2) .textFile( )val hadoopRDD sc filePath?? ? { (3) .mapPartition(val FIRDD hadoopRDD?? ? (4) {p???? ?? (5) FP- growth( )p??????  }) ; /* Use FP-growth algorithm to deal  with the data block p and get locally frequent item sets */ (6) .broadcast( )val bro FIRDD sc FIRDD to Local?? ? ? ?? ?? ; } /*Localize  FIRDD, eliminate duplicate elements, broadcast to each node */ (7) .mapPartition(val support item hadoopRDD?? ? ? (8) {p???? ?? (9)   get ( , ))Frequet p bro FIRDD???? ? /* Construct FP-tree to get  frequentness  of item sets */ (10) }) ; /* Complete the processing of fine-grained of local  data block */ (11) getFilter( , )val L support_item min_sup? ?? ?  /* Combined the  data and according to minimum support min_sup to filter the inappropriate sets to get the final data L */  (12) return L?? ; /* Get all global frequent item sets */

V. THE RESULTS AND EVALUATION To verify the effectiveness, this paper uses five computers  (Intel Core i5, CPU 2.4GHz, memory 2GB) consist distributed cluster of Spark environment. Parameters: Ubuntu14.04, Hadoop2.4.1, Spark1.2.0, Scala 2.10.4, JDK 7u55. One computer is the Master node, the others are Salve node. The test datasets are from the UCI a public database, or Frequent ItemSet Mining DataSet Reposito-ry [4].

Mushroom [5]. It describes the mushroom whether can be used or has toxic dataset through different attributes. The data set has 8124 data instances and 119 project values totally.

Accidents. It is the traffic accident statistics among 1991 to 2000 from the Flemish region of Belgium National Bureau of Statistics. It has 340,184 instances containing 572 attributes, per transaction contains 45 property values.

Average many values to eliminate errors to obtain the final results. These datasets use PFP, OPFP and SPFP. PFP is a parallelized FP-growth algorithm based on MapReduce while OPFP based on Spark. The results are shown in the following Figure V and Figure VI:    FIGURE V MUSHROOM MIN_SUP=35%       FIGURE VI ACCIDENTS MIN_SUP=20%  Through analysis, execution time and increasing copy number rise in positive correlation. PFP is the most obvious.

Because of the high latency, lack of support of the iterative nature and other shortcomings of MapReduce model.

Compared to SPFP and OPFP, the execution efficiency of PFP is lowest, almost 20 to 50 times longer than SPFP. SPFP is several times higher than OPFP with improved data structure.

To perform the scalability, this paper has the following experiment: maintain the support of dataset, the cluster node scale grows from 1 to 5, one is Master node, and the others are Salve nodes. Set the variable range of copy number from 0 to 5, the results are shown in Figure VII and Figure VIII    FIGURE VII MUSHROOM MIN_SUP=35%    FIGURE VIII ACCIDENTS MIN_SUP=20%  Through analysis, the running time declines while the nodes increase. It has a large decreasing amount when the node is less. With the nodes increasing, it almost decreases linearly and tends to be horizontal.

To sum up, the SPFP algorithm in this paper has higher efficiency than other algorithms and also has the very well scalability of data and cluster.



VI. SUMMARY AND FUTURE WORK This paper analyzes the shortages of FP-growth algorithm,  the traditional association rule mining. According to these shortages, the paper proposes the optimized schemes from the realization of the head table and FP-tree data structure and other angles. Submit a distributed algorithm in Spark environment?SPFP. Finally, it does experiment from date and cluster flexibility. The results prove that SPFP algorithm is an efficient frequent item set algorithm.

Based on the work, the next step will to consider how to apply the implemented algorithm to the practical problems and try to analyze the reality stock or basket data to find out the meaningful rules or relationships.

