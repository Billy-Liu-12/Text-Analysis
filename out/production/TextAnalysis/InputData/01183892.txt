Speed-up Iterative Frequent Itemset Mining with Constraint Changes

Abstract  Mining of frequenr iremsels is a fundamental dara mining rask. Pasr research has proposed m n y  efficient algorirhms for rhe purpose. Recent work also highlighred the imporrance of using consrrainrs Io focus rhe mining process ro mine only rhose relevanr itemsets. In pracrice, data mining is ofren an inrerocrive and irerative process.

The user rypicallv changes constraints and runs rhe mining algorirhm many rimes before sarisjed wirh rhe f i ~ l resulrs. This inreracrive process is very rime consuming.

Exisring mining olgorirhms are unable ro rake advanrage of rhis iterative process lo use previous mining resulrs ro speed up rhe currenr mining process. This resulrs in enormous WaSre in rime and in compurarion. In rhis papsr.

we propose an efficient rechnique 10 urifize previous mining results ro improve rhe eficiency of currenr mining when consrrainrs ore changed. We firsr inrroduce the concepr of tree boundav ro summarize the useful informorion avoilable from previous mining. We rhen show rhar the free boundary provides an gffecrive and efficienr framework for rhe new mining. The proposed technique has been implemenred in the conrexrs of rwo existing frequent iremser mining algorirhms, FP-tree and Tree Projection. Erperimenr resulrs on horh syntheric and real- Ire darasers show rhnr rhe proposed approach achieves dromaric saving in compurarion.

1. Introduction  Frequent itemset mining plays an essential role in mining association rules 131, correlations, sequential patterns, maximal patterns [4], etc. Although many efficient algorithms 13, 16, 1, 91 have been developed, mining of frequent itemsets remains to be a time consuming process [IO], especially when the data size is large. To make the matter worse, in most practical applications, the user often needs to run the mining algorithm many times before satisfied with the final results. In each prxess, the user typically changes some parameters or constraints.

Considering a mining task with only the minimum supporr constraint (also called the frequency constraint), the user may initially set the minimum support lo 5% and  a mining algorithm. After inspecting the returned  0-7695-1754-4/02 $17.00 0 2002 IEEE 107  results, she finds that 5% i s  too high. S h e  then decides to reduce the minimum suppon to 3% and runs the algorithm again. Usually, this process is repeated many times before s h e  is satisfied with the final mining results.

This interactive and iterative mining process is very time consuming. Mining the dataset from scratch in each iteration is clearly inefficient because a large portion of the computation from previous mining is repeated in the new mining process. This results in enormous waste in computation and time. So far, limited work has been done to address this problem, and to the best of our knowledge there is still no effective and efficient solution.

In recent years, many constraints (apan from the traditional suppon and confidence constraints) are introduced into frequent itemset mining in order to find only those relevant itemsets [13, IO, 121. On one hand, these additional constraints give the user more freedom to express hisher preferences. On the other hand, however, it often prolongs the mining process because Ihe user may want to see the results of various combinations of constraint changes by running the mining algorithm more times. This makes mining using previous results for efficiency even more imponant.

Constraint changes can mean righrening consrrainrs and relaxing consrrainrs. Let us  use an example to start the discussion.

Example: Consider that one sets the constraint that the average price of the items in an itemset i s  less than $100 in the old mining process (for a market basket problem).

After inspecting the mining results, one finds that the results are not satisfactory. There are possible two reasons: (1) $100 is too low (many useful itemsets may not be discovered), and (2) $100 is  too high (too many itemsets are generated). One may wish to change the average price to $150 or to $80 for the new mining. The question is ?can we make use of the results from the old mining to speed up the new mining??  It is straightfonvard to answer pan of the question, i.e., when constraints are righzened (the solution space is reduced), e.g., when the average price of frequent itemsets is decreased. To obtain the new set of frequent itemsets under the new constraints, we can simply check the frequent itemsets from the old mining to filter out those itemsets that do not satisfy the new constraints. This filtering process i s  sufficient because the set of new frequent itemsets is only a subset of the old set.

When constraints are relared (the solution space is    expanded), the problem becomes non-trivial as re-running the mining algorithm is needed to find those additional frequent itemsets. For instance, in the above example, when the average price of frequent itemsets is increased, more itemsets may be generated. The problem becomes even more complicated when multiple constraints are changed at the same time. The objective of this work is to study how to make use of the previous mining results to speed up re-mining when constraints are changed.

In this paper, we propose a novel technique to solve this problem: Using the relaxation of frequency constraint (the decrease of minimum support) as an example, we first propose the concept of free bounday  to summarize and to reorganize the previous mining results. We then show that the additional frequent itemsets can be generated in the new mining process by extending only the itemsets on the free boundav  without re-generating the frequent itemsets produced in the previous mining (note that our tree boundary based technique is quite different from the incremental mining approaches based on negative border).

The proposed technique has been implemented in the contexts of two frequent itemset mining algorithms. FP- tree 191 and Tree Projection [I]. This results in two augmented itemset mining algorithms RM-FP (re-mining using FP-tree) and RM-TP (re-mining using Tree Projection). Extensive experiments on both synthetic data and real-life data show that RM-FP and RM-TP dramatically outperform FP-tree and Tree Projection algorithm respectively. Finally, we also address how the proposed technique can be applied to handle the changes of other types of constraints given in previous studies [ 13, 10. 121.

2. Related work  Frequent itemset mining has been studied extensively in the past e.g. in [3, 16, 1.9, 15, 4.51. Most current algorithms are variations of the Apriori algorithm 131. They use support-based generate-and-test approach to find all the frequent itemsets. Recently. some tree-based algorithms were also proposed. e.g., the FP-tree algorithm 191. which is based on the frequent pattern tree. and Tree Projection algorithm [I], which is based on the lexicographic tree.

Both algorithms do not strictly follow the Apriori-like candidate generate-and-test approach and were shown to be more efficient than the Apriori algorithm [3].

Since [ I31 first introduced item constraints to produce only those useful itemsets, many other types of constraints have been integrated into itemset mining algorithms [ I O , 121. Although many efficient algorithms for mining frequent itemsets with constraints exist, user interaction is at the minimum level. To remedy this situation, [ IO] proposes to establish breakpoints in the mining process to accept user feedback to guide the mining. Furthermore, online association rule mining also allows the user to  increase minimum suppon during the mining process 121.

However. 121 does not allow decreasing of minimum support. Similarly, the suppon threshold used in [ I l l  for incremental and interactive sequence pattern mining can also be increased but not decreased.

The closely related work to ours is the incremental mining, where the concept of negative border (proposed in [I611 is utilized to update the mining results when additional data becomes available [14. 15, 8. I l l .  A negative border consists of all the itemsets that are candidates of the Apriori algorithm that do not have sufficient support. Although the methods in [14, 15. 81 only need one scan of the updated dataset, they could not avoid the disadvantage of negative border, i.e.. maintaining a negative border is very memory consuming and is not well adapted for very large databases [ I  I].

The approach in [14. 15, 81 seemingly can be adapted for handling constraint relaxation. [ 151 actually mentions the possibility but no detailed algorithm is proposed.

However, one significant shortcoming of the approach is that generating candidates under new constraints using the negative border under old constraints usually result in over-generation of a huge number of useless candidates.

This makes the approach in [ 14, 15. 81 impractical for our constraint relaxation problem for large datasets, especially when the minimum support is low. For example, i f  10? frequent itemsets are obtained given minimum support of 1% and 50 I-itemsets become frequent after minimum support is reduced to 0.9%. the number of candidate itemsets generated using the above approach is (2s0-l)*105 = 10? even if we do not consider the expansions of I@ frequent itemsets themselves. This is clearly impractical.

FUP in 161 is another incremental mining method that follows the Apriori framework. FW is not for mining with constraint changes. If it is applied to our task, it basically re-runs the Apriori algorithm without re-counting the supports of those itemsets generated previously (they still need to be re-generated). The computation saving is thus very limited, if any, because of some overheads (see [7] for more details).

3. Problem statement  Let I be the set of all items, and r be a transaction database. Each transaction in r consists of a subset of items in 1. Let S (r 0 be an itemset. The supporl of S (denoted by Supporr(S)) is defined as in [31. Given a minimum support MinSup. an itemset S is frequenl in r i f Supporr(S) 2 MinSup. With a transaction set r and a MinSup, the problem of frequenl ilemsel mining is to find the complete set of frequent itemsets in C  Constraints can be imposed on both itemset S itself and its attributes (e.g.. price,  type, etc) in frequent itemset mining. There are many types of constraints that can be imposed on frequent itemset mining. Four categories of     constraints: anti-monotone, monotone, succinct, and convertible constraints have been effectively integrated into some mining algorithms [ IO .  121.

Iterative mining of frequent iternsets with constrain; changes: Given a transaction database K the whole process of iterative (and interactive) mining of frequent ilemsels with constraint changes is captured with the following iterative steps:  ( I ) (2) run the mining algorithm (3)  specify the initial set of constraints SC.

check the returned results to determine whether they are satisfactory. If so, the mining process ends.

Otherwise, the user changes one or more constraints in SC (including deletion and addition of constraints). and the process then goes to ( 2 ) .

( I )  and (3) will not be discussed further in the paper as it is the user?s responsibility to devise and to change constraints. Our objective is to design a framework for the mining algorithm i n  (2) so that it is able to leverage on the mining results from the previous mining iteration to improve the efficiency of the current mining, and consequently speed up the whole data mining process.

Conslrainl changes: Change of a constraint includes two cases:  (1) Tighten the constraint: The solution space is reduced. For example, when the minimum support is increased.

(2) Relax the constraint: The solution space is expanded. For example, the minimum suppon is decreased.

Constrain1 changes mean changes to one or several constraints in a set of predefined constraints. The changes cover deletion or addition of constraints. Adding a new constraint corresponds to tightening the constraint. while deleting an existing constraint corresponds to relaxing the constraint.

As discussed earlier. if a constraint C i s  tightened to C: the set of itemsets that satisfy the new constraint C?is only a subset of the itemsets that satisfy the old constraint C.

Thus, the set of itemsets that satisfy C?can be obtained by filtering the set of itemsets that satisfy C. The challenge comes when a constraint C is relaxed to C: The set of itemsets that satisfy the old constraint C i s  only a subset of ihe itemsets that satisfy the new constraint C! The problem is how to efficiently discover the set of itemsets F, that satisfy the new constraint C?but not the old constraint C.

The rest of the paper focuses on this problem. We also study how to utilize the previous mining results to efficiently discover the set of itemsets when multiple constraints are changed at the same time.

4. The proposed technique  We use the minimum support constraint as an example t o  present the proposed technique for finding the set of itemsets F. that satisfy the new but not the old minimum  support when the minimum support is reduced (relaxed) from one mining process to the next. The relaxation problems of the other constraints can be solved within the proposed framework (to be discussed in Section 7).

although the technical details may vary.

Let MinSup,, be the minimum support used in the previous (or old) mining, and MinSup,, be the relaxed (or new) minimum suppon. This section first introduces the useful information that can be obtained from the previous mining process using a tree-based itemset mining framework. The reason that we use a tree-based framework will become clear later. We then describe a method to represent the old information for the purpose of mining under MinSup.,,. Next, we present a nayve approach and the proposed technique for discovering the set of itemsets F. that are frequent under MinSup.,, but not MinSup,~d.

4.1. Useful information from previous mining  After running a mining algorithm using MinSup,,,~, we find the set of frequent itemsets. One byproduct of the process is the set of itemsets that are checked against MinSupOld (supports are counted) but are not frequent. Let 4 be the set of frequent itemsets under MinSup,,,,,, and Lg be the set of itemsets that are counted, but found infrequent (the byproduct). Although all frequent itemset mining algorithms generate the same set 4, the set of infrequent itemsets L6 checked in the process varies according to algorithms.

Algorithms, such as those in [4, 1 .  91, do not strictly follow the candidate generation of Apriori-like algorithms [3, 16, IO]. Instead, they are based on some kinds of tree.

We classify these algorithms as tree-based algorithms.

Tree-based algorithms will count the support of an itemset S = [ i , ,  i2. ..., i k )  if two proper subsets of S, namely S, = ( i , ,  ..., ik.2,ik.,J a n d & =  [i, ,... ,ib2.ill.arefrequent.

We use tree-based mining algorithms as the underlying mining framework of our proposed technique because tree- based mining algorithms give us sufficient information, while Apriori-like algorithms do not (see the end of the Section). [1,9] also show that tree-based algorithms are actually more efficient in many cases.

As in [I] ,  we use a lexicographic tree to represent the set of frequent itemsets 4. Given the set of items I, it is assumed that a lexicographic order R exists among the items in 1. The order R is important for efficiency and for the organization of mining results. We use the notation i CL j to denote that item i occurs lexicographically earlier than j .

Definition 4.1 (Lexicographic Tree) A node in a lexicographic tree corresponds to a frequent itemset. The root of the tree corresponds to  the null itemset.

We extend Definition 4.1 to also represent those itemsets in Lf with a lexicogaphic tree. An example lexicographic tree is shown in Figure 1 .  Those nodes enclosed in circles are frequent itemsets under MinSup.,     but not MinSupOu, which ate in F,. Those nodes enclosed by dotted squares are the itemsets in L, that are not frequent under either MinSupOu or MinSup.,. The other nodes are itemsets that are frequent under both MinSup,u and MinSup.,. Let P and Q be two itemsets and Q be the parent of P.

Definition 4.2 (Tree Extensions) A frequent I - extension of an itemset such that the last item is the contributor to the extension is called a tree extension. The list of tree extensions of a node P is denoted by E(P).

Figure 1. A lexicographic tree In Figure 1. under MinSupou, the list of tree extensions  of node 3 E(3) = <4,6>.

Delinition 4.3 (Candidate Extensions) The list of  candidate extensions of a node P is defined to be those items in E ( Q )  that occur lexicographically after the node P.

We denote the list by C(P) .  Note that E(P)  is a subset of C P ) .

Items in C(P) are possible frequent extensions of P.

Under MinSup,,,,, the tree extensions of null node E(nul1) = c3.4. 5 .  6.7, (note that 2 is not frequent under MinSup,,d).

and the candidate extensions of node 3 C(3) = <4,5,6,7>.

4.2. Extensions of lexicographic tree  This subsection extends the lexicographic tree with some new conceptions. which will be used in our proposed technique.

Definition 4.4 (Infrequent Borders) If a I-extension i of iternset P i s  not frequent, i is called an infrequent border.

The list of infrequent borders of a node P is denoted by IB(P) .  We have the relationship: IB(P) = C(P)  - E(P).

In Figure I ,  under MinSupou, the infrequent borders of node 3 /R(3) = <5,7>.

Definition 4.5 (New Tree Extensions) If itemset P U ( i ) ,  i E /B(P),  becomes frequent after MinSup is reduced from MinSup,, to MinSup . ,  i is called a new tree extension of node P w.r.1. MinSup,,,. The list of new tree extensions of node P W.T.I. MinSup.,, is denoted by NTE(P).

In Fiaure I ,  the list of new tree extensions of node 3 - w.r.1. MinSup,,,NTE(3) = <5,7>.

For any frequent itemset P (can be null) under MinSup, ,  its tree exfernions E(P) and infrequenf borders /R(P) are stored for mining under MinSup.,. Its new tree extensions NTE(P) w.r.1. MinSup., can be obtained by checking the list of infrequent borders of P, / B ( P ) .  Under MinSupOu, the set of tree exlensions of all frequent tree nodes makes up 4 and the set of infrequent borders of all frequent nodes in the tree makes up Lw  4.3. A naive approach  With the two sets 4 and Lb from the mining under MinSup,u, we first look at a naive approach to making use of previous mining results for the new mining. We then present the proposed approach based on tree boundary.

The naive approach checks all itemsets in L,and Lfone by one to find the change of their candidate extensions under MinSup,,, and to extend them to obtain the complete set F. (in which itemsets are frequent under MinSup,,, hut not MinSup.,). Figure 2(a) shows the children itemsets of null node and the children itemsets of itemset ( 3 )  in the naive approach. To make the figure manageable, we assume that itemset (3, 8 )  is frequent under MinSup.,, but (4, 81, ( 5 ,  8), (6.81, and (7,8) are not. Candidate extensions of each node are shown under the node in Figure 2(a). The only saving in the new mining is that we can utilize the count information saved previously for those itemsets in b a n d  Lv  However, this saving in computation is very limited in a tree-based algorithm. Thus, the computation is basically the same as re-mining from scratch. In tree-based algorithms, the main computation co'lres from the generation of projected transactions for each node. Project transactions for an itemset S are the set of transactions containing S. Tree-based algorithms use this sub- transaction set for counting support and for all subsequent itemset (containing S) generations. This naive approach still requires the same computation to generate the projected transactions as running a tree-based algorithm from scratch. For instance in Figure 2(a), we still need to create projected transactions for ( 3 )  to count the support for itemset (3, 8 )  although the supports of its other children itemsets (3. 4) ,  (3. 51, (3, 6 )  and (3, 7 )  are known previously (the projected transactions for ( 3 )  are also used to generate the projected transactions for children itemsets of 13)). Similar computation is required for creating projected transactions for (21, (3). (41, (51, (6) and (7).

Another shortcoming of the naive approach is that it cannot avoid re-generating itemsets in I!, because they need to be extended in the new mining. For example, in Figure 2(a), itemsets (3) .  (4). ( 5 ) ,  (6) and ( 7 )  still need to be generated to check whether item 8 is in  their tree extensions although their supports are already counted in previous mining.

(a) The naive approach (b) Our approach with lreeboundary Figure 2. Pam of mining results under  MinSup,,  Based on the above discussion, we see that saving by the naive approach is limited. It is thus not efficient.

4.4. The proposed approach  Definition 4.6 (Tree Boundary) A tree boundaly w.r.r.

MinSup,,, is defined to be the set of itemsets TB = (rb I rb E Lg, Supporr(rb) 5 MinSup.,,). where Lg is the set of counted but infrequent itemsets under MinSup,,d, and Supporr(rb) is the supporr of itemset fb .

For example, the itemsets on the dotted line shown in Figure I make up the free boundary w.r.1. MinSup.,.

Itemsets ( I ]  and (3, 4, 6 )  are not in TB although they are in Lf because they are not frequent under MinSup.,,.

Our proposed approach discovers the complete se1 of F, by extending only the itemsets on the free boundary. The basic idea is to eliminate the effect of MinSup decrease on itemsets in L,, i.e., no itemset will he extended i f  i t  has been extended in previous mining. This is achieved by changing the order of rree exrensions of every node (including the null node) in L,(under MinSup,,d).

Let S, be null node or any itemset in Lp Tree extensions of S, under MinSup,,., denoted by E.&). contains two parts:  tree extensions of S, under MinSupOM, EoIASp).

e.g., EOld(3) = <4,6>, and  new tree extensions of S, ( w . T . ~ .  MinSup,,,), NTE(S,), e.g.. hTE(3) = <5.7>.

We change the item order of E.,(S,) as follows: move items from the new tree extensions, hTE(S,,), to the front of the (old) tree extensions of S, under MinSupOl, Eo&,).

For example, in Figure I ,  we change the tree extensions of null under MinSup,,, from 4, 3 , 4 , 5 ,  6 .7 .8> to <2, 8. 3, 4 ,5 ,6 .7>.

With the new ordering, for a child itemset of S, such that S, = S, U (i l ,  where i E E&,SJ (S, E 4). the candidare exlensions of S, are the same under MinSup,, and MinSup,,,,. For a child itemset of S, such that S, = Sou ( ( 1 ,  where i E hTE(S,), the candidare exrensions of S, consists o f :  ( I )  those items j such that i S j ,  where j E hTE(S,),  and (2) those items j .  j E E.,&,).

Due to the re-ordering. candidate extensions of the  itemsets in L, are not affected. For instance, after we change the tree extensions of null node under MinSup., into <2, 8, 3, 4, 5.  6, 7>, the tree extensions of itemsets (31, (41, (51, (61 and ( 7 )  under MinSup.,, are the same with those under MinSup,,d. The tree extensions of itemset (8) become <3. 4, 5, 6, 7> from 0 under MinSup,,. We compute the projected transactions for itemset ( 8 )  to decide whether items 3 ,4 ,5 ,6 ,  and 7 are tree extensions of (81. There is no need to compute projected transactions for (31, (41, (51, ( 6 )  and (71 (they were computed in previous mining).

Another example is given in Figure 2(b), which shows the corresponding pan of Figure 2(a) in our approach.

After we change the order of tme exieiisions of null node, there is no need to extend itemsets (3) ,  (41, ( 5 ) .  ( 6 )  and (71 with 8. We change tree extensions of itemset ( 3 )  from <4, 5 ,  6, 7> to <5, 7, 4, 6>. The candidate extensions of node (3. 5 )  are <4, 6, 7>. The candidate extensions of node 13, 71 are <4, 6>. As a result, we only need to compute projected transactions for itemsets (3, 5 1 and (3, 7 )  (which are not computed in previous mining) while the naive approach needs to compute projected transactions for itemsets (3,41, (3.51, (3 .61 and (3.7) .

Notice that those itemsets on the rree boundary whose candidate extensions are empty can be removed from the free boundary, e.g., itemsee (4 ,5 ,7]  and (5 .7)  in Figure 1.

Let us summarize the advantages of our free boundary based extension with ordering change.

I )  Our approach is able to avoid the computation of counting the suppons of itemsets in 4 and L? We do not re-generate the itemsets in L, to extend them in,the new mining process.

2) Our approach is able to avoid the generation of projected transactions that were done in previous mining while the naive approach is unable to.

The ordering change is the key of our technique. It also brings some additional benefits when integrating tree- based algorithms with free boundary. Refer to [7].

Now, let us prove the correctness and completeness of free boundary approach.

Property 4.1 Given free boundary TB w.r.f. MinSup.,, extending the itemsets in TB is able to generate the complete set of itemsets F. (frequent under MinSup.,, but not MinSupOld).

Interested readers can refer to [7] for proof.

Remark: In Apriori-like algorithms, previous mining  results under MinSup,, do not provide sufficient information to build the free boundary for re-mining under MinSup,, Moreover, even i f  we could build a free boundary, Apriori-like algorithms could not be easily modified to extend itemsels on free boundary to discover F,,.

Interested readen can refer to (71 for proof.

5. Tree boundary based re-mining  We realized the proposed technique using the FP-tree frequent itemset mining and the Tree Projection algorithms. The algorithm using FP-tree is called Re- Mining using FP-tree (in short RM-FP), and the algorithm using Tree Projection is called RM-TP (Re-Mining using Tree Projection). Interested readers can refer to [7] for the algorithms RM-FP and RM-TP.

6. Experimental evaluation  This section presents performance comparison of FP- tree algorithm with RM-FP on both synthetic and real-life data sets. The comparison of Tree Projection algorithm with RM-TP achieves similar results, and is given in 171.

All experiments are performed on a 750-Mhz Pentium PC with 512 MB main memory, running on Microsoft Windows 2000. All the programs are written i n  Microsoft Visual C++ 6.0.

The synthetic datasets were generated using the procedure described in [31. We repori experiments results on two synthetic datasets: One is T25.120.DZOOk 191 with I K  items, which is denoted as D1. In D1, the average transaction size and the average maximal potentially frequent itemset size are 25 and 20 respectively. The number of transactions is 2M)k. The other dataset is T20.16.DIOOk [3] also with IK  items, denoted as D2.

We also tested our approaches on two real-life datasets obtained from the UC-lrvine Machine Learning Database R e p o s i t o r y ( h n p : I l w w w i c s u c i . e d u / - m l e a m l M 1 ). One is the Connecr-4 dataset the other is the Mushroom dataset.

Figures 3 and 5 show the comparisons of RM-FP with F?-tree algorithm on datasets DI and Connect-4. In the curves for RM-FP, the CPU time for each point (except the first point) is obtained by running RM-FP (with the value of that point as MinSup.,,) based on the previous mining results under MinSupou just before that point. For example in Figure 3, the CPU time of RM-FP at MinSup.., = 1.75% is based on the old mining results with MinSupOl,, = 2%.

and the CPU time for RM-FP at Midup., = 1.5% is  based on the old mining results with MinSup,,,I = 1.75%.

and so on. Note that when MinSup.,, of RM-FP i s  the same as MinSupOld of the previous mining, e.g.. at MinSup = 2% in Figure 3, the extra running time of RM-FP against FP-tree shows the overhead of RM-FP to output itemsets in 4 The time is very small as shown in Figures 3-9. The results on D2 and Mushroom are not shown due to space limitations. Actually, readers can see them based on Figures 7 and 9.

From Figures 3 and 5 ,  we observe that RM-FP is able to save more than 40% running time of FP-tree in each iteration. The saving is very significant in practice. In fact, RM-FP can achieve even better results if the decrease of MinSup is smaller in each iteration as shown in Figure 4.

In Figure 4,  the MinSup is reduced by 10% each time (the decrease is smaller than that in Figures 3 and 5). At each point, again RM-FP is run based on the mining results of the previous point except for 2%. In each iteration, we can save more than 70% of the running time.

More performance curves on datasets DI,  D2.

Mushroom and Connecr-4 are given in Figure 6, 7, 8 and 9 respectively. In Figure 6, RM-FP was run based on the initial mining results of the FP-tree algorithm with MinSupOm = 2%. 1.5% and 0.75%. In each case, a few decreased MinSup,,, values are used. In Figure 7, RM-FP was run based on the mining results of MinSup,,,,, = 2%.

I% and 0.5%. In Figure 8, RM-FP was N n  based on the mining results of MinSup,,, = 60%. 50%. and 45% (we use very high minimum suppon because the dataset is very dense). In Figure 9, RM-FP was mn based on the mining results at MinSupOld = 2%. I%. and 0.5%. In each of these figures, we show results with different MinSup,,,, values.

All the experiments show that RM-FP consistently outperfoms the FP-tree algorithm even when MinSup drops to a very low level from a very high level. Using the same initial (old) mining results, we observe that the lower the MinSup,,, is in the new mining, the smaller is the percentage of saving in computation. This is clear because the number of frequent itemsets at MinSup,,,, is much larger than the number of itemsets in L,from old mining.

For example, for D2, the discovered frequent itemsets at 2% is 381 while the number at 0.15% is 558.834.

However, in practice, the user typically will not reduce the MinSup so drastically from one mining process to the next.

For example, in most cases, it is quite unlikely that the user uses MinSup,,,, = 2% first, and then changes i t  to MinSup,,, = 0.15% suddenly for the next mining. Instead, the decrease each time is usually small as in the cases of Figures 3.4, and 5.

Note that in Figure 9, RM-FP based on I% support takes more time than RM-FP based on 2% support at MinSup.,, = 0.75%. This is because the time used to check previous mining results offsets pan of the benefit from utilizing previous mining results when the previous mining results are very large.

..

him F  E:  20 !

i !

I O *  ,.I 1 0.71 0.5 0.3, 0.2 0.1  The scalability experiments are conducted by increasing the number of transactions on dataset DI.  As shown in Figure IO, both FP-tree and RM-FP have linear scalability with the number of transactions, but RM-FP is more scalable.

7. Application to other constraints  This section shows that the proposed approach is also applicable to discovering the set F. when any other single or multiple constraints are changed. The detailed techniques for handing changes of these constraints differ.

We only present methods for dealinn with the channe of  7.1. Dealing with Individual Constraint Changes  We discuss the methods for discovering the set F,, when a single constraint is changed.

Method 1: Filtering previous mining results  The set F, can be obtained by filtering previous results in the following two cases: ( I )  tightening of a constraint of any kind; (2) relaxation of a convertible monotone or monotone constraint.

Method 2: Tree boundary based re-mining  This method as discussed in Section 4 applies to the relaxation of a convertible anti-monotone or anti- monotone constraint although it is a bit different when  individuai constraints and multiple c k a i n t s  intuitl'vely.

Interested readers may refer to our technical report [7] for additional details and examples.

applying 10 anti-monotone c&traint relaxation due to the special property of convertible constraints [7].

Method 3: Simpler tree boundary based re-mining  Tree boundav in this method is easier to devise than     that for Method 2 and usually contains only I-itemsets. It applies to the relaxation of a succinct and anti-monotone constraint. or a succinct and monotone constraint. When one of such constraints is relaxed, it can be dealt with as follows: Let E(nul1) be the list of frequent items that satisfy the old constraint. By checking the old mining results, we first find the list of frequent items NTE(nul1) that satisfy the new constraint hut not the old constraint.

Itemsets made of individual items in NTE(nul1) make up the tree boundary.

Table 1. Handling the change of two combined constraints  7.2. Dealing with multiple constraint changes  Although users usually change one constraint at a time to see the effect of the change. it is also possible that multiple constraints are changed at the same time. Table 1 shows the methods for discovering . F,, when two constraints are changed at the same time. Most of the combined cases can be handled by combining the approaches to handling the change of individual constraints. For example, tightening a succinct & anti- monotone constraint and relaxing a succinct & monotone constraint requires Method I (handling the tightening) and 3 (handling the relaxation). Interested readers can refer to [7] for the meanings of those exceptional cases including ?Adapted, ?Violates?, ?Depends? and ?-?.

Finally, when more than two constraints are changed at the same time, they can be handled by combining the methods for their respective changes in consideration of the exceptional cases in table I .

8. Conclusions  Practical data mining is often a highly interactive and  iterative process. Users change constraints and tun the mining algorithm many times before satisfied with the final results. Current mining algorithms are unable to take advantage of the previous mining results to speed up the new mining process. Motivated by this problem and using the minimum support constraint as an example, this paper first proposed the concept of tree boundary to  summarize and reorganize the previous mining results. It then presents an effective and efficient framework for re-mining under the reduced minimum suppon. Experiment results demonstrate that the proposed technique is highly effective. Finally, we also show that when any other individual constraint i s  changed or multiple constraints are changed at the same time, the new set of frequent itemsets can also he mined efficiently using the proposed technique.

