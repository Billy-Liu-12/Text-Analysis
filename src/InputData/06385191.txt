An Algorithm for Predicting Frequent Patterns over Data Streams Based on  Associated Matrix

Abstract?With the wide application of data mining, many data mining applications need to use past and current data to predict the future state of the data. In view of this situation, we propose a new method, namely AMFP-Stream, for predicting frequent patterns over data streams efficiently and effectively. AMFP- Stream algorithm can predict those frequent itemsets that have high potential to become frequent in the subsequent time windows to meet users? needs. Firstly, the algorithm converts the data to 0-1 matrix. Then it will update the associated matrix by tailoring the matrix and bitting operations, from which frequent itemsets can be mined as well. Finally, it will predict possible frequent itemsets that may appear in the windows next time by using the current data. Experimental results show that AMFP- Stream algorithm can predict the frequent itemsets in different experimental conditions; therefore, the algorithm is feasible.

Keywords?frequent itemsets; Data stream; Data mining; Associated matrix; Predict

I. INTRODUCTION With the expanding field of data stream applications, data  stream mining has become a hot research topic. There?re varieties of data stream min ing algorithms, including multi- stream and single data stream mining. [1-4]. The main task of multiple data stream mining is analyzing the relationship between the parallel data stream and association rules. The main function of data stream mining includes  classification of data streams [5], clustering [6], frequent pattern min ing [7]  and outlier analysis [8].Among them, frequent pattern mining of data streams plays an important role in business decision- making and knowledge base application.

In the course of the study of frequent pattern mining of data streams, many researchers put forward their own algorithms.

[11].However, these algorithms mainly aim to analyze the current data, and few predict the trend of the data stream, which are difficult to meet actual application requirements such as flood forecasts, stock analysis  ,and so on. In summary, this paper proposes the associated matrix-based algorithm for predicting frequent patterns over data streams . Compared to current frequent pattern min ing algorithms, the algorithm we proposed can not only mine frequent patterns in the current time windows, but also predict frequent pattern from the next time window effectively.



II. RELATED WORK Definition 1.Frequent Itemsets.

Let X be a set of items ??? s)sup(X  (s user-defined  minimum support number in the range [0,1]), X is called a frequent item sets.

Definition 2. Frequent k-item sets.

Frequent k-itemsets contains frequent itemsets of k items is  called a frequent k-itemsets.

Definition 3.Associated Matrix.

Associated matrix  matrix Aij is recorded :Where A0j(1?j?n)  1-itemsets, Ai0(1?i?(m+1)) the number of items contained in the transaction Ti, A(m+1)k(1?k?n)the corresponding column 1- set the number of support.

? ? ? ? ? ?nmmm  iniii  n  ij  AAA  AAAA  AAA  A       ???  ?  ?  ??  ?  ??  ?  1.If the itemset {x1,x2,?,xk} is a frequent k-itemsets, then all nonempty sets are also frequent.

2.Let Xk be a frequent k -itemsets, the number of items is less than k of affairs can?t generate k-item sets.

3.Let Xk be a frequent k-item sets in the window, the number is less than k item sets cannot produce k-item sets.



III. PREDICTION ALGORITHM The process of frequent itemsets  mining is divided into the  following three steps by frequent item sets update-algorithm based on the data flow of the associated matrix: generate excavated associated matrix making use of transactional data; and then update the associated matrix, delete the associated matrix which can?t generating the frequent itemsets rows and columns, and mine frequent itemsets taking advantage of the updated associated matrix; pred ict the frequent itemsets that may arise after the window slides which have been made use of the current window data.

2012 Ninth Web Information Systems and Applications Conference  DOI 10.1109/WISA.2012.40     A. Generator associated matrix At first, the data is converted to 0-1 associated matrix. If the  current window size N = 4, the supported the minimum number min_ sup=3, mining W1 data shown in Table I.

Table I: Transaction data  Mining results are six 1-itemsets of a, b, c, d, e , g. Generate associated matrix using definit ion 3. In the associated matrix, A0j(1?j?n) stores all the 1-itemsets; A5j(1?j?n) stores the number of support corresponding to column 1-itemsets; Ai0(1?i?n) records the number of items in the corresponding line of the transaction; Aij(1?i?n, 1?j?n) records whether 1- itemsets exist or not in the corresponding transaction, if existing, the value will be 1; otherwise, the value will be 0.

0 gedcba  ADB ?  Algorithm 1 describes the process of the generation of associated matrix.

Algorithm 1 : The generation of associated matrix.

Input: A transaction data set Output: Associated matrix //str[][]store W1 data, a[][] memory associated matrix.

1: Initialize a[][] array of the 0.

2:a[0][1]=str[0][0]; 3: In order to judge each item of W1 ; 4: for(s=1;s<q;) 5:if(str[m][n]==a[0][s]){  a[m+1][s]=1; 6:a[m+1][0]++;   //Statistical Serv ice contains the number of  items; 7:a[t+1][s]++;  //Support the number of stored data plus 1;} 8:else{  if(a[0][s]==null) 9: a[0][s]=str[m][n]; //Storage 1-itemsets data;  10:else s++}  B. Associated matrix updates and frequent itemsets mining .

After associating matrix generation, updating the associated  matrix before min ing frequent itemsets ; delete non-frequent 1- itemsets and the items which less than k are described in the nature 2.Update associated matrix ADB obtained in the first window in Table 1, and mine frequent k-itemsets from corresponding associated matrix. Associated matrix updating process is shown in figure 1.

edc  A ?     edc  A ?     edc  A ?  Figure 1: Associated matrix transformations  In Figure 1, A1 means removing 1-itemsets of which the support number is less than 3, from which frequent 1-itemsets will be mined. A2 expresses the associated matrix in results of removing transaction which items number is less than 2; from which frequent 2-itemsets will be mined. A3 expresses the associated matrix in results of removing transaction which items number is less than 2; from which frequent 3-itemsets will be mined.

Algorithm 2 describes the process of the update of associated matrix.

Algorithm 2 : Update associated matrix.

Input: Associated matrix generated by the data set.

Output: The updated associated matrix and frequent  itemsets.

1:for(i=1;i<q;){ 2: if(Item set support data <min _sup){ 3:    for(m=1;m<t;m++){  if(a[m][i]==1) 4: a[m][0]=a[m][0]-1;}// Transaction contains the item  number -1 5:  delete J-th column; //remove non-frequent data  where the data associated matrix } 6:   else  i++; 7: for(s=1;s<=m;s++) 8:   if(a[s][0]<k){  if (a[s][m]==1) 9:       a[t+2-flag][m]--;// Itemsets support data -1 10: delete J-throw; }// According to Property 2, delete  the 0 in less than k rows of data Mine frequent k-itemsets from associated matrix Ak when  updating the associated matrix.  The corresponding associated matrix Ak stores 1-items that can generate k-itemsets, the generation of which is a combination of the corresponding associated matrix Ak. Combine 1-items and determine the support number to  get frequent k-itemsets. Shown in Figure 1, A1 generates the frequent 1 ? itemsets c, d, the e; A2 generates frequent 2 ? itemsets cd, ce, de; A3,a frequently 3 - itemsets cde.

Algorithm 3 describes the process of mining frequent item sets.

Algorithm 3: Mine frequent item sets.

Input: The updated associated matrix and frequent item sets.

Output: Frequent itemsets.

fun(flag, i, k, sflag,a[][],B[][]) 1: if(flag!=0){ 2:   for(m=k+1;m<q;m++){  i++; 3:       if(a[0][m]==0){} 4:        else{  for(s=0;s<k;s++) 5:     Generate k-itemsets and determine the supporting data.; 6:             if(flag+1==k){} 7:             else  fun();//Recursive call fun()}} 8: flag--;     9: fun();}//Recursive call fun () 10:else{  sflag++;i++; 11:    if(a[0][k]!=0) 12:   for(s=0,j=sflag+1;s<k,j<k+sflag+1;s++,j++) 13: B[i][s]=a[0][j];}  C. Frequent itemsets that may occur after the  mining window slides  Based on associated matrix generation and frequent itemsets mining algorithm, pred ict the frequent itemsets that may occur after the arrival of the new transaction making use of the current window data. The predict ion algorithm is divided into the following steps: Delete the o ldest transaction in the current window  before the arrival o f the new t ransaction. After window sliding, it will no longer affect the frequency of itemsets  Update window data is divided into two parts of the DB and db, Among  )()()( dbDBSupdbSupDBSup ??? Predict  the next window frequent itemsets in the data  set DB and db. If the itemsets in data db are frequent itemsets,they should meet )sup(min_)( dbdbSup ? ,when  ||)( dbdbSup ? , if the itemsets in data DB are frequent itemsets, they should meet  ||)(min_)sup(min_)( dbdbSupDBDBSup ?? .

Frequent itemsets should meet  in  the next  slid ing window:  ||)sup(min_)sup(min_2)()( dbDBdbdbSupDBSup ??? .

When the support s = 60%, sliding window N = 4, the data  in Table 1, for example, predict frequent item items in  W1 with W2 data.|DB|=3 min_sup(DB)=s ? |DB|=1.8 |db|=1 min_sup(db)=s ? |db|=0.6  Mine the itemsets which meet Sup(db)?0.6 in data items db to get the following frequent itemsets: c, d, e, g, cd, ce, cg, de, dg, eg, cde, cdg, deg, cdeg mine frequent itemsets in the data set db which meet Sup(DB)?1.8+0.6-1=1.4 in the data set DB to get the frequent itemsets: c, d, e, cd, ce, de ,cde; itemsets appearing frequently in the data set DB and db should satisfy both conditions; intersect frequent itemsets from the DB and db to obtain predictable results: c, d, e, cd, ce, de, cde. The experiments show that the results are the same to frequent itemsets of W2 in table 1.

Algorithm 4 describes the process of frequent itemsets that may arise in the mining process.

Algorithm 4: Mine frequent item sets that may arise.

Input: The current sliding window data.

Output: The next sliding window may appear frequent  itemsets.

//Algorithm 1-3 describes the associated matrix to generate,  update and frequent item set mining process.

1: F? Mining the frequent itemsets exist in the db; 2: D?Mining DB all set results; 3: E=D?F; 4: The judgment E exists in the DS data items.

D. Analysis of experiments In order to assess the effectiveness of the AMFP-Stream  algorithm, we analyze its accuracy.

The AMFP-Stream algorithm uses Microsoft C + +  programming software and all of the experiments are conducted in the same environment. The experimental environment: Windows XP system, 2.66GHz Pentium 4 processor, 512MB of memory.

The experimental literature [3] standard test set T10.I4.D100K test, table 2 describes the data set characteristics, sliding  window consists of four basic windows.

Table 2: Data set characteristics  Database T10.I4.D100K Transactions 100K Items 870 Length 10.1  Figure 2 depicts the changes of the AMFP-Stream algorithm accuracy in the process of digging test items results. With supportting rate arising, accuracy of the min ing results gradually improves; when the support rate is greater than 60%, the accuracy of the results up to 100%.

Support rate (%)  A cc  ur ar  y( %  )  AMFP-Stream  Figure 2: Changes of accuracy under different support rates.

Window size  Ac cu  rar y(  % )  AMFP-Stream  Figure 3: The changes of accuracy under different window size.

Figure 3 depicts that with the window size increasing, the accuracy of the algorithm is rising; when the window size is greater than 16, the accuracy is close to 100%.The AMFP- Stream algorithm is suitable for data stream mining under a large window.

Itemsets  Ac cu  rar y(%  ) AMFP-Stream  Figure 4: The number of different projects under the accuracy of change.

Figure 4 shows the AMFP-Stream algorithm accuracy decreases with the increase of the number of items. When the project number declines, the algorithm accuracy is close to 100%. The experiment shows that the data stream mining AMFP-Stream algorithm is suitable for small projects.

Through experimental analysis, the algorithm AMFP- Stream is able to predict the frequent itemsets that may occur when next window sliding.



V. CONCLUSION In this paper, we put forward data stream frequent pattern  prediction algorithm based on the associated matrix, which can not only predict the frequent itemsets of the current time window, but also predict  frequent itemsets of the next  window.

The experimental results show that the AMFP-Stream algorithm can predict the frequent itemsets effectively in different experimental conditions. Meanwhile, data stream mining results are satisfactory in high support rates, larger window and less items.

