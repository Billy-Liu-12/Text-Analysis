2004 IEEE International Symposium on Cluster Computing and the Grid

Abstract  Data privacy is a major concern that threatens the widespread deployment of Data Grids in domains such as health-care and finance. We propose a unique ap- proach for obtaining knowledge - by way of a data min- ing model - from a Data Grid, while ensuring that the data is cryptographically safe. This is made possible by an in- novative, yet natural generalization for the accepted trusted third party model and a new privacy-preserving data mining algorithm that is suitable for Grid-scale sys- tems. The algorithm is asynchronous, involves no global communication patterns, and dynamically adjusts to changes in the data or to the failure and recovery of re- sources. To the best of our knowledge, this is the first privacy-preserving mining algorithm to possess these fea- tures. Simulations of thousands of resources prove that our algorithm quickly converges to the correct result while us- ing reasonable communication. The simulations also prove that the effect of the privacy parameter on both the con- vergence time and the number of messages, is logarith- mic.

1. Introduction  The objective ora Data Grid is to maximize the availabil- ity and utilization of data that was often obtained through the investment of much labor and federal capital. Maximal utilization would be achieved if the owners of different data (resources) were able to share it with each other and with the research community at large -i.e., make it available for ev- eryone. Nevertheless, this is frequently prohibited by legal obligations or commercial concerns. Such restrictions usu- ally do not apply to cumulative statistics of the data. Thus, the data owners usually do not object to having a trusted third party (such as a federal agency) collect and publish these cumulative statistics, provided that they cannot be ma- nipulated to obtain information about a specific record or a  We thank Intel Corporation and the Mafat Institute for Rrsrwch ilnd Development for their generous support of this research.

0-7803-8430-W04F$20.00 02004 IEEE 41 1  specific data source. Trusted third parties are, however, dif- ficult to find, and the procedure involved is necessarily com- plicated and inefficient.

This scenario is most evident in the health maintenance business. Health Maintenance Organizations (HMOs) have a high interest in sharing medical data, both for public health reasons, such as plague control and the evaluation of different medical protocols, and for commercial reasons, such as detecting medical fraud patterns or medical mis- conduct. However, sharing medical data is very problem- atic: it is legally forbidden to expose specific records - i.e., a patient?s medical record -and it is commercially undesir- able to expose statistics about a single HMO - e.g., mortal- ity rates or the average expenditure per client. Similar ex- amplcs can be found in other domains, such as the finan- cial domain in which i t  i s  desirable to share account infor- mation in order to detect money laundering. In both these cases the need for global statistics is so great that fedcral agencies do collect them. Still, the procedures involved are indeed complicated and, at least in the HMO domain, suf- fer from regular information leaks with serious implications for some HMOs.

Distributed data mining offers a way by which data can he shared without compromising privacy. On the one hand, data mining techniques have been shown to be a leading tool for data analysis, and as such they are likely to satisfy re- searchers? needs as an interface to the data stored in the Data Grid. On the other hand, the models produced by data min- ing tools are statistical and thus satisfy the privacy concerns of the data owners. Thus, different HMOs can choose to re- veal their databases not for direct reading but rather to a dis- tributed data mining algorithm that will execute at the dif- ferent sites and produce a statistical model of the combined database. That the algorithm produces statistics is not in it- self sufficient: an HMO also has to make certain that the data mining algorithm does not leak information through its own operation. For instance, an algorithm in which each HMO computes its mortality rate and then sends it over to a polling station which computes the global statistics would not meet this criterion because the polling station would he informed of the mortality rate for each HMO. This calls for a specific type of distributed data mining algorithm that is    2004 IEEE International Symposium on Cluster Computing and the Grid  privacy-preserving.

Privacy-preserving data mining was first introduced by  Agrawal and Srikant in 2MO [3]. The original idea pre- sented there is to perturb the data by adding random trans- actions to the database. These perturbations hide the orig- inal data, but average out in the statistics - i.e., the same data mining models are created regardless of the perturha- tions. Perturbation fully guarantees data privacy and thus this approach is considered sufficient for the sequential set- ting. Yet in a distributed setting, where there are several data sources, perturbation does not maintain the privacy of each of the sources (e.g., the mortality rate for each HMO). Thus, a different method must he employed in distributed settings.

An alternative approach to privacy-preserving data min- ing is to replace each message exchange in an ordinary dis- tributed data mining algorithm with a cryptographic prim- itive that provides the same information without disclos- ing the data of the participants: for example, rcplacing a sum reduction by a cryptographically secured sum reduc- tion in which the participants learn only the final sum and not each other?s partial sums. When practiced well, this ap- proach guarantees the privacy of both single rccords and source statistics. However, all of the algorithms which have taken this approach so far have failed to scale above a few computational nodes. They all rely on cryptographic prim- itives that are both global - requiring all-to-all communi- cation patterns - and rigid - requiring that the primitive be evaluated all over again if the data changes even slightly or a node joins or leaves the system. That would be unac- ceptable in a Data Grid system which is expected to scale to hundreds of nodes (there are hundreds of HMOs in the US alone) or even to tens of thousands of nodes (a typi- cal HMO uses the services of hundreds of independent lah- oratories, clinics, and medical specialists, all of which have their separate databases), especially since communication is to be performed at Internet speeds.

Consider the algorithm described in [9] for the same dis- tributed association rule mining problem that is the subject of this paper. On several occasions, that algorithm requires that a message traverse all of the computing nodes twice, one-by-one, and that the algorithm hang until the message does so. Furthermore, if the data in even one part of the dis- tributed database changes just slightly, the whole algorithm has to he executed all over again. The algorithm pays no regard to the possibility that one of the nodes might fail.

Clearly, this is unacceptable in large-scale systems.

The main contribution of this paper is in presenting a cryptographic privacy-preserving association rule mining algorithm in which all of the cryptographic primitives in- volve only pairs of participants and are thus scalable. We use a non-private association rule mining algorithm as a ba- sis, and replace the message that was sent by resources with encrypted versions which the recipient cannot decrypt. By  virtue of the encryption scheme we use, oblivious counters, a resource can still perform most of the steps required by the non-private algorithm by itself.

Several steps require the assistance of a manager. Man- agers are stateless entities, implemented as part of the Data Grid infrastructure, whose sole purpose is to decrypt mes- sages; thus, there can be many of them and they can he lo- cated as near to the resource as required - possibly even on the same machine. It is important to note that a manager is not a trusted third party. Instead, using its ability to de- crypt messages, it  can help the resource perform those steps without either of them learning anything other than the fi- nal outcome of the algorithm.

Since the basic algorithm we use is extremely scalable in itself, and since our transformation of i t  does not require global operators, our algorithm can he shown to be scal- able to millions of resources -wel l  above the current re- quirements of Grid systems. Furthermore, the algorithm re- sponds very efficiently to changes in the databases, espe- cially if the changes are minute and do not affect the out- come of the algorithm. A key quality of our algorithm is that it offers a trade-off between the amount of privacy at- tainable (measured in the sire of the population on which the statistics are evaluated) and the computational effort re- quired to attain this privacy. Still, even when the maximal security level is required, the algorithm maintains some of its qualities (such as the efficient response to changes in the data). Finally, the algorithm does not, as our analysis re- veals, disclose any information other than the list of fre- quent itemsets and the list of correct rules.

2. Related Work  The distributed association rule mining (ARM) prob- lem has been studied for nearly a decade. Until recently, however, none of the algorithms presented for this prob- lem could scale above several dozens of participants. The first scalable algorithm for the distributed ARM problem was presented in [14]. Since our algorithm is based on that work, we thoroughly describe it in Section 4. Nevertheless, the algorithm does not preserve privacy; specifically, if a re- source communicates with the system via a single neigh- bor, then that neighbor will learn the resource?s statistics (e.g., the mortality rate for that HMO).

Privacy-preserving data mining has received a lot of at- tention in the past few years. In [3, 51, techniques based on perturbing the original data before initiating the mining pro- cess were used. However, this approach can only secure the privacy of records and not of the sources (e.g., of the pa- tients but not of the HMOs).

An alternative to the perturbation approach is to develop cryptographically secured versions of the data mining al- gorithm. This has been shown to be possible for three data     2004 IEEE International Symposium on Cluster Computing and the Grid  mining problems: distributcd ARM (the same problem dis- cussed in this paper) 191, ARM in vertically partitioned data [I31 - i.e., where each transaction is split among several nodes, and decision tree induction [IO]. The main problem with these three algorithms is that the cryptographic prim- itives they use are global and rigid. The evaluation of ev- ery primitive requires the participation of all of the nodes, and if the data at even one of the nodes changes or a sin- gle node joins or leaves the system, the process has to be repeated from scratch. This means that none of these algo- rithm can be employed in Data Grid scales.

3. Problem Definition  A Data Grid is composed of a group of resource nodes St - computers which contain parts of the database -and a group of management nodes &It - computcrs that manage thc system -all of which communicate by exchanging mes- sages via an overlay network composed of a S C ~  ofedges Et.

The composition of the system may vary with time. That is, S,, AIc and Et may be different from St,, &It, and E,,. Nev- ertheless, we assumc that an underlying mcchanism main- tains a communication tree that spans all the resources. We refer to the nodes of St as resources, and to those of Mt as managers. We denote E? the set of edges colliding with a resource U at timet.

Neithcr the resources nor the managers trust each other.

Instead, we make two accepted cryptographic assumptions on them. The first is that they are honest-but-curious (also referred to as semi-honest) [7]: they follow the protoco1,but may try to learn as much as they can from the computations they make and from messages they receive. The honest-hut- curious model was found useful in many domains, includ- ing data-mining [ 12,9] and secure information sharing [I] .

The second assumption is that colluding [7] is not allowed, either between a resource and a manager (a similar assump- tion is made in [12,4]) or between two resources (as in [9]) or two managers.

The association rule mining (ARM) problem is tradi- tionally defined as follows: Let I = { i L , i 2 ,  ... , i m }  be the items in a certain domain. An itemset is some sub- set X 2 I .  A transaction t is also a subset of I ,  associ- ated with a unique transaction identifier. A database D B is a list that contains IDBI transactions. Given an item- set X and a database DB,  Support  (X, D B )  is the num- ber of transactions in D B  which contain all the items of X  threshold MinFreq E [0,1], we say that an itemset X is frequent in a database D B  if Freq (X, D B )  2 MinFreq and infrequent otherwise. For two distinct frequent item- sets X and Y ,  and a confidence threshold MinConf E [0,1], we say the rule X + Y is confident in D B  if Freq (X U Y, DB)  2 MinConf . Freq (X, DB).  We call  and Freq ( X ,  D B )  = S u p p o r t ( X . D B )  lDBl . For some frequency  confident d e s  between frequent itemsets correct and the remaining rules false. The solution of the ARM problem is R [DB] -all the correct rules in the given database.

In many applications the database is updated over time, and hence, DBt will denote the database at time t and R [DBt] the rules that are correct in that database. In dis- tributed association rule mining the database is also parti- tioned among the resources (is., different HMOs connected to the Data Grid). We denote the union of partitions belong- ing to a group of resources S C St by D B f ;  that is, DBt equals D B T .  When the number of resources is large and the frequency of updates is high, it may not be feasible to propagate the changes to the entire system at the rate they occur. Thus, it is beneficial if an incremental algorithm can compute ad hoc results quickly and improve them as more data is propagated. Such algorithms are called anytime a[- gorithms. The performance of an anytime algorithm is mea- sured by its average recal[ and precision. Let Ru [D&] be the ad hoc solution known to the resource U at time t .  The recall and precision of U at that time are  R [ D B L ] n R [ D B  . An anytime algorithm is said to be and Ik..[DBtII correct if during static periods, in which the database and the system do not change, both the average recall and the average precision converge to one.

A distributed ARM algorithm is said to be privacy- preserving if an observer that has access to all of the data of a single resource or a single manager (database, internal variables, and all of the messages i t  received), plus some do- main knowledge 7f (e.g., the demographic characteristics of a certain HMO clientele), does not learn more than can be deduced from the result R [LIBt] and 7f. In other words, that observer cannot outperform a random guesser that is only given R [DBt] and H, when computing any predicate on the data. The algorithm is said to be k-resources-private if the observer cannot outperform a random guesser that is given 7f and is allowed to repeatedly choose a set of k or more resources (HMOs) - Sk C St -and told the rules that are correct in their joint databases - R [DB;'] I .  The al- gorithm is said to be k-transactions-privat~ if that observer cannot outperform a random guesser thalis given H and is allowed to repeatedly choose a group of k transactions (pa- tients) - dbk C DBt - and told the set of rules that are cor- rect from dbb - R kk]. For simplicity, in this paper we set k and E to be equal and define an algorithm as k-private if it is both k-resources-private and k-transactions-private.

Ik..IDBtlnR[DBt]l  I The definition can be strengthened by requiring that the guesser be given the rules R [DB:] , R  [ D B Z ]  , . . . only for set of muups {V,)suchthut(Vil t k,V, C V,+~.ao"deitherlV,+1 \Vi\ 2 k o r V;+I = Vc. It is  straightforward to extend OUT solution to this stronger definition.

41 3    2004 iEEE International Symposium on Cluster Computing and the Grid  4. Prerequisites  The work presented here relies on two bodies of re- search: a scalable algorithm for association rule mining which does not require global communication and a cryp- tographic technique called oblivious counters. Following is a short description of these methods.

4.1. A Scalable Distributed Association Rule Min- ing Algorithm - Majority-Rule  In a previous paper [ 141 we describe Majority-Rule - a highly scalable distributed ARM algorithm. The algorithm is based o n  two main inferences: That the distributed ARM problem is reducible to a sequence of majority votes, and that if the vote is not tied, majority voting can be done by a scalable algorithm - which we also present in that paper.

Since it  turns out that the frequency of an overwhelming number of candidate itemsets is significantly different from MinFreq (i.e., the vote is not ticd), the outcome of these two observations is a local, and thus highly scalable, distributed ARM algorithm.

The idea behind the scalable majority voting algorithm - Scalable-Mujority - is to have every node agree with its im- mediate neighbors about the majority. In the case of a dis- agreement with a neighbor, the node will share with that neighbor the evidence it has for the majority. The node will make sure it does not mislead its neighbor by taking care to update it whenever that evidence is weakened as a result of other updates or as a result of a change in its vote.

This is achieved by storing at each node its input hit (its vote), the last message it sent to each of its neighbors, and the last message it received from them. Each message contains evidence which consists of two integers, count and sum. The first is the number of input bits the mes- sage counts. The latter is the number of those which me set. Each pair of neighbors computes the evidence that has been agreed upon: Auv = Auu = sum"' f sumvu - X (count"" +cant""), where sumUU and countUw com- prise the evidence stored in the last message sent from U to U, sumVU and countVU comprise the most recent evi- dence sent from zi to U, and X is the majority threshold. Ad- ditionally, node U computes the total evidence it has been informed of: ,Au = (sum"" - Xwunt""), where N; is the set of U'S  neighbors plus {L} (which represents U itself), countLu is defined as one, and sum'" is one if U'S input bit is set and zero otherwise. Upon initialization, each node that votes one sends this evidence to its neigh- bors. Then, whenever A" or A"" changes, U will evaluate the following condition in order to decide whether it should send its current evidence to zi: A"'. 2 0 and A." > A" or A.'' < 0 and A." < A.. This is referred to as the Majority-Rule Condition. If it evaluates true, U will send U  the sum of the evidence collected from U'S vote and its other neighbon, with the result that A.' be set to A".

To see how Scalable-Majority translates into an associ- ation rule mining algorithm Majority-Rule, consider a ma- jority vote in which the transactions vote over every candi- date itemset, with each transaction voting one if it contains the itemset and zero otherwise, and with X set to MinFreq.

Similarly, to decide whether a rule is confident, the transac- tions again must vote. This time only transactions that in- clude the left-hand side of the rule vote, and their vote is one if they contain the right-hand side and zero otherwise; X is set this time to MinConf.

It is left to show how candidates are generated. Note that in Majority-Rule candidates must bc rules. This is because Majority-Rule is an anytime algorithm, and as such, it can- not wait for termination before it produces rules. Here a generalization of Apriori's [Z] criterion is used: Each re- source u.generaies initial candidate rules of the form 0 =+ { i }  for each i E I .  Then, each time it updates the candidate rule set, it generates, for each rule 0 =+ X E E,, [LIBt], new candidate rules X \ {i} + { i }  for all i E X. Additionally, the resource will look for pairs of rulcs in  8, [D&] which have the same left-hand side and right-hand sides that dif- feronlyinthelasti tem-X +YU{i l}andX +YU{i2}.

For every i s  E Y ,  the resource will verify that the rule X + Y U { i l , i z }  \ { i 3 }  is also correct, and then gener- ate the candidate X =+ Y U { i l ,  i2). It can be shown that the minimal set ofcandidate rules is created when I?, [D&] is 100% precise.

4.2. Oblivious Counters  We denote public-key cryptosystems by (E ,D) : Epub(m) is the encryption of a given plain text m us- ing the public key p u b  and DpyZu(c) is the decryption of a given cipher text c using the corresponding pri- vate key prizi. As we deal with a single key-pair, we write E (m) instead of Epub (m) and D (c)  instead of D,,,, (c).

A public-key cryptosystem ( E ,  D )  is called probabilis- tic [8] if the encryption process involves, in addition to the plain and public key, a random element, such that given two ciphers encrypted with uniformly selected random el- ements, it is hard to verify that they encode the same plain.

We denote E (z) - the rerandomization of E (z) - an- other element in  the cipher range, such that D E (z)  D ( E  (z)) but E T ) A public-key cryptosystem ( E ,  D ,  A+, A - )  is called ad-  ditively homomorphic if there exist polynomial algorithms A+ and A- such that for all E ( z ) ,  E(y):  (7 = E (z) with high probability.

A+ ( E  (x) , E  (y))) = E (z + y) A- ( E  (z), E (Y)) = E (x - Y).

2004 IEEE International Symposium on Cluster Computing and the Grid  An additively homomorphic public-key cryptosystem can be used to implement oblivious counters by which one can add two ciphers without knowing their plain. By us- ing A+ iteratively, one can easily calculate E (m . z) from E (z) for some m E A. In the interest of clarity, we mark E (z) $E (y) for A+ ( E  (z) , E  (Y)), E (2) lEJy) for A- (E (z) , E  (y)), miE (z) for E ( m  . z), and CE (z%)  There are several cryptosystems which are both prob- abilistic and additively homomorphic. In such cryptosys- tems, the rerandomization operator can he implemented, for example, by E (z) = E (z) +E (0). For implementing the oblivious counters, the algorithm proposed in this paper uses the popular Paillier cryptosystem [ I  I]  - an additively- homomorphic probabilistic cryptosystem over Z,. How- ever, any other such cryptosystem can be uscd. Finally, we note that in order to support the encryption of ncgative inte- gers, standard shifting techniques can he applied.

f o r A f (  ... A + ( A + ( E ( z i )  , E ( z ~ ) ) , E ( z ~ ) ) . . . ) .

5. K-Private Distributed Association Rule Mining  We now describe Private-Majority-Rule, a k-private dis- tributed association rule mining algorithm. The master plan of Private-Majority-Rule is similar to that of Majoriry-Rule: the resources perform majority votes over candidate rules to  decide whether they are frequent and confident. How- ever, in Private-Majority-Rule all of the counters are en- crypted into oblivious counters that cannot be decrypted by the resources. This ensures that a resource can never dis- cover the data of its neighbors. The only ones which can decrypt the counters are managers; however, a manager will never be given the oblivious counter directly. Instead, when- ever a resource has to decide whether to send a message to its neighbor, it performs a secure protocol with a manager, by the end of which the resource learns whether the mes- sage should be sent and the manager learns nothing. Also, whenever new candidates should be generated, the resource performs a similar protocol with a manager, by the end of which the resource learns the new candidate set and noth- ing more and the manager learns nothing.

The private majority voting procedure we use is simi- lar to the one described in [6] ,  with one important differ- ence: In [6], the resource is not allowed to l ean  the ma- jority. However, in privacy-preserving association rule min- ing many majority votes are performed - one for each can- didate - and those votes are dependent in the sense that a vote taking place for 0 + { U ,  b }  signifies that the major- ity for both 0 + { a }  and 0 + { b }  is one. What this means is that, unlike the model discussed in [6], our majority vot- ing algorithm must remain privacy-preserving even though a resource does learn the majority.

5.1. Private-Majority-Rule Algorithm  Consider a system composed of resources running Majority-Rule with all votes, and consequently all mes- sages, encrypted in oblivious counters. Instead of maintain- ing sumuv, cmnluv, sumvu, countuu, A., and Auu, it will maintain sum:;,.,, count& sum:;,.,, count:&, A&,,, and A:;,., - their encrypted versions. m n t  counts trans- actions. But, in order to maintain k-resources privacy, we also need to count resources. For this purpose we add the counter num. When the resource needs to send a neigh- bor a message that sums the evidence provided by the rest of its neighbors, it will use the c algorithm to sum the oblivi- ous counters. Problems arise only when it needs to evaluate the counters: when it needs to decide whether a mes- sage should be scnt or what the majority is. In both these cases it must consult with a manager. Ncvenheless, it is es- sential that the manager not learn the contents of the oblivi- ous counters.

Our first step, thus, is describing a secure primitive - PrivateEvalCond (Algorithm I )  - by which a resource can use a manager to evaluate a condition without disclosing to the manager the contents of the respective oblivious coun- ters. The primitive's input is a tuple of encrypted values,  , xpr and a condition which should he evaluated on them. The algorithm proceeds in three main steps: First, the tuple is hidden among M similar ones. Then, the group of tuples is sent to a manager, which decrypts them all and returns a vector containing the results of evaluating the condition on each tuple. Finally, the resource will choose the true result from amongst the returned values. A re- source will use this primitive on two occasions. The first is when its input has changed and it has to decide whether to update a neighbor. The condition in this case is that, for the candidate rule considered, either the Majoriry-Rule condition evaluates true, or C,EN,Ycount"" < k (mean- ing the resource does not retain k-transactions privacy), or CvEN,.numUU < k (meaning the resource does not retain k-resources privacy). The second occasion is when the re- source needs to h o w  whether the rule is correct; here, the condition is that Sign (Au) 2 0, and C,,N~counl"" 2 k , and ~vEN, -numUV 2 k.

Using this secure primitive, Private-Majoriry-Rule con- tinues as follows: Where a resource u in Majoriry-Rule would evaluate the condition on A' and Auu to decide whether a message should be sent to a neighbor w, in Private-Majoriry-Rule u will initiate the PrivareEvalCund primitive and send the message if the result is true. When u needs to generate new candidates, i t  will again initiate the PrivateEvalCond primitive in order to discover, for each candidate whose oblivious counters have changed, whether the rule is correct. It will then generate new candidates according to the criteria defined in the Majority-Rule al-  41 5    2004 IEEE International Symposium on Cluster Computing and the Grid  Algorithm 1 PrivateEvalCondp (Cond, X I , .  . . , xP) Inputs: Romeo (the resource) knows E (zl), . . . , E  (zp) .

and the public key. Maria (the manager) knows the private key. They both know X I , .  . . , X, -the distributions of val- ues of XI,. . . , xp.

Outputs: Romeo should learn only Cond (xl , .  . . ,xp).

Maria should leam nothing.

Privacy parameters: T,  M .

The algorithm:  1. For each i E {l, . . . , p } ,  Romeo randomly generates vector Ai [l, . . . , M ]  of values from the cipher range, where Aij t xiti, xi - Xi, ti - U [ l , .  . . ,TI, and encrypts i t  using pub.

2. Romeo selects m - U [l, . . . ,MI.

3. For each i E {l, . . . , p } ,  Romeo sets A, [m] +  t i i E ( z i ) w h e r e t i - U [ l , . _ . , T ] .

4. Romeo sends A I , .  . . , A ,  to Maria.

5. For each i t {1 ... M } ,  Maria sets B [i] t  Cond ( D  (Al [ i ] )  , . . . , D ( A ,  [ i ] ) ) .  Finally, she sends B to Romco.

6. Romeo's output is B [m].

gorithm. The algorithm of Private-Majoriry-Rule is given in Algorithm 3. The private majority voting procedure - Private-Scalable-Majority - is given in Algorithm 2.

Privacy analysis. To show that Private-Majority-Rule is indeed k-private we  make^ three observations: The first is that as long as data gathered for a rule is not based on at least k resources and at least k transactions, the resource be- havior is independent of the data and therefore does not dis- close anything about it. The second observation is that the PrivateEvalCond primitive does not leak information. This is because the chances of guessing where the true inputs are hidden are lower than h. Moreover, consecutive calls are independent and thus can not assist in boosting this proba- bility.

The third, somewhat more involved observation is that when U'S vote changes, it is impossible to guess the change unless it affects the majority in a group (of either transac- tions or resources) of size k. Assume, for example, that U'S vote does change the majority in such a group. In this case, a random guesser that is given the majority before the change, the majority after the change, and the information that there has been a change, would do,just as well in guessing the ac- tual change. Now assume that the change in U'S vote does not affect the majority and suppose, first, that the major- ity is of ones. We claim that the resulting pattern of mes- sages is independent of the data and thus nothing can be learned by looking at such patterns. This is true because, in Private-Scalable-Majority, sum is first decreased below the new value and then increased to the new value (see Al- gorithm 2). Thus, the change will first decrease A" and then increase it. If messages are sent, they will be in response to  Algorithm 2 Private-Scalable-Majority - Algorithm for a resource Input: (sum, count, A) -Private dynamic sum and count registers, and the rational majority ratio X = X,/Xd.

Local variables: The set of colliding edges E;, the privacy parameter k, and the managers' common public key.

Definitions: NF = {I} U {v E V, : uw E E:}, = E(sum) ,  = E(ccmnt), numi2c = E(I),  X,pi (sum~&+sum;&) - A n i  (mnt::',U,+count:;c).

Outpuf(): Return the output of PrivateEvalCond3 with my, where Cond ( Z I , X Z . Z ~ )  = (zl 2 k) A (zZ 2 k) A ( z 3  2 01, using C,E,VPcount:&. C.tNrnum:&. A:".,,, as the inputs xl,  x2, x3 respectively.

Updule(o): sum:;.,., t CwPUEN;1sum;2c, count:& t  Send (sum;Zc, count;;c, num:zc) to U .

MajorityCond(u): Return the output of PrivateEvalCond4 with my, where Cond(z1,xZ,z3,z4) = (ZI < k )  V ( X z < k )  ,v (23<0AZ4<0) v (23>0/\Z4>0), using C W E N ~ c o i m t Z  Cw,Nrnum::c. A::,.,, A;:clA;n.,, as the inputs zl, XZ, z3. zq respectively.

On initialization for each uu E E?, or on failure or re- covery of a neighbor v: Set sum:,",, sum;;,, count:&, count;:L, num:$ and  On receiving (.sum', count', num') from U :  Set sum::',., t sum', count::, t count', numE& t num'.

On change in sum from s to sf: Set sum to min(s, .s') - 1 and call Onchange(),  then set sum to maz(s,s') + 1 and call Onchange(), finally set .sum to s' and call Onchange().

On a change in one of the local counters - OnChange(): For each neighbor U: if MajorityCond(v), call Updafe(v).

the decrease. An increase in Au does not trigger messages if A' is already positive. The same argument holds when there is a majority of zeroes. Hence, the pattern of mes- sages is indeed independent of the data, and nothing can be learnt from it.

A;"~ = ZvtNP (Xdtsum:~',u,-X,icount~,"=), =  - - C w j & E  N;' cozLnt22cU,U,, num;;l,u, C w + v E  N;'num;%.

to E (0).

6. Experimental Results  To evaluate the performance of Private-Majority-Rule, we implemented a simulator capable of running thou- sands of simulated resources. The network topol- ogy was generated using the B R I E  topology gen- erator [ht  t p  : / /www. c s .  bu . edu/bri t e ] .  Syn- thetic databases were produced using the stan-  41 6    2004 IEEE International Symposium on Cluster Computing and the Grid  Algorithm 3 Private-Majority-Rule - Algorithm for a re- source Inputs  of resource U :  Local database DBP, the set of col- liding edges @, the set of items I ,  the frequency threshold MinFreq, the confidence threshold MinConf, and the man- agers? public key. . . - Output  of resource U :  The ad hoc set of rules & [DB,].

Local variables: (X + Y, A) denotes a candidate-rule X + Y with desired majority threshold A. C is a set of candidate-rules together with counters r.sum and r.count, both initially set to zero.

Initialization: Set C + {(0 + { i }  ,MinFreq) li E I } .

Repeat the following continuously:  For each rule T t C for which there is no active Private-Scalable-Majority instance, initiate one using (r.sum,r.wunt,r.A) as the input.

Cyclically, read a few transactions from the database DSP. For each transaction T ,  and rule T = (X + Y, A) E C which was generated after T was last read: If X C T ,  increase r.count. If X U Y g T ,  in- crease Tsum.

Once every few cycles:  - Set & [LIBt] to the set of rules T E C which their cor- responding Private-Scalable-Majority instance out- puts true.

- For each r  = (0 + X,MinFreq) t 8, [DB,], i E X: if r? = (X \ { i }  +- {i} ,MinConf) C,  add T? to C.

- F o r  each T I  = ( x - + Y U { i l } , A ) , ~ z  = ( X  3 Y U { i z }  , A )  E R, [DB,], il < i ~ :  if T? = ( X + Y U { i l , i 2 } , A )  C and Vi,ty (X + Y U { i l ,  iZ} \ {i3}, A) E 8, [DBt] ,  add r? to C.

On receiving a Private-Scalable-Majority message rele- vant  to rule T = ( X  + Y, A), from a neighbor t~: If T $Z G, add it to C. If T? = (0 + X U Y, A) C, add r? to Cas  well. Anyway, forward the message to the appro- priate local Private-Scalable-Majon?ty instance.

dard generation tool from IBM Quest group [http://www.almaden.ibm.com/cs/quest].

Three databases were generated T512, T1014, and T2016, where the number after the T denotes the average transac- tion length and the number after the I stands for the av- erage pattern length. Each database contains a million transactions. Using standard, pair-wise independent hash- ing techniques, transactions are sampled from the database to simulate the local database of each resource. Ex- cept in Figure 2b, the privacy argument k always equals 10.

At the beginning of the simulation each resource samples  10,000 transactions, which it processes in batches of about 150. After processing each batch, it decides what messages should be sent, and on every fifth batch it also communi- cates with its manager to create new candidate rules. We simulate dynamic databases by incrementing every resource with ten additional transactions at each batch. We simulate dynamic composition changes by using 50 resources at the outset and adding an average of five at each hatch, stop- ping at about 2,500 resources. Transactions continue to he added and messages exchanged until the systems reach a near-stasis (the computation never really terminates because transactions continue to be added). Throughout this process we measure the recall and precision compared to the precal- culated result, of the result at each resource. In addition, we count the number and type of messages that are exchanged.

The main results are presented in Figure I .  Figure l a  de- scribes the recall of the algorithm. In all three databases, by the time each resource scans its pan of the database for the second time, the recall has already reached 90%. This is in comparison to just one scan in the Majority-Rule algo- rithm [14]. In the Private-Majority-Rule algorithm, a rule cannot be found correct before the algorithm gathers infor- mation from k resources. Thus, candidate generation occurs more slowly, and hence the delay in the convergence of the recall.

Figure Ib describes the precision of the algorithm. The average precision also climbs above 90% in about two database scans. An interesting phenomenon is the decline in precision for the T20.16 database toward the end of the first scan. A deeper look reveals that the choice of MinFreq and MinConf led to the creation, around that time, of a very large number of candidate rules. Sheer numbers dic- tate that only a few of these candidates would he false pos- itives. However, since the number of correct rules is only ahout a hundred, these false positives led to a noticeable de- cline in precision. Note, however, that the false positives were quickly identified and did not significantly impair the convergence rate of the precision for this database.

Figure IC describes the communication pattern of the algorithm broken down according to the context of the message: resource-to-resource communication for the pur- pose of an update, resource-to-manager communication for the purpose of deciding whether to send a message, and resource-to-manager communication for the purpose of de- ciding whether a rule is correct and generating new candi- dates accordingly. At the beginning, many candidates are generated. Because the resource has not yet gathered infor- mation from k resources, the manager will give a positive answer every time i t  is asked whether an update should be sent. This explains the large quantity of update messages in the first database scan.

Another notable pattern is an increase in the amount of manager consultation messages. However, as time passes,  41 7  http://www.almaden.ibm.com/cs/quest   2004 IEEE International Symposium on Cluster Computing and the Grid  (C) Co"""iCefion F ib) Precislo" 1W  I 80 1 - - j 60 m F a 4'   0.0, 0.1 I 10 0.01 0.1 1 lo  f 0.0, 0.1 1 10  Figure 1. Recall, precision, and communication load of Private-Majority-Role X IranSaCtiOnl read (x 10,WO) X lranracUons Dad (x 10.0001 x tranractionr mad (I 10,WO)  this number declines, signifying that the result is in most cases negative. Note however that the number of messages to the manager does not decline, but rather stabilizes to a few condition messages for each candidate generation mes- sage. T h i s  is due to our dynamic database simulation - we continuously add transactions to the database. Every change in the counters leads the resource to consult the manager each time a transaction is  added.

- (a) Scalabiliry  ..__- p 2 0 1.8  E 0.01 0.1 1 i o  100 f 1.4 * ,eY)urces (X 10,OOO) 2 (b) The enem a! the privacy parameter  3.1 8 ! I ~ 2.9 a 3  I I I Y  5 2'3 0 5 10 1'5 20 25  k  Figure 2. Scalability and the effect of k  Two additional experiments are shown in Figure 2. Fig- ure 2a presents the number of transactions read until 90% recall is reached on a single itemset, when the number of re- sources is increased towards a million. The curve converges to a constant and, hence, the algorithm is infinitely scalable.

Figure 2b  measures the number of transactions read until 90% recall is reached when run over the database T1014, versus the privacy argument k. The graph shows that for each increase of ten in the privacy parameter k, there i s  a penalty of about one thousand transactions.

