An New Algorithm of Association Rule Mining

Abstract   Efficiency is critical to data mining algorithm.

Based on fully analyzing the PF_growth, an association rule mining algorithm, we in this paper give a new association rule mining algorithm called MFP.  MFP algorithm converts a transaction database to an MFP_tree through scanning the transaction database only once, then prune the tree and at last mine the tree.  Because the MFP algorithm scans a transaction database one time less than the FP_growth algorithm, the MFP algorithm is more efficient under certain conditions.

1. Introduction   Association rule mining belongs to data mining area.  It is used to search for interesting relationship among items in a large transaction database [1].

Boolean association rule mining is used more widely than other kinds of association rule mining.  Its whole mining process can be completed in three steps. Firstly, the database which will be mined is transformed into a transaction database. And then, some mining method is used to mine out all candidate frequent patterns.  At last, the association rules are created from the candidate frequent patterns. The second stage is the most important. It will decide the correctness and efficiency of the mining process. There are two mining algorithms which are widely used to mine association rules. One is Apriori; the other is FP_growth [3].

FP_growth algorithm is more efficient than Apriori.

Some related research showed that FP_growth algorithm is about one order of magnitude faster than the Apriori [4].  The larger the transaction database, the higher FP_growth?s efficiency.  The main reason is that Apriori algorithm must scan transaction database being mined several times and FP_growth algorithm need to scan the database only twice.  FP_growth algorithm is used normally to mine transaction  database for Boolean association frequent patterns. Its mining process is quite complicated, and can be divided into three basic stages.  The first stage is to scan the transaction database being mined and construct table L, a set of frequent 1-itemsets, with the value of minimum support count given.  The second stage is to scan the transaction database again, and build an FP_tree. The last stage is to mine the FP_tree, and search for all candidate frequent patterns.  After we get the patterns, we can construct all association rules from them easily.  Although FP_growth algorithm is more efficient than Apriori algorithm, it scans the transaction database twice. The first time, table L is constructed.  The second time, an FP_tree is built.  The cost of scanning a transaction database is usually very high.  If we can decrease the number of scan times of association rule mining algorithms, the algorithms will be even more efficient than FP_growth.

We design a fast association rule mining algorithm called MFP algorithm. MFP algorithm firstly scans a transaction database and converts the database into MFP_tree which is similar to FP_tree, and then, the algorithm mines MFP_tree to find all possible candidate frequent patterns.  Comparing with FP_growth algorithm, MFP algorithm scans a transaction database only once, so it has higher efficiency than FP_growth.  We have not found the similar work so far.

2. The Principle of the MFP algorithm   We give the following related definitions first.

2.1. Related Definition  Definition 1.  Transaction database: Transaction  database stores transaction records. Every transaction record in a transaction database has a sole identifier and all items included in the transaction record are listed in order. Figure 1 is a simple transaction   DOI 10.1109/CIS.2008.42     database named D.  T001 is the identifier of the first transaction record in D.  Transaction T001 includes items I1, I2, I5, which are listed in the order of the item suffixes [8].

TID List of item_ID?s T001 I1,I2,I5 T002 I2,I4 T003 I2,I3 T004 I1,I2,I4 T005 I1,I3 T006 I2,I3 T007 I1,I2 T008 I1,I2,I3,I5 T009 I1,I2,I3   Fgure 1. Transaction database   Definition 2.  MFP_tree: An MFP_tree is composed  of a number of tree nodes and a root labeled with ?null?. Every node has n sub-nodes (n = 0, 1, 2?).

When n = 0, the node is called leaf node. We use an MFP_tree to present a transaction database.  A tree node is labeled with the name of an item in the transaction database.  Except of the root, every node in the tree has two fields.  One is Ii.count and the other is Ii.pointer.  The Ii.count is equal to the number of the items, which appear in the nodes, and is displayed in a bracket on the right of the node label.  Ii.pointer is a pointer, which points to its mother node. An example of an MFP_tree is shown in Figure 2.

Figure2. MFP_tree   Definition 3.  C: Combination C is any combination  of nodes (the root is not included ) on a branch from a leaf to the root.  The C is presented with the labels of the nodes combined.  The name has a number in a bracket on the right.

I4, I5 are leaf nodes in the Figure 2. Because I5.count=1, and there are three nodes I1, I2, I5 on the branch, four compositions are constructed. They are {I5, I2}(1), {I5, I1}(1), {I5, I2, I1}(1), {I2, I1}(1).

There are two nodes I2, I4 on the other branch, and I4.count = 2,   so   we   can    get   the composition of {I4, I2}(2).

Definition 4.  Table TL: Table TL consists in three columns showed in Figure 3.  The first column is a list of item_IDs which appear in the transaction database D; the second column is filled with the support count of the item listed in the left column; the third one is made up of the item pointers pointing to its occurrences in the MFP_tree via a chain of node_links.

Definition 5.  Set CF: Set CF is a kind of sets whose element is C.

2.2. The principle of MFP Algorithm   The mining process of MFP Algorithm can be divided into three steps.  The first one is to construct MFP_tree; the next is to prune MFP_tree; and the last step is to mine MFP_tree.

(1) Constructing MFP_tree The root of an MFP_tree labeled with ?null? is  created first.  Then, the first transaction record is picked up from the transaction database D being mined and inserted into the MFP_tree in the following way.

The first item of the record is taken out.  If the root of the tree has a sub-node whose label is the same as the label of item just taken out, we add 1 to the node?s count field.  Otherwise, we create a new sub node of the root with the same label as the item.  After that, we use the sub node as a sub tree?s root, take out the next item from the transaction record and insert it into the sub tree in the same way.  The process repeats till all the items in the transaction record are put into the MFP_tree.  In this way, we can insert all the transaction records in D into the MFP_tree and complete the process of converting the transaction database D to the MFP_tree.  In the MFP_tree, one branch from a leaf to the root presents one or more transaction records of D and stores the association information among the items of a transaction record.

In order to mine an MFP_tree easier, according to Definition 4, the table TL is built.  The first column of the table is filled with the item_IDs which appear in the transaction data base.  Then the corresponding chains of node_links are built so that the occurrences of one item in the MFP_tree are linked together.  After that, each item support count is calculated through the node links and the results are put into the second column of table TL.

We can convert the transaction database D showed in Figure 1 to the MFP_tree shown in Figure 3.  The number in the bracket on the right side of a node label is the node?s Ii.count value.

Figure 3. The MFP_tree from D  (2) Pruning MFP_tree In order to facilitate the MFP_tree mining, we prune  the tree according to the value of minimum support count given beforehand. Suppose that the minimum support count is 3 (i.e. min_sup 3/9 = 33%). Those items whose support counts are less than 3 are deleted from the table.  All the tree nodes linked with the deleted item in the table are deleted also.  If a deleted node has a sub tree linked, have its sub tree link to its mother node. In the example shown in Figure 3, I4 and I5 in TL are deleted because their support count is less than 3. Their occurrences in MFP_tree are deleted afterward. After pruned, MFP_tree is shown in Figure 4.

Figure 4.  The MFP_tree pruned   (3) Mining MFP_tree We take out the first leaf node I3 from the left of  MFP_tree.  All of combinations are made up from the nodes (except the root) on the branch to which the leaf connects.  We then put labels and values to all the combinations according to Definition 3.  After that, we send all combinations into set CF, if there are not the same combination labels in set CF.  Otherwise, we merge the two combinations with the same label by adding together the two count values.  When all combinations of the nodes on the branch are sent into set CF, we modify the nodes on the branch in following way.  The leaf node?s count value is  subtracted from every node?s count value (including the leaf node?s) on the branch.  If a node?s count value on the branch is zero after subtracting, the node will be deleted.  Then we take out the new first leaf node again from the left of MFP_tree and process it in same way.

On finishing processing the MFP_tree, we delete those combinations in CF, whose count value is less than minimum support count given. After that, all the combinations left in set CF are candidate frequent patterns we want.  We can create all association rules from the combination in set CF, and use min_conf given to find strong association rules.  An example of mining MFP_tree shown in Figure 4 is given below.

We find leaf nodes I3 which is the first leaf node of MFP_tree from the left, and get the branch node I3, I1.

We combine the two nodes to get the combination of {I3, I1}(1).  Because set CF is empty at this moment, the combination enters CF directly.  Then we modify the nodes on the branch, by subtracting the number of the I3.count from the node.counts on the branch.  After subtracting, the I3.count equals 0 and I1.count equals 4.  Because I3.count is zero, the node is deleted from MFP_tree.  Now we take out the new first leaf node of the tree from the left, which is I3 and is the sub node of I2, and repeat the above process.  This time, we get the branch from I3 to the root.  The branch is composed of I3, I2, and I1.  We can get all the combinations from the three nodes {I3,I2,I1}(2), {I3, I2}(2), {I3, I1}(2) , {I2, I1}(2) and put them into set CF.  Then, we modify the count fields of the three nodes on the branch.  At this time, we subtract the value of I3.count from the nodes.

counts on the branch.  Because the value of I3.count is 0, the node is deleted and the node I2 becomes the first leaf node of MFP_tree.  We continue the process in the same way till the MFP_tree is empty.  After finishing processing MFP_tree, we get set CF as below.

CF = {{I3,I1}(4), {I3,I2,I1}(2), {I3,I2}(4), {I3,I1}(2), {I2,I1}(4) }  We delete those combinations in set CF, whose support count is less than the minimum support count given beforehand, (minimum support count = 3 in this example) and obtain set CF as below.

CF = {{I3,I1}(4), {I2,I1}(4), {I3,I2}(4) }  3. MFP Algorithm  3.1 The Algorithm   The poseudcode of MFP algorithm lists below.

input: Transaction database D, minimum support count output?    Candidate frequent set CF method??1?build MFP_tree   {     create root node; open D? while (not EOF)  {  R = current record? call insert_tree ( R, null )? move the pointer of D to the next record;}  create chains of node_links; }   procedure insert_tree (record, root_nod) {  while ( record <> ? ) {  first = the first item of the record? delete the item from the record? if ( root node has a sub node labeled with A  and the label == first ) A.count = A.count+1?  else {  create node A;  A.count=1; A.pointer point to root_nod ; }  If ( record <> ?) call insert_tree (record, A) recursively ;  } }   ( 2 ) pruning MFP_tree ( MFP_tree , TL  ) { move the pointer to the first row of TL;  while ( not EOF ) { if ( the item count < minimum support count ) { While ( the chain of node_links < >?) { delete the first tree node in the chain; if ( the sub tree of the deleted node < >? ) { let the sub tree link to the mother  node of the deleted node; } } delete the item in TL; delete the item count in TL; delete the node_link in TL; } move the pointer to the next row of TL; } }  ( 2 ) mining MFP_tree ( MFP_tree , TL )  {  while ( TL< > ? ) {  A = the first leaf node of MFP_tree from left ; combine all nodes on the branch from A to root to get C1?C2?????Cm; for ( I = 1; I <= m; i++ ) {  Ci.count = a.count; if (Ci ? CF)  CF.Ci.count = CF.Ci.count + Ci.count ; else  put Ci into CF ? } subtract A.count from all nodes.count of the items on the branch; if?node.count of items on branch = = 0?  delete those nodes; } delete those combinations in CF whose count < minimum support count?  }   3.2 The Result of the trial operation   In order to test MFP?s algorithm efficiency, under the same software and hardware environment, we use MFP algorithm and FP_growth algorithm respectively to mine an experiment transaction database.  The database has about 50000 transaction records and 100 items. The test results show that two algorithms can mine out the same candidate frequent patterns, but MFP algorithm?s mining efficiency is about 20% higher.  It can be inferred reasonably from the principle of the algorithm that MFP algorithm?s efficiency will get even higher, when a transaction database becomes larger and the number of item_IDs becomes smaller.

4. Conclusion   It is very important to have a data mining algorithm with high efficiency because transaction database usually are very large can not be stored in main memory. MFP algorithm can complete the mining process through scanning the transaction database only once. The experiments show that MFP algorithm has higher time efficiency. Because the input of MFP algorithm is the same as those inputs of FP_growth or Apriori, MFP algorithm can be applied to any situation where FP_growth or Apriori algorithm can be used.

5. Acknowledgements      The author appreciates the associate editor anonymous reviewers for their invaluable comments and suggestions to improve the manuscript. This study is partly supported by key Foundation of Shanghai Educational Committee (07ZZ164, 06OZ016), Foundation of Shanghai Institute of Technology(YJ2004-05), key subject of Shanghai Institute of Technology(Computer science and information) and Foundation of Shanghai Educational Committee(003HK08)?Leading Academic Discipline Project of Shanghai Municipal Education Commission (Project Number?J51501).

6. References  [1] T Imielinski, A Virmani, MSQL: Aquery languang for database mining, Data Mining and Knowledge Discovery, 1999,3(2)pp.373 -408.

[2] R Groth. Data Mining: Building Competitive Advantage, Prentice Hall, 1999.

[3] M Goebel, L Gruenwald. A survey of data mining and knowledge discovery softwareTools, SIGKDD Explorations, 1999,1(5)pp.20-33.

[4] G Grahne, Efficient mining of constrained correlated sets, In Proc 2000 Int. Conf. Data Engineering(ICDE?00), San Diego, 2000,pp.512-521.

[5] J Han, Mining frequent patterns without candidate generation, In Proc. 2000 ACM-SIGMOD Int.Conf. Dallas: 2000.

[6] Jiang Xiaoliang, FP_growth Based Algorithm for Mining of decision rule, Computer Science, 2003,8(6), pp.23-25.

[7] J Han, J Pei, Freespan, Frequent patternprojected sequential pattern mining, In Technical Report CMPT2000- 06, Simon Fraser University, 2000, pp.6-12.

[8] Jiawei Han, Data Mining: Concepts and Techniques, Burnaby: Simon Fraser University, 2000, pp.155-163.

