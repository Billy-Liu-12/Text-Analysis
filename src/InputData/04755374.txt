Information Privacy Values, Beliefs and Attitudes:   An Empirical Analysis of Web 2.0 Privacy

Abstract  The commercial potential and rapid growth of Web 2.0 phenomenon have been accompanied by concerns regarding the collection, dissemination, and re- identification of personal information by website operators, marketers, and other users on the social networks. To address critical and acute concerns for information privacy, this study investigated users? privacy perceptions in the Web 2.0 context by integrating privacy values, beliefs and attitudes into a theoretical framework. The research model was tested through a survey study among 218 users of Web 2.0- related sites. In addition to enhancing our theoretical understanding of privacy issues in the Web 2.0 context, this research is also potentially useful to privacy advocates, the website operators, and marketers to help shape or justify their decisions concerning the development and deployment of Web 2.0 features.

Keywords: Perceived Privacy, Information Control, Perceived Vulnerability, Anonymity, Secrecy.

1. Introduction   Recently, the booming popularity of Web 2.0 has  attracted significant attention. By providing user- centered platforms for information sharing, information publishing, collective editing and collaboration, Web 2.0 is disrupting traditional ideas about how users interact online and how content is generated, shared, and distributed. In the literature, Web 2.0 is often considered to be inclusive of a shift from a World Wide Web that is ?read only? to a Web that is being described as the ?Read Write Web? [25]. Examples of prominent Web 2.0 features that support the creation and consumption of user generated contents include blogging (e.g., Blogger), tagging (e.g., del.icio.us, and Flickr), user-driven ratings (e.g., Digg), and social networking (e.g., Facebook and MySpace), among many others.

The explosion of Web 2.0 technologies creates a plethora of niche markets within the media landscape  that are expected to generated $4.3 billion by 2011, more than four times what Web 2.0-related sites generated in 2007 with more than 70 million users [20].

Among these Web 2.0-related sites, the growth of social networking sites (SNSs) has been striking, especially among young adults. For example, both MySpace.com and Facebook.com have attracted about 115 million unique visitors in April 2008 [6].  According to a recent industry report published by eMarketer.com, it is estimated that 50 percent of U.S. adult Internet users and 84 percent of online teens will engage in online social networking monthly [20]. Furthermore, the revenue potential of social networks through advertising is huge: marketers are expected to spend $1.6 billion in 2008 to reach users of online social networks [20].

Unsurprisingly, the commercial potential and rapid growth of Web 2.0-related sites have been accompanied by concerns regarding the collection, dissemination, and re-identification of personal information by website operators, marketers, and other users on these sites.

These concerns pertain to the confidentiality of accumulated personal data and the potential risks that users may experience over the possible privacy and security breaches [1, 27]. Users often reveal and share a lot of their personal information on Web 2.0-related sites, thus exposing their published personal information with potential abuse by online crooks, stalkers, bullies, and, not rarely, even by their own friends [27, 28].

To address critical and acute concerns for information privacy, this study investigated users? privacy perceptions by integrating privacy values, beliefs and attitudes into a theoretical framework. We conducted a survey study to test the research model. In what follows, we first present the literature review for our research, describing the overarching theory that guides the development of the research model.  Then we develop the logic underlying the research hypotheses that identify the process through which individuals form privacy perceptions. This is followed by a description of the research methodology and          findings.  The paper concludes with a discussion of the results and implications of the findings.

2. Theory  2.1. The Concept of Privacy  Researchers from a number of disciplines have examined the concept of privacy including psychology [e.g., 3, 31], human resources [55, 59], sociology [e.g., 21], law [e.g., 49], political science [e.g., 63], marketing [e.g., 26], and management information systems [e.g., 14, 35, 51]. This rich ground of conceptual and empirical exploration has led to welcome efforts to synthesize various perspectives and identify common ground [53, 55].

Due to the complexity and inconsistencies of defining and measuring privacy per se, most behavioral research on privacy used privacy concerns as a proxy for the concept of privacy. A very extensive body of literature examines privacy concerns (for references, see for example Dinev and Hart [16]), especially because these are also the very proxy used to measure privacy attitudes in public opinion polls and marketing firms and thus provide a good connection with individuals' primal feelings when thinking about privacy. Landmark studies that have impacted our understanding of privacy concerns and their implications on individual's behavior include those of Culnan [13], Culnan and Armstrong [14], Milberg et al.

[37], Malhotra et al. [32] and many others. Smith et al.

[52] developed Concern for Information Privacy (CFIP) scale which identified four data-related dimensions of information privacy concerns (collection, errors, secondary use, and unauthorized access to information).

These dimensions have since served as some of the most reliable scales for measuring individuals? concerns toward organizational privacy practices.

In this study, however, we will consciously stay away from the commonly adopted proxy to privacy.

Instead, we attempt to seek a rigorous definition and antecedents to information privacy per se. We do this for three reasons: while a good proxy for information privacy, we believe that information privacy concerns are not identical to information privacy ? indeed, one may have high concerns about his or her privacy and yet it may be that his or her privacy may have not been violated, and vice versa. Until we do not know what privacy is (that is, have not defined it rigorously yet), at least we cannot claim that it is identical to privacy concerns. The second reason to avoid privacy concerns as a construct in our model is that we did not find it in the aforementioned privacy theories, nor did we find it as a possible dimension of privacy per se. Finally, privacy concerns carry a negative connotation of the concept of privacy and thus may be inadequate if  privacy should be regarded as potentially valuable to any human being and the society as a whole.

One of the most telling observations about the lack of identification of privacy is the one of Margulis [34]: ?theorists do not agree...on what privacy is or on whether privacy is a behavior, attitude, process, goal, phenomenal state, or what? (p. 17). Privacy has been described as multidimensional, elastic, depending upon context, and dynamic in the sense that it varies with life experience [4, 31]. This rich ground of conceptual and empirical exploration has led to welcome efforts to synthesize various perspectives and identify common ground [53, 55].

2.2. Privacy Attitudes, Beliefs, and Values  In social-psychology literature,  values, beliefs, and attitudes are theoretically and empirically connected to each other [2]. Attitude refers to a person?s favorable or unfavorable evaluation of an object. Belief, as a psychological state, represents the information that the person has about the object [54]. Belief is usually shaped by the internalization of value formed through affective and cognitive evaluations [45]. Value, defined as preferences for certain end-states of existence [2], evolves from circumstances with the external world and can change over time. Once a value has been internalized, it becomes a criterion for developing and maintaining belief toward relevant objects and situations [43]. Value is shown to be a key determinant of attitude through the mediating role of belief [e.g., 18].

Figure 1. Research Model  Following the similar theoretical reasoning, for the  context of information privacy in this research, we conceptualize and operationalize ?privacy? as an attitude, defined as a learned predisposition to respond in a favorable or unfavorable manner to information disclosure [23]. We develop a model to understand the underlying antecedents to the attitude factor (i.e.,          perceived privacy), namely perceived vulnerability and perceived information control, as each operates as a privacy belief related to the potential consequence of information disclosure. We further identify the antecedents to these two privacy beliefs and propose that: (1) an individual?s belief about the information control is a function of anonymity [58] and secrecy to data [9, 57]; (2) an individual?s belief about the vulnerability is a function of the type of information collected by an organization [47] and the expectation about the information handling (collection, storage, usage, and dissemination) practices of the organization [54]. Figure 1 presents the research model.

2.3. Beliefs-Attitudes Relationship  A number of studies support for the correlation between privacy attitudes and privacy beliefs [54].

Consistent with the privacy literature [15], we identify two factors account for the level of privacy perception an individual develops when determining whether to disclose personal information: perceived information control and perceived vulnerability. The relationships between these two constructs and perceived privacy are based on definitions of privacy that have emerged among scholars from a range of disciplines. Two important streams of research have followed Altman?s [3] and Westin?s [63] definitions of privacy. Based on a psychological interest in how individuals interact with their physical, social, and cultural environments, Altman [3] defined privacy as a process of regulating social interactions - ?the selective control of access to the self? (p. 24). Westin?s [63] perspective is more focused on information disclosure: ?Privacy is the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others? (p. 7). In comparing the work of these two scholars and those whose research is based on these definitions, Margulis [34] identified common core elements: ?Privacy involves control over transactions (interactions, communications) that regulate access to self and that, as a consequence, reduce vulnerability and increase decisional and behavioral options? (p. 415).

This definition reflects the view of privacy as a complex construct, the dichotomy between the individual and others [29] and captures the important factors of privacy: (1) control over disclosure of personal information, and (2) the notion of vulnerability.

Below, we present the theoretical foundation of the control and vulnerability constructs, and their relationship with perceived privacy, and the resulting hypotheses.

2.3.1. Perceived Information Control. Consumers, in general, find it unacceptable for marketers to sell information about them [41]. They strenuously object to  the secondary use of personal information without their knowledge [61]. As discussed above, the element of control is embedded in most privacy definitions and has been used to operationalize privacy in numerous measurement instruments [3, 13, 32, 63]. The conceptualization of control as a related but separate variable from privacy concerns may prove to be controversial [33]. One of the strongest arguments for separating control from privacy concerns was made by Laufer and Wolfe [31], who essentially argued that ?the dimensions of the privacy phenomenon are conceptually distinct from control/choice, which is a mediating variable? (p. 39). They further argue that ?a situation is not necessarily a privacy situation simply because the individual perceives, experiences, or exercises control? (p. 26). Conversely, the individual may not perceive she has control, yet the environmental and interpersonal elements may create perceptions of privacy [31].

These considerations suggest that perceived control over disclosure and subsequent use of personal information is a separate construct from privacy concerns. Following this perspective, we propose that perceived control over personal information is strongly related to information privacy. Individuals tend to perceive disclosure as less privacy-invasive when they believe that they have control over the collection and use of their personal information [14]. Several privacy studies argue that the loss of control over personal information is central to the notion of privacy invasion [38, 47, 50]. Therefore, we hypothesize:  H1. Perceived information control positively affects perceived privacy.

2.3.2. Perceived Vulnerability. Perceived vulnerability enters a decision-making process when circumstances of the decision create feelings of uncertainty, discomfort and/or anxiety [17], such as when conflict arouses in the consumer concern [8]; psychological discomfort triggers feelings of uncertainty [40]; anxiety causes pain [56]; and when there is cognitive dissonance [22].  The notion of vulnerability is related to privacy and shares some of the latter?s complexity.

Introduced separately from privacy, vulnerability has been described as the perceived potential risk that occurs when personal information is revealed [44, 48].

However, it has also been described as a possible consequence of concealing information, when disclosure would be important for attaining a positive outcome [46]. Fusilier and Hoyer [24] and Petronio [46] have argued that the perceived state of privacy is determined by an individual?s sense of vulnerability.

Applying their findings to the specific context of Web 2.0, we define the perception of vulnerability as the user?s perceived expectation of suffering a negative          outcome as a consequence of online disclosure of personal information.

Users may perceive two kinds of vulnerabilities if their personal information is not used fairly or responsibly [13, 26, 52]. First, a user may perceive that her privacy is invaded if unauthorized access is made to her personal information as a result of a security breach or in the absence of appropriate internal controls.

Second, as computerized information may be readily duplicated and shared, a user may perceive a relatively high risk that the information she has provided is being put into secondary use for unrelated purposes without her knowledge or consent [14]. In the context of Web 2.0, improper handling of personal information would result in the discovery and matching of personal data to enhance the visibility of their behavior, and increase the scope for situations that may be personally embarrassing to them. Furthermore, users often reveal a lot of personal information through social networking sites and blogs, thus exposing their published personal information with potential abuse by online crooks, stalkers, and bullies [27, 28]. Therefore, when individuals perceive that information will not be used fairly and that there will be negative consequences, they will be less likely to engage in the online activities that require information disclosure. Hence, we hypothesize:  H2. Perceived vulnerability negatively affects perceived privacy.

2.4. Value-Beliefs Relationship   2.4.1. Mechanisms to Information Control. Based on the proposed definitions and the direct relationship between perceived information control and perceived privacy, we posit that the Westin's states of privacy are actually mechanisms for maintaining the desired state of privacy which, in the case of information privacy, is achieved through control over the information exchange between the individual and the world outside his or her information boundaries [33]. Particularly relevant to information privacy are anonymity and secrecy, and we introduce these constructs in our model as predictors to perceived information control. Solitude and isolation, defined as absence of others is specific to physical privacy [64]. It is hard to transpose the connotation of solitude to the realm of information privacy where data flow in the networked computers and digital devices regardless whether an individual is alone in the physical space. Likewise, intimacy loses its relevance in the information privacy since electronic exchange between the individual and an intimate partner or group (e.g., chatrooms, text messages and emails etc.) can be easily captured and retained by any third party sniffing or storage tool.

Anonymity is the ability to conceal the relationship between a particular user and the data about him. It is  central for the information collected for statistical purposes. The distinction between privacy and anonymity is clearly seen in the information technology context. Anonymity corresponds to being able to send the contents of the e-mail without any information that enables a reader of the message to identify the person who wrote it. Anonymizers (e.g., anti-spyware tools, anonymous browsers) allow an individual to explore cyberspace (e.g., using e-mail, viewing Web sites) with a high degree of anonymity [60]. Online anonymous communication is morally neutral and should be considered a human and constitutional right, according to Teich et al. [58]. Online anonymization mechanisms offer several types and levels of anonymity [30]. Giving users the option to conceal their identities seems a viable way to alleviate users? privacy concerns while preserving the benefits of personalized interaction [60].

Users? beliefs in anonymity can be expected to lead to more extensive and frank interaction, hence to higher level of information control perceptions. Therefore:  H3. Anonymity positively affects perceived information control.

Secrecy has been defined as intentional concealment of information [9, 57]. Although secrecy is easily distinguishable from privacy, they are often mistaken and confused with each other [36]. "Privacy need not hide; and secrecy hides far more than what is private" [9, p.11]. A property can be private but not necessarily secret, and vice versa: a gift can be secret but not necessarily private. Warren and Laslett [62] also reflect on the conceptual comparison between privacy and secrecy: according to them, secrecy implies the concealment of something which is negatively valued by the excluded audience; privacy, by contrast protects behavior which is either morally neutral or valued by society. Additionally, while privacy is consensual ? the behavior it protects is socially legitimated, secrecy is nonconsensual and usually involves the interest of the excluded [57]. Secrecy enables individuals to manipulate and control environments by denying outsiders vital information about themselves [57]. Thus, secrecy is directly related to control.

H4. Secrecy positively affects perceived information control.

2.4.2. Information Sensitivity. Support for individuals having different information-related beliefs as a consequence of differing information experiences or interacting with external environment is suggested by prior privacy literature [54].  It has been shown that perceived privacy beliefs is a function of the type of personal information collected, stored, used, and released by an organization [32, 39, 47, 50]. All things being equal, individuals perceive greater vulnerability when disclosing more sensitive information than they          do for disclosing less sensitive information. In the context of social networking sites, it has been shown that majority of users are selective in terms of the type of personal information they post online. For example, most would publish their sexual orientation, birthday and political views but conceal the class schedule, address, home phone and cell phone numbers [1]. Thus, when sensitive information is requested, vulnerability beliefs are hypothesized to increase:  H5. Information sensitivity positively affects perceived vulnerability.

2.4.3. Expectation of Information Practices. A common phrase in discussions of privacy is ?reasonable expectation of privacy?, which has a long history in case law [60]. In the context of information privacy, the expectations are all about how the information will be handled by the organizations. Thus, expectation of information practices is defined by the individual's expectations on how organization should handle (collect, store, use, and release) his or her personal information and data so that data will not suffer accidental disclosure and harm in any way the individual [54]. Expectations of privacy vary depending on many factors, but place and social relationships are among the most important. Earp et al [19] examined Internet users? major expectations about website privacy and revealed a notable discrepancy between what privacy policies are currently stating and what users deem most significant. The hypothesized relationship between expectation of information practices and perceived vulnerability is supported by the research of Awad and Krishnan [7] which revealed that perceived privacy beliefs were significantly related with individuals? expectations of the organization's information-handling practices. It has been indicated that customers who desire greater information privacy perceive greater vulnerability and thus are less willing to be profiled [7]. Hence, we hypothesize:  H6. Expectation of information practices positively affects perceived vulnerability.

3. Method  3.1. Scale Development  The research hypotheses were empirically tested using data collected with a survey that included items for the constructs specified in the model. Scale development for the constructs was based on an extensive survey of the privacy literature. Validated standard scales were adapted for use as much as possible. Perceived privacy was measured by three questions adapted from [11]. Drawing on Dinev and Hart [15], we measured perceived vulnerability using  four items to reflect the potential losses associated with the information disclosure. Items measuring perceived privacy control were measured by four questions that were directly taken from Xu [65]. Anonymity was measured three items developed from [58] and secrecy was measured by three items adapted from [9, 57].

Information sensitivity was measured by three items based on [39, 47, 50] and expectation for privacy was measured by four items adapted from [54].

3.2. Survey Administration  The initial questionnaire was reviewed by four Information Systems (IS) faculty members for clarity.

Next, a pilot study involving 51 undergraduate students was conducted using the improved questionnaire. The main objectives of the pilot study were to assess the clarity and conciseness of the survey instructions and questions, evaluate the measurement model, and gauge the duration of the survey. The respondents were also contacted for a face-to-face interview so that their opinions on the survey instructions and questions could be gathered. Following their feedback and analysis of measurement model, a number of revisions were made: some items were dropped, wording changes were made, and instructions that the respondents found confusing were clarified. All measurement items were included in the Appendix A.

Table 1. Respondent Demographics   The survey was administered to undergraduate,  graduate and MBA students at two large universities in the U.S. Participants were asked to recall their experiences in using Web 2.0-related sites such blogging sites (e.g., Blogger), tagging sites (e.g., del.icio.us, and Flickr), user-driven rating sites (e.g., Digg), and social networking sites (e.g., Facebook and MySpace). They were also asked to list the name or URL of the website that they used within the last 6 months. Since participation of the study was completely voluntary, several respondents submitted empty or only          partially filled questionnaires that were subsequently eliminated.  A total of 218 responses were usable.

Table 1 provides respondent demographics.

Non-response bias was assessed by verifying that early and late respondents were not significantly different [5]. Early respondents were those who responded within the first week (48%). The two groups of early and late respondents were compared based on their demographics (age, gender and Web usage experience). All t-test comparisons between the means of the two groups showed insignificant differences.

4. Data Analysis and Results Partial least squares (PLS), a second-generation causal modeling statistical technique, was used for data analysis.

4.1. Measurement Model  We evaluated the measurement model by examining the convergent validity and discriminant validity of the research instrument. Convergent validity is the degree to which different attempts to measure the same construct agree [12]. In PLS, three tests are used to determine the convergent validity of measured reflective constructs in a single instrument: reliability of items, composite reliability of constructs, and average variance extracted by constructs. Table 2 presents the assessment of the measurement model.

Table 2. Measurement Model    We assessed item reliability by examining the loading of each item on the construct and found the reliability score for all the items exceeded the criterion of 0.707. Thus, the questions measuring each construct in our experiment had adequate item reliability.

Composite reliabilities of constructs with multiple indicators exceeded Nunnally?s [42] criterion of 0.7.

The average variances extracted for the constructs were all above 50 percent, and the Cronbach?s alphas were also all higher than 0.7. These results support the convergent validity of the measurement model.

Discriminant validity is the degree to which measures of different constructs are distinct [10]. To test discriminant validity, the square root of the variance shared between a construct and its measures should be greater than the correlations between the construct and any other construct in the model. Table 3 reports the results of discriminant validity which may be seen by comparing the diagonal to the non-diagonal elements. All items in our study fulfilled the requirement of discriminant validity.

Table 3. Discriminant Validity   4.2. Structural Model  After establishing the validity of the measures, we tested the structural paths in the research model using PLS. We conducted hypothesis tests by examining the sign and significance of the path coefficients. A bootstrapping technique was applied to estimate the significance of the path coefficients. Since PLS does not generate any overall goodness of fit indices, predictive validity is assessed primarily through an examination of the explanatory power and significance of the hypothesized paths. The explanatory power of the structural model is assessed based on the amount of variance explained in the endogenous construct (i.e., privacy concerns in our study). We conducted the statistical tests at a five-percent level of significance using one-tailed t-tests.

Figure 2 presents the structural models. The structural models explain 52.2% of the variance in perceived privacy.  As hypothesized, perceived control and perceived vulnerability strongly influence perception of privacy, thus validating H1 and H2.

Anonymity and secrecy are found to be the significant mechanisms to information control, validating H3 and H4. Information sensitivity and expectation of privacy are found to have significant impacts on perceived vulnerability, validating H5 and H6.

Figure 2. Structural Model    5. Discussion and Conclusion This study developed and empirically tested a  research model to investigate privacy perceptions in Web 2.0-related sites. Our proposed model is able to account for 52.2% of the variance in perceived privacy, and thus possesses enough explanatory power to make the interpretation of path coefficients meaningful. The evidence from this study provided empirical support that privacy attitudes are grounded in both an individual?s values in terms of information sensitivity and expectations of organizational privacy practices that enable a person to assess the consequences of information disclosure. A cognitive process of assessing perceived information control and perceived vulnerability is shown to be important in shaping an individual?s privacy perception.

This research presents a model linking privacy values, beliefs and attitudes together, which shows that privacy constructs relate to each other in organized, meaningful ways. This is important because definitions of privacy and relationships among privacy-related constructs have been inconsistent and not fully developed in the extant literature. Having a coherently developed and rigorously tested framework with consistent set of constructs should enable privacy research to progress more quickly by having systematic understandings. From a practical perspective, this study shows that vulnerability beliefs and perceived information control are the important factors in users? interactions with Web 2.0-related sites. In this aspect, this study provides some insights into the approaches that could be used by a Web 2.0 site operator to address privacy issues by reducing vulnerability beliefs and enhancing control perceptions. To the extent that perceived control is a key factor influencing privacy perception, it is important for Web 2.0 site operators to develop privacy control features with user-friendly interfaces for ensuring individual?s capability to  maintain the anonymity and secrecy of their personal information.

Users? information control and vulnerability perceptions could play primary roles in addressing privacy issues pertaining to Web 2.0-related sites, especially in the absence of well-established legal resources. This study provides a preliminary understanding of the privacy issues in Web 2.0-related sites by integrating privacy values, beliefs and attitudes into a theoretical framework. Using the groundwork laid down in this study, further work could contribute significantly to extending our theoretical understanding and practical ability to foster the diffusion of Web 2.0 features.

6. References [1]   A. Acquisti and R. Gross, "Imagined Communities: Awareness, Information Sharing, and Privacy on the Facebook," Proceedings of Proceedings of Privacy Enhancing Technologies Symposium, 2006, pp. 36-58.

[2]   I. Ajzen and M. Fishbein, Understanding Attitudes and Predicting Social Behavior, Englewood Cliffs, NJ: Prentice-Hall, 1980.

[3]   I. Altman, The Environment and Social Behavior: Privacy, Personal Space, Territory, and Crowding, Monterey, CA: Brooks/Cole Publishing, 1975.

[4]   I. Altman, "Privacy Regulation: Culturally Universal or Culturally Specific?" Journal of Social Issues, vol. 33, no. 3, 1977, pp. 66-84.

[5]   J.S. Armstrong and T.S. Overton, "Estimating Non-response Bias in Mail Surveys," Journal of Marketing Research, vol. 14, August, 1977, pp. 396- 402.

[6]   M. Arrington, Facebook No Longer The Second Largest Social Network, in The Washington Post. 2008, http://www.washingtonpost.com/wp- dyn/content/article/2008/06/13/AR2008061300129.html  [7]   N.F. Awad and M.S. Krishnan, "The personalization privacy paradox: An empirical evaluation of information transparency and the willingness to be profiled online for personalization," MIS Quarterly, vol. 30, no. 1, 2006, pp. 13-28.

[8]   J. Bettman, "Perceived risk and its components: a model and empirical test," Journal of Marketing Research, vol. 10, 1973, pp. 184-190.

[9]   S. Bok, Secrets: On the Ethics of Concealment and Revelation, JSTOR, 1989.

[10]   D.T. Campbell and D.W. Fiske, "Convergent and Discriminant Validation by the Multitrait-Multimethod Matrix," Psychological Bulletin, vol. 56, no. 1, 1959, pp. 81-105.

[11]   R.K. Chellappa, "Consumers? Trust in Electronic Commerce Transactions: The Role of Perceived Privacy and Perceived Security," Working Paper, 2008, Emory University: Atlanta, GA.

[12]   M. Cook and D.T. Campbell, Quasi- Experimentation: Design and Analysis Issues for Field Settings, Boston: Houghton Mifflin, 1979.

[13]   M.J. Culnan, "'How Did They Get My Name'? An Exploratory Investigation of Consumer Attitudes toward Secondary Information Use," MIS Quarterly, vol. 17, no. 3, 1993, pp. 341-364.

[14]   M.J. Culnan and P.K. Armstrong, "Information Privacy Concerns, Procedural Fairness and Impersonal Trust: An Empirical Investigation," Organization Science, vol. 10, no. 1, 1999, pp. 104-115.

[15]   T. Dinev and P. Hart, "Internet Privacy Concerns and Their Antecedents - Measurement Validity and a Regression Model," Behavior and Information Technology, vol. 23, no. 6, 2004, pp. 413-423.

[16]   T. Dinev and P. Hart, "An Extended Privacy Calculus Model for E-Commerce Transactions," Information Systems Research, vol. 17, no. 1, 2006, pp.

61-80.

[17]   G. Dowling and R. Staelin, "A model of perceived risk and intended risk-handling activity," Journal of Consumer Research, vol. 21, 1994, pp. 119- 134.

[18]   R.H. Ducoffe, "Advertising Value and Advertising on the Web," Journal of Advertising Research, vol. 36, 1996, pp. 21-35.

[19]   J.B. Earp, A.I. Anton, L. Aiman-Smith, and W.H.

Stufflebeam, "Examining Internet privacy policies within the context of user privacy values," Ieee Transactions on Engineering Management, vol. 52, no.

2, 2005, pp. 227-237.

[20]   eMarketer, User-Generated Content: Will Web 2.0 Pay Its Way? 2006, http://www.eMarketer.com  [21]   A. Etzioni, The limits of privacy, New York: Basic Books, 1999.

[22]   L. Festinger, A Theory of Cognitive Dissonance, Stanford, CA: Stanford University Press, 1957.

[23]   M. Fishbein and I. Ajzen, Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research, Reading, MA: Addison-Wesley, 1975.

[24]   M.R. Fusilier and W.D. Hoyer., "Variables affecting perceptions of invasion of privacy in a personnel selection situation," J. of Applied Psych, vol.

65, no. 5, 1980, pp. 623-626.

[25]   D. Gillmor, The Read-Write Web: Technology that Makes We the Media Possible. 2007, http://www.oreilly.com/catalog/wemedia/book/ch02.pdf  [26]   C. Goodwin, "Privacy: Recognition of a Consumer Right," Journal of Public Policy and Marketing, vol. 10, no. 1, 1991, pp. 149-166.

[27]   R. Gross and A. Acquisti, "Information revelation and privacy in online social networks," Proceedings of the 2005 ACM workshop on Privacy in the electronic society, 2005, Alexandria, VA.

[28]   S. Kelly, "Identity 'at risk' on Facebook," BBC News, May 1st 2008, http://news.bbc.co.uk/2/hi/programmes/click_online/73 75772.stm  [29]   P. Kelvin, "A social-psychological examination of privacy," British J. of Social Clinical Psych., vol. 12, no. 2, 1973, pp. 248-261.

[30]   A. Kobsa and J. Schreck, "Privacy through Pseudonymity in User-Adaptive Systems," ACM Transactions on Internet Technology, vol. 3, 2003, pp.

149?183.

[31]   R.S. Laufer and M. Wolfe, "Privacy as a Concept and a Social Issue - Multidimensional Developmental Theory," Journal of Social Issues, vol. 33, no. 3, 1977, pp. 22-42.

[32]   K.N. Malhotra, S.S. Kim, and J. Agarwal, "Internet Users' Information Privacy Concerns (IUIPC): The Construct, the Scale, and a Causal Model," Information Systems Research, vol. 15, no. 4, 2004, pp.

336-355.

[33]   S.T. Margulis, "On the Status and Contribution of Westin's and Altman's Theories of Privacy," Journal of Social Issues, vol. 59, no. 2, 2003, pp. 411-429.

[34]   S.T. Margulis, "Privacy as a Social Issue and Behavioral Concept," Journal of Social Issues, vol. 59, no. 2, 2003, pp. 243-261.

[35]   R.O. Mason, "Four Ethical Issues of the Information Age," MIS Quarterly, vol. 10, no. 1, 1986, pp. 4-12.

[36]   D. McLean, Privacy and its invasion, Westport, Conn.: Praeger, 1995.

[37]   S.J. Milberg, H.J. Smith, and S.J. Burke, "Information privacy: Corporate management and national regulation," Organization Science, vol. 11, no.

1, 2000, pp. 35-57.

[38]   G.R. Milne and M.-E. Boza, "Trust and Concern in Consumers' Perceptions of Marketing Information Management Practices," Journal of Interactive Marketing, vol. 13, no. 1, 1999, pp. 5-24.

[39]   G.R. Milne and E.M. Gordon, "Direct Mail Privacy-Efficiency Trade-Offs Within an Implied Social Contract Framework," Journal of Public Policy and Marketing, vol. 12, no. 2, 1993, pp. 206-215.

[40]   C. Moorman, R. Desphande, and G. Zaltman, "Factors affecting trust in market research relationships," Journal of Marketing, vol. 57, no. 1, 1993, pp. 81-101.

[41]   G.J. Nowak and J. Phelps, "Understanding Privacy Concerns: An Assessment of Consumers's Information-Related Knowledge and Beliefs," Journal of Direct Marketing, vol. 6, no. 4, 1992, pp. 28-39.

[42]   J.C. Nunnally, Psychometric Theory, 2nd ed., New York: McGraw-Hill, 1978.

[43]   S. Oskamp, Attitudes and Opinions, 2nd ed., Edition, NJ: Prentice-Hall, 1991.

[44]   P.A. Pavlou, "Institution-based trust in interorganizational exchange relationships: the role of online B2B marketplaces on trust formation," Journal of Strategic Information Systems, vol. 11, no. 3-4, 2002, pp. 215-243.

[45]   R.M. Perloff, The Dynamics of Persuasion, New Jersey: Lawrence Erlbaum Associates, Inc., 1993.

[46]   S. Petronio, Boundaries of Privacy: Dialectics of Disclosure., Albany, NY.: State University of New York Press, 2002.

[47]   J. Phelps, G. Nowak, and E. Ferrell, "Privacy Concerns and Consumer Willingness to Provide Personal Information," Journal of Public Policy and Marketing, vol. 19, no. 1, 2000, pp. 27-41.

[48]   C.D. Raab and C.J. Bennett, "The distribution of privacy risks: Who needs protection?," Information Society, vol. 14, no. 4, 1998, pp. 263-274.

[49]   J. Rosen, The unwanted gaze : the destruction of privacy in America, New York: Random House, 2000.

[50]   K.B. Sheehan and G.M. Hoy, "Dimensions of Privacy Concern among Online Consumers," Journal of Public Policy and Marketing, vol. 19, no. 1, 2000, pp.

62-73.

[51]   H.J. Smith, Managing privacy : information technology and corporate America, Chapel Hill: University of North Carolina Press, 1994.

[52]   H.J. Smith, J.S. Milberg, and J.S. Burke, "Information Privacy: Measuring Individuals' Concerns About Organizational Practices," MIS Quarterly, vol.

20, no. 2, 1996, pp. 167-196.

[53]   E.F. Stone, Research Methods in Organizational Behavior, Scott, Foresman Series in Management and Organizations, ed. Lyman W. Porter, Glenview, IL: Scott, Foresman & Company, 1978.

[54]   E.F. Stone, G.H. Gueutal, D.G. Gardner, and S.

McClure, "A Field Experiment Comparing Information-Privacy Values, Beliefs, and Attitudes Across Several Types of Organizations," Journal of Applied Psychology, vol. 68, no. 3, 1983, pp. 459-468.

[55]   E.F. Stone and D.L. Stone, "Privacy in Organizations: Theoretical Issues, Research Findings, and Protection Mechanisms," Research in Personnel and Human Resources Management, vol. 8, no. 3, 1990, pp. 349-411.

[56]   J. Taylor, "The role of risk in consumer behavior," Journal of Marketing, vol. 38, 1974, pp. 54- 60.

[57]   S.K. Tefft, Secrecy, a Cross-Cultural Perspective, New York, N.Y.: Human Sciences Press, 1980.

[58]   A. Teich, M.S. Frankel, R. Kling, and Y.C. Lee, "Anonymous communication policies for the Internet: Results and recommendations of the AAAS conference," Information Society, vol. 15, no. 2, 1999, pp. 71-77.

[59]   P.D. Tolchinsky, M. McCuddy, J. Adams, D.C.

Ganster, R. Woodman, and H.L. Fromkin, "Employee perceptions of invasion of privacy:  A field simulation experiment," J. of Applied Psych, vol. 66, no. 3, 1981, pp. 308-313.

[60]   J. Waldo, H. Lin, L.I. Millett, and e. Inc, Engaging Privacy and Information Technology in a Digital Age, National Academies Press, 2007.

[61]   P. Wang, "Information-Systems Solutions for Transborder Data Flow Problems for Multinational Companies," International Journal of Information Management, vol. 13, no. 1, 1993, pp. 29-40.

[62]   C. Warren and B. Laslett, "Privacy and Secrecy - Conceptual Comparison," Journal of Social Issues, vol.

33, no. 3, 1977, pp. 43-51.

[63]   A.F. Westin, Privacy and Freedom, New York: Atheneum, 1967.

[64]   A.F. Westin, "Social and Political Dimensions of Privacy," Journal of Social Issues, vol. 59, no. 2, 2003, pp. 431-453.

[65]   H. Xu, "The Effects of Self-Construal and Perceived Control on Privacy Concerns," Proceedings of Proceedings of the 28th Annual International Conference on Information Systems (ICIS 2007), Montr?al, Canada, 2007.

Appendix A. Measurement Items (measured  on seven-point, Likert-type scale)  Perceived Privacy (PRIV) 1. I feel I have enough privacy when I use these  websites.

2. I am comfortable with the amount of privacy I  have.

3. I think my online privacy is preserved when I use  these websites.

Perceived Information Control (PCTL) 1. I believe I have control over who can get access to  my personal information collected by these websites.

2. I think I have control over what personal information is released by these websites.

3. I believe I have control over how personal information is used by these websites.

4. I believe I can control my personal information provided to these websites.

Perceived Vulnerability (VULN) 1. In general, it would be risky to give personal  information to websites.

2. There would be high potential for privacy loss  associated with giving personal information to websites.

3. Personal information could be inappropriately used by websites.

4. Providing websites with my personal information would involve many unexpected problems.

Anonymity (ANYT) 1. I believe I can hide my true identity on these  websites.

2. I believe I can stay anonymous and do everything I  want on these websites.

3. I can keep my information anonymous on these  websites.

Secrecy (SCRT) 1. I believe I can conceal some information from  these websites when I want to.

2. I feel I could keep some of my personal  information secret from these websites when I feel uncomfortable providing it to them.

3. I believe I could refuse to give my personal information to these websites when I think it is too personal.

Information Sensitivity (IS)  When visiting web sites that collect information, many people find there is some information that they generally feel comfortable providing, some information they feel comfortable providing only under certain conditions, and some information is too personal that they never or rarely feel comfortable providing. Please indicate how much you agree with the following statements: 1. I do not feel comfortable with the type of  information these websites request from me.

2. I feel that these websites gather highly personal  information about me.

3. The information I provide to these websites is very  sensitive to me.

Expectation of Information Practices (EXP) 1. In general, online companies should clearly reveal  how personal information is collected and used.

2. Online companies should allow their customers to  correct inaccurate personal information stored in their databases.

3. Online companies should prevent unauthorized access to personal information stored in their databases.

4. Without their customers? consent, online companies should never share customers? personal information with other parties.

