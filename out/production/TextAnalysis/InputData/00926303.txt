Mining Association Algorithm with Threshold Based on ROC Analysis

Abstract  The mining association algorithm is one of the most im- portant data mining algorithms to derive association rules at high speed from huge databases. However, the algo- rithm tends to derive those rules that contain noises such as stopwords then some systems remove the noises using noise filters. We have been improving the algorithm and developing navigation systems for semi-structured data us- ing the algorithm, and we also use a dictionary to remove noises from derived association rules. In order to derive ef- fective rules, it is very important how to determine system parameters such as threshold values of the minimum sup- port and the minimum confidence. Then we have adapted the ROC analysis to the algorithm on our navigation sys- tems and evaluated the performance of derived rules. In this paper, we import the parameters from the ROC anal- ysis into the algorithm to propose extended mining associ- ation algorithms. Moreover, we evaluate the performance of our proposed algorithms using a experimental database and show how our proposed algorithms can derive effective association rules. We also show that our proposed algo- rithms can remove stopwords automatically from raw data.

1. Introduction  In the research fields of data mining[3, 5] and text mining[4], various algorithms have been proposed to dis- cover interesting patterns, rules, trends and representations in various databases. Many algorithms can derive just quite simple patterns or rules as knowledge, so it is very hard to derive meaningful rules or knowledge in the viewpoints of human experts. However, even these simple patterns or rules may be helpful for beginners who don?t have much background or domain knowledge of the interesting topics.

Focusing on the basic algorithm of association rules [1, 10], we have been developing navigation systems for semi-structured data like as bibliography and Web page.

Our navigation system provides associative keywords with a query to users and provides helpful functions to begin- ners as shown in Figure 1[7]. However, it is rather difficult for the administrator to determine system parameters such as the minimum support threshold Minsup and the min- imum confidence threshold Minconf , which are used in the mining association algorithm[1, 10]. Therefore we pro- posed a method which specifies the optimal values for the thresholds based on the ROC (Receiver Operating Charac- teristic) analysis[2, 8] and evaluated the performance of our proposed method based on the experimental results from our bibliographic navigation system[6]. As the result from these researches, we found that the parameters used in the ROC analysis can be used as thresholds to derive associa- tion rules effectively.

In this paper we extend the mining association algorithm to propose methods which are based on the parameters in the ROC analysis and can derive more effective association rules than the original algorithm. And we evaluate the per- formance of our proposed methods in the view point of the ROC analysis[6]. In Section 2 we summarize the mining association algorithm. In Section 3 we define several pa- rameters for the ROC analysis and propose a model in order to adapt the method to our experimental bibliographic nav- igation system. In Section 4 we propose extended mining association algorithms based on the ROC analysis. In Sec- tion 5 we evaluate the performances of our algorithms based on the experimental results from INSPEC database. Finally, we make concluding remarks in Section 6.

2. Mining Association Algorithm  The mining association algorithm well known as ?Apriori?[1] is one of the most popular data mining algo- rithms. The mining association algorithm requires two pa- rameters support and confidence to derive rules. Given a set of transactions, where each transaction is a set of items, an association rule is represented by an expression X ? Y , where X and Y are sets of items and X ? Y = ?. The intuitive meaning of such a rule is that transactions in the  0-7695-0981-9/01 $10.00 (c) 2001 IEEE 1     Query window Result window  Figure 1. Our navigation system for semi-structured data  database which contain the items in X tend to also con- tain the items in Y . The support of the rule X ? Y is the percentage of transactions that contain both X and Y , hence p(X?Y ). And the confidence of the rule X ? Y is the percentage of transactions that contain Y in transactions which contain X , hence p(Y | X).

Adapting this algorithm to a bibliographic database, we adjust keyword to item and adjust tuple to transaction in the database. And let?s assume the following:  Definition  T : An attribute used as a retrieval region.

Q: A set of keywords given in a query.

R: A set of keyword sets derived from Q as as-  sociation rules in the database.

B: A set of tuples which contain Q in T .

KB : A set of all keywords in T of B except the  keywords in Q.

KC : Any combinations of KB .

C: A set of tuples which contain both Q and  KC in T of the database.

U : The set of all tuples in the database.

Support of KC , which is denoted by support(KC), is given by the ratio of | C | to | U |:  support(KC) = | C || U | . (1)  While confidence of KC , which is denoted by confidence(KC), is given by:  confidence(KC) = | C || B | . (2)  Thus if KC holds both support(KC) not less than Minsup and confidence(KC) not less than Minconf , then the keyword set KC is stored into R as an association rule enough to cause demands. Where Minsup is the min- imum threshold of support to judge whether the keyword set holds enough retrieval needs, and Minconf is the min- imum threshold of confidence to judge whether the key- word set holds enough confidence.

3. ROC Analysis  ROC graphs have been used in the signal detection the- ory to depict tradeoffs between the hit rate and the false alarm rate. ROC graphs illustrate the behavior of a clas- sifier without regard to class distribution or error cost, and so they decouple classification performance from these factors[2, 8].

3.1. ROC Graph  It is assumed that a instance can be classified into two in- stance classes: the positive instance class P or the negative instance class N , and positive y (yes) or negative n (no) are assigned by a classifier.

0-7695-0981-9/01 $10.00 (c) 2001 IEEE 2     False Positive rate  T ru  e Po  si tiv  e ra  te  0 0.5 1   0.5 A  B  C  D  Figure 2. An ROC graph of four classifiers  We also assume that p(c | I) is the posterior probability that instance I is positive c. Then the true positive rate TP of a classifier is given by:  TP = p(y | P ) ? positive correctly classified  total positives . (3)  While the false positive rate FP of a classifier is given by:  FP = p(y | N) ? negative incorrectly classified  total negatives . (4)  Focusing on the concepts of ROC curves in an ROC graph, FP is plotted on the X axis and TP is plotted on the Y axis on a graph for several instances, we can draw monotone curves which are shown in Figure 2.

Moreover, TP is higher and the point is located in the upper area of the ROC graph, then it represents that an in- stance is classified correctly by the classifier. While the right point (FP is higher) represents that an instance is clas- sified incorrectly by the classifier. Therefore the ROC curve near the area of higher TP and lower FP , that is the most upper left line, must be better. For example, we can con- clude that the curve A is better than the curve D, because the curve A dominates the curve D in all points.

3.2. ROC Analytical Model of Bibliographic Navi- gation System  In order to adapt the ROC analysis to a bibliographic database, let?s assume that  ? is the set operator of union,  U The universal set of all bibliographies B A set of bibliographies covered by a query keyword set of Q R  U  : : :   B  j  B R2  B R2  |B R |jTP = |B|  B  |B R |jFP = |B|  R1  R  R3  A set of biblipgraphies covered by a keyword r  derived from Q, where j = 1,2,3,...j  Figure 3. Status of bibliographies covered by keywords in a bibliographic database.

? is the set operator of intersection, || is the set operator to  count the number of items, and the following:  Definition Q: A set of keywords given in a query.

B: The set of bibliographies covered by Q.

m: The number of keyword sets derived from  Q.

Kj : The j?th keyword set derived from Q  (1 ? j ? m).

Rj : The set of bibliographies covered by Kj .

Figure 3 shows a status of coverage by B and Rj in the universal set U , which contains all bibliographies in the database. In a retrieved set, the positive instance is those B that decreases the number of bibliographies and the nega- tive instance is those B that increases the number of them.

Thus the true positive instance is B??mj=1 Rj , and the false positive instance is B ? ?mj=1 Rj . For instance, in Figure 3 the true positive instance is B ? R2 and the false positive instance is B ?R2.

Then, TP is represented by:  TP = | B ? ?mj=1 Rj |  | B | , (5)  and FP is represented by :  FP = | B ? ?mj=1 Rj |  | B | . (6)  Using the definitions of TP and FP , we could illus- trate ROC graphs by plots of points (FP, TP ) using dif- ferent Minsup or Minconf values as classifiers. Then by applying the ROC convex hull method[8] to the ROC graphs, we can choose the best classifier based on the value of Minsup[6].

0-7695-0981-9/01 $10.00 (c) 2001 IEEE 3     False Positive rate  T ru  e P  os iti  ve r  at e  0 0.5 1   0.5  closely associative  rarely associative  ho m  og en  eo us  heterogeneous  Figure 4. Semantic property of a position on the ROC graph  4. Thresholds Based on ROC Analysis  Thinking about the semantic property of a position on the ROC graph, a rule positioned nearer to the upper line TP = 1 covers the same space as the query, and a rule positioned nearer to the most right line FP = 1 covers the different space from the query in the retrieval. So it can be thought that TP shows homogeneousness and FP shows heterogeneousness as shown in Figure 4. Therefore a rule positioned near to the most upper left point (0, 1) has weaker heterogeneousness and stronger homogeneous- ness, then it is closely associative with the query, for exam- ple they may be the words appeared in an idiom. While a rule positioned near to the most lower right point (1, 0) has stronger heterogeneousness and weaker homogeneousness, then it is rarely associative with the query, for example it may be used in a domain different from that of the query.

Hence when the rules derived from the query are plotted on the ROC graph according to their (FP ?, TP ?), it can be visualized how each rule is associative with the query.

Where TP ? and FP ? for each rule Kj are provided by the equations:  TP ? = | B ? Rj |  | B | , (7)  FP ? = | B ? Rj |  | B | . (8)  Focusing these parameters, it is found that TP ? is equiv- alent parameter to confidence used in the mining associa-  False Positive rate  T ru  e P  os iti  ve r  at e  0 0.5 1   0.5  Minconf  FP Threshold  Rule  Figure 5. Association rules cutoff by FP threshold  tion algorithm, thus the rules must be plotted on the upper area of the threshold line TP ? = Minconf on the ROC graph. While FP ? is never used in the mining association algorithm, even though FP ? is effective parameter in the ROC analysis. If some thresholds are given to make use of FP ? in the mining association algorithm, it is thought that there is some possibility of deriving more effective rules.

Because the thresholds can classify the heterogeneousness between a query and the rule according to the semantic property. Therefore two parameters can be given for FP ?  as the thresholds.

One is a maximum threshold of FP , which is calculated  by the equation (8). A rule which holds higher value of FP ? has stronger heterogeneousness and then it is rarely associative with the query even when the rule holds high value of TP ?. Because those rules that appear frequently in the retrieval space tend to become stopwords[9]. Hence the rules which hold value of FP ? more than the maximum threshold MaxFP should be removed as shown in Figure 5, and the algorithm based on FP is summarized by the following steps:  Algorithm 1 Mining association algorithm based on FP  1. Derive rules by the mining association algorithm.

2. Select rules which hold values of FP ? not more than MaxFP from the rules.

Another parameter is a minimum threshold of ROC distance, which is represented by dROC in this paper.

0-7695-0981-9/01 $10.00 (c) 2001 IEEE 4     False Positive rate  T ru  e P  os iti  ve r  at e  0 0.5 1   0.5  Minconf  ROC Threshold  Rule  Figure 6. Association rules cutoff by ROC threshold  d?ROC is the distance between a point (FP ?, TP ?) and the  point (1, 0) on the ROC graph, and given by:  d?ROC = ?  TP ?2 + (1.0 ? FP ?)2. (9) Since dROC can evaluate the performance of derived rules[6], the rule which holds the higher value of d?ROC is expected to keep the higher performance. Hence the rules which hold value of dROC less than the minimum threshold MinROC should be removed as shown in Figure 6, and the algorithm based on dROC is summarized by the following steps:  Algorithm 2 Mining association algorithm based on dROC  1. Derive rules by the mining association algorithm.

2. Select rules which hold values of d?ROC not less than MinROC from the rules.

5. Performance Evaluation  In order to evaluate the performance of our algorithms, we have used INSPEC database, which contains 331,504 bibliographic titles published by INSPEC in 1998, for many queries. In the database, keywords are represented by the regular expression:  [a-zA-Z0-9]+  and all of uppercase letters are mapped into lowercase let- ters in the index searches so that case sensitivity is ignored.

1 10 100 1000 10000 100000  F re  qu en  cy n  um be  r  Frequency order  Figure 7. The frequency of commonly used keywords in the attribute Title and the cate- gories separated by boundaries  Then we derived association rules from sufficient num- ber of those keywords which appeared in the attribute Title on the database. Table 1 shows an example of association rules, which are associative keywords, derived from a key- word ?knowledge? as a query. And each column in the table is sorted in order of confidence (TP ?), FP ? and d?ROC re- spectively.

As shown in Table 1, the original algorithm tends to de- rive those words which are prepositions or have little se- mantic content, for example ?of?, ?for? and ?and?. Such word is called as stopword[9]. Since stopwords appear in many documents, and are thus not helpful for retrieval, it is required that these terms are removed from the internal model of a document or query. Some systems have a pre- determined list of stopwords. SMART[9] system, which is one of the first and still best IR systems available, has a list of 570 stopwords. However, stopwords could depend on context. For example the word ?system? would probably be a stopword in a collection of computer science journal articles, but not in a collection of articles from WWW.

Using the stopwords list, we would evaluate how our al- gorithms are effective to derive association rules. In Table 1, keywords in italics are stopwords listed in SMART sys- tem. And it is found that both Algorithm 1 and Algorithm 2 derive keywords not in the stopword list are above stop- words in rank. Hence if appropriate thresholds are given for Algorithm 1 or 2 and lower ranked keywords are removed, stopwords will be removed automatically and the derived rules will contain little stopwords.

In order to evaluate properties of the proposed algo- rithms, we examined results derived from sufficient number  0-7695-0981-9/01 $10.00 (c) 2001 IEEE 5     Table 1. Association rules and ROC distances of them derived from a keyword ?knowledge?.

Original algorithm (confidence/TP ) Algorithm 1 based on FP Algorithm 2 based on dROC  Order keyword confidence dROC keyword FP ? dROC keyword d?ROC dROC 1 of 0.359756 0.585520 image 0.010558 0.989517 based 1.006857 1.006857 2 for 0.357143 0.682527 information 0.010785 0.981050 information 0.990688 1.013293 3 and 0.310105 0.770465 models 0.011034 0.971406 image 0.989517 1.006305 4 a 0.309233 0.823405 modeling 0.011097 0.961952 models 0.989091 0.999904 5 based 0.304878 0.873307 process 0.011600 0.954512 modeling 0.989014 0.994384 6 the 0.249129 0.889206 neural 0.012029 0.946889 process 0.988844 0.992641 7 in 0.245645 0.916425 development 0.012284 0.941721 development 0.988460 0.990514 8 system 0.143728 0.919563 algorithm 0.012387 0.932910 neural 0.988340 0.988971 9 systems 0.115854 0.923652 network 0.014236 0.927067 algorithm 0.987712 0.982448  10 to 0.111498 0.934984 as 0.014587 0.917555 network 0.985950 0.978857 11 on 0.097561 0.935967 simulation 0.015008 0.908688 as 0.985693 0.972798 12 an 0.097561 0.940047 networks 0.015217 0.902118 simulation 0.985146 0.964533 13 using 0.092334 0.948166 applications 0.01536 0.891600 networks 0.985085 0.960036 14 design 0.067944 0.950711 application 0.016491 0.885490 approach 0.984930 0.962338 15 from 0.064460 0.958273 approach 0.016906 0.887760 applications 0.984697 0.954397 16 approach 0.060105 0.959136 data 0.017566 0.888003 application 0.983929 0.953711 17 information 0.054007 0.960841 power 0.021837 0.875434 data 0.983602 0.959144 18 data 0.047909 0.962526 new 0.023366 0.862282 power 0.978239 0.947732 19 with 0.047038 0.966343 design 0.024643 0.865618 design 0.977721 0.948882 20 model 0.039199 0.966320 method 0.024770 0.855152 new 0.976734 0.938115 21 development 0.038328 0.966306 control 0.031469 0.846755 method 0.975454 0.929927 22 control 0.033972 0.967140 study 0.031487 0.828988 control 0.969127 0.923048 23 by 0.030488 0.971279 model 0.034187 0.821813 study 0.968669 0.908088 24 process 0.029617 0.971269 from 0.036818 0.817730 system 0.966644 0.911843 25 application 0.028746 0.971266 analysis 0.038610 0.805403 model 0.966608 0.904343 26 neural 0.027003 0.972128 based 0.040411 0.887428 from 0.965337 0.904076 27 networks 0.024390 0.972984 systems 0.041661 0.894615 systems 0.965316 0.910620 28 as 0.023519 0.973830 system 0.044101 0.902095 analysis 0.961617 0.902095 29 method 0.020906 0.973823 an 0.055029 0.900671 an 0.949994 0.900671 30 analysis 0.020906 0.974678 using 0.057941 0.906396 using 0.946574 0.906396 31 network 0.019164 0.975526 by 0.069958 0.887954 to 0.935935 0.904398 32 study 0.017422 0.975524 to 0.070730 0.887708 by 0.930542 0.887708 33 simulation 0.017422 0.975516 with 0.088144 0.875521 with 0.913068 0.875521 34 models 0.015679 0.975506 on 0.127469 0.866884 on 0.877969 0.866884 35 modeling 0.014808 0.975498 for 0.215625 0.909067 for 0.861856 0.909067 36 new 0.013937 0.975476 a 0.216700 0.918953 a 0.842131 0.918953 37 algorithm 0.013937 0.975471 the 0.276190 0.936043 and 0.777113 0.942133 38 power 0.012195 0.975434 and 0.287441 0.956716 the 0.765484 0.956716 39 image 0.012195 0.975420 in 0.290129 0.969058 in 0.751171 0.969058 40 applications 0.011324 0.975414 of 0.538038 0.975414 of 0.585520 0.975414  Table 2. Categories of retrieval keywords.

category frequency keyword number sampling rate average of derived  keyword number 1 10000 ? 10 10 72 2 3163 ? 9999 81 20 74 3 1000 ? 3162 392 20 71 4 317 ? 999 1086 20 63 5 100 ? 316 2073 21 56 6 32 ? 99 3722 37 50 7 10 ? 31 6894 69 27 8 ? 9 72231 ? ?  0-7695-0981-9/01 $10.00 (c) 2001 IEEE 6                0 10 20 30 40 50 60 70 80 90 100  C on  te nt  b y  pe rc  en ta  ge [%  ]  Range of derived keywords [%]  confidence FP  ROC distance  Figure 8. Total average percentage of stop- words contained the derived keywords for each query.

of queries which contain keywords appeared in attribute Ti- tle. The frequency of keywords in Title sorted in order is shown in Figure 7, but words in the stopword list are re- moved. And we divide the frequency in log scale equally on the graph in Figure 7 to categorize keywords into sev- eral classes in order to observe deriving tendencies for each category. Each category in Table 2 is equivalent to each sep- arated area in Figure 7 respectively. We selected keywords randomly to sample about not less than 1 % of keywords in each category as shown in the field ?sampling rate? in Table 2. And Minsup and Minconf are given by:  Minsup = 0.000001 (10) Minconf = 0.01. (11)  Figure 8 shows the average percentage of stopwords con- tained in the derived keywords for each query, where each number of derived keywords is adjusted to the range of 100%. So it is found that our algorithms always make the content by percentage of stopwords lower level than the original algorithm, and there was the same tendency for each category.

Looking at Figure 8 and Table 1, it seems like our al- gorithms tend to derive similar rules. However, as shown in Figure 9 which shows the average of ROC performance of the derived rules, the curve drawn by Algorithm 2 dom- inates the curve drawn by Algorithm 1 in all points. This means that Algorithm 2 always keeps higher performance than Algorithm 1.

Figure 9 also shows that the curves drawn by our algo- rithms cross the curve drawn by the original algorithm. So it seems like the ROC performances of the keywords in rank under 38% derived by our algorithms are worse than the original algorithm. But the cause is that our algorithms begin to derive stopwords in such lower rank as shown in  0.75  0.8  0.85  0.9  0.95   1.05  0 10 20 30 40 50 60 70 80 90 100  R O  C d  is ta  nc e  Range of derived keywords [%]  confidence FP  ROC distance  Figure 9. Total average ROC performance of the derived rules.

0.75  0.8  0.85  0.9  0.95   1.05  0 10 20 30 40 50 60 70 80 90 100  R O  C d  is ta  nc e  Range of derived keywords [%]  confidence FP  ROC distance  Figure 10. Total average ROC performance of the derived rules without stopwords.

Figure 8 and Table 1, while the original algorithm begins to derive effective keywords. However, it is no longer needed to derive such meaningless keywords in the lower rank.

Therefore our algorithms, especially Algorithm 2, can keep higher performance than the original algorithm.

Moreover, Figure 10 shows the average of ROC perfor- mance of the derived rules after stopwords are removed. In this case, the curve drawn by Algorithm 2 dominates the curves drawn by Algorithm 1 and the original algorithm then Algorithm 2 can always keep higher ROC perfor- mance than the other algorithms.

While the curve drawn by Algorithm 1 is dominated by the curve drawn by the original algorithm. Then Algorithm 1 does not always keep higher performance than the original algorithm if those keywords which hold lower performance such as stopwords are removed by some filtering method.

Thus Algorithm 1 can be used effectively to remove rules which show heterogeneousness without any filters.

0-7695-0981-9/01 $10.00 (c) 2001 IEEE 7     6. Conclusion  In this paper, we proposed additional thresholds, which are the maximum FP threshold and the minimum ROC distance threshold, based on the ROC analysis for the min- ing association algorithm and evaluated the performance of them. As the results, our algorithms can remove noises such as stopwords automatically and keep higher perfor- mance than the original algorithm in the view point of the ROC analysis. Especially the algorithm based on the ROC distance threshold can keep the highest performance and derive the most effective association rules.

