Toward Real-Time In-Home Activity Recognition Using Indoor Positioning Sensor and Power Meters

Abstract?Automatic recognition of activities of daily living (ADL) can be applied to realize services to support user life such as elderly monitoring, energy-saving home appliance control, and health support. In particular, ?real-time? ADL recognition is essential to realize such a service that the system needs to know the user?s current activity. There are many studies on ADL recognition. However, none of these studies address all of the following problems: (1) privacy intrusion due to the utilization of high privacy-invasive devices such as cameras and microphones; (2) limited number of recognizable activities; (3) low recognition accuracy; (4) high deployment and maintenance costs due to many sensors used; and (5) long recognition time. In our prior work, we proposed a system which solves the problems (1)? (4) to some extent by using user?s position data and power consumption data of home electric appliances. In this paper, aiming to solve all the above problems including (5), we propose a new system by extending our prior work. To realize ?real-time? ADL recognition while keeping good recognition accuracy, we developed new power meters with higher sensing frequency and introduced new techniques such as adding new features, selecting the best subset of the features, and selecting the best training dataset used for machine learning. We collected the sensor data in our smart home facility for 11 days, and applied the proposed method to these sensor data. As a result, the proposed method achieved accuracy of 79.393% in recognizing 10 types of ADLs.



I. INTRODUCTION  In recent years, sensing devices such as smartphones and smart watches have become widespread, and many studies have been conducted to recognize various human activities using these devices. In particular, recognizing activities of daily living (ADL) in a home is expected to realize living support services such as elderly monitoring [1] and energy- saving home appliance control [2][3].

In order to realize these services, it is important to recognize target activities with high accuracy and quickly among various activities that can occur in daily life. In this paper, we aim to recognize ADLs related to elderly monitoring and energy- saving home appliance control in real-time with high accuracy.

There are many studies on ADL recognition. However, none of these studies address all of the following problems required to recognize our target ADLs: (P1) privacy intrusion due to the utilization of high privacy-invasive devices like cameras and microphones; (P2) limited number of recognizable activities; (P3) low recognition accuracy; (P4) high deployment and maintenance costs due to many sensors used; and (P5) long recognition time.

In our prior work [4], we proposed a method for recognizing ADLs using user?s position and appliances? power consump- tion data. The method achieved recognizing 10 kinds of ADLs with more than 90 % accuracy by coping with the problems P1 to P4. However, this method requires 5 minutes observation to recognize each activity. Thus the problem P5 is not solved.

In this paper, we extend our prior work and propose a new method that can solve the problems P1 to P5 by developing new sensors with higher sensing frequency. Using small time window of sensor data for real-time recognition will reduce the recognition accuracy. To cope with the problem, we introduce new techniques: adding new features and selecting effective subsets of features and training data for machine learning.

To collect the data for building classifier and conducting evaluation, we asked four participants to spend usual daily life in our smart home facility for two or three days each.

The total of 11 days data are labeled with 16 kinds of ADLs (cooking, dining, cleaning room, sleeping, going out, dishwashing, working with PC, bathing, watching TV, reading, cleaning bathroom, playing TV game, operating smartphone, washing, face washing, and other) at 10 second intervals.

Among 16 kinds ADLs, we selected 10 important activities and applied our proposed method to them. The selected activities are cooking-related, dining, cleaning room, sleeping, going out, working with PC, bathing-related, watching TV, washing-related and other. We used Random Forest as a machine learning algorithm. We conducted leave-one-day-out cross-validation. As a result, our method achieved 75.122% accuracy on average by using position and power consumption data. When we used the selected subset of training data for learning, the average accuracy was improved to 75.548%.

Moreover, when we selected the most effective features, the accuracy was further improved to 79.393%.



II. RELATED WORK  This section surveys existing studies on ADL recognition and shows the difference from our study.

Brdiczka et al. [5] proposed a method using an ambient sound sensor and a 3D video tracking sensor, and achieved recognition accuracy ranging from 70% to 90%. Ouchi et al.

[6] proposed an indoor-outdoor activity recognition method with accelerometer and microphone of a smartphone. They achieved classification of 8 ADLs with 85 % accuracy on  The First International Workshop on Pervasive Smart Living Spaces 2017     average. The above methods achieve a high recognition accu- racy, but they may violate user?s privacy because high privacy- invasive devices like camera and microphone are used for recognition.

To protect users? privacy, many methods using low privacy- exposure sensors have been proposed. Kalantarian et al. [7] proposed a method for monitoring eating habits using a necklace embedding a piezoelectric sensor. Maekawa et al. [8] focused on the magnetic field generated by home appliances when used, and proposed a method of recognizing ADLs such as ?watching TV,? ?shaving,? ?operating mobile phone,? ?tooth-brushing,? and ?cleaning room with a vacuum? using a wearable magnetic sensor. However, the above mentioned approaches are limited to few activities such as eating habits and ones entailing appliances operation.

To increase the number of recognizable activities, use of many different sensors is considered. Kasteren et al. [9] designed a system for recognizing many types of ADLs includ- ing ?eating,? ?watching TV,? ?going out,? ?using the toilet,? ?taking showers,? ?doing the laundry,? and ?changing clothes? in a smart home deploying door sensors, pressure-sensitive mats, float sensor, and temperature sensor. The recognition accuracy of their system ranges from 49% to 98%. This method can recognize many types of ADLs, but takes high initial deployment cost and the recognition accuracy for some activities is not satisfactory.

Chen et al. [10] designed a system for recognizing complex living activities such as ?making coffee,? ?cooking pasta,? ?watching TV,? ?taking a bath,? and ?washing hands? in a smart home deploying contact, motion, tilt and pressure sensors. Their system achieved high recognition accuracy of 94.44%. Fleury et al. [11] designed a system for recognizing ADLs in Health Smart Home that deploys multiple types of sensors. However, these methods require many sensors and overall system cost and maintenance cost will be high.

Although many existing studies used a supervised learn- ing and construct activity recognition models from labeled datasets, some other methods use unsupervised learning like ontology-based methods [12] [13]. For example, Riboni et al.

[12] proposed an unsupervised method to recognize complex ADLs exploiting the semantics of activities, context data, and sensing devices. However, this method requires a relevant knowledge engineering effort to define a comprehensive ontol- ogy. This method is promising because it does not require the labeling task which takes heavy human labor, but currently this method does not solve some of the problems P1 to P5 such as cost and accuracy.

On the other hand, there are many studies for detecting which appliance is used at each time in a home. Gupta et al. [14] proposed a new solution for automatically detecting and classifying the use of electronic devices in a home from a single point of sensing. It is clear that there is a close relationship between electric appliances to be used and human activities. However, activities that do not use appliances such as eating cannot be recognized only from the use of appliances.

To solve the problems in existing studies (P1 to P4 in  Section 1), in our prior work [4], we proposed a method utilizing only power meters attached to appliances and a positioning sensor attached to a user. The method targeted 10 different ADLs which cover most time of our daily life at home, and achieved 97.6% average recognition accuracy.

We also showed the possibility to make the system low cost by using cheap-medium-accuracy positioning sensor [4].

However, this method needs a long time (five minutes) to recognize each activity, that means this system does not solve the problem P5 (real-time recognition).

As mentioned, the existing studies (including our prior work) on ADL recognition did not solve the problems P1 to P5 described Section 1.



III. PRIOR WORK AND UNSOLVED PROBLEMS This section first describes our prior work on the ADL  recognition system using position and power consumption data (called?Ueda?s method,? hereafter) [4], then clarify the problems which have not yet been solved.

To solve the problems P1 and P4, Ueda?s method uses indoor positioning sensor attached to user and power meters attached to appliances that are relatively less privacy-invasive than cameras/microphones and expected to be widespread in the future. Sampling periods of positioning sensor and power meter used in Ueda?s method are 0.5 seconds and 30 seconds, respectively. To solve the problems P2 and P3, Ueda?s method records sensor data of multiple activities, extracts training data for each activity, selects effective features for training data, and constructs appropriate recognition models. Target activities of Ueda?s method are the following 10 activities that cover about 90 % of daily life in the experiments: cooking, eating, watching TV, washing dishes, taking bath, working/studying with PC, sleeping and going out.

Although Ueda?s method solves the problems P1 to P4 to some extent, it does not solve the problem P5 since five minutes are required to recognize activities. Also, sampling period of power meters used in Ueda?s method is 30 seconds, it is not possible to reduce the recognition time to less than 30 seconds.

In [4], evaluation for accuracy was done only for the extracted samples (not for the whole time of daily life).

For real-time ADL recognition, it is desirable to know how accurately activities can be recognized for the whole time of daily life. In addition, Ueda?s method targets 10 ADLs but we confirmed that other ADLs happen as we repeat data collection experiments.

In the following sections, aiming to solve the problem P5 in addition to P1 to P4, we propose a new ADL recognition method and evaluate it in more realistic conditions, e.g., for the whole time of daily life with more types of ADLs.



IV. PROPOSED METHOD TOWARD REAL-TIME ADL RECOGNITION  In this section, we propose a new method for real-time ADL recognition consisting of new power meters with high sensing frequency, enhanced target activities, and new analysis method.

The First International Workshop on Pervasive Smart Living Spaces 2017    Fig. 1. The furniture layout in the smart home  A. Sensors  We developed new power meters of two types and use them with the existing Ultrasonic indoor positioning sensor for ADL recognition.

1) Power meters: As new power meters, we employed Bluetooth Watt Checker of RATOC Systems Inc. 1 that has a plug connected to a power outlet on the wall, and can measure and send to PC via Bluetooth the power consumption of appliance that is connected its own outlet. We developed a program for sending all the measured data to our server via Bluetooth every second based on the sample program offered by RATOC Systems. These sensors were used in 9 places shown in Fig.1 by filled circles and boxes (air conditioner in bedroom, outlet on the desk in bedroom, extension cord in bedroom, refrigerator, microwave, electric pot, rice cooker, TV, extension cord in living room). Here, to empty outlets, PC, a vacuum, etc. can be connected.

2) Current Transformer (CT) sensors: We implemented the current transformer sensors using Arduino boards and attached them to almost all power systems of the distribution board.

Each sensor board can measure four power systems at the same time. The sampling period of these sensors is one second. All the measured data are sent to our server via ZigBee. We collect data from twelve power systems: (i) IH heater, (ii) electric water heater, (iii) air conditioner in living room, (iv) bathroom dryer, (v) lighting in living room, kitchen and bedroom, (vi) outlets in corridor and refrigerator, (vii) air conditioner in bedroom, (viii) outlets in bedroom, (ix) lighting in entrance, corridor, bathroom, lavatory and changing room, (x) outlets in changing room and washer, (xi) outlets in kitchen, and (xii) outlets in living room.

B. Target Activities  Toward more realistic understanding of daily life, we increased the number of ADL types for labeling to 16: ?cooking,? ?dining,? ?cleaning room,? ?sleeping,? ?going out,?  1http://www.ratocsystems.com/products/subpage/btwattch1.html  TABLE I RE-CLASSIFIED ACTIVITIES  Before After cooking cooking-related  dishwashing cooking-related bathing bathing-related reading no label  cleaning bathroom bathing-related playing TV game watching TV  operating smartphone no label washing washing-related  face washing washing-related  ?dishwashing,? ?working with PC,? ?bathing,? ?watching TV,? ?reading,? ?cleaning bathroom,? ?playing TV game,? ?operat- ing smartphone,? ?washing,? ?face washing,? and ?no label?.

Then, for accurate recognition, we re-classify these 16 types to 10 types of activities: ?cooking-related,? ?dining,? ?cleaning room,? ?sleeping,? ?going out,? ?working with PC,? ?bathing- related,? ?watching TV,? ?washing-related,? and ?no label.? These 10 types of activities are our target for recognition. The re-classified target activities are shown in TABLE I.

New label ?cooking-related? is introduced because ?cook- ing? and ?dishwashing? are similar activity and difficult to distinguish. Similarly, ?cleaning bathroom? and ?bathing? are similar and hard to distinguish, so ?bathing-related? activity is newly introduced to cover them. ?Reading? and ?operating smartphone? are re-classified to ???no label? because these activities are hard to recognize with sensors used in our method and they are not very important for the daily living support services such as energy-saving home appliance control and elderly monitoring. ?Playing TV game? is re-classified to ?watching TV? because whether playing a game or not is not very important for our target living support services. ?Wash- ing? activity corresponds to putting in/ taking out clothes to/from a wash machine and cannot recognize it from power consumption of the wash machine. Thus, ?washing? and ?face washing? that happen in the same place are hard to distinguish with our sensors. So, we introduced ?washing-related? activity to cover them.

C. Analysis Method  We extract the training and test data from all collected data consisting of the position and power consumption data. We construct a classifier using the training data using machine learning. As an algorithm, we empirically use Random Forest algorithm based on our prior work [4]. We then evaluate the recognition accuracy using the test data.

For machine learning, we use the following features.

? The explanation variable : user?s position data (x-, y- , and z-coordinates) and power consumption data of home electric appliances (9 types) and power systems (12 types)  ? The objective variable : activity label (10 types of activ- ities)  The First International Workshop on Pervasive Smart Living Spaces 2017    TABLE II GINI IMPORTANCE OF ALL FEATURES  Feature?s name type*1 Importance x PS 3572.762 y PS 1738.734 TV PM 1549.456 lighting in five spots*2 CT 1502.311 outlets in bedroom CT 1488.203 z PS 1411.559 IH heater CT 1410.848 extension cord in living room PM 1340.066 lighting in three spots*3 CT 1007.354 outlets in changing room and washer CT 732.530 air conditioner in living room CT 567.898 electric water heater CT 549.575 outlets in living room CT 448.280 outlets in corridor and refrigerator CT 431.301 bathroom dryer CT 423.505 rice cooker PM 418.997 extension cord in bedroom PM 391.960 air conditioner in bedroom CT 282.763 refrigerator PM 269.325 air conditioner in bedroom PM 251.469 outlets in kitchen CT 186.321 outlet on the desk in bedroom PM 161.719 microwave PM 117.334 electric pot PM 82.041 *1 PS: positioning sensor, PM:power meter, CT:current trans-  former sensor *2 entrance, corridor, bathroom, lavatory and changing room *3 living room, kitchen and bedroom  Unlike our prior work [4], we use the whole 1 day data of daily life as the test data, aiming realistic evaluation. We also use all the data excluding the test data for training recognition models. However, there is a possibility that the recognition accuracy of specific activities that have a small number of samples may get low. To cope with this problem, we limit the number of each activity samples (10 second interval data) for training to 550, empirically (the best result was achieved in preliminary experiments). If the number of each activity samples is more than 550, we extract 550 samples used for training at random.

In addition, to improve accuracy, we remove some useless features that become noise. To investigate the effectiveness of each feature, we use the Gini importance [15]. The larger the Gini importance, the feature is more effective to the accuracy. Therefore, we can improve the recognition accuracy by removing the features with small Gini importance. We used R language [16] to calculate the Gini importance of all features. The result is shown in TABLE II. In our method, we empirically removed the features that have less than 500 of the Gini importance for training.



V. EVALUATION  To evaluate recognition accuracy of the proposed method, we conducted experiments2. This section describes the detail of the experiments consisting of data collection and experi- mental methods and results.

2The experiments were conducted with the approval of research ethics committee of NAIST.

A. Outline of experiments  We collected the dataset in our smart home testbed, which has a living room with a kitchen, a bedroom, a bathroom and changing room with a washstand and washer, and a lavatory, as shown in Fig.1. Four participants (a male in thirties, two males in twenties, a female in twenties) spent usual daily life in the smart home for two or three days each in February 2016.

Each of the participants wore an ultrasonic position transmitter.

They performed normal daily living activities while staying in the smart home. When participants exit the home for a short period of time, they keep the sensors worn. When they sleep or take a bath, they remove the sensors and place them on the side of the bed or on the washstand. During the experiment, we asked each participant to perform each of 16 pre-defined activity types at least once in his/her stay (two or three days).

Moreover, to obtain the ground-truth activity labels, the kitchen, living and bed rooms were recorded using three video cameras, two in the kitchen/living room and one in the bedroom. We built an easy labeling-support system where each participant pushes a mechanical button at the start and the end of each activity so that the timestamps are recorded in the server. The data from video cameras data were managed by each participant for privacy preservation.

After the experiment, we compiled all the sensor data into a CSV file. We then asked the participants to label each second of the the sensor data with a corresponding activity type based on the timestamps and video data recorded. For labelling support, we independently developed a Windows application that can retrieve and play back the video of the activity specified based on the recorded timestamps. Also, after the experiment, we asked participants to label to the data.

B. Data Processing  We divided the sensor data with labels into samples of 10 second time window, without considering the border between different activities. Then we calculated features for each sam- ple as follows. For the position data, we used the median value of 10 seconds as a feature. The position data was lost while the participants went out for short time. So, we complemented the lost data with the fixed value. For the power consumption data of each power meter or CT sensor, we used the mean value of 10 seconds as a feature. We removed samples containing any missing values or multiple activity labels.

We applied leave-one-day-out cross-validation to the total of 11 days data and evaluated the recognition accuracy. We used Random Forest classifier of Python library (scikit-learn [17]) to build a recognition model.

C. Experimental Results  As a result of experiments, we could obtain the data with one second resolution and build the activity recognition model using data with 10 second resolution.

We built recognition models with three cases for evaluation: (Case 1) using all data (10 days) other than test data (1 day) for training; (Case 2) using 550 samples for each activity selected  The First International Workshop on Pervasive Smart Living Spaces 2017    TABLE III THE RESULT OF CASE 1 (USING ALL DATA)  living activity N?1 P(%)?2 R(%)?3 F(%)?4  cooking-related 3744 0.897 0.914 0.906 dining 1363 0.706 0.598 0.648  cleaning room 186 0.854 0.726 0.785 sleeping 257 0.826 0.498 0.621  going out 520 0.995 0.729 0.841 working with PC 4366 0.746 0.613 0.673 bathing-related 1982 0.939 0.975 0.957 watching TV 5910 0.754 0.818 0.785  washing-related 729 0.462 0.198 0.277 no label 5575 0.611 0.724 0.663  Weighted Avg. 24632 0.752 0.751 0.746 ?1 The number of samples ?2 Precision ?3 Recall ?4 F-measure  TABLE IV THE RESULT OF CASE 2 (USING LIMITED DATA FOR TRAINING)  living activity N?1 P(%)?2 R(%)?3 F(%)?4  cooking-related 3744 0.899 0.968 0.932 dining 1363 0.706 0.814 0.756  cleaning room 186 0.805 0.887 0.844 sleeping 257 0.674 0.805 0.734  going out 520 0.941 0.948 0.944 working with PC 4366 0.725 0.639 0.679 bathing-related 1982 0.920 0.973 0.946 watching TV 5910 0.770 0.811 0.790  washing-related 729 0.401 0.626 0.488 no label 5575 0.649 0.546 0.593  Weighted Avg. 24632 0.755 0.755 0.752  at random (from 10 days data) for training; and (Case 3) using only selected features in addition to the case (Case 2).

The recognition accuracy of one day was calculated using the following formula, and the recognition accuracy of all days was the weighted average of the 11 days.

The recognition accuracy = Ttrue Tall  ? 100(%)  where Ttrue is the number of correctly classified test data samples, and Tall is the number of test data samples.

Case 1: Using all data for training: The result of Case 1 is shown in TABLE III. The average recognition accuracy (corresponding to recall in the table) was 75.122%.

Case 2: Using limited data for training: The result of Case 2 is shown in TABLE IV. The average recognition accuracy (recall in the table) was improved to 75.548%.

Case 3: Using limited data & selecting features for training: Finally, the result of Case 3 is shown in TABLE V. The average recognition accuracy (recall in the table) was further improved to 79.393%.

D. Discussion  Fig.2 shows comparison of F-measure for each activity among the three cases. We found that the accuracy was improved for almost all activities except for ?no label? by limiting the number of training samples. We also found that the accuracy was further improved by selecting only effective  TABLE V THE RESULT OF CASE 3 (USING LIMITED DATA & SELECTING FEATURES  FOR TRAINING)  living activity N?1 P(%)?2 R(%)?3 F(%)?4  cooking-related 3744 0.913 0.973 0.942 dining 1363 0.686 0.789 0.734  cleaning room 186 0.789 0.903 0.842 sleeping 257 0.698 0.934 0.799  going out 520 0.943 0.948 0.945 working with PC 4366 0.779 0.761 0.770 bathing-related 1982 0.917 0.973 0.944 watching TV 5910 0.823 0.864 0.843  washing-related 729 0.443 0.606 0.512 no label 5575 0.709 0.563 0.628  Weighted Avg. 24632 0.793 0.794 0.790  Fig. 2. Comparison between the three methods by the f-measure of each of activities  features (Gini importance of more than 500). The average accuracy of all activities except for ?no label? is 75.592% when using all data for training (Case 1), 81.681% when limiting the number of training samples (Case 2), and 86.152% when selecting features (Case 3). As you can see, we were able to confirm great improvement in accuracy.

It is important to recognize labeled activities more ac- curately than no-label activity for our target smart home services such as energy-saving appliance control and elderly monitoring. So, we believe that this result is reasonable to be applied for such services. However, as shown in Fig.2, the F-measures of ?dining?, ?cleaning room?, ?going out?, and ?bathing-related? were decreased by selecting features.

For example, ?going out? activity can be more accurately recognized with more features because basically users likely turn off all appliances (especially lights) when they go out.

For ?dining? activity, the feature of ?microwave? has greater importance than other activities. Similarly, the features of ?extension cord in bedroom? and ?outlets in corridor and refrigerator? have the greater importance for ?cleaning room? and ?bathing-related?, respectively. However, these features were not selected for Case 3 because the average importance of these features for all activities were small. Hence, we may need to rethink the Gini importance of each feature for each activity and improve recognition accuracy of specific activities by intentionally leaving some features with small Gini importance.

Fig.3 shows the confusion matrices of Case 1 (using all data), Case 2 (using limited data for training) and Case 3 (using limited data & selecting features for training). In the  The First International Workshop on Pervasive Smart Living Spaces 2017    Fig. 3. Confusion matrices of Case 1 (using all data), Case 2 (using limited data for training) and Case 3 (using limited data & selecting features for training)  figure, darker shades indicate more samples. The correctly- recognized samples are shown in the diagonal from the top- left to the bottom-right. When comparing Case 1 and Cases 2 and 3, we see that the color of the rightmost vertical column is getting thinner. This shows that there are fewer activities that are mis-recognized as ?no label? in Cases 2 and 3, while there are many mis-recognized activities as ?no label? in Case 1. Because huge number of ?no label? activities were collected including the movement between defined activities, the influence of ?no label? becomes large when all data is used for training. Approximately 22% of all data collected in this experiment are ?no label? activities. Therefore, limiting the number of training samples (Case 2) was effective because labaled activities had smaller influence by ?no label? activities.

In particular, we see that ?washing-related? was affected by ?no label? activity in Fig.3. Even though basically ?washing- related? is the activity done in changing room, it is considered that it was more susceptible to ?no label? than other activities since the accuracy of the position information of this area is low (only one ultrasonic receiver exists) and also there ?no label? activities such as change of clothes occurred many times.

For Cases 2 and 3, although there are some differences in contrasting density, there was no significant change in each confusion matrix. However, we believe that the proposed techniques (limiting training data and selecting features) are effective since there is a change when looking at the average accuracy.



VI. CONCLUSION  In this paper, we proposed a method for recognizing various ADLs in real-time with high accuracy. The proposed method used user?s position and appliances? power consumption data for recognizing the activities. To realize the real-time recog- nition, we developed used two types of new power meters. In addition, we introduced new techniques that limit the training data and select features depending on Gini importance. We collected the sensor data from four participants living two or three days each in a smart home and evaluated the proposed method. As a result, the recognition accuracy of the proposed method (limiting training data and selecting features) was 79.393%, that is about 4% improvement from the method that uses all data for training and does not select features.

This result suggests that the proposed techniques that limit training data and select features are effective to improve the recognition accuracy. In the experiment, we removed features that have low Gini importance for all activities. However, some removed features were effective to specific activities. We will consider this and improve the proposed method as part of future work.

