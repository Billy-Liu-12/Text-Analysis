An Efficient Association Rule Mining Algorithm and Business Application

Abstract-In this paper, aim at the inefficient problem of an important field of data mining and substantial researches the Apriori algorithms, we design a new matrix data have been conducted on association analysis on all aspect. A structure, called Co-Occurrence Matrix, in short COM, number of algorithms for association rule mining have been to store the data information instead of directly using the proposed in the literature. One of the most important transactional database. In COM, any item sets can be algorithms is the innovative works presented by Agrawal et randomly accessed and counted without many times full al. in [2], in which the usage of the monotone Apriori scan of the original transactional database. Based on property is introduced to reduce the candidate space. Webb[3] COM, we first divide association rule into two kinds of proposed the OPUS approach for association rules. Han et rule and then we present an efficient algorithms al.[5] construct a compact tree-structure to alleviate the (COM mining) to find the valid association rules among repeated I/ 0 scan problem and improve the frequency the frequent items. Finally we apply COM_mining itemsets generation. And many others like [6],[7]and [8] have algorithm and Apriori algorithm simultaneously to made important contributions as well. Branches of analyze up-down association relationship between association rule mining problem, such as numerical various industry stock blocks of China A stock market. association rules [9][10], sequential rules["l]'2], inter- From analytical result we can find that in China A stock transactional rules[131 and constraint-based rules[14][15], have market, there are indeed up-down association also been defined and studied.

relationship between various industry stock blocks. At In this paper, aim at the inefficient problem of the the same time, through comparing COM_mining Apriori algorithms, we present an efficient algorithms toalgorithm and Apriori algorithm in this application, we . ' . .

can see, COM_mining is more efficient than Apriori. find the valid associaton rules among the frequent items.

Instead of directly using the transactional database, we

I. INTRODUCTION design a Matrix data structure, called Co-Occurrence Matrix, in short COM, to store the data information. Based on COM,  Association rule mining is one of the most important any item sets could be randomly accessed and counted areas in data mining. The purpose of association rule mining without full scan of the original transactional database, is the discovery of association relationship or correlations . . . . .

among a set of items. The area of association rule mining which significantly increases the efficiency of association has received a great deal of attention. An association rule in rule mining. Finally apply this new algorithms to analyze the form X -* Y can be interpreted as "when user buy up-down association relationship between various industry X item also buy Y item". Because of its clear and easy stock blocks of China A stock market and find some understandable format, association rule mining is widely interested association rule.

used in transaction data analysis in business decision- making process. II. PROBLEM DEFINITION  Agrawal, Imielinski and Swami first introduced the problem of deriving categorical association rule from Let I = {il, i2 ........ i} be a set of literals called items.

transactional databases in [']. The original concern is about A subset X ( I is callednan item set. A k-item set is an to find relationships among different item sets in a market- itembset X coIns k itemLet. A transetion an basket database. Such information will be helpful for sales item set that contains k items. Let T be a transaction and purposes. Since then, finding association rules has become that itself is an item set. Define database  Sponsored by Natural science fund and Innovative team science fund of BeiJin China . Fund no (9052006) (70521001)     D = {IT, T2......T. } be a multi-set of transactions. An item 6 B,E,I,J,K set X in transaction database D has a statistical significance 8 A,C,D,E,G called support, denoted as p(x) . The support of an item set 9 D,E,G,K,L is the fraction of transactions that contains this item set, 10 A,C,D,E,G such as (1) III. A EFFICIENT ASSOCIATION RULE MINING  {T|TED,TIDX} ALGORITHM BASED ON CO-OCCURRENCE MATRIX PD( In order to avoid the drawbacks of the original  transactional database, we create a matrix structure called An association rule is an implication X -* Y, where Co-Occurrence Matrix to store the data information. As long  X and Y are item sets, and X and Y are disjoint. The item as COM is constructed, full access of original database is no set X is called the antecedent and Y is called the consequent longer necessary. Thus the algorithms designed on the base of the rule. For an association rule, there are two basic of COM are very efficient and fast.

statistical significant, support and confidence. The support of a rule is the ratio of transactions in database D A. theConstruction oftheCo-occurrenceMatrix containing both item setsX and Y, such that(2) To transform the original transactional database into  the Co-Occurrence Matrix requires two passes of the  IX -Y |{T |T ED, T D X T D }() database. The first pass of the original database is to countP{ D (2)DI the occurrence of each item and sort items into descending order according to their occurrence count. During the  The confidence of a rule is the strength of implications second pass of the original database, each transaction is and is defined as (3) sorted and then inserted into Co-Occurrence Matrix.

{TJTeD,TDX,TDY} p(X-Y) To illustrate the process, let us consider thecJX->YJ} (3) construction of the COM using our example. After the first{IT T ED TD X}I P(X) pass of the transcations, items are sorted in the descending order. And a list is created to store the count of each item.A valid rule defined by support-confidence framework  is: X -> Yisavalid ruleif ~Tab.11 shows this list. Then according min_support selectediS: X-*Y iS avalid rulei1f by users, deleting item which count smaller than (1)p(X -*Y) .mm support min support. For example, if we set min support=0.4, then (2) c(X -* Y) . min-confidence only G,E,C,A,D,B,I is keep down.

Item sets with support greater than or equal to TABLE II LIST OF ITEM COUNT  min support are called frequent item sets. So association rule mining is divided two steps: the first step is to find all Item G E C A D B I K J F H L frequent item sets from D , the second step is to find count 7 7 6 5 5 4 4 3 3 2 2 2 association rule based on frequent item sets. The first step is key step in the process of association rule mining and it finally decided the efficiency of association rule mining. Before the second pass of the database, we first  Apriori algorithms and some other improved construct a Co-Occurrence Matrix according to frequent item algorithms directly using the original transactional database in table II. It is a square matrix with the row dimension size to mining association rule, as shown in Tab.I. The equal to the number of frequent items in the database plus 1 disadvantage of this data structure is obviously. There is no and the column dimension size equal to the number of index for items, which makes it hard to count the support of frequent items in the database. During the second pass of the  an itemset. However Apriori algorithm .willprodu a original database each transaction is sorted and then insertedan itemset. However Apriori algorithm will produce a lot of ginto Co-Occurrence Matrix. In the Co-Occurrence Matrix,candidate itemset, anytime when the support of a candidate irt harOwuincates the ofthensatios itemset is desired, a full scan of the database is necessary. I the vaus in the diagoa ce are the occurrence count of finally results in the efficiency problem of Apriori  h ausi h ignlcl r h cufnecuto finallyoresults i th efiinypolm fAroi every single frequent item. The values in the lower leftalgorithms. triangle matrix cells are the co-occurrence count of any 2-  frequent item. The values in the upper right triangle matrix cells are the list of runtime occurrence counts of column item  Transaction Items 1 B,G,H,I,J in different branch starting from head row. The links are one- 2 A,C,D,E,F way links from the item with lower occurrence count point to 3 ~~~~~~~~B,C,E,F,G the item with higher occurrence count. In our example, we  4 A,C,D,E,G first created a 8*7 dimension Co-Occurrence Matrix. After 5 B,I,J,K,L     second pass of the transactional database, we can construct a For each item ii E I Co-Occurrence Matrix, as shown in Tab11. IfIsupport(i1).u then i U{i}  End if  =G E (' A\ D B1 I End for  Head 7 --Z., ii3. Sort the items of If in decreasing order according to IN7~ C L ] \ their occurrence count[i]  4. Construct a COM with size (If +1) * ( If) E \5++ Rowname- {head, i, }, i, E If  Columnname= {i,},i, eif 5. While there is a transaction T in D  Sort the items in T in decreasing order according _3 _ ______ to their occurrence count and delete items which  occurrence count smaller than min-support.

A 4 4 5 5 tAFor each item I in T  For each item J<=l in T  XIAdd 1 to the number at Cell(J,I) in the diagonal and lower left triangle matrix  B 2 21 0 0 4 1 ~~~~~~~~~~Endfor 1 If I is the first item in T then  I 2 1 1 1 0 3 4 Cell(head,I)= runtime occurrence count[I]  TABLE III CO-OCCURRENCE MATRIX Else  N= the item before I in T B. Pseudocode ofAlgorithm to Construct the Co- K= the item before N in T  Occurrence Matrix If I is the second item in T then  Name: ConstructCOM  Input: Database D, min support (T Cell(N,I)= runtime occurrence count[I]  Create link from Cell(N,I) to Cell(head,N) Output: the Co-Occurrence Matrix(COM)  Else Begin: 1. Set I be the set of items in D,  I = jij },i = 1,2........ n Cell(N,I)= runtime occurrence count[I] Set count[i]=O Create link from Cell(N,I) to Cell(K,N)  While there is a transaction T in D End if  For each item ii E I, End if  If ii E T then count[i]= count[i]+1 End for End while  End if  End for C. Algorithm that FindAssociation Rules Using COM  End while According to the size of the antecedent and the consequence of association rule, we divide association rule  2. Set If be the set offrequent items to two types of rules, the simple rules and the  Set fJ multidimensional rules.

Define 1: set X -* Y is a association rule, if the Based on 1,2-frequent item set triangle matrix in COM, number of items in X and the number of items in we can directly find all simple rules by following formula(4) Y simultaneously equal 1, we define X -* Y as simple rules  Define 2: set X -* Y is a association rule, if the c(I J) - p(I -* J)- p({I, J}) - cell(I,J) >min confidence(4) number of items in X and the number of items in Y do not p(I) p(I) cell(I, I) simultaneously equal 1, we define X -* Y as multidimensional rules. For example, if we set min confidence=0.5. because  COM combines the forest like structure and matrix into cell(G, E) 5 one and it reserve the item information as well as the c(G -> E) cell(G, ) 7 transactional information, so COM has great advantages in So G -* E is a vaiciL simpic rulc, IL S suppori -3/ 10=0.5 and the mining process. We defined association rule algorithm confidence=5/7=0.71.

based on COM as COM-ming. Association rules are mined out in two steps in COM-ming: In the second step of COM_ming, to find out all valid  multidimensional rules, we should first find out all k(k > 3)- (1)Find out all valid simple rules frequent item sets. The upper right triangle matrix of COM  (2)Find out all valid multidimensional rules stores transactional information in tree structure. So to find all k(k>3)-frequent item sets, we only need to scan some  According definition of simple rules and branches of tree structure, which is only a small part of the multidimensional rules, we knows simple rules based on 2- original database. According to the Apriori property, we frequent item sets and multidimensional rules based on knows if one item set is frequent, it's subset must be frequent.

k(k>3)-frequent item sets. Because structure advantages of So we only need to scan the branches through link from COM, we can quickly find all frequent item sets. In COM, min_occurrence count item to max_occurrence count item of every column item corresponds to all 1-frequent item sets, all 2-frequent item sets. In our example, we only need to the values in the diagonal cell are the occurrence count of scan the branches through link from column item D to every single frequent items. The values in the lower left column item G to find all k(k>3)-frequent item sets. For triangle matrix cells are the co-occurrence count of any 2- example, in upper right triangle matrix of COM, as shown in frequent items, so through comparing cells value with table III, we first scan column D to find all cells which are  * D we can not empty, then tracking the link starting from these cells tommn support C * II, we can quickly get all 2-frequent Item find all branches including at least 3 items between G and D.

sets. In our example, all 1-frequent item sets and 2-frequent we can get three branch starting from D and including at item sets be shown in Tab.IV. least 3 items between G and D, they are GED(1), ECAD(1),  GECAD(3). The number in parentheses is occurrence count of item in branch equaling to starting item D's occurrence  TABLE IV 1,2-FREQUENT ITEMSET TRIANGLE MATRIX count stored in cells. In these branches, we can find all k(k > 3)-item sets that contain item D and the items with higher occurrence count by combination, we can find item  G E C A D sets GED(4), GCD(3), GAD(3), ECD(4), EAD(4), CAD(4), GCAD(3), CEAD(3), GECD(3), ECAD(4), GECAD(3). By comparing with (min_support=0.4* IDI ), finally we can get  G 7 all k(k> 3)-frequent item sets GED(4), ECD(4), EAD(4), CAD(4), ECAD(4) that contain item D and the items with higher occurrence count. In the same way, we can get other  E 5 7 k(k> 3)-frequent item sets GCA(4), ECA(4) and GEC(4) starting from A or C. Based on all k(k > 3)-frequent item sets, we can find out all valid multidimensional rules by  C 5 5 6 comparing association rule confidence with min_confidence.

For example, if we set min_confidence=0.5, based on 3- frequent item set GED(4), we can find two valid association  A 4 4 S S rules G -* ED, GE -* D, because the following inequality  A4 ~~~~~~~~~~~~~~~~~~istrue.

c(G + ED) occurrence - count(GED) 4 2 0.5 D 4 5 4 4 5occurrence_ count(G) -70.

I ~~~~~~~~~~(GE? D) occurrence -count(GED) 4>O occurrence_count(GE) - .05     In order to further increase the efficiency of End if multidimensional rules mining algorithms, we define the following property: End for  End for  Property 1: If X -X Y is a valid rule, then X -X Z must be 2. in the upper right triangle matrix of COM a valid rule where Z c Y and Z X s Set I be the set of frequent items contained in all 2-frequent Proof: since Z is the non-zero subset of Y, then following item sets, I = {il, i2,.., in } andis always true  occurrence_count (i4 ) > .. > occurrence_count (in) p(X -> Z) =p(X U Z) . p(X U Y) =p(X -> Y)  so C(X o Z) AX 2) > AX u Y = C(X -> Y) 25 JSet ISSET be the set of item sets, ISSET = 0 p(X) p(X) Set JISSET be the set of frequent item sets, ISSET 0  so X -> Z must be a valid rule Jf~~~~ ~ ~ ~ ~~~~~ ~o eahie r i h e I,from i~to i3Property 2: If X -* Z is not a valid rule, then X YY can't For each item i in the setn  be a valid rule where Z cY For each integer C1 in column ir in upper right Proof: since Z is the subset of Y, then following is always triangle matrix of COM true  Set J1be the set of items, J1 = 0 p(X - Y) = P(X U Y) < P(X U Z) =p(X -> Z) Set J, be the set of item sets, J, =  so c(X->Y)= p(XUY) <p(XUZ) = c(X->Z).8,p(X) p(X) Start with C1 follow the links and trace back to row 'head' so X -> Y is not a valid rule  For each item i in the pt hr Property 3: If X -X Y is a valid rule, then W -X Z must be s path where i, r a valid rule where X c W c (X U Y) and J1 = J, u{iUs} (W U Z) =(X U Y) Occurrence-count (J,) = Cl Proof: End for  C(W->Z)=P(WUZ) p(XUY) p(AXUY) =c(X->Y).8,p(W) - p(W) pX() J, k(k > 3)-item sets contained in J, with ir is least item.

so W->Zmust be a valid rule If J, is not in ISSET then  In our example, because EC - AD is a valid rule, = S U,  according property 1, we can directly get EC -X A and ISSET SET EC -* D that are also valid rules. Another example, Occurrence_count (J,)=C because G -X ED is a valid rule, according property3, we Else can directly get GE -X D are also valid rules.

Occurrence-count (J,) = Occurrence_count (J,) + C1 D. Pseudocode ofCOM mining Algorithm End if  Name: COM_mining End for  Input: COM, ming_support UT,min_confidence 3 For each item set J, in ISSET Output: simple rules and multidimensional rules If Occurrence count (J,) . a then Begin: 1. in the lower left triangle matrix ofCOM IISSET = IISSET U J1  For each column J in lower left triangle matrix End if  For each row I except head row in lower left End for triangle matrix  End for If cell(I,J) > C * IDI and  cell(Icll/ ( ) r C(J,J)=/( ) 3. For each item set ISA in IISSET  Set ISC be difference of ISB and ISA Then I -* J and J -* I are valid simple rules  If occurrence_count( ISA ) > occurrence_count( ISB )* 5'     ISB - IS, is a valid multidimensional rule Figure. 1 Runing time in second needed to mine ISTD with different End if support  levels  End for From above comparing result, we can see thatCOM_mining algorithm is more efficient than Apriori

IV. EVALUATION AND EXPERIMENTAL RESULTS algorithm. When we set min_support=0.35 and  In order to test the efficiency of our algorithms, we use min-confidence=.9, we can mining the following valid our algorithms to analyze up-down association relationship association rules through using COM mining algorithm between various industry stock block in China stock market. based on ISTD, as shown in Tab.VI. These information are According to divisiory standard of industry style useful to stockjobber.

exponential of ZHONGXIN stockjobber, we divide all stocks of A market to 45 industry stock blocks and use 45 TABLE VI VALID ASSOCIATION RULES MINED FROM ISTD industry style exponential to express them. Then we select Rule sup conf up-down extent as market variable to describe up-down Electron industry up -X wiring industry up 0.36 0.95 situation of 45 industry stock blocks in every day. Further Electron industry down -X wiring industry down 0.37 0.93 more, we divide up-down extent variable to 5 different Steel industry down -X metal industry down 0.35 0.94 states variable according size of extent. They are big-up, up, auto industry up -X auto fittings industry up 0.38 0.97 equal, down and big-down. Finally, we select 1444 trade auto industry down-.auto fittings industry days between 2001-2006 year as transactions and select 45 down 0.38 0.98 industry exponential up-down extent states of every day as items. So we construct a industry stock transactional V. CONCLUSION database( ISTD), which has 1444 transactions 225 items In this paper, aim at the inefficient problem of the Apriori and an average transaction length of 45 items. algorithms, we design a Matrix data structure, called Co-  Based on ISTD, the computer we used is running on Occurrence Matrix, in short COM, to store the data WindowsXP with P4 1.8GHz processor and 512 MB RAM. information. Based on COM, we present an efficient We compare the efficiency of our algorithm with Apriori algorithm to find the valid association rules among the algorithm with different minimum support threshold. The frequent items. Finally we apply COM mining algorithms to results in Tab.V and Fig.1 show running time for mining analyze up-down association relationship between various ISTD with different support level. industry stock blocks of China A stock market and fimd  some interested association rule.

TABLE V RSEULT OF MINE ISTD WITH DIFFERENT SUPPORT  Min-support 0.35 0.25 0.1 0.05 0.025 0.01 REFERENCES Apriori 4.9 20.1 79.9 117.6 122.3 235.3 [I]R.Agrawal, T.Imielinski, and A.Swami. Mining association rules COM_mining 2.2 5.37 13.4 22.5 35 63.8 between sets of items in large database. In Proceedings of the ACM  SIGMOD Conference on Management of Data, pages 207-216,1993.

Frequent itemsets 5 30 102 256 756 4786 [2]R.Agrawal and R.Srikant. Fast algorithms for mining association rule. In  Santiago,Chile pages 487-499,September 1994.

[3]G.Webb, Efficient search for association rules. In Proceedings of runing tim insecndneeedIternational Conference on Knowledge Discovery and DataMiningruning time in second needed tomlne pages 99-107,2000.

ISTD with different support levels [4]A.Savasere, E.Omiecinski, and S.Navathe. An efficient algorithm for mining association rules in large databases. In Very Large Databases,  Apriori COM_mining pages 432-443, 1995.

250 [5]J.Han, J.Pei, and Y.Yin. Mining frequent patterns without candidategereration. In ACM-SIGMOD, Dallas, 2000  S 200 [6]S.Brin, R.Motwani and C.Silverstein, Beyond market baskets: X 150generalizing association rules to correlations. In: Proceedings of the  m 150 ACM SIGMOD Conference on Management of Data, pages 255- ioo l00264,1997.

[7]R.Agarwal, C.Aggarwal, and V.V.V.Prasad. A tree projection algorithm .~ 50 for generation of frequent itemsets. In J.Parallel and Distributed 0 Computing,2000  [8]M.Ei-hajj and O.Zaiane. Inverted matrix: efficient discovery of frequent 0. 35 0. 25 0. 1 0. 05 0. 025 0. 01 items in large datasets in the context of interactive mining. In  support (%) Proceedings of Iternational Conference on Knowledge Discovery and DataMining pages 109-118,2003.

[9]R.Srikant and R.Agrawal. Mining quantitative association rules in large ralational tables. In Proceedings of the ACM SIGMOD Conference on Management of Data, pages 1-12,1996.

[10]R.Rastogi and K.Shim, Mining Optimized association rules with categoriacl and numeric attributes. In Proceedings of Iternational Conference on Data Engineering,pages 503-512,1998  [1 I]R.Srikant and R.Agrawal. Mining Sequential Patterns: Generalizations and performance Improvements. In Proceedings of Iternational Conference on Extending Database Technology,pages 3-17,1996  [12]G.Das, K.Lin, H.Mannila, G.Renganathan and P.Smyth. Rule discover form time series. In Proceedings of knowledge discovery in databases.

Pages 16-22,1998.

[13]L.Feng, T.Dillon and J.Liu. Inter-transactional association rules for multi-dimensional contexts for prediction and their application to studying meteorological data. In Data and Knowledge Engineering,pages 85-115, 2001  [14]L.Lakshmanna, R.Ng, J.Han and A.Pang. Optimization of constrained frequent set queries with 2-variable constraints. In Proceedings of the ACM SIGMOD Conference on Management of Data, pages 157- 168,1999  [15]R.Bayardo, R.Agrawal. Constraint-based rule mining in large database.

In Proceedings of Iternational Conference on Data Engineering,pages 188-197,1999.

[16]C.Zhang and S.Zhang. Association rule mining: Models and Algorithems. Springer press, 2002  [17]M.Chen, J.Han and P.Yu. Data mining: an overview from a database perspective, In IEEE Trans. Knowledge and Data Eng. Pages 866- 881,1996.

