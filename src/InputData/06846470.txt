PLAStiCC: Predictive Look-Ahead Scheduling for Continuous dataflows on Clouds

Abstract?Scalable stream processing and continuous dataflow systems are gaining traction with the rise of big data due to the need for processing high velocity data in near real time. Unlike batch processing systems such as MapReduce and workflows, static scheduling strategies fall short for continuous dataflows due to the variations in the input data rates and the need for sustained throughput. The elastic resource provisioning of cloud infrastructure is valuable to meet the changing resource needs of such continuous appli- cations. However, multi-tenant cloud resources introduce yet another dimension of performance variability that impacts the application?s throughput. In this paper we propose PLAStiCC, an adaptive scheduling algorithm that balances resource cost and application throughput using a prediction-based look- ahead approach. It not only addresses variations in the input data rates but also the underlying cloud infrastructure. In addition, we also propose several simpler static scheduling heuristics that operate in the absence of accurate performance prediction model. These static and adaptive heuristics are evaluated through extensive simulations using performance traces obtained from Amazon AWS IaaS public cloud. Our results show an improvement of up to 20% in the overall profit as compared to the reactive adaptation algorithm.

Keywords-Continuous Dataflows; Predictive scheduling; IaaS Clouds; Elastic resource management; Stream processing

I. INTRODUCTION  There has been a tremendous rise in the capability to  collect data ? pervasively and continuously ? for a wide  range of application domains such as financial trading, social  networks, and cyber-physical systems (CPS) like Smart  Power Grids and Smart Transportation. Consequently, there  is increasing attention on data analytics frameworks that  perform continuous data processing with low latency and  guaranteed throughput. Batch processing systems[1], [2] that  deal with high volumes of slow changing data abound.

In contrast, continuous applications are characterized by  data streaming with high velocity and at variable rates,  on which multiple stages of information integration and  analytics are performed. They offer online insight to domain  experts (or their digital agents) to help detect and prevent  frauds, power outages or security situations, as may be the  case. Runtime environments for such applications demand  continuous adaptation of user logic and dynamic scaling of  resources, under changing stream workloads, to meet the  user?s quality of service (QoS) requirements.

Cloud computing platforms, especially Infrastructure-as-  a-Service (IaaS), provide flexible, on-demand resources.

Their elastic resource provisioning is well suited to scale  resources at runtime in response to changing needs of contin-  uous applications. Several stream processing frameworks[3],  [4], [5] and adaptive provisioning algorithms[6], [7], [8],  utilize this online elasticity to balance resource cost against  application performance in response to changing data rates.

However, cloud infrastructure exhibit performance vari-  ability for virtualized resources (e.g. CPU, disk, network)  as well as services (e.g. NoSQL store, message queues)  both over time and space. These variations may be caused  by factors including shared resources and multi-tenancy,  changing workloads in the data center, as well as diversity  and placement of commodity hardware[9]. For time sensitive  continuous dataflow applications, it becomes imperative to  address such fluctuations in performance to ensure that the  desired QoS is maintained. Strategies may range from simple  over-provisioning and replication to dynamic application re-  composition[8] and pre-emptive migration[10].

Proactive management of application and resource map-  ping is possible with predictive models that can forecast  resource behavior. Several performance models have been  proposed for computational Grid infrastructure that also  exhibit similar performance variability[11]. These models  use the network topology and workload characterization to  estimate the behavior of specific Grid resources[12], [13].

Similar models have also been developed for short and  medium term predictions of performance metrics for virtual  machines with varying degrees of prediction confidence  using techniques such as discrete-time Markov chain[14].

Given the ability to elastically control Cloud resources and  the existence of resource performance prediction models, the  question arises: How can we re-plan the allocation of elastic  resources for dynamic, continuous applications, at runtime,  to mitigate the impact of resource and workload variability?

In answering this question, we consider continuous  dataflows as the abstraction used to compose these con-  tinuous applications. In our previous work[8], we proposed  adaptive scheduling heuristics for online task re-composition  of dynamic and continuous dataflows as well as allocation  and scaling of cloud resources. However, these strategies  reacted to changes in workloads and resource variations to  ensure QoS targets were met. In this paper, we leverage the  knowledge of future resource and workload behavior to pro-  actively plan resource allocation, and thus limit costly and  2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing  DOI 10.1109/CCGrid.2014.60     frequent runtime adaptation. We propose a new Predictive  Look-Ahead Scheduling algorithm for Continuous dataflows  on Clouds (PLAStiCC) that uses short term workload and  infrastructure performance predictions to actively manage  resource mapping for continuous dataflows to meet QoS  goals while limiting resource costs. We also offer, as alterna-  tives, simpler scheduling heuristics that enhance the reactive  strategy from our prior work. The specific contributions of  the paper are as follows:  1) We analyze performance traces for public and private  Cloud VMs to highlight spatio-temporal variations  (?II). These motivate our problem while offering in- sights to build resource forecasting models; however,  the modeling itself is beyond the scope of this paper.

2) We build upon our prior continuous dataflow ab-  straction (?III) to formalize look-ahead scheduling on Clouds as an optimization problem (?IV).

3) We propose several scheduling heuristics for elastic  resources, including PLAStiCC, that leverage short  and medium term performance predictions (?V).

4) The proposed heuristics are evaluated through exten-  sive simulations that use real performance traces from  AWS public cloud VMs for a representative synthetic  continuous dataflow with different workloads. (VI).



II. ANALYSIS OF CLOUD PERFORMANCE VARIABILITY  Performance variations present in virtualized and multi-  tenant infrastructures like Clouds make it challenging to  run time-sensitive applications such as continuous dataflows.

Several studies have observed such variations both within  and across VMs[9]. Their cause is attributed to factors in-  cluding multi-tenancy, evolving hardware generations in the  data center, placement of VMs on the physical infrastructure,  hardware and software maintenance cycles, and so on. In  this section, further empirical evidence of such performance  variation, both on public and on private clouds, is offered  that motivates the need for our proposed predictive look-  ahead scheduling algorithm.

Two Cloud providers are considered: FutureGrid, a private  academic IaaS Cloud running Eucalyptus 2.0 and OpenStack  Grizzly Clouds, supporting over 150 research projects1, and  Amazon EC2, a popular public commercial IaaS Cloud.

The experimental setup consists of running three groups of  VMs: 20 Eucalyptus, and 10 OpenStack VMs on FutureGrid,  and 10 EC2 VMs on Amazon, over 1?26 day period.

Each VM?s class was equivalent to Amazon?s m1.small,  with one dedicated virtual CPU core and 1024 MB of  memory. Standard CPU (whetstone[15]), disk, and memory  benchmarks are run on each VM every 2 mins, and a peer-  to-peer network benchmark between the VMs measure TCP  connection time, packet latency and bandwidth [16]. Here,  we focus only on the CPU and network performance metrics  since our proposed algorithms only account for these.

1https://portal.futuregrid.org/projects-statistics  In our analysis we focus on two specific aspects. First,  we analyze the overall average performance deviation over a  period of time relative to the rated performance, and second,  we analyze the performance fluctuations observed between  two consecutive time slots (of 2 mins each). The former mo-  tivates the need for dynamic adaptations in general while the  latter motivates the need for proactive look-ahead scheduling  to minimize the thrashing phenomenon (i.e. reversal of  resource provisioning decisions) observed in the reactive  versions. The observed instantaneous performance for a VM  in each of these group (i.e. eucalyptus, openstack or AWS)  is normalized to [0, 1] by dividing it by the best observed (rated) performance for that metric in that particular group.

Although the absolute performance for each of the VM  groups differ, we do not consider that in our analysis since  we assume single cloud deployment for an application.

First we analyze the overall average performance across  different VMs. Figure 1(a) shows the cumulative distribution  function for the normalized average CPU core performance  across all VMs in each of the three VM groups. The Y  axis shows the cumulative fraction of the number of VMs  whose observed performance is less than the normalized  performance on the X axis. We see that all three VM  groups show significant variations in performance, with the  EC2 VMs on Amazon?s public Cloud showing the highest  variations, possibly due to greater data center diversity and  high multi-tenancy and utilization of physical resources.

Specifically, 23% of EC2 VMs have a normalized core performance of < 0.80, while < 10% of the FutureGrid VMs exhibit this shortfall, possibly due to more uniform  physical resources. Similar variations are also seen in the  network performance measures when considering all VM  pairs over time; we do not plot this in the interests of space.

In brief, we see a high deviation in normalized packet latency  with more than 45% of the VM pairs exhibiting less than 0.70; and 22% of VMs have a normalized bandwidth of less than 0.80. These can punitively impact the exchange of small messages by streaming applications.

Second, we also analyze the transient and sharp fluc-  tuations in performance (i.e. high amplitude of ?, small duration), both in CPU as well as network performance,  for the same VM. Figure 1(b) shows the percentage change  (unsigned) in average normalized CPU performance between  two consecutive time slots. Larger the % value of the X  Axis (Left), greater the variation in performance between  consecutive periods, and more pronounced are the perfor-  mance fluctuations. For example, in 25% of the observations, the performance changes by > 20% across consecutive time slots for an EC2 VM. We see similar performance  fluctuations for future grid eucalyptus and openstack deploy-  ments. Further, the extent of variations is different across  VMs. Figure 1(c) shows a box-and-whiskers plot with the Y  axis representing the average normalized CPU performance  for each time slot and the X axis representing different     0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1           cu  m ul  at iv  e fr  eq ue  nc y  (p er  ce nt  ag e)  CPU Core Coefficient      Amazon EC2 Eucalyptus OpenStack  (a) Cumulative Distribution Function (CDF) of normalized CPU Core performance, across VMs and over time.

cu m  ul at  iv e  fr eq  ue nc  y (p  er ce  nt ag  e)  Percentage change in CPU performance w.r.t previous time slot      Amazon EC2 Eucalyptus OpenStack  (b) CDF of performance variation relative to previous measurement time-slot.

0.3  0.4  0.5  0.6  0.7  0.8  0.9   1 2 3 4 5 6 7 8 9 10 Virtual Machine # (Amazon AWS)  C P  U C  or e  C oe  ffi ci  en t  (c) Box-and-Whiskers plot of normalized perfor- mance distribution over time (Y axis) and for different Amazon AWS VMs (X axis).

Figure 1. CPU Core performance characteristics, across space and time.

EC2 VMs. The height of the box shows the difference in  performance between q1 and q3 quartiles and the + indicates outliers (< q1? 1.5? (q3? q1). We also observe significant fluctuations in network characteristics as shown in figure 2.

A detailed discussion is omitted for brevity.

Such performance fluctuations and outliers mean that  the immediate past performance of a resource may not  be sustained in the immediate future, and assuming so  will cause sub-optimal resource allocation strategies[8]. In  particular, such transient performance changes can cause  decisions that need to be unrolled soon after. Thus a look  ahead adaptation strategy that not only accounts for the  performance variations across VMs, but is also resilient to  such short term fluctuations is warranted.



III. PRELIMINARIES & BACKGROUND  We introduce the abstraction of continuous and dynamic  dataflows, and summarize our existing work on reactive  scheduling of such dataflows on Clouds with infrastructure  variability[8]. We build upon this for our current contribution  on pro-active scheduling with look ahead.

A continuous dataflow is a directed acyclic graph G =  (P,E, I, O), where P = {Pi} is a set of processing elements (PEs); E = {ei,j : ? a dataflow edge between Pi and Pj} is a set of dataflow channels between the PEs; and I ?= ? ? P and O ?= ? ? P are the sets of input PEs (without an incident channel) and output PEs (without an outgoing  channel), respectively. Each PE is a long-running compute  unit, processing data messages from the incoming channels  and producing data messages on the outgoing channels.

This DAG-based application composition model, prevalent  in various domains, provides a flexible abstraction to build  complex continuous dataflow applications[17].

A. Dynamic Continuous Dataflows  Continuous dataflows are extended to dynamic dataflows  that allow run-time application re-composition in response  to the domain triggers. They also provide an additional  dimension of control to schedule the dataflow to balance  application QoS, resource cost and application value.

The main characteristic of a dynamic dataflow is the set  of ?alternates?[18] available for individual PEs. This lets  the user define more than one alternate implementation for  each PE. All alternates for a PE perform the same logical  operation but with a different trade-off between the domain  perceived ?value? and the resource needs. Only one alternate  is active for a PE, and the choice of an alternate does not  impact the dataflow correctness, nor does changing it while  the continuous dataflow is executing. Each alternate pji of a PE (Pi) has as associated relative domain value, ?  j i ; resource  requirement, cji ; and selectivity, s i j .

The relative domain value, 0 < ( ?ji =  f(pj i )  maxj f(p j i )  ) ? 1,  is the domain perceived relative benefit of activating that  alternate for a given PE relative to its best available alternate,  where f(pji ) is a user-defined positive valued function, e.g., the F1 statistical measure. In a timestep, t, the application value for the entire dataflow is the aggregation of all active  alternates? values, one for each PE, in that duration.

The resource requirement, cji , is the number of core- seconds required to process a single incoming message by  an alternate on a ?reference? CPU core. The reference CPU  core is an infrastructure specific unit of computing in a  heterogeneous Cloud environment. This allow us to use a  simple linear scaling to obtain the processing requirements  for that alternate on other benchmarked CPUs. For e.g.,  given an alternate with cji = 3.6 for a reference 1 Ghz core, the processing latency on another CPU core (x) bench-  marked at 1.8 Ghz is given by, processing latencyx = processing latencyref  cpu capacityx = 3.61.8 = 2secs.

Selectivity, sji , is the ratio of the number of messages produced by the alternate to the number of messages con-  sumed by it to complete a logical unit of operation by that  alternate. Selectivity determines the message load on the  downstream PEs in the dataflow. The impact of an alternate  on overall dataflow cost is thus its own resource cost and its  contribution to the cost of downstream PEs.

The dataflow application is deployed in a distributed  environment[19]. One alternate is active for each PE at  deployment and the scheduler can switch between alternates  during the application?s runtime. Several instances of an  alternate can run in parallel across independent cores; while  instances may inter-communicate through some persistence               cu  m ul  at iv  e fr  eq ue  nc y  (p er  ce nt  ag e)  Percentage change in latency w.r.t previous time slot     Amazon EC2 Eucalyptus OpenStack  (a) Latency             cu m  ul at  iv e  fr eq  ue nc  y (p  er ce  nt ag  e)  Percentage change in connect time w.r.t previous time slot      Amazon EC2 Eucalyptus OpenStack  (b) Connect             cu m  ul at  iv e  fr eq  ue nc  y (p  er ce  nt ag  e)  Percentage change in bandwidth w.r.t previous time slot      Amazon EC2 Eucalyptus OpenStack  (c) Bandwidth  Figure 2. CDF of variation in normalized network performance measures relative to previous measurement time-slot.

mechanism, for simplicity, we assume that each instance of  a PE is data parallel and can execute independently. So, a PE  can be scaled up/down by increasing/decreasing the number  of instances, each using an exclusive core.

The QoS of the application is measured by the rela-  tive application throughput, ?, which is the ratio of ob- served output throughput to the maximum achievable output  throughput, given the incoming data rate to the dataflow. The  observed throughput depends on the number of instances of  each PE and the resources assigned to them. The dataflow?s  lifetime is divided into optimization periods of duration T , and the user specifies as a QoS constraint the minimum  average relative throughput, ??, to be met for each T .

The overall profit, ?, for the application deployment is  defined as ? = ?????, where 0 ? ? ? 1 is the normalized application value and ? is the dollar cost incurred by the application, both defined over each optimization period T , and ? is the value coefficient defined as:  ? = Valuemax ? Valuemin  CostMaxV al ? CostMinV al  where V aluemax and V aluemin are the maximum and minimum application values while CostMaxV al and CostMinV al represents acceptable costs at those maximum and minimum values respectively. The user (or adminis-  trator) specifies the acceptable cost parameters while the  application values are obtained by selecting different al-  ternates for the dynamic dataflow. The optimization goal  for scheduling dynamic continuous dataflows, thus, is to  maximize the overall profit, ?, while meeting the user defined QoS constraint ? ? ?? for each optimization period.

B. Reactive Runtime Scheduling and Resource Mapping  To achieve the optimization goal, the scheduler can, at  runtime: (1) switch the alternate for a PE, (2) change the  number of instances for an alternate, and (3) select the  Cloud VMs on which instances are deployed. These can  be in response (i.e. reactive) to changes in the incoming  data rates and variability in infrastructure behavior (or even  the scheduler?s prior sub-optimal decision), that cause a  deviation from the goal. Our prior work on a reactive  scheduling algorithm[8], discussed in brief here, forms the  basis for the proposed PLAStiCC algorithm(? V).

The scheduling algorithm has two phases[8]. In the initial  deployment phase, the algorithm uses the rated performance  for the Cloud resources and estimated data rate suggested by  the user, and allocates resources to each PE. This determines  the initial alternates that are active, the number of data  parallel instances of each, the number and size of VMs to be  launched, and the mapping of PE instances to these VMs.

In the runtime adaptation phase, the scheduler continuously  monitors the dataflow and infrastructure, measuring the  current relative throughput, incoming data rates, and the  CPU performance for, and bandwidth between, different  VMs. Based on these observed performance metrics, it can  decide to change the active alternates, and scale up/down  the number of VMs and PE instances to balance the QoS  against resource cost and the application value.

The reactive algorithm[8] has two independent stages,  alternate re-deployment and resource re-deployment. The  former selects feasible alternates for each PE such that they  do not require any changes to the resources required. This  depends not only on the active alternates but also on the  current resource performance. It then picks the alternate  for a PE with the highest value relative to its cumulative  cost, i.e., the sum of its own resource needs and resources  needed by downstream PEs due to its selectivity. Resource  re-deployment, on the other hand, preserves the active al-  ternates while it scales up/down the number of instances  of the alternates and launches/releases VMs. Here, the  heuristic makes several decisions: Which PE is under/over  provisioned?, which PE instance to be scaled down?, and  which VM has to be shutdown? These decisions affect the  overall application QoS, its value, the resource cost.

The ?reactiveness? is because the scheduler assumes that  the observed data rates and resource performance will sus-  tain in the future. Although this reactive algorithm mitigates  the effects of variations in workload and infrastructure  performance, due to its myopic nature, is susceptible to  spikes and short term fluctuations in the VMs? performance.

This leads to adaptation decisions (e.g. launching a new VM  in response to a performance drop) that need to be reversed  in the near future (once the VM?s performance is regained).

Besides adding to the scheduling overhead, it increases the  cost of Cloud resources that are billed by the hour.



IV. PROBLEM FORMULATION  Reactive scheduling can be mapped to a constrained utility  maximization problem applied to continuous dataflows[8].

We define the pro-active look-ahead optimization as a refine-  ment of this by including predictions for the incoming data  rates and performance of the underlying infrastructure. In  contrast, the reactive problem only has access to the current  snapshot of the behavior.

We define a fixed optimization period T over which the  application schedule is to be optimized while satisfying the  QoS constraint. T may be the duration of the application lifetime or some large time duration. T is divided into a number of fixed length timesteps, t0, t1, ..., tn. The initial deployment decision, based on the rated infrastructure per-  formance and user estimated data rates, is done at the start of  timestep t0, the system is monitored during ti and runtime decisions performed at the start of timestep ti+1.

Figure 3(a) shows the reactive optimization problem de-  fined over an optimization period T . The profit (i.e. utility) function to maximize, ?, is defined over the normalized application value and the total resource cost over the entire  period T . Similarly, the application throughput constraint ? ? ?? is defined over the average throughput observed over T . Consequently, the instantaneous ? at a given time may not satisfy the given constraint though the average is  satisfied by the end of T .

This problem is modified for pro-active look-ahead opti-  mization as follows. Since prediction algorithms are often  accurate only over short horizons (i.e. near future), and  to reduce the time complexity of the problem, we reduce  the above global optimization to a set of smaller local  optimization problems (Figure 3(b)). First, the optimization  period T is divided into prediction intervals [P0, ..., Pk], each of size equal to the length of the prediction horizon  given by the prediction model (?oracle?). As before, we  divide each interval Pj into timesteps t j 0, t  j 1, ..., t  j k, at the  start of which the adaptation decisions are made.

Next, a stricter version of the application constraint is  defined, requiring it be satisfied for each prediction interval  Pj , i.e. ?Pj : ? p j ? ?? . It is evident that if this constraint  is satisfied for each interval, it will be satisfied over the  optimization period; however, the converse may not hold.

Further we cannot define ? for each interval since it is  cumulative over the resource cost, and the VM provisioning  may span multiple prediction intervals. Rather, we optimize  the profit calculated ?so far?, given as the cumulative average  over each of the previous intervals, i.e., ?p?j = ?i?j  ? ?p i?  Pi ?  ?j ? ??j , where ??j is the cumulative cost till prediction interval Pj . While conciseness precludes a formal proof, it can be shown by contradiction that the global profit function  ? defined earlier is equivalent to ?p?k, where Pk is the last prediction interval in the optimization period T .

The look-ahead optimization problem described above  assumes a prediction ?oracle? that can predict into the  ? ?? ???? ?  ? ? ??? ? ? ?????  ? ? ?  ??? ? ??????  ? ? ? ? ? ? ? ?  ? ?? ??  ????????    ??????  ???	 ? ? ? ? ??  ? ????? ?  ?? ? ? ??? ? ?  ? ?????  ?  ?? ? ? ??  ? ? ? ? ??  ?  ?? ? ? ??? ? ?  ? ?????  ?  ?? ? ? ??? ? ?? ?????  ?  ?? ? ? ??  ? ? ? ? ??  ?  ?? ? ? ??? ? ???????  ?  ? ????? ???? ???  ?    ???	 ? ? ? ? ? ??  ???  ???  ??	 ????? ??  Figure 3. The (a) reactive and (b) look-ahead runtime optimization problems defined over the optimization period T .

entire prediction interval. With a perfect oracle, the predicted  values for an interval remain fixed for that interval. However,  given the limitations of state-of-the-art multivariate time  series models[20], in practice, the errors in the predicted  values will increase with the horizon of prediction. Hence,  we will get better prediction values as we move further  into a prediction interval. To utilize this, we allow new  predictions to be made at each timestep ti rather than only at the start of each prediction interval. Further, anytime a new  (improved) prediction is available, we slide the prediction  interval window to that point and re-plan actions for the all  its timesteps, retracting the prior planned actions.

This sliding window of replanning does not change the  optimization problem, except that the optimization decisions  planed in one interval may be altered in the succeeding  interval if improved predictions are available. However,  note that this is different from the reversal of decisions in  the reactive version, since the decisions there are enacted  immediately for the next timestep whereas in the look-ahead  version the replanning may just change a future planned  action and hence not incur any resource penalty.



V. SCHEDULING HEURISTICS  As with reactive scheduling (? III-B), the look-ahead scheduling consists of two phases, the initial deployment  phase which maps the application to VMs in the Cloud  assuming rated performance and estimated incoming data  rate; and the runtime adaptation phase which alters the  resource allocation and alternates to account for the observed  and predicted behavior. In this paper, we retain our earlier  initial deployment algorithm[8] and focus on the latter. As  such, the impact of the initial deployment is amortized  by the runtime adaptation for long running dataflows. We  propose a look-ahead algorithm, PLAStiCC, which uses the  predicted resource performance and data rates to generate the  adaptation plan for a near future. Further, we propose several  heuristics that use simpler averaging models to estimate  performance and data rates. These, while out-performing  reactive scheduling in some cases, offer different trade-offs  than PLAStiCC(?VI).

A. Predictive Look-Ahead Scheduling (PLAStiCC)  The PLAStiCC algorithm is run at the start of each  prediction interval. It plans a set of adaptation actions for  timesteps in that interval to maximize the cumulative profit  while meeting the constraint for that interval. The key  intuition is to identify the farthest timestep in the current  interval for which the existing deployment meets the QoS  constraint for messages expected in that interval, given  the performance and data rate predictions. The cross-over  timestep indicates the future timestep beyond which the  current deployment fails to meet the QoS. Once identified,  we replan the deployment starting at the cross-over timestep  and recursively repeat the process till the last timestep of  the interval. The result of this algorithm is zero or more  cross-over timesteps, identified in the interval, where the  QoS constraint fails and the planned adaptation action to  be taken at that timestep.

Algorithm 1 shows the PLAStiCC runtime adaptation  algorithm. It takes as input the continuous dataflow DAG  D, the predicted data rate PRit..t+n for each input PE Pi as a time series [t..t + n] for timesteps in the interval, and the predicted VM performance time series PV jt..t+n for each VMi, which includes CPU and inter-VM network behavior.

The algorithm outputs a plan of actions X to be taken at timesteps in the prediction interval [t, t+ n].

PLAStiCC is called as and when new predictions are  made. It is run before the first timestep, t, of the prediction interval and tries to identify the farthest non-cross-over  timestep. The algorithm maintains two pointers, ot, which is the last-known cross-over timestep in the interval, initially  blank, and ft, the last timestep of the interval, set to ft = t + n. It tries to locate the last timestep when the aggregate constraint is met (lines 5?13). Starting at the  last timestep, it calculates the aggregated throughput (?) by computing the processing capacity available to each PE  (Alloc), the cumulative incoming data messages at each PE  using the predicted data rates and the network behavior (M),  and the aggregated relative throughput resulting from these  values. If this aggregate throughput is not within ??? ?, we try the previous timestep (line 12). If it is met, have found  the cross-over boundary between constraint being satisfied  and not (line 10). If the constraint is met in the first iteration,  i.e. at the interval?s end, no adaptation is needed (line 15).

Once the cross-over is identified, ot is set to this timestep,  and ft is reset to t + n for the next iteration. We then decide the action to be taken at the cross-over to meet the  constraint. For this replanning, we get the aggregated values  for the available resources, the incoming messages and the  relative throughput for the rest of the interval, (ot, t + n] (lines 18?20). Since the expected throughput is deviating for  this period, we either scale up (?ot..t+n < ??? ?) or scale down (?ot..t+n > ?? + ?)), incrementally (lines 21?27).

Both the SCALEUP and the SCALEDOWN functions try  to balance the overall application value ? (Sec. III-A)  and the total application cost ?. The SCALEUP function first identifies the ?bottleneck? PE with minimum relative  throughput, lying on the critical path from the input to output  PEs[8]. It can then either switch to an alternate for this PE  with lower processing needs (and potentially decrease the  application value) or increase the number of instances (and  possibly increase the resource cost) for the bottleneck PE.

This choice is based on the local optimization of the profit  function ?t which uses the user specified ? coefficient that determines the ?acceptable? value:cost ratio.

Specifically, the cost of increasing an instance is zero if a  VM has spare cores or else is equal to the cost of a new VM.

Then, the change in application value from switching to the  alternate with next lower processing needs is calculated. The  change in ?ot?ft from either of these actions is calculated, and the adaptation that results in higher profit is selected.

Similarly, the SCALEDOWN function identifies an over-  provisioned PE and makes a choice between switching to  an alternate with higher value or decreasing the number of  instances, whichever leads to higher profit.

Once such incremental action is planned for the cross-  over timestep, we resume evaluating the planned deployment  ensure it satisfies the constraint for the rest of the interval,  (ot, t+n] (lines 5 - 13). The replanning is incrementally done till all cross-over timesteps and adaptations are identified for  the interval, and the resulting plan satisfies the constraint  for the entire interval. Finally, the algorithm performs a  repacking of VMs to collocate neighboring PEs as well as  shuts down those that are unused (line 30).

B. Averaging Models with Reactive Scheduling  Rather than use fine-grained predictions (PLAStiCC) or  assume that the most recent observed values will sustain  (reactive), we develop several heuristics that use simple  but intuitive estimates of future behavior and use it as a  representative in the reactive algorithm. This also addresses  PLAStiCC?s susceptibility to prediction errors since it over-  fits the schedule to the predictions. Similar to the reactive  scheduler, these heuristics are executed only when the ap-  plication QoS deviates from the constraint.

Current After-the-fact (CAF): This chooses observed  value in the most recent timestep as the estimated behavior  for remaining timesteps. This is same as the classic reac-  tive scheduler[8]. This reacts after-the-fact to the observed  resource and data rate changes.

Windowed Average After-the-fact (WAAF): This uses the  average seen over several recent timesteps as the estimated  behavior. This smooths out spikes while accounting for the  recently observed trends that might last in the near future.

Windowed Predictive Average (WPA): This averages the  values predicted for all timesteps by the advanced prediction  model used by PLAStiCC, and uses the single average value  in all timesteps in the interval. This mitigates the impact  of large prediction errors in a few timesteps, where the  PLAStiCC is susceptible.

Algorithm 1 PLAStiCC Runtime Adaptation Heuristic  1: procedure PLASTICC(Dataflow D, MinThroughput ??t, DataRatePredictions PRt..t+n, VMPerfPredictions PVt..t+n)  2: ot ? ?, X ? ? ? Init cross-over list to null 3: while ot ? t+n do 4: ft ? t+n 5: while ft ? t do ? Work back from last timestep.

6: Alloc ? AVAILABLERESOURCEALLOC(PVot..ft) 7: M ? CUMULATIVEINCOMINGMSGS(PRot..ft) 8: ?? CUMULATIVETHROUGHPUT(D, M, Alloc) 9: if ??? ? < ? < ?? + ? then  10: Break ? QoS constraint met at this timestep.

11: end if 12: ft ? ft - 1 ? QoS not met. Work backwards.

13: end while 14: if ft = t+n then ? QoS met at end of interval.

15: Break ? No more replanning. Done.

16: end if  ? Replan actions for the remaining duration (ft, t+n] 17: ot ? ft ? Update last-known cross-over.

18: Alloc ? AVAILABLERESOURCEALLOC(PVot..t+n) 19: M ? CUMULATIVEINCOMINGMSGS(PRot..t+n) 20: ?? CUMULATIVETHROUGHPUT(D, M, Alloc) 21: if ? < ?? then 22: bpe ? BOTTLENECK(D,CA) 23: X ? X ? SCALEUPORDECAPPVALUE(bpe, ot)  24: else if ? > ?? then 25: ope ? OVERPROVISIONED(D,CA) 26: X? X ? SCALEDOWNORINCAPPVALUE(bpe, ot) 27: end if 28: end while 29: X ? X ? REPACKANDSHUTDOWNVMS( ) 30: return X ? Return cross-over timesteps and action plan.

31: end procedure  Windowed Predictive Optimistic (WPO): This too uses the  advanced prediction model of PLAStiCC but picks the most  favorable infrastructure performance (highest) and data rate  (lowest) from among all timesteps predicted for, and uses  that single value for all timesteps. This offsets the impact  of prediction algorithm with under-prediction bias[21]. This  heuristic usually leads to low relative throughput since it  tends to under-provision resources.

Windowed Predictive Pessimistic (WPP): This is similar  to WPO, except it picks the least favorable performance  and data rate prediction as the single value. This handles  prediction algorithms with over-prediction bias[21]. This  heuristic usually gives the best relative throughput since it  tends to over-provision resources.



VI. EVALUATION  Simulation Setup: We evaluate PLAStiCC and other  heuristics through a simulations study. We extend the  CloudSim[22] data center simulator to IaaSSim2, that incor-  porates temporal and spatial performance variability using  real traces collected from IaaS Cloud VMs. Further, FloeSim  simulates the execution of the Floe stream processing  2http://github.com/usc-cloud/IaasSimulator  engine[19], on top of IaaSSim, with support for continu-  ous dataflows, alternates, distributed deployment, dynamic  instance scaling, and plugins for different schedulers.

For each simulation experiment, we deploy a dataflow to  the Cloud using FloeSim, run it for 12 hours (simulated)  using Amazon EC2?s performance traces (? II) ? which is also the optimization period (T = 12hrs), and repeat it at least three times to get an average. We use a timestep  duration of t = 5mins and the prediction intervals between P = 10? 30mins.

Synthetic Dataflows and Streams: We evaluate the adap-  tation algorithms using a synthetic dataflow in Figure 4 with  10 stages of 3 PEs each, and 3 input and output data streams.

The dataflow is randomly perturbed to generate between 1?  3 alternates each, with different cost, value and selectivity.

This gives us a total of 30 PEs and ?45 alternates.

Each of the three input data streams are independently  generated based on observations in domains like Smart  Power Grids[17]. Starting from a base stream with sinusoidal  data rates whose peak and trough range from 75 ? 2 messages, and with wave length of 24hrs, we add random noise every 1min that varies the rate by up to ?20%.

???  ?????? ?????????? ??? ? ???????? ??????	???? ?	??????	? ??????????????????	? ?????????	?  ? ??????? ????????? ?????? ????? ? ??? ??????	?? ????????? ??????? ??	?? ?	????????????	????? ?????  Figure 4. Sample dataflow pattern used for evaluation  Evaluation Metrics We evaluate the heuristics using fol-  lowing metrics. The overall application relative throughput  (?), the overall application profit (?) and the Heuristic Stability (?). Specifically, we verify if the heuristic satisfies the QoS constraint ? ? ??. A higher value of ? beyond ?? is not necessarily good unless it also gives a higher overall  profit. Further, given two heuristics which satisfy the QoS  constraint, the one with a higher overall profit is considered  better. Note that profit is unit-less and can only be compared  relatively. chi is the frequency of deviation in instantaneous relative throughput ?t from the ???? during the optimization period and a smaller value indicates a more stable heuristic.

Prediction Models The proposed heuristics are evaluated  under different prediction oracle models. First we evaluate  different heuristics under a perfect oracle model that gives  accurate predictions over the prediction interval. We also  run experiments where the predicted performance and data  rate values include bounded errors, e?, to simulate short- comings of real world prediction models. The predictions  have smaller error for near timesteps and larger ones for  farther timesteps. First, we linearly scale the error from zero  for the current timestep (e0) to the 2? e? for the last timestep (en) in the prediction interval, to give a mean close to e?.

????  ???  ????  ???  ????  ???  ????    ? ??? ?? 	??? ??? ???? ???? ? ??  ? ?? ?? ?? ?? ?? ??  ?? ??  ?? ??  )  ?????????? !?"  #$%  #%%&  '%&  #$(  #$$  $???????  (a) Overall Relative Throughput (?)  ??? ???? ???  ???? ???  ???? ???  ???? ???  ???? ??  ? ??? ??? ?? ???? ???? ???? ????  ? ?? ???  ? ?? ?  ?????????????  ???  ???  !?  ??"  ???  ????????  (b) Total Profit (?)  ? ?? ?? ?? ?? ??? ??? ???  ??? ???? ???? ???? ???? ????    ?? ?? ?  ?? ??   ? ??   ? ?  ???????? ????  ??? ???? ??? ?? ??? ???????  (c) Heuristic Stability (?)  Figure 5. Performance of scheduling for a perfect, oracle prediction model, as the prediction interval horizon (in secs) vary on X axis  Then, we sample the actual error for a timestep i from a normal distribution with mean 0 and variance equal to ei/2, and use this as the actual error for that timestep to obtain  the predicted value. We can also optionally specify a ?bias?  of ?5% that is added to get a positive or negative biased model. We make predictions every 10mins for all models.

Further, we evaluate them with prediction intervals ranging  from 10 mins (i.e. two 5min timesteps per interval) upto to 30 mins and study the effect of the length of prediction  interval under different oracles.

A. Results  Perfect Oracle Model: We first present the results ob-  tained for the perfect oracle model, which signifies the best  case results for the PLAStiCC heuristic as compared to  the various reactive models. Figure 5 shows comparison  between the PLAStiCC algorithm to the reactive models  for different metrics (?, ?, and ?) with different prediction interval lengths for which the oracle predictions are avail-  able). Figure 5(a) shows the overall relative throughput for  various algorithms observed at the end of the optimization  duration. We observe that all the adaptation algorithms  successfully satisfy the application constraint (? ? 0.8) over the optimization duration for prediction interval lengths.

Higher values of relative throughput do not necessarily  mean a better algorithm. We compare this with ?, and ?.

Figure 5(b) shows the overall profit (? = ?? ??) obtained for different algorithms. First we observe that the PLAStiCC  algorithm performs consistently better than any of reactive  algorithms across different prediction interval lengths. Fur-  ther, we also observe that the profit value for the PLAStiCC  algorithm increases as the length of the prediction interval  increases. This is because, with shorter prediction intervals,  the planned actions for that interval may be already executed  before the plan for the future is obtained, and hence leads to  a reversal in the actual action and not just the planned action,  the former of which incurs additional cost. As the length of  the interval increases, fluctuations further in the future are  known and hence the planned activities may be reversed  before they are enacted and hence lowering the resource  cost. In addition, we observe that the heuristics based on  current (CAF) and historical average (WAAF) performance  perform fairly similar. However, the WPP algorithm leads to  much lower profit since it always tries to allocate resources  for the worst case scenario, hence incurring higher resource  cost. Further, Figure 5(c), shows the stability of the different  heuristics (lower values are better). We observe that the  PLAStiCC algorithm is more stable than any of the other  heuristics and hence provides more predictable performance  over the optimization duration. This is mainly because the  algorithm pro-actively takes actions (such as launch VMs in  advance to account for VM launch time while initiating a  new instance at the desired time), whereas in the reactive  versions the delay incurred by such actions cause constraint  mismatch till the action is performed.

This simulation study thus show that the look-ahead  PLAStiCC algorithm out-performs all the reactive algo-  rithms in the presence of data and infrastructure variability.

Further, it shows that the PLAStiCC algorithm is dependent  on the length of the prediction interval and performs better  as the interval length increases.

Predictions with Errors and Biases: Next, we analyze  PLAStiCC under a more realistic prediction model condi-  tions, with prediction errors. We compare PLAStiCC against  WPO, WPA, and WPP to evaluate their relative strengths.

Figure 6 shows the performance of PLAStiCC for models  with prediction errors but no biasing. As before, we observe  that the profit of the algorithm for a perfect oracle model  (0% error) increases from 0.6 to 0.7 with increase in the prediction interval from 10 ? 60mins. However, we see  ???  ???  ???  ???  ???  ??  ? ??? ??? ?? ???? ???? ???? ????  ? ?? ???  ? ???  ????????????? ????? ??!??????" ????? ??!??????" ????? ??!????? ?" ????? ??!????? ?" ????? ??!???????"  Figure 6. Overall profit of PLAStiCC for different prediction error %, with prediction interval horizon (in secs) on X axis     degrading performance as the error rate increases to 20%.

We make two observations. First, for a given prediction  interval length the performance decreases, as expected, as  prediction error increases. Second, with high error values  (> 10%), the performance of the algorithm, for a given error rate, initially increases with the prediction interval length,  and then falls with further increase in the interval length  (inverse bell curve). The reason for such behavior is that  as we predict farther into the future, the error increases.

But as we move into the future, more accurate results are  obtained and hence they lead us to reverse actions. While  most of these are planned actions, some enacted ones may  be reversed too. As the error increases, only prediction very  close to the current time will prove accurate and hence the  PLAStiCC degenerates to the reactive version.

Finally, we compare PLAStiCC against the reactive ver-  sions which aggregate predicted values, and are potentially  affected by the prediction error. CAF and WAAF are un-  affected by prediction errors and hence skipped. Figure 7  shows the overall profit for WPA, WPO, WPP and PLAS-  tiCC for different error rates and prediction biases (P = 20min). As seen in the figures, PLAStiCC out-perform the others for smaller errors, irrespective of the prediction bias,  while its performance degrades as the error increases, since  it tries to over-fit to the predicted values. WPA, on the other  hand performs consistently with different error rates and for  different biases. While the WPO algorithm, which assumes  an optimistic infrastructure behavior, performs poorly when  the prediction errors are unbiased. However, it performs  better than WPA with under-biased predictor. With lower  predicted values, the best performance values over the inter-  val tend to be closer to the real performance value than the  average. On the other hand, WPP performs poorly under  all scenarios because it assumes pessimistic infrastructure  behavior and hence a single dip in the predicted performance  causes it to over-provision resources.



VII. RELATED WORK  Continuous dataflows have emerged as an extension to  the Data Stream Managements systems, which were focused  on continuous queries over the data streams. These have  evolved into a general purpose abstraction that provides  strong composition tools for building large scale stream  processing applications. Several such stream processing  systems have been recently proposed such as S4[4], IBM  InfoSphere streams[23], D-Streams[5], Storm[24], and Time  Stream[6]. While these systems are built for large scale  stream processing applications and provide distributed de-  ployment and runtime, most of these (with the exception of  Time Stream) do not provide automatic, dynamic adaptations  to changing data rates or performance variability of the  underlying infrastructure, over the application?s lifetime.

The notion of ?alternates? is similar to flexible  workflows[25]. It also draws inspiration from dynamic tasks  defined in heterogeneous computing[18] where a task is  composed of one or more alternatives with different char-  acteristics, such as resource requirements and dependencies.

However, unlike these systems, where the alternate to be  executed is selected in advance, in our dynamic continuous  dataflow abstraction such decisions are made at periodic  intervals based on the changing execution characteristics.

Time Stream[6] supports similar dynamic reconfiguration,  called resilient substitution, which allows replacing a sub-  graph with another in response to the changing load. This  requires dependency tracking and introduces inefficiencies.

In contrast, we restrict dynamic adaptation to single process-  ing elements making the process of dynamic reconfiguration  independent for each PE and hence allow more flexibility in  dynamic adaptation, while restricting the application com-  position model. Our earlier work has discussed consistency  models for enacting such runtime updates[26].

The predictive scheduling approach proposed in the pa-  per follow the generic ?scheduler, monitor, comparator,  resolver? approach proposed by Nof et. al.[27]. Several  such predictive scheduling techniques have been studied on  computation grids[28], [12], however in the context of batch  task scheduling instead of continuous dataflows. Further,  several performance prediction models for the Grid have  been proposed to profile workloads as well as infrastructure  variations[29]. Although, we do not provide models for  performance prediction in the Clouds, we envision that  similar performance models may be applicable. PRESS[14]  is one such system which uses ?signature driven? prediction  for variations, with periodic patterns and a discrete-time  Markov chain based model for short-term predictions for  VMs. They achieve high prediction accuracy with less than  5% over-estimation error and close to zero under-prediction  error. We presume existence of such monitoring and predic-  tion algorithm to be used as the basis for our look-ahead  scheduling algorithm.



VIII. CONCLUSION  In this paper, we analyzed the temporal and spatial perfor-  mance variations observed in public and private IaaS Clouds.

We proposed PLAStiCC, a predictive look-ahead scheduling  heuristic for dynamic adaptation of continuous dataflows,  that responds to fluctuations in stream data rates as well as  variations in Cloud VM performance. Through simulations,  we showed that the proposed PLAStiCC heuristic results  in a higher overall throughput, up to 20%, as compared  to the reactive version of the scheduling heuristic, we  proposed earlier and improved here, which performs adap-  tation actions after observing the effects of these variations  on the application. We also studied the effect of realistic  prediction models with different error bounds and biases on  the proposed heuristic, and identified scenarios where the  look-ahead algorithm falls short of the reactive one.

??? ????  ??? ????  ??? ????  ??? ????  ???  ? ? 	? 	? ? ?  ?? ?  ??? ??  ??   ???????????????????????  ???  ???  ???  ???????  (a) Overall profit for different algorithms for un- biased predictor (0%)  ???  ????  ???  ????  ???  ????  ???  ????  ? ? ?? ?? 	? 	?   ? ?  ??? ??  ?? ?  ???????????????????????  ???  ???  ???  ???????  (b) Overall profit for different algorithms for low biased predictor (-5%)  ??? ????  ??? ????  ??? ????  ??? ????  ???  ? ? 	? 	? ? ?  ?? ?  ??? ??  ??   ???????????????????????  ???  ???  ???  ???????  (c) Overall profit for different algorithms for high biased predictor (+5%)  Figure 7. Performance of scheduling with realistic prediction models, having different prediction error % on X axis. Plots differ in prediction bias.

