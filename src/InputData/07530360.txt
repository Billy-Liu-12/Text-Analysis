Parallel Frequent Itemset Mining with Spark RDD

Abstract?The aim behind frequent itemset mining is to find all common sets of items defined as those itemsets that have at least a minimum support.  There are many well known algorithms for frequent itemset mining.  Some of which are Apriori, ?clat, RElim, SaM, and FP-Growth.  Although each of these algorithms is well formed and works in different scenarios, the main drawback of these algorithms is that they were designed to perform on small chunks of data. These limitations were imposed based on time that they were developed. The notion of big data was not up and running at these times. So in the present scenario these algorithms won?t perform well on the current statistics of data present.  So we propose a new approach of implementing these well known algorithms on a parallelized manner so that it can handle the data perfectly. The proposed work parallelizes, dynamic frequent itemset mining algorithm, Faster-IAPI with spark RDD framework. The main goal of selecting Apache Spark is that it overcomes the limitations of the Hadoop architecture which was basically designed to handle big data processing in a parallelized manner. The main drawback of the architecture was that it doesn?t handle the Iterative algorithms very well. This drawback is rectified in spark which handles it well. In this approach this algorithm is applied to find correlation between different symptoms of patients in faster and efficient manner and provides the support for the prediction of occurrence of disease based on the symptoms.

Keywords? Frequent itemset mining, Faster-IAPI algorithm, Spark RDD, Parallel computing, Disease prediction

I.       INTRODUCTION    The world is cornered by issues that affect the daily life of mankind. Amongst these issues the health of a person promotes itself to be of paramount concern. Many diseases have existed and continue to evolve in the world today. The only means to diagnose a disease before it becomes fatal to a human being is by analyzing its respective symptoms. Even a newly formed disease leaves behind a trail of symptoms by which its future occurrence can be depicted.

This work aims at collectively mining the information obtained from the diagnosis of the symptoms of various patients and using that information, a prognosis is made as to what disease a patient is affected by. The architecture of the work includes a framework by which all the doctors around the world can contribute their diagnostic expertise   to   a centralized   repository.

The   Faster-IAPI algorithm is applied to this repository to find the correlation between different symptoms of the disease and map it on to the disease. Faster-IAPI algorithm has many noteworthy features compared to other frequent  itemset mining algorithm [1]. This algorithm comes up with generating frequent itemset from incremental massive dataset in two database scan. Other benefits of this algorithm are it is efficient, scalable, faster and dynamic. Another remarkable feature of this   algorithm is that it supports   incremental updating of frequent itemset without rescanning entire database. Faster-IAPI algorithm come up with four phases: during first phase it generates all the frequent itemset from large data sore, In second phase it holds the newly arrived transactions   to the existing set and updates the frequent itemset to provide incremental mining, Third phase covers eliminating old transaction after a preset time period and modifies the patterns to accommodate the behavioral change.

At the last phase it serves a facility to adjust minimum support value as per the user?s requirement. The Spark RDD framework is used to parallelize the Faster-IAPI Algorithm [12]. Batch processing workload can be executed effectively in Spark. In Hadoop, where batch processing workload is not present, optimized result cannot be delivered due to two reasons; first is lack of iteration support and second is high latency due to persisting intermediate data onto disk .By taking into account the strengths and weakness of Hadoop, Spark has contributed to bigdata community by promising parallelization for big data analytics. With the help of Spark, applications can be made quickly by Java, Scala, python.

Spark endorses flexible DAG -based (directed acyclic graph) dataflow and in-memory data sharing across DAG due to which different jobs can work with the same data. The disadvantage of Hadoop is overcome in Spark by holding intermediate result in memory instead of writing them back to disc. By this the benefit of Spark RDD framework is that it can work on the same dataset multiple times . RDD (Resilient Distributed Dataset) is the heart of Spark framework.RDD can be compared to a table in a database that can hold any type of data. Data in RDD is stored in different partition by Spark. By this, rearrangement of computation and optimization of data processing can be achieved. Since a RDD knows how to recreate and recomputed the datasets, it is fault tolerant. On modification of a RDD a new RDD is obtained but the original RDD remains the same. A transformation function takes a RDD and return a single RDD. There are the two operations of RDD.  A transformation function which takes a RDD and returns a single RDD and an Action function computes all the data processing queries present and the result value is returned[15,16].



II.       RELATED WORK   The huge research efforts devoted to a variety of sophisticated and efficient algorithms to find frequent item sets.  Among the  best-known approaches are  Apriori ,Eclat ,FP-growth,SaM,RElim. Apriori algorithm [3] is the most classic and most widely used algorithm for mining frequent itemsets which generate Boolean association rules. Apriori [2] algorithm finds all the frequent itemsets by scanning the database repeatedly and it will consume a lot of time and memory space. When scanning large dataset, which will become the difficulty of Apriori algorithm [4]. ECLAT algorithm [5] derives from Apriori algorithm, so both two algorithms share the same theoretical base. ECLAT algorithm scans a continually updating database and then it updates the database. Each item in the databases represented by set of transaction IDs (called a tidset), which adopts a vertical layout and also implements a depth first search to represent the database. Tidset of an itemset is generated by intersecting tidsets of its items. The depth first search makes the downward closure strenuous in utilization. However; using tidsets has an advantage that there is no need for counting support. The size of the tidset affects the running time and memory usage of ?clat because the main operation of the ?clat is intersecting tidset. More time and memory are needed for bigger tidset. FP-Growth [6] follows a divide-and-conquer strategy and a FP-tree data structure   to   achieve   a compact   representation   of   the transaction database. It   is currently one   of   the   fastest algorithms for frequent itemset mining. It uses a sophisticated and rather complex data structure and thus requires loading the transaction database into main memory.  SaM    (split and merge) [7] algorithm utilizes only a single transaction list which is purely a horizontal representation and it stored as an array. This array is processed with a simple split and merge scheme and it computes a conditional database. The conditional database is processed recursively and finally eliminates the split item from original database. Advantage of this scheme is its simple data structure and processing scheme, easy to implement, and very convenient to execute on external storage.  Limitation of this scheme is, SaM struggles on ?sparse? data sets, In RElim (Recursive Elimination) [8] algorithm the transaction database is preprocessed in essentially the same way as for the SaM algorithm. The main difference is instead of listing all transactions in one array, they are grouped according to their leading item.

These lists are sorted in descending order with respect to the frequency of their associated items in the transaction database: the first list is associated with the most frequent item, the last list with the least frequent item.  Faster-IAPI algorithm provides some added features like incremental and interactive mining support and another feature is that it is capable of generating frequent itemset mining from incremental massive dataset in two database scans.

MapReduce [9] is   a   programming model which was introduced by Google. It includes two functions map and reduces which is used to preserve data generated by real world application on to the disc. The underlying system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the  network and disks. This has proved to be very easy in use for a wide variety of users but the disadvantage is that it does not implement full memory in hadoop cluster. The iterative structure of frequent itemset mining does not fit well into the MapReduce framework [14] because in each round a new MapReduce job need to read the data from and write back to HDFS which will create a lots of I/O overhead and increase time cost as well [17] .  To improve the performance we propose Spark RDD framework [13] for parallelize Faster-IAPI   algorithm   and   can   achieve better   memory utilization and can avoid many overheads.



III.       PROPOSED WORK  The proposed work is divided into 3 sections 1.  Data  Preprocessing 2.  Frequent Pattern Mining 3. Correlation.

As illustrated in Fig. 1 first, evaluation of all the  symptoms pertaining to each disease known today, doctor can add   their   evaluation   of   the   disease   to   the preprocessing framework.  Data preprocessing framework provide a standard format for data submitted by doctor. The processed data is fed to the Faster-IAPI algorithm that run in spark RDD framework, then frequent patterns generated by  the  system  is  correlated  to  predict  the disease.

Fig .1. Proposed architecture    A. Medical Data Preprocessing   Dataset is taken from UCI repository. Data set has both numeric and nominal values. The table 1 shows the result before preprocessing the data set. The data preprocessing framework provides an endpoint for doctors around the world to  submit  the  patient  details  for  the evaluation  of  their diseases. The data submitted by the doctors from around the world is saved into the data preprocessing framework. The framework provides a standard format for submitted data so that everyone can use the endpoint, integrate it into their application. From the above 14 attributes, the listed features such as age, trestbps, Chol, thalach and oldpeak are numeric attributes and  the remaining  9  comes  under  nominal.  The primary  step  of preprocessing  involves  the  conversion  of numeric attribute  to  nominal  attribute and  fill  the  missing values in the dataset. After cleaning, dataset is trained for accuracy. Last step is to validate the dataset to acquire optimal redundant feature for prediction [10].

TABLE 1 HEART ATTACK PREDICTION ITEMS IN THE  DATASET   Age Thalach(maximum heart rate achieved )  Sex Exang(exercise induced angina (1 = yes; 0 = no))  Cp(chest pain type ) Oldpeak( ST depression induced by exercise relative to rest )  Trestbps( resting blood pressure (in mm Hg on admission to the hospital) )  Slope(the slope of the peak exercise ST segment )  Chol(serum cholestoral in mg/dl )  Ca(number of major vessels (0-3) colored by flourosopy)  Fbs((fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) )  Thal( 3 = normal; 6 = fixed defect; 7 = reversable defect )  Restecg(resting electrocardiographic results)  Num(diagnosis of heart disease (angiographic disease status)    A. Frequent Pattern Mining   Faster-IAPI Algorithm   Faster-IAPI algorithm come up with four phases: during first phase it generates all the frequent itemset from large data sore, In second phase it holds the newly arrived transactions to the existing set and updates the frequent itemsets to provide incremental mining, Third phase covers eliminating old transaction after a preset time period and modifies the patterns to accommodate the behavioral change.

At last phase it serve a facility to adjust minimum support value as per the user?s requirement. In this algorithm transaction items are pre-processed and arranged according to the  item  code, so  that  individual item counting and  count comparisons are made faster. Another remarkable feature of this algorithm is that it uses a range of support values (Sl, Sh) for making the dynamic and the interactive mining faster. If any  existing  frequent  itemsets  is  found  to  be  infrequent, remove  it  from  the  Fset  list [11] . Then include it with the NFset list if it?s support  Sl along with the current partition number. Further find the count of its subset and if found to be frequent include it in the Fset. Then find the new frequent itemsets having support  Sh in the new partition. If any, then find its count in other partitions by searching it in the NFset list.  If  not obtained, conduct a possibility test, if there is possibility to be frequent, search its count in the entire dataset. If found to be frequent include it in the  Fset list, else if nearly frequent, include  in  NFset  list  else  discard it.  Here  the  dataset  is logically divided into small sized non-overlapping horizontal partitions of user specified sizes so  that  each  partition  can be   accommodated  in   the main   memory.   To reduce the computational cost, I/O overhead as well as space complexity, each frequent item transaction group is collected separately and four level filtering is done to remove infrequent items. In first level it  removes all the global infrequent items from the selected transaction, at the second level it remove items whose support count less than the selected frequent item, during third level it select the itemsets which have length k or more to obtain the frequent k-itemset, at the last level it consider only the itemset which are frequent in a set where a frequent item belongs to.

In the first scan, Faster IAPI generates frequent 1- itemsets. To generate higher frequent itemsets, do the second scan of database and collect only frequent items from each transaction. The drawback is that it requires more memory (multiple memory buffers) to hold the different frequent item transaction groups. Prepare a co-occurring item list (Cf) for each frequent item, i.e. items having support greater than or equal to the support of that item which is considered for the frequent itemset selection. Then form separate transaction set groups of each frequent item and keep only the corresponding co-occurring items of each transaction group in separate buffers. Also eliminate the similar transaction entry in each transaction group (compress the transaction set) by recording the occurrence count, then find the frequent items in the selected group and eliminate others. Then the higher frequent itemsets of each transaction groups are obtained sequentially.

Frequent itemset generation steps of Faster-IAPI algorithm are given below.

1) Faster-IAPI Algorithm (PhaseI) Input:   D: Transaction database contain N transactions (T1, T2, ??.

TN), horizontally partition D into n non-overlapping partitions (P1, P2  ? Pn) and sort the items of each transaction in the order of item code.

Sl: low minimum support value Sh: user selected min. support (Sh > Sl) Output: Complete set of frequent itemsets 1.    For each partition do   Read each transaction and find frequency flocal(i) for each item i;   2.    Identify frequent 1-itemsets F1-itemset ={i |  flocal(i) Sh for each item i}   3.    Sort F1-itemset in ascending order F1-sorted = {f1, f2,?..,fm}   4.    Prepare co-occurring itemset list   Cfi = {{fi+1,fi+2...fm}|frequency(fi+1,fi+2,?.fm) frequency(fi)} for each fi   5.    Read each transaction of D and do Collect transactions contain each fi in to separate buffers and remove items that are not in the Cfi list from each transaction.

6.    For each fi-transaction group   i. Find frequency of each Cfi item in the selected fi- transaction group   ii.   If frequency(Cfi )  Sl   F2-itemset= {Cfi } for each Cfi item iii.   Else remove Cfi from the selected buffer iv.   Sort F2-itemset in ascending order v.   To obtain higher frequent itemsets of F2           7.  for each item in F2-itemset do   Fitemset = Higher-frequentItemset-Generate (fi- transactions (Buffer1), F2-itemset );   If support (Fitemset)  Sh then Fset = Fitemset   Else NFset = Fitemset   Procedure Higher-frequentItemset-Generate (fi- transactions (Buffer1), Fn)  //Fnp : pth item of Fn-itemset   1. Collect fi-transactions contain Fnp to a newtemporary buffern  and remove items having  count  Fnp  from each transaction in buffern, p initialized to 0   2    Find frequency of each item in the selected Fnp transaction group   3.    F(n+1)-itemset = {Fn(p+k) | frequency(Fn(p+k))  Sl} for each Fn(p+k) item where k=1 to (m-p)   4.    else remove Fn(p+k) from the Fnp transactions   5.    Sort F(n+1)-itemset in ascending order   6.    To obtain higher frequent itemsets of fi   do   7.    if (F(n+1)-itemset  ) then   n = n+1 & Repeat above steps   8.    else if p < size(Fn-itemset) then   p = p+1 & repeat above steps   9.    else remove  buffern content n=n-1, p=1  10   if n  2 repeat above steps   11  else return Fitemset   2) Incremental mining (Phase II)   Faster-IAPI algorithm support incremental mining by utilizing NFset (nearly frequent itemsets), so it is possible to add new transaction to existing frequent itemset without rescanning the entire database. The initial step of this process is to add new transaction to a separate partition and count of items in the new partition is calculated and added with the existing count to update the  frequent items. Frequent item transaction groups of the newly added partition are collected to separate buffers and find their higher frequent itemsets in the new partition. Then update the count of the existing Fset (frequent itemset) belongs to each group. If any existing frequent item/itemsets is found to be infrequent, remove it from the Fset   list and include it with the NFset   list if it?s support  Sl along with the current partition number. If any new frequent itemset obtained from new partition, obtain its global count using NFset. If not obtained from NFset, then conduct a possibility test using (1) and if possible to be frequent find their global count from the old transaction set .

S*Z+(Pc-Pi-1)(U*Z-1)+L*Pi*Z-1 Pc*U*Z          - (1)    Where Pi ? no. of partitions used for initial pattern generation, Pc  ?  current  partition  no  .Z?  Partition  size,  L -  Lower minimum support, U- Upper minimum support, S - New Fset support in new partition  The Apache Spark as the base to create a framework that parallelizes the computational process [13, 16]. The framework is shown in the fig. 2.

Fig .2.Apache Spark Framework    B. Correlation   The  correlation  phase  reads  the  values  from  the output of the algorithm and computes the relation between the disease and symptom. For example: the association rule generated from the identified frequent itemset {(cp, thalach, thal Num), with support count  Sh} correlates as there is more possibility for heart condition. This method also can also apply to predicting  the  chance  of  occurrence of  Jaundice, Cancer and Kidney failure.



IV.      IMPLEMENTATION   Proposed method can be implemented with Apache  Hadoop with Spark-1.2.0 in Ubundu platform. Dataset can be collected from UCI repository. Only 14 attributes from the dataset are required for prediction. The priority of each attribute is to be considered. The Relative importance of attributes can be listed as cp,thalach,thal,oldpeak,ca,age, exang[10].Proposed method can be implemented with 3 modules.

A. User Module In this approach authorized user can add symptoms of patient to system. System will compare added symptoms value with symptoms of different patients stored in dataset and will predict the chance of occurrence of heart attack.

B.  Frequent Pattern Mining Faster-IAPI algorithm is implementing with Spark-  RDD framework. For that first we need to load the transaction data from HDD into Spark RDD framework. For the purpose of loading spark allows direct transition of flat files into RDD and is done using textFile method in spark context. Once the file is loaded, the count of each individual element (symptoms) is identified using flatMap and reduceByKey methods respectively. Once the element count of each symptom is identified, each symptom is taken from the list and is filtered based on a threshold. The resultant symptoms and its co-occurring symptoms are identified and the count is         calculated. The symptoms and co-occurring symptoms is combined to find higher frequent item set (set of frequently occurring symptoms) and its count is calculated. The filtering based on threshold is applied once again to eliminate the infrequent items. The result is written back to file suing save As Text File method of spark context.

C.  Association rule mining In this module, need to discover interesting rules  using frequent patterns generated by Spark RDD framework.

Once the Frequent pattern mining is completed each element in the frequent pattern is iterated to find the confidence. Once the support and confidence is calculated the rules are generated based on the minimum threshold. The rules are written back to the file. This rule helps to predict the occurring chance of heart attack.



V.       CONCLUSION    This paper proposes a mechanism for disease  prediction based on Faster-IAPI algorithm. The algorithm support's incremental mining and it is capable of generating frequent patterns from a massive data store in two database scan.  Our work guarantees the advantage o f  i n -memory computation, over other models using spark RDD framework.

