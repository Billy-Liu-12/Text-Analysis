A Survey on Closed Frequent Itemset Mining on Data  Streams

Abstract? Mining Frequent Itemsets from a transaction database is an very important and most widely used task for analyzing data in any business. It is the preliminary step to find the correlation between the items which are called Association Rules.

Closed Frequent Itemsets are the compact representation of the Frequent Itemsets which can save memory and time for large, dense data. It is very challenging to mine Closed Frequent Itemsets in uncertain data streams due to concept drifts. This paper presents a detailed survey on various popular algorithms developed for mining closed frequent itemsets from data streams.

Keywords?closed frequent itemsets, data streams, frequent itemsets, incremental mining

I.  INTRODUCTION Data Mining is an inter-disciplinary subject applied by many  businesses such as health care, retail, manufacturing etc. for retrieving valuable information from the large amount of data which are used to make better business decisions. Finding frequently occurring patterns which are called Frequent Itemsets and correlations between different items/attributes which are called Association Rules are being used from many years by the business analysts and data scientists as they provide vital information about the business or any phenomenon. Association rules can also be used as base algorithms for Classification and Clustering of the data which are named as Associative Classification and Associative Clustering respectively.

In a dense and high dimension data, a large number of long frequent itemsets can be found. As per the Apriori Principle [1], all subsets of a frequent itemset are also frequent. So for an frequent itemset of length L there are 2L - 2 additional frequent itemsets. Mining all frequent itemsets from a large, dense and high dimension dataset will be very expensive in terms of memory and processing time.

Due to the downward closure property of the frequent itemsets, a large number of frequent sub-itemsets can be merged with their superset if their support is same as their superset thus reducing number of frequent itemsets to store and process. These supersets are called Closed Frequent Itemsets (CFI). Few of the  most popular algorithm for mining CFIs have been discussed in the next subsection of this paper.

Many efficient algorithm for mining CFIs on both static and streaming data have been proposed. Conventional CFIs mining algorithm requires multiple pass over the data and needs complete dataset to be available to its disposal which cannot be satisfied by data streams. The mining algorithm used on data streams should process the data incrementally. Thus finding CFIs over data streams poses additional challenges than mining static data due its uncertainty nature.

In this paper, we have provided a detailed survey on the techniques used to mine CFIs over data streams.  This survey is not an exhaustive research on the every work carried out on the subject but considers popular algorithms developed since its inception till date.

The rest of the paper is organized as follows. Section 2 provides preliminary information about Frequent Itemsets, Association Rules and Closed Frequent Itemsets. A detailed analysis on the previous work carried out on mining CFIs over data streams is provided in Section 3. In Section 4, the key findings of the survey is discussed. The paper is concluded in Section 5.



II. PRELIMINARIES Let I={i1, i2, ..., im} be a set of distinct items. Let D be an  unbound list transactions {T1, T2, T3, T4, ...} representing the continuous data stream, where each transaction t is the subset of

I. Each transaction in the set S is has a unique identifier, called tid. A set of items is referred as an Itemset. If an itemset contains k items then it is called k-itemset.

Let X and Y be an itemset and it is said to be present in a transaction T if and only if X T and Y T.

The support S of an itemset X is defined as the number of transaction the itemset X present in the give list of transactions.

Minimum Support (min_sup) is the support threshold where itemsets with support count below this threshold are considered     infrequent. Itemsets with support count above or equal to this threshold are called Frequent Itemsets.

An association rule X?Y with confidence C is the percentage of transactions in D containing X which also contains Y and it given by the conditional probability, P(Y|X).

Therefore,  confidence(X?Y) = P(Y|X) = support(AUB) support(A)  (1)  An itemset A is said to be closed in a given dataset D if it has no proper superset-itemset B having the same support count as A.

An itemset A is said to Closed Frequent Itemset if A is both closed and frequent in a given dataset D.



III. SURVEY The most popular and commonly used CFI mining algorithms  used for finding CFIs in static data are discussed below.

Mohammed J. Zaki and Ching-Jui Hsiao [2] proposed an efficient algorithm named CHARM for mining all CFIs from static data. The algorithm enumerates closed itemsets using Itemset and Tidset search tree called IT-Tree. They proposed a hybrid search method which skips levels of IT-Tree to quickly find the closed frequent itemsets which reduces the search time.

Vertical data representations are used to produce diffsets which helps in fast computation of frequencies of the itemsets.

However, for large datasets the system will run out of memory as  the algorithm requires all CFIs to be present in the memory for checking closed itemsets.

Jianyong Wang, Jiawei Han and Jian Pei [3] performed extensive study on various strategies for efficient mining of CFIs and proposed CLOSET+ algorithm which integrates advantages of various other effective algorithms along the new strategies. It uses depth-first search strategy as it shrinks search space for long patterns. Horizontal format of data is used to avoid maintaining tidset which will be large and memory consuming for large databases. FP-Tree has been used as compression technique and a novel Hybrid Tree Project method which build bottom-up projection tree for dense data and top-down tree for sparse data.

The item skipping technique efficiently merges the itemsets to form closed frequent itemsets. Experimental results show that CLOSET+ is more memory and time efficient than CHARM.

Xin Ye, Feng We, Fan Jiang and Shaoyin Cheng [4] proposed NewCHARM which is the optimized version of CHARM. Along with CHARM, it uses checkset which to hold the tidset in bit format. It is more memory efficient and faster than CHARM but still requires transaction ids to be managed which is not feasible for large and streaming data.

An detailed analysis of the algorithms used to mine CFIs from data streams is given in Table 1. Many algorithms The list of algorithms referred is not exhaustive but covers most important and popular techniques proposed by research community.

TABLE I.  COMPARATIVE STUDY OF CFI MINING ALGORITHMS ON DATA STREAMS  Authors [Reference] Year Proposed Method Limitations  Yun Chi, Haixun Wang, Philip S. Yu, Richard R.

Muntz [5]    ? Proposed algorithm named MOMENT ? Uses Sliding Window for collecting latest transactions from the  data stream ? Stores itemsets in Closed Enumeration Tree (CET) where each  node stores the itemset with the transaction IDs that particular itemset present  ? Labels nodes in the tree with 4 different labels for making them closed frequent, intermediate, gateway & infrequent nodes  ? The tree gets updated and nodes are relabeled if a change occurs due to new transaction arrived in the window.

? It is the first algorithm proposed to mine closed frequent itemesets from data stream.

1. Requires complete CET to be in memory  which is not feasible for large datasets.

2. CET stores nodes other than Closed Frequent  Itemsets consuming more memory 3. More nodes in the tree makes tree traversal  complex and time consuming 4. Need to specify minimum support which is not  appropriate for unknown streaming data 5. Slides window by only one transaction at a  time which is not appropriate for high speed data stream  Nan Jiang, Le Gruenwald [6] 2006   ? Designed to overcome the limitations of MOMENT [5] mentioned  in point 2 and 4 ? Proposed algorithm named CFI-Stream ? Stores only closed itemsets in proposed Direct Update (DIU) Tree  thus making it more memory efficient than MOMENT ? Tree is organized in Levels (itemset size) so that nodes in the tree  can be directly accessed when a new transaction arrives making the tree traversal faster  ? Use can query for frequent itemsets of his choice of minimum support   1. Requires complete DIU Tree to be in memory  which is not feasible for large datasets 2. Since it stores all closed frequent itemsets  without pruning infrequent itemsets, the size of the tree will be large for sparse data.

3. Slides window by only one transaction at a time which makes is more processing intensive as it checks each itemsets in each transaction for closeness in the DIU Tree.

Ranganath B.N, M.

Narasimha Murty [7] 2008   ? Designed to overcome the limitations of CFI-Stream[6] mentioned  in point 3 ? The CFI_Stream algorithm is extended to work with set of  transactions when the window is slide by more than one transaction.

? The DIU Tree is extended as Lexicographical DIU (LDIU) Tree which orders the itemsets in the tree in there lexical order.

? Along with the support, the count of transactions which are same as the itemset.

? Infrequent itemsets are pruned before scanning the LDIU Tree which makes maintenance of Tree less time consuming   1. Requires complete LDIU Tree to be in  memory which is not feasible for large datasets 2. Need to define order of items if they are  lexicographical 3. Requires re-ordering of the tree when a new  item as arrived which is not present in the current tree  4. Since it stores all closed frequent itemsets without pruning infrequent itemsets, the size of the tree will be large for sparse data.

Guojun Mao, Xialing Yang, Xindong Wu [8] 2008   ? It is an enhancement of MOMENT[5] algorithm ? A new itemset tree named FULL-CET was proposed which is an  extension to CET.

? FULL-CET eliminated the redundancy in CET which made it  more memory and time efficient than MOMENT.

1. Inherits the demerits of MOMENT algorithm  except for memory consumption and tree traversal time  Haifeng Li, Zongjian Lu, Hong Chen [9] 2008   ? An approximation based closed frequent itemset mining has been  proposed.

? The CET of MOMENT[5] is extended to store approximate closed  frequent itemsets.

? User need to define a approximation level lamba whose value  varies from 0 to 1.

? An itemset is said to be approximately closed itemset if it has  support less than lamda multiple of support of its parent.

? Size of the Approximate CET (ACET) is comparatively smaller  than CET as it doesn't contain closed itemsets in the same branch whose support are very close to each other.

1. Inherits the demerits of MOMENT algorithm  except that the closure property is relaxed due to which the memory consumed is less than CET.

2. Contains approximate support of few closed itemsets and not actual support.

Li Zhao, Yongxin Tong, Dan Yu, Shilong Ma, Mengdong Chen [10]    ? It is an extension to MOMENT[5] algorithm ? A compressed pattern (CP) Tree has been proposed where a closed  itemset is covered by its parent if its support is less than specified delta value.

1. Inherits the demerits of MOMENT algorithm  except that the closure property is relaxed due to which the memory consumed is less than CET.

2. Few closed frequent itemsets are approximated to their nearest parent closed frequent itemsets.

Hua-Fu Li, Chin-Chuan Ho, Suh-Yin Lee [11] 2009   ? Proposed a method named NewMOMENT, an extension to  MOMENT[5] ? Instead of processing transactions directly, the NewMOMENT  converts the transaction into BitVector format.

? Since instead of storing the transaction list, the bit vector format of  the transactions are stored in nodes which reduce memory consumption compared to MOMENT   1. Inherits the demerits of MOMENT algorithm  except that this algorithm consumes more time in processing transactions in the current window as it needs to convert the transactions to BitVector Format. It is worst if the window size and number of items are large.

Guanglu Zhang [12] 2010   ? Uses Sliding Window for reading transactions ? BitVector is used to store the presence of item in the transaction ? Digraph is used to store the closed frequent itemsets where each  node is the item and contains link flow higher order item to lower order items which complte itemsets.

? Each link contains the count of 2-itemsets.

1. Requires lexical ordering of the items for  forming digraphs 2. Each node has to maintain the transaction list  in Bit Vector format which will grow endlessly for continuous high speed data streams.

Show-Jane Yen, Cheng-Wei Wu, Yue-Shi Lee, Vincent S. Tseng, Chaur-Heh Hsieh [13]    ? Proposed new algorithm named CloStream which doesn't require  searching for previous closed frequent itemsets for finding current closed frequent itemsets.

? Stores all Closed Frequent itemsets.

? Uses table structure (two tables used) to store the itemsets instead  of conventional tree or graph format.

? Improved processing time compared to MOMENT[5], CFI-  Stream[6] and NewMOMENT[11]   1. Takes more time to process compared to  MOMENT and NewMOMENT when the minimum support is higher.

2. Has to update two tables for each update.

Ye-In Chang, Chia-En Li and Wei-Hau Peng [14] 2012   ? Uses lexical order of the items ? Use bit sequence for representing presence of item in the  transaction.

? Uses Sliding Window ? Itemsets are stored in Subset-Lattice format which is an extension  of Lattice. An extra link from superset to subset is added in the proposed Subset-Lattice format.

? Stores all Closed Frequent itemsets ? Processing time is less than NewMOMENT[11]   1. The complete set of items that can contain the  data stream shall be known prior for lexical ordering of items.

2. Consumes more time for high dimensional data.

3. Slides window by only one transaction at a time which makes is more processing intensive  Cao Xiaojun [15] 2012   ? Uses damping sliding window where the size of window gets  reduces as more number of transactions are processed.

? Finds Top K Closed Frequent Itemsets ? Uses weighted support count for each items which helps in  adjusting the minimum support.

? Memory efficient as it stores only Top K Closed Frequent  Itemsets.

1. For an uncertain data stream, mentioning K  value can be difficult as there could be more important itemsets beyond K or may be less important itemsets within K.

Vikas kumar, Sangita Rani Satapathy [16] 2014   ? It is an extension of MOMENT [5] ? Uses variable sliding window instead of fixed sliding window as in  case of MOMENT ? The size of window expands when there is no concept drift and  reduces when the concept drift occurs.

? For each window processed, the concept drift is calculated using  the difference in newly arrived frequent itemsets and previously frequent but currently infrequent itemsets.

1. Inherits demerits of MOMENT algorithm  except that this algorithm is more adaptable to concept drift.

Massimo Quadrana, Albert Bifet and Ricard Gavald? [17]    ? Implemented IncMine algorithm which uses a error parameter to  save potential closed frequent itemsets but currently infrequent itemset. These itemsets are called Semi-Frequent Closed Itemsets.

? The implementation is performed using Massive Online Analytics (MOA) toolkit and results are compared with MOMENT [5].

? Semi-Frequent Closed Itemsets are stored in a new data structure called inverted Index Structure.

? The minimum support threshold is progressively updated to reduce the number of itemsets to process based on the quality of the semi- frequent closed itemsets.

1. Memory intensive as it has to store index table  for semi-frequent closed itemsets for all previous windows.

Bay Vo, Tuong Le, Tzung- Pei Hong, Bac Le [18] 2015   ? Uses diffSet instead of tidSet for creating frequent itemset lattice.

? DiffSet is the set of transaction Ids which are not present in its  subset.

? Requires less memory as only the difference is stored instead of  complete list of transaction IDs.

? Maintains Pre-Large Itemset list to avoid rescanning of the lattice  when new transactions are read.

1. Requires 1-itemsets to be ordered in  descending order of their support which is not feasible for uncertain data due to concept drift.

Komate Amphawan, Philippe Lenca [19] 2015   ? Finds Top K Closed Frequent Itemsets ? Uses minimum length for the itemsets to consider. This will prune  most itemsets whose length is less than minimum length.

? Uses Partitioned Dynamic Bit Vector (PDBV) format which is  extension to Dynamic bit Vector (DVB) to store tid set for items which is very compact thus saving memory.

1. Finds only regular patterns i.e. the pattern  should occur regularly within some transactions limit. This limit should be specified by the user. Doesn't suit well for sparse data.

Zahoor ur Rehman, Muhammad Shahbaz, Muhammad Shaheen, Aziz Guergachi [20]    ? Finds Top K Closed Frequent Itemsets ? Uses both minimum length and maximum length for the itemsets  to consider for processing. This will prune most of the less interested itemsets.

? Uses Bitvector for representing tids for items.

1. Needs specification of both Minimum and  Maximum length of the itemset which is of user interest. But most of the time users will not have enough knowledge to set these values for uncertain data.

Riddhi Anjankumar Shah, M. Janaki Meena and S.P.

Syed Ibrahim [21]    ? Finds Top K Closed Frequent Itemsets ? Experimented on Big Data context where the algorithm is tested on  single and multi node configuration.

? Used bit vector for representing tids for items ? Itemsets are stored in lattice format   1. Uses a naive method to find closed frequent  itemsets 2. Not tested for concept drift  Koji Iwanuma, Yoshitaka Yamamoto, Shoshi Fukuda[22]    ? The algorithm is developed by merging Lossy Counting and  CloStream[13] algorithms and named as LC-CloStream ? While computing support of the itemsets in the sliding window  lossy counting is used and CloStream is used for maintaining the itemset tree   1. Support values are approximated and error  introduced can vary depending density of the data which cannot be quantified accurately.

Dai Caiyan, Chen Ling [23] 2016   ? Proposed dynamically construction of pattern tree and calculate  densities of the itemsets in tree using a time fading factor.

? The infrequent itemsets whose density is less than threshold are  timely deleted from the pattern tree reducing the memory and processing time  ? From the pattern tree, Head table and Frequent Closed Itemset Table   1. Error gets introduced due to timely deletion of  low density itemsets which can be improved to increase the accuracy of the closed frequent itemset and their support values.



IV. KEY FINDINGS OF THE SURVEY Earlier algorithms extended frequent itemset mining  algorithms to mine CFIs and used tree and lattice data structures.

While some algorithms required minimum support to be specified, couple of algorithms were developed to mine all CFIs from the data stream. Recent techniques are focused on mining top K CFIs where user need not have mention minimum support but need to specify the K value. From our previous work on mining approximate frequent itemsets from data streams [24], we have observed that specifying an optimum minimum support threshold is not possible for an uncertain data stream. For lower minimum support threshold, we will find a very large number of frequent itemsets for dense data but none or very small number for sparse data. So either the algorithm should mine all CFIs or shall learn the value of minimum support threshold value from the data itself based density and drifting concepts.

Due to limited memory in the computational systems, algorithms have been continuously improved for better memory utilization. Different data structures like tree, lattice, table form etc have been proposed. Since tree and lattice format compresses the original database to a large extent, traversing it is complex and time consuming. So hybrid method of using tree or lattice along with table format is preferred. The algorithm shall not require the complete list of CFIs to be in the memory for searching. Instead should adopt techniques to merge itemsets with acceptable approximation and develop an compact structure to quickly identify CFIs from latest transactions from data streams reducing the memory footprint and processing time.

To make the algorithms faster and memory efficient, approximation, minimum length, maximum length of itemsets etc have been used to prune infrequent and uninterested itemsets. If the dimensionality of the data is uncertain then it will be difficult  to specify the minimum and maximum length of the interested itemsets. The error introduced due to approximation will not be constant for all the itemsets for both dense and sparse data. The error will be more for less frequent sparse data bur less for frequent and dense data. So there is a need for an algorithm to use approximation with less error or specified acceptable error with uniform error distribution.

Big data has gained lot of focus in the recent years. Due to the wide use of internet enabled smart portable devices, increased deployment of Internet-of-Things (IoT) etc has pushed several applications to process the high speed data stream in faster and distributed manner. Since big data analytics and distributed computing has gained focus from recent years, the algorithm for mining CFIs on high speed data from parallel different source shall be developed using distributed computing techniques. This also complicates the data structure used to store CFIs as it also needs to be distributed.

Last but not the least, the distributed data structure used to store CFIs from big data stream shall be queried in real-time. A distributed query processing framework shall be developed which can process user queries and return the result in real-time.



V. CONCLUSION Even though data mining is being performed on small and  large databases from many decades, mining data streams were not a regular practice due to its complexity. But as the size and frequency of micro data generation increased like IoT, Retail transactions, GPS, Smart Phones etc, demand for faster and real- time data mining algorithm have raised. Businesses requires decision to be taken in real-time with change in nature of the business operations and customer preferences. These demands can be fulfilled by mining data streams as they arrive before storing in the persistent storage.

Mining data streams is very complex and challenging as conventional assumptions of static data does not apply. Also data stream mining algorithms can be used on static data directly by reading the static data record by record as stream. But it is not possible to use any algorithm designed for static data mining to mine streaming data directly.

In this paper, we have performed a detailed analysis of the important techniques used till date to mine CFIs from uncertain continuous data streams and analyzed their advantages and limitations. Also the applicability of these algorithm for parallel and distributed computing environment to mine big streaming data is studied. From this study, few major research gaps have been identified and discussed in detail. In future, new solutions shall be developed to mine Closed Frequent Itemsets from Data Streams for parallel different sources on a big data platform to overcome the drawbacks of the current techniques.

