IT Capacities Assessment Tool: A Survey of Hospitals in Canada

Abstract   This study presents an IT assessment tool that aims at capturing the level of IT sophistication in hospitals. In order to develop a measure that reflects IT capacities in hospitals, an IT scoring approach was proposed that incorporate eight IT dimensions related to the implementation of computerized processes and emerging technologies, and the level of internal and external systems integration. The instrument was validated through a survey of hospitals in two provinces in Canada (Qu?bec and Ontario), and the psychometric properties revealed a good level of validity and reliability. Based on the results of the survey and the IT scores obtained, hospitals in both provinces seem to have a moderate to high level of implementation of various computerized processes; limited implementation of clinical systems was observed. Low IT scores were reported in relation to the implementation of emerging technologies. The level of systems integration was moderate with significantly higher level of integration among hospitals in Ontario; limited clinical systems integration was observed.

1. Introduction   Since the release of the Institute of Medicine reports, ?To Err is Human? [1] and ?Crossing the Quality Chasm? [2], health information technologies (IT) have gained increasing attention and have been recognized as essential components for an improved health system. In a recent report presented by the national coordinator for health  information technology in the U.S. [3], there was a clear emphasis on the value of IT in achieving consumer-centered care. Similarly, efforts in Canada that encourage fast deployment of technologies are underway, as demonstrated by the national funding of projects in various IT-related areas across provinces (e.g., electronic health records, telehealth, etc.) [4].

Hospitals, which represent essential  components of health care systems, are continuously exploring opportunities for investing in IT to improve efficiency, promote patient safety, and better quality of care [5-7]. According to a recent survey by the American Hospital Association (AHA) on hospital use of IT, around 46% of hospitals reported moderate to high use of clinical IT in 2006 [8], which represents an increase compared to previous years. At present, IT priorities are mostly related to reducing medical errors, upgrading / replacing inpatient clinical systems, and implementing electronic medical records [9]. A recent survey of hospitals in Ontario also showed that the implementation of technologies that reduce medical errors and promote patient safety was ranked as top e-health priority for hospitals [10].

Despite recognizing the role of IT as a critical  enabler for patient safety and quality of care and the increasing efforts invested by hospitals to benefit from these resources, little is known about the level of IT capacities in these settings.

Although scattered efforts have been made to develop measures that gauge IT in hospitals (e.g., [11-14]), no comprehensive tool exists that captures the level of IT sophistication and allows        the development of a valid IT score. Prior efforts in this area remain constrained by limitations associated with the measures and tools used. For instance, the crude nature of the indicators, the absence of a consistent scale that reflects the extent of implementation of various applications and technologies in hospitals and the lack of a well- developed scoring approach to gauge IT capacities in hospitals are examples.

This research addresses these issues, proposes  an instrument for assessing IT capacities in hospitals, and validates it through a survey of Canadian hospitals. For this purpose, a comprehensive literature review was conducted to build on existing evidence and identify prior efforts to assess IT in hospitals. The results were mapped using the original conceptual framework developed by Par? and Sicotte [15], which defined IT sophistication along three dimensions (functional, technological, and integration). The term ?IT sophistication? is used to represent IT capacities in hospitals, including various applications and technologies as well as the integration among different systems. This paper focuses on the findings of the survey, and provides an overview of the IT scoring approach used to represent the level of IT sophistication in hospitals.

2. Description of the instrument   A comprehensive literature review was conducted on Medline until September 2006 to build on the existing evidence and identify prior efforts that attempted to assess IT in hospitals. A total of 17 studies that provide indicators of clinical and administrative IT capacities were found. Six varied in their approaches to address this issue (e.g., [16-18]), while 11 studies that represent two more recent streams of research in this field relied on two IT measurement instruments in hospitals (e.g., [12,13,19-21]). Although the recently developed instruments presented important contributions in this area, limitations remained in relation to the absence of instrument validation, the crude nature of the measures, and the absence of a valid scoring approach (e.g., [12,13]). The length of the instrument and lack of a consistent scale to reflect the implementation of various applications and technologies represent additional issues that must be addressed (e.g., [15,19,21]).

We mapped the results of these studies using  the original conceptual framework proposed by Par? and Sicotte [15]. Subsequently, an IT assessment tool was developed that included 34  items exploring computerized processes in four areas (administrative, clinical, patient management, and clinical support activities), 13 items assessing the implementation of contemporary technologies, and 11 items investigating internal and external information sharing (Appendix A). We further incorporated a time frame in the tool to reflect current versus plans for implementation of IT; in the former, the extent of use of computerized processes and technologies was further assessed on a [1-7] scale. A general information section about the respondents and organizations was introduced at the end of the instrument.

3. Methodology  3.1 Sample and data collection  In order to apply the IT assessment tool and evaluate its psychometric properties, we conducted a survey of health care organizations in two Canadian provinces (Qu?bec and Ontario) between June and September 2007. All hospitals in these two provinces, which represent the largest health jurisdictions in Canada in terms of population served and health infrastructures, were invited to participate in this study. As part of the pretest, seven respondents (three from Qu?bec, two from Ontario and two from the United States) completed a first version of the questionnaire and provided feedback about the process (e.g., administration time, clarity of directions) and the measures. Following the pretest, a number of minor changes were incorporated in order to improve the measures and the questionnaire?s overall structure and clarity.

The revised version of the questionnaire, with a cover letter indicating the purpose and the importance of the study, was sent to all hospitals in Qu?bec and Ontario. As a first step, we contacted IT directors / administrators by phone, excluding those who had participated in the pretest, to present the study and solicit their participation (Qu?bec: N=92; Ontario: N=129). Five IT directors in Qu?bec and 12 in Ontario refused to participate due to reported time constraints; they were excluded from the survey. A hard copy of the questionnaire was then sent with a return envelope to all remaining organizations. Four weeks following the initial mailing, a reminder letter was mailed to the organizations that had not responded.

In total, 60 and 46 responses were received in Qu?bec and Ontario, respectively, which represents an overall response rate of 52% (106 hospitals).

3.2 Measurement issues   As indicated in Figure 1, following Par? and Sicotte?s model for assessing IT sophistication [15], which was validated among hospitals in the U.S. and Canada [15,19], eight dimensions provided the conceptual framework for the survey instrument used in this study. The first four dimensions refer to Functional IT sophistication, the fifth dimension relates to Technological IT sophistication, and the last three dimensions refer to the Integration level:   D1 = Administrative systems (9 items) D2 = Patient management systems (8 items) D3 = Clinical support systems (4 items) D4 = Clinical systems (13 items) D5 = Emerging technologies (13 items) D6 = Internal integration ? Administrative  (Enterprise Resource Planning system) D7 = Internal integration ? Clinical (Electronic  Medical Record system) D8 = External integration (9 items)   A total of 58 items were included in the questionnaire. For the first five dimensions, the respondents were asked to check the answers that best reflect the current status of various computerized processes and technologies in their organizations. They could choose between: 1) No plan for implementation; 2) Planning to implement; 3) Began installation; and 4) Implemented. If they chose ?Implemented? for questions under D1-D5, then they were also asked to identify on a [1-7] scale the extent to which the  systems or technologies are currently used (1 = ?Barely Used? and 7 = ?Extensively Used?).

For the internal integration dimensions (D6  and D7), respondents were asked to check the answers that best reflect the current status of Enterprise Resource Planning (ERP) and Electronic Medical Record systems (EMR). They could choose between: 1) No plan for implementation; 2) Planning to implement; 3) Began deployment; and 4) Implementation completed. If they selected ?Began deployment? or ?Implementation completed?, they were also asked to choose the modules that are being deployed in the case of ERP, or the systems that are fully integrated with the EMR; a list of modules and systems was provided to them.

Last, respondents were asked to identify the  extent of information sharing with external entities (dimension D8) on a [1-7] Likert scale (1 = ?Not at All? and 7 = ?Very Much?). The last section of the instrument included questions that provide an overview about the respondents and their respective hospitals.

3.3 Scoring approach   We developed a scoring approach that assigns weights (points) to the questions in the survey and allows the calculation of an IT score for each dimension, as well as an overall IT score for hospitals.

First, items measuring the status of  computerized processes and technologies within hospitals (dimensions D1 ? D5) were assigned the following weights: 1) No plan for implementation = 0 point; 2) Planning to implement = 1 point; 3) Began installation = 3 points; 4) Implemented with weak utilization as indicated by answers within the [1-4] interval on the Likert scale = 4 points; and 5) Implemented with strong utilization as indicated by answers within the [5-7] interval on the Likert scale = 5 points. It is important the note however that four items assessing the implementation of advanced computerized processes (clinical & support staff workload management; remote monitoring applications; on- line consumer health information; on-line patient appointment) were excluded from the calculation of scores due to the absence of variability in our sample and the consistently very low implementation levels.

Figure 1: Conceptual model representing IT capacities in hospitals.

HOSPITAL   External Entities  Systems Integration with Other Entities       Technological IT  Capacities   Emerging Technologies  Internal Integration Clinical  Administrative       Functional IT Capacities   Clinical  Administrative Patient Management  Clinical Support        Second, the questions assessing internal integration (dimensions D6 and D7), which represent the extent of implementation of ERP and EMR systems, were assigned similar weights as above: 1) No plan for implementation = 0 point; 2) Planning to implement = 1 point; 3) Began deployment = 3 points; 4) Implementation completed with (1-3) ERP modules or 1-4 systems integrated with the EMR = 4 points; and 5) Implementation completed with more than 4 ERP modules or more than 5 systems integrated with the EMR = 5 points.

The resulting score (over 100) for the first  seven dimensions (D1 to D7) equals the sum points for all items under a specific dimension, divided by the total number of items in that dimension multiplied by 5 (i.e. maximum number of points for an item), times 100:         Third, the questions measuring the external  integration of systems (Dimension D8), which was assessed on a [1-7] scale, were assigned the following weights: 1) No external integration (i.e.

1 on the Likert scale) = 0 point; 2) Minimal external integration (i.e. 2 and 3 on the Likert scale) = 1 point; 3) Moderate level of integration (i.e. 4 on the Likert scale) = 3 points; 4) High level of external integration (i.e. 5 and 6 on the Likert scale) = 4 points; and 5) Very high level of external integration (i.e. 7 on the Likert scale) = 5 points. Five items, which did not present variability and showed consistently very low information sharing levels (with drug stores; with insurance companies; with external laboratories; with governmental agencies; with patients), were excluded. The score (over 100) for the external integration dimension D8 equals the sum of points for the four items measuring external integration, divided by the total number of items (i.e. four) multiplied by the maximum number of points for an item (i.e. five), times 100:        Based on the answers to the questions falling  under the eight IT dimensions in the survey, IT  scores representing functional IT capacities, technological IT capacities,  internal and external integration, and an overall IT score (over 100) can be computed for hospitals as follows:              The overall IT scores can range from 0 to 100.

A score of zero represents no current or plans for implementation of systems and technologies along the dimensions D1 to D7, and no external integration at all. A score of 100 is associated with strong utilization of technologies and systems, and very high systems integration. By using this formula, hospitals can assess their level of IT capacities in various areas, examine the evolution of their scores over time, and compare themselves to other hospitals. Scores falling in the following ranges are expected to represent different levels of IT capacities:  Scores between 0 and 25: Very low level of IT sophistication with minimal computerized processes and technologies, and limited levels of integration.

Scores between 26 and 50: Low to moderate level of IT sophistication; the level of IT capacities might vary according to the eight dimensions.

Scores between 51 and 75: Moderate to high level of IT sophistication; the level of IT capacities may vary according to the eight dimensions.

Scores between 76 and 100: High level of IT sophistication with implemented computerized processes and emergent technologies, and good levels of systems integration.

3.4 Data analysis   First, descriptive analysis was conducted to provide an overview of the respondents and their respective organizations, and present the findings of the survey on IT capacities in hospitals along the eight IT dimensions. Specifically, the percent of hospitals in each of the categories of implementation was determined. Second, Chronbach Alpha and correlation coefficients were computed to assess the reliability and validity of the IT sophistication measures used.

Score (Dx) = Sum of points for all items * 100 (5 * No. items in Dx)  Where Dx = D1 ? D7  Score (D8) = Sum of points for four items*100  Functional IT score = Sum (D1 to D4) Technological IT score = D5  Integration score = Sum (D6 to D8)  Overall IT score = Sum (D1 to D8)         Table 1: Profile of the respondents and hospitals.

Profile of Respondents Quebec  n=60 Ontario  n=46 Total n=106  High school / College  10% 24% 16%  Undergraduate   46% 36% 41%  Highest degree of education  Master level  44% 40% 42% Administration   37% 22% 31% Computer science   27% 17% 22% Information systems 24% 39% 31% Computer engineering  9% 2% 6%  Project management  2% 5% 3% Medical informatics   - 12% 5%  Main area of specializationa  Others  1% 3% 2% Mean  [range] Mean  [range] Mean  [range ] Years experience in current position   7  [1 - 30]  [1 - 31]  [1 - 31] Years experience in the current healthcare organization  [1 - 31]  [1 - 33]  [1 - 33]  Years experience in IT  16 [1 - 35]  [3 - 37]  [1 - 37]   Profile of Hospitals  N (%) N (%) N (%) Urban healthcare organization   41% 33% 38% Affiliation with a teaching university   55% 39% 48% Organizations with emergency room    93% 91% 92% Organizations with operating room(s)a   92% 76% 85% Organizations with intensive care unitb  88% 59% 75% Mean  [range] Mean  [range] Mean  [range] Number of bedsb 430  [42 - 1227]  [18 - 1120]  [18 - 1227] Annual budget 150 M$  [12 - 750M$] 160 M$  [4 - 1200M$] 155M$  [4 - 1200M$] Number of physicians 223  [14 - 1300]  [20 - 2500]  [14 - 2500] Number of registered nurses 1 015  [60 - 10000]  [30 - 4000]  [30 - 10000] Significant differences between Qu?bec and Ontario: a : p<.05; b : p<.005    Third, IT scores were computed over 100 to reflect the level of IT sophistication along the eight dimensions, and the overall IT scores in hospitals.

Last, significant differences on the respondent and hospital characteristics, and the IT scores between hospitals in Qu?bec and Ontario were assessed using Chi Square and t-tests.

4. Results   This section presents the survey findings and is divided into three parts: 1) Sample overview; 2) Psychometric properties of the instrument; and 3) IT capacities and overall IT scores.

4.1 Sample overview   As indicated in Table 1, most of the respondents in both provinces had either an undergraduate or master level education, and varied in backgrounds with the majority having an area of specialization in administration or  information systems / technology. The managerial and IT tenure among the surveyed CIOs / IT directors was high; the average years of experience in IT was 17 years with more than 10 years experience in the current organization and 8 years in the current position.

The profile of the surveyed hospitals shows that more than half were not affiliated with a teaching university (52%) and were characterized as rural hospitals (62%). Yet, the average size of the hospitals was 354 beds, and the majority reported having emergency rooms (92%), operating rooms (85%), and intensive care units (75%) in place.

Hospitals in Qu?bec were significantly larger and had more intensive care units and operating rooms than hospitals in Ontario.

4.2 Psychometric properties of the instrument   In order to assess the reliability of the measures used to assess IT capacities in hospitals, Cronbach alpha coefficients were computed, which are good indicators of internal consistency. With the exception of the measures falling under the clinical support applications dimension, which were associated with a coefficient of 0.65, all coefficients for the other dimensions varied between 0.70 and 0.85, which indicates a good level of reliability of the measures developed.

Construct validity, which refers to the ability of an instrument to measure specific constructs and traits [22], was also determined to examine whether the developed measures behave as expected. As Table 2 shows, the correlations on the leading diagonal (correlations between similar measures), which represent the square root of the variance shared by the dimensions and their measures, are larger than off diagonal correlations among dimensions. This is reflective of convergent and discriminant validity [22].

Table 2: Construct validity of IT measures in the eight dimensions.

D1 D2 D3 D4 D5 D6 D7 D8  D1 .68 D2 .51 a .82 D3 .27 b .41 a .69 D4 .37 a .58 a .31 a .79 D5 .51 a .65 a .34 a .65 a .81 D6 .07 ns .06 ns .02  ns .13 ns  .10 ns  -  D7 .05 ns .25 b .25 c .48 a .35 a .08 ns - D8 .16 ns .12 ns .23 c .33 a .26 b .08 ns .31 a .83  a : p<.001; b : p<.05; c : p<.01; ns = non significant D1 = Administrative applications D2 = Patient management applications D3 = Clinical support applications D4 = Clinical applications D5 = Contemporary technologies D6 = Internal integration - administrative D7 = Internal integration ? clinical D8 = External integration    Table 3: Distribution of hospitals for computerized administrative processes.

Administrative Systems  No Plan for Implementation  Planning to Implement  Began Installation Implemented  Accounting / Financial IS  QC ON  -- --  -- --  3% --  97% 100%  Disease costing QC ON  43% 39%  10% 20%  5% 2%  42% 39%  Material management  system  QC ON  -- 2%  3% 11%  5% 4%  92% 83%  Human resources  management system  QC ON  3% 4%  4% 7%  5% --  88% 89%  Staff scheduling  system  QC ON  2% 20%  15% 22%  10% 4%  73% 54%  Financial dashboards  QC ON  12% 28%  25% 33%  15% 4%  48% 35%  Business intelligence applications  QC ON  23% 50%  22% 26%  13% 2%  42% 22%  E-Commerce for material purchasing  QC ON  57% 44%  17% 17%  2% 6%  25% 33%  IS = Information system; QC = Quebec; ON = Ontario   Table 4: Distribution of hospitals for computerized patient management processes.

Patient Management Systems  No Plan for Implementation  Planning to Implement  Began Installation Implemented  Ambulatory care scheduling system  QC ON  -- 26%  5% 20%  8% 6%  87% 48%  ADT system QC ON 2% 7%  2% -  - 2%  96% 91%  Master Patient Index (MPI)  QC ON  2% 7%  30% 4%  18% 2%  50% 87%  Patient chart tracking system  QC ON  27% 20%  22% 15%  - 2%  52% 63%  Emergency room system (nQC=56) (nON=42)*  QC ON  -- 38%  16% 27%  9% 7%  75% 28%  Operating room management system* (nQC =55) (nON =35)  QC ON  15% 20%  9% 23%  3% 3%  73% 54%  Critical care systems* nQC=53) (nON =27)  QC ON  68% 2%  17% 50%  -- 4%  15% 44%  * nQC = Number of hospitals that responded to these questions in Quebec. nON = Number of hospitals that responded to these questions in Ontario.

QC = Quebec; ON = Ontario      4.3 IT capacities and scores  4.3.1. Computerized processes   The extent of implementation of computerized  processes varied according to the IT dimensions examined. The early administrative computerized systems (e.g., material management systems, accounting / financial information systems) were implemented in the majority of hospitals, with comparable levels in the two provinces. The new generation of administrative systems however (e.g., business intelligence applications, disease costing systems) is still not widely implemented, and hospitals in Qu?bec seem to be ahead in introducing these systems as compared to hospitals in Ontario (Table 3).

As indicated in Table 4, the implementation of  patient management systems varied between hospitals in Qu?bec and Ontario. Hospitals in Qu?bec have more advanced capacities with respect to operating room systems, emergency room systems, and ambulatory care scheduling systems. An opposite trend is observed however with respect to the implementation of the Master Patient Index (MPI) with the majority of hospitals in Ontario (87%) having these systems in place.

Interestingly, critical care systems were only implemented in a small number of hospitals in both provinces and only hospitals in Ontario reported considering future implementation of these systems.

Computerized clinical support processes  including laboratory, pharmacy, and radiology information systems were widely implemented with more than 80% of hospitals in both provinces reporting these systems in place.  The only difference between the two provinces was related to the implementation of Picture Archiving and Communication System (PACS) (76% in Ontario vs. 55% in Qu?bec), although 31% of the hospitals in Qu?bec had plans for implementing these systems.

Last, the implementation of the majority of computerized clinical processes was limited, with the exception of electronic discharge summary, on- line access to knowledge database, and continuous quality improvement / risk management systems (Table 5). Specifically, advanced systems (e.g.,        Table 5: Distribution of hospitals for computerized clinical processes.

Clinical Systems No Plan for Implementation Planning to Implement  Began Installation Implemented  Nursing documentation  QC ON  38% 6%  45% 46%  3% 20%  14% 28%  Clinical documentation  QC ON  30% 15%  42% 46%  2% 17%  26% 22%  Continuous quality improvement / Risk management  QC ON  5% 17%  17% 20%  3% 11%  75% 52%  Electronic discharge summary  QC ON  5% 22%  5% 24%  2% 11%  88% 44%  Electronic dictation  QC ON  22% 38%  2% 4%  23% 4%  53% 58%  Order entry / Results reporting  QC ON  13% 11%  28% 30%  10% 9%  48% 50%  Computerized Physician Order Entry (CPOE)  QC ON  52% 17%  40% 67%  3% 9%  5% 7%  Clinical decision support  QC ON  63% 35%  27% 43%  3% 9%  7% 13%  On-line access to knowledge database  QC ON  18% 9%  2% 15%  -- 2%  80% 74%  E-learning applications  QC ON  45% 26%  18% 28%  8% 13%  28% 33%  Telemedicine  QC ON 25% 9%  23% 9%  10% 4%  42% 78%  QC = Quebec; ON = Ontario   Table 6: Distribution of hospitals for emerging technologies.

Emerging technologies No Plan for Implementation Planning to Implement  Began Installation Implemented  Medical record scanning QC ON 47% 35%  37% 30%  3% 9%  13% 26%  Biometry QC ON 42% 68%  38% 26%  5% 4%  15% 2%  Single sign-on technology  QC ON  43% 39%  43% 44%  7% 2%  7% 15%  Bar coding for supplies / material management  QC ON  27% 28%  18% 39%  10% 7%  45% 26%  Bar coding for medications management  QC ON  22% 37%  52% 43%  5% 9%  21% 11%  Bar coding for patient identification  QC ON  47% 23%  40% 50%  3% 7%  10% 20%  Robots (medication preparation / dispensing)  QC ON  12% 70%  35% 9%  10% 2%  43% 19%  Voice recognition QC ON 50% 39%  35% 26%  5% 9%  10% 26%  Portable computing / wireless devices  QC ON  27% 17%  23% 35%  12% 11%  38% 37%  RFID technology QC ON 67% 63%  27% 26%  3% --  3% 11%  Administrative data warehouse  QC ON  10% 52%  18% 20%  17% 4%  55% 24%  Clinical data warehouse QC ON 25% 46%  37% 28%  8% 2%  30% 24%  Bedside terminals or PCs QC ON 82% 44%  18% 35%  - 2%  - 19%  QC = Quebec; ON = Ontario   Table 8: Hospitals IT scores.

Dimension Total  Sample (n=106)  Quebec Hospitals  (n=60)  Ontario Hospitals  (n=46) D1 Administrative systems a 64.5 67.6 60.3 D2 Patient management systems a 63.6 67.2 58.9 D3 Clinical support systems 83.5 82.3 85.1 D4 Clinical systems 52.1 51.0 53.6 D5 Emerging technologies 30.1 31.7 28.2 D6 Internal integration - Administrative 74.1 78.0 69.1 D7 Internal integration - Clinical b 44.6 34.9 57.0 D8 External integration b 33.7 25.5 44.3  Overall IT sophistication score 56.3 55.0 58.0 Functional IT sophistication score 66.3 67.0 65.4 Technological IT sophistication 30.1 31.7 28.2 Integration level b 50.9 46.3 56.8 Significant differences between Qu?bec and Ontario: a : p<.05; b : p<.005    computerized physician order entry, clinical decision support) were not available in the majority of the hospitals despite reported plans for their implementation. Telemedicine however was used in 78% of hospitals in Ontario, which represents a significant penetration of these processes as opposed to Qu?bec (42%). Order entry / results reporting systems were implemented in around half of the sample, but these systems are expected to become more prevalent with a large number of hospitals planning to implement them.

\  4.3.2 Emerging technologies  As indicated in Table 6, the implementation of  contemporary technologies (e.g., voice recognition, RFID technology, bar coding for patient identification, single sign-on technology, biometry) was minimal as compared to the implementation of computerized processes. Hospitals in Qu?bec are leading on some of technologies (e.g., bar coding for material and medications management, robots for medication preparation and dispensing, biometry, administrative data warehouse). On the other hand, more hospitals in Ontario reported having technologies such as single sign-on, voice recognition, medical record scanning, bar coding for patient identification, and bedside terminals in place. Although most technologies were not widely used, a large number of hospitals reported plans for their implementation, with the exception of advanced technologies (e.g., RFID, biometry, voice recognition and bedside terminals). .

4.3.3. Internal and external integration   The level of internal integration for  administrative systems, as reflected by the implementation of ERP modules was high in both provinces. The majority of hospitals reported ERP in place (85% in Qu?bec and 78% in Ontario). The        Table 7: External systems integration.

Mean* [Range] Extent of information sharing with?  QC ON  Other acute care organizations 2.5 [1-7] 4.4  [1-7]  Long term care organizations 2.3 [1-7] 3.2  [1-7]  Primary care organizations 2.5 [1-7] 3.5  [1-7]  Medical clinics 2.6 [1-7] 3.2  [1-7] * The extent of external systems integration was assessed on a [1-7] scale with 1 = ?Not at all? and 7 = ?Very much?.

QC = Quebec; ON = Ontario    level of internal integration of clinical systems however was lower as indicated by the poor implementation of EMR and the internal systems integrated with them. In this case, more hospitals in Ontario had either implemented (37%) or began installation of EMR (30%), as compared to hospitals in Qu?bec (18% and 20%, respectively).

Similarly, hospitals in Ontario had a higher level of external integration with outside facilities than in Qu?bec (Table 7).

4.3.4. IT scores   We further computed IT scores for hospitals, which revealed information about their IT capacities (overall and along the eight dimensions).

As indicated in Table 8, hospitals in Qu?bec and Ontario did not differ significantly on their overall IT sophistication; the overall IT sophistication score for the sample was moderate (score = 56.3).

A closer examination of the results shows that functional and technological IT sophistication were not significantly different between the two provinces. The overall functional IT score was moderate to high (score = 66.3) while the technological IT score that was low (score = 30.1).

The two provinces differed significantly on the scores for the integration level (Ontario: 56.8; Qu?bec: 46.3), which was moderate in both cases.

In general, the lowest IT scores were observed  for clinical systems, emerging technologies, and external integration, which indicate limited capacities with respect to these dimensions; the scores for emerging technologies were particularly low in both provinces. The highest scores however were observed for clinical support systems and internal integration of administrative systems, which were moderate to high.

Significant differences were observed between the two provinces for administrative and patient management systems; hospitals in Qu?bec had significantly higher scores on these two dimensions. On the other hand, significantly higher levels of internal integration of clinical systems were reported in Ontario (Table 8).

5. Discussion   Although progress has been made over the past years in relation to assessing IT capacities in hospitals (e.g., [13-15, 24-26]), prior measures have been constrained by conceptual and methodological issues, which precluded the development of an IT scoring approach that reflects the level of IT capacities in hospitals.  This research addresses these issues and proposes an IT capacities assessment tool and a comprehensive IT scoring approach that captures various dimensions of IT sophistication in hospitals.

The instrument was validated through a survey  of hospitals in two provinces in Canada, and the psychometric properties demonstrated a good level of validity and reliability of the measures. The findings show a moderate level of IT sophistication among hospitals in Qu?bec and Ontario.

With respect to functional IT sophistication,  hospitals in Qu?bec and Ontario reported moderate to high levels of implementation of computerized processes, with the exception of computerized clinical systems that were not widely available in these settings. Although these systems have the potential to reduce errors and support clinical decision making (e.g., nursing and clinical documentation, CPOE, and clinical decision support systems), they were still not widely used among the surveyed hospitals. Nevertheless, the high percent of hospitals reporting plans to implement these systems highlights current efforts undergone to address this issue.

A closer examination of the other dimensions  along functional IT sophistication reveals that hospitals in Qu?bec have a higher level of implementation of administrative and patient management systems (e.g., operating room and emergency room systems), which might be explained by the differences in hospitals? characteristics; surveyed hospitals in Qu?bec were larger and had more intensive care units and operating rooms than hospitals in Ontario. In        addition, the organization of the health care delivery system in Qu?bec, which is based on the Health and Social Service Centers that provide a range of specialized and general services, necessitates having certain administrative and patient management systems in place in order to function effectively. On the other hand, the province of Ontario is leading in terms of the implementation of MPI, PACS, and telemedicine.

This is not surprising in light of the recent efforts toward integrating services in various geographic areas in Ontario, and the increasing support of the government for telemedicine initiatives through the creation of the Ontario Telemedicine Network in 2006.

Technological IT sophistication scores in both  provinces revealed a significant gap in relation to the implementation of technologies that have the potential of reducing errors, improving efficiency, and addressing security issues (e.g., bar coding for patient identification and materials management, bedside terminals, single sign-on, RFID, biometry).

And surprisingly, most of the surveyed hospitals did not report plans for implementing several of these technologies (e.g., RFID, biometry, and bedside terminals), which underscores the greater emphasis of hospitals on implementing computerized processes than technologies.

The IT integration level was relatively low in  our sample, with the exception of the internal integration of administrative systems (ERP).

Hospitals in Ontario had significantly higher level of implementation of EMR, and more external systems integration with other organizations. This might be explained by the creation of Local Health Integration Networks by the Ontario government in 2006, which support the integration of services in the province.

It is important to note that the exclusion of the  9 items, which showed no variability and had consistently low scores in our sample, does not undermine the importance and relevance of these computerized processes and external integration approaches. However, they seem too advanced at present and practically not available in hospitals.

Thus, incorporating them in the calculation of IT scores will not differentiate between hospitals on these items. Nevertheless, we expect that as these processes and approaches gain more attention in the future, they can further be incorporated in the IT sophistication scores.

Although the response rate in this study appears to be highly satisfactory in comparison with most mail surveys [23], we acknowledge that the absence of data on non-responding hospitals precluded a comparison between responding and non-responding hospitals to confirm the representativeness of our sample. Finally, given the fact that the instrument was validated among hospitals in two specific provinces in Canada, replicating the survey in other settings outside Canada and in other provinces can further support the instrument generalizability.

Finally, the development of a valid and reliable  tool for assessing the level of IT sophistication in hospitals, which can produce IT scores that reflect IT capacities in these settings, presents an important contribution to managers and researchers. This instrument can be a useful tool for hospitals to exercise benchmarking and assess their positions in the market in relation to IT capacities. In addition, it can also be used to further examine the relationship between IT and organizational / contextual variables, as well as the process and outcomes of care.

6. Conclusion   The development of IT scores is a critical step forward towards addressing important research questions involving the determinants of IT sophistication in hospitals and the relationship between IT capacities and outcomes measures. By developing and validating an IT capacities assessment tool in hospitals, we unified prior literature in this area and proposed an IT scoring approach along eight dimensions representing computerized processes and technologies in administrative and clinical areas, as well as internal and external systems integration.

The survey of hospitals in Qu?bec and Ontario revealed a moderate level of IT sophistication.

Nevertheless, the IT capacities varied between the two provinces, although limited implementation of emerging technologies and clinical systems, and minimal internal integration of clinical systems, was observed in both provinces.  This might raise concerns in light of the increasing focus on patient safety, especially that many of these systems and technologies have potential of reducing errors.

Future efforts are necessary to optimize on the available solutions on the market, and improve the level of systems integration, to ensure better continuity and integration of care.

7. References  [1] Institute of Medicine. To Err is Human:  Building a Safer Health System.

Washington, DC: National Academy Press, 2000.

[2] Institute of Medicine. Crossing the Quality  Chasm: A New Health System for the 21st Century.  Washington, DC: National Academy Press, 2001.

[3] T.G. Thompson, and D.J. Brailer, The  Decade of Health Information Technology: Delivering Consumer-Centric and Information-Rich Health Care, Framework for Strategic Action. Washington, DC: US Department of Health and Human Services, 2004.

[4] Canada Health Infoway. Coming Together:  The First Electronic Health Record Systems are beginning to Transform Canadian Health Care. 2003-2004 Annual Report. Montreal: Canada Health Infoway, 2004 Available from: http://celarc.ca/cppcdoc1- 12/201404.pdf.

[5] M.J. Ball, ?Hospital Information Systems:  Perspectives on Problems and Prospects, 1979 and 2002?, International Journal of Medical Informatics, 2003; 69, pp.83-9.

[6]  D.W. Bates, and A.A. Gawande, ?Improving  Safety with Information Technology?, New England Journal of Medicine, 2003; 348, pp.2526-34.

[7]  B. Chaudhry, J. Wang, S. Wu, M. Maglione,  W. Wojjica, E. Roth, et al. ?Systematic Review: Impact of Health Information Technology on Quality, Efficiency, and Costs of Medical Care?, Annals of Internal Medicine, 2006; 144, pp.E12-E22.

[8]  American Hospital Association, Continued  Progress: Hospital Use of Information Technology. American Hospital Association (AHA); Chicago, 2007. Available from: http://www.aha.org/aha/content/2007/pdf/07 0227-continuedprogress.pdf.

[9] Healthcare Information and Management  Systems Society. 18th Annual HIMSS Leadership Survey: CIO Results Final  Report. Chicago: Healthcare Information and Management Systems Society; 2007 Available from: http://www.himss.org/ 2007survey/DOCS/18thAnnualLeadershipS urvey.pdf.

[10] Ontario Hospital Association. Ontario  Hospital e-Health Adoption Survey: 2007 Survey Top Line Report. Toronto: Ontario Hospital Association; 2007. Available from http://www.oha.com.

[11] D.E. Burke, and N. Menachemi, ?Opening  the Black Box: Measuring Hospital Information Technology Capability?, Health Care Management Review, 2004; 29(3), pp.207-17.

[12] D. Burke, N. Menachemi, and R.G. Brooks,  ?Diffusion of Information Technology Supporting the Institute of Medicine?s Quality Chasm Care Aims?, Journal of Healthcare Quality, 2005; 27(1), pp.24-32, 39.

[13] N. Menachemi, J. Burkhardt, R. Shewchuk,  D. Burke, and R.G. Brooks, ?Hospital Information Technology and Positive Financial Performance: A Different Approach to Finding an ROI?, Journal of Healthcare Management, 2006; 51(1), pp.40-58.

[14] E.G. Poon, A.K. Jha, M. Christino, et al.,  ?Assessing the Level of Healthcare Information Technology Adoption in the United States: A Snapshot. BMC Medical Informatics and Decision Making. 2006; 6, pp.1-9.

[15] G. Par?, and C. Sicotte, ?Information Technology Sophistication in Health Care: An Instrument Validation Study among Canadian Hospitals?, International Journal of Medical Informatics, 2001; 63(3), pp.205-23.

[16] Y. Haruki, Y. Ogushi, Y. Okada, M.

Kimura, I. Kumamoto, and Y. Sekita, ?Status and Perspective of Hospital Information Systems in Japan?, Methods of Information in Medicine, 1999; 38(3), pp.200-6.

[17] D. Goldberger, and R. Kremsdorf, ?Clinical  Information Systems: Developing a Systematic Planning Process?, Journal of        Ambulatory Care Management, 2001; 24(1), pp.67-83.

[18] S.H. Brown, M.J. Lincoln, P.J. Groen, and  R.M. Kolodner, ?VistA ? U.S. Department of Veterans Affairs National-Scale HIS?, International Journal of Medical Informatics, 2003; 69, pp.135-56.

[19] M. Jaana, M.M. Ward, G. Par?, and D.

Wakefield, ?Clinical Information Technology in Hospitals: A Comparison between the State of Iowa and two Provinces in Canada,? International Journal of Medical Informatics, 2005; 74(9), pp.719-31.

[20] M.M. Ward, M. Jaana, J.A. Bahensky, S.

Vartak, and D.S. Wakefield, ?Clinical Information System Availability and Use in Urban and Rural Hospitals,? Journal of Medical Systems, 2006; 30(6), pp.429-38.

[21] M. Jaana, M.M. Ward, G. Par?, and C.

Sicotte, ?Antecedents of Clinical Information Technology Sophistication in Hospitals,? Health Care Management Review, 2006; 31(4), pp.289-99.

[22] G.A. Jr. Churchill, ?A Paradigm for  Developing Better Measures of Marketing Constructs?, Journal of Marketing Research, 1979; 16, pp.64-73.

[23] A. Pinsonneault, and K.L. Kreamer, ?Survey  Research Methodology in Management Information Systems: An Assessment,? Journal of Management Information Systems, 1993; 10(2), pp.75-105.

Functional IT Capacities                     Technological IT Capacities         Integration        Clinical Support Applications  Laboratory IS  Radiology IS   Pharmacy IS  PACS  Patient Management Applications   Operating room management system Emergency room system  Critical care systems Patient chart tracking system  Master patient index (MPI)  ADT system  Administrative Applications  Accounting / Financial IS    Staff scheduling system           Disease costing E-commerce / B2B applications Business intelligence system   Human resources Material management systems Financial / Clinical dashboards  Clinical Applications  Nursing documentation system Electronic discharge summary E-learning Clinical documentation system Order entry / Results reporting  Telemedicine Continuing quality improvement  Computerized physician order entry  Electronic dictation Clinical decision support systems  On-line access to knowledge base  Contemporary Clinical and Administrative Technologies   Medical record scanning  Single sign-on technology   Bedside terminals Biometry    Bar coding ? medication management  Voice recognition Bar coding ? materials management  Bar coding ? patient identification  RFID Administrative data warehouse Clinical data warehouse Portable computing / wireless devices Robots (medication preparation / dispensing)  Internal  Enterprise resource planning  Electronic medical record  External   With acute care organizations  With long term care organizations With primary care organizations With medical clinics  Appendix A: Overview of the items included in the proposed IT capacities assessment tool.

