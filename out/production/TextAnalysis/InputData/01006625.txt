Comparison of Heuristic Rule Weight Specification Methods

Abstract - We examine the performance of heuristic methods for rule weight specification in fuzzy systems for pattern classification problems. Each heuristic method is defined by the confidence measure used in the field of data mining for evaluating association rules. Simulation results show that a proposed heuristic method outperforms existing ones.



I. INTRODUCTION  We have already demonstrated that rule weights have a significant effect on the classification performance of fuzzy rule-based systems [ 11. This means that the classification performance strongly depends on the specification of the rule weight of each fuzzy rule. The aim of this paper is to propose new methods for rule weight specification and compare them with exiting ones. We use fuzzy rules of the following form for an n-dimensional pattern classification problem.

Rule R , :  If x1  is A,1 and ... and x, is A,, then Class C, with CF, , (1)  where x = (XI ,..., x, ) is an n-dimensional pattern vector, A,i is an antecedent fuzzy set for the i-th attribute, C, is a consequent class, and CF, is a certainty grade (i.e., rule weight). Various types of fuzzy rules have been used for pattern classification problems. For example, Cordon et al.

[2] examined three types of fuzzy rules: One has a single consequent class with no rule weight, another is the same as (l), and the other has multiple consequent classes where a different certainty grade is assigned to each class.

In this paper, we first describe two exiting methods [2], [3] for rule weight specification using the terminology in data mining. We use fuzzy versions [4] of two measures of association rules in data mining: confidence and support [5].

Next we propose two heuristic methods for rule weight specification. Differences among the four heuristic methods are visually demonstrated through computer simulations on an artificial test problem. Then we examine the classification performance of fuzzy rule-based systems designed by each heuristic method through computer simulations on wine data with 13 continuous attributes. Simulation results show that one of the proposed methods clearly outperforms the exiting ones. Finally we discuss the interpretability of fuzzy rule- based systems. Simulation results show that a small number of simple fuzzy rules with rule weights have high interpretability and high classification ability.

11. HEURISTIC RULE WEIGHT SPECIFICATION  A.  Rule Evaluation Measures in Data Mining In the field of data mining [5], two measures (i.e.,  Confidence and support) are frequently used for evaluating association rules. The fuzzy rule in (1) can be viewed as an association rule A ,  a C, where A ,  = ( A q 1  , ..., A,, ) .

We first briefly explain fuzzy versions [4] of these two rule evaluation measures. Let us assume that m labeled patterns x p  = ( x p l  ,..., x p n )  , p = 1 , 2  ,..., m are given from M classes for an n-dimensional pattern classification problem.

We denote the set of these training patterns as D = { X I  , ..., x, } . The cardinality of D is denoted by I D I where 1 D I = m .

Let D ( A ,  ) and D ( C ,  ) be the sets of compatible training patterns with A ,  and C, , respectively. Then the confidence of A ,  a C, is written as follows [5].

The confidence can be viewed as measuring the validity of  A ,  C, is defined as follows [5]:  C, . On the other hand, the support of A ,  The support can be viewed as measuring the coverage of training patterns by A ,  3 C, . From (2) and (3), the following relation holds.

I D ( A ,  ) I ID1  s ( A q  s C q )  = 4 A q  *cq ) . (4)  When the antecedent A ,  is defined by non-fuzzy concepts, the calculations in the above definitions are simple.

We can easily calculate the confidence and the support by simply counting the number of training patterns that are compatible with A ,  and with both A ,  and C When A , is fuzzy, we have to take into account the compatibility grade of each training pattern with A, [4]. As in our former studies on fuzzy rule-based classification systems [l], [3], we define the compatibility grade of each training pattern x p with the antecedent A ,  by the product operation as  q :  P A q  ( x p  )=pAql  ( x p I  ) x " ' X p A q n  ( x p l  1, ( 5 )  0-7 803-728O-8/02/$10.00 02002 IEEE 908  mailto:yama}@ie.osakafu-u.ac.jp   where p A  . ( .  ) is the membership function of the antecedent &zy set Aqi . Thus the total compatibility grade with the antecedent A, is calculated as  We define the compatibility grade of each training pattern x p  with the fuzzy rule R, (i.e., with both the antecedent A, and the consequent C ,  ) as  ( x P  ), if P E  Class C ,  , (7)  Thus the total compatibility grade with both A, and C ,  is calculated as  m  p=l ?  The confidence in (2) and the support in (3) can be calculated using (6) and (8).

B. Heuristic Methods for Rule Weight Specification  We assume that a set of antecedent fuzzy sets (i.e., linguistic values) is given for each attribute. The antecedent A, is constructed by combining antecedent fuzzy sets for n attributes. The corresponding consequent C ,  is determined by finding the class with the maximum confidence (or support) for the antecedent A, :  c(A,  a C ,  )=max{c(A, =,Classh)I h=1,2 ,  ..., M}.

(9)  Note that the same consequent C, is obtained from the support s ( 9 ) instead of the confidence c ( . ) in (9) because ID(A, ) I / JDI  in (4) is independent of C , .  When the consequent C, cannot be uniquely determined in (9), we do not generate any fuzzy rule with the antecedent A, .

The confidence c(A, 3 C, ) can be used as the rule weight CF, of the fuzzy rule A, zC, as in Cordon et a1.[2]. That is, one definition of the rule weight is as follows:  where the superscript ?I? shows that CFd is the fist definition of CFq . In our former studies on fuzzy rule-based pattern classification [l], [3], we used a different definition of rule weights. Our former definition can be rewritten as  where cAve is the average confidence over fuzzy rules with the same antecedent A , but different consequent classes:  0-7803-7280-8/02/% 10.00 02002 IEEE 909  (12) We propose a more intuitive definition of the rule weight  CF,, which is based on the difference between the largest confidence and the second largest confidence. That is,  CFF =c(A,  = C q ) - c s e c ,  (13)  where cSec is the second largest confidence for the antecedent A, :  csec =max{c(A, -Class h )  I h=1,2 ,  ..., M ;  h # C ,  } .

We also examine the following definition: (14)  C F F  =c(A,  3 C q  )-csUm, (15)  where cs,, is the sum of the confidence over fuzzy rules with the same antecedent A , but different consequent classes from C, :  M  h=l cSum = C c ( A ,  =Classh) -c(A,  = C , ) .  (16)  While CF, is always positive in the first three definitions, CF, can be negative even when the consequent C ,  is uniquely determined in (9). We do not use fuzzy rules with negative certainty grades in our fizzy rule-based system.

Thus some fuzzy rules may be removed from fuzzy rule- based systems when we use the last definition of rule weights.

Note that the third and fourth definitions in (1 3) and (1 5 ) are the same as the second definition in (1 1) when our pattern classification problem involves only two classes (i.e., when M = 2 ) .  In t h s  case, cAve =cSec =cSum in (12), (14) and (1 6). The difference among these definitions becomes significant when the number of classes is large. As we will show later, the second definition becomes similar to the first definition when the number of classes is very large.

Let S be a set of fuzzy rules of the form in (1). The rule set S can be viewed as a fuzzy rule-based classification system.

We use a single winner rule method [6] for classifying new patterns by the rule set S. See [2], [6] for other fuzzy reasoning methods for pattern classification. The single winner rule Rw is determined for a new pattern x p  =  N  ( X p l  7.?., X p n  ) as  P A ,  ( x p  =Max{PA, ( x p  IRq ES) . (17)  That is, the winner rule has the maximum product of the compatibility grade and the certainty grade. If multiple fuzzy rules have the same maximum product but different consequent classes for the new pattern x , the classification of x p  is rejected. The classification is also rejected if no    fuzzy rule is compatible with the new pattern x p  .

C. Characteristic Feature of Each Definition  For visually illustrating the characteristic feature of each definition of rule weights, let us consider a two-class pattern classification problem on the unit interval [0, 11. We assume that an infinite number of training patterns are uniformly distributed in the pattern space [0, 11. We also assume that each training pattern x p  belongs to Class 1 or Class 2 depending on its location as shown in Fig. 1: If x p  I I9 then x p  belongs to Class 1 otherwise x p  belongs to Class 2. In Fig. 1, threshold value I9 is specified as 8 = 0.47. For generating fuzzy rules, we use three antecedent fuzzy sets in Fig. 2 (i.e., small, medium, and large).

Class 1 Class 2  0.0 e = 0.47 1.0 Pattern space  Fig. 1. Distribution of training patterns in an artificial test problem.

0.0 0.0 0.5 1.0 -  Pattern space  Fig. 2. Three antecedent hzzy sets.

Using the uniform distribution of training patterns in Fig. 1 and the three antecedent fuzzy sets in Fig. 2, we can generate the following fuzzy rules:  R I  : Ifx is small then Class 1 with CFI ,  : If x is large then Class 2 with CF3 .

(18)  (20) R 2 : If x is medium then Class 2 with CF2 , R  (19)  Rule weights of these fuzzy rules are calculated from the uniform distribution of training patterns as  CF,' =0.996, CF; =0.558, CF: = 1.000, (21)  CF," =0.993, CF? = 0.116, CF; = 1.000, (22)  CF;" = 0.993, C F F  = 0.1 16, CF;" = 1 .OOO, (23)  CF,'v =0.993, CF2N =0.116, CF," =1.000. (24)  Since our test problem is a two-class problem (i.e., A4 = 2 ), the second definition is exactly the same as the third and fourth definitions. We can observe a large difference in the rule weight CF2 of the second fuzzy rule R2 between the first definition and the other definitions. The confidence of this fuzzy rule is not so different from that of the fuzzy rule "medium 3 Class 1" with the same antecedent and the different consequent:  c (  medium 3 Class 1) = 0.442, (25)  c(  medium Class 2 )  = 0.558. (26)  Thus the rule weight CF2 of the fuzzy rule " R2 : medium Class 2" is very small in the last three definitions. On the  other hand, the rule weight CF2 is not small in the first definition because the confidence is directly used as the rule weight.

Using the three fuzzy rules in (18)-(20), we estimate the class boundary between two classes. The estimated class boundary 6 is calculated as follows: 6 = 0.320 by the first definition and 6 =  0.448 by the other definitions. The estimated class boundary I9 has a large error in the case of the first definition while it is close to the actual threshold 0.47 in the case of the other definitions. The large error in the case of the first definition is due to the large rule weight CF; of the second rule R2. Since the rule weight CF: is not negligible, the second hzzy  rule R2 has a significant effect on the classification of new patterns around the center of the pattern space [0, 13. That is, the second fuzzy rule R 2 has a significant decision region in which R 2  is selected as the winner rule. As a result, the estimated class boundary 6 is pushed to 6 = 0.320. On the other hand, the rule weight CF2 is very small when we use the other definitions. Thus the second rule R 2  has a small cecision region. As a result, the estimated class boundary I9 is close to the boundary between the two dominant rules R I  and R3 (i.e., 0.5).

In the same manner, we calculated the estimated class boundary I9 between two classes for our test problem with various specifications of the actual threshold value B .  We examined 51 versions of our test problem with different values of 0 : 0 = 0.25, 0.26, 0.27, ..., 0.75 . Simulation results are summarized in Fig. 3. This figure shows the relation between the actual threshold I9 and the estimated class boundary e .  The line in this figure shows the case of 6 = I 9  . From this figure, we can see that the difference between I9 and 6 is very large in the case of the first definition. On the other hand, the estimated class boundary 6 is almost the same as the actual threshold I9 when we use the other definitions. This figure suggests that the direct use of the confidence c ( A ,  3 C ,  ) as the rule weight CF, (i.e., the first definition CF6 ) may lead to large classification errors.

0-7803-7280-8/02/$10.00 02002 IEEE 910    0 lstdefinition 0 2nddefinition  Actual threshould B  Fig. 3. Simulation results by the four definitions of rule weights for the two-class artificial test problem in Fig. 1. Results by the least  three definitions are the same.

T J  0.25 0.5 0.75 Actual threshould 8  Fig. 4. Simulation results by the second definition of rule weights for M-class test problems.

Let us extend our test problem in Fig. 1 to an M-class problem ( M > 2 ). For simplicity of discussion, we assume that the unit interval [0, 11 in Fig. 1 is a part of a larger entire pattern space. We also assume that training patterns from the other classes (i.e., Class 3, ..., Class M) exist in the other region of the pattern space. From those assumptions, we can discuss the specification of rule weights locally in the unit interval [0, 11. In this situation, the increase in the number of classes has no effect on the rule weight specification except for the second definition. Only the second definition depends on the number of classes A4 as shown in (12). Thus the second definition is not the same as the thrd and fourth definitions when pattern classification problems involve more than two classes. For example, the rule weights of the three fuzzy rules in (18)-(20) is calculated from the second definition for the case of A4 = 5 and 0 = 0.47 as  CF: = 0.996, CF! = 0.448, C F f  = 1.000. (27)  The class boundary between two classes is calculated as 6 = 0.345 by the second definition while the actual threshold is B = 0.47. Note that the class boundary was calculated as 6 = 0.448 when A4 = 2. This result suggests that the increase in the number of classes has a bad effect on the classification perfonnance of fuzzy rule-based systems constructed by the second definition of rule weights. In the same manner as Fig.

3, we calculated the estimated class boundary 6 using the second definition of rule weights for three specifications of A4 (i.e., M = 2,  5, 10 ). Simulation results are summarized in Fig. 4. From this figure, we can see that the difference between the actual threshold 8 and the estimated class boundary 6 increases as the value of M increases. This is because the rule weight CF; of the second fuzzy rule R 2 becomes unnecessary large when our test problem involves more than two classes as shown in (27).

111. PERFORMANCE EVALUATION  We compare the four definitions of rule weights with one another through computer simulations on wine data. This data set is available from the UC Irvine machine learning database. The wine data set is a 13-dimensional pattern classification problem with 178 samples from three classes.

We chose this data set because it involves many continuous attributes. In our computer simulations, we first normalized each attribute value into a real number in the unit interval [0, 11. Thus the pattern space of the wine data was normalized into the 13-dimensional unit hypercube [0, l]I3. Then we calculated average classification rates on test patterns as well as training patterns. All the given samples were used as training patterns when we examined the classification performance of fuzzy rule-based systems on training data. On the other hand, we used the leaving-one-out (LVl) technique [7] when we examined the classification performance on test data. In the LVl technique, 178 samples were divided in a single test pattern and 177 training patterns. A fuzzy rule- based system designed from training patterns was evaluated by a single test pattem. The design-and-test procedure was iterated 178 times so that all the given samples were used as test patterns once.

Since we did not know an appropriate fuzzy partition for each of the 13 attributes in the wine data, we used four fuzzy partitions in Fig. 5 for each attribute. That is, we used 14 fuzzy sets in Fig. 5 and ?don ?t care? as antecedent fuzzy sets.

Thus the total number of combinations of antecedent fuzzy sets is 15 l 3  . It is impractical to examine all combinations of antecedent fuzzy sets. Thus we only generated short fuzzy rules of the length three or less. Note that the rule length is defined by the number of antecedent conditions. Fuzzy rules  0-7803-7280-8/02/$10.00 02002 IEEE 911    of the length three or less for the 13-dimensional wine data include at least ten don't cure conditions. When all the 178 samples were used as training patterns, 71 1727 fuzzy rules # of rules No weight 1st Def. 2nd Def. 3rd Def. 4th Def.

were generated. 3 89.89 89.89 89.89 89.33 89.33  6 80.34 83.15 85.96 84.83 85.39 9 88.76 91.57 92.13 93.26 93.26 12 93.26 93.26 92.70 93.26 93.26 15 88.76 91.57 91.57 94.38* 93.26 18 88.20 89.89 89.89 92.13 91.01 21 89.33 89.33 89.33 91.57 91.01  0.0 1 .o 0.0 1 .o 24 88.20 89.33 89.33 91.57 91.01 27 88.20 89.89 90.45 92.70 91.57 30 90.45 90.45 91.01 93.26 92.13  Table 2. Classification rates on test patterns. The best result in each row is indicated by boldface.

0.0  * Best result in this table.

0.0 '"Dc>c>a* :rlKxxN* In these tables, no weight means that rule weights were not 0.0 1 .o 0.0 1.0 taken into account in the single winner classification method.

'"M* ::w+ T h s  situation was simulated by assigning the same rule weight to all fuzzy rules (i.e., CFq = 1 for Vq ). From Table  Fig. 5 Four fuzzy partitions used in computer simulations.

The generated fuzzy rules were divided into three groups according to their consequent classes. Fuzzy rules in each group were sorted in a descending order of a rule selection criterion. We used the product of the confidence c ( . ) and the support s ( . ) as the rule selection criterion in this paper (see [4] for other rule selection criteria: the confidence c ( . ) and the support s ( . ) ). When multiple fuzzy rules had the same value of the rule selection criterion, they were randomly sorted (i.e., random tiebreak). We constructed a fuzzy rule- based system by choosing the first N fuzzy rules from each group. Using various values of N (i.e., N = 1, 2,..., lo) ,  we examined the classification performance of fuzzy rule-based systems with different sizes. Simulation results on training data and test data are summarized in Table 1 and Table 2, respectively. In these tables, the best result in each row is indicated by boldface. On the other hand, the best result in each table is indicated by "*".

Table 1. Classification rates on training patterns. The best result in each row is indicated by boldface.

# of rules No weight 1st Def. 2nd Def. 3rd Def. 4th Def.

3 89.89 89.89 89.89 89.33 89.89 6 91.01 91.57 91.01 92.13 91.01 9 93.26 93.82 92.13 93.82 93.82 12 93.26 93.82 92.70 94.94* 94.94* 15 88.76 92.70 92.13 94.94* 94.94* 18 91.01 91.57 92.70 94.94* 94.38 21 91.01 91.57 92.70 94.38 93.82 24 92.13 92.13 92.70 94.38 93.82 27 90.45 92.13 92.70 94.38 93.82 30 90.45 92.13 92.70 94.94* 93.82  * Best result in this table  1 and Table 2, we can see that the use of rule weights improved the classification performance of fuzzy rule-based classification systems. Among the four definitions of rule weights, the best results were obtained from the third definition (i.e., difference between the largest and the second largest confidence).

Iv. INTERPRETABILITY OF FUZZY SYSTEMS  Let us demonstrate that very simple fuzzy rules with rule weights have high classification ability. For selecting a small number of fuzzy rules with high classification ability, we used a rule selection method based on a three-objective genetic algorithm [SI. This algorithm can find a number of non-dominated rule sets with respect to three objectives: to maximize the classification ability, to minimize the number of fuzzy rules, and to minimize the total rule length. In our computer simulations, we first chose 900 fuzzy rules from the generated 711727 rules for the wine data in the previous section using the rule selection criterion as in the previous section. Then the three-objective genetic algorithm was used for find non-dominated rule sets. In this computer simulation, all the 178 samples in the wine data were used as training data. The rule weight of each fuzzy rule was specified by the third definition. Examples of obtained non-dominated rule sets are shown in Fig. 6 and Fig. 7. Each fuzzy rule in Fig. 6 has only a single antecedent condition. Since antecedent fuzzy sets are not adjusted, each fuzzy rule can be easily understood by human users. While fuzzy rules in Fig. 7 have two or three antecedent conditions, they are still easy to understand.

For the wine data, Setnes & Roubos [9] reported a 98.3% classification rate on training data by three fuzzy rules. While  0-7803-7280-8/02/$10.00 02002 IEEE 912    we used simple homogeneous fuzzy partitions with no membership tuning, our fuzzy rule-based system with a 100% classification rate in Fig. 7 outperformed the reported result in [9]. Castillo et al. [lo] reported a 96.76% average classification rate on test data (30% of the wine data) where the average number of fuzzy rules was 5.2 over five independent trials. Since their SLAVE algorithm used a union (i.e., disjunction) of multiple linguistic values as a single antecedent fuzzy set, fuzzy rules in [IO] are more complicated than our fuzzy rules in Fig. 6 and Fig. 7. That is, more fuzzy rules with higher complexity were obtained in [lo] than our fuzzy rule-based systems in Fig. 6 and Fig. 7.

From computer simulations using the LV1 procedure, we obtained a 96.1% average classification rate on test data by three fuzzy rules of the average length 2.33 and a 97.2% average classification rate on test data by three fuzzy rules of the average length 2.67.

I I XI x7 4 7  lconseauent I  Fig. 6 Three fuzzy rules with a 94.9% classification rate.

Fig. 7 Three fuzzy rules with a 100% classification rate.



V. CONCLUSIONS  In this paper, we examined four heuristic definitions of rule weights in fuzzy rule-based classification systems. First we proposed two heuristic definitions using the confidence of fuzzy association rules. Next we described the characteristic feature of each definition. Through computer simulations on an artificial test problem, we illustrated the drawback of each of the two existing definitions. Then we compared the four definitions with one another through computer simulations on the wine data. We also examined the case with no rule weights by assigning the same rule weight to all fuzzy rules.

Simulation results showed that the use of rule weights improved the classification performance of fuzzy rule-based  systems. Among the four definitions, the best results were obtained from a proposed one where the rule weight of each fuzzy rule was defined by the difference between the largest and the second largest confidence. Finally we demonstrated that very simple fuzzy d e s  with rule weights have high classification ability as well as high interpretability. We used a genetic algorithm-based rule selection method for finding non-dominated rule sets with respect to three objectives: to maximize the classification accuracy, to minimize the number of fuzzy rules, and to minimize the total rule length.

Since the number of fuzzy rules and the total rule length were minimized, very simple rule sets were obtained by a three- objective genetic algorithm. While those rule sets were very simple, they had high classification ability. This is because an appropriate rule weight was specified for each fuzzy rule by the proposed definition.

Reference [I] H. Ishibuchi and T. Nakashima, ?Effect of rule weights in fuzzy  rule-based classification systems,? IEEE Trans. on Fuzzy Systems, vol. 9, no. 4, pp. 506-5 15, August 2001.

[2] 0. Cordon, M. J. del Jesus, and F. Herrera, ?A proposal on reasoning methods in fuzzy rule-based classification systems,? International Journal of Approximate Reasoning, vol. 20, pp.

21-45, January 1999.

[3] H. Ishibuchi, K. Nozaki, and H. Tanaka, ?Distributed representation of fuzzy rules and its application to pattem classification,? Fuzzy Sets and Systems, vol. 52, no. 1, pp. 2 1-32, November, 1992.

[4] H. Ishibuchi, T. Yamamoto, and T. Nakashima, ?Fuzzy data mining: Effect of fuzzy discretization,? Proc. of 1st IEEE November 2001.

[ 5 ]  R. Agrawal and R. Srikant, ?Fast algorithms for mining Very Large Data Bases, pp. 487-499, September 1994.

Expanded version is available as IBM Research Report RJ9839, June 1994.

[6] H. Ishibuchi, T. Nakashima, and T. Morisawa, ?Voting in fuzzy rule-based systems for pattem classification problems,? Fuzzy Sets andsystem, vol. 103, no. 2, pp. 223-238, April 1999.

[7] S. M. Weiss and C. A. Kulikowski, Computer Systems That Learn, Morgan Kaufmann Publishers, San Mateo, 1991.

[8] H. Ishibuchi, T. Nakashima, and T. Murata, ?Three-objective genetics-based machine learning for linguistic rule extraction,? Information Sciences, vol. 136, no. 1-4, pp. 109-133, August 2001.

[9] M. Setnes and H. Roubos, ?GA-based modeling and classification: Complexity and performance,? IEEE Trans. on Fuzzy Systems, vol. 8,  no. 5, pp. 509-522, 2000.

[IO] L. Castillo, A. Gonzalez, and P. Perez, ?Including a simplicity criterion in the selection of the best rule in a genetic hzzy learning algorithm,? Fuzzy Sets and Systems, vol. 120, vol. 2, pp.

309-32 1,200 1 .

