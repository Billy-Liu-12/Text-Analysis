Principal Component Analysis in Business Intelligence Applications

Abstract ? With the enormous amount of information available on the web, many innovative applications in the domain of business intelligence have emerged. Information regarding market trends, consumer profile, competitors, etc., enables a firm to chart its direction and formulate strategies.

However, in this big data era, getting the right information is not an easy task. In this work, we introduce business intelligence (BI) applications in general, and examine the use of principal component analysis (PCA) in these applications. A study case reveals how PCA can be used for identification of relevant keywords as prominent features, as well as reducing the search space for an individual's specific requests, in the context of a BI recommender.

Keywords - principal component analysis; business analytics; business intelligence; information retreival; consumer profiling; market trends; page rank; dimensionality reduction; recommender

I.  INTRODUCTION Business intelligence (BI) encompasses many facets of  business management, from data warehousing to decision support systems. BI is a very broad term with many interpretations. As Turban et al. suggested, the term ?means different things to different people? [15], and one can regard it as ?an umbrella term that combines architectures, tools, databases, analytical tools, applications, and methodologies?to enable interactive access to data, to enable manipulation of data, and to give business managers and analysts the ability to conduct appropriate analysis.?  For the past two decades, data warehousing and web data mining have been the most prominent research areas in BI.

Dating back to the late 1990s and early 2000s, many people have recognized the ease and importance of information available on the web. The web offers an enormous amount of information, as well as the opportunity of automating the information collection and analysis process. However, with these advantages, the web also comes with challenging issues related to information overload and dynamic changes.

This work examines the use of principal component analysis (PCA) in improving the performance, in terms of space and time, in search operations within the context of a business intelligence recommender. The commonly used method to further improve the results of PCA, the varimax rotation, is also investigated.



II. BACKGROUND AND RELATED WORK Emerging methods for dealing and properly reducing the  available information collected during the BI process started to become an essential stage in BI. Among these, PCA seems to be a suitable one, having a reduced computational complexity and providing reliable results for dimensionality reduction and information representation. Below we present research related to applications of PCA in BI.

In [9] neural networks are used for business forecasting.

As there are numerous factors affecting the business forecast, the number of input nodes is large. In order to reduce this number, factors that affect business forecasting are first standardized, and then reduced using the PCA method.

Li et al. [8] consider a classification task of enterprise email messages into sensitive business topics. An incremental PCA technique is introduced for email representation, which can incrementally learn a feature subspace and effectively reduce the feature dimensionality.

Linear SVM (support vector machine) is then adopted to learn the classification models. Experimental results show that SVM outperforms other classification methods, and the incremental PCA produces a substantial reduction in the processing time and a slight increase in the classification accuracy compared to SVM with all the features.

Furthermore, in [3] PCA is applied to determine distinctive dimensions of consumer trust in food suppliers in China. The PCA reveals that the various trust items could best be described by five dimensions: actual behavior, customer relationship, firm scale, providing information, and expertise. Having conducted stepwise regression, only four dimensions are kept in the regression equation, while expertise is omitted. Furthermore, by carefully manipulating the four dimensions in formulating marketing strategies, managers can build consumer trust in food suppliers and gain a competitive edge in the business context.

As well, by applying the symbolic principal component analysis (SPCA) on the empirical data of the CITIC style indices over a period of six years (2005-2010), authors of [10] study the characteristics of Chinese stock market from multiple perspectives. Two components were extracted from five variables (P/E ratio, NMC, turnover rate, return rate and volatility), being defined as the market performance factor and the size factor.

DOI 10.1109/3PGCIC.2013.68    DOI 10.1109/3PGCIC.2013.68    DOI 10.1109/3PGCIC.2013.68     Jiang proposes a model for evaluating e-commerce website core competence based on PCA [4]. The model includes financial and operational measures, and also customer satisfaction measures. An illustrative example demonstrates that the PCA model can not only effectively reflect the relative core competence of e-commerce firms but also identify their potential problems.

In a similar manner, [11] focuses on the competitiveness analysis for logistics enterprises in e-commerce. The PCA is employed in selecting the samples and evaluating indicators.

According to the competitiveness analysis method, the principal constituent factors are identified so as to increase the logistics enterprises' competitiveness.

In [1], self organizing map (SOM) and PCA are employed to determine the property of the stock bubbles in Shanghai stock market from January 2000 to April 2008.

In order to examine the relationship between ownership structure and firm performance of private companies, Yan [16] considers 283 private companies listed in two Exchanges in the period 2008 to 2010. Ownership structure is described in two aspects: ownership concentration and equity properties. First, a new comprehensive performance index is obtained by PCA method based on the financial indexes. Then the paper makes linear regression analysis of the new performance index and ownership structure.

Empirical findings bring a new light in improving companies? performance.

Risk evaluation of technology innovation is a complex problem, being affected directly by the evaluators' knowledge, cognitive abilities, personal preferences, and the hard to get-rid-of bias caused by human. A comprehensive, systematic risk evaluation of technology innovation indicator system is established in [14]. It makes use of PCA and several other methods, including fuzzy comprehensive evaluation, BP neural network and information fusion technology.

In [13], a diverse set of analytical tools, including time series models, PCA, decision tree optimization, generalized linear models, K-means clustering, and linear programming, is employed to improve efficiency in the online video advertisement space by connecting consumers with advertisements on which they are most likely to click.



III. METHODOLOGY AND APPROACH  A. A Business Recommender A common characteristic with today?s search engines is  that they are tuned towards the needs of the general population rather than the need of business individuals as they have different searching needs. For example, businesses are interested in keeping up on the latest news of their competitors such as product launches, sales performance, and market shifts.

The Web-based Intelligence Recommender for Enterprise (WIRE) is designed to assist individuals who seek business information pertaining to a particular industry [6].

WIRE uses existing Internet search engines as a starting point, and then recursively crawls the web via the links found on each suggested page. The pages visited are  analyzed and given a score according to certain criteria as dictated by the individual user. The score represents the suitability and validity of a page for business use. Selected pages are ranked and presented to the user for further actions.

In the prototype design and implementation of WIRE, there are numerous issues and problems associated with the search terms to be used and the filtering (re-ranking) of the returned webpages. The methodologies reported in this work may facilitate the design of these modules.

B. PCA and Varimax Rotation The PCA method was initially developed in early 1900s  (see [2] and [12]). Over the years, the conventional PCA has inspired a great deal of research interest in various fields that in turn has led to a number of new PCA-based methods and algorithms with improved performance.

The method is mostly used as a tool in exploratory data analysis and for making predictive models. It is an eigenvector-based approach that seeks to capture the variation in a collection of data. Often, its operation can be thought of as revealing the internal structure of the data in a way that best explains the variance in the data.

PCA uses the eigenvectors of the covariance matrix of the data set to extract relevant information. Therefore, eigenvectors may be regarded as a set of features which offers a characterization of the global variation among the analyzed data. Other advantages of using eigenvectors are efficient data representation using a small number of parameters and thus, reduced computational and dimensional complexity.

The results of a PCA are usually discussed in terms of component scores, sometimes called factor scores (the transformed variable values corresponding to a particular data point), and loadings (the weight by which each standardized original variable should be multiplied to get the component score) or principal components, sometimes plainly referred as eigenvectors.

Given a data set D consisting of M observations ?i, each one having N variables, the first step is to standardize the data. An average vector ? is computed as ? ==  M  i i M  /1 ?? ,  and subtracted from each vector ?i to construct vector ai as .?? ?= iia  The data matrix is then formed as  MaaA M /]...[ 1=  and the covariance matrix is constructed as ./1  TT  i M  i i AAaaMC == ? =  Then the  eigenvectors ui and eigenvalues ?i of matrix C are computed and used to represent the original data from D, as follows.

A p-dimensional space is generated by the span of the p most significant eigenvectors (i.e., principal components) that are associated with the p largest eigenvalues of C, and the matrix composed of these p eigenvectors is denoted by U. The value of p can be determined based on the distribution of eigenvalues ?i, or as a certain percentage of the available number of eigenvectors ui.  Matrix U is used to yield a p-dimensional pattern vector s, also referred as score, which actually is the new representation of data in the     principal component space, aUs T=  where ?? ?=a  and ? is a given observation.

As suggested by Kaiser [5], the varimax rotation is a scheme for orthogonal rotation used in PCA and factor analysis that maximizes the sum of the variances of the squared loadings. After applying varimax to principal components yielded by PCA, that is to matrix U, any given variable is expected to have a high loading on a single principal component but near-zero loadings on the remaining components, and each one of the new components would be constituted by only a few variables with very high loadings while the remaining variables have near-zero loadings on this component. In this case, the new loading matrix U  is said to have "simple structure," and varimax rotation brings the loading matrix closer to such simple structure as much as the data allow.



IV. EXPERMENTAL SETUP Since our targeted application area is business  intelligence, we decided to use BI-related keywords for our experimentation. Three sets of keywords are used:  Set A: ?Business intelligence?, ?Competitor analysis?, ?Consumer behavior?, ?Market trend?, and ?Product introduction?.

Set B: ?Business analytics?, ?Competitive intelligence?, ?Customer profile?, ?Market forecast?, ?Product launching?.

Set C: Combination of Sets A and B.

The above corresponds to the scenario that two people are searching for BI-related subjects and they use similar search words/phrases as illustrated in Sets A and B. Although the search terms are similar, there is minimal overlap in the search results obtained using Google search engine.

Therefore, the combined set is being used to increase the coverage of the search.

For each set of keywords, the top 50 ranked webpages returned are archived for later analysis. Note that PDF and DOC files are not used.



V. RESULTS AND ANALYSIS The results obtained are processed based on the  keywords used in the search, or term frequency in the resulting webpages.

A. Term Frequency Statistics Tables 1, 2, and 3 show the term frequency among the  webpages using keyword Set A, Set B, and Set C, respectively. For Set A and Set B, 8 pages have the sum of all 15 keywords over 200 occurrences. For Set C, there are 8 pages having the sum of all 15 keywords over 300 occurrences, as expected, due to the use of all 10 phrases or 15 keywords. In Tables 1 and 2, the shaded entries are the terms corresponding to the search using that Set of keywords; while Table 3 shows the common terms in both Set A and Set B in shades.

Table 1 shows that most keywords from Set A used in search have high occurrences in the resulting webpages collectively, except ?behavior? and ?trend. The most interesting term is ?competitive? which is not part of Set A,  but in Set B, and has relatively high frequency. Therefore, one could conclude that the intended search should also include the keyword ?competitive?. From the perspective of the selected webpages, all have relatively high frequency for the terms from Set A, together with keyword ?competitive?.

Table 2 shows that most keywords from Set B have high frequency of occurrence except ?profile?, ?forecast?, and ?launching?. This may due to the fact that these terms are not commonly found in webpages that have large number of the other Set B terms. Similar to Table 1, all selected webpages have relatively high frequency. Also, the term ?analysis? seems to occur frequently with the keywords from Set B and therefore one should consider using ?analysis? as one of the search terms.

As expected, keywords common to keyword Set A and Set B have high occurrence count (as marked by keyword- A/B and a shaded entry in Table 3). The lone exception is the term ?analysis? which has a high count-sum. One may conclude that for this particular search, the common terms in A and B as well as ?analysis? should be used, and the resulting webpages would have the desired high term frequency. These webpages are most probable to be useful to the user.

If we consider webpages with high term frequency to be desirable, the top-ranked webpages from using Set A and Set B are quite different. Only webpages A-42 and B-22 are the same. For Set C, C-13 is the same as A-47, and C-42 is the same as B-45. This minimal overlap among the three Sets means that the similarity among the search results, in term frequency, is minimal.

Concluding this section, the term frequency statistics may be used along with a threshold on the number of keyword occurrences for ranking the webpages accordingly and determining the most relevant keywords. However, to validate the above approach extensive experiments and user surveys are required. In the next section, we explore another method to perform more focused searches, which in combination with term frequency statistics can form a stand- alone analysis technique for BI recommender.

B. Applying Principal Component Analysis and Varimax on Keywords As shown in the last section, it seems reasonable to use  term frequency and a variety of related keywords to determine top-ranked webpages. In this section, we investigate other approaches: principal component analysis and varimax.

For each set of search keywords, A, B, and C, three types of operations are performed: applying PCA to the set of keywords (which corresponds to data matrix A containing the number of keywords occurrences; columns of matrix A correspond to webpages, and rows to keywords); applying varimax on the first three principal components; and applying varimax on all principal components. The results of these operations are shown on the right-hand side of Tables 4, 5, and 6, respectively.

In each table, the keyword, its numerical label, the sum of its occurrence in each of the 50 documents (which also determines its rank), are shown on the left side. Entries in the     PCA and varimax tables are highlighted, if its (absolute) value is above 0.4. This number is determined after extensive examination of all results and using it as the threshold gives consistent conclusions.

In Table 4, keywords or features with |0.4| or above in each of the three operations correspond to the top 5 most frequently occurred keywords; while in Tables 5 and 6, the |0.4| threshold give the top 7 and top 6 keywords, respectively.

As shown above, PCA and varimax can be used to optimally choose/reduce the number of keywords for improved search results. In this study case, out of 15 initial distinct keywords only half proved to be necessary for getting the relevant webpages, while the remaining 7 keywords (?competitor?, ?profile?, ?behavior?, ?trend?, ?forecast?, ?introduction?, and ?launching?) are not essential.

Furthermore, by considering only the results for varimax applied to all principal components, one may conclude that ?business?, ?intelligence? and ?product? are the most relevant keywords for this search.

C. Applying Principal Component Analysis and Varimax on Webpages We further examine the feasibility of improving search  results by applying PCA and varimax on webpages. Once more, all 3 operations: PCA, varimax on the first 3 principal components, and varimax on all principal components, are applied, this time, to the 50 webpages obtained by keyword Set A, B and C (which correspond to the transposed data matrix A). Entries above |0.4| are considered. For Set A, these correspond to webpages # 8, 28, 29, 42, and 47. The expectation is that these 5 should constitute the top-5 ranked pages and should be recommended to the user in a search.

These results agree with the ones obtained from Table 1 by ranking webpages with the most frequently used keywords from Set A. In addition, the authors reviewed these pages and indeed they are pages that contain and explain many of the keywords used as well as introduce related terms. One would definitely rank these pages highly in a manual process.

Furthermore, using varimax, the supposedly top-ranked pages concur with the results from using PCA alone. Similar results are obtained for keyword Sets B and C. Our preliminary conclusion is that varimax?s use in screening out the non-relevant webpages provides no additional information that should be recommended to user.

Nevertheless, PCA alone appears to supply sufficient information to be considered in the analysis process for a BI recommender.



VI. DISCUSSIONS AND FUTURE WORK In this work, we examined the use of PCA and varimax  on different sets of keywords used in a search related to business intelligence. Results related to the search keywords and returned webpages are examined.

The experimental results suggest that terms with high frequency can be used effectively as search keywords, and webpages that contain a large number of keywords can be ranked highly as used by many existing ranking algorithms.

However, the advantage presented here is the use of principal component analysis which, in combination with varimax rotation, can potentially minimize the search space by reducing the number of search keywords and number of candidate webpages.

More experiments and surveys need to be performed to validate the various ?claims? in this work. It is necessary to employ human interpretation as well as some automated deterministic means [7].

