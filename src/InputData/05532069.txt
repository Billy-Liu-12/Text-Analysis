A Survey on Utilization of Data Mining for

AbstractIn this paper we present data mining and its utilization  for childhood obesity prediction. Data mining was widely used in  many childhood obesity prediction systems. Predicting obesity at  an early age is both useful and important because the number of  obese patients is increasing while its main cause cannot yet be  defined. The ability to predict childhood obesity will help early  prevention. The purpose of this survey is to provide the needed  understanding of the childhood obesity problem, introduce the  use of data mining on childhood obesity prediction, describe  current efforts in the area, and provide the strength and  weaknesses of each technique presented.

Keywords-data mining; childhood obesity prediction;

I. INTRODUCTION  Childhood obesity is a common issue nowadays. With  advances in technology, people are becoming less concerned  about living a healthy life. Not only adults, but the number of  children that suffer from obesity is increasing every year. To  determine whether a child is obese, Body Mass Index (BMI)  was used. A child with BMI at or over the 97th percentile is  considered obese [1].  If the children start to become obese at a  very young age, their condition may become worse by the time  they are adults. To help prevent childhood obesity, some effort  has been made to predict obesity at early age. Some of the  previous work on childhood obesity prediction used an  artificial intelligence technique called data mining. This paper  will introduce data mining utilization for childhood obesity  prediction based on previous studies, provide comparisons in  different data mining methods, and look for future direction in  the area. In section 2, we define the concept of data mining and  its technique which relate to childhood obesity prediction. In  section 3, we describe how data mining was applied in    childhood obesity prediction systems.



II. DATA MINING  Data mining is the process of analyzing and summarizing  data from different perspectives and converting it into useful  information [2].  Data mining is a growing area of research that  intersects with many disciplines such as AI, databases,  statistics, visualization, and high-performance and parallel  computing. The goal of data mining is to turn data into  knowledge. Data are facts, numbers, or text which can be  processed by a computer [2].  In a large database, data mining  is employed to detect patterns to extract hidden pieces of  information [21].

Data mining tasks can be classified as summarization,  classification, clustering, association and trend analysis [2].

Summarization is the generalization or abstraction of a set of  data resulting in a smaller set that gives a general overview of  the data. Classification derives the class of an object based on  its attributes. It will help for better understanding of the object  class in databases. Clustering refers to identifying groups or  clusters of objects with unknown classes. By looking at the  objects common features, they can be summarized to form  class descriptions [2]. Association is the discovery of  togetherness or the connection of objects [14]. This connection  of objects is termed the association rule  for example if an  appearance of a set of objects in a database is strongly related  to the appearance of another set of objects, the two sets are said  to be associated. Trend analysis is finding the patterns and  common attributes in data that change over time [2]. Many data  mining techniques have been applied to childhood obesity  prediction, including decision trees, association rules, Artificial  Neural Network (ANN), Bayesian networks, Nave Bayes and  Support Vector Machines (SVMs) [9] [10] [11].

Among these methods, we chose to look at three: Artificial  Neural Networks, Nave Bayes classifiers, and decision trees.

In our study we saw that these methods have more advantages  in accuracy and efficiency and have recently become popular  in many applications, especially in the medical field.

A.  Artificial Neural Networks  The human brain has many advantages over modern  parallel computers such as massive parallelism, learning  ability, generalization ability, adaptiveness, fault tolerance, low  energy consumption, distributed representation and distributed    computation [3]. ANN is based on biological neural networks  in the human brain.  A neuron (Fig.1) is a cell that processes                  Figure 1.  A sketch of a neuron inside human brain [3].

information. It has several parts: the cell body, two types of  branches (axon and dendrites), and the nucleus inside the cell  body. The axon works as a transmitter to transmit signals or  impulses generated from the cell to other neurons while the  dendrites receive incoming signals or impulses from other  neuron. Each neuron is connected to many other neurons and  neurons communicate through short trains of pulses. Important  information is transmitted indirectly through interconnections.

ANN can be described as a connectionist model based on the  human brain [3].

ANN can be drawn as weighted directed graphs where the  artificial neurons are nodes and directed edges show the  connection between output neurons and input neurons, as  shown in Fig. 2 [3]. ANN has been successfully used in many  medical applications, such as predicting outcomes [15],  diagnosis [16], and decision making systems [17] [18].

B. Nave Bayes Classifiers  A Bayesian network consists of a structural model and a set  of conditional probabilities [4]. The structural model is a  directed graph where nodes represent attributes and arcs  represent attribute dependency. For classification problems,  Bayesian networks are used to construct classifiers from a  given set of training examples with class labels. Assume that  A1, A2,,An are n attributes (refer to nodes in Bayesian  network).  An example E is represented by a vector <a1, a2,,  an,>, where a1, is the value of A1. Let C represent the class  variable (refer to class node in a Bayesian network). Then let c  represent the value that C takes and c(E) denote the class of E.

Figure 2.  A neural network model [3].

The classifier of a general Bayesian network is defined in (1):    (1)    By assuming that all attributes are independent, the result is a  classifier called Nave Bayes as defined in (2):      (2)    Fig. 3 shows graphically the structure of Naive Bayes.

Nave Bayes has been used in many medical applications such  as skin disease detection and biometric recognition [5] [6].

C. Decision Tree  Decision trees are powerful classification algorithms that  are popular in information systems [8]. Widely used decision  tree algorithms include Iterative Dichotomiser 3 (ID3),  assistant algorithm, C4.5, C5, and CART [7][8].  Decision tree  techniques perform separate observation in branches  recursively to construct a tree for prediction. Splitting  algorithms  i.e. information gain (used in ID3, C4.5, C5), Gini  index (used in CART), and Chi-squared test (used in CHAID)  are used to identify a variable and its corresponding threshold  and split the input observation into two or more subgroups.

Then the steps are repeated until a complete tree is built. The  reason for the splitting algorithm is to find the variable-  threshold pair(s) which maximizes the order of the samples [8].

Fig.4 shows graphically a decision tree structure.

Figure 3.  An example of nave Bayes structure [4].

Figure 4.  A structure of a decision tree.

Decision trees have been used for many medical purposes such  as predicting the outcome of coronary heart diseases and in  medical diagnosis systems [8][19].



III. APPLICATION OF DATA MINING FOR CHILDHOOD  OBESITY PREDICTION  Obesity can be defined as an excessive accumulation of  body fat [11]. Prediction means an indication in advance based  on observation, experience, or scientific reason [20].  A  childhood obesity prediction system, therefore, is a system to  identify young children who are at risk of excessive body fat  (obesity) by predicting from their early growth records.  Using  data mining, childhood obesity predictions are possible  [9][10][11]. We present three data mining techniques that have  been used for childhood obesity prediction systems.

A. Artificial Neural Networks  For the ANN childhood obesity prediction system, massive  amounts of data were collected from health care service  organizations. In the first stage, data about pregnancy course,  morphological changes of the mother, and her psychological  attitude were collected and observed. In the second stage,  observations of newborns took place in maternity hospital.

In the third stage, children from 1 to 12 months of age were  monitored along with their nutrition and vaccinations.

Observation was repeated when they were 3 years old and  again when they were at the entrance of grammar school, with  periodic health examinations by specialists. The parents also  took part in questionnaires about their health and their  economic and social status [9].

The reason for such observation is to identify risk factors of  childhood obesity and childrens tendency towards obesity.

The first risk factor is the family itself: history of obesity in the  family, parental disease, the mother`s weight during pregnancy,  family nutrition style, education and level of physical activity.

The second factor is lifestyle: good and bad habits, handling in  early years of life, nutrition, physical activities, illness and the  personal character of the child. The third factor is the social    environment: family size, income and status. These risk factors  are used as the inputs in the ANN childhood obesity prediction  system [9].

The system was developed using a new generation of  radial basis artificial neural network (RBANN) to overcome  the weaknesses of ANN which consume time and are less  optimum [9]. Fig. 5 shows a graphic of radial basis function  network.

Figure 5.  A radial basis function network [9].

The formula for the technique is as follows [9]:  given m different points in                                    ?n   n  and m  real numbers                            a function is calculated from     n  to      that satisfies the interpolation condition:  (3)  function s can be obtained from m-dimensional linear space.

An interpolation method in which s has the form:    (4)  was selected for RBANN where mr is the number of radial  basis functions and the      are the weights. In Fig. 5, weights  w1 to w3 refer to     in (4) while V is the radial basis layer and  O is a sum of linear combination of values output from the  radial basis layer V- (4).While In radial basis layer V, this  equation is performed:    (5)  The    `s value is calculated using linear least squares  solution (LLSS). One problem of RBANN is that for large sets  of patterns, ill conditioned matrices can arise in (4), blocking a  perfect solution. Storage problem also arise with the usage of  LLSS [9].  Fast convergence and a way to avoid under fitting  and over fitting is needed to overcome this problem by using a  minimum number of neurons. One possible solution is to use  one neuron in the hidden layer and add one neuron for each  iteration until the convergence criteria is not satisfied [9]. One    of the simplest forms of RBANN is to set the number of  neurons equal to the number of patterns that exist in the input.

The simple RBANN form leads to a direct solution called the  zero error solution [9].

B. Naive Bayes Classifiers  In this system, data were collected from children during the  first 2 years of life. Using nave Bayes, the collected data were  employed to predict whether the children belonged to the lean  or obese class. Several attributes were chosen for the training  process: gender, adjusted Standard Deviation Scores (SDS)  birth weight; adjusted SDS weight gain from birth to 6 weeks,  adjusted SDS weight gain between 6 weeks and 8 month,  adjusted SDS length at 6 weeks, adjusted SDS height at 2  years, length of gestation, adjusted SDS BMI at 2 years, BMI  at 8 months, and whether the child was obese or lean at 3 years  old [10].

To evaluate the prediction success rate, four parameters  were studied: sensitivity, specificity, positive predictive value,  and negative predictive value. The most important parameter is  the sensitivity value, which refers to the number of correctly  predicted obese cases compared to total obese cases. A higher  sensitivity value means that the prediction is more accurate. To  evaluate nave Bayes prediction success rates, tests were done  when the children were 6 weeks, 8 month, and 2 years old  [10].

This is how the technique is implemented. Let X be the  children whose class is to be determined (obese or non-obese).

Let H be the hypothesis, that child X belongs to obese class C.

For classification, we want to determine P(H|X), the  probability that the hypothesis H holds given the observed data

X. The formula to calculate P(H|X) using Bayesian networks is  as follows:    (6)  where P(H) is the probability of H, P(X|H) is the posterior  probability of child X conditioned on H, and P(X) is the    probability of X. To determine P(H|X), we must first  determine P(X|H), P(H) and P(X). This can be determined  from the data used for training [10]. For nave Bayes  classifier, the steps to predict child obesity probability for data  sample X is as follows:  First, calculate the posterior probability                 ,  conditioned on X. Sample X will be assigned to class Ci if and  only if (7) is fulfilled:  (7)  P (Ci|X) can be determined by Bayes theorem :  (8)    P(X) is constant for all classes. Only the maximum  P(X|Ci)P(Ci) needs to be calculated. If no samples are given,  then all classes are assumed as equally likely. Therefore,  P(X|Ci) would be maximized rather than maximizing  P(X|Ci)P(Ci)  To determine P(Ci):  (9)  where NU1 is the number of training samples that belong to  class Ci, and  NU is the total number of training samples [10].

Then, assume that all the attributes are independent of each  other (no dependence relation among them). This equation is  applied:  (10)  P(x1|Ci), P(x2|Ci),,P(xn|Ci) can be calculated from the  training samples. If Ak is categorical, then:    (11)  where NUik is the number of training samples of class Ci for  nominal value xk for Ak, and NUi is the number of training  samples belonging to Ci.

Next (8), (9), and (10) are replaced into (7). Then assign  sample X to the class Ci with the highest probility  P(X|Ci)P(Ci). Nave Bayes have shown good quality of  prediction when the attributes are independent and when  applied to a large database [10].

C. Decision Tree  One system that uses the decision tree technique is a weight  management counseling system for obese children. The system  contains two modules, a Knowledge Management Module and  Case Based Reasoning Module, as shown in Fig. 6. The  Knowledge Management Module has three components: a data    repository, a knowledge miner and a case based rule structure.

In the knowledge miner component, the decision tree technique  is used to build trees from a database of cases. The decision  tree technique is also used in the Case Based Reasoning  Module to find possible solutions to a new child case [11].

A decision tree starts with root attributes and ends with leaf  nodes. Usually it has several branches which represent classes.

Below, we show an example of decision tree algorithm that  was used for childhood obesity prediction [10].

The tree is generated based on information-gain measure.

The steps are as follows.  Calculate:    (12)    (13)    where pi is the probability that an arbitrary sample belongs to  class C.

Figure 6.  Child weight management counseling system architecture [11].

Then, calculate the entropy E(Ai) of the expected information  based on partitioning by attribute Ai  as follows:    (14)      (15)    where Pij = sij / | Sj |, and | Sj | is the number of samples in  subset Sj. Then by branching on Ai, the encoding information  that would be gained is:    (16)  For the root node, the attribute Ai with the highest information  gain is selected. Then the branches are built based on different  values of aij, j = 1,,q. The tree will grow until all the samples  are in same class, at which point the node becomes a leaf and is  labeled with that class [10]. Fig.7 shows a graphical example of  a decision tree for an obesity problem. S1, S2, and S3 in Fig. 7  refer to the solutions of the obesity problem.



IV. DISCUSSION  In this section, we discuss the effectiveness, efficacy, strengths  and weaknesses of the three data mining techniques. We also  include the challenge within the problem and its applicability to  other adult diseases. Table 1 summarizes the strengths and  weaknesses of each technique discussed.

ANN, nave Bayes classifier, and decision tree are data  mining techniques that are applicable for childhood obesity  prediction. For ANN, environment is considered as an  important factor for childhood obesity prediction. The  prediction result can be more promising because environment  undeniably plays major role in a childs growth. The nave  Bayes classifier focuses more on the childs personal attributes  rather than the environment. However, the result of nave  Bayes classifier has been proven acceptable for childhood  obesity prediction [10].

Table I.  Data mining methods comparison  Technique Strengths Weaknesses  Artificial Neural  Networks (ANN)    1. Can handle a large  amount of input data      2. Fault tolerance and low  energy consumption    1.  Efficiencies (error vs.

network size) are  problem dependent  2.   The run time speed  may be slow when  many problems are  involved  Nave Bayes 1. Accurate when sample  attributes are  independent  2. Simple and  computationally  efficient    1.  High bias  2.  Less accurate and  performance degrades  when attribute are  dependent  Decision Tree 1. Fast learning and  classification speed  2.  Results in human-  understandable rules    1.  Prone to error if there    are many classes and a  relatively small  number of training  examples  2.  Can be  computationally  expensive to train    For the decision tree, we see that the technique is easier to  build than the other two methods since various attributes can be  used for childhood obesity prediction.

In the future, we will work on hybridizing two or more  applicable data mining methods. We hope that the results will  be better than current methods available.  Our goal is to  increase the accuracy, sensitivity, and specificity of  predictions, and reduce the cost (time and space) of current  methods. We will also increase our efforts to find better  solutions to childhood obesity.

Figure 7. A decision tree for an obesity problem [11].

The main challenge within this problem is to successfully  predict obesity at an early age. As we know, it is difficult to  identify potentially obese children when they are still young.

Their parent(s) might belong to a lean class but the children can  become obese when they grow up. Many factors are related to  obesity, including environment, family, lifestyle and habits.

Obesity may lead to many co-morbidity disorders such as type    2 diabetes, cardiovascular, early puberty, suicide, smoking,  bulimia, poor self image, social isolation and hypertension [1].

If obesity prediction is successful, then early prevention steps  can be taken.

The data mining techniques outlined above have also  been used to predict other adult diseases such as diabetes and  heart diseases [12][13]. The similarities with childhood  obesity prediction are the way data was collected and the risk  factors, while the differences are the input and output of the  prediction and how the techniques were implemented for that  purpose.



V. CONCLUSION  This survey has shown that data mining can be used to  successfully predict childhood obesity. The three methods  presented  ANN, nave Bayes, and decision tree  are proven  applicable to childhood obesity prediction.  These methods  each have their weaknesses and strengths; thus, further  improvements of the techniques are necessary to fully resolve  the childhood obesity prediction problem. This survey also  reminds the reader about co-morbidity of childhood obesity  and why it is important to prevent it at early age.

