An Improved Algorithm for Fuzzy Data Mining  for Intrusion Detection

Abstract- We have been using fuzzy data mining techniques to extract patterns that represent normal behavior for intrusion detection. In this paper we describe a variety of modifications that we have made to the data mining algorithms in order to improve accuracy and efficiency. We use sets of fuzzy association rules that are mined from network audit -data as models of ?normal behavior.? To detect anomalous behavior, we generate fuzzy association rules from new audit data and compute the similarity with sets mined from ?normal? data. If the similarity values are below a threshold value, an alarm is issued. In this paper we describe an algorithm for computing fuzzy association rules based on Borgelt?s prefix trees, modifications to the computation of support and confidence of fu ly  rules, a new method for computing the similarity of two fuzzy rule sets, and feature selection and optimization with genetic algorithms. Experimental results demonstrate that we can achieve better running time and accuracy with these modifications.

Zndex Terms-Fuzzy logic, intrusion detection, data mining

I. INTRODUCTION  N intrusion detection system (IDS) is a component of the A computer and information security framework. Its main goal is to differentiate between normal activities of the system and behavior that can be classified as suspicious or intrusive [l]. IDS?S are needed because of the large number of incidents reported increases every year and the attack techniques are always improving.

IDS approaches can be divided into two main categories:  misuse or anomaly detection 111. The misuse detection approach assumes that an intrusion can be detected by matching the current activity with a set of intrusive patterns (generally defined by experts or ?underground? web sites).

Examples of misuse detection include expert systems, keystroke monitoring, and state transition analysis. Anomaly detection systems assume that an intrusion should deviate the system behavior from its normal pattern. This approach can be implemented using statistical methods, neural networks, predictive pattern generation and association rules among others techniques  In previous work [4,10,11] we used the standard Apriori algorithm described by Agrawal and Srikant [2] for mining  This work was supported in part by the National Science Foundation Grant# CCR-9988524 and the Army Research Laboratory Grant# DAAD17-01-C-0011  association rules as modified by Kuok, Fu, and Wong [7] for fuzzy association rules. Fuzzy logic is appropriate for the intrusion detection problem because quantitative features such as the number of different connections or messages are often used for anomaly detection, and because security itself involves fuzziness [4]. In order to detect anomalous behavior, we mine sets of fuzzy association from new audit data and compute the similarity with sets mined from ?normal? data. If the similarity values are below a threshold value, an alarm is issued.

Originally we used Kuok, Fu, and Wang?s [7] method for computing confidence and support in which an ?occurrence? of an itemset is computed by multiplying the memberships of each item. This method of computation has some properties that seem counter-intuitive when applied to intrusion detection. Suppose that an itemset consists of attributes each of which has an associated membership value of 0.9. If the itemset contains 2 attributes, its occurrence would be 0.81. If it contains 5 attributes, its occurrence would be 0.59. The result is that small itemsets tend to have much higher support and confidence than large itemsets. However, we have found that, for our application, larger itemsets tend to be more informative.

Christian Borgelt [3] has developed a much faster algorithm for association rule mining that uses prefuc-trees to store itemsets with sufficient support and confidence (among other constraints). His algorithm is included in the commercial datamining tool Clementine available from SPSS.

We have adapted this algorithm for mining fuzzy association rules. In standard association rule mining, itemsets are sets of attribute values that have occurred in a transaction. Fuzzy association rule mining is more complicated because the elements of the itemsets may (and usually do) occur to some degree. Instead of just counting items to compute the confidence and support for a rule, we must compute fuzzy occurrences of the items in the itemsets. In order to adapt Borgelt?s algorithm to mine fuzzy association rules, we modified the prefix tree structure to store the fuzzy frequencies of each itemset and modified the algorithm to propagate these values through the tree as it is updated.

This paper is organized as follows. Section I1 presents literature review, Section 111 describes data preprocessing, section IV shows improvements to the Apriori algorithm, section V describes genetic algorithms for feature selection and optimization, Section VI discusses some experiments  0-7803-7461-4/02/$17.00 0 2002 IEEE 457    with a fuzzy prefix-tree implementation of the Apriori algorithm, and Section VII presents our conclusions.



II. LITERATUREREVIEW  A. Fuzzy Association Rules Agrawal and Srikant [2] defined an association rule using  the following notation: n transactions, {TI, T2, ..., Tn) of m items, ( i l ,  il, ..., i,,,) in the set of all items, I. Each of the transactions Tj (1  I j I n) in the database D represents an association of items (Tj E I). An itemset is defined as a non- empty subset of I. An association rule can be represented as: X + Y, c, s, where X c I, Y c I, and X n Y = 0. In this association rule, s is called support and c is confidence of the association rule. The support is the percentage of the transactions in which both X and Y appear in the same transaction and the confidence is the ratio of the number of transactions that contain both X and Y to the number of transactions that contain only X.

Originally, Agrawal and Srikant [2] implemented the Apriori algorithm to mine single-dimensional Boolean association rules from transactional databases [5]. However, in the intrusion detection field we need to mine quantitative attributes. Kuok, Fu, and Wong [7] integrated fuzzy logic with association rules to handle numerical values and to obtain rules that are more understandable to human beings.

Using fuzzy logic, a quantitative feature can be mapped to different fuzzy sets.

-P  t z  n S  a ? b d c ? b  a b+d c  Figure 1. Representation of the standard membership functions: S, n, and Z  Figure 1 (taken from Shi [ll]) shows the standard membership functions Z (low), ll (medium) and S (high) that we are using to express membership values (Each function is controlled by two parameters) .

B. The Apriori Algorithm The basic Apriori algorithm [2] finds frequent itemsets for  Boolean association rules, receiving as input a database T of transactions and the minimum support for the rules. It uses the Apriori property: if an itemset I is not frequent, the itemset I U A (A is any other item) is also not frequent; i.e.

?all nonempty subsets of a frequent itemset must also be frequent? [5, pp. 23 11.

The Apriori algorithm builds a set ck (candidate itemsets of (frequent itemsets of size k) to create frequent size k) and  itemsets of size k+l: ~~  L1 ={frequent items} k=2 While(Lk != 0) [  Ck = GenerateCandidates(Ld; for  each transaction t in the database  Increment the count of all candidates in Ck that belong to T  L ~ + I  = candidates in ck with enough support K++;  I retum (L=L, uLZ u....);  GenerateCandidates() returns a subset of the join operation of Lk and 4, pruning itemsets that do not satisfy the Apriori property. Computing the support and confidence of all nonempty susbsets of each frequent itemset generates the set of association rules  111. DATA PREPROCESSING We are using the DARPA-MIT dataset for the 1999  intrusion detection systems evaluation [9]. This dataset contains 3 weeks of traffic wilh normal patterns (attack free) and some old (well-know) attacks. For testing, the fourth and fifth weeks of data contain 20 1 instances of about 56 types of attacks distributed throughout these two weeks. Specifically, we are interested in network anomaly-detection, so we are using the tcpdump binary files that contain the information of packet headers of the outside traffic in the Air Force simulated network.

The first step in the data preprocessing consists of the extraction of an ASCII file with selected fields of the TCPAP header (features) by using a modified version of sanitize-tcp program (downloaded from http~/ita.ee.lbl.gov/html/software on February 2001). The features extracted are timestamp, source host (renumbered), destination host (renumbered), source port, destination port, flag, and size of each packet.

0.0 1.0 2.0 3.0 4.0 5.0 -- PIu 2 seconds? timestamp  k2d 2 s e c o n d e l p3* 2 !~ccon&-  Figure 2. Specification of temporal stai.istica1 measurements for the experiments     We have implemented a program that joins those records using the timestamp to compute the frequency of the attributes for consecutive fixed-intervals of time. Such a program extracts 11 features: number of different source IP addresses, number of different destination IP -addresses, number of different source ports, number of different destination ports, number of SYN flags, number of FYN flags, number of RST flags, number of packets of normal data (i.e. with no special flag associate with it), number of PSH flags, total size of the packets, and total number of packets.

These features not only reflect the header information used by Luo [ 101 or Shi [ 111 but also give information about the data transfer itself. We are using a fixed-interval of 2 seconds, as is shown in Figure 2 (taken from Luo [lo]).



IV. IMPROVING THE APRIORI ALGORITHM WITH FUZZY VALUES We have modified the fuzzy association rules algorithm  implemented by Lee, Stolfo and Mok [8] and Luo [lo], to define a symmetric similarity function of two rules. Given the association rules: R1: X + Y, c, s, R2: X? 3 Y?, c?, s?, where X, Y, X?, and Y? are fuzzy itemsets, the similarity of these rules is given in (1).

I  For the experiments reported in this paper, we are using a minimum confidence of 0.85 and a minimum support of 0.3.

We are analyzing 11 features of TCP header packets. This large number of features improves the detection capability of the IDS, but increases the execution time of the algorithm.

In order to reduce the running time of the Apriori algorithm, we are penalizing rules with few itemsets (since we have found that large itemsets tend to be more informative for our application and Luo?s [ 101 implementation generates too many uninteresting rules). The basic idea is to modify the minimum support and confidence constraints of a rule taking into account the number of items (features) in the left-hand side (LHS) and right-hand side (RHS). A user threshold K (between 0 and 1) is used to control this pruning step. If K increases, the number of rules generated decreases.

Equations (4) and (5) are used to compute the new support and confidence. It is important to observe that the support or confidence of the rule does not change; only the constraints of rule selection in the candidate generation step of the Apriori algorithm change dynamically.

= - sup) (NwnberFeatures - CurrenrFeatures) K + min-sup NumberFearures  (4) 0 if(X # Y)or(X?+ Y ? )  Shifarify(R,,R,) = NewMinconf = ( I  - min-conf) (NumberFeaures - CurrenrFemures) K + min-conf (5) NumberFeawes i f (X = Y ) d ( X ? =  Y ? )  (1) NumberFearures is the total number of features available, CurrentFeatures is the number of itemsets in the LHS and RHS of the rule, K is the user threshold, minsup is the minimum support and min-conf is the minimum confidence.

If K is equal to 0, all the rules will have the same confidence and support (i.e. the basic Apriori algorithm). If K is 1, then rules with few itemsets in its LHS and RHS must have much  max(c, c?) * max(s. s * )  Given two rule sets SI and S2, we can define s as (2).

s = 2 similarity ( R I ,  R 2 )  V R 1 E S 1 V R z E S z  (2)  The total similarity is given in (3).

(3) Figure. 3 shows the similarity between 6 hours of normal  data (from week one) with respect to attack free data (from week 3) and test data (week 4). We can see, for instance, that for Monday, the similarity with attack free data is about 0.5, but the similarity with test data (with many attack instances) is almost 0.

0 9  0 8  0 7 0 6  0 5  0 4  0 2    Test-data  1 Monday Tuesday Wednesday Figure 3. Similarity using 6 hours of data  more confidence and support to be selected by the algorithm.

As an example of this pruning step, consider the following rule (with 3 itemsets) being generated:  (nlf=low) (npf=high) + (tsize=medium) support = 0.346,conjidence= 0.82  If min-sup = 0.2 and min-conf = 0.8, then with the basic Apriori algorithm (i.e. with K=O) this rule would be selected.

However, by using K=0.5, this rule does not satisfy the new Apriori constraints:  NewMinSup  NewMinConf  = (1 - 0.2)- (11 - 3,  (0.5) + 0.2 = 0.49  = (1 - 0.8) - (11 - 3) (0.5) + 0.8 = 0.872  Experimental results demonstrate that large values for K (near 1) result in a similarity function that is not accurate, because the number of rules generated by the algorithm is too low.

The algorithms were tested with a well know network intrusion, the mailbomb attack, using different amounts of network traffic information (300, 600, 1800 and 3600     seconds). Mailbomb ?is an attack in which the attacker sends many messages to a semer, overflowing that server?s mail queue and possible causing system failure.? [6,pp. 441.

Figure 6. Impact of K for the mailbomb attack detection (3600 seconds) Figure 7 shows the impact of K in the number of rules  produced by the fuzzy associatiaa rules algorithm.

0 8  Smilarlty 0 5  0 2 0 1  -..-,,- 0 4  I-.. - .

0 02 0.4 0.5 0.6 0.8 K  Figure 4. Impact of Kfor the mailbomb attack detedon (300 seconds)  Figure 4 shows the similarity between an attack-free set, with normal traffic and mailbomb sets, using an interval of time of 300 seconds. The x-axis corresponds to K, and y-axis is the similarity. We can see how K values near 0 or 1 cause the similarities to drop (with 0. there are too many rules; with 1, there are too few). A K value near 0.5 gives the best accuracy. Figure 5 shows the results of an experiment with 600 seconds of network traffic data and Figure 6 with 3600 seconds (with K=O we obtained a false positive because of the large amount of uninteresting rules).

0 8 0 7 0 6  Simuarity 0 5 0 4 0 1  0 03 0.4 0.5 0.6 0 8  K  Figure 5. Impact of Kfor the milbomb attack detection (600 seconds)  s I   0 8 0 7  Ob  - 0 5 0 4  0 3 0 1    0 0 2  0 4  0.5 0 6  0 8  I K  Figure 7. Impact of K in the number of rules generated (1800 seconds)

V. USING GENETIC ALGORITHMS Genetics algorithms (GA) are used for feature selection  (reducing the running time and improving the accuracy of the Apriori algorithm) and to optimize the membership functions (Each function Z, ll and S is controlled by two parameters).

Shi [ll] implemented a GA (using Luo?s algorithm [lo] to compute fitness) where the main goal is ?to maximize the similarity of the reference rule iset and normal rule sets mined from data that contains no intrusions while minimizing the similarity of the reference rule set and abnormal rule set mined from data containing intrusions? [I 1, pp. 571.

Features are represented with binary values, and each one is associated with the fuzzy membership function parameters (a real number). See Figure 13 (taken from Shi [ll]). The upper box indicates whether the ?feature? is selected or not.

The bottom represents the fuzzy membership function parameters to be optimized.

I  Figure 8. The representation of a single fuzzy variable  This algorithm uses roulette selection, uniform crossover and a bit flipping mutation straiegy.

We have implemented the following improvements to Shi?s algorithm: 1) Inclusion of the pruning step for relative support and confidence (see Section IV]l in the execution of LUO?S algorithm for the fitness evaluation.

2) Modification of the fitness function. The fitness function is computed with (6). Smj,, is the similarity between the reference rule set and the normal rule set, and Sm~.6nom is the similarity between the reference rule set and the abnormal rule set.

fitness = ?ref .mm  S r e ~ , ~ n o m  (6)  Shi [ 113 correctly stated that by using this equation a high fitness value could be achieved by evolving parameters that caused no rules to be mined. He tried to solve the problem by using a threshold value to penalize chromosomes that produce a very small number of rules for the reference set. We have modified this approach to decrease the value of the fitness of an individual (Equation 6) taking into account Rr (number of reference set rules), Nr (number of normal set rules), Ar (number of abnormal set rules), and p (a user threshold):  Rr + Nr + Ar  Tr = p *  Nr i f (  Nr c Tr)  + Fitness = Fitness * -  Tr Ar if (Ar  c Tr)  + Fitness = Fitness * - Tr  In order to prevent overjitting and to give more exploration to the system, we have changed the fitness evaluation framework. In [ l l ]  the general approach of the fitness function is: Use ReferenceRuleSet  compare with NomlRuleSet (similarity must be high) compare with AbnormalRuleSet(simi1arity must be low)  The new approach uses different reference rule sets. Thus, the fitness function selects randomly a reference set each time an individual is being evaluated: Select ANY fire from the set of ReferenceRuleSetfiles  compare with NormalRuleSet (similarity must be high) comnare with AbnormalRuleSet(simi1aritv must be low)  When the GA is completed successfully, we save the fuzzy membership function parameters and the selected features.

Since the GA learned from different reference sets, the optimization is more general. As an example consider Figure 9. We have randomly selected a reference set (with normal data) and we have executed the fuzzy association rules algorithm with and without the GA optimization. The data shown for the GA optimization is the average of 10 executions. The GA did not select more than 7 features (reducing about 60% of the execution time of the algorithm), however, it tried to increase the similarity between the reference set and the normal profile (using 600 seconds),  while tried to decrease the similarity between the reference set and the mailbomb attack (using 1800 seconds).

Simlarily 0 5 0 4  0 2  nNormal (whhoul GA)  .Mailbomb (wthoul GA)  0 Madbomb cGA)  300 600 1800 Network tr.amC (seconds)  Figure 9. Comparison of the fuzzy association rules algorithm with and without GA optimization

VI. PREFIXTREES Christian. Borgelt [3], from the Otto-von-Guericke-  University of Magdeburg, implemented an efficient version of the Apriori algorithm (Find Association RuledHyperedges with Apriori Algorithm). The use of this software is under the terms of the GNU Public License, and it was downloaded from http~/~zzv.cs.uni-maedeburg.de/-borpel~aDnon/aDnon.ht~ (Accessed on August, 2001).

Borgelt uses prefix trees to store itemsets with enough support and confidence (among others constraints). We have modified the software to include the following features: 1) Computation of fuzzy membership values for each item in the input dataset (the fuzzy functions Z, ll and S are applied to the input dataset before Borgelt?s program is executed).

2) Computation of the total support and confidence of a fuzzy itemset with the use of the operator MULT (multiplication of the membership of each item) or ,MIN (minimum membership of the items).

3) Inclusion of the pruning step for relative support and confidence (see Section IV).

As an example of this algorithm, consider the small dataset in Table 2 with three items (columns): A, B, and C. Each item has associated a membership value for each transaction (row). The fuzzy prefix tree is shown in Figure 10 (using MULT): A has support of 50% (2.0 units) and 50% of confidence, A t B has support of 8.25% (0.33 units) and 35.67% confidence, and C t A B has support of 1.80% (0.072 units) and 21.82% confidence.

TABLE 2. A DATABASE WITH MEMBERSHlPS  I 0.5A I 0.3B I I 0.1c  0.9A 1 0.28 I 0.4C  46 1    A I  B I  C  I 2 1  0.9 I 1.4  (seconds) M O  0.072  Normal Mailbomb Normd Mailbomb 0.89 0 0.18 0 0.57 0 0.81 0 0.908 0.65 0.72 0.03 , 0.801 0.115 0.9 0.1 .

Figure 10. Refix tree with fuzzy memberships  The main advantage of this approach is efficiency. There is not need for candidate generation since the frequent itemsets of size k+l (i.e. the new levels in the tree) are obtained directly by reading the dataset. It also stores the fuzzy frequency of each one of the possible itemsets, so the time spent in the generation of the association rules is reduced dramatically. However, this algorithm only builds rules with one item in the LHS.

A program was written to compute the similarity between two set of rules generated by our version of Borgelt's algorithm. Fig. 11 shows a comparison of the running time of the fuzzy association rules algorithms. The prefix-tree implementation of the Apriori algorithm is much faster than the nai've Apriori. Although we are generating rules with only one item in the LHS, the algorithm is able to distinguish between normal and suspicious behavior. Table 3 shows the accuracy of the Apriori algorithms with the GA optimization, K=0.6, min-sup=0.3 and min-confi0.85.

TABLE 3. COMPARISON OF THE ACCURACY OFTHE Nzzy ASSOCIATION RULESALmRmiMS  SIMlLARllY APRlORl I PREFIX-TREE  I NBIWOTK U a I l C  1 I I I  VXI. CONCLUSIONS Fuzzy association rules can be used to implement a  network intrusion detection system based upon the assumption that an attack can be identified as burst traftic in audit logs. In order to improve the accuracy of such IDS, we have been using 11 features of the TCP header packet.

However, with this relatively large number of features we obtain many uninteresting rules (since the number of possible combinations of the fuzzy variables is quite large) and the running time of the Apriori algorithm increases dramatically.

To solve this problem we have introduced a new pruning rule in the candidate generation of the Apriori algorithm to penalize itemsets with few items. Experiments showed that this pruning step not only reduces the number of rules, but also increase the accuracy of the system. We have also improved a genetic algorithm to optimize the fuzzy association rules. The GA is able to learn from different  reference sets, eliminating the overfitting problem. Prefix trees seems to be an efficient altlemative to find association rules with only one item in the LIJS. We have included fuzzy logic management in the software provided by Borgelt, and we have obtained similar accuracy with respect to the basic Apriori algorithm. However, the running time of Borgelt's algorithm is much lower, and its use may enable online detection.

