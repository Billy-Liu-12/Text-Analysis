Audit-trail-based modelling of the decision-making process in

Abstract   In a behavioural and organisational context,  complex problems that reflect the multidimensional attributes of human activity  inevitably arise and have to be addressed. In an  attempt to model human decision-making  behaviour, the vast number of potential  parameters raises the question of how this complexity can be harnessed.  This paper proposes  a data-driven approach, with which dependencies  or associations are extracted from the data itself.

The complex and dynamic nature of modern  business processes makes this approach more  suitable, as the design of competent rule-based models or expert systems would be cumbersome,  expensive or even infeasible. A hybrid behaviour-  modelling method, based on both statistical  component analysis and sensitivity analysis, is  proposed to directly model decision behaviour.

The derived model is the outcome of an optimisation process, where model-data matching  is maximised in terms of known, pre-defined  criteria. The implementation of the proposed  intelligent system as an integral part of real-life  business/accounting activity is discussed, and its  capability to provide intelligent support to the decision making and internal control processes in  management and accounting is demonstrated  using realistic data from a business procurement  application.

1. Introduction   In a behavioural and business context, it is  inevitable to have to cope with a lot of different  information attributes which by and large reflect  the multidimensionality of the human nature.

Resource-Based-Agents accounting information  systems and user navigation in management  information systems are two indicative areas in  which the vast amount of potential parameters  raise the question of how all this complexity can  be harnessed.

The answer can be two-fold. First, the  accounting, auditing or managerial staff can design  appropriate models which could act as rule-based  systems and give solutions to well-defined  problems. The second approach concerns data-  driven methods which intend to extract the  appropriate rules based on the data itself. The  complex and dynamic nature of the contemporary  business processes makes this approach more  suitable, as the design of appropriate models or  expert systems would be cumbersome, expensive  or even infeasible. Thus, classification and  prediction in a behavioural context can be valuable  alongside a necessary data reduction or some kind  of feature selection procedure.

The main aim of this work is to identify a  suitable algorithmic framework that can maximize  classification and prediction in organisational  domains that are examined under a behavioural  context. A second objective is to propose an  exemplar for audit trail design, analysis and  modeling in management information systems.

1.1.  Audit trail analysis   Audit trail is a term used in both accounting  and computing disciplines. Literally, it reflects the  chronological order of the events which take place  in an organisation or in a computing server.

Behavioural analysis (of user or interactions) can  be carried out by examining the records of the  audit trail file. The prevalence of electronic forms  of data has forced originally disparate Computing  and Management disciplines (especially that of  information systems auditor) to converge.

According to current practice, the audit trail  analysis and initial setup can be carried out by  computer experts or internal auditors.

In computer systems, audit trail are produced  by application software systems. They record  details of all user activity, in a chronological order,  0-7695-2268-8/05/$20.00 (C) 2005 IEEE      including the input transactions, the processing  paths they traverse, and the resultant effects on  database records.  Weber [1] distinguishes two  types of audit trail: (a) an accounting audit trail,  which maintains a record of events within a  subsystem and (b) an operations audit trail, which  maintains a record of the resource consumption  associated with each event in the subsystem. The  audit trail must be analysed by auditors or  management to detect possible control weaknesses  in the system. According to O?Leary [2], intrusion- detection systems can be employed. These systems  monitor users to determine whether current  behaviour conforms with past behaviour. Denning  [3] clarified the role and use of audit trail in the  context of intrusion detection. This model is based  on the hypothesis that security violations could be  detected from abnormal patterns of system usage.

1.2. Aim of computational algorithms   Our aim is to produce appropriate algorithms  for behavioural data classification capable of  coping with:    a. The multidimensionality of data. To do  this, feature selection methods are applied  in order to select the optimal feature  subset, which maximises the  classification and prediction performance  of the algorithm.

b. Multicollinearity issues. This is an  important step, since the large number of  features in a behavioural analysis context  make the probability of correlated each  other features very high.

c. To cope with overfitting. Overfitting is  the result of an over-trained sample which  is damaging as to the proper classification  of the rest of the data. The complexity  and uncertainty of human-generated data  can cause problems. Methods for  overcoming such difficulties are  proposed.

The large number of features is often a  restrictive factor. The algorithms should be able to  perform almost equally well with datasets  containing fewer features that exhibit a high  sensitivity to the classification target. Determining  the sensitivity of features is most important, since  the sensitivity score can be used as a metric by  which a feature?s worthiness is evaluated.

2.  Some background on Behavioural  Accounting   According to Belkaoui, [4] and the Committee  of Behavioural Science [5], accounting can be  considered to be a behavioural process. The  behavioural accounting approach applies  behavioural science to accounting. The objectives  of this approach are very similar to that of  behavioural science. As a main objective of  behavioural science is to analyse and predict  human behaviour, the corresponding task in  behavioural accounting is to analyse and  generalise the behaviour of financial information?s  users in all possible accounting contexts. Users of  accounting information can be accountant or non-  accountant individuals. Behavioural accounting is  a multidisciplinary field that includes accounting  of financial theory, statistics or other  computational methods, cognition and psychology,  and increasingly elements of information theory  and computing.

In terms of human information processing in  accounting there are two main components that  can be considered as the main objectives. The first  deals with the improvement of the quality of the  data (including representation). The second  concerns the ability/skills of users processing  business data. Several approaches have been  proposed in contemporary literature based on  probabilistic judgments, computational aspects and  cognitive attributes.

The Brunswick?s Lens Model [6] is based on  the recognition of the interaction between the  environmental and individual-specific variables. A  regression or ANOVA model is used where the  personal attributes are categorical values. Other  methods include conjoint measurement,  multidimensional scaling techniques, and  discriminant analysis. The expected benefits come  in the form of improved decision making in terms  of:    1. The importance of attributes in the  judgment process examining the  consensus between decision makers  2. The accuracy of judgments  3. Effects of task characteristics on  achievement and learning    In accounting, especially in the auditing areas,  the judgment accuracy is assessed by two main  criteria. One is the degree of consensus regarding  the decision made and the other is a mathematical  or statistical model.

0-7695-2268-8/05/$20.00 (C) 2005 IEEE      2.1.  General behavioural aspects   An Accounting Information System (AIS) in an  organisation plays the role of supporting the  decision making process that is carried out by  internal or external users of the organisation. This  can be done through the appropriate process and  presentation of financial information. Ko and  Mock [7] argue that to design a successful AIS,  the integration of human behaviour in the system  is important.

In support of this argument, Dickson [8]  advocates that the decision makers are different  (having obviously different needs) and the  information system requirements should vary per  type of decision being considered. Thus, it might  be expected that behavioural studies in AIS can  support not only the design of effective accounting  systems but also the provision of new theoretical  insights into the nature of accounting information.

The decision-facilitating function of AIS is  emphasised in the AIS behavioural research. In  their review, Ko and Mock [7] argue that these  studies investigate the parameters that influence  the decision makers? effectiveness in using  accounting information. These parameters can be  divided in three categories including  a. Information structures,  b. Individual difference characteristics  and  c. Task characteristics.

2.1.1 Information structures and  presentation format   Information structures that communicate the  information to the users play an important role and  they can include: a. the way information is  presented, b. the degree of aggregation of  information and c. the types and frequencies of  feedback to the decision-maker. The report format  of financial information is investigated by several  studies, whereas salient effects seem to be  relevant. Stock and Watson [9] investigated the subject by examining different formats of financial  accounting ratios revealing classification  differences due to different treatment of these  ratios.

2.1.2 Individual difference  characteristics and cognition   Individual difference characteristics refer to  cognitive issues as well as the experience of the  users. The cognitive characteristics can be  considered as the independent variables and the  information processing behaviour or task  performance as the dependent variables.

According to Ko and Mock, some AIS researchers  hypothesise that a decision maker?s performance is  likely to be affected by these characteristics.

Dermer [10] investigated the effect of decision  makers? cognitive characteristics on the perceived  importance of information. The results suggested  the cognitive characteristics of users need to be  considered in the design of accounting information  systems.

2.1.3 Task characteristics.

The decision task characteristics play an  important role. Behavioural research in AIS  investigates the effects or relationships of task  parameters (e.g. task complexity, ambiguity or  time and financial constraints) on the decision  maker performance.

2.2.  Information Systems Audit and  Security   Multidimensional accounting systems seem to  take into account non-financial information and be  more adjusted to behavioural issues. Current ERP  applications include not only human resources  subsystems, but also tools of recording the user  behaviour for security and change-management  purposes [11] [12]. Security is one of the most  critical areas in Internal Auditing. A definition  [13] of computer audit (or Information Systems  Audit) is ?the application of the principles of  internal auditing to the practices of computing and  information systems?.

2.3. The rationale for data reduction   Contemporary accounting and management  information systems deal with huge amounts of  data which must be processed and evaluated on an  annual, monthly, daily or other basis. The  dominance of internet, intranets, and other  networking environments have increased the  complexity of current databases and made the need  for data reduction tools more imperative. Human  behaviour also plays a distinctive complex role,  since it is unpredictable and much more difficult to  follow specific rules.

According to Inza et al [14], dimensionality  reduction offers the following advantages for a  classification system:  ? Cost reduction in data acquisition  0-7695-2268-8/05/$20.00 (C) 2005 IEEE      ? Improvement of the comprehensibility of the classification model  ? Faster induction of the classification model  ? Improvement of classification accuracy ?  3. The proposed audit-trail modeling  system   3.1. The data analysis system and  simulation data   The simulation is relevant to internal agents  modelling while they access and explore  information data for completing a task and/or  making a decision. This experiment aims to  achieve maximum generalisation using a neural  network model.

The high-level architecture of the proposed  audit-trail data analysis system includes a user  behavior pattern generation stage, where the key  features of the user (user model) are calculated,  and a user classification stage. The performance of  such a system depends crucially on the  effectiveness of the chosen behavior modeling  process. Existing data-driven models of human  behavior employ some form of correlation  analysis, usually via calculation of the covariance  matrix [15] or via Principal Component Analysis  (PCA) [6] [16].

26 postgraduate students ran a simulation of an  REA-oriented reporting system. The students were  asked to make a decision about the purchase of a  software package (choice of 10 packages in total).

They were prompted to execute some queries  which concerned relevant information of financial  or non-financial qualitative data. This report  system involves the view of queries based on  disaggregated and localized data. Thus, the viewed  queries belong into groups with respect to the  operating business functions.

To model human decision behavior with a  limited set of parameters, the proposed method  uses PCA to reduce the dimensionality of the input  data and provide a simple behavioral model. Thus  the method is a hybrid of statistical and self-  learning methods, comprising:  a. Pre-processing, which includes feature  extraction and selection (redundancy  reduction),  b. Statistical component analysis (PCA),  c. Sensitivity analysis through neural  network bootstrapping, and finally  d. Supervised nonlinear classification by a  neural network.

The result is a compact, robust behavioral  model (user representation in terms of a small  number of parameters/features). Given this model,  the data analysis system will be able to generate  the behavioral pattern for a particular user and  then characterize/classify it by employing the  derived neural network model.

The method intends to produce a classification  and prediction tool for decision makers identifying  the important features and removing redundant  information. In this experiment, the decision  makers are classified into 2 categories according to  if their selected purchase (software) includes high  level of support service (provided by suppliers) or  not.

3.2. Feature Design   Time-based features can be extracted regarding  3 time-based characteristics. The features are  designed according to:  ? The contextual environment of decision making process  ? The level of interest which can be interpreted, furthermore, as motivation  ? The salient effects which can identify focal points or sensitive information  ? The cognitive characteristics of users which reveal users? exploration style  (cognitive style) or cognitive strategies    1. Duration of activity (37 features). Features of  this type are pertinent to how long a user stays in a  file (where he can execute several queries) or  duration aspects based on the overall simulation  (like total duration of the experiment,  longest/shortest file duration, start time etc.).

2. Activity frequency (37 features). Features of  frequency are relevant to the number of times the  user visits the files (that correspond to operating  functions) or how many times he/she executed  queries within each file. The number of files or  queries used by users make up the rest of this  feature type.

3. Order-based (44 features). These features are  relevant to the cognitive characteristics of the user.

The time he/she accesses a file is recorded and an  ?order score? is calculated. The earlier a user  views a file the bigger the ?order score? value. For  0-7695-2268-8/05/$20.00 (C) 2005 IEEE      each file:  S = T/A, where S is the ?order score?  value, T is the total simulation time for a user and  A the file?s access time. Different features are  extracted for each file considering either the  average of these values or the (unique)  earliest/latest access time. 118 features per user  were extracted from the raw log data. Table 1  depicts the contextual and time structure of  features.

Table 1: Structure of features   Duration Frequency Order Sum  Files  Activity  33 33 44 110  Overall  Activity  4 4 - 8  37 37 44 118  3.3. Principal Components Analysis The number of features designed is inevitably  high. Some of them are possibly redundant adding  more noise or delay to the process, making the  need for data reduction imperative. PCA is a  classical method which has been used mainly for  data reduction purposes. This study involves PCA  as a step of transforming the input of the neural  network (NN) to avoid NN overfitting or noise  errors. The original features will be selected or  discarded using a NN boot-strapping method.

3.4. The NN Bootstrapping Approach   NN cross-validation and bootstrapping is  considered to be well performing in terms of  defining the generalisation error and best model  selection ([17] [18] [19]). In this study, NN  bootstrapping is used as the core method to:    1. Perform a Sensitivity Analysis of inputs  which can be the original features or the  Principal Components Scores variables.

2. Remove the redundant features from the  system and keep only those which appear  to have the greatest sensitivity to output  giving simultaneously the minimum  generalisation error.

3. Select the best model that minimises the  classification error and gives maximum  generalisation value.

3.4.1. Description of the NN Bootstrapping. In fig. 1, the NN Bootstrapping method is depicted.

There is one hidden layer with 4 nodes and the training error is defined as .05.  The classification target vector takes 2 values which are 0 for selection of packages type A and 1 for type B.

(Type A = software packages with moderate or low service support, type B packages with high service support). The maximum number of the models is 1500. In each model a data validation subset is defined at random. Consequently 23 users are treated as the training set and 3 as the validation set.  The target is to find 100 models with low generalisation error, which is taken to be equal to the lowest error of the first 10 models.  In case that the instances of this error are fewer than 100, we select the 100 best models out of 1500.

Figure 1: NN Bootstrapping   Furthermore a random variable/feature is added  which can be used as a metric of sensitivity. For each successful model we run a simulation where for each variable of an input vector we assign 10 values from 0 to 1 increasing by step s = 0.1. Then the variance of output is calculated regarding the 10 variables? values. For each variable (including the random variable) the procedure is repeated for all the input vectors of the data and we calculate the variance mean of all outputs.

The final sensitivity of each variable is  calculated as the average of all 100 models as S =  V/M where   V  =  The average of variance of all  models? and  M  =  The average of all models?  simulated outputs means   It should be mentioned that the variance is divided by the overall mean of the outputs to smooth any distortions that can occur due to  0-7695-2268-8/05/$20.00 (C) 2005 IEEE      different magnitude of the output values. The variables with lower sensitivity than random are excluded from further analysis. The same happens when the variables have sensitivity less than 110% of the random gauge.

3.4.2. The feature selection algorithm. The method involves PCA and 3 stages of sensitivity analysis (see fig.3). These are:   1. PCA and extraction of Principal Components (PC) Scores  2. NN Sensitivity Analysis of  PC Scores  3. NN Sensitivity Analysis of  Selected  Features  4. NN Sensitivity Analysis to define the best  Model   3.4.3  Principal Component Analysis (PCA).

Initially the Principal Components (PCs) which  contribute to 95% of the covariance are computed.

This number is 18. As a second step we carry out Varimax [20] rotation on the PC loadings. This is a necessary step to achieve maximisation of variance within each loading and therefore a bigger differentiation of components in terms of variables? significance within each loading.

Finally the PC Scores are calculated.  PC Scores indicate the score of user on each component and they can be expressed as S = A * L, where A= Standardised data and L = PC Loadings   3.4.4. Using PC Scores as Input to the  Bootstrapping NN.

NN Overffiting is a critical issue which should  be tackled if adequate generalisation and less output variance are to be achievec. Causes of overfitting include large number of input variables as well as multicollinearity problems [21] [22].

Since the number of original variables is large (in respect to the training cases), PC Scores can be used as inputs to the NN instead of the original variables and overcome respective problems. The task in this phase is to assign a degree of sensitivity to PC Scores. The number of selected significant components with the greater sensitivity is 7.

PCs are then converted into features again through loadings after being weighted according to the result of the PC Scores? sensitivity. In this way, the system runs an intermediate process offering more reliable results and avoiding overfitting. 80 (out of 118) features with the greater sensitivity (over 0.1) are selected.

The selected features from the sensitivity analysis process feed a similar NN. Following the same NN procedure, 13 features are finally extracted (Table 2).

Table 2: Final features    N  o  Descript-  ion File  Time  Character  istic  Sens-  itivity  (%)    Idle time  between  file  opening  Package  Functionality  Info  Duration   11.35    Idle time  after file  process  Budget Duration 9.84    Times  that file  was  accessed  Package  Performance  Info  Frequency   5.48    Number  of  different  queries  Supplier?s  Offers Frequency 5.22    Number  of  different  queries  Supplier?s  pricing  (discounts,  price policy  etc)  Frequency 5.71    Number  of  different  queries  Package  Performance  Info  Frequency 5.54    Number  of  different  queries  Package  Functionality  Info  Frequency 4.55    Number  of  different  queries  Package  Service Info  Reports  Frequency 7.38    Number  of  different  queries  Logistics  Department  Files  Frequency 5.67    First Time  Access  ?Order  Score?  Budget Order 6.8    First Time  Access  ?Order  Score?  Supplier?s  Stability/Relia  bility  Information  Order   11.35    First Time  Access  ?Order  Score?  Package  Performance  Info  Order 4.91    First Time  Access  ?Order  Score?  Package  Functionality  Info  Order 6.4     Average  ?Order  Score? of  Access  Package  Performance  Info  Order   4.71     Average  ?Order  Score? of  Access  End  Package  Performance  Info  Order   5.2    0-7695-2268-8/05/$20.00 (C) 2005 IEEE      3.5. Assessing the Generalisation  Performance ? Best Model Selection   The NN process is repeated without the  generalisation restriction. A cross-validation  procedure with 100 random samples is carried out  and the overall performance of the 100 models is  calculated. Finally the one with maximum  performance in terms of classification and  generalization is selected.

The criteria for selecting the best model out of  100 are (in order of importance):    1. The lowest total (training and validation)  error for both users? classes.

2. The lowest validation error for both  users? classes.

3. The most equal representation of both  classes in the validation set.

The selection of best model is determined  mainly by the low generalisation (or validation)  error for the two classes, since the training  misclassifications are equal to zero most of the  times. The third criterion concerns the equal  prediction capability for both classes.

Table 4 shows the average performance of the  100 models for 3 different combinations of  features. Comparing this performance to that of  the 1 st row which is to do with the 1  st   Bootstrapping stage where all features are  included (via components), it is seen that the  contribution of data selection/reduction stage to  performance is extremely important. It can be  noted that the average performance of the data  with the final set of features outperformed  significantly the original representation of the data.

Table 3: Average Performance (100 models) Features Class 0 Class1 Overall  All features  included (118) 47% 46% 46%  Selected features  with extreme values  impact (15)  81% 71% 76%  Selected Features  without extreme  values impact (15)  90% 87% 88%    The last row of table 4 shows the average  performance of the 3 rd  final bootstrapping.  It can  be concluded that there is actually a pattern in  users? behaviour, which can validate and give an  interpretation of the users? cognitive styles and  interest.

3.6. Discussion  As is shown in Table 2, feature 70 related to the  ?Package Service Info Reports? file appears to  have a significant level of sensitivity (or  discrimination value) regarding the users?  classification. The value of this feature depends on  the frequency of queries activities within the file.

This makes sense if we consider that the more  queries the users use the more interest they have  for the software support after purchase.

Apart from this obvious observation, salient  attributes can be considered on features pertinent  to ?Package performance Info? file. That probably  indicates that the interest of decision makers for  the package?s technical performance appears to  have a real information value regarding the users?  final judgment. This is a ?salient effect? which -  since the presentation format of the respective  queries? menu do not have any distinct  characteristics in the prototype interface ? can be  considered as a genuine information effect.

4. Conclusion  The proposed method can be considered as a  hybrid of data reduction and classification  algorithm techniques. The main advantage of the  method is that the users can be modelled using  only the most significant variables which give the  maximum prediction value.

Abnormal behaviour detection techniques can  be based on the selected features with the highest  sensitivity to the decision made. Identification of  features non-compatible with the task could reveal  bias or deviations from normal procedures.

Moreover, misclassification of a new user by the  NN model could indicate a user?s different  behaviour which should be examined and further  analysed. Thus the method can assist in verifying  that the organisational procedures are followed  and compliance is met. Also it could have the form  of an intelligent agent possibly embedded in:  1. Executive Information System (EIS)  2. Auditing software (Computer Assisted  Auditing Tools and Techniques ?  CATTS)  3. Control self assessment tools and  4. Decision aid tools    Contribution to task performance is also  relevant, since decision making bias or  information effects [23] to the task accuracy can  be identified. Problems pertinent to the complexity  of the contextual environment can be resolved by  removing redundant information.

0-7695-2268-8/05/$20.00 (C) 2005 IEEE      The method can have equal success in  analyzing multidimensional accounting  information that includes human and non-human  (economic) components mixed together.

Regardless the accounting/auditing context, the  proposed algorithm can be a significant  contribution to supervised classification, non-  linear regression and data reduction techniques. It  represents a procedure for variable elimination  according to generalisation and non-linear  regression criteria, which is ideal for analyzing  human behaviour due to the complexities of (a)  information load (too many variables) and (b)  nature of human cognition.

Acknowledgements. One of the authors (SF)  gratefully acknowledges financial support from the  State Scholarships Foundation (I.K.Y.) of Greece.

5. References   [1] Webb, G.L., Pazzani, M.J., and D. Billsus, ?Machine  Learning for User Modeling, User Modeling and User-  Adapted Interaction?, Vol. 11, 2001, 19-29.

[2] O?Leary, D.E., ?Intrusion-Detection Systems?,  Journal of Information Systems (Spring), 1992, 63-74  [3] Denning, D.E., "An intrusion-detection Model",  IEEE Trans. Soft. Eng., SE-13, 1987, 222-232.

[4] Belkaoui, A., ?Accounting theory?, 2nd International  Edition, Harcout Brace Jovanovich, Inc, 1985.

[5] Report of the Committee on Behavioural Science  Content of the Accounting Curriculum, The Accounting  Review, supplement, 1971, p.247  [6] Brunswick, E., ?The Conceptual Framework of  Psychology?, Chicago: University of Chicago Press,  1952.

[7] Ko, C-E. and Theodore J. Mock, ?Behavioural  Accounting Research: A Critical Analysis?, Kenneth  Ferris, Century Publishing Co., Chapter 8, 1987, pg.

171-201  [8] Dickson, G.W., Sen, J.A. and N.L. Chervany,  "Research in Management Information Systems: The  Minnesota experiments." Management Science, May  1977, 913-923  [9] Stock, D. and C.J. Watson, ?Human Judgment  Accuracy, Multidimensional Graphics, and Humans  Versus Models?, Journal of Accounting Research 22(1)  1984, 192-206."  [10] Dermer, J.D., "Cognitive Characteristics and the  Perceived Importance of Information". The Accounting  Review July 1973, 511-519  [11] Barnes M., ?Customization of ERP apps requires  development skills?, Michael Barnes. Informationweek.

Manhasset, 722, 1999, pg. 9A.

[12] Best, P., ?SAP R/3 Audit Trail Analysis?, 4th  Annual SAP Asia Pacific Institute of Higher Learning  Forum, SAPHIRE 2000  [13] Chambers, A.D. and J.M. Court, ?Computer  Auditing?, London, Pitman Publishing, 1991.

[14] Inza, I., Larraaga, P., and B. Sierra, ?Feature Subset  Selection by Bayesian Networks: A Comparison with  Genetic and Sequential Algorithms?, International  Journal of Approximate Reasoning, 27(2), 2001, 143-  164.

[15] Lam, K.Y., Hui, L., and S.L. Chung, (),  ?Multivariate Data Analysis Software for Enhancing  System Security?, J. Systems Software, 31, 1995, 267-  275.

[16] Chen, H.M. and M.D. Cooper, "Using Clustering  Techniques to Detect Usage Patterns in a Web-based  information System", J. Am. Soc. Info. Sci. Tech., 52,  2001, 888-904.

[17] Baxt, W.G. and H. White, "Bootstrapping  Confidence Intervals for Clinical Input Variable Effects  in a Network Trained to Identify the Presence of Acute  Myocardial Infarction", Neural Computation, 7, 1995,  624-638.

[18] Efron, B. ?The Jackknife, the Bootstrap and Other  Resampling Plans?, Philadelphia: SIAM, 1982.

[19] Efron, B., "Estimating the Error Rate of a  Prediction Rule: Improvement on Cross-validation", J.

of the American Statistical Association, 78, 1983, 316-  331.

[20] Kaiser, H. F., ?The Varimax Criterion for Analytic  Rotation in Factor Analysis?, Psychometrica, 23, 1958,  187-200.

[21] Hurvich, C.M. and Chih-Ling Tsai, ?Regression  and Time Series Model Selection in Small Samples?,  Biometrika, 76(2), 1989, 297-307  [22] Sarle, W.S., "Stopped Training and Other  Remedies for Overfitting", Proceedings of the 27th  Symposium on the Interface of Computing Science and  Statistics, 1995, 352-360,  [23] Haynes, C.M., S.J. Kachelmeier, ?The Effects of  Accounting Contexts on Accounting Decisions: A  Synthesis of Cognitive and economic Perspectives in  Accounting Experimentation?, Journal of Accounting  Literature, Gainesville, 17, 1998, 97.

