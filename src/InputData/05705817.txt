?

Abstract -Mining of frequent patterns is a basic problem in  data mining applications. The algorithms which are used to  generate the frequent patterns must perform efficiently. The  objective was to propose a new algorithm which generates  maximal frequent patterns in less time. We proposed an  algorithm which was based on Array technique and  combines a vertical tidset representation of the database  with effective pruning mechanisms. It removes all the non-  maximal frequent itemsets to get exact set of MFI directly. It  works efficiently when the number of itemsets and tidsets  are more. The proposed approach has been compared with  GenMax algorithm for mushroom dataset and the results  show the proposed algorithm generates less number of  candidate itemsets to find all MFIs. Hence, the proposed  algorithm performs effectively and generates frequent  patterns faster.



I. INTRODUCTION  The association rule problem is a very important problem  in the data-mining field with numerous practical    applications, including consumer marketbasket analysis,  inferring patterns from web page access logs, and network  intrusion detection. The association rule model and the  support-confidence framework were originally proposed  by Agrawal et al. [1,7,8,9,13,23,24]. Let I be a set of items  (we assume in the remainder of the paper without loss of  generality I = {1,  , N}). We call X C I an itemset, and  we call X a k-itemset if the cardinality of itemset X is k.

Let database T be a multiset of subsets of I, and let  support(X) be the percentage of itemsets Y in T such that  X C Y. Informally, the support of an itemset measures  how often X occurs in the database. If support(X) ?  minSup, we say that X is a frequent itemset, and we  denote the set of all frequent itemsets by FI. If X is  frequent and no superset of X is frequent, we say that X is  a maximally frequent itemset, and we denote the set of all  maximally frequent itemsets by MFI. The process for  finding association rules has two separate phases. In the  first phase, we find the set of frequent itemsets (FI) in the  database T. In the second step, we use the set FI to  generate interesting patterns, and various forms of  interestingness have been proposed. In practice, the first  phase is the most time-consuming. Smaller alternatives to  FI that still contain enough information for the second  phase have been proposed including the set of frequent  closed itemsets FCI [19, 21]. An itemset X is closed if  there does not exist an itemset X such that X'C X and t(X)  = t(X), with t(Y) defined as the set of transactions that  contain itemset Y. It is straightforward to see that the  following relationship holds: MFI C FCI C FI. The set  MFI is orders of magnitude smaller than the set FCI,  which itself is orders of magnitude smaller than the set FI.

Wherever there are very long patterns (patterns containing  many items) are present in the data, it is often impractical  to generate the entire set of frequent itemsets or closed  itemsets . Also, there are applications where the set of  maximal patterns is adequate, such as combinatorial  pattern discovery in biological applications.

There is much research on methods for generating all  frequent itemsets efficiently [ 5, 6,30] or just the set of  maximal frequent itemsets [14,26,27,29]. When the  frequent patterns are long (more than 15 to 20 items), FI    and even FCI become very large and most traditional  methods count too many itemsets to be feasible. Straight  Apriori-based algorithms count all of the 2  k  subsets of each  k-itemset they discover, and thus do not scale for long  itemsets. Other methods use lookaheads to reduce the  number of itemsets to be counted. However, most of these  algorithms use a breadth-first approach, i.e. finding all  k-itemsets before considering (k+1) itemsets. This  approach limits the effectiveness of the lookaheads, since  useful longer frequent patterns have not yet been  discovered. Recently, the merits of a depth-first approach  have been recognized.

The database representation is also an important factor in  the efficiency of generating and counting itemsets.

Generating the itemset Z = (X U Y) refers to creating t(Z)  = t(X) ? t(Y), and counting is the process of determining  support(Z) in T. Most previous algorithms use a horizontal  row layout, with the database organized as a set of rows  and each row representing a transaction. The alternative  vertical column layout associates with each item X a set of  transaction identifiers (tids) for the set t(X). The vertical  representation allows simple and efficient support  counting.

978-1-4244-5967-4/10/$26.00 2010 IEEE  ?

II. RELATED WORKS  The problem of mining frequent itemsets has been a topic  of Intensive research. Since the number of such sets is  huge, it is common and more efficient to restrict the search  to closed item-sets, where a set is closed if all its supersets  have strictly lower frequency in the database. The  collection of frequent closed sets contains the same  information as the overall collection of frequent item-sets,  but is much smaller. There is also a growing interest in  mining structured data, such as graphs, and more generally  multi-relational databases, and the notion of closed sets  has also been imported to this richer setup. Another  variation exist between mining in a single interpretation  (graph), or across multiple interpretations. Finally, some  authors restrict the implication relation used in defining    closures to range-restricted clauses only. In addition to  these differences, the notion of a closed set can be coupled  with a closure operator that takes a set and calculates its  closure and there is more than one way to define such  closures. The literature gives the impression that these  different choices are unimportant and that algorithmic  issues can be studied independently of the semantics. Our  investigation shows that this impression is false and that  semantics do matter. Methods for finding the maximal  elements include All-MFS, which works by iteratively  attempting to extend a working pattern until failure. A  randomized version of the algorithm that uses vertical  bit-vectors was studied, but it does not guarantee every  maximal pattern will be returned.

Max Miner is another algorithm for finding the maximal  elements. It uses efficient pruning techniques to quickly  narrow the search. Max Miner employs a breadth first  traversal of the search space; it reduces database scanning  by employing a look ahead pruning strategy Depth Project  finds long itemsets using a depth first search of a  lexicographic tree of itemsets, and uses a counting method  based on transaction projections along its branches. It  returns a superset of the MFI and would require  post-pruning to eliminate non-maximal patterns. FP  growth uses the novel Frequent Pattern tree (FP-tree)  structure, which is a compressed representation of all the  transactions in the database.

Mafia is one of the recent methods proposed by Burdick,  D., M. Calimlim and J. Gehrke,[29] for mining the MFI.

Mafia uses three pruning strategies to remove  non-maximal sets. The first is the look-ahead pruning first  used in Max Miner. The second is to check if a new set is  subsumed by an existing maximal set. The most important  category of approaches in multi-relational classification is  ILP (Inductive Logic Programming). Besides ILP,  probabilistic approaches are also popular for  multirelational classification and modeling. The most  important one is the probabilistic relational models  (PRM's) which is an extension of Bayesian networks for  handling relational data. PRM's can integrate the  advantages of both logical and probabilistic approaches  for knowledge representation and reasoning. An approach    is proposed to integrate ILP and statistical modeling for  document classification and retrieval.

Given this conceptual framework, we can describe the  most recent approaches to the maximal frequent itemset  problem. As a baseline, Apriori traverses the lattice in a  pure breadth-first manner, discovering all frequent nodes  at level k before moving to level (k+1); Apriori finds  support information by explicitly generating and counting  each node. Max Miner performs a breadth-first traversal of  the search space as well, but also performs look aheads to  prune out branches of the tree. The look aheads involve  superset pruning, using apriori in reverse (all subsets of a  frequent itemset are also frequent). In general, look aheads  work better with a depth-first approach, but Max Miner  uses a breadth-first approach to limit the number of passes  over the database. Depth Project performs a mixed  depth-first traversal of the tree, along with variations of  superset pruning. Instead of a pure depth-first traversal,  Depth Project uses dynamic reordering of children nodes.

With dynamic reordering, the size of the search space can  be greatly reduced by trimming infrequent items out of  each nodes tail. Also proposed in Depth Project is an  improved counting method and a projection mechanism to  reduce the size of the database. The other notable maximal  pattern methods are based on graph-theoretic approaches.

MaxClique and MaxEclat both attempt to divide the subset  lattice into smaller pieces (cliques) and proceed to mine  these in a bottom-up Apriori-fashion with a vertical data  representation. The VIPER algorithm has shown a method  based on a vertical layout can sometimes outperform even  the optimal method using a horizontal layout. Other  vertical mining methods for finding FI are presented by  Holsheimer and Savasere et al. The benefits of using the  vertical tid-list were also explored by Ganti et al. GenMax  is a backtrack search based algorithm which was proposed  by Karam Gouda and Mohammed J. Zaki[32] for mining  maximal frequent itemsets. GenMax uses a number of  optimizations to prune the search space. It uses a novel  technique called progressive focusing to perform  maximality checking, and diffset propagation to perform  fast frequency computation.



III. PROPOSED APPROACH    The proposed approach focuses on Mining Maximal  Frequent Itemset Generation. In this paper, Array based  approach and Effective Pruning Mechanism is used for  generating Maximal frequent patterns.

There are two main ingredients to develop an efficient  MFI algorithm. The first is the set of techniques used to  reduce the size of search space, and the second is the  representation used to perform fast frequency  computations. This paper describes how proposed  algorithm achieves the same.

?  In general the structure of the transactional database may  be in two different ways -Horizontal data format and  Vertical data format. Here, we are using vertical data  format for storing the transactions in the database. In  vertical data format, the data is represented as item-tidset  format, where item is the name of the item and tidset is  the set of transaction identifiers containing the item.

Consider our example database which includes six  different items, I = {A, B, C, D, E, F} and six transactions  T= {1, 2, 3, 4, 5, 6}. The vertical data format of the  database DB is given below.

Table 1 : Vertical Data format of the transactional database DB.

All Frequent items are extracted first. The support is  directly given by the number of transactions in the tidset of  each item. Let us consider the minimum support to be 3.

From the above structure, all items except F are frequent.

The items A, B, C, D and E are frequent items and will be  considered to next level.

In the next level a dynamic array (N) is constructed by  intersecting the tidsets of every two frequent items. The  constructed array (N) shows the association between every  two frequent items. The size of the array will be n(n+1)/2,  where n is the number of frequent items. Value of each  and every cell in the array is initialized to zero. The value  of cell N[i,j] is 1 if number of transaction occurred in the  intersection of tidset of frequent item i and j satisfies the  user specified minimum support. Otherwise the cell value  is zero. Once the array is constructed successfully, all  possible Maximal frequent itemsets(PMFI) are obtained  from the array. The constructed array is given below.

N ABCD    E  D  C  B    Table 2: Dynamic array (N) shows the association between every two  frequent items.

The possible maximal frequent itemsets (PMFI) which are  obtained from this array are considered to the next level.

All the other itemsets are pruned. The number of possible  large itemsets is less than or equal to number of frequent  itemsets. From this array, PMFIs are obtained in two  ways. We can take all columns and first row. (Columns A,  B, C, D and row E) or all rows and first column. (Rows E,  D, C, B and Column A).

One column entry or one row entry is a single PMFI. For  example the itemset (x,y,z) is possible maximal frequent  itemset if and only if there is an entry 1 in both cells  N[x,y] and N[x,z]. For example ADC is a PMFI because  of the values of both cells N [A, D] and N [A, C] is 1.

Once all PMFIs are retrieved from the array, they are  arranged in descending order with respect to their size.

First column entries produce the PMFI that includes the  frequent item A (ADC). Second column entries produce  the PMFI includes the frequent item B (B). Third column  entries produce the PMFI that includes the frequent item C  (CDE). Forth column entries produce the PMFI includes  the frequent item D (D). First row entries produce the  PMFI that includes the frequent item E (EC). All PMFIs  are arranged in descending order with respect to their size.

So the Itemsets in PMFI are ADC, CDE, EC, B, D.

The First itemset ADC has no superset in MFI and it is  frequent. So ADC is a MFI(with support count 3) and it is  added to MFI.

The Second itemset CDE has no superset in MFI and it is a  infrequent item set. so all (n-1)-itemsets (includes C) of  CDE are generated. 2-itemsets of CDE are CD and  CE.(DE is not taken for test. It does not include the item  C) From these itemsets CD is subset of MFI and it is  ignored. CE is frequent and it has no supersets in MFI. So  it is added to MFI. CE is a MFI(with support count 3)  obtained from CDE.

The Third itemset EC is already included in MFI and it is  ignored.

The Forth item B has no superset in MFI and it is a  frequent item and it is added to MFI.

The Fifth item D has a superset in MFI and it is ignored.

From above example, MFIs with support count 3 are  ADC, CE, B.

The process will be continued till testing all possible  maximal frequent itemsets. The pruning can be done while  finding the MFI itself, but not after finding FI completely.

The pseudo code for proposed algorithm is given below in  figure 1.

Item  Tidset  A  T1, T2, T3, T4  B  T1, T4, T5  C  T1, T2, T3, T5, T6  D  T1, T2, T3  E  T2, T4, T5, T6  F  T6, T5  ?      Pseudo code  Find All MFI(PMFIs,min_sup) Function to find  all Maximal Frequent Itemsets  Inputs  (i) PMFIs (Possible Maximal Frequent itemsets)  (ii) min_sup -Minimum support the has been defined  for mining process Interfacing Functions  Output  (i)MFIs  Find All MFI(PMFIs, min_sup)  For each x ? PMFIs if x has  a superset in MFI continue;  else if x is  frequent  MFI=MFI U x;  else Find MFI by obtaining  Permutations(x,min_sup);  For End;  return MFI;    Find MFI by obtaining Permutations (PMFI, min_sup)  Function to find Maximum Frequent Itemsets form K-  itemsets of PMFI  Inputs  (i) PMFI  (ii) min_sup -Minimum support the has been  defined for mining process Interfacing Functions  Figure 1. Pseudo code for ABMFI Algorithm  Output  (i)MFIs  Find MFI by obtaining Permutations (PMFI, min_sup)  n=number of items in PMFI;  k=n-1; // k-itemsets  Freq_item={}; S={}; do  In_Freq=0; //to check infrequent itemsets.

C=generate k-itemsets that includes first item of  PMFI; Foreach x ?C if x has a superset in MFI  S=S U x; continue; else if x is  frequent Freq_item=Freq_item  U x; else  In_Freq=1; For End; If  PMFI==unique(Freq_item U S)  MFI=MFI U Freq_item; return; End  if; K--; while(In_freq!=0 && k!=0);  The proposed algorithm performs better because MFI is  being calculated directly before computing FI completely.

The Pruning mechanism works effectively and counting is  not performed for the subset of MFIs. So, the time taken  to compute MFI is negligible. As we are following vertical  data format, support also need not be calculated separately.

In this case, support is directly given by the number of  transactions in the tidlist of each FI. The vertical  representation has the following major advantages over the  horizontal layout: Firstly, computing the support of  itemsets is simpler and faster with the vertical layout since  it involves only the intersections of tidsets. Secondly, with  the vertical layout, there is an automatic reduction of the  database before each scan in that only those itemsets that  are relevant to the following scan of the mining process  are accessed from disk.

Pruning  The Possible Maximal Frequent itemsets(Maximal    Candidate Itemsets) are directly retrieved from Dynamic  array. All Maximal frequent itemsets are obtained from  only these PMFIs. Other itemsets are pruned  automatically. The pruning can be done while finding the  MFI itself, but not after finding FI completely. The  proposed approach applies superset checking to eliminate  the non maximal frequent itemsets. Once all PMFIs are  generated, each PMFI is checked whether it is a subset of  any maximal pattern. If so the itemset is eliminated  entirely. Counting is not performed for this itemset and  next PMFI is taken for test.



IV. RESULTS  The testing of the proposed algorithm has been carried out on the  real dataset (containing long itemsets) mushroom. We measured,  the number of candidate itemsets taken by the proposed  algorithm to find MFIs and it is compared to Genmax algorithm  for various values of minimum support. The support is varied  from 75 to 95. The proposed algorithm had been compared with  GenMax algorithm and results show the proposed approach  generates less number of candidate itemsets to find all MFIs.

Figure 2 illustrates that, the proposed approach generates  less number of candidate itemsets and produces all MFIs  very quickly than GenMax algorithm. Support is taken as  x axis and the number of candidate itemsets taken to find  all MFI is taken as y axis.

For Mushroom, the improvement is best explained by how  the MFI is computed at each level and found directly  without waiting for FI completely. This leads to a much  greater reduction in the overall search space, since the  reductions is so great at highest levels.

?  Figure 2. Number of Candidate itemsets taken by ABMFI and  GenMax Algorithm from Mushroom dataset.

This approach will be working very efficiently for any  sparse and dense dataset, when the size of maximal  frequent itemsets is close to the number of frequent  itemsets.



V. CONCLUSION  In this paper we have investigated an array based approach  and algorithm (ABMFI) for mining maximal frequent  itemsets. The algorithm is straight forward  basic steps  are finding frequent items from the database, Dynamic    array construction and Pruning infrequent itemset,  obtaining Possible Maximal Frequent itemsets from array  and finding MFIs from PMFIs. Our algorithm had been  compared with GenMax algorithm and obtained that the  proposed algorithm generates less number of candidate  itemsets to find all MFIs. The vertical data format  representation of the database, Dynamic array construction  and directly computing MFIs from PMFIs are the added  advantages of this algorithm.

