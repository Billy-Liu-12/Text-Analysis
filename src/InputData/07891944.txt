2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Abstract?Many data owners are required to release the data in a variety of real world application, since it is of vital importance to discovery valuable information stay behind the data. However, existing re-identification attacks on the AOL and ADULTS datasets have shown that publish such data directly may cause tremendous threads to the individual privacy. Thus, it is urgent to resolve all kinds of re-identification risks by recommending effective de-identification policies to guarantee both privacy and utility of the data.

De-identification policies is one of the models that can be used to achieve such requirements, however, the number of de-identification policies is exponentially large due to the broad domain of quasi-identifier attributes. To better control the trade off between data utility and data privacy, skyline computation can be used to select such policies, but it is yet challenging for efficient skyline processing over large number of policies. In this paper, we propose one parallel algorithm called SKY-FILTER-MR, which is based on MapReduce to overcome this challenge by computing skylines over large scale de-identification policies that is represented by bit-strings. To further improve the performance, a novel approximate skyline computation scheme was proposed to prune unqualified policies using the approximately domination relationship. With approximate skyline, the power of filtering in the policy space generation stage was greatly strengthened to effectively decrease the cost of skyline computation over alternative policies. Extensive experiments over both real life and synthetic datasets demonstrate that our proposed SKY-FILTER-MR algorithm substantially outperforms the baseline approach by up to four times faster in the optimal case, which indicates good scalability over large policy sets.

Index Terms?de-identification policy, anonymization, skyline computation, data privacy.

F  1 INTRODUCTION  IN the age of big data, it is important to exchange andshare data among different parties. For example, all reg- istered hospitals in California of US are required to submit specific demographic data on some patients which have been in good condition [1]. However, publishing those data containing sensitive information could violate individual?s privacy. In order to get sufficient protection while main- tain high data utility, privacy-preserving data publication (PPDP) is becoming an important and interesting research topic [1],[2].

Not all attributes are sensitive, only some of them which are sensitive need to be protected, like the salary, the name of disease in medical records and so on. Usually, the identi- fication attributes such as id, names and phone numbers are removed from the data table prior to release. However, the published records may still contain quasi-identifiers, such as demographic attributes which contain age, race, gender or post code. Even though the quasi-identifier (QI) attributes do not directly reveal individual?s identity, but they may appear together with identification attributes in another published datasets, which may lead to linkage attacks to re-identify private information. Thus, re-identification be- comes one of the most important privacy threats for public data tables that contain individual?s records. Many privacy preservation algorithms that rely on QI attributes general- ization are proposed to solve this challenge. They usually adopt syntactic sanitization approaches to disturb the data,  ? Xiaofeng Ding, Li Wang, Zhiyuan shao and Hai Jin are with the Services Computing Technology and System Lab, Cluster and Grid Computing Lab, the School of Computer Science and Technology, Huazhong Univer- sity of Science and Technology, Wuhan 430074, China.

E-mail: {xfding,lwangcgcl,zyshao,hjin}@hust.edu.cn  and the utility of sanitized data is also measured syntac- tically. To protect personal sensitive information, various laws require that personal data which can be used to link one record in one table to another table containing explicit identifiers (e.g., name) based on QI attributes [3] (e.g., Age, Gender, ZIP), should be de-identified. For instance, to achieve de-identification, the Privacy Rule of the Health Insurance Portability and Accountability Act defines two approaches: Safe Harbor and Expert Determination [4]. In this paper, we focus on the de-identification policy [4], [5], [3], which is one common privacy-preserving approach and an important application of generalization. By using de- identification policies, a continuous balance between pri- vacy protection and data utility can be achieved by choosing the appropriate policies.

Many attempts have been made to obtain a good bal- ance between data privacy and data utility. One represen- tative method is to concern at privacy models, and re- searchers have proposed a series of privacy standards like k- anonymity [6], l-diversity [7], t-closeness [8], ?-disclosure [9] and ?-likeness [10]. Although these models can improve the level of privacy protection, and the re-identification risk can be set small enough with respect to different requirements, but their corresponding policies can only cover a narrow spectrum of utility and risk space compared to the rule- based policies, which enumerate all attributes to obtain more risk and utility values [11]. Another concern is focused on anonymization operations. Among them, generalization [3] and perturbation [12], [13] are two primary methods.

In general, the perturbation makes larger data distortion than the generalization operation, thus for the benefits of higher data utility, we choose the full-subtree generalization to preserve the data privacy. Note that, the work in [3]    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   is closely related to our research, and it designs heuristic algorithm to search de-identification policies to balance the needs of minimizing re-identification risk and information loss. It is a method of applying rule-based policies and introduces a new scheme to compute skyline over a set of policies, which covers a broader range of risk and utility space than previous privacy models (e.g., k-anonymity, l- diversity). However, their work has limitations in several ways. First, their framework requires a lattice which con- tains all the alternative policies to organize with high time cost. Second, their algorithms are approximate approaches which have no guarantee of optimal solution.

In order to overcome these limitations, we propose an approximate skyline scheme, which is a dual-objective opti- mization problem. First, this scheme deals with the policies which cover a broad spectrum of utility and risk. Second, it does not need to index the lattice, and it generates all possible policies by enumeration which is different from the work in [3] by random selection. Finally, our scheme can provide a constant factor approximation by the definition of approximate skyline. We argue that our proposed approxi- mate skyline scheme is completely different compared to the above approximation algorithms (which have no optimal solution), users can choose an approximation precision pa- rameter ? to achieve certain guarantee of optimal solution.

In particular, the de-identification policies are generated according to the independence of QI attributes firstly. This is good for reducing the length of binary string, and it can also reduce the size of alternative policy sets greatly.

Secondly, by sacrificing a given range of accuracy in risk (re- identification risk) and utility (information loss) cost, a large number of unpromising policies can be pruned. Generally speaking, our approximation scheme can formally guaran- tee the generated policies whose risk and utility cost are within a certain range of the optimal solution with factor ?, which can be tuned seamlessly to trade off the near- optimality guarantee for lower risk and higher data utility.

In summary, the contributions of this paper are listed as below:  ? We give the formal definition of recommendation over de-identification policies and denote the prob- lem as RIDP. We propose algorithms using MapRe- duce to speedup the parallel computation efficiency and obtain high scalability.

? Through analyzing the characteristics of data distri- bution, we give the formal definition of independent property, which can be used to generate new policies effectively.

? To reduce the sort overhead of skyline and decrease the number of alternative policy set in Map phase of the first round, a new scheme was introduced for recommendation of de-identification policies.

? We demonstrate the superiority of our methods through extensive experiments, and the results show that our approach can preserve the privacy substan- tially with high data utility and query efficiency.

The rest of this paper is organized as follows. In Section 2, we review related work from four aspects. Section 3 introduces preliminary concepts about de-identification pol- icy, risk and utility cost, approximate skyline, and propose  the definition of de-identification policies recommendation problem. Section 4 describes the independence property and how to generate policies efficiently. We present how to process effectively and efficiently by using approximate skyline model in Section 5. Then, the experimental results are described in Section 6, and Section 7 concludes the paper.

2 RELATED WORK To provide sufficient background knowledge for our work, we discuss research efforts in privacy preserving data publication, risk and utility cost, skyline queries with a special focus on parallel processing, and discovery of de- identification policies.

2.1 Privacy Preserving Data Publishing  PPDP is an important research area, its privacy models can be used in many applications for privacy-preserving data analytics. They have been exhaustively studied in [14], [15], [9], [12], [16], [13]. Among them, k-anonymity [17], [18], [19], [20],[21],[22], l-diversity [7], [8], t-closeness [23],[24] are the most popular privacy models. They choose the domain- specific generalization over QI attributes and leave the sen- sitive attribute unchanged. However, these anonymization- based privacy models are vulnerable for linkage attack or background knowledge attack. Recently, [13] presented an perturbation algorithm based on differential privacy for releasing high-dimensional data, and it has good scala- bility and can obtain high data utility. In work [25], the authors make analysis on the original data table firstly, then after domain partition, they adds appropriate amount of noise to satisfy differential privacy. Although differen- tial privacy has been paid more attention in recent years, data anonymization is still an important privacy preserv- ing method. [10] introduced one robust privacy-preserving model called ?-likeness for microdata anonymization, and [16] considered the non-homogeneous generalization to prevent additional attacks. Instead of setting privacy risk threshold, [3] achieved dual-objective optimization over de- identification policies. There are also privacy-preserving methods for other data types, [26] introduced one privacy- preserving image retrieval scheme in a cloud computing scenario and applied secure kNN algorithm to encrypt the visual features. Keyword is also an important data type needs privacy-preserving, [27] proposed a keyword- based document retrieval scheme over encrypted cloud data, where a special tree-based index is constructed and the secure kNN algorithm is utilized to encrypt the index.

2.2 Risk and Utility Cost  Privacy preservation is only one purpose of anonymization, another important criterion is to maintain the availability of information contained in the published data. Informa- tion measurement is used to evaluate the usefulness of data, which includes data metrics measurement and search metrics measurement. Measuring the data quality in an anonymizated table with respect to the original table is de- noted as data metric measurement. While guiding each step of any search algorithm to identify an anonymous table with    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   minimum information loss is called search metric. Further- more, empirical privacy and empirical utility of anonymized data are proposed in [28]. They reverse the idea of privacy attack by incorporating a new privacy measurement, and define the empirical privacy based on the posterior beliefs of an adversary to draw inferences about sensitive values.

Meanwhile, they present an empirical approach to measure the utility based on query workloads. In [29], they put forward the similarity measurement between original table and anonymous table based on minimizing the information distortion. [30] introduced a general measurement method denoted as ILoss, which is more accurate compared to the data quality loss measurement as proposed in [17].

2.3 Skyline Skyline is an important data analytic operator and many methods have been studied. [31] firstly studied skyline query over large datasets, where block-nested-loop (BNL) and divide-and-conquer strategies are proposed. BNL out- puts all the skyline points which are not dominated by other points by comparison, and the data space is divided into several regions to compute skyline locally, then the global skyline is calculated by combining all local skylines. The Sort Filter Skyline (SFS) [32] is introduced by adding one pre-sorting operation to BNL, and LESS [33] has achieved more efficiency by optimization over SFS. Furthermore, SaLSa [34] is proposed by removing the scanning operation over the complete set of sorted points from SFS and LESS.

As far as we are concerned, among various algorithms proposed in the literature for skyline processing, BBS [35] is one of the most preferred algorithms due to two significant properties, namely returning the skyline result progres- sively and I/O optimality. With the rapid increasing of data volume, parallel skyline computation algorithms have also attracted tremendous research interests [36], and a number of research efforts for computing skyline in MapReduce model have been proposed [37]. For example, Tao et al [38] proposed a minimal MapReduce algorithm to deal with 2D-skyline based on TeraSort. The main idea in their work is to determine an appropriate sampling parameter to divide the whole dataset effectively and fairly, which can ensure that each participating node has balanced storage and computation workload.

2.4 Discovery of De-identification Policies The optimal balance between data privacy and data utility have been paid more and more attention. To meet the multi- level needs of users for privacy and data utility, the dis- covery of de-identification policies is of paramount impor- tance. Fortunately, some approximate algorithms have been proposed [4], [3], [11] to solve the problem. In particular, [4] is a kind of binary search algorithm based on hamming distance, which can quickly recommend good policies, but their accuracy of recommendation is not high and the range of recommended policies is quite small. [3] proposed the heuristic search algorithms based on probability, and their range covers the whole RU space. Since each time a certain amount of policies are handled within one path, thus their recommendation error is closely related to the initial skyline set and the path selected. Based on the algorithm proposed  in [3], the authors in [11] tried to improve the initialization and path selection. For initialization, the frontier is initial- ized by selecting a random path from the most general one to the most specific policy in the lattice, and they sample a full-domain generalization space to compose the initial frontier. For path selection, they iteratively select the sub- lattice chain to improve the frontier. Note that, the sub- lattice chain in [3] is a subgraph in the lattice containing all policies between a top and a bottom policy. While the sub-lattice chain in [11] is a sequence between the most generalized and the most specific policies in the lattice, by using the bottom policy in the current iteration as the top policy of the sub-lattice in the next iteration, it randomly restarts from the most generalized policy when the chain reaches the most specific ones in the lattice. However, the algorithm in [11] still converges slowly.

3 PROBLEM DEFINITION We first present some preliminaries about the de- identification policy, the risk and utility cost, and the skyline frontier in this section. Then, we give the formalization of recommendation on the de-identification policies and propose two schemes for the problem. Table 1 summarizes the mainly used notations.

TABLE 1: Mainly used notations  Notation Description D a data table Qi the ith attribute of QI ri the size of domain for Qi l the length of bit-string for a policy S the universal policy set |G| the size of alternative policy set G F the skyline frontier t the number of machines used  3.1 De-identification Policy In this paper, we focus on data table D whose explicit identifier attributes have already been suppressed and the remaining attributes constitute the QI attributes. Each tuple corresponds to an equivalent class (EC) which is the set of records sharing the same QI . In order to de-identify the data record, the QI values of each tuple have two choices: i) remain the same or ii) be recoded to the generalization state.

Meanwhile, we choose the full-subtree generalization model [19], which means all QI values are in an ordered domain, and they are required to map into a list of non-overlapping intervals. Note that, one mapping function corresponds to a domain partition for one QI attribute, and the set of domain partitions for all QI attributes constitute one de- identification policy.

Definition 1. (De-identification Policy) Let Q =  {Q1, Q2, . . . , Qn} be a set of QI attributes, and pi is the partition on the ordered domain of Qi. We call the set {p1, p2, . . . , pn} is a de-identification policy, where pi = {I1, I2, . . . , Iri?1}, and Ij implies that the jth value in domain of Qi is separated from the (j + 1)th value.

As defined above, policy is represented as bit-string. Let Q = {Q1, Q2, . . . , Qn}, and Qi has ri values in its domain.

2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   Age = { 42,43,44 } Gender={Male,Female} Race={White}  42 43,44 Male Female White  Fig. 1: An example of a de-identification policy defined over the QI attributes, {Age, Gender, Race}.

The size of bit-string corresponds to the QI is l ( l = r1?1+ . . .+rn?1). Then, we have 2l policies in total to search. The 2l policies constitute a universal set S. In our work, a bit of 0 stands for the complete generalization where each value is mapped to the whole domain, while a bit of 1 implies a partition of the domain for a QI attribute.

Example 1. As shown in Fig. 1, Q = {Age,Gender,Race} and their domains are {42, 43, 44}, {Male, Female} and {White}, respectively. Age is partitioned to [42] and [43, 44]. Gender and Race are partitioned to [Male], [Female] and [White], respectively.

These partitions constitute a de-identification policy which can be represented as [1,0,1].

3.2 Risk and Utility Cost  A de-identification policy stands for the set of domain partitions for each QI attribute. Risk cost stands for the re- identification risk, and utility cost stands for the information loss. If the domain values of QI attributes are provided more specific, the risk cost is becoming larger and utility cost is getting smaller. That is, the smaller is the information loss, the larger is the re-identification risk. Generally speaking, our goal is to minimize the risk and utility cost.

Risk Cost. The risk cost of a policy stands for the re- identification risk of the data table which is generalized by the policy. Given a data table D, an original tuple distribution P , the formal definition of the risk cost R for generalized data table with tuple distribution P  ? is:  R =  ? e??P ?  |e? |  maxRisk (1)  maxRisk = ? e?P   |e| (2)  where, |e? | is the number of tuples in equivalence class e? , and all e  ? constitute the tuple distribution P  ? .

Utility Cost. The utility cost of a policy stands for the information loss of the data table which is generalized by the policy. And it is measured by the KL-divergence by the generalized data table with respect to its original table.

Given a data table D, an original tuple distribution P , the formal definition of utility cost U for generalized data table with tuple distribution P  ? is:  U =  ? e?P |e| ln  |e| |e?|  N (3)  where, N is the number of tuples for the entire table, and |e?| is the average number of tuples of the new EC which is generalized from e in distribution P  ? . For example, sup-  pose we have the following distribution: Age={17, 18, 19}  and the number of tuples for each Age is {2, 4, 2}. Af- ter the distribution is generalized to the new distribution: Age={[17, 18], 19} and the number of tuples for each Age becomes {[3, 3], 2}, where 3 is the average number of tuples of Age is 17 or 18 in the new distribution, while for Age=19 the number of tuples is 2.

3.3 Skyline Frontier  Strictly Dominated. A policy ? dominates policy ?, denoted by ? ? ?, if ? has smaller or equivalent value than ? in risk and utility cost. We define policy ? strictly dominates ?, denoted by ? ? ?, if ? ? ? and there exists at least one cost (risk or utility) of ? is smaller than the cost of ?.

Skyline Frontier. A policy p with risk cost and utility cost is said to be in the skyline set, if there is no other policies from the alternative policy set G strictly dominates p. That is to say, the skyline set for G contains no equal-cost policies for each skyline policy. The skyline frontier F is constituted of those skyline policies that is strictly not dominated by any other policies.

3.4 Approximate Skyline  ?-Approximately Dominated. Policy ? approximately dom- inates ? with precision ?, denoted by ? ?? ?, if the cost of ? is larger at most by factor ? in risk and utility, i.e.

Risk(?)? ??Risk(?), Utility(?)? ??Utility(?).

?-Approximate Skyline Frontier. An ?-approximate sky- line set for S contains those policies p such that, for ev- ery policy p? in the skyline frontier, the policy p satisfies p ?? p?. Note that, an ?-approximate skyline frontier also contains the risk and utility cost of all policies in an ?- approximate skyline set.

3.5 Problem Definition  We concentrate on the recommendation problem on the de- identification policies. In fact, this can be considered as a 2D-skyline problem over de-identification policies. Based on the domination relationship, our goal is to find those policies which are the skyline frontier from the universal policy set S. Now, we give the formal definition about the recommendation of de-identification policies.

Definition 2. (Recommendation of De-identification  Policies) (RDIP) Give a data table D, let Q = {Q1, Q2, . . . , Qn} be a set of QI attributes, r = {r1, r2, . . . , rn} denotes the domain of Qi has ri values.

If we consider all possible partitions, the universal policy set S have 2l policies. Here, l = (r1?1+r2?1+. . .+rn? 1) is the length of policy bit-string. Our RDIP problem is to find the skyline frontier from set S.

In Fig. 2, we show the general framework for recom- mending de-identification policies. The process is initiated by the following information from the data owner: 1) a dataset to be de-identified, 2) aggregate statistics for the dataset. The framework is composed of two modules: risk and utility evaluator (policy generation), and skyline com- putation. Risk and utility evaluator computes the risk and utility cost of policies from the universal policy set to derive a policy space {S, (R,U)}. Then the next step selects those    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   Policy  Generator  Set of Alternative Policy  Dataset  Utility  Evaluator  Risk  Evaluator  Skyline  Population  Statistics  Skyline Policy Set  Fig. 2: A general framework of recommending de- identification policies.

un-dominated policies by skyline computation over the generated space. The details of each module are described in the following sections.

3.6 Two Scheme for RDIP Definition 3. (RDIP Exact Scheme ) An exact scheme for  RDIP can only guarantee to achieve an exact skyline frontier for any RDIP problem.

Definition 4. (RDIP Approximation Scheme ) An approx- imation scheme for RDIP guarantees to achieve an ?- approximate skyline frontier, with tunable user-specified precision parameter ? for any RDIP problem.

Example 2. As shown in Fig. 4, Q = {Age,Gender,Race} and their domains are {42, 43, 44}, {Male, Female} and {White}, respectively. We can get l = 3 and |S| = 8, then we compute their risk and utility cost to achieve the policy space {S, (R,U)} as shown in Fig. 4(c). Then, we have two choices: exact scheme and approximation scheme for the RDIP. Fig. 4 illustrates the exact scheme (? = 1) and final skyline set is F = {000, 100, 010, 001, 101, 011, 111}. With the assumption that we set the precision parameter ? = 1.5, based on approximation scheme, a filter is added in the Map phase of the second round and the results of alternative policy set G becomes {000, 001, 011, 111}, and the final skyline set is F = {000, 001, 011, 111}. As we can see that, skyline set for approximation scheme has lower accuracy than that for exact scheme, while the alternative policy set G is smaller and takes less time for skyline computation over G.

4 POLICY GENERATION This is the first module. The risk and utility evaluator module computes the risk and utility cost for policies from the universal set S to derive the policy space {S, (R,U)}.

Since the number of de-identification policies is increased by exponential order with the growth of l, we try to reduce the size of alternative policy set G by independent property when l is very large. Typically, the distribution of tuples for each attribute of QI are independent [3] and they do not affect each other.

Definition 5. (Independent Property) Let Q =  {Q1, Q2, . . . , Qn} be a set of QI attributes, and  Xi is a variable that represents the value of Qi.

We say every attribute of QI are independent, if P{Xi} = P{Xi|X1, . . . , Xi?1, Xi+1, . . . , Xn}, i = 1, . . . , n.

Note that, the independent property exists approxi- mately in Adult (Age=[17-56]). Where P1 = P (Age), P2 = P (Age|Race = White), and P3 = P (Age|Race = White,Gender = Famle). First, P1, P2, and P3 are computed based on Adult dataset. Second, KL(P1, P2), KL(P1, P3), and KL(P2, P3) are calculated as shown in Ta- ble 2, where KL(P1, P2) =  ? P1 ln  P1 P2  is the KL-divergence between P1 and P2. We can see that these three values are much small, which indicates the distribution among P1, P2, and P3, are closely related with each other.

TABLE 2: The independent property for Adult  Description Value KL(P1, P2) 0.0004 KL(P1, P3) 0.0232 KL(P2, P3) 0.0224  By Definition 5, we can get:  R(S[Q1, Q2]) =  ? P  ? (X1, X2)?  P (X1, X2)  =  ? P  ? (X1)P  ? (X2)?  P (X1)P (X2)  =  ? P  ? (X1)?  P (X1)  ? P  ? (X2)?  P (X2)  = R(S[Q1]) ?R(S[Q2]) (4)  Note that, S[Q1, Q2] stands for the policies which are gen- erated with only considering the partitions of Q1, Q2. And the above equation is only equivalent expression.

U(S[Q1, Q2]) = ?  P (X1, X2) ln P (X1, X2)  P ?(X1, X2)  = ?  P (X1, X2)(ln P (X1)  P ?(X1) + ln  P (X2)  P ?(X2) )  = ?  P (X1) ln P (X1)  P ?(X1)  + ?  P (X2) ln P (X2)  P ?(X2)  = U(S[Q1]) + U(S[Q2]) (5)  Similarly,  R(S[Q1, . . . , Qn]) =  R(S[Q1]) ? . . . ?R(S[Qn]) (6)  U(S[Q1, . . . , Qn]) =  U(S[Q1]) + . . .+ U(S[Qn]) (7)  Lemma 1. For data table D, let Q = {Q1, Q2, . . . , Qn} be a set of QI attributes, and r = {r1, r2, . . . , rn} denotes the domain of Qi has ri values. {S[Q1, Q2, . . . , Qn], (R,U)} is a policy space and S[Q1, Q2, . . . , Qn] is the set of all policies whose length is l. Since all possible partitions are considered, then we have:    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   sky({S[Q1, Q2, . . . , Qn], (R,U)}) = sky(sky({S[Q1], (R,U)})  ? . . .

? sky({S[Qn], (R,U)})).

Where, (1) sky({S[Qi], (R,U)}) is a function return the skyline set over policy space {S[Qi], (R,U)} based on minimizing R and U, and S[Qi] is the set of all policies whose length is ri?1, with values of other attributes are mapping to the whole domain, respectively.

(2)  ? is a symbol indicates that the policy spaces are  reproduced, and the length of new policy is l, l = (r1 ? 1 + r2 ? 1 + . . .+ rn ? 1).

Proof: Following are the notations used in our proof: Fi = sky({S[Qi], (R,U)}), i = 1, . . . , n is the skyline computation over the policies which are gener- ated by only considering partitions of attribute Qi and other attributes are mapped to the whole domain. F i  = sky({S[Q1, . . . , Qi], (R,U)}), i = 1, . . . , n, is the sky- line over the policies which are generated by consider- ing partitions of attribute Q1, . . . , Qi and other attributes Qi+1, . . . , Qn are mapped to the whole domain.

Here our proof begins. First, when n=2, we must prove:  F 2 ? F1 ?  F2, (8)  Second, when n=n-1, with an assumption that the Lemma 1 holds, we must prove:  Fn ? Fn?1 ?  Fn, (9)  Finally, we can prove Fn ? F1 ?  . . .

?  Fn by applying the mathematical induction, then clearly our conclusion holds: Fn = sky(F1  ? . . .

? Fn).

Next, we give the proof of (8) and (9). For (8), First, the definition of  ? guarantees that F1  ? F2 is the set of  answering over the universal policy set S. That is, the F 2  and F1 ?  F2 is in the same space S[Q1, Q2]. Second, for any policy p that is not in F1  ? F2 (p is in the complement  set of F1 ?  F2), and suppose p is composed of one policy ?1(R1, U1) from S[Q1] and another policy ?2(R2, U2) from S[Q2]. Then we have two cases: a) ?1 is not in F1 and ?2 is not in F2, b) ?1 is not in F1 and ?2 is in F2. For the first case, there must exist one policy ?1 ? F1, such that ?1(R  ?  1, U ?  1) ? ?1(R1, U1), and another policy ?2 ? F2, such that ?2(R  ?  2, U ?  2) ? ?2(R2, U2), then we have the following inequalities:  R ?  1 ?R ?  2 < R1 ?R2, U ?  1 + U ?  2 < U1 + U2, We can get ?1  ? ?2 ? ?1  ? ?2 by applying Equations  (4) and (5). Note that ?1 ?  ?2 ? S[Q1, Q2], then policy p = ?1  ? ?2 is not in F 2, and thus (8) holds. For the second  case, the policy ?1(R ?  1, U ?  1)? ?1(R1, U1), R ?  1 ?R ?  2 < R1 ?R ?  2, U  ?  1 + U ?  2 < U1 + U ?  2, that is ?1 ?  ?2 ? ?1 ?  ?2, similarly, policy p is not in F 2, thus (8) holds. To summarise, F 2 ? F1  ? F2.

For (9), by the above deduction, for any policy p that is not in Fn?1  ? Fn, it must not in Fn by applying Equations  (6) and (7), then, we have Fn ? Fn?1 ?  Fn.

By Lemma 1, we devise an effective approach to solve the policy generation problem for large l. The idea is that 1) counting up the tuples of every attribute respectively; 2) generating policies for each attribute, and calculating their risk and utility cost; 3) making skyline computation over  alternative policy set for every attribute to get a new policy space; 4) synthesizing new policies with length l = (r1?1+ r2 ? 1 + . . . + rn ? 1) by using the policy space generated above, and calculate their risk and utility cost for skyline computation.

Table 3 illustrates the benefits from this way based on independent property. The expected skyline cardinal- ity of generated points in d dimensions is around m = O((lnn)d?1) according to the analysis of [39]. |G1| ? |G2|, when ri > 2, i = 1, 2, 3, . . . , n. Here G1 is the alternative policy set for our approach and G2 is the alternative policy set for traditional approach.

TABLE 3: Two ways of policy generation  Attribute Q1 . . . Qi . . . Qn  Domain r1 . . . ri . . . rn Policy 2r1?1 . . . 2ri?1 . . . 2rn?1 |F | O((r1 ?  1) ln 2) . . . O((ri ?  1) ln 2) . . . O((rn ?  1) ln 2)  |G1| 2r1?1+. . .+2rn?1+O((r1?1) ln 2)+. . .+O((rn?1) ln 2) |G2| 2r1?1 ? . . . ? 2rn?1  5 PARALLEL ALGORITHMS This is the second module. Intuitively, we can deal with the problem in two steps. First, the risk and utility cost of policies from the universal policy set S is computed to obtain the policy space {S, (R,U)}. Second, the skyline over the policy space is calculated to get the policy skyline set, and the partition on the QI attributes as well as risk and utility cost are returned. Obviously, the first module usually generate a huge number of policies as the growth of bit- string length. We know that the skyline calculation has to do a large number of repeated comparisons, thus it is quite time consuming. So it is important to choose some good algorithms for skyline computation.

5.1 SKY-MIN-MR for Exact Scheme  It is worth notice that RDIP problem is a typical 2D-skyline problem compared to the traditional skyline computation.

According to the dimensionality property, Tao et al [38] pro- posed the minimal MapReduce algorithm, which contains a presort-based skyline algorithm that can achieve balanced space for data storage and bounded net-traffic, constant round for termination and optimal computation cost with appropriate sampling parameter setting ? = t|G| ln (|G|t). To the best of our knowledge, this is one of the best algorithms that can deal with 2D-skyline computation problem over large datasets. So we propose our baseline parallel algo- rithm called SKY-MIN-MR by using this MapReduce based framework. Firstly, we enumerate all the policies from S to generate the policy space. Secondly, by adding the risk and utility calculation over policies in the map-shuffle phase, we do 2D-skyline computation by the minimal MapReduce algorithm. We also provide experimental evaluation and formal analysis for RDIP. In particular, the parallel algorithm SKY-MIN-MR consists of the following four phases, and the pseudo code of SKY-MIN-MR is shown in Algorithm 1.

2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   Algorithm 1 SKY-MIN-MR({S, (R,U)},?) Input: {S, (R,U)}: the policy space, ?: the sampling parameter.

Output: F : the policy skyline frontier.

1: sample = Sampling({S, (R,U)},?); 2: sky-patition = SKY-PATITION(sample,t); 3: Broadcast sky-partition; 4: Local-ST = L-SORT-MR({S, (R,U)},sky-partition); 5: HashMap = HASHMAP-R.setup(Local-ST); 6: Broadcast HashMap; 7: F = G-SCREEN-R(Local-ST, HashMap);  8: Function G-SCREEN-MR(Local-ST, HashMap); 9: min u lowerKey = FindHashMap(key);  10: for each policy in list do 11: if policy.U < min u Key lowerR and policy.U <  min u lowerKey then 12: policy ? F ; 13: if policy.U < min u Key lowerR then 14: min u Key lowerR = policy.U; 15: return F ;  Algorithm 2 SKY-F-MR({S, (R,U)}, ?, ?) Input: {S, (R,U)}: the policy space, ?: the sampling parameter,  ?: the precision.

Output: F : the policy skyline frontier.

1: {G, (R,U)} = FilterPolicy-M({S, (R,U)},?); 2: F = SKY-MIN-MR({G, (R,U)}, ?)  3: Function {G, (R,U)} = FilterPolicy-M({S, (R,U)},?); 4: map(key = R,value = string);//string = R + U + policy 5: risk = key, utility = string.U; 6: flag = false; // policy is not in approximately dominated  area 7: for each policy in G do 8: a = risk*? - policy.R, b = utility*? - policy.U; 9: if (a*b)? 0 and (a+b)>0 then  10: // a ? 0, b? 0, a+b ?=0 11: flag = true;// policy is in the approximately domi-  nated area 12: break; 13: if flag == false then 14: policy ? G; 15: output(key,value); 16: return {G, (R,U)};  ? Sky-partition phase: To achieve balanced work load for all participating nodes, a new function Sky- partition which decides the partition strategy is pro- posed. We build sky-partition with t-1 samples from the set of ordered samples that is received by all nodes for further speed up, and these samples are chosen as the break points.

? Local sort phase: We partition the policies set S based on the regions divided by the sky-partition, and sort them locally in their region independently by using MapReduce, this phase was called L-SORT-MR.

? HashMap building phase: In this phase, the corre- sponding relation table HashMap of the minimum risk and utility cost about each node is created.

? Global screen phase: In the last phase, we judge if the policy belongs to the skyline set by using HashMap in MapReduce, which was called G-SCREEN-MR.

Algorithm 3 SKY-FILTER-MR({S, (R,U)}, ?, ?, h) Input: {S, (R,U)}: the policy space, ?: the sampling parameter,  ?: the precision, h: the depth of filter.

Output: F : the policy skyline frontier.

1: {G, (R,U)} = FilterPolicy-M({S, (R,U)}, ?, h); 2: F = SKY-MIN-MR({G, (R,U)}, ?)  3: Function {G, (R,U)} = FilterPolicy-M({S, (R,U)}, ?, h); 4: map(key = R,value = string);//string = R + U + policy 5: risk = key, utility = string.U; 6: flag = false;// policy is not in the approximately dominated  area 7: for each policy in G by inverse sequence do 8: // reverse traversal 9: a = risk*? - policy.R, b = utility*? - policy.U;  10: depth = 0;// the depth of reverse traversal 11: if (a*b)? 0 and (a+b)>0 then 12: // a ? 0, b? 0, a+b ?=0 13: depth = depth + 1; 14: flag = true;//policy is in the approximately dominated  area 15: break; 16: if depth > h then 17: break; 18: if flag == false then 19: policy ? G; 20: output(key,value); 21: return {G, (R,U)};  Although we can output the accurate results by calculating all the policies from the universal set S, it is clear that the computation cost is exponentially large with the growth of l. We can guarantee the time cost for each machine is O(l ? 2l/t) based on the analysis of [38].

5.2 SKY-F-MR for Approximation Scheme  We get some observations on the experiments of Algorithm 1: 1) Although the policy space {S, (R,U)} is large (2l), the size of its skyline set is small which is about O(l ln 2) [39].

This indicates that many policies from S are dominated by other policies. 2) The risk and utility cost for many policies are closed to each other by just a narrow margin. To make full use of the characteristics of policy distribution, we can filter data based on approximately domination. Obviously, the filtering power for approximately domination is larger than that for exact domination. Next, we propose an ap- proximate skyline algorithm called SKY-F-MR for RDIP, and it was composed of five phases by adding the following filtering phase on the basis of SKY-MIN-MR. The pseudo code of SKY-F-MR is shown in Algorithm 2.

? Filtering phase: We insert policies into a new pol- icy space {G, (R,U)}, if their risk and utility cost are neither in the dominated nor the approximately dominated area.

Fig.3 illustrates this statement: the SKY-MIN-MR inserts all the policies of {S, (R,U)} into {G, (R,U)}, if their risk and utility costs do not fall into the dominated area. While, the SKY-F-MR only inserts those policies if their risk and utility costs do neither fall into the dominated region nor into the approximately dominated area. New policies of {S, (R,U)} are still compared with all policies that are in    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   Policy  Approximately  Dominated Area  Dominated Area  Risk cost  Utilitycost     Fig. 3: Dominated versus approximatedly dominated area (with ? =1.5) in RU space.

the common dominating area. However, if no other policy approximately dominates the new one, it will be only in- serted into {G, (R,U)}, which means that the SKY-F-MR tends to insert less policies than the SKY-MIN-MR. So the number of G is smaller and the time for skyline query over {G, (R,U)} is less according to the analysis in [38].

5.3 SKY-FILTER-MR for Approximation Scheme In order to speed up the filtering, two improvements are included in the stage of filtering in SKY-F-MR. We call the new algorithm as SKY-FILTER-MR. Firstly, a reverse traversal output set G is made since the policies are often dominated by the one related with it in non-dominated region. Secondly, the traversal depth h can be tuned to prevent the large overload of filtering. In fact, the bigger is the depth of traversal, the smaller is the average hit ratio of being approximately dominated. Usually, the most effective h is varying with different {S, (R,U)} and we can test the effectiveness of h to achieve near-optimal filtering efficiency.

The algorithm SKY-FILTER-MR consists of five phases by improving the filtering phase in SKY-F-MR. The pseudo code of SKY-FILTER-MR is shown in Algorithm 3.

? Filtering phase: We insert a policy into the policy space {G, (R,U)}, if the policy is not in the cur- rent subset of policy space {G, (R,U)} (the approxi- mately dominated area). Note that, this operation is carried out in reverse order.

Fig. 4 shows an example of data flow in SKY-FILTER-MR framework with ? = 1. It consists of policy generation and algorithm execution. Consider table D in Fig. 4(a), eight policies are generated as shown in Fig. 4(b). These policies are split into smaller subsets, and each map task handles one split on the node by computing their risk and utility cost.

The results are denoted as {S, (R,U)} in Fig. 4(c). To avoid too much skyline computation, we add the filter in map phase of the second round, which is denoted as FilterPolicy- M. The detailed description was given from line 3 to line 21 in Algorithm 3. Next, we get {G, (R,U)} as shown in Fig.

4(d) with approximate skyline. The sampling parameter ? equals to 0.75 when the reducer task is set to 2. Suppose one sample is {001; 010; 111}, then it becomes {010; 001; 111} after sorting, and its break point 001 will be recorded in partition file. In Shuffle stage of the third round, the policies are partitioned into two blocks {000; 100; 010} and {001; 101; 011; 111} based on break point 001. In Reduce stage, the key for each tuple is set to the minimum risk cost of policies in each block. That is, the key for 000, 100 and 010 is 0.021; while the key for 001, 101, 011 and 111 is 0.111. The outputs are shown in Fig. 4(f). In the fourth round, the Map  stage is taken in default manner. While in the Reduce stage, a table containing the key and the minimum utility cost for every block is created, that is {0.021; 0.1213} for the first block and {0.111; 0} for the second block, and we denote this table as HashMap. Finally, all the tuples are checked as shown in Fig. 4(h), we use min u lowerKey to denote the minimum utility cost of those tuples whose key is lower than the current block, and min u Key lowerR to denote the minimum utility cost of those tuples whose risk is lower than the current tuple, and we take those policies whose utility is smaller than both of them as skyline results, Fig.

4(g) shows the final skyline set.

The following theorem shows that the SKY-FILTER-MR guarantees to generate near-optimal policies.

Lemma 2. The SKY-FILTER-MR algorithm with precision ? generates an ?-approximate skyline frontier.

Proof: Let F ? and F denote the skyline frontier and the ?-approximate skyline frontier respectively.

First, the strictly dominated relationship has transitivity property. That is, ? ? ? and ? ? ?, ? ? ? is obtained.

However, the approximately domination relationship has no such property.

Second, the SKY-FILTER-MR algorithm consists of two steps. The first step is FilterPolicy-M and each node filters the policies by approximately dominated relationship, and each policy has only one chance to be filtered. Although the approximately dominated relationship cannot be transmit- ted, we make an approximately skyline over policies only once and no precision error is accumulated. The second step is SKY-MIN-MR and we make an exact skyline over policies with no transmission error. Thus, when the precision is ?, the SKY-FILTER-MR algorithm generates an ?-approximate skyline frontier.

Finally, we give the detailed proof. Each policy p? in F ?  has two states in our algorithm. In the first case, p? is in F and p? ?? p?, thus Lemma 2 holds. In the second case, p? is not in F , if p? is dominated or approximately dominated by p in F , then p ?? p? is obtained, thus Lemma 2 holds.

Next, we discuss the condition that p is not in F . 1) If p?  is dominated by p which is not in F , there is a policy p1 dominates or approximately dominates p. That is p ? p?, p1 ?? p or p1 ? p, we can get p1 ?? p?, clear Lemma 2 holds. 2) If p? is approximately dominated by p which is not in F (the first step), there must be one policy p1 dominates p, that is we have p ?? p?, p1 ? p, which gets p1 ?? p?, thus Lemma 2 holds.

6 EXPERIMENTS In this section, we evaluate the performance of the proposed algorithms on an in-house cluster with one master and 9 slave nodes, each of which has two Inter Xeon(R) E5- 2670 2.60GHZ processors with 8 cores, 128GB memory, and installed 64-bit Linux operating system. We implement all algorithms on Hadoop (version 1.2.1), and set the block size of distributed file system to 64MB.

Dataset. In the experiments, we use the Adult dataset from the UCI Machine Learning Repository [3] and the 2009 Census microdata extracted from IPUMS USA [40]. For    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   R ed u ce  S o rt b y k ey  M ap         R ed u ce  Sky-partition HashMap  Skyline F  (g)  42|Male|White| 465  42|Female|White| 168  43|Male|White| 468  43|Female|White| 163  44|Male|White| 444  44|Female|White| 150          M ap  0.021  0.111  0.098  0.514  0.095  0.490  0.170   0.1218 000  0.0004 001  0.1213 010  0.0000 011  0.1216 100  0.0003 101  0.1213 110  0 111  M ap  policiesQI Number of tuples R U policies key value key value  M ap  R U policies key value  0.021  0.021  0.021  0.111  0.111  0.111  0.111  0.021 0.1218 000  0.095 0.1216 100  0.098 0.1213 010  0.111 0.0004 001  0.490 0.0003 101  0.514 0.0000 011  1.000 0.0000 111  Min_R R U policies key value  (a) (b) (c) (d)  (e) (f)  policies key R U Min_u_lowerKey Min_u_Key_lowerR skyline  0.021 0.021 0.1218 + + Y 0.021 0.095 0.1216 + 0.1218 Y 0.021 0.098 0.1213 + 0.1216 Y 0.111 0.111 0.0004 0.1213 + Y 0.111 0.490 0.0003 0.1213 0.0004 Y 0.111 0.514 0.0000 0.1213 0.0003 Y 0.111 1 0 0.1213 0.0000 Y  (h)  0.021  0.095  0.098  0.111  0.490  0.514   0.1218 000  0.1216 100  0.1213 010  0.0004 001  0.0003 101  0.0000 011  0 111  0.021  0.111  0.098  0.514  0.095  0.490   0.1218 000  0.0004 001  0.1213 010  0.0000 011  0.1216 100  0.0003 101  0 111  U policies key value R  Fig. 4: An example of data flow in SKY-FILTER-MR framework with ? = 1  Adult, this dataset consists of 32561 tuples without missing values and we retain four fields {Age, Gender, Race, Occu- pation}. Specifically, we use the demographics {Age, Gen- der, Race} as the QI attributes and the field {Occupation} as sensitive attribute. In order to have comparison with the ideal area which is the dominated area of k-anonymity, l-diversity and t-closeness, we append one additional at- tribute, the 5-digit ZIP codes which is generated randomly based on uniform distribution for Tennessee?s, to the Adult dataset. In this synthetic dataset, {Age, Gender, Race, Zip} are regarded as the QI attriutes. For Census, this dataset consists of 100,000 tuples and four fields {Age, Gender, Race, Relation} are retained. Thus, the demographics {Age, Gender, Race} are regarded as the QI attributes and the field {Relation} is regarded as the sensitive attribute. Similarly, in order to make comparison with common privacy models, a synthetic dataset based on Census is generated by adding ZIP code and {Age, Gender, Race, Zip} are used as the QI attributes. We set the depth of traversal h = 200 for real datasets and h = 100 in synthetic datasets.

Efficiency. Here we present the average running time  20 21 22 23 24 25  0.5   1.5   2.5  x 10   Length of a policy  R un  ni ng  ti m  e( m  s)  SKY?MIN?MR SKY?FILTER?MR( ? =1) SKY?F?MR  (a) SKY-MIN-MR and SKY-F-MR vs SKY-FILTER-MR  20 21 22 23 24 25  4.5   5.5   6.5  x 10   Length of a policy  R un  ni ng  ti m  e( m  s)  SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001) SKY?FILTER?MR( ? =1.01)  (b) SKY-FILTER-MR vs.?  Fig. 5: Running time for different l in AD  of the SKY-MIN-MR (the baseline algorithm), SKY-F-MR and SKY-FILTER-MR for different length of policies, and the size (|G|) of alternative policy set G of the SKY-MIN- MR and SKY-FILTER-MR algorithms were also reported with varying l. For Adult dataset, we set l from 20 to 25.

Different l indicates that the domain of attribute Age is different. The domain for Race and Gender are {White,    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   22 23 24 25 26 27        x 10   Length of a policy  R un  ni ng  ti m  e( m  s)  SKY?MIN?MR SKY?FILTER?MR( ? =1) SKY?F?MR  (a) SKY-MIN-MR and SKY-F-MR vs SKY-FILTER-MR  22 23 24 25 26 27     x 10   Length of a policy  R un  ni ng  ti m  e( m  s)  SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001) SKY?FILTER?MR( ? =1.01)  (b) SKY-FILTER-MR vs.?  Fig. 6: Running time for different l in CD  TABLE 4: |G| of SKY-MIN-MR (-M-) and SKY-FILTER-MR (? = 1, 1.001, 1.01) in AD |G|\ l 20 21 22 23 24 25 -M- 220 221 222 223 224 225 ?=1 60739 89673 182280 277057 534294 1216159  1.001 21660 35202 63022 81718 145363 340095 1.01 1432 3525 8199 11361 37530 61771  Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black} and {Female, Male} respectively, and we denote this dataset as AD for convenience. While, l varies from 22 to 27 for Census dataset, the domain for Race is {White, Black, American Indian, Chinese, Japanse, other Asian or Pacific, Other,}, and we denote this dataset as CD. The results for AD are shown in Fig. 5 and Table 4 respectively. It is clear that SKY-F-MR algorithm and SKY-FILTER-MR algorithm are significantly faster than the baseline algorithm, and our improved algo- rithm is slightly more efficient than the SKY-F-MR algorithm with the increasing length (l) of policies. Meanwhile, we can see from Fig. 5(b) that the improved algorithm with ? = 1.001 is slightly more efficient than that with ? = 1, and the algorithm with ? = 1.01 is slightly more efficient than that with ? = 1.001. For example, when l equals to 25 (Fig. 5), we can see that our proposed algorithms with ? = 1, ? = 1.001 and ? = 1.01 are 4.0076, 4.3365 and 4.5912 times faster than the baseline algorithm on average. Meanwhile, the efficiency gap between SKY-FILTER-MR and the baseline algorithm is getting larger with the growth of l. For example, when l equals to 25 and 20 (Fig. 5), our algorithms with ? = 1 are 4.0076 and 1.2480 times faster than the baseline algorithm. It means that our proposed algorithms are significantly faster than the baseline algorithm for long policies. In addition, the size of G for SKY-FILTER-MR is much smaller than that for the baseline algorithm, and it decreases dramatically with the reducing of ?. Our algorithm outperformed the baseline approach with the number of alternative policies decreased up to 732 times in the best case. As expected, the running time and |G| of all the algorithms were increased with growing l. The experimental results for CD are similar as shown in Fig. 6 and Table 5.

Scalability. Here we test the scalability of SKY-FILTER- MR algorithm. We vary the total number of polices |S| from 220 to 225 in AD and from 222 to 227 in CD, and test the time for filtering and total running time of our algorithm respectively. The precision parameter ? was set to 1, 1.001 and 1.01. The results are shown in Fig. 7 and Fig. 8. From Fig.

7, we can see that our proposed algorithms scale quite well.

TABLE 5: |G| of SKY-MIN-MR (-M-) and SKY-FILTER-MR (? = 1, 1.001, 1.01) in CD |G|\ l 22 23 24 25 26 27 -M- 222 223 224 225 226 227 ?=1 12953 54450 196988 402692 674820 1384353  1.001 6520 20473 86350 223051 393766 873381 1.01 2801 5801 14983 31918 56453 160017  0 1 2 3 4  x 10          Number of policies  R un  ni ng  ti m  e fo  r fil  te rin  g pe  r  po  lic ie  s  SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001) SKY?FILTER?MR( ? =1.01)  (a) Running Time (ms) for Filtering vs. |S|  0 1 2 3 4  x 10       x 10   Number of policies  R un  ni ng  ti m  e pe  r  po  lic ie  s SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001) SKY?FILTER?MR( ? =1.01)  (b) Total Running Time (ms) vs. |S|  Fig. 7: Scalability of the SKY-FILTER-MR algorithm in AD  When the size of S is larger than 1048576, the increasing speed of S is higher than the increasing speed of the running time. The results further confirmed that our algorithms can be applied to handle very large datasets.

TABLE 6: Running time and |G| vs.? (for the SKY-FILTER- MR algorithm in synthetic dataset based on Adult)  ? 1 1.001 1.005 1.01 1.05 time(ms) 46413 45021.1 44094 10984 9637  |G| 6739 4090 2639 1394 338  TABLE 7: Running time and |G| vs.? (for the SKY-FILTER- MR algorithm in synthetic dataset based on Census)  ? 1 1.0000001 1.00001 1.001 1.01 time(ms) 44612 42496 42515 13570 9553  |G| 7060 1706 1630 880 352  Effects of parameter ?. Here we study how the pa- rameter ? affects the efficiency and effectiveness of the SKY- FILTER-MR algorithm. For this purpose, we set ? = 1, 1.001, 1.005, 1.01, 1.05 for synthetic dataset based on Adult, and ? = 1, 1.0000001, 1.00001, 1.001, 1.01 for synthetic dataset based on Census, and use the running time, the size |G| of alternative policy set G and the proportion of ideal area to evaluate the efficiency and effectiveness of our algorithm, respectively. The dominating area was composed of those policies who dominate 10-anonymity, 2-diversity, and 0.45- closeness which are commonly adopted privacy protection levels [11], and we denote this dominating area as ideal area.

For three privacy models, we utilize Incognito algorithm [41] to find the skyline set. Also, we set l = 20, and similar results can be observed for other values. We test the SKY- FILTER-MR algorithm in the synthetic dataset. The results of running time with varying ? are shown in Table 6 and Table 7. As we can see, the running time decreases with increasing ?. In Table 6, when ? =1.01 or 1.05, the running time of the algorithm is much more smaller than that with ? = 1.005. However, when ? ? 1.005, the running time smoothly decreasing with increasing ?. This is because the filter stage    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2690660, IEEE Transactions on Big Data   0 5 10 15  x 10   0.5   1.5  x 10   Number of policies  R un  ni ng  ti m  e fo  r fil  te rin  g pe  r  po  lic ie  s  SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001) SKY?FILTER?MR( ? =1.01)  (a) Running Time (ms) for Filtering vs. |S|  0 5 10 15  x 10       x 10   Number of policies  R un  ni ng  ti m  e pe  r  po  lic ie  s SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001) SKY?FILTER?MR( ? =1.01)  (b) Total Running Time (ms) vs. |S|  Fig. 8: Scalability of the SKY-FILTER-MR algorithm in CD  0 0.2 0.4 0.6 0.8 1  0.1  0.2  0.3  0.4  0.5  0.6  0.7  R  U  10?anonymity 2?diversity 0.45?closeness SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.001)  (a) R-U Space  0 1 1.001 1.005 1.01 1.05 1.5  0.2  0.4  0.6  0.8   ?  P ro  po rt  io n  of id  ea l a  re a  1 0.9925 0.9916 0.9896 0.9412  (b) Proportion of Ideal Area vs. ?  Fig. 9: Effectiveness of the SKY-FILTER-MR algorithm in synthetic dataset based on Adult  takes relatively long time to get space {G, (R,U)} when ? is very small. However, when ? is large and |G| is small, the computation can be done with centralized algorithm (G < 1500) to decrease the time cost of skyline calculation.

Similar conclusions can be obtained in Table 7.

We report the proportion of ideal area of the SKY- FILTER-MR algorithm with different ? in Fig. 9 and Fig.

10. First, it is intuitively plausible (Fig. 9(a) and Fig. 10(a)) that policies generated from SKY-FILTER-MR dominate the policies from k-anonymity, l-diversity and t-closeness, that is, SKY-FILTER-MR dominates the ideal area. Second, we make a quantitative analysis of dominant condition about our algorithm. From Fig. 9(b), we can find that the propor- tion of ideal area decreases with increasing ?. The reason is that ? controls the quality of skyline frontier policies and a large ? results in a low quality. However, we get relatively high quality with different ?. For instance, when ? = 1.001 (Fig. 9(a)), the skyline frontier of SKY-FILTER-MR algorithm is close to the exact skyline frontier F .

7 CONCLUSIONS We study the recommendation on a great number of de- identification policies using MapReduce. Firstly, we put forward an effective way of policy generation on the basis of newly proposed definition, which can decreases the time of generating policies and the size of alternative policy set dramatically. Secondly, we propose SKY-FILTER-MR, which is a three-round MapReduce-based parallel algorithm, to answer skyline de-identification policies efficiently. We use bit-strings to represent one policy in the framework. In order to further improve the performance, a vigorous approximate skyline scheme is proposed to decrease the number of al- ternative policy set. By integrating the approximate skyline  0 0.2 0.4 0.6 0.8 1  0.05  0.1  0.15  0.2  R  U  10?anonymity 2?diversity 0.45?closeness SKY?FILTER?MR( ? =1) SKY?FILTER?MR( ? =1.0000001)  (a) R-U Space  0 1 1 1.00001 1.001 1.01 1.5  0.2  0.4  0.6  0.8   ?  P ro  po rt  io n  of id  ea l a  re a  1 1 1 1 0.9524  (b) Proportion of Ideal Area vs. ?  Fig. 10: Effectiveness of the SKY-FILTER-MR algorithm in synthetic dataset based on Census  with the minimal MapReduce algorithm, the filtering power in the Map phase of first round was optimized without in- creasing the transmission cost. We perform comprehensive experimental evaluation on both real-world and synthetic datasets, and the results indicate good performance and scalability of our proposed SKY-FILTER-MR.

There are several aspects could be improved in the future. For example, our framework requires a complete ordering in the domain of all QI attributes. In order to com- pare with original algorithms, the domain of attribute which is unordered in original state must be ordered randomly. We plan to make more efforts to design an effective approach to deal with the unordered attributes.

