Benefits of a Bayesian Approach to Anomaly and Failure Investigations

Abstract-It is often the case in failure and anomaly investi- gations that data is either limited or so wide ranging that it is difficult to bring focus to a key root cause. For this reason, a disciplined approach incorporating root cause trees (Ishikawa Diagrams) is usually taken to develop and track root cause hypotheses and analyses. During the investigation, statistical tools can be used to evaluate various hypotheses of failure.

However, in many cases, there is limited failure data and it is often necessary to set up accelerated life tests involving many samples in order to induce failures under controlled condi- tions so that a statistically significant population of failures can be obtained. Root cause is sometimes achieved only af- ter extensive and expensive efforts to reduce the number of root cause hypotheses. Other times, root cause investigations are truncated to "most probable cause" based on the evidence available and expert opinion.

Bayesian analysis allows test or observation data to be com- bined with prior information to produce a posterior estimate of likelihood. It can be a tool that provides a number of bene- fits to the root cause determination process. The first benefit is to provide an estimate of the likelihood that certain hypothe- ses are true based on the limited data available. This can pro- vide useful direction to the failure investigation. For example, it can provide an indication as to where more data collection might be valuable, i.e., tests of most likely hypothesis as op- posed to tests of all hypotheses in a root cause analysis. It also can provide a way to assess the incremental impact of data as it becomes available to the decision making process.

Another benefit is to organize the logic, once root cause has been determined, that can lead to a more quantitative mea- sure of the likelihood of a future failure. This latter benefit can help guide the decision making processes necessary for determining what corrective action (if any) might be neces- sary.

This paper provides an elementary introduction to a Bayesian approach to data analysis for anomaly and failure investiga- tions and provides a number of worked examples illustrating its utility.

1. INTRODUCTION  H ???a large amount of reliability and quality-control testing is needed in modem technology. In some cases, particularly, in the aero-space field, acquisition ofa single data point can cost more than the yearly salary ofa statistician. Use ofsta- tistical methods that fail to extract all the relevant informa- tion from a sample, or fail to make use of relevant prior in- formation, is therefore not only illogical; it can lead to stag- gering economic waste." [1J  Root cause investigation is typically employed in the inves- tigation of failures and anomalies. One method is the use of a fishbone diagram (Ishikawa diagram) in an attempt to map out all the possible causes that may have led to an eventual failure or anomaly. As the investigation proceeds, data is col- lected and evaluated to determine whether or not a particular root cause is supported. As more and more data is collected and perhaps more insightful experiments are conducted, the potential root causes on the Ishikawa diagram are crossed out until only one remains. During these investigations, much data can be collected and often the analysis of the data is con- ducted with the intention of being able to come to precise conclusions. This can sometimes lead to large sample sizes being evaluated for what may tum out to be ultimately un- likely root causes.

Analysis ofdata using Bayes' theorem in order to improve de- cisions in situations where failures or defects have occurred is not new. In fact, many examples used in college level texts from the last half of the 20th century illustrate Bayes' theo- rem using situations involving production defects and/or part (supply chain) defects. For example, Hadley [2] describes the case of a manufacturer trying to determine what the likeli- hood is that he has accepted a good or a bad lot based on a lot sample that contains a specified number of defects. Mosteller, Rourke and Thomas [3] give an example of trying to deter- mine which production machine likely produced a part that turns out bad. More complex analysis can be performed as is illustrated by the separation of a signal from noise [4].

In this particular case, one might imagine a failure analysis where slight current increases might be separated out from the normal background and perhaps illustrate the initiation of a shorting event.

Equation 1 can be written  Bayes' rule is given by the following equation [3]:  ( I ) - P(Hi n E) (1)  P Hi E - ) ( )P(H1 n E + ... + P H n n E  Bayesian analysis techniques can also be applied in other ways that are useful for evaluating data either gathered or generated during a failure investigation. Many failure inves- tigations involve the assessment of what are considered to be normally distributed parameters. Often an analysis of data involves calculating means and standard deviations of exper- imental or process control parameters. When investigating failures, since a process or material may not be exhibiting what is considered to be "normal" behavior, it is probably more appropriate to think of the mean and variance as un- known parameters that each have a distribution associated with their true value. Barrett and Green [5] and Gelman et al. [6], provide a description of the Bayesian approach to this problem, and later some examples are given, using methods described by Albert [7] and implemented in R [8], which il- lustrate the utility of the approach. While a traditional ap- proach to data analysis may get you to the same conclusions in process and material testing, the use of a Bayesian ap- proach can, I believe, provide important insight, focus, and direction in failure investigations.

Although not addressed in this paper, some investigators [9], [10], [5] have applied Bayesian analysis to failure data fol- lowing a Weibull distribution model in order to update relia- bility data and improve reliability estimation. From a practi- cal standpoint, the utility in a failure or root cause investiga- tion would be the incorporating of test results under acceler- ated life conditions in predicting future failure behavior. For example, consider the case of component failures during sys- tem verification testing. Since the failures are fairly far down- stream from the component bum-in screens, which should identify and remove a weak population, and also downstream from assembly screen testing, which should identify and re- move workmanship defects, one is left with potential failure causes due to wear-out mechanisms.

gives a probability that the lot contains a given percentage or less of defects. Knowledge of this percentage combined with the supplier's prior data can improve the manufacturer's knowledge concerning the expected number of defects in the lot. In root cause investigations, particularly when the failure of supplied parts must be considered as potential root causes, the application of Bayesian analysis can prove to be valuable.

Later, some examples will be provided to demonstrate this utility.

If assets are available, the investigation team will want to investigate potential failure mechanisms by conducting tests that mimic the operating environment as closely as possible in terms of voltages, currents, temperature and duty cycle.

And, if the tests are accelerated, then the local technical ex- perts will want to ensure that they are accelerated within rea- sonable bounds of where the failure mechanism is likely to operate. Also, it would be desirable to add any pre-existing failure data to any failure data that is generated in testing as this data provides additional statistical evidence in determin- ing a cumulative failure distribution for the population of sus-  (2)  (3)  where P(Hi IE) is the probability of hypothesis i given that event E has occurred and P(Hi nE) is given by the following equation which can be read as follows. It is the probability that the hypothesis Hi is true times the probability of event E occurring given that the hypothesis Hi is true.

In equation 3, P (Hi) is called the prior probability. It is the probability that the hypothesis is true based on previously ex- isting information. The term P(EIHi ) is called the likeli- hood and is the probability of event E occurring given that a particular hypothesis is true. The denominator in equation 3 is a normalizing function. The term on the left side of the equation is the posterior probability that the hypothesis is true given that event E has occurred and is the product of the prior probability times the likelihood divided by the normalizing function. Examples will be give later; however, this simple illustration may help to clarify the concept. Suppose that a component supplier has been collecting data from in-house tests that show the expected percentage of defective parts in each lot that they ship. The supplier may keep this data in a discrete histogram format, or they may try to fit the data to a continuous probability distribution. For the purposes of the illustration, this is the prior probability for a hypothesis that states: given a particular lot, the probability that a given per- centage of parts in this lot is defective is given by the data shown in a normalized histogram (or fit to the continuous probability distribution).

Now, suppose that a manufacturer buys a lot from the compo- nent supplier and conducts an in-house acceptance test on a sample of multiple parts drawn from the lot. Given the num- ber of parts in the lot, the number of parts in the sample, and the number of failures in the acceptance test, the manufac- turer calculates a probability distribution or likelihood for the expected percentage of discrepant parts in the lot purchased from the component supplier. To give an even better esti- mate of the expected distribution of discrepant parts in the lot, the manufacturer can use Bayes' theorem to combine his data with the historical data (the prior data) from the part sup- plier. The reader might ask why, after lot testing, the manu- facturer would need to combine the in-house acceptance data with the prior data. As will be shown later, the acceptance sampling scheme or plan (unless all parts are tested), only     pect parts. The results of the testing along with analysis can then be used to help determine a path forward.

Using equation 3 the probability that the resistor came from either Supplier A or B can be calculated:  The examples that follow are realistic in that they describe situations that do arise in failure investigations. The "data" upon which the examples are based are representative of real situations, and not taken from any specific failure investiga- tion.

P(H IE) - (0.70)(0.15) - 1 - (0.70) (0.15) + (0.30)(0.05) - 0.875 (6)  2. EXAMPLES  lOne might question the use of the initial part-level bum-in yield in this situation as the initial bum-in should have screened out a number of workmanship-related defects that wouldn't then make it to an assembly-level bum-in. However, consider that the initial bum-in for both Supplier A and Supplier B reduces defects by a factor of 10. Using the yields for future assembly level bum-ins that this generates does not change the outcome of the calculations that are conducted since both the numerators and denomina- tors of the fractions are divided by the same number (e.g., 10). One might be more easily convinced that the calculations shown actually underestimate the difference between Supplier A and B since intuitively one might expect more downstream failures from Supplier A than from Supplier B because the initial bum-in yield was worse.

Now, the PM&P engineer recognizes that the previously men- tioned burn-in yield history might also be helpful here. Intu- itively, the fact that Supplier A's resistors have a lower yield through the part level burn-in is an indication that they are less robust than Supplier B's resistors. Therefore, the engi- neer makes the assumption that the probability of the event (Le., resistor failure) given that HI (Le., the resistor came from Supplier A) is true is 0.15. Similarly, the probability of the event (resistor failure) given that H 2 (resistor came from Supplier B) is true is 0.05 which is the fall-out at Supplier B during the initial burn-in. 1  Lot Sampling and an Available Discrete Prior Distribution  A simple example illustrating Bayes' theorem follows. Sup- pose that an assembly house obtains resistors from two sup- pliers. Each of the suppliers subjects all resistors in a lot to a burn-in of 100 hours at elevated temperature and voltage stress. If the burn-in fall-out is greater than 20% then the lot is failed. It is known that Supplier A typically has a 15% fall- out in burn-in and Supplier B typically has a 5% fall-out in burn-in. Since Supplier A typically charges less, 70% of the resistors bought by the assembly house are from Supplier A.

The assembly house integrates the resistors into a higher level of assembly that then also goes through a burn-in. This burn- in is at a slightly elevated temperature and is conducted for 300 hours. During burn-in, a resistor fails and before opening the unit up, a parts, materials and processes (PM&P) engi- neer makes an estimate of the probability that the resistor that failed came from Supplier A. In this case, the event (E) is the failure of the resistor, and there are two hypothesis with two different probabilities. The first hypothesis is that the resistor came from Supplier A, and the second hypothesis is that the resistor came from Supplier B. The associated prior probabil- ities are  (7)P(H IE) - (0.30)(0.05) - 2 - (0.70)(0.15) + (0.30)(0.05) - 0.125  These new probabilities are called the posterior probabilities.

In effect, available data, Le., the fall-out during burn-in at the supplier (the likelihood that a failure will occur given that a part is from a specific supplier) is multiplied with the prior probability, which reflects the mix of resistors on hand that were available for the assembly process (70% from Supplier A and 30% from Supplier B). The resulting products are then normalized to come up with posterior probabilities. Compare this to an estimate without any prior knowledge of the burn-in drop-out at the supplier. One would have estimated P (H11 E) as 0.70 and P(H2 IE) as 0.30.

One could extend this example a bit as was typically done in the references and texts like those listed above and perform a cost-benefits analysis of buying from Supplier B rather than A given that replacement costs on returned units are taken into account.

In another situation, there is a failure of a capacitor on a board assembly that is only about a hundred hours into unit test. Two similar failures had occurred in the previous three months and the capacitors, which were of the same lot as the most recent failure, were replaced. Now, however, the pro- gram manager is worried that there may be a problem with the capacitor lot and is reluctant to continue manufacturing until a root cause is determined. The PM&P engineer is asked to examine the available capacitor data and come back with an estimate as to whether the lot is good or bad.

The PM&P engineer recovers the lot data for the capacitor.

The capacitor comes from Supplier A and, as part of the ac- ceptance tests, a life test was conducted with 20 parts. One failure was allowed and one failure did indeed occur. The en- gineer also notes that the lot consisted of 1000 pieces. The engineer is also curious about Supplier A's history in terms of delivering parts and asks the buyer to obtain information to that effect. The buyer comes back with the following in- formation. He tells the PM&P engineer that since Supplier A provides capacitors to customers with a wide range of re- quirements, it is asked to perform a wide range of lot accep- tance tests and then to certify the results in a letter accom- panying the lot delivery. They can't necessarily correlate pre- cisely the lot test results given the wide range of tests that they are asked to do; however, for their own benefit they do keep a tally in the following manner and with the following results.

Over the years, they have found that 10% of the lots that they  (4)  (5)  P(H1 ) == 0.70  P(H2 ) == 0.30     where N is the total lot size, n is the sample size, M is the number of failures in the lot, and k is the number of failures within the tested sample.

(9)  0.25  --n=20 --- n = 100  -I L.

-L1.

o-l-------.....---~:::..:..-.._--___r--___, a 0.05 0.1 0.15 0.2  Lot Fraction Defective  0.9  0.1  II ~ 0.8 IV ~ 0.7 II ~ 0.6 cf (; 0.5  >- ~ 0.4  :a IV 0.3 .a f 0.2 a.

from the population and not replaced (i.e., not put back into the population after the completion of the test). This is a case of sampling without replacement, and the proper distribution to use would be the hypergeometric distribution which is:  P(Y = kip) = (~) ~=~;) (n)  For the two sample plan examples described above, 100 sam- ples with a 5 failure limit, and 20 samples with 1 failure limit, the operating characteristic function was determined and the results are shown in Figure 1. After examining the operating characteristic curve for the lot sampling plan that his com- pany used (20 parts out of 1000 with 1 failure allowed), the PM&P engineer realizes that there is a fairly good chance that the actual defect rate in the capacitor lot was higher than in- tended.

The PM&P engineer considers a lot of 1000 capacitors and two different acceptance schemes. In the first scheme, 100 capacitors are taken from the lot and put through a 1000 hour life test consisting of elevated temperature and voltage stress.

If greater than 5 of the capacitors fail, then the lot is consid- ered to have failed. In the second scheme, 20 capacitors are removed from the lot and tested in a like manner. If greater than one of the capacitors fails, then the lot is considered to have failed. Let us suppose that in both cases the lot passes.

It is a natural question to ask whether or not the acceptance of the sample might entail the acceptance of a lot which truly didn't meet the intended requirement of having 5% or less defects. Intuitively, one realizes that the more samples that are tested, the less likely it is that one will make this er- ror. To characterize this, operating characteristic curves are constructed which provide the probability of accepting a lot, given that a certain percentage of it is defective.

ship exhibit 5% or less defects during testing. Thirty percent exhibit between 6 and 10% defects. Forty percent show be- tween 11 and 15% defects and 20% show between 16 and 20% defects. If a lot shows greater than 20% defects they scrap it.2  The PM&P engineer is somewhat surprised by the data in that it indicates that the quality of Supplier's A product is some- what variable, and engages the buyer in more discussion. The buyer says that although the variability in the quality of the lots from Supplier A appears to be high, only those lots that meet the requirements of having fewer than 5% failures in the lot acceptance life test (Le., 0 or 1 failure out of 20) are shipped to the company's assembly line. The buyer is com- fortable with the requirements and has no concern. However, the PM&P engineer is somewhat dubious and does further investigation into what the lot acceptance test really means.

(8)  Following the exposition of Lindgren [11], the operating characteristic function is determined from Equation 8  c  OC(p) == L P(Y == kip) k=O  where P (Y == kip) is the probability that the lot passes a specified sampling plan given that the proportion of defects in the population is p. The acceptance number is c. For ex- ample, if a test of 20 parts is conducted and a single failure is allowed, then the acceptance number is 1. The operating characteristic function is then the sum of the probability of observing no failures in the test sample plus the probability of observing one failure in the test sample, given that the pro- portion of failures in the population is p.

The probability distribution function to use for P (Y == kip) depends on the kind of sampling that is done. In the case of the life tests described above, the samples would be taken  2Por the purpose of this exercise, we won't pursue the question of what pro- portion of lots are scrapped, but in a real situation, that would be the next question to ask.

Figure 1. Operating Characteristic Curves for a lot size of 1000 parts and a rejection limit of 5% or less. The size of the sample taken from the lot (without replacement) is denoted by "n".

The PM&P engineer now wishes to obtain a more quantita- tive number of the probability that the accepted lot was bad and uses Bayesian analysis to do so. The prior probability is the historical fractional distribution data that the buyer has described. The likelihood is the cumulative hypergeometric probability distribution shown for a sample size of 20 with 1 failure in Figure 1. The Bayesian analysis is summarized in Table 1 and illustrated in Figure 2. This figure illustrates that the likely lot fraction which was defective was higher than what was intended. In fact, by summing up the area below the normalized posterior defect probability distribution it is found that the probability that a good lot was accepted is only about 24% and the probability that a bad lot was accepted is about 76%.

After concluding the analysis, the PM&P engineer explains to     r----I I ----I I I  I II L ?  0.05 0.1 0.15 0.2  Lot Fraction Defective  -- Cumulative Hypergeometric Distribution (n=l00, x=2) - - - - Prior Defect Probability for Supplier A - - - - - Posterior Defect Probability  0.0-I-------r--~-.........----__._---___.

o  0.1  0.3  0.2  0.9  0.7  0.8  1.0  ~ 0.6  :c II 0.5 .c E Q. 0.4  0.2  -- Cumulative Hypergeometric: Distribution (n=20, x=l) - - - - Prior Defect Probability for Supplier A - - Posterior Defect Probability  1.0  0.9  0.3  0.7  0.1  0.2  0.8  r--- I I  I I  ---r'-~ ---J ~~  O.O~---.......---..........----"-r;;;;;;;;;;;;;;;~--..

o 0.05 0.1 0.15  Lot Fraction Defective  ~ 0.6  :c II 0.5 ..Q o 0:. 0.4  Figure 2. Prior and posterior probabilities for Supplier A with the lot acceptance test data of 1 failure in 20.

Figure 3. Probability distribution for fractional lot defective from Supplier A after additional life testing has been con- ducted.

the program manager that the lot acceptance test plan likely did not adequately reflect the state of the purchased capacitor lot. The program manager now has some data to make an as- sessment concerning the problem encountered on the produc- tion floor and is leaning toward recalling some product and performing remove and replace operations for assemblies still in manufacturing (hopefully with a capacitor lot that had an improved lot acceptance test). However, because of the cost associated with the recall and remove-and-replace operations, the program manager asks if anything else might be done to determine whether or not the capacitor lot was indeed truly "bad".

The PM&P engineer thinks about this and and suggests that an additional life test be conducted to provide more infor- mation with which to make a decision. The program man- ager asks how many capacitors from the lot would have to be tested and what kinds of results would be needed be- fore enough confidence could be gained that the capacitor lot demonstrated a likelihood of a 5% or less failure rate. The PM&P engineer analyses the problem and determines that if 80 more parts are put into test (for a total sample size of 100 parts when including the original lot acceptance test) then, with just one more failure, the probability that the lot was good would rise to 88%. Results of this analysis are shown in Figure 3. After consultation on the analysis and based on the cost of recall and other manufacturing costs, the program manager decides for testing of 80 more parts. In addition, since the root cause has not been determined conclusively, there is still a possibility that the lot is good and that there is another problem on the production line causing the defects.

Unfortunately, the results are not good and the company has to implement a recall.

Note that in this example, the PM&P engineer has not only used a Bayesian approach to evaluate the likelihood that the  capacitor lot is good, but he has also used the Bayesian ap- proach to determine the number of additional capacitors and allowable failures for further testing that if successful would lead to a different outcome. A positive outcome would have had two implications. First of all, remove and replace opera- tions would not have been undertaken, and secondly, another root cause hypothesis for the production and test floor failures would have been needed.

The PM&P engineer is curious as to how the situation would have turned out had they ordered the capacitors from Supplier B. The buyer provides the data shown in Table 2. It is appar- ent that Supplier B has a much tighter control on the qual- ity of the product than does Supplier A. As the data bins are more finely divided, it is also apparent that Supplier B does more than Supplier A in developing and keeping records of lot quality. Had it been the case that Supplier B had provided the parts then the results as shown in Figure 4 would have resulted. Note the influence of the prior lot data.

Normal Distributed Parameter with Both Mean and Variance Unknown  As another example, consider the case of a manufacturer who has recently experienced a number of failures in product test- ing. The product that the manufacturer produces involves a number of processing steps and incorporates material from a number of suppliers. In setting up the root cause diagram, a number of possible failure mechanisms based on the nu- merous processes and potential changes in incoming material are proposed. As part of the root cause investigation proce- dure, the plant manager asks the engineering staff to gather as much data as possible from in-process checks and receiving material lot testing.

The plant manager knows that material lots vary in their     Table 1. Combination of Supplier A Historical Data with Lot Sampling Information (n=20, c=l).

Fraction of Probability of Acceptance Based Prior Defect Probability Probability of Acceptance x Posterior Defect Lot Defective on Lot Sampling Method for Supplier A Prior Defect Probability Probability  0 1.000 0.1 0.100 0.044 0.01 0.984 0.1 0.098 0.044 0.02 0.942 0.1 0.094 0.042 0.03 0.882 0.1 0.088 0.039 0.04 0.811 0.1 0.081 0.036 0.05 0.736 0.4 0.294 0.131 0.06 0.660 0.4 0.264 0.117 0.07 0.586 0.4 0.234 0.104 0.08 0.515 0.4 0.206 0.091 0.09 0.449 0.4 0.180 0.080 0.1 0.389 0.35 0.136 0.060  0.11 0.335 0.35 0.117 0.052 0.12 0.286 0.35 0.100 0.044 0.13 0.243 0.35 0.085 0.038 0.14 0.205 0.35 0.072 0.032 0.15 0.173 0.15 0.026 0.011 0.16 0.144 0.15 0.022 0.010 0.17 0.120 0.15 0.018 0.008 0.18 0.099 0.15 0.015 0.007 0.19 0.082 0.15 0.012 0.005 0.2 0.067 0.15 0.010 0.004  Total = 2.254 1.000  Figure 4. Probability Distribution for Fractional Lot Defec- tive from Supplier B.

0.20.15  -- Cumulative Hypergeometric Distribution (n=1oo. c=5) _. - Prior Defect Probability - _. Posterior Defect Probability  _l-:JJ.I L ~. L'L.

o-+--a...- ---C'---...? --~-....__---_ o 0.05 0.1  Lot Fraction Defective  0.2  0.8  ~ 0.6  2i ftI J2 a. 0.4  Fractional Lot Supplier B Fractional Distribution of Defective Bins Lots Supplier BLots  0 97 0.025 0.01 459 0.120 0.02 845 0.220 0.03 1032 0.269 0.04 568 0.148 0.05 427 0.111 0.06 205 0.053 0.07 165 0.043 0.08 43 0.011 0.09 0 0.000 0.1 0 0.000  Total 3841 1  Table 2. Supplier Bum-in Fall-out Data  properties between different suppliers and also knows that over time even a constant supplier may not deliver a ma- terial with properties that are constant. The plant manager also knows that processes are changed slightly on the floor to allow for the differences with incoming material property changes. To roughly determine where the problem in the pro- cess stream might be, data from a strength test that occurs  halfway through the process is examined for any variation over time. Because of the previously mentioned variability in the process and incoming materials, the plant manager has an analyst look at the intermediate strength data as if the mean and the variance of the population were not known. The idea would be that if a change has been noticed in the dispersion of the mean and variance parameters at the intermediate point,     then the problem causing the failures is probably located up- stream of the testing rather than downstream, and that knowl- edge helps to limit the scope of the investigation. Table 3 shows two sets of strength data obtained from this test. Two of the data sets come from records three months before prob- lems in acceptance test were observed, and the other two sets of data are the most recently obtained. For the purposes of the test, strengths in excess of 300 Ibs were required so all were considered to have passed.

Table 3. Four Sets of Strength Values Determined at an Intermediate Step in the Fabrication Process. Sets 1 and 2  come from data taken 3 months before failures were observed. The data shown in Sets 3 and 4 were recently  taken.

Set 1 Set 2 Set 3 Set 4 400 415 350 350 365 385 400 395 385 395 405 410 415 400 425 430 425 390 340 375 395 425 365 355  The approach that the analyst takes in analyzing the data is described by Gelman et al [6]. A similar description of this problem has also been given by Barrett and Green [5].

The joint posterior distribution p(J.-l, a 2 ly) is proportional to a prior density (1/( 2 ) times the likelihood function.

The parameters of interest are the mean J.-l and the variance a 2 ? The analysis is detailed in Albert [7] and makes use of the capabilities of R [8] to perform the calculations and generate the results. The results of analysis are shown in Figures 5 through 8.

Figures 7 and 8, which represent the most recent data, show an increased dispersion of the variance and the mean for the strength values at this stage of the fabrication process. Be- cause of this information, the production line manager runs a few more tests and analyses to confirm that the difference exists and, once confirmed, decides to focus more attention in the investigation on potential root causes up-stream of the test.

3. DISCUSSION  For the examples concerning lot sampling and prior knowl- edge of a supplier's quality history, the use of a Bayesian ap- proach in the investigation provided insight into a realistic probable failure cause. It is interesting to consider the impli- cations for the particular manufacturer who was affected.

If the manufacturer had relied only on the lot sampling plan, then what would have been the state of knowledge concerning the purchased lot? Based on just the 20 piece sample alone, the intuitive answer would be that the lot contains 5% defec- tive parts. Taking into account the operating characteristic curve shown in Figure 1, one would realize that the proba- bility of passing the lot screen test is quite high even for lots with higher proportion of defects than what is desired. This is called consumer's risk and can lead to a Type II error. A Type II error is the error of accepting the hypothesis that a lot is good (based on the lot sample test) when in fact the lot is bad.

The operating characteristic curve gives the probability that the lot screen test will pass when there is a specified propor- tion of defects in the lot. It would be nice to know what the sample test says about the proportion of defects in the lot.

This concern has been addressed by Graves et al [12] who define what they call a "Bayesian consumer's risk." This is "the probability that a lot which is accepted will contain more than a designated level of defectives." The determination of the Bayesian consumer's risk is essentially what was illus- trated previously when the area under the normalized poste- rior distribution shown in Figure 2 was determined in order to provide a probability of either a good lot (24%) or a bad lot (76%).

To extract similar information from just the sampling test, a uniform prior was assumed. That is, it was assumed that the probability of any specified proportion of defects within the lot population was equal to any other specified proportion of defects. This seems reasonable, as nothing a priori is known about the lot. Using the sample data, the hypergeometric dis- tribution (n=20, c = 1) gives the likelihood. The results of this analysis show that after the sample test, there is a 49% probability that the lot has more than 5% defects. Although this sample test provided some information about the lot, if the manufacturer had relied on it alone, it would have been almost equally likely that a bad lot would be accepted as a good lot (as defined by the desired defect proportion being less than 5%). When the discrete prior information (Supplier A history) was considered the probability that a bad lot was accepted increased to 76%.

The use of Bayesian methodology highlighted the inadequacy of the lot acceptance testing and provided insight into the im- portance of understanding the quality of one's suppliers be- yond just the particular lot of items being procured. In addi- tion, it was seen that prior knowledge can be very beneficial in determining the path forward in a failure investigation. When the program manager needed to understand how many more capacitors needed to be tested in the off chance that the pur- chased lot might actually be good, the answer using Bayesian techniques was different in light of the prior information from the one that he would have gotten had only the particular lot in question been considered.

It also is interesting to consider the different situation with Supplier B. Supplier B more tightly controlled, to lower de- fect proportions, the lots that it supplied. The prior data pro- vided more assurance that the accepted lot was good. The comparison between the situations with Supplier A and Sup- plier B highlights the problem with particular lot sampling plans of not considering supplier history in the lot acceptance process.

For the example concerning the test failure of a manufac- tured item, there was an opportunity using existing data to determine where more focus of the investigation should oc- cur. In this case, none of the test samples actually failed the in-line test; however, the observed dispersion in the variance and mean indicated that something upstream was providing more variance in the product. This information gave the root cause investigation team an indication of where to apply more investigative resources.

4. CONCLUSIONS  Some simple examples of the use of Bayesian analysis in fail- ure and anomaly investigations have been given. They have illustrated the importance of considering prior information in determining answers to questions that typically come up dur- ing root cause investigations. A Bayesian approach can pro- vide insight and point to fruitful directions in the pursuit of root cause.

