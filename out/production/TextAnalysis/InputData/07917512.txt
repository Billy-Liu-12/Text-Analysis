Challenges of Collecting Empirical Sensor Data from People with Dementia in a Field Study

Abstract?Collecting annotated sensor data in real life field studies is a challenging task, especially when observing people with dementia. In this paper we outline our attempt on con- ducting a large scale experimental study while focusing on the technical aspects. We conclude by giving a brief summary of the obtained data set and reporting our lessons learned.



I. MOTIVATION  Agitated behaviour of people with dementia is a heavy burden for caregivers. To support them we are aiming at an assistive system which, based on sensory inputs, generates suitable interventions. Based on a custom sensor bracelet, we gathered motion and contextual sensor data for inferring short- term activities, repetitive behaviours, and long-term progres- sions. For training our classifiers and models a vast amount of annotated data had to be obtained in nursing homes over two months, while being as unobtrusive as possible.

In this paper we first lay out the general experimental setup and extrinsic constraints we had to cope with. After discussing several data sets found in the literature, we introduce our approach to this task and our tool chain. We then present the outcomes of the field study, describe the resulting data set, and report examples of issues we encountered. We finish by reporting our lessons learnt by formulating more general requirements for incorporating organisational, social, techni- cal, data validity and privacy related aspects, followed by an outlook towards our next steps of work.



II. EXPERIMENTAL SETUP  As we are targeting on an assistive system for a real world scenario, we are relying on realistic sensor data which cannot be obtained in a simulation or a laboratory setting.

The only possible way for us to obtain such data was to conduct a field study with people with dementia in their natural domestic environments (of course with a signed consent of all participants after a successful ethics approval). For training and evaluation of our recognition models we need large scale samples of motion, contextual, and physiological sensor data collected over a long period of time for different participants at multiple levels of impairment. Due to the need of realistic physiological measurements, ideally full daytime routines, and sleeping behaviour we could not use medically trained actors performing similar behaviours. Modality and classes of anno- tations were predetermined by the clinical project partners. The following briefly depicted challenges and external constraints had to be addressed during our field study:  Location: Data had to be recorded on site in a domestic environment, no laboratory. Participants were located in 2 separate nursing homes. Both locations are separate and no engineers were allowed on site during the recording. Video recording only allowed on second site in common spaces.

No networking or video infrastructure available, no addi- tional wiring allowed, ferroconcrete limits wireless signals.

Duration: 4 weeks of continuous recording on each location.

Recording of sensor data possible during day and night.

Video recording was allowed during the day for 10 hours.

Participants: 9 participants in parallel on the first location, 8 on the second. Participants were people with severe dementia and very special needs. The experimental setup should not trigger agitated behaviour. Uppermost priority was to preserve the dignity of the patients. Personnel: No technical staff on location during recording, only for (de-)installation. Normal care routine had to be preserved during study. Caregivers were changing daily. Care personnel should not be burdened with too much additional workload and had to be kept motivated.

Camera acceptance could be problematic for some. General: The trial could not be repeated. Every day without recording is a very expensive complete loss (costs of annotators, inter- ruptions of study). Participants would not be available for a second try.



III. RELATED WORK  Two main fields of research can be identified from the lit- erature for collecting large scale annotated sensor data in field studies: the medical community is interested in actigraphic measurements for people with dementia, and the activity recognition community trying to gather large annotated data sets of activities of daily living.

Bankole et al. [1], [2] observed 6 patients with dementia for 3 x 3h using 3 accelerometers at the dominant wrist, waist, and opposite leg. They used live annotation to find correlations between raw data and agitation. Mahlberg and Walther [3] used actigraphy in a large scale medication study. They instru- mented 24 dementia patients and 20 healthy controls with an Actiwatch worn at the wrist for 14 days. Only the NPI score and no annotation was used. Nagels et al. [4] instrumented 110 patients for 48h with an octogonal basic motionlogger at the non-dominant wrist. They were using basic actigraphy features to infer the CMAI score. Again, no annotation has been used. Valembois et al. [5] attached the Vivago wrist actigraph to 183 patients for 10 days. They used statistical tests      to analyse the significance of motion intensity with respect to NPI and MMSE scores. Yakhiaa et al. [6] collected data from 20 patients with mild cognitive impairments and 14 healthy subjects with an chest-mounted actigraph during a 30min test scenario. They used different assessment scales to look for differences in motion patterns between depressed and non- depressed subjects. Kirste et al. [7] equipped 23 dementia patients and their healthy partners (46 in total) for 50h at home with an ankle worn Shimmer sensor. They were able to infer the mental state by analysing spectral features of the motion behaviour. Again no other annotation than assessment scores like MMSE has been used.

For the CMU-Multimodal Activity Database [8] 43 subjects were instructed to prepare 5 different recipes in a laboratory kitchen setting. They have been instrumented with inertial sensors on several bodyparts and partially an optical motion capturing system. All recordings were accompanied by video and audio, some of them beeing annotated afterwards. (Total: 65GB; 13hours) For the Opportunity data set [9], [10] single subjects performed 60 instructed runs of Activities of Daily Living also in a laboratory setting. (Total: >130GB; 25h) Van Kasteren [11] recorded 28 days of everyday behaviour in the subjects home using environmental switches and online annotation via headset. He was able to record 2120 sensor events and 245 activity instances. The SPHERE data set [12] contains about 21GB of partially live annotated recordings from (un)scripted kitchen activities in a home environment from accelerometers, environmental sensors, and cameras.

In the medical field of research mainly off the shelf simple actigraphs and rarely more than basic statistical tests have been used to draw conclusions based on the patients motion behaviour. Although in some cases a large number of study participants were monitored over long periods of time mostly no annotation was recorded at all. In the activity recognition community most people collect their own experimental data as side effect of testing new algorithms or sensors. Only a few attempts to record a large scale data set can be found in the literature. For them the great amount of effort needed for the annotation leads to sparsly annotated data only.



IV. REALISATION  To realise the recording, we created a solution incorporating social, organisational and technical aspects.

1) System Overview: The technical solution had to meet the requirements of the data security and safety boards of the involved institutions. For this, we had to ensure, that all data is kept safe and secure, i.e., that no unauthorized access is possible, that all nessessary data is collected and the integrity of all data is ensured. We used a sensor bracelet based on the ?GreySense?-platform by Grey Innovation, different cameras (bullet point and fisheye cameras for the overview), a laptop as primary interface for the nursing staff during the study, a NAS (Synology NAS DS415+) for data storage, a webserver and the necessary network infrastructure between the different components. The recording pipeline is shown in Figure 1.

3.

backup  1.

data offload  5.

transfer to server  6.

data analysis  signing and encryption of data  2.

4.

backup to ext.

harddisk  Fig. 1. Pipeline of the data recording created for our study  In addition to the recorded sensor and video data, the behaviour of the persons with dementia was annotated by trained annotators using the dementia care mapping (DCM) approach. This is based on a codebook of 23 classes which are assigned to 5-minute intervals (the most prominent out of the 23 classes and a mood and engagement value (?5 . . .+5) is assigned to every interval). A single mapper can map up to 8 persons simultaneously. As we are targetting certain types agitated behaviour, we extended the DCM-mapping with an additional codebook containing 6 classes of which all that occured within the interval are safed.

The sensor bracelet, shown in Figure 1 next to the laptop, is able to record the following modalities: movement (accelerom- eter, gyroscope), temperature (environment, body), ambient light and sound, heart rate variability. It can be worn on the wrist, like a watch, or on the ankle. In our study, we used two bracelets (i.e., on both locations) during the daytime, and one at night-time on the ankle. The sensors are able to record data for about 12h, which results in 3 data-sets per patient per day.

The laptop was used to offload the data from the sensor bracelet, to recharge them via USB, and as interface for the nursing staff. The offload manager shows the current state of all connected bracelets (offload, re-initialise, charging, ready).

In addition, all video cameras could be switched on and off through the laptop. Therefore it was located in the nurses? room and is not suitable as single storage system for the data.

A network-attached storage (NAS) was used as primary data sink within the nursing home. It was located in the locked server room of the nursing home. All data was transfered to the NAS and stored there. The NAS? integrated video surveilance solution was used to capture the videos from 4 cameras installed in the public areas within the nursing home.

2) Data acquisition, storage and preprocessing: One de- sign goal was to enable a short-time data analysis while making the solution as robust and safe as possible. After offloading the data from the bracelet, every file was signed and encrypted as early as possible, i.e., data files on the laptop and the video files on the NAS. The files were stored on the NAS and in addition on an external hard disk attached to it.

All sensor data has, in addition, be kept on the laptop. Using this, we could ensure that every data file was stored on at least two different storage media.

To analyse the data as quickly as possible, we transfered them to our university servers, were we created visualisations to inspect the data and find anomalities. These anomality     checks need to be done as soon as possible, as described below.

The transfer worked fine in the first nursing home, but was not possible in the second, due to the limited bandwidth of the internet connection. For the second nursing home, we changed the pipeline slightly. Instead of transfering all data, we created data excerpts containing only 10.000 out of > 6.000.000 records per datafile. Those excerpts contain enough data to visually inspect it, and are small enough to be transfered.

3) Monitoring the recording: In our study, it was crucial to collect as many data records as possible in a predefined period of time, because only at certain days, the DCM mappers were available. Therefore, we had to identify potential problems as soon as possible. For this, we monitored our system as follows: Storage media: Report of remaining capacity every 24h; Create warnings (< 50%) and errors (< 25%) Storage directory: Report size of all folders influenced by the recording every 24h; Monitor the (expected) increase Data file: Report the deviceID, file size, number of atomic events, start- and end time as well as the time of important steps in the recording pipeline (offload, copy to NAS, upload to server, create report for inspection); Create warning if deviation from schedule, i.e., expected data files are not uploaded (3 per patient per day), insufficient number of events in file, or filesize to small. Video file: Report camera name, filename, start time and file size; Create warning if deviation from schedule, i.e., expected videos are not uploaded (16 per camera per day), or filesize to small. Checks: In addition, sanity checks have been defined which generate error messages on different levels, whenever the tasks have not been executed, i.e., if the expected files or data entries are not present. Dashboard: The data listed above, and all warnings and errors were collected in a dashboard, which provided a simple issue tracking system to mark recordings as erroneous or open issues as being solved.

4) Debugging: To enable a simple and fine-grained error tracing, we decided to build the pipeline using well known Unix/Linux file system tools. We used shell scripts automati- cally executed as cron-jobs to ensure a repeated execution, and the independence of different sub-tasks. Every shell script had a single specific purpuse and well defined results: entries in the corresponding log-files, submissions into the dashboard, creation of marker files to indicate completion of the task.

Relying on shell programming also allowed easy maintainance and debugging by remote access through ssh connections.

5) Organisational Aspects: The technical solution outline above was accompanied with different actions we took to brief the nursing staff and to organise the data acquisition workflow. All day-by-day work had to be done by the nursing staff. Therefore the daily tasks had to be as simple and as short as possible. For the briefing, we created manuals, short video sequences and step-by-step guides for each of the daily tasks. All hardware items were labelled with the patients? study IDs and color coded for (hand/foot, day/night) to simplify the process. We designed protocols to be filled out and signed by the nurses, to ensure we know which sensor was carried when by whom. This information has been used while postprocessing the data and checking the data integrity.



V. RESULTS AND LESSONS LEARNED  We recorded data of N=17 participants (11f , age: 81.2?5.4, GDS: 5.4?1.1) at two locations (N1=9, N2=8) over a period of 52 days (23d+29d). Other persons involved in the study were approximately 25 relatives, > 4 caregivers present at each time, 11 trained annotators during the study, 3 offline video annotators, 5 computer scientists, and additional on-site personnel. We collected >124 GB of compressed sensor data (accelerometer, gyroscope, temperature, force, barometric pressure, heart-rate, ambient noise and light) at a sampling rate up to 100 Hz (i.e. 5,591,077,401 values for an accelerometer). 1, 342 entries have been made in the wearing protocols, making a total 13,978.1 hours of verified sensor recordings (15,804 hours theoretically possible). We recorded 1.6 TB of video from 4 cameras on the second location (1,076.5h of 1,102h possible). Online annotation was done every day from 9am to 1pm and 3pm to 7pm in 5 min intervals, resulting in 52.231 annotated intervals. To assess annotation quality by means of interrater reliability about 5% of the 5 min intervals were observed by two independent observers.

Although high quality annotated experimental data is seen as a crucial requirement for training and evaluation, very few information can be found wrt. conducting such experiments and lessons learned. Based on our experiences, we tried to pin down our findings in form of more general requirements.

While the external parameters may be individual for each study, the following requirement categories should be applica- ble to many areas and are a check list for future use.

1) Installation and Hardware: Portability: The hardware installation must be convenient to transport, install and dein- stall. It should also be reusable in multiple installations without major alterations while being flexible enough to adapt to differ- ent settings. Minimally Invasive: The installation has to leave the existing IT infrastructure untouched. Building alterations, rewirering, or drilling have to be omitted where possible. All alterations have to be fully reversable. Safety: Environmental installations and wearable devices have to be designed that the risk of accidents or other hazards should be minimal. This is of fundamental significance due to the special health and mental condition of the study participants. Devices should be medically certified where applicable. Robustness: Devices and installation need to be robust enough for rough daily handling and cleaning. Identification markings should not be removable.

Size: The size and weight of the wearable devices should be as small as possible. A bulky form factor would significantly reduce the acceptance of the participants. Individualisation: The wearable devices have to be preconfigured to match the individual physique of the participants.

2) Recording Software: Robustness: Software and pro- cesses design should assure operation over the whole recording period. Prescheduled automatic tests should report errors or occurring problems. Security: Mal-operation must not af- fect the installation and already recorded data. User account restrictions and data storage permissions must be applied where possible. Emergency Shut Down: especially for the     video recording, is required to avoid potentially embarrassing behaviour being caught on camera. It has to be ensured that the recording can and will be restarted afterwards. Re- mote Support: The installation must be fully diagnosable and controllable from remote to assure immediate intervention and assistance in case of error. It should also be possible to reprogram the wearable devices if necessary. Parallelism: The software and background processes must be capable of handling and charging all devices at the same time.

3) Data: Volume and Bandwidth: With an expected daily amount of data in a scale of gigabytes efficient processing, compression, and sufficient storage has to be provided. For data transfers between the study site and research servers only very limited bandwidth is available. Data transfers also must not interfere with normal operation at the nursing homes. Raw Data: Due to the value of the recordings as much data as possible should be recorded without aggregation and other further processing. This prevents potential data loss through malfunctioning algorithms and unwanted artefacts. Also this enables researchers to look for patterns in the data not thought of beforehand and formulate new research questions. Privacy: No personal information which allows to affiliate sensor data to individuals must be stored at any point. Sensor devices and participants must use pseudonyms to ensure privacy and a double blind analysis. In case of hardware or data theft no personal information should be derivable. Uploading data to a cloud is not allowed. Encryption: For storage and transfer all data has to be strongly encrypted immediately after offload / recording. Decryption must be impossible on the test site only. Validity: For every data it has to be recorded by whom and where the sensor was worn. This, has to be signed by caregivers and intermediately be controlled. It should also be visible in the data, whether a sensor was worn or not. Integrity: The risk of losing data during recording and transfer or due to hardware failure should be minimised. To ensure that all files remain unaltered signatures must be used. Annotations: To detect and minimise annotation errors, consistency and statistical interrater tests must be performed.

4) Workflow: Integration: The processes needed for han- dling the technical equipment should limit the additional burden on the caregivers. Attaching and detaching the sensors should integrate into the usual daily workflow and not irritate the participants. Offloading and recharging should work fully unattended. No Interaction: Recharging, recording, offloading data, device initialisation, and data transfer should not require any manual interaction with the software and have to be scheduled and managed automatically. Also a restart of the installation must be possible without manual assistance. The caregivers do not have any technical or scientific expertise.

Timely Evaluation: To detect errors and recording related problems as early as possible the recordings, protocols, and annotations should be monitored daily by the researchers for immediate feedback. Automated checks and reports should be applied where possible. Real-time Annotation: Due to the lack of video material from the first site live annotation is needed. Standardized and established methods should be used  where applicable for validation and comparison reasons and use a predefined ontology. The annotation process should be as unobtrusive as possible to limit influences on the behaviour.

Pre and Post Tests: Standardised cognitive tests have to be performed before and after each period of recording. This al- lows for identifying external factors and detecting behavioural changes during the study which may affect results later.



VI. DISCUSSION AND OUTLOOK  Currently we are wrapping up our hard and software to build an out-of-the-box recording solution for future experiments and other researchers. A third study is planned for 2017 and also a concluding field study for evaluating the prototypical assistive system at the end of the project will be conducted.

The dataset we collected is currently further enhanced by detailed video annotation for selected challenging behaviours on a per second basis for the second nursing home. This gives us the opportunity for very fine-grained training and evaluation of our recognition engine. More detailed results of the data analysis (sleeping disorder recognition, correlation of motion behaviour and level of impairment, identification of challenging behaviour) are under preparation. We believe other researchers confronted with similar tasks will find our reported configuration and experiences helpful and can it as a preparation guideline to avoid pitfalls.

