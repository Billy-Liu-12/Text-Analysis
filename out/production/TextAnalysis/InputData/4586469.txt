A Density-based Quantitative Attribute Partition Algorithm for Association Rule Mining on Industrial Database

Abstract? Quantitative attribute partition is an important work of association rule mining, which is widely applied in industrial control at present, and the current partition methods are not suitable for the industrial database, which is generally large, high-dimensional and coupling. The paper proposes a density-based quantitative attribute partition algorithm for industrial database. The proposed algorithm uses an improved density-based clustering algorithm to detect the clusters. The clusters are agglomerated to form the new clusters according to the proximity between clusters and the new clusters are projected into the domains of the quantitative attributes. So the fuzzy sets and the membership functions used for partition are determined. We performed the experiments on a test database and a real industrial database. The experiments results verify the proposed algorithm not only can partition the quantitative attributes of industrial database successfully but also has the higher partition effectiveness.



I. INTRODUCTION  ASSOCIATION rule mining is useful for discovering in-teresting association or correlation relationships hidden in large data sets [1]. For industry process, we can use it on field data to extract some unknown knowledge and many studies of this work have been introduced recently, such as, the identification of the fuzzy model of a controlled plant, the establishment of the control rules bases and the determination of the operation optimization values [2]-[6]. Therefore, the development of association rule mining will be benefit for a future control design of supervisory controller in order to optimize the plant performance.

Apriori is a classical algorithm of association rules mining and it is to the binary databases, in which values of each attribute are Boolean [7]. However, many variables of an industrial process are quantitative, so the algorithm can not be used directly. Reference [8] presents the quantitative association rules mining, which partitions the value of the quantitative attributes, and the quantitative association rule problem is mapped into the Boolean association rule prob- lem. To deal with the problem ?sharp boundary?, which may under-emphasize or over-emphasize the elements near the boundaries of intervals, fuzzy sets are used in quantitative  The research is financially supported by National High Technology Research and Development Program of China (2006AA04Z180).

Hui Cao is with The Electrical Engineering School of Xi?an Jiao Tong University, Xi?an, Shaanxi, 710049, P. R. China (corresponding author to provide phone: +86-029-82668666-212; fax: +86-029-83237910; e-mail: huicao@mail.xjtu.edu.cn).

Gangquan Si is with The Electrical Engineering School of Xi?an Jiao Tong University (e-mail: gangquan@mail.xjtu.edu.cn).

Yanbin Zhang is with The Electrical Engineering School of Xi?an Jiao Tong University (e-mail: ybzhang@mail.xjtu.edu.cn).

Lixin Jia is with The Electrical Engineering School of Xi?an Jiao Tong University (e-mail: lxjia@mail.xjtu.edu.cn).

attribute partition process [9]. In this process, a database containing quantitative attributes is replaced by one with values from [0,1]. However, because the fuzzy sets are always provided by domain experts, it is difficult to know the fuzzy sets will be appropriate. Reference [10] presents that the fuzzy sets can be determined automatically from data by using clustering techniques and a model-based clustering algorithm, CLARANS, is adopted. Reference [11] and ref- erence [12] use k-means and c-means, which are also the model-based clustering algorithm, to discover the clusters.

Since there is not a suited model for industrial data, the algorithms can not be used effectively. Reference [13] adopts the CURE algorithm, which is a hierarchical clustering method, and it can not undo the completed step and correct erroneous decisions. Moreover, the clustering result of CURE mainly relies on the representative objects, and we can not estimate that the representative objects are correct. Reference [14] presents the notion of ?density? and uses the grid- based method to capture the characteristics of quantitative attributes. Nevertheless, since creating a grid structure for high-dimension database is difficult, the algorithms can not be fit for the industrial database.

This paper proposes a density-based quantitative attribute partition algorithm for association rule mining on industrial database. The proposed algorithm uses an improved density- based clustering algorithm to detect the clusters in industrial database. The clusters are agglomerated to form the new clusters according to the proximity between clusters and the new clusters are projected into the domains of the quantitative attributes. So the fuzzy sets and the membership functions used for partition are determined. The organization of this paper is as follows. In section II, some related works are discussed. The proposed algorithm is explained in detail in section III. In section IV, the experiments are presented to verify the effectiveness and the practicability of the proposed algorithm. Finally, section V concludes the paper.



II. RELATE WORK  Density-based clustering locates region of high density that are separated from one another by regions of low density.

DBSCAN is an effective density-based clustering algorithm and it is based on the concept of dense areas to form data clustering [15]. DBSCAN can handle the clusters of arbitrary shapes and it is relatively resistant to the outliers. Industrial database is used to record the values of the variables of an industrial process. If a variable is deemed as an attribute of an object, namely, a dimension of the database, the industrial database is high-dimensional because an industrial  2008 American Control Conference Westin Seattle Hotel, Seattle, Washington, USA June 11-13, 2008  WeAI02.4  978-1-4244-2079-7/08/$25.00 ?2008 AACC. 75    process generally includes many variables. Moreover, some variables of industrial process are nonlinear and coupling mutually. Therefore, the industrial database is large, high- dimensional, coupling and complex. Using DBSCAN on industrial databases directly would result in some mistakes because the distances between objects become more uniform in high dimensional data sets [16]. To deal with this issue, reference [16] uses shared nearest neighbor(SNN) similarity as the measure of distance metric between objects. Let p and q are two objects and if and only if they have each other in their k-nearest neighbor lists. Their SNN similarity is defined by the following equation:  SNNsimilarity = size(NN(p) ?  NN(q)) (1)  where NN(p) and NN(q) are the k-nearest neighbor lists of p and q, respectively. size(?)is the operator for calculating the size of data set.

SNN similarity provides us with a more robust measure of similarity and it works well for data with high dimension.

However, in SNN similarity approach, calculating the k- nearest neighbor list of an object is based on the distance be- tween objects and Euclidean distance are generally adopted as the distance metric, so the coupling of industrial database would affect the results. We cite some examples to explain that.

Let D be a three-dimension industrial database, and the three dimensions are d1, d2, and d3, respectively. d2 and d3 are coupled with each other. An object in D can be written as {vd1, vd2, vd3}, and vdi is the value of the i-th dimension of the object.

Example I: Let p, q1, and q2 are three objects in D, which are {0, 0, 0}, {0, 1, 1} and {0,  ? 2, 0}, respectively. Because  dist(p, q1)=dist(p, q2)=2, q1, and q2 may be deemed as the neighbor of p. However, because d2, and d3 are coupled with each other, namely, in general, d2, and d3 may reflect the same system state in industrial process. Therefore, according to the experience of experts, q1 is more ?close? to p,. The reason of this contradiction is the duplicating calculation of d2, and d3.

Example II: Let p, q1, and q2 are three objects in D, and they are {0, 0, 0}, {1, 10, 10} and {2, 9, 9}, respectively.

dist(p, q1)=14.18 and dist(p, q2)=12.88, so we can estimate that q2 is more close to p. Nevertheless, in industrial process, compared with other variables, some variables reflect the system state more clearly. In this example, q1 is more close to p actually. The reason is that the absolute figure of vd2 and vd3 are larger than that of vd1, so vd1 is almost ?ignored? in the process of computing the distance between objects.

In general, after the clusters are detected, the fuzzy sets used for quantitative attribute partition are determined. Then, the clusters are projected into the domains of a quantitative attributes to identify the partition interval and establish the membership functions. However, since projecting the clusters would form some overlap intervals, identifying the membership value of an object based on the intervals will make some mistakes, and we cite example III to explain that.

Example III: D is a two-dimension databases and a and b are the two dimensions of D, that is shown in Fig.1. C1 and C2 are two clusters and projecting them into attribute a forms two intervals [l1, u1] and [l2, u2], respectively. c1 and c2 are two objects in C1 and C2, respectively. ca1 and c  a  are the projections of c1 and c2 in attribute a, respectively.

Therefore, for the attribute a, the general algorithm will determine that the membership values of c1 equals that of c2.

However, since they belong to different clusters, they need be distinguished in partition process, otherwise the results of future association rule mining will be wrong.

Fig. 1. Projecting the clusters into the attribute a.



III. THE ALGORITHM  In this section, we describe our algorithm for partitioning quantitative attribute. The proposed algorithm is divided into several phases, where phase I is a clustering process of the improved density-based clustering algorithm, phase II is agglomerating the clusters, detected in phase I, to form the new clusters and calculating the centroids of the new clusters, and phase III is establishing the membership functions based on the projections of the new clusters and identifying the membership values of each quantitative attribute of the objects.

Let D={D1, D2, ? ? ? , Dn} be an industrial database, n is the number of objects. Di is an object in the database. If the number of dimensions of D is m, then Di can be presented as follows:  Di = {vii , vi2, ? ? ? , vim}  where vji , j = 1, 2, ? ? ? ,m, is the value of the j-th dimension of the ith object.

We assume that a and b, a ? [1,m], b ? [1,m], a 6= b, be a pair of coupling dimensions of D, where the coupling dimensions is the dimension which is coupled with other dimensions in industrial database.

Phase I Step1: Calculating the fuzzy weighted distance between  objects [17].

Let p and q are two objects in D, the weighted distance     between them is defined by:  wdist(p, q) =  ???? m? j=1  wj(v p j ? v  q j )  2 (2)  where j = 1, 2, ? ? ? ,m. wj is weight of j-th dimension.

Although the weights of the dimensions are generally set  beforehand, the weights of the coupling dimensions would be adjusted according to the objects in database, which reflects the working states of the industrial process. The approach of weight adjustment is based on the fuzzy control strategy.

Let vpa and v q a represent the value of p and q in a,  respectively, then the absolute distance between of p and q in a is adpqa = |vpa ? vqa|. In like manner, ad  pq b represents  the absolute distance between p and q in b. ADa and ADb are linguistic variables of adpqa and ad  pq b , respectively, and  the set of them is {ZO, PS, PM, PB}, where ZO, PS, PM, and PB represent zero, positive small, positive middle, and positive big, respectively.

Let w ??  a and w ??  b are the adjusted weights of a and b. W ??  a  and W ??  b are linguistic variables of w ??  a and w ??  b , respectively.

The set of W  ??  a and W ??  b are adopted as {NB, NS, ZO, PS, PB}, where NB, NS, ZO, PS, and PB represent negative big, negative small, zero, positive small, and positive big, respectively. The fields of ADa and ADb is [0,1] and that of W  ??  a and W ??  b is [-1,1]. Based on the knowledge and the experience of experts, the discrete values of membership respected to them are assigned and a series of fuzzy logic rules can be obtained. For example,  Rules I: IF ADa is PS and ADb is PS, THEN W ??  a is NB and W  ??  b is ZO.

The max-min algorithm is used in fuzzy logic inference,  and the defuzzification is accomplished by the largest of maximum method. So, the querying table of adjusted weights can be calculated during the period of design, which is shown as Table I.

TABLE I QUERYING TABLE OF ADJUSTED WEIGHTS  IF THEN adpqa ad  pq b w  ?? a w  ?? b  0 0 0 0 0 0.3 0 -0.5 0 0.7 0 -0.5 0 1.0 0 -1.0 0.3 0 -0.5 0 0.3 0.3 -1.0 0 0.3 0.7 -1.0 0.5 0.3 1.0 -1.0 1.0 0.3 0 -0.5 0 0.7 0.3 0.5 -1.0 0.7 0.7 -1.0 0 0.7 1.0 -1.0 0.5 1.0 0 -1.0 0 1.0 0.3 1.0 -1.0 1.0 0.7 0.5 -1.0 1.0 1.0 -1.0 0  In actual clustering process, w ??  a and w ??  b can be obtained directly by querying the table. The weights, wa and wb, can  be figured out with the following equation:  wj = w ?  j + kwj ? w ??  j (3)  where j = a, b, w ?  j is the initial weight, and kwj is adjusted weight coefficients, which can let the range of w  ?  j to be set with considering actual demand. Finally, the fuzzy weighted distance between objects can be gotten.

Step2: According to the fuzzy weighted distance between objects, k-nearest neighbor lists of each object in D are established.

Step3: Calculating the SNN similarity between objects, and the pseudocode of this step as follow:  01 IF two objects, x and y are not among the k-nearest neighbor lists of each other THEN  02 SNNsimilarity(x, y)=0 03 ELSE 04 SNNsimilarity(x, y)=number of shared neighbors 05 END IF  Step4: Performing the clustering process, that is similar as that of DBSCAN. The algorithm begins with the arbitrary object o in industrial database D, and retrieves all neighbors of o, whose SNN similarity between them and o is greater than Eps. In the proposed algorithm, Eps is a threshold of SNN similarity between objects. If the number of neighbors is greater than MinPts, a cluster is created. The point o and its neighbors are assigned into this cluster. Then, let the neighbors be the expand objects to iterate the same process until all of the points have been labeled.

Step5: Collect the clusters and output.

Phase II The improved density-based clustering algorithm, men-  tioned in phase I, is more suitable for industrial data and it provides a more reasonable basis for forming the fuzzy sets, which are used in quantitative attribute partition. However, the number of clusters detected by phase I is not limited.

More is the number of clusters, more is that of linguistic terms. It would increase the time complexity of the future association rule mining. To treat with the problem, we agglomerate the clusters based on the proximity between clusters. The proximity between clusters usually includes three different metrics, MIN, MAX and Group Average, come from a graph-based view of clusters. MIN defines cluster proximity as the proximity between the closest two objects that are in different clusters. MAX takes the prox- imity between the farthest two objects in different clusters to be the cluster proximity, and Group Average defines cluster proximity to be the average pairwise proximities of all pairs of objects from different clusters. In phase II, we choose Group Average as the proximity between clusters and the proximities of a pairs of objects is the SNN similarity between objects, which has been calculated in phase I. The steps of phase II as follows:  Step1: If the number of clusters is greater than ck, then do the next step, otherwise, got to Step 5, where ck is a integer and the threshold of the number of clusters.

Step2: Calculating the Group Average between clusters.

Step3: Agglomerating the nearest two clusters to form the  new cluster, and updating the information of the clusters.

Step4: Repeating Step1 to 3.

Step5: Calculating the centroids of the clusters.

Let the j-th cluster Cj={d1, d2, ? ? ? di} be a set of objects  and s is the number of objects in Cj . The centroid of Cj is denfined as  Cj = s  s? r=1  dr (4)  Step6: Output the new clusters and the centroids of them.

Phase III In phase II, a set of clusters {C1, C2, ? ? ?Cck} are detected,  and in phase II, we use them as the linguistic terms for establishing the fuzzy membership functions, namely, the fuzzy set is {C1, C2, ? ? ?Cck}.

We project the clusters into the domains of the h-th quantitative attribute, where h ? [1,m], and the projections of the clusters will form the intervals. [lhg , u  h g ] represents  the interval formed by the projections of Cg in the h- th quantitative attribute. cg is the centroid of Cg and its projection in the h-th quantitative attribute is chg , where g ? [1, ck] and chg ? [lhg , uhg ]. The triangular function is adopted as membership function, and lhg , u  h g and c  h g are the  leftmost value, the rightmost value and the center value of the triangular membership function, respectively, that are shown in Fig.2. For the h-th quantitative attribute, the membership function of an object belonged to the linguistic term Cg can be defined as  fhcg (x) =  { (x ? lhg )/(chg ? lhg ) lhg ? x ? chg (uhg ? x)/(uhg ? chg ) chg ? x ? uhg (5)  Fig. 2. Membership function of the linguistic term Cg in the h-th quantitative attribute.

To avoid the mistakes of example III in section II, we use the weighted membership function. For the h-th quantitative attribute, the weighted membership function of an object belonged to the linguistic term Cg is defined as  wfhcg (x) = w h cg ? f  h cg (x)  = SNNsimilarity(x, cg)  ck? r=1  SNNsimilarity(x, cr)  ? fhcg (x) (6)  where wcg is the weight of the linguistic term Cg and it represents the relationship degree between the object and the linguistic term Cg .

In the same way, we can establish the weighted mem- bership functions of other linguistic terms in the h-th quantitative attribute, namely, we finish partitioning the h- th quantitative attribute. After all quantitative attributes in industrial database are partitioned and the weighted member- ship functions of them are established, so we can perform the quantitative association rule mining algorithm to find a set of association rules. For example,  IF attribute a ? C1 and attribute b ? C2, THEN attribute c ? C3.

In the following, we analyze the time complexity of the proposed algorithm. The time complexity of calculating SNN similarity is O(n2), and the time complexity of querying table and recomputing the weights are both O(1), which is smaller than that of other steps. Moreover, the complexity of DBSCAN is O(n2) also, so the time complexity of phase I is O(n2). The complexity of the agglomerating algorithm is O(n2) and the complexity of calculating the centroids is O(n2), then the time complexity of phase II is O(n2). In addition, the complexity of phase III is O(n). Therefore, the time complexity of the proposed algorithm is O(n2).



IV. EXPERIMENT EVALUATION  To evaluate the proposed algorithm, experiments are done on a test database and a real industrial database. The test database is a three-dimension database and the number of objects of the database is 100. Moreover, the second dimension and the third dimension of the test database are a pair of coupling dimensions. The fuzzy c-means algorithm and the proposed algorithm are used on the test database and we compare the partition effectiveness based on the clustering results of them. At first, we use the fuzzy c- means algorithm on the test database and k is set as 3.

The clustering result is illustrated in Fig.3. There are three clusters marked by ?+?, ???, and ???, respectively, and the centroids of them are also marked. Since all objects are labeled as different cluster by this method, some far point, who have higher outlier-ness, affect the clusters and the calculating cluster centroids. The cluster ?+? and the cluster ??? are much near and some objects in boundary between the two clusters are not evaluated clearly. In addition, in fuzzy c-means algorithm, the initial objects chosen randomly also affect the final results.

On the same test database, we use the proposed algo- rithm to form the clusters. The initial weights of the first dimension, the second dimension, and the third dimension are 0.3, 0.35, and 0.35, respectively. The adjusted weight coefficients of the second dimension and the third dimension are both set as 0.35. Table I, which was shown in section III, is used as the querying table of adjusted weights. The     Fig. 3. Clustering result of fuzzy c-means algorithm on test database.

parameter k of k-nearest neighbor list is set as 4. Both Eps and MinPts are 3, and ck is set as 3. The clustering result is shown in Fig.4. Three clusters are marked by ?+?, ???, and ???, respectively, and the centroids of them are also marked. Moreover, the outliers are marked by ???.

Compared with Fig.3, the outliers can be detected and they can not impact the clustering result. The boundaries of three clusters are distinct and all objects are estimated correctly.

Therefore, the clustering result of the proposed algorithm is more reasonable. Based on this clustering result, the partition for quantitative attributes would be more proper.

Fig. 4. Clustering result of the proposed algorithm on test database.

The experiments on a real industrial database are presented to verify the effectivity of the proposed algorithm. The real database is the database of the Pulverizing System of Power Plant, which is used to record the service data. To facilitate our experiment, we simplify the real database. The simplified database includes five dimensions, the ball mill load, the mill current, the outlet temperature, the entrance negative pressure, and the inlet-outlet pressure difference, and they are all quantitative attributes. The initial weights of them are set as 0.3, 0.2, 0.1, 0.2, and 0.2. Since the entrance negative pressure and the inlet-outlet pressure difference is a pair of coupling dimensions, the querying table of adjusted weights, which is shown in Table I, is used for them, and the adjusted weight coefficients of them are set  as 0.2. The parameter k of k-nearest neighbor list is set as 4. Eps and MinPts are 2 and 3, respectively, and ck is set as 3. We use the proposed algorithm on the simplified database with the number of objects increasing. During the experiment process, all parameters are not changed. The experiments results are shown in Table II. Since ck is 3, namely, there are three linguistic terms. We use [li, ui, ci]to represent the triangular membership function of the linguistic term RCi, where i = 1, 2, 3 and li, ui, and ci represent the leftmost value, the rightmost value and the center value of the triangular membership function, respectively. The parameters of membership function of the ball mill load are shown in the second column of Table II and all the parameters are normalized. With the number of objects increasing, the par- tition of the ball mill load becomes more reasonable and the increasing degree of running time satisfies the analysis of the time complexity mentioned in section III. The experiments results show that the proposed algorithm can partition the quantitative attribute of industrial database successfully and do not increase the algorithm complexity.

TABLE II EXPERIMENTS RESULTS OF THE PROPOSED ALGORITHM  Number of objects  Parameters of membership function of ball mill load {RC1; RC2; RC3}  Running time (sec.)  100 {[0.1954, 0.9577, 0.3596]; [0.2844, 1, 0.6269]; [0, 0.7668, 0.2388]}  0.0870  200 {[0.2844, 1, 0.6269]; [0.1843, 0.9577, 0.2780]; [0.0158, 0.7668, 0.2472]}  0.4676  400 {[0.2844, 1, 0.6269]; [0, 0.7668, 0.2518]; [0.0897, 0.9577, 0.2493]}  3.2827  600 {[0.2011, 0.9577, 0.3532]; [0.2928, 1, 0.6840]; [0,0.5787, 0.2489]}  10.8088  800 {[0.2928, 1, 0.6373]; [0.0158,0.5787, 0.2472]; [0, 0.3764, 0.2398]}  25.3868  1000 {[0.2537,0.8980, 0.4418]; [0.4515, 1, 0.7287]; [0, 0.5117, 0.2514]}  49.0990  2000 {[0.0986, 0.2751, 0.1860]; [0.2278, 1, 0.7484]; [0, 0.9750,0.49137]}  380.5010  3000 {[0.7540, 1, 0.8651]; [0.2278, 0.9111,0.7354]; [0, 0.9767, 0.5466]}  1261.0932

V. CONCLUSIONS  In this paper, a density-based quantitative attribute par- tition algorithm for association rule mining on industrial database is proposed. The proposed algorithm has some advantages as follows. First, it can partition the quantitative attributes of industrial database effectively. Second, it uses the SNN similarity based on the fuzzy weighted distance between objects to instead of the general distance metric, and the approach is more suitable for the industrial databases.

Third, it agglomerates the detected clusters to identify the fuzzy sets for quantitative attributes partition, and decreases the complexity of the future association rule mining process.

Fourth, based on the projections of clusters, the proposed algorithm can establish the triangular membership functions of quantitative attributes conveniently. Fifth, in the proposed algorithm, the weighted membership functions is defined, and it determines the membership value of an object more     reasonably. The experiments results also verify the effective- ness of the proposed algorithm and the time complexity are not increased. Since our work is partitioning the quantitative attributes of industrial database, we would integrate the proposed algorithm and the quantitative association rule mining algorithm to further verify the partition effectivety in our future work.

