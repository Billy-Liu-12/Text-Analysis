- 121 -

Abstract: A lot of papers have studied how to select accurate association rules for the users, and most of them make use of efficient statistical measurements, such as support, confidence, chi-square, lift, collective strength, and so on. However, it is still an open question about how to select a more proper statistical measurement for a certain user to find association rules in a certain domain. Since different measurements consider different interesting aspects of the association rules, we propose a novel method, named RuleRank, combining these statistical methods, in order to provide an alternative with more flexibility and robustness for users. In order to capture the user?s interest more closely, we also integrate semantic similarity into RuleRank model. The simulation results show that RuleRank model could give satisfying results for the user.

Keywords: Nonlinear RuleRank, Association Rule, Genetic Network Programming, Semantic Similarity.

1. INTRODUCTION  Association rule mining has been a popular research topic for more than 10 years and various methods have been proposed for mining association rules efficiently.

However, most of the existing methods are focusing on the efficiency, but not enough on effectiveness. Usually, we could find thousands of, or even more, association rules by these methods, and there is a new challenge fac- ing us: how could we choose what we need?

Some researchers have tried many new approaches to  overcome the above problem by discovering significant patterns [1], evaluating the novelty of rules [2], extract- ing redundancy-aware top-k patterns [3], analyzing rule interestingness using OLAP operations [4], or selecting right interestingness measures [5]. Unfortunately, most of these methods rely on statistical measurements, and seldom consider the semantic knowledge behind the sta- tistical numerals. In the recent research [6], Mei et al.

interpret the discovered frequent patterns by generating semantic annotations with a context model, which mim- ics the structurized entities with semantic information in the dictionary. Our research is a little analogous to the re- search in [6] in the aspect of motivation, but the pathway is completely different.

In this paper, by borrowing the style of search engines,  we propose a novel method to rank the association rules for a person by inputting several interested keywords. We measure the interestingness not only by statistical infor- mation but also by semantic relations between rules and keywords. First of all, we?d like to discuss more about the critical ideas of interestingness.

Which rule is interesting? Many researchers have been making efforts to find the right statistical metrics for eval- uating the interestingness of association rules [4] [5] [7] [8] [9]. However, the statistical information, e.g., sup- port, confidence, lift, chi-squared, and so on, is usually not enough for measuring the interestingness. That is to say, it cannot be concluded affirmatively that the rule with higher support value is more interesting or the rule with  higher confidence value is more interesting. Sometimes, different measures may even provide conflicting informa- tion [5]. Tan et al. [5] also find that each measure has its own advantages and disadvantages and whether a mea- sure could contribute to the evaluation of interestingness depends on what kind of problem to solve. Liu et al [4] argue that a rule is only interesting in the context of other rules and each rule may not be interesting in many cases.

However, none of them have mentioned that the semantic knowledge behind the datasets could help building a new metric to evaluate the association rules.

In fact, we prefer to say that whether a rule is interest- ing or not depends on not only its statistical significance but also the users? choice. For example, we could mine many rules from the data about Volatile Organic Com- pounds (VOCs) and diseases caused by VOCs. Environ- mental scientists may be interested in how much concen- tration of Benzene is dangerous in indoor air, while lac- querers may want to know which paint is not suitable for office equipments. How could we decide which rule to be presented for the user? The method proposed in this paper aims to solve this problem by personalized ranking or selection. First, let the user specify the topics that he is most interested in, and the topics could be described by several keywords, like the keywords used in search engines. After that, we could find the most related asso- ciation rules according to the keywords, and these rules could be most interesting for the user.

In order to find the related association rules, we use semantic similarity to evaluate the relations between key- words and rules. An ontology should be built first to de- scribe the concepts and relationships in the domain for measuring the semantic relation and calculating the se- mantic similarity [10]. Although we introduce semantic knowledge to measure the interestingness of rules, it does not mean that we give up all the statistical information which measures rules widely and effectively to a certain extent. In fact, we propose a new ranking method, named RuleRank, to combine the semantic knowledge and sta-  SICE Annual Conference 2008 August 20-22, 2008, The University Electro-Communications, Japan  PR0001/08/0000-0121 ?400 ? 2008 SICE    - 122 -  tistical information together to evaluate the rules based on Genetic Network Programming [11].

We have already proposed a linear RuleRank model in  [12] before, and in this paper we propose another non- linear RuleRank model, where the relations among the statistical measurements and semantic similarity are non- linear.

The rest of this paper is organized as follows. In Sec-  tion 2, we describe the problem by an example. In Sec- tion 3, we introduce some background knowledge, and we also give some notations and definitions which are used in this paper in Section 4. Nonlinear RuleRank is in- troduced in Section 5. Some simulation results are given in Section 6 . At last, we conclude this paper in Section 7.

PA PB PC PD PE PF PG PH sup conf lift chi sim  r1 1 2 4 7 4 3 3 2 7 8 5 10 7  r2 2 1 4 3 1 1 1 2 8 7 6 5 8  r3 3 2 4 2 4 3 3 5 10 9 9 1 1  r4 4 5 4 7 2 1 6 5 3 2 2 2 2  r5 5 2 4 1 2 3 2 1 1 5 7 4 3  r6 6 6 4 3 6 3 9 7 2 3 8 9 4  r7 7 9 1 3 6 8 6 9 4 10 3 3 9  r8 8 9 1 7 6 8 9 10 9 6 1 6 6  r9 9 6 4 7 6 8 3 2 6 1 10 8 5  r10 10 6 1 3 6 3 6 7 5 4 4 7 10  (a)Ranking of RULE SET1.

PA PB PC PD PE PF PG PH sup conf lift chi sim  r1 6 8 1 2 6 9 1 1 1 1 7 1 1  r2 6 8 2 5 6 9 2 3 3 2 6 2 2  r3 6 1 2 7 6 9 2 1 2 4 8 3 3  r4 2 11 4 7 6 1 7 10 11 3 5 4 8  r5 4 3 8 5 3 3 9 3 4 11 9 11 9  r6 1 3 8 2 5 1 7 10 5 8 11 8 5  r7 2 2 8 1 6 3 9 8 10 9 4 9 4  r8 6 3 4 7 1 3 5 3 8 6 1 6 6  r9 6 3 4 7 1 3 5 3 7 5 2 7 7  r10 4 3 8 2 3 3 9 8 9 7 3 5 10  r11 6 8 4 7 6 3 2 3 6 10 10 10 11  (b)Ranking of RULE SET2.

PA PB PC PD PE PF PG PH sup conf lift chi sim  r1 4 3 4 1 1 1 1 3 8 4 3 5 4  r2 4 10 4 6 4 9 5 9 10 7 2 8 5  r3 2 5 4 4 4 5 8 9 5 1 9 4 1  r4 4 5 3 6 4 1 5 5 6 5 5 3 2  r5 4 2 1 6 4 5 8 6 7 9 1 6 3  r6 4 3 4 2 3 5 3 1 4 10 10 7 10  r7 2 1 4 2 1 9 1 1 2 3 4 1 6  r8 4 5 2 6 4 1 4 3 3 2 7 9 7  r9 1 5 4 6 4 1 8 6 9 6 8 10 8  r10 4 5 4 4 4 5 5 6 1 8 6 2 9  (c)Ranking of RULE SET3.

PA PB PC PD PE PF PG PH sup conf lift chi sim  r1 4 1 2 1 4 9 4 1 1 6 6 6 4  r2 1 3 5 6 1 4 1 2 10 4 7 4 5  r3 1 3 5 6 1 1 6 5 3 5 4 5 2  r4 4 9 2 6 6 9 10 9 9 2 5 1 3  r5 4 9 2 2 6 4 9 9 2 3 9 9 8  r6 4 8 1 3 6 4 6 5 7 9 2 3 10  r7 4 3 5 3 1 1 1 2 4 10 1 10 6  r8 4 2 5 3 5 1 1 2 5 7 3 2 7  r9 1 3 5 6 6 4 6 5 8 1 10 7 1  r10 4 3 5 6 6 4 4 5 6 8 8 8 9  (d)Ranking of RULE SET4.

Fig. 1 Rankings by 8 persons and 5 measurements.

2. PROBLEM DESCRIPTION  Let?s describe the problem that we want to solve by an example.

We chose a census data from UCI KDD Archive [13]  to mine association rules by Genetic Network Program- ming [14], and built a simple ontology about the con- cepts and relations related to the census. 41 of them were selected and divided into four groups, denoted  as RULE SET1, RULE SET2, RULE SET3 and RULE SET4, which consists of 10, 11, 10 and 10 rules, respectively. A keyword was assigned to each group. The four keywords were: age, family, sex and income. There were totally 8 persons, denoted as PA, PB , PC , PD, PE , PF , PG and PH , who finished giving a score to each rule in the rule sets. Five kinds of measurement values of each rule were calculated, including support, confidence, lift, chi-squared value, semantic similarity between the rule and corresponding keyword, which were represented as sup, conf , lift, chi and sim, respectively. (Semantic similarity will be introduced later.) In the investigations, every person was asked to give  each rule a score between 1 and 5, where the rule with score 5 was most interesting. Then we ranked the rules, where the most interesting rule had the ranking value 1.

For example, if the first person, P1, has given scores to all the 10 rules in RULE SET1 and the set of score val- ues is {3, 3, 1, 4, 5, 3, 2, 5, 2, 1}, then, the set of ranking values is {4, 4, 9, 3, 1, 4, 7, 1, 7, 9}. By calculating the statistical and semantic information, we could give some other rankings of the rules. For example, if the set of support values of the 10 rules in RULE SET1 is {0.31, 0.52, 0.88, 0.59, 0.61, 0.85, 0.13, 0.26, 0.37, 0.70}, then, the ranking is {8, 6, 1, 5, 4, 2, 10, 9, 7, 3}.

Now, we could show the rankings by each person and  each measurement in Fig. 1(a), Fig. 1(b), Fig. 1(c) and Fig. 1(d) for each rule set. In the four figures, the smaller round means the more interesting association rule. We could see that most of the rankings are distinct from each other.

In order to show the difference between different rank-  ings more clearly, we calculate the Spearman?s rank cor- relation coefficient [15] between the ranked results by dif- ferent persons in Table 1, and the the correlation between the ranked results by each person and the ranked results by each measurement in Table 2. From Table 1, we could see that although there are some values more than 0.5, which means strong positive correlation, there are also many small values, or even negative values, which means the correlation is not strong positive or even negative.

From Table 2, we could see that most of the values are less than 0.5, and many of them are less than 0. As a result, if we let one person rank the rules for another per- son, or use only one measurement to rank the rules, the results are far from satisfaction.

In this paper, we propose a new method to rank the  rules, and the ranked results by our method and the ranked results by each person could be more strong posi- tively correlated.

3. NOTATIONS AND DEFINITIONS  Here are some formal definitions which are used in our method.

Definition 1 (Rule Similarity): Given the set of rules  RULE and keywords KEY , we define a new metric, Rule Similarity, to measure the semantic relation between every rule ruler and the keyword setKEY . Suppose we    - 123 -  Table 1 The correlations between ranked results by different persons  (a)Investigation of RULE SET1 PA PB PC PD PE PF PG PH  PA 1 0.56 0.75 0.76 0.8 0.58 0.57 0.40 PB 0.56 1 -0.10 0.43 0.78 0.73 0.81 0.81 PC 0.75 -0.10 1 0.47 0.39 0.15 0.03 -0.29 PD 0.76 0.43 0.47 1 0.56 0.46 0.41 0.14 PE 0.8 0.78 0.39 0.56 1 0.79 0.72 0.64 PF 0.58 0.73 0.15 0.46 0.79 1 0.38 0.4 PG 0.57 0.81 0.03 0.41 0.72 0.38 1 0.85 PH 0.40 0.81 -0.29 0.14 0.64 0.4 0.85 1  (b)Investigation of RULE SET2 PA PB PC PD PE PF PG PH  PA 1 0.35 0.13 0.75 0.75 0.73 -0.06 -0.29 PB 0.35 1 -0.2 0.37 0.59 0.10 -0.28 0.04 PC 0.13 -0.2 1 0.08 0.33 -0.35 0.91 0.68 PD 0.75 0.37 0.08 1 0.40 0.25 -0.01 -0.14 PE 0.75 0.59 0.33 0.40 1 0.572 0.13 0.33 PF 0.73 0.10 -0.35 0.25 0.57 1 -0.59 -0.70 PG -0.06 -0.28 0.91 -0.00 0.13 -0.59 1 0.69 PH -0.29 0.04 0.68 -0.14 0.33 -0.70 0.69 1  (c)Investigation of RULE SET3 PA PB PC PD PE PF PG PH  PA 1 0.56 0.81 0.64 0.85 0.31 0.30 0.27 PB 0.56 1 0.61 0.73 0.70 0.21 0.49 0.73 PC 0.81 0.61 1 0.54 0.8 0.44 0.33 0.35 PD 0.64 0.73 0.54 1 0.86 0.12 0.8 0.67 PE 0.85 0.70 0.8 0.86 1 0.25 0.69 0.56 PF 0.31 0.21 0.44 0.12 0.25 1 -0.06 0.10 PG 0.30 0.49 0.33 0.8 0.69 -0.06 1 0.78 PH 0.27 0.73 0.35 0.67 0.56 0.10 0.78 1  (d)Investigation of RULE SET4 PA PB PC PD PE PF PG PH  PA 1 0.43 0.56 0.4 0.69 0.47 0.19 0.38 PB 0.43 1 -0.07 0.27 0.57 0.29 0.74 0.86 PC 0.56 -0.07 1 0.8 0.32 0.01 -0.16 0.13 PD 0.4 0.27 0.8 1 0.44 0.25 0.27 0.49 PE 0.69 0.57 0.32 0.44 1 0.54 0.57 0.65 PF 0.47 0.29 0.01 0.25 0.54 1 0.43 0.30 PG 0.19 0.74 -0.16 0.27 0.57 0.43 1 0.89 PH 0.38 0.86 0.13 0.49 0.65 0.30 0.89 1  have J items in ruler andK keywords inKEY , the Rule Similarity could be calculated as:  SIM(ruler,KEY ) =  ?J j=1  ?K k=1sim(itemrj , keyk)  J ?K , (1)  where sim(itemrj , keyk) is the semantic similarity be- tween concept itemrj and keyk.

Definition 2 (RuleRank): RuleRank is the name of  the model proposed in our research. Given a set of associ- ation rules, the RuleRank model ranks these rules by both semantic information and statistical information. There are two kinds of RuleRank: Linear RuleRank and Non- linear RuleRank. For Linear RuleRank, the ranking value is calculated by a linear equation, while for Nonlinear RuleRank, the ranking value is calculated by a nonlinear equation.

Definition 3 (Linear RuleRank): The Linear RuleR-  ank model has been studied in [12], so in this paper we set it as a comparison of the nonlinear model. Suppose  Table 2 The correlations between ranked results given by different measurements and different persons  (a)Investigation of RULE SET1 PA PB PC PD PE PF PG PH  sup 0.19 -0.12 -0.01 0.29 0.23 0.10 -0.13 0.02 conf 0.08 -0.13 -0.09 -0.17 0.15 0.03 -0.15 0.12 lift 0.02 -0.46 0.34 -0.17 0.18 -0.12 -0.41 -0.67 chi 0.33 0.07 0.05 0.38 0.46 0.07 0.19 -0.20 sim 0.33 0.30 -0.27 0.11 0.40 0.18 0.09 0.19  (b)Investigation of RULE SET2 PA PB PC PD PE PF PG PH  sup -0.09 -0.02 0.50 0.14 0.03 -0.82 0.65 0.62 conf 0.00 -0.49 0.74 0.04 0.05 -0.67 0.57 0.13 lift 0.08 0.07 0.14 0.05 0.55 -0.00 -0.17 -0.14 chi 0.01 -0.40 0.68 0.13 0.01 -0.75 0.54 0.12 sim 0.12 -0.02 0.50 0.35 -0.04 -0.76 0.46 0.18  (c)Investigation of RULE SET3 PA PB PC PD PE PF PG PH  sup 0.10 0.46 0.16 0.40 0.17 -0.29 0.36 0.46 conf 0.28 0.10 0.13 0.23 0.21 0.04 0.19 -0.01 lift -0.01 0.07 0.30 0.10 0.21 -0.43 0.20 -0.11 chi 0.11 0.42 0.09 0.49 0.28 -0.48 0.37 0.16 sim 0.13 0.06 0.26 0.06 0.10 -0.09 -0.15 -0.41  (d)Investigation of RULE SET4 PA PB PC PD PE PF PG PH  sup -0.12 0.13 0.23 0.64 0.19 0.01 -0.10 0.12 conf 0.27 -0.32 0.17 -0.07 -0.07 -0.46 -0.70 -0.47 lift -0.12 -0.04 0.18 0.36 0.4 0.22 0.26 0.32 chi 0.05 -0.26 0.28 0.03 -0.01 -0.34 -0.23 -0.05 sim 0.34 0.21 -0.01 -0.08 0.33 -0.27 -0.26 0.01  we have some statistical information for rule ruler: sup- port value supr, confidence value confr, lift value liftr, and chi-squared ?2r , then the ranking value of rule ruler, RuleRank(ruler), is calculated as follows:  RuleRank(ruler) = w1 ? SIM(ruler,KEY )+ w2 ? supr + w3 ? confr + w4 ? liftr + w5 ? ?2r,  (2)  where, wi (i = 1, 2, 3, 4, 5) is a parameter, 0.0 ? wi ? 1.0, and  5? i=1  wi = 1.

Definition 4 (Nonlinear RuleRank): Nonlinear RuleRank also utilizes statistical information and seman- tic information, and the ranking value of rule ruler is calculated by a nonlinear equation. Without loss of gen- erality, suppose an initial nonlinear equation is:  RuleRank(ruler) = (w1 ? SIM(ruler,KEY )+ w2 ? supr) ? (w3 ? confr + w4 ? liftr + w5 ? ?2r).

(3)  The parameter wi is also evolved simultaneously.

Definition 5 (Operator, Weight, Measurement and  Expression): For clarity, we also define four concepts which will be mentioned frequently in the Nonlinear RuleRank model. The operator is a symbol for mathe- matical calculation, including +, -,?,?,?x and x2. The weight is a real number between 0 and 1. The measure- ment contains both statistical and semantic measurements    - 124 -  of association rules, including support(also denoted by sup), confidence(also denoted by conf ), lift(also denoted by lift), chi-squared(also denoted by chi) and semantic similarity(also denoted by sim). The expression consists of operators, weights and measurements. One expression could also contain another expression. Each expression is a RuleRank equation in Nonlinear RuleRank model. We also use o, w, m and e as the abbreviations for operator, weight, measurement and expression, respectively.

4. NONLINEAR RULERANK MODEL  The Linear RuleRank has already been discussed in [12], so in this paper we do not explain how to evolve the Linear RuleRank by Genetic Algorithm. In this section, we introduce how to evolve the Nonlinear RuleRank by Genetic Network Programming, which is inspired by the research of Automatic Program Generation [16], and find the Optimal Equations. The general structure of evolving Nonlinear RuleRank is shown in Fig. 2.

4.1 Basic Structure  First of all, we introduce the general gene structure of a GNP individual when it is applied to evolve Nonlin- ear RuleRank. The GNP structure also consists of three kinds of nodes: Judgement Node, Processing Node and Start Node. The Judgement Nodes decide the branches of the transition , while the Processing Nodes generate the Nonlinear RuleRank equations. Besides three kinds of nodes, we also design a memory structure which is asso- ciated with each Processing Node. The memory structure is made up of four parts: Weight Memory, Measurement Memory, Operator Memory and Expression Memory.

J1 P1  J2  S  P2  w1 w2 w3 ... ... m1 m2 m3 ... ... o 1 o 2 o 3 ... ...

e1 e2 e3 ... ...

Gene Structure Node Connection Function  S J1 ?? ??  J1 P1 J2 ??  J2 P1 P2 ??  P1 J2 ?? o 2 m2 e2 w1  P2 J1 ?? o3 e 1 w 2 ?  Weight Measurement Operator  Express ion  Fig. 2 An example of evolving equations by GNP.

The Start Node indicates the place where the pro- gram starts. Each processing node is connected to sev- eral functional components, such as an operator in Oper- ator Memory, one or two weights in Weight Memory, one or two measurements in Measurement Memory, and one or two expressions in Expression Memory. Each judge- ment node is connected to Processing Nodes or Judge- ment Nodes. After executing the Judgement Node, one of the candidate nodes is selected as the next node to be ex- ecuted, and the transition policy of the Judgement Node  decides which candidate will be selected as the next ac- tive one.

Generally speaking, there are three kinds of transition  policies: Random Policy, Equal Policy and Prior Policy.

By Random Policy, the candidate node is selected ran- domly. When using Equal Policy, the candidate is se- lected one by one, and its sequence is decided by the se- quence of their unique ID in the database. When Priori Policy is applied, there should be criteria to evaluate the importance of each candidate node and the sequence is affected by its evaluation value. For example, we could evaluate each node by recording its contribution to the fit- ness value of the GNP individual. In this paper, we use Equal Policy for simplicity.

Here is an example to illustrate the general gene struc-  ture of GNP in Fig. 2. There are one Start Node(S), two Judgement Nodes(J1 and J2) and two Processing Nodes(P1 and P2). After S is activated, J1 will be the next active node. After J1 is executed, there are two pos- sible nodes, P1 and J2, to be the next one. By equal policy, we may select J2 at first. The following nodes are executed in the same manner. Obviously, this kind of transition may cause loops, and we import a parameter named Maximum Transition Steps to stop the loops after a certain number of transition steps. P1 is associated with an operator o2, together with a weightw1, a measurement m2 and an expression e2. After P1 is executed, a new ex- pression, i.e., e3, is generated as follows, for example: e3 = w1 ?m2 o2 (1-w1) ? e2, where o2 could be +, -, ?, or ?, andm2 could be sup, conf , lift, chi, or sim.

J1 P1  J2  S  P2 Crossover  J '1 P '1  J '2  S'  P '2  J1 P '1  J2  S  P2  J '1 P 1  J '2  S'  P '2  (a)Crossover.

J1 P1  J2  S  P2  Mutation of Node Connection  J1 P 1  J2  S  P2  (b)Mutation of node connection.

J1 P1  J2  S  P2  Mutation of Node Content  J1 P '1  J2  S  P2  (c)Mutation of node content.

w1 w2 w3 ... ...

Weight  Mutation of Weight w1 w'2 w3 ... ...

Weight  (d)Mutation of weight.

J1 P1  J2  S  P2  w1 w2 ... ... m1 m2 ... ... o 1 o 2 ... ...

e1 e2 ... ...

J1 P 1  J2  S  P2  w1 w2 ... ... m1 m2 ... ... o 1 o 2 ... ...

e1 e2 ... ...

Mutation of Memory Connection  (e)Mutation of memory connection.

Fig. 3 Genetic Operators.

- 125 -  4.2 Memory Structure  The memory structure of GNP is developed for gener- ating, storing and reusing the RuleRank equations. There are two kinds of memories: Static Memory and Dynamic Memory. The Static Memory will keep the same content during the whole evolutionary generations like Operator Part and Measurement Part, while the Dynamic Memory will be changed as the evolution goes on like Weight Part and Expression Part. The Weight Part will be changed only when the mutation operator is performed on GNP, which will be explained with more details in the follow- ing subsection. When a new generation starts, the con- tent of the Expression Part will be cleared, and during each generation, the newly generated expressions will be stored to the Expression Part.

4.3 Fitness Function  The fitness value of a GNP individual is directly affected by the Spearman?s correlation between a hu- man being?s ranking result and the ranking result given by the RuleRank equation generated by the GNP in- dividual. Suppose there are 10 rules RULE = {rule1, rule2, . . . , rule10} and a human being gives it a ranking, i.e., RANK ??1 = {3, 10, 2, 7, 6, 1, 4, 5, 8, 9}, where the value 1 means the according rule is the most in- teresting one, and 10 means the least interesting. Then, an GNP individual generates an RuleRank equation, and by calculating the RuleRank value, it gives another ranking, i.e., RANK ?1 = {4, 8, 1, 5, 6, 2, 7, 10, 9}. The Spear- man?s correlation value of RANK ?1 and RANK  ?? 1 is the  fitness value of the individual.

Usually, a GNP individual could generate more than one RuleRank equation, because during the tran- sitions of GNP nodes, each Processing Node could be executed for several times, and each time it could give a RuleRank equation. For example, a GNP individual generates 15 equations, and the equations give a set of rankings, RANK SET ? = {RANK ?1,1, RANK ?1,2, . . . , RANK ?1,15}. After calcu- lating the correlation between RANK ??1 and each ele- ment of RANK SET ?, we will have 15 correlation val- ues. There are three methods to calculate the fitness value by 15 correlation values: Average Method, Maximum Method and Minimum Method. By Average Method, the fitness value is equal to the average value of 15 corre- lation values, and by Maximum Method and Minimum Method, the fitness value is the maximum and minimum value of 15 correlation values, respectively. In this paper, we use the Maximum Method.

4.4 Genetic Operators  There are five kinds of genetic operators for evolv- ing GNP: crossover, mutation of node connection, mu- tation of node content, mutation of weight and mutation of memory connection, which are shown in Fig. 3(a), Fig. 3(b), Fig. 3(c), Fig. 3(d), Fig. 3(e) and Fig. 3(f), respectively.

5. PERFORMANCE EVALUATION  The simulations use the same data source and four groups of association rules introduced in Section 2.

RULE SET1 is used as the training set, while the other three rule sets are testing sets. First of all, We want to study how well the Linear RuleRank model and Non- linear RuleRank model perform. Using two RuleRank models for RULE SET1, the correlations between the ranked results by RuleRank model and the ranked results by human beings are shown in Table 3.

Table 3 The Correlations Between Ranked Results by RuleRank and Different Persons in the Training  PA PB PC PD PE PF PG PH Linear  RuleRank 0.42 0.48 0.54 0.78 0.15 0.46 0.49 0.33 Nonlinear RuleRank 0.43 0.83 0.38 0.76 0.68 0.56 0.73 0.66  Then, we make use of the RuleRank model trained by RULE SET1 to rank another three sets of rules as testing, and the results are shown in Table 4. Generally speaking, the correlation values are high, especially in the Nonlinear RuleRank.

Table 4 The Correlations Between Ranked Results by  RuleRank and Different Persons in the Testing  (a)Test Linear RuleRank  PA PB PC PD PE PF PG PH RULE SET2 0.28 0.45 0.28 0.3 0.57 0.57 0.18 0.46 RULE SET3 0.86 0.62 0.76 0.56 0.32 0.63 0.48 0.75 RULE SET4 0.27 0.20 0.64 0.50 0.31 0.50 0.31 0.52  (b)Test Nonlinear RuleRank  PA PB PC PD PE PF PG PH RULE SET2 0.68 0.66 0.86 0.69 0.72 0.52 0.86 0.83 RULE SET3 0.43 0.78 0.44 0.73 0.43 0.72 0.84 0.85 RULE SET4 0.41 0.73 0.63 0.77 0.67 0.64 0.75 0.69  In order to show clearly that the performance of RuleRank could exceed all other methods, we calculate the average value of the above data. In Table 5, we fig- ure out the average performance of each method, i.e., by one human being, by one measurement, by Linear RuleR- ank and by Nonlinear RuleRank. The top 8 lines of data show how well one person could rank the rules for the other 7 persons. The middle 5 lines show how well one measurement, including both statistical measurement and semantic measurement, could rank the rules for all 8 per- sons. The last two lines show how well the Linear RuleR- ank model and Nonlinear RuleRank model could rank the rules for all 8 persons. We could see that the Nonlinear RuleRank model and Person E could exceeds others in two rule sets, respectively, but the Nonlinear RuleRank model has the best average performance.

If we compare the overall performance of the four  kinds of ranking methods shown in Table 6, the advan- tage of RuleRank is much more obvious. The first line shows the average performance of all 8 persons if we let them rank the rules, and it is the average value of the top 8 lines of data in Table 5. The second line shows the average performance of all 5 measurements, which is the average value of the middle 5 lines of data in Table 5. The    - 126 -  Table 5 The Average Performance of Different Ranking Methods  RULE SET1 RULE SET2 RULE SET3 RULE SET4 avg.

PA 0.63 0.31 0.53 0.44 0.48 PB 0.57 0.14 0.58 0.44 0.43 PC 0.20 0.22 0.55 0.22 0.30 PD 0.46 0.24 0.62 0.41 0.44 PE 0.67 0.41 0.67 0.54 0.57 PF 0.50 0.01 0.19 0.33 0.25 PG 0.54 0.11 0.47 0.42 0.38 PH 0.42 0.08 0.49 0.53 0.38 sup 0.12 0.12 0.23 0.13 0.15 conf 0.04 0.04 0.14 -0.20 0.01 lift 0.07 0.07 0.04 0.19 0.09 chi 0.04 0.04 0.18 -0.06 0.05 sim 0.09 0.09 -0.01 0.03 0.05 Linear  RuleRank 0.46 0.39 0.62 0.41 0.47 Nonlinear RuleRank 0.63 0.73 0.65 0.66 0.67  last two lines show the performance of Linear RuleRank and Nonlinear RuleRank. The Nonlinear RuleRank has a significant advantage over all the other methods, while the Linear RuleRank is the second best one.

Table 6 The Overall Average Performance of Different  Ranking Methods  RULE SET1 RULE SET2 RULE SET3 RULE SET4 avg.

Person 0.50 0.19 0.51 0.42 0.4  Measurement 0.04 0.07 0.12 0.01 0.06 Linear  RuleRank 0.46 0.39 0.62 0.41 0.47 Nonlinear RuleRank 0.63 0.73 0.65 0.66 0.67  6. CONCLUSION  In this paper, we proposed a novel GNP based model, Nonlinear RuleRank, to rank association rules. The Non- linear RuleRank could generate equations which could be used to rank association rules for a person with satisfy- ing precision, and it could be even better than the Linear RuleRank proposed in our previous research.

