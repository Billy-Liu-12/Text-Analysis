Provenance Comparison for Large-Scale Knowledge Discovery

Abstract?Provenance is a record that describes entities and processes involved in producing, delivering and influencing a resource. Provenance management and reuse can enable interesting applications for knowledge discovery and analytics.

One crucial component of a provenance management system is the comparison between provenances. In the era of big data, provenance management systems are in need of a scalable algorithmic solution for efficient comparison. Existing solutions to the problem have large memory footprint and require overlong system response time. In this paper, we present a new solution to threshold-based provenance comparison. We model provenance directly as graph, and propose to measure provenance similarity using provenance edit distance. Following the depth-first search paradigm, we design an algorithm PEDSim based on an encoding technique specific to provenance graphs and quantifiable heuristics. Extensive experiments on real data demonstrate the superiority of our method to other alternatives.



I. INTRODUCTION  Provenance is a record that describes entities and processes for producing, delivering and influencing a physical or digital resource. It provides a crucial foundation for assessing authenticity, enabling trust, and allowing reproducibility.

Harvesting provenance from execution histories, we may be able to mine common computational structure or determine differences between executions [14]. Hence, such discovered knowledge can be used to suggest possible completions for partial workflows, summarize a set of approaches, or extend past work in new directions.

The importance of archiving not only data and results but also the lineage of these entities has led to a variety of systems that capture provenance. Despite significant work on obtaining and modeling provenance, however, there is still little work on using it [11]. In order to support knowledge discovery and reuse from collected provenance, the management of those provenance data has become of great importance. One critical component of a provenance management system is the comparison between provenance; that is, to determine the pairwise similarity or difference between provenances. With this comparison function, we can perform a number of knowledge-driven analytical tasks, e.g., finding alternative working procedures, suggesting better workflows, consolidating multiple operations, etc. We  ?Corresponding Author  investigate the problem of efficient provenance comparison for large-scale knowledge discovery in this paper.

Approaches for querying provenance are largely based on physical data representations, e.g., relational and XML schemas, where users express provenance queries through cor- responding query languages like SQL and XQuery. However, formulating a query in SQL or XQuery may not be an easy task for end-users. Thus, a recent trend is to utilize graphs to model provenance, and directly execute querying tasks on provenance graphs [14], [1]. This direct modelling requires less additional effort from an end-user of the provenance management system, enabling easier interaction among human, machine and system for large-scale knowledge discovery and analytics.

In order to compare provenances, i.e., to evaluate the similarity/difference between provenance graphs, there has not been a measure that receives wide consensus. By modelling provenances as graphs, an intuitive approach is to utilize the existing similarity measures for abstract graphs. To this end, constrained version of edit distance has been employed to measure the similarity between scientific workflows [2].

To make it applicable to general provenance, we propose the concept of provenance edit distance for measuring the similarity between provenance graphs. This novel concept is developed based on the graph edit distance, which is a well-known metric for expressing the differences between graphs on both vertices and edges [3]. As a consequence, provenance edit distance inherits the rigorous theoretical foundation, serving as a good metric specific to provenance.

Besides the merits, however, the intrinsic NP-hardness of edit distance [8] poses serious algorithmic challenges. An adapted solution to evaluating provenance graph similarity, i.e., provenance edit distance, is developed on the conventional A?- based algorithm [9]. Due to the design of A? search paradigm, it requires fairly large memory space, in addition to tedious system response time. Facing the era of big data, a vital aspect of a practical provenance management system is scalabil- ity [12], since all analytic tasks require a scalable infrastructure to support efficient query and accessible reuse. Thus, the rudimentary algorithm is unlikely to meet the need of current large-scale provenance management for effective reuse and knowledge discovery. This research addresses the challenge.

In this paper, we present a scalable algorithmic solution to provenance comparison. Particularly, we propose to      model provenance as graph, and formally define the provenance edit distance to measure the similarity between two provenance graphs. Moreover, to efficiently carry out threshold-based provenance comparison, we design a scalable algorithm following the depth-first search (DFS) paradigm. It involves an encoding technique specific to provenance, and incorporates several quantifiable heuristics to further expedite the searching process, and hence, improve the system response time. Comprehensive experiments suggest the effectiveness and efficiency of the solution.

In short, our contribution can be summarized as follows:  ? For provenance comparison, we propose a novel concept of provenance edit distance to measure the provenance graph similarity. The new measure captures both the labeling and structural differences on the vertices and arcs such that all provenance graphs can be compared universally.

? We propose a scalable algorithm PEDSim for efficiently evaluating threshold-based provenance similarity via PED.

It leverages an encoding technique specific to provenances, and incorporates a novel vertex selection and ordering heuristic to turbocharge the system performance.

? The effectiveness and efficiency of the proposed algorithm is demonstrated by experiment results on public real datasets, which outperforms other alternatives regarding both running time and memory footprint.

Note that in this paper we focus on comparing provenance exactly, and elaborate the in-memory implementation of the algorithms. The rest of the paper is organized as follows: We briefs the related work in Section II. Section III formally defines the problem, and reviews the current solution to the problem. In Section IV, we design a new algorithm that is scal- able to large provenance and datasets. Section V empirically evaluates the algorithm, followed by conclusion in Section VI.



II. RELATED WORK  Provenance similarity has been investigated under several scenarios. Due to the large size of provenance, a compression algorithm was proposed based on the process similarity of successors [21]. Akin to that, a family of similarity-based factorisation algorithms were devised to reduce the provenance storage [6]. The trustworthiness of data items based on the trace similarity was studied in [13]. Among others, a classifica- tion method was presented to detect provenance similarity of binaries [5]. A closely related work is [2], where an efficient algorithm was developed to compare two workflow executions conforming to the same workflow specification. We investigate the provenance similarity from a more general perspective.

Based on edit distance algorithms, a content-based approach was presented to automatically reconstruct provenance [15]. A system CTrace [14] was developed lately using the traditional maximum common edge subgraph (MCES)-based similarity measure. The system is able to detect the semantic similarity between vertex labels via an ontology. Albeit, CTrace does not lend itself to slightly larger provenance graphs due to the inherent inability of the algorithm. On the contrary, we conceive a scalable algorithm to large provenance in this paper.

Graph edit distance computation has been a research topic keeping receiving attention [8]. A widely accepted exact  solution to compute graph edit distance is based on the A?  search algorithm [9], which explores the space of all possible vertex-to-vertex mappings between two graphs by means of an ordered tree. With an estimation of the potential cost that is no larger than the real value, namely, admissible, an optimal solution from the root to a leaf is guaranteed to be found. So far, the fastest exact algorithm is credited to an A?-based algorithm incorporating a bipartite heuristic [16].

We compute the provenance edit distance using a depth-first search paradigm, disparate from all mentioned above. To render the matching process less computationally demanding, a number of approximate methods were proposed to find suboptimal answer [19], [7]. The basic idea is to perform local search to solve the problem [19]; i.e, to optimize local criteria instead of global optimum. Recently, the problem was also transformed into an assignment problem, and solvable by existing algorithms with sub-optimal results [7]. Another solution is to convert it to binary linear programming and compute the bounds of the real distances [10].



III. PROVENANCE EDIT DISTANCE  This section formally defines the basic concepts and the problem, and adapts a rudimentary solution to the problem with an in-depth analysis.

A. Problem Definition  In this paper, we model provenance as simple directed graph, namely, provenance graph, with neither self-loops nor multiple arcs. From now on, we may abbreviate ?provenance graph? to ?provenance? when there is no ambiguity.

Specifically, a provenance p is represented by a triple (V,A, l), where V is a set of vertices, and A ? V ?V is a set of arcs. l is a label function that assigns labels to vertices (and arcs). Vp denotes the vertex set of p, and Ap denotes its arc set.

Hence, |Vp| and |Ap| are the numbers of vertices and arcs in p, respectively. l(u) denotes the label of vertex u, and l(?u, v?) denotes the label of arc ?u, v? from u to v, u, v ? V . We use do(v) = |{ u|?v, u? ? A }| (resp. di(v) = |{ u|?u, v? ? A }|) to denote the out-going (resp. in-coming) degree of v.

Afterwards, we introduce a concept of provenance edit distance on top of the classic graph edit distance [3], [17].

Definition 1 (Provenance edit operation): A provenance edit operation is an edit operation to transform one provenance graph to another.

We consider the following operations in this paper:  ? Insert an isolated vertex into the provenance graph; ? Delete an isolated vertex from the provenance graph; ? Change the label of a vertex in the provenance graph; ? Insert an arc between two disconnected vertices in the provenance graph;  ? Delete an arc from the provenance graph; ? Change the label of an arc in the provenance graph; and ? Change the direction of an arc in the provenance graph.

Definition 2 (Provenance edit distance): The provenance edit distance (PED) between two provenance graphs p and p?, denoted by PED(p, p?), is the minimum number of provenance edit operations to transform p to p?.

A  CB1 B2  D  E  A  C2C1  D  E  p p'  Fig. 1. Example of Provenance Graphs  Example 1: Figure 1 abstracts two provenances p and p?, which are extracted from a scientific analysis workflow of protein annotation for inferring biological functions.

Subscripts are added for differentiation, while they correspond to the same task in the real data. It can be seen these two provenances are quite similar in terms of tasks conducted during the workflows. The provenance edit distance between p and p? is 4. One possible edit script is as follows: delete one vertex with label B and its incident arcs, and relabel the remaining vertex of B with C. This may suggest that, in order to achieve the same result, two B-tasks could be replaced by one C-task due to the same potential function.

It has been a recent trend to measure the graph similarity using edit distance [20], [22], as it cover a wide range of potential application including provenance [2]. In essence, edit distance used in [2] is a constrained version of provenance edit distance. In another word, the provenance edit distance proposed in this paper serves a more general purpose of provenance comparison. Furthermore, provenance edit distance can capture not only the structural difference but also the labeling diversity on vertices (and arcs) between provenances.

In addition, it is easy to verify the following result.

Lemma 1: Provenance edit distance is a metric.

Due to the aforementioned elegant properties, in this paper, we propose to use provenance edit distance to measure the similarity of two provenance graphs. We formally state the problem in Definition 3.

Definition 3 (Threshold-based provenance comparison): Given two provenance graphs and a provenance edit distance threshold, a threshold-based provenance comparison tests whether the two provenance graphs are similar, i.e., whether the provenance edit distance between the two provenance graphs exceeds the threshold.

The input of the problem is two provenance graphs p and p?, as well as a provenance edit distance threshold ? ; the output is a boolean ? being true if PED(p, p?) ? ? , and false otherwise.

B. A Rudimentary Algorithm  Since the provenance edit distance is defined based on graph edit distance, an immediate solution to evaluate the provenance edit distance-based similarity is via an adaptation of the existing algorithms for computing graph edit distance.

Currently, the fastest algorithm for computing graph edit distance is attributed to an A?-based algorithm incorporating bipartite matching heuristic [16]. We first brief the adaptation  of this algorithm to PED, and then unveil the inability of this rudimentary algorithm to cope with large provenance.

The A?-based algorithm explores all possible vertex- to-vertex mappings (?vertex mapping? in short) between provenances in a best-first search (BFS) fashion. It maintains a priority queue of partial vertex mappings F . Each vertex mapping is associated with a priority via function f(F). A partial vertex mapping essentially divides the provenance into two parts ? the partially mapped subgraph induced by the vertices already mapped, and the remaining subgraph.

Estimated distance f(F) is the sum of:  ? existing distance g(F): the distance between the partial subgraphs regarding the current mapping; and  ? future distance h(F): the distance estimated on the remaining subgraphs from the current to the full mapping.

As a easily computable heuristic [7], we use the numbers of vertex and edge relabeling between the remaining subgraphs of p and p? to estimate h(F), which can be done in O(|Vp|+ |Vp? |).

We encapsulate the pseudocode in Algorithm 1. It takes as input two provenance graphs and a PED threshold, and returns the distance if PED(p, p?) ? ? , or ? + 1 otherwise.

First, it arranges the vertices of p in ascending order of vertex identifers [16] (denoted O, Line 1). The mapping F is initialized as an empty set and inserted in a priority queue Q (Line 2). Afterwards, it goes through an iterative mapping extension process till either all the vertices of p are mapped with a distance no more than ? (Line 6), or the queue is empty, meaning the distance exceeds ? (Line 18). In each iteration, it retrieves the mapping with the minimum f(F) in the queue (Line 4). Then, it tries to match the next unmapped vertex of p, as per O (Line 8), with either an unmapped vertex of p?, or a dummy vertex to indicate a vertex deletion. Upon a new mapping state is composed, it is evaluated by ExistingDis- tance (omitted) and EstimateDistance (omitted) to calculate the values of g(F) and h(F), respectively. Only if f(F) ? ? is the mapping inserted into the queue (Lines 10 ? 14).

C. Algorithm Analysis  Let |F| denote the number of vertices already mapped in F .

Algorithm 1 possesses a tree-structured search space, in which the maximum depth of the search tree equals |Fmax|, the size of the largest (partial) vertex mapping visited by the algorithm.

It is easy to verify that the search space of Algorithm 1 is ex- ponential in the number of vertices in provenance graphs, even if we employ the estimated distance to bound the search depth.

As a consequence, it has to maintain a fairly large number of partial vertex mappings in a priority queue 1. To quantize, we define the number of partial mappings visited by an algorithms.

Definition 4 (Visited partial mapping): A partial mapping F is visited once by an algorithm if the mapping F is formed and processed during the algorithm.

Subsequently, the total number of visited partial mappings of Algorithm 1 is NA? =  ?|Q| i=1 |Fi|.

1Although engineering techniques are available to expedite the operations on priority queue [4], it is unlikely for the cost of queue operations to dominate the overall cost.

Algorithm 1: AstarProvDist (p, p?, ? ) Input : p and p?  are two provenance graphs; ? is a distance threshold.

Output : PED(p, p?), if PED(p, p?) ? ? ; or ? + 1, otherwise.

1 O ? order of Vp; 2 F ? ?,Q.push(F); 3 while Q ?= ? do 4 F ? Q.pop(); 5 if |F| = |Vp| then 6 return g(F) 7 end if 8 u? next unmatched vertex in Vp as per O; 9 foreach v ? Vp? such that v ?? F and |do(u)?do(v)| ? ?  and |di(u)? di(v)| ? ? or a dummy vertex do 10 F ? F ? { u? v }; 11 g(F)? ExistingDistance(F); 12 h(F)? EstimateDistance(F); 13 if f(F) = g(F) + h(F) ? ? then 14 Q.push(F); 15 end if 16 end foreach 17 end while 18 return ? + 1  Intuitively, the number of visited partial vertex mappings is directly associated with the performance of Algorithm 1.

Our empirical result in Section V suggests that Algorithm 1 has a large number of visited partial mappings, most of which fail to grow to a full mapping, and thus, it does not perform well, especially on large provenance. Besides runtime cost, it also brings about serious challenges to the memory consumption. For instance, recent empirical studies on graphs are forced to choose machines with large memory, e.g, 128G, to accommodate the algorithm [20], [22]. It raises an interesting problem of developing an algorithm for provenance comparison, which is efficient in terms of both time and space. Meeting the needs, We present PEDSim in Section IV to improve our rudimentary algorithm.



IV. A SCALABLE ALGORITHM FOR EVALUATING PED  As analyzed above, if we can reduce the search space, i.e., the number of visited vertex mappings, the system performance can be greatly improved for large-scale knowledge discovery.

Moreover, to avoid the memory constraint set by BFS, we need to initiate another search paradigm for a scalable algorithm. In this section, we present a new algorithm for comparing provenance efficiently and scalably.

A. Algorithmic Framework  Recall that Algorithm 1 is a tree-structured BFS-based algorithm, which in the worst case expands the fewest nodes 2  among all admissible algorithms using the same cost function, but typically requires exponential space. As opposed to BFS, another search paradigm is depth-first search (DFS) which needs only linear memory space in the maximum search depth, but does not have a worst-case guarantee on the number of nodes. Note these claims are correct on the condition of unbounded search, not leveraging the given  2We differentiate a state in the tree-structured search, as ?node? from a vertex in a provenance graph.

similarity threshold. We observe that the similarity threshold is useful for bounding the search depth; in addition, if we can determine the failure of a partial vertex mapping earlier, we can explore smaller search space before reaching the result.

Assume there is a encoding seq of provenance p such that it provides an linear ordering of the vertices in Vp. We will discuss the effect of this encoding shortly. Algorithm 2 presents the proposed algorithmic framework for scalable provenance comparison via provenance edit distance.

The algorithm takes as input two provenance graphs p and p?, a PED threshold, a encoding sequence of p, and a (partial) vertex mapping; and output a boolean indicating whether the two provenances are similar conforming the threshold.

We assume seq encodes the provenance p according to the ascending order of their vertex identifiers for now. In particular, it first tests whether the current vertex mapping is a complete mapping (Line 1). If the answer is affirmative, this indicates that a mapping conforming the threshold is found, and hence, the provenances are similar. Otherwise, it proceeds with u in seq, which is the next vertex to be matched (Line 4).

Then, the partial vertex mapping is extended in an iterative procedure (Lines 6 ? 12). Only those vertices having valid in-coming and out-going degrees or dummy vertex can be used for extension. Mapping u to a dummy vertex implies a deletion of the vertex. Moreover, each new vertex mapping is evaluated by ExistingDistance and EstimateDistance. This serves as the same function as Line 13 of Algorithm 1, to bound the depth of the searching process. A valid mapping is fed into the next iteration (Line 11). If the extension in the next iteration eventually succeeds, i.e., a valid complete mapping is found, the algorithm returns with a true; otherwise, it executes the backtrack procedure (Line 15). The algorithm terminates when either a full mapping is discovered, or the whole search space is explored and no valid mapping can be found.

Correctness and Complexity Analysis. As an exhaust tree-  Algorithm 2: PEDSim (p, p?, ?, seq,F ) Input : p and p?  are two provenance graphs; ? is a distance threshold; seq is an encoding of p; F is a vertex mapping.

Output : a boolean ? true, if PED(p, p?) ? ? ; false, otherwise.

1 if |F| = |Vp| then 2 return true 3 end if 4 u? the |F|-th vertex in seq; 5 F ? ? F ; 6 foreach v ? Vp? such that v ?? F and |dego(u)?dego(v)| ? ? and |degi(u)? degi(v)| ? ? or a dummy vertex do  7 F ? F ? {u? v }; 8 g(F)? ExistingDistance(F); 9 h(F)? EstimateDistance(F);  10 if f(F) = g(F) + h(F) ? ? then 11 if PEDSim (p, p?, ?, seq,F) then 12 return true 13 end if 14 end if 15 F ? F ? ; /* backtrack */ 16 end foreach 17 return false     A  B2  B1  C  D  E  v1  v2  v3  v4  v5  v6  seq:  v1 v2a12 v3a23 v4a34 v5a15a53 v6a16a63  Fig. 2. Example of PEDCode  structured search, it is immediate that Algorithm 2 correctly evaluates the PED-based similarity between two provenances with respect to a given threshold. Due to the intrinsic hardness of the problem, the worst case runtime complexity of the algorithm remains O((|Vp? | ? (|Vp| + Ep + ?p))|Vp|), where ?p is the maximum vertex degree of p. Nevertheless, it has a quite small space complexity of O(|Vp| + |Ep|). This substantially reduces the memory footprint from Algorithm 1, and enables a good scalability towards large provenance and collections. Afterwards, we will see more heuristics to further boost the performance by shrinking the search space, and experiment results in Section V witness that the proposed algorithm works well with real data ready for large-scale provenance-oriented knowledge discovery.

B. A Provenance Encoding Technique  We present PEDCode, an encoding technique adapted from [18] to support provenance. The encoding was originally proposed for efficient subgraph isomorphism test. We extend it to provenance graphs, and utilize this to guide the comparison of provenances in Algorithm 2.

Specifically, we encode a provenance graph p as a regular expression seq = [[via?jia  ? ij ] |Vp|], 1 ? j < i ? |Vp|, such that  vi and aij (aji) are from Vp and Ap, respectively. Each entry of the regular expression is identified by one vertex vi from Vp, where i denotes the i-th ordered entry, which may differ from its vertex identifer in p.

For instance, we may arrange the vertices of the provenance according the ascending order of vertex identifiers. We will analyze and discuss more about the effect of vertex ordering shortly in the subsequent section.

For all i > j, aji in each entry records  ? sArc ? the spanning arc between vertex vj to vertex vi (either ?vi, vj? or ?vj , vi?); and  ? iArc ? in-coming arcs from vertex vj to vertex vi.

In addition, aij stores oArc ? out-going arcs from vertex vi to vertex vj .

Example 2: Consider provenance p in Figure 1. Figure 2 present the graphical presentation of PEDCode of p on the left, where solid lines indicate spanning arcs, and dashed  lines are the other arcs. On the right is the regular expression of PEDCode, where spanning arcs are colored in red (we also color the spanning arcs of p in red in Figure 1 for reference). We construct seq with A-task as the first vertex, followed by C-task, D-task, etc, and end with B2-task.

It is immediate that PEDCodes defines a vertex ordering, according which the vertices of p are matched one after another in Algorithm 2. We remark that any ordering of the vertices of p does not affect the correctness of Algorithm 2. Nevertheless, it greatly influences the search space that the algorithm ex- plores. Next, we present several heuristics to effectively order the vertices in order to shrink the search space.

C. Effective Vertex Ordering  In general, there exist P (|Vp? |, |Vp|) = |V  p? |!

(|V p? |?|Vp|)!

3 differ- ent ways to match the vertices in p to those in p?. To efficiently determine whether p matches p? under the PED threshold, it is essential that Algorithm 2 traverses the search space in a judi- cious manner in order to locate a valid complete vertex map- ping as early as possible, if there is any. Eager determination of edit operations expedites the failure of a vertex mapping, and thus, early backtrack and stop in future. This substantially reduces the number of visited vertex mappings, and saves ?un- necessary? computation. We exploit this observation to order vertices by constructing a PEDCode based on how likely the match of each entry can reduce the search space subsequently.

Choosing the first vertex. We observe that a provenance graph may have several (usually one) vertices without in- coming arcs, namely, source vertices. These source vertices provides a good starting point for building the spanning tree.

Moreover, the number of source vertices are usually small in real applications. This enable us to choose the root from a small range of candidates. More importantly, if we take connectivity into consideration, taking a source vertex as root can usually lead to a spanning tree of the provenance graph.

Any vertex mapping that does not following the spanning arcs gives rise to edit operations. Recall that early determination of edit operations speed up the comparison. Before describing our method, we introduce the follows.

Definition 5: The neighborhood of a pair of vertices (u, v) in a provenance graphs is a 6-tuple nb(u, v) = (l(u), l(v), di(u), di(v), do(u), do(v), ?), where ? is an indicative variable, equal 1 (resp. -1) if there is an arc ?u, v? (resp. ?v, u?), and 0 otherwise.

Definition 6: The neighborhood edit distance (NED) between the neighborhoods of (u, v) and (u?, v?), denoted by NED((u, v), (u?, v?)), is the minimum number of provenance edit operations to transform the neighborhood of (u, v) to that of (u?, v?).

It is easy to compute neighborhood edit distance in polynomial time as follows. For vertex pairs, we compare them from both ends by swapping the positions of u and v,  3Known as partial permutations, or k-permutation of n. Without loss of generality, we assume |Vp| ? |Vp? | to avoid the pathological case in which P (|Vp? |, |Vp|) is undefined.

A  C  E  B1  B2  D  v1  v2  v3  v4  v5  v6  A  CB1 B2  D  E  p''  Fig. 3. Example of Vertex Ordering  and take the smaller distance of the two as NED. That is,  NED((u, v), (u?, v?)) =  min  { ?(l(u), l(u?)) + ?(l(v), l(v?)) + ?((u, v), (u?, v?)), ?(l(v), l(u?)) + ?(l(u), l(v?)) + ?((v, u), (u?, v?))  } ,  where ?(x, y) equals 1 if x ?= y, and 0 otherwise; and ?((x, y), (z, w)) is a function to determine the minimum number of edit operations to make the degrees of x and y identical to those of z and w. We omit the detailed induction of ?(?) in the interest of space.

Consider vertices u, v ? Vp, let c(u, v) denote the number of vertex pairs (u?, v?) in Vp? such that NED((u, v), (u?, v?)) ? ? .

To facilitate this step, we may pre-compute the vertex degree statistics in p and p?.

Intuitively, we want to choose the source vertex with minimum candidates as the first vertex. To this end, we first inspect the vertices of provenance p and pinpoint the vertices u with in-coming degree as 0. Then, we examine every possible vertex pairs (u, v) and determine c(u, v). Among all candidate vertex u, we pick the one that is associated with smallest c(u, v) as first vertex 4.

Choosing the next vertex. As aforementioned, we may map a pair of vertices (u, v) of p to c(u, v) candidate pairs of vertices in p?. If a vertex u is chosen to be mapped first, the search space induced by this action can be estimated as  c(u, v) ? P (|Vp? | ? 1, |Vp| ? 1).

The remaining entries of PEDCode is determined similarly to the method adopted for the first entry. Assume we have decided a set K of k vertices as the first k entries in PEDCode, and are about to choose the next vertex. Without loss of generality, let v be an unselected vertex in p. We estimate the effect including v as the next entry as follows.

Nv = Nk ? c(u, v) ? P (|Vp? | ? k ? 1, |Vp| ? k ? 1), (1)  where Nk is estimated search space induced by the first k vertices, v ? K.

4Ties can be broken arbitrarily; in our experiment, we prefer the vertex with smaller identifer.

Algorithm 3: GeneratePEDCode (p, p?, ?, seq,F ) Input : p and p? are two provenance graphs.

Output : seq is the PEDCode of p.

1 obtain frequency histogram for unique vertices and arcs in p?; 2 u? the source vertex with minimum c(?u, v?) and c(u); 3 T ? T ? {u } ; /* T is an ordered set */ 4 while T ?= Vp do 5 Nmin ? max; 6 foreach u such that v ? T ? ?v, u? ? Ap do 7 Nu ? estimation by Equation (1); 8 if Nu < Nmin then 9 Nmin ? Nu;  10 end if 11 end foreach 12 T ? T ? {u|u is associated with Nmin}; 13 end while 14 seq ? ConstructPEDCode(p, T ); 15 return seq  Finally, for all possible candidates v, we select the one with the smallest estimation as the next vertex in PEDCode,  v = argmin v  Nv. (2)  Note that the values of Nk and P (|Vp? |?k?1), (|Vp|?k?1)) are the same for all possible v in each round, and thus, do not influence the selection.

Example 3: Consider the provenance p?? on the left of Figure 3, and we want to compute PED(p??, p?). We find that there is two vertices with in-coming degree being zero, i.e., A-task and C-task. From p?, we have c(?A,B?) = 0, c(?C,D?) = 1. Thus, we pick A-task as the first vertex. Then, we start extending it with either B1 or B2. Assume B1 is chosen. In the next step, we have two options ? B2 and D. According to Equation (2), we verify that B2 is a better option in terms of shrinking the search space. Eventually, the complete PEDCode of p?? is presented on the right.

Algorithm. Compiling the heuristics above, we present our algorithm for constructing PEDCode in Algorithm 3.

Correctness and Complexity Analysis. Since Algorithm 3 finds an ordered set of vertices from Vp, it also produces a PEDCode for p by including the arcs in corresponding entries, and thus, the correctness follows. The worst-case complexity of the algorithm is O(?p ? |Vp|2), where ?p is the maximum vertex degree of p.

It is not easy to give a closed-form formula of the total number of visited vertex mappings for Algorithm 2.

Nevertheless, we will see in Section V that the proposed algorithm explores a much smaller number of vertex mappings than Algorithm 1, before identifying the valid mapping if any.



V. EXPERIMENTS  This section reports experiment results and our analyses.

A. Experiment Setup  We obtained the datasets SCI from the collected real scientific workflows 5. We selected six specifications from  5http://www.myexperiment.org     the web site. For each specification, we randomly generated pairs of valid runs, varying the average number of arcs in {400, 800, 1200, 1600, 2000} with variation of +/-50, and the PED between pairs ranging from [1, 7]. For each group of arc number, we generated 200 provenances, and hence, we had 1, 000 pairs of provenance graphs in total.

Experiments were run on a machine of Quad-Core AMD Opteron Processor 8378@800MHz with 94GB RAM 6. All the algorithms were implemented in C++ and ran in main memory. We measured (1) the number of visited vertex mappings; (2) peak memory consumption; and (3) running time. We ran each set of experiments for 5 times, and the average results are reported here per pair of provenances.

B. Evaluating Encoding and Ordering  We first evaluate the proposed encoding and vertex ordering techniques. Specifically, we use ?Basic PEDSim? to denote the basic implementation of the proposed algorithm (Algorithm 2) for evaluating threshold-based PED, which employs the provenance encoding technique to guide the comparison. Integrating Basic PEDSim with the vertex ordering technique (Algorithm 3) gives ?+ Order?.

We ran the two algorithms on the whole dataset of SCI, varying distance threshold ranging in [1, 6], and plot the results in Figures 4(a) ? 4(c). We observe that the search space of Basic PEDSim and + Order both grow gradually along with the growth of PED threshold. The average number of partial mappings visited by + Order is always less than that of Basic PEDSim; moreover, the margin between them is more substantial towards large PED thresholds. In particular, Basic PEDSim visits up to 1.8x more mappings than + Order. Since both of them follow the DFS paradigm, the peak memory consumptions of them are exactly the same 7.

As anticipated from the search space size, + Order is always faster than Basic PEDSim, up to 2.2x.

In the following experiments, we used + Order as our com- plete algorithm, and renamed to ?PEDSim? for differentiation.

C. Comparison of PED Computation  The following algorithms were involved in this comparison:  ? A?, labeled by ?AS?, is the A?-based algorithm for computing PED adapted from the state-of-the-art graph edit distance algorithm, i.e., Algorithm 1.

? PEDSim, labeled by ?PE? is the proposed DFS algorithm incorporating the encoding and ordering techniques.

We compared the two algorithms on the whole SCI by varied distance threshold from 1 to 6. Figures 5(a) ? 5(c) report the results in details. Note we draw the comparisons on partial mapping number and peak memory consumption in logarithmic scale. It is clear from the Figure 5(a) that PEDSim explores a much smaller number of partial mappings before find the answer, while A? keeps tracking of fairly large number of partial mappings in the priority queue. As  6The choice of large RAM is to accommodate the A?-based algorithm, as we will see in the Section V-C  7We used the same data structure to record the partial mappings.

a result, the memory consumption of A? is much higher than that of PEDSim, due to disparate search paradigm. The number of visited partial mappings of PEDSim can be as low as 8% of that of A?, and 0.005% regarding peak memory consumption. Hence, the result on running time becomes expectable. PEDSim runs fairly efficient, reaching almost one order of magnitude faster than A?.

D. Evaluating Scalability  We evaluate the scalability of PEDSim and A? against the size of provenances. Recall we had 5 groups of provenances with average number of arcs in {400, 800, 1200, 1600, 2000}.

In particular, we ran the test on the five groups with distance threshold fixed as 4, and in each group, there were 200 pairs of provenances, respectively.

We present the results in Figures 6(a) ? 6(c). It can be seen that, due to the exponential nature of the problem, the search space of both PEDSim and A? grow according to the average number of arcs in graphs. Nevertheless, PEDSim showcases a substantially smaller growth rate, in comparison with A?. Moreover, the same conclusion can be drawn from Figure 6(b). In specific, PEDSim uses only 0.0004% memory of that required by A? on the set of provenances with |A| = 1200. In short, the result demonstrates the good scalability to provenance size.

We also conducted experiments on larger synthetic datasets; in the interest of space, we omit the results in this paper.

Summary. PEDSim effectively shrinks the search space, and it does not pose strong memory constraints to the computation, and thus, scaling itself to large provenances.

Further, the heuristics substantially speed up the search process by inducing much smaller search space than the baseline algorithm. Hence, the integrated algorithm outperforms all other alternatives in terms of time and space.



VI. CONCLUSION  In this paper, we study the problem of scalable evaluation of provenance similarity. We propose a novel concept of provenance edit distance to measure the similarity between provenance graphs. Unlike previous methods using A? search for computing the distance, we conceive a method exploiting a simple idea based on DFS fashion combining several effective heuristics. Comprehensive experiments performed on real data demonstrate that the new algorithm outperforms alternatives.

As the next step, we would like to adapt the algorithm to semantic-rich graph model so that it can evaluate not only structural but also semantic differences between provenance.

Acknowledgement. This work was partially supported by Natural Science Foundation of China (NSFC) under grants No. 61302144 and No. 61303062.

