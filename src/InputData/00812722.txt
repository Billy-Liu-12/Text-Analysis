Distributed Shared Memory with Log Based Consistency for Scalable  Data Mining

Abstract  This paper presents the scalable data mining prob- lem, proposes the use of software DSM (Distributed Shared Memory) with a new mechanism as an effec- tive solution and discusses both the implementation and performance evaluation results. I t  is observed that the overhead of a software DSM is very large for scalable data mining progmms. A new Log Based Consistency (LBC) mechanism, especially designed for scalable data mining on the software DSM is proposed to overcome this overhead. Tmditional association rule based data mining progmms frequently modify the same fields by count-up operations. In contmst, the LBC mechanism keeps up the consistency by broadcasting the count-up operation logs among the multiple nodes.

1 Introduction  Data mining discovers the knowledge from massive amounts of data. The knowledge required varies from industry to industry. Therefore, many industries are developing specialized data mining programs to sat- isfy their needs and requirements. A popular exam- ple is data mining in retail organization. In general, large number of data mining programs process massive amounts of data available in SMP(Symmetric Multi- Processor)-type parallel computers or cluster-type dis- tributed systems.

A scalable data mining program should be able to run in both SMP-type parallel computers and cluster- type distributed systems. The development of scal-  Toshitsugu Yuba Graduate School of Information Systems  The University of Elect ro- Communicat ions yuba@is.uec.ac.jp  able data mining programs will be easier with the use of software DSM (Distributed Shared Memory) such as [2] [3]. DSM enables the development of scalable programs based on the shared memory programming model rather than the message passing programming model even in cluster-type distributed systems.

Association rule [l] is the most popular technique used in data mining. Typical association rule based data mining programs frequently modify the same data fields by count-up operations. Thus the overhead of a software DSM is very large for data mining p r e grams. If those programs are executed in the soft- ware DSM, many data items in the fields are fre- quently passed among the multiple nodes for keeping up the consistency. So we propose a new consistency mechanism, the LBC (Log Based Consistency) mech- anism, on the software DSM. It is especially designed for scalable data mining. The LBC mechanism keeps up the consistency by broadcasting the count-up oper- ation logs among the multiple nodes. To evaluate the performance of the LBC mechanism, we have devel- oped a scalable data mining system, VISIONA (Virtual - Shared Memory Envkenment for Scalable Data Miging &plications).

2 Large Scale Data Mining  Association rule based mining [l] in the retail orga- nization is an example of data mining programs pro- cessing massive amounts of data. The association rule defines two measures, a support value and a confidence value. The support value is a measure based on the ra- tio of the transaction record including an item X. The  0-7695-0368-3/99 $10.00 0 1999 IEEE  mailto:hirayama@yuba.is.uec.ac.jp mailto:yuba@is.uec.ac.jp   confidence value is a measure based on the ratio of the transaction record including an item X also including an item Y. Users specify the constraints, the minimum support value and the minimum confidence value, for mining association rules.

Association rule mining is done by the following Apriori algorithm. The steps outlined process the item- sets (sets of items) having k integer number of items, which are called pass-k. And they are iterated after k is incremented.

1. Read all transaction records and count-up the oc- currences of the item-sets having k items. They are called the candidate item-sets of k.

2. Select the item-sets from the candidate item-sets of k, which support values greater than the min- imum support value. They are called the large item-sets of k.

3. Make the candidate item-sets of k+l out of the large item-sets of k. Repeat the above steps until the large item-sets will be null.

3 Log Based Consistency Scheme  There are two types of DSMs (Distributed Shared Memory). One is a hardware DSM such as "DASH" [4] and the other is a software DSM such as "TreadMarks" [2] or "CVM" [3]. We propose to use software DSM but not to use hardware DSM.

The software DSM or simply DSM provides a virtual shared memory and enables users to develop programs with shared memory programming model in cluster- type distributed systems. The traditional DSMs such as "TreadMarks" has the lazy release consistency and the multiple writer protocol [2]. They increase the performance compared to the former sequential con- sistency protocol by alleviating the problem caused by mis-matches between page size and application gran- ularity which is known as the false sharing. That is, they are effective even if the fields in the same page are frequently updated in multiple nodes.

The lazy release consistency and the multiple writer protocol are insufficient and ineffective for association rule based data mining programs and others. Those programs frequently update the same fields in the mul- tiple nodes. Therefore, if those programs are executed in the traditional DSM, many data items in the fields need to be passed frequently for keeping up the consis- tency. Moreover, they can not be executed simultane- ously. Such a problem is hardly alleviated by the lazy release consistency or the multiple writer protocol.

It is observed that most of the processing time of those programs is spent on the count-up operations.

These count-up operations follow the commutative law and the associative law. By taking advantage of the features of commutative law and the associative law of the count-up operations, we propose the LBC (Log Based Consistency) scheme. In the LBC scheme count- up operations can be executed simultaneously in the multiple nodes while keeping up the consistency.

In the Apriori algorithm for association rule based mining, a hash tree of the candidate item-sets is cre- ated in the DSM. After the hash tree is created in the DSM, transaction records are read and the occurrences of the item-sets are counted by all nodes. The opera- tions have a large overhead in the traditional DSM, be- cause it is necessary to pass the data items in the fields at every count-up operation for keeping up the consis- tency. Those count-up operations can not be executed simultaneously. However, performing count-up oper- ations with the commutative law and the associative law, it is possible to keep up the consistency without passing data items at every count-up operation.

In the DSM with LBC implementation, when the count-up operations are executed in a node, the count- up operation logs are recorded in a log buffer of the node, as shown in figure 1. The count-up operations can also be executed simultaneously in the multiple nodes without passing data at every count-up opera- tion.

I I .  .V.

Figure 1. The DSM with the LBC scheme.

The count-up operation log has an address field which is counted-up in the node and to be counted- up in all other nodes. When the log buffer reaches full, the logs are sent to all other nodes by broadcast- ing. When the other nodes receive the logs, the logs are processed or the count-up operations are executed.

The LBC mechanism makes it possible to count-up the same fields simultaneously in the multiple nodes with- out passing data at every count-up operation. There-     fore, the LBC mechanism is very effective for the count- up operations. The mechanism make use of the char- acteristics of commutative and associative laws.

Daemons receive the count-up operation logs, they re- flect them into their own shared memory spaces.

5 Programming 4 Implement at ion  Figure 2 shows the system structure of VISIONA which is a prototype of the DSM with the LBC scheme.

Each Manager unit is a daemon process. The Re- source Manager manages shared memory spaces and semaphores which can be used in cluster-type dis- tributed systems. The Space Managers manage the data in shared memory spaces and send the count-up operation logs to all other nodes by broadcasting. The function of Shadow Daemons is to receive the count- up operation logs sent from other nodes and to re- flect them into the shared memory spaces in their own nodes.

FigureZ. System structure of VISIONA.

When an application process creates a shared mem- ory space or a semaphore, it sends the request to the Resource Manager (A). When the Resource Manager wants to create a shared memory space, it requests the Space Managers and the Shadow Daemons in all nodes to create the shared memory space and map them (B) accordingly. Semaphores are controlled by the Resource Manager.

When an application process attaches a shared memory space into its own address space, it sends the request to the Space Manager in its own node to query the address of the shared memory space. When an a p plication process counts-up the occurrences of the can- didate item-sets in the shared memory space, it sends the request to the Space Manager in its own node (C).

The Space Manager saves the count-up request as a log in a log buffer. When the log buffer reaches full, the Space Manager sends them to the Shadow Daemons in all other nodes by broadcasting (D). When the Shadow  Figure 3 shows the pseudo code for association rule based mining in the DSM with LBC. The functions with prefix "VISIONA" are provided by the VISIONA library. In s t e p l ,  a master process creates a shared memory space and a semaphore. All the processes in the multiple nodes of the cluster-type distributed sys- tem, count-up the occurrences of the candidate item- sets in a hash tree on the shared memory space. Syn- chronization is done with the semaphore.

Figure 3. Association rule mining (pseudo code).

Step2 through step13 are executed by all the pro- cesses.

In step2, all the processes attach the shared mem- ory space into their own address spaces.

Step2 through step13 are executed by all the pro- cesses.

Step3 through step12 show the sequence of the Apriori algorithm, the sequence iterates with in- crementing k until the candidate item-sets of k become empty.

Step4 through s tep7 iterate for all the transac- tion records.

0 In step-4, a transaction record is read. In step-5, an item-set of k is selected from the transaction record. In step-6, the item-set is searched in the hash tree. In step-7, the occurrence of the item-set is counted-up. In step-8, the count-up operation logs remained in the log buffer are flushed to all other nodes. In step-9, all the processes synchro- nize with the semaphore. In s teplo,  after com- pletion of the pass-k, the large item-sets of k are made. In step-11, the candidate item-sets of k+l are made out of the large item-sets of k. In step-12, the variable ?k? is incremented and the sequence iterates from step-4.

When the candidate item-sets of k reach empty, the Apriori algorithm terminates. In step-13, all the processes detach the shared memory space.

0 Finally, in s tepl4,  the master process deletes the shared memory space and the semaphore.

type number of processors  SMP 1  This is the pseudo code for association rule mining.

It can be executed simultaneously in cluster-type d i s tributed systems.

parr-1 pais-2 paas-3 pass-4 total [sec.] [sec.] [rec.] [aec.] (aec.1  44 192 . 84 38 358 29 99 44 a5 197  a4 152 27 70 31  6 Evaluation  DSM  We have implemented a program of association rule mining in VISIONA to compare the performance of the DSM with LBC. We synthesized the data for evalua- tion according to the specifications given in the [l].

Specifically, 400 total number of items, lOOB mean record length, 10 mean number of items in a record, 600,000 total number of records (approximately 60MB) and 0.4% minimum support value.

To evaluate the performance of DSM with LBC, we compared the performance with four uni-processor computers (represented as UPS) and an SMP-type par- allel computer (represented as SMP). UP has a 70MHz SPARC processor and 32MB memory. SMP has four lOOMHz HyperSPARC processor and 128MB memory.

A data file is stored in a local DISK of each computer in every case. The DISK performance of the UP and the SMP is different.

Table 1 shows the performance of association rule based mining executed by the SMP and the UPS us- ing the DSM with LBC (represented as DSM). Table 2 shows the results normalized by those of the UP. Ac- cording to the results, speed up obtained by increas- ing the number of processors of the DSM with LBC is greater than or equal to that of SMP-type parallel computer.

4 25 61 29 a3 138 1 73 331 133 65 602 2 45 i n  68 33 318 3 34 119 46 a3 211 4 29 91 36 17 173  SMP 1 1.00 1.00 1.00 2 0.66 0.5a 0.52 3 0.61 0.36 0.37  1.00 1.00 0.66 0 . ~ 5 0.63 o.4a  Table 2. Normalized performance.

type I number of I pass-1 I pass-2 1 Pas*-3 I pass-4 I total I  DSM 4 0.57 0.39 0.35 0.60 0.39  a 0.62 o m  0.51 0.51 0.53  4 0.40 0.27 0.27 0 . a ~  0.29  1 1.00 1.00 1.00 1.00 1.00  3 0.47 0.36 0.35 0.35 0.37  7 Conclusion  This paper presented the use of DSM as a common tool to develop scalable data mining programs. This is an efficient way of developing scalable data mining programs. To decrease the overhead of the DSM, we proposed the LBC mechanism on the DSM.

To evaluate the effect of the DSM with the LBC, we have implemented VISIONA in UNIX computer clus- ters. Performance results of the evaluation shows a speed up for increasing number of processors of the DSM with LBC. The speed up is greater than or equal to that of SMP-type parallel computer.

