Autonomic RSS: Discarding Irrelevant News

Abstract   Information overload is becoming a big problem in  the modern world. Several technologies face this  problem, amongst them feed aggregators. Using this  technology, users receive a huge amount of news that  may contain a large number of irrelevant bits of  information. This paper discusses this problem and  provides an autonomic way to reduce it through the  use of Data Killing Operators. These operators use  SECONDO database based on high-level Petri nets  patterns.

1. Introduction   As a result of new technology developments,  specifically the Internet in the last years, people have  had to deal with an information overload. This  condition is a result of the large volume of information  made available nowadays. However, days remain 24  hours long and our brains remain in roughly the same  state of development as they were when the cavemen  communicated by scrawling messages on stone.

The researchers that work in this area say that  although the technology is causing this problem, it also  provides ways to solve it. An interesting strategy is the  use of filters. Expressive examples are the email filters  that are used to eliminate noncritical messages,  avoiding an overload of undesirable information [1].

These filters are directly connected to the quality  information concept as when one has a great deal of  available data, quality becomes an important  characteristic when deciding what information to use or  not [2]. This way, it is important to consider that in a   1 Despite the subtle difference between data (the  representation/notation) and information (is the  meaning/denotation), in this paper, we use these terms indistinctly.

scenario with so much data there are irrelevant, similar,  false, wrong and obsolete data elements. Thus, one  sometimes needs to delete this data.

Currently, the technologies that have the problems  explained above are the Web feeds. In spite of the great  potential in the use of RSS files, its applications are  extremely limited. Users include the linking to feed  files in software that reads feeds (feed aggregators) and  receives, from time to time, without accessing the Web  page, the most recent news on many issues. Like the  Firefox aggregator, most of these applications that exist  nowadays store and order the news by date, not  offering additional resources (filtering considering the  user profile, keywords, rules, etc). Because of these  deficiencies, users receive a huge volume of news.

However, lots of them have only some or no relevance  to them.

As regards this scenario this work shows a possible  solution through the use of the Autonomic Data Killing  Framework [9]. This method uses active rules and Data  Killing Patterns based on high-level Petri nets that  execute, in an autonomic way, the filtering of relevant  news to the user. In this work we have used the  Allowed Data (AD) operator, previously defined by  Pinheiro [9], and in addition, we define two new Data  Killing Patterns and their operators, Discarding Similar  Data (DS) and Discarding Prohibited Data (DP). The  Feed Organizer Plug-in was also implemented as well  as the experiments to evaluate this tool. In short, the  information overload is reduced through plug-in  execution and the rules related to the patterns.

The next section presents the background related to  our work. In section 3 we present the Data Killing  Operators. Section 4 shows the architecture and  Section 5 introduces the Feed Organizer Plug-in. After  that, we discuss the plug-in results through a simple  experiment in Section 6. Finally, in Section 7 we  conclude the chapter and point out some future trends.

DOI 10.1109/ICAS.2009.11       2. Background   The term Autonomic Computing (AC) was  introduced by IBM in 2001 [1]. It can be understood as  the pursuit of self-managing computer systems, i.e.,  systems that need little or no human interference. It  mainly aims at reducing the complexity of computer  systems for users; increasing the quality of systems;  reducing installation time, testing cycles and  maintenance; and anticipating problems.

The technology related to Web feeds has a great  potential for the use of autonomic computing. Although  users receive news without accessing the Web pages,  the entire remaining job is done by them (subscribing  interesting feeds, selecting relevant news, deleting  irrelevant news, etc.). Currently, there are three main  specifications related to the creation of feed files: RSS  1.0 (RDF Site Summary 1.0) , RSS 2.0 (Really Simple  Syndication 2.0) and Atom  . For the sake of  simplification, we only consider the RSS 2.0 feeds.

Besides, we should point that this specification for feed  files is the most used nowadays.

There are many aggregators available and they may  be Web-based or not. Specifically for this research,  which aims at developing a Firefox plug-in, we  concentrated our efforts in adding a new extra  functionality to the Firefox aggregator that comes  integrated with this browser. In this aggregator, the  feeds are treated as entries in the set of the user?s  favourite pages. This plug-in is called Feed Organizer.

The elimination of irrelevant news uses a  combination of Data Killing Patterns developed with a  tool named CPN Tools [4][5]. It lets us edit, simulate  and analyze coloured, hierarchical and temporized  Petri nets, also known as high-level Petri nets. Below,  we give some reasons to justify the use of high-level  Petri nets with CPN Tools in pattern representation:  ? It allows detection of infinite loops in the creation of the rules that form the patterns;  ? It has a well-defined semantic that determine, in an unambiguous way, each pattern;  ? It allows the representation of a truth concurrency among events, starting a transition with  multiples entering arcs (and not the changing among  events that usually happens in other tools);  ? It allows hierarchical descriptions; ? It executes an interactive simulation and an  interesting behavioural analysis.

2 http://web.resource.org/rss/1.0/spec 3 http://cyber.law.harvard.edu/rss/rss.html 4 http://www.ietf.org/rfc/rfc4287  The pattern interface is possible in two ways,  through an API created for CPN Tools and through the  SECONDO database.

SECONDO [6][7][8] is an extendable database  management system that supports especially  applications that are not suitable to specific patterns.

For example, it allows creating or modifying existing  algebras and it also provides a generic database  management system model that can be set with  implementations of a large variety of data models. In  this work we are going to use an operator?s algebra  where each operator in SECONDO communicates with  a pattern modelled by CPN Tools. Because of that, an  operator in SECONDO can be considered an interface  to a pattern. The use of the SECONDO database as an  interface offers some advantages such as:  ? The creation of a customized algebra that represents the Data Killing Patterns (operators);  ? The historical storage of occurred events; ? The storage of discarded data for future  analysis (an essential requirement in some systems).

The Data Killing operators are started every time a  client downloads an updated news files. Among the  existing Autonomic Data Killing Patterns [9], we  selected the following ones for the Feed Organizer  Plug-in development: Allowed Data, Discarding  Prohibited Data and Discarding Similar Data. This  choice was made aiming at complexity reduction in the  first version of this tool. However, other patterns will  be included in the next ones.

3. Data Killing Operators   In this work, an algebra containing the Data Killing  Operators was implemented using the SECONDO  database. The interface used in SECONDO accepts  inputs with the format <integer><attribute><value>,  where <integer> is the data identifier, <attribute> is the  data attribute (metadata) that forms the data, and  <value> is the content of this attribute. This format,  based on the RDF format, was chosen as it allows the  easy representation of any data set. Let us suppose that  it was necessary to represent the following information:  Brian, 33 years old, and Joe, 40 years old. We would  obtain the representation:  <01><name><Brian>   <01><age><33>  <02><name><Joe>   <02><age><40>  This research uses some Data Killing Operators  based on Data Killing Patterns to process data inputs.

The SECONDO database allows using these patterns  through a set of operators detailed as follows:   5 http://www.w3.org/RDF/     ? Allowed Data: compares the contents of one or more data attributes with the contents of a  parameter. All data considered not similar to the  parameter is discarded;  ? Discarding Prohibited Data: compares the contents of one or more data attributes with the  contents of a parameter. All data considered similar to  the parameter is discarded;  ? Discarding Similar Data: compares the contents of data attributes among themselves. All data,  but the newest one, with one or more similar attributes  considered similar is discarded.

These operators are defined in the algebra and can  use additional parameters, among which:  ? Similarity function name (Jaccard Coefficient, etc) and similarity level (0% to 100%);  ? Stemming (reduces words to their stem, base or root form);  ? Stop words (eliminates frequent/common words before processing data);  ? Languages (English, French, etc).

Table 1 defines the Data Killing Operators Algebra  that contains the operators presented previously.

Table 1: Data Killing Algebra Operator  syntax and symbols in BNF  <S>::=query <command> \n  <command>::=<pattern> <data>  <data>::=(<integer><metadata><text>)<data>  |(<integer><metadata><text>)  <metadata>::=<attribute>::=<text>  <pattern>::=  ad<parameters1>|dp<parameters1>|ds<parameters2>  <parameters1>::=<comparedMetadata><parameters>  <parameters2>::=  (comparedMetadata=<metadata>)<parameters>  <comparedMetadata>::=(comparedMetadata=<metadata>)  |(comparedMetadata=<metadata>)<specificMetadata>  <specificMetadata>::=  (<metadata>=<text>)<specificMetadata>  |(<metadata>=<text>  <parameters>::=(similarityStrategy=Jaccard|Keyword)  (similarityCoeficient=<integer>)  (stemming=<bool>)(stopwords=<bool>)  (language=english|portuguese)  <bool>::=true|false    The nonterminals symbols represented between "<"  and ">", and the symbols <integer> and <text> express  their own meanings. Because of that they correspond to  terminals symbols in this representation.

It is also possible to use data inputs through an API  similarly to the operators implemented by SECONDO.

The Allowed Data Pattern has been already defined  by Pinheiro [9]. The other two patterns will be defined  as follows:  ? Discarding Similar Data Pattern: represents the most interesting pattern to the Feed  Organizer Plug-in as it acts over a recurring problem in  the feed area: repeated or very similar information.

Normally, feed aggregators show this duplicated data  to users as if it were new data. Figure 1 models the  Discarding Similar Data Pattern. The internal  repository represents repositories that may contain  repeated or very similar data and trash represents  discarded data. These places allow the creation of a  data flow. The places in grey allow the creation of a  control flow.  This flow may contain events and  parameters. It consists of two rules: R1 (transition R1,  place eventSource and place detectedSimilarData) that  checks the existence of data to be processed, and R2  (transition R2, place detectedSimilarData and place  eventResult) that effectively discards the data. The  double-ended arrows represent read arcs, allowing the  reading of tokens without consuming them.

Figure 1: Discarding Similar Data Pattern  ? Discarding Prohibited Data Pattern: acts as an anti-spam system. Figure 2 models the Discarding  Prohibited Data Pattern. Similarly to Discarding  Similar Data Pattern this pattern simultaneously models  two views: data flow and control flow (consisting of  two rules). The number of places and transitions, and  the structure are the same in both patterns, but the  semantics of some elements is different. The internal  repository may contain irrelevant data and the trash  represents the discarded data. The places in grey allow  the creation of a control flow. This flow may contain  events and parameters. It is consisting of two rules: R1  (transition R1, place eventSource and place  detectedProhibitedData) that checks the existence of  data to be processed and R2 (transition R2, place  detectedprohibitedData and place eventResult) that  discards the data.

Figure 2: Discarding Prohibited Data Pattern    4. System Architecture   Figure 3 shows system architecture, where the CPN  Tools corresponds to the model and execution  component. It is responsible for modelling and  adapting the patterns, and also allows active rule  creation and execution with control and data flows.

Figure 3: System architecture  The second set of components (SECONDO, API,  JBOSS) deals with communication issues. The CPN  ML can communicate with other programming  languages (for example, Java and C++), using sockets.

This architecture has two communication possibilities:  the Java API and the SECONDO database that uses  C++. The Data Killing Algebra was developed using  this database. SECONDO is also responsible for  storing events, data that needs further analysis and the  rules created by users. These rules involve the data  killing operators and their respective execution  sequence. The RSS files are received by the JBOSS    6 http://www.jboss.org/  application server that is responsible for the  RSS/API/SECONDO format converting.

Lastly, we have the third component that is the main  part of this research. It corresponds to the Feed  Organizer Plug-in that will be depicted in details on the  next sections.

5. Feed Organizer Plug-in   Figure 4 shows the interface developed in this work.

To use it, it is necessary to install the Firefox Feed  Organizer plug-in and then click on the feed organizer  button that will become visible. After that, a new  window will open with some configuration options.

When the user selects the desired options and clicks on  the filter button, the plug-in starts the process of  filtering feeds.

Figure 4: Feed Organizer Plug-in  The Allowed Data operator allows users to define  topics of interest and similarity levels to these topics.

Afterwards, the Discarding Prohibited Data Operator  has fields for prohibited topics and similarity levels  related to the provided topics. The last operator,  Discarding Similar Data, has just a field to define the  desired similarity level that is used to detect similar  news. A future tool improvement is the use of a hybrid  approach that will be able to capture the set of  keywords through user behaviour, considering  frequently read and deleted subjects.

Currently, the plug-in uses the Jaccard coefficient  [10] as a similarity measure but other strategies will be  available in future versions. As a result of that, new  options would be added to the plug-in configuration  interface. Before the application of similarity measures,  the text may be pre-processed. It eliminates stopwords  and uses stemming techniques based on the Porter  Stemming Algorithm [11]. This research applied the  Snowball Stemmer Algorithm. Execution time was not  considered as the filtering process is executed in the  background.

The tool works as follows: after receiving the user  options, the filtering process is initiated, and the plug-  in searches all favourite user feeds and sends them to     the server with the selected filtering options. After that,  the feed Organizer Parser downloads every XML file  corresponding to each user feed. It then assembles a  single XML file containing all the information from the  feeds plus the user?s filtering options. Afterwards, the  Feed Organizer parser carries out the parsing of the  XML file, reconfiguring it for the SECONDO entry  format, according to chosen operators. Another  important function performed by the Feed Organizer  Parser is the generation of the queries that will be  executed in the SECONDO, based on the filtering  options selected by the user. These queries and the  database created are sent to SECONDO via sockets.

Lastly, SECONDO executes these queries in the given  database and sends the result back to the Feed  Organizer Parser. It executes another parsing on the  result, which is in the SECONDO format, in order to  convert it to a feed (filtered) again. This feed is sent to  the plug-in (client), and finally, it is shown to the user.

Figure 5 shows the result of this process.

Figure 5: Feed Filtering Result    6. Experiment   An experiment was conducted with 18  undergraduate students aiming at analyzing the  proposed tool and the results obtained, considering the  Allowed Data (AD) and Discarding Prohibited Data  (DP) patterns. A random selection of 93 news items  from 3 communication channels (The New York  Times, The Herald Tribune, and The Washington Post)  on 3 subjects: Sports, Business, and US news.

Figure 6 and Figure 7 show the AD and DP  characteristic curves related to the average number of  news returned by users as per similarity level between  news and user selected keywords. The curves obey the  expected results: when the similarity level rises for AD  operator, the number of news decreases. DP operator  has an inverse behaviour. Moreover, it is possible to  verify that the average number of returned results from  the AD Operator are relatively low (less than 16% of  returned results), showing that users are interested in a  small subset of the news that is provided by the Web  feeds. This excessive number of news may make it  difficult for users to find relevant information.

Differently, the DP operator discards fewer numbers of  news items (maximum value is 12%). However, it is  important to consider that its goal is to eliminate  prohibited subjects, allowing the rest.

Figure 6 ? AD Operator Characteristic curve     Figure 7 - DP Operator Characteristic curve  Figure 8 shows the average precision obtained from  the users? search considering the similarity level, using  the DP Operator. Precision [10] can be defined as the  quantity of relevant returned answers divided by the  number of returned answers, in our case given by the  quantity of relevant returned news divided by the  number of returned news. It is possible to see that high  precision values correspond to low similarity values.

The average precision for the DP Operator reaches,  as its minimum value, 90%. The reason is also the use  of isolated keywords and few combinations of terms.

The average precision for the AD Operator is always  100% for any similarity level. It happens so because  this operator aims at getting relevant news according to  the user?s search, and, in all cases, it contains only  relevant answers. If the similarity level is increased  then less relevant news are included.

Figure 8 ? DP Operator Precision  Figure 9 shows the average recall obtained from the  users? search considering the similarity level using the  AD Operator. Recall [10] can be defined as the  quantity of relevant returned answers divided by the  number of relevant answers. In our case this is given by  the quantity of relevant returned news divided by the  number of relevant news. Average recall for the DP  Operator is always 100% for any similarity level. It  happens so because this operator aims at removing  irrelevant news according to the user?s search, and, in  the most restricted case, it contains all relevant  answers. If the similarity level is increased then more  irrelevant news are included.

Figure 9 ? AD Operator recall    7. Future Trends and Conclusion   In this work, we presented the use of data filtering  and elimination methods to get better news selection in  a RSS client. We had satisfactory results considering  that, in the experiments that were made, it was possible  to filter more than 84% of the news with the AD  pattern and 12% of the news considered as prohibited  were blocked with the DP pattern. Besides, we  introduced the use of similarity to execute a filtering on  the news that exists in feeds which gave us an  alternative, at least interesting, in relation to the  traditional AND and OR operators.

As future works, we hope to increase the autonomic  process maturity level executed in this tool, decreasing  the need for human intervention. As a consequence, the  tool will be able to monitor user actions, selecting  relevant issues, as well as an adequate similarity level.

Nowadays, the tool checks relevant issues but the user  has to provide a set of relevant words and the similarity  level. This project includes the construction of a RSS  server and a data structure that will make it possible to  carry on rules that will be better understood in the  client.

8. References  [1] P. Krill, ?Overcoming Information Overload?, InfoWorld Media Group, Janeiro, 2000. Available at:  http://www.infoworld.com/articles/ca/xml/00/01/10/000110c  aoverload.html.

[2] M. Burgess; W. Grey, N. Fiddian, ?Quality Measures and the Information Consumer?, Proceedings of the Ninth   [3] J. O. Kephart, D. M. Chess, ?The Vision of Autonomic Computing?, IEEE Computer Society, Vol. 36, Issue 1, pp.

41--50, Los Alamitos, CA, USA, IEEE Computer Society  Press. ISBN: 0018-9162. 2003.

[4] A. V. Ratzer, et al, CPN Tools for Editing, Simulating, and Analysing Coloured Petri Nets?, Proceedings of the 24th   Petri Nets, Eindhoven, The Netherlands, Spring. 2003.

[5] K. Jensen, L.M. Kristensen, L. Wells, ?Coloured Petri Nets and CPN Tools for Modelling and Validation of  Concurrent Systems?, In International Journal on Software  Tools for Technology Transfer (STTT). 2007.

[6] R.H. G?ting, et al, ?SECONDO: An Extensible DBMS Platform for Research Prototyping and Teaching?, 21st Intl.

Conf. on Data Engineering (ICDE, Tokyo, Japan), 2005,  1115-1116.

[7] R.H. G?ting, et al, ?SECONDO: An Extensible DBMS Architecture and Prototype?, Fernuniversit?t Hagen,  Informatik-Report 313, March 2004.

[8] R.H. G?ting, et al, ?SECONDO User Manual?, Fernuniversit?t Hagen, Germany, September 2007.

[9] W. A. Pinheiro, G. Xex?o, J. Souza, ?Autonomic Patterns: Modelling Data Killing Patterns using High-Level   and Autonomous Systems, IEEE Computer Society, 2008.

[10] R. Baeza-Yates, B. Ribeiro-Neto, Modern Information Retrieval, Addison-Wesley, 1999.

[11] M. Porter, ?The Porter Stemming Algorithm?, Cambridge University, United Kingdom, 2006. Available at:  http://tartarus.org/~martin/PorterStemmer/.

