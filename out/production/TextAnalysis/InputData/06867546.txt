

Large-scale Entity Extraction and Probabilistic Record Linkage  Dr. Flavio Villanustre Reed Elsevier  LexisNexis Risk Solutions Alpharetta, GA USA  flavio.villanustre@lexisnexis.com    EXTENDED ABSTRACT    Large-scale entity extraction, disambiguation and linkage in Big Data can challenge the traditional methodologies developed over the last three decades. Entity linkage, in particular, is cornerstone for a wide spectrum of applications, such as Master Data Management, Data Warehousing, Social Graph Analytics, Fraud Detection and Identity Management.

Traditional rules based heuristic methods usually don't scale properly, are language specific and require significant maintenance over time.

This presentation will introduce the audience to the use of probabilistic record linkage, also known as specificity based linkage, on Big Data, to perform language independent large- scale entity extraction, resolution and linkage across diverse sources. The presentation also includes a live demonstration reviewing the different steps required during the data integration process (ingestion, profiling, parsing, cleansing, standardization and normalization), and show the basic concepts behind probabilistic record linkage on a real-world application using the open source big data platform, HPCC Systems [1] from LexisNexis.

Keywords - Big Data, entity extraction, disambiguation, public data, identity management, record linking, identity fraud, public data  Attendees will be shown how record field and value specificities, together with phonetics, edit distances and other metrics can be used to disambiguate entities. They will also be shown how social graphs can be assembled based on specific dimensions in the data, and how this social graph information can be used to detect heavily connected cliques that could represent interesting associations (like, for example, those that could be related to potential collusion fraud).

This session will discuss the challenge of resolving identity from billions of identity fragments and why the bigger the data and the higher the redundancy in it, the better the resolution.

The session will outline what this means for key business challenges such as Master Data Management and Data Warehousing.

