Local Mining of Association Rules with Rule Schemas

Abstract? One of the central problems in Knowledge Dis- covery in Databases, more precisely in the field of Association Rule Mining, relies on the very large number of rules that classic rule mining systems extract. This problem is usually solved by means of a post-processing step, that filters the entire volume of extracted rules, in order to output only a few potentially interesting ones. This article presents a new approach that allows the user to explore the rule space locally, incrementally, without the need to extract and post-process all rules in the database. This solution is based on Rule Schemas, a new formalism designed in order to improve the representation of user beliefs and expectations, and on a novel algorithm for local association rule mining starting from Schemas. The proposed algorithm has been successfully tested on the database provided by Nantes Habitat1.



I. INTRODUCTION  KNOWLEDGE Discovery in Databases is the non-trivialprocess of identifying valid, novel, potentially useful, and ultimately understandable patterns in data [1]. The pro- cess of knowledge discovery is a complex one, comprising several phases that deal with problem and dataset focusing, data quality and cleaning, pattern or rule mining, evalua- tion, explanation, reporting and visualization of discovered knowledge. One of the most important techniques used in the mining phase is Association Rule Mining [2]. An Association Rule is an implication of the form a ? b, that shows that the presence of itemset a in a transaction implies, with a certain confidence c, the presence of itemset b in the same transaction.

Association rules may provide valuable information in databases. Nevertheless, the number of rules extracted by knowledge discovery systems is so large that it is impossible to inspect them manually. Moreover, most of the discovered rules are not interesting to the user, since he/she might already know or might not be interested in them, or might not be able to perform any action as a consequence of their discovery [3], [4]. Generally, the interestingness of rules depends on statistical measures as the support and the confidence in the database (the objective aspect of interestingness), but, more important, it depends on the database domain, on user background knowledge and on  Andrei Olaru was with the LINA Laboratory, Ecole Polytechnique de l?Universite de Nantes rue Christian Pauc BP 50609 44306 Nantes Cedex 3, France. He is now with the Departement of Computer Science, University Politehnica of Bucharest, Splaiul Independentei 313 060042 Bucharest, Romania (email: cs@andreiolaru.ro).

Claudia Marinica and Fabrice Guillet are with the LINA Laboratory, Ecole Polytechnique de l?Universite de Nantes rue Christian Pauc BP 50609 44306 Nantes Cedex 3, France (email: {claudia.marinica, fabrice.guillet}@univ-nantes.fr)  1We would like to thank Nantes Habitat, the Public Housing Unit in Nantes, France, and especially to Ms. Cristelle Le Bouter for supporting this work.

user expectations (the subjective aspect of interestingness).

Two main subjective measures of interest were proposed: unexpectedness ? rules are surprising to the user ? and actionability ? rules helping the user to take actions [4].

Focusing on the interesting rules can be done in the rule mining phase of the KDD process or in the post-processing phase. The second approach is suggested as a solution for the rule reduction problem in most of the papers, but its main weakness is that the entire set of association rules must be mined, and then most of them are considered as not interesting and eliminated, the whole process being quite inefficient [4].

This paper presents a new approach, in which post-mining principles are introduced into the mining step, focusing on interesting rules without the necessity of extracting all rules existing in the database. Instead of letting the user inspect huge amounts of output containing thousands of rules, the user may explore the rule space incrementally [5], starting from his own beliefs and knowledge and discovering rules that relate to these beliefs ? confirming rules, specialized rules, generalized rules or exception rules. At each step, the user inspects only a small amount of rules and he/she is able to choose the most relevant ones, for further exploration.

Global post-processing is avoided in favor of a local and focused rule exploration.

There are two key issues in this approach. The first one is focusing on the expectations and beliefs of the user. The solution for representing the user beliefs and knowledge is based on the concept of General Impressions [6], [7]. This paper proposes a novel, more unitary manner of represen- tation ? the Rule Schema, that is not only more flexible and intuitive, but can also use as base elements the concepts from an ontology, providing the representation with infinite possibilities. The ontological aspect is not treated in this paper. Four Operations on Rule Schemas are proposed, that facilitate the exploration of the rule space: Confirmation, Specialization ? discovery of rules with the same conclusion but a more specific condition and a notable improvement in confidence, Generalization ? discovery of rules with a more general condition and a higher support, Exception ? discovery of low-support regularities that contradict more general rules [8].

The second important aspect of our approach is the mining algorithm. As it is inefficient to extract all rules in order to filter a few interesting ones, an algorithm is required in order to focus on interesting rules during the extraction, in the mining step. Such an algorithm has been designed, that acts in a novel manner: based on the existing Rule Schemas and on the Operations performed by the user, the algorithm generates all candidate rules ? all possible rules that may     result from applying the Operations to the Rule Schemas ? and then checks their support against the database. This method is efficient, because the algorithm acts on a local scale, but provides globally valid results.

The proposed method has been tested on a real-life database, provided courtesy of the Nantes Habitat agency.

Several interesting experiments have been carried out and relevant results have been obtained.

The paper is organized as follows. Section 2 presents the research domain and reviews related works. Section 3 describes the Rule Schema formalism and the Operations that the user can perform on the Rule Schemas. Section 4 presents the algorithm focusing on and discovering interest- ing association rules starting from Rule Schemas. Results are discussed in section 5. Finally, section 6 presents the conclusion.



II. RELATED WORK  Subjective measures and the integration of user beliefs were first discussed in the paper of Silberschatz and Tuzhilin [4], in which the most important two subjective interest- ingness measures are introduced: unexpectedness and ac- tionability. Different manners for the representation of user beliefs and expectations have been proposed, mainly related to the two measures above. Three cases of unexpectedness are generally considered, comparing discovered rules and previous knowledge: unexpected condition, unexpected con- clusion, and both condition and conclusion unexpected [9], [10].

The concept of rule templates is introduced by Klemet- tinen [11], as items in two lists: inclusion ? rules that are interesting, and restriction ? rules that are not interesting.

However, all rules must be extracted and the search is not done locally. Moreover, the formalism is very simple and not too flexible. A logical representation and comparison for user beliefs has been suggested [12], but this approach is fairly limited. Liu presented [6] and later developed [7] an interesting representation of user beliefs. It contains three levels of specification: General Impressions (GI), Reasonably Precise Concepts (RPC) and Precise Knowledge (PK). All three formalisms use items in a taxonomy, therefore allowing only for is-a relations between items. Moreover, using three different levels of specification might be difficult to use, if the user wants to combine their features. For instance, the user might know that an item A leads to an item B and knowing that item C relates to them, without being sure on what side of the implication it might be. Representing this kind of knowledge is not possible with the formalism given.

A very early paper discussing the integration of domain knowledge suggests using special structures for the integra- tion of domain knowledge and constraints [13]: Hierarchi- cal Generalization Trees (HG-Trees), Attribute Relationship Rules (AR-rules) and Environment Based Constraints (EBC).

Using item taxonomies was suggested [14], and taxonomy items are also used in the General Impressions formalism [7].

However, taxonomies are limited to is-a relations. There are many advantages in using ontologies instead [15]. Different  manners of integrating ontologies are possible [16], either in post-processing or in a pre-processing step, for filtering of transactions before mining [17].

From the great variety of pattern mining algorithms [18], [19], the Apriori algorithm [20] is the most popular. However, it is difficult to modify the pruning strategy in order not to extract all patterns, but only the ones that might be interesting to the user. In fact, most of the usual pattern- mining algorithms extract all patterns that have a minimum support. Moreover, most algorithms extract patterns, and not rules, association rules being built by using the mined itemsets.

Exceptions to a rule have been taken into account as in- teresting in the KEFIR system [3], that finds deviations from certain norms and references. The algorithm ZoomUR [12] finds rules with a more specialized condition and unexpected conclusion. However in both algorithms the search is not done locally, but considers all rules in the database.



III. FOCUSING ON INTERESTING RULES WITH RULE SCHEMAS  A. Rule Schema formalism  Focusing on the rules that are interesting to the user means finding rules that are in a certain relation with his/her current beliefs. This relation can be one of confirmation or one of contradiction. A formalism representing the user beliefs and knowledge has been designed: the Rule Schema is based on the three levels of specification in the General Impressions formalism [7], but comprises their advantages into one single level of specification. The Rule Schema represents what the user believes about the associative relations in the database.

A Rule Schema is represented as follows:  rs(Condition ? Conclusion [General]) [s% c%] The Condition and the Conclusion contain the items  that the user believes to be present in the antecedent and, respectively, in the consequent of the rule. In complement, the General part contains the items that the user is not sure if they exist in the antecedent or in the consequent. The Rule Schema also contains optional constraints of support and confidence.

The three parts ? Condition, Conclusion and General ? are all Expressions of the following form:  Expr = {Expr} | [Expr] | Expr? | Item That is, an Expression may be a disjunction of other  Expressions, a conjunction of Expressions, an optional Ex- pression or an item from the database. The optionality operator applied over an Expression means that the items that are composing it may or may not appear in the rule.

This formalism completely covers the three levels of specification presented in the General Impressions formalism [7]. If the Condition and Conclusion are used, the Schema is more like a Reasonably Precise Concept or Precise Knowl- edge. If the General part is used, the Schema is more like a    General Impression. The improvement is that a Rule Schema may use all three parts.

Example. If the user knows that there is an implication between Sausage and Mustard, in the form Sausage ? Mustard, and he/she believes that these elements are also associated with Bread, but he/she does not know on which side of the implication Bread exists, the corresponding Rule Schema is:  rs([Sausage] ? [Mustard] [Bread]), with no con- straints.

Moreover, if the user has a feeling there might be some influence of Diet Coke in the condition, and also wants to filter the output based on some support and confidence constraints, the new elements are added to the Rule Schema:  rs([Sausage,Diet Coke?] ? [Mustard] [Bread]) [10% 75%]  The Confirmation operation on the Rule Schema above might output the following rules:  Sausage,Diet Coke, Bread ? Mustard [12% 87%] Sausage ? Bread,Mustard [17% 78%]  B. Operations  Several operations have been designed, that allow the user to explore the rule space starting from previous beliefs and knowledge.

Confirmation is the most simple of the operations that may be performed on Rule Schemas. It finds all rules that comply with the support and confidence constraints and contain the items in Condition in the antecedent, the items in Conclusion in the consequent and the items in the General part in any of the two sides of the implication.

The items in the General part may be split in any possible way between the antecedent and the consequent.

More formally, the searched rules are of the form: Condition ? Subset ? Conclusion ? (General ?  Subset), where Subset ? General Example. The Rule Schema rs([Sausage] ?  [Mustard] [Bread,Bagels]) is confirmed by any of the four following rules:  Sausage,Bread,Bagels ? Mustard Sausage,Bread ? Mustard,Bagels Sausage,Bagels ? Mustard,Bread Sausage ? Mustard,Bread,Bagels During Confirmation, the Expressions present in the Rule  Schema are transformed into lists of items. Disjunctive and optional expressions result into different groups of rules, each corresponding to one element in the disjunction. For example, if the condition is an Expression of the form [{A B} C?], the resulting rules have as condition [A,C] or [B,C] or just [A] or [B].

Specialization allows the user to find the rules that have a more particular condition and the same conclusion, with the condition that the confidence of the specialized rule must be higher than the confidence of the more general rule. That is,  a specialization of a ? b [s1, c1] is a ? c ? b [s2, c2], and it is required that c2 > c1.

The operation is not performed directly on the Rule Schema. Instead, it is preceded by a Confirmation of the Schema, in order to transform expressions into item lists, to split the General part and to calculate confidence and support. The Specialization is performed on rules in the output of the Confirmation operation. On the basis of the rules of the form Condition ? Conclusion resulting from the Confirmation, searched rules for a given specificity level k are of the form:  Condition ? Set ? Conclusion, where |Set| = k and Set ? (I ? (Condition ? Conclusion)), with I the full itemset.

Example. For a Rule Schema rs([A] ? [B] [C]) and I = {A,B,C,D,E} the output of the Specialization operation may be:  A ? B,C [s1 c1] A,D ? B,C [s2 c3] A, E ? B,C [s3 c4]  A,C ? B [s1 c2] A,C,D ? B [s2 c5]  In the example above, it is required that the confidence measures satisfy c3 ? c1, c4 ? c1 and c5 ? c2. For support, it is obvious that s2 ? s1 and s3 ? s1.

As presented, different levels of Specialization are possible. For example, a specialization of level 2 of the rule A ? B,C above might issue the rule A,E, F ? B,C where not one, but two items are added to the condition.

Generalization is the opposite of Specialization. This operation finds the rules that have a more general condition implying the same conclusion. The support is expected to be higher and the confidence slightly lower. Formally, searched rules for level of generality k are of the form:  Condition ? Set ? Conclusion, where |Set| = k and Set ? Condition.

For example, possible generalizations of a rule A,B ? C are A ? C and B ? C.

Exception is an important operation, as it finds rules with an unexpected conclusion, in the context of a more specialized condition. That is, for rules of the form a ? b exceptions are of the form a ? c ? ?b, with the restriction that b must be a single item, so it is possible to be negated.

There are some conditions for a good exception, as speci- fied in [8]. In this paper, it is considered that if the confidence of a ? b is c1, the confidence of a ? c ? ?b is c2 and the confidence of c ? ?b is c3, then c2 must be higher than c1, and c3 must be fairly low, because it must not be c that leads to ?b, but the association of a with c.

Exception may be considered as a Specialization of the rule with the original condition and a negated conclusion. If the attribute in the conclusion is multi-modal, all values are considered, except for the one in the original conclusion.



IV. LOCAL RULE MINING  A. Algorithm description  Following the idea of integrating user knowledge and expectations into the rule mining process, a first attempt was to integrate the Rule Schemas into the Apriori algorithm [20].

However, modifying the pruning strategy in order to focus on interesting rules, in conjunction with the operations described in the previous section, is not very effective and does not generate good results.

Therefore, a novel approach was used. In this approach, the search for interesting rules is done locally, in the neighbor- hood of rules and associations that the user already knows, or that the user believes to be true, specified by means of the Rule Schemas. Instead of finding all valid rules in the database and then filtering them according to interestingness criteria, the algorithm acts in an inverse manner. First, it generates all possible interesting rules ? candidate rules ? based on the Rule Schemas. In the second step, candidate rules are checked for support and confidence requirements, against the transaction database. The final results are pre- sented to the user ordered by their confidence. The steps taken by the algorithm are presented in Figure 1.

Example. Suppose the user wants to find all rules that are the level 1 Specialization of the Rule Schema rs([A] ? {B,C}[D]) [10%, 60%]. That is, A leads to either B or C, and they are associated with D. Support and confidence must be over 10% and 60% respectively. The full item set is I = {A,B,C,D,E, F}. The algorithm works as follows:  ? regardless of the operation, a set of candidate rules is created that result from the Expressions in the Rule Schema and from splitting the General part between condition and conclusion. The result is: [A] ? [B D] [A D] ? [B] [A D] ? [C] [A] ? [C D]  ? all results are tested against the database for support and confidence. Candidates failing to comply with support requirements (support is lower than 10%) are pruned: [A] ? [B D] [25% 67%] [A D] ? [B] [25% 44%] [A] ? [C D] [8% 26%] ? pruned [A D] ? [C] [8% 35%] ? pruned  ? based on the rules that result after pruning, and consid- ering the items in the full item set I that are not already in the rules, all candidate rules are generated, obtaining a first level specialization. Support and confidence are checked and candidates are pruned if the measures do not comply with the requirements of the Schema or if the confidence is not greater than the confidence of the more general rule.

[A C] ? [B D] [7% 20%] ? pruned for support [A E] ? [B D] [17% 62%] ? pruned: confidence is not higher than confidence of ancestor [A F ] ? [B D] [20% 83%] [A D C] ? [B] [7% 35%] ? pruned for support  [A D E] ? [B] [9% 48%] ? pruned for support [A D F ] ? [B] [14% 66%]  ? the remaining rules are sorted according to their confi- dence: [A F ] ? [B D] [20% 83%] [A D F ] ? [B] [14% 66%]  B. Algorithm efficiency  There are a number of advantages that this approach has, compared to the Apriori algorithm. They result in great part from the fact that the Rule Schemas are partially instantiated, so the search space is greatly reduced. Moreover, the more the user refines current Rule Schemas, the lower is the number of generated candidate rules.

Compared to Apriori, the number of passes through the databases is lower. Once all candidate rules are generated, only one pass through the database is necessary, to check the support of the candidates. For complexity reasons, in the case of multi-level operations one pass per specificity / generality level is necessary.

One important issue in the presented approach is the number of generated candidate rules. This depends on the operation and on the properties of particular Rule Schemas, as shown below.

For the operation of Confirmation on a Rule Schema rs(X ? Y [Z]) (where X,Y,Z are item sets), the number of generated rules is equal to the number of possibilities of splitting the Z set into subsets. The subsets are added to the left and right sides of the implication. The number of possibilities is equal to 2|Z|, the number of subsets in Z: for each subset S in Z, S is added to the condition and Z ? S to the conclusion. As searches are performed in the close neighborhood of the rule, the number of items in Z is fairly low.

For the operation of Specialization, all the rules of the form X ? S ? Y are generated, where S is not included in X ? Y and |S| is the specificity level. Normally, the number of candidate rules would be |I||S| where I is the set containing all items that appear in the database. However, there is a way of implementing this operation more efficiently, based on the idea of the Apriori algorithm. First, all the candidate rules with one item added to the condition are generated, then checked for support. This prunes most of the level 1 candidates. The level 2 candidates are obtained by adding one more item to the condition of the level 1 results and then are checked for support. This approach greatly reduces the total number of generated candidate rules.

For the operation of Exception, the rules of the form X ? S ? y? are generated, where y is a single item and S is a set of items not in X and not containing y. The number of candidate rules is of the same order with the Specialization operation, but, in the case of multi-modal attributes, it is multiplied with the number of modalities of the attribute y, minus 1. The same approach as for Specialization may be used for Exception.

For the operation of Generalization on a schema X ? Y , candidate rules with fewer items in the condition are    create empty lists of rule candidates rList and rListS  // Confirmation for each side Sd in {Condition, Conclusion, General}  create set C[Sd] containing all item lists resulting from the Expressions in Sd for each item list Cond ? C[Condition], Cons ? C[Conclusion], Gen ? C[General]  for each subset GS of Gen add to rList a new candidate rule CR(Cond ? GS ? Concl ? (Gen - GS))  for each transaction T in the database for each candidate rule RC ? rList  check support s and confidence c for CR remove from rList all rules with s < minsup  // Specialization for each candidate rule CR(X ? Y) ? rList  for each item i ? I - (X ? Y) add to rListS the CR(X ? {i} ? Y)  for each transaction T in the database for each CR(X ? {i} ? Y) ? rListS  check support s and confidence c1 for CR and check confidence c2 for {i} ? B remove from rListS all rules with s < minsup or c1 < minconf or c1 < c2 return rListS  Fig. 1. Candidate rule generation and matching algorithm  generated. For all levels of generality, 2|X| candidate rules are generated, but X is not likely to have more than 5 or 6 items.

One more factor is added to the complexity of candidate rule number. If the expression lists contain disjunction op- erators, then candidate rules are generated for each term in the disjunction. However this is not likely to significantly increase the number of candidate rules as the expected number of terms in the disjunctions is quite low.

Comparing the algorithm above with apriori, the operation of confirmation would require, using apriori, the extraction of all the rules in the database and then the filtering of the result, in order to focus on the desired rules. The extraction of all frequent itemsets requires several passes through the database, equal to the maximum number of items in the frequent itemsets. Moreover, discovery and filtering of rules requires additional database access. With the algorithm presented in this paper, the confirmation operation requires only one pass through the database, testing each candidate for required support and confidence. In practice, the number of candidates is considerably low and the number of items in a rule is fairly reduced, therefore the complexity of the algorithm is almost linear with the size of the database.



V. RESULTS AND DISCUSSION  An application was developed that implements the algo- rithm described above and allows the management of Rule Schemas. The application was tested on a real-life database.

The database used was provided by Nantes Habitat, a pub-  lic office that manages social accommodations in Nantes, France. Each year, 1500 Nantes Habitat clients (out of a total of 50000) answer a questionnaire about the quality of their accommodation. The questionnaire contained 78 questions in 2006. Nantes Habitat offered for data mining experiments the results obtained between the years 2003-2006. Each question refers to a certain element related to the accommodation and may be answered with one of 4 degrees of satisfaction.

In the database, there exists one attribute for each ques- tion. The possible values for the attributes are 1 to 4 for the satisfaction level, 95 and 96 for ?not applicable?, 99 for ?don?t know? and 0 if the client did not answer the question. The database contains one transaction for each questionnaire. The transaction is represented by the answers (or the values representing the lack of answer) to each of the questions. Because the algorithm needs binary attributes, items of the form question answer are formed, for example the item Q35 1 represents an answer of ?very satisfied? to the question number 35 ? about the lighting of common spaces.

Therefore there are a total of 624 items.

For testing, two databases were used, from year 2003 and 2006, containing 1490 transactions each. Using the provided databases, some simple examples have been created and encouraging results have been obtained. The most interesting ones are presented below.

Example 1. The analyst is interested on the dissatisfaction related to common spaces in the proximity of the accom- modation. The search starts with unsatisfied answers (value ?4?) to two questions related to the problem: Question 7 ?    ?The quantity of green spaces is sufficient? and Question 65 ? ?The cohabitation difficulties are treated efficiently?. The analyst already knows the direction of the implication (which is quite obvious) and creates a Rule Schema of the form:  rs([Q7 4] ? [Q65 4] [ ]) with no support and confidence constraints.

An operation of level 1 Specialization has the following output:  62 results.

[Q7_4, Q72_4] -> [Q65_4] [ 1.2% 81.8% ] [Q7_4, Q93_4] -> [Q65_4] [ 1.2% 78.2% ] [Q7_4, Q37_4] -> [Q65_4] [ 0.9% 76.4% ] [Q7_4, Q55_4] -> [Q65_4] [ 0.8% 75.0% ] [Q7_4, Q22_4] -> [Q65_4] [ 0.5% 70.0% ] ...

It is the rule with the highest confidence that shows the relationship with Question 72 ? ?In case of works performed in the common spaces, are you satisfied with the information received?. This relation with maintenance works leads the analyst to want to add another item to the search: the unsatisfied answer to Question 58 ? ?Delays of the interventions to repair degradation of common spaces?.

However the analyst does not know how this answer relates to the other elements in the rule, so he just puts it in the General part of the Schema. An operation of Confirmation on the resulted Rule Schema rs([Q7 4] ? [Q65 4] [Q58 4]) shows that item Q58 4 is most likely a condition rather than a conclusion:  2 results.

[Q7_4, Q58_4] -> [Q65_4] [ 1.4% 75.0% ] [Q7_4] -> [Q65_4, Q58_4] [ 1.4% 18.2% ]  Now the analyst runs a level 1 Specialization on the same Rule Schema. The results are interesting:  78 results.

[Q7_4, Q39_4, Q58_4] -> [Q65_4][ 0.8% 100.0%] [Q7_4, Q49_4, Q58_4] -> [Q65_4][ 0.9% 93.3% ] [Q7_4, Q25_4, Q58_4] -> [Q65_4][ 0.9% 92.9% ] [Q7_4, Q93_4, Q58_4] -> [Q65_4][ 0.7% 91.7% ] [Q7_4, Q57_4, Q58_4] -> [Q65_4][ 0.7% 90.9% ] [Q7_4, Q50_4, Q58_4] -> [Q65_4][ 0.5% 88.9% ] [Q7_4, Q6_1, Q58_4] -> [Q65_4] [ 0.5% 87.5% ] [Q7_4, Q63_4, Q58_4] -> [Q65_4][ 0.9% 86.7% ] [Q7_4, Q5_1, Q58_4] -> [Q65_4] [ 0.8% 85.7% ] [Q7_4, Q2_1, Q58_4] -> [Q65_4] [ 1.1% 84.2% ] ...

A number of relevant conclusions can be drawn related to the dissatisfaction about common spaces. Although the rules extracted have fairly low support, it is the high confidence that shows that they are important and must be considered.

The new items in the conditions of the extracted rules show that the problem relates to unsatisfied answers to other questions like Q39 ? on the building?s ambiance, Q25 ? state of building?s proximity or Q57 ? important reparations on common parts. However the last rules in the first 10 results are unexpected: the problem relates with very satisfied answers (value ?1?) to the three questions Q2, Q5 and Q6 ? access to the city center, administrative services and parking  spaces. This can mean only one thing: that the problems of common spaces and repair works in the common spaces are most likely related to the accommodations closer to the center. That may be considered as valuable information.

Example 2. The analyst knows that there is a relation between questions Q13 and Q2 ? ?There are sufficient spaces for children? and ?Access to the city center?, more precisely between the ?very satisfied? answers to the two questions.

A Confirmation operation on the Rule Schema rs([ ] ? [ ] [Q13 1 Q2 1]) shows that the implication is from the first to the second:  2 results.

[Q13_1] -> [Q2_1] [ 15.30% 75.50% ] [Q2_1] -> [Q13_1] [ 15.30% 23.46% ]  The first rule that resulted is quite strong, so the analyst wants to know if there are any exceptions to the rule. He/she performs a first level Exception operation and he/she gets the result below:  1 result.

[Q1_4, Q13_1] -> [Q2_2] [ 0.20% 100.00% ]  Although the resulting rule has a low support, it has a very strong confidence, which is much higher than the confidence of the initial rule, even if the support is smaller. Moreover, the confidence is higher than the confidence of the rule Q1 4 ? Q2 2 [0.87% 56.52%], so it is the association of Q1 4 and Q13 1 that leads to the result.

The result shows that, although generally the satisfaction about spaces for children leads to a satisfaction about the access to the center, in the special case where there is dissatisfaction related to transportation (Question 1), people tend to be less satisfied about access to the center. This quite interesting association might be considered as valuable information.



VI. CONCLUSION  In this paper we have presented a new solution for local association rule mining that integrates user beliefs and ex- pectations. The solution has two important components. The Rule Schema formalism, based on the concepts introduced by Liu [7], helps the user focus the search for interesting rules, by means of a flexible and unitary manner of representation.

The local mining algorithm that was developed does not extract all rules and then post-process them, but, instead, searches interesting rules in the vicinity of what the user believes or expects. This way, the user can explore the rule space in a local and incremental manner, global processing being avoided.

The proposed algorithm was tested on a real-life example, showing that the presented solution is valid and leads to good practical results.

