SmartMiner: A Depth First Algorithm Guided by Tail Information for Mining  Maximal Frequent Itemsets

Abstract Maximal frequent itemsets (MFI) are crucial to many  tasks in data mining. Since the MaxMiner algorithmfirst introduced enumeration trees for  mining MFI in 1998, several methods have been proposed to use depth first search to improve performance. To further improve the performance of mining MF!, we proposed a technique that takes advantage of  the information gathered from previous steps to discover new MFI. More speci$cally, our algorithm called SmartMiner gathers and passes tail information and uses a heuristic select function which uses the tail information to select the next node to explore. Compared with Mafia and GenMax, SmartMiner generates a smaller search tree, requires a smaller number of support counting, and does not require superset checking. Using the datasets Mushroom and Connect, our experimental study reveals that SmartMiner generates the same MFI as Mafia and GenMax, but yields an order of  magnitude improvement in speed.

1. Introduction Mining frequent itemsets in large datasets is an  important problem since it enables essential data mining tasks such as discovering association rules, data correlations, sequential patterns, etc.

Let I be a set of items and D be a set of transactions, where a transaction is an itemset. The support of an itemset is the number of transactions containing the itemset. An itemset is frequent if its support is at least a user specified minimum support value, minSup. Let FI denote the set of all frequent itemsets. An itemset is closed if there is no superset that has the same support. Let FCI be the set of all frequent closed itemsets. A frequent itemset is called maximal if it is not a subset of any other frequent itemset. We denote MFI as the set of all maximal frequent itemsets. Any maximal frequent itemset X is a frequent closed itemset since no nontrivial superset o f X  is frequent. Thus we have MFIcFCILFI.

There are three different approaches for generating FI.

First, the candidate set generate-and-test approach [ I , ]  1,14,8,12,7]: most previous algorithms belong to this group. The basic idea is to generate and then test the candidate set. This process is repeated in a bottom up  fashion until no candidate set can be formed. Second, the sampling approach [7]: it selects samples of a dataset to form the candidate set. The candidate set is tested in the entire dataset to identify frequent itemsets. Sampling reduces computation complexity but yelds incomplete result. Third, data transformation approach [6,16,17]: it transforms a dataset for efficient mining. For example, the FP-tree [6] builds up a compressed data representation called FP-tree from a dataset and then mines FI directly from the FP-tree. Another example is the pattern decomposition algorithm (PDA) [16,17] which decomposes transactions and shrinks the dataset in each pass.

When the frequent patterns are long, mining FI is infeasible because of the exponential number of frequent patterns. Thus, algorithms mining FCI [9,15,10] are proposed since FCI is enough to generate association rules. However, FCI could also be as large as the FI. As a result, researchers now turn to find MFI. Given the set of MFI, it is easy to analyze many interesting properties of the dataset, such as the longest pattern, the overlap of the MFI, etc. Moreover, we can focus on part of the MFI via supervised data mining.

: i !CreatingBz before i,-/exploring B,  ! I iCreating Wafter 'i.;./exploring B, '\. ,'  (a) Dynamic reordering (b) SmartMiner Strategy \.,'  Figure I: SmartMiner takes advantages of the information from previous steps.

The current MFI mining uses depth first search with dynamic reordering as in DepthProject[Z], Mafia[l], and GenMax[5]. Those methods are significantly faster than previous approaches. However, they do not use the information from previous steps for exploring next nodes and requires the traverse of a larger search space than necessary. As shown in Figure 1, the dynamic reordering technique creates a set of sub nodes B,-B. before exploring B,. In contrast, SmartMiner takes full advantage of the information from previous steps and explores B, before selecting the node B'.

0-7655-1754-4102 $17.00 Q 2002 IEEE 570    Using tail information has many benefits: it does not require superset checking, reduces the computation for counting support, and yields a small search tree.

In this paper, we first discussed the limitations of current MFI algorithm, then introduced the partition and pruning properties used in the SmartMiner. The SmartMiner strategy and implementation are then presented. Finally, the experimental performance comparison of SmartMiner with Mafia and GenMax are included.

1.1 Related works We first introduce an enumeration tree for an itemset 1.

Assume there is a total ordering over I which can be used to enumerate the search space. Each node has a head and a tail representing a state. The head is a candidate while the tail contains items to form new heads. For example, Figure 2 shows a complete enumeration tree over five items abcde with the ordering a.b,c.d.e. Each node is written as head:tail. For an item ai in  the tail of a node X;Y, a sub-node is created with Xai as its head and the items after ai in Y as its tail. For instance, the head of :abcde is empty and its tail is abcde.

:abcde  a:bcdr k < u - d u \  ab:ede acde ade ae: bcde M:e be: c d e  ce: de:  abcde aM:e abe: acde ace: j ade:j bcde  bce: i Me: cde: a b d e  i ahccabde: acde: abcde:  -==z- ?--==.- pg=p ..... .y . .

-w- Cut .... b.~d.e I ........-  Figure 2: An enumeration tree for abcde for the given order of a, b, c, d, e.

The problem of mining frequent itemsets is to find a cut through this lattice such that all itemsets above the cut are frequent, and those helow the cut are infrequent (see Figure 2) [14].

Using the enumeration tree as shown in Figure 2, we can describe recent approaches to the problem of mining MFI. MaxMiner [3] uses a breadth-first search and performs look-ahead pruning which prunes a whole tree if the head and tail together is frequent. MaxMiner also first uses dynamic reordering which reorder the tail items in the increasing order of their supports. In general, however, superset pruning works better with a depth-first approach [2] since many long frequent itemsets may already have been discovered. But MaxMiner uses a breadth-first approach to limit the number of passes over the database.

Since large main memory size is available in Gigabytes, current MFI mining uses depth first search to improve performance to find long patterns.

DepthProject[Z] uses depth first search on a lexicographic tree of itemsets to find MFI, and projects transactions database on the current node to speed up the  counting for support. Depthproject also uses look-ahead pruning and dynamic reordering. With dynamic reordering, infrequent i t e m  at the current node can be deleted from the tail so that the size of the search space can be greatly reduced.

Mafia [4] proposes parent equivalence pruning (PEP) and differentiates superset pruning into two classes FHUT and HUTMFI. For a given node X:aY, the idea of PEP is that if sup(Xj=sup(Xaj, i.e., every transaction containing X also contains the item a, then the node can simply he replaced by Xa:Y. The FHUT is to use the leftmost tree to prune its sister; if the entire tree with root XatY is frequent, then we do not need to explore the sisters of the node Xa:Y. The HUTMFI is to use the known MFI set to prune a node. That is if an itemset o f X a Y  is subsumed by some itemset in the MFI set, the node Xa:Y can be pruned.

Mafia also uses dynamic reordering. The results show that PEP has the largest effect of the above pruning methods (PEP, FHUT, and HUTMFI) and dynamically reordering also has significant savings in computation.

Both Depthproject and Mafia mine a superset of the MFI, and require a post-pruning to eliminate non-maximal patterns [SI. GenMax [5] integrates pruning with mining and returns the exact. First, just like the transaction database is projected on the current node, the known MFI can also be projected on the node and thus yields fast superset checking. Second, GenMax uses Diffset propagation to perform fast frequency computation.

Experimental results show that GenMax has comparable performance with Mafia.

1.2 Limitations of previous approaches The algorithms discussed above do not take full  advantage of previous searching. Let us use Mafia as an example to illustrate that limitations exist in previous approaches. For the example in Figure 2,  Mafia will generate a search tree as in Figure 3, assuming that frequent itemsets have different support and the nodes are already'sorted in the order of increasing support. In the figure, the shaded nodes will be removed by superset pruning. The node abcde: in the dotted box is not in the search. The nodes with crossing lines are tested and found to be infrequent.

:ahcde  xbcde 6% - c:de d e  e: - abcde ac:de a d e  ae:' bcde  b d e  be: cde ce:; de: -1 Y.'.

abc:de wy.. abde  abea-> ...y.. ... ... ... ........._ abcda i &ab&+ &  e& \ 8 6 $ b  I  .... * ......

cut &&;l  Figure 3: The search tree for Mifia.

First, the size of the tree is too large and can be  reduced. Although the shaded nodes can be pruned away,     a more efficient strategy is not to generate those nodes in the search tree. As shown in Figure 3, Mafia traverses 31 nodes. SmartMiner uses such a strategy and traverses only 9 nodes (see section 3.2) for the same example.

Second, there is too much counting for determining the frequency of tail items. Figure 4 shows the counting tree for Figure 2. Let X be an itemset and T(X) be the set of transactions that contains X. For the root node at the top level, the transaction set is T(4) since the head of the node is empty 4. For the node, the supports of a,b,c,d,e are counted and found to be above minsup. In the transaction set T(a), we found b.c,d,e frequent. Likewise, items c,d,e are frequent in T(ab), and item d is frequent and e infrequent in  T(abc). Mafia requires a total of 30 frequency tests. Using tail information and a heuristic select function, SmartMiner needs only 23 such tests.

a-bLh7e hC\\ I\\ I b d e c  d e d e u  c d e d e + d  e + +  d * + +  U I\\ \ I  Figure 4: The Mafia counting tree.

Finally, all previous approaches require superset  checking for two purposes: pruning nodes and removing non-maximal itemsets in MFI. If the set of MFI is large, as in most real datasets, superset checking can be very expensive. In the above example, Mafia performs 30 superset checks. As will be discussed later, SmartMiner does not require any superset checking.

2. Partition and Pruning Properties 2.1 Partitioning a search space  Let N = X Y  be a node where Xis the head of N and Y is the tail of N. The power set of Y is the set of all possible subsets of K denoted by P@).

Definition 1 For a node N=X:Y, the set of all itemsets obtained by concatenating X with the members in P(Y) is called the search space of N, denoted as { X Y } .  That is  { X Y }  = { XUYl Y E P @ ) } .

For example, the search space {b :cd )  includes four  itemsets b, bc, bd, and bcd. Likewise, the search space (:abcde) includes all subsets of abcde.

By definition 1, we have { X ; Y } = { X Z )  where Z=Y-X.

Thus we will assume the X and Y share no item when { X : Y )  is used in this paper.

Definition 2 Let S, SI, and SI he search spaces. The set {SI,  SI} is apartition of S if and only if S= SI U S, and S l n S , = @ .  The relationship is denoted by S=Sl+S2 or SI= S-S, or S,= SS,. We say S is partitioned into SI and S,. Similarly, a set {SI, SI, ..., S,) is a partition of S if and only if S= SI u S, U. .. US, and S i n  q=$ for i,;? [ I . . k ] and it;. We denote it asS=Sl+S2+ ...+ S,.

Let a be an item, then &is an itemset by adding a to X.

Theorem 1 For aP X. Y, the search space of (X:aY} can he partitioned into {Xa:Y) and (X:Y} by item a ,  that is, ( X a  Y} =(Xa: Y} +{X: U.

I t  follows from the fact that each itemset of {X:aY)  either contains a or does not contain a.

Proof  For example, we have { b : a d ) = { b a : d ) + { b : d } .

In general, al,a2, .... ak can he distinct items and  Theorem 2 Partition search space: the search space of ala ,... akY forman itemset.

{ X  ala >... a k Y }  can he partitioned into x  x { X a i  : a,+, ... a, Y }  +{X : Y } ,  where a , r X  Y.

Proof It follows by partitioning the search space via items al.a,, ..., at sequentially as in theorem 1 .

For example, we have {b:cd)={bctd)+{bd:}+{b:) and { o b c d e  )= {ab:cde)  +(ac:de ) + { a ; d e ) .

Let { X : Y }  he a search space and Z be a known frequent itemset. Since Z is frequent, all subsets of Z will be frequent, i.e. every itemset of { : Z }  is frequent.

Theorem 3 Pruning search space: if Z does not contain the head X, the space { X Y }  can not he pruned by Z, i.e., { X ; Y } - { : Z ) = { X Y J .  Otherwise, the space can be pruned as  ,=I  k  { x y i - { : z i  =C{xai : u8+] ... a, (Y n z ) }  , o , o ~ . . . o k = ~ - z .

i=l  Pro08 If Z does not contain X ,  no itemset in {X: Y )  is subsumed by Z. Therefore, knowing Z is frequent can not prune away any part of the search space { X : Y } .

Otherwise, Xis a subset of Z.  Thus we have  ( X : Y ) = c { X a ,  :a ,+,  ... a ,V}+X:  V,m,here Y = Y n Z .

The head in the first part is Xai. Since Z does not contain ai,  the first part can not he pruned. For the second part, we have {XV) - { :Z}={XY}-{X: ( z -X)} .  Since X n Y = @ ,  we have Y G Z - X .  Therefore { X : V )  can be pruned away entirely.

For example, we have { :bcde}-{ :abcd)={ :bcde)- { :bcd)= {e:bcd) .  Likewise, (e :bcd}- {  :abe)={e:bcd)- { :be  )= {e :bcd)- {e:b  } = { ectbd}+{ ed:b}.

2.2 Evaluating Tail Information  Definition 3 Let M he the known frequent itemsets and N = X Y  be a node. The tail information of M for N ,  Tlnf (NIM), is the tail parts of the frequent itemsets in { X Y } that can be obtained from M, i.e.,  k  i.1  T'nf(N I M )  = {Y  n Z  I VZG M , X  c Z) For example, TInf(e:bcd/{abcd,abe,ace))={ b , c ) ,  which means that eh and er are frequent given { a b d a b e , ace)  is frequent. Likewise, lnf(e:bcd/{abcd.abe,ace, bce}) = {b , c ,bc } .  For simplicity, we refer to tail information as information,     Definition 4 Let W be tail information and Z be a The value of tail information W is the member of W.

union of the power set of 2. That is, VTI = U Pp). ZE W  For example, VTl((b,c,bc))={ 4 ,b,c.bc)=VTl({bcJ).

Notice that removing non-maximal itemsets from tail information does not decrease its value. Therefore, a non- maximal itemset in the information set can he deleted.

3. The SmartMiner 3.1 Information guided depth-first search  Since the tail of a node contains many infrequent items, pure depth-first search is inefficient. Hence, current approache uses dynamic reordering to prune away infrequent items from the tail of a node before exploring its sub nodes.

Input Output Transaction set T=T(X) A UpdaledGlnf Tail of the nade S=Y Global information  'Figure 5: Search strategy at the node Ni=X:Y In contrast, SmartMiner uses tail information to guide  depth-first search to improve search efficiency. We illustrate the strategy for a given node N;=X: Y as shown in Figure 5 .  The purpose of the node Ni=XY is to compute maximal frequent itemsets in the transaction set T(X). The input for node N,=X:Y is transaction set T(X), the tail Y, and the tail information for N; known so far, Gini  is called global tail information for node N;. The output of the node is the updated Gin/ and discovered maximal frequent itemsets Mfi. Upon calling the node N,, we count the supports for the items in the tail Y. Yo is obtained by removing infrequent items from Y.

The time sequence at node N, in Figure 5 is tbti, ..., tn.

At the moment to, item a.  is selected from Yo to be the head of next state Si and Y,= Y, a s i s  the tail of SI. The tail information In& is computed by Inf(aO:Y, IGlnfi. We then create node Ni+,=Xa,:YI. The call for node Ni+l returns Mfin and updated In& in which the members survive in the node Ni+/ are returned, i.e. those subsumed by Mfo are deleted (no superset checking). At ti, we calculate the tail information In/& for Yl from In/&, infio, and Mfo. The information from Inf& and Infli-n is updated  .global information. The information from Mfio is local  information. Using information In/&,. item a ,  is selected from Yl to be the head of the next state Si and Yz= U,- a,  is the tail of Si. Then node Nj+2=Xaz:Yz is created and called to compute maximal frequent itemsets in transaction sets t(Xa 3. This process continues untill In where no item can be selected as head of SI. The returned maximal frequent itemsets Mf= U a, Mfit, i E  [O . .n - I ] ;  the updated Glnfare these itemsets in the original GInfwhich have not been marked as deleted.

SmartMiner uses tail information to guide the depth- first search which is different from dynamic reordering depth-first strategies (DFS). First, SmartMiner defers creating a node untill its preceding nodes are visited, while DFS creates nodes for each item in the tail of a node in the increasing order of their supports. DFS creates as many sub trees as the number of frequent items in the tail.

Second, SmartMiner uses a heuristic select function with consideration of the tail information and the frequency about each item (see section 4.3). Using this heuristic, SmartMiner creates far fewer sub trees than dynamic reordering. Finally, by passing tail information, SmartMiner does not require the time for superset checking that is required for DFS.

3.2 An example  We now use an example to illustrate how SmartMiner finds the same MFI for the example in Figure 3. As shown in Figure 6,  there are nine nodes No, N I ,  ... , Ns in the search tree. For a given node, the columns to, 11, ..., t , represent sequential time points. The row Sn represents the initial state and the Info is the tail information for So.

The row SI is the next state to explore and the relevant information is on the row In&. Note here Inf, also called the global information as input for the next state and will be updated. The row Mfi is the returned mfi after exploring the state Si. On top of each node, we give the transaction set for the node. For example, the transaction set for No is the entire dataset T(@); the transaction set for NI is T(a) which represents all the transactions containing i tema.

SmartMiner begins at the node No at to, No(td, where Sn=:abcde and Info is empty. At this point, item a is selected and thus the next state Sl=a:bcde. Here Infi is empty since Info is empty. Next SmartMiner creates the node NI for the state SI=a:bcde by setting its transaction set T(a) and its initial set So=:bcde. When SmartMiner calls the new node NI,  each item in the tail So=:bcde will be sorted in the increasing order of their support in T(a) and the infrequent items will be dropped. The process continues to N & ) ,  and then to N3(td where &=:de and e is dropped since it is infrequent in T(abc). This yields So=:d; SmanMiner returns d as mfi to N & j  which will be added into Info at N,(tJ. Thus at N&, In& =d.

SmartMiner then selects Sl=e:d for the next node, N&.

Figure 7 shows the tree for counting support using SmartMiner. At node No, SmartMiner counts the supports for a.b,c,d.e and finds they are frequent. At node NI, items b.c,d,e are found to be frequent in T(a). It is shown that there are a total of 23 times to count for support.

4. Implementation of SmartMiner 4.1 Object model design  Our data mining system is implemented in Java rather than C++ because Java has better portability. Figure 8 shows the three classes in our system whose data types are specified using Java language. The class VDatu is the vertical data model for a transaction dataset. It loads data from a given fileNume and builds up a BitSet for each frequent item. The Tlnf class manages the tail information for a given node. The Miner class uses the proposed tail information based on depth-first search to recursively discover all MFI. An instance of Miner has exactly one object of VData and will dynamically create one object of Tlnffor a node when the mining starts. More details are given in the following sections.

Input  MR=obcd,obe,oce,ebc.ed  - VData  .data: BitSa[] - mi"sJp: in1 + VData(String tileName, float rm"S"P) + @tan(%orts lail):shon[] + ealSup(int[] bare, Shorts tail):shon[] + etBardim[] base, shon itm):int[] - uilSup(int[] base, shon item):int - loadDala(S1ring fileName):void  Info nil  lnf, nil M f i  d  Tlnf  + @"t snledShotts[] + mfi: Vector +tail: S o n s - infs: Hashtable -pep:  short[]  +Tlnf(Vcclor@nf,shotl[] pep, Shons tail) + Addlnfdvector newLn0:void + AddMfilnf(Venormfi1):void + Doltan(short itm):Vector + rc1cctO:shan . maxlenO:shon[]  ~ -  t A n o b e )  Info nil  l"f, nil M f i  M"er -"Data: VData -mfi:vector -1  ,.....

j + min(Stingargv[]): void + ~ i ~ e r ( s t r i n ~ f i i ~ ~ ~ ,  noat minsup) + minin$): void - inM fi(inl[] base, Sholls tails, Venor @no: Venor - output0:void  I .

............ jT=T(d  S=e:bed !

! Glnf=b, c I  t  butput !

1 Glnf+, e !

1 Mfi=be d !

Figure 6: An SmartMiner Example.

The entire search route will be No&,), N&J, N2(td, Ndtd.  N z ( f 3 ,  N d d ,  Nz(t.d. Ndtd, Ndtd, N V 3 ,  No(t3, N&. N,(t,J, N6(tl), N&, Nti(tJ. and No@J As shown in the figure 6,  at Nl,(tl), Info=bcd,be,ce, Sl=e:bcd, and the two itemsets be,ce contain e.  By removing e from be,ce, we get Inf,=b.c. When calling No, global information Ginf=b,c is passed from NOPI) to N&. Upon completing exploring the node Nti. bc,d are found to be mfi and Ginf=b,c will be updated to be empty since they are dropped respectively at Nnlta) to No(tl) and at Nti(tl) to N6(tJ. When it returns from N6, the Inf, at No@]) will be empty. By collecting Mfi, Inf,, and unselected In& at No(rl), we have Inf,=bcd,bc,d at No(tJ. The search terminates at Nn@J since the tail of So=:bcd is in the Inf.

b c d  b c d  c d e  c 4  d b s m R I n h l d Figure 7: The counting  tree for SmartMiner.

in methods caCSup and getBase is an array of transaction IDS. The base of a node represents the transaction set T(X) where X i s  the head of the node. The private method calSup(int[] base, short item):int is to calculate the support of the item in the given base.

The VData provides three methods for data mining.

First, the method getSfart(Shorts tail):short[l returns the set of items that occur in every transaction. It also passes other items by Shorts tail in the order of increasing support. The getstart is called at a root node. Second, the public method calSup(int[] base, Shorts tail):short[l is similar to the getStart. It returns the set of items in every transaction of the base and passes other frequent items at the base in the order of increasing support.

Finally, the method getBase(int[] base, short item):intu simply returns a new base which is the subset of the base whose corresponding transactions contain the item.

Note that when calculating support of an item in a base, the VData needs to test as many bits as the size of the base. It is slower than the Bitmap model where supports can be calculated a byte (8  bits) at a time. Our VData model is also slower than the difset model of GenMax[] .

However, the VData keeps only one copy of data and thus needs less memory than the other two models. In other words, both Mafia and GenMax need to build up new datasets for the mining of sub nodes. Moreover, the VData is easy to implement and is fair to use as a common data model to compare different search strategies of SmartMiner, MaJk,  and CenMax.

4.3 Tail information class: TInf For a given node, an instance of the Tinf class is created  to manage the tail information. The ginf is passed from its parent node and the mfi is the local maximal frequent itemsets for the node. The itemsets to be explored is stored in the tail whose information is stored in the hash table inf. The pep is the set of items occumng in every transaction of the node.

The constructor method accepts ginf, pep, and rail to create a new instance. The public methods Addlnfo and AddMfilnf calculate relevant information of the newinj and the mfil on tail respectively and then hash them into the hash table infs. The method Doltem separates the members in the i n f  into two groups: one mentions the item; another does not. The first group will he removed from the hash table and returned as a vector after dropping the item from every itemset. The second group remains in the table. The method also removes the item from the tail.

For every item in the tail, the private method maxLen is to find the maximal length of itemsets in inf that contains the item. Note that, in our experiment, we use a simplified marLen that returns an array of value either 0 or the maximal length. More specifically, the maxLen first finds the longest itemset V in the infs and then set the lengths of items in V t o  Iy and the lengths of others to 0.

I*' * Select an item to build a sub node.

* @return > = O  i f  success, -1 if no next items.

* I  public short select0 1 if ltail.sizeO<=l) 2 if t a i l  i n  i n f s  then mfi=null e l s e  mfi=tail; 3 return -1 ; 4 short11 len = maxLen0; 5 find the min. nax p s i t i o n  mi-, - i n  len; 6 if llen[maxpl==tail.sizeO) 7 u-te the ginf info; 8 return -1: 9 return tail.get(minp);  Figure 9: The selection method: a heuristic to select an item for oartitionino the search soace.

Figure 9 describes the heuristic method to select an item to partition the search space. In dynamic reordering, the item of the least support is chosen to explore first. Such heuristic has been shown to be effective. Our heuristic select function considers both tail information and the supports. The observation is that, if an item contained by an itemset of size k in the inf, there are 2' itemsets that are known to he frequent and can be pruned away from the search space. Therefore our heuristic chooses an item of the smallest known space. If the size of current tail is less than 2, the search space is immediately solvable as shown in line 1-3. Line 4 calls the method maLen.  Line 5 is to find the positions of the minimal and maximal values in fen. Note that, if several items have the minimal value, we will choose the one having the least support. If an itemset in the inf has the size of the tail, this means the whole search space of the tail is frequent and thus there is no need to build a sub node as shown in lines 6-8; other itemsets in the infs are non-maximal and those originated from ginf will be deleted. Note that no superset checking is used to eliminate non-maximal itemsets. Line 9 returns the selected item.

4.4 Data mining class: Miner The Miner class has two attributes and five methods as  shown in Figure 8. The vData stores transaction data in vertical format. The mfi is a vector of maximal frequent itemsets. The main reads filename and minSup from command line and calls Miner, mining, and output sequentially. The Miner initializes vData and the output stores the mfi into a file. The mining method is to mine the vData.

Now we present the information guided depth first algorithm which returns local MFI as in Figure 10. The parameter base is the transaction set for the node head.

The globe information ginf will he updated upon return.

Line I calls vData.calSup to get the pep and an updated tails sorted in the increasing order of supports. Line 2 creates an instance of the Information class for this node.

Lines 3-9 loop selects an item for the next node and solve it. More specifically, it selects an item i fm for next node as show in line 3. If there is no node selected, it goes to line 10. Otherwise, i t  enters the loop body. A new base is calculated at line 4, the infDoIfem method is called and the new-tail is set. Then line 7 solves the sub node.

Upon returning from the sub node, it adds the updated newsinfinto the infat line 8 and also saves the new-mf; by method AddMf;/nf at line 9. It returns the mfi of the node at line IO.

I * * * Recursively find mfi.

* @param base The tidSet for Current head.

* @param tail The possible extension of the head.

* Bparam ginf The global information.

@return The local maximal frequent itemsets.

* I  private Vector infMfi(int[l base. Shorts tails, Vector ginfl  1 short[] pep = voata.calSuglbase.tails); 2 TInf inf = new TInfrainf. oeo. tails]: - 3 while((itm=inf.selectill~=Ol 4 int[l newbase = vOata.getBaSeiba5e.itml: 5 Vector newginf=inf.DoItem(itml: 6 Shorts newtail=new Shorts(inf.tail1: 7 Vector newmfi=infMfiinewbase,newtail,newginfl; 8 inf .AddInfa(newginfl : 9 inf .AddMfiInf (newmfil : 10 return inf.mfi;  Figure 10: The infMfi method  For the node at the level 0, the local new-mf; is actually maximal frequent itemsets and can output directly into a file. Since its information for future searching is saved by the method inJAddMfilnf in line 9, there is no need to keep the new-mfi and the memory of new-mfi can he released.

5. Experimental Results  10 1 0.1 0.01 Mnirmrn Support (%)  Figure 11: Running time on Mushroom.

We compare SmartMiner with Mafia and GenMax. All of them are implemented in Java JDK1.3. For fair comparison, the three methods use the same vertical data model VData. As we discussed before, there are many ways to implement the vertical data model. In this paper, our purpose is to study the efficiency of different search strategies. We choose VData because it takes less memory and is easy to implement. The experiment was done on a  lGhr Celeron with 512 MB of memory. A detailed comparison of SmartMiner with Mafia and GenMax was conducted on two datasets: Connect-4 and Mushroom.

Figure 11 shows the performance comparison of the three methods on Mushroom. All three methods use the PEP pruning technique. Our running time does not include the input time but does include the output time. The horizontal axis shows minimum support in percentage.

The vertical axis is the running time in seconds. In general, SmartMiner is one order of magnitude faster than both Mafia and Genmax. When minimal support is high, Mafia is faster than Genmax. Low minimal support increase the number of MFI, then Genmax performs better than Mafia   10 1 0.1 0.01 Mnirmrn Support (%)  Figure 12: Search tree size on Mushroom.

Figure 12 compares the sizes (number of nodes in a tree) of the search trees for the three methods. From the figure, we noticed that Genmax generates 10 times more nodes than SmartMiner and also much more than Mafia.

This indicates that the static ordering in GenMax is  not as efficient as the dynamic reordering used by both SmartMiner and Mafia. Moreover, we noticed that SmartMiner generates less nodes than Mafia, which is due to the heuristic select function used the SmarMiner.

10000 I 1  5 1000 .- - a 100  10 1 0.1 0.01 Minimum Support (%)  Figure 13: the # of counting on Mushroom.

Figure 13 compares the number of support counti.ng  which shows the number of times that the private method calSup(int[] base, short item) in VData is called. As shown in Figure 13, Genmax calls the calSup methods significantly more than both SmartMiner and Mafia.

Further, SmartMiner needs less number of support counting than Mafia.

Since GenMax introduces a fast superset checking algorithm, the performance gain of dynamic reordering of Mafia is mitigated by the increasing time for superset checking when the set of MFI becomes large. This is the reason we see in Figure 10 and Figure 13 that Mafia is better than Genmax when minimal support is high and the reverse when minimal support is low.

P I . . ... . .smrtMinx  95 90 80 70 60 50 40 30 20 10 Mnirmm Support (X)  Figure la: Running time on Connect.

Figure 14 shows the performance comparison of the  three methods for the Connect dataset. Again, we noticed the significant performance improvements of SmartMiner than Mafia and GenMax.

6. Conclusion In this paper, we propose the SmartMiner algorithm to  find exact maximal frequent itemsets for large datasets.

The SmartMiner algorithm is able to  take advantage of the information gathered from previous steps to  search for MFI. First, it gathers global and local tail information and uses an heuristic select function to  reduce the search tree.

Second, the passing oftail information eliminates the need of known MFllfor supersel checking. Smartminer does not require superset checking which can be very expensive.

Finally, SmartMiner also reduces the number of support counting for determining the frequency of tail items and thus greatly saves counting time. Our experiments reveal that the SmartMiner algorithm yields an order of magnitude improvement over Mafia and GenMax in generating the MFI on the two datasets.

Acknowledgements The authors wish to thank Professor Mohammed J.

Zaki for stimulating discussion in the performance study.

