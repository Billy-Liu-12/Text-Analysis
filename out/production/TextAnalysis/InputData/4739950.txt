Conjunction Graph-based Frequent-sets Fast Discovering Algorithm

Abstract  Existing algorithms that mine graph datasets to discover patterns corresponding to frequently occurring sub-graphs can operate efficiently on graphs that are sparse, contain a large number of relatively small connected components, have vertices with low and bounded degrees, and contain well-labeled vertices and edges. However, for graphs those do not share these characteristics, these algorithms become highly unintelligent. In this paper, we present a novel algorithm Conjunction Graph-based Frequent fast Discovering(CGFD) for mining complete frequent itemsets. This algorithm is referred to as the CGFD algorithm from hereon. In this algorithm, we employ the graph-based pruning to produce frequent patterns.

Experimental data show that the CGFD algorithm outperforms that algorithm TM.

1 Induction Association rules mining can discovery association  among itemsets in a great deal of data. Agrawal e.t. [1] firstly studied the problem to find association rules from client transaction data in 1993, and presented the conception of association rules mining, which was later formed into so-called Apriori algorithm[2].

Since then there were more and more investigation on association rules mining widely in the field of data mining. Park e.t. presented a data-processing model[3] based on direct hashing and pruning(DHP), which hashed the (k-1)-itemset into a hash table for creating k-candidate itemset; DIC(dynamic itemset cunting) algorithm[4] attempted to reduce the number of database scans by dividing the database into blocks and adding new candidate itemsets if all their subsets were already known to be frequent. Eclat[5] was the first algorithm to find frequent patterns by a depth-first search and it has been shown to perform well. Zaki and Gouda[6] developed a new approach called dEclat using the vertical database representation. This algorithm has been shown to gain significant performance improvements over Eclat.

FP-growth[7] is a well-known algorithm that uses the FP-tree data structure to achieve condensed representation  of database transactions and employs a divide-and conquer approach to decompose the mining problem into a set of smaller problems.

Song e.t. presented TM(transaction mapping) algorithm[8] using vertical database layout and achieving significant improvements over existing algorithms(including FP-growth and dEclat) by transaction mapping. It?s an excellent algorithm for finding frequent itemset at present. However there are two reasons affecting the runtime: for the first one TM algorithm is a simi-Apriori one using recursion technique; for the second one it used continuous transaction intervals representing the transaction ids, which increases the main memory spending and the I/O time. However the novel notation of correlative graph-based data mining theory and technique[9,10,11] have been studied up today and received excellent effect.

In this paper we have presented the notation of conjunction graph-based database mapping and used the structure characteristic of graph as the guide of pruning when finding frequent patterns. And then put forward the CGFD(conjunction graph-based frequent-set fast discovering)algorithm, which making use of heuristic searching to reduce data resident in main memory technique to improve the runtime.

The rest of this paper is organized as follows. Section 2 introduces the conception of conjunction graph and the principle of algorithm CGFD. Section 3 provides a detailed describing of the CGFD algorithm and analysis its astringency. Section 4 shows a detailed experimental evaluation of CGFD on datasets from different domains and compares it against existing algorithms TM. Finally, Section 5 provides concluding remarks and the works in the future.

2.The background notation and the principle of CGFD  In this section, we will give out the notation needing later, including the conception of conjunction graph, and describe the principle of the CGFD algorithm.

Second International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2008.117   Second International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2008.117   Second International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2008.117     2.1 The conception of conjunction graph We define the conjunction graph of transaction data  D: G={V, E}, where V=  being vertexes of G, T being the set of transaction ids, I being the set of itemset of each transaction,  IT ?  ??IT ? ; E={(t,i): t?T, i? I } being the edges set of G. The potential of a set S means the number of items in set S, denoted |S|.

From the graph theory, we know that here the conjunction graph is a bipart graph[12], which can perspicuously describe a transaction data set, for example, its vertexes denoting the transactions and items, its edges denoting the association between transaction and item.

To illuminate the application of conjunction graph, we use an assumptive transaction data set D, for example, seeing the table2-1:  Here we let vertexes set T= , I=  and edges set E={(1,a),(1,b),(1,c), (1,e), , (8,f)} according to table 2-1, then getting the conjunction graph such as fig 2-1.

}8,,2,1{ ? },,,{ oba ?  Table 2-1 transaction data TID Items 1 a,b,c,d,e,f 2 b,c,f, 3 a,g,h 4 a,c,i.j 5 a,b,c,k,d 6 b,d,l,j 7 a,m,n 8 b,d,o,f  1 2 3 4 5 6 7 8  a b c d e f g h i j k l m n o  1,3,4,5,7  Transaction set   1,2,5,6,8 1,5,6,8 1,2,8 3 4,6 6 7  3 4  5 7 81,2,4,5  Items  Figure 2-1 conjunction graph  In the conjunction graph, we define control set item i, denoted O(i), including all transactions containing item i, for instance, ={1,3,4,5,7} in fig 2-1. )(aO  2.2 The principle of the CGFD algorithm  Now we discuss the principle of the CGFD algorithm using the conjunction graph in section 2.1. The first problem is to adopt heuristic technique when producing candidate set and the other one is that when creating frequent set.

Supposed the support of the transaction set D is 0.25, when producing 2-candidate set we can select the item vertex whose in-degree is no less than 2, for example, the in-degree of each vertex in is 1, so these vertexes can not be selected and we can get the 2-candidate set . Noting that the in-degree of vertex  f and j is just 2, so the 3-canditate set is , , and so on.

},,,,,,,,{ onmlkihge  },,,,,{ jfdcba  },,,{ dcba  When we create k-frequent set from k-candidate set, we have to check the if inequation  is true, false then stopping, true then computing the intersection of all control sets of items in k-candidate set, if whose potential being no less than the support, then getting one k-frequent set, or else getting no one.

mk ?  However there will be  combinatorial cases judgments to find all frequent set using the method discussed above, when m and k are big numbers the computing complexity is also great. So here we import heuristic search mechanism: observing that the item in (k-1)-candidate set who?s appearing times smaller than (k-1) will not appear in k-frequent set, so we can check this property in the first and delete these itemset, thereby reducing the search space. For example, when finding 3-frequent set from 3-candidate set , we can observe 2-frequent set {{a,b},{a,c},{b,c},{b,d}, {b,f}}, noticing that items d and f only appear one time (smaller than 2), so they are out of the question to appear in the 3-frequent set and can be delete directly from 3-candidate  k mC  },,,{ dcba     set. Then we can get the new 3-candidate set , only to check the potential of , getting that = , so find one 3-frequent set . And so, noticing the potential of 4-candidate set  is 3, therefore there are no 4-frequent set, the whole discovering progress stopping.

},,{ cba )()()( cObOaO ??  )()()( cObOaO ?? }5,1{ },,{ cba  },,{ cba  3.CGFD (conjunction graph-based frequent set discovering)algorithm  After describing the principle of algorithm CGFD, We can conclude that the main technique is to use conjunction graph-based data representation and adopt heuristic searching technique to reduce searching space and increase run efficiency. The main process of CGFD algorithm is listed as follows: Input: Database, D, of transactions, minimum support threshold, min_sup.

Output: L= Fk, Fk is a frequent itemsets in D with k elements.

Step one: first scanning the meta data D, creating the conjunction graph G(V,E) of D, V= , the control sets {O(ii)| ii I},{O(ti)| ti T};  IT ?  Step two: getting the candidate itemsets Ck for(k=1;k<max(|O(ti)|)+1;k++) if(|O(ti)|>=k) add ti to Ck.//getting the k-candidates.

return Ck.

Step three: getting the frequent itemsets L for(i=1;i<k+1;i++) while(i!>| Ck |) { Ck= Ck ? CheckFrequent(Fk-1) ; if(CheckJoin(Ck)>= min_sup) add Ck into Fk; } L= Fk; return L; Method CheckJoin(Ck): for all  in Ck kic return ;|| kiCc ckki ?? Method CheckFrequent(Fk): for all x, counting time(x); if(time(x)<k) add x into P; return(P);  This algorithm completes discovering all frequent set from transactions data in three steps:  Step one: standardization of the data, i.e. mapping the original transaction data into conjunction graph-based data representation(for instance, seeing fig 2-1), and storaging them as a 2-dimensional array-based binary file, where the raw-order denoting all items arranged  digressively according to their potential in the conjunction graph;  Step two: checking the potential of all items and getting  the k-candidate set firstly, the sufficient condition is that the potential is no less than k;  kC  Step three:  discovering frequent sets , at the first computing the appearing number of each item in the frequent set , and deleting those items whose number is smaller than (k-1), then getting new k-candidate set, later creating  from it and so on.

kF  1?kF  kF CGFD algorithm maps transaction data into  conjunction graph and resident in the main memory, so saving the I/O run time. When the data are too much we partition them properly and run the program group by group[4]. In addition, when the data are present the search space is fixed, so much the workload to discovery the frequent sets. Hence the CGFD algorithm is convergent and valid to process those problems debated above.

4.Experiments  In this paper our experiment environment is in the personal computer of Intel(R) Pentium(R) 4, 1843 MHz-CPU DDR512MB-memory Win-XP system and all program are compiled by C++. We make use of two synthesize data sets(T10I4D100k and T25I10D10k), which taking on feeblish correlation. Also we use a public data set(Connect-4: http://miles.cnuce.cnr.it/~palmeri/ datam/DCI/datasets.php) with strong correlation. these data specification is showing in The table 4-1.

Table 4-1 experiment data data attributes Average  length Transaction number  T10I4D100k 1000 15 100,000 T25I10D10k 1000 25 9719 Connect-4 130 43 67557  Here we run our algorithm CGFD compared with TM[8] and get the experiment result, putting out the reports as following:  Table 4-2 run time(s) for T10I4D100k data     From table 4-2 we can include that for the data T10I4D100k and vary support from 0.01% to 5%, the algorithm CGFD run faster than TM increasing about 15% 40%. It is set out syllabify in fig 4-1.

Figure 4-1Run time for T10I4D100k data  Table 4-3Run time (s) for T25I10D10k data  From table 4-3 we can include that for the data T25I10D10k and vary support from 0.1% to 5%, the algorithm CGFD run faster than TM increasing about 40% 54%. It is set out syllabify in fig 4-2.

Figure 4-2Run time for T25I10D10k data  From table 4-4 we can include that for the data Connet-4 and vary support from 40% to 90%, the algorithm CGFD run faster than TM increasing about 7% 30%. It is set out syllabify in fig 4-3.

Table 4-4Run time (s) for Connect-4 data  Figure 4-3Run time for Connect-4 data  Above all, in despite of feeblish correlation of the data and of strong one, algorithm CGFD is excelled compared with TM, especially the runtime enhancing by 7%~54%, and in spite of strong or feeblish association, and nor long or short itemset data, algorithm CGFD can manage.

5.Conclusions  In our article we discussed the new algorithm of conjunction graph-based frequent set discovering(CGFD) for discovering frequent set from transaction data. And we also applied it into the real transactional data. This method can be applied in many fields, especially in the correlation mining. But there are much more technique needs to study in the future and we now are addressing this work. These are several tasks to be treated with: ? The optimized work of data pretreatment; ? Discussing of the presentation of the relationship  among the relative items; ? The deep studying the complexity of the whole  algorithm.

Acknowledgements  This paper is supported by the University Science &Technology Program of 211 Engineering, P. R. China (No:843300) and the Science & Technology Program of Guangdong Province, P. R. China No: 2006B10101033.

