Knowledge Discovery of Improved Apriori-Based  High-Rise Structure Intelligent Form Selection

Abstract  First, evaluation indexes of association rule are provided; meaning of them is analyzed; the Apriori arithmetic about knowledge discovery is introduced and its defects are analyzed. Next, a knowledge discovery method of improved Apriori-based high-rise intelligent form selection is established. Finally, examples of this method are presented.

This method provides a new approach to mining knowledge information in engineering cases, guiding structural form selection design and to improving quality, efficiency and intelligence level of structural design.

1.  Introduction   With growing investment in high-rise buildings as well as gain in their height, scale and optional forms, increase ensuingly not only knowledge and information resources needed but also complexity in structural form selection, so do difficulty and risk. Form selection is highly intelligent, experience-oriented and subjective. intelligent form selection (IFS) is an important direction in structural form selection design and knowledge acquirement is the ?bottleneck? of it.

At present, numberless high-rise buildings have been constructed and such building is still going on and on the increase. Every engineering case contains information such as knowledge, strategy and experience utilized by men in optimization of structural form selection. This sea of information undoubtedly plays an important role of reference and guidance in IFS design. Therefore, to study so as to establish a method capable of acquiring useful knowledge information from the existing high-rise structure cases will be of theoretical significance and practical value in tapping engineering case resources and in solving the ?bottleneck? problem of knowledge acquirement in IFS. In recent years, we?ve set up the decision-tree-based knowledge discovery method and the GA-based one [1-4].  The former has high precision requirements for data, incapable of excluding the attributes with smaller support while the latter can describe only the general tendency, instead of a direct result, of a large number of engineering cases.  In this paper we will present, in combination of structural form selection characteristics, a knowledge discovery method of IFS on the basis of improved Apriori. It has been proved that this method can freely control  and choose quality as well as quantity of both antecedent and consequent of a mining rule by setting a support value and a confidence value.

2. Association Type of Apriori about Knowledge Discovery 2.1.  Definition of Association Rules   Association rule is the rule that denotes associational relationships between a group of objects in a database. Let I={i1,i2,?,im} be an itemset and D a transaction database.

Every transaction T is an item subset (T ? I) with a sole identifier. Association rule is a formula like X? Y, where X ? T?Y ? T?and X?Y=?. X is called antecedent and Y consequent, which means ?If X is satisfied, so is Y.? The rule satisfying both min sup and minimum confidence at the same time is called strong rule. An itemset containing k items is called k-itemset, indicating that the length of this itemset is k.

If the itemset meets the requirement of minimum support, it is called frequent itemset, whose set is usually noted as Lk   2.2. Evaluation Indexes and Meaning of Association Rule   The indexes to evaluate an association rule are: support,  confidence, expected and lift.

Confidence is a measurement of accuracy degree of an  association rule while support is a measurement of importance of an association rule. The bigger the support is, the bigger is the quantity of data on which the association rule depends, the less likely that this kind of data appear by chance, the more likely that the relational information provided by the association rule represents some rule and thus is more valuable. Some association rules have high confidence, but their supports are very low. This indicates these rules support less data. The reason for it is either the collected data is not enough or this kind of data may belong to a different type in the system and should be utilized according to different circumstances.

Expected describes the support of Y in itself without X?s function.  Lift depicts how much the influence of X is on Y.

0-7695-2528-8/06 $20.00  ? 2006    The bigger it is, the more Y is influenced by X. Generally speaking, the lift of a useful association rule should be greater than 1. Only when the confidence of an association rule is greater than the expected, can it prove that X plays a helpful or promotive role to Y. It also proves that there is some relativity between them. If lift is not greater than 1, this association rule does not have any meaning.

2.3.    Apriori about Association Rule Mining   Mining of the association rule broken up into two questions:  (1) Find all the frequent itemsets in D. (2) Use them to create a strong rule. Apriori is the most basic method to search and generate frequent itemsets[5], almost the core of all frequent- itemset-discovering arithmetics. [6?7] Apriori is an arithmetic of width priority. It accomplishes mining all the frequent itemsets by repeating the searching work in order. This method is : to generate (k+1)-itemset with k-itemset, namely through the first scanning of D, calculate the support of each single item in every record I in D to generate frequent 1- itemset which is to be noted as L1; then in the k time of scanning, to generate the set of all new itemset candidates using the set Lk-1 of all frequent itemsets discovered in the preceding scanning and to note it as Ck; to scan Database D and calculate support of these itemset candidates; finally, keep all the itemsets with supports greater than minimum support to form the set of frequent itemsets with length of k and is noted as Lk; to repeat the above process until there is no new frequent itemset to be found.

2.4.    Examples of Apriori   Apriori is made up of two steps: to generate Ck, set of  itemset candidates and to take count of them. The process of the first step can still be subdivided into two steps: join step: join Lk-1 to Lk-1; prune step: delete unnecessary itemsets. For instance, L3={{I1, I2, I3}, {I1,I2,I4}, {I1,I3,I4}, {I1,I3,I5}, {I2,I3,I4}}, through joining, we get C4={{I1,I2,I3,I4}, {I1, I3, I4, I5}}. Because {I1,I4,I5} is not included in L3,  {I1,I3,I4,I5} should be pruned from the set of itemset candidates C4.  Now taking the database in Table 1 for example, we shall explain the working process of the Apriori.

From Table 1 we know: First, initialize C1 as the set of all items, take count of elements in it and put in L1  elements satisfying the minimum support. Next, generate C2 using L1 and then take count of set C2 to get L2. When we get L3, C4is empty and this arithmetic comes to an end ?min_support=2?.

Table 1.  Database D   Tid Items 100 ACD 200 ACE 300 ABCE 400 BE   2.5.    Generation of Association Rule   The second sub-question of association rule mining is to  generate the association rule using the frequent itemsets found in D. To every frequent itemset A, we get all non-empty subsets B(B ? A ? B ?? ), and if confidence(B ? (A- B))?min_conf, we get association rule?B ? (A-B)?, where confidence can be ascertained with Formula 1; support_count(B ? A-B) is the number of transactions containing Itemset B ? A-B and support_count(B) is the number of transactions containing Itemset X.

)B(portsup ))BA(B(count_portsup))BA(B(confidence ?=?? ?    (1)   ItemsetCount  {A} 3  {B} 2  {C} 3  {D} 1  {E} 3   Itemset Count  {AB} 1 {AC} 3  {AE} 2  {BC} 1  {BE} 2  {CE} 2   Itemset Count  {ACE} 2   Fig. 1. Process of getting set of itemset candidates and  frequent itemsets with Apriori.

3.  Improvement of Apriori 3.1.    Defects of Traditional Apriori   To ascertain frequent itemset Lk, traditional Apriori needs to  join Lk-1to itself to generate all the new k-itemset candidates Ck , the superset of Lk.  By scanning database and calculating the support of every itemset candidate in Ck, we can simply ascertain Lk. However, when we use this method to do the data mining work of some attribute values of high-rise structure cases, we will encounter the problem of unnecessary increase in joining items, which makes both the number of itemsets in Ck and Lk and calculation work increase, influencing efficiency and quality of the Apriori. Obviously, traditional Apriori arithmetic is not able to solve the KD problem of high-rising structure form selection efficiently. Therefore, according to attributes characteristics of engineering cases and the requirement of structural form selection as well we will make some necessary amendments of it as follows.

3.2.    Improvement of Apriori    L1  C2 L2  C3 L3  Itemset Count  {AC} 3  {AE} 2  {BE} 2  {CE} 2  Itemset Count  {ACE} 2  Itemset Count  {A} 3  {B} 2  {C} 3  {E} 3  C1  0-7695-2528-8/06 $20.00  ? 2006    In the process of knowledge discovery of IFS, people usually hope to know the hidden intrinsic association between structure forms and such continuous, discrete or enumerating type of attributes as height, number of floors and site class, etc.. Here, if we use a single concrete attribute like height or number of floors to do the above-mentioned rule mining work, it is obviously neither necessary nor practical. To this, people usually solve this problem by subdividing the above- mentioned attributes into some sub-attributes having some intervals. But these sub-attributes are usually mutually exclusive. If we do the joining work with traditional Apriori, we need to use both the sub-attributes and the other attributes all as 1-itemset candidates, C1.  On this basis of it, we ascertain L1, through carrying out self-joining of Lk-1 and Lk-1 , ascertain Ck and consequently ascertain Lk. Obviously, when we use this method to do the joining work, calculation work of the subsequent calculating process increases due to reckoning without the mutual exclusiveness of all the decomposed attributes, which results in low efficiency. Therefore, considering the semantic mutually exclusive relationship between the data whose attributes is decomposed and transformed,  and using conditionally selective joining strategy, Lk-1 does self-joining at the generation time of itemset candidate Ck. Through filtration of this restrictive condition, the number of itemsets likely to generate is greatly reduced, and so is the number of frequent itemsets, speeding up the work of this arithmetic. For instance, to Set L1 containing six frequent 1-itemsets {A1}?{A2}?{A3}?{B1}?{B2} and {B3}, where Ai and Bj(i,j=1,2,3) are 3 sub-items transformed from the original A and B, if we use traditional Apriori to do self-joining of L1, we will get as many as 5? 4? 3? 2? 1=120 itemset candidates while with the improved Apriori we will just get 3 ? 3=9 itemset candidates at most. Therefore, the improved arithmetic has apparent advantage. Obversely, comparing with the traditional Apriori arithmetic, the improved  arithmetic has more superiority with less calculation, fast speed and high efficiency in processing the KD problem of high-rising structure form selection.

The pseudocode to generate C2, set of 2-itemset candidates of the improved Apriori, is given as follows:  L1=find_frequent_1-itemsets(D);//  L1 is the set of frequent 1-itemset  for each item l1?  L1  //  Decompose Set l1, we get Item I1.

for each item l2?  L1   // Decompose Set l2, we get Item I2.

if (LEFTSTR(I1) ? LEFTSTR(I2)) then { c= l1?l2; //join step: generate candidates add c to C2; }  return C2, where Function LEFTSTR(Ii) returns to the sub- cluster on the left of character ?_?in Item Ii.

4. Rule Mining of Form Selection Based on Improved Apriori 4.1. Attribute Characteristics of High-Rise Structures and Steps of Association Rule Mining   We can solve the problem of quantitative association rule  based on quantitative and discrete attributes by contrasting it  to the Boolean association rule problem. In the high-rise structural case library, engineering experts suggest mining data of attributes such as height of the main building, overground floor, length-to-width ratio, height-to-width ratio, the maximum wind pressure, performance, fortification intensity, site class, main structure form and so on. Due to complexity of projects, these attributes vary in value type and have big value range, so it is necessary to divide them first and then parallel them to the Boolean attributes. Mining association rule can be solved in three steps: Step 1, to ascertain the interval division of value domain of every quantitative attribute. Step 2, to mine all the frequent itemsets.

Step 3, to form association rule from the frequent itemsets we got.

4.2.  Attribute Classification of the Target Case Library and Interval Division of Value Domain   The second and third steps in the above arithmetic are  basically consistent with Boolean association-rule-mining arithmetic. Next, we introduce the first step alone.  In light of the characteristics of the attributes, we divide them into three groups. Group 1: height of the main building, overground floor, length-to-width ratio, height-to-width ratio, the maximum wind pressure. Group 2: main structure form and performance. Group 3: fortification intensity and site class.

The values of each attribute in the first group are concrete data, which are divided in equidistance after they have been discussed and proved by experts. Meanwhile, the system provides their default values: height of the main building-10 (m), overground floor-3, length-to-width ratio: 0.05, height-to- width ratio: 0.05, the maximum wind pressure-500?N/m2?.

Table 4 is the interval division of some attributes when they are transformed into Boolean attributes. Attributes in Group 2 are main structure form and performance. Considering the fact that the values of these two types of attributes share some synonyms and parasynonyms, we adopt standardized method about value domain and get typical values of the thesaurus of main structure form and performance as follows: frame, shearing, tube, frame+shearing, frame+tube, tube in tube, complex; office premises, residence, hotel and complex. With the typical values we can do the Boolean attribute transformation work. Values of each attribute in Group 3 are simpler, which can be transformed into Boolean attributes directly. Table 2 presents the interval division and classification when some attributes are transformed into the Boolean ones.

Table 2.  Interval division of overground floor    overground floor  8-11  over- ground  floor 11-  overground floor 14-17  overground floor 17-20  overground floor 20-23  overground floor 23-26  overground floor 26-29  ??  ? ? ? ? ? ? ? ??   4.3.    Establishment of Simplified Database  0-7695-2528-8/06 $20.00  ? 2006     In the high-rise structural case library, customers or  residents are more concerned about association between main structure forms and other attributes and its degree. This demands we mine only limited data instead of all. Therefore, we, on the basis of original case library, choose part of the fields to build the simplified Database D for data mining.

Attributes in it are shown in Table 3. On the basis of it, mining of quantitative association rule will be done.

4.4.    Booleanization of Database Attributes   The attributes in Table 3 can be transformed into Boolean  ones according to the ascertained attribute class and value domain interval. The transformation is shown as in Table 4,  From which we can see that all the quantitative attributes are decomposed into Boolean ones and the original one corresponds to several attributes. Now that all the attributes have become the Boolean type, the problem of mining quantitative rule is changed into mining Boolean association rule. To run in the database as shown in Table 4 the arithmetic of mining Boolean association rule comes out accomplishing mining of all the association rules   4.5.    Examples of Quantitative Association Rule  Some useful rule knowledge about the generation of  structural forms can be obtained from the evaluation of strong rules discovered by the experts in this field. The following is part of the strong rules and explanation about them we acquired.(1) Performance_residence=>main structure form- shearing: support 7.6% ,confidence 50.3%, expected 10.5%  Experts? explanation: The percentage that projects whose performance is residence and main structure form is shearing take up in all projects is 7.6%; among all the projects whose performance is residence, 50.3% of them have shearing as their main structure form; projects whose main structure form is shearing constitute 10.5% of all the projects.

(2) Floor_18~24, function_residence, fortification intensity_7=> main structure form_shearing: support 4.8%, confidence 80.0%, expected 10.5%, lift 7.6.

(3) Main building height_40.0~60.0, floor_12~18, function_residence, fortification intensity_7=> main structure form-shearing: support 3.7%  confidence 56.1% expected 10.5%, lift 5.3.

It is clear that the above-mentioned rule about generating structure form is of great reference value for guiding form selection design.

Table 3. Simplified database D    number main structure form height of the main  building (m) number of floors  length-to-width ratio  height-to-width ratio  maximum wind pressure (N/m2)  performance fortification  intensity site class  1 frame support shearing 66.74 23 1.00 2.50 981 office 7 ?  2 4?24 shearing -3?3 frame+shearing  93.51 29 1.31 1.46 1200 office 8 ?  3 tube in tube 100.60 24 1.93 2.66 1500 residence 9 ?  4 frame +shearing 101.00 30 2.02 3.77 1600 office 7 ?  ? ? ? ? ? ? ? ? ? ?   Table 4.   Booleanized database D    No.

structure form frame  shearing ?  height 70? 80m  ? floor 20?     length-to-width ratio 1.5?2 ?  height-to-width ratio 1.5?2 ?  maximum wind pressure (N/m2)  1000?1500N/m2 ? perfor-mance  office ? fortification  intensity 8 ?site class??  1 T ? F ? T ? F ? F ? F ? F ? F ? T ? 2 F ? F ? T ? F ? F ? F ? T ? T ? T ? 3 F ? F ? T ? T ? F ? T ? F ? F ? F ?  4 T ? F ? T ? F ? F ? F ? T ? F ? F ?  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?    5.    Conclusion This paper presents definition and evaluation indexes of  association rule and analyzes the meaning of the indexes.

Next, in combination of characteristics of high-rise structural form selection, this paper analyzes the weaknesses of Aprior and makes improvement of it, on the basis of which, a  knowledge discovery method of high-rise IFS is established.

Finally, it provides several examples of the method. They show: ?It can effectively acquire the desired structural form selection knowledge from engineering cases. ? It can make full use of information in the existing cases. ?It can solve the ?bottleneck? problem of knowledge acquirement about intelligent form optimization of high-rise structures all right. It  0-7695-2528-8/06 $20.00  ? 2006    provides a new approach to improving quality, efficiency and intelligence level in structure design.

