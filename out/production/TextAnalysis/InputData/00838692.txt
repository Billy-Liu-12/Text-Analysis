Uncertainty

Abstract-The KDD Drocess aims  handling in the data mining process  Michalis Vazirgiannis, Maria Halkidi  Athens University of Economics & Business Patision 76, 10434, Athens, Greece (Hellas)  Department of Informatics  at searchine for interesting instances of patterm- in data sets. It is widely accepted that the patterns must be comprehensible. One of the aspects that are under-addressed in the KDD process is the handling of uncertainty in the process of clustering, classification and association rules extraction. In this paper we present a classification framework for relational databases so as to support uncertainty in terms of natural language queries and assessments. More specifically, we present a classification scheme of non-categorical attributes into lexically defined categories based on fuzzy logic and provides decision support facilities based on related information measures.



I. INTRODUCTION  The purpose of Data Mining is the extraction of knowledge from large data repositories. The knowledge may have various forms such as, classifications, association rules, decision trees etc.

In the vast majority of KDD systems and approaches the data values are classified to one of a set of categories that have resulted from a clustering process. Then, we have two issues that may result in knowledge to be partially extracted or not to be extracted at all during the KDD process. We address the following facts and their implications:  the clusters are not overlapping. This means that each database value may be classified into at most one cluster, in some cases it falls out of the cluster limits so it is not classified at all. Though, everyday life experience leads us to the fact that actually a value may be classified into more than one categories. For instance a male person 182cm high in Central Europe is considered as of ?medium? height as well as ?tall? to some degree.

the data values are treated equally in the classification process. In traditional data mining systems database values are classified in the available categories in a crisp manner, i.e. a value either belongs to a category or not. The person of the above example is considered as tall and also another person 199cm high is also considered tall. It is profound that the second person satisfies to a higher degree, than the first, the criterion ?tall?. This piece of knowledge (the difference of belief that A is tall and also B is tall) cannot be acquired using the schemes.

As it is clear from the above brief analysis there is interesting knowledge that is not captured due to the fact that uncertainty is not considered in the KDD process.

The KDD process mainly aims at searching for interesting instances of patterns in data sets. It is widely accepted that the patterns (e.g. classifications, rules etc) must be comprehensible i.e. they should be understood by the analysts [8][5]. Assume the transaction log of a computer sales store, and that a subset of its scheme is: R = (client-salary, client-age, price}. Applying the techniques proposed in [ 121, we would have to come up with rules of the form: cIient-salafy[8000,1 lOOO] and client-age[25-40] ;;rprice[l300,2000]  with fuzzy logic  Apparently the rule introduced above is not clearly comprehensible, since it does not place the rule in the greater context of the involved attributes (i.e. what does that range client_salury[3000,4500] mean in the full range of salaries as well as in their population distribution features?). A managedanalyst, as non-domain expert, would not understand the meaning of such a rule since the underlying data semantics are not made clear in the rule context. Thus, a requirement for understandable patterns of knowledge as results of the data mining process arises. This will be achieved by classifying the data into understandable categories represented by natural language values.

Another issue is the ?crispness? of the value domains imposed by this approach. For instance, (see Table I), the tuple with tid=ll is excluded from the supporting set although all its values support quite well the rule apart from the value of the attribute ?price? which is only 0.00615% out of the required range. The result is that many ?interesting? tuples (i.e. contributing to the semantics hidden behind such a rule), are rejected due to the crisp limits that have been set. It is evident that the problem here is that the classification of the values in these domains is flat, i.e. all the values in the domain are treated equally as for the criterion of partitioning (i.e. the price). The partition in domains reflects the classification of the attribute values in categories (i.e. ?.?very cheap?, ?cheap?, ?moderate?, ?expensive?). These natural language expressions should be mapped to the underlying database through a layer that maps the natural language terms to the underlying database schema and values.

TABLE 1 THE SALES TRANSACTION LOG TABLE  I I I  10 14447 1?9 1136 11 19765 136 11292  I I I  12 16822 137 11136 13 18763 179 I1444 I  I I I  14 11643 I66 18 15 15387 173 1283  18 6963 69 983 19 2323 80 742  0-7803-5877-5/00/$10.00 0 2000 IEEE     Another requirement addressed is the usage and reveal of uncertainty in this context is an important issue [6]. Another issue addressed in the bibliography is the relatively few efforts that have been devoted to classical data analysis techniques like clustering & classification in the area of data mining research [2].

In this paper we propose a methodology that represents uncertainty in the classification stages in KDD environment for large relational databases so as to support uncertainty in terms of belief measures. More specifically, we present:  A scheme that classifies non-categorical attribute values into categories maintaining the classification belief. We use fuzzy logic in order to represent and manipulate this belief.

Information measures for the evaluation of the above defined classification scheme based on fuzzy logic concepts. We can exploit classification belief based on these measures in order to support decision-making related to one or multiple data sets.

The paper is organized as follows. In section two we present the classification scheme while in section three we propose information measures based on fuzzy logic in order to evaluate and exploit the information included in proposed scheme. In section four we elaborate on the multi- dimensional extension of this scheme, while in section five we present reasoning based on proposed information measures. We conclude in section six by summarizing and providing further work directions.

11. CLASSIFICATION SCHEME  The term classification implies the procedure according to which each of a set of values is decided to belong into one of a set of related categories. As it is well known, in order to classify a data set there has to be a set of clusters as a result of a preceding clustering process. In this research effort we assume that there is a given set of clusters for each attribute.

As we mentioned in previous sections each value that belongs to a cluster (category) should not be treated equally but contribute according to its classification belief. Thus we also assume a set of mapping functions assigned to the clusters as a result of an enhanced clustering process. Then each database value is mapped to a category bearing a d.0.b.

(degree of belief) for this classification as a result of using the corresponding mapping function.

The classification scheme is applied on a data set S under a certain relational schema R = {Ai] where Ai is an attribute.

The values of the non-categorical attributes (Ai) are classified into categories according to a set of categories L={ li] (where ii a category, for instance: ?tall?, ?short? etc.) and a set of classification functions based on fuzzy logic methodologies.

The result of this procedure is a set of degrees of belief (d.0.b.s) M ={pl,(tk.Ai)}. Each member of this set represents the confidence that the specific value tk.Ai (where tk is the tuple identifier) belongs to the set denoted by the category li.

A. Classification space (CS) The term Classification Space (CS) implies the specifications for mapping data base values to the fuzzy domain. Each value of the database is classified in one of the above mentioned categories (clusters) with an attached d.0.b. We assume the attribute ?client-salary? from our running example, which in a data set ranges between the values 1500 and 10000. In real world people characterize the value of a salary as high, low, moderate. How would one classify a specific salary value  Min Max Function  1 8 2 2 2 6 3 0 3 4 3 8 4 2 4 6 & 5 4 5 8 6 2 6 6 7 0 7 4 7 8  18 30 50 I 40 60 80 decr triangle increasing  Fig. 1 .The transformation functions for the attribute ?client-age?  Min Max Function  into a category? What are the values? ranges corresponding to these categories? Are they overlapping?

As it  is clear, there is inherent uncertainty in the classification of a value in a set of categories. A fundamental issue is the acquisition of the related knowledge i.e. the categories, the corresponding value ranges, and the mapping functions between the real values and the fuzzy domain. Assuming the appropriate set of value domains for these categories, for each attribute Ai we define the corresponding classification set L A , ={ ct I ct is a classification tuple]. The classification tuples are of the form: (li,[vl, vz], fi) where 1, is a lexical category, [v,, vz] is the corresponding value interval and fi the assigned transformation function. The value domains may be overlapping. This increases the expressive power of the classification mechanism since some values may be classified to more categories than one with different d.0.b.s. Then the collection of all the classification tuples ct related to the relational schema R forms the Classification Space (CS), which defines the mapping of the data set to the fuzzy domain.

In Table I1 the CS appears based on the schema of our sales example (see Table I). For each attribute, a set of lexical categories, the corresponding domain limits and the related transformation functions are provided.

The transformation function selection is an important issue that can affect the results of classification. In our system we have currently adopted linear functions (decreasing, triangle and increasing) [7]. In Figure 1 the mapping of the age values to the fuzzy domain appears based on the CS specifications (see Table 11).

I I O  35 70 15 50 80 150 decr triangle triangle triangle  TABLE II THE CLASSIFICATION SPACE FOR THE SALES SCHEMA.

]client-salary I Min 1, Max 5500 10000 Function decr trian le Increasin  [price I very cheap Cheap moderate expensive     As it is depicted in the figure 1 the value domains may be overlapping, so that an age value may be classified into two categories. In a similar way the rest of the attributes are mapped to the fuzzy domain.

For each tuple t k in the data set S there is a value t k.Ai that corresponds to the attribute Ai. Then the d.0.b. that this value belongs to the sets denoted by the categories and the corresponding domains is:  where f is the transformation function that maps the value t,.Ai to the fuzzy domain. The choice of functions is a fundamental issue and will have a great impact on the creditability of the d.0.b.s. Thus, it is clear that for each value t k.A, a set of d.0.b.s {pli(S.tk.Ai)} is produced. Assume n, is the number of tuples in the relation and lAi is the number of categories corresponding to the attribute Ai, then the overall number of d.0.b.s produced is:  li (S.tk.L%)= f (tk.L%) (1)  x n r  *?Ai (2) Ai  B. Classification Value Space (CVS)  The result of the transformation of the data set values to the fuzzy domains using the CS is a 3D structure (see Figure 2) further called Classification Value Space (CVS). The front face of this structure stores the original data set (included in Table I) while each of the other cells C[Ai, lj, tk] , where j,k > 1 ,  stores the d.0.b. pli(S.tk.Ai). Further we reference a cell in the CVS as CVS(tk.Ai.lj).

The higher the d.0.b. is the higher is our confidence that the specific value belongs to the specific set. It is interesting to have an overall measure of classification information, which is included in the values of the attribute with regard to each category.

The algorithm for computing the d.0.b.s for the data set values with reference to the CS follows:  for each category Cj of Ai for each attribute Ai in CS  for  each value tk.Ai in the data set  end compute d.0. b.(Ai, Cj, tk.Ai)  end end  Thus the time complexity is O(d*c*n) where d is the number of attributes (data set dimension), c is the number of categories(c1usters) and n is the number of d.0.b. values for a category n (number of tuples in the data set). Usually c, d <<< n. Thus, the time complexity for computing the d.0.b.s for a data set will be O(n).

111. INFORMATION MEASURES IN THE CVS  Classification Categories  r!

1 Tuples Data Set S Fig. 2. The CVS holding the ?degrees of belief? (d.0.b.s) for  the classification of the attributes? values.

A. Category energy metric  Let Ai be an attribute and li a related category. Then the overall belief that the current data set S contains data that are successfully classified in the category li is given by the normalized information measure:  (3)  where n, is the number of tuples in the data set, hence the number of values of the attribute and q is a positive integer.

The usual value of q is 2. Higher values suppress lower d.0.b.

making thus the contribution of the tuples with high (close to 1) d.0.b.s more significant. The exponent l/q is used to amortize the effect of the exponent q.

W e  can further compare the information measures of different categories of the same attribute. So for a given data set S and a given attribute A with attached categories 11, 12,..,ln the corresponding information measures E li (S.A) are ordered making thus feasible to decide which category has better support by the data set and also to compare. For instance the query: ?Does the sales database contain mostly high of medium salaries?? is answered by comparing the values: Emdium (salary), E high (salary) as resulting from (3).

B. Attribute energy metric  The overall energy of an attribute Ai, is the normalized sum of the energy metric values for all the attribute categories.

This measure expresses the average overall information energy that is included in the values of the attribute (i.e. how strong is the belief for the classification assessment) and also the amount of information regarding the considered categories. Hence:  (4) where C is the number of categories for the attribute Ai.

Essentially EA,(S) is a measure of how successful is the classifications scheme.

E I i ( S . A i ) =  XLl, (S?tk?Ai )) /..r L  EA,  (s) = xli Eli /C  The CVS conveys significant knowledge included in cumulative information measures. One of the imoortant  c. cvs E~~~~~ & classification quality information measures that have been proposed in the bibliography is the Energy metric [7], which reflects the information auantitv that is included in a fuzzv set. This in the data set is given bv the equation:  The overall information that is included in the CVS and represents the amount of classification information included  ( 5 )  information quantit; essentially is a measure of?the overall Ecvs = C E A i  - belief for a fuzzy set. Ai  where Ai are the attributes. The result is the information content of the CVS. This measure is used to compare different data sets as for their information content. Data sets with higher Ecvs correspond to higher overall measure of     information. This energy shows how significant is the information contained in the values of this attribute and also how well the data set fits to the classification scheme. Also this measure is an indication of the quality of classification.

In principle an ideal classification scheme should maximize the Ecvs value. Indeed when Ecvs is maximized the uncertainty is minimized and thus the confidence for classification is high.



IV. MULTI-DIMENSIONAL CLASSIFICATIONS  Another need that arises is the representation of the d.0.b.

related to composite classifications of tuples. For instance we are interested to know to what degree a tuple in our sample data set satisfies more than one criteria e.g.: ?morning and cheap purchases?. The term ?morning and cheap? defines a new category and we need to provide a mapping function for this. In this case we can introduce two alternatives:  Classijication based on multi-dimensional clusters. In this case we define clusters (initial categories) for our data set taking into account all the attributes referred to our criteria. Then the clustering process produces multi- dimensional clusters and we can define the membership functions for them based on the procedure used in the case of one-dimensional data sets.

Classification based on one-dimensional clusters. We adopt the min measure for composition of fuzzy predicates from the bibliography [7]. Thus for two attributes At, A, and I,, lj two corresponding categories ( li referring to A, and lj to A& the d.0.b. that a tuple tk belongs to the set characterized by the predicate ?AJi and AJj? is given by the equation:  pllandl, (tk.At, tk.Ae) = min(pli (tk.At), plj (tk.fb)) (6)  The overall information measure related to the criterion ?A,.li and A,.l,? is given by the equation:  Liiandlj (t k ? A t  7 k 1) which represents the belief that tuple tk has both features  (belongs to both categories) li, Z j  and, therefore, it is classified accordingly. For instance, we may submit the query: ?What is the overall belief that the database contains transactions for cheap purchases made in the morning??.

A. An experimental study of multi-dimensional classification approaches The objective of this study is to compare two approaches described in section I11 for the definition of multi- dimensional classification. More specifically, we use a data set with data related to stock exchange transactions and we compute the overall energy produced by the adoption of the above-described alternatives. The size of our data set was 1000 tuples and its schema is : R = (closegrice, highgrice, volume}, where closegrice is the daily closing price of the stock, highgrice is the highest price of the stock during a session and volume is the number of transactions for the specific stock. In this point, we also have to mention that the energies of our data set classification scheme computed based on a system we have implemented according to the above described classification framework.

TABLE 111 ENERGY METRIC FOR A GIVEN NUMBER OF CLUSTERS  Close Price, Volume  TABLE IV ENERGY METRIC FOR THE OPTIMAL CLUSTERING SCHEME  Close Price, Volume  .,__.

!Ecl-vol p,284 I  The overall result of this study is that the first approach based on multi-dimensional clusters, produces better classification schemes. Multi-dimensional clustering extracts clusters that are the best partitioning for a data set as it examines simultaneously all the attributes (dimensions). Also categories that are not supported by the data set ignored and thus the classification scheme could be adjusted better to the data set. Assuming a two dimensional data set (closegrice, volume) of stock exchange database, we demonstrate the above with the following experiments:  1. Classification scheme based on a given number of clusters. In this case, the clustering procedure is applied for a given number of clusters so as to compare the results of the two approaches with respect to the definition of a data set partitioning that is as good as possible for the given number. More specifically, we apply clustering to each of the attributes (closegrice, volume) so as to define three clusters (categories) for each of them. Thus, we defined nine new dusters  for the category ?closegrice and ?volume? combining the extracted categories of each attribute. Then we apply two-dimensional clustering in order to define a partitioning of the data set into nine clusters. Table I11 presents the overall energy (as in (4)) as computed in each of the approaches. As it is obvious, the overall belief produced by two-dimensional clustering is higher. It is also noteworthy that, none of the nine categories produced by multi-dimensional clustering has zero (0) energy in contrast to the case of one-dimensional.

As a consequence, the approach based on multi-     TABLE v.

SAMPLE QUERIES AND THE RELATED INFORMATION MEASURES  salaries??  dimensional clustering searches for the best nine clusters that can be extracted by the data set and ignores the categories that are not supported.

2. Classification based on optimal clustering schemes. In this case, we apply clustering procedure giving a range in which the number of clusters can take values and we ask for the optimum clustering scheme. The selection of the clustering scheme is based on well-defined quality clustering criteria. Table IV shows the overall energy in each of the multi-dimensional classification approaches.

The result of comparing two approaches is that the overall belief produced by two - dimensional clustering is higher and as a consequence the classification scheme defined is better. The clustering procedure has defined the optimum partitioning of the data set taking into account both attributes and thus the outcome (clusters) are adjusted better to our data set than the clusters produced by the combination of clusters defined by separate attributes.

We carried out a similar study for three-dimensional data sets and we concluded into similar results to two-dimensional data i.e. that multi-dimensional clustering could result in better initial categories for the multi-dimensional classification  v. REASONING WITH INFORMATION MEASURES The result of the KDD procedure is a set of assessments about the underlying data. These assessments should be in an understandable form for the humans so that they will be useful and exploitable. The scheme presented above contributes to this requirement, since the results of the data set can be represented in the form of natural language statements. The information measures mentioned above are exploited to support queries and decision support of the following categories:  A. Single data set, single attribute queries  Here we have queries related to categories of an attribute in the same data set. In Table V there is a list of indicative queries and the way they are handled by the classifications scheme.

B. Multi-data set queries In this category we are concerned with queries that involve two or more data sets of the same relational schema and CS.

Assume two data sets including sales in two different supermarkets namely S1, S2. Then the queries appeared in Table VI can be processed using the information measures defined above.



VI. RELATED WORK  One of the three components~of a KDD system is the model whose functions among others include [ 5 ]  the classification procedure. ?Classification? aims at mapping an object to a predefined set of categories/classes, unlikely to the ?clustering? procedure where the extraction of the classes from a set of data is achieved by finding grouping of values and similarity metrics.

The classification problem has been studied extensively in statistics, pattern recognition and machine learning community as a possible solution to the knowledge acquisition or knowledge extraction problem [ 1 I].

TABLE VI QUERIES INVOLVING MULTIPLE DATA SETS  Query I Value returned ?Which of the SI ,  S2 1 If ( L m , d S  1 .time_ofb) > contains more transactions made early morning??  ?In which supermarket there are more cheap purchases made in the evening??  E,,,aning(Titime-oC-pjj? retum Lmmg(S1 .time-of-p))  else retum &,,.,(S2.time-of-p)  If (EdleapandeWing(S1 .price. S.time-of-p) > heap and evening(S2.pri~e, S.time-of-p))  else retum Edcapandevening(S 1 .price, S.time-of-p)  retum Ehrap andrvmlnu(S2.pri~e, S.time-of-p)  A number of classification techniques have been developed and are available in bibliography. Among these, the most popular are: Bayesian classijication [3], Neural Networks [ 11 and Decision Trees [ 141.

The above reference to some of the most widely known classical classification methods denotes the relatively few efforts that have been devoted to data analysis techniques (i.e.

classification) in order to handle uncertainty. These approaches produce a crisp classification decision, so an object either belongs to a class or not, which means that all objects are considered to belong to a class equally. Moreover, most of the classification proposals and algorithms consider the classes as non-overlapping [SI. It is obvious that there is no notion of uncertainty representation in the proposed methods, though usage and reveal of uncertainty is recognised as an important issue in research area of data mining [ 6 ] .  For this purpose, the interest of research community has been concentrated on this context and new classification approaches have recently been proposed in bibliography so as to handle uncertainty.

The issue of classification involves the definition of categories that group the values of an attribute A in sets that have a specific feature. A recent approach in classification for data mining is presented in [4].

Also, an important issue in data clustering and classification is the extraction of appropriate value intervals that correspond to logical categories related to an attribute. An interesting approach related to this issue is addressed in [9].

An approach for pattern classification based on fuzzy logic is represented in [lo]. The main idea is the extraction of fuzzy rules for identifying each class of data. The rule extraction methods are based on estimating clusters in the data and each cluster obtained corresponds to a fuzzy rule that relates a region in the input space to an output class. Thus, for each class ci the cluster centre is defined that provides the rule: If {input is near x,]  then class is e,. Then for a given input vector x, the system defines the degree of fulfilment of each rule and the consequent of the rule with highest degree of fulfilment is selected to be the output of the fuzzy system. As a consequence, the approach uses fuzzy logic to define the best class in which a data value can be classified but the final result is the classification of each data to one of the classes.

In [13], an approach based on fuzzy decision trees is presented and aims at uncertainty handing. It combines symbolic decision trees with fuzzy logic concepts so as to enhance decision trees with additional flexibility offered by fuzzy representation. More specifically, they propose a procedure to build a fuzzy decision tree based on classical decision tree algorithm (ID3) and adapting norms used in fuzzy logic to represent uncertainty [ 131. However, there is no evaluation of proposed inference procedures as regards the quality of new sample classification.

In general, there are some approaches proposed in bibliography, which aim at dealing with uncertainty representation (e.g. fuzzy decision trees). According to these approaches each data value can be assign to more than one categories with an attached degree of belief. However, they don?t propose ways to handle classification information and exploit it for decision-making. In this paper, we propose an approach that aims at uncertainty handling in the classification process based on fuzzy logic concepts. We propose a classification framework that maps data to fuzzy domains and maintains uncertainty in terms of degrees of belief.



VII. CONCLUSIONS  One of the objectives of a KDD process is to produce understandable knowledge in terms of patterns detected in a large data set. We feel there is a lot of potential in the area of mining patterns of knowledge, as regards classification of quantitative attributes. In this paper we presented: 0 A scheme for classification of database values putting  emphasis in uncertainty handling and classification quality measures. The classification scheme maintains the uncertainty through the maintenance of a framework based on fuzzy logic.

Information measures for the classification scheme based on the energy metric function, which reflect the information quantity that is included in a fuzzy set. Based on these measures, we can compare different data sets as to the degree they fit to the classification scheme or compare different data sets under a specific criterion. Also, we extract ?useful? knowledge for reasoning and decision making based on the information measures.

Moreover, we present how the proposed classification scheme can be used for multi-dimensional classification so as to support decision-making that combines more than one- classification criteria. For this purpose, we proposed two approaches: i) classification based on multi-dimensional clusters, ii) classijication based on one-dimensional clusters, while we described an experimental study we have carried out in order to evaluate these two approaches. The overall result of this study is that the approach based on multi- dimensional clusters, produces better classification schemes.

Further work will be concentrated in usage of the proposed framework in order to adjust an initial classification model according to the feedback we get by classifying different data sets. This adjustment will result in classification scheme that maximizes the energy metric functions related to the various related entities. The overall objective in this case is the incremental production of optimal classification and association extraction models. Also, we aim at the study of different mapping functions and their effect to the proposed classification scheme as regards uncertainty representation.

Moreover, in future, more information measures for our  classification scheme will be proposed based on various proposed in bibliography, and they will be evaluated in order to select the optimal definition for the classification quality measures.

