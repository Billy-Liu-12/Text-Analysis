Nonparallel Support Vector Ordinal Regression Huadong Wang, Yong Shi, Lingfeng Niu, and Yingjie Tian

Abstract?Ordinal regression is a supervised learning problem where training samples are labeled by an ordinal scale. The ordering relation and nonmetric property of the label set distin- guish it from the multiclass classification and metric regression.

To better exploit the inherent structure in the label and benefit from the hidden information in data distribution, we propose a novel ordinal regression model, which is named as nonpar- allel support vector ordinal regression (NPSVOR) to emphasis the utilization of nonparallel proximal hyperplanes. The new model constructs a hyperplane for each rank such that the pat- terns of this rank lie in the close proximity while maintaining clear separation with the other ranks. Since the learning of hyperplanes can be carried out independently, NPSVOR can be trained in parallel. Furthermore, we design an efficient solver at the same time for training the hyperplanes in NPSVOR based on the alternating direction method of multipliers.

Extensive experimentation demonstrates that NPSVOR yields a large and statistically significant improvement in terms of generalization performance and training speed against nine baselines.

Index Terms?Alternating direction method of multiplier (ADMM), nonparallel SVM, ordinal regression, proximal hyper- plane, support vector machine (SVM).



I. INTRODUCTION  ORDINAL regression is a supervised learning problemwhere training samples are labeled by an ordinal scale called ranks. Since an order exists among the different cate- gories in many situations, lots of problems can be modeled as ordinal regressions. In fact, in the fields where preference plays a major role, ordinal regression has a wide range of applications. It has been successfully applied in credit rat- ing [1], face recognition [2], [3], information retrieval [4], medical research [5]?[7], and social sciences [8].

In term of learning ranks, one straightforward way is to ignore the ordinal nature and take the ranks as labels for clas- sification directly [6]. Another way is to transform the ordinal scales into numeric values, and then treat the problem as metric regression [9], [10]. However, although ordinal regression is  Manuscript received April 29, 2016; revised August 23, 2016 and January 14, 2017; accepted March 11, 2017. This work was supported in part by the National Natural Science Foundation of China under Grant 11671379, Grant 11331012, Grant 71331005, and Grant 91546201, and in part by the UCAS under Grant Y55202LY00. This paper was recommended by Associate Editor J. Jayadeva. (Corresponding author: Lingfeng Niu.)  The authors are with the University of Chinese Academy of Sciences, Beijing 100190, China, and also with the Key Laboratory of Big Data Mining and Knowledge Management, Research Center on Fictitious Economy and Data Science, Chinese Academy of Sciences, Beijing 100190, China (e-mail: wanghuadong14@mails.ucas.ac.cn; yshi@ucas.ac.cn; niulf@ucas.ac.cn; tyj@ucas.ac.cn).

Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.

deemed to between classification and metric regression, it still has some differences. On one hand, the ordering relation on the label distinguishes it from the general multiclass classifi- cation. On the other hand, in contrast to the metric regression, the label set is finite and nonmetric. Therefore, to better exploit the structure hidden in the labels and benefit from the order- ing information, more specific models to deal with ordinal regression problem have been proposed in recent years.

An outstanding survey on ordinal regression is given in [11], which divides the existing models into three categories. The first group, just as we mentioned in the above paragraph, converts the ordinal regression into the multiclass classifica- tion or metric regression directly. The second group, which is referred as ordinal binary decompositions, utilizes the ordering information to decompose the original ordinal regres- sion into several binary classification tasks [12]?[18]. The third group, which is referred as threshold models, is based on the general idea of approximating a real value predic- tor and then dividing the real line into intervals [19]?[25].

Guti?rrez et al. [11] also carried out a thorough experi- mental study and compared 16 state-of-the-arts approaches for ordinal regression. Their numerical results demonstrate that methods based on support vector machines (SVMs) have shown promising results and achieved relatively better performance.

However, there are still some limitations. To be specific, the SVM-based threshold methods utilize the ordering relation to construct parallel discrimination hyperplanes in the primal feature space. The SVM-based binary decomposition methods utilize the ordering information by imposing weights over dif- ferent patterns. Obviously, both approaches fail to consider the data distribution of different ranks properly and might lead to unreasonable solutions. To better utilize the distribution infor- mation, we propose constructing a set of possible nonparallel hyperplanes. For this purpose, a hyperplane is constructed for each class independently. In detail, for each rank, a hyperplane will be found based on the ordinal partition, such that the pat- terns of this rank lie in the close proximity while maintaining clear separation with the other ranks. To emphasis that the new model is based on SVM and the allowance of nonparallel discrimination hyperplanes, we name it as nonparallel support vector ordinal regression (NPSVOR) in this paper. Another advantage of NPSVOR is that the proximal hyperplanes for each rank can be trained independently, which means the train- ing efficiency can be greatly improved with the careful parallel implementation. In order to solve our proposed model effi- ciently, we also designed a training algorithm based on the alternating direction method of multipliers (ADMMs) which is one of the most popular and efficient first order algorithms for big data analysis.

See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

mailto:wanghuadong14@mails.ucas.ac.cn mailto:yshi@ucas.ac.cn mailto:niulf@ucas.ac.cn mailto:tyj@ucas.ac.cn http://ieeexplore.ieee.org http://www.ieee.org/publications_standards/publications/rights/index.html   This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

The rest of this paper is organized as follows: In Section II, we briefly review the state-of-the-art SVM-based ordinal regression methods. In Section III, we present our non- parallel SVM model for ordinal regression. In Section IV, the designation of tailored ADMM algorithm for NPSVOR is introduced. We conduct experiments in Section V. the corresponding results also are discussed at this section.

Finally, the conclusions and some future works are given in Section VI.



II. RELATED WORKS  Shashua and Levin [20] generalized the SV formulation for ordinal regression by finding a set of thresholds that divide the real line into several consecutive intervals for the ordered cat- egories. By applying a large margin principle to this learning problem, they introduced two main approaches for implement- ing the large margin optimization criteria. The first is the ?fixed margin? policy in which the margin of the closest neighbor- ing classes is being maximized. The second approach allows for different margins where the sum of margins is maximized, thus effectively having the solution biased toward the pairs of neighboring classes which are the farthest apart from each other.

Chu and Keerthi [21], [26] proposed two new SV approaches and for ordinal regression, which optimize multiple thresholds to define parallel discriminant hyperplanes for the ordinal scales. The first one, which is named as SVOREX, takes only the adjacent ranks into account in determining the thresholds. The second approach, which is named as SVORIM, considers the training samples from all the ranks to determine each threshold. Both approaches guarantee that the thresholds are properly ordered at the optimal solution.

The SMO algorithm is adapted for the resulting optimization problems. Gu et al. [25] presented a modified SVOR formu- lation based on a sum-of-margins strategy and proposed an effective incremental SVOR algorithm.

Li and Lin [23], [24] presented a reduction framework from the ordinal regression to the binary classification based on extended samples, which consists of three steps: 1) extracting extended examples from the original examples; 2) learning a binary classifier on the extended examples with any binary classification algorithm; and 3) constructing a ranking rule from the binary classifier. They used a weighted 0/1 loss of the binary classifier bound the mislabeling cost of the ranking rule and derive new generalization bounds for ordinal rank- ing from known bounds for binary classification. By choosing standard SVM as the binary classification solver, reduction-to- SVM (REDSVM) was proposed at the same time. REDSVM constructs #ranks-1 parallel hyperplanes that simultaneously maximize the corresponding margins. The obtained parallel hyperplanes separate the hyperspace into #ranks blocks by using #ranks-1 thresholds.

In all the above methods, the resulting hyperplane rankers are all composed of a set of parallel hyperplanes. On the one hand, since all the hyperplanes share the same slope, SVM- based threshold methods usually result in large scale models, especially when there are many classes. On the other hand,  the underlying assumption of threshold methods is that these classes are well ordered in a unique direction and separable by hyperspaces. Since this assumption could not be always satis- fied, ranker with nonparallel hyperplanes should be studied to capture more scattered data [15].

Frank and Hall [27] converted an ordinal regression problem into nested binary classification problems that encode the ordering of the original ranks and then organized the results of these binary classifiers in some ad hoc ways for prediction.

They presented a simple method that enables standard clas- sification algorithms to exploit the ordering information in ordinal prediction problems using the decision tree learner.

At prediction time, an instance of unknown class is pro- cessed by each of the classifiers and the probability of each of the ordinal class values is calculated. The class with max- imum probability is assigned to the instance. In the work of Waegeman and Boullart [13], Frank and Hall?s framework in [27] is used but different weights are imposed over the patterns of each binary system, in such a way that errors on training objects are penalized proportionally to the absolute difference between their rank and the corresponding estima- tion. Additionally, labels for the test set are obtained by combining the estimated outcomes of a set of binary clas- sifiers. An enhanced ensemble method for ordinal regression was proposed in this paper. Weighted SVMs were used as base classifiers. As stated by the authors, this strategy can result in ambiguities for some test patterns, and they should be solved by using similar techniques in nominal classification.

Another similar scheme is proposed in [15], where the weights are obtained in a slightly different way, and different kernels are used for the different binary classification sub-problems.

A cost-sensitive property is exploited to find better hyper- planes based on the classification costs. The proposed ordinal hyperplanes ranker achieved promising performance on the age-estimation application. However, all the approaches based on the framework of Frank and Hall [27] may lead to negative probability estimates. According to the numerical comparison, the performance of the ordinal binary decomposition methods is still inferior to the threshold methods.

Recently, [16] proposed an ensemble methodology specif- ically adapted to the ordinal regression problem. It is based on computing different classification tasks through the formu- lation of different order hypotheses. Every single model is trained in order to distinguish between one given class and all the remaining ones. Inspired by their way of utilizing ordi- nal information, to further improve the performance of the binary decomposition methods, we concentrate on designing a nonparallel hyperplane ranker for ordinal regression in this paper.



III. NONPARALLEL SUPPORT VECTOR ORDINAL REGRESSION  In ordinal regression, each sample in the training data set is composed of an input vector and an ordinal label. Suppose there are p different ordered categories, without loss of gen- erality, we use consecutive integers 1, 2, . . . , p to denote the ranks in this paper. Let the number of samples be n. Then the    This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

WANG et al.: NPSVOR 3  Fig. 1. Construction of proximal hyperplanes. (a) rank 1, (b) rank 2, (c) rank 3. ??,? ? ?,? and ??? stand for ranks 1, 2, 3, respectively. SVs are marked in bold.

training set can be represented in the following way:  S = {(xi, yi)}i=1,...,n where xi ? ?n is the input vector and yi ? {1, 2, . . . , p} is the label of xi.

Consider predicting based on the proximity [28]?[30], sup- pose a proximal hyperplane could be learned from the training data set S. Then the label of a new input can be naturally assigned to the rank corresponding to the nearest hyperplane for each rank. Generally speaking, a good set of proxi- mal hyperplanes should represent the distribution of samples, reflect the order in labels, and possess good generalization ability at the same time. Since the quality of proximal hyper- planes directly decide the quality of the prediction, we will concentrate on the construction of hyperplanes in the next section.

A. Construction of Nonparallel Hyperplanes  Given k ? {1, 2, . . . , p}, we define three index sets for each rank k  Lk = {i|yi < k}, Ik = {i|yi = k} and Rk = {i|yi > k} where yi is the rank of the instance xi. We seek the hyperplance w?k x + bk = 0 with the following properties.

1) The Hyperplane Should Be Close to the Samples With Rank k: Inspired by [31], we require that the ?-band between the hyperplanes w?k x+bk = ? and w?k x+bk =?? should contain as many as possible samples from the kth categories, that is  ?? ? w?k xi + bk ? ?, i ? Ik (1) where ? > 0 is a given parameter.

2) The Hyperplane Should Be Far From the Samples With Other Ranks: To achieve this goal, the samples from other categories should be pushed away from the hyperplane with a certain distance, that is  ? ? ?w?k xi + bk  ? ? ? ? 1, i /? Ik. (2)  3) In order to reflect the order in labels, samples whose ranks are lower than k and samples whose ranks are  higher than k should be located at different sides of the constructing hyperplane, that is  w?k xi + bk ? ?1, i ? Lk (3a) w?k xi + bk ? 1, i ? Rk. (3b)  4) The Hyperplane Should Possess Good Generalization Ability: To this end, the confidential interval should be minimized, i.e., min ?wk?2.

By combining the above requirements and introducing the slack variables to include the nonseparable situations, we obtain the following quadratic programming (QP):  min wk,bk,?  + k ,?  ? k ,?k   ||wk||22 + C1  ?  i?Ik  (  ?+ki + ??ki ) + C2  ?  i/?Ik ?ki (4a)  s.t. ?? ? ??ki ? w?k xi + bk ? ? + ?+ki , i ? Ik (4b) w?k xi + bk ? ?1 + ?ki, i ? Lk (4c) w?k xi + bk ? 1 ? ?ki, i ? Rk (4d) ?+ki , ?  ? ki ? 0, i ? Ik (4e)  ?ki ? 0, i /? Ik (4f) where C1, C2 > 0 are model parameters. Denote the optimal proximal hyperplane of rank k obtained by (4) as x?w?k +b?k = 0 for all k = 1, 2, . . . , p. Fig. 1 gives a geometrical illustration of the construction of proximal hyperplane in ?2. Then the prediction rule can be written as  f (x) = arg min k?{1,...,p}  ? ? ?  (  w?k )?x + b?k  ? ? ?. (5)  To emphasis that the p proximal hyperplanes are computed independently and are not necessarily parallel with each other, model (4) is named as NPSVOR in this paper. Obviously, when the number of ranks is two, NPSVOR can be degenerated to nonparallel SVM for binary classification [31].

We use a 2-D dataset with three ordinal scales to demon- strate the differences between our proposed model and SVM- based threshold methods. Two famous models (SVR [32] and SVORIM [26]) are used for comparison. Fivefold cross vali- dation is used to select the optimal values of the parameters in SVR and SVORIM. For the simplicity of tuning parameters, two regularization factors C1, C2 of NPSVOR are set equal in the grid search and the insensitive parameter ? is fixed to 0.2.

This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

Fig. 2. Differences between NPSVOR and other SVM-based ordinal regression models. 3?100 instances are sampled from three bivariate Gaussian clusters.

The mean of the clusters is set to (10, 10), (15, 15), and (20, 10), respectively. The variances are fixed to (5, 5). ??,? ? ?,? and ??? stand for ranks 1, 2, 3, respectively. For each rank, 25 samples are used for training and others for testing.

The training results of the three methods are shown in Fig. 2.

From the figure we can see that our model can adaptively get nonparallel proximal hyperplanes, but SVR and SVORIM just obtain parallel decision boundaries. For this kind of datasets without parallel distribution, NPSVOR works reasonable better than the SVM-based threshold models.

B. Dual Problem and Kernel Formulation  Let ?+ki , ? ? ki ? 0 be the Lagrangian multipliers for  the right-hand side and left-hand side inequalities in (4b), ?ki, ?  + ki, ?  ? ki, ?ki ? 0 be the Lagrangian multipliers for  the inequalities in (4c)?(4f), respectively. Denote ?+k = (?+ki )i?Ik , ?  ? k = (??ki )i?Ik , ?k = (?ki)i/?Ik ,?+k = (?+ki)i?Ik ,  ??k = (??ki)i?Ik , ?k = (?ki)i/?Ik . The Lagrangian function of problem (4) is  L (  wk, bk, ? + k , ?  ? k , ?k,?  + k ,?  ? k ,?k,?  + k ,?  ? k , vk  )  = 1 ?wk?22 + C1  ?  i?Ik  (  ?+ki + ??ki ) + C2  ?  i/?Ik ?ki  + ?  i?Ik ?+ki  (  w?k ?(xi) + bk ? ? ? ?+ki )  ? ?  i?Ik ??ki  (  w?k ?(xi) + bk + ? + ??ki )  ? ?  i/?Ik ?ki  (  y?ki (  w?k ?(xi) + bk )  ? 1 + ?ki )  ? ?  i?Ik  (  ?+ki? + ki + ??ki??ki  ) ? ?  i/?Ik ?ki?ki  where ?(?) is a feature mapping function, and y?ki = ?1 if i ? Lk ? Ik, otherwise, y?ki = 1. Then from the Karush?Kuhn?Tucker conditions of (4), we have  wk = ? ?  i?Ik  (  ?+ki ? ??ki )  ?(xi) + ?  i/?Ik y?ki?ki?(xi) (6)  and the constraints  0 ? ?+ki , ??ki ? C1, i ? Ik, 0 ? ?ki ? C2, i /? Ik.

Apply the kernel trick K(xi, xj) = ?(xi)??(xj), the dual problem of (4) becomes  min ?k,?  ? k ,?k  ?  i,i??Ik Kii?  (  ?+ki ? ??ki )(  ?+ki? ? ??ki? )  ? ?  i?Ik,j/?Ik y?kjKij  (  ?+ki ? ??ki )  ?kj  + ?  j,j? /?Ik y?kjy?kj?Kjj??kj?kj?  + ? ?  i?Ik  (  ?+ki + ??ki ) ?  ?  i/?Ik ?ki  s.t.

?  i?Ik  (  ?+ki ? ??ki ) ?  ?  i/?Ik y?ki?ki = 0  0 ? ?+ki , ??ki ? C1, i ? Ik 0 ? ?ki ? C2, i /? Ik (7)  where Kij = ?(xi)??(xj), ?(?) is the feature mapping function.

Problem (7) for rank k has n + lk variables, where lk is the  number of samples belong to the kth rank. Noticing that the standard SVM for classification (SVC) has only n variables, if a dual-based solver is applied without a careful designa- tion, the computational cost of solving (7) will be significantly higher than that for SVC. It should be noted that an important property of the dual problem (7) is that at the optimum  ?+ki ? ? ki = 0, i ? Ik  which, together with the condition ?+ki , ? ? ki ? 0, imply that at  the optimum  ?+ki + ??ki = ? ??+ki ? ??ki  ? ?, i ? Ik.

Denote ?k = (?k1, . . . , ?kn)?, where ?ki =  {?(?+ki ? ??ki )  i ? Ik y?ki?ki i /? Ik.

Then the problem (7) can be transformed as  min ?k   ??Kk ?k +  ?  i?Ik ?|?ki| ?  ?  i/?Ik y?ki?ki  s.t. e??k=0 ? C1 ? ?ki ? C1, i ? Ik 0 ? y?ki?ki ? C2, i /? Ik (8)    This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

WANG et al.: NPSVOR 5  Algorithm 1 NPSVOR 1: Input S, K(?, ?), C1, C2 > 0 and ? > 0.

2: for each k ? {1, 2, . . . , p}, do 3: Construct and solve subproblem (8) to get proximal  hyperplane of rank k in (10).

4: end for 5: Obtain the decision function by (10).

where K is the n by n symmetric kernel matrix and e ? ?n is the vector of ones. Problem (8) is the submodel for rank k which need to be solved in this paper.

Denote the optimal solution of the dual problem (8) as ??k .

The proximal hyperplane of rank k becomes  fk(x) = n  ?  i=1 K(x, xi)??ki + b?k (9)  here b?k can be obtained from the complementarity conditions.

Concretely  i ? Ik,?C1 < ??ki < 0,? ?  j  k (  xi, xj )  ??kj + bk = ?  i ? Ik, 0 < ??ki < C1,? ?  j  k (  xi, xj )  ??kj + bk = ??  i /? Ik, 0 < y?ki??ki < C2 ? y?ki ?  ? ?  j  k (  xi, xj )  ??kj + bk ?  ? = 1.

And the decision function (5) can be rewritten as  f (x) = arg mink?{1,...,p}|fk(x)|. (10) We summarize the training process of NPSVOR in  Algorithm 1. Compared with the existing SVM-based thresh- old models (such as SVOREX and SVORIM in [26]) that need to solve a large scale QP with p ? 1 equality constraints, Algorithm 1 needs to solve p small scale QPs and each of them only contains one equality constraint. Furthermore, these p QPs are independent with each other and can be solved in parallel.

Definition 1: Denote the optimal solution of the dual problem (8) as ??k . The sample xi is called SV for rank k if  ??ki = 0, i = 1, 2, . . . , n.

In Fig. 1, the SVs are marked in bold, from which we can see that only a few amount of samples are SVs. Since the con- struction of decision function in (10) only needs the samples whose corresponding variables are nonzeros, the sparsity of SVs means that the predicting process of NPSVOR could be done very efficiently in practice.



IV. TRAINING ALGORITHM FOR NPSVOR  Now we discuss how to train the proposed NPSVOR effi- ciently. Since the decision function of NPSVOR is composed of p proximal hyperplanes, which can be obtained indepen- dently from (8). We concentrate on solving the subproblem (8) in this section. For the simplicity of representation, the sub- script for rank k is dropped in the following discussion.

The ADMM is a convex optimization algorithm dating back to the early 1980s [33], [34]. With the ability of deal- ing with objective functions separately and synchronously, ADMM turned out to be a natural fit in the field of large- scale data-distributed machine learning and big-data related optimization, and therefore received significant amount of attention in the last few years [35]. Therefore, we propose an efficient algorithm based on ADMM to solve NPSVOR.

A. ADMM for NPSVOR  Rewrite the dual problem (8) with auxiliary dummy vari- ables z in the following way:  min ?,z  f (?) + g(z) s.t. ? = z (11)  where f (?) = (1/2)??K?, g(z) = ?i?I ?|zi| ? ?  i/?I y?izi, domf = {?|e?? = 0}, and domg = {z| |zi| ? C1, i ? I; 0 ? y?izi ? C2, i /? I}. The augmented Lagrangian function with the scaled dual variable of (11) becomes  L?(?, z, u) = f (?) + g(z) + ?  (  ?? ? z + u?22 ? ?u?22 )  (12)  where u is the scaled dual variable and ? > 0 is the penalty parameter. The form of ADMM at tth iteration is  ?t+1 = arg min ??domf f (?) +  ?   ? ?? ? zt + ut??22 (13a)  zt+1 = arg min z?domg g(z) +  ?  ??t+1 ? z + ut?22 (13b)  ut+1 = ut + ?t+1 ? zt+1. (13c) The ?-update in (13a) is just to solve a quadratic function restricted to an affine set domf , whose Karush?Kuhn?Tucker system [36] can be rewritten as  [  K + ?I e e? 0  ][  ?t+1 vt+1  ]  = [  ? (  zt ? ut)  ]  (14)  where e ? Rn is the vector of ones and v is the Lagrangian multiplier. It has a close form solution  vt+1 = ?e ?(K + ?I)?1(zt ? ut)  e?(K + ?I)?1e (15a)  ?t+1 = (K + ?I)?1 (  ? (  zt ? ut) ? vt+1e )  . (15b)  Noticing that the coefficient matrix of the ?-update in (14) is the same for all the iterations and for all the ranks, which reduces the computational cost drastically.

The z-update in (13c) can be splitted into n separate scalar optimizations. In detail, (13b) is equivalent to solve the following problems:  zt+1i = arg minzi?[?C1,C1] ?|zi| + ?   (  ?t+1i ? zi + uti )2  , i ? I (16a)  zt+1i = arg min y?izi?[0,C2]  ?y?izi + ?  (  ?t+1i ? zi + uti )2  , i /? I.

(16b)    This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

Algorithm 2 ADMM for NPSVOR 1: Set t = 0, choose ? > 0, C1 > 0, C2 > 0 and initialize  ?0, z0, u0.

2: repeat 3: Update ?t+1 via (15); 4: Update zt+1 via (17) and (18); 5: Update ut+1 via (13c); 6: t: = t + 1.

7: until Stopping criterion in (19) is satisfied.

The objective function of (16b) is one variable quadratic function and the solution can be written out directly  zt+1i = mid (  0, ?t+1i + uti + y?i/?, y?iC2 )  , i /? I. (17) The objective function of (16a) is not differentiable, but we still can easily compute a simple closed-form solution to this problem by using subdifferential calculus [37]. In detail, the solution of (16a) is  zt+1i = mid (  ?C1,S?/? (  ?t+1i + uti )  , C1 )  , i ? I (18) where mid(?, ?, ?) is the operation that supplies the median of its three arguments, and the soft thresholding operator S is defined as  S?(a) = ?  ?  ?  a ? ?, a > ? 0, |a| ? ? a + ?, a < ??.

According to [35], the ADMM iterates in (13) terminate when the following conditions are satisfied:  ? ?rt  ? ?  2 ? ?  n?abs + ?rel max{???t??2, ? ?zt  ? ?   }  (19) ? ?st  ? ?  2 ? ?  n?abs + ?rel??ut??2 (20) where rt = ?t ? zt and st = ?(zt ? zt?1) are primal and dual residuals at the tth iteration, respectively. ?abs ? 0, ?rel ? 0 are pregiven tolerances. We will further discuss how to choose the proper value of ?abs, ?rel in the experiment part. Tailored ADMM for NPSVOR is summarized in Algorithm 2.

B. Convergence Analysis and Computational Complexity  The convergence property of Algorithm 2 can be derived from the standard convergence theory of the ADMM [35]. To be more specific, the following theorem can be obtained.

Theorem 1: Suppose the kernel matrix satisfy Mercer?s condition, the iterates generated by Algorithm 2 with ?abs, ?rel = 0 globally converge to an optimal solution of (8).

The convergence rate is at least linear.

The major computational burden of Algorithm 2 lies mainly on updating ? by (15). One good merit of our new proposed model is that, given an ordinal regression problem, the coeffi- cient matrix K + ?I is always the same, in all the submodels of NPSVOR and all the iterations of each submodel. Based on this fact, to improve the efficiency of the training process of NPSVOR, we suggest to form the inverse matrix in advance.

One thing we want to stress is that it is a commonly used tech- nique to calculate and store the matrix which needs to be used  many times in advance, especially in ADMM algorithms [35].

Furthermore, since K + ?I is a positive definite coefficient matrix, the Cholesky factorization can be used to compute its inverse. When the scale of the problems is too large to com- pute and store the inverse of K +?I, the incomplete Cholesky Factorization with factor matrix in low rank [38], [39] and Sherman?Morrison?Woodburg formula can be used to com- pute the inverse matrix approximately. Another thing we want to mentioned is that our current ADMM algorithm is a sequen- tial version. It can be extended into a distributed version by splitting the training examples or features directly [35], [40].



V. NUMERICAL EXPERIMENTS  In this section, numerical experiments are carried out to test the performance of NPSVOR. All the experiments are con- ducted on 3.80 GHz ADM FX(tm)-4300 CPU PC running Linux with 4 GB main memory. Our method was imple- mented in MATLAB. The source code is available online at https://github.com/huadong2014/NPSVOR/. The RBF kernel K(x, x?) = exp(?? ||x ? x?||22) is used in the experiments. The following two evaluation metrics, which are commonly used for ordinal regression, are utilized to access the accuracy of predicted ordinal scales {y?1, . . . , y?n} with respect to true targets {y1, . . . , yn}.

1) Mean zero-one error (MZE) is the fraction of incorrect predictions.

2) Mean absolute error (MAE) is the average deviation of the prediction from the true target, that is  MAE = 1 n  ?n  i=1 ? ?y?i ? yi  ? ?.

A. Selection of Parameter ?  Besides the regularization factors C1 and C2, ? is another parameter in our model, which is used to control the width of insensitive margin. Since ? influences the sparsity of solu- tion and the performance of NPSVOR, our first experiment is to investigate how to choose a suitable value of ?. Fig. 3 shows how MZE and MAE vary with the value of ? on two representative datasets. Generally speaking, ? ? [0.1, 0.3] can capture the structure information of data distribution and obtain the minimal value of MZE and MAE. For ease of tuning parameters, we fix the value of ? = 0.2 for the rest experiments.

B. Termination Tolerances for ADMM  In this section, we discuss how to set the termination tol- erances of Algorithm 2. In order to see how ?abs and ?rel in stopping criterion (19) affect the performance of MZE and MAE, we fix the hyperparameters C1, C2, ?, and ? ,1 and vary the value of ?abs and ?rel in the range {10?10, 10?9, . . . , 100}.

Fig. 4 shows the variation of MZE and MAE with ?abs and ?rel. It can be seen that the values of MZE and MAE become stable when ?abs ? 10?1 and ?rel ? 10?1. By considering the computational cost and the robustness of the algorithm, we  1The fixed values were chosen with fivefold cross validation.

https://github.com/huadong2014/NPSVOR/   This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

WANG et al.: NPSVOR 7  (a) (b)  Fig. 3. Variation of MZE and MAE with the value of ?. The results are reported for ? on the interval [0,0.5] with grid linearly spaced by 0.025. California (eight features and 20 640 samples) and census (16 features and 22 784 samples) can download from http://www.dcc.fc.up.pt/ltorgo/Regression/DataSets.html.

The targets of these two benchmark datasets were discretized into five equal-frequency bins. The number of training and test patterns were those suggested in [26]. Fivefold cross validation was used to determine the optimal values of C1 = C2. (a) Results on the California. (b) Results on the census.

Fig. 4. Variation of MZE and MAE on testing datasets with ?abs and ?rel.

(a) California (MZE). (b) California (MAE). (c) Census (MZE). (d) Census (MAE).

suggest terminate the ADMM iterations with ?abs = 10?2 and ?rel = 10?2.

C. Performance Comparison  In this section, we compare NPSVOR against the state-of-the-art SVM-based methods for ordinal regression.

1) Benchmark Datasets: All the real datasets in [11] are used for our experiments. The input vectors of all datasets are normalized to zero mean and unit variance, coordinate-wise.

30 random stratified splits with 75% and 25% of the patterns in the training and test sets are considered, respectively.2 To fur- ther examine the performance of our model on larger datasets, we also choose six benchmark datasets from the website http:// www.gatsby.ucl.ac.uk/chuwei/ordinalregression.html. These datasets are not real ordinal classification problems but regression ones, which are turned into ordinal regression by discretising the target into five different bins with equal frequency. We randomly partitioned each dataset into  2The generated partitions of these datasets are available at http://www.uco.es/grupos/ayrna/orreview.

TABLE I DATA STATISTICS  training/test splits as specified in Table I. The partitioning was repeated five times independently. The input vectors were also normalized to zero mean and unit variance, coordinate-wise. Data statistics are given in Table I, including the number of instances, features and classes, the class distribution (number of patterns per class) and training/test partition.

2) Compared Methods: To test the performance of NPSVOR, we compared it with all the SVM-based ordinal regression models reported in the survey [11] and the method proposed in [16]. The baselines are as follows.

1) SVC1V1: Standard SVC with one versus one [41].

2) SVC1VA: Standard SVC with one versus all [41].

3) SVR: Support vector regression [32].

4) CSSVC: Cost-sensitive support vector classifier [41].

5) SVMOP: SVMs with ordered partitions [13].

6) SVOREX: SVM for ordinal regression with explicit  constraints [26].

http://www.dcc.fc.up.pt/ ltorgo/Regression/DataSets.html http://www.gatsby.ucl.ac.uk/chuwei/ordinalregression.html http://www.gatsby.ucl.ac.uk/chuwei/ordinalregression.html http://www.uco.es/grupos/ayrna/orreview   This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

TABLE II TEST MZE FOR EACH DATASET AND METHOD, INCLUDING THE AVERAGE OVER ALL THE SPLITS AND THE STANDARD DEVIATION  7) SVORIM: SVM for ordinal regression with implicit constraints [26].

8) REDSVM: The reduction from cost-sensitive ordinal ranking applied to weighted binary classification frame- work to SVM [24].

9) OPBE: Ordinal projection-based ensemble,where the based classifier is SVORIM [16].

3) Parameter Setting: Fivefold cross validation is used to determine the optimal values of model parameters, and the test error is obtained by using the optimal parameters for each formulation. We set C1 = C2 in NPSVOR and select its values the same as the regularization parameters C in other SVM- based models in range [10?3, 10?2, . . . , 103]. The grid search for kernel parameter ? is done in range [10?3, 10?2, . . . , 103].

We set ? = 1 in Algorithm 2. For the SVR, the ? is set to 0.1. The criteria for selecting the best configuration are both MAE and MZE performances, depending on the measure we are interested in.

Comparisons are carried out on the common MATLAB framework which can be downloaded from http://www.uco.es/grupos/ayrna/orreview. We used the LIBSVM for SVC1V1, SVC1VA, SVR,3 and CSSVC.4  Codes used for SVOREX and SVORIM are downloaded from http://www.gatsby.ucl.ac.uk/?chuwei/svor.htm. REDSVM is downloaded from http://www.work.caltech.edu/?htlin/ program/libsvm/. The code of OPBE was provided by P?rez-Ortiz one of the authors of [16]. For all the other methods that are used for comparison, the default stopping criteria in the corresponding packages are used.

3SVC1V1, SVC1VA, and SVR(libsvm-3.21): https://www.csie.ntu.edu.tw/ ?cjlin/libsvm/.

4CSSVC(libsvm-weights-3.12): https://www.csie.ntu.edu.tw/?cjlin/ libsvmtools/weights/.

4) Performance Comparison: We report the computational results of NPSVOR and nine baselines on 23 datasets in Tables II and III. The lowest average values of MZE and MAE are marked in bold face in the last row. A p-value threshold of 0.05 in Wilcoxon signed sum test is used to decide the ranking of the ten methods on each dataset. The average ranks of each methods on MZE and MAE are presented in the last row of Tables II and III, respectively. The best results are also high- lighted in bold face. The Wilcoxon test is also applied to check the existence of significant differences. In detail, each pair of methods is compared for each dataset and the total number of statistically significant wins, draws or losses are reported in Table IV.

To conduct comparison more systematically, Friedman test [42], which is widely accepted as the favorable statisti- cal test for comparisons of multiple algorithms over a number of data sets, is employed. The null hypothesis states that all the algorithms are equivalent, and so, their ranks should be equal. If the null hypothesis is rejected, we can proceed with a post-hoc test to find out which algorithms differ from oth- ers significantly. To be more specific, the performance of two algorithms is considered to be different significantly if the difference of their average ranks is larger than the critical difference (CD). Fig. 5 shows the CD diagrams for the ten models on MZE and MAE (? = 0.05 significant confidence was considered), where the average rank of each compared model is marked along the axis. The axis is turned so that the lowest (best) ranks are to the right. Groups of models that are not significantly different are connected with a thick line.

From these results, several conclusions can be drawn: first, when the MZE is considered, NPSVOR is the second best among the compared methods. When the MAE is consid- ered, NPSVOR outperforms all the baselines. As we expected  http://www.uco.es/grupos/ayrna/orreview http://www.gatsby.ucl.ac.uk/?chuwei/svor.htm http://www.work.caltech.edu/~htlin/program/libsvm/ http://www.work.caltech.edu/~htlin/program/libsvm/ https://www.csie.ntu.edu.tw/~cjlin/libsvm/ https://www.csie.ntu.edu.tw/~cjlin/libsvm/ https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/weights/ https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/weights/   This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

WANG et al.: NPSVOR 9  TABLE III TEST MAE FOR EACH DATASET AND METHOD, INCLUDING THE AVERAGE OVER ALL THE SPLITS AND THE STANDARD DEVIATION  TABLE IV WILCOXON TESTS OVER 23 DATASETS AND TEN METHODS. IN ALL, 23 ? 9 = 207 COMPARISONS ARE CONDUCTED. THE METHODS ARE  ORDERED BY THE NUMBER OF STATISTICALLY SIGNIFICANT #WINS?#LOSSES  when we began our research, these results were not far-fetched since the parallel decision boundary is just a special case of NPSVOR. Second, the advantage of our model is more obvious on MAE than MZE. This is because MZE does not take into account the distance from the predicting label to the true rank. While MAE measures the average deviation of the prediction from the true target. Since NPSVOR con- structs the model based on ordering information, MAE is a more proper measurement. Another thing we should be noted is that in the above experiment, for the fairness of comparison, we set C1 = C2 and fix ? = 0.2 in NPSVOR. In this case, although NPSVOR is a triple-parameter model, there is only one model parameter need to be tuned. In practice, if more computational efforts can be paid for the selection of param- eters C1, C2, and ?, such as tuning ? on a certain interval or allowing C1 = C2, which generalization performance could be further improved.

Fig. 5. CD-diagram of (a) MZE and (b) MAE. Comparison of NPSVOR (control algorithm) against nine baselines with the Friedman test.

We also report the time of cross validation for each problem in Table V and depict the results for the problems whose num- ber of training samples is larger than 500 in Fig. 6(a). We can see that although NPSVOR is slower than binary decomposi- tion methods on small problems, it is quite efficient on larger problems.

D. Scalability  In this section, we study the scalability of the proposed NPSVOR and other state-of-the-art approaches. Experiment is carried out on the California Housing dataset, which was    This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

TABLE V TOTAL COMPUTATIONAL TIME OF CROSS-VALIDATION  Fig. 6. Plot of cross validation time of datasets whose number of training samples is larger than 500.

used to study the algorithm scalability in [26]. For our exper- iment, nineteen training datasets with different sizes ranging from 100 to 10 000 were generated by random selection from the original dataset. The remaining samples are corresponding testing datasets. In order to assure a fair comparison, we set ? = 1 and C = 100 for all the methods.5  Fig. 7(a) and (b) give plots of MZE and MAE of the ten methods as functions of the problem size, respectively.

It shows us that NPSVOR has good scaling with the size of training datasets. Especially, considering the MAE, NPSVOR is significantly better than the baselines. Considering the MZE, although our method is not the best for small datasets, the performance of NPSVOR is improved quickly with the increasing of dataset size. For the cases whose the number of training data is larger than 1000, NPSVOR outperforms all the baselines. Fig. 7(c) gives the plot of the CPU time versus #training data on x-log scale, from which we can see that NPSVOR is a well scaling method and is faster than all  5For NPSVOR, C1 = C2.

the baselines except SVC1V1. Notice that SVC1V1 calls the famous solver LIBSVM for training, which is implemented in C. While NPSVOR is in MATLAB currently, we believe that if NPSVOR could be implemented carefully in C, the training of NPSVOR would be at least as efficient as SVC1V1.

E. Collaborative Filtering  In this section, we test the generalization performance of NPSVOR on a practical application?collaborative filtering (CF). The goal of CF is to predict a person?s rating on new items given the person?s past ratings on similar items and the ratings of other people on all the items. The rat- ings are ordered, thus CF fall naturally under the domain of ordinal regression (rather than general multiclass learning).

Experiment is carried out on the MovieLens 1M dataset.6 The MovieLens dataset contains approximately 3 900 movies rated by 6040 MovieLens users arranged as a matrix whose columns represent the movies and the rows represent the users. The rat- ings given by users on movies were used as the targets. About 4.25% of the entries of this matrix are filled-in with ratings between 0, 1, . . . , 5 totaling 1 000 209 anonymous ratings. The learning task in this experiment is to predict the rating of the new user.

We selected 1500 users who contributed the most ratings on these 518 movies for test. The ratings given by the 1500 users on each movie were used as the input vector accordingly.

In the 503 ? 1500 input matrix, about 35.17% elements were observed. As not all ratings are observed in the input vec- tors, we use mean imputation as a reasonable strategy to deal with missing values and identify the unobserved ones with the mean value. More details about handling the miss entities of the input matrix could be found in [26]. We randomly selected  6The dataset is available at http://grouplens.org/datasets/movielens/.

http://grouplens.org/datasets/movielens/   This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.

WANG et al.: NPSVOR 11  Fig. 7. Plots of MZE (a) and MAE (b) versus the size of training datasets on x-log scale, respectively. (c) Plot of CPU time versus the size of training datasets on x-log scale.

Fig. 8. Performance on a subset of MovieLens data. The grouped boxes represent the results at different training data size.

a subset with size {100, 150, . . . , 400} of the 503 movies for training, and then tested on the remaining movies. At each size, the random selection was carried out 20 times indepen- dently. All the parameters are determined in the same manner as explained in Section V-C. The test results averaged over 20 trials are presented as boxplots in Fig. 8, from which we can see that, when the size of training dataset is small, OPBE out- performs NPSVOR. With the increasing of #training data, the MAE obtained from NPSVOR decreases steadily. When the number of training data is larger than 250, NPSVOR achieves the best performance.



VI. CONCLUSION  In this paper, we proposed a new model for ordinal regres- sion problem by constructing a set of nonparallel proximal hyperplanes. For each rank, the hyperplane is determined in the following way: on one hand, data with the same rank lies in the proximity of the ?-insensitive band of this hyper- plane. On the other hand, data with rank lower than k and data with rank greater than k should be separated on the both sides of the hyperplane. Compared with the fact that most of the existing SVM-based model are based on the binary decompositions, our proposed model is based on a nested triple decompositions. Numerical comparisons with state-of-the-art SVM-based methods on a large pool of datasets demonstrated the effectiveness and the efficiency of our method.

There are still more works that can be done for the fur- ther study of our proposed model. For example, unbalance always occurs between the regression class and the rest classes.

We may improve this situation by giving different weights for different submodels. In addition, mislabeling cost are widely  considered in ordinal regression problem. In order to further improve the generalization performance, we can also consider introducing the mislabeling cost matrix in our model. Last but not least, how to design an distributed version of our model and apply it to the big data situation is an interesting and challenging problem.

