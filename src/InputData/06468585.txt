Quantum-Negative Selection Algorithm for Associative Classification

Abstract-Most of classification and rule learning algorithms in machine learning use heuristic search to find part of rules for classification. Classification Associative Classification (AC) has shown a great dominance over many classification techniques. It integrates the rule discovery and classification process to build the classifier that supports decision making process. Artificial Immune Systems (AIS) have emerged during the last decade,It uses the population-based search model of evolutionary computation algorithms that it is regarded as a suitable way for dealing with complex search space. This paper proposes a Quantum-Negative Selection Algorithm (Q-NSA) for associative classification. It integrates quantum computing concepts and Negative Selection Algorithm (NSA) to building an efficient classifier by generating rule detectors to find the best subset of rules for all possible association rules. It employees a mutation operator with a quantum-based rotation gate to control and maintain diversity, and guides the search process. The performance of proposed algorithm is evaluated using benchmark datasets. The experimental results showed that the proposed algorithm is preformed well with large search space and has higher accuracy, and maintain diversity.

Keywords-Associative Classification, Quantum Computing , Artificial Immune Systems (A IS), Negative Selection Algorithm, Q-gate mutation, Pruning Process.



I. INTRODUCTION  An immune system is a biological system within an organ? ism that protects it against diseases by detecting and killing pathogens. It consists of a complex of cells, molecules and organs and It has the ability to distinguish antigen and antibody.lt has three immunological principles the immune network theory, negative selection mechanism, and clonal selection principle. Nowadays, Immune system applications spread in alot of fields as data mining, production, ... etc since it has some features like learning, memory acquisition, pattern recognition, diversity generation, noise tolerance ,de? tection and optimization. In this paper we focus in negative selection principle and mutation operator using quantum theory.

Associative classification uses association rules to pre? dict data class label. The main issue with the associative classification approach is the high quality association rules discovery in a very large space of candidate rules and incorporating these rules in the classification process by an   efficient way so applying quantum-inspired immune system (QIS) for associative classification will useful because we will get the benefit of immune system features and quantum computing contribution. So, the aim of this paper is to develop a Quantum-Negative Selection Algorithm (Q-NSA) for Associative Classification. The rest of this paper is orga? nized as follows. problem backgrounds and reviewing related works on the QIS and AC with evolutionary algorithms are introduced in section II. The proposed algorithm is presented in section III. Experimental results and discussion are presented in section IV. Finally, section V is devoted to conclusion and points for further research.



II. PROBLEM BACKGROUND AND RELATED WORKS  Classification association rules approach was firstly intro? duced by to Liu et al in 1998 with the classification based on associations (CBAs) algorithm. They integrate the two mining techniques classification and association rule mining.

The integration is done by focusing on a specific subset of association rules whose right-hand-side are restricted to the classification class attribute and they refer to this subset of rules as the class association rules (CARs) [2]. Based on U-Apriori algorithm and CBA algorithm,Qin et al proposed an associative classifier for uncertain data, uCBA (uncertain Classification Based on Associative), which can classify both certain and uncertain data. Their algorithm redefines the support, confidence, rule pruning process and classification strategy of CBA [3]. Mamta et al proposed a new model (associative classifier) based on weightage and utility for useful mining of substantial class association rules. This model uses the CBA-RG algorithm to produce a set of class association rules from a database and as well as exploits the downward closure property of the apriori algorithm [4]. A new associative classification method called CMAR is introduced, classification based on Multiple Association Rules. The method extends an efficient frequent pattern mining method, FP-growth, constructs a class distribution? associated FP-tree, and mines large database efficiently [5]. Classification based on Predictive Association Rules, (CPAR), is developed by Yin and Han at 2003. CPAR depends on a greedy algorithm to generate rules directly    from training data Instead of generating a large number of candidate selection rules. [6]. In 2011, Asha et al apply predictive rule mining techniques such as CPAR Predictive Rule Mining (PRM) and First Order Inductive Learner (FOIL) with statistical and Laplace as rule evaluation mea? sures for predicting Tuberculosis. CPAR and PRM were better than FOIL and also statistical measure results in less generation time compared to Laplace measure [7]. Yanbo et aI, proposed an efficient algorithm to solve a specific problem called (the SSR-CARM problem) in binomial time O(k2n2) which avoids selecting all k significant rules in a one-by-one manner [8]. Veloso et al proposed demand? driven associative classification algorithm, so that the corre? sponding algorithm achieves high classification performance even in the case of limited labeling efforts [9].Mangalampalli et al proposed a fuzzy associative classification algorithm for object class detection in images using interest points which relies only on the positive class for training [ 10]. Dixit et al studied and optimized an artificial immune system based classifi cation system. They evaluated the performance of the AIS based classification system by computing accuracy at different clonal factors and varying number of generations.

They used three standard datasets to compute the accuracy .They found that the system gives highest accuracy with clonal factor 0.4 [ 1 1]. Tien Dung et al investigated the clonal selection algorithm for Associative Classification (AC). They proposed a new approach known as AIS-AC for mining association rules effectively for classification and treat the rule mining process as an optimization problem of finding an optimal set of association rules according to some predefined constraints. AIS-AC approach is efficient in dealing with the complexity problem on the large search space of rules and It avoided searching greedily for all possible association rules, so it could find an effective set of associative rules for classification [ 12], [ 13].

In 1994, Forrest et al proposed a method called negative selection algorithm (NSA) for distinguishing self from other, which is based on the generation of T-cells in the immune system. In the training step, the negative selection algorithm generates detector set by eliminating any detector candidate that matches any self sample. In the testing step, the detector set is used to classify the testing samples. They described a general method for distinguishing self from other in the con? text of computational systems [ 15]. Dasgupta et al showed that NSA has attracted the attention of many researchers and practitioners [ 16]. Negative selection algorithm has been shown to be efficient for anomaly detection problems. Gong et al proposed an improved negative selection algorithm called FtNSA by integrating a novel further training strategy into the training stage for reducing self-samples to reduce computational cost in testing stage. They also investigated the influence of parameter a to the classification performance [ 17].

Quantum-Inspired Immune System is introduced by  Yangyang and Licheng ,they proposed a new immune clonal algorithm, called a quantum inspired immune clonal al? gorithm (QICA), based on the concept and principles of quantum computing, such as a quantum bit and superposition of states. QICA uses a quantum bit, the smallest unit of information [ 18]. Researchers also apply the Quantum Immune algorithm in the multi-objective optimization area, Gao et al proposed a novel quantum-inspired artificial im? mune system (MOQAIS) is presented for solving the multi? objective 0-1 knapsack problem (MKP), their algorithm is composed of a quantum-inspired artificial immune algorithm (QAIS) and an artificial immune system based on binary encoding (BAIS) [20].



III. PROPOSED ALGORITHM  In our proposed algorithm we deal with the associative algorithm process as an optimization problem to find the optimal (best) classification association rules (CARs) that will build the classifier. Rules discovery process differs from the rule discovery in the basic association rule mining algorithm. In the classification problem, there is a specific attribute called the class attribute that can take a given number of values and the goal is to induce a model that can be used to discriminate new data into classes. Associative classification is defined as follows:  Let I = {i1,i2 ... im} be a set of items. Let D be a set of transactions (the dataset), where each transaction d (a data record) is a set of items such that d ? I. A class association rule (CAR) is an implication of the form,R: X=} y, where X ? I and y E Y. The rule has a support(s) in D that equals percentage of transactions from a database that the given rule satisfies.

Supp(X =} y) = P(X u y) ( 1)  The rule X =} Y holds in the transaction set D with confidence (c) if c% of transactions in D that contain X also are labeled with class y and calculated by :  Conf(X =} y) = P(X I y) = su;p(? ? y) (2) upp y  We search classification association rules using negative selection algorithm. We considered each CAR as an immune cell and each generation is a set of class association rules.

The confidence measure is considered as the affinity function of our immune system.

Rule Selection process implicitly consists of two parts rule discovery (generation) and rule evaluation (selection).

Rule discovery come from the testing dataset starting from initial population then memory population increases through generations. We search for rules with the highest confidence values and confidence measure as the affinity in immune system so we select rules with high affinity and the selected rules should satisfy the support constraint to filter specific rules from the population before the selection process. We    Figure 1. Detectors Generation  terminate this process when generation count equals the number of generations and classification process applied after getting the CARs from memory pool. We build the classifier and apply it with the testing data then determine classifier accuracy by using any error analysis technique such as absolute error or square error.

A. Algorithm Steps  The main steps of the proposed algorithm are described in Algorithml where the detailed description of these steps are introduced in the following subsections.

B. Negative Selection process  1) Detectors Generation: In the training phase, dataset is considered as protected data so when a specific attribute has a value that doesnt appear in the training set, so this attribute value will be in the detector sets. Detectors generation is occurred for all items (values) not in the original data set as shown in figure 1. In the testing stage, the detector set is used to classify the testing samples. We proposed the detector as a rule that does not match any of the protected data.

2) Monitoring of protected rules: Monitor the protected rules by comparing them with the detectors. If a detector is ever activated, a change is known to have occurred as shown in figure 2. Monitoring process is performed also after mutation process. After detectors generation and monitoring process are performed, rules with the support less than min? Support threshold are eliminated; where selectionNumber of rules with the highest confidence are selected. The selection criterion is based on the best fitness.

C. Mutation process  In this process, each cell is mutated using quantum-based rotation Q-gate operator, a high probability is given for each low affinity cell to be mutated more than high affinity cell and then a new offspring is produced.

1) Mutation Operator: As mentioned above, the used mutation operator is a quantum-based rotation Q-gate. By selecting a subset Cs <;;; C where C is the population rules and assume there exists a parent cell  (3)  Algorithm 1 Q-NSA  I: Initialize a random population of rules Po of size n, 2: set the memoryset M = <I> and gCount = 0 3: Generate detectors from protected data by 2a.

4: Monitor the random populationPo by algorithm 2b.

5: while gCount < NoOfGenerations do 6: for each rule R in P do 7: if Support(R) < minSupport then 8: Remove Rule R from P.

9: end if  10: end for 11: Sort rules in P according to affinity value in descend?  ing order.

12: Select the first selectionNo affinity rules and insert  them into P instead other rules.

13: Mutate P by algorithm 3.

14: Monitor P by algorithm 2b.

15: Prune rules inside P.

16: for each rule R in P do 17: if conf(R) > minConfidence then 18: Insert R into M.

19: end if 20: end for 21: Reselect randomly new population (Pnew) from M  and make P=Pnew.

22: gCount=gCount+ 1.

23: end while  Algorithm 2a Generating Detectors  1: Generate a population Pvalues of all attributes possible values and Detectors = <I>  2: for all member( m) in Pvalues do 3: if m exists in protected data then 4: do nothing 5: else 6: Insert m in Detectors.

7: end if 8: end for  Algorithm 2b Monitoring protected rules  I: if a rule exists in Detectors then 2: Reject rule 3: else 4: Continue 5: end if    where:  Figure 2. Monitoring of protected rules  then recalculate support and confidence of mutated solutions.

The main steps of the quantum-based rotation Q-gate muta? tion are described in algorithm 3.

Algorithm 3 Mutation process  I: for each cell i E Cs do 2: Let j = be a selected randomly item from cell i  where:  [aj] =  [COS( B) (3j cos( B)  Bj is the rotated angle  - sin( B)] [aj] sin (B) (3j  Bj = arctan ((3j ).

aj  3: Given itemset Sj of possible values:  Sj = {iteml, item2, ... itemL}  where: L = size( Sj) 4: while L > 1 do 5: r=U(O,l) 6: if r < (a?)2 then 7: Sj +-- Sj{l : lL/2J} 8: else 9: Sj +-- Sj{lL/2J + 1: L}  10: end if 11: L = size(Sj) 12: end while 13: selectedj = Sj{l} 14: end for  (5)  (6)  (7)  (8)  (9)  D. Pruning Process  In this process, covered rules by the memory set rules are pruned to insure that those covered rules will not be exist in the coming generations and reduce complexity by eliminating redundancy.

Pruning Criteria: Rule R* : itemset* =} c is covered by rule R : itemset ===} c. If the following two conditions are satisfied:  1) itemset C itemset*and 2) Confidence value of R is Greater than or equal R*.

E. Reselection process  We reselect from memory set randomly to form the new population . The memory set contains the best uncovered rules with highest affinity value so the next generation will converge to the optimal solutions.



IV. EXPERIMENTAL RESULTS AND DISCUSSION  The proposed algorithm is implemented and evaluated using two benchmark datasets Adult, Nursery, Iris and Breast-Cancer from the DCI Machine Learning Repository [22]. Each record regards as an immune cell and each item has a predetermind possible values stored in item sets pop? ulation. The obtained results are compared with experiment implementation result of AIS-AC algorithm [ 13].

In mutation process , a point (item, value) is picked to mutate. Getting the "item" which is equal to the itemset population name and get a possible value from its item? sets population. The search criterion is the high value of affinity which is regarded as the algorithm compass. AIS is essentially based on the mutation operator so it can achieve a diverse number of local optima.AII experiments are performed within 70 % minimum confidence (minCon? fidence) and minimum support values (minSupport) are % 10 ,%5,%2.5,%0.6.

A. Affinity Analysis  The affinity of the proposed Q-NSA are analyzed and visualized for all datasets. Figures 3 show the obtained average affinity values at various support values for Nursery, Iris, Adult, and Breast-Cancer datasets. As shown in figure 3 the average affinity growth rate is increased through generations. For Nursery in figure 3 the affinity value is improved through runs and achieve good evolution and average affinity is between 0.91 and 0.99 so we have a small interval and small growth rate, but when the support value decreased the growth rate is increased since the lower support value will get small confidence value so the growth will be clear.

For Iris dataset in figure 3, it is noticed that the affinity value is improved through runs with different support values and the average affinity value is between 0.95 and 0.99. The algorithm in Iris dataset explores the search space faseter    NUf5erv Affinity Anilllrsis  0." .J-----...... -ri1trltH-H .=o.9S  ?O_t7 +-+H1+1-1I-HH-IfH-H-tff 0." Hlll-l+lI-HH-IfH-H-t+t-lt-H-I 0.9S .......... ? ......... .,.,.,.?.,.,..,.,.,.o' ...

Gl GS G5 G1 G9 Gt1GH G1SG17G19 GelllCflltiOR  IriiA.lrini.yAn? l yii .'l 0.986 ?------- 0 ... +---------;? OSS2  ?? ? +-??H+??+I-I? iii 0." +-r.,.,-l?H+ .... ?+I_IH- il(OS7ti  0.974 If+Hf+f-l+l-lI+l-Hf+t-l? 0972 -lI-I-1-U4+l-l+lI-H-Hf+t-lcf . .. ,  Gl GJ, G5 G1 G9 Gl1GB G15G17G19  <ielW:fJCiO'"  Adutt: AHlnity Ana l ysis 0.767 T'-------  ?.;::- .. 0.764 ? o.,., .. 0.762  0.'61 .,.

O.'?9 .

Gl Gl GS G7 G? Gl1GHG1SG.17G.U  GcncfatiDrl  B?t,,=:" ,:=, ? c=:":=n.,,=,::::Aff ::::ln:=I'Y::::An="::::IY=II ,=;:;: 018' 0815 j ???  .. 0.JI75 ,,=0.JI7 ? O .ll 65  ....

01lSS ....

0.145 .jI,J.,1,ll,.J.&,Jy.,.o,.,.,...,.,.,..,.......,.., Gl G3 G5 G1 (ig Gll G13G15G11G1'  6eMfMkWll-  Figure 3. Affinity analysis  Table I ACCURACY VALUES NURSERY AND IRIS DATASETS  Support  O.l 0.05 0.025 0.006 0.003  Nursery Dataset II Iris Dataset AIS-AC NSA  0.9 0.99 0.91 0.99 0.92 0.99 0.97 0.99 0.98 1  II AIS-AC 0.92 0.92 0.92 0.91 0.92  NSA  0.95 0.95 0.95 0.95 0.94  than any other dataset since the small size of data so it is clear that the lowest value of average affinity is 0.95.

For Adult dataset in figure 3, it is noticed that the affinity value is improved through runs with different support values and the average affinity value is between 0.75 and 0.76.

In Breast-Cancer dataset in figure 3, the affinity value is improved through runs with different support values and the average affinity value is between 0.8 to 0.88.

B. Accuracy Analysis  Suppose the accuracy when a rule R : itemset ===} c is used to predict the class label of a transaction T is the probability of which c is the class label of the transaction that contains the itemset iset [ 13]. Accuracy is calculated  Table II ACCURACY VALUES FOR ADULT AND BREAST-CANCER DATASETS  Adult Dataset Breast-Cancer Dataset Support  AIS-AC NSA AIS-AC NSA  0.1 0.74 0.76 0.68 0.79 0.05 0.77 0.79 0.67 0.79 0.025 0.77 0.74 0.65 0.74 0.006 0.70 0.73 0.66 0.74 0.003 0.72 0.73 0.68 0.74  by:  a I aei  ? .-- 1-  a.?  Figure 4. Accuracy analysis  f- I-  l- I- 1,- I-  DS. o. ?5 .........

dJ  accuracy(R) = p(c I itemset)  - I- I-  D.DOJ  Now, the probability of which c is the class label of T that contains the item set iset should be calculated. Each transaction T which contains iset can be regarded as a "trial". If a trial belongs to c , then the outcome is "success," otherwise the outcome is "false". The accuracy can then be considered as the probability of success on a random trial [ 13].

Accuracy values of the proposed Q-NSA algorithm are reported and compared with AIS-AC [13] for used datasets in tables I and II, and visualized in figure 4. As shown in figure 4 the accuracy of the proposed Q-NSA is decreasing when the support value is decreasing. For example, when the support value equals O.l, for Iris dataset figure 4(b), the accuracy of Q-NSA is 0.95 and AIS-AC is 0.91; and when the support value of 0.025, the accuarcy will be 0.95 and 0.9 respectively. For Nursery dataset Figure 4(a) when the support value equals 0.1, the accuracy of Q-NSA is 0.98 and AIS-AC is 0.91 but when the support value of 0.006, the accuarcy will be 0.97 and 0.96 respectively.

For Adult dataset Figure 4(c) when the support value equals 0. 1 the accuracy of Q-NSA is 0.76 and when support value of 0.006 the accuracy will be 0.72 but the best accuracy value is 0.79 at support value=0.05.In Breast? Cancer dataset the accuracy will be 0.79 with support value = 0.1. Based on accuracy analysis it is concluded that the accuracy of Q-NSA is better than AIS-AC and is decreasing when support value is decreasing but Q-AIS is decreasing with lower rate, and the proposed Q-NSA dominates the    AIS-AC.



V. CONCLUSION  In this paper, a quantum-negative selection algorithm for associative classification is proposed. It is based on the negative selection algorithm and quantum theory. The proposed algorithm generates association rules efficiently for classification process in a large search space by evaluating discovered rules after each generation and eliminates bad rules from memory set. The Q-gate mutation operator is employed to control diversity of immune cells in the search space and guide the search process. It is able to deal with complex search space of association rules. The proposed algorithm is implemented and evaluated for benchmark datasets and obtained results are compared with results of AIS-AC and showed that the proposed algorithm is performed well and has significant accuracy and average affinity values. For further research , detectors generation process can be enhanced and also monitoring strategy can be modified or further analyzed as well as more experiments.

