?

Abstract? Current trends in health management  improvement demand the standardization of care protocols to  achieve better quality and efficiency. The use of Clinical  Pathways is an emerging solution for that problem. However,  current Clinical Pathways are big manuals written in natural  language and highly affected by human subjectivity. These  problems make their deployment and dissemination extremely  difficult in real practice environments. Furthermore, the  intrinsic difficulties for the design of formal Clinical Pathways  requires new specific design tools to help making them relly  useful and cost-effective. Process Mining techniques can help to  automatically infer processes definition from execution samples  and, thus, support the automatization of the standardization  and continuous control of healthcare processes. This way, they  can become a relevant helping tool for clinical experts and  healthcare systems for reducing variability in clinical practice  and better understand the performance of the system.



I. INTRODUCTION  A. The Problem  Medical Knowledge and clinical guidelines are typically developed and agreed upon by medical community per disease. When such guidelines are defined, there is a significant effort spent to understand how to map and adjust them per patient into an executable care plan. In complex scenarios such as the case of multimorbid conditions, the whole patient condition needs to be considered and treatment should focus on a common pathway, rather than isolated parallel treatments (e.g. symptom relief drugs) for each disease.

The main difference between Clinical Guidelines and Clinical Pathways is the application environment. While the Clinical Guideline is mainly focused on the definition of general recommendations about care, treatments and diagnosis, Clinical Pathways are specifically designed to coordinate the actors involved in the care and management processes in an explicit way. Integrated Care Pathways (ICPs) provide a template for multi-disciplinary care that is evidence-based and coordinated, normally agreed locally by the involved agencies, based on guidelines and evidence where available for a specific patient group [1].

*Research co-funded by the 7th Framework Programme of the European  Commission in the framework of the HeartCycle project.

T.M, V.T, S.G. and J.B. are with the Universitat Polit?cnica de  Val?ncia, Spain (phone: +34 963877606; fax: +34 963877278; e-mail:  tmeneu@upvnet.upv.es, vtraver@itaca.upv.es; sguillen@itaca.upv.es)  B.V. is with Instituto de Investigaci?n Sanitaria La Fe of Valencia,  Spain (e-mail: valdivieso_ber@gva.es)  Pathways have been traditionally designed to be executed by human actors so they usually lack from a formal specification that enables the use of computerized system.

Normally, they are represented as a flow diagram, a plain text or as a document template that health professionals follow and fill in. But their execution using computers requires them to be formally specified first, and one of the major problems that this brings out is the need for a representation format that is able to adequately model the process.

In the area of integrated care, the challenges of defining and modelling the care plans and pathways that represent the actual process are even more complex. Current care processes are normally defined per disease, just including basic screening about major comorbidities, they normally don?t apply to more than two care levels and they mostly forget social or informal care. Additionally, there is limited understanding, beyond exchanging discharge reports or summaries, of what data that should flow with the patient across the different settings and how to handle shared care transversely to those bridges.

Process specification languages need to be expressive enough and easy enough to be used directly by the experts in the different health areas to model the real health and social care models in a formal way. Traditionally, this translation has been made by ICT professionals (who are not expert in care processes) who, when interpreting complex health processes may introduce errors. To deal with this, deployments that use computer interpretable clinical pathways are gaining popularity [2],[3],[4]. There are attempts to standardize care using knowledge-based systems such as GLIF [3],[5] Asbru [6] or ProFORMA [7], which represent medical knowledge in a declarative way, defining rules that describe the process. Nevertheless, its execution is complex [8] and requires additional advanced technical skills that doctors are not familiar with, to be effectively used.

Another critical issue to take into account in relation to healthcare processes representation is the difficulty of their design. Namely, to standardise clinical pathways and adapt them to a particular healthcare context, a high amount of iterative discussions with multiple experts are required to achieve a consensus. It is also common that the consented pathways do not exactly represent the pathway of a particular patient due to his specific characteristics and the associated multimorbidities. And this situation only gets worse when multiple professionals and care agencies are involved, as it?s usually the case of integrated carepathways.

Heart Cycle: Facilitating the Deployment of Advanced Care  Processes  T. Meneu, V.Traver, S.Guill?n, B. Valdivieso, J. Bened?, Member, IEEE, C. Fern?ndez-Llatas,  Member, IEEE    Osaka, Japan, 3 - 7 July, 2013       B. The Hypothesis  Thus, this complexity in the definition and representation of multidimensional healthcare processes is often a huge barrier in relation to the acceptance and the penetration of computerized healthcare processes in real healthcare settings.

In order to tackle this problem, we believe that process mining technologies[9] have the potential to generate a disruptive change in the applicability and usefulness of computerized care processes. They can be used to automate the learning process to build up computer-assisted tools helping ?clinical pathways experts? to design and deploy standardized care protocols in real practice. The significant deployment in healthcare organizations of electronic health records (EHR), hospital information systems (HIS), personal health records (PRH) and other computer based decision support and care management systems represent a great opportunity for the development of process mining techniques able to improve how technologies positively influence health care processes.

Process Mining algorithms are created to infer Workflows from real execution samples gathered from workflow execution systems. Applying this paradigm to the clinical pathways design problem, it will be possible to infer formally defined Workflows representing the real protocols executed in real environments, using the data acquired from the healthcare information systems. These Workflows can be used to help designing and executing Clinical Pathways with more accuracy and ensuring a better alignment with the real care process. Thus, we believe that process mining techniques, applied in an information technologies (IT) intensive care scenario, have the potential to generate the following effects:  x Enable the reconstruction of the real process and its comparison to the designed one. This will allow to identify misalignments between design and real execution and assess variability in real practice.

Further analysis of population data, frequency of pattern variations and clustering of the different reconstructed patterns can also provide valuable information about the reasons behind the variability.

x Facilitate the design process, by highlighting missing patterns or changes in priorities that were not incorporated by the medical experts in the original designs. Eventually, some processes could be directly designed based on the workflow schema built by the process mining tools, and just validated in a second iteration with the care experts.

x Realize simple and automatic mechanisms to gather information to feed a continuous quality management procedure. An automatic monitoring framework could be established including threshold and quality control indicators relating not only to aggregated or individual data but also taking into account the process dimension.



II. METHODS AND MATERIALS  A.Clinical Workflows  Healthcare processes are complex and their representation in a workflow form would require a very efficient workflow engine that supports the execution of multiple instances. Workflow Engines allow the interpretation of workflows through computer based systems.

These are software tools able to understand workflow languages in order to automatically execute them. The majority of current workflow languages are associated to a specific Workflow engines (e.g. Drools, Windows Workflow Foundation, TPA Engine). On the language side, there are also different available options according to requirements of expressivity, understandability and complexity. Some of the most common commercial workflow representation languages such as Business Process Modeling Notation(BPMN), XML Process Definition Language (XPDL), or Business Process Execution Language (BPEL)[10], offer simplicity and are context free but, at the same time, provide no support for highly complex patterns.

On the other side, theoretical workflow languages frameworks like Timed Parallel Automaton (TPA)[11], Finite Deterministic Automaton[12] and Petri Nets[13] are either more complex to understand or have a regular grammar complexity (in relation to execution)[11], but they normally enable more expressivity and complex patterns.

B. Process Mining  In order to optimize the deployment of clinical processes, care managers need to have a clear understanding of the status and the performance of the process. However, strong performance indicators of real execution are not easily obtained. This is especially true due to the large amounts of data that needs to be analyzed, as the data is distributed in different databases and in a heterogeneous way, making it very difficult for health professionals to adequately understand them.

The pattern recognition paradigm [12] can be used to collect and summarize the information by creating indicators to support physicians in the understanding of the real deployment of care protocols and the performance of the care process. However, in order to allow to go one step further from the overview provided by classical pattern recognition techniques, a much comprehensive understanding of the real processes deployment is needed.

To enable this, the implementation pattern recognition algorithms that allows a human understandable presentation of the process deployment is required. In fact, it is demonstrated that the use experts in the middle of the pattern recognition process improves significantly the accuracy of the models [8]. Therefore, the use of pattern recognition models that represents the whole process in an expert understandable way constitutes an accurate way to support care optimization processes. Process Mining technology [12] has been developed specifically to deal with this problem.

Process Mining technology aims to infer the graphical representation of processes from the log traces that the processes leave in their executions. However, classical       Process Mining algorithms (Event-based [12]) are not able to fulfill the needs of clinical protocols because they do not use the results of activities as variables for the transitions in the process [13]. To solve that problem, a Process Mining algorithm called PALIA (Parallel Activity Log Inference Algorithm) was presented [13]. PALIA follows an Activity- Based strategy, which means that use activities with results to model state transition models. PALIA is able to infer workflows with very complex patterns. This system has been tested with simulation corpus [13] and with real data to infer human behavior [14]  C. Evaluation Scenario  After the simulated validation of the performance of the PALIA algorithm, the subsequent step focused in its application to a real scenario, where a real process could be modelled and the casuistic from real executions would be analyzed. The selection of the evaluation scenario was made taking into account two main considerations:  1. The process needed to be sufficiently supported by IT and the data from the actors participating had to be available and accessible in an electronic format.

2. As the objective was to make an assessment of the algorithm?s main capacities when dealing with real data, the selected initial process was not too complex in clinical terms, in order to enable a limited amount of variability in the practice so that monitoring mechanisms can be deployed to compare the real situations with the information extracted from PALIA.

These two assumptions would enable an easier assessment of the algorithm?s performance and provide mechanisms to improve its characteristics or the way it?s been deployed before moving towards a totally uncontrolled scenario. The environment selected to perform the validation of the process mining algorithm was the integrated chronic disease management service of the Hospital La Fe in Valencia (Spain).

This service is, at the moment, undergoing a clinical research trial for assessing remote monitoring technologies for management of complex chronic conditions. The process is fully IT supported and includes multiple stakeholders.

However, being part of a clinical trial, the developed protocols are known and professionals are purposely required to reduce variability. Once the trial has finished in the end of 2013, the service will be fully deployed in the real portfolio offer of the hospital, so the validation exercise of PALIA could be extended in a second iteration. This way, the first step will enable us to validate the functional characteristics of PALIA in a nearly controlled environment and the second one will allow the evaluation of the potential impact of the algorithm in real life. The possibility to do the two assessments sequentially and in the same scenario will reinforce the strength of the comparisons and provide important insights about the powerfulness of the developed tools.

Once the overall scenario and framework was selected, the boundaries of the process to be modelled were selected  and the main data collection points were identified. In this case, the selected process was the remote monitoring branch of the clinical trial, starting with a risk stratification protocol to identify the patients inside the health department populations with a higher probability of suffering from a relapse, a decompensation or an exacerbation that requires the consumption of high cost healthcare resources (intensive care, hospitalization, emergency). The second step in the process relates to specific training provided by a specialized nursing team (home hospitalization team) at the home of the patient and the configuration of the monitoring equipment.

The final phase follows the patients for a minimum length of one year and deploys a specifically designed protocol of monitoring and intervention based on a collaborative care plan that includes actors from primary care, specialized care, case managers (specialized nurses) and other nursing teams.



III.  RESULTS  A. Technologies and Data Sources  The selected process is supported by different IT modules and systems that will be capturing the data that will be used for the evaluation:  NOMHAD CHRONIC?[15]: innovative system designed to support the deployment of integrated services for comprehensive chronic patients management, based on remote monitoring technologies.

ORION CLINIC: Integrated information system of the hospital. This HIS constitutes a comprehensive platform including the clinical, the health management and administration dimensions.

ABUCASIS: IT system for the outpatient and primary care, integrated into one unique patient record. This system includes management of appointments, access to EHR, screening and risk stratification and decision support for primary care care-plans.

GAIA: IT system collecting the data from medication prescriptions for the patients, from the doctor?s office to the pharmaceutical delivery in the pharmacy.

B.  Data Collection  Data will be acquired from the different IT modules involved in the target care processes, without disrupting the activities of the clinical trial. To do so, several data capture milestones have been set in order to capture and analyze data in the different interim evaluation points defined in the protocol. No additional data collection activity has been defined, but the corpus will be constructed using just the data automatically acquired by the different information systems.

In this framework, the following data sources have been identified:  x NOMHAD CHRONIC ? Patient and professional?s databases and system log.

x ORION CLINIC ? Extract from patient?s and professional?s databases.

x ABUCASIS - Extract from patient?s and professional?s databases.

x GAIA ? Extract from patient?s medication prescriptions.

This way, the workflow reconstruction process has been made using heterogeneous data sources, better testing the robustness of the designed algorithm. The data has pre- processed on a preliminary state to match a common format that can be directly understood by PALIA. The idea will be that, in the future, an automatic formatting plug-in will be created to ensure that the algorithm can feed from the real data without the need for human processing of the data.

The first monitoring point included the initial beta testing of the healthcare process before the start of the clinical trial.

These testing databases were analyzed in order to ensure that the mapping of the data collection points were appropriated for the desired purpose. In this first step, data from one month test of 10 patients, including daily monitoring and participation of all the professional stakeholders has been analyzed.

The second monitoring point will be made in February 2013, according to the directions of the clinical trial. In this point 6 months follow-up of 30 patients will be analyzed, The final group will be composed by 90 patients with a one year follow-up. Once the clinical trial has finished, the researchers will have access to all the acquired data, thus, more progressive data analysis could be done to trace the evolution in the variability of the care processes along the time.

C. Preliminary Data Analysis  The data analysis of the first beta-testing period highlighted the capacity of the PALIA algorithm to reconstruct the real process in a realistic way, providing a feasible picture of the modelled processes for each of the patients. As the number of patients in the first iteration was reduced, the PALIA results were compared individually to the real processes, using the available data and carrying out personal interviews with the involved health professionals and matching it with the data reported in the hospital information systems or in the medical record. This exercise enabled the preliminary validation of the inference capabilities of the algorithm for a limited amount of events.

Due to the short duration of the evaluated process, the variability in the practice was not present, so this dimension could not be traced. However, this first step proved to be extremely useful to validate the reconstruction feature of the PALIA algorithm in advance of the more complex evaluations of its potential that will be made in the subsequent validation steps. In relation to the data processing, the data extraction from the different data sources didn?t pose any huge difficulty and a minor adjustment was made in the algorithm in order to better fit the data characteristics of the data corpus. The development of the automatic formatting plug-in has started in order to facilitate the posterior phases of evaluation.



IV. CONCLUSIONS & FUTURE STEPS  The first stage of evaluation of the performance of PALIA algorithm has demonstrated the advanced capacities of the technology for the reconstruction of a real care process. However, to evaluate its full potential, a more detailed analysis of longer term data will be done in 2013. In relation to the ease of use, PALIA has been applied to four different data sources, from different technology providers and has been able to interpret both system logs as well as system databases. These results generate an extremely positive feedback in relation to the validation of the initial hypothesis.

