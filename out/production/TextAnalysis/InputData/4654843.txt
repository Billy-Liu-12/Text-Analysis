- 1214 -

Abstract? propose an efficient data mining system for making quick response to users and providing a friendly interface. When data tuples have higher relationship, it could contain long frequent itemsets. If apriori algorithm mines all frequent itemsets in those tuples, its candidate itemsets will become very huge and it has to scan database huge times. Meanwhile, the number of rules mined by the apriori algorithm is huge. Our method avoids mining rules through huge candidate itemsets, just mines maximal frequent itemsets and scans the database for the frequent itemsets users are interested in. First, use GA to mine the maximal frequent itemsets and show them to users. Second, let users pick up one to deduce the association rules. Final, scan the database for the real support and confidence and show them to users. So, our method can not only save many times scanning the database and make quick response to users, but provide a friendly interface that let users select his interesting rules to mine.



I. INTRODUCTION Data mining, which is also referred to as knowledge  discovery in database, means a process of nontrivial extraction of implicit, previously unknown and potentially useful information (such as knowledge rules, constraints, regularities) from data in database[1]. The knowledge mined is always expressed by using association rule.  An association rule is a rule which implies certain association relationships among a set of objects (such as ?occur together? or ?one implies the other?) in a database [2]. The association rule mining generally can be viewed as a two-step process: find all frequent itemsets and generate strong association rules from the frequent itemsets.  The first step is a major challenge and such mining often generates a huge number of itemsets satisfying the minimum support (min_sup) threshold, especially when min_sup is set low. This is because if an itemset is frequent, each of its subsets is frequent as well [3].

Apriori algorithm, proposed by Agrawal et al. [4] [5], is a popular method mining frequent itemsets. It starts from candidate 2-itemset to candidate k-itemset, scans the database for obtaining the support count of these candidate itemsets and extracts all the frequent itemsets satisfying the min_sup.

Wenxiang Dou Jinglu Hu Kotaro Hirasawa are with the Graduate School  of Information, Product and Systems, Waseda University, 2-7 Hibikino, Wakamatsu, Kitakyushu-shi, Fukuoka, 808-0135, Japan  william@ruri.waseda.jp, jinglu@waseda.jp and hirasawa@waseda.jp Gengfeng Wu is with the Graduate School of Computer Engineering and  Science, Shanghai University, Shanghai200072, P. R. China.

gfwu@shu.edu.cn    But when the tuples have higher relationship, it could contain long frequent itemset containing many items. If apriori algorithm mines all frequent itemsets in those tuples, its candidate itemsets will become very huge and it has to scan database million times or ten million times, or even more than hundred million times. So we call this low efficient problem of apriori algorithm. The primary reason of the low efficient problem is that the mining process is executed on huge candidate itemsets. Meanwhile, the number of rules mined by the apriori algorithm is huge and these rules are rough.

Therefore, several algorithms have been proposed for finding the ?best?, ?optimal?, or ?most interesting? rule(s) among these rules mined according to a variety of metrics including confidence, support, gain, chi-squared value, gini, entropy gain, laplace, lift, and conviction [7] [8] [9] [10] [11].  But these interesting rules are just subjective opinions of authors and they can not reflect the real demands of users, because users maybe want to select the pattern of rules they are interested in.

For solving the above two problems about the low efficiency and the real demanded rules, we propose a quick response data mining method. Our method avoids mining rules through huge candidate itemsets, just mines maximal frequent itemsets and produces rules after users select their interested maximal frequent itemsets, and scans the database for obtaining real support and confidence of these rules.  Due to adopting the global searching character of genetic algorithm (GA), we can use GA to mine the maximal frequent itemsets in set time or set number and show them to users.

Thus, we can make quick response to users in short time.

After, we let users pick up one to deduce the association rules.

Thus, we will produce the real demanded rules. Final, scan the database for the real support and confidence and show them to users.

So, our method can not only save many times scanning the database and make quick response to users, but provide a friendly interface that let users select his interesting rules to mine.

The remaining of the paper is organized as follows. In Section II, we describe the basic ideas of the quick response data mining model. Section III introduces our GA and illustrates its application in finding maximum frequent itemsets. Section IV gives the experimental results. Section V is the conclusions and the future work.



II.  QUICK RESPONSE DATA MINING  A. The Idea of Quick Response  Quick Response Data Mining Model Using Genetic Algorithm Wenxiang Dou, Jinglu Hu, Kotaro Hirasawa and Gengfeng Wu  SICE Annual Conference 2008 August 20-22, 2008, The University Electro-Communications, Japan  PR0001/08/0000-1214 ?400 ? 2008 SICE    - 1215 -     As above mentioned, the primary reason of the low efficient problem is that the candidate itemsets are huge when data tuples contain long itemsets, because a long itemset will contain a combinatorial number of shorter, frequent sub-itemsets. For example, a frequent itemset of length 100,  such as {a1, a2, ? , a100}, contains ( )1001  = 100 frequent 1-itemsets: a1, a2, ? , a100, ( )1002  frequent 2-itemsets: (a1, a2), (a1, a3), ? , (a99, a100), and so on. The total number of frequent itemsets that it contains is thus,  ( ) ( ) ( )100 100 100 100 301 2 100... 2 1 1.27 10+ + + = ? ? ? This is too huge a number of itemsets for any computer to compute or store [3].  Even apriori algorithm will mine rules on candidate itemsets containing such huge a number of itemsets, so it is very low efficiency when data tuples contain long itemsets. Meanwhile, the number of rules produced is huge and most of rules are no higher price. We just need these rules users are interested in. So, for overcoming the low efficient problem and obtaining real demanded rules, we propose a novel idea of quick response data mining. Before illustrating our idea, we have to express a concept about maximal frequent itemset. An itemset X is a maximal frequent itemset (or max-itemset) in set S if X is frequent, and these exists no super-itemset Y such that X  Y and Y is frequent in S.  From the definition of the maximal frequent itemset, we can know all the frequent itemsets, even all association rules are the subsets of maximal frequent itemsets.

According to the character of maximal frequent itemsets, our method just mines the maximal frequent itemsets from data tuples and let users pick up one they are interested in for deducing the association rules from the chosen maximal frequent itemset directly. Then, we obtain the real support and confidence of those association rules by scanning the database and show them to users. So, this method can not only save many times scanning the database, but provide a friendly interface. Because it just scans the database for the demanded frequent itemsets, not for all candidate itemsets, and the number of the maximal frequent itemsets is much less than all frequent itemsets. But, in the first, we have to find maximal frequent itemsets in whole k-itemset space.

Therefore, we combine this idea with GA, because GA can search frequent itemsets in global tuples space. In section 3, we will introduce how the GA to find the maximal frequent itemsets. Though GA can not find all the maximal frequent itemsets, GA can stop in any time and start from the stop point. So, we use GA to mine the maximal frequent itemsets in set time or set number and show them to users. If users want more maximal frequent itemsets, then continue the mining process.  This is our idea of quick response data mining using GA.

In the following we will propose the system architecture of quick response data mining using genetic algorithm based on our new idea and introduce its flow process.

B. Quick Response Data Mining Using Genetic Algorithm In this phase, we will introduce the quick response data  mining system (QRDM). This system consists of two major sections. One is in charge of mining maximal frequent itemsets by using GA. Another is to deduce the association rules in terms of maximal frequent itemsets and scans the database for obtaining real support and confidence of those rules. Figure 1 shows the system architecture of quick response data mining using GA.

The flow of the system is as follows: 1. Find maximal frequent itemsets using GA, for  example {I1, I2, I3}, {I3, I4, I5} are max-itemsets.

2. Obtain real support count by scanning database and  show them to user.

3. Go to step 1, if user wants more frequent itemsets.

Otherwise, go to step 4.

4. Let user pick up some maximal frequent itemsets he is  interested in to deduce the association rules, for example, we can get (I1, I2 => I3), (I1, I3 => I2), (I3, I4 => I5), ? , from {I1, I2, I3}, {I3, I4, I5}.

5. Obtain real support and confidence of rules by scanning database, for example, (I1, I2 => I3) (0.1)(0.4), (I1, I3 => I2) (0.1)(0.8), (I3, I4 => I5) (0.2)(0.8), ?  6. Show them to user.

7. Go to step 3, if user doesn?t want to quit the system.

Otherwise, end.

Therefore, the QRDM system can not only make quick  response to users in short time, but also produce the rules that are really demanded by users. In next section, we will present our GA and its application of mining maximal frequent     Fig. 1.  System Architecture of Quick Response Data Mining Using    - 1216 -      Fig. 2.  Individual of GA with the min_sup being 4  1 2 3 4 5 1 0 1 1 0 0 2 0 1 1 1 0 3 0 0 1 0 1 4 1 1 1 1 0 5 0 1 1 1 1  I I I I I T r a n s T r a n s T r a n s T r a n s T r a n s     Fig. 3.  Example of the Transaction Records  itemsets.



III. MINING MAXIMAL FREQUENT ITEMSETS USING GA  A. Genetic Algorithm with Modifications As mentioned in the previous section, for mining maximal  frequent itemsets from data tuples directly, we need an effective algorithm that can search itemsets in whole k-itemset space. GA, which is one of the evolutionary computation techniques, has powerful ability of global search and optimization [15] [16]. Thus, we use modified GA to mine the maximal frequent itemsets in data tuples space.

Most existing methods judge whether some itemset is frequent through obtaining its real support count and comparing it with the min_sup. But these methods have to scan the database for every itemset. Our GA, judging the itemset whether it is frequent, doesn?t need to scan the database. We just need to know some k-items subset of data tuples (k is min_sup) whether its each transaction contains some itemset. If it's true, then the itemset is frequent because its support at least satisfies the min_sup. Therefore, our individual of GA is different with the traditional GA. Figure 2 shows the individual structure of our GA with the min_sup being 4.

Individual: the individual consists of transactions that  have the different transaction ID and its size is equal to the min_sup. Each transaction will be viewed as a chromosome and the transaction ID will become the identity number of each chromosome. If some itemset appears in each chromosome of the individual, we say it is frequent and extract it because its real support at least satisfies the min_sup.

Fitness: If some individual can produce a frequent itemset, then the number of items in the frequent itemset is the fitness of the individual, otherwise the fitness is 0. For example, the fitness of the individual in Fig.2 is 2.

But these frequent itemsets produced by the individuals are not all the maximal frequent itemset. After executing heuristic genetic operators of every generation, we have to  filter for getting the current maximal frequent itemsets. In the following phase, we will introduce the initialization of the group, definition of some parameters and genetic operators of GA.

B. Initial Individuals Selection For most genetic algorithms, a random policy is adopted to  initialize individuals. But, for our problem of rule-mining, the individual that cannot get a frequent itemset is useless and a random police maybe produce many useless individual. So, we will use a special method to initialize individuals for avoiding producing this kind of individual.

In apriori algorithm, the frequent one-item set is the foundation for producing the latter frequent n-items sets. So, we initialize individuals from these transaction sets that can extract frequent itemset containing at least one item.

For example, let us see Fig. 3. Ii (i=1?5) denotes some  item and Transj (j=1...5) denotes some transaction. If Ii appears in Transj, then we write 1 in the ith column of the jth row. Otherwise, we write 0.

Therefore, the frequent one-item set satisfying the minimum support 60 percent is (I2, I3, I4), and the transaction sets containing these items are respective (Trans1,Trans2,Trans4,Trans5),(Trans1,Trans2,Trans3,Tra ns4,Trans5) and (Trans2,Trans4,Trans5). So, the individuals will be initialized among these transaction sets. In this examples, the individuals will be (Trans1,Trans2,Trans4) (Trans5,Trans1,Trans2)(Trans1,Trans2,Trans3)(Trans4,Tra ns5,Trans1) (Trans2,Trans4,Trans5). So, this method can produce better groups for the latter genetic operation.

C. Parameter Definition Before introducing the genetic operators, some parameters  should be explained  because they will be used in the latter operation. Let us use (Trans1,Trans2,Trans3) as an individual to illustrate these parameters (See Fig. 3).

Individual Identity (IVI), consists of the symbols of chromosomes in the individual. Every chromosome has a unique symbol that is the ID of the corresponding transaction.

This can distinguish these individuals. For example, the IVI of the individual (Trans1,Trans2,Trans3) is (1-2-3).

Individual Fitness (IVF), is the number of items contained by the rule of the individual. It means that if the individual cannot extract a frequent itemset, then IVF is 0, otherwise, IVF is the number of items. For example, because    - 1217 -     the individual (Trans1,Trans2,Trans3) can extract frequent itemset (I3), so the IVF is 1.

Upgrade Index (UI), shows a distance for getting or expanding the frequent itemset of the individual, and is denoted by a negative number. The larger the value of UI is, the more possible the frequent itemset is got or expanded through using genetic operators.

For example, the individual (Trans1,Trans2,Trans3) can extract frequent itemset (I3). But if I2 also appears in Trans3, the individual can expand the frequent itemset as (I2, I3). So, the UI of the individual is -1. About the individual (Trans2,Trans4,Trans5), can extract frequent itemset   (I2, I 3, I4). If I1 can appear in Trans2 and Trans5, the individual can expand the frequent itemset as (I1, I2, I3, I4), So, the UI of the individual is -2.

Upgrade Genes (UG), is set of genes (items) needed by the individual for enhancing the UI. In most situations, we want to know not only whether the individual can produce the frequent itemset, but also which genes contained by these chromosomes influence the frequent itemset to be produced or expanded. So, the UG can help us to answer the question.

Let us see the above example. For the individual (Trans2,Trans4,Trans5), if we can find some transaction containing { I1, I2, I3, I4} to replace the Trans2 or Trans5, or transaction containing { I2, I3, I4, I5} to replace the Trans2 or Trans4, the UI of this individual will become -1. So, the UG of the individual is the set of {I1, I5}. When the value of UI reaches 0, it means the individual gets or expands the rule and the UI will be reset.

In the next phase, we introduce how to execute the genetic operation by using these parameters.

D. Genetic Operators Our genetic operators are like a standard GA including  selection, crossover and mutation, but the implementation is different. Our objective is to find the individuals containing the frequent itemset as more as possible and obtain the current maximal frequent itemsets through filtering. Therefore, we adopt heuristic genetic operators to search better individuals by using the above defined parameters. In addition, initial individuals will be as the reserved group and not attend the selection and mutation, because they contain all the information of transactions. Let us see the following genetic operators.

Selection: For getting current maximal frequent itemsets, we extract all the individuals whose value of IVF is larger than 1 and just retain the individuals containing the maximal frequent itemset through filtering operation. During the selection, for making each individual be unique, we exclude the individuals that have been selected according to the value of IVI.

Crossover: Our crossover operation will retain the parents.

There are two crossover strategies: One is the random crossover that exchanges chromosomes owning different ID for producing two new individuals between parents randomly.

Another is the heuristic crossover that checks whether there  are some appropriate chromosomes in a parent that can make the UI of another parent enhance through replacing operation (See the definition of UG). If this kind of chromosomes exists, we produce a new individual by replacing other chromosomes of another parent. The purpose of the random crossover is to keep the diversity of the group and the heuristic crossover is to obtain more new frequent itemsets quickly. We pair the individuals randomly and adopt the two strategies for every pair.

Mutation: adopts heuristic mutation operation. It excludes a transaction that has low relative to other transactions of an individual and replaces that transaction with another transaction that is selected from all tuples randomly. We use UG of the individual to judge which transaction has lower relationship. The mutation probability will be according to the value of UI. The larger the value of UI is, the more possible the individual takes place the mutation. The objective of the mutation is to find more new frequent itemsets.

After executing heuristic genetic operators generation by generation in set time or set number of itemsets, we can get some current maximal frequent itemsets.



IV. EXPERIMENTS For our experiments, we produce a single table randomly.

The table consists of 100 transactions and the attribute is the items from I1 to I40. Each transaction contains 24 items in the average.

The minimum support is set 10% and the minimum confidence is set 50%. We set the stopping number of maximal frequent itemsets be 500.

Figure 4 shows the generations and the number of the maximal frequent itemsets (max-itemsets) during the mining process of GA.

Fig. 4. The number of max-itemsets and generations    - 1218 -                             Table I shows the experimental results of the max-itemsets mining by using GA and apriori algorithm respectively.

Figure 5 shows the part result of the quick response mining by using GA.

From the experimental result, we can see that the proposed method can make quick response to users in just about ten seconds, while apriori algorithm spent 979 seconds on mining all frequent itemsets and 2502 seconds on filtering for obtaining max-itemsets. Though GA could not find all max-itemsets, GA can continue to mine new max-itemsets from stop point. Meanwhile, it lets users choose their interested max-itemsets for showing the real demanded association rules to them.



I. CONCLUSIONS In this paper, we propose a new data mining method in  order to overcome the low efficient problem and provide users with real demanded rules. Our approach has two novel points:   One is the idea of quick response mining by using GA.

Another is the friendly user interface that can let users make the selection by themselves and provide the real demanded rules. In our experiment, the GA based quick response data mining method can make a quick response to users in short time and users can select their interested frequent itemsets for mining demanded association rules. Therefore, our method can reduce larger mining time than the apriori algorithm.

Meanwhile, unlike the most traditional methods producing huge amounts of association rules which contain many low price rules, our method provides users with less and real demanded association rules.

In the future research, we will apply our method to the network data mining with large data, and combine it with other method for mining multi-relation data.

