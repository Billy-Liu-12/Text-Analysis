A Combination of Positive and Negative Fuzzy Rules for Image Classification Problem

Abstract  In this paper, we propose a new fuzzy rule-based system for application in image classification problem. Each rule in our proposed system can represent more than one class.

While traditional fuzzy systems consider positive fuzzy rules only, in this paper, we focus on combining negative fuzzy rules with traditional positive ones leading to fuzzy infer- ence systems. This new approach has been tested on image classification problem consisting of multiple images with excellent results.

1 Introduction  Image classification has found widespread applications in image processing and image recognition systems. A cor- rect classification result provides more information for fur- ther diagnosis. However, images easily get corrupted with noise. Therefore it is not an easy task to classify an image when it is significantly degraded by noise. In the last few years, there has been a growing research interest in the ap- plications of fuzzy systems to the image classification prob- lems.

In the fuzzy system [1], we can generate fuzzy rule-base with one of the following three types of rules:  (a) Fuzzy rules with a class in the consequent [2], [3].

These types of rules have the following structure:  Rule r : IF x1 isAr1 and...and xN isArN Then y is classCm (1)  where x = [x1, ..., xN ] is an N -dimensional pattern. Arn, n = (1,2,...,N ), is an antecedent fuzzy set, and y is the class Cm to which the pattern belongs.

(b) Fuzzy rules with a class and a rule weight in the con- sequent [4], [5]:  Rule r : IF x1 is Ar1 and...and xN is ArN Then y is class Cm with Wr  (2)  where Wr is the rule weight. It is a real number in the unit interval [0,1].

(c) Fuzzy rules with rule weight for all classes in the con- sequent [6], [7], [8] can be written as:  Rule r : IF x1 is Ar1 and...and xN is ArN Then y1 is class C1 with Wr1 and...and yM is class CM with WrM  (3) where Wrm is a rule weight for class Cm, m=(1,2,...,M ).

From Eq.(1), Eq.(2) and Eq.(3), we can see that a typical rule in the rule base of a fuzzy system contains only posi- tive rules (weight is positive). This is one of the limitations of traditional association mining [9]. In this case, mining algorithms only search for positive associations like ?IF A Then do B?, while negative associations such as ?IF A Then do not do B? is ignored. In addition to the positive rules, the negative rules (weight is negative) can provide valuable in- formation. Interestingly, very few papers have focused on negative association rules due to the difficulty in discover- ing these rules. Although some researchers have pointed out the importance of negative associations [10], only few groups of researchers [11], [12], [13] proposed an algorithm to mine these types of associations. This not only illustrates the novelty of negative association rules, but also the chal- lenge in discovering them.

In this paper, we propose a new adaptive fuzzy system having both positive and negative rules in its rule base.

Moreover, each fuzzy rule in our proposed system can rep- resent more than one class. A scatter-type fuzzy partition is used to generate fuzzy ?IF-Then? rules. This system is applied to the image classification problem. The rest of this paper is organized as follows. The positive and negative association rules and related problems will be presented in Section 2. Section 3 presents the structure of our proposed fuzzy system. Section 4 describes a learning algorithm for inference parameters. The proposed approach studied for image classification problem with different images will be shown in section 5. Final conclusions are given in section 6.

DOI 10.1109/ICMLA.2008.14     2 Positive and Negative Association Rules  Fuzzy systems can be broadly categorized into two fam- ilies. The first includes linguistic models based on collec- tions of fuzzy rules, whose antecedents and consequents uti- lize fuzzy values. The Mamdani model [14] falls into this group. The second category, based on Sugeno-type sys- tems [15], uses a rule structure that has fuzzy antecedent and functional consequent parts.

Generally, in the rule-base of fuzzy system, if we assume A is the premise of the rule and B is the consequent of the rule, a typical rule of the ?IF-Then? type is ?IF A then do B?. This type of rule is called positive rule (weight is positive) because the consequent prescribes something that should be done, or an action to be taken. However, if an action might lead to severe damage, then the action must be avoided. This kind of action is also possible to augment the rule-base with rules in the form, ?IF A, Then do not do B?.

This type of rule is called negative rules (weight is negative) because the consequent prescribes something that should be avoided rather than done.

For instance, let us consider the following two fuzzy ?IF-Then? rules:  Rule 1 : IF customer is a child Then he buys Coke and he does not buy bottled water Rule 2 : IF customer is an adult Then he buys Coke and he buys bottled water  (4) In this example, the negative rule (rule 1) guides the sys-  tem away from situations to be avoided, and after avoid- ing these areas, the positive rules (rule 2) once again take over and direct the process. Depending on the probabil- ity of such an association, marketing personnel can develop better planning of the shelf space in the store or can base their marketing strategies on such correlations found in the data. In some situations [16], [17], [18], a combination of positive and negative rules can form more efficient fuzzy systems.

Another limitation of fuzzy IF-Then rules in Eq.(4) is that these two classes (Coke, bottledwater) appearing in the consequence parts of the above rules have the same degree of importance. Clearly, to help marketing person- nel develop better planning of different products (Coke, bottledwater) for different customers (child, adult), we should assign different weights to different classes appear- ing in the consequence part of the rule.

Based on these considerations, we suggest a new adap- tive fuzzy system that is applied to image classification problem. The main advantage of this fuzzy model is that every fuzzy rule in its rule-base can describe more than one class. Moreover, it combines both positive and negative  rules in its structure. This approach is expressed by:  Rule r : IF x1k is Ar1 and...and xNk is ArN Then yk1 is class C1 with Wr1 and...and ykM is class CM with WrM  (5) where Wrm, r=(1,2,...,R), m=(1,2,...,M ), is the weight of each class of the rule r. We use rule weight of the form below:  Wrm = wrm0 + wrm1x1k + ...+ wrmNxNk (6)  When the rule weight Wrm has a negative value, it will narrow the choices for class Cm (detail in section 3).

The parameters wrml, l=(0,1,...,N ) are determined by least squares estimator, which will be discussed in section 4. R, M , K, N denote the number of fuzzy rules, the number of classes, the number of patterns and dimension of patterns, respectively. Classes will be denoted by C1,C2,...,CM and the N -dimensional patterns will be denoted by xk = (x1k, x2k, ..., xNk), k = (1,2,...,K).

Consider a multiple-input, multiple-output fuzzy system (MIMO) in Eq.(5), similar to Takagi-Sugeno fuzzy models [15], [19], the m-th output of MIMO with product infer- ence, centroid defuzzifier and Bell membership functions is of the following type:  ykm =  R? r=1  N? n=1  Arn(xnk)Wrm  R? r=1  N? n=1  Arn(xnk)  =  R? r=1  ?r(xk)Wrm  R? r=1  ?r(xk)  = R? r=1  ?r(xk)Wrm;m = 1, ...,M  (7)  where the normalization degree of activation of the r-th rule ?r is expressed by:  ?r(xk) = ?r(xk) R? r=1  ?r(xk) ; ?r(xk) =  N? n=1  Arn(xnk) (8)  The fuzzy set Arn(xnk) and rule weight Wrm will be mentioned in detail in section 4. The output of the classifier is determined by the winner takes all strategy. That is, ?xk will belong to the class with the highest activation?.

yk = Cm? ;m? = max 1?m?M  (ykm) (9)  3 Structure of The Proposed Fuzzy System  So far, our discussion has focused on class estimation in Eq.(9) to determine which class the pattern xk should be assigned. In this section, we suggest a new adaptive fuzzy system that can adjust automatically the values of fuzzy set Arn(xnk) and rule weight Wrm. After training     Figure 1. Proposed fuzzy system with 2 inputs (N=2), 2 classes (M=2) and 4 rules (R=4).

our fuzzy system, we can determine to which class the pat- tern xk should be assigned. The proposed structure consists of two visible layers (input and output layer) and three hid- den layers as shown in Figure 1. This fuzzy system can be expressed as a directed graph corresponding to Eq.(7).

Layer 1 (Input layer): each node in this layer only trans- mits input xnk, n=(1,2,...,N ), k=(1,2,...,K) to the next layer directly. No computation is done in this layer. There are a total of N nodes in this layer. The output of each node in input layer is O1n = xnk.

Layer 2: The number of nodes in this layer is equal to the number of fuzzy rules. Each node in this layer hasN inputs from N nodes of the input layer, and feeds its output to the node of the layer 3. To overcome the major disadvantage from Anfis [20], namely that an explosion in the number of inference rules limits the number of possible inputs, a fuzzy scatter partition is used in this layer. Therefore, our system can work well when the dimension of pattern ( N ) is high. We use the bell type distribution defined over a N -dimensional pattern xk for each node in this layer. The degree of activation of the r-th rule ?r(xk) with the an- tecedent part Ar = (Ar1, ..., ArN ) is expressed as follows:  ?r(xk) = N? n=1  Arn(xnk) = N? n=1   1 + ( xnk?crn arn  )2brn (10)  where the parameters arn, brn, crn, r=(1,2,...,R), n=(1,2,...,N ) are constants that characterize the value of ?r(xk). The optimal values of these parameters are de- termined by training, which will be discussed in the next section. There are R distribution nodes in this layer, each node has 3xN parameters. The output of each node in this layer is O2r = ?r(xk).

Layer 3: This layer performs the normalization opera- tion. The output of each node in this layer is represented by:  O3r = ?r(xk) = ?r(xk) R? r=1  ?r(xk) (11)  Layer 4: Each node of this layer represents the rule weight in Eq.(6), Wrm = wrm0 + wrm1x1k + ... + wrmNxNk. Where the parameters wrml, r=(1,2,..., R), m=(1,2,...,M ), l=(0,1,...,N ) are determined by least squares estimator, which will be discussed in the next sec- tion.

In this paper, for pattern xk, the output of the classifier is determined by the winner takes all strategy. Therefore, when the rule weight Wrm has a negative value, it will nar- row the choices for class Cm (the more negative value of Wrm is the smaller value of ykm in Eq.(13)) . Or we can say that this negative rule weight prescribes actions to be avoided rather than performed. The output of each node in this layer is  O4rm = WrmO3r = Wrm ?r(xk) R? r=1  ?r(xk) (12)  There are MxR nodes in this layer, each node has (1+N ) parameters.

Layer 5 (Output layer): Each node in the output layer determines the value of ykm in Eq.(7)  O5m = ykm = R? r=1  O4rm = R? r=1  Wrm?r(xk) R? r=1  ?r(xk) =  R? r=1  ?r(xk)Wrm  (13) There are M nodes in the output layer.

4 Parameter Learning Algorithms  The goal of the work presented here, is to perform pa- rameter learning to minimize the sum squared error with respect to the parameters ? = [arn, brn, crn, wrml]. The objective function E(?) for all the training data sets is de- fined as:  E (?) =  2KM  M? m=1  K? k=1  (ykm ? ydkm)2 (14)  where ykm is the output of class m obtained from Eq.(13).

For a training data pair, {xk,ydk}, the input is xk =  (x1k, x2k, ..., xNk), k=(1,2,...,K), and the desired output     ydk is the form of  ydk = (ydk1, ydk2, ..., ydkM )T  =  ??????? (1, 0, ..., 0)T , if xk ? class C1 (0, 1, ..., 0)T , if xk ? class C2 ...

(0, 0, ..., 1)T , if xk ? class CM  (15)  In this section, when the initial structure has been identified withN inputs,R rules andM classes, the fuzzy system then performs the parameter identification to tune the parameters of the existing structure. To minimize the sum squared error E(?), a two-phased hybrid parameter learning algorithm [20] is applied with a given network structure. In hybrid learning, each iteration is composed of a forward pass and a backward one. In the forward pass, after the input pattern is presented, we calculate the node outputs in the network layers. In this step, the parameters arn, brn and crn in layer 2 are fixed. The parameters wrml in layer 4 are identified by least squares estimator. In the backward pass, the error signal propagates from the output towards the input nodes.

In this step, the parameters wrml are fixed, and the error signals are propagated backward to update the arn, brn and crn by steepest descent method. This process is repeated many times until the system converges.

Now we begin to optimize the parameters wrml in layer 4 using least-squares algorithm in the forward step. To min- imize the errorE(?) in Eq.(14) , we have to minimize each output-error (m-th output) and make it as small as possible:  Em = K? k=1  (ykm ? ydkm)2 (16)  When the pattern xk is fed into the fuzzy system, the Eq.(13) is written:  ykm = ?1(xk)w1m0 + ?1(xk)w1m1x1k + ...+ ?1(xk)w1mNxNk+ ?2(xk)w2m0 + ?2(xk)w2m1x1k + ...+ ?2(xk)w2mNxNk+ ...

?R(xk)wRm0 + ?R(xk)wRm1x1k + ...+ ?R(xk)wRmNxNk (17)  For all training patterns, we have K equations of the form Eq.(17). The Eq.(16) is expressed by the following form:  Em = ?AWm ?Ym? (18)  where Wm, Ym, and A are matrices of ((N+1)*R)x1,Kx1, and Kx((N+1)*R) respectively, and  Wm = [w1m0, w1m1, ..., w1mN , ..., wRm0, wRm1, ..., wRmN ]T  (19)  Ym = [ yd1m yd2m ... ydKm ]T (20)  Figure 2. SAR image classification results, (a): original Image, (b): training data with 3 classes, (c): K-Means clustering method, (d): Fuzzy C-Means methods, (e): Anfis method, (f): proposed method.

Now, we apply linear least-squares algorithm in [20] for each output (m-th output) to turn the parameters wrml.

Wm = (ATA)?1ATYm (22)  After the forward pass of learning, the error signals are propagated backward to update the premise parameters arn, brn and crn by gradient decent with the error functionE(?) in Eq.(14). The learning rule is:  anewrn = a old rn ? ?  ?E(?) ?arn  ; bnewrn = b old rn ? ?  ?E(?) ?brn  cnewrn = c old rn ? ?  ?E(?) ?crn  (23)  where ? is the learning rate.

5 Simulation Results  In this section, the proposed method was compared with Fuzzy C-Means [21], K-Means algorithm [22], Feed- forward Backpropagation Network [23], [24] and Anfis method [20], [25], [26]. We will demonstrate the perfor- mance of our classifier system for SAR Image and natural image.

5.1 SAR Image Classification  The image used in this simulation is the JPL L-band po- larimetric SAR image of San Francisco Bay [27], [28], [29] as shown in Figure 2a. The size of image is 1024x900 pix- els. The goal is to train our fuzzy system to classify three different terrains in this image namely water, park and urban areas. The training patterns are enclosed in red boxes     A =  ???? ?1(xk) ?1(xk)x11 ... ?1(xk)xN1 ... ?R(xk) ?R(xk)x11 ... ?R(xk)xN1 ?1(xk) ?1(xk)x12 ... ?1(xk)xN2 ... ?R(xk) ?R(xk)x12 ... ?R(xk)xN2 ... ... ... ... ... ... ... ... ...

?1(xk) ?1(xk)x1K ... ?1(xk)xNK ... ?R(xk) ?R(xk)x1K ... ?R(xk)xNK  ???? (21)  Figure 3. Natural Image Classification.

as shown in Figure 2b. The proposed system was trained us- ing these features to estimate the parameters. The algorithm was run in 100 training iterations. In this example, our pro- posed system with 3 inputs (3 polarimetric channels [29]: hh, vv, and vh), 4 rules (R=4) and 3 classes (M=3) were used to indicate three distinct classes. The desired outputs for urban, park and water classes were chosen to be [0 0 1], [0 1 0], and [1 0 0], respectively.

After training, the trained system was then used to clas- sify the whole image. Figure 2f shows the classification results of our proposed method. We first compare the pro- posed classifier with the K-Means classifier as shown in Figure 2c and Fuzzy C-Means classifier in Figure 2d. These two methods are executed on Matlab with the same 3 inputs (hh, vv, and vh), 3 classes and default values for auxiliary parameters. As can be seen from Figure 2, the classifica- tion accuracy of K-Means and Fuzzy C-Means methods was lower in regions of water and park, when compared with our proposed method. Figure 2e shows the simulation re- sult of Anfis. In this example, the same training areas in red boxes (as shown in Figure 2b) is used to train the Anfis sys- tem. Anfis system with 3 inputs and 8 rules was run for 100 training iterations. The desired outputs for urban, park and water classes were chosen to be 1, 2, and 3, respectively.

Compared with Anfis method, clearly, our classifier accu- racy is higher and the effect of noise on the performance of the detector is much less.

5.2 Natural Image Classification  In this experiment, our algorithm is compared to other classification algorithms on natural images. The images from the Berkeley Dataset [30] are used for testing as shown in Figure 3.

Figure 4a shows the image that we wish to segment into 3 classes (snow, wolf , and tree). This image is corrupted by Gaussian noise (0 mean, 0.1 variance). The input image  is scanned by 5x5 pixel window. For each window, we feed it into the trained fuzzy system to decide whether the center pixel of this 5x5 window should belong to snow, wolf or tree class.

Figure 4. Natural image classification results, (a): Noisy image, (b): Fuzzy C-Means meth- ods, (c): Feedforward Backpropagation Net- work, (d): proposed method.

To train our proposed system, the training patterns en- closed in red boxes as shown in Figure 4a are used. In this experiment, we choose fuzzy with 25 inputs (corresponding to 5x5 window), 8 rules (R=8) and 3 classes (M=3) to in- dicate three distinct classes. The desired outputs for snow, wolf and tree classes were chosen to be [0 0 1], [0 1 0], and [1 0 0], respectively. Figure 4b shows the clustering results of Fuzzy C-Means classifier with 25 inputs, 3 classes.

The image shown in Figure 4c is the result using Feed- forward Backpropagation networks. In this example, the networks established with the structure of 25-8-8-8-3, five layer network with 3 hidden layers, 8 neurons in each hid- den layer and 3 neurons in the output layer. We use tansig for hidden layers and purelin for output layer. The same training areas in red boxes as shown in Figure 4a are used to train this network. The desired outputs for snow, wolf or tree classes were chosen [0 0 1], [0 1 0], and [1 0 0], respectively. Both Fuzzy C-Means and Feedforward Back- propagation networks in this example are executed on Mat- lab with default values for auxiliary parameters.

Comparing the aforementioned methods, our proposed     system (as shown in Figure 4d) could not only successfully segment the image when it is significantly degraded by high noise, but also makes the effect of noise on the final segment image much less.

6 Conclusion  In this paper, we introduced a fuzzy system that can com- bine both positive and negative association rules in its struc- ture. Another advantage of this new model is that each rule can represent more than one class. Through experimental tests and comparisons with other existing algorithms on a number of natural images, it is found that the proposed sys- tem is a powerful tool for image classification.

Acknowledgements  This research has been supported in part by the Canada Research Chair Program, AUTO21 NCE, and the NSERC Discovery grant.

