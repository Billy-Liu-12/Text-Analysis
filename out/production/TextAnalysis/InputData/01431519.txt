Decisianmaking with Fuzzy

Abstract  An outstanding problem is how lo make decisions with uncertain and incomplete data f rom disparate sources without NP-hard algorithms. Here we introduce a new reasoning methodology, fuzzy-belief-state-based reasoning, to solve this problem. In this methodology. weprst  create a fuzzy-beliefstate base fo r  a system from its historical data.

For any component n (n = l , . , , , N )  of  the set of empirical state vectors, the values 0J that component are clustered into LOW, MEDIUM and HIGH fuzzy sets. Then each state vector is fuzzified into a fuzzy-beliefstate vector ofNtriples.

where the n-th triple contains the fuzzy truths ofmembership o f t h e  variable value in these respective three Jiuzzy sets.

Each such vector of N triples is associated with a decision to form afuzzy-belief case andsuch cases comprise afurzy- belief-state base. Then, when given an observed state vector that i s  incomplete and uncertain, we mine fuzzy association rules from the fuzzy-belief-state base and apply them to infer the missing values and their fuzzy beliefs based on that incomplete observation. The completed observation is used io match fuzzy-beliefstate vectors in the fuzzy-beliefstate base. Decisions of the best malching cases are retrieved fo r use as in case-based reasoning.

1. Introduction  Decisions underlie any action that a problem solver may take in structuring problems, reasoning about situations, allocating resources, retrieving and displaying information, or in controlling physical, organizational or political activities (see [271). Decisions are needed, e.g., in pattern recognition and classification, diagnosis, prognosis, product design, marketing and military strategy, public policy, routing, scheduling and negotiations.

Given a situation where one of multiple competing choices, classes, actions, strategies, targets, etc. (called decisions), is to be selected, some considerations are: i) the completeness of the data upon which the decisionmaking i s based; ii) the level of  uncertainty of this data; iii) the  0-7803-881 9-4/04/$20.00 02004 IEEE.

-Belief-State-Based Reasoning   Carl G. Looney Dept. of Computer Science & Engineering  University of Nevada, Reno Reno, NV 89557 USA  looney@cs.unr.edu  consistency o f  the data that may be from disparate sources; iv) the degree of belief in the decision; and VI) the optimal cost of the decision. The expense of obtaining complete and essentially certain data makes it necessary and important to make decisions based on uncertain and incomplete data.

Each of the existing tools for decisionmaking under such conditions is either NP-hard, its parameters are very difficult and costly to obtain, or it lacks the flexibility of completing missing data. Bayesian belief networks ( B B N s )  [ 12, 241, f i z z y  belieJnelworks (FBNs) [ 171 andfuzzy belief Petri nets (FBPNs) [ I  51 (also see [ZO]) can accommodate uncertainty, incompleteness and data from multiple and disparate sources. However, BBNs are NP-hard [6, 71 and the necessary conditional probabilities are difficult or impossible to obtain. But all types of these influence networks, which originated in 192 1 [28] require knowledge of the structure of the influence network. Many BBN algorithms exist [22, 29, 301.

Other methodologies use beliefs of some kind but do not work without one or more of certainty, completeness and knowledge of the relationships between disparate sources.

Rule-based sysrems [2, 4, 10, I I ]  attempt to deal with uncertainty by means of certainty factors, but these are neither axiomatic nor consistent. Completeness is required by the theory ofevidence methodology [S ,  261, operations research (see [2 I ]  for a connection to BBNs), mathematical models and data mining [ 5 ,  9 ,  141, which associates disparate data in tabular columns. Fuzzy logic methods require the completeness of the input data, as do genetic algorithms. Rough sets 1231 require certainty as well. Neural networks (see 1191) generally require complete data as do pattern recognition and classification [ 1 S I .  Case-based reasoning (CBR) is powerful [ l ,  13, 16, 251 but requires certainty and incompleteness degrades its performance.

In this paper we introduce a new reasoning methodology  that we callfuzzy-beliej*-siare-based reasoning, to solve this problem. Section 2 introduces how a fuzzy-belief-state base is created and Section 3 introduces our new fuzzy-belief- state-based reasoning approach. We applied this approach on real world data and show the results in Section 4. Section 5 discusses conclusions and future directions.

mailto:LLiang@udc.edu mailto:looney@cs.unr.edu   2. Fuzzy-belief-state base creation  S  0 -  Situations for a given system can be described by stute vectors s = (sir s2 ,..., sN), where s,, (n = 1 ,..., N )  is a state variable or parameter of the system. The state can vary over time as is indicated by s(t). A basic assumption here, as in other methodologies, is that the system is stationary rather than evolutionary, that is, the system at different times has the same relationships among the variables (the correlations are constant over time). For a set of Q state vectors s(tl), ..., s(tQ), we consider the set of all Q values S , =  {sn(tq): q E Q} for a fixed component n. Considering the Q vectors as Q rows, S, is the set of all values in the nth column.

For each n = I ,  ..., N, we cluster the Q values in S, into three clusters and find their Gaussian weighted centers [ 1 SI.

This process weights the prototype (center) of each cluster according to the density of the surrounding points and locates the center among the most densely situated points.

These three clusters o f  the S, values are designated as the fuzzysets LOW,(LJ, MEDIUM,(MA andHIGH,(HJ with fuzzy set membership functions centered on their centers.

Figure 1 shows the components n across the horizontal axis, the range of values and cluster centers on the vertical axis and the fuzzy set membership function values coming out of the plane in the third dimension,  I -* I I " / .I.I........__ ._.__. 4 -. k  Figure 1. Fuzzy set membership functions of component n.

The fuzzy set membership functions (FSMFs) are Gaussians centered on the cluster centers except for the LOW and HIGH end functions where half Gaussians are used with the other half being a constant o f  unity. The FSMFs for L ,  M, and H, are  where, e.g., fLn is the fuzzy truth that component value s, belongs to fuzzy set L,, while pLn and uL,, are the center and the standard deviation for the FSMF for L,. Thus, via fuzzification o f  each component value s,(t), a state vector s(t) = (s!(t), s2(t) ,... ,sN(t)) is mapped into a fuzzy-beliefistate (FBS) vector of N triples as shown in Equation (4).

For any s,, there are two non-negligible fuzzy truths of membership (called fuzzy beliefs) respectively for two ofthe three fuzzy sets L,, M, and H,. These two sufficiently describes the fuzzy set memberships of s,. The lowest fuzzy truth is set to 0.

Table 1 displays a tabular base of Q fuzzy-belief-state vectors {B(t)} with each having a decision adjoined as an extra component. Such decisions are to have been previously selected so as to be optimal in some sense. The decision column can actually be taken to be any column in the state vector or a new component, but either way it represents the output of the decisionmaking process. Such a table is called a fuzzy-belief-state base (FBSB). A row (record) in the FBSB is a fuzzy-belief-slate cnse.

Table 1. A fuzzy-belief-state base 2 1 -  . . .  SN  t fLt-fi\ll&,l, . . .  fLN&N&ly Decision t, 0.0 0.5 0.8 . . . 0.7 0.5 0.0 Decisiond, t2 0.3 0.7 0.0 . . . 0.0 0.5 0.9 Decision d,  tp 0.6 0.5 0.0 . . . 0.8 0.4 0.0 Decision d, . . .  . . .  . . .  . . .

3. Fuzzy-belief-s t ate-b ased reasoning  In the real world it is often true that not all of the variables in a state can be observed at a given time t. in this case we say the observation data is incompIete (due to missing component values). Also, the present measurements of the observed variables contain noise (uncertainty) and come from disparate sources such a s  sensors, reports, archived data, etc. From an uncertain and incomplete observed input state vector we propose to use the knowledge that exists within the data in the fuzzy-belief-state base to complete the observation, account for the uncertainty with beliefs, and perform a type of reasoning to select a decision as a response to that input.

The high level ulgorithm. The fuzzy-belief-state-based reasoning (FBSBR) approach assumes no functional relationship between the output decisions and the inputs, but uses only knowledge in the FBSB data. Given the incomplete and uncertain observation state vector s-(t), we     1) Fuzzification: fuzzify the variables that are present to obtain an incomplete FBS vector B-(t)  2) Data Association: perform fuzzy association rule mining  3) Belieflnferencing: infer beliefs to get the complete the FBS vector B(t)  4) Decision Retrieval: retrieve decisions of FBS cases from the FBSB that best match B(t)  5 )  Decision Adjuszment: adjust retrieved decisions and use  Figure 2 shows the above steps that make up fuzzy-belief- state-based reasoning. In the rest of this section we introduce these steps one by one. + Fuzxification  1 Decision Adjustment 1 ? I  Final Decision  Figure 2. FBSBR flowchart.

Fuzzification. For a given incomplete observation s-(t), we first fuzzify it to obtain an incomplete fuzzy-belief-state vector B-(t). The fuzzification process is done for each present value sk(t) by obtaining its fuzzy truths fLk, fm and fm by putting it through the three FSMFs Lk, Mk and H,.

This step is similar to the fuzzification step in FBSB creation, which we introduced in Section 2. The lowest one of fU, fm and fHk is set to 0.

Duta ussociation. In this step, we implement our fuzzy association rule mining from the FBSB. Let X be a statement such as sk is  L,  and Y be a statement such as sj is Mi. The support of X in the FBSB is the set of all cases in  that FBSB where X is true. Thesupportofa rule of the form X - Y is the set of all cases in the FBSB where both X and Y are true, i.e., the cases that support XuY. The rule confidence for X =. Y is the ratio of the number of cases that support XuY to the number of  cases that support X (sometimes expressed as a percentage). In our situation here, X will be a pair of statements where each has a nonzero fuzzy truth, and Y will be a single statement with its fuzzy belief. Thus X * Y will have a form such as  sk is L, (fu) ; sk is M, (fm) - sj is Mj (fMj) ( 5 ) For each sk that is present in the observation, we create  rules of the above format with the pair of statements that are true for sk as X, and a statement of each missing sj(t) being either Lj, Mj or Hj as the statement in Y. To determine the fuzzy truth of sj in a rule, we examine all cases in the FBSB that support the statements of that rule and average their fuzzy beliefs for si.

The rule confidence is computed for each rule. The rules and their confidences are to be used in the fuzzy-belief inferencing, which is the next step.

Fuzzy-belief inferencing. We now do the fuzzy belief inferencing to estimate each missing value sj(t). All fuzzy rules obtained for sj(t) are applied and each rule votes for its consequent statement Y with its confidence. Letting F represent any of  Lj, Mj and Hj, the fuzzy belief (fF) that sj(t) belongs to F is  (r=l,R(F)) cr fFr  fF = (6) C (r=l,R(F)) r  where  R(F) = number of rules with statement Y = (sj(r) is F) fFr is the fF in Rule r c, is the confidence of Rule r Only the two highest fF values for sj(t) are kept and the  other one is set to 0. Thus we account for the missing datum si in s with a triple of fuzzy beliefs for B-(t). Each missing component of s i s  accounted for in this way to complete the fuzzy-belief-state vector B(t).

Decision retrieval. Next, we measure the similarity of the completed B(t) to each FBS vector in the FBSB. The similarity measurement h, is determined by  where  (7)     is the similarity of the q-th vector in the FBSB to B(t) a,, is the vote of template matching of the q-th vector to  B(t) on the n-th dimension, when either both of non- zero L, and M,, or both of non-zero H, and M,, then a,, =I, otherwise  aq? = 0 6,, is the square root of the mean square error between the  beliefs of the q-th vector and B(t) on dimension n  We then retrieve the decisions of the cases with the and use either one decision or maximum similarity  interpolated decisions.

4. Computer runs on real world data  We test the methodology on real world noisy and incomplete data. The Wisconsin breast-cancer database was originally provided by Dr. William H. Woldberg [3] and used by a number ofresearchers in pattern recognition. This database contains 699 cases, each of which is described by ten attributes in  addition to the unique identification (code) number. Attribute 10 is the class decision here. The attributes are listed in table 2:  Table 2. Wisconsin breast-cancer data attributes  # Attribute Domain 0. Sample code number id number I .  Clump Thickness 1 - 1 0 , 2. Uniformity of Cell Size 1 - 1 0 3. Uniformity of  Cell Shape 1 - 1 0 4. Marginal Adhesion 1 - 10 5. Single Epithelial Cell Size 1 - 10 6 .  Bare Nuclei 1 - 1 0 7. Bland Chromatin 1 - 10 8. Normal Nucleoli I - 10 9. Mitosis 1 - 10  10. Class: (2 for benign, 4 for malignant)  Experiments with existing incomplete data. There are 16 records in the Wisconsin breast-cancer database with the value of Feature 6 missing. We use these 16 records as incomplete observations with their class label masked and use the rest of the data set for creating a FBSB. The FBSB is created and FBSBR is applied to make decisions for these observations as to their membership in the disjoint classes benign or malignanl. Decisions were compared against the masked labels and accuracy was computed. The results are shown in Table 3. As can be seen, 14 out of the 16 cases were labeled correctly by the FBSBR. Cases 1096800 and 704 168, which are highlighted in Table 3,  were mislabeled to mnlignont. The accuracy for this test is 14/16, or 87.5%.

Table 3. Result with records of misslng Feature 7  Sample code # Label by FBSBR OriEinal Label I05701 3 malignant malignant  11 83246 benign benign 1 I84840 benign benign 1193683 benign benign 1197510 benign benign 1241232 benign benign 169356 benign benign 432809 benign benign 563649 malignant malignant 606 140 benign benign  benign benign 61634  733639 benign benign 1238464 benign benign 1057067 benign benign  1096800 malignant !?iP.&l?

-- i 704168 malignant? bFwn_  Experiments with created incomplete datu. We also did tests on the Wisconsin breast-cancer with the missing data taken out. We divided the 683 complete cases into 10 portions. Each time we drew one portion out of the ten to use as an observation set and used the rest for creating a small fuzzy-belief-state base.

Table 4. Accuracy with created incomplete data (missing one attribute each time)  ?Missine?Attribute Dntaset 1 2 3 4 5 6 7 8 9  1 St 81 81 81 85 85 87 84  7 8  82 2nd 97 97 94 96  99 91 99 97 97 3th 97 97 99 99 97 94 99 97 99 4th 88 96 91 94 90 90 91 91 91 5th 88 97 96 97 97 91 97  96 97 6th 99 99 97 99 99 97 99 99 97 6th 99 99 97 99 99 97 99 99 97 7th 96 96 9 4 ,  94 96 96  96 96 96 8th 97 99 97 96 97 99 97 96  97 9th 100 100 100 100 100 100 97 100 100  10th 100 100 100 100 100 100 100 100 100  For the observation set, we deliberately masked their labels, and also cleared their values of  one or more features to simulate real world incomplete observations. Then the FBSB was created and FBSBR was applied to infer about the missing data and to make decisions for these observations. The decisions were compared against the masked labels and the accuracy was computed. W e  repeated this for each different observation set. Tables 4 and 5 show the results.

Table 5. Accuracy (%) with created incomplete data (missing three attributes each time)  ?M issing?Attribu tes Dataset 1 . 4 ,  9 2, 5.  7 3. 6 ,  8  1 St 82 84 91 2nd 96 97 90 3th 97 97 94 4th 93 91 90 5th 91 96 87 6th 99 97 96 7th 96 96 96 8th 99 97 100 9th 100 100 100 10 th 100 100 99  5. Conclusions and future work.

A new methodology, fuzzy-belief-state-based reasoning, is introduced for making decisions with uncertain and incomplete data from disparate sources. In this methodology, a FBSB is created from historical data of a system by clustering and fuzzification. When given observed incomplete and uncertain data, the FBSB is then mined for fuzzy association rules to infer about the missing data. After that, each case in it is matched against the inference-completed observation to retrieve decision(s) of the best match(es). The test results on real world data prove the effectiveness of this methodology.

F B S B R  leverages the strength of fuzzy clustering, belief inferencing and case-based reasoning to provide an innovative and intuitive way of reasoning under uncertainty and incompleteness. Compared with the existing Bayesian network models of belief inferencing, FBSBR has the following advantages  1 )  it i s  not NP-hard. The fuzzy association rules are mined after an incomplete observation is made, Only the association rules fur the observed ones and the unobserved ones are mined in a one-to-one manner.

The time complexity for the rule mining is 3N.

2) it isflexible. This post-observation mining not only prunes the miningspace, but also makes FBSBR much more flexible than any other model that is predefined before observation.

3) it avoids the graphical structure problem. F B S B R reasons at the data level, instead of using graphical representations for events or associations. This avoids the big graphical representation problem, which inhibits the utilization of existing network models.

4) it is self-expandable. As new cases are added and new rules are found and saved, the FBSBR system grows and learns.

Compared with the case-based reasoning (CBR)  technique, FBSBR handles problems that CBR cannot  handle without degrading the performance for retrieval of cases, i.e., FBSBR reasons under incompleteness.

Future work includes the investigation o f  evolutionary processes whose interrelationships change over time. It will also include searching for more complex rules. Future applications will include diagnosis, tracking, and threat analyses, for examples.

