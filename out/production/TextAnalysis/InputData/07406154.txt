MapReduce-based H-mine algorithm

Abstract?Frequent Itemset Mining (FIM) is a very effective method for knowledge acquisition from data, but with the advent of the era of big data, traditional algorithms based on memory are facing severe challenges such as the computation speed and storage capacity. Fortunately, MapReduce model provides an efficient framework for distributed programming and operation framework.

This paper proposes a novel MapReduce-based H-mine algorithm (MRH-mine), a version of H-mine algorithm in the distributed operation environment. Experimental results show that MRH-mine algorithm has a better performance and scalability than traditional H-Mine when facing massive data growth.

Keywords?distributed data mining; MapReduce; H-mine; parallelization

I. INTRODUCTION With the continuous advancement of Internet technology,  particularly the advent of the era of big data, how to fully utilize the value of data becomes a serious problem. Frequent Itemset Mining (FIM) [1] is an important research field of data mining and data analysis and a series of algorithms for mining frequent patterns have been proposed, such as Apriori [2], FP- growth [3] and H-mine[4] et al. However, these algorithms are based on memory. Therefore, they are subject to single computer performance in varying degree. Faced with large data to be processed, traditional algorithms generally have a series of problems include small memory, low processing speed and inadequate hard disk, and so on. In order to solve these problems, the algorithm needs to be ported to a distributed computing environment.

Distributed computing environment is a software system whose components are located on network and actions are coordinated by passing message. Distributed computing environments have many outstanding features, like resource sharing, high transparency, high reliability, high flexibility et al, but there are also disadvantages, like more complex programming, node failure, network disruption et al.

MapReduce[5][6] framework proposed by Google solved these issues to a large extent. MapReduce framework not only simplifies the programming for distributed data processing but also enhances the reliability of distributed computing. In order to make the traditional frequent mining algorithms meet the needs of large data processing, one possible way is to use the advantages of MapReduce framework to transform traditional FIM algorithms from single machine to a distributed computing environment.

In this paper, we introduce a novel MapReduce-based H- mine algorithm. There are mainly three points of improvement:  1) Paralleling algorithm in order to make full use of  distributed  computing environment.

2) Averaging task distribution in order to achieve optimal result  of  parallel processing.

3) Reducing network traffic between nodes in order to reduce the loss of processing network data..



II. PRELIMINARIES  A. MapReduce MapReduce is a parallel programming framework  proposed by Google for parallel computation of large-scale data sets. MapReduce framework can help users write parallel programs for processing massive data sets, enabling developers to concentrate on writing logic code, without the need to consider underlying details, thus greatly improves the efficiency of development. MapReduce framework simplifies the complex process into two simple stages: Map and Reduce.

Map stage parsing disorganized, unrelated data, extracting key and value from data. After shuffle processing, Reduce stage got the summarized data. Then we can be further processed to get desired result.

B. FIM algorithm FIM algorithms are mainly divided into two categories:  1) Candidate-generation-and-test approaches, such as Apriori.

2) Pattern-growth methods, such as FP-growth.

Traditional FIM algorithms have two main drawbacks:  Firstly, memory space which the algorithm needs is unpredictable, and when the data set size increases, the required memory space will soar; and secondly, the algorithm is very inefficient or can?t process in most occasions (dense vs.

sparse, huge vs. small).

H-mine algorithm solves the problems mentioned above to some extent. H-mine is a memory-based and efficient FIM algorithm, using the new data structure H-Struct, which can traverse the data more quickly. Theoretically, memory-based H-mine has a polynomial space complexity and is more space efficient than pattern-growth methods such as FP-growth and TreeProjection when mining sparse data sets, and also more efficient than Apriori-based methods which generate a large number of candidates.

DOI 10.1109/IMCCC.2015.373    DOI 10.1109/IMCCC.2015.373     Experimental results show that H-mine has excellent scalability and overall performance in any case better than the memory based Apriori and FP-growth.



III. MAPREDUCE-BASED H-MINE ALGORITHM Let the first two columns of Table  be our running  transaction database TDB. Let the minimum support threshold be min_sup = 2.

TABLE I. TDB USED AS OUR RUNNING EXAMPLE  Transaction ID Items  Frequent-item projection  100 c,d,e,f,g,i c,d,e,g  200 a,c,d,e,m a,c,d,e  300 a,b,d,e,g,k a,d,e,g  400 a,c,d,h a,c,d  Step1. Through MapReduce phase, we can get the frequent items from transaction sets, then filter value less than the min_sup can be removed in the Reduce stage. As shown in Table , we will obtain the frequent items {(a,3),(c,3),(d,4),(e,3),(g,2)}, where the notation (a,3) means item a?s support (occurrence frequency) is three.

TABLE II. STATISTICAL FREQUENT ITEM  Items Map stage Reduce stage  c,d,e,f,g,i (c,1) (d,1) (e,1)  (f,1) (g,1) (i,1)  (a,3) (c,3)  (d,4) (e,3) (g,2)  a,c,d,e,m (a,1) (c,1) (d,1)  (e,1) (m,1)  a,b,d,e,g,k (a,1) (b,1) (d,1)  (e,1) (g,1) (k,1)  a,c,d,h (a,1) (c,1) (d,1)  (h,1)  Step2. The frequent items obtained in Step1 are sorted in support ascending order, then dictionary is generated, thus we can clean data according to the dictionary (filter, conversion, duplicate removal, sort). As shown in Fig. 1.

Fig. 1.  Dictionary generation and conversion process  There are two main benefits of using dictionary:  1) Filtering non-frequent items, converting original data to digital numbers and duplicate removal can reduce the size of transaction sets, thus significantly reduces network traffic between nodes.

2) Using dictionary can make a better distribution of transaction sets, detailed description in Step3.

Step3. In H-mine, a transaction is divided according to its first item and can be viewed as a queue. After a queue is completed, its data need to be repartitioned, so transaction sets will go through multiple distribution. As shown in Fig. 2, transaction {1,3,4,5}, will be assigned to queue-1 in accordance with the first data {1} in the first distribution.

When queue-1 is completed, the transaction will be reallocated to queue-3.

Fig. 2.  H-mine  distribution process  We can see from Fig. 2 that the transaction {1,3,4,5} will allocate three times in H-mine. Deal with a queue at only one time can significantly reduce the memory requirements, which is the advantage of memory-based H-mine. Distributed computing environment has no memory constraints, so transactions can be assigned at the same time. As shown in Fig.

3.

Fig. 3. MRH-mine distribution process  In MRH-mine each queue can get desired transaction sets at one time, the new distribution method will need more space than original distribution method. If the original distribution method occupies n, the new distribution  method will be  )1( ?nn . In the new method, the original  transaction sets will not be used after distribution, therefore it can be removed in order to save space. Intermediate results which need large space should be stored in the HDFS, so it is a classical problem of exchanging time with space.

The new distribution method has two major advantages:  1) It greatly simplifies the process, with no transaction sets assignment repeatedly.

2)  Each queue can mine its own assigned data independently with no data exchanges when mining.

Fig. 4.  Generate different sort of dictionary  When parallel mining data, using dictionary can allocate the transaction sets in a apparently better way. After cleaning the transaction sets, each transaction will be sorted from small to large. Therefore, the smaller the number is the more forward position it will be, and the more forward position it is  the longer transaction we will get, and it is clearly that the longer transaction needs the longer execution time, as shown in Fig. 2 and Fig. 3.

Because the dictionary is sorted by  support ascending order, the smaller support is the smaller number it will be.

Therefore, smaller support leads to longer transaction and larger support leads to shorter transaction, as shown in Fig. 4- 7. This kind of dictionary can make the distribution more balance.

Fig. 5.  Different cleaning process  Fig. 6.  Transaction set 1 distribution process     Fig. 7.  Transaction set 2 distribution process  As shown in Fig. 6, after the distribution, the data in transaction sets 1 will no longer be used, can be deleted to reduce disk usage.

Step4. In this stage, we can filter data by using statistic result obtained in Step3. Execute Step3 repeatedly until the length of queue?s transaction is 1. Specific process is shown in Fig. 8.

Fig. 8.  Queue-1 mining process  We can see from Fig. 8, queue-1 has two transactions {3,4,5} and {2,4,5}, the statistical result is { 2,1  3,1 4,2 5,2 }. Therefore, (1,2)?s support is one, (1,3)?s support is one, (1,4)?s support is two, (1,5)?s support is two. We also know (1,4,5)?s support is two by statisticing queue-14.

MRH-mine?s flow chart is shown in Fig. 9.

Fig. 9.  Flow chart of MRH-mine

IV. EXPERIMENT AND ANALYSIS To evaluate the efficiency and scalability of MRH-mine,  we test our algorithm performance on a variety of compute nodes and data set with other algorithms.

A. Experimental environment and data In the experiment, the distributed computing environment  consists of nine desktop computers, the master node is configured for i7 3770 processor, 4G RAM, 1T HDD, and compute nodes is configured for e 2140 Pentium processor, 1G RAM, 250G HDD. 32 bit Ubuntu14.04 operating system and Hadoop [9] version 2.4.0 are used.

In order to ensure the objectivity of experiment, we use public data set Connect-4 [10] and Gazelle [11]. Connect-4 is a dense data set. It contains 67,557 transactions, with 43 items in each transaction. Gazelle is a sparse data set. It contains 59,601 transactions, with up to 497 distinct items. Considering those data set is too small for distributed systems, we obtain experimental data set by using the synthetic data generator.

B. Experimental results and analysis In order to verify the correctness of MRH-mine,  MRH-  mine and H-mine (Mem) results are compared in Connect-4.

Experiment result shows that the result is consistent. In order to verify the performance of MRH-mine, we use the FPC [7] and BigFIM [8] as the comparison algorithm. All algorithms have done the same preprocessing. In order to ensure the correctness of time consuming for all experimental results, we use average values of 10 runs.

In the first experiment, we will test time usage in different sizes of data, support threshold and compute nodes. As shown in Fig. 10-15.

Fig. 10.  Time usage on 10G Connect-4  Fig. 11.  Time usage on 20G Connect-4  Fig. 12.  Time usage on 30G Connect-4  Fig. 13.  Time usage on 10G Gazelle  Fig. 14.  Time usage on 20G Gazelle  Fig. 15.  Time usage on 30G Gazelle  Data will be assigned more than once in MRH-mine, and the process of MRH-mine is more complex than the process of FPC and BigFIM. As can be seen from Fig. 10 and Fig. 13, the impact on performance is more serious when the data is small.

With the increase of data set and compute nodes, MRH-mine can more fully exploit the advantages of cluster resources, its ability to process data showed class of linear growth, with higher scalability.

When handling sparse data, MRH-mine may encounter the problem of small data partitions. MapReduce is not suitable for dealing with small data, resulting in too much time consumed in MapReduce promoter. With the     increase of data set, this problem will be solved to some extent.

As shown in Fig. 10-15.

MRH-mine needs to store some data in the running process, including dictionary, queues, statistical results, etc.

Hard disk  usage changes along with the change of intermediate results. Ultimately, only the dictionary and statistical results of each queue are saved. The maximum amount of disk required for the storage of data is shown in Fig. 16 and Fig. 17.

Fig. 16.  Max hard disk usage on Connect-4  Fig. 17.  Max hard disk usage on Gazelle  Compared with FPC and BigFIM, MRH-mine needs larger space to store intermediate values. MRH-mine runs in distributed computing environment and can improve the processing ability by simply adding nodes, so it very suitable for handling big data.



V. CONCLUSION In the Big Data era, H-mine is unable to process massive  amounts of data. In this paper, we proposed a MapReduce- based H-mine algorithm. Through dictionary filtration, parallelism, optimization of data distribution, makes H-mine run efficiently in distributed computing environment. MRH- mine is a very good solution to FIM problem under condition of massive data. However, the intermediate data take up too much disk, optimize intermediate data management is a further research issue. Experiments show MRH-mine has good performance and scalability when handling big data.

