Fast Evaluation of T-norms for Fuzzy Association Rules Mining

Abstract?The aim of this paper is to present a bitwise approach on evaluation of fuzzy t-norms. T-norms are functions that generalize the notion of conjunction, and as such play an important role in fuzzy association rule mining process. Efficient algorithms for batch evaluation of the most common t-norms is proposed that minimizes computation time as well as memory space requirements at the cost of user-adjustable loss of precision of the membership degrees.



I. INTRODUCTION  Searching for association rules [1], [2] is a broadly dis- cussed, developed and accepted data mining technique. An association rule is commonly understood as an expression X ? Y , where antecedent X and consequent Y are conditions ? the former usually in the form of elementary conjunction.

Such rules are usually interpreted as implication ?if X is satisfied, then Y is true very often, too?. Two traditional measures of intensity of an association rule are often used, support and confidence. A task of searching for association rules is the task of finding rules with their support and confidence above some user-defined thresholds.

The task of searching for association rules fits particularly well on binary or categorical data and many has been written on that topic [1]?[4].

For association analysis on numeric data, a prior discretiza- tion is proposed by Srikant et al. [5]. Unfortunately, that may lead to danger of undiscovering important knowledge due to information loss caused by discretization [6], therefore, alternative techniques are investigated that would dispose or at least mitigate the unwanted information loss [7]?[9].

The problem of information loss due to discretization is tightly connected to the fact that quantitative attribute is transformed to several categories given by crisp boundaries.

A rational request to ?soften? these boundaries leads us to the fuzzy sets theory. The use of fuzzy sets in connection with association rules has been motivated by many authors (see [10] for recent overview). By allowing for soft bound- aries of discretization intervals, fuzzy sets can avoid certain undesirable threshold effects [11]. Fuzzy association rules are appealing also because of the use of vague linguistic terms such as ?small?, ?very big? etc. [12], [13].

Fuzzy rule mining algorithms are usually based on well- known algorithms developed for binary data such as Apriori [2], [14] or FP-tree [15]. However, adoption of that algorithms  means moving from boolean {0, 1} to fuzzy memberships specified by numeric degrees from the [0, 1] interval.

In order to optimize searching for association rules on binary data, Rauch and Simunek [16] propose to encode data columns as bit-strings such that i-th bit of j-th bit-string represents the presence or absence of feature j in object i. To compute conjunction of features k and l, it lasts to compute bitwise AND operation of bit strings k and l so that on computer with 64bit registers, a single AND instruction computes conjunctions for 64 different objects.

This paper provides optimizations similar to [16]. However, instead of boolean {0, 1} memberships, we must deal with a numeric fuzzy membership degree. Moreover, contrary to the single possible boolean conjunction performed by the AND instruction, fuzzy logic provides many different t-norms, i.e.

functions that generalize the notion of conjunction.

In this paper, the bit-string ideas from [16] are extended for numeric fuzzy membership degrees and bit-handling al- gorithms are designed to evaluate the most common t-norms: minimum and ?ukasiewicz t-norm [17]. As a consequence, a significant minimization of the computation time is achieved as well as reduction of memory space requirements at the cost of user-adjustable loss of precision of the membership degrees.



II. PROBLEM DEFINITION  A fuzzy set F of an universe U is defined by a membership function that for each element u ? U specifies the degree of membership of u in the fuzzy set. For us, the membership function is a mapping U ? [0, 1]. We will not distinguish between a fuzzy set and its membership function, that is, F (u) denotes the degree of membership of the element u in the fuzzy set F . (Clearly ordinary sets are special cases of fuzzy sets such that their membership function maps U to {0, 1}.)  T-norm ? is a generalized logical conjunction, i.e. a function [0, 1] ? [0, 1] ? [0, 1] which is associative, commutative, monotone increasing (in both places) and which satisfies the boundary conditions ? ? 0 = 0 and ? ? 1 = ? for each ? ? [0, 1]. Some well-known examples of t-norms are:  ? minimum t-norm: ?min(?, ?) = min(?, ?); ? ?ukasiewicz t-norm: ??uk(?, ?) = max(0, ?+ ? ? 1).

T-norms are used for defining the intersection of fuzzy sets  F and G: (F ?G)(u) def= F (u)?G(u).

CINTI 2013 ? 14th IEEE International Symposium on Computational Intelligence and Informatics ? 19?21 November, 2013 ?  Budapest, Hungary     The cardinality of a fuzzy set F is defined as the sum of the membership degrees: |F | def=  ? ?u?U F (u) [17].

Let D be a set of objects, for which, some properties are identified by the fuzzy subsets of D that we will call the fuzzy attributes; let there be n fuzzy attributes. For instance, if D was a set of people, then t could be a fuzzy subset of D of people that are ?tall?. I.e. for each x ? D, t(x) results in a membership degree of x being ?tall?. A fuzzy association rule is then a rule of the form A ? B, where A and B are sets of fuzzy attributes. For example:  {leading position,middle age} ? {high income};  i.e. ?middle-aged people working on leading position have high income very often?.

Let A = {A1, A2, . . . , Am} be a set of m fuzzy attributes.

A support of the set A is the cardinality of the intersection of all attributes Ak ? A:  supp(A) def=  ????? m?  k=1  Ak  ????? = ? ?x?D  (A1(x)? . . .?Am(x)). (1)  Similarly, a support of a rule A ? B is defined as a support of the set A ? B:  supp(A ? B) def= supp(A ? B). (2)  A confidence of the rule A ? B is given by  conf(A ? B) def= supp(A ? B) supp(A)  . (3)  Mining for fuzzy association rules means searching for all rules with support and confidence above some user-specified thresholds. Discussion about the search algorithms is out of the scope of this paper ? details may be found e.g. in [2], [14], [15]. However, during the search, many different combinations of sets A,B of fuzzy attributes are generated and supports and confidences of rules A ? B are evaluated.

In order to compute supp(A), t-norms of fuzzy attributes Ai have to be computed for each object in the dataset D and the results have to be summed up. The aim of this paper is to optimize such computations by using a bitwise algorithm for batch t-norm evaluations.

This paper assumes all data to fit in the computer?s opera- tional memory. Although it may seem as limitation disquali- fying very large datasets, many real world data are in fact so small to fit to nowadays computers? RAMs. Moreover, as the industry evolves, memory sizes increase ? what does not fit into the memory today, it will fit tomorrow.

We assume each fuzzy attribute Aj (j ? {1, 2, . . . , n} being somehow encoded into an array aj , so that aj [x] represents a membership degree ? ? [0, 1] of the x-th object in the fuzzy attribute Aj .

In the following text, we will concentrate on fast implemen- tations of the following functions:  1) SET(a, x, ?) ? set x-th value of array a to value ?; 2) GET(a, x) ? get x-th value of array a;  3) TNORM(a, b) ? vectorized evaluation of t-norm; a and b as well as function?s return value are arrays of member- ship degrees;  4) SUPP(a) ? summarization of membership degrees stored in array a.

A naive approach assumes fuzzy attributes to be encoded as arrays of floating point numbers from the interval [0, 1] and the functions SET, GET, TNORM and SUPP to be realized as in algorithm 1.

Algorithm 1 Naive realization 1: function SETnaive(a, x, ?) 2: a[x]? ? 3: end function  4: function GETnaive(a, x) 5: return a[x] 6: end function  7: function TNORMnaive(a, b) 8: r ? new array of size |a| 9: for x ? {1, 2, . . . , |a|} do  10: r[x]? a[x]? b[x] 11: end for 12: return r 13: end function  14: function SUPPnaive(a) 15: return  ?|a| x=1  a[x] 16: end function

III. BITWISE IMPLEMENTATION  A common idea for fast bitwise implementation of t-norm computations lies in encoding multiple membership degree values into a single integer. Besides memory consumption savings, a single operation on that integer in fact processes many membership degrees inside of it.

Such approach was initially introduced to association rules mining by Rauch and Simunek [16]. Having crisp boolean data, they use a single bit as a flag of presence or absence of a single object?s attribute. For each attribute, they handle an array of integers called bit strings such that every bit in that array corresponds to different object, i.e. r-th bit of an s-th 64bit integer in an array corresponds to an attribute?s value of a (64 ? (s? 1) + r)-th object.

Having two bit strings a and b that correspond to two different attributes A and B, a support of {A,B} can be easily computed by using bitwise AND operation pairwisely on each element of arrays a and b and counting the number of 1?s in the result. It is evident that a single bitwise AND operation evaluates conjunction of 64 objects (on a computer with 64bit integers), so the algorithm may run roughly 64? faster.

Unfortunately, things are not such simple in the fuzzy case. Instead of a single bit, we need to handle membership degrees from interval [0, 1]. Moreover, there do not exist CPU instructions for direct t-norm computations that could be used instead of bitwise AND. However, as will be shown in this section, a solution exists at least for ?min and ??uk, that enables to store several membership degrees into a single  M. Burda ? Fast Evaluation of T-norms for Fuzzy Association Rules Mining     TABLE I ARRANGEMENT OF CHUNKS INSIDE OF A SINGLE 64BIT INTEGER  bit index: 56?64 . . . 9-16 1?8 data: chunk8 . . . chunk2 chunk1  TABLE II THE MEANING OF BITS INSIDE OF A CHUNK OF 8 BITS  bit index: 8 7 6 5 4 3 2 1 data: sign/overflow b7 b6 b5 b4 b3 b2 b1  integer and perform a sequence of bitwise operations that result in t-norm evaluations. As discussed in section IV, the proposed approach runs several times faster than the naive approach in algorithm 1.

In the algorithms, ?&?, ?|?, ?!?, ??? and ??? stand for bitwise operations AND, OR, NOT, shift left and shift right, respectively.

A. Data Format  Let intSize be the size of integer in bits (= 32 or 64 on nowadays computers). As defined above, the membership degrees are values from the [0, 1] interval. Computers of course can not work with infinitely many real numbers ? rounding is always needed.

In our approach, user may select the desired precision by specifying chunkSize ? {2t : t ? {1, 2, . . . , log2(intSize)? 1}}, a number of bits to be used for a single value. Evidently, there fit intSizechunkSize chunks into a single integer.

Bits b1, b2, . . . , bchunkSize?1 are used to store an integer number from {0, 1, . . . ,max}, where  max = 2chunkSize?1 ? 1. (4)  The chunkSize-th bit is reserved for overflow, that is impor- tant for the t-norm computation algorithm described later. The conversion of ? ? [0, 1] into ?? ? {0, 1, . . . ,max} is simply done by  ?? = round(? ?max). (5)  For example, if intSize = 64 and chunkSize = 8, then max = 127 and the arrangement of chunks and bits is as in tables I and II. We assume little-endian byte arrangement.

For the algorithms described below, we will also need some bit masks, i.e. integers whose bits are set to 1 on some specific places. More concretely:  ? chunkMask def = 2chunkSize?1 is a bit mask of chunk1  i.e. integer with first chunkSize bits set to 1; ? overflowMask is a bit mask with 1s on the  sign/overflow position of each chunk, i.e. binary:  ( 1 0 . . . 0? ?? ? (chunkSize?1)?  ) . . . ( 1 0 . . . 0? ?? ? (chunkSize?1)?  )  ? ?? ? (intSize/chunkSize)?  .

(The purpose of the sign/overflow bit will be explained later.)  ? oneMask is a bit mask of first bit (b1) in each chunk, i.e. binary:  ( 0 . . . 0? ?? ? (chunkSize?1)?  1 ) . . . ( 0 . . . 0? ?? ? (chunkSize?1)?  1 )  ? ?? ? (intSize/chunkSize)?  .

For intSize = 64 and chunkSize = 8, chunkMask is decimal 255, oveflowMask equals to binary 100000000 repeated 8 times, and oneMask equals to binary 000000001 repeated 8 times.

The methods SET (resp. GET) are responsible for encoding (resp. decoding) a membership degree value ? into an array of integer chunks ? see algorithm 2.

Algorithm 2 A common realization of SET, GET and SUPP functions for both the minimum and ?ukasiewicz t-norms 1: function SETmin|?uk(a, x, ?) 2: index? (x ? chunkSize) / intSize 3: shift? (x ? chunkSize) mod intSize 4: bits? round(? ?max) 5: bits? bits? shift 6: temp? a[index] & !(chunkMask ? shift) 7: a[index]? temp | bits 8: return a 9: end function  10: function GETmin|?uk(a, x) 11: index? (x ? chunkSize) / intSize 12: shift? (x ? chunkSize) mod intSize 13: bits? (a[index]? shift) & chunkMask 14: return bits/max 15: end function  16: function SUPPmin|?uk(a) 17: r ? 0 18: for x ? {1, 2, . . . , |a|} do 19: shift? 0 20: while shift < intSize do 21: r ? r + ((a[x]? shift) & chunkMask) 22: shift? shift+ chunkSize 23: end while 24: end for 25: return r/max 26: end function  The SET method first gets the right position in the array (variable index at line 2) and the correct chunk within the integer on the index-th position (variable shift at line 3).

The value ? is then transformed to integer (at line 4) and finally stored into the correct chunk of array a using bitwise operations (lines 5 to 7).

The GET method works the opposite way. It gets the coordinates index and shift of value to be obtained (lines 11, 12) and uses them for decoding the value from chunks in array a (line 13). Finally, membership degree ? is returned by dividing the obtained value by max.

The SUPP function is pretty straightforward. It traverses through the elements of array a (the for loop at line 18), and for each integer a[x], the chunks are unpacked and their values added to r (line 21). Finally, since we add values from the {0, 1, . . . ,max} domain, we divide r by max to obtain sum of [0, 1] membership degrees.

CINTI 2013 ? 14th IEEE International Symposium on Computational Intelligence and Informatics ? 19?21 November, 2013 ?  Budapest, Hungary    B. The minimum t-norm implementation  The idea behind minimum t-norm implementation using bitwise operations is that minimum of the two numbers p and q can be deduced from the sign of p ? q: if negative, the minimum is p, else take q as the minimum.

The operation of subtraction is in computer processors most commonly implemented using the two?s complement. In two?s complement, positive numbers (and zero) have their normal binary representation. On the other hand, negative numbers ?q are encoded by inverting the bits of absolute value q, i.e.

creating the so-called one?s complement !(q), and adding 1 to the result:  ?q = !(q) + 1. (6)  For instance, a two?s complement of ?1 is 11111110+1 = 11111111. If trying to get a complement of 00000000, one obtains 11111111 + 1 = 00000000 because the overflow is discarded. On 8 bits, the range of values is ?128 to 127.

The two?s complement has many advantages and describing all of them is out of the topic of this paper. For our purposes, the most important things are that:  1) subtracting p? q is the same as adding a two?s comple- ment ?q to p (and ignoring the overflow);  2) all negative numbers have 1 (and all non-negative numbers have 0) in their most significant bit (i.e. a sign/overflow bit).

Let p, q be two integer numbers in binary format with intSize bits split into intSizechunkSize chunks so that bits 1 to chunkSize belong to the first chunk, bits chunkSize+ 1 to 2 ? chunkSize belong to the second chunk etc. Symbolically, let pk denote the k-th bit of p, p(i) denote the i-th chunk of p, and p(i)j denote the j-th bit of the i-th chunk, i.e.

p (i) j = p(i?1)?chunkSize+j .

Let the p, q?s chunks contain binary numbers from the set  {0, 1, . . . ,max}, as established by the SETmin|?uk function in the algorithm 2. The aim is to perform such bitwise operations that result in an integer number r that contains a chunk-wise minimum of p and q, i.e.

?i : r(i) = min(p(i), q(i)). (7)  Please observe that the chunkSize-th bit of each chunk is zero (i.e. p(i)chunkSize = 0, q  (i) chunkSize = 0 for each i ?  {1, 2, . . . , intSizechunkSize}).

Lemma 1. Let u, v be integers with chunkSize bits equal to any value from {0, 1, . . . ,max}, ?v be the one?s or two?s complement of v and w = u+ (?v). Then  wchunkSize = 1 ? min(u, v) = u (8)  and wchunkSize = 0 ? min(u, v) = v. (9)  Proof: Let ?v be in the two?s complement, i.e. ?v = !(v) + 1. Adding a positive number u to a negative two?s complement (?v) results directly in value u ? v, which, if negative, is in two?s complement. Therefore, the sign bit  wchunkSize = 1 if u ? v is negative (hence u < v, i.e.

min(u, v) = u), and wchunkSize = 0 if u? v is non-negative (hence u ? v, i.e. min(u, v) = v).

Let now ?v? be in the one?s complement, i.e. ?v? = !(v).

The value of u+(?v?) equals u?v?1 in two?s complement.

Therefore, the sign bit wchunkSize = 1 if u?v?1 is negative (hence u ? v, i.e. min(u, v) = u), and wchunkSize = 0 if u ? v ? 1 is non-negative (hence u > v, i.e. min(u, v) = v).

Lemma 2. Let q ?= 0 be an integer number with arbitrary chunks q(i) ? {0, 1, . . . ,max}, each chunk having chunkSize bits. Then there exists such k ? {1, 2, . . . , chunkSize} that:  1) ?i ? {1, 2, . . . , k ? 1} holds (?q)(i) = 0; 2) (?q)(k) is negative two?s complement of q(k); 3) ?j ? {k+1, k+2, . . . , chunkSize}, (?q)(j) is negative  one?s complement of q(j).



I.e. k is an index of the first non-zero chunk and that chunk is in two?s complement and any subsequent chunk is in one?s complement.

Proof: The q?s two?s complement is ?q = !(q) + 1.

Evidently, the +1 is added to the first chunk, !(q(1)).

Let first k ? 1 chunks of q equal to zero, i.e. !(q(i)) = 11 . . . 1, for any i ? {1, 2, . . . , k?1}. If adding +1 to !(q(1)), the result is (?q)(1) = 0 and overflown +1 is carried to the next chunk. That way all k ? 1 chunks get 0 value and cause carriage of +1 to the next chunk, . . . , and finally to the k-th chunk, which is non-zero. Since !(q(k)) ?= 11 . . . 1, adding +1 to it does not cause any carriage to the next chunk, and therefore, (?q)(k) is in two?s complement, while any subsequent chunk (?q)(j) = !(q(j) (for j ? {k + 1, k + 2, . . . , chunkSize}) is in one?s complement.

Theorem 1. Let p, q be two integer numbers split into chunks p(.), q(.) ? {0, 1, . . . ,max}, with the same number of chunks and with each chunk consisting of chunkSize bits. Let r = p+ (?q), where ?q is a two?s complement of q. Then  r (.) chunkSize = 1 ? min(p  (.), q(.)) = p(.) (10)  and r (.) chunkSize = 0 ? min(p  (.), q(.)) = q(.). (11)  Proof: Accordingly to lemma 2, there exists such k that (?q)(k) is in two?s complement, any (?q)(i) (for i < k) is equal to zero, and any (?q)(j) (for j > k) is in one?s complement. Then  1) r(i) = p(i) + 0, hence r(i)chunkSize = 0 because p (i)  is non-negative and less than 2chunkSize?1; evidently min(p(i), q(i)) = q(i) = 0;  2) r(k) = p(k) + (?q)(k), where (?q)(k) is in two?s com- plement, and because of lemma 1, the implications (10) and (11) hold;  3) r(j) = p(j) +(?q)(j), where (?q)(j) is in two?s comple- ment, if the adding in (j ? 1)-th chunk caused carriage of +1; otherwise, (?q)(j) is in one?s complement; either  M. Burda ? Fast Evaluation of T-norms for Fuzzy Association Rules Mining     way, lemma 1 says that the implications (10) and (11) hold.

Algorithm 3 presents the details of minimum t-norm im- plementation. Firstly, the elements p, q of arrays a, b are subtracted. Accordingly to theorem 1, the chunkSize-th bits (a.k.a. sign bits) of each chunk of the result equals 1 or 0 to indicates the position of the minimum value ? see line 5.

Everything except the sign bits is reset to 0 (the & operation at line 5), and by shifting and |-ing, a mask s of 00 . . . 0?s or 11 . . . 1?s is created for each chunk (see lines 6 to 10). That mask is then used to obtain the correct minimum value (see line 11).

Algorithm 3 Bitwise computation of the minimum t-norm 1: function TNORMmin(a, b) 2: r ? new array of size |a| 3: for x ? {1, 2, . . . , |a|} do 4: p? a[x], q ? b[x] 5: s? (p? q) & overflowMask  6: s? s | (s? 1) 7: s? s | (s? 2) 8: s? s | (s? 4)  9: ...

10: s? s | (s? 2log2(chunkSize)?1)  11: r[x]? (p & s) | (q & ! s) 12: end for 13: return r 14: end function  C. Implementation of ?ukasiewicz t-norm  For any membership degree ?, ? ? [0, 1], the ?ukasiewicz t-norm equals:1  ???uk ? = max(0, ?+ ? ? 1). (12)  We store the membership degrees ?, ? as fractions p, q of max:  ? = p  max , ? =  q  max . (13)  The values p, q are saved in chunks of bits of integers (see tables I and II) that are represented by the array elements a[x], b[x] in algorithm 4. The idea is that the ?ukasiewicz t- norm is computed as described by the subsequent theorem.

Theorem 2. Let p, q, r, s be integer numbers with chunkSize bits, p, q ? {0, 1, . . . ,max},  s =  { 011 . . . 1 if p+ q > max, 000 . . . 0 otherwise, (14)  r = (p+ q + 1) & s, (15)  and ?, ? be as in equation (13). Then ??uk(?, ?) = rmax .

Proof: Since p, q ? max and both have chunkSize bits, it is evident that the chunkSize-th bit is always zero. Also  1Please note that we strictly distinguish between max (function to obtain maximum of two numbers) and max (value defined in equation (4)).

note that p+q+1 ? max+max+1 = 2chunkSize?1; hence the sum p+ q + 1 never overflows chunkSize bits of r.

Firstly, let p + q ? max. Then s = 0 and thus r = 0.

Evidently also ? + ? ? 1 = pmax +  q max ? 1 ? 0, therefore  ??uk(?, ?) = 0.

Now let p + q > max. Then s = 011 . . . 1. Let also  z denote the sum p + q + 1, for a moment. Evidently, the chunkSize-th bit of z is set to 1 and performing z & s resets to 0 the z?s chunkSize-th bit only, which is the same as subtracting 2chunkSize?1 from z. Therefore, r = z & s = z ? 2chunkSize?1 = z ? (max + 1) = p + q ? max. From assumption p + q > max we get ? + ? > 1, therefore ??uk(?, ?) = ?+ ? ? 1 = rmax .

Algorithm 4 Bitwise computation of the ?ukasiewicz t-norm 1: function TNORM(a, b) 2: r ? new array of size |a| 3: for x ? {1, 2, . . . , |a|} do 4: p? a[x], q ? b[x] 5: t? p+ q 6: s? t & overflowMask  7: s? s | (s? 1) 8: s? s | (s? 2) 9: s? s | (s? 4)  10: ...

11: s? s | (s? 2log2(chunkSize)?2)  12: s? s | (s? 2log2(chunkSize)?1 ? 1) 13: s? s? 1 14: r[x]? (t+ oneMask) & s 15: end for 16: return r 17: end function  Algorithm 4 iterates through all the elements p, q of arrays a and b, and their sum is computed firstly (see line 5) and stored into temporary variable t. Please note that line 5 sums all chunks of p, q pairwisely, i.e. t(i) = p(i) + q(i) without the risk of carriage of +1 from one chunk to another (as discussed in proof of theorem 2).

After that, all chunkSize-th bits, t(i)chunkSize, of each chunk t(i) are extracted into s (see line 6) and multiple ?, | operations are performed to obtain for each chunk the bit masks s(i) equal to (14) ? see lines 7 to 13.

Finally, equation (15) is evaluated chunk-wisely at line 14 producing ?ukasiewicz t-norm of all corresponding chunks in p, q.



IV. PERFORMANCE ANALYSIS Performance measures were realized on Intel? Core? i7-  2600K CPU at 3.40GHz, 8192 KB cache size and 16 GB RAM, powered with the 64bit GNU/Linux operating system, kernel 3.5.0. The C++ source codes were compiled with GNU GCC 4.7.2 with (resp. without) ?-O3? optimizations that enable (resp. disable) use of Streaming SIMD Extensions (i.e. SSE intructions). The algorithm ran single-threaded, with intSize = 64 and chunkSize = 8. Separate run time mea- sures were treated for initialization, t-norm, and membership degree sum computation.

CINTI 2013 ? 14th IEEE International Symposium on Computational Intelligence and Informatics ? 19?21 November, 2013 ?  Budapest, Hungary    TABLE III COMPARISON OF ALGORITHMS? RUN TIMES  Flag Algorithm Init (ms) TNORM (ms) SUM (ms) Total (s) ? naive min 0.1275 0.0275 0.0325 0.31 ? opt. min 0.3306 0.0187 0.0325 0.29 ? naive luk 0.1275 0.0537 0.0325 0.44 ? opt. luk 0.3294 0.0138 0.0331 0.26  -O3 naive min 0.1231 0.0069 0.0106 0.10 -O3 opt. min 0.1850 0.0019 0.0081 0.07 -O3 naive luk 0.1125 0.0106 0.0106 0.12 -O3 opt. luk 0.1856 0.0019 0.0106 0.08  0.0  0.1  0.2  0.3  0.4  0.5  0 10000 20000 30000 40000 50000 data size (number of membership degree values)  to ta  l ru  n tim  e in  se co  nd s  algorithm  naive luk  naive min  opt. luk  opt. min  Fig. 1. Comparison of run time for different data sizes, with enabled compiler ?-O3? optimization that results in use of fast processor Streaming SIMD Extensions.

It is obvious that both naive and optimized TNORM imple- mentations have O(k ? n) complexity (for n = |A| = |B|).

However, they differ in constant k. Also the total run time is influenced by the initialization of all data structures (which is more complicated for the optimized variant) and by number of t-norms computed after a single initialization. To get close to reality, the following test scenario was considered:  1) Randomly initialize 100 different fuzzy attributes and store them into the memory.

2) Compute (  ) = 4950 times the TNORM and SUM  functions. That equals to computing support of all com- binations of a rule {A} ? {B}.

Table III summarizes the time complexity under various settings. ?Flag? specifies the used compiler optimization.

Columns ?Init?, ?TNORM? and ?SUM?, contain time in mil- liseconds for a single run of the initialization step, t-norm and membership degree sum computation, respectively. The ?total? column contains time for the whole test scenario, in seconds.

Figure IV captures the dependence of run time on data size.



V. CONCLUSION  This paper presented algorithms for computation of min- imum and ?ukasiewicz t-norms. The algorithms utilize a bitwise approach so that multiple membership degree values are stored into a single integer (hence less memory is needed) and bitwise operations on that integer compute in fact t-norms on many values at once. That way, some run time is spared.

Experiment shows that the t-norm computation alone runs 3?5 times faster. Together with essential initializations and sum computations, the difference between naive and optimized approach slightly decreases, however, on large datasets it still brings very significant time consumption savings. The run time savings remain evident even after enabling recent CPU?s SSE instructions that are designed for vectorized computations.

Future work will address more thorough performance anal- ysis (due to lack of space in this paper), and also experiments with implementations of other fuzzy t-norms.

