Ad Hoc Association Rule Mining as SQL3 Queries

Abstract  Although there have been several encouraging at tempts  at developing methods f o r  data min ing  using S Q L ,  simplicity and e f i c i ency  still r emain  significant impediments  f o r  further development.  I n  this paper, we  propose a significantly n e w approach and show that a n y  object relational database can be mined  f o r  association rules without a n y  restructuring o r preprocessing using only  basic S Q L 3  constructs and func t ions , and hence n o  additional machineries  are necessary. I n particular, we  show that the cost of computing association rules f o r  a given database does no t  depend o n  support and confidence thresholds. More precisely, the set of large i t ems  can be computed using one  simple j o i n  query and a n aggregation once the set of all possible meets  (least f ixpoint) of i t e m  set patterns in the  input  table i s  known .  T h e  principal f ocus  of this paper i s  t o  demonstrate that several S Q L S expressions exists f o r  the min ing  o f  association rules.

1 Introduction The motivation, importance, and the need for integrating data mining with relational databases has been addressed in several articles such as [3 ,  41. They convincingly argue that without such integration, data mining technology may not find itself in a viable position in the years to come. To be a successful and feasible tool for the analysis of business data in relational databases, such technology must be made available as part of database engines and as part of its declarative query language. Some of the benefits of using existing relational machinery may include opportunity for query optimization, declarative language support, selective mining, mining from non-transactional databases, and so on.

From these standpoints, it appears that research into data mining using SQL or SQL-like languages bear merit and warrant attention.

In this article, we demonstrate that there is a simpler SQLS expression for association rule mining that does not require candidate generation such as in [6, 51 or any implementation of new specialized operators such as in [2]. We also show that we can simply add a mine by operator to SQL, with an optional having clause to facilitate filtering of unwanted derivations, in a fashion similar to the cube by operator proposed for data warehousing applications. The striking feature of our proposal is that we can exploit the vast array of optimization techniques that already exists and possibly develop newer ones for better performance. These are some of the advantages of our proposal over previous proposals in addition to its simplicity and intuitive appeal.

0-7695-1 119-8/01 $17.00 0 2001 IEEE 609  2 A Set Theoretic Perspective of Data Mining  In order to introduce a few ideas, let us consider a database, called the transaction table, T as shown in figure 1.  Based on the traditional understanding of association rule mining we expect to  obtain the ?non-redundant?? large item set table (Ltable) and the rules table (r-table) shown in figure 1 below from the table T once we set the support threshold at 25%.

The reasoning process of reaching to the large item set and rules tables can be explained as follows.

le Items  a b  b  f b f a b  b e d f d  C  C  C  1-table  r-table  0.29 0.66 {b} {f} 0.29 0.40  {b,c} {a} 0.29 0.66 association rules table  Figure 1: Source transaction database T is shown as t-table, large item set table as I-table, and finally the association rules as r-table.

We can think of T as the set of complex tuples shown in nested table (n-table) in figure 2 once we nest the items on transaction numbers. If we use a group by on the Items column and count the transactions, we will compute the frequency table (f-table) that will show how many times a single item set pattern appears in the transaction table (t-table) in figure 1. Then, let us assume that we took a cross product of the frequency table with itself, and selected the rows for which  0 the Items column in the first table is a proper subset of the Items column in the second table, and finally projected out the Items column of the first table and Support column of the second table?, or  ?This will give us < { b ,  j } ,  1 > and < { d } ,  1 >    0 the Items columns are not subset of one another, and we took the intersection of the Items of both the tables, created a new relation (int-table, called the intersection table) with distinct tuples of such Items with Support 0, and then finally computed the support counts as explained in step 1 now with the frequency table and intersection table'.

This will give us the inheritance table (i-table) as shown in figure 2. Finally, if we took a union of the frequency table and the inheritance table, and then do a group by on the Items column and sum the Support column, we would obtain the count table (c-table) of figure 2.

n-table Tranid Items  Ia,b,c} t 5  @,e)  {d,f} t7  nested table  frequency table  ifable  inheritance table  c-table Support   ;able  Figure 2: n-table: t-table after nesting on Tranid, f-table: n-table after grouping on Items and counting, i-table: gener- ated from f-table, and c-table: grouping on Items and sum on Support on the union of i-table and f-table.

The entire process of large item set and association rule generation can be conveniently explained using the so called item set lattice found in the literature once we enhance it with some additional information. Let us consider placing the transactions with item set I appearing in the frequency table with their support count t as a node in such a lattice as shown in figure 3. Notice that in the lattice, each node is represented as I:, where it denotes the fact that  I appears in exactly t transactions in the source table, and that I also appears as a subset of other transactions n number of times such that c = n + t .  t is called the transaction count, or frequency count, and c is called the total count of item set I .

In the lattice of figure 3, the nodes marked with a solid rectangle are the nodes (or the item sets) in T, nodes identified with dotted rectangles are called the intersection nodes or the virtual nodes (as they do not appears in T explicitly), and the nodes marked with dotted ellipses are redundant. The solid ellipse nodes are redundant as well as  2The result of this will be tuple < { b ,  c}, 3 >, < { b } ,  5 >, and < { f } , 3  > in this example. Note that the intersection table will contain the tuples < {b,c},O >, < { b } , O  >, and < {f} ,o  >, and that these patterns are not part of the frequency table in figure 2. The union of step 1, and step 2 processed with the intersection table will now produce the inheritance table in figure 2.

Figure 3: Lattice representation of item sets in the database T.

they are not large item sets. The nodes below the dotted line, called the large item set envelope, or 1-envelope, are the large item sets. Notice that the node bc is a large item set but is not a member of T, while bc f , df and be are, yet they are not included in the set of large item sets of T. We are assuming here a support threshold of 25%. So, basically, we would like to compute only the nodes abc, bc, 6 f , 6, d and f from T. This set is identified by the sandwich formed by the I-envelope and the zero-envelope, or the z-envelope, that marks the lowest level nodes in the lattice.

The concept of node redundancy, and consequently large item set and rule redundancy are formalized as follows.

Definition 2.1 Let 7 be a transaction table over item sets 2, I Z be an item set, and n be a positive integer. Also let n represent the frequency of the item set I with which it appears in 7.  Then the pair ( I ,  n)  is called a frequent item set, and the pair is called a large item set if n 2 S,, where 6 ,  is the minimum support threshold.

If for any large item set I ,  its frequency n can be determined from other large item sets, then I is redundant. Formally,  Definition 2.2 (Redundancy'of Large Item Sets) Let L be a set of large item sets of tuples of the form ( Iu ,n%) such that Vz,y(s = ( I z , n , ) , y  = (Iy,ny) E L A  I ,  = Iy 3 n, = ny) ,  and let U = (Iu, nu)  be such a tuple. Then U is redundant in L if 3v(v E L ,  v = (I , ,  n,), I ,  C_ I ,  * nu = nu).

The importance of the definition 2.2 may be highlighted as follows. For any given set of large item sets L ,  and an element 1 = ( I i , n l )  E L ,  If is unique in L.  The implication of anti- monotonicity is that for any other w = (I,, n,) E L such that If C I ,  holds, n, 5 nf because an item set cannot appear in a transaction database less number of times than any of its supersets. But the important case is when n, = n1 yet If c I,.

This implies that If never appears in a transaction alone, i.e., it always appeared with other items. It also implies for all large item sets s = (Is,ns) E L of I ,  such that I ,  2 I,, if it exists, nu = ns too. As if not, nf should be different than n,, which it is not, according to  our assumption. It also implies that If is not involved in any other sub-superset relationship chains other that  I,.

Because redundant large item sets exists, traditional mining algorithms such as apriori generates all possible rules, some of which are essentially redundant. For example, let a +- b ( % , y )  and ab +- c ( % , % )  be two rules discovered from a any tracsaction table F f ,  where sx and m represent respectively the frequency of an item set X in     the item set table and the number of transactions in the item set table S. Then it is also the case that the set of discovered rules contains another rule (transitive implication) a + bc(%, F). Notice that this last rule is a logical consequence of the first two rules that  can be derived using the following inference rule, where X, Y,  Z C Z are item sets.

x -+ Y(*, y) x U y + z(sxumyuz, "-:;:;" ) x + Y U Z (  sxumyuz, s x " ~ u ~ )  sx  Written differently, using only symbols for support (6) and confidence ( q ) ,  the inference rule reads as follows.

x U Y + Z ( 6 2 , ? l 2 )  x + Y(61.171) x + Y U Z(S2,q * 72)  Based on these observations, we take the position and claim that the table I-table shown in figure 1 is an information equivalent table of the large item set table produced by apriori on T, which essentially means that these tables faithfully imply one another (assuming identical support thresholds).

3 SQL3 Expressions for Computing Association Rules  Now that we have explained what non-redundant large item sets and association rules mean in our framework, we are ready to discuss cornputing them using SQL. The reader may recall from our discussion in the previous section that we have already given this problem a relational face by presenting thein in terms of (nested) tables. We will now present a set of SQL3 sentences to compute the tables we have discussed earlier. We must mention here that it is possible to evaluate the final table in figure 1 by mimicking the process using a lesser number of expressions than what we present below. But we prefer to include them all separately for the sake of clarity.

For the purpose of this discussion, we will assume that several functions that we are going to use in our expressions are available in some SQL3 implementation, such as Oracle, DB2 or Informix. Recall that SQL3 standard requires or implies that, in some form or other, these functions are supported3. In particular, we have used a nest by clause that functions like a group by on the listed attributes, but returns a nested relation as opposed to a first normal form relation returned by group by. We have also assumed that SQL3 can perform group by on nested columns (columns with set values). Finally, we have also used set comparators in where clause, and set functions such as intersect and setminus in the select clause, which we think are natural additions to SQL3 once nested tuples are supported. As we have mentioned before, we have, for now, used user defined functions (UDFs) by treating set of items as a string of labels to implement these features in Oracle.

create view n-table as (select Tranid,  I t e m s from 1-table nest by Tranid) create view f-table as (select I t e m s ,  c o u n t ( * )  as Support from n-table group by I t e m s )  3Although some of these functions are  not supported right now, once they are, we will be in a better shape. Until then, we can use PL/SQL codes to realize these functions.

The two view definitions above prepare any first normal form transaction table for the mining process. Note that these view definitions act as idempotent functions on their source.

So, redoing them does not harm the process if the source table is already in one of these forms. These two views compute the n-table and the f-table of figure 2.

Before we can compute the i-table, we need to know what nodes in the imaginary lattice will inherit transaction counts from some of the transaction nodes in the lattice - Support value of Items in the f-table. Recall that  nodes that are subset of another node in the lattice, inherit the transaction count of the superset node towards its total count. We also know that only those (non-redundant) nodes which appear in the f-table, or are in the least fixpoint of the nodes in f-table will inherit them. So, we compute first the set of intersection nodes implied by f-table using the newly proposed SQL3 create view recursive statement as follows.

create view recursive int-table as ((select distinct intersect (1. I t e m s ,  p .  I tems) ,  0 from f-table as t, f-table as p where t . I t e m s  @ p . l l e m s  and p . I t e m s  @ t . I t e m s  and not exists (select * from f-table as f where f .  I t e m s  = intersect( t . I tems ,  p .  I t e m s ) ) )  union (select distinct intersect (1. Ite.ms? p . I tems) ,  0 from int-table as 1, int-table as p where t . l t e m s  @ p . l t e m s  and p.1tem.s @ t . I t e m s  and not e x i s t s  (select * from f-table as f where f . I t e m s  = i n t e r s e c t ( t . l t e m s ,  p . l t e m s ) ) ) )  We would like to mention here again that we have implemented this feature again using PL/SQL in Oracle.

Notice that we did not list the int-table we create below in figure 1 or 2 because it is regarded as a transient table needed for the computation of i-table.

It is really important that we create only distinct set of intersection items and only those ones that do not appear in the f-table for the purpose of accuracy in support counting.

Take for example three transactions in a new frequency table, f'-table, represented as {abck, bcd:, bc fd ,  bc;}. Assume that we compute the set of intersections of the entries in this table.

If we do not guard against the cautions we have mentioned, we will produce the set {bc:, bc:, bc:} using the view expression for int-table - which is not desirable. Because, these three will inherit Support from {abck, bcd:, bc fd}  giving a total count of 10, i.e., bcio. The correct total count should have been bc:. If we just ensure the uniqueness of a newly generated item set (but not its absence in the f-table) through meet computation, we still derive {bc:} instead of an empty set, which is incorrect. This means that not including the following condition (or its equivalent) in the above SQL expression will be a serious mistake.

not exists (select * from f-table as f where f . I t e m s  = i n t e r s e c t ( t . I t e m s ,  p . I t e m s ) Once we have computed the int-table, the rest of the task  is pretty simple. The i-table view is computed by copying the Support of a tuple in f-table for any tuple in the collection of f-table and int-table which is a subset of the tuple in the f-table. Intuitively, these are the nodes that need to inherit the transaction counts of their ancestors (in f-table).

create view i-table as (select t .  I t ems ,  p .Support from f-table as p ,  ((select * from f-table) union (select * from int-table)) as t ,  where t . I t ems  C p . I t e m s ) From the i-table, a simple grouping and sum operation as  shown below will give us the count table, or the c-table, of figure 2.

create view c-table as (select t .  I t ems ,  sum( t .Suppor t )  as Support from ((select *  from f- table) union (select * from i- table)) as t  group by t . f t ems ) The large item sets of 1-table in figure 1 can now be  generated by just selecting on the c-table tuples as shown next. Notice that we could have combined this step with the c-table expression above with the help of a having clause.

create view l-table as (select Items, Support from c-table where Support 2 hm) Finally, the (non-redundant) association rules of figure 1  are computed using the r-table view below. The functionality of this view can be explained as follows. Two item sets ~ [ f t e m s ]  and v [ f t e , m s ]  in a pair of tuple U and in the I-table implies an association rule of the form u [ f t e m s ]  -+ v [ f t e m s ]  \ u [ ~ t e m s ] ( v [ ~ ~ p p o r t ] ,  M) only if u l ~ t e r n s l  c w11temsl and there does not exist any intervening item set z in the 1-table such that z is a superset of ~ [ I t e m s ]  and is a subset of ~ ( l t e m s ]  as well. In other words, in the lattice, ~ [ I t e m s ]  is one of the immediate ancestors of ~ [ I t e m s ] .  In addition, the ratio of the Supports, i.e., s a  must be at least equal to the minimum confidence threshold qm.

create view r-table as (select a. I tems ,  c. Items\a. I t ems ,  c.Support,  from 1-table as a, 1-table as c where a . f t e m s  c c . I tems  and c . I t e m s / a . I t e m s  2 qm  c .  Support/a.  Support  and not exists (select I t e m s from 1-table as i where a. I t e m s  c a. I t e m s  and a. I t e m s  C c.Ztems))  The readers may verify that these are the only ?generic? SQL3 expressions (or their equivalent) that are needed to mine any relational database (assuming proper name adapta- tions for tables and columns). The essence of this relational interpretation of the problem of mining, as demonstrated by the SQL3 expressions above, is that  we do not necessarily need to think procedurally - in terms of number of iterations, can- didate generation, space time overhead, and so on. Instead, we can now express our mining problems on any relational database in declarative ways, and leave the optimization is- sues with the system and let the system process the query using the best available method to  it, recognizing the fact that depending on the instance of the database, the choice of best methods may now vary widely.

In another recent research [l] we have demonstrated that to  implement apriori in SQL3, one need not be constrained by the complexity and availability of combination and GatherJoin [7, 61 operators. Without much discussion we present below the set of SQL3 queries (see [l] for details) that  correctly implement apriori. Again, a comparison with the works in [6, 21 will expose the strength and simplicity of our proposal.

