Combination Tree for Mining Frequent Patterns Based on Inverted List

Abstract In this paper, a combination-tree algorithm is  presented for mining frequent patterns based on inverted list. Compared with Apriori algorithm and FP-growth algorithm, our algorithm has better efficiency. Our algorithm insert items one by one with inverted list to buildfrequent tree, then transfer count between branches in order to make branches independent. our algorithm need only scan data set twice, can share more common items of transactions, can omit the local infrequent items, at the same time, avoid lots of recursive operations. Our performance study and theory analysis show that it is efficient in both dense datasets and sparse datasets.

Keywords: data mining, frequent patterns, inverted list, combination tree.

1. Introduction  The problem of mining frequent patterns is present as follow: Let I=(I1, 12,..., I} is a set of lots of items, and T=(TI, T2,..., Tn} is a set of all transaction in data library and TicsI.f set of items A is subset of I. The support of A is the number of transaction in D and A.

When the support ofA is bigger than a number defined by user, A is calledfrequentpatterns.

There are two kinds of algorithms for mining frequent patterns: Apriori algorithm and FP-growth algorithm. Apriori algorithm is efficient for mining short frequent patterns. But when the length of frequent patterns is big, the efficiency of Apriori algorithm becomes bad. FP-growth algorithm has no this defect. But when mining frequent patterns for sparse data such as commercial sales data, which has large amount transactions and short frequent patterns, we have to build lots of sparse FP-tree which share few prefix, so the efficiency of mining frequent patterns on such FP tree is awful.

Hu Yun-Fa Computer and Information Technology  Department, Fudan University Shanghai 200433, China huyunfa fudan. edu. cn  This paper present a Combination Tree algorithm based inverted list named ComTree algorithm, which has better efficiency than Apriori algorithm and FP- growth algorithm in sparse and dense data-set.

2.The disadvantage of FP-growth algorithm and an example of ComTree  2.1 The disadvantage of FP-growth algorithm  FP-growth algorithm shares some common items of all transactions. It has better efficiency than Apriori algorithm. But it still has some disadvantages.

1 It has to build lots of dynamic FP sub-trees in the process of mining, which bring to lots of recursive function calls and effect the efficiency of algorithm.

2:The efficiency of algorithm for large scale sparse data-set is awful.

3:FP-growth algorithm can only share prefix of transactions.

2.2 The idea of ComTree algorithm  Now we describe the step of ComTree algorithm.

Example 1. let a data-set as table 1,the minimal  support is 2.

The transactions behind T5 don't include I1.For  simplify the example, we only consider the sub-tree has I1 as root node. FP-growth algorithm builds a sub- tree show as figurel.

Because nodes 5 and nodes 4 have more than one node, they include more than one branch . For this case ,FP-growth algorithm needs to build dynamic FP sub- tree. When the amount of node increases, the amount of branch of FP increases too, and the amount of dynamic FP sub-tree and recursive call increases.

Branches in FP tree is dependant, while our algorithm is to make all branches relatively independent by transfer counts between branches and then gain all  1-4244-0605-6/06/$20.00 C2006 IEEE. 805    frequent patterns through combination of all independent branches. In fact the FP tree shown as figure 1 approximately equal to the tree shown as figure 1' figure l'includes all frequent patterns in figure 1. But figure I' includes repeated patterns with  Table 1 data-set.

transactions items  T, | 11,12,13, 14,15 T2 |11,12,13,15 T3 |I, 14,15 T4 11,12,16 T5 12,16  a4 :4 2b3 4:1 2b 4e:2 5 g:3  3c2 i:1 5 h:13c2\3 f:2 /d:1 5 f:1  |'e: 1 5 d:2 51e:1I  Figure 1 Figure 1' different count. For example path 1235 includes 15 and path 145 also includes 15. We can combine each path and then omit repeated patterns. By this way, we can reduce lots of recursive call. Now we build the tree shown as figure 1'. Because in FP-growth algorithm ,we insert transactions one by one into former tree to build new tree. In this way, we can't implement the change from figure 1 to figure 1' easily. So we insert items one by one to build new tree.

3.The ComTree algorithm for mining frequent patterns based on inverted list.

3.1 frequent branch and count transferring  Definition 1: frequent-sub-branch. For every non- root node in tree shown as figure 1 there is a corresponding path from this node to root node. When path A and path B meet the conditions below, we call path B is the frequent-sub-branch(FSB) of path A.

(I)The node corresponding to path A and the node corresponding to path B represent same item. (2) The node corresponding to path B is frequent.(3) All items in path B can be found in path A. Which also mean that path B can gain through combination of path A.

In same way , we can define frequent-sub-branch- node(FSBN).

Definition 2: close-frequent-branch-set. There is a set X, which includes and only includes all frequent-  sub-branch of path A. when set Y meet the conditions below, we call Y is the close-frequent-sub-branch- set(CFSBS) of path A. ( 1 ) set Y is a sub-set of set X.

( 2 ) The path in set X is either the path in set Y or the  frequent-sub-branch of path in Y. ( 3 ) Y is the minimal sub-set which meet condition ( 1) and ( 2 ) . In same way, we can define close-frequent-branch- node-set(CFBNS).

Now we consider about finding out FSB, adding a new node and transferring count. Consider the FP tree shown as figure 2-a.In the way of insertion items one by one, after insert item I and I2, we get the tree shown as 2-b. After insert item I3, we save the count relative to 13 into the nodes in figure 2-b ' save the count of 111213 into node b and the count of 1113 into node a.

Because 111213 includes 1113, we transfer the count of node b to it's parent node a. So the count of node a is 3. Because the count of node b is 2,which equal to minimal support, so we add a new node c below node b. And the count of node a is bigger than the count of node b, so we also add a new node d below node a.

We get the tree shown as figure 2-c. Path da is a frequent-sub-branch of path cba. If the count of node a equal to count of node b, we don't add a new node below node a because path da can be obtained through combination of path cba. When we insert 14, we save the count of 11121314 into node c. We will transfer the count of node c to its parent node b and a, and also transfer the count to its FSBN d.

a:3 a:3 a:3  2 3d13 2 22b:2 2b:2 2b:2~~~3d:3 3c:2 4 f: 1 3c:2  4 e:2 rigLue 2-a Figure 2-b Figure2-c  Consider the FP tree shown as figure 3-a. In the way of insert items one by one, after insert 11,12 and 13, we gain the tree shown as figure 3-b. After insert 14 and transfer count, the count of node a is 2 and the count of other node is 1. We add a new node f and new branch fa shown as figure 3-c, because there are not corresponding node and branch in corresponding FP tree, we call them virtual node and virtual branch respectively. Through adding virtual branch, we can share more common items between transaction which can't be shared in FP tree. The frequent-sub-branch- node of node c and e are all node f. When insert item 15, we transfer the count of node c and node e to node f.

We find out the node position in tree to increase count when inserting new item through transaction-frequent- set. Initially, all transaction-frequent-set are null.

When inserting the first item, we add a new node, and  1-4244-0605-6/06/$20.00 C2006 IEEE. 806    put the pointer that point the new node into the corresponding transaction-frequent-set according to inverted list of items. After that, insert the later item, find all corresponding transaction-frequent-set according to items inverted list, and find corresponding pointer, add 1 to the count of corresponding node which we call scan-node because we access them by scanning transaction-frequent-set. After scan all transaction-frequent-set, we transfer the count of scan- node to relative node. At first we transfer the count of the node to all FSBN. Secondly  a:4 a a:4  2b:'2 3d:2 2:2 34d2 2fb. d:2 4c:1 4e:1/I  4 c:1 4 e:1 5f:1 5g:1  Figure 3-a Figure3-b Figure3-c transfer the count to it's parent node and all frequent- sub-branch-node of it's parent. Repeat the operations until root node. After the transferring, add new node according to the count of relative node. At end, update the pointer in transaction-frequent-set. Then we insert next item until all items be inserted.

3.2 Add a new node and find frequent-sub- branch-node-set  If the count of root node is less than minimal support after transfer count, the newly inserted item is locally infrequent in this tree. So we don't add a new node for this item in this tree. In this way, we reduce lots of unnecessary items in all trees. We find out CFSBN of the new node while add a new node.

Because some nodes have lots of FSBN, we only save close-frequent-branch-node in each node for reducing the data saved in tree. We can access all frequent-sub- branch-node of a node layer by layer. Now we begin from scan-node to add new node and find out frequent- sub-branch-node-set layer by layer.

There are two directions to find out FSBN. Let a node r and a new node s added below node r. At first, we consider the close-frequent-sub-branch-node of node r. We put all CFSBN into a temporary queue named queue-temp. Dequeue the node one by one. If the node is set a access mark, dequeue the next node.

When a dequeueed node t has the count bigger than the count of node r, if there has been a new added node u below node t, we put node u into the CFSBNS of node s and set access mark to all nodes on the path corresponding to node t and FSB of it. If there isn't a new added node below node t, we add a new node u, and put u into the CFSBNS of node s. At same time, find out the closed-frequent-sub-branch-node-set of  node u by recursive way, and set access mark during recursive process. If the count of node t equal to the count of node r, put all of close-frequent-sub-branch- node into queue-temp. Repeat above operations until queue-temp is null.

Then we consider the direction of ancestor of node r. when an ancestor node v has count bigger than the count of r, if there isn't a new added node below node v, we add a new node w below node v( at same time find out the CFSBNS of node w by recursive way), or there has been a new node w, we both put w into the CFSBNS of node s and complete the process of finding. If node v is set access mark, complete the process of finding. Else put the CFSBNS of node v into queue-temp, repeat the dequeue operations.

Complete the process until the root node.

3.3Transferring count to FSBN and siblinglist node  We can transfer the count of all scan-node in way of temporary queue. Let a scan-node x and it's count is m. At first, we put all close-frequent-sub-branch-node of x into queue-temp. Then dequeue node one by one.

For a node y isn't set access mark, add m to the count of node y and set access mark to node y and put all CFSBN into queue-temp. Repeat above operations until the queue-temp is null.

We can transfer the count to nodes in siblinglist in same way.

3.4 The combination of frequent branch  After insert all items, we do traversal to trees.

When we access a new frequent node, we gain a new path for combination. When a node is infrequent, we don't consider it and the node below it. Through combining these paths and omitting the same frequent patterns, we can gain all frequent patterns.

3.5 ComTree algorithm for mining frequent patterns based on inverted list  We can get the ComTree algorithm for mining frequent patterns based on inverted list as follow: Algorithm 1:ComTree algorithm for mining frequent patterns based on inverted list.

Input :transaction set D 'minimal support?8 Output: all frequent patterns step: 1. Scan D one time to get inverted list and support  count of all single items.

2. Omit all single items which support is less than  ? ' and sort the left items in increase order.

1-4244-0605-6/06/$20.00 C2006 IEEE. 807    3. Create a null transaction-frequent-set (TF)for all single frequent items.

4. Insert frequent item one by one, find pointer in corresponding transaction-frequent-set with inverted list, add 1 to the corresponding node.

5. Transfer the count of all scan-node to their FSB.

6. Begin from scan-node, add corresponding node  and put the CFSBN into the member field in these node.

7. Update the pointer in corresponding transaction- frequent-set.

8. Repeated the operations in step 4-7, until all items are inserted.

9. Gain paths through traversal of all tree, then deal with the combination of all paths, omit all repeated frequent patterns, output them.

4.Experimental evaluation  4.1. Environment and dataset characteristics  In this section, we will compare the efficiency of Apriori, FP-growth and ComTree based on experiments. The programming language is C++. All experiments are run on a PC with 500MHz Celeron CPU and 512M memory.

The data set are publicly available from IBM Almaden (www.almaden.ibm.com). Mushroom is a dense data set and T4011ODl00K is sparse data.

4.2.Experiment result  The experiment result on given data set are shown below. The ordinate of the figure is mining time with second as unit. And abscissa is support.

For dense data set, because the efficiency of Apriori algorithm is bad. So we don't compare with it.

We only provide the comparison with FP-growth. The experiment result is shown in figure 4-a. From the  1000 + ComTree 500 -  800 -FP / 400 600 ~~~~~~~~300 400 200  FP  1~~~~~~~~00 0~~~~~~~~~~0  0.1 0.08 0.06 0.04 0.02 0 0.1 0.08 0.06 0.04 0.02  Figure 4-a Mushroom Figure 4- b T40I1OD10K  recursive call increase rapidly too. ComTree algorithm avoid lots of recursive call and improve it's efficiency  From the result of figure 4-b, for sparse data set, when the support is big, the performance of Apriori algorithm is good. When support becomes smaller, the efficiency of Apriori algorithm decreases. For sparse data set, the efficiency of mining frequent items with FP-Tree is awful. And the efficiency of ComTree algorithm is better than the efficiency of Apriori algorithm.

5.Conslusion  Compared with FP-growth algorithm, ComTree algorithm can omit locally infrequent items and share more common items between transactions and avoid lots of recursive calls. The experiments also show that the efficiency of ComTree algorithm is better than the efficiency of Apriori algorithm and FP-growth algorithm in both dense and spare data-set.

Reference  [1] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. Int 1 Conf. Very Large Data Bases 487-499(September 1994).

[2] Jiawei Han, Jian Pei and Yiwen Yi. Mining Frequent Patterns without Candidate Generation.

Proc. 2000 ACM-SIGMOD Int. Conf.

