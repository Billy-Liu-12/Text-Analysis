Content-based Retrieval of Medical Images by Continuous Feature Selection?

Abstract  Feature selection can significantly improve the preci- sion of content-based queries in image databases by remo- ving noisy features or by bursting the most relevant ones.

Continuous feature selection techniques assign continuous weights to each feature according to their relevance. In this paper, we propose a supervised method for continuous fea- ture selection. The proposed method applies statistical as- sociation rules to find patterns relating low-level image fea- tures to high-level knowledge about the images, and it uses the patterns mined to determine the weight of the features.

The feature weighting through the statistical association ru- les reduces the semantic gap that exists between low-level features and the high-level user interpretation of images, improving the precision of the content-based queries. More- over, the proposed method performs dimensionality reduc- tion of image features avoiding the ?dimensionality curse? problem. Experiments show that the proposed method im- proves the precision of the query results up to 38%, indi- cating that statistical association rules can be successfully employed to perform continuous feature selection in medi- cal image databases.

1. Introduction  Image mining has been focused by many researches in the field of data mining and information retrieval in current years. A major challenge of the image mining field is to effectively relate low-level features (automatically extrac- ted from image pixels) to high-level semantics based on the human perception.

When working with image databases, high-level data manually supplied by domain experts can also be employed together with low-level features in the image mining pro- cess. However, with the fast growing of large-scale image repositories, manual annotation of images has become un- feasible, because of its inherent problems of subjectivity,  ?This work has been supported by FAPESP and CNPq.

non-scalability, as well as non-uniformity of vocabulary.

Content-based image retrieval (CBIR) systems are propo- sed to overcome these limitations, where the most similar images of a given one are retrieved based on comparisons of visual features (automatically extracted from images). The retrieved images can be employed to label a new one or, in case of medical images, to help the decision making process of diagnosing a new image.

Generally, CBIR techniques use intrinsic visual features of images, such as color, shape and texture yielding vec- tors with hundreds or even thousands of features. The large number of features actually represents a problem. It leads to the ?dimensionality curse? problem [5], where the inde- xing structures degrade and the significance of each feature decreases, making the process of storing, indexing and re- trieving extremely time consuming. Moreover, in several situations, many features are correlated, meaning that they bring redundant information about the images that can de- teriorate the ability of the system to correctly distinguish them. To avoid this problem, feature selection techniques can be employed to reduce the feature vector size.

Another problem is the semantic gap where the low-level features automatically extracted from images do not satis- factorily represent the semantic interpretation of the ima- ges. Image mining techniques that associate low-level fe- atures with high-level knowledge about the images can be employed in order to diminish the semantic gap.

In this paper, we propose a method that deals with the ?dimensionality curse? and the semantic gap problem. The method applies statistical association rule mining to relate low-level features with high-level specialist?s knowledge about the image, in order to reduce the semantic gap exis- ting between the image representation and interpretation.

These rules are employed to weight the features according to their relevance. The dimensionality reduction is perfor- med by discarding the irrelevant features (the ones whose weight are null). The obtained weights are used to calculate the similarity between the images during the content-based searching. Experiments performed show that the proposed method improves the query precision up to 38%. Moreover, the method is efficient, since the complexity of the query  21st IEEE International Symposium on Computer-Based Medical Systems  DOI 10.1109/CBMS.2008.82   21st IEEE International Symposium on Computer-Based Medical Systems  DOI 10.1109/CBMS.2008.82   21st IEEE International Symposium on Computer-Based Medical Systems  DOI 10.1109/CBMS.2008.82   21st IEEE International Symposium on Computer-Based Medical Systems  DOI 10.1109/CBMS.2008.82     processing decreases along the dimensionality reduction of the feature vector.

The rest of this paper is structured as follows. Section 2 summarizes the concepts and related works needed to understand our method. Section 3 presents the proposed method, while Section 4 discusses the experiments and re- sults achieved with the developed method. Finally, Section 5 presents the conclusions of this work.

2. Background and Techniques  Mining of association rules [1, 8] is one of the most in- vestigated areas in data mining. Currently, finding associati- ons has been widely used in many applications such as cus- tomer categorization, data classification and summarization [6, 7]. Mining images demands to extract their main featu- res regarding specific criteria. After extracted, the feature vector and image descriptions are submitted to the mining process.

Performing exact searches on image datasets are not use- ful, since searching for the same data already under analysis has very few applications. Thus, the retrieval of complex data is mainly performed regarding similarity. The most well-known and useful types of similarity queries are the k-nearest neighbor (e.g. ?given the Thorax-XRay of John Doe, find in the image database the 10 images most similar to it?), and range queries (e.g. ?given the Thorax-XRay of John Doe, find in the image database the images that dif- fer up to 4 units from it?). Similarity search is performed comparing the feature vectors using a distance function - or dissimilarity - function to quantify how close (or similar) each pair of vectors is. We focus our work on medical ima- ges, more specifically on the feature vectors employed to compare and retrieve the images by similarity. The motiva- tion is to weight the features according to their contribution to the high-level semantic interpretation, sifting the featu- res that keep the majority of image information, making the image retrieval processing more efficient.

The distance functions most widely employed to per- form similarity queries are those of the Minkowski family (or Lp norm) [11], which is usually employed over vector spaces. In a vector space, the objects are identified with n real-valued coordinates {x1,..., xn}. Considering two fea- ture vectors F = {f1,..., fn} and G = {g1,..., gn}, the Lp distances are defined as:  Lp((f1, ..., fn), (g1, ..., gn)) = p  ???? n? i=1  |fi ? gi|p (1)  According to the value assigned to p we obtain the Lp fa- mily variations. The Lp distances are additive, in the sense that each feature contribute independently to the distance  measure. The well-known Euclidean distance corresponds to L2. The L1 distance also called City Block or Manhattan, corresponds to the sum of the differences along the coordi- nates. The L? also known as Infinity or Chebychev cor- responds to taking the limit of equation 1 when p tends to infinity. The result obtained by the computing of L? dis- tance is the maximum difference of any of its coordinates. A variation of the Minkowski family distance is the weighted Minkowski, where different weights are assigned to each feature from a given image. The idea behind the weighted Minkowski is to introduce weighting to stress important fe- atures. Thus, it is used when there are different influences between the features that will affect the similarity compa- rison. This distance admits that different contexts requires different weighting vectors, considering that some features presents a higher or lower relevance regarding to others in a given context. The Weighted Minkowski is formally defi- ned as:  dLp(F,G) = p  ???? n? i=1  wi (fi ? gi)p (2)  where wi is the weighting vector wi = (w1, w2, ..., wn).

Dimensionality reduction (also called dimension reduc-  tion) is the process of reducing the number of features (attri- butes or dimensions) used to represent a dataset under con- sideration. Techniques of dimensionality reduction can be supervised or unsupervised. While supervised techniques need a pre-classified training set, the unsupervised techni- ques do not.The dimensionality reduction approaches are also classified into feature selection and feature transfor- mation approaches. The key difference between feature se- lection and feature transformation is that the former consists in selecting a subset of the original features, while the later generates a completely new set of features to represent a gi- ven dataset. Feature selection approaches do not transform the original features; they only remove the subset of redun- dant and irrelevant features, preserving the semantical me- aning of the original data. Feature selection techniques can be divided into binary and continuous techniques. Continu- ous feature selection techniques assign continuous weights to each feature, while the binary approach assigns binary weights to each feature. In this paper, we present a new supervised method of continuous feature selection that im- proves similarity queries, by weighting the image features according to their relevance.

2.1. Statistical Association Rule Mining  The essence of our approach is the concept of association rule mining. Traditionally, the problem of mining associa- tion rules consists to find relationships of the form A ? B, where A an B are set of items, indicating that A and B frequently occurs together in the database transactions, and     that, if A occurs there is a high probably that B also oc- curs. These type of rules work well when dealing with cate- gorical (nominal) data items. However, when dealing with image features that consists of continuous attributes, a type of association rule that considers continuous values is ne- cessary. A recent type of continuous association rules is the statistical association rules, which are rules generated using statistical measurements.

Our proposed method employs an algorithm, named StARMiner [9], to mine statistical association rules from features of a training dataset. The mined rules are used to weight the features according to their relevance, making a new and enhanced representation of the images.

Let T be a dataset of medical images, xj an image class, Txj ? T the subset of images of class xj and fi the ith feature of the feature vector F . Let ?fi(Z) and ?fi(Z) be, respectively, the mean and standard deviation of the values of feature fi in the subset of images Z. The algorithm uses three thresholds defined by the user: ??min - the minimum allowed difference between the average of the feature fi in images from class xj and the average of fi in the remai- ning dataset; ??max - the maximum standard deviation of fi values allowed in a given class and; ?min - the minimum confidence to reject the hypothesis H0. StARMiner mines rules of the form xj ? fi, if the conditions given in Equa- tions 3, 4 and 5 are satisfied.

?fi(Txj )? ?fi(T ? Txj ) ? ??min (3)  ?fi(Txj ) ? ??max (4)  H0 : ?fi(Txj ) = ?fi(T ? Txj ) (5)  In Equation 5, H0 should be rejected with a confidence equal to or greater than ?min, in favor of the hypothesis that the means ?fi(Txj ) and ?f (T ? Txj ) are statistically diffe- rent. A rule xj ? fi, returned by the algorithm, relates a feature fi with a class xj , where values of fi have a statisti- cally different behavior in images of class xj . This property indicates that fi is an interesting feature to distinguish ima- ges of class xj from the remaining images.

The StARMiner algorithm associates classes and featu- res with the highest power to distinguish the images. The features returned in the rules have a particular and uniform behavior in images of a given category. This is important, because the features presenting uniform behavior to every image in the dataset, independently of the image category, do not contribute to categorize them and should be elimi- nated. Hence, the StARMiner rules are very useful to re- veal the relevance of the image features. The rules obtained are employed to perform continuous feature selection in the way explained in the Section 3.

We called in this paper as the StARMiner feature selec- tion, the procedure of using only the features that return at  least one rule by the STARMiner algorithm (without weigh- ting) to compose the feature vector.

3. The Proposed Method  An important question is how to use statistical associa- tion rules to weight the image features. Suppose that the images were classified in m high-level classes X = x1, x2,..., xm. For each feature fi, StARMiner tries to find rules of the form xj ? fi. That is, StARMiner aims at relating each feature fi to each class xj . If a rule xj ? fi is found, it means that the feature fi well discriminate the images from class xj . Therefore, the most discriminative features fi are the ones that generates rules xj ? fi, for every xj ? X , meaning that they discriminate well all image classes. In the same way, the least discriminant features are the ones that do not generate any rule, meaning that they have a uniform behavior among all classes, being not useful to distinguish them. Thus, to weight a feature fi, our proposed method uses the number of mined rules where fi appears. Equation 6 shows the weighting assigned to each feature fi:  wi = 10ri + q (6)  In Equation 6, ri is the number of mined rules where feature fi appears. q is a constant that receives the values q = 0 or q = 1. The use of q = 0 means that it is desi- rable to remove the features that do not generate any rule, because they are the ones with the least power of distin- guishing image classes. When q = 1 is used it means that all the features are kept and weighted by relevance. So, when q = 0, it is performed dimensionality reduction of the feature vector, and when q = 1, all features are weigh- ted according to their relevance. By replacing the weight value in Equation 2 (the Weighted Minkowski distance), it is obtained the formula of the distance function used in the proposed method:  dLp(F,G) = p  ???? n? i=1  (10ri + q) (fi ? gi)p (7)  The proposed method is a supervised approach that deals with two inherent drawbacks of a CBIR system, the seman- tic gap and the high dimensionality of feature vectors. We amend these restrictions by using the association rules to weight the features according to their relevance. The steps of the proposed method are illustrated in Figure 1.

The proposed method is divided in two phases: training phase and test phase. The training phase is composed of th- ree steps: (1) feature selection, (2) association rule mining, (3) continuous feature selection. The test phase employs the weights found in the last step of the training phase to perform similarity searches.

Figure 1. Pipeline of the proposed method.

4. Experiments  This section presents experimental results of using our proposed method in executing similarity queries. To evalu- ate the proposed method, we have generated precision and recall (P&R) graphics [2]. The precision and recall are de- fined as:  precision = |RA| |R|  recall = |RA| |A|  (8)  where, RA is the number of retrieved images that are re- levant; R is the number of images retrieved by the query; and A is the number of relevant images in the dataset. As a rule of thumb when analyzing P&R graphs, the closer the curve to the top, the better the corresponding retrieval tech- nique is. To build the P&R graphs, we applied sets of k- nearest neighbor (kNN ) queries, using randomly selected query images from the image datasets, varying the values of k. For the dataset analyzed, all test images were employed as query centers. The feature vectors employed is described in section 4.2. Each set of feature vectors obtained were indexed using the Metric Access Method (MAM) Slim-tree [10], to accelerate the similarity queries processing.

4.1. The Dataset Description  Due to space limitations, in the present paper there are only results obtained from one representative dataset. The dataset consists of 704 images of magnetic resonance (MR) and heart angiogram exams collected in the Clinical Hospi- tal of University of Sao Paulo at Ribeirao Preto. The data-  set cotains 8 categories of images: angiogram, axial pelvis, axial head, axial abdomen, coronal head, coronal abdomen, sagittal head and sagittal spine. The images are represented by 8 bits depth, resulting in 256 gray-levels and comprising dimensions of 256 x 256 pixels.

4.2. Feature Extractors  Two types of feature extractors were employed to per- form the experiments: (a) a texture-based extractor and (b) a shape-based extractor.

The texture-based descriptor used was based on the Ha- ralick descriptors [4], obtained from co-occurrence matrix that have been largely used to a texture-based image re- presentation. The features obtained from the Haralick des- criptors employed in our experiments are variance, entropy, energy, homogeneity, 3rd order moment, inverse variance and step. All these descriptors were combined in a single feature vector, generating a feature vector composed of 140 elements.

The shape-based extractor employed the improved EM/MPM algorithm proposed in [3]. The images are fis- tly segmented using a technique that combines a Markov Random Field and a Gaussian Mixture Model. The seg- mentation of images are accomplished according to a fixed number of different texture regions, where six features are extracted for each region: the mass m (or size); the centroid (xo and yo); the average gray level (?), the fractal dimension (D); and the linear coefficient (b) used to estimate D. In our experiments we segmented the images in five regions. The shape-based extractor produced feature vectors composed of 30 elements.

4.3. Results  In the experiments, the dataset was divided in two sets: the training set that is composed of 176 images (25% of the MRI dataset), and the test set that is composed of 528 images (75% of the MRI dataset).

The P&R graphs of Figures 2 and 3 correspond, res- pectively, to the experiments performed on the image da- taset represented by the texture-based extractor and by the shape-based extractor. In Figures 2 and 3 the graphs (a), (b) and (c) correspond to the results when using L1, L2 and L? distance functions respectively, comparing our weigh- ting approach, with non-weighting ones. The P&R curves in the graphs of Figures 2 and 3 were built by executing similarity queries employing: (1) non-weighting the featu- res; (2) the StARMiner feature selection; (3) the proposed method, using q = 0 (removing irrelevant attributes) and (4) the proposed method, using q = 1 (weighting features by relevance). In the proposed method, the use of q = 0 leads to dimensionality reduction of the feature vector, re-      0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - Texture  L1 L1 Starminer  Weighted L1 k=0 Weighted L1 k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - Texture  L2 L2 Starminer  Weighted L2 k=0 Weighted L2 k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - Texture  Linf Linf Starminer  Weighted Linf k=0 Weighted Linf k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  L1 L1 Starminer  Weighted L1 q=0  Weighted L1 q=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  on (%  )  L2 L2 Starminer  Weighted L2 q=0  Weighted L2 q=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  on (%  )  Recall (%)Recall (%)Recall (%)  Linf Linf Starminer  Weighted Linf q=0  Weighted Linf q=1  (a) (b) (c)  Figure 2. P & R graphs using (a)L1, (b)L2, and (c)L? obtained over the dataset represented by texture- based features, employing: non-weighting the features; the StARMiner feature selection; the propo- sed method, using q = 0 (removing irrelevant attributes) and the proposed method, using q = 1.

0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - Texture  L1 L1 Starminer  Weighted L1 k=0 Weighted L1 k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - Texture  L2 L2 Starminer  Weighted L2 k=0 Weighted L2 k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - Texture  Linf Linf Starminer  Weighted Linf k=0 Weighted Linf k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - EM/MPM  Linf Linf Starminer  Weighted Linf k=0 Weighted Linf k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - EM/MPM  L1 L1 Starminer  Weighted L1 k=0 Weighted L1 k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  o n  ( %  )  Recall (%)  Feature Extractor - EM/MPM  L2 L2 Starminer  Weighted L2 k=0 Weighted L2 k=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  Recall (%)  L1 L1 Starminer  Weighted L1 q=0  Weighted L1 q=1  L2 L2 Starminer  Weighted L2 q=0  Weighted L2 q=1  Linf Linf Starminer  Weighted Linf q=0  Weighted Linf q=1   0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  on (%  )  Recall (%)  0.2  0.4  0.6  0.8   0  0.2  0.4  0.6  0.8  1  P re  ci si  on (%  )  Recall (%)  (a) (b) (c)  Figure 3. P & R graphs using (a)L1, (b)L2, and (c)L? obtained over the dataset represented by shape- based features, employing: non-weighting the features; the StARMiner feature selection; the propo- sed method, using q = 0 (removing irrelevant attributes) and the proposed method, using q = 1.

moving redundant features of it. For the dataset represented by the texture-based features, the use of q = 0 leaded to a reduction of 20% on the feature vector size. For the dataset represented by the shape-based features, the use of q = 0 leaded to a reduction of 27% on the feature vector size.

Figure 2 shows the P&R graphs obtained on the texture- based features to represent the image dataset. When analy- zing the graph of Figure 2(a) we observe that the propo- sed technique clearly improves the precision of similarity queries. The best precision was obtained using the cons- tant q = 1, considering all the features and weighting them.

The weighted features presented a considerable gain of 30% over the performance of non-weighted features, for the re- call level of 40%. When using q = 0, a gain of about 20% is achieved for the same recall level. It is important to note that, the use of q = 0 also promoted a reduction of 20% on the feature vector size, which diminishes the memory and processing cost. When analyzing the graphs of Figure 2(b), it is possible to note that the proposed technique presented a notable gain in precision. We can observe that the dimensi- onality reduction achieved using the StARMiner algorithm (see Figure 2(b) curve L2 StARMiner) decays the precision values. However, when the proposed technique is applied to  the feature vectors the precision increases, reaching a gain up to 20% using the q = 0 for a recall level of 35%, and a gain of up to 38% when q = 1. These results testify that the proposed technique improves the precision of similarity queries, even when it reduces the dimensionality of feature vectors. Analyzing the graphs of Figure 2(c) we observe that StARMiner generated the worst precision even in com- parison with the original features obtained by the texture extractor. When using our technique with q = 0 (i.e. by weighting the features selected by StARMiner) the preci- sion increases and ties with the precision obtained by the original features. It is important to highlight that although the precisions tie, our technique also accomplished the di- mensionality reduction of 20% on the feature vector size, thus demanding less space and making the processing fas- ter. Applying our technique with q = 1 gave a considerable gain in precision, up to 67% for a recall level of 30% in comparison with the StARMiner algorithm, and a gain in precision, up to 20% in comparison with the precision ob- tained by our technique using q = 0 and also the original features.

Figure 3 shows the P&R graphs obtained from the shape- based features to represent the image dataset. Analyzing     Figure 3(a), one can see that our technique for both q = 0 and q = 1 reached a gain in precision up to 5% in compa- rison with the original features, and the features selected by the StARMiner (without weighting). Figure 3(b) shows that our technique presented a gain in precision of approxima- tely 14% at 45% of recall in comparison with the precision obtained using the original featues and the features selected by StARMiner. Figure 3(c) shows a gain in precision, up to 16% at 35% of recall using q = 0, where the feature vector size was reduced in 27%.

Figure 4 shows an example of a k-NN (k=8) query exe- cution, using the top left image as the center of query. Fi- gure 4(a) shows the result using the original features, and Figure 4(b) shows the result using our proposed method with q = 0 (fewer features). The images highlighted by a dashed line means false positive images. A false positive image is a returned image whose class differs from the class of the query center. Clearly an improvement on the results was reached by applying our method.

Considering the results achieved, we argue that our pro- posed weighting technique is well-suited to perform con- tinuous feature selection in content-based medical images, improving the precision of them. An important fact to stand out is that our weighting technique can be applied to other distance functions too.

(b)  (a)  Figure 4. An example of k-NN (k-8) query exe- cution, using the top left image as the cen- ter of query. (a) using the original features.

(b) using our proposed method with q = 0.

The images wrapped by a dashed line means false positives images.

5. Conclusions In this paper, we presented a supervised method of conti-  nuous feature selection. The proposed method employs sta- tistical association rules to reduce the semantic gap inherent in the CBIR systems. Our approach can also be employed to perform dimensionality reduction, minimizing the ?di- mensionality curse? problem. The experiments performed show that the proposed method improves the precision of the query results up to 38%, always outperforming the pre- cision obtained by the original features, while decreasing the memory and processing costs. These results testify that statistical association rules can be successfully employed to perform continuous feature selection in medical image data- bases, weighting the features in similarity query executions.

Future work includes to verify the results of applying our technique using other distance functions and incorporating other mining techniques.

