mBAR: A Materialized Bitmap Based Association Rule Algorithm

Abstract  With the rapid progress in information technology, the  data mining technique has been exploited in various  applications. The association rule(hereafter, AR) mining,  one of the most popular data mining techniques, is to find  the frequent itemsets which occur commonly in transaction  database. Of the various AR algorithms, the Apriori is most  popular, and it has been continuously improved during the  past decade. Even with recent version, however, it is very  time consuming for the Apriori-based algorithms to count  frequent itemset since, basically for each k-size item set, we  need to compute its support on-the-fly.

In this paper, we propose the mBAR approach to AR  mining, which drastically improves the Apriori algorithm  by exploiting materialized bitmaps. First, we present a  bitmap-based Apriori algorithm. And, we suggest, in  order to boost the performance of finding the frequent  itemsets, how to store(i.e. materialize) the bitmaps,  instead of computing the bitmaps on-the-fly. Related to  the materialized bitmaps, we suggest a way to choose the  bitmaps selectively, instead of full bitmaps, and propose  an incremental maintenance technique for materialized  bitmaps against the changes in transaction database.

1. Introduction With the advances in information technology, most  information is stored in a form of database, and by  analyzing the information, we can find trends or patterns  which may be very useful in business decision making. The  process of finding useful, non-trivial, but unknown  knowledge from the mine of data is called data mining.

This technique is now widely used in various mission  critical applications such as marketing, sales, stock  prediction and et al.

Depending on types of applications and the  knowledge to be mined, various data mining algorithms  have been developed. Among them, the association  rules(hereafter, AR) mining is most popular, and the  famous Apriori algorithm is the de-facto standard AR  algorithm[1].

Since its introduction in 1994, the Apriori-based AR  algorithm has been continuously enhanced in  performance. However, it has some intrinsic  disadvantages, such as repeated database scan,  unpredictable computation cost and memory requirement.

To overcome these problems,  various algorithms have  been proposed. In spite of the huge enhancements, the  Apriori-based AR algorithm does not still, we believe,  meet the strict performance requirements in near real-  time data mining.

In this paper, we propose a materialized bitmap-based  AR algorithm under the Apriori philosophy, which  dramatically improves the performance. The algorithm is  very intuitive and fast in computing the frequent itemsets.

The contributions of this paper are four folds: 1) To  improve the frequent itemset counting by exploiting the  bitmaps, and further more 2)  as far as we know, to firstly  suggest to use the materialized bitmaps in processing the  AR query - a kind of index for data mining, 3) to propose  an algorithms for choosing the materialized bitmaps  selectively under the space constraints, and finally 4) to  develop an incremental maintenance technique for the  materialized bitmaps according to the changes in base  transaction database. With the mBAR algorithm, near  real-time AR will be possible. To sum up, we propose a  comprehensive bitmap-based index framework in the AR  field. We believe that the bitmap concept is very suitable  as a materialized view framework for AR mining.

The remainder of this paper is organized as follows.

Section 2 gives a brief overview of the Apriori algorithm.

Section 3 proposes a bitmap based AR  algorithm(hereafter BAR) and Section 4 extends the  BAR technique by materializing the bitmaps and thus  avoiding the overhead of the repeated on-the-fly  computations of bitmaps, which we call the mBAR  technique. Finally, Section 5 discusses the conclusion and  future works.

2. Related Work - Apriori Algorithm The Apriori algorithm[2], which is the most popular  AR algorithm, has broken new ground for large scale  data mining, and since its introduction, most of the AR  algorithms is based on it. Because our mBAR algorithm  is also based on the Apriori algorithm, we briefly review  the Apriori algorithm.

The main principle of Apriori is that any subset of a  frequent itemset must also be frequent. Using this principle,     the Apriori generates much smaller number of candidate  itemsets than the previous algorithms. The Apriori  algorithm performs as follows. In the first pass, it counts  the support of all items over the database and determines  which of them are frequent. In the subsequence passes,  generating candidate itemsets and finding frequent itemsets  are iterated until no new large itemsets are found.

Candidate itemsets are generated by joining frequent  itemsets founded in the previous pass and pruning. Then,  by scanning database, the support of each candidate itemset  is counted.

However, if any frequent k-itemset exists, it scans the  database k times for frequent itemset counting. This  excessive database scan is the main bottleneck of the  Apriori algorithm. Another bottleneck is to test whether  a candidate itemset is contained in the transaction  database. Thus, we need to do many item containment  test in transaction.

The AprioriTid is also proposed by [2] to overcome  disadvantage of na?ve Apriori. In the AprioriTid, the  database is not scanned after the first pass by buffering  the scanned data as a compressed format in memory. The  AprioriTid uses the buffered data to prevent database  scan, but these data can be larger than original database.

Thus, it may not be a viable option for moderate size of  real data.

Compared to the traditional Apriori algorithms, we  employ bitmaps as the internal representation format of  frequent itemset counting, and this brings many  advantages which will boost the performance of Apriori-  based AR algorithms. You may understand the  advantages of our approach as you proceed this paper.

3. BAR: A Bitmap-based AR Algorithm The bitmap technique is very popular in data warehouse  (DW) fields, where very large database and complex  analytical query are handled. The bitmap index is one of  the main performance boosts in DW field. We had started  our research by wondering whether it is possible to  enhance the Apriori algorithm using the bitmap index  technique.

Our BAR algorithm is basically based on the Apriori  idea, and is in the same vein with AprioriTid in that it  maintains a compressed database within memory. But, its  uniqueness comes from the fact that it uses bitmap as the  data structure for internal processing. By bitmap  representation, we expect to avoid costly database  scans(high disk I/Os) and the very CPU intensive item  containment test.

In order to count support for each itemset, compared to  the previous frequent itemset counting approaches where  we need to scan every transactions, the BAR algorithm  uses the efficient bitmap AND operation, thus being very  intuitive and very fast. The compressed bitmap  representation also enables as much as item information to  be retained in memory, thus reducing disk I/O very much.

Even though the definitions of transaction table and  related notations are generally similar to that of [2], in this  paper, Ck(set of candidate k-itemsets) and Lk(set of frequent  k-itemsets) are represented as bitmaps. Firstly, we scan the  transaction DB and construct a bitmap for each item in the  database,  in which a bit is set to ?1? if the item is contained  in the transaction ID, and otherwise, the bit is set to ?0?.

L1 : { {a}, {b}, {c}, {e} }  C2  : { {a b}, {a c}, {a e}, {b c}, {b e}, {c e} }  TID {a} {b} {c} {d} {e}  100 1 0 1 1 0  200 0 1 1 0 1  300 1 1 1 0 1  400 0 1 0 0 1  supp 2 3 3 1 3  {a}      {b}      {a b}       &  C1 L1  bit-apriori-gen  minsup = 2  TID Items      a c d  b c e  a b c e  b e  D  TID {a} {b} {c} {e}  100 1 0 1  Figure 1. An Illustrative Example of BAR Algorithm  For the example database in [2], the figure 1 shows  how the BAR algorithm represent the transaction DB in  bitmaps and how to calculate the frequent itemset just  using bitmap AND operations.

While scanning the transaction database, we calculate  the support for each 1-item, and construct table C1, which  will be the basis for candidate itemset generation. After  constructing table C1, we create frequent 1-itemset L1 by  removing the item which does not meet the minimum  support. After this step, we can generate next level  candidate itemsets(that is, bitmaps and support value for  each bitmap) without disk scanning and string matching  for item containment test. From the candidate itemsets,  we remove the itemsets whose support value is less than  the minimum support. By repeating this process until no  more new itemset are found, we can completely find the  frequent itemsets. We call this module bit-apriori-gen.

4. mBAR: Materialized BAR Algorithm As previously described, the BAR technique enables  fast calculations of frequent itemsets over the large  volume of data. Nevertheless, because the BAR  algorithm follows the same steps of the Apriori algorithm,  it suffers from repetitive on-the-fly calculations of  bitmaps and their support values. To overcome this  problem, we propose the mBAR technique, which  materializes the bitmaps for itemsets and stores the  support value using B+ tree, thus enhancing the Apriori-  based AR algorithms furthermore. Of course, this  technique requires storage overhead for storing large   200 0 1 1 1  300 1 1 1 1  400 0 1 0 1  supp 2 3 3 3     bitmaps and incremental bitmap maintenance overhead.

However, the performance benefit beats this overhead by  far. In this respect, our mBAR is a kind of index for AR  data mining.

4.1. Overview In contrast to relational views which are virtual relations,  a materialized view(MV) is the stored result of a query[1].

Because we need to store the pre-computed result, it  requires the space overhead. However, if a given query is  relevant to the materialized view - i.e. rewritable to the  view, we can answer the query very fast. Thus, the MV  technique is widely exploited in DW applications, and all  the major commercial DBMSs support the MV  functionality with some variations.

In this paper, Ck means bitmaps for k-itemsets, and Lk refers to bitmaps for frequent k-itemsets. The mBAR stores  all the bitmaps of Ck to Cn, and stores each bitmap?s  support value in the leaf nodes of B+ tree. Thus, with our  mBAR technique, the problem to find all the association  rules for the given confidence and support, is simply to find  the itemsets whose support value is greater than the given  support value, which is just an index traversal operation. To  sum up, the mBAR can accelerate the AR calculation at the  cost of some space overhead.

4.2. Overhead of Materialized Bitmaps If we would like to store all the bitmaps for real  medium size transactional databases, the storage require-  ment is too huge. For our mBAR to be practical, we  should devise a technique which stores minimal bitmaps  but achieve the AR performance as close as in the case of  full bitmap materialization. For example, let us consider a  sample transaction database, where number of  transactions is one million(t) and the number of distinct  items is one thousand(S), the space size for C1 will be  approximately 125MByte, according the following  formula.

e.g. O(n) = (t +1) S bits = 106  103 bits  = 1Gbit + some overheads 125MBytes  C1, which stands for 1-itemsets of bitmap, consumes  large spaces, but the bitmap compression technique will  reduce the space much. The problem lies in that space  requirement is not limited only to C1, but the bitmaps for  upper level itemset also need to be materialized. More  precisely, up to k-level, where k = # of itemsets / 2, the  space requirement exponentially increases. Thus, the total  space overhead for bitmap materialization can be  approximated as follows:  1 1  # of TIDs) # of TIDs) !

n n n r  n r  r r  P C  r  However, in practice in case k  # of itemsets / 2, the  number of frequent k-itemset will be reduced, in  particular, it will be close to 0 as k approaches to n.

Nevertheless, in the worst case, the storage requirements  for bitmap materialization, we need the space of a couple  times of the original transactional database size.

4.3. Bitmap Selection to Materialize Because it is not practical to materialize all the  bitmaps for every k-itemset, we investigate a technique to  reduce the itemsets to materialize. Please note that the  superset-subset relationships between all itemsets make a  lattice structure. By exploiting this lattice structure, we  can materialize bitmaps selectively with a little  performance compromise. Our idea mainly comes from  the cube reduction technique found in [3][4].

Here we assume that it is possible to find almost  association rules from C1, upper 20% of Lk (in terms of  support value), and the support values of all the itemsets  (which are maintained in B+ tree). Our assumption about  the upper 20% is arbitrarily chosen, and in practical usage  it will be given as storage constraint(B) from users, where  the B should be larger than the minimum space. Based on  the given B, we can calculate the number of bitmaps at  each level of frequent itemset counting in Apriori  algorithm. If we are given the space constraint(B e.g.

1GBytes), the number of transactions(t), the number of  distinct items(n), and the unit size of support value  representation(8 bits), we can calculate the minimal  storage which is the summation of 1) all 1-itemset  bitmaps(C1)  and 2) B+ tree  to store the support values of  all the itemsets.

The space for 1-itemset bitmap(C1) is  bits. And,  the space for B+tree can be estimated as  1nC t   n  n r  r  C  bits  according to combination formula. Consequently, we need  the space of   ( ) ( n  n n  r  C t C 8)r bits for C1. If the space  constraint B is larger than this value, the remaining space  for upper k-itemset(where ) is  2k   ( ) ( 8 !

n n r  r  P B n t  r ) . We can calculate the ratio  between the remaining space and the total expected space  as  1 2  [ ( ) ( 8)]/( !

n n n r  n r  r r  P )B n t C t  r . By multiplying this  ratio with the number of items generated in each k-itemset,  we can estimate the upper level bitmaps to materialize.

Figure 2 shows a pseudo code of our mBAR  algorithm. In the line 1, every 1-itemset C1 are generated  and materialized in disk, that is, L1. The line 2 calculates  the size of the available remaining space which can be  used for storing the upper level bitmaps in the lattice. The     line 3 to 11 generates bitmaps for candidate itemsets and  calculates their support values, which are same with basic  BAR algorithm. The line 13 to line 18 materializes the  bitmaps of the most frequent Mk  k-itemsets for each k-  level in the lattice, and also creates B+tree for storing the  support value for every candidate itemsets.

1)  C1  = L1 = {1-items bitmap table};      // Store MV  2)  R =  1 2  [ ( ) ( 8)]/[( ) (# )] !

n n n r  n r  r r  P B n t C t of TIDs  r // Ratio  3) for (k = 2; Lk-1  ; k++) do begin  4) Ck = bit-apriori-gen(Lk-1);        // New candidates  5) forall transaction t do  6)                    // count support and sum_of_items  7) forall candidates c Ck do  8) if (c.bit[t] = 1) then  9) c.count++;  10) end  11) end  12)      // prune column  13) k n kM C R  ;                     // apply gauss function  14)      // store top itemset and all support  15) Lk  ={c Ck  | Top Mk  of c.count};  16)      Store-MV(Lk);                          // Store MV  17)      Store-B+ tree(Ck.count row);     // Store B+ tree  18) end  Figure 2. mBAR Pseudo code  4.4. Incremental Maintenance of Bitmaps For our mBAR algorithm to be viable option for AR,  one of the main issues to be solved is, when the  transactions in base database are inserted, updated or  deleted, how to maintain the stored bitmaps consistently.

The na ve solution which rebuilds the bitmaps from the  scratch whenever there is changes in transactional  database is too time consuming. So, we should devise an  incremental maintenance technique for the materialized  bitmaps - that is, when transactional data is updated in  base database, each bit-string in C1 also should be  appropriately changed and further more the change  should be propagated up to the bitmaps for higher level  itemset s along the lattice.

Let us consider each case of insertion, deletion, and  update. When a new transactional record is inserted, new  corresponding bit is appended in each C1 itemsets and if  the bit is 1, then the support value for the itemset is also  increased, and otherwise, the value needs not to be  changed. Similarly in case of a record deletion, if the bit  to be deleted is 1, then the support value should be  decreased by 1. The update in transaction DB can be  interpreted as insert-after-delete.

For the upper level bitmaps Lk, where , which  are selectively materialized, if the changes in C  2k  1 is  propagated to them, the support value in each of them  also may be changed. So, if some itemset go below the  minimum support requirement for materialization, they  are removed from the materialized bitmaps. In contrast,  we need to materialize some itemsets?s bitmaps because  their support values become larger than the minimum  support value. In particular, when pattern changes occur  in transactional databases, this kind of time consuming  de-materialization and materialization of bitmaps are  necessary. But except in case of the radical pattern  changes, the overhead for upper level bitmap  maintenance is, in general, not much burden.

In the lattice structure, it is less possible for the  itemsets in higher upper level to be affected by changes  in transactional database. In particular, if any sub-itemset  Lk-1 of Lk is materialized, we can compute the bitmap of Lk by bitmap-ANDing Lk-1 and an C1.

5. Conclusion and Future Works We believe that the traditional AR algorithms, including  the Apriori-based algorithms, have too large disk scan cost  and CPU computation cost so that they will not meet the  near real-time data mining performance requirements.

Our BAR technique will eliminate these performance  bottleneck in Apriori-based algorithms, because it can  avoid the repeated database scan and, further more, can  reduce the CPU intensive item containment test operation.

This enhancement is possible because we transform the  original transaction database into bitmap string. After the  data is transformed into bitmaps, then the AR problem is  intrinsically just bit counting problem. Our next  contribution, mBAR, makes it unnecessary to calculate  the numerous itemsets repeatedly, at the cast of the space  overhead and incremental maintenance. In this respect,  our mBAR framework is a viable index for AR data  mining.

We plan the following future works. Needless to say,  we should implement the mBAR algorithm and to  evaluate its performance, compared to the existing AR  algorithms, against real data set. And, we will adopt the  bitmap compression techniques[5] to reduce the  materialized bitmap size dramatically. Finally, we  investigate on exploiting the GPU(Graphic Processing  Unit)?s computation power on bitmap operations. Recent  works such as [6] will shed light on this issue.

Bibliography  [1] R. Ramakrishnan, J. Gehrke, "Database Management Systems  3rd.", McGRAW-Hill, pp. 889-897, 2003.

[2] R. Agrawal, R. Srikant, "Fast Algorithms for Mining Association  rules", Proceedings of the 20th VLDB, pp. 487-499, 1994.

[3] S. Agarwal, R. Agrawal, P. M. Deshpande, A. Gupta, J. F.

Naughton, R. Ramakrishnan, S. Sarawagi, "On the Computation     of Multidimensional Aggregates", Proceedings of the 22th VLDB,  pp. 506-521. 1996.

[4] V. Harinarayan, A. Rajaraman, J. D. Ullman, "Implementing Data  Cube Efficiently", SIGMOD, pp. 205-216, 1996.

[5] T. Johnson ?Performance Measurements of Compressed Bitmap  Indices?, Proceedings of the 25th VLDB, pp. 278-289, 1999.

[6] I. Buck, T. Foley, D. Horn et al, ?Brook for GPUs Stream  Computing on Graphics Hardware?, SIGGRAPH, 2004.

