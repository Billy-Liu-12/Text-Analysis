

Abstract ? Data mining is one of the interdisciplinary fields on the research aspect. Recently, association rules have become an important concept for classification purposes, called Associative Classification. It is a data mining technique that combines association rule mining and classification technique to build classification models. The core objective of this work is to classify the gene expression using Associative Classification algorithm. Our research work has been formulated based on association rule and classification mining. The proposed algorithm contains four phases called as Statistical Gene filtering, Discretization, Class Association Rules and prediction or class assignment. The gene filtering phase is to find the differentially expressed genes and select the significant genes in the specific gene expression. The discretization phase is to convert the continuous values into discrete values and substitute the gene values into gene intervals. The role of the Class Association Rule phase is to generate the set of class association rules using closed frequent itemset and generate the classifier model. The last phase predicts the class from trained model using scoring function. The experimental results carried out by using breast cancer gene expression data which are available on the NCBI online biological database. It has been tested with two class and multi-class datasets and compared with the classical classification algorithms such as Linear Discriminant Analysis, SVM, and Decision Tree. The performance of the classifier model is evaluated using Leave-One-Out-Cross Validation method.  The result of this work is used to the drug designer for the pathway analysis and disease treatment decisions.

Index Terms ? Microarray, Data Mining, Associative Classification.



I. INTRODUCTION Now-a-days, large amount of data are being collected from  biological data. Analyzing and extracting knowledge from huge data is difficult task. Data mining techniques have been used to get the useful knowledge from the large amount of data. Data mining techniques are being applied to all the types of domains that have rich data, such as database technology, machine learning, statistics, mathematics, cybernetics, genetics, neural networks, information retrieval, marketing and etc. In this paper, the proposed methodology focuses on Associative Classification technique which is a new technique in the data mining area for  classifying the data in the field of Bioinformatics such as gene expression and gene sequence to analyze the data. Data Mining is the science of finding new interesting patterns and relationship in massive amount of data. The data mining is defined as ?process of extracting meaningful new correlations, patterns, and trends by extracting from large amounts of data stored in databases?. Data mining is also sometimes called Knowledge Discovery in Databases [1].  The microarray dataset can be form of an M x N matrix of expression values, where the column represents genes g1, g2, g3?, gn and the row represents different experimental samples s1, s2, s3? sn. Each element D [i,j] depicts the expression level of the gene gi in the sample sj.

The matrix usually contains large amount of data [2, 11]. The figure 1 presents the microarray gene expression data matrix [2].

Fig. 1. Gene Expression Data   Associative Classification algorithm operates in three  phases, the discretization, the rule generation and the classifier building. The structural of this paper in organized as follows.

Chapter 2 represents the background of research done in various discretization and associative classification algorithms. Chapter 3 discusses the methodology and techniques that are used in our research. Chapter 4 presents the results of associative classification on breast cancer data set. Chapter 5 discusses the conclusion and future enhancements about the work done in the research.



II. REVIEW OF RELATED WORKS In order to do the survey various algorithms have been  studied. Finding the affected and over expressed genes for the diseases and then classifies the gene expression using association rules and gene intervals. For that the researcher must know the basic knowledge of statistical methods, discretization techniques, associative classification algorithms, and cross validation methods.

Nagata, K., et al., have analyzed the toxic genomic and toxicological data using classification association rules. Then they reported that the statistical t-test have often been applied in microarray data analysis. Then they selected only the genes that were up-regulated (fold change > 2 and p < 0.05) or down- regulated (fold change < 0.5 and p < 0.05) in the groups with increased or not-decreased groups, respectively [3].

Discretization is also forms of transformation, the gene expression are replaced by number of intervals or concept labels.

This simplifies the original data and produces the mining more effective and the resulting patterns are easy to understand.

Garcia, S., et al. have made a survey on discretization techniques. They pointed out discretization is a vital preprocessing techniques used in knowledge discovery and data mining task. The main objective is to transform a set of continuous attributes into discrete values by associating categorical values to intervals [4, 18].

TABLE 1: COMPARATIVE ANALYSIS OF DISCRETIZATION ALGORITHMS  Algorithms Supervised/ Unsupervised Splitting/ Merging  Time Complexity  Equal Width Interval Bin Discretization Unsupervised Splitting O(n)  Equal Frequency Bin Discretization Unsupervised Splitting O(n)  K-Means Clustering Based Discretization Unsupervised Splitting O(ikn)  Entropy (MDLP) Based Discretization Supervised Splitting O(n log(n))  ID3 Based Discretization Supervised Splitting O(n log(n)) Chi-Merge Based  Discretization Supervised Merging O(n log(n))  Class Attribute Contingency Coefficient  Supervised Splitting O(n log(n))   From the comparative analyses of discretization techniques  have been performed and the results are shown in table 1.

Alves,R., et al. have discussed frequent pattern methods for  gene association analysis. Frequent pattern mining has been implemented successfully in various data such as business and scientific data for discovering knowledge patterns, and is becoming a hopeful strategy in microarray gene expression analysis. Though, with dense datasets such as telecommunications, microarrays, etc., where there are many lengthy frequent patterns, these methods scale poorly and sometimes are unfeasible. This problem is due to the high computational cost used by apriori algorithm.

Then they pointed out that the tree based methods such as FP-growth might find some difficulties when dealing with dense or high dimensional datasets [5].

Zakaria, W., et al. have proposed a column enumeration based algorithm using high confidence association rules for up and down expressed genes. Then they explained that the generating all frequent itemsets in dense datasets requires large memory [6].

Creighton,C.,  et al. have demonstrated an algorithm for powerfully mining association rules from gene expression data.

Then they explained that the transcript and protein level in the gene expression profiling can be valuable to study of genes, biological networks and cellular information [7].

Snousy, A. M. B., et al. have discussed the classification techniques among nine decision tree algorithms. They explained the problems in cancer gene expression profiles, is to determine genes or groups of genes that are highly expressed in cancer cells but not in normal cells. Then they pointed out the classification techniques are used with microarray datasets to form classifier models that improve the diagnostic of different diseases [8].

Nagata, K., et al. have applied the Classification Based on Association algorithm on toxicological data. They have been discretized gene expressions and relative liver weights based on their fold changes and p values of the student?s t-test conducted between a compounds treated grouping and its corresponding control group. They generated Class Association Rules using the Apriori-TFP algorithm. The classification between CBA and linear discriminant analysis is showed that CBA is superior to LDA in terms of both predictive performances and interpretability [3].

Refaeilzadeh, P., et al. have discussed the various cross validation methods. The cross validation defined as a statistical method of calculating and comparing learning algorithms by splitting data into two segments, one used to learn or train a classifier model and the other used to validate the model [9].

From the literature study, it has been concluded that the statistical methods are required for a proper selection of differentially expressed genes and significant features for classification. The frequent microarray data sets generated by Apriori algorithm requires large memory [10, 11, 12]. The FP- growth might find some difficulty to dealing with dense or high dimensional datasets. For that, the researcher uses Apriori-Close [13] algorithm to prevent this problem by getting bigger only frequent closed itemsets. The over fitting problem occurs when the classification perform well on the training dataset and poorly on the test data set. This can be affected the accuracy of the classification. For instance, while SVM produces high classification accuracy, resulting classifiers are hard to interpret in non linear, hence complicated to use in order to extract relevant biological knowledge from it. The researchers avoid this problem by using associative classification which combines the association rules mining and classification techniques [14].

Finally, the Leave-One-Out-Cross Validation method has been used for validating the predictive performance of the classifier model and it provides unbiased performance estimation.

Fig.2. Methodology

III. METHODOLOGY The recent advent of new technologies in biology, such as  DNA microarray, produces a large volume of data to the researcher. As the same time it is not easy to derive accurate and understandable knowledge from the data. Hence, computer programs can automatically and accurately classify the gene expression and finding affected genes in gene expression data become a necessity. The proposed methodology of overall diagram has been shown in the figure 2.

A. Phase I - Gene Filter  The human body cell typically expresses large number of genes. The modify in the expression patterns of few genes is sufficient to change the subsequent phenotype of the cells, for that reason the hypothesis testing is used to understand the genetic difference between the cells. Differential gene expression allows for the correlation between changes in physiological and gene expression differences.

It has been utilized to elucidate differences between tissues cells, developmental stages, normal and diseased cells, response to drug treatments, among others. Microarray technology allows to the analysis of the expression patterns of ten thousands of genes, and simultaneously [2]. The detection of differentially expressed genes can help to clarify the differences between two conditions or samples and identify genes that are both statistically important and have biological significance knowledge. In this paper, the gene filtering is the process of selecting the differentially expressed genes and statistically significant in the gene expression data using a statistical independent t-test method. The independent t-statistic supplies a consistent estimate of differential expression according to the following formula (1).

?      )2(     ? mn  Y m  miYXn n  iX  pool   Where represents is sample means and? is an  unbiased estimator for standard deviation. First calculate the sums of squares and Correction factor,  to subtract to give n times normal sample variance also called the sum of squared residuals, the associated likelihood under the null hypothesis is evaluated by reference to the t- distribution with degree of freedom.

The p-value is used to determine if a number is significantly dissimilar from normal to cancer cell. It is the chance of attained a value that deviates from the mean as much as the value being tested with the null hypothesis.  In this paper, the independent test used to find the differential expressed gene and selects the informative genes. First, the sample means for both groups and the standard deviation are calculated. Then the t-statistics value will be calculated and the p-value calculated from t-distribution with n?2 degrees of freedom. Finally, the differentially expressed genes and statistically significant genes are selected or biological significance based on probability with degrees of freedom n?2 and p < 0.5. The last step of gene filtering removes the uninformative genes.

B. Phase II - Discretization  Discretization method generally contains four steps such as, sorting the continuous values of the attribute or feature to be discretized, calculating a cut point or splitting points, splitting intervals of continuous value, and lastly stopping at some point.

Discretization techniques can be divided into supervised or unsupervised depending upon the datasets. Discretization methods can also be grouped in terms of top down approach or bottom up approach [4].

In the top down approach, the intervals are divided, in the bottom up approach, the intervals are merged when discretization process. First step of associative classification is discretizing the continuous attributes. In this paper the process of discretization of continuous features in the gene expression using an ID3 algorithm. ID3 algorithm is one of the supervised discretization algorithms for making class information theory of candidate to select boundary points for discretization. The two metrics of ID3 algorithm are entropy and splitting information. Entropy measure is used in various applications or domains. When used in discretization technique, entropy is calculated in a supervised manner. The entropy value is calculated using the formula (3).

Where  be the entropy information . denotes the probabilities of information . ID3 algorithm is inducing best or correct split point in decision trees. ID3 employs a greedy search to find possible split points within the existing range of continuous values using the following formula (4). In the equation (4), m is the number of classes in , pj, left and pj, right are probabilities that an instances, go to class j, is on the left or right side of a potential split-point T.

The split-point with the lowest entropy is preferred to split the range into two categorical values or intervals, and the binary split is sustained with each part until a stopping criterion is satisfied.

In our proposed methodology, the entropy values are calculated for each gene attributes in gene expression. Similarly, the split values are calculated for each gene attributes in the gene expression data. Consequently, the gene expression values are replaced with the unique interval or period containing it.

C. Phase III ? Class Association Rules  Association Rule Mining is one of the vital roles in data mining method as well as computational biology. Association rule mining is one of the unsupervised data mining techniques, where produces reasonable rules [10]. In this proposed methodology the process of discovered closed frequent rule items using Apriori Close [13] algorithm, after discovered closed frequent itemset, the class association rules has been formed.

Association Rules Let I = {i1, i2, i3 ? im} be a set of m elements is gene items. A  rule is defined as an implication of the form X?Y, where X, Y I and X Y= . The left side of the rule is called as antecedent and right side of the rule is said to be consequent. A set of gene items I= {i1, i2, ? in} and a set of transaction or samples T = {t1, t2, t3 ? tm}, a subset of I, S I is said to be a frequent itemset [1].

Frequent Closed Itemsets The Closed itemset C is called as frequent if the support of C  in D is at least minimum support. Frequent Closed itemset = {C I and support(C) ? minimum support}. The frequent closed itemsets has two properties. The first property is all sub-closed itemsets of a frequent closed itemset are frequent. The second property is, all sub-closed itemsets of an infrequent closed itemset are also being infrequent.

Class Association Rule Let D be the dataset, a set of records d, let I be the set of non  class items or attributes in D, and Y be the set of class labels in D. A record  represents , or simply , if d has all the non-class items of . Likewise, a record represents , or simply , if d has the class label .A rule is an association of the form  , for a rule ,  is called an antecedent of the rule and  is called a consequent of the rule. In our proposed methodology, process of Class Association Rule are contain two steps (1) to produce the entire set of rules that satisfy the user defined support and confidence constraints or threshold value and (2) to build a classifier from these class association rules.

A-Close Algorithm The frequent closed itemset method is different from existing  algorithms and based on the closed itemset lattice for finding frequent itemsets. A closed itemset is a frequent itemset, where maximal set of items common to set of objects. It constructs a set of candidate frequent closed itemsets which decides the frequent closed itemsets using the min-support threshold. In every step, one pass over the database is needed to build the set of candidate frequent closed itemsets [13].

The A-Close Algorithm first initializes the set of generator itemsets in frequent closed 1-candidate with the items present in the data mining. Each iteration contains of three phases. First, the closure property used to determine the candidate frequent closed itemsets and support. Next, the infrequent itemsets pruned from the frequent closed candidate itemsets. Finally, generate the valid frequent closed itemsets. The Associative Classification identifies the closed frequent itemsets for each class ,  by using gene intervals. Those itemsets generate the set of rules  per class.

The antecedence of every rule is the conjunction of the gene expression and consequent is the membership of class . Finally form the class association rules classifier model.

D. Phase IV - Prediction An association rule produces interesting relationships  between gene expressions and classes or labels. The generated complete set of rules that satisfy the user specified minimum       support and minimum confidence constraints and to build a classifier from these class association rules. The last step in the life cycle of associative classification is prediction or class assignment techniques. In our proposed methodology, the process of prediction or class assignment for test data, the researcher used the score based prediction [14]. Let  be an unknown sample and let  be the association rules for class .  For , class association rules calculates how many rules are satisfied in each rule  and assigns to that class whose rules are maximally satisfied using scoring function(9).

The class , Class Association Rules evaluates  for each rule , by using the function .

The phase IV reads the unknown discretized sample or test set and association rules for the class. The score based function evaluates the number of rules are satisfied, even partially in each rule. Then the score values are computed for each rule. Finally, the score value is assigned to the class of the maximally satisfy the test object. If no rules are applicable to the test object, the default class assigned to that test object.

E. Cross Validation Cross Validation is a statistical approach of evaluating  predictive performances and comparing classification model by splitting data into two segments: one used to train a model and the other used to validate the model. In this paper leave one out cross validation (LOOCV) has been implemented to validate the classifier model [14].

For a gene expression data dataset with N samples perform N Experiments, for each experiment use N-1 samples for training and the remaining samples are testing.

F. Classification Accuracy The effective classification model is evaluated with number  of exact and wrong classifications in each possible value of the variable being classified in the form of confusion matrix.



IV. RESULTS AND DISCUSSION All experiments are performed on a computer with a CPU  processor clock rate of 2.8GHz and 2GB of main memory. The algorithm implemented in R statistical programming language with 3.1.1 version. Each experiment performed various times and the best of them is taken for the results.  Microarray gene  expressions are used to assess the performance of the proposed method. The microarray breast cancer2 gene expression data has been collected from the standard database [14]. The microarray gene expression data description has been downloaded from the National Centre for Bioinformatics (NCBI) [15]. Breast cancer 2 data set has been used for the analysis of algorithm. The original data set consists of 60 samples 32 cancer recurred patient and 28 disease free patient and 22575 gene expression conditions. The following table 2 depicts the sample microarray gene expression values.

TABLE 2: GENE EXPRESSION DATA Patient ID class EST AK026789 MLLT1 ..

GSM22449 cancer -0.09 0.42 0.57 ..

GSM22450 cancer -0.91 -0.12 0.59 ..

GSM22451 cancer -0.82 -0.15 0.62 ..

GSM22452 cancer -0.13 0.25 0.79 ..

GSM22453 normal -0.42 0.27 0.53 ..

GSM22454 cancer -0.49 0.1 0.28 ..

GSM22455 cancer -0.38 -0.02 0.5 ..

GSM22456 cancer -0.56 0.27 0.53 ..

GSM22457 cancer -0.48 0.24 0.77 ..

GSM22458 normal 0.19 0.61 0.58 ..

GSM22459 cancer -0.64 -0.19 0.84 ..

GSM22460 cancer -1.09 0.15 1.23 ..

GSM22461 cancer -0.81 -0.17 0.85 ..

GSM22462 cancer -1 -0.16 0.97 ..

GSM22463 cancer -0.45 -0.19 0.9 ..

GSM22464 cancer 0.05 0.42 0.74 ..

GSM22465 normal -0.13 0.35 0.41 ..

GSM22466 normal 0.04 0.23 0.37 ..

.. .. ? .. .. ..

The independent t-test provides the standardized estimate of differential expression using the t-value and p-value. The p-value is used to determine if a number is significantly different from normal genes. In proposed system, calculates these steps in an automated using implementing t-test statistical method.

First calculate the t-statistics then Calculate p value from t distribution with n?2 degrees of freedom. Next, calculates the p- value using t-distribution value. Finally, select differentially expressed and statistically significant genes on probability with degree of freedom and p < 0.05. There are 2701 genes are selected or filtered from 22575 genes. The selected significant genes and differentially expressed genes with t-statistics values and p-values according to the p<0.05 criterion. In our proposed methodology, the entropy values are calculated for each gene attributes in gene expression. Similarly, the split values are calculated for each gene attributes in the gene expression data.

Consequently, the gene expression values are replaced with the unique interval containing it.

The following table 3 represents the discretized gene expression values. The following table 4 depicts the gene expression values are substituted by intervals. After the discretization the gene expression data are converted into transaction data and generate the class association rules.

TABLE 3: DISCRETIZED GENE EXPRESSION VALUES Patient class EST AK026789 MLLT1 ..

GSM22449 cancer 14 18 11 ..

GSM22450 cancer 1 1 13 ..

GSM22451 cancer 1 1 15 ..

GSM22452 cancer 13 13 20 ..

GSM22453 normal 9 14 8 ..

GSM22454 cancer 5 5 4 ..

GSM22455 cancer 11 3 8 ..

GSM22456 cancer 3 14 8 ..

GSM22457 cancer 5 12 20 ..

GSM22458 normal 19 19 12 ..

GSM22459 cancer 3 1 20 ..

GSM22460 cancer 1 9 22 ..

GSM22461 cancer 1 1 20 ..

GSM22462 cancer 1 1 20 ..

GSM22463 cancer 8 1 20 ..

GSM22464 cancer 18 18 18 ..

GSM22465 normal 13 15 5 ..

GSM22466 normal 17 11 5 ..

.. .. .. .. .. ..

TABLE 4: GENE EXPRESSION VALUES SUBSTITUTED BY GENE INTERVALS Patient class EST AK026789 ..

GSM22449 cancer -0.11 -0.08 0.415 0.435 ..

GSM22450 cancer -Inf -0.785 -Inf -0.04 ..

GSM22451 cancer -Inf -0.785 -Inf -0.04 ..

GSM22452 cancer -0.145 -0.110 0.245 0.260 ..

GSM22453 normal -0.445 -0.415 0.260 0.295 ..

GSM22454 cancer -0.510 -0.475 0.060 0.105 ..

GSM22455 cancer -0.395 -0.345 -0.025  0.000 ..

GSM22456 cancer -0.760 -0.535 0.260 0.295 ..

GSM22457 cancer -0.510 -0.475 0.235 0.245 ..

GSM22458 normal 0.12  Inf 0.435   Inf ..

GSM22459 cancer -0.760 -0.535 -Inf -0.04 ..

GSM22460 cancer -Inf -0.785 0.145 0.160 ..

GSM22461 cancer -Inf -0.785 -Inf -0.04 ..

GSM22462 cancer -Inf -0.785 -Inf -0.04 ..

GSM22463 cancer -0.455 -0.445 -Inf -0.04 ..

GSM22464 cancer 0.045 0.120 0.415 0.435 ..

GSM22465 normal -Inf -0.785 0.295 0.390 ..

GSM22466 normal -0.015  0.045 0.175 0.235 ..

Each class generates the number of class association rules  which are shows in figure 3.

Fig. 3. Number of Class Association Rules Generated  The Class-Association-Rules are generated based on closed frequent itemset with support of 50% and confidence of 100%.

The generated rules are used for classification. The antecedence of each rule is the consequent is the membership of class c. Then the class association rules classifier model is constructed which is represented in figure 4.

Fig. 4. Class Association Rules Model   The last step of associative classification is prediction or class assignment techniques. The last phase of classification reads the unknown discretized sample or test set and association rules for the class. The score based function evaluates the how many rules are satisfied, even partially in each rule. Then compute the score values for each rule. Finally the score value is assigned the class of the maximally satisfy to the test object. In our proposed methodology, the process of prediction or class assignment for test data, the researcher implemented the score based prediction. .

For testing data, label removed breast cancer data and classification performance tested via leave one out cross validation method. The following table 5 presents the class prediction results using score based values. It has been analyzed that the use of gene intervals improves the classification accuracy as well as under or over expression and generates significant rules that are capable to find individual variation.

For example, ABCC11 and IL1R2 genes presented in figure 4 these genes are under expression and all these genes are related to breast cancer [16, 17].

TABLE 5: CLASS PREDICTION USING SCORE BASED PREDICTION METHOD  Scores Predicted Class Real Class  0.16306184896678674, 0.11787963311752411 cancer cancer 0.1224552572850139, 0.0397661453730037 cancer cancer  0.44353396669274453, 0.07036692343792059 cancer cancer 0.188646764482539, 0.21119206413432903 normal cancer 0.1522962941752123, 0.2154521600658755 normal normal  0.4197666787808435, 0.30694558869809824 cancer cancer 0.48534506530073757, 0.14346844132709374 cancer cancer 0.40650021365795297, 0.13314684682620015 cancer cancer 0.3590791197979314, 0.18677205116904233 cancer cancer  0.11816739414034069, 0.40892631973628973 normal normal 0.48013078686644045, 0.27622136998949687 cancer cancer 0.4138426396015541, 0.14924947444406078 cancer cancer 0.34798041698293924, 0.1273183791711423 cancer cancer  0.40543790078076125, 0.04401089031827933 cancer cancer 0.20258661595296582, 0.05767396607869007 cancer cancer  0.4627835656463016, 0.4517425343821467 cancer cancer 0.1619104728401953, 0.49982055846561274 normal normal  0.17006433387436767, 0.13532194623044094 cancer normal ? .. ..

A. Comparative Analysis The proposed associative classification algorithm compared  with bench mark classification algorithms viz., Support Vector Machine, Linear Discriminant Analysis, Decision Tree algorithms. The proposed algorithm obtained best result and reduce the time complexity to compare with classical rule generation and classification algorithm.

TABLE 6: EXPLORATION OF VARIOUS SETTINGS IN RULE GENERATION  Min.

sup.

(%)  Min.

conf.

(%)  Number of Rules Using A-  Close  Total Time for A-Close (Second)  Number of Rules  Using Apriori  Total Time for Apriori  (Second)  10 50 2636 8.66 41479 165.83 10 80 2633 8.78 41470 169.74 10 90 2632 8.83 41469 163.66 10 100 2632 8.88 41469 169.54 8 90 3086 10.34 45970 187.14  20 90 600 0.68 1250 0.87 30 90 326 0.17 982 0.86 40 90 212 0.10 780 0.96 50 90 126 0.07 370 0.86 50 50 126 0.09 370 0.89   The above table 6 shows comparative analysis proposed  closed frequent itemset algorithm with apriori algorithm and shows that the of number of rules generation. The following figure 6 shows that comparative analysis of number of rules.

Fig. 6. Comparative Analyses on Rules   The figure 7 depicts the time taken to generate number of rules.

Fig. 7. Comparative analysis of time taken   From that comparative analysis the proposed classification algorithms provides better accuracy then all bench mark or classical classification algorithms. The following figure 8 shows that accuracy and error rates of Associative Classification on microarray gene expression data using gene intervals algorithm with traditional classification algorithm.

8% 10% 20% 30% 40% 50% 80%  N um  be r o  f c la  ss a  ss oc  ia tio  n ru  le s  Minimum Support %  Apriori Proposed Methodology    8% 10% 20% 30% 40% 50%  Ti m  e (S  ce )  Minimum Support %  proposed methodology Apriori           Fig. 8. Comparative Analysis Classification Algorithms

V. CONCLUSION Associative Classification techniques are used to make better  decision in critical situations. The proposed associative classification called as Classification of microarray gene expression data using associative classification and gene expression intervals used to classify the gene expression with gene intervals in affected gene expression. The experimental results are carried out by using the gene expression of breast cancer. The associative classification on gene expression data obtained the best prediction and accuracy of the classification result. The proposed algorithm was tested with two class and multi class data sets. The classification algorithm was compared with the classical classification algorithms such as Linear Discriminant Analysis, SVM, and Decision Tree. After the comparison of traditional classification algorithms, as per the view of possible error rates the Associative Classification algorithm is best for biological data. The results of this work are used to drug designer for cancer diseases. The proposed algorithm works on gene expression data. In future, it will be implemented on hadoop and big data mining for biological data.



VI. REFERENCES [1] Han,J., and Kamber,M., ?Data Mining: Concepts and Techniques?,  Morgan Kaufmann Publishers, Elsevier, 2002.

[2] Tuimala,J., and Laine,M.M., ?DNA Microarray Data Analysis?,  Second Edition, PicasetOy, Helsinki, 2005.

[3] Nagata, K., Washio, T., Kawahara, Y. and Unami, A., ?Toxicity  prediction from toxicogenomic data based on class association rule mining?, ELSEVIER journal, Toxicology Reports, vol.41, no.10, pp. 1133-1142, 2014.

[4] Garcia, S., Luengo, J., S?ez, J. A., L?pez, V. and Herrera, F., ?A survey of discretization techniques: Taxonomy and empirical  analysis in supervised learning?, Knowledge and Data  [5] Alves,R., Rodriguez.B.D.S. and Aguilar. R.J.S., ?Gene association analysis: a survey of frequent pattern mining from gene expression data?, Briefings in Bioinformatics, 2009, vol.2, no.2, pp.210-224.

[6] Zakaria, W., Kotb, Y. and Ghaleb, F., ?MCR-Miner: Maximal Confident Association Rules Miner Algorithm for Up/Down- Expressed Genes?, Applied Mathematics and Information Sciences, vol.8 no.2, pp.799-809, 2014.

[7] Creighton,C.  and Hanash,S., ? Mining gene expression databases for association rules?, BMC Bioinformatics, vol.19, no.1, pp.79- 86, 2003.

[8] Snousy, A. M. B., El-Deeb, H. M., Badran, K. and Al Khlil, I. A., ?Suite of decision tree-based classification algorithms on cancer gene expression data?, Egyptian Informatics Journal, vol.12 no.2, pp.73-82. 2011.

[9] Refaeilzadeh, P., Tang, L. and Liu, H., ?Cross-validation?, Encyclopedia of database systems, Springer US. pp. 532-538, 2009.

[10] R. Agrawal and R. Srikant, Fast Algorithms for Mining Association Rules, Proceedings of the 20th Int. Conf. on Very Large Data Bases (VLDB94),475486, Santiago de Chile, Chile, 1994.

[11] Alagukumar, S., and Lawrance R., "A Selective Analysis of Microarray Data Using Association Rule Mining." Procedia Computer Science, Vol.47, pp.3-12, 2015, doi:10.1016/j.procs.2015.03.177.

[12] Alagukumar, S., and Lawrance R., ?Algorithm for Microarray Cancer Data Analysis Using Frequent Pattern Mining and Gene Intervals?, International Journal of Computer Applications, ISSN: 0975 ? 8887, no.1, pp.9-14, June 2015.

[13] Pasquier, N., Bastide, Y., Taouil, R., & Lakhal, L. ?Pruning closed itemset lattices for association rules?., In BDA'1998 international conference on Advanced Databases pp. 177-196. 1998.

[14] Giugno R, Pulvirenti A, Cascione L, Pigola G, Ferro A.

MIDClass: Microarray Data Classification by Association Rules and Gene Expression Intervals. Tang H, ed. PLoS ONE.

2013;8(8):e69873. doi:10.1371/journal.pone.0069873.

[15] http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1379 [16] Wang, Zuncai, et al. "The prognostic biomarkers HOXB13,  IL17BR, and CHDH are regulated by estrogen in breast cancer." Clinical Cancer Research 13.21 pp. 6327-6334, 2005  [17] Ghilardi G, Biondi M, La Torre A, Battaglioli L, Scorza R ? Breast cancer progression and host polymorphisms in the chemokine system: role of the macrophage chemoattractant protein-1 (mcp- 1)? -2518 g allele. Clinical Chemistry 51: 452?5.2005.

[18] Dash, Rajashree, Rajib Lochan Paramguru, and Rasmita Dash.

"Comparative analysis of supervised and unsupervised discretization techniques." International Journal of Advances in Science and Technology 2.3 (2011): 29-37.

