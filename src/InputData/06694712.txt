An Improved BP Algorithm over Out-of-order Streams for Big Data

Abstract?Due to the difficulty of getting the association rules over out-of-order streams for big data, a new improved BP algo- rithm based on dynamic adjustment is proposed. We firstly use a dynamic adaptive structural adjustment mechanism to change the network training structure according to the environmental requirements, which can automatically remove invalid training node, and optimize the iterative training process. Secondly, we adjust three factors (i.e. learning index, momentum factor and scaling factor) during the learning process to speed up the learning response, and to enhance the stability of the network.

Simulation results show that compared with traditional BP algorithm, this algorithm can get more convergence times,the convergence rate can be improved effectively, and finally obtain the association rules over out-of-order data streams.

Keywords?BP Algorithm, Out-of-order Streams, Machine Learning, Big Data

I. INTRODUCTION  IN big data, we cannot get the association rules out of thesequence data through the current software tools within a reasonable time. Traditional data processing mode is that the collected data is stored in a database management system and then the users inquire to get the final answer. However, it is inappropriate for massive, endless real-time data stream[1].

The BP algorithm is an effective learning prediction algorithm, which is capable of massively parallel information processing, and has a strong ability to simulate the nonlinear system[2].It can also effectively predict the data correlation over huge amount of data stream to identify the association rules. How- ever, the traditional BP algorithm still has some deficiencies.

In specific applications, the learning rate of network is often fixed in case of increasing the number of iterations. In this way, network performance will deteriorate so that it will make a great contradiction between the learning speed of algorithm and network stability. In addition, there are still inherent  Kun Wang,Linchao Zhuo,Heng Lu,Huang Guo,Lili Xu and Yuhua Zhang are with Key Lab of Broadband Wireless Communication and Sensor Net- work Technology (Nanjing University of Posts and Telecommunications), Ministry of Education, Nanjing, 210003, China. Corresponding author: Kun Wang,kwang@njupt.edu.cn  This work was supported by National 973 Program of China (2011CB302903); NSFC (61100199, 61100213, 61170276, 61201160, 61201222); Specialized Fund for the Doctoral Program of Higher Education (20113223120007); Program of Natural Science for Universities of Jiangsu Province(10KJA510035, 12KJD510007); Open research fund of Key Lab of Broadband Wireless Comm. and Sensor Netw. Technology (NUPT), Ministry of Education (NYKL201107);Scientific Innovation Project for Postgraduates of universities in Jiangsu Province(CXLX12 0484,CXLX13 463).

defects in BP algorithm, such as the network structure which is difficult to determine, the hidden layer structure determined by experience, long training time, slow convergence speed and a poor prediction[3,4].

In recent years, the main improved measures to BP algo- rithm include the following aspects. (1) When iterations are increasing, adjustment speed will be slow. Xie et.al proposed an algorithm which can improve the momentum term of the weight adjustment rule[5]. The weight adjustment speed can be quicker and the process will be smoother. This algorith- m can realize quicker convergence rate and better tracking accuracy. (2) The traditional algorithm is easily converging to local minimum in learning process. Wen et.al proposed a new algorithm, which can gradually increase the test data and the hidden units[6].(3) Convergence rate and convergence precision are two main drawbacks in traditional BP algorithm.

Li et.al proposed a new algorithm called GA-BP combined with genetic algorithm and BP algorithm, which can greatly improve convergence speed and accuracy[7].(4)The structured parameter selection and learning rate in artificial neural net- works. Li et.al proposed a self-adapting algorithm of BP in artificial neural network[8]. It can make the selection of input units, hidden units and learning rate easy in the course of training, reduce external interference and improve the self- adapting ability of BP neural network. Xu et.al proposed an improved algorithm which is obtained by modifying the action function, regulating the learning rate and choosing the initial weights[9]. They also used an example about license plate recognition technology, proving that the improved BP algo- rithm has some advantages in fast convergence speed, short recognition time and high recognition rate. (5) BP algorithm usually uses Sigmoid function, and when the Sigmoid function is in the saturation region, the weights correction in the weight correction formula becomes negligible, so that it will make the network training into a saturated state which will greatly reduce the learning efficiency[10].

In order to deal with the problems described above, and make BP algorithm have stronger learning ability, effectively reduce the hidden layer nodes, and get more convergence times, this paper presents an improved BP algorithm based on dynamical adjustment (IBPDA). We use a dynamic adaptive structural adjustment mechanism to adjust three factors during the learning process, in order to speed up the learning response, to enhance the stability of the network, and finally obtain the association rules over out-of-order data streams.



II. IMPROVED BP ALGORITHM BASED ON DYNAMIC ADJUSTMENT  The algorithm we proposed is different from the traditional BP algorithm in the following aspects: firstly, a novel method is introduced in this algorithm to select the number of neurons.

Secondly, we use a self-adaptive adjustment mechanism to dynamically change the three factors, which makes it possible to achieve the desired convergence with less learning iterations and obtain the association rules over the data stream.

A. Determination of the number of neurons In the BP algorithm, the number of neurons is generally  selected through experience value. But the number of inputting samples is not always fixed. This leads to the problem that the number of neurons in the network cannot always be changed artificially during the training iteration. Once the number of neurons is fixed, the network learning model remains un- changed. The excessive number of neurons will cause some redundant nodes, which will result in the performance degra- dation. If the number of neurons is few, it may not converge during the learning process, which will lead to the decline of learning precision significantly. In order to improve the efficiency of the algorithm, we design a method to select the self-adaptive number of neurons dynamically at the beginning stage of learning.

Suppose that the output of the input layer node is equal to its input in the network structure. The number of nodes at output layer is L. The number of nodes at hidden layer is Q. The input of hidden layer and output layer node is the weight sum of the output from nodes at the previous layer, the excitation of each node is decided by Sigmoid activation function.

Assume that there are N training samples in learning phase of the training. We use a fixed sample of input-output patterns to train the network. If the output of network is different from the desired output, the error signal from output terminal will be transmitted in back-propagation to input layer. The weighting factor is constantly revised in dissemination process, so that the output of node at output layer can be close to the desired output. After the adjustment of weight factor of sample, we can use formula (1) to determine the neurons number(NH )in hidden layer:  NH = ? N1 ?N0 +NP /2 (1)  N1 represents the number of input neurons. N0 represents the number of output neurons. NP represents the number of training samples. We can use Sigmoid activation function to calculate the error in each layer. The learning phase of training samples is completed until the calculation results meet the terminal condition.

B. Optimal selection of neurons After the determination of the number of neurons by formula  (1), the problem of invalid or similar related nodes will still exist. These redundant nodes lower the efficiency of the algorithm. Therefore, we propose a novel neurons optimization method.

The sample input is as follows: (1)A set of corresponding learning samples group:(x1,t1 ),(x2,t2),...,(x3,t3),xs, 1 6 s 6 n,represent the first s input;ts, 1 6 s 6 n, represents the corresponding output.

(2) There are m input nodes at input layer.

(3) In the output layer has only one output node.

(4) The output of previous layer is the input of next layer.

Different layers have different numbers of nodes and different types of activation functions. Suppose that the number of learning samples is n,opiis the output of p-th learning sample in nodes at i-th hidden layer,opj is the output of p-th learning sample in nodes at j-th hidden layer..

Definition 1 The output of P-th sample???????  o?i = n =  n? p=1  opi  o?j = n =  n? p=1  opj  (2)  The learning sample can be represented by formula (3).??????? xp = opi ? 1n  n? p=1  opi = opi ? o?i  tp = opj ? 1n n? p=1  opj = opj ? o?j (3)  Then the correlation coefficient between opi and opj can be indicated by formulas (4).

Rij =  n? p=1  xptp? n? p=1  x2p ? ?  n? p=1  t2p  (4)  It is clearly shown that?1 6 Rij 6 1, and the linear correlated modulus betweenopiandopj is increasing and approximates to 1 with the module ofRij , while the decentralization coefficient is decreasing.

Definition 2 Correlation Coefficient  ?ij = |Rij | =  n? p=1  xptp? n? p=1  x2p ? ?  n? p=1  t2p  (5)  This function can describe the correlation between the nodes at hidden layer. ?ijrepresents the correlation coefficient between the i-th node and the j-th node at hidden layer. If the value of?ijexceeds the threshold, it means that the i-th node and the j-th node has the same function. So these two neurons can be merged into one.

Definition 3 Decentralization Coefficient  Si =  n  n?  o2pi ? o?j2 (6)  This function can describe the dispersion between the nodes at hidden layer. The small value of Simeans that the output     in i-th neuron changes very little. It is invalid to the network training. Thus this node should be deleted.

By using definition 1,2,3 we can effectively cut out or com- bine the number of nodes at hidden layer. Therefore, the times of repetitive training and learning can be reduced. The error can be controlled within a reasonable range. The total sample error reduces smoothly and the convergence rate improves. In a training period, the weights and thresholds remain unchanged until all samples have been trained once. According to the total sample error, we can modify the correlation coefficient and the decentralization coefficient of each neurons node, and then proceed to the next cycle of training.

C. Improved algorithm based on three factors The learning propagation model in BP algorithm is changed  with the number of neurons, while the initial value of the weight vector is randomly selected based on statistical the- ory [14]. Although this approach is helpful to increase the probability of obtaining a global optimal value, blindness and randomness still exist. In order to deal with these problems, we propose a new initial value selection method. Since the Sigmoid activation function is used in algorithm, the actual output value is in the interval [0, l]. In order to avoid the blindness in choosing the initial weights, we use the stepwise searching method. Firstly, the range interval is divided into N equal regions with respect to feedback network. The initial weight is randomly generated in the N regions to start learning.

Then the region with the minimum error is selected to be divided into N equal regions. The above step is repeated until the error function value no longer reduces. The algorithm will stop iteration and find the optimal point when the error value reaches the learning terminal condition. This method can effectively avoid sliding to a local minimum when the interval is quite small.

At the beginning of the algorithm, we calculate the actual output value of each node by determined activation function.

Definition 4 The value of input training sample  o = f(x) (7)  In practical applications, the most common type activation function is Sigmoid function [15]. The Sigmoid activation function and its derivative in closed interval [0,1] is defined as: {  f1(x) =  1+e??x  f ?1(x) = ?f1(x)[1? f1(x)] (8)  The compression degree in Sigmoid function is decided by?.

We generally take? = 1 to avoid falling into local minimum.

According to the above definition, when the output value of the respective units is close to 0 or l, the derivative value of Sigmoid will be close to 0. By using the definition 4, we can start iterative learning in the identified learning propagation model network. The variance of performance is calculated by definition 5 and the error term in each node at output layer is obtained by definition 6. Then the error is transmitted in back-propagate propagation to the hidden layer to for iterating.

Definition 7 is used to calculate the error term in each node at hidden layer.

Definition 5 The function of variance of performance  E(?) =   ? k?output  (tk ? ok)2 (9)  tk(k=l,2,...,n) is the desired output value of the sample, ok is the actual output value of k-th node at output layer.

Definition 6 The error term in each node at output layer  ?k = o ? k(tk ? ok) = ok(1? ok)(tk ? ok) (10)  tk(k=l,2,...,n) is the desired output value at output layer ok is the actual output value of k-th node at output layer.

Definition 7 The error term in each node at hidden layer  ?k = o ? h  ? k?output  ?ji?k = ok(1? ok) ?  k?output  ?ji?k (11)  tk(k=l,2,...,n)is the desired output value at hidden layer, ok is the actual output value of k-th node at hidden layer.

Compare the error value with the learning terminal con- dition. If the error precision meets the set requirements, the iteration will be end up. The final result is output. Otherwise the connection weight is modified by definition 8.

Definition 8 The correction value of connection weight  4?ji = ??jxij (12)  ?ji = ?ji +4?ji (13) ? is the initial learning index. The smaller ? can guarantee  a more stable convergence. The bigger ? can improve the convergence speed. xji is the output from node i to node j.

We can adjust the connection weight by using formula (13).

From the formula (12.13) we can know that each modification of connection weight is associated with the learning rate in BP algorithm,so as to ensure the change of learning factor with the changing the weights .Only in this way can the BP network model be self-adapt and adapt to the increasing number of learning. Therefore, we use definition 9 to implement the self- adaptive adjustment.

Definition 9 Self-adaptive adjustment mechanism  4?(k) = ?(?5 E(?(k)) + ? 4 ?(k ? 1)) (14) ? is a vector consisting of all weights. E is the weight vector  in network communication model. 5E(?(k)) is the gradient of ?(k), k indicates the k-th learning? is the learning index, ? is the momentum factor. If the value of and is fixedthe network can not get rapid and stable convergence. So we use formula (14) to modify the learning index and formula (15) to modify the momentum factor.

?(k + 1) = ?(k)? E(k) E(k ? 1)  (15)  ?(k + 1) = ?(k)? E(k) E(k ? 1)  (16)     When ? is largely different from the learning target error, the value of ? will increase.We adjust the learning index and momentum factor to obtain a more stable convergence with higher learning efficiency. At the beginning of learning phase, a large learning index value is required to accelerate the learning speed. When the learning phase is close to the optimal zone, the learning index must accordingly be smaller. Otherwise, the weight would oscillate without convergence, which reduces the stability of network.

Thus, after determining the neuron number of input layer, output layer and hidden layer based on the sample data, we set learning mode and initialize layer parameters. The connection weights and three factors are adjusted dynamically to calculate each unit error and variance according to formula (9-11). Then results are compared with the terminal condition of learning. If the values satisfy the condition, the learning process stops. If the condition is unsatisfied, it returns to the learning mode to re-iterate the training until the error condition satisfies. Then we can obtain the association rules over data flow.

The flow chart of improved BP algorithm is shown in Figure 1.

Fig. 1: Algorithm flow chart

III. SIMULATION In the simulation, the proposed IBPDA algorithm will be  compared with the traditional BP algorithm. We use Matlab 7.0 to implement IBPDA. Simulation settings are shown in Table 1.

TABLE I: Simulation Settings  The number of neurons Input layer 10  Hidden layer 30 Output layer 1  network parameters  Right Learning index 1.5 Momentum factor 1.5  Threshold learning factor 1.5 Scaling factor 1.1  Convergence counter 1  A. Algorithm performance evaluation indicator  In the traditional algorithm presented by Uedan[2], right learning index, momentum factor and threshold learning index will not change with the increasing iteration times upon initial- ization. In order to discuss the efficiency of IBPDA algorithm, we use the convergence rate and convergence time as the indexes to evaluate the algorithm performance. If the number of errors is within the setting range after one cycle of training for all the samples, it could be judged as a convergence. Then we increase the convergence counter by one. The higher value of Convergence counter accounts for more convergence and the better performance of the algorithm.

B. Simulation results  To verify the performance of the improved algorithm on data analysis, we gathered 20 groups of random datasets for simulation experiments. We changed power index, threshold learning index and right learning index, respectively. The comparison shows the advantage of IBPDA on the number of convergence. Finally, we compared IBPDA to the traditional algorithm proposed by Uedan on the convergence time through the dynamic changes of three factors, which shows its higher algorithm efficiency.

We used the rand () function to randomly generate 20 groups of datasets, the discrete distribution points of raw data before training are shown in figure 2.

Fig. 2: The discrete distribution points of raw data     Experiment 1: Right learning index is dynamically changed by formula (14), while the other two indexes, initial momen- tum factor and threshold learning index, are fixed. According to the random generated data, we compared the improved BP algorithm with the traditional BP algorithm to observe their differences in convergence times. The simulation results are shown in figure 3.

Fig. 3: Comparison of right learning index  In figure 3, two convergence curves show that there is not large difference between convergence times and convergence rate at the initial stage. Once it declines to a certain extent (Convergence is 50 times), the improved algorithm can earlier achieve better convergence times before right learning index declines further. However, with the decline of right learning index, two algorithms become consistent on the convergence times and convergence rate, which shows that right learning index will affect the convergence while the convergence times are limited.

Experiment 2: Implementing the BP algorithm with the random data, we compared the improved BP algorithm with the traditional BP algorithm to observe the differences in convergence times through dynamically changing momentum factor by formula (15) with fixed threshold learning index and right learning index. The simulation results are shown in figure 4.

In figure 4, two convergence curves show that IBPDA algorithm and the traditional algorithm keep consistent on the convergence times and convergence rate under the same initial conditions. But with the decrease of momentum factor, IBPDA can get more convergence times and higher convergence rate than the traditional one, and finally become stable when the momentum factor is on a large level.

Experiment 3: Threshold learning index is dynamically changed by formula (13), while the other two indexes are fixed.

According to the random generated data, we compared the improved BP algorithm with the traditional BP algorithm to observe their differences in convergence times. The simulation results are shown in figure 5.

In figure 5, two convergence curves show that IBPDA algorithm can earlier achieve more convergence times before  Fig. 4: Comparison of momentum factor  Fig. 5: Comparison of threshold learning index  threshold learning index declines further. But there is no obvious advantage in convergence rate compared with the traditional algorithm.

Experiment 4: We dynamically change all the three factors at the same time. According to the random data, we compared the improved BP algorithm to the traditional BP algorithm to observe the differences in convergence times. The simulation results are shown in figure 6.

In figure 6, the blue Goal curve represents the target con- vergence points. After implementation, the algorithm is more effective when the curve is closer to the blue target function.

Comparing the two convergence curves, IBPDA can reach the convergences with shorter time and less convergence times.

We make data convergence by running the BP algorithm. The algorithm is more effective if the data points are closer to the original data. Through simulation experiment, the improved algorithm can make effective convergence of the discrete data.

And the error range can be controlled in a reasonable scope under the condition where the training time is increasing. It has a good convergence, but the expense paid for the improvement is the time. Using the dynamic adjustment of three factors     Fig. 6: Comparison of the convergence time  can achieve better learning terminal condition and get a better network performance.



IV. CONCLUSIONS We propose a new improved BP algorithm based on dy-  namic adjustment to get the association rules over out-of- order streams for big data.Considering the effect on network performance that caused by the number of neurons in the BP algorithm, we propose a new method of neurons optimization.

We use a dynamic adaptive structural adjustment mechanism in the learning process to speed up the learning response and enhance the stability of the network. In this way, we can obtain the association rules over data flow. Simulation results show that the convergence of the algorithm will be greatly improved by the dynamic change of each parameter while three factors are in the same initial value. Changing three factors at the same time can achieve the required convergence with limited iteration times and short operation time. Compared with the traditional BP algorithm, IBPDA has faster convergence speed and accuracy precision. Therefore, the network performance is improved effectively.

