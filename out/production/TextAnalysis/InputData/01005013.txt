Combining Fuzzy Rules and a Neural Network in an Adaptive System

Abstract - l t  has been shown that humans can rely on both rules or associations to solve a problem. We present a model in which rules may be applied to a particular sequence learning task, hut rather than the rules being applied in an all-or-none fashion, a continuum from fully representing to not representing a rule is required in order to model human task performance.



I. GENERAL INFORMATION  Computational models have had a large impact in trying to understand how humans solve a certain problem or how they perform on a particular task. In human learning, two main approaches have received considerable attention: one is to assume that human performance on a task is purely statistical (also called ussoc iaf ive)  and thus not guided by the application of explicit rules [ I ] .  In an attempt to simulate this kind of human learning, artificial neural networks have become very popular. One reason for this popularity is the fact that all leaming occurs through the changes of the connection weights and is thus guided by a purely statistical and general learning algorithm rather than an explicit rule to solve a particular problem. In this context it is worth mentioning that the type of neural networks applied have been shown to converge to Bayesian optima [2]-[4]. Other insights have revealed that a purely statistical mechanism is not enough to capture the variety of human responses in a range of learning experiments. In an attempt to simulate task performance here, the use of explicit rules was considered [5]-[SI. We agree that it is essential to have two learning systems (a statistical one and a rule-based one). The way that it bas been suggested that the rules in the rule-based part be implemented, however, postulates deterministic rather than stochastic mechanisms [SI. At this point we diverge from previous discussions of this issue. We do not intend to deny the fact that children or adults may apply deterministic rules under some circumstances, and we do not doubt that may have been the case in the studies mentioned [5]-[SI. In our learning experiments, however, which used different procedures than the previous ones, there is evidence that humans seem to have rather fuzzy representations of the rules or sometimes no representation at all [I] ,  [9], whilst only a minority represent the rules in their entirety. Given this, it is difficult to predict to what extent humans make use of a rule in our experiments. Moreover, we have found that rather than applying a single rule, humans often combine aspects of  different ones in a rather fuzzy way. The emphasis on fuzzy representation arises because humans usually did not apply a combination of each complete rule, but rather seemed to use parts of different rules as a consequence of trying to make analogies between different learning problems. It should be noted that the word fuzzy in our paper is not used as in the classical form of fuzzy logic [IO], hut rather as a type of soft computing that denotes the partial representation of the rules in question. A more detailed explanation will follow after the rules themselves have been introduced. Based on our experimental evidence, we have implemented a computational model that tries to capture the types of human processes used in dealing with the particular sequence learning task that provided the evidence for fuzzy representations rather than deterministic rules.

We start by giving a brief overview of the learning task, followed by a detailed description of our model.

11. THE LEARNING TASK  Participants were seated in front of a computer screen on which a signal flashed in a particular order at different screen locations, and they were told to react as quickly and accurately as possible by pressing the appropriate key on their keyboard (a unique key was assigned to each screen location, similar to [ I l l ,  [12]). They were not told that the signal flashes followed an underlying sequential structure at this stage. Lower reaction times accompanied by increasing accuracy on screen locations which were consistent with the underlying sequence structure previously experienced in the training phase were regarded as evidence of learning on test.

In addition, interviews after the experiment tried to explore the strategies (and rules) that people may have applied. The reaction times and accuracy of people who were able to verbalize particular rules were compared to those who did not verbalize rules. Moreover, the verbalized rules were analyzed in detail. More information ahout the experimental procedure and how the exact experimental conditions (e.g. the Experimental and the Control groups) were created can be found in [I] ,  [9], [13]. In these tasks, humans were trained on the following language (sequences), derivable from the expression below, where each letter refers to a particular screen location on which a signal flashed on (the keys on the keyboard did not carry the letters ABC, hut were just spatially different keys):  0-7803-7280-8/02/$10.M) 02002 IEEE 340  mailto:i.mclaren)@psychol.cam.ac.uk   XJY, X: (AB(C+)BA), Y: (ABB(C+)BBA) where XIY denotes choice between sequences X and Y, and C+ denotes a presentation of at least one C. In X, a single B follows the Cs because there had been a single B before the Cs. In Y, an additional B is added to each B in X. Hence, people should predict an A in sequence type X once a B has followed the unpredictable number of Cs. In sequence type Y, people should predict another B and then an A if a B follows the unpredictable numbers of C.

The general result of these experiments was that humans can exhibit both statistical and rule-based aspects of task performance, depending on the number of sequences they had to learn. If they are trained on more numerous sequences with odd numbers of C only, they will learn those sequences and fail to generalize to even numbers of C. If however, they are trained on more numerous sequences with both odd and even numbers of C, it was found that they not only learn those sequences, but also generalize to both novel odd and even numbers of C. In both of these cases, people were not able to verbalize substantial parts of the rules. Therefore, they were probably not able to make use of any rules to tackle these problems. Because they nevertheless learned the task, it may be hypothesized that their performance was based on purely associative learning. More evidence for this hypothesis stems from a simulation with a type of recurrent neural network [I41 that was shown to converge to Bayesian optima [2]-[4]. This network almost entirely overlapped (in terms of its performance on the task) with both learning and generalization results from the participants in the experiments, which suggests that humans may have solved the task by extracting the statistical structure of the task in an associative way.

If humans are trained on less numerous sequences with odd numbers of C, however, they also show generalization to even numbers of C (the same was found for humans who are trained on even numbers of C and show generalization to odd numbers of C). In this case, their performance is unlikely to be purely statistical and the recurrent network simulation fails to model the results (= network showed no generalization to even numbers). The reason why their performance does not seem to rely on statistical structure alone is because some humans partially verbalize aspects of the underlying rule, whilst a minority verbalizes them completely. Moreover, the rule-verbalizers were substantially better at generalizing to even numbers of C, and when they were left out of the analysis [I], no significant evidence for generalization to even numbers of C was found anymore. In the sequences above, participants who verbalize the rules would say that all sequences share the same analogies in that they are symmetric across the Cs and that the number of As and Bs before the Cs is the same as the number of As and Bs after the Cs. One person could even say that the signals on the locations corresponding to the Cs had flashed an odd number of times. The overwhelming majority, however, would only realize some aspects of the sequences, e.g. that all sequences had the basic structure ABCBA, which is symmetric, but  when asked about the number of flashes at each location, they typically had no idea. Others would verbalize chunks, i.e. repetitions of the same locations such as BB or CCC, but they were not quite sure in which sequences those repetitions occurred and how they related to the overall structure of the sequence. They could not tell, for example, that the Cs always repeated an odd number of times. Others were able to tell that there were either one or two Bs before and after the Cs, but did not detect the dependency between the number of Bs before the Cs and aAer the Cs. As previously mentioned already, when the two participants who verbalized the entire rule were left out of the data analysis, those left would reveal similar results to the entirely statistical neural network, i.e.

learning the trained odd numbers of Cs but showing little generalization to even numbers of Cs.

These considerations suggest that there might be a continuum between not representing aspects of the rule at all and having a full rule representation. We note that this was first suggested by Cleeremans based on a large number of experiments (summarized in [15]). So far, it also stands in line with our own empirical data, [9], [ 1 3 ] .  It would be difficult to generate such a continuum with classical Boolean logic, which would, if applied to our task, only allow either the representation of a rule or not. Our studies suggest that on more numerous sequences, performance is associative, which could be modeled without any reference to rules (consistent with the Boolean approach). However, on less numerous sequences, there is an interplay between rule-based and statistical processing. Moreover, only a minority of the participants represents the rules completely, whilst the majority can only tell about partial aspects of the rules or nothing at all. Purely statistical models, e.g. [14], are generally not able to model the generalization performance of humans on this task, as humans generalized to sequences with an even number of Cs where the models failed [l] .

Although models based on Boolean logic 191, if they interact with a statistical model, are capable of simulating human performance on our task with less numerous sequences (where humans show generalization to even numbers of C), the complete representation of rules on these tasks would also lead to generalization on the tasks with more numerous sequences, i.e. where humans show statistical performance (and thus do not generalize to an even number of Cs). Hence, a model is needed that switches adaptively from partly statistical/rule-based representations to purely statistical ones as the trained sequences become more numerous. It may still be possible to defend a model relying on Boolean logic by adding an external teacher that tells the model at which number of sequences it has to switch off the rule-based representations. But this would be a rather abrupt change as the sequences increase in number. Moreover, this change does not stand in line with the results we have obtained from studying humans. Humans rather show a gradual decline in terms of rule-representations, i.e. the representations become fuzzier as the sequences increase in number [submitted] and partial representation of rule-based aspects may be present whilst they perform in a statistical way.

0-7803-7280-8/02/$10.00 02,2002 IEEE 341    IILTHE MODEL  In order to implement the computational model, we closely adhered to the information that the participants gave us in the interviews after the experiment. It could not he decided whether humans reason using rules during the task, because the interviews were carried out after the experiment.

Nevertheless, we were able to infer that some participants have no rule-based representation (i.e. no verhalizable knowledge) at all whilst a minority are able to verbalize the entire rule after the experiment. In between, however, there seem to exist a variety of partial representations or fragments of the rule, e.g. some people become aware of symmetries, others of repeating elements or the basic sequential structure.

In addition, the more they could verbalize about the individual sequences, the more they seemed to be able to draw analogies between them, e.g. that ABCBA and ABCCCBA are analogous to each other because they only vary in terms of the number of embedded Cs. Two participants were even able to draw analogies between all sequences, e.g. that for all sequences, the number of Bs before the Cs determines how many Bs appear after the Cs.

In order to make use of those analogies, however, the participants had to perceive the individual aspects of the sequences first, i.e. they had to detect the symmetries and the repetitions in each of the individual sequences. For this reason, we made the assumption that each verbalized individual aspect of a sequence can vary between no representation or full representation, and thus could he indexed by values between 0 (no repr.) and 1 (full repr.). In classical Boolean logic, 0 and 1 are regarded as discrete values with no continuum between them. Our decision to rely on fuzzy logic, where continuous values exist between 0 and 1, was in line with OUT experimental evidence, i.e. that people gradually become aware of the entire rule-representation by first perceiving individual parts of the sequences which are verbalized in the interviews (i.e. symmetries, repetitions, etc.). If there had been only people who fully represented the rule ( I )  as well as people who have no representation of the rule at all (0), then both Boolean and Fuzzy Logic would converge on the same results. In our sample, however, there were many people who verbalized aspects of the rule hut not the entire rule, so rule-representation became a matter of degree [I]. Complete rule representation and analogy-making between the sequences, modeled using mechanisms inspired by Hofstadter, Mitchell and Marshall [16]-[19], would therefore happen automatically once the individual aspects (symmetries, repetitions, basic sequential order ABCBA, etc.) had passed certain thresholds. Additionally, some aspects of the sequence were more frequently verbalized than others, which had to be taken into account as well, e.g. the interviews indicated that it was more likely that participants became aware of the fact that the sequence of signals on the screen always followed the order ABCBA (where different letters stand for different screen locations), than it was for them to become aware of the fact that there were repetitions in some sequences, such as BB or CCC or that the AS and Bs are symmetric across the Cs. The probabilities of becoming  0-7803-7280-8/02/%10.00 02002 IEEE 342  aware of these sequential aspects as well as the exact data that our computational model achieved in an attempt to simulate human learning will not he considered in this paper, and can he found in [I], [20]. The purpose of this paper is to present an approach that models gradual rule acquisition in this learning task, and takes into account fuzzy representations of the rule as well. Each aspect in each sequence which is necessary for representing the rule, i.e. a symmetry, a repetition, etc. will have an activity value between 0 and I .  In order to generate rule representations, at least each element in at least two sequences must be represented in the correct order (ABCBA), i.e. each of these elements must have an activity that passes a certain threshold.

Moreover, both symmetries between the As and'the Bs must have activities that pass this threshold. The same must hold true for at least one BB sequence, with the addition that there is one more symmetry between the Bs as well as a repetition on the B elements before and after the Cs. Only if these symmetries and repetitions have reached activities that pass the threshold can the rule representation that the number of Bs before the Cs is the same as the number of Bs after the Cs he formed. In order to arrive at continuous activity values for each of these elements, we created a squashing function that was inspired by findings from human learning experiments. It has excitatory (p) and decay (h) elements and only one of them can he active at a time (i.e. either there is learning and thus an increase in activity or there is forgetting and thus a decrease in activity). It also has a term that modulates interference between other information that is learnt, i.e. the more sequences q a person has to learn, the less slhe can concentrate on a particular sequence and the more the activity will decay. On the other hand, the more often excitation of a particular element has happened in the past, the less its activity will decay, which is controlled through the number of previous excitations q. Bringing all this evidence together finally resulted in Equation 1.

U , * ,  = 1-  +il a, a, -  where h=(l-P) and p {0, I }  when applied and A=p=O when dormant.

At first sight, this looks like a very complex equation because it combines several things at once (e stands for exponential (Euler s number 2.718)). However, it becomes much easier if we consider that, at the most, either the upper part or the lower part of this equation can he active at any one time (either none of them is active (i.e. the equation stays dormant = nothing happens, with p=h=O) or there is excitation and therefore an increase in activity, which has the consequence that p takes on a value of 1 and h takes on a value of 0, or there is decay (with h=l and p=O). This is because there cannot be both excitation as well as decay at the same time.

Moreover, if there had not been any excitation in the past (i.e.

no learning), there can be no decay now (i.e. no unlearning).

In this equation, the activity of one time step is dependent on its own activity on the previous time step, i.e. ai+, is the activity of the next time step (on the left hand side of the equation) and is calculated by inserting the activity of the present time step ai into the right hand side of the equation.

At the start of training, this activity will be 0, but as soon as it is first excited it will generate a positive value in the range between 0 and I ,  which will change according to future excitation and decay. The number of times an element gets excited depends on a probabilistic process, which is based on the percentage of humans who verbalized this aspect of the rule in the interview after the experiment [ZO]. As 50 percent verbalized the basic order ABCBA, then, in order to implement appropriate parameters into the model with the right proportions in relation to the other verbalized aspects, we assigned a probability of 0.5 to excitation of the activity of a particular screen location in a sequence (even though this in itself would not directly result in the structure ABCBA being realized in the model 50 % of the time, that depends on other parameters such as threshold). As an example: when the sequence ABBCCCBBA is presented to the model (which has the sequential order ABCBA, because repetitions do not change the order of screen locations), each of the elements first A, first B, C, second B, second A has a 50 percen!

probability of being excited. Imagine that the first A and the C get excited and this sequence is not presented again for a while. For each training trial (that is each time another sequence is presented to the model), the previously excited activities will decay. If however, this sequence is presented many times, then the activities of those elements will on average be excited more often. The more often (11) they are excited, the slower will be the decay. The decay is further influenced by the number of other sequences c, the model experiences in training: the less this number is, the slower will he the decay. Running a simulation on an element in the experiment described above [ I ]  for 1,000 trials (4 sequences in training = on average, each sequence gets presented 250 times) reveals the following change in activity, if the probability of selecting an element is 0.5. The time series of the activity change over the 1,000 trials is displayed in Figure 1 (note that we were running 40,000 training trials in the simulation, because this was the time taken by recurrent neural networks such as the SRN [14], and we aimed for a reliable comparison between this model and our own).

This non-linear process shows the high impact of decay at the beginning of training (when the problem is not represented strongly enough). As training proceeds, however, decay will have less and less impact and the activity of this element will increase to a value close to I (which means full representation). Only if all the elements relevant to perceiving the rule in each sequence have values that indicate full representation (in our case values > .95), will analogy- making between different sequences be possible. This implementation reflects the empirical results in the human experiment [ I ] ,  where only a minority of the participants were able to report the entire rule. A larger number, however, had partial representations, e.g. some aspects relevant to the rule may have passed the .95 threshold, but not all of them so that no analogy-making leading to full rule comprehension was possible. In many cases, especially if the model, has to learn a large number of sequences, the activity values of each element are so small that not even a partial representation is possible. In these cases, in line with empirical evidence from studying humans [13], processing can be regarded as purely statistical. This equation therefore ensures that more numerous sequences 4 will he less likely to cause the model to pass threshold and thus represent the rules, whilst less numerous sequences will be more likely to make the model represent the rules.

0.8  0.6  0.4  0.2   l o  500 1000 FIGURE 1: Time series of activity change (values ranging from 0 to I on the y-axis) from training trial 1 to 1000 (represented an the x-axis).

We would like to underline, though, that this kind of equation is only one way of implementing the human process of gradually becoming aware of a rule (whilst making some reference to what has been found out about learning, decay and interference). The particular advantage of this equation, however, is that it is well suited to interface with the recurrent neural network that we are going to describe later on. Trained with full gradient descent, this recurrent neural network takes a long time to converge on this problem (40,000 sequence presentations, which is on average 10,000 presentations of each of the 4 sequences). By taking this  0-7803-7280-8/02/$10.00 02002 EEE 343    equation for the rule-based part, where the excitation of activity is in proportion to the slow statistical model (this is why we apply the square root to the exponent of the exponential in the upper right part of Equation I )  we were repeatedly able to simulate the interaction between the statistical part and the rule-based. If we had another, faster statistical model, which required less training trials to converge on this problem, the rule-based part would need to build up its activity faster, which would he possible if we omitted the square root of the exponent of the exponential.

Now we will describe the statistical part of the model. In our experiments, a particular recurrent neural network, the SRN [ 141, provided a very successful simulation of the human data when they seemed to rely on the extraction of statistical structure, both in terms of learning as well as generalization.

An overview of the SRN (Figure 2) and how it compares with other recurrent networks, is given in the taxonomies of Home and Giles [21] or Kremer [22]. Recurrent neural networks including the SRN constitute the largest family of temporal neural networks [23]. A recurrent network in general can be defined as a network containing a state that depends on at least one of its previous states [23]. In the SRN, the network receives input from the input vector, x (t), and the purpose is to predict the next input vector x (t+l) at the output values 0 .  The SRN has connections from the bidden units h (t) to the so-called context units, which are exact copies of the hidden units one time step ago, h (GI). At the next time step, the hidden units will receive input from the input units as well as the context units.

I Output units o I (uredict x (t+l) t weights  Hidden units h (t)  Context units h (t-1)  Hidden units h (t)  Context units h (t-1)  FIGURE 2: Elman s simple recurrent network  The hidden units will apply both kinds of information to predict the next step on the output level. The context units play an important role as they provide the network with a dynamic memory, i.e. depending on the sequence position, the very same inputs can result in different predictions from the network, because the hidden units will be able to develop different activities, i.e. even if the very same inputs appear repeatedly, their representations on the hidden units will be different. The connections from the hidden units to the context units are exact copies, whilst all other weights in the network are adjustable. The weight updates are by backpropagation of error (first discovered by Werbos [24],  0-7803-7280-8/02/$10.00 02002 IEEE 344  and then independently developed by a number of scientists [25]-[28]). We decided to use the most widely accessible form in our simulations, [27], which includes a bias term to compute the activity of each hidden and output unit.

In order to explain how the rule-based model interacts with the neural network, let us consider the following novel sequences: ABCCBA and ABBCCBBA after having experienced sequences with 1 and 3 Cs in training, with the model asked to predict the letter following the final B in the first sequence and the second last B in the second sequence, i.e. ABCCB=>? and ABBCCB=>? Humans who rely only on statistics and a statistical model such as the SRN have not been found to generalize to this case [ I ] ,  [ZO]. Humans who rely partly on statistics and partly on rules generalize to this case by making analogies to the underlying rules in the trained sequences. Our model also makes these analogies if it passes the thresholds of the sequential elements that are necessary to understand the rule, i.e. it would need to pass the threshold activities for each location A, B, C, B and A in a sequence to which an analogy is made. Moreover, it would need to pass the threshold activities of the symmetries between the A s  and between the Bs in this sequence. If this is the case not only in one sequence, but in a number of sequences (including the BB sequences where threshold activities for the repetitions must be passed as well), the model can induce the rule by drawing analogies to the respective predictions of those sequences. In an attempt to predict the final letter in the first sequence, it would make analogies to the rules in all the other sequences, i.e. take the activity of the symmetry between the A s  in the ABCBA sequence and multiply it with the activity of the location preceding it, i.e. the B in ABCBA. It would do the same in the ABCCCBA sequence. If it passes the thresholds for BB repetition, it would also make analogies to the BB sequences by taking the activity of the B locations in the ABBCBBA and ABBCCCBBA sequence and multiplying them with the symmetries between the first and final A s  in both sequences.

This process is described in great detail elsewhere [submitted]. Consequently, we have an analogy value a for each trained sequence that has passed its respective threshold activities. This analogy value (rule-based part) can then be multiplied with the output of the associative representation.

In the simple recurrent neural network, this output is a vector and the analogy value a coming from the rule-based part is a scalar. The formal way of writing this is displayed in Equation 2.

At first sight, this equation may again look pretty complicated, but in fact it is easier than one might think. The output is simply a component of the (3 dim.) output vector, which represents the prediction of the next location, e.g. the desired values of an A could he (l,O,O), the desired values of a B could be (O,l,O), etc.

The upper part of the equation is the output of a normal SRN (which is based on the hackpropagation algorithm. A detailed explanation of this equation can be found in [27]. In this equation, wik represents the weights from all the hidden units hr to the ,-th component of output vector o and ( is a bias term to it. The value e is the exponential (Euler s number    2.718). If there are no analogies (i=O analogies), the performance will be purely statistical. In this case, the output will reduce to the one of the SRN, which is reflected on the upper right hand side of the equation. If there are analogies, all the analogies are added (lower right hand side of equation) and divided by the total number of analogies plus 1 (which reflects the purely statistical prediction).



IV. CONCLUSIONS  It was postulated that the underlying processes of human sequence learning in this task seem to be fuzzy to at least some extent. Many times, an interaction is found between purely statistical and (partly) rule-based processes. As demonstrated in other papers [ I ] ,  [ZO], the rules that help to generalize to novel sequences with the same underlying structure are induced by making analogies to the rules in the trained sequences, if some thresholds of rule-awareness have been passed (e.g. in less numerous sequences), whilst the performance remains statistical if none of the thresholds of rule-awareness have been passed. Our model presents one possible way to simulate these results including the gradual (and often partial) acquisition of rules. It briefly sketches how these tules could interact with a purely statistical neural network. Although other ways to integrate fuzzy logic and neural networks exist, this model shows that fuzzy representations give rise to an interesting phenomenon in partly statisticalhle-based human sequence learning.

