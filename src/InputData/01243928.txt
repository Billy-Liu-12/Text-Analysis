Efficient Generation of Adaptive-Support  Association Rules*

Abstract - We propose here an efficient data-mining algorithm to discover Adaptive-Support Association Rules (ASAR) (71 from databases. Adaptive-support association rules are constrained association rules with application to collaborative recommendation sysfems. To discover association rules for recommendation systems, a specific value of target item in association rules is usually assumed and no minimum support is specified in advance. Based on  -size monotonocify of association rules, i.e., the number of association rules decreases when the minimum support increases, an eficient algorithm using adjustable step size for  finding minimum support and therefore adaptive-support association rules is presented. Experimental comparison with the fixed step size adjustment approach shows that our proposed technique requires less conipufation, both running time and iteration steps, and will alwaysfind a corresponding minimum support.

Keyword data mining, adaptive-support association rules, collaborative recommendation system  1 Introduction Data mining has recently attracted tremendous  amount of attention in the database and machine learning research because of its wide application in many areas, such as market basket analysis, prediction, decision support, financial forecast and collaborative recommendation. Collaborative recommendation (sometimes known as collaborative filtering) is a process by which information on the preferences and actions of a group of users is tracked by a system which then, based on the pattems it observes, tries to make useful recommendations to individual users. Many techniques have been proposed for collaborative recommendation over the past decade. In addition to  the classical linear correlation-based method [I I], there are Bayesian classifier and Bayesian network model [5], neural networks paired with feature reduction techniques [4], graph-theoretic approach [Z], and data mining approach [7,8]. For the data mining approach, constraint-based association rules such as class association rules [8] and adaptive-support association rules [7] techniques have been proposed In this work, we are particularly interested in improving the efficiency of discovering ASARs for collaborative recommendation systems.

For a given transaction data set, the discovery of ASARs assumes that a target item, a specified minimum confidence and a desired range for the number of rules are given. It proceeds to discover association rules with the target item in the heads of the rules. Such that the number of rules is in the desired range and the rules have the highest possible support. In [7], an algorithm called ASARM is proposed to discover this type of rules. The algorithm is a variant of the CBA-RG [8] and therefore of the Apriori algorithm [I]. It differs from those two algorithms in that frequent itemsets and rules are generated simultaneously. Howewr, in the process of calculating minimum support in order to obtain desired number of rules, the ASARM algorithm uses a fmed step size iterative approach, which may not be quite efficient and might not be able to find the minimum support for some desiredrange of association rules. In this work, we propose an adjustable step size approach to calculate the minimum support and therefore ASARs. Experimental comparison with the fixed step size adjustment approach shows that ow proposed technique requires less computation, both running time and iteration steps, and will always find a corresponding minimum suppon.

The rest of our paper is organized as follows.

Section 2 reviews the problem of the discovery of  * 0-7803-7952-7/03/%17.00 Q 2003 IEEE. 894  mailto:slwang@nyit.edu   ASARs. Section 3 presents the proposed data-mining algorithm. Section 4 shows the numerical comparison with the fixed step size approach. A conclusion is given at the end of paper.

1.1 Linear correlation-based method  The vast majority collaborative recommender systems use the correlation-based method to model similarities between users, where they calculate the vote from the active (or target) user (indicated with a snbscripta) for article j ,  p a , , , ,  as a weighted sum of the  votes of other users. The weights reflect correlations among users.

As mentioned in [4], such correlation-based methods suffer from several drawbacks. Firstly, the significance of the correlations between users are not measured; Secondly, when no correlation is found between two users, potentially useful information about these two users is lost; Most importantly, if two users do not rate products in common, they can not be similar under the correlation method even if they share common interests. Our approach can possibly overcome these drawbacks.

1.2 Bayesian classifier and bayesian network model  Breese, Heckerman and Kadie p] list and test several algorithms for collaborative recommendations.

They propose a new approach for finding dependences among products by using a Bayesian classifier and a Bayesian network model. The idea of this approach is similar to our article associations. But they need to calculate the conditional probabilities of all the possible ratings for an article given all possible ratings for other products, which is computationally expensive and they can not estimate how good a prediction they made is. Our approach only needs to find some significant dependence among products, which is above a certain minimum support and we can evaluate a prediction according to the support and confidence of the rule. Since we are only concerned with recommending a certain number of interesting products, not predicting the ratings for all products, the significant dependencies are good enough.

1.3 Neural networks  Billsus and Pazzani p] present a framework for applying machine leaming algorithms paired with feature reduction techniques, such as singular value decomposition (SVD) or information gain, for  collaborative recommendations. Firstly, they use feature reduction techniques to reduce the dimension of the rating data, and then neural network are applied to the simplified data to construct a model for recommendation. While this framework is good for neural networks, it is not so appropriate for rule-based leaming. For example, after the singular value decomposition, the previous boolean valued matrix becomes a matrix containing continuous numbers. So we need to discretize those continuous numbers in order to derive rules from them, which is an additional problem.

2 Problem statement This section reviews the basic definition and  terminology of sssociation mles and adaptive-support association rules.

2.1 Mining of association rules  The problem of mining association rules was introduced in [I]. Let I = { il, i2,..., i, } be a set of literals, called items. Given a set of transactions D, where each transaction. T is a set of items such that T 5 I, an association rule is an expression X Y where X ~ I ,  Y I ,  and XnY=@.  The X and Y are called respectively the body and head of the rule. An example of such a rule is that 90% of customers buy hamburgers also buy Coke. The 90% here is called the confrdence of the rule, which means that 90% of transaction that contains X also contains Y. The support of the rule is the percentage of transactions that contain both X and Y . In other words, the confidence of a rule measures the degree of the correlation between itemsets, while the support of a rule measures the significance of the correlation between itemsets.

The problem of mining association rules is to find all rules that satisfy a user-specified minimum support and minimum confidence. As an example, assuming that we have a database of transactions as listed in Table I .

Given minimum support of 20% and minimum conference of 80%, the 28 association rules that satisfy these thresholds are listed in Table 2.

DE VRAF     Table 2. Association rules discovered from Table 1 E < - D  I  A G V R R F  A C V A V < -  R A  F F  2.2 Adaptive-support association rules  The problem of mining adaptive-support association rules was introduced in [7]. It is a constrained association rule intended for collaborative recommendation systems. For recommendation, a specific value of target item may be assumed. This target item is the item that will be recommended to users in a collaborative recommendation system. In addition, it is not necessary to mine an arbitrady large rule set containing all rules above a minimum support level. In fact, a desired number (or range) of rules is usually specified together with a specific given minimum confidence value, wherein no minimum support is specified. Therefore, the problem of mining ASARs can be described as follows :  Input: Transaction T,  targethem, minconfidence, N,,, Nmar  Output: A set S of adaptive-support association rules such that the head of each rule is targetltem, the number of rules in S is in [Nmin, N,,,], and the confidence of each rule is greater than or equal to minconfidence  T : a transaction dataset V : a target item M :minimum support minconfidence : a specified minimum confidence N,, : minimum rule number of a desired range  [minRulenum,maxRulenum] for the number of rules  N,, : maximum rule number of a desired range [minRulenum,maxRulenum] for the number of rules  N : number of ASARs  As an example, given a bansaction database as in Table 1, a target item V, a minimum confidence of SO%, and desired range of rules [5,10], the adaptiwsupport association rules that can be found are shown in Table 3.

Notice that the number of rules for a given minConfidence may be less than the desired range of rules [A'..., Nmor]. In this case, all rules found will be output. Furthermore, no rule outside S with confidence greater than or equal to the minconfidence has a higher support than a rule in S.

2.2.1 Notation The following notations are used in the proposed  ASAR miniig algorithms.

1. Right =support count ofturgeiltem: I* Initialization *I  2. Left = 0:  3 .  M = (Left+Right)/2: /* lnitial minSupp *I 4. ASAR = FTARV, targetltem, minC0nfidence.M);  *I  5 .  N = /ASAR/;  I* Initialization */  I* Fixed Target AR  I* number of ASARs *I  7. If ( N < N , , , ) 8 .  Right=M;  9. If(N>N,.d  10. L e f = M ;  1 1. M = (Left+Right)/Z;  12.

13. N = /ASAR/; I* number of ASARs */  14. } 15. return M, ASAR;  AsARs*I  ASAR = FTART, targetltem, minC0nfidence.M):  1' End of while *I  /* Retum minimum support and  Table 3. The adaptive-support association rules  IV<- A F (20.0%. 11

I. IlOO.O%) 3 Proposed algorithm  l l i s  section describes the proposed algorithm, based on adaptive adjustment of minimum supports, to discover ASARs more effkiently. The adjustment of minimum supports in [7] has fixed step size, for     example 1%. Based on the property that the number of rules decreases monotonically as support increases, we adjust the minimum supports based on the iterative bisection concept. The midpoint of zero and support of target item is assumed to be the initial minimum support.

If the number of association rules generated by the current initial minimum support lies in the desired range, ASARs are found. If the number of rules is smaller then desired N,,", the midpoint of the leA subinterval is assumed to he the new minimum support. Otherwise, the midpoint of the right subinterval is assumed. This process repeats itself until the correct minimum support is found. The proposed bisectioehased algorithm is described as follows:  Input: T, torgetltem, niinconfidence, N,,,, N,,  Output: M (minimum support), ASARs  The following steps show how the result in Table 3 is found hy bisection-based ASAR algorithm:  STEP 1 : From Table 1,  the support  of torgetltem Vis calculated as 40, i.e., Right = 40;  STEP 2 : Left = 0; STEP 3 : M =  (Left + Right) /2_= (0+40)/2 =20; STEP 4 : ASAR = FTXR(T, V. 80% .. *20): .

STEP 5 : N = /ASAR/ = 8; STEP 6 : Testing While ( N  62 [ N,, , N,, ] ); I/ But 8 E [5,10] STEP 15 : return M, ASAR; Minimum support = 20,  I/ as in Table  ASAR in Table 3  4 Experimental results To show the efficiency of the proposed bisection-  based technique for the discovery of adaptive-support association rules, we have implemented the algorithm in section 3 and compare it with the fixed step size approach adopted in [7]. In our implementation, the FTAR in line 4 of the algorithm is an Apriori-based association rule module with fixed target item. For the fixed step size approach, we have implemented a program similar to ASARMl algorithm in [7]. But a major difference is that we do not generate frequent itemsets and rules simultaneously.

All programs are written in C and run on the same 1.7 GHz Pentium 4 PC with 512 MB of memory running Red Hat Linux operating system release 8.0.

We ran the algorithms on a data set called Assocmdh included in the XpertRule Miner software, which has two tables: Basket-Data.xls and Basket-Data-Test,xls. The former has 5,000 records of transactions dataset and the later has 4,970 records.

In this dataset, there are 10 different items and the average length o f  itemsets is 3.5135, with maximum itemset length 6 and minimum itemset length 1.

Figures 1 and 2 show the running time and number of steps required for desired rule range [ I ,  IO] respectively for both approaches. It can he observed that for small data sizes, the performance of either approach is about the same for small range of rules.

But the bisection-based approach is more efficient when data size gets larger.

Figures 3 and 4 show the running time and number of steps required for desired rule range [20, 301 respectively for both approaches. When the desired range of rules is large, it can be ohsened that the performance of bisection-based approach is obviously more efficient for any data sizes. In fact, the experiments have been carried out on various data sizes up to 100,000 records with similar effects.

In some cases, fmed step size approach might not be able to find the minimum support corresponding to a desired range of rules. This is due io the fact that the number of rules corresponding to two consecutive guesses of minimum supports lie outside of the desired range. One is smaller than Nmtn and the other is greater than N,,,. To resolve this problem, step size must be refined in fmed step approach. However, no such problem occurs for bisection approach  5 Conclusion Adaptive-support association rules are constrained  association rules with application to collaborative recommendation systems. In this work, we have proposed an efficient data-mining algorithm for the discovery of adaptive-support association rules.

Simulation results have demonstrated that its performance is more efficient than the fixed step size approach adopted in [7]. However, our implementations do not generate frequent itemsets and association rules simultaneously as in [7]. This may require further investigation for performance comparisons.

Comparison of Fixed and Bisection (run time) Desired range [ l , l O ]  3 2000  1 500  M 1000 - * e  U e 0 'e,  1 2 3 4 5 6 1  8 9 10  Data size (*lo00 records)  Figure 1 Running time comparison of fvted and bisection approaches for desired rule range [I ,  IO]  Comparison of Fixed and Bisection WO-steps) Desired range [1,10]  Gl  B v1 20 2 10  1 2 3 4 5 6 1 8 9 10  Data size (*lo00 records)  Figure 2 Number-of-step comparison of fvted and bisection approaches for desired rule range [I ,  IO]  Comparison of Fixed and Bisection (run time) Desired range [20,30]   U 500  - OL 3 1000  & e 0 1 2 3 4 5 6  Data size C500 records) ~~ ~~~ ~~ ~~~ ~~ ~  Figure 3 Running time comparison of fixed and bisection approaches for desired rule range [20,30]  a98    Comparison of Fixed and Bisection (No-steps) Desired range [20,30]  - v1 ~~~~~ I  v1  2 20 --C Bisection #a - - - - m- e4  1 2 3 4 5 6  Data size (*500 records) I I  Figure 4 Number-of-step comparison of fmed and bisection approaches for desired rule range [20,30]  6 References [I] Agamal, R, Imielinski, T. and Swami A.: 1993, Mining Association Rules between Sets of Items in Large Databases, In: Proc. of the ACM SIGKDD Conference on Management of Data Washington, D.C., pp. 207-2 16.

[2] Agganval, C .  C. ,  Wolf, J. L., Wu, K. L. and Yu, P S., Horting Hatches an Egg : A New Graph-Theoretic Approach to Collaborative Filtering. In Knowledge DiscoveryandDataMining. pp.201-212,1999.

[3] Balabanovic, M. and Y. Shoham: 1997, Fab Content-Based, Collaborative Recommendation Communications of the ACM 40 (3), 66-72.

[4] Billsus, D. and Pazzani, M.J. 1998. Learning collaborative information filters. In Proc. Of the Learning, Madison, Wisconsin, Morgan Kaufmann Publishers.

[5] Breese, J., Heckerman, D., and Kadie, C. 1998.

Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI.

[6] Cooley, R., Tan, P-N., and Srivastava J.:1999, WebSIFT: The Web Site Information Filter System. In: Proc. of the Workshop on Web Usage Analysis and  User Profiling (WebKDD99). Available at http://www.acm.org/sigkddiproceedings/webk -dd99/.

[7] Lin, W.Y., Sergio A. A, and Ruiz, C., 2002 Jan., Efficient adaptive-support association rule mining for recommender systems. Data Mining and Knowledge Discovery, 6 (1): 83-105,  [SI Liu, B., Hsu, W. and Ma, Y. 1998, Integrating Classification and Association Rule Mining. In Proceedings of the Fourth Intemational Conference on Knowledge Discovery and Data Mining, New York, pp.

80-86.

[9] Sarwar, B.:2001, Sparsity, Scarsity, Scalability, and Distribution in Recommender Systems. Ph.D.

thesis, University of Minnesota.

[lo] Schafer, .I. B., Konstan, J. A., and Riedl, J.:2001, E-Commerce Recommendation Application Data Minig and Knowledge Discovery, S, pp. 115-1 53.

[ I l l  Shardanand, U. and Maes, P. 1995. Social information filtering: Algorithms for automating word of mouth In Proceedings of the Conference on Human Factors in Computing Systems (CH195), pp. 210-2 17.

[ 121 Srikant, R, Vu, Q., and Agmwal, R: 1997, Mining Association Rules with Constraints, KDD, 1997.

