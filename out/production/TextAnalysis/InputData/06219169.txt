A Survey of Transaction dada Anonymous publication

Abstract?Transaction data contain a large amount of information of individuals and entities. Publication of these data can provide important resources for researching such as association rule mining, recommendation systems and user behavior prediction ect.. But on the other hand, it will compromise individual privacy. Recently, many works focus on privacy preserving transaction data publishing, especially on anonymous publishing. In this paper, we will systematically summarize and evaluate different anonymous approaches for transactional data publication.

Keywords-Transaction data, Privacy preservation , Anonymity, Data publication

I.  INTRODUCTION Transaction data, such as shopping basket data[1], web  queries, movie ratings[2] and click streams are extremely useful for association rule mining[3], recommendation systems[4] and user behavior prediction ect.. Publication of these data is more and more necessary. Each transaction consists of some items which are similar to attributes in relational database. As the same case with relational database, besides the identifier items, combination of several items may be linked to a specific individual or reveal individual?s sensitive information. So publishing transaction data directly may lead to privacy breach and incur some new challenges in privacy-preserving transaction data publishing.

In recent years, many people engaged in researching on privacy-preserving for transaction data publication, and have obtained some achievements. However, there is no approach suitable for any privacy-preserving problems. Resumptively, we can divided privacy-preserving approaches into three categories. The first one is distorting which achieves privacy-preserving by perturbation. The second one is encryption. The third one is based on limited release technologies focusing on the "anonymizing" original data.

Anonymization refers to the approach that seeks to hide the identity and/or the sensitive data of record owners, assuming that sensitive data must be retained for data analysis[5]. The goal of anonymization is to transform the original database D into published database D* which satisfies a privacy model.

In order to increase the effectiveness and efficiency of anonymity, the anonymous technology research mainly focus on two aspects: (i)designing better anonymity model (principle); (ii)developing more efficient anonymous algorithm. In this article, our concern is the application of anonymous technologies for transaction data publishing.

Many past works are devoted to study the transaction data  anonymization problem[6][7][8][9][10][11][12].We will systematically summarize and evaluate different approaches for transactional data anonymous publication.

We focus on several issues in the rest of the paper: privacy model for transaction data anonymity publication in section 2, several different anonymity operations in section 3, information loss metrics in section 4, and anonymization algorithms in section 5. Finally, we conclude this paper in section 6.



II. PRIVACY PROTECTION MODELS In order to avoid privacy attacks, scholars have proposed  privacy protection model mainly as a measure of the criterion for judging the released data whether can provide enough privacy protection for the individual, in other word, as the guiding principle of data publishing. There are some typical and common models, such as k-anonymity[13,14], l- diversity[15], t-closeness[16] and anatomy[17], which are initially designed for relational database having predetermined and fixed quasi-identifier and sensitive attributes. These models can not be well used for transaction data publishing because transaction data have variable length and high dimensionality[6]. So some anonymity models special for transaction data born: km-anonymity[6][7], (h,k,p)-coherence[8], public k-anonymity[9] and ?- uncertainty[12].

TABLE I. TRANSACTION DATABASE EXAMPLE  (A) ORIGINAL DATABASE I  D custo  mer Purchase Items  D  Tom a, c  D  Bob b, c , d  D  Jone a, b, d  D  Alice a, b, c , d  (B) GENERALIZED DATABA I  D custo  mer Purchase Items  D  Tom A, B  D  Bob A, B  D  Jone a, b, B  D  Alice a, b, B   2012 IEEE Symposium on Robotics and Applications(ISRA)  978-1-4673-2207-2/12/$31.00 2012 IEEE    km-anonymity On the basis of k-anonymity model for relational data privacy publication, [6][7] proposed a km- anonymity model for transaction database. km-anonymity means that for any itemset which contains at most m items, there should be no transaction or at least k transactions containing this set in the transactional database. For example, in tab.1(a), there is no transaction or at least 2 transactions containing identical itemset which have 1 or 2 items. So we can say this transaction database satisfies the 22-anonymity.

Generally, parameter m means the number of items that adversary knows. In this sense, m limits adversaries? background knowledge to a level, so the km-anonymity only protects individuals? privacy when the adversary knows m or fewer items. In tab.1a, assuming an adversary knows that Tom bought a and c, he can not confirm which transaction D1 or D4 belongs to Tom, therefore, privacy of Tom is protected. But, if adversary knows Jone bought a and b, although D3 and D4 both contains these two items, adversary still can confirm that Jone bought d. So John?s privacy is exposed. Obviously, km-anonymity model is similar to traditional k-anonymity model for relational database, it can not prevent ?homogeneity attack?.

(h,k,p)-coherence A database D is (h,k,p)-coherence if, for every such combination ? of no more than p public items, there is either no transaction contains ? or the set of transactions containing ?, called ?-cohort, contains at least k transactions and no more than h percent of these transactions contains a common private item[8]. Clearly, the parameter p is the same as the m in km-anonymity model. What?s more, km-anonymity is the special case of (h,k,p)-coherence with h=100%. (h,k,p)-coherence ensures that, for an adversary with the power p, the probability of linking an individual to a transaction is limited to 1/k and the probability of linking an individual to a private item is limited to a maximum confidence threshold h[8]. Apparently the (h,k,p)-coherence model has certain limitation because it relies on the assumption, a prior distinguishing between public and sensitive items and every public item equally identifying, while in practice the line between public/private may be blurred and different public items may have different weights to identify a transaction.

complete k-anonymity [9] proposed a privacy model of k-anonymity called complete k-anonymity for transaction data. Similar to traditional k-anonymity model, a transactional database D is k-anonymous means that for any transaction, there are at least k?1 other identical transactions.

Because of no parameter m in k-anonymity, it means that there is no limit on the number of items the adversary can know. In this sense, k-anonymity provides stronger privacy protection for individual. If max is defined to indicate the maximum length of any transaction in the database, km- anonymity is similar to k-anonymity when m is valued for max. For instance, assuming that there is a transcation D5 with identical items of D4 in tab.1a, it is clearly that this new table satisfies 2m-anonymity for any value of m rang between 1 to 4, but not satisfies 2-anonymity. If we generalize the items in tab1.a with the domain generalization hierarchy depicted in Fig.1, we can get the tab.1b which satisfies 2-anonymity and 2m-anonymity. This shows that  every database D must satisfy km-anonymity for all m if it satisfies k-anonymity, however, D satisfies km-anonymity but not always satisfies k-anonymity. In other words, k- anonymity subsumes the km-anonymity[9]. Transactional k- anonymity requires that each transaction has at least k duplicates. Such a requirement is stronger than k?- anonymity and introduces much more distortion than necessary [19].

Figure 1. Item Generalization Hierarchy for Transaction Database in  Tab.1  ?-uncertainty: Models proposed in [8][10][18][23] assume a strict difference between sensitive items and public items and what is sensitive only depends on individual preferences. And there is another assumption that adversaries have no prior knowledge about sensitive items. However, actually, an adversary may possess partial knowledge of some of the sensitive items in a transaction. Therefore, these models can not prevent such attack based on extra sensitive knowledge. [12] raised a novel,  intuitive, and realistic model named ?-uncertainty for transaction anonymization. A transaction data set D, is said to satisfy ?-uncertainty, if and only if, for any transaction t ?D, any subset of items X?t, and any sensitive item ??X , the confidence of the sensitive association rule X?? is less than a value ?[12]. ?-uncertain model is similar to (h,k,p)-coherence, but an essential difference is that this model allows an adversary has some prior knowledge of the private items.

Prior models assume that all combinations of items that contain a certain number of items need to be protected and neglect specific utility requirements. They only formulate some privacy constraints but no utility constraints.[11] proposed a model that prevented identity disclosure by ensuring that each transaction is indistinguishable from at least k?1 other transactions with respect to privacy constraints, while satisfying utility constraints. Owing to space reason, specific model is not described here.



III. ANONYMITY OPERATIONS As mentioned in introduction, original transaction  database must be transformed into a new database which satisfies a certain privacy model before publishing. So in this section, we want to pay attention to transforming operations named anonymity operations. In past researching works, most of them employ generalization[6,7,9,18,20,21] or suppression[8] or generalization and suppression [19,22,12], a few of them adopt permutation[10,23].

Generalization is using more general value which contains less information instead of specific value. For example, instead a by A in fig.1. Generalization can be divided into two types, one is global generalization, also known as full subtree generalization[22], and another is local generalization. In global generalization, a particular detailed   2012 IEEE Symposium on Robotics and Applications(ISRA)    value must be mapped to the same generalized value in all records[7]. If we generalize the items in tab.1a with global generalization from Fig.1,the generalization result is not same to tab.1b. According to global generalization,?a? in one record is mapped to ?A?, consequently, ?a? in all records must be mapped to ?A? with no exception. Obviously, by this means, tab.1a is transformed into a new table which have four identical transactions composing of generalized values ?A? and ?B?. [6][18][20] adopt global generalization. But as we see in above example, global generalization is vulnerable to excessive distortion so that the utility of data reduces. Just for this reason, [9] chooses the local generalization as its anonymity method. Unlike global generalization, local generalization allows the same detailed value to be mapped to different generalized values in each anonymity group, so the distortion potentially reduces[7]. However, everything has two hands, local generalization destroys the domain exclusiveness property.

Relative to generalization, suppression is an easier operation. It points to hide the items to be protected, or sometimes means to delete a record or a transaction to satisfy privacy requirement. Suppression also can be divided into global and local techniques. Global suppression is usually preferred, because it produces data in which all items have the same support as in the original database[20]. Only using suppression[8] to get a new anonymous database will incurs high information loss. So integrating generalization and suppression[19,22,12] is a good choice. Suppression can remove outlier items that otherwise will cause substantially generalization of many other items[19]. The combination of two methods can greatly reduce the overall information loss.

In addition to the above two methods, [10][23] applies matrix permutation techniques. This method makes maximum use of the characteristics of the sparse for transaction database. It organizes the data as a band matrix by performing permutations of rows and columns in the original table, such that most non-zero entries are near the main diagonal. The advantage of this representation is that neighboring rows have high correlation[10] and the formation of anonymized groups becomes easier. Finally, the exact public items together with a summary of the frequencies of sensitive items are published. This operation preserves facticity of the original data, on the other hand, its transparency renders it more vulnerable and provides no protection against identity disclosure.



IV. INFORMATION LOSS METRIC For privacy-protecting anonymous publication, getting an  anonymity of original data to preserve individual?s privacy is important, meanwhile considering how to minimize the information loss is necessary. In order to minimizing the information loss, we must know how to measure it firstly. In this section, we will summarize the information loss metrics which are usually used for transaction data anonymity.

When a generalization solution defined by a cut, the simplest information loss metric is defined by cost(cut), named general loss metric(LM), which can be decomposed into the information loss of constituent items of cut. So, cost(cut)=? x*?cutcost(x*), here cost(x*) is different  according to the type of x* whether categorical or numeric[22]. This metric, which assumes that each identifying item is equally important, is widely used in [12][18][19][22]. There is a similar metric named NCP(Normalized Certainty Penalty). The NCP for the whole database weights the information loss of each generalized item using the ratio of the item appearances that are affected to the total items in the database[6][7][9].

If suppression is also used in anonymity process, the information loss because of suppression will be added to cost(cut). Suppose that we assign a certain information loss to the suppression of an item e, denoted IL(e), ?IL(e) denotes the total information loss in the transformation, where ? is over all the items e suppressed[8].

The metrics mentioned above are suitable for anonymity based on generalization and suppression. But in [10][23], original data are organized as a band matrix by permutation.

Finally, the exact public items together with a summary of the frequencies of sensitive items are published. So there is not data distortion. [10][23] employ a diverse method named KL-divergence(Kullback-Leibler divergence) to determine the utility of the anonymized data as the distance between the real and estimated pdf(probability distribution function) over all cells which correspond to a combination of the QID items.



V. ANONIMITY ALGORITHM An optimal anonymity is that satisfies the given privacy  requirement and produces minimized information loss according to the chosen information metric and it is obtained usually by searching in the potential solution space. Take anonymity based on generalization for example, potential solution is usually named cut. The possible cuts corresponds to the set of possible horizontal cuts of the hierarchy tree.

Searching space is composed of all possible cuts. Generally, global generalization has the smallest search space, but local generalization has the largest[6]. In order to increase the efficiency of searching, anonymity algorithm must be designed. Algorithm based on the universal anonymous principles usually include enumerating of generalization space, space trim, selection of the optimum generalization, the results judgment and output etc steps.

There are two kinds of searching fashions based on generalization technology commonly used, top- down[9][18][21] and bottom-up [6][7]. The algorithm Partition[9], OTA[18] and RBAT[21] all adopt the former pattern.

Partition[9] uses a local generalization model. It starts by generalizing all items to the root of the hierarchy and then replaces this item with its immediate descendants in the hierarchy if complete k-anonymity is satisfied. In subsequent iterations, generalized items are replaced with less general items, as long as complete k-anonymity is satisfied, or the generalized items are replaced by leaf-level items in the hierarchy[20]. This approach is effective at minimizing data distortion but the data transformed by partition algorithm is difficult to use in practice because of not taking utility requirements into account.

Although OTA[18] operated in a top-down fashion similar to partition, but it explored inverse lexicographic tree   2012 IEEE Symposium on Robotics and Applications(ISRA)    for materializing the most general threats, the cut enumeration tree for representing solutions and the extended FP-tree for scalable representation of hierarchical data[18].

[6][7] proposed three classes algorithm and purpose of them is to find generalization that satisfy km-anonymity. The first class is optimal anonymization(OA) which operates in a bottom-up fashion. It explores in the lattice of all possible combinations of item generalizations with very high computational cost, so cannot be applied to realistic databases with thousands of items. The second class include two algorithm, one is apriori anonymization (AA) and another is direct anonymization (DA). They are heuristic approach. AA also operates in a bottom-up fashion. The combinations of itemsets that have to be checked at a higher level can be greatly reduced, as in the meanwhile detailed items could have been generalized to more generalized ones, thus reducing the number of items to be combined[6]. This algorithm is sufficiently scalable for use in practice[11]. The third class algorithms is Local Recoding Anonymization (LRA) and Vertical Partitioning Anonymization (VPA), which anonymize the dataset in the presence of limited memory. The basic idea in both cases is that the database is partitioned and each part is processed separately from the others[7]. LRA and VPA are more flexible than Partition in the sense that they can be configured to offer protection against attackers who do not know all items of a transaction.

Xu et al. [8] proposed an algorithm that discovers all unprotected itemsets of minimal size and protects them by iteratively suppressing the item contained in the greatest number of those itemsets[11].

[10] and [23] adopt a novel representation for sparse high dimensional data. [10] used a band matrix to capture the correlation in the underlying data, and facilitates the formation of anonymized groups with low information loss.

RCM algorithm is employed along with breadth-first traversal in this literature. [23] extended from [10] put forward two categories of novel anonymization methods.

The first category is approximate nearest-neighbor(NN) search based on Locality-Sensitive Hashing(LSH)[24]. In the second category, it proposed two data transformations:(i) reduction to a band matrix and (ii) Gray encoding-based sorting[10].

[20] proposed a novel clustering-based framework.

PCTA algorithm map original items to generalized ones to construct a clustering and then examining whether this clustering satisfies the specified privacy constraints.

COAT(Constraint-based Anonymization of Transactions)[11] focusing on guarding against identity disclosure is an algorithm that operates in a greedy fashion and employs both generalization and suppression[11]. It checks the frequency of combinations of sensitive items that co-occur with potentially linkable itemsets and to further anonymize the latter, in accordance with the utility constraints, until the frequency of the combinations of sensitive items falls below a specified threshold[11]. COAT allows constructing any generalized item that is not more general than an owner-specified utility constraint. When such an item is not found, COAT selectively suppresses a  minimum number of items from the corresponding utility constraint to ensure privacy.



VI. CONCLUSION Along with the development of information sharing,  anonymizing transaction databases for publication becomes an important research field. Most of works pay attention to solving the conflict between privacy-preserving and retaining information utility. In the above sections, we reviewed and compared existing approaches in terms of privacy models, anonymization operations, information loss metrics, and anonymization algorithms for transaction data publishing. In general, transaction data  privacy-protecting is still a new field in recent years, the international research of this problem is very active, but at the same time, there are also many problems need to be further careful Study.

