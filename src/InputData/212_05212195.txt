

Abstract: Annotation is an important step in video content analysis.

In this paper, one inter-concepts strong association and dependency multi-label annotation method for video semantic concept is presented. In video content analysis process, concepts are often correlated. One concept in one shot are usually dependent on others concepts in the same shot.

Co-occurrence of several semantic concepts could imply the presence of other concepts. Unlike previous approaches only to take into count the pair concepts correlations, the proposed methods exploits label correlations between concepts including more than three. For generation the inter-concepts association and dependency rules, join and prune techniques are employed to get potential semantic concept associations in one shot. Compound labels are considered as a single label in annotation step. Experiment results on real-world multi-label media data show that the performance of proposed method is relative satisfied.

Keywords: Multi-label annotation; Machine learning; Video content  analysis; Semantic concept; Semantic scene annotation  1. Introduction  In video content analysis, many concepts have several labels, which are generally called multi-label annotation problem. In this paper, multi-label annotation is solved through multi-label machine learning technique. Therefore, multi-label annotation requires one instance to be assigned to multiple different categories or semantic-labels. Now, multi-label annotation is an important task in video content analysis domain. In many real-world tasks for video content understanding, classes are not independent. For example, the contents of one key frame in a shot is not only beach but also cityscape[1]. Therefore, an instance can be assigned to multiple classes. Common approaches for multi-label annotation are using independent classifiers for each category. Those techniques are only fit to problems in which categories are independent. However, the video  concept labels are highly interdependent. Thus, they do not exploit dependencies between video concept labels.

At present, more attentions are paid to individual concept classifier in media content analysis. Many researchers study the individual classification technique, in which video concepts are detected independently. For example, the paradigm of structure-sensitive manifold ranking (SSMR) is used to detect video concept[2]. The method which individually concept is detected can not extract the potential correlation information between the video concepts. Thus, some researchers add one fusion step following the individually concept detection with the purpose of combination individually classifier. However, the method will lead to the increasing error, because of individually classifier error and fusion error.

Multi-label learning deals with instances each may belong to several concept classes simultaneously, which is the active research issue in machine learning domain.

Text-categorization problems are usually multi-class in the sense that there are usually more than two possible categories[3, 4],  the study in which initially motivated the work of Multi-label learning. In natural, the method of learning a multi-label is to decompose it into many two-class classification problems, which achieve less satisfaction performance. So far, two main multi-label classification categories have been explored[5]. The first category methods try to transform the multi-label classification problem either into one or more single-label classification problem, which will be called problem transformation methods. For example, Boutell et al.

proposes cross-training approach[1]. SML_SVM, a semi-supervised multi--label learning method, is proposed in paper [6]. The second category methods try to modify specific learning algorithms in order to handle multi-label data directly, which will be called algorithm adaptation methods. For example, the Semi-supervised Multi-label Learning by Constrained Non-negative Matrix Factorization[7].Some time, The two strategies are use in      one approach. such as ML-kNN is presented, which is derived from the traditional k-nearest neighbor (kNN) algorithm[8].

In recent years, some encouraging progresses have been made with the development of multi-label text categorization algorithms. But the methods suiting video concept understanding are very few. The typical method for video concept in multimedia content analysis is Correlative Multi-Label (CML) [9]. CML approach could model both the individual concept and the conceptual correlations in an integrated framework. However, only the correlations mutual information between each pair concepts could be directly got in CML. The correlation information of three or more concepts is indirectly got from pair concepts correlation.

Often, the concepts, including high-level video concept and middle-level video concept, in one shot have strong correlation and dependence each other. The co-occurrence of concepts is positive correlations and vice versa. To improve the performance of individually video concept classifier is very difficult. But, making use of the correlations and dependence between concepts is a relatively easy way to increase the detection performance.

For instance, the concept ship is often strongly related to the ocean concept in a shot.

More researchers focus on the intensive study in individual video concept classification and learning technique. Few researchers consider the inter correlations and dependence relation between video concepts. In this paper, the strong correlation and dependence between concepts will be extracted by Aprori-association algorithm.

In the learning process, several concepts having strong association and dependency relation will be treated as one compound label. Through the annotation of compound label, this correlation and dependence relations among classes can be preserve, which are helpful for predicting class labels of test examples. Both CML method and the method in this paper can model the conceptual correlations in an integrated framework. Although some previous work such as method in paper[9] shares similar spirit of using inter-concept correlations relationship to improve multi-label video concept detection, most of them integrated such ideas into their framework only using pair concept correlation. Whereas, the distinctly difference is the correlations of more than two video concepts could be directly got by compound label in this paper. This correlation among classes can be helpful for predicting class labels of test video concept examples.

The remaining paper is arranged as follows: Section 2 introduces general idea of multi-label learning. Section 3 explores inter-concepts strong association and dependency multi-label classification method. Section 4 describes the  the experimental on real-world median data natural scene.

2. Multi-Label Annotation  Traditional single-label classification is concerned with learning from a set of examples that are associated with a single label l from a set of disjoint labels. Multi-label learning refers to the problems where an instance can be assigned to more than one category. Unfortunately, most traditional classifiers can only handle single-label problems.

Let d? ?=  denote the input space and 1 2{ , , , }LY L L L=  denote the finite set of possible labels.

Given a multi-label training set 1 1 2 2{( , ),( , ), ,( , )}m mx Y x Y x Y , where ix ??  is a single instance and 1  ( ) ( ) ( ) 2( , , , )i  i i i ly y y=iY  is the label set associated with xi, the goal of multi-label learning is to learn a function : 2Yh ? ? , which can predicts a set of labels for an unseen example.

The most common problem transformation method learns |Y| binary classifiers : { , }h y y? ? ? , one for each different label y in Y[5], which denotes as PT Method for short. It transforms the original data set into |Y| data sets D  y that contain all examples of the original data set, labeled as y if the labels of the original example contained y  and as  y? otherwise.

3. Strong association and dependence multi-label annotation method  In video concept analysis, multiple correlated concepts usually appear in a video shot at same time. Hence, the correlation and dependence hidden relationships can be helpful to semantic concepts detection. Figure 1 illustrates our proposed inter-concepts strong association and dependency multi-label annotation method. The multi-label classification method consists of strong association and dependency extraction, single compound label transformation, multi-label learning and annotation. The association and dependency relationship extraction is an iterative process, in which candidates subsets will be got after join step and prune step. Finally, the frequent itemsets is compound label set. Considering each different set of labels that exist in the multi-label data set as a single compound label, PT method is used to multi-label learning.

Finally, the multi-labels are annotated.

For video semantic concept understanding, learning and classification are used. Video stream data are composed of frames, shots and scenes. In order to structure video data, the video data are segmented into a sequence of scenes.

Several shots make up of one scene. Thus, each scene is      segmented into some shots. For one shot, a set of key frames are usually representative visual content. Shots are the commonly-used basic semantic units for video content analysis. For video content semantic understanding, some shots must be are manually labeled at the beginning. Let C= {c1, c2, ..., cm} is a set of video concepts, which is called video concept items. Subscript m means the concept number that the system attempts to extract. Let S = {s1, s2,...

si, ..., sn} be the train samples of n video shot, in which si denotes the i-th shot in the train set. Each shot have a unique id, which is SID. L= {l1, l2,... l i, ..., l n}a set of annotation labels, in which l i is the annotation label corresponding to si shot. It is usual that several concepts will appear in one shot. Thus, the annotated label l i is a subset of C ( )il ? C . X Y?  means, the strong association and dependency relation among concept X and Y, .

Where, X ? C , Y ? C , X Y = ?? . The support of association and dependency relation X Y?  is:  ( ) shot number containingX Y total shot number in  ? = ? X YSupport S  (1)  The confidence of X Y?  is defined as:  ( ) shot number containing  Confidence X Y shot number containing X in  ? = ?X Y  S (2)  The support of X Y?  is the percentage of shots that contain X also contain Y. The confidence of X Y?  is the percentage of annotations containing X that also contain Y.

The relations that satisfy both a minimum support threshold and a minimum confidence threshold are called strong association and dependency.

First, some definitions must be presented before further discuss. The set of semantic label in one shot is called semantic label itemset. An semantic concept itemset containing k items is called k-itemset. Usually, semantic label itemset could be looked as a conjunction of semantic concept label. Let min_suport is the minimum support threshold. An itemset satisfies minimum support if the occurrence frequency of the itemset is greater than or equal to min_ suport.

Semantic frequent itemset is defined as the semantic itemset which satisfies minimum support. Frequent itemsets is used to generate association dependency relation. The frequent itemsets have minimum support. The minimum support must be given in the experimentation. A subset of a frequent itemset must also be a frequent itemset. For example, the label {AB} is a frequent itemset, and both {A} and {B} should be a frequent itemset. It is an iterative process, finding frequent itemsets with cardinality from 1 to k (k-itemset). There is no doubt that any subset of frequent  itemset must be frequent. Strong association and dependency relation of video concepts is extracted based on the frequent itemsets.

compound label  annotation  annotate compound label  as a single compound label  PT method transform to single label  Train classifier  Multi-label media data  Learning Multi-label learning  Extraction of strong  association and  dependency  Join Operation  candidate itemset  frequent semantic itemset  Prune Step  Classification result  Multi-label annotation   Figure 1. Annotation method in this paper The iterative process of extraction strong association  and dependency relation have Join and prune steps[10, 11].

4. Experimental  In this paper, the experimental data is natural scene [1].

The data set consists of natural scene images, which belong to the semantic desert, mountains, sea, sunset, and trees.

Natural scene data set are available at http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/. Multi-label semantic concept example information is in Table I, in which #sample means sample number. From the table, we could see that more than 20% of the data simultaneously belong to multi-semantic concept. Each image is represented by a feature vector using the same method as in paper [1].

The total semantic class categories are 6. For all samples, 1211 are trained and 1196 are testing sample. The features number is 294. Another attributes of Natural Scene data set are showed in Table I. Different data set have different attribution. The attribution between the number of labels of each example and the total semantic category number will be represented by label cardinality and label density[5].Let D be a multi-label data set consisting of |D| multi-label examples (x  i , Y  i ), i = 1..|D|. Label density of D is      the average number of labels of the examples in D divided by |L|. Label cardinality of D is the average number of labels of the examples in D.

1( ) D  i i  LC D Y D =  = ?                  (3)   1( ) D  i  i  Y LD D  D L= = ?                  (4)  Table 1. Multi-semantic label of the Natural Scene  Semantic label # Sample desert+mountains 19  desert+ sea 5 desert+ sunset 21 desert+ trees 20  mountains+sea 38 mountains+sunset 19 mountains+trees 106  sea+sunset 172 sea+trees 14  sunset+trees. 28 desert+mountains+sunset 1  desert+sunset+trees 3 mountains+sea+trees 6  mountains+sunset+trees 1 sea+sunset+trees 4  Table 2. Another attributes of Natural Scene data set  Data name labels cardinality density distinct scene 6 1.074 0.179 15    To compare the performance of directly multi-label semantic concept classification and the multi-label classification method in this paper, the method presented will be used to solve multi-label semantic concept analysis problem. Strong association and dependency relations between video semantic concepts satisfying the minimum support will be extraction through an iterative process.

Some single labels with strong relation will be considered as one compound label. The compound labels with strong association and dependency relations, including the remainder single label will be trained with PT method.

Comparing with the directly multi-label classification method using ML-kNN in paper[8], the method presented in this paper are used to multi-label semantic concept learning.

To generate video semantic concepts frequent itemsets, minimum support percent threshold is 50. Strong  association and dependency compound label Lcom are generated after the strong relation extracting. The final labels using to train classifier are Lcom and the single labels which are not in Lcom. Experimental results between the compared method and the method in this paper are showed in Table III. In the table, ? indicates ?the smaller the better? while ? indicates the bigger the better. Because more media semantic concepts have strong association and dependency relation in each other, .the proposing method can improve the performance. That is the fundamentality of the method.

Contrast data of methods directly using ML-kNN, the performance of multi-label learning using the presented method are better. Experimental results between the compared method and the method in this paper.

Table 3. Experimental results between the compared method and the method in this paper  Evaluation metrics  Direct PT method  Method in this paper  Hammloss? 0.126 0.123 One-error? 0.290 0.287  Ranking loss? 0.278 0.276 Average precision? 0.698 0.702  Coverage? 6.920 6.916 The evaluation metrics in this experiment are  hammloss, one-error, ranking loss, average precision and coverage[12, 13]. (1) Hammloss evaluates how many times an instance-label pair is misclassified, i.e. a label not belonging to the instance is predicted or a label belonging to the instance is not predicted. The performance is perfect when hammloss = 0; the smaller the value of hammloss, the better the performance.(2)one-error evaluates how many times the top-ranked label is not in the set of proper labels of the instance. The performance is perfect when one-error=0; the smaller the value of one-error, the better the performance.(3) rank loss evaluates the average fraction of label pairs that are reversely ordered for the instance. the smaller the value of rank-loss, the better the performance.(4)average precision: evaluates the average fraction of labels ranked above a particular label y ? Y which actually are in Y . The bigger the value of average precision is, the better the performance. (5)coverage: evaluates how far we need on the average to go down the list of labels in order to cover all the proper labels of the instance. It is loosely related to precision at the level of perfect recall. The smaller the value of coverage is, the better the performance.

5. Conclusion  Multi-label learning appears in many practical applications, especially among media and video semantic concept analysis. The common approach at present for multi-label learning is to decompose it into multiple independent binary classification problems. Then, final labels for each instance can be determined by combining the classification results from all the binary classifiers.

However, the traditional approach performance is far from satisfaction, ignoring the mutual correlations and dependence among semantic categories.

In this paper, one annotation method using inter-concepts association for video semantic concept is proposed. The method is based on multi-learning technique.

The results of experiments show that the performances of this multi-label annotation method are satisfied.

Acknowledgements  This paper is supported by Project (CSRF200803) Supported by the Scientific Research Foundation of CUIT and Development Found of Chengdu University of Information Technology under Grant No.KYTZ200914.

