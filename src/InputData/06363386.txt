Recommending APIs for mashup completion using association rules mined from real usage data

Abstract?Mashups are becoming the de facto approach to build customer-oriented Web applications, by combining several Web APIs into a single lightweight, rich, customized Web front-end. To help mashup builders to choose among a plethora of available APIs to assemble in their mashups, some existing recommendation techniques rank candidate APIs using popularity (a social measure) or keyword-based measures (whether semantic or unverified tags). This article proposes to use information on co-usage of APIs in previous mashups to suggest likely candidate APIs, and introduces a global measure which improves on earlier local co-API measures.

The gCAR (global Co-utilization API Ranking) is calculated using association rules inferred from historical API usage data. The MashupRECO tool combines gCAR and a keyword- based measure, to avoid the ?cold-start? problem for new or unused APIs. Evaluation of MashupRECO versus the keyword search of the well-known ProgrammableWeb catalog show that the tool reduces the search time for comparable degree of completeness.

Keywords-Web mashup; Web API; recommender system; association rules; frequent itemsets;

I. INTRODUCTION  Mashups are becoming the de facto approach to build customer-oriented Web applications, by combining opera- tions on several Web APIs (Application Programming In- terfaces) into a single lightweight, rich, customized Web front-end. They allow to develop complete applications by searching, composing and executing functionality provided by external sources. Typically, mashups are built with more than one API (according to ProgrammableWeb 1 45% of the registered mashups are built with more than one API). In order to take advantage of the previous compositions made by mashup developers, we expect the API discovery process to have a memory on the iterative items selection.

API Web catalogs provide, besides APIs? documentation, the valuable information about which APIs are used on the registered mashups. In our previous work [1], we argued the need to combine descriptions with social information, where description-based techniques can be leveraged by social indicators. This combination allows the discovery of candidates that would have passed unnoticed because  1http://www.programmableweb.com  of their poor quality descriptions or their low popularity.

We discussed in [2] how our combined approach enriches keyword-based search with the social information provided by the mashup community. We also argued that using this balanced approach could reduce the cold start problem that new APIs exhibit on a market with a preferential attachment trend on their usage. We proposed two indicators: the Web API Rank (WAR), which measures API utilization over time, and the Co-utilization API Rank (CAR), which measures the joint usage of a group of APIs.

In this work, we calculate the CAR indicator using symbolic methods for knowledge discovery in databases, specifically extracting association rules to discover comple- mentary APIs to use in the construction of a mashup.

The remainder of the paper is organized as follows.

Section II discusses the motivation of our research. Section III discusses related work. Section IV identify the specific problem addressed in this paper. Section V presents the background needed to introduce the approach. Section VI and section VII present the complete approach to obtain candidate components to build a mashup in an iterative fashion. Section VIII presents the implementation details of the MashupRECO tool. Section IX shows the experiments performed to test the effectiveness and efficiency of our approach, and finally, section X draws conclusions.



II. MOTIVATION  In this section we describe a case in which a workshop organizer wants to create a mashup for the venue section of the workshop?s website. The first step is to identify the specific functionalities needed (see Figure 1). Typically in a venue section we can find information regarding the celebration?s place, the city and entertainment, nearby hotels, photos of the city attractions and, in some cases, videos.

Then, the organizer needs APIs to display a map of the place, locate points of interest, find hotels, show photos and videos and, as the aim is to keep assistants updated on the latest news, send updates in an easy manner.

Using the ProgrammableWeb search site, the organizer tries to search an API that provides, given a location, photos.

ProgrammableWeb uses a search engine based on tags, then   DOI 10.1109/SCCC.2011.12    DOI 10.1109/SCCC.2011.12    DOI 10.1109/SCCC.2011.12     Figure 1. Mashup Brainstorm  the search could be composed of the words ?photo? and ?location?. If providers did not describe their APIs with representative tags then their probabilities to be discovered, even when they could be good options, are low. There are some problems with the ProgrammableWeb site, we can notice differences between the simple and advanced search.

For instance, when the organizer searches for ?photo? and ?location?, the number of results between using the simple and advanced searching interface increases from 0 to 6.

Nevertheless, ProgrammableWeb has a remarkable value for the community because is an open live mashup catalog, with an API that provides access to all the registry waiting to be properly mined.

Following the example, the organizer obtains six results for the first search trying to find APIs that return photos given a location. Assuming the organizer selects the first API (the results of the first search are not ranked because it is a binary search, the tag is present or not), now he needs to find the other APIs. Ideally, the organizer should be able to save the current selection and then perform the next search constrained by that selection. This option is not available in ProgrammableWeb. Although the user can see a list of the other APIs used in mashups of a given API, this information is not retained for later use and it is not possible to know this for a group of APIs. Thus, the richness of the compositions is not being exploited to help the selection process.



III. RELATED WORK  Given the increasing trend of major firms providing APIs for public use, mashup community is rapidly expanding.

There are studies characterizing the mashup ecosystem as a API-Mashup network [3] which intended to exploit this information.

In [4], the authors proposed the serviut score to rank APIs based on their utilization and popularity. To calcu- late the serviut score they also considered the number of mashups that use the given API but also other aspects that we believe are too ambiguous to be considered, such as classifying mashups in the same category as the API. Even  according to ProgrammableWeb, mashups are not classified in categories because by definition a mashup is a mix of different Web APIs, therefore is quite difficult to classify them in functional categories. According to our experiments, the taxonomy of APIs and mashups are quite different.

In [5], authors proposed a social technique to mine annotated tags of mashups and APIs in order to recommend mashup candidates managing the cold start problem for new competitors. The problem of using tags is that they are not reusable between different catalogs. Then, by using tags we obtain specific taxonomies that are not generic enough to be used with APIs obtained from different catalogs. Web API authors do not necessarily use the same tags to describe them, they typically adapt them according to the tags that are used on each catalog.

In [6], authors proposed MashupAdvisor that also as- sist developers to build mashups. Similar to our approach, MashupAdvisor suggests APIs that could be part of the mashup under construction using a probabilistic approach based on their popularity in the mashup repository. But because MashupAdvisor assists the mashup building process instead of only the selection, this approach is based on specific inputs and outputs. Typically only Web service APIs have this data. Mostly because of their complexity and lack of standards, general APIs do not have interface information of each operation. Then, this approach performs well over Web services but not over general Web APIs. Even when the results are encouraging they actually simulate the data of ProgrammableWeb to conduct the experiments.

In [7], authors proposed ServiceRank to differentiate ser- vices from a set of functional-equivalent services based on their quality and social aspects. The problem is that it needs to access data that providers may not be willing to give, such as the response time and availability measurements.

Also, because providers publish their own measurements, this process could be not completely reliable.

In [8], authors proposed MatchUp, a tool that supports mashup creators to locate components to mash up based on the current component selection and a complete database that describes which components have been used in the different mashups (at the input/output level). The algorithm performs well but is only feasible at level of intra organization because, in general, this information is not shared or public.



IV. THE PROBLEM  Typically mashups are built with more than one API.

Even more, these APIs are iteratively selected and previous selections influence current ones. Then, the problem is, how can developers restrict and guide their search given the current selection of APIs.



V. BACKGROUND  A. Functional-equivalent APIs and Formal Concept Analy- sis  Due to the increasing proliferation of APIs [3], we assume that for each API there is a set of functional-equivalent APIs that are natural candidates to substitute it. Service discovery can be improved by maintaining an API classification that helps users to drive their search for a given functionality.

However, these classifications are typically handled manu- ally by API providers or catalog owners which could lead to rigid and poor classification systems with low or erroneous retrieval capabilities.

To represent functional-equivalent APIs we use a lattice- based classification approach, which is a symbolic data mining technique used for extracting a set of concepts organized within a hierarchy. This structure allows us to arrange nodes of functionality defined by a set of features and a set of APIs that share those features. We decided to use lattices because, as [9] has argued, a canonical approach does not deal with objects belonging to multiple categories, and lattices do. Lattices also allow category overlap.

Formal Concept Analysis (FCA) [10] is a mathematical theory of data analysis using formal contexts and concept lattices. The approach takes as input a matrix specifying a set of objects and their properties, called attributes, and finds both the clusters of attributes and the clusters of objects in the input data, where an object cluster is the set of all objects that share a common subset of attributes, and a property cluster is the set of all attributes shared by one of the natural object clusters. A concept is a pair containing both a property cluster and its corresponding object cluster. Formally, given a formal context (A,K, I), where A is in this case a set of APIs, K is a set of keywords (attributes) which describes functionality, and a binary relation I ? A?K which specifies which APIs have which attributes. A formal concept of the context A,K, I is a pair (X,Y ) where X ? A, Y ? K, where the set X is called the extent (the set of APIs that belong to this concept) and Y is called the intent of the concept (which terms better describe this concept). A concept (X,Y ) is a subconcept of (U, V ) if X ? U , then (U, V ) is called a superconcept of (X,Y ). Then, we can extract the complete lattice using this partial order relation between concepts (<) where a lattice at least has a bottom and a top concept in which the relation bottom < top is true. In our previous work we provided a concise example of building a lattice for APIs.

The advantage of building a lattice representing the func- tionalities provided by APIs is we can, given a required functionality, navigate the lattice to find a set of functional- equivalent APIs for the requirement. When a composer is searching for an API, he is actually searching for a set of functionalities. To represent this search, he uses a set of keywords. This query is transformed into a virtual concept  Table I FORMAL CONTEXT  APIs vs functionality T1 T2 T3 A1 x x x A2 x x A3 x x A4 x  which intent is the set of keywords [11]. Then, we navigate the lattice in order to find the concept which has exactly the same intent in order to retrieve its extent. If there is no concept that matches the intent, the virtual concept must be arranged within the lattice. From the potential set of parents of this virtual node (nodes which intent is a subset of the virtual concept?s intent) we select the concept(s) whose intent is maximum, and then we suggest the extent of that concept(s). Similar to [11], we walk the semantic graph from the virtual concept to their ancestors. The distance from a child node and their direct parents is one. Then the nodes with minimal distance to the virtual node are the best candidates to be recommended. In this work, we are only considering nodes with distance of one, but it is possible to enrich the searching process by walking the graph at longer distances. Algorithm 1 describes this procedure.

Algorithm 1 Searching functional-equivalent APIs Require: The set A of all the available APIs.

Require: The set K of all the selected keywords representing the func-  tionalities extracted from descriptions.

Require: The set C of all the concepts in the lattice.

1: Let CIi ? A be the intent of the concept i.

2: Let CEi ? K be the extent of the concept i.

3: Let T be the set of terms of the query Q.

4: Remove stop words from T 5: for all t ? T do 6: Stem t.

7: end for 8: if ?i ? C | CIi = T then 9: return CEi  10: else 11: Let v be a virtual concept with intent CIv = T and extent C  E i = ?.

12: Let Pv = {p ? C | CIp ? T} be the set of potential parent concepts of v.

13: return CEp of the concept p ? Pv with maximum |CIp | 14: end if  Consider the following example. We have a set of APIs A1: TwitterVision, A2: Twitter, A3: Rummble and A4: Google Maps, which expose different functionalities rep- resented by the terms T1: microblogging, T2: social and T3: mapping. Table I shows which functionalities provide each API. We call this table, the context that is represented by the set of relations R between APIs and functionalities, where Ri,j is blank if the functionality j is not provided by the API i. In Figure 4, we can appreciate the lattice in a visual representation, where we can see at the top concept, the whole dataset. Because we are considering     Figure 2. API taxonomy  APIs of any kind of functionality, we find the top concept empty. On the medium-level, we find formal concepts as the set {TwitterVision, Twitter, Rummble}, that provides ?social? functionality, or the set {TwitterVision, Rummble, GoogleMaps}, that provides ?mapping? functionality. If we browse deeper we can see concepts as the set {TwitterVision, Twitter} that provides two functionalities at the same time: ?microblogging? and ?social?, or the set {TwitterVision, Rummble}, that provides ?social? and ?mapping? function- alities. At the bottom level, and for this particular small dataset, we find one Web API that provides all functionalities at the same time: ?social?, ?mapping? and ?microblogging?.

B. Mining Rules  From the context (A,K, I) described in the previous section, the frequent itemsets can be extracted. Basically, this process consists of extracting from a formal boolean context the sets of APIs sharing a set of common properties. From these frequent itemsets it is possible to generate association rules of the form L ?? R relating a subset of properties on the left side with a subset of properties on the right side.

To extract the association rules, we build a different context (M,A, I), where M represents the set of mashups, A the set of APIs, and I the binary relation which specifies which APIs conform a mashup. An item corresponds to an API which is part of a mashup, and an itemset to a set of APIs. An itemset is said to be frequent if its support is greater than a given frequency threshold. An association rule is defined as the support of the itemset LuR (where u de- notes the union of the itemsets). The confidence of the rule is defined as the quotient support(L uR)/support(L), i.e. the probability of R knowing L [12]. A rule is said to be exact  Figure 3. API Collaboration network  if its confidence is 1, i.e. support(L uR) = support(L), otherwise the rule is partial.



VI. PROPOSAL: GLOBAL CO-UTILIZATION API RANKING  In [1] we introduced a social indicator of API usage to support the discovery process. In [2], we gathered this in- formation and proposed the Co-utilization API Rank (CAR).

Using the ProgrammableWeb catalog which provides APIs and mashups information, we built an affiliation network between both as shown in Figure 3, where each API is represented as a node in the graph, and each edge represents the joint usage of the connected APIs within a mashup.

Then, each time a user selects an API, a group of ?co- APIs? is suggested and ranked according to the number of mashups where this assertion is valid. In [13] authors mined association rules of an open scientific workflow community in order to answer questions as ?given services which I plan to use, which other services are usually used together with them??. Same question answers our CAR.

Our aim is to support composers to build mashups using a co-API-driven search according they select APIs. This way, the effort to discover all the needed APIs is reduced. In this work we implement the CAR by extracting and exploiting association rules from the mashups and the APIs which conform them.

First, we build the context (M,A, I). From this context we select the frequent itemsets with support greater than 1% Second, we extract the association rules and build our knowledge base only considering the rules with con- fidence greater than 50%. For instance, the association rule {LinkedIn, del.icio.us} ? {Twitter} (supp=10 [0.17%];     conf=1.000 [100.00%]; suppL=10 [0.17%]; suppR=589 [10.07%]; provides relevant information to the composer by saying that in the 100% of the cases (in the dataset) where the LinkedIn and del.icio.us APIs were used, the Twitter API was also used. From this rule we can also know that there are exactly 10 mashups that have mashed the three named APIs, there are 10 mashups which have mashed the two first ones, and there are 589 mashups which use the Twitter API (which represents the 10% of the entire dataset).

Third, we calculate the CAR and the list of recommended APIs using the knowledge base. Algorithm 2 describes this calculation.

Algorithm 2 API recommendation and CAR calculation Require: The set A of all APIs.

Require: The set H of association rules.

Require: The set S of selected APIs.

1: Let C be the set of recommended APIs.

2: Obtain association rules HS = {h ? H | S ? Lh}, where h = {Lh ?? Rh}.

3: if HS 6= ? then 4: for all h ? HS do 5: Rank r ? Rh according to the confidence ch of the rule h.

6: Add r to C.

7: end for 8: else 9: Let J = A be the set of the intersection of the right side of the  association rules of S.

10: for all s ? S do 11: Let T = ? be the set of the right side of the association rules  of s.

12: Obtain association rules Hs = {h ? H | s ? Lh}, where  h = {Lh ?? Rh}.

13: for all h ? Hs do 14: T = T ?Rh 15: end for 16: J = J ? T 17: Rank j ? J ? T as the maximum confidence between the  intersected rules.

18: end for 19: C = J 20: end if 21: return C

VII. OUR APPROACH  Given a set S of APIs already selected and a query Q which describes in terms of keywords the required function- ality, our proposal is to recommend other APIs which, in one hand, provide the required functionality, and on the other, are popular enough inside this subspace, and there is evidence of its co-use with the current selection of APIs. In other words, our approach consists of first exploring the searching space and then exploit this subspace using the social information.

Similar to [2], composers can set up the importance of the social indicators to each particular problem. Algorithm 3 summarizes the complete approach.



VIII. IMPLEMENTATION  Our dataset was extracted from the well-known Pro- grammableWeb?s catalog, where the number of published  Algorithm 3 API discovery and recommendation Require: The set M of all mashups.

1: Let KAi = {t1, ..., tm} be the set of keywords defining the type of  API the composer searches at step i.

2: Let I be the number of APIs that will comprise the mashup.

3: Let S be the initial empty set of selected APIs.

4: for i = 1 to I do 5: Remove stop words from KAi 6: Stem KAi 7: Using KAi obtain the API category CA which intent is closest to  KAi as explained in section V 8: Get the APIs ? CA = {a1, ..., aK} 9: for k = 1 to K do  10: Calculate semantic rank Rk given the frequency matrix of the API - terms  11: Let nk the number of mashups m ?M in which APIk is used 12: Let nmax = max1?k?K nk 13: Calculate global WAR of APIk as WARGk =  nk nmax  14: Calculate the final rank FRk of APIk as FRk = ??WARGk + (1? ?) ?Rk  15: end for 16: The user selects one API, adding it to S, probably the one with  highest final rank FRk 17: Obtain the set C of recommended APIs as described in Algorithm 2.

18: end for  Figure 4. MashupRECO architecture  APIs has increased on around 30% from December 2010 to mid-July of 2011, period in which the number of mashups has also increased in about 20%. We reuse the MashupRECO [2] prototype tool 2 in order to evaluate our results with users. In this case, the MashupRECO socially influence, using the mining CAR, the discovery results obtained by a keyword-based search. We are working with an association rules set with confidence ? 50% and support ? 6 (empirically tuned).

The MashupRECO tool contains three main components that give support to the discovery and recommendation process. The Data collector, which extracts descriptions and usage data of APIs and mashups, the Taxonomy builder that takes those descriptions to create functional categories of  2http://bunker.toeska.cl/mashup-reco/     APIs, and the Rules extractor that obtains association rules for APIs, based on the joint usage of APIs within mashups.

The architecture of MashupRECO is presented in Figure 4.

A. Data collector  This module obtains data from external catalogs. It gath- ers information about APIs and mashups. A snapshot was extracted from ProgrammableWeb?s catalog in May of 2011, collecting 3318 APIs and 5848 mashups. The data includes which APIs has been used to create each mashup, their descriptions, tags, protocols, among others.

B. Taxonomy builder  In order to find functional equivalent APIs, we construct a taxonomy using the textual descriptions of APIs. First, we extract a set of tokens from the descriptions and using the TreeTagger tool 3, we filter uncommon nouns and stop words. From the resulting set of terms we must choose those relevant enough to represent the different objects.

For this task, we used Term Frequency/Inverse Document Frequency (TF/IDF). TF/IDF is a common mechanism in Information Retrieval for generating a robust set of repre- sentative keywords from a corpus of documents. Then, using Coron System 4, we generate a concept lattice that allows us to hierarchically arrange nodes (or concepts), each one containing a set of APIs and a set of terms. The number of concepts generated was 754 + 2 (inner nodes plus top and bottom nodes), and the concepts contained no more than 5 terms.

C. Rules extractor  For the recommendation system, we take the information about usage of APIs within mashups and construct a formal context not using APIs and keywords, but using mashups and APIs, which leads us to obtain association rules between APIs based on their past usage within mashups. We used Coron to obtain a total of 118046 rules with different values of confidence. Using these rules is possible to recommend APIs by calculating the CAR for an individual or a set of APIs.

Table II EXCERPT OF THE ASSOCIATION RULES WITH 100% CONFIDENCE  Antecedent Consequent Support TwitPic Twitter 25/.43%  YouTube, Panoramio Google Maps 12/.21% Twitter, YouTube, Yelp Flickr 7/.12% US Postal Service, UPS FedEx 6/.10%  Table II shows an excerpt of the association rules with 100% of confidence. For instance, if the user already se- lected the TwitPic API we could suggest to complete the  3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger 4http://coron.loria.fr/  mashup with Twitter because all the mashups that have used TwitPic before (100% confidence) have been mashed with Twitter. We can also support this suggestion arguing that this information is valid for 25 mashups that represents the 0.21% of the total number of mashups.



IX. EXPERIMENTS  An experiment was carried to evaluate the tool versus searching directly on ProgrammableWeb?s catalog. In order to compare both approaches, the number of steps or different searches required to find suitable APIs for a mashup were measured. Ten target mashups with different number of APIs were evaluated. The results are listed in Table III, where for each case, we have the number of APIs of the mashup, the number of steps required using ProgrammableWeb?s catalog (PW) and MashupRECO tool (MR), and the relative variation using the tool versus the catalog. The results show that we can reduce, in average, 37% of the steps required to obtain relevant APIs for a mashup. When the number of APIs increases, the tool can make recommendations based on the current selection and gives the possibility to reduce steps in the process.

One of the difficulties found using the catalog is the need to supply keywords that match exactly the existing tags.

This becomes more problematic when two or more tags are used together; if one of them does not match a tag, the whole query is affected and no results are listed. Another drawback is that all the items listed in the results have the same importance, they will appear on the list if all the keywords in the query are present in the tags of the item.

By default, the list is sorted alphabetically, but can be sorted also by date, popularity and category. MashupRECO solves these problems by applying a preprocessing stage where the words are stemmed and then used to create the categories of APIs. This allows to find results not only using exact keywords, but also variations of them. Also, the results are ranked according to two measures, one is a rank based on the closeness of the query to a category in the taxonomy, and the other is a social rank (the Web API Rank) based on the past usage of the API. These two ranks are combined using a trade-off factor to sort the results.

Table III EXPERIMENT RESULTS  Case #APIs #Steps PW #Steps MR Variation 1 2 2 2 0% 2 2 2 2 0% 3 2 3 3 0% 4 3 7 5 -29% 5 4 8 5 -38% 6 4 4 1 -75% 7 4 4 2 -50% 8 5 6 3 -50% 9 6 6 2 -67%  10 6 7 3 -57%

X. CONCLUSIONS  In this work we presented a semiautomatic approach to support developers in the iterative and explorative process of selecting APIs for a mashup. The decisions made by the community can be exploited to make recommendations at each stage of the process based on the current selection of APIs. For this task, the MashupRECO tool extracts association rules from historical data to correlate APIs.

Results show that steps can be reduced from the selection process using these recommendations.

ACKNOWLEDGEMENTS  This work was partially funded by projects Content- Compass (FONDEF D08i1155), DGIP-24.08.58 (UTFSM), CCTVal (CONICYT Basal), and CAMPUS (STIC-Amsud).

Torres? work was funded by Conicyt, Basal FB0821 - Project FB.02PG.11 and UTFSM PIIC.

