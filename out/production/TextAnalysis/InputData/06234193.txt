

Abstract?Gene expression data based cancer classification is of great importance to the computer aided diagnosis. In this paper, we propose a novel cancer selection method, AR-SVM. In AR- SVM, association rules are used as feature extraction approach to catch the non-linear relation among different genes, and support vector machine is used to classify the transformed gene expression data.  The proposed method achieves both high classification accuracy and good biological interpretability. The experimental results on various gene expression datasets show that AR-SVM achieves the highest classification accuracy in comparison with existing gene expression classification methods.

Keywords-association rules; support vector machine; gene expression data; computer aided diagnosis

I.  INTRODUCTION Microarray [1] is one of the latest breakthroughs that make  it possible to monitor of gene expression for tens of thousands of genes simultaneously. The gene expression data provide a deep insight into the activity of the gene, which is helpful in the diagnosis of gene related diseases, such as malignancy and inherited diseases.

However, analyzing and handling of noisy, small sample, high dimensional gene expression data is becoming one of the main bottlenecks to utilize the microarray technology. To deal with such challenges, an effective and efficient method is required. The gene selection-based methods and association rule-based methods are the two traditional supervised learning methods for the analysis of gene expression data [2].

In the gene selection-based methods, firstly, a feature selection method is conducted to reduce the dimensionality, and then a serious of common classifiers is trained to classify the data. Support Vector Machine Recursive Feature Elimination (SVM-RFE) [3] and mutual information [4] are the two representative technologies of gene selection-based methods. The advantage of gene selection approach is that it can combined with different classification models to achieve  very high classification accuracy. However, the existing gene selection approaches is hard to catch the non-linear relation among different genes.

Compared with the gene selection methods, association rules provide an easy and convenient way for understanding the relation among genes and becomes an important technology in gene expression data analysis. Association rule interestingness measure and classification model are two main aspects in association rule-based gene expression data classification methods. Cong?s Short [5], Cai?s Min-Subrule-Conf (MinSC), Max-Subrule-Conf (MaxSC) [6] are two of the most used association rule interestingness measure. Refined Classification Based on TopkRGS (RCBT) [5] and Improved RCBT (IRCBT) [6] are two of the state of association rule-based classification models. The lack of effective classification model makes improvement of the association rule-based methods? classification accuracy.

In this work, we try to take the advantages of both gene selection approach and association rule-based approach, by combing the association rule and support vector classification model in a unified framework. In the proposed Association Rule-based Support Vector Machine (AR-SVM), an association mining step is used to discovered the interesting patterns from the gene expression data; then the original data set is convert to a binary vectors by considering whether the sample covers the discovered patterns; finally, a support vector machine is trained on the transformed data to classify the gene expression data.

The rest of this paper is organized as follows. In section II, the preliminaries of our work are introduced. Section III elaborates the AR-SVM algorithm. Section IV describes the details of our experiments. Section V concludes this paper.



II. PRELIMINARIES Association rules and support vector machine are two of the  fundamentals of this work.

A. Association Rules in Gene Expression Data The framework of association rules was introduced into the  data mining domain by Agrawal et al [7]. For its good interpretability, the association rules are preferred in the gene expression data. Here, we will give a brief introduction of the association rules in the gene expression context.

Assuming a gene expression dataset D consists of n rows and m items. We use R = {r1, ..., rn} and I = {I1, I2, ..., Im} to denote the row set and the item set respectively. Here, the row set stands for the samples? gene expression profile while the item set stand for the expression state of a gene. There is also a class label set C = {C1, C2,...,Cn } to denote the class label of each row rn and each row have and just have only one label.

Given a set of items I? ? I, the Row Support Set of I?, denoted as R(I?) ? R, means the largest set of rows that contain I?. Likewise, given a set of rows R? ?R, the Item Support Set of R?, denoted as I(R?) ? I, means the largest set of items contained by all the rows in R?.

An association rule ?, or a rule for short, derived from the dataset D is shown in the form as A ? co. Where A? I and co ?  C. A and co are called respectively the antecedent and consequent. Each association rule has two measures relative to a given set of gene expression samples or samples: its confidence and its support. For instance, the support of the given association ?: A ? co is defined as |R(A?co)|,means the percentage of the samples that contain both A and co. In addition, the confidence is defined as the ratio |R(A ? co)|/|R(A)|,interpreted as the percentage of the samples that contain co among the samples that contain A. To simplify the notation, let sup(?) and conf(?) denote the support and confidence of the association rule ? respectively.

Rule Group is an important concept used in the association rule mining to provide a summary of thousands of rule.  A rule group is a set of association rules G = {?1, ... , ?r} with row support R?, iff (1) ?? ? G, R (?) = R?, and (2) ?R (?) = R?, ? ?G. Obviously, all rules with the same support and confidence make up a rule group.

There are two special types of rules exists in a rule group: upper bound rule (UBR) and lower bound rule (LBR). The UBR is a unique upper bound rule in the rule group such that its antecedent is a superset of the antecedent of all other rules in the rule group. The LBRs in a rule group are a set of rules such that none of their sub-rules are in the rule group. Both of UBR and LBR are used to select the most k valuable association rules in a rule group.

B. The SVM Classifier Support vector machine (SVM) is a kind of supervised  learning methods for classification and regression analysis.

Support vector machine constructs a hyperplane or set of hyperplanes in a high- or infinite- dimensional space in the task. A good hyperplane is achieved when the margin between different classes is maximized, since the larger margin means the lower generalization error of the classifier.

Whereas the original problem may be stated in a finite dimensional space, it often happens that the sets to discriminate  are not linearly separable in the original space. Thus, it was proposed that the original finite-dimensional space be mapped into a much higher-dimensional space, making the separation easier in that space. To keep the computational load reasonable, the mapping used by SVM schemes are designed to ensure that dot products may be computed easily in terms of the variables in the original space, by defining them in terms of a kernel function selected to suit the problem.

For classifying the gene expression data, one can use some sophisticated machine learning methodologies such as artificial neural networks, SVM, rough sets, etc. The relations among genes are always non-linear and SVM has been found useful in handling classification tasks in the case of high dimensional and small sample size data [8]. Small number of sample size, high dimensionality and low signal to noise ratio are the three main challenges of gene expression data mining. Thus, SVM is selected as our target classification model.



III. ASSOCIATION RULE-BASED SVM-CLASSIFIER Traditional classification procedure in gene expression data  usually involves two steps. The first step is gene selection, also known as the ?feature extraction?. This step is intended to select the valuable features from the original dataset and make up both training and testing sets. The second step is putting the training and testing sets into a classifier to launch the classifying procedure and get a classification results from it. In this case, none of the prior knowledge is utilized into the classifier so that it is not easy to interpret the result from a biological way.

Here we put forward a novel method: Association Rule- based SVM-classifier (AR-SVM), a classifier that combines support vector machine and association rule. This method is a sort of supervised learning methods and mainly involves three steps:  The first step is association rules mining, in this step, we will extract association rules from the gene expression data.

There are many approaches to extract the valuable association rules. Traditionally, the support and confidence are the two main interest used for mining the association rules. In Cong?s [5] research, the distance between rules was used and select the top-k shortest LBRs (Short) in a rule group for mining rules.

Cai [6] extend the work of Cong?s research by taking the minimum sub-rule confidence (MinSC)and maximum sub-rule confidence (MaxSC) into consideration for mining the rules. In our research, both Short, MinSC and MaxSC are used as the interest for evaluating the association rules and they would be compared in the experiments. All of the association rules are saved in a file and an association is saved in a form as {RulegroupID: Rule1, Rule2,?,Rulen}. The element Rulen is made up of several GeneID and belongs to the rule group with the identifier RulegroupID.

The second step is to change the original dataset, which was divided into training and testing set, with the knowledge of association rule into a binary vector. We finish this ?transform? procedure by considering whether the samples in the training and testing set contain the discovered patterns. If a sample smp1 is cover by association rule ar1, then we sign ?1? in the result that related to smp1 and ar1,otherwise we sign ?0?.After this     procedure, all the association rules would be  transformed with the information of all gene expression samples. So that we could obtain a result in a binary form ?01001?? as the new training and testing set. Obviously, elements in the new training and testing set contain prior knowledge from the association rules. The framework of this step in our algorithm AR-SVM is shown as Algorithm 1.

The third step is classification. Before the implement of classification, a process called ?format converting?, which converts the training and testing set generated in step3 into a certain format, is needed to be carried out because of the binary form of these file cannot being used as the input data for the SVM-classifier (In our experiment, the libSVM is adopted as the default SVM classifier).After the this process, we put the converted training and testing set into the SVM classifier to launch the classifying procedure and get the classification results from it. In our program, the best kernel function would be auto selected via parameter tuning in training step.

In order to illustrate the whole transforming procedure, we  make a brief example: Assuming a gene expression sample smp: {1, 3, 6, 8, 10: 1} in the original training set DS (Note that the label?: 1? at the end of a sample indicates this sample is a positive sample, otherwise the ?:0? denotes a negative sample) and an association rule dataset RS which is discovered as:{{1,3},{1,2},{1,6},{3,8,10}}, then we match up smp with each elements ar in RS by considering whether all items in ar are also in smp. Obviously, for the items in {1, 3}, both ?1?and?3? are in the smp :{ 1, 3, 6, 8, 10}, thus we put the first result ?1? into the binary vector RC. For the second rule {1, 2} in RS, the item ?2? is not found in smp even the ?1? happens, so we put the second result ?0?into RC. The rest rules can be done in the same method and we can achieve the binary vector of RC :{ 1, 0, 1, 1} related to the gene expression sample smp and the rule dataset RS. Then we combine this binary vector with class label ?:1?, a new training set :{ 1, 0, 1, 1:1} has been generated.



IV. EXPERIMENTS In this segment, we will describe the details of our  experiments and analyze the result of the experiments.

A. Experimental Setting Leukemia [9], DLBCL [10], Lung Cancer [11] and  Bortezomib [12] are the four opened gene expression datasets used in our experiment. They are available on the official website of Gene Expression Omnibus [13]. Detailed specification of these datasets is listed in Table I. The label ?D?, ?F?, ?AML?, etc. denotes the sub-class of the related disease.

TABLE I.  GENERAL INFORMATION OF GENE EXPRESSION DATASETS  Dataset Num. of sample (pos. class : neg. class) Num. of property  DLBCL 58 (D):19 (F) 7129 Leukemia 25 (AML):47 (ALL) 7129  Lung Cancer 150 (A):31 (M) 12533 Bortezomib 58 (R):50 (NR) 44928   The algorithm of association rule mining: Short, MaxSC  and MinSC are available on their project?s official website [14]. We utilize the entire algorithms in the IDE: Visual C++ 6.0 and the SVM classifier is implemented based on LibSVM3.1 + Python 3.2.2. All the experiments are run on a server with a Dual-Core Core i3-330M CPU, and 4GB of RAM, only one CPU is used. For the purpose of fair comparison, the top-10 covering rule groups of each sample are discovered and top-20 LBRs are generated for each rule group.

This experiment is mainly intended to research the classification accuracy of the association rules-based SVM- classifiers. The 3-fold cross validation is adopted in the experiment. In the framework of the 3-fold cross validation, a dataset would be randomly partitioned into 3 subsets with same size. Each time a subset is chosen as the testing set and the remaining 2 subsets are regard as the training set. This process is repeated in 3 times. The final result is the average of the 3 individual experiments. We take the 3-fold cross validation 50 times in order to avoid the influence of randomicity. In order to compare the quality of different interestingness measure of association rule mining, both Short, MinSC and MaxSC are taken into consideration. Different classifiers are also compared in order to test our algorithm. The RCBT [3] classifier and IRCBT [3] classifier are adopted in comparison with the AR- SVM mentioned in this paper.

B. Classification Accuracy Analysis Comparison of various interesting measures: Table II  summarizes the comparison of AR-SVM with different classification models on three interestingness measures, Short, MinSC and MaxSC. The best classification model of each interestingness measure is presented in bold. From the tables, we can see that AR-SVM classifier achieves the best performance among the three classifiers regardless of the interestingness measure. This experiment shows the effectiveness of AR-SVM in the cancer classification problem.

Algorithm 1: framework of transform in AR-SVM Input: DS: dataset of the training (testing) samples;  RS: dataset of association rules; Output: RC: the dataset of the new training (testing) samples, also the input source file of the SVM classifier (1) Set RS =? (2) for each smp in |DS| do (3)   for each ar in |RS| do (4)                CheckCover(smp,ar) (5)        count =0 (6) Return RC; (7) function CheckCover(smp, ar) (8)  for each geneid in ar do (9)                bool = (geneid ? Di) (10)   if bool = false then (11)   insert the label ?0? into RC (12)   else (13)    count = count +1; (14)      if count = |R| then (15)       insert the label ?1? into RC     Comparison with SVM on continuous data: Table II also presents the accuracy of S continuous gene expression data. This method SVM classifier, but in comparison with the method completes the whole classification p original continuous gene expression dat processing. The experimental result shows outperforms SVM on the continuous data, whi association rule mining is an effective fe method for the high dimensional gene e Moreover, the SVM classifier on continuous data is generally considered as the tradition method with high accuracy but difficult to e SVM partial solves this problem by conduct mining on this data set.

C. Sensitivity analysis In order to evaluate the sensitivity to param  do the test in various numbers of LBRs an DLBCL dataset. Studies on other datasets giv Generally, the algorithms are robust to the n and the number of UBRs.

Figure 1.  Varying Num. of LBRs  Figure 2.  Varying Num. of UBRs  Interestingness Measure Short  Classifier AR-SVM RCBT IR Bortezomib 67.03% 64.37% 66  DLBCL 94.20% 84.42% 86 Leukemia 95.42% 83.53% 87  Lung Cancer 98.67% 97.86% 98 Average 88.83% 82.55% 84  gene expression SVM classifier on d also utilized the e AR-SVM, this procedure on the ta without any s that AR-SVM ch shows that the eature extraction expression data.

gene expression  nal ?Black box? explain. The AR- t association rule  meter settings, we nd UBRs on the ve similar result.

number of LBRs      Figure 1 shows that the change number of LBRs. When the numbe the classifier has already captured t dataset. Moreover, when too many less interesting LBRs will be selecte the accuracy of the classifier. Th +MinSC?s accuracy when 80 L phenomenon also shows the neces number of LBRs.

Figure 2 shows the accuracy on Similar to the result of LBRs, the when too many UBRs are selected i SVM +MinSC and AR-SVM + Ma when 40 UBRs are selected.



V. CONCL In this paper, we propose a nov  combine association rule mining m machine. Experimental shows tha advantage of both methods and p cancer classification problems. M easily adopted in solving othe classification problem.

ACKNOWLEDGM This work is financially supp  Foundation of China (61100148), N of Guangdong province (S20110 Technology Planning Project o (2010B080701070), Opening Pro Laboratory for Novel Software Tec Foundation for Distinguished Y Education of Guangdong, China (LY  REFERENC [1] Mark Schena, Dari Shalon, Ronald  Quantitative monitoring of gene complementary DNA microarray. Scien  [2] Ronnie Alves, Domingo S. Rodrigue Gene association analysis: a survey of expression data. Brief Bioinform, 2010  [3] Isabelle Guyon, Jason Weston, Stephen Selection for Cancer Classification u Machine Learning, 2002, 46(1): 389-42  [4] Liu X, Krishnan A, Mondry A. An Ent for cancer classification using microa 2005, 6(1): 76.

TABLE II.  CLASSIFICATION ACCURACY  MaxSC MinSC  RCBT AR-SVM RCBT IRCBT AR-SVM RCBT 6.46% 68.33% 63.81% 65.91% 67.32% 65.19% 6.91% 93.20% 81.79% 84.81% 92.20% 84.75% 7.08% 91.86% 83.47% 87.06% 95.63% 93.69% 8.50% 98.33% 92.00% 92.88% 99.75% 98.84% 4.74% 87.93% 80.27% 82.67% 88.73% 85.62%  e of the accuracy with the er of LBR is larger than 20, the main information of the y LBRs are selected, some ed with a negative effect on he decreasing of AR-SVM LBRs are selected. This ssary of setting the proper  different number of UBRs.

accuracy decreases slightly in this test. Such as the AR- axSC?s accuracy decreased  LUSION vel algorithm: AR-SVM to method and support vector at AR-SVM can take the provide a new method for oreover, AR-SVM can be er high dimension data  MENTS ported by Natural Science Natural Science Foundation 040004804), Science and of Guangdong Province oject of the State Key chnology (KFKT2011B19),  Young Talents in Higher YM11060).

ES d W. Davis, Patrick O.Brown.

expression patterns with a nce, 1995, 270(5235): 467-470.

ez-Baena, Jesus S. Aguilar-Ruiz.

frequent pattern mining from gene  0: 11(2):210-224.

n Barnhill, Vladimir Vapnik. Gene using Support Vector Machines.

22.

tropy-based gene selection method array data. BMC Bioinformatics,  C SVM  IRCBT 66.52% 66.10% 86.88% 88.42% 95.28% 91.41% 99.13% 95.92% 86.95% 85.46%     [5] Cong Gao, Tan Kian-Lee, Anthony K. H. Tung, Xin Xu. Mining Top-k Covering Rule Groups for Gene ExpressionData. Proceedings of ACM SIGMOD Conference. 2005: 670-681.

[6] Ruichu Cai, Anthony K. H. Tung, Zhenjie Zhang, Zhifeng Hao. What is Unequal among the Equals? Ranking Equivalent Rules from Gene Engineering , vol. 23, no. 11, pp. 1735-1747, Nov. 2011.

[7] R. Agrawal, T. Imielinski, A. Swami. Mining Association Rules Between Sets of Items in Large Databases", SIGMOD Conference 1993: 207-216.

[8] Mei Z, Shen Q, Ye B. Hybridized KNN and SVM for gene expression data classification. Life Science Journal, 2009, 6(1):61-66.

[9] T. R. Golub, D. K. Slonim, P. Tamayo, C.Huard, M.Gaasenbeek, J.P.Mesirov, et al. Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring. Science, 1999,286(5439):531-537.

[10] Margaret A. Shipp, Ken N. Ross, Pablo Tamayo, Andrew P. Weng, Jeffery L. Kutok, Ricardo C. T. Aguiar, et al. Diffuse large B-cell lymphoma outcome prediction by gene-expression profiling and supervised machine learning. Nature Medicine, 2002,8(1):68?74.

[11] Gavin J. Gordon, Roderick V. Jensen, Li-Li Hsiao, Steven R. Gullans, Joshua E. Blumenstock, Sridhar Ramaswamy, et al. Translation of Microarray Data into Clinically Relevant Cancer Diagnostic Tests Using Gene Expression Ratios in Lung Cancer and Mesothelioma. Cancer Research, 2002,62(17):4963?4967.

[12] George Mulligan, Constantine Mitsiades, Barb Bryant, FengHuang Zhan, Wee J. Chng, Steven Roels, et al. Gene expression profiling and correlation with outcome in clinical trials of the proteasome inhibitor bortezomib. Blood, 2007,109(8):3177?3188.

