

Abstract? In this paper, a fast identification based on ring die granulator system by using prediction model linear LSSVM regression is discussed for big data system. Because the model of regression prediction based on SVM is suitable for small data, the accuracy of regression prediction is not high. However, if the number of data and dimension of feature increase, the training time of model will increase dramatically. In order to solve the problem of long modeling time for inputting large data, the improved NDCD method is used for solving the models.

Meanwhile, real data is conducted on the granulator to prove the effect. Compared with other methods for large data system by the simulation, this method has not only apparent advantages but also high fitness. In conclusion, this method has good ability of fast modeling and generation, which can be used real prediction on hoop standard granulator by online prediction model to solve the problem that large time is delayed in outputting of hoop standard granulator.

Keywords?Linear LSSVM; NDCD optimization; Big data, Fast Identification

I.  INTRODUCTION1 Pelletizing with ring die is a high added valuable process in  modern poultry feed production. Powdered fodder mixed and uniformly stirred with high steam at a certain ratio become granular fodder. The output temperature of conditioner is very important and closely related to the quality of production.

However, during the production, Variables such as steam flow, steam pressure, steam temperature and feed rate influence the output temperature of conditioner. And the feed rate is also     1  This work is supported by Nantong Research Program of Application Foundation under Grant BK2012030  This work is supported by Key Project of Science and Technology Commission of Shanghai Municipality under Grant No. 10JC1405000.

closely related to the main motor valves. In such a situation of the feed processing, under the premise of ensuring the quality of granulation, how to improve production efficiency (reduce consumption) must be considered, because the installed capacity of hoop standard granulators can reach 100MW. We can draw the conclusion that it is difficult to model ring die granulator, as it is a MIMO system with high degree coupled with and large time delay and nonlinear characteristics. The most modeling common method is nonlinear approximately linearized one. But because the characteristics have mentioned and the approximately linearized method has its localization, linear model cannot satisfy with the controlling performance and see details in literature [1-5]. For complex objects utilizing actual I/O data is an effective method to identify the model.

Fuzzy, ANN and SVM are tried to obtain modeling.

Comparing to the former two methods, SVM processes less convergence support vectors, training time higher precision of prediction, and capacity of generalization. Compared with ANN, SVM can turn into a constrained convex quadratic optimization and can get global optimum solution. From literature [6-8] latest research has found that performance of traditional SVM largely depends on the kernel, and the modeling time will increase dramatically if increasing the number of sample and dimension of feature increase, and it cannot be used in online modeling. Sampling period of ring die granulator is within 1s. So it is necessary to find a new and advanced approach based on SVM to meet the need of accurate prediction of model and the fast identification.

This paper is organized as follows. In Section 2, we introduce linear support vector machine. In Section 3 we investigate an optimization method for training SVM. In Section 4 we build the prediction model of conditioner temperature. In Section 5 we conduct experiments to compare linear SVM with other SVM algorithms based on the actual data. Section 6 concludes this work.



II. LINEAR SUPPORT VECTOR MACHINE  Given a set of instance-target pairs ,i ix y , n  ix R  ,  1, .,i l  , linear SVM finds a model , and T ix  is close to iy . the regularized optimization problem can be solved as following  Tf x x b                              (1)  where  is the weight vector and b  is bias.

If data is not linearly separable, nonlinear regression map  each instance to x  a higher dimensional vector ( )x .

For nonlinear regression, evaluation T x  can be high  because ( )x may be very high dimensional. Kernel methods were introduced to cope with such difficulty, more details in literature [9-11]. However, for large data in the training and testing processes are still time- consuming.

If ( )x x , function [1] is a linear regression. The cost of prediction can be reduced from ( )O ln  to ( )O n  .so it can enjoy faster training and testing.

To generate a decision (1), linear regression involves the following risk minimization problem.

l  T i i  i 1  1min f ? ? C ? ( ;x , y )  (2)  where parameter C is for balancing between T  and the sum of losses.

T 2 i i i i? ;x , y max( x y ,0)                      (3)  ? is the -insensitive loss function associated with i i(x , y ) The decision function becomes Tf x x .

It is known that the dual problem of L2-loss SVM is (4)  A ? ? min f (? ,? )  0 ? ,? , 1,.,i isubject to U i l (4)   2 2  1( , ) ( ) ( ) ( ( )  ( ) ( ) ( ) 2 2  l T  A i  i i i  f Q  y (5)  In (5) l lQ R is the matrix  with , T  i j i jQ x x , 1( , ) ( , )  U c  . Combine , , so  and ( )Af is as follow:  1( )  T T  A  Q Q e y f  e yQ Q (6)  In the paper, we refer function (1) as the primal SVM problem, while (4) as the dual SVM problem, the primal-dual  relationship indicates that primal optimal solution *  and dual optimal solution *  satisfy  l * * *  i i i i 1  ? ((? ) (? ) )x                              (7)  While * *i i(? ) (? 0) . The dual problem is at optimum.

The dual problem of SVM has 2l  variables. If a dual-based solver is applied without a careful design, the cost may be significantly high.



III. OPTIMIZATION METHOD FOR LINEAR SVM  A. DCD Method Dual coordinate descent is evolved from coordinate  descent method and sees more details in literature [12-14].

Coordinate descent is an unconstrained optimization. The biases ?  are iterated step by step, so we can draw an optimization which is faster than others.

Iterate process begins with 0 lR  and get a sequence   k  k , 1k   is update by k  ,and series of vectors  , , 1,..., 1k i l iR l  ,and ,k i k , 1 1k i k  and then get  , ! !

1 1, , , , , 2,  Tk i k k k k i i l i l                       (8)  Vector ,k i  update to , 1k i  it is needed to solve the following sub problem:  2 2  min ( z ) ? 0 0, ,0,1,0, ,0  1z ( ) ( )  k A i id  T i  A i A ii A i  f e z U e  f e f f z f  (9)  The optimal value d can be solved in a closed form: , 0k ii f  If it is needed to be solved, so i  is updated by  2min(max ,0 , ) i  i i ii A  f U  f (10)  At last, the optimization? can be calculated as following: ,?

,?

i i i  i l i l i l  x if i l  x if l i l (11)  Where i   is present value, i is updated value.

B. Improved DCD Method  Improved DCD method is solved , ,together. We use 2( )i i replace  2 2( ) ( )i i  and give the optimal solutions as following     ? ,? 1   1min ( ) ( ) ( ( )  1 )  l T  i i i i i i i  i i i i i  Q  y (12)  Further, i i =0, 0i , 0i  imply that at optimum, | |i i i i  Define   Problem (12) can be turned into    ( )?

B i  T T B  f U Uin  y  m i  f Q (13)  If *  is an optimum of (13), * *  * * ( ) max( ,0) ( ) max( ,0)  i i  i i   We assume  is the present iterated and its i th component, denoted as a variable s , which is updated.

The following problem is solved.

s  g sn smi U U                       (14)  Where  is considered as a constant vector and  21( )  B i i B  i i ii i  g s f s e f  s Q y s Q s (15)  To solve (13) we start with checking the derivative of g s . When s=0 g s  is not differentiable, its derivatives are at s 0 and s 0 respectively.

' p ii ii  g s Q y Q s  0if s , and  ' n ii ii  g s Q y Q s  0if s , and  Both 'pg s , ' ng s  are linear functions of s . and further,  ' ' , ?n pg s g s s R  As to any strictly convex quadratic function, it is minimum when the first derivative is zero. So (0)g  is the smallest when.

0g g s ,  0s  The sub-problem (14) has the following similar form solution.

max( ,min , )is U U                (16)  Following the same technique in DCD, vector can be calculate as   ( ) Ti i i l  i i i  Q u x  u x                        (17)  C. A Comparison between Two DCD Method For comparison, we choose L2-loss SVM with  parameter 1C  and 0.1 . Figure 2 shows the training time of two DCD methods. In this figure, x asis indicates training time, and y asis  indicates optimum minimum error. The number of Iteration is eight. Therefore, results show that NDCD is faster than DCD.

Fig 2. Comparison between DCD and NDCD

IV. PREDICTION MODEL OF CONDITIONER TEMPERATURE BASED ON LINEAR SVM  In literature[15], we analyze the structure of hoop standard granulator, and draw the control pivotal points in conditioner.

The process of pelletizing with ring die is stereotyped machinery without control points. The model of the conditioner can be approximately described as the (18)  (18)  where ( )T s  is the output temperature of condition and ( )F s is the output flow of the supplier. While ( )LF s is the input flow of supplier and ( )ZF s  is the flow of heat steam.

( , , )iif x t  is input and output mathematical relationship, x is the feed formula parameter, t is time,  is the delay time.

From the given model, we can conclude the main reasons of the difficulty control of hoop standard granulator are coupling of variables, large time delay and nonlinear.  F  can be calculated by the main motor current. So in fact, the output of conditioner are output temperature of conditioner and main motor current, input are feeder value and steam flow.

Based on different feeder and construction, the output temperature of conditioner has a delay of 16s to 30s. The output T  can be obtained by T , LF , ZF  The prediction function is as follows:  ],,[ ZL FFFT                        (19)  Linear SVM need not map to high dimension to get the optimum, and only confirm the parameter C, which can be got by genetic algorithm and cross validation. The optimization training model can be made by NDCD algorithm.



V. EXPERIMENT ANALYSIS A total of 10000 samples are collected in this study with  the help of a company in Shandong Province. Table 2 shows some subsets of input and output data. We consider three levels of data sets in experiments, including 500 samples, 2000 samples, and 10000 samples. These experiments are shown the different among Linear SVM, SMO SVM, and LSSVM algorithm. Experiments are carried out on a 64-bit machine with Intel Core? i7 2.1GHz, 4MB. The training time of each SVM model and accuracy are demonstrated in Figure 3-Figure 5 and Table 1. We can draw the conclusion that each training time of SVM algorithm based on small sample is not  far behind. But all of accuracy is not high enough. Linear SVM has obvious advantages based on medium and large samples, because not only training time is competitive but also the regression accurate rated is proved.

In figure 6, we compare the fitting curves between real output temperature of conditioner and prediction output. We can find that, the linear SVM training time is much faster than others, but it is still lack of fitting, especially in the conditioner start. The genetic algorithm still needs improving.

Table 1.  Subsets of Input and Output  Data Time Current(A) Steam(T/h) T (?C) T  set  Feed (%) Feed set  Input (t/h) 28?59 246 3.6 70 71 49 50 12.5 29?54 238 3.8 71 73 52 57 12.4 30?06 261 3.8 72 73 55 60 13.1 30?28 258 3.9 71 73 58 60 12.8 30?52 256 4.0 69 73 58 60 12.8 31?20 271 4.2 69 73 58 60 12.8 31?35 280 4.2 69 73 58 60 12.8 31?45 286 4.3 70 73 58 60 12.8 32?07 282 4.4 70 73 59 60 14.2 32?30 283 4.5 71 73 59 60 14.2     Fig 3. 500 Samples Comparison                                                      Fig 4. 2000 Samples Comparison   Fig 5. 10000 Samples Comparison                                                 Fig 6. Prediction Temperature Fitness   Table 2. Comparison among Three Prediction Algorithm  algorithm 500 samples 2000 samples 10000 samples  MSE training time MSE  Training time MSE Training time LSSVM 0.0579 10s 0.0258 12s 0.0203 52s  SMO-SVM 0.0636 15s 0.0393 24s 0.0367 127s Linear SVM 0.0592 1.8s 0.0386 2.1s 0.0187 2.9s

VI. CONCLUSION After analyzing the process of granulator and getting the  characteristic of conditioner, a fast identification based on NDCD linear is proven in the paper. To compare with SMO- SVM, LSSVM and be verified by some experiments in real data. Linear SVM has much competitive in fast modeling, and it can be used in real time prediction of hoop standard granulator to solve the large time delay of conditioner. The results of experiments show the lack of fitness, genetic algorithm need to improve and find optimal parameters. In future we will introduce Lyapunov energy convergence in searching optimal parameters.

