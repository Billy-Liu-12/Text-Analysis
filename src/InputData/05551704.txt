2010 International Coriference on System Science and Engineering

Abstract- Many parallel programming languages provide a set of low-level parallel constructs which lead to programs that are difficult to design, implement, debug, and maintain. In this paper, we present a parallel programming paradigm using a sequential programming language that encapsulates low-level details of distributed and concurrent programming techniques and makes the details transparent to programmers. This paradigm allows programmers to program on several different platforms in a sequential language that they are most familiar with. In addition, the paradigm provides high-level language constructs for programmers to implement various distributed and parallel algorithms. The programming paradigm is illustrated with two parallel Apriori algorithms in data mining.

Keywords- Apriori, data mining, parallel processing, heterogeneous distributed programming

I. INTRODUCTION  Data mmmg techniques are widely used in finding customers' purchasing habits. One of the core techniques is the association rule mining technique. The association rule mining is used to discover that certain items are purchased with some other items in business transactions. R. Agrawal and R. Srikant in 1994 [ 1] presented the Apriori algorithm for mining frequent itemsets which is based on the generation of candidate itemsets.

Several variants of the Apriori algorithm have been introduced [2, 3]. However, the implementation of distributed algorithms for parallelism is not an easy task. Many programming languages lead to programs that are difficult to design, implement, debug, and maintain. Such kind of difficulty in coding for parallelism applies to general applications in addition to data mining.

A conventional sequential programming language enhanced with a set of low-level constructs is one way of programming of parallel computation. The low-level constructs allow parallel processes to fork but programmers are responsible for the management of process synchronization points. These low? level constructs make programs difficult to debug [4, 5].

Managing parallelism and synchronization explicitly is a time consuming and error prone task in programming.

A simple way to write programs of parallel computation is to use conventional sequential programming languages and let a parallelizing compiler detect and exploit the parallelism in the  program. The strength of this programming approach is that programmers are comfortable with the programming in conventional sequential programming languages. However, there is a serious problem in this approach. Programmers may simplify unneeded sequentializations which lead to the parallelism undetected by the parallel compiler.

Another alternative of programming a parallel computer is using a conventional sequential language with high-level constructs. Parallel languages with high-level constructs present programmers with models of computation that can encompass a wide variety of architectures. The programming approach mitigates the problems of using low-level language constructs for parallel programming. Moreover, the approach keeps the strength of using conventional programming languages for the programming from the perspective of familiarity. Imperative programming languages are more familiar to most programmers and can be compiled more efficiently compared to functional or logic programming. Why add unnecessary complexity to the programmers? Because the approach is based on a high level abstract model of parallel computation, the programs are more machine independent than programs written in a language closer to the underlying machine.

In this paper, we present a programming paradigm that will simplify the development of heterogeneous and distributed programming by encapsulating low-level details of distributed and concurrent programming techniques and making the details transparent to programmers. This paradigm also allows programmers to program on several different platforms in the sequential language that they are most familiar with.

The rest of the paper is organized as follows. Related work is presented in Section II. For the sake of completeness, the association rule mining techniques should be overviewed before Section II. However, we believe that the concepts of data mining and the associated techniques can be easily found in publications. Thus, we directly present our first parallel algorithm for finding frequent itemsets in Section III. Due to the weakness of the first algorithm, we present a variant of the first algorithm in Section IV. The implementations of these two presented algorithms are briefly discussed and presented in Section V. Although the details of the implementations are not covered, they are included in the author's articles listed in the     2010 International Coriference on System Science and Engineering  reference. The two implementations of the two algorithms are discussed for their strengths and weaknesses. Finally, we summarize the paper in Section VII.



II. RELATED WORK  Karp and Babb have called programming languages with low-level parallel constructs: " ... the equivalent of machine language ... " [6]. Hatcher and Quinn [7] also confirm what others have reported: "Novice programmers make most of their mistakes with the message passing protocols. Even experienced programmers are frustrated by the inelegant and error prone method by which processors communicate and synchronize." Thus, we believe that if we can hide the complexity of communications and synchronization from programmers, the programming tasks might be simplified.

Chiang [8] developed a programming paradigm for heterogeneous distributed parallel programming. The paradigm allowing programmers to write distributed programs in their favorite sequential programming languages makes the programming paradigm very unique to the existing programming paradigms. In addition, considering the requirements of programming in distribution, parallelism, and heterogeneity, the paradigm helps programmers write distributed programs in a simplified way by reducing programming complexity. The complexity of distributed and parallel programming lies on the communications among interacting processes. To simplify the programming tasks, the complexity of interactions must be abstracted out from programmers so the programmers can focus on the business logic rather than the details of communication. The separation of design concerns of the above requirements is discussed in the paper. We are applying the paradigm to illustrate a parallel Apriori algorithm in finding frequent itemsets in business transactions.

Many variants of the Apriori algorithm have been proposed that focus on improving the efficiency of the original algorithm. Among these variants, several algorithms apply the partitioning technique for association rule mining in parallel [9]. A dataset is partitioned into several partitions and distributed to processors. However, we show that large itemsets on the processors will exponentially slow down the process on each processor. Our algorithm partitions not only dataset but also itemsets. Reducing the size of itemsets on each processor speeds up the performance on finding large frequent itemsets.

There are several papers for the tutorial of the Apriori algorithm. Dunham et al. [9] present their finding in comparing various association rules algorithms. Ceglar and Roddick prove a tutorial of Association Mining [ 10].



III. DATA MINING AND A PARALLEL APRIORI ALGORITHM  The Apriori algorithm was proposed by R. Agrawal and R.

Srikant in 1994 [ 1]. However, the performance of the Apriori algorithm is a major concern in finding frequent itemsets.

Many variants of the Apriori algorithm have been proposed that focus on improving the efficiency of the original algorithm. In this section, we [ 1 1] present a parallel Apriori algorithm in finding frequent itemsets.

We assume that the dataset D is divided into n non? overlapping partitions Di, where n is also the number of processors. The itemsets I is also partitioned into n partitions Ii.

Each processor Pi is assigned to process partition Di and Ii. The main steps of the algorithm are as follows.

1. The algorithm partitions a dataset into several partitions and distributes these partitions to the processors.

2. The itemsets is also partitioned into several partitions which are distributed to the processors as well.

3. With the data in place, each processor computes the frequency for single itemset based on items in the local dataset partition.

4. The processors are then exchanging their local dataset partitions. Each processor repeats Step 3 until no datasets exchanged.

5. As the counting process is complete, each processor sends their counts to the leader.

6. The leader computes a global single itemset count. The leader removes its infrequent itemsets from the itemsets against the entire dataset. The resulting new itemsets become candidate itemsets and are partitioned into small itemsets and distributed to the processors.

By keeping the dataset and itemsets in a small and manageable sizes, the algorithm improves the performance of the original Apriori algorithm for finding frequent large itemsets in data mining. The algorithm is presented below.

The Apriori Broadcast Itemsets Partition Algorithm(Itemsets: Ii, Transactional Dataset Partitions: D" D2, ... , Dn, Support: s, Processors: P" P2, P3, ... , Pn, Large Itemsets: L) II Perform in parallel at each processor Pi 1. k = 0; II scan number 2. L = $; 3. Ci = Ii; II Initial set of candidate itemsets 4. repeat  { 4.1 4.2 4.3  k = k + 1; Lk = $;  for each Xi  { E Ci,k do  frequency (Xi) = 0; }  4.4 for each t=<ID, Ii> E Di do {  for each Xi E Ci,k and Xi E Ii do  { frequency (Xi) = frequency (Xi) + 1;  Broadcast Di  4.5 Ci,k+' = Apriori -Join (Lk) ; 4.6 send Ci, k+' and Di to the leader 4.7 recei ve new Ii from the leader  until Ci,k = $; I I repeat until no more set of II candidate k-itemsets  - 594 - IeSSE 2010    2010 International Coriference on System Science and Engineering  The leader performs the following actions.

Leader's Algorithm(Itemsets Partitions: I" I" In, Transactional Dataset: D, Support: s, Processors: P" P2, P3, ??? , Pn) 1. recei ve Ci, k+' from the processor Pi  2. for each Xi E Ci,k do { if ? frequency (X,) / I D I) ? s) then  Lk = Lk U Xi;  3. divide the itemsets in Lk into n partitions, I" I" ... , and In  4. send Ii to the processor Pi  The following Apriori-Join algorithm in the Apriori broadcast itemsets partition algorithm takes a set of large k? itemsets, Lk-1 as an input argument and returns a superset of the set of all large k-itemsets an output argument.

Apriori-Join Algorithm(Set of Large (k-1) Itemsets: Lk_" Set of Candidate k-Itemsets: Ck)  1. Ck = $;  2. for each X E Lk_, do {  for each Y E Lk-, and Y * X do {  if (X U Y) e Ck then Ck = Ck U (X U Y) ;  The Apriori Broadcast Itemsets Partition algorithm is illustrated with the following example. Suppose we have T = {t], t2, t3, t4, t5} and I = {a, b, c, d, e} in the following dataset D where D = {<t1' {a, b, c}>, <t2, {d, e}>, <t3, {a, c, e}>, <t4, {b, c, d, e}>, <t5, {a}>}. Figure 1 presents an example to illustrate parallel frequent itemsets mining.

Transactions Item sets  t1 {a, b, c}  t2 {d, e}  h {a, c, e}  ? {b, c, d, e}  t5 {a}  Figure L An example  Suppose we have reserved 3 processors, Po, P], and P2 for this process and I is partitioned into 10 = {a. b}, 11 = {c, d}, and 12 = {e}. Similarly, D is also partitioned into 3 partitions, Do = {t], t2}, D1 = {t3, t4}, and D2 = {t5}, respectively. Thus, each processor Pi will have Ci = Ii and Di where I = 0 .. 2.

10 = {a, b) Do = It"? t,J  I,={c,d} D, = It"? 41  I' = {e) D, = Its}  Figure 2. Dataset and itemsets partitions on processors for Ll  Each processor computes the frequency for single itemset against its local dataset partition. The processors then exchange their local dataset partitions. Each processor again computes the frequency for single itemset against this dataset partition.

The process is repeated until no more dataset partition exchanged. Table 1 shows the results of frequency counts of 1- itemsets done by each processor.

TABLEr. \-ITEMSETS  K Po P, P,  ({a), It"? 1" t5)) ({c), {t" 1" t.,)) ({e), It"? h. t.,}) ({b), It"? t.,} ({d), It"? t.,}  After each processor finishes the computing of frequency of its assigned itemsets, the processors send the result to the leader. The leader begins to compute the support for global itemsets. Assume the support is 45%, thus in this example, the leader will not consider items b and d further for finding large frequent 2-itemsets. Thus L2 is {ac, ae, ce} which will be split into 10, I], and h, respectively. Figure 3 shows the 2-itemsets and dataset partitions each processor is holding for the generation of candidate 3-itemsets.

10 = lac} Do= It"? t,}  I, = {ae} D, = It"? 41  I, = Ice} D,= Its}  Figure 3. Dataset and itemsets partitions on processors for L2  Each processor continues to work on the assigned partitioned itemsets for finding large frequent 3-itemsets. The same steps are repeated as generating 2-itemsets.

TABLE II. 2-ITEMSETS  K Po P, P,  2 ({ac), {t" I,}) ({ae), {I,}) ({ce), {t,})  There is no frequent 2-itemsets which has the support 45% or more. The processors stop the process.

- 595 - IeSSE 2010    2010 International Coriference on System Science and Engineering

IV. A VARIANT OF THE ALGORITHM  The algorithm presented in Section III has communication overhead where processors are required to exchange their local dataset partitions in order to compute global frequency of their local itemsets. The exchange of local dataset partitions create overhead in communication among processors. The algorithm can be modified for the reductions of this communication overhead. Instead of data exchanges, processors can send their local itemsets to the leader. In this scenario, the leader owns the entire dataset and is able to compute the support for single itemset sent by its clients (processors). Since the leader is acting a central role in the algorithm, the dataset does not need to be divided into partitions. The processors won no dataset partitions any more. What each processor needs to do is to build a trie to store the frequency of its local itemsets assigned to it. The main steps of this revised algorithm are below.

1. The algorithm divides the itemsets I into n partitions, II. 12, ... , In where n is the number of processors.

2. Choose a processor as the leader. The algorithm assigns the dataset to the leader. Thus, the leader owns the dataset D.

3. Each processor sends a single itemset to the leader and waits for the frequency of the itemset.

4. Each processor discards the non-frequent itemset.

5. Each processor builds a trie for storing the frequency of the frequent itemset.

6. Each processor generates the candidate k-itemsets.

7. Steps 3 to 6 are repeated until the candidate itemsets are empty.

Corresponding to the processors' steps, the main steps of the leader is below.

1. The leader receives a single itemset from a processor.

2. The leader computes its frequency against the dataset and also computes its support.

3. The leader sends the results back to the processor.

4. Steps 1 to 3 are repeated until all the processors terminate.

The same example in Section III is used to illustrate the use of this algorithm. Figure 4 shows the dataset and partitioned itemsets assigned to the processors and leader.

I, = {a, b) I, = {c, d) 1,= {e)  o ={I" I" 1" 4, Is}  Figure 4. Dataset and itemsets partitions on processors and leader for L2  Suppose the support is still 45% in this example. The items b and e are discarded. The following figure shows the trie structures built by the processors locally.

P3  Figure 5. Tri ditribution for generating candidate \-itemsets  Next, Processor PI generate II = {ab, ac, ad, ae}, Processor P2 creates 12 = {cd, ce} and Processor P3 stops as shown in Figure 6.

10 = {ab, ac, ad, ae}  I, = {cd, ce}  o = {I" I" I" 4, Is}  1,= {e)  Figure 6. Dataset and itemsets partitions on processors and leader for L3  Each processor sends their itemsets to the leader and gets the frequency back. Each processor continues to store their 2- itemsets in the trie as shown in Figure 7.

P3  Figure 7. Tri ditribution for generating candidate 2-itemsets

V. HETEROGENEOUS DISTRffiUTED PROGRAMMING FOR PARALLELISM  Processors are first introducing each other by issuing EXECOPR with a processor reference name including a unique id and a string that uniquely identifies a single process running on the processor. Object references are created by invoking a call to the system. A buffer is allocated in the storage area for sending and receiving data.

- 596 - IeSSE 2010    20 I 0 International Coriference on System Science and Engineering  During the data exchange session, each processor issues GETDATA and PUTDATA for data exchange. These two functions are synchronous operations. For example, Processor PI sends GETDATA(BUFFER) to P2 for P2's dataset partition D2? The system allocates a temporary storage area of the saI?e size of the requested data, namely BUFFER, for temporanly storing the data to be received from P2? Processor P2 has PUTDATA(BUFFER) to synchronize PI'S operation.

To support the operations in a heterogeneous computing environment, EXECOPR, GETDATA and PUTDATA are implemented using CORBA [12]. The implementations of EXECOPR, GETDATA, and PUTDATA can be referenced in [8]. The interface to the functions is simple. Each processor passes one or two arguments to the function, which returns a result value. Before calling these functions, each programmer assembles a packet containing infonnation specitying data to be stored and fetched. After assembling the packets, the processor enables one of the communication functions, which use the infonnation in the packet buffer to send data to the appropriate processor.



VI. DISCUSSION  The two presented algorithms have their strengths and weaknesses. Nevertheless, the implementations of these two algorithms have no differences in the programming skills.

Programmers use EXECOPR, GETDATA, and PUDATA for data exchanges. Programmers can easily understand the high? level design of these two programs. The first program has heavy communication overhead among processors. However, in the second program, there is communication overhead between the leader and the processors. The leader plays a central role in the second algorithm.

Many parallel algorithms for finding frequent itemsets divide the dataset into partitions for parallel processing among processors. However, the Apriori algorithm has a ",:eakness in perfonnance with the exponential growth. The SIze of the itemsets is a key factor in detennining the perfonnance of finding significant association rules in knowledge disc?)Very [11]. Our first distributed algorithm focuses on the reductIon of the size of candidate itemsets. In the first program, the work of candidate k-itemsets generation is evenly distributed to the nodes for workload balancing among processors. In the second program, a trie is incrementally created dependent on the frequency counts of candidate itemsets. The benefit of load balancing is not considered in the second program.



VII. SUMMARY  Finding frequent itemsets is one of the important techniques in data mining. The Apriori algorithm is the original one for frequent itemsets finding. However, the perfonna?ce of the original Apriori algorithm is an issue. Many algonthms h?v? been presented to improve the perfonnance of the Apnon algorithm. Among these algorithms, parallel process!ng plays a major role in the algorithms. However, programmmg for the parallel algorithms is not an easy task. We presented. a programming paradigm that provides programmers to eastly implement the algorithms.

Programming languages for parallel processing usually provide low-level language constructs for programming. The  use of low-level language constructs usually lead to programs that are difficult to debug and maintain because the programming task is very error prone using the low-level constructs.

One programming approach is to provide a compiler to exploit parallelism in a sequential program. Programmers are still writing programs in a sequential programming language for the solutions of the problems. The compiler will discover the concurrency in the programs and make the processing in parallel. The approach will make fewer burdens on the programmers because the programmers do not have to worry about the complexity of parallelism in the code. However, the compiler might easily miss the areas for potential parallelism.

The programming paradigm presented in this paper is distinctive from existing programming paradigms and approaches. The paradigm allows programmers to use their favorite sequential language to write programs for concurrency.

Using their commonly used sequential languages, programmers feel comfortable in coding parallelism and will not be intimidated. In addition, the programming paradigm provides a simple set of high-level functions for progra?e?s to code concurrency. The details of commumcahon and synchronization are hidden from programmers. The programmers can just invoke the functions by supplying correct values without being overwhelmed with complexity of parallelism. The strength of using this programming paradigm for parallelism is that we take heterogeneity into the design .of the paradigm. The paradigm allows programmers to wr?te distributed programs running on different platfonns. Agam, the complexity of programming heterogeneity is also hidden from programmers. The infrastruchlre of the support for heterogeneity is the middleware CORBA in this programming paradigm.

We presented two parallel algorithms to illustrate the application of the presented programming p?adigm in fin?ing frequent large itemsets in data mining. The hIgh-Ieve? functIOns were introduced to implement the cores of the algonthms. We did not discuss the implementations of these functions.

Nevertheless the implementations of the functions can be found in [8]: The functions have been successfully applied in the other applications in industry [13]. In this paper, we showed that the presented programming paradigm can also be successfully applied to parallel data mining.

