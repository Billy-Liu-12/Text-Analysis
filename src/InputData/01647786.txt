A New Method for Image Classification by Using

Abstract  With the popularity of multimedia applications,  the huge amount of image and video related to real life have led to the proliferation of emerging storage  techniques. Contented-based image retrieval and  classification have become attractive issues in the last few years. Most researches concerning image  classification focus primarily on low-level image  features (e.g. color, texture, shape, etc.) and ignore the conceptual associations among the objects in the  images. In this paper, we propose a new image classification method by using multiple-level  association rules based on the image objects. The  approach we proposed can be decomposed of three phases: (1) building of conceptual object hierarchy,  (2) discovery of classification rules, and (3)  classification and prediction of images. At the first phase, we use a hierarchical clustering method to  build the conceptual hierarchy based on the  low-level features of image objects. At the second phase, we devise a multi-level mining algorithm for  finding the image classification rules. The  classification task is performed at the last phase.

Empirical evaluations show that our approach  performs better than other approaches in terms of  classification accuracy.

1. Introduction  For the past few years, due to the popularity of  multimedia applications and Internet, the capacity of  data storage increases rapidly and more and more  digital multimedia datum related to our life are  produced. To handle the huge amount of multimedia  information, multimedia data retrieval has become an  emerging research issue. In order to solve the  problems of data retrieval, Content-Based Image  Retrieval (CBIR) became the focus of the research in  these years [6][7][12][14]. Based on the multimedia  features like Color, Texture and Shape, the systems,  such as QBIC [7] and VisualSeek [18], can  effectively classify, index and retrieve multimedia  data. Image classification is a very important issue in  supporting CBIR and various multimedia  applications. Through the effective classification  method, we can organize large amount of multimedia  data well. Furthermore, it can greatly help construct  the multimedia databases and improve the  performance of multimedia data mining.

One of the new techniques for image  classification is data mining. Basically, image  association rules are generated by analyzing their  properties, such as object analysis, image feature  extraction and training on classified images for  building the correct category model  [1][3][10][11][15]. In this way, the unclassified  images can be automatically classified by generated  association rules. For the past few years, there exist  many approaches concerning image classification,  but most of them focus on using image feature  extraction to find the classification rules by using  methods like SVM and Decision Tree [3][10]. In fact,  the semantics of a whole image can not be  represented by segmentation and low-level features  of an image only. From human viewpoint, taking  advantage of the hierarchical relationships among the  image objects is an effective way for image  classification.

For example, both of yellow dogs and black dogs  are considered as belonged to the dog category.

Furthermore, the pets category includes yellow dog,  black dog, yellow cat and white cat. The association  rules describing the hierarchical relationships among  the objects will help us classify the image in the way  closer to human?s viewpoint. In previous researches,  Hierarchical Association Rule Mining Method [9]  has been found useful for discovering the  associations among hierarchical objects in  applications like market basket analysis. In this paper,  we propose a new image classification method by  using multilevel association rules. Our method can  be decomposed into three phases:     1. Segment an image into several objects and  extract features from them, then automatically  construct a hierarchical feature tree of image  objects by hierarchical clustering.

2. Generate the generalized association rules from  those segmented objects by using multilevel  association rule mining methods. Here, we use  a method improved on CBA (Classification Based on Associations) [13] method.

3. Classify the newly input images automatically  through the generated association rules.

The remaining of this paper is organized as  follows. In section 2, we describe briefly the past  researches and related work. Section 3 describes the  proposed Multilevel Association Rule Mining-based  image classification method in details. Experimental  evaluation results are illustrated in Section 4. Finally,  the conclusions and future work are given in section  5.

2. Related Work  At the present days, most of the image retrieval  systems hunt the images by the queried text  information. There exist some problems in this kind  of image retrieval approach. For example, different  users making different text requisitions may want to  capture the same images in fact. That is to say, it is  difficult to make correct responses to the queries  requested from different kinds of users. Thus,  another way to deal with the image retrieval is to  adopt the features vector for indexing the images. It  is an interesting issue to search images on the basis  of the contents of images, namely CBIR  (Content-Base Image Retrieval). CBIR takes  advantage of the image features like color, shape,  texture and location to organize and index the images.

The representative systems include QBIC by IBM  [7], Virage system by Virage Inc., Photobook System  by MIT Media LAB, etc.

In [12], Li et al. utilizes 2-D HMM (Hidden  Markov Model) to perform the binary classification.

The 2-D HMM employs features of segmentations  and relationships of these segmentations such that  the constructed model can discriminate between  manual and natural segmentations in one picture. In  1988, Szummer et al. [16] proposed another binary  classification approach, called KNN (K-Nearest  Neighbor), to do the binary classification. It  segments an image into several objects and then  extracts features form them through the DCT  (Discrete Cosine Transform) and spatial coordinate  of color. The classification tree proposed by Huang  et al. [10] is used to produce the classification model for classifying the images. Carson et al. [4][5]  proposed efficient ways for representing a decision  tree in capturing the images. In their approach, the  images are divided into several objects, called blobs,  and every blob contains two features, namely color  and texture. By making use of the features, the  distance between any two blobs is computed in  constructing the decision tree. Aghbari et al. [1] exploits hill-climbing [15] and SVM (Support Vector  Machine) to segment a image into several objects  and perform the image classification by the four  vector features extracted from these objects, namely  color histogram, edge direction histogram,  higher-order autocorrelation edge vector and  dual-tree complex wavelet. Out of  multiple-concept-level data, several studies  [8][10][11] were also made in proposing Multi-level  Association Rule Mining method to discover the  implicit generalized association rules from concept  taxonomy. The goal of this approach is to perform  the top-down deepening search progressively and to  explore ?level-crossing? association relationships. In  general, the combination of content-based retrieval  and multi-level association mining discussed in this  paper presents a new approach for the better image  classification with higher prediction power.

3. The Proposed Method  The proposed method consists of two steps as  depicted in Figure 1:  1. Construction of Hierarchical Feature Trees: Construct each hierarchical feature tree in  terms of features like color, texture, and shape  extracted from the image objects.

2. Mining of Classification Rules:  Mine the association rules from the hierarchical  feature tree established in step 1 by using the  multi-level association rules mining method.

Thus, the class of new images can be predicted  by using the classification rules mined.

Figure 1. Workflow of the proposed method.

In conducting image-object-based multi-level  association rules mining, we need the hierarchical  tree of image objects. Therefore, we proposed a  method to construct the multiple levels tree. First, we  segment each image into several objects and extract  their features by some specific methods. Then,  we  construct a tree by using a hierarchical clustering  method improved on CURE method [8]. Then, we  find the Large Itemsets among the image objects by  using multi-level association mining method. At last,  the class of each large itemsets is generated to  produce the complete classification rules by using a  way similar to CBA [13]. For a new image to be  classified, the generated association rules are  deployed to determine the most relevant class for the  image efficiently and automatically.

3.1. Construction of Hierarchical Feature  Tree  The construction of hierarchical feature tree can  be divided into two steps:  1. Extract the objects and their features from the  images.

2. Construct the hierarchical feature tree by  performing hierarchical clustering.

3.1.1. Extraction of Image objects and Features  In our method, we need to analyze each image to  find the objects contained in it and extract three  features of each object, namely color, shape, and  texture. Since the issue of feature extraction is not  the focus in this work, we just adopted the public  software to achieve the goal of image objects  analysis and feature extraction. In this work, we use  the tool provided by Blobworld system  (http://elib.cs.berkeley.edu/photos/blobworld/) [4][5].

Blobworld is a CBIR (Content-Based Image  Retrieval) system developed by UC Berkeley Digital  Library Project. This system could automatically  segment an image into several objects, getting their  features and positions, and make use of the objects  for image query. The Blobworld system provides  both functions of image objects segmentation and  image query. In this research we only employ image  object segmentation and feature extraction in it. The  Blobworld system views similar regions of an image  as an object called blob, and the feature values of  each blob, like color, shape and texture are extracted  accordingly.

3.1.2. Hierarchical Feature Tree. After objects  segmentation and features extraction are done, we  need to construct a hierarchical feature tree for all  objects to support the mining of multi-level  association rules. However, it is difficult to construct  one single hierarchical objects tree for all images  with different features of an image object such as  color, shape, and texture considered simultaneously.

For example, suppose that there are three objects: a  yellow cat, a yellow dog, and a black dog. If we  classify them by color, yellow cat and yellow dog  should be of the same class, and black dog belongs to  another class. However, when shape feature is  considered, black dog and yellow dog should be of  the same class and yellow cat belongs to another  class. Hence, it is hard to construct a single  hierarchical objects tree for all these features.

Furthermore, each feature has its special meaning  and dimension so that the way to calculate the  distance between two features is different, too.

Hence, it is necessary to construct a hierarchical  feature tree for each feature and then map the image  objects on the hierarchical feature trees, as illustrated  in figure 2.

For each feature tree, we design an effective  clustering method based on CURE [8] to do the  hierarchical clustering. In CURE clustering method,  given a parameter k, each node is set to be a cluster and it combines two clusters with the shortest  distance into one. Then, the combination is repeated  until the cardinality of clusters is equal to k. However, there is a critical problem when it is applied for  constructing the hierarchical feature tree. That is, if  each node of the tree recorded by CURE clustering is  viewed as a cluster, it is meaningless for those  generated association rules. For example, if there are  twenty thousand objects, each feature may have  twenty thousand different values, such as twenty  thousand colors, twenty thousand shapes and twenty  thousand textures. Among these twenty thousand  different colors, there might exist two colors which  are very similar in terms of their values. Therefore,  the multi-level association mining does not work if  we exploit every different color to be a leaf node in  color hierarchical feature tree. Hence, we modify the  CURE clustering method in constructing each  hierarchical feature tree. The final k clusters are our  real needs and the intermediate hierarchical relation  of clustering is out of our consideration. That is to  say, what we need is just the hierarchical relation  between clusters.

Figure 2. An example hierarchical feature tree.

In order to solve the above problem, we do the  following modifications on the CURE method.

Given a parameter k, the initial process is performed  the same as CURE method until the cardinality of the  clusters is larger than k in constructing a hierarchical feature tree. Once the cardinality of the clusters is  equal to k, the representative nodes of all clusters are  recorded as leaf nodes in hierarchical feature tree. In  this way, there will be k leaf nodes in the tree. Then,  the hierarchical clustering process is repeated for  choosing the two closest clusters and combining  them to form one new cluster. The new cluster  becomes the parent node of two small old clusters,  and they are inserted into the hierarchical feature tree.

The complete algorithm for constructing the  hierarchical feature tree is as shown in Figure 3.

Figure 3. Algorithm for constructing hierarchical  feature tree.

3.2. Mining of Classification Rules  After the construction of hierarchical feature  tree, we employ the multi-level association mining  approach to generate the classification rules. This  procedure is decomposed into three steps:  Step 1. Map the image objects on the hierarchical  feature tree.

Step 2. Make use of the multi-dimensional  multi-level association mining method to  discover the classification rules.

Step 3.Classify and predict the new un-classified  images by the classification rules generated at  step 1.

3.2.1. Mapping image objects on hierarchical  feature tree  This step maps each image objects on the leaf nodes  of the hierarchical tree we constructed as data  pre-processing for hierarchical association rules  mining. Each node of every hierarchical feature tree  is first encoded using pre-constructed taxonomy and  each image objects is mapped onto the specific code  of leaf node in the hierarchical feature tree. After  mapping, each image can be viewed as an image  transaction. As shown in Table 1, image 1 contains  three objects, namely A, B and C, and the mapping  result is as shown in Table 2. The three hierarchical  feature trees are constructed as depicted in Figure 2  Table 1. The image transaction table  Image Object  Image 1  ObjectA (color3-1, shape3-2, texture3-4),  ObjectB (color3-1, shape3-2, texture3-1),  ObjectC (color3-2, shape3-2, texture3-3)  Table 2. Mapping result  Image Object  Image I ObjectA(11,21,21), ObjectB(11,12,11),  ObjectC(12,12,21)  3.2.2. Multi-dimensional Multi-level Association  Mining for Classification Rules  The process of mining classification rules can be  divided into two steps:  Step 1. Generation of large itemsets: discover all  large itemsets that exceed the specified  support threshold using multi-dimension  multi-level association mining method.

Step 2. Construction of classification rules: generate  the association rules viewed as classification  rules by improved CBA method from the  discovered large itemsets.

In step 1, it is on the basis of the two-dimensional  multi-level association mining [20] and we expand it  to the multi-dimensional multi-level association  mining. The cardinality of its dimensions is decided  by the cardinality of extracted features. In this paper,  we primarily extracted three features, namely color,  shape and texture. That is, we adopted  three-dimensional multi-level association mining to  generate the large itemsets. The complete algorithm  is illustrated in Figure 4.

In this algorithm, the function gen_candidate(k) is  used to generate the candidate k-itemsets, which  contain k items. When k is equal to 1, that function  will generate all candidate 1-itemsets by calculating  the bottom level features of three trees (Tt.level,  Tc.level, Ts.level). Otherwise, the candidate  k-itemsets is generated from the large (k-1)-itemsets.

Function com_Large(k) utilizes candidate  (k-1)-itemsets to discover large k-itemsets, whose  supports are larger than minimum support set by  users.

Figure 4. Multi-dimension multi-level association  rule mining algorithm.

After the generation of all large itemsets is done,  the probability of belonging to the specific class for  every large itemset is calculated by using a  CBA-based method. Through the probability  reasoning, the construction of classification rules is  then generated. That is, each large itemset constitutes  a classification rule. For example, suppose a large  itemset A is composed of (221, 222, 1212) and  (122,111, 2212), that is, this is a large 2-itemsets  {(221, 222, 1212), (122 ,111, 2212)}. Among ten  classified images containing this pattern, six belong  to Animal class, two belong to Plant class and the  other two belong to Scenic class. Consequently, the  probability of class membership for the large itemset  A is depicted in Table 3.

Table 3. The probability of large itemset A  Large Itemset Support Class Prob.

Animal 0.6  Plant 0.2 {(221,222,1212),  (122,111,2212)}  Scenic 0.2  3.2.3. Classification of New Images  In this section, we describe how to classify and  predict unclassified images automatically by using  the classification rules obtained through the  multi-dimensional multi-level association rules  mining. First of all, we segment an unknown image  into several objects and extracted their feature values  by Blobworld system. Next, we map them on the  hierarchical feature tree constructed and then the  classification rules are searched for matching the  unknown image. Because the length of large itemset  and the support value are both critical factors for the  probability of classification rules, the length, support  and every class probability of the large itemset are  multiplied together to find the most possible class  that image should belong to.

As an example, for a simple instance, suppose the  unclassified image has the large itemsets as shown in  Table 4.

Table 4. Large itemsets of an unclassified image.

Large Itemset Support Class Prob.

Animal 0.30  Plant 0.125  {(221,222,1212),  (122,111,2212),  (111,121,1121)}   Scenic 0.57  Animal 0.28  Plant 0.05 {(212,221,12),  (122,111,22)}  Food 0.66  According to our method described previously,  the probability that image belongs to different classes  is as follows.

1. Animal Class:  P(Animal Class) = (3*20*0.3) + (2*50*0.28) = 46.6  2. Plant Class:  P(Plant Class) = (3*20*0.125) + (2*50*0.05)  = 12.7  3. Scenic Class:  P(Scenic Class) = 3*20*0.57 = 34.2  4. Food Class:  P(Food Class) = 2*50*0.66 = 66  Consequently, we determine that the image  belongs to food class because it bears the highest  probability. Therefore, the image is classified into the  Food class.

4. Experimental Evaluation  We have described the new approach for image  classification we proposed in the previous section.

Now we describe the results in evaluating the  performance of proposed method by experiments  using real image data. We have also tuned the  minimum support in multilevel association rules, k  value in the clustering and the cardinality of image  objects and extracted features. Through tuning these  parameters, the proposed method was compared with  general decision tree method (J48) and SVM. The  experiments were implemented in C++ on a     Pentium-4 1.6GHz personal computer with 256 MB  RAM running on Windows 2000 Server.

4.1. Experimental Data  The image data in our experiments are from Corel  Gallery Professional Image Library, which contain  several types of images including signs, backgrounds,  icons and so on. We choose ten thousand images  from one million images as datasets for our  experiments. We choose the images with classes as  shown in Table 5 from Corel Gallery image library  manually and the size of each image is 192*128 or  128*192.

For the performance index, we defined two  measures, the Precision and Coverage for the classification tasks. The definitions of Precision and  Coverage are illustrated as follows:  agesedicted  CorrectC ecision  ImPr  _ Pr  agesTested  agesedicted Coverage  Im  ImPr  Precision represents the ratio of the cardinality for  correctly classified images to the cardinality of  classified images. Coverage indicates anther ratio for the cardinality of classified images to the cardinality  of all tested images. For example, given ten tested  images, if eight images are successfully predicted  and five images are correctly classified from the  eight predicted images, the Precision is 5/8 = 62.5%  and the Coverage is 8/10 = 80%.

4.2. Experimental Results  In the first experiment, we evaluate the number  of rules and classification precision under different  minimum support setting in our proposed  multi-dimensional multi-level association mining  method. We varied the minimum support from 0.001  to 0.05 and observed the variation of quantity of  mined rules and the precision measure for image  classification. As shown in figure 5, nearly 6,000  classification rules are generated when the minimum  support is 0.005 and the quantity of the classification  rules raises to nearly 40,000 when the minimum  support is 0.001. However, when the minimum  support is smaller than 0.05, the number of produced  classification rules is less than 100. Compared with  figure 6, when the minimum support is 0.001, the  classification precision is close to 55%. Though the classification rules are much less than 40,000 as the  minimum support setting is 0.005, its classification  precision is maintained at nearly 50%. When  minimum support is raised to 0.05, the mined  classification rules are extremely few. Hence, the  classification precision degrades to nearly 10%.

As shown in figure 7, when the minimum support  is less than 0.005, the classification coverage is as  good as 100%. This is because that most images will  be covered by the classification rules generated by  the mining algorithm when higher-level  classification rules are produced. Notice that the  coverage is still close to 90% even when the  minimum support is raised to 0.05.

Table 5. The image classes in experiments.

Image Class Number Descriptor  Animal 1900 dog, bird, and  fish, etc.

Transportation 1200 Car, airplane,  and boat,  etc.

Structure 1700 Building  People 1500 All kinds people  Plant 1100 Tree and flower,  etc.

Scenic 900 Mountain, cloud,  and sea etc.

Food 600 All kinds food  Insect 300 All kinds insect  Artifact 800 All kinds of  artifacts  Besides, we process our experimental data by  another feature extraction program, namely the XM  software provided by MPEG-7 official website  (http://www.lis.e-technik.tu-muenchen.de/research/b  v/topics/mmdb/e_mpeg7.html). This program does  not perform the image object segmentation, so the  feature values are extracted from the whole image  directly. We utilized six features and submitted them  to the Decision Tree and SVM modules for  classifications. These six features are ColorStructure,  ColorLayout, RegionShape, ScalableColor,  Homogeneous and EdgeHistogram. The Decision  Tree used here is J48, which is included in WEKA  based on C4.5 decision algorithm. Finally, we  compare the performance results with the proposed  multilevel association mining method with minimum  support set as 0.002.

Figure 5.  Number of Patterns under different  minimum support settings.

Figure 6. Precision at different support values.

Figure 7. Coverage at different minimum support  settings.

Figure 8 illustrates the precisions of the proposed  method, J48 and SVM. Obviously, the proposed  method delivers higher precision than J48 and SVM when the feature leaf nodes are more than 50, with  improvement rate around 15%. A noteworthy point is  that only three image features, namely color, shape,  and texture, are used in our method although more  features can be absorbed in our method. Hence, it is  expectable that our method can deliver even higher  accuracy in classification if more kinds of image  features are incorporated.

Figure 8. Comparisons of Precision.

5. Conclusions and Future Work  In this paper, we have proposed a new method  to construct the image classification rules by using  the hierarchical association relations among the  image objects. The experimental results show that  the proposed method outperforms other classification  methods like C4.5 and SVM in terms of  classification accuracy even though only three kinds  of image features are considered. The main  techniques for the proposed method are as follows.

1. Construction of Hierarchical Feature Tree:  Construct the hierarchical structure of objects  based on the extracted low-level features  (Color, Texture and Shape) by conducting  multilevel clustering on image objects.

2. Mining of Classification Rules:  By utilizing the hierarchical features tree  constructed, we devise a multi-dimensional  multi-level association mining method to find  the large itemsets. Furthermore, a CBA ?based  method is designed to predict the class for new  images.

In the future, we will explore the following issues  from the viewpoint of data mining:  1. In extraction of image object features, we will  consider more feature vectors to achieve more  rich multi-dimensional multi-level association  mining so as to increase classification  precision further.

2. The task of object segmentation in Blobworld  system leaves room for improvement. We shall  integrate other more effective methods for  improving further the accuracy. Therefore, we  can increase classification precision by  complete objects segmentation.

3. Since the proposed multi-dimensional  multi-level association mining method is based  on Apriori [2], it incurs high execution cost. We  will do further enhancement on the algorithm  improve the execution performance.

ACKNOWLEDGEMENT  This research was supported by Ministry of  Economic Affairs, R.O.C., under grant no.

92-EC-17-A-02-51-024.

