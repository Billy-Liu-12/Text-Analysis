Automatic Extraction of Fuzzy Domain Ontology Concepts

Abstract ? We present an Automatic Ontology Concepts Extractor (AOCE) for ontology construction. The AOCE extracts concept knowledge from the movie domain articles.

Two algorithms 1) the Hundred Surname Artist extraction algorithm and 2) Custom Distance Function with the Fuzzy Genetic Expert System are adopted for the extraction process.

Experimental results are promising that the system can reduce human efforts for extracting concepts and knowledge from similar articles in a specific domain. The proposed methodology demonstrates the potentials of automatic ontology construction and creation, which are the big incentive for further research.

Keywords-domain ontology;  fuzzy;  automatic extraction

I.       INTRODUCTION The major bottleneck in information processing is the  lack of an effective automated solution to transform data into meaningful information or knowledge. Although the semantic web becomes popular, such as Google YouTube, the application of the ontology concept using relation tagging by users, and corresponding staff administration of the website, still it involves a large amount of human resources. For example, the IMDB movie management site, and Wikipedia website, they both want to discover the knowledge and allow their clients to search for the information across the knowledge. However, to achieve this goal, they must face a big challenge which is how to tag and link up those concepts. The Tagging process costs many of expertise efforts and takes long time. Facing with the information growth at an exponential speed, human tagging is not a possible solution.

Ontology is a specification of a conceptualization which is used to describe the objects and the relations between them in a domain [1]. Also, ontology defines a set of representational primitives with which to model a domain of knowledge or discourse [2]. Accordingly, ontology enables advanced functionality in knowledge management systems and forms the knowledge base for future innovations. For examples, it can be used for developing the intelligent search engine, content management system like Wikipedia etc. Those reasons let us have the utmost incentive to develop the autonomic solution for extracting ontology concepts from fuzzy problem domain.

This paper is organized as follows. In Section 2, we show the algorithm of AOCE and ontology construction. In  Section 3, we present the implementation details. In Section 4, we show the experiment result. Conclusions are drawn in Section 5.



II.      RELATED WORK There are currently no fully automatic approaches to the  construction of domain ontologies although there are a number of semi-automatic approaches. Text-To-Onto [3] constructs and maintains an ontology using data mining and natural language processing techniques. It extracts concepts with a concept association extraction algorithm and can reduce and simplify the ontology construction process but does involve a number of manual processes. Text2Onto [4] is a refined version of Text-To-Onto. It utilizes a probabilistic ontology model and a data-driven change discovery strategy to extract the concepts and form the initial relationships without the relationship tag. This can quicken the extraction and association of concepts.

Ontolearn [5] which adopts a structural semantic interconnections knowledge-based disambiguation algorithm automatically extracts domain terms from online corpora, documents, and glossaries which are interpreted and arranged in a hierarchy. It uses pattern matching to select between alternative concepts, e.g. it tries to match up the unknown concepts with the corpus.

OntoLT [6] is a plugin for Prot?g? which learns ontologies based on linguistic analysis and statistical methods. It employs rules for mapping between linguistic structures and ontological knowledge. Mo?K [7] is a configurable workbench that can be used for ontology building. It takes parsed corpora as the input and uses conceptual clustering methods. ASIUM [8] is a machine learning system which uses an unsupervised conceptual clustering method for learning semantic knowledge. It quickens the process for developing an information extraction system. DODDLE II [9] is an enhanced version of a domain ontology rapid development environment based on the machine-readable dictionary, WordNet. The system is able to acquire conceptual relationships from domain- specific texts by match result analysis and trimmed result analysis. Lately, [10] developed fuzzy ontology map that can support fuzzy searching and personalization functions for users such as book recommendation and information filtering. While all of these approaches offer various kinds of improvements to ontology construction, none is fully automatic.

DOI 10.1109/FSKD.2009.666    DOI 10.1109/FSKD.2009.666

III.      AOCE ARCHITECTURE We propose Automatic Ontology Concepts Extractor  (AOCE) as shown in Figure 1, an ontology construction algorithm that replaces the manually tagging of concepts, and assists in automating ontology construction.  After filtering unrelated concepts, the related concepts are then fed to Fuzzy Genetic Expert System for constructing the ontology tree. AOCE adopts the Hundred Surname Artist extraction algorithm and the Custom Distance Function with the Fuzzy Genetic Expert System for extracting concept knowledge from movie domain websites. In addition, we collect Chinese articles for the analysis.

The development of AOCE involves the preparation of domain data and four major parts in support of ontology extraction from the movie archive. Figure 2 shows the workflow of ontology construction. A brief discussion of the associated processes is given below.

A. Data Preprocessing We collected 52 articles (in Chinese) from a magazine,  City Entertainment Bi-Weekly [11], which are related to five different movies, Initial D, Battle Of Wits, Confessions Of Pain, Isabella, and Infernal Affairs. Table I shows the number of articles collected per each movie. The articles need to be preprocessed by the system, segmented to form as either an article-based dataset or a sentence-based dataset.

An article-based dataset retains its original format. A sentence-based dataset is stored as sentences, using the HowNet Dictionary [12] which provides an on-line Chinese- English bilingual lexical ontology that describes semantic relationships between concepts and the relationships between the attributes of concepts. It covers over 65,000 concepts in Chinese, equivalent to about 75,000 concepts in  English. HowNet has defined over 110,000 robust concepts [13]. The segmented element should be a noun or something  unknown which is not defined by the HowNet.

HowNet  Dictionary  1.1 Segmentation Process  1.2 Movie Conception Extraction Process  1.3 Artist Concept Extraction Process  1.4 Fuzzy Key Concept Generator (Distance Function Apply)  1.5 Initial Concepts Extractor  2.1 Fuzzy Transaction Format Process  2.1.1 Formation  Method  2.1.2 Article Based Transaction  Forming Process  2.1.3 Sentence Based Transaction Forming Process  2.1.4 Sentence  Based Transaction Forming Process with TF-IDF  4.1 Apriori Algorithm with Fuzzy Transaction Data Set  Data Mining Server  Concept Extraction System (with Distance Function)  City Entertainment Movie Articles  Artist Movie Database  1.6 Concept Monitor  Knowledge Monitor  Ontology Forming Server & CMS Server  3 Model Training Model Testing  1. Concept Extraction System  2. Transaction Forming System  3. Data Mining System --Apriori  3. Fuzzy Expert System (Fuzzy with GA)Provide Model  Provide Model  Figure 1.     AOCE Architecture    Movie Articles Automatic Concept Extractor  Extracted Concepts  Custom Distance Function  Fuzzy Expert System  Adjust Distance Function  Model of the sim ilarityOntology Buildling  Ontology  NO  YES   Figure 2.   Workflow of ontology construction in AOCE  TABLE I.    SAMPLE ARTICLES  Movie Name Number of Articles In Chinese In English  ??? D Initial D 12 ?? Battle Of Wits 12 ?? Confessions Of Pain 10  ???? Isabella 9 ??? Infernal Affairs 9  Total: 52  B. AOCE Functional Components 1) Concept Extraction: We extract concepts from the  articles using linguistic resources. Typically, for the extraction of artist?s names, we have come up with an algorithm based on the information about Hundred Family Surnames [14]. We collected 444 surnames which have one Chinese character and 60 surnames with double Chinese characters. Table II gives the details of the algorithm.

TABLE II.    ARTIST EXTRACTION  Algorithm ArtistExtractor(c) Input: A String c Output: An list of all nameList without repetitions 1 Segmentation the article 2 Check surnames dictionary 3 If  token in surnames dictionary then  3.1 Token + 1 strings followed with token 3.2 Token + 2 strings followed with token 3.3 Token + 3 strings followed with token  4 Check with Artist Database 5 Calculate the frequency count distribution and using  the mean value for the threshold.

6 Evaluate and tune the threshold.

The Fuzzy Key Concept Generator helps to extract key  concepts. The filter engine is based on the trained model from the Fuzzy Expert System with Custom Distance Function. The extracted key concepts will then form the Ontology relation by using Apriori algorithm (e.g. [15]).

The Custom Distance (CD) function is used for measuring the words distribution in the articles. Eq. (1) is used for computing the CD value. The CD value will then be used to form the fuzzy model for extracting the important concepts.

? ? ?= ? ? ?  ?  ?  ? ?  ? ?   ))(( /)(  Max CD                     (1)  where ? is the number of articles which contain the keyword, ?  is the article number, ?  is the sentence number which has the keyword in the article, ? is the total number of sentences in the article.

2) Transaction Forming: The Fuzzy Custom Distance Function is used to filter the key concepts. User needs to specify which format transaction for performing Apriori data mining and extracting the relationships. There are two format transactions: Article-based and Sentence based.

Article based transaction works on the concept keys and gets the appearance number on each article. Each article contains all of the concept keys and appearance numbers.

The number of the appearance of the key concept in the particular article will form one transaction. We first extract the key concepts from article, then use the Custom Distance Function with fuzzy model to filter the useless concepts and build the transaction. User can choose the TF-IDF (term frequency ? inverse document frequency) [16] mode or non TF-IDF mode. The TF-IDF mode transaction uses importance weight for the value of the filtered key concepts.

On the other hand, it will use the number of appearances for the value of the element. It makes use of statistical technique to evaluate how important a term is to a document. The importance increases proportionally to the number of times a word appears in the document but is offset by how common the word is in all of the documents in the document collection.TF-IDF is often used by search engines to find the most relevant documents to a user?s query.

Sentence based transaction requires each transaction to include all of the concept keys. And the appearances  number of each element in the sentence will be recorded in the transaction. The system provides the TF-IDF mode and Appearance rate mode to form the sentence base transaction.

3) Fuzzy Expert System. Zadeh [17] says that rather than regarding fuzzy theory as a single theory, we should regard the process of ``fuzzification'' as a methodology to generalize ANY specific theory from a crisp (discrete) to a continuous (fuzzy) form. Thus recently researchers have also introduced "fuzzy calculus", "fuzzy differential equations". Our system involves fuzzy rules typically for information searching. Therefore, the antecedent of these rules will be a logic expression relating a set of fuzzy variables. The fuzzy variable is defined by the name of physical variable and a qualifier. We also incorporate with a trained Genetic Algorithm (GA) to help adjust the linguistic valuables. We apply fuzzy set and rules to adjust the distance function. The distance and the frequency count can be fuzzified by using the custom distance function discussed earlier.

For the GA encoding, we use 32 bits (4 x 8 bits) to represent a linguistic variable such as LOW, MED or HIGH.

For the rule set, given a particular rule number, the corresponding antecedent combination will be encoded and appended to the chromosome with  bits. This antecedent combination will be passed on to GA Model which in turn randomize the part of all the rules to 0 or 1 (related to the movie article / not related to the movie article).

For the GA decoding, the genes representing the linguistic variables (represented by four vertices) of each of the attributes are decoded based on a decimal integer, and  then multiplied by 12  8 ?  since the range of attributes is from 0 to 1. The decoded values of the new chromosome will be passed through a fitness function to measure its performance in each generation.

4) Data Mining: After we the selection of the transaction record, the Apriori algorithm is applied for mining the relation of the key concepts. The system can use the extracted information to form the upper ontology. The upper-level ontology is an ontology that can provide a set of generic concepts which can be shared and reused by different users. It describes the general concepts across different domains. To model this upper-level movie ontology, we have collected and analyzed a large number of movie guides and related magazines. We make use of the modeled ontology to further develop a movie guiding prototype system.



IV.      EXPERIMENTAL RESULTS AND ANALYSIS A prototype system is developed for training and  learning the Movie Ontology. The system was developed by using Java J2SDK 1.6.0.4. We adopted HowNet for segmentation process. The movie and artist database were stored in the MySQL 5.0 database servers. It contains 3956 movies information and 11493 artist details. The AOCE uses the OWL to generate the ontology tree for concept extraction.

A fuzzy model is required at the initial step of the system development. The model was trained by using three sets of articles. Two attributes are used to describe the articles, and each attribute has three linguistic valuables.

The attribute 1 is ?Appearance Rate? which has three linguistic valuables: Low, Middle, High. The attribute 2 is ?Distance? which has three linguistic valuables: Top, Middle, Bottom. The threshold of the fuzzy model is set as 0.73. Then, we used 3 other sets of non-related movie articles for training. The experiments include 5 cases and each case will be tested with 2 different transactions (Article base and Sentences base).

Table III shows that the precision of related movie extraction on average is 96.18%. In particularly, in the Battle of Wits, the Precision is 100%; however the Infernal Affairs just gives 90.91%, probably due to some typo errors in the article. The application of the Hundred Family Surnames algorithm leads to an average precision of 90.36% (see Table IV)  TABLE III.     RESULTS FOR RELATED MOVIE EXTRACTION  Movie Name  No. of Movie  Concepts (MC)  No. of Correct Movie  Concepts (MCC)  Prec. %  Initial D 39 38 97.44 Battle Of Wits 27 27 100.00  Confessions Of Pain 50 48 96.00 Isabella 29 28 96.55  Infernal Affairs 33 30 90.91 Average 96.18    TABLE  IV.     RESULTS FOR ARTIST EXTRACTION  Movie Name MC MCC  Fitness % Initial D 22 20 90.91  Battle Of Wits 20 17 85.00 Confessions Of Pain 28 27 96.43  Isabella 19 17 89.47 Infernal Affairs 34 30 90.01  Average 90.36   TABLE V.    RESULTS FOR KEY CONCEPTS EXTRACTION  Movie Name MC  MCC Prec. % Initial D 155 126 81.29  Battle Of Wits 244 223 91.39 Confessions Of Pain 151 121 80.13  Isabella 97 77 79.38 Infernal Affairs 190 172 90.53  Average 84.54   The fuzzy model was trained by using 2 sets of the movie data. The system randomly chooses 70% of data for training and 30% for testing and the fitness of the model is 72.36%. Table 5 shows the average fitness of extraction being 84.54% based on the advice of City Entertainment staff. Table VI shows that the Apriori mining algorithm can extract the correct relation with high precision in article  based transaction. However, it requires the adoption a low minimum support (S) value in sentence based transaction (see Table VII). Moreover, the concept was drilled down more deeply to let the extractor extract a more detailed relationship.

TABLE VI.   RELATION EXTRACTION PER ARTICLE BASED TRANSACTION (MINIMUM SUPPORT: 80%)  Movie Name No. of Relations R  No. of Correct  Relations CR Prec. %  Initial D 478 452 94.56 Battle Of Wits 216 195 90.28  Confessions Of Pain 96 88 91.67 Isabella 42 41 97.62  Infernal Affairs 205 191 93.17 Average 93.46    TABLE VII.    RELATION EXTRACTION PER SENTENCE BASED TRANSACTION  Movie Name R CR Prec. % Min. S.

Initial D 46 42 91.30 8.81%  Battle Of Wits 45 38 84.44 9.82% Confessions Of Pain 45 40 88.89 11.98%  Isabella 60 58 96.67 8.94% Infernal Affairs 90 82 91.11 5.57%  Average 90.48 9.02%

V.   CONCLUSION The proposed prototype system gives promising results  and can reduce human efforts to extract the concepts and knowledge from the similar articles in movie domain. It demonstrates the potentials of automatic construction of ontology concepts in fuzzy domain of interest. Future work shall be to exploit the integration of the ontology extractor with some Ontology Translation engine which could automatically translate the relation knowledge from the system extraction to form an upper ontology. The ontology can then collaborate with the content management system and search engine for further application including the checking of correct and consistent ontology construct.

