Sampling Adaptively using the Massart Inequality for Scalable Learning

Abstract?With the advent of the "big data" era, the data mining community is facing an increasingly critical problem of developing scalable algorithms capable of mining knowledge from massive amount of data. This paper develops a sampling- based method to address the issue of scalability. We show how to utilize the new, adaptive sampling method in [4] to develop a scalable learning algorithm by boosting, an ensemble learning method. We present experimental results using bench- mark data sets from the UC-Irvine ML data repository that confirm the much improved efficiency and thus scalability, and competitive prediction accuracy of the new adaptive boosting method, in comparison with existing approaches.

Key Words: Scalable Learning, Ensemble Learning, Adaptive Sampling, Sample Size, Boosting

I. INTRODUCTION  Data mining and machine learning techniques have found increasingly more successful applications to a wide range of real world problems involving huge amount of data.

Such data are often characterized as heterogeneous, dynamic and noisy in nature and extremely large in volume. The success of data mining applications depends critically on the development of scalable learning and knowledge discovery algorithms because the sheer size of data in many real world scenarios renders the traditional data mining methods impractical. We believe that sampling techniques can make important contributions to scalable learning and knowledge discovery. Therefore it is desirable to study smart sampling methods and apply such methods to build scalable learning algorithms. This paper is motivated from such a perspective.

Statisticians have studied extensively sampling techniques  and parametric estimation problems. There is a vast literature in statistics on this topic. In machine learning, researchers use sampling to estimate the accuracy of learned classifiers or to estimate features characteristic of vast amount of data.

Random sampling is an important technique widely used in statistical analysis, computer science, machine learning and knowledge discovery.

A key issue in designing a sampling scheme is to  determine sample size, the number of sampled instances sufficient to assure the estimation accuracy and confidence.

Well-known theoretical bounds such as the Chernoff bound and Hoeffding bound are commonly used for this purpose.

Sample size could be determined a priori as in conventional batch sampling, or it could be dynamically determined as in adaptive, sequential sampling. As recent studies [6], [16] pointed out, there are situations in which using Cher- noff/Hoeffding bounds in "static" (non-adaptive) sampling would require a sample size that is unnecessarily large.

In contrast, adaptive sampling decides whether it has seen sufficient samples based on some criterion related to the samples seen so far. This adaptive nature of sequential sampling method is attractive from both computational and practical perspectives. Earlier works in Computer Science on adaptive sampling include the methods in [11], [12], [13] for estimating the size of a database query. Adaptive sampling is also closely related to active learning[1].

In recent works on Madaboost [7], [8], [15], [16], Watan-  abe et. al. proposed techniques for adaptive sampling and applied the methods to boosting, an ensemble learning method. These works illustrated that adaptive sampling techniques can make important contributions to speed up and scale up ensemble learning, which typically requires much computation because of the need to construct the ensemble with many classifiers.

In a recent work [5], a new adaptive sequential sampling  method based on adaptive application of the Chernoff bound was developed that can handle cases of controlling absolute error and relative error. Empirical results were shown in [5] indicating that the new sampling method uses signifi- cantly lower sample size compared to the method in [16].

We have further applied the adaptive sampling method to develop efficient ensemble learning method by boosting [3].

Experimental results confirm that our proposed adaptive boosting method is much more efficient while maintaining competitive prediction accuracy in comparison with [16].

In the same spirit as the work in [5], we proposed  recently in [4] a new adaptive sampling method based on the Massart?s inequality [14]. We also briefly described in [4] a sketch on how to apply the sampling method to construct an adaptive boosting learner. This current paper presents a more detailed description of the adaptive boosting learner and reports our experimental results using UC Irvine benchmark data sets. The results show that the new adaptive boosting learner with Massart?s inequality achieves competitive pre-   DOI 10.1109/ICMLA.2013.149    DOI 10.1109/ICMLA.2013.149    DOI 10.1109/ICMLA.2013.149    DOI 10.1109/ICMLA.2013.149     diction accuracy and is much more efficient than that in [16]. The adaptive boosting learning algorithm by Massart?s inequality behaves in a similar way to the adaptive boosting learning algorithm based on the Chernoff bound in [3]. In fact, the new algorithm is slightly more efficient than the boosting learner in [3] as our experimental results show (Section V).



II. BACKGROUND The basic sampling problem addressed in this paper is to  estimate the probability p = Pr{X = 1} for a Bernoulli variable X . To estimate the probability, we draw i.i.d.

samples X1, X2, ? ? ? of X and use the relative frequency p? n as an estimator for p. Here p?  n =  P n  i=1 Xi  n , and n is the  number of samples at the termination of the sampling. The frequently-used Chernoff-Hoeffding bound asserts that, for a priori margin of absolute error ? ? (0, 1) and confidence parameter ? ? (0, 1), the coverage probability Pr{|p?  n ?p| <  ?} is greater than 1 ? ? for any p ? (0, 1) provided that n >  ln 2 ?  2?2 . Here ? and ? are called accuracy level parameter  and confidence level parameter respectively. The Chernoff- Hoeffding bound significantly improves upon the Bernoulli bound which states that Pr{|p?  n ? p| < ?} > 1 ? ? if  n > 1 4?2?  . Clearly, the coverage probability tends to 1 as n tends to infinity.

Chernoff-Hoeffding bounds have been used extensively  in statistical sampling and Machine Learning. We seek in this research adaptive sampling schemes that allow us to achieve the goal of low sample size requirements without losing accuracy and confidence. Then we want to use such sampling schemes for better efficiency and scalability in ensemble learning.

Problem 1 - absolute error  We want to design an adaptive sampling scheme (stopping rule) such that for any pre-specified ? ? (0, 1), ? ? (0, 1) and any p ? (0, 1) we have  Pr{|p?n ? p| ? ?} ? ?  when sampling is terminated after seeing n samples.

Problem 2 - relative error  We want to design an adaptive sampling scheme such that for any pre-specified ? ? (0, 1), ? ? (0, 1) and any p ? (0, 1) we have  Pr  {???? p?n ? pp ???? ? ?} ? ?  when sampling is terminated after seeing n samples.



III. REVIEW OF THE ADAPTIVE SAMPLING METHOD PROPOSED IN [4]  In this section we give a brief description of the sampling method presented in [4]. Let us define the functionUM (z, ?) which will be useful for defining the sampling scheme.

Here the subscript "M" in the function name UM stands for "Massart".

UM (z, ?) =  (  (z??)2  (z+2?)(z+2??3) z ? [0, 1], ? ? (0, 1)  ?? z ? [0, 1], ? /? (0, 1)  Associated with the function UM we have the following Massart inqaulity: Lemma 1: Let p = E[X ] be the expected value of the  Bernoulli variable X . Let p?n be the relative frequency of successes in n Bernoulli trials. Then for any 0 < z ? p, we have Pr{p?n < z|p} < enUM (z,p). For any p < z ? 1, we have Pr{p?n > z|p} < enUM (z,p).

A. Controlling Absolute Error Let 0 < ? < 1, 0 < ? < 1. The sampling algorithm  ABSM in [4] for controlling absolute error proceeds by drawing samples one by one until the test condition below is satisfied:  n ? 2 ln 2?  ?2 [1/4 ? (|p?n ? 1/2| ?   ?)2] (1)  Here p?n is the relative frequency of successes (of the Bernoulli trials) and n is the number of samples seen so far.

The following theorem summarizes the analysis about the  sampling algorithm ABSM for controlling absolute error with the above criterion condition (1).

Theorem 1: Let n0 =  max{? ln ?   UM (p+?, p+2?) ?, ?  ln ?  UM (p??,p?2?) ?}. Assume that  the true probability p to be estimated satisfies p ? 12 ? 2?.

Then with probability of at least 1? ?2 , the sampling scheme with criterion function (1) will stop with n ? n0 samples and produce p?n which satisfies p?n ? p + ?. Similarly, if p ? 1  2 + 2?, then with probability of at least 1 ? ? 2 , the  sampling algorithm will stop with n ? n0 samples and produce p?n which satisfies p?n ? p? ?.

B. Controlling Relative Error Given 0 < ? < 1, 0 < ? < 1, the sampling algorithm  RELM in [4] for solving problem 2 proceeds by drawing samples until the following criterion is satisfied:  p?n > 0 and n ? ln ?2  UM (p?n, cpn  1+?) (2)  The following theoretical result was presented in [4]: Theorem 2: Let p be the true probability to be estimated.

Let n1 = ?  ln 2 ?  |UM (p(1? ?), p(1??) 1+?  )| ?.

With probability of at least 1? ?2 , the sampling method using criterion function (2) will stop with n ? n1 and produce p?n ? p(1? ?).



IV. A SCALABLE BOOSTING LEARNER BY ADAPTIVE SAMPLING  In this section we briefly outline how to use the new sampling method in [4] to construct an efficient boosting learning algorithm.

Boosting is an ensemble learning method that proceeds by  constructing a sequence of hypotheses (classifiers) h1, h2, ..., hT (T > 1) in an iterative manner such that the weighted combination of the hypotheses in the ensemble produces a strong classifier with high classification accuracy. Boosting could be done using the entire dataset, or it could be done via sampling (as the Madaboost method in [7], see below).

The well-known Adaboost method [9], which is based on the entire dataset, proceeds as follows. The algorithm is given a fixed data set D, and a probability distribution D(1) over the data set D, which is typically assumed to be uniform. Then at each boosting round 1 ? t ? T , Adaboost will generate a hypothesis ht which has minimal classifica- tion error over D according to the probability distribution D(t). Namely, ht is the hypothesis minimizing the measure errorD (ht) = ?x?D ? ht(x) ?=c(x)D(x), where c(x) denotes the correct classification of instance x. A positive weight ?t is assigned to ht which is proportional to its (weighted w.r.t.

Dt) classification accuracy on D. Moreover the distribution D(t) is updated to generateD(t+1) such that the data points misclassified by ht would have their weights (probabilities) increased while the weights on other data points decreased.

Watanabe [7], [8] proposed the Madaboost approach for  learning by boosting based on the idea of adaptive sampling.

The Madaboost method avoids using all data points inD and handling the distributions D(t) explicitly in selecting ht.

The idea is to use sampling on D (according to distribution D(t)) to construct ht from a subset of training data St from D. A stopping condition that adaptively determines the sample size for St was proposed, and theoretical analysis and experimental results were presented in [7] showing that Madaboost can generate classifiers with comparable accuracies and better efficiency.

We show that our adaptive sampling method in [4] could  be readily applied to construct a new boosting algorithm.

Moreover we present empirical study results (next section) indicating that our adaptive boosting learner uses much smaller sample size compared with Madaboost while main- taining competitive prediction accuracy.

The new boosting algorithm is constructed by adapting the  criterion function (Equation (1)) for estimating the mean of a Bernoulli variable for the task of estimating the prediction accuracy of a hypothesis in each boosting round.

For simplicity of the discussion, let us consider a fixed  t value for the boosting round and thus fix the distribution D(t) = D . For this distribution D , each hypothesis h ? H defines a Bernoulli random variable Vh such that Vh = 1 if h(x) = c(x), and Vh = 0 otherwise, where each  object x is drawn from D according to the distribution D , and h(x) is the classification of x by the hypothesis h, c(x) is the true classification. Namely, Pr{Vh = 1} = ?x?S ? h(x)=c(x)D(x). Put Ph = Pr{Vh = 1}. So Ph is the prediction accuracy of h (according to distribution D). The true error of h (w.r.t. distribution D) denoted by errorD (h), is defined as 1 ? Ph. Here we try to estimate Ph from a sample S of all training data D via adaptive sampling.

When sampling is used to estimate the accuracy (Ph)  of each hypothesis h, we will draw random samples x1, x2, ..., xn, ... from D and thus observe values for the random variable Vh as Vh1, Vh2, ..., Vhn, .... The estimated value of Ph after seeing a set S of samples is Ph,S = |{x?S: h(x) = c(x)}|  |S| . How do we determine, a "reasonable" sample size |S| sufficient to guarantee with high confidence that the estimated accuracy Ph,S based on sample S is "close" enough to Ph, for each hypothesis h? Once that is decided, we can choose the hypothesis h with the highest Ph,S as a result for a boosting round, because h should be close to the actual best hypothesis h? with high probability.

There are various ways to define "closeness" between two hypotheses. The most important requirement for boosting to work is that at least the "weak" hypothesis selected at each round should have accuracy above 1/2. So one very modest requirement of "closeness" between the selected hypothesis h and the best one h? is that if Ph? > 1/2, then Ph > 1/2. So we want our estimated probability Ph,S and the true Ph to fall on the same side of 1/2.

Focusing on each individual hypothesis h, this requirement could be formulated as follows (per [7]). We introduce the utility function Uh for each hypothesis h and define Uh = Ph?1/2. Here the utility function could take negative value in case Ph < 1/2. We want to use Uh,S = Ph,S?1/2 as an estimate for the utility function value Uh such that Uh,S and Uh are close (i.e., with the same sign) with high confidence. The sampling problem is then boiled down to the problem: Problem 3 - We want to design an adaptive sampling  scheme such that when sampling is stopped with n = |S|,  Pr {|Uh,S ? Uh| ? ?|Uh|} ? ? (3)  Note that Uh,S ? Uh = Ph,S ? 1/2 ? (Ph ? 1/2) = Ph,S?Ph for the boosting problem, so boosting by sampling could be formulated as the problem to select a stopping rule on sample size |S| such that  Pr {|Ph,S ? Ph| ? ?|Ph ? 1/2|} ? ?.

The following Fig. 1 illustrates the rationale for this formulation.

The stopping criterion Equation (1) absolute error can be  adapted for the above problem. We will replace the p?n in Eq. (1) Ph,S and the fixed ? in Eq. (1) by ?? = ?|Ph,S?1/2|1+? .

Namely we want to test the condition     ? ? ?? ?  0 1/2 1 ph ???? ?  ?|Uh|  ? ?|Uh|  Figure 1. Illustration for Problem 3 formulation  n ? 2 ln 2? (??)2  [1/4 ? (|Ph,s ? 1/2| ?  ??)2] (4)  The justification for testing this condition is seen from the following proposition.

Proposition 1: Let S be a set of random samples drawn  from the data set D and h be a hypothesis (classifier). Let 0 < ? < 1 be the accuracy level parameter. If S and h satisfies  |Ph,S ? Ph| = |Uh,S ? Uh| ? ?  1 + ? |Uh,S | = ?  ?, (5)  then we will also have  |Ph,S ? Ph| = |Uh,S ? Uh| ? ?|Uh|. (6)  Proof. First we note that when EQ. 5 holds, Ph and Ph,S are on the same side of 1/2. Consider the two possibilities.

If |Uh| ? |Uh,S|, then from |Uh,S ? Uh| ? ?1+? |Uh,S |, we get |Uh,S ? Uh| ? ?1+? |Uh| < ?|Uh|. If |Uh| < |Uh,S|, then |Uh,S| = |Uh| + |Uh,S ? Uh| ? |Uh| +  ? 1+? |Uh,S| by EQ.

5. This shows that 1/(1 + ?)|Uh,S | ? |Uh| and so EQ. 6 follows.

This argument also shows that if a sampling scheme can  assure that the probability of EQ. 5 being true is above 1??, then it would also guarantee the probability of EQ. 6 being true is above 1? ?. From this, we can obtain the following Algorithm HSM (Hypothesis Selection by the Massart rule) for hypothesis selection by our adaptive boosting learner.

Some remarks are due about the HSM algorithm. The  algorithm is executed once in each boosting round. We require that the number of instances drawn is at least 30 in order to avoid terminating the sampling process too early. In our experiments, we did not observe any early termination even without implementing this test condition. The algorithm needs to go over all hypotheses (classifiers) for each instance drawn to update the estimation of Ph,S for every h in the hypothesis space. So the algorithm?s running time is proportional to the size of the hypothesis space and the number of samples used.



V. EXPERIMENTAL RESULTS We have conducted some preliminary empirical studies on  the above Algorithm HSM and the results are encouraging.

For the sake of comparison, we also implemented the Madaboost algorithm. The termination criterion in [7], [8],  Algorithm HSM .

S ? {}.

n? 0.

Done ? false.

While n ? 30 OR Done = false Do begin Draw a random training example x (according to distribution D).

S ? S ? {x}.

n? n + 1.

Compute Ph,S and Uh,S = Ph,S ? 1/2 for each h ? H If n > 30 and n satisfies EQ. 4 and the classifier h ? H with maximal Uh,S has Uh,S > 0 Then Done ? true end Output h, Ph,S and n.

Figure 2. Algorithm for Hypothesis Selection using the Massart Inequality  [16] all test if Uh ? ?n being true or not on seeing n samples. In the earlier formulation in [8], ?n was defined by  ?n = (1 +  ? )  ? 2 ln ? ? ln ln ? + 1  n  where ? = |HDS |n(n+1) 2? ?  ? and |HDS | is the size of the "deci-  sion stump" hypothesis space. The more efficient version of the termination condition [7], [16] was given by  ?n = (1 +  ? )  ? ln n(n+1)?  2n . (7)  We used the above more efficient criterion function Eq. 7 for Madaboost in our comparative study. Our sampling scheme achieves competitive classification accuracies while often using much smaller sample size (e.g., less than 20 percent of the samples used by [7]).

Table I shows a summary description of the two data  sets from the UC Irvine Machine Learning Data Repository that were used in our experiments. Here HDS is the set of all decision-stump hypotheses that were searched by the boosting algorithm. For numerical valued attributes, a discretization is performed that constructs 6 equal-sized intervals. Here the data set "KR-KP" refers to the chess end game "King-Rook vs. King-Pawn" data set. To test the scalability of our algorithm on large data sets, the the "King-Rook vs. King-Pawn" data set is duplicated by a factor of 100. Similar approach was also taken by some of the previous researchers, in particular, the authors of Madaboost also expanded their data sets in their experiments [7]. Table II shows the prediction accuracy comparison between the Madaboost, the method in [3] (denoted as     Table I DATA SETS USED IN THE EXPERIMENTAL STUDIES  Data Set data size number of attributes |HDS| Adult 32561 14 274 KR-KP 319600 36 146  Table II ACCURACY RESULTS FOR THE ADULT AND KR-KP DATA SETS, WITH  ? = 0.1  Data Set ? : 0.1 ? : 0.2 ? : 0.3 ? : 0.4 ? : 0.5 Adult: Massart 0.820 0.822 0.819 0.817 0.820 Adult: Chernoff 0.821 0.817 0.818 0.817 0.820 Adult: Madaboost 0.822 0.820 0.823 0.821 0.820 KR-KP: Massart 0.929 0.932 0.934 0.931 0.924 KR-KP: Chernoff 0.933 0.931 0.926 0.932 0.922 KR-KP: Madaboost 0.932 0.933 0.932 0.930 0.935  "Chernoff" because the stopping rule was derived using the Chernoff bound) and the new method (denoted "Massart") discussed here. The accuracy is computed with a 4-fold cross validation. We set T = 10, which is the total number of boosting rounds. It is clear that the new method as well as the one in [3] achieve prediction accuracy competitive with Madaboost for both data sets.

The following tables III and IV show the sample size  comparisons and the execution time comparisons among the three methods. In addition, the following 4 figures show the experimental results that compare the sample size as well as execution time of our algorithm vs. the one in [16]. In all the experiments, we set the parameter ? = 0.1, with the values of ? varying from 0.1 to 0.5 with 0.1 increment.

Our implementation uses C++ and the program runs on an HP server computer with two quad core Intel CPUs running Linux. The execution time shown (for learning an ensemble of decision stumps with T = 10) is recorded in seconds.

Table III SAMPLE SIZE FOR THE ADULT AND KR-KP DATA SETS, WITH ? = 0.1  Data Set ? : 0.1 ? : 0.2 ? : 0.3 ? : 0.4 ? : 0.5 Adult: Massart 13335 3854 1965 1176 796 Adult: Chernoff 17028 5099 2730 1713 1262 Adult: Madaboost 40210 29235 20076 14327 10162 KR-KP: Massart 4703 1320 680 428 279 KR-KP: Chernoff 5929 1874 916 520 380 KR-KP: Madaboost 41832 14370 6763 4397 3049  Table IV EXECUTION TIME FOR THE ADULT AND KR-KP DATA SETS, WITH  ? = 0.1  Data Set ? : 0.1 ? : 0.2 ? : 0.3 ? : 0.4 ? : 0.5 Adult: Massart 1.503 0.451 0.225 0.133 0.090 Adult: Chernoff 1.943 0.582 0.313 0.197 0.143 Adult: Madaboost 4.531 3.311 2.281 1.634 1.168 KR-KP: Massart 0.325 0.090 0.047 0.030 0.020 KR-KP: Chernoff 0.422 0.136 0.068 0.039 0.028 KR-KP: Madaboost 2.923 1.017 0.482 0.315 0.221  Figure 3. Comparison of sample sizes on the Adult data set. The X-axis is the value of the parameter ?. Here ? = 0.1.

Figure 4. Comparison of execution time (in seconds) on the Adult data set. The X-axis is the value of the parameter ?. Here ? = 0.1.

Figure 5. Comparison of sample sizes on the KR-KP data set. The X-axis is the value of the parameter ?. Here ? = 0.1.

Figure 6. Comparison of execution time (in seconds) on the KR-KP data set. The X-axis is the value of the parameter ?. Here ? = 0.1.



VI. CONCLUSIONS AND FUTURE WORK In this paper we outline a scheme on how to use the  new adaptive sampling method in [5] to build a scalable ensemble learning algorithm with boosting, in the same spirit as in [7]. Preliminary experimental studies show that our method leads to a much lower sample size while maintaining competitive prediction accuracy of the learned classifiers when compared with the method in [7]. Future works would include a thorough theoretical analysis of the proposed sampling method as well as more extensive empirical studies with larger data sets.

