Fuzzy Reasoning Implemented by Neural Networks

Abstract: Viewing the given rule-base as defining a global linguistic association constrained by fuzzy sets, approximate reasoning is implemented here by a Backpropagation Neural Network (BNN) with the aid of the fuzzy ste tbeory. By paying particular attention to the mpability of generalization of the BNN, the underlying principles have been examined in detail using two examples. The simulation results not only indicate the feasibility of the BNN-based approach, but also reveal some deeper similarities which exist in the two methods, which may have some important implications for future studies of fuzzy control.

1. Introduction Fuzzy or approximate reasoning (AR) employed by rule-based fuzzy expert systems or fuzy  logic  controllers can be regarded as a process by which a set of imprecise conclusions is deduced from a collec- tion of imprecise premises [l]. Although the rcasoning can be carried out by fuzzy logic-based re3soning algorithms. here we consider another possibility of implementation of AR by neural networks. The motiva- tion comes mainly from the fact that the goals of AR and mapping neural networks are very similar, that is, to perform some kind of approximation or intcrpolation, although the representation the information they are dealing with is different. In particular, we claim that neural networks inherently possess some fuzzi- ness, the source of approximation in AR, which is displaycd in the network via net-computing in the form of generalization. This view is of pnrticular importancc in the net-based fuzzy control as will be discussed in section 5.

Instead of seeking a structure mapping from a fuzzy reasoning system to a neural network, this paper is intended to find ;1 functional mapping from the fuzzy logic-based algorithm to the network-based approach. By viewing the given rule-base as defining a global linguistic association constrained by fuzzy sets, the approximate reasoning is implemented by Backpropagation Neural Networks (BNN) with the aid of fuzzy ste theory. By paying particular attention to the capability of generalization of the BNN. the underlying principleshave been examined in dctnil using two examples, a small demonsmion at the linguistic level, and a more realistic problem of multivariable fuzzy control of blood pressure. The simula- tion results not only indicate the feasibility of the BNN-based approach, but also reveal some deeper simi- larities which exist in the two methods, which inay hive some important implications for future studies of fuzzy control. In addition, this work may be considcred as another appliction example of the BNN in the case of continuous ouputs and on a relatively larger scale (in the second exmple,the BNN has 26 inputs and 16 outputs, with a total of 2013 weights and thresholds). Furthermore, the work may provide evidence to support the argument that net-computing is. in fact. knowledge representation as claimed very recently by Pa0 [2].

2. Formulation of the problem Assume that the system has n inputs and m outputs denotcd by XI,  X2;-Xn and YI.Y2;- ,Y, Further-  more, it is assumed that L "IF situafiori THEN acfiort " rules, and n inputs in the IF p a t  and m outputs in the THEN part are connected by linguistic connectives ALSO and AND respectively. Then the problem may be described as follows:  Given rules: RULE' ALSO RULE' ALSO ...... ALSO RULEL where RULE' has the form: IF XI is 4 AND X 2  is A$ AND ...... AND X ,  is A', THEN YI is B{ AND Y2 is A{ AND ...... AND U,,, is 4" , j=1,2, -.-. L.

Given input datx XI is CI AND X2 is C2 AND ...... AND X,, is C, To find output daw Y1 is D I  AND Y2 is D2 AND ...... AND U,,, is D,  where X; and Y, are linguistic vnri;ibles whose values we taken from the discourses of universe  which are defined on the correspondin$ discourses, and rcpresent some fuzzy concepts such as big, medium and small etc. More prcciscly. fuzzy subsets A:. Ci, B/I.. Dk are characterized by the corresponding membership functions Aj(ii;) : I/;+[o, 11 , Ci(u;): I/i+[o. 11 . &(v& vk* [0.1],  U;, Vk with U i = ( ~ ; l ,  142, ...e... U;,) and V L = ( V ~ ~ ,  ~ k 2 .  .-...,vkrk). Ai, Ci, B i ,  Dk are fuzzy Subsets  0-7803-05594 /92 53.00 Q 1992 IEEE 11-702    and Dr(vd : v+ [O,I].

The above problem can be solved using fuzzy-logic-based algorithms in the following two ways. The  first one may be called the relational mauix method. The basic idea is first to create a relational matrix R based on the given L rules using some logical operators. Then the outputs for a specific input is determined by Zadeh's compositonal rule of inference. The other solution is a stnightforward one in the sense that the algorithms closely follow the inferencing procedures used by data-driven reasoning systems and which take the fuzzy variables into account [3]. The basic idea is first to treat the L rules one-by-one and then to combine the individual results to give a global output.

3. Solutions using neural networks Although the Bacclrpropagation Ncuml Network (BNN). the Basis Function Network (BFW), and Pro-  bability Function Network (PFW) are good candidates for our purpose, the well-known BNN [4] structrure has been chosen for the current study. In what follows , we will formulate the BNN and AR from the functional viewpoint so as to obtain a formal equivalence between them.

From the mapping perspective. the goal of the BNN is to perform an approximate implementation of an unkown mapping $, from a compact set Pc R an NI demensional Euclidean space, to an NO demen- sional Euclidean space, $: fl -) RNo, by an approximator +* consisting of layered and massively con- nected processing units. Assume that the topology of the network is specified. Then constructing $' is equivalent to determining the parameters of the BNN based on a set of selected examples. More specifically, assume that we are given a set of examples ( U', v1 ), -. ( U', ) with Up being drawn from fi, and 9 being supposed to be satislied with the unknown function +, i.e. 9 = $(U"). Denote all the weights and thresholds in the structure-specified BNN as a panmeter vector w. Furthermore, the P desired and actual outputs cahculated from the BNN at P discrete sample points are denoted as $= [$'(U'). $'(U'), . e - ,  41'(d)] and 4.3 [$'*(U', w), +2*(u2, w), -., +'*(U', w)] respectively. Then the problem can be simply for- mulated as to select w in such a way that a specific error fuction, say, a quadratic one, 3s denoted by  N  (1)  is minimized, provided that the strucure of the BNN is specified a priori. We can expect with some confidence that the approximator constructed from only a finite set of points in fl will work satisfactorily over the whole space of P.

Based on the idea discused above, the problem of the approximate reasoning presented in section two may be solved if it is formulated in the same way as in the BNN, that is, to construct an inference engine Y* based on the given L rules and to genenlize to unseen situations in the domain of interest by directly manipulating the engine. Clearly, a given rule is malogus to an example in the BNN. L IF-THEN state- ments may designate an implicit and global relationship between the situation set and action set. To be more specific, denote the situation variable X=[ XI ,  X2, ..., X,] md the action variable Y =[ YI, Yz, ..., Y,,, I.

X and Y take linguistic labels, represented by fuzzy sets A{ and B i  defined on the corresponding universes Vi and Vr, as their values, for example, X=Xp=[  AY, A{, .... Aa. Further, let Y(X)=[ Y', Y2, ..., f 1 and Y*(X, W)=[Y*(X'.W), Y*(X*,W), ..., Y*(Xp,w)] be the desired action and the actual action calculated from the inference engine Y* with respect to P situations X p ,  p19, where W denotes a set of parameters deter- mining the "*. Then, by analogy to equ 1, the problem may be reformulated to select W in such a way that  2 E ( w )  = - I 1$(4 - +*(U.W) I I'  (2) 1 E(w) = 2 I IY(X) - 'Y'(X,W) I I'  is minimized such that an action Y = [ D , .  D2, ..., D,,,] will be approximately deduced from the constructed inference engine Y* when a new situation X=[CI, CZ. .... C,] is encounted. Thus, the Y* accomplishes an approximate implimenution of linguistic mapping from one linguistic set of the situation domain to another linguistic set of the action domain.

It is obvious, from the above discussions, that the AR problem can be solved by the network method if the linguistic values can be mnslatcd into numerical forms suitable for the use of the BNN and the numerical outputs from the BNN can be interprcted as liguistic labels. The graded membership function is the first choice for the former tnnsfomntion aid some methods for linguistic approximation may be used for the latter conversion. It is noted that althougli the reasoning system itself has n iuputs and m outputs, the BNN using the fuzzy set representation will have sI+s2+ . . . +s,,inputs and rl+r2+ . . . +r, outputs with  11-703    si & rk being the cardinality of Ui aid V, on which fuzzy sets are delined. Therc exist other possibilities for the hbeVnumencal value tmnsformation, one of which will be discussed in section 5.

Klle*ls KIZe*' [ ACO] = [ 1.0 -24.761 M A P  0.6636 76.38 ~ ~ ~ ~ * f  K ~ ~ ~ ~ P  --  sTZ+I sT2i-I  4. Reasoning capability: a linguistic study The main objective of the study in this section is two-fold, i.e. to investigate the capability of the  BNN-based reasoning system in the linguistic levcl and to examine the effect of the number of hidden units upon this capability, by means of the simulation on a small but typical problem.

Suppose we are given five rules, each of which has the form of "IF X is A THEN Y is B" with the pair (A, B) being specified as (PB. NB), (PM, NM), (ZR, ZR), (NM. PM) and (NB, PB), where PB, PM, ZR, NM, and NP stand for Positive-Big, Positive-Medium. Zero. Ncgative-Medium and Negative-Big respectively. For simplicity, we assume that all the fuzzy sets representing the above linguistic labels are defined on the same discourses of universe, i.e. U=V=(-4,-3.-2,-1,0,1.2,3,4,) and all the membership func- tions are of triangular form located at -4, -2, 0, 2, 4. The BNN consists of one input and one output layer with 9 input and 9 output units, corresponding to the cardinalities of U and V, and one hiden layer with a variable number of units. By setting the initial weights to be uniformly distributed on [-OS, OS], the net was trained by the presentation of five rules with the learning rate being 0.8 and the number of hidden units being 5, 15, 30 and 50 respectively. The tmining process was stopped when the sum of squared error within one cycle was less than 0.0005. Then the BNN was tested using the following two sets of linguistic labels.

The first set of linguistic inputs used so-callcd linguistic hedges to modify the basic labels in the rules. Here two hedges, very and nwre or less were used and defined as very A =A2 and more or less A =AoJ. Thus, ten different inputs could be used to test the performance. For example, if very-positive- medium is presented to the BNN, the expected outputs should be very-riegative-medium  Instead of merely altering the shapes of the basic labels as above, the second set of linguistic inputs was concerned with changing the centnl values with respect to the bllsic labels, representing a much harder situation than the previous one since the inputs are substantially different from that in the given rules. It is convenient to interpret the linguistic labcls as fuzzy numbers meaning linguistically that " X is about U ".

With the same trained BNN. Fig. 2 gives the results corresponding to the expected outputs of "about" +3, +1, -1, -3. At first sight. one may think that the results are not as good as would be expected. However, if we calculate the area under the different curves and accept this quantity as a global measure of the perfor- mance, the results are remarkably good. For example, when the expected output is "about -1". the absolute differences between the expected and actual mas (calculated using a weighted sum) are 0.1552, 0.1141, 0.1142, and 0.0534 corresponding to 5 .  15, 30, and 50 hiddcn units respectively.

It should be noted that the generdization performance of the BNN does not monotonously increase with an increase in the number of the hidden units. To clarify this point, we adopt another global measure, namely the centre of gravity (COG) which is an important quantity in fuzzy control, where it is used to produce a non-fuzzy output, For the present problcm. the averaged differences between the expected and actual COG were 0.1239. 0.0912. 0.1109, and 0.0965 corresponding to 5. 15.30, 50 hidden units respec- tively, indicating that, at least in the current context, the rmoning performance could be degraded with too few or too many hidden units.

[4f)OP] ASNP (3)  This problem has been investigated by the authors [3] using the logic-based fuzzy control approach.

For the purpose of comparisons. we employ the same architecture as used in [31 except that here the fuzzy  11-704    controller is implemented using the BNN-based method. The control system, as shown in Fig.3. consists of two separated control loops, CO/DOP and M A P / S N P ,  with the aid of a simple compensator to reduce the interactive effects. For simplicity, the two controllers, e x h  comprising two linguistic inputs, error e and change-inerror ce, and one liguistic output U, are assumed to be idcntical and thcrcfore only one of them is described  Suppose that dl the discourses of unvcrse have the sane form consisting of 13 integers ranged from -6 to 0 to 6, and that seven Linguistic hbcls (negative-big (medium, small). zero, and positive-big (medium, small)) are used. They are dclined by the m e  tmgu la r  form with the central values located at -6.4.- 2.0.2.4.6 respectively. Thus the resultant BNN has 26 inputs and 13 outputs. If one hidden hyer with 50 units is used, the BNN will have a total of 2013 adjustable parameters.

Two phases, off-line training and onrline application, are needed. Using the given 33 rules as shown in Table 1, the BNN was mined with 50 hidden units and a leaning rate of 0.02. Although the actual out- puts of the BNN are in the interval [OJ] in xcordcnce with the range of a sigmoid nonlinear active func- tion, it has been found that a faster convergency could be achieved if linear active functions in the output layer are used, as illustrated in Fig.4. To investigate the elfects of the number of rules upon the reasoning performance, a set of 16 rules selected from 33 rules as marked with "*" in Table 1 was also tnined. As expected the sum of the squared error decreases more quickly as shown in Fig.4.

Because the measured error e, change-in-error ce aid the required control U are numerid, the e and ce have to be fuzzified into fuzzy sets and the fuzzy scts output of the BNN must be defuzzified into a real number during the application stage. Here singleton fuzzification and COG defuzzification methods m employed. However, if the linguistic labels are viewcd as fuzzy numbers and the BNN is trained with the central values of the fuzzy numbers only, the complexity of the controller is greatly reduced and the efficiency in speed and storage is dnmaticaly increased due to the fact that the number of inputs and out- put is reduced to 2 and 1 and neither fuzzilication nor defuzzification is needed. To verify this possibility, the BNN with 15 hidden units was trained and tested using 33 and 16 rules respectively. The results are reported next.

After appropriate training, the BNN was used as the controller in the system. The capability of the generalization of the BNN was evaluated indirectly by the control performances measured by two fre- quently used indices: integnl of square of the error (ISE) and integral of time and absolute error product (ITAE) for each output. We considered four cases: the BN"s with linear active functions in the output layer mined by fuzzy sets with 33 arid 16 rules (dcnotcd by FS-33 and FS-16) and by fuzzy numbers with 33 and 16 rules (FN-33 and FN-16). Tiible 2 shows the simulation results when the system was subject to square-like inputs as shown in Fig. 6. The results obtained using the logical-based method [3] are also included in Table 2 for comparison purpose. Due to space limitation, only the output responses in the case of FS-33 are presented in Fig.5.

The following conclusions can be drawn from the results: (a) the BNN possesses a high ability to generahe, a very useful property for fuzzy reasoning. This is pmicularly demonstrated by the case of FS-33 and FS-16 where the measured singleton inputs were very different from the Wining inputs;(b) it is possible to use fewer rules to obhin a valid generalization as illustrated by FS-16 and FN-16: (c) perhaps the most important conclusion from the rcsults is that the BNN trained by the fuzzy numbers can produce performances 3s good 3s. or even better than, the one trained by the fuzzy sets as indicated by the case of F S 3 3  wrt. FN-33 or FS-16 wrt. FN-16: (d) the similar pcrfomances obtained by the logic-based and the BNN-based reasoning approaches suggest the feasibility of the BNN for the application of fuzzy control.

6. Conclusion  By paying particular attention to the capabilily of generalization of the BNN, it has been demon- stmted that a forward-chaining fuzy  reasoning system with parallel rule-bases c m  be implemented within the framework of neural networks. The studies into the BNN-based fuzzy controller suggest that, besides a seeming resemblence between rules and patterns in the logic-based and BNN-based approaches, there exists a deeper similarity in the information processing aspect in them, namely. fuzziness vs. distributiveness. The authors believe that this suggestion has some important implications for the development of fuzzy control under the h e w o r k  of neural networks. Some studies along these lines are currently in progress.

