The Decision Rules Mining Algorithm of Information  System Based on Rough Set

Abstract?There are many uncertainties of the data in information systems, which affects the extraction of decision rules. Using rough set to deal with these non-precise data can achieve effective decision-making rules by deleting redundant attributes. Through the relationship of key attributes, we can get association rules in a higher interested degree. The rules reflected the decision-making feature between attributes can provide decision support for policy-makers.This paper describes the implementation of rough set theory in incomplete data decision and reasoning of the basic principle of two-dimensional relational database, and presents a decision rules mining algorithm of information system based on rough set. The algorithm can select the decision rules on the basis of meeting the support and confidence, which can improve the accuracy and reasonableness of the decision rules mining.

Keywords-rough set; information systems; decision rules; attribute reduction

I. INTRODUCTION Rough set is a new mathematical tool of dealing with  incompleteness and uncertainty knowledge. Its main feature is not described the number of certain characteristics or properties in advance. From the classification of a given problem and by the indiscernibility relation and classes we can determine the knowledge reduction, deduce decision or classification rules, and provide decision support to the information systems or decision-making system[1]. In this paper, two-dimensional decision table in a relational database based on rough set decision-making system are described in detail[2].



II. ROUGH SET In the rough set theory, the extent of concept definition can  be described by three similar domains including positive domain, negative domain and boundary domain. The domain of given problem can be divided based on the Knowledge, then determining the degree of support of a concept: that certainly support this concept, certainly does not support this concept and possibly support this concept. Rough set dose not need membership functions and know much background about the data of given problem[3].



III. ALGORITHM ANALYSIS  A.  Information Systems and Decision Support System An information system S = (U, A),domain U: a non-empty  finite set, A: non-empty finite attribute values. Va is the value domain of attribute a, a ? A, U ? Va is a single map, so any element value in the domain U take unique value of a in Va. If A includes the set of condition attributes C and decision attribute set D, C and D satisfy C ? D = A, C ? D = ?, S is called decision-making system. For simplicity, the decision-making system is described as (U, C ? {d}) in this paper, that is, a collection of conclusions of attribute value contains only one element, and for the decision-making attributes set of multi-element, its treatment is similar. For the decision-making system S = (U, C ? {d}), condition attributes B is a subset of the condition attributes C, B   C, and binary relation ind(B, {d })={( x, y) ? U ? U: d (x) = d (y) or a?B, a(x)=a(y)} is called as indiscernibility relation of S, x, y is the element of U .It can divide U into different equivalence classes[4].

B.  Top Approximation and Bottom Approximation Suppose X is a subset of U and a is an object of U, [a]R is  the set of all indiscernibility objects, R is an equivalence relation of U. When the set X can be expressed as the composition of equivalence classes and the basic set, called set X can be precisely defined[5]. Otherwise, set X can only be characterized by method of approximation. The bottom approximation of set X on R is defined as (1).

R(X)={x?U| [x]R   X }                          (1) The largest set consisted of the objects belonging to X  judged by knowledge is called positive  domain and denoted by POS (X); The top approximation of X on R is defined as (2).

(X)={x?U|[x]R(X)?X??}                     (2)  From the intersection of all non-empty equivalence class [a]R and the set X, who may belong to the minimum set of objects; According to the existing knowledge the  set of objects certainly not belonging to X is called the negative domain of X, denoted by NEG(X) as (3).

NEG(X)=U-  (X)                           (3)  ?  ?  R  R     Boundary region BN (X) = (X) - R (X), if the BN (X) is the empty set, called X on R is clear, on the other hand if the BN(X) is not empty set, called set X is rough set of R.

Inaccuracy of X is caused by the presence of the border, we can use the formula shown in (4) describes the approximate precision of X.

(4)  |X| is the number of elements in finite set X, 0 ? ? R (X) ? 1, when ? R (X) = 1, X is called R-definable set; ? R (X) <1, set of X relative to R is rough[6].

C.  Knowledge Reduction In the decision system S = (U, A), some attributes are  redundant, and these redundant attributes can be removed, that is knowledge reduction. We can obtain minimum condition attributes set of non-excess attributes and correct classification.

If ind (B) = ind (B-{a}),B  A?a?A, then B can be reduced. A decision table may also exist several reductions, the intersection of the reductions is defined as the core attributes and core attributes is the important attributes in the classification[7].

We can use discernibility functions for matrix attribute reduction. Discernibility matrix is defined as (5).

M(B)={m(i,j)| n?n,1?i,j?n}  m(i,j)={a?A|a(i)?a(j)and d(i)?d(j)},n=|U|           (5)  Discernibility function is defined as (6).

(6)  ? is operator of "?" and ? is operator of "?".



IV. EXAMPLE ANALYSIS We use a two-dimensional table to describe the  decision-making system, with rows of U to describe the domain, N is the sample number, condition attributes is A1, A2 and A3, decision attribute is D4, attribute values is shown in Table 1.

Table 1. ATTRIBUTE VALUES  U    N A1 A2 A3 D1  U1   16  U2   22  U3   17  U4    6  U5   15  U6    5  U7   12  U8    7                          M  B  M  B  P  P  S  S  The discernibility matrix can be obtained shown in Table 2.

According to Table 2 we can derive discernibility function as follows:  ?= ? A1?A2 ??? A1? ?A2 A3 ??? A1?A2 ?? ?A1? ?A2 A3???A1?A3???A1? ?A2 A3???A1?A2? ??A2?A3???A2???A1???A2?A3???A1? ?A2 A3? ??A2?A3???A3???A2???A2???A1?A2??(A1 ? ? ? ? A2  A3) (A1  A3) ? ? ? ? ?(A1  A2  A3) (A2  A3) ? ? ? ? ? ?(A3) (A1  A3) (A2  A3) ?A2?A3?? ?(A1  A2) ? ?A1? ?A2 A3?=A2?A3  Table 2. DISCERNIBILITY MATRIX  U1 U2 U3 U4 U5 U6 U7  U1 U2 U3   U4 U5 U6   U7   U8    A1,A2  A1,A2,  A3  A1,A2,  A3  A1,A2    A2,A3    A2,A3      A1,A2    A1,A3  A2,A3  A1,A2,  A3  A1,A2  A3  A3          A1,A2,  A3  A2    A2,A3    A1,A3            A1  A3    A1,A2,  A3  A2,A3              A2    A1,A3    A2,A3                  A1,A2,  A3  A1,A2                      A1,A2,  A3  The decision table has two attributes reduction {d1, d2}, core attributes is {d1, d2}. Which can be derived rules set based on attributes of (d1, d2) shown in Table 3.

Table 3. DESITION RULES  rules ?s ?c  A2=4?A3=2?D1=M  A2=2?A3=5?D1=B  A2=1?A3=4?D1=M  A2=4?A3=2?D1=B  A2=1?A3=3?D1=P  A2=2?A3=5?D1=P  A2=4?A3=6?D1=S  A2=7?A3=2?D1=S  0.22  0.27  0.17  0.22  0.15  0.27  0.12  0.07  0.73  0.81  1.00  0.27  1.00  0.19  1.00  1.00  Suppose rule set support degree is ?s = 0.20 and rule confidence degree is ?c = 0.60, based on attributes {A2, A3}, the rules can be obtained as follows:  A2=4?A3=2?D1=M  A2=2?A3=5?D1=B

V. ANALYSIS OF EXPERIMENTAL DATA Through the comparing analysis of rough mining and  normal mining, we can get the accuracy rate result. One  ? (X)R  RX RX  =  ?  ?  ?= ?? ?  UUj)(i, j)m(i,?    comparison is the number of elements shown in Fig.1. The other is the number of attributes shown in Fig.2.

Figure 1. Comparison on number of elements                    Figure 2. Comparison on number of attributes  According to the data analysis, rough mining has higher accuracy of decision-making rules mining than normal mining when the data has large number of and elements and attributes.



VI. CONCLUSION The decision analysis based rough set theory dose not  require the completeness of the data, through the division and reduction, and under the constraints of objective interest measure ?s and ?c, we can get the set of high accuracy decision rules.In the actual extraction of decision rules, how to combine fuzzy set theory and the principle of subjective measure of interest for improving the accuracy and robustness of the algorithm to reduce the algorithm complexity and the practice of space complexity, which is worth further study.

