Vertical Mining for High Utility Itemsets

Abstract-Recently, high utility itemsets mining becomes one of the most important research issues in data mining due to its  ability to consider different profit values for every item. In the  past studies, most algorithms generate high utility itemsets from  a set of transactions in horizontal data format. Inspired by the  problem of frequent itemset mining, vertical mining may be a  promising approach superior to horizontal mining. In this paper,  a high utility itemsets mining algorithm based on vertical  database layout is proposed. Candidate high utility itemsets are  discovered by intersection of covers at first. Then, high utility  itemsets are checked within candidates by scanning database  once. Thus, the advantages of vertical database layout, such as  low storage, and high efficiency, are utilized. Experimental  results show that the proposed algorithm is both efficient and  scalable.

Keywords- data mining; frequent itemset; high utility itemset; vertical database layout

I. INTRODUCTION  Frequent item sets mining [ 1, 2] is a fundamental and important research topic for data mining. The goal of frequent item set mining is to find items that co-occur in a transaction database above a user given frequency threshold, without considering the quantity or weight such as profit of the items.

However, quantity and weight are significant for addressing real world decision problems that require maximizing the utility in an organization. To address the limitation, utility mining [3, 4] emerges as an important topic in data mining.

The basic meaning of utility is the importance or profitability of items to the users. The utility values of items in a transaction database consist of two parts: one is the profit of distinct items which is called external utility, the other one is the quantity of items in one transaction which is called internal utility. Then the utility of an itemset is defined as the external utility multiplied by the internal utility. The high utility item set mining problem is to find all itemsets that have utilities no less than a user specified value of minimum utility. Mining high utility itemsets is a very important research for retrieving more useful information from a database by measuring how useful the item is. The information can help us make several business decisions like revising revenue, adjusting inventory or determining purchase orders.

High utility itemsets mining is not an easy task. The difficulty is that high utility item sets mining does not follow the "downward closure property" [ 1], that is, a high utility   itemset may consist of some low utility sub-itemsets. Earlier studies [4, 5] suffer from the level-wise candidate generation? and-test problem and several database scans depending on the length of candidate itemsets. In view of this, some novel tree structures are used for high utility item sets mining [6, 7]. As these algorithms are based on the pattern growth approach [2], they are also generate a huge number of conditional trees, which costs a lot of time and space.

The previous work on high utility item sets mining mainly utilized the horizontal transactional database format. That is, each transaction has a transaction identifier and a list of items occurring in that transaction. Another commonly used layout is the vertical data layout. In a vertical database each item is associated with its corresponding cover, the set of all transactions (or tids) where it appears [8, 9]. To the best of our knowledge, there are few vertical mining algorithms for high utility itemsets. The advantages of vertical mining stems from the fact that frequent itemsets can be counted via cover intersections, instead of using complex internal data structures (candidate generation and counting happens in a single step).

The horizontal approach on the other hand requires complex hash/search trees. Cover offer natural pruning of irrelevant transactions as a result of an intersection.

In this paper, a high utility itemsets mining algorithm using vertical database format is proposed. In this algorithm, high transaction-weighted utilization item sets are discovered by intersections of covers, rather than the candidate generation? and-test scheme. Extensive performance analysis show that our proposed UDepth algorithm is both efficient and scalable.

The remainder of this paper is organized as follows. In section 2, we describe the high utility itemset mining problem and related work. In section 3, the proposed algorithm is presented in details. In section 4, we show experimental results on both synthetic and real datasets. Finally, conclusions are drown in section 5.



II. BACKGROUD AND RELATED WORK  A. Pr oblem Defin iti on We adopted similar definitions to those presented in the  previous works [4, 6, 7]. Let I={i " i2, . . .  , i m} be a [mite set of items, a set X ? I is called an itemset, or a k-itemset if it contains k items. Let D={T" T2, . . ?  , Tn} be a transaction database. Each transaction T,ED, with an unique identifier tid, is a subset of 1.

The internal utility q (ip, Td) represents the quantity of item ip in the transaction h The e xternal utility p (ip) is the unit profit value of item ip. The utility of an item ip in the transaction Td is defined as u (ip, Td)= p (ip) x q (ip, Td).

The utility of an itemset X in the transaction Td is defmed as: U (X, Td)= I u (ip, Td)?  ipEX I\Xc;;,Td  The utility of an itemset X in D is defmed as:  u (X)= I u (X, Td)? X';;;,.TdI\TdED  An itemset X is called a h i gh utility itemset if u (X)? min_util, where min_uti! is a user-specified minimum utility threshold. Otherwise, it is called a low utility itemset. Given a transaction database D, the task of high utility itemset mining is to fmd all item sets that have utilities no less than min uti!.

The main challenge of high utility itemset mining is the itemset utility does not have the downward closure property.

Liu et al. [4] proposed transaction-weighted downward closure to prune the search space of high utility itemsets.

The transaction utility of a transaction Td is defmed as TU (Td) = U (Td, Td). The transaction-weighted utilization of an item set X is the sum of the transaction utilities of all the transactions containing X, which is defmed as:  TWU (X)= I TU (Td ) .

Xc;;,TdI\TdED  X is a High Transaction-Weighted Utilization Itemset (abbreviated as HTWUI) if TWU(X) ? min_uti!. Otherwise, it is called a Low Transaction-Weighted Utilization Itemset (abbreviated as LTWUI).

As shown in [4], any superset of a LTWUI is also a L TWUI. Thus we can prune the supersets of L TWUIs.

However, since transaction-weighted utilization is an over? estimation of the real utility itemset value, further pruning of HTWUls will be required.

TID         Total  Item  profit  TABLE!. THE EXAMPLE DATABASE  Transactions  (A, 2) (C, I) (D, 1) (A, 2) (B, I) (C, 1) (C, 1) (D, 1) (E, 10) (B, 1) (E, 15) (A, 1) (C, 1) (F, 1) (A, 2) (D, I) (E, 10) (A, 2) (E, 8) (F, 1) (A, I) (B, I) (D, I) (E, 2) (A, I) (D, I) (E, 10) (A, I) (B, I) (E, 5)  TABLE II. PROFIT TABLE  A  B C 150 25  D  E  TU        F  In a vertical database layout, each item set is associated with its corresponding cover, the set of all transactions (or tids) where it appears. The cover of an itemset X is described by the following function: g (X) = {TEDIViEX, iE T}.

Example 1. Consider the transaction database in Table I and the profit table in Table II. For convenience, we write an itemset {A, F} as AF. In the example database, the utility of item A in transaction T5 is: u (A, T5)=10xl =10, the utility of itemset AF in transaction T5 is: u (AF, T5) = u (A, T5) + u (F, T5) = 10 + 2 = 12, and the utility of itemset AF in transaction database is u (AF) = u (AF, T5)+u (AF,T7) = 12 + 22 = 34. Given minimum utility threshold min_util = 129.9, i.e., 10 percent of the total transaction utility in Table I, since u (AF) < min_util, AF is a low utility itemset. The transaction utility of TJ is: TU (Ta = u (ACD, Ta = 80, and the transaction-weighted utilization of an itemset AF is: TWU (AF)=TU (T5)+TU (T7) =37+62=99. Thus, AF is a LTWUI, any superset of AF can be safely pruned.

B. Ex i stin g Algor ithms The basic concepts of high utility itemset mmmg were  given in [5]. This approach, called Mining with Expected Utility (MEU), uses a heuristic to determine whether an itemset should be considered as a candidate itemset. However, this approach cannot maintain the downward closure property.

MEU usually overestimates, especially at the beginning stages, where the number of candidates approaches the number of all the combinations of items. This trait is impractical whenever the number of distinct items is large and the utility threshold is low.

Liu et al. [4] propose a Two-Phase algorithm to mine high utility itemsets. They use a transaction weighted utility measure in the first phase to find supersets of high utility item sets, followed by a rescan of the database to determine the actual high utility itemsets among them. This algorithm suffers from the same problem of the level-wise candidate generation-and? test methodology. Li et al. [10] proposed an Isolated Items Discarding Strategy, abbreviated as lIDS, to reduce the number of candidates. By pruning isolated items during the level-wise search, the number of HTWUls can be reduced effectively.

However, this approach still scans database multiple times and uses a candidate generation-and-test scheme to fmd high utility itemsets.

To solve the problems of large number of candidates and multiple times of database scanning, several researches focused on constructing tree structures, such as CTU-Tree [6], HUC? tree [7] and so on. These tree-based algorithms consist of three parts: 1) construction of trees, 2) generation of candidate high utility itemsets from the trees by pattern growth approach, and 3) identification of high utility itemsets from the set of candidates. As these tree-based algorithms discover HTWUIs in a pattern-growth approach, they still suffer from the problem of huge memory usage for constructing and visiting conditional trees.

To the best of our knowledge, in the existing high utility pattern mining methods, there are few algorithms based on vertical database layout, where the advantages of vertical database layout, such as low storage and high efficiency, can be    utilized. Therefore, we propose a new vertical high utility itemsets mining algorithm. Our algorithm maintains the downward closure property with a transaction-weighted utilization value of an item set, and uses cover intersection operation to avoid level-wise candidate generation-and-test problem.



III. THE PROPOSED UOEPTH ALGORITHM  In this section, we describe our high utility item set mining algorithm based on vertical database format.

Algorithm 1. Udepth  1) Scan database D once. Compute the transaction? weighted utilization of each item, and delete those items with transaction-weighted utilization lower than min_uti!;  2) Sort the remaining items in each transaction in transaction-weighted utilization descending order, and compute the transaction utility of each transaction again;  3) Represent the database D with BitTable;  4) for each item i do  5) HTWUlsMine(i, t(i )); II t(i ) is the set of items that after i according to the transaction-weighted utilization descending order.

6) end for  7) Scan database D once. Compute HTWUls' utility.

Output high utility itemsets.

Procedure HTWUIsMine(i, t(i ))  1) i is a HTWUI;  2) if t(i )==0 then  3) Return;  4) for each itemjE t(i ) do  5) Compute g (i uj) = g (i )ng(j);  6) if g (i uj}t.0 then  7) Compute TWU (i uj);  8) if TWU (i uj)?min _uti! then  9) HTWUlsMine(iuj, t(iuj));  10) end if  11) end if  12)end for  In Algorithm 1, the database D is first scanned once to determine the high transaction-weighted utilization items (Step 1). In Step 2, the remaining items are sorted in transaction? weighted utilization descending order, and the transaction utility of each transaction is recomputed. In Step 3, the BitTable representation of database D is built [11]. For each high transaction-weighted utilization item i ,  the HTWUls containing i is computed recursively in the loop (Steps 4-6). In Procedure HTWUlsMine, we traverse the search space of  HTWUls in pure depth-first order. Note that the cover of any itemset is determined by intersecting the covers of two of its subsets.

Example 2. We illustrate Udepth algorithm on example database shown in Table I and Table II.

At fust, scan database once, and compute the cover and transaction-weighted utilization of each item (Shown in Table III). Suppose min_uti!=129.9, F can be deleted from database, as any superset of F can not be high utility itemsets.

TABLE Ill. THE COVER AND TRANSAcnoN-WEIGHTED UnUZA nON OF EACH ITEM  Item cover TWU  E 3, 4, 6, 7, 8, 9, 10 987 A 1, 2, 5, 6, 7, 8, 9, 10 964 B 2, 4, 8, 10 810 D 1, 3, 6, 8, 9 595 C 1, 2, 3, 5 422 F ? 99  Then, items are sorted by transaction-weighted utilization descending order in each transaction. The utility of each transaction after deleting low transaction-weighted utilization items is shown in Table IV.

T ABLE IV. THE R?-ORGANIZED DATABASE  TID Transactions TU  T, (A, 2), (D, 1), (C, 1) 80 T2 (A, 2), (B, 1), (C, 1) 195 T3 (E, 10), (D, 1), (C, 1) 110 T4 (E, 15), (B, 1) 225 Ts (A, 1), (C, 1) 35 T6 (E, 10), (A, 2), (D, 1) 105 T7 (E, 8), (A, 2) 60 Ts (E, 2), (A, 1), (B, 1), (D, 1) 205 T9 (E, 10), (A, 1), (D, 1) 95 TIO (E, 5), (A, 1), (B, 1) 185  Total 1295  Next, we take item E as example, t(E)={A, B, D, q, E is identified as a HTWUI. g (EA) = g (E)ng(A)= {3,4,6,7,8,9,1O} n {l,2,5,6,7,8,9,1O} = {6,7,8,9,1O}, so TWU (EA) = TU (6) + TU (7)+ TU (8) + TU (9) + TU (10) = 650. Because TWU (EA)?

min_uti!, Procedure HTWUlsMine(EA, t(EA)) is called recursively. Thus, all HTWUls containing E are {E: {3, 4, 6, 7, 8, 9, 1O}, 987; EA: {6, 7, 8, 9, 1O}, 650; EAB: {8, 10}, 390; EABD: {8}, 205; EAD: {6, 8, 9}, 405; EB: {4, 8, 10}, 615; EBD: {8}, 205; ED: {3, 6, 8, 9}, 515}, where the number after comma means the transaction-weighted utilization of itemsets.

The HTWUls containing A, B, D and C can be computed similarly.

The set of all HTWUls is {E: {3, 4, 6, 7, 8, 9, 1O}, 987; EA: {6, 7, 8, 9, 1O}, 650; EAB: {8, 10}, 390; EABD: {8}, 205; EAD: {6, 8, 9}, 405; EB: {4, 8, 1O}, 615; EBD: {8}, 205; ED: {3, 6,    8, 9}, 515; A: {I, 2, 5, 6, 7, 8, 9, 10}, 964; AB: {2, 8, 1O}, 585; ABD: {8}, 205; ABC: {2}, 195; AD: {I, 6, 8, 9}, 485; AC: {l, 2, 5}, 310}; B: {2, 4, 8, 10}, 810; BD: {8}, 205; BC: {2}, 195; D: {I, 3, 6, 8, 9}, 595; DC: {l, 3}, 190; C: {l, 2, 3, 5}, 422}.

Then, scan database once again to compute the actual utility of candidate itemsets. The high utility itemsets are {E: 300; EA: 245; EAB: 355; EABD: 205; EAD: 255; EB: 560; EBD: 195; ED: 300; AB: 490; ABD: 195; ABC: 195; AD: 200; B: 600; BD: 185; BC: 175; D: 175}.



IV. PERFORMANCE EVALUATION  In this section, we evaluate the performance of our algorithm Udepth and compare it with Two-Phase [4] and HUC-Prune [7]. First of all, we introduce the datasets that used to do the experiments. Then the experimental results of runtime and scalability are discussed.

A. Exp er imental Envir onment and Datasets The experiments were performed on a 2.40 GHz CPU with  2 GB memory, and running on Windows XP. Our programs were written in C++. Both synthetic and real datasets are used to evaluate the perfonnance of the algorithms. We generated two synthetic datasets from IBM data generator [1]: Tl0I4D100k and T20I4DlOOk. The parameters are described as follows: D is the total number of transactions; T is the average size of transactions; 1 is the average length of maximal pattern; N is the number of distinct items. Real dataset mushroom is downloaded from Frequent Itemset Mining Implementations Repository [12]. Table V presents the characteristics of the datasets used in the experiments.

TABLE V.

Datasets  TlOI4DI00k  T20I4DlOOk  mushroom  CHARACTERISTICS OF DAT ASETS  T     D  100,000  100,000  8,124  N     These datasets do not provide utility value or quantity of each item in every transaction. In order to fit them into the scenario of high utility item sets mining, we randomly generate the quantity of each item for each transaction, ranging from 1 to 5 and the numbers for the utility values ranging from 1.0 to 10.0. Observed from real databases that most items carry low profit, we generate the utility values using a log normal distribution. Fig. 1 shows the external utility distribution of 1000 distinct items.

120 ? 110 / ? 100 I 90 ?   I 70 60 ?  / 50 ? 40 ? / 30 ? / 20 ?  I  ?  External Utility  '\, r \, \ \ . . \  \ . . \, ????  Utility Value   Figure 1. External utility distribution for 1000 distinct items  B. T h e  Runtime All of the figures use total running time as the performance  metric. Because all of the datasets are relatively small, the time to load and prepare the data is negligible and, therefore, the total running time reflects the algorithmic performance only.

? 350 <.> <I> C/) Q;' 300 E i= 250 <: o '? 200 <.> <I> U:i 150    5.0  T1014D100k  --UDepth  ----0- H U C-Prune -----b--- Two-Ph ase  4.5 4.0 3.5 3.0 2.5 2.0 1.5 1.0  Minimum Utility Threshold(%)  Figure 2. Execution times on Tl0I4DIOOk    2000 T2014D100k  1800 ---- UDepth --0-- HU C-Prune  1600 ---l:r-- Tw o-Phase  U 1400 <I> (/) '$ 1200 E i= 1000 I: . 2 ::; 800 <..> <I> x 600 W    8.0 7.5 7.0 6.5 6.0 5.5 5.0  Minim um Utility Thresh old(%)  Figure 3. Execution times on T2OT4DIOOk  Fig. 2 and Fig. 3 show the results of run time comparison on two synthetic datasets. These datasets normally have too many distinct items. Although in the average case their transaction length is small, they normally have many transactions. As described in previous work [2, 7], handling many distinct items is a severe problem in generation-and-test algorithms, which makes the Two-Phase algorithm taking much more execution time than our proposed algorithm.

Furthermore, as the data sharing may be rare in these two sparse databases, the compression factor of tree structure could be small. Thus, the proposed UDepth algorithm is also much faster than HUe-Prune.

4000 mushroom  3500 -UDepth  -0- HUC-Prune  3000 --l:r--- Two-Ph ase  ? <..> 2500 <I> (/) '$ E 2000 i= I: .2 1500 ::; <..> <I> 1000 x  W    30 25 20 15 10  Minimum Utility Threshold(%)  Figure 4. Execution times on mushroom  Fig. 4 shows the results of run time comparison on real dataset mushroom. Real datasets have many long frequent as well as high utility itemsets. In mushroom, the performance of Two-Phase is also much worse than those of UDepth and HUe-Prune. But the gap between UDepth and HUe-prune is not as obvious as in synthetic datasets. Because the probability  of an item's occurrence is very high in every transaction, which makes tree structure achieving high compression ratio.

C. Scalability We test the scalability using the dataset series T20I4D I 0-  lOOk with base sizes from 10k tuples to lOOk tuples, and the dataset series Tl0I4DIOOkNIOO-500k with number of items from lOOk to 500k respectively. They are all generated by ruM data generator [I] .

U <I> 1200 (/) '$ E 1000 i= I: 800 .2 ::; <..>  600 <I> X  W     U 200 <I> (/) '$ E i= 150 I: 'S <..> 100 <I> X  W   T2 0 14D 10 k-1 OOk  ---UDepth  ---Q--- HU C-Prune  ---l:r-- Tw o-Phase  10 20 30 40 50 60 70 80 90  Number of Transaction(k) Minimum Utility Threshold=5%  Figure 5. Scalability comparison on T20l4DlO-IOOk  ?   T 1 014D 1 OOkN 1 00-500 k  -UDepth  -0- HUC-Prune  --l:r--- Two-Pha se  . -- . ? .---"'  ?  450 400 350 300 250 200  N umber of Item Minimum Utility Threshold=3%  ?   Figure 6. Scalability comparison on TlOI4DlOOkNIOO-500k   -   From Fig. 5 and Fig. 6 we can see that, in comparison with Two-Phase and HUe-Prune, UDepth not only runs faster, but also has better scalability in terms of base size and item size: the slope ratio of UDepth is lower than those of Two-Phase and HUe-Prune. Thus, the utility mining methods with UDepth significantly reduced the running time while offering linear scalability, especially on the dataset series by varying the number of transactions.



V. CONCLUSIONS AND FUTURE WORK  In this paper, we propose an efficient algorithm named UDepth for mining high utility itemsets from transaction databases. We use the vertical data representation in this algorithm, which quickens the process of identifying HTWUIs.

The experimental results show that UDepth outperforms the Two-Phase and HUC-Prune algorithms both in efficiency and scalability.

In our current algorithm, the database is stored in main memory using the vertical database layout and the transaction? weighted utilization of an itemset is computed by intersecting the covers of two of its subsets. Although UDepth shows performance improvements, this is not always possible since the total size of all covers at a certain iteration of the local itemset generation procedure could exceed main memory limits.

So to investigate an efficient out-core algorithm for mining high utility itemsets is our future work.

