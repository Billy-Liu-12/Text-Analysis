Research on Association Rules Mining Algorithm With Item Constraints

Abstract The issues in the Jield of association rules mining  with specific items are discussed first. To solve the problems in the ordinary algorithm, we put forward a new but efticient mining algorithm with item- constraints, called EclatII. We then give an analysis on the performance of the algorithm as well as on its strategy. The experimefital result shows that the Eclat11 algorithm is more robust in items of using "low support"" and "long pattern" association rules than others.

Key words: data mining; association rules; item constrains; frequent item-set; lattice theory  1. Introduction The topic of association rules mining is one of the  important data mining subjects['], which aims at exploring the association or relation of item-set on transaction database or relational databases. For instance, "if 90% of potential customers purchase product A, then they would also purchase product B." This statement exemplifies the association rules. A typical application of the association rules mining is to analyze the sale. Though the mining algorithm based on association rules have solved the problem of how to step up the generation of frequent item-set eff i~ientl~[ '~[~~[~I,  in reality, we will have to deal with the massively increasing rules which can't be tackled by ordinary mining methods due to the expanding of a databases over time. So in application, the user is normally interested in a specific subset of association rules rather than the total association rules, as it is more convenient for the user to go through the rules where the number of the rules has been trimmed down.

Thus, introducing some proper constrains in the algorithm can effectively guide the mining process thus making it more efficient. So, it is necessary for the user to settle these problems via the exploration of association rules mining and the specific item or item- set.

The first problem to be solved by using the association rules mining is locating all frequent item- sets in the transaction database rapidly. Efficiency is a  key concern in performing the algorithm. Some researchers, such as Agrawal, propose several mining methods on processing the item  constraint^[^]. One method, simply titled Direct algorithm, directly generates the candidate set. However, if the candidate set contains a larger number of element, the performing algorithm's efficiency will decrease while computing the "support" for the item-set. The Eclat algorithm proposed by Zaki is a counter-part of classical Apriori algorithm, which greatly enhances the performing efficiency. However, the Eclat algorithm does not solve the association rules mining problems when using constraints. In this paper, we mainly discuss the method of introducing the item constraint into an Eclat algorithm, adopting the vertical structure database and conceptual lattice theory to partition the candidate set into small sub- grids. Then, we utilize the co-relation among the neighboring grids to conduct item-set pruning. As each sub-grid is designed to be processed separately in memory, we in turn reduce UO costs, allowing us to maximum frequent item-sets while simultaneously the association rules mining problem with item constraint, "low support", and "long pattern" can be efficiently solved by this EclatII algorithm given in this paper.

2. Constraint algorithm in association rules mining  2.1 Constraint algorithm Direct based on Apriori  Let Ck be the set which includes all of the possible k item-sets, which we call the candidate set of frequent k-item-set, represented as  C, = {X 11 XI= k,sup(X) 2 min-sup) This formula indicates that all lengths of the K-1  subsets in X are recurrent, but X itself must be tested for frequency by scanning the database.

The number of scanning the database in Apriori algorithm is determined by the length of the maximum frequency sets. There are two phases in each scan: In first phase, the Ck is created by Lk-, which is obtained     by the k-l'th scanning, ie., by generating an element in Ck using connection of two randomly chosen elements in Lk-/ which are the same as the elements in the number of K-Z items. The creation of an algorithm for this candidate set guarantees that Ck is the super set of Lk. In the second phase, the database is scanned, and the elements in the candidate set contained in each record are determined by utilizing the data structure of Hash-Tree. The counter of these elements is increased by I .  After scanning all of the records, we can determine which item-set is frequent through examining the element counter in the candidate set.

The creation of the candidate set utilizes the property called Apriori, which formulates that if an item-set is frequent, then all of its subsets are also frequent. The creation of Ck process follows:  1) the join step among the elements of Lk-I.

2) the k'th item set will undergo the prune step  created by the join step.

Assuming all items are ordered alphabetically, the  following SQL-like language specifies the method of  Inset into Cwl Select p.iterm, piterm, ... , p.item-I, q.item.1 From P, q  One must verify that all I subsets are within Lk-I in the joint set. If this is not the case, then the element should be eliminated. We use the following example to illustrate the process.

Example1 Let L3={ {a b c), {a b d), {a c e), {c b d) ), after join step process, we get C4, C4={ {a b c d), {a b c e) 1. The prune set eliminates the element {a b c e), since its subset {a b e) is not involved in Lj. So we eventually have C4={{a b c d) ).

If an item constraint exists, the above mentioned operation is incomplete. For example, we are only interested in mining the association rules containing item 2: L2={ {a b), {b c) ). But if the joint step is to generate the element {a b c), we require {a c) to be in L2. {a c)  is eliminated from Lz due to the existence of the constraint. Therefore, the algorithm of association rules mining must be modified. Thereafter, we will discuss a variety of mining algorithms with item constraint.

There are normally three processing item constraint methods, 1) Multi-joints, 2) Recorder, and 3)  Direct. The first two methods are similar in performance since they have the same item-sets in computing the "support". They all adopt the following method: creating a selected item-set S based on B, and then generating all the item-sets meeting S. For example, each item-set contains at least one element from S, finally filtering these item-sets with B. This  method is in-efficient, since too many elements exist in the candidate-set due to usage of constraint B to generate the candidate setIS1. In contrast, the Direct algorithm has a rather high efficiency rate due to the utilization of constraint B to directly generate the candidate set. The algorithm is based on the following facts:  Any k+l item set X which meets the constraint B contains at least a K item subset which meets B, unless each disjunction D with the truth value of true in X has exactly K+I non-negative elements.

Assume that I={a b c d e), B=(a A b) V (d "7 e), and all of the items in I are frequent, then we get L: ={{d)). To generate cZb, first we need to perform L: X F resulting { {a b) {b d) {c d) {d e) 1. As {d e) does not satisfy B, {d e) {prune 1 )  should be deleted. Prune 2 does not play a role of pruning for c:, since all item subsets satisfying B are frequent. At last, we put {a b) into c:, getting { {a d} {b d) {c d) {a b) ). L; can be obtained through computation of "support" for the elements in the set. When the iteration ends, all the frequent sets satisfying B can be obtained.

Through analysis, we find an existing defect when using the method ck: = L~~ x F for generating candidate-set in Direct algorithm. For example, we still have too many elements in the candidate-set. To perform "support" computation for a larger number of item-sets, we would have to lower the algorithm's efficiency.

2.2 Eclat method based on conceptual lattice theory  Direct constraint algorithm belongs to the class Apriori mining algorithm. Though introducing the item constraint can speed up the algorithm performance and make the mining result meet the user's requirement, Direct algorithm also has a limit in the process of mining "low support", "long pattern" association rules. On the basis of Direct algorithm, Zaki has suggested Eclat algorithm[". By using the vertical database structure, and the equivalent relationship based on prefix, the whole searching space (conceptual lattice) is split up into smaller subsets (sub-conceptual lattice). Each sub-conceptual lattice can be processed in memory by performing the algorithm if the number of database scans is reduced, thereby greatly improving the efficiency of association rules mining.

Vertical tid-list database The so called vertical tid-list database means that  each record in the database is constructed by the item and all the existing transaction records. This makes any frequent set's "support" obtained through the operation on "meet" set. The transaction database in     table 1 illustrates an example of a database. Each un-frequent item sets. ABCDE denotes the top element record represents the author of the book purchased by in the conceptual lattice, and { ) denotes the bottom the customer. Table 2 illustrates its tid-list format element. The connecting line in the picture is drawn (assume that ABCDEF represent the first letter of six in a top-down way. The nodes from which the solid authors' names respectively). lines lead out are frequent, and those from which the  Table1 tramaction database dotted lines lead out are un-frequent. The largest Tld Transactron Id 14 recurring lines in the picture are {ABDE). The following lemmas are given by Zaki. They  form an important foundation for computing item set 4  A B C E 5  A B C D E  support.

6  B C D F  Lemma 1: For any XE P, i f X = U  y g  .,I: then  Table2 the verhcal form of the table1 Items Trd-bt  I&=l U Y E J L O  I .

A  1 3 4 5  In lemma 1, if X can be expressed by a join-set of B 1 2 3 4 5 6  the elements in J, then we can compute the X's c 2 4 5 6  "support" by computing the meet-set of these D  1 3 5 6 E 1 2 3 4 5  elements' tid table. Here, J={ YE A(P(I)))I Y I X) conceptual lattice theory indicates the set constituted by atoms of P ( ' .  I@)  For set I, the ordered set P@ denotes the power set represents the " su~~or t "  for X, and represents the of set I. In the case that the bias-order has set tid  containing relation ?6 and "meet" ( A  ) and "join" ( V ) Lemma 2: all of the subsets of the frequent set are  operations are "disjunction" and "conjunction" frequent.

respectively. Any subset of Po) is called a complete This deduction is inferred based on the fact that the  conceptual lattice if the P(I) satisfying "join" and "meet" operation of the fi.equent set is closed. This is  "meet" operations. The set constituted by all frequent a solid foundation of prune set in the process of  sets is "semi-meet" conceptual lattice. The set frequent computing. As any "support" of K item-set  constituted by all un-frequent sets is semi-join can be computed through the "meet" operation of tid table between any two K-1 subsets, for computing all conceptual lattice, since the set constituted by all  frequent sets is closed through the meet operation. For the frequent sets in PQ), a direct way is to compute the  example, any meet of two frequent sets is still a "support" of all the item-sets fiom bottom to top, layer by layer. Meanwhile, all the frequent sets satisfying frequent set. Whereas, any join of two un-frequent sets  is still an un-frequent set. the minimum "support" specified by the user can be  Picture 1 illustrates an example of a complete obtained. Actually, as P(7,J is larger, it is hard to put all  conceptual lattice P(I), where I is a set constituted by item sets' tid tables into the memory at the same time.

all of the items. Therefore, it is useless using the above method for AB large P o .  We get an idea of partitioning the space of  conceptual lattice constituted by P o .

We then split P(I) into [A],[B],[C].[D],[E] five  equal sub-conceptual lattices. The Eclat algorithm adopts a classification method based on prefix. For example, [C]={ {C) {C D) {C E) {C D E) ). After Po) is split up into smaller sub-conceptual lattices, each equivalent class will be processed using the Eclat algorithm in a counter order of the classification, aiming at performing the prune operation for all  F r n  subsets. For instance, after the process of [El, we can use the element E from [El to prune the element DE . . . . I . , _ _ - *  -._ '. I ,' in [Dl. If E is infrequent, then DE is also infrequent. ?-... . ' 5 ~ -  ' * - - Therefore, there is no need to perform the L(DE)=L(D)~E(E) operation. By doing this, the number of operations of "meet" for corresponding tid  Picture 1 complete conceptual lattice P o  table will be decreased.

Compared with Apriori algorithm, the operating  In the picture, the closed item sets represent time of Eclat algorithm is decreased. Eclat algorithms frequent item sets, and the opened item sets represent are suitable for mining "low support" and "long     pattern" association rules. However, situations concerning item constraint pose unresolved issues.

Therefore, we have improved the Eclat algorithm and make it more optimal, and propose the algorithm Eclat fl , which tackles the problem existing in association rules mining with the item constraint.

2.3 Eclat II algorithm (1) implementing strategy  Normally, let I={ il,i 2,...,in} denote the set of all items. B denotes the Boolean expression of I, and the disjunctive norm B=DI A D2 A ... A Dm represent the item constraint B. Each disjunctive term D, can be expressed as a conjunctive norm, Kl A K2 A ... A K,.

Ordering operation: Take the first elements of conjunction from any two disjunctive items in B as the first class constraint. After introducing the first class constraint, the items in item-set I need to be ordered.

In ordering process, we first delete the disjunctive terms constituted by all the item's complement in B.

For example, say there are k disjunctive terms; we take all the first elements as the first m-k elements of I and order it alphabetically. The remaining n-(m-k) elements in I must also be alphabetized. After re- ordering the items in I, the order of the disjunctive items in B should be the order of first elements of first m-k disjunctive items. Each disjunctive item is then ordered according to order of I.

Lemma 1: assume that B belongs to the first class constraint. After obtaining frequent set of each disjunctive item, we obtain all the frequent sets which satisfy the constraint B.

em ma 2: the frequent set of each disjunctive item in B must be contained in equivalent class corresponding to the first term of the disjunctive items.

If m disjunctive items exist in B, then all the frequent sets to be obtained to satisfy the constraint must exist in the first m equivalent classes in P(0.

These two lemmas show that we can decompose the disjunctive item satisfying the constraint B into the corresponding equivalent class. The performed ordering operations guarantee that the disjunctive items in B will be ordered in front equivalent classes.

The closer an equivalent class is placed to the front, the more item sets will exist. Additional work needs to be done concerning the "meet" operation between the tid tables. Therefore, the algorithm's efficiency can be raised by adding constraints in the large equivalent classes. In Eclais numerating method for frequent 'top-down' sets, the iteration decomposing method is adopted when processing each equivalent class. This method decomposes large classes into small equivalent classes. Numeration, allows the "meeting" set of all  the atomic terms in each equivalent class, to be layered, because we know that the first corresponding disjunctive item in first-class constraint decomposes into the corresponding equivalent class. We make the searching space smaller for the equivalent class corresponded by single a disjunctive item.

Pruning method: for above mentioned conceptual lattice, assume that B=(A A B A C), P(4 is still a conceptual lattice, and the first term of the disjunctive item in B is A. According to the above statement, all the frequent set satisfying B must be contained in the equivalent class (A). When enumerating two item sets, we numerate all the two item sets containing A. When enumerating three item-sets, we enumerate all three item sets containing AB. When enumerating four item-sets, we enumerate all item sets containing ABC.

The reason for doing this is that we can pass through all frequent sets satisfying the disjunctive item through the "meet" computation among the atomic terms from top to bottom.

Theorem 1 : the pruning method used in conceptual lattice space guarantees that top to bottom search methods pass through all the frequent sets satisfying a single disjunctive item constraint.

The proportion of the pruning: the ratio of the item set number in [A]- to those in[A].

Theorem 2: according to the above method and using disjunctive item (AI A A2 A ... A A,) to prune the equivalent class space of [A J ,  the pruning proportion must be [1/2(2n-m)(rn-l)+2""~/T-~, where n is the number of the items in I. When n>>m, the pruning proportion is about 2"".

Theorem 3: any item set with the length K+L in equivalent class [A J pruned by disjunctive item (A, A A2 A ... A A J can have the form of XY, where the length o f x i s  ~ a n d ~ i & & , X ? @  ( A ~ A A ~ A . . . A A J ,  and the length of Y is L. The lost quantity of the subset with the length of K+L-I in the item set will be K-2 when L=l, and K-1 when L>1.

(2) Description of the algorithm  The search algorithm adopted is the same as Eclat for the equivalent class without the disjunctive constraint. The only difference is that instead of putting the frequent-set of the equivalent class into the set of frequent-set, we need to mark which of these are frequent and which are not. For equivalent class with constraint, we adopt the Eclat 11 algorithm.

From the above algorithm, we can see that K+L>>K-2 and K-1 hold under the circumstance of the longer frequent set existing in the database.

Although there few subsets are lost and cannot be pruned, the operation of pruning is still efficient due to the existence of the most existing subsets. However,     when L is small, the increase of the number of the subsets lost will lead to the extra computation cost.

The enumerating space shrinks when using the item constraint, though the algorithm is still efficient.

3. Comparison of the algorithms We now introduce a comparison among the number  of candidate sets obtained by performing the algorithms Eclat II, Recorder, and Direct. The reason for doing this is that the quantity of the candidate sets in association rules mining will be the key factor affecting the speed of performing the algorithm. The larger the candidate set, the more complex the computation. The main differences of the algorithm is as follows:  1) When the Recorder algorithm needs to generate an additional chosen item set S, such as B=(1 A 2) V (3 A 4), according to the constraint, the chosen item set may be {1,3}. When the contrary item is contained in B, the size of S may approach item set I. Whereas, the Eclat fl algorithm can generate Ck by using Lk which is consistent with the equivalent class in B. In this way, the number of processing the candidate item sets can be reduced.

2) Although the Direct algorithm has adopted the method of directly generating the candidate item set, the number of the candidate item set to be processed compared with Eclat 11 algorithm is quite large. Since the longest length satisfying the pattern in B is L e n ~ and the longest length contained in B itself is L e n ~ , then we have LenaiienD. For the candidate item set with a length greater than LenD+I, we still adopt the method LBKx F in Direct algorithm to generate the candidate item set. Whereas in algorithm Eclat II, we use the kequent K-1 items' "meet" set to generate k item set. So the number of the candidate sets is reduced.

3)  The Eclat fl algorithm is based on the prototype of Eclat. Recorder and Direct are based on the prototype of Apriori. The former cannot use the Hash- Tree database structure, but rather utilizes the simple "meet" operation. Therefore, it is more robust and flexible, providing us with the following three advantages: 1) "low support", 2) "long pattern", 3) and larger databases. The number of database scans based on the algorithm Apriori depends on the length of the largest pattern. The algorithm Eclat 11 requires only two database scans. The number of database scans directly affects algorithm efficiency. Since we can partition the conceptual lattice space, the larger memory space can hold the entire sub-conceptual lattice and the performance efficiency thus improved.

The following examples illustrate the differences among these algorithms. Assume B=(I A 2). In general, the chosen item set in the algorithm Recorder is S, and LI-L3 indicate sets kom frequent item set 1 to frequent item set 3, where:  S={I} LIE{ {1},{2) ,..., {300) ) L,={{l 2),{1,3} ,....{I 30) ) L3={{1,2,3),{1,2,4} ,..., {1,2,5) 1 We assume that the frequent 4 item set is not  included in the data set.

4. Conclusion By introducing the constraints in association rules  mining, the process of mining can be performed to meet the main requirement of the user. This deters superfluous mining. The association rules mining with item constraint is a hndamental rule in mining. Our research augments and completes the related techniques in association rules mining. Additionally, our methods develop and inherit the research methods in association rules mining, playing an important role in research and application on association rules and data mining. Continued development of high performance algorithms is key in ensuring efficient association rules mining techniques.

