Performance Evaluation of Distributed Algorithms  for Mining Association Rules on Workstation Cluster

Abstract  The mining of association rules is one of the database mining techniques used to extract useful in- formation f rom large quantities of data. Finding as- sociation rules, however, requires that the transaction database be scanned repeatedly, and we need to handle very large amounts of transaction data. This requires an incredibly large amount of computation time. There have therefore been many attempt.9 to speed-up database mining by using parallel computers. Recent improve- ments in the performance of PCs and workstations (WSs) ,  and the recent dissemination of network tech- nology have made parallel processing distributed within computer clusters an attractive alternative to parallel computers.

In this paper we describe two new algorithms effec- tive for  parallel processing distributed in a WS clu.9- ter environment. One is an algorithm in which the size of data transmitted between WSs is smaller than that of the former algorithm. The other is an algo- rithm that reduces the number of scan processings at each node by dividing data and that uses shift opera- tions for  data communication. W e  have implemented these algorithms on  a WS cluster and have evaluated their performance.

1. Introduction  The amount of data accumulated by enterprises and individuals has recently become enormous. This is a re- sult of the development of such computer technologies as microprocessors, storage devices and computer net- works. Database mining is one of the methods used to search large databases for useful information, such as rules or previously unknown relations between data items. One of the most important fields in database  0-7695-077 1 -9/OO $10.00 0 2000 EEE  mining is the discovery of association rules inferred from transaction databases. An association rule im- plies certain association relationships among sets of items, and several algorithms for the mining of associ- ation rules have been proposed(1, 2, 3). Some of them are parallel algorithms used to process large quantities of data efficiently by distributing the processing among the nodes of parallel computers 14, 5 ,  61.

On the other hand, the performance of the proces- sors in PCs and WSs has advanced rapidly and the prices of PCs and WSs has fallen. Furthermore, the dissemination of network technologies has also reduced the cost of using high-performance networks. As a re- sult parallel processing distributed among PC and WS clusters has become an attractive alternative to parallel computers.

This paper describes new distributed algorithms ef- fective on W S  clusters and evaluate their performance.

One is the Count Communication (CC) algorithm that transfers small amounts of data between nodes and uses broadcast operations. The other is the Shift algo- rithm, which reduces the number of scan processings needed at each node by dividing data and which uses shift operations for data communication. We also im- plemented these algorithms on an SR2201 distributed- memory parallel computer and compared their commu- nication cost and search cost in that environment with the corresponding costs in the cluster environment.

The rest of the paper is organized as follows. Section 2 gives an overview of the mining of association rules and of the Apriori algorithm on which our parallel algo- rithms are based. Section 3 describes an earlier nonpar- titioned Apriori algorithm and also describes the CC and Shift algorithms. Section 4 describes the experi- mental environment, and Section 5 presents the results of the performance measurements. Section 6 discusses the experimental results, and Section 7 concludes by very briefly summarizing its results and mentioning some future work we intend to do ourselves.

2. The mining of association rules  Association rules show relationships between items or itemsets. For example, consider the following rule: ??SO?% of customers who purchase bread and butter also purchase milk.?? This association rule may be used for actually digging up the combination pattern of pur- chase items through an analysis of POS (point-of-sales) systems at retail stores. The results of such an analysis can be used when planning advertisements, the layout of items at various stores, and so on. Since association rules cannot be found without scanning the transaction database repeatedly, the mining of association rules in- curs a very high processing load and a large execution time.

2.1. Association rules  We first review some basic concepts of association rules here. Let I = {il, i2,. . . , im} be a set of items and let D = { t l ,  t z , .  . . , tn} be a set of transactions, each of which consists of a set of items such that T E I. We say each transaction T contains a set of items S if X I.

The itemset S has support s ( s = support(X) ) in the transaction set D if s% of transactions in D contain

X. An association rule is an implication of the form S + Y, where X? c I,E? c I and X - n l ?  = Q. Each rule has two measures of value, support and confidence.

The support of rule X Y is support(X U Y). The confidence c of the rule X + Y in the transaction set D means c%# of transactions in D that contain X also contain Y. That is,  S U p p O T t ( X  U E?) .%Lpp0?.t(X)  confidence(X =+ Y) x 100. (1)  When mining association rules, we need to find all the rules that satisfy the user-specified minimum sup- port and minimum confidence. This can be decom- posed into two subproblems:  Find all sets of items (itemsets) whose support is greater than the user-specified minimum support.

Itemsets which satisfy the minimum support are called large itemsets.

Generate from these itemsets the association rules whose confidence is greater than the user-specified minimum confidence.

2.2. Aprior i  a lgori thm  One of the algorithms most widely in the mining of association rules is the Apriori algorithm for finding  all large itemsets [l]. The first pass of the algorithm simply counts the number of item occurrences to deter- mine the large itemsets having one item (called large 1-itemsets).

A subsequent pass, say pass k, consists of two phases. First the large itemsets found in the (k - 1)th pass are used to generate candidate itemsets produced by combining of the large (k - 1)-itemsets. Then the database is scanned to determine the support of these candidate itemsets. For all passes k > 1, the algorithm works as follows:  1. Generate the candidate k-itemsets using the large (k - 1)-itemsets created at the end of pass k - 1.

2. Scan the transaction database and count the num- ber of occurrences of the candidate k-itemsets, and compute support.

3. Let the large k-itemsets be candidate k-itemsets which satisfy the minimum support.

4. The procedure terminates if the large itemset is empty. Otherwise k := k + 1 and go to  step 1.

3. Parallel algorithms  3.1. Former parallel algori thms  Several researchers have proposed parallel algc- rithms which execute the Apriori algorithm shown in Section 2.2 [4, 5, 61. Assuming that transactions are evenly partitioned into each node in advance, these par- allel algorithms use the following four steps to find the large itemsets.

1. Each node generates the candidate k-itemsets by using the large (k - 1)-itemsets created at the end of pass k - 1 and copied into each node.

2. Each node counts the number of occurrences of the candidate k-itemsets using its local transactions.

3. All node?s local counts are gathered, merged, and checked to determine whether or not the minimum support condition is satisfied.

4. If large k-itemset is empty, the algorithm termi- nates. Otherwise k := k+ 1, the large itemsets are copied into each node, and go to step ?1.?  Next, we introduce the earlier non-partitioned Apri- ori (NPA) algorithm which uses the notation in Table 1.

In this algorithm the candidate itemsets are copied over all the nodes. Each node counts the number of     k-itemset L k  Ck Cl I j - th  node.

1 The local transaction datasets of the 03  An itemset having k items.

Set of all large k-itemsets.

Set of all candidate k-itemsets.

The local candidate E-itemsets of the  Xi  occurrences of itemsets using its local transactions, and one node gets global counts and the large itemsets by merging local counts. The processing of pass k is as follows:  j- th node.

The number of occurrences of the can- didate k-itemsets at the i-th node.

Each node generates the candidate k-itemsets C b by using the large (k - 1)-itemsets L(k-l) created at  the end of pass k - 1 and copied into each node.

Each node counts the number X k  of occurrences of the candidate k-itemsets by scanning the local transactions.

All node's local counts are gathered, merged, and checked to determine whether or not the minimum support condition is satisfied. Those for which the condition is satisfied are large k-itemsets L k .

If large k-itemset L h  is empty, the algorithm ter- minates. Otherwise k := k + 1, the large itemsets are copied into each node, and go to  step 9.''  A problem with the algorithm is that the number of scans increases when there are many candidate item- sets.

3.2. Algorithms for cluster-based parallel dis- tributed systems  Since algorithms mining association rules process the mining of large itemsets from candidate itemsets, they need to refer to large itemsets of the previous step frequently. Therefore the search cost becomes very large. And when this processing is executed in par- allel, the communication cost becomes very large. The former NPA parallel algorithm reduces the communi- cation cost by copying all of the large itemsets of the previous step into each node. Then each node executes the same operation individually and generates candi- date itemsets locally.

These algorithms are applicable to parallel comput- ers whose communication between processors is fast.

Communication delay becomes a problem when they are executed on cluster-based parallel distributed sys- tems where nodes are PCs or WSs connected via Eth- ernet. We developed two algorithms to reduce the com- munication cost and evaluated them on a cluster-based environment.

3.2.1. Count communication algorithm. The Count Communication(CC) algorithm does not broad- cast the large itemsets to all the nodes but instead broadcasts the global counts because data size is smaller. Each node has the large itemsets which sat- isfy user-specified minimum support. The processing of pass k in CC algorithm is as follows.

1. Each node generates the candidate k-itemsets Ck by using the large (k - 1)-itemsets L ( k - l )  created at  the end of pass k - 1 and copied into each node.

2. Each node counts the number of occurrences of the candidate k-itemsets using its local transac- tions.

3. All node% local counts are gathered and merged a t one node, and the global count S k  is broadcasted to all the other nodes.

4. Each node checks to determine whether or not the candidate k-itemsets in Ck satisfy the user- specified minimum support.

5. If large k-itemset L k  is empty, the algorithm ter- minates. Otherwise k := k + 1 and go to step "1."  candidate  (D )  Figure 1. CC Algorithm.

3.2.2. Shift algorithm. When transmitting transac- tion databases, Shift algorithm does not execute broad- cast operations but instead does shift operations. The processing of pass k in Shift is as follows:     1. Each node generates the candidate k-itemsets Ci by using the large (k  - 1)-itemsets L(k-1) created at the end of pass k - 1, and the candidate k- itemsets Ck are partitioned into each node.

2. Each node counts the number Xi of occurrences of the candidate k-itemsets using its local trans- actions, and shifts the transaction database Dj to the next node. The transactions transmitted from other nodes are executed similarly.

3. After scanning all the transaction data, each node determine individually whether or not the candi- date k-itemsets C'; satisfy the user-specified mini- mum support.

4. If large k-itemset Lk is empty, the algorithm termi- nates. Otherwise k := k+ 1 and the large itemsets are copied into each node and go to step "1."  Table 2. Variables.

variable interpretation  CAN Size of candidate itemsets Size of counts Number of transactions Number of nodes  CC Algorithm: This algorithm broadcasts only the counts. There- fore, the amount of communication MFc in pass k is as follows:  Figure 2. Shift Algorithm.

3.3. Cost analysis  This section analyzes the communication cost and the search cost for the NPA, CC, and Shift algorithms.

3.3.1. Communication cost analysis. The com- munication cost is the total amount of data which are transmitted among nodes in one pass of the mining of association rules.

NP.4 Algorithm: This algorithm incurs communication costs when counts are merged and when the large itemsets are broadcasted. The amount of communication Mrp4 in pass k is as follows:  ivIfP4 = LARk X ( P  - 1) + nk (2) This equation and the following equations in this  subsection use the variables listed in Table 2.

Shift Algorithm: This algorithm transmits data  when shifting all transaction data and merging counts. The amount of communication in pass k is as follows:  Since the count size is less than the size of large item- sets or the size of all transactions, the amount of com- munication iWF" is smaller than L%f2p4 and Mfhift.

3.3.2.Search cost analysis. The search cost is the total amount of data which are searched at all nodes in one pass of the mining of association rules. Paral- lel algorithms generate candidate itemsets using large itemsets, search the candidate itemsets in transaction databases, and count the number of candidate item- sets.

NPA Algorithm: In this algorithm each node computes the all can- didate itemsets, and one node generates the large itemsets. The search cost S r P A  in pass k is as follows:  SFp4 = c.4ivk X P f L.4Rk ( 5 )  CC Algorithm: In this algorithm each node computes the all can- didate itemsets, and all nodes generate the large itemsets. The search cost SEc in pass k is as fol- lows:  sFc = C-AXk X P 4- L-4Rk X P = (c.4Lvk f L.4Rk) X P (6)     Shift Algorithm: This algorithm computes the candidate itemsets partitioned into each node, and one node generates large itemsets. The search cost S f h i f t  in pass k is as follows:  CAXk q ' f t  - x P + L4Rk - P  = C-4iVk -t L.4Rk ( 7)  The search cost Szhif* is smaller than SrP" and S,Cc. And because each node computes the all candi- date itemsets and all nodes generate the large itemsets in CC algorithm, SFc is greater than either S c P A  or S f h i f t .  Since each node executes the search processing at almost the same time, the search cost does not show the computation time of each algorithm.

4. Experiments  4.1. Experiment environments  We implemented the NPA, CC, and Shift algorithms on a W S  cluster and on the parallel computer SR2201.

WS cluster: Our U'S cluster comprised thirty-two 5OOMHz Al- pha 21164 WSs connected via a 100Mbps Ethernet LAN.

Parallel computer SR2201: The SR2201 is a distributed-memory parallel com- puter which nodes are connected via high-speed three-dimensional crossbar switch networks. We used a SR2201 with 16 nodes.

4.2. Programming environments  We implemented the algorithms by using C-based XIPI (Message Passing Interface) programming li- braries. The MPI was designed for efficient and re- liable communication and it can be implemented on many platforms.

4.3. Execution of parallel algorithms  We used transaction datasets comprising 10000 transactions, the average length of the transactions was 5 and the number of items was 50. With the similar- ity of POS ID, we used natural numbers as items of transactions. The datasets were partitioned into each node.

In the experiments reported in this paper) we varied the number of transactions, the minimum support, and  the number of nodes. The experiment was executed 10 times for a pair of fixed values of the number of transactions, the minimum support and the number of nodes, and the minimum execution time was reported.

5. Performance evaluation  5.1. Relation between execution time and min- imum support  In Figure 3 the execution time of the three algo- rithms is plotted against the minimum support. These results were obtained on the W S  cluster when the num- ber of nodes was 8 and the number of transactions was 5000. It shows that when the minimum support is  NPA __ cc -  \. Shin - 4.5  3.: t  0 '  I 1 1.2 1.4 1.6 1.8 2 2.2 2.4  minimum suppott(%)  Figure 3. The execution time vs. minimum support.

small, Shift algorithm is superior to NPA and CC algo- rithms. It also shows that when the minimum support is small, the execution times for NPA and CC rapidly increases. On the other hand, the execution time for Shift does not increase as rapidly as do the execution times for NPA and CC.

5.2. Relation between execution time and the number of transactions  The execution time and the communication time for three algorithms are plotted against the number of transactions in Figure 4. These results were obtained on the U'S cluster when the number of nodes were 8 and the minimum support was 1% This figure also contains the exection time of a sequential algorithm.

The  execution time for each parallel algorithm is plot- ted in Figure 5 as a percentage of the execution time for the corresponding sequential algorithm. Figure 4      Number of nodes  Number of nodes  1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 amount of transaction  WS cluster NPA CC Shift 0.148 0.117 0.258 2.180 2.180 0.766 1.855 1.855 0.469  SR2201  0.369 0.356 0.889 0.385 0.385 1.114 0.378 0.378 0.842  Figure 4. The execution time and the commu- nication time vs. the number of transactions.

3 140 160 i Shin . cc - i  - _ .  . -  1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 number of transactions  Figure 5. The ratio of the execution time for each parallel algorithm to the execution time for corresponding sequential algorithm.

shows that the execution time and the communication time for all algorithms increase in proportion to the number of transactions. The execution time for the Shift is shorter than those for the other algorithms.

The advantage of parallelization is evident when the number of transactions is more than 2500. Figure 5 shows that the ratio of the execution time of a parallel algorithm to that of a sequential algorithm decreases as the number of transactions increase.

5.3. Relation between execution time and the number of nodes  The execution time and the communication time of three parallel algorithms on the WS cluster when the number of transactions was 5000 and the minimum  support was 1% are plotted in Figure 6 against the number of nodes. For all algorithms the execution time     I 3 ._ E    2 4 8 16 32  number of nodes  Figure 6. The execution time and the commu- nication time vs. the number of nodes.

decreases when the number of nodes increases, whereas the communication time increases when the number of nodes increases. The performance of Shift algorithm is the best, and there is little difference between the performances of the NPA and CC algorithms.

5.4. Results on the parallel computer  The execution time and the communication time of the three algorithms running on the parallel computer when the number of transactions was 5000 and the min- imum support was 1% is plotted in Figure 7 against the number of nodes. The communication times for three algorithms running on the 11's cluster and on the par- allel computer are listed, along with the numbers of nodes, in Table 3.

Table 3 shows that the communication times for NPA and CC algorithms are shorter on the parallel computer than they are in the WS cluster environment.

NPA -- 1 EO 1  number of nodes  Figure 7. The execution time and the commu- nication time on the SR2201.

On the other hand, the communication time for Shift algorithms is shorter on the WS cluster than that on the SR2201.

6. Discussions  6.1. Execution on a workstation cluster  The execution times for NP.4 and CC algorithms increase rapidly with a decrease in the minimum sup- port. This is because the number of candidate itemsets increases when the minimum support decreases, and these algorithms scan the all candidate itemsets in the transaction database at each node. But because the Shift algorithm partitions the candidate itemsets into each node, the execution time of scanning is shorter than that for the other algorithms, and does not in- crease as rapidly when the minimum support decreases.

The execution times for all algorithms increase with an increase in the number of transactions, and the ra- tio of the execution time of each parallel algorithm to the execution time of the corresponding sequential al- gorithm decreases with an increase in the number of transactions. This ratio for the Shift algorithm reaches a minimum value when the number of transactions is 4000, and the algorithm converges more rapidly than the other algorithms.

The execution times for all algorithms decreases with an increase in the number of nodes. The re- duction of the communication time in Shift operations seems to be due to the scanning processing and com- munication processing being executed asynchronously.

Because data are searched in parallel and all amounts of searched data are almost the same for all these al- gorithms, CPU processing time which is the difference  of the communication time from the execution time is almost the same for all algorithms.

Our cost analysis showed that the amount of com- munication was smallest for the CC algorithms, but the execution times for NPA and CC algorithms were almost the same in our experiments. This seems to be because that the size of data used in our experiment is not so large.

6.2. Execution on the parallel computer  The execution times for all algorithms were much longer on the parallel computer than that were in the WS cluster environment. We think -this is because amount of CPU memory available on the parallel com- puter was insufficient. On the other hand, the com- munication time was more stable on the parallel com- puter, and the time for communication between nodes is shorter on the parallel computer. In other words, the ratio of the communication time to the execution time is large in a W S  cluster environment, and the commu- nication time has a great influence on the execution time.

In the W S  cluster environment, the communication time for the Shift algorithm, which uses shift opera- tions, is less than that for the CC algorithm, which uses broadcast operations. On the other hand, the commu- nication time for the Shift algorithm on the parallel computer is l age r  than that for the CC algorithm. The Shift algorithm is therefore effective in a LVS cluster environment that can execute shift operations rapidly.

7.  Conclusion  The distributed algorithms proposed in this pa- per are effective when parallel processing distributed throughout clustered computers is used to mine databases for association rules. When we implemented these algorithms on a SVS cluster and on a parallel com- puter so that we could evaluate their performance, we found that the Shift algorithm was the most effective when there was a large number of candidate itemsets and processor nodes in the WS cluster environment.

This is because the ratio of communication time to ex- ecution time is large in a WS cluster environment, and the communication time therefore has a great influence on the execution time.

We intend to perform more analysis about the com- munication cost between nodes. We also intend to per- form further experiments with large size data which are used at  companies and institutes. We also intend to develop a new algorithm to share the loads among nodes because real data are often distributed unevenly.

