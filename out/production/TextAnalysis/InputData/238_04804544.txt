Some Observations of Sequential, Parallel and Distributed Association Rule Mining  Algorithms

Abstract?This paper mainly focuses on the need, merits, demerits and designing of different Sequential,  Parallel and Distributed ARM algorithms developed so far on different hardware platforms and categorising them according to database format used, search techniques used and whether they find all or maximal frequent itemsets. The goal of this survey is to provide information that serve as a reference for both the researchers and practitioners interested in  the designing and implementation of ARM algorithms that has high performance in terms of response time and the ability to scale massive data sets with minimum communication overheads, privacy and security, which is the requirement of  today?s world.

Keywords-parallel data mining, distributed data mining, association rule mining

I.  INTRODUCTION Association Rule Mining (ARM) searches for interesting correlations among items in a given data sets and establishes an association between two non overlapping sets of frequently occurring values in a database. By finding association between the different items that the customer purchased ARM will analyze customers buying habits which help retailers in planning marketing or advertising strategies, catalog design, store layout, etc. e.g. If customer tends to buy laptop and wireless broadband connection together then sale on broadband connection may encourage the sale of laptop as well as broadband connection.

The configuration of this paper is as follows: In the first section, we differentiate between parallel and distributed system while in the second section, we present concepts of ARM. In the third section, firstly, we describe sequential ARM algorithms, their merits and limitations that focus on the need of parallel and distributed versions and discuss their merits and demerits. In the fourth section, we present the summary of all ARM algorithms discussed and at last give the conclusion.

Now a days, companies like Walmart, Sears, etc. already have data warehousing in the terabyte range and scientific data is reaching gigantic proportions e.g. NASA space missions, Human Genome Project etc., a lot of disk I/O is required to process such data causes increase in data in terms of both the dimensions or the number of items and the size or number of transactions. To handle these massive data sets ARM algorithm needs to be scalable. Sequential ARM  algorithms cannot provide the scalability, in terms of data dimension, size or the runtime performance for such a large database and leads to the requirement of high performance parallel and distributed computers to handle it [1].

Implementation of ARM in high performance parallel and distributed computing is thus becoming crucial for ensuring system scalability and interactivity as data continues to grow inexorably in size and complexity [2]. One can define Parallel and Distributed system as:-  Parallel System Distributed System -It deals with tightly coupled system including shared memory system (SMP), distributed memory machines (DMM) or cluster of SMP workstations (CLUMPS) with a fast interconnect.

-It deals with loosely coupled system such as cluster over a slow Ethernet LAN, geographically distributed sites over WAN like Internet.

-SMP offers programming simplicity but limits scalability due to finite bandwidth of a common bus.

-Programming is difficult. Message passing architecture cures the scalability problem by eliminating the bus.

It is ideal choice in organizations with centralized data stores.

-It is essential in cases where there are multiple distributed data sets.

Parallel data mining (PDM), developed on parallel system and distributed data mining (DDM), developed on distributed system, provides the ability to scale massive data sets and improving response time. To achieve good performance on today?s multiprocessor system both PDM and DDM faces challenges includes synchronization and communication minimization, work load balancing, finding good data layout, data decomposition and I/O disk minimization [2].



II. ASSOCIATION RULE MINING: BASIC CONCEPTS  Let J = {i1, i2,?.,im} be a set of items, D be a set of database transactions and T is transaction contains set of items such that JT ? . Each transaction is associated with an identifier, called TID. Let A, B be set of items and T is said to contain A, iff TA ? . An association rule is an implication of the form BA ? holds, where JA ?  and also JB ? and A?B is NULL. The rule BA ? holds in transactions set D with support s, where s is the percentage of both A and B. The rule has confidence c in the transaction set D if c is the percentage of transactions in D containing A that also contains B [3]. ARM is two step process:- 1. Find all frequent itemsets having minimum support.

DOI 10.1109/ICCAE.2009.28     2. Generate strong association rules having minimum confidence, from the frequent itemsets.

e.g. Let six customers purchased Bread (B), Butter (U), Egg (E), Biscuit (C) and Tea (A) in a glossary shop. Following figure illustrates the generation of frequent itemsets and association rule based on sale database D shown below and market basket analysis.

Let Database D based on purchase of items together by customers contains the following number of records.

Number of Transactions (T) made by customers  Items Purchased together in a transaction (J)  1 B E A U 2 E C U 3 B E A U 4 B E C U 5 B E C A U 6 E C A  Let an itemset be Frequent iff its min_support = 50%. From D we get:- Support in Percentage Frequent Itemsets  ( s>=50%) generated 100% (Present in all T) E 83%   (Present in 5 T) U, EU 67%   (Present in 4 T) B, C, A, BE, BU, EC, EA, BEU 50%   (Present in 3 T) BA, CU, AU, BEA, BAU, ECU, EAU, BEAU  Here Maximal Frequent itemsets generated are BETU, ECU (present in 3 T).

Following Association rules (with min_conf = 100%) are generated:-  (4/4) Both items present in 4 T  (4/4)  (3/3) All 3 items present in 3 T  (3/3)  B        E B        U B        EU C          E A          E  BE           U BU           E U        E (5/5)  BA           E BA           U CU           E AU           B AU           E   BA            EU BEA          U BAU          E EAU          B  Figure 1: Illustration of Association Rule Mining [1]

III. SEQUENTIAL, PARALLEL AND DISTRIBUTED ARM ALGORITHMS  ARM algorithms are characterized on the basis of Complete vs. Heuristic Candidate Generation, All vs. Maximal Frequent Itemset enumeration, Horizontal vs. Vertical Data Layout and Bottom up vs. Hybrid Search.

Different Sequential, Parallel and Distributed ARM algorithms designed with their characteristics are:-  A.  APRIORI, Sequential ARM algorithm -Proposed by Rakesh Agrawal and J. Shafer [14].

-It is mining single-dimensional, single-level and Boolean association rule from transactional database.

-It uses a complete bottom up search and horizontal data layout and generates all frequent itemsets.

-It?s an iterative algorithm that generates frequent itemsets by generating candidates.

-It involves 3 basic steps i.e.

(i)Generate candidates of length k from the frequent (k-1) length itemsets.

(ii) Prune any candidate with at least one infrequent subset.

(iii) Scan all transactions to obtain candidate supports.

-Merits (i) It?s  a simplest ARM algorithm designed so far.

-Demerits (i)Large number of candidate itemsets is generated.

(ii)Database is scanned at every step.

(iii)For m number of items 2m frequent itemsets generations are possible.

(iv)The number of database passes is equal to the largest size of the frequent itemsets.

It?s Parallel and Distributed Versions -On the basis of hardware platform used and decomposition involved, Apriori based parallel algorithms are categorised as:-   Distributed Memory System                                  Shared Memory System  Data Parallelism    Task Parallelism             Data Parallelism   Task Parallelism    CD, NPA, FPM        DD, Cand Dist., SPA              CCPD                 PCCD  HPA, IDD, HD Figure 2: Categorisation of Apriori based parallel ARM algorithms      FDM             ED-ARM           ODAM            Distributed Decision Miner  Figure 3: Apriori based distributed ARM algorithms   1)   Its Parallel version for Shared Memory System a) CCPD (Common Candidate Partitioned Database)  and PCCD (Partitioned Candidate Common Database) -Proposed by M. J. Zaki, M. Ogihara, S. Parthasarathy and W.Li.[1, 5].

CCPD PCCD -Similar to Count Distribution algorithm.

-Logical partition of database is done.

-Candidate itemsets are generated in parallel and are stored in a hash tree (HT) which is shared among all processors.

-Each processor then scans its logical partition of the database and atomically updates the counts of candidates in share HT.

-It additionally uses short circuit join and HT balancing to enhance the performance.

-Merits (i) Able to speedup processing.

-Demerits (i) Serial I/O depreciates the performance.

-Processor constructs disjoint candidate trees and scans the entire database to get candidate support.

-Demerits (i) I/O overhead and disk contention for PCCD was unacceptable, resulting in slow-downs on more than one processor.

2)  Its Parallel version for Distributed Memory System  a) Fast Parallel Mining (FPM) -D. Cheung and Y. Xiao proposed FPM [8, 16].

-The first step is same as Count Distribution algorithm.

-In addition to L1 (local frequent) each processor also computes GL1(i) (global frequent) for 1<=i<=n.

-After computation of candidate set it will do distributed pruning then global pruning to prune the candidates in CGk.

-After that it scans database partition Di to find out the local support count and the global support count for all remaining candidates.

-It will compute GLk(i) (global frequent for partition Di) and support and exchange the result with all other processor.

-Merits (i)Improved Count Distribution by adopting two pruning.

(ii) Generates less number of candidates.

(iii)It outperforms Count Distribution in context to performance as work load balance is high when skewness is in the range of high to moderate.

APRIORI based Parallel algorithms  APRIORI based Distributed algorithms     -Demerits (i)It is more sensitive to work load balance than data skewness.

(ii)To obtain very high ARM efficiency, first database should be partitioned using Balanced k-means clustering and then FPM is executed on it.

b) Count Distribution (CD), Data Distribution (DD)  and Candidate Distribution (Cand Dist) -Proposed by Rakesh Agrawal and J. Shafer. [1, 2, 6].

CD DD Cand Dist.

-Each processor generates the partial support of all candidates itemsets from its local database partition.

Then global count is obtained by exchanging counts with all other processors.

-Replication of candidates are done.

-Excluding the global reduction, each processor in executes the serial Apriori algorithm on the locally stored transactions.

-Merits (i)It minimizes communication since only count is exchanged among processors.

-Demerits  (i) It doesn?t utilize memory as the entire hash tree is replicated on each processor.

-Data is partitioned among processors and each processor has disjoint candidate set.

-Each processor scans the entire database in all iterations to generate the global support.

-Merits (i)It efficiently utilizes system memory.

-Demerits (i) It suffers from high communication overhead because of all to all broadcast to send the local database portion to every other processor.

(ii)Unable to divide the work done on each transaction at every processor.

-Here both the data and candidates are partitioned in such a way that each processor can generate global counts independently.

-The partitioning uses a heuristic based on support, so that each processor gets an equal amount of work.

-Merits (i) Work load of all processors are balanced.

-Demerits (i)Cost incorporated due to redistribution of the database.

(ii)Scanning local database partition repeatedly.

c)  Non-Partitioned Apriori (NPA), Simply-Partitioned  Apriori (SPA) and Hash-Partitioned Apriori (HPA) -Proposed by T. Shintani and M. Kitsuregawa  [1, 4].

NPA SPA HPA -Similar to CD.

-Only difference is that the sum reduction of candidate is performed on a single master processor.

-Merits (i)As compared to CD communication overhead is reduced.

-Demerits (i)No proper utilization of memory.

(ii)Involves extra computation overheads.

-Similar to DD.

- Only difference is that the sum reduction of candidate is performed on a single master processor.

-Merits (i)As compared to DD communication overhead is reduced.

-Demerits (i)Involves use of complicated internal structures and additional computation overheads as compared to DD.

-Similar to Cand Dist.

-The candidates are generated on each processor and determine a home processor for that candidate by applying a hash function.

If it itself is home for a candidate then inserts the candidate in the local HT otherwise discard it.

-Merits (i)No replication of database as in candidate distribution.

-Demerits (i)Involves use of complicated internal structures i.e. HT   d) Intelligent Data Distribution (IDD) and Hybrid  Distribution (HD) - proposed by E-H. Han, G. Karypis and V. Kumar [6].

IDD  HD -A logical ring is formed by processors where each processor can determine its neighbouring processors and use Right buffer and Left buffer to collect the counts of the candidates assigned to it.

-Here Ck, candidates is partitioned in such a way that each processor gets itemsets  -It?s a combination of CD and IDD algorithms.

-P processors are partitioned into M equal sized groups.

-Each of the M groups is considered a super processor.

- CD algorithm is performed on M  that begin only with a subset of all possible items, then we can check the items of transaction against this subset to determine if the HT contain candidates starting with these items. We traverse HT with only the items in the transaction that belong to this subset.

-It switches to CD once candidates fit into memory.

-Merits (i)Reduces communication contention.

(ii)Provides good load balancing.

(iii)It eliminates redundant work.

(iv) Discard transaction if it doesn?t contain candidate itemsets.

-Demerits (i)It involves use of complicated structures to partition items.

(ii)As number of processors increases the number of candidates assigned to every processor reduces that leads to two problems (a) With fewer number of candidates per processor it?s much difficult to balance the work and (b) the smaller number of candidates gives smaller HT and less computation work per data that reduces overall efficiency.

super processor.

-Among M super processors the database is horizontally partitioned.

-Among P/M processors the candidates are partitioned.

-The number of groups is dynamically decided on each pass.

-Merits (i)The communication cost is reduced by a factor of 1/M.

(ii)Each processor is assigned enough with computation work by maintaining minimum number of candidates per processor.

(iii)It can handle much larger database as compared to CD algorithm.

(iv)Amount of data movement reduces by 1/M of IDD algorithm.

(v)Better exploits the memory than CD algorithm.

(vi)It provides good load balance.

-Demerits (i)It involves extra computation to determine number of processor in a group at every pass.

3)  Its Distributed Version  a)  Fast Distributed Mining (FDM) -proposed by D. Cheung, V. T. Ng, A. Fu and Y. Fu [7].

-Here it?s assumed that the database is horizontally partitioned among the distributed sites.

-In the first step, each site generates candidates using the (globally frequent at site i) GLi from all other sites and assigns a home site for each candidates.

-After that local support for all candidates are computed on each site and then local pruning and count polling optimization is done.

-At the end, each site has globally frequent set and new iteration may begin.

-Merits (i)The communication overhead is less than CD.

(ii)The number of candidates used for counting is much less.

(iii)It suggest three optimization i.e. Local pruning, global pruning and count polling.

-Demerits (i)The FDM?s polling requires two rounds of messages in each iteration that depreciates the performance in a parallel setting.

b)  ED-ARM (Efficient Distributed ARM)  -proposed by Yan Zhao, Yong Yao and Zhijng Liu [23].

-Here, DB database with D transactions is partitioned among n sites S1,S2,..Sn, as DB1,DB2,..DBn. The size of partition DBi be Di for i=1,..,n and c.supp and c.suppi be support counts of an itemset c in DB and DBi. L is the globally large itemset and a coordinator is introduced as global control that collects the local frequent itemset Lki and their support count and gets Lk L.

-It involves following steps:- (i)Find Lki (local large k- itemset in Li) by using algorithm that builds a HT,     eliminates all infrequent items from transactions in DBi and get the new database DBi?.

(ii)Send Lki and support count of c.suppi (local support of c at site Si) to the coordinator.

(iii)The coordinator gets the Lk and computes L = UkLk.

Merits (i)It reduces the size of database to be scanned, so that more transactions can be accumulated in the main memory.

(ii)It also minimizes candidate itemsets generation costs by hash methods and thus improves the speed of finding the large itemsets over the distributed transaction database.

c) Distributed Decision Miner  -proposed by Assaf Schuster and R Wolff [24].

-It generates only those association rules that have confidence above the threshold level without generating a rules exact confidence in distributed sites.

Merits (i)It reduces communication overhead.

Demerits (i)The final rule model generated won?t be identical at different sites.

d)  ODAM (Optimized distributed association mining) -proposed by M. Z. Ashrafi, D. Taniar and K. Smith [25].

-Firstly, support counts of 1-itemsets from each site is computed same as sequential Apriori. Then these itemsets are broadcast to other sites and discovers the global frequent 1-itemsets.

-Candidates 2-itemsets are generated with their support counts at each sites and at the same time, ODAM also eliminates all globally infrequent 1-itemsets from every transactions and inserts the new transactions into memory with check, if it?s already present then increment the transaction count otherwise it is set to one.

-It then generates the globally frequent itemset of that respective length by broadcasting the support counts of candidates after every pass.

Merits (i)It generates support counts of candidates itemset quicker and reduces the size of the average transactions data sets and message exchange.

Demerits (i)Total transactions could exceed the main memory limit.

B. DHP (Direct Hashing and Pruning), Sequential ARM algorithm  - Proposed by J.S.Park, M. Chen and P. S. Yu. [9].

- DHP uses a hash table (HT) to precompute support of 2-  itemsets while counting 1-itemsets.

- DHP adds k itemsets into Ck (candidates) and stores it in  hash tree only if that k-itemset passes the hash filtering i.e. that k-itemset is hashed into a hash entry when value is larger or equal to minimum support.

- Merits (i)Size of database is reduced in each iteration by removing infrequent item and transactions that don?t contain it.

(ii)Size of candidate 2-itemset is reduced significantly.

- Demerits (i)Only logical pruning can be performed since physical pruning involves rewriting of the database in each iteration, which is impractical.

1)  Its Parallel Versions -  Parallel Data Mining (PDM)  -Proposed for DMM by J.S.Park, M. Chen and P. S.Yu [10].

-Each processor Pi generates the local supports of 1-itemsets and approximate counts for the 2-itemsets via hash table.

-The global counts for 1-itemsets are obtained by an all to all broadcast of local counts.

-For second pass, local candidates are generated using the global 2-itemset hash table and for subsequent passes directly from frequent itemsets from previous pass.

-Candidates are generated in parallel.

-Merits (i)It improves aggregate memory utilization.

-Demerits (i)Communication and writing cost is high.

(ii)It performs worst than count distribution algorithm.

C. Dynamic Itemset Counting (DIC), Sequential ARM algorithm  -Proposed by S. Brin, R. Motwani, J. Ullman and S. Tsur., is a generalization of Apriori [11].

-Here, database D is partitioned into p equal sized partitions that fit in memory.

-DIC gathers support of single items in partition 1. Locally frequent items are found and used to generate candidate 2- itemsets.

-After that partition 2 is read to find support of all current candidates.

-This process is repeated for the remaining partitions.

-DIC starts counting candidate k-itemsets while processing partition k in the first database scan.

-The processing wraps around to the partition 1 after the last partition p has been processed.

-The global support of a candidate is known once the processing wraps around the database and reaches the partition where it was first generated.

-If no new candidates are generated from the current partition, and all previous candidates have been counted, DIC stops.

-Merits (i)The number of database scan is reduced if most partitions are homogeneous.

(ii)The data partition skew is reduced by using random partitioning technique.

-Demerits (i)In case of non homogeneous data, it can generate many false candidates.

1) Its Parallel Versions- Asynchronous Parallel Mining (APM) -Proposed by D. Cheung, K. Hu and S. Xia. for SMP [12].

-Here, the database is logically divided into many small equal sized virtual partitions say l >= no. of P processors.

Let no. of items = m. The local count of m items is computed in each partition and forms l x m datasets.

-These l vectors are grouped into k clusters such that inter- cluster distance is maximized and intra-cluster distance is minimized to skew the k clusters.

-Then DIC is applied in parallel to each processor and asynchronously builds a shared TRIE.

-APM terminates when all processors have processed all candidates and no new are generated.

-Merits (i)The size of candidate 2-itemsets is reduced.

(ii)It works well for non homogeneous data also.

(iii)It outperforms CD, CCPD algorithm by a factor of 4-5.

-Demerits (i)Here data skewness is achieved but not load balance among processors.

(ii)It needs extra computation for getting intra-processor partition homogeneity.

D. FP- Growth (Frequent pattern growth), Sequential  ARM algorithm -Proposed by J. Han, J. Pei and Y. Yin [16, 17].

-The algorithm is divided into two phases. Phase-I involves construction of FP-Tree with respect to given support threshold whereas association rules are generated in phase-II by using FP-Tree that contains all frequent itemsets with respect to the given support.

-It involves divide and conquer strategy as follows: First draw FP-Tree of a given database while retaining the itemset association information and then divide FP-Tree into a set of conditional databases, each associated with one frequent item and mine them separately.

-Merits (i)It reduces search cost as it uses the least frequent items as a suffix and is faster than Apriori algorithm.

(ii)It is efficient and scalable for mining both long and short frequent patterns.

(iii)FP-Tree is constructed in two passes over the whole database.

-Demerits (i) Difficult to construct a main memory based FP-Tree for large database.

(ii) FP-tree is support threshold dependent.

1) Its Parallel Version - Parallel FP-Growth -Proposed by O. R. Zaiane, M. El-Hajj, and P. Lu. [20].

- It is divided into two phases as in F-P Growth.

-?The construction of FP-tree involves following steps:- (1)The database is evenly divided into horizontal partitions among all processes.

(2)The database is scanned in parallel by partitions and mines all frequent items.

(3) A local FP-tree is constructed by each process from its local database partition with respect to the global frequent items [19].

-The steps involved in mining all frequent itemsets from the FP-trees are:- (1)Each process generates local conditional pattern bases for all frequent items, from the local FP-tree.

(2)Frequent items are assigned to processes.

(3)For each frequent item, all its local conditional pattern bases are accumulated and transformed into the conditional FP-tree on the designated process.

(4)To mine frequent itemsets in the presence of the given item, each process recursively traverses each of the assigned conditional FP-trees. Here, the mining process starts with a bottom-up traversal of the local FP-trees to generate the conditional pattern bases starting from their respective items in the header tables.

-Merits (i)The disk I/O is minimized by scanning the original database only twice.

(ii)Involves relatively low communication/synchronization cost.

-Demerits (i) During the processing of the conditional pattern bases the load balancing techniques used do not meet the expected performance.

E. Eclat, MaxEclat, Clique and MaxClique, Sequential ARM algorithms  -Proposed by M. J. Zaki, S. Parthasarathy, M. Ogihara and W. Li.  are equivalence class based algorithms [13]. The steps involved in all four algorithms are:- -Firstly, it computes frequent items from vertical tid-list database and then frequent 2-itemsets.

-After that generates the sublattices by applying either the maximal clique based pseudo equivalence relation or prefix based equivalence relations on the set of frequent 2- itemsets.

-The sublattices are then processed to generate maximal frequent itemsets one at a time in reverse lexicographic order in memory using either bottom-up, top-down or hybrid search.

-Then rules are generated accordingly.

Eclat MaxEclat Clique MaxClique -Uses prefix based equivalence relations.

-Involves bottom-up search.

-Enumerates all frequent itemsets.

Merits (i) outperforms because of few  -Uses prefix based equivalence relations.

-Involves hybrid search.

-Enumerates the long maximal frequent itemsets.

Merits (i)It is able to handle very low  -Uses maximal clique based pseudo equivalence relations.

-Involves bottom-up search.

-Enumerates all frequent itemsets.

Demerits (i)Not able to handle very low support value.

(ii)Performance degrades with the  -Uses maximal clique based pseudo equivalence relations.

-Involves hybrid search.

-Enumerates long maximal frequent itemsets and some non maximal ones.

Sequential ARM algorithms  database scans.

(ii)No HT required.

support value. increase of transactions.

Demerits (i)Same as Clique.

1) Its Parallel versions- ParEclat, ParMaxEclat,  ParClique and ParMaxClique -proposed by M. J. Zaki, S. Parthsarathy, M. Ogihara and W. Li [15].

-All four algorithms have the following same characteristics:- (i) They all use vertical data layout of database.

(ii) Here partitioning of database is done among n host in such a way that each will get entire tidlist for a single item and almost the same number of tidlist.

(iii)The tidlist on each n host is further vertically partitioned among p processors.

-All the four algorithms use similar parallelization process and differ only in search strategy and equivalence class decomposition techniques used.

-The parallelization process contains three main phases:- (i) Initialization phase, which performs computation and data partitioning.

(ii) Asynchronous phase where frequent itemsets are  generated independently by each processor.

(iii) Reduction phase where final results are aggregated.

-ParEclat, ParMaxEclat, ParClique and ParMaxclique are parallel versions of Eclat, MaxEclat, Clique and MaxClique respectively with same characteristics.

F.  Sampling large databases for Association Rules -Proposed by Hann Toivonen [21].

-Here, a random sample is picked and is used to determine all association rules that probably hold in the whole database.

-After that result is verified with the rest of the database.

-Merits (i) The exact association rules are produced in one pass over the database.

-Demerits (i) There is risk of losing valid association rules if rely on the results from sampling alone.

1)  Its Parallel versions-  D- Sampling -Proposed by A. Schuster, R. Wolff and D. Trock [22].

-It firstly, loads a sample into memory which is stored in a trie-a lexicographic tree.

-Each node of the trie stores, structural information and the list of TIDs of transactions that include the itemset associated with this node.

-Then it finds estimated frequent itemsets by setting low frequency and loops until error probability falls below the required probability.

-After that candidates are generated and each partition of the database is scanned exactly once and in parallel to calculate the actual frequencies of each candidates.

-With this computed frequencies D-Sampling performs another round where the original minimum frequency is  used and will produce candidate which is not outside the negative border if chances of failure is nil.

-Merits (i)It divides the disk I/O costs of the single scan by partitioning the database among several machines.

(ii)The performance of algorithm increases by use of the combined memory to linearly increase the size of the sample.

(iii)The frequency of the least frequent candidate can be controlled by reducing low frequency.

-Demerits (i)Lowering the frequency threshold increases the number of candidates which can affect the scan time.



IV.    SUMMARY OF ARM ALGORITHMS From above discussion, it is clear that among different Sequential ARM algorithms, the Apriori is the simplest one.

Fig 3 shows the list of all sequential and based on them parallel and distributed ARM algorithms discussed above whereas fig. 4 shows the categorisation on the basis of data layout, search technique used, data structure used and enumerations involved.

Eclat, Clique,            Sampling large Apriori         MaxClique, MaxEclat        database              DHP    DIC    FP-Growth   Parallel  Parallel  Parallel  Parallel                       Parallel  Parallel  Distributed ParEclat, ParClique  PDM    APM     Parallel F-P    ParMaxClique   D-Sampling   Growth  CD,DD           FDM         ParMaxEclat Cand Dist.      ED-ARM  NPA, FPM     ODAM, DDM SPA, HPA  IDD, HD, CCPD, PCCD  Figure 4: List of different sequential ARM algorithms and their parallel and distributed versions    Categorisation of ARM algorithms on the basis of   Data Layout                         Search                Data Structure            Enumeration    Horizontal   Vertical     Bottom up    Hybrid           HT        Trie              All          Maximal   Apriori       MaxClique          Apriori       MaxEclat      Apriori       DIC         Apriori      MaxEclat  DHP           MaxEclat            DHP,DIC   MaxClique    DHP          APM        DHP          MaxClique  DIC, FDM       Eclat              Clique, Eclat                                                      Clique  Parallel           Clique             Parallel                                                               DIC  FP Growth      D-Sampling    FP Growth                                                         Eclat  Figure 5: Shows categorisation of ARM algorithms

V.  CONCLUSION The discussion above clearly suggests that for achieving high performance, parallel and distributed ARM algorithms are required. Although PDM algorithms scale up data sets, only few organizations can afford to spend on parallel computers because of its high cost. DDM provides an alternative that can run on cheap clusters of standard, off-     the-shelf PCs. From experiments conducted it is observed that ED-ARM improves the speed of finding the large itemsets over the distributed transaction database system and has a superior performance over CD and FDM.

However, by comparing different algorithms it is seen that DDM algorithms were not shown to scale well [18]. So, there is need of designing of one that has merits of both the parallel and distributed algorithms. The simple solution proposed for this problem is a hybrid of PDM and DDM approach.

The DDM algorithm based on other than Apriori sequential algorithms has to develop. Moreover, DDM algorithms developed so far ignores the differences among distributed sources and can leads to incorrect results and also cannot incrementally mines evolving databases. So, there is great need for the designing and implementation of ARM algorithms that overcomes all these constraints.

References   [1]     M. J. Zaki, ?Parallel and Distributed Association Mining: A Survey?, IEEE, 1999, pp. 2- 3, 13- 15.

[2]    R. Agrawal and J. Shafer, ?Parallel mining association rules?,  IEEE Trans. On Knowledge and Data Engg., 8(6):962-969, December 1996, pp. 4-6, 14.

[3]     Jiawei Han, Micheline Kamber, Simon Fraser University, A book on ?Data Mining: Concepts and Techniques?,  Academic Press, Morgan Kaufmann Publishers, 2001, pp.

227-240.

[4]  T. Shintani and M. Kitsuregawa, ?Hash based parallel algorithms for mining association rules?, in 4th Intl.

conference on Parallel and Distributed Info. Systems, December 1996, pp. 20-25.

[5]     M. J. Zaki, S. Parthasarathy and W. Li. ?Parallel data mining for association rules on shared memory multi-processors?, in the proceedings of Supercomputing 1996, pp. 17-22,  Pittsburg, PA, November 1996.

[6]    E-H. Han, G. Karypis and Vipin Kumar, ?Scalable parallel  data mining for association rules?, in ACM SIGMOD Conf.

Management of  Data, May 1997, pp. 279-284.

[7]  D. Cheung J.Han, V. T. Ng, A. Fu and Y. Fu, ?A fast distributed  algorithm for mining association rules?, in 4th Intl. Conference Parallel and Distributed Info. Systems, December 1996, pp. 32-36.

[8]    D. Cheung and Y. Xiao, ?Effect of data skewness in parallel mining of association rules?, in 2nd Pacific-Asia Conference on Knowledge Discovery and Data Mining, April 1998, pp.

51-55.

[9]    J. S. Park, M. Chen and P. S. Yu, ?An effective hash based algorithm for mining association rules?, in ACM SIGMOD Intl. Conf. Management of Data, May 1995, pp. 176-182.

[10]  J. S. Park, M. Chen, and P. S. Yu, ?Efficient parallel data mining for association rules?, in ACM Intl. Conf.

Information & Knowledge Management, Nov. 1995, pp. 2.

[11]  S. Brin, R. Motwani, J. Ullman and S. Tsur, ?Dynamic itemset counting and implication rules for market basket data?,. in  Proc. of the 1997 ACM SIGMOD Int?l Conf. on Management of Data, May 1997, pp. 255-264.

[12] D. Cheung, K. Hu and S. Xia, ?Asynchronous parallel algorithm for mining association rules on shared-memory  multi-processors?, in 10th ACM Symp. Parallel Algorithms and Architectures, June 1998, Press, pp. 281-284.

[13]  M. J. Zaki, S. Parthasarathy, M. Ogihara and W. Li, ?New algorithms for fast discovery of association rules?, in  Proc.

of 3rd Int?l. Conference on Knowledge Discovery and Data Mining, August 1997, pp. 283-296.

[14]  R. Agrawal, H. Mannila, R. Srikant, H. Toivonen and A.

Inkeri Verkamo, ?Fast discovery of association rules?, in U.

Fayyad and et al, editors, Advances in Knowledge and Data Mining, pp. 307-328, AAAI Press, Menlo Park, CA, 1996.

[15]  M. J. Zaki, S. Parthsarathy, M. Ogihara and W. Li. ?Parallel algorithms for fast discovery of association rules?, Data Mining and Knowledge Discovery:  An International Journal, pp. 343-373, December 1997.

[16]   J. Han, J. Pei and Y. Yin, ?Mining frequent patterns without candidate generation?, in the proceedings of the 2000 ACM-  Dallas, Texas, USA, May 2000, pp. 2-6.

[17] Arun k. Pujari, A Book on ?Data mining techniques?,  Universities Press (India) Ltd., Hyderabad, 2001, First edition pp.  94-100.

[18] Assaf Schuster, Ran Wolff and Dan Trock, ?A High- Performance Distributed Algorithm for Mining Association Rules?, in the proceedings of the Third IEEE International Conference on Data Mining, IEEE 2003, pp. 1-4.

[19] Jianwei Li ,Ying Liu, Wei-keng Liao, Alok Choudhary, ?Parallel Data Mining Algorithms for Association Rules and  Clustering?, 2006 by CRC Press, pp. 3-5.? [20] Osmar R. Zaiane, Mohammad El-Hajj, and Paul Lu., ?Fast  parallel association rule mining without candidacy generation?, in the Proceedings of the IEEE 2001 Intl. Conf.

on Data Mining (ICDM, 2001), pp. 665-668.

[21]  Hannu Toivonen, ?Sampling large databases for Association Rules?, in the proceedings of the 22nd VLDB Conference Mumbai,   India, 1996, pp. 3-4.

[22] Assaf Schuster, Ran Wolff and Dan Trock, ?A High Performance Distributed Algorithm for Mining Association Rules?, in the proceedings of the Third IEEE International Conference on Data Mining, 2003 IEEE, pp. 1-2.

[23] Yan Zhao, Yong Yao and Zhijng Liu, ?An Efficient distributed Algorithm for Mining Association Rules?,  Discovery (FSKD 2007), 2007 IEEE, pp. 1-2.

[24] A. Schuster and R. Wolff, ?Communication-Efficient  Distributed Mining of Association Rules?, in the proceedings of ACM SIGMOD Int?l Conf. Management of Data, ACM Press, 2001, pp 473-484.

[25] Mafruz Zaman Ashrafi, David Taniar and Kate Smith, ?ODAM: An Optimized Distributed Association Rule Mining Algorithm?, IEEE Distributed Systems Online 1541- 4922, 2004, Published by IEEE Computer Society Vol. 5, No. 3, March 2004, pp. 7-9, 15.

