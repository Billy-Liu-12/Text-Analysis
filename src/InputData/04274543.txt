Systems, Man, and Cybernetics October 8-11, 2006, Taipei, Taiwan

Abstract-Finding association rules in transaction databases is most commonly seen in data mining. In real applications, different items may have different support criteria to judge their importance, taxonomic relationships among items may appear, and data may have quantitative values. This paper thus proposes a fuzzy multiple-level mining algorithm for extracting knowledge implicit in quantitative transactions with multiple minimum supports of items. Items may have different minimum supports and the maximum-itemset minimum- taxonomy support constraint is adopted to discover the large itemsets.

Under the constraint, the characteristic of downward-closure is kept, such that the original Apriori algorithm can be easily extended to find fuzzy large itemsets. The proposed algorithm adopts a top-down progressively deepening approach to derive large itemsets. It can also discover cross-level fuzzy association rules under the maximum-itemset minimum-taxonomy support constraint. An example is also given to demonstrate that the proposed mining algorithm can derive the multiple-level association rules under multiple item supports in a simple and effective way.



I. INTRODUCTION  Among the data-mining technologies, finding association rules in transaction databases is most commonly seen [1] [2][3][7][8]. An association rule is expressed as the formA a B, where A and B are sets of items, such that the presence ofA in a transaction will imply the presence of B in the same transaction. It is initially applied to market basket analysis for getting relationships of purchased items. The mined knowledge about the items tending to be purchased together can then be passed to managers as a good reference in planning store layout and market policy.

Transaction data in real-world applications usually consist of quantitative values, so designing a sophisticated data-mining algorithm able to deal with quantitative data presents a challenge to workers in this research field [3][8].

Recently, fuzzy set theory has been used more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning.

In real applications, different items may have different  This research was supported by the National Science Council of the Republic of China under contract NSC 94-2213-E-390-005.

Y. C. Lee is with the Department of Information Engineering, I-Shou University, Kaohsiung, 84008, Taiwan, R.O.C. (e-mail: d9003OO7(stmail.

isu.edu.tw).

T. P. Hong, is with the Department of Electrical Engineering, National University of Kaohsiung, Kaohsiung, 81 1, Taiwan, R.O.C. (corresponding author; phone: +886+7+5919191; fax: +886+7+5919374; e-mail: tphong@ nuk.edu.tw).

T. C. Wang is with the Department of Information Management, I-Shou University, Kaohsiung, 84008, Taiwan, R.O.C. (e-mail: tcwang@isu.edu.

tw).

criteria to judge their importance. The support requirements thus vary with different items. For example, the minimum supports for cheaper items may be set higher than those for more expensive ones. Liu et al. [6] proposed an approach for mining association rules with non-uniform minimum support values. Their approach allowed users to specify different minimum supports to different items. Wang et al. [9] proposed a mining approach, which grouped items into disjoint sets called bins, and items within the same bin were regarded as non-distinguishable with respect to the specification of a minimum support. We also proposed a simple and efficient algorithm based on the Apriori approach to generate large itemsets under the maximum constraints of multiple minimum supports [4][5].

Furthermore, taxonomic relationships among items often appear in real applications. For example, wheat bread and white bread are two kinds of bread. Bread is thus a higher level of concept than wheat bread or white bread. The information needed by decision makers in some applications is not necessary to be detailed to the primitive concept level, but at a higher one. For example, the association rule "bread - milk" may be more helpful to decision makers than the rule "wheat bread - juice milk". Discovering association rules at different levels may thus provide more information than that only at a single level [2][7].

This paper thus proposes a fuzzy multiple-level mining algorithm with multiple supports of items for extracting implicit knowledge from transactions stored as quantitative values. The proposed algorithm adopts a top-down progressively deepening approach to finding large itemsets. It integrates fuzzy-set concepts, data-mining technologies and multiple-level taxonomy to find fuzzy association rules in given transaction data sets. Each primitive item is given a predefined support threshold, and the minimum support of an item at a higher level and an itemset is determined by the maximum of the support thresholds of the items contained in it. The mined rules are expressed in linguistic terms, which are more natural and understandable for human beings.



II. REVIEW OF RELATED MINING ALGORITHMS  In this section, some related researches about mining multiple-level association rules and mining association rules with multiple minimum supports are reviewed in this section.

A. Mining Multiple-Level Association Rules Previous studies on data mining focused on finding  association rules at a single-concept level. Mining association rules at multiple concept levels may, however, lead to  1-4244-0100-3/06/$20.00 C2006 IEEE 4112    discovery of more general and important knowledge from data. Relevant item taxonomies are usually predefined in real-world applications and can be represented as hierarchy trees. Terminal nodes on the trees represent actual items appearing in transactions; internal nodes represent classes or concepts formed from lower-level nodes. A simple example is given in Fig. 1.

Food  Dairyland Foremost  Fig. 1.

OldMills Wonder  A taxonomy example.

Han and Fu [2] proposed a method for finding level-crossing association rules at multiple levels. Their method could find flexible association rules not confined to strict, pre-arranged conceptual hierarchies. Nodes in predefined taxonomies are first encoded using sequences of numbers and the symbol "*" according to their positions in the hierarchy tree. For example, the internal node "Milk" in Fig. 1 is represented by 1**, the internal node "Chocolate" by 11*, and the terminal node "Dairyland" by Il 1. A top-down progressively deepening search approach is used and exploration of "level-crossing" association relationships is allowed. Candidate itemsets at certain levels may thus contain items at lower levels. For example, candidate 2-itemsets at level 2 are not limited to containing only pairs of large items at level 2. Instead, large items at level 2 may be paired with large items at level 1 to form candidate 2-itemsets at level 2 (such as {1*, 2**}).

B. Mining Association Rules with Multiple Minimum Supports A variety of mining approaches based on the Apriori  algorithm were proposed, each for a specific problem domain, a specific data type, or for improving its efficiency.

In these approaches, the minimum supports for all the items or itemsets to be large are set at a single value. But in real applications, different items may have different criteria to judge its importance. Liu et al. [6] proposed an approach for mining association rules with non-uniform minimum support values. Their approach allowed users to specify different minimum supports to different items. The minimum support value ofan itemset is defined as the lowest minimum supports among the items in the itemset. This assignment is, however, not always suitable for application requirements. For example, assume the minimum supports of items A and B are set at 20% and 40 %0 respectively. As mentioned above, the minimum support of an item means that the occurrence frequency of the item must be larger than or equal to it for  being considered in the next mining steps. Ifthe support of an item is not larger than or equal to the support threshold, this item is not worth considering. When the minimum support value ofan itemset is defined as the lowest minimum supports of the items in it, the itemset may be large, but items included in it may be small. In this case, it is doubtable whether this itemset is worth considering. For the example described above, if the support of item B is 30%, smaller than its minimum support 40%0, then the 2-itemset {A, B} should not be worth considering. It is thus reasonable in some sense that the occurrence frequency of an interesting itemset must be larger than the maximum of the minimum supports of the items contained in it.

Wang et al. [9] then generalized the above idea and  allowed the minimum support value of an itemset to be any function of the minimum support values of items contained in the itemset. They proposed a bin-oriented, non-uniform support constraint. Items were grouped into disjoint sets called bins, and items within the same bin were regarded as non-distinguishable with respect to the specification of a minimum support. Although their approach is flexible in assigning the minimum supports to itemsets, the mining algorithm is a little complex due to its generality. Although Wang et al.'s approach can solve this kind of problems, the time complexity is high. Besides, their approach does not consider items with quantitative values and organized into multiple levels.

In our previous work [4][5], a simple algorithm based on the Apriori approach was proposed to find the large-itemsets and association rules under the maximum constraint of multiple minimum supports. The proposed algorithm is easy and efficient when compared to Wang et al.'s under the maximum constraint. Below, we will propose an efficient algorithm based on fuzzy sets and Han's mining approach for multiple-level items to generate the fuzzy large itemsets level by level.



III. THE PROPOSED ALGORITHM The proposed mining algorithm integrates fuzzy set concepts, data mining and multiple-level taxonomy to find fuzzy association rules in a given transaction data set. The knowledge derived is represented by fuzzy linguistic terms, and thus easily understandable by human beings. In the proposed algorithm, items may have different minimum supports and taxonomic relationships, and the maximum- itemset minimum-taxonomy support constraint is adopted to discover the large itemsets. Each primitive item is given a predefined support threshold (minimum support). The minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset, while the minimum support for an item at a higher taxonomic concept is set as the minimum ofthe minimum supports ofthe items belonging to it. Under the constraint, the characteristic of downward-closure is kept, such that the original Apriori algorithm can be easily extended to find the fuzzy large itemsets.

The proposed fuzzy mining algorithm first encodes items (nodes) in a given taxonomy as Han and Fu's approach did [2]. It then filters out unpromising itemsets in two phases. In the first phase, an item group is removed if its occurring count is less than the support threshold. In the second phase, the count of a fuzzy region is checked to determine whether it is large. In this phase, a set ofmembership functions are used to transform the quantitative transactions into fuzzy values. The proposed algorithm then finds all the large itemsets for the given transactions by comparing the fuzzy count of each candidate itemset with its support threshold. Furthermore, some pruning strategies are used to reduce the number of candidate itemsets generated. The framework for mining fuzzy multi-level association rules is shown in Fig. 2. The details of the proposed fuzzy mining algorithm under the maximum constraint are described below.

Fig. 2. The framework for mining fuzzy multi-level association rules.

The mining algorithm for fuzzy multiple-level association  rules under the maximum-itemset minimum-taxonomy support constraint ofmultiple minimum supports: INPUT: A body of n quantitative transaction data D, a  predefined taxonomy with the primitive items assigned their own minimum supports, a set of membership functions, and a minimum confidence value A.

OUTPUT: A set of fuzzy multiple-level association rules under maximum constraints of multiple minimum supports.

STEP 1: Encode the predefined taxonomy using a sequence of numbers and the symbol "*", with the 1-th number representing the branch number of a certain item at level 1.

STEP 2:Translate the item names in the transaction data according to the encoding scheme.

STEP 3: Set k = 1, where k is used to store the level number being processed.

STEP 4:Group the items with the same first k digits in each transaction Di, and add the amounts of the items in the same groups in Di. Denote the amount of thej-th group IJkfor Di as v .

STEP 5: Calculate the count (occurring number) of each group in all the transactions. Check for each group ijk whether its count is larger than or equals to the support threshold Tk that is the minimum of minimum supports of the primitive items descending from it. Remove the group with their counts less than their respective support thresholds.

STEP 6:For each remaining group 1jk, transform the Vkquantitative value V.. of Ijk in each transaction datum  Di into a fuzzy setf1 represented as:  -k+ ~~+ *I+  jiRJ J2 Rjh) using the given membership functions, where I= 1 to n, h is the number of fuzzy regions for jk, Rk. is the 1-th fuzzy region of I, 1 < I < h, and fv is V s fuzzy membership value in region Rj,.

STEP 7:Collect the fuzzy regions (linguistic terms) with membership values larger than zero to form the candidate set Clk; Calculate the scalar cardinality count k of each fuzzy region R k in the transaction data as:  n  countj = fi I i=l  STEP 8:Check whether the value coun ,, of each region R.k in C1k is larger than or equals to the threshold rj, which is the minimum of minimum supports of the primitive items descending from it. If R" satisfies  kthe threshold, put it into the large 1-itemset (Li ) for level k. That is,  Lk = {Rk, CoUntk, 2k 5 RkERk ClI j ~~~I' j/ IJ STEP 9:If k reaches the level number of the taxonomy, go to  STEP 16 to find association rules; otherwise, ifLIk is     null, set k = k + 1 and go to STEP 4; otherwise, do the next step.

STEP 10: Generate the candidate set C2k from L1 , L12, ..., L k to find "level-crossing" large itemsets. The generated candidate set C2k has to satisfy following conditions:  (1)Each 2-itemset in C2f must contain at least one item in LIk.

(2)The two regions in a 2-itemset may not have the same item name.

(3) The two item names in a 2-itemset may not be with the hierarchy relation in the taxonomy.

(4) Both ofthe support values ofthe two large I -itemsets comprising a candidate 2-itemset must be larger than or equal to the maximum of the minimum supports of the two large 1-itemsets.

STEP 11: Do the following substeps for each newly formed candidate 2-itemset s with regions (SI, S2) in C2k:  (a) Calculate the fuzzy value of s in each transaction Di as fs = fs A ,s, where fj5 is the membership value of region sj in Di. Assume the minimum operator is used for intersection, then:  fis = min(fis,,J*)) (b) Calculate the scalar cardinality of s in all the  transaction data as: n  counts = fisf  (c) If countS is larger than or equals to the maximum of the minimum supports of the items contained in it, put s into L2.

STEP 12: Set r - 2, where r is used to represent the number of regions stored in the current large itemsets.

STEP 13: If Lrk is null, then set k = k + 1 and go to STEP 4; otherwise, do the next step.

STEP 14: Generate the candidate set C'1 from Lrk in a way similar to that in the Apriori algorithm [1]. That is, the algorithm first joins Lk and Lk, assuming that r-1 regions in the two itemsets are the same and the other one is different. There is a difference from the Apriori algorithm in that the supports of all the large r-itemsets comprising a candidate (rl-l)-itemset I must be larger than or equal to the maximum of the support thresholds of these large r-itemsets. Store in Ck all the itemsets with all their sub-r-itemsets in 14 and satisfying the above conditions.

STEP 15: Do the following substeps for each newly formed (r+1)-itemset s with regions(s1, S2, ..., Sr+i) in Ck+  (a) Calculate the fuzzy values of s in each transaction Di as fis = f5sl A f;sf A A f5 , where f is the membership value of region sj in Di. Assume the minimum operator is used for intersection, then:  r+1  fs =minfs.j=1 J (b)Calculate the scalar cardinality of s in all the  transaction data as:  n  counts = E tis i=l  (c) If count, is larger than or equals to the maximum of the minimum supports of the regions contained in it, put s into L4+.-  STEP 16: Set r = r + 1 and go to STEP 13.

STEP 17: Construct the fuzzy association rules for all large  q-itemset s containing regions (sI, S2, ..., Sq), q > 2, by the following substeps:  (a) Form all possible association rules as follows:  SI A...ASr-i ASr+i A...ASq >Sr r= I toq.

(b) Calculate the confidence values of all association rules by:  n  fs  Z(Jisi A--A/ f Jsrl s,.+ /\ A Jisq,)  STEP 18: Output the rules with confidence values larger than or equal to the predefined confidence value A.

Note that since the hierarchical relationship of the items in a candidate 2-itemset has been checked in STEP 10, the candidate 3-itemsets will not need to be checked for it according to a lemma in [7]. All the large itemsets will thus exclude the hierarchical relationship of items.



IV. AN EXAMPLE In this section, a simple example is given to demonstrate  the proposed fuzzy mining algorithm, which generates a set of fuzzy taxonomic association rules from a given quantitative transaction dataset under the maximum-itemset minimum- taxonomy support constraint ofmultiple minimum supports. Assume the quantitative transaction dataset includes the ten transactions as shown in Table 1.

Each transaction includes a transaction ID and some purchased items. Each item is represented by a tuple (item name, item amount). Assume the predefined taxonomy is shown in Fig. 1. Also assume that the predefined minimum support values of items (minsup) are given in Table 2 and the minimum confidence value is set at 0.8.

Assume that the fuzzy membership functions are the same  for all the items and are shown in Fig. 3. Note that the proposed algorithm can also process items with different membership functions. In this example, amounts are represented by three fuzzy regions: Low, Middle and High.

Thus, three fuzzy membership values are produced for each item amount according to the predefined membership functions.

Each item name is first encoded using the predefined taxonomy. The results are shown in Table 3. All the items in the transactions are first grouped at level one and their corresponding amounts are added. The count of each group is then checked with its own support threshold that is the minimum of minimum supports of the primitive items     descending from it.

TABLE 1.

THE TEN TRANSACTIONS USED fN THE EXAMPLE  ID Items  TI (Wonder wheat bread, 2); (Linton black tea beverage, 4); (Old Mills white bread, 9)  (Linton black tea beverage, I); (Old Mills wheat bread, 3); T2 (Nestle green tea beverage, 5); (Old Mills white bread, 5);  (Nestle black tea beverage, 2)  T3 (Wonder wheat bread, 2); (Wonder white bread, 4); (77 lemon cookies, 5); (Nestle black tea beverage, 3)  (Present chocolate cookies, 3); (Old Mills white bread, 4); T4 (Wonder white bread, 2); (Diaryland chocolate milk, 3);  (Linton black tea beverage, 7); (Nestle black tea beverage, 1)  T5 (Nestle black tea beverage, 6); (77 lemon cookies, 3)  T6 (77 lemon cookies, 1); (Wonder white bread, 2); (Nestle green tea beverage, 3); (Present chocolate cookies, 9)  T7 (Old Mills wheat bread, 6); (Present chocolate cookies, 5); T8 (Diaryland chocolate milk, 7); (Foremost plain milk, 3)  T9 (Wonder wheat bread, 4); (Present lemon cookies, 3); (Linton green tea beverage, 2)  (Linton green tea beverage, 8); (Present lemon cookies, 7); T10 (Old Mills white bread, 2); (Wonder white bread, 8);  (Old Mills wheat bread, 3)  TABLE 2.

THE PREDEFINED MINIMUM SUPPORT VALUES FOR ITEMS  Diaryland Foremore Diaryland Foremore Item chocolate chocolate plain milk plain milk  milk milk  minsup 2.5 2.0 2.3 1.8  Item Old Mills Wonder Old Mills Wonder em white bread white bread wheat bread wheat bread  minsup 1.4 1.5 1.4 1.5  Present 77 chocolate Present 77 lemon Item chocolate lemon  coe cookes cookiescookies cookies  minsup 1.5 1.7 1.6 1.9  Item Linton black Nestle black Linton green Nestle green  tea beverage tea beverage tea beverage tea beverage  minsup 1.2 2.1 1.5 1.7  Membership value    items  Fig. 3. The membership functions used in the example  For example, the item 1 ** includes the items 11 1, 1 12, 121 and 122, its minimum support is then calculated as min(2.5, 2.4, 2.3, 2.1) = 2.1 according to the minimum supports given  in Table 2. The group 1 ** is then removed since its count is only 2, less than 2.1. In this example, 2**, 3** and 4** are larger than their support thresholds.

TABLE 3.

ENCODED TRANSACTION DATA IN THE EXAMPLE  ID Items  Ti (222,2)(411,4)(211,9)  T2 (411,1)(412,2)(422,5)(211,5)(221,3)  T3 (222,2) (212,4) (322,5) (412,3)  T4 (311,3)(111,3)(212,2)(211,4)(411,7)(412, 1)  T5 (412,6)(322,3)  T6 (322,1)(212,2)(422,3)(311,9)  T7 (221,6) (311,5)  T8 (111,7) (122,3)  T9 (222,4)(321,3)(421,2)  TI1 (421,8)(321,7)(211,2)(212,8)(221,3)  The quantitative values of the items at level 1 are represented as fuzzy sets by the given membership functions.

Take the first item in transaction T5 as an example. The amount of 4** (= 6) is mapped to the membership function Low in Fig. 3 with value 0, to Middle with value 0.8, and to High with value 0.2. The fuzzy set transformed is then represented as:  0.0 0.8 0.2 4**.Low 4**.Middle 4**.High  where the notation item. term is called a fuzzy region. The fuzzy regions with membership values larger than zero are collected as the candidate set C,'. The scalar cardinality of each region in Cll is then calculated as its count value. Take the fuzzy region 2**.Middle as an example. Its cardinality = (0.4 + 0.8 + 0.8 + 0.8 + 0.67) =3.47. This step is repeated for the other regions.

The count of each region is checked against the minimum ofminimum supports of items included in it. According to the predefined minimum supports of items shown in Table 2, the minimum supports of 2**, 3** and 4**, are 1.4, 1.6 and 2.1 respectively. Since the count values of 2**.Middle, 2**.High, 3**.Low, 3**.Middle, 4**.Low and 4**.Middle satisfy their respective minimum supports, they are put into LI1.

Since LI' is not null, the candidate 2-itemset C21 is generated from LI1. Note that (2**.Middle, 2**.High), (3**.Low, 3**.Middle) and (4**.Low, 4**.Middle) are not formed since they have the same item names. In addition, the 2-itemset (3**.Low, 4**.Low) is not a candidate since the count value of3**.Low (=2.0) is not larger than the minimum support of 4** (=2.1). Some pruning can thus be done in this way.

The fuzzy membership values of the candidate 2-itemsets are calculated for each transaction data. Here, the minimum operator is used for intersection. Take (2**.Middle, 3**.Middle) as an example. The derived membership value of     (2**.Middle, 3**.Middle) for transaction T2 is calculated as min(0.8, 1) (- 0.8). The scalar cardinality (count) of each candidate 2-itemset in C2' is calculated. Since only the count value of {2**.Middle, 3**.Middle} is larger than its support threshold (the maximum of the minimum supports of items), it is then put into the set of large 2-itemsets L2'. That is, L21 = {(2**.Middle, 3**.Middle)}. Since there is only one 2-itemset in L2', the candidate 3-itemsets generated at level 1 is null. The mining process is iteratively executed until the level number of the predefined taxonomy is met.

In the process of generating candidate itemsets, the ones in the following five cases may be pruned.

Case 1: An itemset is pruned if any of its subset is not large.

For example, the 3-itemset {21 *.Middle, 22*.Low, 32*.Middle} is pruned since its subset {21 *.Middle, 32*.Middle} is not a large 2-itemset.

Case 2: An itemset is pruned ifthe fuzzy regions contained in it have the same item name. For example, 22*.Middle and 22*.Low can not be formed as a 2-itemset {22*.Middle, 22*.Low} since both ofregions have the same item name 22*.

Case 3: An itemset is pruned if its regions possess the hierarchical relation in the given item taxonomy. For example, 2**.Middle and 22*.Low can not be formed as a 2-itemset {2**.Middle, 22*.Low} since 2** is the antecedent of 221*.

Case 4: An itemset is pruned if the support value ofany fuzzy region in the itemset is smaller than the maximum of minimum supports of the items. For example, the fuzzy counts of the two fuzzy regions 32*.Middle and 42*.Middle are 2.27 and 1.73, which are respectively larger than their own minimum supports. 32*.Middle and 42*.Middle are thus large 1-itemsets. The 2-itemset {32*.Middle, 42*.Middle}, however, is not likely to be a large itemset since the count value (1.73) of the region 42*.Middle is smaller than the maximum (2.5) ofminimum supports ofthese two items. The 2-itemset {32*.Middle, 42*.Middle} is thus pruned.

Case 5: An itemset is pruned if its count value is smaller than the maximum of minimum supports of the items included in it. For example, the count (=1.47) of the candidate 2-itemset {21*.High, 22*.Low} at level 2 is smaller than the maximum (-1.5) of the minimum supports of 21 * and 22*. The itemset {21 *.High, 22*.Low } is then discarded.

The proposed algorithm can thus find the large itemsets  level by level without backtracking.

minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset. The rational for using the two kinds ofsupport constraints has also been well explained and this constraint may be suitable to some mining domains. The proposed fuzzy mining algorithm can thus generate large itemsets level by level and then derive fuzzy association rules from quantitative transaction data. An example is also given to demonstrate that the proposed mining algorithm can derive the multiple-level association rules under multiple item supports in a simple and effective way. Currently, we are working on the experiments for evaluating the efficiency of the proposed algorithm.

