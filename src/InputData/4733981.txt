Rules Extraction from Multiple Decisions Ordered Information Tables

Abstract   Ordered information table is one of the most  important research areas of Granular Computing. In this thesis, we introduce multiple decisions ordered information tables based on the concept of ordered information tables. Multiple decisions ordered information tables are used to describe the actual multiple decision attributes situation of reality. We study the process of rule extraction from multiple decisions ordered information tables thoroughly and several concepts about this process are proposed and discussed. At last, an example of multiple decisions ordered information tables is used to illustrate the basic ideas. These ideas and methods are quite useful for KDD, DM and GC.

1. Introduction   Ordered information table ?OIT? is one of the most important research branches in Granular Computing (GrC) [4]. Granular computing is a large research category, and Rough Sets theory [10] is one of the relatively mature and wildly applied theory fruits in GrC, which was first put forward by Z.Pawlak in 1982.

Rough set operates attributes of decision tables directly. It can generalize and extract relationships between attributes and essential contents of decision tables. However ordered information table aims at rankings of decision target elements O . So it can induce, extract and abstract more information from attributes, and penetrate through to the substance of decision tables [1,2,7].

In order to induce ordered rules, we should transform ordered information tables into binary information tables, which is introduced by scholar Yao.Y.Y.. This concept is convenient for describing the relationship, the intention and the extension between elements. It is based on the binary element  operation symbols:  and ? . Literature [3] brings forward a binary information tables based on multiple values, and it has shortcomings, such as large numbers of attribute values, hard discovery and explanation of laws between these mass attribute values.

Rules discovery and learning are research emphases in Machine Learning and Data Mining research domain. Here rules commonly include decision rules, association rules, function dependence rules, data dependence rules etc [2]. Reference [6] has studied rule measurement and built a preparatory frame of rule measurement. Professor Yao.Y.Y figures that in an information table decision rules can be divided into one-way and two-way connect rules according to the connection direction, or local connection and global connection rules according to the applicability [2].

Ordered rules have many original virtues and are in process of development and maturity. Reference [8] introduces neighborhood into ordered information tables, and thus reinforces the mining and discovery in ordered information table vertical direction. We can apply this method into approximate information granular and approximate information retrieval. But we can find that these ordered rules [1,2] are all relatively simple, and have a great distinction compared with reality. They can?t fully exert ordered rules merits, and are difficult to deal with the situations with multiple decision attributes. So in this thesis, we present a multiple decision rules based on ordered information tables, and discuss the process and properties of multiple decision rules discovery thoroughly.

2. Ordered information tables   Professor Yao.Y.Y defines ordered information tables (OIT) in reference [1,2,7], which are summed up as following.

DOI 10.1109/ICDM.Workshops.2008.104    DOI 10.1109/ICDMW.2008.75     Definition 2.1 Information tables (IT) are defined as the following quadruple:  })|{},|{,,( AtaIAtaVAtUIT aa ??= where, U  is a finite non-empty set of instances;  At  is a finite non-empty set of attributes; aV  is a non- empty set corresponding to Ata ? ; aa VUI ?:  is an information function.

Definition 2.2 U  is a finite non-empty set, and symbol  is a weak binary ordered relation on U , if it satisfies the following two properties:  Asymmetry property: )( xyyx ?? ;  Negative transitivity: )())(),(( zxzyyx ???? .

Note: )( xyyx ??  is not always correct.

We can disprove that: if there is yx ~  (? is given by definition 2.3) , premises )( xy?  is true, but conclusion yx  is false.

Definition 2.3 When weak binary ordered relation satisfies the following formula, we can define equivalence relation ? :  ))(),((~ xyyxyx ??? .

If yx ~ , we say x  and y  are indiscernible by  weak binary ordered relation . When )( yx?  we write it as yx? .

Definition 2.4 An ordered information table is defined as a pair:  })|{,( AtaITOIT a ?= where IT  is an information table, and a  is a  weak binary relationship in aV . We can deduce instance order by a certain attribute a :  )()( yIxIyx aaa ? .

For attribute subset AtA? , we define:  . )()( )]()([  }{a Aa  aaa Aa  aaaA  yIxI yIxIAayx ? ??  ?? ???  ?  We mark overall order of objects as }{o .

Definition 2.5 Assume in an ordered information  table OIT , original expression )(ae  is a  or a? .

Thus in information table, for AtA ?  expression of A  is )(aeAa?? . Write binary relation set as:  }.,,|),{( }|),{()(  yxUyxyx UxxxUUUU  ??= ???=? +    We define the following formulas based on the above binary relation set:  yxiffayx a}{       ),(|),( = ; yxiffayx a}{       ),(|),( ??= ;  ?? =?= |),(        |),( yxnotiffyx ; ???? ==?= |),(  |),(       |),( yxandyxiffyx ;  ???? ==?= |),(  |),(       |),( yxoryxiffyx ; ???? ??=?=  |),(       |),( yxiffyx ;  . |),( |),(       |),(  ?? ????  ?= ?=?=  yxand yxiffyx    At the same time, define ? ?s meaning set as: }|),(|),{()( ?? =??= yxUUyxm .

Definition 2.6 For equivalence class X , A  and B  are attribute sets, )(AP  and )(BP  are partitions of instances, then )(APX ??  )(BPY ?? , we get  YX ? . Then we call )(AP  is a finer partition of )(BP , written as BA ? , namely, attribute set A  decides attribute set B .

If and only if BA ?  and AB ? , we have  )()( BPAP ?  and we say that attribute set A  and B  are equivalent.

Definition 2.7 Attribute Aa ?  is independent in A , if and only if A  and }{aA ?  are equivalent;  otherwise Attribute Aa ?  is an indispensable one.

Attribute set A  is a independent set to object o , if and only if Aa ??  is independent to object o ; otherwise A  is a dependent set.

A subset AB ?  is a reduction of A  to object o , if and only if B  is an independent set to object o  and equivalent to set A . A reduction AB ?  to object o is also called a relative reduction to object o . The set of all relative reductions of A  to object o  is denoted by )(AREDo . The set of all indispensable attributes of A  is denoted by )(ACOREo  and is called the relative core of A  to object o . So it has the following formula:  )()( AREDACORE oo ?= .

Definition 2.8 We define the accuracy and coverage  of an ordered rule ?? ?  respectively as:     )( )(  )( ?  ?? ??  m m  accuracy ?  =? ,  )( )(  )(cov ?  ?? ??  m m  erage ?  =?  where   ?  denotes the cardinality of the meaning set inside.

3. Multiple decisions ordered information tables 3.1. Multiple decisions ordered information tables (MDOIT)   It is easy to find that the theories proposition of thesis [1,2,7] and their applications analysis mainly discuss with focus on single decision attribution situations. They have not further talked about the situations with multiple decision attributes, which exist in reality widely. Thus in this thesis, we extract this kind of ordered information tables with multiple decision attributes from OIT class and study them in detail. We name this subset multiple decisions ordered information table (MDOIT).

Definition 3.1 Multiple decisions ordered information tables are defined as the following triple:  })  2,|{ },|{,(  NiandiOoo AtaITMDOIT  ii  a  ??? ?=    where, IT  is an information table; a  is a weak binary relation in aV ; io  is a decision attribute; O  is the set of decision attributes.

The decision attribute order of objects is denoted by  }{ io , where Ni  2 ?? andi .

Multiple decisions ordered information tables class is a subset of ordered information table. So it also has the properties of ordered information tables.

Definition 3.2 in binary relation, define new logic formula:  ?? == |),(       |),( xyiffyx where, instance x  and instance y  change their  place with each other. So we can call it reverse logic.

Reverse logic )( yx  is also can be noted as yx ? , namely, )()( xyyx ? .

Inference of Definition 3.2?  (1) 2121 ???? ?=? ; (2) 2121 ???? ?=? .

Proof:  (1) 21),( and , ?? ???? yxUyx , then 21),( ?? ??xy , so 1),( ??xy  and 2),( ??xy .

Thus 1),( ??yx ? 2),( ??yx ?and we can induce  21),( ?? ??yx . So we get 2121 ???? ??? .

21),( and , ?? ???? yxUyx , then  1),( ??yx , 2),( ??yx , so 1),( ??xy  and 2),( ??xy . Thus 21),( ?? ??xy , then  21),( ?? ??yx . So we get 2121 ???? ???  at the same time.

Therefore we get 2121 ???? ?=? . Equation (1) is then proofed.

(2) Proving by the same methods of (1).

We write reverse logic as . This symbol is used to  unify symbols ? , ? , ? ,  together and is convenient for our discussion.

Note: we should distinguish between NOT logic |),( ??=yx  and reverse logic ?=|),( yx .

Definition 3.3 UyxAa ???? ,, , if there is no yx ~ , we call A  is completely mutually different;  otherwise we call A  is non-completely mutually different. Completely mutually different attribute set A  composes the meaning set )(?m , and we say  )(?m  is completely mutually different; otherwise we say )(?m  is non-completely mutually different.

Apparently we have: 2)( ICm =? . At the same time, we have the following properties.

Inference of Definition 3.3? (1) The meaning set )( ?? ?m  is completely  mutually different ? )(?m  is completely mutually different )( ?mand  is completely mutually different ?  (2) The meaning set )( ?? ?m  is completely mutually different ? )(?m  is completely mutually different )( ?mor  is completely mutually different.

Completely mutually different attribute set A  is the most exceptional situation of independent attribute set A .

Definition 3.4 If there is symbol ?  exited in an ordered information rule, we say that this rule is an AND ordered information rule; If symbol ?  appears     in an ordered information rule, we call that this rule is an OR ordered information rule; If there is symbol ? , we can say it is a NOT ordered information rule; If  symbol  exists in ordered information rule, we call it a reverse ordered information rule; Otherwise it is a meta ordered information rule.

Obviously all of the rules in ordered information tables can ultimately be expressed as the combination of AND, OR, NOT, reverse ordered information rules or meta ordered information rules.

Similarly, the meaning sets (expressions) using  as binary ordered relation and appearing ? , ? , ? , or none of above are respectively called AND meaning sets (expression), OR meaning sets (expression), NOT meaning sets (expression) or meta meaning sets (expression).

Definition 3.5 We name the rules with multiple decision attributes in the conclusion part of rules multiple decisions ordered information rules; the rules with multiple decision attributes both in the precondition part and in the conclusion part is called mutual decisions ordered information rules.

Multiple decisions ordered information rules consider the precondition influencing on the multiple decision attributes at the same time; Mutual decisions ordered information rules represent the mutuality between precondition decision attributes and conclusion decision attributes.

4. Properties of the meaning sets and ordered rules   Professor Yao.Y.Y. has researched weak binary relation properties [2,9], and has mainly considered satisfying two characteristics: asymmetry property and negative transitivity. These two characteristics implicate the important relationship of the weak binary equivalence.

Here, we study the attributes of the meaningful sets of weak binary ordered relation and that of the ordered rules.

Theorem 3.1 The meaning sets )(?m , )( ??m have the following relationship:  )()( ?? mm ?? where, equation is gotten if and only if )(?m  is  completely mutually different.

Proof: We can induce Theorem 3.1 easily by Definition 2.5  and Definition 3.2.

Theorem 3.2 Assume ? ? 1?  and 2?  are logic expressions, then the item numbers of the meaning sets have the following formulas:  (1) )()( ?? mm = ;  (2) )()( ?? mm ?? , where equation is gotten if and only if )(?m  is completely mutually different;  (3) )()( 2121 ???? ?=? mm ;  (4) )()( 2121 ???? ?=? mm .

Proof: (1) It is easy to prove by Definition 3.2.

(2) We can get )()( ?? mm ??  from Theorem 3.1, where equation is gotten if and only if )(?m  is completely mutually different. We have  )()( ?? mm =  from Theorem 3.2 (1). Thus the conclusion is gotten.

(3) According to Inference of Definition 3.2,  2121 ???? ?=? , so we have )()( 2121 ???? ?=? mm . Thus it can be seen  )()( 2121 ???? ?=? mm  from Theorem 3.2 (1).

So equation (3) is proved.

(4) The proof process of equation (4) is as same as equation (3).

Theorem 3.3 Suppose there is a binary ordered relation , then )( yxyx ??? .

Proof: We can induce Theorem 3.3 easily by Definition  2.5.

Theorem 3.4 Assume ? , ? , ? , 1?  and 2?  are  all logic expressions, then we have: (1) )(cov)(cov ????? ???? erageerage ,  )(cov)(cov ????? ???? erageerage ; (2) )(cov)(cov ????? ???? erageerage ,  )(cov)(cov ????? ???? erageerage ;  (3)  )(cov)(cov ???? ???? erageerage ; (4) )( 21 ??? ??accuracy )( 1?? ?? accuracy ,  )()( 221 ????? ???? accuracyaccuracy ;     (5) )( 21 ??? ??accuracy )( 1?? ?? accuracy , )()( 221 ????? ???? accuracyaccuracy ;  (6) )()( ???? ???? accuracyaccuracy .

Proof: (1) For )()( ????? ???? , we get  )()( ????? ???? mm . So from Definition 2.8 we have  ? ??  =?? )(  )( )(cov  ? ???  ??? m  m erage  )( )(  )(cov ?  ?? ??  m m  erage ?  =? . By the same  way, we get the formula )(cov)(cov ????? ???? erageerage .

Thus expressions (1) are proved.

(2) For )())(( ????? ???? , we have  )())(( ????? ???? mm . Then from Definition 2.8, the formulas are proved.

(3) From Theorem 3.1, we know that  )()( ?? mm ?? , so )()( ???? ???? mm . At the same time according to Definition 2.8, the conclusion of (3) is easy to get.

(4) It is easy to prove by the same way.

(5) It is easy to prove by the same way.

(6) It is easy to prove by the same way as (3)  proving process.

According to formulas (2), we know that we can  increase coverage further more by using ?  in the precondition part of rules.

According to formulas (5), a better accuracy is gotten when we use symbol ?  in the conclusion part of rules.

Note: the following empirical formulas (7) are not always correct, but they are often right when  )( ?? ?accuracy  and )( ?? ?accuracy  can bring certain information to decisions order of expression ? . They mean that the rule accuracy can be promoted when we use symbol ?  in the precondition part of rule and they have a preferable practical value in real applications.

Empirical formulas (7): )()( ????? ???? accuracyaccuracy , )()( ????? ???? accuracyaccuracy .

At the same time, we have empirical formulas (8), which are not always correct. But if both  )(cov 1?? ?erage  and )(cov 2?? ?erage can offer much information, the rule coverage can be  further improved by using symbol ?  in the conclusion part of rule.

Empirical formulas (8): )(cov)(cov 121 ????? ???? erageerage , )(cov)(cov 221 ????? ???? erageerage .

These empirical formulas have high practical values in reality.

From Theorem 3.4, we know that if we want to increase the coverage or the accuracy of a rule, formula (2) and (5) bring us a useful approach respectively.

According to formulas (1), (2), (3), (4), (5), (6) and empirical formulas (7), (8), we can improve the validity of a rule, but the accuracy and the coverage of ordered rule can not reach the best point at the same time. So we have to make a compromise between the accuracy and the coverage of a rule. One practical method is to set thresholds of minimum accuracy and minimum coverage. If rule accuracy and rule coverage reach their thresholds, the rule is acceptable, or else it is failed and need to be improved. Another method is to adjust rules according to user?s feedback, then a satisfy rule is gotten.

After defining mutual information in Definition 3.6, we will get best ordered rules according to mutual information measurement.

Theorem 3.5 Let 1? , 2?  be logic expression, then we get:  (1) )(cov)( 1221 ???? ?? erageaccuracy ? , )()(cov 1221 ???? ?? accuracyerage ? .

(2) )()( 2121 ???? ?? accuracyaccuracy ? ,  )(cov)(cov 2121 ???? ?? erageerage ? .

Proof: (1) According to Definition 2.8 formulas (1) are easy  to get.

(2) According to Definition 3.2, it is easy to prove  formulas (2).

Note: formulas (2) also can be transformed into  )()( 2121 ???? ?? accuracyaccuracy ? , )(cov)(cov 2121 ???? ?? erageerage ? .

Definition 3.6 Let 1? , 2?  be logic expressions, for ordered rules 21 ?? ?  and 12 ?? ? , the mutual information ),( 21 ??I  between 1?  and 2?  can be defined as  ),( 21 ??I = )(cov)( 2121 ???? ??? erageaccuracy .

Inference of Definition 3.6:     (1) Symmetry property: ),(),( 1221 ???? II = .

(2) ),(),( 2121 ???? II = .

Proof? (1) It is obvious that according to Theorem 3.5 and  Definition 3.6, the inference of Definition 3.6 (1) is correct.

(2) According to Definition 3.6, Definition 2.8 and Definition 3.2, we can prove  ).,( )(  )( )(  )(  )(  )(  )(  )(  )(cov)(  ),(            ?? ?  ?? ?  ??  ?  ??  ?  ??  ????  ??  I m  m m  m  m  m  m  m  erageaccuracy  I  = ?  ? ?  =  ? ?  ?  ???=  ?   Thus, according to Inference (1) of Definition 3.6, in  mutual decisions ordered information rules 21 ?? ? and 12 ?? ? , we can say that the information which expression 1?  brings to 2?  is equal to the information that 2?  brings to 1? .

The mutual information of ordered rules is able to provide a reference for ordered rule?s validation. We can consider an ordered rule with more mutual information is better than a rule with less mutual information.

Empirical method: the principle of Occam's Razor is that one should not increase, beyond what is necessary, the number of entities required to explain anything [11].

So according to this principle, in the situation of equal mutual information, it prefers to choose the simple ordered rule rather than select the complex one.

It is obvious that the value scope of mutual information ),( 21 ??I  is [0,1]. When both the accuracy and the coverage of ordered rules reach the maximum value 1, the mutual information also gets the maximum value 1; when the accuracy or the coverage is 0, the mutual information gets the minimum value 0.

Definition 3.7 The comparability ),(C ba  of information table attribute a  and attribute b  is defined as:  ),(C ba = )],(),,(max[ baba II .

Inference of Definition 3.7?The comparability of ordered information table ),(C ba  has the property of symmetry: ),(C),(C abba = .

Proof: According to Definition 3.7, we have  ).,(C)],(),,(max[  )],(),,(max[  )],(),,(max[),(C  abII  II  IIba  abab  baba  baba  ==  =  =    Inference of Definition 3.7 is then proved.

The comparability of information table ),(C ba  represents the similarity of attribute a  and attribute b . It is easy to compute that the value scope of  ),(C ba  is [0,1] too.

Definition 3.8 We have attribute a  and decision  attribute o , then the significance ),( oaS  of attribute a  relative to decision attribute o  is able to defined as:  ),( oaS = )],(),,(max[ oaoa II .

To the same attribute a , the information brought to  decision attribute o  by positive order a  and that brought by inverse order a  are different. So the larger one manifests the significance of attribute a  to decision attribute o .

Thus, according to ),( oaS , we can sort the importance of different attributes to a certain decision attribute.

Definition 3.9 Assume the decision attribute set of an ordered information table has several decision attributes: nooo ,, 21  and let a  be a attribute?the significance )(aS  of attribute a  is defined as:  n noaSoaSoaSaS ),(),(),()( 21 ?? .

Inference of Definition 3.9: In the process of ordered information table reduction, it is preferable to preserve the attributes with greater importance. If we delete the attributes whose significance is equal to 0, the information of OIT does not lose.

)(aS  indicates the importance of attribute a  to the whole decision attribute set.

Similarly, we can set an importance order of every attribute in ordered information table according to  )(aS .

The value scope of importance measurement  ),( oaS  and )(aS  is [0,1]. At the same time, attribute importance is a fuzzy concept from the view of fuzzy set theory, and its definition scope is between     0 and 1 too. So our definition scopes of ),( oaS  and )(aS  tally with fuzzy membership of fuzzy set. It  shows our definition?s validation fully.

5. Mining MDOIT rules: an illustrative example   Here, we use the example come from literature [2], and add a new decision attribute Overallolder to the old one. Then consider the following multiple decision ordered information table [2,7] :   Table 1. Multiple decisions ordered information  table illustration Model 1 2 3 4 5 Size Midd-  le Large Small Small Small  Warranty 3 years 3 years  years  years  years  Price $ 200 $ 300 $ 300 $ 250 $ 200 Weight Heavy Very  heavy Light Very  light Very light  Overallyo- unger  Best Good Good Better Good  Overallol- der  Best Best Good Good Good   Towards five different models of goods, a certain  kind of consumer, i.e. the younger, have the evaluation results of Overallyouger, while another sort of consumer, i.e. the older, give an integration evaluation showed in decision attribute Overallolder of Table 1.

According to different attributes, a series of ordered relations can be set up respectively. Here we have not listed all of the ordered relations for thesis length?s reason. In the following, we also have not written down all weak binary relations, accuracy values, coverage values, etc. Readers can refer literature [2] to complement them:  izeS : largemiddleSmall izeize SS ,  izeS : Smallmiddleel izeize SSarg ,  goungerOverall :  GoodBetterBest goungergounger OverallOverall ,  olderOverall : GoodBest olderOverall .

Thus five goods have the following weak binary  ordered relations:  izeS : ]2[]1[[3,4,5] ** SizeSize ,  izeS : ]5,4,3[]1[[2] ** SizeSize ,  goungerOverall :  ]5,3,2[]4[]1[ ** youngeryounger OverallOverall ,  olderOverall : ]5,4,3[]2,1[ *  olderOverall .

Consequently we can get the following meaning  sets: Meta meaning set:  )( Sizem ={(1,2),(3,1),(3,2),(4,1),(4,2),(5,1),(5,2)}, Reverse meaning set:  )( Sizem ={(1,3), (1,4), (1,5), (2,1), (2,3), (2,4), (2,5)},  NOT meaning set: ))(( Sizem ? ={(1,3), (1,4), (1,5), (2,1), (2,3), (2,4),  (2,5),(3,4),(3,5),(4,3),(4,5),(5,3),(5,4)}, Meta meaning set:  )( Pricem ={(1,2),(1,3),(1,4),(4,2),(4,3),(5,2),(5,3),( 5,4)},  Meta meaning set: )(  goungerOverall m ={(1,2),(1,3),(1,4),(1,5),(4,2),(4,3  ),(4,5)}, Meta meaning set:  )( olderOverall  m ={(1,3),(1,4),(1,5),(2,3),(2,4),(2,5) },  AND meaning set: )( Size youngerOverallm ? ={(1,2),(4,2),},  AND meaning set: )( Price youngerOverallm ? ={(1,2),(1,3),(1,4),(4,2),  (4,3)}, AND meaning set:  )( PrSize icem ? ={(1,2),(4,2),(5,2)}, AND meaning set:  )( PrSize youngerOverallicem ?? ={(1,2),(4,2)}.

Further more, we induce the corresponding accuracy  values and coverage values of ordered rules. We can easily find that the order of Size provides less information about the ranking of Overallyounger:  )( youngerOverallSize  accuracy ? =2/7,  )(cov youngerOverallSize  erage ? =2/7.

While the Price meta OIT rule gives us more about  the Overallyounger ranking:     )( Pr youngerOveralliceaccuracy ? =5/8,  )(cov Pr youngerOveralliceerage ? =5/7.

By combing both Size and Price, we have another  AND OIT rule. This new rule improves the accuracy, but decreases the coverage:  )( Pr youngerOveralliceSizeaccuracy ?? =2/3,  )(cov Pr youngerOveralliceSizeerage ?? =2/7.

Here, mutual information gives us a reference to  measure the performance of these two rules:  56/5),(Pr =youngerOveralliceI ,  21/2),Pr( =? youngerOveralliceSizeI .

So  ).,Pr( ),(Pr  younger  younger  OveralliceSizeI OveralliceI  ? >    Thus we have a strong reason to support that the Price tells us more information about the Overallyounger ranking, namely, the former ordered rule is better than the latter one.

If we use an OR OIT rule, the accuracy decreases, but the coverage does not descend:  )( Pr youngerOveralliceSizeaccuracy ?? =5/12 ,  )(cov Pr youngerOveralliceSizeerage ?? =5/7.

In the same way, we can see that the Size and the  Price give less or no information to Overallolder ranking:  )( olderrOverallSize  accuracy ? =0/7, )(cov  olderOverallSize erage ? =0/6.

)( Pr olderOveralliceaccuracy ? =2/8, )(co Pr olderOveralliceverage ? =2/6.

On the contrary, the NOT OIT rule of attribute Size offers more information to Overallolder?s ranking:  ])([ olderOverallSize  accuracy ?? =6/13, ])([cov  olderOverallSize erage ?? =6/6.

However, the reverse OIT rule of attribute Size gives more information to Overallolder than the NOT one. It increases the accuracy, and does not decrease coverage at the same time.

)( olderOverallSize  accuracy ? =6/7, )(cov  olderOverallSize erage ? =6/6.

Using the following AND rule, we can further enhance the accuracy, but the coverage drops.

)( Pr olderOveralliceSizeaccuracy ?? =2/2, )(cov Pr olderOveralliceSizeerage ?? =2/6.

In the same way, using OR rule, the accuracy drops, while the coverage keeps invariable:  )( Pr olderOveralliceSizeaccuracy ?? =6/13, )(cov Pr olderOveralliceSizeerage ?? =6/6.

We also can get some multiple decisions ordered information rules.

The reverse order of the Size offers more useful information about decision attributes Overallyounger and Overallolder simultaneously:  )( olderyounger OverallOverallSize  accuracy ?? =3/7,  )(cov olderyounger OverallOverallSize  erage ?? =3/3.

According to empirical formulas (7), a higher  accuracy can be brought by using AND ordered rules, but the coverage drops:  ,2/2)  ( Pr =  ???  older  younger  Overall  OveralliceSizeaccuracy   .3/2)  (cov Pr =  ???  older  younger  Overall  OveralliceSize erage    Because the coverage has reached the best value in reverse OIT rule of attribute Size, we don?t need to use OR operation in precondition part of rule to improve the coverage.

Similarly, we can easily get the accuracy and the coverage of rule  olderyounger OverallOverallSize ?? ,  and rule )Pr olderyounger OverallOveralliceSize ??? .

Here we don?t list them one by one.

Also we can get mutual decisions ordered  information rules: )(  olderyounger OverallOverall accuracy ? =3/7,  )(cov olderyounger OverallOverall  erage ? =3/6.

In the same way, we have:  )( youngerrolder OverallOverall  accuracy ? =3/6,  )(cov youngerrolder OverallOverall  erage ? =3/7.

According to Definition 3.6, the mutual information  between Overallyounger and Overallolder are induced:     .42/3  )(  )(  ),( ),(  =  ?  ?? =  =  olderyounger  olderyounger  OverallOverall  OverallOverall  youngerolder  olderyounger  accuracy  accuracy  OverallOverallI OverallOverallI    The Significance of the Size, the Warranty, the Price and the Weight to decision attribute Overallyounger is listed in the following.

),( youngerOverallSizeS =3/7,  7/1),( =youngerOverallWarrantyS ,  142/5),(Pr =youngerOveralliceS ,  7/1),( =youngerOverallWeightS .

Then we can compare their importance to  Overallyounger:  ).,( ),(  ),(),(Pr  younger  younger  youngeryounger  OverallWeightS OverallWarrantyS  OverallSizeSOveralliceS  =  >  >  Thus the Price and the Size can give more information to Overallyounger, and they are more important than other attributes.

The Significance of the Size, the Warranty, the Price and the Weight relative to decision attribute Overallolder and their order are:  7/6),( =olderOverallSizeS ,  6/1),W( =olderOverallarrantyS ,  32/1),(Pr =olderOveralliceS ,  3/2),( =olderOverallWeightS ,  ).,(Pr ),W(  ),(),(  older  older  olderolder  OveralliceS OverallarrantyS  OverallWeightSOverallSizeS  > >  >   At last, we can give an overall order of their importance to the decision attribute set:  )()(Pr)()( WarrantySiceSWeightSSizeS >>> .

6. Discussion   Ordered information table is an important part of Granular Computing. In this thesis, we present a new idea of multiple decisions ordered information tables based on OIT theory, which is used to deal with  multiple decisions situations in everyday life. We study the process of discovering multiple decisions OIT rules in detail. This article enriches MDOIT logic expressions and discusses the properties of the meaning sets and ordered rules in MDOIT.

Furthermore, we introduce mutual information of logic expressions, comparability of attributes and significance of attributes, which are used to direct the MDOIT rules mining and the reduction of OIT.

An illustrative example of MDOIT rules discovery is also given to interpret the above important definitions and methods. This new thoughts and methods enrich the ordered information tables theory and establish a stability basis for future development of OIT. It is important and useful for people to comprehend the essence of ordered information tables.

Acknowledgement This paper is the partial achievement of project 60533040 and 60525202 supported by the National Natural Science Foundation of China (NSFC), project 2006BAH02A01 supported by the National Key Technology R&D Program of China, and project Z104267 supported by Natural Science Fund of Zhejiang Province.

