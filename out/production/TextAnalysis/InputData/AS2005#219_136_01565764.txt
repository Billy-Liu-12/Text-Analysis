Average Number of Frequent (Closed) Patterns in Bernouilli and Markovian Databases

Abstract  In data mining, enumerate the frequent or the closed pat- terns is often the first difficult task leading to the association rules discovery. The number of these patterns represents a great interest. The lower bound is known to be constant whereas the upper bound is exponential, but both situations correspond to pathological cases. For the first time, we give an average analysis of the number of frequent or closed pat- terns. Average analysis is often closer to real situations and gives more information about the role of the parame- ters. In this paper, two probabilistic models are studied: a BERNOULLI and a MARKOVIAN. In both models and for large databases, we prove that the number of frequent patterns, for a fixed frequency threshold , is exponential in the number of items and polynomial in the number of trans- actions. On the other hand, for a proportional frequency threshold , the number of frequent patterns is polynomial in the number of items and does not involve the number of transactions. Finally, we prove in the BERNOULLI model that the number of closed patterns, for a proportional fre- quency threshold, is polynomial in the number of items.

1 Introduction  The aim of the data mining is to extract relevant informa- tion from large databases. These databases gather transac- tions, which are sets of items, for example a list of purchase in a shop or a set of biomedical characteristics. In associa- tion rules discovery, the sets of items which are frequently present play a central role. These frequent patterns can tell that a conjunction of items are often present together in the transactions. They allow to build association rules, which are at the core of numerous data processes, but the difficulty of the task is known to lie in the frequent patterns mining.

The motivation of our article is to make clearer this dif- ficulty. When the complexity of a pattern mining algo-  rithm is studied, it most of the time focuses on the worst cases, or on the bottleneck of specific sub-tasks, such as database accesses. For example, in A-PRIORI [2], the first and most popular algorithm, there will be as much database scans as the size of the largest frequent pattern. Facing to large databases, this is an important point. More precisely, GUNOPULOS et al. have shown that mining the frequent patterns with such level-wise algorithms requires as many database accesses as there are elements in the positive and negative borders [5] (i.e. the number of maximal frequent and minimal infrequent patterns). It follows that the com- plexity of A-PRIORI intuitively lies in the quantity of fre- quent patterns. The number of database accesses does not address the real difficulty of pattern mining, and TOIVO- NEN gives in [12] a probabilistic method based on sampling, which finds all the probably frequent patterns with only one database access.

In order to improve the efficiency of pattern mining, closed patterns are very interesting. A closed pattern is the maximal pattern (w.r.t. the inclusion) of the set of patterns having the same frequency and being present in the same transactions. When they are associated with the correspond- ing pattern of transactions, both constitute a concept. Con- ceptual learning is a hot topic [13], and closed patterns are an easy way to non redundant association rules [14]. Their mining has then been widely examined [7, 3].

Gunopulos et al. have shown that deciding whether there exists a frequent pattern with t items is NP-complete [6, 10].

The associate counting problem is #P-hard. When all the items belong to all the transactions, each pattern is frequent pattern so that, in the worst case, the number of frequent patterns is of order O(2m). On the other hand, if each trans- action is empty, all the patterns are infrequent and the num- ber of frequent patterns is of constant order. There is a large gap between the worst and the best cases and both situations are pathological examples. In practice, the real order is not known.

Regarding the complexity, average analysis is an inter- esting point of view for three reasons. First of all, each      database is associated to a probability, so that the analy- sis considers the diversity of cases. Then, if the model is close to the reality, this analysis gives a realistic average behaviour of the studied parameter, which is sometimes far from the worst case. Finally, if the concentration property around the average is satisfied, fast counting algorithm are available. On the other hand, real life is often complex and the modelization is not an easy task. Furthermore, the more complex is the modelization, the more difficult is the aver- age analysis.

We found one such study [10], but it is related to the failure rate of A-PRIORI. It is useful for predicting the number of candidates that the algorithm will have to check.

This work confirms the results of [4], which used an upper bound. On the other hand, the authors of the A-PRIORI algorithm have explained in [1] that there are very few long patterns in a random database. In a previous work [8], we used the same probabilistic model and recall here our re- sults. We also improve them with studying a MARKOVIAN model.

In this article, we propose for the first time an average analysis of the number of frequent and closed patterns for two probabilistic models of databases. In the worst cases, the results are well mastered: there is an exponential num- ber of frequent patterns, according to the number of items.

On the contrary, we provide an average analysis of the num- ber of frequent patterns, with two probabilistic models: the first is the simple BERNOULLI, where each transaction con- tains an item with a uniform probability p; the second is a MARKOVIAN model, which better reflects the correlation of the real data, because each transaction is generated by a MARKOVIAN source. Indeed, this model considers local correlations between close items but the transactions stay independent two by two. Both models are rather simple and not close to the reality, however they point very interest- ing phenomena. In particular, we show that the number of frequent patterns, with a proportional minimum frequency threshold, is surprisingly polynomial in the number of items and does not involve the number of transactions.

2 Database modelization  2.1 Definitions and notations  The set of items is noted I = {1, . . . , m} and has the cardinality m whereas the set of transactions is noted T = {t1, . . . , tn} and has the cardinality n. By definition, each transaction ti is a subset of I and a database B is a couple (I, T ). The database B admits a matrix representation ? where ? is a boolean matrix whose coefficients ?i,j , i = 1..n, j = 1..m satisfy ?i,j = 1 if and only if j ? ti. We will not discuss here about the methods for obtaining such a boolean matrix, starting from continuous or multi-valued  items (see [11] for an example). The support of a pattern A ? I is the set of all transactions containing A, and the frequency of A is the size of its support.

Definition 1 (frequent pattern). Let B be a binary database with m items and n transactions and ? a strictly positive integer smaller than n. A pattern A is said ?- frequent if |support(A)| ? ?.

We now give, in this framework, the definition of a ?-closed pattern:  Definition 2 (frequent closed pattern). Let B = (I, T ) be a binary database with m items and n transactions and ? a strictly positive integer smaller than n. Fix also ? the matricial representation of B. A pattern A is ?-closed if: - A is a ?-frequent pattern, - for all item j in I\A, there exists a transaction ti in support(A) such that j does not belong to ti, i.e., ?i,j = 0.

2.2 First hypothesis  Hypothesis on the sizes: biological databases have many items and few transactions, leading to fat databases, which are wider than high. It was observed that the number of frequent or closed patterns have a completely different behaviours than in large databases, which are higher than wide. It is then normal to consider this phenomenon. In this article, we deal with large databases where the number of items is at most polynomial in the number of transactions and vice versa. The mathematical version of this property is: (H1) log m ? c logn, c > 0.

Recall that m (resp. n) is the number of items (resp. trans- actions). We will see that this property plays an important role in our results.

Hypothesis on the frequency threshold: a pattern is said frequent as soon as its frequency rises over a user defined threshold ?. For ? = 1, experiments lead to an exponential number of frequent/closed patterns whereas for ? = n, it is constant and often equal to zero. Hence according to the frequency threshold, we may expect different results. Two kinds of thresholds are considered in this article: - fixed threshold: ? is fixed and does neither depend on n nor m. It corresponds in practice to a very small threshold compared to the number n of transactions (10 for instance).

- proportional threshold: there exists r ?]0, 1[ such that ? = r ? n. In this case, the threshold is a non-negligible proportion of all the transactions (10% for instance).

Remark that with the proportional threshold, the number of unfrequent patterns is much more important than with the fixed threshold, leading to a complete different behavior (see next section).

2.3 BERNOULLI model  We now describe the simple BERNOULLI model. Since we can not appreciate in advance the correlations existing in a databases, we first suppose that:  Model 1 (BERNOULLI model). The database (?i,j)i=1..n,j=1..m forms an independent family of random variables which follows the same BERNOULLI law of parameter p in ]0, 1[.

This model is far from the reality. Indeed, an equivalent in Information Theory is to modelize the French language with a memoryless source that respects the probability of each letter. The result is not very realistic but theoretical analysis can yet be lead.

2.4 MARKOVIAN model  In the second model, each transaction is a sequence of m random variables, with values in {0, 1} that follows a MARKOVIAN process of order k. In other words, an item belongs to a transaction according to a law that only in- volves the values of the k previous items.

The MARKOVIAN model (of order k) is completely de- scribed by the way the first k items are affected and the tran- sition probabilities (pw?x)w,x, x ? {0, 1}, w ? {0, 1}k, where pw?x is the probability that the new item takes the value x knowing that the k previous items form the word w.

We suppose that the initial values of the first k variables are given by the distribution finit = (fw)w?{0,1}k .

We now precisely describe the second model.

Model 2 (MARKOVIAN model). Fix k ? 1, finit = (fw)w?{0,1}k an initial distribution on {0, 1}k and (pw?x)w?{0,1}k,x?{0,1} the transition probabilities. Then, each transaction is computed independently from the other transactions according to the following method: for a transaction t = (?1, . . . , ?m), (?1, . . . , ?k) is com- puted according to the initial distribution finit. Then, the values of ?k+1, . . . , ?m are sequentially evaluated using the k previous values and the transition probabilities.

Contrary to the BERNOULLI model, the MARKOVIAN model introduces local correlations between items. This is of course insufficient for modeling real databases but it constitutes an improvement compare to the first model.

MARKOVIAN databases may have a sense if an organisa- tion of the items entails that close items are much more cor- related than distant items. In bioinformatics, the items are the genes and it is known that close genes are much more correlated than distant genes.

3 Theoretical results  This section enumerates three new theorems about the average number of frequent or closed patterns in a ran- dom database. Results in the BERNOULLI model always involve explicit constants. On the other hand, results with the MARKOVIAN model express with theoretical constants related to the transition matrix. The proofs can be found in [9].

Theorem 1 (Fixed threshold). Fix a threshold ? and sup- pose that the hypothesis H1 is fulfilled. Then, the aver- age number of frequent patterns Fm,n,? in a BERNOULLI database of parameter p or in a MARKOVIAN database with matrix transition P is polynomial in the number of transactions and exponential in the number of items,  Fm,n,? ? c0 n?  ?!

?m, ? > 1.

In the BERNOULLI model, ? = 1 + p? and c0 = 1. In the MARKOVIAN model, ? is the dominant eigenvalue of a strictly positive matrix and c0 is related to dominant spec- tral objects.

This average result is standard with the intuition given by the worst case: according to the number of items, there is an exponential quantity of frequent patterns. This phenomena is well known, and the difficulty of pattern mining lies in the size of the item set I. This theorem also shows that the number of frequent patterns polynomially depends on the number of transactions. This is coherent with the complex- ity of A-PRIORI regarding the number of database scans, equal to the maximum pattern length. The results with a proportional frequency threshold are more surprising:  Theorem 2 (Proportional threshold). Fix r ?]0, 1[ and suppose that the hypothesis H1 is fulfilled. Finally, suppose that the frequency threshold satisfies ? = r?n. Then, the av- erage number of frequent patterns Fm,n,? in a BERNOULLI database of parameter p or in a MARKOVIAN database with matrix transition P is at most polynomial in the num- ber in the number of items with an upper bound that does not involve the number of transactions,  Fm,n,? ? c1ms.

In the BERNOULLI model, it is an equivalence as soon as r is not a power of p. Then c1 = 1/s! and s = ?log r/ log p?.

Theorem 2 is an unexpected result. Indeed, experiments usually highlight a very important number of frequent pat- terns, even with such a proportional threshold. It is never- theless not sufficient to conclude that this quantity is expo- nential. When the threshold ? varies from 1 to n, the num- ber of frequent patterns goes from an exponential behaviour      to a constant one. Theorem 2 suggests that a proportional threshold is sufficient to get a polynomial behaviour.

We finish this section with a theorem concerning the closed patterns in the BERNOULLI model.

Theorem 3 (Closed patterns). For ? > (1+ ?) log m | logp| , the  number of closed patterns, Cm,n,? and frequent patterns are equivalent,  Cm,n,? ? Fm,n,? .

With the uncorrelated model of BERNOULLI, the number  of frequent and closed patterns coincides. In real databases, closed patterns are yet well known to be very few than fre- quent patterns and allow to design very efficient mining algorithms because they synthesise the correlations in the data. Mining the closed pattern is more complicated than for the frequent patterns, and it is not justified for the uncor- related databases.

Corollary 1. With a proportional threshold ? = r ? n, the average number of closed patterns Cm,n,? is polynomial in the number of items:  Cm,n,? ? ms  s!

where s = ?log r/ log p?.

For a large enough frequency threshold ?, the number of frequent patterns is almost equal to the number of closed patterns. Experiments with classical synthetic databases T10I4D100K and T40I10D100K confirm the theoreti- cal result [8] since synthetic data are almost without cor- relations. On the other hand, the theorem does not reflect the real behaviour of Pumsb (another database concerning fault diagnosis problem of electro-mechanical devices), be- cause this dataset does not follow our uncorrelated model and the same remark applies with the database Connect.

4 Conclusion  In this article, we have given three new results about the average number of frequent and closed patterns in random databases. It is the first time that such analysis is performed.

Two probabilistic models were studied: a BERNOULLI model that generates uncorrelated databases and a MARKO- VIAN model, where close items are correlated. These mod- els are far from real life but give new fruitful information for the pattern mining. In particular, we proved that for a fixed frequency threshold, the number of frequent patterns is polynomial in the number of transactions and exponential in the number of items. On the other hand, if the frequency threshold is proportional to the number of transactions, the average number of frequent patterns admits a polynomial behaviour with respect to the number of items. This last re- sult is unexpected for specialists that commonly refer to the worst case and its exponential growth.

The average number of frequent patterns is quite inter- esting to evaluate the complexity of A-PRIORI. In order to be complete, we also need to evaluate the size of the nega- tive border, and it is a work in progress. In the same field, we are also interested in many other open problems, such as the number of closed patterns for a fixed threshold and for other probabilistic models, the average size of the pos- itive border, the average size of the largest frequent (which corresponds to the number of steps for A-PRIORI), etc.

