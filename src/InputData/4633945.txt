

=  ?  ?? ?=?  ?=  =  =  1158 2008 International Joint Conference on Neural Networks (IJCNN 2008)      ?  ?  ?  ?  ?  ?  ?   ?  ?  ?  ?      ?  ?    2008 International Joint Conference on Neural Networks (IJCNN 2008) 1159    1160 2008 International Joint Conference on Neural Networks (IJCNN 2008)    been used. From figure 7, we can find imputation correcting rates descend when minimum supports are from 5, through 15, 25 to 35.  Especially minimum supports are more than 25 percent, imputation correcting rates descend sharply.

Fig. 7.  The distribution of imputation correcting rates by different minimum supports in train data sets  Figure 8 also gives the distribution of imputation correcting rates by different minimum confidence. When minimum confidences are 70 percent, imputation correcting rates achieve max values in two train data sets, but when confidences are more than 70%, imputation correcting rates descend quickly in monk1 and monk2 data sets. From figure 7 and figure 8, we can find that higher support and confidence levels may not result in higher prediction accuracy. The higher supports and confidences mean the less strong rules that can be used.  So, a sufficient number of rules is a precondition for high prediction accuracy. We may consider that varieties of minimum supports and minimum confidences are the key factors to affect the usefulness of our method.

Fig. 8. The distribution of imputation correcting rates by different minimum confidences in train data sets  Lastly, we use our method in bridges and labor data sets which contain missing data. Firstly, we omit all missing data to generate association rules set, then for each attribute that contains missing data, we use our method to impute missing ones. Because we do not know the true values of the missing data in data sets, so we test the validity of association rules based on weighted voting imputation method by comparing with classification accuracy before or after imputing missing data. See table 4 and table 5 for detail. Experimental results in these tables indicate that the accuracy of classification is increased when the proposed method is applied for missing attribute values imputation except the bridges data set in  Na?ve Bayes method. These results prove that our method is feasible in some incomplete data sets. Here, we use AlphaMiner 2.0 which is developed by HIT-HKU Business Intelligence Lab. to finish the classification experiments.

TABL COMPARING WITH CLASSIFICATION ACCURACY BEFORE OR AFTER  IMPUTATION OF BRIDGES DATA SET  Classification methods  Accuracy of containing missing  data  Accuracy after imputation  missing data C4.5 88% 89%  Decision Table 76% 79% Na?ve Bayes 91% 88%  Multilayer Perceptron 74% 75% HyperPipes 100% 100%  TABLE COMPARING WITH CLASSIFICATION ACCURACY BEFORE OR AFTER  IMPUTATION OF LABOR DATA SET  Classification methods  Accuracy of containing missing  data  Accuracy after imputation  missing data C4.5 89% 91%  Decision Table 93% 95% Na?ve Bayes 89% 93%  Multilayer Perceptron 93% 96% HyperPipes 58% 75%

IV. CONCLUSIONS In this paper we have proposed a new imputation method  based on the weighted votes of association rules. In order to test the performance of the proposed method, five UCI databases have been selected in the experiment. Experimental results show that the proposed method is feasible in these databases. It should be noted that the proposed method can only used to handle the discrete values. How to impute the continuous missing values will be discussed in another paper.

