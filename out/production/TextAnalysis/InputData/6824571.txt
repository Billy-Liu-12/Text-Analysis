A New Architecture for Cloud Computing System Protection

Abstract?According to the National classified protection of information system security requirements, the cloud computing systems classified above rank 3 is important information system, playing vital roles from the point of view of National Security. This paper develops a conceptual framework with which to address the protection of integrality protection named ?Dual Systems Architecture? to protect computing environments. While attempting to be logical and rigorous, formalism is avoided.

Keywords- important information system;trusted computing; formal method

I.  INTRODUCTION Transitive trust is the key technical to achieve the  controlling ability of Trusted Computing Platform. TCG presents that if the information system starts from an initial root of trust, and every time the transition of the right of control, the trust will be transferred to next components by integrity measurement, thus the platform computing environment is always credible. Trusted Platform Module is a kind of SOC chips and is the root of trust for trusted computing platform. For TPM, operation systems and applications are all objects that need to precede the integrity measure because of the external need. So when a new module is loaded in the internal storage, first the kernel of OS takes charge of distinguish and examination whether the module is credible. If what is loaded is distinguished to be a credible module (such as a driver), the kernel of OS would allow the loading action, conversely if it is distinguished to be incredible, the kernel of OS would refuse the load.

Transitive trust transmission models that presented by TCG usually is BIOS OS Loader OS Kernel, finally is passed on to the kernel load area of OS. On Linux platform, Sailer[1-2] fulfilled credible transmission of executable code from OS to applications, Maruyama[3] explored credible transmission mechanism from Grub to OS. Huang Tao[4] gave the way to fulfill the credible guide on server platform.

Research in transitive trust now include European OpenTC, NGSCB of Microsoft, LT technic of Intel and so on[5-7].

TCG software stack (TSS) is software that supports TPM on trusted computing platform. The main aim of TSS includes the following aspects:  1) Offer an entry point for applications to use TPM 2) Offer the synchronous access to TPM 3) Hide the byte ordering and aligning of structuring  command stream to applications  4) Manage the resource of TPM (include create and free) The architecture of TSS can be divided to trust service  provider (TSP), trust core service(TCS), trust device driver library (TDDL), trust device driver(TDD) and so on levels, TSP, TCS and TDDL are all executed on application level.

For the four goals mentioned above, the way for TSS to achieve them is: first, offer a trusted computing function entrance to applications by the TSPI interface of applications; next, offer a TSP instance to every application, only achieve a TCS mirror in system; then, offer a unified TDDLI interface in TDDL, hide the details of command stream of TPM; finally, achieve various managers in TSP and TCS of application level to manage the resource of TPM.



II. THE DESIGN STRUCTURE FRAMEWORK OF TRUSTED ASSURANCE OF DUAL SYSTEM  The Trusted Computing Group attempts to resolve the weakness of traditional Von Neumann cloud computing architecture lacking of security mechanism have gain several achievements by adding trusted hardware[8-11]. However, there are still three remaining issues on the essential information system security assurance.

1) Lacking reasonable security architecture. Current trusted computing single architecture can?t separate trusted computing base and operation system. Hence they are vulnerable to the attacks and violation and can?t fulfill the purpose for protection: several dual-system architectures are based on attribute value to maintain the passive protection mechanism. The trusted computing function is called passively by the application. Once the security loopholes are attacked there are no restrictions on those illegal usages.

2) Lacking trusted resources sharing methodology. With multiple applications sharing the same trusted resources. The dynamical calling of the trusted services may lead to the potential conflicts, deadlocks, dispatching problems.

3) Lacking information flow security mechanism among the applications in current operation system. Application can easily be called by others, enabling free flow of information that is unnecessary, which cause unexpected circulation of information.

4) Lacking of verification mechanism between security attributes and practical engineering. Abstract model and real system are different from observation perspective. Security attributes in Formalized models are highly conceptual abstraction.  In the real system, there is lacking of transition   DOI 10.1109/CBD.2013.6     and explanatory methodology. Consequently bring disjoint between practice and theory.

This paper puts forward credible security system architecture to achieve trusted computing core function on OS level to support the initiative credible monitoring action.

This architecture builds a credible software base that is logically relative independent to manage credible resource and computing process by virtual method and support credible mechanism of monitoring application resource processing behavior by active intercept on system level.

Trusted assurance of dual system has features which are entirely different from single system. We design its function to initiative control mechanism, credible computing service mechanism and other related auxiliary mechanism. At the same time, combining with the function of initiative measure control of TPCM, hierarchical architecture of CDSA and the double system idea of TBOS, we give the basic framework of dual system initiative credible security as following.

Compared with the TSS norm of TCG, this system increases credible access, credible computing framework, credible data base, credible resource management and so on; it also includes what is presented in TSS such as the synchronous access to TPCM, being able to hide the structuring command stream to applications, the management of credible hardware resource of TPCM and so on. The model is shown in figure 1:   Figure 1. Trusted assurance of dual system architecture  TSB and the host system are logically separated; two systems are combined by system switch of interface. For the applications of host system, application visible accessing resources are virtual resources by system calls, what they really access is the physical resources that are mapped from application level to source level. So during the process of the access of virtual resources, we put the stuck point in it, logically switch the information to the judgment of TSB and then access the virtual resources. But for the applications, the flows happen in TSB are unaware; we call the flows  transparent to applications. The initiative credible security functions that TSB has mainly include:  1) Initiative measure control function: because applications use virtual application resource (VAR) by system call, so TSB deploys host stuck point (HSP) during the system call service, initiatively intercepts the information of applications and sends it to TSB to measure and judge.

The host stuck point of TSB gets the context of application object from host, gathers credible related information and access control related information of application, changes over to TSB by system switch interface, TSB processes credible measure and credible control according to this information. It executes credible measure operation according to credible measure policy; determines the credible attribute of related objects by the result of measurement and the credible judgment policy, then writes it to the credible context of the object stored in TSB; determines mode of control by the attribute of system action, credible attribute of related object and credible control policy; executes credible control operation. The computing result is returned to host system by the host stuck point of TSB. The access control strategies executed in TSB are common discretionary access control strategies and mandatory access control strategies. This security policy is totally in an environment independent of host system when they are executed in TSB, the privileged core process in host system can?t interfere it, so we solve the security problem discussed before in system.

2) Offering credible computing function: after judgment, applications that need credible service send the information that the credible service need to TSB by host stuck point.

TSB configures exclusive virtual credible service environment for it by building credible pipelines, and sends the computing result to applications by host stuck point.



III. FORMALIZATION OF TRUSTED ASSURANCE OF DUAL SYSTEMMODEL  We give the security approximation requirements in non- ideal conditions by defining and describing security computing environment in ideal conditions, so that we can simulate the security effect of trusted assurance of dual system.

A. Security Computing Environment in Ideal Environment We think the attributes of an ideal security computing  environment are: the policy of application layer, system layer, resource layer has perfect mapping (as the picture 3.4), as:      Figure2. Perfect mapping in an ideal system  1) The real policy that the user layer formulates in computing environment completely shows the security requirement  2) The safety policy formulated by applications in application layer can completely translate the real policy of user layer and switch it to comprehensible action of OS layer, then transfer it downward;  3) The application security policy executed by OS can be completely executed without tamper and by-pass, so that we can achieve the right access to the physical resource in resource layer.

Next we will give the formalized description: Definition 1: computing environment (E) includes the  following component:  1 2={ , ,..., }nP p p p  means the set of real security policy formulated by users in computing environment;  1 2{ , ,..., }nA a a a=  means all the applications in application layer;  1 2{ , ,..., }nO o o o=  means all the operation behaviors executed in OS;  1 2{ , ,..., }nRE re re re=  means the set of hardware resource in resource layer, just the storage space that the application really possesses in physical hardware  1 2{ , ,..., }nSE se se se= because there may be multiple OS in computing environment, so SE means all the OS and applications that executed in computing environment. SE proceeds the perfect management to all the resource of OS;  Definition 2: when the security policy p of real user is executed in system, the executive of it is application a, let  { , , ,[ , ]}s ea PO I Q t t= .

PO is theoperation setallowed in application a; I is the input set of application A; Q is the output set of application A;  [ , ]s et t  is the operation execution time from ts to te for application a.

So from the definition we can know that the real policy logic in computing environment determines the concrete behavior of application a.

Definition 3: event ? is defined as the security policy that task a achieves in computing environment as users expect, mark as : P c? ? .

Definition 4: computing environment CE means the task that follows the uniform security policy c and the set of hardware resource, system service platform and resource related to it.

{ | ( ) }i iCE RE SE O a a c= ? ? ? ? = Because we need to make sure that user?s policy is  accurately executed without tamper and by-pass during the implementation, we need to make forced control of the authority when task a is executed, and make sure task a is executed the semantic of user?s policy without unexpected action. So we should regard application as abstract function, the methods of determine whether the security policy made by users can be completely converted to security mechanism is defined as follow:  Definition 5: suppose A is a function: 1 nI I R? ? ?? .

So A is an application with n inputs k ki I? ,1 k n? ? , and an output r R? .

Definition 6: suppose E is the output set when application a returns error results during the operation. Security mechanism m is a function:  1 nI I R E? ? ?? ? , k ki I? ,1 k n? ? Then 1) 1 1( , ) ( , )n na i i a i i=? ?  or 2) 1( , )nm i i E?? Definition 7: suppose the security policy of application a  is 1: nc I I A? ? ?? , then the security mechanism of application a is m: 1: nm I I R E? ? ?? ? . if and only if for all the k ki I? , 1 k n? ? , function ' :m A ? R E? satisfies 1 1( , , ) '( ( , , ))n nm i i m c i i=? ? . We think security mechanism m is safe. This definition explains that for any input set, the return value of security mechanism is in accordance with the security policy c.

Definition 8: suppose m1 and m2 are two security mechanisms in policy c, m1 and m2 are independent each other. If for all the inputs 1( , )ni i? , 2 1( , , )nm i i =?  1( , , )na i i? , and 1 1 1( , , ) ( , , )n nm i i a i i=? ? , then m1 and m2 are similarly accurate. If there are inputs 1( ', ')ni i? ,  1 1 1( ', , ') ( , , )n nm i i a i i=? ?  and  1 1 1( ', , ') ( , , )n nm i i a i i?? ? , then m1 is more accurate than m2.

Definition 9: suppose m1 and m2 are protection mechanisms of application a , then the combination of them m3=m1 m2 is defined to be   1 1 1 1  3 1 2 1 1  1 1  ( , ) ( , ) ( , ) ( , ) ( , ) ( , )  ( , )  n n n  n n n  n  a i i if m i i a i i or m i i m i i a i i  m i i else  =? ?= =? ? ?  ? ? ? ? ? ?  ? T heorem 1: for the function 1( , )na i i? , the output available information after execution can be achieved by 1, ni i? .

Theorem 2: for any security policy c and application a, if there is a security mechanism m to be accurate, then application a is security.

Theorem 3: computing environment E is secure if it contents theorem 3-1 and theorem 3-2.

B. Security Approximation Conditions Based on Non- interference Attributes For all the reasons talked above, important information  system computing environment can?t reach the ideal security state. So we give the security approximation conditions in non-ideal state, just the approximation attributes of system.

Definition 10: suppose ( )B B S??  is all the visible operation to system for a certain user, so the user can only see the trace shown by his window ( )B B S?? , which we call ?the part of ( )t t S??  confined to window B, mark as . And:   Definition 11: all the trace of s user B can see is called  the projection of S on B, mark as :   And   Definition 12: the deduction extent of S after user B?s  survey l  is defined as  just ?all the t in ? S that contents t| B = l  can reflect the extent of deduction to system S that B makes.

And   If user is S? , then the observing window of him is all  the system alphabet, so his observing window and system behavior are accurately corresponding and he can deduce the behavior happening in system; otherwise if user can?t observe the system, just the observing window is blank {} user can?t do any deduction.

For example: the alphabet A of system S ={a, b}, S first executes event a ,then executes event b ,finally ends.

So: . The trace of , the projection of a, b on S is  , , then a ,b can get deduction from each window is:     So user a in system S can?t deduct whether and when  event b happens from window {a}.

We mark system Q as { , }A a b= , mark action of system  Q as : . The trace of Q is , the projection of a, b on R is , , so a, b can get deduction from each window is:   So users in system Q can?t deduct how many times event  happens by window {b}, but only know event a will happen after b happens once.

C. CSP Description without Interference  Because process algebra CSP has quite completely formalized descriptive approach to what process may do and what process has already done, it is very easy to combine with non-deducible model, express security policy such as ?system will never divulge information? and make real modeling and confirmation to security attributes of system by this formalized description. The object CSP focuses on is the behavior model of guest in system, just process. Each process is related to a component. The alphabet in CSP shows all the events a process may do. Trace shows each event the process has already done and can be recorded one by one.

Mark the sets of all the events a process can provide at original state in certain environment as X, at the same time suppose the environment has the same alphabet as P. Now put P in the environment. If P is deadlock at the beginning of execution, we call X as a rejection set of P. Mark the set of this kind of rejection set as ( )refusals P . To an uncertain process, at some point it may refuse the execution of an event because of an uncertain choice in it. If a process can?t execute all the events it can execute, we call this process certain process.

Mark the rejection set of process as , the specific definition of it is:   /P s means P after event in the execution trace s.

P can execute all the event sequence recorded by trace s, and then refuse to do more things. We mark it as an impasse ( , )s X . Using CSP to describe stable failures model:  Theorem 4: if , ' ( )a a traces S? ?  makes 'La a? ( / ) ( / ')initials S a L initials S a L? = ?   Then , ' ( )b b traces S? ? , satisfies  .

The meaning of  is the set of trace s limited in  event set A, just the set of trace without all the events that don?t belong to A.

Theorem 4 shows that if the traces that content (1) (2) are of equal value, S still can receive or reject the same event, and then s contents the attribute of noninterference in L.

Proof: the way to prove they are of equal values to prove the two impasses belong to each other.

Use any  to prove . Mark as ( , )f c X=  From the projection of impasse we can know there exists ' ( ', ')f c X=  makes  .

First we investigate the rejection set 'X : Because , so  . Make projection of two sides, then , or equal to . From the hypothesis 'Lb b?  we can know that 'Lc c? . The projections of their sequence on L are still equal, just . From our hypothesis  .

Then we investigate trace 'f : We want to prove that . Mark  trace 'c as 1 2' , ,..., nc e e e=< > .From the definition we can know .

If ie L? , it means that   From the logic above,   means .

So from our hypothesis:  So if ie L? , then  .

Use the biggest i(mark as i*), from the definition of trace  we can know *1 2, ,... ( / ')ie e e traces S b< >? . So, because the sequence *1 2, ,... ie e e< > includes all the events in c, we can know that . This means ( / ')c traces S b? , accordingly  .

By transforming to the presentation that can be simulated  by CSP, just after the CSP description of system, by simulating whether it contents theorem 4, we can prove whether the system is of noninterference, just achieve the security approaching of system.



IV. CONCLUSIONS This paper aims at the characteristic of cloud computing  environment and the problem of it, gives theory model of innovative initiative security protection base of dual system, describes it by formalized method and gives the authentication method of security attribute.

