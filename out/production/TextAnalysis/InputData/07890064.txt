Evaluation of Task Clustering Algorithm  by FFT for Heterogeneous Distributed System

Abstract? In this paper, the evaluation result of a task clustering heuristic algorithm proposed for heterogeneous distributed systems is shown. The proposed heuristic algorithm is based on our original concept, known as ?Worst Schedule Length (WSL)?.

It derives the lower bound of the total execution time of the cluster for each processor using WSL, then the processor which contributes to minimize WSL is chosen as an assignment target.

Task clustering is then performed to get minimal response time (i.e., minimal schedule length). We show that our proposed method has advantages over existing conventional approaches through the evaluation results.

Keywords? Big Data, Distributed Processing, Fast Fourier  Transform, Task Graph

I. INTRODUCTION Distributed processing is indispensable when dealing with  large scale of data like big data. Especially in cases of heterogeneous distributed systems with various processing speed and communication bandwidth, it is necessary to assign multiple tasks to multiple processors adequately. Assuming a job is expressed as DAG (Directed Acyclic Graph) it is necessary to develop a task clustering algorithm to assign multiple processors to multiple tasks. DAG is a directed graph where nodes represent tasks and directed edges represent the dependency among tasks. Assigning tasks in DAG to processers to minimize the response time is known as NP- complete problem [1], and several heuristic algorithms have already been proposed such as HEFT (Heterogeneous Earliest Finish Time) [2]. However these are not efficient for jobs that transfer large amounts of data.

In this paper, the evaluation result of the task clustering heuristic [5] algorithm proposed for data intensive jobs on heterogeneous distributed systems is shown. The proposed heuristic algorithm is based on our original concept, known as ?Worst Schedule Length (WSL)?. We derive the lower bound of the cluster size assigned to each processor using WSL, then the processor which contributes to minimize WSL is chosen as an assignment target. Then the task clustering is performed to  get minimal response time (i.e., minimal schedule length). We show that our proposal has advantages over existing conventional approaches through the evaluation results.



II. ASSUMED MODEL  A. Job Model  We assume that a job is expressed as a directed acyclic graph (DAG), which is known as a workflow type job. GScls = Vs, Es, Vscls (Fig 1) is the DAG, where V is the set of tasks, E is the set of edges (data communications among tasks), and Vscls is the set of task clusters including one or more tasks by s task clustering steps.

Figure 1. Example of Job Model [3]  This means that GScls has (|V| ? s) unclustered tasks and |V| = |Vscls| for s = 0. The i-th task is denoted as nsi, and let   ISBN 978-89-968650-9-4 ICACT2017 February 19 ~ 22, 2017    w(nsi) be the size of nsi, i.e., w(nsi) is the sum of unit times for processing by the reference processor. We define data dependency and direction of data transfer from nsi to nsj as ei,j, where c(ei,j) is the sum of unit times for transferring data from nsi to nsj over the reference communication link. One constraint imposed by a DAG is that a task cannot start execution until all data from its predecessor tasks arrive.

pred(nsi) is the set of immediate predecessors of nsi, and suc(nsi) is the set of immediate successors of nsi. If pred(nsi) = ?, nsi is called START task, and if suc(ni) = ?, nsi is called END task. If there are one or more path form nsi to nsj, we denote such a relation as nsi nsj.

B. System Model We assume each computer in the system model isconnected  to others with various processing speeds and communication bandwidths. Data transfer time within one computer is supposed to be negligible.

C. Task Clustering Task clustering is to merge tasks into a cluster to localize  data transfer and tasks in a cluster are assigned to the same PE (processing element). Also by localization of data transfer, c(ei,j) i.e., data transfer time becomes zero in the cluster.

Procedure of task clustering is as follows; Let cls(i) be the i-th cluster in Vscls If nsi is included in cls(i) after the (s + 1)-th task merging step, we formulate one task merging step as clss+1(i) clss U {nsk}  Task clustering is finished when a certain criterion is satisfied, otherwise the process mentioned above is repeated.



III.MINIMIZING WORST SCHEDULE LENGTH(MWSL)  A. Worst Schedule Length(WSL) WSL is the maximum execution path length, in case  each  task is executed as late as possible in a PE, provided that there is no data waiting time for each task once the PE starts execution. That is, WSL is a value determined for each task that is assigned to the PE, so that if it is assigned minimized WSL, it can be shown that the actual lower bound and the upper bound of the schedule length becomes smaller [4].

Table 1 shows notations for deriving WSL. WSL(M(Gscls)) is the maximum of LVs(clss(i)), which corresponds to the maximum of level(nsi ), where nsi clss(i). level(nsi ) is the maximum time duration from the START task to the END task in case nsi is scheduled as late as possible. That is, WSL(M(Gscls)) is the maximum level value in all tasks at the clustering state of M(Gscls). For a task cluster clss(i), tops(clss(i)) is the set of tasks which can start execution first in clss(i), and ins(clss(i)) is the set of tasks having incoming edges from other task clusters and outs(clss(i)) is the set of tasks having outgoing edges to other task clusters. btms(clss(i)) is the set of tasks having no immediate successor tasks in clss(i), and dc(nsi ,clss(i)) is the set of tasks being one of descendant tasks of nsi in clss(i). S(nsi , clss(i)) is the time span from the start time of the task in tops(clss(i)) to the start time of nk in case that tw(nsi, pp) = 0 and every task having no dependencies  with nsi is executed before nk. TLs(clss(i)) is the latest start time of the task in tops(clss(i)), and tlevel(nsi ) is the latest start time of nsi without data waiting time if nsi tops(clss(i)).

tlevel(nsi ) is derived by S(nsi , clss(i)) if nsi tops(clss(i)), otherwise it is the latest data ready time. blevel(nsi ) is the longest path length from nsi to the END task, and BLs(clss(i)) is the maximum execution path length including S(nsi , clss(i)) and blevel(nsi ). If LVs(clss(i)) is defined as the sum of TLs(clss(i)) and BLs(clss(i)), WSL at M(Gscls), i.e., WSL(M(Gscls)) is defined as the maximum value of LVs(clss(i)) where clss(i) Vscls.

TABLE 1. Notation for WSL(M(Gscls)) [4]  Parameter Definition tops(clss(i)) The set of tasks having no immediate  predecessor tasks in clss(i) ins(clss(i)) The set of tasks having one or more  immediate predecessor tasks in the cluster other than clss(i)  outs(clss(i)) The set of tasks having one or more immediate successor tasks in the cluster  other than clss(i) btms(clss(i)) The set of tasks having no immediate  successor tasks in clss(i) dc(nsi ,clss(i)) The set of tasks in clss(i) having paths  from nsi, i.e., {nsj | nsi nsj , nsj clss(i)} U {nsi}  S(nsi , clss(i)) nsl clss(i)  w(nsj) - nsl dc(nsi ,clss(i))  w(nsj)  tlevel(nsi ) nsj pred (nsi) m a x{ tlevel (nsj) + w(nsj) + c(esj,i)},  if nsi tops(i) TLs(clss(i)) + S(nsi , clss(i)),otherwise  TLs(clss(i)) nsi tops(clss(i)) m a x{tlevel(nsi)}  blevel(nsi ) nsj suc(nsi ). nsj clss(i) m a x{w(nsi) + c(esi,j) + blevel  (nsi)}  level(nsi ) tlevel (nsi) + blevel (nsi) BLs(clss(i))  nsi outs(clss(i)) m a x{ S(nsi , clss(i)) + blevel (nsi)  LVs(clss(i)) TLs(clss(i)) + BLs(clss(i)) = nsi clss(i) m a x  {level(nsi )} WSL(M(Gscls))  clss(i) Vscls m a x{LVs(i)}   ISBN 978-89-968650-9-4 ICACT2017 February 19 ~ 22, 2017    Figure 2. State after 4 task merging [3]  B. Algorithm MWSL consists of the following 2 phases:  1)  Phase-1 We define ? as a lower bound of the execution time at a task cluster. At first, we identify the path generating WSL by using virtual PE with the maximum processing speed and maximum communication bandwidth (we shall call "virtual PE"). We derive the upper bound of the WSL for each clustering step. Such upper bound of WSL is a function of ?, processing speed and communication bandwidth of PE. Next, we choose a PE minimizing the upper bound of WSL from PEs that have not been assigned to clusters, then differentiate the upper bound of the WSL with respect to ? and get the minimum value of the upper bound of WSL.

Figure 3. Try to minimize WSL [3]  2)  Phase-2: In MWSL, two clusters are merged into a new task cluster in order to reduce WSL. The first one is called "pivot", and the other is called as "target" [4]. At first, a task cluster, which dominates WSL is selected as pivot. Then a task cluster, by which WSL reduction is achieved by  merging it with pivot, is selected as a target. This merging step is repeated until execution time of the new cluster exceeds the ?opt.. Phases 1 and 2 are repeated until all tasks are merged into clusters and assigned to PEs.



IV.EVALUATION RESULT  A. Evaluation Method We compare the proposed algorithm with HEFT by using  specific jobs. We chose FFT (Fast Fourier Transform) as the exemplary job. Next, we generated FFT DAG and implemented it using a simulation program. The maximum to minimum ratio in terms of processing speed and communication bandwidth are set to 10, respectively. Then we derived the response time by averaging 100 DAGs for the comparison. As for the characteristic of each DAG, we varied CCR (Communication to Computation Ratio) ranging from 1, 5, and 10. CCR in this simulation is derived by the averaged data transfer time to the averaged processing time, i.e., CCR=1 means transferred data is the same as processing tasks, CCR=10 is in the case of transferred data is 10 times of processing tasks.

B. DAG of FFT  In the simulation, we define Butterfly Computation as one task. Therefore, the FFT DAG generates N/2logN tasks, where N is the matrix size [5].

Figure 4. The DAG of FFT in the case of N = 8  If the matrix size of the FFT DAG is 8, this DAG generates 12 tasks. Moreover, each task executes the same operation, so that execution time of each task is the same if the assigned processor has the same processing speed.

C. Simulation Results The simulation of FFT has been performed in the case that  N = 128 and N = 256. Table 1 shows the result in case that N = 128 and N =256, and Table 2 shows the data showing Table 1 as a ratio of MWSL. Fig.5 shows the result of simulation in case that N = 128 and Fig.6 shows in case that N = 256.

ISBN 978-89-968650-9-4 ICACT2017 February 19 ~ 22, 2017    TABLE 2. The data by simulation in case that N = 128 and N =256  Matrix Size CCR MWSL HEFT  N=128 1 993.04 1159.58 5 1132.02 1412.83 10 1132.71 1766.61  N=256 1 1150.94 1323.49 5 1314.97 1666.49 10 1337.76 2101.93  TABLE 3. The data showing Table 1 as a ratio of MWSL  Matrix Size CCR MWSL HEFT  N=128 1 1 1.1677 5 1 1.2481 10 1 1.5596  N=256 1 1 1.1499 5 1 1.2673 10 1 1.5712  Figure 5. The result of simulation in the case of N = 128  Figure 6. The result of simulation in the case of N = 256  From Table 1, Table2, Fig. 5and Fig. 6, it can be seen that MWSL shows better response time as CCR becomes larger.

Therefore, it can be concluded that MWSL is more suitable algorithm than HEFT for data intensive jobs.



V. CONCLUSIONS In this paper, we have shown the evaluation result of our  proposed algorithm.

We performed a simulation of FFT 100 times in each case  N = 128, N = 256 we compared response time of HEFT with MWSL. From the simulation results, we have shown that our proposed algorithm is a more suitable algorithm than HEFT in the case of large application of data.

