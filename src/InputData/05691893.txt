Improvement and Realization of Association Rules  Mining Algorithm Based on FP-tree

Abstract Traditional FP-growth algorithm adopts FP-tree structure to express association of item sets in transaction sets and finds all of frequent item sets recursively. The algorithm increases the time complexity and the space complexity in calculating conditional pattern base, because it backtracks the same paths many times. As to the above defects, a FPIFM algorithm is presented in the paper. The algorithm stores all of precursor nodes of every node in the node domain, then the sub- condition pattern base of every node are calculated. Finally, sub-condition pattern base are combined and ergodic nodes are released. Experimental result shows that FPIFM algorithm is superior to the traditional FP-growth algorithm.

Keywords-data mining; association rules; frequent pattern tree; conditional pattern base

I. INTRODUCTION Data mining mines the knowledge which is implicit, useful  and unknown from a mass of original data. It provides theoretical basis for market planning, enterprise management and enterprise decision[1]. The process of data mining is the process of finding knowledge. Association rule mining serves as an important subject in the data mining domain[2]. At present, most algorithms[3,4,5] are the series of Apriori algorithm and its improvement. They have the same defects as the Apriori algorithm, it needs multiple-scan the database repeatedly and produces plenty of candidate sets.

Jiawei Han, Jian Pei and Yiwen Yin etc presented FP-growth algorithm to overcome the defects of Apriori algorithm. It compresses every record in the database into a FP-tree by the technique of dividing and rule to keep the relationship among the items; then, frequent item sets are mined by creating conditional pattern base. The algorithm needs only scan the database twice and does not produce candidate frequent item sets. Moreover, it calculates frequent patterns by the frequent degree of every item sets, according to the sequence from low to high. However, The algorithm scans the same path many times when calculating frequent patterns, namely, after calculating frequent patterns of an item set, it will backtrack ergodic paths again when calculating frequent patterns of its parent node, and this will lead the unnecessary overhead. Meanwhile, the algorithm occupies plenty of memory (It is relevant to the depth and width of FP-tree).

Therefore, it will not effectively work, if the number of frequent 1-itemset is large and the mapping information of all items in the FP-tree cannot be stored in the memory[5]. Minyu Shi etc presented frequent pattern mining algorithm based on FS-tree, the space complexity of algorithm is obviously reduced through splitting FP-tree into many FS-trees[6]. Wei Shi etc presented FPRSG algorithm, the storage mode and  creating mode of conditional pattern base in the FP-growth algorithm are changed, through introduce data structure FP reference tree/table, and the frequent pattern mining problem is solved efficiently[7]. Yuejin Yan etc presented the maximum frequent set mining FPMFI algorithm, using the mechanism based on superset checked by projection, the time of superset check is reduced effectively, at the same time, the scale of FP subtrees is compressed effectively by delete the redundant information of FP subtrees, so it reduces the ergodic overhead[8].

In order to solve the problem that it travels the same path twice that is mentioned in the previous paper, and the problem that the FP-growth occupies plenty of memory. A domain can be increased on every node of the FP-tree to store its parent node, to avoid scanning the same path many times when we calculate its frequent pattern; meanwhile, it adjusts tree structure and deletes the node to reduce FP-tree when a leaf node is calculated to optimize.



II. BASIC CONCEPTS AND FP-TREE STRUCTURE  A. Relative definition and properties Let { }miiiiI ,...,,, 321=  serves as a set of all items and if a  set is X, IX ?  and Xk = are true, X is defined as the k-itemset. DB acts as the set of all transactions (that is a database), each transaction T is a set of some items, IT ? , for the given database DB, the support of X is defined as the number of transactions that include X in the database, denoted by )(XSup . A user-define minimum support number is less than equal to |DB|, denoted by min_sup.

Definition 1 Given the transaction database DB and the minimum support min_sup, for a item set IX ? , if  supmin_)( ?XSup  is true, X is defined as a frequent item set in the DB. Meanwhile, if Xk =  is true, X is defined as the  frequent k-itemset in the DB, denoted by kL .

Definition 2 Conditional pattern base of the item set composed of lots of parts which are obtained by the path that includes the item. Every part is defined as a sub-conditional pattern base.

B. Frequent Pattern Tree FP-tree and FP-growth 1) FP-tree preserves original database, the structure  consists of a root node(the value is null), prefix of items sub-trees(as children)and a head table of frequent items. Every transaction in the DB is compressed in the FP-tree by scanning     DB twice, a transaction is presented as the path from each leaf nodes to root nodes in the DB. Because the overlap of some anterior item sets, the DB can be compressed by share the superposed item sets, and the first appeared position of each item is preserved in a Head table. Every node in trees represents an item, the node preserves relationship among items. Each node consists of 5 domains: the node frequency m_sFreq, the node name m_sItem, the parent node m_pParent, the right brother node m_pRight_bro, the left child node m_pLeft_child, the same name node m_pNext. Parent node, brother nodes and childern nodes can be found through these domains.

The creation process of FP-tree is as follows: At first, scanning the DB, find out the items which are satisfied with the support count, and combine them to frequent 1-itemset L. Then put them into the Head list in descending order based on the support count. Following, create the original FP-tree which sets ?NULL? as its root node. And then, the header table is created, in order to travel the original FP-tree more convenient, a frequent item is represented by each line in the item head list, and the corresponding pointer is set to point the node in the FP-tree. Then travel the DB for the last time, and adjust the sequence of items in the DB according to the Head list.

Creating a transaction branch for each transaction whose sequence of items is adjusted. If the branch can share the path, then do it ,and record the number of sharing transaction on each node[9]. As the table 1 shows, TID represents the number of transaction in the DB and Item ID represents its content. The created FP-tree is shown in Fig. 1.

TABLE I.  TRANSACTION RECORD  TID Item ID TID Item ID  T1 a,b,e T6 a,c  T2 b,d T7 c  T3 a,c T8 b,d  T4 c T9 a,b,e,f  T5 a,b,d,f T10 c     Figure 1.   FP-tree  2) FP-growth algorithm is a new method for mining all frequent item sets, which does not produce candidate sets. It  adopts divide and conquer strategy as follows: DB offering frequent item sets are compressed in a FP-tree, and reserve correlative information among item sets, then the DB which is compressed is divided into a group of conditional DB, it is linked to a frequent item and is mined respectively.

C. FPIFM Algorithm FPIFM algorithm adds two domains in every node in  FP-tree: m_sFrearea and m_sFlag. The former is used for storing sub-frequent pattern base and the latter is used for judging whether the node is processed. Travel the path that the node exists in when seeking the sub-frequent pattern base of a certain node, then the sub-frequent pattern base of each node in the path is obtained, and they are stored in the m_sFrearea.

Next time, when the sub-frequent models of parent node are calculated, traveling is avoided, so it can avoid the repeated ergodic on the same path. Meanwhile, when the sub-frequent pattern bases of every nodes are calculated with the algorithm, nodes have been processed and without left and right children are released.

The pseudocode of the FPIFM algorithm is as follows: Input: present FP-tree; Head table that the frequent degree is in descending order Output: frequent item sets of every ID (1) For every? in the Head table//operating according to the  order of the support which is from low to high (2) { for? appearance in the FP-tree every time (3)   { if(m_sFlag== 0)  // nodes not be processed (4)     {sub-frequent pattern bases of every nodes are  obtained and they are stored in the m_sFrearea ; (5)      m_sFlag= 1; (6)      } (7)     else (8)        break; (9)    } (10)    for sub-frequent pattern base of every node (11)    { if(the support sum of sub-frequent pattern base >  min_sup) (12)      Stored in the frequent List with no repeat; (13)    } (14)    Output result in the frequent List; (15)    Free? ; (16) }

III. ANALYSIS OF PROPERTY AND COMPARISION OF EXPERIMENTAL RESULT  The FPIFM algorithm have two advantages compared with FP-growth algorithm:  1) It calculates conditional pattern base of every node in the FP-tree and stores the result in the m_sFrearea after one ergodic. It is different from original algorithm that is to solve by the sequence of the head table. This avoids repeated ergodic on the same path. Here, the main workload of algorithm includes judging m_sFlag and creating the conditional pattern base. Its time complexity is O(n). The nodes share the prefix more ,the time consumed is shorter.

2) Meanwhile, the strategy of deleting FP-tree is used in the algorithm , when the conditional pattern base of a certain node is obtained, judging whether children are exist, if the node has children, jump out the loop, and calculate the next node.

Else, free the node. It decreases the consumption of memory gradually, which become more obvious with the algorithm operating in the rear. Here, the main workload of the algorithm is judging whether it has the children node, its time complexity is O(n).

In order to test property of algorithm, we select loose data set T10I4D100K as testing data, FP-growth serves as object of comparison. Experimental environment is as following: Intel(R) core(TM)2 Duo CPU T6670 @2.20GHZ, 2GB memory. Operating System is windows 7. Code is realize in Visual C++6.0.

Figure 2.  Running time of two algorithms  Figure2 displays running time of the FPIFM and FP-growth algorithms under the different minimum support (divided into 4 degrees: 15%, 10%, 8%, 6%). When )(XSup  equals to 6%, the FP-growth algorithm spends 42s, and the FPIMF algorithm spends 32s which is 10s less than FP-growth. This is because FPIMF adopts the method that ergodic the FP-tree once and avoid repeated scanning on the same path in the FP-growth, while it structures the conditional pattern base, so it improves the efficiency of the algorithm. However, when the )(XSup increases, FPIFM spends less time than FP-growth, but the effect is not obvious, that is mainly because conditional pattern base become shorter with the )(XSup  increasing.

Analysis on the memory consumption, the memory use rate of FPIMF is lower than FP-growth significantly, because of the strategy that deletes FP-tree.

D.  Conclusion The FPIFM algorithm contraposes the defects of  FP-growth: traveling the same path repeatedly and failing to release  nodes processed in time. It uses a strategy that ergodic the path only once, and the conditional patterns of all nodes are obtained by adding m_sFrearea and m_sFlag node domains. Meanwhile, it adopts the strategy of deleting FP-tree and releases the processed nodes to reduce the memory which the algorithm occupies, so it improves the efficiency of the algorithm. In the end, it is proved that the FPIFM algorithm has  very obvious superiority by algorithm analysis and experimental comparison.

