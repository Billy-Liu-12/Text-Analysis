2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Abstract?Big longitudinal data provide more reliable information for decision making and are common in all kinds of fields. Trajectory pattern recognition is in an urgent need to discover important structures for such data. Developing better and more computationally-efficient visualization tool is crucial to guide this technique. This paper proposes an enhanced projection pursuit (EPP) method to better project and visualize the structures (e.g. clusters) of big high-dimensional (HD) longitudinal data on a lower-dimensional plane. Unlike classic PP methods potentially useful for longitudinal data, EPP is built upon nonlinear mapping algorithms to compute its stress (error) function by balancing the paired weights for between and within structure stress while preserving original structure membership in the high-dimensional space. Specifically, EPP solves an NP hard optimization problem by integrating gradual optimization and non-linear mapping algorithms, and automates the searching of an optimal number of iterations to display a stable structure for varying sample sizes and dimensions. Using publicized UCI and real longitudinal clinical trial datasets as well as simulation, EPP demonstrates its better performance in visualizing big HD longitudinal data.

Index Terms?Enhanced projection pursuit, Pattern recognition, Visualization, Longitudinal data.

?  1 INTRODUCTION  Building up the infrastructure for big data visualization is a challenge but an urgent need [1], [2]. Big longitudinal data are generated every day from all kinds of fields in industry, business, government and research institutes [3]? [15]. Discovering useful information from heterogeneous data requires trajectory pattern recognition techniques [16]? [22]. However, developing visualization tools is crucial to guide this technique, which can facilitate the discovery, pre- sentation and interpretation of important structures buried in complex high-dimensional data. Projection Pursuit (PP) is a classical technique to data visualization, first introduced by Friedman and Tukey in 1974 for exploratory analysis of multivariate data [23]. The basic idea of PP is to design and numerically optimize a projection index function to locate interesting projections from high- to low-dimensional space.

From these interesting projections, revealed structures such as clusters could be analyzed [24]?[27]. PP is based on the assumption that redundancy exists in the data and the major characteristics are concentrated into clusters. For example, principle components analysis is one of the typical PP methods, widely used for dimension reduction by removing uninteresting directions of variations [23], [26], [28]?[39] and now often used as an initialization before high dimensional data mapping and clustering [26], [40]?[45].

In the present study, our newly developed PP method  ? Hua Fang is corresponding author.

? Hua Fang (E-mail: hfang2@umassd.edu)is with Department of Com-  puter and Information Science, Department of Mathematics, University of Massachusetts Dartmouth, 285 Old Westport Rd, Dartmouth, MA, 02747, and Department of Quantitative Health Sciences, University of Massachusetts Medical School, Worcester, MA, 01605. Zhaoyang Zhang (E-mail: zzhang1@umassd.edu) is with College of Engineering, University of Massachusetts Dartmouth and Department of Quantitative Health Sciences, University of Massachusetts Medical School.

is compared to two typical PP methods: Andrews Curves and Grand Tour, as all three methods are potentially useful for big longitudinal data visualization where high dimen- sionality (HD) and repeated measures for each dimension are common. Section II introduces the involvement of An- drews Curves and Grand Tour; Section III discusses the EPP function and algorithms; Section IV includes the comparison of EPP with other methods using real datasets; Section V evaluates EPP with simulated and artificial data; Section VI concludes this study.

2 ANDREWS CURVES AND GRAND TOUR  Proposed in 1972, Andrews Curve has been widely uti- lized in many disciplines such as biology, neurology, sociology and semiconductor manufacturing. The algo- rithm of Andrews Curve was designed to project high dimensional data onto a predefined Fourier series [46], and if any structures exist, they may be visible via An- drews Curves. Briefly, for each case X = {x1, x2, . . . , xd}, which is a vector of measurements, we define a series (  1? , sin(s), cos(s), sin(2s), cos(2s), . . .

)  , then the Andrews  Curve is calculated as  fx(s) = x1? + x2 sin(s) + x3 cos(s) + x4 sin(2s) + . . . , (1)  for ?? < s < ?. Each case may be viewed as a curve between ?? and ?, and structures may be viewed as dif- ferent clusters of curves. Since 1972, several variants of the Andrews Curve have been proposed. Andrews himself also proposed to use different integers to generalize fx(s),  fx(s) =x1 sin(n1s) + x2 cos(n1s)  + x3 sin(n2s) + x4 cos(n2s) + . . . .

(2)    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, IEEE Transactions on Big Data   By testing n1 = 2, n2 = 4, n3 = 8, ..., the author concluded that Equation (2) is more space filling (ie., a curve whose range contains the entire 2-dimensional unit square, or the mapping is continuous) than Equation (1) but more difficult to interpret when used for visual inspection [46]. A three-dimensional Andrews plot was suggested by Khattree and Naik [47], ? 2fx(s) = x1 + x2 [sin(s) + cos(s)] +  x3 [sin(s)? cos(s)] + x4 [sin(2s) + cos(2s)] + . . . .

(3)  As every projection point is exposed to a sine function and a cosine function, the advantage in Equation (3) is that the trigonometric terms do not simultaneously vanish at any given s, which establishes an interesting relation between the Andrews Curve and the eigenvectors of a symmetric positive definite circular covariance matrix.

Different from Andrews Curve, Grand Tour proposed by Asimov [48] and Buja [49] in 1985 is an interactive visual- ization technique. The basic idea is to rotate the projected plane from all angles and search the interesting structures [50]?[56]. However, these methods were not ideal in terms of intensive computation, computer storage, and projection recovery turns out to be difficult. Motivated by Andrews Curve, Wegman and Shen [57] suggested an algorithm for computing an approximate two-dimensional grand tour, called pseudo grand tour which means that the tour does not visit all possible orientations of a projection plane. The method has recognized advantages, such as easy calcula- tion, time efficiency in visiting any regions with different plane orientations, and easy recovery of projection. Briefly, assuming d is an even number without loss of generality [57], let a1(s) be ?  d  (  sin(?1s), cos(?1s), . . . , sin(?d/2s), cos(?d/2s) )  , (4)  and a2(s) be ?  d  (  cos(?1s),? sin(?1s), . . . , cos(?d/2s),? sin(?d/2s) )  ,  (5) where ?i has irrational values. a1(s) and a2(s) have the following properties,  ?a1(s)?22 =  d  d/2 ?  j=1  (  sin2(?js) + cos 2(?js)  )  = 1,  ?a2(s)?22 =  d  d/2 ?  j=1  (  cos2(?js) + (? sin)2(?js) )  = 1,  (6)  and  ?a1(s), a2(s)? =   d  d/2 ?  j=1  (sin(?js) cos(?js)? cos(?js) sin(?js)) = 0, (7)  where ??? is the inner product of two vectors a1(s) and a2(s). Then, the projections of data points on the plane formed by the two basic vectors are  fxi(s) = (  X ?  i1 , X  ?  i2  )  , i = 1, 2, . . . , N, (8)  TABLE 1: Notations  Symbols Definitions  X a vector of measurements Xi,Xj The i-th and j-th cases Xi  ?,Xj ? The projections in a 2D space  s angle, 0 < s < ? ? Linearly independent over the rational a1(s), a2(s) Orthonormal basis for a 2D plane N Number of cases T Sample times d Number of dimensional p Number of components Dij Distance between Xi  ? and Xj ?  D?ij Distance between Xi and Xj S Stress ci Cluster label of case i k The optimal number of clusters  D Average distance ? Total data size ? Weight of the within-cluster stress ? Weight of the between-cluster stress SEPP Total EPP stress fx Low-dimensional projections of data ? Size of the simulated data  in which  X ?  i1 =  d ?  k=1  xka1k,  X ?  i2 =  d ?  k=1  xka2k.

(9)  According to (6), a1(s) and a2(s) form an orthonormal basis for a two dimensional plane. Because of the depen- dence between sin(?) and cos(?), this two-dimensional plane is not quite space filling. However, the algorithm based on (8) is much computationally convenient. By taking the inner product as in (7), a [a1(s), a2(s)] plane is constructed on which the high dimensional data are projected.

Different from Andrews Curve and Pseudo Grand Tour, our new enhanced projection pursuit (EPP) method was built upon Sammon Mapping, assuming not all big longi- tudinal data fit trigonometric functions or transformation.

Sammon mapping has been one of the most successful nonlinear multidimensional scaling methods [58], [59] pro- posed by Sammon in 1969 [60]. It is highly effective and robust to hyper-spherical and hyper-ellipsoidal clusters [60].

The idea is to minimize the error (called ?stress?) between the distances of projected points and the distances of the original data points by moving around projected data points on lower dimensional space (mostly 2-dimenstional place) to best represent those in high-dimensional space. Since its advent, much effort concentrated on improving the optimization algorithm [61]?[65] but rarely on modifying Sammon?s Stress function [64].

Our proposed EPP modified Sammon Stress Function by balancing two weights for between and within cluster errors, respectively, in order to better segment and visualize structures (e.g., clusters) on a projected two-dimensional    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, IEEE Transactions on Big Data   plane while preserving their cluster membership in high- dimensional space. To this end, we developed a nonlinear algorithm to compute EPP stress. Besides, our EPP was developed to automate the searching and finding of the optimal number of iterations to display a stable structure, for varying sample sizes and dimensions. Our goal is to aid the trajectory pattern recognition of longitudinal data.

To evaluate the performance of EPP, one big publicized data set and two real longitudinal random controlled trials (RCT) datasets including a large web-delivered trial data were used to compare EPP with Andrews Curve and Pseudo Grand Tour. Simulated big longitudinal data sets based on RCT data parameters were used to evaluate EPP perfor- mance at varying conditions.

3 ENHANCED PROJECTION PURSUIT (EPP)  In longitudinal data analyses, repeated measures for each dimension result in inevitable high-dimensionality. Built upon Sammon Mapping [60], we proposed an Enhanced Projection Pursuit method (EPP) where the Sammon stress becomes a special case of EPP stress when there is only one cluster and the weights of within and between cluster stresses are equal. EPP is used to aid trajectory pattern recognition for such longitudinal data. The key idea of EPP is to balance the weights of between and within cluster variations in order to achieve better visualization, thus aid pattern recognition for high dimensional (HD) longitudinal data. Table 1 summarizes the notations used hereafter. First, we define our data size and high dimensional space.

Definition 1. let N be the number of cases (e.g., subjects, data points, etc. ), Xi, 1 ? i ? N be a vector of d variables {x1, x2, ..., xd}, each Xi be repeatedly measured with t times, then the data has dt dimensional space and the entire data size is ? = Ndt. e.g, with N cases, Xi is a dt dimensional vector {x11, x12, ..., x1t, x21, x22, ..., x2t, ..., xd1, xd2, ..., xdt}.

Then, the projection of the big longitudinal data from high-dimensional space onto a two-dimensional plane is defined as follows:  Definition 2. To project big HD longitudinal data onto a two dimensional plane and similar to [60], let the distance between any two vectors of Xi and Xj in the dt high dimensional space be defined by D?ij , D  ? ij = ?Xi ?Xj?2 , where ???2 is the Euclidean  norm.

Based on Definition 1 and 2, randomly choose an initial two-dimensional space for the N vectors of X? and compute all the two dimensional distances Dij , 1 ? i, j ? N, i 6= j.

The Sammon Stress [60] is calculated as:  Ssam =  ?  i<j  D?ij  ?  i<j  (  D?ij ?Dij )2  D?ij . (10)  Different from Equation (10), the Stress of EPP stress function SEPP is expressed as the weighted sum of the within-cluster stress SEPP w and between-cluster stress SEPP b,  SEPP = ?SEPP w + ?SEPP b (11)  Algorithm 1(a): Main EPP Algorithm  Input: longitudinal data Xi, i = 1, 2, ..., N , cluster labels ci, 0 ? i ? N , and a range of stress error bound ?, maximum iteration number, lmax, weight change step ?  Output: ?, ?, fx and SEPP 1: Initialize X? by PCA 2: Set initial values for SEPP 0 ? ?, l = 0, m = 0, ?0 and  ?0 (?0, ?0 > 0, ?0 + ?0 = 1) 3: for l = 0 to lmax do 4: fxl = argmin  fx  SEPP (?l, ?l, fx)  5: SEPP l = SEPP (?l+1, ?l+1, fxl) 6: while ?l, ?l > 0, ?l + ?l = 1 do 7: if SEPP (?l+?, ?l??, fxl) < SEPP (?l, ?l, fxl) then 8: ?l+1 = ?l+1 + ?, ?l+1 = ?l+1 ? ? 9: else  10: if SEPP (?l ? ?, ?l + ?, fxl) < SEPP (?l, ?l, fxl) then  11: ?l+1 = ?l+1 ? ?, ?l+1 = ?l+1 + ? 12: else 13: break 14: end if 15: end if 16: end while 17: if  ?  ?SEPP l ? SEPPl?1 ?  ? ? ? then 18: break 19: end if 20: end for  in which ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  SEPP w =  ?  i<j  D?ij  ?  i<j,ci=cj  (  D?ij ?Dwij )2  D?ij  SEPP b =  ?  i<j  D?ij  ?  i<j,ci 6=cj  (  D?ij ?Dbij )2  D?ij  (12)  where 1? i<j  D?ij is a constant for a given big HD longitudinal  data, ?  i<j,ci=cj  (  D?ij?Dwij )2  D?ij and  ?  i<j,ci 6=cj  (D?ij?Dbij )  D?ij are the  within-cluster and between-cluster stress, respectively, Dwij is the within cluster Euclidean distance between case i and j if they are in the same cluster, and Dbij is the between cluster Euclidean distance between case i and j if they belong to different clusters; ? and ? are the weights of the within-cluster stress and between-cluster stress, respec- tively, a, ? > 0 and ?+ ? = 1. Note again that the Sammon stress is a special case of EPP stress when there is only one cluster, ci = 1, i = 1, 2, ..., N and the weights of within cluster and between cluster stresses are equal, ? = ?.

EPP algorithm aims to obtain an interesting two- dimensional projection of the original high dimensional data that minimizes its stress function. The optimization problem is expressed as  minimize ?SEPP w + ?SEPP b subject to ?, ? > 0, ?+ ? = 1.

(13)  Definition 3. To minimize SEPP (?, ?, fx) where fx stands    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, IEEE Transactions on Big Data   for the projections of Dwij and Dbij , the gradual approximation algorithm works as: Given a fixed pair of ? and ?, update the values of fx where SEPP has the minimum value, that is, keep updating ? and ? until there are no changes according to (12).

?  ?  ?  ?  ?  ? = ?+ ?, ? = ? ? ?, if SEPP (?+ ?, ? ? ?, fx) < SEPP ? = ?? ?, ? = ? + ?, if SEPP (?? ?, ? + ?, fx) < SEPP ? = ?, ? = ?, otherwise  (14)  The main EPP algorithm is shown in Algorithm 1(a). The embedded gradual approximation algorithm is displayed in Algorithm 1(b) to minimize SEPP given ? and ?; the values of fx were retained when SEPP has the minimum value.

Specifically, the EPP algorithm initialize X? based on the results from PCA; update fx according to Algorithm 1(b) based on Equation (15), calculate the EPP stress and update ? and ?, with a weight change step ? based on Equation (14). If the difference between two consecutive stress values is less than the threshold ?, the algorithm stops. Repeat this process until reaching the maximum iteration number, lmax.

fxl = argmin fx  SEPP (?l, ?l, fx). (15)  Algorithm 1(b): Algorithm for Updating fx  Input: Projections X?, ? and ?, error bound ?, maximum iteration number mmax, SEPP  (0) ? ? Output: SEPP  (m+1) and fx (m+1)  1: for m = 0 to mmax do 2: fx  (m+1) = fx (m) ? ? ??(m)  3: SEPP (m+1) = SEPP (?, ?, fx  (m+1))  4: if ?  ?  ? SEPP  (m+1) ? SEPP (m) ?  ?  ? ? ? then  5: break 6: end if 7: end for  Note that in Algorithm 1(b) when updating fx, fx (m) are  the projections of the data on the two-dimensional space at the m-th iteration, ? is the iteration step size which is set at  0.3 or 0.4 according to [60], ?(m) = ?SEPP (m)  ?fx(m)  /?  ?  ?  ?  ?2SEPP (m)  ?(fx(m))  ?  ?  ?  ?  and w = ?2? i<j  D?ij is a constant. Then the first-order derivative  with respect to fx is shown in Equation (16) and the second- order derivative is expressed in Equation (17).

Unlike nonlinear mapping algorithm [60], the EPP algo- rithm further automates the searching and finds the optimal number of iterations to display a stable structure by learning the change of SEPP in two consecutive iterations at a range of varying error bounds, sample size and the number of dimensions.

4 EPP PERFORMANCE IN CASE STUDIES  Our EPP method was tested on 3 real datasets, including one publicized [66] and two random controlled trial (RCT) datasets [43], [67]?[69]. These data features are summarized in Table 2.

TABLE 2: Real Data Description  Name Waveform TDTA QuitPrimo  Cases(N ) 5000 109 1320 Components(p) 21 5 3 Time points(t) 1 4 6 Total data size(?) 105,000 2,180 23,760 Clusters(c) 3 3 4  The Waveform data were generated by a clustering data generator described in [70] and published by [66], [70]. It consists of 5000 cases, each with 21 attributes (? = 105, 000).

There are 3 clusters of waves identified for testing algo- rithms. Figure 1 shows the performance of the three PP methods for waveform datasets. Clearly, Andrews Curve and grand tour were unable to visualize the three classes while the EPP demonstrated its projection power in visual- izing the 3-cluster structure.

TABLE 3: Mean values of TDTA Data  t1 t2 t3 t4  Benefits  C1 133 128 127 127 C2 138 127 133 134 C3 113 112 115 112  Family Norm  C1 116 116 113 111 C2 116 115 114 115 C3 101 102 100 99  TABLE 4: Standard Deviation of TDTA Data  t1 t2 t3 t4  Benefits  C1 13.89 21.15 17.35 22.60 C2 14.88 25.80 16.21 14.54 C3 26.38 16.11 16.59 19.95  Family Norm  C1 9.94 7.19 9.88 12.20 C2 7.22 7.98 9.14 9.63 C3 12.96 10.81 12.17 9.47  TDTA data were collected from a longitudinal culturally- tailored smoking cessation intervention for 109 Asian Amer- ican smokers (? = 2, 180). It contains three identified culturally-adaptive response patterns [43]. This interven- tion used three components: Cognitive behavioral therapy, cultural tailoring, and nicotine replacement therapy. The first two were measured by scores on Perceived Risks and Benefits, Family and Peer Norms, and Self-efficacy scales.

Each scale has four repeated measures, total 20 attributes, of which only Perceived Benefits and Family Norms were used using our multiple imputation based fuzzy clustering method discussed elsewhere [71]?[73]. As shown in Figure 2, two of the three clusters projected by Andrews Curve was completely overlapped, while Grand Tour seems to perform as good as EPP for this longitudinal dataset. The parameters of TDTA data are shown in Table 3 and Table 4.

QuitPrimo dataset includes 1320 cases (? = 23, 760) with missing values about 8.4%. This study aims to evaluate an    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, IEEE Transactions on Big Data   ?SEPP (m)  ?fx (m)  =  ?  ?  ?  ?  ?  ?  ?  ?  ?  w N ?  j=1,j 6=p  [  D?j ?Dwj D?  j Dwj  ] (  fx (m) ?Xj ?(m)  )  if cp = cj ,  w N ?  j=1,j 6=p  [  D?j ?Dbj D?j Dbj  ] (  fx (m) ?Xj ?(m)  )  if cp 6= cj .

(16)  ?2SEPP (m)  ? (  fx (m)  )2 =  ?  ?  ?  ?  ?  ?  ?  ?  ?  w N ?  j=1,j 6=p  D?  j Dwj  [  (  D?j ?Dwj )  ? (fx (m)?Xj ?(m))   Dwj  (  1 + D?j ?Dwj  Dwj  )  ]  if cp = cj ,  w N ?  j=1,j 6=p  D?jDbj  [  (  D?j ?Dbj )  ? (fx (m)?Xj ?(m))   Dbj  (  1 + D?j?Dbj  Dbj  )  ]  if cp 6= cj .

(17)  (a) Andrews Curve  4 6 8 10           (b) Grand tour  ?1.5 ?1 ?0.5 0 0.5 1 1.5  ?1  ?0.5   0.5       (c) EPP  Fig. 1: Projection Pursuit of Waveform data using Andrews Curve, grand tour and proposed EPP  0 0.2 0.4 0.6 0.8 1 ?50          (a) Andrews Curve  20 25 30 35 40           (b) Grand tour  ?1 ?0.5 0 0.5 1 ?1.5  ?1  ?0.5   0.5       (c) EPP  Fig. 2: Projection Pursuit of TDTA data using Andrews Curve, grand tour and proposed EPP  integrated informatics solution to increase access to web- delivered smoking cessation support. The data is collected via an online referral portal about three components: 1) My Mail, 2) Online Community, 3) Our Advice. Each of the first three component has 6 monthly values measured during 6 months. Figure 3 again showcases the strength of EPP over the other two methods for this big longitudinal dataset. Projected four patterns were overlapped using An- drews Curve while and the blue and green patterns were overlapped to a noticeable degree using the Grand Tour.

Table 5 and 6 show the mean values and standard deviations of QuitPrimo dataset, respectively.

The optimal pairs, ? and ?, for included real longi- tudinal datasets TDTA and QuitPrimo given fx can be detected by the following steps. Initialize a pair of values, e.g., (0.5,0.5), and calculate the stress of the proposed EPP method by Equation (10) and (11). Increase ? and decrease ?, or vice versa, by a boundary parameter ?, e.g., ? = 0.1, to obtain a new stress value. Updating ? and ? until the  TABLE 5: Mean values of QuitPrimo Data  t1 t2 t3 t4 t5 t6  MM  C1 0.747 0.154 0.017 0.025 0.006 0.000 C2 1.091 0.465 0.139 0.080 0.139 0.043 C3 0.047 0.000 0.000 0.000 0.000 0.000 C4 0.659 0.157 0.003 0.000 0.000 0.000  OA  C1 5.708 8.601 8.736 6.902 3.997 3.638 C2 5.708 8.601 8.736 6.902 3.997 3.638 C3 0.888 0.100 0.000 0.000 0.000 0.000 C4 6.345 8.686 5.857 1.213 0.007 0.000  OC  C1 0.284 0.020 0.006 0.006 0.003 0.006 C2 0.455 0.080 0.011 0.021 0.021 0.000 C3 0.006 0.000 0.000 0.000 0.000 0.000 C4 0.275 0.031 0.014 0.000 0.000 0.000  stress values no longer decease, we can obtain the optimal    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, IEEE Transactions on Big Data   (a) Andrews Curve  0 5 10 15 ?2             (b) Grand tour  -1.5 -1 -0.5 0 0.5  -0.8  -0.6  -0.4  -0.2   0.2  0.4  0.6  0.8   1.2  (c) EPP  Fig. 3: Projection Pursuit of QuitPrimo data using Andrews Curve, grand tour and proposed EPP  0 0.2 0.4 0.6 0.8 1 0.01  0.02  0.03  0.04  0.05  ?  S tr  es s     EPP Sammon  (a) TDTA dataset  0 0.2 0.4 0.6 0.8 1  0.02  0.04  0.06  0.08  0.1  ?  S tr  es s     EPP Sammon  (b) QuitPrimo dataset  Fig. 4: Finding an optimal pair of weights that balance the between and within stresses for TDTA and QuitPrimo using EPP (blue line is reference line from Sammon?s Stress)  TABLE 6: Standard Deviation of QuitPrimo Data  t1 t2 t3 t4 t5 t6  MM  C1 1.718 1.124 0.237 0.339 0.106 0.000 C2 1.595 2.437 0.979 0.732 1.079 0.462 C3 0.384 0.000 0.000 0.000 0.000 0.000 C4 1.972 1.246 0.059 0.000 0.000 0.000  OA  C1 1.972 1.246 0.059 0.000 0.000 0.000 C2 2.431 0.875 0.893 1.394 1.172 1.484 C3 2.249 0.457 0.000 0.000 0.000 0.000 C4 2.490 1.067 3.384 1.797 0.083 0.000  OC  C1 2.490 1.067 3.384 1.797 0.083 0.000 C2 0.996 0.463 0.103 0.178 0.206 0.000 C3 0.078 0.000 0.000 0.000 0.000 0.000 C4 0.783 0.194 0.186 0.000 0.000 0.000  weights ? and ? for the within and between cluster stresses.

As shown in Figure 4(a) and Figure 4(b), the optimal weights of (0.8, 0.2) were founded for TDTA and QuitPrimo data, respectively.

5 EPP PERFORMANCE USING SIMULATED LON- GITUDINAL DATA  The proposed EPP was also evaluated using simulated data.

First, simulated longitudinal data were generated using pa-  TABLE 7: Cluster Information for TDTA and QuitPrimo  cluster 1 2 3 4  TDTA # of cases 50 31 16 - proportions 0.52 0.32 0.16 -  QuitPrimo # of cases 356 187 490 287 proportions 0.27 0.14 0.37 0.22  rameters from the two real datasets, TDTA and QuitPrimo.

The data generation procedure is described as follows:  1) Fit the multivariate normal distribution to TDTA and the zero-inflated Poisson mixture distribution to the QuitPrimo web trial data [71], respectively, and learn the parameters such as cluster mean vectors and standard deviations, the results are shown in Table 3, 4, 5 and 6;  2) Set the number of cases of each cluster according to the proportion of each cluster (Table 7);  3) Generate data for each cluster based on the model parameters from (1) and cluster size (2).

4) Randomize data from (3) to generate a complete dataset;  5) Repeat (1-4) and generate datasets with varying sample sizes, N is in {100, 200, 300, 500, 1000, 5000}, dTDTA = 20, dQuitPrimo = 18, and ?TDTA =    2332-7790 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, IEEE Transactions on Big Data   {2000, 4000, 6000, 10000, 20000, 100000}, ?QuitPrimo = {1800, 3600, 4800, 9000, 18000, 36000}.

Figure 5 displays the EPP projection based on the TDTA parameters using different sample sizes. From N = 100 to N = 5000, the clusters are clearly projected. With smaller sample sizes, the data points are more spread within the cluster. The red and green clusters are closer to each other compared to the blue cluster.

Based on the QuitPrimo parameters, EPP again clearly projected the four clusters across a range of data size ?. The blue cluster is always far apart from the red cluster; the other three clusters always touch each other as shown in Figure 6.

Using the same simulated data sets, the optimal number of iterations were tested for the proposed EPP method using a different number of sample sizes or dimensions. In Figure 7 (a), the number of dimensions was fixed at 20, and the data sizes ? were varied from 2,000 to 100,000. In Figure 7 (b), the data sizes ? was fixed at 100,000, and the number of dimensions d were varied from 2 to 100. For all conditions, the change between iterations (?) was varied from 10?3 to 10?6.

The findings indicate that across different sample sizes or dimensions or the change of stresses between iterations (?), the optimal number of iteration seem to be always below 350.

Furthermore, using the same data generation procedure, an artificial longitudinal dataset was generated with stan- dardized mean and variance-covariance matrices to evalu- ate the EPP performance. The mean vector was set as 0.2, 0.5, and 0.8 for three clusters [74], [75], the correlation matrix (standardized variance-covariance matrix) was set with 1 at the diagonal and other matrix elements were randomly selected from {0.1, 0.3, 0.5} [74], [75]. The data size was varied from 1,000 to 500,000 and dimensions were changed from 10 to 100. The different colored planes stand for the four settings for the change of stresses between iterations (?), 10?3, 10?4, 10?5, and 10?6. As shown in Figure 8, the optimal number of iterations seem to be always below 500 across different sample sizes, dimensions and error bounds (?) for the change between iterations. Using 500 iterations could be an empirical rule for setting the iterations for EPP.

Overall, in terms of computational time, EPP cost 11 and 22 seconds for projecting real TDTA and QuitPrimo data while up to 9 minutes assuming the worst scenario of N = 20,000 and dt = 100.

6 CONCLUSION Pattern visualization is a challenging field. A robust projec- tion pursuit method could enormously ease pattern recog- nition. Our enhanced projection pursuit (EPP), a variant of classic Sammon Mapping, balances the weights of be- tween and within cluster variations and better project big high dimensional longitudinal data onto two-dimensional plane using nonlinear mapping algorithms. Compared to classical Andrews Curve and Grand Tour, our EPP method seems to perform consistently well and was more robust to such data. Different from the two methods, EPP was not built upon trigonometric functions as not all longi- tudinal datasets follow this assumption, especially those longitudinal random controlled trial (RCT) or observational  data [40]?[45], [67], [74], [76]. Using the publicized UCI dataset, real longitudinal RCT datasets and a number of simulated big longitudinal data, EPP showcases its clear and better projection power with respect to high-dimensionality, sample sizes and error bounds for the change between iterations with satisfactory computational costs. Embedding EPP into different trajectory pattern recognition systems and further reducing computational time for bigger data would be future tasks. Testing EPP on more big longitudinal data could further warrant its robustness.

