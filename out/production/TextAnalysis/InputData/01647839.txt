LAPIN-SPAM: An Improved Algorithm for Mining Sequential Pattern

Abstract  Sequence pattern mining is an important research prob- lem because it is the basis of many other applications. Yet how to efficiently implement the mining is difficult due to the inherent characteristic of the problem - the large size of the data set. In this paper, by combining SPAM, we pro- pose a new algorithm called LAst Position INduction Se- quential PAttern Mining (abbreviated as LAPIN-SPAM), which can efficiently get all the frequent sequential pat- terns from a large database. The main difference between our strategy and the previous works is that when judging whether a sequence is a pattern or not, they use S-Matrix by scanning projected database (PrefixSpan) or count the number by joining (SPADE) or ANDing with the candidate item (SPAM). In contrast, LAPIN-SPAM can easily imple- ment this process based on the following fact - if an item?s last position is smaller than the current prefix position, the item can not appear behind the current prefix in the same customer sequence. LAPIN-SPAM could largely reduce the search space during mining process and is considerable ef- fectiveness in mining sequential pattern. Our experimental results show that LAPIN-SPAM outperforms SPAM up to three times on all kinds of dataset.

1. Introduction  Sequential pattern mining is an important research theme because it is the basis of many applications. Consider the sales database of a store. If we know that ?80% of the persons who buy television also buy video camera within a week?, we can efficiently use the shelf space to conve- nient the customers. Another business example is that if we know that ?every time Microsoft stock drops 5%, IBM stock will also drops at least 4% within three days?, we can properly decide what to do when economic problem hap- pens. Sequential pattern mining is also used in biological  data, telecommunication network analysis, web access click stream, and so on.

CID Customer Sequence 10 ac(bd)c(ab) 20 b(cd)acd 30 a(bc)(acd)c  Table 1. Sequence Database  Example. Let our running database be sequence database S given in Table 1 and min support=2. We will use this sam- ple database throughout of this paper. We can see that the set of items in the database is {a,b,c,d}. A 2-sequence ?ac? is contained in the customer sequence 10, 20 and 30, respec- tively. So the support of ?ac? is 3, which is larger than the user specified minimum support, from where we can know that ?ac? is a frequent pattern.

1.1. Related Works  Sequential pattern mining algorithms could be grouped into two categories. One is candidate-generate-test such as GSP [1], SPADE [3] and SPAM [2], the other is pattern growth such as PrefixSpan [4].

As proposed in [5] , all of these algorithms use some common strategies such as candidate sequence pruning, database partitioning and customer sequence reducing.

The main difference between our algorithm and all algo- rithms proposed before is that when judging a sequence is a pattern or not, they use comparison, ANDing or S-Matrix, which need to implement in every recursive step. But for the LAPIN-SPAM, we can directly accumulate the candidate?s support by using ITEM IS EXIST TABLE, which is con- structed while scanning the database for the first time. Be- cause the unavoidable large iteration when mining, our pro-     posed algorithm can effectively reduce the cost used to test the candidates.

The rest of this paper is organized as follows: In Sec- tion 2 we introduce the detail of LAPIN-SPAM algorithm.

In Section 3 the experiment of comparing LAPIN-SPAM and SPAM is presented. Finally we make a conclusion and present future works in Section 4.

2. LAPIN-SPAM (LAst Position INduc- tion Sequential PAttern Mining)  Because our algorithm is built based on SPAM [2], first we will introduce SPAM.

2.1. SPAM  Ayres et al. [2] proposed SPAM algorithm, which uti- lizes a bitmap representation of the database. While scan- ning the database for the first time, a vertical bitmap is con- structed for each item in the database, and each bitmap has a bit corresponding to each element of the sequences in the database. If an item appears in an element, the bit corre- sponding to the element of the bitmap for the item is set to one; otherwise, the bit is set to zero. The size of a se- quence is the number of elements contained in the sequence.

A sequence in the database of size between 2k + 1 and 2k+1 is considered as a 2k+1-bit sequence. The bitmap of a sequence will be constructed according to the bitmaps of items contained in it.

To generate and test the candidate sequences, SPAM uses two steps: S-step and I-step, based on the lattice concept. As a depth-first approach, the overall process starts from S-step and then I-step. To extend a sequence, the S-step appends an item to it as the new last element, and the I-step appends the item to its last element if possible. Each bitmap parti- tion of a sequence to be extended is transformed first in the S-step, such that all bits after the first bit with value one are set to one. Then the resultant bitmap of the S-step can be obtained by doing ANDing operation for the transformed bitmap and the bitmap of the appended item. On the other hand, the I-step just uses the bitmaps of the sequence and the appended item to do ANDing operation to get the resul- tant bitmap. The support counting becomes a simple check how many bitmap partitions not containing all zeros. Yet for the inherent characteristic existed in the sequential pattern mining problem, these ANDing operations cost a lot dur- ing the whole mining process, which should be reduce for efficiency improving.

According to the two processes existed in SPAM, it uses two pruning techniques: S-step pruning and I-step pruning, based on the Apriori heuristic to minimize the size of the candidate items.

2.2. LAPIN-SPAM  Although the authors of SPAM claim that they efficiently count the support of the candidate, we have found more ef- ficiency improving space in this support counting process.

In SPAM, to judge a candidate is a pattern or not, it does as many ANDing operation as to the number of customers involved. For example, if there are 10000 customers in cer- tain dataset, it will cost 10000 ANDing operation time for each candidate item testing. Consider the recursive charac- teristic in the implementation, this cost is too big. So how to avoid this ANDing operation becomes essential step.

As mentioned earlier, if given a current position in cer- tain customer, we can know which items are behind cur- rent position and which are not based on the last position of them. So a naive method to judge a candidate is to compare the last position of it with the current position. This is in fact the same cost as ANDing operation in SPAM. To avoid this comparison or ANDing operation, we can construct a ITEM IS EXIST TABLE when scanning the database for the first time. In each iteration, we only need to check this table to get information that a candidate is behind current position or not. By this way, we can save much time by avoiding ANDing operation or comparison.

Figure 1. ITEM IS EXIST TABLE  Figure 1, which is built based on the example database in Table 1, shows one part of the ITEM IS EXIST TABLE for the first customer. The left column is the position num- ber and the top row is the item ID. In the table, we use bit vector to represent candidates existence for respective posi- tion. Bit value is 1 indicates the item existing, otherwise the item does not exist. The bit vector size is equal to the to- tal number of the candidate items. For example, if the cur- rent position is 2, we can get its corresponding bit vector as 1111, which means that all candidates can be appear behind current prefix. When the current position is 4, we can get the bit vector as 1100, indicates that only item a and b exist in the same customer sequence after the current prefix. To ac- cumulate the candidate sequence?s support, we only need     to check this table and add the corresponding item?s vec- tor value, avoiding comparison, ANDing operation or con- structing S-Matrix in each recursive step, which largely im- prove efficiency during mining. Attention that here we only discuss the S-Step process, the reader can easily extend it to the I-Step process based on the same strategy.

2.2.1. Space Optimization SPAM assumes that the whole vector representation of the database should be filled in the main memory, yet the space necessary is always a key fac- tor of an algorithm. As Figure 1 shows, we can easily know that the main memory used in LAPIN-SPAM is no more than twice of that used in SPAM, because each item needs one bit for every transaction no matter it exists or not in the ITEM IS EXIST TABLE.

Figure 2. Optimized ITEM IS EXIST TABLE  After consideration, we find that only part of the table is useful and most are not. For example in Figure 1, when the current position is smaller than 3, all items exist and when the position is larger than 4, there is no item existing. So the useful information is store in some key positions? lines.

We define key position as follows: Given a position, if its corresponding bit vector is different from that of the posi- tion one smaller than it (except the one whose bit vector is equal to 0), this position is called key position. For ex- ample, in Figure 1, the position 3 and 4 are key positions and others are not (position 5 is not because its bit vector is equal to 0). We can find that these key positions are indeed the last positions of the candidates items (except the last one). The optimized ITEM IS EXIST TABLE is shown in Figure 2, which stores only two bit vectors instead of eight ones shown in Figure 1. For long pattern dataset, this space saving strategy is more efficient. Through thorough experi- ments what we will mention in Section 3, the memory used to store the ITEM IS EXIST TABLE is less than 10 per- cent of the one used in SPAM, which can be neglected when comparing LAPIN-SPAM and SPAM efficiency.

3. Experiment  We perform the experiments on a 1.6GHz Intel Pen- tium(R)M PC machine with 1G memory, running Microsoft Windows XP. The synthetic datasets are generated by the IBM data generator described in [1]. The meaning of the  different parameters used to generate the datasets is shown in Table 2. As [2] shown, SPAM is by far the fastest al- gorithm when mining to get the whole set of the sequen- tial patterns, nearly an order faster than PrefixSpan [4] and SPADE [3] for large datasets. So we only compare SPAM and LASIN SPAM in this paper. All methods are imple- mented using Microsoft Visual C++ 6.0.

Symb. Meaning D Number of customers in 000s C Average number of transactions per customer T Average number of items per transaction N Number of different items in 000s S Average length of maximal sequences  Table 2. Parameters used in datasets genera- tion  Because the dataset size plays a key role on the performance of the algorithm, we first compare SPAM and LAPIN- SPAM for different size of datasets, as Figure 3 shown. This set of tests presents that LASIN SPAM outperforms SPAM by about 2 to 3 times for different size of the datasets.

In the second group of the experiments, we consider the different parameters used to generate the datasets on the ef- fect of the performance. Figure 4(a) shows the result when changing the number of the customers. Figure 4(b) presents the effect when varying average number of transactions per customer. Figure 4(c) shows the result when changing the average number of items per transaction parameter. Figure 4(d) modifies the average length of maximal sequences and the variable in Figure 4(e) is the number of different items in the datasets. We can see that no matter which parameter changes, LAPIN-SPAM is always faster than SPAM about 2 to 3 times. The primary reason that LAPIN-SPAM per- forms so well for all datasets is due to avoiding ANDing operation or comparison of the bitmap for efficient count- ing. This process is critical because it is performed many times at each recursive step, and LAPIN-SPAM can save much time compared with SPAM.

4. Conclusion and Future Works  In this paper, we have proposed a new strategy, named LAPIN-SPAM, to mine sequential patterns. The key idea is that if given the current position, we can immediately know which items should be appear behind current prefix items, based on the items? last positions. LAPIN-SPAM avoids ANDing operation or comparison in each iteration in the support counting process, which can largely improve the ef- ficiency. In fact, for any time-series database, the last posi-     Figure 3. Varying support for different size of the datasets  Figure 4. Varying parameters of the datasets  tions of different items should be paid more attention be- cause they can be treated as the judgement for the items? existence at each recursive step. We also present a set of thorough experiments when comparing LAPIN-SPAM and SPAM on different kind of the datasets. The result shows that our algorithm outperforms the current fastest one by about 2 to 3 times.

In the future, we want to apply our strategy on other more applications, such as dynamic database(data stream, etc).

