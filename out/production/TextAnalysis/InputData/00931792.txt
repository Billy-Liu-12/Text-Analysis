PERSONALIZED RECOMMENDATION BASED ON ITEM DEPENDENCY MAP

ABSTRACT  In data mining we want to find hidden knowledge, unexpected pattem and new rule from massive data. In this paper, we intend to find user?s item purchasing pattem and recommend goods that he/she wants. So we suggest item dependency map which express relation between purchased items. Using an algorithm that we suggest, we can recommend an item, which a user has not bought yet but maybe is likely to interested in. And item dependency map is used as pattems for association in hopfield network so we can extract users? global purchasing item pattem only using users? partial information. Hopfield network is an iterative auto-associative network consisting of a single layer of fully connected processing elements which can function as an associative memory. And hopfield network can extract global information from sub-information.

Therefore this algorithm obtains an advantage of hopfield networks. Our algorithm can be applied to real web site and help web master to know users? taste.

1. INTRODUCTION  Data mining is motivated by the decision supporter problem faced by most large companies. Many companies collect and store massive amounts of sales data and they want to find hidden knowledge, which is unexpected pattems and new rules from those data. Through data mining, they can extract lots of knowledge. Association rule, generalization, clustering, similarity search, sequential pattem, neural network, decision tree and etc.

Then they apply these rules to real business?s decision problem. Especially we concem about goods recommendation in which a user is likely to interested.

We introduce a way to extract important information from data and recommend goods to user using item dependency map that we suggest and hopfield network.

Item dependency map is matrix that expresses relations between items. In other words, each element value of matrix is approximate probability of which after a user purchases A, helshe purchases B.

0-7803-7090-2~0l/$10.00 @ 2001 IEEE. 250  2. PRELIMINARIES  In this chapter, we explain the hopfield network that is applied to our algorithm. And we explain sequential pattem mining that analyze data in order of time as related work.

2.1. Hopfield Network  Hopfield network is one of neural networks, which is iterative auto-associative networks consisting of a single layer of fully connected processing elements that can Sunction as an associative memory.

Hopfield networks are quite interesting from the information processing system point of view. They do support the parallel-distributed information storage aspect common to all neural network models, but information processing is not really performed in a parallel fashion.

The processing elements perform computations in an asynchronous fashion. This allows the network to avoid the difficulties encountered in propagating synchronization signals throughout the large network. Another advantage is that this relieves the need of requiring that each processing dement have global knowledge of the entire network at all times.

For the discrete hopfield network processing, elements may take on either binary (110) or bipolar(l/-1) values. A pattem constituting N discrete binary value can be presented to the network, resulting in a state vector for the system. The network is fully connected in the sense that each processing element is connected to every other processing element. The weights are symmetric and there is no connection between a neuron and itself.

We intend to use the fact that Hopfield network has features that it can extract global information from sub- information. We can infer the user?s global item purchase pattem by using user?s partial item purchase pattem as hopfield network?s input. So with the result value, we can recommend item that users are satisfied with.

2.2. Sequential Pattern Mining  Since bar-code appeared, retail organizations can collect and store massive sales data, referred to as the basket data.

ISIE 2001, Pusan, KOREA    These data generally consists of transaction date and purchased items. Retail organizations stores data through bar-code in order of date. When many companies solve the problem, they analysis these data and use the results for resolving the problem.

Sequential pattern mining is introduced first by Agrawal[2]. This method is different from association rule, because sequential pattern mining analyze data on order of time. Each continuous data consists of transactions that have items (customer-id, time. etc) and each transaction is sorted by transaction time. After all, user sequential pattern mining is to find user?s continuous pattern that satisfies minimum support. Here we define minimum support as percentage of continuous data that include pattern.

Sequential pattem mining starts in a filed of retail industry, marketing, additional sale, customer satisfaction and etc. But now it is applied to field of science and management.

Customer ID  3. ITEM DEPENDENCY MAP  Customer Sequence  (1 14, 112, 116) (111, 112)  3.1. Problem Statement  As we mentioned, item dependency map is matrix that expresses relation between items. In this chapter, we explain the method to decide item dependency map. We use user?s transaction data.

We are given a database D of customer item purchase transaction. Each transaction consists of following .fields: customer id, customer group id, transaction time and the purchased items in the transaction. Customer group id is identification of group of which people have ?same concern or job with each other.?For example; if we identify group id by age, group can be lo?s, ~ O ? S ,  ~O?S, and etc. We do not consider quantities of items purchased in a transaction.

An itemset is a non-empty set of items. A sequence is an ordered list. We denote an itemset I by (i l ,  i 2  ... im), where ij is an item.

An itemset is ordered by increasing transaction-time, corresponds to a sequence. This is the item sequence.

Given a database D of customer transactions, we extract item dependency maps to use hopfield network.

3.2. Preprocessing  We explain the preprocessing by showing the example.

Consider the database shown in Table. 1.

We have to make item dependency maps by each group.

Table.2 and Table.3 are item sequence divided by group id.

So later item sequence of each group is used to make item dependency map of each group  Table 1 Database Sorted by Customer Group ID, Customer ID and Transaction Time  Table 1 Item Sequence of Group 1  Table 2 Item Sequence of Group 2  3.3. Processing  3.3.1 Pre item dependency map First we make pre item dependency map using item sequence of each group.

Let the number of items m. After all preprocessing, we will get a m*m matrix. We assign each item the number from 1 t o m .

if kth pre item dependency map is above, we suggest two way to calculate a value of element (i, j).

,  Method 1-1 Each itemset is traversed and a value of element (i, j) is calculated.

An algorithm is like this.

for(i=O; i<# of itemset in each sequence item; i++){ item = 1; while(unti1 all items are traversed in each itemset){ tempgtl  = transaction[i][item];  25 1 ISIE 2001, Pusan, KOREA    //the item of ith itemset tempgt2 = transaction[i][item+l]; .

pre-Pattem[group-id][temp-ptl][tempgt2]  = pre_Pattem[group_id][tempgtl][temp_pt2] + 1 ; 1 -  item ++;  First method is concemed about items purchased continuously by only one step. If a user purchase item j after purchasing item i, we add 1 to the value of element ( i j ) .  And then we divide the summation by total number of purchased item i in item sequence.

Ex) Let suppose each itemsets of item sequence of group A be like this, (111, 113, 115, 112), (111, 115, 112) and we number each items. Item 1 1 1?s number is 1, item 1 12?s number is 2 and so on.

Then  (1,3) = 1/2, (3,5) = 1/1, (5,2) = 2/2, (1, 5) = 1/2.

In case of element (1,3), a user purchased item 3 after purchasing item 1 and item 1 is purchased totally 2 times.

So the value of element (1,3) is 112.

Method 1-2 Second method is concemed about interval time between two item purchased. Previous method can express only relation between purchased item and rightly next purchased item. But in case of purchased many items for short time, several items have relation each other. So we give weight after counting how many times item is separated other item. If a user purchased item j after hetshe purchased a, b and i, weight is low 1 *a*a (O<as 1).

The way to calculate value of element (i, j) is partly same with 1st method. If a user purchase item j after purchasing item i, we add 1 to value. But this algorithm needs additional calculation. We have to add away items? relation value, namely weighted value a.

for(i=O; i<# of itemset in each sequence item; i++){ item = 1 ; while(unti1 all items are traversed in each itemset){ tempgt l  = itemset[i][item]; tempgt2 = itemset[i] [item+ 1 ] ; pre-Pattem[group-id] [ tempgt l  ] Ltempgt21  = pre-Pattem[group-id][tempqtl][temp-pt2] + 1 ; forCj=item-2; j>O; j--){ value = value * a; tempgt l  = itemset[i]b]; tempgt2 = itemset[i] [item] ;  pre-Pattem[group-id] [tempgt 13 [tempgt2] = pre-Pattem[group-id][tempgtl] [tempgt2] + value;   item ++; 1 .

See the way to calculate using example.

Let suppose item purchase itemset be same with, previous example. Then if we apply this method, we have to calculate (3,2) and (1,2) that is not calculated in first method and the value of element ( 1 3  changes.

Here in case of element (1,2), a user purchased item 2 after purchasing item 1,3 and 5 in 1?? itemset and item 5 in Yd itemset.

(1,2) = ( a  * a + a)/2, (3,2) = d l ,  (13)  = (1 + a)/2  1st item is purchase by both itemset, so a denominator?s value are 2.

(3,2) = d l  3th item is purchased only one bme in itemset, so  In this method, an element?s value reflects relation denominator?s value is 1.

between two items considered.

3.3. 2. Item dependency map ,4fter we make pre item dependency map of each group, we need post processing to decide item dependency map?s value, namely bipolar(-l/l) value because item dependency map of each group is the pattem in hopfield network. The value of each element is -1 or 1.

We decide. the value of item dependency map through testing weather the value of pre item dependency map is over a criterion which we determine.

Here we suggest two method.

Method 2-1 First of all, we define the terminology we use.

Pk(i, J )  is the value of element (i, j) of item dependency  map in kth group.

]<(t) = the #of purchaseditemj after purchaseditemi by totaluser the#of purchaseditemi by totaluser  If the value of Pk(i, j) is over than E(t) , 1 otherwise - l(or 0).

Method 2-2 Second method uses ranking. To begin with, we rank Pk(i, j )  about total group. And then we determine marginal high ranking R as the group?s number. So if ranking of Pk(i, j) is over R, 1 otherwise -l(or 0).

252 ISIE 2001, Pusan, KOREA    In case of first method, if the number o f  group is small, the [3] Mehmet M. Dalkilic, Edward L. Roberston, average of group is dangerous because too heavy or small ?Information dependencies,? Proceedings of the value makes average not to represent standard value. nineteenth ACM SIGMOD-SIGACT-SIGART symposium Now we have k pattems through above processing. These on Principles of database systems, pp. 245 - 253,2000.

pattems are used for association memory in hopfield network. An association memory made using these [4] Rosa Meo, ?Theory of dependence values,? ACM methods is applied to hopfield network program. Trans. Database Syst. pp. 380 - 406, Sep. 2000.

4. CONCLUSIONS AND FUTURE WORK  4.1. Evaluation  To evaluate the performance of the algorithm, we intend to generate synthetic customer transactions. And we apply our algorithm to those transactions in four situations. In other words, we simulate combination of two preprocessing and two post processing. After we make an item dependency map, we use it as input pattem in hopfield network. And then to validate, we reuse partial user?s itemsets. When a user data of group A is input and the conclusion is similar to item dependency map of group A, we can thing that the algorithm that we suggest is good.

At early experiment, when we give a weight value(a) and use ranking, performance is best. But we have to decide the factor whether the output is similar to the pattern of item dependency map. And we need more evaluation.

4.2. Conclustions  In this paper, we have introduced item dependency map which express relation between purchased item. This algorithm can recommend an item that yet a user don?t buy but maybe is likely to interested in. And item dependency map is used pattems for association in hopfield network so we can extract users? global purchasing item pattem with users? partial information.

But we cannot test fully and determine parameter function about the number of groups and items. And we will suggest optimal value of a and R in the future.

Continuously we will develop this algorithm and evaluate more perfectly. Until now we suggest item dependency map with experimenting. In future we will extend algorithm modifylng weight and add refining method.

Then we apply developed algorithm to real web site.

5.REFERENCE .

[ 11 Tarun Khanna, ?Foundations of Neural Networks,? Addison-Wesley Publishing Company, 1990.

[2] Rakesh Agrawal, Ramakrishnan Srikant, ?Mining Sequential Pattems,? In Proc. of the 1 1 th Int?l Conference on Data Engineering, Taipei, Taiwan, March 1995.

