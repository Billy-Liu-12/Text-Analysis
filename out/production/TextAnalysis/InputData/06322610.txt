A parallel algorithm of frequent itemsets mining based on bit matrix

Abstract?Mining frequent item sets is an important issue in association rules community. This paper proposes a parallel algorithm for mining frequent item sets based on bit matrix.

The algorithm reduces the memory space and the I/O overhead, for it scans database only once and builds a compressed bit matrix. It combines both top-down approach and bottom-up approach to improve the efficiency of pruning, and uses dynamic scheduling parallel multi-threaded of OpenMP to mine frequent item sets. The experiments show that this algorithm has higher computing efficiency than Apriori algorithm.

Keywords- association rules; frequent item sets; bit matrix; parallel;  multi-thread

I.  INTRODUCTION Association  Rules  is  one  of  the  important  branches  in  data mining research, The frequent item sets mining is the key of the problem, and also the key point in the research [1].

The classical researches about serial algorithm include the Apriori algorithm [2] and the FP-tree algorithm [3]. But as the quantity and dimension of  item sets increased, serial algorithms are not provided with good performance. In order to deal with very large data bases, parallel algorithm research is another focus in frequent item sets mining.

Taking advantages of computer binary operation[4], this paper proposes a parallel algorithm of frequent item sets mining based on bit matrix.  It effectively shows the ability of multi-core computer and is superior to the algorithm Apriori obviously.



II. BASIC CONCEPTS (1)Let I={I1,I2,?,In} be constituted by n different data  items, called item set. Let A be any subset of I. If |A|=k, A is referred as k-item sets.

(2)Let D={T1,T2,?,Tm} be constituted by m transactions, called transaction database. And Every transaction Tk  is  a  set  of  items,  that  is  Tk?? and  Tk?I.

Every transaction is identified only by TID.

(3)The  support  of  A,  which  is  a  set  of  items,  is  the probability of containing A in the transaction set D. If support(A) is not less than the minimum support threshold min_support, A is referred as a frequent item set, or it is referred as a infrequent item set.

The purpose of this algorithm is to find out a frequent item set whose support is no less than a predefined minimum support threshold min_support.



III. PARALLEL ALGORITHM OF FREQUENT ITEM SETS MINING BASED ON BIT MATRIX  A. Algorithm Thinking The guiding idea of this algorithm is that transaction  database is scanned for once and is transformed into a compressed bit matrix. Using the method of partition parallel, the algorithm makes full use of properties of frequent item sets (The nonempty subset of frequent item sets must be a frequent item set, and the superset of infrequent item sets must not be a frequent item set). The algorithm combines both top-down approach and bottom-up approach. Main thread is responsible for top-down mining, and sub-thread is responsible for bottom-up mining. Both of them collaborative achieve the goal that mining all the frequent item sets rapidly.

B. Algorithm steps (1) Construct a bit matrix. Scan the database and  transform it into a transaction compressed bit matrix. Each row represents a transaction and each column represents an item. Set up a transaction counting array at the same time.

Scan a transaction and transform it into a representation of a bit vector. Check up whether it  is in the matrix. If it  is,  the corresponding transaction counter plus 1; if not, add the vector as a row into the matrix and set the corresponding transaction counter as 1. The same transaction in the bit matrix has only one record and the corresponding counter reflects its actual number of records. The database D which has n different data items and m transactions is scanned for one time and formed into a bit matrix An?s  where  ??  ? ? ?  ?  ? ?  ij  ij ij TI  TI A   ,s?m. Get the transaction counter array TS[s].

(2) Generate frequent 1-item sets. Calculate the support  counts of each item, for example, calculating ])[(  jTSA  s  i ji   ? for the item Ij . If the value is less than the support threshold, which means the item Ij is a infrequent 1-item set, then delete the column and make up a frequent 1-item by the items which corresponding the rest of columns at last.

DOI 10.1109/ICICEE.2012.321     (3) Main thread mines the maximum frequent set. Main thread scans the transaction counter array TS[s], determines the frequent item sets directly for the transaction items whose value of counter is bigger than the support threshold and stores them into the list of frequent item sets.

(4) Generating frequent 2-item sets. Main thread calls several paralleled sub-threads according to the number of detected processor core. Starting with the first column, each sub-thread only processes the mining task on frequent 2- item sets contained specified column and each column after it. To deal with the mining task on frequent 2-item set contained  the  jth  column  and  each  column  after  it  for example, sub-thread p should firstly check up whether j and j+1 exist in the same item set in the list of frequent item sets.

If  they?re  in,  p  skips  them  directly  and  deals  with  the  column j and j+2. If not, calculates ])[)&(( 1  jTSBVBV j  s  i j 	?  ?     and  check  up  whether  it  is  a  frequent  item  set.  If  it  is,  p stores it into the private frequent item sets result array. If not, p stores it into the private infrequent item sets result array.

When the number of frequent item sets is small, threads wait for synchronization, which leads to the reduction on parallel efficiency. Using the dynamic scheduling methods [5] (such as oriented scheduling) provided by OpenMP, a sub-thread will go on and deal with next untreated column. When all the sub-threads finished, main thread stores frequent 2-item sets and their support counts into the results array of the frequent item sets in shared memory and stores the infrequent 2-item sets into list of the infrequent item sets in shared memory.

(5) Generating frequent k-item sets(k?3). Main thread calls some paralleled sub-threads according to the candidate item sets and the number of processor core. Also starting with the first column, each son thread only processes the mining task on frequent k-item sets contained specified column and the column after it. To deal with the mining task on frequent k-item sets contained the column j and each column after it for example, sub-thread p should first examine if these k items exist in the same item set in the list of frequent item sets. If they?re in, p skips them directly and deals with the next k columns. If not, p calculates their supports and check whether they are frequent item sets. The following treatments are the same with the previous step which is no longer to be described here.

(6) Let k+=1 and go to the step (5) until new k-item sets cannot be made up.

C. Example of Algorithm Illustrate the implementation of this algorithm through  a sample below. A transaction database is shown in TABLE

I. Set the minimum support counts as 3 here for the convenience of expression.

TABLE I.  TRANSACTION DATABASE  TID Item list TID Item list TID Item list T01 I1,I2,I4,I5 T07 I1,I2,I4,I5 T13 I2,I3,I4,I6 T02 I2,I3,I5 T08 I1,I2,I3 T14 I2,I3,I4,I6  T03 I2,I5,I6,I7 T09 I1,I4,I5 T15 I1,I3,I7 T04 I1,I4,I5 T10 I2,I3,I6 T16 I1,I2,I3 T05 I2,I4,I5 T11 I2,I3,I5 T17 I2,I3,4,I6 T06 I1,I3 T12 I2,I3,I5  (1) The algorithm firstly scans the database and constructs a bit matrix A9?6 , transaction counter TS[9] and the support counter IS[6] of frequent 1-item sets as shown in TABLE II.  Because the support counts of item I7 equals to 2, the algorithm rejects it.

TABLE II.   BIT MARTIX  Bit matrix A BV1 BV2 BV3 BV4 BV5 BV6 Transaction counter TS  1 1 0 1 1 0 2 0 1 1 0 1 0 3 0 1 0 0 1 1 1 1 0 0 1 1 0 2 0 1 0 1 1 0 1 1 0 1 0 0 0 2 1 1 1 0 0 0 2 0 1 1 0 0 1 1 0 1 1 1 0 1 3 8 13 11 8 9 5 Support counter IS  (2) Main thread scans the transaction counter TS. It finds out the item sets {I2,I3,I5} and {I2,I3,I4,I6} whose support is no less than the minimum support threshold 3 and stores them into the two-dimensional array of frequent item sets. Then main thread calls four sub-threads. Sub-threads P1 calculates every frequent 2-item set which is constituted of  I1  and  each  item  after  I1.  P2  and  P3  are  similar  to P1.Using the dynamic scheduling algorithm which adopts orientation, algorithm calculates the next untreated item after sub-thread ends. Calculating the previous frequent item sets {I2, I3, I5} and {I2, I3, I4, I6} and supports of their nonempty subsets, sub-thread P4 stores them into the two- dimension array of frequent item sets results.

(3) The parallel processing of a sub-thread generates frequent 2-item sets. Take the sub-thread P1 as an example, P1 firstly scans the frequent item sets list {I2, I3, I5} and {I2, I3, I4, I6} in shared memory. If I1 is not found in this list, BV1 will have ?Bit And? operation with BV2,BV3,BV4,BV5,BV6 respectively and inner product with transaction counter to get the support counts. It generates a frequent 2-item sets which is constituted of I1 and each item after it: {I1,I2},{I1,I3},{I1,I4},{I1,I5}, whose supports are all 4; The support count of {I1, I6} is 0 and should be stored into the list of infrequent item sets. Sub- thread P2 also firstly scans the frequent item sets list in shared memory. If I2 is found in this list, and I3,I4,I5,I6 are also found in the same item sets in turn, which illustrate {I2,I3},{I2,I4},{I2,I5},{I2,I6} are all frequent 2-item sets.

So P2 skips them in turn. Due to the dynamic dispatching, P2 calculates the next untreated the frequent 2-items which is constituted of item I4 and each item after it. Similarly I4 is also found in frequent item sets list where I5 is found and I6 is not. P2 calculates the support counts of {I4, I5} and get 5, which means it is a frequent 2-item sets, and skips {I4, I6}. P3 is similar to P2. Unlike these sub-threads, P4 is responsible for calculating the list {I2, I3, I5} and {I2, I3, I4, I6} of frequent item sets and the support counts of their all     nonempty 2-item sets. I6 is the last item and other following items which can form a 2-item with it do not exist. So every sub-thread is waiting for implicit synchronization of each sub-thread and no longer to process I6. The processing results returned by each sub-thread are shown in TABLE III.

TABLE III.  THE FREQUENT 2-ITEMSETS PROCESSING RESULTS EACH SUB-THREAD RETURNED  Sub-thread P1 P2 P3 P4 Processing item I1 I2,I4 I3,I5 none  {I1,I2} 4 {I4,I5} 5  {I2,I3} 9 {I1,I3} 4   {I2,I4} 6 {I1,I4} 4   {I2,I5} 7 {I1,I5} 4   {I2,I6} 5  {I3,I4} 3 {I3,I5} 3 {I3,I6} 4  Frequent 2- itemsets and the support counter  {I4.I6} 3 List of infrequent  item sets I1?I6  I5?I6  (4) Main thread calls four sub-threads to mine frequent 3-item sets according to the way above continuously. The processing results returned by each sub-thread are shown in TABLE  IV..

TABLE IV.  THE FREQUENT 3-ITEMSETS PROCESSING RESULTS EACH SUB-THREAD RETURNED  Sub-thread P1 P2 P3 P4 Processing  item I1 I2,I4 I3 none  Frequent 2- itemsets and the support  counter  {I1,I4,I5} 4 {I2,I4,I5} 3  {I2,I3,I4} 3 {I2,I3,I5} 3 {I2,I3,I6} 4 {I2,I4,I6} 3 {I3,I4,I6} 3  List of infrequent item sets  I1?I2, I3?I2, I4?I2, I5?I3,  I4?I3,I5  I3?I4,I5  (5) The main thread examines the result returned by each sub-thread and finds out that a new 4-item set cannot be made up. Then the algorithm ends 3.4 Performance Analysis  This algorithm needs to scan the database for only one time, which reduces I/O load and the occupied memory. It reduces synchronous expenses based on OpenMP which dynamically dispatches multithreading to mine frequent item sets. Using two-way mining and properties about frequent item sets, the algorithm greatly reduces the number of candidate item sets. Some parallels need additional calculation to get global support because the calculation results of each node are just local support counts of the item set .  While different in this algorithm, the processing result of each sub-thread is the global support of the item set. This algorithm stores the processing results in the private variable of each sub-thread, which is a good solution to the problem of data competition. This algorithm decides the number of sub-threads based on the actual number of processor core.

And the impact of bus competition on performance is limited.



IV. EXPERIMENTAL RESULTS AND ANALYSIS In  order  to  test  the  effectiveness  of  this  algorithm,  the  author achieve the algorithm on a Core 2 Duo four core Q8200 intel-based (2.33 GHz) PC machine with 2GB main memory, running with WINDOWS XP + VC2005 + OpenMP. Our experimental data sets come from IBM artificial data sets. T10I4D100K contains 870 items, 100000 data records and each transaction of it has 10 items on average. T40I1D100K contains 942 items, 100000 data records and each transaction of it has 40 items on average.

And the algorithm is compared with the serial algorithm Apriori.  With  the  same  data  set  and  support  threshold,  the results of algorithms are same, which illustrates this algorithm is effective. To facilitate the unified comparison, time calculation starts from the point that the file is read into the memory to generating all the frequent item sets and their support counts, regardless of the time used for writing into a disk file. There?s no virtual memory. For each data set and support threshold, the two algorithms are run for 5 times.

Then we get the average running time. The results are shown as Figure 1.

Figure 1.  Execution times for T10I4D100K and T40I10D100K.

From the Figure 1, time of these two kinds of algorithms is substantially increased as the support threshold reduces.

Because the parallel of this algorithm actually begins after the generation of frequent 1-item sets. The efficiency of this algorithm is even lower than the algorithm Apiori when the support threshold is big and less item sets need to be operated. But with the decrease of support threshold, the item sets which need to be operated are sharply increased.

Time expense of this algorithm is smaller than Apriori.

Compared with the small item set such as T10I4D100K, the rate upgrades evidently in a big item set and minimum support threshold such as T40I10D100K. The repeat rate of typical business transaction database is high. Using  5 1 0.5 0.3 0.2 0.1       Ti m  e( se  c)  support thresholds(%)  This algorithm Apriori  T10I4D100K    5 3 2 1 0.9 0.8         Ti m  e( se  c)  support thresholds(%)  This algorithm Apriori  T40I10D100K       compressed bit matrix which makes the advantage in space and time more evident with large data sets, the algorithm mine the large frequent item sets more rapidly with the top- down approach.



V. CONCLUSION This paper proposes a parallel algorithm for mining  frequent item sets based on bit matrix. It partition the items as multithreading tasks, which is different from most parallel algorithm of frequent item set mining. Theoretical analysis and experiment results show that this algorithm is not only effective but also has higher mining efficiency, especially under the condition of large item sets with small support threshold and high transaction repeatability.

