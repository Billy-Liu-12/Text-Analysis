Improved Target Tracking with Particle Filtering Petar M. Djuric? and Mo?nica F. Bugallo

Abstract? In the literature, there are claims stating that par- ticle filters cannot be used for high dimensional systems be- cause their random measures degenerate to single particles.

While this may be true for standard implementations of par- ticle filtering, it may not be true for alternative implementa- tions. In this paper we build on our previous work for track- ing multiple targets with multiple particle filters, where each particle filter tracks its own target. We avoid the collapse of traditional particle filtering by considering an interconnected network of such particle filters where each of them works on a relatively low dimensional space. We assume that our interest is in finding the marginal posterior distributions of the state vectors describing the different targets and not in the joint posterior of all the targets. We test the method on the prob- lem of multiple target tracking based on sensor data which represent a superposition of contributions of all the targets in the field. The computer simulations demonstrate the perfor- mance of the newly proposed method and compare it with other implementations of particle filtering.

TABLE OF CONTENTS  1 INTRODUCTION  2 PROBLEM FORMULATION  3 MULTIPLE PARTICLE FILTERING  4 SIMULATIONS  5 CONCLUSIONS  6 ACKNOWLEDGEMENTS  1. INTRODUCTION  Many problems in adaptive filtering are nonlinear and non- Gaussian. Of the many methods that have been proposed in the literature for solving such problems, particle filtering has become one of the most popular [1], [4], [7], [9], [10].

The roots of particle filtering were established about fifty years ago with methods for estimating the mean squared extension of a self-avoiding random walk on lattice spaces [12], [14]. One of the first applications of the methodology was on the simulation of chain polymers. The popularity of particle filters (PFs) in the last fifteen years was triggered by [11], where the sampling-importance resampling filter was presented and applied to tracking problems. The timing of [11] was perfect because it came during a period when computing power started to become widely available. Ever since, the amount of work on particle filtering has proliferated  IEEEAC paper #1341  and many important advances have been made.

Rather than trying to adaptively provide point estimates of the unknown state of the system xt, as almost all existing methods do, particle filtering attempts to find approximations of the a posteriori distributions of the states, i.e., approxima- tions of p(xt|y1:t), where the symbol y1:t ? {y1 y2 ? ? ? yt} represents observations from time instant one to time instant t (where t is a positive integer). To that end, particle filter- ing uses random grids which are composed of nodes, usually referred to as particles, with assigned weights, the latter be- ing interpreted as probability masses. The particles and the weights form discrete random measures, which are basically probability mass functions. In the generation of particles, each particle has a ?parent,? and the parent its own parent and so on. Such sequence of particles is called a particle stream, and it represents one possible evolution of the state with time.

PFs use many such streams and their weights to approximate the evolution of state distributions with time.

The traditional approach in particle filtering consists of using a single filter for computing approximations of complete joint distributions of interest. As pointed out, the approximations are based on discrete representations of these distributions by samples from the space of unknowns and weights associated to the samples. The method relies on Bayes? theory and comprises three steps: (1) generation of particles (samples from the space of unknowns), (2) computation of particle weights, and (3) resampling. The last step does not have to be implemented at every time instant but it is essential for accurate performance.

One driving force for the advancement of particle filtering is the ever increasing range of its applications. In theory, PFs can be applied to any state space model where the likelihood and the prior are computable up to proportionality constants. The accuracy of the method depends on how well we generate the particles and how many particles we use to represent the random measure. Particle filtering methods are computationally very intensive, but they allow for significant parallelization of their operation.

In [6], it has been stated that PFs, in general, do not avoid the curse of dimensionality. In other words, when the dimension of the state space increases, it is expected that the number of necessary particles for good performance of the PFs grows rapidly. Indeed, their computational complexity is a function of the dimension of the state space as is their accuracy. The latter, however, is true for any filtering algorithm. From esti- mation theory, for example, it is well known that the Crame?r-     Rao bounds of the unknown parameters is a nondecreasing function of the dimension of the model [13].

In the multiple target problem, too, one can expect that with larger number of targets, the PFs have to work with higher dimensional spaces. As a result, the PFs would need many more particles to preserve their accuracy. In this paper, we propose an approach to particle filtering that would require much less particles than the number of particles needed by a standard PF (SPF). However, we note that our objective here is to track marginalized filtering distributions rather than to track complete joint filtering distributions of the states of all the targets. We also stress that, in spirit, the idea is the same as the one used in Rao-Blackwellization [5].

We extend our previous work for tracking multiple targets with multiple PFs [3] and in general, the way we address complex systems [2]. We use a set of interconnected PFs operating on subspaces that form a partition of the complete state space. In essence, the algorithm is designed by em- ploying one PF per target. The building blocks are based on ideas from [8]. Here we propose an efficient strategy that copes with the problem of tracking simultaneously several targets. The sensors report their measurements to a fusion center (FC), which implements the sequential tracking.

The paper is organized as follows. First we formulate the problem in Section 2. In Section 3, we describe some of our initial results on this topic and then we present the proposed method. Simulation results that demonstrate the method?s performance are shown in Section 4. The paper ends with Section 5 with concluding remarks about the proposed approach.

2. PROBLEM FORMULATION  In a sensor field of N sensors, there are K targets that move according to  xk,t = Akxk,t?1 + Bkuk,t (1)  where xk,t = [xk,1,t xk,2,t x?k,1,t x?k,2,t]?  with xk,1,t and xk,2,t being the coordinates of the k?th target in the two-dimensional Cartesian coordinate system, and x?k,1,t and x?k,2,t being the respective components of the target?s velocity; Ak and Bk are respectively 4? 4 and 4? 2 known matrices; and uk,t is a 2 ? 1 state noise vector with a known probability distribution. The number of targets is assumed known. The locations of the sensors are also known, and they are denoted by rn, n = 1, 2, ? ? ? , N . These sensors collect information about the targets which is contained in the data  yn,t = gn(x1,t,x2,t, ? ? ? ,xK,t) + vn,t (2) where n = 1, 2, ? ? ? , N ; yn,t is a vector of observations obtained by the n?th sensor at time instant t, and vn,t is the observation noise process of the n?th sensor. The probability distributions of vn,t, ?n, t are known. In principle, the  functions gn(?) may be different which would correspond to a scenario of a sensor field with different types of sensors. The objective is to track the targets with multiple PFs, i.e., with as many PFs as there are targets.

3. MULTIPLE PARTICLE FILTERING  Previous work  In [8] we proposed and analyzed solutions for improved particle filtering for high dimensional systems by using a set of interconnected PFs operating on subspaces that partition the complete state space. There, the underlying idea is to decompose the state space into separate subspaces of lower dimensionality that form a partition of the original space. The interest is in finding the marginal posterior distributions of the state vectors that span these subspaces.

More specifically, in [3] we apply this idea on the problem of tracking multiple targets moving in a sensor field as described in the previous section. There, the state equation is given by (1) and the observation equation by  yn,t = gn(xt) + vn,t n = 1, ? ? ? , N  = 10 log10 K?  k=1  ( ?kd?0  |rn ? lk,t|? )  + vn,t, (3)  where ?k = ? is the emitted power of the k?th target measured at a reference distance d0, lk,t = [x1,k,t, x2,k,t]? is the location of the k?the target at time t, rn ? R2, n = 1, ? ? ? , N are the locations of the sensors, and ? is path- loss parameter that depends on the transmission medium and is considered the same for all sensors.

The steps of the proposed algorithm from [3] can be summa- rized as follows:  1. Initialization: It consists of setting initial values of parti- cles, weights and other information used for communication among filters.

2. Generation of particles: The states of the targets are separable, which means that the k?th filter, which tracks the k?th target does not need information from other filters in order to generate its own particles at time instant t. Thus, every PF proceeds with particle generation in the usual way.

3. Communication of predictive information: The observa- tion equation suggests that the computation of the particle weights would require information about the states of the other targets in the system. To that end, the PFs exchange information, which is the predicted locations of the targets they track. In other words, based on the weights from time instant t ? 1 and the newly generated particles for time in- stant t, the PFs compute the predicted location of their target and broadcast it to the remaining PFs.

4. Update of the associated weights: Given the latest sensor measurements and the predicted locations of the other targets, the PFs calculate the new weights of their particles and normalize them.

5. Estimation and Resampling: The PFs compute the desired estimates and perform resampling if necessary.

Initialization  new observation  ... M2  M21 ...

send/receive predictive information to/from connected particle filters  Update and normalize weights  Exit  no  observations?

More  no  yes  necessary?

resampling  is  yes  send/receive information to/from connected particle filters  Generate particles  Compute estimates of desired unknowns  T im  e up  da te  M ea  su re  m en  t u pd  at e  update information  update information  resampling  Output   Figure 1. Flowchart of the k?th PF in the system.

The algorithm repeats (from step 2 to 5) until there are no more observations. Fig. 1 summarizes the graphical flow and interpretation of the algorithm that takes place at the k?th PF.

We note that the flowchart also includes a possible exchange of information among the PFs before the generation of new particles.

Proposed approach  Our interest is primarily in tracking targets based on sensor measurements representing a superposition of contributions from all the targets in the sensor field. As an example we use sensors that measure signal power emitted by the targets, where the model of received signal power is given by1  yn,t = K?  k=1  ?kd?0 ?rn ? lk,t?? + vn,t, n = 1, 2, ? ? ? , N (4)  where the notation is the same as before. We reiterate that all the processing is done at the FC and with as many PFs as there are targets. For simplicity, we assume that all the sensors are of the same type (generalizations for the case of sensors with different types is not difficult).

Given that we know the emitting power of a target at the next time instant, ?k,2 and the predicted location of the target, l?k,t, the FC can predict which sensors in the field will sense that target. Obviously, if a target is far away from a sensor, that sensor will not sense the target, and in that case, there is no  1Note the difference of the observation models between (4) and (3).

2If the emitting power of the target is not known, we could add it to the  state vector and estimate it. Subsequently, we would use this estimate in the required computations. If ?k also varies with time, we could model it as a time-varying process ?k,t = f(?k,t?1, ?k,t), where f(?) defines the model of the power variation with time, and ?k,t is some stochastic process with known distribution. Again, we could estimate ?k,t in the usual way, and instead of the true value in the computations that follow, we would use its predicted value.

need to use its data for estimating the location of that target.

So, an important part of the algorithm is the classification of the sensors into groups, where each group contains the sensors that should sense the target at a particular time instant.

If there are K targets in the sensor field, then at time instant t, we define the sets Sk,t, k = 1, 2, ? ? ? ,K, where the set Sk,t is a set whose elements are the indexes of the sensors that should sense the k-th target at time instant t.

Now we explain how the FC decides to assign the sensors to the various sets Sk, k = 1, 2, ? ? ? ,K. Suppose that the predicted location of the k?th target at time instant t is l?k,t.

Then, based on this location the FC can predict where in the sensor field the received signal power due to the k?th target will be greater than a predefined threshold ?. In other words, all the sensors that satisfy the inequality  ?kd?0???rn ? l?k,t???? > ? ? ?v, k = 1, 2 (5) are assumed to have information about the k-th target and will be assigned to Sk . The symbol ?v stands for the mean of the noise vn,t. At the end of this classification process, we have the K sets Sk, with their elements representing the indexes of the relevant sensors of the estimation of the k?th target.

For example, if there are two targets in a field of 10 sensors, the outcome S1,t = {s5, s6, s7, s8} and S2,t = {s7, s8, s9} implies that information about target 1 is in the data from sensors s5, s6, s7, and s8 and for target 2, in the data from sensors s7, s8, and s9.

One alternative to the above scheme is to simply populate the set Sk with L sensors that are closest to the predicted position of the k?th target, and where L is some small predefined number. A second alternative is to simply select the closest sensors (four, for example) to a predicted location of the target, and then use the measurements of these sensors for obtaining the filtering distribution of the PF.

If we employ as importance distributions the priors of the states, the update of the weights is carried out according to  w (m) k,t ? w(m)k,t?1p(yk,st |xk,t)  where yk,st represents the selected set of sensor measure- ments at time instant t for the weight update of the k?th par- ticle filter. From the problem formulation, it is clear that we cannot compute the marginal likelihoods p(yk,st |xk,t), since we do not have their forms. In [3], we resorted to the use of  p(yk,st |xk,t,Y1:t?1) = ?  p(yk,st |xk,t,x?k,t,Y1:t?1) ? p(x?k,t|Y1:t?1)dx?k,t  where x?k,t represents the states of all the remaining targets in the system, and Y1:t?1 are the data used for computation of the state distributions of the remaining targets. In [3], we used the approximation  p(x?k,t|Y1:t?1) = ?(x?k,t ? x??k,t)     where x??k,t are the predicted states (the locations are only relevant for the computation of the likelihood), and ?(?) stands for the Dirac delta function. Therefore, we approx- imated the distribution p(x?k,t|Y1:t?1) with a single delta function located at x??k,t.

In this paper, we propose to work with a more refined approximation, given by  p(x?k,t|Y1:t?1) = K?  i=1 i?=k  ( W  (1) i,t (?(x  (1) i,t ? x?(1)i,t )  + W (2)i,t (?(x (2) i,t ? x?(2)i,t )  ) (6)  where W (1)i,t + W (2) i,t = 1, and x?  (1) i,t and x?  (2) i,t are two  predicted values of xi,t. In other words, we approximate  each p(xi,t|Y1:t?1) with two impulses weighted with W (1)i,t and W (2)i,t . Clearly, the approximation of the predictive distribution with two delta functions should be better than with one delta function.

Before we proceed, it is important that we specify how the location of the k?th target is predicted. We assume that at time instant t?1, the FC has the probability random measures ?k,t?1 = {x(m)k,t?1, w(m)k,t?1}Mm=1, k = 1, 2, ? ? ? ,K. Then the first step of the PFs is the propagation of the particles, from x  (m) k,t?1 to x  (m) k,t , m = 1, 2, ? ? ? ,M . Subsequently, we need  to approximate the distribution ??k,t = {x(m)k,t , w(m)k,t?1}Mm=1, with one that has only two particles. This can be done, for example, by using a fast clustering algorithm. From the clustered points we can compute centroids and weights of the clusters, which are then used in (6).

Once all the particles in all the filters are propagated and all the positions of the targets are predicted, one is ready to update the weights of the particles. Since, we assume that resampling is applied at every time instant and that the particles are propagated from the priors, the update of the weights is computed according to  w (m) k,t ?  ? nk  p(y?nk,t |x(m)k,t ,Y1:t?1) (7)  where y?nk,t are data from the sensor snk ? Sk, that are modified according to  y?nk,t = ynk,t ? K?  i=1 i?=nk  ? ???W (1)i,t ?id?0????rnk ? l?(1)i,t  ???? ?  + W (2)i,t ?id?0????rnk ? l?(2)i,t  ???? ?  ? ??? . (8)  By subtracting the contributions of all the targets in the field except the k?th one, we simplify the problem to tracking of one target only.

It is clear that this idea can be extended with the use of more than two impulses per distribution. One can also exploit the specifics of the problem and work with proposal distributions that may lead to improved performance.

4. SIMULATIONS  In our simulations, we considered the problem of tracking two vehicles moving along a two-dimensional space moni- tored by a network of sensors placed on a grid. The tracking was modeled by equations (1) and (4). The transition matri- ces were given by  Ak = [  I2 TsI2 02 I2  ]  and  Bk = [  T 2s 2 I2 TsI2  ]  where k = 1, 2; Ts was the sampling period; and I2 and 02 were the identity and zero matrices, respectively. The state noise process ut was modeled as independent Gaussian with zero mean and variance ?2u = .15.

We considered a network of 169 sensors placed on a 13 ? 13 grid and separated 100 m from each other. In this way, the first sensor was located at [200,200] (m) and the last one at [1400,1400] (m). The measurements from each sensor were obtained following (4) by setting d0 = 1 m, the attenuation parameter ? = 2 and the parameters ?1 and ?2 were set to 5,000 and 10,000, respectively [15]. The observation noise was simulated as Gaussian with mean 1 and variance ?2v = 1.

With these numbers, the SNRs of the first target at distances 10 and 50 m were about 17 dB and 3 dB, respectively, whereas those of the second target were 20 dB and 6 dB, respectively. Of all the measurements when the targets were within the grid, the lowest SNR was 0 dB, and it was of the first target when it was in the middle of a square obtained from four adjacent sensors.

We implemented the standard particle filter (SPF), and two versions of multiple particle filters, one from [3] which approximates the predictive distributions with a single delta function (MPF 1) and one that approximates the predictive distribution with two impulses (MPF 2). So, each particle of the SPF was 8-dimensional (four state variables per target) and of the PFs of the MPFs, four-dimensional. For clustering of the particles needed in the implementation of MPF 2, we applied the k-means algorithm. In carrying out the multiple particle filter (MPF) we did not always assign to the individual PFs the same number of particles M as to the SPF, that is, it was not always the case that Mk = M,k = 1, 2.

One can argue that a fair comparison would require that the total number of particles in the system should be the same for all the filters (which would imply that for the case of two     0 20 40 60 80 100         t  R M  S E  ( m  ) SPF MPF 1 MPF 2  0 20 40 60 80 100  0.5   1.5   2.5  t  R M  S E  ( m  /s )  SPF MPF 1 MPF 2  Figure 2. RMSE?s of location (left) and velocity (right) by the standard particle filter (SPF) and the two versions of multiple particle filters (MPF 1 and MPF 2).

targets, the PFs of the MPFs should run with M/2 particles).

On the other hand, since the PFs of the MPFs can execute in parallel, one may assign the same number of particles to all the PFs.

In the first experiment, the targets started from [300,800] (m) and [800,1300] (m) with initial velocities [8,0] (m/s) and [0, ?9] (m/s) respectively, and evolved according to the motion equation for 100 s with a sampling period of Ts = 1 s. The SPF used M = 1000 particles and MPF 1 and 2, Mk = 500 particles, k = 1, 2. In Figure 2 we can see the root mean- square error (RMSE) of the locations and velocities of the targets as functions of time obtained from a single realization.

The RMSEs were computed by  eloc,t =  ????1  2? k=1  [|xk,1,t ? x?k,1,t|2 + |xk,2,t ? x?k,2,t|2]  evel,t =  ????1  2? k=1  [ |x?k,1,t ? ??xk,1,t|2 + |x?k,2,t ? ??xk,2,t|2  ] .

where xk,t = [xk,1,t xk,2,t x?k,1,t x?k,2,t]? represents the true state vector of the k-th target at time t, and x?k,t = [x?k,1,t x?k,2,t ??xk,1,t ??xk,2,t]? was the corresponding estimates obtained with the PFs. The results in the figure suggest that for this particular realization, the best performance was obtained by MPF 2 and then by MPF 1. The worst results were obtained by SPF. For other realizations, this was not always the ranking in performance.

In order to obtain statistical results, we performed estimation of 100 realizations with the same setup. The results of the estimation are shown in Figure 3. There we plotted the cumulative distribution functions of the estimation errors of the targets? locations, F (e) = P (E ? e). So basically, these graphs provide information about the estimated distributions  of the estimation errors of the targets? locations. On the left we see the results when the PFs of the MPFs used Mk = M/2 = 500 particles, and on the right when Mk = M = 1000 particles. For example, from the graphs we can state that for the MPF 2, the probability of having an RMSE smaller than 50 m is almost 1, whereas for MPF 2 it is only about 0.8 and for the SPF about 0.75. In other words, the further the curves are pushed to the left, the better are the performances of the filters. It is interesting to point out that the performances of MPF 1 and MPF 2 did not improve statistically with the increase of number of particles from 500 to 1,000. In both cases, MPF 2 showed superior performance.

We also provide results of another experiment where the tar- gets started from [300,300] (m) and [1700,1300] (m) and had initial velocities [4,0] (m/s) and [0, ?5] (m/s), respectively.

They evolved as before according to the motion equation for 100 s. The measurements were made with a sampling period of Ts = 1 s. Note that with this setting, the tracking of the targets is likely to be more difficult than in the first exper- iment because the targets have smaller velocities and spend more time in parts of the sensor networks where they are not sensed very well (recall that the received signal strength de- creases very quickly with the distance between the targets and the sensors). The results are shown in Figure 4. The SPF used M = 1, 000 (left) and M = 10, 000 particles (right), and MPF 1 and 2, employed Mk = 5, 000 (left) and Mk = 500 particles (right), k = 1, 2.

By comparing the performances of MPFs 1 and 2 in the first and second experiments, we see that, indeed, in the second experiment they obtained worse results than in the first one (compare Figure 3 left and Figure 4 right). It is also somewhat surprising that MPFs 1 and 2 performed better than the SPF with 20 times less particles (Figure 4 right). The comparison of MPFs 1 and 2 in Figure 4 left suggests that MPF 1 is more likely to make smaller errors than MPF 2. Overall, the performance of MPF 2 was the best, which was especially     0 50 100 150 200 250  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   e (m)  F (e  ) SPF MPF 1 MPF 2  0 50 100 150 200 250  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   e (m)  F (e  )  SPF MPF 1 MPF 2  Figure 3. CDFs of the obtained RMSEs where the SPF worked with M = 1, 000 particles and the MPFs worked with Mk = 500 particles (left) and with Mk = 1, 000 particles (right). (Experiment 1)  0 50 100 150 200 250 300  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   e [m]  F (e  )  SPF MPF 1 MPF 2  0 50 100 150 200 250 300  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   e [m]  F (e  )  SPF MPF 1 MPF 2  Figure 4. CDFs of the obtained RMSEs where the SPF worked with M = 10, 000 particles and the MPFs worked with Mk = 5, 000 particles (left) and with Mk = 500 particles (right). (Experiment 2)  evident when the number of used particles was small.

5. CONCLUSIONS  In this paper we extend our previous work on tracking of mul- tiple targets with multiple particle filters. Based on the princi- ple ?divide and conquer,? we avoid the collapse of traditional particle filtering when operating in high dimensional spaces by considering an interconnected network of particle filters, each of them working on lower dimensional spaces. Com- puter simulations on tracking of two targets show the feasibil- ity of the method and its advantages over the standard particle filtering approach. We expect that this advantage will further grow if the number of tracked targets is larger than two. It is important to point out that the addressed problem may allow for further improvements in performance. They may not only be based on using more samples to approximate the predic- tive distributions of the targets? states but also on using more  creative proposal distributions.

6. ACKNOWLEDGEMENTS  This work has been supported by the National Science Foun- dation under CCF-0515246, the Office of Naval Research un- der Award N00014-06-1-0012. The work has been carried out while the first author held the Chair of Excellence of Uni- versidad Carlos III de Madrid-Banco de Santander.

