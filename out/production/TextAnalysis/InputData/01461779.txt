

A Memory-based Learning Approach to Reduce False Alarms in Intrusion Detection  Ill-Young Weon+,Doo Heon Song*,Chang-Hoon Lee?,Young-Jun Heo*,Ki-Young Kim- ?Dept of Computer engineering, Konkuk Wniversity  93-I,Mojin-dong, Kwangiin-gu, Seoul (clcc, chlee) @konkuk.ac. kr  ?Dept of Computer & Information, Yong-in SongDam Colleage 577-1 Mapyong Dong Young-in Kpngki  dsong@ysc.ac. kr ?Network Security Department, Electronic and Telecommunication Research Institute  161 kajong-dong, Yusong-Gu, Taejon, 305-350 {yjheo, kykim} @etri. re. kr  Abstraci - Signature-based IDS is known io have acceptable accuracy but suffers from high rates of false alarms. We show a behavior based alarm reducfion by using a memopbased machine learning iechniquc - insiance based learner. Our mended form of IBL W B L )  mamines SNORTalarm signals iftirat signal is worthy sending signals to s e c u m  manager. A preliminav experiment shows that these exists an apparent difference between hue alarms and false alarms wiih respect to XIBL behavior and the full uperirnenf successfully ahibiis thepower of hybrid sysfem is there is a rich set of analyzed daia such as DARPA 1998 dafa set we used.

Keywords - instancebased learning, false alnrm, machine learning, network security  1. Introduction  AIthough it is valuable to use intrusion detection systems in order to protect the resource of computer systems and networks, the security managers have another practical problem - how to manage thousands of alarms generated by the IDS per day. A striking consumer report says 70% of IDS purchasers in Korea, mostly financial enterprises and public administration offices, want to purchase another IDS that has less false alarms with similar accuracy. And in fact, many security managers ignore alarms until other supporting evidences are found [lo].

Another problem is that ,most commercial IDSs are signature-based which identify an attack by matching input with the rules or patterns generated from known attacks. While the accuracy (identify attack if it truly is) of signature-based IDS is more acceptable than that of anomaly-based IDS which labels any input as ?malicious? if it i s  far from ?normal? behavior, it is known that signature-based systems tend to produce more false positives than anomaly based systems.

I41[51  The situation could be worse in that packets can be crafted to match attack signatures on a target signature-based IDS due to the vulnerability of signature-based systems. [7 ]  Two types of partial solutions have been proposed to reduce false alarms recently. A knowledge-based pre-filter with data  mining techniques that handles most frequent alarms significantly reduces the security managers? burden.[2][3] However, this approach tends to ignore infrequent abnormal signals and related otherwise valuable information so that reducing the amount of alarms may cost the accuracy.

Another type of study reducing false alarms i s  to use association rules after an alarm is triggered and investigate if that is worthy sending signals to the security personnel.[6] This behavior based approach. seems to be safer in that the signature-based IDS did its role with full information available to trigger an alarm and the data mining technique, if appropriately chosen, validates it.

However, this post-hoc analysis assumes that the front IDS(signature-based) has no false negative in that it can only find that an alarm signal is in fact ?normal? by association rules. In other words, there is practically no chance to beat the accuracy of front IDS to their hybrid system since it can only response when the front IDS triggers an alarm.

We propose here a behavior-based approach that could reduce false alarms and also compensate the accuracy of front IDS with a memory-based supervised learning algorithm. Our system is originally intended to effectively combine two heterogeneous IDSs developed separately - a system based on SNORT[XJ by Electronics and Telecommunication Research Institute(ETR1) in Korea and another anomaly based engine developed by co-authors of this paper affiliated with universities. [ 1 I ]  We use a variant of instance based Iearning (IBL) algorithm [I ]  as a behavior investigator of SNORT not only if a SNORT alarm is truly worthy informing to the security manager but also generate an alarm with IBL?s o\\n evaluation although SNORT has no action.

IBL stores a subset of real instances that are recognized as ?abnormal? or ?normal? from the training examples. Thus, the knowledge it has is the set 0f?important? instances. When a set of events occur in a network, IBL algorithm searches the most similar instance from its knowledge base to current event and decides whether it is normal or not by following the label of the most similar knowledge. For our case, the instance is a packet represented by 16 real and nominal attributes. [ I O ]  -241 -    However, IBL is noise-sensitive, real-valued attribute based learning engine as it originally was, we extend it to support symbolic attnbute, [9] and give leave-one-out analysis to exclude noise instances and attribute weighting procedure appears to be better than original IB4 [I]. Hence we will call this engine as XIBL (extended IBL) in this paper.

The remainder of this paper is organized as follows. In  Section 2, we give a short explanation of XIBL algorithm and its behavior over SNORT alarm in training set, which gives a rationale of combining two systems. Then, the result of full experiment on DARPA 1998 data will be reported in section 3 and we will conclude this laboratory scale research at the end.

2. Behavior of IBL on SNORT aIarm.

2.1. XIBL  IBL learns by storing examples as points in a feature space, and it. requires some means of measuring distance between examples. An example is usually a vector of feature values plus a category label (class). When the features aie numeric, normalized Euclidean distance can be used to compare examples. However, when h e  feature values have symbolic, unordered values, original IBL typically resort to much simpler metrics, such as counting the features that match. [ 11  D. Aha?s original IBL[ I ]  has had series of developments - from its pure form called IB1 to most complex version of fB4.

Briefly analyzing them, the major difference of one version from another is as follows. IB1 stores all training instances as its knowledge base whereas TB2 stores only important subset by an evaluation function. However, it is known to be noise sensitive. Thus, IB3 effectively eliminates noise from TB2.

And IB4 gwes a penaltyhcentive algorithm in !mining phase to discriminate relatively important features from others.

Our version of IB3, re-implemented in C++, called XiBL in this paper has three important changes from the original one.

First. XIBL avoids overestimating symbolic attributes by applying Value Difference Metnc (VDM)[9] whereas original IB3 took the ?winner-takes-all? strategy. IB3 has the normalization process in it in order to calculate the distance between two instances., Real-valued attributes usually have a distribution between 0 and 1. However, IB3?s strategy gives 1 if the attribute values are different and 0 if they are the same.

This inevitably overestimates symbolic attributes over real-valued attributes.

Value Difference Metric (VDM) takes into account the overall similarity of classification of all instances for each possible value of each feature. Using this method, a matrix defining the distance between all values of a feature is  derived statistically, based on the examples in the training set. The distance 6 between two values for a specific feature is defined in below equation.191  where VI,  V2 denote two points in the example space and Ck and Cki denote the number of examples labeled as class k and i?th value of class k in  respectively.

Second, IBL is noise sensitive. Aha?s 183 showed how to exclude noise of IB2.[ I ]  However, leave-one-aut procedure as a noise filter is more statistically sound. So we take leave-one-out as a noise filtering process.

Third, original IB4 has weighting feature scheme but the perfomance of it rarely beats IB3 mainly due to its simple penaltyiincentive scheme. XIBL takes a sort of backward stepwise attribute filtering technique based on stepwise regression in order to set the weights of attributes. Among N attributes we have, we compare the accuracy of full N attributes and those of when only N-k attributes are considered.

The difference of the two?means the importance of k attributes in classification. Hence, we set the weights of attributes proportional to the difference in a training set. In this paper, we take k = 2 only for the simplicity.

Figure 1 shows the pseudo-code of XIBL used in this experiment.

Key: .

T: Training set TE: Test set P Set of attributes VDM: Symbolic value distance metrks k : Number of most similar instances used PCD: Partial concept description W : Weight of each attributes Train( T , P ,  VDM , k,W) 1. PCD=() 2. VDM = Mab-VDMfT, P) 3. for each xt E T do  3.1 classValue=NearstNeighbor(P, PCD , VDM,W,k, x,) 3.2 if classVahe not equal targetvalue then  3.3 LerveOoeOut(PCD, k, M M ,  P) NcarstNeighbor(P, PCD, VDM, W, k , I) 1. Update each attribute?s mar min values for numeric type 2. for each yI E PCD do  2.1 Similarity&,a,W) 3. KSET=k_most_simibr_ins~nce( PCD , k) 4. return Vote(KSET) Leaveoneout( PCD , k , VDM , P) 1. NOISE={} 2. for each I, E PCDdo  PCD = PCD + XI  2.1 classVatuc=NearstNefghbor(P, PCD , VDM, xI) 2.2 if classVnlue not equal targetvalue then  NOISE = NOISE + XI 3. PCD = PCD - NOISE Test(TE, P, VDM, k) 1. for each x4 E TE do  1.1 return NearstNelehbor(P. PCD . VDM.k I,) Figure 1. XIBL Pseudo code  2.2. XIBL in preliminary experiment  We used DARPA 1998 off-line intrusion detection evaluation set[8] throughout this paper. We are interested in the relative classification perfomance of XIBL to the types of SNORT alarms - true and false alarms. XlBL IabeIs every packet as ?normal? and ?abnormal? which are meaningless if it is used alone. However, we test the classification power of XIBL over the training set explained below in order to find its characteristics.

Our preliminary experiment data set is organized as follows.

First, we randomly collect 70% of real attacks from DARPA  - 242 -    data set and part of normal data set in contiguous time frame with about the same size in packets. In results, we have 44726 packets and 45453 normal packets. Then, we conduct a IO-fold cross validation on this data set.

We choose the best PCD which contains noise-filtered packet vector from above procedure. The best PCD contains 365 normal packets and 294 abnormal packets or about 8% of training data with 99.4% fitting rate.

With this PCD, we test 30% of attack packets and about the same size of normal packets. The result shows that 88% of normal packets are classified into ?normal? but only 68% of attack packets are correctly classified.

Instances in XIBL PCD denote a representative polygon of each class in the vector space. If a test packet is coming in, XlBL finds the most similar instances from *the PCD and labels the class of input as that of the ?closest instance from PCD. In this way, XIBL tends to mode1 ?normal? packets more correctly than that of ?abnormal? since a stream of abnormal packets consist an attack.

Then, we examine the performance of SNORT 1.8.7 with the same training data. SNORT identifies an attack if one or more alarms are triggered within the stream of ?attack? labeled data.

For every attack type we calculate the number of packets consisting that attack approximately and see how XIBL responses to that attack.

There are several false alarms from SNORT in this pilot data set. We send all ?normal? labeled .data to SNORT and it triggers alarms with known and unknown types. Then we compare these false (labeled with known attacks) alarms with true alarms with respect to XIBL behavior if there exists any pattem. For some back attacks (2-fri-back, 3_wed_back), the packet sequence has completely same subsequences so that we only analyze that subsequence instead of full sequence.

Figure 1 and Figure 2 clearly shows that XlBL behaves differently whether an alarm signals true attack or not. In this pilot data set, there are only four types of false alarms labeled with known attacks. Figure 3 shows if we set a threshold according to the XIBL?s performance within the attack sequence. The number of packets in false alarm is induced from that of true alarm. And also there were more than 200 false alarms as ?unknown attacks?. In that case, we analyze 100 packets in front of alarmed packet and see how XIBL behaves.

From Figure 1 to Figure 3, we can set a threshold that if SNORT triggers an alarm, trace back to 100 packets(if type is unknown) or the average packet size of a known alarm and see if XIBL?s ?abnormal? rate is more that 50%, if yes then regard it as ?true? alarm.

7 mon phf I I 2 7 wed phf 7 6  216 C ortswee 2-mongortswe ep  Table 1. Activity o f  XIBL la True Alarm  5 71.43 1 14.28  216 100  Name of Attack  satan 1-mon 4 4 .  50 1-thur IO 5 ?  33.33 2-fI-i 3 5 62.5 3 mon -31 ; 5 62.5 3 - wed 31 5 62.5  33 336 10 monjortswe I  Table 2. Activity o f  XIBL in False Alarms I  27.2 ortswee  Another factor considered in this preliminary experiment is how long XIBL?s ?abnormal? consecutive sequence is and if that is different between real normal and attack data. Let?s call it as ?picks?. The rationale of this criterion is that if an attack is real, some number of packets with similar characteristics will flood in the network meanwhile normal data should not have that long sequence of incorrectly classified packets by XIBL.

For most of real attacks, this pick criterion turns out to be  more than 50 if the number of packets in the attack sequence is sufficiently long (say more than 100 packets). Table 4 and Figure 2 shows that the distribution of picks over number of patterns detected in the sequence of normal data.

- 243 -    picks Patterns  Accuracy 86.52 91.03 Missed attack 49 17  1 454  ,?]  I 2d  Figure 2. Distribution of picks and patterns  3. Full Experiment  We conduct an experiment with full DAWA 1998 data. The purposes of this experiment are as follows.

1) If appropriately combined, can we reduce the amount of alarms while preserving the accuracy?

2) Will our second criterion (number of consecutive XIBL abnormal packets) play any role to detect another attacks that passes SNORT signature?

Recall that that data set of our preliminary experiment consists of a part of data and the distribution of training data was, set to approximately 5050 of normal and abnormal packets. In real situation, 99% of packet flow is normal. In DARPA data, there are more than 3 million packets and only little more than 2 % of them are known as attack packets.

Thus, it is easy to expect that here will be more false alarms from SNORT.

Also, in our preliminary experiment, we count on only One  alarm per attack data set. In real situation, for the same type of attack, SNORT will trigger many more alarms regardless of its real figure. Thus, we set a decision rule of triggering an alarm in this hybrid architecture as follows.

Key:  AB: XIBL rate of abnormality P XIBL picks K : average packet size of known type attack  Decision Rule  If SNORT triggers an alarm on input packet x, Then Begin  if the type of attack i s  *known? Then trace back to k packets  Else trace back to 100 pickets Examine k packets by XIBL  Examine ID0 packets by XIBL Endif If AB > 50% Then Send Alarm  Endif End  Else Begin  Else pass that packet I.

Examine P with the same source IP If P > 50 Then Send Alarm  Endif Else Update P of that source IP  End  Figure 3. Decision Role  Table 5 summarizes the experiment.

I SNORT I Hybrid I Rate  TrueAlarm I 83084 8 3 4  99.98 I I I  I2945 ew True  ew False  Total 960251 91304 95.

I  The result shows that the hybrid system actually reduces SNORT false alarm to 60% level and retain most of SNORT true alarm. Moreover, hybrid system did find some number of new attacks that SNORT could not find. However, in that case(new true alarm), only 1-3 alarms are triggered since the decision rule reset P(picks) after it detects new attack(n0 SNORT alarm) and usually picks are very high.

Another noticeable finding is that while SNORT did not generates any alarm for 49 attack set in DARPA 1998 data, the hybrid system misses only 17 of them which usually consists of less than 100 packets.

-244-    4. Conclusion [I  11 Won, I. ,  Song, D., Lee, C. Heo., Y. & Jang, J., A Machine Learning approach toward an environment-free network anomaly IDS - A primer report, In Proc. of 5th Intemational Conference on Advanced Comunication Technology, 2o03. We have presented a series of experiment to set up a hybrid system of combining signature-based IDS (SNORT) with a  machine learning based anomaly detector engine. While many other systems have tried data mining techniques to reduce false alarms, we have shown that if rich set of analyzed data is available, memory based supervised leaming can be effectively used to improve the performance of signature based IDS.

The experiment shows that the reduction rate is though far from satisfactory. This might be resulted by poor set of signature we have in SNORT in that too many alarms are triggered from the same attack set. In that sense, a careful alarm filter that does not omit valuable information could be helpful for this hybrid system.

At this point of time, the implementation level of this hybrid system is just a taboratory style. We are developing this hybrid system continuously and some other new ideas and test sets are ready to be included.

Acknowledgements  This research is fully supported by Electronic and Telecommunication research Institute.

