A Clickstream-based Collaborative Filtering Recommendation Model for E-Commerce

Abstract In recent years, clickstream-based collaborative  filtering (CCF) recommendation models have received much attention mainly due to their scalability. The common CCF recommendation models are Markov modesl, sequential association rules, association rules, and clustering. The models have shown the trade-off relationship between precision and recall in performance.

To address the trade-off relationship, some study has combined two or more different models or applied multi- order models. The increase of recommendation effectiveness by these models is also at best marginal. To increase recall while minimizing the loss of precision and therefore to increase overall performance measured by the F value, we build a sequentially applied model (SAM) by applying the individual models in tandem in an order determined through a learning process. We evaluated SAM over the individual models with Web usage data, and the result is promising.

1. Introduction  Collaborative Filtering (CF) is a technology of making use of peers? evaluations or behaviors for a personalized recommendation [7]. Depending on data type in use for CF, it can be classified into either user-based CF or item-based CF [10][16][27]. User-based CF employs user data such as user profiles to find the most similar users or a reference group for a user, and based on their preferences it recommends items for the user. Item- based CF employs item data such as products or Web pages to find item relationships based on which it recommends items for a user.

User-based CF has been extensively used in research and in practice. However it has a limitation in scalability [10][16][20][21]. Traditional user-based CF (e.g., K- Nearest Neighborhood) does most of recommendation computation in online real time. For example, from the user-item matrix in Figure 2, its online computational  complexity is O(mn) in the worst case because it needs to scan all the users once to find similar users and scan all the items to find the items that the similar users have selected [16]. Because some typical electronic commerce (EC) sites have millions of customers and items, this online computation complexity becomes a problem [9] [16][20]. Although some statistical methods such as sampling or clustering can mitigate the online computational complexity, these methods reduce recommendation quality [16]. For instance, clustering performs much of its computation offline, but there are chances that the most similar user found in the closest cluster is not truly the most similar user [16]. This is illustrated using a simple clustering in Figure 1.

Figure 1 A bad clustering example.

Item-based CF can have heavier computation than user-based CF, but the heavy computation is performed in offline batch process. The batch process usually builds recommendation models with which online recommendation is made (so this item-based CF is called model-based CF) [27]. This makes its online computation lighter than user-based CF. So the scalability problem can be overcome. For this reason, item-based CF has received much attention as a way of doing CF. In practice,      Amazon.com, which has tens of millions of customers worldwide and millions of products, is using item-based CF [16]. From Figure 2, its offline computational complexity could be O(n2m) in the worst case: i.e., nC2 m.

For an item i it scans all the users, and it calculates item similarities for the rest of the items {1,2,..i-1,i+1,?, n} by using m dimensional user space. This process is repeated up to n-1. Its online computation complexity is O(n) in the worst case, but on average the complexity is O(constant) because the online computation is just to look at the constant number of items for an item (i.e., the number of the related items is very small or it recommends only TOP N items).

Item 1 Item 2 ?.. Item n User 1 ? ?.. ? User 2 ? ?..

?.. ?.. ?.. ?.. ?..

User m ? ?.. ?  ? = selection or purchase of an item by a user Figure 2. A user-item matrix.

Clickstream-based CF (CCF), a kind of item-based CF [10][27], has received much attention as a way of doing collaborative filtering recommendation in Web navigation because user data is generally not available (IP addresses may be used as implicit user identifications).

Like other item-based CF, CCF needs to adopt prediction models for efficient and effective recommendations of pages (or products) due to its vast amount of data stream to process: it trains the models offline and uses them in online recommendations. Unlike other item-based CF recommendations (i.e., market basket data in EC), the sequence of pages is important for its recommendation quality due to the fact that the sequential structure is embedded through the hyperlinks in Web pages.

Clickstream-based CF recommendation has its importance in EC because it could customize Web sites with relevant pages (or recommend relevant products) to increase user experience. That is, from browsing patterns we can know a user?s product preference and then recommend relevant pages or products [9][10][26][30].

Many studies have worked on CCF recommendation models using browsing patterns and their performance.

The common models for CCF recommendation are Markov models [1][2][6][7][9][17][24][28][31][32], sequential association rules [17][23][7][12][22][13], association rules [7][20][6][22][10][19] and clustering [4][11][30][32].

The contribution of this paper is as follows: (1) it proposes a hybrid model, SAM, which applies the individual models in sequence. SAM increases recall and  the F value while keeping the loss of precision at minimum. To the best of our knowledge, SAM is the first hybrid model that applies different model types in sequence; and (2) we show the performance of the hybrid model, SAM, mathematically and experimentally.

In the next section, we present our motivation. In section 3 we propose a new CCF recommendation model, and in the following section we evaluate the proposed model in experiment and present its results. And then we discuss related work. Finally, we make a conclusion with some possible future work.

2. Motivation  Markov models (MM) have been well positioned as a CCF recommendation model because of its high precision coming from the consideration of consecutive orders of preceding pages. However, this high precision comes at the cost of low coverage because the clickstream data is inherently sparse and MM cannot cover the sparse data well. Markov models generally have high precision and low coverage. In order to address this lower coverage and recall, multi-order mixed Markov models have been devised [28]. The All K-th order Markov model [24] is one example. This applies the highest order first to predict a next page (or product). If it cannot predict the page, it keeps decreasing the order one by one until it can recommend the next page or product (i.e., cover a current active clickstream) [9][24]. This can increase the coverage (and recall) of the model, but the increase could be still marginal for some applications (e.g., cross-selling in EC) where recall is more important.

Association rules (AR) are based on the relationship of co-occurrences of pages or products, without considering the sequence of them [19][20]. The co- occurrences may represent diverse (multidirectional) semantic relationships between pages. Girl vs. woman (similar) and male vs. female (opposite) are the examples (for all possible relationships, refer to [29]). Association rules have been applied for finding frequent product sets in EC [10].

The frequent product sets are used for recommending products. There is no order consideration. This makes AR generally produce low precision, but high recall in the prediction. Association rules first identify large frequent page or product sets from a training data set using a support threshold (i.e., minsupport in [3]). Then, for each active path (i.e., antecedent) in a test set, it identifies frequent sets containing the active path. From the identified frequent sets, it recommends pages or products in the order of their confidence. In order to increase the coverage on the test set with the training set, the size of the active path can be decreased one by one recursively until the path is covered by the training set. Association      rules? performance also varies depending on the threshold values of support and confidence, which should be set in advance before training [14]. A high threshold value would result in higher precision and lower recall, while a low threshold value would result in lower precision and higher recall. There is no good way to a priori select optimal values of support and confidence. Therefore AR may require an extensive learning experiment to find the optimal values [10].

Sequential association rules (SAR) stand between MM and AR in that it considers the sequence of pages, which is not necessarily contiguous, and uses frequent sets for its recommendation as association rules do. It is expected that SAR come between MM and AR in precision and recall.

Clustering alone may not be an appropriate approach for CCF. It usually employs different feature sets such as contents (or concepts) [4][11][30] or link structures [32] of pages, or is used as a moderator (in terms of computation) with other models [12][32]. This statistical method is to partition pages, or sessions into closely related subsets, part of which is used for recommendation (it is possible to create clustering using all data set). Because it does not use all the pages directly but through the controlled clusters (i.e., the number of clusters, and maximum and minimum sizes of clusters are set in advance), it may lose some accuracy [16]. Clustering based on the feature sets like bit vector (visit or non-visit) [19], spent time, or frequency does not partition pages or sessions well because those feature sets usually cannot capture well structural and semantic relationships between pages.

The prediction models for CCF show strengths and weaknesses in their performance due to the inherent trade- off relationship between precision and recall. Even the hybrid models [22][31] show their limitations in their performance increase, especially recall, because they mainly focus on increasing precision and apply only one model type at a prediction point. Therefore it is always a research issue to find (or devise) a model addressing precision as well as recall. Thus we are presenting a hybrid model SAM combining the individual models at model level to increase recall and the F value while minimizing the loss of precision at minimum.

3. Proposed Work  One main goal in this work is to devise a new CCF model that provides better recall and the F value over existing models. Without using contents or the structure information, a way to increase both coverage and recall while keeping the loss of precision at a minimum is to apply the individual models (MM, SAR, and AR) in tandem in an order (presumably precision order) decided  through a learning process. Conceptual motivation is depicted in Figure 3. Since the prediction models show varying performance depending on a data set and the parameters such as the number of pages (or items) in recommendation, window size, minimum confidence and support, the learning process is needed to decide the order in applying the individual models. In Figure 3, the performance of the proposed model may be represented as the combined area of the three individual models. Modelh represents a model with the highest precision, modell a model with the lowest precision, and modelm a model with the middle precision. Each area (i.e., the product of precision and recall) represents the performance of each model. Because the models are applied sequentially and recall has a non- decreasing property, we can build SAM that applies the models in tandem in an order. In Figure 3, modelh represents a model with the highest precision and the lowest coverage; modell a model with the lowest precision and the highest recall; and modelm a model between modelh and modell. The precision of SAM comes between the highest precision and the lowest precision of the member models, but much more towards the highest precision since SAM is constructed with the individual models usually in their precision order.

Figure 3 The conceptual representation of the performance of the proposed model.

First, with Figure 4, we can show by a simple calculation how the precision and recall of the proposed SAM position in comparison to the ones of the individual models. From Figure 4, let Pi be the precision of the individual model i where i = h, m, or l. Let the total number of covered records Ai be Ci+Wi. If Ai, a subset of the whole test set, is large enough, then the precision Pi of each model from the whole data set can be represented as follows:  Pi = Ci/ (Ci +Wi) where i = h,m, or l  Pi = Ci /Ri (1)      Then the precision PSAM of the proposed SAM is:  PSAM = ?iCi / ?iAi Basically, the order of applying the individual models  is determined through a learning process. However for the sake of explanation, Figure 4 assumes SAM constructed with the individual models applied in their precision order, which is intuitive. If individual models with lower precision are used first, there is a chance that the individual model with the highest precision is not used for recommendation, which makes the precision of SAM closer to the precision of the model l.

Figure 4 The way of building SAM.

In order to know where the precision PSAM will be positioned compared to the precisions of the individual models, let?s first compare PSAM with Ph.

Ph ? PSAM = Ch / Ah - ?iCi / ?iAi = (Ch?iAi ? Ah?iCi) / Ah?iAi  Since Ah?Ai > 0, then we only need to decide the sign of the numerator to determine the order between PSAM and Ph:  Ch?iAi ? Ah?iCi = ChAm+ChAl-CmAh-ClAh (2)  From (1),  Ci = Pi Ai (3)  Insert (3) into (2):  PhAhAm+ PhAhAl- PmAmAh- PlAlAh  = AhAm(Ph- Pm) + AlAh(Ph-Pl)  Since Ph- Pm>0 and Ph- Pl>0,  ?Ph > PSAM  This means the precision of the model with the highest precision is always greater than the one of the proposed SAM. This implies the decreasing nature of precision in SAM. In the same way, if we compare PSAM with Pl  Pl ? PSAM = (Cl?iAi ? Al?iCi) / Al?iAi  The numerator is decomposed into:  AlAh(Pl - Ph)+ AlAm(Pl ? Pm)  Since Pl ? Ph < 0 and Pl ? Pm< 0,  ?Pl < PSAM  This tells us that the precision of the model with the lowest precision is always less than the precision of the proposed SAM. Let us compare PSAM with Pm:  Pm ? PSAM = (Cl?iAi ? Al?iCi) / Al?iAi  In the same way, we get the following numerator:  AlAm(Pm- Pl) ? AmAh(Ph - Pm)  Let AlAm(Pm- Pl) ? AmAh(Ph - Pm) equal to 0.

AlAm(Pm - Pl) ? AmAh(Ph - Pm) = 0  ? Al/Ah = (Ph- Pm)/(Pm- Pl)  After transforming the numerator and removing Am from it, the sign of the numerator depends on the ratio of two items, Al/Ah and (Ph- Pm)/(Pm- Pl). That is, if the ratio of the number of records covered by the model l over the number of records covered by the model h is greater (less) than the ratio of the difference in precision between h and m over the difference in precision between m and l, then Pm is greater (less) than PSAM.

If the two ratios are equal, then Pm is equal to PSAM.

Figure 5 Performance representation of SAM.

For the recall of the proposed hybrid model SAM,  RSAM = ?iCi / (?i(Ci+Wi)+U)  Ri= Ci / (?i(Ci+Wi)+U)  ? RSAM? Ri  This tells us the non-decreasing property of recall in SAM.

In Figure 5, the shaded area represents the overall performance of the proposed hybrid model SAM. The more darkly shaded area (P1P2V2V1) can be included depending on the ratio of Al/Ah and (Ph - Pm)/(Pm - Pl), as explained earlier.

We need to compare the performance of SAM when the individual models are applied in their precision order like in Figure 4 with the performance of SAM when they are not applied in their precision order, for example, m, l, and h in that order whereas Ph>Pm>Pl. Let P  ? SAM be the  precision of SAM when the individual models are applied in the order of m, l, and h.

PSAM - P ? SAM = (CSAM / ASAM) ? (C  ? SAM / A  ? SAM)  = (Ch+Cm+Cl)/(Ah+Am+Al) ?  (C?m+C ? h+C  ? l)/ (A  ? m+A  ? l+A  ? h) (9)  Since the total number of covered records for both PSAM and P?SAM is the same (i.e., Ah+Am+Al = A  ? l+A  ? h+A  ? l), (9)  can be written as:  = (Ch+Cm+Cl) ? (C ? m+C  ? h+C  ? l) (10)  (10) tells us that the sign of PSAM - P ? SAM depends on the  number of the correct records in PSAM and P ? SAM.

Intuitively, the size of Ch+Cm+Cl should be greater than the one of C?m+C  ? h+C  ? l. However, it is possible that the  size of C?m+C ? h+C  ? l be greater than the one of Ch+Cm+Cl  (i.e., P?SAM > PSAM). The reason is: the order of applying the individual models determines what part of a training data set that each model uses and the size of the part; and therefore it is possible that Ci ? C?i (where i = h, m, and l).

Thus in order to make sure that we choose SAM with the best performance, we need to perform a learning process that measures the performances of all possible SAMs in different orders of the individual models.

4. Experimental Evaluation  In this section, we first present the evaluation metrics we used for measuring recommendation effectiveness, and then the results of our experiment based on these metrics.

4.1 Performance Evaluation Metrics  The performance metrics, recall and precision, will be used for measuring the prediction quality (i.e., effectiveness) of the models. These metrics have been used as the effectiveness measures of the prediction models [28][20][6][18][22].

To measure the performance of the models in experiment in the context of personalization, a session data set is divided into training and test sets. The training set is used to generate the models while the test set is used to evaluate the models set with the training set [27]. Each session s in the test set is divided into two parts. The first n clicks, <1,2,?,n> (where 0<n<s), in s are treated as an active session and are used for making predictions, while the remaining portion, <n+1,?,s>, in s is used to evaluate the prediction models. Active session window is the portion of a user?s active clickstream used by a prediction model for recommendation. So each model starts to recommend pages with an active session with the highest order (i.e., a full active session) and decreases the order one by one up to a minimum active session window until the active session is covered by the model (in our experiment, the average session size of the data set is set as the highest order, as suggest in [19]). The active session is denoted by ass, and the remaining portion |s|-n of a session s is by tests. A prediction model takes ass as an input and makes a prediction. A set of pages generated by the prediction model is denoted as P(ass). Then precision, recall, and the F value [5][15] can be represented in Figure 6 [22]. The F value is used for comparing the overall      performance of the models by giving equal weights on precision and recall [18][25].

Figure 6 Performance metrics.

4.2 Experimental Results  The performance of SAM was evaluated over varying TOP N values, the number of pages recommended by a prediction model. Depending on applications, TOP N may vary. In typical recommendations like in cross-selling in EC, the TOP N could be relatively small (e.g., ten or so).

For the experiment, the publicly available NASA Web access log data, NJMC (New Jersey Meadowlands Commission, http://www.meadowlands.state.nj.us) and CIMIC (Center for Information Management Integration Connectivity, http://cimic.rutgers.edu) log data are used.

A data set is divided into training and test data sets by their dates such that the test data is the session data at later dates than the training data. For example, the experimental instance of Figure 7 used the NJMC Web server access log between January 01, 2004 and February 19, 2004 as a training data set, and the access log between February 19, 2004 and March 4, 2004 as a test data set. This experimental design reflects the fact that a recommendation for a current active session is based on the past session data. The training data set of the instance contains a total of 5,453 session records and its average session length is 7.088. Its test data set contains a total of 939 session records and its average session length is 8.368, which is a little bit longer than the length of the training data probably due to the small size of the test data set. As we increase the size of a data set, its average session length decreases, and vice versa. Also as we changed the size of the test set with the size of the training set fixed, the performance of SAM over the ones of the individual models is consistent in order.

The models (the individual models plus SAMs in different combinations of the individual models) are evaluated also with different parameter values (of window size, minimum confidence and minimum support, etc) because these parameters also affect the performance of the models. With any given context, SAM will be constructed with the individual models after a learning process. The performance of SAM is better than, at least is equal to, the ones of other models in recall and the F measure while SAM keeps the loss of precision at minimum over the model with the highest precision. As a part of the learning process, the performances of all the other possible SAMs are also shown for comparison in Figure 7.

We have tested about hundred trials with different combinations of data set and parameters. All the tests support the mathematical proof presented in the section 3: the recall and the F measure of SAM are always greater than the ones of the individual models, and its precision loss is minimum when the individual models are applied in their precision order. For this instance, MSAD applying MM, SAR, AR, and a default model in that order is the best performing SAM. The default model is the last model to be used when the other individual models do not cover the active session. The default model recommends pages (aka., consequents or actions) in the order of their frequency from a whole data set. Because it doesn?t use an antecedent at all, its performance is not expected to be as good as the other individual models [1][17]. The precision of MM is the highest while its recall is almost the lowest.

It shows that SAR takes a position between MM and AR.

5. Related Work  Gundiz and Ozsu [13] built clusters, inside which trees are constructed by using sequential association rules, to predict Web pages. Zuckerman et al. [31] built hybrid models that combine variants of Markov models based on the time and/or structural sequences of pages. Based on these hybrid Markov models, they created a hybrid model that selectively chooses a best performing model at a prediction point. Nakagawa and Mobasher [22] also proposed a hybrid model utilizing the site structure and the degree of local hyperlink connectivity. The model selectively uses MM or AR based on the hyperlink connectivity measure of a page, which affects the individual models? precision. These hybrid models apply only one model at a prediction point so that their performance increase is at best marginal. Also the adoption of the structure information may limit the extension of the models into other domains: for example, the predictions of a service order [9], editing commands in      Microsoft Word [10], and different alarms in a telephone switch [10].

Recall: All Kth order, minConf=0, minSup=0, Win=2; M=MM, S=SAR, A=AR, D=default   0.02  0.04  0.06  0.08  0.1  0.12  0.14  M M  S A  R  A R  D E  FA U  LT  M S  A D  M A  S D  S M  A D  S A  M D  A M  S D  A S  M D  Models  R ec  al l  top 2  top 4  top 6  top 8  top 10  top 12  top 14  top 16  top 18  top 20  Precision: All Kth order, minConf=0, minSup=0, Win=2; M=MM, S=SAR, A=AR, D=default   0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  M M  S A  R  A R  D E  FA U  LT  M S  A D  M A  S D  S M  A D  S A  M D  A M  S D  A S  M D  Models  P re  ci si  on  top 2  top 4  top 6  top 8  top 10  top 12  top 14  top 16  top 18  top 20  F measure: All Kth order, minConf=0, minSup=0, Win=2; M=MM, S=SAR, A=AR, D=default   0.02  0.04  0.06  0.08  0.1  0.12  0.14  0.16  M M  S A  R  A R  D E  FA U  LT  M S  A D  M A  S D  S M  A D  S A  M D  A M  S D  A S  M D  Models  F va  lu e  top 2  top 4  top 6  top 8  top 10  top 12  top 14  top 16  top 18  top 20  Figure 7. The performance of the models over top N  6. Conclusion  Due to its scalability, CCF recommendation has received much attention as a way of doing CF in Web  Recommendation. Although several prediction models have been adopted for Web recommendation, they have shown strengths and weaknesses in their performance.

Some hybrid models also have limitations in their ability to increase their performance because they primarily focused on precision and used only one model at each prediction point. We propose a new hybrid model to increase the CCF recommendation performance, especially recall and the F value. This is important in EC, e.g., cross-selling, where recall counts more. When we evaluated the proposed model over different TOP N values, the proposed model shows the highest recall and F value and a good precision comparable to the individual models with higher precision. The order of the individual models should be set through a learning process since some parameters, i.e., minimum support and minimum confidence, may affect the performance of the individual models.

This paper?s main contribution is that it shows a way of increasing recommendation performance by combining different types of models sequentially, without any processing performance issue because of its online real- time reference to lookup tables that are built offline. The proposed model is scalable to include other individual models, e.g., a selective Markov model [9], together with or in place of a regular Markov model.

7. Acknowledgments  This work is supported in part by NSF grants, DUE- 0226075, DUE-0434998. The first author thanks Nabil Adam for providing the log data of CIMIC and NJMC.

8. References  [1] Ahmad M. Ahmad Wasfi (1999). Collecting User Access Patterns for Building User Profiles and Collaborative Filtering. ACM IUI 99 Redondo Beach CA USA, pages 57-64.

[2] Corin R. Anderson (2002), Pedro Domingos, and Daniel S.

Weld. Relational Markov Models and their Application to Adaptive Web Navigation. ACM SIGKDD, Edmonton, Alberta, Canada. 2002, pages 143 - 152.

[3] Rakesh Agrawal, Tomas Imielinski, and Arun Swami (1993). Mining Association Rules between Sets of Items in Large Databases. Proceedings of the 1993 ACM SIGMOD Conference. Washington DC, USA, May 1993, pages 207- 216.

[4] A. Banerjee and J. Ghosh (2001). Clickstream clustering using weighted longest common subsequences. In Proceedings of the Web Mining Workshop at the 1st SIAM Conference on Data Mining, Chicago, April 2001, pages 33-40.

[5] Daniel Billsus and Michael J Pazzani (1998). Learning Collaborative Information Filters. Proc. 15th International Conf. on Machine Learning. 1998, pages 46-54.

[6] Mao Chen, Andrea S. LaPaugh, Jaswinder Pal Singh (2002). Predicting Category Accesses for a User in a Structured Information Space, ACM SIGIR'02, pages 65- 72.

[7] Robert Cooley, Bamshad Mobasher, and Jaideep Srivastava. Data Preparation for Mining World Wide Web Browsing Patterns, Knowledge and Information Systems, Volume 1, No. 1, 1999.

[8] Ayhan Demiriz (2002). Analyzing Service Order Data using Association Mining. Technical paper, Information Technology, Verizon Inc.2002.

[9] M. Deshpande and G. Karypis (2001). Selective Markov models for predicting Web-page accesses. First SIAM 2001.

[10] M. Deshpande and G. Karypis (2004). Item-Based Top-N Recommendation Algorithms. ACM Transactions on Information Systems, Vol. 22, 1, January 2004, Pages 143- 177.

[11] Yongjian Fu, Kanwalpreet Sandhu, and Ming-Yi Shih (2000). Clustering of Web Users Based on Access Patterns.

Technical Paper, Computer Science Department, University of Missouri-Rolla, 2000.

[12] Enrique Frias-Martinez and Vijay Karamcheti (2002). A Prediction Model for User Access Sequences. Proc.

WEBKDD Workshop: Web Mining for Usage Patterns and User Profiles.

[13] Sule Gundiz and M. Tamer Ozsu. A Web Page Prediction Model Based on Click-Stream Tree Representation of User Behavior. SIGKDD?03, August 24-27, 2003, Washington, DC, USA.

[14] Weiyang Lin, Sergio A. Alvarez, and Carolina Ruiz (2000).

Collaborative Recommendation via Adaptive Association Rule Mining. Technical Paper, Dept. of Computer Science, Worcester Polytechnic Institute, 2000.

[15] D. Lewis and W. A. Gale (1994). A sequential algorithm for training text classifiers. In Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, London, Springer-Verlag, pages 3-12.

[16] Greg Linden, Brent Smith, and Jeremy York (2003).

Amazon.com Recommendations: Item-to-Item Collaborative Filtering. IEEE Internet Computing, January- February 2003, pages 76-80.

[17] Ian Tian Yi Li, Qiang Yang, and Ke Wang (2001).

Classification Pruning for Web-request Prediction. In Poster Proceedings of the 10th World Wide Web Conference (WWW10), May 2-4, 2001. Hong Kong, China.

[18] Bamshad Mobasher (2004). Web Usage Mining and Recommendation, Practical Handbook of Internet Computing, Munindar P. Singh (ed.), CRC Press, forthcoming in 2004  [19] Bamshad Mobasher, Rober Cooley, and Jaideep Srivastava (2000). Automatic Recommendation Based on Web Usage Mining, Communication of the ACM, August 2000, 43(8):142-151.

[20] Bamshad Mobasher, Honghua Dai, Tao Luo, Miki Nakagawa (2001). Effective Recommendation Based on Association Rule Discovery from Web Usage Data, WIDM 2001, ACM 2001, pages 9-15.

[21] Bamshad Mobasher, Honghua Dai, Tao Luo, Miki Nakagawa (2002). Using Sequential and Non-Sequential Patterns in Predictive Web Usage Mining Tasks. In Mining (ICDM2002), Maebashi City, Japan, December 2002, pages 669-672.

[22] Miki Nakagawa, Bamshad Mobasher (2003). A Hybrid Web Recommendation Model Based on Site Connectivity.

WebKDD Workshop 2003, Washington USA, August 28, 2003, pages 59-70.

[23] A. Nanopoulos, D. Kastsaros, Y. Manolopoulos (2001).

Effective Prediction of Web-user Accesses: A Data Mining Approach, WEBKDD'01, 2001.

[24] J. Pitkow and P. Pirolli (1999). Mining longest repeating subsequences to Predict WWW Surfing. In Proceedings of the 1999 USENIX Annual Technical Conference, 1999, pages 139-150.

[25] C. J. van Rijsbergen (1979). Information Retrieval.

Butterworths, London, second edition, 1979.

[26] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. Analysis of Recommendation Algorithms for E- Commerce. ACM EC?00 October 17-20, 2000, Minneapolis, Minnesota. USA.

[27] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl (2001). Item-based Collaborative Filtering Recommendation Algorithms. The Proceedings of WWW conference, May 1-5, 2001, Hong Kong. Pages 285-295.

[28] Z. Su, Q. Yang, H.J. Zhang (2000). A prediction system for multimedia pre-fetching in Internet. In Proceedings of the ACM Multimedia Conference 2000, 2000.

[29] Joonhee Yoo, and Michael Bieber (2000). "Towards a Relationship Navigation Analysis," Proceedings of the 33th Press, Washington, D.C., January 2000.

[30] Tak. W. Yan, Matthew Jacobsen, Hector Garcia-Molina, and Umeshwar Dayal (1996). From User Access Patterns to Dynamic Hypertext Linking, Fifth International World Wide Web Conference, May 6-10, 1996, Paris, France, pages 1007-1014.

[31] I. Zuckerman, D.W. Albrecht, A.E. Nicholson (1999).

Predicting Users' Request on the WWW. In Proceedings of pages 275-284.

[32] Jianhan Zhu, Jun Hong, John G. Hughes (2002). Using Markov Models for Web Site Link Prediction. ACM HT?02. June 11-15, 2002, College Park, Maryland, USA, pages 169-170.

