Strong Key-Exposure Resilient Auditing for Secure Cloud Storage

Abstract? Key exposure is one serious security problem for cloud storage auditing. In order to deal with this problem, cloud storage auditing scheme with key-exposure resilience has been proposed. However, in such a scheme, the malicious cloud might still forge valid authenticators later than the key-exposure time period if it obtains the current secret key of data owner.

In this paper, we innovatively propose a paradigm named strong key-exposure resilient auditing for secure cloud storage, in which the security of cloud storage auditing not only earlier than but also later than the key exposure can be preserved.

We formalize the definition and the security model of this new kind of cloud storage auditing and design a concrete scheme.

In our proposed scheme, the key exposure in one time period doesn?t affect the security of cloud storage auditing in other time periods. The rigorous security proof and the experimental results demonstrate that our proposed scheme achieves desirable security and efficiency.

Index Terms? Cloud computing, cloud storage auditing, data integrity, key exposure.



I. INTRODUCTION  NOWADAYS, cloud storage is becoming one of the mostattractive choices for individuals and enterprises to store their large scale of data. It can avoid committing large capital of users for purchasing and managing hardware and software.

Although the benefits of cloud storage are tremendous, security concerns become significant challenges for cloud storage. One major concern on cloud storage security is about the integrity of the data stored in cloud. Because clients lose the control of their data stored in cloud and data loss might happen in cloud storage, it is natural for clients to doubt whether their data are correctly stored in cloud or not. Cloud storage auditing, as one effective security technique, is proposed to ensure the integrity of the data stored in cloud.

Many cloud storage auditing schemes have been proposed up to now [1]?[13]. These schemes consider several different aspects of cloud storage auditing such as the data dynamic  Manuscript received September 14, 2016; revised January 17, 2017 and March 18, 2017; accepted April 12, 2017. Date of publication April 18, 2017; date of current version May 10, 2017. This work was supported in part by the National Natural Science Foundation of China under Grant 61572267, Grant 61272425, and Grant 61402245, in part by the Open Project of Co-Innovation Center for Information Supply and Assurance Technology, Anhui University, and in part by PAPD and CICAEET. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Shouhuai Xu. (Corresponding author: Jia Yu.)  J. Yu is with the College of Computer Science and Technology, Qingdao University, Qingdao 266071, China (e-mail: qduyujia@gmail.com).

H. Wang is with the Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, Nangjing University of Posts and Telecommunications, Nanjing 210023, China (e-mail: wanghuaqun@aliyun.com).

Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.

update [5], [6], the privacy protection of user?s data [7], [8], the data sharing among multiple clients [9], [10] and the multicopies of cloud data [11], [12]. Key-exposure resilience, as another important aspect, has been proposed recently [13].

Indeed, the secret key might be exposed due to the weak security sense and/or the low security settings of the client.

Once a malicious cloud gets the client?s secret key for cloud storage auditing, it can hide the data loss incidents by forging the authenticators of fake data. As the same reason, it even can discard the client?s rarely accessed data for saving the storage space without being found out by cloud storage auditing.

In [13], a key update technique based on binary tree structure is used to protect the security of authenticators generated in time periods earlier than the key exposure. As a result, the cloud storage auditing scheme in [13], to some extent, can deal with the key exposure problem.

However, in some cases, the key exposure problem is not fully solved in the scheme [13] due to the following reason.

When the key exposure happens, it often cannot be found out at once. The key exposure might be difficult to be found out because the attacker might stop intrusion at once when it gets the client?s secret key. So it is common that there is a long time span crossing multiple time periods between key exposure and its detection. The key exposure might be detected only when the user finds the valid authenticators are not generated by himself. At that time, the user has to revoke the old pair of public key and secret key, and regenerate a new pair. We give an example to show this problem in Fig. 1.

Suppose the hacker has appropriated the client?s secret key during session te but the key exposure has not been detected at that time. The attacker can update the exposed secret key, as same as the client does, to generate the secret keys for time periods te, . . . , td until key exposure is found out during time period td . This means that the malicious cloud trading with this hacker can modify even delete the client?s data uploaded during time periods te, . . . , td without worrying about being found out. It can generate the authenticators for fake data to pass the cloud storage auditing using the updated secret keys.

It is a natural problem of how to protect the security of the cloud storage auditing during the time periods not only earlier than but also later than the key exposure.

A. Contribution  The contribution of this paper can be summarized as follows:  (1) We investigate how to preserve the security of cloud storage auditing scheme in any time period other than the key-exposure time period when the key exposure happens.

See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Fig. 1. The security problem between key exposure and its intrusion.

We propose a paradigm named strong key-exposure resilient auditing as a practical solution for this problem in this paper.

(2) We design a concrete strong key-exposure resilient auditing scheme for secure cloud storage. A novel and efficient key update technique is used in the designed scheme. In our detailed construction, the Third Party Auditor (TPA) generates an update message from his secret key in each time period, and then sends it to the client. The client updates his signing secret key based on his private key and the update message from the TPA. This method makes the malicious cloud unable to obtain the signing secret keys in unexposed time periods.

Different from [13], the lifetime of the file stored in cloud does not need to be fixed initially. So it can support key updates for unlimited time periods.

(3) We formalize the definition and the security model of this new paradigm. In the security model, we consider the most powerful adversary who can query the secret keys of the client in all except one unexposed time period. We also prove the security of our scheme in the formalized security model and justify its performance by concrete implementation.

B. Related Work  In recent years, a lot of studies on cloud security, such as searching over encrypted cloud data [14]?[16] and checking the integrity of cloud data [1]?[13], have been done. The notion of Provable Data Possession (PDP) was firstly pro- posed by Ateniese et al. [17] for ensuring data possession on untrusted servers. This scheme checked the integrity of outsourced data by the techniques of random sample and homomorphic linear authenticators. Juels and Kaliski [18] explored the model named as Proof of Retrievability (PoR) which can ensure both possession and retrievability of the files on untrusted servers. They used the techniques of error- correcting codes and spot-checking to construct the PoR scheme. Shacham and Waters [19] provided an improved PoR model with stateless verification. They proposed a private verification scheme based on pseudorandom functions and a public verification scheme based on BLS signature scheme.

In [20], Dodis et al. studied on different variants of the existed PoR work. In [7], Wang et al. integrated the HLA with random masking technique to make the auditor unable to infer the original data from auditing process. Shen et al. [21] proposed a light-weight and privacy-preserving secure cloud auditing scheme for group users via the third party medium .

The PDP supporting for data dynamic operations was firstly researched in [22]. Wang et al. [5] proposed another cloud storage auditing scheme that supported data dynamics  by utilizing the BLS-based HLA and Merkle Hash Tree.

Erway et al. [23] proposed a PDP scheme to support data dynamics using a skip list-based structure. Zhu et al. [24] proposed a cooperative provable data possession scheme.

Yang and Jia [8] considered the dynamic operation and privacy-preserving property in cloud storage auditing scheme.

Cash et al. [25] proposed a dynamic PoR scheme using oblivious ram technique. Some other important researches about dynamic cloud storage auditing [26], [27] have been done. The problem of user revocation in shared cloud data auditing was considered in [10]. Identity-based cloud storage auditing schemes were proposed to simplify key management process in [28] and [29]. Multiple-replica cloud storage audit- ing schemes were proposed in [11] and [12]. Identity privacy and identity traceability for shared cloud storage were studied in [30] and [31].

Recently, key exposure problem and its verifiable outsourc- ing of key updates for cloud storage auditing have been considered in [13] and [32], respectively. In [13], the client?s secret keys are updated in different time periods. The key exposure cannot affect the security of authenticators generated before the key-exposure time period. However, as we have analyzed, it cannot fully solve the key exposure problem in some cases, i.e., the security of authenticators generated later than the key-exposure time period is still unable to preserve.

Therefore, the contributions of this paper can be viewed as the further research on the key exposure problem in cloud storage auditing.

C. Organization  The rest paper is organized as follows: In Section II, we introduce system model, definition, security model and preliminaries. Then, we give a detailed description of the proposed scheme in Section III. The security analysis and the efficiency evaluation are given in Section IV. At last, we conclude the paper in Section V.



II. FORMULATION AND PRELIMINARIES  A. System Model  The system comprises three parties: the cloud, the client and the third party auditor (TPA). The cloud offers storage services to the client. The client uploads his files along with the corresponding authenticators to the cloud, and then deletes these data from his storage space. The client can retrieve them from the cloud when he needs them.The TPA is a powerful party and is in charge of two important tasks. The first is to    YU AND WANG: STRONG KEY-EXPOSURE RESILIENT AUDITING FOR SECURE CLOUD STORAGE 1933  Fig. 2. The proposed system model.

provide auditing service, i.e., periodically check the integrity of the files stored in cloud for the client. The second is to help the client update his secret keys by providing update messages to the client in different time periods. As same as most of public integrity auditing schemes, the TPA is honest for integrity auditing on behalf of cloud users. However, it is not fully trustworthy for key update in our system model. The system model is shown in Fig. 2. Assume that one file F stored in cloud is divided into n blocks mi (i = 1, . . . , n). Different from the system model in [13], the lifetime of file F in our system model does not need to be fixed initially. It means the total number of time periods in unbounded, which is more close to the reality.

B. Definition and Security Model  Definition 1: A strong key-exposure resilient auditing scheme for secure cloud storage consists of six algorithms such that:  1) System setup algorithm SysSetup: This algorithm is run by the client. It takes as input a security parameter k, and generates a system public key PK, the TPA?s secret key SKT P A and the client?s private key SKc.

2) Update message generation algorithm UMGen: This algorithm is run by the TPA at the beginning of each time period. It takes as input the public key PK, the cur- rent time period t and the TPA?s secret key SKT P A , and generates an update message ?t .

3) Client key update algorithm CKeyUpdate: This algo- rithm is run by the client at the beginning of each time period. It takes as input the public key PK, the current time period t, the update message ?t and the client?s private key SKc, and generates the signing secret key SKt for time period t.

4) Authenticator generation algorithm AuthGen: This algorithm is run by the client. It takes as input the public key PK, the current time period t, the client?s signing secret key SKt and a file F, and generates a set of authenticators ? for F in time period t.

5) Proof generation algorithm ProofGen: This algorithm is run by the cloud. It takes as input the public key PK, a time period t, a challenge Chal, a file F and a set of  authenticators ?, and generates a proof P that is used to prove the cloud stores F correctly. In this algorithm, the (t, Chal) pair is issued by the TPA, and then used by the cloud as input.

6) Proof verifying algorithm ProofVerify: This algorithm is run by the TPA. It takes as input the public key PK, a time period t, a challenge Chal and a proof P, and returns ?true? if the verification passed; or ?false?, otherwise.

Note that the client?s secret information includes two parts.

One is the signing secret key SKt , which is used to generate authenticators in time period t. The other is the private key SKc, which is used to generate the signing key SKt in time period t . In order to formalize the security, we define a game between an adversary A and a challenger C to show how the adversary attacks the security of a strong key-exposure resilient auditing scheme. In this game, we consider the most powerful adversary who can query the secret keys of the client in all except one unexposed time period. This game comprises the following four phases.

1) Setup phase. Initially set time period t=0. C runs SysSetup algorithm to generate the public key PK, the TPA?s secret key SKT P A and the client?s secret key SKc. C sends PK to A and holds SKc himself at this phase.

2) Query phase. C runs key update algorithm to generate the client?s signing key SKt in time period t .



I. Authenticator queries. A adaptively selects a series of blocks m1, . . . , mn , and submits them to C to query the corresponding authenticators in time period t. The chal- lenger computes and returns the corresponding authen- ticators for mi (i = 1, . . . , n) in this time period.



II. Secret key queries. A can select to query the secret key of the client in time period t. If he does, C sends the client?s ptivate key SKc and signing key SKt in time period t to A.

At the end of each time period, A can select to stay in this phase or go to the Challenge phase.

3) Challenge phase. C selects a time period t? in which A does not make the secret key queries. C sends A a challenge Chal= {i, vi }i?I (where I = {s1, s2, . . . , sc}, 1 ? sl ? n, 1 ? l ? c , 1 ? c ? n ). It also requests A to provide a proof of possession P for file F = (m1, . . . , mn) under Chal for the blocks ms1, . . . , msc in time period t?.

4) Forgery phase. A outputs a proof of possession P for the blocks indicated by Chal in the time period t?, and returns P. If ProofVerify (PK, t*, Chal, P)=?true?, then A wins in above game.

The above security model captures that an adversary cannot provide a valid proof for a time period in which the secret key is not exposed without owning all the blocks corresponding to a given challenge, if it cannot guess all the missing blocks.

In each time period, the adversary can query the authenticators of all the blocks. The adversary can also query the secret keys in all except the challenged time period. The goal of the adversary is to construct a valid proof of possession P for the blocks indicated by Chal in the time period t?. The following     definition shows that there exists a knowledge extractor that can extract the challenged file blocks whenever the adversary can produce valid proof of possession P in the time period t?.

Definition 2: We say a cloud storage auditing scheme is strong key-exposure resilient if the following condition sat- isfies: whenever an adversary in above described game can cause the challenger to accept its proof with non-negligible probability, there is a knowledge extractor that can extract all the challenged file blocks except possibly with negligible probability.

The following definition describes the detectability for the auditing scheme, which shows the cloud should maintain the blocks that are not challenged with high probability.

Definition 3: We say a cloud storage auditing scheme is (?, ?) detectable if, given a fraction ? of corrupted blocks, the probability that the corrupted blocks are detected is at least ?.

In above system model, the TPA generates an update message to help the client update his secret key in each time period. Another security requirement is that the TPA is not able to forge any authenticator through his secret key and the generated update messages. We give the following security definition to capture this requirement.

Definition 4: We say the authenticator generation is secure if the TPA cannot forge the authenticator for any block through his secret key and the update messages he generates.

The TPA might incorrectly execute the update key gener- ation algorithm. That is, the TPA might provides the client wrong update key due to some reason. In this case, the client should be able to verify the correctness of the update key provided by the TPA.

Definition 5: We say a strong key-exposure resilient audit- ing for secure cloud storage is verifiable if the TPA provides the wrong update key in UMGen algorithm, he cannot pass the verification of our proposed scheme.

C. Preliminaries  1) Bilinear Map: There are two multiplicative cyclic groups G1 and G2, which have the same prime order q. We say a map e? : G1 ? G1 ? G2 is a bilinear map if it satisfies:  1. Bilinearity: For ?g1, g2 ? G1 and ?a, b ? Z?q , e?(ga1 , g  b 2) = e?(g1, g2)ab.

2. Non-degeneracy: e?(g1, g2) ?= 1, where g1, g2 are the generators of G1.

3. Computability: There is an efficient algorithm to compute e?(g1, g2) for g1, g2 ? G1.

2) CDH Problem: Given (g, ga, gb), where g is a generator of multiplicative group G1 with order q, and a, b ? Z?q , compute gab.



III. OUR PROPOSED SCHEME  A. Technique Explanation  One big challenge of designing such a scheme is that the signing secret keys change in different time periods while the public key is unchanged in all of time periods.

We use a new key update technique that is different from that of [13]. In order to achieve the strong key-exposure resilience,  we make the signing secret key in each time period be a multiplication of two parts. Each part is the power of H1(t), where H1 is a hash function and t is the current time period.

One part is the update message generated by the TPA, which is computed through the secret key of the TPA and the current time period. The other part is computed from the secret key of the client and the current time period. The signing secret key in any time period must be jointly generated by the client and the TPA. This technique can support both the provable security and the efficient key update. As a result, if the attacker intrudes the client in one time period, he cannot obtain the client?s signing secret keys in other time periods without the secret key of the TPA. The designed authenticator can support the structure of signing secret keys and the property of blockless verifiability. Because the time period as an important factor is integrated into the computation of authenticators, the authenticators of the same file blocks generated in different time periods are different. The ProofVerify algorithm can verify whether the proof corresponding to the declared time period is indeed valid or not.

B. Description of Our Scheme  Let e? : G1?G1 ? G2 be a bilinear map, where G1 and G2 are two multiplicative groups with order q. Let g and u be two generators of group G1, and H1 : {0, 1}? ? G1, H2 : {0, 1}?? G1 ? G1 be two cryptographic hash functions. Generally, there is a digital signature SSig that is used to ensure the integrity of the file identifier name in previous cloud storage auditing schemes [5], [7], [13]. In this paper, we also use the same digital signature SSig to ensure the integrity of the file identifier name and the time period t . We assume (spk, ssk) is a pair of public key and secret key corresponding to signature SSig, the client has held the secret key ssk, and the public key spk has been published. Such an assumption can simplify our scheme description thereafter.

Similar to previous cloud storage auditing schemes [2], [4], [5], [7], [8], [13], the client firstly divides one file F stored on the cloud into a set of n ordered blocks m1, m2, . . . , mn , where mi ? Z?q in our scheme. In time period t , the signing secret key of the client is SKt ? G1. The authenticator for each block mi in time period t is generated as follows. The client selects a random r?Z?q and computes R = gr . He computes the authenticator for each block mi in time period t as ?i = H2(t||i ||name, R)r ? urmi ? SKt , where name is the name of the file F.

1) SysSetup algorithm a) The client randomly selects SKc ? Z?q as his  private key. The client?s public key is P Kc = gS Kc .

b) The client randomly selects SKT P A ? Z?q , and  sends it to the TPA as the TPA?s secret key. The TPA?s public key is P KT P A = gS KT P A .

c) Set the system public key P K = (g, u, P KT P A, P Kc, spk).

2) UMGen algorithm a) At the beginning of time period t, the TPA com-  putes the update message ?t = H1(t)S KT P A accord- ing to his secret key SKT P A.

YU AND WANG: STRONG KEY-EXPOSURE RESILIENT AUDITING FOR SECURE CLOUD STORAGE 1935  b) The TPA sends the update message ?t to the client.

c) The client can verify whether the update message  is valid or not by the following equation  e?(g, ?t ) = e?(P KT P A, H1(t)).

3) CKeyUpdate algorithm When the client gets the update message ?t from the  TPA at the beginning of time period t, he computes SKt = H1(t)S Kc ? ?t as the signing secret key in time period t.

4) AuthGen algorithm When the client wants to upload a file F = {mi}  (1 ? i ? n) to the cloud in time period t, he does as follows:  a) The client selects r?R Z?q , and then computes R = gr .

b) Then the client computes the authenticators ?i = H2(t||i ||name, R)r ? urmi ? SKt , where name is the name of the file F.

c) The client uploads the file tag tag = name ||t||SSigssk(name||t) and the set of authenticators ? = {t, R, ?1, . . . , ?n} along with file F to the cloud.

5) ProofGen algorithm  a) The TPA first verifies the validity of the file tag by checking whether SSigssk(name||t) is a valid signature using spk. If it is, then the TPA selects a c-element subset I = {s1, s2, . . . , sc} of set [1, n] as the index of the blocks to be checked.

b) For each i ? I , the TPA selects random values vi (||vi || < ||q||), and sends the challenge {i, vi }i?I to the cloud.

c) After the cloud receives the challenge {i, vi }i?I , he computes an aggregate authenticator ? =?  i?I ?i vi . He also computes ? = ?  i?I mivi .

d) The cloud sends P = (t, R, ?, ?) to the TPA as  his reply.

6) ProofVerify algorithm When the TPA receives the proof P, he verifies  whether the following equation holds:  e?(g, ? ) = e?(R, ?  i?I H2(t||i ||name, R) vi ? u?)  ?e?(P Kc ? P KT P A, H1(t) ?  i?I vi ).

If it holds, then return ?true?; Otherwise, return ?false?.



IV. SECURITY AND PERFORMANCE  A. Security Analysis  Theorem 1 (Correctness): For one random challenge {i, vi }i?I and one valid proof P = (t, R, ?, ?), the ProofVerify algorithm always returns ?true?.

Proof: It is because the following equations hold:  e?(g, ? ) = e?(g, ?  i?I ?i vi )  = e?(g, ?  i?I (H2(t||i ||name, R) r ? urmi ? SKt )vi )  = e?(g, ?  i?I (H2(t||i ||name, R) r ? urmi ? H1(t)S Kc  ??t )vi ) = e?(g, (  ?  i?I H2(t||i ||name, R) vi ? u  ? i?I vi mi )r  ?H1(t)(S Kc+S KT P A) ?  i?I vi )  = e?(g, ( ?  i?I H2(t||i ||name, R) vi ? u?)r )  ?e?(g, H1(t)(S Kc+S KT P A) ?  i?I vi )  = e?(R, ?  i?I H2(t||i ||name, R) vi ? u?)  ?e?(P Kc ? P KT P A, H1(t) ?  i?I vi )  Theorem 2 (Strong key-exposure resilience): If the CDH problem in G1 is hard, then our proposed auditing scheme is strong key-exposure resilient.

Proof: We define a series of games, and analyze the difference in adversary behavior between successive games.

Game 0: Game 0 is the game defined in Section II.

Game 1: Game 1 is the same as Game 0, with only one  difference. The challenger keeps a list of all signed tags he generates. The challenger will abort when the adversary submits one valid tag generated by SSig signature algorithm but not signed by the challenger.

Analysis: If the adversary makes the challenger abort in Game 1, it is easy to use the adversary to construct an attacker to break the SSig signature scheme. From now on, we can assure that name and t in the interactions with the adversary are all generated by the challenger.

Game 2: Game 2 is the same as Game 1, with only one difference. The challenger keeps a list of his responses to the adversary?s authenticator queries. If the adversary succeeds but R in its proof P is different from the real R in the list of authenticators that the challenger has kept, then the challenger will abort.

Analysis: We will show if the adversary can make the challenger abort in Game 2, we can construct a simulator to solve the CDH problem with non-negligible probability.

The simulator acts like the challenger in Game 1, with the following differences:  Firstly, the challenger C is given a CDH challenge (g, X = ga, Y = gb). The challenger C will compute gab by running the adversary A. The challenger C selects (spk, ssk) as the public key and the secret key to generate a signature for file name and time period. Assume that the adversary A makes qk secret key queries and qs authenticator queries.

1) Setup Phase: The challenger C randomly selects SKc ? Z?q , and sets P KT P A = X , P Kc = gS Kc . The challenger C randomly selects ? ? Z?q , and sets u = g?. Finally, C sends the public key P K = (g, u, P KT P A, P Kc, spk) to A.

2) Query Phase: H1 and H2 are viewed as two random ora- cles controlled and stored by the challenger C. The challenger needs to answer the queries for these random oracles from A.

a) H1 oracle query: The challenger C maintains an H1-table to reply A?s queries of H1 oracle. Firstly, C initially sets this table empty. When A queries H1 oracle at < t >, C does as follows.

(1) If H1-table contains a tuple (t, c, ?, h1) for input < t >, then C responds with h1 .

(2) Otherwise, C flips a coin c ? {0, 1} that yields 0 with probability qk+qsqk+qs+1 and 1 with probability  qk+qs+1 .

When c = 0, C selects ??R Z?q , and computes g?. He adds (t, 0, ?, h1 = g?) to H1-table. Otherwise, C selects ??R Z?q , and computes Y ?. He adds (t, 1, ?, h1 = Y ?) to H1-table.

Finally, C responds with h1.

b) H2 oracle query: The challenger C maintains an H2-table to reply A?s queries of H2 oracle. Firstly, C initially sets this table empty. When A queries the oracle H2 at < t||i ||name, R >, C does as follows.

(1) If H2-table contains a tuple (t||i ||name, R, ?, h2) for input < t||i ||name, R >, then C responds with h2.

(2) Otherwise, C selects ??R Z?q , and adds (t||i ||name, R, ?, h2 = g?) to H2-table. C responds with h2.

c) The secret key query: When A queries the secret key in time period t, C retrieves (t, c, ?, h1 = g?) from H1-table (WLOG, assume that A has queries the oracle H1 at < t >).

(1) If c = 1, C aborts (Denote this event by E1).

(2) Otherwise, C computes SKt = X? ? h1S Kc .

Note that SKt = h1S KT P A ? h1S Kc = g?S KT P A ? h1S Kc =  X? ? h1S Kc . Finally, C responds with (SKc, SKt ).

d) Authenticator query: When A queries an authenticator  at < t, mi , i >, C does as follows.

(1) Firstly, C recovers (t, c, ?, h1) from H1-table.

(2) If c = 1, C aborts (Denote it by E2).

(3) Otherwise, C selects r?R Z?q , and then computes R = gr .

C also selects ?i?R G1.

(4) C defines the hash value H2(t||i ||name, R) as  (?i ? X?? ? h1?S Kc)r?1/umi .

Note that  H2(t||i ||name, R)r ? urmi ? SKt = ((?i ? X?? ? h1?S Kc)r?1/umi )r ? urmi ? h1S KT P A ? h1S Kc = ?i ? X?? ? h1?S Kc ? g?S KT P A ? h1S Kc = ?i ? X?? ? (gS KT P A )? = ?i Finally, C responds with (t, R, ?i ).

3) Challenge Phase: The challenger C selects a time period  t? in which A does not make the secret key queries. C sends A a challenge Chal= {i, vi }i?I (where I = {s1, s2, . . . , sc}, 1 ? sl ? n ,1 ? l ? c, 1 ? c ? n) and the time period t?.

It also requests A to provide a proof of possession P of file F = (m1, . . . , mn) under Chal for the blocks ms1, . . . , msc in time period t?.

4) Forgery Phase: Finally, the adversary A outputs a proof P = (t?, R, ?, ?). C recovers (t?, c?, ??, h?1) from H1-table.

(1) If c? = 0, C aborts(Denote it by E3).

(2) Otherwise, if R is different from the real R in the  authenticators set, C recovers (t?||i ||name, R, ??i , h2 = g? ? i )  from H2-table. In this case, h?1 = Y ? ? . If this forgery is valid,  then  e?(g, ? ) = e?(R, ?  i?I H2(t||i ||name, R) vi ? u?)  ?e?(P Kc ? P KT P A, H1(t) ?  i?I vi )  = e?(R, g ?  i?I ??i vi ? g??) ? e?(gS Kc ? X, Y ?? ?  i?I vi )  = e?(g, R??+ ?  i?I ??i vi ) ? e?(g, Y ??S Kc ?  i?I vi )  ?e?(X, Y ?? ?  i?I vi )  So  e?(X, Y ? ? ?  i?I vi ) = e?(g, ? ) ? e?(g, R?(??+ ?  i?I ??i vi ))  ? e?(g, Y ???S Kc ?  i?I vi )  (1) If ?  i?I vi = 0, C aborts(Denote it by E4).

(2) Otherwise, C can compute gab as gab =  (? ? R?(??+ ?  i?I ??i vi ) ? Y ???S Kc ?  i?I vi )(? ? ?  i?I vi ) ?1  .

Probability Analysis: We analyze the probability that C  does not abort in above simulation. From above description, the probability that C does not abort is  Pr[?E1 ? ?E2 ? ?E3 ? ?E4] ? ( qk +qs  qk +qs + 1 ) qk ? ( qk + qs  qk + qs + 1 ) qs ? 1  qk + qs + 1 ? q ? 1  q  = ( qk + qs qk + qs + 1 )  qk+qs ? 1 qk + qs + 1 ?  q ? 1 q  ? q ? 1 e ? q ? (qk + qs + 1)  Here, qk is the number of secret queries and qs is the number of authenticator queries made by A.

If the adversary succeeds but R in its proof P is different from the real R in the list of authenticators, C can solve the CDH problem in G1 with no-negligible probability.

Game 3: Game 3 is the same as Game 2, with only one difference. The challenger C keeps a list of his responses to authenticator queries from the adversary. The challenger C observes each instance in this list. If in any instance the adversary succeeds but the adversary?s aggregate authenticator ? is not equal to ? = ?i?I ?i vi , then the challenger will abort.

Analysis: Suppose the file that makes the challenger abort in time period t is composed by m1, . . . , mn . The name of this file is name and that the set of authenticators for this file is ? = {t, R, ?1, . . . , ?n}. Let the query making the challenger abort be {i, vi }i?I and the proof of the adversary be P = (t, R, ? ?, ??). Let the expected response from the honest prover be P = (t, R, ?, ?). Therefore, the validity of the proof can be verified by the following equation.

e?(g, ? ) = e?(R,?i?I H2(t||i ||name, R)vi ? u?) ? e?(P Kc ? P KT P A, H1(t)  ? i?I vi )  Because the challenger aborts, we can know that ? ? ?= ? and ? ? can pass the following verification equation i.e., that  e?(g, ? ?) = e?(R,?i?I H2(t||i ||name, R)vi ? u? ? ) ? e?(P Kc ?  P KT P A, H1(t) ?  i?I vi ).

Denote 	? = ?? ? ?. Obviously, 	? ?= 0, otherwise,  it means ? ? = ? , which contradicts the assumption. Now we construct a simulator to solve the CDH problem.

YU AND WANG: STRONG KEY-EXPOSURE RESILIENT AUDITING FOR SECURE CLOUD STORAGE 1937  Input a tuple (g, ga ? , v) to the simulator; the simulator  finally outputs va ? . The simulator plays the role of the chal-  lenger in Game 2, with the following differences: In Setup phase, the simulator sets u = g?v? for some  ?, ??R Z?q . The simulator generates the secret keys of all the time periods like the real circumstance.

H2 is viewed as a random oracle controlled and stored by the simulator. When the adversary queries H2 ora- cle at a point < t||i ||name, R >, the simulator checks whether < t||i ||name, R > has appeared in one tuple < t||i ||name, R, h, ?, ? > of H2 table. If it has, the chal- lenger returns h to the adversary; Otherwise, the simula- tor selects ??R Z?q , computes h = g? , and adds tuple < t||i ||name, R, h, ?, ? > to H2 table. Finally, the simulator returns h to the adversary as the reply.

When the adversary queries the authenticator of one block mi with name name in time period t, the simulator selects ?, ri?R Z?q , computes R = (ga?)? , and sets h = gri /(g?v?)mi .

The probability that H2(t||i ||name, R) has been defined is negligible.

The simulator can compute authenticator  ?i = H2(t||i ||name, R)a?? ? ua??mi ? SKt = (gri /(g?v?)mi )a?? ? (g?v?)a??mi ? SKt = gri a?? ? SKt  Note that the simulator knows SKt because he gener- ates the secret keys of all the time periods at the begin- ning. The simulator adds < t||i ||name, R, h, ri , ? > to H2 table.

If the adversary succeeds in the game by replying a proof P = (t, R, ? ?, ??) in which ? ? is different from the expected ? , we can extract a tuple < t||i ||name, R, h, ri , ? > from H2 table. By dividing the verification equation for the forged ? ? by the verification equation for the expected ? , we can get e?(g, ? ?/?) = e?(R, u	?) = e?(R, (g?v?)	?).

So e?(g, ? ? ? ??1 ? R??	?) = e?((ga?)? , v?	?). We can solve the CDH problem va  ? = (? ? ? ??1 ? R??	?)(??	?)?1 .

Therefore, if there is a non-negligible difference between  the probabilities that the adversary succeeds in Game 2 and Game 3, the constructed simulator can solve the CDH prob- lem. From now on, we know ? must be true in any successful proof.

Game 4: Game 4 is the same as Game 3, with only one difference. The challenger keeps and observes each instance of its responses to authenticator queries with the adversary.

If in any instance the adversary is successful but there exists one adversary?s aggregate message ? is not equal to ? =?  i?I mivi , then the challenger will abort.

Analysis: Suppose Chal = {i, vi }i?I is the query that makes  the challenger abort, and P ? = (t, R?, ? ?, ??) is the proof from the adversary. Let the expected response from the honest prover be P = (t, R, ?, ?). From Game 2 and Game 3, we know R = R? and ? = ? ?. So it can be at most the value ?? is different from ? in P and P ?. Define 	? = ?? ? ?; again, 	? ?= 0. If the adversary can cause the challenger in Game 4 abort, then we can construct a simulator to solve the discrete logarithm problem.

The simulator is given two values g, v ? G1; his goal is to compute x satisfying v = gx . The simulator acts like the challenger in Game 3, with the following differences:  In Setup phase, the simulator sets u = g?v? for some ?, ??R Z?q . The simulator interacts with the adversary until the adversary successes in responding with the aggregate value ?? that is different from the expected aggregate value ?. By the verification equations using ?? and ?, we can get the following equations  e?(R, ?  i?I H2(t||i ||name, R) vi ? u?)  ?e?(P Kc ? P KT P A, H1(t) ?  i?I vi )  = e?(g, ? ) = e?(g, ? ?) = e?(R,  ?  i?I H2(t||i ||name, R) vi ? u??)  ?e?(P Kc ? P KT P A, H1(t) ?  i?I vi ).

So we know u? = u?? ? u	? = 1 ? g	??v	?? = 1 ? v = g??/?  Therefore, if there exists a non-negligible difference between the adversary?s probabilities of success in Game 3 and Game 4, we can construct a simulator to solve the discrete logarithm problem.

As we have analyzed, there is only negligible difference probability between these games. Note that the hardness of the CDH problem implies the hardness of the discrete logarithm problem. If the CDH problem in G1 is hard and the signature scheme SSig used for file tags is existentially unforgeable, the challenger will reject except when the prover responds with correctly computed values in proof P.

Now we will construct a knowledge extractor to extract the whole challenged file blocks ms1, ms2, . . . , msc . By selecting independent coefficients v1, v2, . . . , vc to execute the chal- lenge phase on the same blocks ms1, ms2, . . . , msc for c times, the extractor can collect c independent linear equations in the variables ms1, ms2, . . . , msc . The extractor can extract ms1, ms2 , . . . , msc by solving these equations. This completes the proof of Theorem 2.

Theorem 3 (Detectability): Our proposed auditing scheme is (mn , 1 ? ( n?mn )c) detectable if the cloud stores a file with n blocks including m bad (deleted or modified) blocks, and c blocks are challenged.

Proof: Assume that the cloud stores a file with total n blocks including m bad (deleted or modified) blocks. The number of challenged blocks is c. Thus, the bad blocks can be found out if and only if at least one of the challenged blocks chosen by the TPA matches the bad blocks. We use a discrete random variable X to denote the number of blocks selected by the challenger that matches the block-tag pairs changed by the adversary. We use PX to denote the probability that at least one block chosen by the challenger matches the blocks changed by the adversary. So  PX = P{X ? 1} = 1 ? P{X = 0} = 1 ? n ? m  n  n ? 1 ? m n ? 1 ? ? ? ? ?  n ? c + 1 ? m n ? c + 1     We can get PX ? 1 ? ( n?mn )c. Thus, the proposed auditing scheme is (mn , 1 ? ( n?mn )c) detectable if the cloud stores a file with n blocks including m bad (deleted or modified) blocks, and c blocks are challenged.

Theorem 4: The TPA cannot forge the authenticator for any block through his secret key and the update messages he generates.

Proof: From AuthGen algorithm, we know the computa- tion of any authenticator in time period t requires the secret key SKt . According to the key update of the client, the secret key SKt is determined by two secret keys SKT P A and SKc, that is, SKt = H1(t)S Kc ? ?t = H1(t)S Kc ? H1(t)S KT P A . From the view of the TPA in our scheme, the TPA only knows SKT P A and can only compute the update message ?t . It means the TPA can not compute SKt because it does not know the secret key SKc of the client. Therefore, the TPA cannot forge the authenticator for any block through his secret key and the update messages he generates.

Theorem 5: The proposed strong key-exposure resilient auditing for secure cloud storage is verifiable.

Proof: From UMGen algorithm, we know any incor- rect update key cannot pass the equation e?(g, ?t) = e?(P KT P A, H1(t)). Therefore, this Theorem follows.

B. Performance Analysis  We firstly give numerical analysis of computation and communication overhead of the proposed scheme in main phases, and then evaluate the proposed scheme through several practical experiments.

1) Computation and Communication Overhead: In the phase of key update, the client needs to compute the signing secret key SKt , which costs Ex pG1 + MulG1 , where Ex pG1 denotes the computation of one exponentiation in G1 and MulG1 denotes the computation of one multiplication in G1.

In the phase of challenge generation, the TPA only chooses some random values to construct a challenge message, which costs little computation. In the phase of proof generation, the cloud needs to generate the proof P = (t, R, ?, ?). It costs c ? Ex pG1 +(c?1) ?MulG1 +c ?MulZq +(c?1) ?Sum Zq , where MulZq denotes the computation of one multiplication and Sum Zq denotes the computation of one addition in Zq . In the phase of proof verifying, the cloud needs to verify whether the proof P is valid or not by the verification equation. It costs (c +2) ? Ex pG1 + (c +1) ? MulG1 + (c ?1) ? Sum Zq +3Pair + MulG2 , where Pair denotes the computation of one pairing, and MulG2 denotes the computation of one multiplication in G2.

The communication overhead in our proposed scheme includes the challenge overhead and the proof overhead. The challenge message is composed by c pairs of elements (i, vi ).

So the challenge overhead is c ? (|n| + |q|), where |n| is the length of an index and |q| is the length of an element in Zq . The overhead of proof message (t, R, ?, ?) is about 2|G1|+ |q|, where |G1| is the length of an element in G1(The size of t is negligible compared with G1 and q).

2) Experimental Results: With the help of the Pairing-Based Cryptography (PBC) library [33], we evaluate the proposed  Fig. 3. The key update time in our proposed scheme and the scheme. [13]  scheme in several experiments. We run these experiments on a Linux server with Intel processor running at 2.70 GHz and 4 GB memory. We choose a bilinear map that uses a super- singular elliptic curve to achieve the fast pairing operations.

The base field of this curve is 160 bits, the size of an element in Z?q is 20 bytes, and the size of an element in group G1 is 128 bytes. In our experiments, the data file is set to 20M, which consists of 1,000,000 blocks. In order to compare the efficiency of our proposed scheme with that of the scheme [13] which uses a full binary tree with depth 2, we consider the current time period varying from 0 to 14.

In our proposed scheme, the time for the client to update a secret key is independent of the time period because it needs one exponentiation and one multiplication in G1 in any time period. In contrast, the key update time of the client is relevant to the time period in scheme [13]. We compare the key update time between the both schemes in Fig.3. In the scheme [13], the key update time is related to the depth of the node corresponding to the current time period in the full binary tree. When the node is the internal node, the key update time is about 12.6ms; when the node is the leaf node, the key update time is nearly 0ms. In our proposed scheme, the key update time is about 5.8ms in all time periods. It means the client can update the signing secret key using the same computational resource in each time period. The average update cost of our proposed scheme is the same as that in the scheme [13].

Therefore, our proposed scheme achieves stronger security without decreasing the efficiency of key updates for the client.

In addition, our proposed scheme supports key updates for unlimited time periods. However, the lifetime of the file stored in cloud must be known and fixed initially in the scheme [13].

Thus, the scheme [13] can only support key updates for a fixed T time periods. When T time periods are over, the cloud storage auditing cannot work any longer.

With the different number of challenged blocks, we demon- strate the time of different auditing processes including the challenge generation process, the proof generation process, and the proof verification process through the experiments in Fig.4. In our experiment, the number of challenged blocks varies from 100 to 1,000. From Fig.4, we can know the challenge generation process spends the least time, which is 0.26s at most; the proof generation process spends a little more time, varying from 0.18s to 1.79s; the proof verification process spends the most time, varying from 0.22s to 2.05s.

YU AND WANG: STRONG KEY-EXPOSURE RESILIENT AUDITING FOR SECURE CLOUD STORAGE 1939  Fig. 4. The time of auditing processes with different number of challenged blocks.

Fig. 5. The challenge overhead with different number of challenged blocks.

Fig. 6. The proof overhead with different number of challenged blocks.

In our proposed scheme, the communication overhead consists of the challenge overhead and the proof overhead.

As same as most of cloud storage auditing schemes, the chal- lenge overheads of the proposed scheme and the scheme [13] are both Chal= {i, vi }i?I , where i is used to determine which blocks will be checked and vi is used to mix the challenged blocks. Therefore, the proposed scheme and the scheme [13] have the same challenge overhead. Because the challenge overhead is c ? (|n| + |q|), it has a linear relationship with the number c of challenged blocks. In Fig.5, when the number of checked blocks varies from 100 to 1,000, the size of the challenge message varies from 2.29KB to 22.89KB. Because the size of the proof message is 2|G1|+ |q|, it is independent of the time period. From Fig.6, we can see that the size of the proof message keeps about 148B in all the time periods, which is much smaller than that in the scheme [13].



V. CONCLUSION  In this paper, we further study on how to deal with the key exposure problem in cloud storage auditing. We propose a new paradigm called strong key-exposure resilient auditing scheme for secure cloud storage. In this paradigm, the security of the cloud storage auditing not only earlier than but also later than the key exposure can be preserved. We formalize the definition and the security model of this new kind of cloud storage auditing and design a concrete scheme. The security proof and the experimental results demonstrate that the proposed scheme is secure and efficient.

