

A Novel Water Quantities Allocation Arithmetic in Water Management *  CHEN Xu-sheng  , 1 School of Management, Management Science and  Engineering Postdoctoral Researcher Flow Station  Harbin University of Science and Technology  Harbin, China  wxmchxsh@126.com  FAN De-cheng  2. School of Economics and Management  Harbin Engineering University  Harbin, China  wxmchxsh_03@163.com  Abstract?A water quantities allocation arithmetic was  proposed, Radial basis function neural network  (RBFNN) was designed, and simulated annealing  arithmetic was adopted to adjust the network weights.

MATLAB program was compiled; experiments on  related data have been done employing the program.

All experiments have shown that the arithmetic can  efficiently approach the surface with 10 -4 mm error  precision, also the learning speed is quick and  predictions is ideal. Trainings have been done with  other networks in comparison. Back-propagation  learning algorithm network does not converge until  2000 iterative procedure, and exactness design RBFNN  is time-consuming and has big error. The arithmetic  can approach nonlinear function by arbitrary precision,  and also keep the network from getting into partial  minimum.

Keywords- water quantities allocation arithmetic; RBFNN;  simulated annealing arithmetic; water management

I. INTRODUCTION  Models of water resource allocation have been studied  since the 1950s, and made a vigorous progress from the  1960s to 1970s[1~3]. In recent years, multi-objective  analysis and optimization methods are the main  approaches in water resource allocation researches.

Considering conflicting objectives, stochastic hydrology  behavior, and uncertain consumptive water use, the  research methods and models have become increasingly  complex [4].

Some researches have considered water quality in  allocation process. Afzal et al. developed a linear  programming model to get optimal use of water with  different quality [5]. Developed an optimal allocation  model of regional water resources of different quality [6,7].

In these two researches, the water quality is considered as  input in the water allocation and not a time-variation  condition, and the models are not physical. Wu et al.

developed a multi-objective model of the integrated   optimal distribution of water quantity and quality [5]. Cao  presented a water quantity and quality model of optimal  water allocation based on ?green benefit?[8]. In Wu and  Cao?s researches, Water Quantity?Quality Model for  Water Allocation Analysis water quality is simulated,  however, the simulation is based on given conditions, not  in a long series of time. And it will be not enough when  the allocation in a series of time needs to be analyzed.

Here, a new neural network arithmetic?RBFNN based  on simulated annealing arithmetic is proposed. RBFNN is  superiority to BP neural network on the aspect of  approximating capability, classify capability and learning  speed. Simultaneously, simulated annealing arithmetic has  characteristic of global optimization which keep the  network from getting into local minimum consequently.



II. RADIAL BASIS FUNCTION NEURAL NETWORK  ARITHMETIC  Radial basis function neural network is a kind of feed-  forward three layers network. The general structure of the  network is composed of input layer, hidden layer and  output layer. Radial basis function adopts Gauss function  which is defined as [9]  ( ) ( ) ? ? ?  ?  ? ? ?  ? ?? ?=   exp)( j  j  T  j  j  CXCX Xu  s h  Nj ,,2,1 L= (1) Where )(Xu  j is output of the jth hidden node,  ( )T n xxxX ,,, 21 L= are input samples, jC is center of Gauss  function, j  s is known as width parameter which control  the radial effect scope of radial function and h  N represents  number of hidden nodes.

The output of radial basis function neural network is  defined as [10]  UWuwXy T ij  N  j  iji  h  =?= ? =  q  )( mi ,,2,1 L= (2)  Where iW is the weights vector from hidden to output  layer ( )TiNiii hwwwW ??= ,,,, 21 L , U denotes the output of hidden layer ( )TNhuuuU 1,,,, 21 L= and ? is threshold vector.

The structure of radial basis function neural network in  paper is shown in Fig.1, here input vector number is four  and output vector number is one.

It is important to choose available radial basis function  for neural network learning method in simulation. So non-  supervise learning method is adopted, and hidden node  center jC and width js are ascertained here. Among  numerous clustering algorithms, seeking for center and  width parameters, the most simple and effective method is  K-means algorithm which is an unsupervised clustering  method [11].

input layer hidden layer output layer  Figure 1. Structure of RBFNN in paper  The second step is to carry out weight vector from  hidden to output layer using error revise learning method.

Considered CPU memory space request is limited,  performance hour is short and automation degree is high  in surface reconstruction processing, simulated annealing  (SA) is employed to adjust the weights.

Simulated annealing (SA) is a straightforward global  optimization method used for combinatorial problems  typically. The method was originated from the physical  phenomenon of cooling metals where atoms move from a  random state to a maximally organized state. The main  parameter is the cooling schedule, which including an  initial temperature, reducing temperature, controlling the  duration at a given temperature and a terminal criterion.

Solutions are altered via a move operator which usually  transforms a solution to a neighboring one randomly.

The flow chart of RBFNN based on simulated  annealing arithmetic is shown in Fig.2

III. ALGORITHM OF SIMULATED ANNEALING  MATLAB program is compiled for the arithmetic.

Adjusting weight stage could be described as follows.

Step 1: Initialize the original high temperature T,  weights and threshold vector. Specify the initial weight  values as system optimization solution W*. Specify sum  squared error MSE which is obtained from the first  network training as the minimum value MSE*. Specify  network training target value e and learning rate ?, ? for  *Supported by Natural Science Foundation of China(70473020)  Natural Social Scientific Foundation of China(04BJY026)  Heilongjiang province Social Scientific Foundation 06D069  and Heilongjiang province Programs for Science and Technology  Development (GB05D105-3) of China, Heilongjiang province  Education Department Humanity Social Scientific (11512113)  ?>1!?>1 and ???. Choose suitable convergence criterion  m, n and their maximal value M and N. Choose available  temperature dropping strategy and step length accordingly.

Step 2: Sum squared error should be minimum value,  target function is defined as  ( ) ( )[ ] 2N  1k  kk xy-xy  N  J ?  =  = ? (3)  Where kx is the input vector. )(xy k? is the practical  output vector and ( ) k xy is the predicting output vector of  neural network. N is samples number. Target of adjusting  weights vector is to let J approximately equal toe .

Step 3: Dropping temperature by half step within a  temperature range under original high temperature T.

Adapt the weights following www ?+=? a , compute )()( wJwJJ ??=? , where w? is a random  increment. w is former weight and w? is current weight.

Figure 2. Flow chart of RBFNN based on simulated annealing arithmetic  Step 4: Determine J, if e<J , go to step 9.

Step 5: Determine J? , 0<?J means that the error is  reducing and the training is successful. Specify w? in current training as W*and specify MSE as MSE*, set m=0.

Step 6: If 0??J , decide whether to specify w? in current training as W*according to probability function,  where the probability function is given by  )exp( i T  J p  ? ?= (4)  Initialization  MSE MSE*  End  No  Yes  Calculate MSE base on errors  Calculate errors between predicting  and practicing outputs  Training with adjusted weight  matrix and output results  Adjusting  weight  matrix by SA  arithmetic  Calculate outputs of the hidden and output  layer  Input training samples and  predicting outputs  x  i x  n x  y  i y  n y  i w     Where i T is the current temperature.

If w ? is accepted to be W*, then let weights www ?+=? a , otherwise weights www ??=? b . Set  m=m+1.

Step 7: When m>M, if MSE is no longer reduced in  training, then goes to step 8, otherwise continue.

Step 8: Annealing: set T=?T, where ? is step length  coefficient in temperature dropping strategy. In this paper,  ?=0.9. Repeat procedure from step 3 to step 6, if W* is  reduced, set n=0. Otherwise, set n=n+1. When n>N, if  MSE is no longer reduced, go to step 9. Otherwise,  specify w? in current training as W*and specify MSE as MSE* then continue.

Step 9: Export current W* and MSE*, stop.



IV. THE INITIAL TEMPERATURE NUMERICAL  CALCULATION METHOD  The initial temperature numerical calculation method is  as following [12]:  Step1. Given a constant T, initial temperature t0, 0c ,  R0"0,k#=1  Step 2. At this temperature iteration L steps (for a  given constant), respectively, simulated annealing  algorithm records accepted and rejected number of states to  calculate the ratio RK between states to receive and number  of iterations,  Step 3. When ec <0k -R , stop the calculation;  Otherwise, when, 1-kR and kR < 0c , then k: = k +1, t0: =  t0 + T, goto step2,  When 1-kR and kR ? 0c  , then k: = k +1, t0: = t0-T,  goto step2,  When 1-kR ? 0c and kR ? 0c  , then k: = k +1, t0: = t0  + T / 2, T: = T / 2, goto step2,  When 1-kR ? 0c and kR ? 0c , then k: = k +1, t0: = t0-  T / 2, goto step2.

Here, 0c = 0.9 or 0.8.



V. EXPERIMENTS RESULT AND WATER DEMAND  PREDICTION  Radial basis function neural network is established with  end of the total population, industrial output value, the  effective irrigation area and forest cover as input vector,  the total water consumption as output vector. It is a three  layers neural network with four inputs and single output.

Simulated annealing arithmetic methodology is used in  this study to adjust weight.

Here, ? is given by 10-4, spread constant is specified as 0.6668, the number of neurons identified as 35-50.

Training analysis curve is shown in Fig.3, the network  converges after iterating 30 times. It means that network  learning speed is high. Error surface of output data is  shown in Fig.4 and Fig.5, we can see that errors are  between -4?10-4~1.5?10-4, errors are very little.

Figure 3. Training analysis curve  Figure 4. Error surface of output data  Figure 5. Error colors map     Employing the arithmetic and convergent RBF neural  network based on simulated annealing algorithm to predict  the total water consumption. The process is as following:  When RBF neural network based on simulated  annealing algorithm has been convergent, input the total  population, industrial output value, the effective irrigation  area and forest cover four sets of input values,  The network output data shall be the total expenditure  predictive value of water. Application of numerical input  data, such as 2095, 3296.61, 3465.40, 2.94, XinJiang  Autonomous Region, the network output is 558.3. The  actual value of the total water consumption is 537.3.

Comparison is informed that the prediction error is 3.9%.

The multiple sets of similar data test error is below 3.9%.



VI. CONTRASTING  Trainings have been done using other kinds of net  works in comparison.

Efficiency design of radial basis function neural  network, the network parameters is set as follows: network  expansion constant is 1, neuron numbers are 25 and below,  network training objectives (squares and error parameter)  is 0, radial basis function networks Training characteristic  curve is shown in Fig.6, network training result is not ideal.

0 100 200 300 400 500 -4  -3  -2  -1      500 Epochs  T ra in in g -B lu e G o a l- B la c k  Performance is 0.0436157, Goal is 0.0001  Figure 6. Training analysis curve by efficiency design RBF  Fig.7 is error curves of exactness design RBF neural  network, the errors are 10-3 orders of magnitude. If number  of input data is large, neurons number is hugeness and  training time is long.

Conclusion can be drawn from Fig.6~Fig.8 that method  proposed in this paper is preponderant.

BP learning algorithm and exactness design RBFNN  neural network were employed in simulations here. BP  network does not converge until 2000 iterative procedures.

The exactness design RBFNN consumes 30minites when  input data approaching 1000, whereas method proposed in  this paper consumes 10 seconds only.

Figure 7. Error curves of exactness design RBF

VII. SUMMARY  A new neural network in the field of water demand  prediction based on RBFNN and simulated annealing  arithmetic is discussed in detail. Simulation in this  research can lead to the following conclusions:  The neural network in the paper realizes water demand  prediction.

The simulation results verify the water demand  prediction is successful and is of good generalization  ability.

Simulation shows that capability of the neural network  in the paper is superior to BP learning algorithm and  efficiency design and exactness design RBF neural network  using same parameters.

