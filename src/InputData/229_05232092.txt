Association Rules Algorithm Research in Optical Warning System

ABSTRACT: Mining association rules with multiple minimum supports is an important research aspect of data mining. In this paper we propose a database partition method to mine the frequent item sets, and use MIS-tree to store the crucial information about frequent patterns. We use the CFP-growth algorithm to mine local frequent patterns and insert them into the global frequent pattern. The experiment on OASN shows that the method is effective to predict the optical warning level.

KEYWORDS: database partition; MIS-tree; frequent pattern; CFP-growth

I. INTRODUCTION Data mining association rules was put forward by  Agrawal etc. since 1993, it caused the academic extensive concern[3]. In recent years, the data mining technology causes extensive attention by experts and scholars in artificial intelligence and database field. It is an important research topic to discover the association rules in transaction database. The purpose of correlation analysis is to mine the hidden rules and to discovery all the strong rules in database. People have studied out kinds of fast algorithms for mining association rules such as Apriori, AprioriTid, AprioriHybrid and DHN etc. Those algorithms need to scan database too many times and analysis static data, generate many candidate sets. The timeliness and spatiality grow with database increasing, especially in long mode data mining.

J.Han proposed a FP-growth algorithm to generate the frequent set which compress the frequent sets in FP-tree to store the association rules, use the FP-tree to generate the frequent sets[1]. But FP-growth generates lots of FP-tree which need vast memory and occupy great CPU processing time when transaction database is dense. With the increasing of the FP-tree, it will cause the memory cannot load 1-item which the FP-tree mapped, leads to the algorithm cannot work efficiently.

In this paper, we propose a database division method to solve the frequent pattern trees take up great space and time.

We divide database into several sub databases and use MIS- tree to load frequent pattern information, the MIS-tree mining processing is similar to the FP-tree. In the MIS-tree, data sets sort by the minimum set in nonincreasing order, we use CFP-growth to get sub sets frequent patterns, then join these local frequent patterns to get the global frequent pattern. In the paper, we analyzed CFP-growth algorithm, proposed CFP-growth algrithmm based on database division. We use the algorithm in optical warning system to mine association rules between the light powers and its  attributes. From the experiments we found the algorithm is valid.



II. DATABASE PARTITION  A. Relevant Concepts Assume I is all items set, D is transaction database, X is  item set. T is X?s sub item, each transaction has an only identify TID. If X contains k items, then we call it k-item.

User can definite a minimum supporting value min_sup which less than the transactions of D[7].

Definition1 Support: The item sets support is the percentage of item set X?s accounts in D. The association rule X Y?  support is ( ) /s X Y D= ?  . If the item set?s support is above the min_sup that the user giving, the item set is frequent set.

Definition2 confidence: The item sets confidence presents the association rule X Y? density in D. We use c to present X Y?  confidence, c defines in Equation(1):  sup ( ) /sup ( )c port X port Y=                       (1)  Definition3 Insert data into frequent item set: When we insert series set S into X, it defines as follows:  (1) The generation item set { }X X S? = ? (2) The support S in X is: If S X? , then sup ( ) sup ( ) .port S port X S count= + ; If S X?  , then sup ( ) .port S S count= .

B. Relevant Theorems and Properties We divide D into several sub database, they are satisfied with the following theorems:  Theorem1 Suppose that the conditional frequent pattern tree | ( )MIS tree a a F? ? ?s global frequent item set is L(MIS-tree|a), then  ( | ) F  L L MIS tree ?  ? ?  = ??                          (2)  F is the set that make up by the global frequent item.

This theorem proves that we can excavate global  frequent item through conditional frequent pattern.

Theorem2 Suppose that the conditional frequent pattern  tree is |MIS tree ai? and its local frequent item set is , then  2009 International Forum on Information Technology and Application  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Application  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Application  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Application  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Application  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Application  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Applications  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Applications  DOI 10.1109/IFITA.2009.242   2009 International Forum on Information Technology and Applications  DOI 10.1109/IFITA.2009.242       ( | ) ( | ) n  i i i  L MIS tree a L MIS tree a =  ? = ??         (3)  The theorem proves that we can get the global frequent item by computing the local frequent item.

From the above theorems, we divide D into n mutually disjoint pieces of sub database 1 2, , ..., nD D D . The global  minimum support is minsup_count. Each piece iD ?s local minimum support is minsup_counti (i=1,2,...,n), they define as follows:  minsup_counti=minsup_count*||Di||/||D||     (4)  Property1 Suppose D is divided into n mutually disjoint pieces of sub database 1 2, , ..., nD D D . If item set S is not  frequent on all the pieces ( 1, 2, ..., )iD i n=  , S is a frequent pattern set in global database too.

Property2 Suppose that there are n local transaction databases 1 2, , ..., nD D D , the minimum support is minsup.

If 1 2( ) ( ) ... ( )nX LF D LF D LF D? ? ? ? , then X is a global  frequent item set. ( )iLF D is the frequent item set in local  database iD .

The property describes that if all item sets are not  frequent pattern sets on the sub transaction database, then the whole transaction database is also not a frequent pattern database.



III. MULTIPLE ITEM SUPPORT TREE  A. MIS-tree Design  and  Construction A MIS-tree is a tree structure. It defined as follows[4]: 1. It consists of one root labelled as ?null?, a set of item  prefix sub-trees as the children of the root, a MIN frequent item header table which contains all items in F;  2. Each node in the item prefix sub-tree consists of three fields: item-name, count and node-link, where item-name registers which item this node presents, count registers the number of transactions represented by the portion of the path reaching this node, node-link links to the next node in the MIS-tree carrying the same item-name, or null if it is none.

3. Each entry in the MIN frequent item header table consists of three fields: item-name, item?s minsup MIS(ai) and head of node-link which points to the first node in the MIS-tree carrying the item-name.

4. All the items in the table are sorted in non-increasing order in items of their MIS value.

B. MIS-tree Construction  Algorithm We need to scan database twice in order to construct the  MIS-tree, the algorithm describe as follows: Input: transaction database D, classification structure  table S, minimum support upper limit a, lower limit b;  Output:MIS-tree.

Input S and scan D, add each item?s ancestor in D to D  and delete the mehrmals ancestor. Get the expanding transaction database ED, calculate each item?s support and leaves in ED. According to a and b to get MIS(a).

MIS(a)=b+{(a-b)*g(a)}                          (5)  g(a)=(a?s instance count in D)/( area instance count).

Then we get the item set F which satisfies with MIN, List F?s item in a non-increasing order according to the minimum support. So we get Flist.

Create the root of the MIS-tree, R, label it as null. For ED, delete the transaction from ETrans which is not in Flist, and order the ETrans according to the Flist sort. We use [p|P] to present Etrans, where p is first element and P is remaining list. Call insert_tree([p|P],R).

Insert_tree([p|P,R]) describe as follows: Procedure insert_tree([p|P,R])  While (P is nonempty) If R has a child N  such that p.item-name=N.item-name then  N.count++;  else Create a new node N, let its count be 1; Let its parent link be linked to R;  Let its node-link be linked to the nodes with the same item-name via the node-link structure;  C. Example of MIS-tree Construction Consider transaction database D shown in TABLE?.

TABLE I. TRANSACTION DATABASE  MIS value of each item is shown in TABLE?.

TABLE II. MIS VALUE  Items a b c d e f g h MIS 4 4 4 3 3 2 2 2  To create the MIS-tree, we create the root of the tree, label as ?null? and build a header table which points to the node-link. Nodes with the same item-name are linked in sequence via node-link. Scan D, the tree with the associated node-links is shown in Figure1.

TID item bought item bought(ordered) T100 d c a f a c d f T200 g c a f e a c e f g T300 b a c f h a b c f h T400 g b f b g f T500 b c b c      Figure1. MIS-tree construction

IV. DIGGING FREQUENT PATTERN  A. Mining Frequent Pattern Algorithm In this section, we?ll propose the division database  method and use CFP-growth algorithm for mining the database frequent patterns[5].

There are three steps to get global frequent patterns.

1. Divide D into several sub transaction databases; 2. Construct MIS-tree, use CFP-growth to mine the sub  database?s local frequent patterns.

3. Find global frequent patterns.

Input: transaction database D, partition count n,  minimum support minsup_count Output: frequent patterns X ? Input (n,minsup_count); X ? ? ?  ; Partion D; for int i=1 to n do begin minsup_counti=minsup_count*||Di||/||Dj||; Generate_LocalFrequent(Di,minsup_counti);  Generate_global(minsup_count, X ? ) Return X ? ;  The algorithm use CFP-growth to get the frequent patterns to mine the sub database.

B. CFP-growth Algorithm Input: MIS-tree, a set of MIN frequent item F, MIS (ai)  of each item ai in F Output: the complete set of all f?s conditional frequent  patterns and the complete set of all support values of f?s conditional patterns  Method: call CFP_growth(MIS-tree, null) Procedure CFP-growth (Tree, f )  for each ai in the header of Tree do generate pattern a = ai?a with support = ai.support;  construct b?s conditional pattern base and then b?s conditional MIS-tree Treeb;  If Treeb ? ? then call CP_growth(Treeb, b, MIS(a) );  Procedure CP-growth (Tree, f)  Input: MIS-tree, MIN frequent item f and its minsup; Output: f?s conditional patterns Method:call CP_growth(Tree,a, minsup) Procedure CP_growth(Tree, a, MIS(a) )  for each ai in the header of Tree do generate pattern b = ai ? a with support = ai.support; construct b?s conditional pattern base then b?s conditional MIS-tree Treeb;  If Treeb ? ? then call CP_growth(Treeb, b, MIS(a) );  CFP-growth traversal the MIS-tree?s node from the item which has minimum support in Flist, and call CFP-growth in each sub database to get the local frequent patterns. We scan X and use global minimum support to statistics local frequent support.

C. Generate  Global  Frequent  Pattern Generate_global function describe as follows: Generate_global(minsup_count, X ?  )  for(int i=0;i<n;i++) for all S X[i] do  sup_count(S)=sub[X].count; if( S X? )   { }X X S? = ? ;  else count(S)=sup_count(X)+S.count; update X ?  ;  for all S? X ?  do if sup_count(S)<minsup_count  then  X ? = X ? -{S}; for (int k=1;k< X ? .count;k++)  for each l1 for each l2 if (l1[1]= l2[1] ? l1[2]= l2[2] ? ? ?  l1[k-1]= l2[k-1]?l1[k]? l2[k]) l3=l1 ? l2; if(l3.count?minsup_count) X ?  = X ? ?  l3  Return  X ?

V. EXPERIMENT EVALUATION Optical Auto Switch Network(OASN) system offer  monitoring light power, switching line automatically and protecting network.

The light power monitor module collects light power information and sends them to the database ZYOC. We analyze the light power and decide the warning level according to the reference values. In this paper we mine association rules in light power by dividing ZYOC and using CFP-growth algorithm. We read about 15000 light power records from ZYOC, divide the database into five sub database, transaction?s average length is about 50. The experiment are performed on a Celeron M550 2.00GHz CPU PC with 512MB main memory, running on Microsoft Windows XP server. All the programs are building in     VC6.0. One of transaction light power information is shown in Figure 2.

Figure2. Light power charm  In our experiments, we define MIS(ai) as follows:  ( ) ( ) ( )  ( ) ( )  M a M a MINi iMIS ai MIN otherwise  M a f ai i?  ?? ? ??  >  = ? (6)  ( )M ai is the actual frequency of item in D, MIN is the smallest MIS value of all items, and? is a parameter that controls how MIS for items are related to the frequencies.

Figure 3 shows the frequent patterns with? .

Figure3. Frequent patterns  The experiment turned out the method is effective and the running results as follows:   Figure4. Experiment result  Figure4 shows that our method is effective to mine frequent patterns from database ZYOC.



VI. CONCLUSIONS In this paper, we have developed an efficient method for  mining association rules with dividing the database. We implemented the MIS-tree and the CFP-growth algorithm in optical warning system to mine the local frequent patterns,  and then get the global frequent patterns. Through the pruning tactics we delete those non-frequent items. The result indicates that our method is effective in mining the light power information.

