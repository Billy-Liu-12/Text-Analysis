A Model for the Development of NFC Context-

Abstract In this paper a model for the development of context-  awareness applications using Near Field Communication is  presented. The model is based in the association of services and  resources to augmented objects through Tags. The different types  of services assigned to the objects are modeled in a hierarchy  defining the execution order and personalizing the user  interaction through the use of resources and rules. A tool for the  testing and validation of the model has been developed and is  described in the paper together with an application example.

Keywords- Context-awareness, Phone Mobile, NFC, Internet of  Things

I. INTRODUCTION  Future of Internet seems as a fully connected world through  hidden connected computer linked to also connected  augmented objects: from books, cars, house machines, foods to  anything. From the Weiser vision [1] of this world some  ubiquitous computing paradigms [2] have been proposed for  the development of applications able to build the Internet of  Things (IoT) [3].

IoT should not be seen as a simple extension of the current  Internet, but as a set of new interdependent systems that  operate with their own infrastructures. Therefore, IoT would be  set up together with new services, as is stated in a report from  the Information Society Technology Advisory Group (ISTAG)  [4].

IoT supports the idea of a context where the objects are  augmented by Tags. Those Tags store encoded information  under a standard format or at least on a format known by the  objects/devices that interact with them, with the objective of  gathering information and services. Pending on the interaction  model, IoT is based on the use of different paradigms, being    undoubtedly the Touch Paradigm [5] one of the most  attractive of all. Recent investigations are focused on make  those services and systems offered by IoT aware of the context.

Context awareness is referred to the capability of an  application or a system to be aware of its physical environment  and the situation in order to be able to act and answer in a  proactive and intelligent way [6], [7]. Building upon the  context acquisition and context management models discussed  in literature, numerous context management architectures have  been proposed [8]-[10]. Although many EU projects [11]-[13]  and industrial research [14], [15] have explored context-  awareness aspects, however the proposed approaches fail to  completely offer a generic, scalable and flexible architecture  supporting both evolving context models and evolving services  and applications. Moreover, an efficient context diffusion and  coherent integration into mobile communication services  continues to be a challenging research area.

A. NFC in the development context-awareness IoT  Lately, different ubiquitous applications have been  proposed making use of NFC (Near Field Communication):  payment applications, ticketing and loyalty [16], tourism,  location and surfing [17], elderly and home assistance (AAL)  [18], building intelligent ambient where it has been studied  how to make the context sensitive to the user interaction with  the scenario [19], [20].

The interaction with the objects from a scenario could be  more or less complex regarding some parameters as the type  of sensor: whether is active (it has its own autonomous  power) or passive, or the information and services associated  to the object.

The active objects have some processing capability, either  by themselves, or because they are connected directly to any  system with this capability (as can be a reader connected  through the net with a central server). The scenarios with this  type of objects could be easily customized, with the  intelligence of the process relying over the Back-end system  that stores information about the scenario, users, devices, etc.,  and the logic that allows adapting the interaction to the  characteristics of the scenario, users and interactions. Passive  objects simply store information that would be read by the  user device, being his/her device, through the appropriate  software, the one that would guide the interaction, initiating    the needed actions. Although in several environments, mainly  closed, intelligent scenarios could be built making use of  active objects; in open scenarios and other applications, the  objects are passive, being augmented with Tags.

The user interaction in augmented scenarios with passive  objects is normally based on: a) the user touches with  Second International Workshop on Near Field Communication  978-0-7695-3998-0/10 $26.00  2010 IEEE  DOI 10.1109/NFC.2010.8   his/her NFC device the Tag associated to the object, b) the  device receives the information stored in the Tag c) the  software installed in the device would read the information  and execute the corresponding action. Evidently, in this case  any user interacts with the objects in the scenario in the same  way, either his/her characteristics, preferences or previous  interactions were.

If the mobile device has a software (MIDlet) installed, the  information stored in the Tag could be far more complex and  the actions executed by the MIDlet could be far more complex  that those established by the NFC-Forum standard and  specifications. In this case, the intelligence in the interaction  could be carried out by: a) a Back-end system that interacts  with the mobile device through some of the available media  (WLAN, GPRS, Bluetooth, etc.), b) the mobile device, and c)  both systems.

In the first case, the NFC device would act as terminal,  sending the information of the Tag to the Back-end system,  which would perform its processing, answering the user in a  proper and customized way. The main issue of those systems  lies in its cost, security and reliability of the communication in  open environments with user mobility and communication  losses.

In this paper we propose a solution for scenarios formed by  passive Tags that allow complex interactions with the user and  where the interaction is organized mainly by the mobile device,  having the Back-end system none or little responsibility.

Within those intelligent environments different scenarios could  be defined, having different objects, where each scenario would  behave in a different way regarding the user that interacts  with it, his preferences, his characteristics and even his  devices characteristics.



II. A MODEL FOR THE NFC SERVICES DEFINITION  The objective of our work is to propose and define a model  that allows the interaction with a scenario formed by  augmented objects, and which is able to allow different  interaction contexts defined by the user characteristics and  preferences.

A. Definitions and basis of the model  Being a scenario S defined by a group of objects O = {o1,  o2, , on} that have assigned a set of Tags T = {t1, t2, , tn}  where t1 ? o1, t2 ? o2  , tn ? on. For each Tag ti a set of services  Vij (j = 1..m) that define the interaction offered by each object  oi can be defined.

Being C = {c1, c2, , cn} the set of different interaction  contexts that are defined for a scenario S, and U = {u1, u2, ,  un} the set of users that interact with the scenario S as per a  certain interaction context ci.

As shown in Fig. 1, in each context ci a subset equal or  different to the set of objects O that form the scenario S can  actuate, offering the same or different set of services V(u)  to  the users ui that interact with the scenario S.

In Fig. 1 it is shown how the two users interact with, as an  example, the object o2 from the scenario, however the object  o2, can offer the same or different services v2i to each user, and  those services are executed as per the user preferences,  customizing the interaction of the users with the context.

Figure 1. An example of  user interaction with scenario objects  Therefore, besides those elements described, the proposed  model is characterized by offering a logic or procedures that  ease and make intuitive the interaction of the users with the  context. This logic establishes the behavior that is offered by  the objects in the scenario and how those objects are going to  answer to the different users. Thus, regarding the user that  interacts within the same context, the interaction with the  scenario could be different and adapted to the user.

In order to define the behavior of the objects and how the  set of services vij associated to each of them is going to be  executed pending of the user, a set of rules R = {r1, r2, , rn}  is defined. Each one of these rules give the logic needed for  the interaction between the intelligent object of the context  and the user, allowing the customization of the context ci to  different users ui.

The rules establish a customized processing logic in the    interaction of the users with the objects. This customization is  supported by a set of resources D = {d1, d2, , dn} which  characterize the way or media used to carry out the interaction  user-context and how that communication will be performed.

Figure 2. Elements of a interaction context   As can be seen in Fig. 2, each object has associated a set of  services that can be offered to the user. Those services can be  associated to the actions that would happen when the user  touches the Tag, matching the expectations. Whether one  service or other is executed is defined by the rules defined for  determine the interaction model with the user and therefore, as  per the user characteristic and interaction preferences.

Different types of services can be defined: a) based on the  use of URIs (Uniform Resource Identifier) that allow  performing actions such as sending a mail (mailto:), making a  phone call (tel:), opening a web page (http:), mailing (sms:), or  starting an application, etc., b) those offered by applications  installed in the mobile device, and c) services which execution  lies on the Back-end system.

The interaction with the objects is defined by the resources  created to that purpose. The resources allow the customization  of the NFC device so the interaction is carried out in the best  and most intuitive way and as per the preferences defined; i.e.,  through a resource a device can be ordered to vibrate, or to play  a sound, voice or image in order to start the associated  operative.

Figure 3. Services hierarchical structure  Obviously, the use of the resources associated to the objects  is limited to the characteristics of the own device that is part of  the interaction. The resources can be assigned to the Tags and  to the different services defined for the Tags. A resource  associated to the Tag is executed in the moment that the user  interacts with the Tag (touches it). The resources associated  to the services are executed during the service operation and  ends up in any of the following situations: a) when the service  finishes, b) when a new service starts, c) when the interaction  with the user finishes.

As can be seen in Fig. 3, those services are defined within a  priority structure defined by the level of service definition in  the hierarchical structure. The first service that is going to be  executed is the Service 1.

For that, the service will check based on its properties, rules  and preferences defined and the resources needed whether it  can or should instantiate it. If the execution is properly done, it  will continue executing the services of the same level of the  tree. It a service cannot be executed or an error occurred, the  execution will go down a level in the structure, in order to  process the subordinated services (Service 2.1, Service 2.2,  etc.). Note that when all the services at this level are finished,  subordinated, the next service level to be executed will be the  corresponding to the directly upper level, that is, Service 3.



III. NFC SCENARIOS CREATOR  With the purpose of testing the functionality and utility of  the interaction model described, a tool named NFC Scenarios  Creator (NFCSC) has been developed. NFCSC is a tool fully  developed in Java for the scenario definition under the model  described and that integrates the use of them to be understood  by a MIDlet that will be executed in a NFC device.

NFCSC allows, therefore, the definition of the scenario,  rules and user interaction preferences; it also has the capability  both of recording the Tags associated to the objects in the  scenario as of generating the contents needed for a proper  performance of the MIDlet.

Although NFCSC is still in development stage, the system  allows to establish the hierarchy of functionalities associated  to each object and to define restrictions and preferences.

NFCSC (Fig. 4) allows the definition in parallel of several  scenarios or projects. For each project a set of identifying  attributes are defined, as well as the objects that compose the  scenario, the services associated to the objects, the general and  user interactions preferences and the resources used on it.

Each scenario is described by a XML document, as shown  in the DTD file from Chart I.

CHART I. DTD FOR THE SCENARIO DEFINITION  <?xml version=1.0 encoding=UTF-8?>  <!ELEMENT XMLProject (XMLDescription, XMLPath,  XMLResource*, XMLTag+)>  <!ATTLIST XMLProject  ID CDATA #REQUIRED  name CDATA #REQUIRED>  <!ELEMENT XMLTag (XMLDescription, XMLResource*,  XMLService+)>    <!ATTLIST XMLTag  ID CDATA #REQUIRED  IDScenario CDATA #REQUIRED  name CDATA #REQUIRED>  <!ELEMENT XMLService (XMLUri?, XMLMethod?, XMLOS?,  XMLResource*, XMLService*)>  <!ATTLIST XMLService  ID CDATA #REQUIRED  activated (on|off) on  execution (manual|automatic) automatic  iterative (on|off) off>  <!ELEMENT XMLResource (XMLContent?, XMLPath?)>  <!ATTLIST XMLResource  type CDATA #REQUIRED  state (on|off) on>  <!ELEMENT XMLUri (XMLContent)>  <!ATTLIST XMLUri  type CDATA #REQUIRED>  <!ELEMENT XMLPath (#PCDATA)>  <!ELEMENT XMLDescription (#PCDATA)>  <!ELEMENT XMLContent (#PCDATA)>     In order to make the devices that interact with the user able  to answer properly to the different scenarios, the MIDlet  installed must have initial knowledge of its definition. So,  when an object is detected the services to be offered can be  defined and also the way to execute them. Herewith, together  with the installation or deployment of an application, the  initial XML file of the project is also stored in the device,  being the processing of that file by the MIDlet the one that  really defines the interaction.

The user can modify the XML file making use of the  MIDlet, adjusting the parameters that define the interaction  model (properties and resources) to his preferences. Therefore,  a user that in the scenario definition decided that when  touching a certain object an action started automatically, could  modify that decision converting it to manual afterwards, or  activate/deactivate the vibration when touching a Tag, simply  by changing the values of the corresponding properties in the  XML file.

As can be seen in Chart I, each project is defined by a    unique name and identifier, a description, and a set of Tags  assigned which characterize the scenario together with a set of  resources. The Tag identifier includes the scenario identifier,  which allows the MIDlet of the device to reach the XML  document that has to been used in order to guide the  interaction.

For each Tag one or several services could be defined and  one or several resources could be associated to them. The  services could be defined in a recursively way, which allows  specifying the execution hierarchy aforementioned. For each  service a set of attributes is defined, those attributes define  their activation and execution mode.

The resources used in the interaction should also be stored  in the device, so, together with the definition and, pending of  the type it is possible to: define its content (XMLContent), or  specify the path where it is stored in the device (SMLPath).

Figure 4. NFC Scenario Creator main interface  As can be seen in Fig. 4, the NFCSC interface is divided in  some sections. The left sidebar presents the different projects  (scenarios) defined in a classic tree structure, being each one  of the projects represented as the root of the tree, while the  Tags assigned to each scenario are added as if they were their  leaves. The system allows to edit the information of the  elements from each scenario, both the Tags and the own  project.

Pending of which element is selected among the project  tree, the content of the central panel would be different. For  each project the system allows to introduce a general  description, as well as to assign the general resources used.

If a Tag is chosen, the possibilities offered by the system  change, allowing: a) general description edition, b) resources  management, c) management of the services and resources  associated to the services, and d) sorting of the functionalities  among the execution hierarchy established.

NFCSC has an event viewer (frame placed under the main  pane) in charge of showing the set of messages generated by  the system during the interaction with the user. Each entry in  the event viewer is composed by the time when that event  happened and a description that allow the user to know the  action that has been performed. Thanks to this log the edition  or step back in the scenario building is easier.



IV. AN EASY EXAMPLE. EMERGENCIES AND ASSISTANCE    SYSTEM  With the aim of showing the characteristics of the proposed  model and the tool built, its application to a very simple  example will be described with the purpose of not including an  extension and complexity not needed.

Figure 5. Emergencies and assistance example  The basic idea of this scenario is that any user in urgency  could ask for help in an easy, quick and intuitive way, just by  touching with their NFC device an image with a Tag  associated. Chart II shows a fragment with the definition of  the scenario described.

As shown in Fig. 5, the scenario is formed by a frame  where, in order to represent the emergency, a picture of an  ambulance has been placed. Behind the ambulance there is a  Tag. Where the device is got close to the Tag placed in the  frame: a) it detects it and start up automatically the MIDlet, b)  the MIDlet retrieves and decode the content in order to  identify the scenario, c) it locates in its internal storage the  XML file and its resources, d) it starts the execution of the  corresponding action and services and, e) once finished, it  ends up the application.

The full definition of the XML file that specifies the  interaction in this simple example contains two services: a) a  phone call to the emergencies number, and b) sending a text  message to two relatives, both making use of multiple device   resources. However, and for keeping it short, Chart II only  shows a partial view of the example, showing only the  definition of the general properties of the Tag as well as the  first two services and some examples of resource use.

As shown in Chart II, the Tag has defined the use of two  resources. First one is associated to the vibration of the device,  while the second is about an information text that will be  displayed to the user when starting the interaction.

CHART II. SCENARIO INTERACTION DEFINITION. XML FILE  ....

<XMLTag ID="T1245132"IDScenario="S4514152"  name="Ambulance Picture">  <XMLDescripcion>This is the tag that will be  associated to the ambulance picture  </XMLDescripcion>    <XMLResource type="vibration" state="on">  </XMLResource>  <XMLResource type="InfoText" state="on">  <XMLContent>S.O.S. Emergency application  </XMLContent>  </XMLResource> ...

<XMLService ID="S3292378" activated="on"  execution="automatic"  iterative="off">  <XMLUri type="tel:">  <XMLContent>112</XMLContent>  </XMLUri>  <XMLResource type="Audio" state="on">  <XMLPath>E:/scenarios.midlet/S4514152  /T1245132/sound/HelpCall.wav  </XMLPath>  </XMLResource>  </XMLService>  <XMLService ID="S3292379" activated="on"  execution="automatic"  iterative="off">  <XMLUri type="sms:">  <XMLContent>+34667406220 </XMLContent>  </XMLUri>  <XMLResource type="Image" state="on">  <XMLPath>E:/scenarios.midlet/S4514152  /T1245132/pictures/ambulancia.gif</X  MLPath>  </XMLResource>  </XMLService>  </XMLTag>  ...

The definition of the first service is characterized by a set of  parameters as its identifier, whether the execution would be  manual or interactive and an URI that defines the action to be  performed. In this case is a tel URI. This service makes use of  an audio resource whose content it stored on the device  storage. In future versions it will be implemented with a voice  synthesizer.

Notice how the following service definition, corresponding  to sending a sms, is indented from the previous one. This    means that the service is in the same branch, but at a lower  level in the hierarchy of services execution. Therefore, this  service will only be conducted if an error has occurred in the  execution of the previous one. As shown in chart II the latter  service uses an image resource in charge of showing some  information at the MIDlet display and whose content is also  stored on the device.

Besides, the MIDlet allows in a simple way to modify all  those parameters that define the execution of the services and  their use. As commented before, a user could not want that a  service is executed automatically and requires manual  confirmation. For that, he/she only would need to change the  value of the execution parameter of the service into manual. In  the same way, the user can activate or deactivate the use of  resources just by modifying the value of the state attribute into  off. Even more, it is possible to add new resources, if, together  with their definition some content needed for their execution is  included.

Therefore, it can be checked as, even when the user define  an initial interaction for a scenario and even when the same  deployment is done in different devices, each user could easily  adapt and customize the interaction to its needs and  preferences afterwards.

Equally, the user could activate or deactivate a service,  changing the execution order and modifying the hierarchy  initially defined for them. Herewith, the same scenario could be  customized and act in a different way depending of the person  that interacts with it.



V. DISCUSSION  IoT is not a reality yet, but a prospective view of a series of  technologies that, combined, could sharply modify the  interaction mode with our environment and the working of our  society in the following years. In order to establish the IoT  philosophy, it would be needed an advance of the development  and dissemination of elements as sensors, new communication  technologies (as well as their intercommunication), new  mobile devices able to integrate them, a proper infrastructure,  and above all software applications that supports them and are  able to integrate all those elements, as well as to fulfills the  needs and requirements of the users.

Those new systems must also be adapted to the different  interaction scenarios and, mainly, to the different    characteristics, requirements, preferences and needs of the  people that interact with the environment. In this paper we  present a model that provides a solution to this issue.

The model is based in augment different objects among a  scenario with Tags, by the assignment of services and  resources defined in an abstracted hierarchy that allows  configuring a customized interaction model. Thus, for the  same scenario, the model is able to define different interaction  contexts. So, a context is defined as the aggregation of: a) a  certain scenario formed by a set of intelligent objects offering  a set of services, b) an user profile that bears in mind its  characteristics, preferences and needs, c) an interaction device  and d) some interaction rules and resources.

Under the proposed model a tool that allows the definition  and scenario deployment has been built. A neuter MIDlet  installed in the NFC device is the one in charge of guiding the   interaction through the definition of the scenarios stored in a  XML file. This architecture allows that the same MIDlet could  be used with any scenario and that the user could adapt the  interaction to his preferences.

Currently we are working in the completeness of the model  and the complex interaction scenarios generalization, being the  latter based in rules systems that allows adapting the different  interaction contexts to the users.

