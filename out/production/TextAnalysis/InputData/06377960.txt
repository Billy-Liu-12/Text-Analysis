Integrated Fuzzy GNP Rule Mining with Distance-based Classification for Intrusion Detection

Abstract?With the increased usage of Internet, network se- curity attracts many researchers to propose various kinds of approaches. Data mining techniques are efficient to construct a reliable Intrusion Detection System. Classification is an essential task in data mining. In this paper, a new classification method is proposed to build an accurate and efficient classifier for intrusion detection. The new classification method utilizes the average distances of the new data to its closest neighbor points to classify it as normal or intrusion. Then, the distances of the data to the centroids of normal, misuse intrusion and anomaly intrusion is used to get the accurate class label of the data. In addition, this paper integrates Fuzzy GNP-based class association rule mining method to extract rules. Fuzzy GNP avoids the use of the domain knowledge and solves the continuous attributes efficiently.

On the basis of the extracted rules, the multi-feature space is projected into a two-dimensional average matching degree space.

The benchmark data KDD Cup 1999 and NSL-KDD are used to evaluate the performance of the proposed method.

Index Terms?Intrusion Detection System, Distance, Centroid, Fuzzy GNP, Average Matching Degree

I. INTRODUCTION  Network security is extremely important since various at- tacks are launched frequently with increased usage of comput- ers and networks in many fields. Therefore, intrusion detection systems(IDSs) are designed to detect a wide range of security violations from attempted break-ins by outsiders to system penetrations and abuses by insiders[1].

Generally, there are two techniques for IDSs, misuse detec- tion and anomaly detection. Misuse detection aims to detect the attacks through the predefined signatures of them. Whereas, anomaly detection uses normal network behaviors to identify unknown attacks by detecting significance deviation from the established normal patterns. However, misuse detection has the inherent drawback that it cannot detect novel attacks. Whereas, anomaly detection is paid for in terms of high positive false  rate[2][3]. Various pattern recognition and computer intelli- gence methods have been proposed to construct an efficient and reliable IDS. One of them develops data mining methods to discover useful information that describes users? or programs? behaviors from the network connection data for training.

In recent years, Genetic Network Programming(GNP) is developed as an evolutionary algorithm. It has directed graph structure which is different from Genetic Algorithm(GA) and Genetic Programming (GP)[4]. When GNP is used to extract class association rules, it is evolved generation by generation without identifying frequent item sets used in Apriori-based methods[5]. Moreover, the pre-experienced knowledge is not needed in GNP-based class association rule mining. In ad- dition, fuzzy set theory is introduced into GNP to solve the continuous attributes in data mining in order to avoid the sharp boundary problem. The Fuzzy membership functions are also evolved with GNP[6].

In this paper, in order to make full use of class association rules extracted by Fuzzy GNP, a new classification method has been proposed. Generally, after extracting rules from the train- ing data, the multiple-feature space in the training is projected into a two-dimensional average matching degree space. Then, the distance among the average matching degrees of the data is used to identify the class label of the data. This classification method is named as Distance-based classification. Firstly, N- Closest neighbors classifier is employed to categorize each new audit data into either normal or misuse intrusion. So far, it is only a general procedure for simply identifying normal and misuse intrusion. However, after that, anomaly connection data has been mixed into normal or misuse intrusion data.

Usually, it is reasonable to assume that anomaly intrusion data is like neither misuse intrusion data nor normal data or like both misuse intrusion data and normal data. In order  October 14-17, 2012, COEX, Seoul, Korea     Fig. 1. Structure of GNP  to improve the detection performance, a multiple centroid- based modification is introduced. In the proposed method, the centroids of anomaly intrusion are defined by the centroid of normal data and misuse intrusion data. In the new IDS, misuse intrusion connection data also has contribution to detect anomaly intrusion data.

The rest of this paper is organized as follows. Section II briefly reviews GNP and Fuzzy GNP class association rule mining. The proposed distance-based classification is described in Section III. Section IV presents simulation results. Finally, conclusions are given in Section V.



II. RULE MINING USING FUZZY GNP  A. Genetic Network Programming  Each individual of GNP has a directed graph structure which has a start node, plural judgment nodes and processing nodes as shown in Fig. 1. Start node decides the first node to be executed. Judgment nodes judge the information from the environments and determine the next node. And processing nodes execute the action or processing functions of GNP.

In contrast to judgment nodes, processing nodes have no conditional branch. By separating processing and judgment functions, various combinations of judgment and process can be handled by GNP. That is, the fitness of different combi- nations of judgment and processing functions in GNP can be evaluated.

Each individual is evaluated by the fitness values. The fitness function is represented as follows.

f itness = ? r?R  { ?2(r)+10(nante(r)?1)+?new(r)  } (1)  R is the set of suffixes of extracted rules by the individuals, ?2(r) is the chi-square value of rule r. nante(r) is the number of attributes included in the antecedent part of rule r and ?new(r) is an additional constant when rule r is new.

On the basis of the fitness value of each individual, the structures of GNP are evolved by performing genetic operators, e. g., selection, crossover and mutation.

First, the best 1/3 individuals in terms of the fitness values are selected to do crossover and mutation.

Crossover is executed between two parents selected by tournament selection and two offspring are generated. In detail, each node in parent individuals is selected as a crossover node with the probability of Pc(0 ? Pc ? 1). Then, two parents  Fig. 2. Fuzzy membership function  exchange the genes of the corresponding crossover nodes.

Finally, the generated individuals become new ones for the next generation.

Whereas, mutation is executed in one individual selected by tournament selection. In this paper, we use two kinds of mutation operators[6]. Each connection node is selected with the probability Pm1 and changed to another node. And each node function is selected with the probability of Pm2 and changed to another function.

B. Class association rule mining using GNP  When extracting the rules using Fuzzy GNP, the database containing continuous attributes should be preprocessed[6].

The fuzzy membership function of Low, Middle and High for each continuous attribute in Fig. 2 is used. In addition, the fuzzy membership function of each continuous attribute is also evolved along with the evolution of GNP, in order to extract diversified rules.

Fig. 3 shows how the candidates of class association rules are extracted by Fuzzy GNP. In Fig. 3, processing node P1 serves as the starting point of the class association rules and connects to a judgment node. One judgment node has two possible branches, Yes-side branch and No-side branch. As Fig. 3 shows, the first judgment node J1 examines whether the discrete attribute Land equals to 1. If it equals to 1, J1 would connect to another judgment node J2. If it does not equal to 1, then a candidate rule which contains only one item in antecedent part is extracted and go to processing node P2, where P2 serves as another starting point of the class association rule mining. Then, judgment node J2 checks whether the discrete attribute Service equals to htt p. If the judgment function is not satisfied, one more candidate rule is extracted, which has two items in the antecedent part and go to the next processing node. Otherwise, another judgment node J3 is connected and its judgment is done. In Fig. 3, J3 is the third judgment node and it would check the continuous attribute Duration = Low. In this case, Fuzzy GNP is used to decide which branch should be selected. Actually, if (Ai is Qi) is satisfied or not is judged in this node, where Qi is the linguistic term of attribute Ai.

Once the continuous attribute is examined by judgment node, a random value r(r ? (0,1)) is generated, then the fuzzy     Fig. 3. Fuzzy GNP-based class association rule mining  membership value of the continuous attribute is compared with r like Fig. 3, which is called probabilistic node transition. If the random value is smaller than or equal to the membership value ?Qi(ai), then go to Yes-side of the judgment node, otherwise, go to No-side of the judgment node, where ai is the continuous value of Fuzzy attribute Ai. At the end of evolution, Fuzzy GNP automatically counts the number a, b and c, which are the numbers of tuples moving to Yes-side at the judgment nodes.

aN , bN , cN are those with normal class in the application of intrusion detection. aI , bI , cI are those with misuse intrusion class.

C. Evaluation of the importance of rules  The obvious difference from general association rules, class association rule mining gives a class label to each association rule. Specifically, the form of the association rule, that is, X ?Y is changed to X ? (k ?C), where, X is the antecedent part of rule X ? Y , k ? C is the consequent part in class association rules. In the consequent part, k is class label and C is the set of suffixes of classes. To evaluate the class association candidate rules, support, confidence and ?2 are used. Suppose that a simple rule which has the form of X ? k, the support of rule X ? k, that is, support(X ? k) can be defined as the number of tuples containing X and k divided by the number of total tuples. con f idence(X ? k) is calculated as the number of tuples containing X and k divided by the number of tuples containing X . Suppose support(X) = x, support(k) = y and support(X ?k) = z, then the ?2 value of the rule is calculated by  ?2 = N(z? xy)  xy(1? x)(1? y) , (2)  where, N is the number of total tuples.

Support, con f idence and ?2 value are used to evaluate  whether a candidate rule is important or not. An important rule should satisfy the minimum values of support, con f idence and ?2.



III. BUILDING DISTANCE-BASED CLASSIFIER  In order to build the distance-based classifier, the two- dimensional average matching degree space should be formed  Fig. 4. Overlapping  firstly. Then, the distance of average matching degree is used to decide the class label of a new data dnew.

A. Definition of average matching degree  At first, the average matching degree should be calculated to assess how well each data matches to the rules in each class.

mk(d) = ?Rk? ?r?Rk  (Matchk(d,r)) (3)  Eq. 3 calculates the average matching degree of data d with all the rules in class k. Rk is the set of suffixes of the rules in class k. Matchk(d,r) is the matching degree of data d with rule r in class k as shown in Eq. 4,  Matchk(d,r) =  p+q ( ?  i?CA ?Qi(ai)+ t), (4)  where, CA is the set of suffixes of continuous attributes of rule r in class k, and t is the number of matched discrete attributes of rule r in class k with data d, whereas, ?Qi(ai) represents the fuzzy membership function for linguistic term Qi. p is the number of continuous attributes of rule r in class k and q is the number of discrete attributes of rule r in class k.

B. Distance-based classification model  In order to build the distance-based classification model for IDS, all training data should be mapped into the 2-dimensional average matching degree space. For this reason, each training data d is represented as the coordinate of (mN(d),mI(d)).

When a new connection data dnew is observed, dnew is represented as the coordinate of (mN(dnew),mI(dnew)). The Euclidean distance of new connection data dnew to the rules in class k, k ? (normal,misuseintrusion), denoted by Dk(dnew), can be defined as follow,  Dk(dnew) =  ?DN?Closest(k)? ?d?DN?Closest(k) D(dnew,d), (5)     Fig. 5. Distance-based classification model  where, DN?Closest(k) is the set of suffixes of N-Closest training data in class k to new data dnew. Using Eq. 5, we can calculate the distances of new connection data dnew to normal and misuse intrusion classes, which are denoted by DN(dnew) and DI(dnew). It is reasonable to tell that dnew is more likely to be a normal data or a misuse intrusion data by comparing DN(dnew) and DI(dnew). That is, a new data dnew is labeled as the class with the smaller distance between DN(dnew) and DI(dnew). The application of N-Closest neighbors method can solve the overlapped problem in Fig. 4 to some extent by using the detailed information on training data.

Based on the given information about normal data and misuse intrusion data, the centroid point (CN(N),CI(N)) of normal training data, called normal centroid, can be also calculated using Eqs.(6)?(7).

CN(N) = ?d?DTrain(normal) mN(d) ?DTrain(normal)? , (6)  CI(N) = ?d?DTrain(normal) mI(d) ?DTrain(normal)? , (7)  where, DTrain(normal) is the set of suffixes of normal training data. The centroid point (CN(I),CI(I)) of misuse intrusion training data, called misuse centroid, can also be calculated in the same way. It is dangerous for systems that new attacks are easily regarded as normal connections. Thus, it is appropriate to suppose two points as the centroid of anomaly intrusions.

We have no information about such anomaly intrusions, so we should analyze the known information from normal and misuse intrusion connection data in the training data to solve this problem. Therefore, anomaly centroids are manually set by using the coordinates of normal centroid and misuse intrusion centroid, i.e., (CN(I),CI(N)) and (CN(N),CI(I)).

Once the three kinds of centroids are determined, the distances of data dnew to normal or misuse intrusion can be recalculated as D?N(dnew) or D?I(dnew). The distance of data dnew to anomaly intrusion centroids, denoted by DA(dnew), is also  TABLE I PARAMETERS OF FUZZY GNP-BASED CLASS ASSOCIATION RULE MINING  Population Size 120 Generation 1000  Processing Node 10 Judgment Node 100 Crossover Rate 1/5 Mutation Rate1 1/3 Mutation Rate2 1/3  ?2min 6.64 supportmin (N) 0.1 supportmin (I) 0.075 con f idencemin 0.8  calculated. Fig. 5 shows the basic idea to decide the centroids of anomaly intrusion data, where D?N(dnew) and D?I(dnew) are calculated by Eqs.(8)?(9) using normal centroid and misuse intrusion centroid, meanwhile DA(dnew) is calculated by E- q.(10) using anomaly intrusion centroids.

D?N(dnew) = ? (mN(dnew)?CN(N))2 +(mI(dnew)?CI(N))2  (8)  D?I(dnew) = ? (mN(dnew)?CN(I))2 +(mI(dnew)?CI(I))2 (9)  DA(dnew) = min{ ?  (mN(dnew)?CN(I))2 +(mI(dnew)?CI(N))2,? (mN(dnew)?CN(N))2 +(mI(dnew)?CI(I))2}  (10)

IV. SIMULATIONS  In order to evaluate the performance of the proposed method, the simulations are conducted using intrusion detec- tion database KDDCup 1999[7] and NSL-KDD[8]. NSL-KDD is generated from KDDCup 1999 by removing the redundant records and increasing the level of difficulty[9]. The training data in both KDDCup 1999 and NSL-KDD are labeled as normal or one of the 24 different kinds of attacks, which can be grouped into four classes: Probing, DoS, R2L and U2R.

Similarly, the test data is also labeled as either normal or one of the attacks belonging to the four attack groups. And it includes specific attack types not included in the training data. Each record in both the two data sets is represented as a combination of 41 attributes which contain binary, linguistic and continuous values.

We select 4,000 records from NSL-KDD for the training to extract rules, since NSL-KDD data set is not biased towards frequent records. Among the training data, 2,000 audit records are labeled with normal, and 2,000 are labeled with misuse intrusion including 1,500 records of neptune type and 500 records of smurf type. For rule extraction, Fuzzy GNP-based class association rule mining is applied and its parameters are listed in Table 1, where, supportmin (N) means the min- imum support value to select interesting normal rules, and supportmin (I) means the minimum support value to select interesting misuse intrusion rules. After 1,000 generations, Fuzzy GNP extracts 50,324 rules consisting of 15,149 normal rules, 25,022 neptune misuse intrusion rules and 10,153 smurf misuse intrusion rules. Fig. 6 shows the total number of rules     Fig. 6. Number of rules extracted vs. generation  TABLE II RESULTS OF DISTANCE-BASED CLASSIFICATION  Probe U2R R2L DoS neptune & smur f Test data 4,116 228 12,189 229,851 222,092  DR 94.83% 75.88% 70.73% 97.54% 100%  extracted vs. generation. The number of rules is too large to be applied to build the classifier, two-phase rule pruning mechanism[10] is implemented to pick up useful rules to reduce the influence of redundant and irrelevant information in the rule pool. Therefore, there are only 432 normal rules, 416 neptune misuse intrusion rules and 152 smurf misuse intrusion rules after pruning. Then, the average matching degrees of each training data with normal rules or misuse intrusion rules are mapped into a two dimensional space.

Four criteria are used to evaluate the testing results, which are Detection Rate(DR), Positive False Rate(PFR), Negative False Rate(NFR) and Accuracy(ACC). DR means the rate of connection data which are correctly classified into normal and intrusion classes. PFR means the rate of normal connection data which are not classified into normal class and NFR means the rate of intrusion connection data which are not classified into intrusion class. ACC means the rate of connection data which are correctly classified into normal class, misuse intru- sion class and anomaly intrusion class. In the first simulation, all the test data are from KDD Cup 1999 data set to check the DR of the proposed method on the four groups of attacks, respectively.

Table 2 shows DR of each group of intrusion types with N = 30. The first line means the number of test data. In addition to the four groups of intrusions, we also list the case that only neptune type and smur f type exist in the group of DoS intrusion. From Table 2, DR on these two classes reaches at 100%. Even those classes do not exist in training data set, the proposed classifier can detect intrusions well.

The next simulation is conducted on the KDDTest+ data set in NSL-KDD data sets with N = 30. In this data set, there is no redundant records, meanwhile, normal, misuse intrusion and anomaly intrusion are all included. The classification results of the proposed method are shown in Table 3. Normal(T ), Misuse(T ) and Anomaly(T ) indicate the number of nor- mal, misuse intrusion and anomaly intrusion labeled by the Distance-based classifier, respectively. Normal(C), Misuse(C)  TABLE III RESULTS OF DISTANCE-BASED CLASSIFICATION  Normal(T ) Misuse(T ) Anomaly(T ) Total Normal(C) 8,080 168 1,463 9,711 Misuse(C) 0 5,301 21 5,322  Anomaly(C) 1,910 1,010 4,591 7,511 Total 9,990 6,479 6,075 22,544  Fig. 7. DR and ACC comparisons between Distance-based classifier and Distribution-based classifier  and Anomaly(C) indicate the correct number of normal, misuse intrusion and anomaly intrusion, respectively. From Table 3, it is obvious that most of anomaly intrusion connection data can be detected by this classifier, which means it has better detection ability on anomaly intrusion. According to Table 3, DR, PFR, NFR and Accuracy are calculated as shown in Eq.

(11)?(14).

DR= (8,080+5,301+4,591+1,010+21)/22,544= 84.29%  (11)  PFR = (168+1,463)/9,711 = 16.80% (12)  NFR = (1,910+0)/(5,322+7,511) = 14.88% (13)  ACC = (8,080+5,301+4,591)/22,544 = 79.72% (14)  From Eq. (11)?(14), even on the KDDTest+ data set where intrusion detection is difficult, the proposed classifier can get good performance. Fig. 7 and Fig. 8 show the comparisons of the proposed classifier and Distribution-based classifier in Unified Intrusion Detection proposed by us in[10]. Generally, in the Distribution-based method, the mean ? and standard deviation ? of the distribution of the average matching degree  Fig. 8. PFR and NFR comparisons between Distance-based classifier and Distribution-based classifier     TABLE IV EXPERIMENTS ON N-NEAREST NEIGHBORS  N = 10 N = 20 N = 30 N = 50 N = 100 N = 300 DR 84.21% 84.22% 84.29% 84.21% 84.21% 83.58%  ACC 77.17% 78.48% 79.72% 78.99% 78.56% 77.31% NFR 14.92% 14.94% 14.88% 14.90% 14.82% 15.59% PFR 17.25% 16.90% 16.80% 16.97% 17.07% 17.52%  over all the training data are calculated. Next, the average matching degrees mN(t) and mI(t) of each test data t are calculated. Then, we can regard the test data as normal, misuse intrusion and anomaly intrusion by the relationships among mN(t), mI(t), (?I?kI?I) and (?N?kN?N), where the subscript I and N mean Intrusion and Normal, respectively, and kI and kN are weight parameters so as to distinguish normal, misuse intrusion and anomaly intrusion for better performance.

Fig. 7 shows the comparisons of DR and ACC. And Fig.

8 shows the comparisons of PFR and NFR. It is shown that DR and ACC of Distance-based classifier is higher than those of Distribution-based classifier. PFR of the proposed classifier is lower than that of Distribution-based classifier. Only NFR is a little bit higher than that of Distribution-based classifier classifier. Consequently, Distance-based classifier outperforms Distribution-based classifier. And the reason for better per- formance of the proposed classifier is that it provides more accurate information for the classifiers.

On the other hand, since Distance-based classifier is a non- parametric method, the number of nearest neighbors is the only factor which should be pre-determined. We also check the influence of this factor on the performance of the proposed method. The DR, ACC, NFR and PFR are only a little sensitive to the selection of N as shown in Table 4. Therefore, in the real applications, we would empirically select it without much consideration of its positive or negative effect on the detection performance of the proposed method.



V. CONCLUSION  In this paper, a new classification method is proposed to in- tegrate it with Fuzzy GNP-based class association rule mining.

By projecting the multi-feature space into a two dimensional average matching degree space, the new classification method firstly utilize the distances of an observed data to its closest neighbor points to classify it as normal or intrusion. Then, the observed data is classified as normal, misuse intrusion or anomaly intrusion accurately by the distances of the data to the centroids of normal, misuse intrusion and anomaly intrusion, respectively. According to the performance of the IDS evaluated on both KDDCup 1999 data set and NSL- KDD data set, it is shown that the proposed method can get acceptable results. In addition, the influence of N is checked.

We concluded that the results are not so sensitive to N. Then, the proposed classifier is compared with Distribution-based classifier. The results show the proposed method has better performance. It is remarkable that the proposed classifier can detect all the connection data of neptune type and smur f type in the test data set of KDDCup 1999.

