MODIFIED HEBBIAN LEARNING RULE FOR SINGLE LAYER LEARNING  J. M. Zurada, A. Malinowski, P. F?rzestrzelskit

Abstract - The paper introduces a new learning method based on the supervised Hebbian learning of encoded associations.

The learning is performed with weight initialization of any values and with invariable learning constant. The method is suitable for training of single-layer networks and compares favorably with other conventional learning rules discussed in the paper.



I. INTRODU~ION  Single-layer neural networks are usually trained using generalized delta training rules, Hebbian learning rule or competitive unsupervised winner-take-all training [l-21.

This paper introduces a new form of supervised Hebbian learning formula which is characterized by rather quick convergence. This feature can be helpful especially for large networks and for large amount of input data. In addition, initial weights in the proposed rule do not have to be assumed as in the case in the Hebbian rule near zero. In the paper, the rule is implemented for case of three training point clusters and compared with other rules suitable for providing the classification of the training set data.

The modified supervised Hebbian learning rule is based on the supervised Hebbian (correlation) learning which will be reviewed first [3].

11. SUPERVISED HEBBIAN LEARNING  Let us revise the Hebbian learning rule [l-31 for a single continuous neuron described with the activation function  where the activation and input and weights vectors are, respectively  net = w%  x = [ X I , X 2 ,  ..., XN]T w = [ W l ,  w2, ...) WJ  0-7803-1254-6/93$03.00 Q 1993 IEEE  In the classical Hebbian rule learning neuron is taught by modifying its weight vector w after every input pattern using the formula  Aw = qxo (2) where 7 denotes a positive learning constant. Initial weights cannot all be equal to zero but should be close to it. The response of the neuron to the present input pattern needs to be evaluated every time its weights are updated.

Neurons taught that way with patterns from several classes or clusters usually learns how to recognize one of them, but because of the random initial weights it cannot be determined which particular set of patterns is recognized.

We thus can only obtain learning of the data without their proper labeling. To achieve training with labeling, a supervised Hebbian learning of the neuron is performed, and its weights change according to the following formula  Aw = qxd (3)  where d denotes the desired output to the input pattern x, and r\ is the learning constant. While using this method we no longer need to evaluate neuron?s responses to the training patterns no matter if we train a single neuron or single-la yer network.

Let a neuron be trained by a set of P patterns x1, ..., xp , and the desired outputs for those pattern be known as dl, ..., dp . The learning cycle consists then of steps as follows :  W O  are initial weights  w1 = WO + qx1d1 wz = w? + qx& = WO + qx,d, + qxgi,  ...

After completing the n-th learning cycle the weights become   mailto:jmzura02@ulkyvx.louisville.edu   Let us see that for large enough n we can usually neglect w for  i = l,..N  what is true if only the sum is not equal to zero. However, ?or the same reason there is a possibility that weights will increase until an overflow occurs during learning. To prevent this, the learning constant 4 should be decreased after each cycle, e.g.

In this case we can evaluate the limit of the weights :  q'"' = a"-' q (0) , a is U constant E (0,i) (6)  It can now be seen that the initial weights of non-zero value may introduce a significant error in the final value independent of learning process. However, since we use formula (3) instead of (2) non-zero weights are no longer necessary, because we no longer use the network response for its training.

111. MODIFIED SUPERVISED HEBBIAN LEARNING  We now propose the modification of the supervised learning rule as described above. Our modification causes improvement of convergence of the learning process so that we can terminate it after shorter period. Let us consider the following formula for weights adjustment  d w  = p - l w  + Lqxd P P where P is total number of input patterns which neuron shell recognize after the training. As previously, the learning cycle consists of P steps as follows  W O  are initial weights  ...

After completing the n-th learning cycle the weights become This result has been proven using the  mathematical induction, and the proof is omitted here for brevity. If we consider the limit of the training after infinite number of cycles we obtain  lim,,,W"P = Owo +  which simplifies to  Let us note that in contrast to the previously discussed learning rule in which learning constant q was decreasing, here it must be fixed, otherwise the limit as in (12) will be equal zero. Furthermore, we can see another effect: if the training is terminated in the middle of the cycle, resulting weights are not a solution because for large enough cycle number n we have  where b is a number of step within the learning cycle after which we stopped learning. It can be seen from (12), that the weights oscillate periodically around the solution and are close to it only after the end of each cycle. This is apparently the only disadvantage of the method which has to be paid for the very rapid training convergence of this algorithm.

w. EXPERIMENTAL RESULTS AND CONCLUSIONS Simulation of learning efficiency using the new  modified supervised Hebbian rule has been tested on a number of cases, including pattern classifier described below. Non-augmented continuous inputs have been fed to a single-layer network with bipolar neurons having continuous characteristics. The new algorithm has shown much better performance than both a regular supervised Hebbian learning and competitive unsupervised learning which have been used in the comparative study. The same learning constants q=O.l were used for all algorithms, a=O.8 was used for decreasing q in the first algorithm.

Results of these three experiments are shown on figures below. On Fig.1 and Fig2 changes of weights of one of the neurons are presented (the slowest one) during all steps of     wcighb  ? 1 0 I  h u g  .$ckdcs Fig.]. Weight changes during leaning: B) Hebbian mthod b) competitiw mthod  c) modified Hebbian mctbod  learning cycles. Fig.la illustrates the case of supervised Hebbian learning, Fig. l b  unsupervised competitive learning, Fig.lc and Fig.2 are for modified Hebbian learning rule. It can be seen from Fig.2 that weights are changing periodically every training cycle.

The well-trained networks from Fig.la and Fig.lc will respond every time to a pattern from one set by activating only one neuron, responsible for that particular data. The network from Fig.lb, trained according to the winner-take-all algorithm shall respond with one neuron with the highest activation than others, and therefore, negative output of other neuron is not required.

200 m i  i  0 5 t  -0 5 t  -1 0 ; -  output.

1 o ? - -  0 5 j  0 o +  -0 5 t  -1- 15 20  Fig.3. Wont ax of output changes during Ielming: a) Hcbbian mcthod b) compctitiw mctbod e) modified Hebbim mcthod     Clearly, the movement of weights is not as important as the overall output performance of network. Fig3 and Fig.4 illustrate the output of one of the neurons for each method tested after each learning step during the cycles using one of the learned patterns. The graphs highlight the case of the slowest learning. It can be seen that both Hebbian and competitive learning are worse than the proposed algorithm while tested at the end of each training cycle.

The new modified Hebbian learning rule produces the well trained network after the fourth learning cycle. On Fig.4 it can be seen that for best results learning preferably should be stopped at the end of a learning cycle.

a t p u b I O ,  -_ *  i  a o i  I /-\  The end-of-training condition can be specified as unchanged network responses to the training patterns at the end of a cycle in comparison to response at the previous end of cycle compared with certain accuracy. Outputs stable in this sense indicate that learning is complete.

The new algorithm has also been tested for the case of unsupervised Hebbian learning phase which follows the supervised training phase. It can be observed on FigSa that a well trained neuron changes his response during unsupervised learning performed with initial weights obtained from supervised experiment. FigSb presents another neuron which has improved its performance during unsupervised learning.

The new supervised learning algorithm is numerically less complex than most classical supervised learning algorithms because no need exists here for evaluating network response in every learning step,It is about of the same complexity as supervised Hebbian learning but it shows, in general, faster convergence. It represents therefore, a valuable modification of Hebbian learning, especially for large layers trained on large number of input patterns.

outpab  FigS. Ncurmu' output to one of the ptbxnr - unrupclviscd lconing folloaring aupctviscd lemming.

