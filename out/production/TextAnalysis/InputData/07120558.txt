A Novel Parallel Algorithm for Frequent Itemset Mining of Incremental Dataset

Abstract?Most Algorithms for frequent itemset mining  typically make the assumption that data is centralized or static.

They may waste computational and I/O resources when the data is dynamic, and they impose excessive communication overhead when the data is distributed. As a result, the data mining process is harmed by slow response time. In this paper we propose a novel algorithm that uses overlapping data partitions and parallelizes the workload among machines efficiently.

Experiments confirm that our algorithm results in excellent running time improvements.

Keywords?frequent itemset, parallel mining, incremental mining

I. INTRODUCTION1 Frequent itemset mining is an important subject in many  data mining applications, such as the discovery of association rules, correlations, sequential rules and episodes.

A great number of algorithms have been proposed for frequent itemset mining. But most algorithms assume that the dataset is centralized or static and the algorithm can use unlimited computational and I/O resources. However, in most cases this assumption does not hold. Many datasets are updated with blocks of data at regular time intervals. For example, data warehouses are always updated at large intervals and data streams are updated at small intervals.

Moreover, as the size of many datasets gets larger and larger, the resource requirement is unacceptable for one machine.

Those algorithms may waste computational and I/O resources when the data is dynamic, and they impose excessive communication overhead when the data is distributed. How to guarantee a reasonable response time for data mining applications is quite difficult in huge time-evolving datasets.



II. RELATED WORK There has been a lot of research in developing efficient  algorithms for frequent itemset mining. The most traditional method is Apriori[1] algorithm which generates level-wise candidates and scans the dataset to calculate the support count of each itemset. It may scan the dataset many times.

Han et al.[2] proposed the FP-growth algorithm which utilizes a creative data structure, FP-Tree. FP-tree takes the advantage of common paths to record the sorted frequent   Project supported by the National Natural Science Foundation of China (Grant No. 41376178).

items in transactions. The algorithm just need scan the dataset once. Although FP-tree is more concise than the dataset, it may have huge space requirement for large datasets.

The problem of maintaining frequent itemsets is first studied in [3]. That paper proposes the FUP algorithm, which can update frequent itemsets in a dataset when new transactions are added to the dataset. It is based on the framework of Apriori and finds new frequent itemsets iteratively. The FUP2[4] algorithm, adapted from FUP, can simultaneously handle deletions and additions. Lee and Chenug[5] proposed the DELI algorithm, which is based on the framework of FUP2. DELI uses statistical sampling methods to determine when to update frequent itemsets.

Three parallel versions of the Apriori algorithm were introduced in [6].The paper concludes that the Count Distribution approach performs the best. The FDM[7] and DMA[8] algorithms result in fewer candidate itemsets and smaller message sizes compared to the Count Distribution algorithm. Veloso[8] proposed a shared-memory algorithm that parallelized the search for maximal frequent itemsets in an incremental manner.

Some efforts[9][10] parallelized the FP-Growth algorithm across multiple threads with shared memory.

PFP[11] algorithm takes the MapReduce approach of parallelizing the FP-Growth algorithm. PFP divides one entire mining task into independent subtasks and maps them onto MapReduce jobs. This parallel algorithm has to scan the whole data and cannot make use of previous results.



III. PFUP: PARALLEL FUP PFUP shards a large-scale mining task into independent,  parallel tasks with the usage of overlapping data partitions. It borrows some ideas from FUP in the local mining process on each machine. In this chapter we first describe the key points of FUP algorithm and then present our parallel FUP algorithm, or PFUP.

A. FUP The idea of FUP is to store the counts of all the frequent  itemsets found in a previous mining operation. Using these stored counts and examining the newly added transactions, the algorithm can generate a very small number of candidate itemsets. The overall count of these candidate itemsets are then obtained by scanning the original database.

DOI 10.1109/ICISCE.2015.18    DOI 10.1109/ICISCE.2015.18    DOI 10.1109/ICISCE.2015.18    DOI 10.1109/ICISCE.2015.18     Consequently, all new frequent itemsets are found. The FUP algorithm is very efficient.

The details of FUP are as follows:  1.First Iteration. FUP scans the new dataset db and calculate the support counts of all items occur in db. On one hand infrequent items in L1(L1 is the frequent items in the original dataset DB) are removed based on the support counts in db and DB. On the other hand, a set C1 is created, which contains all frequent items in db except the items in L1. Then FUP scans DB and finds the support counts for all itemsets in C1. By checking their support counts, new frequent items ???  are found by combining with those identified items in L1.

2.Second iteration and beyond. Ck(Ck is the set of candidates of size k ) is generated by join operation on ???? ? (the set of frequent itemsets of size k-1 in DB db). Ck  can be divided into two subsets. The first subset contains frequent itemsets in DB. The second subset is the remaining itemsets of Ck, which are infrequent itemsets in DB. Similar to the first iteration, the algorithm first scans db to find support counts of Ck. Then FUP scans DB to calculate support counts of some itemsets in the second subset, which are frequent itemsets in db. Note that support counts of frequent itemsets in the first subset in DB are already known. At last ???  can be concluded based the above information.

B. PFUP outline Unlike most parallel algorithms, PFUP algorithm adopts  a novel mechanism to divide the dataset into a group of partitions, which are allocated into different machines. For most parallelled/distributed algorithms, the dataset is divided into non-overlapping partitions. In the case, an itemset that is locally frequent in one partition may be globally frequent in the dataset. In order to decide a globally frequent itemsets, these algorithms has to scan all partitions to collect support counts of the itemset. As the number of machine increases, the efficiency of algorithm decreases significantly. On the contrary, PFUP uses overlapping partitions which is named by group-dependent partitions. PFUP can find a set of frequent itemsets independently in one partition, which save a lot of resources on exchanging information in a parallel environment.

Given a group of machines(the number of machines is n), the original dataset DB(DB=DB1 DB2... DBi...

DBn, DBi is allocated to i-th Machine), the set of frequent itemsets F(F=F1 F2... Fi... Fn, Fi is the set of frequent itemsets of DBi) and the incremental dataset db, the main steps of PFUP are described as follows.

Step 1: Partitioning: Dividing db into n partitions and storing the partitions on n different machines respectively.

Step 2: Updating frequent itemsets: the key step of PFUP. PFUP generates a new set of frequent itemsets of DBi dbi.

Step 3: Aggregating: aggregating the results generated in Step 2 as the final result.

Step 4: Optimizing: changing the distribution of frequent itemsets and the dataset to balance the workload of different machines.

1) Partitioning Incremental Dataset We assume that the set of items, I, has been divided into  n groups. I=I1 I2... Ii... In, Ii is a set of items, Ii Ij= (i j). According to this grouping strategy, the incremental  dataset db is partitioned as follows:  db1 : transcations contain items in I1;  db2: transcations contain items in I2 except the transactions merely contain items in I1 I2  ...

dbi: transcations contain items in Ii except the transactions merely contain items in I1 I2... Ii  ...

dbn: transcations merely contains items in In.

When PFUP deals with the first incremental dataset (DB= ), it divides the items into n groups evenly. The grouping strategy is not fixed and can be changed in the later mining process in step 4.

2) Updating frequent itemsets In this step our solution is to use a slightly modified  FUP algorithm. PFUP limit the range of candidate itemsets.

In i-th partition DBi dbi it processes itemsets that contain items in Ii and don't contain items in I1 I2... Ii-1. In the first Iteration, it neglects the items in I1 I2... Ii-1. In the second Iteration or beyond, it neglects the itemsets that don't contain items in Ii.

3) Aggregating frequent itemsets As we use overlapping partitions, each frequent itemset  in Fi is also a globally frequent itemset. In the step the algorithm only need collect Fi from each machine.

4) Optimizing load among machines Balancing load among all machines plays a key role in  improving parallelization of the mining process. However, it is hard to computing precise load. We use the number of frequent itemsets to simulate the load of each machine. As the composition of frequent itemsets is not static and may change slightly after completing each incremental dataset, the algorithm doesn't keep the absolute average of the number of frequent itemsets on each machine. It redistributes frequent itemsets only when the maximal number of frequent itemsets is three times bigger than the minimal one. We assume the size of Fm is three times bigger than Fn. The algorithm moves the item with the largest frequency in Gm into Gn to balance the load of two machines. The distribution of frequent itemsets is modified as follows:     There are two possible cases:  1) m<n:  Fm: Itemsets that don't contain other items except  in Gm are removed (These deleted itemsets is denoted by D).

Fi(m<i?n): Subset of D that contain  and items in Ii and don't contain any item in Im Im+1 .. Ii-1 are inserted.

2)m>n:  Fi(n<i?m): Itemsets that contain  are removed (These deleted itemsets on i-th machine is denoted by Di) .

Fn: Dn+1 Dn+2 ... Dm-1 are inserted.

Transactions are also redistributed using the similar method as above. Normally, as this step is executed only when necessary and just require the transfer of a small fraction of the dataset and frequent itemsets, PFUP doesn't spend much time on this step.



IV. EXPERIMENTAL RESULTS We used a cluster of 4 nodes. All nodes have the same  hardware and software configuration. Each machine has two 2.4GHz Intel Xeon processors and 8GB memory, the OS is Windows 2008 Enterprise Server, the C++ compiler is Microsoft Visual Studio 2012. The experimental data is a synthetic datasets T10 are generated by the IBM data generator[12] and mimic transactions from retail stores. For T10, the number of items, the average size of transactions and the average size of the maximal potentially frequent itemsets are 1000, 10 and 4, respectively.

We compared the execution time of PFUP against FUP with different support values. The size of each incremental db is 10K and two support thresholds are 0.07% and 0.1%.

Figure 1-2 shows results of experiments. Obviously, PFUP outperforms FUP. Moreover, we can observe some interesting trends:  a)As the dataset grows larger, the performance gain of PFUP is clearer.

b)In contrast with FUP, PFUP shows better performance for small support thresholds than large support thresholds.

The above fact implies that PFUP can handle large datasets or large size of frequent itemsets well.



V. CONCLUSION The paper focuses on the problem of parallel frequent  itemset mining in dynamical datasets. We proposed and evaluated a balanced parallel algorithm in an incremental manner, which improves the performance of FUP algorithm by balancing load of finding frequent itemsets. In the next stage, we are looking forward to improving performance by using concise representation of frequent itemsets.

