Mining Efficacious Association Rules under Length-Decreasing Support Constraint

Abstract?In mining association rules, Itemsets with high- length usually has lower support, but still have potential value.

To mine efficacious association rules under long-pattern, a new mining method of efficacious association rules is proposed under length-decreasing support constraint. Compare to other mining methods of association rules, the new method can mine more efficacious long-patterns and improve correlation between the antecedent and the consequent of the rules.

Keywords-association rules, correlation, length-decreasing support, match

I.  INTRODUCTION Data Mining is an active research area and one of the  most popular approaches is discovering association rules. At present, the main research work about association rules includes efficiency analysis and correlation analysis. In the aspect of improving the efficiency of mining frequent itemsets, since R.Agrawal et al firstly introduced the association rules mining algorithm Apriori [1], many researches have done to make corresponding improvements according to the shortage of Apriori. FP-growth [2] is an improved mining method which doesn?t generate candidate itemsets and has higher efficiency. But it has several disadvantages, such as the constructed FP-tree is too large, the algorithm is too complex and the generated FP-tree doesn?t certainly fit into the main memory at a time.

Frequent closed itemsets mining algorithms, such as A-Close [3], CLOSET [4], CHARM [5], CLOSET+ [6] and FPClose [7] etc can reduce the redundant in the frequent patterns. The difficulty of frequent closed itemsets mining algorithms is to check whether itemsets are closed. Frequent closed itemsets mining algorithms generate a relatively smaller result set, so the algorithms have better expansibility and intelligibility.

Aim at the correlation of the generated rules. In order to make the rules more interesting, researchers have put forward a number of metrics of interestingness. In [8] three types of metrics (any-confidence, all-confidence, and bond) are proposed to take place of support. In [9] a new metric of interestingness by using the information of classification is proposed. It gives a definition of interestingness: the support of rule is R times more than expected, or the confidence is R times more than expected. R is a constant specified by user.

In [10] an improvement is made based on interestingness in [9]. It took account of generalization as well as specialization. In [11] a measure of interestingness is derived from the correlation of statistics and it is defined as  P(AB)/sqrt(P(A)P(B)) . It contains two important factors: interest factor and support. In [12] a significance measure for association is proposed by making use of 2?  correlation test.

Its interestingness is defined as IS=P(AB)/(P(A)P(B)) .

Because of the shortcomings of symmetric interestingness in [12], in [13] Certainty: P(A) P(?B)/P(A??B) is proposed.

But it is anti-symmetric for the rules. In [14] a framework based on correlation is proposed. In this framework, it uses residual analysis to determine whether two items are independent. In [15] a method based on linear regression and reverse authentication is presented to verify the correlation of the association rules. The method is based on the analysis of the correlation of the incident and verifies the generated rules through the selected time period. Therefore, how to select the size of time period will become an issue which is worth exploring.

The existing association rules mining algorithms are mostly studying on the efficiency and correlation analysis.

So it is hard to mine the long itemsets with low support.

Therefore, this paper did some corresponding analysis and proposed a length-decreasing support constraint to mine long itemets, then combined the effective association rules mining method to mine the association rules.



II. THE BASIC PROBLEM Given a transaction set D, mining association rules is to  find the rules whose support and confidence are respectively larger than or equal to the minimum support threshold ( minsup ) and minimum confidence threshold ( minconf ) given by user. Therefore the association rule mining can be divided into two sub-problems as follows:  Find out all the itemsets, the support and confidence of which are larger than or equal to the minsup  required by the customers. The itemsets with minsup  are called frequent sets.

Set up association rules through frequent sets. Finding out all M?s non-empty subsets ms to each frequent set M.

Association rule m (M-m)?  can be obtained if support(M)/support(m) minconf? .

support(M)/support(m)  is defined as the confidence of the rule m (M-m)?  where m  is the antecedent of the rule and M m?  is the consequent of the rule.

DOI 10.1109/AICI.2010.269    DOI 10.1109/AICI.2010.269     The traditional association rules mining uses fixed minimum support threshold, thus it is unable to extract the frequent patterns with low support and it can?t reflect the changing of the minimum support of itemsets with different length. Besides, the traditional association rules mining adopts confidence threshold. Confidence can denote the probability that some itemset? emergence will lead to others? occurrence. But we notice that the confidence of association rule F=>E only considers the possibility of the case when E and F will occur simultaneously, without considering the possibility of the case when only E occur and the case whether E and F are correlated. Then many association rules obtained are ineffective.



III. LENGTH-DECREASING SUPPORT CONSTRAINT  A. The Formula of Length-Decreasing Support According to the above-mentioned problems, this paper  proposes a new length-decreasing support constraint to mine those long patterns which have low support but have potential value. Considering that the changing of the support can not only reflect the requirement of the minimum support for different long itemsets, but also can aim at datasets from different fields, the correlation coefficient is need to be capable of adjustment. Therefore, we define the calculation function as follows.

-2 2a k+b+c 1-d k (k<max_length)f(k)= s (k max_length)  ?? ? ? ?  ??? (1)  where k is the length of the itemset, a, b, c and d are coefficients (a<0,b>0,0<c?1, d>0), s is a constant, and max_length denotes the maximum length. When the length of the itemset reaches the threshold given by experts, the corresponding minimum support will get the value s and no longer reduce. The maximum support threshold is f(1), that is, it is the support threshold of itemsets whose length is 1, f(1)= -2a+b+c 1-d? <1. The minimum support threshold is f( max_length )=s>0. So the range of f(k) is [s, f(1)].

How to determine the parameters For example, when ( )f k  is selected as the elliptic  function curve, we can use the following value to compute the parameters.

2f(1)=c 1 d ?? ?                                  (2)  ( (max_-2 2f max_length)=c 1-d length) s? =          (3) The significance of the formula  The formula contains linear function and elliptic function so as to do corresponding adjustment according to datasets from different fields. When the minimum support of frequent itemsets with different length decrease linearly, we can set the parameter c to zero; when meet elliptic diminishing relations, we can set both a  and b  to zero; when adjusting the minimum support curve with different length, we can respectively set the corresponding coefficients and obtain a combination of linear function and elliptic function. Fig. 1 shows the relationship between ( )f k  and k.

B. related properties Property 1 x y? ? , then ( ) ( )support x support y> .

Property 2 Any itemset whose length is k satisfies:  f(1)?f(k)?f(k+1), then f(k) is called a length-deceasing support constraint to the transaction database.

Property 3 Any itemset x whose length is kx satisfies: xsupport(x) f(k )? , then x is called a frequent itemset that  satisfies a length-deceasing support constraint.

Property 4 The property of smallest valid extension  (SVE): Assume itemset x and itemset y, their length are kx and yk  respectively and x y? , support(x)<f(kx). Then the necessary condition that y is a frequent itemset to ( )yf k  is  yk ? -1f (support(x)) .

In our problem, an itemsets can be frequent even if its subsets are infrequent. So the traditional way to mine association rules loses effectiveness in removing the candidate itemsets. Therefore, we mainly use Property 4 and the constant s to discard non-frequent itemsets.



IV. EFFICACIOUS ASSOCIATION RULES According to the problems discussed above, this paper  considered the correlation between the antecedent and consequent of the generated rules, and then applied the framework of support-match to produce association rules by combining the existing the research results [16]. Match is defined as follows:  Assume P(A) denotes the probability that A occurs, P(B) denotes the probability that B occurs, P(AB) denotes the probability that A and B occur simultaneously, P( AB ) denotes the probability that A  and B occur simultaneously, P( A ) denotes the probability that A doesn?t occurs. Then, we define the match of rule A B?  as match = (the confidence of A B? )-(the confidence of A B? ), that is:  P(AB) P( A B)match= - P(A) P( A )  (4)  To facilitate the understanding and calculation of the formula, the above formula can be transformed as:  Figure 1.  the curve of minimum support function  Length of itemsets  linear  elliptic  max-length 1   f(1)  f(max-length)     P(AB)-P(A) P(B)match= P(A) (1-P(A))  ? ?  (5)  We make the declaration that an itemset is unrelated to any other itemset when its support is 1, in which case we can overlook the match of this item set with other item sets.

Consequently, the probability for any itemset A?s occurrence is 0< ( )P A <1. The range of match is [-1, 1] because 0< ( ) / ( )P AB P A ?1, 0< ( ) / ( )P AB P A ?1. If match>0, we have ( ) ( ) ( )P AB P A P B> , which proves that A and B are correlated. If match=1, we have ( ) ( ) ( )P AB P A P B= = , which indicates the case that A and B appear simultaneously.

Furthermore, we analyze the match theoretically. We define the concept of correlation.

P(AB)cor= P(A) P(B)?  (6)  1 P( AB)cor P( A ) P(B)  = ?  (7)  Hence, we have ( 1) ( )match cor cor P B= ? ? . We will get 1 1cor cor= = when cor  equals to cor1 for the reason that  1 P(A)1 1 P(A) corcor ? ?= ?  . That is to say, A is unrelated to B  when A is unrelated to B. Moreover, 1cor  will be smaller than 1 while cor  is bigger than 1. In other words, A is negatively correlated to B if A is positively correlated to B.

We can also find from the equation that the definition of match not only includes some correlation factors but also some ( )P B  factors. Therefore, it can reveal the validity of rule A=>B with the definition of match.



V. EXPERIMENTAL RESULTS AND ANALYSIS The paper uses the adult database to verify the  effectiveness of the proposed algorithm. Experiments are carried out on an IBMR52 notebook computer with 512M memory and 1.86GHz main frequency. The numerical attributes need to be discretized and we extract 24000 records from the database. The objective of the experiments is to test whether the algorithm can dig more effective long patterns and improve the correlation between the antecedent and consequent of the rules under long patterns.

Experimental settings are as follows:  The Formula of Length-Decreasing Support adopts -2 2f(k)=c 1-d k? , where (1) 0.3f = , f(max_length) =0.5, max_length =5, and the minimum  match=0.3. The experimental result is shown in Fig.2.

When the number of records is 24,000, we extract two  rules to do analysis: frequent itemset 14,11,12,19,23, rule 14=>11,12,19,23, support=0.39, match=0.34; frequent itemset 13,14,11,19,23, rule 13,14=>11,19,23, support=0.45, match=0.31. If we use a constant minimum support, the above itemsets whose length is 5 can?t be frequent, not to mention generating rules. But if we use a length-decreasing support constraint, they will meet the requirement and  generate association rules. Therefore, the method proposed in this paper can not only mine the long patterns with potential value, but also can obtain efficacious association rules.



VI. CONCLUSIONS In order to discover the long patterns with potential value  and remove the invalid short patterns in intensive database, this paper proposes a new length-Decreasing Support Constraint and combines the framework of support-match to generate association rules. Theory and experimental results have proved that the proposed method can not only discover the long patterns with potential significance but also can generate efficacious association rules. We can believe that the proposed method has high theoretical and practical value in the study of intensive data or decision support fields.

