Efficient Incremental Itemset Tree for Approximate  Frequent Itemset Mining On Data Stream

Abstract?Mining frequent itemsets and association rules on data stream is an important and challenging task. Tree based approaches have been extensively studied and widely used for their parallel processing capability. Itemset Tree is an efficient data structure to represent the transactions for performing selective mining of frequent itemsets and association rules. The transactions are inserted incrementally and provide on-demand ad-hoc querying on the tree for fining frequent itemsets and association rules for different support and confidence values.

However the size of tree grows larger for unbounded data streams limiting the scalability.  In this paper, we propose an Approximation based Incremental Memory Efficient Itemset Tree (AIMEIT) algorithm which is an extension to Memory Efficient Itemset Tree (MEIT) algorithm to construct the itemset tree from data stream. The user defined minimum support of interest has been used along with Lossy counting algorithm to prune transactions before inserting them into the tree.

Experimental results show that the proposed algorithm is more memory efficient and takes lesser processing time for constructing the tree.

Keywords?data mining, itemset tree; frequent itemset; assocition rule; lossy counting; data stream

I.  INTRODUCTION Frequent Itemset mining is a process to effectively and  efficiently mine frequently occurring set of items and discover correlation among them in a transaction database. Several algorithms have been proposed to find frequent itemsets in a static database. Mining frequent itemsets on large volume of high velocity streaming data is being focused in the recent years. Mining frequent itemsets in streaming data is more challenging as frequent items may become infrequent and infrequent items may become frequent as time elapses. Also due to the rapid flow of the data, the algorithms will have only one chance to parse the data. so of the batch processing algorithms are found to be not suitable for mining streaming data due to its high velocity, volume and drift in the concept.

Many incremental algorithms have been proposed which store all or approximate frequent items satisfying a given minimum support. These algorithms generate frequent itemsets which satisfy the given minimum support and don?t construct a data structure for storing these items for future reference. Users cannot perform selective mining by querying the data for finding frequent itemsets or association rules for different support and confidence thresholds. This is due to the  fact that the volume of the streaming is so huge that it cannot be stored and processed at real-time. It requires of huge amount of memory to hold the data for quick processing. For today?s fast evolving business needs, constantly changing requirements, on-demand, ad-hoc querying is very essential.

In this paper, we propose a memory efficient data structure which is constructed incrementally and provides the flexibility to dynamically query for approximate frequent itemsets and association rules with no false positives.

This paper is organized into following sections: Section II provides the review of related work, Section III details the problem statement, Section IV describes the proposed AIMEIT algorithm, Section V provides the experimental results and characteristics of the datasets used in those experiments. The conclusion and future research is provided in Section VI.



II. REVIEW OF RELATED WORK There are many algorithms that have been proposed to  build tree for frequent itemset mining from data streams. The Pre-FP Tree[1] and Itemset-TidSet-Tree (IT-ITree)[2] are proposed to incrementally generate the itemset tree from streaming data. The Pre-FP Tree is a based on FUFP-Tree.

FUFP-Tree is a regular FP-Tree with bidirectional links between the child and parent nodes. Both Pre-FP Tree and IT- Tree algorithm categorizes the itemsets as frequent, pre-large and infrequent in the original database and the stream window, and handles the insertion of the itemsets based on their category in original database and window stream. It maintains additional tables to maintain the pre-large itemsets for future insertion into the original tree. Maintaining additional tables is a memory overhead. It is also processing intensive as it has to read the original tree to get the different categories of itemsets while processing each stream window.

The canonical ordered tree (CAN-Tree)[3] reads the transactions and arranges the tree nodes according to some canonical order. The user shall mention the canonical order before the tree construction or during the mining process. The algorithm finds the frequent itemsets for pre-Minimum Support value which is usually less than the actual minimum support and builds the tree in the canonical order defined earlier. It is efficient in terms of quality of tree as it stores only frequent itemsets but lacks on the processing time and memory usage. For large window size, more time is spent in     finding the frequent itemsets before inserting them into the tree. The data structure used to construct tree can also be improved for memory efficiency.

The Generate and Merge Tree (GM-Tree)[4] is based on the CAN-Tree. In GM-Tree, the frequent itemset tree is generated for every stream window and then merged with the original tree. The generation of itemset-tree for transactions in stream window works in the batch mode which requires parsing of the data twice. First parse to order the transactions and second to build the itemset-tree. Also the time complexity increases as the stream window size increases.

The Incremental Mining Binary Tree (IMB-Tree)[5] requires the data to be stored in the database first and then the transactions are extracted one by one to build the lexicographic tree to store the generated frequent itemsets. The tree is a binary tree i.e. each node can represent maximum of two itemsets. The child node contains itemset of the parent node as well which makes the tree grow bigger for large, sparse dataset.

Many other data structures have been proposed such as Array-Tree[6], BFP-Tree[7], Ordered-Tree[8] etc which lack the capability of incrementally mine the high volume data stream due to their batch processing nature.

Most of the trees proposed represent the format of Itemset Tree[9] which provides a lossless representation of transaction. It is an efficient representation of the itemsets and can be built incrementally. The tree can be dynamically queried. However the major limitation of this tree is that it consumes huge amount of memory. This limitation has been overcome by Memory Efficient Itemset Tree (MEIT)[10]. In this algorithm the parent node information is not duplicated in the child node unless in the itemset tree. Also the leaf nodes contains the itemsets rather than single items if their support is same thus reducing the size of the tree.

The MEIT algorithm has been used as the base for the proposed faster incremental algorithm for its simplicity and memory efficiency.



III. PROBLEM STATEMENT  A. Preliminaries Consider a set of distinct items I = {i1,i2,i3,?in}. A subset  of set I is called as an itemset. Let T be the set of transactions {t1, t2, t3,?,tm} where each transaction t contains subset of I.

An itemset is said to be frequent if the count of occurrence of the itemset in the complete transaction is more than the given threshold called minimum support. A data stream is an unbounded list Ds = {t1,t2,t3,?} of transactions arriving at the processing node sequentially.

The items in the transactions are arranged in the lexicographical order before inserting them into the tree.

B. Problem Definition ? The MEIT algorithm stores every transaction in the  tree in form of itemset without pruning the infrequent itemsets. For sparse datasets, the size of the tree grows with large number of low interest itemsets which may never be mined consuming large memory.

? Large size of the tree also affects the query processing time as the algorithm needs to parse through different branches of the tree to serve the query.

? Pruning all infrequent itemsets from the stream window before inserting them into the tree becomes time consuming when the data is dense i.e. large number of frequent itemsets are generated or window size is large.



IV. AIMEIT ALGORITHM  A. Determining Window Size The fixed sized window is adopted to buffer the streaming  transactions. The size of the window (WS) is determined by the user minimum support of interest (SI) and acceptable support error  as given below;    The above equation sets the safer window size to pruning infrequent items safely.

The  is considered with respect to SI provided by the user.

For example, if SI = 0.2 and  = 0.1 then it means the error can be ?10% of the SI i.e. minimum support can vary between 0.22 and 0.18.

B. Determining Delta The Delta value is the local minimum support that items  should satisfy to be called as frequent in the given stream window. The Delta value is determined using the minimum support of interest SI and acceptable support error  using the equation given below;    Example: if SI = 0.2 and  = 0.1, then WS = 50 and Delta = 9. Notice that the Delta value is just below the user specified minimum support interest which will avoid any border itemset getting pruned.

C. Algorithm Input: SI,  , Transactions from Stream Window Output: Itemset Tree 1: Determine Window Size WS 2: Determine Delta value 3: Read Transaction Stream 4: if buffer size reached Window Size then 5:     for each Transaction t in Stream do 6:         Extract 1-itemsets and Update their Support Count 7:     end for 8:     for each 1-itemset do 9:         if Support Count < Delta then 10:             remove the 1-itemset from Transactions 11:        end if 12:     end for 13:     MEIT.Insert (Ordered Modified Transactions) 14: else 15:     Repeat Step 3 16: end if     The AIMEIT algorithm uses the MEIT algorithm for constructing the tree and adds a pre-processing stage to prune the infrequent items from the data stream before inserting the transactions into the tree. The algorithm is split into five major steps. First, the window size for buffering the data stream is determined (line 1). Second, the delta value used by the Lossy counting algorithm for pruning infrequent itemsets is determined using the user specified minimum support of interest SI and acceptable error  (line 2). The transactions are read and stored in the buffer till the buffer size reaches the window size (line 4 and 15). Third, the support of 1-itemsets in the given stream window is found (line 5 to 7). Fourth, using Lossy counting algorithm, the infrequent 1-itemsets are removed from the transactions (line 8 to 12). The transactions will then contain only those items which are frequent in the given stream window. Fifth and last step, the modified transactions are incrementally added into the MEIT (line 13).



V. EXPERIMENTS AND PERFORMANCE ANALYSIS In this section, the details of the dataset used for  experimentation and results of the experiments are reported.

All experiments were perfomed on Dell Inspiron 3537 with Intel i5 CPU, 8 GB memory and Ubuntu Desktop 14.04 LTS operating system. The algorithm is implemented using Java JKD version 1.8. In the experiments, the proposed algorithm is compared with the MEIT implemention in SPMF open source data mining library using widely used synthetic and real datasets.

The T10I4D100K and T40I10D100K are synthetic datasets generated from the IBM Almaden Quest research group[11]. The Retail dataset is an anonymized retail market basket data from an anonymous Belgian retail store [11]. The Accident dataset contains the traffic accident data obtained from the National Institute of Statistics for the region of Flanders, Belgium for the period 1991-2000[11]. The characteristics of these datasets are given in Table I.

TABLE I.  DATASET CHARACTERISTICS  Transactions Count  Distinct Items Count  Minimum Transaction  Length  Maximum Transaction  Length T10I4D100K 100000 870 1 29 T40I10D100K 100000 942 4 77 Retail 88162 16470 1 76 Accident 340183 468 18 51    The datasets were evaluated for different support threshold to find the distribution of density of frequent itemsets. The number of frequent itemsets for support threshold ranging from 0.01 to 1 is given in Table II. Due to memory and processing limitation on the hardware, the frequency count for accident dataset in Table II for support lesser than 0.1 is given as Very Large to denote that the frequent itemset counts are larger than the count at support 0.1.

From Table I and Table II we can infer that the Accident dataset is found to be very dense. Next to it is the TK0I10D100K dataset. Retail and T10I4D100K datasets are sparse.

In the experiments, as shown in the Fig. 1 and 2, the following observations are derived: The memory consumed to generate the itemset tree using the proposed AIMEIT algorithm is reduced by average of 60% for sparse datasets and 3% for very dense dataset compared to MEIT algorithm.

The processing time taken to construct the itemset tree by AIMEIT algorithm is reduced by average of 43% for sparse data and increased by 52% for dense data.

TABLE II.  FREQUENT ITEMSET DISTRIBUTION IN DATASETS  Minimum Support T10I4D100K T40I10D100K Retail Accident  0.01 385 65236 159 VERY LARGE 0.02 155 2293 55 VERY LARGE 0.03 60 793 32 VERY LARGE 0.04 26 440 18 VERY LARGE 0.05 10 316 16 VERY LARGE 0.06 4 239 15 VERY LARGE 0.07 2 183 13 VERY LARGE 0.08 0 137 13 VERY LARGE 0.09 0 110 12 VERY LARGE 0.1 0 82 9 10691549 0.2 0 5 3 889883 0.3 0 0 3 149545 0.4 0 0 2 32528 0.5 0 0 1 8057 0.6 0 0 0 2074 0.7 0 0 0 529 0.8 0 0 0 149 0.9 0 0 0 31 1.0 0 0 0 0    As only infrequent 1-Itemsets are pruned before inserting into the tree, there may be k-itemsets in the tree which are not frequent. This overhead is compromised for the reduced processing time for constructing tree to enable the algorithm for real-time processing.

Fig. 1. Memoary Utilized for Constructing Itemset Tree using AMEIT and MEIT Algorithms       Fig. 2. Processing Time Taken for Constructing Itemset Tree using AMEIT and MEIT Algorithms

VI. CONCLUSION AND FUTURE WORK This paper described the Approximation based Incremental  Memory Efficient Itemset Tree (AIMEIT) which is a compact data structure for storing itemsets facilitating dynamic querying for frequent itemsets and association rules. The tree prunes only 1-itemsets from the transactions before inserting them into the tree to avoid pruning of itemsets which can be potential frequent items in future. The algorithm is very robust for sparse data and its performance reduces for highly dense data. Setting higher minimum support of interest (SI) shall make the algorithm efficient for dense data but a mechanism shall be employed to detect the density of the data and adjust the SI accordingly.

In the future work, the algorithm shall be made adaptive to both sparse and dense data, and improve the pruning strategy.

The algorithm can be redesigned for parallel processing on large cluster of computers scaling it for Big Data Stream.

