Novel Sensitive Information Preserving Mining  (SIPM) Algorithm for Association Rule Mining in

Abstract?- The recent advancement in data mining technology to analyze vast amount of data has played an important role in several areas of Business processing. Data mining also opens new threats to privacy and information security if not done or used properly. The main problem is that from non-sensitive data, one is able to infer sensitive information, including personal information, fact or even patterns which are generated by any algorithm of data mining.  In order to focusing on privacy preserving association rule mining, the simplistic solution to address the problem of privacy is presented. The solution is to survey different aspects which are discussed in the several research papers and after analyzing those research papers conclude a new solution which is best in efficiency and performance. In this paper we propose a novel algorithm named Sensitive Information Preserving Mining (SIPM). The entire system architecture consists of three phases: 1) Check for Authentication. 2) Reading the database.  3) Perform Pruning.

Our algorithm is a good way to apply data mining techniques with security that hides our logical instances from others.

Keywords: Data Mining, Association Rule Mining, Privacy Preserving, SIPM

I. INTRODUCTION In 1993[1], the association rule mining has received a great  deal of attention. It is still one of most popular pattern- discovery methods in the field of data mining. Various proposals and algorithms have been designed for it in recent years. Simultaneity, Data mining algorithms are analyzed for the side-effects which incur in data privacy. Thus, several privacy-preserving techniques for association rule mining have also been proposed in the past few years. Various proposals and algorithms have been developed for centralized data, while others refer to a distributed data scenario.

Distributed data scenarios can also be classified as horizontal data distribution and vertical data distribution.

Data mining technology can analyze massive data.

Although it plays vital role in many domains, if it is used improperly it can also cause some new problem of information security. There are some new problems in the application of data mining recently.

By studying deep in some special algorithms with association rule mining, some techniques also can be  applied to other data mining computations, such as decision tree inducers, association rule mining algorithms, clustering algorithms, rough sets and Bayesian networks etc.

Fast increasing of a series of digitized data causes people of the world attend the privacy problem of information more and more. Because the data mining technology of traditional centralized database must collect all the data together to process, it will cause the individual information abused or misused easily. Therefore more and more people will not to provide individual privacy data and suspect the using of data mining. Some people mine the privacy information pattern of the database owner from the original data. It has harmed the database owner's benefit. In order to solve the privacy preserving problem of association rule in centralized database, before publishing database we should hide the privacy or the sensitive information pattern of the database owner including the sensitive association rule information [2, 3]. Usually we use disturbing data method to change the data of original database to hide association rule. But the data disturbance may generate some information pattern that is not existed at all or reduce the accuracy of the original database. Before executing the privacy preserving algorithm, we should analyze the information pattern of association rule and the data structure of the database and find the preferred plan to keep the balance between the accuracy of database information and the privacy of sensitive information.

However, data mining also brings some problems.

For example, credit card centres may intentionally or unconsciously make sensitive information of clients leak while mining relating information of clients. With the Internet popularity, because more and more information can be obtained in electronic form, that people have their own privacy confidential is becoming increasingly urgent.

According to statistics, even if privacy protection measures, about one-fifth of Internet users don?t like to provide their own information to the Web site and more than the half investigators only in good privacy-preserving measures are willing to provide their own information to the Web site.

Among the potential consumers shopping in internet browser, there are almost half who gave up the hope for internet shopping because of worrying about no protection of their privacy. Therefore, how to ensure personal privacy in data     mining has become a need to be addressed. The service overview is shown in fig1.

Figure.I.  Service Overview  We provide here an overview of privacy preserving association rule mining. The rest of this paper is arranged as follows: Section 2 introduces Association rule mining strategies; Section 3 describe about Privacy Preserving Algorithm; Section 4 shows the evolution and recent scenario; Section 5 describes the proposed method. Section 6 describes Conclusion and prospect.



II. ASSOCIATION RULE MINING   The association rule mining can be conceptualized as follows [4]: Let I= {i1,i2,?,im} be the set of all items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T is subset of I.

Each transaction is associated with an identifier, called TID.

Let X be a set of items. A transaction is said to contain X if and only if X is subset of T. An association rule is an implication of the form X is subset of Y, where X is subset of T, Y is subset of T, X?Y=NULL, the support s and confidence c of the rule X is subset of Y are defined as: s=Count(X)/|D|,c= Count(X is subset of Y)/ Count(X).

A set of items is referred as an itemset. An itemset that contains k items is a k-itemset. The support count of an itemset is the number of transactions containing the itemset.

An itemset is frequent if its support count is not less than the minimum support count.Rules with the support more than a minimum support threshold (smin) and the confidence more than a minimum confidence threshold (cmin) are called strong.

Association rule mining is a two-step process: (1) Finding all frequent itemsets; (2) Generating strong association rules from the frequent itemsets.

The purpose of privacy preserving is to discover accurate patterns without precise access to the original data. The algorithm of association rule mining is to mine the association  rule based on the given minimal support and minimal confidence. Therefore, the most direct method to hide  association rule is to reduce the support or confidence of the association rule below the minimal support of minimal confidence. With regard to association rule mining, the proposed methodology that is effective at hiding sensitive rules is implemented mainly by depressing the support and confidence. The existing tree algorithms, D_CONF1, D_CONF2 and D_SUPP, are simply introduced in [5], which are to hide the sensitive association rule all by reducing the support or confidence.



III. PRIVACY PRESERVING ALGORITHM A lot of implementations of the confidentiality of data and  knowledge are applied in association rule mining process.

According to privacy protection technologies, at present, privacy preserving association rule mining algorithms commonly can be divided into three categories [6].

Heuristic-Based Techniques Heuristic-based techniques are to resolve how to select the appropriate data sets for data modification. Since the optimal selective data modification or sanitization is an NP-Hard problem, heuristics can be used to address the complexity issues. The methods of Heuristic-based modification include perturbation, which is accomplished by the alteration of an attribute value by a new value (i.e., changing a 1-value to a 0-value, or adding noise), and blocking, which is the replacement of an existing attribute value with a ???. There is a basic principle of choosing the transaction or the item of itemset to be modified that we should reduce the influence of the original database as far as possible. Those related works are given below.

A. Data Perturbation-Based Association Rule The algorithms can be described as the following one. Let  D be the source database, R be a set of significant association rules that can be mined from D, and let Rh be a set of rules in R.How can we transform database D into a database D', the released database, so that all rules in R can still be mined from D', except for the rules in Rh. The heuristic proposed for the modification of the data was based on data perturbation, and in particular the procedure was to change a selected set of 1- values to 0-values, so that the support of sensitive rules is lowered in such a way that the utility of the released database is kept to some maximum value. Therefore, the key question of this algorithm is how to put D into D' with the use of heuristic thought.

A subsequent work described in [7] extends the sanitization of sensitive large item sets to the sanitization of sensitive rules.

The work in [8] aims at balancing between privacy and disclosure of information by trying to minimize the impact on sanitized transactions or else to minimize the accidentally hidden and ghost rules. The utility in this work is measured as the number of non-sensitive rules that were hidden based on the side-effects of the data modification process. Wang et al.

propose a matrix based sanitization approach to hide the sensitive patterns in [9]. It is the first paper to involve the consideration of avoiding the Forward-Inference Attacks [10], which can also be avoided in the sanitized database generated by our sanitization process. Oliveira et al. propose a novel     method to modify databases for hiding sensitive patterns in [11]. Multiplying the original database by a sanitization matrix yields a sanitized database with private content. The method can avoid the question of the Forward-Inference Attacks.

This paper in [12] describes a technique that uses a queue and a random number generator to generate the items so that each item has an approximately equal frequency of being added to transactions. And the work avoids the question that it is hard for [13, 14] to utilize existing tools for association rule mining.

B. Data Blocking-Based Association Rule The approach of blocking is implemented by reducing the  degree of support and confidence of the sensitive association rules. That is by replacing certain attributes of some data items  with a question mark or a true value. In this regard, the minimum support and minimum confidence will be altered into a minimum support interval and a minimum confidence interval correspondingly. As long as the support and/or the confidence of a sensitive rule lies below the middle in these two ranges of values, then we expect that the confidentiality of data is not violated. Yucel Saygin et al. first apply blocking to the association rule confusion, which has been presented in [15, 16].

a) Replacement-Based Techniques After original data is replaced the value of some data with  the unknown value, the support and confidence of sensitive association rules will not be able to determine, which may be a range of arbitrary values. The paper in [17] discusses specific examples with the use of an uncertain symbol used in association rule mining, in which case the support and confidence interval are used to support and confidence interval to replace.

b) Anonymity Techniques Agrawal et al. improve on the distribution reconstruction  technique presented in [18] by using the Expectation Maximization (EM) method. The authors claim that EM is more effective than the currently available technique in terms of the level of information loss. Finally, they propose novel metrics for the quantication and measurement of privacy preserving data mining algorithms.

The paper in [19] presents a new generalization framework on the concept of personalized anonymity in order to perform the minimum generalization for satisfying everybody?s requirements, the core of personalized anonymity is the concept of personalized anonymity. It provides privacy protection of different size for the records of data table. The paper in [20] proposes a personalized anonymity model on the base of (?,k)-anonymization model in order to resolve the problem of privacy self management and proposes corresponding anonymity method by using local recoding and sensitive attribute generalization. Although these personalized generalization approaches are flexible, the definitions of sensitive attributes are the same with other approaches. Thus, dynamic specifying sensitive information needs be future researched.

We should choose the algorithm according to the different situation that can reduce the influence for the original database  as far as possible. D_CONF1 algorithm will increase one transaction item when it circulates one time. Usually there are much data and many association rules while it processing the problem of privacy preserving. Frequent using of D_CONF1 algorithm will increase the quantity of data and generate some association rules that do not exist. It has influenced the accuracy of database. If there are some important items that cannot be modified or deleted, D_CONF1 algorithm is suitable for this situation. The front parts of D_CONF2 and D_SUPP are same. D_CONF2 algorithm can only select sacrifice item in back-end itemset and D_SUPP algorithm can select sacrifice item in whole generated itemset. So if the influence for the original database of selecting sacrifice item in front-end is smallest we can choose D_CONF2 algorithm.

If the influence for the original database of selecting sacrifice item in back-end is smaller, we can choose algorithm through comparing the efficiency, the quantity and importance of selected sacrifice item and support of D_CONF2 and D_SUPP algorithm.

We should analyze the transaction set of the original database and the sensitive association rule set to be hidden and find the relation of them. So we could select the sensitive transaction and sacrifice item more efficient. The modified data will be fewer and the influence for the original database will be smaller.



IV. EVOLUTION AND RECENT SCENARIO Recently some studies on data privacy are being conducted  [21, 22, 23, 24, 25, 26]. The idea is to replace classical model of secure computation with special algorithms [27], which represent from disclosing private data and keep functionality simultaneously. Most of methods were based on a secure mathematical operations, like secure size of intersection [21], secure sum of sets [21].  secure sum [21].Data mining with preserving data privacy only concerns mining from distributed data. In case of association rule mining, data can be partitioned and distributed horizontally and vertically. For horizontally partitioned data, HPSU algorithm was introduced.

It uses secure sum of sets, secure sum. For vertically partitioned data, VPSI algorithm can be used, which utilizes secure sum of sets and secure size of set intersection.

For vertically partitioned data there is another approach, which is based on secure scalar product, but it has a considerable drawback, which limits its application to only two data sources. The two, early mentioned algorithms, can mine from several data sources. It is also feasible to increase a level of data privacy, by generalization of the data. This approach assumes smaller harm by giving away generalized data than detailed data. Data can be generalized in several manners. In our study we use VPSI algorithm and aggregation as a manner of generalization.

Agrawal et al. in [27] first proposed the method of distribution reconstruction on numeric data which is disturbed by Bayesian algorithm in 2000.

Then, Dakshi and Charu in [28] improve the work over the Bayesian-based reconstruction procedure by using an     Expectation Maximization (EM) algorithm for distribution reconstruction.

The work presented in [29] and [30] deals with binary and categorical data in the context of association rule mining. Both papers consider randomization techniques that offer privacy while they maintain high utility for the data set.

The security of the scalar product protocol is based on the inability of either side to solve k equations in more than k unknowns. Some of the unknowns are randomly chosen, and can safely be assumed as private. A similar approach has been proposed by Ioannidis et al. who present an extremely efficient and sufficiently secure protocol for computing the dot-product of two vectors by using linear algebraic techniques and demonstrate superior performance in terms of computational overhead, numerical stability, and security by using analytical as well as experimental results [31].

Another way for computing the support count utilizes the secure size of set intersection method described in [32]. If the transactions are vertically partitioned across the sites, this problem can be solved by generating and computing a set of independent linear equations [33]. The work in [34] develops a log-linear model approach for strictly vertically partitioned databases and a more general secure logistic regression for problems involving partially overlapping data bases with measurement error.

In addition, privacy-preserving algorithms relying on other means of data mining are proposed one after another. For example, GENG Bo[35] etc. developed privacy preserving technique in multi-temporal sequence rule mining, which employs one simple untrusted third-party algorithm to solve the problem of calculating the frequency of temporal sequence rule by multiple partners together.

In 2008, Shaofei Wu et al. [36] proposed a new algorithm for balance privacy preserving and knowledge discovery in association rule mining. The solution is to implement a filter after the mining phase to weed out or hide the restricted discovered association rules. Before implementing the algorithms, the data structure of database and sensitive association rule mining set have been analyzed to build the more effective model.

In 2009, Yongcheng Luo et al. [37] proposed a privacy preserving association rule mining into three categories: heuristic-based techniques, reconstruction-based techniques, cryptography-based techniques. Finally, they conclude further research directions of privacy preserving algorithms of association rule mining by analyzing the existing work.

In 2009, Jie Liu et al. [38] proposed the algorithm which is designed to solve the shortage of low privacy protection of the geometric transform algorithm. The algorithm first gives four parameters, corresponding to the probability of four different types of geometric transformations. According to the various random number generated, different geometric transformation method is selected, which serves the dual effect of privacy protection.

In 2010, Brian, C.S. Loh et al. [39] proposed a framework involves several components designed to anonymize data while preserving meaningful or actionable patterns that can be  discovered after mining. In contrast with existing works for traditional data-mining, this framework integrates domain ontology knowledge during DGH creation to retain value meanings after anonymization. In addition, users can implement constraints based on their mining tasks thereby controlling how data generalization is performed. Finally, attribute correlations are calculated to ensure preservation of important features. Preliminary experiments show that an ontology-based DGH manages to preserve semantic meaning after attribute generalization. Also, using Chi-Square as a correlation measure can possibly improve attribute selection before generalization.

In 2010, Chirag N. Modi et al.[40] proposed an algorithm provides privacy and security against involving parties and other parties (adversaries) who can reveal information by reading unsecured channel between involving parties.

In 2010, Wang Yan et al.[41] proposed a privacy preserving association rule mining algorithm based on SRRCR is presented, which can achieve significant improvements in terms of privacy and efficiency. Finally, they present experimental results that validate the algorithms by applying it on real datasets.



V. PROPOSED WORK In this section, we describe the proposed method. We  propose a novel algorithm named Sensitive Information Preserving Mining (SIPM). The entire system architecture consists of three phases: 1) Check for Authentication. 2) Reading the database.  3) Perform Pruning. Our algorithm is a good way to apply data mining techniques with security that hides our logical instances from others.

In First phase of algorithm we check the authentication that  the user is authorized or not. In second phase we start reading the database, and in the final phase apply the pruning strategy.

Our algorithm shows good performance in different operating environment.

Algorithm:  SIPM (Sensitive Information Preserving Mining)   Input:  A. Set of rules to hide the data values  B. The source database  C. A Key for visualizing the authentication.

Output:  D. The database (DB) transformed so that the set of rules are properly applied and produce the result with security.

SIPM(R, DB, Key) Step 1: [Check for Authentication] 1 a. Enter a number 1 b. Enter the password 1 c. if(number==ndb && password==pdb) { Welcome in the database     SIPM(DB) } 1 d. else { Not an authorized user } Step 2. SIPM(DB) 2 a. While(object.read()!=-1) { [Start Reading] } 2.b [compute the occurences] For i=1 to n iterations do { Itemset[i]=count; Count++; } 2 c. [Enter the minimum support] Check for authentication again Enter the min-sup key If(min-sup==msdb) { Prune(db,key) } Else  { [enter the value again] } Step 3 Prune(db,key) 3a enter the min-sup For i=1 to n do If(count[i]>min-sup) List=itemset[i]; Else Remove from the list Step 4 Add the final result

VI. CONCLUSION AND FUTURE WORK We present a classification and an extended description and  clustering of various algorithms of association rule mining.

The work presents in here, which indicates the ever increasing interest of researchers in the area of securing sensitive data and knowledge from malicious users.

We propose a novel algorithm named Sensitive Information Preserving Mining (SIPM). The entire system architecture consists of three phases: 1) Check for Authentication. 2) Reading the database.  3) Perform Pruning. Our algorithm is a good way to apply data mining techniques with security that hides our logical instances from others. In future we also include the simulation result for showing the efficiency and performance.

