suvfs: A virtual file system in userspace that supports large files

Abstract?As a consequence of voluminous growth and prolif- eration of digital data, the file system size and count limitations have become problematic. The fact is that file systems use fixed length fields within their metadata structures to keep track of volume size, file size and file count, and hence need design (and source) modification to cope up with this growth. In this paper, we propose a Scalable User-space Virtual File System, namely suvfs, which when mounted on top of any file system extends its capability to store and process large files not natively supported by the file system. It works by exploiting the concept of virtual unification to present a large virtual file that spans over a number of legitimate sized physical files. It does so without modifying user applications, system libraries, system calls and even file systems. We implemented it using FUSE framework & evaluated it for performance overhead added by layering it over FAT32 file system. The results indicate that there is a very minimal performance hit encountered by FAT32 with suvfs mounted on top for sequential reading, while as for sequential writing & deletion the performance hit increases with file size but is largely due to FUSE framework & not by suvfs.



I. INTRODUCTION  File System Scalability is defined as the ability of a file system to support large volumes, large files, large directories and large number of files while still providing I/O performance.

Thus, scalability is a two part term: Scalable to Capacity and Scalable to Performance. To what extent a file system is scalable to capacity, depends on how it stores information about files, directories and the file system itself. As an ex- ample, if the file size is stored as 32-bit integer, then no file on that file system can exceed 232 bytes (4 GB). The fact is that file systems use fixed length fields within their on-disk metadata structures to keep track of volume size, file size, file count, and so on. Thus being fixed in length, they are not scalable and hence limit the file system. An obvious solution to this problem would be the usage of dynamic length fields.

In fact, the limitation on filename length in ext2 file system was mitigated by replacing the fixed length filename field with a dynamic one. However, in general there are three problems associated with this approach; 1) it hinders the performance as extra computations are to be performed, 2) an extra metadata structure is added which demands space and management, and 3) because very little space is allocated to metadata structures, they can?t grow dynamically after certain limit.

Another possible solution would be to keep a large fixed length field whose length would never be possibly defeated. This idea has four limitations; 1) the memory requirements are high, 2) a lot of space is occupied by metadata structures, 3) a lot of  space is wasted, and 4) still there is an upper limit.

In this paper, we propose a novel approach to overcome the file size limitation of file systems without instrumenting the file system by using the concept of virtual-unification to present a large virtual file that spans over a number of legitimate sized physical files. The proposal, namely suvfs, is implemented as a virtual file system using FUSE framework [1] and can be layered on top of any file system in user-space to extend its capability to support large files. Furthermore, we empirically evaluated the performance overhead added by the suvfs algorithms by layering it on top of FAT32 file system. After exercising the file system with Sprite LFS large- file micro benchmark, the results indicate that the average growth of performance overhead added by suvfs algorithms with doubling the file size is 0.51% for reading, 6.73% for writing and 9.54% for deletion.



II. BACKGROUND & RELATED WORK  Virtual Unification provides a merged view of several directories, without physically merging them. This allows the files to remain physically separate, but appear as if they reside in one location. As such, Virtual Unification presents a large directory wherein there is no limit on the number of files and directories it contains. Conversely, Virtual Unification presents a file system that is scalable to store and process large number of files and directories even though they may actually reside at different locations within the file system or may even belong to different file systems. Furthermore, as it can merge directories from different file systems into one, the file system so created is scalable to large volume size if the specified directories are mount points of different file systems. Many proposals for virtual-unification of directories (simple or mount-points) have surfaced from time to time; however the following text briefly discusses the most influential and popular designs.

Plan-9 developed by Bell Labs can connect different ma- chines, file servers, and networks, and offers a binding ser- vice that enables multiple directories to be grouped under a common namespace [2]. Similarly, 3DFS, also developed by AT&T Bell Labs for source code management, maintains a per- process table that contains directories and a location in the file system that the directories overlay [3]. This technique is called viewpathing, and it presents a view of directories stacked over one another. Although, the Translucent File System (TFS) released in SunOS 4.1 [4] also provides a viewpathing solution like 3DFS, but is an improved one as it better adheres to UNIX semantics when deleting a file. Moreover, Union-Mounts, which were implemented on 4.4BSD-Lite,     merge directories and their trees to provide a unified view [5].

This structure, called the union-stack, permits directories to be dynamically added either to the top or the bottom of the view. Unionfs proposed by Wright et al. [6] is the most improved union file system as it maintains UNIX semantics while offering advanced unification features such as dynamic insertion and removal of namespaces at any point in the unified view. Unionfs allows users to specify a series of directories and a mount point which presents the union of specified directories. Although, originally intended for name- space unification, union file systems can also be used for snapshotting, by marking some data sources read-only and then utilizing copy-on-write for the read-only sources [7].

Finally, mhddfs is another union file system developed by D.E. Oboukhov that allows to unite several mount points to the single one [8]. mhddfs simulates one big file system by combining several hard drives or network file systems. As such, mhddfs can be argued as to be a file system scalable to large volume size and file count in the same way as other union file systems can be. However, mhddfs goes a step further by supporting load balancing. In mhddfs, if an overflow arises while writing to some unified mount point, the file content already written will be transferred to another unified mount point containing enough of free space for the file. The transferring is processed on-the-fly, fully transparent for the application that is writing.

It is worth mentioning here that no proposal (based on concept of virtual unification) that directly claims to have overcome any size or count limitation of the file systems exists. Never- theless, this paper proposes the one.



III. DESIGN OF suvfs  suvfs is a scalable user-space virtual file system that breaks the maximum file size limitation of any file system when mounted on top of it. suvfs can extend capability of any file system to handle large file sizes without modifying the design and source of the file system. Also, with suvfs on top, there is logically no upper limit on the file size. Therefore, the design goals of suvfs are as follows:  1) To extend the capability of a file system to handle large files with logically no upper limit on the file size.

2) To break this file size limitation without modifying the design and source of the file system.

3) To add this capability to every existing file-system.

4) To add this capability in user-space so that the kernel  stability and reliability is not compromised.

suvfs mitigates its core design goal (enumerated above at 1) by first splitting a large file which cannot be created, stored and processed in its entirety on the native file system, into a number of legitimate sized files called fragments. fragments belonging to a file have same name as that of the file with 2 extra parts: 1) magic string that identifies a fragment, and 2) an integer that identifies its position in the unification. This way we are able to store the contents of a large file whose size crosses the file size limitation. Unfortunately, this way we are only able to store the large file but can?t process it. Second, in order to overcome this problem, suvfs presents a large virtual file as the representative of associated fragments (a virtual unification of files) instead of a large physical file to the user applications  for processing. The operations performed on this large virtual file are reflected in the associated fragments. Third, to avoid individual access to the fragments and to exclude them from directory listing, suvfs filters fragments from simple files using the magic string in their filenames.

Furthermore, to ensure that the split and unification is trans- parent to user applications, suvfs uses file system layering to perform transparent splitting and unification, thus avoiding any design or source modification of user applications, libraries, system calls, file systems, etc. Layering allows trapping, pre- processing and post-processing of file system syscalls targeted to the below mounted file system. As such, layering is trans- parent to both; user applications on one side and native file systems on other side. This mitigates the design goals of suvfs enumerated above at 2 and 3.

suvfs is implemented as a file system layer in user-space using FUSE framework [1]. This design decision mitigates design goal enumerated above at 4. Figure 1 shows the design of suvfs using FUSE framework.

Fig. 1. Design of suvfs using FUSE framework

IV. IMPLEMENTATION OF suvfs  suvfs is implemented using FUSE framework [1]. FUSE is an acronym for Filesystem in UserSpacE and is used to develop full-fledged file systems and to extend existing ones.

The file systems so created run in the user space. As such, it promises ease of development as user-space allows access to facilities (like C library) which kernel-space development lacks. The FUSE framework contains a null-pass virtual file system, fusexmp, which passes all the file system opera- tions to below mounted file system without any modification.

suvfs is implemented by overriding the various procedures of fusexmp. However, fusexmp doesn?t support overlay mounting and as such any mount point passed to fusexmp during mounting, mounts the root directory (/) on that mount point. Having said that, a little modification to fusexmp gets it overlaid on the specified mount point, which can be a simple directory or a mount point of some other file system. It has two benefits; 1) it adds to transparency of suvfs as no path change is required by applications accessing that volume, and 2) it leaves no path to access native file system without the intervention of suvfs.

suvfs in specific and FUSE file systems in general, incur performance overhead as kernel boundary is crossed to process the call. In addition to multiple context switching, multiple process switching and data copying during call processing also     adds overhead [9]. However, the benefits of development-ease, reliable environment and portable file system outweigh the drawbacks. Figure 2 shows the path of write() file system call targeted to a file system with suvfs mounted on top.

Fig. 2. Path of write() call to a file system via suvfs  The Figure 2 clearly depicts the overhead incurred during the write() call due to the framework. The figure also shows that every file system call can be pre- and post-processed in user space to reflect the desired operation.

Although, the implementation of suvfs demands processing many syscalls but for most of these calls suvfs does a minimal amount of work of restricting the access to fragments. Besides, suvfs write() and suvfs read() are primarily responsible for creating, writing and reading a large file. Also, suvfs readdir() implements the logic to restrict listing of fragments and suvfs getattr() presents a large virtual file which is the virtual unification of associated fragments. In addition, calls like su- vfs unlink() reflect the same operation on associated fragments while calls like suvfs open() restrict direct access to fragments.

