Automatic High-Dimensional Association Rule Generation for Large Relational  Data Sets

Abstract Data mining extracts knowledge from a large amount  of data. It has been used in a variety of applications ranging from business and marketing to bioinformatics and genomics. Many data mining algorithms currently available, however, generate relatively simple rules that include a small number of attributes. Moreover, these algorithms need to build decision trees, which take a significant amount of time due to a large number of attributes and lack of field knowledge. Thus, in this paper, we propose a method that automatically generates high-dimensional association rules in large data sets with high accuracy and broad coverage.

Keywords: data mining, high-dimensional association rules, random number generator, rule prediction, rule validation, rule learning    1. Introduction and Related Work  Data mining extracts knowledge from an extremely large data set with minimum human interference. The extracted knowledge can be expressed as if-then rules, which can be used to predict future patterns or behaviors.

Currently, one of the most challenging topics in data mining is to build up powerful association rules [1, 2, 3, 4, 5, 6]. However, many algorithms for discovering association rules have very poor response time [7].

Particularly, when discovered association rules are used for classification, they suffer severe degradation of performance [8]. Moreover, many efforts specifically address simple rules, which include small number of attributes. For example, mining item-based association rules [9], quantitative association rules [10] and causality models [11] focus on simple attributes [12]. They are inadequate to discover high-dimensional association rules in a large number of data, and can not automatically predict and validate rules.

Besides, many data mining techniques require predefined conditions or factors, which should be  continually adjusted. Fuzzy logic, neural computing [8, 13, 14] and other mining methods find classifications of new instances by constructing classification or decision trees [1, 15, 16]. However, in realistic applications such as biological or pharmaceutical domains, we even don't know how to define or find the most significant factors to classify data or to build decision trees. A solution to the problems mentioned above is to develop a method, which can automatically propose and validate predictions, and consequently, generate new rules.

Thus, our objective is to develop a method which includes 1) construction of prediction space; 2) generation of predictions; 3) validation of the proposed predictions; and 4) production of new rules. The reminder of this paper is organized as follows: Session 2 describes a novel method and algorithms in great detail. Section 3 concludes the paper with future work.

2. Method and Algorithms  The knowledge can be represented by a set of rules, each of which consists of a set of conditions and one consequence. The method we proposed is iterative and self-improving. It consists of four major tasks: hypothesis space construction, rule prediction, rule validation and rule learning. In the rule prediction phase, the predicates of conditions and consequences are generated with the uniform distribution function and random number generator. Following the prediction phase, a validation phase is started to verify the predictions based on the coverage. If the prediction is correct, for example 95% for the coverage, this rule is stored into the knowledge base.

Otherwise, the system will start learning algorithms to refine the proposed rules towards the given consequence.

To explain our method, consider the following bank database schema (refer to Figure 1): ? Account-schema = (Branch_Name, Account_No,  Balance) = account (BN, AN, BAL); ? Customer-schema = (Customer_Name, Customer-  Address, Account_No) = customer (CN, CS, AN) ? Branch-schema = (Branch_Name, Branch_City,  Branch_Assets) = branch (BN, BC, BA);      In the example above, we have seven attributes for the prediction process: BN, BC, BA, AN, BAL, CN and CS.

Each attribute can be defined by certain values and ranges. For a certain attribute, an actual form of values or ranges can be represented as the 'parameter' of the attribute.

2.1 Method Workflow Below is the algorithm that shows an overall workflow  of our method.

Algorithm 1  //Start Prepare a hypothesis space; Guess rules; Validate predictions proposed by the system; iff a  prediction is validated to be correct, stop here; else iff A prediction is validated to be semi-correct; Begins a supplementary learning process else A prediction is validated to be incorrect; Discards the first guess and begins a new and full learning process to find a rule with a high coverage; //End  From the algorithm discussed above, we designed an exhaustive rule guess algorithm to predict the candidate rules from the search space. Each attribute will have an even chance to be selected during the guess process.

Afterwards, all the guesses must be validated. After the validation, three scenarios can be considered: 1) Stop here if the prediction has a high coverage; 2) Execute a supplementary learning process if it covers a part of positive instances as well as negative instances; and 3) Start full learning process if it covers few positive instances. Through the learning process, the refined predictions may have a high coverage and become the real rules to be stored into the knowledge base.

2.2 Construction of Prediction Space Because a rule is composed of conditions and  consequences, we need to consider conditions and consequences separately. We assume that the conditional part consists of one or several sub-conditions, which are the parametric form of attributes from a specific domain.

Definition 1 Each sub-condition Ci, i ?  N comes from the condition  { }| 1, 2,...,iC i N=  where N is the number Similarly, we have the consequence set S  S = { | 1,2,..., }jS j M= where M is the number of conditions involved in the consequence part. The whole consequence can also be represented with a combination of several sub-conditions.

From the condition and consequence mentioned above, the following rule can be obtained such of conditions involved in the conditional part. For example, a conditio C = Ci Cj, is the combination of sub-condition: CS = 'Irvine', and sub-condition: BAL > '15,000'.

Definition 2 Similarly, we have the consequence set S  S = { | 1,2,..., }jS j M= where M is the number of conditions involved in the consequence part. The whole consequence can also be represented with a combination of several sub-conditions.

From the condition and consequence mentioned above the following rule can be obtained as  If CS = 'Irvine' BAL > '15,000', Then BC = 'Los_ Angeles' BN='City_Bank' That is, Customers who live in Irvine and have the  balance over 15,000 choose to deposit their money in the City Bank located in Los Angeles.

Therefore, a rule can be expressed in the form  1 2 1 2m k C C C S S S! ! ! " ! ! !L L  1 , 1m N k M! ! ! !

For simplicity, we consider a rule that includes multiple sub-conditions and single condition  1 2 m C C C S! ! ! "L  First, the system considers one condition as the initial prediction SC !

. Afterwards, other conditions are  added through a learning process.

We assume each condition belonging to C1 is a  predicate of certain parametric expression, which is a range of continuous values, or a finite set of categorical values [1].

Each condition is proposed based on the dataset.

However, the prediction can be an exact record in the dataset, or a range of a certain attribute. If the condition selects the Account_No as the attribute to be proposed, then a parametric expression can be AC = ?100010?, or ?100005? < AC < ?100015?.

Among all attributes, it is assumed no knowledge is given to determine which one should be chosen as the conditions for the conditional part and consequent part.

We assume that all attributes have an even chance to be selected.

We know that once a conditional attribute is selected, a consequential attribute will be chosen from the rest of attributes, because they can not be chosen from the same      type of attributes. Otherwise, it will break the integrity and coherence of the rule of guess.

Definition 3  First, we define three sets as follow: ? A ? set of n attributes to be as the candidates of the  conditional part; ? B ? set of n - 1 attributes to be as the candidates of  the consequent part; ? G ? set of T guesses of rules.

where, { }| 1, 2, , ,iA Attribute i n n N= = !L { | 1, 2, , , , , }j jB Attribute j n j i n N Attribute A= = ! " "L  B A!

Let n be the number of attributes that can be chosen in  the conditional part. In our case, the number of the attributes n is 7. Suppose that the candidate conditional attribute is Attributei. If only one attribute from the n attributes can be chosen as the conditional part each time, we have Cn1choices. Similarly, the possibility of the consequences is Cn-11.

Therefore, the system will have Cn1 ? Cn-11 choices to create a guess space.

Definition 4 Suppose that for each Attributei there are mi parametric expressions, which are either the ranges or the exact values:  { | 1 , 1 }mi ji i iParameter Parameter i n j m= ! ! ! !

where, 1 ,i im boundary m N! ! "  where Parameterimi stands for the parametric set of the certain attribute, while boundary is the upper bound of the certain attribute stored in the training dataset.

For example, for the attribute ?Account_No? (100001- 100019), There are three sorts of range comparison operators such as '>', '<', and '=', which have C181 and C181 possibilities of ranges, and C191 possibilities of values, respectively. Therefore, there will be mi= C181+ C181+ C191 parametric expressions. However, for the categorical attribute 'Branch_Name', we have to enumerate all the possible parameters stored in the dataset. So, there will be mi=3 expressions for this attribute.

Based on the above, the number of choices for the selected conditional attribute is Cn1 ? Cmi1. Similarly, the number of choices for the selected consequence attribute is 1 1  1n m jC C! " . Consequently, the total number of possible rules is  G T = 1 1 1 11  , 1,  n  n mi n mj  i j i j  C C C C!

= "  # # #$  = , 1,  ( 1)  n  i j  i j i j  n n m m  = !

" #     (1)  where G designates the set of all possible rules.

2.3 Guessing of Rules In order to guess an attribute automatically, first we set  a group of intervals with a series of continuous natural numbers, for example,  n]1,[n:interval,2],[1,:interval1],[0,:interval n21 !L Second, build up one to one relationship between the  attributes and the intervals. That is, make each attribute connect to one interval based on a predefined sequence.

At the same time, a group of random numbers can be used as indices pointing to corresponding intervals. With intervals, a specific relationship should be created between attributes and random numbers.

Since we have seven attributes to be guessed by the system, we give seven intervals:  ? 0~1:  Account_No ? 1~2:  Balance ? 2~3:  Branch_Name ? 3~4:  Customer_Name ? 4~5:  Customer_Address ? 5~6:  Branch_Address ? 6~7:  Branch_Assets  The system can select parametric ranges or values by assigning a random number to a specific interval. Thus, if we can control the selecting process of the interval, we can pick out all attributes and parametric expressions one by one throughout the entire guess space.

We generate random numbers by using a uniform distribution. Many advanced languages, such as the C++ class library, provide a uniform or non-uniform random number generator [17]. The method discussed below shows an exhaustive process, which searches the entire guessing space thoroughly and evenly.

We first try the following uniform distribution to generate a real random number, which is equally probable in the interval x ~ uniform (min, max)  ( )  max min 1 f x =  ! + (2)  For simplicity, suppose that min = 0. At the same time, we use seconds or milliseconds as the unit of the self- variable Time, which can be captured at random by the system or generated by a linearly increasing function after we preset a time value as a seed.

Since time will be always increasing throughout the experiment, we need to process the variable Time with a divisor d to get its remainder so that a continuously varying process becomes a periodical process with a fixed period d.

Definition 5  Let Re ( )dx m Time=                                                        (3) where x is the remainder of Time, and d is the divisor. As shown in equation (2), the variable max is the maximum in the periodical time series. So, given max ( )Max x= , we      can have a whole time series X:{0,1,2,?,Xm} where Xm = d ? 1.

Example 1 If the experiment begins at 5:30:17 and samples at 5:32:53, the total number of second counts is 156''. Let's set divisor d = 10, then series X is {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} Xm = 9, then   156 Re (156) 6x m= = Therefore, the random number will be generated by  ! ! ! + =  + =  +" ==  sample  start  x x  mmm X  x dx  X dx  minX dx)x(f)x(F  0 0    1    (4)  Before we implement this approach, we need to prove it completely. First, we prove the existence below: Theorem 1 There must be at least one existing attribute that can be picked from Set A by a uniform random guessing.

Proof Because we have the limited and exact number of intervals of the attributes, we need to extend the theoretical distribution from the range (0~1) to the current range. (For example, the current range of attributes is: 0~7) We suppose, the number of the intervals that need to be scanned is R. After multiplying a factor R, the function (4) becomes:  ( )  m  x F x R  X  = !

+  (5)  The theorem to be proved can be transformed into: ?  i x X! , to satisfy the following inequality:   m  x R R  X  < < +  (6)  , 0 1,  m  m  x x X  X  ! < < +  Q ? 0  m  x R R  X  < < +    (7) Second, we need to prove that the system can select all the attributes. The problem can be restated as follows. For any interval from which we need to choose an attribute, the system can generate at least one random number to index to this interval. If each interval can be indexed by a certain random number, all the attributes included in the set A will be selected by random numbers through the intervals. The problem above can be presented with the inequality below: Theorem 2 There must be at least one generated number in each attribute interval represented by two boundaries: ri and ri+1, that is  ,x X! "  i i  m  x r R r  X +! !

+ (8)  where R is the number of the intervals or attributes; ri and ri+1 are the boundaries of the attribute interval i + 1, ri, ri+1! . N.

Proof The inequality can be transformed into two inequalities:  (10)1  (9)1  )X(rxR  xR)X(r  mi  mi  +!

!+  +    Here,  i i r r+ = + .

Let's prove it reversely.

Iff suppose  m X R< , Q , , 1  m m X R N X R! " # $ , and  Q  x R  x + is an increasing function,  ?  1 1 1 1 1  m  m  X R R R R  X R  !

" = !

+ ! +   Because the generation function (x/Xm+1)R is a continually increasing function, the maximum number will be generated when x = Xm. As conducted above, this maximum Xm is at most equal to R-1. That means the system will not generate a number to present the interval between R-1 and R unless Xm is larger than R. Therefore, we reach this conclusion as well as a condition: Xm ? R.

Further,  i r R!Q  and  m x X! , let ,  m r R x X!+ = + " = , the  inequality (9) becomes ( )( 1) ( )  m m R X X R!" + # " $ ?  m R R X! !+ " # $ % " ?  ( ) m m  R R X x X! !+ " # # $ " ?  m m R R X X R x! !+ " # # " $ " ? 1  m m X X x  R R  ! !

+ " " #  Q 0 1 R  !< " ? 1 1 m m X X x  R  !

" + # # $ ? (1 )  m X x  R  !

" #  ? 1 m  x  R X  !

" # ? 1  m  R r x  R X  !

! " ?  m  r x  R X  !  ? m  r X x  R  !

Therefore, there must be x X! " , when  m m  r X x X  R  < ! , it will make the inequality (9)  satisfied. As for the inequality (10), Q m  r X x  R  !  and  x N! , let [ 1] m  r x INT X  R  = +  (the biggest integer no  larger than ( 1 m  r X  R  + )), and  Q [ 1] 1 m m  r r INT X X  R R  + ! + , and  i i r r+ = + , mX R! ,  ? [ 1] ( 1) m m  r r R INT X R X  R R  ! + " ! +  m m m  rX R rX X r= + < + + + ( 1)( 1) m  r X= + +      1( 1)i mr X+= +  That is, 1( 1)i mR x r X+! +  Therefore, the two inequalities are satisfied finally. The conditions to satisfy the inequalities are:  { m  m m  X R  r X x X  R  !

< "    This means, we need to select Xm reasonably so as to meet the requirements of guessing and searching for the space of attributes. Besides, guess process will work well when x satisfies the conditions above. We give an example below to represent the guess process in detail.

Example 2  In the example, there are C71 choices of attributes for the conditional part and C61choice for the consequent part. Furthermore, the system will go to the parameter level in order to 1) locate possible ranges or values or 2) just enumerate an exact value of this attribute. As presented before, there will be mi= C181+ C181 +C191 choices of expressions for the ranges of the attribute account-No. Regarding Balance, if we could segment the whole range into a set of short ranges by $5000, we have mi = C1521+ C1511 +C191 expressions. For Branch_Name, we have to enumerate all values as the parameters. Below is part of the training dataset.

Account_No Balance Branch_Name 100001 123200 City bank-Irvine 100002 634520 Western Mutual-Tustin 100003 91000 OCTFCU-Tustin 100004 8700 Western Mutual-Tustin 100005 760000 OCTFCU-Irvine 100006 76200 City bank-Irvine 100007 89120 Western Mutual-Los Angeles 100008 100000 OCTFCU-Tustin 100009 120000 Western Mutual-Los Angeles 100010 10000 OCTFCU-Irvine 100011 210000 City bank-Irvine 100012 3000 Western Mutual-Los Angeles 100013 21000 OCTFCU-Tustin 100014 1500 Western Mutual-Tustin 100015 17000 OCTFCU-Irvine 100016 8000 City bank-Irvine 100017 7100 Western Mutual-Tustin 100018 18000 OCTFCU-Irvine 100019 91000 Western Mutual-Los Angeles  Customer_Name Customer_Address Account_No John Smith Irvine 100001  Steve Gross Tustin 100002  Ronald Meyer Los Angeles 100003 Kathy William Irvine 100004 Diane Lin Tustin 100005  Joseph Armer Riverside 100006 Donald Anderson Los Angeles 100007 Patrick Healey Irvine 100008 Richard Campbell Long Beach 100009 Felix Wang Sata Ana 100010  R. Brachmann Tustin 100011 Deborah Grady Long Beach 100012 Steve Lipkin Irvine 100013 Paul Vrana Los Angeles 100014 Christine Gall Sata Ana 100015  Timothy Bradley Long Beach 100016 Robin Bush Riverside 100017 James Hicks Sata Ana 100018 Robert Josephson Los Angeles 100019   Branch_Name Branch_Address Branch_Assets  City Bank Irvine 10000000 Western Mutual Tustin 50000000 OCTFCU Irvine 20000000 Western Mutual Los Angeles 80000000 OCTFCU Tustin 100000000  Figure 1. Training dataset tables (Account, Customer, and Branch)  Let's follow the sample shown in Example 1. Because we got the sample time x156 = 6, the random number is  ( ) 7 4.2  1 9 1 m  x F x R  X  = ! = ! = + +  . Therefore, the system  will choose ?CS? as the conditional attribute. Following this way, the parameters of attributes can also be selected through the sampling of time. If F(x) = 0.47, the system will point to ?Irvine?. Thus we get the condition: CS ? ?Irvin?. Similarly, the consequent condition can be proposed step by step. If we have the guess track {4.2 ? 0.47; 1.4 ? 0.31}, meaning {CS ? ?Irvine?; BAL ? ?<5000?}, the system will propose the following prediction:  If customer (CN, CS, AN) and branch (BN, BC, BA) and account(BN, AN, BAL) and (CS ='Irvine') Then BAL <  5,000  2.4 Validation of Predications After proposing the prediction, the system should start  a validation process to verify the prediction based on a given coverage. If the prediction is correct, say 95% for the coverage, we may output a successful flag and put this      rule into the knowledge base. Otherwise, the system will start learning algorithms so as to refine the raw rules towards the given consequence.

When a rule-form prediction is proposed, generally, it may cover both the positive instances and the negative instances if it is not fully correct. Below are three situations for the prediction result.

(a) Whole Data Set  Hit by  Prediction  Same  Consequence  Not Conditions  Consequence  Fact  Non-Consequence  Fact      Hit by  Conditions     (b) Whole Data Set  Hit by  Conditions  Consequence  Fact  Non-Consequence  Fact    Same  Consequence  Not  Conditions    (c) Whole Data Set  Consequence  Fact Non-Consequence  Fact  1 4  Hit by  Prdiction Figure 2. Prediction result  Explanation 1 In Figure 2, we can see that there are mainly two  separated parts in each figure: Consequence Part which contains all the instances sharing the same consequence guessed by the prediction, and the Non-Consequence Part  which contains all instances having different consequences from that of the prediction.

Besides, in Figure 2 (a), area 1 includes the instances hit by both the conditional and consequent parts of this prediction. Area 2 doesn't have the same condition as the prediction though it has the same consequence. Similarly, area 3 doesn't have the same consequence but it has the same condition as the prediction. Area 4 is unrelated to either the consequence or condition of this prediction.

Thus we partition the positive and negative sets by this way. In Figure 2 (a), the positive set is area 1, while the negative set contains the rest of areas because we need to append other conditions through learning to eliminate the negative instances. Generally, once a prediction is proposed, its conditional part may cover the instances in both area 1 and area 3. The instances in area 1 are what we need, so our mission is to exclude the instances of area 3 by refining the conditional part continually so as to purify the set hit by the prediction.

In Figure 2 (b), the prediction guesses nothing because it doesn't hit any useful instances. In this case, we set area 1 as the positive set, and both area 3 and 4 as the negative set.

In Figure 2 (c), the system predicts almost all the instances with the same consequence and the same condition in the training dataset with a very high coverage.

Because the prediction is a sufficient condition to its consequence, we need to verify the support throughout the training set so that we can delete rules with a very low support. Afterwards, we need to verify the confidence of predictions that have high support. If confidence is not enough then the system will report the coverage rate.

Algorithm 2 //Validation Starts Collect the instances which satisfy both the conditional and consequent part; Num_ Same_Prediction= the number of collected  instances; Support= Num_ Same_Prediction / Num_total_data; iff (Support<SUPPORT)        Delete  the prediction; else { Collect the instances which is hit by the prediction; Place them into the Same_Condition_Set; Num_Same_Condition= the number of instances in the  Same_Condition_Set; for (i=1; i<Num_ Same_Condition; i++) { iff (the instance has the same consequence) Hit_Num=Hit_Num +1 } Confidence=Hit_Num / Num_ Same_Condition; iff (Confidence<= Coverage) Start Learning Process; else Return Correct; } //Validation Ends      2.5 Learning for Conditions of the Rule As represented in Section 2.4 and Algorithm 1, there  are two learning processes in current research. One is the supplement learning that appends new conditional atoms into the original prediction to eliminate the negative instances. The other is the full learning that discards the original guess if the coverage is very low and starts a new learning process to work out the rules.

(a)Training data  (b) Supplement learning process Figure 3. Supplement learning  We first focus on the supplement learning. As shown in Figure 3, area 2, 3 and 4 compose the negative set.

Figure 3 (b) describes a learning process  Area 5 is one of the middle learning results covering not only positive instances but also some negative instances. With the learning proceeding by appending other attributes or parameters, the system gets area 6. And then, the learning process ends at area 7 that covers only the positives. Once we get the supplement of conditions, we should combine the result with the original condition to satisfy the original consequence. If the currently generated rules can't cover all the positive instances, the system needs to continue learning other new rules till the positive set is empty or it reaches a very high coverage.

So each time, the system needs to readjust the positive set by eliminating the covered positives in area 1.

Because we are now using the relational data, it is beneficial to decrease the searching scale by fixing the current parametric attribute to be used in the next step.

For the detail of learning process, we mainly use the inductive learning of Horn clauses to learn the first- order logic rules [18, 19]. This is based on a rule-learning algorithm called Incremental Reduced Error Pruning (IREP) [20]. The conditional literal added is the one that yields the largest information gain for rulei+1 relative to rulei [19]. Information gain is defined as:  1 1 2 2  1 1  ( , ) ( log log )i i i i i  i i i i  T T Gain rule rule T  T T T T  + +  + +  + + + ! + !

+ +  = ! + + +  (11)  where Ti+ (Ti-) is the number of positive (negative) instances in the growing set covered by rulei. Information gain rewards rulei+1that increase the density of positive instances covered by the rule, without greatly reducing the total number of covered positive instances. After  growing a rule, the rule is pruned. At each stage, IREP considers deleting any final sequence of conditions from the rule and chooses the deletion that maximizes the function  1 1  1 1  ( ) i i  i  i i  U U f rule  U U  + !

+ +  + !

+ +  !

=  + (12)  where Ui+1+ (Ui+1-) is the number of positive (negative) instances in the pruning set covered by the new rule. After pruning, the pruned clause is added to the rule set, and the instances covered by it are removed.

Algorithm 3 // Supplement learning Put the original attributes and parameters into 2 arrays: *Attributes_to_be_learned and Parameters_to_be_learned; Record the Minimum, Maximum and minimum Interval of parameters  in Parameters_to_be_learned; Condition .Attr = * Attributes_to_be_learned; Condition .Attr.Par = * Parameters_to_be_learned; iff (*Attributes_to_be_learned!=NULL) { iff (*Parameters_to_be_learned!=NULL) { iff (the value of the parameter is numeric) { Value= Minimum; for (i=Minimum; Maximum; Interval++) { Condition .Attr.Par.Value = Value; Compute Information Gain (rulei+1, rulei);  iff Gain is increasing   Keep this value and attribute in the Pruning Set; iff (the Gain doesn't increase any more) break; Value=Value+ Interval; }  } // Learning process for categorical attributes else { Condition .Attr.Par.Value =*Parameters_to_be_learned;  Compute Information Gain; iff Gain is increasing   Keep this value and attribute in the Pruning Set;  iff (the negatives are reduced to a given minimum) break; Parameters_to_be_learned++;  } Parameters_to_be_learned++; Condition .Attr.Par=* Parameters_to_be_learned; } Attributes_to_be_learned++; Condition .Attr = * Attributes_to_be_learned; } Prune the conditions in the Pruning Set; Merge the parametric values and ranges together; Delete the positives covered by the former conditions; iff (the Positive Set is empty or Coverage is  satisfied )  Positive Set  Negative Set  Consequence  Fact Non-Consequence  Fact        Done  N N  N  P  Consequence  Fact  Non-Consequence  Fact      P  N  N  N      stop learning; else start a learning process again ; // Learning Ends  As for the full learning, the whole process is similar to the supplement learning except for neglecting the original condition and beginning from scratch to find the rules.

Besides, the positive and negative sets need to be repartitioned only according to whether the instance belongs to the Consequence Part or Non-Consequence Part.

3. Conclusions and Future Work  In this paper, we have explained a new approach to generating high-dimensional association rules. This method includes a set of tasks such as 1) construction of prediction space; 2) generation of predictions; 3) validation of the proposed predictions; and 4) production of new rules. We showed that our approach is solid and sound.

We have introduced here an exhaust searching method to propose the possible predictions based on a uniform distribution. Actually, there would be some routines and relationships existing among the attributes and their parameters. For future work, we need to develop a set of appropriate algorithms to enhance the automatic proposing algorithms of predictions. These algorithms should be robust and flexible to control the proposing process, and should wisely judge and recognize what kinds of attributes will be proposed at next step based on statistical analysis and field knowledge.

Our current target dataset consists of a large volume of relational data. We will extend the current work to object relational applications. The representation and storage means will differ from those of relational data.

