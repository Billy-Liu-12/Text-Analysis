Study on the Application of Multi-level Association Rules Based on Granular Computing

Abstract For the issue that classical association rules can not  mine multi-level association rules, we proposed a multi-level  association rule mining method based on binary information  granules in granular computing and multiple minimum supports,  and gave the definition of the support and confidence based on  binary information granules. In this new association rules  method, we can reduce the generation search space of frequent  itemsets, extract multi-level association information(including  cross-level information), and find more effective rules.

Keywords-data mining; granular computing; multi-level  association rule; multiple minimum supports

I.  INTRODUCTION  Association rules proposed by R. Agrawal,etc[1] for the first  time is one of the most important research areas in data mining.

Its target is to find out all frequent itemsets in the database that  meet the minimum support, and to generate all association  rules used by all frequent itemsets to meet the minimum degree  of confidence. Granular computing [2-4]is a kind of knowledge  processing method which can express the semantic information  of the data stored in the system. A large amount of complex    information can be divided into a number of relatively simple  pieces in accordance with their respective characteristics and  performance, each of which is called an information granule.

The information processing process is called Information  granulation. Using Granular computing in mining association  rules, this method enables people to easily observe, analyze and  solve problems from different granularity.

Traditional data mining methods are mostly single-level  association rule mining. In practice, because of the sparsity of  the data in multi-dimensional data space, it is very difficult to  find out strong association rules among the low-level data  items. For instance, the apparent hierarchy, fruit -- fresh fruit --  apples, is usually recorded by the particular item "Apple" in the  database. The traditional association rule mining algorithm can  only get such association rules as "Apple - Chestnut ", while  other higher level association rules, such as "fresh fruit  nuts",  can not be derived. So we require to spot strong association  rules at a higher level to obtain meaningful knowledge.

Minimum support and minimum confidence are two important  factors in the process of mining association rules, while  minimum confidence is obtained by minimum support, so the  minimum support becomes a key factor that has an impact on  mining association rules. Usually, there is only one minimum  support in the whole process in the traditional association rules  method.As the following two rules:  Buys?X?fresh fruit? ?buys?X?chestnut  [sup=8%?confidence=70%]       ?Formula 1?

Buys?X?apple? ?buys?X?chestnut?

[sup=2%?confidence=70%]       ?Formula 2?

If the minimum support is set to 8%, we can not find the  underlying rules (Formula 2); if it set to 2%, it may generate  association between frequent itemsets because of the too low  minimum support. Therefore it may arise a lot of meaningless  rules, leading to combinatorial explosion. So, we make use of  multiple minimum support of the data items to generate all the  frequent itemsets, and use minimum confidence to generate all  the association rules. In this way, we can find different rules  relied on different data items by different minimum support.

Using this new model can find rules contained in new scarce  items, and avoid to generate large amounts of useless rules  because of high frequency itemsets.

In this paper, through the hierarchical coding of attributes,    we give granularity, support, multi-minimum supports and  several other basic definitions of terms based on binary  information granules from the perspective of information  granulation. Then we proposed a multi-level association rules  mining method based on binary information granules in  granular computing and multi-minimum support constraint. By  the application of association rules in the agricultural products  Information, we prove that the proposed method can reduce the  generated search space of frequent itemsets effectively, and can  achieve multi-layer association rules (including cross-level  association rules) as well as more interesting rules.



II. RELATED CONCEPTS  Let the item set I = {a1,a2,,am} be a set of m different  items .For a set A, if  A? I  and k =|A|, then it is called k item  sets.

For a given transaction database D, transaction number in  the D is called support of A, which is denoted by sup (A).

For the minimum support ,which defined by users is less  than |D|, and denoted by s.

Based on the above assumptions, we have the following  definition:   978-0-7695-4077-1/10 $26.00  2010 IEEE  DOI 10.1109/ICICTA.2010.656   Definition 1: For a given transaction database D and  support s, for the item-set A? I, if sup (A) ?  s, then A is called  the frequent itemsets of D.

Definition 2: For the item set A = {a1,a2,,am} (1 ?  k ?

m) ,if MIS?A?=min[MIS(a1), MIS(a2),?MIS(ak)], then  MIS (ai) is called the minimum support of the item ai.



III. HIERARCHICAL ASSOCIATION RULES BASED ON  GRANULAR COMPUTING  A. Hierarchical structure coding  The relationship of nodes among the tree structure can  constitute a hierarchical classification structure. If the child  nodes of the tree structure have sequential relationship, it is  called ordered tree. Using different symbols mark at each node  of the ordered tree, so the tree is called addressing trees. Both  the general tree structure and the ordered tree structure can  express the hierarchical structure easily, express the multi-level  concept or use the concept to achieve multi-level algorithm.

Figure 1.  Hierarchical classification structure  We select the interesting properties, and use the  hierarchical structure to encode data from the multi-level  structure of the projects to the projects of various single-level  structures. Then we obtain a multi-level association rules  through the single-level structure of the various projects. Such  as the user's purchase information shown in Table 1, is  corresponding to Figure 1 of the fruit-level as the layer of 0,  and then can be divided into first level and second level and so  on. Take the transaction identifier TID "121" as an example,  the first "1" in TID corresponds to the first layer of the "fresh  fruit." the second "2" in TID corresponds to the second layer of  "melons." Finally, the "Watermelon" corresponds to the last  "1" in TID, belonging to the third layer. So 121 in TID  represents the watermelon of the melons in the fruit, you can  encode values to correspond to the hierarchical structure  quickly.

TABLE I.  TRANSACTION DATABASE  TID Items Hierarchical coding Level 2 Level 1  T1 {chestnut?apple} {22*?111} {22*?11*} 2**?1**}  T2 { wild grape?watermelon} {3**?121} {12*} {3**?1**}  T3 { watermelon?pear} {121?112} {12*?11*} {1**}  T4 {chestnut?watermelon?apple}  {22*?121?

111}  { 22*?12*  ?11*}  {2**?

1**}  T5 { wild grape } {3**}  {3**}  T6 { chestnut } {21*} {21*} {2**}  B. The definition of support and confidence based on  Granular Computing  When we settle and process a large number of complex  information issues, the information in accordance with their  respective characteristics and performance can be divided into  a number of relatively simple pieces, each of these is called a  information granule. Some definitions of granules are as  follows[2-4] .

Definition 3, for a given information system S = (U, A = C  ? D), where U is the entire set of objects, A is an attributes set    composed of condition attribute set C and decision attribute set  D. Let B ? C, if the range of B is VB = (b1, b2, b3, ..., bK),  the number of range B is | VB | = k, and | U / IND {B}| = k,  then B can be decomposed into k binary information granules  by quotient set|U/IND {B}|The decision attribute set D can be  decomposed into | U / IND (D) | binary information granules  by quotient set |U/IND {D}|.

For example: The values in corresponding to the objects of  the item of TID in Table 1 were {chestnut, apple, wild grape,  watermelon, pears, walnuts}, can be decomposed into six  binary information granules as follows:a1={100100} ?

a2={100100}?a3={010010}?a4={011100}?a5={001000}  ?a6={000001}.

Definition 4 The number of 1 in the binary information  granules P is defined as granularity of the binary information  granules, which is denoted by | P |.

For example: The granularity of the binary information a1  = (100100), a6 = (000001) are respectively 2 and 1.

Definition 5 For a given information system S = (U, A = C  ? D), {C1?C2??Ck}?C , ci is a binary information grain  in Ci, then we have the granularity associated with computing  is ci?cj??ck (where ? on behalf of binary Boolean "and"  operator).

For example: Two binary information granules are a1=  (101000011001) and b2 = (100101001101). Associate  operation is as follows: 101000011001 ? 100101001101 =  100000001001.

Based on the above definition, we give the definitions of  support and confidence based on binary information granules  as follows.

Definition 6 For any item set X ? I, Y ? I, X ? Y =?, the  support of X is sup (X) = |[X]|/ | U |, where | U | is the number  of collection of objects; [X] = [x1] ? [x2] ? ... ? [xn], xi is  one of the project in X; Y is the same like X.

The support of the rule X?Y :  sup(X ? Y) =|[X]?[Y]|/|U|  The confidence of the rule X?Y :  confidence(X?Y)= (sup(X?Y)/|U)|/ (sup(X)/|U|)= sup(X  ?Y) / sup(X)  For example ? The support between the two binary  information granules a1 and b2 is sup(a1 ?

b2)=|100000000001|/|U|=2/12=1/6?The confidence of a1 is  confidence(a1?b2)= sup(a1?b2) / sup(a1)=2/5.

C. The computing of multiple minimum support based on  granular computing  When we use multiple minimum support in the multi-level  association rules, we can get the rules of high frequency of data  entry rules by higher minimum support, as well as low  frequency data entry rules by lower minimum support. In this  paper, for setting multiple minimum support of each item, we  adopt the multiple minimum support proposed by Lin[5] to  remove some redundant rules as much as possible, and to  reduce the generation search space of frequent itemsets.

Definition 7 Let I={a1?a2??an},and sup?ai??sup  ?ai+1?,1?i?n-1, Then minimum support can be specified as  follows:  ??

?

=  ???

=  +  niasup  1ni1asupasup  )MIS(a  i  1ii  i ??

????

Definition 8 Let A ? B be a frequent itemset, A ?  B = ,  and without loss of generality, let a? A , and a be the one with  the smallest minimum support, i.e. MIS(a)= mina BA?? MIS(ai). if  the minimum support of a is set as MIS (a) = sup (a)  minconf, then the association rule A?B is strong.

Summarize the above two different definitions of the  minimum support, so that the overwhelming majority of rules  generated are effective. To prune the spurious frequent itemsets  so as to make most of the generated rules become interesting,  we combine these two specifications as shown below, which  we call the definition 9.

Definition 9 Let I={a1?a2??an},and sup?ai?? sup  ?ai+1?,1 ? i? n-1, Then minimum support can be specified as  follows:    ??

?

=  ???

=  +  niasup  1ni1}asupminconf{maxasup  )MIS(a  i  1ii  i ??

?????

For example: we can see from Table 2, the support of [1  **] is 4/6, and the support of [1 **] is the greatest in the all  items, so its MIS value is its own support 2/3. From this  calculation, we can draw the support of various items and items  among layers in Table 3.



IV. APPLICATION EXAMPLE  We use the form of a hierarchical structure to encode the  user purchase information in table 1, express the value in the  corresponding with the various items hierarchical encoded of  the TID by information granulation, and calculate the support  corresponding to each item encoded by the hierarchical  structure, which are shown in table 2. Through the definition  of multiple minimum supports based on Granular Computing  and the minimum support derived form the various items  calculated in Table 2,we can calculate minimum supports  corresponding to each item and level-items and show  in Table  3.

The entire mining process of multi-level association rules is  start at the search of is high-level frequent itemsets. Each item  has a minimum support by definition 2. Search the transaction  data in table 2 to find the frequent itemsets which meet the  minimum support in same layer and multiple layers, while  record them in table 4. For example, we calculate the multiple  minimum support of [1 **] and [2 **] is1 / 3, sup ([1 **] [2  **]) = | (111100 ? 100101) | / | 6 | = | 100100 | / 6 = 2 / 6,  which meet the minimum support 1 / 3. therefore, [1 **] and [2  **]are combined as frequent itemset. To extract the frequent  itemsets repeatedly, and filter the candidate itemsets which  does not meet the minimum support. Finally all the frequent 2 -    itemsets are shown in table 4. While no further increase in  levels, the entire search process will end.

Then we find frequent 3 - itemsets from all the frequent 2-  itemsets in table 4 which meet the multiple minimum support  of definition 2, and filter out the candidate itemsets which does  not meet. Repeatly extract the frequent 3  itemsets, until the  entire search process is completed, the results is shown in table  5.

The generation process of frequent itemsets of multi-level  mining is as follows.

TABLE II.  THE EXPRESSION ANDSUPPORT OF BINARY INFORMATION  GRANULE  The Name of Information  Granule  The Expression of Binary  Information Granule Support  [21*] 000001 1/6  [112] 001000 1/6  [3**] 010010 2/6  [22*] 100100 2/6  [111] 100100 2/6  [11*] 101100 3/6  [12*] 011100 3/6  [121] 011100 3/6  [2**] 100101 3/6  [1**] 111100 4/6  TABLE III.  MULTIPLE MINIMUM SUPPORTS  Items MIS Items MIS  [1**] 2/3 [21*] 1/12  [2**] 1/3 [22*] 1/6  [3**] 1/6 [111] 1/6  [11*] 1/4 [112] 1/12  [12*] 1/4 [121] 1/4  TABLE IV.  TABLE TYPE STYLES  The Combination  of Items  The Expression of Binary Information  Granules Support  [1**]and[2**] 100100 2/6  [1**]and[22*] 100100 2/6  [1**]and[3**] 010000 1/6  [11*]and[12*] 001100 2/6    [11*]and[22*] 100100 2/6  [11*]and[2**] 100100 2/6  [11*]and[121] 001100 2/6  [12*]and[111] 000100 1/6  [12*]and[112] 001000 1/6  [12*]and[22*] 000100 1/6  [12*]and[3**]  010000 1/6  [111]and[2**]  100100 2/6   [111]and[22*] 100100 2/6  [111]and[121] 000100 1/6  [112]and[121] 001000 1/6  [121]and[22*] 000100 1/6  [121]and[3**] 010000 1/6  TABLE V.  TABLE TYPE STYLES  The Combination of Items  The Expression of  Binary Information  Granules  Support  [11*]and[12*]and[22*] 000100 1/6  [11*]and[121]and[22*] 000100 1/6  [12*]and[111]and[22*]  000100 1/6  [12*]and[111]and[2**] 000100 1/6  [121]and[111]and[22*] 000100 1/6  [121]and[111]and[2**] 000100 1/6  The multiple minimum support of each item is compared  with the support assembled by various items shown in the table  4, then we can get the sets of the table 5. From the results, we  can get the association rules of the same layer, such as [11 *]  and [12 *] and [22 *], and they all satisfy the minimum support  MIS ([11 *] and [12 *] and [ 22 *]) = min [MIS ([11 *]), MIS  ([12 *]), MIS ([22 *])]= 1 / 6; we can also get the association  rules of different layers, such as [12 *] and [111] and [2 **],  they also satisfy the minimum support MIS ([12 *] and [111]  and [2 **])= min [MIS ([12 *]), MIS ([111 ]), MIS ([2 **])]= 1  / 6, so that we achieve the multi-level association rules.

Different rules support of different data items produced  need to meet different multiple minimum support in order to  find these rules, such as the support of [12 *] and [2 **] is sup  ([12 *] and [2 **])= (011100 ? 100101) / 6 = 1 / 6, while the  multiple minimum supports MIS ([12 *] and [2 **])= min    [MIS ([MIS ([12 *]), MIS ([2 ** ])] = 1 / 4> MIS ([12 *] and  [2 **]). Therefore, we can delete this rule, reducing the  frequency down-generating search space of frequent itemsets.



V. CONCLUSIONS  This paper presents a multi-level association rule mining  method based on binary information granules operations and  multiple minimum support constraint, with hierarchical  encoding and binary granular computing of information  granules operation to acquire frequent itemsets at intra level as  well as inter level. We give a new definition of support and  confidence based on binary information granules. And  combined with the definition of multiple minimum supports,  we effectively restrained the generation search space of  frequent itemsets, and found new rules implied in the scarce  data items, achieved association rule mining of multi-layer  including cross-layer. We got more meaningful rules, and  avoided the generated useless rules from the high frequency  data items. At last, the method is applied to mining agricultural  information association rules, which has been proven to be  effective and practical.

