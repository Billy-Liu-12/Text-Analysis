Using the Real, Gentle and Modest AdaBoost Learning Algorithms to Investigate the Computerised Associations between Coronal Mass Ejections

Abstract- Space weather forecasting is a very challenging task and investigating the associations between properties (i.e., shape, scale, location) of the related solar features, appearing in solar images, are usually complicated because of the variation in their physical and visual properties. Establishing the correlations among the occurrences of solar activities and solar features is a long-standing problem in solar imaging. This work is an attempt to shed more light on the drivingforces behind the initiations of Coronal Mass Ejections (CMEs). This is still a big mystery in this field and in this work we have analysed years ofdata relating to one particular feature, filaments, to determine if an association between filaments and the eruptions of CMEs can be drawn. The resulting association set has been fed to a powerful machine learning algorithm to determine if CMEs can be predicted solely based on filaments. Our learning algorithm, AdaBoost, is used because of robust and accurate performance. Three of the most common versions of the Adaboost algorithm are used in this work, which are the Gentle AdaBoost, the Real AdaBoost and the Modest AdaBoost.

Index Terms-Data mining; machine learning; information retrieval, AdaBoost, Solar Imaging, space weather;

I. Introduction  The term space weather refers to conditions on the Sun, in the solar wind, and in the Earth's magnetosphere, ionosphere, and thermosphere that may affect space-borne or ground-based technological systems and endanger human health or life [1]. The importance of space weather is increasing as more human activities  take place in space, and as more reliance is placed on communications and power systems.

Solar flares and Coronal Mass Ejections (CMEs) are the most dramatic solar events affecting the terrestrial environment. The Earth environment and geomagnetic activity are affected by the ionized solar plasma, known as the solar wind. Solar wind flows outward from the sun to form the heliosphere and it is affected by solar activity and carries with it the magnetic field of the Sun [2]. This interplanetary magnetic field (IMF) creates magnetic storms by injecting plasma into the Earth's magnetosphere [3, 4].

Geomagnetic storms are correlated with CMEs [5] and predicting CMEs can be useful to forecasting space weather [6]. Previous CMEs research [7-9], reported that most CME events are associated to some extent with eruptive filaments/prominences and/or solar flares.

Currently, five major CME eruptions models exist [10-13]. These are: the Thermal Blast, the Dynamo, the Mass Loading,. the Tether Release and the Tether Straining Models. The last three are storage and release type models, where a slow build-up of magnetic stress occurs before eruption begins [14]. The model which is directly related to this work is the Mass loading model. This can be manifested during the pre- eruption phase of a CME in the fonn of a growing quiescent or eruptive filament. Mass loading can be associated with prominences, which are extremely dense, contained in a compact volume, and of chromospheric temperature. Prominences are thought to play a major role in CME eruptions because of their coincident starting, according to observations reported in [15, 16]. And the mass of the prominence is considered as a crucial criterion for CMEs eruptions [17, 18].

The exact degree of association is not clear because most of the available studies have been  MIC-CCA 2008 Page 37    carried out on only a few years of data or on limited cases and using physics-based modelling. In some cases, contradictory findings have been reported. For example, not all researchers agree that strong relationships exist between CMEs and filament/prominence eruptions. In reference [19], for example, it was reported that the association rate was about only 30%. On the other hand, it was reported in [20] that more than 94% of the CMEs studies were associated with eruptive prominences/filaments.

This means that the exact degree of association is one of the long standing uncertainties in solar research and it is the aim of this paper to reduce this uncertainty. An example of an associated CME-Filament pair is depicted in Figure 1 (filament) and Fi re 2 CME.

Figure 1 H-alpha 6563 Afull disk image taken on 19 Jul 2001 at 09:49 UT showing a filament with centroid located in S20W59.

Figure 2 LASCO C2 image taken on 19 Jul 2001 at 10:30 UT showing a Partial Halo CME with central position angle of 275?.

The work presented here is an extension of previous work, described in references [21-23], which designed computer vision systems to analyse the associations between solar flares and sunspots and also between flares and CMEs.

This work has been extended by carrying out a larger-scale analysis of associations for years of  solar data contained in CMEs and filaments catalogues. In addition, the knowledge extraction introduced in this paper uses the AdaBoost algorithm for the automated prediction of CMEs based on features extracted from filament catalogues. The data used in this study are from the publicly available NGDC filament catalogue [24] and the SOHOILASCO CME catalogue [25].

This paper is organised as follows: Section 2 explores the AdaBoost algorithm. Section 3 describes the creation of our training set and our Computer Platfonn for CME Prediction. The practical implementation and evaluation of the learning system is discussed in Section 4.

Concluding remarks and recommendations for future work are presented in Section 5.



II. Adaptive Boosting Algorithm  In some real-time situations experts identify rules of thumb that they can use to predict the outcomes of certain situations on the basis of their accumulated experience. To maximise the advantages associated with the use of these rules of thumb they need to be represented using computerised rules. However, this process faces two problems. Firstly, how to choose the collections of data presented to the experts in order to extract a representative set of rules of thumb? Secondly, how to combine the selected rules of thumb into a single and accurate prediction rule?

The principle of boosting could provide a solution to the problems highlighted above.

According to [26], "Boosting refers to a general and provably effective method of producing a very accurate prediction rule by combining rough and moderately inaccurate rules of thumb in a manner similar to that suggested above." Boosting enhances the perfonnance of a weak learning algorithm, which perfonns slightly better than random guessing, into an arbitrary strong learning algorithm.

The AdaBoost procedure, short for Adaptive Boosting, algorithm was introduced in reference [26] and a pseudo code description is shown in Figure 3. As shown in this figure, the algorithm takes as input a training set (Xl, Yl), .. .,(xm, Ym) where each Xi represents a vector of extracted features from the input space and each label Yi represents the associated class, which is usually  MIC-CCA 2008 Page 38    Figure 3 The AdaBoost algorithm.

CMEsinthis region are not  associated with the shown filament  Figure 5 CME-Filament association example  In this work, all the CME and filament data in the period from January 1996 until the end of December 2001 were processed, analyzing data relating to 5449 CMEs and 7332 eruptive filaments/prominences.

By applying the association algorithm an associated data set, consisting of 522 filaments with 209 (40%) A filaments and 313 (60%) NA filaments, was created. Properties such as start time, end time, location, type and extent of the  Figure 4 Location-based CME-Filament association  Using these criteria we automatically associate the filament of Figure 1 and the CME of Figure 2 as shown in Figure 5. After finding all the associations, a numerical dataset was created for the learning algorithms using all the associated and not-associated filaments.

Angle (CPA) for every CME is compared with the angular polar coordinate of the centroid of every filament.

An associated filament is labelled "A" and a not-associated filament is labelled "NA" as explained below: ? If a CME is not recorded within 60 minutes  before or after the time a filament disappears, then this filament is labelled NA.

? Otherwise, if the CPA for the recorded CME is located within ?30? of the centroid of the filament, as shown in Figure 4, then this filament is labelled A [27].

(1)ft = E Dt(i) i:ht (Xi ),eYi  Given:(Xl' Yl), "., (Xm , Yrn) ,vhere Xi EX, Yi E Y = {-1,+1}  Initialize D 1 = .ltn Fort=O,???,T:  ?Train \veak learner using distribution D t ? ?Get weak hypothesis ht:X ---+ {-I, +1} ,vith error Et = PrirvDi [ht(Xi) =1= Yi]  ?Choose (Xt = ~lr~( l~t~t)  U d .D (.)_ D(i) {e-Ot if ht(Xi)== Yi. pate. t+1 't --ZX Ot ?fh ( .. )-/.. .

tel t l:,~ I Yl  \vhere Zt is a normalization factor.

Output the final hypothesis:  H(x) = sign(L,;=l Otht(x)).

either -lor 1. As described in [26] a weak or base learning algorithm is called repeatedly in a series of rounds t == 1, ... , T. AdaBoost maintains a distribution or set of weights over the training set. Dt(i) represents the weight of this distribution on training example i and round t.

The training starts with all the weights set equally. On each round, the weights of incorrectly classified examples are increased to force the weak learner to focus on the hard examples in the training set. The error is measured with respect to the distribution D t on which the weak learner was trained. The weak learner finds a weak hypothesis ht appropriate for D t? The error associated with ht is found as follows:

III.Association Algorithms and the Prediction System  In this work we introduce a computer platform that analyses all the available years of data in the filament and CME catalogues and defines learning rules to provide automated predictions for CMEs. A C++ platfonn was created to automatically associate CMEs in the SORa/LASCO catalogue with filaments in the NGDC solar filaments catalogue. The association is determined based on timing and location information; the date and time for every CME is compared with the date and time for every filament. In addition, the Central Position  MIG-GGA 2008 Page 39    filaments can be extracted from the NGDC filaments catalogue. We wanted to include more features but unfortunately a large number of the associated filaments do not have location details given for both ends. As it was not clear which properties are more important for machine learning and for the prediction of CMEs it was decided to carry out extensive experiments in order to detennine the significance of each property for this application. The properties selected are shown in Table 1.

Table 1 Groups of properties that are used as input nodes in the AdaBoost algorithm  Group Inputs 4 Timing, duration, type, extent 3 Timing, duration, type 2 Timing, duration 3a Timing, duration, extent 3b Timing, type, extent 2a Timing, type 2b Timing, extent

IV. Practical Implementation and Results  IJJ:A The Learning Algorithm For this work we have implemented three different boosting algorithms: Real AdaBoost, Gentle AdaBoost and Modest AdaBoost. Real AdaBoost is the boosting algorithm reported in [28], which is a generalisation of the basic AdaBoost algorithm introduced by [29]. The Gentle AdaBoost, introduced in [30], is a more robust and stable version of the Real AdaBoost algorithm and perfonns slightly better than the latter on regular data and considerably better on noisy data [30].

Modest AdaBoost, described in [31], can provide better generalization capability and higher resistance to over fitting compared to the alternative AdaBoosts. In addition, Modest AdaBoost, in certain cases, can provide good perfonnance in tenns of test error. The three AdaBoost algorithms have been implemented using the GML AdaBoost matlab toolbox, which is publically available at: http://research.raphiconru/achine-Iearning!gml- adaboost-matlab-toolbox.html.

All the machine leaming!training and testing experiments have been carried out with the aid of the Jack-knife technique [32]. This technique  is used to provide a correct statistical evaluation of the perfonnance of a classifier when implemented on a limited number of samples.

The technique divides the total number of samples into two random sets: a training set and a testing set [32]. In this work, all the experiments were carried out using 80% randomly selected samples for training and the remaining 20% for testing.

IJJ:B The Practical Implementation The CME prediction perfonnance was evaluated using the Receiver Operating Characteristic (ROC) analysis technique [33]. Intensive training totalling 5 learning experiments, with 1000 iterations for each experiment, were carried out for the optimum group of input features, which is proven to be three in reference [34]. Each experiment involved training on a random set of associated sets followed by a testing phase on the remaining sets. As explained previously these sets were obtained using the Jack-Knife technique and were quite different for each experiment. The ROC perfonnance indicators were found for every experiment. These indicators are TP, FP, FN, TN, accuracy, specificity and sensitivity, all calculated as explained in reference [33]. The averages of these indicators over all the experiments and for the three AdaBoost algorithms are shown in Table 2.

Table 2 Average ROC performance indicators for different input combinations  Real Gentle ModedstAlgorithm AdaBoost AdaBoost AdaBoost  TP 0.57407 0.46296 0.57407 FP 0.25658 0.11842 0.26316 FN 0.42593 0.53704 0.42593 TN 0.74342 0.88158 0.73684  Acc. 0.67308 0.70769 0.66923 Spec. 0.74342 0.88158 0.73684 Sense 0.57407 0.46296 0.57407 The TP and FP values obtained from all the  experiments on the three types of AdaBoost algorithm are plotted in Figure 6 and are used to detennine the input group providing the best perfonnance. The best perfonnance shown in a ROC curve is the one furthest away from the random guessing diagonal line in the northwest  MIG-GGA 2008 Page 40    direction [33]. This was used to detennine the optimal values shown in Table 2.

o55 ------------1------.-.~?:--f--?-:---:----h-~-~-~-~-~-~rd-~-:--?-??  0.5 . ---- -.- --- -~-.-- ---- -:---~-~-. ???:????-r-~-:-:~~*~ ~~-- ---- : ..;,. : . .~. ....

~ '" ?:~,????T?:?;;l;?????????j:?????????f?;?:?:???? 0.4 - ------- -.- -~. -.- .?? -.- .? -.~- ??? ---- --- --~. -- ?? -- --- ----~- -----------  : : : ~  035 -.---.-.-- .. ~.. -.. -... -..-.~-----------).. -.. --.--.---~-.---------- 1 1 1 ~  0.25 OJ  Figure 6 The ROC graph for the AdaBoost learning experiments

IV. C Discussion ofResults As indicated in the introduction, the prediction of CMEs is a long standing problem in solar physics. It is well agreed that CMEs eruptions are associated with other phenomena such as filaments and flares. In this work we are investigating the mass loading model, of CME eruptions, which assumes that filaments are associated with this phenomena. Hence, in this work we only focus on the one factor, to study its significance for CME eruptions using machine learning. The resulting prediction rate will enable us to measure the significance and accuracy of this model.

As shown in Table 2, the Adaboost algorithms provides good accuracy compared to our previous study with Radial Basis Functions [34], but still not very high values because of the physical nature of CMEs as explained above.

Compared to Radial Basis Functions they provide lower TP rates but also higher TN rates.

The best prediction performance, measured in terms of the accuracy of predictions is 70.8% and is provided by Gentle AdaBoost. However, the high accuracy value is caused mainly by the high TN value which is 88.1% not by the TP value which is 46.3%. This TP value is very low and even a random guesser would perfonn better than this. Hence a major conclusion of this study is that the Gentle AdaBoost can provide reliable performance if used as a rejection classifier to predict when CMEs are not likely to occur. It is less efficient ifused as a positive classifier tool.

The Real and Modest AdaBoosts provide higher TP rates but their accuracy and TN rates are lower. It is worth noting that the TP rates  provided by the Real and Modest AdaBoosts are not as high as the TP rates provided by Radial Basis Functions used in our previous work [34].

Hence, it is not very feasible to use them within the context of this problem.



V. Conclusions and Future Research  In this paper, we propose a novel machine- learning based system that analyses the available data in the NGDC filament catalogues and the SOHO/LASCO CME catalogues. Our system associates CMEs with filaments and represents these associations numerically in training vectors, which are input to the Real, Gentle and Modest AdaBoost learning algorithms. The AdaBoost algorithms are used because of their advantages, highlighted in Section 2. One of the major findings of this work is that the Gentle AdaBoost algorithm can provide accurate performance if used as a rejection classifier to predict when a CME is not likely to occur.

In this work we provide an objective and computerised representation of the degree of association between solar filaments and CMEs based on historical solar data and represent it using learning rules. This work has the potential to be used to measure the accuracy of the existing CMEs models, which exhibit high degrees of conflict. It can shed more light on the pre-conditions associated with CMEs eruptions.

The creation of automated and reliable prediction systems that can predict the extremes of space weather depends on the creation of machine learning-based representations of these associations. In the near future, we will investigate the association of CMEs with flares and compare our findings with the reported associations with filaments.



VI. References  [1] H. Koskinen, E. Tanskanen, R. Pirjola, A. Pulkkinen, C.

Dyer, D. Rodgers, P. Cannon, J.-C. Mandeville, and D.Boscher, "Space Weather Effects Catalogue," FMI, QinetiQ, RAL Consortium 27, 2001.

[2] M. Pick, C. Lathuillere, and J. Lilensten, "Ground Based Measurements," Alcatel-LPCE Consortium 2001.

[3] L. S. Yevlashin and Y. P. Maltsev, "Relation between Coronal Mass Ejections, Solar Flares, Certain Parameters of the Magnetosphere, and Different Auroras during Great Magnetic Stonns," Geomagnetism and Aeronomy, vol.

43,pp.291-297,2003.

MIG-GGA 2008 Page 41    [4] V. Yurchyshyn, H. Wang, and V. Abramenko, "How Directions and Helicity of Erupted Solar Magnetic Fields Define Geoeffectiveness of Coronal Mass Ejections," Advances in Space Research, vol. 32, pp. 1965-1970, 2003.

[5] R. M. Wilson and E. Hildner, "Are interplanetary magnetic clouds manifestations of coronal transients at 1 AU?," Solar Physics, vol. 91, pp. 169-180, 1984.

[6] D. F. Webb, "Understanding CMEs and their source regions," Journal of Atmospheric and Solar-Terrestrial Physics, vol. 62, pp. 1415-1426,2000.

[7] R. H. Munro, J. T. Gosling, E. Hildner, R. M.

MacQueen, A. I. Poland, and C. L. Ross, "The association of coronal mass ejection transients with other foons of solar activity," Solar Physics, vol. 61, pp. 201-215, 1979.

[8] A. I. Poland, R. A. Howard, M. J. Koomen, D. J.

Michels, and N. R. Sheeley, "Coronal transients near sunspot maximum," Solar Physics, vol. 69, pp. 169-175, 1981.

[9] S. Yashiro, N. Gopalswamy, S. Akiyama, G. Michalek, and R. A. Howard, "Visibility of Coronal Mass Ejections as a Function of Flare Location and Intensity," Journal of Geophysical Research, vol. 110, 2005.

[10] J. A. Klimchuk, "Theory of Coronal Mass Ejections," Space Weather (Geophysical Monograph 125), ed. P.

Song, H. Singer, G. Siscoe (Washington: Am. Geophys.

Un.), vol. 125, p. 143,2001.

[11] B. C. Low, "Magnetic Energy and Helicity in Open Systems," in Magnetic Helicity in Space and Laboratory Plasmas: Geophysical Monograph 111, M. R. Brown, R.

C. Canfield, and A. A. Pevtsov, Eds. Washington, DC USA: The American Geophysical Union, 1999, p. 25.

[12] B. C. Low, "Coronal mass ejections, magnetic flux ropes, and solar magnetism," Journal of Geophysical Research, vol. 106, pp. 25141-25164,2001.

[13] B. C. Low, "Solar Coronal Mass Ejection: Theory," in Encyclopedia ofAstronomy and Astrophysics, P. Murdin, Ed. Bristol: Institute of Physics Publishing, 2001.

[14] M. J. Aschwanden, Physics of the Solar Corona: An Introduction. Chichester, UK: Praxis Publishing, 2004.

[15] B. C. Low, "Solar activity and the corona," Solar Physics, vol. 167, pp. 217-265, 1996.

[16] B. C. Low, "Coronal Mass Ejections, flares and prominences," in The solar wind nine conference, Nantucket, Massachusetts (USA), 1999, pp. 109-114.

[17] B. C. Low, B. Fong, and Y. Fan, "The Mass ofa Solar Quiescent Prominence," The Astrophysical Journal, vol.

594,pp.l060-1067,2003.

[18] M. Zhang and B. C. Low, "Magnetic Energy Storage in the Two Hydromagnetic Types of Solar Prominences," The Astrophysical Journal, vol. 600, pp. 1043-1051, 2004.

[19] G. Yang and H. Wang, "Statistical Studies of Filament Disappearances and CMEs," in Solar-Terrestrial  Magnetic Activity and Space Environment, Proceedings of the COSPAR Colloquium held in the NAOC. , Beijing, China, 2002, p. 113.

[20] G. Zhou, J. Wang, and Z. Cao, "Correlation Between Halo Coronal Mass Ejections and Solar Surface Activity," Astronomy and Astrophysics, vol. 397, pp.

1057-1067,2003.

[21] T. Colak and R. Qahwaji, "Automated McIntosh- Based Classification of Sunspot Groups Using MDI Images," Solar Physics, 2007.

[22] R. Qahwaji and T. Colak, "Automatic Short-Term Solar Flare Prediction Using Machine Learning and Sunspot Associations," Solar Physics, vol. 241, pp. 195- 211, 2007.

[23] R. Qahwaji, T. Colak, M. AI-amari, and S. Ipson, "Prediction ofCMEs Using Automated Machine Learning of CME-Flare Associations," Solar Physics, Topical Issue on Solar Imaging, vol. 248, pp. 471 - 483, 2008.

[24] NGDC, "The National Geophysical Data Centre,"flo://ftp.ngdc.noaa.gov/STP/SOLAR OATA, 2007.

[25] SOHO/LASCO, "SOHO LASCO CME Catalogue,''http://cdaw.gsfc.nasa.gov/CME list!,2007.

[26] Y. Freund and R. E. Schapire, "A decision-theoretic generalization of on-line learning and an application to boosting," Journal ofComputer and System Sciences, vol.

55,pp. 119-139,1997.

[27] J. Jing, "Dynamics of Filaments, Flares and Coronal Mass Ejections (CMEs)," in http://archives.njit.edu/vol01/etd/2000s/2005/njit- etd2005-073/njit-etd2005-0 73. pdfthesis: PhD, 2005.

[28] R. E. Schapire and Y. Singer, "Improved boosting algorithms using confidence-rated predictions," Machine Learning, vol. 37, pp. 297-336, 1999.

[29] Y. Freund and R. E. Schapire, "Game theory, on-line prediction and boosting," in Proceedings of the Ninth Annual Conference on Computational Learning Theory, 1996, pp. 325-332.

[30] J. Friedman, T. Hastie, and R. Tibshirani, "Additive logistic regression: A statistical view of boosting," The Annals ofStatistics, vol. 38, pp. 337-374,2000.

[31] A. Vezhnevets and V. Vezhnevets, Modest AdaBoost- teaching AdaBoost to generalize better. Graphicon,2005.

[32] K. Fukunaga, Introduction to Statistical Pattern Recognition. New York: Academic Press, 1990.

[33] T. Fawcett, "An introduction to ROC analysis," Pattern Recognition Letters, vol. 27, pp. 861-874,2006.

[34] R. Qahwaji, M. AI-amari, T. Colak, and S. Ipson, "Computerised Representation of the Association between Solar Features and Activities using Radial Basis Visualization, Imaging and Image Processing (VIIP 2008) Palma de Mallorca: Spain, 2008.

