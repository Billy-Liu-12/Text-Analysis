Improving the Processing of Decision Support Queries:  The Case for a DSS Optimizer

Abstract Many decision support applications are built upon  data mining and OLAP tools and allow users to answer information requests based on a data warehouse that is managed by a powerj5ul DBMS. In this paper, we focus on tools that generate sequences of SQL statements in order to produce the requested information. Our thor- ough analysis revealed that many sequences of queries that are generated by commercial tools are not very e f l - cient. An optimized system architecture is suggested for these applications. The main component is a DSS opti- mizer that accepts previously generated sequences of queries and remodels them according to a set of optimi- zation strategies, before they are executed by the under- lying database system. The advantages of this extended architecture are discussed and a couple of appropriate optimization strategies are identifed. Experimental re- sults are given, showing that these strategies are appro- priate to optimize query sequences of OLAP applications.

1. Introduction  During the last decade data warehouses turned out to be the common basis for the integration and analysis of data in modern enterprises. Decision support applications are used to analyze data on the operational level as well as on the strategic level. This includes techniques like online analytical processing (OLAP) and data mining.

Additional tools are used for the preprocessing and inte- gration of data from different sources.

A lot of work has been done on decision support sys- tems and their optimization. In the field of data mining the focus was on algorithms. There is for example a huge set of algorithms for mining association rules including parallel algorithms [l 11 [2]. For OLAP applications, sev- eral important aspects have been discussed in literature.

One is the integration of additional operators into the database system, e.g. the cube operator [9] [lo] and its efficient implementation [ 121. Query primitives that al- low related query plans to share portions of their evalua- tion are introduced in [34]. Another focus is the use of  specific index types in order to optimize typical OLAP queries [ 181 [ 191. There has also been a lot of work in the area of using materialized views to answer decision sup- port queries and the maintenance of these materialized views [3] [27] [28] [33]. Our work is recognizing this previous work, but also complementing it. We are not aware of any comparable approach that involves a sepa- rate optimizer in between the decision support tool and the data warehouse database system (DWDBS) as we suggest it.

In this paper, we focus on a commonly used process- ing model for decision support systems (DSS). According to this model, the application generates a sequence of SQL statements, which is processed by the DWDBS. The result tables of the statements in a sequence build the basis for the final result that is presented to the user as reply to hislher information request. SQL is used as query language because most data warehouses are based on a relational or extended relational database system. As the information requests of the users are likely to be very complex, many applications produce sequences of rather simple statements for each request in order to reduce the complexity of the query generation process and in order to preserve portability to other database systems.

We analyzed tools that work according to this model and found that there are many possibilities to improve the query sequences they generate and the way they are exe- cuted. We will show that several of these approaches are independent of the application and its special query gen- eration process. Hence, they could be used for many de- cision support applications that are run on a data ware- house. This leads us to an optimized system architecture.

The central element of this architecture is a DSS opti- mizer that accepts sequences of SQL statements. The sequences are processed according to a set of optimiza- tion strategies. An optimized version of the sequence is sent to the DWDBS and executed there. As in the original model, the application uses the partial results in order to produce the final result for an information request. The strategies we suggest for the DSS optimizer include the combination of a sequence of statements into a single complex statement, semantic rewrite strategies, parallel execution of statements in a query sequence as well as  1098-8068/01 $10.00 0 ZOO1 IEEE  http://uni-stuttgart.de   providing additional statistical information for the query optimizer of the DWDBS.

This paper is organized as follows: In Section 2 we describe our application scenario and the common archi- tecture of decision support systems. The optimized archi- tecture that includes a.DSS optimizer as an additional component is introduced in Section 3. In Section 4 we discuss some strategies that are appropriate for this DSS optimizer. The results of our performance analysis assessing the benefits of these strategies are explained in Section 5. Finally, our conclusions are given in Section 6.

2. Application Scenario  In this section we describe some basic aspects of data warehousing, decision support systems and the OLAP application scenario we have chosen for our investiga- tions. We present some examples for typical information requests and the common architecture of systems that process such requests.

2.1. Data Warehousing  Data warehousing has gained more and more impor- tance for decision support in organizations and enter- prises [15] [26]. Most medium-sized and large organiza- tions integrate data that is relevant for decisions and that originates from different data sources into a data ware- house. Due to the huge amount of data, usually parallel, (object-) relational database systems are deployed. In addition, several tools are needed for the extraction and cleansing process as well as for the analysis of the data.

The analysis of data has two main aspects. On the one hand, OLAP tools are used to view the data along differ- ent dimensions [4]. Typical dimensions that are relevant for an enterprise are time, customers, suppliers and prod- ucts. The users should know which information they are about to retrieve from the data warehouse. In knowledge discovery, on the other hand, data mining tools are able to detect correlations and to find previously unknown pattern in data. It is possible, for example, to determine correlations between the consuming behavior of a certain group of customers and some characteristics of these cus- tomers like age or profession. Examples for OLAP tools are Microstrategy [ 161 and Businessobjects [ 11 whereas Darwin [29], Enterprise Miner [24] and Intelligent Miner [ 301 are representatives for data mining tools.

Typical data models for data warehouses are called star schema and snowflake schema. For our experiments, we have chosen the snowflake schema given in Figure 1 that shows some important aspects of a retailer. Our schema is based on the TPC-H Benchmark [31], which comprises decision support SQL queries. The original schema consists of eight tables describing a typical sce- nario of a retailer. The retailer receives orders (table ORDERS) that consist of single items (LINEITEM). The  orders are sent by customers (CUSTOMER), which re- side in a nation (NATION) and region (REGION). The items refer to parts (PART) delivered by suppliers (SUP- PLIER), which reside in a nation and region, too. Finally, the parts delivered by a supplier are given by the joint table PARTSUPP.

We used a modified schema for our experiments.

There are two main reasons for that: 0 The OLAP tool we used for our experiments needs a  special type of schema, a snowflake schema with par- tially redundant dimension tables. The necessary modifications are just formal, and easily achievable by syntactical equivalence transformations. There are no semantic changes.

The time dimensions are extended in two ways. First, the date field of the original schema is split into sepa- rate tables for days, weeks, months and years. Second, additional information is provided for each unit of time, e.g. the last day, week or month for a given date.

These extensions make days, weeks, months etc. ex- plicitly available for queries and enable for example the comparison of a given month with the respective month in the preceding years.

The modified schema has more fact and dimension  tables than the original schema. Figure 1 depicts the part of the modified schema, which is relevant for our exam- ple queries. The main fact table is shown in the middle of the picture. Some of the dimension tables and connec- tions to further tables are given around this fact table.

DRMR CUSTOMER  L- I \ LINEITEM OROERS~ I - I PART  Figure I .  Snowflake Schema based on TPC-H  2.2. OLAP Scenario  We have chosen a typical OLAP scenario of a retail company for our experiments. This includes some infor- mation requests a user could define and process by means of an OLAP tool. The selection of requests is based on the following requirements:  The requests have to be typical questions a retailer would ask based on the information available in the data warehouse.

Information request A: Which are the top products whose number of sold pieces in the months chosen by the user compared to the respective month ago has in- creased mostly?

Information request B: What is the distribution of the number of sold products over the different countries for products and years chosen by the user?

Information request C: Which are the top customers who bought products in the last three years of a mini- mum total amount chosen by the user and who show the lowest standard deviation of the totals in these years?

Figure 2. Selected Information Requests  It must be feasible to model the requests with currently available OLAP tools and it must be feasible to answer these questions based on our schema.

The complexity of selected requests should be similar to the complexity of business questions in the TPC-H benchmark.

Three typical information requests that meet these re-  SELECT a2.orderyearkey. a2,ordermonthkey. al.partkey. SUM(al.quantity) FROM lineitem-orders al. orderday a2 WHERE a2.orderdate = al.orderdate AND a2.ordermonthkey I N  (199401.199402)  \GROUP BY a2.orderyearkey. a2.ordemonthkey. al.partkey; F  INSERT INTO A2 lordermonthkey. partkey. sumquantity) \ SELECT a2.ordermonthkey. al.partkey. SUM(al.quantity) FROM lineitem-orders al. orderday a2 WHERE a2.lastmonthdate = al.orderdate AND a2.ordennonthkey I N  l199401, 199402)  quirements &e shown in Figure 2. They are important for the management of a retailer as the questions belong to the categories merchandise management or customer relationship management [ 141 [23]. The schema we pre- sented above includes the relevant information that is necessary to answer these requests.

orderyear, partkey. partname, sumquantity, lmswoquantity. incrquantity. incrquantity21  SELECT a3 .ordermonthkey. a3.ordermonthname. a4.arderyearkey.

a4.orderyear. a5.partkey. a5.partname. al.sumquantity.

a2.sumquantity. al.sumquantity-a2.smquantity.

(a1.sumquantity - a2,rumquantity) I a2.sumquantity  FROM A1,Aa. ordermonth a3. orderyear al. part a5 WHERE Al.ordermonthkey = A2.ordermonthkey AND Al.partkey = A2.partkey AND Al.ordermonthkey = a3.ordemonthkey  2.3. Architectural Issues  Numerous decision support applications are based on the system architecture given in Figure 3. The end users specify the information they need by means of a graphi- cal user interface. For example, they have to define the relevant data and the necessary calculations on these facts as well as criteria for filtering and the way results should be presented. These requirements are used by the applica- tion to generate a sequence of SQL queries. Meta data is used by the query generator in order to produce the ap- propriate query sequences. In an OLAP application the meta data include information about available fact tables and the hierarchical dependencies of attributes in one dimension. As soon as the query generator produced a sequence of SQL queries, these queries are sent to the data warehouse database system one after the other. The application reads and processes partial results from the DWDBS and finally presents the result to the end user.

Many typical decision support applications generate sequences of SQL queries. For information request A in our scenario such a sequence is given in Figure 4. This query sequence (QS) was produced by an OLAP tool.

The Figure only shows the four insert statements. The create table statements and other details that are also part of the generated sequence are omitted here for the sake of readability. The first statement (Ql) produces the tempo- rary table A I that includes the sum of the fact quantity for all parts in January and February 1994. The second  statement (Q2) only differs in that it sums the same quan- tity for the preceding months of January and February 1994. The purpose of the third query (Q3) is mainly to calculate the absolute and relative increase of the quantity for each part based on the values of Q1 and 42. Finally, Q4 selects all parts from Q3 according to the given rank- ing criterion and provides the result data in table A4.

Graphical User Interface  Resukf I Information Request  Partial Results  Figure 3. Standard System Architecture  This sample query sequence consists of four state- ments. In general, the conversion of OLAP information requests into sequences of SQL statements results in se- quences of different complexity, which ranges from just one to eight queries for the information requests we have chosen here. According to our experience, it is very likely that relevant business questions result in query sequences with several statements, sometimes even more than 20.

Hence, the three information requests given in Figure 2 represent important types of OLAP queries and are rele- vant in order to judge optimization strategies.

Figure 4. Query Sequence for Request A     3. Optimized System Architecture  In the standard architecture presented in Figure 3 the performance of a decision support application mainly depends on the capabilities of the query generator and on the query optimization and execution capabilities of the DWDBS. Therefore, if one envisages performance prob- lems there are two different ways to go: On the one hand, one could improve the query generator and on the other, one could improve the query optimizer of the DWDBS.

Improving the query generator means to enhance the set of rules according to which the queries are generated.

This task depends on the underlying DWDBS. The opti- mum query sequence for IBM DB2 could look quite dif- ferent compared to the optimum sequence for Oracle or SQL Server. Since almost all decision support applica- tions aim to support several database systems, the optimi- zation strategies of the query generator have to be devel- oped for each dedicated database system. Furthermore, this has to be done for each decision support application separately. Hence, there could be different optimization strategies for every combination of a decision support application and the underlying DWDBS.

Improving the query optimizer of the DWDBS is also a very difficult task. New query optimization strategies for decision support that are implemented in a database system should on the one hand be based on the-analysis of a couple of decision support applications. On the other hand, the developers have to show that the irew optimiza- tions do not negatively influence the performance of other types of applications or even deteriorate the per- formance of the optimizer itself.

In summary, both starting-points for performance en- hancements of decision support applications in a standard architecture turn out to be very difficult. The complexity results from the heterogeneity of applications and data- base systems as well as from the complexity of query optimizers that are used in commercial database systems.

We suggest an optimized system architecture for de- cision support which is shown in Figure 5. p e  main idea of this architecture is a DSS optimizer as an additional system component between the query generator and the DWDBS. This optimizer accepts query sequences from different applications. It transforms these sequences into optimized versions of query sequences, which are then sent to the DWDBS. The DSS optimizer is neither part of a special application nor of the database-system. The main advantages of the extended architecture are as fol- lows: 0 In a typical data warehouse environment, several deci-  sion support applications access data in the warehouse.

The DSS optimizer offers performance enhancements for all of these applications.

The DSS optimizer is not part of a decision support application. Therefore, its development and enhance-  ment is not part of the application development. It is done only once and not especially for each application.

The DSS optimizer offers performance enhancements for existing decision support applications without the need to change the query generation process of these applications. 'They benefit from the optimizer simply by directing their query streams to it instead of sending them directly to the DWDBS.

Using the DSS optimizer reduces the need for each application to consider special capabilities of the un- derlying database system. The query generators of the applications can mostly be kept independent of the da- tabase system, thus they are less complex.

The DSS optimizer may include optimization stuate- gies that are offered by some database systems as well as strategies that are not supported by state-of-the-art database systems. Multi-Query-Optimization is an ex- ample for an area where current systems offer only Iit- tle support.

In summary, the optimized system architecture offers  support for many decision support applications and many database systems without additional development effort for each of the applications or database systems.

Graphical User Interface  R e s u p  I Information Request  Figure 5. Optimized System Architecture  4. Strategies for the DSS Optimizer  In this section, we describe a set of strategies that of- fer performance enhancements for sequences generated by decision support tools. For each of them -we argue whether it is an appropriate strategy for the DSS opti- mizer or not. The goal is to incorporate all optimizations into the DSS optimizer that need no information about the application aid little information about the underlying database system. For all strategies we identified as a p propriate, we discuss the main aspects of their implemen- tation. More details are given in [25].

Not all optimization strategies mentioned here are new. The contribution of this paper is not to find new algorithms for a database optimizer, but to combine exist-     ing technology in an additional system component that offers performance advantages for a huge range of appli- cations and that is independent of the concrete applica- tion and the DWDBS. Currently, none of the existing systems follows this approach.

