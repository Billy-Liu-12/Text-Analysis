Towards Early Detection of Novel Attack Patterns

Abstract? Darknet monitoring provides a cost-effective way to monitor the global trend of cyber-threats in the Internet. To make full use of the darknet traffic at hand, in this paper, we present a study on early detection of emerging novel attacks observed in the darknet. First, exploration of the regularities in the communications from attacking hosts are done by feeding all observed packets in the darknet to a frequent itemset mining engine, where the most frequently occurred attack patterns are automatically grouped together. Second, a time series which characterizes the activity level of each attack pattern is created over the observation period. Then, to extract the most prominent attack patterns, a clustering algorithm is engaged to cluster the attack patterns into groups that carry the similar activities in a long run and dimension reduction is employed to provide visual hints about their relationship.

Finally, attacks featured by a recent rapid increase are picked up to be further inspected by security experts for incident handling purpose. The experiments show that the proposed scheme is effective and efficient in early detection of new attack patterns from conventional approaches.



I. INTRODUCTION  The conventional practice of cybersecurity has been fo-  cused on mitigating cyber-threats at the network edge: IPS  (Intrusion Prevention Systems) /IDS (Intrusion Detection  Systems), firewalls, and web security appliances are installed  at the enterprises? access points to the Internet, making binary  ?yes, no? decisions while scanning network traffic that passes  through. The implicit assumption behind this perimeter pro-  tection scheme is that the interior of our (enterprise) network  is a trusted zone, while everything outside is untrusted.

Nevertheless, the past few years of cybersecurity has seen  emerging new types of cyberattacks which can easily get  through the edge without alarming the network security  devices. Among them are the Drive-By Download (DBD) at-  tacks which happen when a user is visiting a website, viewing  an e-mail message, or cheated to click on a deceptive pop-  up window [1], [2], and Advanced Persistent Threat (APT)  attacks which employs sophisticated evasion techniques to  intrude and stole information from target organizations in  sectors with high-value information [3], [4]. Getting across  the edge gives the adversaries free reign to move laterally  within organizations, locate valuable intellectual properties,  and exfiltrate them out using undetectable protocols. This  poses significant threats to the confidentiality, integrity, and  availability of our data stored and communicated in the  Tao Ban, Masashi Eto, Daisuke Inoue, and Koji Nakao are with the National Institute of Information and Communications Technology, Tokyo, 184-8795 Japan. Shaoning Pang is with Unitec Institute of Tech- nology, Auckland, 92025 NZ. Runhe Huang is with Hosei University, Tokyo, 184-8584, Japan. (email: {bantao, eto, dai, ko-nakao}@nict.go.jp, ppang@unitec.ac.nz, rhuang@hosei.ac.jp).

Internet. To address the concerns raised by these threats,  there is a pressing need for a proactive warning system  which detects the emergence of new threats at its early  stage and provides detailed forensic information to facilitate  appropriate countermeasures.

The best practice to foster such an early warning scheme  is by global network monitoring [5]. While the computa-  tion, communication, and storage costs for monitoring and  analyzing a densely populated global-scale network in real-  time may render it impractical, the monitoring of unused  address space known as a darknet, usually provides a good  trade-off between the monitoring costs and global knowledge  acquisition [6]. Darknets, also known as network telescopes,  blackhole monitors, sinkholes, or background radiation mon-  itors, is a portion of routed, allocated IP space that contains  no advertised services [6], [7], [8]. Because of the absence  of legitimate hosts in the darknet, any traffic observed on  a darknet is by its presence aberrant: it is either caused by  malicious intent or a mis-configuration. Assorted works have  deployed darknets in existing networks to help identify the  types and sources of malicious traffic present on the larger  network of which they form a part, with darknets used to host  flow collectors, backscatter detectors, packet sniffers and so  on [9], [10]. Considerable improvements in detection rate and  cut-down in false positives are reported in related works.

Driven by the necessity to gain further understanding  of the nature of malware-infected hosts, to devise their  behavioral regularities, and to predict their future activities,  in [6], Ban et al. describe a study on behavior analysis of the  attacking hosts monitored on a darknet using association rule  learning (ARL) [11], [12]. The discovered association rules  are used to characterize the regularities among the scanning  behaviors of attacking hosts. The following findings have  motivated the study presented in this paper.

1) When infected by a certain type of malware program,  network devices tend to probe the Internet in a pre-  defined way, resulting in frequent and highly stable  association rules discovered.

2) Destination ports, which specify the network services  targeted by the attacking hosts, can be used to identify  the activity of a specific malware program.

In this paper, based on the above discoveries, we extend  the work of Ban et al. to fulfill a more specific purpose: to  identify the emerging types of attacks at their early stage  so as to enable proactive countermeasure of these cyber-  threats. To do so, we follow the steps below to mine the  darknet traffic and retrieve the information most relevant to  2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress  DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.157     the attacks of interest.

? Frequent attack-pattern mining stage  In this stage, we try to group the probing activities  from millions of attacking hosts into malware-specific  factions by exploring the regularities in the communi-  cations.

? Attack activity-level profiling stage  The attack patterns obtained from the first stage have  varying levels of activity during the observation period.

To track the fluctuations therein, the activity levels of  each attack pattern are measured and recorded as a time  series, in which each data point records the indicator  with a fixed time interval.

? Attack pattern clustering and visualization stage  To extract the most prominent attack patterns, a cluster-  ing algorithm is employed to cluster the attack patterns  into groups that show the similar activities in a long run.

Nonlinear dimension reduction is used in this stage to  visualize the clustering results and provide visual hints  and reduce redundant information for security operators.

The proposed approach of a combination of human ex-  pertise and an exploratory analysis of the behavioral ir-  regularities of the attacking hosts observed in the darknet  can complement existing malware countermeasures in the  following aspects. First, the detection of new attack patterns  can be achieved by finding the abrupt changes on the time  series of attack activity-levels. The emergence of these new  attacks could be the symptom of pandemic incidents and  early detection and take-down of related hosts can help  prevent heavy loss. Second, discovered knowledge can be  used to improve the performance of an adaptive monitoring  system so that more pertinent malware information can be  collected using limited system and network resources. For  example, darknet sensors can be (partially) updated to an in-  teractive honey-pot system to collect more information about  the attacks. The efficacy of such a hybrid monitoring system  will be greatly improved if the interesting type of attacks can  be defined beforehand. Last but not least, prevalent attack  patterns and others attacks with exceptional features may be  undiscovered following the same scheme, whose discovery  can lead to further insights into the mechanism and current  status of the attacks so as to enable better countermeasures  for them.

This paper is organized as follows. Section II introduces  related work on the data mining algorithms involved in the  study: ARL, clustering, and dimension reduction. Section III  describes the background of darknet. Section IV reports the  setting and results of the experiments. Finally, Section V  presents our conclusions.



II. RELATED WORKS  This section briefs ARL, data clustering, and dimension  reduction. Involved in the first stage, ARL aims at finding  regularities in the attacking behavior of malicious hosts in the  Internet. Data clustering is applied in the third stage to group  the activity-level time series of all attacking hosts to form a  condensed representation of the data. Dimension reduction  is used to visualize the result of data clustering and provide  visual hints about the complicated relationship between the  attacks.

A. Association Rule Learning  The problem of association rule learning (ARL), in which  frequent pattern mining (FPM) is usually the first key step,  was originally proposed in the context of market basket  data in order to find frequent groups of items that are  purchased together [11], [12]. FPM has numerous recent  applications to major data mining problems such as customer  transaction analysis, web log mining, software bug analysis,  and chemical and biological applications. Recent surveys on  algorithms and applications of ARL and FPM can be found  in [13], [14].

Following the original definition in [11], the problem of  ARL is defined as follows.

Let D = {T1, T2, . . . , TN} be a set of N transactions called the database. Let I = {i1, i2, . . . , iM} be the universal set of M items present in the database. Each transaction in D has a unique transaction ID and contains a subset of the items in I . The support supp(X) of a set of items (for short itemset) X is defined as the number/proportion of transactions in the database.

Frequent pattern mining is to determine all patterns P ? I that occur in at least a fraction S of the transactions. The fraction S is referred to as the minimum support, expressed either as an absolute number, or as a fraction of N .

An association rule is defined as an implication of the  form  X ? Y, for X,Y ? I,X ?Y = ?. (1)  The confidence of a rule is presented by the conditional  probability, P (Y |X), i.e.,  conf(X ? Y ) = P (Y |X) = supp(X ? Y )/supp(X). (2)  To select interesting rules from the set of all possible rules,  rules that meet both a minimum support threshold, S, and a minimum confidence threshold, C, are called strong.

In general, ARL can be done in two steps: frequent pattern  mining and association rule generation.

Frequent pattern mining invokes searching in a power set  of all possible combinations of items, for itemsets that satisfy  the minimum support condition. The key to an efficient  search algorithm is the so-called Apriori property [11]: ?All  nonempty subsets of a frequent itemset must also be frequent.

Thus for an infrequent itemset, all its supersets must also  be infrequent.? Frequent Pattern growth (FP-growth) [?] is  among the fastest and most popular algorithms for FPM.

Based on a prefix tree representation of the given database,  FP-growth can save the extensive amounts of memory for  storing the transactions and reduce the search space. Refer  to [15] for a fast implementation of FP-growth which have  been used in our experiments.

Association rule generation can be done by manipulating  the frequent itemsets in the previous step as follows. a) For     each frequent itemset l, generate all nonempty subsets of l.

b) For each nonempty subset s of l, output the rule ?s? (l? s)? if its confidence is higher than the confidence threshold C. Since the rules are generated from frequent itemsets, all association rules created in this way automatically satisfy the  minimum support condition.

B. Clustering  Due to the combinational nature of FPM, discovered fre-  quent patterns tend to form high correlated groups. For exam-  ple, in our experiments, port set {443, 465, 993, 995, 8443} is one of the frequent attack patterns when the regularities  in targeted destination ports are exploited. It is easy to  confirm that all its subsets such as {443}, {443, 465}, {443, 465, 993} are also among the frequent attack patterns under the same condition. As the attack targeting port set  {443, 465, 993} may constitute a considerable part of that targeting {443, 465}, the activity-level time series created in the second stage in our scheme for the frequent attack-  patterns tend to form condensed clusters for these highly  correlated port combinations. To model these clustered data  and discover the essential information, we sort to data  clustering methods to give a condensed view of the data.

Cluster analysis or clustering is a highly interdisciplinary  field whose goal is to divide a set of objects into homoge-  neous groups such that objects in the same group (called a  cluster) are more similar (in some sense or another) to each  other than to those in other groups (clusters) [16]. It is a main  task of exploratory data mining, and a common technique  for statistical data analysis, studied and used in many fields.

Refer to [17] for a thorough survey of clustering algorithms  and their applications.

For the sake of its simplicity and ease of implementation,  hierarchical clustering is one of the most widely studied  clustering algorithms. It solves clustering by developing  a binary tree-based data structure called the dendrogram.

Once the dendrogram is constructed from the data, one  can automatically choose the right number of clusters by  splitting the tree at certain levels to obtain different clustering  solutions for the same dataset without rerunning the cluster-  ing algorithm again. This particular feature of hierarchical  clustering renders the human interaction effective in treating  with complicated activity-level time series created in the  previous stage.

The basis steps involved in an agglomerative hierarchi-  cal clustering algorithm generally known as linkage are as  follows. First, using a particular proximity measure, a dis-  similarity matrix is constructed and all the data points (time  series of activity-level time series) are visually represented  at the bottom of the dendrogram. The closest sets of clusters  are merged at each step and then the dissimilarity matrix  is updated correspondingly. This process of agglomerative  merging is carried on until no clusters are closer than a  predefined cutoff parameter.

For concreteness, we use the ubiquitous Euclidean distance  to measure the proximity between two time series, i.e.,  D(x,y) =  ???? T? i=1  (xi ? yi) 2, (3)  where T is the length of the time series. Following the convention in the field, x and y are normalized to have  mean zero and a standard deviation of one before calling  the distance function,  To update the distance between clusters in the dissimilarity  matrix, we choose the ?complete distance? rather than the  ?single distance?. The complete distance is determined by  the proximity measure of the most dissimilar members in two  clusters. Therefore, the maximal pair-wise distance between  all time series in the same cluster is guaranteed to be smaller  than the chosen cutoff. Therefore, the so-called ?complete  linkage? algorithm can yield compact shaped clusters while  being robust to noise and outliers.

C. Dimension Reduction  The time series which record the activity-level of different  attack patterns generally have very a high dimension based  on the length of the observation. These time series are inher-  ently correlated because of the complicated composition of  attacks targeting the same ports. For such complicated data,  nonlinear dimension reduction is one commonly resorted  technique to represent the relevant location of the time series  in a visible layout for easy understanding. In this paper,  we adopt t-SNE, a popular nonlinear dimension reduction algorithm, to perform the mapping from high dimensional  time series to a layout in 2 dimension. t-SNE is known to work better than existing techniques at creating a single map  that reveals structure at many different scales, and it tends  to produce good visualizations by reducing the tendency to  crowd points together in the center of the embedded layout.

Below is a brief review of t-SNE following [18].

Given M data points in a D dimensional space, and  the pairwise distances between the data points defined by  a distance function, t-SNE finds a mapping from the D dimensional input space to a d-dimensional space as in the following. It defines joint probabilities pij that measure the pairwise similarity between objects xi and xj by symmetriz- ing two conditional probabilities using the Gaussian kernel:  pj|i = exp(?d(xi,xj)  2/2?2i )? k ?=i exp(?d(xi,xk)  2/2?2i ) , pi|i = 0, (4)  pij = pj|i + pi|j  2M . (5)  Here, the bandwidth of the kernels, ?i, whose optimal value is usually determined using a simple binary search or a robust  root-finding method, is required to make the perplexity of the  conditional distribution Pi equals a predefined perplexity u.

Then, in the d-dimensional embedding, the similarities  qij between two points yi and yj are measured using a normalized Student-t kernel with a single degree of freedom:  qij = (1+ ? yi ? yj ?  2)?1? k ?=l(1+ ? yk ? yl ?  2)?1 , qii = 0. (6)     The locations of the embedding points yi are determined  by minimizing the Kullback-Leibler divergence between the  joint distributions P and Q:  C(E) = KL(P ? Q) = ? i?=j  pij log pij . (7)  The above non-convex optimization problem can be normally  solved using a steepest descent algorithm.



III. BACKGROUND ON DARKNET TRAFFIC ANALYSIS  Network traffic captured on a darknet contain valuable  forensic information of malware programs that are probing  the Internet. The results reported in this paper are based on a  long term observation over a group of darknet sensors hosted  in the NICTER project [19], [20].

A. Characteristics of the Darknet Traffic  In the NICTER, the sensors are installed in a variety of  network environments. Darknet monitoring relies on the fact  that most kinds of malware consist in a scanning phase  in search for the next potential victims. Thus the more IP  addresses encompassed by the darknet, the more essential  information the darknet could gather. Of course, due to the  limited scale of a darknet compared with the IPV4 space and  its passive nature, only partial information of the attacks is  observable on the darknet [6].

The attacks towards the darknet are captured in the form  of network packets. In general, a packet is consisted of  two parts: control information and user data (also known  as payload). Due to the passive nature of the darknet, except  for some special cases, e.g., a mis-configured server which  connects to a presumed printer in the darknet space, there  will be very few persisting connections toward a darknet,  especially toward a single IP address. Most of the observed  hosts send only a couple of connection initializing packets  to the darknet, i.e., TCP packets with SYN flag set on. This  renders the darknet connections more fragmented, lacking  application level information. Therefore our analysis focus  on the control information in the fields stored in packet  headers, including time stamp of the communication, source  and destination IP addresses, source and destination ports,  used IP protocols, etc.

B. Investigated regularities in the attacks  The regularities in the scanning packets can be explored  at multiple levels: At packet level, scans towards a certain  vulnerability usually confined to a specific destination port.

At target-host level, attacks can be featured by the com-  bination and order of destination ports on a targeted host.

At network-level, precoded rules to select the next targets  provide a clue for the type of the malware. At meta-level,  the strength and frequency of the probing packets can be the  indicator of certain attacks. All of the above information can  be helpful to determine the type of the attacks.

In our experiments, we select to exploit the regularities in  the targeted ports of the attacks. In computer networking, a  port is a software construct that serves as a communication  endpoint in a network device?s host operating system. A  port uniquely identifies different applications or processes  running on the device and thereby is used as a single  physical connection shared in packet-switched networks. The  port number, identified by a 16-bit number, together with a  device?s IP address, completes the destination address for  a communication session. By convention, applications im-  plementing common services often use specifically reserved,  well-known ports, e.g., the first 1024 ports, for receiving  service requests from client hosts. The open ports on a  device are usually probed by malware to determine available  services before exploitation of known vulnerability on the  service.

As the destination ports of the scans carries the most  essential information about the targeted network services,  attacks can be grouped by the destination ports of their scan  packets. Despite that scans towards a single port can be easily  grouped, enumeration of the minor and new combination of  destination ports could only be done efficiently by advanced  ARL algorithms such as FP-growth. In [6] a large number  of strong association rules with regards to the destination  ports are discovered and confirmed, providing valuable clues  for malware diagnosis. Because the port combinations in the  strong association rules have to satisfy the minimum confi-  dence condition, only a small part of the port combinations  are covered in the results. To provide an overall view of  the attacks targeting different ports, we choose to perform  analysis on the frequent patterns, i.e., port combinations in  this paper, which is the output of the frequent pattern mining  step of FP-growth. This results in increased number of time  series created in the second stage, nevertheless we can rely  on the clustering algorithm in the next stage to create a  condensed view of the analysis results.



IV. EXPERIMENTS  The experiments described in this section are based on the  traffic collected from a class B darknet which include 65536  unused IP addresses during the full year of 2015. We use  the TCP SYN packets, i.e., TCP packets with the SYN flag  set on to perform the analysis. Figure 1 show the number  of packets and number of unique host observed everyday  in 2015. Note that due to some technical problems, the  observation is terminated for a few hours in late January and  for a few days in early May, resulting in missing values in the  time series. Because the observation time is chosen to be a  full year to produce a long-term view of the attack activities,  the influence of these missing values is small enough to be  ignored.

A. Frequent patterns of destination ports  To apply the FP-growth algorithm, the set of unique  destination ports probed by an attacking host during a fixed  interval is taken as a transaction in the database. The time  interval is select to be 1-hour on account of the following  factors. First, a comparatively short interval will generally  enable fine-grained analysis and fast response. Second, an  interval as long as 1 hour is proved to be long enough to     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Jan  N um  be r o  f P ac  ke ts  ?107      N um  be r o  f U ni  qu e  At ta  ck in  g H  os ts  ?105      Fig. 1. Formulation of darknet sensors  reduce the chance to slice one attack into multiple incoherent  attacks. The influence of dynamic IP address assignment  commonly used in modern networks, i.e., IP addresses as-  signed via the DHCP protocol, could be safely ignored for  such a short time interval.

TABLE I  FREQUENT ITEMSETS RELATED TO PORT 23  (JANUARY 1ST, 2015 0:00AM ? 0:59AM)  ID Port 1 Port 2 Port 3 Port 4 Occur.

1 23 21374 2 23 10073 296 3 23 80 17 4 23 58455 16 5 21 23 10 6 23 443 10 7 21 23 80 10 8 21 23 443 10 9 21 23 80 443 10 10 23 80 443 10 11 23 32764 9 12 23 80 32764 7 13 23 80 58455 7 14 23 80 32764 58455 7 15 23 32764 58455 7 16 23 139 2 17 23 3389 2 18 23 445 1 19 23 8080 1 20 22 23 1  The well-known network services on involved ports are as follows. 21: file transfer; 22: SSH remote login proto- col; 23: telnet; 80: hypertext transfer protocol (HTTP); 139: NetBIOS Session Service; 443: hypertext transfer protocol over TLS/SSL (HTTPS). 445: Windows server message block; 554: real time streaming protocol; 1433: Microsoft SQL server; 3389: Microsoft terminal server; 8080: HTTP alternate.

To extract as many attack patterns as possible, we have  to set a small value, ideally 1, to the minimum support S.

However, one of the factors that make this impractical is the  existence of a couple of port scanning hosts. Port scanners  which is referred to applications designed to probe networked  devices for open ports, are often used by administrators to  verify security policies of their networks and by attackers to  identify services running on a host and exploit vulnerabilities.

For a port scanner probing up to k different ports, k! attack patterns will be generated. Common network scanners seen  in the darknet tend to scan more than 20 different ports, which renders the further analysis difficult. As a port scanner  can be simply identified by the extraordinary number of  destination ports it probes, we choose to remove the traffic  from hosts who is probing more than 6 ports within an 1-hour interval and preserve it for other research purpose.

When the port scanners are removed, FP-growth returns a  few thousands of frequent attack patterns for S = 1, which is significantly smaller than all the possible combinations of  destination ports, which indicates that 6 is an appropriate threshold to remove the negative effect of port scans.

TABLE II  ASSOCIATION RULES RELATED TO PORT 23  ID Rule Support Confidence  1 10073 ? 23 318 93.08% 2 443, 23 ? 80 10 100% 3 58455 ? 23 16 100% 4 58455, 80 ? 23 7 100% 5 21, 80 ? 23 10 100% 6 21, 23 ? 80 10 100% 7 21, 443 ? 23 10 100% 8 21, 23 ? 443 10 100% 9 443, 23 ? 21 10 100% 10 21, 443, 80 ? 23 10 100% 11 21, 443, 23 ? 80 10 100% 12 21, 80, 23 ? 443 10 100% 13 443, 80, 23 ? 21 10 100% 14 32764 ? 23 7 100% 15 32764, 80 ? 23 7 100% 16 32764, 23 ? 80 7 100% 17 32764, 58455 ? 23 7 100% 18 32764, 23 ? 58455 7 100% 19 32764, 58455, 80 ? 23 7 100% 20 32764, 58455, 23 ? 80 7 100% 21 32764, 80, 23 ? 58455 7 100% 22 58455, 80, 23 ? 32764 7 100% 23 23 ? 10073 296 1.38% 24 23 ? 80 17 0.1% 25 23, 32764 ? 80 7 77.78%  The last three rules which do not satisfy the minimum confidence C = 80% are not considered as strong association rules.

Table I shows the frequent itemsets discovered from the  traffic collected in the darknet sensor in the first hour of 2015.

20 frequent itemsets which are related to port 23 are selected  from a pool of 1108 frequent itemsets, with the number of  their occurrences shown in the last column. As shown in the  table, 21,374 hosts probed port 23 during the 1-hour frame-  work on January 1st, 2015. Spotted ports that are probed  together with port 23 include ports 21, 22, 80, 139, 445, etc.

Port 23 hosts the telnet service on a PC. It is a popularly  probed partially because of the following facts. Along with  the rise of Internet of Things (IoT), many Linux embedded  devices, e.g., routers, web cameras, network storage, tend  to stay 24-hour online, with port 23 open for facilitating  remote control. These IoT devices are frequently targeted  by attackers because they often lack operating system and  security updates so that when compromised they can serve     as step stones for various attacks.

As can be seen in Table I, ports 21, 23, 80, and 443 show  a strong correlation: they tend to be probed at the same time.

This is confirmed by the association rules shown in Table II,  which are generated from the frequent patterns in Table I.

Rules 5 to 13 illustrate the correlation between ports 21, 23,  80, and 443: If two of the ports are probed, the chance for  the other ports to be probed is 100%. Because of the high  correlation of these ports, they can be treated as the signature  of the probing behavior.

Take the rules 15 and 25 in Table II as another example.

The association rule 15 (23764, 80 ? 23) has a strong confidence of 100%. Therefore, probes to ports 80 and 23764  can be considered as the causal factor of the probes to  port 23, e.g., if packets directed to ports 80 and 23764 are  observed from a host, then port 23 will be also probed with  a large chance by the same host. On the other hand, despite  of the comparable high number of co-occurrence between  ports 23, 80, and 23764 (line 15 in Table I), the association  rule 23 (23, 23764? 80) only has a confidence of 77.78%, failing to meet the minimum confidence requirement 80%.

The association rules shown in Table II help to confirm  the high correlation between the ports that are often probed  together. Nevertheless, it is not recommended to take these  rules as the subject for next-step study on the their activity  levels because of two reasons. First, strong rules are not  always strong during the whole observation period. Due to  network issues such as packet loss and the variation of attacks  over time, the strong rules may change from time to time.

If a rule is strong for a certain period but fails to meet  the minimum confidence condition for other periods, the  recorded time series will subject to uncontrollable fluctua-  tions. Second, it is difficult to choose an optimal minimum  confidence threshold, C. Because of the combinational nature of the rule creation procedure, when the minimum confidence  threshold is set to a low value, there will be too many similar  strong association rules. On the other hand, if the threshold  is set to a large value, information of many important attacks  will be lost because they are not significant enough.

Therefore, we propose to take the frequent patterns as the  subject of the analysis on activity levels. That is, attacks are  organized in the name of the frequent patterns discovered  in the first stage. The strong association rules serves as a  good indicator of the purity of the pattern. For example,  the frequent pattern {23} consists activity components of many attack patterns, whilst {21, 23, 80, 443} represents the activity of a type of attack because of the high confidence  in the related rules.

B. Activity level of hosts  An attack pattern obtained from the first stage may have  varying activity level during an observation period as long as  one year. To track the fluctuations therein, the activity level  of an attack pattern is measured and recorded as a time series,  in which each data point denote the indicator in a fixed time  interval. Common indicators to measure the activity level  include the number of packets, number of unique attacking  1000 2000 3000 4000 5000 6000 7000 8000  [2   ]      1000 2000 3000 4000 5000 6000 7000 8000  [2    3]       1000 2000 3000 4000 5000 6000 7000 8000  [2  ]      1000 2000 3000 4000 5000 6000 7000 8000      1000 2000 3000 4000 5000 6000 7000 8000  [2   3]     1000 2000 3000 4000 5000 6000 7000 8000  [2   2]       1000 2000 3000 4000 5000 6000 7000 8000  [2   4]      Fig. 2. Activity-level time series collected in 2015.

hosts, number of probed destination IPs, and combination of  above measurements. For simplicity, we use the number of  unique attacking hosts observed in each time interval which  scales to the number of compromised hosts in the Internet  as the indicator of activity level.

To illustrate the long term characteristics of the attack  hosts, Fig. 2 shows a few examples of the activity-level  time series that are created for different attack patterns. In  the graphs, each data point denotes the number of unique  attacking hosts observed in an 1-hour period, and the tags of  the time series are shown on the y-axis. It can be seen that the time series for {23, 80, 443} and {21, 23, 80, 443} look almost the same in a long run, because of the high correlation  confirmed by the high confidence of the related association  rules in Table II. The time series for port set {23, 80} deviates slightly from the first two. This can be explained     that association rule such as (21, 443, 80 ? 23) does not hold with a 100% confidence for other time intervals. It  can be more clear that because port 23 is involved in  many type of attacks besides the attacks probing ports set  {21, 23, 80, 443}, the time series for {23} is totally different from the first three.

The 5th time series in Fig. 2 shows the records of an  attack pattern which has reduced activities starting from mid-  2015. In fact, port set {23, 10073} is the signature of the Linux Moose worm, which infects Linux-based routers and  other Linux-based devices and turns them into social network  bots. Few weeks after the publication of the whitepaper  [21] in May 2015, the Moose C&C servers went dark and  the number of infected hosts significantly decreased. It is  reported that an update on this atypical embedded Linux  botnet is one online after a few weeks, using a different port  set, i.e. {23, 20012}, to perform the infection [22]. This can be confirmed on the 6th time series in the figure: more than  200 unique attacking hosts are observed at peak time.

The last time series in the figure gives an example of tem-  porally coordinated attack activities observed in the darknet,  which is of particular interest for security experts. There are  many abrupt changes on the graph indicating that the burst of  attacks are only observable during a very short time period.

This agrees with the facts reported in other studies of botnets,  groups of Internet-connected computers communicating with  other in an effort to complete repetitive tasks and objectives.

As infected PCs in a botnet is typically governed by a bot  master, they tend to carry out attacks in a coordinated fashion  after they got the attack command via the C&C channels.

C. Data clustering and visualization  All the above cases indicate that the shape of the time  series could provide valuable information about the nature  of attacks associated with the attack patterns. Nevertheless,  the complicated shape of the time series also indicate that  a universal algorithm which could characterize all possible  attacks in an optimal way may not exist. Rather than relying  on an analytical tools playing as the oracle, we advocate a  scheme to combine human expertise together with advanced  machine learning tools to approach such a challenging task.

While a security expert may be able to identify attack  patterns of particular interest based on extensive experience,  he/she may still rely on machine learning to provide valuable  hints and filter out irrelevant and redundant information. In  the following we describe the application of the linkage  algorithm and the t-SNE algorithm to fulfill this goal.

As shown in Fig. 2, highly correlated attack patterns will  generate very consistent activity-level time series. It is ideal  to pick out the representative ones and discard those without  much new information. The one year darknet traffic yield  more than 150,000 distinct attack patterns. Before applying  the linkage algorithm to form condensed clusters, we use  a simple filtering rule to remove the less significant attack  patterns: patterns that have been less observed than 1000 out  of the 365?24 hours are removed for simplicity. This results in 852 attack patterns as input to the linkage algorithm.

Distance between Clusters  In de  x of  C lu  st er  s  31 3 36 1 73 7 55 8 43 6 32 9 71 5  Fig. 3. Dendrogram create by a completed linkage algorithm. 30 clusters are generated when the cutoff is set to 64.8.

The dendrogram created by a complete linkage algorithm  is shown in Fig. 3. When the number of clusters is selected  as 30, the distance threshold to partition the clusters is 64.8.

To get an insight to the data distribution in the high  dimensional input space, we apply the t-SNE algorithm to create a 2-dimensional embedding of the data, which is  shown in Fig. 4. In the figure, each colored disk denotes the  location of the attack pattern in the embedding space. Data  points in different clusters are shown with different colors as  illustrated in the color bar at the right side of the figure. The  size of a disk indicates the average number of hosts with the  same attack pattern. To confirm that the highly correlated  attack patterns fall close to each other and belong to the  same cluster, we connect them using line. More specifically,  a point is connected to its parent when they are in the same  cluster. A port set A is called the parent of set B if A ? B and A contains exact one less element than B. For example, set {21, 23, 443} is the parent of set {21, 23, 80, 443}, whilst set {21, 23} is not. The relationship is so defined to create connections between related attack patterns but not to result  in too many connections in the plot.

In Fig. 4, it can be confirmed that the attack patterns  generated from the same attack are assigned to the same  cluster. For attack patterns that are related in two aspects,  high similarity in terms of the shape of the time series ?  indicated by the same color of the data points, and the  correlation in terms of the shared ports ? illustrated by a  connecting line segments, they can be considered as the same  attack.

A closer look into the cluster structures in the figure  reveals attack patterns in the same cluster but are not  connected by any lines. This indicates that these attacks  patterns belongs to different attacks but happen to have a  similar shape of activity-level. These attack patterns shall  be investigated individually. Attack patterns which are in  the same cluster of port set {23, 20012} will be the most interesting for they have a high chance to be related to some  novel types of attacks.

-40 -30 -20 -10 0 10 20 30 40  -40  -30  -20  -10             Fig. 4. Clustering results in the 2D embedding created by t-SNE.



V. CONCLUSION  In this paper we presented a study on application of  association rule learning, clustering, and dimension reduction  on the darknet traffic. Frequent itemsets with respects to  probed destination ports are reported in the experiments.

Some of the significant association rules discovered in the  experiments are proved to correspond to specific known  attacks from IoT devices. Analysis on the activity-level time  series of the attack patterns has reveal emergence of new  type of attacks. The proposed scheme can help security  experts to discover new emerging attacks at their early stage,  providing valuable hints for further investigation. We leave  the formulation of a strategic framework to countermeasure  the new threats discovered by this approach for future work.

