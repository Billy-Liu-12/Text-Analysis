ARIPSO : Association Rule Interactive Postmining  Using Schemas And Ontologies

Abstract?One of the central problem in the field of knowledge discovery is the interestingness problem and the huge number of association rules being mined. As rule interestingness depends on user knowledge and goals, past research and applications have found that it?s too easy to discover huge number of rules and patterns. The existing methods in literature like postprocessing and algorithms to reduce itemsets and nonredundant rules do not guarantee mining of interesting rules for the user. As, these methods depend on statistical information rule discovery becomes a tedious process. In Data Mining, the usefulness of association rules is strongly limited by the huge amount of delivered rules. This paper proposes a new interactive approach ARIPSO to prune and filter the discovered rules. We propose to integrate user knowledge in association rule mining using three types of formalism: Ontologies, Rule Schemas and interactive framework. First, we use Domain and Background Ontology with the concept of GAR (Generalized Association Rules), Rule schema is based on specification language as represented by user knowledge and the interactive framework of ARIPSO assist the user throughout the analyzing task and permits him for easy selection of rules and also to revise the information that is proposed. Moreover page ranking algorithm is used for retrieval of frequently accessed rules and the concept of privacy is enforced while mining. Thus on applying our new approach the number of rules is reduced to several dozens or less.

Keywords?clustering, classification, association rule, interactive data exploration and discovery and knowledge management application.



I. INTRODUCTION  It has long been recognized in the knowledge discovery research and applications that rules are the most expressive and human understandable representations of knowledge i.e.

rules provide a self explanatory result to the user. The development of World Wide Web made the internet accessible to millions by making it easy for anyone to access information from internet. The enormous and explosive growth of a number of documents led to the serious problem of information overload.  So, rule discovery is considered to be the most important issue in data mining and in machine learning. Association rule discovery produces a full fledged rule set with the rules satisfying the minimum threshold value.

Association rule discovery is a general-purpose rule-discovery  scheme and has wide applications. The threshold measures of association rule are support and confidence. An association rule is represented by an implication P c where p is the antecedent and c is the consequence. An association rule is said to be strong if it satisfies both the minimum support and confidence.  There are two steps in finding association rules.

In the first phase we find the set of frequent itemsets and in he second phase w use the frequent itemsets to generate the interesting patterns. Apriori is the first developed algorithm to mine association rules. To make the rules more interesting for the user the support threshold must be minimum. Minimum the support threshold the maximum the number of rules mined. But, as the number of rules exceeds a count of 100 it creates a critical situation for the user to find out his needed one.

For this serious issue to reduce the huge voluminous number of rules many approaches in the literature have been proposed. Few include mining the rules using the deductive method thereby it interacts with the user frequently by making them to pick the interesting items. And few techniques make use of taxonomies for reducing only the hierarchical redundant rules in multilevel datasets.  By generating closed, optimal and frequent itemsets many algorithms tried to reduce the number of rules. Postprocessing methods like pruning, summarizing, grouping and visualization also were used in existing methods.

The rules should be expressed to the user in a more efficient, accurate and in a flexible manner for him to easily identify them.

The use of ontologies in semantic web enables quick and accurate web search. It also allows the development of intelligent internet agents and facilitates communication between a multitude of heterogeneous web-accessible devices.

The existing post processing depends on the statistical information, which do not prove that the mined rules are interesting for the user.

This paper proposes a new framework called ARIPSO (Association Rule Interactive Postprocessing Using Schemas And Ontologies) to prune and filter the discovered rules.

ARIPSO combines using ontologies, rule schemas and interactive framework together. We propose domain and background ontologies for binding the user knowledge during the postprocessing step. Rule Schemas extends the  PROCEEDINGS OF ICETECT 2011       specification language for user belief and expectation.

Interactive framework acts as guide for the user acting as a iterative loop through out in analyzing the task. In this paper, we propose to use page ranking algorithm that will prove that relations among concepts embedded into semantic annotations. This sort of ranking  behaves  at  an  inner  level b (i.e., it  exploits  more  precise  information  that  can be made available within a Web page). Our approach only relies on the knowledge of the user query, the Web pages to be ranked, and the underlying ontology. Thus, it allows us to effectively manage the search space and to reduce the complexity associated with the ranking task. Privacy is enforced while retrieving the data from the database. The exposure of the inner datas depends only on the rights of the user. Not all the secure versions of the large organizations will be exposed for everyone to access. Only the authentic persons can access the secure datas.

This paper is structured as follows: Section 2 deals about the basic definitions about the concepts discussed through the rest of the paper, Section 3, Section 4, Section 5 and finally section 6.



II. DEFINITIONS Formally, the association rule problem can be stated as follows: Let I ={i1, i2, . . . im} be a set of m distinct literals called items. D is a set of variable length transactions over I.

Each transaction contains a set of items i1, i2 . . . ik ? I. An association rule is an implication of the form X  Y , where X, Y ? I and X ? Y =?. X is called the antecedent and Y is called the consequent of the rule.

In general, a set of items (such as the antecedent or the consequent of a rule) is called an itemset. The number of items in an itemset is called the length of an itemset. Itemsets of some length k are referred to as k-itemsets. For an itemset X?Y, if Y is an m-itemset then Y is called an m-extension of

X. The threshold measures of an association rule are support and confidence.

Definition 1:  The support of an implication is P c is the ratio of the number of records containing both P and c to the number of records in D, denoted by supp (P c).

Support (P c) = #tuples_containing_both_P_and_c  #total_no_of_tuples  Support P c) =P (P U c)  Definition 2:  The confidence of the implication P c is defined to be ratio of supp (P c) to supp (P), represented by conf (P c).

The confidence forms the conditional probability.

Confidence (P c) = #tuples_containing_both_P_and_c  #tuples_containing_P  Confidence (P c) =P (P | c)  Starting from the database minsupp and minconf are the two thresholds been defined and any rule whose support and confidence exceeds this value is considered to be the proper rule. This process is basically done in two steps  1. First, all frequent itemsets are extracted. An item is called so if supp(x) >=minsupp.

2. Then for each frequent itemset the set of rules with conf(x)  >=minconf  is generated.

Definition 3:  A Frequent Itemset is defined as an itemset X which satisfies the minimum support count. The number of transactions required of the itemset to satisfy minimum count is called minimum support count.

Definition 4:  An Optimal rule is a subset of a non redundant rule set. A rule set is optimal with respect to interestingness metric if it contains all tuples except those with no greater interestingness than one of its more general rules.

Definition 5:  An Ontology is a quintuple (5-tuple) consisting of the core elements of an ontology, i.e., concepts, relations, hierarchy, a function that relates concepts non-taxonomically and a set of axioms. The elements are defined as follows:    O: = {C, R, Hc, rel, Ao} consisting of:    Two disjoint sets, C(Concepts) and R(Relations)  A Concept hierarchy, Hc: Hc is a directed related Hc  C*C which is called concept hierarchy or taxonomy. Hc (C1,C2) means C1 is a subconcept of C2.

A function rel: R  C*C that relates the concept non taxonomically.

A set of ontology Axioms Ao, expressed in appropriate logical language.



III. RELATED WORK    The ORD algorithm was proposed to mine the optimal rule sets. A unified framework for the discovery of a family of optimal rule sets is generated and the relationships with other rule-discovery schemes such as non redundant association rule discovery are characterized. The ORD algorithm is efficient since it does not generate all frequent patterns. It only makes use of a small subset of frequent patterns. Moreover,  it deals only with the heuristic rule discovery and not with association rule discovery.

Deductive method of mining rules was proposed. This method mine frequent itemsets starting from candidate two- itemsets to candidate (n-1) itemsets with inductive method to       produce huge rough rules on these frequent itemsets. It avoids producing huge amount of frequent itemsets. Moreover, it needs dynamic interaction with user any time when users want to check whether their interesting patterns were selected.

User-Expectation method was used in finding interesting patterns and also to reduce the number of rules mined. In this technique, the user is first asked to provide his/her expected patterns according to his/her past knowledge or intuitive feelings. Given these expectations, the system uses a fuzzy matching technique to match the discovered patterns against the user's expectations, and then rank the discovered patterns according to the matching results. A variety of rankings can be performed for different purposes, such as to confirm the user's knowledge and to identify unexpected patterns, which are by definition interesting. This method does not solve the problems associated with unexpected measures.

Gehrke and Burdick proposed the MAFIA algorithm based on depth-first-traversal and several pruning methods. It combines a vertical bitmap representation of the data with an efficient bitmap compression scheme. MAFIA also generates all frequent itemsets and closed frequent itemsets, though the algorithm s optimized for mining only maximal frequent itemsets. It uses many pruning techniques PEP (Parent Equivalence Pruning), FHUT, HUTMFI or dynamic reordering. The drawback with MAFIA is the loss of information because the subset frequency is not available; also it requires more space in memory to fit the entire database completely in memory.

Another measure mines the association rule based upon any-confidence, all-confidence and bond. The downward closure property is applied to both the all-confidence and bond.  It also proves that associations have a minimum all- confidence or minimum bond, then those associations will have a given lower bound on their minimum support and the rules produced from those associations will have a given lower bound on their minimum confidence as well. It uses association finding algorithm to generate large itemsets. The drawback of this method is that it fails to find itemsets which are small.

ML_T2L1 algorithm is an adaptation of Apriori to multi- level datasets. Association rule mining plays an important role.

For multi-level datasets the number of discovered rules is large and huge. This approach eliminates the redundant rules from multilevel datasets. This approach modifies the Apriori algorithm to work with multi-level datasets which is designed for single-level datasets. But the ML_T2L1 does not find cross level itemsets.

A novel technique called rule cover is used for redundancy reduction. The rule cover is defined as a subset of a rule set describing the same database transaction set as a rule set.

A. User Driven Mining Interestingness Measures were proposed to discover only the rules that are interesting for the user. Subjective and Objective measures are the two different types. Objective Measures that depend only on the data structure of a pattern and the underlying data used in the discovery process.

Subjective Measures depend only on the class of the user who examine the pattern. But the objective measures are not sufficient to reduce the number of extracted rules and to capture the interesting ones. Unexpectedness and actionability are the two measures are the two types of subjective measures proposed by Silbershatz and Tuzlin. Unexpectedness-a pattern is interesting if it is surprising to the user. Actionability-a pattern is interesting if the user can act on it to his advantage.

Klemttinen proposed templates and described the form of interesting rules and not interesting rules. Other approach used rule like formalism to express user expectation and the discovered form of rules are mined.

Another approach proposed query language called Constrained Association Query and dealt with the importance of user feedback and user flexibility in choosing then metric.

B. Ontologies in Mining Ontology is a widely adopted key technology for intelligent knowledge processing, providing a concept system of certain domain, which can reuse prior knowledge and reduce or eliminate confusion of concepts or terms. The ontology comes from the Greek ontos (being) + logos (word).

It has been introduced in philosophy in 19th century, by German Philosophers, to distinguish the study of various kinds of beings in the natural sciences. One of the most cited ontology definition is provided by Gruber ?An ontology is a formal, explicit specification of a shared conceptualization? where conceptualization stands for an abstract model, explicit means that the elements are clearly defined and lastly, formal means that the ontology should be machine processable.

An ontology is a ?formal specification for the intended mining of a formal vocabulary? There are several ways of using Ontologies: 1. Domain and Background Ontologies 2. Ontologies of data mining process 3. Metadata Ontologies. In this paper, we focus on the Domain and Background Ontologies introduced by Srikant and Agrawal. The advantage of the Domain and Background Ontologies is that it can benefit all phases of KDD cycle.

A concept called Raising was presented which is related to GAR (Generalized Association Rules). Raising is the operation that makes rules more abstract and in keeping confidence high enough it increases support. Also raising discovers strong rules which possess low support before.

In this paper we propose using the postprocessing step.

Basically pruning and abstraction are the two types of constraint.  In the preprocessing task the process of applying the constraints is done in the first step. Mining is done in the first step. Pruning excluded from the first the unwanted rules.

There are four types of Ontologies been defined in literature: 1. Upper (or top level) Ontologies 2. Domain Ontologies 3. Task Ontologies 4. Application Ontologies. The upper ontology deals with the general concept and the other three types deal with domain specific concepts.

Fig 1: Process of user query checking  Through assistance of ontologies the system will take more responsibilities in controlling the correctness and effectiveness of the query formulation (Fig 1). First check the syntax and then performs the semantic checking if syntax is full right.

A few ontology repositories have previously been developed for information system including ontoserver, webonto and ontolingua. They provide a repository of ontologies to assist users in generating new ontologies and in managing the existing ontologies.



IV. FRAMEWORK DESCRIPTION    The proposed approach is composed of integration of all the three representations: ontology, rule schema and interactive framework.

Fig 2: Framework Description   In fig 2 we find that the postprocessing step follows the ontology and it applies iteratively a set of filters over the rules.

There are three types of filters: Minimum Improvement Constraint Filter, Item-Relatedness Filter, Rule Schema Filters / Pruning. In this paper we use Item-Relatedness Filter and  measure the idea of relatedness between the items and their similarities. Relatedness between the condition of the rule and the consequent of the rule is also measured.

ARIPSO makes use of rule schemas. There are types of rule schemas: GI (General Impression), RPC (Reasonable Precise Concepts) and PK (Precise Knowledge). The syntax of GI is given by   Gi (<s1,s2,?.sm>) [support, confidence]  Where si is an element of item taxonomy.

The main difference between the rule schemas GI and RPC is based on the implication characteristics. In GI the direction of the implication is not known, so it is not possible to find out the antecedent and consequent. But the RPC supports complete implication, so the consequent and the antecedent can be easily found. The problem with Precise Knowledge is that it needs the exact support and confidence for rule schema and because it s statistically defined, so its not used in many cases for filtering. The concept of ontology is different from that of taxonomy. Taxonomy is a classification or hierarchical categorization of items in a domain. But ontology specifies many characteristics of a domain.

Fig 3: Ontology Description  The expressiveness for ontology is provided only by rule schemas by combining the abstraction and pruning constraints.

The syntax of rule schema is given by   RS (<x1,?.,xn ( ) y1,?,ym>)   Where xi and xj are subset of C of O where O is the ontology which is {C, R, I, H, A}. And  is optional, which when used comes under implicative rule schema and when not used comes under non implicative rule schemas.

RSi (Low Chemical Product, chemical Product>), which is a non implicative rule schema and comes under GI.

RSj (<Low Chemical Product   chemical Product>), which is a implicative rule schema and comes under RPC.

The above rules are framed from the Fig 3. Also three concepts of ontology can be defined form them 1. Leaf concepts 2. Generalized concept 3. Restriction concepts. The Leaf concepts include the one in the leaf nodes of the figure.

The generalized concept are defined as roots at level 1 and       level 2 and does not include the ontology concepts. Restriction concepts include only the ontology at level 2 in bold.

The paper makes use of four operators for filtering the rules. The type of rules includes confirming rules, unexpected antecedent rules, unexpected consequent rules and both side unexpected rules.  The types of operators that are used to filter these rules are 1. Pruning 2. Conforming 3. Unexpectedness 4.

Exceptions. The representation of these operators are defined by P(RS), C(RS), U(RS) respectively.

To filter the uninteresting rules the pruning operators are used. The conforming operator confirms the implication from the concepts in the database. It filters the non implicative rule schema are filtered. Rules which provide surprise effect to the user are filtered using the unexpectedness filter. Conforming rules are mined from exception operators.

Fig 4: Operators in Rule Schema  Among the filters used MICF (Minimum Improvement Constraint Filter) selects those rules whose confidence is greater than minimp. IRF (Item-Relatedness Filter) measures the semantic distance between the item taxonomies.

In our approach we use the IRF filter because users are interested in finding association between items with different functionalities. The distance between the items is calculated by the minimum path that connects the two items. Thus the IRF calculates the minimum of all the distance computed among items in the condition and the consequent.

The role of page ranking technique is used after all the operations are performed. In this module ranking algorithm defines the rank results, most of the solutions need to work on the whole annotated knowledge base. Relevance is measured as the probability that a retrieved resource actually contains those relations whose existence was assumed by the user at the time of   querying. We propose a novel ranking strategy that provides a score (rank) for each web page.

On each access to the page simultaneously the rank for the page is incremented. Based on the user query the page with high rate is chosen and is considered as most frequently accessed web pages. Accordingly the rules with higher ranks  are displayed in the top. Several ranking algorithm based on the relation based metadata have been proposed but they mainly use page relevance criteria based on the information from the knowledge base making the application infeasible in huge platforms. Relevance is measured as the probability that a retrieved resource actually contains those relations whose existence was assumed by the user at the time of   querying.

The database contains the pages or concepts and the rules along with association rules been mined. Thus against each page the ranks are provided. It provides fast accessing technique by searching the database table. There is no necessity to scan the entire server and search for the number of times the particular rule is accessed. Also it contains information about the frequently accessed rules there by making the accessing fast.

Based on the rank the rules are placed for visualizing to the user. Thus the rules having higher ranks are placed at the top and the rules at the bottom have low rank.

Also the concept of privacy is implemented when mining the data from the database thereby the concept of security is implemented. This privacy concept does not expose all the datas intended to the user but it exposes the data based upon the authorized datas.

The basic steps include ontology construction, defining the rule schemas, operators, visualizing rules, validating them, using filters, ranking them and applying privacy concept while mining.



V. CONCLUSION This paper discusses mining interesting association rules from a huge voluminous number of rules. We propose combing usage of ontologies, rule schemas, interactive framework, rnking approach and privacy together in mining the rules and also IRF filters out the unwanted rules using different operators. These operators are used in the postprocessing task in mining and guide the user all over the process. ARIPSO framework thus prunes and filters the needed rules with respect to the expectation of the user. The future enhancement might include other filters in pruning the rules. Thus, by the interactive approach the rules are mined whch are expected  and needed by the user.



VI. REFERENCES   [1] Chin-Ang Wu, Wen-Yang Lin, Chuan-Chun Wu, ?Ontology-Assisted Query Formulation in Multidimensional Association Rule Mining?.

[2] Wenxiang Dou, Jinglu Hu, Gengfeng Wu, ?Interesting Rules Mining with Deductive Method?, ICROS-SICE International Joint Conference 2009.

[3] Gavin Shaw, ?Extracting Non-Redundant Approximate Rules from Multi-Level Datasets,? 2008 20th IEEE [4] Sufal Das, Bhabesh Nath, ?Dimesionality Reduction using Association Rule Mining?, 2008 IEEE Region 10 Colloquium and the Third ICIIS, Kharagpur, India       [5] Tao Jiang, Ah-Hwee Tan, Senior Member, IEEE, and Ke Wang, ?Mining Generalized Associations of Semantic Knowledge And Data Engineering, Vol. 19, No. 2, February [6] Ding Pan, Yan Pan, ?Using Ontology Repositary to Support Data Mining,? Proceedings of the 6th world congress on Intelligent Control and Automation, June 2006.

[7] Karin Koogan Breitman, Julio Caesar, ?Ontology as Requirement Engineering Product,? Proceedings of the 11th IEEE International Requirement Engineering Conference.

[8] E.R. Omiecinski, ?Alternative Interest Measures for Mining Associations in Databases,? IEEE Trans. Knowledge and Data Eng., vol. 15, no. 1, pp. 57-69, Jan./Feb. 2003.

[9] B. Liu, W. Hsu, L.-F. Mun, and H.-Y. Lee, ?Finding Interesting Patterns Using User Expectations,? IEEE Trans.

Knowledge and Data Eng., vol. 11, no. 6, pp. 817-832, Nov.

1999.

[10] M.J. Zaki, ?Generating Non-Redundant Association Rules,? Proc. Int?l Conf. Knowledge Discovery and Data Mining, pp. 34-43, 2000.

[11] J. Li, ?On Optimal Rule Discovery,? IEEE Trans.

Knowledge and Data Eng., vol. 18, no. 4, pp. 460-471, Apr.

2006.

[12] D. Burdick, M. Calimlim, J. Flannick, J. Gehrke, and T.

Yiu, ?Mafia: A Maximal Frequent Itemset Algorithm,? IEEE Trans. Knowledge and Data Eng., vol. 17, no. 11, pp. 1490- 1504, Nov. 2005.

[13] A. Silberschatz and A. Tuzhilin, ?What Makes Patterns Interesting in Knowledge Discovery Systems,? IEEE Trans.

Knowledge and Data Eng. vol. 8, no. 6, pp. 970-974, Dec.

1996.

A. Books Referred [1] Jiawei Han, Micheline Kamber, ?Data Mining?Concepts and Techniques,? B.Sites Referred  1. en.wikipedia.org/wiki/Concept_mining 2. en.wikipedia.org/wiki/Data_mining 3. www.dataentryindia.com/data_processing/data_minin  g.php 4. www.scribd.com/doc/21860679/Data-Mining-  Concepts 5. ieeexplore.ieee.org/iel5/10226/32596/01525216.pdf 6. www.springer.com/life+sciences/.../book/978-1-  4419-6514-1 7. books.google.co.in/books?isbn=1402089740...

