ICTON 2013  Tu.D4.3

ABSTRACT The big data era is posing unprecedented challenges on the existing network infrastructure. In today?s networks, data are transferred across the network as a combination of a series of packets, delivered one by one, without considering the data in their entirety with respective service level requirements. The so called elephant data, which may be less sensitive to transfer delay, compete precious network resources with mice data, in most cases from interactive and delay sensitive applications. Consequently, the Quality of Service (QoS) of interactive applications is hard to provision, and the utility of network is low. We propose a new data transfer model to complement the existing per-packet forwarding paradigm. In the new data transfer model, a service level requirement is assigned (by the data source) to each big data transfer request. Instead of transferring these data on per-packet bases immediately upon entering the network, the network stores the data until it find necessary, or enough network resource is available for that transfer. The scheduled data delivery is realized through the use of dynamic circuit switching. We also present some preliminary simulation results of SSS networks.

Keywords: Big Data, OpenFlow, Data Delivery, Network Resource Management, Dynamic Circuit Switching.

1. INTRODUCTION As the cost in creating, capturing, processing and storing information is decreasing steadily, explosive growth in digital data has been seen in the last several years. It is reported that in 2011, the amount of information created and replicated exceeds 1.8 zettabytes, growing by a factor of 8 within 5 years [1].  The biggest domestic C2C website, taobao.com, generates about 20 terabytes of data each day, from within tens of millions of online transactions. The human society has now entered the so called ?big data era?.

One apparent change that the big data era brings to the network infrastructure is that data are moved across the network more frequently, and often, in larger size. Email servers that support large attachments with up to a few hundred Mbytes are commonplace. In 2012, Google announced that Gmail accepts 10 GB attachment, 400 times larger than what you can send through traditional attachment [2].  Exchange of photos/videos with a few Giga-bytes is now becoming part of everyone?s daily life.

The movement of the increasing number of large data files is posing unprecedented challenges on the existing network infrastructure. In today?s networks, data are transferred across the network as a combination of a series of packets, delivered one by one, without considering the data in their entirety with respective service level requirements. The so called elephant data, which may be less sensitive to transfer delay, compete precious network resources with mice data, in most cases from interactive and delay sensitive applications. Consequently, the Quality of Service (QoS) of interactive applications is hard to provision, and the utility of network is low [3].

Intuitively, by relaxing the delivery time of large data files according to their respective priorities, the network resources may be used more efficiently and network congestion can be alleviated. In this paper, we propose a new data transfer model to complement the existing per-packet forwarding paradigm. In the new data transfer model, a service level requirement in terms of delivery priority (or deadline) is assigned (by the data generator) to each big data transfer request. Instead of transferring these data on per-packet bases immediately upon entering the network, the network stores the data until it find necessary, or enough network resource is available for that transfer. The scheduled data transfer is realized through the use of dynamic circuit switching.

2. SSS - A NEW DATA DELIVERY MODEL IN THE BIG DATA ERA  2.1 Rationale and Overall Description In today?s data networks, data from applications are packetized before entering the network and then delivered on a per-packet basis in the network until all pieces have reached their destination. This makes packet processing/forwarding the only function the network has to perform, simplifies the application/network interaction and consequently, drives application innovations. While this being the biggest benefit of pure packet switching has been recognized by everyone, its shortcoming are also becoming more and more evident, in the presence of higher traffic volume and larger data size. Application designers, especially in the context of big data, find it difficult to move big data from one side of the network to another. Without the use of concurrent TCP flows, or other transport level optimizations, the movement of data files with a few gigabytes is difficult,    ICTON 2013  Tu.D4.3    if not impossible, in a congested network. And network operators also find it difficult to deploy a new service on top of a shared packet switched network, which is prone to unpredictable congestion at all times.

The problem lies in the heart of ?best effort? packet switching. Little effort can be exerted at the network level: i) to perform access control on incoming packet delivery requests; ii) to coordinate the delivery of data at the right moments; and iii) to take advantage of different delivery priorities (timeliness). As a result, performing consistent and differentiated services to big data, which have already been packetized, is difficult.

Efforts to improve the effectiveness of moving big data (or large file) in a public Internet have been constantly seen during the past two decades. Examples include early peer-to-peer file sharing, multipath transport, and other application specific optimizations. Often, these optimizations are overlaid on top of the existing Internet, without changing operations of the network layer and lower. At times when the majority of data traffic is in small volume and big data movement demand is scarce, overlay optimization is effective. With the dramatic increase in the demand of big data generation and movement, a network infrastructure that is capable of moving big data more naturally should be considered. Unlike the best-effort packet delivery in the existing Internet, a more natural way to move big data should, in our opinion: i) be able to perform access control so that network congestion may be avoided/controlled; ii) be able to treat a piece of data as a whole with respective delivery priority; iii) be a fundamental network level service, and independent from applications.

Based on the discussion above, we propose a Store, Schedule and Switch (SSS) data delivery model, to tackle the data delivery challenge in the big data era. This delivery model makes use of mass storage and fast (virtual) circuit switching. Data sources assign a delivery priority to each piece of big data. The priority is used by the network to decide at which moment the data should be delivered/moved.  In the following two subsections, we first introduce the SSS data delivery model. Then we discuss the key controlling challenges to realize this model.

2.2 The SSS Architecture The proposed Store, Schedule and Switch (SSS) data delivery model is shown in Fig. 1(a). In the eye of applications, an SSS network is capable of providing scheduled network services in the form of standard APIs (Fig. 1(b)). When there is data ready to send, the data source (mobile devices or computers) sends a request to a centralized scheduler through the type (1) interface, providing information such as data size, destination and priority (e.g., deadline of delivery). Upon receiving such a request, the scheduler makes a decision on whether the request can be admitted, according to historical request information. If the request is admitted, the data source sends the data to the nearest switching node (the ingress node) and the data is then stored in the network.

Data from multiple sources under the same switching node are aggregated in the storage. The data for the same destination egress node and with close delivery deadlines form a delivery batch. As the deadline of a batch approaches, the scheduler configures a (virtual) circuit for the batch through the type (2) interface, and moves it to the storage on the egress node. After arriving at the egress node, the data in the batch are delivered to their destination applications through their respective procedures. It is worth noting that although type (1) interface exists between the scheduler and all data sources/sinks, and type (2) interface exists between the scheduler and all switching nodes, only a few are illustrated for simplicity. Also for simplicity, the network device that connects multiple data sources/sinks to a SSS switching node, e.g., a router or a commodity switch, is not shown.

(a) (b)  Figure 1. Store, schedule and switch (SSS) data delivery.

It is apparent that the introduction of storage into circuit switching networks relaxes the delivery timeliness of data, and hence is helpful to use the network resources in a more uniform and balanced manner. The higher the storage capacity is, and the less tighter requirements application data have on delivery deadline, the higher capacity an SSS network might have. Here, high capacity means that more data delivery request can be admitted and accomplished. In this sense, the storage on switching nodes helps to reduce conflicts among those data delivery requests arrives closely in time, a very close analogy to the use of buffers in routers to avoid packet contentions.

SSS does not require storage on every switching node. Ideally, only switching nodes that are close to data source/sinks need to be equipped with storage. On the other hand, when the network is large, it might be difficult    ICTON 2013  Tu.D4.3    to establish a high capacity (virtual) circuit across the whole network. In that case, installing storage on intermediate nodes may improve the network performance by delivering data in 2 or more stops.

It is also worth noting that the SSS architecture does not impose any particular requirements on the underline (virtual) circuit switching network. Any network technology that is capable to provision bandwidth guaranteed pipes can be used to implement SSS. For instance, SSS can be implemented on a wavelength switched optical network, on an IP network with Traffic Engineering, or on a Software Defined Network with OpenFlow control [4]. Although it is not clear at this moment whether the use of fine granular virtual circuits (as opposed to the full capacity lightpath) as the delivery vehicle is helpful to improve network performance, it is apparent that such a capability will give the scheduler more flexibility in scheduling different sized data batches, at the cost of higher computing complexity.

2.3 Controlling Challenges Implementing the SSS architecture requires additional controlling intelligences and these can be roughly divided into the following categories.

Protocols ? In the current Internet, the intelligence of storing data into/retrieving data from the network (such as cloud servers) is built into specific applications without involving the network devices. In SSS, protocols must be defined so that the application and the network can interact (on the type 1 interface). During the interaction, they exchange information of data to be delivered, negotiate service levels, and possibly, negotiate the price for delivery. Protocol may also need to be defined to govern the data storing and retrieving process. For instance, the data sink must be informed of the availability of the data on the storage of the egress switching node, when the movement of data has finished. Within the network, procedure must also be defined between the scheduler and switching nodes (on the type 2 interface), so that a (virtual) circuit can be provisioned when a data batch is ready to be moved. The existing signaling protocols such as RSVP-TE can be good candidates for a distributed implementation. Flow switching can be used as a centralized implementation [4].

Algorithms ? In an SSS network, data with the same egress switching node and close delivery deadline can be aggregated in the storage before moved in a batch. The size of the batch has important implication on the network performance and end-to-end data delivery delay. Larger batch size will result in higher network utilization, longer average delivery delay and improved throughput in terms of the number of data being delivered. Smaller batch offers shorter average delivery delay, at the expenses of higher controlling overhead and lower throughput. This is especially true when the delay in provisioning a bandwidth pipe in the SSS network is not negligible compared with the delivery time of the batch. The batch size should be carefully chosen according to the delivery deadline distribution, network provisioning performance and targeted average delivery delay.

Variable batch size may be desirable to balance the quality of delivery service, network utilization and throughput.

When a piece of data arrives at the SSS network, the batch that it will ultimately belong to does not yet exist, thus it might be very difficult to guarantee the successful delivery of the data at this moment. On the other hand, performing access control is very important for an SSS network to achieve predictable delivery service. So algorithms must be designed to estimate the current and future delivery load and based on that, make appropriate decisions on incoming data delivery requests. Of equal importance is allocating an appropriate bandwidth pipe for each batch. This includes determining the size of the bandwidth pipe, its route and start time.

Network design ? In an SSS network, data are delivered in their entirety. Thus classical performance metrics, such as packet delay, jitter, and node/network throughput are no longer applicable. An SSS network is more appropriately characterized by its capability in delivering data, namely, the amount of data being successfully moved and their delay. Given the network topology, storage configuration and networking technology, such capacity is in fact fixed. Determining the capacity of an SSS network will be of primary importance at the network design phase. It is also interesting to investigate how the size and placement of storage may affect the performance and capacity of a particular SSS network.

3. PRELIMINARY PERFORMANCE EVALUATION A preliminary performance evaluation of SSS networks is conducted through simulations on the 14-node NSFNET. In the simulation, every switching node is equipped with storage. Link speed in the network is assumed to be 10Gbps. Fig. 2 shows how the number/ratio of discarded data is related to storage equipped on each switching node and to the traffic load. As shown in Fig. 2(a), increasing the storage capacity on switching nodes is helpful to reduce the number of discarded data caused by lack of storage  (on the x-axis, the storage capacity is unified to the number when no data is discarded due to insufficient storage). During the meantime, increasing the storage capacity will increase the number of accepted data flows and will ultimately increase the number of data flows that cannot be delivered in time. The overall discard ratio decrease slightly as the storage    ICTON 2013  Tu.D4.3    capacity increases. Figure 2(b) indicates that the discard ratio is low at light traffic load, but increase quickly when the load exceeds a certain value.

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8        Storage capacity  N um  be r  of d  is ca  rd ed  fl ow  s      discarded flows by consumer deadlines discarded flows by limited storages   0 2 4 6 8 10 12 14   0.1  0.2  0.3  0.4  0.5  0.6  0.7  lamda  di sc  ar de  d flo  w s r  at io   (a) Number of discarded data vs. storage capacity (b) Discard ratio vs. data arrival rate (or load)  Figure 2. Performances of a SSS network.

4. CONCLUSIONS In this paper, we propose a Store, Schedule and Switch (SSS) data delivery paradigm for the big data era, to complement existing per-packet forwarding networks. In SSS networks, data storage becomes part of the network, and together with dynamic virtual circuit switching, provides scheduled data delivery services to applications. SSS networks relax the delivery timeliness requirements of data, and are thus able to make use of network resources in a more balanced and controllable way. As discussed above, SSS introduces a number of challenges and they are subjects of future study.

ACKNOWLEDGEMENTS This work is supported in part by the 863 Program, the NSFC (61271217), Fok Ying-Tong Education Foundation and 973 program of China (2010CB328204-5).

