Hierarchical Multi-Label Associative Classification (HMAC) Using Negative Rules

Abstract?Hierarchical Classification is a very important clas- sification task for arranging data in a hierarchical structure.

Hierarchical arrangement of data is one of the best methods to achieve better understanding of complex data. In this paper, we propose the HMAC method to perform Hierarchical Multi-label Associative Classification. This method uses multiple and negative rules to predict class-set and to filter exceptional cases in order to improve both accuracy and explanatory ability of the resulting classifier. Redundant rule pruning method for negative rules and rule ranking method for hierarchical associative classification are developed. Moreover, we propose a rule evaluation measure, Sim, that tread-off between F-measure and Jaccard?s coefficient to encode hierarchical structure meaning of actual and predicted node collections. We show that Sim is robust and simple rule evaluation measure. Experimental results show that HMAC im- proves accuracy and explanatory ability of hierarchical classifiers compared with various rule ranking and pruning techniques.

Index Terms?Data mining; Associative classification; Hier- archical classification; Negative rule; Multiple rule; Multi-label classification; Rule ranking

I. INTRODUCTION Association rule mining has been used effectively to build  classification models (classifiers), known as Associative Clas- sification (AC) [1, 2]. [2?4] show that AC often builds more ac- curate classifiers than traditional classification techniques and many of the rules found by AC methods cannot be discovered by traditional classification algorithms. This paper, we focus on three aspects of associative classification, which are 1. the number of classes to be predicted for each transaction (single- label vs. multiple-label classification), 2. the particular type of structure over labels (flat vs. hierarchical structure) and 3.

presence or absence of items and classes in the representation of rules (positive vs. negative).

Traditional single-label classification algorithms such as CBA [2] and CMAR [5] refer to classification tasks that predict only one label. These basic algorithms are generally known as single-label classification. The algorithms are not suitable for the data structures found in real world applications.

For example, in medical diagnosis, a patient may be suffering from diabetes and prostate cancer at the same time [6]. Hence, multi-label classification algorithms such as MCAR [7] and MMAC [8] algorithms are preferred. These algorithms have been used to predict more than two labels for classification tasks.

Most of the existing algorithms in AC have been developed for flat structure over labels [2, 4?8]. However, these algo- rithms do not cover many significant real world classification tasks involve a large number of categories, which are arranged in a hierarchical structure; for example, classifying documents into subject categories under the Library of Congress scheme, classifying World Wide Web documents into topic hierarchies, or classifying proteins by gene ontology which annotate them.

For this reason, hierarchical classification has been proposed to support hierarchical structures [9?12]. Little research has focused on hierarchical AC. Itskevitch [9] built COMAR that applies AC to e-mail classification using multiple rules.

In additional, the author proposed rule cohesion and phase cohesion measures for rule ranking in hierarchical AC, prob- abilistic hierarchical accuracy for evaluation of hierarchical class. However, this method focused only on single-label classification.

Negative AC, classification using negative rules, has been investigated by [13?16] proposed. Antonie [13] and Bala [16] focused on rule generation. Antonie [13] uses the correlation coefficient between an item and the set of class labels to generate and prune rules. [16] uses lift instead of correlation coefficient. A positive association rule is produced with a lift value greater than 1 and a lift value of less than 1 implies a negative association rule. Another work focuses on classifier building, [14, 15] use negative rules to improve accuracy and explanatory ability. However, these methods cannot classify multi-label classification and the negative rule form cannot represent some complex cases in applications; for instance, prevention or diagnosis of new infectious diseases such as swine flu.

This paper aims to improve the prediction accuracy and explanatory ability of a Hierarchical Multi-label Associa- tive Classification (HMAC) method using multiple and neg- ative rules such as rules of positive class-set, x1?x2 ? c1c2, to predict class-set, and rules of negative class-set, x1?x2?(x4x5) ? ?(c1c2), to filter exceptional cases in order to improve explanatory ability of rule based classifier.

This paper proposes three improvements to hierarchical AC algorithms. First, we extend the pruning of redundant negative rules. Second, we introduce a rule ranking method based on estimated accuracy to add more tie-breaking conditions.

Lastly, we propose a corresponding evaluation measure, Sim  Proc. 9th  IEEE  Int. Conf. on Cognitive  Informatics  (ICCI?10) F. Sun, Y. Wang, J. Lu, B. Zhang, W. Kinsner & L.A. Zadeh (Eds.)  ?    Fig. 1. Associative classification steps  that presents relation between hierarchical class-sets.

The rest of this paper is organized as follows. Section II re-  views background knowledge; Section III descries the HMAC approach; Section IV describes evaluation measures for hierar- chical classification; Section V show the experimental results.

Conclusions and future work are presented in Section VI.



II. BACKGROUND KNOWLEDGE This section gives background information about associative  classifier building, hierarchical structure of ontology, hierarchi- cal associative classification, and negative association rules.

A. Associative Classification Associative classification (AC) is a technique relying on  a special type of association rule called Class Association Rules (CARs) [2]. The rhs of a CAR contains only a class label. This section presents the main steps in building the AC model, shown in Figure 1. The first step is CAR generation, the second step is rule selection, and the last step is classifier creation from the selected rules. In Step I, itemsets whose support is higher than a threshold are selected. Then, the CARs are generated from these frequent itemsets; only CARs whose confidence level is higher than a threshold are retained.

The rules derived from Step I can be redundant or erroneous.

Several rule pruning techniques [3, 5, 8, 13, 17] have been proposed in order to create a more effective and accurate classifier. In this pruning step, a commonly used measure is Pearson?s correlation coefficient between left hand side (lhs) and the right hand side (rhs) of the rules [13, 15, 16].

The other pruning methods try to discard specific rules with lower confidence values than general rules. In this redundant rule pruning [3, 5, 13], A ? c is considered as more general than A? ? c if A ? A?. This pruning method reduces the size of the resulting classifiers and minimizes rule redundancy.

In order to build a classifier from the selected rules, ranking plays an important role. Indeed, the rank of rules indicates which rule is to be applied first. Highly ranked rules are then used more frequently in predicting test data. The rule ranking is usually based on several parameters including support, confidence, and rule antecedent cardinality [2, 5]. In some cases, tie breaking conditions are required. For example, [7, 8] propose two tie breaking conditions based on class distribution frequency and favors rules that are associated with the most representative class (ActOccr). Note that, the above-mentioned algorithms focus on flat (non-hierarchical) classification methods.

Fig. 2. A hierarchial ontology  In Step III, a classifier is formed by the ranked CARs which are selected incrementally. Only rules that cover at least one training data not covered by previous selected rules are kept for further classification. This database coverage method was created by the CBA and subsequently adopted by other algorithms, including those in [5, 7, 18].

B. Hierarchical Structure of Ontology Definition 1 (Hierarchy H(S,?)): [19] Let S be a par-  tially ordered set under ordering ?. We say that an ordering ? defines a hierarchy for S if the following three conditions are satisfied: (1) x ? y ? x ? y;?x, y ? S. We say (S,?) is better than (S,?), (2) (S,?) is a reflexive, transitive closure of (S,?), (3) No other ordering ? satisfies (1) and (2).

Example: Let S = {Plant, Fruit, Orange}. We can define a partial ordering ? on S according to the is-a relationship. For example, Fruit is a Plant, Orange is a Fruit, and Orange also is a Plant. In addition, everything is a itself. Thus, (S,?) = {(Plant, Plant), (Fruit, Fruit), (Orange, Orange), (Fruit, Plant), (Orange, Fruit), (Orange, Plant)}. The reflexive, tran- sitive closure of ? is the set: (S,?) = {(Fruit, Plant), (Orange, Fruit)}, which is the only hierarchy associated with (S,?).

Figure 2 shows an ontology including the hierarchy asso- ciated is-a and part-of relationships. Indeed, an ontology is often used by domain experts to encode domain knowledge.

It is represented as a directed acyclic graph in which each node represents a concept, and links between nodes represent some relation between them. For a given relation, the ontology?s sub- graph is described by a hierarchy associated with that relation.

In this paper we focus only on the is-a relation in hierarchical structure of ontology.

C. Hierarchical associative classification Hierarchical associative classification (HAC) is a task in  which class labels are assigned a hierarchical structure, as given by Definition 1. An associative classifier is composed of class association rules that can be used to predict hierarchical class. Therefore, a rule that predicts ?Fruit? when an input image is indeed a ?Grape? should not be considered as totally in error. Compared with traditional associative classifiers that work with flat structure, HAC, should take into account the class hierarchy in rule pruning and rule ranking phases.

Further, a class association rule that contains more than one class on the rhs is called multi-label associative classification.

??    Fig. 3. Steps in HMAC method  Thus, a HAC that supports multi-label classification is called hierarchical multi-label associative classification.

D. Negative association rule Note that not only the presence of attributes can be used  to predict class, but their absence is also a useful indicator in some cases. Following the derivation in [20], let X denote a positive itemset meaning that X contains only items possessing some attributes, N denote a negative itemset containing items absent the attributes, and NP is negation of positive itemset denoting the non-simultaneous presence of attributes. For example, ?x1 is of type N , and means that x1 must be absent. If ?(x1x2) is of type NP , it denotes non-simultaneous presence of x1 and x2. This means that x1 or x2 can still be present but not simultaneously. To simplify the discussion, let Pa denote the lhs of CARs.

In an analogous manner, the rhs of CARs can be separated in three types, C, NC, and NPC. Let C be the positive class- set denoting the presence of class C; NC be the negative class-set denoting the absence of the class; and NPC be the negation of positive class-set denoting the non-simultaneous presence of classes such as ?(c1c2) and ?(c1c3c4). In the following, let Pc denote the rhs of CARs. Then, a negative association rule is of the form Pa ? Pc. Note that Pa is a conjunction of three patterns X , N , and NP , while Pc is either C, NC, or NPC. We will call all CARs for which Pc = C the rules of positive class-set (RPC), and all CARs for which Pc = NC or Pc = NPC the rules of negative class-set (RNC).



III. HMAC: HIERARCHICAL MULTI-LABEL ASSOCIATIVE CLASSIFICATION  In this section we present a new Hierarchical Multi-label Associative Classification method called HMAC, using mul- tiple and negative rules. An overview of HMAC is shown in Figure 3. The RPC are generated in Step I. Pruning strategies to reduce the number of generated rules are applied in Step II.

The rule precedence is an important concept to use appropriate conditions to decide which rules are better. In Step III, the classifier builder for HMAC that uses rule pruning based on database coverage is vital for selecting a subset of high quality rules for the classification step. Finally, a classification step, for given testing data object obj, HMAC extracts a subset of rules matching the obj and predicts the class label of the obj by analyzing this subset of rules.

A. Rules Pruning In Step II a subset was selected to form the classifier, mainly  focused on avoiding redundant rule that would mislead the prediction process in testing data. HMAC uses two pruning strategies to reduce the size of RPC.

1) Pearson?s correlation coefficient: For each Positive Class-set rule RPC, we calculate Pearson?s correlation coeffi- cient ? between the lhs and the rhs and prune the rules whose correlation is below a user-specified threshold. If ? = 0, the lhs and rhs of the rule are independent; ? = +1 and ? = ?1 mean the lhs and rhs of the rule are perfectly positively and negatively correlated, respectively.

2) Redundant rules pruning: The rules in the resulting classifiers may share lhs and there could be several specific rules containing many general rules. Redundant rule pruning discards specific rules that have a lower rank than general rules. In this study, the redundant rule pruning method for the negative rules is as follows. Once the rule generation process is finished, the negative rules are classified by the lhs of each rule in four clusters: X , X ?N , X ?NP , and X ?N ?NP .

Then, an evaluation step is performed to prune all rules for each cluster, such as Pa? ? Pc, from the set of generated rules, where there is some general rule Pa ? Pc of a higher ranking and Pa ? Pa? as defined in definition 2.

Definition 2: A set of itemsets Pa ? Pa? if (X ? X ?) ? (N ? N ?) ? (NP ? NP ?).

For example, rule r1 : x1?x2?(x4x5) ? c1c2 and rule r2 : x1?x2?x3?(x4x5)?(x6x7) ? c1c2. Moreover, both of them have the same rhs pattern of classes and rule r1 is higher than rule r2. The X component of r1 and r2 is x1 and x1, respectively, then {x1} ? {x1}. Next, the N component of r1 and r2 is x2 and x2, x3, respectively, then {x2} ? {x2, x3}. The last component, NP itemsets, r1 and r2 are (x4x5) and (x4x5), (x6x7), respectively, then {(x4x5)} ? {(x4x5), (x6x7)}. Therefore, the rule r1 ? r2, hence r2 is discarded.

B. Rule Ranking Traditional rankings are based on flat non-hierarchial clas-  sification. In this study we focus on hierarchical classification, so the HMAC ranking method proposed as shown in Figure 4 is used to rank RPC only. The rule ranking based on several parameters that order rules by priority, which are F-measure, Jaccard, support, ActOccr, and specific rule. HMAC ranking replaces confidence parameter with two measures, the first is F-measure (FM), which is given in Equation 1. This measure has a high value if two node collections exactly match. The second measure is weighted Jaccard?s coefficient, Jaccardw, that encodes hierarchical structure meaning to evaluate the strength of the semantic link between two groups of concepts from the difference or same hierarchical structure (this paper focuses on the same hierarchical structure). Jaccardw is given in Equation 4. Section IV describes details of these measures.

Moreover, we rank the rules that have more conditions in the lhs higher than the others.

??    Fig. 4. HMAC rule ranking method  C. HMAC Classifier We propose an algorithm to create HMAC classifier in Phase  III, HMAC algorithm uses multiple and RNC to filter the exceptional case for the following RPC (see Figure 5). HMAC algorithm can be summarized as follows:  Step I. Rule sorting: RPC are sorted by rule precedence in descending order as shown in Figure 4 (line 1).

Step II. Classifier building: Each rule rpci is considered from top to bottom. If rcpi match at least one training transaction, we will create a classifier, else consider the next rpci (line 4). In classifier building, all RNCi are generated from rpci (line 5), then mark all training transactions tj that are matched rpci and unmatched RNCi (line 6). Next, default class-set (Def ) is created (line 7-9). We also choose a default class-set, which is the majority class-set in the training data T  ?. Then in line 10-11 the new classifier (Clnew) is created.

Step III. Classifier selection: After the measure of Clnew  accuracy is calculated in line 11, a classifier is selected (line 12-15). If Clnew is selected, then we will remove all marked tj , else all tj are unmarked.

Repeat Step II-III until there is no more transactions or rules remaining. Remaining rules are appended to the classifier in the accuracy decreasing order. Figure 6 shows an example set of classification rules that compose HMAC classifier.

D. Classification In classifying an unseen data obj, shown in Figure 7, obj is  compared with the rule-sets in classifiers from top to bottom.

If it matches a rpci without any RNC, then the RPC classifies it (line 7). If the matching rpci has RNC, we examine each rules in RNC and attempt to match each of them (line 5). If RNC does not match the obj, then the RPC classifies it (line 6). Otherwise, if prediction is cannot be made, we move on to the next rule-set and repeat the process (line 8). If prediction is cannot be made, then default class-set is predicted (line 9-10).



IV. EVALUATION MEASURES A. Traditional similarity measures  In order to evaluate our task of hierarchical multi-label classification, keep in mind that the system predicts not a single class but several classes containing in the class-set.

Fig. 5. HMAC classifier builder algorithm for selecting rules based on database coverage  Fig. 6. An example for HMAC classifier. RPC are ordered by Sim.

RNC filter the exceptional cases for the following RPC, and as a result the RPC makes more accurate predictions.

These classes are related to each other by the relation given in the considered hierarchy. Indeed, within the given hierarchy, a class corresponds to a node and a class-set corresponds to a node collection. Thus evaluation measure could be built upon the similarity between the predicted nodes collection and the actual nodes collection. Some traditional set similarity measures like F-measure or Jaccard?s coefficient could be then  Fig. 7. Classifying a test instance is compared with the rule-set that have a rule of positive class-set rpci and many rules of negative class- set RNC for a set of rule.

??    used.

1) F-measure: is a common evaluation measure in informa-  tion retrieval task. It is indeed the harmonic mean of precision and recall. Precision is the fraction of predicted nodes that are actual nodes while recall is the fraction of actual nodes which are predicted. This measure can be extended to take into account hierarchical structure by considering ancestor nodes of both predicted and actual nodes. Let A = (a1, a2, ..., am) and P = (p1, p2, ..., pn) be the actual node collection and the predicted node collection respectively. We shall denote by AncA and AncP the set of ancestor nodes of A and P respectively. Using this notation, the normal F-measure (FM(A,P )) and the modified F-measure (FMAnc(A,P )) are defined by  FM(A,P ) = 2 |A ? P |  |A| + |P | (1)  FMAnc(A,P ) = 2 |AncK ? AncP |  |AncK | + |AncP | (2)  Note that after some calculation FMAnc(A,P ) is exactly the same as Dice?s coefficient [21].

2) Jaccard?s coefficient: Another measure of set similarity is Jaccard?s coefficient (Jaccard), that is given by  Jaccard(AncA, AncP ) = |AncA ? AncP |  |AncA ? AncP | (3)  B. Our similarity measure One may expect the FMAnc(A,P ) or  Jaccard(AncA, AncP ) to be suitable for evaluate our hierarchical multi-label classification problem. However, by further analyzing, we can see that these 2 measures fail to distinguished between predicted node collections if they both contain nodes on the same path. For example, in Figure 8 FM(AncA, AncP1) = FM(AncA, AncP2) = 0.89 and Jaccard(AncA, AncP1) = Jaccard(AncA, AncP2) = 0.80. The normal F-measure does not suffer from this problem since it focuses on exact match between nodes in collections. Hence, we propose a new similarity measure, Sim(A,P ), to estimate the accuracy of classifier to predict the hierarchical classification. Our evaluation measure is based on a similarity measurement that trades off between exact match and the relational between nodes in hierarchical structure. Jaccardw(AncA, AncP ) and Sim(A,P ) are computed by  Jaccardw(AncA, AncP ) =  ? ?i?(AncA?AncP )  wi? ?j?(AncA?AncP )  wj  (4)  Sim(A,P ) = ??FM(A,P ) + (1 ? ?)?Jaccardw(AncA, AncP ) (5)  where 0 ? ? ? 1. Thus, in Figure 8, let ? = 0.50 and ?wi = ?wj = 1, then Sim(A,P1) = 0.735 and Sim(A,P2) = 0.65.

In this paper, the weight of nodes involving in the calcula- tion of weighted Jaccard?s coefficient (Equation (4)) is com-  Fig. 8. Graph a), b) and c) in an ontology graph, let A = {c3, c4, c6, c8, c9} be an actual node collection and AncA = {c0, c1, c2, c3, c4, c5, c6, c7, c8, c9} be an ancestor node of A. Next, P1 = {c2, c3, c4, c9} and P2 = {c2, c3, c9} be a predicted node collection of P1 and P2, respectively. AncP1 = AncP2 = {c0, c1, c2, c3, c4, c5, c7, c9} be an ancestor node of P1 and P2.

puted as function of its information content. The information content of a node c, IC(c), is defined by IC(c) = ?log[P (c)] where P(c) corresponds to the occurrence probability of c or one of its directly or indirectly subsumed concepts [22].



V. EXPERIMENTAL RESULTS  The dataset containing 15,088 protein sequences, 1,353 PROSITE motifs and 849 molecular functions were down- loaded from the PROSITE database (release 20.22, of November 14, 2007), ftp://au.expasy.org/databases/prosite/, and the Gene Ontology Annotation (GOA) database from http://archive.geneontology.org/latest-lite/ in November 19, 2007. Experiments were conducted using stratified 5-fold cross validation [23].

Following is the list of parameters together with their values used in respectively rule generation and pruning steps. For rule generation step: support(%): 12, 14, 16, 18, 20; confidence: 50.

For rule pruning step: Pearson?s correlation coefficient: 0.5; alpha(?): 0.5. Table I shows experimental results on different ranking methods with respect to different support values.

Experimental results show a significant improvement of the HMAC rule ranking method (p < 0.01) over six rule ranking methods which are (conf (CBA), conf (MMAC), FM, Jiang & Conrath?s Dist, Lin?s Sim and Resnik?s Sim. Conf (CBA) and conf (MMAC) are based on respectively CBA and MMAC.

Resnik?s Sim [24], Jiang & Conrath?s Dist [25] and Lin?s Sim [26] are the measures used in Gene Ontology evaluation.

Moreover, the proposed rule ranking method has a significant improvement (p < 0.05) over Jaccard rule ranking method at 16% and 18% minimum support thresholds. HMAC rule ranking method gives the best results (in bold) in improving the predictive power of the resulting classifiers.

Table II shows the robustness of the alpha parameter (?) over the accuracy of HMAC. We observe no significant dif- ference for various values of alpha (?) parameter. Thus, the proposed Sim(A, P) in Equation 5 is simply measure to utilize.

?4    TABLE I IMPACT OF THE TEN RULE RANKING METHOD ON THE ACCURACY OF  HMAC ALGORITHM  Supp. (%) Ranking Method  12 14 16 18 20 HMAC 45.17 43.25 41.38 39.96 39.75  JaccardIC 44.04 42.39 40.51? 38.89? 38.97 Jaccard 44.15 42.28 40.71 39.12 38.99 FMAnc 44.15 42.28 40.71 39.12 38.99  FM 37.66?? 36.43?? 35.18?? 33.84?? 32.32?? conf(CBA) 38.18?? 35.10?? 34.47?? 33.35?? 33.47??  conf(MMAC) 37.56?? 35.66?? 35.15?? 33.19?? 28.65?? Resnik?s Sim 35.53?? 33.73?? 32.60?? 31.59?? 31.76??  Lin?s Sim 37.59?? 36.47?? 35.14?? 3.83?? 32.32?? Jiang&Conrath?s 37.57?? 36.46?? 35.15?? 33.83?? 32.32??  Dist 1** 0.01 significant level 2* 0.05 significant level  TABLE II IMPACT OF THE ALPHA PARAMETER (?) ON THE ACCURACY OF HMAC  ALGORITHM  ? 0.0 0.2 0.4 0.6 0.8 1.0 accuracy (%) 45.13 45.15 45.16 45.18 45.19 45.21

VI. CONCLUSIONS AND FUTURE WORKS  In this paper, HMAC method can improve accuracy and explanatory ability of rule-based classifier using multiple and negative rules. HMAC has the following features over other existing associative classification techniques:  ? Negative redundant rule pruning: We extend pruning negative redundant rule in complex form that can improve explanatory ability of complex data in real world.

? Appropriate rule ranking method for hierarchical associa- tive classification: HMAC rule ranking uses combination of two scoring methods: (1) FM , (2) Jaccard. Moreover, the experimental results show that HMAC can improve the predictive power of the resulting classifiers.

? Robust rule evaluation measure for hierarchical classi- fication: Sim evaluation measure is a tread-off between F-measure and Jaccard. Experimental results show that Sim is a robust evaluation measure bounded [0, 1].

In our future work, we are going to improve explanatory ability of HMAC by proposing a better representation of classification rules.

