Discovery of Association Rules in Tabular Data

Abstract  In this paper we address the problem of finding all association rules in tabular data. An Algorithm, ARA, for finding rules, that satisfy clearly specified constraints, in tabular data is presented. ARA is based on the Dense Miner algorithm but includes an additional constraint and an improved method of calculating support. ARA is tested and compared with our implementation of Dense Miner; it is concluded that ARA is usually more eflcient than Dense Miner and is often considerably more so.

We also consider the potential for  modifying the constraints used in ARA in order to find more general rules.

(weight c height2) A (colour = green v colour = red) a wheels > 6 v (Engine # diesel).

We refer to rules of this type as ?general association rules? or simply as ?rules?. The problem with generalisation is that the search space is often very large.

In order to limit the search space constraints may be imposed on rules.

mb-rules in tabular data may be defined by constraining general association rules so that the antecedent and consequent are conjunctions of attribute tests (ATs) where each AT is an equality test of the form ?attribute = value? and ATs can be formed for each attribute / value pair. ATs are then synonymous with items in mb-rules. An example of this type of rule is:  1. Introduction model = sports A colour = red risk = high.

The problem of mining association rules was introduced by Agrawal et al. in 1993 [l] in the context of the analysis of transaction data (often referred to as market basket data). A transaction database comprises a set of transactions where each transaction comprises a set of items. The set ofall items in the database is U.

Association rules were presented as expressions of the form antecedent a consequent where antecedent c U , consequent c U and antecedent n consequent = @ , they express an association between the antecedent and consequent. We refer to rules of this type as ?market basket association rules? or mb-rules.

Several algorithms have been developed to find mb- rules in transaction data. The most well known of these is Apriori [2], others include AIS [3] and SETM [4].

However, association rules can be considered to be much more general, particularly when applied to tabular data. A tabular database comprises a set of records. A record specifies values for each attribute in a set of attributes.

The antecedent and consequent may each then describe any subset of records in a database. They could, for example, include feature constructions, conjunctions, disjunctions, negations, equality and inequality tests etc.

An example of a general association rule is;  When mb-rules are expressed in this format the constraints are clearly defined and it is also clear how they can be modified. The consequences of this are discussed further in section 3.

Algorithm ARA (All Rules Algorithm), for finding mb-rules in tabular data is presented in section 2.

Section 2.9 describes the evaluation of ARA. The final section describes ways in which ARA may be developed.

2. All Rules Algorithm  ARA is based on Dense Miner [5  and 61 but applies directly to tabular data, includes additional pruning functions and collects more support information to enable the calculation of tighter bounds for pruning. Dense Miner is described in greater detail in [5] and ARA in [7].

2.1. Notation  The antecedent of a rule, r, is designated r - c where c is the consequent of the rule.

Operations on conjunctions of ATs A M  and A P are defined in terms of the equivalent operations on the associated sets of ATs M and P as follows.

0-7695-1119-8/01 $17.00 0 2001 IEEE 465  mailto:uea.ac.uk mailto:sys.uea.ac.uk   A rule, r', is a subrule of a rule, r, if the consequents of the two rules are identical, c, and r'- c c r - c .

The support of a conjunction of ATs or a single AT, M ,  sup(M ) , is the number of records in the database for which M holds.

2.2. Constraints  The constraints imposed by ARA are described below.

2.2.1. Rule Structure Constraints. U is the set of all ATs that can be formed from attribute / value pairs in the database.

Consequent constraint: A single AT, c, from U is designated as the consequent for all rules in a single search. This reduces considerably the number of valid rules. The justification for incorporating the consequent constraint is that often there is a single target class of interest.

Antecedent Constraint: I' is the subset of ATs in U with the same attribute as the consequent. I = U - I'.

The antecedent of a rule is a conjunction of ATs drawn from I .

MaxATs Constraint: A user-defined value, maxATs, sets the maximum number of ATs that can be used in the antecedent of a rule. Introducing this constraint can considerably reduce the search space and also improve the bounds used for pruning. The justification for using it is that, when the rules are required for gaining insight into data, shorter rules are generally preferable.

2.2.2. Rule Value Constraints. Three parameters, minSup, minConf and minlmp, are specified by the user.

Support constraint: The support for a rule, r, sup(r) ,  is defined as sup(r-c A c). Rule r satisfies the support constraint iff sup(r) 2 min Sup . This constraint ensures that rules have generality.

Confidence constraint: The confidence of a rule, r,  conf(r),  is defined as sup(r) . Rule r satisfies the  confidence constraint iff conf(r) 2 min Conf . This constraint ensures the predictive value of rules.

Improvement constraint: The improvement of a rule, r, imp(r ) ,  was introduced in [ 5 ]  and is defined as conf(r)-conf(r'),  where r' is the subrule of r with the greatest confidence.

sup(' - c )  Rule r satisfies the improvement constraint iff imp(r) h minlmp . This constraint ensures that all ATs in a rule add significantly to its value.

2.3. Search Strategy  Dense Miner and ARA are constraint based searches.

The search space of rules is explored by use of a set enumeration tree (SE-Tree) as described in [SI.

Each node in the SE-Tree is represented by a structure called a group. A group, g, has a headH(g)and a tail  The head is a conjunction of ATs that represents the antecedent of a rule. The tail is a set of ATs that can be added to the head to form a new antecedent. A total order, 2 is defined on the tail ATs of a group, g. In practice the  tail ATs are stored in a vector that is sorted according to the ordering.

The head and tail of the group at the root of the SE- Tree are H(roor) = @ and T(root) = I ,  where I is defined in section 2.2.1.

A group, g, is expanded to create a set of groups in the next level of the SE-Tree by producing one child for each of the ATs in T ( g )  .

For each child, h, of group, g, H ( h )  is a conjunction of the head of the parent and a single AT, v, from the tail of the parent. T(h)  consists of each of the tail ATs in g that follow v in the ordering.

T ( g ) ,  g = H ( g ) I T ( g ) .

~ ( h ) =  H ( ~ ) A  v for some v~ T ( g ) and then T(h)=  {wl W E  T ( g )  and w >8 v }.

Tail ordering determines the order of expansion of groups. It thus leads to more effective pruning by concentrating unpromising groups in one part of the tree.

Tail ordering is carried out within each group by sorting the tail vector of ATs according to some heuristic; it is discussed in more detail in section 2.8.

Figure 2- 1 shows an SE-Tree for the set of ATs {A, B, C ) ,  the ordering of tail ATs is indicated by their positions in the tails. An arbitrary reordering of the tail ATs has been carried out at each level to demonstrate that the completeness of the tree is not compromised but no pruning is carried out, i.e. the tree is complete. It can be seen that the antecedent of every possible rule that can be constructed from the ATs is enumerated in the heads of the groups.

A group, h, is derivable from a group, g, iff  i.e. a group is derivable from itself. g is an ancestor of h iff h is derivable from g.

fI(h)A(AT(h))E H ( g ) A  ( A m )  and H ( d c  H ( h )     A rule, r, is derivable from a group, g, iff r - c E  H ( g ) A ( A T ( g ) )  and H ( g ) c r - c .

C I ?3 I ( A )  \ BAAI~J  n CAA I(B) CAB I $I  I CAAABI~J  Figure 2-1. SE-Tree for the set {A, B, C}.

2.4. Top level of algorithm  Database D group root c create-rootsroup(D) set of groups G t ( root ] set of rules R t $I while (G f Cp and headkngth < maxATs )  Gctail-sort( G) G +evaluate(G, D ) Rcextract-rules(G, R) G +prune((;) G +split( G) G +prune(C)  R t p o s t j r o c e s s  (R,  0)  Figure 2-2. Top Level of Algorithm  The algorithm enumerates the antecedents of all rules that potentially satisfy the constraints by expanding an SE-Tree. The create-root_group function creates the group at the root of the SE-Tree as described in section 2.3. A set of groups, G, is defined; initially this comprises the single group, root. The set of rules, R,  is used to return the set of all rules that satisfy the constraints.

The main loop of the algorithm executes until either all groups have been pruned from G or the maximum length of antecedent has been reached.

The order of the ATs in the tails of each group in G are redefined using the tail-sort function before G is evaluated. The necessity for ordering before evaluation is described in section 2.5.

The evaluate function collects support information for each group in G for the purpose of calculating rule support and confidence and for use in the pruning function. The function, extract-rules, adds rules that potentially satisfy the constraints to R .

The split function takes the set of groups, G, and expands each g E G as described in section 2.3, the children of g replace g in G, forming the next level of the SE-Tree. The prune function is applied both before and after the split function. It removes some groups from G and is described in section 2.7.

The posrgrocess function removes any rules that do not satisfy the constraints from R. It is the same as described in [ 5 ]  and is not repeated here.

2.5. Evaluate Function  A candidate set of conjunctions is defined for each group. The evaluation function computes the support for each of the conjunctions in the candidate set of each group in G. A group is described as an evaluated group when the supports for all the conjunctions in its candidate set have been computed.

The candidate set used in Dense Miner for each group, g, is:  H(g)and H ( g ) A c ,  and,foreach t ~ T ( g ) ,  H ( g ) A t  and H ( g ) A t h c .

H k ) A  ( A m )  and H ( g ) A  (A T ( d ) A  c 9  The candidate set used in ARA is: H(g)and H ( g ) A c ,  .

andforeach t~ T ( g ) ,  H ( g ) A r ,  H ( g ) A t A c and H(g)A(A{wlweT(g)andw2 t })A-c.

Thus, ARA collects more support information for each group. This requires additional time to collect and more storage but means that tighter bounds can be calculated for use in the pruning functions, as described in section 2.7. Also note that 2 must be defined before g is  evaluated.

Each group has a counter associated with each  conjunction in its candidate set. As in Dense Miner, each record is considered in turn. A trie is used to find all groups in C for which the antecedent of the rule represented by the head of a group holds for the record.

For each group, g, that is found, the counter for H(g)is incremented and, if the conclusion holds for the record, the counter for H ( g ) ~ c  is incremented. Then, for each group that is found, the tail ATs are considered in reverse order. If a tail AT, I ,  holds for the record then the counter for H ( g ) A  t is incremented, if the conclusion also holds for the record then the counter f o r H ( g ) ~ t ~ c  is incremented, if the conclusion does not hold for the record and every previously considered AT in T ( g )  held for the record then the counter associated with      H(g)A (A {wIW E T ( g )  and w 2 f})A l c is incremented.

Thus, after considering all of the records in the database, the supports for all of the conjunctions in the candidate sets of each of the groups in G have been computed. The purpose of collecting this support information is to maximise the pruning opportunities, as described in section 2.7.

2.6. Extract Function  Extract-rules extracts, from the set of evaluated groups, rules that can potentially satisfy the constraints; these rules are added to the set of rules, R .  For each g E G the rules that are considered are  A rule can potentially satisfy the constraints and is H(g)At C v t ?  T ( g ) .

added to R iff  AND sup(H(g)A  t c)= sup(H(g)A  t A c) 2 min sup  conf (H(g)At  c)= suP(H(g)A  t A 4 2 Conf sup@ (g )A t )  AND c o n f ( H ( g ) A t  3 c ) - C m a x ( g )  2 minlmp ,  where Cmax(g)  is the maximum confidence of any rule represented by the head of an ancestor of g or g itself.

The minlmp constraint is fully enforced in the post processing stage, as described in [SI.

2.7. Prune Function  The pruning function is applied to a set of groups after evaluation and after a new level of the SE-Tree has been created.

A group, g, is said to be pruneable if i t  can be determined that no rule derivable from g can satisfy the constraints. If g is pruneable and is a member of G then g can be removed from G. If a group, g, is not pruneable it may be possible to remove some ATs from its tail. A new group, g', can be formed from g by moving a single AT, v, from the tail into the head. If g' is pruneable then no rule derivable from g that includes v can satisfy the constraints and v can be removed from the tail of g. If some ATs are removed from the tail of g then tighter bounds for pruning can be achieved. Therefore, the pruning function is re- applied until either the whole group is pruned or no tail ATs are removed.

2.7.1 Pruning based on support. If sup(H(g ) A c) < min Sup then no rule derivable from g can meet the minSup constraint and g is pruneable. The  value, s u p ( H ( g ) A  c ) ,  is available from the candidate set of g', where g' is the last evaluated ancestor of g.

2.7.2 Pruning based on confidence. Let r be the rule with maximum confidence that is derivable from a group, g. The maximum confidence of any rule derivable from g is max Conf(g) = conf(r ) .  If max Conf(g) < min Conf then g is pruneable.

maxConf(g)  can be expressed as maxConf(g)=- X +  Y  where x = sup(r) and y = sup(' - c)- sup(r) .

maxConf(g)  is monotonically increasing in x and monotonically decreasing in y. Therefore, x may be replaced with an upper bound x' and y with a lower bound  X  X' y', then maxConf(g)<-  .

x'+y' When attempting to prune an evaluated group Dense  Miner uses the bounds x'= s u p ( H ( g ) A  c) and y'= y,  where y, = sup(H(g)A ( A T ( g ) ) A l c ) .  ARA, however, uses the maxATs constraint. It is then possible to calculate another lower bound on y, y2.

Lemma I y2 is a lower bound on y = sup(' - c)- sup(r) where y2 = sup(H(g) A 1c ) -  sup(H(g) A -d A 7c),  where S comprises the n tail ATs, t ,  of T ( g )  with the highest values of sup(H(g)A A TC) and n = min(rnaxATs - I H ( g l , l T ( g ] ) .

The proof is initially given for the general case y, I sup(u - c)- sup(u) where U is any rule derivable from a group, g, as this is required for improvement pruning, and then for the particular case y2 I sup(' - c)- sup(r) .

I? s  Proof  Rule, U, may be written as, H ( g ) r \  M a conjunction of ATs from T ( g ) , Then,  c , where M is  sup(u - c)- sup(u) = S U p ( H ( g ) A  M ) -  SUp(H(g)A M A C) = S U p ( f f ( g ) A  M A i C ) = s U p ( H ( g ) A  1C)- sUp(H(g)A i M  A IC)  NOW, M =(m,  A m ,  A . . . A m , , )  and 4 4  =,(rn, A m 2  A . . . A ~ , , )  =(-lm, v l m 2  v . . . v l m , , )     Since sup(u v b)= sup(u)+ sup@)- sup(a ~ b )  it follows that I sup(a)+ sup(b)  x S U p ( H ( g ) A - I ? A - I C )  >SUp(H(g)A&f A-IC) l?M  In the presence of maxATs, lMll min(m,ATs-(H(gl,lT(gI)=n =IS1  Given that S comprises the n tail ATs with the highest values of s u p ( H ( g ) A l r ~ - I c )  and ISI2IMI it follows that  x s u P ( H ( g ) A l  r A1 c)  2 x s u p  (&)AT ? A y  c) 1E s l ?M  Therefore, SUp(f f (g)A ' C ) - x S U p ( H ( g ) A  -I I A -I C)  I? s I S U p ( H ( g ) A  -IC)- SUp(H(g)A 4 A -IC)  Hence, SUp(H(g)A -IC)- x SUp(H(g)A i t A -I C)  l?S  I sup(u - c ) -  sup(u) and y, I sup(u - c)- sup(u).

Therefore, since r is a rule derivable from g, y2 2 sup(r - c)-  sup(.) = y .

When attempting to prune an evaluated group the supports are available to calculate x' and both y1 and y2; y' may then be set to max{y,, y2) for use in the pruning function. However, when considering a group, g, that is not evaluated it may not be possible to calculate x'or y1 or y2. Then, since x'is an upper bound, it may be set to s u p ( H ( h ) ~  c),  where h is the last ancestor of g to have this value available in its candidate set, since sup(H (h) A C )  5 sup(H(g  ) A c). It is also possible to calculate values y; and y; such that y; I y,and y', I y,. The values yl and y2 are lower bounds on y, therefore, so are y; and y; and so y' may be set to  When y1 cannot be calculated, Dense Miner calculates m ~ b : l Y ; l .

SUPb (g )A (A T ( g  A -4 y: = max s U p ( H ( g ) A i C ) -  tsTf8'0 x S U p ( f f ( g ' ) A - I f A i C j  where g is the. parent of g in the SE-Tree. Both of these values are less than or equal to yl and can be  calculated from the supports of the conjunctions in the candidate set of g .

ARA, with its larger candidate set, can often find a higher value for yi and also a value for y; .

Let g be a group that is derived from an evaluated group g'. Two cases are considered; case 1, when H (g) = H ( g ' )  i.e. some ATs have been removed from the tail of  g' to create g, and case 2, when H ( g )  = H ( ~ ' ) A  v  where v is a single AT from T ( g ' ) ,  i.e. g is either a group created for the purpose of tail pruning or g is in the next level of the SE-Tree from g'.

Case1, H ( g )  = H ( g ' ) .

y, = SUp(H(g)A (A T(g))A ,c) then ARA calculates y ;=sup(H(g ' )~(A{w I wcT(g')and "5. ~ ] A ~ c ) , where p is the minimal AT in T(g)under the ordering 2 . Provided that the ordering of g is the same as g' yi is less than or equal to yI .  The issue of tail ordering, and how the ordering can be maintained, is discussed in section 2.8.

sup(H(g')A(/\{wI w ~ T ( g ' ) a n d w >  r]Alc) is  If the supports are not available to calculate  8'  available for every t E T ( g ) ,  since these conjuncts are members of the candidate set of g', and is therefore available for the minimal AT, p.

y, = sup(Hfg) A -IC)- C sup(H(g) A -It A Tc)  are available from the candidate set of H ( g ' ) ,  since H ( g )  The supports necessary to calculate  rs S  = H ( g ' ) .

case 2. H ( g )  = ~ ( g ' ) r \  v .

yI = sup(H(g)r\  (A T ( g ) ) A - - c ) .  Then ARA calculates y; = sup(H(g' )A (A {w I W E  T(g' )and w r ,  U ]A -IC) where U is the minimal AT in T(g)u{v} under the ordering 2 . y; is less than or equal to yl (provided that the ordering of g is the same as g').

sup(H(g')A(A{wI weT(g ' )andw2 ~ t j ~ ~ c )  is  available for every t E T(g)u {v}, since these conjuncts are members of the candidate set of g', and is therefore available for the AT, U.

Again it may not be possible to calculate     It may also not be possible to calculate y2 = sup(H(g) A 7c)-  c sup(H(g) A -d A l c ) .

However, sup(H(g) A -c) = sup(H(g ' ) A  v A 7 c )  and for every t E T ( g ' )  Therefore,  I? s  sup(H(g')r\  l t  A 1 c ) Z  s u p ( H ( g ) A  -.lt A ~ c ) .

sup(H(g ' ) A v A 1c)-  c sup(H(g ' ) A l f  A l c ) I sup(H(g) A 1c ) -  c sup(H(g) A -d A -c)= y2  where S' consists of the IS1 tail ATs of g with the maximum values of sup(H(g ' )A  -d A l c ) .  ARA therefore calculates  t? S'  I? s  The support values necessary to calculate yi are available from the candidate set of g'.

2.7.3 Pruning based on improvement. Let r be the rule derivable from a group, g, with the maximum improvement. Then imp(r)= maxImp(g) .  If maxlmp ( g )  I minlmp then g is pruneable.

In order to find an upper bound on maxImp(g)  the same methods as Dense Miner are used. However, because the value of y' calculated for confidence pruning is re-used and may be higher in ARA than in Dense Miner, the upper bound on maxImp(g) may be lower.

The methods are presented below without proofs. These can be found in [51 or [71.

Method 1. maxZmp(g) I maxConf (g ) -  conf(r') where r' is the highest confidence rule enumerated in any ancestor group of g.

X' X' Method 2. maxlmp ( g )  I - - x'+y '  x ' + y ' + / l '  where  x '  = rnaxkin sup, rnin(sup(H(g)r\ c), J-)), y' is defined above and B' I sup((H(g)-  Z)A lz A lc) where z is the AT in H ( g )  that minimises this expression.

In order to be used in improvement pruning, y' must be a lower bound on sup('- c)- sup(.) where r is the rule derivable from g with the maximum improvement. It was shown in lemma 1 that y ' l  sup(u - c)- sup(u) where U is any rule derivable from g. Therefore, y '  is a lower bound on sup(r - c ) -  s u p ( r ) .

Example of pruning. Let A I {B,C, D, E,  F , G ,  H }  be an evaluated group, g'. Assume that g' is not pruneable, therefore try to remove some tail ATs. To do this we form a group, g'= A A B I {C, D,  E, F , G ,  H } .  It is found that no rule derivable from g' can satisfy the constraints, i.e. g' is pruneable, and so B can be removed from the tail of g'.

After considering each of the tail ATs in the same way it is found that ATs B and D may be removed from the tail of g'. We form a new group, g ,  = A I { c , E , F , G , H } , which replaces g' in the SE-Tree. Now, because some ATs have been removed from the tail and tighter bounds may be available for y an attempt is made to prune g,.

When attempting to prune gl (and when attempting to prune ATs from the tail of gl) ARA will use the value sup(^ A c A D A E A F A G A H A ,c) as a value for  y; I y,   sup(^ A c A E A F A G A H A ~ C ) which is potentially higher than sup(A A B A C A D A E A F A G A H A 7 c )  as used in Dense Miner. Also, y2 is greater than or equal to the other value used in Dense Miner,  Assume it is found that g, is not pruneable and no ATs can be removed from its tail. A new set of groups in the next level of the SE-Tree are created which replace gl .

Amongst these is the group h = A A F I {G, H } .  Now, in determining if h is pruneable ARA has available and will use y,  = sup(A A F A G A H A l c ) .  Dense Miner will use s u p ( A ~  B A  C A D A  E A F A G  A H A ~ c ) ,  which is likely to be lower. Again yz  is greater than or equal to the other value used in Dense Miner, sup(H(g)A  1c ) -  c s u p ( H ( g  )A 1 1  A 7 c ) .

This example shows how tighter bounds can be achieved for pruning using the additional support information collected by ARA. If the maxATs constraint is specified even tighter bounds can be achieved.

IS Tfx)  2.8. Tail ordering  As described in [ 5 ]  tail ordering is essential for efficient algorithm performance. ARA requires that the tail of a group, g, is ordered before evaluation and the order maintained in groups derived from g until pruning is complete. Therefore, the vector of tail ATs is sorted before a group is evaluated. The ordering used to sort the vector of tail ATs of a group, g, is descending value of sup(H(g ' )h l t  A 7c)where g' is the last evaluated ancestor of g. An initial evaluation is carried out as the basis for sorting the tail of the root group. For clarity this has not been shown in Figure 2-2.

2.9. Results  ARA was evaluated on two databases; the connect 4 database [9] and a census database [IO]. Due to limitations of space only the results of the connect 4 tests are reported here. The results achieved using the census data base were similar and are presented in [7]. Connect 4 has 65,577 records and 42 predictive attributes each of which is categorical with 3 possible values, the consequent was defined as ?result = draw? of which there are 6,449 records.

The algorithm was evaluated according to the following measures.

Execution Time. Times are for the search phase only, post processing time is not included.

Number of groups evaluated. This represents the size of the search tree.

Number of tail ATs evaluated. This is required because a small number of groups with large tails may be more time consuming to evaluate than a large number of groups with small tails.

In order to compare ARA with Dense Miner a version of Dense Miner was implemented in accordance with the description given in [ 5 ] ,  this version of Dense Miner is referred to as ARA-Dense. ARA-Dense is identical to ARA in all respects except for the support information collected and the pruning functions; any variation in performance can thus be attributed to these differences alone. The execution times for ARA-Dense were compared with the times for Dense Miner reported in [5] and found to be slower by a factor of 1.5 - 1.8. This variation may be attributable to hardware or compiler differences or the detail of implementation.

All tests were carried out on a Dell Dimension XPS PI11 450 with 128MB memory.

1 .

2.

3.

2.10. Commentary on test results  When rninConf was set to zero it  was found that there was no significant difference in the execution times of the two algorithms over a wide range of tests; indicating that the advantage of a smaller search tree was offset by the overhead for collecting more information. Figure 2.1 shows the effect of using confidence for pruning by varying the values specified for rninConf. The size of tree searched by ARA was smaller than ARA-Dense by a factor of 1.2 to 2.5, the higher the setting of rninConf the greater the reduction in tree size. The number of tail items evaluated varied by a similar order. Execution time also varied in proportion to the size of the search tree; indicating that the overhead for collecting the additional support information was outweighed by the benefit of a smaller tree when confidence was used for pruning.

The second set of tests, reported in figure 2.2, shows the effect of introducing the rnuxATs Constraint.

In order to demonstrate the effect of the maxATs constraint a further algorithm, ARA-Part was implemented. This is identical to ARA but does not include the additional pruning functionality based on the maxATs constraint.

ARA-Dense and ARA-Part simply stop searching when the number of ATs in the consequent of extracted rules is equal to maxATs. The improvement of ARA-Part over ARA-Dense is thus attributable to the additional support information collected. The improvement of ARA over ARA-Part is attributable to the additional pruning using the d T s  constraint.

When muxATs is lower than 11 (the maximum antecedent length of any rule that satisfies the other constraints) there are considerable benefits to using the constraint. For example, with muxATs set to 6 the execution times for ARA and ARA-Part were 149 and 493 seconds respectively; a saving of over 5 minutes. The time for ARA-Dense was 818 seconds which is over 5 times or 11 minutes longer.

It is concluded that when minConf is specified ARA generally outperforms ARA-Dense. When the d T s constraint is specified further significant gains in performance can be achieved.

3. Future Work  An attribute test in ARA is a 3 tuple [attribute, operator, value] where operator is ?=?. However, it is straightforward to construct ATs with different operators.

For example an AT could be ?age c 50? or ??colour # red? allowing a richer variety of rules to be constructed.

A problem with increasing the variety of ATs is that the search space and the number of discovered rules may be vastly increased. To counteract this, additional constraints may be necessary. However, these could be problem specific rather than algorithm specific. For example, one possible constraint is to define which ATs (or combinations of ATs) are of interest (or conversely which are not of interest) before the search is undertaken.

As a result some generality of the search will be lost but the search can be targeted at areas of interest, thus making the problem more tractable and avoiding rules that are not likely to be interesting.

One of the problems of finding all rules is specifying suitable values for rninCov and rninConf. In this research we have experimented with the use of the heuristic search techniques in the DataLamp package developed by the University of East Anglia and the Lanner Group [ l l ] .

DataLamp has been used to find a good rule according to its fitness function, then ARA used to find all rules with coverage and confidence greater than that rule.

47 1    04 I  250,000 - B 200.000 -  & 100,000 - n 5 50,000 - A .. z  UY 150,000 - - /-. * -4? f/ ,*?  07 &-? 20 30 40 50 60  minConf (%)  I  7,000,000  ui 6,000,000 I-  4.000.000 c,j 3,500,000 - 2 3,000,000 - Z 2,500.000 - /  /  - c  5 2,000.000 - 7 --+ -0 & 1,500,000 -  2 500,000 - /* ,* n E i,ooo,ooo - L- ,*  0 7  1 4 O C  I 20 30 40 50 60  minConf (%)  I  . 2,500 h  0 g 2,000  g 1,000  Y  E 1.500 .- c .- e 8 500 m,  * - * .

- *  maxATs = 42 (all), minSup=65, minlmp=0.02%.

Figure 2-1 Varying minConf  4. References [ 11 Agrawal R, Imielinski T, Swami A. Mining association rules between sets of items in large databases. Proceedings of the Data, May 1993, pp 207 - 216. ACM Press, 1993.

[2] Agrawal R, Srikant R. Fast Algorithms for Mining Association Rules. Proceedings of the 20th International Conference on VLDB, September 1994, pp 487 - 499, Morgan  [3] Agrawal R, Imielinski T, Swami A. Mining association rules between sets of items in large databases. Proceedings of the Data, May 1993, pp 207 - 216. ACM Press, 1993.

[4] Houtsma M, Swami A. Set Oriented Mining of Association Rules in Relational Databases. Proceedings of the Eleventh  [5] Bayardo R, Agrawal R, Gunopulos D. Constraint-Based Rule Mining in Large, Dense Databases. Proc. of the 15th  ? Kaufmann, 1994.

25 - 33. IEEE, 1995.

1,400 7  minSup = 65, minConf = 40%, minlmp = 0.02%.

Figure 2-2 Varying maxATs  International Con$ on Data Engineering, March 1999, pp 188 - 197. IEEE, 1999.

[6] Bayardo R, Agrawal R. Mining the Most Interesting Rules.

Discovery and Data Mining, (KDD 99), August 1999, pp 145 - 153. AAA1 Press, 1999.

[7] Richards G. Mining All Rules. University of East Anglia Technical report. SY S-COO- 10.

[8] Rymon R. Search Through Systematic Set Enumeration.

of Knowledge Representation and Reasoning, (KR 92), October 1992, pp 539 - 550. Morgan Kaufmann, 1992.

