A Personalized Association Rule Ranking Method Based on Semantic Similarity And Evolutionary Computation

Abstract? Many methods have been studied for mining asso- ciation rules efficiently. However, because these methods usually generate a large number of rules, it is still a heavy burden for the users to find the most interesting ones. In this paper, we propose a novel method for finding what the user is interested in by assigning several keywords, like searching documents on the WWW by search engines. We build an ontology to describe the concepts and relationships in the research domain and mine association rules by Genetic Network Programming from the database where the attributes are concepts in ontology.

By considering both the semantic similarity between the rules and the keywords, and the statistical information like support, confidence, chi-squared value, we could rank the rules by a new method named RuleRank, where genetic algorithm is applied to adjust the parameters and the optimal ranking model is built for the user. Experiments show that our approach is effective for the users to find what they want.



I. INTRODUCTION  ASSOCIATION rule mining has been a popular researchtopic for more than 10 years and various methods have been proposed for mining association rules efficiently [1] [2] [3] [4] [5] [6] [7] [8]. However, most of the existing methods are focusing the efficiency, but not enough effectiveness.

Usually, we could find thousands of, or even more, asso- ciation rules by these methods, and there is a new challenge presented before us: how could we choose what we need?

Some researchers have tried many new approaches to overcome the above problem by discovering significant pat- terns [9], evaluating the novelty of rules [10], extracting redundancy-aware top-k patterns [11], analyzing rule inter- estingness using OLAP operations [12], or selecting right interestingness measures [13]. Unfortunately, most of these methods rely on statistical measurements, and seldom con- sider the semantic knowledge behind the statistical numerals.

In the recent research [14], Mei et al. interpret the discovered frequent patterns by generating semantic annotations with a context model, which mimics the structurized entities with semantic information in dictionary. Our research is a little analogous to the research in [14] in the aspect of motivation, but the pathway is completely different.

In this paper, by borrowing the style of search engines, we propose a novel method to rank the association rules for a person by inputting several interested keywords. We measure the interestingness not only by statistical information but also by semantic relations between rules and keywords. First of  The authors are with Graduate School of Information, Produc- tion and Systems, Waseda University, Hibikino 2-7, Wakamatsu-ku, Kitakyushu, Fukuoka, 808-0135, Japan (email: {yang@fuji.waseda.jp, k.shimada@aoni.waseda.jp, mabu@aoni.waseda.jp, hirasawa@waseda.jp).

all, we?d like to discuss more about the critical ideas of interestingness.

Which rule is interesting? Many researchers have been making efforts to find the right statistical metrics for evalu- ating the interestingness of association rules [12] [13] [15] [16] [17]. However, the statistical information, e.g., support, confidence, lift, chi-squared, and so on, is usually not enough for measuring the interestingness. That is to say, it cannot be concluded affirmatively that the rule with higher support value is more interesting or the rule with higher confidence value is more interesting. Sometimes, different measures may even provide conflicting information [13]. Tan et al. [13] also find that each measure has its own advantages and disadvantages and whether a measure could contribute to the evaluation of interestingness depends on what kind of problem to be solved. Liu et al [12] argue that a rule is only interesting in the context of other rules and each individual may not be interesting in many cases. However, none of them have mentioned that the semantic knowledge behind the datasets could help building a new metric to evaluate the association rules.

In fact, we prefer to say that whether a rule is inter- esting or not depends on the users? choice. For example, we could mine many rules from the data about Volatile Organic Compounds (VOCs) and diseases caused by VOCs.

Environmental scientists may be interested in how much concentration of Benzene is dangerous in indoor air, while lacquerers may want to know which paint is not suitable for office equipments. How could we decide which rule to be presented for the user? The method proposed in this paper aims to solve this problem by personalized ranking or selection. First, let the user specify the topics that he is most interested in, and the topics could be described by several keywords, like the keywords used in search engines.

After that, we could find the most related association rules according to the keywords, and these rules could be most interesting for the user.

In order to find the related association rules, we apply semantic similarity to evaluate the relations between key- words and rules. An ontology should be built first to describe the concepts and relationships in the domain for measuring the semantic relation and calculating the semantic similarity.

Although we introduce semantic knowledge to measure the interestingness of rules, it does not mean that we give up all the statistical information which measures rule widely and effectively to a certain extent. In fact, we propose a new ranking method, named RuleRank, to combine the semantic knowledge and statistical information together to evaluate the      rules, and the parameters in RuleRank are trained by Genetic Algorithm.

The rest of this paper is organized as follows. In Section II, we introduce some background knowledge used in this paper, and we also give a formalized problem description in Section III. In Section IV, we make use of Genetic Network Programming [18] [19] [20], to mine association rules. In Section V, we describe how to evolve the parameters in RuleRank model by Genetic Algorithm. Some simulation results are given in Section VI and some more detailed discussions are given in Section VII. At last, we conclude this paper, describe the future work in Section VIII and thank several contributors in Section IX.



II. BACKGROUND  A. Ontology  An ontology is a formal and explicit specification of shared conceptualization (T. R. Gruber, 1995) [21]. This is the most cited one among various definitions of ontology.

Although different people will have different opinions about ontology, in computer science, it is often used to describe the hidden structured or semi-structured knowledge in a domain of interest. In other words, ontology could give us an explicit representation of the implicit knowledge usually existing in human beings? head. There are five main components in an ontology [22]:  ? class, also called concept; ? property, sometimes called slot or role, describing var-  ious features of classes; ? facet, sometimes called role restrictions, describing the  restrictions on properties; ? instance; ? relationship, also called relation.

B. Semantic Similarity  The semantic similarity is often used to measure how similar or related two concepts are in an ontology. There are various methods to calculate semantic similarity. Resnik pro- posed a method by using the information content of the most informative hypernym concept (super-concept) [23] which also has many variations [24] [25]. Some other researchers made use of conceptual distance by counting edges between concepts to evaluate similarity [26] [27]. Leacock et al. [27] defined the semantic similarity as:  sim(ci, cj) = ? log[ minlen(ci, cj)  2 ? MAX ], (1)  where, minlen(ci, cj) is the length of the shortest path between ci and cj , and MAX is the maximum depth of the ontology. There is also another definition with different expression but same meaning [23]:  sim(ci, cj) = 2 ? MAX? minlen(ci, cj). (2)  Considering the characteristic of the database in our re- search, we make use of the distance based approach.

A  FED  CB  G  is-a  is-ais-a  is-a  is-a is-a  part-of  produced-by  part-of  Fig. 1. An example of ontology with more relations.

Many experts consider an ontology as a tree structure because they usually only consider is-a relation, which is the basic relation and could be extended by introducing more semantic relations, like part-of, infected-by, produced-by, and so on. For example, in Fig. 1, there are more relations and we would say it is a kind of network structure rather than tree structure. In this paper, we?d like to treat the ontology as network structures. Note that different relations would be of different importance in an ontology, but the edge counting approach treats all the relations as the same. So we could improve the traditional distance based approach as follows:  wsim(ci, cj) = MAXnet ? ?  p?pat(ci,cj)  wei(p), (3)  where, wei(p) is the weight assigned to the path p, pat(ci, cj) is the shortest path between concept ci and cj , and MAXnet = max{  ? p?PATH wei(p)} where PATH is the set of all  the shortest paths between any pair of concepts. The value of each weight should be determined by domain experts considering the relationship between the concepts in the domain when building the ontology. Dijkstra?s algorithm [28] was used to find the shortest path in our simulations.



III. PROBLEM FORMULATION  In this section, we formally describe the problem of personalized association rule ranking.

The general principle of the method proposed in this paper could be described by the following steps:  1) Mine association rules offline by Genetic Network Programming to get the rule set RULE;  2) Build an ontology O to describe the concepts and re- lations in the research domain, e.g., VOCs and related diseases; (All the attributes in database are concepts in O)  3) Let an user input keyword set KEY which he is interested in; (Here, all the keywords are the concepts in O)  4) Ask an user to rank a fairly small number of rules by hand, and train the RuleRank model by this ranking results;  5) Rank all the rules in RULE and give a ranked rule set RULE? automatically by RuleRank model;  488 2008 IEEE Congress on Evolutionary Computation (CEC 2008)    6) Show RULE? to the user.

Given a dataset containing P attributes, ATT = {att1, att2, . . . , attp, . . . , attP }, we first build a domain knowledge with Q concepts, CON = {con1, con2, . . . , conq, . . . , conQ}, where each attribute in a database is also a concept in ontology, i.e., attp ? CON and ATT ? CON . The user inputs K keywords that he is interested in, KEY = {key1, key2, . . . , keyk, . . . , keyK}, and here we suppose every keyword is also a concept, i.e., keyk ? CON , KEY ? CON . After using Genetic Network Programming based association rule mining method, we could get R association rules, RULE = {rule1, rule2, . . . , ruler, . . . , ruleR}, where each rule contains J items, ruler = {itemr1, itemr2, . . . , itemrj, . . . , itemrJ}. Because the items in association rules are attributes in the dataset, we could infer that itemrj ? CON , ruler ? CON .

Now, the problem is to get a ranked association rule set RULE? = {rule?1, rule  ?  2, . . . , rule ?  r, . . . , rule ?  R}, where the upper rule is more interesting to the user.

We first introduce several definitions used in this paper.

Definition 1 (Rule Similarity): Given the set of rules  RULE and keywords KEY , we define a new metric, Rule Similarity, to measure the semantic relation between every rule ruler and the keyword set KEY . Suppose we have J items in ruler and K keywords in KEY , the Rule Similarity could be calculated as:  SIM(ruler, KEY ) =  ?J j=1  ?K k=1wsim(itemrj, keyk)  J ? K ,  (4)  where wsim(itemrj, keyk) is the weighted semantic simi- larity between concept itemrj and keyk.

Definition 2 (RuleRank): Given a set of related rules, Rule Ranking orders these rules by both semantic infor- mation and statistical information. Suppose we have some statistical information for rule ruler: support value supr, confidence value confr, lift value liftr, and chi-squared ?2r, then RuleRank value of rule ruler, RuleRank(ruler), is calculated as:  RuleRank(ruler) = w1 ? SIM(ruler, KEY ) + w2 ? supr  +w3 ? confr + w4 ? liftr + w5 ? ? r,  (5)  where, w1, w2, w3, w4 and w5 are parameters, 0 ? w1 ? 1, 0 ? w2 ? 1, 0 ? w3 ? 1, 0 ? w4 ? 1, 0 ? w5 ? 1, and (w1 + w2 + w3 + w4 + w5) = 1.

Definition 3 (Optimal Ranking Parameter Set): If we use a ranking parameter set, W = {w1, w2, w3, w4, w5}, in the RuleRank model, and the Spearman?s correlation [29] between the ranking results given by RuleRank model and the ranking results given by the user is maximized, we say the parameter set is the Optimal Ranking Parameter Set, denoted as W ? = {w?1 , w  ?  2 , w ?  3 , w ?  4 , w ?  5}.

In order to find the optimal parameters, a training set is needed. We ask some students and teachers, with a certain related domain background, to check some association rules and give an order by hand considering both the keywords pre- assigned and the statistical information of rules. The training set consists of a part of these manually ranked results, and we will make use of Genetic Algorithm to find the optimal parameter values by learning the training set.

Definition 4 (Optimal Rule Ranking): Given a set of rules RULE, after we train the RuleRank model from the data given by person A to get the Optimal Ranking Parameter Set, and use the Optimal Ranking Parameter Set to rank RULE, we can get a new ranked rule set RULE?, RULE?  is called Optimal Rule Ranking for person A.



IV. MINING ASSOCIATION RULE BY GENETIC NETWORK PROGRAMMING  In this section, we will briefly introduce Genetic Network Programming (GNP) and apply GNP to mine association rules.

A. Genetic Network Programming  Genetic Network Programming (GNP) is an extension of GP, which uses directed graphs as genes for evolutionary computation [18] [19] [20]. As Fig. 2 shows, the basic structure of GNP has three kinds of nodes: a Start Node, some Judgement Nodes and some Processing Nodes. The start node is a special node, indicating the first position to be executed. Judgement nodes judge the information from the environment and determine the next node to be executed. Processing nodes represent some functional actions that could be taken. GNP evolves the graph structure with the predetermined number of nodes, and reuses these judgement nodes and processing nodes during the execution. As a result, it could be quite compact and efficient and never cause the bloat.

1 32 4 5   Proc ess ing Node Judgem ent Node  0 Direc ted Graph Struc ture  Start Node  Fig. 2. Basic structure of GNP  B. GNP Based Association Rule Miner  GNP has been proved to be an effective method to mine association rule [5] [6] [7] [8]. In our previous research [5], [6], we have tried to apply evolutionary method (i.e., GNP) to mine generalized association rules efficiently, while in this paper, the key point is to use evolutionary method  2008 IEEE Congress on Evolutionary Computation (CEC 2008) 489    (i.e., GNP and GA) to find interesting association rules for users effectively. When applying GNP to data mining, the individual of GNP could be predigested into a kind of chain structure. We first present the most basic structure of an individual, i.e., Sequentially Connected Chain (SCC) in Fig. 3(a).

C=1B=1 E=1A=1 D=1 F=1  1P 2P 4P 5P3P 6P  SP E P...  . . .

8 5 3 0  (a) Sequential Connected Chain  C=1B=1 E=1A=1 D=1 F=1  1P 2P 4P 5P3P 6P  SP ...  . . .

(b) Sequential Connected Chain with One Loop  C=1B=1 E=1A=1 D=1 F=1  1P 2P 4P 5P3P 6P  SP ...  . . .

(c) Randomly Connected Chain  Fig. 3. Three kinds of item chains  SCC is a chain of judgement nodes, e.g., A=1, B=1, C=1, etc, which consist of the concepts in ontology where each judgement node has only one previous judgement node and one next judgement node. SP is the start node and EP is the end node representing the end of execution. Each judgement node has a corresponding processing node, for example, P1 for A=1 and P2 for B=1. Judgement nodes, like A=1, B=1, C=1, etc, decide whether the concept A, B or C occurs in the Hierarchical Transaction when scanning the transactions. If the judgement result is negative, the corresponding processing node will be activated, otherwise the program will go on to the next judgement node. For example, if C is not in the transaction, P3 will be activated to stop the scan and check the rule, and if C occurs, the program will continue to check D without dealing with P3.

As soon as one processing node is activated, it will check the candidate association rules just scanned.

TABLE I  AN EXAMPLE OF CANDIDATE RULES.

Candidate rules Support Confidence A,B?C 30% 60% A?B,C 30% 38% A?B 50% 63%  Here is a simple example in Fig. 3(a) and Table I shows the process of using SCC to find association rules. Without loss of generality, we assume that there are 10 records of transactions in the database. Class A occurs 8 times in the records, class B occurs 5 times in the records where A also  occurs, and class C occurs 3 times in the records where both A and B also occur. If class D does not occur in the records that contain A, B and C, which means the judgment result of D=1 is negative, the processing node P4 is activated to end the scanning and the support and confidence value of the candidate rules are calculated. If we set 40% for the minimal support value and 60% for the minimal confidence value, we could get one association rule (A ? B) from the candidate rules in Table I.

We specify a parameter, Maximum Rule Length (MRL), to restrict the rule length, because sometimes even the short length rules contain enough information for us and some long length rules may be redundant. Of course, when MRL is the length of SCC, that is, MRL equals to the number of judgement nodes in SCC, there is no restriction for rule length.

C. Genetic Operators in GNP  There are three kinds of genetic operators in GNP: crossover, mutation of content, mutation of connection.

Crossover operation is shown in Fig. 4(a), and here we use only one crossover point.

CBA D  JIH K  JBA K  CIH D  (a) Crossover.

CBA D HBA D  (b) Mutation of content.

CBA D CBA D  (c) Mutation of connection.

Fig. 4. Examples of GNP genetic operators.

There are two kinds of mutation in GNP: mutation of contents and mutation of connections as illustrated in Fig.

4(b) and Fig. 4(c).



V. EVOLVING PARAMETERS  In this section, we try to make use of Genetic Algo- rithm to find the Optimal Ranking Parameter Set W ? = {w?1 , w  ?  2 , w ?  3 , w ?  4 , w ?  5}.

A. Evaluate Rule Ranking  Before introducing how to evolve the parameters, we first discuss how to evaluate the quality of the ranked rules, which will help evaluate the fitness of individuals.

The main purpose of this paper is to let computer programs rank association rules for human beings. Whether a rule is good or not could only be decided by human beings eventually. In order to generate Optimal Rule Ranking, we must find Optimal Ranking Parameter Set by the help of human beings. We could let the computer programs rank the rules by the following steps:  490 2008 IEEE Congress on Evolutionary Computation (CEC 2008)    1) Give a keyword set KEY = {key1, key2, . . . , keyk, . . . , keyK}, where each keyword keyk is also a concept in ontology O;  2) Draw a reader-friendly data graph G for human beings, containing the information about rule set RULE, re- lated concept set CON and relationships S in ontology O;  3) Let one human being (with a certain domain back- ground) assign an order to each rule in RULE consid- ering its relativity to KEY and statistical importance, and produce a new ranked rule set RULE?? where the upper rules are more interesting to the user;  4) Run RuleRank model to rank the rules considering the semantic similarity between the rules and KEY , resulting in another new rule set RULE?;  5) Compare the rank in RULE? and RULE?? to see how strong the correlation is between them;  6) Train the RuleRank model gradually so that the corre- lation between RULE? and RULE?? is maximized at last.

We use Spearman?s rank correlation coefficient to measure the associations between two ranks [29]. If these two ranks are correlated with each other positively, it means that the computer programs could rank the rules appropriately for human beings.

We will give several groups of keywords and association rules and let several human beings rank the rules. Then, the ranked rules will be divided into two sets: training set and testing set. The training set is used to find the Optimal Ranking Parameter Set by Genetic Algorithm, while the testing set is used to see whether the method could really mimic human beings? ranking behavior by evaluating the Optimal Rule Ranking.

B. Training Parameters By Genetic Algorithm  In this subsection, we will discuss how to use Genetic Algorithm to find the Optimal Ranking Parameter Set using the training set.

The whole procedures is shown in Fig. 5. First of all, we randomly generated some individuals IND0 = {ind01, ind02, . . . , ind0i, . . . , ind0I}, where each element in the individual is a parameter in RuleRank model, ind0i = {w0i1, w0i2, w0i3, w0i4}. Then, we calculate the Rule Simi- larity between each rule and keywords set. Suppose there are R rules, RULE = {rule1, rule2, . . . , ruler, . . . , ruleR}, and the set of Rule Similarity could be represented as SIM = {SIM1, SIM2, . . . , SIMr, . . . , SIMR}. Dur- ing each generation of the evolution, we first cal- culate the RuleRank value of each rule, considering both SIMr and the parameters in the individual. For example, in the gth generation, we have individuals INDg = {indg1, indg2, . . . , indgi, . . . , indgI}, where indgi = {wgi1, wgi2, wgi3, wgi4}, and we could calculate RuleRank value of ruler by Equation 5 with SIMr and indgi. Considering the RuleRank value of each rule, we could rank the rules and get a new ranked rule set RULE?g.

Spearman?s correlation could be used to calculate the corre- lation between RULE?g and RULE  ??, where RULE?? is the ranked rule set in the training set. The correlation value is also used as the fitness value of the fitness function.

Initializatio n  S IM C alculatio n  R uleR ank  F itness  C alculatio n  C ro sso ver  Mutatio n  End  O utp ut  Y  N  Fig. 5. The evolutionary training procedures for Optimal Ranking Param- eter Set.

w 1 w 2 w 5w 3  Head  P o int T ail P o int  w 4  Fig. 6. The structure of an individual for Optimal Ranking Parameter Set.

The structure of an individual is represented in Fig. 6.

There is a head parameter (w1) and a tail parameter (w5).

The tail parameter does not have genetic operations because its value could be calculated by other parameter (w5 = 1 ? w1?w2?w3?w4). As a result, the tail parameter is hidden when performing genetic operations.

w 1 w 2 w 1 w '3  w 1 w '2 w '3  w 2   w 3 w 4 w 4  w 4  Fig. 7. An example of mutation.

There are two steps in a mutation operator as illustrated in Fig. 7. In the first step, we carry out typical single point mutation. In the second step, we check the validity of the new individual. If (w1 + w2 + w3 + w4 ? 1), this individual is invalid and we will choose the parameter with the largest value to perform the mutation operator again. The second step may happen several times.

In Fig. 8, we could see that a crossover operator also has two steps. After single point crossover is carried out, we will  2008 IEEE Congress on Evolutionary Computation (CEC 2008) 491    w 1 w 2 w 3  w '1 w '2 w '3  w 1 w '3  w '1 w 2 w 3  w 1 w ''2 w '3  w '1 w 2 w 3  w '2   1w 4  w '4  w '4  w 4  w '4  w 4  Fig. 8. An example of crossover.

check the validity of the new individuals, too. If any one of the new individuals is invalid, the parameter with the largest value in this individual should perform the mutation operator several times until all the individuals are valid.



VI. SIMULATIONS  A. Simulation Design  We select VOCs in the indoor air and related diseases as our research domain, and generate two datasets: D1 and D2.

From the first dataset D1, we mine 26 association rules, while 25 rules are mined from the second dataset D2 by setting the statistical thresholds properly, including support, confidence, lift, and chi-squared value. For each dataset, we designed two investigations with four different keywords: ENT(K1), Vine- gar Acid(K2), Viscera(K3), Dimethylbenzene(K4), where two keywords are belonging to VOC, and the other two are disease-related concepts. As a result, there are totally 4 investigations: I1 (using dataset D1 and keyword set K1), I2 (using dataset D1 and keyword set K2), I3 (using dataset D2 and keyword set K3), and I4 (using dataset D2 and keyword set K4).

After drawing seven pages of data graph describing the concepts and relations in ontology, we invited four persons, with a certain background of data mining and VOCs analysis, to assign a score with the range from 1 to 100 for each association rule. Since each person needs to fill in four investigations, there are totally 16 manual ranking results: R??A1(ranking results given by person A for investigation I1), R??A2, R  ??  A3, R ??  A4, R ??  B1, R ??  B2, R ??  B3, R ??  B4, R ??  C1, R ??  C2, R ??  C3, R??C4, R  ??  D1, R ??  D2, R ??  D3 and R ??  D4.

When all the investigations have been finished, we use the  ranking results of I1, i.e., R??A1, R ??  B1, R ??  C1 and R ??  D1, as the training set and the other rankings as the testing set.

We also calculate the correlation between the ranking results given by different persons.

B. Simulation Results  We first present the Spearman?s rank correlation between the ranking results given by different persons for the same investigation in Table II. From these tables, we could see that most of the correlation value is less than 0, which means that there are negative correlations between the ranking results.

TABLE II  THE CORRELATION BETWEEN RANKING RESULTS GIVEN BY DIFFERENT  PERSONS  (a) for investigation I1 Person A Person B Person C Person D  Person A 1 -0.427009 0.279316 -0.363419 Person B -0.427009 1 -0.0905983 0.025641 Person C 0.279316 -0.0905983 1 -0.160342 Person D -0.363419 0.025641 -0.160342 1  (b) for investigation I2 Person A Person B Person C Person D  Person A 1 -0.271111 -0.161026 0.0338462 Person B -0.271111 1 -0.0994872 0.26359 Person C -0.161026 -0.0994872 1 -0.190427 Person D 0.0338462 0.26359 -0.190427 1  (c) for investigation I3 Person A Person B Person C Person D  Person A 1 -0.136154 -0.00615385 0.19 Person B -0.136154 1 0.00384615 0.21 Person C -0.00615385 0.00384615 1 -0.285385 Person D 0.19 0.21 -0.285385 1  (d) for investigation I4 Person A Person B Person C Person D  Person A 1 -0.2 -0.106923 -0.325385 Person B -0.2 1 -0.165385 -0.0669231 Person C -0.106923 -0.165385 1 0.173846 Person D -0.325385 -0.0669231 0.173846 1  We also trained our method by the ranking results given by each person for investigation I1, and got the Optimal Ranking Parameter Set. For example, we used the rank- ing results given by person A, i.e., R??A1, as the training data and got the Optimal Ranking Parameter Set W ? = {w?1 , w  ?  2 , w ?  3 , w ?  4 , w ?  5}. With the optimal parameters, the com- puter ranked the rules in investigation I2, I3 and I4 and gave three Optimal Rule Rankings, R?A2, R  ?  A3 and R ?  A4. By comparing the correlation between R?A2 and R  ??  A2, R ?  A3 and R??A3, R  ?  A4 and R ??  A4, we could test how well the computer had ranked the rules for human A. Table III shows the training results and testing results for four persons.

TABLE III  THE TRAINING AND TESTING RESULTS OF RULERANK METHOD  Training Testing I2 Testing I3 Testing I4 Person A 0.261538 -0.310769 0.343846 0.113077 Person B 0.414017 0.0598291 0.126154 -0.326154 Person C 0.277265 0.0454701 0.132308 -0.33 Person D 0.429744 0.130256 -0.195385 -0.163077  In Table III, 58.3% of the testing correlation is pos- itive, while in Table II, only 33.3% values is positive.

This phenomena proves that after being trained by the data given by person A, RuleRank method could generate better rule ranking results for person A than the ranking results generated by another person, e.g., person B.

492 2008 IEEE Congress on Evolutionary Computation (CEC 2008)

VII. DISCUSSION  A. What is the main advantage of this method?

In our simulation, we only give about 25 rules and ask several persons to rank the rules. However, if there is not 25 but 25,000 or even more rules, it will be a terrible task for the user to find the interesting ones. Our method could overcome this problem. For example, if a person A has got 25,000 rules, he first rank a small number of rules. Then, after learning his judgement results, RuleRank model could rank the rest of the rules by finding Optimal Rule Ranking automatically.

Moreover, our RuleRank method could give better results than the results given by other persons. For example, if person B ranks rules for person A, and at the same time RuleRank model also ranks rules for person A, from the simulation results in the previous section, we could see that the results given by RuleRank model is more positively correlated with person A?s judgements.

B. How about ranking for person B using the parameters evolved from the data given by person A?

In this paper, we designed a method for personalized rule ranking, that means the parameters trained from the data given by person A will only be used for ranking rules for person A. We also did some simulations to use the parameters trained from the data given by one person, e.g., A, to rank the rules for another person, e.g., B. Table IV shows the correlation comparison results. We could see that most of the correlation values are negative, and there are only 33.3% positive values, which is so similar to the situation in Table II(a), II(b), II(c) and II(d). This phenomena also proves that our RuleRank model could mimic human being?s thinking style to a certain extent.

TABLE IV  USING THE PARAMETERS TRAINED BY ONE PERSON TO TEST THE DATA  GIVEN BY ANOTHER PERSON  Person A Person B Person C Person D Person A training -0.197949 -0.338803 -0.171966 Person B -0.13641 training -0.313504 0.197949 Person C -0.283419 -0.153504 training 0.109744 Person D 0.170598 -0.150769 0.105641 training  C. Why combining semantic knowledge and statistical infor- mation?

Traditional methods usually only consider the statistical information to measure the interestingness or importance of rules, and we have discussed that they cannot satisfy personal requirements. So we introduce semantic knowledge to evaluate the rules for personal interests. However, only semantic knowledge is also not enough to evaluate the rules.

For example, there are two rules: rule rule1(SIM : 80.5%, sup: 5.1%, conf : 8.3%, lift: 9.2%, chi ? squared: 2.7%) and rule rule2(SIM : 72.1%, sup: 88.3%, conf : 92.4%, lift: 56.0%, chi? squared: 38.2%). Although the semantic similarity between rule1 and keywords is very high, its  statistical information are very low, which means that this kind of rule does not always happen. As a result, many users will prefer rule2 rather than rule1, even the similarity between rule2 and keywords is a little smaller.

We think that no unique or absolute metric could measure a rule correctly for ever. The available useful metrics should be combined together to evaluate the rule. In fact, this is natural as human beings? thinking styles, because when a person evaluates a rule, he not only consider whether it is related to his interests, but also check whether it is a statistically strong rule.

D. Why there are so many negative correlation values in the simulations?

We thought that there may be more positive correlation between the choices made by different persons, however, it turns out to be not true. The main reason is that the persons who did the investigations are not so familiar with the domain knowledge of VOCs and related diseases. Among the four persons, three concentrate on the data mining algorithms for VOCs analysis, who understand some basic knowledge of chemistry or environment only, while one of them is an expert in VOC pollution research, who is interested in but not familiar with data mining techniques. As a result, their judgements may differ from each other greatly. Nevertheless, even if different people make different choice, there should be some patterns or preferences existing for only one person.

Our method could mimic such kind of preference.

E. What are the characteristics of the Optimal Ranking Parameter Set?

We first show the parameters training procedure of person C in Fig. 9. However, in our simulations, we find that it is very hard to get perfect Optimal Ranking Parameter Set which could result in the correlation value more than 0.5. (If the Spearman?s rank correlation is more than 0.5, it means there is strong positive correlation.)  Table V also shows the five parameter values obtained during the training process in Table III, and we could find the Optimal Ranking Parameter Sets are not similar to each other very much. We think it is natural because different people have different interests and understandings.

TABLE V  THE PARAMETER VALUES OBTAINED BY TRAINING  w1 w2 w3 w4 w5  Person A 0.1622 0.1008 0.2973 0.2904 0.1493 Person B 0.2144 0.2315 0.2307 0.2883 0.0351 Person C 0.2112 0.2112 0.3057 0.2363 0.0356 Person D 0.1845 0.3643 0.369 0.0003 0.0819

VIII. CONCLUSIONS AND FUTURE WORK  In this paper, we proposed a method for personalized as- sociation rule ranking. From the simulations and discussions, we could see that our method could mimic human being?s thinking style to a certain extent. The RuleRank model will be very useful to help the user rank and find what he is  2008 IEEE Congress on Evolutionary Computation (CEC 2008) 493    ????  ????  ????  ????  ?  ???  ???  ???  ???  ? 	? ??? ?	? ??? ?	? ??? ?	? ??? ?	? 	?? 		? ?? ? ??? ?	? ??? ?	? ?? 	? ????  ??????????  ? ? ? ? ? ?? ? ?? ?  ???  ???  ???  Fig. 9. The Parameters Training Procedure.

interested in, especially when the number of rules becomes too large.

In the future, we will study the method more deeply from the following aspects:  1) Consider more statistical and semantic measurements for RuleRank model;  2) Design some better experiments and invite more infor- mants;  3) Classify the users into several groups and find the Optimal Ranking Parameter Set not only for one person but also for one group.



IX. ACKNOWLEDGEMENT  We?d like to show our many thanks to Dr. Korposh in Cranfield University, PhD student Mr. Eloy and Miss Kala of Waseda University for their cooperation of investigations.

