An Ontology based Frequent Itemset Method to Support Research Proposal  Grouping for Research Project Selection

Abstract Research proposal grouping is one of the most  important tasks for research project selection in research funding agencies. In this paper, a novel ontology based frequent itemset method is proposed to deal with research proposal grouping problem. In the proposed method, a research ontology is firstly constructed to standardize research keywords.

Secondly, frequent itemsets with different support degrees are extracted from research proposals based on research ontology. Thirdly, a new measure of similarity degree between two research proposals is developed and then a clustering algorithm is proposed to classify research proposals based on the similarity degree, in which some parameters are discussed, and the proper parameters are selected. Finally, when the number of research proposals in some clusters is still large, research proposals are further divided into small groups, in which the number of research proposals is approximately equal. The proposed method is validated based on the selection process at the National Natural Science Foundation of China (NSFC). The experimental results show that our proposed method can improve the efficiency and effectiveness of research proposal grouping, and is a potential and alternative one to support research project selection processes in other governments and private research funding agencies.

1. Introduction  Project selection is a recurring and significant activity in many organizations (e.g., research funding agencies), and it is also a complicated and multi-stage decision-making process. It begins with a call for proposals (CFP), and proposals are then submitted to the body, such as research funding agencies. When these proposals are collected, they are sent to reviewers for peer review. Reviewers normally review proposals according to the instructions on the rules and criteria  provided by organizations. Once the review process is finished, the review results are aggregated and these proposals are ranked. Finally, some outstanding proposals are funded. To support project selection process, several formal methods have been proposed.

For example, a fuzzy logic approach is applied to project selection [1]. A fuzzy AHP method is suggested to select government-sponsored projects [2].

An AHP and fuzzy TOPSIS method is applied to project selection [3], while a fuzzy DEA and knapsack formulation integrated model is proposed for project selection [4]. Similarly, a hybrid fuzzy DEA and Bayesian belief network evaluation model is offered [5]. Also, an integrated DEA and balanced scorecard approach is presented [6].

Research project is one of the most important government-sponsored projects in China, and several funding agencies have been set up to improve scientific or social development and cultivate talents. Among them, National Natural Science Foundation of China (NSFC, http: //www.nsfc.gov.cn) is the largest funding agencies. NSFC receives thousands of research proposals from universities and institutions all over the country each year, and the research project selection process is shown in Figure 1.

CFP Proposalsubmission Proposal grouping  Reviewer Assignment  Peer reviewResultaggregationPanel review Final  decision  Figure 1 The research project selection process  As can be seen from Figure 1, the research project process begins with a call for proposals (CFP), and CFP is sent to universities and research institutes.

Before deadline, applicants submit research proposals to NSFC. When research proposals are collected, proposals with similar topics are classified in the same group, and then proposal groups are sent to reviewers for peer review. Reviewers normally review the   DOI 10.1109/HICSS.2013.90    DOI 10.1109/HICSS.2013.90     proposals according to the instructions on the rules and criteria provided by NSFC, and return the review results. When the review process is finished, the review results are aggregated and some of research proposals with higher ranking are recommended for panel review. Finally, some outstanding proposals are funded.

During the process, there is a strict evaluation to decide whether to fund a proposal or not. So, to support research project selection, some specific methods and systems are proposed. For general research project selection process, an organizational decision support system to assist research project selection [7-8], while a multilingual ontology framework is suggested to support research project selection [9]. To support specific phases for research project selection, a hybrid knowledge rule and genetic algorithm is suggested for research proposal grouping [10-11], and furthermore, an ontology based text mining method (OTMM) to cluster proposals is proposed for research project selection [12]. A group decision support method is offered to evaluate experts for research project selection [13], and an integrated decision support model to assess reviewers for research project selection [14]. A hybrid knowledge-based and modeling approach is offered to assign reviewers to proposals for research project selection [15], while a decision support approach is presented for assigning reviewers to grouped proposals, and genetic algorithm is employed to solve the assignment problem [16]. A text-mining approach is suggested to identify reviewers, and assign reviewers to proposals [17]. A method of optimal allocation of proposals to reviewers is presented in order to facilitate the selection process [18]. Finally, an integrated method for collaborative research project selection is proposed according to competitiveness and collaboration of candidates [19].

As can be seen from the process, proposal grouping is one of the most critical stages because the quality of proposal grouping can greatly affect the review quality.

Among the literatures, previous studies mainly focus on general project selection process but not specific phases, such as proposal grouping. Furthermore, specific phases to cluster proposals mainly focus on the diversity of applicants? characteristics [10-11], while ignoring the content similarities of research proposals.

Through text mining has been introduced for research proposal grouping [12], due to the high computing complexity and the difficulty of controlling clustering results, this method may lead to poor performance when the number of research proposals is large [20].

To cover this research gap, this paper contributes an ontology based frequent itemset method (OFIM) to support research proposal grouping.

The rest of this paper is organized as follows.

Literature review is presented in Section 2, and the proposed ontology based frequent itemset method is developed to cluster research proposals for research project selection in Section 3. For illustrating the efficiency of the proposed method, empirical analysis of proposal grouping is reported in Section 4. Finally, conclusions and future research directions are summarized in Section 5.

2. Literature review  As mentioned above, research proposal grouping is critically important in the process of research project selection. So, some formal methods have been proposed from different aspects. Firstly, the applicants? characteristics are considered in research proposal grouping. In each research proposal group, the applicants? characteristics should be diversified. A hybrid knowledge rule and genetic algorithm is proposed for research proposal grouping according to applicants? characteristics [10-11]. In the proposed method, knowledge rules are designed to identity and classify research proposals, and genetic algorithm is developed to group research proposals. Secondly, topic similarity is also an important issue when dealing with grouping. Research topic should be similar in each research proposal group. So, an ontology based text mining method to cluster proposals is proposed for research project selection [12]. In this proposed method, a research ontology is constructed, and research proposals are classified according to discipline areas using a sorting algorithm, and then research proposals in each discipline are clustered using a self-organized mapping (SOM).

When the number of research proposals is large, OTMM using traditional term frequency method may lead to poor performance due to the high computing complexity. Frequent itemsets, which can make use of relationship among documents, can improve the quality of clustering [20]. So, frequent itemset methods have been introduced for text clustering problems. Two clustering algorithms including clustering based on frequent word sequences (CFWS) and clustering based on frequent word meaning sequences (CFWMS) is suggested for text clustering [21], while a fuzzy frequent itemsets for hierarchical document clustering is proposed [22]. Similarly, maximum capturing is developed for text clustering [23].

In this paper, the idea of frequent itemset clustering is employed, and a new clustering algorithm is designed to support research proposal grouping for research project selection.

3. The proposed method  3.1. The framework of the proposed method  When research proposals are received by the NSFC, they are firstly classified into different disciplines in terms of discipline codes. However, when research proposals belonging to one certain specific discipline, they will be further divided into different groups, in which the number of research proposals is approximately equal.

Although many text-mining approaches have been applied in English texts clustering and some even in Chinese ones, the ideal accuracy hasn?t achieved in various text materials, especially the research proposals.

To attain this requirement, combining the ontology based text mining method (OTMM) [12] and frequent itemsets [20-23], an ontology based frequent itemset method (OFIM) is proposed for research proposal grouping, and the framework of the proposed method is shown in Figure 2.

Research Projects  Research Proposals  Research Proposals in Disciplines  OFIM  Research Proposal Clusters  Research Proposal Groups  Research Ontology  Figure 2 The framework of the proposed method  As can be seen from Figure 2, a research ontology is first built by the keywords collected from the research projects in latest five years, and research proposals are classified into each discipline. When research proposal are classified into disciplines, proposal grouping is considered in the following three phases. In the first phase, all concepts and sub- concepts in the ontology are encoded and put into a set, and research proposals are transformed into figures  sequence, and the words outside our set are removed.

After this processing, in the second phase, the method supported by generalized suffix tree (GST) data structure proposed in [23] is used to extract the frequent itemsets with different minimal support and different length from research proposals. In the last phase, different combining patterns of these frequent itemsets is tried as representatives of research proposals, then a new clustering algorithm is proposed to group proposals.

In short, the proposed OFIM can be divided into three phases, including Phase 1 ?coding and compacting research proposals?, Phase 2 ?getting frequent itemsets?, and Phase 3 ?clustering research proposals?. The following subsections will give details about the above mentioned three phases of the OFIM.

3.2. Phase 1: Coding and compacting proposals  This subsection can be called the preprocessing of research proposals. Through this processing, the proposal texts without apparent delimiters, especially Chinese texts, are segregated into different words with a specific meaning in this domain. And these meaningless words are naturally filtered out. Besides, every meaningful word is represented by a corresponding integer which is called identifier of this word and proposals are transformed into encoded proposals, which are composed by sequences of integers. The process is shown in Figure 3.

Ontology and Key words  Proposal 1 Proposal 2 Proposal n  Dictionary: a set {C1, C2, ..., Cn}  Coded Proposal 1  Coded Proposal 2  Coded Proposal n  All the concepts and sub-concepts  Step 1 Step 2  Figure 3 Coding and Compacting proposals  Step 1: Building a dictionary from the ontology. All the concepts and sub-concepts included by the ontology and key words of these proposals are extracted out to form a dictionary. This dictionary can be expressed as a set {C1, C2, ..., Cn}, where Ci is a concept or sub-concept in the ontology and n is the identifier of the concept or sub-concept. And the set {C1, C2, ..., Cn} are mapped to a set {1, 2, ..., n}.

Through this process the concept Ci in the {C1, C2, ...

Cn} is corresponding with the identifier i.

Step 2: Filtering proposals according to this dictionary. As long as a word is included in this dictionary, it will be retained and replaced by its     identifier. Otherwise, it will be filtered out of the proposals. Considering the concept may be the substring of its sub-concept in Chinese, since the sub- concept can reveal more specific information about the article, sub-concepts should be retained rather than their substrings. An encoding algorithm is designed to encode the proposal, as shown in Table 1. After this processing, the proposals are transformed into sequences of integers and you can find out identifier of any concept or sub-concept in the dictionary. And  we call these proposals ?coded proposals? after this process.

Table1 The encoding algorithm  //where n      number of concepts, //      p     number of proposals //     m[i]    number of chinese words in the proposal i // rank the concepts from the longest to the shortest For i = 1 to n  For j = 1 to n If length(concept[i]) < length(concept[j]) Switch(concept[i],concept[j]);  End End  End //use the ranked concepts to filter proposals For k = 1 to p  For i = 1 to n For j = 1 to m  If compare(concept[i], proposal[k][j], length(concept[i])) replace(concept[i], number_cor_with(concept[i]))  End End  End End //remove all the remaining chinese words from  proposals For k = 1 to p  Remove_all_word(proposal).

3.3. Phase 2: Transforming research proposals  After proposals are encoded and compacted, a proposal can be represented by a sequence [n1, n2, ? nm], which we call coded proposal, where m denotes the length of the compacted  proposal.

The purpose of selecting frequent itemsets is finding some word sequences in certain specific other can show more accurate and more tightly logical link among proposals that have them in common. And we will use six steps to extract different frequent word sequences from these proposals including selecting frequent 2-word itemset, building the generalized suffix tree (GST), extracting the Itemset in an assigned sequence length, picking out Itemset with assigned  minimal support, transforming each proposal into a vector, and building matrix with different assigned length and assigned minimal support. The details of each step are as follows.

Step 1: Selecting frequent 2-word itemsets.

Association rule miner is used to find out the 2-word sequences which satisfy the minimal support. The minimal support means that the minimal number of proposals which selected 2-word sequences should exist in. In this step, firstly we extract all 2-word sequences in all proposals. Then pick out these 2-word sequences that satisfy assigned minimal support (we call it basic minimal support) to form the frequent 2- word itemset and collect all words in the frequent 2- word itemsetas a dictionary and remove words outside this dictionary from all proposals. The process is shown in Figure 4.

Coded Proposal 1  Coded Proposal 2  Coded Proposal n2-word itemset  Frequent 2-word itemset  Dictionary: all words in Frequent 2-word  itemset Filtered Proposal 1  Filtered Proposal 2  Filtered Proposal n  Figure 4 The process of selecting frequent 2-word itemsets  Step 2: Building the generalized suffix tree. Based on filtered proposals in the Step 1, we build a generalized suffix tree (GST) for each proposal. We use an example to demonstrate the GST date structure.

Suppose there is a proposal ?abcbcabc?, where a, b, c represent different Chinese words in the proposal.

Every subsequences of proposal is used to build the GST, shown as the Figure 5. For example, in this example, subsequences are ?abcbcabc?, ?bcbcabc?, ?cbcabc?, ?bcabc?, ?cabc?, ?abc?, ?bc?, ?c?. So every tree is corresponding with one proposal, all information about a proposal is stored in the corresponding tree.

Figure 5 The process of building the GST  Step 3: Extracting the itemsets in an assigned sequence length. Since each generalized suffix tree     corresponds with one proposal, we traverse every generalized suffix tree and collect all subsequences with the assigned length in this tree. For example, in the Figure 5, we can try to extract all word sequences composed by 3 words. And from the GST we can get node c, b, a, c, b whose depth equals to 3. And the subsequences corresponding with them are abc, bcb, bca, cbc, cab. By this means, we can extract all subsequences with the assigned length in one proposal.

These sequences in a proposal are collected together to form word-sequence seti, where i indicates that seti is corresponding the treei and proposali. Then we merge all sets to form itemset with assigned length. But there may be the same word subsequences in different GSTs.

So we remove redundant word sequences from the itemset with assigned length.

Step 4: Picking out itemset with assigned minimal support. Use the association rule miner again and pick out word sequences with assigned minimal support from itemset with assigned length to form itemset with assigned length.

Step 5: Transforming each proposal into a vector.

In this process, every proposal is transformed into a vector. And every dimension in the vector is the frequency of a word sequence in the itemset with assigned length in the corresponding proposal. So when different itemset with assigned length is given, the proposals can be represented by different vectors.

We call the specific meaning of a dimension ?vector pattern? which corresponds with Itemset with different assigned length. Proposals are transformed to vectors.

To get the frequency of every element in itemset with assigned length in a proposal, we traverse the corresponding GST that we have built. If the subsequence doesn?t exist in one GST, its frequency is 0. And if the subsequence exists in one GST, its frequency in the corresponding proposal equates the leaves belonging to the node corresponding with the last word in the subsequence. For example, in a suffix in Figure 5, if we want to get the frequency of sequence ?bc?, we traverse the tree along the sequence, and the last word ?c? has three leaves. So we can know that the frequency of sequence ?ab? in this proposal is 3.

So we traverse each GST again and get all vectors.

Then we put all row vectors together to form a Matrix which can represent the entire corpus which need be clustered.

The Step 3, Step 4 and Step 5 are shown in the Figure 6.

GST 1 GST 2 GST n Itemset with assigned length  Itemset with assigned minimal support  Vector patternVector 1 Vector 2 Vector n  Assigned length  Assigned minimal support  Figure 6 The process from Step 3 to Step 5  Step 6: Building Matrix with different assigned length and assigned minimal support. By means of above mentioned procedures, all proposals are transformed into vectors and the corpus is transformed in to Matrix. However, since the Matrix has two parameters, assigned length and assigned minimal support. We can express one Matrix as Matrix (j, S), where j denotes the length of frequent word sequences and S denotes the minimal support of frequent word sequences. By changing j and S, we can get various Matrix (j, S).

3.4. Phase 3: Clustering research proposals  We use K-means algorithm to cluster proposals. So every Matrix (j, S) can be used to cluster proposals.

And we can Euclidean Distance of two proposals to indicate the similarity of two proposals.

So the problem becomes into a multi-criteria decision process [24-25]. Based on every Matrix, we can calculate Euclidean Distance among them and our criterion is minimizing the Distance within a cluster and maximizing the distance between two clusters.

Since we have several Matrixes, we have several criteria.

The remaining problem is how to combine these criteria. Firstly, we define a new distance. The new distance is a combination of several Euclidean Distances calculated according to a several different Matrixes.

Suppose we have 4 different Matrix, where L equates 2, 3, 4, 5, we have 4 Euclidean Distance. The new distance is the sum of 4 Euclidean Distances with different weights. The expression is as follows.

??? ???? ?? = ? ????? ??????? ???? ??? (1) where ?, ?, ?, ?  denotes different weights for different Euclidean Distance. And with this new distance, we propose an improved K-means algorithm.

We replace the Euclidean Distance by the New distance and use the same iterating algorithm, and shown in Table 2. Through this means, we combine these different criteria.

Table 2 The improved K-means algorithm  //where //      p     number of proposals //     Initialize centres cj j=1,..., m For i = 1 to p  For j=1 to m Computing the similarity vi and cj If ck achieve max similarity vi and cl  vi belongs to cl End  //update the centres cj For k = 1 to m  Updata cj End  The next task is to cluster research proposals according to the improved K-means algorithm. When the clustering is finished, if the number of research proposals in some clusters is still large, research proposals are further divided into smaller group randomly, in which the number of research proposals is approximately equal.

4. Empirical analysis  4.1. Data description and evaluation criteria  To determine the appropriate parameters in Matrix (j, S) and how many Matrixes to be used in the new distance, several experiments are conducted. The corpus that we use consists of 750 proposals in 4 different topics and in our experiment the basic minimal support is set as 50.

And we will evaluate the clustering result with F measure. F measure is the typical criterion for measuring the quality of text clustering [12]. For predefined research topic t and cluster c, the Precision and Recall are defined as follows:  ???????? (?, ?) = ?(?,?)??                            (2) ???	??(?, ?) = ?(?,?)??                                  (3)  where (?, ?) be the number of research proposals in both topic t and cluster c, ? be the number of proposal in topic c, and ? be the number of proposal in cluster c.

The F measurement can be expressed as:  ? ?? ?max ,i i  n F F i j  n ??                         (4)  where ? ? ? ? 2Re , *Pr ( , )  , Re ( , ) Pr ( , )  call c t ecision c t F c t  call c t ecision c t ?  ? .

4.2. Experimental results  4.2.1. Single Matrix results  In the subsection, the weights are set as follows:  ! =  " 1 , # = $ 0 , # ? $ ?                             (5) Thus, when K-means clustering algorithm is used to  cluster research proposals, the new distance is equal to Euclidean Distances based on one single Matrix (j, S).

And we change the j and S in Matrix (j, S) to check out the clustering performance. We set j from 2 to 5, and for every fixed j, we change Sj from 5 to 100. (Sj should be adjusted according to the size of proposal)  In our experiment, we find that with the increase of j, the performance of clustering deteriorates sharply (see Table 3 and Figure 7).

Table3 The performance of single frequent itemset sj=10 sj=20 sj=30 sj=40 sj=50  j=2 0.606 0.760 0.762 0.884 0.841 j=3 0.576 0.658 0.572 0.570 0.550 j=4 0.403 0.487 0.505 0.473 0.453 j=5 0.451 0.438 0.436 0.434 0.395  sj=60 sj=70 sj=80 sj=90 sj=100 j=2 0.8344 0.809 0.791 0.752 0.752 j=3 0.5635 0.555 0.450 0.464 0.434 j=4 0.4935 0.409 0.424 0.424 0.428 j=5 0.3955 0.397 0.412 0.413 0.403  Figure 7 The performance of single Matrix  As can be seen from Table 3 and Figure 7, when j=2, the average value of F-measure can achieve the highest accuracy. However, when j = 5, no matter what sj is chosen, F measure is low than 0.5. So, we don?t conduct any experiments with longer frequent itemset.

Furthermore, with the increase of the length of frequent itemset, the performance decreases. Meanwhile, with the increase of support degree, the performance increases first, and then decreases. Figure 8 shows the best performance of different j.

Figure 8 The best performance in different length  As can be seen from Figure 8, when j = 2 and sj = 40, the optimal clustering result can be achieved.

Furthermore, with the increase of the length of frequent itemset, the performance decreases.

4.2.2. Weighted Matrixes results  In this subsection, weighted Matrixes with different weights are considered. As typical situations, we choose Matrix (L, S), where S is corresponding with the best-performance situation in the above experiment.

So we set S = 40.

We select different weights in our experiments.

Firstly, we give equal weights and check out the result.

And then, we enhance the weight of Matrix (2, 40) to see the variation in F measure.

When the several sectors are given equal weights, the comprehensive vectors show a poor clustering performance. But with the enhancement of the weight of Matrix (2, 40), the F measure rises sharply (see Table 4 and Figure 9).

Table 4 The performance of weighted frequent itemsets No. Weight distribution F measure  ' 	? 	? 	? 1 1/4 1/4 1/4 1/4 0.587 2 1/3 2/9 2/9 2/9 0.565 3 1/2 1/6 1/6 1/6 0.653 4 2/3 1/9 1/9 1/9 0.693 5 3/4 1/12 1/12 1/12 0.700 6 4/5 1/15 1/15 1/15 0.727 7 5/6 1/18 1/18 1/18 0.785 8 1 0 0 0 0.884  Figure 9 The performance of weighted frequent itemsets  Though these experiments, some conclusions can be found that the Matrix (2, 40) can achieve the best performance. With the increase of frequent itemsets, the frequent word sequence maybe too specific and over-differentiate these proposals. So the Matrix (2, 40) can be successfully applied to research proposal grouping.

4.2.3. Comparison with other methods  In this subsection, to show the advantage of our proposed method, our proposed method ((OFIM) is compared with the traditional method (OTTM). Two methods are carried out using the same corpus and the same clustering algorithm (K-means). The results can be shown in Table 5.

Table 5 The performance of ARIMA model Methods OFITTM OTMM  F-measure 0.884 0.808  As can be seen from Table 4, the results show that the F measure has an obvious rise, comparing with OTMM. Therefore, our proposed method, OFIM, is an efficient and effective method to group research proposals in one specific discipline with high-quality performance.

5. Conclusions  This paper proposed a novel frequent itemset method for research proposal grouping. In the proposed method, research proposals are firstly coded and compacted, and then frequent itemsets are constructed. Finally, a new clustering algorithm is developed to cluster research proposals. In terms of evaluation criteria, the empirical results revealed that among Matrix with different length and support degrees, the proposed method with Matrix (2, 40) outperforms others. We also find that with the increase of the length of frequent itemset, the performance decreases. Meanwhile, with the increase of support     degree, the performance increases first, and then decreases. Furthermore, compared with OTMM, our proposed method can get better performance. So, it indicates that the proposed frequent itemset method can improve the efficiency and effectiveness of the research proposal grouping process, and the proposed method can be used as a potential alternative to cluster research proposals.

In addition, this study also has some research questions for future studies. Firstly, to validate our proposed method, some additional experiments can be done using different dataset from other disciplines, and different number of research proposals in one discipline. Second, when research proposals are grouped, expert evaluation can be carried out to find proper match between reviewers and proposal groups, and then reviewer assignment can also be considered.

Thirdly, when dealing with the proposal grouping problem, the document structure characters of research proposals may also be considered, such as title, abstract and references, to improve the grouping quality. Finally, the proposed methodology can also be applied to other research fields, especially to text clustering problem.

Acknowledgement  The authors would like to thank the minitrack chair and the anonymous reviewers for their valuable comments and suggestions which have helped immensely in improving the quality of the paper. This work was supported in part by National Natural Science Foundation of China under Grant (No.

71001103), Beijing Natural Science Foundation under Grant (No. 9122013) and Program for Excellent Talents in Beijing.

