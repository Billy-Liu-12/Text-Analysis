Deriving Fuzzy Discretization from Interval Discretization

Abstract - We examine two methods for deriving fuzzy discretization from interval discretization for classification problems. One method uses linear membership functions with trapezoidal shape. The other extends them to piecewise linear functions. In both methods, we use a control parameter that specifies the overlap grade between adjacent membership functions. The overlap grade can he viewed as the fuzzification grade of interval discretization. Through computer simulations, we examine three interval discretization methods from which fuzzy discretization is derived equal width intervals, equal frequency intervals, and minimum entropy intervals. We extract fuzzy rules for wine data and sonar data with many continuous attributes. Simulation results show that the classification ability of fuzzy rules is improved in some cases and degraded in other cases by the increase in the fuzzification grade.



I. INTRODUCTION  When our knowledge extraction task involves numerical data with continuous attributes, each attribute is usually discretized into intervals [ 11, [2]. Interval discretization has been used for handling continuous attributes in many machine learning techniques such as decision trees (31, [41. In some situations, human knowledge is exactly based on interval discretization of continuous attributes. For example, the domain of our ages is?divided into two intervals by the threshold age 20 in the following knowledge ?People under 20 are not allowed to smoke.? In other situations, the discretization into intervals is not appropriate for describing human knowledge. For example, we usually use linguistic terms for dividing our ages into some categories (e.g., young, middle-aged, and old). Such a linguistic term cannot be appropriately represented by an interval because there is no clear boundary between linguistic terms. A mathematical framework for representing linguistic terms is fuzzy logic.

Fuzzy logic is a convenient tool for handling continuous attributes in a human understandable manner. Many approaches have been proposed for extracting interpretable knowledge in a form of linguistic rules from numerical data (e.g., [5l-[Sl). Those studies usually assume that a set of linguistic terms is given for each attribute. That is, it is assumed that each attribute has already been partitioned into some linguistic terms. In real-world applications, fuzzy discretization is not always available. Our idea in this paper is to utilize interval discretization methods investigated in many studies [11-[4] for generating fuzzy discretization.

We use fuzzy rules of the following type for pattern classification problems with n attributes [9]:  Rule R,: If xI is Aql and ... and x, is A, then Class C, with CF,, (1)  where R, is the label of the qth fuzzy rule, x = (xI. ... , x n )  is an n-dimensional pattern vector, A,, is an antecedent fuzzy set for the ith attribute, Cq is a class label, and CF, is a rule weight. The consequent class Cy and the rule weight CFq are specified from training patterns in a heuristic manner [9]- [ll]. The fuzzy rule R, can be viewed as a fuzzy association rule A, s Cy where A, is the antecedent fuzzy vector A, = (Aq1, ..., A q n ) .  The confidence and support of fuzzy association rules are calculated by extending their standard definitions [I21 to the case of fuzzy discretization [SI, [13].

In this paper, we show how fuzzy discretization can be derived from interval discretization. We examine two methods for deriving fuzzy discretization. One is based on linear membership functions with trapezoidal shape [13], [14].

The other extends them to piecewise linear functions. In both methods, we use a control parameter that specifies the overlap grade between adjacent membership functions. The overlap grade can he viewed as the fuzzification grade of interval discretization. Interval discretization is a special case of fuzzy discretization where the overlap grade is zero.

This paper is organized as follows. In Section 11, we briefly describe a heuristic method for determining the consequent class and the rule weight of each fuzzy rule. Then we explain some advantages of fuzzy discretization in Section 111. Two methods for deriving fuzzy discretization from interval discretization are explained in Section IV. In Section V, we examine the effect of the fuzzification of interval rules through computer simulations on wine data and sonar data using various values of the overlap grade. Finally Section VI concludes this paper.

11. FUZZY RULE-BASED CLASSIFICATION  A. Fuzzy Rules Let us assume that we have m labeled pattems  x p  = ( x p l  ,..., x p n )  fromMclasses(p=1,2 ,.... m ) .  Wedenote the set of these training pattems as D = (x,. ..., x n l )  . We define the compatibility grade of each training pattern xp with the antecedent part A, of the fuzzy rule A, 3 C, using the product operator as   mailto:yama)@ie.osakafu-u.ac.jp   P A q ( x p ) = P A q ~ ( x p l ) . P A q ~ ( x p 2 ) '  '" . f i A q n ( X p n ) ?

where f iA , ( . ) is the membership function of the antecedent fuzzy set Aqi . Let D(A,) be the fuzzy set of compatible training patterns with the antecedent part A,.  Then the total compatibility grade with A, is calculated as  (3)  where I D(A,) I is the cardinality of the fuzzy set D(A,) .

training pattern x p  with the fuzzy rule R, as Using (2), we define the compatibility grade of each  Let D(A,)nD(C,) be the fuzzy set of compatible training pattems with both A, and C,  . Then the total compatibility grade with both A, and C,  is calculated as  The confidence c(A, 3 C,) of the fuzzy rule A, a C, is defined as follows [SI, [12], [131:  On the other hand, the support s(A, a C,) is defined as  E. F u u y  Rule Generation The antecedent part A, of the fuzzy rule A, 3 C, is  constructed by combining antecedent fuzzy sets for n attributes. For low-dimensional pattem classification problems, it is possible to generate fuzzy rules corresponding to all combinations of antecedent fuzzy sets. When each attribute is divided into Kj antecedent fuzzy sets ( i  = 1,2,..4), the total number of combinations of antecedent fuzzy sets is K 1 . K z .  ... .IC, . It is impractical to use all fuzzy rules corresponding to those combinations in a single fuzzy rule-based system for a high-dimensional pattern classification problem. Moreover it is difficult for human users to intuitively understand long fuzzy rules with many antecedent conditions. Thus we only generate short fuzzy rules with a few antecedent conditions. The number of antecedent conditions of each rule is referred to as the rule length in this paper.

The consequent class C, is determined as the class with the maximum confidence for the antecedent part A, :  c(A, 3 C,) = max[c(A, =Class h )  I h = 1.2, ..., M I .  (8) While the confidence c(A, = C,) can be directly used as  the rule weight CF, of the fuzzy rule A, - C ,  , our preliminary computer simulations showed that better results were obtained from the following definition than the direct use of c(A, a C , )  when we use a single winner-based fuzzy reasoning method for pattern classification [ 121.

M  h=l h#Cq  CF,=c(A,*C,)- C c ( A , j C l a s s  h ) .  (9)  This definition of CF, can be easily understood if we consider the case of M = 2.  In this case, CF, is written as  CF, = c(A, =Class 1) - c(A, Class 2), if C,  =Class 1, c(A, 3 Class 2) - c(A, = Class l), if C, =Class 2.

(10) C. Fuuy  Reasoning for Pattern Classification  Let S be a set of fuzzy rules of the form in (1). We use a single winner-based method for classifying new pattems. The winner rule R ,  is chosen from S for a new pattem x p  as  i  PA,,, (X,). CF, = max { PA, ( X p )  ' CF, I R, E s 1 . (1 1) That is, the winner rule R, has the maximum product of the compatibility grade and the rule weight. The new pattern x p is classified as the consequent class of the winner rule R,,, .

111. ADVANTAGES OF FUZZY DISCRETIZATION  In our former studies [13], [14], we examined the effect of the fuzzification of interval rules on their classification performance using linear membership functions with trapezoidal shape. Some advantages of fuzzy discretization over interval discretization were demonstrated in those studies. In this section, we briefly explain those advantages, which are examined further in Section V through computer simulations.

A. Advantages in Ruk  Generation Phase The main characteristic feature of fuzzy discretization is  the existence of the overlap between adjacent fuzzy sets. On the other hand, there is no overlap in the case of interval discretization. This difference is illustrated in Fig. 1 where 14 training pattems are given in the two-dimensional pattem space [O, 11'. The pattem space is divided into 25 regions.

We assume that each region has a single rule. In Fig. 1 (a) with fuzzy discretization, 22 fuzzy rules in the shaded cells are compatible with at least one training pattem. This means that those rules can be generated from the training pattems.

On the other hand, only nine rules are compatible with at least one training pattern in the case of interval discretization in Fig. 1 (b).

750 The IEEE International Conlerence on Fuzzy Systems    Class 1 0 Class 2 1 0  0 0  . . . .

I , , ,  (a) Fuzzy discretization.

1.0  0.0 ' M S ' M  I M L '  . , ,  AHIH,H;A  (b)  Interval discretization,  Fig. 1. Generated rules from the given training patterns.

As shown in Fig. I ,  much more fuzzy rules can be generated from a small number of training patterns than the case of interval discretization. This characteristic feature has a large effect on the classification ability of rules when only a small number of training patterns are available in the pattern space with fine discretization.

Another advantage of fuzzy discretization is that more training patterns are involved in the generation of each fuzzy rule than the case of inferval discretization. Let us consider the rule ( M ,  M ) =  Cq in Fig. 1. In the case of interval discretization, the consequent class C, is determined as Class 2 by the three training patterns in the small square at the center of Fig. 1 (b). On the other hand, the consequent class C, is determined as Class 1 from the five training patterns in the dotted square at the center of Fig. 1 (a) in the case of fuzzy discretization. As shown in this example, more training patterns are involved in the determination of the consequent class of each fuzzy rule than the corresponding interval rule. This may help fuzzy rules to avoid the overfitting to training patterns.

B. Advantages in Classification Phase Characteristic features of fuzzy discretization in the  classification phase stem from the fact that multiple fuzzy rules overlap with one another in the pattern space. In general, each fuzzy rule covers a much larger region than the corresponding interval rule. For example, the fuzzy rule ( M ,  M )  =, Cq covers the large dotted square at the center of Fig. 1 (a) while the corresponding interval rule covers the smaller square at the center of Fig. 1 (b). The difference in the size of covered regions between fuzzy and interval rules leads to the difference in their classification ability. Better results are usually obtained from fuzzy discretization than interval discretization when only a small number of long rules are used in a high-dimensional pattern space with fine discretization.

The classification boundary is determined by the rule weight of each fuzzy rule in addition to its antecedent fuzzy sets in the case of fuzzy discretization [IO], [l I ] .  On the other hand, the classification boundary is determined by the threshold values (i.e., lower and upper limits of each interval) in the case of interval discretization. This suggests that the use of fuzzy discretization may improve the classification ability of rules &ugh rule weights when interval discretization is not fine-tuned.

IV, DERIVING FUZZY DISCRETIZATION  Let us assume that the domain interval [O, 11 of an attribute is divided into K intervals ( I , ,  1 2 .  ..., I K ) .  Each interval I j is denoted by its lower limit I j  and upper limit U, as I j  = [ I j , u j ]  where 1, = 0 ,  uK = I ,  and u j  =1,+1 for j =  1,2 ...., K - 1 .  Our task is to derive K fuzzy sets [ A , ,  A, ,  .... A K J from the given K intervals (i.e., to derive fuzzy discretization from interval discretization).

A. Fuzzy Discretimtion with Linear Membership Functions First we briefly describe a specification method of linear  membership functions with trapezoidal shape, which are extended to piecewise linear functions in the next subsection.

As shown in  Fig. 2, we denote each trapezoidal membership function A, by its four parameters as A ,  = ( a j .  b j ,  c j .  d j ) .

a, I b, cj ! 4 j  I,., 1 4 1 Ij+l I ,  *I  Fig. 2. Trapezoidal membership function of the luzzy set A     The fuzzy discretization {A, ,  A,, ..., A,) is derived from the interval discretization [ I , ?  I,. ..., 1 , )  based on the following constraint conditions (see Fig. 2):  (a) Membership functions are linear.

(b) The sum of neighboring membership functions is 1.

(c) Crossing points of neighboring membership functions  coincide with the threshold values in the interval discretization.

(d) The membership function of each intermediate fuzzy set (i.e., A, , A , ,  ..., AK-, ) is 1 at the midpoint of the corresponding interval. The membership function of the smallest (i.e., left-most) fuzzy set AI is 1 at the lower bound of the domain interval [O, I]. The membership function of the largest (i.e., right-most) fuzzy set A, is 1 at the upper hound of the domain interval [O, I].

It should be noted that these constraint conditions do not uniquely determine the fuzzy discretization { A l ,  A,, ..., A,) .

Fig. 3 (b) is an example of partially fuzzified discretization while Fig. 3 (a) shows fully fuzzified discretization. Fully fuzzified discretization is obtained by maximizing the overlap grade between adjacent membership functions under the four constraint conditions (see [131, [ 141 for details).

We denote the overlap grade (i.e., fuzzification grade) by F where F = 1 and F = 0 mean the maximum overlap and no overlap, respectively. Let AT = ( a $ ,  b f .  c f .  d f )  be thejth trapezoidal fuzzy set Ai with the overlap grade F. In the case of F = O ,  A: = ( a ! ,  by, cy ,  dp) is the same as the interval I j = [ l j . u j ] :  n ? = b y = l j  and cy=d~=u j .The t r apezo ida1 fuzzy set A? = ( a y ,  bf, c r .  d r )  with an arbitrary overlap grade F can be generated from the interval I j  (i.e., AY) and the fully fuzzified fuzzy set A: as  (12)  (13)  a j  F O I  = a j  + ( a j  - a q ) F ,  bF J =bo J + (b! J l  - b o ) F  ,  (14) c F = c Y + ( c ) - c j ) F ,  0  df = d g t ( d j - d j ) F .  I O  (15) Actually Fig. 3 (b) was depicted using these formulations for F = O S  from the fully fuzzified discretization and the interval discretization in Fig. 3 (a).

- 1.0 0-.0 0.0 113 U3  (a) Fully fuzzified discretization. @I) Partially fuzzified one.

Fig. 3. Two examples of fuzzy discretization.

B. Fuuy Discretization with Piecewise Linear Functions When interval discretization includes very narrow intervals,  the derived fuzzy discretization does not have large overlap regions even in the case of fully fuzzified discretization with F = 1. This is illustrated in Fig. 4 (a) where fully fuzzified discretization is generated from interval discretization including two very n m o w  intervals. It is somewhat counter- intuitive to consider Fig. 4 (a) as being fully fuzzified because the first, third and fifth fuzzy sets are similar to intervals. Thus we extend trapezoidal membership functions to piecewise linear ones as shown in Fig. 4 (b) where the first, third and fifth fuzzy sets are denoted by bold lines. Among the above-mentioned four constraint conditions (a)-(d), we relax only the first condition from ?Membership functions are linear? to ?Membership functions are piecewise linear. ? We still use the other constraint conditions (b)-(d).

(a) Linear functions. (b) Piecewise linear functions.

Fig. 4. Comparison of two methods for deriving fuzzy discretization from interval discretization.

As shown in Fig. 5, we denote the piecewise linear membership function of the jth antecedent fuzzy set A j using its six parameters as Aj = ( a j ,  I j ,  bi, ci. u j .  di). Since the 0.5-level set (i.e., a - c u t  at a = O S )  of Aj is always the same as the corresponding interval I j  = [ I j .  u j ]  from the constraint conditions (b) and (c), the second and fifth parameters ( i t . ,  I j  and u j )  are independent of the value of F. On the other hand, the other four parameters depend on the overlap grade F as in (12)-(15).

aj 4 cj I 4 j  4 ??1 Fig. 5. Piecewise linear membership function of the fuzzy set A j .

I,-, 4 j r,+,  The fully fuzzified discretization ( A i ,  A i ,  ..., A h )  is derived from the interval discretization ( I I ,  I,, _.., I,) as     d'. 1-1- -b* j -  - ~ ' . = a ~ + ~ = ( l ~ + u j ) / 2 ,  j = 2 , 3 ,  ..., K - 1 ,  (17)  Partially fuzzified discretization [A:, A:, .:., A i )  with an arbitrary value of the overlap grade F is derived from the fully fuzzified discretization [Ai ,  A i ,  ..., A:) with F = 1 and the interval discretization (A: ,  A;, ..., A ! )  with F = 0 (i.e., {II, I, ,..., I,))inthesamemanneras(12)-(15).



V. COMPUTER S m A T I O N S In this section, we examine the effect of the fuzzification  of interval rules on their classification ability through computer simulations using various values of the overlap grade F. For specifying interval discretization from training patterns, we employed three discretization methods: equal width intervals, equal frequency intervals, and minimum entropy intervals (for details, see [2]). We used two data sets with many continuous attributes available from the UC lrvine Machine Learning Repository: wine data with 13 continuous attributes and 178 samples from three classes, and sonar data with 60 continuous attributes and 208 samples from two classes. All the given samples are used as training patterns.

A.  Simulation Conditions W e  first generated interval discretization for each attribute.

One of the three. methods for interval discretization was employed in each computer simulation for dividing the domain interval of each attribute into K subintervals. The number of intervals (i.e., K )  was specified as K 7 2,3,4,5.

That is, four interval partitions with different granularities were generated. Then one of the two methods for fuzzy discretization was used for generating antecedent fuzzy sets with a pre-specified value of the overlap grade F. In this manner, we generated four fuzzy partitions including 14 antecedent fuzzy sets in total for each attribute. Since we used "don't care" as an additional antecedent fuzzy set, the total number of combinations of antecedent fuzzy sets was (14 + 1)" for an n-dimensional pattern classification problem.

We only examined short fuzzy rules with a few antecedent conditions (i.e., with many don'r care conditions) in order to find comprehensible rules. For the wine data, we examined fuzzy rules of the length three or less. For the sonar data, we examined fuzzy rules of the length two or less. We used the product of the confidence and the support as a heuristic rule selection criterion. That is, N rules with the largest values of this criterion were selected for each class. The heuristic rule selection was independently performed for each value of the overlap grade F. Thus different rules might he selected for different values of F.

As we have already mentioned in Section 111, fuzzy discretization has several advantages when the pattern space is divided into small regions (i.e., when the granularity of the discretization is fine). In our computer simulations, we simultaneously used four different granularities (i.e., K = 2.3, 43) .  This means that some antecedent fuzzy sets of different size overlap with one another even when the overlap grade F was very small. The use of such multiple partitions with different granularities decreased the superiority of fuzzy discretization over interval discretization. The use of all training patterns for generating interval and fuzzy rules also decreased the superiority of fuzzy discretization. Moreover interval discretization was specified from training patterns using heuristic criteria (i.e., equal width, equal frequency, and minimum entropy) while fuzzy discretization was not generated from training patterns. Thus the simulation conditions somewhat favor interval discretization. As shown in [14], the superiority of fuzzy discretization can be easily demonstrated i f .  we use tine discretization and a small number of training pattems. In this paper, we examine the effect of the fuzzification of interval rules on their classification ability using the above-mentioned conditions that somewhat favor interval discretization.

E. Simulation Results We report simulation results for the cases of N = 1 (i.e.,  only a single rule was selected for each class) and N = 2  (i.e., only two rules were selected for each class). Eleven values of the overlap grade F were examined: F = 0.0, 0.1, ..., 1.0.

Simulation results on the wine data are summarized in Fig. 6 for N = 1 and Fig. 7 for N = 2.  On the other hand, simulation results on the sonar data are summarized in Fig. 8 for N = 1 and Fig. 9 for N = 2.

When F = 0.0, the best results were obtained by minimum entropy intervals on the average (i.e., the left-most triangles in Figs. 6-9). The main drawback of this discretization method is long computation time. The worst results were obtained by the discretization with equal width intervals (i.e., the left-most squares), which requires the least computation time. On the other hand, when we fuzzified interval discretization (i.e., F > O  ), good results were not always obtained by fuzzy discretization generated from minimum entropy intervals. For example, the best results were obtained from equal frequency intervals in Fig. 6 when F = 1.0 (i.e., the right-most circles). This suggests the possibility that good results can be obtained without spending long computation time on discretization when we use fuzzy discretization. The fuzzification of interval discretization improved the classification rates in many cases in our computer simulations on the wine data in Fig. 6 and Fig. 7. On the other hand, the fuzzification degraded the classification rates in many cases for the sonar data in Fig. 8 and Fig. 9.

& Emropy & Li- U Frequency &Linear-*-- Frequency & Piecewise Linear + Width & Linear  --A-- Entropy & Piecewise Linear  --D-- Width & Piecewise Lima  A.--&..A...p - .

- c e! 95 c I % 90 D  ?P  8 5 L : o ?  ? ? ? 0.5 ? ? ? ? ? 1.0 ? Overlap grade ( E )  Fig. 6. Simulation results on wine data using three rules ( N = 1)  85 - 0.0 0.5 1.0  Overlap grade (0 Fig. 7. Simulation results on wine data using six rules ( N = 2).

8 0 1 ?  ? ? ? ? 8 ? ? ? ? ?1  5 0 ?  ? ? ? ? ? ? ? ? ? ? 0.0 0.5 1.0  Overlap grade (0 Fig. 9. Simulation results on sonar data using four rules ( N = 2).



VI. CONCLUSIONS In this paper, we examined two methods for deriving fuzzy  discretization from interval discretization. From computer simulations using various values of the overlap grade between adjacent membership functions, we obtained mixed results with respect to the effect of the fuzzification of rules on their classification ability. That is, the classification ability was improved in some cases and degraded in other cases by the increase in the overlap grade.

REFERENCE  [l]  U. M. Fayyad and K. B. Irani, ?Multi-interval discretization of continuous-valued attributes for classification leaming.? Proc. of 13th International Joinr ConJ on Anificial Intelligence, 1022- 1027,1993.

[21 T. Elomaa and J. Rousu, ?General and efficient multisplitting of numerical attributes.? Machine Learning 36,201-244, 1999.

[31 J. R. Quinlan, C4.5: Programs for Machine Learning, Morgan Kaufmann, San Mateo, 1993.

[41 J. R. Quinlan, Improved use of continuous attributes in C4.5.

Journal of Anificial Intelligence Research 4,77-90, 1996.

[SI L. Castillo, A. Gonzalez, and R. Perez, ?Including a simplicity criterion in the selection of the best rule in a genetic fuzzy learning algorithm? Fuzzy Sers and Sysrpmr 120, 309-321, 2001.

[61 L. Castro, J. I. Castro-Schez, and I. M. Zurita, ?Use of a fuzzy machine learning technique in the knowledge acquisition process.? F u u y  Sers and Systems 123, 307-320.2001.

[71 J. Casillas, 0. Cordon, M. I. Del Jesus, and F. Herrera, ?Genetic feature selection in a fuzzy rule-based classification system learning process for high-dimensional problems,? Informarion Sciences 136,135-157,2001.

[8] T. -P. Hong, C. -S. Kuo, and S. -C. Chi, ?Trade-off between computation time and number of rules for fuzzy mining from quantitative data,? Internarional Journal of Uncenoinry.

Fuzziness and Knowledge-Based Systems 9.587-604,2001,  [91 H. Ishibuchi, K. Nozaki. and H. Tanaka, ?Distributed representation of fuzzy rules and its application to pattem classification,? Fuzzy Sers and Sysrems 52.21-32, 1992.

[IO] H. Ishibuchi and T. Nakashima, ?Effect of rule weights in fuzzy rule-based classification systems,? IEEE Trans. on F u u y Systems 9, 506-515,2001.

[ I  11 H. lshibuchi and T. Yamamoto, ?Comparison of heuristic rule weight specification methods,? Proc. of 2002 IEEE International ConJ on F u w  Sysrems, 908-913.

[12] R. Agrawal et al., ?Fast mscovery of association rules,? in U.

M. Fayyad et al.(eds.): Advances in Knowledge Discovery and Data Mining, AAA1 Press, Metro Park, 307-328, 1996.

[I31 H. Ishibuchi, T. Yamamoto. and T. Nakashima, ?Fuzzy data mining: Effect of fuzzy discretization,? Proc. of 2DDI IEEE Inremarional Cony? on Data Mining, 241-248.

1141 H. lshibuchi and T. Yamamoto, ?Performance evaluation of fuzzy partitions with different fuzzification grades,? Proc. of 2002 IEEE Inremational Cony? on F u u y  Systems, 1198-1203.

