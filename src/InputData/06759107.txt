Investigations into Consumers Preferences Concerning Privacy:

Abstract Online privacy is becoming an increasingly im-  portant topic, and an increasingly controversial one.

The EU is imposing strict limitations on the use of data obtained from its citizens? online activities [9], while Big Data advocates and online advertisers in the United States are concerned that this may represent interference in their basic business models or even in international trade [13].

It is clear that laws and regulations are incon- sistent across national borders.  They are also incon- sistent within nations, depending on the industry clas- sification of companies, or even the designation given to specific technologies.  ISPs are prohibited from reading subscribers? email; other information services companies can do so legally.  Data stored electroni- cally is offered protection that is denied to data stored in the cloud.

This paper proposes that regulatory confusion be addressed starting with some basic principles of uni- formity.  More importantly, it suggests that regulation be driven by what consumers actually want, and pro- vides some preliminary research aimed at determining what consumers want from privacy regulation around the world.

1. Introduction Consumer privacy legislation has received a great  deal of attention globally.  The EU, Japan, Korea, Malaysia, and many other nations are actively review- ing their policies towards online privacy1.  The US has preferred to allow the online information services industry to regulate itself, and the FTC has convened a meeting of the W3C to determine if an acceptable policy could be developed without active involvement by the Congress, the FTC, the FCC, or other regulatory bodies [11,14,17].  To some extent, this activity has been prompted by concerns about what companies like   1 On May 25, 2013 Peking University Law School hosted a workshop on the future of Internet regulation, with a significant focus on the future of privacy regula- tion.  On May 30th and 31st Keio University and Korea University hosted a workshop on Big Data, with a session on the future of privacy regulation in Asia.

On June 3, Tokyo University held a workshop on privacy and privacy regulation in Japan.

Google, Facebook, and AT&T in the US, Softbank and NTT in Japan, Daum and KT in Korea, and other large information services and communications firms might be able to do.

Paradoxically, the recent (June 2013) surge in in- terest in, and outrage over, potential online privacy abuse in the United States has been prompted by reve- lations from a former CIA employee and former NSA consultant about widespread abuse of privacy by the National Security Agency.  Allegedly the NSA has been monitoring our calls.

We say paradoxically because there has been wide- spread outrage over what the NSA has been doing [20,28,31], in the name of national security [32], with only limited supervision by the Foreign Intelligence Surveillance Court [30].  And yet, there has been virtually no concern in the US over what Google and Facebook have been doing, sometimes far more exten- sive than the privacy abuses of the NSA, in the interest purely of corporate gain, and with no supervision whatsoever.  Indeed, there has been more concern over the NSA?s alleged abuses than there was over Google?s admitted violations of its own privacy poli- cies [3,6] and more outrage over the NSA?s alleged abuses than there was over Google?s admitted viola- tions of its signed consent decree after its initial viola- tions.

Our intent with this paper is to provide a sound ba- sis for public policy concerning privacy, in the US and abroad.  In order to provide such a sound basis, we conducted surveys and focus groups, in the US, Japan, Korea, and German, concerning consumers? attitudes towards the privacy policies of large information services firms.  We explored both consumers? aware- ness of specific potential activities in which these large information services firms might engage and consumers? approval of those activities, whether or not firms actually engaged in them.  We also explored consumers? attitudes towards the degree of privacy protection they believe they received from their regula- tory systems.  Finally, we explored parents? attitudes towards data mining of their children?s email accounts, including school email accounts.  This work as yet has been completed only in the US and Japan.

Our research is motivated by the following beliefs: ? Technology has rendered traditional relationship  between personal identifiers and private infor- mation largely irrelevant.  We discuss this in sec-   DOI 10.1109/HICSS.2014.504       tion 3 below.

? Regulations are largely inconsistent and have not  kept pace with technology driven changes in the marketplace for information services.  There are two ways in which regulations have created a gap in which non-traditional information services com- panies act with limited regulatory oversight.  We discuss this in section 4, below.

We believe that regulatory protections for consum- ers should be the same, regardless of the company or carrier being regulated.  Regulations generally place meaningful restrictions on telecommunications com- panies and other common carriers, because their capa- bilities and the dangers to privacy that they represented were well understood.  Laws, sometimes even consti- tutional protections, limit the ability of postal services and telecommunications companies to read their cus- tomers? messages, eavesdrop on their customers? conversations, or even use the logs of customers? conversations to track their behavior.  These protec- tions have been extended to protect forms of commu- nication that were unanticipated by the framers? of these regulations, such as email messages carried by common carriers.  In contrast, most information ser- vices companies, such as Facebook, Google, and Microsoft, face no similar restrictions on their use of customers? information.

We believe that regulatory protections for consum- ers should be simple, reasonable, and what the cus- tomer would expect.  They should be driven by the need to provide meaningful and modern protection, and not driven by regulators? interpretation of and attempt to apply inapplicable legislation or precedent.

Once again, regulations are largely inconsistent and have not kept pace with technology driven changes in the marketplace for information services. It is clearly reasonable that conversations overheard because the speaker made no attempt to protect the conversation cannot be considered private or protected.  It is clearly not reasonable that, by extension, email conversations that have been overheard for the same reasons cannot be considered private or protected.  There is no plausi- ble rationale for arguing by extension that the text messages on a phone are not private because reading them is no different from overhearing a conversation [18].  There is likewise no plausible rationale for arguing that although email stored on a vendor?s elec- tronic storage is private and protected because it is covered by laws regulating the electronic storage of data, but the same email is not private and protected if stored in the cloud, because the cloud is not electronic storage [21,33].

Most importantly for the contribution of this paper, we believe research into the privacy protections that consumers want and expect online if fundamental to privacy policy.  If privacy policy is to be simple, rea-  sonable, and consistent with consumers? preferences, it must be informed by an understanding of those prefer- ences.  The principal contribution of our paper is an analysis of what consumers want and expect from privacy protection, based on our ongoing research around the world.

Our research findings can be summarized as fol- lows:  (1) Consumers mostly do not know what search engines and other data intermediaries are doing with their data, and mostly they know that they do not know.

(2) Consumers mostly do not approve of the major- ity of the practices of online service vendors when they use consumers? data.  This is captured through ques- tions such as, ?If it were true that Google did track your searches, would you approve or disapprove?? or ?If it were true that your service provider did read your texts, would you approve or disapprove??  The vast majority of consumers disapproved or strongly disap- proved of most forms of the use of their online data, no matter what activities resulted in the capture of that data.

(3) Consumers? silence regarding privacy practices and the use of their data by information services firms does not represent consent, and most certainly does not represent informed consent.  We use the term ?in- formed consent? to refer to those consumers who are aware of a practice online and who also approve of that practice.  Our data suggests that informed consent is very limited, on the order of 0-1%, for all forms of online privacy abuse.  The data are largely consistent across populations surveyed in the US, Japan, Korea, and Germany  (4) Consumers by overwhelming majorities support the position that actually protecting consumers? priva- cy online should be the default setting on browsers and email services, and on linking online activities with text or GPS information obtained from the user?s phone.  There was even stronger support for the posi- tion that any privacy settings a consumer had chosen to protect privacy, whether set explicitly by the consumer or set implicitly by accepting default settings, should be honored by online service providers.  To be clear, consumers believed that the default settings should be do not track individual services and do not integrate across multiple services, and that these default settings should be honored by all online service providers.

(5) Consumers do not believe that regulators are doing enough to inform them about online risks to their privacy and consumers do not believe that regula- tors are doing enough to protect them from online risks to their privacy.

(6) Consumers have equally strong views about protecting the privacy of their children from data mining activities of information services vendors.

(7) Consumers? feel strongly about protecting the privacy of their children from data mining.  They continue to feel strongly even if the email service provider offers email without charge in exchange to the right to perform data mining..

We do believe that public policy is important for two reasons:  (1) Many consumers, including the youngest con- sumers, do not appear to be fully aware of the privacy risks they create for themselves.

(2) Until the recent incident with the NSA, con- sumers did not appear to be greatly concerned with privacy risks, and even after the NSA disclosures, most consumers appear to be more concerned with the potential of governmental abuses stemming from governmental privacy intrusions than the potential for corporate abuses stemming from far more pervasive corporate privacy intrusions.

We suspect that dealing with this public policy ex- plicitly is important, and that the results of this survey are important, because it contradicts the young, hip, blogosphere.  When Microsoft tried to create public awareness of and public interest in the problems of privacy violation [26], TechCrunch and its readers found the subject just silly [29].  To the best of our knowledge, ours is the first study that attempts to gather opinion from a range of subjects.

This paper is structured as follows:  Section 2 pro- vides alternative definitions of privacy and of inva- sions of privacy.  Section 3 provides a brief review of the regulatory gap in which most information services companies, other than common carriers and telecom- munications providers, currently operate.  Section 4 describes the ?myth of anonymization?; despite popu- lar belief to the contrary, anonymous ads are not anon- ymous, better targeted ads are not better for you, and clicking on targeted ads can hurt you.  Section 5 de- scribes our experimental design for our first survey, which assessed consumers? attitudes towards protect- ing their own privacy.  Section 6 summarizes our findings from our first experiment, summarizing con- sumers? attitudes towards protecting their own privacy.

Section 7 describes our experimental design for our second survey, which assessed consumers? attitudes towards protecting their children?s privacy.  Section 8 summarizes our findings from our first experiment, summarizing consumers? attitudes towards protecting their own privacy.  Section 9 concludes the paper.

2. Defining Privacy There are at least three different ways to character-  ize privacy and online invasions of privacy [2,8,24,38]:  (1) Perhaps the least threatening form of privacy violation is represented by an uninvited intrusion into a user?s personal space.  Online marketing, spam adver-  tising, pop-ups, and sponsored sites around the edges of a web-page can all be seen as invasions of the user?s personal space.  Our focus groups indicated that this was the form of privacy violation most salient in users? minds, across age groups and across nations.  When users thought of privacy violations from their email, phone, search, or social network providers, they thought almost exclusively about unwanted ads and unwanted interruptions.  That is, they thought of priva- cy violations in terms of unwanted knocking on a hotel room door when a ?Privacy Please? sign was visibly hanging from the doorknob.

(2) Surely the most extreme and most threatening form of privacy violation is represented by fraudulent ecommerce transactions, or even by identity theft.

There is no indication that Google, Daum, Navor, Yahoo, or Bing have been associated with such threats to privacy, and there is no indication that consumers were concerned about this.

(3) And surely the form of privacy violations most important to Google, Daum, Navor, and Yahoo are based on personal profiling for some form of commer- cial advantage.  This is definitely an intermediate form of privacy violation.  It is far more than simply an invasion of personal space, and far less than identity theft.  It involves uniquely identifying an individual and associating him with one or more characteristics of interest to an advertiser.  The advertiser?s intent may be benign; the firm simply wants to know everyone interested in visiting Osaka, or everyone interested in buying a food processor; this simply results in being sent ads for flights of interest, or products of interest.

The advertiser?s intent may also be less benign; the advertiser wants to know who engages in risky hobbies, so that he can avoid offering life insurance at rates that are too low, or who desperately needs to get to Chica- go, so he can offer higher airfares.

Interestingly, consumers participating in our focus groups in Japan and Korea initially seemed to focus solely on the first form of privacy violation, the unin- vited intrusion into personal space through various forms of spam and targeted marketing.  A few hypo- thetical examples of integration and profiling were sufficient to arouse consumers? concerns.  What if your phone tracked your position and it was clear that you now had a new geographic center of activity, your home, your office, your favorite restaurants, and the apartment of your new girlfriend?  What if the phone read your text and knew whom you were seeing for lunch?  What if it started suggesting her favorite res- taurants to you?  What if it accidentally started sug- gesting your new girlfriend?s favorite restaurants to your friends?  What if it accidentally started suggest- ing your new girlfriend?s favorite restaurants to your other girlfriend?

A participant at one of the focus groups got truly       agitated when one of the other participants described targeted ads based on his search history.  He suddenly realized that shortly after he was diagnosed with can- cer he started to get email ads for cancer treatments, nursing care, and hospices.  He realized that this was not simply coincidence and random spam; his search engine provider had made his most personal and sensi- tive medical history public, based on his searching for information on his specific form of cancer.

Participants at focus groups changed their attitudes towards privacy violations as they considered increas- ingly intrusive hypothetical examples of data mining and data integration.  While these hypotheticals even- tually became quite intrusive, none actually violated the published privacy policies of major search engine providers.  Subjects came to realize during the course of the focus groups how much their search engine providers know.  Moreover, they came to believe that if your search engine provider knows who you are and where you are and what you are going to do next and with whom you are going to do it, this is potentially compromising.  This is potentially compromising, no matter who you are, and no matter how unexceptional your life might appear at the moment.

Since participants became increasingly aware of the full range of potential privacy violations only as the focus groups progressed, we believe that the level of awareness among survey subjects was actually lower than the level of awareness of focus group par- ticipants.  We thus believe that the survey results are actually weaker than they appear and actually under- state levels of concern among online users.  Although the survey results appear quite strong, they understand concerns because they are based upon subjects? think- ing principally about the weakest of the three levels of privacy violation.

3. Understanding the Regulatory Gap in Which Information Services Compa- nies Operate  Information services companies operate in a regu- latory vacuum, created by the difference between tight privacy regulations imposed upon traditional postal carriers and telecommunications carriers on one side, and the almost total absence of privacy regulation on many information systems companies like Google and Facebook.

(1) A traditional postal carrier cannot read your mail, and a rogue individual mail carrier cannot inter- cept and read your US mail, nor can a curious neigh- bor; doing so is a felony.  Even government agencies cannot read your mail in the process of a criminal investigation without a court order.  In contrast, Amer- ican companies like Google and Facebook, and foreign companies like Daum and Navor, have built much of  their publicly presented business models on their right to read and data mine any and all of your writings, whether public, like a Facebook post, or private, like a gmail or a text from an Android phone.

(2) A traditional telecommunications provider, like AT&T in the US, cannot eavesdrop on your communi- cations or use your phone logs; indeed, it cannot allow a government agency to tap your phone or observe your phone call log without a court order.  In contrast, Google can use your call logs from an Android phone to assess your social network, and Google has applied for patents that would allow it convert voice to text, and thus to text mine even your private voice commu- nications.

(3) Likewise, until recently an ISP provider, like Yahoo in Japan, could not examine your communica- tions, because an ISP provider was treated as a tele- communications company; in contrast, Google Japan could do whatever it wants with the packets that it sees a user generate.  Interestingly, regulators responded to this anomaly not by protecting Google?s users from invasion of privacy, but rather by subjecting Yahoo?s users to the same risks as Google users.  Since this so evidently is counter to the preferences expressed by participants in our focus groups and surveys, we be- lieve that this provides further support for the im- portance of understanding consumers? preferences and of using consumers? preferences in the design of regu- latory regimes to protect consumers? privacy.

We believe that ?a packet is a packet is a packet? and similar packets should be treated similarly, wheth- er they are carried by a traditional postal carrier, a package delivery service, an email vendor, the users? ISPs, or the backbone network that moves that packet between ISPs.  Whether the packet is hand written on a single sheet of paper, typed onto a single sheet of paper, typed and loaded into a single SMS frame, or typed and loaded into numerous packets for delivery over the internet, users? communications should be protected.

4. The Myth of Anonymization Privacy may not be dead, but anonymization by  those who capture personal data surely is.  Despite any and all claims that an information vendor protects consumers? privacy through anonymization, this simp- ly is false.  There are two factors, completely separate, that independently are sufficient to render anonymiza- tion impossible.  Historically anonymization involved stripping off what are called personal identifiers, such as name and address and date of birth, or social securi- ty number, or other combinations that uniquely identi- fy a single individual.  This is how most privacy legis- lation is written today.  Institutional Review Boards follow federal guidelines when they insist that research data be stripped of personal identifiers, and if it is       necessary to be able to identify individuals later the data and the identifying keys be encrypted and stored in separate locations.  Both factors undo the effects of anonymization that is based on stripping off unique personal identifiers.

(1) The first factor is the ability to combine dozens, hundreds, even thousands of seemingly inconsequen- tial factors, to identify an individual.  Big data elimi- nates the relationship between identity and personal identifiers.  An individual can now be uniquely identi- fied in countless ways, without the use of personal identifying information.

(2) The second factor is the ability to induce the in- dividual to identify himself, under conditions in which he would never willingly consent to do so.

Personal identifying information is no longer nec- essary for identifying an individual.  Work by Acquisti and others shows that city of birth, year of birth, and the last for digits of a social security number is gener- ally sufficient to identify an individual [1,16].  This was precisely the data that Google required to accom- pany every entry in their competition for children?s art, Doodle 4 Google [4].  No one is suggesting that Google systematically engages in identity theft target- ed at children.  And yet they clearly have captured data that are sufficient to allow them to do so.  Work by researchers at Microsoft has demonstrated that an individual?s sequence of seemingly irrelevant online ?likes? with very high probability can allow the re- searchers to identify an individual?s sex, sexual orien- tation, marital status, and religion [23].  When this is combined with a modest amount of additional infor- mation it is once again possible to identify a unique individual.

More importantly, when an individual clicks on a targeted ad, he uniquely identifies himself and associ- ates himself with the bucket of individuals with the characteristics the advertiser used to define the bucket.

We call this the paradox of anonymous ads; these ads are indeed anonymous, until the user clicks on them; at this point the user has been fully identified, by himself.

Airlines have long searched for the ?truth-o-matic? pricing system, which would enable them to charge each individual his maximum willingness to pay for each trip.  The best they can do now is to approximate by attributes that they have found are loosely sugges- tive of willingness to pay.  If I buy my ticket in ad- vance, I am willing to accept severe cancellation pen- alties, and am willing to stay for a weekend; this is probably a leisure trip, and I will be given a deep discount.  If I buy later, I am unwilling to pay cancella- tion fees, and travel mid-week; this is probably a business trip, and I will be offered higher fares.  But airlines would like to know far more, and data mining offers this.  Imagine that someone texts his best friend in Chicago and says that he is terribly bored and would  love to join him for dinner tomorrow night, if he can find a good airfare.  Now imagine that instead the same individual texts his daughter in Chicago, says that his best friend is terribly ill, asks her to find a hotel room immediately, and tells her he needs to fly to Chicago as quickly as possible.  An information ser- vices firm does not need to compromise the privacy of an individual by telling an airline that the specific individual is bored, or that the specific individual has a friend who is desperately ill.  All the information services firm needs to do is send that individual an ad, appropriate to the individual?s condition, or descriptive bucket.  As soon as the individual clicks on the ad, he identifies himself as bored, or as having a friend who is desperately ill, depending on the ad he received.  His airfare can be priced accordingly.  The truth-o-matic has been delivered.  No major university would be allowed to perform research that induced individual research subjects to identify themselves, especially if this could and would be used in ways that cause the subjects economic harm.  And yet there is no regula- tion of this behavior by the targeted advertising indus- try.  Indeed, many do not understand the problem, and argue that targeted ads are better for the consumer, because they waste less of the consumer?s time, or are at worst harmless.  They are not harmless, and do not need to be harmless.

We are not arguing that data mining is good, or that it is bad.  We are not arguing that targeted advertising is good, or that it is bad.  We are arguing that anony- mization based on the process of stripping off what are normally called personal identifying information is no longer sufficient, in the presence of data mining.  We are not arguing that targeted advertising is good, or that it is bad, or that individuals have or have not consented to receive targeted ads in exchange for free internet services.  We are arguing that when an indi- vidual clicks on a targeted ad he now uniquely identi- fies himself, and that he may be doing so in a way that unambiguously links him to a set of actions and attrib- utes with which he would never willingly link himself.

5. Experimental Design ? Experiment One  Whether or not consumers actually believe that privacy is dead, it suits the companies that exploit private information to act as if this is so.  For example, in 2010, Facebook changed its privacy policy so that its use of subscribers' private information is now the default, requiring users to opt out of publicly display- ing information and granting Facebook the right to share information with third party sites [34].  Early last year, Google changed it privacy policy, allowing it to merge all the information it has collected from any and all of its products to develop an integrated profile on all of its users [27].

The study we conducted seeks to understand the following: ? The extent to which consumers do or do not know  what information is collected, stored, and analyzed.

? The extent to which consumers do or do not know  information is stored, combined, and analyzed.

? The degree to which consumers do or do not ap-  prove of practices, whether or not they were aware of them.

? The extent to which they do or do not believe that regulators are doing an adequate job of informing them about potential threats to their privacy.

? The extent to which they do or do not believe that regulators are doing an adequate job of protecting them from potential threat to their privacy.

? Consumers? preferences about whether privacy, do not track, or do not track and integrate, should be the default.

The study2 can be viewed in some sense as an up- date of prior studies, including a study conducted by a colleague at the Annenberg School of Communication in 2005 [36].  In the intervening seven years since the Annenberg study was conducted, threats to privacy have become greater.   Facebook has grown from millions of users to hundreds of millions.  Google has acquired YouTube, and launched Chrome, Android, and Google +.  The amount of information captured and the possibility of integration of information from multiple sources is enormously greater than it was seven years ago.  Incidents like the Wi-Spy scandal have received press coverage around the world [19,15].

The abuse of privacy through Google analytics has resulted in litigation in the EU [37, 25].  Google re- cently accepted a 20-year audit because of privacy abuses during the launch of its social network, Google+ [12]. Privacy abuses are both more salient and potentially more damaging than when previous studies were conducted, and new studies are clearly warranted.

As with our prior studies on consumer trust in online shopping [5], we believe that national differ- ences in behavior are interesting.  We have therefore conducted this study in the US, Japan, Korea, and Germany.

6. Principal Findings on Consumers? Atti- tudes towards Protecting Their Own Privacy  Even working with survey subjects who we believe were principally focusing on the weakest of the three forms of privacy intrusion, we found strong disapprov- al of many common practices of online service provid-  2 U.S. (n=310), Japan (n=442), Korea (n=442), and Ger- many (n=505)  ers.  Users in general are willing to accept tracking of their searches.  They do not always know which activi- ties already occur, and they are less tolerant of tracking or monitoring many of their other online activities.

They are less comfortable with the tracking and min- ing of their texts sent (see table 1), or of texts received (see table 2).  Consumer resistance is comparably high for mining the content of emails that they send or receive (see tables 3 and 4).  Comparing tables 3 and 4 with table 5, we see that surprisingly, gmail users are both more aware of privacy intrusions and more con- cerned about these intrusions.   Table 6 shows that us- ers? acceptance of having the content of their voice communications mined is even more limited.  Finally, table 7 shows that subjects are only slightly more accepting of mining data from social networks.  As can be seen from these tables, many subjects are unaware that various intrusions either are contemplated or have already been implemented, or have a misplaced confi- dence that they have not been.  The lack of public objection therefore may be indicative of ignorance rather than indicative of approval.

Tables 8 and 9 show the extent to which consumers believe that their regulators are doing an adequate job ensuring that they are aware of the online threats to their privacy and the extent to which consumers be- lieve that regulators are doing an adequate job of protecting them from online threats to their privacy.

Two points can be observed immediately:  (1) In all four populations studied, by a large mar- gin, consumers believe that their regulators are not doing an adequate job of informing them of online threats to their privacy.

(2) In all four populations studied, by a large mar- gin, consumers believe that their regulators are not doing an adequate job of protecting them from online threats to their privacy.

Table 1. Awareness of and acceptance of min-  ing texts sent   Table 2.Awareness of and acceptance of mining  texts received        Table 3. Awareness of and acceptance of min-  ing emails sent ?   Table 4. Awareness of and acceptance of min-  ing emails received.?   Table 5. Email users? awareness of and ac-  ceptance of mining gmail.

Table 6.Awareness of and acceptance of mining  voice.

Table 7.Awareness of and acceptance of and  mining data from social networks.

Table 8.Consumers? confidence that regulators  are informing them adequately about threats to privacy online.

Table 9. Consumers? confidence that regulators  are protecting them adequately from online threats to privacy.

Our findings regarding privacy settings are summa- rized in table 10.  Our survey defined tracking as recording and analyzing a user?s behavior over time at a single website and integration as recording, integrat- ing, and analyzing all of a user?s online behavior, including search, texting, email, phone, and other activities.  Comparing the data in tables 1-7 to that of table 10, consumers appear to be much less tolerant of online tracking and integration than their behaviors and their answers to individual questions would sug- gest.  Most significantly, the data appears to be no support for Google?s position, adopted by the W3C, that a browser with DNT set as the default would not be in compliance with the standard, and thus that the privacy settings of their users could be ignored [35].

We find ourselves echoing Microsoft?s position at the W3C, ?To say that a standard cannot not support a privacy by default choice for consumers is odd to say the least.? [35]   Table 10. Consumers? attitudes towards online  tracking and integration  7. Experimental Design ? Experiment Two  The second experiment was similar to the first, ex- cept that it was aimed at assessing parents? attitudes towards data mining the email accounts of their public school students 3.  While data mining of students? accounts is prohibited by federal law [10] and by law in many states [7], the practice appears to be wide- spread, and may indeed be legal when approval is granted by the school district?s representatives.

Our second experiment had three parts: 1. A first survey was conducted, assessing parents?  attitudes towards data mining of their children?s email accounts, including a range of forms of de- tailed tracking and integration with search, texting, and other online activities.

2. A second survey was conducted, asking public school students to describe activities that they per- formed online, or were aware of other students   3 U.S. Parents (n=246), U.S. Teenagers (n=469), Japan Parents (n=300), Japan Teenagers (n=241)?       performing online.

3. A third survey was conducted, replicating the  questions asked of parents in the first survey.  In this survey, parents were first informed about what students actually did online.

The survey was performed in the United States and Japan.  Results are summarized in the next section.

8. Principal Findings on Consumers? Atti- tudes towards Protecting Their Chil- dren?s Privacy  Table 11 shows that Japanese parents are signifi- cantly less aware of the activities that are done by online information service providers than their US counterparts are.  Approximately one third are aware that searches are tracked, and approximately one fourth are aware that email can be linked to other online activities.  More than 75% of US parents are aware that searches are tracked, and 40% or more are aware that some form of integration is performed across different online services.

Table 11. US and Japanese parents? awareness  of data mining their children?s online activities.

Data values are stacked vertically, US / Japan /  Average  Table 12 shows that both US and Japanese parents would strongly prefer that their children?s online activities be free from data mining.  However, Japa- nese parents are significantly more tolerant of the possibility that students? email may be data mined, even if the email is provided by the students? school district.  This may in part be explained by their belief that their students are less likely to engage in inappro- priate behavior online.

Our data (not reported here due to length limita- tions) show that US parents have reason to be con- cerned about data mining their students? online behav- ior.  A significant fraction of students have engaged in inappropriate behavior online, or are aware of students who have.  As we have discussed in section 4 above, nothing learned about online behavior is truly anony-  mous. Japanese parents do appear to have less reason for concern, given the apparently better behavior of Japanese students online.  However, self-reported data on sensitive subject areas are always imperfect, and differences in cultural norms may partly explain dif- ferences in the data on self-reported student activities.

Table 12. US and Japanese parents? attitudes  towards data mining their children?s online activi- ties.  Data values are stacked vertically, US / Japan  / Average  Additionally, students? have their own attitudes towards being profiled and to having their online activities tracked and integrated, and may consider this an invasion of privacy.  Students? strongly disapprove of tracking and integrating their online behavior, as summarized in tables 13 and 14.

Table 13. US and Japanese students? attitudes  towards tracking their individual online activities.

Data values are stacked vertically, US / Japan /  Average  ?       Table 14. US and Japanese students? attitudes towards linking their email accounts with their texting. Data values are stacked vertically, US /  Japan / Average  9. Conclusions Consumers? preferences would suggest that the de-  fault privacy settings should be no tracking without explicit permission and no integration without explicit permission.  Governments should hold firms accounta- ble for violations and should ensure that violations are visible when they occur.  Governments should ensure that consumers can know exactly what companies have done, so that they can protect themselves, register displeasure, and change vendors if they deem it neces- sary to stop violations of their privacy.  Our data also show that the public is not widely aware of criminal violations of privacy, such as the WiSpy scandal in the US or iPhone hacking in the US, or Google Analytics violation of EU privacy laws.  Given that these viola- tions are strongly counter to consumers? preferences, perhaps they should receive greater attention and be more severely punished when they occur.

Many have argued that consumers? use of systems that compromise their privacy do so fully informed, and accepting the reduction in personal privacy as a free trade and a fair exchange for services rendered.

Clearly, we do not believe this to be the case, and clearly we do not believe that consumers are fully informed or have offered informed consent.  As Jay Kesan and his colleagues ask [22], ?What data are consumers willing to trade in exchange for conven- ience and services online? Would they be as willing to engage in this trade if their privacy rights were more protected and if they had the ability to exercise mean- ingful control over their data??  We believe that any policy regulations enacted should have the following characteristics.

? Regulations should treat companies equally,  regardless of their industry classification.  Tele- communications companies, regulated common carriers, and information services providers should have comparable obligations.

? Regulations should be consistent.  If letters are protected, then emails and texts should be protect- ed as well.  If information stored in remote elec- tronic data storage facilities is protected, then in- formation stored in remote electronic cloud data storage facilities should be protected as well.

? Companies? policies should be transparent.  Users should know what they are giving up, in exchange for ?free services.?  Users should understand the loss of anonymity associated with data mining and targeted ads.  Users should understand how the in- formation gathered can be used, both for them and against them.

? The fact that a service is free is not sufficient justification for obscuring the risks associated with that service.  No tobacco company could successfully argue that it was not subject to regu- lation because it provided its tobacco products free of charge to public school students.  Similarly, providing information services free of charge does not eliminate the need to provide products that are safe and that observe all relevant regulations.

We are still conducting focus groups and experi- ments in additional locations.  Data analysis is also ongoing.

