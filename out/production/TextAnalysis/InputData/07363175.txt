Mining Binary Data with Matrix Algebra Ritu Chaturvedi and C.I.Ezeife*

Abstract?Many applications such as intelligent tutoring sys- tem (ITS) use data that are better represented as binary data.

This paper presents a novel algorithm called MBER (Mining Binary Data Efficiently by Reduced AND operations) for finding frequent itemsets in a binary dataset using matrix algebra operations. Frequent itemsets are sets of items in a transactional database that occur together frequently (defined by a user-given threshold value called minimum support). Existing algorithms that operate on binary data, such as ABBM, generate frequent itemsets by performing exhaustive AND operations using brute- force method. MBER, on the other hand, generates frequent itemsets using a novel technique in which it first uses matrix algebra operations to find those transactions that have m common items in them (called as potential transactions) and then performs AND operations on only such potential transactions. This reduces the total number of AND operations required considerably (by less than a quarter) and thereby improves the efficiency of the algorithm. MBER also shows a significant improvement over traditional algorithms that generate frequent itemsets, such as Apriori, by eliminating the need to (i) scan the database more than once and (ii) to generate large number of candidate itemsets.

This paper concludes by a proof of correctness of MBER and a discussion on evaluating it.

Index Terms?Data mining, Matrix algebra, boolean AND, frequent itemsets

I. INTRODUCTION  Data Mining is a key step in the process of knowledge discovery and association rule mining is one such mining technique that discovers interesting relationships among differ- ent items in a given transaction. Figure 1a shows an example of market-basket transactions with items such as bread, milk and beer (adapted from [5]). Association rule mining (ARM), proposed by Srikant and Agarwal [9] works in three phases : phase I discovers candidate items and itemsets (k-itemset is a set of k items) that could possibly be frequent by scanning the database; phase II selects those candidate itemsets that occur in at least x% of transactions, where x is known as minimum support (min?sup); phase III uses these frequent itemsets to generate association rules. More formally, candidate k- itemsets Ck are generated in phase I by self-joining frequent itemsets Lk?1and Lk?1 using an Apriori-gen algorithm [9].

This phase also scans the database to count the support of each itemset. Phase II prunes these k-itemsets Ck in two ways.

Firstly, it deletes those itemsets that do not satisfy the Apriori property (all nonempty subset of frequent items must also be frequent). Secondly, it prunes those itemsets that have a support count less than the desired threshold min?sup. These frequent itemsets are then used to generate association rules  of the form X->Y, where X and Y are items and are items and X  ? Y={}. E.g. Diaper ? > Beer is an association rule  for items in Table1. Our research focusses on phases I and II (frequent itemset generation) since it dominates the computing time of any ARM technique. Many ARM algorithms have been proposed including Apriori [9] and FP-Growth [2]. Apriori al- gorithm has seen many improvements since its inception such as those proposed by Jong et al., Li et al. and Sarkar et al. [3], [6], [8]. To use an algorithm such as Apriori, data in a dataset has to be transformed into transactional items. E.g., Figure 1b shows a sample student database with several attributes (each column represents an attribute). This data is transformed into a transactional database with items such as shown in Figure 1a, so that algorithms such as Apriori can be applied to them.

Datasets such as those used in educational data mining consist of attributes that are mostly binary or categorical attributes, although some of them may even be continuous. Our study proposes a modified Apriori algorithm applied to a dataset that has only binary attributes. Binary attributes (also known as Boolean) are those that can assume only two values such as true or false. Figure 1b contains student data with boolean attributes such as gender and computer_at_home. Categorical attributes are those that can assume a finite set of values (e.g. letter grades in a course with values A+, A, A-, B+, B, B-, F) and therefore are generic cases of binary attributes.

Continuous attributes are those whose values are real numbers (e.g. attributes assignment_marks and final_exam_marks in Figure 1b). In order to discover interesting relationships such as {50 < assignment_marks <= 65} -> {computer_at_home = No}, such continuous attributes need to be transformed to categorical or binary attributes and then to items in a transaction. For example, assignment_marks get transformed into boolean attributes I3, I4, I5 and I6, as shown in Figure 2a.

Then they are transformed to items in a transaction, similar to Figure 1a items. Figure 2b shows the dataset in figures 1b and 2a transformed into an apriori-ready dataset of items.

Items I1, I2 are used for gender; I3..I6 for assignment marks; I7, I8 for computer at home; I9.. I12 for final exam marks and I13, I14 for success. We propose a method that takes a dataset with boolean features such as the one shown in Figure 2a and generates k-frequent itemsets in a more efficient way than Apriori. Representing data as boolean has several advantages. Firstly, boolean data can be interpreted as bit streams and operations on bit streams such as AND are fast and easily applicable to boolean data. Secondly, boolean data  Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing  DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.135     (a) Example of market-basket transaction adapted from [5]  (b) Example student database  Figure 1. Sample transactions  (a) Student database attributes transformed to Boolean (e.g., I1, I2 for gender; I3..I6 for assignment marks)  (b) Apriori-ready student database  Figure 2. Student dataset : Boolean and Transactional  as shown in Figure 2a can be represented efficiently as sparse matrices, although our research in this paper does not use sparse matrices.



II. RELATED WORK  Many association rule mining algorithms have been pro- posed including Apriori [9] and FP-Growth [2]. Apriori algo- rithm has seen many improvements since its inception such as those proposed by [3], [6] and [8]. As elaborated in section 1, data has to be transformed to items in a transaction for algorithms such as Apriori and FP-growth to be applied to them. Many applications such as educational data mining have data with attributes that could be binary, categorical or continuous. Figure 1b of Section I has one such example of student data. Such data has to be transformed to transactional items so that algorithms like Apriori can be applied to them.

Many researchers ([3], [4], [7] and [10]) have attempted to modify Apriori and Apriori-like algorithms to handle binary attributes such as shown in Figure 2a. Our research takes this modification further by proposing an algorithm that is more efficient than the existing ones. Wiu and Leu [10] proposed a technique using boolean data as input, in which they perform AND operations on rows (or transactions) that have more than k items in them. They then prune the rows and columns in  the boolean matrix that do not satisfy the min ? sup value.

This method has 2 disadvantages. Firstly, it scans the database multiple times for matching the items and secondly, it performs a delete operation after each iteration, which itself is O(m*n) complexity, where m = number of transactions and n = number of items. Liu and Wang [4] find all possible joins (similar to Apriori-gen) and perform AND operations between items in each of these combinations to generate k-itemsets (sets with k items in it). This results in several redundant AND operations in each iteration of k. For example, if {I1, I2, I3} and {I1, I2, I4} are two 3-itemsets, a join of these results in a 4-itemset {I1, I2, I3, I4}. To check if this 4-itemset has a support count of >=min_sup, 3 AND operations are performed I1 AND I2 AND I3 AND I4. Similarly, for each k-itemset generated, there are k-1 AND operations performed.

Their algorithm also deletes, in each iteration, the rows and columns of the boolean matrix that do not satisfy the min_sup condition, similar to Wiu ?s algorithm. They then perform AND operations on those transactions and items to generate frequent k-itemsets. An approach similar to Liu and Wang is used by Rao et. al. [7], in which they represent boolean matrix using both bit-stream approach and as sparse matrix.

In all the existing approaches mentioned above, several AND operations are performed either between transactions or items to generate frequent k-itemsets. Our approach reduces the number of AND operations considerably by first finding the potential transactions that have at least k common items in them and then performing AND only on those transactions.

Experimental results show that our approach is more efficient than the existing algorithms that work on boolean data.



III. MINING BOOLEAN DATA EFFICIENTLY BY REDUCED AND OPERATIONS (MBER)  This section presents an efficient algorithm called MBER that generates frequent itemsets using boolean data. MBER adopts matrix algebra operations such as transpose and product to find the potential transactions that have common items in them. If they have more than k items in common and if there are more than min?sup number of such transactions for a certain k, then they are considered as potential transactions.

Thereafter, AND operations are performed only on those potential transactions, thereby reducing the number of AND operations considerably. MBER does not perform expensive join operations and does not generate candidate itemsets.

A. Definitions, Propositions and Claims  Definition 1: Boolean Matrix: Boolean matrix BM is a ma- trix with elements as ?1? or ?0?, in which each row represents a transaction and each column represents an item. A value of 1 indicates the presence of an item in a transaction.

Definition 2: Items: I = {I1, I2, ...In} is a set of n items called attributes in a transaction database D.

Definition 3: k-itemset: k-itemset is a set of k items drawn from I found together in a transaction (or a record) of database D.

Definition 4: Potential transaction PT (i,j)k : When gener- ating itemsets of size k, transaction j is assigned to be a potential transaction for i, if transactions i and j have k items in common.

Definition 5: Transaction matrix : a transaction matrix tm is defined to be a symmetric square matrix of size m x m, where m = #transactions in D generated by multiplying a boolean matrix by its transpose.

tm = BM ?BMT Proposition 1: Diagonal of transaction matrix tm stores the  total number of items in each transaction.

Rationale: By matrix algebra, a diagonal element d(i, i)  of tm stores the sum of the product of row i of BM with itself (represented as column i in BMT ). This value is equal to the sum of row i of BM , which is the number of items in transaction i.

Proposition 2: The size of the largest itemset that can possibly be generated for a dataset represented by BM is maxk = max(d(i, i)).

Rationale: By proposition 1 and definition 3.

Proposition 3: Logical AND of any 2 rows of boolean  matrix BM generates an itemset of size p, where p=# of 1?s in the logical AND.

Rationale: Let q = BM [rowi]&&BM [rowj ],where q is a vector of 1?s and 0?s. By definition 1, q(t) = 1signifies the presence of item t in both rows (transactions) i and j and therefore is included in the itemset being generated. The itemset generated has p =|q(t) == 1|items where t = 1..n, n=number of items in D.

Claim 1: Each element d(i, j) of transaction matrix tm,j > i, represents the number of items that are common to transactions i and j. More formally, if Ti and Tj are transactions with n elements each (where n is the number of items in D), then |Ti  ? Tj | = d(i, j)  Proof: By contradiction Assume |Ti ? Tj | ?= d(i, j).

case 1: Assume |Ti ? Tj | < d(i, j)  LHS: By definition of intersection,  Ti ?  Tj =  { 1 if Ti(z) = Tj(z)=1, z=1..n 0 otherwise  RHS: By proposition 1, d(i, j) = sum(Ti ? TjT ) Since product of two boolean values is 1 only when both  the operands are 1,  Ti ? TTj = {  1 if Ti(z) = TTj (z)=1, z=1..n 0 otherwise  =>Ti ? Tj=Ti ? TjT => |Ti  ? Tj | = d(i, j), which is a  contradiction.

case 2: Assume |Ti  ? Tj | > d(i, j)  LHS: By definition of intersection,  Ti ?  Tj =  { 1 if Ti(z) = Tj(z)=1, z=1..n 0 otherwise  RHS: By proposition 1, d(i, j) = sum(Ti ? TjT ) Since product of two boolean values is 1 only when both  the operands are 1,  Ti ? TTj = {  1 if Ti(z) = TTj (z)=1, z=1..n 0 otherwise  =>Ti ? Tj=Ti ? TjT => |Ti  ? Tj | = d(i, j), which is a  contradiction.

B. Algorithm MBER in detail  Algorithm MBER takes 2 inputs {Boolean matrix BM (m,n), m = number of transactions; n = number of items and Threshold for minimum support (min?sup)} and consists of three phases:  1) Transform transactional database into boolean matrix using binarization.

2) Generate frequent itemsets of size 1 (L1) 3) Generate frequent itemsets Lk, k>=2 Step 1: Transform transactional database into boolean  matrix : A transactional database D with m transactions and n items is transformed into a Boolean matrix BM with m rows and n columns. BM(i,j) = 1, if item Ij is in transaction Ti; 0 otherwise. More formally, f is a function defined below that transforms database D to boolean matrix BM.

f : D ? BM = (d(i, j))m?n,  d(i, j) =  { 1 if Ij is in Tj 0 otherwise  For example, f maps transactional data in Figure 2b to a boolean matrix in Figure 2a. Element d(1, 1) = 1, signifies that item I1 is contained in transaction 1. Similarly, element d(2, 14) = 1, signifies that item I14 is contained in transaction T2.

Step 2: Generate frequent itemsets L1 of size 1 : Compute the sum of each column j of BM, j=1..n, where each column represents an item and n is the total number of items in D.

Column sum represents the total number of transactions that item j belongs to, columnsum =  ? j=1..n BM(j).

L1 = {j|j ? [1..n] and columnsum(j) >= min?sup}  Step 3: Generate frequent itemsets Lk, of size k>=2: We divide the process of generating frequent itemsets of size k, k>=2, into 2 steps - step 1 generates initial itemsets (IInew), and step 2 uses IInew to generate additional itemsets(AInew).

In order to efficiently generate initial itemsets, a transaction matrix tm of size m x m, where m = |transactions| in D is generated defined as tm = BM ? BMT (Definition 5). Since tm is a symmetric square matrix, our algorithm saves time by using only the upper triangular matrix of tm.

Using propositions 1 and 2, diagonal elements d(i, i) of tm represent the total number of items in each transaction and MBER uses the maximum of d(i, i) (maxk) to terminate the process of generating itemsets. Now, initial itemsets of sizes k = 2..maxk are generated using tm. If tm(i, j) = k, then we consider transaction j as a potential candidate for transaction i (Definition 4 and Claim 1) and therefore, only then rows i and j of BM are ANDED to generate a new itemset of size k (new?itemset) (Proposition 3).

Each new?itemset generated in this step saves transactions i and j that were used to create it in trans?nitemset. The condition tm(i, j) = k subsumes or hides itemsets of sizes less than k. E.g., tm(i, j) = 3 implies that transactions i and j have 3 common items and therefore an itemset of size 3 (e.g. {I1, I2, I3}) is generated by ANDing rows i and j of BM. This itemset subsumes itemsets of sizes 2 such as {I1, I2},{I1, I3} and {I2, I3}. This leads us to the next step of generating additional itemsets. For each itemset s of size p > 2 in IInew, MBER finds all possible combinations of sizes (p-1) .. 2, which is (2Cp + 3Cp + ....p?1Cp) that s can generate. For each combination r of itemset s (we call s as parent of r) , MBER checks if r exists in IInew. If it does, then all transactions belonging to the s are added to r (trans?nitemset(r) = trans?nitemset(s)). If r does not exist in IInew, then r is added as a new?itemset to AInew and all transactions belonging to s are copied to r. The next and final step counts all transactions in trans?nitemset for each itemset t in IInew ?AInew. If this count for t is greater than min?sup, then t is added to L.

A formal algorithm for MBER is given in Algorithm 1.

Algorithm 1 MBER (Mining Boolean Data Efficiently by Reduced AND operations) Input: Database D of m transactions and n items, threshold for minimum support (min?sup) Output: Frequent itemsets of sizes 1 .. k (L)  Method: 1. Transform D into boolean matrix BM (m,n) for each row t in D,  1.1. for each item i?I, 1.1.1 if i?row then BM(t,i)=1 else BM(t,i)=0  2. Generate itemsets of size 1  2.1. Initialize L1=? 2.2. for each column j of BM  2.2.1 if column_sum(j) >= min?sup, then L1=L1 ? Ij  2.3 Delete from all those items that have a support < min?sup  3. Generate itemsets Lk, k = 2..maxk (proposition 2)  3.1. Generate initial itemsets (IInew) using algorithm 2 (cre- ate_itemsets_initial). This function reduces AND operations since it performs AND on selected few transactions to generate itemsets of size k.

IInew= create_itemsets_initial(BM) 3.2. Generate additional itemsets (AInew) using algorithm 3 (Cre- ate_itemsets_additional). This function uses existing itemsets from IInew to generate new ones. There are no AND operations required in this step.

AInew= create_itemsets_additional(IInew) 3.3. for each itemset c in AInew  3.3.1 if |trans?nitemset(c)| >= min_sup Lk? c // itemset i is added to Lk  3.4. L = L1 ?  Lk // L holds all large itemsets of sizes 1 .. k  Algorithm 2 Function create_itemsets_initial Input: BM Outputs: Initial list of frequent itemsets IInew, array to store trans- actions of each itemset trans?nitemset Method: 1. compute the inner product of BM and its transpose (BMT ) and store it in a square symmetric matrix of size m*m transaction?matrix = BM ?BMT 2. Initialize c = 1 // first itemset 3. for k=2..maxk(proposition 2)  3.1.for each row i of transaction?matrix 3.1.1. for each column j of transaction?matrix, j > i  3.1.1.1. if transaction?matrix(i, j) = k (i and j are poten- tial transactions), then  3.1.1.1.1. generate an itemset of size k by ANDing rows i and j of BM  new = BM(row(i)) andBM(row(j)) //new is a vector of 1?s and 0?s  3.1.1.1.2. If new does not exist then 3.1.1.1.2.1. Increment c; IInew(c) = Iz, z is index of  new with value 1 //Add the new itemset to IInew at position c. E.g., if c=1  and new=[1,1,0,1], then {I1,I2,I4} is added to IInew(1) 3.1.1.1.2.2. Add transactions i, j to trans?nitemset(c)  //e.g., if i=1 and j=3 in step 3.1.1.1.1, then {1,3} are added to trans?nitemset(1)  3.1.1.1.3. else //if new already exists, add j to its list of transactions  3.1.1.1.3.1. Add transactions j to trans?nitemset(c)  Algorithm 3 Function create_itemsets_additional Input: IInew,trans?nitemset Output: AInew,trans?nitemset (updated) 1. Initialize AInew= IInew; cn = number of items in IInew 2. for each itemset parent in AInew with length > 2,  2.1. find all combinations r of sizes (p-1). . . 2, p=#(parent) 2.1.1. if r does not exist in AInew then  2.1.1.1. AInew(cn) = r and increment cn //add r as a new itemset to AInew  2.1.1.2. copy(trans?nitemset(r), trans?nitemset(parent)) //copy parent?s transactions to r  2.1.2. else //if r already exists in AInew 2.1.2.1. add(trans?nitemset(r), trans?nitemset(parent))  //add parent?s transaction to r  C. Example trace of MBER  Inputs : Database D and min?sup = 3  D=  Transaction Items T1 I1,I2 T2 I1,I3,I4,I5 T3 I1,I2,I3,I4,I6 T4 I1,I2,I3,I4 T5 I1,I2,I3,I6  Step 1 : Transform D to BM     I1 I2 I3 I4 I5 I6 T1 1 1 0 0 0 0 T2 1 0 1 1 1 0 T3 1 1 1 1 0 1 T4 1 1 1 1 0 0 T5 1 1 1 0 0 1  Step 2: find column_sum of BM = [5,4,4,3,1,2] L1 = {I1 : 5, I2 : 4, I3 : 4, I4 : 3} I5 and I6 are not included since their sum is < min_sup.

Therefore, columns 5 and 6 are deleted from BM.

Step 3 - 3.1: Generate initial itemsets IInew, using algo- rithm 2; c=1 transaction?matrix = BM ? BMT (BM = boolean  matrix and BMT is its transpose)  =  1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0  *  1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0  =  2 1 2 2 2 1 3 3 3 2 2 3 4 4 3 2 3 4 4 3 2 2 3 3 3  E.g., transaction?matrix(1, 1) is computed by multiplying row 1 of BM with column 1 of BMT as 1*1+1*1+0+0+0+0 = 2  For k=2 (step 3 of algorithm 2) For i=1, potential transactions are j=3,4,5 For i = 1 and j = 3: new = BM(row1)ANDBM(row3) =  1, 1, 0, 0, 0, 0 ?IInew(1)={I1,I2} and trans?nitemset(1) = {1, 3}  //new itemset {I1,I2} generated at c=1 For i = 1 and j = 4: new = BM(row1)ANDBM(row4) =  1, 1, 0, 0, 0, 0 Since new already exists at c=1, ?trans?nitemset(1) = {1, 3, 4} by step 3.1.1.1.3 of algorithm 2  For i = 1 and j = 5: new = BM(row1)ANDBM(row5)= {1,1,0,0,0,0}  Since new already exists at c=1, ? trans?nitemset(1) = {1, 3, 4, 5} by step 3.1.1.1.3 of algorithm 2  Now, IInew(1)={I1,I2} has 4 transactions in it, implying that it has a support count of 4.

Similarly, for i=2, potential transaction is j=5 and the new itemset generated is IInew(2)={I1,I3} and trans?nitemset(2) = {2, 5}  Repeating this process for k = 3 and 4, the final output is IInew ={{I1,I2}{I1,I3}{I1,I3,I4}{I1,I2,I3}{I1,I2,I3,I4}} trans?nitemset = {{1,3,4,5}, {2,5}, {2,3,4}, {3,4,5},  {3,4}}  Step 3 - 3.2: Generate additional itemsets (AInew) using algorithm 3: Initialize cn and AInew as :  cn = 5; AInew=IInew= {{I1,I2}{I1,I3}{I1,I3,I4}{I1,I2,I3}{I1,I2,I3,I4}}  parent ={I1,I3,I4} and trans?nitemset(3) = {2, 3, 4} (repeated for all parents of length >2)  Table I FINAL LIST OF ITEMSETS GENERATED FOR DATABASE D BY MBER  index itemset trans?nitemset 1 {I1,I2} {1,3,4,5} 2 {I1,I3} {2,5,3,4} 3 {I1,I3,I4} {2,3,4} 4 {I1,I2,I3} {4,5,3} 5 { I1,I2,I3,I4} {3,4} 6 {I1,I4} {2,3,4} 7 {I3,I4} {2,3,4} 8 {I1,I2,I4} {3,4} 9 {I2,I3,I4} {3,4} 10 {I2,I3} {4,5,3} 11 {I2, I4} {3,4}  All combinations of {I1,I3,I4} are r = {{I1,I3},{I1,I4},I3,I4}}  {I1,I3} exists in AInew at c=2 ?trans?nitemset(2) = {2, 5, 3, 4} (3 and 4 get added)  {I1,I4} does not exist ?AInew(6)={I1,I4} and trans?nitemset(6) = {2, 3, 4}  {I3,I4} does not exist ? AInew(7)={I3,I4}and trans?nitemset(7) = {2, 3, 4}  Doing this similarly for all parents of length > 2, table 1 shows the final list of itemsets AInew generated for tranactions in database D.

Step 3 - 3.3: Itemsets that have transactions intrans?nitemset >=min_sup are  Lk ={{I1,I2},{I1,I3},{I1,I3,I4},{I1,I2,I3},{ I1,I4},{I3,I4},{I2,I3}}  Step 3 - 3.4: Frequent itemsets generated are L={I1, I2, I3, I4, {I1,I2},{I1,I3},{I1,I3,I4},{I1,I2,I3},{ I1,I4},{I3,I4},{I2,I3}}

IV. EVALUATION OF MBER  We provide a proof of correctness of MBER in section 4.1 and then compare its performances with those of existing algorithms that generate frequent itemsets using boolean data (e.g. ABBM[4]) by comparing the number of reduced AND operations performed on boolean data.

A. Proof of correctness of MBER  Steps 1, 2 and 3 (3.1) of MBER are verified to be correct using propositions 1 to 3 and claim 1. A formal proof of claim 1 and rationales of each proposition can be found in section 3.1. To verify step 3 (3.2) of the algorithm, we use the monotone property [1] that states that if a set passes a test, then all its subsets will pass the test as well. In the context of itemsets, if an itemset is frequent, then its subsets are also frequent. More formally, ?x, y, (x ? y)? frequent(y)? frequent(x)  B. Comparative Evaluation  ABBM [4] combines an item with every other item to build itemsets (similar to Apriori). For example, item I1 will be combined with items I2, I3, I4, I5, I6 to build five 2-itemsets     and therefore, 5 AND operations will be performed to find their suport count. A similar process is followed to build k- itemsets.

Number of AND operations in ABBM = (2Cn + 3Cn + ....n?1Cn) =  ?n x=0  ( n x  ) By theorem of binomial expansion [1],  ?n x=0  ( n x  ) = 2n  This implies that ABBM performs O(2n) AND operations.

MBER, on the other hand, performs AND operations only if it finds that 2 transactions have the potential to build an itemset of size k, and to extablish this, it uses the upper triangular ma- trix of the square symmetric matrix (transaction?matrix) generated by step 3.1 of MBER. This ensures that in the worst case scenario (when each transaction has a potential to build itemsets with every other transaction in the database), the number of AND operations that are done in MBER are m-1 (for row 1), m-2 (for row 2) ... 1 for row m-1, 0 for row m.

? (m? 1) + (m? 2) + ...1 = m(m? 1)/2 = O(m2).

Even though ABBM performs AND operations on items,  and MBER performs them on transactions, MBER shows a remarkable improvement in terms of reduced AND operations.

A comparison of number of ANDs and number of joins/subsets generated for a small dataset with 5 transactions and 6 items (example shown in Section 3.2.4) is shown below: ? Number of AND operations  ? ABBM[4] : 10 (for 2-itemsets) +14(for 3-itemsets) + 6 (for 4-itemsets) =30 ANDs  ? MBER : 6 ? Number of joins / subsets  ? ABBM[4] : Number of joins = 10 (for size 2) + 9 X 9 (for size 3) + 7X7 (for size 4) = 140  ? MBER : Subset generation: Initial itemset has 2 itemsets of size 2, 2 of size 3 and 2 of size 4 ? maximum number of subsets generated =2 ?2C3+2 ? (2C  4 +3 C 4) = 6 + 2 ? (6 + 4) = 26  In future, we will appraise the performance of MBER by conducting experiments using C++ and Matlab.



V. CONCLUSIONS AND FUTURE WORK We use matrix algebra operations that are convenient to  use and efficient in terms of running time when applied to transaction databases represented as boolean matrices of 1?s and 0?s to generate frequent itemsets. Once the database is scanned and transformed into a boolean matrix, the proposed algorithm MBER does not scan it again for support count (as is required in Apriori and ABBM). Another feature that distinguishes MBER from Apriori is that it does not perform expensive joins and does not generate candidate itemsets.

Although existing algorithms such as ABBM also operate on boolean data to generate frequent itemsets, MBER reduces the number of AND operations performed (AND being the main operation of such algorithms that use boolean data) from exponential to quadratic.



VI. ACKNOWLEDGMENTS *This research was supported by the Natural Science and  Engineering Research Council (NSERC) of Canada under an  Operating grant (OGP-0194134) and a University of Windsor grant.

