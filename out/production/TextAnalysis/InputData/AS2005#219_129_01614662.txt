A Distributed Algorithm Based on Competitive Neural Network for Mining Frequent Patterns

Abstract-Although FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm, it is unrealistic to construct memory-based FP-tree when dataset is huge, because the FP-tree is too great to be held in memory entirely. In this study, we propose a novel method named Competitive-Network-based FP-growth method (CNFP), which combines competitive neural network with FP-growth to mine frequent patterns. In competitive learning, similar patterns are grouped by the network and represented by a single neuron. This grouping is done automatically based on data correlations. Huge database is divided into sets of similar data. After competitive learning, neurons in competitive layer are regarded as root to construct FP-sub-trees, in which transactions are similar to each other.

Frequent patterns are mined based on FP-sub-tree to decompose the mining task into a set of smaller tasks, which dramatically reduces the search space. CNFP can mine frequent patterns on web log files and discover association rules between URL pages users access. Not only can it help us to discover the user access patterns effectively, but to provide the valid decision-making for the Web master to devise the personalized web site. Our experiments on a large real data set show that the approach is efficient and practical for mining association rules on website pages.



I. INTRODUCTION  Association rule[l], which is used widely in additive post, directory devised and client divided, is an important research field in data mining. A lot of Apriori-like approaches[2-4] have achieved good performance.

However, it is costly to handle a large number of candidate sets. Synchronously it needs to scan database repeatedly.

FP-growth[5] that avoids the costly generation of a huge number of candidate sets is efficient and scalable for mining frequent patterns, and it runs faster than Apriori-like algorithms.

Although FP-growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm, it is unrealistic to construct memory-based FP-tree when dataset is huge, because the FP-tree is too great to be held in memory entirely.

Xiaoying Tai, Jieyu Zhao Institute of Computer Science and Technology  Ningbo University Ningbo 31521 1,China  Besides these studies on sequential data mining techniques, algorithms for parallel mining of association rules have been proposed recently. In PDM[6] and CD[7] algorithms, not only do a great many of candidate sets need to be transmitted, but iteration need to be synchronous.

FDM[8] and DDDM[9] adopt heuristic method to prune the local candidate sets to reduce the traffic. However, all above methods will create a lot of local candidate sets in large databases that it will cost much more time to handle.

In this paper, FP-tree structure is applied under the distributed environment. Combining competitive neural network with FP-growth, we propose a novel distributed method to mine frequent patterns, which named Competitive-Network-based FP-growth method (CNFP). In competitive learning, similar patterns are grouped by the network and represented by a single neuron. This grouping is done automatically based on data correlations. Huge database is divided into sets of similar data. After competitive learning, neurons in competitive layer are regarded as root to construct FP-sub-trees, in which transactions are similar to each other. Frequent pattern is mined based on FP-sub-tree to decompose the mining task into a set of smaller tasks, which dramatically reduces the search space.

The remaining of the paper is organized as follows:  Section II introduces CNFP algorithm we proposed, which develops existed FP-growth method. Web log files are mined using CNFP method in section III. Section IV summarizes our study and points out some future research issues.



II. CNFP MODEL  A. Network Structure CNFP is a two-layer directed graph, whose characters are  as follows: (1) Nodes in directed graph are binary neurons; (2) Directed graph is divide into two layers: input  layer and competitive layer;  0-7803-9422-4/05/$20.00 C2005 IEEE    (3) Whole-linked structure is adopted between input layer and competitive layer. Competitive connected weight Wij describes the connected intensity between two layers.

There is one winner in competitive layer for each input datum.

Whole-linked structure is employed between input layer and competitive one to form basic competitive network.

Neurons in competitive layer representing classification primarily, the vectors of competitive connected weight from input layer to competitive layer show the centroid of sub-clusters.

B. Learning algorithm Definition l(Transaction):Suppose that I={al,a2,...,am}  is a set of items, and a transaction database DB={Tl,T2,...,Tn}, where Ti(i E [1,n]) is a transaction which contains a set of items in I.

Definition 2(Frequent pattern):The support of a pattern P is the number of transactions containing P in DB. P is a frequent pattern if P's support is no less than a predefined minimum support threshold 4.

Given a transaction database DB and a minimum support threshold 4 ,what we should do is to find the complete set of frequent patterns.

Learning and working of CNFP is by the way of competition in competitive network and constructing FP-sub-tree by taking the competitive neurons as root.

Each input vector of neural network, namely a transaction, is presented to the network to compare with the prototype vector that it most closely matches. If there are not any prototype vectors to match the input pattern, a new prototype is generated to hold the input vector. After training finished, DB should be rescanned to construct FP-sub-tree. One neuron in competitive layer, which will be activated by a new input transaction, is treated as root of FP-sub-tree. The transactions that activate the same neuron in competitive layer disposed in the same FP-sub-tree.

CNFP mining is mining FP-sub-tree to discover the frequent patterns.

There are five steps in learning period: initialization, competition, FP-sub-tree construction, CNFP-growth and global FP generation.

Initialization: Three parameters are selected to be initialized in CNFP: {Wij}, A and 4, where Wij is weight between input layer and competitive layer, 2 and 4 are threshold. A, a win threshold whose value is between 0 and 1, represents the match level of prototype vector. 4 is minimum support threshold for mining frequent patterns.

Competition: Competitive process is a process to discover the match prototype. The winner neuron g is ensured by choosing out the maximal similarity Sg after every similarity between input patterns and prototype vectors is computed.

N  s=Te Wy = t~~2 wijtk  1=1 i= i Si= 1,,..,  Similarity Sj computed from above formula denotes the match degree between input vector Tk and Wij. Sj=l means complete match between Tk and Wij. The match between prototype and input vector is allowed to be a gap because classification is clustering to similar objects. Completely match is not required. The difference is determined by threshold p . If Sj>=2, the recognition is accepted for the match is in our range. The output of corresponding neuron in competitive layer is set to be 1 and the competitive connected vector is revised simultaneously. If Sj<2, the recognition is rejected since the match is not adequate. A new prototype is generated to be a new classification.

FP-sub-tree Construction: In second scan of database, the won neuron in competitive layer is treated as root of an FP-sub-tree. The frequent items in transaction T is selected and sorted by order. When a branch is generated for a transaction, the count of nodes with same prefix path are increment by 1, and a new node after prefix path is created and let its count be 1.

CNFP-growth: For each root of competitive neurons, conditional pattern base of initial postfix pattern is constructed from frequent pattern whose length is 1. Then its condition FP-tree is constructed and mined recursively.

We achieve pattern increase by connecting the postfix patterns and frequent patterns created from conditional FP-tree. From this step many local frequent patterns are created.

Global FP Generation: Local frequent itemsets maybe not the frequent patterns of whole DB. Every frequent itemsets of DB should come forth in one partition as local frequent itemset. The set of local frequent itemsets forms the global frequent itemsets ofDB.

The algorithm is as follows: (1) Initialize: U is learning count. {w, }is given an  arbitrary value between 0 and 1.

(2) New input pattern T, = (Qt,4,...,t) is provided.

Collect the set of frequent items F and their supports.

(3) Similarity between input patterns and prototype  vector is computed.

N  ENNIITk WY. =II - JS || Tk |||| Wy || $(ti)2I S 2  WY =  M (4) Select the winner sg = MAX[sj ]  j=l (5) Judge whether the formula sg >A come into     existence for the winner g. If it is true, then go to step (6) because the winner g is exactly a winner, else go to step (8)  (6) Discriminating result is admitted to adjust the competitive connected weight as following:  Wig = wig + Awig t.

Awig=a.('( Wig)  i=1,2,...,N (0<a<1) where a is a learning rate (7) Return to step (2) for next input pattern (8) A new prototype is created p=M+l. Initialize W w t, i = 1,2,...,N (9) Return to step (2) for next input pattern until p  learning samples are trained.

(10) Let u=u+l, return to (2) until u=U (11) Sort F in support descending order as L, the list of  frequent items (12) Mining local frequent itemsets by FP-growth  algorithm (13) The set of local frequent itemsets forms the global  frequent itemsets ofDB.



III. WEB LOG MINING: EXPERIMENTAL RESULT  Web mining [10]-[12], the discovery of knowledge on the Web, has become an interesting research area. Web log mining is finding patterns in the usage of the Web. An important topic in Web log mining is the relation of pages accessed by users. For example, 40% of all users taking care of stock are favor for national economy. By analyzing the characteristics of these relations, webmasters may understand Web usage better and may provide more suitable, customized services for users. The association rules on web can provide a very useful tool for many applications in education and e-commerce.

In our experiment, CNFP proposed is used to mine association rules based on browsing activities or access patterns on the Web. The server log data should be pre-processed [12] to identify the sessions.

A. Session e-xtraction Web log files contain records of user accesses. Each  record represents a page request from a Web user. A typical record contains the IP address of client, the date and time of request, the URLs of the page, the protocol, the return code of the server and the size of the page if the request is successful, etc. Above all users browsing pattern from server's log files need to be extracted. Session, which describe the set of URL pages clients browse in period of time, is used to describe the users browsing pattern that is made up ofURL pages and time consume on these pages.

Definition 3(Session P) Session P is the element as  follows: P =< sid1, userj, {(url _ idk, timek)}" > where sidi is session id, userj is user j, url_ idk is the  URL serial users visit, timek is the time users spend on the web page, (url_idk, timek) is the time users spend on the web page url_idk .

Irrelevant information for Web usage mining such as background images and unsuccessful requests is ignored.

The users are identified by the IP addresses in the log and all requests from both the same IP address and the same operating system are regarded as one user. Two thresholds are used to recognize the sessions: one is min_time to exclude noises in the data. If the time spent on one page is less than min_time, the page is assumed to be uninteresting to the user or an index page and is discarded. Another one is max_idle_time. If the elapse of time between two consecutive requests from the same user exceeds a max_idle_time, it will be regard as two sessions.

A new IP address implies a new session by scanning the  server to recognize the sessions. Subsequent requests from the IP address is added to its session as long as the elapse of time between two consecutive requests does not exceed max_idle_time. Otherwise, the current session is finished and a new session is created.

B. Miningfrequentpatterns Our approach has been implemented using VC++ on  1.7GHz Pentium IV PC machine with 256 megabytes main memory, running Windows 2000. The experimental data set used was obtained from "www.nbol.net". The server logs are approximately 50M in size taken in November 2004.

After Web log files pre-processing, min_time choosing as 5 seconds, max_idle_time choosing as 30 minutes, we extracted sessions and pages from different sets of data after ignoring background images and unsuccessful requests.

Table 1 is the result of our algorithm in different sub datasets when p is 0.75 and minimum support of 1%.

There are 5 datasets in Table 1. In 1OM dataset, there are about 72589 records and 775 sessions extracted. URL page number is 147. Through competitive network of CNFP, about 65 neurons created in competitive layer. Table 1 also shows that the number of sessions is linear to the number of records in datasets, and page number increases with size of datasets.

Analyzing the frequent itemsets, we can find that some interesting association rules have been mined, such as 46.3% of all users taking care of stock are favor for national economy, 52.7% persons who like basketball are also pay more attention to football, etc. These useful relationships between URL pages may help webmaster understand web usage better and establish adaptive website to provide more suitable, customized services for users.

Table I  Datasets in experiment  SIZE RECORD_NUM SESSION NUM PAGE_NUM COMP_NEURON_NUM  1OM 72589 775 147 65 20M 148722 1505 172 124 30M 214104 2146 211 172 40M 287048 2848 234 227 50M 354312 3556 247 295  C. Comparison ofCNFP andApriori Because datasets are so large that FP-growth is different  to hold FP-tree in memory entirely, we select Apriori to be compared with our algorithm CNFP. We implement Apriori to the best of our knowledge based on the published reports on the same machine and compare in the same running environment. Figure 1 shows the relation between runtime and minimum support threshold with 50M dataset in size and p of 0.75. From Figure we can recognize that the execution times increase for both CNFP and Apriori as the minimum support is reduced because the total number of large.

CNFP performed better than Apriori as expected. It  shows that CNFP has good scalability with the reduction of minimum support threshold. Although the number of frequent itemsets grows exponentially, the run time of CNFP increases in a much more conservative way.

0 0,5 LO 1 Is Z. GI GI  .~ ~ ~ ~ W"Jt \  Fig. 1. Scalability with threshold  lv. CONCLUSION  We have proposed a novel algorithm combining competitive network with FP-growth to mine association rules. There are several advantages of CNFP:(1) CNFP  [4]  [5]  rides huge dataset into sets of similar data to construct '-sub-tree. It solves the problem of space cost that -growth exists. (2) In competitive learning of CNFP, nilar patterns are grouped by the network and represented a single neuron. This grouping is done automatically sed on data correlations. This partition, which is different m other arbitrary partition methods, is based on stering, so it makes global frequent itemsets from local quent itemsets easily. Experiment on web log files to ,cover the relation between pages users access show that QFP approach is efficient and practical for Web mining plications.

ACKNOWLEDGEMENT  This work is partially supported by Scientific Research nd of Zhejiang Provincial Education Department of ina(20030485) to Yihong Dong, Natural Science undation ofChina(NSFC 60472099) to Xiaoying Tai.

