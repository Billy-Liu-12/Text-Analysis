

Abstract????Sequential pattern mining approaches mainly deal  with finding the positive behaviour of a sequential pattern  that can help in predicting the next event after a sequence of  events. In addition, sequential patterns may exhibit  periodicity as well, i.e. during weekends 80% of people who  watch a movie in cinemas will have a meal in a restaurant  afterwards. This is a problem that has not been studied in the  literature. To confront the problem of discovering periodicity  for sequential patterns we adopt and extend a periodic pattern  mining approach which has been utilised in association rule  mining. However, due to the sequential/temporal nature of  sequential patterns, the process of finding the periodicity of a  given sequential pattern increases the complexity of the above  mentioned association rule mining approach considerably. As  a key attribute of any data mining strategy we provide a  comprehensive and flexible problem definition framework for  the above mentioned problem. Two main mining techniques  are introduced to facilitate the mining process. The Interval  Validation Process (IVP) is introduced to neutralise  complexities which emerge due to the temporal/sequential  nature of sequential patterns, whereas the Process Switching  Mechanism (PSM) is devised to increase the efficiency of the  mining process by only scanning relevant data-sets from the  source database. The approach proposed in this paper is  based on a post-mining environment, where the identification  of sequential patterns from a database has already taken place.

Index Terms????Incremental data mining, post mining  environment, sequential pattern, periodic patterns

I. INTRODUCTION  Advances in data storage technology mean that storing  the different status of data and its temporal information has  become feasible. By utilising the time dimension in the data  mining process, we can yield more accurate knowledge to  be applied in decision making processes.  Mining  sequential patterns is an important problem in knowledge  discovery and has significant applications in broad areas.

Discovering periodicity (cyclic behaviour) of sequential  patterns is one of the key temporal features to mine in  sequential data. Mining periodicity for sequential patterns   Fahad Anwar is with School of Computer Science, University of  Manchester, Manchester, UK, E-mail: fahad.anwar@manchester.ac.uk  Ilias Petrounias is with Manchester Business School, University of  Manchester, Manchester, UK Phone: +44-161 3063386, E-mail:  ilias.petrounias@manchester.ac.uk  Vassilis S. Kodogiannis is with School of Computer Science, Univ. of  Westminster, London HA1 3TP, UK,  E-mail: kodogiv@wmin.ac.uk  Violeto Tesseva and Desislava Peneva is with Centre for Biomedical  Engineering "Prof. Ivan Daskalov",Bulgarian Academy of Sciences,  Sofia-1113, Bulgaria, E-mails: {violeta,desi}@clbme.bas.bg    is a process of extracting information which can help in  predicting the temporal cyclic behaviour of these patterns.

In many situations sequential patterns with periodicity  information are more useful than simple sequential  patterns. For example, information that ?during every  weekend 80% of people who watch a movie in cinemas  will have dinner at a restaurant afterwards? is more  significant than the simple information of ?people who watch movies are likely to eat dinner in restaurants  afterwards?.

After reviewing previous research work in the area of  periodic pattern discovery, it is identified that the Chen  approach presented in [1] can be moulded for efficient  mining of periodic time intervals for a given sequential  pattern. However, since the approach mentioned purely  concentrates on mining periodic intervals for association  rules, implementing the same approach for sequential  patterns will increase the complexity of the mining process  considerably.  The main reason for this is the difference in  the nature of association rules and sequential patterns.

Association rules deal with the dependencies of events in a  database; however, they completely ignore the temporal  nature of these events, whereas sequential pattern mining is  a process which identifies the dependencies of events in  temporal/spatial ordering. This fundamental difference  means that, when using the Chen and Petrounias approach  to discover periodic time intervals for a given sequential  pattern, we have to tackle a number of challenges, such as  valid time windows, flying support, cyclic-flying support  and flying intervals. We will formally define and examine  these challenges in section 4.  The contributions that this  paper makes during the discovery of periodic time intervals  for a sequential pattern are listed below:    ? A comprehensive problem definition framework, which includes both a sequential pattern definition  framework and a framework to define temporal  features.

? A framework to discover all the periodic time intervals by scanning the database once only.

? The Interval Validation Process (IVP) and Process Switching Mechanism (PSM) are introduced to  discover all the periodic time intervals. The main  objective of IVP is to tackle the complexities which  emerge due to the sequential/temporal nature of  sequential patterns. PSM is devised to increase the  Efficient Periodicity Mining of Sequential  Patterns in a Post-Mining Environment  Fahad Anwar, Ilias Petrounias, Vassilis S. Kodogiannis, Violeta Tasseva, and Desislava Peneva   2008 4th International IEEE Conference "Intelligent Systems"       efficiency of the mining process, by only scanning  relevant intervals from the database.

The remaining of the paper is structured as follows:  Section 2 presents related work and identifies how it differs  from the work presented in this paper. Section 3 defines the  problem to investigate and Section 4 contains the main  algorithm. Section 5 presents incremental data mining  concept and  Section 6 contains generalized model for  proposed framework. Section 7 we conclude our work and  discusses future research work.



II.RELATED WORK  In [2], Ozden et al. identify the potential benefits of  finding cyclic association rules. The main problem to  investigate was to find association rules that repeat  themselves throughout the input data.  Two algorithms  were suggested to achieve the above mentioned goal. In the  first approach (Sequential Algorithm), a straightforward  method is used. That is, to first generate rules in each time  unit and, after that, to apply pattern matching algorithms to  discover cycles, which is known as Cycle Detection. To  reduce the expensive process of calculating the support of  item-sets, the Cycle pruning, Cycle skipping and Cycle  elimination techniques were introduced. The second  approach, which is also known as the ?Interleaved  Algorithm?, consists of two phases. First the cyclic large items are discovered and in the second phase cyclic  association rules are generated by using the already  discovered large item-sets and cycles without scanning the  database.

Mining Segment wise periodic patterns (also known as  partial periodic patterns) was first introduced by Han et al.

in [3]. The idea is based on the practical reality that in the  real world it is quite possible that not every point in a time  series may contribute to the periodicity (full periodicity);  rather only few time points contribute to the cyclic  behaviour of a pattern (partial periodicity). This type of  looser periodicity is also known as segment-wise  periodicity. Integration of three important techniques was  suggested to discover segment-wise periodicity in temporal  databases [3]:    ? Data Cube Structure  (Reference Cube, Working Cube)  ? Bit mapping technique  ? Apriori Mining technique   Mining asynchronous periodic patterns in time series  data was introduced by Yang et al. in [4]. The goal was to  find patterns that occur periodically in some sub-sequences  but their occurrences may be shifted due to disturbances. It  is useful to still consider in a pattern, if the disturbance is  within some user defined disturbance threshold.  Huang  and Chang in [5] propose a general model for mining  asynchronous periodic patterns. In their work three  algorithms SPMiner, MPMiner, and CPMiner were devised  to discover valid segments. A further improvement on  approached presented in [5] was carried out in [6].  Yang et  al., in [7], introduced the problem of discovering surprising  periodic patterns. In many applications, e.g. computation,  biology, an infrequent pattern can still be considered very  significant if its actual occurrence frequency exceeds the  prior expectation by a large margin. A surprising periodic  pattern is a pattern which may not have large frequency of  cyclic behaviour; however this frequency is more than the  expected one.

One of the difficult questions in mining periodicity is  how to describe the desired periodicity to mine. Moreover,  how to select the temporal data when the user does not  know how to describe the goal in terms of a specific query  [8].  Chen  and Petrounias address the above mentioned  problems in [9] and introduce a framework for expressing a  problem definition for temporal data mining. Calendar time  expressions were used to specify temporal features of  patterns (temporal patterns).  A simple example of temporal  pattern is < ?Low-Blood-Pressure ? Nausea?, Days.Hours  (21:22) >, which indicates that patients? low blood pressure  is followed by nausea from 21 to 22 o?clock every night.

Chen and Petrounias in [1] discuss the importance of  temporal features in association rules. In that research work  two important temporal aspects for association rules were  investigated.

? Discovery of Longest Intervals  ? Periodicity Discovery   Most of the work presented above is based upon a pre-  mining environment compared to the approach presented in  this paper which is based on a post-mining environment. In  a pre-mining environment, the mining algorithm is not  dependent on prior knowledge about the data-sets; whereas,  in a post-mining environment mining algorithms utilise  already mined results or perceptions of domain experts  about certain knowledge hidden in data-sets. An advantage  of this approach is that the new algorithms can be  integrated with any existing sequential pattern mining  approach.



III. PROBLEM DEFINITION FRAMEWORK  In a broader view, the problem of discovering all the  periodic time intervals for a given sequential pattern can be  defined as: ?We are given a time-stamped database D over  a time domain T and a sequential pattern SP along with all  user defined parameters as well as temporal constraints.

The goal is to discover all the periodic time intervals with  reference to the given sequential pattern?.

As we are dealing with two concepts, sequential pattern  and periodic time interval, the suggested problem definition  framework should be flexible enough to define both these  concepts comprehensively and easily. The framework for  temporal data miming presented by Chen and Petrounias in  [9] is utilised and extended here to define the concerned  mining problem.

16-3      A.  Sequential Pattern Definition Framework  A sequential pattern can be defined as a set of elements  (event/event-sets) SP=(e1,e2,e3?.en) with  temporal/sequential ordering satisfying the user defined  parameters of min_supp (minimum support), SD (Sequence  Duration) and SW (Sliding Windows). Support for a  sequential pattern is the fraction of data sequences in the  database having the given sequential pattern as sub-  sequence. SD (Sequence Duration) is the time limit during  which the sequential pattern must exist; whereas, the SD  (Sliding Window) constraint is used to relax the rigid  definition of transaction time. Hence, a sequential pattern  can be defined as:    Definition 1.1  <SP, min_supp, SD, SW >  <?computer?printer?scanner?, 60%, 45days, 3days>    B. Periodic Time Definition Framework  To discuss the periodic time definition framework, we  first need to introduce some basic temporal entities used to  define and interpret time related concepts [1].

? Chronons: In temporal databases transactions are stamped with chronons. A chronon is a non-  decomposable time interval of some fixed minimal  duration, in which an event takes place. Depending  upon different applications, the granularity of a  chronon varies. For example, it might be a second, a  minute or an hour.

? Interval (ITVL): Interval is a fundamental element of any periodic time. An interval is a non-empty set of  contiguous chronons. The granularity of intervals in  data mining applications varies due to the user  preferences; for example, interval granularity can be  of a week, a month, a quarter or a year.

? Periodic Time: Periodic time can be defined as a set of regular intervals in cycles; these intervals are  composed of three basic features:  ? Interval Range (RR): All the regular intervals in a periodic time are located in some specific position in  their corresponding cycles, for instance the position of  month can be 1-3 for the first quarter of year.

Hence, a periodic time can be represented as a triplet of  <Cycle, Granule, Range>. Cycle is the length (given by a  calendar unit) of a cycle, Granule is the duration (given by  a calendar unit) of a granular interval, and Range is a pair  of numbers which give the position of regular intervals in  the cycles [1].

Definition 1.2  PT=<Cycle, Granularity, Interval Range >  PT =<CY,GR,RR>  PT =<Year, Month, [10,12]>    Two user defined parameters of min_ilen (minimum  length) and min_freq (minimum frequency) are also very  important for defining the problem statement. ?min_ilen? is  used to define how long the time interval should be in order  to be considered as interesting periodic time interval. The  ?min_freq? parameter is used to determine the minimum  required frequency of valid periodic intervals. Therefore,  for a time interval to be considered as valid periodic time  interval, it has to satisfy both these parameters.

? Periodic time interval length has to be ? to min_ilen.

? Periodic interval has to occur in ? number of cycles (min_freq).

We further extend the problem definition by including  the important temporal feature of Time Period (TP) in the  mining process. TP represents the time period during which  a cyclic behaviour is found against a pattern.  For example,  we can say a pattern X occurs every Monday of the week  during the time period of 1 st March 1999 to 1  st July 2005.

C. Complete Problem Definition Framework  By combining the problem definition of both concepts  we can formulate the definition of the problem to be  confronted in this paper: ?Given a set of time-stamped  transactions D over a time domain T, and a sequential  pattern SP along with all user defined parameters  (min_supp, SD, SW); as well as the temporal information  of time period (TP), cyclicity (CY) and granularity (GR) of  interest, and minimum frequency (min_freq) and minimum  interval length (min_ilen) parameters; the mining problem  is to find all possible periodic times (PT) of < CY, GR, RR  > with respect to the given SP.?    Definition 1.3  < (SP, min_supp, SD, SW)  (TP, CY, GR, RR, min_ilen,min_freq)>  < (computer?printer?scanner, 60%, 45days, 3days)  (?1990-2004?,Year, Month, RR,2,70%)  >  Here, RR (Interval Range) is expected to be discovered.



IV. DISCOVERY PROCESS  According to the approach presented in [1] the process of  mining periodic time intervals for a given sequential pattern  can be divided into three main steps. Data transformation,  discovery of all the longest intervals for each cycle and  discovery process of all the periodic time intervals.

It is identified that almost all the database scanning and  processing is carried out in the first two phases (mainly in  the second phase); moreover, the third phase is completely  dependent on already discovered longest intervals for each  cycle (second phase). Therefore, it is realised that if we are  able to mould the first and second phase for effective  discovery of all the longest intervals for a given sequential  pattern in each cycle, then we can straightforwardly  implement the PIDeriver algorithm presented in [1] to  discover all the periodic time intervals. Hence, the rest of  the paper is mainly focused on the problem of discovering  16-4      all the longest intervals for a given sequential pattern in  each cycle.

A.  Data Transformation  For effective implementation of search techniques for the  discovery of all the longest intervals, the original database  has to be transformed. The data transformation process  includes the steps of data filtering, database transformation  and multiple segmentations of data (Fig 1).

Fig. 1.  Data Transformation    In the first step of data transformation, the database is  filtered according to the user defined Time Period (TP)  parameter. For example, if the TP is 2004-2005 then all the  transactions not having transaction time within the given  TP are excluded from the further mining process. In the  second step, the database is transformed into a sequence  database; where each sequence is a collection of  events/event-set mapped to specific sequence_ID (Unique  key of the record). Moreover, events/event-sets are sorted  on transaction date/time.

Since we have to find the longest intervals for each  cycle, the sequence database is divided into user defined  cycles D(cy),D(cy2),D(cy3)??..D(cyn). Next, the  segmented database is further divided into the user  interested granularity interval  D(cn)=ITVL1,ITVL2,ITVL3?. ITVLn.  For example, if the  granularity of interest is ?month? then data will be divided  in (January, February, March,??.December). In the last  step of data transformation, the database is further divided  into finer granularity according to the user defined Sequence Duration (SD) parameter. This further  segmentation is required as sequential pattern support has  to be calculated during the specified SD. In the case of the  example used above, data will be divided into days (Day1,  Day2?..Dayn).

B. Longest Interval Discovery Process  After the data transformation phase, the next phase in the  discovery process is to find all the longest intervals for each  cycle D(Cn).  We can define longest interval as:    ? Longest interval is a set of continuous valid intervals on a given time-line with the following properties:  ? The length of the interval cannot be less than the user defined min_ilen parameter.

? The longest interval cannot overlap with any other longest interval.

? The longest interval is followed by either an invalid interval or the last interval of the longest interval is  equal to the last interval of the said cycle.

Before further exploring the concept of longest interval  and discussing its discovery process, it is important to first  introduce the basic component of longest interval, which is  known as ?valid interval?.



I.) Valid Interval  An interval (ITVL) is valid with reference to a given  sequential pattern SP, if it satisfies all the user-defined  parameters (min_supp, SD, SW) within the said ITVL. For  example, if we have ITVL as month with 10 data sequences  in total and a given min_supp of 0.6,  we will say that this  ITVL is valid if and only if 6 or more data sequences  support the given sequential pattern and also satisfy the  other user defined parameters (SD, SW) (Fig 2).

Fig. 2.  Valid/Invalid Intervals    An interesting point here is that even if the ITVL does  not satisfy the min_supp parameter, it can still be  considered as valid interval. The reason for this notion lies  in the following characteristic of sequential patterns.

A sequential pattern can exist in multiple transactions.

Therefore, if we divide data into different ITVLs (data  transformation phase), it is quite possible that we may find  sequential pattern support, which exists in two ITVLs. To  differentiate these two support concepts, we introduce the  two kinds of support for sequential patterns (Fig 3):    ? Standard Support: Sequential pattern support exists completely in one interval (ITVL).

? Flying Support: Sequential pattern support exists between two intervals (ITVLs)    Once the flying support is discovered, the question arises  of how to decide in which interval (ITVL) it really belongs.

To answer this question we take the weight of sequential  pattern support as the deciding factor. By weight, we mean  support of different elements of the sequential pattern. If  the weight of the flying support is more towards ITVLx,  ITVITV Time  Valid  Invalid  16-5      then it is considered that flying support belongs to ITVLx;  whereas, if the weight of flying support is more towards  ITVLy; it will be considered as ITVLy support. However, if  the weight of flying support is equal between two ITVLs,  we will assume that flying support belongs to the ITVL  from where the sequential pattern flying support has  started.

Fig. 3.  Standard and Flying Support

I.1). Valid Interval Definition  After discussing the flying support concept, valid  interval can be defined as: an interval (ITVL) is valid with  reference to a given sequential pattern SP, if it satisfies the  user defined parameters (SD, SW) within the said ITVL  and one of the following conditions is true    ? Standard Support is  ?  min_supp  ? Standard Support + Flying Support   ?   min_supp  ? Flying Support  ?   min_supp   C. Longest Interval (Problem Definition)  The problem to mine all the longest intervals can be  defined as ?Suppose we have a database of events D and a  sequential pattern SP along with all its user defined  parameters and also the user defined granularity. The  problem is to discover all the longest intervals satisfying  the min_ilen parameter for each cycle D1,D2,D3?.Dn.?

I.)  Framework to Discover Longest Intervals  Due to the temporal and inter-transactional  characteristics of sequential patterns, it is recognised that  longest interval discovery will be quite an expensive  process. Consequently, it is important to devise different techniques, which can help to scan the minimum amount of  the database during the mining process. Keeping in view  the above consideration, we decompose the problem of  longest interval discovery into four sub-problems. These  sub problems are basically set of valid intervals with  different length:    ? Strictly Loose Seed Interval (SLSI)  ? Loose Seed Interval (LSI)  ? Seed Interval (SI)  ? Longest Interval (LI)    Fig. 4.  Framework to Discover Longest Intervals    Two main search techniques, the Interval Validation  Process (IVP) and the Process Switching Mechanism  (PSM) are introduced here for the discovery of all the  longest intervals in each cycle. The main objective of IVP  is to confront the complexities which emerge due to the  sequential/temporal nature of sequential patterns; whereas,  PSM is devised to increase the efficiency of the mining  process by only scanning relevant intervals from the  database.



I.1.)  IVP (Interval Validation Process)  During different stages of the longest interval discovery  process, PSM passes the CITVL (Current Interval) to IVP to  verify if the CITVL is valid or not (Fig 4). IVP first checks  the validity of CITVL by counting standard support and then  if required it also counts the flying support to check CITVL  validation.  IVP utilises DSCP (Dynamic Support Counting  Process) during the standard support counting process for  each data sequence. (DSCP scans only the minimum  number of required data-sets from the database in order to  find the support of a given sequential pattern). This process  continues until the counted support of the given SP is equal  to min_supp parameter and IVP returns ?valid? to PSM or  there is no data sequence left in CITVL to check (IVP returns  ?invalid? to PSM). If after checking the standard support,  IVP retains ?invalid? against CITVL then the flying support  concept needs to be explored (Fig 4).

Algorithm  IVP (Interval Validation Process) for standard ITVL  stage=s_supp   // indicate different stages of IVP  i=1;  //counter to fetch next record  CS=0;  //current support of given SP  CR  //current record  C_Supp  //calculated Support  RR  //remaining records  TR  //total records  if stage=s_supp then  // IVP is in standard support stage//  LR_ID= LR(CITVL) // Fetch the last record ID//  Loop  ITVLY  Standard Support Flying Support  ITVLX Time Line  16-6      {  CR= Fetch_Rec(CITVL,i)  //to fetch data sequence//  C_Supp= DSCP(CR, SP(SD,SW))  if  C_Supp<>0 then  CS=CS+C_Supp;  i=i+1;  Add(CSeq_Id, Seq_List)  else  i=i+1;  end if  if CS ? (min_supp*TR) then  return(?valid?)  else if ( (min_supp * TR)-CS > RR) or (i > LR_ID) )  i=0;  Store(CS,Data_Struc);  stage=?f_f_supp?  exit;  end if  }  end if  if stage=?complete?  //IVP on CITVL is complete//  exit  end if; Fig. 5.  IVP Algorithm for standard support      I) Flying Support Discovery  Flying support can exist on both sides of CITVL.

Therefore, first certain portions of CITVL and NITVL (Next  Interval) have to be scanned to find flying support of the  given SP. We can call this ITVL as FFITVL (Forward Flying  Interval). However, after checking the FFITVL if CITVL is  still invalid then certain portions of CITVL and PITVL  (Previous Interval) have to be scanned as well; we call such  ITVL as BFITVL (Backward Flying Interval) (Fig 6).

Fig. 6.  Flying Intervals    Once the FFITVL is created, the next step is to find pattern  support in it. Upon finding the flying support for CITVL, IVP  aggregates the support against CITVL in the data structure  (Table 1). This aggregation depends on the weight of the  discovered flying support. For example, if 70% of the  weight is in CITVL, then current support is aggregated with  0.7. The process continues until the min_supp parameter is  satisfied or the algorithm scans the last data sequence of  FFITVL.

Data Structure of IVP ITVLID ITVLSTATUS SUPPORTSTATUS CYCLE CALSUPPORT  CITVL Valid  Invalid  Standard  Flying  Both  Cycle  of the  CITVL  Calculated  Support    After scanning the FFITVL, if the min_supp parameter is  not satisfied, then IVP will count flying support in BFITVL.

Once the BFITVL is created, the next step is to count pattern  support in it. Upon finding the flying support, IVP  aggregates the support against CITVL. This process  continues until the min_supp parameter is satisfied or the  algorithm scans the last data sequence of BFITVL.



I.2.) PSM (Process Switching Mechanism)  The main aim of implementing PSM is to scan only  those intervals (ITVLs), which can be part of any longest  interval. This is done by switching the discovery process  into different modes (forward mode, backward mode and  jumping mode). Switching of process modes depends on  different scenarios during the discovery of SLSI, LSI, SI  and LI.  Let us first discuss the definitions of each sub-  problem.

Strictly Loose Seed Interval (SLSI): An interval is a SLSI  (Strictly Loose Seed Interval) with reference to a given  sequential pattern if and only if it is a valid interval and  satisfies both the following conditions    ? SLSI is not surrounded by immediate valid intervals.

? SLSI is not a part of any LSI, SI or LI   Loose Seed Interval (LSI):  An interval is loose seed  interval (LSI) with reference to a given sequential pattern if  and only if, it satisfies all of the following conditions:    ? At least first and last ITVLs of potential seed interval are valid.

? The distance between first and last valid interval of LSI is equal to min_ilen parameter.

? There is not a single invalid ITVL between first and last ITVLs of LSI.

Seed Interval (SI): An interval is considered as seed  interval (SI) with reference to a given sequential pattern if  the length of consecutive valid interval is equal to min_ilen  parameter.

Longest Interval (LI): The longest interval definition was  presented in section 4.2. In Fig 7 the longest interval is  depicted as LI=(ITVL17,ITVL18,ITVL19,ITVL20, ITVL21)

I.2.1)  PSM (Process Switching Mechanism) Algorithm  The PSM algorithm starts in forward mode by  undertaking the first problem, that is to find SLSI (Strictly  Loose Seed Interval).  It scans the first ITVL to check if it  is a valid interval.  If IVP discovers that CITVL (Current  Interval) is invalid then the process simply moves to NITVL  (Next Interval) and this process continues until PSM  discovers SLSI or the process reaches the last ITVL of the  said cycle (Fig 8-a).

Fig. 7.  Different stages of longest ITVL    However, if CITVL is recognised as valid interval it means  16-7      that we have found the first SLSI. Upon finding the SLSI,  PSM undertakes the second sub-problem (discovery of  LSI). According to the definition of LSI, for any LSI at  least first and last ITVL of potential loose SI have to be  valid, therefore PSM jumps to the last interval of the  potential loose seed interval. The reason for this jump is in  the following property of longest interval    ? The longest interval cannot be less than min_ilen and every ITVL within the longest interval has to be valid  ITVL.

Hence, if we found that ITVL8 is invalid then there is no  need to check the ITVLs between ITVL4 to ITVL7 since  they cannot be part of any longest interval (Fig 8-b)    After jumping to the last ITVL of potential LSI; PSM  again passes the CITVL to IVP to check if the ITVL is valid  or not. If it is recognised that CITVL is invalid then it means  current SLSI cannot be a part of any longest interval.

Therefore, PSM switches to forward mode by moving to  the NITVL (Next Interval) and the process of searching the  next Strictly Loose Seed Interval (SLSI) continues (Fig 8-  c).  However, if CITVL is valid at this stage, that means we  have found the first LSI. Upon discovering the LSI, PSM  confronts the third sub-problem (discovery of SI). To  discover SI, PSM has to scan the remaining ITVLs between  first and last ITVL of the already discovered LSI.

Therefore, PSM switches into backward mode and scans  the ITVL, which is one ITVL previous than the CITVL (Fig  8-d).

Validation of CITVL is checked by IVP again. If CITVL is  identified as valid interval then the process of discovering  the seed interval will continue.  PSM will remain in  backward mode and moves to the previous ITVLs one by  one to check the validity of different ITVLs. This process  continues until PSM reaches the already discovered valid  interval or it encounters an invalid interval (Fig 8-e).

During the process of discovering SI, if PSM encounters  an invalid ITVL at any stage, then it does not have to check  the rest of the ITVLs of LSI (as this LSI cannot be part of  any LI). In this scenario, PSM assigns a new value to SLSI,  that is the last valid interval identified by PSM in (see Fig  8-f new SLSI is assigned with ITVL7). Now the process of  discovering the next LSI proceeds again. According to the  definition of LSI, for any LSI at least the first and last  ITVLs have to be valid; therefore, PSM jumps to the last  interval of the potential loose seed interval. How long this  jump will be, depends on the min_ilen parameter. If PSM  continues in backward mode and reaches the already  discovered ITVL, then it means we have found a  consecutive set of valid intervals whose length is equal to  the min-ilen parameter (which is the definition of SI). In  that scenario PSM jumps to the first ITVL after the last  ITVL of current SI and the discovery process of LI  proceeds (Fig 8-g).  In the Longest Interval (LI) discovery  process, PSM switches to forward mode to check the  validity of the CITVL. However, if the CITVL is identified as  valid interval then the seed interval is extended by this  CITVL. This process continues until PSM encounters an  invalid ITVL or PSM reaches the last interval of the data  set. Once PSM encounters an invalid ITVL the process of  extending the seed interval terminates. The discovered LI is  stored in the data structure and the PSM algorithm proceeds  to the search of the next SLSI (Fig 9). As we have to  discover all the longest intervals for each cycle, the process  given in Fig 4 is recursive and it will continue until all the  longest intervals of each cycle are found.

D.  PIDeriver Algorithm for Periodic Interval Discovery  Once all the longest intervals for each cycle are  discovered with the above motioned approach, we can  straightforwardly implement the PIDeriver algorithm  presented by Chen in [1] to derive all the periodic time  intervals for a given sequential pattern.

Fig. 9.  Discovery process for LI

V. INCREMENTAL DATA MINING  Mining periodicity for sequential patterns is a time  consuming process. Maintaining the already discovered  periodic patterns in the updated database is very important,  since new data may invalidate some of the discovered  periodic patterns and new periodic patterns may emerge  due to new data. Assuming that the cyclicity, granularity  and sequential pattern of interest remain the same, the  approach presented in this paper to discover periodic time  intervals for a specific SP can be used for incremental  mining of periodic time intervals as well.  The approach  presented in this paper divides the main problem of finding  the periodic time intervals into two sub-problems: finding  the longest interval for each cycle and discovery of periodic  intervals by using already discovered longest intervals of  each cycle.  Since the second problem is purely based on  mining results of first problem, the discovered longest  intervals in the previous data mining efforts can be used in  an incremental data mining process. During the incremental  data mining process, the algorithm will only focus on  finding the longest intervals from new data. However, due  to the temporal nature of sequential patterns some portion  of the old database will be used as well, the size of this is  directly proportional to the user defined parameter of SD  (Sequence Duration). Since finding the longest interval  involves most of the processing and complexity during the  process of periodic time interval discovery, this approach  will benefit the incremental data mining quite significantly.



VI.GENERALISED MODEL FOR FRAMEWORK  The Generalised model (GN) shows the discovery  process of all data filtration, transformation, discovery of  16-8      all longest intervals for each cycle and periodic time  intervals. Transition Z1 represents the filtration process of  the time stamped database. The process of data  transformation is represented by transition Z2 and the data  segmentation by transition Z3.  Transitions Z4 and Z5 show  respectively the Process Switching Mechanism (PSM) and  Interval Validation Process (IVP). Transition Z1 has the  following form:    Z1 = <{l1, l2, l4}, {l3, l4}, r1>,  l3 l4  r1 = l1 false True  l2 false True  l4 W4_3 W4_4  W4_3 = ?The process of data filtration has finished?  W4_4 = ? W4_3.

Place l1 corresponds to the entrance point for the  stamped database in the GN. It is represented by one ?  token which enters the input place with initial  characteristic?a stamped database?. In place l2 enters ?  token with initial characteristic ?time period (TP)?.

The ? token simultaneously with the ?1 token passes  through transition Z1 and enter place l4. This place  corresponds to the process of filtration. The two tokens  merge and form one new token with initial characteristic  the result of the united characteristics of the tokens. On  each transition activation the new token passes through the  transition and enters again place l4 extending its  characteristic with the current results of the filtration  process. After the process finishes the final token moves to  place l3 obtaining as a characteristic, ?filtered database?.

Transition Z2 has the following form:    Z2 = <{l3, l5, l7}, {l6, l7}, r2>,  l6 l7  r2 = l3 false True  l5 false True  l7 W7_6 W7_7  W7_6 = ?The process of data transformation has finished?,  W7_6 = ? W7_7.

The description of transition Z2 functioning is similar to  the one of transition Z1. As a joint place between transitions  Z1 and Z2 place l3 do not need any addition explanations.

The tokens from place l3 pass through the transition and  enter place l7, which corresponds to the process of data  transformation. Place l5 is an entrance point for the  parameter giving the sequential pattern (SP), which is  represented by one ? token. ? token enters the net with  initial characteristic, ?sequential pattern?. The tokens from  places l3 and l5 pass simultaneously to place l7, merge and  obtain join characteristic. This characteristic is extended on  every transition activation by the current results of the  transformation process. After the process finishes the final  token moves to place l6 obtaining as characteristic  ?sequence database? The process of data segmentation  consists of three consecutive stages; splitting into user  defined cycles, division into user interested granules and  granulation according to user defined sequence duration  parameter. The form of transition Z3 is the following:    Z3 = <{l6, l8, l9, l10, l12, l13, l14}, {l11, l12, l13, l14}, r3>,  l11 l12 l13 l14  l6 false true false false  l8 false true false false  r3 = l9 false false true false  l10 false false false true  l12 false W12_12 W12_13 false  l13 false false W13_13 W13_14  l14 W14_11 false false W14_14  W12_12 = ?The process of database division into user  defined cycles has not finished?, W12_13 = ? W12_12,  W13_13 = ?The process of database granulation has not  finished?, W13_14 = ? W13_13, W14_11 = ?The process  of database segmentation has finished?, W14_14 = ?  W14_11.

In places l8, l9 and l10 enter respectively one ?, ? and ?  token with initial characteristics ?cyclicity interval  (CY)?,  ?granularity interval (GR)? and ?sequence duration  (SD)?.

At the first activation of the transition the two tokens  from places l6 and l8 pass simultaneously through it, merge  into one new token and enter place l12. At the beginning the  newly created token obtains composite characteristic. It  extends its characteristic on every pass through the  transition and entering into place l12 with the current state  of the process of database division into user defined cycles.

After this process finishes the resulting token  simultaneously with the ? token from place l9 pass through  transition Z3 and enter into place l13. In this process the two  tokens merge into one token with initial characteristic the  composition of the characteristics of the parent tokens. Like  in the previous case the resulting token enters place l13  extending its characteristic with the current state of the  process until a granulated database is obtained. On the next  step the obtained token enters place l14 simultaneously with  the ? token from place l10. The two tokens unite each other  merging their characteristics. The newly created token  passes through transition Z3 and enters place l14 until a final  granulated database is obtained. On each entrance into  place l14 the token extends its characteristic with the current  state of the process of database final granulation. At the end  of this process the token moves to place l11 with a  characteristic ?segmented database?. Transition Z4 has the  following form    Z3 = <{l6, l8, l9, l10, l12, l13, l14}, {l11, l12, l13, l14}, r3>,  l11 l12 l13 l14  l6 false true false false  l8 false true false false  r3 = l9 false false true false  l10 false false false true  l12 false W12_12 W12_13 false  l13 false false W13_13 W13_14  l14 W14_11 false false W14_14  16-9      W12_12 = ?The process of database division into user  defined cycles has not finished?, W12_13 = ? W12_12, W13_13 =  ?The process of database granulation has not finished?,  W13_14 = ? W13_13, W14_11 = ?The process of database  segmentation has finished?, W14_14 = ? W14_11.

In places l8, l9 and l10 enter respectively one ?, ? and ?  token with initial characteristics ?cyclicity interval  (CY)?,  ?granularity interval (GR)? and ?sequence duration  (SD)?.

At the first activation of the transition the two tokens  from places l6 and l8 pass simultaneously through it, merge  into one new token and enter place l12. At the beginning the  newly created token obtains composite characteristic. It  extends its characteristic on every pass through the  transition and entering into place l12 with the current state  of the process of database division into user defined cycles.

After this process finishes the resulting token  simultaneously with the ? token from place l9 pass through  transition Z3 and enter into place l13. In this process the two  tokens merge into one token with initial characteristic the  composition of the characteristics of the parent tokens. Like  in the previous case the resulting token enters place l13  extending its characteristic with the current state of the  process until a granulated database is obtained. On the next  step the obtained token enters place l14 simultaneously with  the ? token from place l10. The two tokens unite each other  merging their characteristics. The newly created token  passes through transition Z3 and enters place l14 until a final  granulated database is obtained. On each entrance into  place l14 the token extends its characteristic with the current  state of the process of database final granulation. At the end  of this process the token moves to place l11 with a  characteristic ?segmented database?. Transition Z4 has the  following form    Z4 = <{l11, l17, l18, l19}, {l15, l16, l17, l18}, r4>,  l15 l16 l17 l18  l11 true false False false  r4 = l17 false W17_16 W17_17 false ,  l18 false false W18_17 true  l19 false false True false  W17_16 = ?The process of data segmentation has  finished?, W17_17 = ? W17_16, W18_17 = ?The PSM has to  jump minimum length parameter steps?.

Initially in place l18 enters one ? token with initial  characteristic ?minimum interval length (min_ilen)?.

The already segmented database from place l11 pass  interval (ITVL) by interval through transition Z4 to place  l15. The token from place l11 passes directly to place l15 for  validity check without obtaining any new characteristics.

The ? token moves simultaneously with one of the tokens  in place l19 to place l17 obtaining as characteristic the  current state of the process of the longest interval (LI)  finding?    At the end of this process the resulting tokens move to  place l16 and merge with the tokens from the same interval  obtaining characteristic ?segments of the longest interval?.

The form of transition Z5 is    Z5 = <{l15}, {l19}, r5>,  l19  r5 = l15 true .



VII. CONCLUSION AND FUTURE WORK  In this paper the problem of finding the periodic time  intervals for a given sequential pattern is addressed. The  approach presented in this paper divides the main problem  into two sub-problems: finding the longest intervals for  each cycle and discovery of periodic time intervals by  using the already discovered longest intervals of each  cycle. Almost all the data processing and complexity is  covered during the process of finding the longest intervals.

Moreover, the second problem is purely based on mining  results from the first problem.  Therefore, in this paper we  mainly focused on the problem to find all the longest  intervals for each cycle. To confront the above problem  efficiently, we introduced two main search techniques IVP  (Interval Validation Process) and PSM (Process Switching  Mechanism).  In this paper we have presented an effective  mining approach for finding all the periodic time intervals  for a given sequential pattern. As a future work the process  presented in this paper can be extended to find periodic  time intervals for all the given sequential patterns in one  database scan. However, to accomplish this task a more  complex data-structure/memory management technique  needs to be implemented.

