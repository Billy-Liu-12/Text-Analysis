

Abstract?Association rule mining associates one or more attributes in a dataset to discover hidden and significant relationships between the attributes. The quality of the association rules are strongly limited by the interestingness measures and the number of the rules obtained. This paper intends to propose a technique to reduce the quantity of the rules without compromising the usefulness factor and thereby improves the computational efficiency of rule mining. The proposed framework reduces the number of rules by combining mining and post-mining techniques. Particle swarm optimization is used in the mining process to compute an optimal support and confidence parameters. The collection of strong rules is then obtained using these computed parameters. In the post-mining process, domain ontology is designed to map the database. Domain ontology helps in providing a formal, explicit specification of a shared conceptualization. Based on the user knowledge and the domain ontology, most interesting rules are discovered. A GUI based framework is also designed to assist the users in discovering the rules. Promising results were obtained when experiments were conducted with the Adult dataset of UCI machine learning repository.

Keywords- Association rule mining; particle swarm optimization; Ontology;  User-defined constraints.



I. INTRODUCTION Association rule mining (ARM) aims in uncovering  interesting and useful patterns in a transactional database.

Association rules are conditional statements of the form P?Q where P and Q are itemsets, which are disjoint in nature.

Association rules are useful in analyzing and predicting customer behavior and it is also important for decision-making tasks. Apriori is the first algorithm for association rule mining.

Support and confidence are principal elements used in evaluating the quality of rules generated. The major drawback in ARM is the generation of large volume of rules. Extracting useful knowledge from the large volume of rules is difficult, because the relevant information for mining may be hidden within the rules. Setting the support and confidence thresholds plays a crucial role in the ARM. Setting these parameters too low will result in a tremendous amount of rules which have less value for analysis. Setting too high will produce rules of common knowledge. Setting the values for support and confidence puts the users in problem.



II. LITERATURE SURVEY  A.  Association rule definition: Association rules are conditional statements that help to  reveal relationships between distinct data items in a relational database or other data storage. An association rule has two parts, antecedent and consequent.  First part is a set of items found in the transactional data. Second part is an itemset that is present in combination with the antecedents. An association rule is an implication of the type P?Q, where P and Q are itemsets, which are disjoint in nature. i.e., P ? Q = ?.

Generally, the power of the association rule is determined by its objective parameters such as support and confidence.

Support determines the percentage of transaction containing both antecedent and consequent in the dataset. Confidence determines the ratio of the number of occurrence of both antecedent and consequent to the number of occurrence of antecedent in the data set.

Support is an objective measure which frequently takes very low value. A low support rule is expected to be less interesting from the business perspective, because it may not be useful in forecasting a customer?s purchase behavior. Confidence on the other hand, measures the consistency of the conclusion made by the rule.

B.  Association rule algorithm The most widely adopted algorithm for mining association  rules is the Apriori algorithm, proposed by Agarwal et al. [4] in 1993. The major task involved in the Apriori association rule mining algorithm is decomposed into two subtasks. First task extracts all the itemsets that satisfy the minimum support threshold. The second task, extracts high confidence rules from the frequent itemset which was obtained from the previous subtask.

C.  Concept of Ontology Ontology is a theory concerned about the nature and  relations of beings. Ontologies [6] have received much attention in various areas such as information retrieval, multiple agent systems and database design. Ontologies      538 ICRTIT-2012  contain concepts for classes, properties and relationships of entities in a specified domain of knowledge. Four types of ontologies are proposed in literature [5] namely Upper or top level ontologies, Domain ontologies, Task ontologies and Application ontologies. In our work, Domain ontology is used, which are descriptions of specific topic or subject areas.

D.  Particle Swarm Optimization Particle swarm optimization (PSO) proposed by Kennedy  and Eberhart [7] in 1995 is a population-based evolutionary computing technique. It does both exploration and exploitation of the solution space. PSO is popular, because of its social behavior and performance. Every particle in the solution space is assigned with a random velocity, with which the particles flow through the problem space following the present best particles.

PSO is initialized with a set of particles uniformly distributed over the solution space. According to an objective function, each particle?s position is estimated. Current position of the particle is updated, if it is found to be better than its previous position. Particle best(pbest) and global best (gbest) are two significant values used in computing the current position of each particle. pbest signifies the best solution of a particle so far achieved and gbest signifies the best solution by any particle in the population so far achieved. Each particle modifies its velocity and position with the Eqs. (1) and (2) [8]:  Vit+1 = ?Vit+ c1r1t (pbi t ? xj t) + c2r2t (gb t ? xj t)                   (1)  xit+1=xi t + Vi t+1 (2)   where Vi t+1 is the velocity i th particle?s at time instance t+1, Vi t  is the velocity ith particle at time instance t , ? is the inertia weight,  r1 and r2 are random numbers between (0,1),  c1 and c2 are learning factors usually set as c1= c2 = 2. xj the current particle?s solution and  pbi and gb are the particle-best and the global best solutions respectively.

Clerc[9], proved that the use of the constriction factor (X) into PSO, improves the convergence rate to a very great extent.

These coefficients can prevent explosion and induce particles to converge on local optima.

Vi t+1 = ?(?vi t+ c1r1t (pbi t ? xj t) + c2r2t (gbt ? xjt))                  (3)  X=                                                                    (4) where ? is a constant and ?= c1 +c2 > 4.0

III. METHODOLOGY The proposed methodology involves two steps. First, the  association rules are generated from the database using particle swarm optimization. This step provides a mechanism to effectively choose the threshold support and confidence values.

In the second step, generated rules are reduced using post- mining techniques.

A.  The proposed algorithm The proposed algorithm comprises of two parts, mining  using particle swarm optimization and post-mining using ontology. Fig. 1 illustrates the algorithm structure.

Fig.1. The proposed association rule mining algorithm          539 ICRTIT-2012  B.  Mining using PSO The data preprocessing steps should be done for applying  PSO. First, the database is transformed into binary form and then partition point for the data is calculated. PSO is used as a module which computes best fitness value using the method proposed by Kuo et al [2]. The procedure for representing the chromosome, calculating the fitness value, generating the population, evaluating the best particle and termination criteria are explained in the following steps.

1) Binary transformation and chromosome encoding: Each record in the transaction is transformed into binary type data represented as either 0 or 1. The occurrence of an item in the transaction is represented by 1, else it is denoted by 0. The scanning of the database is accelerated by this approach.

Chromosome encoding is done using front and back partition of a particle. By the definition of association rule, the intersection of itemset X and itemset Y must be null. String encoding approach is used for chromosome encoding.

2) Fitness value calculation: The optimality of the particle is  determined by calculating the fitness value of the particle. The fitness value is derived from the fitness function. The objective of the fitness value can be either as a maximizing or minimizing fitness function. The target function employed by Kung [10], is used to compute the fitness value of a particle is given in Eqn (5)   Fitness(k)=confidence(k)*log(support(k)*length(k)+1)        (5)  where, confidence(k) represents the confidence of the association rule of the form k, support(k) is the support of the association rule of form k , length(k) is the length of association rule of form k. Fitness(k) is the fitness value of association rule of type k. The original data is ordered into a matrix, where the each row represents a transaction and the columns represent items present in the transaction. The efficiency of the system is improved by this approach.

3) Population generation: The initial population comprises of particles with larger fitness values. The size of the swarm can be large if convergence needs to be faster.

4) Particle updation: The maximum fitness value obtained  by the particle is taken as the ?gbest?. Each particle?s initial position is taken as ?pbest?. Depending upon the cognitive and social component in the equations (1) and (2), the initial position of the particle is updated.

5) Termination condition: Condition for terminating the  evolution is necessary. The evolution process can be terminated when the fitness of all the particles in a solution space remains same in the next iteration. The maximum number of iterations can be also set as a termination condition.

Finally, the support and confidence of the best particle is taken as optimal value for minimal support and minimal confidence in the association rule mining.

C.  Post-mining using Domain Ontologies 1) Constructing ontology using Prot?g?: The attempt to  integrate user knowledge using ontologies was proposed by Claudia Marinica et al. [1]. Prot?g? 3.4.1 is open source software which is used to create ontology. Conceptual descriptions are present in the domain ontology. The vocabulary of the concepts for the dataset is also specified.

Each class can have any number of sub-classes. These sub- classes take the properties of classes. Instances are created for each sub-class. All the values in the dataset should come under any of the sub-classes. Object and data type properties can be given for the classes in the ontology. The classes along with their instances are required to be generated. The process flow of constructing a ontology is given in the Fig.2.

Fig.2. Flowchart of process flow   2)  Operators over Rule Schemas: The specialization  language proposed by Liu et al. [3] represents user expectations in the form of rule schemas. A rule schema defines the user expectations in terms of rules. The discovered rules are filtered using these rule schemas. The interesting rules are filtered using the four types of rules. They are:  Conforming rules: A rule is said to be conforming, if it matches both the antecedent and consequent part of the rule schema.

Unexpected consequent rules: A rule is said to be unexpected consequent, if it matches with only the antecedent part of the rule schema.

Start  Identify and create the Classes  Create the instances of the classes  Create the properties  Associate the classes  Ontology complete      540 ICRTIT-2012  Unexpected antecedent rules: A rule is said to be Unexpected antecedent, if it matches with only the consequent part of the  rule schema.

Both-side unexpected rules or Pruning: A rule is said to  be Both-side unexpected rules or Pruning, if it does not match both the antecedent and consequent part of the rule schema.

The filtering of rules depends on the operators that are  applied over the rule schemas. Four operators are used in our post-mining process. They are:  Pruning: If a pruning operator P is applied over rule schema RS, P(RS), all association rules matching the rule schema are removed.

Conforming: If a conforming operator C is applied over rule schema RS, C(RS), all association rules matching the rule schema are extracted.

Unexpectedness: If a unexpectedness operator U is applied over rule schema RS, U(RS), all association rules unexpected regarding the antecedent, rules unexpected regarding consequent and rules unexpected regarding the both sides are extracted.

Exceptions: If a exception operator E is applied over implicative rule schema RS(A B), E(RS), all association rules matching the new implicative rule schema A?Z  ? B, are extracted, where Z is a set of items.



IV. RESULTS Experiments were conducted with the Adult database of  UCI machine learning repository. Attribute values of the instances are transformed into binary format. By applying the PSO algorithm, minimum support and confidence values are computed as presented in Table 1.

TABLE 1  PSO threshold value results   Results Minimal Support Minimal Confidence  1 0.1219 0.7755  2 0.1828 0.5635  3 0.1996 0.5465  4 0.2217 0.5316   In this work, the maximal value 0.2217 was taken as the  minimum support threshold value. Using Weka 3.6, the input parameters such as minimum support, the upper and lower bound of confidence, the delta parameters and the number of rules were set as shown in Fig.4. By applying Apriori  algorithm, 1000 best association rules are extracted in our experiment. Domain ontology for Adult database was constructed using Prot?g? 3.4.1.  Design of the ontology used, is shown in the Fig.3. The concepts in the ontology are extracted and stored in SQL server. Analysis on post-mining process is done initially with 1000 rules. These large amount of rules discovered lack user knowledge. Rule Schemas defined by user helps in improving the efficiency of the results by reducing the number of rules. List of rule schemas used in our work is shown in Table 2.

Fig.3. Ontology construction using Prot?g? 3.4.1                            Fig.4. Rule Generation using Weka 3.6          541 ICRTIT-2012  TABLE 2 User defined rule schemas   User defined Rule Schemas    RS1 : <Relationship ,Master-degree ? sex>  RS2 : <Private-sector, Capital-gain ? Race>  RS3 : <Age, Race ? Sex>  RS4 : < Marital- status, Professionals? Class>  RS5 : <North-America, Government ? Hours-per-week>   The rules are reduced by applying the operators such as  pruning (P(RS)), conforming (C(RS)), unexpected antecedent(UP(RS)) and unexpected consequent.(UC(RS)).

The number of rules reduced by each operator is shown below in Table 3.

TABLE 3 Reduction of Rules    USER-DEFINED RULE SCHEMAS  OPERATOR NO. OF RULES  NO. OF RULES REDUCED  RS1 : <Relationship , Master-degree ? sex>  P(RS1) 692 308  RS2 : <Private- sector , Capital- gain? Race>  UC(RS2) 516 176  RS3 : <Age, Race ? Sex>  UP(RS3) 263 253  RS4 : < Marital- status, Professionals? Class>  C(RS4) 27 236  RS5 : <North- America, Government ? Hours-per-week>  P(RS5) 13 14

V. CONCLUSION  For effective decision making, association rule mining is one of the popular techniques in data mining. Apriori algorithm is the widely used algorithm for ARM. The performance of the Apriori algorithm is influenced by the support and confidence values. Particle swarm optimization algorithm can provide feasible threshold values for minimal support and confidence for improving the efficiency of ARM.

Domain ontology help to integrate user domain knowledge  related to the database. Use of the operators over rule schemas improves the effectiveness of the post-mining process.

Combining PSO and domain ontology interactively, reduced excessive amount of rules without compromising the usefulness of rules.

