Hybrid Strategies for Attribute Relation Learning from Candidates

Abstract Attribute relation learning is important, but has  been few studied. This paper proposes hybrid strategies for attribute relation acquisition from candidate attributes. The composition of candidate attributes is firstly analyzed and subdivided into three types: non-attribute vocabularies, invalid attribute, and valid attribute. Secondly, the HowNet-based filtering strategy is presented which filters out the non- attribute vocabularies and invalid attributes from the candidates using the knowledge of ?is-a? relations and attribute-host relations described by attribute sememe in HowNet. Thirdly, the pruning strategy based on domain concept tree is proposed to further perfect the associations between a concept and its candidate attributes. We define some pruning rules through which some redundant, unreliable, even wrong attributes can be discarded from candidates and some lost attributes can be recalled. Our results about attribute relation learning show the efficiency of our hybrid strategies.

1. Introduction  Concept intension is the aggregation of common attributes of all instances belonging to the concept.

Therefore, it is very important to identify attributes of a concept for the understanding of concept. Besides, attribute relation has an important role in many ontology-based computer application systems. But comparing with is-a relation, researchers pay little attention to attribute relation. Almost all-existing ontology learning tools and systems don?t provide support for attribute relation learning.

Classification of attributes varies with the difference of understanding. According to Pustejovsky?s Generative Lexicon theory [1], there are four types of attributes: the Formal Role, the Constitutive Role, the Telic Role and the Agentive Role. In order to identify concept attributes, Poesio and Almuhareb[2] firstly collected candidate attributes using text patterns. They considered that the training data in the experiment could be classified into six type categories: qualities, parts, related-objects, activities, related-agents and non-attributes. And then, they constructed attribute classifier using four types of information: morphological information, an attribute model, a question model, and an attributive-usage model. These  works are positive attempts about attribute knowledge.

But all the above categories of attribute are broad, and could meet the requirement of attribute relation acquisition of ontology construction.

This paper proposes hybrid strategies for attribute relation acquisition from candidate attributes. The candidate attributes are collected using the text-pattern method implemented in our ontology learning system, OntoFactory [3]. The HowNet-based filtering strategy is presented which filters out the non-attribute vocabularies and invalid attributes from the candidates.

The pruning strategy based on domain concept tree is proposed, so that some redundant, unreliable, even wrong attributes can be removed from candidates and some lost attributes can be recalled.

The rest of this paper is organized as follows. In Section 2, we review HowNet and attribute knowledge in HowNet. We also introduce our ontology learning system, OntoFactory. Section 3 details filtering strategy of candidate attributes based on HowNet.

Pruning strategy of attribute relations based on domain concept tree is introduced in Section 4. Experimental results are provided in Section 5. Finally, we present conclusions of our work.

2. Background 2.1 HowNet and its attribute knowledge  HowNet is an online common-sense knowledge base exposing inter-conceptual relations and inter- attribute relations of concepts as connoted in lexicons of Chinese and their English equivalents [4]. The essential concept is sememe which broadly speaking refers to the smallest basic semantic unit that cannot be reduced further and is used to define the other words that are not the sememe. These sememes have been classified into five types (event, thing, attribute, value of attribute and sub-feature) that comprise the fundamental layer of the knowledge base.

The way understanding attribute in HowNet is any one object necessarily carries a set of attributes.

Similarities and differences between the objects are determined by the attributes they each carry. There will be no object without attributes. The relationship between the attributes and their host is unbending. The attributes simply come with the host and vice versa [4].

There exist attribute sememe and attribute value sememe in HowNet. Attribute sememes are subdivided  Annual IEEE International Computer Software and Applications Conference  DOI   Annual IEEE International Computer Software and Applications Conference  DOI 10.1109/COMPSAC.2008.21   Annual IEEE International Computer Software and Applications Conference  DOI 10.1109/COMPSAC.2008.21   Annual IEEE International Computer Software and Applications Conference  DOI 10.1109/COMPSAC.2008.21     into seven types: appearance, measurement, property, relationship, situation, quantity property and quantity.

They are hierarchically organized according to taxonomic relations among attributes. The hierarchical tree is shown in Fig.1.

Fig. 1 The hierarchical tree of attribute sememe Attributes are necessarily defined in terms of the  possible classes of host in HowNet, which is to annotate the attribute-host relation. An example of attribute sememe?s definition is given in Fig.2. We can find that the host of attribute ?fatness? is concept ?animal? or ?human? from the attribute sememe?s definition given in Fig.2. The character ?&? is the symbol used to label the attribute-host relation.

Fig. 2 The form of attribute sememe?s definition 2.2 OntoFactory  OntoFactory is an system for automatic acquisition of domain ontologies from web pages, domain dictionaries, general ontology and other sources [3]. It supports the language of English and Chinese. The tasks of ontology learning in OntoFactory include domain concept acquisition, is-a relation learning, attribute relation learning and ontology instance acquisition. Concept learning is achieved using statistical, linguistical approaches and short-term information extraction techniques. Is-a relations are mainly learned through the method based on self-study pattern and based on the discovery of web directories.

Attribute relation acquisition is achieved on the basis of results of concept learning and is-a relation learning.

The method of text-pattern attribute acquisition is implemented in OntoFactory system.

3. Filtering  of Candidate Attributes Based on HowNet  Candidate attributes of a concept can be collected using the text-pattern method implemented in our ontology learning system, OntoFactory. Acquired candidates consist of many other vocabularies, besides attributes. The goal of filtering of candidate attributes is to separate attributes from the others.

Candidates are composed of attribute vocabularies and non-attribute vocabularies. Attribute vocabularies can be further divided into valid attributes and invalid attributes. Valid attributes are attribute vocabularies between which and their host concept there exists the attribute-host relation described in HowNet. Invalid attributes are attribute vocabularies that don?t satisfy the attribute-host relation. The composition of candidates discussed above is shown in Fig.3.

Candidate Attributes  Fig. 3  Composition of Candidate Attributes  Non-attribute Vocabularies  Attribute Vocabularies  Valid Attributes  Invalid Attributes   Filtering of candidate attributes based on HowNet is  to filter out non-attributes vocabularies and invalid attributes from candidates using the knowledge of attribute sememe in HowNet. The filtering process includes two phases: non-attribute vocabularies filtering phase and invalid attributes filtering phase.

The first phase is to discard non-attribute vocabularies from candidate attributes, and then attribute vocabularies are left. The second phase is to delete invalid attributes from attribute vocabularies, and then only valid attributes satisfying the attribute-host relation is left. Our goal is reached after the two-phase filtering. Filtering of non-attribute vocabularies and invalid attributes are discussed below in detail.

3.1 Filtering of Non-attribute Vocabularies  Candidate attributes include known vocabularies and unknown vocabularies in HowNet from the perspective of HowNet. For a known vocabulary, we may directly determine whether a candidate is an attribute vocabulary or not according to the definition of attribute sememe in HowNet. For an unknown vocabulary, the determination process is relatively complicated. The idea is to measure the similarity between the candidate and existing attribute vocabulary in HowNet, and to make determination according the similarity. If the value of similarity is smaller than an experiential threshold value, the candidate is view as a non-attribute vocabulary. If the value of similarity is bigger than or equal to the experiential threshold value, the candidate is view as an attribute vocabulary. Besides, we can identify the attribute type that the candidate belongs to, according to the most similar attribute descending by the value of similarity and ?is-a? relations of attribute sememe described in HowNet.

From the above basic idea of filtering of non- attribute vocabularies, we can find that it is the key to     measure the similarity between the unknown vocabulary and existing attribute vocabularies in HowNet. We firstly search the candidate in other semantic dictionaries, such as WordNet, Synonyms dictionary. If the candidate is found in above dictionaries, then the similarity is measured using the semantic similarity algorithm proposed in [5]; else the similarity is calculated using the literal similarity algorithm proposed in [6].

3.2 Filtering of Invalid Attributes  After filtering of non-attribute vocabularies, there are only left attribute vocabularies in candidate attributes. The next work is to filter out invalid attributes from attribute vocabularies, which is based on the previous work.

Same as non-attribute vocabularies, attribute vocabularies can also be divided into two types: known vocabularies and unknown vocabularies in HowNet, from the perspective of HowNet. Respectively, filtering of invalid attributes includes the processing of known candidates and unknown candidates. For a known attribute vocabulary in HowNet, we can match the attribute vocabulary and the concept with the attribute-host relation described by the attribute sememe in HowNet. If the match succeeds, the attribute vocabulary is determined as a valid attribute of the respective concept, or else as an invalid attribute.

For an unknown attribute vocabulary in HowNet, due to recording of its most similar attribute and identification of attribute type, we can determine whether it is an invalid attribute or not according to its most similar attribute.

4. Pruning of Attribute Relations  After filtering of candidate attributes, some refinement and pruning work should be done in order to further perfect the associations between a concept and its candidate attributes. In some cases, some redundant, unreliable, even wrong attributes need to be discarded from candidates. In other cases, some lost attributes need to be recalled through rules. We solve these problems using our pruning method based on domain concept trees, which is detailed as below.

4.1 Generation of Domain Concept Tree with Attributes  The domain concept tree with attributes is the basis of our pruning method. The generation process of domain concept tree with attributes consists of two steps: the generation of domain concept tree and the mapping of candidate attributes.

In order to generate the domain concept tree, we should first make use of the knowledge of ontology concepts and ?is-a? relations among them, which are learned by OntoFactory system. The generation rule of domain concept tree is defined as below.

Rule I: Let Hc={(ci,c) | is-a(ci,c), i=1,2,?,n} be the ?is-a? relations aggregation, where c is the hypernym concept, ci is the hyponym concept. When generating the domain concept tree, we create a tree node for each concept, and let the tree node containing concept c as the parent node, other tree nodes as child nodes.

The mapping of candidate attributes is to map all candidate attributes into the domain concept tree. It needs to find the tree node containing the host concept of candidate attributes in the domain concept tree, and then to insert candidate attributes into the tree as the found tree node?s attributes. An example of domain concept tree with attributes is shown in Fig. 4.

publications  Fig. 4  A domain concept tree with attributes  paper publications magazine(price,publisher,intrudction,Vol)  electronic eublications(price,publisher)  book(price,publisher,intrudction) cyclopaedia(price,publisher,intrudction) ??  CD(price,publisher,singer?s name) VCD(price,publisher,film?s name) video tape(price,publisher,singer?s name) music tape ??   4.2 Pruning Rules Based on Concept Tree  After Generation of domain concept tree with attributes, we can prune the attribute relations in the domain concept tree using the leaf-root methods. Our pruning methods are implemented based on the following three pruning rules:  Rule II: If candidate attribute aggregations of each hyponym concept of concept c contain candidate attribute a, then attribute a is determined as an attribute of concept c and should be recalled.

Rule III: If candidate attribute aggregations of concept c and its most hyponym concepts contain candidate attribute a, then attribute a is determined as an attribute of concept c, and so attribute a should be added to candidate attribute aggregations of other hyponym concepts which don?t contain attribute a.

Rule IV: If attribute a only exists in candidate attribute aggregations of concept c and few hyponym concepts, then attribute a is an unreliable attribute and should be discarded from candidate attribute aggregations of concept c and its all hyponym concepts.

The following is some explanations of applying above rules to prune attribute relation with the Fig. 4.

Due to all hyponym concepts of ?paper publications? have the attributes ?publisher?, ?introduction? and ?price?, we can infer that attributes ?publisher?, ?introduction? and ?price? are the attribute of concept ?paper publications? according to RULE II. Owing to concept ?electronic publications? and its most     hyponyms have the attribute ?price? and ?publisher?, we can determine that the hyponym ?music tape? has the high probability of having the attribute ?price? and ?publisher? according to RULE III, though no attribute is learned in the learning process.

5. Experimental Results  We selected online consumed product sold in electronic markets, such as www.alibaba.com.cn and www.hc360.com, as our experiment domain. We recently acquired concepts and is-a relations between these concepts using our ontology learning system, OntoFactory. After constructing and refining the ontology, there are left 2,137 concepts. Then we collected candidate attributes for each concept using the text-pattern method implemented in OntoFactory.

The number of all candidate attribute relations is 19,954. We threw out every candidate attribute with the appearing frequency less than 15; this reduced the number of candidate attribute relations to 3,898.

Considering complexity of work, 1,588 candidate attribute relations were randomly selected and hand- labeled as testing data set.

We do two experiments in turn: filtering of candidate attributes based on HowNet and pruning of attribute relations based on domain concept tree. In experiments on filtering of candidate attributes based on HowNet, we let the threshold value of similarity be 0.45 experientially.  We filtered out non-attribute vocabularies and invalid attributes from the testing data set using the filtering strategy introduced in Section II. In experiments on pruning of attribute relations, we let the threshold value of RULE II be 0.67 experientially. Then, we pruned attribute relations on the basis of filtered results. The experimental results are given in TABLE I.

TABLE I  EXPERIMENTAL RESULTS Phase Extracted  relations Precision Recall F-value(?=1)  1,953 814 2,335 0.417  0.349 0.380 1,137 785 2,335 0.690  0.336 0.452  1,404 1007 2,335 0.717  0.431 0.539  From TABLE I, it is observed that the precision increases and the recall decreases through the initial phase to the filtering phase. According to our filtering strategy, non-attribute vocabularies and invalid attributes are discarded from candidate attributes.

Therefore, the precision is improved. At the same time, a few correct attribute relations may be incorrectly discarded also; this result in the decrease of the recall.

In the pruning phase, the precision continues to increase and has a value of 0.717. This is because some correct attribute relations were recalled according to pruning RULE II and RULE III, the same as the recall.

During the pruning phase, only a few attribute relations may be deleted from candidates and the effect can be ignored.

In general, the F-value always increases during the process of all experiments. It is indicated that attribute relations are improved using our hybrid strategies.

6. Conclusion  In order to further perfect attribute relation learning from candidate attributes collected using text-pattern method, HowNet-based filtering strategy and pruning strategy based on domain concept tree are proposed in this paper. Candidate attributes are classified into non- attribute vocabularies, invalid attribute, and valid attribute. Non-attribute vocabularies can be filter out from candidates by using of the knowledge of attribute sememe in HowNet and similarity measures between the candidate and existing known attribute in HowNet.

And then attribute vocabularies are only left in candidates. Invalid attributes can be filter out from attribute vocabularies using of the knowledge of attribute-host relation in HowNet. After filtering of candidate attributes, some refinement and pruning rules are defined based on domain concept tree with attributes, so that some redundant, unreliable, even wrong attributes can be removed from candidates and some lost attributes can be recalled.

Acknowledgement This research is supported by the National Natural  Science Foundation of China under Grant NO.70572079 and National Key Project of Scientific and Technical Supporting Programs under Grant NO.2006BAH02A08.

