Application of  SVM Combined with Mackov Chain  for Inventory Prediction in Supply Chain

Abstract? The aim of this paper is to predict the inventory of the relevant upstream enterprises in supply chain. The support vector machine, a  novel  artificial  intelligence-based  method developed from statistical  learning  theory, is  adopted  herein to establish a  short-term stage forecasting  model.  However, take the  fact  into  account  that  demand signal is  affected by variant random   factors  and  behaves   big  uncertainty,   the predicted accuracy of SVM  is  not   approving when the data show  great randomness. It is obligatory that we   present Markov chain to improve the predicted accuracy of SVM. This combined  model takes  advantage  of  the  high   predictable power of SVM model and at the same time take advantage  of the  prediction  power of   Markov  chain  modeling  on  the discrete  states  based  on the  SVM modeling  residual sequence. Then we use the statistical data of the output of the gasoline of China from Feb-06 to Dec-07 for a validation of the effectiveness of the above model.

Keywords: SVM; supply chain; Markov chain; predict.



I.  INTRODUCTION A supply chain is the system of organizations, people,  technology, activities, information and resources involved   in moving a product or service from supplier to customer. Many of these exchanges and processes above encountered in the supply chain will therefore be between different companies who will seek to maximize their interest within their sphere, but may have little or no knowledge or interest in the remaining players in the supply chain [1], even worse, may overlook it. In the 1980s the term Supply Chain Management (SCM) was developed, to express the need to integrate the key business processes, from end user through original suppliers.

Supply chain management, which is a hierarchical and strategic approach to planning supply and demand, sourcing raw materials and components, making products and parts, tracking inventory and order  fulfillment,  and delivering to the customer and end user, focus on the flows of materials, the service aspects,   information and funds involved in transform- ing raw materials into final products .An important input for business executives and managers is knowledge of essential component  of  supply  chain  management  and   the profound   impact of those components on the organization?s performance, especially for some prediction about the future demand, for the upstream companies, which is called the inventory, on a certain extent.

If all relevant information is   accessible to any relevant company, every company in the supply chain has the possibility to and can seek to help optimizing the entire supply chain rather than procure optimizing based on a local interest [2]. It is inevitable that incorporating SCM successfully leads to a new kind of competition on the global market where competition is no longer of the company versus company form but rather takes on a supply chain versus supply chain form.

Therefore, it has become a strategic and programming problem that how to solve the problem that the upstream companies apprehend the advance information of demand offered by the downstream sides precisely and predict the demand of the market scientific. Relative to the customers? order fulfillment, the circulation framework of the supply chain can be commonly classified by two sorts: the impetus flow and the drawing flow. In practice the impetus flow and the drawing flow will be used according to the reaction of the customer?s orders and the reaction of the customer?s anticipated order respectively. The first one requires the managers of the supply chain to mark out the throughput, while the other one requires the managers of the supply chain to enhance the purveying ability. Naturally the first step that the managers should adopt is forecasting the demand of customers in the future, namely the inventory of the upstream companies, and analyzing the developing trend in the future according to past fact [3-4]. Since the developing trend of the demand of the customers in the future is affected by variant random factors, it is not realistic to establish a single prediction model, which can take all the influential factors into account. The more the factors that related to the system are considered, the higher he prediction precision of the model will be. So statistics method, on the other hand, becomes a good choice [5]. As a prediction model, SMV has the advantages of establishing a model with few and uncertain data. In this paper, Markov chain based on statistical method is incorporated with the SVM to further enhance the prediction accuracy [6]. Markov chain [7] requires the prediction object Corresponding Author: Wenjin Zhu  zhuwj_07@lzu.cn     to be a stationary process, which made the combination of these two methods become necessary. The rationale of SVM? Markov forecasting model is as follows: SVM forecasting model is built to calculate the fluctuating trend of the historical data series firstly, then specify some states around the trend and as a result a Markov transition matrix can be built to find out the transition probability, finally these two models should be combined to forecast accurately by the historical time- series data. This forecasting method greatly increases the prediction accuracy of random fluctuating sequences.



II. SVM  THEORY Support vector machines (SVM) are a novel way to train  polynomial neural networks or radial basis function neural networks employed the structural risk minimization (SRM) principle which seeks to minimize an upper bound of the generalization error instead of minimizing the empirical error implemented in other neural networks. SVM is especially suitable for solving problems of small sample size and time series prediction.

Let the training data set D be ( ){ } 1, n  i i i x y  = , where input vector  m ix X R? ? and output vector iy Y R? ? . The essential idea  of SVM is to map the input vector into a higher dimensional feature space F via a nonlinear mapping ( )Z x?=  and then a linear regression problem is obtained and solved in this feature space. The mapping function can be formulated as  ( ) ( ) ^  , T Ty f x w w Z b w x b?= = + = +  when the training data ( ){ } 1,  n i i i x y  = have been given, such that it deviates least from  the training data according to the loss function (? -insensitive loss function [8] is used), and at the same time it is as flat as possible ( w is as small as possible).

Formally we represent it as follows:  Min [ ] ( ) 2*   n  i i i  R f C w? ? =  = + +?                                (1)  Subject to ( )( )( ) ,i i iy x b?? ? ?? + ? +                             (2) ( )( )( ) * *, , 0i i i i ix b y?? ? ? ? ?+ ? ? + ?  ? 1,2,i n= ???     (3)  Here, i? , * i?  are slack variables and ?  is the  predetermined maximum allowed deviation between the actual value and the estimated one. C  is a predetermined trade-off term that says how much deviations from ?  are tolerated to reduce the complexity of the approximating functions. We  could have ( ) ( ) ( )* *  , , , .

n  i i i i i i  f x a a a a K x x b =  = ? +?             (4)  Kernel function K (any function satisfies Mercer?s theorem [9] could be used) takes the form: ( ) ( ) ( ), i iK x x x x? ?= .

Lagrange multipliers ia  and * ia which are the coefficients  for 1,2,i n= ???  that maximize (5) can be obtained by  solving the dual form of (1):  Min ( )( ) ( )* * * 1 1  1, ,  n n  i i i i j j i j i j  R a a a a a a K x x = =  ? ? = ? ?? ? ??  ( ) ( )* * 1 1  , n n  i i i i i i i y a a a a?  = =  ? ? + +? ?                                                (5)  Subject to ( )* *  0,0 , , 1,2, n  i i i i i a a a a C i n  =  ? = ? ? =? ???      (6) According to the KKT conditions of quadratic programming [10], only part of ia  or  * ia will be nonzero and the  corresponding data points will be called support vectors. The threshold b  can be computed with following equation recommended by ( where  ( )*i i isign a a? ?= ? ):  ( ) ( )*  , .

n  i i i i i i i  b average y a a K x x ? =  ? ?= ? ? ?? ? ? ?  ?           (7) In practice, the prior knowledge required by SVM is less  restrictive than the assumptions required by the traditional statistics. SVM allows different distributions for the additive error in the regression function. In this paper, we adopt optimizing strategy and apply genetic algorithm to determine the parameters automatically.



III. MARKOV   CHAIN In this section, we present Markov chain to improve the  predicted accuracy of SVM. The original data are first simulated by the SVM above, and then the residual errors between the predicted values and the simulated values for all previous time steps are calculated. In order to correct the predicted value as accurately as possible, it?s convenient for us to use the SVM-Markov Chain to establish the transition behavior of those residual errors by Markov transition matrices, and the correction can be made from those Markov matrices. The detailed procedure is shown as follows.

The residual error can be obtained by this equation step by  step ( ) ( ) ( )e i x i x i ?  = ? , where ( )x i ?  is obtained by SVM model. Assume that there exists some inerratic information in the residual error series of SVM. To conduct Markov state transition matrices, r states are defined for each time step according to the distribution of ( )e i .Each state is an interval whose width is equal to a fixed portion between the maximum and the minimum of the whole residual errors. Let ijs  be the j th state of the i th time step , , 1, 2,...,ij ij ijs L U j r? ?? =? ?   (8)  Where ijL  and ijU  are the lower boundary and upper boundary of the j th state for the i  th time step of the residual error series: ( ) ( ) ( )( )1min max minij jL e i e i e ir  ?= + ? ,   (9)  ( ) ( ) ( )( )min max minij jU e i e i e ir= + ?  ,   (10)     where ( )e i  is the residual error.

The state transition probability from state i  to j state after  m steps is written as  ( ) ( )  , m ijm  ij i  M P  M = , 1,2, ,i j r= ??   (11)  where ( )mijM  is the number of state transition from state i to j state after m steps and iM  is the total number of i state.

And for all , 1,2, , ,i j r= ?? ( )mijP ?0; ( )  1, r  m ij  j P  = =? for  all 1,2, ,i r= ?? , the transition probability matrix of state  can be written as ( )  ( ) ( ) ( )  ( ) ( ) ( )  ( ) ( ) ( )  11 12 1  21 22 2  1 2  m m m r  m m m m r  m m m r r rr  P P P  P P PR  P P P  ? ? ? ? ? ?= ? ? ? ? ? ?? ?  ?  ? ? ? ? ?  ?  . (12)  There?s still a significant property ( ) ( )( )1 mmR R=  .               (13) The state transition probability ( )m  ijP  reflects the statistical law of each state transition in a system, which is the foundation of Markov probability matrix forecast. The future development of the system can be forecasted by studying the  state transition probability matrix ( )mR .When the effects on the r th step are considered, r  state transition matrices are then obtained. Those transition probabilities indicate the tendency of the state transition and then can be used to predict the possible state for the next step. With all r transition probability vectors are available? the possibilities of a certain state for the next step are obtained by summing all those probabilities [11].

The residual error series ( )e i have been divided into r states? correspondingly there are r transition probability row vectors. The possibilities of a certain error state for the next step are computed by the probabilities in r  row vectors, written as { ( )ia T  1, 2, ,i r=  } at time step T. Define the centers of r states as{ }, 1,2,iv i r= ?, . The predicted value for the next step is ( ) ( ) ( )  ~ ^  1 1  r  i i i  x T x T a T v =  + = + +?     (14)  where ( ) ( ) ( ) ( ) ( ) ( )11 2, , ,T T mra a T a T a T a R?? ?= =? ?  .      (15) And, according to (13), it is obvious that (where m=1):  ( ) ( ) ( )1T k T k ma a R+ + ?=    .                                                 (16) In (14), the predicted value ( )  ~ 1x T +  of SVM-Markov  chain is calculated by the centers of r states as { }, 1, 2,iv v i r= = ?, .



IV. PREDICTION OF THE OUTPUT OF GASOLINE Choose the mean square error as the evaluating criterion  (where ( ) ( ) ( )e i x i x i ?  = ? ):  ( )2  1 n  i  MSE e i n =  = ? .               (17) We take the first 20 original data (the original data is listed  in TABLE?) as training elements and therefore establish the corresponding model which predicts the output of gasoline from Oct-06 to Dec-07 as followed table (TABLE ? ) to verify the predicting accuracy of SVM model. The residual errors have been divided into 5 states where each predicted value must belong to.

TABLE I.  STATISTICS OF THE  NUMBER OF OUTPUT OF GASOLINE FROM     FEB-05 TO DEC-07  Time Output Time Output Jan-05 449.79 Jul-06 451.85 Feb-05 434.31 Aug-06 454.25 Mar-05 450.64 Sep-06 455.01 Apr-05 426.31 Oct-06 476.42 May-05 435.71 Nov-06 483.31 Jun-05 409.21 Dec-06 500.51 Jul-05 453.15 Feb-07 466.4 Aug-05 454.3 Mar-07 499.7 Sep-05 462.78 Apr-07 486.88 Oct-05 458.93 May-07 516.95 Nov-05 466.21 Jun-07 506.26 Dec-05 464.49 Jul-07 511.2 Feb-06 450.92 Aug-07 500.3 Mar-06 470.95 Sep-07 480.03 Apr-06 459.22 Oct-07 500.3 May-06 458.34 Nov-07 504.83 Jun-06 447.49 Dec-07 536.73  Where the unit is 1000 ton.

TABLE II.   STATISTICS OF PREDICTED VALUE AND RESIDUAL ERROR AND STATE  OF   ERROR  Time Predicted value Residual error State Oct-06 458.6995 17.7205 4 Nov-06 458.3349 24.9751 4 Dec-06 467.7266 32.7834 5 Feb-07 452.5492 13.8508 3 Mar-07 465.3477 34.3523 5 Apr-07 462.5485 24.3315 4 May-07 477.4679 39.4821 5 Jun-07 487.3941 18.8659 4 Jul-07 496.9351 14.2649 3 Aug-07 489.2867 11.0133 3 Sep-07 499.7071 -19.6771 1 Oct-07 487.3621 12.9379 3 Nov-07 516.7415 -11.9115 1 Dec-07 517.2623 19.4677 4   Based on Markov chain theory, we calculate the transition  probability matrix of state when 1m =      ( )1  0 0 0.5 0.5 0 0 0 0 0 0 0.5 0 0.25 0 0.25 0 0 0.25 0.25 0.5 0 0 0.33 0.67 0  R  ? ? ? ? ? ? ? ?= ? ? ? ? ? ? ? ?  .

And { }1 2 3 4 5, , , ,v v v v v v= = {-14.09,-2.26, 9.57, 21.4, 33.23}.

According to (14), (15) and (16), we can easily obtain the emendation value with MATLAB7.1 and the results are listed in the following table (TABLE?).

TABLE III.     EMENDATION VALUE AFTER USING MARKOV AND THE EMENDATION  ERROR  Time Emendation value Emendation error Oct-06 483.1 -6.7 Nov-06 473 9.7 Dec-06 483.7 16.8 Feb-07 467.6 -1.2 Mar-07 480.5 19.2 Apr-07 477.5 9.4 May-07 492.5 24.5 Jun-07 502.4 3.86 Jul-07 512 -0.8 Aug-07 504.2 -3.9 Sep-07 514.7 -34.7 Oct-07 502.3 -2 Nov-07 531.7 -26.9 Dec-07 532.3 4.4   It is obviously that the absolute value of residual error  between the original data and the predicted value has been greatly minished.  The accuracy comparison of the two models is in the table as followed (TABLE?), where we choose MSE as the criterion.

TABLE IV.    THE MSE OF THE TWO MODELS  Models MSE SVM 520.8 SVM-Markov 247.3   On account of the approving accuracy of the SVM-Markov  model, we can have enough confidence to predict the output of gasoline of China in the next two month, which are listed in TABLE?.

TABLE V.     TWO  PREDICTED VALUES BY  USING SVM-MARKOV MODEL  Time SVM-Markov predicted value Jan-08 541.62 Feb-08 533.01

V. THE CONCLUSION In this paper a novel model based on the classic ? -  intensive SVM is proposed to the inventory forecast task. We firstly propose an approach of SVM to establish a model, secondly combine the Markov chain together to improve the  accuracy, finally obtain two predicted value. The results assess the feasibility of SVM and demonstrate that our method is a promising alternative for time series forecasting (where the inventory of supply chain is a concrete time series). This method possesses several attractive advantages. For one thing, the non-uniform distribution and the tremendous fluctuation of the information offered by training data is taken into account.

With proper feature selecting, we can overlook or even eliminate the redundant information and obtain a more concise but more efficient and more straightforward model. For another thing, this method also allows us to tune all the parameters automatically with optimizing algorithms.

Obviously, this idea is also valid for SVM in classification and for SVM in other cases. This work demonstrated the strong performance of SVM in forecasting and proposed an easy and systematic method for selecting the lags of the variables and the model parameters, which has been integrated with Markov chain, and finally achieved a novel model with high accuracy and formidable prediction ability. However, various issues, such as the use of different loss functions, the properties of kernel functions and the identification of support vector points, were not discussed and researched further more herein. More work is being conducted to explore these subjects, and the results will be presented in the future.

