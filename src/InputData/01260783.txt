Similarity Search in Sets and Categorical Data Using the Signature Tree

Abstract  Data mining applications analyze large collections of set data and high dimensional categorical data. Search on these data types is not restricted to the classic problems of mining association rules and classification, but similarity search is also a frequently applied operation. Access meth- ods for multidimensional numerical data are inappropriate for this problem and specialized indexes are needed. We propose a method that represents set data as bitmaps (sig- natures) and organizes them into a hierarchical index, suit- able for similarity search and other related query types. In contrast to a previous technique, the signature tree is dy- namic and does not rely on hardwired constants. Experi- ments with synthetic and real datasets show that it is robust to different data characteristics, scalable to the database size and efficient for various queries.

1 Introduction  Similarity search is a core operation of many data analysis tasks in data mining, multimedia and time-series databases, biological and scientific databases. Database re- search has primarily focused on the special case, where the data and queries are points in a multidimensional space and the domains of the dimensions are numerical. However, in many applications multivariate analysis is applied on com- plex data domains which do not have a natural order.

Consider, for example, a database ? that contains con- sumer transactions. Given a transaction ? , corresponding to a customer, a search problem is finding the most similar transactions in the database, in order to provide recommen- dations about items the customer would be interested in. If?  is the total number of available items, this problem can be thought of as nearest neighbor search in an  ? -dimensional  space, where the (discrete) domain of each dimension is? ? 	 ? . A related problem is similarity search in a multi-  dimensional space, where the dimensions have categorical domains. It is not hard to see that it is a special case of  the search problem in transactional data described above; the items correspond to values of categorical attributes and they are divided into ? groups ? ? 	 ? ? 	 ? ? ? 	 ? ? , which cor- respond to the natural dimensions (i.e., the attributes). The data are ? -tuples ? ? ? 	 ? ? 	 ? ? ? 	 ? ? ? , where ?  is an element of group ?  . In this case the data tuples have fixed size and no two items (i.e., values) of the same group co-exist in a tu- ple; essentially, an attribute takes exactly one value in each tuple.

Although these problems are fundamental in data anal- ysis tasks, they have not received much attention from the database literature, as opposed to the extensive work (e.g., [20, 18, 23, 21, 6]) for similarity search in low and high di- mensional spaces of ordered domains. On the other hand, categorical and set data types are ubiquitous. For example, in most high-dimensional datasets of the UCI-KDD Archive [22], collected by real application domains, the majority of the attributes are categorical. In addition, set data types (e.g., market basket transactions) are frequently used to de- scribe complex data in object-oriented/object-relational sys- tems [11].

In this paper we show how a hierarchical index can be used to process efficiently similarity search and other re- lated query types on sets and categorical data. In contrast to a previous method [1], the signature tree (SG?tree) is suitable for a dynamic environment with frequent updates and does not rely on hardwired constants, which are hard to define a-priori. The SG?tree is a natural extension of the B ! ?tree and the R?tree [13], found in many commercial DBMSs. Thus, the index carries many advantages of these structures; it is (i) easy to implement (sharing most of its modules with them) and (ii) appropriate for various query types.

The remainder of the paper is organized as follows. Sec- tion 2 defines the problem of similarity search in sets and reviews related work. In Section 3 we describe the hier- archical indexing method. Section 4 shows how similar- ity search and other related queries can be evaluated us- ing the SG?tree. Section 5 includes an experimental study               methods are considered for nearest neighbor search. Some (e.g., [18]) are based on dimensionality reduction, others (e.g., [23, 21]) on compression and others (e.g., [6]) on data or query skew.

However, extending these methods to operate on set and categorical data is not straightforward. To our knowledge the only method previously proposed for similarity search in set and categorical data spaces is [1]. Due to its high rel- evance to our approach, we describe it in detail in the fol- lowing paragraph. The similarity search problem for sets has also been studied in [11], where hash-based indexes which provide approximate results are proposed. In this pa- per, we deal with the problem of finding the exact answers to queries, thus our method is not directly comparable to these indexes. Finally, a similar hierarchical index to the SG?tree was proposed in [7]. Nevertheless optimization of insertions and splits has not been studied and the method is tuned/tested only for exact retrieval of signatures. More- over, as shown in [14] signature trees are not appropriate for set equality or subset queries, which are best processed by inverted indexes and hash-based indexes. In this paper we demonstrate that the SG?tree is conversely suitable for similarity search.

The related problem of clustering categorical data has been studied during the past few years and several algo- rithms have been proposed (e.g., [10, 12, 9]). These meth- ods apply on a static set of categorical data and consider the number of common neighbors as a metric of similarity between two transactions. Using the same techniques for nearest neighbor search requires preprocessing information which may not be available in a dynamic environment.

2.2.1 The signature table  The signature table (SG?table) is a hash-based index, built from a static set of market-basket data ? . It is used to hash the transactions into a set of buckets based on their similar- ity to ? frequent itemsets called signatures in [1]. In our paper we will refer to them as vertical signatures, to distin- guish them from the signature definition that we use.

The SG?table [1] is constructed in two steps. First a minimum spanning tree algorithm is run to cluster the set of items ? into ? groups each containing frequently cor- related items. The grouping process starts by consider- ing each item a separate cluster and progressively refines the clusters by merging item pairs with the maximum co- occurrence frequency. In order to achieve clusters whose contents appear with approximately the same frequency in some transaction, groups for which the total support in the database of their contents exceeds a certain threshold (called critical mass) are removed before they grow larger.

The itemsets of the resulting clusters formulate the set of ? vertical signatures, which are used to construct the SG?  A = {a,e} B = {c,d} C = {b,f,g}  T1 = {c,d} T2 = {a,b,c} T3 = {a,b,e} T4 = {b,d,f,g} T5 = {a,b,c,d,e} T6 = {b,e,f}  S = {a,b,c,d,e,f,g}  A B C  0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1  signature table (in memory) transactions  (in disk)  {T2}  {T1}  {} {T5}  {T3} {}  {T4,T6}  {}  (a) dictionary, vertical signatures, and transactions  (b) the signature table  Figure 1. Example of signature table  table and hash the transactions. Let ? be a small constant called activation threshold. If a transaction ? has at least ? common items with a vertical signature ? ( ? ? ? ? ? ? ? ), ? is said to activate ? . Based on which vertical signatures a transaction activates it is hashed into one of the  ? entries of the SG?table. Figure 1 shows an example of a signa- ture table and a set of transactions ? ? ? ? ? ? ? ? ? ? ? hashed into it. The items in the dictionary ? are split into three groups? ? ? ? ! , and the activation threshold is set to 2. For exam- ple, transaction ? # activates only the vertical signature ? ( ? ? # ? ? ? ?  ), and is hashed to the partition with binary code $ % % .

The index is used to answer similarity queries as follows.

The query transaction is compared to each signature ? and a lower bound for the distance between ' and the trans- actions indexed by the table entries, depending on whether their ? -th bit is % or $ , is computed. These lower bounds are accumulated for each table entry in an (optimistic) estima- tion of the distance between ' and the transactions indexed by that entry. The table entries are sorted in increasing or- der of their lower-bound distance and the hash buckets are read in this order to be compared with ' . If after reading a partition the distance between ' and the ( -nearest neighbor found so far is smaller than the optimistic bound in the next table entry (in the sorted order) the search stops, since none of the remaining entries may point to a closer transaction in the worst case (see [1] for more details).

Although the signature table can be fast for nearest neighbor search queries, it suffers from certain drawbacks.

First, its performance is sensitive to various parameters (number of vertical signatures, critical mass, activation threshold) which are hard to determine a-priori and have to be tuned to achieve good performance. Second, it is appro- priate for static data, on which a clustering algorithm has to be applied in order to determine the vertical signatures. The preprocessing cost is rather high and the index is sensitive to data updates (which may change the correlations between the items and their optimal grouping). Thus expensive pe- riodic re-organization of the index is required in a dynamic environment. Finally, the SG?table is not efficient when the        memory resources are limited. The experiments in [1] in- dicate that its performance drops fast as the space allocated for the memory-resident table decreases. Moreover, since the size of the table is hardwired at construction time, it does not adapt to dynamic changes in memory resources.

In the next section we show how a hierarchical index can alleviate these problems.

3 The Signature Tree (SG?tree)  A nice property of the signatures is that we can use the same representation (i.e., a bitmap) for transactions and groups of transactions. In other words, assuming that ? is a group of transactions, we can characterize it by a signature which has 1 in a position iff the corresponding item exists in at least one transaction in ? . Formally: Definition 5 Let ? be a set of transactions. The signature of ? is defined by  ? ? ? ? ? 	 ? ? ? ? ? ?? ? ? ? 	 ? ? ? ? ? ? ? ? ?  ? 	 (1)  This property is employed by a simple, yet efficient, hi- erarchical index for signatures. The SG?tree (or signature tree) is a dynamic balanced tree similar to R?tree [13] for signature bitmaps. Each node of the tree corresponds to a disk page (using multipage nodes is a potential implemen- tation) and contains entries of the form ? ? ? ? ? ? ? ! # . In a leaf node entry, ? ? ? is the signature of the transaction and ? ? ! is a transaction-id.2 The signature of a directory node entry is the logical OR of all signatures in the node pointed by it and ? ? ! is a pointer to this node. In other words, the signa- ture of each entry is the signature of all transactions in the subtree pointed by it. All nodes contain between % and & entries, where & is the maximum capacity and % ( & + - , except from the root which may contain fewer entries. Fig- ure 2 shows an example of a signature tree. The leaf entries contain the signatures and ids of nine transactions. In this graphical example the maximum node capacity & is three and the signatures are six bits long. In practice, & is in the order of several tens and the length of the signatures in the order of several hundreds.

The SG?tree is not useful only for restricted types of queries, but can serve as a general-purpose index for set data. In Section 4 we will describe how it can be used to evaluate similarity search queries. Here we will discuss briefly how it can be used for simple queries, like itemset containment queries, e.g., find all transactions containing items . and / . Assuming that 0 ? 2 4 ? . ? % ? 6 ? 9 ? / < , this  2The transaction-id, although not necessary during nearest neighbor search, may be useful when search on the tree is combined with other op- erations (e.g., there may be additional features related to a transaction, like customer class).

100000 100010  T1 T2  001010 001100  T3 T4   T5  110000 011000  T8 T9  100001 010001  T6 T7  100010 001110 110001 111000  101110 111001  level 0  level 1  level 2  Figure 2. Example of a signature tree  query can be transformed to a signature ? ? ? ? = 	 ? @ B @ @ @ B and the tree is traversed in a depth-first fashion to evaluate it.

The search algorithm follows entries whose signature con- tains ? ? ? ? = 	 ; if the signature of an entry does not contain? ? ? ? = 	 , no transaction indexed in the subtree below it can participate in the result. Consider for example the tree of Figure 2. Since the first entry of the root has 0 in the sixth position, we know that no transaction indexed in the sub- tree under it can participate in the query result. On the other hand, the second entry should be followed and the right- most node of the next level (i.e., level 1) is visited. Only the first entry of this node contains the query signature, and it is followed. Finally, the query result is found in the third leaf node. The qualifying entries are highlighted in the figure.

Observe that the number of visited pages in this case is op- timal. On the other hand, assuming that we are looking for transactions containing item % , multiple paths are traversed and a significant part of the tree is accessed. Therefore the efficiency of the tree increases if transactions with similar signatures are clustered together in the leaf nodes. This observation holds for all query types including similarity search.

3.1 Construction and updates  The insertion algorithms of hierarchical access methods aim at a common goal: to bring together indexed units which have small distance between them and separate well ones with large distance. The B C ?tree uses the natural or- der of the indexed domain to solve the problem optimally.

Multidimensional access methods like the R?tree employ heuristics to achieve this goal, since there is no total or- dering of objects in space that preserves spatial proximity [8]. Figure 3 shows the generic insertion algorithm used for these hierarchical access methods. When a new entry9 needs to be inserted, the algorithm is called with param- eters the root node and 9 and recursively traverses the tree in order to find the most appropriate leaf node to accommo- date 9 . If the leaf node overflows a split algorithm divides the entries into two groups and moves one group to a newly created node. A pointer to the new node is returned to the parent directory node and a new entry is created for it. Splits are recursively propagated upwards.

The core components of the ? E ? 9 ! ? function are % F G G ? 9 ? I . ? ! 9 9 and ? ? J ? ? . The first chooses the most ap-        function ? ? ? ? ? (Node ? , Entry ? ): Node ? ? ? ? ? ? ? ? ? if ? is a leaf node then ?  insert ? into ? ; if ? overflows then  ? ? ? ? ? ? ? := ? ? ? ? ? ? ? ; return ? ? ? ? ? ? ? ;"  else ? /* ? is a directory node */ ? ? # := % & ? ? ? ? ? ' ( ? ? ? ? ? , ? ? ; ? ? ? ? ? ? ? ? := ? ? ? ? ? ? ? ? # , ? ? ; if ? ? ? ? ? ? ? ? 12 ? ' ? ? then  insert new entry pointing to ? ? ? ? ? ? ? ? in ? ; if ? overflows then  ? ? ? ? ? ? ? := ? ? ? ? ? ? ? ; return ? ? ? ? ? ? ? ;"  return ? ' ? ? ;"  Figure 3. Insertion in balanced tree indexes  propriate entry of the current node 4 in order to insert 5 un- der it. The second divides the entries of an overflowed node into two groups. Both functions should be tuned to maxi- mize the efficiency of the tree. For the SG?tree, we need to define quality criteria based on which these functions oper- ate. The directory node entries of a good SG?tree should have (i) a small area3, which intuitively decreases the dis- tance between the transactions in the subtrees indexed by them and (ii) small overlap between them, if they are at the same level, which intuitively discriminates as much as pos- sible the branches of the search process and maximizes the data that are pruned during search.

The 6 7 8 8 9 5 9 ; = > @ 5 5 algorithm we used in our SG?tree implementation can be described as follows. When a entry  5 is to be inserted in the subtree under node 4 three cases are considered. In the first case, only one entry 5 B D 4 con- tains the new entry 5 and it is directly chosen. In the second case, multiple entries contain 5 . The algorithm chooses the one with the minimum area, since this refines the structure (in analogy to choosing the smaller MBR that contains the new entry in R?trees). Finally, the third case applies when no 5 B D 4 contains 5 . The algorithm in this case picks the entry which requires the smallest area enlargement to index  5 under it, or more formally the entry for which G I K K M 5 N 5 B O is the minimum. Ties are broken by choosing the entry with the minimum area. We also implemented another version of  6 7 8 8 9 5 9 ; = > @ 5 5 that picks the entry which, after extended, has the minimum overlap increase with the rest of the en- tries in the same node. Nevertheless, through experimenta- tion we found that the minimum area enlargement heuristic creates trees of the same quality at a much lower insertion cost.

3For simplicity, we extend the function definitions of Section 2.1, to apply on SG?tree node entries, e.g., S ? ? T ? ? ? U S ? ? T ? ? W ? ? X ? .

For the split algorithm of the SG?tree we consider sev- eral alternatives. The first one is based on the quadratic-split method of the R?tree [13]. We first pick the pair of entries in the overflowed node with the maximum distance. We call these two entries seeds and assign them to two groups, with initial signatures same as the seeds. The rest of the entries are assigned to the group that requires the smallest signa- ture area enlargement to include them. Ties are broken by choosing the group with the minimum area. In case of a new tie the group with the minimum number of entries is selected. If at some point the cardinality of a group plus the number of remaining entries equals 6 , the remaining en- tries are assigned to the group to avoid underflow in the new node.

We also consider two more approaches for splitting a node. The first is based on hierarchical clustering with group average [16]. Initially, all entries are considered as clusters. Then clusters are hierarchically merged until only two remain; these will form the new nodes after the split. The next pair of clusters Y Z \ N Z ^ _ to be merged is the one for which the average distance G I 9> M 5 \ b 9 I d N 5 ^ b 9 I d O between pairs Y 5 \ N 5 ^ _ of entries 5 \ D Z \ N 5 ^ D Z ^ in them is the smallest. In order to avoid under-utilization of a node, when a cluster grows above a threshold (accord- ing to 6 ) the other clusters are immediately merged and the algorithm terminates. We denote this method by d i 9 j k I > .

The last split policy is based on hierarchical clustering ac- cording to the minimum spanning tree; the next pair of clus- ters Y Z \ N Z ^ _ to be merged is the one containing the closest pair of entries Y 5 \ N 5 ^ _ N 5 \ D Z \ N 5 ^ D Z ^ . We denote this method by n 9 > 9 j k I > . In Section 5 we compare @ 9 j k I > , d i 9 j k I > , and n 9 > 9 j k I > .

Finally, deletions in the SG?tree are handled as in the R? tree; if a leaf node underflows, it is deleted, the entries are put in a temporary buffer and reinserted to the tree. This increases space utilization and the quality of the tree.

3.2 Compression  In many cases the signatures are very sparse, i.e., a single transaction contains only a small percentage of the possible items. Only few bits are then set in the signatures and saving them as bitmaps would waste a lot of space. In order to alleviate this problem we use a compression technique; if a bitmap is too sparse we choose to encode the signature as a list of positions, where the bits are set (or else as a list of item-ids). For example a 256-bit signature having only 10 1?s would be encoded by a sequence of 10 characters indicating the positions of the 1?s which occupy 10 bytes as opposed to 32 bytes needed to store the bitmap. We also store an extra flag-byte, which stores the number of 1?s and also indicates that the next bytes contain the positions of 1?s.

Other compression schemes can also be employed, but it is        out of the scope of this paper to study their effectiveness.

4 Query Processing  In this section we describe how the branch-and-bound techniques for similarity search on R?tree-like structures can be adapted to perform search on the SG?tree efficiently.

We discuss first the most common and simple types of sim- ilarity search and then some more complex queries.

4.1 Similarity search  Given a query transaction ? , we can identify two types of similarity search queries on a database ? of transactions, which constitute components of various data analysis tasks.

The first is the similarity range query, asking for all ? ? ? within some distance ? from ? . The second is the nearest neighbor search query, asking for the ? closest ? ? ? to ? , given a (small) constant ? . Both queries can be evaluated efficiently if the database is indexed by an SG?tree. The search algorithms are adaptations of the equivalent ones that apply on an R?tree and they take advantage of the coverage property of the entries in the directory nodes to derive dis- tance bounds for the transactions indexed by them. We first confine our discussion on the evaluation of nearest neighbor queries, where ? =1 (i.e., simple nearest neighbor queries) and then show how the same techniques can be extended for the other cases.

Figure 4 shows a depth-first search algorithm for nearest neighbor queries on R?trees [20], adapted for the SG?tree.

Two variables 	 	 and 	 	 ?  ? ? are initialized to ? ? ? ? and  ? , corresponding to the nearest neighbor found so far and its distance from ? . The branch-and-bound ? ? ? ? ? ?  " # % algorithm is initially called for the root of the SG?tree.

It recursively traverses the tree, following the entries that are most likely to contain the query result. When visit- ing a directory node, the entries ? are sorted according to  ?  & & ( ? * ? + ?  . 0 , which provides a lower (optimistic) bound for the nearest neighbor of ? in the subtree indexed by ? .

Intuitively, by visiting the subtrees in this order, the chances of finding early the result are maximized. Ties between en- tries having the same lower bound are broken by picking first the one with the minimum area. This secondary sort- ing key is due to the fact that among several subtrees with the same number of common items with ? the one with the smallest area is more likely to index an entry with exactly these common items (i.e., the optimistic nearest neighbor).

In other words, given two groups of transactions 1 3 , 1 5 , where 6 1 3 6 9 6 1 5 6 and ; " ?  ( ?  . ( 1 3 0 0 ? ; " ?  ( ?  . ( 1 5 0 0 , and an itemset B that could be included in both 1 3 and 1 5 (i.e., both ?  . ( 1 30 and ?  . ( 1 5 0 cover ?  . ( B 0 ), probabilis- tically the group with the smallest area (i.e., 1 3 ) is more  likely to contain B .4  function C ? ? ? ? ? 	 ?  ? (Node ? , ? , ? ? , int ? ? ? ? ? ? ) ? if ? is a directory node then ?  sort entries ? in ? in ascending order of C ? ? ? ? ?  ? # ? ? % ' ; break ties by placing first the entries with the smallest area; for each entry ? in this order do /* recursive call */  (1) if C ? ? ? ? ?  ? # ? ? % ' , ? ? ? ? ? ? then C ? ? ? ? ? 	 ?  ? ( ? # 1 ? ? , ? , ? ? , ? ? ? ? ? ? );  else break for loop; /* no need to visit other subtrees */3 else /* ? is a leaf node */  for each entry ? in ? do (2) if C ? ? ? ? ?  ? # ? ? % ' , ? ? ? ? ? ? then /* new NN found */  ? ? := ? ; ? ? ? ? ? ? := C ? ? ? ? ?  ? # ? ? % ' ;3  Figure 4. A depth-first search algorithm for NN queries  The nodes under the entries are visited in this order. If the optimistic bound for some subtree is greater than the distance of the nearest neighbor found so far, search is not required for this subtree and the remaining ones in the or- der, since they may not contain a closer neighbor to the one already found. When a leaf node is visited during the search process, the distances between ? and all its entries are com- puted and the bounds 	 	 and 	 	 ?  ? ? are updated if a closer neighbor is found.

The search algorithm of Figure 4 is appropriate for find- ing one nearest neighbor of ? . It can be easily adapted for finding all nearest neighbors with the same (minimum) distance from ? , by maintaining a set of current nearest neighbors instead of a single variable 	 	 , and changing the predicates in lines (1) and (2) of the algorithm to ? 8 ?.

In the general problem, where the ? nearest neighbors are required ( ? -NN search) the parameter 	 	 is replaced by a priority queue of size ? , organizing the ? nearest neighbors found so far, and 	 	 ?  ? ? bound corresponds to the first el- ement of the queue, i.e., the one with the largest distance, among the ? -NN found so far.

The algorithm of Figure 4 can also be used to evaluate similarity range queries. In this case, the 	 	 ?  ? ? bound is replaced by the (fixed) query parameter ? and all transac- tions within this distance from ? are retrieved. The direc- tory entries with ?  & & ( ? * ? + ?  . 0 : ? are pruned as before, filtering out large parts of the data early.

Finally, we need to mention that the ? ? ? ? ? ?  " # % al- gorithm of Figure 4 is, in fact, sub-optimal for nearest neighbor search on the SG?tree. An optimal ; ? ? ? ? ?  " # % algorithm (in terms of node accesses) follows a best-first search paradigm [15] and employs a priority queue. This queue organizes < ? * ?  & & ( ? * ? + ?  . 0 > tuples for directory  4 ? @ has higher density than ? B and thus higher probability to includeC .

large itemset I, and the cardinality D. For example, a dataset with 200,000 transactions of mean size 10 and large item- sets of mean size 6 is denoted by T10.I6.D200K. By tuning these parameters we were able to generate a wide range of datasets with various characteristics.

We also experimented with a real, categorical dataset from the UCI KDD Archive [22]. The dataset contains cen- sus data extracted from the 1994 and 1995 current popula- tion surveys conducted by the U.S. Census Bureau. Each tu- ple corresponds to an individual and includes demographic and employment related information. After removing some numerical attributes and cleaning the data (e.g., missing val- ues were replaced by an extra special value for each at- tribute), we ended up with 36 categorical attributes, the do- main sizes of which vary from 2 to 53 (the total number of values is 525). The data are split into two datasets with 200K and 100K tuples, respectively. We indexed the first dataset (which we denote as CENSUS) and we used ran- dom samples from the second for querying it.

5.2 Comparison between split policies  In the first experiment we compare the three SG?tree split policies described in 3.1. We generated three (uncom- pressed) SG?trees for the CENSUS dataset, using ? ? ? ? ? 	 ,  ? ? ? ? ? 	 , and ? ?	 ? ? ? ? 	 , respectively. Table 1 compares the characteristics of the resulting trees and shows their relative performance averaged on 100 nearest-neighbor queries.

Table 1. Comparison of the three split policies comparison metric ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? average " ? % ? & % ) at level 1 90 73 74 average " ? % ? & % ) at level 2 210 158 154 average " ? % ? & % ) at level 3 458 325 348 insertion cost (msec) 0.331 0.655 0.645 % of data accessed 15.79 4.78 5.72 CPU time (msec) 119 34.6 41.8 I/O accesses 862 266 323  All three trees have 4 levels. The entries in level 0 (leaf level) have fixed area 36 (since all data tuples have 36 val- ues). The first three rows of Table 1 show the average area of the entries at levels 1,2, and 3 (root). This can be considered as a quality metric for the three split poli- cies; the smaller the average area of the entries at the in- termediate levels, the better the quality of the clustering.

The ? ? ? ? ? 	 and ? ? 	 ? ? ? ? 	 policies construct much better trees than ? ? ? ? ? 	 , and this can be validated from the last three rows of the table which show the average pruning (in terms of data accessed), the average CPU cost, and average number of node accesses at nearest neighbor search queries.

On the other hand, ? ? ? ? ? 	 has the lowest average insertion cost and tree construction time. Experimentation with other  datasets shows similar results. In the sequel we use ? ? ? ? ? as the standard split policy for the SG?tree, since it achieves the best quality of the three at an acceptable cost.

5.3 NN search on synthetic data  We compared the performance of SG?table and SG?tree on nearest neighbor search by generating a series of syn- thetic datasets and using the same itemsets and parame- ters to also generate a number of queries for each dataset.

Figures 5 through 12 show the relative performance of the methods for various parameter settings. For each experi- mental instance, the results were averaged over 100 queries.

Figures 5, 7, 9, 11, and 12 show in combined diagrams the pruning efficiency (bars) and computational cost (lines) of the two methods. The pruning efficiency is measured in terms of the transactions accessed and compared with the query transaction (percentage). Figures 6, 8, and 10 com- pare the number of random I/Os on the two indexes for three of the five experimental instances.

Figures 5 and 6 show the performance of the indexes when the size of itemsets is fixed (I=6), the size of the dataset is 200K, and the size of the transactions (T) varies.

When T is small, both indexes have similar performance, but as T increases the SG?tree starts to (slightly) outper- form the SG?table, managing to prune more transactions.

Especially the I/O cost difference is high for large values of T, since in that case the distance of the nearest neighbor usually increases and the contents of many entries of the SG?table need to be visited.

Figures 7 and 8 show the relative costs for T=30 as the size of the large itemsets (I) increases. This increase gen- erates datasets where the transactions are better clustered having smaller average distance between them and favors both structures. Observe that the relative performance be- tween them increases, and the SG?tree becomes signifi- cantly faster than the SG?table when both T and I are large.

In the third experimental instance (Figures 9 and 10) we fix the ratio I/T to 0.6 and increase the transaction size. The rationale is to test the robustness of the indexing methods to the dimensionality of the problem, when the data skew re- mains constant. Clearly, the SG?tree is robust to the trans- action size, whereas the SG?table fails to index well large transactions even if they contain well-clustered data. This observation is also validated at the comparison of the struc- tures for real categorical datasets of high dimensionality (see Section 5.4).

We also tested the robustness of the two structures to the database size, by fixing T=10 and I=6 (two parameter values for which the SG?table performs well) and increas- ing the dataset cardinality D. Figure 11 shows that the rel- ative pruning efficiency of the SG?tree increases with the database size. The I/O cost diagram is omitted since it                 10 15 20 25 30  average number of items in transactions (T), I=6, D=200K  % of  da ta  pr oc  es se  d             tim e(  m se  c)  SG-table(%data)  SG-tree(%data)  SG-table(time)  SG-tree(time)  Figure 5. Pruning and CPU time, varying T          10 15 20 25 30  average number of items in transactions (T), I=6, D=200K  nu m  be r  of ra  nd om  I/O s  SG-table  SG-tree  Figure 6. Random I/Os, varying T           6 12 18 24  average length of large itemsets (I), T=30, D=200K  % of  da ta  pr oc  es se  d             tim e(  m se  c)  SG-table(%data)  SG-tree(%data)  SG-table(time)  SG-tree(time)  Figure 7. Pruning and CPU time, varying I          6 12 18 24  average length of large itemsets (I), T=30, D=200K  nu m  be r  of ra  nd om  I/O s  SG-table SG-tree  Figure 8. Random I/Os, varying I           T=10,I=6 T=20,I=12 T=30,I=18 T=40,I=24 T=50,I=30  Varying T and I, I/T=0.6, D=200K  % of  da ta  pr oc  es se  d           tim e(  m se  c)  SG-table(%data)  SG-tree(%data)  SG-table(time)  SG-tree(time)  Figure 9. Pruning and CPU time, fixed I/T             T=10,I=6 T=20,I=12 T=30,I=18 T=40,I=24 T=50,I=30  Varying T and I, I/T=0.6, D=200K  nu m  be r  of ra  nd om  I/O s  SG-table SG-tree  Figure 10. Random I/Os, fixed I/T          100 200 300 400 500  Dataset cardinality, T=10, I=6  % of  da ta  pr oc  es se  d            tim e(  m se  c)  SG-table(%data)  SG-tree(%data) SG-table(time)  SG-tree(time)  Figure 11. Pruning and CPU time, varying D         0 1 to 3 4 to 10 11 to 20 >20  distance of nearest neighbor (T30.I18.D200K)  % of  da ta  pr oc  es se  d           tim e(  m se  c)  SG-table(%data)  SG-tree(%data)  SG-table(time)  SG-tree(time)  Figure 12. Pruning and CPU time, var. ? ? ? ? ?        shows a pattern similar to the CPU cost (as in the previous experiments).

During the experiments we observed that queries hav- ing a close nearest neighbor were processed fast using both structures, whereas for cases with distant neighbors the SG?tree was significantly faster than the SG?table. We validated this observation by running 1000 queries on the T30.I18.D200K dataset and averaging the query costs for various distance ranges of the nearest neighbor. Figure 12 shows the average pruning and CPU cost for five distance ranges. When the distance is small search is fast for both methods (actually for distances in the range 1?3, the SG? table outperforms the SG?tree). However the distant cases are handled much faster by the SG?tree, showing that this access method is more robust to ?outlier? queries.

As a general conclusion from this set of experiments, the SG?tree is a more efficient and robust access method than the SG?table, in addition to its other inherent advantages (dynamic data handling, independence to hard-wired con- stants). In the next subsection we compare the indexes for other query types on both synthetic and real data.

5.4 Real data and other queries  Figures 13 and 14 show the performance of the indexes for ? -NN queries on the T30.I18.D200K synthetic dataset and the CENSUS dataset, respectively, for various values of ? . The results for each experimental instance were aver- aged over 100 queries. In both figures, for small to medium values of ? the SG?tree is significantly faster than the SG? table. When ? is large ( ? ? ? ? ? ), the fraction of the data that need to be visited becomes too large for the indexes to be useful. This is due to the fact that the search space becomes less appropriate for search. For example, when  ? 	 ? ? ? ? ? we observed that the average distance of the ? -th neighbor is very large (31.81 for T30.I18.D200K and 18.06 for CENSUS) and very close to the average distance of all transactions from ? . This is due to the ?dimension- ality curse? effect [3] often observed in high-dimensional search problems. Observe, that the SG?tree is less sensitive to this effect, since its performance degenerates at a smaller pace, especially for the real dataset.

We also compared the indexes for similarity range queries (Figures 15 and 16). The same datasets and queries as before are used and the distance threshold from the query varies from 2 to 10. For  	 ? , the SG?table outperforms the SG?tree on the synthetic dataset. In all other cases the tree is much faster. Observe that on the real dataset, in par- ticular, for both ? -NN queries and range queries the per- formance difference quite large in favor of the tree. This indicates that the structure can perform very well in real life cases.

1 10 100 1000 10000  k-nn search, varying k (T30.I18.D200K)  % of  da ta  pr oc  es se  d          tim e(  m se  c)  SG-table(%data)  SG-tree(%data)  SG-table(time)  SG-tree(time)  Figure 13. ? -NN queries (T30.I18.D200K)             1 10 100 1000 10000  k-nn search, varying k (CENSUS)  % of  da ta  pr oc  es se  d         tim e(  m se  c)  SG-table(%data) SG-tree(%data)  SG-table(time)  SG-tree(time)  Figure 14. ? -NN queries (CENSUS)  5.5 Dynamic data changes  In this experiment we compare the structures simulat- ing a case where the nature of the data changes dynami- cally. We generated a synthetic dataset T10.I6.D100K and built an SG?table and SG?tree for it. We then gradually updated the structures by inserting batches of 100K trans- actions each with the same characteristics (i.e., T=10, I=6), but putting different seeds to the random generator (i.e., the large itemsets used were different for each batch). We ran nearest neighbor queries on the two structures after each in- sertion phase. The queries for phase ? (after batch ? has been inserted, ? ? ? ? ? ) are generated as follows. For each query (i) a random number ? from 1 to ? is chosen and (ii) the generator parameters (i.e., large itemsets) for batch  ? are used to produce the query. For example, a query for the phase where the dataset contains 300K data is generated using randomly one of the generators of batches 1, 2 or 3.

Figure 17 shows the average pruning efficiency and CPU time of the two structures. Initially, both have similar per- formance, but as more data with different characteristics are inserted into the structures the performance of the SG?table degenerates, since it is optimized for the first 100K data.

2 4 6 8 10  similarity range queries, varying epsilon (T30.I18.D200K)  % of  da ta  pr oc  es se  d           tim e(  m se  c)  SG-table(%data) SG-tree(%data) SG-table(time) SG-tree(time)  Figure 15. Range queries (T30.I18.D200K)           2 4 6 8 10  similarity range queries, varying epsilon (CENSUS)  % of  da ta  pr oc  es se  d           tim e(  m se  c)  SG-table(%data) SG-tree(%data) SG-table(time) SG-tree(time)  Figure 16. Range queries (CENSUS)  On the other hand, the SG?tree is robust to updates and ex- hibits very good query performance, since each batch con- tains skewed data (generated from a different collection of large itemsets).

6 Conclusions and Future Work  We presented a hierarchical indexing method for simi- larity search in sets and categorical data. The SG?tree is a disk-based height-balanced tree that organizes fixed-length bitmaps and is appropriate for various query types. We have shown how several branch-and-bound methods, which ap- ply on R?tree-like structures, can be adapted for efficient similarity search on the SG?tree. Extensive experimental evaluation has shown that the SG?tree is in most cases much faster than the SG?table, a previous, hash-based index. The advantages of the SG?tree can be summarized as follows:  ? It is efficient and robust to various data types (both cat- egorical and set data) and characteristics (cardinality, density, dimensionality). It is a versatile structure that can be used for several query types.

? The tree is dynamically adapted to updates and re-         100 200 300 400 500  Dataset cardinality, T=10, I=6  % of  da ta  pr oc  es se  d             tim e(  m se  c)  SG-table(%data)  SG-tree(%data) SG-table(time) SG-tree(time)  Figure 17. NN search after dynamic updates  quires no preprocessing of the data. Thus it can be useful for analyzing data which change dynamically over time.

? It relies on no hardwired constants, and requires no tuning using a-priori defined parameters.

? It is a disk-based, paginated data structure, so it can operate with limited memory resources, and dynami- cally changing memory resources. Caching policies, previously used for the B ? ?tree and the R?tree can be seamlessly applied on this structure.

There are several directions for extending the current work. In our study we used hamming distance as the sim- ilarity metric. However, the SG?tree can also be defined, tuned and searched for other set theoretic similarity met- rics. For example if the Jaccard coefficient is used, the lower distance bound (in fact the upper similarity bound) for nearest neighbor search can be defined by ? ? ? ? ? ?  ? ? ? ? ? ? ? ? ? ? ? ? ? . We plan to test the effectiveness of the structure using alternative metrics.

Another direction for future work is to study methods for bulk-loading SG?trees, instead of inserting the data one- by-one. We can adapt categorical clustering algorithms [12, 9] for this purpose. Another approach is to sort the transactions using gray codes as key, in analogy to using space-filling curves for bulk-loading multidimensional data to an R?tree [17]. Alternatively, hashing techniques can be used to group similar signatures together. The result- ing ?globally-optimized? tree could have much better qual- ity characteristics, while being built faster. In a reverse di- rection, we can investigate whether the SG?tree can be used for clustering large, dynamic collections of set and categor- ical data. The cost of existing methods is at least ? " ? and the tree could be used to derive good clusters much faster (e.g., by merging the leaf nodes using their signatures as guides).

Finally, we plan to empirically test the efficiency of the tree to the query types, discussed in Section 4.2. In        addition, for some data types search can be further opti- mized. For example, if the indexed categorical data have fixed-dimensionality ? we know that the area of each in- dexed signature is fixed to ? . We can use this property to derive stricter lower bounds for the directory node en- tries ? , instead of the rather relaxed ? ? ? ? 	 ?  ? ? ? ? ? ? . For this example, a better bound is ? ? ? ? 	 ?  ? ? ? ? ? ? ? 	 ? ? " $ 	 ? ? ? ? ?  ? ? ? . We plan to study such search optimiza- tions, using domain properties or statistics from the indexed data.

