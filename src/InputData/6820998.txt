Exploring Virtual Machine Covert Channel via I/O Performance Interference

Abstract  The weakness of performance isolation in system virtualization leaks a time window for various kinds of attacks which can be leveraged by malicious users to threaten the security of the virtual machines (VMs) atop or construct hidden information channel. In this paper, we propose vLeaker, a practical covert timing channel built on fine-grained VM I/O performance in- terference, by which VMs co-resident in storage aspect can exchange the information with relatively high trans- mission speed and low data error rate. We evaluate our vLeaker system on Xen and VMware hypervisor and show that the maximal transmission rate can ar- rive at 125 bps on our local testbed. Moreover, the effective transmission rate ranges from 72 to 124 bps with average error rate lower than 13% under different configurations.

1. Introduction With the prosperity of cloud computing, more and  more customers start their businesses by renting vir- tual machines (VMs) from third party cloud provider (e.g., Amazon?s EC2 platform [1]) instead of build- ing their own computing infrastructure. Besides the benefits (e.g., cost saving, high availability, convenient management) brought by system virtualization through resource consolidation, the isolation weakness in phys- ical resource sharing (e.g., CPU, Memory, Bus and I/O system) opens doors to various kinds of security attacks especially the timing channel threat [2, 3, 4, 5, 6].

As is well known, timing channels nearly exist in each system which provides service via resource sharing. Once a kind of resource is shared, there are at least two parties simultaneously accessing such re- source. And the key reason which causes the timing channel [5, 6] is that one party (named as information Carrier) influences the access time observed by an- other party (named as information Observer), then the Observer can deduce or extract the information from the  Carrier via the variance of observed time. There are two kinds of timing channels, i.e., covert [7] and side timing channel [8]. When the information Carrier and Observer negotiate with each other, a covert timing channel is constructed. On the other hand, if the information Car- rier does not know the existence of the Observer, this is a side timing channel, i.e., the Observer monitors its time on accessing the shared resource in order to infer the resource access patterns of the Carrier. Obviously, timing channels violate the designed security policies of the computing systems and it should be mitigated to prohibit information leaking. Since 1990, there are great efforts in system research area to explore or prevent the timing channels [9, 10, 5] and the battle continues in cloud era.

Recent research works show that different timing channel attacks are explored in cloud environment. For example, malicious tenants can explore the CPU cache based side channel for private key extraction [2, 4].

Soon after that, several approaches are provided to address the CPU cache based timing channel on vir- tualization platforms such as CPU cache usage detec- tion and measurement [11], CPU cache partition [12] by dynamic page coloring, CPU cache non-sharing via system level protection [13] and etc. Meanwhile, Wu [3] et al. also explores a practical memory bus based covert timing channel among resource sharing VMs.

Undoubtedly, CPU cache and memory bus based timing channels are valuable to exploit due to common CPU and memory bus sharing situation and the high data leaking bandwidth.

In this paper, we would like to explore I/O based covert timing channel in virtualized environment, i.e., to construct a covert timing channel among storage co-resident VMs (VMs which share the storage re- sources) by performance interference. Although VM I/O based covert timing channel is less powerful than CPU and memory based approaches, it is still deserved to explore and can be used as an alternative choice when existing methods are not applicable. Compared   DOI 10.1109/CLOUDCOM-ASIA.2013.62    DOI 10.1109/CLOUDCOM-ASIA.2013.62     with the previous approaches, VM I/O timing channel does not mandatorily require that VMs are co-resident in the same host (server). The only premise is that those VMs share the I/O resources, i.e., their virtual disks are put in the same storage system. Our proposed methodology can be applied into the following scenario, i.e., VMs do not share the CPU, DRAM resources but only the I/O resources. In reality, VDI (virtual desktop infrastructure) application is in such scenario, as in most cases that the disks of those VMs are managed in the centralized storage system, which provides the possibility to explore the I/O timing channel.

Currently, we focus on how to construct the I/O covert timing channel through VM I/O performance interference. Generally, I/O performance variation of a VM is caused by the I/O contention by other co- resident VMs. Though great efforts [14, 15, 16, 17, 18] are applied into I/O scheduling aspect on the virtual- ization platforms for enhancing the performance fair- ness among VMs, the I/O performance isolation is still not perfect which brings the opportunity to VM I/O performance interference attack [19]. Once there is performance interference from other VMs, the I/O execution time of the workloads in the VM can be greatly increased compared with the case when there is no performance interference. Derived from the ex- ecution time variation of VM I/O workload between interference and non-interference environments, we can construct a simple information leakage rule (described in Section 2.1) to exchange one bit information in a designated time window. By extending the basic infor- mation exchange rule, we build an information leaking system vLeaker, which can be utilized to exchange the information among storage co-resident VMs.

To summarize, we have made the following contri- butions in this paper:  ? We propose a novel approach to construct a covert channel through VM I/O performance interference.

? We provide a prototype system vLeaker , which can be used by storage co-resident VMs to implicitly exchange the information instead of an explicit manner (e.g., network connection and file sharing). Moreover, We evaluate our vLeaker system on VMware and Xen hypervi- sor to demonstrate the practicality and effec- tiveness.

? We discuss some approaches to prevent or de- tect the VM I/O timing channel in both system and user aspects.

The remainder of this paper is organized as belows.

Section 2 presents the design and implementation of our prototype system, vLeaker. Section 3 demonstrates the experiments of vLeaker on both Xen and VMware plat- form. Section 4 discusses how to detect and prevent the VM I/O timing channel. Then Section 5 and 6 discuss some related and future work. Finally, we conclude this paper in Section 7.

2. System Design and Implementation It is a great challenge to not only explore the VM  I/O based covert timing channel but also construct a reliable protocol above the identified channel. As de- scribed, our VM covert channel is derived from VM I/O performance interference, thus we should firstly collect the I/O information (e.g., I/O scheduling and related parameters) of the virtualization platform and identify the existence of VM I/O covert channel; then we need to profile the interference time window and select the appropriate interference workloads; finally we have to propose a practical transmission protocol to make such channel reliable.

2.1. I/O covert channel identification  Measuring the VM I/O performance isolation is a premise to identify such timing channel. Previously, Yang et al. [19] demonstrate that VMs which simultane- ously execute I/O operations can be mutually influenced on most virtualization platforms, i.e., with the decreas- ing of throughput and the increasing of I/O execution time.

Ideally, once the quality of I/O service is not guar- anteed, the I/O based covert timing channel can be constructed with the following approach: Supposing there are two participators, i.e., one sender (S) and one receiver (R), they both locate in storage co-resident VMs. S and R can negotiate a fixed interference time window (denoted as ITW) for one bit data transmission, as shown in Figure 1. During one ITW, S sends one bit information via selectively executing the disturb- ing workload. Meanwhile, R measures the time (i.e., Tmeasured) on executing the designated workload and uses Tmeasured to compare with the threshold time Tthreshold. In such a way, an information channel can be constructed.

2.2. Interference time window determination  The value of ITW chosen by S and R (denoted with TS and TR) should be the same. If TS equals TR, S (in one TS) can mostly influence the behavior of R in two adjacent TR, which can greatly eliminate the deviation.

Figure 1. The behavior of S and R in ITW  Figure 2. I/O interference window determination  However, if TS > TR, then S (in one TS) may affect the behavior of R in many adjacent TR, which can result in duplicated information error, e.g., if S sends one bit value ?1?, then R may receive many ?1?s. Vice versa, if TS < TR, then S (in several TS) may only influence the behavior of R in one TR which can cause the losing information error, e.g., S sends many ?1?s, but R only receives one ?1?.

Also the transmission rate (TR) in theory has the following relationship with ITW, i.e., TR=1/ITW. Ob- viously, the smaller of ITW, the larger value of TR. For example if ITW is 10 ms, the expected transmission rate is 100 bps. As the value of ITW is influenced by the execution time of the designated I/O workload run by S and R (denoted as WS and WR), then the value of ITW can be determined by the algorithm shown in Figure 2.

The selection of WS and WR must satisfy the two properties, i.e., stability and effectiveness. Stability means that the execution time of WS and WR should be stable when there is no interference. If not stable, we won?t have a convincing base to determine the value of Tthreshold, then R cannot precisely determine the information to be received.

To achieve the stability of WS and WR, we must bypass the cache and buffer effects in OS kernel to avoid the time difference when the same workload is executed multiple times. For example, when you open a file in a disk and issue the read operations (e.g., read  (fd, buf, 16KB)), the I/O latency of the first operation is relatively long since the OS controls the disk driver to load the contents from the disk. However, the I/O latency of next read operations will be relatively short due to the prefetch features provided by OS kernel.

Generally, read I/O operations are not suitable for being selected as WS or WR as the unstable execution time.

However for write operations, we can make them stable through the following approaches: (1) Using ?O DIRECT? mode to bypass the kernel buffer; (2) Using I/O synchronization (e.g., O SYNC flag) to issue the write through I/O operation instead of write back operation. Thus write operations are suitable to be se- lected as WS or WR.

Effectiveness means that we must find those WS and WR with low execution time, thus the value of ITW can be small and the transmission rate can be improved.

Considering the I/O execution path and stack, write operation with 4KB size is a good candidate since the basic disk transmission size is 4KB.

2.3. Simple transmission protocol To practically and efficiently transfer the informa-  tion through the VM I/O covert timing channel, a simple transmission protocol is provided.

Table 1. Data Format Description  HEAD SIZE DATA TAIL Detailed DATA Field Description  HEAD The beginning mask of the information SIZE The size of the ?DATA? field DATA The information to be sent TAIL The ending mask of the information  Table 1 demonstrates the data format used by the protocol. The two fields, ?HEAD? and ?TAIL?, are used to describe the beginning and ending labels of the information and each is defined with fixed length, e.g., ?HEAD? = 0x9999 and ?TAIL? = 0x9001. The ?SIZE? field describes the length of the information contained in ?DATA? field. Although R can identify the beginning and ending labels in theory, it may not recognize them in practical environment. Once R does not identify the ?TAIL? label, it has no idea on the length of the information. Thus ?SIZE? field is needed, and we define a maximal size for the information (e.g., 256 bytes) contained in ?DATA? field. Since the ?SIZE? field is also transferred through unreliable covert channel and one bit flip can cause a totally different value, thus some erasure coding methods (e.g., checksum) should be applied.

Figure 3. Sender?s logic  Figure 4. Receiver?s logic  The following describes the logic of S and R for information exchange:  The logic of S: S adopts the following steps to transfer the information as shown in Figure 3, i.e., (1) It slices the information file into many blocks, e.g., block#1,block#2,...,block#n. Then some FEC (Forward error correction) codes (e.g., Reed-solomon [20]) can be applied into each block to remedy the unreliable channel. Definitely, S and R must have a pre-defined negotiation on the coding rules; (2) for each block#i, S encapsulates it into pre-defined format shown in Ta- ble 1, then S executes the designated workload WS in each ITW according to the contents of block#i.

The logic of R: As shown in Figure 4, R utilizes a state machine with three status to receive the infor- mation, named as Monitor, Receiving and End. In the Monitor state, R continues executing the designated workload WR. According to the rule, if the execution time of WR exceeds the Tthreshold, R receives a value ?1? otherwise it receives ?0?. When R identifies an expected value which matches the ?HEAD? label, it steps into the Receiving state; In the Receiving state, R receives the information until it identifies the expected ?TAIL? label or the size of received data exceeds the maximal length . Once one of the two events occurs, R transfers itself into the ?End? state. In the ?End? state, R recovers the information with FEC code if needed, then it stores the received information into a file, and finally it rolls back to the ?Monitor? state again and waits for the information in next round.

2.4. Implementation details  Our vLeaker system is written in C language with about 3K LOC (line of codes), which is mainly com- posed of the information detection module (IDM), in- formation sending module (ISM) and information re- ceiving module (IRM). The IDM is designed to ver- ify the possibility of VM I/O covert timing channel via coarse-grained VM I/O performance interference.

Moreover, it is also responsible for determining WS , WR and the ITW; ISM and IRM implement the logic of S and R according to the transmission protocol described in Section 2.3. In detail, there are following challenges to implement a practical VM I/O covert timing channel system:  Accuracy of interference time window. As de- scribed in Section 2.2, S and R negotiates a fixed ITW to exchange one bit information. While exchanging more information in a continuous time period, it is important to maintain the stability of ITW. To address such issue, we utilize the timing policy (e.g., timer settime func- tion in Linux) to guarantee a relatively stable window, as such function can accurately control the time in microsecond level.

Appropriate selection of Tthreshold. In our proto- col, R measures the execution time of WR to determine the received information. As the execution time of WR can be different on different virtualization platforms, which means that the Tthreshold has a great variation under different configurations. In detail, we argue that assigning a static value to Tthreshold can not satisfy the cross-platform requirements. To solve this program, we use IDM to profile and collect the execution time of WR then dynamically derive the value of Tthreshold.

3. Evaluation In this section, we focus on verifying the effects  of vLeaker on virtualization platform with our local testbed servers. Table 2 shows the configuration of our environment. On each platform, we deploy two VMs (named S-VM and R-VM) which own non-shared areas of the DAS (direct attached storage) disk equipped in the server.

3.1. Covert channel identification experiment  In both S-VM and R-VM, we deploy a program, named PIP (performance interference program) in the IDM (described in Section 2.4), which writes the raw disk from low LBA (logical block address) to high LBA with designated I/O size and fixed space interval (i.e., 8MB, to avoid the spatial locality). When only R-VM     Table 2. Experimental configuration  Server configuration Hard Disk 300GB SCSI local disk NIC Intel Corporation 82546GB Gigabit  Targeted Hypervisor VMware ESX-4.0 Xen Xen-3.0.1  VM configuration OS kernel Fedora 12, 2.6.31 X86 64 kernel Memory 4GB Disk Two disks: 30G system disk; 10G raw disk  Figure 5. VM I/O interference experiment  occupies the platform, we measure the average response time (ART) of operations issues by PIP. Then we let S- VM and R-VM concurrently execute PIP, and measure the ART of operations issued by PIP in R-VM. In Figure 5, VMware-non/Xen-non stands for that R-VM runs on VMware/Xen platform without performance in- terference; VMware-inter/Xen-inter means that R-VM and S-VM concurrently conduct I/O operations on the designated platform. From Figure 5, we can see that the ART of PIP in R-VM greatly increases when there is performance interference from S-VM, which indicates the existence of VM I/O covert channel.

3.2. Profiling I/O interference parameters  According to the algorithm described by Figure 2 in Section 2.2, following experiments are conducted to profile the ITW. In our experiment, WS and WR are assigned with the same workload, named as DW, which writes a raw disk from low LBA to high HBA with 4KB size and a fixed space interval (i.e., 8MB). We still use two VMs (S-VM and R-VM) to execute DW to determine ITW. As shown in Table 3, the value of ITW must exceed 9512 us on VMware platform and 7812 us on Xen platform. And we can configure ITW as 10000 us on VMware platform and 8000 us on Xen platform.

Moreover, we should profile the Tthreshold, which is used by R to determine the value of received informa-  tion in each ITW. However, it is not a good practice to assign a static value to Tthreshold. As the value Tbase of WR can vary in different experiments, the better solu- tion is to profile the relationship between Tthreshold and Tbase. Currently, we use the following simple formula Tthreshold = X ? Tbase to dynamically regulate the value of Tthreshold. For example, the value of X can be configured with 1.1 on VMware platform or 1.39 on Xen platform. Generally, this formula is practical but not quite meaningful and we expect to improve it in the future.

Table 3. Interference time window identification  Platform VMware Xen Workload WS WR WS WR Tbase (us) 8549 8612 5520 5569 Tinter (us) 9403 9512 7681 7812  Ratio:Tinter /Tbase 1.100 1.104 1.391 1.403 ITW (us) ITWvmware ? 9512 ITWxen ? 7812  3.3. Performance related experiments  We evaluate the transmission rate and data error rate of the constructed VM covert channel on our local testbed. On each virtualization platform, we still deploy two VMs (i.e., S-VM and R-VM) to exchange the in- formation via VM I/O interference. In our experiment, we configure each field (i.e., ?HEAD?, ?SIZE? and ?TAIL?) with 2 bytes, thus the total overhead is 6 bytes.

Also for ?SIZE? field, we reserve the 4 bits for error correction. And we configure the maximal size of the ?DATA? as 256 bytes.

Figure 6 and 7 show the performance and effective experiments on Xen and VMware platforms. In each di- agram, TR standards for transmission rate; ETR means the effective transmission rate since we have 6 bytes overhead for data encapsulation; ADER expresses the average data error rate of the information transferred in ?DATA? field. From the two diagrams, it shows the value of TR in experiment is very close to the value in theory (e.g., 100bps on VMware platform and 125bps on Xen platform). With the size increase of the infor- mation in ?DATA? field (ranged from 8 to 256 bytes), it shows that the value of ETR stably increases. Moreover, when there is no FEC code on ?DATA? field, the ADER ranges from 10.37% to 10.45% on VMware platform, and ranges from 12.35% to 12.58% on Xen platform. It indicates that ?DATA? size is not relevant with the value of ADER when there is no noise, i.e., the interference from other VMs. Moreover, the different value of AD- ER reflects the characteristics of different virtualization platforms. Although the transmission speed of CPU     Figure 6. Transmission experiments on VMware  Figure 7. Transmission experiments on Xen  cache based covert channel is much faster (about 746.8 bps shown in [3]), the transmission speed of I/O based covert channel is still acceptable since I/O devices are relatively low speed devices.

To improve the reliability of VM I/O covert timing channel, we apply some FEC codes (e.g., RS code [20]) into vLeaker system to decrease the data error rate. For example, when transferring 223 bytes information via vLeaker system, we can utilize RS(255, 223) to encap- sulate the information into 255 bytes in ?DATA? field.

With such approach, the total overhead is 38 bytes on transferring 223 bytes. Table 4 shows the experimental results, we can see that the error rates on both VMware and Xen platform are downgraded around 5%.

Table 4. Channel reliability improvement via RS code  TR (bps) ETR (bps) ADER (%) VMware Platform 99.97 85.41 5.03  Xen Platform 124.9 106.80 5.31  4. Discussion The existence of I/O covert timing channel has been  revealed more than 20 years, and there are several ap- proaches [5, 6] to mitigate such channel. However, most hypervisors [21, 22] deployed as the key component  in the IaaS (infrastructure as a service) layer seems not seriously considering the threat of VM I/O timing channel, which gives the opportunity for such kind of attack. In this section, we would like to present some countermeasure techniques to mitigate the I/O timing channel in both system and user aspects.

4.1. System based approach  The key issue causes the I/O timing channel is the weak I/O isolation of I/O resources. To reduce the band- width of I/O timing channel, the following approaches can be utilized in the hypervisor.

Random time clocks. Usually, the process iden- tifies the information via measuring its I/O execution time. However if the clocks are random, then the timer interrupts generated to the process are also random, thus the process cannot get the precise time information and finally makes it hard to to derive the information via time measurement. For example, Hu [6] proposed to reduce the bandwidth of covert timing channels with Fuzzy time, i.e., the virtual interrupt periods presented to the VMs are added with the noise. Such approach is implemented in the VAX kernel [23], and the timer interrupt is uniformly distributed around 20 ms. The random clock approach is useful, however it also has the side effect on the normal applications which rely on the clocks for accurately collecting the timing information.

I/O execution time regulation. The key idea of this approach is to make each type of I/O operation stable in execution time aspect, i.e., each type of I/O operation can have nearly stable time to complete.

However such approach is difficult to achieve, as we need to re-design the I/O scheduling algorithm and may abandon the normal usage of I/O related cache in the hypervisor or storage system. Generally, such approach is not applicable as it can sacrifice the I/O performance of the whole system.

4.2. User based approach  Re-designing and implementing a VM I/O timing channel against system is a long-term work. It can not solve all practical problems as many COTS hypervisors (e.g., Xen, VMware ESX(i) server, hyper-V) or storage systems are already used in current cloud computing system. To solve the legacy issue, some workarounds are needed, as shown in the following.

Deploying friendly I/O disturbing process or VM. The purpose of this I/O process is to disturb the I/O timing channel constructed by the cooperated VMs.

As the information observing VM measures the I/O     execution time in a fixed ITW to identify the received information (as shown in Figure 1), random generated I/O operations by the third party can make the channel noisy and the information unrecognizable. When the hypervisor provides the VM disks via DAS (direct attached storage), a permanent disturbing VM can be deployed on the host. When the hypervisor provides the storage service through the assistance of the backend storage server, several processes can be deployed to conduct the I/Os in different partitions of the storage.

Furthermore, there should be some policies to control the I/O patterns of the process in order to make the I/O disturbing effective and efficient. As described in [19], we may have four parameters (Xiosize, Xpread, Xpseq , Xpburst) to adjust the I/O patterns run by the disturbing process. For example, we can use the following I/O pattern,i.e., (4KB, 50,0, 50) on our local testbed. Abso- lutely, we should adjust the four features to generate dif- ferent I/O patterns for the disturbing process according to the VM I/O workload on the virtualization platform.

Fine-grained management of VM disks. As the I/O timing channel is caused by the I/O contentions in the I/O subsystem including the I/O controller, I/O bus, disk drives and etc. Ideally, it is hard to influence the usage of I/O controller and bus except the disk drives.

To mitigate the I/O contention, fine-grained placement policies for the VM disks can be applied. Generally, disks owned by VMs with different protection levels should not be putted together on the same disk drives.

For example, suppose we have two VMs (named high- VM and low-VM), i.e., the high-VM has no network access right; the low-VM has free network access right.

If the virtual disks of the two VMs are put in the same physical disk, there is a chance that the sensitive information can be transferred from the high-VM to the low-VM via I/O covert timing channel, and finally such information can be spread into the external world. To avoid such issue, detailed placement policies of VM disks are needed.

5. Related Work  The feature of sharing the physical resources pro- vided by system virtualization has brought the benefit to IT industry by reducing the management and operation costs, but meanwhile some issues related with VM iso- lation are found. Although the virtualization platforms can logically isolate the VMs to prevent them accessing others? resources, it is hard to perfectly guarantee the performance and security requirements of VMs. Due to the weak isolation, a series of timing channel attacks are explored, as the following shows.

CPU cache and memory based timing channel.

Ristenpart [2] et al. firstly proposed the CPU cache based side channel attack in virtualized environment, and demonstrated it in real cloud products, e.g., A- mazon?s EC2 platform. Later, more and more attack and defense work are conducted by researchers in this aspect. Besides the existed hardware based method- s [24, 25, 26] to defend the CPU cache based timing channel, researchers proposed some novel approach- es [11, 13, 12] to address the issue in the cloud envi- ronment; In the contrary, Xu et al. [27] proposed the enhanced L2 Cache Covert Channels attacks that can improve the channel bit rate, they also show the limita- tion of CPU cache based timing channel. Independent but at the same time, Wu et al. [3] proposed a practical covert channel method by exploiting the memory bus.

VM I/O based timing channel. In this paper, we propose a covert I/O timing channel derived from VM I/O performance interference and demonstrate the prac- ticality in different hypervisors (e.g., VMware ESX, Xen). Compared with the Disk-arm channel presented in [5], our approach is more feasible since we do not need to construct the timing channel from the the low cylinder level. In our approach, the I/O timing channel can be easily constructed by the normal processes in the storage co-resident VMs after the ITW (interference timing window) is identified. To systematically mitigate the I/O timing channel, we discussed and proposed several approaches in both system and user aspects, e.g., the limitation of Fuzzy time [6] approach.

6. Future Work We explore a novel VM covert channel via I/O per-  formance interference, however it is still not perfect yet.

In the future, we would like to make the vLeaker system robust and practical in real environments. Generally, the following issues must be considered:  Scalability. We have not evaluated our vLeaker system in a noisy environment. The covert channel may lose its functionality on information exchange when other storage co-resident VMs are conducting I/O tasks.

Thus a solid approach must be proposed to solve this issue and make the channel reliable.

Practicality. Currently, our covert channel is ex- plored on local testbed, which is not persuasive. We expect to deploy our vLeaker system on Amazon?s EC2 platform and verify whether it is practical or not. As Amazon?s EC2 is based on the Xen platform, we are confident that the similar I/O timing channel can be constructed based on the local instance store.

Countermeasure methodology. Although some approaches have been discussed to defend the VM I/O timing channel, we would like to conduct more detailed research work to enhance the VM I/O isolation and mitigate such timing channel.

7. Conclusion  This paper presents vLeaker, an information leaking system built on VM I/O performance interference, by which storage co-resident VMs can exchange the in- formation without the explicit communication manner (e.g., via network, file sharing), and such timing channel cannot be tracked by traditional firewall in information protection system. To verify the practicality of our system, several experiments are done on both Xen and VMware platforms. And the result is quite promising, the effective transmission rate is around 100 bit/s with average data error rate less than 13% on our local testbed. Moreover, we discuss the potential approaches in both system and user aspects to prevent or detect such kind of channel. Finally, exploring VM based I/O covert timing channel in third party cloud and provide effective and practical countermeasure methodologies will be our valuable future work.

