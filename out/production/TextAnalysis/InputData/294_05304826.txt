An Efficient Association Rules Mining Algorithm  Based on Coding and Constraints

Abstract?The mining association rules is an important research field in data mining. The traditional association rule mining methods often generate too many candidate items and have to scan whole database for generating each candidate item. An efficient association rules mining scheme has been proposed in this paper. First, the sub-block coding method is used for the properties. Moreover, the constraints are made for the antecedent and consequent of rules. By using above strategies, the number of candidate items has reduced as well as the scanning size of the database. Therefore, the algorithm greatly improves the operating efficiency. Experimental results demonstrate that the proposed algorithm is more effective than the traditional approach.

Keywords-association rule; Apriori algorithm?constraint; code

I.  INTRODUCTION Mining association rules is an important area in data  mining. It can discover interesting correlations between itemsets in very large transaction database. Data mining research during the last several years has led to the development of a variety of algorithms for finding frequent itemsets. The classical Apriori algorithm proposed by Agrawal etc. [1, 2, 3] and FP-growth (frequent-pattern growth) algorithm proposed by Han[4,5] etc. are most well-known.

Apriori algorithm takes advantage of the Apriori knowledge of frequent sets property and uses a level-wise algorithm.

However, it may generate too many candidate sets and it needs scan the database many times. FP-growth algorithm does not generate candidate sets but uses conditional patterns to discover frequent patterns. The FP-tree and conditional pattern base achieve that by performing just two passes over the transactions. But the algorithm is complex and is not easy to maintain. Besides, it needs to compactly store FP-tree in memory the transaction of the original database. Otherwise, it will have an impact on the implementation of the program.

Based on the two algorithms, a variety of improved algorithms have been proposed. Such as (DHP) algorithm [6], Closet algorithm [7], Closet+ algorithm [8], CHARM algorithm [9], FP-Close algorithm [10]. These algorithms have improved the efficiency at the cost of complexity and they are not easy to maintain.

In order to improve the efficiency and quickly discover frequent itemsets from the transaction database, the sub-block coding method is used for the properties. Moreover, the constraints are made for the antecedent and consequent of  rules. In the paper we propose an efficient association rules mining algorithm based on coding and constraints according that records in sub-block have orders. The proposed algorithm can greatly reduce the number of candidate itemsets and the passes over the transaction. Thus it can save the running time and improve the operation efficiency of the algorithm.



II. RELATED DEFINITIONS Definition 1 Let D be a set of n transactions such that (s.t.)  D = {T1,T2,...,Tn }, where Ti ?I and I is a set of items, I = {i1,i2,...,im}. A subset of I containing k items is called a k- itemset. Let A and B be two itemsets s.t. A?I,B ?I, and A ? B = ?. An association rule is an implication denoted by A ? B , where A is called the antecedent and B is called the consequent.

Definition 2 The support of the rule A?B in the transaction database D is the ratio between the transaction number including A and B in the transaction sets and all the transaction number, which can be written as sup(A?B), that is to say sup(A?B)=|{T:A?B?T?T?D}|/|D|.

Definition 3 The confidence of the rule A?B in the transaction sets is the ratio between the transaction number including A and B and those including A, which can be written as conf (A?B), that is to say conf (A?B)=|{T: A?B?T, T ?D}|/|{T: A?T, T?D}|.

Definition 4 Frequent itemsets. If the ratio between the transaction number including A in the transaction itemsets and all the transaction number is higher than or equal to the minimum support (minsup), |{T:A?T?T?D}|/|D|?minsup , A is called a frequent itemset.

Apriori Principle: If an itemset is frequent, then all of its subsets must also be frequent. Conversely, if an itemset is infrequent, then all of its supersets must be infrequent too.

Definition 5 Find out all S?s non-empty subset s to each frequent itemset. Association rule s?S-s can be obtained when sup(S)/sup(s)>=minconf, minconf is defined as the minimum confidence of the rule. Sup(S)/sup (s) is defined as the confidence of the rule s?S-s where s is the antecedent of the rule and S-s is the consequent of the rule.

This work was supported by a grant from the National Science Foundation of China (No. J0724003?60773084?60603023) and a grant from the Ph.D. Programs Foundation of Ministry of Education of China (No.

20070151009).



III. ASSOCIATION RULES MINING  ALGORITHM BASED ON CODING AND  CONSTRAINTS    In Apriori algorithm, if the number of frequent 1-itemsets is n, then the number of candidate 2-itemsets generated is . It is obvious that the number of candidate itemsets is too large.

Besides, it needs to scan the transaction database (k+1) times to generate the maximal frequent k-itemsets. That is to say, the transaction database must be scanned multiple times in generating the frequent itemsets and it is very time consuming.

The association rules mining algorithm based on coding and constraints we proposed in this paper adopts the properties of Apriori algorithm and makes some improvements based on it. It uses constraints in the process of mining frequent itemsets and does the sub-block coding for attribute value in database.

A. Constraints In this paper a constraint is made for the antecedent and  consequent of rules. We divide the attribute values into decision attributes and non-decision attributes. Decision attributes can only appear in the antecedent of rules, and non- decision attributes can only appear in the consequent of rules.

Definition 6 Assume },...,,{ 21 tiiiI =  is an itemset of decision attributes, },...,,{ 2  ' rtt iiiI +=  is an itemset of non-  decision attributes. Let frequent 1-itemsets on decision attributes is ?= },,,{ 2111 miiiL ? I , frequent 1-itemsets on non-decision attributes is },,,{ 2112 nmm iiiL ?++= ?  'I , A? L11,B?L12. For a rule A?B, we need to calculate  Sup(A? B)=P(A) and conf(A?B)=P(B|A)=P(AB)/P(A). We can learn that it doesn?t need the value of P (B). Therefore, when generating candidate 2-itemsets, L12 L12 is not necessary.

So, the number of the generated candidate 2-itemsets is  )(C2 mnmn ??+ .

B. Coding strategy Our algorithm adds the constraint of the antecedent and the  consequent, so we need to code the attribute values block by block in transaction database D. First we code the decision attributes those act as the antecedent of rules from zero to M.

Then we code the non-decision attributes those act as the consequents of rules from M+1 to r. The transaction database after coding has the following characteristics: Each record in the database can be divided into two parts. Decision attributes are concentrated in the front part of the record and non-decision attributes are concentrated in the latter part.

C. Improvements based on Apriori algorithm The equations are an exception to the prescribed  specifications of this template. You will need to determine whether or not your equation should be typed using either the Times New Roman or the Symbol font (please no other font).

To create multileveled equations, it may be necessary to treat the equation as a graphic and insert it into the text after your paper is styled.

(1) Scan the transaction database D and generate frequent 1-itemsets on decision attributes and on non-decision attributes respectively;  (2) Generate candidate 2-itemsets through L11 L12 and L11 L11;  (3) The process of scanning database is improved. For the item whose code is less than or equal to M, it scans the database from left to right and each record is only scanned its front part (the part of decision attributes). For the item whose code is larger than M, it scans the database from right to left and each record is only scanned its latter part (the part of non- decision attributes).

D. Algorithm Realization Mining association rules can be divided into two sub-issues  as follows: (1) Find out all frequent itemsets. (2) Set up association rules through frequent itemsets. According to the thought above, we give the code of the algorithm.

Input:  D?transaction database after coding;  minsup?minimum support count threshold;  M?the maximum coding in the antecedent.

Output?  L?frequent itemsets in D.

Method?  (1) 11L =find_frequent_1-itemsets_qian(D,M)?  (2) 12L =find_frequent_1-itemsets_hou(D,M)?  (3) 2C =apriori_gen2 ( 11L , 12L );  (4) For each candidate 2Cc ? , count(c);  (5) 2L = { 2Cc ? | Count(c) ?minsup};  (6) For (k=3; ???1kL ; k++){  (7) Ck=apriori_gen ( 1?kL );  (8)   For each transaction t?D{  (9)     Ct=subset ( kC ,t);  (10)     For each candidate c?Ct  (11)           Count(c) ;}  (12)    kL = {c?Ck| count(c) ?minsup;}  (13)  Return L= kk LU ;  Procedure apriori_gen2 ( 11L  , 12L , frequent_1-itemsets)    (1)  For each itemset 1l ? 11L  (2)     For each itemset 2l ? 12L  (3)        C= 1l 2l ;  (4)       Add C to 2C ;  (5)  For each itemset 1l ? 11L  (6)        For each itemset 2l ? 11L  (7)           C= 1l  2l ;  (8)       Add C to 2C ;  (9)   Return 2C Procedure Count (itemsets)  (1) for each transaction t?D  t ? I ? I' (2) {for each item? itemsets  (3)    If item<= M  find items in L  (4)    Else find items in L'  (5)  If  all item?t  (6)  Itemsets.count++;}  (7) Return Itemsets.count;  E. Algorithm Performance Analysis (1) It has reduced the number of candidate itemsets.

From the description above, we can learn that the asso- ciation rule algorithm based on coding and constraints can greatly improve the efficiency and save the operating time. The traditional Apriori algorithm will generate 2nC  candidate 2- itemsets, but the improved algorithm just  generate  ).(C2 mnmm ??+ Because  )( 2 )( mnmmnmn CmnmCCC ??+ +??+== ?  222 )]([ mnmn CmnmCC ?=??+? .

We can learn that the improved algorithm has reduced  mnC ?  candidate 2-itemsets. Similarly, the number of frequent  2-itemsets has been reduced. So do frequent k-itemsets.

(2) It has reduced the scanning size of the database.

Assume a record contains a items on average. And the number of items that can act as antecedent or whose code is less than or equal to M is b. Then the number of items that can act as the consequent or whose code is larger than m is (a-b).

The traditional Apriori algorithm needs to scan the entire record. But our improved algorithm will scan the next record when the front part does not meet or it has scanned to item  whose code is larger than M. At this point, we only have scanned (b+1) items.

Assume that there are q records in transaction database and there are q1 records whose front parts are not meet the candidate k- itemsets. At this moment, Apriori algorithm has to scan a?q items while the improved algorithm has to scan a? (q?q1)+(b+1)?q1 items. The number of reduced items in the scanning process is a?q?[a?(q?q1)+(b+1)?q1]=(a?b? 1)?q1.

Therefore, the proposed algorithm can significantly reduce the number of candidate items as well as the scanning size of the database and greatly improve the operating efficiency.



IV. EXPERIMENTS In order to verify the efficiency of the improved algorithm,  we extract two groups of data from Coronary Heart Disease (CHD) database in Traditional Chinese Medicine (TCM). The first group includes TCM syndrome types and the channel tropisms. The second group includes TCM syndrome types and medication. We define the constraint that TCM syndrome types act as the antecedent of rules, the channel tropisms and medication act as the consequent of rules. These two sets of data are coded as table 1 and table 2. The data after coding are shown in table 3 and table 4.

Table I code of TCM syndrome typesand the channel tropisms TCM syndrome typesand the channel  tropisms Code  turbid phlegm 0 heat syndrome 1 ?? ?? renal 26 triple warmer 27 ?? ?? lung 36 intestinal 37  Table II code of TCM syndrome types and medication  TCM syndrome types and medication Code turbid phlegm 0 heat syndrome 1 ?? ?? depletion of yang 25 menispermaceae 26 ?? ?? lotus seed 622 ash bark 623  TableIII data of TCM syndrome types and the channel tropisms 14,26,28,30,31,32,33,34,35,36 12,14,26,28,29,30,31,32,33,34,35,36 12,14,26,28,29,30,32,34,35,36 14,23,26,28,29,30,31,32,33,34,35,36 14,26,28,30,31,32,33,34,35,36 ??? 12,14,26,28,29,30,31,32,34,35,36    Table IV data of TCM syndrome types and medication 14,56,94,190,223,250,261,277,317,367,368,474,487,535, 543,600,613 12,14,37,56,94,116,188,213,250,261,317,368,412,427,446, 474,476,487,535,543,558,600,603,613 12,14,38,143,189,214,225,250,317,358,367,405,411,446,474, 479,485,487,536,543,606,613 14,56,101,192,213,220,250,396,603,613 ?? 12,14,40,52,53,66,73,75,93,94,96,184,213,214,292,308,317, 319,422,503,513,530,543,558    Let the support threshold is 0.08, 0.10, 0.12 and do the experiments by using traditional Apriori algorithm and improved algorithm respectively. All tests are running on an ASUS notebook with 1.67G frequency and 1.5 G memory.

From the following figures, we can learn that the improved algorithm is much better than traditional Apriori algorithm on the implementation speed.

f i gur e 1 TCM syndr om e  t y pe s  and t he channel  t r opi s m s   s u p =0 . 0 8     5 10 15 20 25  r ecor d count s*100  ti m  e/ s Apr i or i  al gor i t hm  i m  pr oved al gor i t hm    f i gur e 2 TCM syndr om  e t ypes and t he channel  t r opi sm  s  sup= 0. 10    5 10 15 20 25  r ecor d count s*100  ti m  e/ s Apr i or i  al gor i t hm  i m  pr oved al gor i t hm  figure 3 TCM syndrome types and  the channel tropisms  sup=0.12       5 10 15 20 25  record counts*100  t i m e / s Apriori algorithm  improved algorithm    figure 4 TCM syndrome types and  medication sup=0.08        5 10 15 20 25  record counts*100  t i m e / s  Apriori algorithm  improved algorithm    figure 5 TCM syndrome types and  medication sup=0.10          5 10 15 20 25  record counts*100  t i m e / s  Apriori algorithm  improved algorithm    figure 6 TCM syndrome types and  medication sup=0.12        5 10 15 20 25  record counts*100  t i m e / s  Apriori algorithm  improved algorithm

V. CONCLUSIONS In this paper, an efficient association rules mining  algorithm based on coding and constraints is presented. The sub-block coding method is used for the properties. Moreover, the constraints are made for the antecedent and the consequent of rules. The proposed algorithm greatly reduced the number of candidate itemsets and times of scanning database. It also has the advantages of the traditional Apriori algorithm. For example, algorithm is simple and it is easy to maintain.

Experimental results demonstrate that the algorithm has some theoretical and practical value for mining association rules with decision attributes and non-decision attributes.

