Efficient Algorithm for Extreme Maximal Biclique Mining in Cognitive Frequency  Decision Making

ABSTRACT?The cognitive radio is growing an important interest in wireless communication study. A cognitive radio ad hoc network may take a master-slave tree-based structure in some special applications. For a master node with limited communication capability, slave nodes usually use the same frequency to access a subnet managed by the master. Each slave node can acquire many frequencies for communication by a local spectrum sensing process. However, there may be no common set of frequencies available for every slave node. In this case, we should delete some slave nodes and keep other nodes staying in the subnet as many as possible. By mapping the node set and frequency set to be both parts of a bipartite graph respectively, the problem can be turned into a special case of searching for maximal bicliques. Based on a well- known LCM (Linear time Closed itemset Miner) algorithm which enumerates frequent item sets (maximal bicliques), and using a new technique in terms of dynamic thresholds, we have solved this problem in real time to meet requirements of most cases from our application. And we also improved the LCM algorithm by pruning more rows and columns of vertices in a bipartite graph and by mining more heuristic information about what vertices make others unclosed to achieve much better performance.

Keywords-maximal bicliques; dynamic thresholds; cognitive radio ad-hoc network; frequency decision.



I. INTRODUCTION Frequent item set mining is an important problem in data  mining and has many applications such as Associating Rule Mining [1][2], life science data analysis [3] and inductive database. Enumerating frequent closed item sets, a subproblem of frequent item set mining, can be stated as follows [4]. Graph mining is also an important and active research topic in data mining field. Enumerating maximal biclique from a graph can be one-to-one correspondence with the enumeration of closed pattern pairs [5] and the problem is described as follows.

Let G = <V, E> be a graph with vertex set V and edge set E. A pair of disjoint nonempty subsets V1 and V2 of V is called biclique if (u,v)?E for all u?V1 and v?V2. Define ?(v) as the set of all vertices in G that are adjacent to v, i.e., ?(v) = {u|(u,v)?E }. For a nonempty subset X of vertices of a graph, ?(X) is the set of common neighbourhood of all vertices in X.

For an existing biclique subgraph H = < V1?V2, E >, the biclique subgraph is a maximal biclique subgraph if ?(V1) = V2 and ?(V2) = V1.

Many real-life applications can be modeled by maximal bicliques or closed pattern pairs. One example is given here.

For social relation, common characters of persons can be modeled by maximal biclique which is useful in commercial filed. Surprisingly this idea has similar scenario in wireless communication filed.

In this paper, we propose a new application in CRAHNs(cognitive radio ad hoc networks)[13]. Suppose that there is a simple network consisting of a master node and several slave nodes. The slave nodes only communicate with the master node directly and they must use the same parameters decided by the master node, such as frequency.

Each slave node in the network firstly senses electronicmagnetic surroundings and then determines which frequency set can be used for communication and this process will cost too much time and energy. After gathering all frequency sets from slave nodes, the master node then decides to use which frequency for communication and backup several frequencies for use in future because of high cost of the sensing process. It does not need too many backup frequencies as these selected frequencies are not valid over a certain long period. However, maybe there is not a frequency which can be used by all slave nodes since the electromagnetic surroundings are complex. Under this condition, not all slave nodes can stay in the network and it is the master node to decide the remnant slave nodes and the common frequency set of them. How to choose the slave nodes and the frequency set is the problem called CFDM (Cognitive Frequency Decision Making).

We can model CFDM by enumerating maximal bicliques from a bipartite graph in which one part represents the node set while the other part represents the frequency set. For a maximal biclique of the graph, the master node can make the slave nodes represented by one part of the biclique remnant and use the frequency set represented by the other part.

Enumerating frequent item sets and enumerating maximal bicliques from a graph are both long studied. There are several algorithms for these problems at present, such as CHARM [6], CLOSED+ [7], FPclose [8] [9], LCM (Linear time Closed itemset Miner) [14][4][15] for enumerating frequent item sets and [5], [10], [11], [12] for enumerating maximal bicliques. However, all these algorithms are enumerating all maximal bicliques or closed pattern pairs.

For CFDM problem, we are only interested in the best solution defined later in this paper. Considering good performance of LCM, we choose it as the base of our algorithm. There are three versions of LCM for different  ___________________________________     applications including enumerating frequent, closed and maximal itemsets. We select to modify their function for enumerating closed frequent item sets to solve the CFDM problem.

The remainder of this paper is organized as follows. In Section II, we describe the details of CFDM. In Section III and Section IV, we introduce the algorithm LCM and our algorithm EMBS (Extreme Maximal Biclique Searcher). The experiments and results are listed in Section V. And Section VI is the conclusion.



II. CFDM PROBLEM DETAILS Let Net=<N ? F, EN> be a network with node set N,  frequency set F and the relationship EN among nodes and frequencies. The pair (n, f) ? EN represents that the node n can use the frequency f to communicate with the master node.

A solution to the problem is a pair of subsets (Ni ? N, Fi ? F) where the master node retains nodes in Ni and uses one frequency in Fi for communication. Let the set of all solutions be S and the limit of the frequency is fm. S should satisfy below conditions to meet requirements of CFDM.

S={(Ni, Fi)| Ni ? N, Fi ? F, Ni?Fi ? EG, |Fi| ? fm} (1)?  ?( Ni, Fi) ?S, ( (?f ? Fi) (n, f ) ?EG) ?n ? Ni) (2)  ?( Ni, Fi) ?S, ( (?n ? Ni) (n, f ) ? EG) ?f ? Fi) (3)  Let G = < V1 ? V2, EG > be a bipartite graph with vertex set V1, V2 and edge set EG. To model the network, let the node set N be V1 and the frequency set F be V2. If there is a pair of (n, f) in EN, add the corresponding pair into EG.

Therefore, the graph can be modified to G = < N ? F, EN > and the set S of all solutions in Net is the set of all maximal bicliques in G because the conditions satisfied by S are equal to those satisfied by maximal bicliques.

However, we are only interested in the best solution Bm=<Nm, Fm>, i.e., the best maximal biclique (also called extreme maximal biclique), satisfying (4).

?Bi=<Ni,Fi>?S,|Ni|<|Nm| ? (|Ni|=|Nm| 	 |Fi|?|Fm|) (4)?

III. LCM ALGORITHM In this section, LCM algorithm is described in graph  format while it is described in the database format in original paper [4]. This work has been done detailedly in [5] and here we only list the information needed in this paper. For a bipartite graph recorded in a matrix, the rows of the matrix represent one part of the graph as the columns of the matrix represent the other part. Before an introduction to the LCM algorithm, some notations will be given bellow.

Let G=<V1?V2, EG> be a bipartite graph. The characteristics of a maximal biclique have been given in the section I. For a biclique B = < X, Y >, the set X and Y are  called closed sets if and only if B is a maximal biclique, else they are called unclosed sets. For a vertex  v ? V1, ?(v) is the neighbourhood of v and id(v) is the position of v in V1 which is sorted by |?(v)| in decreasing order.

For a matrix recording a bipartite graph, let X be a part of a maximal biclique. X is empty at the beginning. LCM algorithm recursively selects vertices represented by columns in matrix and inserts them into X.

Algorithm LCM() global: a bipartite graph G with vertex set V1 and V2 p is the threshold of one part in a maximal biclique q is the threshold of the other part in the biclique Description: 1: sort {v ? V1}, {v ? V2} by |?(v)| in decreasing order 2: V1?{ v ? V1 | |?(v)| ? p } 3: for each v ? V1, set flag(v)=0 4: T ? ? 5: for each v ?V1 6:     X? ? 7:     if ?(v) ? q and LCM_CLOSED(X,v) = 0 8:          then LCM_Iter(X,V2,v) /* ?(?)= V2 */ Algorithm LCM_Iter() Input: X is a vertex set ?(X) is the neighbourhood of X v is the vertex to be added to X Description: 1: Y ? X ? {v} 2: for each u ? {?|? ? V1 	 ? Y 	 id(?) < id (v)} 3:     if ?(u) ???(Y)   then Y?Y ? {u} 4: Z?{?|??V1?Y 	?id(?)<id(v) 	 |?(?) ? ?(Y)| ?q} 5: if |Y| + |Z| < p   then return 6: if |Y |? p    then output (Y, ?(Y)) 7: for each ??Z 8:     for each s?T 9:           if flag(s) ? id(?)  then flag(s) ?0,  T?T ?{s} 10:     if flag(?)=0  then r?LCM_CLOSED(Y, ?) 11:         if r = 0    then LCM_Iter(Y, ?(Y), ?) 12:         else flag(?) ?r, T?T ? {?} 13: for each s?T 14:    if flag(s) is set during the current iteration process 15:    then flag(s) ? 0, T ? T ? {s} Algorithm LCM_CLOSED() Input: X is a vertex set and v is a vertex to be added to X Description: 1: for each u?V1 , u X 2:    if ?(X ?{u}) ???(X ? {v}) then return id(u) 3: return 0 The pseudo code of LCM is rebuilt from a program1. The  purpose of this paper is to modify LCM to solve the CFDM problem and do some improvements.



IV. OUR ALGORITHM: EMBS In this section, we list all improvements on LCM.

1 Downloaded from http://fimi.cs.helsinki.fi/src/    Figure 2.  An example of the process of recursion.

A. Dynamic thresholds In our algorithm, we introduce two parameters pm and qm  representing the best maximal biclique to be found currently.

In LCM, the thresholds are constant and the algorithm enumerates all maximal biclique. In EMBS, only the best maximal biclique will be saved and the thresholds will be dynamically updated according to the biclique found. Fig. 1 will show this difference.

In Fig. 1, M is the matrix sorted, and m and n are the amount of rows and columns of M respectively. (a) of Fig.1 is the pruning tree of LCM and (b) is that of EMBS. The italic sets are the leaves or pruned branches while the boldfaced sets are maximal bicliques found.

The difference is caused by dynamic thresholds (pm, qm).

The pair (pm, qm) is always (2,2) in (a) of Fig.1 produced by LCM. But in (b) of Fig.1 from EMBS, (pm, qm) is changed to (2, 3) when the first maximal biclique is found and it is changed to (3,3) when the second one is found. Because of the increasing in the thresholds, more nodes are pruned in part (b).

B. Improve the judgment of closed state Let X be the first parameter of the function LCM_Iter.

According to the pseudo code, |X| is increasing continuously in recursive process while |?(X)| is decreasing. For parameter v, if there is a vertex u not included by X, id(u) > id(v) and ?(X?{u}) ???(X?{v}), then X?{v} is not closed. If id(u) < id(v) and ?(X?{u}) ???(X?{v}), the vertex will be inserted to X with v together. So we do not iterate on vertices with id less than that of v. For each step S? iterated from a step S, let Y be the set of the vertices selected from S to S? and let u be  the vertex making X unclosed in S. If u Y, X?Y?{v} is not closed also because ?(X?Y?{u}) = ?(X?{u})??(Y), ?(X?{v})??(Y) = ?(X?Y?{v}) and ?(X?{u}) ???(X?{v}).

So at step S, we can record the vertex making v unclosed and keep this information valid for S? to skip some evaluations on closed states until S returned. But if the vertex u has been inserted into Y, X?Y?{v} may be closed. At this condition, the state of X?Y?{v} should be recomputed.

LCM algorithm uses arrays unclosed_u and unclosed_v to manage the closed state. If u makes v unclosed at step S, set unclosed_u[v] = u and unclosed_v[length] = v while a variable length is used to indicate the length of unclosed_v.

All elements put to unclosed_v by step S will be sorted by the corresponding values in unclosed_u. When iterating on a vertex i at step S?, LCM deletes all values which are not bigger than i from the tail of unclosed_v and clear the corresponding values in unclosed_u also.

Fig. 2 is an example to show this clearly. In Fig. 2, M is the input graph and p, q are two thresholds. From S0 to S7 is the recursion order starting from set {5}.The sets marked italic are unclosed sets. Table in Fig.2 shows the process of transformation of unclosed_u and unclosed_v. unclosed_u[1] is set to 3 at step S2 and is cleared at step S3. But at step S5, unclosed_u[1] is recomputed and reset. In fact, the value 3 of unclosed_u[1] should be ignored only when the vertex 3 has been in the selected set.

In EMBS algorithm, each vertex in V1 has a stack to manage closed states. Firstly zero is pushed into every stack and suppose that u is the vertex making v unclosed in Si, u will be pushed into stack of v and it will be valid until u is  Figure 1.  The difference of the pruning tree of LCM and that of EMBS.

selected or Si returns. If Sj is an offspring step iterated from Si and only if u is selected in Sj, closed state of v will be recomputed, or there is no any calculation on closed state about v in step Sj. When step Si returns, every stack changed in Si will pop the top value. While using stacks to manage closed states, each operation except computing closed state can be completed in O(1) time and the result of computation can be used more effectively. After optimizing, the process of sorting for unclosed_v is cut while all redundant recomputation of closed states is reduced.

C. Reduce the size circularly In LCM algorithm, only the vertices in one part of the  graph are reduced by the relationship of the neighbourhoods.

In EMBS algorithm, all vertices in both parts of the graph  are reduced. After reducing the vertices in one part, the neighbourhoods of the vertices in the other part are changed simultaneity. So we should reduce the other part again until all the two parts can not be reduced any more.

Fig. 3 shows two matrices reduced by LCM and EMBS.

M is the original matrix. M1 is the matrix reduced by LCM and M2 is the matrix reduced by EMBS. It shows that the matrix reduced by EMBS is smaller than the matrix done by LCM. The sixth column of M is eliminated by LCM while the last two columns and the last two rows of M are removed by EMBS.

D. The algorithm Detailed algorithm.

global: R is one part of the result biclique.

?(R) is the other part of the result biclique.

pm is the current threshold of R(main threshold) qm is the current threshold of ?(R) p is the initial threshold of R(main threshold) q is the initial threshold of ?(R) Algorithm EMBS() Input: a bipartite graph G with vertex set V1,V2 Description: 1: pm ? p , qm ? q 2: while v? V1 ?|?(v)|< pm ? v?? V2 ?|?(v)|< qm 3:           then V1 ? V1 ? {v}, V2 ? V2 ? {v?} 4: sort {v ? V1}, {v ? V2} by |?(v)| in decreasing order 5: initialize stacks for every v ? V1, stack[v].push(0) 6: for each v ? V1 7:     X? ? 8:     if ?(v) ? qm and LCM_CLOSED(X,v) = 0 9:     then EMBS_Iter(X, V2,v) /* ?(?)= V2 */ 10: return <R, ?(R)> Algorithm EMBS_Iter() Input: X is a vertex set ?(X) is the neighbourhood of X v is the vertex to be added to X Description: 1: Y?X ? {v}, ?(Y) ? ?(X) ? ?(v) 2: for each u ? {?|??V1?Y 	 id(?) < id (v)} 3: if  ?(u) ? ?(Y)   then Y?Y ? {u};  4: Z?{?|??V1?Y 	 id(?)<id(v) 	 |?(?) ??(Y)| ?qm} 5: if |Y| + |Z| < pm    then return 6: if (|Y|> pm 	 |?(Y)| ?q) ? (|Y|= pm 	 |?(Y)| ?qm) 7: then <R,?(R)>?<Y,?(Y)>, <pm,qm>?<|Y|,|?(Y)|+1> 8: T? ? 9: for each ?? Z 10:    if stack[?].get() = 0 ? stack[?].get()? Y 11:       then r ? LCM_CLOSED(Y, ?) 12:            if r = 0  then EMBS_Iter(Y, ?(Y), ?) 13:            else stack[?].push(r), T? T?{?} 14: for each ?? T   stack[?].pop() The 7th line of function EMBS_Iter is to update  thresholds dynamically. In EMBS algorithm, the both line 2 and 3 are to reduce the size of the matrix circularly, and lines between 9th and 14th of function EMBS_Iter represent the improvement for judgment of closed state.



V. EXPERIMENT AND RESULT We evaluate the efficiency of EMBS with dynamic  thresholds by running on different size of graphs and evaluate that of EMBS without dynamic thresholds by comparing it to LCM algorithm. The experiments are conducted on randomly generated matrices representing bipartite graphs. Our computer for experiment is a PC with a 3.0GHz CPU and 1GB of memory.

Table I shows the performance of EMBS with dynamic thresholds on randomly generated bipartite graphs in different size. Row one is the size of the graphs and m+n means that there are m vertices in the part representing nodes and n vertices in the other part representing frequencies. Row two is edge density of the graphs. If there are m+n vertices and w edges in the graph, the edge density will be calculated by w/(m*n). The first column is the threshold of frequencies while the threshold of nodes is 1. The number in the table is time in milliseconds and data of first two size graphs are in integral number while others maintain two digits after decimal point.

Figure 3.  Matrices processed by LCM and EMBS    To evaluate the efficiency of EMBS with dynamic thresholds, we use four different sizes of graphs to represent different size of subnet. The biggest value of threshold of frequencies is eight because we only need to keep at most eight frequencies to use over a certain long period. The threshold of nods means that one node is needed at least. We can find that the running time of EMBS with dynamic thresholds is below one second at most times. This performance meets the real-time requirements of our applications. In some cases, the running time is still very long. However, these cases are very rare in real applications.

Table II shows performance of both LCM and EMBS without dynamic thresholds on different number of vertices and edge density. At each row of the table, the performance is averaged over five randomly generated graphs of the same vertices and edge density. The thresholds are both one in this case. Note that both LCM and EMBS here are searching for all maximal bicliques (complete bipartite graphs) not only  for the extreme maximal biclique. The first column of the table is the amount of nodes in each part of the graph. The second column is the edge density in the graph. The third column is the amount of all maximal bicliques ever found.

The maximal bicliques found by LCM and those found by EMBS without dynamic thresholds are the same. The forth and fifth columns are running time of LCM and EMBS while the sixth column is the ratio of data in the fifth column and data in the forth column. The last column denotes the performance improvement of EMBS, and obviously EMBS without dynamic thresholds performs better than LCM according to Table II. The first reason is that we reduce the time for judgment of closed state, though the pruning tree of EMBS and that of LCM are the same. The second reason is that EMBS can reduce the graph better than LCM, especially when the edge density of graph becomes little.

TABLE I.  PERFORMANCE OF EMBS WITH DYNAMIC THRESHOLDS ON RANDOM BIPARTITE GRAPHS.

Vertices 64+512 32+256 16+128 8+64 Density  Threshold 10 30 50 70 90 10 30 50 70 90 10 30 50 70 90 10 30 50 70 90 1 40 34 47 55 87 29 4 7 11 17 1.73 1.39 1.80 2.55 2.82 0.50 0.64 0.77 0.81 0.89 2 5 34 47 55 87 2 5 7 12 17 0.77 1.47 1.79 2.42 4.46 0.49 0.66 0.76 0.82 0.86 3 8 52 92 76 89 2 4 9 15 17 0.77 1.51 2.11 3.18 2.89 0.52 0.70 0.71 0.77 1.49 4 15 144 493 489 95 3 11 16 24 17 0.99 2.02 3.30 5.36 2.81 0.52 1.98 0.78 0.77 0.85 5 18 356 2,099 3,486 109 3 13 51 34 17 1.06 1.79 3.66 5.08 2.72 0.51 0.75 0.75 0.84 0.85 6 32 668 8,251 13,477 149 5 26 101 63 18 0.99 2.20 6.56 6.57 3.44 0.52 0.77 0.81 0.83 0.89 7 36 1,083 19,450 68,684 551 4 34 193 194 17 1.09 2.82 8.31 13.65 3.13 0.52 0.80 0.85 0.83 0.82 8 42 2,049 45,016 340,940 11,295 6 62 432 969 17 1.09 2.88 14.70 16.84 2.74 0.50 0.91 0.94 0.86 0.86    TABLE II.  PERFORMANCE OF LCM AND EMBS WITHOUT DYNAMIC THRESHOLDS ON RANDOM BIPARTITE GRAPHS.

Vertices Edge density Maximal biclique Time of LCM(milliseconds) Time of EMBS (milliseconds) Ratio  Performance Improvement  (1-Ratio) 100+100 0.10 1,371 120 80 67% 33% 100+100 0.20 11,340 102 95 93% 7% 100+100 0.30 96,809 896 848 95% 5% 100+100 0.40 844,410 8,594 8,235 96% 4% 100+100 0.50 11,264,781 120,075 113,920 95% 5% 200+200 0.10 13,640 132 126 95% 5% 300+300 0.10 59,296 787 731 93% 7% 400+400 0.10 178,732 3,282 2,908 89% 11% 500+500 0.10 433,874 10,156 8,672 85% 15%  1000+1000 0.01 4,233 45 43 96% 4% 2000+2000 0.01 35,322 511 417 82% 18% 4000+4000 0.01 419,076 9,399 6,964 74% 26% 6000+6000 0.01 1,823,122 60,598 44,910 74% 26%

VI. CONCLUSION In this paper, we discussed a new application named  CFDM (Cognitive Frequency Decision Making) in cognitive radio ad-hoc networks. Based on a well-known algorithm LCM for frequent item set mining, the CFDM problem has been solved by our algorithm EMBS (Extreme Maximal Biclique Searcher) perfectly through introducing the idea of dynamic thresholds. Benefiting from dynamic thresholds, EMBS can prune small maximal bicliques efficiently to find the extreme maximal biclique. Therefore, most CFDM problems can be solved in real time. We also improved the performance of LCM algorithm itself in two aspects: reduce the size of the graph and reduce the time for judgment of closed state. We found that the performance of EMBS with dynamic thresholds relates to the thresholds while the performance of EMBS without dynamic thresholds relates to the edge density of the graph. And the experiments show that EMBS outperforms much more than LCM.

Nevertheless, we now just solve CFDM problem in one subnet. In real-life applications, there may be more than one subnet. Therefore, the future work may focus on how to solve CFDM problem in cases following. One is that there are several unattached subnets and slave nodes can communicate to several master nodes. Another is that the subnets in a network are organized in tree-form topology.

One slave node in a subnet may be the master node in another subnet so that deleting one node in a subnet may remove a large branch of subnets in the whole network. In such case, we should assign more weight on some special nodes to prevent such node from being deleted when searching for maximal bicliques. And we should develop more efficient algorithm to achieve real-time performance in some very large wireless networks, though such networks are very rare in current applications. Still, the future work also includes those related applications with different definitions of extreme maximal bicliques. For example, some applications may be interested in maximal bicliques which includes the most nodes in both parts of a biclique.

[1] R. Agrawal, and R. Srikant, ?Fast algorithms for mining association  rules,? In Proceeding of Int. Conf. Very Large Data Bases, pages 487- 499, Santiago, Chile,  September 1994.

[2] K. Gouda, and M.J. Zaki, ?GenMax:An Efficient Algorithm for Mining Maximal Frequent Itemsets,? Journal of Data Mining and Knowledge Discovery, pages 1-20, 2005  [3] Liping Ji, Kian-Lee Tan, and K H. Tung, ?Compressed Hierarchical Mining of Frequent Closed Patterns from Dense Data Sets,? IEEE Trans. on Knowledge and Data Engineering, Vol 19, No.9, Sept 2007.

[4] T. Uno, M. Kiyomi, and H. Arimura, ?LCM ver.2: Efficient mining algorithms for Frequent/closed/maximal itemsets,? In Proc. IEEE ICDM?04 Workshop FIMI?04, 2004.

[5] Jinyan Li, Guimei Liu, Haiquan Li, and Limsoon Wong, ?Maximal Biclique Subgraphs and Closed Pattern Pairs of the Adjacency Matrix: A One-to-One Correspondence and Mining Algorithms,? IEEE Trans.

Knowledge and Data Engineering, vol. 19, No. 12, pp. 1625-1637, Dec. 2007.

[6] M. J. Zaki, and C.-J. Hsiao, ?CHARM: An efficient algorithm for closed itemset mining,? in Proceedings of the Second SIAM  [7] J. Wang, J. Han, and J. Pei, ?CLOSET+: Searching for the best strategies for mining frequent closed itemsets,? in Proceedings of the  Discovery and Data Mining (KDD?03), Washington, DC, USA, 2003, pp. 236?245.

[8] G. Grahne, and J. Zhu, ?Efficiently using prefix-trees in mining frequent itemsets,? in Proceedings of FIMI?03: Workshop on Frequent Itemset Mining Implementations, 2003.

[9] G?sta Grahne, and Jianfei Zhu, ?Fast algorithms for frequent itemset Engineering, vol. 17, no. 10, pp.1347?1362, October 2005.

[10] G. Alexe, S. Alexe, Y. Crama, S. Foldes, P. L. Hammer, and B.

Simeone, ?Consensus algorithms for the generation of all maximal bicliques,? Discrete Applied Mathematics, vol. 145(1),  pp. 11?21, 2004.

[11] D. Eppstein, ?Arboricity and bipartite subgraph listing algorithms,? Information Processing Letters, vol. 51, pp. 207?211, 1994.

[12] K. Makino, and T. Uno, ?New algorithms for enumerating all maximal cliques,? in Proceedings of the 9th Scandinavian Workshop on Algorithm Theory (SWAT 2004). Springer-Verlag, 2004, pp. 260? 272.

[13] I. F. Akyildiz, W.-Y. Lee, and K. Chowdhury, ?CRAHNs: Cognitive Radio Ad Hoc Networks,? Ad Hoc Net. J., vol. 7, no. 5, July 2009.

[14]  T. Uno, T. Asai, Y. Uchida, and H. Arimura, ?LCM: An Effcient Algorithm for Enumerating Frequent Closed Item Sets,? In Proc.

IEEE ICDM?03 Workshop FIMI?03, 2003.

[15] T. Uno, M. Kiyomi, and H. Arimura, ?LCM ver.3: Collaboration of Array, Bitmap and Prefix Tree for Frequent Itemset mining,? In OSDM?05: Proceedings of the 1st international workshop on open source data mining, pages 77?86, 2005.

