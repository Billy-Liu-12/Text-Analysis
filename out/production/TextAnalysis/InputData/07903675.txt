1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Abstract?In this paper, we consider the problem of mutual privacy-protection in social participatory sensing in which individuals contribute their private information to build a (virtual) community. Particularly, we propose a mutual privacy preserving k-means clustering scheme that neither discloses individual?s private information nor leaks the community?s characteristic data (clusters). Our scheme contains two privacy-preserving algorithms called at each iteration of the k-means clustering. The first one is employed by each participant to find the nearest cluster while the cluster centers are kept secret to the participants; and the second one computes the cluster centers without leaking any cluster center information to the participants while preventing each participant from figuring out other members in the same cluster. An extensive performance analysis is carried out to show that our approach is effective for k-means clustering, can resist collusion attacks, and can provide mutual privacy protection even when the data analyst colludes with all except one participant.

Index Terms?Privacy Preservation; k-Means Clustering; Social Participatory Sensing; Homomorphic Encryption; Social Networking Big Data.

F  1 INTRODUCTION  O NLINE/MOBILE social networking and the sensors (pedome-ter, cardio watch, etc.) embedded in various smart devices have become deeply involved in our daily lives, which conse- quently triggers a large variety of social participatory sensing applications. Participatory sensing is a process of acquisition, integration, and analysis of big and heterogeneous data, which is generated by a diversity of sources, such as smart devices and sensors [1], [2], and it can reduce the resource cost as data collection no longer depends on the large-scale deployment of sensors. With such applications, people show more or less inter- ests in performing social comparisons with others, which could help them get an accurate view about themselves and motivate them to achieve more, according to the social psychology theory [3]. For example, people constantly engage in comparison with their friends on emotional moods, travelled locations, walking distances, fitness status, etc. One question that is frequently asked is: where am I in my community? A study on the community data with data mining techniques could answer such questions.

However, although the underlying data about the participants are  Manuscript received Oct. 31, 2016; revised Dec., 17, 2016; revised Feb., 28, 2017; accepted April 1, 2017.

? Kai Xing and Fengjuan Zhang are with the School of Computer Science and Technology, University of Science and Technology of China, Hefei Anhui, P.R.China. E-mail: kxing@ustc.edu.cn, fjzhang@mail.ustc.edu.cn  ? Chunqiang Hu (Corresponding Author) is with the College of Software Engineering, Chongqing University, and with Key Laboratory of Depend- able Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, China.E-mail: hcq0394@163.com  ? Xiuzhen Cheng is with the Department of Computer Science, The George Washington University, Washington DC. USA. E-mail: cheng@gwu.edu  ? Jiguo Yu (Co-corresponding Author) is with the School of Informa- tion Science & Engineering, Qufu Normal University, China. E-mail: jiguoyu@sina.com.

? ? These two authors contribute equally to this study.

Copyright (c) 2009 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org.

greatly helpful, such information may trigger serious concerns on privacy leakage (location, emotion, health, etc.). Consequently there is a conflict between data privacy and the wide adoption of social participatory sensing applications.

For a typical social participatory sensing application, it is important to motivate participation while at the same time the participatory sensing process should not disclose the private information of any participating party (the private data) or the community (patterns, distribution, etc.). Therefore it is essential to develop a mutual privacy preserving data mining technique to protect both the users and the community. In other words, we need a technique that can mutually protect the privacy of both the participants and the community, i.e., a technique that allows the data analyst (the social application server) to extract information about the community without accessing any user?s private data while no participatory participant can obtain any information about other participants and the community.

However, existing privacy-preserving techniques either focus on protecting the privacy of one single side only, namely the participating users, or leak intermediate results during community learning to potential privacy attackers, or cannot resist collusion attacks. For example, the collaborating participants could iden- tify the candidate clusters within each iteration of the k-means clustering in [4]. Exposing such intermediate information or the final community characteristics data can possibly put individual?s privacy at risk, or cause panic and extreme actions among the participants in the community.

In this paper, we propose a mutual privacy preserving clus- tering scheme based on a well-known data mining method, the k-means algorithm [5], [6], which groups similar entities into clusters with the goal of minimizing intra-group distance and maximizing inter-group distance. Specifically, k-means clustering is an iterative algorithm with each iteration consisting of two steps: assigning each participant to the nearest cluster, and updating the center of each cluster. The iteration terminates in a fixed number    1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 2  of rounds or until the change of the cluster centers meets a given threshold [6].

Our main contributions can be summarized as follows:  ? We propose two privacy-preserving algorithms called at each iteration of the k-means clustering. The first one is employed by each participant to find the nearest cluster and the second one updates cluster centers. Security and privacy analysis demonstrates that our k-means clustering scheme can resist collusion attacks.

? The proposed algorithms enable mutual privacy protection in clustering not only via keeping individuals? information private, but also by restraining the leakage of any cluster center information to the participants and preventing each participant from figuring out other members of the cluster, which is different from traditional approaches [7].

? To our best knowledge, this is the first mutual priva- cy preserving and collusion-resistant k-means clustering scheme, and we believe that its basic idea can be general- ized to other iterative data mining algorithms for privacy protection.

? We carry out an extensive experimental study to validate our design. The results indicate that our privacy-preserving k-means clustering scheme is effective in clustering, and can provide mutual privacy protection.

The rest of the paper is organized as follows. Section 2 introduces the most related existing work on privacy-preserving k-means clustering. Section 3 presents the preliminary knowledge about k-means clustering and introduces the assumptions adopted by this paper. Our privacy-preserving k-means clustering algo- rithm is detailed in Section 4, and its corresponding privacy and cost analyses are carried out in Section 5. Experimental studies are reported in Section 6. We conclude this paper with a future research discussion in Section 7.

2 RELATED WORK Many existing privacy-preserving k-means clustering algorithms have been developed for different data distributions such as (horizontally partitioning data, vertically partitioning data, and arbitrarily partitioned data [4]) to protect the privacy of the users and the communities in a social participatory sensing application.

In this subsection, we mainly summarize the state-of-the-art of existing privacy-preserving k-means clustering algorithms.

In a vertically partitioned data distribution, the data of an entity is distributed to different participants in such a way that each party obtains a portion of the attributes owned by the entity. Hence there is a need for the participating participants to disclose their private data during the computation of k-means clustering. The intermediate assignments of entities to their nearest clusters also pose a threat to privacy. The first privacy-preserving k-means algorithm for vertically partitioned data was proposed by Vaidya in [7], in which the distance between participants is securely computed based on the secure permutation scheme proposed by Du [8] and homomorphic encryption. However, this protocol requires the existence of three non-colluding participants, an assumption that cannot be easily guaranteed in many real- life applications. In [9], additive secret sharing [10], [11] was adopted as a cryptographic primitive to implement a secure multi- party computation protocol, so as to realize privacy preserving clustering. To avoid the requirement of non-colluding participants,  Samet [12] proposed an algorithm to compute the sum of distances by adopting the secure sum scheme. There also exists other research [13], [14] on vertically partitioned data distribution; but none of them can protect the number of entities in a cluster from being leaked. This problem is solved by our scheme proposed in this paper.

In a horizontally partitioned data distribution, each entity is owned by a single party; thus the distance to cluster centers can be computed without violating privacy. However, privacy disclosure can happen during the computation of intermediate cluster centers.

Inan et al. [15] introduced a protocol for securing multi-party computation of a dissimilarity matrix over horizontally partitioned data, which constructs the dissimilarity matrix of objects from different sites in a privacy preserving manner. Jha et al. [16] p- resented a privacy-preserving k-means clustering algorithm based on oblivious polynomial evaluation and homomorphic encryption.

This approach can be applied in a multi-party environment, but the intermediate centers are often exposed to potential privacy attacks.

Our privacy preserving k-means clustering proposed in this paper can be applied to horizontally partitioned data and to prevent the disclosure of any additional information about intermediate centers and the cluster label of each entity.

Arbitrarily partitioned data was first considered in [4], in which a privacy preserving k-means clustering was proposed for arbitrarily partitioned data distributed between two participants.

The idea is to split all the intermediate results into random partitions. Yu et al. [17] applied the concept of parallel computing to tackle the privacy-preserving multi-party k-means clustering problem, which can speed up the clustering process. This approach was designed for both vertically partitioned and horizontally partitioned data. Bunn et al. [18] proposed a two-party k-means clustering protocol based on homomorphic encryption to guaran- tee privacy in arbitrarily partitioned data, in which the protocol does not disclose the intermediate results and cluster assignments.

Moreover, they designed a secure protocol for randomly selecting k initial centers. However, if the protocol is extended to multi- party k-means clustering, it may bring new security and privacy risks. For example, the protocol cannot resist collusion attacks when more than n2 participants have collusion activities, where there are n participants.

There exist many other research on privacy-preserving k- means clustering. Rao et al. [19] described a two-party k-means clustering protocol, which can be implemented by utilizing any semantically secure homomorphic encryption scheme. Liu et al.

[20] presented an outsourced k-means clustering, which proposed an encryption algorithm to generate trapdoor information; but this scheme only protects one party?s privacy. Lin [21] applied the linear transformation and the random perturbation of the kernel matrix for privacy preservation in k-means clustering. Patel et al.

[22] adopted secret sharing and the code-based zero-knowledge identification scheme to construct a distributed privacy-preserving k-means clustering scheme under the malicious adversarial model, in contrast with the mainstream research that assumes the semi- honest adversarial model. In [23], an overview on existing privacy preserving k-means clustering algorithm based on secure multi- party computation was provided. To ensure I/O efficiency, [24] and [25] proposed a privacy-preserving version of the simple de- terministic algorithm Recluster; but the cluster centers are exposed to both participants in the protocol. Erkin et al. [26] distributed trust among a number of helper users instead of relying on a single party to obtain k-means clustering without leaking the clusters?    1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 3  privacy; but this approach requires a strong assumption of non- colluding activities among the participants. Samanthula et al. [19] proposed a privacy-preserving distributed clustering mechanism via outsourcing multi-user k-means clustering to cloud servers; unfortunately this scheme still cannot resist collusion attacks.

In summary, existing privacy preserving clustering solutions cannot provide mutual privacy protection as either the private data of the participants or the (intermediate) cluster information may be disclosed; moreover, most of them cannot resist collusion attacks.

In this paper, we propose a robust mutual privacy preserving k- means clustering algorithm that can preserve the privacy of the participating participants as well as the intermediate results of the cluster centers while resisting collusion attacks. Our research was motivated by social participatory sensing applications where the community information should be kept confidential since otherwise it may result in panic or extreme actions among the com- munity members, and the personal data of the social participants should be kept private as regular community members usually do not want to disclose their private information; meanwhile, such applications are vulnerable to collusion attacks.

3 PRELIMINARIES AND ASSUMPTIONS For better elaboration, the notations used in this paper and their semantic meanings are presented in Table 1.

TABLE 1 The Notations and Their Semantic Meanings  Notations means Ui The ith cluster, 1 ? i ? k uj The jth cluster center p1, q1 Two prime integers E(?) Encryption operation D(?) Decryption operation PU Public key PR Private key  3.1 The k-Means Clustering Algorithm The process of k-means clustering is based on (1) and (2). Assume that there are n participants with each participant ai holding a q- dimensional sample data ai. Suppose that the participants need to be grouped into k clusters U1, ..., Uk, with the center of the j-th cluster denoted by uj. Initially, each cluster center is arbitrarily and randomly assigned. Note that cluster centers can also be initialized with the method proposed in [27]. A sample data ai belongs to a cluster Uj if the center uj is the closest among all centers to ai according to (1), where uj is the mean of the samples in Uj computed from (2). There are many criterions to measure the distance between a sample and the related cluster center. In this paper, we adopt the Euclidean distance as our criterion. At each iteration, the k-means algorithm re-assigns the sample data to their nearest centers following (1) and re-computes the cluster centers u1, ...,uk according to (2). The iteration terminates when there is no or little change in the cluster centers.

ci := argmin j ||ai ? uj||2, (1)  uj =  ?n i=1 I{ci = j}ai?n i=1 I{ci = j}  (2)  where 1 ? j ? k, 1 ? i ? n, and I{ci = j} is the index function that equals 1 if ci = j and 0 otherwise.

3.2 Homomorphic Encryption Homomorphic encryption [28] allows certain computation over encrypted data. Paillier cryptosystem [29] is a popular Homo- morphic encryption scheme that provides fast encryption and decryption, which is a probabilistic asymmetric algorithm based on the decisional composite residuosity problem. It is adopted by the secure scalar product, which has been widely used in privacy preserving data mining. The Paillier cryptosystem is briefly intro- duced as follows:  ? Key generation: An entity selects two large primes p1 and q1 and computes N = p1q1 and ? = lcm(p1 ? 1, q1 ? 1), where lcm stands for the least common mul- tiple. It then chooses an integer g such that gcd(L(g?  mod N2), N) = 1, where gcd stands for the greatest common divisor, g ? Z?N , and L(x) = x?1N . The public key and private key are respectively {N, g} and {?}.

? Encryption: Let m ? Z?N be a plaintext and r ? Z?N be a random number. The ciphertext of m is computed by  E(m) = gm ? rN mod N2, (3)  where E() denotes the encryption operation using public key {N, g}.

? Decryption: For the ciphertext E(m), the corresponding plaintext can be computed by  D(E(m)) = L(E(m)? mod N2)  L(g? mod N2) mod N, (4)  where D() denotes the decryption operation using private key {?}.

? Homomorphic : The Paillier cryptosystem is additively homomorphic as it satisfies the following conditions: Giv- en {m1,m2} ? Z?N , we have:  E(m1) ? E(m2) = E(m1 +m2), (5)  Furthermore, given E(m) and a constant c, E(c ?m) can be computed by:  E(c ?m) = E(m)c. (6)  3.3 Clustering Model We consider a clustering problem consisting of n participants a1, ..., an. Each participant ai holds its own private information ai, a q-dimensional vector describing its features or activities.

As shown in Fig. 1, there also exists a data analyst A who is responsible for grouping those participants with similar proper- ties/activities into one cluster. However, due to privacy concerns, the data analyst cannot access the private information of any participant.

Our goal is to build mutual privacy protection between the data analyst A and the participants a1, .., an when computing the k centers of the private data a1,a2, ? ? ? ,an. Neither of A and the participants should deduce any private information about the other side except those being published as a result of the k-means clustering scheme. In other words, the data analyst A cannot learn any private information owned by the participants since a compromised A may potentially sell the data to others.

Similarly, malicious participants should learn nothing about the data analystA?s data (the centers) and should not be able to disrupt A?s computation.

1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 4  Fig. 1. Clustering Model  We assume that:  ? any pair of the participants ai and aj share a unique pairwise key;  ? the data analyst A shares a unique pairwise key with each participant ai;  ? the data analyst A generates a public and private key pair (PU,PR) that can be used for additive homomorphic encryption, and distributes its public key PU to all the participants.

Messages from each participant ai to A need to be encrypted with PU . Let m denote the plaintext, and m? the corresponding ciphertext. We have m? = E(PU,m) and m = D(PR,m?).

Due to homomorphic property, we have  E(PU,m1) ? E(PU,m2) = E(PU,m1 +m2) (7)  4 PRIVACY PRESERVING K-MEANS CLUSTERING In this section, we present our privacy preserving k-means cluster- ing algorithm. As mentioned earlier, there exist two steps within each iteration: assigning each participant to its closest center, and computing the new center of each cluster in a secure way.

4.1 Stage 1: Assign Participants to Their Nearest Cen- ters This step assigns participants to their nearest centers within an iteration. The cluster centers (u1, ...,uk) are initialized and updated by the data analyst A.

Let Dij be the distance between the i-th participant ai and the center of the j-th cluster Uj , i.e.,  Dij = (ai ? uj)T (ai ? uj)  Now consider ai and its distances to the clusters Uj and Uj? . We have  Dij ?Dij? = (ai ? uj)T (ai ? uj)? (ai ? uj?)T (ai ? uj?) = aTi ai ? 2aTi uj + uTj uj ? (aTi ai ? 2aTi uj? + uTj?uj?) = uTj uj ? uTj?uj? ? 2aTi (uj ? uj?) (8)  Remark 1: If A can send uTj uj ?uTj?uj? and uj ?uj? to ai, then ai can calculate Dij?Dij? according to (8). If Dij?Dij? < 0, ai is closer to uj ; otherwise, ai is closer to uj? . This process can be repeated for k?1 times for ai to identify the closest cluster center among all the k clusters.

However, if the data analyst A sends all the {uj ? uj?}?s directly to a participant ai, then ai can collect u1 ? u2, u2 ?  u3, ? ? ? , uk?1 ? uk, and thus the cluster centers can be leaked.

Therefore, A should send randomly perturbed values of {uj ? uj?}, as shown below, where the ?(i,j) > 0 values are random numbers:?????????????????????????????????????????????????  ?(i,1)[(u1 Tu1)? (u2Tu2)], ?(i,1)(u1 ? u2)  ?(i,2)[(u1 Tu1)? (u3Tu3)], ?(i,2)(u1 ? u3)  ? ? ? , ?(i,k?1)[(u1  Tu1)? (ukTuk)], ?(i,k?1)(u1 ? uk) ?(i,k)[(u2  Tu2)? (u3Tu3)], ?(i,k)(u2 ? u3) ?(i,k+1)[(u2  Tu2)? (u4Tu4)], ?(i,k+1)(u2 ? u4) ? ? ? , ?(i,2k?3)[(u2  Tu2)? (ukTuk)], ?(i,k+1)(u2 ? uk) ? ? ? , ? ? ? , ? (i, k(k?1)2 )  [(uk?1 Tuk?1)? (ukTuk)],  ? (i, k(k?1)2 )  (uk?1 ? uk)  (9)  Remark 2: Since ?(i,j) > 0, the randomized results have no influence on determining the sign of Dij ? Dij? , as well as the closeness between the participant ai and the clusters.

After obtaining this information, each participant ai can i- dentify the nearest center based on its own private data ai.

The procedure is stated as follows. The participant ai first computes the value S(i,1) = ?(i,1)[(u1Tu1) ? (u2Tu2)] ? 2?(i,1)ai  T [(u1 ? u2)], which is related to the received infor- mation ?(i,1)[(u1Tu1) ? (u2Tu2)] and ?(i,1)(u1 ? u2). If S(i,1) < 0, ai is closer to u1, and it can choose ?(i,2)[(u1Tu1)? (u3  Tu3)] and ?(i,2)(u1 ? u3) to calculate the value of S(i,2) = ?(i,2)[(u1  Tu1)? (u3Tu3)]?2?(i,2)aiT [(u1?u3)]; otherwise, ai is closer to u2, and it can compute the value S(i,k) = ?(i,k)[(u2  Tu2) ? (u3Tu3)] ? 2?(i,k)aiT [(u2 ? u3)] based on the received information ?(i,k)[(u2Tu2) ? (u3Tu3)] and ?(i,k)(u2 ? u3). This process repeats until the nearest center is figured out. Then ai informs the data analyst A which cluster (the one with the nearest center) it belongs to. Note that when this procedure terminates, A only knows which cluster ai belongs to; it has no knowledge about ai?s private information ai.

The above process is summarized in Algorithm 1.

Note that each ai only needs k rows of the information  included in (9) to identify its nearest cluster. But we choose to let the data analyst A deliver all information included in (9) to each participant ai for privacy protection as an interactive procedure asking only the required cluster center information may disclose the privacy of both ai and the cluster centers.

4.2 Stage 2: Update the Cluster Centers After each participant identifies its closest cluster with Algorithm 1 and informs the data analyst A, A should re-evaluate the cluster center uj for each clusterUj . Assume that there are nj participants assigned to cluster Uj ; then n1 +n2 + ? ? ?+nk = n. After Stage 1, A can get the cluster membership list shown in Table 2, where s(j,l) ? {a1, ..., an} is a participant indicating that this participant is the l-th participant in the j-th cluster, where 1 ? l ? nk and 1 ? j ? k.

Next, we present an additive homomorphic encryption scheme to re-compute the cluster centers, in order to ensure that only the data analyst knows the intermediate cluster centers, and the participants are kept blind to such private information. While in    1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 5  Algorithm 1 Identifying the nearest cluster for a participant ai.

1: Initialize: There are n participants and one data analyst  A. Each participant ai owns a q-dimensional private data ai = (ai1, ? ? ? , aiq). There are k cluster centers {u1, ? ? ? ,uk}, with their initial values randomly deter- mined by A.

2: ? = 1 3: for j = 1 to k ? 1 4: ? = j + 1; 5: for ? = ? to k 6: A sends to ai: ?(i,?)[ujTuj ? u?Tu?] and ?(i,?)(uj ?  u?); 7: ? = ? + 1 8: endfor 9: endfor  10: ai identifies the nearest center based on the received data and its own private data as follows:  11: ai first compares its distance to u1 and u2 by computing S(i,1) = ?(i,1)[(u1  Tu1)?(u2Tu2)]?2?(i,1)aiT [(u1? u2)];  12: If S(i,1) < 0, ai is closer to u1, and then ai compares the distances to u1 and u3 using the related received data and its own private data as in Step 11;  13: else if ai is closer to u2, then ai compares its distances to u2 and u3 as in Step 11;  14: EndIf 15: ai repeats Steps 11 to 14 to identify the nearest cluster.

16: ai notifies A which cluster it belongs to.

TABLE 2 participant Label  `````````?Cluster participants participant Label  U1 (n1 participants) s(1,1), s(1,2), ? ? ? , s(1,n1) U2 (n2 participants) s(2,1), s(2,2), ? ? ? , s(2,n2) ...

...

Uk (nk participants) s(k,1), s(k,2), ? ? ? , s(k,nk)  many existing privacy-preserving k-means clustering algorithms such as [7], [16] and [25] this information cannot be protected.

According to (2), a cluster center is the mean of the private data of the participants that belong to that cluster. From Table 2, one can see that the data analyst knows nj , the number of participants in cluster Uj . Therefore we need to compute the sum of the private data of the participants belonging toUj . Consider the cluster Uj and its member participants s(j,1), s(j,2), ? ? ? , s(j,nj).

First, the data analyst A randomly generates nj q-dimensional vectors V(j,1),V(j,2), ? ? ? ,V(j,nj) satisfying  V(j,1) +V(j,2) + ? ? ?+V(j,nj) = 0 (10)  Then A securely sends {V(j,l),+} to each participant s(j,l) ? Uj encrypted with their pairwise key, where ?+? denotes that s(j,l) belongs to the cluster currently under consideration. Meanwhile, A generates another (n ? nj) q-dimensional vectors R(j?,l) for  each s(j?,l) /? Uj satisfying:  R(1,1) +R(1,2) + ? ? ?+R(1,n1) + ? ? ? +R(j?1,1) +R(j?1,2) + ? ? ?+R(j?1,nj?1) +R(j+1,1) +R(j+1,2) + ? ? ?+R(j+1,nj+1)  + ? ? ?+R(k,1) + ? ? ?+R(k,nk) = 0  (11)  Then A securely sends {R(j?,l),?} to each s(j?,l) /? Uj .

Next, all of the n participants should compute their encrypted  data. Recall that each participant owns a q-dimensional private vector. For each s(j,l) ? Uj , s(j,l) should encrypt the received vector V(j,l) and its private vector a(j,l) after receiving the mes- sage {V(j,l),+} with a label ?+?. The encryption is computed with the public key PU of the homomorphic encryption system.

Then s(j,l) obtains:  Yj,l = E(PU,a(j,l) +V(j,l)). (12)  While for each s(j?,l) /? Uj , s(j?,l) only encrypts the received vector upon receiving the message {R(j?,l),?} with a label ???.

That is, s(j?,l) gets:  Yj?,l = E(PU,R(j?,l)). (13)  After completing the encryption operation, each participant should share part of its ciphertext with others. This can be done as follows. Each participant s(p,q) first randomly divides its ciphertext Yp,q (computed either from (12) or from (13)) into m components Y 1p,q , Y  p,q , ? ? ? , Y mp,q , where 1 ? m ? n, satisfying  Y 1p,q ? Y 2p,q ? ? ? ? ? Y mp,q = Yp,q.

Note that s(p,q) must keep one of the m components to itself.

Then s(p,q) randomly selects m ? 1 participants in the network and sends one component to each chosen participant through the secure channel protected by their pairwise keys.

Note that each participant should complete the above slicing and distributing process on its ciphertext computed from (12) or (13). Meanwhile, each participant may receive components (slices of ciphertexts) from other participants. Then each participant applies the homomorphic operation on all the received cipher components as well as the slice kept to itself by multiplying them together to get r(p,q), which should be sent to the data analyst A after the computation is over.

Lastly, A multiplies all the received data, and obtains the following result according to (7), (10), and (11):  Yj,1 ? Yj,2 ? ? ? ?Yj,nj ? ? ? ?Yj?,l ? ? ? ? = E(PU,a(j,1) + a(j,2) + ? ? ?+ a(j,nj)+  V(j,1) +V(j,2) + ? ? ?+V(j,nj) + ? ? ?+R(j?,l) + ? ? ? ) = E(PU,a(j,1) + a(j,2) + ? ? ?+ a(j,nj))  (14) Then A gets a(j,1) + a(j,2) + ? ? ? + a(j,nj) by decrypting with its private key PR, and finally computes the cluster center uj by dividing it by nj . The whole procedure is summarized by Algorithm 2.

An example detailing the procedure is given in Fig. 2, which illustrates how to compute the center of the first cluster whose members include the circled participants 1, 2, 3.

Following the above process, the data analyst can compute the new center for each cluster. The advantage of our algorithm is the ability to ensure mutual privacy preservation.

? The data analyst can obtain the sum of the data in a cluster without accessing the private information of each participant.

1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 6  1 2 3  ??,? = ?(?(?,?) + ?(?,?)),  Data Analyst  1 2 3 4  ??,? = ?(?(?,?)), ??,? = ?(?(?,?)), ??,? = ?(?(?,?) + ?(?,?),  ??,? = ?(?(?,?) + ?(?,?)), ??,? = ?(?(?,?)), ??,? = ?(?(?,?))  (a) The data analyst sends random data to each participant, satisfy- ing V(1,1) + V(1,2) + V(1,3) = 0, R(2,1) + R(2,2) + R(2,3) + R(2,4) = 0.

2 3 4  ?1,1  ?1,1 ?  ?1,1 ?  ?1,1 ?  ?2,1 ?  ?2,1 ?  ?2,1 ?  ?1,2 ?  ?1,2 ?  ?1,3 ?  ?1,3 ?  ?1,3 ?  ?1,3 ?  ?2,2 ?  ?2,2 ?  ?2,2 ?  ?1,2 ?  ?2,3  ? ?2,3 ?  ?2,3 ?  ?2,3 ?  ?1,1 ?  ?2,4 ?  ?2,4 ?  ?2,4 ?  (b) Each participant slices its encrypted data, keeps one piece to itself, and sends the remaining to randomly chosen participants.

2 3 4  ?? = ??,? ? ? ??,?  ?  ?? = ??,? ? ? ??,?  ? ? ??,? ? ? ??,?  ?  ?? = ??,? ? ? ??,?  ? ? ??,? ? ? ??,?  ?  ?? = ??,? ? ? ??,?  ? ? ??,? ? ? ??,?  ?  ?? = ??,? ? ? ??,?  ? ? ??,? ? ? ??,?  ? ?? = ??,?  ? ? ??,? ? ? ??,?  ? ? ??,? ?  ?? = ??,? ? ? ??,?  ? ? ??,? ?  (c) Each the participant multiplies its received data and the compo- nent held by itself.

1 2 3  ??  Data Analyst  1 2 3 4  ?? ?? ?? ?? ?? ??  (d) All the participants send their results from Fig. 2(c) to the data analyst, who can compute the new cluster centers.

Fig. 2. The process of computing the new cluster centers within one iteration.

? The participants know nothing about each other. Particu- larly, they do not know who else are in the same cluster.

? The participants know nothing about the intermediate clus- ter centers. This information is protected by the random values (the ? values) known only by the data analyst.

4.3 Stopping Criterion Stage 1 and Stage 2 should be repeated iteratively until little or no change occurs in the clustering process. At the end of  Algorithm 2 Computing the new center of cluster Uj .

1: Initial State: Cluster Uj has the member participants s(j,1),  s(j,2), ? ? ? , s(j,nj), with a(j,l) being the private data of member s(j,l).

2: The data analyst A generates the random V values according to (10) and the random R values according to (11).

3: The data analyst A sends (V(j,l),+) to each s(j,l)?Uj , and sends R(j?,l) to each participant s(j?,l) /? Uj .

4: Each member computes its encrypted data with (12) if it belongs to cluster Uj , or with (13) otherwise.

5: Each member slices the ciphertext into m components, and sends m ? 1 components to other participants randomly selected in the network.

6: Each participant multiplies the encrypted component it has kept for itself and all the received cipher components to compute r.

7: Each participant sends r to the data analyst A.

8: The data analyst multiplies all the received data to get a(j,1)+  a(j,2) + ? ? ?+ a(j,nj) via decryption.

9: The new center of the cluster Uj can be obtained by a(j,1) +  a(j,2) + ? ? ?+ a(j,nj)/nj .

each iteration, the data analyst needs to compare the newly obtained cluster centers with those from the previous iteration.

If they are ?close enough? according to an application-specific parameter (e.g., the total distance change of the clusters and their corresponding participants is no more than a threshold between two iterations), the iteration process can terminate.

5 PRIVACY AND EFFICIENCY ANALYSIS  In this section, we discuss the ability of our scheme to ensure privacy preservation against potential passive and active attacks.

Before delving into details, we first define our goals in privacy protection. In our consideration, each participant should not get the following information:  ? cluster centers; ? other participants in the same cluster; ? the private data of the other participants.

The data analyst A knows where are the cluster centers, but it cannot access any private information of any participant. In other words, A knows that the participant s(j,l) belongs to the j-th cluster, but it does not know the private data a(j,l) of s(j,l) nor the distance from s(j,l) to the associated cluster center uj.

5.1 Privacy Analysis on the Stage of Assigning Partici- pants to Their Nearest Clusters  In Stage 1, each participant only notifies A which cluster is the closest; therefore the data analyst knows nothing about the private information of the participants. Now considering the worst case when n ? 1 participants collude with each other to detect the cluster centers. Without loss of generality, we assume that these n ? 1 participants are denoted by a1, a2, ? ? ? , an?1 and they combine their information to compute the cluster center u1. All these colluding n ? 1 participants can construct the following    1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 7  equations using the received data from the data analyst A and their own data:???????????????????????????????????????????????????????????????????????  ?(1,1)(u1 Tu1 ? u2Tu2)? 2?(1,1)a1T (u1 ? u2) = S(1,1)  ?(2,1)(u1 Tu1 ? u2Tu2)? 2?(2,1)a2T (u1 ? u2) = S(2,1)  ?(3,1)(u1 Tu1 ? u2Tu2)? 2?(3,1)a3T (u1 ? u2) = S(3,1)  ? ? ? , ?(n?1,1)(u1  Tu1 ? u2Tu2)? 2?(n?1,1)an?1T (u1 ? u2) = S(n?1,1) ?(1,2)(u1  Tu1 ? u3Tu3)? 2?(1,2)a1T (u1 ? u3) = S(1,2) ?(2,2)(u1  Tu1 ? u3Tu3)? 2?(2,2)a2T (u1 ? u3) = S(2,2) ?(3,2)(u1  Tu1 ? u3Tu3)? 2?(3,2)a3T (u1 ? u3) = S(3,2) ? ? ? , ?(n?1,2)(u1  Tu1 ? u3Tu3)? 2?(n?1,2)an?1T (u1 ? u3) = S(n?1,2) ? ? ? , ?(1,k?1)(u1  Tu1 ? ukTuk)? 2?(1,k?1)a1T (u1 ? uk) = S(1,k?1) ?(2,k?1)(u1  Tu1 ? ukTuk)? 2?(2,k?1)a2T (u1 ? uk) = S(2,k?1) ?(3,k?1)(u1  Tu1 ? ukTuk)? 2?(3,k?1)a3T (u1 ? uk) = S(3,k?1) ? ? ? , ?(n?1,k?1)(u1  Tu1 ? ukTuk)? 2?(n?1,k?1)an?1T (u1 ? uk) = S(n?1,k?1)  (15) For the participants, the coefficients {?(1,1), ?(2,1), ..., ?(n?1,1), ?(1,2), ?(2,2), ..., ?(n?1,2), ......, ?(1,k?1), ?(2,k?1), ..., ?(n?1,k?1)} and {u1,u2,u3, ....,uk} are unknowns in (15), which come from the data analyst A, and the cluster center is a q-dimensional vector. Thus there are (k ? 1)(n? 1) + kq unknown parameters in (15), but there exist only (k ? 1)(n ? 1) equations; therefore the participants cannot figure out the cluster u1. Similarly, the colluding participants cannot find out other cluster centers {u2,u3...,uk}. Actually, when all the available information from the n ? 1 colluding participants are combined, (n ? 1) ? k(k?1)2 equations can be obtained but there are (n ? 1) ? k(k?1)2 + kq number of unknowns, which again proves that it is impossible for the participants to recover the cluster centers {u1,u2,u3...,uk}.

Thus we conclude that our scheme can resist the collusion attacks launched by any number of participants without leaking any information about the cluster centers.

Cost Analysis on Stage 1: We next analyze the communication and computation overheads of our algorithm in Stage 1. It should be noted that both com- munication and computation overheads of the k-means clustering algorithm depend on the size of the data set. The number of iterations being conducted to meet the stopping criterion depends on the dataset size and the initial cluster centers. A clustering algo- rithm targeting real world applications should not incur too much communication and computation overheads. A simple analysis on the complexity of Algorithm 1 reveals the following results: In Stage 1, each participant needs to do multiplication at the complexity of O(q(k ? 1)) to find the nearest cluster. For each participant, the communication complexity is O(kq(k ? 1) + 1).

The total communication complexity is O(kq(k ? 1)n+ n)).

5.2 Privacy Analysis on the Stage of Computing New Cluster Centers In Algorithm 2, a public-key based additive homomorphic en- cryption scheme is adopted to compute the cluster centers. The encrypted data Yi = E(PU,ai +Vi) or Yi = E(PU,Ri) held  by the participant ai is semantically secure, since only the data analyst A knows the private key PR. As Yi is sliced, shared, and finally sent to A, the process is secure for both ai and A. The data Yi is mixed with a random vector Vi only known by A and secured by the pubic-key cryptosystem; thus Yi is secured against other participants. As the data that A obtains has already been mixed and operated by the participatory participants, A knows nothing about the private data of ai.

At each round of Algorithm 2, the data analyst A sends a random vector to each participant. Then a participant ai slices its encrypted data Yi into m components and sends m ? 1 components to m ? 1 randomly selected participants. Participant ai reserves the remaining component to itself. As a result, no one knows which participants are in the same cluster, and no one knows who are selected to receive the slices. If an attacker wants to acquire the private data held by ai, it must break all the m? 1 outgoing slices and other incoming slices. Since 1 ? m ? n, the maximum number of incoming slices for a participant is n ? 1, and the maximum number of outgoing slices is n ? 1; and the private data of a participant may be disclosed only if an attacker has the ability to break all the 2n ? 2 slices in this case. Let p denote the possibility that a single slice is leaked to an attacker.

Then the possibility that the private slices held by the participant ai may be disclosed is:  Pi = p m?1.

Cost Analysis on Stage 2: In Stage 2, some computation is done by the data analyst, while the participants need to perform very little calculation. Consider the computational complexity of Algorithm 2. Each participant does one public-key encryption in step 3, then takes O(n?q) time for each of step 4 and 5. The data analyst conducts the public-key decryption and takes O(n?q) time on the multiplication operation in step 7, and takes O(q) time in step 8.

Now we consider the communication complexity of Algorithm 2. We observe that step 2 takes O(n ? q) time, step 4 takes O(n2 ? q) time, and step 6 takes O(n ? q) time. To update all the cluster centers, the data analyst needs to execute the corresponding steps in Algorithm 2 for k times. Therefore the communication complexity for updating all cluster centers is O(n2qk).

5.3 Security Against Collusion Attacks Our algorithm makes no assumption on non-colluding partici- pants. In the following, we will show that our algorithm can resist against collusion attacks. We assume that a semi-honest data analyst and participants follow the proposed protocol.

5.3.1 Collusion Between the Data Analyst and Participants Our method ensures that a participant can hide its private data safely, even if the data analyst is an adversary. In Algorithm 2, the data analyst A receives r1, r2, ? ? ? , rn from the n participants.

Although A can decrypt the data ri, no further information can be derived since ri is the result of the sliced components mixed with other random data.

Consider the scenario when the data analyst A colludes with one or more participants. At maximum, there can be as many as n ? 1 participants colluding with A to deduce the private information of the remaining participant ai. We assume ai has sliced its encrypted data into m pieces, then m ? 1 of the m    1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 8  components will be taken by the n ? 1 colluded participants.

Although A knows the decryption key and the random vector held by ai, A cannot get ai?s private information since one of the m slices is reserved by ai. Thus the collusion alliance still cannot get ai, which illustrates that our algorithm is robust even in the worst case where there are as many as n?1 participants colluding with the data analyst. Therefore we conclude that our protocol can protect the privacy of each participant under the collusion of the data analyst and the participants.

5.3.2 Collusion Among the Participants We have argued that the data analyst can hide the cluster centers with a random vector in our algorithm in Section 5.1. According to the analysis in Section 5.1, even if there are n? 1 participants colluding together, they still cannot deduce any information about the cluster centers, because there exist (n ? 1) ? k(k?1)2 + kq unknowns for the cluster centers while there are only (n ? 1) ? k(k?1)  2 equations. Thus we claim that our algorithm can securely protect the data analyst?s privacy.

6 EXPERIMENTAL STUDY We use three datasets for the experiments. The first one is a health dataset that includes systolic pressure and heart rate. This data set is collected from 20 elderly people with high blood pressure and surveying 70 healthy students. The clustering results can help the subjects perceive their health conditions in their community.

The second dataset is about location [30], and users can figure out the population distribution in the vicinity from the results of our clustering algorithm. In the last experiment, we consider mobile users and select the Human Activity Recognition on Smart-phones [31] as the test dataset. This dataset contains mobile location data which describes the historical location of some mobile users belonging to a telecommunications operator. It records about 900 users? latitude and longitude data in several days. This dataset is important to reflect the spatial distribution of travel demands.

60 80 100 120 140 160 180         systolic pressure  he ar  t r at  e     Cluster 1 Cluster 2 Cluster 3 Cluster 4 Centroids  Fig. 3. Clustering results from our algorithm.

Fig. 3 shows our clustering results on the health data. If the clustering results indicate a very bad health condition in the neighborhood, then users may be alerted to start a healthy diet habit or look for health advisory, which can help promote a healthy life while preserving all users? privacy. Fig. 4 compares the cluster centers computed from our scheme and the classic k- means algorithm. The results show that our scheme can achieve  100 105 110 115 120 125 130 135 140            systolic pressure  h e  a rt  r a  te      cluster center of the non?privacy preserving algorithm  cluster center of the privacy preserving algorithm  Fig. 4. Comparison on the cluster centers computed from our algorithm and the general k-means algorithm.

TABLE 3 Evaluation on the cluster assignment in our algorithm.

cluster accuracy recall 1 99.89% 99.81% 2 99.92% 99.87% 3 99.91% 99.98% 4 99.97% 99.90%  almost the same accuracy while being able to preserve individual?s privacy. Table 3 shows the accuracy and recall of our scheme compared with the clustering results which are computed from the original private data. One can conclude that our privacy preserving clustering scheme can compute cluster centers with the same accuracy.

100 105 110 115 120 125 130 135            Longitude  L a ti tu  d e      Cluster 1  Cluster 2  Cluster 3  Cluster 4  Centroids  Fig. 5. Clustering distribution result without leaking each person?s loca- tion.

Fig. 5 shows our clustering results on the location data.

The results demonstrate that a user can be clustered with others in vicinity even though no location information is disclosed to each other. With our scheme, users can perceive the population distribution without leaking anyone?s location information. Fig.

6 indicates that our scheme can compute cluster centers at the same accuracy as the non-privacy preserving algorithm. Table 4    1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2695487, IEEE Transactions on Industrial Informatics  MUTUAL PRIVACY PRESERVING K-MEANS CLUSTERING IN SOCIAL PARTICIPATORY SENSING 9  100 105 110 115 120 125 130       Longitude  L a  ti tu  d e      cluster center of the non?privacy preserving algorithm  cluster center of the privacy preserving algorithm  Fig. 6. Cluster center comparison of our scheme with the general k- means algorithm.

TABLE 4 Cluster assignment evaluation of our scheme.

cluster accuracy recall 1 99.51% 99.18% 2 97.1% 99.8% 3 99.67% 98.82% 4 99.39% 99.71%  indicates our scheme can get the same accurate clustering results without disclosing private location information.

In our last experiment, we select the Human Activity Recog- nition on Smart-phones [31] as our test dataset. This data was collected from a group of 30 volunteers within an age bracket of 19-48 years. Each person carries a smart-phone with an embedded accelerometer and a gyroscope. The data contains 3- axial linear acceleration and 3-axial angular velocity. Each of the 7352 samples contains 561 features. A certain part of the samples reflect one particular type of activity. Participants do not want to disclose their activities or location information, but want to play with others participating in similar activities. Next we conduct experiments to show that our solution allows the mobile users to recognize the others participating in the same activity without leaking the private activity information.

We perform privacy preserving clustering on the test data to group people?s activities into several categories. Fig. 7 shows the clustering results from our scheme compared with the ground truth grouping.

One can conclude from Fig. 7 that our clustering solution can effectively group participants with similar activities in a secure way. The mobile users can easily find people who share the same interests without leaking anyone?s individual private data.

Table 5 presents a simple comparison study over the three  !htb TABLE 5  The comparisons among [7], [13], [20] and our scheme.

Properties [7] [13] [20] Our scheme Collusion attack resistance No No No Yes Individual?s information protection Yes Yes Yes Yes Cluster center protection No No No Yes Intermediate result leak Yes Yes Yes No  Fig. 7. Result comparison between our experiment result and users? ground truth action.

schemes proposed in [32], [13], and [20]. From Table 5, one can notice the significant advantages of our scheme compared to the other three schemes in terms of privacy preservation and collusion attack resistance.

7 CONCLUSION AND FUTURE RESEARCH In this paper we propose an efficient privacy-preserving clus- tering scheme that ensures no leak of any intermediate result.

Our scheme can securely compute the nearest cluster center for each participant without disclosing any cluster information to the participants. In addition, our scheme can update the cluster centers at each iteration without exposing any participants? information to the data analyst.

Our scheme can achieve more privacy preservation goals when compared to other existing works. No participant can obtain any private information of other participants or the cluster centers.

Furthermore, the cluster centers can be computed without leak- ing the cluster label of each participant. And participants have no knowledge about the other participants in the same cluster.

Through an extensive security analysis, we conclude that even in the existence of collusion participants, no private information of the remaining participants is released. Finally, we conclude that our scheme does not incur much communication and computation overheads on the participants.

In our future research, we shall consider the mutual privacy- protection of other clustering algorithms such as the Gaussian Mixture Modeling for social participatory sensing. On the other hand, we will investigate how to figure out the relative position of a participant in a community when the community model is available while protecting the privacy of both the participant and the community.

ACKNOWLEDGEMENT The authors would like to thank all the reviewers for their helpful comments. This research was partially supported by the National Science Foundation of the US under grants CNS-1318872, CCF- 1442642 and IIS-1343976, and the National Natural Science Foun- dation of China under grants 61332004, 61672119, 61672321, and 61373027.

