AN EQUIVALENCE-CLASS-BASED ALGORITHM FOR THE MAXIMAL  NUMBER OF CANDIDATE ITEMSETS

Abstract: Mining association rules is one of the most important  problems in the field of data mining. To devise an algorithm that can reduce the number of database scans and without taking the risk of getting a combinatorial explosion of the number of candidate itemsets, we must study what is the maximal number of candidate itemsets that can be generated.

In this paper, the theory of itemset equivalence class is proposed. The property of itemset equivalence class is explored and some useful lemmas are presented. Based on the foregoing theory and Apriori property, we derive some theorems about the maximal number of candidate itemsets.

Based on these theorems, we devise an algorithm EC for calculating the maximal number of candidate itemsets.

Furthermore, the performance study shows that algorithm EC is more accurate than algorithm KK and the cost for computing the maximal number is negligible compared to the cost of the complete algorithm for association rules.

Keywords:  Knowledge Discovery; Databases Data Mining; Association Rules; Candidate Itemsets;  1 Introduction  Among the various data mining problems, mining of association rules is an important one. This problem has been studied substantially with many interesting and efficient data mining algorithms reported. Apriori [ 11 is the most famous algorithm for association rules. Many algorithms for association rules are the improvements on Apriori. Algorithm DHP [2] and IHP [3] use hash tables to prune some of the candidate itemsets and use transaction trimming and pruning method to trim the transaction database.. But Apriori, DHP and IHP tend to suffer from the inherent problem of need multiple scans of database.

Several algorithms try to reduce the number of database scans. For example, FP-tree [4] proposes a novel frequent pattern tree structure and develops an efficient FP-tree based mining method, which only needs to scan the database once but it is only suitable for small databases.

The Partition algorithm [5] obtains the support of the  candidate itemsets by intersecting the TID-lists of the individual items in the candidate itemset. It also only needs to scan the database once. However, a major problem is that the size of the TID-lists would be too large to maintain when the number of the transactions in the database is very large. AprioriHybrid [6] uses Apriori in the initial iterations and switches to AprioriTid when the size of the encoding of the candidate itemsets is small enough to fit in main memory and there are fewer candidate itemsets in the current level than in the previous pass. However, the decision of switch to AprioriTid may be premature because the number of new candidate itemsets in the afterwards iterations can be growing exponentially. FUP2 [7] and SWF [SI are incremental updating techniques for maintaining the association rules discovered when the database is updated. However, FUP2 tend to suffer from the inherent problem of the need of multiple database scans.

SWF is a sliding-window filtering algorithm for incremental mining, which partitions the transactions database into several partitions and only needs to scan the updated database once. But it will incur the huge size of the number of candidate itemsets.

From the describing above, we consider that the incremental algorithm, which can reduce the number of database cans, and without taking the risk of getting a combinatorial explosion of the number of candidate itemsets, may possess superior performance. So the following combinatorial problem must be studied: Given the current set of fiequent itemsets and at a certain iteration of the algorithm, what is the maximal number of candidate itemsets that can be generated in the passes yet to come? As far as we know, KK algorithm [9] is the one and only algorithm to address this problem, which is derived from the Kruskal-katona theorem [lo]. The contribution of KK is to solve this problem by providing a combinatorial upper bound on the number of candidate itemets. It is technical sound. However, it is not make the most of the Apriori property. So the upper bound calculated by KK is not accurate enough.

The contribution of this paper is as follows. 1) The  0-7803-7865-2/03/$17.00 02003 IEEE     theory of itemset equivalence class is presented; 2) An of A on S,  under R,,, is defined as follows: algorithm EC for the maximal number of candidate itemsets is presented, which is based on the itemset [AI,,,  = { X E s k l X  ' k , m  A )  . It is obvious that equivalence class theory. Furthermore, the performance study shows the results calculated by EC are more accurate than that of KK .

The remainder of the paper is organized as follows: Lemma 2.2 is derived from lemma 2.1. It is the theory The theory of the itemset equivalence class is presented in for the number Of section 2. The algorithm EC for the maximal number of candidate itemsets is presented in section 3. The Lemma 2.2. Let s, be a set of k-itemsets. The  = { A )  and = sk '  foundation Of Our itemsets.

performance study of the algorithm EC is reported in section 4. The conclusions are presented in section 5.

2 Theory of Itemsets Equivalence Class  Definition 2.1. ( k  -itemset) Let I = {i,,i *..., i,) be a set of items, a k-itemset X is a set of items such that X E I and 1x1 = k . For convenience, the ith item of X is denoted as X[i] and assume that X [ i ]  < X[j] , when i <  j .

Definition 2.2. (Relation R,,,) Let S ,  be a set of k-itemsets, VA,B E S, . If l l m l k  , we define A B if and only if A[i ]  = B[i] for 1 5  i I m . If m = 0 ,  we define A Rk9, B .

Lemma 2.1. Relation Rk,m is an equivalence .relation on the set of k -itemset S,  , where 0 I m I k .

Proof. 1) Reflexive: V A  E Sk , according to definition  2) Symmetric: Suppose A Rk, ,  B . I f  m = O  , B Rk,m A . If 1 I m I k , B[i] = A[i ]  for 1 I i 5 m .

According to definition 2.2, B R,,, A .

2.2, A Rk,, A .

3) Transitive: Suppose A R,,, B and B Rk,m C .  If m = O ,  A Rk, ,  C .  If I < m l k ,  A [ i ] = B [ i ] = C[i]  for 1 I i  I m . According to definition 2.2,  A ' k , m  '' Definition 2.3. ( R,,, equivalence class) Let S, be  a set of k-itemsets, VA E S, , the Rk>, equivalence class  family of all R,,, equivalence classes on S,  under Rk,m is a partition of S ,  into disjoint nonempty subsets.

Proof. According to lemma 2.1 and the property of equivalence relation [ 111, it can be proved easily.

Definition 2.4. ( Ck+, ( [ A ] , , , ) )  Suppose S ,  be the set of frequent or candidate k-itemsets. is one of  the equivalence classes on S,  under R,,, . Let Ck+, be the set of candidate ( k  + p )  -itemset. [B],+,, ,  is  one of the equivalence class on e,+, under Rk+p,m .

When m 21 , If vx ? [ A ] , , ,  , v y  E [ B ] k + p , m  , X [ i ]  = Y[i]  for 1 I i I m . We define that [B]k+p,m is generated from [A] , , , .  When m = 0 ,  it is obvious that  = S,  and [B],+,,, = C,,, . We define that Ck+, is generated from S, . We denote the set of candidate ( k  + p )  -itemsets that are generated from [ A ] , , ,  as ' k + p  (LA],,, ) '  Lemma 2.3. Let s, be a set of k-itemsets. [A] , , , is one of the equivalence classes on S, under R,,, .

V X  ? [ A I k , ,  , We have c [AI,,,  where 0 1  m I k - 1 .

Proof. V Y  E [ x ] ~ , , + ,  , if m = o Y E [XI,,,,, c S, = [A] , , , .  I f  1 I m I k - 1,  according to the definition 2.2 and definition 2.3, Y [ i ]  = X [ i ]  = 41'1 for 1 I i I m . It implies that Y E  [A], , ,  . So [ X l k , m + l  c LA]k ,m '  Lemma 2.4. Suppose Ck+, is generated from S,.

V A , B  E S, , A # B , A and B can be joined to (p + 1) - itemset'generated in the join step. Thus, we have generate a candidate k +  p ( p 2 1 ) itemsets only if  = [B] , , , - , ,  in other words, A and B are in  the same Rk,k-l equivalence class.

Proof. The candidate generation process of Apriori[ 11  algorithm works in two steps. In the join step, we join S,  with itself to obtain a superset of Ck+, . 'dA, B E S, , They are joinable only if their first ( k  - 1 ) items are in common. Hence only the itemsets in the same Rk,k-l equivalence class can be joined to generate candidate k + 1 itemsets. Furthermore, only the itemsets in the same Rk,k-l equivalence class can be joined to generate candidate k + p ( p 2 1 ) itemsets.

Definition 2.5. (> and relation) Q A , B E S , ( A # B ) ,  if 3 m ,  I I m S k ,  it is satisfied that A[i] = B[i] for 1 I i < m and A[m] < B[m], it is defined that A < B or B > A .  If VB E S , ,  B > A or B = A ,  then A is the minimum element in S,  .

3 The algorithm EC for the maximal number of the candidate itemsets  Based on the theory of itemset equivalence class, we propose the algorithm EC for the maximal number of the candidate itemsets in this section. The main idea in EC is the combine of the theory of itemset equivalence class and Apriori property [l]. Apriori property states that all the subsets of a frequent itemset must be frequent.

We first present the theorems that will be used in algorithm EC.

Theorem 3.1 Let L, be the set of frequent  1 -itemsets. Then )Cl+, (L,  )I I 1;: .

Proof: t/c E c,+p(L,) , according to Apriori  property, C[m] is a frequent 1-itemset for 1 5 m I p + 1   Since there are (b"? I) ways to select p + 1 items from given lL,l items, there are at most (p"! 3 candidate  Theorem 3.2. Suppose Ck+p is generated from s, Let [A] , , ,  be an equivalence class on S, under R,,, , if  Proof. Suppose, for the sake of contradiction, that candidate (k + p )  -itemset C E C,+,([A], , , )  . According to Apriori property,  c S ,  , where X[i] = C[i], for 1 5 i 5 m, X [ j ]  E set, form < j < k  set = {C[m + 11, ..., C[k + p]} . According to definition 2.4, ~ [ i ]  = ~ [ i ]  for 1 I i I m . It implies that [B],,, c [A],,, .

The number of itemsets in [B],,, is @la"). Thus k + p - m  we have[A],,, 1 I > ( k - m  - ). It is contradictive to the assumption. Hence IC,+,([A],,,)I = 0 .

Theorem 3.3. Suppose [A]k,m be an equivalence classon S, under R,,,. I f  m =  k ,  Proof. If m = k , [A],,, = {A}. According to lemma 2.4 and the process of generating candidate itemsets. A can only join with the itemsets in the set of  M=(X(XEIA]k,m-l A X > A ] .

Therefore,  C[i] = A[& for 1 5 i I k E set, for k < j 5 k + p  where set = {Y[k](Y E M} . Thus we have  Theorem  class on S,  3.4. Suppose [A],,, be an equivalence under ' k , m  * = { [ x l k , m + l l x  E I A l k , m )  .

we have ([AI,., )I cp,+, ([XI,.,,, )I ' where [Xl,,..,=F  O l m l  k - 1 .

Proof. QC E C,+,([A],,,) , x = ~ i k _ ,  (~[ i ]}  is one  of the k-subset of C . According to Apriori property.

XES,  . According to definition 2.4, C [ i ] =  A[ i ]  for 1 I i 5 m , thus X E [A], , ,  . It implies that [XI,,,,, E F .

It is obvious that C [ i ]  = X [ i ]  for 1 I i I m + 1  .

According to definition 2.4, C E C,+p([X], ,m+l)  . Then,  Thus, we haveJC,+p(IAli,,)J ~ p k + p ( t ~ l k , m + l ) J  .

I X I I . . . I ~ F  The above theorems only consider the join step in the candidate generation process of Apriori algorithm. We can take the prune step into account to optimize the above results.

Theorem 3.5. Suppose [A] , , ,  be an equivalence class on S, under R,,, , where 1 I m I k-1  .

F = {[Xlk,,+,1X E [A] , , , }  . The following results can be proved:  a)  If p = 1  ([AI,,, )I 5 Cmin((c,+p ([XI,,+, $ I [ x ~ - I ~ , ~ I ) I X l i . m + i ~ F  b)If p > 1  Where  [X"-  I , , ,  = {yly E [AI,,,-, * nm1 = X [ m  + l l } Proof. Q[Xl,,m+I E F and QC E C k + p  ([XI,,,+, 1 .

According to Apriori property, C"- = C - C[m] must be a candidate ( k + p - 1 )  -itemset. It is clear that C"-[m] = C[m + 11 . According to definition 2.4, C[m + 11 = X [ m  + 11 . Thus C"-[m] = X [ m  + 11 .

According to definition 2.4, C"-[i] = C[i ]  = A[i ]  for 1 I i I m - 1  . Based on the discussing above, QY E [ X m - ] , , , ,  we have Y[i]  = Cm-[ i ]  for 1 I i I m .

a) If p = l  , C"- is a k itemset. We have C"- E [ X m - ] k , m  . It implies that ~ C k + p ( [ X l k , m + l ) ~  5  ([X"-], , ,I .  Considering the result in theorem 3.4, we get the conclusion that  b) If p > 1  , C"- is a ( k + p - 1 )  itemset.

According to definition 2.4, we have C"- E C k + p - l  ([X"'- I k , m  ) so that  I c k + p  ([XI,,,+, )I 2 1 ~ k f p - i  ( [ x m - l k , m  )I . Considering the result in theorem 3.4, we arrive the conclusion that  I c k + p  ( l ~ 1 k . m  )I 5 C min(lc,+p  XI,,,+^ ,b Ic .+p- l  ([xm-l,,m 11) [Xlr.n+ieF  Theorem 3.6 is same as proposition 5 and 6 in reference  Theorem 3.6. If S, is the set of frequent k-itemets, the maximal size of the candidate itemset is no more than  k + A4 , where = k -!- m i 4  ICk+p+l (sk)l= O}. The total number of candidate itemsets that can be generated in the iterations even to come is at most Cp=, IC,+~ (s, )I .

[lo].

M  EC is a recursive algorithm. The maximal value of (C,+,(S,)l can be determined by calling EC ( S , ,  k , 0, p ), where s, is the set of frequent or candidate itemsets and p is the level we are predicting.

The pseudo code of the algorithm EC is as follows.

Algorithm EC ( [ A ] , , ,  , k , m , p ) // Apply theorem 3.1  1)if k=l,return ry; I/ Apply theorem 3.2  F = { [ x I , , ~ + , I x E [ A I ~ , ~ } ; upper = 0;  for each [X],,,,, E F  I/ Apply theorem 3.3 2) if m = k - 1  {YlY E [ A ] , ,  A Y > X }  ;  bnd-l= (l;lj ;      else  end if if m = O  or bnd-l=O  bnd -1  = EC([Xl,,,+, , k , m + 1,  P 1;  upper = upper + bnd - 1 ; //Apply theorem 3.5  else if p = 1  s 2  = {YlY E [A]k,m-, A Y[m] = x[m + I ] }  ; bnd_2=IS21;  else  bnd-2 = EC([Xm-Ik,,, , k,  m, p - 1)) ; end if; upper = upper + min{bnd - 1, bnd - 2 )  ;  end for; return upper.

4 Experimental Evaluation  To assess the performance of the algorithm EC, we performed several experiments on a computer of 2.0GHz and 512 MB of memory. The simulation program was coded in C++. In the experiments, we used synthetic data as the input databases to the algorithms. The data are generated using the same technique as that used in reference [l]. We use the notation Tt.Ii.Dm to denote a database in which ID1 = m , (TI = t and 111 = i , where ID1  is the number of transactions in the origin database, IT1 is  the mean size of the transactions, 111 is the mean size of the potentially frequent itemsets. s is the minimum support threshold.

T5 14 DlOk s = 1 0%  I l l  Iteration k  Figure 1 Actual and estimated number of candidate itemsets.

Fig.1 shows, after each iteration k, the maximal number  of candidate itemsets at the next iteration, as well as the actual number ICk+l 1 it turned out to be. It is obvious that the result calculated by EC is almost same as the actual number of candidate itemsets. EC is more accurate than KK.

W l l  I I I l l  5 I 1  I  Iteration k Figure 2 Actual and estimated total number of  candidate itemsets.

Fig.2 shows actual and estimated maximal number of candidate itemsets that could still be generated, as well as the actual total number of candidate itemsets. It can be seen that the total number of candidate itemsts are still be very large when estimated in the first two passes because at these initial stages, there is not much information yet. From the third pass on, however, the estimations become almost exact. It also be shown that EC is exacter than KK in every pass.

T5.14.DlOK s = 1.0%  I I I I I I I I i l l /  . . . . . . . . . . . . . . . . . . . . . . .

I I I I I  1 1 1 1  ~ - - - l - - - T  - -  1 -  - - t - - 1 - - -  '1 2 3 4 5 6 7 8 9 iteration k  Figure 3 Estimated size of the largest possible candidate itemsets.

Fig.3 shows the estimated maximal size of a candidate itemsets. In this experiment, this maximum turned out to be 9. The maximal size of the candidate itemsets estimated by EC is also more close to the actual number than that of KK.

T5.14.DlOK s = 1.0%  Iteration k  Figure 4 Time needed to compute the number of candidate itemsets  Fig.4 shows the time needed to compute the maximal number of candidate itemsets generated in the next level and the actual time to generate the candidate itemsets. In the first several passes, the time needed by EC is longer than that of KK because it need more time to take into account the prune step. In the last several passes, the time needed by EC is less than that of KK . The cost for computing the maximal number is about 1% of the cost of generating the candidate itemsets and is negligible compared to the cost of the complete algorithm.

5 Conclusion  In the level wise algorithm for association rules, the strategy to reduce the number of database scans can improve the performance efficiently. But it may incur the combinatorial explosion on the number of candidate itemsets. So we must study the problem of how many candidate itemsets can be generated from the current iteration and current frequent itemsets. An algorithm EC for the maximal number of candidate itemsets is presented, which is based on the itemset equivalence class theory proposed in this paper. The performance study shows that the results calculated by EC are more accurate than that of KK.

Acknowledgements  This paper is supported by the National Natural Science Foundation of China under Grant No.60173066.

[2] J.S. Park, M. S .  Chen, and P. S .  Yu. Using a hash-based method with transaction trimming for Knowledge and Data Engineering, vol. 9, 1997, pp.

[3] John D. Holt, Soon M. Chung. Mining association rules using inverted hashing and pruning. Information Processing Letters 83 (2002) 21 1-220.

[4] Jiawei Han, Jian Pei, and Yiwen Yin, Mining frequent pattems without candidate generation. Proceeding of ACM SIGMOD Intemational Conference on Management of Data, 2000, pp.1-12.

[5] Savasere, E. Omiecinski, S .  Navathe, An efficient algorithm for mining association rules in large databases, in: Proc. 21st VLDB Conf, 1995, pp.

43 2444.

R. Agrawal, R. Srikant. Fast algorithm for -mining association rules, IBM Research Report RJ9839, IBM Alamaden Research Center, San Jose, California, June 1994.

[7] D. W. Cheung, J. Han, V. T. Ng and C.Y. Wong. D.

W. Cheung, S.D. Lee, Benjamin Kao. A General Incremental Technique for Maintaining Discovered Association Rules. Proceedings of the FiRh Advanced Applications, 1997, pp. 185-194.

[SI Chang-Hung Lee, Cheng-Ru Lin, and Ming-Syan Chen. Sliding window filtering: an efficient algorithm for incremental mining. Proceedings of the ACM Knowledge Management (Atlanta, Georgia, USA),  [9] F. Geerts, B. Goethals, J. Van den Bussche, A tight upper bound on the number of candidate pattems 2001 IEEE Intemational Conference on Data Mining (ICDM'Ol), November 29 - December 02, 2001, San Jose, Califomia, pp. 155-162.

[lo] P. Frankl. A new short proof for the Kruskal-Katona theorem. Discrete Mathematic, 1984,48. 327-329.

[ I l l  Joe L. Mott, Abraham Kandel, Theodore P. Baker, Discrete Mathematics for Computer Scientists and Mathematicians. 1986, a reston book, published by prentice-hall, pp. 9-15, pp. 349-351.

1993, pp.207-2 16.

813-825.

[6]  2001, pp.263-270.

