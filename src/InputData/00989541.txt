CMAR: Accurate and Efficient Classification Based on Multiple  Class-Association Rules *

Abstract  Previous studies propose that associative classification has high classification accuracy and strong jlexibility at handling unstructured data. However, it still suffers from the huge set of mined rules and sometimes biased classi- fication or overfitting since the class$cation is based on only single high-confidence rule.

In this study, we propose a new associative classi- fication method, CMAR, i.e., Classification based on Multiple Association Rules. The method extends an ef- ficient frequent pattern mining method, FP-growth, con- structs a class distribution-associated FP-tree, and mines large database eflciently. Moreovel; it applies a CR-tree structure to store and retrieve mined association rules ef- ficiently, and prunes rules egectively based on conjidence, correlation and database coverage. The classification is pelformed based on a weighted x 2  analysis using multiple strong association rules. Our extensive experiments on 26 databases from UCI machine learning database repository show that CMAR is consistent, highly effective at classifi- cation of various kinds of databases and has better aver- age classification accuracy in comparison with CBA and C4.5. Moreover, our performance study shows that the method is highly eficient and scalable in comparison with other reported associative classification methods.

1 Introduction  Building accurate and efficient classifiers for large databases is one of the essential tasks of data mining and machine learning research. Given a set of cases with class labels as a training set, classification is to build a model (called classifier) to predict future data objects for which the class label is unknown.

Previous studies have developed heuristiclgreedy search techniques for building classifiers, such as decision  *The work was supported in part by the Natural Sciences and En- gineering Research Council of Canada (grant NSERC-A3723), and the Networks of Centres of Excellence of Canada (grant NCWIRIS-3).

trees [ 101, rule learning [2], nayve-Bayes classification [4], and statistical approaches [8]. These techniques induces a representative subset of rules (e.g., a decision tree or a set of rules) from training data sets for quality prediction.

Recent studies propose the extraction of a set of high quality association rules from the training data set which satisfy certain user-specified frequency and confidence thresholds. Effective and efficient classifiers have been built by careful selection of rules, e.g., CBA [9], CAEP [3], and ADT [ 111. Such a method takes the most effec- tive rule(s) from among all the rules mined for classifi- cation. Since association rules explore highly confident associations among multiple variables, it may overcome some constraints introduced by a decision-tree induction method which examines one variable at a time. Extensive performance studies 16, 9, 3, 111 show that association- based classification may have better accuracy in general.

However, this approach may also suffer some weakness as shown below.

On one hand, it is not easy to identify the most effective rule at classifying a new case. Some method, such as [9, 3, 111, simply selects a rule with a maximal user-defined measure, such as confidence. As we will see later, such a selection may not always be the right choice in many cases.

Such a simple pick may affect the classification accuracy.

On the other hand, a training data set often generates a huge set of rules. It is challenging to store, retrieve, prune, and sort a large number of rules eflciently for classifica- tion. Many studies [ 1,5] have indicated the inherent nature of a combinatorial explosive number of frequent patterns and hence association rules that could be generated when the support threshold is small (i.e., when rare cases are also be included in the consideration). To achieve high accu- racy, a classifier may have to handle a large set of rules, including storing those generated by association mining methods, retrieving the related rules, and pruning and sort- ing a large number of rules.

Can we solve the above two problems? To solve the first problem, that is, to predict a new case accurately, in- stead of applying only a single rule, one may consider a small subset of the most related, highly confident rules and make a collective and all-around decision. Intuitively, that  0-7695-1 119-8/01 $17.00 0 2001 IEEE 369    would help us avoid bias, exceptions, and overfitting of too small data sets. To overcome the second problem, the effi- ciency and scalability problem of association-based classi- fication, one needs to develop efficient methods for storing and retrieving rules. This may help improve efficiency as well as the accuracy of classification since more rules can be stored and considered. This is the motivation of this research. .

In this paper, we develop a new technique, CMAR, for accurate and efficient classification and make the follow- ing contributions.

First, instead of relying on a single rule for  classiJica- tion, CMAR determines the class label by a set of rules.

Given a new case for prediction, CMAR selects a small set of high confidence, highly related rules and analyzes the correlation among those rules. To avoid bias, we develop a new technique, called weighted x2, which derives a good measure on how strong the rule is under both conditional support and class distribution. An extensive performance study shows that CMAR in general has higher prediction accuracy than CBA [9] and C4.5 [lo].

Second, to improve both accuracy and eficiency, CMAR employs a novel data structure, CR-tree, to com- pactly store and ejjiciently retrieve a large number of rules for  classiJication. CR-tree is a prefix tree structure to ex- plore the sharing among rules, which achieves substantial compactness. CR-tree itself is also an index structure for rules and serves rule retrieval efficiently.

Third, to speed up the mining of complete set of rules, CMAR adopts a variant of recently devel- oped FP-growth method. FP-growth is much faster than Apriori-like methods used in previous association-based classification, such as [9, 3, 111, especially when there ex- ist a huge number of rules, large training data sets, and long pattern rules.

The remaining of the paper is arranged as follows. Sec- tion 2 revisits the general idea of associative classification.

Section 3 devotes to the generation of rules for classifica- tion. Section 4 discusses how to classify a new data ob- ject using the generated rules. The experimental results on classification accuracy and the performance study on effi- ciency and scalability are reported in Section 5. The paper is concluded in Section 6 .

2 Associative Classification  Suppose a data object obj = j a l ,  . . . , a,) follows the schema ( A I , .  . . , A , ) ,  where A I ,  . .., A, are called at- tributes. Attributes can be categorical or continuous. For a categorical attribute, we assume that all the possible values are mapped to a set of consecutive positive integers. For a continuous attribute, we assume that its value range is dis- cretized into intervals, and the intervals are also mapped to consecutive positive integers. By doing so, all the at- tributes are treated uniformly in this study.

Let C = {cl, . . . , em} be a finite set of class labels. A  training data set is a set of data objects such that, for each object obj, there exists a class label c&j E c associated with it. A classijier C is a function from ( A I , .  . . , An) to C. Given a data object obj, C(obj)  E C returns a class label.

In general, given a training data set, the task of classi- fication is to build a classifier from the training data set such that it can be used to predict class labels of unknown objects with high accuracy.

Besides many different approach for classification, such as decision tree approach, naive Bayesian approach, k - nearest neighbors approach, neural network approach, a new approach is to explore association relationships be- tween object conditions and class labels [9]. The idea is natural since it utilizes frequent patterns and association relationships between cases and class labels in training data set to do classification. If strong associations among some frequent patterns and class labels can be observed in training data set, the future object of similar patterns can be classified.

In general, a pattern P = ai, . . .a ik  is a set of attribute-values such that for (1 5 j 5 k ) ,  ai, E Ai,, and i j  # i j j  for j? # j .  A data object obj is said to match pattern P = ai ,  . . . aik if and only if for (1 5 j 5 k ) ,  obj has value ai, in attribute Ai,.

Given a training data set T ,  let c be a class label. For rule R : P + c, the number of data objects in T match- ing pattern P and having class label c is called the support of R, denoted as sup(R).  The ratio of the number of ob- jects matching pattern P and having class label c versus the total number of objects matching pattern P is called the confidence of R, denoted as conf (  R).

For example, if 95% of customers who have no job cannot get a credit limit more than $3000, i.e., the confi- dence of rule R : no-job + creditlimitless-than-3000 is 95%, then we can use rule R to classify future data objects. To avoid noise, a rule is used for classification only if it has enough support. Given a support thresh- old and a confidence threshold, associative classification method finds the complete set of class-association rules (CAR) passing the thresholds. When a new (unknown) object comes, the classifier selects the rule which matches the data object and has the highest confidence and uses it to predict the class label of the new object.

Recent studies show that associative classification is in- tuitive and effective and has good classification accuracy in many cases. In most existing associative classification methods [9, 3, 111, the rule with the highest confidence is used for classification. However, such a decision may not always be the correct one.

For example, suppose we want to determine the credit limit of a customer with attribute values (nojob,  invest- ment-immigrant, oversea-asset> 500k).  The top-3 most confident rules matching the customer are as follows.

Rule RI : no-job + credit-limit-3000- (support: 3000, confidence: 95%);     Rule R2: investmentimmigrant + ~ r e d i t - l i m i t 3 0 0 0 ~  (support: 5000, confidence: 93%); and  Rule R3: overseaasset 2 500k + credit_limit3000+ (support: 8000, Confidence: 91%).

Row-id A B 1 ai bi 2 ai bz  So, given such a customer, what class label should we pre- dict?

A conventional associative classification method, like CBA, may predict credit-limit3000- according to rule RI only, since it has the highest confidence. However, a closer look at rules R:! and R3 may suggest that we reconsider the decision seriously. The three rules have very similar confi- dence, but R2 and R3 have stronger support. The decision based on rules R2 and R3 seems to be more reliable.

The above example indicates that to make a reliable and accurate prediction, the most confident rule may not al- ways be the best choice, and a thorough, detailed, and all- around measure analysis based on multiple rules may lead to better quality prediction.

C D Classlabel ci di A ct dz B  3 Generating Rules for Classification  In this section, we develop a new associative- classification method, called CMAR, which performs Classification based on Multiple Association Rules.

CMAR consists of two phases: rule generation and classification.

In the first phase, rule generation, CMAR computes the complete set of rules in the form of R : P + c ,  where P is a pattern in the training data set, and c is a class label such that sup( R )  and emf( R )  pass the given support and confidence thresholds, respectively. Furthermore, CMAR prunes some rules and only selects a subset of high quality rules for classification.

In the second phase, classijcation, for a given data ob- ject obj, CMAR extracts a subset of rules matching the ob- ject and predicts the class label of the object by analyzing this subset of rules.

In this section, we develop methods to generate rules for classification. The second phase, classification, will be discussed in Section 4.

3.1 Mining Class-Association Rules Passing Sup- port and Confidence Thresholds  To find rules for classification, CMAR first mines the training data set to find the complete set of rules passing certain support and confidence thresholds. This is a typi- cal frequent pattern or association rule mining task [ 11. To make mining highly scalable and efficient, CMAR adopts a variant of FP-growth method [5].  FP-growth is a frequent pattern mining algorithm which is faster than conventional Apriori-like methods, especially in the situations where  there exist large data sets, low support threshold, and/or long patterns. The general idea of mining rules in CMAR is shown in the following example.

Table 1. A training data set.

First, CMAR scans the training data set T once, find the set of attribute values happening at least twice in T. The set is F = { a l ,  b z ,  c1, d3 )  and is calledfrequent item set.

All other attribute values, which fail the support threshold, cannot play any role in the class-association rules, and thus can be pruned.

Then, CMAR sorts attribute values in F in support de- scending order, i.e., F-list = al - b2 - c1 - d3. Then, CMAR scans the training data set again to construct an FP-tree, as shown in Figure l(a).

FP-tree is a prefix tree w.r.t. F-list. For each tuple in the training data set, attributes values appearing in F-list are extracted and sorted according to F-list. For example, for the first tuple, ( u l ,  c1) are extracted and inserted in the tree as the left-most branch in the tree. the class label is attached to the last node in the path.

Tuples in the training data set share prefixes. For exam- ple, the second tuple carries attribute values ( a l ,  6 2 ,  CI) in F-list and shares a common prefix a1 with the first tuple.

So, it also shares the a1 sub-path with the left-most branch.

All nodes with same attribute value are linked together as a queue started from the header table.

@ Header Table Header Table 9  (a) FP-wee (b) FP-tree afler merging nodes of d3  Figure 1. FP-tree in Example 1.

Third, based on F-list, the set of class-association rules can be divided into 4 subsets without overlap: (1) the ones     having d3; (2) the ones having c1 but no d3; (3) the ones having b2 but no d3 nor c1; and (4) the ones having only al .  CMAR finds these subsets one by one.

Fourth, to find the subset of rules having d3, CMAR tra- verses nodes having attribute value d3 and look ?upward? to collect a d3-projected database, which contains three tu- ples: (ax, b2, c1, d3) : C, (al ,  b2, d3) : C and d3 : A.  It contains all the tuples having d3. The problem of finding all frequent patterns having d3 in the whole training set can be reduced to mine frequent patterns in d3-projected database.

Recursively, in d3-projected database, a1 and bz are the frequent attribute values, i.e., they pass support thresh- old. (In d3-projected database, d3 happens in every tu- ple and thus is trivially frequent. We do not count d3 as a local frequent attribute value.) We can mine the pro- jected database recursively by constructing FP-trees and projected databases. Please see [ 5 ]  for more details.

It happens that, in &-projected database, a1 and b2 al- ways happen together and thus a l b 2  is a frequent pattern.

a1 and bz are two subpatterns of alb:, and have same sup- port count as alb2.  To avoid triviality, we only adopt fre- quent pattern a1 b2d3. Based on the class label distribution information, we generate rule albzd3 -+ C with support 2 and confidence 100%.

After search for rules having d3, all nodes of d3 are merged into their parent nodes, respectively. That is, the class label information registered in a d3 node is regis- tered in its parent node. The FP-tree is shrunk as shown in Figure l(b). Please note that this tree-shrinking opera- tion is done at the same scan of collecting the d3-projected database.

The remaining subsets of rules can be mined similarly.

There are two major differences in the rule mining in CMAR and the standard FP-growth algorithm.

On one hand, CMAR finds frequent patterns and gen- erates rules in one step.

Conventionally, association rules must be mined in two steps [I] .  This is also the case for traditional associative classification methods [9]. First, all the frequent patterns (i.e., patterns passing support threshold) are found. Then, all the association rules satisfying the confidence threshold are generated based on the mined frequent patterns.

The difference of CMAR from other associative clas- sification methods is that for every pattern, CMAR main- tains the distribution of various class labels among data ob- jects matching the pattern. This is done without any over- head in the procedure of counting (conditional) databases.

Thus, once a frequent pattern (i.e., pattern passing support threshold) is found, rules about the pattern can be gener- ated immediately. Therefore, CMAR has no separated rule generation step.

On the other hand, CMAR uses class label distribution to prune.

For any frequent pattern P ,  let c be the most dominant class in the set of data objects matching P.  If the number of objects having class label c and matching P is less than the support threshold, there is no need to search any super- pattern (superset) P? of P since any rule in the form of P? -+ c cannot satisfy the support threshold either.

3.2 Storing Rules in CR-tree  Once a rule is generated, it is stored in a CR-tree, which is a prefix tree structure. We demonstrate the general idea of CR-tree in the following example.

Example 2 (CR-tree) After mining a training data set, four rules are found as shown in Table 2.

1 Rule-id I Rule I Suoeort I Confidence1 I , .. , I  1 1  abc -+ A I 80 I 80% 2 I abcd -+ A I 63 I 90% 3 1  abe -+ B I 36 1 60% 4 I bcd + C I 210 I 70%  Table 2. Rules found in a training data set.

A CR-tree is built for the set of rules, as shown in Figure 2, while the construction process is explained as follows.

Header Table 0  Figure 2. A CR-tree for rules in Example 2.

A CR-tree has a root node. All the attribute values ap- pearing at the left hand side of rules are sorted according to their frequency, i.e., the most frequently appearing at- tribute value goes first.

The first rule, abc + A is inserted into the tree as a path from root node. The class label as well as the support and confidence of the rule, denoted as ( A ,  80,80%), are registered at the last node in the path, i.e., node c for this rule.

The second rule, abcd -+ A,  shares a prejix abc with the first rule. Thus, it is inserted into the tree by extending a new node d to the path formed by the first rule. Again, the class label, support and confidence of the rule are reg- istered at the last node, i.e., d.

The third and fourth rules can be inserted similarly. All the nodes with the same attribute value are linked together     by node-link to a queue. The head of each queue is stored in a Header table.

To store the original rule set, 13 cells are needed for the left hand sides of the rules. Using CR-tree, only 9 nodes are needed.

As can be seen from the above example, the CR-tree structure has some advantages as follows.

CR-tree is a compact structure. It explores potential sharing among rules and thus can save a lot of space on storing rules. Our experimental results show that, in many cases, about 50-6076 of space can be saved using CR-tree.

CR-tree itself is an index for rules. For example, if we want to retrieve all the rules having attribute value b and d in the set of rules in Example 2, we only need to traverse node-links of d, which starts at the header table, and keep looking upward for b.

Once a CR-tree is built, rule retrieval becomes efficient.

That facilitates the pruning of rules and using rules for classification dramatically.

3.3 Pruning Rules  The number of rules generated by class-association rule mining can be huge. To make the classification effective and also efficient, we need to prune rules to delete redun- dant and noisy information.

According to the facility of rules on classification, a global order of rules is composed. Given two rules R1 and Rz, RI is said having higher rank than Rz, denoted as R1 > Rz,  if and only if (1) conf(R1) > conf(R2); (2) conf(R1) = conf(R2) but sup(R1) > sup(R2); or ( 3 ) conf(R1) = c o n f ( R ~ ) ,  sup(R1) = sup(R2) but RI has fewer attribute values in its left hand side than R2 does. In addition, a rule RI : P -+ c is said a general rule w.r.t.

rule R2 : P' + c', if and only if P is a subset of PI.

CMAR employs the following methods for rule pruning.

First, using general and high-confidence rule to prune  more specijic and lower confidence ones. Given two rules R1 and R2, where R1 is a general rule w.r.t. R2. CMAR prunes R2 if R1 also has higher rank than R2, The ratio- nale is that we only need to consider general rules with high confidence, and thus more specific rules with low confidence should be pruned.

This pruning is pursued when the rule is inserted into the CR-tree. When a rule is inserted into the tree, retrieval over the tree is triggered to check if the rule can be pruned or it can prune other rules that are already inserted. Our experimental results show that this pruning is effective.

Second, selecting only positively correlated rules. For each rule R : P + c, we test whether P is positively cor- related with c by x 2  testing. Only the rules that are posi- tively correlated, i.e., those with x2 value passing a signif- icance level threshold, are used for later classification. All the other rules are pruned.

Algorithm 1 (Selecting rules based on database coverage) Input: a set of rules and a coverage threshold 6 Output: a subset of rules for classification Method:  1 .  Sort rules in the rank descending order; 2. For each data object in the training data set, set its  cover-count to 0; 3. While both the training data set and rule set are not  empty, for each rule R in rank descending order, find all data objects matching rule R. If R can correctly classify at least one object then select R and increase the cover-count of those objects matching R by 1. A data object is removed if its cover-count passes cov- erage threshold 6;  Figure 3. Selecting rules based on database coverage.

The rationale of this pruning is that we use the rules re- flecting strong implications to do classification. By remov- ing those rules not positively correlated, we prune noise.

This pruning happens when a rule is found. Since the distribution of class labels w.r.t. frequent patterns is kept track during the rule mining, the x2 testing is done almost for free.

Third, pruning rules based on database coverage.

CMAR selects a subset of high quality rules for classifica- tion. That is achieved by pruning rules based on database coverage. CMAR uses a coverage threshold [7] to select database coverage, as shown in Figure 3.

The database coverage method used in CMAR IS simi- lar to that in CBA. The major difference is that, instead of removing one data object from the training data set imme- diately after it is covered by some selected rule, we let it stay there until it is covered by at least 6 rules. That allows more selected rules. When classifying a new data object, it may have more rules to consult and may have better chance to be accurately predicted.

This pruning is pursued when the rule mining process finishes. It is the last pruning of rules.

4 Classification Based on Multiple Rules  After a set of rules is selected for classification, as dis- cussed in Section 3, CMAR is ready to classify new ob- jects. Given a new data object, CMAR collects the subset of rules matching the new object from the set of rules for classification. In this section, we discuss how to determine the class label based on the subset of rules.

Trivially, if all the rules matching the new object have the same class label, CMAR just simply assigns that label to the new object.

If the rules are not consistent in class labels, CMAR di- vides the rules into groups according to class labels. All rules in a group share the same class label and each group has a distinct label. CMAR compares the effects of the groups and yields to the strongest group.

To compare the strength of groups, we need to mea- sure the ?combined effect? of each group. Intuitively, if the rules in a group are highly positively correlated and have good support, the group should have strong effect.

There are many possible ways to measure the combined effect of a group of rules. For example, one can use the strongest rule as a representative. That is, the rule with highest x 2  value is selected. However, simply choosing the rule with highest x2 value may be favorable to minority classes, as illustrated in the following example.

RZ ed=univ edfuniv  Example3 In a credit card application approval case, there are two rules.

RI : job = n o  + rejected(support = R2 : education = universi ty  + approved(sup =  The observed and expected contingencies are shown in  confidence = SO%), and  200, confidence = 99.5%)  Figure 4.

I RI 1 amroved I reiected I total 1  approved rejected total 199 1 200 251 49 300  L , I job=yes I 438 I 32 I 470 iob=no I 12 I 18 I 30 total I 450 I 50 I 500  The observed contingency of rule R I .

I I I  total 1 450 I 50 I 500.

The observed contingency of rule Rz.

[ RI I approved I rejected I total I I iob=ves I 423 I 47 I 470 I _ . I ,  job=no I 27 1 3 1  30 total I 450 I 50 I 500  customer having no job and with university education, we may predict her application would be rejected using rule R I ,  if the choice of rules is based on only x2 values.

However, rule R2 is intuitively much better than RI since Rz has much higher support and confidence.

Another alternative is to use the compound of correla- tion of rules as measure. For example, we can sum up x2 values in a group as the measure of the group. However, this method suffers from the same problem that it may fa- vors minority too much.

A better way is to integrate both information of cor- relation and popularity into the measure. After empirical verification, CMAR adopts a weighted x2  measure [7] as follows.

For each rule R : P + c,  let sup(c)  be the number of data objects in training data set that associated with class label c and IT1 the number of data objects in the training data set. We define maxX2 for rule R as follows.

where  rnaxX2 computes the upper bound of x2 value of the rule w.r.t. other settings are fixed. Then, for each group of rules, the weighted x2 measure of the group is defined as  As can be seen, we use the ratio of x2 value against its upper bound (i.e., rnaxx?) to overcome the bias of x2 value favoring minority class. Please note that, theoreti- cally, it is hard to verify the soundness or effect of mea- sures on strength of groups of rules. Instead, we explore the effect of measures empirically, and according to our experimental results, weighted x2 value is the best from among a good set of candidate measure formulas that can be worked out by us.

E&$.

The expected contingency of rule R I .

I R2 I approved I rejected I total I I ed=univ I 180 I 20 I 200 1  edfuniv I 270 I 30 I 300 total I 450 1 50 1 500  The expected contingency of rule Rz.

Figure 4. Observed and expected contingen- cies for rules.

Based on the observed and expected values, the x2 val- ues for R1 and Rz are 88.4 and 33.6, respectively. For a  5 Experimental Results and Performance Study  To evaluate the accuracy, efficiency and scalability of CMAR, we have performed an extensive performance study. In this section, we report our experimental results on comparing CMAR against two popular classification meth- ods: CBA [9] and C4.5 [lo]. It shows that CMAR outper- forms both CBA and C4.5 in terms of average accuracy, efficiency and scalability.

All the experiments are performed on a 600MHz Pen- tium PC with 128M main memory, running Microsoft Windows/NT. CBA and C4.5 were implemented by their authors, respectively. In the experiments, the parameters of the three methods are set as follows.

All C4.5 parameters are default values. We test both C4.5 decision tree method and rule method. Since the rule method has better accuracy, we only report the accuracy for rule method.

For CBA, we set support threshold to 1% and confi- dence threshold to 50% and disable the limit on number of rules. Other parameters remain default.

For CMAR, the support and confidence thresholds are set as same as CBA. The database coverage threshold is set to 4 and the confidence difference threshold to 20%.

All reports of the runtime include both CPU time and VO time.

We test 26 data sets from UCI Machine Learning Repository. We use C 4 . 5 ' ~  shufle utility to shuffle the data sets. Also, we adopt the same method used by CBA to discretize continuous attributes.

I Data set I # attr I # C I S  I # rec I C4.5 I CBA I CMAR I I Anneal I 38 I 6 I 898 I 94.8 1 97.9 I 97.3 I  I I I I I I  Austral I 14 I 2 I 690 I 84.7 I 84.9 I 86.1 Auto I 25 I 7 I 205 I 80.1 1 78.3 I 78.1  I I I I 1 -  Breast I 10 I 2 I 699 I 95 I 96.3 I 96.4 Cleve I 13 I 2 I 303 1 78.2 I 82.8 I 82.2  Table 3. The comparison of C4.5, CBA and CMAR on accuracy.

As can be seen from the table, CMAR outperforms both C4.5 and CBA on accuracy. Furthermore, out of the 26 data sets, CMAR achieves the best accuracy in 13 ones.

In another word, CMAR wins in 50% of test data sets. In some data sets, e.g. Lymph, CMAR wins the second place over 5% in accuracy.

There are two important parameters, database coverage threshold and confidence difference threshold, in  CMAR.

As discussed before, these two thresholds control the num- ber of rules selected for classification.

In general, if the set of rules is too small, some effective rules may be missed. On the other hand, if the rule set is too large, the training data set may be overfit. Thus, we need to test the sensitivities of the two thresholds w.r.t.

classification accuracy.

As an example, we test different database coverage threshold values on the Sonar data set from UCI Machine Learning Database Repository. The results are shown in Figure 5 ,  where the confidence difference threshold is set to 0. On the other hand, we test different confidence differ- ence threshold values on the Sonar data set. The results are shown in Figure 6, where the database coverage threshold is set to 1.

I " " " ' 1  1 1.5 2 2.5 3 3.5 4 4.5 5 Database coverage threshold  Figure 5. The effect of coverage threshold on accuracy.

0 0.02 0.04 0.06 0.08 0.1 0.12  Confidence difference threshold  Figure 6. The effect of confidence difference threshold on accuracy.

From the figures, one can see that the peaks of accu- racy are achieved at the middle of both curves. That is, there are optimal settings for both thresholds. However, according to our experimental results, there seems no way to pre-determine the best threshold values. Fortunately, both curves are quite plain. That means the accuracy is not very sensitive to the two thresholds values.

CR-tree is a compact structure to store rules. To test the effectiveness of  CR-tree, we compare the main mem- ory usage of CBA and CMAR on large test data sets. The     results are shown in Table 4. 6 Conclusions  mem (M) mem (M) associative classification: (1) efficiency at handling huge  Table 4. The comparison of CBA and CMAR on main memory usage.

Dataset Auto Hypo Ion0 Sick  Please note that, in this experiment, we disable the lim- itation of number of rules in CBA. In such a setting, CBA and CMAR generate all the rules necessary for classifica- tion and thus are compared in a fair base. From the table, one can see that, on average, CMAR achieves 77.12% sav- ing on main memory usage.

The saving in main memory usage can be explained from two apsects.

First, CMAR uses CR-tree. The compactness of CR-tree brings significant gain in storing a large set of rules where many items in the rules can be shared.

On the other hand, CR-free is also an index structure of rules. Before a rule is inserted into a CR-tree, CMAR checks if there is a general rule or some more specific rules in the tree. If so, related pruning is pursued immediately.

Such a pruning techique also contributes to  the saving of main memory.

To test the scalability of CMAR, we compare the run- time of CBA and CMAR on six data sets. The results are shown in Figure 5 .  Again, we disable the limit on number of rules in CBA. In the experiments, CBA spends a large portion of runtime on YO.

# attr # cls # rec CBA runtime CMAR runtime 25 7 205 612s 408s 25 2 3163 92s 19s 34 2 351 150s 89s 29 2 2800 74s 13s  Sonar I 60 I 2 ] 208 1 226s 145s  Table 5. The runtime of CBA and CMAR.

As can be seen from the table, CMAR is faster than CBA in many cases. Please be note that the machine we use for testing is with relatively small size of main memory (128M). Both CBA and CMAR can be expected running significantly faster if more main memory is available.

racy, (2) it prunes rules effectively based on confidence, correlation and database coverage, and (3) its efficiency is achieved by extension of an efficient frequent pat- tern mining method, FP-growth, construction of a class distribution-associated FP-tree, and applying a CR-tree structure to store and retrieve mined association rules effi- ciently.

Our experiments on 26 databases in UCI machine learning database repository show that CMAR is consis- tent, highly effective at classification of various kinds of databases and has better average classification accuracy in comparison with CBA and C4.5, and is more efficient and scalable than other associative classification methods.

