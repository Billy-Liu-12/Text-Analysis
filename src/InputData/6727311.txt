Using Value Network Analysis to support Data Driven Decision Making in Urban  Planning

Abstract?This article provides a methodology of assessing the (Big)/(Open) Data quality in Data Driven Decision Making with the Value Network Analysis approach discovering the value creation failure point(s) in the network and evaluating the impact of loss of vale of data in DDDM process.

Keywords:Data Driven Decision Making, Value Network Analysis, urban planning

I.  INTRODUCTION  Today, to be more effective in urban planning and decision making, public administrators need to gain useful knowledge from their territory to support the so called Data Driven Decision Making[14]. Intuitive decisions are not the path to success when working with the mountains of structured and unstructured information 1 . But there are several misunderstanding around the ?data? term and researches tends to use alternatives like ?Evidence Based decision making?. In fact, according to [15]  there is a huge distinction to be made between "evidence" and "data." The former is the way for understanding where your business has been and where it needs to go. The latter is the instrument that lets us get to that end game. Data itself isn't the solution. It's just part of the path to that solution.

According to [12], data, information, and knowledge  form a continuum in which data, are transformed to information, and ultimately to knowledge that can be applied to make decisions. As defined in [13]: Data exist in a raw state. They do not have meaning in and of itself and whether or not data become information depends on the understanding of the person looking at the data.

Information is data that is given meaning when connected to a context. It is data used to comprehend and organize our environment, unveiling an understanding of relations between data and context. Alone, however, it does not carry any implications for future action. Knowledge is created through a sequential process and is the collection of information deemed useful, and eventually used to guide action. Data, information and knowledge are generated by a number of different actors acting in urban   1 MIT panelists: Big data calls for data-driven decision-making skills http://searchbusinessanalytics.techtarget.com/news/2240184734/MIT- panelists-Big-data-calls-for-data-driven-decision-making-skills  context but what about their actual usefulness? Usually Big Data are described with the 3 V?s ? volume, velocity and variety but  it?s the 4th V ? Value ? where we really should focus.  In the DDDM in urban planning, this Value could be identified as the ability of generating common goods (public value) from decision taken exploiting valuable knowledge.

Figure 1.  Data Driven Decision Making process in urban  contenxt(inspired by Ellen et al 2006)  Thanks to approaches like data mining and analytics, the knowledge can be extracted from the huge amount of data daily produced by different agents like users through social networks and sensors, public administrations, companies, utilities, etc. but its actual value has to be determinate.

The Value Chain as both a concept and a tool has been used for the last 30 years to understand and analyze industries. It has proved a very useful mechanism for portraying the chained linkage of activities, and, furthermore, it has also framed our thinking about value and value creation [5].

When products and services become dematerialized (and the value chain itself no longer having a physical dimension), the value chain concept becomes inappropriate. In fact, for Open Data based services, the classical approach of Porter?s value chain (grounded in the assumptions and the model of an industrial economy) is not anymore adequate [4], since the fundamental logic of value creation is linked to a network and complex context.

Global competition, changing markets, and new technologies are opening up qualitatively new ways of creating value. In this respect, strategy is the way in which a company defines its business and links together the only two resources that really matter in today?s economy: knowledge and relationships with markets, stakeholders   DOI 10.1109/SITIS.2013.161     and territories.  In the traditional value chain the focal is the end product and the chain is designed around the activities required  to produce it, while in the current Data Driven context, value is co-created by a combination of players (social networks, sensors, data scientists, city managers, city council, utilities, etc.) with a defined roles in the network in a strong co-operative manner playing a significant role in strategic performance.

According to this, this work adopted the Value  Network Analysis perspective as a suitable approach to identify the value of the inputs/outputs in DDDM steps and identify the potential value creation failure points in the networks that could  affect the final impact of the decision.



II. VALUE NETWORK ANALYSIS  The Value Network Analysis (VNA) was developed by Verna Allee in the 1990s and uses a basic network modeling approach of nodes and links to show collaborative relationships, analyze value transactions, and visualize critical "flow" sequences.

The first step of VNA is to identify the roles of the  players in the network. In our context the players are: a) Data Analysts: this role represents the team  devoted to collect and process data to extract knowledge (DISIA and MOSIS Lab).

b) External Data Providers: this role represents social networks data (e.g. Fliker).

c)  Internal Data Provider: this role represents the Open Data dept. of  City of Florence  d)  Decision Makers: this role represents city managers of Florence(e.g. tourism dept.)  Accorind go VNA approch[17], once the roles are identified, the scenario has to be mappend on value network using the following notation: 1. Nodes (often shown as ovals) represent real actors and the contributing role they play in that activity.

2. A directional arrow shows a single transaction - something moving from one role to another.

3. A transaction with an intangible deliverable is shown here with a dashed line, and a transaction with a tangible  deliverable is shown with a solid line.

Figure 2.  Simplyfied Value Network map  When a participant (role) receives a value input they should find ways to use that input to either improve their own capability (Impact Analysis), or provide value to other roles in the network  (Value Creation Analysis).

The first level of the value analysis is the Impact Analysis  and shows if a role is realizing value from their inputs. According to [7], the value realization in a network can be defined as ?the act of converting a value input, either tangible or intangible, into gains, benefits, or asset improvements that contribute to the success of a role or organization?. The second level of value analysis - Value Creation Analysis - explores how the value network creates value by role and as a whole. According to [7], some of basic questions are: How well are we using our assets to create a given value output? What value features or enhancements do we provide with this output?

The two roles under analysis are: Data Analysts and Decision Maker. We selected these two roles since the former represents the real transformation engine of data to knowledge, while the latter is who transform the knowledge into public value.

Role: Data Analysts  Its value realization can be referred to the act of converting high quality and appropriate data (tangible value input)  into Information (tangible assets)  through data harvesting and processing techniques.

The value output of Data Analysts role is represented by the knowledge as a result of  Information  (assets) syntetization of Data Analysts.

It is important to remark that, according to the ?garbage- in, garbage-out? principle of the information systems, a low value input produces a low realized value at the end of the process. In fact, initiatives like Open Data undertaken by many public organisations, have been primarily oriented to address institutional transparency (short term political achievements), instead of being designed to support data mining and analysts as shown in the following chapters. This results in a loss of value of outputs and the realized value.

Role:Decision Maker In particular, the value output of DA represents the input value for Decision Maker role and is expressed as a tangible deliverable like ?Analytics? as shown in Fig 1.

The value realization for DM is the DDDM process accomplishment achieved converting analytics (knowledge) into awareness rising about city issues, a reduction of uncertainty and bias, a cost-efficiency and performance understating, a way to check assumptions, clarify choices, prioritize decisions, a way to identify solutions and prioritize decisions, and so forth The value output of DM can be identified in tangible deliverables like the new city plan, initiatives, and so forth.

Another value output are guidelines that represent a value input for the Internal data producer role. This deliverable is crucial since it represents a way to implement an internal side data production strategy able to ignite a value propagation through the network rasing up the DM output vale.

Thus, for their successful uptake in value realization process, it is  important to provide the foundation for the development of business and usage cases revolving around the adoption of Linked Open Data, in the general framework of the Value Analysis [7]; the idea is to conceptualizes the Linked Open Data value chain and  to identify and categorize potential pitfalls which have to be considered by business and information engineers. In this perspective, providing intellectual frameworks, conceptual models, and  governing ideas allows a company's managers to identify opportunities for bringing value to customers and for delivering that value at a profit.



III. TERRITORY AS LINKAGE KEY  Nowadays many public administrations are committed to Open Data and transparency issues and, over time, more information for re-use and share is available for analysis.

If institutions are often aware of the exigency of opening their repositories, a lack of attention is still devoted on assuring the conditions for transforming Open Data in valuable data (value input).  This is particularly serious when data represent assets and events on the territory. In fact, a territory represents the linkage key which connects together processes and actors that have in common the fact of happening/acting in the same place. Public administration ought to pay a great attention on the quality and completeness of the geographical attributes of their Open Data, as they allow to link together not only their administrative data sets, but also independent sources, like, for instance those originated by social and web activities.

In this perspective, an exercise focused on linking together city of Florence administrative Open Data, Flickr data and sensors data like city Wifi, will allow us to identify where the loss of value happened due to issues in  data production process, quality  and semantics that prevents a reliable accomplishment of DDDM process.

Big efforts have already been done, in general, on social network data reuse and, in particular, on Flickr data exploitation; the need of providing a shared semantic has been already discussed in [9], [8].

In this work we are interested in discovering where are the value creation failure points in such a vale networks that prevent the joint usage of public Open Data with social media data (Flickr, in this specific application) in a profitable manner. The idea is that the a DDDM is effective only if it represents a complete, reliable and evolutive narration [11], [10] in which different stakeholders and actors could recognize themselves. The analysis has been structured in these main steps:   (i) External Data producers: the Flickr data collection.

To collect data from Flickr we have used the Flickr REST APIs providing the Lat/long of a point representing the centre of the Cascine Park, namely Piazza del Re, with a radius of 10Km. The results is an XML of the photos that fall in the distance, with some related information (metadata) like ID, title, owner, Lat/long, tags, and so forth.

(ii) Internal Data producers: City of Florence Wifi logs data collection. This dataset is generated by the wifi access points situated in different parts of the city and includes the ID of the user (usually the mobile number), datestamp of each event (es. login/logout), the amount of data transferred. We have collected 100K records representing more than 400 unique users within a temporal window of 2,5 months (from 12-04- 2012 to 29-07-2012), but only a subset of log records related to the park has been processed. It is worth to notice that the re-use and processing of logs data involves privacy issues and specific hash algorithms has been applied to mobile number data to guarantee privacy during the processing.

(iii) Internal Data producers City of Florence geo Open Data. Geo Open Data about the territory (streets, buildings, etc.) have been downloaded from the Open     Data portal of City of Florence (http://opendata.comune.fi.it). We have selected only the datasets that we considered relevant for the Cascine Park case study. All this information are downloaded as shpfile format in order to create a GIS map as a base to bind on, join and process data from the identified data sources.



IV. VNA DELIVERABLE: KNOWLEDGE VALUE  Temporal and geographical distributions of Flickr and wifi  events could reveal some interesting expected and unexpected behavioral patterns that represent a potential value input for DecisionMaker process to taken good decision in DDDM process. From the government perspective, in fact, uncovering the city places dynamic social character means gaining insights for urban design, public service planning, infrastructure monitoring and so forth.

A first exercise has been focused on trying to understand in which time slots of the day, the Cascine Park is visited.

To obtain such a information we have combined events logs data with access points geographic datasets obtained (in shapfile) as Open Data. During the value conversion performed by Data Analys some issues emerged that affected the value of the outputs.

Loss of value In particular, we have faced a problem related to the lack of a join key between access point geographic representation (feature) with datastrems coming from Open Data logs. This scenario shows that the integrated data value is seriously affected by not having properly modeled the Open Data production process and the benefit of having wifi access point layer freely accessible, is strongly reduced.

According to the VNA, the value creation failure point is represented by the low value of the transaction between Decision Makers and Internal Data producer. In fact, the deliverable (guidelines) expected by the Decision Making role, is on quantitavite targed to be achieved by  data production process instead of inputs framed within a value oriented strategy.

To overcome these limitations and to show the information potentialities of this harmonized information system ,we have added manually the missing key values.

Figure 2 shows the results of this work obtained manually adding the name of the wifi access point in the access points layer.

Figure 3.  Wifi log based place profile analysis   For instance it is worthy to notice that the access point situated in the Cascine Park (fig. 2 feature 1) has no detected any presence within the 2-6 (blue) range and only few presences within the 6-10 range (yellow), while the 10-14 (red), 14-18 (purple) and 18-22 (green) ranges seem to be the most ?crowded. This result reveals that the Park is mainly used during the daylight hours. This behavior might be due to security issue or the lack of services and events.

A second exercise has involved also Flickr data looking for other issues able to affect the information system value in terms of Quality [2]. For instance, according to the approach presented in [3] we have retrieved Cascine Park Flickr posts, title and the tags.

Figure 4.  Figure 3 Buffering   The first processing has been done applying the ArcGIS buffering function to the points representing the place where the photos are taken. The Figure 3 shows their spatial distribution and it is possible to identify 3 major areas of concentration that corresponding to the Anfiteatro, Piazzale del Re and Piazza Vittorio Veneto.

Once the most visited areas are identified, the second step of the analysis is to understand ?why? a photo has been taken in a place. The Figure 4 represents a sort of ?profile? of the place derived by the motivation behind a picture (red triangle) is taken that can be clusterized with three high level concepts: Events, Leisure, Panoramic areas. The analysis has been conducted with a visual analytics methods [3]. This method require human involvement in addition to the automated analysis in the exploration of the data, due to the presence of not     controlled semantics in metadata that affect automatic processing. It is clear that this approach is not sustainable with an high number of instances to be processed.

Figure 5.  Photo clustering analysis  The data collected from Flickr have been further processed for Time series analysis. We have analyised the entire datasets (Cascine Park with a radius of 10Km) and a subset of the dataset filtered for neighborhood metadata field with the value of ?Cascine?.

In this way we aimed to verify if there were similarities in trends. The graph below represents the Time series of the entire dataset.

The blue line represents the Italian visitors (mostly resident) while the red line shows the contribution of foreign.

Figure 6.  Time series of the selected fliker datasets  The chart below shows the Time series applied to the dataset filtered with neighborhood = ?Cascine?. It is worthy to notice that the foreign (red line) follow a different distribution.  Moreover, the graph shows that the Park tends to be used/exploited in spring and in late Summer/early Autumn. This trend is well represented by the seasonal chart.

Figure 7.  Time series of the filtered fliker datasets  The chart below shows the general trends of presences in the area (cascine +10Km).

Figure 8.  Trends of fliker datasets  The graph below shows the seasonal distribution of the time series. It is interesting to notice that the major pick is in spring (april-may).

Figure 9.  Seasonaldistribution of the time series of selected fliker  datasets  Indeed these results have been extracted for demo purpose and they need to be validated.

Loss of Value  The data collected show several issues as: empty field (completeness), device auto generated name (e.g.?DG00001), brand name (e.g. ?Nikon?), and so forth.

Moreover, as stated in [1], geo-referenced photo data may introduce a level of uncertainty. In some cases, coordinates could refer to the position of the photographer, while in others they refer to the location of the object being photographed. The results of data     inspection retrieved from flickr has revealed a number of criticisms listed below:   - automatic generated tag from application (e.g.?istant gramm?) - too generic concepts (e.g. ?me?, ?girl?, ?Florence?) - concatenated words (e.g. ?goingtowork?, ?picoftheday?) - name of mobile apps (e.g. ?hipstamatic?) - neologisms/slang terms(e.g. ? igers? ) - content wrong assignment (e.g. Rome, Vatican Museum)  Thus, according to the VNA, the value creation failure point is represented by the low value of the transaction and related deliverable between External Data producers and Data Analytics.

In fact, it is clear that without a common semantics and a controlled vocabularies the integration and the automatic processing of these data in a meaningful framework cannot be realized completely.

These results show that if a city manager wants to profit of the territory usage information coming from social networks activities, new roles (dedicated services) must be created in the network. These services, in particular, ought to offer facilities to uploading activities while controlling the semantic heterogeneity and the biases indicated in this report.



V. CONCLUSION  The data value creation failure points in the networks are several. In fact, the actual capability to achieve data value realization to support DDDM process is linked to the capability of the network of creating value in terms of knowledge and right decisions form data. A number of issues in data production, semantics and quality affects the value realization, preventing and limiting analysis and decision support. This report shows that Open Data strategy is needed and must take in account not only transparency issues but also all those aspects affecting data linking and harmonization: in some cases these drawbacks rely on a not perfect coordination between Open Data publication strategies between different administration branches.

This is the easier situation to solve and it could be faced at organizational level.

In other case the lack of information rely on the semantics adopted by social network actors: the second exercise suggests that the solutions could be found in specialized services that, while giving an added value to the users, harmonize the different semantic plans and remove bias causes.

