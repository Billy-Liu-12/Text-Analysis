Automated Construction Chinese Domain Ontology from Wikipedia

Abstract  Wikipedia (Wiki) is a collaborative on-line encyclopedia, where web users are able to share their knowledge about a certain topic. How to make use of the rich knowledge in the Wiki is a big challenge. In this paper we propose a method to construct domain ontology from the Chinese Wiki automatically.

The main idea in this paper is based on the entry segmenting and Feature Text (FT) extracting, where we segment the name of entries and establish the concept hierarchy firstly. Secondly, we extract the FTs from the descriptions of entries to eliminate the redundant information. Finally we calculate the similarity between pairs of FTs to revise the concept hierarchy and gain non-taxonomy relations between concepts. The primary experiment indicates that our method is useful for Chinese domain ontology construction.

1. Introduction   Wikipedia (Wiki) is an environment where web users  are able to share their knowledge about a certain topic [1].

The Wiki includes many entries. Each entry has a corresponding web page-- description.

Obviously, the knowledge offered by Wiki is loose arrangement, which lacks of well concept hierarchy structure and the logical inference mechanism. Therefore it makes computer systems difficult to deal with the content of Wiki in a semantic way. A potential solution is to use ontologies which are established based on Wiki.

There has been much research on the construction ontology from free text. The major automated methods are the pattern-based method [1], the statistic based method [7], the dictionary based method [8], the correlation rules based  method [9], and the knowledge base method [10].

Constructing ontology from Wiki is different from  constructing ontology from the free text. First, the entries in Wiki can be considered as concepts directly. Secondly, the contents of entries of Wiki are shorter with few words. It is difficult to extract the relations without other accessorial corpora. Thirdly, Wiki allows users to freely create and edit description content using any Web browser. Therefore, there exists redundant data in Wiki?s content, which will disturb the forming of the hierarchy.

In this paper we propose a method to construct the Chinese domain ontologies from Wiki based on the entry segmenting and feature text (FT) extracting automatically.

The method does not need accessorial corpora. It extracts the FTs from the descriptions of entries to eliminate the redundant information.

The rest of this paper is organized as follows. Section 2 proposes the architecture for the .ontology construction.

Section 3 introduces the processing of automated ontology construction and the relative technology. Section 4 explains the experimental results on the wine ontology construction from baidu Wiki [4]. Finally, section 5 draws the conclusion.

2. The architecture of system   Figure 1 displays the architecture of our system to  automated construct the Chinese domain ontology from Wiki according the feature of the Wiki.

Ontology uses classes to represent concepts. It also supports taxonomy and non-taxonomy relations between classes. So, a common ontology learning system comprises three basic stages: the domain terminology extraction, concept hierarchy arrangement, and the non-taxonomy relations discovering [5]. The concept hierarchy   DOI    DOI    DOI 10.1109/ICNC.2008.717         arrangement is according the taxonomy relations.

Figue1 the architecture of system to automated construct  the Chinese domain ontology from Wiki  There are five steps to accomplish three basic stages in  our system. They are Web page pre-processing, entry segmenting and concept clustering, feature text (FT) extracting, FTs similarity calculating, and property finding which are described below  1) Web page preprocessing Wiki offer some entries about the same topic. Each  entry has a corresponding web page. These web pages have a similar structure, which has an entry and a description.

This step partitions Wiki web pages into entries and descriptions according the html tags and web page pattern.

The entries can be treated as the concepts directly.

2) Entry segmenting and concept clustering This step forms the concepts hierarchy using entries.

Chinese entry consists of terms(?). There is semantic information in the combinatorial sequence of these terms.

The system uses a hierarchical agglomerative clustering algorithm: ES (Entry Segment) algorithm to segment and cluster the entries (concepts) at the same time. The ES algorithm maps entries to concepts in a hierarchy according the name compounding. The hierarchy is rough. Some entries are located in an error place.

3) Feature text (FT) extracting This step deals with descriptions which are generated  by step1. In the description, several of information is mixed together. Only the Feature Text (FT), which embodies its dissimilarity with other entries, is needed. To eliminate the disturbed information, we extract the feature text from the description at first. The hierarchy generated by step2 is an assistant data in this step.

4) FTs similarity calculating The FT is a definition of an entry. It contains several  sentences. Each sentence contains terms. The system uses the proportion of cooccurrence terms to calculate the similarity between FTs. If the similarity is 1, there is a ?sameas? relation between entries. If the similarity between  FTs is larger than a threshold, they are sibling. The system locates the entry according its sibling?s location. This step revises the concept hierarchy.

5) Property finding In the ontology, the sibling concepts are differentiated  by the properties of concepts. Same property name and different property value form the classified rule. From a contrasting point of view, the system uses the hierarchy and FTs to find the property of concepts.

3. Automated ontology construction   3.1? Entry segmenting and concept clustering   Chinese entry?s name consists of terms. There is  semantic information in the combinatorial sequence of these terms. Most Chinese entry includes a subject term and several decoration terms. The subject term usually locate in the last portion of the entry. For example, an entry: ?drywhiterwine? ( ????? ) has a subject term ?alcohol?(? )and three decoration terms : ?dry? (? ), ?white? (?) and ?grape? (??). It has a meaning: alcohol, which has a dry taste, white color and brewed by grape.

There is no space between terms of Chinese entry name. So, the entry name must be segment at first. There are many tools for Chinese term segment. They are not fit for the specific domain. So, we design a name segment method, which is a byproduct of concepts clustering.

Because all the entries are talk about the same topic, the subject term will appear time after time. So, we use a hierarchical agglomerative clustering algorithm: ES (Entry Segment) algorithm to segment and cluster the entries (concepts) at the same time.

ES algorithm Input: All entries E=(e1,e2,...,en) Output: classification tree F 1:  for( i=1; i<=n; i++)  ci={ei}; fi=ei //add ci  as a leaf node in the tree F  2: for( n=max( len(fi)); n>1;n--) 2.1: using formula (4) to calculate the threshold t  2.2: for any cluster ci 2.2.1: for any cluster cj using formula (1) calculate the similarity sim(ci, cj) if  sim(ci,cj)>t ck = ci?cj;  cj=NULL;  fj=NULL; 2.2.2: ci=NULL;  fi=NULL;  fk is the n-1 right side sub string of fi add ck  as a node in the tree F  3: End.

1) Web pages preprocessing    2 ? entry segmenting and concepts clustering  Descriptions  3 ? feature text (FT) extracting    FTs  5?property finding    Concepts hierarchy  feedback  4 ? FTs similarity calculating    Non-taxonomy relations concepts entries  Ontology  Wiki web pages         ES algorithm is an improved hierarchical agglomerative clustering algorithm. At first, each entry is treated as a cluster. fi ,which is a string, is the feature of the cluster ci. Because the algorithm deals with the entries (concepts) name, the level of the hierarchy is less than the maximum length of entry name. The similarity between clusters is the measure of distance between clusters. Using formula (1) to calculate the similarity between the cluster ci and the cluster cj  ? =  ?= |)||,min(|   ),()(),( ji ee  k  jikji ffWkccsim ?              (1)  fi is the feature of the cluster ci. fj is the feature of the cluster cj,. They are strings also. The string consists of terms.

In the formula, k is the position of the term from the right side. The parameter )(k? embodies the effect of the position k of term. It ensures that the term located in the right side is more important than the left. The function  ),( jik ffW  is used to compare the terms at the same position k.

kk ?= 12)(?                               ?2?  { jkik jkik  jik ff ffffW  = ??=  1),(                      ?3?  We use formula (4) to calculate the similarity threshold t.

)()(   nkt n  k  ?? ?=? ?  =  ?4?  The ES algorithm maps entries to concepts in a hierarchy according the name compounding. For example, ?drywhitewine?(?????) is a subclass of ?whitewine? (????) ,and ?whitewine?(????) is a subclass of ?wine?(??? ), and ?wine?(??? ) is subclass of ?alcohol?(?). Most taxonomy relations between concepts are finding.

But, the hierarchy is rough. The named rule is not fit for every entry. So, some entries are put on a wrong position. For example, ?red_ alcohol?(??) is a sibling concept of ?wine? (???) in the hierarchy. In the fact, ?red_ alcohol? (??) is a shortened form of ?redwine? (? ???). It is a child concept of ?wine?(???). Another entry name is rooted in pronounce of its foreign name. for example ?PinotNoir?(???). It is a type of grape. There is not information about the grape in the entry name.

3.2. Feature text (FT) extract   In the description, several of information is mixed together. Only the feature text, which embodies its  dissimilarity with other entries, is needed. To eliminate the disturbed information, we extract the feature text from the description at first.

Where the FT of an entry appears?

In description of an entry, it contains its FT and other  information, which maybe talk about the subclass entries.

To distinguish these subclass entries, the definitions of subclass entries are a good choice.

For example, the description of ?wine?(??? ) consists of the definition, the classification (definition of ?redwine?(????), definition of ?whitewine?(????) and so on) , the history, the taste, and the culture about the ?wine?. The definition is the FT of the ?wine?(???). the description of ?redwine?( ???? ) consists of the definition, the classification (definition of ?CabernetFranc? (???), definition of ?CabernetSauvignon?(???) and so on). The definition of ?redwine?(????), which co occurrence in two description, is the FT of the ?redwine?(????).

To extract the FT of an object entry, we select correlative sentences in its ancestry entries at first.  The description of the ancestry entry consists of many paragraphs. If only the object entries name exists in a paragraph, all the sentences in the paragraph will be selected. If both the object entry name and other entries name exist in the same paragraph, the selected sentences range from the sentence that contains the object entry name to the sentence that contains other entry name.

Obviously, the similar sentence exists in both its description and its ancestry?s description is the FT of it. At the same time, the sentence is excluded from FT of its ancestry entry.

We use formula (5) to calculate the similarity between sentences.

|})|{||,}|{max(| |}|{|),(    sttstt ststtsssim  iiii  ii  ?? ???=         ?5?  The formula (5) calculates the proportion of the terms which cooccurrence in both S1and S2.

3.3. FTs similarity calculating   To eliminate the influence of the named rule of  entries?the entry is deleted from the FT. Then, the system uses the vector model to calculate the similarity.

|||| ),( ??  ??  ?  ?= ji  ji ji  FTFT  FTFTFTFTsim                   ?6?  If the similarity is 1, there is a ?sameas? relation between entries. For example, the ?red_rose_wine?(??? ???) is same as the ?rose_red_wine?(??????).

The ?dry_white_wine?( ????? ) is same as the ?dry_white?( ?? ). But, the entries maybe locate in different place of the hierarchy. For example, the ?rose_red_wine?(?????? ) is a subclass of the ?red_wine? (????). the ?red_rose_wine?(????? ?) is a subclass of the ?wine? (???). So, taxonomy relations must be corrected. If the similarity between FTs is larger than a threshold, they are sibling. The system locates the entry according its sibling?s location.

4. Experiments  The system select ?wine?(???) topic in Chinese baidu encyclopedia Wiki [4] . there are 221 entries about the topic. All the entries are correlated to the ?wine?. There are 19 classifications in the topic. The table 1 shows the proportion of entries name that can be segment.

Table 1: the proportion of entries name that can be segment  classification name can be segment  the number of entries  ?(wine) 30 36 83.33 ??(grape) 8 21 38.10 ???(grapery) 17 21 80.95 ???? 2 2 100.00 ??(farm) 2 2 100.00 ??(wine garden 2 2 100.00 ??(wine cabine 5 5 100.00 ?? (wine town) 2 2 100.00 ??(winery) 6 11 54.55 ??(wine cup) 2 2 100.00 ??(corp) 21 42 50.00 ??(area) 2 3 66.67 ?? manor 63 63 100.00 ?? 4 4 100.00 other 5 5 100.00 total 171 221 77.38   After executing the ES algorithm, we form a hierarchy.

The root node of the hierarchy is a virtual node-- ?thing?.

All of 19 classifications are its child nodes. We will compare this hierarchy with an expert-defined ontology that is downloaded from [11]. Precision and recall are then used to evaluate the hierarchy. We defined two kinds of precision evaluation methods, as follows. classification precision demonstrates the precision of the classification which the entries belong to; location precision shows the precision of the location in the hierarchy. The formula of classification  precision (C-precision), location precision (L-precision), and recall are listed below:  BA A +  =precision-C                        ?6?  DC C +  =precision-L                    ?7?  EA A +  =recall                          ?8?  A: entries that the system generates and belongs to the classification  B: entries that the system generates and do not belong to the classification  C: entries that the system generates and the expert defines whose locations are right.

D: entries that the system generates and the expert defines whose locations are error.

E: entries that the system does not generate and belong to the classification   Table 2: The relationships between expert ontology and the  hierarchy formed by ES algorithm classification A B C D E ?(wine) 30 2 22 8 6 ??(grape) 8 0 13 ???(grapery) 17 0 4 ???? 2 0 0 ??(farm) 2 0 0 ??(wine garden) 2 0 0 ??(wine cabinet) 2 0 2 0 0 ?? (wine town) 2 0 0 ??(winery) 6 0 6 0 5 ??(wine cup) 2 0 0 ??(corp) 21 0 21 0 21 ??(area) 2 0 1 ?? manor 63 0 0 ?? 4 0 0 other 5 50 0 total 168 52 51 8 50   After calculating the similarity among FTs, the  performance is improved. Table 3 listed the relationships between expert ontology and the hierarchy corrected by calculating the FTs similarity. Based on the foregoing, the classification precision C-Precision is up to 95%, L-Precision(C_L) is up to 90%, and the Recall is up to 95%.

The figure 3 shows a part of the wine ontology generated by system. The gray concept (????) locate in a error location. The main reason of the error is that too fewer information can be used. None other entry is similar to the concept. So, the error generated by ES algorithm can not revise.

Table 3: The relationships between expert ontology and the hierarchy corrected by calculating the FTs similarity  classification A B C D E ?(wine) 33 2 22 8 3 ??(grape) 18 1 3 ???(grapery) 21 2 0 ???? 2 0 0 ??(farm) 2 0 0 ??(wine garden 2 0 0 ??(wine cabine 2 0 2 0 0 ?? (wine town) 2 0 0 ??(winery) 6 0 8 0 3 ??(wine cup) 2 0 0 ??(corp) 42 3 42 0 0 ??(area) 2 0 1 ?? manor 63 2 0 ?? 4 0 0 other 5 0 0 total 206 10 74 8 10  Thing  ?  ??  ???  ??  ????  ????  ??  ??????  ??????  ?  ?????  ??  ???? ????  ?????  ????  ????  ? ? ?  ???  ??  ??????  ?????  ????  ?? 40 ?/?  ? 0.4% ??  ? 4?12 ?/???  ??? same_as property has_value  Entry name  Concept generated by system  Property value  is_a   Figue3 part of the wine ontology generated by system  5. Conclusion  In this paper we propose a novel method to construct  Chinese domain ontologies from Wiki based on the Entry segmenting and feature text (FT) extracting automatically.

The method does not need accessorial corpora and can construct ontologies well in terms C-precisions, L-Precision and recall.

In the future, we will improve our system in two directions. First, we will explore our method in a wide range. Secondly, we will mix the method with the pattern-based method in order to find more non_taxonomy relations.

