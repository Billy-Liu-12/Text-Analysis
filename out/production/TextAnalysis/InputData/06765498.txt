Organic Streams: Data Aggregation and Integration  Based on Individual Needs

Abstract?With the high accessibility of the social media, more and more people have been accustomed to sharing their personal contents across the social networks, which results in an explosive increase of data scale. In this study, in order to support information and knowledge discovery in big data, we propose an approach to aggregation and integration of personal big data from life logs in accordance with individual needs, which can benefit the sustainable information utilization process. In details, the organic stream, which is designed as an extensible data carrier, is introduced and developed to formulize and organize the personal big data, in order to extract dynamical individual needs from the tremendous amount of data posted through social media, and further aggregate and integrate the related data in a meaningful way, which can also facilitate the personalized information retrieval and reuse process. The architecture of the system with the foundational modules is given, and the experiment result is presented to demonstrate the usability and effectiveness of our approach.

Keywords?Big Data; Life Log; Data Aggregation; Data Integration; Individual  Need

I.  INTRODUCTION With the continuous development of social media (such as  Twitter, Facebook), more and more populations have been involved into this social networking revolution, which leads to a tremendous increase of data scale, ranging from the daily text data to multimedia data that describes different aspects of people?s life. For instance, every month, Facebook deals with 570 billion page views, stores three billion new photos, and manages 25 billion pieces of contents [1]. Big data, which ?includes data sets with sizes beyond the ability of current technology, method and theory to capture, manage, and process the data within a tolerable elapsed time? [2], are ?high-volume, high-velocity, and/or high-variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization? [3]. That is, it has become a big challenge to process such massive amounts of these complex big data, which has attracted a lot of attentions from academia, industry and government as well.

Life log, a kind of personal big data, has also attracted increasing attentions in recent years. Life logs include a variety of data, such as text, location, sound, images and videos, which are dynamically produced from multiple sources and with different data structures or even no data structures.

Consequently, it is difficult for an individual (end-user) to  utilize the useful information hidden in these records, such as user experience, knowledge, by simply processing the raw data from life logs. Therefore, it is necessary to find a way to effectively integrate and mine this kind of personal big data that records people?s information behaviors and social activities in both cyber space and real world, in order to provide people with valuable individualized service.

In our previous study, we have introduced and defined the so-called organic stream with the formal description, which can discover and represent the potential relations among data, in order to organize the raw stream data into the methodically pre- prepared form [4]. In this study, in order to facilitate the sustainable data utilization process, we propose and develop an effective way to aggregate and integrate the personal big data in accordance with individual needs, which can further benefit the information fusion and knowledge discovery process. We extend and refine the definition of organic stream to be an extensible data carrier to formulize and organize the personal big data from life logs in a meaningful and flexible way, which can assist the transformation from data to information, and from information to knowledge, and finally from knowledge to asset iteratively.

The rest of this paper is organized as follows. We give a brief overview on the related issues and works in Section II. In Section III, we introduce and extend the concept of organic stream into the data level, and further propose the mechanism to aggregate and integrate the personal big data in accordance with individual needs. We present the architecture of a data aggregation and integration system, and show empirical analysis results in Section IV. We conclude this study and give some promising perspectives on future works in Section V.



II. RELATED WORK Big data has drawn more and more researchers these years  [5-10]. Alsubaiee et al. [5] have built a parallel database system called ASTERIX, which tried to combine time-tested principles from parallel database systems with those of the Web-scale computing community, in order to deal with the ?Big Data? management challenges. Berkovich et al. [6] have developed a tool to cluster diverse information items in a data stream mode, which can enhance the available information processing resources for on-the-fly clusterization from diverse sources.

Hoi et al. [7] have proposed a feature selection algorithm in     order to solve the online feature selection (OFS) problem.

Zhang et al. [8] have presented a parallel rough set based approach using MapReduce for knowledge acquisition on the basis of the characteristics of data, in order to mine knowledge from big data. Menon et al. [9] focused on data warehousing and analytics platform of Facebook to provide support for batch-oriented analytics applications. Han et al. [10] introduced a big data model which used social network data for information recommendation related to a variety of social behaviors.

There are many analyses, as well as applications, which focus on life logs [11-16]. Yamagiwa et al. [11] have proposed a system to achieve an ecological lifestyle at home, in which sensors measure the social life log by the temperature, humidity, intensity of illumination related to human action and living environment closely. Hori et al. [12] developed a context-based video retrieval system which utilized various sensor data to provide video browsing and retrieval functions for life log applications. Hwang et al. [13] developed a machine learning method for life log management, in which a probabilistic network model was employed to summarize and manage the human experiences by analyzing various kinds of log data. Kang et al. [14] have defined metadata to save and search life log media, in order to deal with those problems such as high-capacity memory space and long search time cost.

Shimojo et al. [15] have re-engineered the life log common data model (LLCDM) and life log mashup API (LLAPI) with the relational database MySQL and the Web services, which can help access the standardized data, in order to support the integration of heterogeneous life log services. Nakamura et al.

[16] proposed a method to infer users? temporal preference according to their interests by analyzing the web browsing logs.

As for data aggregation [17-22], Ozdemir [17] has presented a reliable data aggregation and transmission protocol based on the concept of functional reputation, which can improve the reliability of data aggregation and transmission.

Jung et al. [18] proposed and developed two data aggregation mechanisms based on hybrid clustering: the combined clustering-based data aggregation mechanism and the adaptive clustering-based data aggregation, in order to improve both data aggregation and energy efficiency. Iftikhar et al. [19] have presented a rule-based tool to maintain data at different levels of granularity, which features automatic gradual data aggregation. Rahman et al. [20] proposed a privacy preserving data aggregation scheme named REBIVE (reliable private data aggregation scheme), which considers both data accuracy maintenance and privacy protection, in order to provide privacy preservation technique to maintain data accuracy for realistic environments. Wei et al. [21] have proposed three prediction-based data aggregation approaches: grey-model- based data aggregation (GMDA), kalman-filter-based data aggregation (KFDA), and combined grey model and kalman filter data aggregation (CoGKDA), which can help reduce redundant data communications. Ren et al. [22] proposed an attribute-aware data aggregation (ADA) scheme which consists of a packet-driven timing algorithm and a special dynamic routing protocol, to improve the data aggregation efficiency and further benefit the data redundancy elimination.

Research works have also been tried on data integration.

[23] defined a system for online data integration based on  the binary operations of relational algebra. Atkinson et al. [24] have proposed a framework of data mining, access and integration, to deal with the scale-up issue of data integration and data mining across heterogeneous and distributed data resources and data mining services. Sarma et al. [25] have described the approximation algorithms to solve the cost- minimization and maximum-coverage problems for data integration over a large number of dependent sources. Tran et al. [26] have developed a platform for distributed data integration and mining, in which data are processed as streams by processing elements connected together into workflows.

Gong et al. [27] introduced the architecture and prototype implementation to provide a dynamic solution for integration of heterogeneous data sources.



III. DATA AGGREGATION AND INTEGRATION In this section, based on the extension of organic stream  which is employed as a self-adaptive data carrier to meaningfully formulize and organize the personal big data from life logs, an integrated mechanism is proposed and developed for the user need-based data aggregation and integration.

A. Organic Streams: Extension and Refinement In our previous study [4], we have introduced and defined  the concept of organic stream, in order to benefit the meaningful organization of social streams. In this study, we extend the organic stream as an effective means to formulize and organize personal big data from life logs based on individual needs, which can assist the data aggregation and integration process.

The following definitions are given for the analysis and collection of the data that fit individual needs.

Heuristic Magnet  The Heuristic Magnet is the data that is aggregated to describe an individual?s continuous changing need, concern and interest.

Associative Entity: The Associative Entity is used to describe the related data entity that is aggregated in a data collection in accordance with individual needs, which can further be employed to describe the relationships among data.

Collective Body The Collective Body is the meaningfully aggregated and integrated data collection based on individual need, concern and interest.

We discover and mine individual needs by analyzing and aggregating his/her related data, which are represented by Heuristic Magnets, and will further become the aggregating center. The data related to this center will be aggregated as the Associative Entity. Finally, the Collective Body is generated to describe the relationships among data according to individual need, concern and interest.

Based on these discussed above, we extend the concept of organic stream as a data carrier in the individual need-based data aggregation and integration process.

(1)  where,  Hm = { Hm[u1, t1], Hm[u2, t2], ..., Hm[ux, ty]}: To represent a nonempty set of Heuristic Magnet, where Hm[ui, tj] denotes the Heuristic Magnet that indicates the need for a specific individual ui in a specific time period tj.

Ae = {Ae1, Ae2, ?, Aen}: To represent a set of Associative Entities based on inherent or potential relations to the individual needs.

R: To describe the relationships among Heuristic Magnets and Associative Entities in organic stream.

These relationships can be defined as follows.

Heuristic Magnet ? Associative Entity: The basic relationship between Heuristic Magnet and Associative Entity in organic stream, which is used to describe relationships between aggregated data and individual needs.

Heuristic Magnet ? Heuristic Magnet: The relationship among Heuristic Magnets in organic stream, which is used to describe the similarities among different individual needs.

Associative Entity ? Associative Entity: The relationship among Associative Entities in organic stream, which is used to describe the relationships among aggregated data in a Collective Body.

Following the definitions given above, in organic stream, the raw data can be aggregated according to the Heuristic Magnet ? Associative Entity relation, and further be integrated based on Heuristic Magnet ? Heuristic Magnet relation and Associative Entity ? Associative Entity relation, which can be re-organized in an iterative and self-adaptive way.

B. Data Aggregation and  Integration Based on Individual Needs Based on the discussions above, in order to capture an  individual?s time-changing needs, the whole time period should be divided into several time slices (e.g. one day, one week), in which the developed TFIDF method can be employed to extract the data to represent individual needs, concerns and interests within this specific time slice. After that, the data related to the extracted individual need can be selected and aggregated according to the Heuristic Magnet ? Associative Entity relation in a hierarchical way. Based on these, the Collective Body can be generated, in which the selected data shall be integrated and organized according to the Heuristic Magnet ? Heuristic Magnet relation and Associative Entity ? Associative Entity relation. All the Collective Bodies compose the organic stream in an extensible way. The procedure for the data aggregation and integration process is shown as follows.

Step 1: For the whole time period T, divide it into a series of time slices{t1, t2, ?, tn}, accordingly, divide the  data set M  into several sub-set Mt in each time slice ti.

Step 2: For each  in the time slice ti, calculate the weight based on the TFIDF method, in order to extract the  Heuristic Magnet set Hm = { Hm[u1, t1], Hm[u2, t2], ..., Hm[ux, ty]}.

Step 3: For each Hm[ui, tj], according to the Heuristic Magnet ? Associative Entity relation, select the related data into the Associative Entity set Ae = {Ae1, Ae2, ?, Aen}.

Step 4: Use the data in set Hm and Ae to generate the Collective Body as set Cb.

Step 5: Calculate the Heuristic Magnet ? Heuristic Magnet relations and Associative Entity ? Associative Entity relations in each Collective Body Cbk, record all the relationships in the relation set R.

Step 6: Return the Heuristic Magnet set Hm and Associative Entity set  Ae with the relation set R to form the integrated data set M?.



IV. EXPERIMENT AND ANALYSIS In this section, after the introduction of the architecture of  the basic functional modules for data aggregation and integration, we show and discuss experiment analysis results to illuminate the feasibility of our proposed method.

A. Functional Modules The architecture for the individual need-based data  aggregation and integration is shown in Fig. 1, which consists of five major components: Data Collector, User Need Extractor, Data Aggregator, Data Integrator, and Data Relation Analyzer.

Fig. 1. Functional modules for data aggregation and integration  As shown in Fig. 1, the Data Collector, which is the fundamental function module in this system, is used to collect the raw data from individuals and connect with the major database which saves the life logs of all users. The User Need Extractor is employed to extract individual needs, concerns and interests from his/her life logs to generate the heuristic magnets.

In addition, the Data Aggregator works for aggregating the data related to the extracted individual needs, while Data Integrator is responsible for integrating the heuristic magnets with the Associative Entities. Finally, Data Relation Analyzer analyzes the major relations among these data and further organizes them to generate the collective bodies.

B. Experiment Analysis The Twitter data has been utilized to conduct our  experiment in order to demonstrate the feasibility of our proposed method.

Fig. 2. An example of experiment analysis result for data aggregation    Fig. 3. Conceptual image of data integration    We obtained the Twitter dataset from a list of Twitter users selected from a famous Twitter list named ?twitter?, as well as some of their followers. The majority of the tweets that are collected for our experiment are published in April 2013.

Finally, a total of 320,000 tweets were collected. In order to  illuminate our method, in this case, during the time period April 4 to 16, the keyword, ?Boston?, is extracted as the Heuristic Magnet using the TFIDF method, which can indicate the interest or need within this group of users. And then those data that is related to ?Boston? is aggregated to form the     Associative Entities. An example of experiment analysis result is shown in Fig. 2.

We further integrate the aggregated data according to the relation R discussed above. As shown in Fig. 3, the selected Heuristic Magnet became the aggregating center, and the related data converged to it as the Associative Entity.

According to the relation, Heuristic Magnet ? Associative Entity, the distance from Associative Entity to the center namely the Heuristic Magnet, describes the relevance between them, that is, the more related Associative Entity would be closer to the center. Moreover, according to the relation, Associative Entity ? Associative Entity, the Associative Entities which have the same relevance to the Heuristic Magnet will distribute in the same layer. For instance, in Fig. 3, all Associative Entities distribute in four layers, while in each layer, the more related data will stay closer to each other.

Finally, the Heuristic Magnet with these related Associative Entities will form the Collective Body.



V. CONCLUSION In this paper, we have introduced and extended the organic  stream to aggregate and integrate personal big data from life logs according to individual needs, in order to benefit the sustainable information utilization process.

We developed and refined the organic stream as an extensible data carrier, in which we defined Heuristic Magnet, Associative Entity, and Collective Body to describe the individual need, related data, and integrated data set respectively. The major relations: Heuristic Magnet ? Associative Entity, Heuristic Magnet ? Heuristic Magnet, and Associative Entity ? Associative Entity, were proposed and studied in order to organize the aggregated data in a meaningful way. Based on these, we developed a mechanism to aggregate and integrate the personal big data in accordance with individuals? time-changing needs, which can further support the information fusion and knowledge discovery process. Finally, we gave the system architecture with major functional modules and the experiment analysis results to show the feasibility and effectiveness of our proposed method.

As for our future work, we will develop and complete our system with the improved mechanism to realize the data aggregation and integration process in real world situations.

We will further quantify the relations in organic stream. The classification of the aggregated data, and the data quality assurance will also be considered, in order to deal with heterogeneous life log data from multiple sources. Moreover, a unified physical storage mechanism in regard to these diverse data will be developed, and we will try to utilize the organic stream in the information fusion and knowledge discovery process, in order to realize the sustainable utilization.

