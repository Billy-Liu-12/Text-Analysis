<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">2004 IEEE

Abstract - Nowadays, association rules mining has become one of the predominate tasks employed to discover informotive rules from large data set to support decision-moking. One of the major dflculties in applying associations mining technique is the setting of an appropriate minimum support.

Unfortunately, A large support threshold would hinder the discovery of some rare but informative rules. In this paper, we propose a novel algorithm called CBW,,, By keeping and utilizing the set of frequent itemsets MF and on auxiliary set of infrequent a-itemsets MFm the proposed CBW,.

algorithm can significantly reduce, over on order of magnitude, the computation time spent on re- discovery offrequent itemsets.

Keywords: Association rules, frequent itemsets, fast remining, minimum support 1 Introduction Mining association rules from a large database of business data, such as transaction records, has been a hot topic withii the area of data mining. This problem is motivated by applications known as market basket analysis to find relationships between items purchased by customers [Z], that is, what kinds of products tend to be purchased together.

An association rule is an expression of the form X j Y, where X and Yare sets of items. Such a rule reveals that transactions in the datahase containing items in X tend to contain items in Y, and the probability, measured as the fraction of transactions containing X also containing Y, is called the confidence of the rule. The support of the rule is the fraction of the transactions that contain all items both in X and Y.

For an association rule to hold, the support and the confidence of the rule should satisfy a user- specified minimum support, called minsup, and minimum confidence, called minconf; respectively.

The problem of mining association rules is to discover all association rules that satisfy minsup and minconj In general, the work of association rules mining can be decomposed into two phases: ( I )  Frequent itemsets generation: find out all itemsets that sufficiently exceed the minsup, and (2) Rules constmction: from the frequent itemsets generate all association rules having confidence higher than the minconJ Since the second phase is straightforward and less expensive, we concentrate only on the frst phase for finding all frequent itemsets.

One of the problems in applying associations mining method to read world applications is that users have to specify an appropriate support threshold in advance. But in fact, most users have no knowledge about the characteristics of the data and thus need to employ consecutive mining queries with different thresholds to obtain the best results. Though in the  past few years, researchers have made substantial improvements over the original Apriori algorithm, the problem of how to provide an on-line mining environment is still a challenge.

In this paper, we propose a new algorithm, called CBW,, an online version of our previously proposed    CBW,, an online version of our previously proposed CBW algorithm [SI. Adopting tbe concept of preprocessing and materialization, the CBW, algorithm stores the set of frequent itemsets MF and an auxiliary set of infrequent a-itemsets M F m  and utilize them to employ a bi-directional search strategy in frequent itemset generation. Empirical evaluations show that our algorithm can maintain its performance even at relative low support thresholds, and can significantly reduce, over an order of magnitude, the computation time spent on re-discovery of frequent itemsets..

The rest of this paper is organized as follows. A review of previous work is given in Section 2. In ' 0-7803-8566-7/04/$20.00 0 2004 IEEE.

Section 3, we describe the proposed algorithm for finding frequent itemsets. Empirical evaluations of our algorithm on lBMs synthetic data set are described in Section 4. Finally, conclusion and future work are stated in Section 5.

2 Previous work Agganval and Yu [l] considered the on-line generation of mles and provided a lattice based approach, called adjacency lattice, to pre-fine and pre- store the primary itemsets. They analyzed the on-line queries and then supplied several adjacency lahice based algorithms corresponding to the kinds of on-line queries. Users with their on-line mining framework are free to launch different queries at different thresholds. The approach, however, may suffer the following problems: 1. If the adjacency lattice is complex and large, the preprocessing time for constructing the 1ati:ice will be unacceptable.

It is difficult to trade off the amount of pre-stored data against the query time.

In [ 101 the authors proposed the concept of using materialized itemsets for fast mining of association rules. Their approach divided the database into a set of non-overlapping partitions according to sc.me attributes, e.g. education type of customers, store location, product category, and then generate the frequent itemsets in each partition over the lclcal threshold. Then, tbe positive borders [9] corresponding to the frequent itemsets in eich partition are computed. Finally, all the positive borders are combined to re-mine the new frequent item;ets with supports greater than the global threshold. ?his approach, however, works only when the new queries with milisup larger than the presetting threshold. If users adjust minsup below the threshold, the materialized frequent itemsets fail to generate all associations. The process of frequent itemsets generation needs to be performed afresh.

2.

Without any pre-computation, Carma [3] is an algorithm intended to bring frequent itemsets computation on-line using only two database scms.

During the fmt scan, the algorithm continuou.sly constructs a lattice of potential frequent itemsets. The algorithm repeatedly displays the result and the ur.ers are free to specify the threshold at any time. At the second scan, it determines the precise support of each set of lattice and constantly removes all small itemsets.

Our observation about Carma is presented as follows: 1. The performance of Canna is better than Apriori- like algorithms when the threshold is much small. However, it cannot defeat Apriori-like algorithms when the threshold is larger than a critical value.

The performance of Carma is worse than on-line    The performance of Carma is worse than on-line mining with preprocessing, because the whole mining procedure still has to be carried out repeatedly. If the data is too large to be handled in real-time, the performance of Carma will be even worse. In this situation, Carma itself needs to be performed iteratively.

2.

3 The proposed CBW,, algorithm 3.1 Algorithm basics As revealed in the literature [4][5], the performance bottleneck of frequent itemsets generation lies in two aspects: the database scan and support counting. Most contemporary efficient algorithms for frequent itemset generation are devoted to attack these two issues. We notice, however, almost of these algorithms suffer from performance degradation as the minimum support decreases; they behave well under large minimum supports, hut as the minimum support decreases, their performances decrease significantly. Unfortunately, in some applications, the minimum support must be specified relatively small to mine interesting pattems from database.

The effect of a lower support threshold has two facets: On the one hand, much more candidate itemsets are generated and inspected, and on the other band, the cardinalities of maximum frequent itemsets become larger. Therefore, the computation of support counting grows dramatically. To alleviate this problem, we have proposed an algorithm called CBW (Cut the space &amp; employ Both-Ways search) [8]. The basic idea is illustrated in Figure 1.

Viewing the solution space as a pyramid that contains frequent itemsets located at different levels equal to their cardinalities, we first pursue an appropriate cuffing level a to divide the space into two different parts. After identifying all frequent itemset at this level, we perform a downward search to enumerate all frequent itemsets below the cutting level a and determine their support values, followed by an upward search to enumerate all frequent itemsets with cardinalities larger than a.

Itemset Pyramid frequent itemsets Cufting /eve/ a / auent 1-ihnesets Figure 1. Concept illustration of CBW The insight behind this paradigm is that no approach based on single algorithmic strategy performs the best in all cases [4][5]. Bottom-up search will suffer too many database scans as well as wasted set enmeration to count the supports of candidates at higher cardinality levels, especially in the case of low support threshold. Top-down search, on the other hand, can not utilize the anti-monotone property to prune the search space. Furthermore, according to the investigation in [4], vertical intersection performs much better in counting the support values of candidates with larger cardinality, while horizontal counting favors the opposite situation. All of these suggest hybridizing different algorithmic approaches to attack the itemset mining problem.

Our paradigm has the following features. First, by guessing the appropriate cutting level, we can identify the most promising cardinality to perform downward search. If o w  guess is correct, i.e., most of the itemsets under this level are frequent, then the effectiveness of Apriori pruning is overwhelmed by its cost, Therefore, it is more economic to enumerate all candidate itemsets and count their supports within one    candidate itemsets and count their supports within one datahase scan. Second, for upward searching frequent itemsets with cardinalities larger than the cutting level, the synergy gained from the Apriori pruning and vertical intersection can save lots of unnecessary computations.

Before carrying out the paradigm shown in Figure 1, we need to determine an appropriate cutting level, which as will be seen later is a crucial factor to the effectiveness of CBW. If the cutting level is too low, unnecessary intersections will happen frequently during upward searching. On the contrary, if the cutting level is too high, the downward search will spend much more time in itemsets enumeration and counting their supports. Therefore, we have to trade the favors between upward search and downward search to fmd an appropriate cutting level. An insightful idea is to pursue the average Cardinality of frequent itemsets, expecting that most of the frequent itemsets will appear in this level. This value, however, is impossible to be obtained without knowing the frequent itemsets. We thus adopt a simple heuristic described in the following.

Defmition 1. Let D be a transaction table and ti the i- th transaction. The cutting level a is defmed below: where INT[r] denote the nearest integer of r, for r 2 1, and fihj,, be the set of items in f ,  with support larger than minsup. More specifically, fihinq= {x I x E f ,  and sup(x) 2 minsup} For an illustration, consider the transaction data in Table I .  Assume that minsup = 40%. Then, the frequent 1-itemsets include (A], {B}, {C}, and {D}.

The cutting level athus is (3 + 2  + 1 + 4 + 3  + 2  + 3 + 3 + 3  + 3 ) /  10 - 3 .

Table 1. An example transaction data 3.2 Algorithm detail CBW, is an on-line version of CBW and inherits most of the features of CBW. The main difference is that CBW,. stores the set of frequent itemsets MF and the set of infrequent a-itemsets MTF, according to a presetting minimum suppod threshold prims, and utilizes them to employ a bi-directional search strategy in frequent itemset generation. For this reason, CBW.. does not undergo repeating the whole procedure as minsup is tuned above or below pri.w.

The basic process of CBW,. is described below.

Case 1. minsup &lt; p r i m We perform the CBW.. in this case as follaws.

First, we collect the frequent a-itemsets stored in .W and the infrequent a-itemsets stored in MFm,  and perform the downward search. The search strategy is illustrated in Figure 2. For each transaction, only its subsets that are subsets of the infrequent itemsets in M F c  need to he generated and counted. After finding all of the frequent itmesets below cutting level a, we then perform the upward search starting from the frequent itemsets in level a.

Figure 2. Searching strategy of CBW,. with minsup lower thanprims Case 2. minsup &gt;prim In this case, there is no need to generate the frequent itemsets. All of the qualified frequent itemsets have been materialized in MF. We only have to filter those with support lower than minsup.

Detail description of the CBW,, algorithm is given in Figures 3,4,  and 5, where sup(X) denotes the support of an itemset X and T denotes the set of fidlisfs For an illustration, let us consider Table 1 agrin.

Assume that a is 3 and prims is 3. For the case that minsup &lt; prims, as shown in Figure 6, we assume minsup = 2.

minsup = 2.

Input: The transaction database D and minimum Output: The set of frequent itemsets F; 1. if minsup &lt; prims then 2. AF = (4 sup@') t minsup, X E MF=}  U (v Y ~ M F a n d I v = a ) ; 3. DF = Dwnsearch(0, A F ,  a, minsup); 4. UF = Upsearch(AF, minusup); 5. F = D F u U F ; 6. else 7 .

8. endif 9. returnF; support minsup; F =  (4 X E MFandsup(X) t minsup}; Figure 3. Algorithm CBW, 1. for i = 1 to do 2.

3.

4.

5. x.count++; 6. end for 7. DF=(XI sup(X) 2 minsup); 8. retnrnDF; scan the i-th transaction ti; delete the items in tibut not in .aF, for each subset X of ti and 2 2 5 a do Figure 4. Procedure Dwnsearch 2.

3. k=a,Fk=F,; 4. repeat transform borizontal data D into t-id lists; 5 .  w, 6. Ck= the set of new candidate k-itemsets generated from FM; 7. for eachXg ck do 8.

9.

IO. endfor 1 I.

13. unti lFk=O 14. return UF; perform bit-vector intersection on X; compute the support ofX, sup(X); Fk = (4 sup(X) t minsup, X E ck}; 12. UF = UF U Fk; Figure 5.  Procedure Upsearch The infrequent a-itemsets are {A, B, C}, {A, B, E}, (A, C, D), (A, C, D) and {A, D, E), and the frequent itemsets with cardinality of a are {A, B, D}, {B, C, D}, (B, C, E), {B, D, E} and (C, D, E). We first perform downward search for frequent 3-, 2- itemsets, obtaining itemsets {A, B, D), {B, C, D), , I Figure 6. Find out all frequent itemsets from the database in Table 1 with lower minsup using CBW,, 4 Empirical evaluations To evaluate the performance of CBW,,, we compared it with CBW on two synthetic data sets, T10.14.DIOOK and T10.14.D200K, which were generated using the IBM data generator [2]. The presetting minimum support, prims, was specified as 0.5%. All experiments were performed on a HP LH6000R workstation with 1GB RAM and 18GB HD running Windows 2000 Server.

Two different cutting levels, 3 and 4, were used.

The results are shown in Figures 6 and 7. It can be Observed: 1. A good cutting level is critical to the performance of CBW and CBW,,, cutting at levels below or above the best value yields not    only poor performance but also significant performance degradation as minsup decreases.

2. When minsup t prims, there is no frequent itemset generation for CBW,, and so CBW, clearly outperforms CBW, with an ,order of magnitude faster.

When minsup cprims, the MFa scheme makes CBW,. again beat CBW but the performance gap decreases as the minsup decreases. This is because that there are more infrequent itemsets at the cutting level becoming frequent, and so CBW,. spends more time in upward searching.

3.

-X-CBWon, cl=4 -X-CBW, c l 4 -A- CBWon, cl=3 + CBW, ck3 3 60 p 40 h B zn 0 1 1.00% 0.75% 0.50% 0.25% minsup Figure 6. Execution times of CBW,. and CBW using TI 0.14.Dl OOK 1.00% 0.75% 0.50% 0.25% minsup Figure 7. Execution times of CBW.. and CBW using T10.14.D200K 5 Conclusions In this paper, we have adopted the concept of preprocessing and materialization to store the frequent itemsets over a presetting minsup and the infrequent itemsets, with cardinality of a. Utilizing these materialized itemsets, we have proposed the CBW,.

algorithm to facilitate the process of employing consecutive mining queries with different threshold!; to obtain the best mining rules. When the user-specified minsup is larger than prims, CBW,. can generate all frequent itemsets immediately by scanning the stored frequent itemsets. On other hand, when the threshold is smaller thanprims, CBW,. also can responds to users efficiently by utilizing an auxiliary set of infrequenl E- itemsets, without repeating the whole mining procedure. Our CBW.. algorithm has ht:en incorporated into an online multidimensional association rule mining system currently under development [6]. In the future, we will incorporate into CBW,, the taxonomy information and extend it to allow multiple minimum support specification.

