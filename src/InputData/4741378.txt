CRMMS An Algorithm of Classification Rule Mining with Multiple Support Demand

ABSTRACTT ?   The paper presents an algorithm CRMMS of classification rule mining with multi-support demand, which adopts the frequent classification item-set tree FCIST to organize the frequent pattern sets, and builds the array-based threaded transaction forest ATTF, and applies multiple supports for classification rules mining. The CRMMS uses the breath first strategy assisted by the depth first strategy, and adopts pseudo projection, which makes it unnecessary to scan the database, and to construct the projected transaction subsets repeatedly.

The algorithm reduces the memory and time cost, and makes the projection more efficient and scalable. The CRMMS algorithm can be used in the consumer?s basket analysis, consumption behavior rules mining in the retailing industry.

Keywords: frequent pattern, rules mining, Classification rule, FCIST, ATTF.

1. INTRODUCTION  The association rule mining is an important research topic of data mining, especially the multi-support association rule mining. The current researches on classification rules mainly focus on the mining of the unevenly distributed and huge databases.

The existing algorithms of classification rules mining support either multi-support thresholds or scalability of store memory. These algorithms mainly adopt the strategies of breadth-first, depth first, or both of them. However the algorithms with breath first strategy, like Apriori [1][2][3] are inefficient for dense datasets that contain long patterns. The algorithms with depth first strategy such as FP-Growth [4][5], H-Mine [6] and etc, do not scale to large sparse datasets and are time-wasting in mining dense datasets. Some algorithms like OP[7][8] putting breath first and depth first strategies together but using single support are not good for mining unevenly-distributed business databases. Although algorithms like CRM-PP [9] adopt multi-support method, they are not scalable for store space with the limitation of memory.

This paper presents a novel algorithm, multi-support algorithm CRMMS, for mining classification rules in business databases, which is efficient on dense databases at all levels of support threshold, and scalable to very large databases. Our contributions are as follows: first, we present frequent classification item-set tree for constructing frequent pattern sets, and adopt both breath first and depth first strategies, which enhances the build of frequent pattern tree. Second, we propose an array-based format for classification tree for pseudo projection with high efficiency and low memory cost, and adopt multi-support thresholds to mine more potential and effective association rules. Finally, we design and implement a  multi-support algorithm CRMMS of classification rules mining. And with the compare experiments with Apriori, FP-Growth and OP, CRMMS has certain advantages in mining efficiency and scalability of the large business databases.

2. CONSTRUCTION OF FREQUENT  CLASSIFICATION ITEM-SET TREE  2.1. Problem Descriptions Definition 1 The classification database D=(O,I,C), in which O is the finite set of data objects, I is the set of data attributes, and C is the set of classification items.

The data attribute set also known as an item set, I={i1,i2, ,im}, in which ik is called data attribute. The data object set O={(tid1 t1) (tidn tn)}, in which tidk tk presents a data object or a transaction, and tidk is the identifier of the object or transaction, tk is the attribute set of classification objects, and tk  I C, tk ?C = 1. The classification item set C={c1 cs}, in which ck stands for a classification item.

According to the definition above, the database in table 1 can be described as: I ={a,b,c,d,e,f,g,h,j,k,l,m,p,s}; C={ c1, c2}; O={(01,t1),(02,t2) ,(08,t8)} composed by 8 transactions, in table 1.

c2b e k s08  c2a d e g f j p07  c1a k l06  c2a e f m p s05  c2b e f m p04  c1a b e j p03  c2a c e f g j l p02  c1a b c d e f h p s01  ClassItemsTid  c2b e k s08  c2a d e g f j p07  c1a k l06  c2a e f m p s05  c2b e f m p04  c1a b e j p03  c2a c e f g j l p02  c1a b c d e f h p s01  ClassItemsTid  Table 1. The classification database  Definition 2 (Classification) pattern p I is frequent if support(p) minsupk, minsupk is the minimum support(threshold) of class ck.

?  Definition 3 If support (X {ck} ,T) minsupk , and support (X {ck} ,T) / support (X,T) minconf, X< I ,ck  C , then X {ck} is a classification rule.

2.2. Frequent Classification Item-set Tree Frequent classification item sets can be represented by a tree, namely frequent classification item-set tree, abbreviated as FCIST, and in order to avoid repetitiveness, we impose an ordering on the items.

FCIST is an ordered tree, where each node is labeled by an item, and associated with a weight. The ordering of items labeling the nodes along any path (top down) and the ordering   DOI 10.1109/CW.2008.123     of items labeling children of any node (left to right) follow the imposed ordering. Each frequent classification item set is represented by one and only path starting from the root and the weight of the ending node is the support of the item set. The null root corresponds to the empty item set. The weights associated with nodes need not be actually implemented.

Each node has its own classification projected transaction set (abbreviated as CPTS). CPTS consists of transactions that support the item set represented by the path starting from the root to the node. CPTS of the null root is the original database.

CPTS of any node other than the null root is obtained by projecting transactions in CPTS of its parent node, according to the priori property. One CPTS is filtered if each transaction in the CPTS only maintains items that contribute to the further construction of descendants. In other words, filtered CPTS of a node only contains items that label the sibling of its parent node. Otherwise, the CPTS is unfiltered. Apparently, items in filtered CPTS are local frequent in its parent CPTS.

Each FCIST node is represented by[i,w1, ,ws]followed by its own CPTS, ws is the weight of item i belonged to the classification cs. Let  be the dictionary order, then the classification database in Table 1 can be represented as Figure 1 with the support thresholds minsup1 2 and minsup2 3.

The path[,,] [p,2,4] [e,2,4] [a,2,3] represents the classification item sets{a,e,p,c1} with support of 2 and{a,e,p,c2} with support of 3. The unfiltered CPTS of the root, namely priori classification database has 8 transactions, in which transactions 01, 02, 03, 04, 05, 07 support item p, and transactions 01 and 03 belong to classification c1, transactions 02, 04, 05 and 07 belong to classification c2. So the CPTS of [p,2,4]is composed by such 6 transactions. The CPTS of all the nodes except the root is filtered, only containing the brother nodes ahead.

c2b e k s08 c2a d e g f j p07 c1a k l06 c2a e f m p s05 c2b e f m p04 c1a b e j p03 c2a c e f g j l p02 c1a b c d e f h p s01  c2b e k s08 c2a d e g f j p07 c1a k l06 c2a e f m p s05 c2b e f m p04 c1a b e j p03 c2a c e f g j l p02 c1a b c d e f h p s01  c1a03 c1a01 c1a03 c1a01  [ , , ]  [ a,3,3 ] [ b,2,2 ]  [ a,2,0 ]  [ e,2,5 ]  c2b08 c2a07 c2a05 c2b04 c1a b03 c2a02 c1a b01  c2b08 c2a07 c2a05 c2b04 c1a b03 c2a02 c1a b01  [ a,2,3 ]  c1a03 c1a01 c1a03 c1a01  [ b,2,2 ]  [ a,2,0 ]  [ f,1,4 ]  c2a e07 c2a e05 c2b e04 c2a e02 c1a b e01  c2a e07 c2a e05 c2b e04 c2a e02 c1a b e01  [ a,1,3 ] [ e,1,4]  c2a07 c2a05 c2a02 c1a 01  c2a07 c2a05 c2a02 c1a 01  [ p,2,4 ]  c2a e f07 c2a e f05 c2b e f04 c1a b e03 c2a e f02 c1a b e f01  c2a e f07 c2a e f05 c2b e f04 c1a b e03 c2a e f02 c1a b e f01  [ a,2,3 ]  c1a03 c1a01 c1a03 c1a01  [ b,2,0 ]  [ a,2,0 ]  [ e,2,4 ]  c2a07 c2a05 c2b04 c1a b03 c2a02 c1a b01  c2a07 c2a05 c2b04 c1a b03 c2a02 c1a b01  [ a,2,3 ]  c1a03 c1a01 c1a03 c1a01  [ b,2,0 ]  [ a,2,0 ]  [ a,1,3 ]  [ f,1,4 ]  c2a e07 c2a e05 c2b e04 c2a e02 c1a b e01  c2a e07 c2a e05 c2b e04 c2a e02 c1a b e01  [ a,1,3 ] [ e,1,4]  c2a07 c2a05 c2a02 c1a 01  c2a07 c2a05 c2a02 c1a 01  [ a,1,3 ]  Figure.1 The FCIST in the example  2.3. Representing CPTS by ATTF and Pseudo-projecting  An array-based threaded transaction forest, ATTF, is adopted to represent CPTS because of its low memory spending. And two different pseudo-projecting methods are used to construct the FCIST. ATTF consists of two parts: an item list (IL), and a forest. Each local item in CPTS has an entry in the IL, with three fields: an item-id, multiple supports, and a pointer, namely e.item, e.conut and e.link respectively. And the multiple supports e.count can be divided into ||C|| different parts, called e.count (k) representing the support in  classification ck. Entries in IL are ordered by the imposed ordering. Each transaction in the CPTS is represented by one and only one path in the forest. Each node in the forest is labeled by an array [i,w1, ,ws] where i is an item and wk is a count that is the number of transactions in classification ck represented by the path starting from the root ending at the node. Items labeling nodes along any path are sorted by the same ordering as IL. All nodes labeled by the same item are threaded by the entry in IL with the same item. ATTF is filtered if only local frequent items appear in ATTF, otherwise unfiltered.

For example, the filtered ATTF representation for the CPTS of the null root in Figure 1 is shown in Figure 2, where the path [a,3,3]-[b,2,0]-[e,2,0]-[p,2,0] represents transaction 01 and 03, [b,0,2]-[e,0,2]-[f,0,1]-[p,0,1] represents transaction 04, and so on. The third item in FIL is item e, with multi supports 2 and 5 in classifications c1 and c2 respectively. The pointer ( arrow-headed broken line) links the nodes [e,2,0],[e,0,3] and [e,0,2] together.

From the ATTF representation of the CPTS of a parent node in FCIST, we can project its children?s ATTFs either in a bottom up way or in a top down way. The FCIST in Figure 1 is constructed in a top down projecting way, so we will introduce this way in the paper.

In the top down way, the pseudo ATTF of a child CPTS consists of sub forest whose leaves are threaded together in its parent ATTF. Firstly, we choose the IL items one by one from the parent ATTF in the imposed ordering. Secondly, by traversing the sub forest threaded by the chosen IL, we can delimitate the CPTS by re-threading nodes in the sub forest, count the support of each item in the sub forest by re-calculating the count of each node according to the leaves? multi supports. For example, in Figure 3, the sub forest whose leaves, [f,0,3] and [f,0,1] are threaded by the entry of item f, compresses transactions that support item f. By traversing this sub forest, we get local multi supports of item a, b and e of [0,3],[0,1] and [0,4] respectively, and the count of first node label by a is changed from [3,3] to [0,3], and node [b,0,2] is adjusted into [b,0,1], node [e,0,2] into [e,0,1]. Therefore, the sub forest of the pseudo ATTF consists of two paths, [a,0,3]-[e,0,3] and [b,0,1]-[e,0,1]. The IL is {([a,0,3],ptr), ([b,0,1],ptr), ([e,0,4],ptr)}. This is a recursion process, e.g. the child ATTF of the node [e,0,4] in Figure 3can be pseudo projected as shown in Figure 4.

Such method of pseudo projection avoids recursively building projected transaction set, which is in the same number as frequent item sets. This method is not only space efficient in that no additional space is needed for any child ATTF, but the counting and projecting operation is also highly CPU-efficient.

Especially we adopt different supports for classification items which makes the FCIST construction more efficient.

3. ALGORITHM CRMMS  Now we present the multi-support algorithm of classification rules mining, abbreviated as CRMMS, which integrates depth first and breadth first strategies, array-based threaded tree forest representation and filtered projection. First, CRMMS creates a null node for the root of the FCIST, whose CPTS is the priori classification database. Second, CRMMS calls BreadthFirst to grow the upper portion of FCIST by breadth first search until the reduced set of transactions can be held in a memory based structure. Third, DepthFirst is called to build the lower portion of FCIST by depth first search.

MSC O, ,Minsup create FCIST root R and let R.PTS=O;  BreadthFirst (R,L, ,Minsup); DepthFirst (T, ,Minsup);   BreadthFirst attaches counting vectors to all nodes at the current level L to accumulate local supports for items in the CPTS of each node. The counting vector has an element for the item of each sibling node that is before the node attached according to the imposed ordering . We project the transaction t along the path from the root to nodes at the current level L and accumulate counting vectors. If a transaction can be projected to a level L node and contribute to its counting vector, it may also be projected to level L+1, therefore record it in D?. Otherwise it can be removed from further consideration. Then we create children for each node at the current level L for its local frequent items whose element in the counting vector has a value over the multi-support thresholds. The BreadthFisrt is a recursive procedure. We use the available free memory as parameter to control breadth first search process.

BreadthFirst(R,L, ,Minsup,D) for each node v at level L top down by do CreateCountingVector(v); D?={}; for each transaction t in D do  ProjectAndCount(t,L,D?) for each node v at level L do  GenerateChildren(v); If(NoMem(D?)) then BreadthFirst(T,L+1, , Minsup) ;  else return(D?);  If bread first projecting ends at level L, then DepthFirst is called to build the sub trees with roots of the leaves in level L.

DepthFirst (v, ,Minsup) for each node e in v.PTS.IL top down by do  if e.count(k) minsupk for some class ck in C then create a child node d for v; d.item= e.item; d.weight(k)= e.cuont(k); PseudoProj(v,d, ); DepthFirst (d, ,Minsup);   In DepthFirst, first, the IL items are chosen by the imposed ordering; second, if the classification items of the IL item are frequent then creates the corresponding children nodes; third, calls the PseudoProj process. The PseudoProj process will adjust the weights and re-threading the sub trees to guarantee the children CPTS be contained in the parent CPTS.

4. PERFORMANCE EVALUATIONS  To evaluate the efficiency and effectiveness of our algorithm CRMMS, we have done experiments on the dataset Forest from UCI machine learning data warehousing by comparing with Apriori and FP-Growth on a 286MHz Pentium III PC with 512 MB main memory and 30 GB hard drive, running on Windows 2000 Professional.

The empirical results indicate that CRMMS is one to three orders of magnitude more efficient than Apriori and FP-Growth. For example, in Figure 5, when the support thresholds are lower than 0.1%, CRMMS is 2 to 12 more efficient than Apriori and 1.5 to 8 than FP-Growth. At the reasonable low support threshold of 0.05%, CRMMS requires 16 seconds, whereas FP-Growth requires 31 seconds and Apriori requires 65 seconds. At the even lower support threshold of 0.02 %, CRMMS requires 20, while FP-Growth requires 72 seconds and Apriori requires 155 seconds. The rankings of algorithms are CRMMS FP-Growth  Apriori.

Figure 5. Performance comparison of frequent item set mining     0.010.020.030.040.05 0.06 0.08 0.1 threshold (%)   5. CONCLUSIONS AND FUTURE WORK  The paper introduced a multi-support algorithm CRMMS of classification rules mining, which adopts array-based threaded transaction forest method and pseudo projection to highly improve the efficiency of classification rules mining. The future work will be focus on the association rules mining in the business data streams [10].

6. REFERENCES  [1] R Agrawal, R Srikant., ?Fast algorithms for mining association rules?, The 1994 VLDB, Santiago, Chile, 1994, pp. 487-499.

[2] S Brin , R Motwani , J Ullman et al, ?Dynamic item set counting and implication rules for market basket analysis?, The 1997 ACMSIGMOD, Tucson , AZ , May 1997, pp. 255-264.

[3] Lu Jie, Zhang Zhijing, ?An Improved Apriori Algorithm for Mining Association Rules?, Microelectronics & Computer, Beijing, China, volume 23, No.2, 2006, pp. 10-12.

[4] J Han, J Pei , Y Yin, ?Mining frequent patterns without candidate generation?, The 2000 ACM2SIGMOD, Dallas, TX, 2000, pp. 1-12.

time (s)     [5] Song Yuqing, Zhu Yuquan, Sun Zhihui, Chen Geng, ?An algorithm and its updating algorithm based on FP-Tree for mining maximum frequent itemsets?, Journal of Software, China, volume 14, No.9, 2003, pp.1586-1592.

[6] J. Pei, J. Han, H. Lu, S. Nishio, S. Tang, and D. Yang,? H-Mine:Hyper-Structure Mining of Frequent Patterns in Large Databases?, Proc. 2001 Int. Conf. on Data Mining (ICDM'01)}, San Jose, CA, Nov. 2001, pp.441-448.

[7] Liu JQ, Pan YH, Wang K, Han J. Mining frequent item sets by opportunistic projection. In: Hand D, et al, eds.

Proc. of the 8th ACM SIGKDD Int?l. Conf. on Knowledge Discovery and Data Mining. Alberta: ACM Press, 2002, pp.229-238.

[8] Liu Junqiang, Pan Yunhe, ?An efficient algorithm for mining closed itemsets?, Journal of Zhejiang University Science, Zhejiang, China, Jan 2004, pp. 8-15.

[9] Liu Junqiang, Sun Xiaoying, Wang Xun, ?Pseudo projection algorithm for mining of classification rules?, Computer application & Software, China, Sept 2003, pp.

8-10.

[10] Geoff Hulten, Laurie Spencer, Pendro Domingos, ?Mining time-changing data streams?, In Proc.ACM Int.Conf. on Knowledge Discovery and Data Mining[C], San Francisco, California, 2001,pp.71-80.

