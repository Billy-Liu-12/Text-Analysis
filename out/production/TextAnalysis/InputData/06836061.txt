Scale-Invariant Line Descriptors for Wide Baseline Matching

Abstract  In this paper we propose a method to add scale- invariance to line descriptors for wide baseline matching purposes. While finding point correspondences among dif- ferent views is a well-studied problem, there still remain difficult cases where it performs poorly, such as texture- less scenes, ambiguities and extreme transformations. For these cases using line segment correspondences is a valu- able addition for finding sufficient matches. Our general method for adding scale-invariance to line segment descrip- tors consist of 5 basic rules. We apply these rules to en- hance both the line descriptor described by Bay et al. [1] and the mean-standard deviation line descriptor (MSLD) proposed by Wang et al. [14]. Moreover, we examine the effect of the line descriptors when combined with the topo- logical filtering method proposed by Bay et al. and the re- cent proposed graph matching strategy from K-VLD [6]. We validate the method using standard point correspondence benchmarks and more challenging new ones. Adding scale- invariance increases the accuracy when confronted with big scale changes and increases the number of inliers in the general case, both resulting in smaller calibration errors by means of RANSAC-like techniques and epipolar estima- tions.

1. Introduction Stereo wide baseline matching is a problem within com-  puter vision in which correspondences between two views are found in a systematic way. These two views can differ in viewpoint, rotation, scale, illumination and camera param- eters. The fundamental matrix can be derived for the two views given at least 7 point correspondences and the epipo- lar geometry with at least 5 point correspondences [5].

Wide baseline matching has been largely solved in the case of textured scenes. For instance, MSER [8] and Lowe?s scale-invariant feature transform (SIFT) algorithm [7] are robust methods to efficiently find matches between such images. Several ?SIFT-like? descriptors have been docu-  mented. We call ?SIFT-like? the methods that either use the SIFT descriptor or propose a descriptor using the same principles as SIFT. In combination with graph matching methods or topological filters [3], often complemented with RANSAC-based [4] methods, SIFT and its derivatives per- form well when applied on two or more views, even when additional information like epipolar geometry is missing.

Graph matching methods take the geometric consistency of the correspondences into account. As a result they tend to have a high complexity [2, 6], especially the higher order graph matching methods. Liu and Marlet [6] describe a graph matching method in which only consistency with the local neighborhood is checked, resulting in a much faster al- gorithm. Moreover, most graph matching methods require a high inlier rate in order to work correctly.

Topological filters also consider the layout of the cor- respondences, but enforce weaker constraints. As a result, the execution time of topological filtering is significantly smaller, but the matching performance decreases as well.

Topological filters have been shown to resist a higher per- centage of outliers than most RANSAC-based algorithms do.

On the other hand, wide baseline stereo matching for texture-less scenes still represents a much harder problem: interest point detectors will not provide enough correct cor- respondences in order to be able to estimate the epipolar ge- ometry correctly. Such scenes typically occur indoors and therefore are often characterized by many straight lines. It is in these cases that wide baseline matching using line seg- ments, often in combination with interest point methods, are particularly useful. However, using line segments intro- duces some problems of its own, the most prominent being the fact that the endpoints of a line segment are inaccurately localized. Therefore more statistical measures need to be taken to describe line segments than is the case for point or region descriptors.

Bay et al. [1] propose a method that describes line segments using color histograms and a topological filter.

While yielding distinctive information, the drawback of us- ing color information for matching is that the method may    rmoore3 Text Box    not be sufficiently robust to illumination transformations.

Moreover, Bay et al.?s color histogram descriptor does not take into account the scale of the objects in the view.

Wang et al. [14], on the other hand, use a SIFT-like strat- egy for describing line segments called the mean-standard deviation line descriptor (MSLD). Similar to SIFT, MSLD is more robust than Bay et al.?s descriptor to changes in illumination conditions. MSLD does not take scale into ac- count either. Zhang and Koch [16] extended the MSLD descriptor by adding geometric constraints and a topolog- ical filter to eliminate wrong matches. While the geomet- ric constraints applied after the MSLD algorithm are scale- invariant, the descriptor itself is not. Wang et al. [15] ex- tended the MSLD descriptor to also make use of color infor- mation, thereby slightly increasing the matching accuracy for baseline images with similar illumination conditions.

In this paper we propose an approach to add scale- invariance to line segment descriptors for wide baseline matching. We show that the scale-invariant descriptors cope better with larger scale changes, while maintaining its robustness under other image transformations w.r.t. their scale-variant counterparts without scale spaces. In gen- eral these scale-invariant descriptors will yield more in- liers. Despite many of these inliers being redundant, this allows better epipolar estimations. The introduced redun- dancy also yields more efficient and effective topological filtering and graph matching, which in some methods, e.g.

our slightly modified implementation of Bay et al.?s line segment matching algorithm, results in a speed up of the algorithm.

2. The scale-invariant line segment descriptor  2.1. Scale-invariant line segment matching: the principles  Wide baseline stereo matching often has to deal with scale changes. It is therefore important to take scale into account when matching. MSER and SIFT adapt to those scale changes, but line descriptors still largely lack such ca- pacity. Scale-invariant wide baseline methods typically use a scale space for this purpose [7]. Unfortunately building a scale space requires N line segment detections and (N ?1) image rescales, whereN is the number of scale levels in the image pyramid. This tends to slow down and increase the complexity of the algorithm w.r.t. the scale-variant case.

Therefore we introduce a faster but less robust alternative to extract the scale by using the line segments detected on the lowest scale only. A pair of line segments can be the edges of a thicker line. More details in Section 2.2.

The main principle when matching line segments is that corresponding descriptors must describe corresponding re- gions w.r.t. the line segments. In order to find these regions we derive five rules for extending a line descriptor to be-  come scale-invariant:  1. Preserve the principles of the original descriptor and apply them whenever possible.

2. Real world parallel lines do not necessarily stay paral- lel under baseline changes. Most lines parallel in the real world become lines that intersect into one point and we use this in the new descriptor (see also rule 5).

3. Distances between points change w.r.t. scale s. There- fore, given d the distance between the line segment and the region in the original descriptor, this distance scales as d(s + 1), such that the distance never goes to zero. This is a result of the fact that one-pixel wide lines are defined to have scale zero (s = 0).

4. As a result of the previous rule, the width and height of a region both scale with a factor of s + 1 as well.

Other parameters that depend on the size of a region scale accordingly.

5. Take into account the global (assumed) scale deforma- tion. The same deformation should be applied to the distances and the regions of the descriptor. Note that this will often lead to a similar conclusion as rule 2 since deformed parallel lines will indeed not stay par- allel in most cases, but will intersect.

In section 2.3 and 2.4 these rules will be illustrated on two scale-variant line segment descriptors. In these sections it will be shown that these rules should be applied multiple times on several aspects of the descriptor. First, section 2.2 describes our method for extracting the scale in more detail.

2.2. Line segment scale extraction: the fast approach  Typically scale-invariance is achieved using scale spaces. In this paper we will use a different approach that will apply a single line segment detection.

In this approach, we will focus on line segment pairs that lie close to each other in the image, capable to be edges of thicker line segments (or stripes). The typical case will be (near-) parallel line segments. Therefore the angle between the two line segments (? in Figure 1a) is sufficient to de- scribe the deformation. We define the scale angle ? as the complementary angle of ?2 (Figure 1a).

A first step in our method of extending scale-invariance to line segment detectors is to find the thickness of stripe- like structures in the images. A stripe is a line segment with a width of multiple pixels. Due to deformation the stripe can become trapezoidal, resulting in a so-called stripe-like structure. In order to find those stripe-like structures, we first detect all line segments using a traditional line seg- ment detector [13]. This results in one-pixel wide lines that     B  A C  D  A?  B?  C?  D?  ?  ?  (a) Scaled line segment  B  A C  D B?  C?  ?  ?  s1  4(s1 + 1)s2  4(s2 + 1)  E  FF?  E?  F?  E?  ? ?  (b) Scaled color extraction region for SBay  Figure 1: Illustrations on how scaled lines (a) and their cor- responding scaled regions in SBay (b) are constructed.

depict the edges of the stripe-like structure rather than the stripe-like structure itself. Next we select all pairs of line segments for which ? (see Figure 1a) as well as the mean of the orthogonal distances between the line segment end- points and the other line segment are below selected thresh- olds. A further pruning of pairs will follow, but already here we are quite selective. The threshold applied to the orthog- onal distance is kept rather small, i.e. 50 pixels for images of 800 ? 600 pixels. The threshold on ? is taken to be 10 degrees.

Further pruning is applied by considering the overlap be- tween the projections of the two line segments onto the bi- sector line, as shown in Figure 1a. In this figure the overlap is given by the line with endpoints B? and C?. We compute the scale at these endpoints by considering the sum of the orthogonal distances of the endpoint to the original line seg- ments (2d(B,B?) and 2d(C,C ?) in this case). These scales are indicated as s1 and s2 in Figure 1b. The two endpoints, the scale in each of the endpoints and the scale angle de- scribe the scaled line B?C?. These five parameters will play a role when describing our scale-invariant adaptations for both the Bay descriptor (Section 2.3) and the MSLD de- scriptor (Section 2.4).

When the scale of the images decreases, the stripe will eventually become a one-pixel wide line segment. Such one-pixel wide line segments are considered to have scale 0 for both endpoints and a scale angle of ?2 .

2.3. Scale-invariant Bay line segment matching de- scriptor  Bay et al. [1] propose a descriptor in which a color his- togram is constructed using the color information along two parallel line segments with the same length at a transversal distance of 4 pixels from the originally detected line seg- ment. We adapt this descriptor to become scale-invariant by applying the rules mentioned in section 2.1. In this text we will further refer to the line segment algorithm proposed by Bay et al. as Bay and to our adapted algorithm as scale-  invariant Bay or SBay.

For the SBay descriptor, first the middle line of the re-  gion from which we want to extract the color information needs to be found (rule 1). This is done by starting in an endpoint of the scaled line segment and go for a distance of d(s+1)+ s2 (rule 3) in the direction given by the scale angle (rule 2 and 5). This is done for each endpoint of the scaled line segment in both the +? and ?? direction (rule 1,2 and 5). This is illustrated in Figure 1b for one direction, result- ing in line EF. Here d is chosen to be 4, as was suggested by Bay.

Next, we have to extract the color information around this line. Since Bay extracts a one-pixel wide line with the same length to describe an original line segment of the same width, SBay also extracts the color information within a ?line? that has the same ?thickness? and length as the scaled line. Since scaled lines are in fact regions, color extrac- tion will also occur from an entire region that scales with the scale of the scaled line (rule 4). As we already know the deformation parameters from the scaled line generation phase, we can simply apply kind of the reverse operations on the earlier constructed line for constructing the extrac- tion region. First, starting from the middle line EF, two flanking line segments need to be constructed. To that end a distance of s2 in the direction of +? and ?? w.r.t. middle line EF for each endpoint needs to be taken (rule 2 and 5), resulting in points E?, E?, F? and F? in Figure 1b. The re- gion from which SBay will extract the color information for the descriptor is the resulting hexagon (E-E?-F?-F-F?-E? in Figure 1b).

Note that Bay applies spline interpolation on the intensi- ties after they are extracted in order to suppress noise. This requires SBay to do a 2D-spline interpolation. However, empirical results from Bay?s algorithm seem to indicate that the spline interpolation degrades the performance of the line matching method. Therefore noise suppression on the ex- tracted colors for both Bay and SBay are omitted in our implementation.

2.4. Scale-invariant MSLD  The MSLD algorithm proposed by Wang et al. [14] ap- plies a SIFT-like approach to nine parallel lines where the fifth line (in the middle) is the original line segment. The lines are separated by a distance of 5 pixels. The SIFT-like method is applied to a subregion of 5 px ? 5 px centered around each pixel on each line. The subregions are mapped on four different directions (+ and ? in horizontal and ver- tical direction). Next the mean and standard deviation over each direction of all points on each line are taken and nor- malized. The MSLD descriptor does not use a scale space and is not scale-invariant. The MSLD descriptor can be adapted to become scale-invariant by once again applying the rules of Section 2.1 on several aspects of the algorithm.

A  B  C  D  C?  D?  s1  d(s1 + 1)  s2 2d(s2 + 1)  1 2 3 4 5  ?  Figure 2: Subregion generation of SMSLD. The right side is the mirror of the left.

In this text we will further refer to this adapted algorithm as scale-invariant mean-standard deviation line descriptor or SMSLD. When discussing the SMSLD algorithm, the nine lines are numbered from top to bottom and from left to right (see Figure 2).

Note that, in order to describe the exact same region for different scales, ? should be used to additionally change the direction between every line. As a result the lines would be no longer parallel but would all intersect in the same point (rule 5). However, the placement of the lines is simplified to an approach similar to how the middle line of the region from which to extract the colors in SBay (see Section 2.3) is constructed. Lines 4 and 6 are at a distance d(s+ 1) + s2 from the line segment (rule 3) in the direction denoted by ?? and +? respectively (rule 2 and 5). Lines 1-2-3-4 and 6- 7-8-9 are each time separated by a distance d(s+1) (rule 3), measured in the same direction as line 4 and 6 respectively.

d is chosen to be 5 pixels, as proposed by Wang et al. [14].

To speed up the description, not every pixel on each of these lines is taken as a center for a subregion: the centers of each subregion on the same line are separated by a dis- tance of s + 1. The size of each subregion is adjusted to the scale as well: the width and height of each subregion is d(s + 1) (rule 4). A further speedup of the algorithm is accomplished by keeping the orientation of each subregion the same as if it was a subregion for the originally detected line segment on the same side (see Figure 2: the orientation of the subregions for line 1 - 2 - 3 - 4 are oriented as if they are subregions of line AB). Only for the middle line (line 5) the orientation of the subregions is adapted to the line itself.

Note that SMSLD needs a big region at each side of a line segment in order to be able to describe the line segment.

Line segments whose descriptor regions contain too many invalid points are rejected. To increase the number of valid scaled lines we add 50 pixels to all sides of the image and repeat the 50 closest lines or columns in reverse order.

3. Evaluation The proposed descriptors are evaluated on standard  benchmarks and on some typical (challenging) indoor scenes1. The original descriptors are provided as a reference as well. In addition we provide the results for K-VLD [6], a state-of-the-art region and point descriptor, and, where meaningful, SIFT [7]. The impact when combined with a topological filter [1] or the K-connected graph matching fil- ter [6] is also examined. More details about the evaluation follows in Section 3.1.

3.1. Evaluation units  The following units are combined in order to evaluate the SBay and SMSLD descriptors:  LSD The line segment detector version 1.5 implementation of Grompone von Gioi et al. [13] is used for detect- ing line segments. When used with Bay and SBay, the scale and EPS parameter are adjusted until the number of line segments is below 400. For MSLD and SMSLD the scale is set to 1 while all other parameters are set at their default values. In the case of MSLD and SMSLD all found line segments are kept.

Bay Our MATLAB implementation of the line segment matching method proposed by Bay et al. [1] up to the correspondence boosting. Note that this is not the en- tire algorithm as proposed by Bay et al. The remain- ing filtering stages are omitted since these can be ap- plied to all line segment descriptors for improving their accuracy as well. The snapping part is also omitted.

This method also includes the collinear line merging method described by Bay et al. The default parameters as described by Bay et al. are used for the algorithm, however due to efficiency considerations only the 200 best soft matches are kept before the topological filter- ing phase.

SBay Our MATLAB implementation of Bay adapted to become scale-invariant as described in Section 2.3.

Scaled lines are generated using the parameters men- tioned in Section 2.2.

MSLD The original C++ implementation of the MSLD al- gorithm provided by the authors [14]. No collinear line merging is used. Using an adapted version of Bay et al.?s collinear line merging method results in longer matched line segments, but without significant impact on the accuracy and is therefore omitted. The MSLD descriptor is set to only use straight line segments for matching, the other parameters are the default ones.

No scale space is used for this descriptor.

1The SMSLD implementation and evaluation code is available at: https://github.com/bverhagen/SMSLD     SMSLD The scale-invariant adaptation of the MSLD C++ implementation as described in Section 2.4. Scaled lines are generated using the parameters mentioned in Section 2.2.

Btopo The topological filter as described by Bay et al. [1].

While this filter is able to cope with both line segments and points, only line segments are used during the eval- uation. For the topological filtering stage the default parameters as proposed by Bay et al. are used.

KVLD The K-VLD algorithm as implemented by Liu and Marlet [6]. K-VLD uses interest points, region de- scriptors and the K-connected graph matching algo- rithm.

K The implementation of the K-connected graph matching algorithm, as provided by Liu and Marlet [6]. The mid- dle point, scale and orientation of the matched line seg- ments are provided as input. Since the middle points of the line segments are not as accurately localized as interest points, a precision of 20 pixels is used for the graph matching. The VLD-consistency is raised to 1 and the contrast suppression is removed.

ORSA The original implementation of the optimized ran- dom sampling algorithm (ORSA) [10]. ORSA is used both for eliminating outliers and for estimating the ho- mography between pairs of images. The middle points of the matched line segments are used as input points.

Since the midpoints are not as accurately localized as interest points, a precision of 20 pixels is used.

SIFT The VLFeat 0.9.16 implementation [12] of SIFT.

This method uses Lowe?s criterion (the ratio of the second closest to closest match) of 0.8 for pruning the matches.

In all the evaluations the fast approach for line segment scale extraction as described in Section 2.2 is used. During the evaluations the accuracy is defined as the ratio of the number of correct correspondences w.r.t. the total number of found correspondences. Since the midpoints of the line segments are not accurately localized and the corresponding lines (rather than only corresponding segments on the lines) are sufficient to accurately calculate the epipolar geometry, the correctness of a line segment correspondence is verified by its deviation from its actual corresponding line. Line segments with a difference in angle of less than 5 degrees and whose middle has an orthogonal distance of less than 5 pixels from the corresponding line are considered right matches.

3.2. Point matching benchmarks  First, the descriptors are tested using Mikolajczyk et al.?s dataset [9]. This dataset is often used for evaluating  and comparing point detectors and descriptors under image transformations like blurring, viewpoint changing, zoom, rotation, illumination and JPEG compression. The dataset contains 8 sequences of 6 images each testing one or more of these transformations. Within one sequence the image transformation is intensified for each consecutive image.

Each image in the sequence is matched with the first im- age of that sequence. Note that the Bark sequence is not well suited for line segment matching. The UBC sequence on the other hand gives very good results. Both sequences are not shown in Figure 3. The K-VLD method is provided as a reference, it uses point and region descriptors in combi- nation with the K-connected graph matching algorithm and achieves top performance on these benchmarks [6].

We compare Bay and SBay using the topological filter.

MSLD and SMSLD are compared using no post-filter, the topological filter (Btopo) and the K-connectd graph filter- ing method (K). The inlier rate is defined as the number of matches after K-filtering divided by the number of matches before K-filtering is applied.

As shown in Figure 3 in most of the setups adding scale-invariance to the Bay and MSLD line descriptors im- proves the performance by increasing the number of correct matches. While MSLD and SMSLD give a similar accuracy for the considered image transformations, post-filtering af- ter SMSLD tends to give a higher accuracy increase than is the case with MSLD. This is a result of the redundancy present within the end result of the SMSLD algorithm. Note that Bay and SBay use color information and are vulnerable to illumination changes and repetitive color patterns. More- over, Bay and SBay perform poorer than MSLD and SM- SLD. Therefore, we do not report results based on the Bay descriptor with other filtering strategies.

3.3. Zoom sequence  The Zoom sequence tests specifically for the per- formance of the descriptor when confronted with scale changes. The scene depicts one zoomed in picture (pic- ture 2) and 4 zoomed out pictures (3 - 4 - 5 - 6). The re- sults are shown in Figure 4. The middle points of correct matches in image 1 are connected in green or yellow with their corresponding point on the support line in image 2, while wrong matches are connected in red with the middle point of their wrongly matched line segment. The correct extra correspondences found by SMSLD w.r.t. MSLD are marked in yellow.

As shown in Figure 4b, the original algorithms achieve a similar performance as the scale-invariant ones for small scale changes. However, even here the scale invariant meth- ods already find more correct matches. For bigger scale changes the methods based on SMSLD have an accuracy that is about 10% to 15% higher than their scale-variant counterparts, while still being able to find more matches     Bay SBay MSLD SMSLD MSLD + Btopo SMSLD + Btopo MSLD + K SMSLD + K KVLD  inlierrate MSLD + K inlierrate SMSLD + K  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y  Boat (zoom and rotation)  2 3 4 5 6      Index of image N  b of  m at  ch es  Boat (zoom and rotation)  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y  Graf (viewpoint)  2 3 4 5 6      Index of image  N b  of m  at ch  es  Graf (viewpoint)  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y  Trees (blur)  2 3 4 5 6      Index of image  N b  of m  at ch  es  Trees (blur)  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y  Leuven (light)  2 3 4 5 6      Index of image  N b  of m  at ch  es  Leuven (light)  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y  Wall (viewpoint)  2 3 4 5 6      Index of image  N b  of m  at ch  es  Wall (viewpoint)  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y Bikes (blur)  2 3 4 5 6      Index of image  N b  of m  at ch  es  Bikes (blur)  Figure 3: Performance evaluation on Mikolajczyk?s dataset. Note that the results for UBC and Bark are not included, very good results are obtained on UBC while Bark is not well suited for line segment matching. Note the logarithmic scale for the ?number of matches?.

in all but the SMSLD+Btopo case. SBay finds more cor- respondences than Bay, but suffers from the repeatability of the textures within the image.

An important side note is that SMSLD is a trade-off be- tween accuracy and execution time: MSLD combined with a scale space (PMSLD) of 5 levels and a scaling factor of 0.8 achieves on image pair 1 and 4 of the Zoom sequence an accuracy of 94% (89 found line segments) calculating 1145 (MSLD) descriptors, while SMSLD calculates 1004 (SMSLD) descriptors and has an accuracy of 83%. SM- SLD combined with the same scale space (PSMSLD) also achieves 94% (102 found line segments), calculating 1833 (SMSLD) descriptors.

3.4. Repeatability  The first two images of the Castle-K19 sequence [11]2  are used for testing the repeatability performance of the descriptors. We combine the SIFT, K-VLD, MSLD and SMSLD descriptors with ORSA to determine the domi- nant homography. The resulting inliers (green) and outliers  2The authors provide [11] as reference for using the Castle-K19 se- quence.

(blue) as considered by ORSA are provided in Figure 5.

Since the size of the images of the Castle-K19 sequence are 3072 px ? 2048 px, the orthogonal distance threshold for scaled lines is set to 100 pixels and the minimum line seg- ment length to 60 pixels. Noteworthy is that ORSA fails in estimating a good homography when used with SIFT, since the inliers are clustered on a tree. K-VLD is also provided as a reference. SMSLD outperforms MSLD in terms of (in- lier) matches.

3.5. Difficult scenes  Line segments are especially useful in texture-less scenes. Figures 6 and 7 show the found correspondences for two texture-less indoor scenes. Figure 6 shows an exam- ple where line segment matching methods and point corre- spondence matching methods complement each other rather well: K-VLD finds most of its correspondences within the boxes on the wall, while line segment methods find corre- spondences in the surroundings. Note that where K-VLD fails (see Figure 7) in finding good correspondences, the line descriptors are able to find a few. In both images cor- rect and incorrect correspondences are connected with blue     (a) Images  Bay SBay MSLD SMSLD  MSLD + Btopo SMSLD + Btopo MSLD + K SMSLD + K  PMSLD PSMSLD  2 3 4 5 6   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Index of image  A cc  ur ac  y  Zoom sequence  2 3 4 5 6    Index of image N  b of  m at  ch es  Zoom sequence  (b) Performance of the zoom sequence (c) MSLD (11/15) (d) SMSLD (15/18)  Figure 4: Results of the zoom sequence. (a) shows the 6 images of the sequence. (b) shows the accuracy and number of matches for each image in the sequence when matched with image 1. (c) and (d) show the result of MSLD and SMSLD respectively when matching images 1 and 4 of the sequence. For these we also report the number of correct matches/total number of matches between brackets. We depict with green lines the correct matches, with red the incorrect ones, and with yellow the extra correct correspondences found by SMSLD w.r.t. MSLD.

lines by their middle points. Yellow depicts the correspon- dences that are found only by one of the MSLD and SMSLD techniques (the bulk of correspondences in blue is common for both).

4. Conclusions This paper proposes a method for adding scale-  invariance to line segment descriptors. This method is illus- trated on the scale-variant line segment descriptor proposed by Bay et al. [1] and the MSLD [14] descriptor resulting in the SBay and SMSLD algorithm respectively. The pro- posed descriptors are evaluated using standard and more challenging image datasets. The envisaged application of these descriptors is efficient wide baseline matching. For textured scenes, point correspondence methods are supe- rior to line segment correspondence methods. However, for more difficult scenes the line segment matching methods are often a valuable addition to the point based methods.

Scale-invariant methods offer the advantage of finding more correct matches resulting in better post-filtering or more ac- curate epipolar geometry estimations in the general case, while yielding a higher accuracy when confronted with big- ger scale changes.

