Generating Closed Frequent Itemsets with the

AbstractAn approach is proposed to discover closed frequent  itemsets with a simple linear list structure called the Frequent  Pattern List(FPL) in transaction database. The approach selects  representation patterns from candidate itemsets to reduce  combinational space of frequent patterns. By performing two  operations, signature vertex conjunction and vertex counting, it  simplify the process of closed itemsets generation.

Keywords-closed frequent itemset; Frequent Pattern List; vertex  conjunction; vertex counting; signature vector

I. INTRODUCTION  Frequent pattern mining is an important task of data  mining. It is essential for mining association, relevant and  interesting links. In addition, it is widely used in data  classification, clustering and other data mining tasks.

Many effective, scalable algorithms have been developed in  terms of frequent pattern mining. The Apriori algorithm is a  classical frequent itemsets generation algorithm, and a  milestone in the development of data mining. there were many  improvements on the original works [1-4]. These methods  adopted the generation-and-test approach. They iteratively  generate the set of candidate frequent patterns of length (k+1)  from the set of frequent patterns of length k, and then check  their support counts in the database. However, there are two  fundamental drawbacks [5] with the Apriori-like  generation-and-test approach. First, the generation of a huge  number of candidate sets is costly. Second, the repeated  scanning of the database and the testing of candidates by    pattern matching is time consuming.

Aiming at the two problems, researchers put forward a lot  of effective methods. From the data structure point of view,  these methods are broadly categorized as:(1) Algorithm based  on set structure, such as the Apriori-like approach. And space  theory based on project set lattice algorithm for mining  association rules [6,7].(2) Algorithm based on tree structure,  such as the type FP-growth algorithm [8,9], etc.(3) Algorithm  based on vertical data layout[10].

Compared with the Apriori-like methods, the FP-tree  approach is novle and efficient, but it still has something to be  improved. First, for the same frequent item,there are duplicated  tree nodes on different branches of the tree. Second, the FP-tree  structure is rather complicated, and the recursive construction  of conditional FP-trees is a nontrivial task.

Fan-Chen Tseng and Ching-Chi Hsu present another  approach to mining frequent patterns without candidate  generation: using a simpler linear list structure called the  frequent pattern list (FPL) [5]. The FPL structure can divide  transaction database into several parts without intersection,  compress and store transactions in its nodes efficiently.

However, it has disadvantage in complexity of space because  of recursively building sub-FPL, and it is possible to generate  repeat mining frequent patterns  Closed frequent itemsets [11-14] contain complete  information on frequent itemsets, and compress the number of  frequent itemset in a high degree. In particular, It has great  advantages in the longer pattern mining in densely database, It  has became a research focus.

In this paper, we present an approach to mining closed  frequent itemsets with FPL in transaction database(CFPL). The  CFPL introduces two operations named as signature vertex  conjunction and vertex counting. The vertex conjunction  operation has the potential parallelism. Operations among  signature vertex reduce combinational space of frequent  patterns and improve the efficiency of the algorithm.

The rest of the paper is organized as follows. Section 2  describes the construction of the FPL. Section 3 details the  CFPL. Section 4 discusses our approach with other related  works. Section 5 gives the conclusion.



II. FREQUENT PATTERN LIST CONSTRUCTION  Let I = {a1, a2, , am} be a set of items, and a transaction    database DB={T1, T2,, Tn}, where Ti ( i = 1, 2, ..., n) is a  transaction which contains a set of items in I.

The example of transaction database (borrowed from  reference [5]) shown in table 1 is used for illustration. For  convenience, only frequent items are shown, and the frequent  items in each transaction are listed in the order of descending  frequency.

TABLE 1.  THE EXAMPLE TRANSACTION DATABASE, DB.

Transaction ID Frequent Items  T1 f, c, a, m, p  T2 f, c, a, b, m  T3 f, b  T4 c, b, p  T5 f, c, a, m, p  978-1-4244-6977-2/10/$26.00 2010 IEEE  Scan the database DB. Find the frequent items and their  corresponding frequencies. Create a linear list of item nodes of  frequent items in order of descending frequency. For each  transaction Tx in DB, A bit string, called transaction signature,  is formed from left to right to indicate the existence and  absence of frequent items in Tx. When all the frequent items  in Tx are examined, the FPL is formed. The example resultant  list is shown in table 2. Construction of the FPL and other  details of the FPL not elaborate. For details, see [5].

TABLE 2.  THE GLOBAL FPL CONSTRUCTED FROM DB OF TABLE 1  Item  node 1  Item  node 2  Item  node 3  Item  node 4  Item  node 5  Item  node 6  f?4 c?4 a?3 b?3 m?3 p?3  Empty  set  Empty  set    Empty  set  T3 1001 T2   T1   T4   T5

III. MINING CLOSED FREQUENT ITEMSETS WITH FPL  A. Basic concept and properties  Definition 1  Itemset A is the union of the items of I, then  the support of itemset A is defined as the probability that A  appears in DB, written as Sup(A), also Sup(A)=P(A).The  support counting of A is defined as the transaction data that A  appears in DB.

Definition 2  Let 1( , , )Tn? ? ?= " 1( , , )Tn? ? ?= " be two  arbitrary n-dimensional vectors in Euclidian space, where  { }, 0,1i i? ? ? , 1, ,i n= " .The operation ? ??  is defined by  ( )1 1, , Tn n? ? ? ? ? ?? = ? ?" ?        where  0 0 0, 0 1 0,1 0 0,1 1 1? = ? = ? = ? = .

The operation ? ?? is called the conjunction of vector ? and  vector ? .

CFPL considers the transaction signature of FPL in same  bit and in same node as a signature vector. In Tab.2 for  example, among the nodes of frequent item p corresponds to,  the first, the third and the fifth signature vectors are  ( )1,0,1 T ,and the second is ( )1,1,1 T . Where, every component of  the vector takes separately corresponding bit of transaction  signature. In FPL, the LSBs (least significant bits)[5] of  transaction signature in every nodes are all 1. Its signature  vector is ( )1,1,1 T .

The conjunction of arbitrary two signature vectors is the  signature vector of the union of frequent itemsets that two  signature vectors correspond to. For example, conjunction the  first bit signature vector ( )1,0,1 T and the second signature  vector ( )1,1,1 T ,we obtain ( )1,0,1 T ,and this is the signature vector  of pattern fc in present node.

Definition 3 Let 1( , , )Tn? ? ?= " ,Vector counting is defined  as the sum of all components of the vector, written as  ( )verCounting ? , i.e.

( )  n  i  i  verCounting ? ?

=  =? .

Obviously, Vector counting is the support counting of the  corresponding pattern.

Definition 4 [13]  Assume that ,X Y are frequent itemsets  in DB, if  (1) X Y?

(2) it doesnt exist arbitrary frequent itemset Y ? ?

Y Y ?? ,such that ( ) ( )Sup Y Sup Y ?= ,then Y  is called the closed  frequent itemset of X , written as ( )X? .

There are the following properties of the above definitions.

1. The patterns possessing same signature vector in same  nodes have same support.

2. If two arbitrary patterns, 1P  and 2P , possess the same  signature vector in same nodes, it would be ( ) ( )1 2P P? ?= .

3. The support of the closed frequent itemset of node i can  be computed by  ( ) ( ( ). )( ) verCounting X SignatureSup X  DB  ?? =    Where ( ( ). )verCounting X Signature?  is vector counting of  ( )X? signature vector, and DB is the transaction number  contained in transaction database.

B. Algorithm for mining closed frequent itemsets with FPL  In this section, we give the algorithm for mining closed  frequent itemsets with the FPL. The example in section 2 is  used here for explanation.

Algorithm (CFPL mining: mining closed frequent itemsets)  Input: the FPL, a minimum support threshold t.

Output: the complete set of closed frequent itemsets.

Steps: Procedure CFPL-mining (FPL, t)  {  1) Traverse the FPL at the end, generating the initial  patterns and signature vertexs.

Item node 6 in the table 2 resultant list, is shown in table 3.

TABLE 3.  THE INITIAL PATTERN FROM DB OF TABLE 2  item i item1 item2 item3 item4 item5 item6  item[i].

pattern  f c a b m p  signature ( )1,0,1  T    ( )1,1,1 T    ( )1,0,1 T    ( )0,1,0 T    ( )1,0,1 T    ( )1,1,1 T    2) Signature vertex counting; (Ignore the patterns whose  signature vertex counting are below the minimum support  threshold t.)  3) Partition patterns by the signature vertex; (The patterns  in the current Generated frequent itemsets are listed in the  order of descending of signature vector counts.)  Assume that minimum support threshold is 1. Table 4  shows the details of step 2 to 3 for the example.

TABLE 4.  THE PARTITION PATTERNS FROM TABLE 3  closedItemSet i closedSet[1] closedSet[2] closedSet[3]  base p p p  pattern c f,a,m b  signature ( )1,1,1 T  ( )1,0,1  T  ( )0,1,0  T  4) Select pattern base;  5) Remove the base from the list;  6) Take conjunction operation with the pattern base vector  and the rest of their representation pattern signature vectors.

Generate patterns by the conjunction results;  7) Ignore the patterns whose vector counts are below the  minimum support threshold;  8) The patterns in the current generated frequent itemsets    are listed in the order of descending of signature vector counts.

9) Repeat step 4 to 8 untill the number of the generated  pattern itemsets candidate is 1. Generate closed frequent  itemsets of the node.

The Example continues. (p, ( )1,1,1 T ) is pattern base. As all  counting of signature were greater than 1, take conjunction  operation with the base and the rests. Generate pattern  candidate sets: (cp, ( )1,1,1 T ), (famp, ( )1,0,1 T ) and (bp, ( )0,1,0 T ).

resultant list is shown in table 5.

TABLE 5.  THE PATTERNS BY P AS PATTERN BASE  item i item1 item2 item3  item[i].pattern cp famp bp  signature ( )1,1,1 T  ( )1,0,1  T  ( )0,1,0  T  Select (bp, ( )0,1,0 T ) as pattern base, take conjunction  operation with other patterns, results obtained is shown in  table 6.

TABLE 6.  THE PATTERNS BY BP AS PATTERN BASE  item i item1 item2  item[i].pattern cbp fambp  signature ( )0,1,0 T ( )0,0,0 T  Remove (fambp, ( )0,0,0 T ), output (cbp, ( )0,1,0 T ) as a  closed frequent itemset.

Select (famp, ( )1,0,1 T ) as pattern base, take conjunction  operation with (cp, ( )1,1,1 T ), the only pattern (fcamp, ( )1,0,1 T )  generated. Output it as a closed frequent itemset.

(cp, ( )1,1,1 T ) is unque remaining pattern, output it as a  closed frequent itemset.

(famp, ( )1,0,1 T ) , (fcamp, ( )1,0,1 T ) and (cp, ( )1,1,1 T ) is the  closed frequent itemsets under the algorithm to generate in  node 6, and their supports are computed by propertie 3  sup(cp) 60%= ?sup(fcamp) 40%= ?sup(cbp) 20%= .

10) Signature trimming and migration, go to step 1 with  the trimmed FPL as input until FPL is empty. Signature  trimming and migration operation see [5].

}  The mining process repeats the cycle of the pattern base  selecting, signature vertex conjunction , vertex counting ,  signature trimming and migration. Recursive calls are made, if  necessary.

C. Experimental Results  We test our algorithms on two data sets, Chess and  Mushroom, provided by UCI Machine Learning Repository.

To compare our method with FP-CLOSE [13], we run our  program on a Pentium 233-GHz PC with512 megabytes main  memory, running Microsoft WindowsXP. The algorithms are  implemented with Microsoft Visual C++ 6.0. The result is  shown from Fig. 1 to 2.From the result we see that  CFPL-Mining is much faster than FP-CLOSE.

TABLE 7.  EXPERIMENTAL DATA SETS  Database Number of items  Number of  Attributes  Number of  Records  Chess 76 36 3196  Mushroom 120 22 8124    Figure 1.  Experimental results in chess  Figure 2.   Experimental results in Mushroom

IV. DISCUSSIONS  Compared with other closed frequent itemsets mining  algorithms and the FPL algorithm proposed in literature[5], the  efficiency of CFPL-Ming comes from the following aspects:  First, it adopts a frequent pattern growth method.

Therefore, it avoids to costly generate and handles a huge  number of candidate sets.

Second, it uses a simpler and more straightforward data  structure, FPL. Unlike othermining closed pattern methods, it  does not need to scan original database more times or construct  a complex FP-Tree.

Third, an improved scheme is proposed to aim to the space  complexity caused by recursively building sub-FPL with  FPL-Ming. Seen from example, there are strong complement  between the data intersection based on FPL and the mining of  closed frequent itemset. The scheme devides patterns into  several parts with the signature vertex which are refered to as  equivalent class. Operation of the signature vertex conjunction  among different equivalent classes reduces combinational  space of frequent patterns. Transverse operation using  signature vertex as its unit differs from FPL which takes  transaction signature as its operation unit. The operation has    the potential parallelism. This is the main difference of the  CFPL and the FPL.

Generated closed frequent itemset is still frequent after  deleting pattern base from it. Thus, when mining closed  frequent itemset of other nodes, we only need to consider the  support of corresponding pattern, no mining anymore. This is  also the difference between the improved algorithm and  literature[5].



V. CONCLUSIONS  In this paper, an improved approach, combined the  advantages of FPL and closed frequent itemset mining, is  proposed. This scheme can drop scanning space quickly and  improve mining efficiency by abstracting dedicate patterns  during the process of mining frequent pattern .

There are several issues related to CFPL- mining. For  example, more efficient algorithms for performance  improvement should be studied. Also, the CFPL approach can  be applied to other applications like the mining of data  classification and other data mining tasks.

