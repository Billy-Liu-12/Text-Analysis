RDF Visualization ? Thinking Big ?

Abstract  Graph visualization is one of the popular ways to present RDF data. But all practical RDF visualizers have to some- how deal with the problem of the size of the data. Not only can the total number of triples in RDF data be very large, but even degrees of the nodes of the graph can be very high.

This article discusses some problems and solution related to visualization and exploration of such data, usually in re- lation to the RDF node merging technique.

1 Introduction  The Semantic Web [2] idea is already well established, as well as some of the standards that accompany it. One of those standards is the RDF [3] data format which is intended to be the low-level format for semantic data. By their very nature, the RDF data form a directed, labeled graph. This may be used to fight one problem ? the RDF data often tend to be large, complex and hard to read and explore when se- rialized to some text-based format (especially in the case of RDF-XML). If we present the data visually, we may be able to give the user much better idea about the content and structure of the data. It is important to note that this visu- alization is aimed at the same group that would otherwise look at the raw data (in some serialized form) ? developers of RDF-based software, not the users of the Semantic web.

But to handle data that may contain millions or more of nodes and edges, the visualization itself is not sufficient and some kind of navigation is necessary. A few years ago, we developed a navigating RDF visualizer that uses several new techniques, notably triangle layout and node merging [6, 4, 5]. It is one of the visualizers that display the ?pure? RDF data. The node merging technique was used to reduce the space needed to display the data and to present possi- bilities for further navigation to the user. The basic idea is to draw one node of the RDF graph as a rectangle that not  ?This research was supported in part by Grant Agency of Charles Uni- versity (GAUK) and VEGA 1/0726/09  Figure 1. Merged node  only displays information about the node, but also about its neighbors and edges that connect the node to the neighbors.

For an example see the Figure 1.

The triangle layout is an algorithm for layered drawing of trees. It was designed to handle different sizes of merged nodes, but the exact layout need not concern us in this paper, since the techniques described in this paper do not depend on it in any way.

The section 2.1 deals with the problem of selecting the first node to be presented to the user and the section 2.2 focuses on nodes with high degree. The section 3 explains the idea of tabbed browsing in RDF visualizers. Handling of large graph drawings is discussed in the section 4. The last section of the paper is concerned with the usability of the proposed solutions in other visualizers and it is followed by the concluding remarks.

20th International Workshop on Database and Expert Systems Application  DOI 10.1109/DEXA.2009.64     2 Determining points of interest  The great disproportion between the amount of informa- tion that can be stored in an RDF graph and the information that can fit onto a screen means that the user can only see small portion of the graph. This section deals with several types of situation where the visualizer is forced to choose one or several of many items.

2.1 Starting node  Our visualizer starts by displaying one node (in the form of a merged node) and lets the user navigate to other parts of the graph. The problem is selecting the best node to start the visualization.

One important aspect to mind is the size of the displayed graph ? it is often not possible or viable to load and ana- lyze the whole data when the visualizer starts. The size of the data may exceed the available memory or loading might take too long. Even if the visualizer is using a database as its data source, it may not be possible to compute the optimal starting node at the server side, since most such algorithms use graph operations which are poorly supported by most RDF database [1].

On the other hand, there is the fact that RDF databases can store arbitrary data and that namespaces can be used to store data from different domains without breaking other applications. This way, the visualizer can store some meta- information about the data directly in the database. For in- stance, one of the nodes can be marked as the best starting node and the visualizer can start by querying the database for such node.

This eliminates the need to compute the starting node ev- ery time the visualizer starts, but still it has to be computed at some point. The advantage is, that this process can occur at the server thus eliminating the huge data transfers. For example, application server modules of the Trisolda archi- tecture [7] are ideal for this task, but some solution could be used with any centralized RDF store.

This architecture allows us to use even complex analysis of the whole data to select the starting node.

But let us start with some simpler possibilities. In some cases, the starting node can be specified manually. For ex- ample, consider RDF data containing organizational struc- ture ? in this case, the root of the structure is probably the best place to start a visualization and it can easily by de- fined by the database administrator or by the user during his or her previous session.

Another simple case is selection of a random node. This would work for data that correspond to a graph with rela- tively small diameter. In that case, any node can be used to quickly navigate to any part of the graph. The question is determining the random node. One possibility is to use  the server-side processor that selects a node and marks it as a root. Another, much simpler, is making a database query whose solution is the list of all triples (or nodes ? depend- ing on the query language used). The visualizer can either choose a random node from the complete result set or sim- ply select the first record returned by the server.

A whole class of algorithms can be defined as graph- based selection. These focus on the structure of the graph defined by the RDF statements and usually require some server-side processing since they process the whole data.

Obvious examples are finding the center of the graph or finding the node with the highest degree. The idea is that such nodes provide good access to the rest of the graph.

Using the center of the graph produces undesirable result if the graph contains a long path ? in that case the start node can easily be near the center of the path forcing the user to navigate to one end. This situation can occur if there is a big collection represented as a first-rest type of a linked list.

Using a node with the highest degree is even more likely to select a bad starting point. The reason is, that e.g. node that represents the numeric literal 1 is very likely to have a high degree and it may be connected to many different types of nodes. In that case, we face a problem very similar to the starting node selection problem, only the number of possibilities is limited.

An interesting option is some variant of the PageRank [9] algorithm. But it is problematic, since in the visualiza- tion incoming and outgoing edges are equally important and the PageRank would likely select a node with high number of incoming edges, resulting in the same problem that was described for the highest degree selecting algorithm.

A completely different approach is to start the visualizer with a search dialog that allows the user to select a node.

The problem is that the user has to be at least partially fa- miliar with the data. An alternative is to list all predicates used in the data. Their number should be much lower, usu- ally tens or hundreds of different URIs. After that, some of the previous techniques can be used to select the starting node with the limitation that it must be an endpoint of an edge labeled by the selected predicate. For instance, one such node can be selected randomly.

Yet another variant is to strengthen the cooperation be- tween the server and the visualizer. As the user navigates the data, the visualizer informs the server about the nodes the user visited and the server keeps the statistics. As was mentioned earlier, this information can be stored by the RDF store alongside the actual data. The starting node is determined by randomly selecting one of the nodes that was visited most times. Note that displaying a node as one item in the merged node is not considered to by a visit to the node. The user must actually navigate to the node ? this eliminates the problems caused by common literals (like the number 1).

So far we have assumed that the visualized graph is con- nected, i.e. there is a (non-directed) path between any two nodes. But the RDF data need not look that way, although it is common, since for example the whole data may share the same class hierarchy or two parts may be connected via a literal.

If the data is not connected and we cannot use server- side analysis, there is no way to handle the problem since we need (almost) the whole data to check whether it is con- nected or not.

With server side processing we can identify the compo- nents of the graph and then select starting node for each of them separately. Then we create a virtual node and con- nect it to all of the individual starting nodes. The virtual node and the new edges are sent to the user as the starting (merged) node. While we could present the user with some list of components, this solution should be just as useful and does not introduce new concepts to the visualizer applica- tion.

Based on these options, we have decided to use the fol- lowing solution. If the data on the server contain informa- tion about preferred starting node, it is used. If no server side processing can be done and the data is read from a re- mote data source (a database), we can only use a random starting node. This means, that if the data is not connected, the user cannot access the whole data. If the data can be made available locally (e.g., if the visualizer is used to pro- cess one local RDF file or we know that the size of the data is comparable to the transfer rate from the server and lo- cally available memory) we use the random node approach but extended with component handling described in the pre- vious paragraph. If server-side processing is available we perform component analysis on the server and then return random node for each component.

A search dialog is an interesting option for any situation, but its design and capabilities have to be tailored to the ac- tual data access layer used by the visualizer. Still, it should be present at least in some limited form in all situations. To at least handle the situation where the user is interesting in one specific node (i.e., the URI or literal value is known).

It is tempting to include the statistics of users? behav- ior. The problem with this approach is the use-case we are trying to handle, i.e. pure RDF visualization for software developers. For this approach to work, we need to collect reasonably large sample. This means having large group of developers working on the same data set. When new devel- oper joins the team, he or she may benefit from the usage data already collected, but it is questionable whether the rel- atively large effort is worth it. Despite all these doubts, we plan to test such system in the future.

2.2 Nodes with high degree  In order to create only reasonable drawings of the dis- played graph, we cannot allow merged nodes to have arbi- trary height. The maximal reasonable number of edges dis- played in a merged node seems to be somewhere between 20 and 40. But the actual degree of a node can go to thou- sands or in extreme cases even millions (one of our test data sets contains a node with degree of about 1.3 million, al- though it was rather pathological situation).

As we have already mentioned, while the number of in- cident edges (i.e. statements that contain the value repre- sented by the node in question) can be very large, the total number of different predicates is usually small. If this is the case, we can display only one row for each predicate either listing the predicate and total number of edges or predicate, total number of edges and one example. The choice de- pends on the data layer ? whether it is capable of providing just the number in a much more efficient way (e.g., a vari- ant of SQL?s select count(*) . . . group by . . . ) than providing the number and the example (e.g., by listing all nodes). To help the user backtrack his or her way through the graph the edge connecting a node to its parent (the node it was reached from) is always displayed as a separate line. This is also done with the edges that connect the node to any other node that is currently displayed, providing that the number of such edges is small.

There is one typical situation where the predicate based ?compression? would not work. The RDF recommendation provides vocabulary for containers and members of the con- tainer are specified by sequentially numbered predicates.

This usually means that there are as many different predi- cates as there are outgoing edges. Fortunately, this situation is easily distinguishable and can be solved by displaying only some elements stored in the container. The actual of displayed elements depends on the count of other incident edges ? such edges have precedence over the elements in the container and they are handled as if there were no ele- ments only with slightly lower limit for the number of rows ? we always want to display at least a few elements stored in the container.

If even the reduced number of rows that should be dis- played in the merged node is too high, we display only the most important (with highest cardinality) rows and use the last row to inform the user about the total number of edges and predicates that had to be omitted.

It is obvious that we need to provide the user with some way of accessing even the edges that have not been dis- played in the merged node. Such situation is always rep- resented graphically ? either the number of edges with the same predicate is displayed or the rows-omitted notice is present. In such case the user can display a special dia- log that can be used to search the complete list of incident     edges. The user can specify a substring or regular expres- sion (this once again depends on the capabilities of the un- derlying data layer ? some RDF stores can handle regular expressions, some cannot) for the value of subject, predi- cate or object and all edges that satisfy the condition are displayed.

Note that it does not make sense to specify both sub- ject and object since one of them must be equal to the node whose neighbors we are exploring. The predicate can be selected from the list of all relevant predicates since ? as we have already stated ? their number is small in most cases.

The user can select any node displayed this way and ex- pand the current view of the graph by addition of that node.

3 Multiple views  One of the significant advances in web browsers was the addition of tabs, i.e. the ability to display more pages with- ing one browser instance and quickly switch between them.

It has quickly become very popular. Some people use even tens of tabs while they surf the Web, requiring addi- tional improvements to the tabs support in browsers or third party plug-ins to better organize the tabs.

Two common usage scenarios are browsing pages like Wikipedia or e-shopping. In the first case many users tend to read one page and when they encounter an interesting link they open it as a new tab but continue reading the original page. The opened tabs contain topics the user intends to read in the future. When shopping, one common practice is to browse the categories in the shop and open pages for items that appear interesting at a first glance in new tabs.

After browsing the categories, the user explores the selected items in greater detail and closes the tabs with items he or she is no longer interested in.

These are similar to some of the ways an RDF visualizer can be used. The user is either exploring the data and he or she may come to a point where two or more promising directions of further navigation are at hand. Or the user may be ?shopping? for interesting data, i.e. searching for data items that are worth further analysis or processing.

Addition of tabs to an RDF visualizer is very straightfor- ward ? all possible drawings (the basic view, node neigh- bor explorer, special views like reification view or neighbor view, . . . ) can be displayed as a tab. At any point where such view can be opened, it can be opened as a new tab.

Furthermore, any node in any view can be used to open new tab with the visualization containing only the selected node because it is displayed as a merged node so the user can navigate (explore) the neighborhood of the node.

4 Big fat graphs  As we have already stated, we cannot display the whole data as their amount cannot even be processed in reason- able time, let alone display it within reasonable space. Of course there are visualizations, where this can be done (for example visualizations of web page relations or large so- cial networks), their purpose is to only suggest the overall structure of the data, not display individual items.

Although our visualization ? the triangle layout algo- rithm ? produces asymptotically optimal area [6], the layout alone can not overcome the problem raised by the large size of the graph. Some navigation in the graph is necessary.

In [8] authors summarize three basic ways for navigation in large graphs.

Zoom is traditional tool in visualization. It is well suited for graphs, since in most cases the zoom can be made easily by scaling the image. However, for the zoom we have to draw the whole image (whole RDF graph) first.

This is often impossible since the size of the data may exceed the available memory or the load time may be way too long.

Focus+context Another well known problem with zoom- ing is the loss of the context. This can be partially over- come by displaying a map of the whole graph. Other possibility is to draw focus and context in the same image. For this purpose the fisheye technique can be used. The technique is independent of the layout al- gorithm and is practically a separate processing step on the graphical layout of the graph. The view of the graph enlarges the area of interest (the so called focus) and shows the other parts of graph with less details (e.g. more distant parts are smaller).

Incremental exploration. As we have already mentioned, the size of the graph may prevent us from processing it all at once. Incremental navigation is a good choice in such cases. Only a small part of the graph ? a logical frame ? is displayed (possibly even just one node) and then according to some strategy new logical frames are generated as modifications of previous frames.

In our RDF visualizer we use the incremental explo- ration, where the user navigates the data by adding con- nected nodes to the already visible part of the graph. How- ever, even by the navigation the graph may grow more than we can display. Therefore we need additional navigation in the displayed view. For this purpose either a map (see Figures 2(a) and 2(b)) of the context or a cartesian fish- eye view (see Figure 2(c)) may be used. Since the current frame (displayed part of the whole data) is smaller than the     (a) Map (b) Focus (c) Cartesian fisheye view (the same focus)  Figure 2. Additional navigation  data by several orders of magnitude, we can use the tech- niques without worrying about required memory and com- putational time.

5 Related work  Some of the approaches described in the section 2 are de- pendent on the node merging technique, but most of them can either be used directly in other visualizers, adapted for different drawings or the visualizers can be extended to sup- port node merging (this would be possible in many of them).

The starting node selection problem is common for all vi- sualizers. Since most of the visualizers always display all neighbors of a node, the problem of picking the rows to dis- play in a merged node do not apply to them directly.

But in order to display nodes with extremely high degree, some of them would have to adopt a similar approach since most drawings of the RDF graph cannot reasonably handle nodes with a million or more neighbors.

The node neighbor explorer could be used in any visu- alizer as well as tabbed browsing. Most of the visualizers already have their ways to handle large graphs.

6 Conclusions  The extreme size of many RDF data sets is a big concern for any RDF visualizer. In this article, we pointed out some of the problems with several variants for their solution.

One big problem is the selection of the first node to be presented to the user. We have presented several options, but the different deployment scenarios and the size of the data together with the fact that there are no limitations to their structure (connected/unconnected graph, arbitrary de- gree of nodes etc.) limit the usability for most of them, making even the most simple solution ? selecting a random node ? an interesting and reasonable option.

A similar, but fortunately more limited, situation is han- dling of nodes with high degree. Typical properties of RDF  data (most notably the limited number of distinct predi- cates) allow for better handling of such situation. The user can be presented with a condensed overview while being able to access all neighbors via a search dialog.

An interesting way of extending a navigating visualizer (not only for RDF) is to use tabbed browsing known from most current web browsers. While unusable to visualize the data directly, some of the common graph drawing tech- niques can be used in conjunction with the navigation.

