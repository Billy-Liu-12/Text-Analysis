Mining Data Streams with Labeled and Unlabeled Training Examples?

Abstract  In this paper, we propose a framework to build predic- tion models from data streams which contain both labeled and unlabeled examples. We argue that due to the increas- ing data collection ability but limited resources for labeling, stream data collected at hand may only have a small num- ber of labeled examples, whereas a large portion of data re- main unlabeled but can be beneficial for learning. Unleash- ing the full potential of the unlabeled instances for stream data mining is, however, a significant challenge, consider that even fully labeled data streams may suffer from the concept drifting, and inappropriate uses of the unlabeled samples may only make the problem even worse. To build prediction models, we first categorize the stream data into four different categories, each of which corresponds to the situation where concept drifting may or may not exist in the labeled and unlabeled data. After that, we propose a rela- tional k-means based transfer semi-supervised SVM learn- ing framework (RK-TS3VM), which intends to leverage la- beled and unlabeled samples to build prediction models.

Experimental results and comparisons on both synthetic and real-world data streams demonstrate that the proposed framework is able to help build prediction models more ac- curate than other simple approaches can offer.

1. Introduction  Due to the increasing availability of data recording and transmission techniques, applications such as data ware- housing and sensor networking are facing dynamic data streams instead of static data sets. Such dynamic natures of data streams raise two fundamental challenges for data mining research: (1) large and continuous data volumes and  ?This research has been supported by the National Science Foundation of China (NSFC) under Grant No. 60674109, and the National Basic Re- search Program of China (973 Program) under Grant No. 2007CB311100  (2) evolving or drifting of the concepts (or patterns) under- neath the data. Motivated by the two challenges, a lot of work exists for association rule mining [8], clustering [1], and building prediction models [4, 7, 12, 16, 15].

From classification perspective, two sets of solutions ex- ist for building prediction models from data streams: incre- mental learning [4] and ensemble learning [12, 9, 16, 15].

The former uses new data to update the models trained from historical stream data so the learning process is able to scale up to large data volumes as well as adapt to the changing concepts. Ensemble learning, on the other hand, trains a number of base models from a small portion of stream data (i.e., a data chunk), and combines all base models to form an ensemble classifier for prediction. For either approach, one presumption is that the underlying stream data must be fully labeled. In practice, labeling training examples is a costly procedure which requires full attention and intensive investigation on the instances. For stream data with con- tinuous data volumes, this becomes a huge burden or even infeasible to realize.

Consider a bank fraud detection center which audits daily credit card transactions to determine high risk or fraudulent transactions. In order to build an automatic fraud prediction model, it is essential to let banking experts pro- vide (label) a number of fraud transactions as training sam- ples. The labeling ability the experts can offer is rather lim- ited and probably no bank is willing to pay experts to man- ually label every single transaction, assuming that 10,000 transactions may arrive on a daily basis. A more practical solution is to label a small portion, say 1% or 5%, of trans- actions, but keep the rest of the transactions unlabeled. Due to the missing of the labels, none of the existing stream min- ing algorithms is able to utilize such unlabeled data to help train fraud prediction models.

Indeed, just because stream data have large volumes it does not necessarily mean that mining algorithms are able to utilize them all. Hiding behind the large/continouse data volumes of the stream data is the reality that only a small portion of samples are actually labeled. Unfortunately, al-   1550-4786/09 $26.00 ? 2009 Crown Copyright DOI 10.1109/ICDM.2009.76     though many methods exist for mining data streams, very few attempts have been made to address unlabeled sam- ple issue. For static data sets, active learning and semi- supervised learning are two common approaches to solve the problem, where the former intends to reduce the label- ing cost and the latter directly utilizes the unlabeled sam- ples to boost the learning. In [16], Zhu et al. proposed an active learning framework to minimize the labeling cost for stream data, and the main goal is to select the most impor- tant sample for labeling such that the classifiers built from the stream data can gain maximum prediction accuracies.

A recent work [10] also addresses the limited training ex- ample problem for stream data by using semi-supervised clustering techniques. But no work currently exists to help understanding the impact of the unlabeled samples on the concept drifting of the data streams.

To build prediction models from stream data, one impor- tant task is to identify and emphasize on historical examples which share identical or similar distributions to the test data (usually the stream data at the next time point). This prob- lem, in practice, is difficult to solve given that we may not have any prior knowledge on the test data and we also do not know when and where the concept drifting may occur [6]. Consequently, most stream mining methods take the assumption that data which are temporally close are also relevant to each other at the concept level. So if we can separate data streams into chunks with the assumption that instances within a chunk share identical distributions (e.g., no concept driting), the most recent data chunk (up-to-date chunk) can be used to train classification models to predict instances yet to arrive (i.e, yet-to-come chunk) [12, 9, 15].

Although this assumption is popularly accepted in data min- ing research, for data stream with both labeled and unla- beled samples (referred to as mixed stream in this paper), samples within one data chunk may not share an identical distribution. Consider that even fully labeled stream data are suffering from the concept drifting problem, the exis- tence of unlabeled samples only makes the learning from data stream even more challenging. Answers to the follow- ing three fundamental questions are needed before we can devise effective algorithms for mixed data streams.

? What are the typical concept drifting scenarios for data streams with unlabeled samples?

? How to categorize the mixed stream data in order to re- veal the genuine concept drifting underneath the data?

? How to devise effective solutions to handle different categories of stream data, so the whole mining frame- work can be effective for mixed data streams?

In this paper, we report our research efforts in resolving the above three concerns. In short, we revisit the concept drifting scenarios by categorizing instances in mixed data  streams into four types: (1) labeled (Type I) and unlabeled (Type III) examples which have the same distributions as the yet-to-come data chunk; and (2) labeled (Type II) and unlabeled (Type IV) examples which have similar distri- butions to the yet-to-come data chunk. Based on the cat- egorizations, we propose a new Transfer Semi-Supervised SVM (TS3VM) model to learn from Types I, II, and III in- stances. A relational k-means (RK) based model is also pro- posed for learning from Type IV examples. By combining TS3VM and RK together, we propose a RK-TS3VM learn- ing framework which is able to fulfill the learning from the mixed data streams.

The remainder of the paper is structured as follows. Sec- tion 2 discusses data categorization for mixed data streams.

We derive a new Transfer Semi-Supervised SVM (TS3VM) model and a relational k-means (RK) model in Section 3.

Section 4 formulates the complete RK-TS3VM learning framework. Experimental results are reported in Section 5, and we conclude this paper in Section 6.

2. Categorizing sample types for mixed data streams  Assume stream data arrive chunk by chunk with each chunk containing a number of labeled and unlabeled in- stances. At any specific time, the yet-to-come data chunk is dedicated as the target domain and the mining purpose is to build prediction model to accurately classify instances in the yet-to-come data chunk. For this purpose, the in- stances in the up-to-date chunk can be used to train pre- diction models, under the constraint that only a small por- tion of instances in the up-to-date chunk are labeled. To accurate describe the concept drifting scenarios for mixed data streams, we can category the examples in the up-to- date chunk into following four types based on the samples? distributions with respect to the distributions of the target domain (i.e, the yet-to-come chunk): (1) labeled and same distribution examples (Type I Examples), labeled and simi- lar distribution examples (Type II Examples), unlabeled and same distribution examples (Type III Examples), and unla- beled and similar distribution examples (Type IV Examples).

A conceptual view of the above four categorizations is shown in Fig. 1. Assume the yet-to-come data chunk (test chunk) is dedicated as the target domain, blue solid circles denote the labeled and same distribution examples (Type I), red solid circles denote the labeled and similar distribu- tion examples (Type II), blue hollow circles denote the un- labeled and same distribution examples (Type III), and red hollow circles denote the unlabeled and similar distribution examples (Type IV). Due to the temporal correlations [12] of the concepts, Types I and III data usually locate at the tail of the training chunk, which are close to the yet-to-come chunk. Types II and IV data usually locate at the head of     ??  Type I  Type III Type IV Type II  Test chunk Training chunk  Up-to-date chunk Yet-to-come chunk Historical stream data  Figure 1. A conceptual view of the example type catego- rization for mixed data streams.

the training chunk, which are relatively far away from the yet-to-come chunk.

After defining the four types of examples for mixed data streams, a following question is how to identify their sizes and locations in the up-to-date chunk (training chunk). In- tuitively, the percentage of labeled examples depends on the labeling speed the experts can offer and the number of the same distribution examples depends on the concept drifting rate. As shown in Fig. 1, Types I and III examples usu- ally locate at the tail of the up-to-date chunk while Types II and IV examples locate at the head of the up-to-date chunk.

Consider a data stream which flows at a speed of n exam- ples per second, and its concept drifts with a possibility of c, where 0 ? c ? 1. At each time stamp, a training chunk D = {x1, ? ? ? , xn} is buffered and labeled by experts with a speed of l examples (l ? n) per second. The number of the same distribution examples will have a reverse proportion to the concept drifting rate c with a constant coefficient ?, so we can estimate that about ? ? c?1 ? n examples in chunk D have the same distributions as the test examples while the remaining (1 ? ? ? c?1) ? n examples will have similar dis- tributions as the test examples. Denote the size of the four types of examples as L1, L2, L3, and L4 respectively, we can estimate that their values are given in Eq. (1).

L1 = ? ? c?1 ? l; L2 = (1 ? ? ? c?1) ? l L3 = ? ? c?1 ? (n ? l); L4 = (1 ? ? ? c?1) ? (n ? l) (1)  Ideally, we can exactly identify the sizes of the four types of examples by calculating Eq.(1). In practice, we may not have any prior knowledge on the concept drifting rate c, so the above two equations can?t be used directly. In this case, an alternative solution is to assign an empirical small value to c. In our experiments in Section 5, the 10% examples at the tail of the training chunk are assigned as the same dis- tribution examples. In following sections we will propose detailed solutions for learning from the four types of data.

3. TS3VM and RK learning models  In this section, we introduce two learning models to han- dle the four types of examples in the mixed stream. More  specifically, because Types I & III examples are assumed to have the same distributions as the target domain, generic semi-supervised learning model [14, 3, 2] (we use SVM in this paper) can be used to directly train classifiers from Types I & III data. For Type II samples, although they are assumed to have different distributions from the target domain, because they are labeled, we can employ transfer learning principle [5] to build models from Type II sam- ples. Consequently, our first objective is to devise a trans- fer semi-supervised learning based model (TS3VM) to train classifiers from Types I, II, & III examples. For type IV ex- amples, because they are unlabeled and have different distri- butions from the target domain, we will propose a relational k-means based learning model (RK) to handle such data.

The final learning framework (RK-TS3VM) (discussed in Section 4) will then combine the strength of TS3VM and RK to train prediction models from the mixed stream.

For ease of understanding, we will use bi-class classi- fication as an examples to articulate our algorithm design.

The four types of examples are simplified as follows: Type I data are denoted by T1 = (x1, y1), . . . , (xL1 , yL1 ) , where xi ? Rd, d is the dimension, yi ? {?1,+1}; Type II data are denoted by T2 = {(xL1+1, yL1+1), . . . , (xL, yL)}, where L = L1 + L2 ; Type III data (U unlabeled examples) are denoted by T3 = {xL+1, . . . , xL+U }; and Type IV data (N un- labeled examples) is denoted by T4 = {xL+U+1 , . . . , xL+U+N }.

3.1 TS3VM Learning Model  Intuitively, the TS3VM model can be formulated by se- quentially incorporating instances in T1, T2, and T3 for learning. More specifically, we first formulate a generic SVM model by taking Type I examples into consideration.

After that, we can formulate a transfer SVM model by tak- ing Type II examples into consideration. Finally, we can in- clude Type III examples and formulate the TS3VM model.

3.1.1 Learning from Type I Examples  To learn from T1 = {(x1, y1), . . . , (xL1 , yL1 )}, a generic SVM model can be trained by maximizing the margin distance be- tween classes while minimizing the error rates as given in Eq. (2), where w is the projection direction, b is the classifi- cation boundary, ?i is xi?s error distance to b, and parameter C denotes the penalty of the examples inside the margin.

min ||w||2 +C  L1? i=1  ?i (2)  s.t. : yi(wxi + b) ? 1 ? ?i ?i ? 0, 1 ? i ? L1  The SVM model given in Eq. (2) is a constrained con- vex optimization problem. To simplify the expression, the Hinge Loss function [3] in Fig. 2 can be used to transform     Eq. (2) into an unconstrained convex optimization problem as defined by Eq. (3), where ? = (w, b) and f?(x) = (wx+b).

The similar approaches have been commonly used to for- mulate the semi-supervised SVM model [2].

min? ||w||2 +C  L1? i=1  H(yi f?(xi)) (3)  Figure 2. An illustration of the Hinge Loss function (a) H(t) = max(0, 1 ? t), and the Symmetric Hinge Loss func- tion (b) H(t) = max(0, 1 ? |t|). The Hinge Loss func- tion is equivalent to the following optimization problem: min ?, s.t. : ? ? 0, ? ? 1 ? t.

3.1.2 Learning from Types I & II Examples  Existing research has shown that SVM is capable of iden- tifying optimal classification boundaries given sufficient number of training samples. In practice, the number of samples in T1 may be very limited, which may leave clas- sical SVM incapable of learning the optimal classification boundaries. To overcome such deficiency, transfer learn- ing can use labeled samples in T2 to refine the classification boundary by transferring the knowledge from T2 to T1. An effective way to transfer the knowledge between T2 and T1 is to take the problem as a multi-task learning procedure [5].

A common two-task learning SVM model on T1 and T2 can be formulated as in Eq. (4), where parameters C1 and C2 are the penalties on each task, v1 and v2 are the discrepan- cies between the global optimal decision boundary w and the local optimal decision boundary (i.e., w + v1 for task 1 and w + v2 for task 2).

min ||w||2 +C1||v1||2 +C2||v2||2 +C  L? i=1  ?i (4)  s.t. : yi((w + v1)xi + b) ? 1 ? ?i, 1 ? i ? L1 yi((w + v2)xi + b) ? 1 ? ?i, L1 + 1 ? i ? L ?i ? 0, 1 ? i ? L  In Eq. (4), parameters C1 and C2 controls the preference of the two tasks. If C1 > C2, then it prefers task 1 to task 2; otherwise, if C1 < C2, it prefers task 2 to task 1 (Our experimental results in Section 5 will further study the re- lationship between C1 and C2). By using the Hinge loss function, Eq. (4) can be transformed into an unconstrained form in Eq.(5) where ? = (w, v1, v2, b) , f?(x) = (w+v1)x+b for task 1 while f?(x) = (w + v2)x + b for task 2.

min? ||w||2 +C1||V1||2 +C2||V2||2 + C  L? i=1  H(yi f?(xi)) (5)  3.1.3 Learning from Types I, II, & III Examples  In addition to T1 and T2, learning on T3 may further im- prove the performance in the reason that (i) labeled samples in T1 and T2 are only a small percentage of the whole train- ing examples; and (ii) T3 contains a relatively large number of examples that come from the same distribution as the test examples, which can greatly help in differentiating the gen- uine classification boundaries. In past several years, learn- ing from a large number of unlabeled examples has been extensively studied from semi-supervised learning perspec- tive. An effective way to train a semi-supervised learning model is to find a classification boundary that achieves a maximum margin not only between labeled examples, but also unlabeled examples, i.e., semi-supervised SVM [2] adds an extra term C?  ?L+U i=L+1 H(| f?(xi)|) to penalty the mis-  classification of unlabeled examples which locate inside the margin as shown in Eq. (6),  min? ||w||2 + C  L? i=1  H(yi f?(xi)) +C ?  L+U? i=L+1  H(| f?(xi)|) (6)  Thus, by adding the last term of Eq. (6) (which is used to learn from T3) onto Eq. (5) (which is used to learn from T1 and T2), We finally derive the objective function of TS3VM in Eq. (7), where ? = (w, v1, v2, b) , and f?(xi) = (w+v1)xi+b for 1 ? i ? L1, f?(xi) = (w + v2)xi + b for L1 + 1 ? i ? L, f?(xi) = wxi + b for L + 1 ? i ? L + U.

min? ||w||2 +C1||v1||2 +C2||v2||2  +C L?  i=1  H(yi f?(xi)) +C ?  L+U? i=L+1  H(| f?(xi)|) (7)  Balance Constrain A possible difficulty of the TS3VM model is that all unlabeled examples in T3 may be classified into one class with a very large margin, which may lead to poor performance. To solve the problem, an additional balance constraint should be added to ensure that unlabeled examples in T3 should be assigned into both classes. In the case that we don?t have any prior knowledge about the class ratio in T3, a reasonable way [3] is to estimate its class ratio from T1 and T2 as in Eq.(8),  U  L+U? i=L+1  f?(xi) = L  L? i=1  yi (8)  Thus by taking account of the balance constrain, we derive the TS3VM model in Eq.(9),  min? ||w||2 +C1||v1||2 +C2||v2||2 (9)  +C L?  i=1  H(yi f?(xi)) +C ?  L+U? i=L+1  H(| f?(xi)|)  s.t. : U  L+U? i=L+1  f?(xi) = L  L? i=1  yi  where ? = (w, v1, v2, b) , and f?(xi) = (w + v1)xi + b for 1 ? i ? L1, f?(xi) = (w + v2)xi + b for L1 + 1 ? i ? L, f?(xi) = wxi + b for L + 1 ? i ? L + U.

3.1.4 Solution to the TS3VM Objective Function  As shown in Eq. (9), the objective function of TS3VM is a non-convex optimization problem, which is difficult to find global minima especially for large scale prob- lems. To overcome this difficulty, we propose to solve this non-convex problem by using Concave-Convex Procedure (CCCP) which was developed by the optimization commu- nity in the last few decades [13, 3, 2]. CCCP method de- composes a non-convex function into the sum of a convex function and a concave function, and then approximates the concave part by using a linear function (a tangential approx- imation). By doing so, the whole optimization procedure can be carried out iteratively by solving a sequence of con- vex problem. Algorithm 1 describes the algorithm in detail.

Algorithm 1 CCCP Algorithm Require: the objective function J(?)  Get the initial point ?0 with a best guess J(?) = Jvex(?) + Jcav(?) repeat ?t+1 = argmin? Jvex(?) + J?cav(?t) ? ?  until convergence of ? return a local minima solution ??  From the CCCP perspective, we can observe that the first four terms TS3VM are convex functions, whereas the last Symmetric Hinge Loss part C?  ?L+U i=L+1 H(| f?(xi)|) makes it a  non-convex model. Thus, we will decompose and analysis the last part by using the CCCP method. To simplify the no- tation, we denote zi = f?(xi) , so the last part can be rewrit- ten as C?  ?L+U i=L+1 H(|zi|). Considering a specific zi (without  loss of generality, we denote it as z here), the Symmetric Hinge Loss on z can be denoted by J(z) as in Eq.(10),  J(z) = C?H(|z|) (10) Eq.(10) is a non-convex function, which can be spitted into a convex part and a concave part as in Eq.(11),  J(z) = C?H(|z|) = C?max(0, 1 ? |z|) +C?|z|?????????????????????????????????????????????????????? Jvex (t)  ?C?|z|???? Jcav(t)  (11)  According to Algorithm 1, the next iterative point can be calculated by the approximation of the concave part Jcav as shown in Eq.(12),  ?Jcav(z) ?z  ? z = {  C?z, z < 0 ?C?z, z ? 0 (12)  and then minimizing Eq.(13),  J(z) = C? ? max(0, 1 ? |z|) +C?|z| + ?Jcav(z) ?z  ? z (13) If at the current iteration z < 0, then to the next iteration,  the effective loss on this point can be denoted as L(z,?1) in Eq.(14):  L(z,?1) = C?max(0, 1 ? |z|) +C?|z| +C?z = ?????????  2C ?z, z ? 1 C?(1 + z), |z| < 1 0, z ? ?1  (14)  On the contrast, if z ? 0, then to the next iteration, the effective loss on this point can be denoted as L(z,+1) in Eq.(15),  L(z,+1) = C?max(0, 1 ? |z|) +C?|z| ?C?z = ?????????  0, z ? 1 C?(1 ? z), |z| < 1 ?2C?z, z ? ?1  (15)  By doing so, at each iteration, when taking all the zi = f?(xi) into considering, solving TS3VM model is equivalent to solving Eq.(16) under the balance constrain Eq.(8),  min? ||w||2 +C  L? i=1  H(yi f?(xi)) + L+U?  i=L+1  L( f?(xi), yi) (16)  where yi (L + 1 ? i ? L + U) is the class label of the corresponding xi which has been assigned at the previous iteration. If yi < 0, then Eq.(14), will be used to calculate the loss function, else Eq.(15), will be used to calculate the loss function. The detailed description of solving TS3VM is given in Algorithm 2.

Algorithm 2 TS3VM Learning Model Require: T1, T2 and T3  Use T1 and T2 to build a transfer SVM model as shown in Eq.

(4), and get the initial point ?0 = (w0, v10, v20, b0) repeat  yi ? sgn(wxi + b), ?L + 1 ? i ? L + U ?? Calculate Eq.(16) under the balance constraint Eq.(8)  until yi remains unchanged, ?L + 1 ? i ? L + U return f (x) = sgn(wx + b)  Kernel Trick The TS3VM model in Eq.(9) can be only used for linear classification. To identify non-linear classifica- tion boundaries, we can incorporate the kernel function into TS3VM by simply replacing the quadratic terms with a form of the sum of the mapped examples  ?L+N i=1 ?i?(xi), where ?(?)  denotes a high dimensional feature mapping function [11].

Thus the optimization problem Eq.(9)) shifts to a new opti- mization problem with ?i as the variables.

3.2 RK Learning Model  Learning from T4 is more challenging than learning from T1, T2, and T3 because examples in T4 are unlabeled and have different distributions from the target domain. In this section, we introduce a relational k-means (RK) [17] based learning model which aims to construct some new features to the labeled examples by using information extracted from unlabeled instances in T4. An example of the RK learning is shown in Fig. 3, where instances in T4 are fist clustered into a number of k clusters, G1, ? ? ? ,Gk based on a relational matrix built between T1 and T4. After that, k new features f (xi,G?) (? = 1 ? ? ? , k) are added to each instance xi in T1 to construct a new data set T ?1 by calculating the relationship between xi and each cluster center. By doing so, the new     data set T ?1 will contain information transferred from T4, which can help build a more accurate prediction model.

Class label for T1Information from T4  A1 A2 .. Ad G1 .. Gk Y 1 2 .. 5 f (x1, G1) .. f (x1, Gk) 1 .. .. .. .. .. .. .. ..

3 7 .. 1 ),( 11 Gxf L .. ),( 1 kL Gxf 2  Information from T1  Figure 3. An illustration of the RK learning model  Given L1 examples in T1, and N examples in T4. The purpose of the relational k-means clustering is to cluster in- stances in T4 into a number of groups, by taking the rela- tionships between instances in T1 and T4 into consideration.

Assume W ? RL1?N denotes the similarity matrix between T1 and T4 with each wi, j describing the similarity (which can be calculated according to the Euclidian distance) be- tween instance xi in T1 and instance x j in T4, for each clus- ter G? on W the average pair-wise similarities of all exam- ples in G? can be defined as in Eq. (17),  S G? = |G?|2  ? x?G?  ? x??G?  S (x, x?) (17)  where S (x, x?) denotes the similarity of two examples x and x?.

On the other hand, the variance of the relationship values of all examples in G? can be calculated by Eq. (18).

?G? = |G?| ? yi?G?  (? j ? ?G? )T (? j ? ?G? ) (18)  where ?G? denotes the average relationship vector of all instances in G?, and ?i ? R1?L1 denotes the relationships of instance x j with respect to all examples in T1. The ob- jective of the relational k-means is to find k groups, G?, ? = 1, ? ? ? , k, such that the sum of the similarities is max- imized while the sum of variances is minimized as defined by Eq. (19),  J?e = max k? ?=1  JG? = max k? ?=1  S G? ?G?  (19)  Explicitly solving Eq. (19) is difficult, alternatively, we can employ a recursive hill-climbing search process to find so- lutions. Assume instances in T4 are clustered into k clusters, G1, ? ? ? ,Gk, moving an instance x from cluster Gi to cluster G j will only change the cluster objective values JGi and JGj .

Therefore, in order to maximize Eq. (19), at each step t, we can randomly select an instance x from a cluster Gi, and move x to cluster G j. We accept the movement only if the Inequity (20) reaches a larger value at step t + 1.

JGi (t) + JG j (t) < JGi (t + 1) + JG j (t + 1) (20)  Based on the search process in Inequity (20), major steps of the relational k-means are listed in the Algorithm 3.

Algorithm 3 Relational k-means Clustering Require: T1, T4, number of clusters k, and number of iterations T  W ? Calculate similarity matrix between T1 and T4 G1, ? ? ? ,Gk ? Apply k-means to W for t ? 1 to T do  x? Randomly select an instance from T4 Gi ? current cluster of instance x JGi (t)? Calculate Gi?s objective value in Eq. (19) JGi (t + 1)? Gi?s new value after excluding x for j? 1 to k, j ? i do  JG j (t)? Calculate G j?s objective value JG j (t + 1)? G j?s new value after including x if Inequity (20) is true then  G j ? G j ? x; Gi ? Gi \ x Break  end if end for  end for ?1, ? ? ? , ?k ? Calculate cluster centers for G1, ? ? ? ,Gk return ?1, ? ? ? , ?k  4 RK-TS3VM Learning Framework  Algorithm 4 lists the detailed procedures of the RK- TS3VM learning framework which is the combination of the TS3VM and RK learning models. Given a training chunk D, the first step is to identify the four types of ex- amples T1, T2, T3, T4 based on the procedures discussed in Section 2. The second step is to construct a group of k feature vectors, denoted by ? = {?1, ? ? ? , ?k}, by applying RK to T1 and T4. In the third and fourth steps, the k new features will be appended to each instances in T1, T2, T3 to form three new sets denoted by T ?1, T  ? 2, and T  ? 3 respectively  (Section 3.2). The fifth step is to build a TS3VM model F from T ?1, T  ? 2, and T  ? 3 (Section 3.1). At the last step, the fea-  ture vectors ? and the TS3VM model are combined as the final prediction model. For any instance x in the test chunk, RK-TS3VM first calculate k new features for x, then uses TS3VM model to predict a label for x.

5. Experiments  In this section, we report experimental results and com- parisons of the proposed RK-TS3VM framework from the following three aspects: (1)the parameter setting for TS3VM; the algorithm performance with respect to the (2) concept drifting rate; and (3) the percentages of labeled ex- amples.

5.1 Experimental Settings  Benchmark Methods: We implement RK-TS3VM in C++ by using the VC++ 6.0 developing environment. Because RK-TS3VM is a SVM based learning framework, we use     Algorithm 4 RK-TS3VM Learning Framework Require: training chunk D, chunk size n, labeled rate l, concept  drifting rate c, number of clusters k  Step 1: Identify the four types of data T1, T2, T3, T4 in D ac- cording to the labeled rate l and concept drifting probability c using Eq. (1)  Step 2: Using RK model on T1 and T4 to get k cluster centers denoted by ? = {?1, ? ? ? , ?k} Step 3: for each instance x in T1, T2, and T3, add k attributes using the inner produce between x and ? Step 4: Get the new samples T ?1 , T  ? 2, and T  ? 3 from Step 3  Step 5: Construct a TS3VM model using T ?1, T ? 2, and T  ? 3, and  get the model F return ? and F together as the prediction model  the optimization package in the IMSL Fortran Library 1  to solve the TS3VM model in Eq.(9). To assess the algo- rithm performance, we use the conventional SVM model, the Transfer SVM (TrSVM) model (which is formulated following the mutli-task SVM model [5]), and the semi- supervsied SVM (S3VM) model on both labeled and unla- beled examples, as the benchmark models for comparisons.

We build the SVM and TrSVM models on labeled samples and the S3VM model is trained on both labeled and unla- beled samples.

Data Streams: A synthetic data stream and two real-world data streams are used in our experiments. The employment of the synthetic data stream is to assess the algorithm per- formance under different concept drifting scenarios (which we usually don?t have control on the real-world streams).

The real-world data streams provide the genuine algorithm performance in real-world environments.

In our experiment, the synthetic data stream is gener- ated as an infinite sequence of {(xi, yi)+?i=1} , where xi ? Rd is the feature vector and yi ? {?1,+1} is the class label.

The feature values of xi are generated by a uniform distri- bution between 0 and 1, and the classification boundary is controlled by Eq.(21),  d? i=1  ai xi = a0, (21)  where ai controls the decision boundaries. For each exam- ple xi, if  ?d i=1 aixi ? a0, it is labeled as yi = +1; otherwise,  yi = ?1. To simulate the labeling process, we randomly choose p percentage of examples and label them by using Eq.(21). To simulate the concept drifting, ai is given a prob- ability c (0 ? c ? 1) to evolve between ai and ai + 0.1 with 10% chance to reverse the direction. Besides that, we set a margin between the two classes. For the ?+1? class, the boundary is set to be  ?d i=0 aixi + 0.05; while for the ?-1?  class, the boundary is set to be ?d  i=0 aixi ? 0.05. To keep 1http://www.vni.com/products/imsl/  class distributions relatively balanced, we enforce the clas- sification boundary around the central point of the feature space by setting a0 = 12  ?d i=1 ai. In order to make the deci-  sion surface nonlinearly separable, 3% noise is introduced to the stream by randomly flopping the class labels of the selected instances.

Real-world data streams Two real-world data streams, Sensor and Power Supply, downloaded from the Stream Data Mining Repository [18], are used in our experiments.

Sensor stream contains information (temperature, humid- ity, light, and sensor voltage) collected from 56 sensors de- ployed in a lab environment. The data are read every 1-3 minutes from all sensors, and the whole stream contains information recorded over a 2 months period. The learn- ing task is to correctly identify the sensor ID (1 out of 56 sensors) purely based on the sensor data and the recording time. While the data flow over time, so do the concepts un- derlying the stream. For example, the lighting during the working hours is generally stronger than the night, and the temperature of specific sensors (conference room) may sud- denly rise during the meetings. Power Supply stream con- tains three year hourly power supply of an electricity com- pany from two sources: power supply from main grid and power transformed from other grids. The learning task of this stream is to predict which hour (1 out of 24 hours) the current power supply belongs to. The concept drifting in this stream is mainly driven by the issues such as the season, weather, or hour of a day. In our experiments, both streams are transferred into binary-class classification problems.

5.2 Parameter Setting for TS3VM  Four important parameters of the TS3VM objective func- tion in Eq.(9) are C1, C2, C, and C?. From multi-task learn- ing perspective, C1 and C2 control the discrepancies be- tween the global optimal boundary w and the local optimal boundary w + v1, and w + v2. If we assign a relative large value to C1 (compared to C2), the global optimal solution w will bias towards task 1, and vice versa. If we let C1 ? C2, i.e., C1C2 > 10000, v1 will approach to 0 and the classification boundary of Task 1 becomes the global optimal boundary.

The parameter C controls the penalty of the misclassified examples in T1 and T2, and the last parameter C? controls the penalty of the misclassified examples in T3.

In Fig.4, we report the accuracies of TS3VM (the y-axis) with respect to different parameter values (the x-axis). All the results are based on the average over 100 data chunks each containing 500 examples (synthetic data stream). The concept drifting probability c is set to be 50%, and the per- centage of labeled examples p = 10%. From Figs.4(a) and (b), we can observe that increasing C2 will result in a more noticeable performance deterioration than increasing C1. This is consistent our assumption that task 1 is supposed     0 0.01 0.1 1 10 100 1000 10000 0.95  0.96  parameter C  (a)  0 0.01 0.1 1 10 100 1000 10000  0.95  0.96  parameter C  (b)  0 0.01 0.1 1 10 100 1000 10000 0.93  0.94  0.95  0.96  parameter C*  (c)  0 0.01 0.1 1 10 100 1000 10000  0.95  0.96  parameter C  (d)  Figure 4. The parameter study of the TS3VM learning model. The y-axis denotes the prediction accuracies of TS3VM, and the x-axis denotes the parameter values for (a) C1, (b) C2, (c) C?, and (d) C, each varies from 0 to 10000.

to comply with the same distributions as the target domain.

The results in Figs.4(a) and (b) also suggest that a reason- able setting for C1 and C2 is to ensure that  C1 C2 = 10. From  Fig.4(c) we can observe that the performance of the TS3VM model has a significant improvement when C? increases from 0 (where the accuracy is about 0.93) to 1 (where the accuracy is above 0.96). That is to say, adding T3 to learn a classifier will significantly improve the performance. Based on the above observations, in following experiments, we set C1 to be 10 while the remaining to be 1.

5.3 Sensitivity to the Concept Drifting  In order to investigate RK-TS3VM?s sensitivity with re- spect to different probabilities of the concept drifting, we collect a set of results from 100 data chunks with chunk size 500, and the percentage of labeled examples p is set to be 10%. According to our description in Section 2, the sizes of the Types I, II, III, and IV examples are partially determined by the concept drifting probability value c. Al- though we have the power to control the probability value c for synthetic streams, we do not, however, know the proba- bility value c in real-world data streams. To bring the results one step closer to the real-world setting, we pretend that we do not know the probability value c and simply take a small portion (i.e., 10%) of instances at the tail of each training chunk as the Types I and III examples, and the rest of sam- ples are taken as the Types II and IV examples.

In Table 1, we report the algorithm performance with re- spect to different concept drifting probability c values (for synthetic stream). For any specific c value, RK-TS3VM out- performs its other peers and SVM also performs the worst.

On the other hand, when comparing each algorithm with respect to different concept drifting probability values, we can observe that all the four algorithms suffer a loss in ac- curacy when c increases. This asserts that RK-TS3VM is relatively stable in handling data streams with high concept drifting probabilities. We believe that the robustness of the RK-TS3VM may be attributed to the following two facts.

First, due to the difficult of identifying the concept drift- ing points, we cannot determine the proper chunk size to ensure that the concepts within a data chunk remain sta-  Table 1. Synthetic stream: different concept drifting rates  Learning Concept Drifting Models c=10% c=30% c=60% SVM 0.8792?0.07 0.8644?0.07 0.8348?0.08  TrSVM 0.9215?0.04 0.9047?0.04 0.8912?0.04 S3VM 0.9573?0.04 0.9427?0.05 0.9277?0.05  RK-TS3VM 0.9610?0.01 0.9548?0.02 0.9473?0.02  ble. So the concept drifting may actually happen within a data chunk. RK-TS3VM considers that each data chunk is subject to the concept drifting and only a small portion of instances at the tail of each chunk have the same dis- tribution as the target domain. This categorization closely simulates the real-world data stream, especially when the concept drifting probability value c is large. Second, the TS3VM and RK learning models can properly utilize the four types of examples by learning from them separately.

Consequently, the RK-TS3VM is able to receive good per- formance even if it might not be able to accurately estimate the size of the Types I, III and Types II, IV examples.

5.4 Sensitivity to Labeled Examples  In Table 2 we report the algorithm performance with re- spect to different percentages of labeled examples. In the experiment, we use 100 data chunks each containing 500 examples. A fixed portion of 10% examples at the tail of the training chunk are selected as the same distribution ex- amples (Types I & III). The results in Table 2 indicate that for a specific p value, S3VM and RK-TS3VM consistently outperforms other two methods which discard the unlabeled for learning. This is consistent with the common observa- tions made from the semi-supervised learning, and further concludes that utilizing unlabeled samples is also an effec- tive way for learning from data streams. When comparing four methods across different percentages of labeled exam- ples, we can observe that all four methods receive signifi- cant improvements, especially for SVM and TrSVM, when the value p increases. This observation indicates that pro- viding a sufficient number of labeled samples is crucial to     Table 2. Synthetic stream: different % of labeled exps.

Learning Labeled example percentages Models p=1% p=5% p=10% SVM 0.5818?0.11 0.7600?0.10 0.8605?0.07  TrSVM 0.5896?0.14 0.8387?0.07 0.9033?0.05 S3VM 0.8917?0.05 0.9229?0.04 0.9416?0.02  RK-TS3VM 0.9190?0.04 0.9415?0.03 0.9517?0.02  Table 3. Sensor stream: different chunk sizes Learning Chunk Size Models n=100 n=500 n=1000 SVM 0.6262?0.11 0.7655?0.07 0.7750?0.07  TrSVM 0.6985?0.11 0.7774?0.06 0.7860?0.05 S3VM 0.7511?0.08 0.7994?0.07 0.8083?0.06  RK-TS3VM 0.7729?0.07 0.8050?0.06 0.8094?0.06  ensure the accuracy of the prediction models, if learning has no mechanism of utilizing unlabeled samples or no un- labeled samples are available to boost the learning.

5.5 Results on Real-World Data Streams  In Tables 3 and 4, we report the algorithm performance on two real-world data streams with different chunk sizes (with p=10%). The results assert that comparing to its other peers, RK-TS3VM can help build the most accurate predic- tion model. When comparing each method across different chunk sizes, we can see that the prediction models trained from RK-TS3VM are the most robust ones with respect to different chunk sizes. Take the Sensor stream in Table 3 as an example, when the chunk size increases from 100 to 1000, RK-TS3VM has the lowest change (only 0.0365) compared to SVM (0.1488), TrSVM (0.0875) and S3VM (0.0472) methods. The above results assert that RK-TS3VM not only helps build accurate prediction models from data streams, but also relatively less sensitive to different chunk sizes. In Tables 5 and 6, the four methods are compared with respect to different percentages of labeled instances (with n=500). For comparisons purposes, we also list the detailed chunk by chunk results of all four methods in Figs.

5 and 6. The results also validate our conclusion that RK- TS3VM is the most robust model with respect to different chunk sizes, percentages of labeled instances, and concept drifting probabilities.

The above advantages render RK-TS3VM a useful tool for practical usages, where real-world users may not have any priori knowledge on the proper chunk sizes, labeling percentages, and concept drifting rates in the data streams.

So a method insensitive to these parameters is able to deliver stable and consistent mining results.

Table 4. PowerSup. stream: different chunk sizes Learning Chunk Size Models n=100 n=500 n=1000 SVM 0.6032?0.11 0.6919?0.07 0.6923?0.07  TrSVM 0.6076?0.12 0.6957?0.05 0.7105?0.06 S3VM 0.6148?0.11 0.7002?0.05 0.7195?0.05  RK-TS3VM 0.6700?0.09 0.7124?0.04 0.7226?0.05  Table 5. Sensor stream: different % of labeled examples Learning Percentage of Labeled Examples Models p=1% p=5% p=10% SVM 0.5406?0.10 0.7063?0.09 0.7655?0.07  TrSVM 0.6175?0.11 0.7475?0.10 0.7774?0.06 S3VM 0.7826?0.08 0.7913?0.07 0.7994?0.07  RK-TS3VM 0.7967?0.08 0.7980?0.07 0.8050?0.06  6 Conclusions  For years, stream data mining research has been primar- ily focused on the data volumes and the concept drifting challenges, under assumption that the stream data are fully labeled. Although the advancement in the hardware and networking technologies has made the data collection eas- ier than ever before, labeling is still a rather expensive pro- cess and instance labels are hardly immediately available for stream data which constantly flow with large volumes.

The mining algorithms should therefore consider a three- fold change, labeled/unlabled samples, data volumes, and concept drifting, to build accurate prediction models. In this paper, we proposed a relational k-means based transfer semi-supervised SVM learning framework (RK-TS3VM) for data streams containing both labeled and unlabeled sam- ples. Our essential goal is to leverage labeled and unla- beled examples to boost the learning. This goal is achieved through the combination of a transfer semi-supervised SVM learning paradigm and a relational k-means based learning model. Empirical studies on both synthetic and real-world data streams demonstrated that RK-TS3VM is superior to other simple approaches such as the classical supervised SVM, Transfer SVM, and Semi-Supervised SVM models.

The contribution of the work reported in the paper is fourfold: (1) we characterize instances in data streams con-  Table 6. PowerSup. stream: different % of labeled exps.

Learning Percentage of Labeled Examples Models p=1% p=5% p=10% SVM 0.5408?0.13 0.6026?0.12 0.6919?0.07  TrSVM 0.5792?0.10 0.6529?0.10 0.6957?0.05 S3VM 0.6785?0.06 0.6991?0.06 0.7002?0.05  RK-TS3VM 0.7002?0.05 0.7011?0.05 0.7124?0.04     5 10 15 20 25 30 35 40 45 50  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Chunk ID  Ac cu  ra cy  SVM TrSVM  S3VM  RK?TS3VM  (a) p=1%  5 10 15 20 25 30 35 40 45 50  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Chunk ID  Ac cu  ra cy  SVM TrSVM  S3VM  RK?TS3VM  (b) p=5%  5 10 15 20 25 30 35 40 45 50  0.3  0.4  0.5  0.6  0.7  0.8  0.9   Chunk ID  Ac cu  ra cy  SVM TrSVM  S3VM  RK?TS3VM  (c) p=10%  Figure 5. Chunk by chunk comparison of the first 50 data chunks (Sensor stream, n=500)  5 10 15 20 25 30 35 40 45 50 0.2  0.3  0.4  0.5  0.6  0.7  0.8  Chunk ID  Ac cu  ra cy  SVM TrSVM  S3VM  RK?TS3VM  (a) p=1%  5 10 15 20 25 30 35 40 45 50 0.2  0.3  0.4  0.5  0.6  0.7  0.8  Chunk ID  Ac cu  ra cy  SVM TrSVM  S3VM  RK?TS3VM  (b) p=5%  5 10 15 20 25 30 35 40 45 50 0.2  0.3  0.4  0.5  0.6  0.7  0.8  Chunk ID  Ac cu  ra cy  SVM TrSVM  S3VM  RK?TS3VM  (c) p=10%  Figure 6. Chunk by chunk comparison of the first 50 data chunks (Power supply stream, n=500)  taining labeled and unlabeled samples into four categories.

Such a categorization not only provides a clear concept drifting definition, but also may motivate interested read- ers to devise efficient and effective solutions for data stream with labeled and unlabeled samples; (2) we proposed a re- lational k-means based learning model, which is useful for semi-supervised learning when training and test data have different distributions; (3) we proposed a transfer semi- supervised model to leverage labeled and unlabeled samples for learning. This model is generally useful when train- ing examples share similar distributions to the test data; and (4) although we used SVM-like model as the learning algorithm, our principle of combining transfer and semi- supervised learning and relational clustering can be fur- ther extended to other learning algorithms for mining data streams contained labeled and unlabeled samples.

