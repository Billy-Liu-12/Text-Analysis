Automatic Objects Removal for Scene Completion Jianjun Yang

Abstract?With the explosive growth of web-based cameras and mobile devices, billions of photographs are uploaded to the internet. We can trivially collect a huge number of photo streams for various goals, such as 3D scene reconstruction and other big data applications. However, this is not an easy task due to the fact the retrieved photos are neither aligned nor calibrated. Furthermore, with the occlusion of unexpected foreground objects like people, vehicles, it is even more challenging to find feature correspondences and recon- struct realistic scenes. In this paper, we propose a structure- based image completion algorithm for object removal that produces visually plausible content with consistent structure and scene texture. We use an edge matching technique to infer the potential structure of the unknown region. Driven by the estimated structure, texture synthesis is performed automatically along the estimated curves. We evaluate the proposed method on different types of images: from highly structured indoor environment to the natural scenes. Our experimental results demonstrate satisfactory performance that can be potentially used for subsequent big data processing: 3D scene reconstruction and location recognition.

Keywords: Image Completion, Texture Synthesis, On- line Photos, Scene Reconstruction, Object Removal

I. INTRODUCTION  In the past few years, the massive collections of imagery on the Internet have inspired a wave of work on many interesting big data topics: scene reconstruction, location recognition, and online sharing of personal photo streams [2] [3] [4]. For example, one can easily download a huge number of photo streams associated with a particular place.

By using features (e.g. SIFT), it is possible to automatically estimate correspondence information and reconstruct 3D geometry for the scene [5] [6]. Imagine building a world- scale location recognition engine from all of the geotagged  images from online photo collections, such as Flickr and street view databases from Google and Microsoft. However, it is a challenging task as the photo streams are neither aligned nor calibrated since they are taken in different temporal, spatial, and personal perspectives. Furthermore, with the occlusion of unexpected foreground objects, it is even more difficult to recover the whole scene or accurately identify overlapping regions between different photos.

To resolve the above issue, image in-painting is an effective solution. In this paper, we propose an automatic object removal algorithm for scene completion, which ben- efits subsequent large imagery processing. The core of our method is based on the structure and texture consistency.

Our proposed approach has two major contributions. First, we develop a curve estimation approach to infer the potential structure of the occluded region on the image. Second, an orientated patch matching algorithm is designed for texture propagation. Our work has a broad range of applications including image localization [7] [8], privacy protection [9] [10] [11], and other network based applications [12] [13] [14] [15] [16].



II. RELATED WORKS  In the literature, image completion or in-painting has been intensively studied: in [17], Efros and Leung used a one- pass greedy algorithm to render unknown pixels based on the assumption that the probability distribution of the pixel?s brightness is independent to the rest of the image when the spatial neighborhood is given. In [18], the authors proposed an example-based approach to fill in the missing regions.

It worked well in filling in small gaps but not in large ones. The weakness of such approach is that it fails to preserve the potential structures. Jia et al. [19] designed  2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data  U.S. Government work not protected by U.S. copyright 553     (a) (b) (c)  (d) (e) (f)  Fig. 1. Scene recovery by removing specified foreground object (a) Original Image (b) Our result (c) Contour detection by using OWT-UCM method [1] (d) Edge extraction (e) Structure generation in the occlusion region by identifying corresponding edge pairs (f) Some denotations in our algorithm.

an image in-painting method based on texture-segmentation and tensor-voting that created smooth linking structures in the occluded regions. This method sometimes introduces noticeable artifact due to the texture inconsistency. Criminisi et al. [20] made an improvement by assigning in-painting orders based on the edge strength levels. Their algorithm used a confidence map and the image edges to determine the patch completion priority. However, the structures in the resulting images are not well preserved. The method in [21] produced a better result via structure propagation, while this approach requires more interaction. The completion results largely depend on the animator?s individual technique. Some other existing work also explored in [22] [23] [24].



III. OUR APPROACH  The process of our framework is: for a given image, users specify the object for removal by drawing a closed contour around it. The enclosure is considered an unknown region that is inferred and replaced by the remaining region of the image. Figure 1(a) shows an example: the red car is selected as the removing object. In the resulting image Figure 1(b), the occluded region is automatically recovered based on the surrounding environment.

First let us define a set of notations for the rest of our paper. For an image I, the target region for in-painting is denoted as ?; the remaining part of the image is denoted as ?(= I ??), which is also known as source region. The boundary contour along ? is denoted as ??. A pixel?s value is represented by p = I(x, y), where x and y are the 2D  coordinates on the image. The surrounding neighborhood centered at (x, y) is often called as a patch, denoted as ?p.

The coordinates of pixels inside the patch ?p should be in the range: [x? ?x, y? ?y]. These concepts are illustrated in Figure 1(f). In our framework, there are three phases involved to achieve the scene recovery:structure estimation, structure propagation, and remaining part filling.

A. Structure Estimation  In this phase, we estimate the potential structure in ? by finding all the possible edges. This procedure can be further decomposed into two steps: Contour Detection in ? and Curve Generation in ?.

1) Contour Detection in ?: We first segment the region ? by using gPb Contour Detector [25]. It is based on the idea of computing the oriented gradient signal G(x, y, ?) on the four channels of its transformed image: brightness, color a, color b and texture channel. G(x, y, ?) is the gradient signal, where (x, y) indicates the center location of the circle mask that is drawn on the image and ? indicates the orientation. The gPb Detector is composed of two important components: mPb Edge Detector and sPb Spectral Detector [25]. We apply linear combination on mPb and sPb (factored by ? and ?) according to the gradient ascent on F-measure:  gPb(x, y, ?) = ? ?mPb(x, y, ?) + ? ? sPb(x, y, ?) (1) Thus a set of edges in ? can be retrieved via gPb. Howev-  er, these edges are not in close form and have classification  2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data      ambiguities. To solve this problem, we use the Oriented Watershed Transform [25] and Ultrametric Contour Map [1] (OWT-UCM) algorithm to find the potential contours by segmenting the image into different regions. The output of OWT-UCM is a set of different contours {Ci} and their corresponding boundary strength levels {Li} as Figure 1(c) shows.

2) Curve Generation in ?: After obtaining the contours {Ci} from the above procedure, salient boundaries in ? can be found by traversing {Ci}. Our method for generating the curves in ? is based on the assumption: for the edges on the boundary in ? that intersects with the ??, it either ends inside ? or passes through the missing region ? and exits at another point of ??. Below is our algorithm for identifying the curve segments in ?:  Algorithm III.1 Identifying curve segments in ? Require: Construct curve segments in ?.

Ensure: The generated curves have smooth transition between  known edges.

1: Initial t = 1.0 2: For t = t ? ?t 3: if ?e ? {C} : E ? ?? ?= ? 4: Insert e into {E} 5: End if t < ?T 6: Set t = t0, retrieve all the contours in {Ci} with Li > t 7: Obtain < ?x1, ?x2 > for each Ex 8: DP on {< ?01, ?02 >,< ?11, ?12 >, ...} to find optimal pairs  from the list.

9: According to the optimal pairs, retrieve all the corresponding  edge-pairs: {(Ex1, Ex2), (Ex3 , Ex4), ...)}.

10: Compute a transition curve Cst for each (Es, Et).

In algorithm III.1, it has three main parts: (a) collect all potential edges {Ex} in ? that hits ??; (b) identify optimal edge pairs {(Es, Et)} from {Ex}; (c) construct a curve Cst for each edge pair (Es, Et).

Edges Collection: The output of OWT-UCM are contours sets {Ci} and their corresponding boundary strength levels {Li}. Given different thresholds t, one can remove those contours C with weak L. Motivated by this, we use the Region-Split scheme to gradually demerge the whole ? into multiple sub-regions and extract those salient curves.

This process is carried out on lines 1-9: at the beginning the whole region ? is considered as one contour; then iteratively decrease t to let potential sub-contours {Ci} faint out according the boundary strength; Every time when any edges e from the newly emerged contours {C} were detected of intersecting with ??, they are put into the set {E}.

Optimal Edge Pairs: the reason of identifying edge pairs is based on the assumption if an edge is broken up by ?, there must exist a pair of corresponding contour edges in ? that intersect with ??. To find the potential pairs {(Es, Et)} from the edge list {Ex}, we measure the cor- responding enclosed regions similarities. The neighboring  regions < ?x1, ?x2 > which is partitioned by the edge Es are used to compare with the corresponding regions of another edge Et. This procedure is described on lines 7? 9 of the algorithm III.1. Each neighboring region is obtained by lowing down the threshold value t to faint out more detailed contours as Figure 1(d) shows.

To compute the similarity between regions, we use the Jensen-Shannon divergence [26] method that works on the color histograms:  d(H1, H2) =  n?  i=1  {Hi1 ? log 2 ?Hi1  Hi1 +H i  +Hi2 ? log 2 ?Hi2  Hi2 +H i  }  (2) where H1 and H2 are the histograms of the two regions  ?1, ?2; i indicates the index of histogram bin. For any two edge (Es, Et), the similarity between them can be expressed as:  M(Es, Et) = ||Ls ? Lt||  Lmax ? min{d(Hsi, Hti) + d(Hsj, Htj)}  (3) i and j are the exclusive numbers in {1, 2}, where 1 and  2 represent the indices of the two neighboring regions in ? around a particular edge. The Lmax is the max value of the two comparing edges? strength levels. The first multiplier is a penalty term for big difference between the strength levels of the two edges. To find the optimal pairs among the edge list, dynamic programming is used to minimize the global distance:  ? s,t M(Es, Et), where s ?= t and  s, t ? {0, 1, ..., size({Ei})}. To enhance the accuracy, a maximum constraint is used to limit the regions? difference: d(H1, H2) < ?H. If the individual distance is bigger than the pre-specified threshold ?H, the corresponding region matching is not considered. In this way, it ensures if there are no similar edges existed, no matching pairs would be identified.

Generate Curves for each (Es, Et) : we adopt the idea of fitting the clothoid segments with polyline stoke data first before generating a curve [27]. Initially, a series of discrete points along the two edges Es and Et are selected, denoted as {ps0, ps1, ..., psn, pt0, pt1, ..., ptm}. These points have a distance with each other by a pre-specified value ?d. For any three adjacent points {pi?1, pi, pi+1}, the correspond- ing curvature ki could be computed according to [28]:  ki = 2 ? det(pi ? pi?1, pi+1 ? pi)  ||pi ? pi?1|| ? ||pi+1 ? pi|| ? ||pi+1 ? pi?1|| (4)  Combining the above curvature factors, a sequence of polyline are used to fit these points. The polylines are expected to have a possibly small number of line seg- ments while preserving the minimal distance against the original data. Dynamic programming is used to find the  2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data      most satisfied polyline sequence by giving a penalty for each additional line segment. A set of clothoid segments can be derived corresponding to each line segment. After a series rotations and translations over the clothoid, a final curve C is obtained by connecting each adjacent pair with G2 continuity [27]. Figure 1(e) demonstrates the curve generation result.

B. Structure Propagation:  After the potential curves are generated in ?, a set of texture patches, denoted as {?0, ?1, ...}, need to be found from the remaining region ? and placed along the estimated curves by overlapping with each other with a certain proportion. Similar to [21], an energy minimization based method is proposed in a Belief Propagation (BP) framework. However, we have different definitions for the energy and message passing functions. The details are in the algorithm III.2.

Algorithm III.2 BP Propagation Algorithm Require: Render the texture for each patch ?i in ? along the  estimated structures.

Ensure: Find the best matching patches while ensuring the global  coherence and consistency.

1: For each curve C in ?, define a series of anchor points on it,  {ai, |i = 1? n}.

2: Collect exemplar-texture patches {??ti } in ?, where ti ? [1,m] 3: Setup a factor graph G = {V, E} based on {C} and {ai} 4: Defining the energy function E for each ai: Ei(ti), where ti  is the index in [1,M].

5: Defining the message function Mij for each edge E in G, with  initial value Mij ? 0 6: Iteratively update all the messages Mij passed between {ai} 7: Mij ? minai {Ei(ti) + Eij(ti, tj) +  ?  k?N (i),k ?=j Mki} 8: end until ?Mij < ?, ?i, j (by Convergence) 9: Assign the best matching texture patch from {??t} for each ai  that arg min[T,R]{ ?  i?V Ei(ti) + ?  (i,j)?E Eij(ti, tj)}. Here T is an n dimensional vector [t1, t2, ..., tn], where i ? [1, n]; R is also an n dimensional vector [r1, r2, ..., rn] with each element representing the orientation of source patch ??ti .

In the algorithm, the anchor points are evenly distributed along the curves with an equal distance from each other ?d.

These points represent the center where the patches {?i} (l? l) are synthesized, as shown in Figure 1(f). In practice, we define ?d = 1  ? l. The {??t} is the source texture patches  in ?. They are chosen on from the neighborhood around ??. For the factor graph building, we consider each ai as a vertex Vi and Eij = aiaj, where i, j are the two adjacent points.

In previous works [21] [20], each ?i have the same orientation as ??ti , which limits the varieties in the source texture. Noticing that different patch orientations could produce different results, we introduce a scheme called Adaptive Patch by defining a new formulas for E and M in the structure propagation.

Traditionally, the node energy Ei(ti) is defined as the Sum of Square Difference(SSD) by comparing the known pixels in each patch ?i with the candidate corresponding portion in ??ti . But this method limits the salient structure directions. Instead of using SSD on the two patches, a series of rotations are performed on the candidate patch before computing the similarity. Mathematically, Ei(ti) can be formulated as:  Ei(ti) = ?? ? P ? ?  ||?i ? R?(?) ? ??ti ||2? (5)  Where R? represents different rotations on the patch ??ti .

Since the size of a patch is usually small, the rotation can be specified with an arbitrary number of angles. In our experiment, it is specified as ? ? {0,??  ,??  , ?}. The  parameter ? represents the number of known pixels in ?i that overlap with the rotated patch ??ti . P is a penalty term, the more number of overlapping pixels, the higher of similarity is assigned. So we use P to discourage the patches with smaller number of sharing pixels. Here, the percentage is expressed as P = ?  l2 (l is the length of ?).

?? is the corresponding normalized scalar. Thus the best matching patch ?? is represented by two factors: index ti and rotation Ri.

In a similar way, the energy Eij(ti, tj) on each edge Eij can be expressed as:  Eij(ti, tj) = ?? ? P ? ?  ||?i(ti, ?ti) ? ?j(tj, ?tj)|| ? (6)  Here i and j are the indices of the two adjacent patches in ?. A penalty scheme is applied to the similarity comparison.

The two parameters for ?i indicate the index and rotation for the source patches in {??ti }. The messages propagation is derived from the results of the above energy functions.

We adopt a similar method as [21], where the message Mij passes by patches ?i is defined as:  Mij = Ei(ti) + Eij(ti, tj) (7)  Through iterative updating on the BP graph, an optimal decision of {ti} for the patches in {?i} is made by minimiz- ing the nodes? energy. This principle can be formulated in the definition below:  t?i = arg min ti  {Ei(ti) + ?  k  Mki} (8)  Where k is one of the neighbors of the patch ?i: k ? N (i). t?i is the optimal index for the matching patch. To achieve minimum global energy cost, dynamic programming is used. Each assignment for ?i or ai is considered as a stage. In each stage, the choices of ??ti represent different states. The edge Eij represents the transit cost from state ??ti at stage i to state ??tj at stage j. Starting from i = 0, an  2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data      optimal solution is achieved by minimizing the total energy ?i(ti) from last step:  ?i(ti) = Ei(ti) +min{Eij(ti, tj) + ?i?1(ti?1)} (9)  where ?i(ti) represents a set of different total energy values at current stage i. In the situation of multiple inter- sections among curves C, we adopted the idea in [21], where readers can refer for further details.

C. Remaining Part Filling:  After the curves are generated in ?, we fill the remaining regions by using the exemplar-based approach in [20].

The ?? is getting smaller and smaller by spreading out the known pixels ? in a certain order. To enhance the accuracy, all the pixels in the above generate patches along the estimated curves are assigned with a pre-computed confidence value based on the confidence updating rule in [20].



IV. EXPERIMENTS  (a) (b)  (c) (d)  Fig. 2. Kanizsa Triangle Experiment (a) The original Image (b)Curve reconstruction for the missing region ? (c) Result by Criminisi?s method (d) Our result.

In our experiments, we first evaluate our proposed ap- proach in terms of structure coherence by comparing our result with the one in [20] that works on the well-known Kanizsa triangle. As shown in Figure 2(a), the white triangle in the front is considered as the occluded region ? that needs to be removed. First, a structure propagation is carried out based on the detected edges along ??. The dash lines in Figure 2(b) indicate the estimated potential structures in ?.

Texture propagation is applied to the rest of the image based on the confidence and isophote terms. One can notice both  the triangle and the circles are well completed in our result Figure 2(d) comparing with Criminisi?s method in Figure 2(c).

To further demonstrate the performance, a set of images are used for scene recovery: ranging from indoor envi- ronment to natural scenes. Figure 3(e) shows an indoor case where highly structured patterns often present, such as the furniture, windows, walls. The green bottle on the office partition is successfully removed while preserving the remaining structure. In this example, three pairs of edges are identified and connected by the corresponding curves that are generated in the occluded region ?. Figure 3(g) and 3(f) show the results of removing trees in the nature scenes.

Several curves are inferred by matching the broken edges along ?? and maximizing the continuity. We can notice the three layers of the scene (sky, background trees, and grass land) are well completed. In Figure 3(h), it shows a case that a perching bird is removed from the tree. Our structure estimation successfully completes the tree branch with smooth geometric and texture transitions.



V. CONCLUSION  In this paper, we present a novel approach for foreground objects removal while ensuring structure coherence and tex- ture consistency. The core of our approach is using structure as a guidance to complete the remaining scene. This work would benefit a wide range of applications especially for the online massive collections of imagery, such as photo localization and scene reconstructions. Moreover, this work is applied to privacy protection by removing people from the scene.

