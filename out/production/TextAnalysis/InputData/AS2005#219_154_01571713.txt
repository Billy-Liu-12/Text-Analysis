A New Technique for Fast Frequent Closed Itemsets  Mining

Abstract - This paper proposes a new technique for fast frequent closed itemsets mining. The method employs the concept of prefix-based equivalence class to partition the database in such a way that the possible frequent itemsets will be uniformly distributed in the partitions. One unique property of this technique is that it guarantees only frequent closed itemsets are generated and they are generated only once. Thus it avoids the closed-set examination in the entire mining processing. Our technique can be used in the existing frequent closed itemsets mining algorithms, including both Apriori-based and frequent pattern growth based algorithms, to improve their performance.  Moreover, the technique is well suited for parallel mining of frequent closed itemsets.

Keywords: frequent itemset mining, data mining, association rule mining.

1. Introduction As one of key data mining techniques, the association rule mining searches for the statistically meaningful associations among the items of a transaction database. Let I = { i1, i2, ?, im} be a set of items and D = { t1, t2, ?, tn} be a database of transactions, where each transaction t has a unique identifier tid and t ? I. An association rule is defined as X Y where Y ? I, X ? I, 1|||| =Y , and  ?=?YX . The support of an association rule X Y is defined as the number of transactions in D that contain the rule, and the confidence is defined as the ratio of the number of transactions containing the rule YX ?  to the number of transactions containing X. The major task of association rule mining is to find frequent itemsets, because once the frequent itemsets have been found, finding strong association rules will be easy.

Frequent itemsets mining finds all itemsets with supports no less than a user-specified minimum support threshold min_sup. Furthermore, based on the concepts of closed set, the problem of mining frequent itemsets in a database is evolved to mining frequent closed itemsets.  An itemset X is closed if it has no proper superset XX ??  in D such that )(sup)(sup XX ?= .  Given a set of itemsets, there exists a unique smallest closed set that contains the set.

Any set of itemsets can be represented by its closed set.

Compared with the frequent-itemset mining, the frequent- closed-itemset mining produces a compact and information rich output. [1].

Since the seminal work of R. Agrawal on association rule mining [2], many researches have been done to make mining frequent closed itemsets efficient and scalable. The existing approaches to frequent closed itemsets mining are either Apriori-based or frequent-pattern-growth(FP) based[3]. The Apriori-based algorithms find frequent itemsets based upon an anti-monotone property that employs an iterative approach to generate candidate itemsets. Various techniques, such as hash-based techniques, partitioning, transaction reduction, sampling, and dynamic itemset counting have been applied to improve their efficiency [4-11]; however, Apriori-based algorithms suffer from two nontrivial costs: generating a huge number of candiate itemsets and scanning the database repeatedly for the frequency counting of candidates set. The FP-growth based algorithms avoid candidate itemsets generation. Instead of generating candidate sets, they recursively partitions the database into conditional databases according to the frequent patterns found and searches for local frequent patterns to assemble longer global patterns. Each conditional database is associated with a frequent pattern, which is shared as a prefix by all the frequent itemsets of the conditional database. To obtain frequent closed itemsets, a closure- checking procedure is used to examine whether a newly found frequent closed candidate is a subset of an already found closed itemset.  Such closure-checking procedure is computationally expensive when mining a large database because the potential frequent closed itemsets are likely very large. Improvements have been proposed to reduce any unnecessary closure-checking [12] and making the closure-checking more efficient [13], but none of them can completely eliminate it from the mining process. In addition, the closure-checking procedure makes it difficult to parallelize the existing efficient frequent closed itemset algorithms among a group of processors due to the overhead of communication cost incurred by closure checking.

In this paper, we propose a new method for frequent- closed-itemset mining that eliminates the closed-set- checking procedure. Our method uses the prefix-based equivalence class concept to partition the search space of a    transaction database into a set of subspaces called classes.

Then by exploiting the relationships of frequent itemsets among different classes it is able to identify the redundant itemsets before generating them and thus prevents the generation of any non-closed itemsets.

Our method is especially suitable for mining very large datasets for two reasons. First, it is stateless, that is no memory is needed for keeping the frequent closed itemsets obtained by the previous iterations of the mining. Second, because of the statelessness the entire mining process can be divided into a set of independent subtasks so that each subtask can be accommodated into the main memory.  The method is also suitable for parallel mining frequent closed itemsets among a group of processors such as a cluster, from a horizontal partitioned database. Each processor will work independently without any communications with other processors when loaded with a portion of the database, and the final mining result is simply an aggregation of the outputs from all processors. It is worth of pointing out that the method can be easily adopted by existing algorithms to improve their efficiency. To demonstrate the effectiveness of our method, we have implemented the proposed method in a sequential algorithm and conducted the experiments using different datasets.

The remainder of this paper is organized as follows.

Section 2 presents the related work. Section 3 gives a brief overview of the prefixed-based equivalence class and split algorithm on which our work is based on. Section 4 introduces our method. Section 5 presents the experimental results and section 6 offers conclusion of this work.

2. Related work Efficient algorithms are proposed for mining frequent closed itemsets including CHARM [14], LCM [15], CLOSET+ [12] and AFOPT[13]. Both CHARM and LCM uses a vertical representation of the database and enumerates frequent closed itemsets. CHARM enumerates closed sets using a dual itemset-tidset search tree, while LCM defines a child-parent relationship between frequent closed itemsets which induces a tree-shaped transversal routes composed only of all the frequent closed itemsets.

Both CLOSET+ and AFOPT algorithms take FP-growth approach that uses the divide-and-conquer method.

CLOSET+ improves CLOSET algorithm by (1) a hybrid tree-projection method to improve the space efficiency for tree construction of databases, (2) item skipping for further pruning search space and speeding up mining, and (3) efficient subset checking for saving memory and accelerating the closure checking. AFOPT uses an adaptive approach to dynamically adjusts strategy for item search order, conditional tree database representation, conditional database construction, and tree traverse.

Our proposed method assumes a horizontal representation of the database. Similar to CLOSET+ and AFOPT, it uses the divide-and-conquer methodology to partition the search space of a database and mine each partition recursively. Different from frequent-patter growth based algorithms, our method uses the prefix-based equivalence class concept to partition the search space of a database. By dividing a conditional database into class and non-class segments, our method is able to identify redundant itemsets before generating them and thus ensures that only frequent closed itemsets are generated and they are generated only once.

3. Equivalence class and the split algorithm  Let I be a set of m items and D be a database of transactions. Denote 2I- as the power set of I, and  ??=? II 22 . ?I2  consists of all possible frequent itemsets defined on I. An itemset s ? I can be represented as a sequence that is sorted in support ascending order. Such a sequence is referred to as a canonical attribute sequence (cas). For instance, given an itemset s= {a, c, e, d, f} with the individual item support as 3, 4, 4, 2, and 4 respectively, s can be represented by the cas dafec.  The cardinal of a cas s is denoted as |s|. In the reminder of this paper, an itemset s is represented by a cas, to which all the set operators are applicable. Without causing confusion, we also use s to represent its corresponding cas and s[i] to denote its ith )1( ?i item.

Definition 1 Let s be a cas, and k be an integer such that sk ??0 . The k-length prefix of s is denoted pre(s,k).

Definition 2 Let } ||  |  2{)(2 kssk II ??= ??  represent the subset of cass whose sizes are greater than or equal to some fixed threshold k. For any )(2 ks I ??  and )(2 kr I ?? , ?(k) defines a prefix-based equivalence relation as follows:  ),(),()( krpreksprers k =??? .

Definition 3 A prefix-based equivalence class, denoted as [C] where IC ? , is a set of all cass that share the common prefix C [14][16].

Let )(k? be the set of prefix-based equivalence classes induced by ?(i), ki ??1 . Based on the concept of equivalence class, Algorithm 1 provides a way of partitioning ?I2  of a given transaction database D into a set of equal-sized disjoint equivalence classes [16].

In the Algorithm 1, I is a cas representing a set of m items on which a transaction database D is defined. ?.? is the catenation operator. In this paper we use the notations  }1|][{)( kjjIkI p ??=  and }1|][{)( mjkjIkIs ??+=    for the first k items and the last m?k items of I, respectively.

Given an integer k, 10 ??? mk , the split algorithm partitions ?I2 into k2 disjoint prefix-based equivalence classes [Xi], where )(2 kIi pX ? . In other words, )(][ kX ?? if )(][ kX ?? . Each member in a class [Xi] shares the same prefix Xi. Each class is of the same size 12 ??km .

The proof of the split algorithm can be referred to [17].  Figure 1 shows an example of partitioning the search space of a database into the classes by the split algorithm.

In the example, I=abcde, k=2, ))2(,,2( ?Isplit generates ?(2)={[ab],[a],[b],[?]} where each class has seven members.

? ][?  Figure 1 Equivalent classes )2(?  4. Proposed method 4.1 Motivation The closure-checking procedure of the existing frequent-closed-itemset mining algorithms not only is computational expensive but also wastes processor time and memory space for producing and keeping redundant itemsets. Could it be possible to completely eliminate the closure-checking? This question motivates our work.

To answer this question, we need to understand why the closure-checking is needed by the current algorithms.

As we know, all FP-growth based approaches employ the divide-and-conquer methodology. The search space of frequent itemsets of a database D is partitioned into disjoint sub-spaces, and mining frequent itemsets in D is transferred to mining frequent itemsets from a set of conditional databases, each is associated with a search subspace.  As itemsets of one conditional database are potentially the subsets or supersets of the itemsets of other conditional  databases, the closure-checking is necessary for removing the redundant itemsets.

Thus, is there any way to predict which itemsets are redundant before generating them?  The reminder of this paper discusses a method of partitioning the search space of a databases based on the concept of the prefix-based equivalence class so as to avoid the generation of redundant itemsets in the mining process.

4.2 Class segment and non-class segment In the following discussion, we assume that (1) given a database D, a predefined integer k, and I represented as a cas, the split algorithm partitions the search space of frequent itemsets, ?I2 , into k2  classes denoted as )(k? ;  (2) [Xi], ki 21 ?? , denotes a prefix-based equivalence class with the prefix Xi; (3) }1|][{)( kjjIkI p ??=  denotes the k-prefix-set and }1|][{)( mjkjIkI s ??+= the k-suffix-set of I, respectively; (4) For an itemset X ? I , X?s conditional database, denoted as cond(X), is defined as  },|{)( ItXDttXcond iii ???= .

Lemma 1 Let [X] be a prefix-based equivalence class and Y be any frequent itemset from D. If ][XY ? , then cond(Y) ? cond(X).

Proof XYXY ??? ][ , so YtDt ii ???? , Xti ? .  In other words, )(Ycondti ?? ,  we have )(Xcondti ? . Thus,  cond(Y)? cond(X).

Lemma 1 states that Y can be mined directly from cond(X) if Y is a member of [X]. When extending Lemma 1 to all the itemsets of the class [X], we have that these itemsets can all be mined directly form cond(X).

For any two classes [X1] and [X2] of )(k? , their relationships can be summarized as follows.

1) Lemma  2.1 ][ 21 XX ?  belongs to )(k? .

Proof From )(][],[ 21 kXX ?? , we have )(1 kIX p? and )(2 kIX p? . Thus, )()( 21 kIXX p?? , which means  )(][ 21 kXX ??? .

2) Lemma 2.2 If ??21 , XX  and ?=? 21 XX , then ],[ 1Xx ??  no ][ 2Xy ?  exists such that xy ?  or  yx ?  holds.

Proof   Given an itemset ][ 1Xx ? , assume there is an itemset ][ 2Xy ?  such that yx ? . Based on the definition of the prefix-based equivalence class, x and y can be represented as 11 sXx ?=  and 22 sXy ?= , where  )(, 21 kIss s? , ?=? 21 sX , and ?=? 12 sX .  Thus,  Algorithm 1 split( I , k , )(k? ) ?=? )(k ;  for (h = k-1; h ? 0; h--) do )};,1()(|{),,( IkpreShSShkIcasSet ???==  for each ),,( hkIcasSetS ?  do ]]}[[],{[)()( kISSkk ??=? ? ;    .)()()( 21212211 ?=???=??=? sXXXsXXyX It indicates that X1 is not a subset of y, thus 11 sXx ?= cannot be a subset of y either. Similarly we can prove y is not a subset of x either.

3) Lemma 2.3 if 21 XX ? , then ][],[ 21 XyXx ???? such that yx ? .

Proof An itemset ][ 1Xx ?  can be represented as sXx ?= 1 , where )(kIs s? . Based on s, we can  construct an itemset ][ 2Xy ?  such that sXy ?= 2 . Since  21 XX ?  and both x and y share the same suffix s, we have yx ? .

Lemma 2.1 states that union of the prefixes of any two classes of )(k?  still makes a prefix of some class of  )(k? .  Thus, when mining frequent closed itemsets of the class [Xi], it is possible to avoid generating redundant itemsets by examining the [Xi]?s relationship with other classes. For example, if X1 appears in some transactions of cond(X2), it can be removed from these transactions because the itemsets containing both X1 and X2 should be mined from cond( 21 XX ? ). If X1 appears in every transaction of cond(X2), then cond(X2) does not need to be mined since no itemset x?[X2] can be closed because of sup(x?X1) = sup(x). Lemma 2.2 states that the itemsets in [X1] are mutual exclusive to the itemsets in [X2] if  ?=? 21 XX .

To identify which itemsets in a class should be generated and which should not, this paper proposed to partition a conditional database cond(Xi) into a class segment and non-class segment so as to identify any redundant itemsets in [Xi].

Definition 4 (class segment and non-class segment) The conditional database cond(Xi) can be partitioned into two parts: class segment and non-class segment. They are defined as follows:  )}()( ,,|{|)( kIXtItXDttXcond siiclassi ?????=  classiinclassi XcondXcondXcond |)()(|)( ?= where }1|][{)( mjkjIkI s ??+= .

The class segment of cond(Xi)  is made up of the transactions that can be represented as sX i ? , where  )(kIs s? . The non-class segment is made up the transactions that can be represented as szX i ?? , where ))(( ip XkIz ?? . When cond(Xi) is not empty, it can have three structures:  1) ?=??? classinclassi XcondXcond |)(|)( ; 2) ????= classinclassi XcondXcond |)(|)( ;  3) ????? classinclassi XcondXcond |)(|)( .

Let ip XkIG ?= )( . In the following discuss we explain how to ensure only closed itemsets are generated for each of the above cases.

Case-1: In this case, each transaction contains both Xi and some items of Ip(k). If there exists an itemset  Gp ?  appearing in every transaction of cond(Xi), then cond(Xi) will not be mined because ?x?[Xi],         sup(x) = sup( px ? ). Thus no itemset in [Xi] is closed.

Otherwise, for any itemset Gp ?  in nclassiXcond |)( , removes p from nclassiXcond |)(  because  any itemset containing pX i ?  can be mined from )( pXcond i ? .

Case-2: In this case, every frequent closed itemset of cond(Xi) belongs to ][ iX  and is globally closed. To prove it, assume a frequent itemset ][ iXx ?  has a superset   ][ jXy ?  such that yx ?  and sup(x)=sup(y).

Let ji XXz ?= . Then z must appear in cond(Xi). This contradicts the condition ?=nclassiXcond |)( .  Thus, if Case-2 holds, any frequent closed itemsets generated from cond(Xi) are closed.

Case-3:  In this case some transactions contain an itemset Gp ?  and some not; however, no itemset p is included in every transaction since ??classiXcond |)( .

If an itemset spy ?= , with Gp ?  and )(kIs s? , appears in every transaction of nclassiXcond |)( ,  then s is removed from nclassiXcond |)(  due to the fact that no itemset  x=Xi ? s is closed  since sup(x)=sup(x?p).

4.3 Mining frequent closed itemsets without closure checking Based on the above discussion, Algorithm 2 describes a frequent closed itemsets mining algorithm without closure-checking. Given a support threshold min_sup, a prefix Xi, and Is(k),  )),(),(,( iipi ZXcondkIXextract obtains all the frequent closed itemsets in [Xi] and stores them in Zi.

Definition 5  An itemset x is closed iff there exists no itemset y such that y?x and sup(y)=sup(x).

In the Algorithm 2, ? , class? , and nclass?  represent the number of transactions in cond(Xi), classiXcond |)( , and  nclassiXcond |)(  respectively, and nclassclass ?+?=? ; )(s? denotes the number of transactions in )( iXcond containing s, and nclasss |)(?  the number of transactions in  nclassiXcond |)(  containing s.

extract )),(,,( iii ZXcondX ? takes an iterative approach, like FP-based algorithms, to generate frequent closed itemsets of the class [Xi]. Before mining any frequent itemset ][ iXx ?  it examines if x has a superset belonging to a different class that has the same support. If the answer is yes, then x is redundant and will not be generated. This redundancy-evaluating procedure ensures that no subset of a closed frequent itemset is generated, and thus it guarantees that only closed frequent itemsets are generated and they are generated only once.

The algorithm first checks if iX is frequent or not. If ? <min_sup, then it stops and returns. Lines 7-9 evaluate which itemset in [Xi] is redundant for Case 1. Line 10 generates the frequent closed itemset 1YX i ? , if it exists, for Case 2. Lines 11-13 evaluate which itemset in [Xi] is redundant for Case 3. Line 14  removes 1Y and 3Y from ? , if applicable, because 1YX i ?  forms a new common prefix pattern of cond(Xi). Lines16-20 recursively call this algorithm until ?=? .This algorithm has two advantages.

First, it uses equivalence class to quickly filter an itemset that is frequent but not closed, without performing closure- checking operation as FP-based algorithms do. Secondly, it ensures that any frequent closed itemsets from D  is extracted only once.

Algorithm 3 ),,(pmine ?DI,min_sup,k  describes how to mine the complete set Z of frequent closed itemsets of D. The input parameter D of the algorithm is preprocessed and contains only items whose support is no less than min_sup.  Given a predefined k, we assume that the split algorithm ))(,,( kIksplit ?  partitions the itemset space I into disjointed classes, and that the algorithm parallelly constructs k2 conditional databases and extracts all the frequent closed itemsets of each class.

Let?s use an example to illustrate this algorithm.

Table 1 shows a transaction database DB defined on  abcdeI = . Assume min_sup=2 and k=2.  After pre- processing, DB becomes D, as shown in Table 2, bI =]2[ , and  P={c,d,e}.

Tid Items tid Items 1 bcade 1 abcde 2 bfd 2 bd 3 cde 3 cde 4 bcae    4 abce 5 cde  5 cde  Table 1 Original DB                  Table 2 Database D  First, the algorithm ))2(,,2( ?Isplit   generates ]}[],[],[],{[)2( ?=? baab .Then pmine(k, I, min_sup, D,Z)  extracts all the frequent closed itemsets of each class.

Figure 2 illustrates how to parallelly construct and mine the conditional database for each class. The four conditional databases are cond(ab), cond(a), cond(b),  and cond(?).

The notation x: sp represents an itemset x and its support sp.  Initially P={c,d,e}.  The algorithm proceeds as follows.

1) Find all the frequent closed itemsets in [ab]. Because ??classabcond |)(  and ?=nclassabcond |)( , cond(ab) is in  Case-2. Since sup(abce) = sup(ab) = min_sup, 2:abce  is added into ab? . Besides, sup(d) <min_sup leads to ?=? .

Therefore, the mining in ][ab  finishes.

Algorithm 3 pmine( ?D,min_sup,,, Ik ) 1) }1|][{ mjkjI ??+=? ; 2) ))(,,( kIksplit ? ; 3) foreach )(][ kX i ??  do 4)  ?=iZ ;  5)  },|{)( IXDtXtXcond iiii ???= ; 6)  )),(,,( iii ZXcondXextract ? 7) i  i k ?=?  ?? 21 ? ;  Algorithm 2   extract( iipi ZXcondkIX ),(),(, ) Let ip XkIG ?= )( , P= )(kI s 1)  if ? < min_sup,  then return; 2) )})(()(|{1 ?=???= sssY ? ; 3) )}|)()(()(|{11 nclassnclassssssY ?==???= ?? ; 4) )})(()(|{2 ?=??= sGssY ? ; 5) )}|)(()(|{21 nclassnclasssGssY ?=??= ? 6) )}min_sup)(()(|{3 <???= sssY ? ; 7)  if 00 >??=? nclassclass , then 8)   if  ?=2Y   then    1YXX ii ?= ; 9)  else     return; 10)  if 00 =??>? nclassclass   then 1YXX ii ?= ; 11)  if 00 >??>? nclassclass , then 12)   1YXX ii ?= ; 13)  if ??21Y , then 11Y??=? ; 14) 31 YY ???=? ;  15)  if )( ??iX    then }{ iii X??=? ; 16)  if ?=?    then return; 17)  foreach ??s   do 18)      }{s??=? ; 19)      }),(|{)( iiiii tsXcondttsXcond ??=? ; 20)      )),(,,( iii ZsXcondsXextract ??? ;    2) Find all the frequent closed itemsets in [a]. Since ?=classacond |)(  and ??nclassacond |)( , cond(a) is in  Case 1. Because nclassnclassb ?=|)(? ,  itemsets of ][a  are not mined.

3) Find all the frequent closed itemsets in [b]. Since ??purebcond |)( , ??npurebcond |)( , cond(b) is in Case-3.

As no itemset has the same support as b , b:3 is added into b? . Because of nclassnclassace ?=|)(? , c and e are removed  from P. Since sup(d)=min_sup, cond(bd) with P = ? needs to be mined. Clearly cond(bd) is in Case-3 as  ??classbdcond |)(  and ??classbdcond |)( . As no itemset has the same support as bd, bd:2 is added into b? . The mining then finishes.

4) Find all the frequent closed itemsets in [?]. Because of ??? classcond |)(  and ??? nclasscond |)( , cond(?) is in  Case-3. The task of mining cond(?) is further decomposed into mining of cond(c) with P={d,e}, cond(d) with P={e}, and cond(e) with P=?. cond(c) is in Case-3 as  ??classccond |)(  and ??nclassccond |)( . Because e appears in every transaction of cond(c) and sup(ce)=4, ce:4 is added into Z?. d does not appear in every transaction of nclassccond |)(  even though ab does so, hence mining  cond(cde) with P=? is still needed. With sup(cde)=3,  cde:3 is added into ?? . cond(d) is in Case-3 due to ?=classdcond |)(  and ??nclassdcond |)( . Since sup(d)=4, d:4 is added into ?? . cond(de) with ?=?  is in Case-1 as ?=classdecond |)(  and ??nclassdecond |)( . Due to nclassnclassc ?=|)(? , cde:3 is not added to ??  even though sup(cde) > min_sup. cond(e) is in Case-1 as  ?=classdcond |)( and ??nclassdcond |)( .  Because  nclassnclassc ?=|)(? , ce:4 is not added to ?? . The mining of ][?  finishes.

It is worth of pointing out ),,(pmine ?DI,min_sup,k can be directly applied to parallel mining. In this case, k is determined by the number of processors in a parallel computing system. Each processor is loaded a conditional database of a class, and the mining of each class can be done in parallel. When a processor finishes its job much earlier than others, load balancing is required.

5. Experimental Results In this section, we compare the performance of our method PMINE with AFOPT. All experiments are performed on a 500MHz Pentium III with 192MB of memory, running RedHat Linux 6.0. For performance comparison we used the original source for AFOPT obtained from its authors.

We choose benchmark datasets downloaded from FIMI?03 workshop web site. Table 3 shows the datasets characteristics.

Dataset Size #Trans MaxTL AvgTL T10I4D100K 3.93M 100000 30 10.10 T40I10D100K 15.12M 100000 78 39.61 Connect-4 9.11M 67557 43 43.00 Pumsb 16.30M 49046 74 74.00  Table 3 Dataset characteristics  Figures 3-6 show the running time for different datasets with different minimum support threshold. In the experiment, we combine our technique with FP-Tree data structure. Generally, it is faster than AFOPT.  In addition, the new technique can be easily used in the existing frequent closed itemsets mining algorithms to improve their efficiency. The most important is its capability of parallel mining with workload balance.

abcde bd cde abce cde  D  ----------- cde ce  cond(ab) P={c,d,e}  bcde bce -----------  cond(a) P={c,d,e}  acde ace ----------- d  cond(b) P={c,d,e}  abcde bd abce ----------- cde cde  cond(?) P={c,d,e}  Zab={abce:2} P=?  Za=? P=?  Zb={b:3} P={d}  Z?=? P={c,d,e}  abde abe ----------- de de  cond(c) P={d,e}  Z?={ce:4} P={d}  ace ----------- ?  cond(bd) P=?  Zb={b:3, bd:2} P=?  abce b ce ce -----------  cond(d) P={e}  abcd cd abc cd -----------  cond(e) P=?  ab ----------- ? ?  cond(cde) P=?  Z?={ce:4,d:4} P={e}  Z?={ce:4,d:4} P=?  Z?={ce:4,d:4,cde:3} P=?  abc c c -----------  cond(de) P=?  Z?={ce:4,d:4,cde:3} P=?  non-class part ----------- class part  Note: A conditional database is divided into two parts, shown as the right figure. The part above the dashed line is non-class segment. The part under the line is class segment.

conditional database  Z={abce:2, bd:2, b:3,cde:3,ce:4,d:4}  Figure 2  Mining frequent closed itemsets using pmine    6. Conclusions In this paper, we investigate a new frequent-closed- itemset mining method that can greatly enhance the efficiency and scalability of the current association rule algorithms. The main contributions of this work are: 1) the method completely eliminates the computationally expensive closure-checking procedure in the frequent closed itemset mining and thus is particularly useful for mining very large datasets; 2) the method is applicable to not only sequential mining but parallel mining.

Dat aset :  T10I 4D100K      4 3 2 1 Mi ni mum Suppor t ( %)  T i m e ( s e c .

)  PMI NE AFOPT   Figure 2 Running time for dataset T10I4D100K  Dat aset :  T40I 10D100K       2. 5 2 1. 5 1 Mi ni mum Suppor t ( %)  T i m e(  s e c .

)  PMI NE AFOPT   Figure 3 Running time for dataset T40I10D100K  Dat aset :  Connect - 4    95 90 85 80 Mi ni mum Suppor t ( %)  T i m e(  s e c .

)  PMI NE AFOPT   Figure 4 Running time for dataset Connect-4  Dat aset :  Pumsb      95 90 85 80 Mi ni mum Suppor t ( %)  T i m e(  s e c .

)  PMI NE AFOPT   Figure 5 Running time for dataset Pumsb  7. References [1] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal.

Discovering frequent closed itemsets for association rules.

In ICDT?99, Jan. 1999.

[2] R. Agrawal, T. Imielinski, and A. Swami.  Mining association rules between sets of items in large databases.

SIGMOD'93, 207-216, Washington, D.C.

[3] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proc. 2000 ACM- SIGMOD Int. Conf. Management of Data (SIGMOD?00), Dallas, TX, May 2000.

[4] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In Proc. 1994 Int. Conf. Very large Data Bases (VLDB?94), pages 487-499, Santiago, Chile, September 1994.

[5] H. Mannila, H. Toivonen, and A. I. Verkamo.

Efficient algorithms for discovering association rules.

KDD'94, 181-192, Seattle, WA, July 1994.

[6] A. Savasere, E. Omiecinski, and S. Navathe. An efficient algorithm for mining association rules in large databases. VLDB'95, 432-443, Zurich, Switzerland.

[7] H. Toivonen.  Sampling large databases for association rules.  VLDB'96, 134-145, Bombay, India, Sept. 1996.

[8] M.J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li.

New algorithms for fast discovery of association rules.

KDD?97. August 1997.

[9] S. Brin, R. Motwani, J. D. Ullman, and S. Tsur.

Dynamic itemset counting and implication rules for market basket analysis. SIGMOD'97, Tucson, Arizona, May 1997.

[10] D.W. Cheung, J. Han, V. Ng, and C.Y. Wong.

Maintenance of discovered association rules in large databases: An incremental updating technique. ICDE'96, New Orleans,  LA.

[11] J.S. Park, M.S. Chen, and P.S. Yu. An effective hash-based algorithm for mining association rules.

SIGMOD'95, San Jose, CA, May 1995.

[12] J. Wang, J. Pei, and J. Han. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD 2003.

[13] C. Liu, H. Lu, J. X. Yu, W. Wang, X. Xiao. AFOPT: An Efficient Implementation of Pattern Growth Approach.

In SDM 2003.

[14] M. J. Zaki and C. Hsiao. CHARM: An efficient algorithm for closed itemset mining. In SDM, 2002.

[15] T. Uno, T Asai, Y. Uchida, and H. Arimura. LCM: An Efficient Algorithm for Enumerating Frequent Closed Item Sets. In SDM 2003.

[16] C. Hughes, T. Hughes. Parallel and Distributed Programming Using C++. Addison Wesley Professional, Aug 25, 2003.

[17] J. Adamo. Data Mining for Association Rules and Sequential Patterns --Sequential and Parallel Algorithms.

Springer  2000.

