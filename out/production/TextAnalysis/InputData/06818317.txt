PDS4: A Model-Driven Planetary Science Data  Architecture for Long-Term Preservation

Abstract ? The goal of the Planetary Data System (PDS) is the digital preservation of scientific data for long-term use by the scientific research community.  After two decades of successful operation, the PDS found itself in a new era of big data, international cooperation, distributed nodes, and multiple ways of analysing and interpreting data. A project was formed to develop a disciplined architectural approach that would drive the design and implementation of a scalable data system that could evolve to meet the demands of this new era. PDS4, the next generation system, uses an explicit model-driven architectural approach coupled with modern information technologies and standards to meet these challenges in order to ensure the planetary data assets can be mined for scientific knowledge for years to come.



I. INTRODUCTION The Planetary Data System (PDS), NASA's planetary  science data archive, is tasked to ensure long-term preservation and usability of big scientific data in seven diverse science domains: Atmospheres, Geosciences, Imaging, Planetary Plasma Interactions, Rings, Small Bodies, and Radio Science. In addition navigation data is also archived for the Navigation Ancillary Information (NAIF) node. The system is distributed and managed by domain experts at physical locations known as nodes.

The PDS facilitates achievement of NASA?s planetary science goals by collecting, archiving, and making accessible digital data and documentation produced by or relevant to NASA?s planetary missions, research programs, and data analysis programs. Its primary goals are to gather and preserve the data obtained from exploration of the Solar System by the U.S., facilitate new discoveries by providing access to and ensuring usability of those data to the worldwide community, and provide the general public with access to the body of knowledge reflected in the PDS data collection. [1, 2]  After two decades of operation, the future arrived for the archive and with it many lessons learned about the approaches pursued to collect, preserve, and support the distribution and use of science data by the user community. With this legacy, the PDS embarked on a complete system redesign starting with the definition of an explicit, over-arching system architecture that would scale to meet the big data demand and  leverage new information technologies. This next generation system is called PDS4.

The PDS4 architecture has two primary components: the information architecture and the software/technical architecture.  The PDS4 information architecture [3, 4] allows all PDS data to be described using a common model. It uses the Extensible Markup Language (XML) [5], a widely accepted and well-supported standard for data product labelling, validation, and searching. It supports a hierarchy of data dictionaries built to the ISO/IEC 11179 standard [6] and designed to increase flexibility, enable complex searches at the product level, and to promote interoperability that facilitates data sharing nationally and internationally.

The software/technical architecture is a distributed service- oriented architecture and encompasses the individual PDS discipline nodes and the PDS?s international partners. It provides consistent protocols for access to the data and services and deploys an open source registry infrastructure to track and manage every product in the PDS. Finally it supports a distributed search infrastructure.

PDS4 is the first operational system resulting from the application of a lifecycle developed for model-driven software systems for science. It has been used to coordinate data archiving in both the national and international planetary science communities. The capture of the information model in an ontology formalized the system?s information requirements.

This allowed significant but controlled change during development and will allow evolution of the system as the science domains and implementation technologies change.

PDS4 will provide a scientific research asset that allows current and future users to re-analyse the data within new contexts.

In the following a problem description, the information model and software infrastructure, and a critical evaluation of the results are presented.



II. PROBLEM DESCRIPTION The PDS is a mature and successful data archive system  that had become technologically dated. Version 1.0 of the PDS went operational in June 1990. It consisted of a high- level catalog for finding data sets by mission, instrument,     spacecraft and target body and a collection of data set archive volumes stored and distributed on tape. The Object Description Language (ODL) [7] was used to capture catalog metadata and to label data for the archive. In 1992, significant changes were made to the system to use CD-ROM as the primary archive and distribution media. At this time the high- level catalog was also simplified to use more text instead of keywords to capture metadata. By 1996, the PDS had a web presence and in 2002 there was a significant change in product distribution shifting from an archive consisting of CD and DVD media to an online system supported by on-line mass storage and data bricks.

After two decades of successful operation, PDS management decided that continued evolutionary change was not sufficient to meet the needs of an increasingly web-based science community. In 2010, a complete redesign of the system was initiated. The goals included a distributed service architecture, new data standards, data formats and data structures, an integrated confederation of nodes, and support for international collaboration [8]. Some of the specific problems that were addressed are summarized below.

A. Aging Architecture and Technology The original system had been designed as an offline system.

Even though there had been significant effort to modernize the original system, the data standards and software infrastructure were limited in scalability and extendibility, could not support the future growth of data and users, and was not sufficient to support online operations.

The growth of the PDS, both for NASA and non-NASA missions, had stressed the structure and capabilities of the original data standards. For example, even though accepted data engineering principles had been used to design the original catalog database, the designs of the archive volumes and data product labels were based on an early object-based model that did not adapt well to changing science domains.

This allowed ambiguity to creep into the standards and resulted in data that should not have been accepted being placed into the archive.

Maintenance and extension of the legacy tools, infrastructure, and supporting technologies became increasingly difficult. It was evident that a new architectural approach using modern information technologies provided an opportunity to greatly improve the overall scalability, operation, and usability of the PDS for the big data era.

B. The Era of Big Data Since 2001, the PDS has grown from a total size of 4  terabytes to over 500 terabytes in 2013.  This includes all the data captured from robotic exploration of the solar system since the 1960s.   Today, instruments have significantly greater capability to capture detailed scientific measurements and to make them available to the scientific community.

Beyond the size of data, the number and diversity of the types of measurements has made the PDS archive a collection of massive, heterogeneous sets of data represented by about 4000 different types. These trends are expected to continue in the foreseeable future.

In addition to the growth of the data, the U.S. is actively working with multiple space agencies around the world to collaborate and share instruments and scientific data results.

In 2006, the International Planetary Data Alliance was created which would focus on extending the PDS standards and infrastructure towards a world-wide archive.

These drivers are consistent with many challenges that various scientific communities themselves are encountering in the big data era.  Coined the ?3 Vs? of big data - volume, variety and velocity - the PDS exhibits each of these elements.

C. The PDS Supports a Diverse Community The PDS archives data for seven science domains. Within  each domain the science data structures are diverse, ranging from simple text tables to hyper-spectral cubes. This diversity makes system interoperability and data correlation difficult.

The information model developed for Version 1.0 of the PDS catalog had been successful in providing a common set of broad concepts and relationships for data sets, collections of data products. For example, templates for instrument, mission, and target descriptions had been designed, related to data sets, and used in search. However there was little in common in the design of data products. For example, it was not until Version 3.0 of the PDS data standards that a common product identifier was defined. The lack of a common identifier and other common product descriptors seriously hindered the development of general cross-discipline data product search.

This situation resulted in a very loosely federated system where each discipline node managed one or more product catalogs. There were a few attempts to provide cross- discipline product searches. However in general users first searched the main catalog and were then directed to the node?s product catalogs. As suggested in [9] the attempt to achieve seamless connectivity, for example system interoperability and data correlation, after the fact is essentially cryptography.

Under Version 3.n and earlier versions of the PDS data standards, if a data provider could describe the data structures using ODL then the data was typically accepted into the archive. Initially it was believed that system software could be maintained to support all data structures in the archive however it was soon clear that this was not reasonable.

Ultimately, and in too many cases, special software had to be written to convert complex data structures for them to be used.

Retrospectively it was determined that a few simple data structures would suffice for the majority of the data in the archive. Simpler data structures are also more stable suggesting that the more complex data structures should be converted before submission to the archive. The simpler structures also improve ease-of-use, data correlation, and system interoperability.

D. Long-term Preservation Desired for Future Scientists The primary requirement of the PDS is to preserve  planetary science data for long-term use. This is especially important for planetary science since the data is typically unique and difficult to replace.

The planetary science archive is continually re-mined by scientists for new scientific discoveries. Decades after a mission scientists not involved in the original mission will be searching for and retrieving data. The archive must provide the data and all available metadata in order to recreate the context within which the data was collected and processed so that it can be understood and effectively used.



III. PDS4 INFORMATION MODEL AND ARCHITECTURE ?An information model is a representation of concepts,  relationships, constraints, rules, and operations to specify data semantics for a chosen domain of discourse.? [10] For the PDS, the domain of discourse is the planetary sciences. In the following sections, some of the key principles and methodologies used in the development of the PDS4 information architecture will be described.

A. Use a knowledge acquisition process to extract domain knowledge from experts across the designated community  The development of an information model primarily involves the development of a consensus definition for each thing-of-interest in the community?s domain. To accomplish this, the PDS4 Data Design Working Group (DDWG) was formed using experts from each domain in the community.

The team started from scratch but considered lessons learned from the legacy system. The team, numbering an average of 17 individuals held two-hour teleconferences almost weekly for four years to produce the first operational version. To obtain consensus, the definition of each item was raised as an issue, claims were presented as to the best way to model the item, and evidence was then provided either for or against each claim. The claims were most often resolved after a majority opinion was formed; however, in some cases formal votes were required. Often an issue was revisited two or more times as the model matured. In general, the team understood that some uncertainty always existed and that the original issue could always be revisited.

B. Use a commonly accepted knowledge capture and modeling tool  Our Version 1.0 data modeling experience as well as the literature [10] strongly suggested that a modeling tool should be used for the design and maintenance of the information model. In particular, a modeling tool allows the results of knowledge acquisition to be consistently and formally captured in both a machine and human readable form. The Prot?g? [11] ontology modeling tool was adopted since it was object-oriented and had good support and a large user base. It also provided what we determined to be the best means to capture a model that was ?complete, sharable, stable, extensible, well-structured, precise, and unambiguous.? [10] Tools and languages such as the Unified Modeling Language (UML) were considered however we desired to use the most powerful and expressive language commonly available at the time. This also was consistent with our intent to keep the model independent of its implementations.

A key requirement for the PDS4 development was to reduce the level of ambiguity that existed in the prior model.

To address this issue, concepts resulting from the knowledge acquisition task were implemented as proof-of-concepts as soon as possible. This allowed a common and unambiguous reference source to be produced and made available to the working group for review and discussion.

C. Use a commonly accepted data dictionary standard for fundamental interoperability  ?A data dictionary is a centralized repository of information about data such as meaning, relationships to other data, origin, usage, and format.? [12] Where the ontology-modeling tool captures the information model in an object-oriented paradigm, the requirement for systems interoperability suggested that a comprehensive data dictionary was needed for sharing the information model. The standard reference model, ISO/IEC 11179 Information Technology -- Metadata registries [4], provides a metadata-registry schema as well as recommendations for all aspects of metadata management, including best practices for naming, writing definitions, and governance. The majority of the registry schema was implemented in a second Prot?g? ontology. In particular, the multi-level governance model and the ability to capture names and definitions in multiple natural languages have proven to be very useful. The data dictionary is dependent on and captures all of the ontology?s content. For example the data dictionary has a data element entry for each ontology property.

D. Use a commonly accepted language for implementation The science metadata that is to be ingested into the archive  must be encoded into a language, written to digital files, and associated with the science data. The language needs to be widely available, stable, and have comprehensive software support. XML was the logical choice for PDS4. To create XML label templates and validate label content the XML Schema Definition (XSD) language [13, 14] was adopted.

Other languages were available but were not then as widely used.

The translation of an object-oriented model into XML Schema raised many issues that took considerable time to resolve. These include the choice of XML Schema constructs for the implementation, level of complexity, look-and-feel, and ease-of-use. These issues probably made up half of the issues resolved over the four years. Breakthrough solutions were often found late, requiring earlier proof-of-concept to be replaced. For example, to reduce schema complexity XML Schema was ultimately limited to primarily defining XML document  structure and Schematron [15] was adopted to validate constraints. So currently the structure of a PDS4 product label is validated using XML Schema and enumerated values in the label are validated using Schematron rules.

E. Use an accepted archive reference model for key archive components.

The requirement for system interoperability and data correlation suggested that at a fundamental level, common and widely accepted archiving principles should be used. The de- facto standard for archived systems is the Open Archive Information System (OAIS) reference model [18]. A key     component of the OAIS reference model, the information object, was adopted as a core component of the PDS4 information model. An OAIS information object is simply a data object paired with the metadata object that describes it.

The reference model defines two types of data objects, the digital object (e.g., a raster image) and the physical object (e.g., a meteorite). For PDS4, an additional type of data object was defined, the conceptual object, that is used to define things that are not physical, for example NASA missions.

The adoption of the information object allows all digital objects like images, physical things like instruments, and conceptual things like missions to be modelled similarly. Also since the definition of information object is recursive, the PDS4 product is itself an information object. This approach greatly simplifies the information architecture and software development. For example, the XML Schema implementation of a PDS4 product is a network of XML elements, each corresponding to a modelled PDS4 information object.

The OAIS reference model also defines several types of metadata required for an archive and provides guidance on packages for submission to the archive, management in the archive, and dissemination from the archive.

F. Use a commonly accepted registry model for object registration, unique identification and versioning, and tracking.

The PDS functions both as a long-term and an active archive for the planetary science community. As an active archive, a registry is needed to uniquely identify, version, and track the archive?s content. It must also support the search of and retrieval from the archive. For the registry?s schema, the Electronic Business XML (ebXML) reference model [19] was adopted. It addresses the requirements mentioned above and also provides the common elements required to ensure compatibility between the information model and the registry software.

Version 3.0 of ebXML was chosen because it is extensible.

The reference model schema defines an extrinsic registry objects as an object that can be registered, associated, classified, and indexed. However the content of the object is opaque to the registry. This allows the registry to be configured to manage registry objects from any domain by providing the requisite metadata such as object type, object classification, index parameters, and object associations. This aspect of the registry is vital to the model-driven architecture adopted for PDS4.

G. Use a model-driven approach to design and implement the system  The information model is a set of information requirements for the system. The implied requirement on software development is that the software must leverage the information model to meet the system?s functional requirements.

At a minimum, the PDS4 information model is used to validate the contents of the archive. In addition the adoption of the registry object, logical identifier, and version identifier from ebXML, the information object from OAIS, and the  governance model from ISO/IEC 11179 resulted in a product centric design. Everything to be placed in the archive is designed as a product that is ingested into the registry as an extrinsic registry object where it is uniquely identified, versioned, and tracked. In addition the model also provides information to support search, retrieval, and data processing.

In PDS4 the content of the information model is extracted, translated, and written in various formats to files for system use and documentation.  Figure 1 illustrates this process.

The XML Schemas are used to create XML templates for PDS4 product labels, typically using an XML editor. Data providers select the appropriate product type and extend it as necessary for their data.

For the user data dictionary an XML file is written in DocBook format. For the next version of the PDS4 data dictionary the contents are written to files compatible with the ISO/IEC 11179 schema as implemented in Prot?g?. Another user document, the Information Model Specification, is written in a simple tabular format in HTML for model browsing.

A configuration file is written to provide the registry with the product types, product associations, indexing parameters, and other information about the products that it will be expected to manage. The query models are class attributes that have been designated as potential search parameters. Their intended use is to configure facet-based search engines.

Finally files in data definition and data exchange languages are written as needed. Currently these include RDFS/XML[16] and XMI/XML[17].

Changes to the information model take on the average about an hour to implement. This includes making the change, document generation, and unit regression testing. The document generation takes less than a minute. A versioning scheme is used at each governance level to indicate the degree of change, for example, whether the schemas are backwards compatible.

The impact of changes to the model on the system depends on the type of change. The majority of the changes should not impact the registry since the content of a registry object (product) is opaque to the registry. For example an addition to the provenance model would have no effect. A change to the product identification or versioning would have an affect however this part of the model was adopted from a standard reference model and should change little, if at all.

Changes to the query models and other parts of the model used by search engines or data processing software will have more significant impact. The impact is related to the degree to which the software can be re-configured.

Figure 1 - The Information Model Driven Process and the Generated Artifacts

IV. PDS4 DISTRIBUTED CYBERINFRASTRUCTURE ?Cyberinfrastructure consists of computing systems, data  storage systems, advanced instruments and data repositories, visualization environments, and people, all linked together by software and high performance networks to improve research productivity and enable breakthroughs not otherwise possible.? [22]. In the following sections, some of the key principles and methodologies used in the development of the PDS4 cyberinfrastructure will be described.

A. Use service-oriented software architecture where appropriate.

Service-oriented software architecture (SOA) is an architecture for building applications that implement business processes or services using a set of loosely coupled black-box components orchestrated to deliver a well-defined level of services [20].  SOA was determined to be the best software architecture for the PDS4 system as derived from the following PDS requirement:  2.8 Architecture: PDS will maintain a distributed architecture based on scientific expertise  Further derivation of this requirement resulted in requirements for a distributed catalog system, common and discipline- specific services, computational services and integrated online interfaces.

With the SOA approach selected, three additional architectural decisions were made to tailor this approach for a PDS implementation:  ? Service-Based Design ? System of Registries ? Enhanced Tool Suite  Although service-based design is a given within SOA, for PDS the service-based functionality will focus on public interfaces for search, retrieval and value-added processing (science services) of data. Among these services, will be a system of registries to support improved tracking and access to PDS data. A registry provides services for sharing content and metadata while a federated registry allows cooperating  registries to appear and act as a single virtual registry. Finally, a tool-based approach is still appropriate for certain functions within the PDS. These functions include design, generation, validation, transformation and visualization.

B. Use a layered architecture to facilitate reuse of functionality  Figure 2 illustrates the layered architecture utilized for PDS4 detailing how the different components (services, tools and applications) in the system interact and build on each other.

Figure 2 - PDS4 Layered Architecture  The client layer represents applications or interfaces utilized and/or developed by the user community. The presentation layer represents the interface to the PDS community and defines where general and customized search applications reside along with tools for preparing and manipulating the data. The logic layer represents the PDS-wide and DN- specific software and is where the services reside. The resource layer represents the PDS-supported platforms and networks hosting the system.

C. ebXML ? The Federated Registry PDS4 adopted the ebXML v3.0 model for implementation  of its online, interoperable, distributed registry architecture.

An ebXML Registry provides services for sharing content and metadata between cooperating registries in a federated environment; and allows cooperating registries to be federated together to appear and act as a single virtual registry/repository within the model. [21] The benefits of this approach are evident in seamless information integration and sharing while preserving local autonomy over data (e.g., federated search seamlessly returns results from multiple stores).

A federation consists of more than one registry that is self- governing but abides by a common set of rules to enable interoperability.  The federation operates at a level where the participants within the federation are in agreement as to how to cooperate with respect to interoperability.  Federation is expressed as a gradient of minimal interoperability to fully     federated interoperability. The current trend in science organizations is towards common systems, tools, and processes. While that is a trend away from disjointed systems; it is unrealistic to assume that there will ever be a single process or tool that can satisfy every need in a large set of science organizations.

Some of the factors and scenarios that are driving the need for a federated architecture follow.

1)  Cost:  Federation allows diverse teams to interact with each other and to have visibility into other team?s work and design decisions is beneficial. This reduction in time delay is a key factor in reducing design cycle time and cost.

2)  Schedule:  As discussed in the previous paragraph, a federated architecture can facilitate the reduction of cycle times.

3)  Agility:  Federation offers more flexibility and agility as organizations change and tools change over the product life- cycle. Federation offers a more practical way to absorb these changes without catastrophic impact to the program and the cooperating organizations.

4)  Organizational issues:  Often organizational issues are the primary reason for selecting a federated architecture since the other architectures clearly do not resolve these issues. For example, it is impractical to assume that all organizations will switch over to a common tool or process for every program.

5)  Autonomy:  A federated architecture enables members to have more autonomous control over their infrastructure.

Many organizations feel uncomfortable letting go of this control and fear the loss of responsiveness and agility that accompanies a centralized architecture.

6)  Regulations:  Government regulations could force separation of information into two systems that then need to be federated for local users.

The goal of a federated architecture is to create the appearance of a single ?corporate? registry-repository while allowing individual organizations regional control over their individual realms.  One of the main requirements in achieving this goal is the ability to link and share information among the federated registries / repositories.

D. Reviews Peer and external technical and readiness reviews are held  throughout the project life cycle to ensure that PDS4 standards and system architecture design and implementation are sound and meet PDS? requirements and missions? needs as well as to demonstrate the readiness of the project. So far, critical reviews include internal Preliminary System and Standards Review, both internal and external Standards and Products Reviews for various builds, external System Architecture and Design Reviews, and external PDS4 Operational Readiness Review for the first missions planning to use PDS4.

E. Operations - First Missions  The first two U.S. missions to archive under PDS4 standards will be the Lunar Atmosphere & Dust Environment Explorer (LADEE) and the Mars Atmosphere & Volatile EvolutioN (MAVEN) spacecraft. The former launched in September 2013 with the latter is scheduled to launch in November 2013 at the time of writing.

LADEE is a short mission that aims to study the exosphere and dust environment surrounding the Moon, investigating sources, sinks, and surface interactions as well as controls on the distribution and variability of the lunar atmosphere. The instrument package includes three main instruments providing data to the archive: Neutral Mass Spectrometer (NMS), UltraViolet Spectrometer (UVS), and the Lunar Dust Experiment (LDEX).  Each of these instruments share heritage from past flown experiments and will provide ?well- behaved? ASCII-Table data to exercise the new structure of the archive system.

The Mars Atmosphere and Volatile EvolutioN (MAVEN) mission will be part of the NASA Mars Scout program scheduled to explore Mars? upper atmosphere focusing on the ionosphere and interactions with the Sun and the solar wind.

Of utmost importance is determining the role played by the loss of volatile compounds in the history of martian climate, liquid water, and potential habitability through time. MAVEN includes 8 instruments providing data to the PDS.  Of these, 6 instruments comprise the particles and fields package including the following experiments: Magnetometer (MAG), Langmuir Probe and Waves (LPW), Solar Wind Electron Analyzer (SWEA), Solar Wind Ion Analyzer (SWIA), Solar Energetic Particles (SEP), and SupraThermal And Thermal Ion Composition (STATIC).  The other two instruments are the Neutral Gas and Ion Mass Spectrometer (NGIMS) and the Imaging UltraViolet Spectrometer (IUVS).  This set of instruments will expand the range of data types being archived under the initial PDS4 mission effort, and will represent a more complex mission interface than the LADEE example.

All data with MAVEN will be variations on ASCII-Tables with the exception of the IUVS, which will be in FITS format.

Again much of the MAVEN mission is flying experiments with a rich heritage from previously flown instruments, presumably corresponding to data that are similar to sets already archived under PDS3.

Additional missions in the U.S. are planned for launch in 2016 including Origins Spectral Interpretation Resource Identification Security Regolith Explorer (OSIRIS-REx) and (Interior exploration using Seismic Investigations, Geodesy and Heat Transport (InSight).



V. CRITICAL EVALUATION In the following sections a critical evaluation of the PDS4  development and results are provided.

A. Successful Parallel Development By Two Teams With Minimal Interaction  Two engineering teams were formed to develop PDS4. The Data Design Working Group (DDWG) had the goal of producing the information model. The Software Design     Working Group (SDWG) had the goal of developing a multi- level software infrastructure that met the archive requirements of a confederation of distributed science nodes.  Given the decision to adopt a model-driven architecture and a standard reference model for the registry, the two teams were able to design and implement their respective deliverables in parallel with minimal effort. Ultimately the DDWG designed an information model that provided the information required to support the registry?s functional requirements and the SDWG adopted the registry reference model for their design. Even though there was intense interaction within each working group, there was relatively little interaction required between the two working groups.

This decoupling ensures that the technologies can evolve independently. In addition the impact of a change to the information model on the software infrastructure is typically localized and minimal.

B. Successful But Difficult Knowledge Acquisition Across Several Disciplines; Good Participation; Some Cannon- Ball Polishing  A difficult task in the development of PDS4 was the process of knowledge acquisition across the planetary science disciplines. A significant amount of time was required to train discipline experts in data engineering principles such as the object-oriented paradigm. However the discipline experts were committed to the process and provided excellent input.

As expected, there were intense discussions about the abstractions and compromises needed for a common model however the multi-level governance scheme promoted by the ISO/IEC 11179 standard helped immensely. Those things that could be agreed on across the disciplines were placed in common for governance by the entire PDS. At the discipline level a discipline node could place their more specific designs for governance by the discipline experts. Finally designs specific to a mission are governed primarily by the mission team with help from the discipline nodes.

As the information model matured there was a tendency to perfect ?blemishes? that appeared. For example, the constraints for creating names cycled between strict rules and general guidelines. As a result most names were ?scrubbed? at least two times.

C. An Information Modeling Expert is Required Without an information modeling expert and supporting  tools the information model development task would probably have failed for at least two reasons. First there was a tendency for some to view XML schema as the modeling language. The use of the Prot?g? ontology modeling tool provided object- oriented constraints on the implementation and helped identify a reasonable subset of XML Schema constructs for the implementation.

The prot?g? ontology also provided a single and formal source for referencing whenever a question came up about past design decisions. There was seldom a question about what had been previously decided. However the reasons were often questioned and the design often changed in any case.

D. Difficulties Integrating Disparate Standards ? Object- Oriented Model Vs Other Models  The information model was designed using an ontology modeling tool. As suggested in the previous section, this forced object-oriented constraints on the implementation and caused some difficulties in the implementation into XML Schema. For example, XML Schema developers have the choice of using XML attributes and/or XML elements when implementing a class in the  model. For the PDS4 implementation, XML elements were used for several reasons, one being that annotations for elements could be retained.

However XML attributes were used for the specification of units of measurement. For example, the PDS4 attribute file_size is defined as an XML element. The unit of measurement is specified as byte using an XML attribute.

E. Enabling Future Science The PDS4 system has successfully addressed the major  problems that were identified in the legacy system. The decision to limit the number and complexity of data structures allows the development of software services that focus on three generalized data structures, an n-dimensional array, a fixed width table, and a delimited variable-width table. These can be specialized as needed. For example the class Array_2d_Image was designed for raster images. These structures were championed by the discipline nodes and are being accepted by the community.

Since the digital objects are stored in standard data structures they can be retrieved and processed by standard system libraries. For example image processing software developed by JPL?s Multi-Mission Instrument Processing Laboratory (MIPL) [23] is being integrated into the system to support system services. The simple formats were also designed to be compatible with many contemporary science analysis tools.

The adoption of the ISO/IEC 11179 multi-level governance model provides for one common model and discipline specific extensions. Where the legacy system had one common model that required PDS-wide approval for any change, in PDS4 the common model defines the standard product types and each discipline is then allowed to develop and govern their specific models, for example cartographic models for map projected images.

The combination of a federated registry model and a common information model enables faceted, text, and semantic search at the product level. This together with the formal and unambiguous specification of the metadata enables the use of the data in ways not considered when it was first archived.

F. Testing Verification of PDS4 adheres to an established test process  that has been put into practice in support of the project?s iterative and incremental development approach. Test activities are performed for the verification of system capabilities as well as the information model against well- defined requirements. The test process ensures that a release     of each PDS4 build meets its intended functionality. The process of verification includes standards review, unit testing, integration and regression testing. A set of test documents is produced for each PDS4 build. They include test cases/scenarios, test procedures, test results, and requirement traceability. Issues found during testing are reported in a well defined issue tracking database and are documented as part of the test report.



VI. CONCLUSION The PDS has already reaped the benefits of a model driven  architecture as the various types of science data being generated for future planned missions have evolved from early decisions and agreements. These changes have been easily accommodated by extending classes in the information model.

These evolutionary changes to the model drive changes to the product definitions and documentation but result in minimal if any changes to the software. Furthermore, the separation of the information architecture from the technical architecture has allowed for construction of a distributed architecture that accommodates a wide variety of types of data. International partners outside the U.S. are already putting PDS4 to work for their missions, and systems are now being integrated to form a world-wide planetary data archive under the auspices of the International Planetary Data Alliance (IPDA).  The experience has shown the importance of having an explicit architecture and ensuring that development follows a principled approach that is coordinated with the research community.

The PDS4 system is the result of a lifecycle developed for model-driven software systems. It is being used to coordinate the planetary science community and has been transitioned to operations. The system has responded well to modification resulting from changes in the science domains and implementation technologies.

