An Improved Matrix Sorting Index Association Rule Data Mining Algorithm

Abstract: Due to the existing Apriori association rules data mining algorithms require to scan the database many times and generate a large numbers of candidate sets, which produce giant I/O expense issues, result in low data mining computational efficiency. Matrix algorithms can improve the efficiency in computing frequency 2-itemset, but not delete non-frequency item set before calculation, not effectively improved efficiency. A matrix-based and sorting index association rules algorithm is proposed. Firstly, delete the unwanted affairs and items, the frequent binomial set obtained by matrix multiplying and search table, combined with sorting index derived the rest of the frequency k-itemsets. Compared with Apriori algorithm and matrix algorithm, the proposed algorithm scan database only once, which can directly find the frequency k-itemsets, especially when frequent item sets are higher or need to have a date mining update, the algorithm has higher efficiency and feasibility. Experiment shows that proposed matrix sorting index algorithm greatly improved the data mining efficiency and scalability.

KeyWords: Data mining, association rules, Apriori algorithm, matrix algorithms, sorting index  1 Introduction With the continuous developments of internet,  information- based economy and information technology.

Data mining is now widely used in many areas, including building energy consumption, installment industry, etc. Data mining is the discovery of vast amounts of data from existing unknown, with a potential value of information or patterns. When the concept proposed, it immediately aroused widespread concern in the scientific community.

Association rule algorithm is an important research direction of data mining, which focus on establishing links between different areas of the database to identify the relationship between satisfying a given support and credibility among multiple domains [1]. R. Agrawal et al proposed this method, it originally proposed for market basket analysis, which is aimed at excavating customer purchase behavior association knowledge to guide commercial sales at transactional matters dataset, including: merchant scientifically arranged the purchase, inventory and shelf design. Since the diversity of situations of data, it need to explore effective data mining methods to obtain useful information from massive data provide support for intelligent human-computer interaction [2, 3]. With the development of data mining association rules, it has been successfully applied in other areas of financial securities analysis, telecommunications and banking risk early warning, which shows its great potential for development and application prospects. Many scholars have done a lot of research on this topic and worked for the development of data mining, which have made a great contribution. The improvements of traditional association rule mining are mostly based on Apriori algorithm. The biggest flaw of Apriori algorithm is necessary to repeatedly scan the database, which affects the data mining operating efficiency. Although improved it in many ways later, but the efficiency is still not very high [4, 5].

P.-G. Cheng et al proposed NFUP algorithm, which joins  strong large itemsets into small quantitative of candidate  *This work was supported by the National Natural Science Foundation (61373126). The research was supported by Jiangsu Province Prospective Joint Research Project Foundation (BY2013015-33).

itemsets based on strong large itemsets concept, and adopts early pruning strategy to cut down the times of scanning database [6]. G. Peng et al based on customer relationship management system, introduces an improved data mining association rules apriori algorithm, which deletes lots of invalid affairs, reduces the records for the following scan, which raises the efficiency of data mining. At the same time, with the deduction of the affair, the scale of database is decreased. Consequently, the scanning time is saved and the processing efficiency is enhanced [7]. X. Lv et al focus on the issues about large number of candidate itemsets and the time of scanning the database, proposed an efficient algorithm-WARDM for mining the candidate itemsets to overcome above problems, which can reduce the amount of candidate itemsets and enhance the execution efficiency [8].

Y.-L. Chen et al firstly identifies the various data types that may appear in a questionnaire, proposed a unified approach based on fuzzy techniques, so that all different data types can be handled in a uniform manner [9]. S.-L. Zhang aimed at the performance bottlenecks of multiply scanning the database and generating a large quantity of candidate itemsets in Apriori algorithm, proposed a new algorithm, which filters out the transactions unconcerned with mining targets by a presupposed filter, greatly improves the whole performance of the algorithm [10]. Z. Kun et al based on RS theory and associate rules data mining algorithms, counting core and a reduction algorithm of attributes based on discrepancy matrix, then put forward a mining model of association rules with decision attributes based on Apriori, AprioriTid and Apriori Hybrid algorithms [11]. B. L. Wang et al proposed a new Apriori algorithm based on Boolean matrix, It scans transaction database only once, thus reduces the system cost and increases efficiency of data mining [12].

P. Haiwei et al proposed a new algorithm GMA, which based on association graph and matrix pruning to reduce the amount of candidate itemsets. Experimental results show that it is more efficient for different values of minimum support [13]. S. Anekritmongkol et al proposed a new algorithm based on Boolean algebra compress technique for association rule data mining (B-Compress), which adopts tree major ideas: compress data, reduce the amount of times to scan database tremendously and reduce file size [14, 15].

Proceedings of the 33rd Chinese Control Conference July 28-30, 2014, Nanjing, China     Z. Hong et al n improved Apriori algorithm which uses support count matrix to generate frequency itemsets [16]. J.

Pavon, D. Oguz et al proposed an algorithm called Matrix Apriori combining the best features of both. Matrix Apriori utilizes simple structures such as matrices and vectors in the process of generating frequency patterns, and it also minimizes the number of candidate sets, thus achieving a more efficient calculation than Apriori and FP-growth. The proposed algorithm can be easily extended to incorporate multiple minimal supports defined by the user with the aim of improving method efficacy [17, 18]. A. Zeng el at proposed a measure of cosine similarity, which treated as an interest threshold, moreover, proposed an improved Apriori algorithm called Sim-Apriori based on similarity [19].

The study shows that, the shortcomings of Apriori  algorithm are mainly the requirement of repeatedly scanning the database and generate a larger numbers of candidate itemsets problems; above improvements of association rules mainly aim at improving the Apriori algorithm efficiency and database scanning time. The matrix algorithm scans the database one time and changes the item value to Boolean, improved the efficiency, but not deletes the unwanted item and affair, which increased the calculation. However, the improved efficiency of the Apriori algorithms and matrix algorithm are low to a certain extent, therefore this paper proposed an improved matrix sorting index association rule data mining algorithm, under the premise of scanning database only once, utilize matrix multiply and sorting index, which greatly improved the efficiency of the algorithm and supports updating mining.

2 Improved Matrix Sorting Index Association Rule Data Mining Algorithm This paper presents an improved matrix and sorting index  association rule data mining algorithms called IMSIA the idea is: Combine the advantage of matrix algorithm high efficiency in k-frequency generation and high information search speed of sort index. convert the transaction database to transaction matrix, then no longer scan and use the transaction database, directly research on the affairs matrix, delete the initial matrix obtained pruning matrix, before the deletion of the matrix, in which the numbers were placed in two sequences, for subsequently search table, after the deletion update the two mark sequences. Multiply the deletion of the matrix with its transpose matrix obtained by the new matrix, analyze their data on the triangle and search the sequences to determine the two-frequent item sets. Base on the two-frequent item sets create sort index matrix, using sorting index matrix to down connections, and finally get all of the frequency itemsets.

2.1 Apriori Association Rule Mining Algorithm  The basic conception of association rules algorithm is: set I is data item, D is task-related transaction database set, each element T in the D is a set of items, and IT , each transaction has an identifier, called TID. Association rule is an form BA , in which IA , IB , and  BA . Rule BA was established in the transaction set D with support s, in which s is the percentage of BA (i.e., both A and B) in D, It is the probability of  )( BAP . Rule BA has confidence c in the  transaction set D, the value of percentage of D contains affairs B and affairs A at the same time is c, similar to the conditional probability )|( ABP , as equation (1) and equation (2):  )()sup( BAPBA (1) )|()( ABPBAconfidence (2)  Set of items called itemsets, itemset contains k items is called a k-itemset. If the item set to meet the minimum support minSup, then called frequency itemsets. Rules also meet the minimum support threshold and minimum confidence threshold is called a strong rule that is the association rules. Mining association rules is to find the given minimum support and minimum confidence of all the conditions of implications, which namely strong association rules.

Apriori algorithm using an extent-first search strategy,  level-wise, iterative search item set space. Firstly, scan the transaction database once, calculate support of each data item and generate candidate itemsets Cl, and utilize support threshold to produce frequency 1-itemsets L1. Connect L1 and itself get candidate itemsets C2, then search the database twice, calculate the support of candidate itemsets C2, compare the support of each candidate itemset with minsup, obtain the L2. And so on, until you cannot find frequency k-itemsets, the algorithm search end.

2.2 Matrix Association Rule Mining Algorithm  The basic idea of the matrix algorithm is to scan the transaction database set D to a Boolean matrix, arrange the transaction database D contain m items and n affairs. The entire database can be represented by the items matrix, namely as equation (3):  mnmm  n  n  mn  AAA  AAA AAA  A  ...

...

...

(3)  Where, )0,0( njmiIAij , the element }{ ijA of matrix mnA is defined as equation(4):  njDiif miDiif  A j  j ij ,...,2,1,,0  ,...,2,1,,1 (4)  The matrix contains m rows and n columns, each row represents an affair, and each column represents an item. If the affair iD contains the j-th item in itemset I, then the matrix value of the i-th row and j-th column is 1, the 1ijA , otherwise the value is 0. Matrix A can also be expressed as a matrix of m dimensional row vector, maaa ,...,, 21 called affair vector.

Association rule have two properties. Property 1: A  record does not contain any frequent k-itemsets, which does not contain any frequent (k-1) - item set. Property 2: a non-frequent itemsets, its superset must be the non-Frequent item sets.

2.3 Improved Affairs Matrix Multiplication and Mark Sequence Search Analysis  The Apriori algorithm need to calculate the candidate itemsets Ck and then execute a pruning operation to frequent itemsets Lk, that generate frequency itemsets will produce a large set of candidates, and find each frequency itemsets have to scan the database once, which take up a lot of memory space and CPU processing time, it is difficult to adapt to massive data mining. Matrix Association Rule Mining algorithm does not delete the non-frequency items and affairs, and also need to search the data to find the frequency itemset, which increase the calculation. While these algorithms have been able to reduce the number of candidate sets or through pruning strategies to improve mining efficiency, but still not completely solved the problem of candidate set produce.

Since the most important feature of the index is to speed  up information retrieval. Through index number to leaping search itemsets, if the line does not meet the condition of down connection, then does not need to scan it again, which improved the speed of itemsets mining. With the defect of large calculation in the apriori algorithm of generating 2-frequent itemsets, Matrix association rule mining algorithm converts a affair database to a affair matrix by matrix operations, the upper triangular matrix formation were analyzed to obtain the frequency itemsets, eliminating connecting steps and pruning step in Apriori algorithm, greatly reduced high calculation time of generating frequency itemsets. The IMSIA algorithm is proposed in this paper, which combined the advantages of index and improved matrix association rule, avoid the generation of candidate sets and solve the problem of multiple scans of the database. Firstly delete the useless items and affairs, and use sequence search to get frequency matrix.

The step as follows: The affair database is converted into  Boolean database affair matrix D, and the matrix corresponding to the ranks of the marker sequence affairs and saved to the corresponding entry in a table, set up a database affair and contain m*n items, the corresponding marker sequence rL = {1,2 , ..., m}, cL = {1,2, ..., n}.

Afterwards delete the properties of the matrix, but beforehand have to mark the affair with the corresponding sequence of items marked for exclusion, after deletion of the matrix, S=A*AT can be obtained by multiplying. The following are the main step assigned to the affair matrix and generate frequency 2-itemset: search the affair database D and initial the affair matrix A, fill the sequences item mark  rL and affair mark cL . According to the two association rule properties to delete the invalid items and affairs in matrix A, and derive matrix B, and update sequence ' rL and  ' cL . Multiply the matrix B with matrix BT, S=B*BT,  analysis upper triangular matrix of S. Compare the value of  ijS with minsup. If ijS minsup (i<j), search the sequence mark, obtain the frequency 2-itemset.

2.4 Improved Adaptive Sorting Index Matrix  Since the apriori algorithm needs to search the database and generate the candidates, which occupies large memory and increased I/O costs. Because of the most important  feature of the index is to speed up information retrieval, and the sorting index storage the number, which occupies little memory, and through index number to leaping search itemsets, if the line does not meet the condition of down connection, then does not need to scan it, which reduced the search time, index quantity, memory usage and I/O expense.

This paper at the basis of improved matrix algorithm and  combined the improved adaptive sorting index matrix, which only scan the database one time and not need to generate candidates, and adapt to choose the sorting rule to sort, which improved the calculation efficiency and raised the performance of mining association. The step as follows: when the k of frequency itemsets is more than 2, then use the improved adaptive sorting index matrix, by adapting to choose optimal sort rule and traversing the index number to leaps search the k-itemsets (k 3).

Use 1-itemset L1 of in descending order as the columns of  the matrix and descending order frequently (k-1) item set as rows to establish a sort index matrix. If a line item set I1 corresponds to a value of 1 and I3 is 1, the row represents a 2-itemset I1I3. Where, in each row frequent (k-1) itemset for each itemset is also in accordance with the support number decreasing order to arrange.

Since the sorting rule has a great influence on sorting  index result, and usually the way to fix the rule by author, which could not choose the optimal sorting rule, the adaptively choice of optimal sorting rule between confidence and support is proposed in this paper. By calculating the support and the confidence of each itemset, compare the value of minsup and minconf, if the quantity of matched itemset less, then choose the corresponding minsup or minconf as the sorting rule, if the database only give one parameter, in that way choose the given parameter as the default sorting rule.

For each column, save all the row number of non-zero  elements to array A in order. If the number of items in a column containing the index is less than the minimum support threshold, then delete the column and the column corresponding frequent itemsets of itemset row. For each column, row number value of ( 1)V j itemset of V to replace non-zero elements of the j-th itemset, use the next position number as index to replace the original column value 1. Assign the last non-zero elements of current column with 1. When frequency k - itemsets (k 3) Lk, the process of data mining is down connection the sorting index matrix.

When k = 3, start a scan from the first row R1, in the last  column of the itemsets index number as the goal, go to the row of the index number Rx, connected the 2-itemset corresponds to R1 and Rx to 3-itemset. Use the smaller support number of two 2-itemset as support number of the connected 3-itemset. In the way by row, until scanned the last row, all the frequent 2-itemset is connected, get all frequent 3-itemsets. Then determine whether to continue generating frequency 4-itemset depending on the association rule property. When k>3, as following steps to generate frequency k-itemset: (1) Start scanning the established sort index matrix from  the first row R1, and down the connection. If the row does not contain 1 and the row exactly has the k-2 same index number y, then directly jumps to the corresponding row Ry of index number, and connects this row and (k-1) -itemset of Ry as k- itemsets. If the row does not meet the conditions of     down connection, then skip the row and continue scanning the next row.

(2) Use the smaller support number of two (k-1) - itemset  as support number of the connected k - itemset.

(3) In the way by row, until scanned the last row, all the  frequent (k-1)-item set is connected, get all frequent k - itemsets. Then determine whether to continue generating frequency (k+1)-itemset depending on the above association rule property.

3 Experimental Results  3.1 Examples Analysis  Arrange affair database, assuming the minimum support: 20%, the number of affair is10, as Table 1:  Table 1: Affair Database  Affair ID itemset T1 I1,I2,I5 T2 I2,I4 T3 I2,I3 T4 I1,I2,I4 T5 I1,I3 T6 I2,I3 T7 I1,I3 T8 I1,I2, I3,I5 T9 I1,I2,I3 T10 I5,I6  Base on the affair database, we can obtain the matrix A, as figure 1:  1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1  A  Fig1: Boolean Matrix A  1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0  B  Fig2: Apply cut rule in matrix A and obtain matrix B  3 1 1 2 1 3 2 1 2 1 2 0 1 1 1 1 2 1 1 2 2 2 2 1 3 1 2 2 1 0 1 1 2 2 2 3 1 2 2 2 4 3 2 1 2 2 2 3 3  S  Fig3: Multiply result matrix S And derive the sequences }10,9,8,7,6,5,4,3,2,1{rL ,  }6,5,4,3,2,1{cL , according to the support and property above to cut the matrix A, and get B, as figure 2. Judge if the numbers of ?1? in each row and column bigger than k=2, and  delete the same row, in ' rL the row 3 and row 6 are the same  and row 5 and row 7 are the same, so get B, and updated }9,8,5,4,3,2,1{'rL , }5,4,3,2,1{  ' cL and when  search the sequence, according to the deleted row. The proposed step reduces the calculation, In particular, in big affair database, the performance especially well. Then, calculate the S=B*BT, as figure 3.

Analyze the matrix S on the triangle, based on minsup and  sequence 'cL , ' rL , when ijS minsup (i<j), obtain the  frequency 2-itemset are as follows:L2= {I2I1(4), I2I3(4), I2I5(2), I2I4(2), I1I3(4) ,I1I5(2)}.

According to the formed 6 frequently 2-itemsets to sort  with their support number, I4 corresponding column only has one ?1?, it means that itemsets I2I4 is impossible connecting with the other 2-itemsets. Therefore, delete the rows and columns corresponding to I4, as Table 2:  Table2: Sort Index Matrix  Number L2 I2 I1 I3 I5 Sup  a {I2I1} b c 0 0 4 b {I2I3} d 0 c 0 4 c {I1I3} 0 e 1 0 4 d {I2I5} 1 0 0 e 2 e {I1I5} 0 1 0 1 2  Where, the sequence number is made of a, b, c, d and e lowercase alphabet, which means that the set of the row number, only play the role of the index. Firstly, scan row 1with I2I1, leaping search column of I1, jump to the third row by the index number c, that is the row of itemset I1I3, connect the row 1 and row 3, obtain the frequency 3-itemset I2I1I5.

The support of I2I1I3 is 4, the support of I2I1 and I1I5 respectively are 4 and 2, so the support of I2I1I5 is 2.

Continue scanning row 2 and row 3, until the last line.

Apriori algorithm in this steps to form a candidate 3-itemset, and there is six, is not conducive to the improvement of the efficiency of the algorithm.

After arrangement, get two frequent 3-itemset, L3 is  {I2I1I3 (4), I2 I1I5 (2)}. And then base on the two itemsets of L3 to establish sort index matrix, can be seen from Table 3, the index number of each row down the connection not meet the conditions, and therefore, will not yield frequency 4- itemset, the algorithm ends.

Table3: L3 sort index matrix  Number L2 I2 I1 I3 I5 Sup a {I2I1I3} b b 1 0 4  b {I2I3I5} 1 1 0 1 2  From the above steps of the algorithm obtained the following results: Frequency 1-itemset L1 is {I2(7), I1(6), I3(6), I4(2), I5(2)}.

Frequency 2-itemset L2 is {I2I3(4),I2I1(4), I1I3(4), I2I5(2), I2I4(2)) I1I5(2)}. Frequency 3-itemset L1 is {I2I1I3(4), I2I5I2(2)}. Frequency 4-itemset L4 is empty; the maximum frequent 3-itemsets is L3.

3.2 Efficiency and Database Analysis  Time complexity of Apriori algorithm to scan the database is (n ? m), the time complexity of the proposed IMSIA algorithm to scan the database is (m), and not need to generate candidate itemset, greatly improved the efficiency.

Experiment use random function Random() automatically  generate data set, database generated by random data in this way is more flexible, each time you enter the number of transactions |T| and item Episode |I|, the database will automatically generate a set of data. The new data set. This data set does not have any artificial interference, can fully reflect the efficient performance of the proposed algorithm.

The proposed IMSIA algorithm, matrix algorithm and  Apriori algorithm are compared and analyzed in running time and memory usage. Use Pentium(R) dual-core 2.62GHz/3.0GB microcomputer (OS is Windows XP) under eclipse environment and java language, realize the algorithm experiment Analyze the running time of each algorithm under the  different minimum support and the same data sets, running time of IMSIA at k=2, is the matrix generation and matrix multiply. When k 3 the total running time of IMSIA is to establish that sort time plus the index matrix leaping search itemsets time, while the total running time of Apriori algorithm is the time of scanning the database plus generates candidate itemsets time plus the pruning time. Compare running time of different supports show in Figure 4, Which can be seen, under the same data sets (|T| = 1000, |I| = 30), the running time of proposed IMSIA algorithm at each support is always less than Apriori algorithm and Matrix algorithm, which means that proposed IMSIA algorithm before computing frequency 2-itemset, firstly delete useless item and affair, decrease the amount of unnecessary calculation, then use matrix multiply and search sequence get the frequency 2-itemset, which better than the normal matrix algorithm, then combine the sort index matrix to compute out the other frequency itemset, which avoid computing the calculations, improved the Computational efficiency, is better than Apriori algorithm. In the case of different support, compare the calculation time of the three algorithms, proposed IMSIA algorithm is more superior and has more efficiency.

1 8 2 0 2 2 2 4 2 6 2 8 3 0 3 2  2 0 0  4 0 0  6 0 0  8 0 0  1 0 0 0  1 2 0 0  1 4 0 0  m in im u m  s u p p o rt / (% )  ru nn  in g  tim e/  s     A p rio ri a lg o rit h m M a t rix  a lg o rit h m IM S IA  a lg o rit h m  Fig 4: Running time of each algorithm with different support  Under the same support and different data sets, the comparison of running time shown in Figure 5. Randomly generated seven data set of different average length, respectively, D1 (|T| = 100, |I| = 15), D2 (|T| = 200, |I| = 30),  D3 (|T| = 1000, |I| = 30), D4 (|T| = 1500, |I| = 30), D5 (|T| = 2000, |I| = 60), D6 (|T| = 5000, |I| = 80) and D7 (|T| = 10000, |I| = 120), set minsup count as 28. At condition of the same minimum support and different data sets, the running time of matrix algorithm is always less than Apriori algorithm, the running time of IMSIA algorithm is always less than matrix algorithm, which means that at different data sets the proposed IMSIA algorithm always keeps the optimal running time among three algorithms. Moreover, with the growth of data sets, the proposed IMSIA algorithm shows linear growth trend, which has a good scalability and high efficiency performance.

1 2 3 4 5 6 7  5 0 0  1 0 0 0  1 5 0 0  2 0 0 0  2 5 0 0  d a ta  s e ts ru  nn in  g tim  e/ s     A p rio ri a lg o rit h m M a t rix  a lg o rit h m IM S IA  a lg o rit h m  Fig 5: Running time of each algorithm with different data sets  Table4: Memory Usage Comparison  Algorithm name  Memory Usage Size/Kb  Memory Usage Rate  Apriori 483,060 15.36% matrix 395,422 12.57% IMSIA 261,634 8.31%  Consideration the algorithm cost, the proposed IMSIA algorithm only scan the database once, and put the index and sort into cache, reduced the cost of I/O operation. In the condition of the same data set (| T | = 1000, | I | = 30), and set the minsup count=28, compare the memory usage among the three algorithms, as Table 4. Apriori algorithm memory usage occupies 15.36%; Matrix algorithm memory usage occupies 12.57%; Proposed IMSIA algorithm memory usage occupies 8.31%. The result shows that the matrix association rule algorithm memory usage is better 2.79% than it of the Apriori algorithm, the proposed IMSIA algorithm memory usage rate is the minim, compare with the apriori, the memory usage rate improved 7.05%, further validate the high efficiency of the proposed algorithm and low memory usage rate and small I/O costs.

4 Conclusions An IMSIA association rules algorithm is proposed in the  paper. Firstly, search the database and establish the affair matrix, build the item and affair mark sequence, then delete useless item and affair in matrix, and update mark sequence, subsequently, multiply deleted matrix with its transpose matrix, obtain the frequency 2-itemset. Afterwards, combined with sorting index derived the rest of the frequency k-itemsets. It scans the database only once, without generates candidate itemsets, reduced the memory and I/O costs, furthermore, can support data mining real update. The proposed algorithm improved the data mining efficiency, saved more memory and I/O resources and increased the scalability.

5 REFERENCES [1] S. Zhang and X. Wu, Fundamentals of association rules in  data mining and knowledge discovery, Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 1:97-116, 2011.

[2] Yang Wenyi, Ye Dan, Xiao Bo, Model of situational awareness data mining system, in 31th Chinese Control Conference Proceedings, China, Hefei, 2012:5.

[3] X. Li, S. Mabu, H. Zhou, K. Shimada, and K. Hirasawa, Genetic network programming with estimation of distribution algorithms for class association rule mining in traffic prediction, in 2010 6th IEEE World Congress on Computational Intelligence, WCCI, IEEE Congress on Evolutionary Computation, Barcelona, Spain, 2010.

[4] K. Taboada, S. Mabu, E. Gonzales, K. Shimada, and K.

Hirasawa, Genetic network programming for fuzzy association rule-based classification, in 2009 IEEE Congress on Evolutionary Computation, CEC, Trondheim, Norway, 2009:2387-2394.

[5] D. Becerra, D. Vanegas, G. Cantor, and L. Nino, An association rule based approach for biological sequence feature classification, in 2009 IEEE Congress on Evolutionary Computation, CEC, Trondheim, Norway, 2009:3111-3118.

[6] P.-G. Cheng, Y. Chen, and X. Yi, Research on an improved association rules data mining algorithm and its application, in and Engineering, ICACTE, Cairo, Egypt, 2009:1211-1219.

[7] G. Peng, Y. Chi, L. Hui, and K. Weili, The application of improved association rules data mining algorithm Apriori in Computing and Applications, ICPCA'07, Birmingham, United kingdom, 2007:95-99.

[8] X. Lv, Y. Li, and X. Lu, A web data mining algorithm based on Weighted Association Rules, in 2011 International Conference on Materials, Mechatronics and Automation, ICMMA, Melbourne, VIC, Australia, 2011:1386-1391.

[9] Y.-L. Chen and C.-H. Weng, Mining fuzzy association rules from questionnaire data, Knowledge-Based Systems, 22: 46-56, 2009.

[10] S.-L. Zhang, A new mining algorithm of association rules and Computing, ICIC, Zhengzhou, China, 2011:123-128.

[11] Z. Kun and L. Shao, Based on rough set of associative rules improve algorithm of data mining, in 2010 International Conference on Computer Application and System Modeling, ICCASM, Shanxi, Taiyuan, China, 2010:V11236-V11239.

[12] B. L. Wang and Y. G. Shen, Improvement of Apriori algorithm based on Boolean matrix, in 2010 International Conference on Micro Nano Devices, Structure and Computing Systems, MNDSCS, Singapore, 2011:144-148.

[13] P. Haiwei, T. Xiaolei, H. Qilong, and Y. Guisheng, An Effective Algorithm Based on Association Graph and Matrix for Mining Association Rules, in 2nd International Workshop on Database Technology and Applications (DBTA), 2010:1-4.

[14] S. Anekritmongkol and K. Kasamsan, The comparative of Boolean Algebra compress and Apriori rule techniques for new theoretic association rule mining model, International Journal of Advancements in Computing Technology, 3: 58-67, 2011.

[15] S. Anekritmongkol and M. L. K. Kasamsan, The comparative of Boolean algebra compress and apriori rule techniques for new theoretic association rule mining model, in 6th Management and Service, IMS2010, with 2nd International Conference on Data Mining and Intelligent Information Technology Applications, ICMIA, Seoul, Korea, Republic of, 2010:216-222.

[16] Z. Hong and F. Bian, An improved Apriori algorithm based on support count matrix, Wuhan Daxue Xuebao (Xinxi Kexue Ban)/ Geomatics and Information Science of Wuhan University, 33:1246-1249, 2008.

[17] J. Pavon, S. Viana, and S. Gomez, Matrix Apriori: Speeding up the search for frequent patterns, in IASTED International Conference on Databases and Applications, DBA, Innsbruck, Austria, 2006:75-82.

[18] D. Oguz and B. Ergenc, Incremental itemset mining based on Data Warehousing and Knowledge Discovery, DaWaK, Vienna, Austria, 2012:192-204.

[19] A. Zeng, D. Liu, and H. Chen, An improved apriori algorithm Materials Science and Information Technology, MSIT 2012, Xi'an, Shaan, China, 2012:1825-1829.

