

Extension of Hierarchically Classifier System using Self GA Invocation  Satoshi ENDOH+ Hiroshi KAWAKAMIj Azuma OHUCHIt  t Depart ment of Information Engineering,Faculty of Engineering University of the Ryukyus  $Laboratory of Harmonious Systems Eng.) Research Group of Complex Systems Eng.

Division of Systems and Information Eng., Faculty of Eng.

Hokkaido University  1 Introduction  Classifier system is one of the powerful and ro- bust learning system which is able to learn good rule set in the nonlinear environments. Although classifier system shows great promise, the sys- tem has a number of serious difficulties about it?s learning efficiency. This difficulty is reflected by the problem of rule clustering and rule associa- tion.

First problem, the rule clustering problem is that  whole classifiers in a population will become similar patterns, but these patterns don?t include whole sub-solutions. Second problem is rule as- sociation problem. Traditional classifier systems do not have effective mechanisms for creating and maintaining default hierarchies or rule chains.

Then we propose the multiple leveled hierarchi- cally structured classifier system called mHCS.

Although the mHCS system leaves many features of traditional CS, one of the important difference is.that some classifiers are grouped together as a family in mHCS. Then mIICS has n-population levels tha t  are classifier level, family level, meta family level, ..., and n-meta family level. Mem- bers of a family work to  maximize their fam- ily?s strength and the each member?s strength. In this system, matching operator is executed at the classifier level. However, the matched classifier?s bid is calculated not only by the strength of clas- sifier and its specificity, but also the strength of the family tha t  it?s belongs to. Most genetic op- erations, except to  the mutation and some parts of crossovers, are executed at the family level. It means tha t  the basic unit for the genetic opera-  tion is changed to  the family from the classifier.

The main causes of the rule clustering prob-  lem are the competitions among good classifiers or their schemata, and the disruption of useful patterns by genetic operations. In traditional classifier system, crossover between two classi- fiers generate offsprings tha t  are not compati- ble with the solution set. The mHCS solve this problem by imposing some relations over these classifiers. These related classifiers may stay in the same family with high probability of generat- ing incompatible offsprings. And then, classifiers in mHCS are grouped into families by selecting competent relations, that  could be default hierar- chies or valid chains. Most genetic operations are doing between families. Therefore, the probabil- ity of breaking default hierarchies or classifiers? chains by genetic operations is reduced.

Another approach t o  get a good performance of CS is to control the timing of GA operator invocation. Our system is able to control the timing of GA-invocation monitoring the satu- ration of family?s strength. Some experiments are designed to  investigate the performance of the mHCS. The results of experiments represents that  the inHCS shows good performance for the problems that  have large search space.

2 Classifier system The research field of Genetic Based Machine Learning(GBML) are divide broadly into two categories. One is the Michigan approach orig- inally proposed by Holland, and the other is the  0-7803-3280-6/96/$5.00 O1996 IEEE - 2534 -    Pittsburgh approach by Smith. CS-1 system de- veloped by Holland is now called Classifier Sys- tem, and this system is one of the most popular learning system. A classifier system(CS) consists of the three subsystems as follows.

1. Rule & Message System  2. Apportionment of Credit System  3. Genetic Algorithm  RuleaMessage System  lasslllers  Apporllonmenl 01 Genelic Algorllhm Credll Syslem I  Figure 1: Classifier system  3 Problems  3.1 Rule clustering First problem, the rule clustering problem is those whole classifiers in a population may over- concentrate t o  similar patterns, but these pat- terns don?t include whole sub-solutions. The main causes of this problem are the competitions among good classifiers or their schemata, and the disruption of useful patterns by genetic opera- tors. In traditional classifier systems, crossover between two classifiers may generate offsprings that are not compatible with the solution set.

mHCS solve this problem by imposing some re- lations over these classifiers. These related classi- fiers may stay in the same family with high prob- ability. If genetic operations are restricted in dif- ferent families, HCS can reduce the probability of generating incompatible offsprings.

Another reason for the clustering problem is premature convergence. If a solution classifier is included in the initial population and more useful classifiers be generate much later, the first clas- sifier would have a much higher strength in the population. Then the population may converge to this classifier prematurely. In HCS, the prob- ability that  at least a correct family is contained in an initial population is much smaller than at  least one solution classifier is included in the ini- tial population in a traditional classifier system.

Therefore, the probability of converging to  one family is smaller.

3.2 Rule association  Second problem is the rule association problem.

Traditional classifier systems do not have effec- tive mechanisms for forming and maintaining de- fault hierarchies or rule chains. In mHCS, classi- fiers are grouped into families by selecting compe- tent relations, that  could be default hierarchies or valid chains. Most genetic operations are doing between families. Therefore, the probability of breaking default hierarchies or classifiers? chains by genetic operations is reduced.

3.3 Rule set association  mHCS is able to  reduce the rule association prob- lem, moreover the system is able to  solve the rule- set association problem. In mHCS the families at HCS are grouped into meta-families by some relations, and the mHCS can form and main- tain the classifier chain sets or default hierar- chy sets. Therefore, the mHCS has more per- formance of correspondence to large search and solution spaces than the ordinary CS.

4 mHCS  CS uses no hierarchy in the population to search solutions. For large search and solution spaces problem, the performance of CS with multiple level that is called mHCS is better than ordinary CS. mHCS with two level hierarchy can reduce the rule association problem by joining some clas- sifiers together as a family, but cannot reduce the rule-set association problem. With two popula- tion levels, mHCS can take care of default hierar- chies and classifier chains, but is not able to  take care of default hierarchies sets or classifier chains sets.

mHCS with multi level hierarchy can reduce the rule-set association problem by joining some families together as a meta-family, by joining some meta-families together as a meta-meta- family. With multiple population levels, mHCS can take care of classifier chains sets.

- 21535 -    4.1 matching  As in traditional classifier systems, matching is done at the classifier level. However, the bid of a matched classifier is determined not only by the strength of the classifier and its specificity, but also the sum of the strength of the family that  it belongs t o  and strength of meta-families tha t  the family belongs to.

The strength of a family is the sum of the strength of whole the classifiers tha t  con- tained in the family, and the strength of a meta-family(meta-meta-family) is the sum of the strength of whole the families(meta-families) that contained in the meta-family(meta-meta-family).

A matched classifier?s bid is calculated by the following formula:  (1) A X  S, x ~f x CS,,, x sp  p - s p bid =  where A is a constant, s, is the strength of the classifier, sf is the strength of the family that containing the classifier, s, is the strength of the? meta-families tha t  containing the family and sp is the specificity of the classifier.

4.2 Crossover  In mHCS, there are three kinds of crossover. The crossover operations are usually done at the fam- ily level. The  possibilities of crossing over at the classifier level and crossing over a t  the meta- family levels are smaller than crossing over at the family level.

4.2.1 crossover between classifiers  The first one is general crossover that  crossing over two classifiers selected from different fami- lies.

L 1 , 1  Figure 2: crossover between classifiers  4.2.2 crossover between families  The second one is crossing over two families se- lected from different meta-families. This kind of crossover has two situations.

situation 1. Swapping family members of the two selected families. In Figure 3, family mem- bers of the two selected families are swapped.

1 J I  Figure 3: crossover between families  situation 2. Swapping part of each family member with tha t  of the corresponding members in the other family.

Figure 4: crossover between families  Figure 4 shows an  example of the situation 2.

Consider a family as a matrix of classifiers, the  above two situations? crossover can be think as swapping rows and swapping columns of the ma- trices.

In mHCS, classifiers are tied t o  a family, and probability of crossing between families is higher than other kinds. Therefore families are become the main part of genetic operations. Classifiers that  belong to  a family are related to  each other by some relations. Then the competitions among these classifiers are restricted.

- 2536 -    4.2.3  The  third one is crossing over two meta- families(or meta-meta-families). Figure 5 shows swapping families(meta-families) of the two se- lect ed met a- families( met a-met a- families).

crossover b et ween met a- families  I I  1-1  1-1  I I  1 1 / 1 1  Figure 5 :  crossover between meta-families  Crossing over between meta-families is swap- ping families or meta-families. In other words, tha t  is swapping default hierarchies set and clas- sifier chains set. Therefore, by using this kind of crossover, mHCS can reduce the rule-set as- sociation problem. The mechanism of crossing over between meta-families can form and main- tain set of default hierarchies and set of classi- fier chains. With this mechanism, mHCS is more useful than ordinary HCS, in large solution and search spaces.

4.3 mutation In mHCS, mutation is done at the classifier level, as in traditional classifier systems. The operation changes one position on a classifier that  selected randomly.

4.4 Experiments 4.4.1 Implementation of mHCS  mHCS is implemented as follows :  B = {r i} ,  where ei (i = 1 , 2  ,..., 2?) is the binary string representation of a number be-  tween 0 and 2? - l, 1 being the  length of the strings. An environment state.

0 F = {fi}, where fi  (i = 1,2,  ..., m) is a fam- ily.

0 M F  = {mifj}, where m;f, (i = 1 , 2 ,  ... n, ?  j = 1 ,2  ,..., m?) is a meta-family. m 2 f j means a meta-meta-family, meta(2)family.

0 Category G = {O, l} .

A classifier contains two parts, the condition part and the action part. Both parts are formed from the alphabets {?0?,?1?,?#?}.

The relation over the classifiers in a family(over the families in a meta-family) is not default hi- erarchies(set) or valid chains(set). They are grouped by randomly.

The genetic operation used in this experi- ment is crossover, mutation is not used here. A matched classifier?s bid is calculated by equation  A general apportionment of credit algo- rithm(the bucket brigade algorithm) and the roulette wheel selection are used. The selection was used to select candidates for crossing over.

Families ( or classifiers in the case of crossing over at the classifier level or meta-families) with higher strength get a greater chance to  be se- lected.

(1).

4.4.2 Problems  mHCS and CS were examined by learning Boolean functions. Several Boolean functions were used in the experiments to contrast the per- formance of mHCS and the performance of CS.

The details of two examples of Boolean functions are as follows.

f1(20,21,22,23,24,25) = (20 and 2 1  and 22)0~(23 and z4 and Z ~ ) O T (21 and 22 and 24)0~(20 and z 3  and Z ~ ) O T (20 and 2 2  and 24)0~(10 and z1 and Z 4 ) O T (q and 2 2  and 2 3 ) 0 ~ ( 2 2  and 24 and Z ~ ) O T (22 and 5 3  and ~ ) o T ( z ~  and 24 and 24)o~ (20 and 2 4  and O~)OT(Z~ and 2 3  and ~ ) O T ( 2 0  and 2 1  and 25).

Figure 6: probreml  Classifier is corded as follows  - 2537 -    where: The  bit x6is output bit and is compared with the value of fl.

,  f2 ( 2 0 , 2 1 ,  2 2 , 2 3 7 2 4 7  z .5 ,26 ,  $7)  (20 and 5 1  and ~ 2 ) 0 ~ ( 2 3  and 24 and z5)or ( 2 1  and 2 2  and ~4)0~(20 and 5 3  and 25)or (20 and 2 2  and 2 4 ) 0 ~ ( 2 0  and 2 1  and z4)or E  r" (zl and 5 2  and 23)0r(22 and 24 and 25)or  o c  ( 2 2  and 2 3  and z5)0~(22 and 24 and 24)or (20 and 2 4  and ~ , ) O T ( Z O  and 23 and z4)or (20 and 2 1  and z5)andX.

Figure 7: probrem2  X is l ox  the  value of  address^, 27.

Classifier is corded as follows If 2 6  = 1,x7 = 0 then X = 2 2  x 10.

2 0 2 1 2 2 2 3 2 4 2 5 2 6 2 7  : 2 8 2 9  The bits 28x9 are output bits and is compared f 2 the  value of f 2 .

The performances of these systems are deter- mine as follows :  where C, is the number of the correct answers at iteration t ,  It is the number of the incorrect an- swers at iteration t and T is the current iteration.

4.4.3 Results and discussions  The fig.8 shows performance curves for three HCS experiments and two CS experiments for probleml. The  differences of HCS-4, HCS-8, and HCS-14 are setting of the parameters about fam- ily size and timing of GA invocation. And the difference of CS-3 and CS-0 is that  the system uses crowding method or not. From the com- parison of performance curves, mHCS shows the efficiency equal t o  or better than CS. But, the HCS curves shows a conspicuous vibration com- pared with CS curves. This feature means that the mHCS system is more sensitive than CS t o  to  propose new method to  invocate genetic algo- rithm on suitable timing.

the timing of GA invocation. Therefore, we have  5 Self GA invocation  5.1 Problems of the mHCS From the results of the above experiments, the mHCS has following merits.

f I I I  I cs-3  - tiCS.4 - - ' IKS-8'- - ' 1 kICS-14 cs-0 --  o'2 I 1 0' 1 1 I I 1 0 2000 4000 6000 0000 10000  iterdion  Figure 8: Performance curves  0 reducing the rule clustering problem  0 reducing the rule association problem  The other side, it becomes clear tha t  the  mHCS has a demerit of computational efficiency against the traditional CS. In the  mHCS, we shifted the objects of genetic operations from classifiers to families. For this extension , the  system becomes more sensitive to  execution of genetic operations before classifier evaluation value is not fixed. In mHCS, if the timing of genetic operation execu- tion is overhastily, there will be a strong proba- bility that  the system disrupts a lot of good clas- sifiers. However, it's obvious that  late execution of GA makes bad influences for computational efficiency. Then, we have to  develop the system which is able to  invocate GA on appropriate tim- ing.

5.2 Strategy of Self GA invocation In learning system like CS, genetic algorithms are used to discover new rules and genetic operations are applied to  classifiers based on its evaluation value as a fitness value. Then, for GA works ef- fectively as a rule discovering system, the evalu- ation values of each classifiers should be decided correctly. However, traditional CS adopts peri- odical GA invocation strategy, therefore useless crossover operator will be carried out so often.

So we propose new strategy about the timing of GA invocation.

In the classifier system, if evaluation value of  - 2538    l I  I I I I 1  _ _ _ _ _ . . - . - . _ . . _ _ - _ _ _ _ -.-.-e- - - - - e - .- - - _ _ _ c _ _ _ - - - - - -  - - - -- -- - - - - --  si-1 - SI-2 - - ' S I 4  - -  cs-3 -- -  each classifiers are decided by system, the sys- tem performance becomes saturation. Using this property, we propose a GA invocation rule as lows;  t--m t  i f (  P(E) Y P(I) )  fhen (GAinuocotion)  Where: P(k) : system performance on timing k t : current iteration number m : constant.

fol-  (3)  This production rule shows that  if there is no improvement about the system performance dur- ing m-th iteration, then the system invocates GA.

Using this strategy, the timing of GA invoca- tion is just after the decision of the evaluation values for each classifiers. Accordingly, it  is ex- pected tha t  (1) reducing the invalid crossover operations,  (2) reducing the unnecessary evaluation of clas- sifiers.

For this reasons, it is possible to  improve the effi- ciency of mHCS. Next section, we show the effec- tivity of this strategy through the computational experiments.

5.3 Experiments We tested the effects of the self-GA invocation method using previous problems.

This figure shows three performance curves of self-GA invocation method and one performance curve of CS. The difference of SI1, SI2 and SI3 is the frequency of GA invocation. This result shows that  the efficiency of self-GA invocation method equal to  or better than normal CS. From this results, the system becomes more effective and robust about control of GA. We are able to summarize the characteristics of mHCS with self- GA invocation as follows,  (1) The system is able t o  control useless GA in- cocation when the evaluation values of clas- sifiers are not determined.

(2) The system is able to  increase the number of invocation times when the evaluation values of populations are saturated.

In addition, we are able to  reduce the labor of determine the parameter about GA invocation.

0.0  0.6  0.4  0.2  0' I 1 I I I 0 2000 4000 6000 8000 10000  iteralion  Figure 9: Performance curves of self-GA invoca- tion  6 Conclusion In classifier system techniques, an effective mech- anism for fording and maintaining rule-set asso- ciation is proposed. And the improvement of ef- ficiency are discussed. The experiments showed effectiveness of mHCS and self-GA invocation method.

