Mining Fuzzy Association Rules in Incomplete Databases

Abstract - Mining quantitative association rules is a particular subject of interest in fuzzy set application theory.

However, the theory generally applies to a transactional database with no missing values. A predictive algorithm is proposed in this paper in order to extrapolate (interpolate) the unknown values. A fuzzy data mining algorithm is used to discover fuzzy association rules over the extended database with filled predictive values.



I. INTRODUCTION  Finding association rules in very large database systems is an important data mining task. The usual model for developing algorithms to discover association rules is the basket market. The algorithms developed for these transactional databases usually do not deal with missing values.

The major scope of discovering association rules in databases is to find some hidden, possibly useful information from the databases. A common approach is to search for association rules in large amounts of data collected in a supermarket basket database. The problem of mining association rules was first introduced by Agrawal [I].

support and confidence. An association rule bread + bufter (sup = IO% and conf = 20%) means that 20% of transactions contain both bread and buffer and 10% percent of transactions that contains bread contains buffer also. The mining association rules problem can be defined as finding all the rules with a minimum support and a minimum confidence defined by the user.

Some approaches append additional evaluation measures (weights for importance of the rule, taxonomies for hierarchical levels, etc.) in order to improve the quality of the algorithms for searching rules according to enriched criteria.

The main assumption in these algorithms is that we have no missing value (null values). Therefore, we do not deal with it.

However, in real databases, it is common to have missing values, and in some situations this fact is oAen inevitable due to disjunctive information, partial knowledge, accidentally damage of some records, or outer-join operations in relational databases (extension ofjoin operation in order to deal with missing values).

Several solutions to deal with missing values has been proposed ([3]-[5], [IS]-191, [23]). The simplest solution is to eliminate the records that have unknown (null) value or to  Two measures are used in evaluation of a rule X+Y:  replace them with one value predicted fiom current knowledge extracted from the database.

The probability distribution of the unknown values are deduced from known values using Bayesian networks [ 1 I].

The closest value can be chosen or one possible value is chosen from division of the examples in fractions.

A probabilistic approach based on attribute distribution is described in [13]. The results are compared with three other approaches to incompleteness: the missing values are ignored, only certain information available for missing values, and no missing values exist (complete database).

queries over incomplete databases is proposed in [9]. Many valued logic for improving the results is used (3-valued  Solutions to the problem of generating decision tree  Different kinds of answers representing sure information in  logic).

(decision rules) using a training set with unknown values was proposed in [14]. The value of an attribute is suggested to be predicted from the values of other attributed and the class information.

The solution to induce rules fiom available data and using them to fill the missing values is a good option taken into account by some papers. Based on this idea and using as start point the Apriori algorithm [8], an improve6 suhtion is proposed in [8]. The algorithm uses fewer and more relevant rules according to the criteria of usefulness in prediction of missing values, and not in actual prediction [8]. This solution reduces the large of rules due to missing values considerable.

An approach where the missing values are estimated is presented in [ 121. A decision tree for filling missing attributes is build based on examples with known attributes. The order that is followed in construction and filling the tree is based on the mutual information concept from information theory.

Experiments on tree repositories with missing attributes (Soybean, BreastCWand Mushrooms) are presented [12].

simplest methods used in machine learning algorithms, is proposed in [17]. The basic idea is to split the database in several databases that have only valid values (without missing values). New definition of support and confidence are given in order to deal with missing values. The algorithms used in [2] were modified in order to compute efficient association rules for incomplete databases.

In [12], the author analyzes the properties of databases with missing values. A pessimistic and optimistic estimation both of support and confidence rules are proposed.

Another treatment of the missing values, based on of the  0-7803-7280-8/02/$10.00 02,2002 IEEE 261    Definitions of expected values of support and confidence based on the records with no missing values is given. Some properties of itemsets and association rules are guaranteed by this approach.

Other approaches, using rough sets are proposed in [ 151, [16], and [17]. Two algorithms in the frame of rough sets, IAprioriCertain and IAprioriPossible are proposed in [ 151.

The algorithms use the specification given for pessimistic support and confidence threshold. By this approach, the authors showed that hypothetical rules applied to an incomplete system can resolve or decrease the uncertainty grade of a rule deduced from the system.

In this paper, we present an algorithm for mining association rules in the frame of fuzzy sets. Our work is close to the work presented in [15] and [16]. However, our proposal is based on fuzzy set theory and not rough set theory. Both fuzzy sets and rough sets model different types of uncertainty [IO]. The concept of approximation given by the equivalence relation R and the approximation space in rough set cannot be replaced by a similar membership function in the sense of fuzzy sets [21]. This means that a simple translation of results from rough sets to fuzzy sets is difficult to do or maybe not realistic to do. Therefore, our work concentrates on the use of fuzzy sets in discovering the association rules from incomplete databases with quantitative attributes.

The rest of the paper is organized as follow. In the next section, the problem of incomplete databases is introduced. In the third section, we present association rules from a fuzzy set perspective. The algorithm used to find association rules in databases with missing values is presented in the next section. Experimental results are described in section five followed by our conclusions.

11. INCOMPLETE DATABASES  There are many proposals to deal with incomplete information or incomplete databases. In the data mining research area, an important problem is the discovery of association rules. Many papers treat this problem in binary, quantitative [ZO], qualitative databases using crisp, fuzzy, or rough techniques.

Missing values in databases are sometimes inevitable and the discovering of association rules with missing attributes is a real necessity.

When the missing values are categorical (e.g., size of one product: small, medium, large, very large) and the solution to deal with missing attributes is predictive, a cnmmon approach is to consider all the possibilities equal (or weighted) probable in the association rule algorithm.

The decision table (DT), can be expanded in different ways, but the main idea is to have for each record (transaction) a number of transactions equal with the number of all possible combinations from domain of attributes for the missing values and the rest of attributes remaining unchanged.

When the attributes are quantitative and the domain of values for the missing value is known to be continuous (a sub-domain of real numbers %={--,+}), the above approach is ineffective and cannot be applies due to non- numerable property of an real interval numbers.

For example in Table 1, the above approach means that for the missing attribute ATRI in transaction 6,  we will count all the four possible attributes as equal probable (or weighted if some additional knowledge about distribution of attributes are available) in the association rule algorithm.

TABLE 1 A DECISlON TABLE WITH MISSlNG ATTRIBUTE  VALUES  T ATRI ATRZ ATR3 ATR4 C 1 small yes 8.5 A 1 2 small no 3.5 A 1 3 large yes 3.9 A 0 4 medium no 6.5 B 1 5 large yes 7.2 A 1 6 .  no 2.2 ?3 0 7 small no A 0 8 verylarge . 3.4 C I  However, we cannot apply the same method if we take into account the attribute ATR3 in transaction 7. Due to the (uncountable) property of an interval of real numbers, we cannot take into account a finite reasonable number of possible values without additional considerations.

A predictive metbcd seem to be a reasonable way to deal with continuous missing attribute values, but some additional restriction can restrict this approach.

We propose a predictive method in order to try to fill the missing values, where it is possible, using a predictive method based on neighborhoods. The main idea is to use close transactional neighborhoods in order to predict probable values for missing values. However, if the number of missing values is too great, the method is ineffective, because we cannot produce knowledge from nothing.

We will use a common notation in the remainder of the paper. We denote the information table (IT) the subset of the table that have no missing values and we denote by (If) the full information table with missing values.

In order to find association rules we will deal with a sure support (sSup) and sure confidence ( C o n / )  based on IT, and a possible predicted support @pSup) and confidence @pConA based of an subset of IT (possible full IT ). The subset of IT' is constructed by filling the missing values with predicted possible values in a step before the algorithm of finding rules.

The above measures are defined in a classic manner (we denoted by A' the extended values of attribute with predicted values):  sSup = sup( A n B ) sConf =sSup(An B) / sSup(A)  0-7803-7280-8/02/s10.00 02002 IEEE 268    ppsup = S U ~ ( A *  n B? )  ppconf = p p ~ u p ( ~ ?  n B* ) / p p ~ u p (  A? )  Attrl?.? A m 3 ? ~ o S A m 9 0 - 3  3 A m 1 5  The number of attributes in the lefl part of implication can be increased if the thresholds for attributes are large.

In the relation above, the However, a too large value (close to 1.0) could conduct to supposed to be taken into account: A + B consider almost all the transaction and almost all the  The predictive step is described below (even sophisticated attributes in the database in the predictor pattern class that is extensions are possible). A transaction and its attributes are represented as: An autoregressive model is used in order to predict the  possible value for the missing value in transaction. The simple and classic M A  model is used.

If we want to use the cateeorical values or b i n m  values in  of a rule  ?* = (Tidi,(at3vi~ ).(a2,vi2),.. .(a,*). . .(a,,,,vi,,, I  corresponding value vil in a table with m attributes an n transactions. The item Tidi is optional and is used only for identification of transaction.

We will use the neighborhood term for prediction. First, we select the transaction with missing values. The common notation used for missing value is (or ???). We consider the case of continuous quantitative missing attribute value.

Our scope is to find a finite set of possible values for this missing value using the other attributes that are known and the subset of pattern transactions that are close enough to the current transaction with missing values. A closeness function for a known attribute aj, is given by:  Dj  - d j  r .  =- D j  J  d ,  = Min / V i j - V k j / k f i k=l ... n  D .  = M a / v - - - v b /  r /  ? k f i k=l,..n  Based on threshold B j  fixed for each attribute, we start the search for predictive patterns in the rest of the transaction.

For each transaction, a predictive neighborhood pattern PNP, is selected.. The PNPj has two parts: the attribute values that are enough close to the transaction with missing values selected and the target (value to be predicted) value of the attribute on the same column as the missing value.

where q Sm-1 and rk, < 0,  Therefore, a predictive pattern can have the form (the implication sense is used not in the same meaning as in data mining hut only to show the target to be predicted, Attrl5, that is 4):  ? . .

For categorical values (small, medium, high, very high), we can associate consecutive numbers to sorted values and assign to each one the value i/im value where i is the index position and i,, is the maximum value of the sorted values.

111. ASSOCIATION RULES AND FUZZY SETS  The algorithm to find fuzzy association rules include basically the main steps:  1. fuzzy partitioning 2.

3.

4.

Our first approach takes into account the equal partitions and triangular fuzzy numbers as membership function. Due to hard predictable distribution of the continuous values in a real database, this method is not suitable.

In the following, we will use the notation used in [6], [7], and [22], and we will consider only convex membership function.

The fuzzy association rules found are typically illustrated in categorical measures:  prediction of missing values where this is possible an extended database is created using the old database and the predicted values discovery of fuzzy rules from extended database  ?lfengine-size is High and horsepower is Medium then the price is High?.

The database is fuzzified using a manual partition of the triangular fuzzy membership function. An automatic procedure to find out medoids and optimal number of membership functions as in [7] was used also in our experiments. A trapezoidal membership function could also be used, but in this case it is possible to have the value ?1? of the membership function corresponding to more values of arguments.

The main steps of the finding association rules are the steps used in [7] .  The only change is that we used a normalized value of the a-cuts, as follow:  0-7803-7280-8/02/$10.00 02,2002 IEEE 269    n count, = Z g ( x i ) / n n  i=l  where nn is the number of not-null values for a specified attribute in the fuzzy data transformed table.



IV. THE ALGORITHM  The algorithm is summarized below. By using the normalization for fuzzy rules also support and confidence is between [0,1].

Step 1. Find all the sure rules using the information table.

The missing values are simply ignored  Step 2. Transform the information table into an extended version taking into account the missing values using a predictive algorithm.

Step 3. The same algorithm is applied to find association rules.

Step 4 I f  the thresholds for  attributes are below a maximal values and no new rule are found, increase incremental the thresholds andgo to step 2  Step 5. I f a  stop condition is reached, the sure rules are discovered in step I ,  and the possible rules are discovered in steps 2-4.



V. EXPERIMENTAL RESULTS  The experimental results refers to the 1985 Auto Import Database [25]. The database has 26 total attributes, 15 continuous, 1 integer and 10 nominal.

The second attribute, "normalized-losses" has continuous values fiom 65 Io 256, with 41 instances missing a value. The "nun-of-doors" is considered as a type of binary attribute (similar to yesho). The number of missing value is = 1.1%.

We partitioned the second attribute in 15 triangular symmetric membership function. For a support of 0.12 and confidence of 0.15 and an adequate increase incrementally of the thresholds, we obtained an additional numher of 11 rules if the thresholds reach the maximum value 10% from the domain of definition.

If this result seem to be not significant, it is possible that some important rules to he not missing (as in neglecting of missing values) hy using this approach. Some limitations of the proposed approach are evidently. If a transaction has too many missing values (for almost all the attributed), the utility of the method decreases dramatically. We cannot predict useful information if we have no minimal information.

attributes, for all the transactions, the result of the method will he that some values are predicted but the rules discovered by this method are too few and not corresponding to reality, because the knowledge was acquired by a very large ignorance.

Also, if the missing values tend to cover a large number of  Figure 1 .  Numberofmles.

We can see from the figure that the algorithm give at least the same number of rules as the original database. The simple median predictor can give in some distribution of the attributes a lower numher of rules depending on how good an approximation can he considered for the mean value as representative for the vector attribute.

A problem could arise in cases where we use a predictor related to dimension of the attribute vector (the rows in the database). If the number of attributes are relatively small (order of tens) the predictors like IBL, our predictor, neural networks, etc. can be considered as a satisfactory solution.

However, if the number of attributes is relatively high (hundreds of attributes), it is hard to build an interpolator vectors of 800 elements for example using a neural network.

A hierarchical solution was chosen as the simplest possible solution (even though this is not optimal) in order to deal with it even some experiment using PCA (principal component analysis) are in progress.

A small improvement was taken into account in order to store the fuzzy set transformed. In the Table 2 fiom [6] after the first intermediary step, taking into account only 10 cases, 5 attributes and a partition of 3 membership functions on each attributes we have a total of 150 values from where 83 values are zero (=55,5%). Therefore, it will be useful to store these results in a tree where each node stores attribute index and each leaf has 3 values (transaction id, nonzero value scalar cardinality). Even though it seem to be a sensible improvement (based on percent of values reduced that we can combine), practical implementation showed that the speed of the complete implementation increase only with 2.91% for a synthetic database with lOOk and 100 attributes uniform distributed over the entire database.



VI. CONCLUSIONS  A predictive method for dealing with missing continuous attribute values is proposed in this paper. The results are encouraging, but some results showed that the computational effort could be large in order to discover only a few additional rules in comparison by the solution of ignoring the missing values.

0-7803-7280-8/02/$10.00 02002 IEEE 270    Preliminary results on tests using a real database are presented. The method is clearly depending on the distribution of missing values in the databases according to transactions and attributes structure.

A few possible directions of investigation can be suggested. The improvement of predictive tool could be one.

If the number of input in the ARMA model is large (like in a base with 500 attributes for example), simpler methods are necessary. A better solution to select the neighborhoods of pattern can be developed. Some extension to multivariate times series could also be a possibility for future development.

