The Analysis on Apriori Algorithm Based on Interest  Measure

Abstract?This paper proposes an improved algorithm to overtime the abuses that the Apriori algorithm has. The algorithm improves the readability of the strong association rules by increasing interest items and constructing the model of the interest.The experimental results show that the algorithm can effectively increase the operation speed , reduce the set of candidates, enhance the efficiency of the algorithm.

Keywords- Data Minin; Aprior algorithm;Interest measur

I.  INTRODUCTION The data mining helps to excavate the interesting unknown  valuable information and knowledge from a huge number of original data in the large data base(LDB), it is also known as knowledge discovery( KDD )[1]. At present, the data mining is thought to be a kind of effective method to solve the problem of ?data explosion? and ?rich data and poor information ?, and to be one of the  hot pots in information technology. Then the Apriori algorithm is employed to find association rules in data warehouse.The association rules can reflect the complex and interesting connections among the data in the database, dig out useful rules, and provide a great help to improve the real work. In this paper, the classical mining algorithm for association rules -Apriori algorithm is analyzed, and an improved algorithm to overtime the abuses that the Apriori algorithm has is proposed.



II. General Overviews Of Association Rules The mail purpose of association rules is to find the relatio-  nships whether there are between the items  in the large dat- abase(LDB). Here we set that  I={i1,i2,?,im} is  M different items  collection  and  i1,i2,?,im I, D is a a collection of database transactions related to task, the association rules is expressed  as  X=>Y  in  which X,Y ? I , X?Y=?[2].

The rule (X=>Y) holds in the transaction of  set D with support,where support is the percentage of transaction in D that contains X Y .This is taken to be support(X=>Y), which is defined as  follows:  ( )YXport ?sup = )()(sup XYPYXport =?  1  The rule (X=>Y) has confidence  in the transaction of  set D .And confidence is the percentage of transaction in D  containing X that also contains Y .This is taken to be confidence(X=>Y), which is defined as  follows:  ( ) ( )( ) ( )XYPXport YXportYXconfidence =?=?  sup sup      2  The minimum support threshold(min_sup) and the minimum confidence threshold(min_conf) are used to determine weather the association  rules is  interesting.If support(X=>Y) ? min_ sup and confidence(X=>Y) ? min_ conf, then the it  is   a  strong association rule , otherwise it is a weak association  rule[3].



III. APRIORI ALGORITHM The most famous and most influential algorithm for mining  association rules is proposed by R.Agrawal in 1994[4]. It is named Apriori algorithm.To find associati-on rules,the algor- ithm divided into two steps.

The first step is to identify all the frequent itemsets, each of these itemsets will occur at least as frequently as a predete- rmined min_sup.

Secondly, the strong assocition rules is generated from frequent itemsets.  if the confidence of  the frequnet itemsets is not less than the min_conf given by the user .

A. Steps Of Apriori Algorithm The main steps of the Apriori algorithm are listed as  follows[5,6]  Step 1. Scan the database, generating candidate 1- set C1  Step 2. According to the min_sup, frequent item 1- set  L1 is generated from the candidate 1- set  C1  Step 3. If k>1, then repeat steps 4,5,6;  Step 4.Operating link and pruning by Lk ,and candidate (k+1)- set Ck+1 is generated  Step 5. According to the min_sup, frequent item (k+1)- set Lk+1 is generated from the candidate (k+1)- set  CK+1;  Step 6. If L  then k=k+1,go to step 4; otherwise go to setp 7;   DOI 10.1109/ICCECT.2012.185    DOI 10.1109/ICCECT.2012.185         Step 7. According to the min_conf, the strong association rules is discovered from frequent itemsets.

B. Apriori algorithm Description The descriptions of the Apriori algorithm is listed as follows :  Input database D,min_sup.

Output:  frequent itemsets L.

L1=find_frequent_1-itemsets(D); For(k=2;Lk-1??;k++){  Ck=apriori_gen(Lk-1,min_ sup); For each transaction  t?D    do {//scan D for counts  Ct=subset(Ck,t);          //get the subsets of these candidates  For each candidates  c? Ct c.count++;  } Lk={c?Ck|c.count?min_ sup}  } Return   L=?kLk  The process of apriori_gen is to generate Ck by linking Lk-1, the apriori_gen is described as follows Procedure apriori_gen(Lk-1,min_sup)  //Lk-1:frequent(k-1)-itemsets;min_sup:minimum support threshold  For each itemset  l1?Lk-1 For   each  itemset l2?Lk-1  If (l l1[1]=l2[1] )?(l1[2]=l2[2])???(l1[k-2]=l2[k-2])?(l1[k- 1]<l2[k-1])  Then{ c=l1?l2  if has_infrequent_subset c,Lk-1 then         delete c;  else add c to Ck; end  end }  C. Algorithm Analysis The Apriori algorithm has been proved to be an effective  algorithm for mining association rules in the large data base .But in the practical application,the apriori algorithm has some abuses[7].

One of its key problem is that vast rules will be produced in the mining process. For example:  Rule ?bread?=>{?milk?, ?coffee?}[confidence=78%]  According to the Apriori algorithm , four rules are generated as follows:  rule ?bread?=>?milk? [confidence =83%];  rule ?bread? => ?coffee? [confidence =88%];  rule {?bread?,?milk?}=>?coffee? [confidence =84%];  rule {?bread? , ?coffee?}=>?milk? [confidence =90%];  So the vast unrelated middle itemsets and  many scans of the database , give a large load of  system ?s I/O.

The association rules  generated  by  support and confidence may not be interesting for users and  even to  be an error rule.This is another disadvantage of Apriori algorithm  in the practical application. For example, in the database of the level of college public computer,25% of students have computers,90% of students gain outstanding achievement,20% of students who have computer and gain outstanding achievement.Set min_sup=0.2,min_conf=0.6, In accordance with the Apriori algorithm ,the association rules will be generated as follows:  ?have computer?=>?outstanding chievement? [support=0.2,  confidence=0.8]  The rule shows that 80% of students will gain outstanding achievement if they have computer.But it is originaly provied that 90% of students gain outstanding achievement.Then this rule is of no value.

These problems of Apriori algorithm limited their improvement to the efficiency of strong association rules discovery research.In this paper,we introduced the third thresholds to optimize the Apriori algorithm, that is interest measure.

D. Apriori Algorithm Based On Interest Measure The interest measure is defined which is based on support  and confidence of association rules,it is updated as follows[8]:  )}(sup),(max{ )(sup)()( YXportYXconfidence  YXportYXconfidenceYXI ?? ???=?        (3)  According to this definition, if |I(interest measure )|? min_interest(minimum threshold of interest measure),then the rule is an interesting association rule,ot-herwise, the rule is of no value.

It  is described as follows  for each X=>Y  supp=support (X=>Y)  conf=confidence(X=>Y);  if supp>=min_sup  and conf>= min_conf  then   i=i(X=>Y)  if |i| < min_interest  then delete  X=>Y  else  returen  X=>Y  end  else  delete X=>Y;  end

IV. EXPERIMENTAL STUDIES In this paper, to test the the significance of interest measure  added to Apriori algorithm,we provide a specific example.We         select a part of the items in the database on psychological evaluation of students from some school ,then the results are proved as table1:  TABLE I.    STATISTICS OF RULE NUMBER WITH DIFFERENT THRESHOLD  min_sup min_conf rule number  no interest easure  rule number min_interest  =1.1  rule number min_interest  =1.2 0.1 0.2 576 235 113 0.1 0.5 345 136 74 0.3 0.2 217 86 54 0.3 0.5 134 65 36 0.5 0.5 85 43 28  According to the data in Table 1, It can show that the rule number with interest measue is a sharp contrast to  the rule number without interest measue ,and it also shows  the contrast in different interest measue threshold.

Figure 1.  Figure1 Contrast in the rule number with different threshold  As we can see from Fig 1,the association rules number is sharply reduced by adding interest measue,and many errors or useless rules are eliminated with the increasing threshold  of interest measue.So the Optimization algorithm improves the validity of data mining.



V. CONCLUSION Among the mang mining algorithm of assocition rules,  Apriori algorithm is an classical algorithm that has caused the  most discussion.It can effectively carry out the mining association rules.However,the Apriori algorithm has some abuses,such as too  many scans of the database ,large load of system ?s I/O and vast unrelated middle itemsets. This paper proposes an improved Apriori algorithm to overtime the abuses. The improved algorithm reduces the set of candidates and accelerates the speed of the algorithm by adding the interest items. The algorithm improves the readability of the strong association by constructing the model of the interest measure. Breaking the traditional steps of algorithm to reduce the database scans and bring down the load of system' s I/O.

Experimental results show algorithm can improve the speed and efficiency of operation effectively.

