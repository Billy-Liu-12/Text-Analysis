Hybrid Association-classification algorithm for

ABSTRACT?Knowledge extraction is a process of filtering some informative knowledge from the database so that it can  be used wide variety of applications and analysis. Due to this  highly efficient algorithm is required for data mining and for  accessing data from large datasets. Although there are various  techniques implemented for the detection of anomalies using  frequent item sets using apriori algorithm but the technique  applied are not suitable for large database and contains more  error rate and also the classification ratio is less. Hence in this  paper an efficient technique is implemented using the  combinatorial method of Classification and association rule  mining. First the fuzzy apriori algorithm is applied to  generate frequent item sets and then CART algorithm is  applied for the classification of the network anomalies.

Keywords?support count, confidence, Association rules, Leverage, Genetic algorithm.



I. INTRODUCTION   Data mining can be achieved by Association, Classification,  Clustering, Predictions, Sequential Patterns, and Similar  Time Sequences. In Association, the relationship of a  particular item in a data transaction on other items in the  same transaction is used to predict patterns. In Classification,  the methods are intended for learning different functions that  map each item of the selected data into one of a predefined  set of classes. Given the set of predefined classes, a number  of attributes, and a ?learning (or training) set,? the  classification methods can automatically predict the class of  other unclassified data of the learning set. Cluster analysis  takes ungrouped data and uses automatic techniques to put  this data into groups. Clustering is unsupervised, and does not  require a learning set. It shares a common methodological  ground with Classification [1]. Prediction analysis is related  to regression techniques. The key idea of prediction analysis  is to discover the relationship between the dependent and  independent variables, the relationship between the  independent variables. Sequential Pattern analysis seeks to  find similar patterns in data transaction over a business  period. Existing algorithms for mining association rules are  mainly worked on a binary database, termed as market basket  database. On preparing the market basket database, every  record of the original database is represented as a binary  record where the fields are defined by a unique value of each  attribute in the original database. The fields of this binary  database are often termed as an item. For a database having a  huge number of attributes and each attribute containing a lot  of distinct values, the total number of items will be huge.

Storing of this binary database, to be used by the rule mining  algorithms, is one of the limitations of the existing  algorithms. Another aspect of these algorithms is that they  work in two phases. The first phase is for frequent item-set  generation. Frequent item-sets are detected from all-possible  item-sets by using a measure called support count (SUP) and  a user defined parameter called minimum support. Support  count of an item set is defined by the number of records in  the database that contains all the items of that set. If the value  of minimum support is too high, number of frequent item sets  generated will be less, and thereby resulting in generation of  few rules. Again, if the value is too small, then almost all  possible item sets will become frequent and thus a huge  number of rules may be generated. Selecting better rules from  them may be another problem. After detecting the frequent  item-sets in the first phase, the second phase generates the  rules using another user defined parameter called minimum  confidence [2] and [3-5].



II. RELATED WORK   Association Rules  Association rules are if and then statements that help uncover  relationships between seemingly unrelated data in a relational  database or other information repository. An association rule  has two parts, an antecedent (if) and a consequent (then).

Association rule is expressed as X=>Y, where X is the  antecedent and Y is the consequent. Each association rule has  two quality measurements, support and confidence. Support  implies frequency of occurring patterns, and confidence  means the strength of implication [1-3] and [9]. Associations:  itemsets and sets of rule the result of mining transaction data  in a rule are associations. Conceptually, associations are sets  of objects describing the relationship between some items  (e.g., as an itemset or a rule) which have assigned values for  different measures of quality. Such measures can be measures  of significance (e.g., support), or measures of interestingness  IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India    (e.g., confidence, lift), or other measures (e.g., revenue  covered by the association). All types of association have a  common functionality in a rule comprising the following  methods:  ? Summary to give a short overview of the set and inspect to  display individual associations,  ? Length () for getting the number of elements in the set,  ? Items for getting for each association a set of items involved  in the association (e.g., the union of the items in the LHS and  the RHS for each rule),  ? sorting the set using the values of different quality measures  (sort),  ? Subset extraction,  ? Set operations (union, intersect and set equal), and  ? Matching elements from two sets (match),  ? Write for writing associations to disk in human readable  form. To save and load associations in compact form, use  save and load from the base package.

The associations currently implemented in package a rules  are sets of itemsets (e.g., used for frequent itemsets of their  closed or maximal subset) and sets of rules (e.g., association  rules). Both classes, itemsets and rules, directly extend the  virtual class associations and provide the functionality  described. Class itemsets contains one item Matrix object to  store the items as a binary matrix where each row in the  matrix represents an itemset. In addition, it may contain  transaction ID lists as an object of class tidLists. Note that  when representing transactions, tidLists store for each item a  transaction list, but here store for each itemset a list of  transaction IDs in which the itemset appears. Such lists are  currently only returned by ?clat [4-6]. Class rules consists of  two itemMatrix objects representing the left-hand-side (LHS)  and the right hand- side (RHS) of the rules, respectively. The  items in the associations and the quality measures can be  accessed and manipulated in a safe way using accessor and  replace methods for items, lhs, rhs, and quality. In addition  the association classes have builtin validity checking which  ensures that all elements have compatible dimensions. It is  simple to add new quality measures to existing associations.

Since the quality slot holds a data frame, additional columns  with new quality measures can be added. These new  measures can then be used to sort or select associations using  sort () or subset (). Adding a new type of associations to a  rule is straightforward as well [6-8].

Rules interestingness measures  The aim of the association rules is to reveal interesting  relations between data. For that reason certain are used which  evaluate the level of importance of each rule. These are:  Confidence: The confidence of an association rule is the  proportion of the isolates that are covered by the LHS of the  rule that are also covered by the RHS. Values of confidence  near value 1 are expected for an important association rule.

Support: The support of an association rule is the proportion  of the isolates covered by LHS and RHS among the total  number of isolates. Support can be considered as an  indication of how often a rule occurs in a data set and as a  consequence how significant a rule is.

Coverage: The coverage of an association rule is the  proportion of isolates in the data that have the attribute values  or items specified on the LHS of the rule. Values of coverage  near value 1 are expected for an important association rule.

Leverage: The leverage of an association rule is the  proportion of additional isolates covered by both the LHS and  RHS above those expected if the LHS and RHS were  independent of each other. Leverage takes values inside [-1,  1]. Values equal or under value 0, indicate a strong  independence between LHS and RHS. On the other hand  values near 1 are expected for an important association rule.

Lift: The lift of an association rule is the confidence divided  by the proportion of all isolates that are covered by the RHS.

This is a measure of the importance of the association that is  independent of coverage [7] and [9-10].

Ignasi Paredes-Oliva, proposed an efficient technique of  classifying frequent patterns on the basis of traffic patterns  [16], here in this paper based on elegant combination of  frequent item-set mining with decision tree learning.

Farah Hanna AL-Zawaidah and Yosef Hasan Jbara and  Marwan AL-Abed Abu-Zanona et. al. presented a novel  association rule mining approach that can efficiently discover  the association rules in large databases. The proposed  approach is derived from the conventional Apriori approach  with features added to improve data mining performance.

They had performed extensive experiments and compared the  performance of the algorithm with existing algorithms found  in the literature. They developed a visualization module to  provide users the useful information regarding the database to  be mined and to help the user manage and understand the  association rules. Future work includes:  1) Applying the proposed algorithm to more extensive  empirical evaluation;  2)  Applying the developed approach  to real data like retail sales transaction and medical  transactions to confirm the experimental results in the real  life domain; 3) Mining multidimensional association rules  from relational databases and data warehouses (these rules  involve more than one dimension or predicate, e.g. rules  relating what a customer shopper buy as well as shopper?s  occupation); 4) Mining multilevel association rules from  transaction databases [1].

Anandhavalli M, Suraj Kumar Sudhanshu, Ayush Kumar and  Ghose M.K et. al. is to find all the possible optimized rules  from given data set using genetic algorithm. The rule  generated by association rule mining algorithms like priori,  partition, pincer search, incremental, border algorithm etc,  does not consider negation occurrence of the attribute in them  and also these rules have only one attribute in the consequent  part. By using Genetic Algorithm (GAs) the system can  predict the rules which contain negative attributes in the  generated rules along with more than one attribute in  consequent part. The major advantage of using GAs in the  discovery of prediction rules is that they perform global  search and its com lexity is less compared to other algorithms  IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India    as the genetic algorithm is based on the greedy approach.

They have dealt with a challenging association rule mining  problem of finding optimized association rules. The frequent  itemsets are generated using the Apriori association rule  mining algorithm. The genetic algorithm has been applied on  the generated frequent itemsets to generate the rules  containing positive attributes, the negation of the attributes  with the consequent part consists of single attribute and more  than one attribute. The results reported in this paper are very  promising since the discovered rules are of optimized rules  [3].

Peter P. Wakabi Waiswa and Dr. Venansius Baryamureeba  et. al. present a Pareto based multi objective evolutionary  algorithm rule mining method based on genetic algorithms.

They used confidence, comprehensibility, interestingness,  and surprise as objectives of the association rule mining  problem. Specific mechanisms for mutations and crossover  operators together with elitism have been designed to extract  interesting rules from a transaction database. Empirical  results of experiments carried out indicate high predictive  accuracy of the rules generated.

In this paper deal with the ARM problem as a multi objective  problem rather than as a single one and try to solve it using  multi-objective evolutionary algorithms with emphasis on  genetic algorithms (GA). The main motivation for using GAs  is that they perform a global search and cope better with  attribute interaction than the greedy rule induction algorithms  often used in data mining tasks. Multi-objective optimization  with evolutionary algorithms is well discussed. The proposed  algorithm was tested on a dataset drawn from the UCI  repository of machine learning databases. For brevity, the  data used is of a categorical nature. In this paper they had  dealt with a challenging NP-Hard association rule mining  problem of finding interesting association rules [5].

Xin Li et al [11] proposed Frequent Itemsets Mining in  Network Traffic Data. They think about the problem of  frequent itemset mining problem in network traffic data, and  propose an algorithm for mining frequent itemsets. They try  to minimize the size of results and only maximal frequent  itemsets are considered. To protect the privacy, intermediate  mining results are encrypted using hashing method by  different servers. The proposed algorithm is evaluated from  the perspectives of accuracy and efficiency.

Mining of frequent itemsets using Genetic algorithm was  proposed in [12]. This work carried out with logic of GA to  improve the scenario of frequents itemsets data mining using  association rule mining. The main benefit of using GA in  frequent itemsets mining is to perform global search with less  time complexity. This scheme gives better results in huge or  larger data set. It is also simple and efficient.

Another frequent itemsets mining approach based on genetic  algorithm for non binary dataset was proposed by G. Vjiay  Bhaskar et al [13]. They present an efficient algorithm for  generating significant association rules among database items.

GA is used to improve the scenario and system can predict  about negative attributes in generated rules.  As per results  obtained this scheme is simple and efficient one. The Time  complexity of the algorithm is also less and suitable for non  binary data sets.

In continuation with this R. Vijaya Prakash et al [14]  proposed similar method mining frequent itemsets for large  data set using Genetic Algorithm. They implement frequent  itemsets mining for numeric attributes also. Association rule  mining is used to find relationship among attributes of  database. This process was much time consuming and applied  on discrete attributes. GA gives the facility of global search  and minimum complexity. This algorithm avoids the  necessity of discretizing apriori in attribute domain. They  used an evolving algorithm to find the most appropriate  amplitude of the intervals that be conventional a k-itemset, so  that they have an elevated support value without being the  intervals too extensive.

Sanat Jain and Swati Kabra [15] proposed Mining &  Optimization of Association Rules Using Effective  Algorithm. In this they work on association rules  organization and frequent itemsets generation using positive  and negative association rule mining. They proposed an  apriori based algorithm to find valid positive and negative  association rule in confidence framework or structure. As per  result this algorithm is efficiently works for mining of  positive and negative association rules in database and also  optimize positive and negative association rule using genetic  algorithm. This approach also reduces the search space and  improved usability of mining rules that uses correlated  coefficient to judge which association rule is used to mine.



III. PROPOSED METHODOLOGY  The work that we are implemented here is a combinatorial  method of generating association rules using fuzzy apriori  and Classification algorithm. Here the network Data set is  passed to the fuzzy apriori algorithm and then the result of  the frequent sets is passed to the CART algorithm to generate  fewer rules and classify the network anomalies in a better  way.

ALGORITHM USED  ? Count supports of each individual item.

? Create a set F with all individual items with min  support  ? Creates "Candidate Set" C [k] based on F [k-1].

? Check each element c in C [k] to see if it meets min  support  ? Return set of all frequent item sets and initialize the genetic parameters and fitness value.

? Create two sets differing only in the last element, based on some seed set  ? Join those item sets into c and generate crossover of each individual set.

? Compare each subset s of c to F [k-1], If s is not in F [k-1] or it?s value is less than fitness value, delete it.

IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India    ? Return final candidate set ? Take Frequent Item Set F ? If {F[1], F[2],...F[k-1]} => {F[k]}meets some min  confidence, make it a rule.

? Remove last element from antecedent, insert into consequent, and check again with child created  using genetic algorithm.

Though the fuzzy Apriori principle allows us to considerably  reduce the search space, the technique still requires a huge  computation, particularly for large databases  This research proposes an approach for finding fuzzy sets for  quantitative attributes in a database by using clustering  techniques and then employs techniques for mining of fuzzy  Associate rules.

CART Algorithm  Step 1: Start with root node (t = 1)  Step 2: Search for a split s* among the set if all possible  candidates s that gives the purest decrease in impurity.

Step 3: Split node 1 (t = 1) into two nodes (t = 2, t = 3) using  the split s*.

Step 4: Repeat the split search process (t = 2, t = 3) as  indicated in steps 1-3 until the tree growing the tree growing  rules are met.



IV.  RESULT ANALYSIS   In our experiment we use a dataset of network traffic from  UCI repository [17]. Here different feature of the network has  been given in numerical form containing 8124 records where  each record contains 119 columns of file size 558 KB. The  different analysis on this dataset is shown below.

As shown in Table 1. Is the analysis of the fuzzy apriori  algorithm on the basis of different parameters. Here in the  table different values of support and confidence is given on  the basis of which frequent item sets are generated and  number of rules which defines the number of sets possible to  identify any unwanted traffic data in the network.

Support    50 35 55 80  Confidence    30 20 35 45  Frequent Sets  in Fuzzy  Apriori    153 1189 99 23  Generation  Time of Fuzzy  Apriori    0.07 sec 0.37 sec 0.06 sec 0.03  sec  # Rules in  Fuzzy Apriori    570 17152 317 44    Table 1.  Parameter analysis on basis of support &  confidence  As shown in the table is the analysis of different  classification algorithm. The analysis shows that the CART  algorithm performs better as compared to the other existing  techniques. The CART algorithm is based on classification  and regression tree, hence the with the classification the tree  is also created which help of classify the attributes of the  dataset. Also the Time complexity of the CART algorithm is  less as compared to the other existing techniques.

Algorithm Correctly  Classified  Instances  Incorrectly  Classified  Instances  Time  taken to  build  model  Na?ve Bayes 50% 50% 0.03 sec  J48 72.2222 % 27.7778 % 0.04sec  Random Forest 61.1111 % 38.8889 % 0.04sec  CART 50      % 50% 0.02sec    Table 2. Result Analysis of different classification  Algorithms    As shown in the below graph is the error rate of the CART  algorithm as compared to the other existing techniques. The  error rate of the CART algorithm is less as compared to the  other classification algorithms.

Graph.1 Result Analysis of the Error rate    IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India

V.  CONCLUSION    Here in this paper a combinatorial method of association rule  mining and classification is applied for the better  classification of network anomalies for large databases.  The  proposed algorithm provides less error rate and contains less  computational times and also the accuracy is more as  compared to the existing technique. The technique used here  provides more classified instances so the chances of  extracting which type of anomaly is maximum and efficient.



VI. REFERENCES   [1] Farah Hanna AL-Zawaidah, Yosef Hasan Jbara and  Marwan AL-Abed Abu-Zanona, ?An Improved Algorithm  for Mining Association Rules in Large Databases?, World of  Computer Science and Information Technology Journal  (WCSIT) ISSN: 2221-0741 Vol. 1, No. 7, 2011, pp. 311 316.

[2] Manish Saggar, Ashish Kumar Agarwal and Abhimunya  Lad, ?Optimization of Association Rule Mining using  Improved Genetic Algorithms?IEEE 2004.

[3] Anandhavalli M, Suraj Kumar Sudhanshu, Ayush Kumar  and Ghose M.K., ?Optimized association rule mining using  genetic algorithm?, Advances in Information Mining, ISSN:  0975?3265, Volume 1, Issue 2, 2009, pp-01-04.

[4] Rupali Haldulakar and Prof. Jitendra Agrawal,  ?Optimization of Association Rule Mining through Genetic  Algorithm?, International Journal on Computer Science and  Engineering (IJCSE), Vol. 3 No. 3 Mar 2011, pp. 1252-1259.

[5] Peter P. Wakabi-Waiswa and Dr. Venansius  Baryamureeba, ?Extraction of Interesting Association Rules  Using Genetic Algorithms?, Advances in Systems Modelling  and ICT Applications, pp. 101- 110.

[6] 1S. Dehuri,A. K. Jagadev, A. Ghosh and R. Mall,  ?Multi-objective Genetic Algorithm for Association Rule  Mining Using a Homogeneous Dedicated Cluster of  Workstations?, American Journal of Applied Sciences 3 (11),  2006, pp. 2086- 2095.

[7] Ansaf Salleb-Aouissi, Christel Vrain andCyril Nortet,  ?QuantMiner: A Genetic Algorithm for Mining Quantitative  Association Rules?, IJCAI- 2007, pp. 1035 1040.

[8] M. Ramesh Kumar and Dr. K. Iyakutti, ?Genetic  algorithms for the prioritization of Association Rules?, IJCA  Special Issue on ?Artificial Intelligence Techniques - Novel  Approaches & Practical Applications? AIT, 2011, pp. 35-38.

[9] Duke Hyun Choi , Byeong Seok Ahn , Soung Hie Kim,  Prioritization of association rules in data mining: Multiple  criteria decision approach, Expert Systems with Applications:  An International Journal, v.29 n.4, p.867- 878, November,  2005.

[10] Choi et al., (2005).Prioritization of association rules in  data mining: Multiple criteria decision approach. Expert  Systems with Applications. v29. 867-878.

[11] Xin Li, Xuefeng Zheng, Jingchun Li, Shaojie Wang  ?Frequent Itemsets Mining in Network Traffic Data?, 2012   Technology and Automation, pp. 394- 397, 2012.

[12] Soumadip Ghosh, Sushanta Biswas, Debasree Sarkar,  Partha Pratim Sarkar ?Mining Frequent Itemsets Using  Genetic Algorithm?, International Journal of Artificial  Intelligence & Applications (IJAIA), Vol.1, No.4, pp. 133 ?  143, October 2010.

[13] G. Vijay Bhasker, K. Chandra Shekar, V. Lakshmi  Chaitanya ?Mining Frequent Itemsets for Non Binary Data  Set Using Genetic Algorithm?, International Journal Of  Advanced Engineering Sciences And Technologies  (IJAEST), ISSN: 2230-7818, Vol. 11, Issue No. 1, pp. 143 ?  152, 2011.

[14] R. Vijaya Prakash, Dr. Govardhan, Dr. S.S.V.N. Sarma  ?Mining Frequent Itemsets from Large Data Sets using  Genetic Algorithms?, IJCA Special Issue on ?Artificial  Intelligence Techniques - Novel Approaches & Practical  Applications? (AIT-2011), ISSN: 0975 ? 8887, Special issue  No. 4, Article -7, pp. 38- 43, 2011.

[15] Sanat Jain, Swati Kabra ?Mining & Optimization of  Association Rules Using Effective Algorithm?, International  Journal of Emerging Technology and Advanced Engineering,  ISSN 2250-2459, Volume 2, Issue 4, pp. 281- 285, April  2012.

[16] Ignasi Paredes-Oliva, Ismael Castell-Uroz, Pere Barlet- Ros, Xenofontas Dimitropoulos and Josep Sol?e-Pareta,?  Practical Anomaly Detection based on Classifying  Frequent Traffic Patterns?,IEEE 2012.

