<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedmgs  of the Thud Internauonal Conference on Macbme Learmng and Cybemeucs, Shangha, 26-29 August 2004

Abstract.

Owing to the widely application in the fields of information retrieval, document poalysis and idormation extraetion, document cluster analysis has been concerned broadly, and gotten a great deal of research issues simultaneously. It is one of essential theme in document mining. Based on vector space model (VSM), this paper presents a new document cluster algorithm based on assoelation rule, and dimL98es the ettidency, the sealability and h e  complexity of the algorithm.

Keywordtx Rule; Document Feature Vector Document Mining; Document Clustering; Assodation 1. Intrnduction Clustering is the process of grouping the data into classes or clusters so that objects within a cluster have high similarity in comparison to one another, but are very dissimilar to objects in other clusters. The dissimilarities are assessed based on the amibute values describing the objects. Distance measures are often used. Unlike in classification, the class label of each object is not known.

The clustering analysis came from many research fields such as statistics, machine learning, pattern recognition and so on. Owing to the huge amounts of data collected in databases, and for it can find the hidden relations and pattems in data without any prior knowledge of application fields, cluster analysis has recently become a highly active topic in data mining. Generally the clustering techniques include partitioning methods, hierarchical methods, density-based methods, and model-based methods??.

Text databases are rapidly growing due to the increasing amount of information available in electronic forms, such as electronic publications, e-mail, and the World Wide Web. Traditional information retrieval techniques become inadequate for the increasingly vast amount of text data. Typically, only a small fraction of the many available documents will be relevant to a user.

Without knowing what could be in the documents, it is difficult to formulate effective queries for analysiing and exbacting useful information from the data. We need useful tools to compare different documents, rank the importance and relevance of the documents, and find patterns and trends among documents. Thus, text mining has become an increasingly popular and essential theme of data mining.

Most researches of data mining have focused on structured data, such as relational, transactional, and data warehouses. But data store in most text databases are semistructured or even unstructured, thus, the modeling and implementation of semistructured or unstructured data have becqme an essential part of document miningt2?.

There mainly existed two ways in document clustering.

One is based on the probabilitymd the other on the distance. The methods based on the Bayesian probability theory?? describe the clustering result by probability distributing method and have the ability to deal with the overlaps between clusters. Meanwhile, there existid a weakness that the result couldn?t be satisfied with the clustering precision and efficiency when the higher dimensions of the feature space or higher associations between feature values. The methods based on the di~tance?~? include k-mean method, BIRCH method typically and so on. Both of them model document by feaNre vector, and then regard document as a point of the vector space and finally cluster by the distance between the    vector space and finally cluster by the distance between the pair of these points. Basically, these methods could be very easy to be understand, but the weakness is the clustering quality and algorithm efficiency decreased obviously when the higher document dimensions. Paper [5] proposed a document clustering based on feature vector space of document subject.

In this paper, firstly, we model document based on vector space model (VSM), conshuct the transaction matrix of document by document feature vectors, then find initial clusters of documents by using classical fast algorithm of finding frequent item sets, lastly, improve the quality of the initial clusters according to the distance between the clusters and the Link intensity of the documents to cluster.

We present relevant algorithms and discuss the efficiency, 0-7803-8403-2104/$20.00 @ZOO4 IEEE 26-29 August 2004 scalability and the time complexity of the algorithm.

2. Modeling of h m e n t In the Vector Space Model (VSM) ['I, document may be deemed to consist of a p u p  of key words/phrases [k~ ,kz ,  .... k]. We put a weighted value w, according to importance of every key wodphrase in document, so the w, could be viewed as k,'s coordinate value, that is to say that a document could be viewed as a point i nn  dimensions space. From this, we transferred the document clustering into the one in the n dimension vector space. We use the value of document feature vector to represent coordinate value of document in vector space. In the following, we will defme specifically and describe the concepts that will be used in the modeling process. For points of the simplification. we consider that the numbers of key worddphrases are the same, denote n.

2.1. h m e n t  Feature Vector ' ' Definition l(associatioli intensity)' Let D be i set of documents, the association intensity between document Dj and keyword ki is defined as' I, I where IIU Djll is the total number of efficient words in Dj.

Ih$ll is the number of occurrence of the keyword k, in document D+ Remark  a, could be standardized by standardization method, still denoted a,, c:=, a, = 1, 1 S i &lt; m , m is the,number of documents: Definition %document feature vector) Let D be a set of documents, Di E D ,  the 'document feature vector is defined as " .

- (2)  T . ai = [ai,,ai, ....... a,] .

In this paper, we use a.. to represent the coordinate ' l i value of document.

Now, we 'could construct the document transaction matrix Mnxm that the column vectors y the document feature vectors a; defined in.definitiou 2.

a,, a,, ... a,j ... a , , a,, a, ... aZj ... azm ai, a, ... a, ... a,  a,, an, ... a, ... a, . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . .

( 3 ) From this, we can view document as transaction and document feature vectors as transaction items, so as to be adapted to association rules.

23. Relevant Algorithm According to the above definitions, we present the algorithm for constructing standardized document transaction matrix.

transaction matrix.

Algorithm: construction of standardized document Input: set of document D.

Output: standardized document transactlon matrix.

Method: for each D, ED for each k, endfor transaction matrix.

computing a,, according to formula ( 1 ) endfor for each D, E D for each k, endfor endfor This algorithm includes two steps, the fmt computea, , and the second standardized it. the time complexity of the algonthmisO(nXm).

3. Doeument Clustering Algorithm Based on the document feature vector defined above, now we could process clustering of document. In this section, we find the initial clusters by using classical association rule first, and then improve the quality of initial clustering by the method that merge clusters and eliminate documents from clusters, finally, we present relevant algorithm.

26-29 August 2004 3.1. Initial Clustering of Dowment In document transaction matrix, we viewed document as transaction, document feature vectors as transaction item.

If some document feature vectors often occur together in some documents, we could say that relevant documents are similar. That is to say, by using the frequent item sets found by association rule, we could get relevant classes of documents. and viewed it as the result of initial clustering.

The support of document set is defined as I k f ~ t i o n  4(support of document) Let D be the set of documents, X C D ,  the support of X is defined as From above definitions, document distance implies the coupling and the link intensity implies the cohesion of clusters.

Re-cluster the initial clusters found by association rule to improve the quality of clustering, this process include two phrases: (1) Compute the cluster distance between different clusters, merge clusters for those whose cluster distance is bigger than specified threshold; (2) Compute the link intensity of documents with cluster within a cluster, eliminate documents from those whose link intensity is less than specified threshold.

(4)  33. Algorithm where lLnl is the number of documents in X.

From above definition, we could say that the support of X is the association means of documents with keywords.

By s(X) defined above, we could find the frequent item sets of keywords by using fast algorithm of finding frequent item sets proposed by Agrawal[?, then scan the document database to get the relevant document frequent item sets.

Fast algorithm of finding frequent item sets has been discussed in detail in [7]. Denote the result of initial clustering as C=[ CJ.

3.2. Final Clustehg of Dowment We give the relevant definitions below.

Definition S(c1uster distance) Let D be the set of documents, G., Gb C D, the distance of G., Gb is defined as IIG.IIIIGLII where IG.11, IIGbII is the number of documents in G,,, Gb.

d(DiPj) is the Euclidean distance of Di, Dj, Di? G,,, DJ E Gb Remark the value of document feature vector is used 10 represent the coordinate value of document in vector    10 represent the coordinate value of document in vector Algorithm: clustering of document.

Input: initial document clusters.

6 : the threshold of coupling.

y : the threshold of cohesion.

output: final document clusters.

function: re-clustering for initial clusters.

for each ci E c do .

for each C j  E c do computing d(Cj ,Cj)  according to (5); if d(Ci ,Cj)  16 then ci =ci uc j ; delete Cj from C; endif endfor endfor for each Ci? C do for each D j  E ci do computing p ( D j , c i )  according to (6); if p ( D j , C i ) &lt; y  then space.

documents, Di E D ,  C C  D, the link intensity is defined as for each CkE C do computing p ( D  j ,  C, ) according to (6); Definition ((link intensity) Let D be the set of ? if p ( D j , C , )  2 y then cJ=cj- (Dj); ct=ck+( Dj ) ; 11-1111- (6) endif I1 I111 sill. * endfor endif - where a, = [ai,,ai *,....., a,]?is the document feature vector, IlCll is the number of documents in C.

endfor endfor Shanghai, 26-29 August 2004 Ans= U ci ; This algorithm include two phrases of merging and eliminating, the time complexity of the phrase of merging is 0 ( 141 x IlCll) , the other is o ( l l ~ / l  x l~ll x Cllcill ) ,so the total time complexity is 0 ( llCll* (1 + ZllC, 11) ) ,where IlC,ll is the number of documents in C,.

4. Experiment Results i In order to evaluate this algorithm, we have compared this clustering algorithm with classical k-mean clustering algorithm. In the experiment, the documents that we used came from the searching engine Google in the Internet. The  whole experiment is running on the platform of the PIV-2.4 computer with Windows XP operating system. We have compared the precision and the scalability of the algorithm.

The result is described in figure 1 and figure 2. From these figures, we can see that our algorithm is better thank- mean algorithm.

I I@% r I I K-means Our Algaritlol I Figure 1 -CKLmeans  -4- Our Algori thln 5" " $ 2  40 Y O aJ3 80 W O f? .6, 6 ?- 2 0 .

c 0 0 0 0 0 0 0 0 0 Lo 0 m 0 Lo 0 U) 0 m N Lo h 2 2 2 5 0 N N N    N N Number of Documents Figure 2 5. Cooelusion In this paper, we present a new document cluster algorithm based on algorithm of association rule, for processing initial clustering by using classical fast ikquent item sets, the efficiency and the precision of the algorithm are higher increasing, the results of the experiment point out that our algorithm is better than k-means algorithm.

Aeknowledgemeats This work is supported by the National Natural Science Foundation of China (No.60173058).

