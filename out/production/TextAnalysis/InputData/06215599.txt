Association Rule Mining Using FPTree As

Abstract- Association rule mmmg is one of the most important aspects of data mining. It aims at searching for  interesting relationships among items in a large data set or  database and discovers association rules among the large no of  item sets. The importance of ARM is increasing with the demand  of finding frequent patterns from large data sources. Researchers  developed a lot of algorithms and techniques for generating  association rules. The main problem is the generation of  candidate item sets before producing frequent item sets. This  result in wastage of time and space. Among the existing technique  the frequent pattern (FP Growth) method is the most efficient  and scalable approach. It mines the frequent item set without  candidate data set generation. The obstacle is it generates a  massive number of conditional fp trees. In this system we propose  an improvement for frequent pattern tree based technique which  does not use conditional fp trees. It generates fp trees using  directed acyclic graph data structure. For this we propose an  algorithm that scans the database and generates fp trees as DAG  so that we can generate Frequent Patterns directly using DAG  without generating conditional fp trees. Using frequent patterns  the association rules are generated. We compare this with  traditional fp growth, MFI in terms of number of database scans,  conditional FPTrees, time complexity and space complexity.

Index Terms- Knowledge Discovery, Data Mining, Association Rule, Frequent Patterns, Frequent Item Sets, FP  Growth, FPTree, Directed Acyclic Graph, DZBDD.



I. INTRODUCTION  Advances in data collection and storage technologies have led organizations to store vast amounts of data pertaining to their business activities. Extracting "useful" information from such huge data collections is of importance in many business decision making processes. Such an activity is referred to as Data Mining or Knowledge Discovery in Databases (KDD) [1][4]. Data mining includes tasks such as Classification, Similarity Analysis, Summarization, Association Rule Mining, Sequential Pattern Discovery,  Neural Networks and so forth [1][4]. Association Analysis [1][2][4][6][10][11] is the discovery of association rules attribute-value conditions that occur frequently together in a given data set. Association analysis is widely used for market basket or transaction data analysis. Association rule mining represents a data mining technique and its goal is to find interesting association or correlation relationships among a large set of data items. With massive amounts of data continuously being collected and stored in databases, many companies are becoming interested their profits [5]. It has a mentionable amount of practical applications, including classification, XML mining, spatial data analysis, and share market and recommendation systems. This rule measure with support. To ensure every dataset treated equally in classical model. The perception of association rule mining suggests the support confidence extent outline and condensed association rule mining to the discovery of frequent item sets. Rule support and confidence are two measures of interestingness.

Association rules are regarded as appealing if a minimum support and a minimum confidence threshold is satisfied [1][2][3][7][9].This paper presents an efficient association rule mining technique with help of Directed Acyclic Graph.

This paper is organized as follows: Section 2 describes Related Work. Section 3 describes Proposed work (Association Rule Mining using DAG). Section 4 describes implementation details. Section 5 presents experimental results and performance analysis. Section 6 presents conclusion and future scope.



II. RELATED WORK  Mining Association Rules is an important research field on KDD presented firstly by those people, e.g. R. Agrawal. Rules represent the interesting associations or relations between item sets in data base. Mining frequent item sets is the fundamental and essential part in many data mining applications, such as the discovery of association rules, sequential patterns, and so on. Apriori algorithm [1] and its improved ones are mostly      adopted to mine frequent item sets in the past researches. All these algorithms make use of the character "all subsets of frequent pattern are frequent", but generate plenty of candidate item sets in mining process, and need to scan the original database many times, thus the mining efficiency is cut down.

Therefore, people such as Jiawei Han presented an algorithm without candidate generation-FP-growth[6][7][8], which only need to scan database twice: frequent I-item sets are gained in the first scanning database, and in the second time non-frequent item sets in original database are filtered with frequent I-item sets and the FP-tree is built, then the complete frequent patterns are mined by performing recursively mining method in FP-tree. Experiments show that FP-growth is about an order of magnitude faster than Apriori. The drawback of mining complete frequent item sets is that if there is a large frequent item sets with size I, then almost all 21 candidate subsets of the items might be generated. However, since frequent item set are upward closed, it is sufficient to discover only all maximal frequent item sets. In addition, there are some mining applications which only need to discover maximal frequent patterns, not to discover complete ones, thus it is greatly significant to mine maximal frequent patterns. But like other algorithms it also have certain disadvantages, it generates a large number of conditional FP trees. It generates this FP trees recursively as a procedure of mining. So the efficiency of the FP growth algorithm is not reasonable. But in our proposed FP Growth using Directed Acyclic Graph there is no need to generate conditional FPTree as the recursive element is connected using acyclic graph.



III. PROPOSED WORK(ASSOCIATlON RULE MINING USING FPTREE AS DTCRECTED ACYCLIC GRAPH)  A. Pattern Growth Framework For Mining Frequent Item Sets  The pattern growth framework for mining frequent patterns grows prefixes by recursively projecting intermediate databases. For each item x, an x-conditional DB is induced. It contains item sets in the input database which contain x. Then, frequent item- sets which contain prefix {x} are grown by recursively creating further projections from the x-conditional DB. FP-growth is one of the strongest techniques that follows this pattern growth approach. In particular, FP-growth uses frequent pattern (FP) trees for storing the input, the output patterns, and the conditional DBs. An FP-tree is created afresh for each of those databases. FP-growth uses a dynamic ordering of the items, such that items in an FP-tree are ordered by decreasing frequency, the most frequent item at the top.

The FP-trees which are created throughout mining may use different item orderings. One of the most efficient implementations of FP-growth grows prefixes by traversing the database in a bottom-up manner.

An FP-tree example is shown in Figure 3.1(a). Each node in an FP-tree contains an item and a value which represents the frequency of that node's prefix path. As a secondary data structure, a header table is used for storing the total frequency  of each item. In this example, the first prefix is grown using item d (the least frequent item). The FP-tree representation for d-conditional DB is shown in Figure 3.1(b).

H a abl  Ibn  C  b ? ?  I  II  ?up p N U J i lID:  ? , , ,  ? "  J 'III j 1_.,  P  ? P.

,  2 "  . [r. Orderll'lg: s < < g < < a < d (a) DatASS D  Figure III-A (a) Var. ordering e<b<g<c<a<d and Data set D  < Fig III-A (b) Var. ordering e<b<c<g<a and conditional data base      B. Zero-Suppressed Binary Decision Tree Diagrams  Directed Cyclic Graph data structure called the Zero? suppressed Binary Decision Diagrams (ZBDDs). Binary Decision Diagrams (BDDs) (Bryant 1986) are canonical directed acyclic graphs (DAGs). Their canonical property  Jllmn allows Boolean formulae to be compactly represented and r their logical operations (AND, OR, XOR, etc.) to be performed in polynomial time with respect to the number of nodes. A Zero-suppressed BDD (ZBDD) (Minato 1993) is a special type of BDD which was introduced for efficient manipulation of sparse combinations. More formally, a BDD is a canonical DAG of labeled nodes. It consists of one source node, multiple internal nodes, and two sink nodes which are labeled as 0 and 1 respectively. Each internal node may have multiple parent nodes, but it can only have two child nodes, which we call O-child and I-child nodes. By canonical, it means that multiple identical nodes are not allowed. Two nodes are identical if they have the same label, and their respective child nodes are also identical. The Nodes are ordered so that the label of any internal node must be of higher index (i.e appear earlier in the variable ordering) than the label of its children. An internal node N with label x, denoted N=node(x,N I,NO), encodes the Boolean formulaN = (xI\Nl)V(xI\NO). We call Nl (resp. NO) the I-child (resp. 0- child) of N. The edge connecting a node to its I-child (resp.

O-child) is also called the true-edge (resp. false-edge). In the illustrations shown shortly, solid lines correspond to true? edges whilst dotted lines correspond to false-edges. Each path from the root to sink- I (resp. sink-O) gives a true (resp. false) assignment for the represented function. For some node N, with label x, the outgoing true- edge of N represents a true assignment for variable x, whereas the outgoing false-edge represents a false assignment for variable x.

BDDs have two important properties 1. Equivalent sub trees are shared (canonical); 2. Computation results are stored for future reuse (referred  as BDD's caching principle).

These properties make the worst-case complexity of most  BDD operations polynomial with respect to the number of nodes. A Zero-suppressed BDD (ZBDD) is a special kind  of BDD which was introduced for efficient combinatorial item set analysis. More specifically, a ZBDD is a BDD with two reduction rules  1. Merging rule: merge identical sub trees (to obtain canonicity);  2. Zero-suppression rule: delete nodes whose I-child is the sink-O, and replace them with their O-child.

By utilizing these rules, a sparse collection of item combinations, which can be seen as a Boolean formula, can be represented with high compression, i.e. for an n variable formula, the possible space of truth values is 2", however the corresponding BDD/ZBDD can have exponentially fewer nodes.

The two Rules can b shown using following Figure 3.2.

M?r In ml?  Figure III-B Merging Rule And Zero Suppression Rule We follow the ZBDD encodings for representing a  collection of item sets. A set S of item sets can be represented by a characteristic function Xs: {O, I} n --+ {O, I} where Xs(P) = 1 if P D S and 0 otherwise. In ZBDD semantics, set S such that S = So D (SI x {x} ) can be represented by a ZBDD node N = (x,NI,No) where SI (resp. So) is the set of item sets encoded by NI (resp. No). An item set p in S is interpreted as a conjunction of the items contained in p and yields a true assignment for the Boolean formula encoded by N. A sink-O node encodes an empty set (D), and sink-l node encodes a set of an empty item set ( {  D } ).

C. Frequent Item Set (FJ) Miner using ZBDD(DAG).

Our algorithm for mining frequent item sets is labeled as FIMiner. The algorithm is shown in Algorithm 1. It is invoked by calling FIMiner (ZD, a, prefix) where ZD contains the input item sets and prefix is initially empty (i.e. prefix = {} ).

Frequent item sets are grown from the given prefix, using the input ZBDD which is traversed in a top-down fashion. Let x be the top-node's label. For a given input ZBDD, item x is firstly used to grow the current prefix since no computation is needed to create the conditional DB for this item. More specifically, an x-conditional DB can be found in the top 1- child node, which contains all item sets containing x in ZD.

This routine finds the patterns which contain x. Patterns which do not contain x are grown later, after removing x from the input ZD and applying the same mining procedure. The output ZBDD is incrementally built from each recursion step, using      the same variable ordering as the input ZBDD which allows both ZBDDs to share nodes.

In addition to the standard ZBDD primitive operations, we push the anti-monotonic support constraint deep inside the routine using an infrequent prefix pruning strategy (line 4-5) which is based on the anti-monotonic property of support.

Here, the bitmap data representation of the input database is needed to calculate the support of each prefix. For a given prefix P, bitmap(P) refers to the bit-vector of the occurrence of P in the initial input dataset. We compute support(P) by counting the number of I's in bitmap(P), denoted as Ibitmap(P)I. Hence, the support of prefix D {x} in FIMiner (line 4) can be computed incrementally by re-using bitmap(prefix) which has been computed in previous mining iteration, and taking its bit-wise intersection with bitmap( {x} ).

When a new prefix which is grown using item x is infrequent, it is deleted from the output by returning the sink-O node and employing ZBDD's zero suppression rule (line 5).

This automatically deletes node x from the output and replaces it by other patterns which do not contain item x, which will be computed later in line 9. Otherwise, the new prefix can be grown further using x-conditional DB (line 7). To remove x from the remaining routines and grow prefixes using the remaining items, the two child-nodes of Zo are merged using a set-union operation, which is a ZBDD primitive operation (line 9). For mining efficiency and data compression purposes, the non-maximal item sets are removed from the merged database, which can be obtained by using ZBDD's max operation. We refer to this operation as DBmerging. Since primitive ZBDD operations store computation results in a cache, DB-merging can be computed efficiently if many of the conditional DBs share common subtrees. Finally, the recursion terminates when the induced database is empty (line 1-2).

Once mining in both the x-conditional database and the merged database have been completed, the output node is created by having item x as its label and the patterns found from the two sub-tasks are assigned to its I-child and O-child respectively. Since, this procedure is performed at each recursion level, it incrementally builds the output ZBDD in a bottom-up fashion. More specifically, the frequent patterns which are found from the x-conditional database become the I-child node, which are seen as patterns which contain item x, and the frequent patterns which are found in the merged database become the O-child. When creating such a node, ZBDD's library checks whether the node has been existed. If it has, then the existing node is shared.

Let us consider again the sample dataset in Figure 1. Figure 3(a) shows the conditional DB for the first item, i.e. d? conditional DB which is given by the I-child of the top-node.

Figure 3(b) illustrates the DB-merging operation. The merged database contains the set-union between item sets in the two child-nodes of ZD. In order to achieve higher data compression and mining efficiency, the non-maximal item sets are simultaneously removed while computing the set-union.

Identical nodes in the merged ZBDD are shared with the input database, as well as the other databases.

Algorithm 1 FTh'liner(ZD,a pre f'i x) Inp ut : ZD: t e databa e induced by prefix  0': minimum upport threshold, prefix: prefix itemset  Output: Zp{ the frequent itemset in ZD Procedure:  1: if (ZD is a i k node) then 2: Te1ininal case:  return ZD 3: end if  Let ZD = n de(x, ZD?: ZD"i:) prefixx = prefix U { x}  4: if (su port(prefixx) < a) then 5: Infrequent prefix pruning:  Zn. =O 6: el e 7: Grow new prefi:r; prefixx and mine FIs:  Zn. = FIMiner (ZDz ? Ci, pre fixx ) end if  9: DB-merging and grow prefix l.?ithout x: Zfj." = FIMiner(Zv.Um(lxZD,, ? Q, prefix)  LO: return ZFI = getNode( x ZPIE ZPI"i:) Note: support (prejixx ) = 1 bitmap (prejix) n bitmap( { x} )1.

Figure III-C 1 Algorithm  (a) ZD = ZBOn r1p!mnt.ioo :or a?;a!BI, 'E, :0,1 DB !Il?r?:? ir.oo?w?o Y,tn ooUn? a?e lte .j{\'i[?t:O!lll [ JB ? ZD:1 1 ???a n,:o! oel',;[)' creatro waft)  Figure III-C 2(a) Conditional DB And 2(b) DB Merging

IV. IMPLEMENTATION DETAILS  In this section, we analyze the performance of our ZBDD? based technique for mining frequent item sets by comparing with incremental FP Tree algorithm and traditional FP Tree algorithm. The algorithms were implemented in java language.

Swing framework is used for designing GUI. We have placed transactional data records in data sets. The SQL Server 2000 data base is used for managing the perfonnance results.



V. EXPERIMENTAL RESULTS  In order to evaluate the perfonnance of our proposed algorithm, we have conducted experiments on a PC (CPU: Intel(R) Core2Duo, 3.16GHz) with 4GByte of main memory running Windows XP. We used 3 data sets. One contains 72 samples (transactions), second one 39 samples and third one 120 samples.

The following shows the results of Association Rule mining using ZBDD( Directed Acyclic Graph).

?. '-'-\?:fl[ ?.:::?i,? 11Io1')'?IUlilo 17'IIl?t;:I:lD.

l?lI:I??llrlo  -'-.1' .r-  [ I?  Fig 5.1 Results of Association Rule mining using ZBDD ( Directed Acyclic Graph).

The following shows the comparison of Proposed Algorithm (ZBBD or DAG) with MFI and FPGrowth in tenns of No of Data base scans and no Of Conditional FPTrees.

BAR CHART ANALYSIS FOR FPGROWTH ALGORITHM AND MFI ALGa?ITHI\IS  00 :! 10 15 :t 2.S la l! '0 U s'( ?s 10 I.! 10 'S IF  ="".?I- ,?- ----------------_  Fig 5.2 Comparison of algorithms in terms of No Of Data base Scans.

BAR CHART ANALYSIS FOR FPGR<lWTH ALGORITHM AND MFI ALGORITHMS  Fig 5.3 Comparison of algorithms in terms of No Of Conditional FP Trees.

o  ? Series 1  ? Series 2  ? Series 3  Fig 5.4 Comparison of algorithms in tenns of No Of Conditional FP Trees and No of database scans.

o  ? Series 3  ? Series 2  ? Series 1  Fig 5.5 Comparison of algorithms in terms of No Of Conditional FP Trees and No of database scans.

The following shows the comparison of Proposed Algorithm with MFI and FPGrowth in terms of Time and Space Usage.

----- - .... ?.?  - .-. --  Fig 5.6 Comparison of algorithms in terms of Time Consumed.

rO?!Iii1i1 itS. WS" .. Ail ,! -  .

".'  Fig 5.7 Comparison of algorithms m terms of Space Conswned.

BAR CHART ANALYSIS FOR FPGROWTH, MFI AND ZBDD(DAG) ALGORITHMS u f.:  Fig 5.8 Comparison of algorithms in terms of Time Consumed.

! ',t" i?IIH15'(,ji'*!o iU'N@p!WiH'?i!Ii ., BAR CHART ANALYSIS FOR FPGROWTH, MFI AND ZBDD(DAG) ALGORITHMS  0.:0 o,s 1.? 15 ; (I ! 5 ,..? 1.= 1.? t 5 : D 55 e: .. ,  Fig 5.9 Comparison of algorithms in terms of Space Conswned.



VI. CONCLUSION AND FUTURE WORK  The In this paper, we proposed a new improved Algorithm for mining Frequent Item Sets that uses Directed Acyclic Graph (ZBDD). Our approach reduces the total step of the process and also takes less time and less memory. In future the process can be applied with xml data base.

