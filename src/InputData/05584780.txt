

AbstractThis paper describes a model that discovers  association rules from a medical database to help doctors treat  and diagnose a group of patients who show similar prehistoric  medical symptoms. The proposed data mining procedure  consists of two modules. The first is a clustering module that is  based on a neural network, Adaptive Resonance Theory 2  (ART2), which performs affinity grouping tasks on a large  amount of medical records. The other module employs fuzzy set  theory to extract fuzzy association rules for each homogeneous  cluster of data records. In addition, an example is given to  illustrate this model. Simulation results show that the proposed  algorithm can be used to obtain the desired results with a  reduced processing time.



I. INTRODUCTION  ATA mining is popularly referred to as knowledge  discovery from data (KDD). It is the process of  extracting desirable knowledge or interesting patterns  from existing databases for specific purposes. Many types of  knowledge and technology have been proposed for data  mining. Among them, finding association rules from  transaction data is the most commonly studied whelm.

An association rule is represented by X?Y where X and Y  are a set of items. The rule means that the transaction records  in a database that contain X also tend to contain Y. Many  effective algorithms for mining association rules from large  databases have been proposed [1], [2].

Over the last two decades, artificial neural networks  (ANNs) have been developed for solving pattern  classification problems and finding association rules [3]. In  the medical domain, neural networks have been used as a  diagnostic decision support system. For example, a  supervised learning neural network was developed for  leukemia diagnosis [4]. Other fault detection models based on  abdicative network model, and combined fuzzy logic and  neural network, were proposed in [5], [6]. In [7] a hybrid  model of Adaptive Resonance Theory (ART) and fuzzy  c-mean clustering for medical classification and diagnosis  with missing features was developed.

Manuscript received Jan. 31, 2010. This work was supported by National  Science Council, Taiwan under Grant NSC97-2221-E-027-034-MY3.

Y.-P. Huang is with the Department of Electrical Engineering, National  Taipei University of Technology, Taipei, Taiwan 10608 R.O.C. (Tel:  +886-2-27712171ext 1002 , e-mail: yphuang@ntut.edu.tw).

T. T. H. Vu is with the Department of Electrical Engineering, National  Taipei University of Technology, Taipei, Taiwan 10608 R.O.C. (e-mail:  t7318111@ ntut.edu.tw).

J.-S. Jau is with the Department of Electrical Engineering, National Taipei  University of Technology, Taipei, Taiwan 10608 R.O.C. (e-mail:  pikachu1982124@yahoo.com.tw).

F.E. Sandnes is with the Faculty of Engineering, Oslo University College,  Oslo, Norway. (e-mail: frodes@hio.no).

The efficiency of combining fuzzy logic and neural  network has been shown in many applications [8], [9], [10]  but the problem of discovering association rules in data  mining is an open research question. Thus, this study  proposes a methodology using fuzzy ART2 to increase the  efficiency when discovering association rules. The input  patterns are first fuzzified using fuzzy logic. The fuzzified  patterns are then clustered into groups by the ART2 neural  network. The patterns in each group have similar properties  that in turn allow us to find the association rules among them.

This will significantly reduce the computational cost in  finding the interesting rules.

We choose ART2 for clustering the patterns, because it is  computationally effective and allows the user to easily  control the degree of similarity of patterns placed on the same  cluster. The inter- and intra-cluster differences among data  indicate that ART2 clusters data according to Euclidean  distance approximately.

In this paper, one case study is presented involving the  grouping of patients who have undergone surgery for breast  cancer. Those with similar symptoms are used to discover  group association rules to assist the doctors in treatment and  diagnosis.

The remainder of this paper is organized as follows.

Section II gives an overview of related work, while the  proposed approach is presented in Section III. Section IV  summarizes the experimental results and discussions. Finally,  the conclusion remarks are made in Section V.



II. RELATED WORK  A. Fuzzy Neural Networks  The learning algorithms of ANNs can be divided into two  categories: supervised and unsupervised. Supervised learning  involves training instances with labeled outputs, which give  feedback about how learning is progressing. This is akin to  having a supervisor who can tell the agent whether or not it  was correct. In unsupervised learning, the goal is unknown as  there are no pre-determined categorizations.

ANN technology offers a decisive job in terms of  summarizing, organizing, and classifying data. Requiring a  few assumptions, it also helps identify patterns among input  data and achieves a high degree of predictive accuracy [11].

The learning and recall procedures allow ANN to mimic the  thinking models of human beings: through memorization and  recall. In general, an ANN includes the following features:  parallel processing, error tolerance, recall memory, and  optimization solutions.

Both ANNs and fuzzy models have been applied in many  areas [8], [9], [10], [12], [13]; each with its own advantages  and disadvantages. Therefore, how to successfully combine  A Fuzzy ART2 Model for Finding Association Rules in Medical Data  Yo-Ping Huang, Vu Thi Thanh Hoa, Jung-Shian Jau and Frode Eika Sandnes  D  978-1-4244-8126-2/10/$26.00 2010 IEEE        these two approaches, ANNs and fuzzy modeling, has  become an active area of research. Due to its lack of  explanation ability, ANNs are unable to offer easily  understandable explanations while the outputs are being  generated [15]. Nevertheless, fuzzy models with its ability to  articulately express knowledge and technology could  compensate for the shortcomings of ANNs. A fuzzy neural  network (FNN) system uses the ANN learning algorithm to  produce parameters. It then adapts these parameters for  optimization.

B. Association Rules Mining  Mining association rules from large databases is a core  topic of data mining. It detects hidden linkages of otherwise  seemingly unrelated data. These linkages are rules that    overpass a preset threshold and are deemed interesting.

Interesting rules allow actions to be taken based upon data  patterns. They can also help make and justify decisions.

Association rules are defined in the form {X1, X2, , Xn}  -> Y, in which Y may present in the transaction if  X1, X2, ,  Xn are all in the transaction. Notice the use of may to imply  that the rule is only probable, not deterministic. The  probability of finding Y in transactions with all X1, X2,, Xn  is called confidence. The threshold that a rule holds in all  transactions is called support. The level of confidence that a  rule must exceed is called interestingness.

There are different forms of association rules. The simplest  type, Boolean association rules, only shows valid or invalid  association. In our medical example, Patients who have old  age and large number of positive auxiliary nodes detected will  die within 5 years is a Boolean association rule.

The problem of discovering association rules can be  generalized into two steps:  (1) Find all large (frequent) itemsets  A large itemset is a  set of items that exceeds the minimum support.

(2) Generate rules from the large itemsets.

For step 1, the Apriori algorithm has been the mostly  mentioned algorithm. Many modifications [16]-[17], e.g.,  speeding up and scaling up, of step 1 are about improving the  Apriori algorithm by addressing its fallacy of generating too  many itemsets. There are also algorithms that are not based on  Apriori [18]-[20] but aim at addressing the issues of data  mining efficiency.

Step 2 is mostly characterized by confidence and  interestingness. Research has addressed different ways of  generating rules [21] and alternative measures to  interestingness [22].



III. METHODOLOGY  A. Data Transformation  The original raw data are collected from experiments and  investigations. To use these data in each application, we have  to transform them into a suitable form. Transformations are  widely used in statistics to normalize data to standard form.

Some common methods of re-expressing data are centering,  standardizing and normalizing.

In this study the input patterns for ART2 are fuzzified and  the clustered results are used to find the association rules    among data. Assume that each input pattern contains n  attributes (X1, X2, , Xn). Generally, such a function maps  each attribute value to a real number in interval [0,1],  ( ) [ ],1 ,0: ?XxA? where A? is called the membership function  of set A. For convenience, we denote the fuzzy membership  function by f? , where the subscript f indicates the  corresponding fuzzy set. The total number of fuzzy sets is  denoted by S ( [ ]Sf ,0? ). The number of membership  functions for each attribute belongs to the interval of the  attribute and the distribution of these attribute values.

The input pattern for ART2 can be represented by new  patterns in form of membership degrees (  11 f? , 22 f? ,, nnf? )  (f1 from 0 to S1, f2 from 0 to S2, , fn from 0 to Sn). Otherwise,  for describing the input patterns of the algorithm to make  efficient in discovering the association rules, we use linguistic  terms instead of membership degrees.

For example, for attribute X1 in a pattern, X1 is expressed  by 3 fuzzy sets with linguistic terms: Small, Medium, Large  (S, M, L) as shown in Fig. 1. If the value of X1 is larger than c,  X1 will be represented by Large (L).

Fig. 1. Linguistic terms of X1.

B. Fuzzy ART2 Neural Network  1) Network Structure: After the fuzzy inputs have been  extracted, the proposed fuzzy neural network (FNN) called  the fuzzy ATR2 is employed to automatically cluster the  pattern data. The input and output relation of the proposed  fuzzy ART2 can be described as follows:  Input layer: The input layer consists of units that are  called short term memories (STM).

Weight layer: The weight layer consists of two kind of  weights, i.e., bottom-up and top-down weights ( ijb  and ijt ),  that are called long term memories (LTM).

Output layer: The output layer is used to express the  clustering results for the given data.

2) Learning Procedures:  The fuzzy ART2 learning procedure contains four steps as  follows:  Step 1: Input the fuzzy vector into input layer.

Step 2: Calculate the distance between the bottom-up  weights and fuzzy inputs. Find the shortest distance.

Step 3: If the shortest distance fails to the vigilance test, a  new node is created with its weights equal to the  fuzzy inputs. If a cluster wins the vigilance test, the        centroid of the cluster is adjusted to adopt the new  input.

Step 4: The process is repeated until all given data have  been clustered into suitable clusters.

If all winners do not pass the vigilance parameter test, it is  necessary to create a new cluster and add the corresponding  weights. If the state is resonance, the current fuzzy input is  assigned to this cluster by modifying the corresponding  weights.

The purposes of using the fuzzy ART2 before discovering  the association rules include:  - Decentralize the volume of data from the originally  large database to some subsets that contain the  smaller number of patterns.

- Because patterns clustered to the same cluster  possess the similar characteristics, the time taken to  discover the association rules will be shorter than to  the originally large data.

C. Algorithm for Finding Association Rules  After grouping all patterns of the original data into some  clusters, the data mining algorithms are used to find the  association rules from each cluster. As mentioned above, we  need two 2 steps to find association rules. First, to improve  the efficiency of the Apriori algorithm, a direct hashing and  pruning (DHP) table [17] is used to reduce the size of  candidate set by filtering any k-itemset out of the hash table if  the hash entry does not reach a minimum support.

Then, rules are determined by interesting measures:    Rules become association rules when they have confidence  larger than or equal to the minimum confidence.



IV. EXPERIMENTAL RESULTS AND DISCUSSIONS  In this section, we use one benchmark study, Haberman's  Survival problem, to illustrate the effectiveness of the  proposed model. The data set is available from the UCI  machine learning repository [23]. The Harbemans Survival    datasets consist of 306 samples. Each data sample constituted  4 attributes: age of patient, patients year of operation,  number of positive auxiliary nodes detected and survival  status. Survival status attribute contains only two values that  are one and two to indicate the patient survived 5 years or  longer and the patient died within 5 years, respectively. Table  I gives all linguistic terms for 4 attributes in each pattern for  this study.

The vigilance value in ART2 model will dominate the  clustering results that in turn affect the number of patterns  clustered to each cluster. Depending on the database size and  the properties of the data, it is hard to decide the number of  suitable clusters before executing the clustering job. In this  study, mid-size clusters, such as 3 to 7, are tested for the  medical data. In case only few data were found in a cluster, a  check is performed to see whether they are outliers or not. For  example, when analyzing datasets we found that one pattern  (83, 58, 2, 2) is an outlier numerically distant from the  remaining data. Therefore, only 305 patterns are used in the  simulations to avoid the overhead of processing this outlier  pattern.

First, we carry out the methodology by fuzzifying the input  patterns using the labels of membership functions of 3, 3, 3  and 1 for four attributes, respectively (case 1, the vigilance  value is set to 3.6). These membership functions are  illustrated in Fig. 2 for details. The cover range and the shape  of membership functions may affect the results of association  rules. Although those parameters can be further optimized by  the genetic algorithm framework [14] they are not the goal of  this research. In this example, all membership functions are  empirically determined.

Fig. 2. Linguistic terms of four attributes for case 1.

After performing the fuzzy ART2, the data can be grouped  into 3 clusters, in which clusters 1 to 3 contain 131, 115 and  59 patterns, respectively. We use DHP and interesting  measures to find the association rules for each cluster.

Because of the differences among the volumes of patterns in  clusters, minimum support (min_sup) and minimum  confidence (min_conf) can be set to different values.

So, we pro rata set minimum support and confidence in  accordance with percentage of the number of each cluster.

Fig. 3 illustrates two cases of the data ratio in the clusters. For  example, cluster 1 in case 1 contains 43% of the 305 patterns,  so we set both minimum support and confidence to 57%.

Fig. 3. Cluster results for case 1 and case 2.

The result of this case is compared with the case that only  uses DHP to mine all 305 patterns without using Fuzzy  ART2. Table II compares the results. Note that, min_sup and  min_conf for mining all 305 patterns will be set lower than  Acontainingtuples  BandAbothcontainingtuplesBAconfidence  ___#  ______#)( =?

that of each cluster because each cluster after clustering has  the similar properties.

From Table II, we can see that the results of association  rules of combining 3 clusters (after mining separately  clusters) and the results after mining from all patterns  (without fuzzy ATR2) are the same but the latter needs more  time to process.

The purpose of the other experiment is to find out the effect  of the number of membership functions on the association  rules. The number of membership functions for the patient  age attribute and the number of positive auxiliary nodes  attribute will be respectively changed to 5 membership  functions as shown in Fig. 4 (case 2, the vigilance value is set  to 3.4) and the vigilance parameter is set to the same as the  case 1.

Fig. 4. Linguistic terms of attribute 1 and attribute 3 for case 2.

The results are presented in Table III and Table IV. In this  case, the dataset is clustered into 5 clusters (larger than that of  case 1) with the numbers of patterns respectively are 78, 66,  57, 85 and 19. And the same as the case 1, the association  rules are similar with or without using fuzzy ART2.

Two cases take full advantage of fuzzy ART2 in finding  association rules. It separates the dataset into some smaller  groups to reduce the computational cost.



V. CONCLUSIONS    This study proposes a novel approach for finding  association rules from medical data. The combination of  fuzzy model and ART2 neural network is developed to cluster  the fuzzified dataset into several groups with similar  properties. The groups are then particularly exploited for  finding the association rules. The approach shows that the  more computationally efficiency can be obtained by reducing  processing time. An application considered is to group the  patients who had undergone surgery for breast cancer into  groups that have the similar properties to use group  association rules. The experimental results show that the  discovered association rules are exactly the same with the  conventional approach. The merit of this research is that the  computational time is significantly reduced and the approach  can be applied to a variety of domains.

