The study of Multidimensional-Data flow of Fishbone   applied for Data mining

Abstract?Data Mining Driven Fishbone, which is whole a new term, is an enhancement of abstractive conception of multidimensional-data flow of fishbone applied for data mining to optimize the process and structure of data mining.

End-to-end DMDF diagram includes complex dataflow and different processing component and improvements for numerous aspects in multiply level. DMDF provides integrated platform and mixed methodology to support the whole life cycle of data mining with comprehensive methodology. Data preprocessing, data Classification, Association rule mining and Prediction are the foundation and linkage of the whole data mining process life cycle. DMDF supports combination of different mining component from strategy level, tactical level to abstractive level, and then re-engineered data mining process into execution system to realize reasonable architecture. DMDF is a new direction of the structure of data mining process.

Keywords-DMDF (data mining driven fishbone); Methodology & Architecture; Fishbone; Data mining process; Multidimensional-Data flow

I.  INTRODUCTION The original Fishbone is also known as the cause and  effect diagram, the root cause analysis. The technique uses graphical means to relate the causes of a problem to the problem itself, in other words, to determine cause and effect. It is generally called the Fishbone diagram because the diagram resembles that of a fishbone. In simple terms, Fishbone is brainstorming in a structured format. The diagram focuses on the causes rather than the effect.

Because there may be a number of causes for a particular problem, this technique helps us to identify the root cause of the problem in a structured and uncomplicated manner. It also helps us to work on each cause prior to finding the root cause [1]. Prerequisite programs (PrPs) have been identified and implemented in the cause and effect diagram (also known as Ishikawa, tree diagram and fishbone diagram).

Data mining is hot area of computer science and technology. Data mining refers to extracting or ?mining? knowledge from large amounts of data. The data mining is appropriately named as ?Knowledge Mining.? There are many other terms carrying a similar or slightly different  meaning to data mining, such as Knowledge Mining from Databases, Knowledge Extraction, Data/Pattern Analysis, Data Archaeology, and Data dredge.

In this article, an effort of doing research in methodology and multidimensional data flow of data mining is introduced, which provides a comprehensive and framework and methodology for data mining process. Data mining driven fishbone is a good implement of the combining fishbone analysis method with multidimensional data flow processing [2]. DMDF methodology is evolvable, interoperable, modular and reconfigurable. We will explain data mining components which are built in fishbone frame structure and the each step of how to implement the data mining fishbone (including 1. Define the direction of the DMDF undergo; 2. Brainstorm (Considering Data preprocessing algorithm is suitable); 3. Identify the cause and the most important branch by considering the weight of each branch; 4 .Receive the solution from DMDF ).I will do more  effort on Data Mining Driven Fishbone research, enabling Data mining process is much more intuitionist and easier through an integrated and combinative ?Fishbone? architecture. Also data mining enhance the function of original fishbone conception.



II. LITERATURE REVIEW  A. Enterprise Complex data environment Complexity is one of the main characteristics of large  enterprise data systems and applications. The description of a system?s behavior is complex, even if we have complete information about its components, its dependencies, and its environment. The correct decision comes from excessive data depend not only on the correctness of data and elements in the system, but also on the number of methodology, interfaces, and other dependencies to other systems and their environment. Figure 1 gives a rough idea of the exponential- growing complexity coupled with the project size. Adding to the factors previously mentioned. It?s so hard to collect useful and essential information from this kind of enterprise complex data environment.

DOI 10.1109/SERA.2009.22    DOI 10.1109/SERA.2009.22      Figure 1: Exponential-growing complexity coupled with the project size    B. Data Mining Driven Fishbone (DMDF) In this paper, Data Mining Driven Fishbone (DMDF) is  a new term that never exits before. This definition comes from both Fishbone conception and Meta data of Data mining. We can look ?Meta data? as cause in original fishbone conception and then the ?ingenious rules?, which come from data mining, delegate effect in original fishbone.

But in the fact, Meta Data driven fishbone is not the same as conventional Fishbone. At enterprise complex data environment, DMDF is being used to not only collect huge data and information from complex system but also process untreated data with using methodology of data mining.

DMDF also helps us to work on each cause of the sub data flow prior to finding the root ?cause?.

C. Data Mining and Data Mining Functionalities Data mining is an essential process where intelligent  methods are applied in order to extract data patterns. Data mining is the process of discovering interesting knowledge from large amounts of data stored in databases, data warehouses, or other information repositories.

Data mining has been used into different areas; many researches had been explored, for example: The study of query processing and data mining techniques for data stream processing has recently attracted the interest of the research community [3-4].

Functionalities of data mining are used to specify the kind of patterns to be found in data mining tasks. It can be classified into two categories such as Descriptive and Predictive. Descriptive mining task characterize the general properties of data in the database, whereas predictive mining task perform inference on the current data in order to make predictions. These functionalities are classified as follows:  ? Characterization and discrimination; ? Association analysis; ? Classification and prediction; ? Cluster analysis; ? Outlier analysis.



III. METHODOLOGY & FRAMEWORK OF FISHBONE-DATA MINING COMBINATION  A. DMDF Methodology & Architecture End-to-End DMDF diagram includes complex dataflow  and different processing component and improvements for numerous aspects in multiply level.

Figure 2: Integrated platform of DMDF   DMDF provides integrated platform as Fig. 2 display  and mixed methodology to support the whole life cycle of data mining with comprehensive methodology. Data preprocessing, data Classification, Association rule mining and Prediction are the foundation and linkage of the whole data mining process life cycle. DMDF supports combination of different mining component from strategy level, tactical level to abstractive level, and then re-engineered data mining process into execution system to realize reasonable architecture. At this diagram the relationship of this different important component will be explained clearly.

Consultants or experts kick off the DMDF in the first phase based on collecting the useful and helpful information for each sub-branch; call it sub-dataflow, which is different data category. And the next step is taking data preprocessing, in this stage data will be processed. DMDF provides powerful data mining process modeling and analysis functionalities and synchronizes the blueprint information with enterprise system data environment After Preprocessed, each sub-dataflow branches come to main branches of DMDF, the most important operation will be happened here, ARM (Association Rule Mining).  In realization phase consultants make the process model configured, classication and prediction is necessary. At the head of this kind of fishbone diagram, two or more utility will be pop up, for example ?Helpful solution? and ?Useful information? or something like this.

About the function of each component will clarify and make a description at the following.

B. The Implement of DMDF How to construct a Data Mining Driven Fishbone  diagram? Here are the various tasks involved in constructing this kind of Fishbone diagram:  1) Define the direction of the DMDF undergo The first step is fairly simple and straightforward. You  have to define the head which is knowledge discovered and abstract solution will be created by DMDF, but these solution and knowledge discovered are all fancied. Fig. 3 gives an intuitionistic description about ?Head of DMDF?.

This is an abstract step; usually the operator who is experienced in this area or is a genuine export will do this.

The leader of DMDF can moderate the whole process.

After the head is identified, the leader can start constructing the Fishbone diagram. Using a sheet of paper, leader defines the abstract solution in a square box to the right side of page. Draw a straight line from the left to the problem box with an arrow pointing towards the box. The problem box now becomes the fish head and its bones are to be laid in further steps. At the end of the first step, the Fishbone diagram looks like:   Figure 3: Head of DMDF   2) Brainstorm (Considering Data preprocessing  algorithm is suitable) Today?s real world databases are highly susceptible to  noisy, missing, and inconsistent data due to their typically huge size, often several giga bytes or more. To improve the quality of the data and efficiency, data preprocessing is introduced.

Real world data tends to be dirty incomplete and inconsistent. This technique can improve the quality of data, thereby improving accuracy and efficiency of the subsequent data mining process. It is an important step in the knowledge discovery process. Since quality decisions must be based on quality data. Detecting data anomalies, rectifying them early, and reducing the data to be analyzed can lead to huge payoffs for decision making.

There are a number of data preprocessing techniques.

They are:  ? Data Cleaning; ? Data Integration; ? Data Transformation; -- Data Reduction.

3) Identify the cause and the most important branch by considering the weight of each branch.

People have difficulty understanding how to structure the sub-dataflow by using different and a large number of data source. Sometimes it is useful to focus on logically related items of the data domain and to represent them in the Fishbone diagram, which will convey the meta data for the whole data mining process.

Categorize:  Data mining is an interdisciplinary field, the confluence of set of disciplines including database system statistics, machine learning, visualization, and information science.

When you apply the Data Mining Driven Fishbone technique to this area problem, the possible ?causes? are usually classified into four categories:  ? According to the Kinds of Database Mined Database system themselves can be classified  according to different criteria such as data models, each of which may require its own data mining techniques. If classifying according to the special types of data handled, we may have a spatial, time series, text, or world wide mining system.

? According to the Kinds of Knowledge Mined  It can be categorized according to the kinds of knowledge they mine, i.e., based on data mining functionalities, such as characterization, discrimination, association, classification, clustering, cluster outlier analysis, and evolution analysis. It can be based on granularity or levels of abstraction of the knowledge mined.

? According to the Kinds of Techniques Utilized  Data mining techniques can be categorized according to the degree of user interaction involved or methods of data analysis employed. A sophisticated data mining system will often adopt multiple data mining techniques or work out an effective integrated technique that combines the merits of a few individual approaches.

4) Receive the solution from DMDF  At the end of the session, Fig. 4 displays the structure of DMDF. Causes from each category were constructed as bonelets in the diagram. The team went about analyzing individual causes.

Figure 4: Data Mining Drive Fishbone  C. Methodology & Architecture of DMDF Data Mining Systems  Data mining is an essential process where intelligent methods are applied in order to extract data patterns. The architecture of data mining is shown in Fig. 5. The major components are described as follows.

Data Warehouse: This is one or a set of databases, spreadsheets, or other kinds of information repositories.

Data cleaning and Data integration techniques may be performed on the data.

Database: The database server is responsible for fetching the relevant data based on the user data-mining request.

Knowledge Base: This can be used to guide the search, or evaluate the interestingness of the resulting patterns. Such knowledge include concept hierarchies, used to organize attributes or attribute values into different levels of abstraction, knowledge such as user beliefs, which can be used to assess the pattern interestingness based on its unexpectedness may also be included.

Data Mining Engine: This is essential to the data mining system and ideally consists of set of functional modules for tasks such as characterization, association, classification, cluster analysis, evaluation, and deviation analysis.

Pattern Evaluation Modules: This component typically employs interestingness measures and interacts with the data mining modules so as to focus the search toward interesting patterns. It may use interestingness thresholds to filter out discover patterns. Alternatively, this module may be integrated with the mining module depending on the implementation of the data mining method used.

Figure 5: The major components of DMDF data mining system   Graphical User Interface: This module communicates  between the user and the data mining system, allowing the user to interact with the system by specifying the data mining query or task, providing the information to help focus the search, and performing exploratory data mining based on the intermediate data mining results.

D. Association Rule Mining of DMDF Association rule mining finds interesting association or  correlation relationships among a large set of data items, with a massive amounts of data continuously being collected and stored, many industries are becoming  interested in mining association rules from their databases.

The discovery of interesting association relationships  among huge amounts of business transaction records can help in many business decision making process, such as  catalog design, cross marketing, and loss-leader analysis.

Association Rule Mining [5-7] is a Two-step Process:   1) Find all frequent item sets. Each of these item sets  will occur at least as frequently as a predetermined minimum support count.

2)  Generate strong association rules from the frequent  item sets. These rules must satisfy minimum support and minimum confidence, it is the easiest process of the two methods. So, the overall performance of mining association rule is determined by the first step.

? Finding Frequent Item sets Using Candidate  Generation The Apriori algorithm is an influential algorithm for  mining frequent item sets for Boolean association rules.

This algorithm uses prior knowledge of frequent item set properties. Apriori employs an iterative approach known as level-wise search, where k item sets are used to explore (k+1) item sets. It also improves the efficiency of level-wise generation of frequent item sets, which is an important property and is called Apriori property and it is used to reduce the search space.

? Mining Frequent Itemsets Without Candidate Generation In many cases, the Apriori candidate generation  and test method reduces the size of the candidate sets significantly and leads to good performance gain.

Iceberg Queries is the Apriori algorithm can be used to improve the efficiency of answering iceberg queries.

Iceberg queries are commonly used in data mining, particularly for market basket analysis. This query computes an aggregate function over an attribute or set of attributes in order to find aggregate values above specified threshold.

E. Smart Prediction of DMDF Classification and Prediction are essential steps in Smart  Prediction of DMDF. Databases are rich with hidden information that can be used for making intelligent business decisions. Classification and prediction are two forms of data analysis that can be used to extract models describing important data classes or predict future data trends. Whereas classification predicts categorical labels, prediction models continuous-valued functions.

1) Data Classification.

It is a two-step process and in the first step, a model is  built by describing a predetermined set of data classes or concepts. The model is constructed by analyzing database tuples described by attributes. Each tuple is assumed to belong to a predefined class, as determined by one of the attributes, called the class-label attribute. The data tuples analyzed to build the model collectively form the training data set. The individual tuples making up the training set are referred to as training samples and are randomly selected from the same population. Since the class label of each training sample is provided, this step is also known as supervised learning.

In the second step, the model is used for classification.

First, the predictive accuracy of the model is estimated. The hold-out method is a simple technique for estimating classifier accuracy that uses a test set of class-labeled samples. These samples are randomly selected and are independent of the training samples as shown in Fig. 6. The accuracy of a model on a given test set is the percentage of test set samples that are correctly classified by the model.

For each test sample, the known class label is compared with the learned model?s class prediction for that sample.

Figure 6: Training samples  2) Prediction The prediction of continuous values can be modeled by  statistical techniques of regression. Many problems can be solved by linear regression, and even more can be tackled by applying transformations to the variables so that a nonlinear problem can be converted to linear one.

Linear and Multiple Regression: In linear regression, data are modeled using a straight line. It is a simplest form of regression. Bivariate linear regression models a random variable, y (response variable), as a linear function of another random variable, x (predictor variable)  Y = ? + ?x                                                                (1) Where the variance of y is assumed to be constant, and  ? and ? are regression coefficients.

Multiple Regression: It is an extension of linear regression involving more  than one predictor variable. It allows response variable y to be modeled as a linear function of a multidimensional feature vector  Y = ? + ?1X1 + ?2X2                                              (2) The method of least squares can also be applied here  to solve for ?, ?1, ?2.

Nonlinear Regression  Polynomial regression can be modeled by adding polynomial terms to the basic linear model. By applying transformation to the variables, we convert the nonlinear model into linear one that can then be solved by method of least squares.

Other Regression Models Linear regression is used to model continuous valued functions. It is widely used, owing largely to its simplicity.

Generalized linear model represent the theoretical foundation on which linear regression can be applied to the modeling of categorical response variables. Common types of generalized linear models include logistic and poisson regression. Logistic regression models the probability of some event occurring as a linear function of set of predictor variables. Count data frequency exhibits a poisson distribution and is commonly modeled using poisson regression. Log linear models approximate discrete multidimensional probability distribution. They may be used to estimate the probability value associated with the data cube cells.



IV. CONCLUSION The effort of Data Mining Driven Fishbone research  enables data mining process is much more intuitionistic and easier through an integrated and combinative ?Fishbone? architecture ,also data mining enhance the function of original fishbone conception. At enterprise complex data environment, the requirement of useful, accurate and predictive information will be needed than ever before, so DMDF provides both methodology and tool covering from strategic analysis, tactical policy design ,to data flow direction.

However, as we start our research with the purpose of improving the architecture of the data mining process and much more comfortable understanding, it?s hard for DMDF to be used universally at the first phase. Besides, more industry insights and experience gained from real data mining system and Data collection system are in need to feed back to research and further enhance DMDF.

