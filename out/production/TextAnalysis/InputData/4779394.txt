Ontology Driven Content Mining and Semantic Queries for Satellite Image Databases

Abstract?Extracting domain-specific knowledge from image databases is challenging and requires a deep understanding of the domain. For example, in the geospatial domain knowledge discovery computationally expensive due to the huge amount of generated imagery. Existing content-based image retrieval systems utilize models that are trained and optimized to experts? knowledge using expert-in-the-loop approaches. However, such approaches may lead to suboptimal models especially when the number of training images is small. In this paper, we propose incorporating existing domain knowledge resources into knowl- edge discovery. More specifically, we have developed methods for using ontological relationships between geospatial semantics to oversample under-represented semantics. Our experimental re- sults show that our technique improves the knowledge discovery process, as evidenced by increased precision of semantic queries.



I. INTRODUCTION  The increasing size of domain-specific image databases makes access to relevant knowledge difficult. To fully exploit these databases, analysts must increasingly rely on computa- tional techniques for knowledge discovery. Existing content- based methods utilize models that are often optimized to experts? knowledge in training processes which have resulted in certain degrees of success. However, manual image labeling is expensive and dependent on the perceptual subjectivity of the image analysts. If only a small number of labeled images are provided during training, overfitting may occur leading to poor generalization performance [1].

Many content-based supervised learning algorithms, such as associative learning [2][3][4], divide the continuous feature space into smaller hyper-rectangular partitions by applying discretization algorithms. These partitions are used as items in defining associations between feature values and semantics.

The main issues for associative learning methods are: (1) mining complexity, which is exponential with respect to the number of generated items [5], and (2) data fragmentation, as the learning performance may decrease with smaller par- titions that contain less training transactions which result in association rules with less statistical significance [6].

Both complexity and fragmentation are key issues when association rule mining algorithms are applied to datasets that have an unbalanced label distribution [1]. An unbalanced label distribution affects knowledge discovery as either the minority  label is ignored or the model is overfitted to the training data.

In either of these cases the resulting model will have high error rate for newly discovered cases. One of the most common techniques for dealing with unbalanced datasets is resampling [7][8][9]. It minimizes unbalance by altering the distribution of training data. In content-based knowledge discovery, existent oversampling techniques may lead to suboptimal performance since images are likely to share multiple semantics.

In this paper we explore methods for optimizing knowledge discovery in geospatial information systems using domain ontology. An ontology describes a catalog of semantics and their relationships from the perspective of domain experts [10]. It can provide additional knowledge needed in supervised learning with an unbalanced label distribution. In this article, we are interested in improving the quality of knowledge ex- tracted from unbalanced geospatial image databases by using existent domain ontology to oversample the training data. We evaluate this improvement using precision-recall measures of semantic query results. This paper is organized as follows.

Section II summarizes the previous work in this area. Section III presents our approach for semantic customization. We then evaluate the performance of the model in Section IV, and conclude the paper in Section V.



II. PREVIOUS WORK  Most content-based algorithms use the similarity between two training instances to create prediction models that can be applied to newly discovered cases [11]. For example, associative learning techniques create associations between feature subspaces and semantic labels. To address complexity issues, approaches use the support and confidence thresholds to prune the number of candidate association rules. The support defines the percentage of records that contain the association while the confidence is the ratio of support of the rule to that of its antecedent. Such an approach may be sufficient for datasets with balanced label distribution. However, it is well known that association rule mining performs poorly in the case of an unbalanced label distribution [1].

Knowledge discovery from image databases with unbal- anced label distribution is a common task in the geospatial domain. For example, in our dataset, lake is under-represented since less than 1% of the images contain this semantic. Also,     Fig. 1. Example of geospatial ontology based on the Cyc ontology. ?is a? relations are depicted with continuous line while ?part of? relations are depicted with dotted line. The numbers in parenthesis show the number of images in the training set that contain that semantic concept.

residential is over-represented because more than 34% of the images contain this semantic. An unbalanced label distribution affects knowledge discovery in two ways: First, minority semantics are ignored since generated item sets from these labels rarely pass the support threshold; Second, knowledge models tend to overfit with respect to the training dataset, resulting in high error rates for newly discovered cases.

Resampling methods address the issue of unbalanced labels by altering the distribution of training samples. The under- sampling method proposed in [7] removes noisy, borderline, and redundant majority training instances. The undersampling approach in [8] uses a kNN approach to remove samples from the majority samples that are close to minority samples. The SMOTE oversampling technique [9] adds minority samples on the lines between minority samples. Although resampling methods have been proven to increase classification accuracy, they also have drawbacks. Undersampling may degrade system performance by potentially discarding useful majority-class examples, while oversampling may lead to overfitting and lower time efficiency [9].

In the geospatial domain, oversampling is preferred over undersampling due to the high cost of expert-in-the-loop processes. However, oversampling with SMOTE may result in suboptimal knowledge models since multiple semantics may coexist in the same satellite image. To address this issue, there is a need to incorporate other knowledge sources, such as an ontology, into the knowledge discovery process. An ontology is a shared vocabulary used to describe a domain of interest as well as assumptions about their intended use [10]. It captures declarative knowledge by defining domain concepts and their relations to other concepts from the perspective of the domain experts. Because an ontology represents abstract and simplified domain knowledge, it can be used in data mining processes to compensate for missing domain knowledge from experts.



III. METHOD  The idea of our approach is to adjust the concept of similarity by incorporating ontological domain knowledge.

Fig. 2. Example of semantic distribution for a satellite image in a 2-d feature space. (a) the minority semantic lake is a visual pattern that can be part of grassland, farmland or forest, (b) example of oversampling using the SMOTE algorithm, (c) example of oversampling using our proposed algorithm, and (d) the corresponding subset of the ontology shown in Figure 1.

This can be achieved by using an existing ontology to create an ontology feature space that will be used to oversample the training dataset. For this article, we have used an ontology for the geospatial domain based on the Cyc knowledge rep- resentation [12]. A fragment of this ontology is depicted in Figure 1. In this figure, each ontological concept is depicted by a rectangle while relationships between concepts shown as lines. There are two types of relationships in this figure: ?is a? (in continuous line) and ?part of? (dotted line). The example in Figure 1 also shows the number of training images that were labeled with each semantic, in parentheses.

Let ? be the number of relationships in ontology O and p ? [1, ?] a unique identifier assigned to each relation- ship. In the ontological feature space, each semantic ? is characterized by a set of ? different measurements FO? = (fO,?,1, fO,?,2, . . . , fO,?,?). Each fO,?,p is calculated using the following equation:  fO,?,p =  ?? ?  0 if ? = root(O) w  depth(child(p)) if p ? path(?, root(O)) 0 else  (1) , where depth(p) is the depth of p in O, child(p) is the child concept of relation p, root(O) is the root concept in O, and w is a weight that depends on the characteristics of the dataset.

For this work we set w to the proportion of the maximum distance in the feature space to emphasize the importance of ontological relationships among semantics. For the example in Figure 2(d), the ontological feature space for semantic  III - 504    lake is, without loss of generality, FOlake = (0, 0.7, 0, 0.35, 0) where the non-zero elements correspond to the path between the semantic lake and the root of the subset of the ontology (natural area). The projection of the feature space is outlined in Algorithm 1. In the first step, we create the ontological feature space as shown from lines 2 to 5. Then, from lines 6 to 8, we append the ontological feature space to the feature space according to the semantic of each training instance. For example, using a 227D feature space and an ontology with 19 relationships, will result in a 246D projected feature space.

Algorithm 1: PROJECT Input : Feature Space F , Semantic Vector S,  Ontology O Output: Higher dimensional training dataset FO R ? relations in the ontology O;1 foreach ? ? S do2  FO? ? array[ |R| ]; ? ontological space for ?3 for r ? 0 to |R| do4  FO? [r] ? fO,?,r; ? see Equation 15 foreach feature vector f ? F do6  F pf ? Ff ? FO? | ? is the label of f ;7 F p ? F p ? F pf ;8  return F p;9  Our oversampling method is shown in Algorithm 2. The first step is to project the feature space for the training dataset into a higher feature space that includes the ontological feature space (line 2). After projection we apply the SMOTE algorithm (line 7) to all the under-represented semantics (line 6) and reproject into the initial feature space (line 8). The resulting oversampled feature space is then used for association rule mining and semantic ranking. For association rule mining , we use a framework that maps domain semantics into low-level feature spaces [13]. This framework uses association rules, r, to map a feature space, F , into a semantic space, S. Each rule has the form r = (a, c, ?, ?) where a, is the antecedent, c is the consequent, ? is the support of the association rule, and ? is the confidence of the rule. The consequent is a semantic term: c = ? | ? ? S. The antecedent, a = {g?(m)}, is defined as a set of functions g : ? ? [0, 1] associated with the measurements, m, of the feature ? ? F .

g(m) =  ????? ????   1+e((? L ?m)/?2L)  ?3 L  for m < ?1L  1 for m ? [?1L, ?1R ]   1+e((m?? R)/?2R)  ?3 R  for m > ?1R  (2)  The function g, shown in Equation 2, is defined as a piecewise function composed of a constant and two sigmoid functions. The sigmoid functions are centered at ?1L and ?  R  with widths ?2L and ? R , and exponential factors ?  L and  ?3R. For indepth information about the semantic modeling procedure, the reader is referred to [4].

Algorithm 2: OVERSAMPLE Input : Feature Space F , Semantic Vector S,  Ontology O Output: The oversampled training dataset F r  d ? dimensionality of F ;1 F p ? PROJECT (F, S, O);2 foreach ? ? S do3  F? ? FP | label = ?;4 cnt? ? number of training samples for ?;5 if cnt? < |FP |/|S| then6  F? ? SMOTE(F p) | label = ?;7 F? ? first d feature values in F? ;8  F r = F r ? F? ;9 return F r10  The advantage of our oversampling method is shown in Figure 2(c) where ontologically related neighbors closer in the feature space are selected over neighbors that are labeled with same semantic but are farther away in the feature space. Figure 2(a) shows an example of an unbalanced label distribution from the geospatial domain. In this example, the minority label lake (circle) is likely to appear together with forest (triangle), farmland (square), or grassland (hexagon).

Figure 2(b) shows an example of oversampling with SMOTE. For highly under-represented semantics, such as lake, the synthetic samples will be created between two minority samples with different coexisting semantics, leading to the population of subspaces that are not relevant to the minority semantic. For example, the training sample 1 labeled lake is closer to the sample 3 labeled forest than sample 2 labeled lake. This results in oversampled training sets that better preserve the local characteristics of the feature space.



IV. EXPERIMENTAL RESULTS  We designed a ten-fold validation experiment on an image database containing 834 geospatial image tiles from Missouri.

For each image tile, feature extraction algorithms [13] are applied to form a 227-dimensional feature vector. These im- ages were labeled by experts to include one or multiple labels from the following set: Commercial, Industrial, Residential, Grassland, Cropland, Forest, Lake, Quarry, or Highway and has the label distribution shown in Figure 1. A total of 221 images in this dataset were labeled with multiple labels.

Association rules were mined using a threshold of 1% for support and 50% for confidence with 80% of the images used for training and 20% for testing. Testing images were ranked using the procedure described above in three different scenarios: (1) no oversampling, (2) SMOTE oversampling, and (3) our proposed oversampling approach. For each of these approaches, we computed the precision-recall measures.

Figure 3 shows the average precision for semantic retrieval when no oversampling was used. As seen in this figure, no rules were generated for the under-represented semantics  III - 505    Fig. 3. Precision-Recall chart for ranking geospatial images without oversampling of the training dataset. Due to the small number of images in the training set, the algorithm did not generate any association rules for the semantics Highway (HWY), Lake (LK), or Quarry (MNQR).

Fig. 4. Precision-Recall chart for ranking geospatial images after applying the SMOTE oversampling of algorithm.

Highway (HWY), Lake (LK), or Quarry (MNQR). This result was expected since the total number of training transactions for these semantics was close to the support threshold. Figures 4 and 5 show the ranking precision when using the SMOTE algorithm and our proposed approach, respectively. As seen in these figures, our oversampling method resulted in better precision for under-represented semantics. Also, both methods maintained similar precision levels for the over-represented semantics.



V. CONCLUSION AND FUTURE WORK  Knowledge discovery with data mining techniques alone might lead to overfitted models with poor predictive power.

Our approach uses declarative knowledge from a domain on- tology in the discovery process to provide a better description of geospatial visual patterns to improve knowledge discovery and representation in the this domain. Our future work includes researching methods to use ontological knowledge in the  Fig. 5. Precision-Recall chart for ranking geospatial images after applying the proposed oversampling of algorithm.

mining process to improve the accuracy of retrieval results.

