FOntGAR Algorithm: Mining Generalized  Association Rules Using Fuzzy Ontologies

Abstract? Most of the works in mining generalized association rules under fuzzy taxonomies are focused on the pre-processing stage, using the concept of extended transactions. A great problem of these transactions is related to the generation of huge amount of candidates. Beyond that, the inclusion of ancestors in database transactions ends up generating redundancy problems. Besides, it is possible to see that many works have directed for the question of mining fuzzy rules, exploring linguistic terms, but few approaches have explored new steps of mining process. In this sense, this paper proposes the FOntGAR (Fuzzy Ontology-based Generalized Association Rules Algorithm), a new algorithm for mining generalized association rules under all levels of fuzzy concept ontologies. In this work the generalization is made during a post-processing stage. Other relevant points of this paper are the specification of a new approach of generalization; including a new grouping rules treatment, and a new and efficient way for calculating both support and confidence of generalized rules.

Keywords?-Generalized Association Rules, Fuzzy Ontologies, Fuzzy Taxonomies,  Post-Processing.



I. INTRODUCTION The mining association rules is a important task in data  mining [1]. In traditional algorithms, like Apriori, the rules are generated only based on database items. This characteristic implies an excessive amount of rules.

In this sense, there are algorithms using domain knowledge, represented via taxonomies, in order to obtain general rules, facilitating the user?s analysis. The association task using taxonomic structures is called mining generalized association rules, and was introduced by [2] and [3].

According to [2], ancestors of taxonomy are inserted into database transactions, which is why they are called extended transactions. Then, from these extended transactions, an algorithm is applied for extract the final set of patterns, which can be composed of traditional rules and generalized ones.

This methodology can be advantageous, however, the inclusion of ancestors results in the generation of many candidate itemsets, in addition the algorithm ends up generating redundant patterns, making it extremely necessary the use of specific measures for eliminate redundancies.

On the other hand, some works, like [4] for example, show that the post-processing can be more advantageous,  because few candidates are generated. Moreover, to realize the generalization during this stage eliminates the need of measures used for prune redundant patterns, since the process is made based on the traditional rules generated.

However, in many applications of the real world ontologies and taxonomies may not be crisp, but fuzzy [5].

This occurs because some applications do not have object classes with pertinence criteria precisely defined [6].

In this context, Wei and Chen [5] introduced the mining generalized association rules under fuzzy taxonomies. They consider the partial relationships possibly existing in taxonomy, where an item may partially belong to more than one parent item. For instance, tomato may partially belong to both fruit and vegetable with different degrees. Wei and Chen thus defined a fuzzy concept taxonomic structure considering extended degrees of support, confidence and interest measures for mining generalized association rules.

Posteriorly, in [7], they proposed an algorithm using linguistic terms.

However, most of the works are interested in to obtain generalized fuzzy association rules, which are the ones composed by linguistic terms, but few works have directed efforts for improve the mining generalized rules under fuzzy concept hierarchies, mainly in relation to the stage that they are used.

Thus, the objective of this paper is to introduce the FOntGAR algorithm for mining generalized rules, using fuzzy ontologies with specialization/generalization relationships varying in the interval [0,1]. Besides, this work introduces the first algorithm for mining generalized rules in the post-processing stage, using fuzzy taxonomic structures.

The generalization can be performed in all levels of fuzzy ontologies. This paper is organized as follow: Section two show some related works. In the section three, the FOntGAR algorithm is presented. The section four presents the experiments, and in the section five some conclusions are explained.



II. BACKGROUND Aiming to obtain generalized knowledge, the generalized  association rules, which are the ones composed by items contained in any level of a given taxonomy, were introduced by [2]. A generalized rule is an implication of the form A ?  U.S. Government work not protected by U.S. copyright  WCCI 2012 IEEE World Congress on Computational Intelligence June, 10-15, 2012 - Brisbane, Australia FUZZ IEEE    B, where A  I, B  I, A ? B = 0 and no item in B is an ancestor of any item in A.

There are many works using crisp taxonomic structures.

These works are different manly in function of the stage in which these structures are used, like the pre-processing or post-processing, for example.

In [9] the mining was done using an efficient data structure. The goal was to use the structure for find rules between items at different levels in a taxonomy tree, under the assumption that the original frequent itemsets and association rules were generated in advance. This approach is included in the post-processing stage.

Also in relation to the post-processing, [4] proposed the GARPA algorithm. That approach, unlike was proposed by [2], do not insert ancestor items in database transactions. The generalization is made using a methodology where rule items are replaced into taxonomy ancestors. This process obtains a set of generalized rules composed by some ones that could not be generalized and by generalized rules.

From a quantitative point of view, the GARPA algorithm is more advantageous than proposed by [2], because implies smaller amount of candidates, and consequently few rules generated, dispensing the use of measures used for pruning redundant rules.

Bay Vo and Bac Le [10] present a new algorithm for mining generalized association rules. That work is included in the crisp context. The authors develop an algorithm that scans the database one time only and use a Tidset to compute the support of generalized itemset. A tree structure is developed to store the database for mining frequent itemsets.

According to Baralis et al [11], extraction, driven by support and confidence constraints, entails (i) generating a huge number of rules which are difficult to analyze, or (ii) pruning rare itemsets, even if their hidden knowledge might be relevant. So, was proposed an algorithm that exploits a crisp taxonomy to drive the pruning phase of the extraction process and extract generalized itemsets. Instead of extracting itemsets for all levels of the taxonomy and post-pruning, like [3], it generalizes an itemset only if the itemset at a lower level in the taxonomy are below the support threshold.

In relation to the fuzzy context, according to Wei and Chen [5], the degree  which any node y belongs to its ancestor x can be derived based upon the notions of subclass, superclass and inheritance, and may be calculated using the max-min product combination. Specifically,  max:   min   (1)  Where l:    is one of the paths of attributes x and y, e on l is one of the edges on access l,  is the degree on the edge e on l. If there is no access between x and y, 0.

The degree of the extended support (Dsupport) is calculated based on this . If a is an attribute value in a certain transaction t   T, T is the transaction set, and x is an attribute in certain itemset X, then the degree  can be viewed as the degree that the transaction {a} supports x.

Thus, the degree that t supports X may be obtained as follows: min max                     (2)  Furthermore, an ?  operator is used to sum up all degrees that are associated with the transactions in T, in terms of how many transactions in T support X:           (3)  Thus, the support of a generalized association rule X ? Y, let X  Y = Z ? I, can be obtained as follows, where | | is the total of transactions in the database: / | | (4)  Similarly, the confidence (X ? Y), called Dconfidence, can be obtained as follows: /   (5)  Angryk and Petry [12] investigated the application of fuzzy hierarchies for mining multi-level knowledge from large datasets via an attribute-oriented approach. Cai CH et al. [13] proposed a fuzzy multiple-level mining algorithm for extracting implicit knowledge from transactions stored as quantitative values. The proposed generalized fuzzy mining algorithm was based on Srikant and Agrawal?s approach to find fuzzy interesting rules. The items may be from any level of the given taxonomy.

Chiu et al. [14] proposed a mining algorithm for mining generalized fuzzy association rules from transaction database based on the hierarchical relationships and cluster-based fuzzy sets tables. Differently than [5], this approach do not consider taxonomies with partial relationships, but they are interested in how separate the clusters in fuzzy sets, obtaining fuzzy association rules.

The work [15] introduces an algorithm for update the discovered frequent generalized itemsets. As well as [5], and our work, the paper [15] also explore fuzzy taxonomies with partial membership degrees, however, the taxonomy  of items cannot be kept unchanged, some items may be reclassified from one hierarchy tree to another for more suitable classification, for example. In [15] generalized rules are obtained like proposed in [2], where was made the use of extended transactions, as well as [5] and [7].

Some works, like [16] and [17] are directed to the semantic of data. Such algorithms use ontologies for extract similarity associations between the database items. Such relations are represented at the ontology leaves. So, the authors say that the ontologies used are fuzzy; however, except by inclusion of similarity, they are crisp in essence, since the specialization/generalization degrees are constant 1, like crisp ontologies.

The work [17] is an extension of [16], where the main differences are the introduction of a redundancy treatment and a step of generalizing non-frequent itemsets. However, both algorithms are limited, since generalizes in only one level of ontology (leaf nodes to parents).

Thus, as was demonstrated, there are few works dealing with mining generalized association rules under fuzzy concept taxonomies. Most of the works are inserted in the line of mining generalized fuzzy association rules, which is a concept smoothly different, since in this case the fuzzy generalized rules may contain linguistic terms, such as young, tall, and others. In such approaches are used crisp taxonomies and the linguistic terms are generated based on fuzzy intervals, which are normally generated through clustering. Besides, such works are directed for explore quantitative or categorical attributes.

Furthermore, it is possible to see a bias, which is the realization of the generalization process as presented in [2], exploring taxonomies during the pre-processing stage, thought extended transactions. In this sense, considering the concept of fuzzy taxonomies presented in [5], no work to date was done for obtain generalized rules in the post- processing stage.

Besides, we have other two main motivations for generalize during this phase: the first is the reduction of generated rules amount, since previous crisp work, like [4] for example, show that this is possible. We cannot say that few rules are always most interesting; however, in many cases where the user is interested in a more general knowledge, a great quantity of rules may be inconvenient. So, will be more advantageous an algorithm that generates general rules. The second motivation is the eliminating of redundancy problems without the use of interest measures, which are very subjective. Such problem is commonly derived from the use of extended transactions.

However, in the post-processing stage, one of the challenges of getting generalized rules under fuzzy taxonomies is related to the calculating of both support and confidence of rules, which should be extended to fuzzy context. Besides, the number of database scans is a very important question, because it may to affect the runtime of the algorithm. That problem is directly related to calculating of support. Posteriorly, in the section three we will present our algorithm, and in section four we will explain some of these considerations.



III. THE FONTGAR ALGORITHM The aim of the FOntGAR (Fuzzy Ontology-based  Generalized Association Rules) algorithm is post-process a set of specialized association rules (AR) using fuzzy ontologies, in order to obtain a reduced non-redundant and more expressive set of generalized rules, facilitating the user?s comprehension. The Figure 3.1 illustrates all the steps of and the Figure 3.2 shows the pseudo-code of the generalization treatment. The steps colored in grey are the main points explored in our algorithm.

A. Main ideas The process of generating traditional association rules is  based on Apriori [18], and as an mining association rule algorithm, it needs of an user-provided minimum support and minimum confidence parameters to run. Moreover, it need of a minGen and a side parameters:  ? minsup, which indicates the minimum support; ? minconf, which represents the mininum confidence; ? minGen, which represents the minimum quantity of descendants in different specialized rules; ? side, which represents the side to be generalized;  The minsup, minconf and minGen parameters are expressed by real value in [0,1]. The side parameter is expressed by a string value left, right or lr, indicating the generalization side. The generalization can be made on one side of the rule (antecedent or consequent) or both sides (lr: left right side). While the left side indicates relations between classes of items and specialized items, the right side indicates relations between the specialized items and classes of items. The lr side indicates relations between classes.

The generalization is made through a sub-algorithm that uses a grouping methodology, where two or more rules are grouped in order to be replaced by a unique generalized rule.

Several groups can be generated, and the grouping is done based on both side parameter and fuzzy ontology. In this case, when compared, two or more rules having identical parents in the generalization side are grouped in a same group. It is important to say a group is generated only if two or more rules can be grouped, because it is not reasonable generalize a unique rule. As several groups may be generated, various generalized rules may be obtained.

During the grouping, the analyzed ancestors are the immediate ones of rule items, which are the ancestors present in the current level of generalization. At first, the patterns used during the generalization are the traditional ones generated by the extracting patterns stage. Posteriorly, the obtained generalized rules are used for obtain a new set of generalized rules. Thus, it is a recursive process.

The side parameter indicates the generalization side.

When this parameter is left or right, if two or more rules have the same elements in the opposite of side, and have elements with identical parents in the generalization side, then they are placed in a same group.

For example, supposing ontology of bread and milk, where bread is a breadA, breadB, breadC, breadD, breadE, and milk is a milkA, milkB milkC. Suppose the algorithm generates, during the extracting patterns stage, a set of traditional rules milkA ? breadA, milkA ? breadB, milkA ? breadC, which are the ones composed only by leaf nodes.

As all rules have the same elements in antecedent side (the opposite of side) and also the parent of consequent items (generalization side) is the same, these rules will be grouped together.

Figure 3.1 ? Steps of the FOntGAR.

Figure 3.2 ? Pseudo-Code of the generalization treatment.

When the side parameter is lr, if two or more rules have items with the same parents in both antecedent and consequent side, then will be grouped together. For example, considering the traditional rules milkA ? breadA, milkB ? breadB, milkC ? breadC, as all rules have the same parents in both antecedent and consequent, these rules will be grouped together.

An important point is that generalized rules can be generated without the use of all descendants in a rule. In this sense, for avoid an over-generalization, a set of specialized rules in a group can be substituted only by a more general rule if a minGen parameter [17] was satisfied. Consider that the minGen value is 0.6 (60%), and the side is lr, the rule milk ? bread will be generated even if there is no rule for each kind of bread and milk in the current group, but only if 60% of descendants of bread and milk are present in this set of rules.

Assuming that a generalized rule contains summarized information, the analysis of the rule milk ? bread could be affected, since this rule does not cover all kinds of bread and milk. Thus, the use of minGen can to produce a semantic loss. In this sense, in order to guide the user?s comprehension, the algorithm shows the items which have not participate in the generalization process. For example, suppose breadE is not present in the specialized AR set, the generalized rule are shown as milk ? bread (-breadE), indicating the item breadE did not compose the generalization.

The use of ontologies was done because these structures allow more formalism and power of inferences, ensuring also superior semantic enrichment. In our research, for represent the fuzzy ontologies, we follow the meta-ontology proposed in [19], which is considered an upper ontology as it  represents fuzzy constructs to be inherited and/or instantiated by specific domain ontologies.

Such ontology is based on OWL DL [20], a W3C recommendation supported by several reasoners and application programming interfaces used to develop ontology-based applications. Figure 3.3 illustrates how to model a fuzzy class, considering an example of domain ontology that inherits and instantiates fuzzy constructs of the upper ontology. In Figure 3.3, instances are colored in grey, fuzzy constructs are identified by the fuz: prefix and domain- specific ontology elements contain the veg: prefix. Instances of the fuz:FuzzyConceptMembership class are responsible for associating domain ontology individuals that have a membership degree 0<?<1 to their correspondent fuzzy classes. In Figure 3.3, the veg:tomato belongs to the veg:Fruit class with a fuzzy degree 0.7.

Figure 3.3 ? The fuzzy meta-ontology.

B. The algorithm step by step First, through the equation 1 of the section two, the  ontology reasoner is used to infer the membership degrees of the leaves in relation to the ancestors. The degrees are stored in a data structure. The steps of data scanning, generating candidates and generating rules are done similarly to the Apriori algorithm.

At end of generating rules we have a set of specialized ones, which will be used in the generalization treatment. So, such rules are passed for the ontologyVerification function (line 5 of the Figure 3.2), which uses the ontology reasoner for locate all parents of items contained in the rules. So, the result of ontologyVerification, the generated rules and the generalization side are used as input in the groupingRules function (line 7), which is responsible by the grouping treatment mentioned above.

Posteriorly, for each group generated, all rules in a group are represented by a more general one (line 10). So, the minGen parameter (line 11) is checked, it is verified if antecedent ? consequent = 0 and if no consequent item is ancestor of any antecedent item (line 12). If such verifications are satisfied (line 13), the calculus of support is made. If the general rule is not frequent then the generalization is not made. In this case, if the generalization is 1 (line 19), the rules of the corresponding group are inserted in the result. But if the general rule is frequent, the rules of the corresponding group are replaced, and the same is inserted in the result.

After that, if there are generalized rules, the same are used in the next level of generalization. If this situation is true for all next levels, the generalization process will be done until a level below the ontology root. However, if there is no generalized rule at a certain level, then will be impossible to generalize in the next levels and the generalization process is concluded. All non-generalized rules are shown in the result.

Finally, after the generalization treatment, the algorithm enters its final stage, which is the results generation. In this step FOntGAR shows to the users all generalized rules separated by level. In addition, FOntGAR also shows the rules that were not generalized under the ontology levels.

C. Calculating the degrees of support and confidence Considering the fuzzy taxonomy of Figure 3.4, Fruit ?  Meat is a generalized rule and {Fruit, Meat} is their itemset format. The support of this rule is calculated based on the sum of all degrees of transactions that support simultaneous occurrences of {Fruit, Meat}.

However, {Fruit, Meat} is obtained and known only during the post-processing. Then, for obtain the degree of each transaction in relation to {Fruit, Meat}, would be necessary a new scanning in the database. As many generalized rules may be generated, the quantity of new scans also may be huge, and depending on the quantity of database rows, the performance would be affected.

In order to allow the calculating of support in the post- processing, avoiding additional scans in the database during the calculus, we used two data structures (Figure 3.4 and Figure 3.5). The structures are composed by keys and values. They are constructed during the 1-itemset generation, while the database is scanned.

In the Figure 3.4, a key can be an database item or ontology ancestor.  Each key is linked in a value, which is a vector storing the identifiers of the database transactions where the key appear.

Several approaches using data structure similar to that, the work [10] is an example. Some works call it of database in a vertical format, since they use only database items.

However we are also considering the inclusion of ancestor items. It is important to say the structure allows an indexed access to data, unlike of the database scans. The equation used in the calculating of support is derived of the Equation 2 (section two). So, if we partitioned the same in two subparts (Part 1 and Part 2), we have:  ? Part 1 = max ? Part 2 = min    .

As said we can have many generalized rules, but we do not know what will be generated, and the itemset format of each may be any X = { , ? , }, where X is the generalized rule, and , ? ,  are the rule items.

That way, during the first database scan, we do the computation of Part 1, which is the degree that each transaction t supports an ontology ancestor x. Note that x may be present in X. Based on the results of Equation 1, found out at beginning, these degrees are calculated and stored in a data structure (Figure 3.5), where a key is the ancestor x (which will be present in generalized rules), and each key points a value, which is a vector storing the degrees mentioned.

Thus, since the result of Part 2 correspond to the min operator for the degrees related to any rule { , ? , }, whatever the itemset format obtained of X, we use the stored degrees of , ? ,  for calculating the Part 2, obtaining the support of any generalized rule.

An important point is that if 0 the transaction does not supports , then the degree  is not stored in the vector. Thus, each vector linked in a key of the Figure 3.4 has the same quantity of positions of the vector linked in the same key of the Figure 3.5.

Besides, in such vectors the values of correspondent positions are related. For example, through Figure 3.4 we can see that the key Fruit is present in three transactions, T1, T2 and T4. Then, from the Figure 4.5 we can infer that the degree which T1, T2 and T3 support Fruit is 1, 0.7 and 0.7, in the same order.

Figure 3.4 ? Data structure used for store items and ancestors.

Figure 3.5 ?Data structure used for store de degrees of transactions.

Now, we will to present an example about how calculate the support of the rule Fruit ? Meat. The algorithm uses the structure shown in the Figure 3.4 for verify the quantity of transactions on the intersection of values stored in vectors of these keys, since this represents all simultaneous occurrences of Fruit and Meat in the dataset transactions.

Figure 3.6 illustrates this idea. In this case we have two occurrences of {Fruit, Meat}.

Thus, in relation to each key of Figure 3.4, the algorithm uses the positions of these transactions to found the degree which each supports the ancestors. Such degrees are in the same positions of the vectors linked at Fruit and Meat in Figure 3.5.

In this case we have: Fruit: 0.7/T2, 0.7/T4; Meat: 0.6/T2, 1/T4, which are results of Part 1. Based on these degrees, we use Part 2 for calculate the , where X is {Fruit, Meat}.

For T2 we have:  min    1 min 0.7, 0.6 0.6 For T4 we have:  min    1 min 0.7, 1 0.7 So, according to Equation 3, we have 0.6 + 0.7 = 1.3.

Furthermore, the Equation 4 is used to calculate the support, which is 0.21. Although we presented a specific example, the process applies to any rule.

Figure 3.6 ? Representation of idea used in the calculating of support.



IV. EXPERIMENTS This section show some experiments performed to  validate the FOntGAR algorithm. Two real datasets were used. The first dataset (DB-1) contains information about Years of study, Race or ethnicity and Sex, and was provided by Brazilian Institute of Geography and Statistics (IBGE).

DB-1 contains 10000 transactions with 12 distinct items.

The second data set (DB-2) contains a one day sale of a supermarket located in S?o Carlos city. DB-2 contains 1716 transaction with 1936 distinct items.

Based on the meta-ontology describes above, two fuzzy ontologies were created, one for the DB-1, called Ont-1 ontology, and other for the DB-2, called Ont-2 ontology.

The Ont-1 was constructed contained two level of abstraction, and Ont-2 was constructed with five levels of abstraction. In both ontologies the average value of specialization/generalization degrees was 0.8. Both Ont-1 and Ont-2 were modeled in OWL (Web Ontology Language) and the Jena Framework was used to allow navigation through ontology concepts and relations. Besides, a crisp taxonomy (corresponding to the Ont-2), and a crisp ontology (corresponding to the Ont-1) were created.

In order to compare and illustrate the performance of FOntGAR, the experiments were carried out with respect to two major aspects. First, with the DB-1, the GARPA algorithm [4] under the corresponding crisp taxonomy, NARFO [17] under the corresponding crisp ontology and FOntGAR algorithm under the Ont-1 were run. The purpose was to show what the effect of fuzzy extensions could be. In this comparison, two experiments have been conducted.

Second, with the DB-2 and Ont-2, the FOntGAR was executed. The purpose was to show how the generalization treatment could improve the reduction of the amount of rules. This experiment checks the compaction rate, which represents the percentage of reduction in the volume of rules. For example, considering a total of 1800 rules          obtained (generalized rules and non-generalized rules) from a total of 3500 rules, the compaction rate is 48,57% (((3500- 1800) /3500) * 100).

A. Comparison between FOntGAR, NARFO and GARPA In this comparison we performed 2 experiments with real  data and taxonomic structures mentioned above, changing a different parameter in each experiment. The experiments were done with default values of parameter, except for the one being varied. By default, minsup = 0.02, minconf = 0.4 and mingen = 0.2. The side of generalization was set to lr in all algorithms.

Number of transactions: In Figure 4.1, the vertical axis is the average of scanning time per transaction (in milliseconds) in relation to first scan in the database. We varied the number of transactions from 2000 to 10000. From Figure 4.1 it is possible to see that the gap between FOntGAR, and NARFO show that the scanning with fuzzy ontologies is more time consuming than scanning with crisp ontologies. There are two reasons. First, the membership degree calculation demands more time. Second, the data structures generation contributes for increase the runtime.

However, we can see that the gap tends keep stable with the increase of the number of transactions. This shows that the computational complexity is linear with the number of transactions, which is the same as the crisp algorithm. The difference between the two curves turns to be constant.

Minimum degree of support: In Figure 4.2 we changed the minimum degree of support from 0.05% to 0.2%. The vertical axis is the total execution time in seconds. Notably, with the increase of minsup, the runtime of both FOntGAR and GARPA decreases. The reason is that when the minsup increases the amount of traditional rules decrease, and consequently a minor quantity of rules are post-processed.

However, we can see that GARPA consumes more time than FOntGAR. GARPA demands more time during the calculating of support, because for each generalized rule obtained a new scan in the database is done. So, depending on the quantity of rules and rows of the dataset, the runtime can be very high. On the other hand, although the data structures used in FOntGAR demands more time during the first scan, they avoid the need of new scans during the post- processing, allowing a more efficient access to data and decreasing the runtime.

Figure 4.1 ? Verification of the reading time per transaction.

Figure 4.2 ? Comparison in relation to runtime, varying the minsup.

B. Compaction rate in FOntGAR The Figure 4.3 shows that the compaction rate is high,  especially when values of minGen are low. This means that for high values of minGen the number of generalized rules decreases and consequently the number of traditional rules increases, reflecting in the amount generated. According to Figure 4.3, when minGen is 0.2 the compaction rate in the rules obtained under the level one is approximately 75%. No rule was obtained in levels more than two.

Figure 4.3 ? Analysis of compaction rate in FOntGAR.



V. CONCLUSIONS AND FUTURE WORKS This paper proposes the FOntGAR algorithm, the first  algorithm for mining generalized association rules under all levels of fuzzy ontologies in the post-processing stage.

The experiments show that FOntGAR makes an efficient generalization treatment, reducing the amount of rules.

Besides, the experiments show that the first reading in the database is more time consuming, but the gap tends keep stable with the increase of the number of transactions.

However, the total execution time is faster than a crisp post- processing approach. The reason is that the quantity of new database scans during the calculating of support affects the performance. Thus, although the data structures created in FOntGAR demands more time during the first scanning, they avoid the necessity of new scans during the post- processing, allowing a more efficient access to data and decreasing the runtime.

This work presents several contributions. First, it is the introduction of the first mining algorithm which uses fuzzy ontologies during the post-processing stage. Considering the existent bias, where related works use the same concept introduced by [2] or are focused in obtain fuzzy rules with linguistic terms, our algorithm makes an important improvement in state of art.

Another contribution is that FOntGAR generates non- redundant rules without use pruning measures. Redundant rules are the ones with similar or identical meaning. Besides, we present a solution for the calculating of support under fuzzy taxonomic structures in the post-processing stage. The solution solves the problem of database scans and improves the algorithm runtime.

For future works we will to automatize the mingen utilization basing on the user?s preferences. Besides, the introduction of context in fuzzy ontologies will be made.

