Association Rule Mining: A Graph Based Approach for Mining Frequent Itemsets

Abstract- Most of studies for mining frequent patterns are  based on constructing tree for arranging the items to mine  frequent patterns. Many algorithms proposed recently have  been motivated by FP-Growth (Frequent Pattern Growth)  process and uses an FP-Tree (Frequent Pattern Tree) to mine  frequent patterns. This paper introduces an algorithm called  FP-Growth-Graph which uses graph instead of tree to arrange  the items for mining frequent itemsets. The algorithm contains  three main parts. The first is to scan the database only once for  generating graph for all item. The second is to prune the non  frequent items based on given minimum support threshold and  readjust the frequency of edges, and then construct the  FP ?raph. The benefit of using graph structure comes in the  form of space complexity because graph uses an item as node  exactly once rather than two or more times as was done in tree.

Keywords- Frequent pattern; FP Jrowth; FP_tree;  FP_graph;, Association rule.



I. INTRODUCTION  Data mining is the process of extracting knowledge from  large amount of data. Data mining involves an integration of  techniques from multiple disciplines such as database and  data warehouse technology, statistics, machine learning,  association rule mining, high-performance computing,    pattern recognition, neural networks, data visualization,  information retrieval, image and signal processing and  spatial or temporal data analysis. Association rule learning is  a method for discovering interesting relations between  datasets in large databases. Based on the concept of strong  rules, Agrawal [2] introduced association rules for  discovering regularities between products in large scale  transaction data recorded by Point of sale (POS) systems in  supermarkets. Association rule mining comprises of two  steps for the complete process. First step finds the frequent  itemsets from given transaction database and second step  generates rule using these frequent itemsets. Frequent pattern  mining is an important part in the data mining tasks.

R.Srikant proposed the classical algorithm called Apriori[I].

that used the generate-and-test approach to find all frequent  patterns. According to the property of Apriori, many like  Apriori algorithms had been proposed, but all algorithms had  the bottle-neck that generating many candidates. In order to  solve this problem, Han jia-wei proposed the FP ?rowth[lO]  algorithm based on FP _tree that used the compressed  FP _tree structure to store the frequent patterns and did not  generate candidates. But constructing the FP _tree need to  978-1-4244-7578-0/$26.00  2010 IEEE 309  scan the database twice, and the time for constructing  FP _tree needs much time. Jun Gao [6] proposed a new  association rule mining algorithm called MFP(modified FP  Growth ). The MFP algorithm can convert a transaction  database into an MFP _tree through scanning the database  only once, and then do the mining of the tree. All algorithms  based on FP Growth process uses tree for arranging the items  before mining, where more than one node can contain single  item. This causes repetition of same item and needs more  space to store many copies of same item.

In this paper we designed an algorithm which uses graph  for arranging items before mining. The benefit of using  graph is that there be only one node for an item. This  requires less memory. Section I of this paper gives  introduction to association rule mining and related  algorithms. Section II explains the principle of Graph based  algorithm. Section III shows the algorithms to implement the  algorithm. Section IV explains experiment and  implementation and Section V show experiment result.

II PRINCIPLE OF GRAPH BASED ALGORITHM  A. Related Definition [4J  Definition I: Transaction database: Transaction database  stores transaction records. Every transaction record in a  transaction database has a sole identifier and all items  included in the transaction record are listed in order. Fig. I is  a simple transaction database named D. TOOl is the identifier  of the first transaction record in D.

Definition 2: FP _Graph: FP _Graph consists of nodes and  edges. Number of node in the graph is equal to number of  distinct items in the database D. Each node is associated with  a value count which stores the number of occurrence of item  in D and a Boolean value which is used while pruning graph.

It is set if corresponding node is frequent otherwise it is  reset. Each edge in graph contains three values marked on it.

First value represents the frequency of edge, second value is  the name of node with which the concerned transaction has  been started and third value represents the number of nodes  we have traversed to reach the destination of this edge  including destination. All these three values are written on  each edge as shown in Fig. 3.

Definition 3: FI: It stands for Frequent Itemset. It is a  data structure used to store Frequent Itemsets found while  mining graph. It simply stores an itemset and prints it and  then another itemset is over written in it.

B. Theprinciple ofFP_GRAPH  This algorithm can be divided into three parts: In first  part we make graph for given database D. In second part  graph is pruned to remove all non-frequent nodes and  readjusting the frequencies of edges connected to it. In third  part frequent itemsets are mined from pruned graph of  second part.

1) Making Graph  This is the first part of algorithm which explains the  formation of graph for transaction database. As shown in  Fig. 2 each edge in graph contains three values marked on it.

We start with first transaction of database and we take first  item of transaction and make a node with this item name and  set its count to 1. Then we make node for second item and  draw an edge between these two nodes. Each time we create  a chain of nodes in one transaction, the value of node count    is increased by one for the successive edges of graph.

-  While  making graph for TOO 1 in database we create node A and B  and then draw an edge between them and mark it with 1, A,  2. Now create a node E and link B with E by an edge marked  with 1, A, 3. For T002, as we have created node B, we create  a node D and link it with B by an edge marked with 1, B, 2.

Now for T004 as we have created both A and B and edge  between them, we just increase the frequency of link  between them by one. This process continues till all  transactions of database. Fig. 2 shows the graph generated  for our transaction database in Fig. 1.

TId. List of"n?lDs  100 1 A,B,E  1002. B,D  1003 B,C  1004 A,B,D  T005 A,C  'IOO5 B,C  TOO 7 A,B  100 & A,B ,C ,E  'IOO9 A,B. , C  Picture 1: Transaction Database   A \-_______ 5.A,2  1,B,2  2,B,2 0/' l.A,2 1,A,3  2.A,3  r------- l.A,4 E  Picture 2: Graph for our transaction  2) Pruning Graph  In second part we remove all nodes with support count  less than minimum support count. While pruning graph if  direct edge exists between two frequent nodes, then edge is  kept intact and if one or more infrequent nodes connects two  frequent nodes. We remove all infrequent node and connect  the frequent node with edge by which first infrequent node of  sequence was connected with source frequent node. Further  we check if an edge with same start node and node count  exist we just increase the frequency of this edge. As in  pruned graph, node count of any edge can not be more than    number of frequent node , we readjust the node count of all  edges. As shown in Fig. 3 where node C and F are frequent  node and node D and E are not frequent. After pruning when  node D is removed node C is directly connected by an edge  1, A, 3 with F and when E is removed, C is connected to F  by an edge 1, A, 3, but as an edge with 1, A, 3 already exists  between C and F. we just change the frequency and mark it  with 2, A, 3. A direct edge between C and F with 1, A, 4 is  kept intact. After pruning the graph is shown in Fig. 4.

C 1----- 1,A,3 ---0  1. A. 3 ---.(DJ  \ '- ? 1,A,4  1,A,4 1.A.4  Picture 3: Pruning Graph   Picture 4: Pruning Graph  3) Mining Graph  Third part of algorithm explains the mining process of  graph. In this process we try to find out biggest group of  items that appears number of times more than minimum  support count. First we find the edge with highest value of  node count and traverse all nodes along the path from  destination of edge found to start node of edge. We traverse  all nodes of the path by finding an edge with destination  equals to source of current edge and same start node and  node count one less than the current edge. This process  continues till the start node and source of current node are  same. The frequency of the path is minimum value of  frequency of all edges along the path. If the frequency of  path is more than or equals to minimum support count, all  node of the path comprises of frequent itemset and if it is  not, we search another path in which this sequence may  occur. If no such path exists we start mining for other smaller  groups.

III PROPOSED ALGORITHM  Pointer first and previous store the first node of  transaction Ti and source of any edge respectively and  syntax of create_edge ( source, destination, frequency_count,  start_node, nd_count) and create_node(node_name)  make?rapb(database D)  {  For (All transaction Ti in database D)    {  For (All items Ij in Ti)  {  If(j = 1)  Set first = Ij  node count = 1  Else  node _count = node_count + 1  end if  If (Ij does not exists in all nodes generated so far)  create _ node(Ij)  Count (Ij) = 1  If (previous *- null)   Create_edge(previous, Ij, 1, first, node_count)  End if  Else  Count (Ij) = count (Ij) + 1  If (previous *- null)  If (an edge with same source, destination, start node,  no.of node does not exists in all edges generated so far)  }  create_edge(previous, Ij, 1, first, node_count)  Else  edge_frequency = edge_frequency + 1  End if  End if  End if  }  previous = Ij  }  end of inner for loop  first = null  previous = null  end of outer for loop  end of make _graphO  MininjLgrapb(G)  {  Else  Find an edge with maximum value of node count  and assign it to j  -    While (j *- 1)  {  FI = null, k = 0, I = 0  If (there exists an edge with node_count = j)  { assign it to E  Visit all node by traversing E and its adjacent  edges with same start node and node count  decreasing by one until it reaches to 2 an ;dd all  nodes to FI store the frequency of path in k  }  While (there exist an edge with destination = FI[1]  and  visit = 0 and start_node = start_ node(E)  node_count> j)  {Assign it to E and visit all nodes of the path and  check whether nodes of FI also exist in this path if  yes store their frequency in i  }  K=k+i  If ( k  >= minimum_support)  Print FI  Print k  End if   }  j = j - l  End if  IV EXPERIMENT  We used 2 datasets in our experiments. The Mushroom  and Connect datasets are real data which are dense in long  frequent patterns. These datasets were downloaded from  http://fimi.cs.helsnki.fi/testdata.htmland and  http://miles.cnuce.cnr.it/::palmeri/datamlDCIIdataset.php.

Some characteristics of these data sets are shown in Fig. 5.

and we compared these algorithms with their  implementations. They were compiled in Visual C++. This  paper focuses on algorithmic concepts rather than on  implementations. For the above algorithms, the total  processing time, Data base scanning and accessibility and  Number of transactions is different for different  implementations. The memory are used frequently, the  memory refreshment also effectively handled using pointer    destructor concepts.

A. Dataset Selection  The datasets [ 10] used in this paper (Fig. 5) is used by  various Data mining experts in their research. The elements  in the datasets which are represented in the numeric format,  easy to evaluate the processes, which involved in those  mining concepts. These datasets consists of frequent itemset  in each record level. In record level they are separated by  special identification. The elements are separated by space.

The original values of Mushroom and Connect datasets  observations represented by its index values using mining  concepts. The frequent items and its associative datasets are  easy to calculate and represented as a flat file (or) text file.

The dataset which are used for the evaluation contains  following characteristics [3]. The Mushroom dataset is a  ?parse data relatively connect dataset with short frequent  Itemset patterns. Thus nodes in the itemset tree will have  small tails and few branches. Connect datasets are dense  datasets .They are characterized by very long itemset  patterns that peak around 10-25 items.

Data #items Transacti #Transacti  on length on  Mushro 120 23 8 124  om  Connect 130 43 65557  Picture 5. Charactenstlc of expenment data sets  B. Factor involve in t his experiment  From the observation of identified factors from the  above frequent itemset mining algorithm 4 factors are taken  in this paper and criticized. The 4 factors are:  1. Total processing time (run time) : It is the total time of  reading time of a dataset, sorting time, reordering time ,   pruning time, FP tree construction time and frequent item  set manipulation time.

2. Data base scanning and accessibility: It gives how many  times the dataset is opened or scanned and the each element  is accessed.

3. Number of transactions: The occurrence frequency of an  itemset is the number of transactions that contain the  itemset.

4. Total page fault.

V RESULT AND CONCLUSION  Under large minimum supports, FP-Growth runs faster  than FP-Graph while running slower under large minimum  supports. Fig 6 and 8 show what minimum support used in  experiments. Both algorithms adopts a divide and conquer  approach to decompose the mining problem into a set of  smaller problems and uses the frequent pattern (FP-tree) tree  and (FP-graph) graph data structure to achieve a condensed  representation of the database transactions. Under large  minimum supports, resulting tree and graph in relatively  small size so with this condition FP-Graph does not take  advantages of small memory space and also page fault for  both algorithm is almost equal. But as minimum supports  decrease resulting data structure size rapidly increase, it  require more memory space , at this point advantage of FP  Graph come in existence with less page fault FP-Graph  considerable work well with high dense database along with  s!llall minimum supports, it shown in Fig. 6 and 8 . Response  time FP Growth tree good but total run time for large  database, FP-Graph good because it gives less page fault. FP  Growth Tree uses tree for arranging the items before mining,  where more than one node can contain single item. This  causes repetition of same item and needs more space to store  many copies of same item. It also cause more page fault.

When the dataset is large, it is unrealistic to construct a main  memory based FP _tree.. In FP-growth-based algorithms,  recursive construction of the FP-tree affects the algorithm's  performance. Experiment result for both algorithm for both  database is shown in Fig. 7 and 9.

