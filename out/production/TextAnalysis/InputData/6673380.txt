Utilising Condor for Data Parallel Analytics in an IoT Context - an Experience Report

Abstract?The current emphasis on sensor-based intelligent  and ubiquitous systems, more commonly known as ?cyber- physical systems?, has the potential to give rise to a new generation of systems and services encompassing several do- mains such as e-Governance, healthcare, transportation, waste management, energy & utilities, insurance, etc., resulting in the metamorphosis of the Internet as we see it, into the Internet of Things (IoT). One probable commonality in each of these services will be the abundance of different types of data from different sources with the success of the systems depending on real-time or near real-time analysis of data. Such analyses are normally performed via well-known algorithms with a time-constraint on the execution, thus creating a requirement for parallel execution techniques. Some of these analyses may have a higher frequency of execution on a relatively small set of data, in which case the current big-data frameworks may actually add an overhead.

Further, the frameworks like Hadoop demand the algorithms to be mapped onto a particular paradigm, which may not always be a suitable option. This paper, which is a work-in-progress, provides an experience report on the use of Condor, a well known Grid framework, for data-parallel ?black-box? style execution of analysis algorithms in the context of Internet of Things. We concentrate on algorithms which are already in use, and can be partitioned into data-parallel subtasks without any modification and use Condor, which has traditionally been used for high- performance or high-throughput computing, as the execution framework.

Keywords?cyber-physical; ubiquitous systems; analytics; par- allel execution; black-box; mobile data mining; mobile grid

I. INTRODUCTION The next generation cyber-physical systems will be com-  posed of networked infrastructures of smart objects, ranging from furnitures, appliances within a home or office, cars or buses and other means of transport, healthcare devices, etc.

to give rise to new complicated applications and services encompassing several domains such as e-Governance, energy & utilities, waste management, healthcare, transport systems and many more. Mobile devices, such as phones and sensors will be integral parts of such a system and will constitute the basis of these intelligent infrastructures as they will act as the primary sources of data. Effective functioning of the services will be dependent on precise analysis of the data accrued through the ubiquitous sensor devices, irrespective of the source and domain. Such analyses will use different techniques to extract useful information from the collected data. As an example, data-mining techniques can be used to create clusters or groups of persons with similar physiological conditions offering the healthcare professionals the opportunity to diagnose the condition based on knowledge gained from clustering. Real-time analysis of streaming data in a medical emergency unit may lead to early detection of impending  medical conditions and alert the caregivers. Analysis of daily energy usage per appliance within a home or office may form the basis of a predictive system for the energy & utilities domain.

It is often claimed that the analytics processes will be executed on huge volume of data, and this is considered to be a generic requirement. However, there can be certain scenarios where the data volume may not be huge, but the frequency of computation is higher, that is, there are short bursts of computations with a predefined time-constraint. This falls in the area of high frequency computing (HFC) [7] as opposed to well-known paradigms such as high performance computing (HPC) [9] and high throughput computing (HTC) [10]. Real- time trading, domestic energy requirement monitoring are example use-cases where such concepts can be used. In the context of the Internet of Things, domestic energy usage monitoring is considered an extremely important scenario where the usage data will be collected from smart meters and devices, and based on the analysis of this usage data and the generation data, demand forecasts may be performed to meet the needs. For such cases, the analysis must be executed in parallel over a number of nodes to meet the time constraints or real-time requirements.

In the recent frameworks such as Hadoop [3], such paral- lelism is achieved by following a particular paradigm, which means that any algorithm that needs to be executed in parallel, must be written in a particular way. This often puts constraints on the developers as rewriting an existing working algorithm following a particular programming paradigm, especially a low-level procedural method like map-reduce [16], is not triv- ial. There are scenarios where analysts want existing algorithm to work in parallel without the need of rewriting them, thus creating a requirement for a ?black-box? style of execution.

Hadoop provides a streaming technique where such execution can be achieved, but there is a performance bottleneck which goes against the real-time or time-constrained requirement.

In this paper, we consider a scenario where data from various wind-turbines are used to forecast near-future wind characteristics to be used for power generation forecasts from the turbines. This problem has a time-constraint as the pre- diction must be completed before the next set of data arrive.

We have used a well-established framework called Condor [26] that was traditionally developed for HTC but is currently being adapted to HFC [8]. The framework has hitherto not been considered as an option for creating an execution framework for data analytics in the context of IoT. We attempt to establish using defined use-cases that it is a rather valid option for certain scenarios.

The paper is organized as follows: in Section II, the  1st International Workshop on Internet of Things Communications and Technologies (IoT'13)     background and related works are discussed and the problem statement is defined in Section III. Section IV discusses the ra- tionale of using the Condor framework for parallelized ?black box? execution of analytics algorithms in an IoT scenario.

We present some experimental results to understand the Con- dor framework?s behaviour when running in low bandwidth networks in Section V and discuss them. A conclusion is presented in Section VI.



II. BACKGROUND AND RELATED WORK The concept of smart cities demand that starting from  healthcare to transportation or energy and utilities, all fields will need to be smart by making use of information technology to analyse the data from each field, and often across fields, in order to gain useful insights that will enable effective prognosis. In most cases, a cycle of ?sense - extract - analyse - respond?, similar to feedback loops in control systems, is followed. This means that there is a requirement of real- time response or action based on the result of the analysis within a defined time period. Such requirements, considering the scale of the computation or the data volume involved, make data-parallel execution at various stages of the ?sense-extract- analyse-respond? cycle a primary choice. The essence of data- parallelism is in partitioning the input data in such a fashion that multiple worker processes can act upon different bits of data in parallel. Once the worker processes have processed their individual datasets, the final output is computed by combining the intermediate outputs from the workers.

One of the biggest issues in this context is related to the volume and/or velocity of data. For example, if the entire population of a ?smart city? is targeted for a health moni- toring system, the data volume generated even for a single day is extremely high. As per the definition from Forrester Research [4], such high volume of data should be categorised as big-data. For some other situations, like a home energy monitoring system where demand forecasts must be obtained at a certain frequency, the velocity of the data is critical, which makes it fall under the big-data category. Such high volume or velocity of data requires an analytical approach different from traditional processing techniques using conventional database systems which rely on a shared-disk architecture and can only be ?scaled up? to a certain extent, without being able to utilize the power of horizontal scalability of a shared-nothing architecture and hence power of massive parallelism.

There are different techniques to address this issue, one of the principal being NoSQL. Amongst many different NoSQL approaches, the most popular approach is based on a dis- tributed file store with an open-source implementation called Apache Hadoop [3]. A peer-to-peer based key-value store called Cassandra [13] offers another solution approach. In either case, the computational approach needs to be changed drastically as outlined by Wang et. al. in [27] where the authors apply the MapReduce [16] approach on an existing health information mining system. There are certain challenges in adapting any working framework to the MapReduce paradigm.

Firstly, all the algorithms must be adapted to the MapReduce model which is non-trivial. Existing executable binaries must be rewritten in Java to use Hadoop natively. There are other options such as pipes in Hadoop for C++ code or Hadoop Streaming APIs for any executable script - but all these have higher overheads which affect the performance adversely. And, secondly, a distributed file system model on which MapReduce  operates works best for large files, and in the context of IoT, data files need not be large, especially where real-time response is needed. Further, the scheduling systems of the current NoSQL parallel frameworks like Hadoop only consider the data locality while scheduling jobs over existing nodes, irrespective of the characteristics of the job in question or the node specifications, such as available CPU/memory and current load. Thus, Hadoop can not guarantee time-bound execution of the jobs as the nodes where the current job is scheduled may actually be busy or of lower specifications.

A more suitable framework in terms of considering the job and resource characteristics and offering high throughput is Condor [26] which uses a matchmaking process to determine the best possible resources amongst the available set for a given job while scheduling it. A job, which is a combination of the executable code and in most cases the data on which the code will operate, is created by the consumer, and submitted to the job scheduling system. A Condor agent stores the job in persistent storage and searches for resources that are suitable for executing the job. Agents and the resources advertise their characteristics and policies to a matchmaker, which introduces potentially compatible agents and resources. After this match- making phase, the agent establishes contact with the resource and verifies the compatibility and the job with the execution code and input data is passed to the resource for execution. For large number of jobs, or multiple execution of the same job on same/different input, Condor maintains a queue, and schedules the jobs accordingly. Condor has been traditionally used for high-throughput computing in scientific domains, and has not been considered for big-data analysis or parallel execution in the context of Internet of Things. Further, Condor was not designed to consider data-locality, and jobs had to be coupled with the data although recent stress on data-parallelism has resulted in the the inclusion of Hadoop Distributed File Sys- tem(HDFS) [6] support inside Condor. Condor offers different universes or execution environments which can be used by different types of executables, like Java, C/C++, MPI or vanilla (suitable for any executable binary). This feature removes the overhead of rewriting any existing working application to fit into a particular paradigm and is thus an interesting option for the ?black box? approach we have earlier mentioned.

In the context of IoT, RIPSAC (Real-Time Integrated Plat- form for Services and Analytics) [22] has been developed as a Platform-as-a-Service (PaaS) created with a view to provide a cloud computing platform that will allow quick and easy de- velopment, deployment and administration of sensor driven ap- plications. RIPSAC provides sensor device management, data acquisition, data storage, analytics and visualization services by interfacing with a heterogeneous set of sensors and devices within a smart computing environment. From these ubiquitous sensors and devices, RIPSAC is capable of collecting sensor observations and storing the data in a database connected with the platform. Applications can be developed and deployed over this platform in order to perform scalable analytics on the data for the benefit of a variety of consumers, including the end subscribers as well as authorized third parties such as insurance farms and/or government regulators for instantaneous decision- making leading to a ?smart? environment. As shown in Fig. 1, the platform provides a suite of infrastructure services in form of APIs and SDKs for application development/deployment and a set of services related to sensor description, discovery, integration, sensor observation and measurement capture, stor-     age and query in the form of APIs and libraries.

Fig. 1: The RIPSAC Platform Architecture  We have considered RIPSAC as there are only a few computational infrastructures available for data analytics in the context of Internet of Things, and RIPSAC is one of them.

Aneka [21] is another framework which allows deployment of data analytics services over sensor data and can integrate with cloud infrastructures. But it is tightly coupled with the .NET framework. Further, RIPSAC uses the Sensor Observation Service standards [12] from the Open Geospatial Consortium for interfacing with the sensor devices and hence is more closely related to the IoT domain, whereas sensor integration in Aneka seems to be an afterthought. However, RIPSAC does not have the capability to parallelise a given job or schedule and coordinate a distributed execution scenario, and hence suffers from a deficiency in the context of data-parallel jobs.

For a number of execution requests, RIPSAC can use load- balancing techniques, but there are situations where simple load-balancing may not be enough, and in this paper, we examine one such relevant real-life usage scenario. In this paper, we investigate the possibility of utilizing Condor as an execution framework within RIPSAC for IoT specific jobs, where data-parallel jobs will be executed on multiple nodes and contribute to the final result.



III. THE PARALLEL ?BLACK BOX? PROBLEM As an example use-case, we consider a requirement given  to us by a team working on an analytical application for wind forecasting based on results received from turbines and associated predictors, which are essentially wind speed sensors. The set of predictors provide wind related data every ten minutes. The number of predictors is variable. An ANN algorithm, coded in ?R?, works on the entire set of data for the past few hours output by the predictors as well as past data from the wind turbine to perform the forecasting.

This algorithm needs to be executed at every half an hour interval. As the number of wind turbines can be very large and the forecasting must be completed within half an hour (before the next iteration of forecasting commences), execution of the R-script in parallel over different predictor data sets is essential. Additionally, any modifications to the R-script to fit into Hadoop-like map-reduce paradigm to enable data- parallelism is out of consideration and we have found this requirement fairly common in the IoT analytics domain.

The current RIPSAC framework provides a solution to this problem using a load-balancer (HAProxy) to route simultane- ous processing requests to multiple nodes which do the pro- cessing in RServe [11]. The solution architecture is pictorially represented in Fig. 2(a). But, this solution is tightly coupled to R and RServe, and for any other IoT scenario that involves any other script/language, the solution will have to be re- architected. At the same time the drawbacks of HAProxy with respect to addition of new nodes or removal of existing nodes makes this solution non-elastic in nature which goes against the common assumption of Cloud frameworks. In the context of Internet of Things, the requirement of elasticity is extremely important. Moreover in such a context the load balancer should not assume that the devices, where the computation needs to be run, are dedicated. Rather, it has to determine when such a device is idle and then schedule the job based on the communication cost to that device. Thus, it can be said that HAProxy is a very good candidate for load balancing between several thousands of dedicated application servers, but it is not designed for the job scheduling challenges in cyber-physical systems.

Our proposed architecture, shown in Fig. 2(b), instead of forwarding the requests to existing RServe instances via HAProxy, submits R jobs to a Condor cluster for parallel execution. This removes the tight-coupling of the HAProxy/RServe-based architecture and enables the RIPSAC framework to use this new execution framework for a variety of jobs where the input data can be partitioned between independent worker processes which execute simultaneously on multiple nodes on different data-sets and the intermediate results can be combined using a user-submitted combiner script/routine.



IV. DETAILED ARCHITECTURE In this section, we describe the architecture of our frame-  work which is capable of parallel execution of arbitrary algo- rithms while considering them as black-box entities. We have used a cluster of Condor nodes with a designated master and several slave nodes, all of which were commodity hardware.

Condor was chosen as the primary candidate because of its ability  ? to match the job requirements with the specifications of available resources and consider the current state of the compute resource.

? to provide a vanilla universe for different types of executable binaries which coincides with our require- ment of being able to run any analytics code without modifying it.

? to form a cluster of both dedicated and non-dedicated nodes, where non-dedicated nodes may only be used when they are idle.

? to migrate running jobs from one node to another if a node becomes unavailable.

? to support HDFS and hence data-location awareness via add-ons.

The IoT scenario involves data generated by millions of smart things, e.g., sensors with minimal computing capabil- ity, different consumer electronic devices within homes like refrigerator, washing machines and other appliances, medical devices etc. The generated data needs to be pre-processed (e.g. volume reduction without loss of information is one of the primary pre-processing tasks) in a case to case basis     (a) Architecture using HAProxy and RServe (b) Proposed architecture using Condor  Fig. 2: Alternative solutions for the Wind Turbine scenario  at the initial stages, for example at the first proxy device receiving the data. Such proxy devices can be smart phones or sensor network gateways, which are constrained nodes in terms of their processing power, memory and network bandwidth compared to cluster servers in a compute cloud. If this initial analysis is heavy in terms of computation, the gateway device may leverage the cloud infrastructure by submitting jobs to the Condor framework. Further, the back-end server infrastructure may also utilise the edge gateway devices to run lightweight jobs that it needs to offload. This architecture is in line with the proxy architecture presented in [25] where the proxy devices hide the underlying constrained nodes and provide an unified interface to their computation capability. It is also worth mentioning that we intend to utilize the idle cycles of the edge gateway devices and not the smart objects/sensors directly.

Thus when the gateway device or the back end server wishes to offload a portion of processing, it submits a job to the execution environment with the job specifications mentioned in a configuration file. This configuration file is used to create a Condor classAd for the submitted job and the Condor Master (running in the back end cloud) schedules the job in a queue.

Based on the availability of resources, the queued jobs are executed on matched resources and results are notified.

This architecture differs from the traditional Condor exe- cution system in that it has a data partitioner module which is capable of splitting the data file based on a criteria submitted by the user. As of now, the partitioner is very basic in nature and can split the data files to single units. In our Wind Turbine use case, each instance of the analysis script written in ?R? is capable of analysing more than one turbine dataset to produce the results. The script requires at least one complete dataset for one turbine and is not able to produce proper results if the dataset from one turbine is split into multiple partitions. Thus, for this particular use-case, the data-set for one turbine is the minimum unit for data parallelism. Analogous to this can be a video analytics algorithm which can detect the presence of a particular object in a given video. To make it data parallel, the entire video file can be split into multiple videos and the same framework we have described in this paper will be able  to analyse one video piece on every node. A file can be as minuscule as possible, but it must be a valid video file with the correct header and trailers which are required to analyse the file. Otherwise, the semantics of the algorithm becomes transparent which is not intended. The combiner module is also rudimentary and can execute basic combiner scripts such as file concatenations submitted by the user.

Based on the number of data files (or partitions), jobs are scheduled on number of nodes to be executed in parallel.

Each job on a given node executes on its specific partition and produces some result which is finally combined using a combiner script provided by the job-submitter. Fig. 3(a) shows the basic process of parallelisation of a job and Fig. 3(b) shows the detailed architecture of the framework.



V. EXPERIMENTAL RESULTS AND DISCUSSION As already stated, this is a work-in-progress and our inten-  tion is to establish that Condor can indeed be considered as an extremely useful framework for parallel execution of analysis jobs in the IoT domain. In the following set of experiments we show the difference of behaviour of the Condor scheduler in a simulated low bandwidth network connected to devices with low computing capability. Further, cpu utilization is vital for the parallel execution, and framework, and hence through these experiments we also try to compare the effectiveness of Condor against the previous solution in this regard.

We have performed two sets of experiments, one on our internal lab network and the other on the Amazon EC2 [2]. In the following sections, we produce the details of each set of experiments and the rationale behind them.

A. Laboratory (internal) Set-up These experiments were conducted on a heterogeneous set  of nodes within our premises. The set-up consisted of Dell Optiplex 755 series machines (Intel Dual Core with 2.33 GHz CPU speed and 2 GB RAM) and Dell Latitude 6420i series laptops (Intel i5 quadcore with 2.5 GHz CPU speed and 4 GB RAM) connected in either 50 Mbps LAN. One Optiplex system hosted the HAProxy module along with the other necessary modules shown in Fig. 2(a) and the rest of the nodes housed     (a) Introducing Data-parallelism  (b) Detailed architecture  Fig. 3: Execution summary on Amazon EC2  upto eigth RServe instances. For the Condor experiments, the Condor Master was hosted on the Optiplex system and the other systems were used as Condor worker nodes. The cluster was a mix of nodes running on Ubuntu 12.04 and Windows XP SP3 with the Condor version being 7.8.6. We installed automated scripts to resubmit jobs in case of job failures when a node became busy (possibly because of a keyboard or mouse event) and ignored the errors. Only the end to end execution time was considered for successful jobs as the goal was to understand how much performance benefits can be obtained by executing data parallel jobs as black-boxes in such a heterogeneous environment. We submitted jobs in a batch starting from one upto 40 to both execution frameworks and noted the results which are shown in Fig 4.

It can be seen from the plots that the HAProxy/RServe architecture fares slightly better than the Condor-based frame- work in terms of make-span for the submitted batch jobs when 2 and 4 CPU cores are used as worker nodes. When the number of cores are increased, the Condor-based framework provides better performance in terms of job make-span. Further, the scalability of the Condor-based framework appears to be better than the RServe-based one. The plot in Fig 4(c) shows how the two frameworks behaved for the entire duration of  (a) Scalability in the Lab Network  (b) Comparison of Make-Span  (c)  Fig. 4: Execution summary on Lab Network  the batch cycle. It appears that the CPU utilisation in the Condor-based framework is much more efficient compared to the HAProxy/RServe architecture as Condor has a dedicated scheduler and HAProxy is just a load-balancer. When jobs are submitted to the Condor framework, they are assigned to dedicated CPU cores which are utilised to their full extent to service the corresponding job. On the other hand, HAProxy routes simultaneous job requests to available worker CPUs in a round-robin manner and several child RServe processes are spawned to serve the incoming requests thereby slicing the CPU between multiple jobs, resulting in the step-like pattern as shown in the plot.

B. Condor Cluster on Amazon EC2 The set-up on EC2 contained one small instance (m1.small)  with one virtual core, 1.7 GB RAM and 15 micro instances (t1.micro) with one virtual core, 0.6GB RAM [1]. All nodes were set up with Ubuntu 12.04 (Precise Pangolin) and Condor 7.8.6. As before, we executed two sets of experiments - one with the original HAProxy/RServe-based architecture and the second with our proposed Condor-based architecture. For the first set of experiments, HAProxy was housed in the small     instance, and each of the micro instances acted as RServe nodes. For the second set, the Condor submitter was running on the small instance and the micro instances acted as Condor worker nodes.

One test-suite was composed of eight analytics scripts written in ?R? analysing data from several (40, to be specific) turbines using eight different jobs. Each script was used to analyse data from five turbines and generate five separate re- sults. Those eight R jobs were executed on HAProxy/RServe- based framework and and then scheduled on the Condor cluster where the number of worker nodes in both cases were increased from one to fourteen in different steps. Results were gathered using automated scripts after each step to check for the scalability by adding new nodes. Fig. 5(a) shows the scaled execution by addition of new nodes to the cluster.

The graph shows that similar to the experiments in the lab network, the scalability of the Condor-based framework is better when more cores are available to the system. For a small number of cores, the HAProxy/RServe-based solution tends to perform better, but as the number of jobs are increased, Condor starts outperforming the 3-tier RServe architecture because of its elastic scalability and scheduling capabilities. These results re-iterate the fact that the Condor vanilla universe can be used to parallelize any executable binary for black-box style execution and thus scale up the system considerably.

To test the scalability and CPU utilisation on AWS, we executed a batch of 40 jobs to compare the HAProxy/RServe- based architecture with the Condor architecture and the result is shown in Fig. 5(b). Again, it was observed that the CPU utilisation by the Condor framework was far better than the framework using HAProxy/RServe which establishes the results obtained during the experiments in the lab network.

(a) Scaling of jobs on the Condor AWS Cluster  (b) Comparing the performance of RServe and Condor  Fig. 5: Performance comparison on AWS  From the results, it can be said that a parallel execution framework like Condor should provide better scalability and  CPU utilisation for data-parallel jobs compared to a tradi- tional 3-tier server-based architecture. And this framework can successfully be used to execute such data-parallel jobs as ?black-boxes? without any modification in the analysis code as compared to other data-parallel execution frameworks such as Hadoop. In the context of Internet of Things, where the analytics processes are data-parallel in nature with the requirement that they must be executed within a given time- frame and at the same time, adapting to a completely different programming paradigm is not desirable, our proposed frame- work adds additional value to the IoT analytics platforms like RIPSAC.



VI. CONCLUSION AND FUTURE WORK Condor has been successfully used for a considerably long  time in the Scientific community for utilizing CPU cycles of a cluster more effectively to achieve greater throughput.

However, the concept of high frequency computing is relatively new, and the use of Condor for sensor analytics is novel. There has been some work on using a Condor cluster from a mobile device acting as a client [20], [28], but the proposals we have made in this paper are radically different from any existing work in the IoT context.

The decision of using the Condor framework for a ?black- box? style execution of sensor analytics algorithms was based on our observation that many analysts in this community wish to leverage the concept of parallel execution, but at the same time, they do not wish to rewrite a working application to fit into a particular paradigm. However, as we plan to apply use the Condor Framework for execution of data analysis algorithms within the context of Internet of Things, few additional points must be considered.

(i) Not all the participant nodes in an IoT scenario will have similar capacity. In the context of IoT, enormous amount of computing power is spread across millions of home gateways, routers, and most of all - smart phones and mobile devices - together we call them edge devices. One very recent research area in this domain is to investigate the possibility of utilising these devices for computation, thereby extending the computation to the edges of a compute cloud rather than restricting it to the core of servers [15]. In such a scenario, it has to be accepted that these devices are mostly low-capacity systems, which mandates that the data must be partitioned following a proportional distribution. Thus, the weakest node will also be able to contribute and at the same time, the fully powered server class systems in the same network get a greater proportion of data to process.

(ii) The access network and the corresponding communica- tion cost to send/receive data to/from the participating nodes is extremely important in determining how much data for processing should be allocated to a participant node.

Considering the points mentioned above, the resource awareness features of Condor makes it more attractive within an IoT context as we are talking about utilizing the abundant computing power of ubiquitous devices and gateways which reside on the edge of the network, not just data centres at the core. Researchers have highlighted the use of gateway devices for various IoT scenarios such as home infotainment [24], low cost remote healthcare [19] and home energy [23] - each of which speak about the requirement of harnessing this abundant     and ubiquitous computing power. One extremely important aspect in this scenario is the ubiquity and volatility of the edge devices. This vast network is not a controlled one and one must accept that the gateways and mobile devices can be switched off or disconnected from the network any time and failure is to be accepted as a norm and not an exception. This indicates that the experiments that we did initially to understand Condor Scheduler?s behaviour in this regard, needs to be extended and scaled up by simulating with a large number of nodes and different workloads.

Though the edge gateway devices we involve in the pro- posed framework are capable enough for running a stripped down Condor scheduler, mobile network bandwidth will al- ways be a constraint making communication cost an extremely important aspect in the IoT domain. Low cost communication protocols such as Constrained Application Protocol (CoAP) [5] are being researched upon for use in the context of IoT. It has been shown in [14] that the low cost of CoAP has a positive effect on performance of cyber-physical systems. It will be interesting to see how the performance of Condor changes if CoAP is opted inside the networking modules of Condor and is used for communication during job execution.

We have already acknowledged that the ?black-box? style execution will be able to solve a relatively restricted class of problems, although the size of this class is by no means small. Further, a framework that is able to execute ?black-box? jobs will also be able to execute jobs that are ?white-box? in nature, and Condor can additionally provide optimization options for such jobs using the linked libraries. In this paper, we have tried to focus on one job or executable that performs a certain task or tasklet. Ideally, there can be combination of algorithms to solve certain problems which brings us to workflow execution on such Condor framework known as Directed Acyclic Graph Manager (DAGMan) [18]. Scientists have long been working on optimizing workflow execution on distributed environments, a suitable example of this being the Pegasus framework [17]. These researches will probably form the backbone of any further research on workflow optimization over distributed frameworks, but using the concepts with the specialities of the IoT domain will be a challenge. Further, keeping the ?black-box? paradigm alive will perhaps be the greatest challenge for our future research.

