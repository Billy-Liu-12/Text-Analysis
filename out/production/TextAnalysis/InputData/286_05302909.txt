General Causal Representations In The Medical Domain

Abstract - The target of many studies in the health sciences is the discovery of cause-effect relationships among observed variables  of interest, for example: treatments, exposures, preconditions,  and outcomes. Causal modeling and causal discovery are central to medical science. In order to algorithmically consider causal relations, the relations must be placed into a representation that supports manipulation. Knowledge of at least some causal effects is imprecise. The most widespread causal representation is di- rected acyclic graphs (DAGs). However, DAGs are severely lim- ited in what portion of the common sense world they can repre- sent. This paper considers the needs of commonsense causality and suggests Fuzzy Cognitive Maps as an alternative to DAGs.

Keywords - causality, fuzzy, commonsense reasoning, com- plexes, imprecision, DAGs, fuzzy cognitive models

I. INTRODUCTION  Causal knowledge makes up much of what we know and want to know in science [1]. Causal modeling and causal dis- covery are central to medical science. Causality is a relation, relating causes to effects [2]. Experimental studies, such as randomized controlled trials, often provide the trust worthiest results for establishing causal relationships. Experimental studies, while potentially highly informative, may not be: safe, ethical, logistically feasible, or financially worthwhile. Alter- natively, observational data is often available in the form of medical records; this data can be data mined to attempt to rec- ognize causal relationships.

The target of many studies in the health sciences is the dis- covery of cause-effect relationships among observed variables of interest, for example: treatments, exposures, preconditions, and outcomes [3]. Yet, until very recently, the dominant meth- odology in health science research has been statistical analy- sis. Statistical analysis of observational data can provide in- formation about correlations, but not necessarily information about causal relationships. For example, the correlation be- tween a patient?s coughing and fever may be high. But, this does not necessarily indicate a causal relationship; i.e., some- one coughs because they have fever to a high causal degree (or the other way around). Correlations do not indicate a causal direction. All that a high correlation tells us is that, for some reason, certain items often occur at the same time.

Causal relationships can have varying strengths; i.e., we can say that they are always true, often, sometimes true, rarely true, etc. The investigator believes that this imprecision can be best represented using fuzzy arithmetic.

Networks of causes and effects can be constructed; i.e.,  (?? ?,?), (?? ?), (?? ?), (? ?? ?)  The question is: How to best represent a causal network if the following characteristics are to be part of it: direction, strength, imprecision, network structure?

Statistical analysis of observational data can provide infor- mation about correlations, but not necessarily information about causal relationships. For example, in a grocery store, the correlation between customer purchases of bread and the pur- chases of milk may be high and may be a frequently occurring data pair (association). But, this does not necessarily indicate a causal relationship; i.e., someone buys bread because they have bought milk (or the other way around).

Sometimes, high medical attribute correlations have led to questionable causal statements. For example, a Prussian army doctor, Hans Reiter, observed a syndrome (called Reiter?s syndrome) that often occurred where the patient also had syphilis. He concluded that Reiter?s syndrome was caused by syphilis; this causal connection description has found its way into many medical textbooks. Unfortunately for this causal connection statement, the incidence of syphilis was high in most armies of that time and almost any disorder, including the common cold, could be similarly causally connected to syphilis. (In the Prussian army, the incidence of Reiter?s syn- drome was lower than the incidence of either syphilis or com- mon colds.)  Data mining analyzes data previously collected. There are several different data mining products. The most common are association rules. At first glance, association rules seem to imply a causal or cause-effect relationship. But, all that is dis- covered is the existence of a statistical relationship between the items. They have a degree of joint occurrence. The nature of the relationship is not known. We do not know whether the presence of an item or sets of items causes the presence of another item or set of items; or the converse, or some other phenomenon causes them to occur together.

The use of simple association rules may lead to errors. Er- rors might occur; either if causality is recognized where there is no causality; or if the direction of the causal relationship is wrong [4] [5]. For example, if  A study of past customers shows that 94% are sick.

? Is it the following rule?

Our customers are sick, so they buy from us.

? Is it the following complementary rule?

If people use our products, they are likely to become sick.

From a decision making viewpoint, it is not enough to know that  People both buy our products and are sick.

what is needed is knowledge of what causes what; if at all.

When trying to precisely reason about causality, complete knowledge of all of the relevant events and circumstances is needed. In commonsense, every day reasoning, approaches are used that do not require complete knowledge. Often, a satis- ficing [6] paradigm is followed.



II. COMPLEXES  When events happen, there are usually other related events.

The entire collection of events can be called a complex. A ?mechanism? [7] or a ?causal complex? [8] [9] is a collection of events whose occurrence or non-occurrence results in a consequent event happening.

Each complex, taken as a whole, can be reduced to a gran- ule if the grain size is increased. Larger complexes can be de- composed into smaller complexes; going from large grained to small grained. For example, when describing starting an auto- mobile, A large-grained to small-grained, nested causal view could start with  When an automobile?s ignition switch is turned on, this causes the engine to start.

But, it would not happen if a large system of other conditions were not in place.

There has to be available fuel. The battery has to be good.

The switch has to be connected to the battery so electricity can flow through it. The wiring has to connect the switch to the starter and ignition system (spark plugs, etc.). The en- gine has to be in good working order; and so forth.



III. GRAPHS AND CAUSALITY  The idea of ?positive? causation (? ? ?) is at the com- monsense causal reasoning core. Often, a positive causal rela- tionship is represented as a network of nodes and branches.

??  Figure 1. Diagram indicating that ? is causally dependent on ?.

A. Directed Acyclic Graphs (DAGs)  Various graph based Bayesian based methods have been suggested to describe causality. Probably the best known is the class of methods based on Directed Acyclic Graphs (DAGs).

The most fully developed approach is Pearl [10]. Silverstein [11] [12] followed a similar approach.

From the commonsense causal reasoning view, the various directed graph methods have similar liabilities, specifically:  A.1 Liability: Discrete or continuous data must be reduced to Boolean values  This is an early technique that was and is used in data mining when analyzing market basket data. However, it is essentially flawed. Quantities do matter; some data co-occur- rences are conditioned on there being a sufficiency of a co- occurring attribute. Also, some relationships may be non-lin- ear based on quantity [5].

A.2 Liability: There can be no missing data  This is at variance with day-to-day experience. There is almost always missing data of some sort. Data collection is rarely fully representative and complete. Incremental data is often acquired that is at variance with previously acquired data. What is needed is a methodology that is not brittle in the face of incompleteness.

A.3 Liability: Causal relationships are not cyclic, either di- rectly or indirectly (through another attribute).

This is at variance with our commonsense understanding of the world. Within cyclic dependencies, there are several variants.

A.3.1 Cycles with time lag: There are many commonsense examples where cycles are needed.

Figure 2. Positive feedback cycle: I tell Jane that I love her. Then, she tells me that she loves me. Then, I tell Jane that I love her more than before.

Then, she ? and so forth and so forth. Clearly, the cyclic rein- forcement would be substantial.

Some cycles can be reasonably collapsed, some cannot be.

Figure 3. Cyclic relationship that can be easily collapsed  Figure 4. Cyclic relationship that cannot be collapsed  A.3.2 Concurrent cycles  Another form of a cycle is joint mutual dependency. It is possible that there might be mutual dependencies [13]; i.e., ?  ? ? as well as ? ? a. It seems to be possible that they do so with different strengths. They can be described as shown in the following figure where Si,j represents the strength of the causal relationship from i to j .

?  ?,? S  S ?,?  ?  Figure 5. Cyclic relationship: Mutual unequal dependency. [13]    A.3.2.1 Different causal strengths for the same activity, occur- ring at the same time  Some argue that causality should be completely asymmet- ric and if it appears that items have mutual influences it is be- cause there is another cause that causes both. A problem with this is that it can lead to eventual regression to a first cause.

Whether this is true or not, it is not useful for commonsense representation. In contrast, Simon [7] and Shoham [14] iden- tify cases where causality is simultaneous.

It is also our commonsense experience. For example, in the preceding figure, ? could be short men and ? could be tall  women. If S?,? meant the strength of desire for a social meet-  ing, it might be that S?,?> S?,? .

A.3.2.2 Different causal strengths for symmetric activities, occurring at different times  It would seem that if there were causal relationships in market basket data, there would often be imbalanced de- pendencies. For example, if  A customer first buys strawberries, there may be a rea- sonably good chance that they will then buy whipped cream.

Conversely, if  They first buys whipped cream, the subsequent purchase of strawberries may be less likely.

A.4 Liability: Markov Stationary Condition holds: Probabili- ties are time independent  This does not correspond to our commonsense under- standing of the world. When one event is dependent on two causal events, if one causal event happens much earlier (or later) than the other event, there may well be a different result.

For example, if the goal is to have a successful dinner party, the catered food should be delivered before the guests arrive.

A.5 Liability: The Markov Memoryless Condition holds:  The Markov Condition is defined as: Let A be a node in a causal Bayesian network, and let B be any node that is not a descendant of A in the network. Then the Markov (Markoff) condition holds if A and B are independent, conditioned on the parents of A. The intuition of this condition is: If A and B are dependent, then B must either be (a possibly indirect) cause of A or (possibly indirectly) caused by A. In the second case, B is a descendant of A, while in the first B is an ancestor of A and has no effect on A once A?s immediate parents are fixed. This makes sense in the example shown in the following figure.

Figure 6. ?Memoryless? Markov condition holds  However, not all of our commonsense perceptions of cau- sality work this way. Often, we believe that history matters as in the example shown in the following figure.

Figure 7. Causality where memory play a part.

B. Markov Models  One possible way of describing the causal relationships is with first order Markov Models. They treat a system as a se- ries of states with specific, constant rate transitions between them. At all times, the system is in exactly one state. (Tran- sitions are considered to be instantaneous.) The only infor- mation available is the current state, the allowed transitions, and the probability of these transitions. This means that the system is totally characterized by its current state. None of the past states or transitions have any effect on the transitions out of the current state.

Describing the relationships between the nodes can be complex. One possibility is an extension of the random Markov model, shown in the following figure. The state value is 1/0 as an event either happens or does not.

b E   D c  0 m  Figure 8. Random Markov model: c = P(D), m = the possibility/probability that when D is present, the causal mechanism brings about E, b = the probability that some other (unspecified) causal mechanism brings about E.

While Markov models are intuitively appealing, they have some of the cyclic representational problems as do DAGs.

Consequently, they are not a good solution.

C. Needed Capabilities Of A General Causal Representation  There are several needs of a causal model. Many cannot be met by a directed graph. The needs are:  ? Represent imprecision ? Accommodate changes in grain size ? Describe complexes ? Support cycle models of all times ? Be time varying ? Not be restricted by Markov conditions

IV. FUZZY COGNITIVE MAPS  A potentially useful form for representing causal structures that overcomes some of the deficiencies of directed acyclic graphs or similar representations is Fuzzy Cognitive Maps (FCMs). However, they bring their own liabilities in that forming FCMs through data mining is unresolved.

Fuzzy Cognitive Maps are fuzzy structures that resemble neural networks. They have powerful and far-reaching con- sequences as a mathematical tool for modeling complex sys- tems. At first, Axelord [15] used cognitive maps as a formal way of representing social scientific knowledge and modeling decision making in social and political systems [16]. Then, Kosko enhanced cognitive maps considering fuzzy values for them [17] [18] [19] [20].

A FCM describes the behavior of a system in terms of concepts; each concept represents a state or a characteristic of the system. A FCM illustrates the system by a graph showing cause and effect between concepts. FCMs model the world as a collection of classes and causal relations between classes.

FCMs are fuzzy signed directed graphs with feedback. The directed edge Wij from causal concept Ci to concept Cj meas- ures how much Ci causes Cj. The time varying concept func- tion Ci(t) measures the non-negative occurrence of some fuzzy event.

Causal feedback loops can occur in FCMs. FCM feedback allows causal adaptation. FCM feedback forces the abandon- ment of classic graph search, forward and backward chaining.

Instead the FCM is viewed as a dynamical system and take its equilibrium behavior as a forward-evolved inference. A FCM has the ability to specify a complex model, shows linear or non-linear relations and allows causal propagation [21].

A Fuzzy Cognitive Map consists of nodes that represent concepts and arcs (edges) between concepts [22]. Each con- cept represents a characteristic of the system; in general it stands for events, actions, goals, values, trends of the system.

Each concept is characterized by a number Ai that represents its value and it results from the transformation of the value of the system?s variable, for which this concept stands, in the interval [-1,1]. The graph?s edges are the casual influences between the concepts.

Figure 9. A simple Fuzzy Cognitive Map  The edges Wij takes values in the fuzzy causal interval [?1, 1]. The weights of the arcs between concept Ci and concept Cj could be positive (Wij > 0) which means that an increase in the value of concept Ci leads to the increase of the value of con- cept Cj , and a decrease in the value of concept Ci leads to the decrease of the value of concept Cj . Or there is negative cau- sality (Wij < 0) which means that an increase in the value of concept Ci leads to the decrease of the value of concept Cj and vice versa. Wij = 0 indicates no causality.

State vectors C are repeatedly passed through the FCM connection matrix W, thresholding or non-linearly transform- ing the result after each pass. The limit cycle or fixed-point inference summarizes the joint effects of all the interacting  fuzzy knowledge.

Figure 10. A urinary bladder tumor grading model [23]  The previous figure shows how a medical FCM applica- tion; where Cn, n=1?8 represent histological features using five positive linguistic variables depending on the character- istics of each particular concept. C9 represents the target, tumor grade. The concepts are: C1: Cell distribution: Even, clustered C2: Cell size: Uniform, pleomorphic C3: Cell number: Numerous, variable C4: Cytoplasm: Homogeneous, variable C5: Nuclei: Uniform, irregular, very irregular, bizarre C6: Nucleoi: Inconspicuous, evident, prominent C7: Neocrosis: Inconspicuous, frequent C8: Mitoses: Absent-rate, occasional, numerous C9: Degree of tumor grade  The value of a node reflects the degree to which the concept is active in the system at a particular time. This value is a function of the sum of all incoming edges multiplied and the value of the originating concept at the immediately preceding state. The threshold function applied to the weighted sums can be fuzzy in nature. Concept values are expressed on a normal- ized range denoting a degree of activation rather than an exact quantitative value.

The mathematical model consists of1? n state vector A that includes the values of the n concepts and a n ? n weight matrix W that gathers the weights Wij of the interconnections between the n concepts of the FCM. The matrix W has n rows and n columns where n equals the total number of distinct concepts of the FCM and the matrix diagonal is zero since it is assumed that no concept causes itself. The value of each con- cept is influenced by the values of the connected weighted con- cepts and by its previous value. The value Ai for each concept Ci is calculated by:  iA f jA jiW j=1 j?1  n ?  ?  ?  ? ? ?  ?          + i  oldA  where Ai is the activation level of concept Ci at time t+1, Aj is the activation level of concept Cj at time t+1, Aj is the activa- tion level of concept Ci at time t, and Wji is the weight of the interconnection between Cj and Ci, and f is a threshold function.

newA = f oldA oW( ) + oldA The new state vector Anew is computed by multiplying the pre- vious state vector Aold by the weight matrix W. The new vec- tor shows the effect of the change in the value of one concept in the entire Fuzzy Cognitive Map.

There are several unsupervised learning algorithms that might be used to reach convergence, or at least convergence within an acceptable tolerance [24] [25] [26] [27] [28] [29] [30]; the algorithms can be comparatively analyzed [31]; how- ever, neither particular methods or a comparative analysis of the methods are within the scope of this paper. The FCM system model takes the initial values of the concepts from the real system and is free to interact. The interaction happens because of change in the value of one or more concepts [32].

The interaction continues until the model: ? Reaches equilibrium at a fixed point, with the output con-  cept values stabilizing.

? Exhibits limit cycle behavior, with the concept values fal-  ling in a loop.

? Exhibits chaotic behavior in a non-deterministic way.



VIII. EPILOGUE  The target of many studies in the health sciences is the dis- covery of cause-effect relationships among observed variables of interest, for example: treatments, exposures, preconditions, and outcomes. Causal modeling and causal discovery are cen- tral to medical science. In order to algorithmically consider causal relations, the relationships must be placed into a repre- sentation that supports manipulation. An algorithmic way of handling causal imprecision is needed. There are several needs of a causal model. The needs are:  ? Represent causal imprecision ? Accommodate changes in grain size ? Describe complexes ? Support cycle models of all times ? Be time varying ? Not be restricted by Markov conditions  The most widespread causal representation is directed acyclic graphs (DAGs). However, DAGs are severely limited in what portion of the common sense world they can represent.

This paper considers the needs of commonsense causality and suggests Fuzzy Cognitive Maps as an alternative to DAGs.

Fuzzy Cognitive Maps appear to be a good approximation of complex casual complexes. They appear to be a compre- hensive representation. Their primary difficulty lies with es- tablishing their initial values.

