2012 4th Conference on Data Mining and Optimization (DMO)        02-04 September 2012, Langkawi, Malaysia

Abstract?Text classification problem receives a lot of research  that are based on machine learning, statistical, and information  retrieval techniques. In the last decade, the associative  classification algorithms which depends on pure data mining  techniques appears as an effective method for classification. In  this paper, we examine associative classification approach on the  Arabic language to mine knowledge from Arabic text data set.

Two methods of classification using AC are applied in this study;  these methods are single rule prediction and multiple rule  prediction.  The experimental results against different classes of  Arabic data set show that multiple rule prediction method  outperforms single rule prediction method with regards to their  accuracy. In general, the associative classification approach is a  suitable method to classify Arabic text data set, and is able to  achieve a good classification performance in terms of  classification time and classification accuracy.

Keywords-associative classification; class association rule;  Arabic text.



I.   INTRODUCTION  Associative classification AC is a subset of data mining fields which utilizes two major tasks of data mining process i.e.

association rule and classification. AC merges association rule discovery and classification to construct a rule based classification model for the prediction purpose. The use of associative classification for text mining-classification- problem appears in the last few years [1]. Text classification is the process of automatically predicting the valid categories of the text documents based on knowledge discovery in the construction phase of classification model. Currently, text classification has a wide range of applications, such as classification of news stories, e-mail routing, spam filtering, news monitoring, document indexing, searching for interesting information on the internet, web page classification, and so on [2].

During the building and testing of text association classification model, we conduct several processes such as data pre-processing, feature weighting and selection, class association rule generation and define the prediction methods.

Given a text training data set which is labelled with many categories, in our approach, we consider each category individually. Assume that D is a set of documents in training data set, D = {D1, D2, D3,?, Dn }, and T is a set of terms that represent documents after data preprocessing and feature  selection processes, T = {T1, T2, T3,?, Tn }, two values are used to determine the importance of class association rules; minimum support and minimum confidence. These values are used as thresholds. Using this restriction, a set of frequent terms is generated where frequent terms are those that exceed the minimum support threshold. Out of these frequent terms, the classification rule is discovered based on rule confidence and based on restriction in which the right hand side of rules must be a class label, for this reason the AC is considered as special case of association rule [3]. Formally, T?C is called class association rule where T is a set of frequent terms and C must be a class label associated with this rule. This rule is strong if the support for the co-occurrence of T?C satisfies minimum support, and the confidence satisfies minimum confidence [4].

Most of the classification methods are applied to English and European languages. In this paper we investigate the use of AC to classify Arabic language text documents. Arabic and English are two different languages. For instance they have different alphabets; the English alphabet has 26 characters while the Arabic alphabet has 28 characters. The writing style is also different, in Arabic language, the text is written and read from right to left while in English language, the text is written and read from left to right. In addition, the shape of the Arabic character is context-sensitive, depending on its location within the words. One of the important properties of Arabic language is that it is a derivational and highly inflectional language so that the morphological analysis takes a significant role when we deal with Arabic text computerized systems.

The rest of this paper is organized as follows: in section II we highlight and discuss the related works. Section III describes our methodology and the architecture of AC and it addresses the issues such as feature selection, associative classifier construction and testing. In section IV, we explain the experimental results. The conclusion and future works are given in section V.



II. RELATED WORKS  Many previous efforts have been conducted for classification methods development. The main motivation of research on classification problem is to obtain a classification model with an acceptable accuracy. In the last decade of research in data mining, AC was presented as a new method for text classification and it has been applied with various of       algorithms in many researches. Particularly, Zu et al. [4] introduce new text associative classifier based on generic rules with regards to closed item sets and they use rough set theory to reduce feature space. Abu Bakar et al. [5] use AC approach to mine knowledge and make strategic decision in the insurance companies, in this study; two types of decision rules are processed using a heuristic approach which enhances CBA, the heuristic process rules that is generated from data that is classified correctly and rules that is discovered from uncertain classified data. Thabtah et al. [3] present a method of rule pruning called high precedence for text associative classification. In this method the rule is added to classifier if its terms partially cover the terms in training data set. High precedence pruning method achieves higher accuracy with MACAR algorithm than lazy and database coverage pruning methods and it produces reasonable classification rules.

Antonie & Zaiane [6], and Srividhya & Anitha [7] describe and use association rule based classifier by category that generates rules for each category in training data set that is divided to N subset by category. Thaicharoen [8] introduces a method called text association mining with cross-sentence inference, this method is considered to be general approach and it can be applied to any application domain. Chiang et al.

[9] apply association rule mining with a manual category priority table to classify Chinese text. Abu Bakar et al. [10] employ AC method to mine association rule and build a knowledge model from diet nutrition data set, the results show that the model can be built using unsupervised data set using the discovered knowledge in association rule mining phase.

AC method is considered to be an accurate and outperform traditional classification method [1]. However, most of the classification methods are applied for English and European languages. In the last years, a few works dealt with Arabic text classification problem, for instance, Al-Rdaidah et.al [11] use association rule mining as a learning method to build their Arabic text classifier, in this study a priory algorithm is used to generate the Arabic text classification association rules.

The ordered decision list, weighted rules, and majority voting prediction methods of test document category are tested and compared regards to their classification accuracy. The experimental results against collection of Arabic text documents show that the majority voting method outperforms the other prediction methods and the association rule mining is a good method to build an Arabic text categorizer. AL-Harbi et al. [12] evaluate two classification methods (SVM and C5.0 decision tree) on seven different Arabic corpora. The classification accuracy reported against seven corpora is 68.65% for SVM and 78.42% for C5.0. In their study, the C5.0 algorithm outperforms the SVM algorithm in all seven Arabic corpora. Al-Halees [13] presents an Arabic text classifier based on maximum entropy, the results show that the text preprocessing techniques increase the F- measure average by about 12.28%, from 68.13% to 80.41%. Thabtah et al. [14] apply k-nearest neighbor with three variations of vector space model ( Cosine, Jacaard and Dice Coefficients) on Arabic newspapers data set. The results related to F1 measures show that Jaccard and Dice coefficient outperform the Cosine coefficient method. Dice and Jaccard which are based on TF-  IDF resulted in 94.91 % which is the highest average in F1 measure.

Al-Kabi & Al-Sinjilawi [15], Khitam [16], and Harrag & Al-Qawasmah [17] apply text classification methods to mine and discover knowledge from Al-Hadith data set (Says of prophet Mohammed ?peace and blessings of Allah be upon him?). Al-Kabi compares different variations of vector space model with Na?ve Bayesian classifier which outperforms the other methods. While Khitam uses stem expansion classification method with similarity based method as a classification method, this method achieves better classification when compared to the other two methods (Al- Kabi 2007 and word based classification methods). However, Harrag uses neural network (NN) classifier with singular value decomposition (SVD) as a feature selection method, the results show that the SVD is effective to reduce feature space and the overall precision, recall and F measures are more stable with SVD and NN, but the overall average is not so high.

Omer & Shilong [18] use stemming algorithm with keywords matching to classify 400 Arabic text documents distributed over four classes. The recall average for four categories ranged from 88% to 99% while precision average ranged from 86% to 100%. Noaman et al. [19] apply Naive Bayesian to classify 300 Arabic text documents that belong to 10 categories, the reported accuracy is about 62%. Mesleh & Kanaan [20] use the ant colony optimization (ACO) based feature subset selection with support vector machine (SVM) to classify Arabic news articles. The experimental results on online Arabic newspaper corpus which contains 1445 articles show that ACO achieves better performance with SVM than other six compared FS methods (Chi-squar, NGL, Odds Ratio, Information Gain, GSS, and Mutual Information).



III. ASSOCIATIVE CLASSIFICATION APPROACH  The overall steps of our associative classifier are shown in Figure 1. The data collection is divided into two data sets; training data set which is used for model construction and testing data set that is used to validate associative classifier.

The following subsections describe the construction and validation processes.

A.  Arabic Text Preprocessing  In this phase the Arabic text document passes through preprocessing steps, which include removal of non Arabic letters, digits, punctuation marks, and Arabic stop words. In addition, the stemming process is also conducted in this phase.

B.  Feature Selection Process  Feature selection FS means the selection of optimal or the relevant subset of features among the whole sets of feature, it deals with data reduction, this process reduces the space of high dimensional data into a small sample dimension that represents the best features of data. FS is an important preprocess through the building of text classification systems, the good choosing of features that enhances the classification accuracy and minimize the classification errors. In this paper, we use TF_IDF based feature selection method as described in [16].  In our approach, each term in a given document, is       assigned to a weight value based on term frequency and inverse document frequency (TF_IDF) weighting method, and the documents are represented as a vector of weighted terms with its class labels. When all terms in a given document are assigned to weighting values, these values are used to select the important features for documents, those features are considered as discriminative features (terms or words) between different classes and it passes to the association rule generation process.

C. Associative Classifier Construction  The class association rules are generated in this phase of our methodology. We employ Apriori algorithm similar to that used in [6] to discover all frequent terms that form rules body from a preprocessed supervised training data set. Two measurable values are used to determine frequent items and frequent class association rules i.e. support and confidence.

The discovered rule are ordered and pruned in this phase, and then the associative classification model is constructed, these steps are called post mining of class association rules [5].

Figure 1.  Associative classifier construction and validation steps.

Rule Ordering and Pruning  Features Selection Method (TF-IDF Based Feature Selection)    Class Association Rule Discovery  Frequent Term Generation   Class Association Rule Generation   Text Pre-Processing  Tokenization Stop word removal  Stemming  Arabic Text  Document  ????  Training  Data      Testing  Data      Preprocessing         CR1: T1?c1  CR2: T2?c2  CR3: T3?c3  ???.

CRn: Tn?cn  Associative Classifier    Assign Class to  Test Document         1)      Frequent Class Terms Generation: The frequent terms for each class are generated during frequent terms  generation process. The term set that are selected in feature  selection step represent training data set that is associated with  its predefined classes are used as an input to the Apriori  algorithm. The frequent class terms are measured using term  set support value, which is the number of occurrence of terms  together in the observed data [1].  An iterative search over  training data set is conducted to discover the associated terms  that distinguish each category from the others, Apriori  knowledge is used to remove unfrequented terms and reduce  search space.

Assume that T = [t1, t2, t3, ?, tm] is a set of terms.

The first candidates term set are generated directly and the frequent 1-term sets that pass minimum support are retained and used to generate candidate 2-term set. The frequent 2- term set is discovered in the next step according to minimum support. The generation process of subsequent candidate and frequent m-term sets continues until no further frequent term set can be generated from the training data set [6], [7].

2)  Class Association Rule Generation: Class association rule must be restricted and constrained in the rule head and  rule body. The rules that form classifier are only rules that  indicate a category label. These rules take the form Tj ? Ci,  where Tj is a set of frequent terms that represent documents in  the training data set, and Ci is the class that is associated with  these documents. Formally, class association rule CR is of the  form Tj ? Ci , where, Tj  is a set of frequent terms of the form  [t1& t2 &?& tm ] and is called rule terms, and Ci is the  category of this rule and is called the rule head. Each rule must  have support and confidence, the rule CR is called a strong  and frequent rule if it passes the minimum confidence and  minimum support threshold values [1], [6], [7].

The support of rule CR: Tj ? Ci  is the percentage of  document that contains rule terms Tj among the whole documents in each observed class Ci [1], ?(1)?,  presented this ratio.

(1)   Where sup (Tj ? Ci) is the number of documents in data set that match terms of R, and associated with class C of R and N is the total number of documents in class data set.

The expected rule accuracy [21] is used as the rule confidence, which is defined as the conditional probability which rule head is valid given the condition of rule body. The classes are already associated with each rule and always occur with rule body. Therefore, the rule accuracy as in ? (2)? will be used in this paper.

(2)  Where Dtot (R) is the number of documents in training data set that contains rule body and Nc is the number of classes.

3) Class Association Rule Ordering and Pruning: The class association rules that are discovered in the last step will  be passed through rule sorting procedure. In this paper, we  order the rules according to its confidence, support and the  number of terms in the rule body as presented in Fig. 2 [1].

After rule ordering process, a list of ordered rules is retained.

Actually, these rules are pruned during the search in the rule  mining process according to rule confidence. The rules that  have lower confidence than the minimum confidence  threshold are eliminated. In addition, the rules are also pruned  based on rule redundancy method if the rule contains another  rule. In other words, if there is a rule body that fully matches  or subset of other rule body and it has less confidence then this  rule is eliminated from the list. The two main reasons of doing  pruning process are to create an Associative classification  model using the set of rules that have a discriminative power  for distinguishing categories and to build model using a  reasonable number of class association rules that could not  take a long time for future prediction [3], [6].

D.  Prediction of New Document Class  Several methods can be used for classification using a set of class association rules. These methods belong to two categories; single rule prediction or multiple rules prediction [1]. In this paper, we focus on ordered decision list (single rule prediction) and majority voting (multiple rules prediction) methods [22]. In ordered decision list method, the first rule that covers new test document is used for prediction; the new test document is assigned to the class that is associated with this rule. However, the majority voting method classifies the new document based on the total number of rules that cover this document. In this method, all rules that cover new document (rule body is partially or fully match the terms of new document) are weighted equally. The majority voting method composed of four steps as follows:  ? Search through the rules list.

? Find all rules that cover the test document to be classified.

Figure 2.  Procedure of the association rule ordering.

( ) ( )  N  iCjT  iCjTSupport ?  =?  sup   ( )  ( )cNRtotD  RtotD accuracyRule  +  + =  )(  1)( _    Procedure: Rule Ordering.

For a given two class association rules CR1 and CR2, CR1 is higher ranked than CR2 if: (A) The confidence of CR1 is higher than the confidence of CR2.

(B) If the confidences are equal, check if support of CR1 exceeds support of CR2.

(C) If both confidences and supports are equal, but CR1 has more terms in its body than CR2.

? If all retained rules have identical class, classify this document to this class.

?  Else, assign this document to the class that is favored by the majority of all retained rules.



IV.  EXPERIMENT AND RESULTS  A.    Data Set  Arabic news article data sets are used in our experiment.

This data set is collected from many sources. Most of our data are taken from online Arabic corpora [23]; the rest is collected from Arabic news channels websites such as Aljazeera web site and from other websites. The data set consists of 5640 documents (about 16.5 MB) with different sizes belong to seven categories. The data set categories and the number of documents for each category are presented in Table I.

B.  Results and Evaluation  The classification accuracy is used in this paper as the base measure of our experimental results. The classification accuracy is calculated as in ?(3)? by dividing the number of the correctly classified document by the total number of documents in the testing dataset.

(3)    Where TrueC is the number of test documents that are classified correctly (True classification) and Total is the total number of test documents.

In this paper, an Arabic data set is used for experiments, this data set described in section IV,A, in our experiment we consider about 70% of data for training and the rest for model testing. The data is processed and the important terms that represent labeled documents are selected as discussed in section III, and the Apriori algorithm is used to discover association rule for each class. The minimum support and minimum confidence threshold values are selected according to the literature and are based on experimental results. We set min-supp to 10% in the first experiment and 5% in the second with 50%, 70%, and 80% for min-conf. The class association rules that are generated are ordered and pruned using the steps that are described in section III, C, and the remaining rules are used to form the Arabic text associative classifier that represents as a set of class association rules. Finally, the ordered decision list and majority voting methods (Section III, D) are used to predict the classes of test documents in testing data set.

Table II shows the number of class association rule that is generated from our data set, the classification accuracy of the two prediction methods that are used in this paper in addition to the training and testing time of our associative classifier. The results obtained when the minimum support was 10% with variant confidences of rules. After analyzing table II, we find that the classification accuracy increases with both prediction methods when the rule confidences is high. The majority voting and ordered decision list reach the peak of accuracy 84% and 81% respectively when the rule confidence is 80% with 50 prediction rules. The majority voting method outperforms than ordered decision list method in most experiments. The execution time for both training and testing does not exceed 6 minutes in all experiments, and most of this time is taken for model training.

Additional experiments are conducted to test the performance of associative classifier with a large number of Arabic class association rules. Table III presents the results when the minimum support is 5%. We discover that the number of class association rules increase roughly by six times than obtained rule when minimum support is 10%. The large number of prediction rules affects the classification accuracy and this indicates that the associative classifier with a reasonable number of rules performs well than those with a large number of rules. Figure 3 depicts the classification accuracy reported in Table II and Table III for both prediction methods (Majority voting and ordered decision list).

Figure 3 depicts the classification accuracy reported in Table II and Table III for both prediction methods (Majority voting and ordered decision list).According to this figure, the classification accuracies for both prediction methods are not so far from each other. The ordered decision list prediction method produces better accuracy than majority voting method when the minimum confidence is 50%, but the majority voting method superior ordered decision list method with 70% and 80% of rule confidences. In general, the results are good and satisfactory when we deal with Arabic text with a size that is used in this study. To the best of our knowledge, the most of the pervious works that conducted on Arabic text classification used small Arabic     Category Name Number of Documents  Culture 1450  Economy 1054  Politic 1098  Sport 1574  Education 144  Information technology 144  Health 176  Total 5640  Minimum Support = 10% Accuracy  Testing Time (m)  Confidence NO. of Rules Training  Time(m)  Majority Voting Ordered Decision List Majority Voting Ordered Decision  List  50% 95 3.26 0.771 0.787 1.39 1.22  70% 82 3.19 0.803 0.792 1.27 1.38  80% 50 3.17 0.846 0.812 1.32 1.35  Total  TrueC Accuracy =  TABLE I.          CATEGORIES AND NUMBER OF DOCUMENTS  TABLE II.     RESULTS OF ASSOCIATIVE CLASSIFIER FOR THE ARABIC TEXT DATA SET         corpus for experiments. However, in our experiment the number of test documents that is used for AC model testing exceeds those used for both training and testing in some previous researches.

Figure 4 shows the number of classification rules that derived from our Arabic data set with different parameter association rule discovery i.e. minimum confidence and minimum supports. As shown in this figure the number of classification rules (with 5% of minimum support) decrease from about 633 rules with 50% of rule confidence into 359 rules with 70% of rule confidence. At 10% of minimum support no much difference between 50% and 70% of rule confidences, only 13 rules is the difference.

classification rules is the same with 50% and 70% of rule confidence when the minimum support is 15% and 20%, which produces 33 and 13 of rules respectively. However, at 15% and 20% of minimum support the culture category appears without any rule, and that means this category doesn?t have much of correlated terms.

As shown in the experimental results, the AC model achieves an acceptable accuracy and it classifies test documents in reasonable time. This indicates that our model is constructed using association rules that are strongly related to its predefined classes and most of these rules have a discriminative power to distinguish each class from t In addition, the number of class association rules that form AC model is not large and the prediction methods are simple with few computations, therefore, the search space for prediction is limited and the prediction method does not need a long classify test documents.

.

Minimum Support = 5%  Confidence NO. of Rules Training  Time(m)  50% 633 3.54  70% 359 3.50  80% 345 4.00  Figure 3.  Associative classification accuracy, minimum confidence varying from 50% to 80%.

TABLE III.  RESULTS OF  in our experiment the used for AC model testing  used for both training and testing in some  Figure 4 shows the number of classification rules that is derived from our Arabic data set with different parameters of  minimum confidence and minimum supports. As shown in this figure the number of classification rules (with 5% of minimum support) decreases from about 633 rules with 50% of rule confidence into 359 rules with 70% of rule confidence. At 10% of minimum  rt no much difference between 50% and 70% of rule confidences, only 13 rules is the difference. The number of  same with 50% and 70% of rule 15% and 20%, which  spectively. However, at 15% and 20% of minimum support the culture category appears without  this category doesn?t have much of  As shown in the experimental results, the AC model d it classifies test  documents in reasonable time. This indicates that our model is constructed using association rules that are strongly related to its predefined classes and most of these rules have a discriminative power to distinguish each class from the others.

In addition, the number of class association rules that form AC model is not large and the prediction methods are simple with few computations, therefore, the search space for prediction is  not need a long time to

V. CONCLUSION AND  In this paper, we investigate the use of associative classification approach for Arab Associative classification method integrates association rule discovery with classification task to build a rule based classification model for prediction. The results obtained in this paper against Arabic text AC is a good classification model which can classify text data set with a reasonable number of understandable classification rules. The model produces an acceptable accuracy when we classify Arabic text data set. In enhance Arabic text associative classifier by examining feature selection methods and we plan between all classes that are used i intend to compare the method with other classification methods.

