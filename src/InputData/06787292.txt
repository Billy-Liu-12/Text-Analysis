Large Scale Data Processing in Ecology: A Case Study on Long-Term Underwater Video Monitoring

Abstract?Ecology is, nowadays, an interdisciplinary, collabo- rative and data-intensive science; therefore, discovering, integrat- ing and analysing daily-produced data is necessary to support researchers to investigate complex questions, ranging from single particles to animals to the biosphere [1]. As a consequence, ecology-related multimedia content has been produced massively in recent years: for example, the Xeno-canto project1 and the Pl@ntNet project2 respectively collected 140,000 audio records of 8,700 bird species and about 60,000 thousand images covering thousand of plant species, to be used by scientists or professionals.

Unfortunately, a manual analysis of such amount of generated data is impossible: automatic analysis tools combined with high- performance computing (HPC) solutions are therefore heavily demanded for making sense of such big ecological data. In this paper we present a case study of large-scale video processing on HPC facilities for underwater fish monitoring in the context of the Fish4Knowledge project3, where a system to analyse long-term underwater camera footage has been developed. The paper is meant to report on the employed hardware/software architecture, the design and deployment of the parallel job manager, and the problems encountered during the whole process, from load balancing to job submission policies to bottlenecks.



I. INTRODUCTION With the recent progress in digital cameras, storage ca-  pabilities and high-speed computer networks, ecology-related multimedia content is, nowadays, routinely and massively generated. This enabled long-term and reliable environmental monitoring through remote-sensing platforms [2], as in the case of the underwater domain, where cameras have been effectively employed to study marine wildlife [3]. In particular, recent projects in the underwater domain have generated visual data at an astonishing rate; for instance, in the Fish4Knowledge project, 10 underwater cameras have been recording videos for 12 hours a day in the last four years, resulting in about 200 TB of raw video data. If, on one hand, the recent technology progress has facilitated the data collection process, on the other hand, it is impractical (and even impossible) for human operators to manually analyse this bulk of data. For this reason, tools for automated video analysis able to achieve high perfor- mance in terms of accuracy are needed, and resorting to high- performance computing (HPC) solutions becomes inescapable, since processing data on such a large scale is unfeasible on  1http://www.xeno-canto.org/ 2http://www.plantnet-project.org/ 3http://www.fish4knowledge.eu  single machines. Recently, various approaches have exploited HPC in ecology, most dealing primarily with either supporting observatory networks for data storage and sharing [4], [5] or computational models for environmental forecasting [6].

However, to the best of our knowledge, no existing system has tackled the problem of on-demand or real-time ecological data processing.

To this end, this paper aims at reporting the case study of large-scale underwater video processing for the system developed within the Fish4Knowledge project, which aims at supporting marine biologists in their research on coral reefs, targeted at studying fish population and biodiversity ? tasks which, so far, have been performed by employ- ing divers to manually count the fish in a specific area [7] and infer fish population?s fluctuations. The automatic processing system relies on computationally-intensive video analysis tools for producing meaningful information (e.g.

fish species counts), running on a thousand-node computing cluster (provided by the Taiwan?s National Center for High- performance Computing) with Load Sharing Facility (LSF) as a job submission/queue manager. This system differs from others tackling similar problems (e.g. [4], [5], [6]) by the type of environment under examination (real-life unconstrained underwater); the type of data being gathered (video footage) and the consequent difficulties such as network bandwidth and video resolution/frame-rate limitations (due to the connection between underwater cameras and the storage servers) and the real-time requirements of the algorithms (although the cameras recorded ?only? 12 hours per day, there was already 4 years? worth of videos had to be processed).

The remainder of the paper is as follows: Sect. II describes the video analysis tools to process underwater videos in order to extract information of fish species count in a given timeframe. Sect. III discusses the large scale video processing system pointing out issues such as load balancing, job submis- sion policies and system?s bottleneck. Sect. IV reports on the achieved results, while, in Sect. V a discussion summarising the key points of the case study together with some future directions on processing big data in ecology are given.



II. THE AUTOMATIC VIDEO ANALYSIS SYSTEM  The video analysis system processes each single video (recorded by the underwater cameras) in order to detect fish   DOI 10.1109/PDP.2014.80     Resolution No. of videos Processing. time  320?240 193,801 3 min 10 s 640?480 328,945 17 min 50 s  TABLE I NUMBER OF PROCESSED VIDEOS AND DISTRIBUTION BETWEEN LOW- AND  HIGH-RESOLUTION AND THE CORRESPONDING AVERAGE PROCESSING TIME.

and recognise the species they belong to.

Three are the main modules involved in these tasks: ? Fish detection: applies background modelling approaches  to learn how a scene looks without fish, then compares the model to each video frame to detect where fish are;  ? Fish tracking: matches fish detections in consecutive frames, thus avoiding to over-count fish;  ? Fish species recognition: infers the species of each de- tected fish by feeding a vector description of its visual features to a trained classifier.

A detailed description of the fish detection, tracking and recognition tools is beyond the scope of this paper and can be found in [8], [9]. The output of the video processing is stored into a MySQL database connected to a user interface [10] through which marine biologists issue queries on fish populations.

As of May 2013, the historical clip repository (dating back to 2009) consisted of 535,345 10-minute videos (with 8 fps) distributed between low-resolution (320?240) and high- resolution (640?480) ones, as shown in Table I, which also reports the average computation time (i.e. the time required to analyse a video and perform fish detection, tracking and recognition) for each videoclip on a machine equipped with a 48-core 2.3 GHz CPU and 128 GB RAM.

A simple computation quickly shows how serially process- ing such huge amount of videos would have been impractical: based on the average computation times and the video reso- lution distribution, it would have taken more than 12 years to process the whole data set. Resorting to parallel processing architectures was therefore necessary.



III. LARGE SCALE VIDEO PROCESSING  The large scale underwater video processing was executed on a supercluster (located at NCHC4 in Taiwan) which offers aggregate performance over 177 TFLOPS. More in detail, the supercomputer5 uses AMDR Opteron 6100 processors, about 3 TB memory cluster and over 25,600 computing cores and runs the LSF6 job queueing platform. However, because the access to the cluster is shared between several users/projects, during the processing period we were able to continuously use an average amount of 600 cores.

In this section, we will first introduce the computation workflow model, showing the processes involved and the  4http://www.nchc.org.tw/en/ 5http://www.nchc.org.tw/en/services/supercomputing/ 6http://www.platform.com/Products/platform-lsflsf  Fig. 1. High-level initial workflow for the master and slave processes.

interactions with the computation cluster and the database used for data storage; this description will be at a high level first, and it will be refined later on as problems and solutions are discussed; secondly, we will describe the parallel cluster architecture, its queueing features, the underlying hardware characteristics, the limitations that were imposed and how they were overcome; thirdly, we will describe the relevant database interface and structure, and the solutions adopted to avoid that the shared database server became the bottleneck for the hundreds of processes trying to access it at the same time.

A. Workflow model  The original workflow for the video processing task was relatively simple (Figure 1), and operated as follows: the master process (MP) spawns several slave processes (SP) which query the database for video identifiers, download the videos, run the video analysis algorithms (referred to as the video processing executable ? VPE) and save the output results to the database. The user can limit the number of cores used by the SPs running at a time, for fair use towards the other users of the cluster. For this reason, when the maximum number of cores is reached, the MP would stop spawning SPs until some cores are freed (i.e. until other SPs end their execution).

B. Cluster infrastructure  The compute cluster, which runs the video processing algorithms, consists of several machines sharing their CPU cores in a transparent way for the user, which allows a job     to run on cores belonging to different physical hosts, without the need of writing code for host communication. Each host is equipped with a 48-core 2.3 GHz CPU and 128 GB RAM.

The first design decision concerned the parallelization strat- egy: either on the video processing algorithms (i.e. paral- lelizing the internal mechanics of the code) or on the video data (i.e. launching as many serial VPEs as possible). Two main reasons led us to parallelize at the data level only: first of all, the algorithms have been designed and written to run single-threadedly, thus a complete rewrite would be impractical for our objectives. Moreover, the level of par- allelization is limited, since due the high number of core requests, the cluster infrastructure rarely assigns more than 20 cores to a single job (whereas typical parallel architectures for image processing provide thousands of cores able to perform simple operations, such as GPUs, rather than few powerful cores). The second reason concerned the fact that the cluster management system does not guarantee that all cores assigned to a job would belong to the same physical machine. Since core communication, in a parallel video processing algorithm, needs to be performed dozens of time per second, networking might have become a bottleneck.

As a side note, since we mentioned GPUs, it is worth explaining the reason why we did not use them. The GPU implementation of our fastest fish detection algorithm (ViBe [11]) on a 2496-core machine provided a 70-times speed-up with respect to the execution on a serial architecture. However, since we could run 600 simultaneous processes on the cluster, we would have needed at least 9 such GPU cards to achieve the same performance. Furthermore, the speed-up was verified on the motion detection algorithm only, which represents the smallest fraction of the computation, since the fish tracking and recognition modules are considerably slower and less apt to parallelization.

Once decided to keep running serial VPEs, while maximis- ing the number of simultaneous running process, issues on how the cluster would handle that many requests and the extent of the queue management and wait overhead were considered:  ? Serial VPE and multi-core jobs ? The interface for the submission of jobs to the cluster consists in a set of command-line applications provided by the LSF job queueing system. A job could be submitted to several dif- ferent queues: each queue defines its own job submission policy ? most importantly, the minimum and maximum number of cores per job. For example, there are queues which allow to assign a single core to each job (most appropriate for our serial VPE approach), while others require each job to be assigned to more than one cores, and this may lead to an efficiency problem, since VPEs are not able to exploit core parallelism.

In order to handle this issue we revised the original workflow as follows: when the MP creates a new SP, the latter is also given information on the number of cores C available for it, and launches C simultaneous VPEs. In this way it is ensured that no cores are left unused, even with queues requiring multiple cores per job.

? Maximum number of cores per queue ? As mentioned above, each queue also has a limit on the maximum number of cores that can be used at a given moment; when that limit is reached, additional jobs are marked as pending until other jobs complete and cores are freed.

However, fair use policy requires not to queue too many jobs when the core limit is reached, since this prevents other users, who might just want to run a one-time job, from gaining access to the cluster in reasonable time (since they would have to wait for all previously queued jobs to be started and finish). Therefore, the MP was modified so it would be aware of the total number of available cores, understand when that limit is reached, and if necessary stop creating new SPs for a while.

? Delay between consecutive jobs ? Administration policy imposes a delay of a few minutes (from 3 to 5) between two consecutive job starts in a given queue. According to Table I, 3-5 minutes is a considerable amount of time with respect to a total VPE execution time, especially for the low resolution videos. This limitation may cause only very few processes to run at the same time, in spite of the large number of cores available.

The solution to this problem was to lengthen the lifetime of SPs. Since the execution time of VPEs is practically fixed (it only depends on the resolution of the input video), the only way is to pack several consecutive VPE runs inside a single SP. In practice, each SP is parameterised by a repetitions value, R, which instructs it to launch R VPEs in sequence, to keep the job running for enough time. This idea, together with the solution for the first issue (see above), led to the following SP-internal workflow:  ? Rather than running a single VPE at a time, executing a set of C simultaneous VPEs (herein referred as VPE block) on a dedicated core each.

? For R times, launching sequentially a VPE block (i.e.

wait for the completion of the previous block to start the next one).

This guarantees that 1) all assigned C cores are used, and 2) the minimum running time for the whole SP is at least equal to the duration of a R consecutive single VPEs. In the actual implementation, in order to handle the case when, in a VPE block, some VPEs complete before others, thus leaving cores unused, the SP does not manage sequential VPE blocks internally, but:  ? It periodically checks for the number of used cores (up to C); if there are free cores, it launches a new VPE, and keeps track of the number of VPEs executed up to that point.

? When the number of launched VPEs reaches R ? C, it quits.

This second solution maximises core utilisation while keeping the job lifetime of approximately the same length as in the case of sequential VPE blocks.

C. Database interaction  The execution of a VPE on a video provides as output the fish detections and trajectories in the processed video. This information is currently stored in a MySQL database (version 5.5.28) for further analysis. The server machine is equipped with a Dual Intel X5650 2.67 GHz CPU, 144 GB RAM and 2 TB FC connecting to a SAN storage.

The main tables involved in the video processing are those containing fish detection and tracking results (table called fish), and the lists of all existing videos (videos) and already processed videos (processed_videos). In detail, the database interactions for each video processing are: 1) selection of the video to be processed by the VPE (query- ing the video and processed_videos tables) and 2) saving of processing?s results to the database (writing the processed_videos table). The issues arisen when dealing with the database can be summarised as follows:  ? Bottleneck on the fish table ? After the VPE com- pletes processing a video, the results are to be written to the database. Because of the high number of parallel processes, the time needed to insert a single fish detection to the database may take a few seconds, which multiplied by the number of processes (up to 600) and the number of fish instances per video (in the order of hundreds or thousands, depending on the video) unavoidably would cause the database server to become unresponsive.

In order to minimise the number of database queries for results insertion, we modified the ORM (Object-relational mapping) software employed to interface the VPE to the database, so that it caches insertion queries, rather than executing them immediately, and runs a single big query inserting all cached rows at once. In this way, we are able to drastically reduce the number of queries performed (by a factor of 100, i.e. the maximum number of cached queries). The only risk is that a failure (e.g.

due to timeout) in the query may cause the loss of several fish detections instead of just one. However, the testing phase of this approach showed that very rarely, and only for very short times, queries queued in the database server. We did not use solutions based on federated tables because they show several limitations: the performance when doing bulk inserts is slower than with other table types, and, federated tables do not support indexes and this is necessary for querying large tables.

? Atomic selection of video ? When the SP starts a VPE, it has to provide the latter with the video to be processed.

By ?video? we mean both the video identifier (ID) and the video file path. The video ID is retrieved by querying the video and processed_videos tables, to find the first (chronologically) video not processed yet. After the video ID is retrieved, it is passed to the VPE which up- dates the processed_videos table, to prevent other VPEs from processing the same video. However, since the video ID retrieval and the processed_videos update are not performed atomically (i.e. after the video  ID is selected, other processes could read the database before the VPE updated processed_videos), the probability that multiple processes would select the same video ID is high, given the number of parallel jobs.

To handle this problem, we introduced a new auxiliary table called reserved_videos so that: when the SP looks up the next video to be processed, it also checks if that video is in the reserved_videos table; if it is, then the SP skips it and looks for the next one; otherwise, it confirms the video ID selection and puts it into reserved_videos. This guarantees that a video ID is selected only by a single SP. However, what if the VPE processing that video fails for some reasons and does not manage to process it? In this case, no other SPs would process that video again, since it is in the reserved_videos table. To avoid this, we added a timestamp field into the reserved_videos table, so that the ?reservation? only holds for a while. In other words, a reserved video could be selected again if a few days have passed since its reservation, and it has not been marked as completed in processed_videos.

? Avoid too frequent video selections ? Given the size of the video table (about 550.000 records) and the increasing size of the reserved_videos and processed_videos tables, after a while the query for the selection of the videos to be processed may start taking too long; this causes the same problem occurred for the insertion of fish detections, i.e. database queries would queue faster than they are being processed.

For this reason, we modified the behaviour of the SP for what concerned the video selection: rather than querying the database to get a single video ID for a newly started VPE, it now selects the video IDs in advance for all VPEs it would be starting during its lifetime (i.e. R ? C, as defined above). Assuming R = 30 (value used in our case), this reduces the number of queries by about two orders of magnitude.

The final workflow of the system, applying the modifica- tions described above to the simple model in Fig. 1, resulted in the schema depicted in Fig. 2. The main difference from the previous scheme is that also SPs internally manage multiple background VPE sub-processes to keep all cores busy, and the retrieval of video IDs is performed only once at the beginning, rather than for one VPE at a time.



IV. RESULTS  The processing of the historical video dataset on the super- computer described in the previous section took 70 days (the estimated time on a single core was about 12 years) using 600 cores 24 hours a day. The design strategies described previously were necessary because the first version of the workflow (see Fig. 1) would unavoidably end up overloading the system.

At the video processing completion, the fish table had about 1.5 ? 109 fish detections and the whole database size consisted of about 300 GB. Therefore, the automatic video     Fig. 2. Final workflow for the master and slave processes and VPE sub- processes.

analysis executed on the supercomputer allowed us to turn about 200 TB of raw video data into 300 GB of useful information ready to be explored by marine biologists.



V. CONCLUSION  In this paper we introduced the problem of large-scale underwater video processing and analysed the technical diffi- culties and challenges of dealing with a huge amount of videos in reasonable time. The context of this work concerns the use of underwater cameras for automatically monitoring fish populations thanks to the use of fish detection, tracking and recognition software running on the captured videos. However, the large number of video clips (more than 500,000 10-minute videos since 2009) and the kind of processing to be performed (which takes longer than the actual duration of the videos) made it impossible, in terms of time required for process- ing, to run the video analysis software on common general- purpose PCs. For this reason, we resorted to massive parallel- computing infrastructures to execute the video analysis al- gorithms in order to reduce the processing times. However, simply increasing the number of available cores turned out to be just not enough to solve the large-scale processing task, as many other problems arose, from administrative usage policies of the cluster to database synchronisation and bottlenecks. To tackle all these problems, a suitable system workflow was designed and proved to work effectively on the given scenario.

It is important to point out that such workflow may be suitable to other applications, e.g. for human video surveillance, with  a processing pipeline (video capture, target identification, statistical analysis) similar to the one here presented, since the knowledge on the visual appearance of the targets may be encapsulated inside the target detection, tracking and classifi- cation algorithms. The source code of the algorithms is freely available online7. As future work on this topic, we plan on investigating algorithm-level parallelisation (instead or beside the data-level one) and intelligent workflow designs, which are able to select the computer vision algorithms used to process a video in accordance to user requirements on the accuracy of the results or the speed of computation. In conclusion, combining automatic analysis tools and HPC facilities allowed us to distill the initial massive raw video data (about 200 TB) and to present it to the end-users in a coherent and concise form, thus providing a very powerful tool and a big dataset containing billions of detected fish (the first ecological dataset of that size) for marine biologists to carry out exhaustive (and never done before) research on underwater life.

