IOMRA -- A High Efficiency Frequent Itemset  Mining Algorithm Based on the MapReduce

Abstract?The goal of Frequent Itemset Mining (FIM) is to find the biggest number of frequently used subsets from a big transaction database. In previous studies, using the advantage of multicore computing, the execution time of an Apriori algorithm was sharply decreased: when the size of a data set was more than TBs and a single host had been unable to afford a large number of operations by using a number of computers connected into a super computer to speed up execution as being the obvious solution. Some parallel Apriori algorithms, based on the MapReduce framework, have been proposed. However, with these algorithms, memory would be quickly exhausted and communication cost would rise sharply. This would greatly reduce execution efficiency. In this paper, we present an improved reformative Apriori algorithm that uses the length of each transaction to determine the size of the maximum merge candidate itemsets. By reducing the production of low frequency itemsets in Map function, memory exhaustion is ameliorated, greatly improving execution efficiency.

Keywords?Frequent Itemset Mining; Aprior; MapReduce; Hadoop

I. INTRODUCTION The data mining algorithm has been widely used in  different fields. As the algorithm needs a lot of information as the basis for the exploration, quickly finding the useful information from a huge dataset is important. But when a single host cannot afford large amounts of computation, using grid computing, cloud computing [1][11]-[15], the Hadoop [2] and MapReduce computing frameworks, etc., the use of multiple computers to compute the Apriori algorithm has been put forward.

Quite a few Apriori algorithms using Hadoop and MapReduce computing frameworks to do parallel operations have been proposed [3]-[7]. The One-phase [4] algorithm produces all candidate items at the same time, but then memory occupation becomes a serious problem. The K-phase [3] algorithm, using a multiple MapReduce computing framework to generate all candidate itemsets, effectively solves the memory problem, but this often increases communication time.

The FAMR algorithm [9] uses the AprioriTID [8] for pre-  processing, then uses the Map function to generate all candidate itemsets at the same time. This reduces the amount of candidate projects in a Map task making a significant speed improvement. But in a Map task, there are still a lot of low- frequency itemsets generated. Therefore, reducing the generation of low frequency itemsets is very crucial.

In this paper, based on the FAMR algorithm, a new algorithm optimizing the performance of the FAMR algorithm, is put forward. Firstly, using the AprioriTID algorithm to do pre-processing will delete all low frequency 1-item itemsets in the original data. Then, the length of every transaction (L) and the minimum support (N) are calculated to determine the possible longest candidate itemsets in the Map task. Effectively reducing the generation of low frequency itemsets in this way, the new algorithm will solve the memory use problem, communication cost, and improve the efficiency of the mining operation.

The rest of the paper is organized as follows: One-phase, K-phase, FAMR as well as the time costing of every phase in the MapReduce framework will be analyzed in Section 2. In Section 3, the improved algorithm, Improve Optimization MapReduce Algorithm (IOMRA), is introduced and Section 4 presents the experimental results. Finally, the conclusion is given in Section 5.



II. RELATED WORKS The Frequent Pattern Mining algorithm[11]-[15] is one of  commonly used data mining techniques. Several Apriori algorithms, based on the MapReduce framework, have been proposed, but the most well-known and popular data mining techniques are the One-phase algorithm [4], K-phase algorithm, [3] and the FAMR [9]  algorithm. The time cost of each stage in the MapReduce process of these three algorithms will be analyzed.

A. Apriori Algorithm On MapReduce (One-phase) A data mining algorithm based on Hadoop [4] was  proposed by L. Li and M. Zhang in 2011. The main advantage of the Apriori algorithm used the MapReduce framework to   DOI    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247    DOI 10.1109/CSE.2014.247     join multiple computers for parallel computing. Using a single MapReduce operation, the algorithm produces all candidate items at one time in the Map task, and the form of every candidate itemset is a product with < Key, value > form. And then, according to the differences of Key, the candidate items are classified and counted by Reduce according to the minimum support for screening the high frequency candidate itemsets. By improving the traditional Apriori algorithm, it can be adapted to the MapReduce framework for distributed parallel computing. But, as it will produce all candidate itemsets at one time in the Map task, there will be a large memory footprint, seriously decreasing the operating efficiency.

B. Parallel Apriori Algorithm(K-phase) In 2012, Ning Li and three other scholars proposed a new  Apriori algorithm [3] based on Hadoop that can effectively solve the memory problem. The authors applied the K-phase method (multiple-phase MapReduce operations), which is similar to the traditional Apriori algorithm. It also finds all frequent itemsets at each stage by multiple MapReduce circular computing divided into multiple stages to process operation saving on memory use compared with the One-phase method.

But when using the MapReduce framework operation a number of times, communication time drastically increases.

C. FAMR Algorithm Based on MapReduce Framework, Huang put forward the  Frequent Patterns Mining Algorithm [9] in 2013. He used the AprioriTID [8] to do pre-processing on initial data. The advantages of the method are identifying 1-item high frequency itemsets and deleting 1-item low frequency itemsets. When taking the TID form back to the original data format, the raw data can be compressed. After using the One-phase algorithm to generate all (2~n)-item candidate itemsets at once time, reducing the generation of candidates, the amount of memory will also be greatly reduced, proportionally making a significant speed improvement. But as the algorithm?s mechanism will produce all (2~n)- item candidate itemsets at the same time in the Map task, when there is a large amount of data the algorithm will generate large amounts of candidate itemsets. The memory footprint will be large.

D. Analyze Each Stage?s Time Cost in a Map-Reduce Operation In the MapReduce framework, from the perspective of  program design, the treatment scheme is Input - > Map - > Partition - > Sort - > Combine - > Reduce - > Output. Starting from the first Map task for the output, the Copy stage of the Reduce task will Copy the output of Map to Reduce, until all the Map tasks are completed, the Copy stage is ended.

Furthermore, in order to estimate the communication overhead of shuffling in the total of Mappers and Reducers execution time under different input data sizes, another experiment was run. Node number 3 was deployed, and the data was, divided into 6 and 3 blocks. The FAMR algorithm was run to test the percentage of all copy stages during the total Mappers and Reducers execution time on D100 K to D2000 K transaction numbers (the amount of data increased from 1.94 MB to 37.8 MB). As shown in Figure 1, the smallest percentage any copy stage took in the whole running time was  48.7%, while the biggest was 62.7%. It is clear that the Copy stage seriously affected the execution efficiency.

Fig. 1. Communication overhead of all copy stages during the total Mappers and Reducers execution time under different input data sizes.

The reasons for the Copy stage influencing the performance of the overall operation include the following three: (1) Data is an entirely remote copy. (2) When using the HTTP protocol for data transmission, a large amount of data needs transport causing data transmission delay. (3) Since the Map task produces all candidate itemsets, memory footprint becomes a problems, seriously affecting the speed of data transmission.

So, in order to improve the performance of an operation data transmission pressure, the time cost of the network transmission, and data output in the Map task need to be reduced. This not only alleviates memory in the Map, but also reduces transmission quantity, the pressure of network communication, and the data that need to computed in the Reduce task, increasing operation efficiency.



III. PROBLEM DESCRIBE For the FAMR algorithm, the AprioriTID [8] was used to  do pre-processing on original data. The advantages of the method lie in the deleting of 1-item, low frequency itemsets. It then takes the TID form back to the original data format, making it possible for the raw data to be compressed. After using the One-phase algorithm to generate all (2~n)-item candidate itemsets at one time, thus reducing the generation of candidate itemsets, it also greatly reduces the use of memory, significantly speeding up the process. However, the algorithm still will generate large amounts of low frequency candidate itemsets.

TABLE I. NEW DATA INFORMATION  Trans ID Itemsets  1 {B,C}  2 {A,B,C}  3 {A,C,D}  4 {A,C,D,E,F}  Table 1 shows the data information that after using the TID form to delete 1-item, low frequency itemsets from original  D100K D400K D900K D2000K  3-Map 50.40% 51.60% 48.70% 50.20%  6-Map 49.40% 57.60% 62.70% 58.10%  20.00%  40.00%  60.00%  80.00%  100.00%  T he  P er  ce nt  ag e o  f T  he C  op y  St ag  e T  ab le     data. If support is set at 30%, the high-frequency itemsets must at least have 2 transaction records. When the average transaction length is 3, the length of all records will be different, so the candidate itemsets for each transaction are different.

Transaction number 4 could have been incorporated into the items{A, C, D, E, F}, but clearly {A, C, D, E, F} is not a high frequency itemset.

In this paper, a new algorithm is proposed?Improved Optimization MapReduce Algorithm (IOMRA)?to improve on the execution efficiency of the FAMR algorithm. After transitioning the TID form into the original data format, records of length and support are used to determine the possible longest candidate itemsets. Thus, effectively reducing the generated of low frequency itemsets in the Map operation, and, by alleviating the serious problem with the amount of memory used, operation efficiency is improved.

As table 2 shows, the length of every transaction was determined, and assuming the minimum support was 40%, for each candidate itemsets, existing in at least two transaction records which length would be greater than or equal to the length of the candidate itemsets, the candidate itemsets would be high frequency. Otherwise, the candidate itemsets would be low frequency.

TABLE II. LENGTH OF TRANSACTION RECORD  Trans ID Itemsets Length  1 {B,C} 2  2 {A,B,C} 3  3 {A,C,D} 3  4 {A,C,D,E,F} 5  From table 2, the longest of candidate itemsets is 5. The transaction that can generate 5-itemsets candidate  has {4}, that which generates 4-itemsets candidate has {4}, that which generates 3-itemsets candidate have {2, 3, 4}, and the transaction that generates 2-itemsets candidate has {1, 2, 3, 4}.

Since the 3-itemsets candidate transaction can generate 3- itemsets and 2-itemsets candidate which is greater than or equal to 2, but the number of transactions that can generate more than 3-itemsets candidate is less than 2, so the length greater than 3- itemsets candidate are low frequency itemsets. Since, when using the Map/Reduce framework to generate candidate itemsets, the possible longest candidate itemsets is 3, only 2- itemsets and 3-itemsets candidate need to be generated; it is not necessary to generate 4-itemsets and 5-itemsets candidate, as shown in table 3.

TABLE III. CANDIDATE ITEMSETS OF TRANSACTION RECORD  Trans ID Candidate Itemsets 1 {B}{C}{B,C} 2 {A}{B}{C}{A,B}{A,C}{B,C}{A,B,C} 3 {A}{D}{C}{A,D}{A,C}{C,D}{A,C,D}   {A}{C}{D}{E}{F}{A,C}{A,D}{A,E} {A,F}{C,D}{C,E}{C,F}{D,E}{D,F}{E,F} {A,C,D}{ A,C,E}{A,C,F}{A,D,E}{A,D,F} {A,E,F}{C,D,E}{C,D,F}{D,E,F}{C,E,F}  Thus, based on the possible longest itemsets calculation, the algorithm effectively reduces the generation of low frequency itemsets in the Map stage, and also reduces execution time and memory usage.

In this study, the main problem was to find the length of possible longest candidate itemsets, so we define some notations as follows.

Let D be a set of transactions, with H is the number of transactions. The length of each transaction is Ti (1?i?H), the longest transaction in D is N and the minimum support is S.

No(i) denotes the total number of transaction with the length of transaction is equal to i. Therefore, the length of possible longest candidate itemsets M should satisfy the conditions that No(M) >= H*S and No(M+1) < H*S.

Since M is the length of possible longest candidate itemsets, we only need to generate all 2-M candidate itemsets in Map stage in IOMRA algorithm. This will reduce the generation of M+1-N candidate itemsets in the Map stage, and also reduces execution time and memory usage.

In Figures 2, 3, 4, 5, 6, the pseudo-code for the IOMRA algorithm is given. First of all, pre-processing is done on the original transaction database. As shown in Figure 2, the initial transaction database is converted into TID format using the AprioriTID algorithm to find the 1-item high frequency itemsets. The 1-item low frequency itemsets are later removed from the TID, then the new TID form reverts to the original data format.

First Task Input: D=Database format, min=minimum support count Output: T=Transforming the TID table into a Database format Scan D and structure a TID table For each item in TID table  If(transaction.size < min) Delete the item; Output(T); End;  End;  Fig. 2. Delete the first-order low-frequency itemsets.

Calculate the length of every transaction according to the length of the transaction and the minimum support; determine the possible longest M of candidate itemsets. As shown in Figure 3.

Second Task Input: T=Database format, min=minimum support count Output: M= the max merged ordered itemsets size Scan D and compute every transaction?s length For each ordered itemset  For each transaction in T If(order.size ? transaction?s length)  Count++; If(Count< minmum support count)  Delete the ordered set; End; End; M=Max(order.size) Output(M); End;  Fig. 3. Largest merged ordered candidate itemsets M.

As shown in Figure 4, the Map task generates all candidate itemsets with a size not more than M. According to the different key, the Reducing task classifies the candidate     itemsets and counts those with the same key, and then filters out the high frequency candidate itemsets. Then output data are stored in the HDFS.

Map Task Input: Si=split I, M Output: <key,1>,key is all of candidate itemsets C= candidate itemset, the itemset?s size?M For each transaction i in I Map(key,value(i))  For each item C in i Output (C,1);  End; End;  Fig. 4. Executing Map task.

In order to reduce the transmission data from the Map to Reduce, use Combine to count the output of Map. However, the combine function does not screen the high frequency itemsets. The Combine function is shown in Figure 5.

Combine Task Input: <key1,value1>,key1 is one of candidate itemsets Output:<key1,value2> Reduce(key1,value1)  Sum=0; For each value1 in key1 list  Sum+=value1; End;  Output (key1,sum); End;  Fig. 5. Executing Combine task.

The input for the Reduce function is the data obtained from the Map function of each host. The Reduce task classifies the candidate itemsets and counts the values with the same key, and then compares them with the minmum support for screening the high frequency itemsets. The pseudo-code for Reduce function is shown in Figure 6.

Reduce Task Input: <key1,value1>,key1 is one of candidate itemsets, minimum support count Output:<key1,value2> Reduce(key1,value1)  Sum=0; For each value1 in key1 list  Sum+=value1; End; If (sum ? minimum support count)  Output(key1,sum); End;  End;  Fig. 6. Executing Reduce task.



IV. EXPERIMENTAL RESULTS In order to verify the efficiency of the IOMRA algorithm,  several evaluation experiments were conducted to test its performance as well as that of the other three algorithms. An IBM data generator was used to produce the experimental data.

The Hadoop was used to do the distributed parallel computing.

The experiment tested the execution time for different amounts of data, the minimum support, and the Map tasks, and then compared the memory use of each.

A. Experimental Set The experiments are run in the Hadoop environment, and  three nodes were established to do the distributed parallel  computing. The detailed hardware and software specifications are shown in the following:  1) CPU  Intel(R) Xeon(R) CPU X3440 @2.53GHz *1  Intel(R) Xeon(R) CPU X3430 @2.40GHz *2  2) Memory         8G DDR3 Memory  3) OS                  CentOS release 5.6  4) Compiler        Java/jdk 1.6.0_24  5) Cluster            Hadoop 1.0.0  In the experimental data format that the IBM data generator produced, the T represented the average time for trading data, I represented the maximum average length of frequent items, D the number of transactions, and N the number of items.

The Hadoop experimental environment was composed of three nodes and the block size adopted the default value of 32 MB. The number of Map tasks was on auto.

Because One-phase [4] algorithm took the longest, only the execution time of K-phase [3], FAMR [9], and IOMRA were compared, as well as support, and the number of Map tasks.

1) The following experiments compared the execution time :  a) When the degree of support was 0.1%, execution time of the K-phase, FAMR, and IOMRA on T5I4D100KN100K, T5I4D400KN100K,T5I4D800KN100K, T5I4D2000KN100K, and T5I4D5000KN100K was tested.

b) When the database was T10I4D400KN100K, and the number of Map tasks was 3 (the data on average was divided into 3 block storage sections in HDFS), the execution time of K-phase, FAMR, and IOMRA was tested when the support was 0.1%, 0.15%, and 0.2%.

c) When the database was T10I4D400KN100K, support was 0.1%, the Map task number is 6,3,1 (the data on average divided into 6,3,1 block storage sections in HDFS), the execution  time of FAMR and IOMRA was tested.

2) The next experiment was analyzing the overhead of all copy stages for the total number of Map and Reduce execution times under different input data sizes was tested:  a) When the support was 0.1%, the number of Map tasks was 6,3, the overhead of all copy stages in the total number of Map and Reduce execution times for the IOMRA algorithm with different input data sizes.

B. Performance and Analysis As shown in Figure 7, with the increase of the size of data,  the execution time for the three kinds of algorithm was rising.

However, the execution time for IOMRA was always lower than that of the other two algorithms. Compared with the K- phase method, which saved on memory, but it often used the MapReduce framework for generating all candidate itemsets, thus increase in basic consumption time. At the same time the communication time kept on increasing. These seriously affected execution efficiency. The FAMR method, in     comparison, used the TID form to find the 1-item frequency itemsets, thus reducing the generation of candidate itemsets in Map end. Although it did reduce the execution time, it also generated (2~n)-itemsets candidate. The memory problem still existed, directly affecting the execution time. By reducing the generation of useless candidate itemsets in the Map end, memory use was reduced, and by using one time MapReduce framework, execution time and communication cost were reduced improving execution speed.

Fig. 7. Execution time of the three kinds of algorithms on five kinds of databases.

As shown in Figure 8, based on the same data, when support increased from 0.1% to 0.20%, the execution time of the three kinds of algorithm was reduced. The IOMRA algorithm?s operation time was the lowest. The reason was that, with the increase of support, the number of high frequency itemsets was reduced. For the K-phase algorithm, each phase of the MapReduce operation produced fewer candidate itemsets, but communication consumption was significant. For FAMR, the low frequency 1-itemsets were deleted by using the TID form, consequently, the number of candidate generated in the Map side could also be reduced. For the IOMRA algorithm, due to the increase of support, the possible longest candidate itemsets was reduce from 14 to 5 times, thus reducing the number of candidate itemsets as well. Furthermore, when the support was 0.2%, the execution time of the FAMR and IOMRA algorithms was almost the same, because of increased support. After using the TID form to preprocess the initial data, the transformed data was negligible. The possible longest candidate itemsets that IOMRA could determine was limited.

When the support increased to a certain degree, the possible longest candidate itemsets that the FAMR and IOMRA algorithms was the same, the execution time of these two algorithms being very close.

As Figure 9 shows, based on the same data, when the Map tasks increased from 1 to 6, the IOMRA algorithm performed faster. When the number of the data blocks was increased, more Map tasks were needed for the operation making full use of multiple computers to do parallel operation and less execution time, which greatly improved execution efficiency.

However, when the data block was divided into too many portions, the computing time increased, because the Map tasks would also increase influencing the task scheduling of JobTracker. Also, as the MapReduce framework suite would realize communication based on network protocols such as TCP/IP, RPC, and HTTP traditional, the communication overhead of the MapReduce increased affecting the overall execution efficiency. So, in the same hardware environment, the segmentation of the data would also affect the computational efficiency.

Fig. 8. Execution time of the three algorithms on three kinds of support  Fig. 9. Execution time of the two algorithms on different number of Map tasks  As shown in Figure 10, when the number of Map tasks was 3, the smallest percentage necessary of the running time was 45.5%, and the biggest 46.8%. When the number of Map masks was 6, the smallest percentage necessary of the running time was 49.4%, while the biggest was 63.9%. So, in conclusion, the Copy stage seriously affected the operation efficiency. But when the number of Map tasks was 6, the execution time was shorter than with 3, and the overhead of the copy stage had a bigger impact on the overall execution. Since the number of Map tasks was 6, Map-Reduce communication would have to happen 6 times meaning that the more Map  D100K D400K D800K D2000K D5000K K-phase 121.3 121.5 120.7 125.3 147.9 FAMR 30.3 30.5 31 34.4 41.6 IOMRA 22.1 23.3 23.5 24.5 29.5       T im  e( se  c.

)  0.10% 0.15% 0.20% K-phase 684.3 312.7 272.8 FAMR 222.2 35.6 22.1 IOMRA 153.6 34.1 21.1           T im  e( se  c.

)  6-Map 3-Map 1-Map  FAMR 151.8 222.2 450.2  IOMRA 141.2 153.6 309.1       T im  e( se  c.

)     tasks would be run, the more communication overhead was generated in the copy stage.

Fig. 10. Communication overhead in Map tasks and Reducing execution time with different input data sizes  According to the experimental results, by using the IOMRA algorithm that proposed in this paper, the transaction records were used to determine the possible longest candidate itemsets, thus reducing the number of candidate itemsets in the Map end, and reducing the computation time and memory consumption. At the same time the amount of data in Map end can be estimated to make full use of resources; realizing the parallel execution, and avoiding communication delay caused by segmenting the Map task too much.



V. Conclusion With the Internet being widely used, many companies that  provide network services are producing more than TB amounts of data every day. Using data mining technique to quickly and efficiently find useful information from the large amounts of data is a necessity. In order to make data mining execution more cost-effective for a single host, this study used the parallel processing ability of the Hadoop cloud computing platform to execute the IOMRA algorithm on a number of computers. Also, IOMRA can improve the use of memory of the previous frequent pattern mining algorithm.

In comparison to the K-phase algorithm, this algorithm dealt with more than 20 MB data reducing execution time by 220sec, and compared to the FAMR algorithm, the shorts execution time was reduced by 60sec. By reducing the number of candidate itemsets in the Map end, memory usage was diminished by the reduction of the data that needed to be transferred from the Map end to Reduce end, thus shortening the transmission time, and improving execution efficiency.

And, this algorithm, having the possible longest candidate itemsets as well as the estimated amount of data that the Map side should generate, made the IOMRA algorithm able to fully use the environment of distributed parallel computing, reducing the communication cost in Map tasks. In future, our work will focus on optimizing the IOMRA in reducing the amount of memory occupied, and thus raising the utilization ratio of the memory.

