Using Association Rules Without Understanding Their Underlying Causality  Reduces Their Decision Value

Abstract Association rules are a data mining cornerstone. Associa? tion rules greatest impact is in helping to make decisions.

One association rule quality measure is a rule's decision value. Association rules are often constructed using sim? plifying assumptions that lead to naive results and conse? quently naive decisions. Perhaps the greatest impact on decision value quality comes from treating association rules as causal statements without understanding whether there is, in fact, underlying causality. Complete knowl? edge of all possible factors might lead to a crisp descrip? tion of whether an effect will occur. However, it is un? likely that all possible factors can be known. Common? sense world understanding accepts imprecision, uncertainty and imperfect knowledge. People recognize that a complex collection of elements can cause a particular effect. The events in the complex may not be known; or, what con? straints and laws the complex is subject to. Sometimes, the details underlying an event can be known to a fine level of detail, sometimes not. Usually, commonsense reasoning is more successful in reasoning about a few large-grain sized events than many fine-grained events. A satisficing solution would be to develop large-grained solutions and only use the flner-grain when the imprecise? ness of the large-grain is unsatisfactory.

1. Introduction  One of the cornerstones of data mining is the develop? ment of association rules. Association rules greatest im? pact is in helping to make decisions. One measure of the quality of an association rule is its relative decision value.

Association rules are often constructed using simplifying assumptions that lead to naIve results and consequently naive and often wrong decisions. Perhaps the greatest area of concern about the decision value is treating association rules as causal statements without understanding whether there is, in fact, underlying causality.

Causal reasoning occupies a central position in human reasoning. It plays an essential role in human decision? making. Considerable effort over thousands of years has been spent examining causation. Whether causality exists at all or can be recognized has long been a theoretical speculation of scientists and philosophers. Serious questions have been asked whether commonsense percep-  tions of the world match the underlying reality. These concerns run from the implications of Zeno's paradox and Plato's cave to Einstein's relativity theory and modem string theory. An introduction to some of these issues may be found in Mazlack [2004].

At the same time, people operate on the commonsense belief that causality exists.

Causal relationships exist in the commonsense world; for example:  When a glass is pushed off a table and breaks on the floor  it might be said that  Being pushed from the table caused the glass to break.

Although,  Being pushed from a table is not a certain cause of breakage; sometimes the glass bounces and no break occurs; or, someone catches the glass before it hits the floor.

Counterfactually, usually (but not always),  Not falling to the floor prevents breakage.

Sometimes,  A glass breaks when an errant object hits it, even though it does not fall from the table.

Positive causal relationships can be described as: if a then f3 (or, a --;. f3). For example:  When an automobile driver fails to stop at a red light and there is an accident it can be said that the failure to stop was the accident's cause.

However, negating the causal factor does not mean that the effect does not happen; sometimes effects can be over? determined. For example:  An automobile that did not fail to stop at a red light can still be involved in an accident; another car can hit it because the other car's brakes failed.

Similarly, simple negation does not work; both be? cause an effect can be overdetermined and because negative statements are weaker than positive statements as the negative statements can become overextended. It cannot be said that ,a --;. ,f3, for example:    Failing to stop at a red light is not a certain cause of no accident occurring; sometimes no accident at all occurs.

Some describe events in terms of enablement and use counterfactual implication whose negation is implicit; for example [Ortiz, 1999a]:  Not picking up the ticket enabled him to miss the train.

There is a multiplicity of definitions of enable and not? enable and how they might be applied. To some degree, logic notation definitional disputes are involved. These issues are possibly germane to general causality theory.

However, it is not profitable to the interests of this paper to consider notational issues; this paper is concerned with the less subtle needs of data analysis.

Negative causal relationships are less sure; but often stated; for example, it is often said that:  Not walking under a ladder prevents bad luck.

Or, usually (but not always),  Stopping for a red light avoids an accident.

In summary, it can be said that the knowledge of at least some causal effects is imprecise for both positive and negative descriptions. Perhaps, complete knowledge of all possible factors might lead to a crisp description of whether an effect will occur. However, it is also unlikely that it may be possible to fully know, with certainty, all of the elements involved. Consequently, the extent or actuality of missing elements may not be known. Addi? tionally, some well described physics as well as neuro? biological events appear to be truly random [Freeman, 1995]; and some mathematical descriptions randomly un? certain. If they are, there is no way of avoiding causal imprecision.

2. Satisficing  People do things in the world by exploiting common? sense perceptions of cause and effect. Manipulating per? ceptions has been explored [Zadeh, 1999] but is not the focus of this paper. The interest here is how perceptions affect commonsense causal reasoning, granularity, and the need for precision.

When trying to precisely reason about causality, com? plete knowledge of all of the relevant events and circum? stances is needed. In commonsense, every day reasoning, approaches are used that do not require complete knowl? edge. Often, approaches follow what is essentially a satis? ficing [Simon, 1955] paradigm. The use of non-optimal mechanisms does not necessarily result in ad hocism; Goodrich [2000] states:  "Zadeh [1998] questions the feasibility (and wis? dom) of seeking for optimality given limited re? sources. However, in resisting nai've optimizing, Zadeh does not abandon the quest for justifiability, but instead resorts to modifications of conventional logic that are compatible with linguistic and fuzzy understanding of nature and consequences."  Commonsense understanding of the world tells us that we have to deal with imprecision, uncertainty and imper? fect knowledge. This is also the case with scientific knowledge of the world. An algorithmic way of handling  imprecision is needed to computationally handle causality.

Models are needed to algorithmically consider causes and effects. These models may be symbolic or graphic. A difficulty is striking a good balance between precise for? malism and commonsense imprecise reality.

3. Complexes  When events happen, there are usually other related events. The entire collection of events can be called a complex. The events can be called the elements of the complex.

A "mechanism" [Simon, 1991] or a "causal complex" [Hobbs 2001, 2003] is a collection of events whose occur? rence or non-occurrence results in a consequent event happening. Hobbs' causal complex is the complete set of events and conditions necessary for the causal effect (consequent) to occur. Hobbs suggests that human casual reasoning that makes use of a causal complex does not require precise, complete knowledge of the complex.

(Different workers may use the terms "mechanism and "causal complex" differently; I am using them as these author's use them.)  Each complex, taken as a whole, can be considered to be a granule. Larger complexes can be decomposed into smaller complexes; going from large-grained to small? grained. For example, when describing starting an auto? mobile, A large-grained to small-grained, nested causal view would start with  When an automobile's ignition switch is turned on, this causes the engine to start.

But, it would not happen if a large system of other nested  conditions were not in place.

There has to be available fuel. The battery has to be operational. The switch has to be connected to the battery so electricity can flow through it. The wiring has to connect the switch to the starter and ignition system (spark plugs, etc.). The engine has to be in good working order; and so forth.

Turning the ignition switch on is one action in a complex of conditions required to start the engine. One of the events might be used to represent the collection of equal grain sized events; or, a higher level granule might be specified with the understanding that it will invoke a set of finer-grained events. In terms of nested granules, the largest grained view is: turning on the switch is the sole causal element; the complex of other elements represents the finer-grains. These elements in tum could be broken down into still finer-grains; for example, "available fuel" could be broken down into:  fuel in tank, operating fuel pump, intact fuel lines, and so forth.

start car: turn on ignition switch  ?/ '''? available  fuel battery  operational wires  connect: battery to  ignition switch  wires connect: ignition  switch to  turn on ignition switch  /? starter, spark plugs fuel  in tank  operating fuel  pump  intact  fuel lines  Figure 1. Nested causal complex.

Sometimes, it is enough to know what happens at a large-grained level; at other times it is necessary to know the fined grained result. For example, if  Bill believes that turning the ignition key of his automobile causes the automobile to start.

It is enough if  Bill engages an automobile mechanic when his automobile does not start when he turns the key on.

However,  The automobile mechanic needs to know a finer? grained view of an automobile's causal complex than does Robin.

Instead of being concerned with all of the fined grained detail, a better approach may be to incorporate granulation using rough sets and/or fuzzy sets to soften the need for preciseness. And then accept impreciseness in the de? scription. Each complex can be considered to be a granule.

Larger complexes can be decomposed into smaller complexes. Thus, going from large-grained to small? grained.

Hobbs [2001] uses first order logic to describe his causal complexes. Pearl [2000] develops probabilistic causal networks of directed graphs (DAGs).

The causal complexes explicitly considered by Hobbs and Pearl have a required structure that may be overly re? strictive for commonsense causal understanding, namely:  ? If all of the events in the causal complex appropriately happen, then the effect will occur  ? There is nothing in the causal complex that is irrelevant to the effect  These requirements are probably too precise and exten? sive to be realized in a commonsense world. Sometimes, only some of the events need to happen. For example,  Someone may be able to save more money:  ? If their taxes are lowered or ? If they earn more money.

Either even may lead to greater savings. However,  Neither may result in increased savings if they also have to pay a large divorce settlement.

So, if all of the events happen, the effect may happen. If some of the events happen, the effect may happen. In the commonsense world, we rarely whether all of the events are in a complex are necessary. For example,  A man may want to attract the attention of a woman. He may do a large number of things (e. g., hair, clothes, learn to dance, etc.). If he does at? tract the woman, he may never know which things were relevant and which were not  An issue is how to distinguish between what is in a complex and what is not. Another issue is how to dis? tinguish between the things that deserve to be called "causes" and those that do not. Hobbs suggests that a con? sideration of causal complexes can be divided into:  ? Distinguishing what events are in a causal complex from those outside of it. [Lewis, 1973] [Oritz, 1999b] [Simon, 1952, 1991] [Pearl, 2000]  ? Within a causal complex, recognizing the events that should be identified as causes from those that are not.

[Macke, 1993] [Shoham, 1990]  A major question concerning complexes is: To what extent can we increase the causal grain size and still have useful causal information? Conversely, can we start with a large-grained causal event and then derive the finer-grained structure? Can we measure and/or control the imprecision involved in changing grain size? If we start with a large? grained structure and resolve it, will our computational complexity burdens be reduced?

Coming to a precise description of what is meant by causality is difficult. There are multiple and sometimes conflicting definitions. For an introductory discussion of these issues, see Mazlack [2004]. Recognizing many things with absolute certainty is problematic. As this is the case, our causal understanding is based on a foundation of inherent uncertainty and incompleteness. Consequently, causal reasoning models must accommodate inherent ambiguity. For an introductory discussion of this, see Mazlack [2003a].

It may well be that a precise and complete knowledge of causal events is not possible or at least uncertain. On the other hand, we have a commonsense belief that causal effects exist in the real world. If we can develop models tolerant of imprecision, it would be useful. Also, to some degree, the degree of importance that some of these items have decreases as grain size increases.

3. Recognizing Causality Is Of Interest In Many Domains  Recognizing causality is of interest in many areas. Of particular interest to this paper are areas where the analysis is non-experimental. The world is taken as it is and not subject to experimentation. In the computational sciences, data mining is of concern. An area not well known to people working in the computational sciences is econormcs .

Perhaps, the applied area that has the greatest history of attempting to deal with causality and non-observational data is economics. Econometrics is distinguished from statistics by econometrics interest in establishing causa? tion [Hoover, 2003]. How and if causality can be recog? nized has been a significant area of discussion. Some of this discussion mirrors discussion that has gone on in the computational sciences. Hoover provides a good entry to the discussion of causality in economics.

Hume [1777/1902, p 165], as a philosopher, suggested that causal statements are really about constant conjunc? tion and time ordering. However, when speaking as an economist, Hume [1742/1985, p 304] was less insistent on causal ordering: "it is of consequence to know the principle whence any phenomenon arises, and to distin? guish between a cause and a concomitant effect." The issue of causal ordering is also often of importance to those modeling causality in data discovery.

Data mining analyzes data previously collected; it is non-experimental. There are several different data mining products. The most common are conditional rules or as? sociation rules. Conditional rules are most often drawn from induced trees while association rules are most often learned from tabular data.

IF Age < 20 THEN vote frequency is: often  with {belief = high}  IF Age is old THEN Income < $10,000  with {belief = 0.8}  Figure 2. Conditional rules.

Customers who  buy beer and sausage also tend to buy hamburger  with {confidence = 0.7} in {support = 0.15}  Customers who buy strawberries  also tend to buy whipped cream with {confidence = 0.8 in {support = 0.2}  Figure 3. Association rules.

At first glance, conditional and association rules seem to imply a causal or cause-effect relationship. That is:  A customer's purchase of both sausage and beer causes the customer to also buy hamburger.

Unfortunately, all that is discovered is the existence of a statistical relationship between the items. They have a degree of joint occurrence. The nature of the relationship is not identified. Not known is whether the presence of an item or sets of items causes the presence of another item or set of items; or the converse, or some other phenome? non causes them to occur together.

Purely accidental relationships do not have the same decision value, as do causal relationships. For example,  IF it is true that buying both beer and sausage somehow causes someone to buy beer, ? THEN: A merchant might profitably put beer (or  the likewise associated sausage) on sale ? AND at the same time: Increase the price of  hamburger to compensate for the sausages' reduce sale price.

On the other hand, knowing that  Bread and milk are often purchased in the same store visit  may not be as useful decision making information as both products are commonly purchased on every store visit. A knowledge of frequent co-occurrences of bread and milk purchases might lead us to placing the bread and milk at opposite ends of the store to force shoppers to visit more of the store and consequently make more impulse buying decisions. However, there is a limit to how often when such a physical distance distribution can be reasonably effected. What is most valuable is knowledge of true causal relationships.

Tangentially, what might be of interest is discovering if there is a causal relationship between the purchase of bananas and something else. (It turns out that bananas are the most frequently purchased food item at Wal-Mart [Nelson, 1998]).

When typically developed, rules do not necessarily de? scribe causality. The association rule's confidence measure is simply an estimate of conditional probability. The association rule's support indicates how often the joint occurrence happens (the joint probability over the entire data set). The strength of any causal dependency may be very different from that of a possibly related association value. In all cases  confidence;;, causal dependence  All that can be said is that associations describe the strength of joint co-occurrences.

Sometimes, the association might be causal; for ex? ample, if  or  Someone eats salty peanuts and then drinks beer.

Someone drinks beer and then becomes inebriated.

there may be a causal relationship. On the other hand, if  A rooster grows and then the sun rises.

or  Someone wears a 'lucky' shirt and then wins a lottery.

there may not be a causal relationship. Recognizing true causal relationships would greatly enhances the decision value of data mining results.

The most popular market basket association rule devel? opment method identifies rules of particular interest by screening for joint probabilities (associations) above a specified threshold.

4.1 Association Rules Without An Underlying Causal Basis Can Lead To Naive Decisions  Association rules are used is to aid in making retail de? cisions. However, simple association rules may lead to errors. Errors might occur; either if causality is recognized where there is no causality; or if the direction of the causal relationship is wrong [Silverstein, 1998a] [Mazlack, 2003b]. Errors might occur; either if causality is recog? nized where there is no causality; or if the direction of the causal relationship is wrong. For example, if    A study of past customers shows that 94% are sick.

? Is it the following rule?

Our customers are sick, so they buy from us.

? Is it the following complementary rule?

If people use our products, they are likely to be? come sick.

? Is there no relationship between product purchase and  illness?

Consequently, from a decision making viewpoint, it is not enough to know that  People both buy our products and are sick.

What is needed is knowledge of what causes what, if any? thing at all.

If causality is not recognized, the naIve application of association rules can result in bad decisions [Silverstein, 1998a]. This can be seen in an example from Mazlack [2003]:  Example: At a particular store, a customer buys:  ? hamburger 33% of the time  ? hot dogs 33% of the time ? both hamburger and hot dogs 33% of the  time ? sauerkraut only if hot dogs are also  purchased  This would produce the binary transaction matrix:  hambur er hot do sauerkraut t, 1 1 1 t2 1 0 0 t3 0 1 1  Figure 4. Binary transaction matrix for hamburger, hot dog, and sauerkraut purchases.

This in turn would lead to the associations (confidence):  ? (hamburger, hot dog) = 0.5  ? (hamburger, sauerkraut) = 0.5  ? (hot dog, sauerkraut) = 1.0  All of the support levels are adequately high for this application.

If the merchant:  ? Reduced price of hamburger (as a sale item)  ? Raised price of sauerkraut to compensate (as the rule hamburger fi sauerkraut has a high confidence.

? The offset pricing compensation would not work, as the sales of sauerkraut would not increase with the sales of hamburger. Most likely, the sales of hot dogs (and consequently, sauer? kraut) would likely decrease as buyers would substitute hamburger for hot dogs.

4.2 Association Rules That Do Not Take Into Account Quantities Can Result In Misleading Causal Inferences  Association rules are often formed by reducing all val? ues to binary zeros and ones.

This is an early technique that was and is used in data mining when analyzing market basket data. However, it is essentially flawed. Quantities do matter; some data co-oc? currences are conditioned on there being a sufficiency of a co-occurring attribute. Also, some relationships may be non-linear based on quantity [Mazlack, 2003b]  Example:  Situation: Customers frequently buy either wine or beer for themselves in varying amounts. However, when buying for a party, they often purchase both beer and wine and they usually purchase in larger quantities.

Actual basket: Binary basket:  Beer Wine   o   o     o   o      Beer Wine   o   o     o   o      Figure 5. Beer, wine transactions: quantified and binary.

Missed rule: When at least 24 beers purchased, wine also purchased;  Otherwise, there is no relationship between beer and wine.

NaiVely constructing an association rule on non-quanti? fied, binary data would find a rule that misleadingly repre? sents the situation; i.e.,  Misleading rule: When beer is purchased, wine is also purchased  {confidence = O.6}  {support = 0.43}  This rule is misleading because it naIvely implies that purchase probabilities are uniform; in fact, they are not.

Under one set of conditions, beer and wine are never pur? chased together under one set of conditions; and, under another set of conditions they are always purchased together.

In neither case is there a direct causal relationship. In the quantified rule case, the larger quantities of beer and wine are caused by a third factor (a party).

5. DESCRIBING CAUSALITY  In some ways, someone may object to this paper, as it does not offer much in the way of solutions. It mostly identifies needs. Part of a reply is that there is limited    space and time. Another is that recognizing a need is the first step to finding a solution. Another is that both rec? ognizing and defining causality is still a very complex and difficult problem, even after over 3,000 years of effort.

Various causality descriptions and discovery tools have been suggested. It may eventually tum out that different subject domains may have different methodological pref? erences. This section is intended to give a selective, non? complete, taste.

5.1 Intuitive Graph Based Approaches  Different aspects of causality have been examined. As in Figure 6, the idea of "positive" causation (a --;. f3) is at the core of commonsense causal reasoning. Often a posi? tive causal relationship is represented as a network of nodes and branches [Mazlack, 2003a]. In part because of their intuitive appeal, there have been many approaches to recognizing causality that use graphs.

?@ Figure 6. Diagram indicating that a is causally de?  pendent on b.

There are a number of different books describing vari? ous aspects of causal graphs. Among them are: Gammer? man [1999], Glymour [2001], Hausman [1988], Pearl [2000], Shafer [1996], Spirtes [1993].

5.2 Directed Graphs  Various graph based Bayesian based methods have been suggested to recognize causality. Probably the best known is the class of methods based on Directed Acyclic Graphs (DAGs). The most fully developed approach is Pearl [2000]. Silverstein [1998] followed a similar approach.

Pearl [1991] and Spirtes [1993] claim that it is possi? ble to infer causal relationships between two variables from associations found in observational (nonexperimental) data without substantial domain knowl? edge. Spirtes claims that directed acyclic graphs could be used if (a) the sample size is large and (b) the distribution of random values is faithful to the causal graph. Robins [1999] argues that their argument is incorrect. Lastly, Scheines [1994] only claims that in some situations will it be possible to determine causality. Their discussion is tangential to the focus of this paper; going deeply into their discussion is outside this paper's scope. It is enough to note that these methods are possibly the most thor? oughly developed methods of computational causal analysis.

From the commonsense causal reasoning view, the various directed graph methods have similar liabilities, specifically. Mazlack [2004] discusses and lists and dis? cusses some of the problems.

5.3 Negation And Counterfactuals  Negation or counterfactuals (...,a --;. ...,f3) also have a place, although it may result in reasoning errors. For ex? ample, the rule:  If a person drinks wine, they may become inebriated.

cannot be simply negated to  If a person does not drink wine, they will not be? come inebriated.

One reason is that effects can be overdetermined; that is: more than one item can cause an effect. If so, eliminat? ing one cause does not necessarily eliminate the effect. In this case:  A person may also drink beer or whiskey to ex? cess and become inebriated.

Events that do not happen can similarly be overdeter? mined. From a commonsense reasoning view, it is more likely that things do not happen than they do. For exam? ple, Oritz [1999a] says that it is not true that  His closing the barn door caused the horse not to escape.

because the horse might not have attempted to escape even  if the door was open. Therefore, a false counterfactual is:  If he had not closed the barn door, the horse would have escaped.

Similarly, for example, the rule  If a person smokes, they will get cancer.

cannot be simply negated to  If a person does not smoke, they will not get cancer.

Again, effects can be overdetermined. In this case,  People who do not smoke may also get cancer.

Another idea that is sometimes involved in causal rea? soning is causal uncorrelatedness [Shafer, 1999] where if two variables have no common cause they are causally uncorrelated. This occurs if there are no single events that cause them to both change.

Similarly, Dawid [1999] focuses on the negative; i.e., when a does not affect f3. Dawid speaks in terms of unre? sponsiveness and insensitivity. If f3 is unresponsive to a if whatever the value of a might be set to, the value of f3 will be unchanged. In parallel, if f3 is insensitive to a if whatever the value a may be set, the uncertainty about f3 will be unaffected. Along the same vein, Shoham [1990, 1991] distinguishes between causing, enabling, and pre? venting. The enabling factor is often considered to be a causal factor. Shoham distinguished between background (enabling) conditions and foreground conditions. The back? ground (enabling) conditions are inferred by default. For example [Shoham, 1991]:  "If information is present that the key was turned and nothing is mentioned about the stated about the state of the battery, then it is inferred that the motor will start, because the battery is assumed, by default to be alive.

Given this distinction, causing is taken to refer to the foreground conditions where enabling and preventing refer to the background conditions (in this example, turning the key causes the motor to start, the live battery enables it, the dead battery prevents it)."  Other ideas that are sometimes involved in causal rea? soning are causal uncorrelatedness [Shafer, 1999] where if    two variables share no common cause they are causally uncorrelated. This occurs if there are no single events that cause them to both change. Similarly, causal independence occurs when speaking about probabilities.

5.4 Observational And Non-Observational Data  Statistics is the traditional tool used to discover causal? ity when handling experimental data. The standard method in the experimental sciences of recognizing causality is to perform randomized, controlled experiments. This produces experimental data. Depending on their design, randomized experiments may remove reasons for uncer? tainty whether or not a relationship is casual.

However, the data of greatest interest in the computa? tional sciences, particularly data mining, is non-experi? mental. This is because analysis is performed on large quantities of warehoused data. In this domain, traditional statistical methods are either not useful an/or are often too computationally complex.

Even if some experimentation is possible, the amount of experimentation in contrast to the amount of data to be mined will be small. This said; some work has been done using chi-squared testing to reduce the search space [Silverstein, 1998].

Several areas can only wholly (economics, sociology) or partially develop non-experimental data. In these areas, investigators can either abandon the possibility of discov? ering causal relationships; or, claim that causality does not exist. There continue to be efforts to discover causal relationships areas where only non-observational data is available. Among the books considering causality in non? experimental data are: Asher [1983], Blalock [1964], Berry [1984], Hilborn [1997], Shipley [2000].

6. EPILOGUE  One of the comer stones of data mining is the devel? opment of association rules. Association rules greatest impact is in helping to make decisions. One measure of the quality of an association rule is its relative decision value. Association rules are often constructed using sim? plifying assumptions that lead to naive results and conse? quently naIve and often wrong decisions. Perhaps the greatest area of concern is treating association rules as causal statements without understanding whether there is, in fact, underlying causality.

Causal relationships exist in the commonsense world.

Knowledge of at least some causal effects is imprecise.

Perhaps, complete knowledge of all possible factors might lead to a crisp description of whether an effect will occur.

However, in our commonsense world, it is unlikely that all possible factors can be known. In commonsense, every day reasoning, we use approaches that do not require complete knowledge.

People recognize that a complex collection of elements causes a particular effect, even if the precise elements of the complex are unknown. They may not know what events are in the complex; or, what constraints and laws the complex is subject to. Sometimes, the details under? lying an event are known to a fine level of detail, some? times not. Generally, people are more successful in rea-  soning about a few large-grain sized events than many fine-grained events. Perhaps, this can transfer over to computational models of causality.

A lack of complete, precise knowledge should not be discouraging. People do things in the world by exploiting our commonsense perceptions of cause and effect. When trying to precisely reason about causality, we need com? plete knowledge of all of the relevant events and circumstances. In commonsense, every day reasoning, we use approaches that do not require complete knowledge.

Often, approaches follow what is essentially a satisficing paradigm.

Instead of being concerned with all of the fined grained detail, a better approach may be to incorporate granulation using rough sets and/or fuzzy sets to soften the need for preciseness. And then accept impreciseness in the de? scription. Each complex can be considered to be a granule.

Larger complexes can be decomposed into smaller complexes. Thus, going from large-grained to small? grained.

Regardless of causal recognition and representation methodologies, it is important to decision making to un? derstand when association rules have a causal foundation.

This avoids naive decisions and increases the perceived utility of rules with causal underpinnings.

