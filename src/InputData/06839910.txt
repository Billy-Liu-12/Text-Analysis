?

Abstract?Matrix-factorization based collaborative filtering is  an efficient approach to the problem of user-side quality-of-service (QoS) prediction. In this work, we focus on building a matrix-factorization-based collaborative filtering model for QoS prediction under a non-negativity constraint. The motivation is that since QoS data such as response time, cost and throughput, are all positive, a non-negative model can better demonstrate their characteristics. By investigating a non-negative training process relying on each involved feature, we invent a non-negative latent factor model to deal with the sparse QoS matrix subject to the non-negativity constraint. We subsequently introduce Tikhonov regularization into it to obtain the regularized non-negative latent factor model. Their efficiency is proven by the experimental results on a large industrial dataset.

Index Terms?Big Data, Collaborative Filtering, Matrix Factorization, Non-negativity, QoS-prediction

I. INTRODUCTION How to predict the user-side quality-of-service (QoS)  accurately is an important research topic in the area of service computing. According to pioneering research [1-10], one efficient way to implement reliable user-side QoS-prediction is via collaborative filtering (CF). CF is initially designed for recommender systems [11-15]. When applying CF to QoS-prediction, the user-side QoS data on a specified QoS-property is organized into a user-service QoS matrix, where each row denotes a specified user, each column denotes a specified service and each entry denotes the historical QoS data of this property by a specified user on a specified service. Since each user can only touch a finite service set, the QoS-matrix is usually very sparse with numerous missing values. Thus, the key problem in CF-based QoS-prediction is to estimate the unknown entries in the QoS-matrix based on known ones subject to globally high accuracy and other requirements [1-10].

CF-based QoS-prediction can be implemented through several ways, among which the matrix-factorization (MF)   This research is in part supported by the National Natural Science  Foundation of China under Grant Number 61202347 and 61103036, and in part supported by the US National Science Foundation under Grant Number CMMI-1162482. The extended version (11 pages) of this paper has been

X. Luo, Y. Xia and Q. Zhu, are with the College of Computer Science at Chongqing University, Chongqing, 400044 China (e-mail: luoxin21@cqu.edu.cn, xiayunni@yahoo.com.cn, qszhu@cqu.edu.cn ).

M. Zhou is with the Department of Electrical and Computer Engineering at New Jersey Institute of Technology, Newark, NJ 07102, USA (e-mail: zhou@njit.edu ).

based approach has proven to be highly accurate and scalable [7-10]. When employing this approach to generate QoS-predictions, a low-rank estimate to the original QoS-matrix is desired. In general, this low-rank estimate can be constructed by mapping both the users and services into the same latent feature space, training desired user/service features according to the original QoS-matrix, and then filling each entry in the desired estimate heavily relying on the products of user and service feature matrices. In other words, once the user/service features are obtained, the missing values can be estimated by the corresponding ones in the resulting low-rank estimate. Zhang et al. [7] propose an MF-based model to integrate the time interval as an additional factor into an MF process, thereby improving the prediction accuracy. Lo et al. [8] propose an extended MF-based model by considering the location information in each historical QoS record. Zheng et al.

[9] propose an MF-based QoS-predictor by considering neighborhood information.

However, current MF-based QoS-predictors are not built under the non-negativity constraint. Thus, they will fail to catch some characteristics of the QoS data. The research in area of computer vision demonstrates that factorizing the image-matrices under the non-negativity constraint can enable the model to better describe the partial characteristics of given pictures [16-18]. For MF-based QoS predictors, to fulfill the constraint of non-negativity should be very important because: a) All user-side QoS data are positive, and clearly a non-negative model can better describe their positive nature than the one allowing negative (and thus wrong) estimates; and b) An NMF model can better describe the partial characteristics of the sparse user-service QoS matrix, which rely mostly on the known entries.

By introducing a non-negativity constraint into an MF process, Lee et al. [16, 17] firstly propose the non-negative MF model, which is initially designed for learning part-based object representations in computer vision. However, unlike problems in computer vision, MF-based QoS prediction comes with the characteristic of sparsity; the target user-service QoS-matrix is incomplete with huge amounts of unknown entries. Therefore, the standard NMF process fails to deal with them without proper tuning. Suggested by Zhang et al. [19], this adaptation can be implemented through introducing either an expectation maximization (EM) procedure or an indicator matrix into the NMF process. However, either strategy leads to high computational complexity.

In this work, we focus on developing an MF-based  Predicting Web Service QoS via Matrix-factorization-based Collaborative Filtering under Non-negativity Constraint  Xin Luo, MengChu Zhou, Fellow, IEEE, YunNi Xia, Member, IEEE, and QingSheng Zhu, Member, IEEE   B5.1.pdf WOCC 2014      QoS-predictor for web services under the non-negativity constraint, which can achieve high computational efficiency and prediction accuracy. It also enjoys easy implementation. Its main idea is to carry out the non-negative update process depending on each involved feature rather than on the whole feature matrices. The detailed case study is conducted on an industrial dataset called WS-Dream [10, 20] to show the efficiency of our model.

The rest of this paper is organized as follows; Section II gives the preliminaries; Section III states our model; Section IV gives the experiments and results; and finally, Section V concludes this paper.



II. PRELIMINARIES When considering the problem of CF-based QoS-prediction,  a user-service QoS-matrix is a fundamental data source and can be huge.

Definition 1. Given a user set U and a service set S, a user-service QoS-matrix Q is a |U|?|S| matrix consisting of the historical records of a specified QoS property by U on S where a known entry qu,s denotes a QoS record by user u on service s.

Since some users may never invoke some services, Q is incomplete, thereby yielding a missing-data-estimation problem. Denote the known and whole entry sets in Q as QK and QW respectively.

Definition 2. Given KT Q? as the training dataset, the problem of CF-based QoS-prediction is to build an estimator Q?  based on T, generate the estimate ,?u sq  for each entry ? ?, Wu s Q? , to  approximate ? ?  , , ,  ?min W  u s u s u s Q  q q ?  ? ??	 ? ?	 ?	 ?? ? .

An MF-based QoS-predictor factorizes the original QoS-matrix Q into two rank-f matrices P and E, where P has dimension |U| f, E has f |S| and ? ?min ,f U S? . Note that P and E can be interpreted as the user and service latent-feature-matrices reflecting the user and service characteristics contained in the historical QoS data, and constant f is the dimension of the latent-feature-space. Q? PE? is the desired model to predict missing entries in Q.

Similar to the process mentioned above, NMF also factorizes the target matrix Q into two rank-f matrices. However, NMF carries out this factorization process subject to the non-negativity constraint, i.e., , 0P E ? . Thus, with the loss function by Euclidean distance, the problem of NMF-based QoS-Prediction is given as follows [16, 17]:   , arg min ,  . . , 0.

P E d Q PE s t P E? ?                                   (1)  As proposed by Lee et al. [16, 17], if Q is a complete matrix, the non-negativity constraint in (1) can be fulfilled via manipulating the learning rate during the optimizing process of P and E. For instance, with gradient decent, each desired parameter is trained via the following process [16, 17]:  ? ? ? ?? ? ? ? ? ?? ?  , , , , ,  , , , , ,  ,  ;  T T u k u k u k u k u k  T T k s k s k s k s k s  p p QE PEE  e e P Q P PE  ?  ?  ? ?   ? ?  (2)  where pu,k denotes the entry at the uth row and kth column in P; ek,s denotes the entry at the kth row and sth column in E; these two parameters actually denote the kth feature of user u and the kth feature of service s, respectively. ?u,k and ?k,s denote the corresponding learning-rate. Given pu,k and ek,s initially non-negative, during the training process they may lose the non-negativity due to the negative component in (2). To maintain the non-negativity of P and Q, NMF diagonally adjust the learning-rate as follows [16, 17]:  ? ? ? ? , ,  , ,  , ,  ;  .u k k su k k sT T u k k s  p e PEE P PE  ? ?? ?                                      (3)  With this transformation, the negative components in (2) are canceled out with the initial values of pu,k and qk,i; thereby, the learning process is reformulated as follows:  ? ? ? ?  ? ? ? ?  , , , , , ,  , ,  ; .

T T  u k k s u k u k k s k sT T  u k k s  QE P Q p p e e  PEE P PE ? ?                        (4)  With (4), the training process will also converge, as proved in [17]. However, in the problem of MF-based QoS prediction, the target matrix Q cannot be complete; and thus, in (4) the products QET and PTQ are intractable. In [19], Zhang et al.

suggest introducing an indicator matrix into the update process to address the sparsity of a target matrix, which results in the weighted NMF (WNMF) model with the update rule given by  ? ?? ? ? ?? ?  ? ?? ? ? ?? ?  , , , , , ,  , ,  ,  ; T T  u k k s u k u k k s k sT T  u k k s  W Q E P W Q p p e e  W PE E P W PE ? ?  ? ?  ? ? (5)  where W is a |U|?|I| matrix, of which the element is equal to 1 if the corresponding entry in Q is known and 0 otherwise; symbol ? denotes the Hadamard product between two matrices. This strategy can deal with the sparse nature of MF-based QoS prediction; however, it results in high computational cost. This is because the Hadamard multiplications are additionally required during the training process; and thus, it is required to iterate on each entry of Q to check if it is known or unknown.



III. THE NON-NEGATIVE LATENT FACTOR MODEL As discussed in [15, 21-24], when factorizing an incomplete  target matrix in a CF-related problem, the distance between the target matrix and low-rank estimate is transformed into the sum squared error. In our problem, this error measures the difference between the given entries in the training set T and the corresponding estimates in PE, formulated by  ? ? ? ?  ? ?  , , ,  ,   , , , , 1  ;  u s u s u s T  f  u s u k k s u s T k  d Q PE q p e  q p e  ? ? ? ?  ? ?  ? ? ?   ? ??	 ?? ?	 ?	? ?     (6)  where ,up ? denotes the uth row-vector of P, and ,se? denotes the sth column-vector of E, respectively.

The loss function (6) can be extended by including the linear biases factors to obtain higher accuracy [15, 22, 23], given by:  B5.1.pdf WOCC 2014      ? ?   , , , , 1  ; f  u s u s u k k s u s T k  q b b p e? ? ?  ? ??	 ??   ?	 ?	? ? (7)  where bu and bs denote the user bias and service bias, respectively. With (7), the task of building an NMF-based QoS-predictor is equivalent to optimize the desired latent features in (7) subject to the non-negativity constraint:  ? ?   , , , , , , , 1  arg min ;  . . , , , 0.

U S  f  u s u s u k k s B B P E u s T k  U S  q b b p e  s t B B P E  ? ? ?  ? ??	 ??   ?	 ?	? ?  ?  (8)  Note that in (8) only the given data in the training set are considered; and thus we need to train each feature only according to meaningful entries in Q while ignoring the missing ones. Given BU, BS, P and E initially non-negative, we can employ the principle of the original NMF model?manipulating the learning rate, to cancel the negative part during the training process of each feature for maintaining non-negativity. Similar to (2), we first use gradient decent to train each feature without considering the non-negativity constraint, given by:  , , ,  , , ,  , , ,  , , , , , , ,  ( , , , ) arg min  2 ,  2 ,   U S  u  s  U S B B P E  f  u u u u u u s u s u k k s s S ku  f  s s s u s u s u k k s u U k  f  u k u k u k k s u s u s u k k s s S k  B B P E  b b b q b b p e b  b b q b b p e  p p e q b b p e  ?  ? ? ?  ?  ?  ? ?  ? ?  ? ?  ?  ? ?? ?	 ?? ? ?   ?	 ?	? ? ?  ? ??	 ?? ?   ?	 ?	? ? ?  ? ??	 ?? ?   ?	 ?	? ?        , , , , , , ,   ,  2 ;  u  s  f  k s k s k s u k u s u s u k k s u U k  e e p q b b p e? ? ?  ????????????????????????? ? ?? ?	? ?? ?   ?? 	 ?	? ? ???      (9)  where Su denotes the set of services invoked by user u, and Us denotes the set of users having invoked service s, respectively.

With a slight abuse of notations, the constant 2 before each learning rate can be omitted to obtain a concise form. Let  , , ,  ? f  u s u s u k k s k  q b b p e ?  ? ? ? . Then (9) can be simplified as  ? ?  ? ?  ? ?  ? ?  , , ,  , ,  , ,  , , , , , ,  , , , , , ,  ( , , , ) arg min  ? ,  ? ,   ? ,  ? ;  U S  u  s  u  s  U S B B P E  u u u u s u s s S  s s s u s u s u U  u k u k u k k s u s u s s S  k s k s k s u k u s u s u U  B B P E  b b q q  b b q q  p p e q q  e e p q q  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?? ? ? ?????? ? ? ??????? ? ? ?????? ? ? ?????          (10)  With (10) we can manipulate each learning rate to cancel the negative factor during the training process. For bu, bs, pu,k  and ek,s, the negative factors in the training rule are ,?  u  u u s s S  q? ?   ,  ,? s  s u s u U  q? ?   , , , ,? u  u k k s u s s S  e q? ?   and , , ,? s  k s u k u s u U  p q? ?   respectively.

Therefore, we can manipulate each involved learning rate as follows,  , ,  , , , , , , , ,  ? ?,  ,  ? ?,  ; u s  u s  u u u s s s u s s S u U  u k u k k s u s k s k s u k u s s S u U  b q b q  p e q e p q  ? ?  ? ?  ? ?  ? ?  ?? ? ?????? ? ?????     (11)  By substituting (11) into (10), we obtain ? ?  , ,  , ,  , , , , , ,  , , , , , ,  , , , arg min ;  . . , , , 0.

? ,  ? ,  ? ,  ?  u u  s s  u u  s s  U S U S  u u u s u s s S s S  s s u s u s u U u U  u k u k k s u s k s u s s S s S  k s k s u k u s u k u s u U u U  B B P E s t B B P E  b b q q  b b q q  p p e q e q  e e p q p q  ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ??	 ?	? ?	 ??	? ? ? ??	 ?	? ?	 ??	? ?  ? ? ??	 ?	? ?	 ??	? ? ?  ?        .

?????????????????????????? ?? ?	? ?	? ?	 ?? ?	? ????  (12)  Note that there are no negative factors in training rule (12); and thus, if BU, BS, P and E are initially non-negative, they so remain the non-negativity across the whole training process.

This non-negative latent factor (NLF) model differs from the WNMF model in two aspects: a) Only the meaningful entries in Q are considered, and b) The update of each feature relies on the other related features but not the whole feature matrices.

Therefore, NLF is expected to be more efficient than WNMF when dealing with the task of QoS-prediction.

Moreover, since the target matrix Q is usually sparse in practice, the NLF model based on (8) and (12) is ill-posed due to the limited number of training examples and the approximations made during the process of gradient decent.

Therefore, it is probable to further improve the model accuracy by integrating Tikhonov regularization, which will extend (8) into the following form,  ? ? ? ?  , , ,  2 2 2 2 2 , , , ,  , 1 1  arg min  ? ,  . . , , , 0;  U S T  B B P E  f f  u s u s U u S s P u k E k s u s T k k  U S  q q b b p e  s t B B P E  ?  ? ? ? ? ? ? ?  ? ??	 ?? ? ? ? ?	 ?	 ?	? ?  ?  (13)  where where ?U, ?S, ?P and ?E denote the regularizing coefficients for BU, BS, P and E respectively. Without the non-negativity constraint, features in (13) can also be optimized via gradient decent similarly to (9) and (10), given by:  ? ?  ? ?  ? ?  ? ?  , , ,  , ,  , ,  , , , , , , , ,  , , , , , , , ,  ( , , , ) arg min  ?  ?   ?  ?  U S  u  s  u  s  U S T B B P E  u u u u s u s U u s S  s s s u s u s S s u U  u k u k u k k s u s k s u s P u k s S  k s k s k s u k u s u k u s E k s u U  B B P E  b b q q b  b b q q b  p p e q e q p  e e p q p q e  ?  ? ?  ? ?  ? ?  ? ?  ?  ?  ?  ?  ?  ?? ? ?  ?????? ? ?  ?????? ? ?  ?????? ? ?  ????          (14)  To fulfill the non-negativity constraint, each learning rate can be manipulated as follows,  B5.1.pdf WOCC 2014      ? ?  ? ?  ? ?  ? ?  ,,  ,,  , , ,  , , ,, , ,  , , ,  , , ,, , ,  ??  ??  ??  ??  uu  ss  uu  ss  u u u  u s u U uu s U u s Ss S  s s s  u s s S su s S s u Uu U  u k u k u k  k s u s u P u kk s u s P u k s Ss S  k s k s k s  u k u s s E k su k u s E k s u Uu U  b b q S bq b  b b q U bq b  p p e q S pe q p  e e p q U ep q e  ? ??  ? ??  ? ??  ? ??  ??  ??  ??  ??  ??? ? ? ??  ? ? ??  ? ? ?  ??  ? ? ??          ??????????????? ??????????????????  (15)  By substituting (15) into (14), we can obtain the training rule for the regularized NLF (RNLF) as follows, ? ?  , ,  , ,  , , , , , , ,  , , , arg min ;  . . , , , 0.

? ,  ? ,  ?  u u  s s  u u  U S T U S  u u u s u s u U u s S s S  s s u s u s s S s u U u U  u k u k k s u s k s u s u P u s S s S  B B P E s t B B P E  b b q q S b  b b q q U b  p p e q e q S p  ?  ?  ?  ?  ? ?  ? ?  ? ?  ? ?  ? ?? ??	 ?	 ??	 	? ? ??	 	 ??	 ?	 ?	 ? ?? ? ? ?? ??	 ?	 ??	 	? ? ??	 	 ??	 ?	 ?	 ? ?? ?  ?  ? ?        , , , , , , ,  ,  ? .

s s  k  k s k s u k u s u k u s s E k s u U u U  e e p q p q U e? ? ?  ?????????????????? ? ?? ?? ?	 ?	? ??	 	 ?? ?	 	 ?? ?	 ?	 ?	 ? ?? ? ???? ? ?? ?? ?	 ?? 	 ??	? 	? ? ??	? 	 ??	 ?? 	 ?	 ? ?? ???   (16)  With RNLF, we can address the problem of user-side QoS-prediction with high accuracy and efficiency subject to the non-negativity constraint.



IV. EMPIRICAL STUDY  A. General Settings Evaluation Metric. Firstly, we focus on the accuracy of  generated QoS predictions since it can directly reflect whether or not the model has captured the essential characteristics of given data. The mean absolute error (MAE), a commonly accepted evaluation metric for CF-based models [25, 26], is chosen as the evaluation metric:  ? ? , ,  ,  ? | |,u s u s u s  MAE p p ??  ? ?  where ?  denotes the validation set. For a given model, low MAE stands for high prediction accuracy.

Meanwhile, we are interested in the computational efficiency of NLF and RNLF. We simply use the consumed time of each training epoch to measure the computational efficiency of each tested model. Note that all tested models are implemented in Matlab R2010B, and tested on a PC Server with a 2.5GHZ CPU and 16GB Memory.

Tested Models. Three models are included in our experiment. The WNMF model [19] is implemented and tested as benchmark. Then, the newly proposed NLF and RNLF are compared with it to validate if our newly proposed strategies can bring positive effect on performance in the QoS-prediction  task.

Dataset. We conduct our experiments on the  WS-Dream-Dataset [10, 20]. This dataset records the response time and throughput during the invocations of 5825 real-world Web-services by 339 users. Both the response time and throughput data are employed during our experiment. The details of these two parts are summarized in Table I.

TABLE I DETAILS OF THE EXPERIMENT DATASETS  Label Property Cols Rows Known Entries D1 Response Time 339 5825 1,873,838 D2 Throughput 339 5825 1,831,253  On either part, we employ the 20%-80% train-validation settings and 5-fold cross-validation technique to evaluate the prediction accuracy of each involved model thoroughly.

Parameter Settings. For each tested model, the dimension constant f is set at 100 uniformly. The initial values of all involved features for each tested model are generated in the scale of (0, 0.2]. For NLF and RNLF, the coefficients are set as  0.06U S P E? ? ? ?? ? ? ? for simplicity. To make a fair comparison, each model is trained for 200 epochs; and the lowest RMSE achieved by each model is recorded and compared.

B. Results TABLE II  LOWEST RMSE OF RSNMF, SNMF AND WNMF  Dataset Lowest MAE/Training Epochs RNLF NLF WNMF D1 0.4283/200* 0.5238/22 0.5261/20 D2 17.17/200 27.13/200 28.16/200  *note that the entries are recorded as MAE/converging epochs TABLE III  CONSUMED TIME OF EACH TRAINING EPOCH BY RNLF, NLF AND WNMF  Dataset Consumed Time of Each Training Epoch (ms) RNLF NLF WNMF D1 7683 7302 13102 D2 7459 7157 12671  The training process of each compared model on D1 and D2 is depicted in Figs. 1-2 respectively. The lowest MAE of each model during the training process is recorded in Table II. The consumed time of each training epoch by each model is summarized in Table III. Based on these experimental results, we have the following findings:  a) The prediction accuracy of NLF and WNMF are very close on D1 and D2. As depicted in Figs. 1-2, the training process of NLF and WNMF is very similar. From Table II, we see that the lowest MAE of NLF and WNMF is also very close.

This indicates that the update rule of NLF given by (12) has the identical effect with that of WNMF given by (5). However, NLF has much higher computational efficiency than WNMF does. This can be clearly seen from Table III. On D1, each training epoch of NLF consumes 7302 ms on average, which is about 56% that of WNMF. On D2, the situation is very similar.

This indicates that the training rule of NLF, which only iterates on the meaningful entries in the QoS matrix, is highly efficient as well as being able to maintain non-negativity.

b) The introduction of Tikhonov regularization into NLF can bring significant improvement in prediction accuracy. On D1, the lowest MAE of RNLF is 0.4283, which is about 18.23%  B5.1.pdf WOCC 2014      lower than that of NLF and 18.59% lower than that of WNMF.

On D2, the lowest MAE of RNLF is 17.17, which is about 36.71% lower than that of NLF and 39.02% lower than that of WNMF.

In the meanwhile, the computational efficiency of RNLF is very close to that of NLF, as recorded in Table III. On D1, the consumed time of each training epoch by RNLF is 7683 ms, only about 4.95% higher than that by NLF, and is about 59% that of WNMF. On D2 the situation is very similar. Actually, by comparing (12) and (16), we see that the training rule of RNLF is nearly the same as NLF except for the integration of the penalty facto. Hence, RNLF and NLF are close in computational efficiency.

Based on the experiment results, we can conclude that NLF can address the task of QoS-prediction with high efficiency as well as maintaining non-negativity. Moreover, RNLF can bring significant improvement in prediction accuracy at the expense of insignificant increase in computational complexity.



V. CONCLUSION This work focuses on predicting the user-side  quality-of-service (QoS) via matrix-factorization based collaborative filtering under the non-negativity constraint. We first carry out the non-negative training process relying on each involved feature, rather than on the whole feature matrices, to from a non-negative latent factor (NLF) model. Thus, the training process depends on only the known entries in the user-service QoS-matrix, and is able to deal with the incomplete QoS-matrix with high efficiency as well as maintaining non-negativity. We subsequently introduce the Tikhonov regularization into NLF to obtain the regulzarized NLF (RNLF) model, for further improving the prediction accuracy. Based on the experiments on a large, real QoS dataset, we conclude that NLF can deal with the task of QoS-prediction with high computational efficiency subject to the non-negativity constraint, while RNLF can significantly improve the prediction accuracy at the expense of some minor increase in computational complexity.

