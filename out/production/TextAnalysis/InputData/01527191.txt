NEW ALGORITHM FOR MINING FREQUENT ITEMSETS IN SPARSE  DATABASE

Abstract: This paper presents novel algorithm for mining frequent  itemsets in sparse database, compared with existing algorithm our algorithm has visible advantage. With this algorithm, the scans is less in transaction database, only one time in little and middle transaction database, and not more than two times in large database. In the algorithm, when the transaction database is scanned, the transaction items are saved in unit triplet, and the count of every transaction item is saved in 1-dimension array so that the frequent itemsets are generated in memory. So I/O spending is reduced greatly. The experimental results show that our algorithm is very promising.

Keywords: Data Mining; Association Rules; Frequent Itemsets; Unit  Triplet  1? Introduction  Mining association rules is one of the important issues of data mining, and the key of mining association rules is mining frequent itemsets (or frequent pattern) . A classical algorithm for mining frequent itemses is Apriori[1] and its enhanced algorithm[2][3]. when Apriori and Apriori-like are used in mining long pattern, often many scans is needed in the transaction database repeatedly, when frequent k-itemsets is mined the transaction database need be scanned k times. Another acknowledged algorithm is FP-growth[4], The strongpoint of FP-growth algorithm is that candidate item need not be generated, when the spending for constructing and mining FP-tree fit main memory , only two times scans are needed, if the database is a huge and sparse, the FP-tree will be large and the space requirement for recursion is a challenge.

When frequent itemsets are mined, the increase of I/O  spending is along with the increase of the scan times to transaction database, so it is important to seek the algorithm of less scan times in transaction database.

This paper presents an algorithm for mining frequent itemsets based on unit triplet, UT-mine algorithm, with this algorithm, only one time scan is needed on little and middle database, and not more than two times on large database.

The experimental results show that this algorithm is high effective.

The remaining of the paper is organized as follows.

Section 2 is devoted to the definition for mining frequent pattern and the data structure of saving the itemsets. In Section 3, an efficient algorithm for memory-based frequent pattern mining is introduced. In Section 4, the algorithm of disk-based databases is presented. In Section 5, the performance of UT-mine is discussed. Our experiment results is reported In Section 6. We conclude our study in Section 7.

2.  Problem definition  2.1.  The Definition of Frequent Itemsets  Definition 1.  Let I={i1, i2, ?, im} be a set of item, X is a subset item I, i.e., X={ik1, ik2, ?, ikn}, where 1?j?n, 1 ?kj?kj+1?m. For the shake of brevity, an itemset X={ik1, ik2, ?, ikn} is also denoted by X=ik1 ik2 ? ikn,. And X(n) denotes the of n-itemsets in which each element contain n items.

Definition 2.  A transaction is denoted by , here  is transaction number. only if , then transaction  },{ ItidT = I?tid X  T  contains X .

Definition 3. Transaction database  is the set that  have D  M  transactions, the number of transaction that contains X  is called as support, which is denoted by      )sup(X . given a support threshold, if sup( , then  supmin_) ?X X  is frequent.

m D Mm ?  TID  mk ??  ki  2.2.   Sparse Database  In the context of frequent itemsets mining, a (projected) database is sparse if the frequent items in it have low relative support. The relative support can be computed as follows:  relative support = the average transaction length in database (projection database of the 1-frequent item)/the sum of the item in database (projection database of the 1-frequent item).

When the relative support is low in a database, such as 10% or below, we define the database as sparse database.

2.3.  The Data Structure for Storage  2.3.1.  The Storage Structure for Transaction Item  Let there be M  transactions and  item in , then the transaction item can be denoted by matrix, the element is transaction item in the matrix, if the transaction contains the item, then the value of the element is 1, otherwise, it is 0. Because every transaction is a little subset of  in sparse database, so there are many element which value is 0 in the matrix. We can use an unit triple to save non-zero element so that save memory space.

An unit triple is denoted by , is transaction number in the transaction database, k  is item number ( 1 ).

m  ),,( 1kTID  Let 1-dimension array  be used to take count of item , and C  be used to take count of frequent item accumulative total in the transaction.

)(kB )(TID  2.3.2.  The Storage Structure for The Itemsets  Hyper-structure: The itemsets which are generated by scanning unit triplet are saved in special hyper-structure, The hyper-structure head table contains two fields: item_number field and pointer field. The pointer in pointer field points to a hash chain structure with same number of items. The hyper-structure is illustrated in Figure.1   Figure1. Hyper-structure  Item number field and pointer field. The pointer in pointer field points to a hash chain structure with same number of items.

Hash function:  Let  be a set of the item number in itemset . The hash function of the itemsets is given below:  },,,{ n21 qqqB ?=  },,,{  i q  i q  i qi n  iiiA ?  =    pz1i2qqqh n   q  qi in21 ?+= ?  ?  = ? mod))((),,,(  ?1?   If , then , otherwise ;  is the sum  of the adjusted pattern of the multi-itemsets.

Bi ? izi = 0=iz p?  Chain Address Structure: The node structure of head table of itemsets are shown in Figure 2 and the node structure of chain table frequent multi-itemsets is shown in Figure 3:   Chain address pointer  Figure 2 node structure of head table   count X pointer Figure 3. node structure of chain table   The chain address is reduced from formula (1) in  Figure 2, Here, the?pointer? points to its chain table node; the?count?is the sum of the count of pattern X in the chain table node. The ?pointer? points to next chain table node in Figure 3.

3.  Memory-based Mining  Firstly, transaction database is scanned a time, corresponding item that appears in transaction is saved in  , and the count of the item ? 1 ?is obtained, and the accumulative total of item is save in  .

),,( 1kTID  )(kB  ki k  mk ??  Secondly,  is scanned a time, and the count of the item which has same  and  is saved in , At the same time, (  which  is less than  is released so that reduce the spending of the main memory and transform  into frequent 1-itemsets transaction table. When frequent 1-itemsets transaction table is scanned according to from 1 to  ),,( 1kTID  ) min_  TID supmin_)( ?kB ),, 1kTID  ),,( 1kTID  TID  (TIDC )(kB sup  M ,the connection algorithm which is similar to Apriori[1] is used to generate 2-itemsets in every frequent 1-itemsets transaction, and 2-itemsets hash structure is formed, and then the frequent 2-itemset is generated, in turn, until non frequent itemsets are generated, the mining procedure stop. The mining algorithm see Figure 4. Under      this case, it needs only to scan a time to database to generate complete frequent itemsets.

Algorithm 1 ?  Memory-based frequent pattern mining  )M(eminUT ?  Imput?transaction database ,  D supmin_ Output?complete frequent Method? 1? Scan transaction database  a time ? save the  transaction item to ?and the accumulative total of item is saved in ? 1 ?  D  )(k ),,( 1kTID  Bk )mk ?? 2? Scan  to prune the of which  corresponding is less than ,and transform  into frequent 1-itemsets transaction table.

),,( 1kTID B ,(TID  ),,( 1kTID _min)k(  ),1k sup  3?  { for );;( ++= km1k do 4?   ?=L ; 5?   ?=1L ; 6?   Do while ??kL  and  kTIDCmax >))(( 7?   { 8?    ;for 1TID =( M ; TID { )++ do 9?     //all sets of frequent 1-itemsets  in transaction of which number is },,,{ nqkk iiiA +=  TID 10?    =B the sets of (k+1)-itemsets which is connected  by all frequent 1-itemsets in A 11?    Save B to (k+1)-itemsets hash structure and take  count of each (k+1)-itemset?} 12?    According to (k+1)-itemsets hash chain structure  form frequent (k+1)-itemsets ; 1+kL 13?    Release non-frequent (k+1)-itemsets hash chain  node and ; )( 1kLLL ++= 14? }} 15? Output L  Figure 4. Algorithm1   In the algorithm,  is used to save the support of so that when linking 1-item only frequent item is linked,  thus, generated the number of the itemsets will be reduced; is used to save the count of 1-frequent item in each  transaction which transaction number is  so that when searching k-itemsets, only the transactions which are equal to or more than k are searched.

)(kB  kI  (C )TID TID  )(TIDC  Example 1.  Transaction database is shown as Table 1.

let ? %supmin_ 50=    Table 1 transaction database D TID Transaction item  1 532 III ,, 2 321 III ,, 3 5432 IIII ,,, 4 53 II ,   After transaction database  is scanned a time, unit  triplet  and  can be obtained.

D  ),,( 1kTID )(kB After is scanned a time to prune the  of which corresponding is less than ,and transform  into frequent 1-itemsets transaction table. and  is calculated and obtained, the values are shown as Table 2 and Table 3.

),,( 1kTID  sup ),,( 1kTID _min  )k(B ),,( 1kTID  )(TIDC   Table 2. the value of unit triplet and array  K TID  1 2 3 4 5  1  1 1  1 2 1 1 1 3  1 1 1 1 4   1  1  )(kB 1 3 4 1 3   Table 3. frequent 1-itemsets transaction table TID transaction )(TIDC  1 532 III ,,  3 2 ,I,I 32  2 3 532 III ,,  3  53 I,I  2  Before is scanned, ),,( 1kTID ?=L  :{ 32 1ii  ,: ii2 53  , ; After first row is scanned,  and item i  and  and  are linked and itemsets  are obtained. After second row is scanned, itemsets  are obtained; After third row is scanned, itemsets  are obtained; After fourth row is scanned, itemsets  are obtained; thus after unit triplet  is scanned a time, frequent 2-itemsets  are obtained. Similarly, after  0k =   ,:, 52 1ii  }: 2  },,{ 532 iii= L  }1 ,:{ ii3ii 232=  }3  A  :,: ii1i 5352 L  :,: ii2i 5352 ),, 1k  }:, 3ii2 53  3i }:15i  L =  L =  {i2  53ii=   ,:{ i2ii 32  ,:{ i3ii 32 (TID  :,: ii3i 523      ),,( 1kTID  ,,{ 5232 iiiii  min_  ?kif =  is scanned again, frequent 3-itemsets { can be obtained. Because of , the mining procedure stops. Finally, the complete frequent itemsets  are obtained.

}532 iii 3))(( ?TIDCmax  D supmin_  ,,D1  )M(eminUT ?  N iN  iD  },53 532 iiii  D  1=i  isup  D  if  if1= F  isup  iD  iD  min_  ),, 1kTID  kD,  iN  D D,D1  =i NN  ??  ? ??  ? ? N N  supmin_ i  4.  The Algorithm for Mining Frequent Itemsets Based on Disk Databases  Algorithm 2? UT-Mine The Algorithm for Mining Frequent Itemsets Based on Disk Databases  Input?transaction database , Output?complete frequent itemsets Method?  1? patition into partitions?that is  so that every partition can be mined in main memory?  k kD  2? For  to  use  to mine the itemsets which support is equal to or more than  in ?here,  and  is the transaction number in and respectively.

k  iD  iD 3? Let  be the frequent itemsets in 4? ?scan  again?to calculate the support of  itemsets in D ?output the itemets which  satisfies  ?to obtain complete frequent itemsets Figure 5. Algorithm 2   If the size of the constructure of unit triplet  is too big to fit in the main memory ,then the transaction database need to be partitioned. The partitioned mining method is similar to a partitioned Apriori method proposed in [5].

(  Let there be  transactions in , min_sup be the support threshold,  is partitioned into  so that every partition can fit main memory. Let there be transactions in ,then there is equation as follows:  N D ,2  ? =  k  i 1   Thus, when we use UT-Mine (M) to mine frequent itemsets in , the support threshold is :  =supmin_ i  The algorithm for mining frequent itemsets based on disk database is shown as Figure 5.

If an itemset satisfies the support threshold in every partition, then it is global frequent; if a itemset satisfies the support threshold in some partitions and the accumulative total support in the partitions in which the itemset is  frequent satisfies , then it is global frequent too.

If the accumulative support of a itemset of all partitions in which the itemset is frequent do not satisfy , then only the partitions which support is less than need to be scanned to calculate the support again. Finally, the support of every partition is added and global support is obtained, if obtained global support of an itemset is equal to or more than , then the itemset is frequent, otherwise it is infrequent. If an itemset is infrequent in every partition, then it is sure infrequent in global, here it is not necessary to scan again.

isupmin_  supmin_  supmin_ min_ isup  5?Algorithm Analyses  To explain performance of UT-Mine, we contrast the algorithm with Apriori and FP-growth algorithm.

An Apriori-like algorithm generates a huge number of candidates. To find a k-frequent itemset k times scans for transaction database are needed, thus, spending for I/O is very huge. Furthermore, huge candidate item can be generated. If there are 104 1-frequent item, then about 107 candidate 2-itemsets are generated, in this case, Apriori algorithm can meet difficulty.

UT-Mine algorithm adopts unit triplet to save transaction item?with this algorithm, only one time scan is needed in little and middle database, and not more than two times scan is needed in large database, furthermore, UT-Mine algorithm use an optimized method so as to reduce the searched transaction item. In conclusion, UT-Mine algorithm is higher efficiency than Apriori algorithm, it has advantage over less spending for I/O and less searched transaction.

Compared with the FP-growth algorithm, the UT-Mine algorithm has an advantage over less scan times on the transaction database, in the UT-Mine algorithm, only one time scan is needed in little or middle database, but in the FP-growth algorithm, two times scan are needed. in the large transaction database, with The UT-Mine algorithm, the scan times are less than two times, but FP-growth algorithm needs more than two times. When mining sparse transaction database, the advantage of UT-Mine algorithm is visible, in this case, FP-growth algorithm needs a large FP-tree structure to save the transaction item so as to decrease the efficiency for using memory and increase the spending for recursion mining process.

6?Experiment  To evaluate the efficiency of UT-Mine, we have performed a performance experiment, in the experiment,      we use a practical dataset that is from transaction database about a chain supermarket in 1996(note: the item do not anew make order in the transactions). the characteristic of the dataset is shown as Table 3. the transaction length of 1-frequent item for the different support is shown as Figure 6. We can see from Table 3 that the item density is very low about a chain supermarket in 1996(note: the item do not anew make order in the transactions). the characteristic of the dataset is shown as Table 4. We can see from Table 4 that the item density is very low in transaction database of the chain supermarket, so it is efficiency to use unit triplet to save the transaction item. We find that the average transaction length of 1-frequent item (when the average transaction length is calculated, the length is regarded as zero in transaction where there is not frequent item) shorten along with the increase of the support, so it is efficiency to use  to prune infrequent. )(kB   Table 4 the dataset to be used in the experiment Title Content  Transaction number   204796 Maximal transaction length 57 items average transaction length 2.5items     Figure 6. the average transaction length in the projection  database of the 1-frequent item under different support, L is the average transaction length?s is support   In the experiments, we use Apriori and UT-Mine  algorithm to mine the frequent itemsets respectively, the support is 0.01%,0.008%,0.006% and 0.004%. All experiments are performed on a 2.0 MHz Celeron PC machine with 128 megabytes main memory and 30G hard disk, running Microsoft Windows 2000. UT-mine are implemented by using Visual C++6.0. while the version of  Apriori that we used is available at http://fuzzy.cs.uni- magdeburg.de/~borgelt/. All reports of the runtime of two algorithms include both CPU time and I/O time. We make the experiment  The result of the experiments show that the time spending of the Apriori is above 130% of the UT-Mine on appointment support. So UT-mine is more efficiency than Apriori in the experiment under the given condition.

7?Conclusion  This paper presents a novel algorithm for mining frequent itemsets, UT-mine algorithm, the algorithm have obvious advantages, for example, simple data structure, easy to calculate for demanded memory space, less scan times and lower spending for I/O etc. Experiment results show that UT-mine is an effective algorithm for mining frequent itemsets in sparse database.

