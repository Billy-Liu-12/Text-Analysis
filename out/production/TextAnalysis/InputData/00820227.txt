A Fuzzy Data Mining Algorithm for Quantitative Values

ABSTRACT This paper attempts to propose a new data-mining  algorithm to enhance the capability of exploring interesting knowledge from transactions with quantitative values. The proposed algorithm integrates the fuzzy set concepts and the apriori mining algorithm to find interesting fuzzy association rules from given transaction data. Experiments on student grades in I-Shou University are also made to verify the performance of the proposed algorithm.

1. Introduction In data mining researches, inducing association  rules from transaction data is the most commonly seen. Most of the previous research works can, however, only handle transaction data with attributes of binary values. In real-world applications, transaction data are usually composed of quantitative values. Designing a sophisticated data-mining algorithm to deal with different types of data turns a challenge in this research topic.

Recently, fuzzy set theory is more and more frequently used in intelligent systems, because of its simplicity and similarity to human reasoning [8]. The theory has been successfully applied to many fields such as manufacturing, engineering, diagnosis, economics, and others [5, 8, 9, 111. This paper integrates the fuzzy-set concepts and the apriori mining algorithm to find interesting itemsets and fuzzy association rules from transaction data with quantitative values. A fuzzy data mining algorithm is proposed, which is specially capable of transforming quantitative values in transactions into linguistic terms, then filtering them, and finding association rules by modifying the apriori mining algorithm [4] .

2. Review of Agrawal et al's data mining  As mentioned above, the goal of data mining is to discover the important associations among items such that the presence of some items in a transaction will imply the presence of some other items. For achieving this purpose, Agrawal and his co-workers proposed several mining algorithms based on the concept of large itemsets to find association rules from transactions [l, 2, 3, 41. They decomposed the mining process into two phases. In the first phase, candidate itemsets are generated and counted by  algorithms  scanning the transactions. If the number of an itemset appearing in the transactions is larger than a pre- defined threshold value (called minimum support), the itemset is thought of as a large itemset. Itemsets with only one item are first processed. The large itemsets with one item are then combined to form candidate itemsets of two items. This process is repeated until all large itemsets are found. In the second phase, the desired association rules are induced from the large itemsets found in the first phase. All the possible combination ways of association rules for each large itemset are formed, and the ones with their calculated confidence values larger than a predefined threshold (called minimum confidence) are output as desired association rules.

In addition to proposing methods for mining association rules from transactions of binary values, Agrawal et a1 also proposed a method [lo] to mine association rules from those with quantitative and categorical attributes. Their proposed method first determines the number of partitions for each quantitative attribute, and then maps all possible values of each attribute into a set of consecutive integers. It then finds the large itemsets whose support values are greater than the user-specified minimum support. These large itemsets are then processed to generate association rules, and the interesting rules are output from the viewpoint of users.

In this paper, we adopt the fuzzy set concepts to mine associate rules from transactions with quantitative attributes. The rules mined out are expressed in linguistic terms, which are more natural and understandable for human beings.

3. The fuzzy data-mining algorithm for  In this section, the fuzzy concepts are used in the apriori data-mining algorithm to discover useful association rules from quantitative values. Notation used in this paper is first stated as follows.

n: the total number of transaction data; m: the total number of attributes; D") : the i-th. transaction data, 1 I i I n ; Aj : th.e j-th attribute, 1 I j l  m;  IAj 1 : th.e number 0ff.z.q regions for A ;  quantitative values  0-7803-5578-4/99/$10.000 1999 IEEE  4 8 0  http://csa500.isu.edu    R,k : the k-thfuzzy region of Aj , 1 I k I IA, I : V y )  : the quantitative value of A for D(?)  :  f)): thefuzzy set convertedfrom V y ) ; f jl) : the membersh.ip value of Vli? in Region R jk : countjk : the summation o f f  j) for  i=l to n; a : the predefined minimum support: A : the predefined minimum confidence value; Cy  the set of candidate itemsets with r attributes  L,: the set of large itemsets with r attributes (items);  (items).

The proposed fuzzy mining algorithm first transforms each quantitative value into a fuzzy set with linguistic terms using membership functions.

The algorithm then calculates the scalar cardinality of each linguistic term on all the transaction data.

The mining process based on fuzzy counts is then performed to find fuzzy association rules. The detail of the proposed mining algorithm is described as follows.

The Fuzzy Data Mining Algorithm: INPUT A set of n transaction data, each with m  attribute values, a set of membership functions, a predefine minimum support valuea , and a predefined confidence value a .

OUTPUT: A set of fuzzy association rules.

STEP 1 :  For each transaction dataD , i=l to n, and  for each attribute Aj, j= l  to m, transfer the quantitative value vj!? into a fuzzy set f f ?  using the given membership functions, where Rjk is the k-th fuzzy region of attribute Ai, f,!;) is vy ) ? s  fuzzy membership value  in region R jl- , and 1 (= IA , I ) is the number of fuzzy regions for Ay  STEP 2: For each attribute region Rjk, calculate its scalar cardinality on the transactions:  n  count jk = fj) .

~  i=l  STEP 3: For each R,, 1 I j I m  and I l k <  A .  ,  check whether its count j k  is larger than or equal to the predefined minimum support value a .  If R ,  satisfies the above condition, put it in the set of large 1-itemsets (L,). That is:  I J I  L, = [ R ,  I count j k  2 a, 1 I j I m and I I k I A, ) .

STEP 4: Set 1=1, where r is used to represent the  number of items kept in the current large itemsets.

STEP 5: Generate the candidate set Crtl from L, in a way similar to that in the apriori algorithm [4] except that two regions belonging to the same attribute cannot simultaneously exist in an itemset in C,,,. Restated, the algorithm first joins L, and L, under the condition that r-1 items in the two itemsets are the same and the other one is different. It then keeps in Cr+l the itemsets which have all their sub- itemsets of r items existing in L, and do not have two items Rjp and Rjq (p # q).

STEP 6: For each newly formed (r+l)-itemset s with  I 1  items(~, , s 2 ,  ..., s , , ,  ) in Cr+lr do the following substeps:  For each transaction data D U ) , calculate its fuzzy value on s as f,?? = f r ! ) A  f r y ) A  ... Afs f2 ,  where f,(i) is the membership value  of D (?1 in region si. If the minimum operator is used for the intersection,  I  r+l then f i i )  = Min ]=I f:).

Calculate the scalar cardinality of s on the transactions as:  If count, is larger than or equal to the predefined minimum support value a, put s in L,.,,.

STEP 7: IF L,+, is null, then do the next step; otherwise, set r=r+l and repeat STEPS 5 to 7.

the association rules by the following substeps:  (a) Form each possible association rule  s ,h  ... hs,_,hs,+,h  as^, + s k , as follows:  k=l to q.

(b) Calculate the confidence value of the  above association rule as: i fp  i ( f A i ) A  ... A fslf!,, f:;:, A ... A f::?) i = l  STEP 9: Output the rules with their confidence values larger than or equal to the predefined confidence threshold a .

After STEP 9, the rules output can act as the meta-knowledge for the given transactions.

4. Experimental Results Student score data from the Department of  Information Management at I-Shou University, Taiwan, were used to show the feasibility of the proposed mining algorithm. A total of 260 transactions were included in the data set. Each transaction consisted of scores that a student had gotten. Execution of the mining algorithm was performed on a Pentium-PC. The minimum support value a. was set at 40 and the minimum confidence value A was set at 0.8. Totally, 42 rules were mined out. Two rules mined out are shown below as examples.

1.  If the Data Structure score is Low, then the System Analysis and Design score is middle, with a confidence factor of 0.81.

2.  Ifthe Management Information Systems score is middle and the C Programming Language score is middle, then the Business Data Communication score is middle, with a confidence factor of 0.85.

Experiments were also made to show the relationships between numbers of large itemsets and minimum support values. Results are shown in Figure 1.

I 30 40 SO 60 70 80 90 100 Minimum Support Value !

Figure 1. The relationship between numbers of large itemsets and minimum support values.

From Figure 1, it is easily seen that the numbers of large itemsets decreased along with an increase in minimum support values. This is quite consistent with OUT intuition. The curve of the numbers of large 1-itemsets was also smoother than that of the numbers of large 2-itemsets, meaning that the minimum support value had a larger influence on itemsets with more items. Also, appropriate minimum support values can avoid too many large itemsets and.uninteresting patterns.

Experiments were then made to show the relationship of the numbers of association rules and the minimum support values along with different minimum confidence values. Results are shown in Figure 2.

From Figure 2, it is easily seen that the numbers of association rules decreased along with the increase in minimum support values. This is also quite consistent with our intuition. Also, the curves for larger minimum confidence values were smoother than those for smaller minimum confidence values, meaning that the minimum support value had a large effect on the numbers of association rules derived  from small minimum confidence values.

I 1    -0.7 mnf.

-0.8 mnf.

I 40 SO 60 70 80 90 100 Minimum Support Value 1 Figure 2. The relationship between numbers of association rules and minimum support values.

The relationship of the numbers of association rules and the minimum confidence values along with different minimum support values is shown in Figure 3.

0.5 0.6 0.7 0.8 0.9 I  Minimum Confidence Value  Figure 3. The relationship between numbers of association rules and minimum confidence values.

From Figure 3, it is easily seen that the numbers of association rules decreased along with an increase in minimum confidence values. This is quite consistent with our intuition. The curves for larger minimum support values were smoother than those for smaller minimum support values, meaning that the minimum confidence value had a larger effect on the number of association rules when smaller minimum support values were used. All of the various curves however converged to 0 as the minimum confidence value approached to 1.

In these experiments, the association rules mined out can actually be used to help the faculty in the Department of Information Management check the course programs and understand the students' learning interest and capability on the courses.

5. Conclusion and future work In this paper, we have proposed a generalized data-  mining algorithm, which can process transaction data with quantitative values and discover interesting patterns among them. The rules thus mined exhibit quantitative regularity in databases and can be used to provide some suggestions to appropriate supervisors. The proposed algorithm can also solve conventional transaction-data problems by using degraded membership functions. Experimental results with the students' scores in the Department of Information Management at I-S hou University, Taiwan, show the feasibility of the proposed mining      algorithm.

Although the proposed method works well in data  mining for quantitative values, it is just a beginning.

There is still much work to be done in this field. Our method assumes that the membership functions are known in advance. In [6, 71, we also proposed some fuzzy learning methods to automatically derive the membership functions. In the future, we will attempt to dynamically adjust the membership functions in the proposed mining algorithm to avoid the bottleneck of membership function acquisition. We will also attempt to design specific data-mining models for various problem domains.

