Index Selection on MapReduce Relational-Databases

Abstract?The physical design of data storage is a critical ad- ministrative factor for optimizing system performance. Improved system performance can be achieved by building indices.It must be noted that, although indices can improve system performance, creating many random indices may have a negative impact on system performance, and result in wasted space. Selecting indices properly is a fundamental aspect of system design optimization, but it is often a complex task.

Index-selection optimization techniques have been widely stud- ied in DataBase Management System (DBMSs). However, they have not been get the same study in MapReduce Relational- Databases. This paper focuses on the index-selection process in Hadoop-database hybrid systems. The main contribution is the utilization of data mining techniques to develop a tool for determining optimal index-set configurations. An overall evaluation shows that the index configurations recommended by the developed tool achieved an average performance gain of up to 48% in total analytical tasks performed.

Index Terms?Big Data, MapReduce, Hadoop, Index-Selection, Data mining, Frequent Itemset

I. INTRODUCTION  In recent years, the volume of data stored has grown exponentially. Effective management of this - Big Data - is a fundamental task, if one is to benefit from collected information. However, administrating huge and heterogeneous data and interpreting it correctly can pose a challenging task.

New administrative tools are to be developed and used as a way to efficiently design the system or make pivotal decisions become on Big Data systems. Efficient system design based on existing information can significantly improve system per- formance. One of the main aspects of the physical design of a system is indexing. In general, an index is created to speed the information retrieval process but not all index configurations are useful for the system; some indices just reserve space.

Building indices is an expansive and time consuming operation so building all candidate indices is a na??ve method.In recent years,the automated selection process of an appropriate index- set configuration using index-selection tools has received a great deal of attention in DBMS physical design optimization research. Data mining techniques are some of the primary methods used to collect workload from the system, and for recommending the optimal index-set for all similar workloads [4].

Hadoop[11] - a MapReduce-based system - is designed to execute queries through its brute-force scanning model. In  contrast to DBMS, Hadoop does not have built-in indices. In theory, Hadoop could obtain DBMS features such as indexing at two levels: the interface-level such as Hive[12] and Pig[10] and the system-level such as HadoopDB[1] and BigSQL[17].

The need for index-selection tools in the systems using Hadoop and obtaining DBMS features through interface-level or system-level is more urgent than in DBMS, and more complex due to data size. Nevertheless, to the best of our knowledge, there is no research on hybrid system physical design index-selection optimization to date. This is because hybrid systems are still new systems that many companies only recently started to adopt and they change very frequently such as citeref53 for Oracal and [9] for IBM  Indexing is fully supported in Hybrid systems, but the index- selection tools from DBMS cannot be directly deployed on Hybrid systems because of the architectural dissimilarities. In DBMS, both the query engine and the storage engine run in the same database, and thus they are able to share the same memory. However, this is not the case in a hybrid system, where the MapReduce model is designed to be independent from the storage layer. In addition, hybrid systems require specific readers to load data from specific databases opposed to load data from the Hadoop Distributed File System(HDFS), which does not.

The goal of this work is to design an index-selection tool on MapReduce?s relational-database hybrid systems using the HadoopDB open-source infrastructure [19]. The proposed tool for optimal index configuration would help the administrator manage the physical design of large-scale system. It would be injected in HadoopDB to collect the workload, and apply data mining techniques to return the optimal index set. Finally, the ideal index-set would be bundled on the database in order to improve system performance. In general, queries with similar workloads execute around twice as fast with optimal configuration than they do with index-less configuration.

The remainder of the paper is organized as follows: section II describe frequent itemset mining for index-selection, sec- tion III looks at the MapReduce and DBMS hybrid system backgrounds and section IV includes details of the proposed index-selection tool. Section V deals with an evaluation of the tool and experimental results are presented in section VI.

Finally, the paper?s conclusion is presented in Section VII.

DOI 10.1109/BigDataService.2015.23

II. FREQUENT ITEMSET MINING FOR INDEX-SELECTION  Frequent itemset mining is a basic method, and the first stage of association. The algorithms find all fre- quent itemset(indexable-attributes) in a practical transaction database(workload). Generally, the transaction log is scanned to count the itemset frequency, then the itemset support, the ratio of transactions containing the itemset is calculated and finally the support is compared to a minimum support threshold defined by the user. Wherever an itemset meets the minimum support threshold, it is set as a frequent itemset.

Frequent Itemset General Definition: ? Database D : Set of transactions on the transaction log, D = t1, t2, t3, ..., tm.

? I : Set of different items appearing in D where I = i1, i2, i3, ..., in and n is the number of items in I .

? Itemset : A subset collection of items appearing together.

? k-itemset : An itemset of size K.

? Support Count ?(X) : Frequency of appearances of  Itemset X in D.

? Supp(X): Support of an itemset X. It is the fraction of  all transactions that contain itemset X , so Supp(X) = ?(X)/m.

? minSup ? : Minimum support threshold.

? Frequent itemset : An itemset that has Supp greater than  or equal to a minSupp.

? Lk : All frequent itemsets for level K ? Ck : Candidate itemsets for level K  A. Apriori Algorithm  The Apriori algorithm [2] is one of the best known solutions for finding frequent itemsets in rule mining. In the initial pass, the databaseD is scanned to extract all individual itemset candidates C1, and calculates their frequencies. Then, Supp is computed for each of them. Finally, Supp is compared with the defined minSup. The item is added to L1 if its Supp is greater than or equal to the minSup. Other levels are generated from the initial pass as well.

Although the Apriori algorithm has a significant history in association rule mining, it suffers from a number of drawbacks.

The algorithm generates frequent itemsets for one level, and saves it in memory in order to generate the next one. This process requires large amount of memory. Furthermore, the number of candidates grows rapidly as the number of items in I increase. Computing frequent itemsets becomes more and more complex and expensive for large K due to the rapid growth of candidates. In addition to the huge amount of computing power that the algorithm needs, it also consumes a significant I/O for each itemset level while loading the previous level frequent itemset phase.

Even high quality processors cannot handle the algorithm?s workload when it runs over large D. Along with the rapid growth of data in applications today, many algorithms, in- cluding the Apriori algorithm, are now developed on the MapReduce framework. This is because it provides an efficient computing and load balancing parallel processing mechanism for large datasets at a low cost.



III. MAPREDUCE AND DBMS HYBRID SYSTEMS  MapReduce-based systems and DBMS both have strong and weak features with respect to processing and analysing large- scale data. Because of this, research and business communities have tried to develop several solutions to integrate MapReduce and DBMS in an effort to effectively process large-scale, structured data in parallel.

A. HadoopDB  Fig. 1: HadoopDB Architecture [1].

By observing and studying PDBMS and MapReduce model features, the HadoopDB [1] team became motivated to imple- ment a hybrid system of MapReduce technology and PDBMS to support analyzing structured Big Data and shared-noting clusters on a large-scale. The HadoopDB system was designed to combine MapReduce and PDBMS technologies, and benefit from the features of both techniques.

HadoopDB?s basic design idea is to run multiple, separate, single databases in every storage node and co-ordinate them in a Hadoop communication layer. Shared-nothing PostgreSQL is used as an additional database storage layer, and Hadoop as a coordination and communication layer.The communication layer assigns jobs to particular nodes in the cluster after analyzing and monitoring node resource availability. In ad- dition, it controls cluster parallel distribution computing. The communication layer links with the additional storage database layer to execute queries and fetch results from a connector. The storage layer contains multiple nodes running independently on a single-node database to provide systems with database properties like indexing and views.

HadoopDB modified the original Hadoop architecture [11] to combine PDBMS and MapReduce, and added four main components: HadoopDB Catalog, Database Connector, Data Loader and SQL-MapReduce-SQL Planner. The HadoopDB architecture is presented in Figure 1.

? Database Connector: provides HadoopDB with DB connection parameters.

? HadoopDB Catalog: an XML file located in HDFS contains database connection information.

? Data Loader:controls data partitioning and parallel load- ing across HadoopDB clusters. HadoopDB provides two levels of data partitioning: global and local.

? SQL-MapReduce-SQL SMS Planner: The HadoopDB SQL interface that converts SQL queries into MapReduce code converts MapReduce query outputs to SQL utilizing Hive[12].



IV. PROPOSED INDEX-SELECTION  Indexing techniques are important for the physical aspects of data storage, such as engine design, and for increasing data retrieval times. The tool recommends the optimal index configuration for the MapReduce relational database system. It is implemented in the MapReduce environment and is injected into the HadoopDB system. It collects query attributes from tasks running over the MapReduce layer and stores them on HDFS as a query database that can be indexed. Then, the query database is analyzed to extract execution details, such as the number of queries and number of attributes that can be indexed. Depending on how many attribute set frequencies can be indexed in the query database, optimal index-set configurations are selected. Finally, optimal index-sets are built on the database layer.

MapReduce divides problems into small chunks and assigns them to different nodes in a cluster for parallel processing. The advantage of this model is that distribution and networking management details are hidden from the programmer, as appli- cations write only on map and reduce functions. However, this simplicity can also introduce challenges because data input and output must be able to convert to the KVP data representation.

This requires athorough understanding of the problem and data model, and occasionally requires the implementation of a new reader.

The tool processes on three stages: Collector, Analyzer and Recommender as shown in Figure 2 and described in the following.

? Collector: The collector extracts all indexable-attributes from system-executed tasks. Each individual query indexable-attribute Iq is stored on a separate line in the query database D, so queries are identified by offset. I is the set of all different indexable attributes in D. The database is stored on HDFS for future processing by the Analyzer and the Recommender.

? Analyzer: The Analyzer extracts information from the query database and feeds it to the Recommender to run the frequent itemset algorithm. The Analyzer counts the number of transactions (queries)?(q) and the number of different items (attributes)?(i) in thequery database.

? Recommender: The Recommender is at the core of the index-selection tool. First, the mapper reads the query database where each record contains Iq for a particular query. The data then continues to the mapper in the form of a KVP where the key is the query offset in the query database, and the value is the set of indexable- attributesIq . The mapper counts the number of different indexable-attributes in the query ?(iq) and it is the maxi- mum frequent itemset candidate size. Then, all index-sets  Fig. 2: Index Selection Flow Chart.

(candidates) Cq in the query are generated from level-1 to level-?(iq). The mapper sets key to index-sets c ? Cq and sets the value to one, where one refers to simply to existing in that particular query, regardless of how many times the attribute or attribute set appears in the same query. This is the rule of the Apriori algorithm: the item occupancy count is one per transaction, even if it appears several times. All mappers send keys and values to the reduce phase before the Reducer groups the values according to the key, which the index-sets c.

Then, it sums the values of that key to find the index-sets frequency on the query database. Next, the index-sets Supp(c) are computed and compared with the minSupp threshold. If Supp(c) is greater than or equal to minSupp then the index-set c is a frequent itemset, and it is saved as an optimal index-set configuration in L. Finally, the optimal configuration is built into the storage layer of each single database node. The Recommender pseudo- code is shown in Algorithm 1.

Algorithm 1 Recommender(?(q), ?) Mapper: for all q ? D ?(iq) ? toknizeV alue.count  Cq ? {c | c ? ?  x=[1??(iq)] Cx ? c ? q}  // Generate all candidate in q from level 1 to K end for for all candidate c ? Cq  appendOutput(c, 1)  Reducer: receive(c,valueList) c.frequency =0 for allvalue ? valueList  c.frequency = + value Supp(c)= (c.frequency ? ?(q)) if Supp(c) ? ?  appendOutput(c, Supp(c))

V. EXPERIMENTS  This section describes the testing environment, and outlines the results of the performance evaluation for the proposed index-selection tool used on the HadoopDB system. The objec- tive of the experiments performed was to assess performance improvement in different index configurations provided by     the proposed tool in a HadoopDB system, when compared to performances in index-less configurations. The experiments show that task response time with the proposed tool index configuration greatly outperform the ones that use a brute- force approach.

A. Experimental Environment  The experiments were conducted on a HadoopDB cluster with two nodes. Each node was equipped with 12 GB memory, 2.67GHz core processors and 250 GB storage. One node acted as a master and both nodes were used as slaves. All experiments were conducted on the HadoopDB open source system [19] and had Hadoop as the communication layer and PostgreSQL database as the storage engine.

The performance of the proposed tool was evaluated using the web analytic benchmark tasks tool that is included in the HadoopDB system, and which was originally developed in [18]. The benchmark had four analytical tasks: Aggrega- tion Task, Join Task, Selection Task and UDF Aggregation Task. The last task,however, was not used in our experi- ments, because it did not contain condition-expression syntax.

Therefore, there is no candidate index set for this task. The rest of the tasks are described in the paper were originally developed. The web analytic tasks did not have many attributes in their condition expression syntax. Consequently, there were a limited number of index candidates in the workload. With few items (index candidates) to select from, the generated frequent itemset were not changed by large minsupp values.

Itemsets are stable for different minsupp percentages when there is no index to be selected from the workload. The web analytic tool is the only benchmarking tool suitable for required testing. However, at best of our knowledge, there is no standard decision support benchmark for Big Data DBMS as of yet. For example, the Transaction Processing Performance Council(TPC) has the TPC-R decision support benchmark standard that is typically used in DBMS index tuning research, but the Big Data standard benchmarking(TPC-BD) tool is still in its development stages [6].

In order to evaluate the tool?s performance, the task ex- ecution times were observed in two stages. First, index-less configurations were used, where tasks were executed without building an index. Then, the same tasks were executed with various index configurations that used different user specified minsupp values. The response times in seconds are the average recorded times, and the experiments were repeated 10 times.

The suggested HadoopDB and PostgreSQL settings on [19] are applied. The DataSets in each node in the cluster contained 20 chunks distributed in different PostgreSQL databases, and each chunk contained Rankings and UserVisits datasets. First, the dataset was uploaded to HDFS. Next, the HadoopDB Global Hasher partitioned the dataset in parallel into all nodes.Then, the Local Hasher partitioned each chunk in each node into 20 small chunks, so the whole cluster contained a total of 40 chunks. The chunk size was 1GB for the UserVisits dataset, and around 51MB for the Rankings dataset. The final step was to load the dataset into the database layer. Small chunks were bulk-loaded into a single PostgreSQL node.In  addition, a workload was created from the analytical tasks and it contained around 36K transactions (tasks), which took about 1MB storage in our HDFS.

B. Analytical Tasks  Fig. 3: Large Aggregation Task.

As mentioned earlier, the proposed tool executes three web analytical tasks: Aggregation, Join and Selection. The Aggregation task has two subtasks: a large Aggregation task and a small Aggregation task. They are treated as two separate tasks in our experiment. In total,we considered four tasks for our experiment.

The task response time examined two possible settings: index-less and index-based. In the index-less configuration, the executed tasks were a sequential scan that did not involve creating any indices on any tables in PostgreSQL instances.

Then, the same tasks were executed several times for the index-based setting with various index configurations that were based on the user selected minsupp value for the index- selection tool.

Overall, the index configurations recommended by the tool achieved an average performance gain of up to 48% in all analytical tasks performed when compared with the index- less configurations. These results are presented in Figure 7.

With a high minsupp threshold, there was no performance distinction between index-less and index-based settings. This was a predictable result, since there is no index candidate for high threshold values. For example, to have index candidates with minsupp= 90%, the index candidates must appear nine times when the workload has ten transactions, which typical.

Figures 3, 4, 5, and 6 display the results of executing the  Fig. 4: Small Aggregation Task.

Fig. 5: Join Task.

Fig. 6: Selection Task.

Fig. 7: Tasks Response Time on Diffident Index Configura- tions.

Fig. 8: Compare Tasks Response Time on Index-based and Index-less configuration.

large aggregation task, small aggregation task, join task and selection task, respectively. As it was explained earlier, the performance gain does flatten out, due to the limited number of index candidate available in our datasets. We also observed fluctuation in the performance of the large aggregation task and in the selection task. These were, in part, due to the fact that part of the task operations took place on database nodes, whereas other operations, such as aggregation and grouping, were finalized on the MapReduce layer. However, optimizing the MapReduce design to address this issue is outside the scope of this work; the proposed index recommendation tool works on the physical design of the database, not the logical execution plans for the database or the MapReduce layers.

Figure 8 summarizes the results of all tasks, and it shows that although join task is a very expensive operation, it performs well with index-based configuration. Aggregation tasks do not exhibit huge improvements, since the GROUP BY clause does not benefit from indices significantly.

1) Large Aggregation Task : compute the overall adRev- enue for each individual sourceIP on the UserVisits.

2) Small Aggregation Task: compute the overall adRevenue for each individual sourceIP on theUserVisits, but it only grouped the first seven-character of the sourceIP.

3) Join Task: computed the pageRank average and the adRevenue sum of the set of sourceIP during specific days.

4) Selection Task : select pageURL and pageRank over the rankings table condition set by the pageRank.



VI. RELATED WORK  Index selection tools are developed for database systems in order to build the physical design effectively, and to improve overall system performance. The tools help the database administrator easily and efficiently manage physical design challenges, including index selection. Index selection is not a new idea; it has been studied in database environments since the late 1980?s by Finkelstein et al.[8]. In commercial applications, Microsoft developed indices and materialized view selection tools for Microsoft SQL Server 2000 [3].

There is a wide variety of research in database index selection on various contexts, we chose to focus the work on using data mining such as [4], that apply a data mining-based optimization approach for index and view selections in DBMS.

Our proposed tool applies the data mining in HadoopDB, where the Apriori algorithm is implemented, and the query workload is collected in the MapReduce layer rather then DB.

Running the Apriori algorithm on massive datasets requires a very expensive and complex computing system. It needs to scan massive data K times to generate candidates. A single processor?s memory and CPU resources are not capable of handing that workload. Thus, parallel and distributed technol- ogy is used for accelerating Apriori algorithm performance.

Recently, [15, 21, 16] developed Apriori-based algorithms in MapReduce to benefit from parallel computing but they use K-phases approach which does not necessarily reduce scanning times. [14] proposed a single phase MapReduce Apriori algorithm to scans the dataset just one time and they compare the algorithm performance in MapReduce and single     processer. We used the same approach but with a very different goal. We use it for gathering the most frequent itemset results, and then recommends the optimal index configuration to the storage layer in HadoopDB. Although MapReduce provides simple parallel computing, it leaves the optimization tasks to the programmer. The MapReduce model does not have a built in optimizer for logical MapReduce job execution, or for physical data organization. Authors of [5, 13] developed a job execution optimizer on the original MapReduce model, as well as HDFS, to automatically select the ideal MapReduce logical execution plan, but not to manage HDFS physical design. The implementation in [20] has the same goal for optimizing the logical execution of MapReduce, but over the Hive interface- level. The optimizer design in [5, 13, 20] chooses the most appropriate index among several existing indices in HDFS for a logical execution plan through MapReduce. The researchers aim to choose indices, not to build appropriate index config- uration for the system and the research in [7] developed an index selection technique on Hadoop for it?s default HDFS storage layer where us build for Hadoop with DB storage.



VII. CONCLUSIONS The proposed index-selection tool could help large-scale  data administrators improve the MapReduce-database system performance by around 48% in total. Indexing is one of the most important aspects in any storage system for speeding-up retrieval of data, and for avoiding irrelevant records. However, not all indices improve performance, some indices just reserve space and are not accessible through any queries. Thus, choos- ing an optimal index configuration can significantly improve system performance.

