

Abstract  Clustering  enhances  the  value  of  existing databases by revealing rules in the data. These rules are useful  for understanding trends,  making  predictions  of future events from historical  data,  or synthesizing data records into meaningful clusters. Through clustering are similar  data  items  grouped  together  to  form  clusters.

Clustering algorithms usually employ a distance metric based  (e.g.,  Euclidean)  similarity  measure  in  order  to partition the database such that data points in the same partition  are  more  similar  than  points  in  different partitions. In this paper, we study clustering algorithms for  data  with  categorical  attributes.  Instead  of  using traditional  clustering  algorithms  that  use  distances between  points  for  clustering  which  is  not  an appropriate  concept  for  Boolean  and  categorical attributes,  we  propose  a  novel  concept  of  HAC (Hierarchy of Attributes and Concepts) to measure the similarity/proximity between a pair of data points.

In this study,  HAC will be used as an aid to represent  medical  domain  knowledge  substructures  to simplify the generation process of the databases through clustering.  As  a  result,  the  research  will  identify interesting  relationships  and  patterns  among the  data, and represent them in the form of association rules.

1. Introduction Data Mining has become a prominent approach  in  recent  years  for  generating  rules  within  databases which  concentrates  on  generating  valuable information for decision making.  Clustering,  in Data Mining,  is the problem of identifying  the  distribution  of patterns  and intrinsic correlations in large data sets by portioning the data  points  into  similarity  classes.  The  traditional clustering algorithms which use distance between points define  boundaries  in  clustering.  But,  these  clustering mechanisms don?t apply on Boolean and categorical  attributes. The clustering is applied on unstructured data to extract knowledge that  may take a form of predictive rules.

This research focuses on hierarchical conceptual clustering  in  structured,  discrete-valued  databases.  By structured  data,  we  refer  to  information  consisting  of data  points  and  relationships  between  the  data  points.

This  differs  from  a  definition  of  unstructured  data  as containing  free  text  and  structured  data  containing feature vectors.

Conceptual  clustering  is  an  important  way of summarizing  and  explaining  data  [1,  6].  However,  the recent  formulation  of  this  paradigm  has  allowed  little exploration  of  conceptual  clustering  as  a  means  of improving performance.  Furthermore,  previous work in conceptual  clustering  has  not  explicitly  dealt  with constraints  imposed  by real  world  environments.  This article  presents  a  clustering  using  HAC (Hierarchy  of attributes  and  concepts),  which  is  a  hierarchical conceptual clustering system that organizes data so as to maximize inference ability. This algorithm uses both the hierarchical  and  conceptual  clustering  methods  to implement  clustering  by  discovering  substructures  in database which compress the original data and represent structural  concepts  in  the  data.  Once  a  substructure  is discovered, the substructure is used to simplify the data by replacing instances of the substructure with a pointer to  the  substructure  definition.  The  discovered substructures allow abstraction over detailed structures in the original  data.  Iteration of the substructure discovery process  constructs  a  hierarchical  description  of  the structural  data in terms of the discovered substructures.

This  hierarchy provides varying  levels of interpretation that  can be accessed based on the specific data analysis goals.

2. Related Work Clustering  is  the unsupervised classification of  patterns (observations, data items or feature vectors) into  Extraction Of Meaningful Rules In A Medical Database  Sang C. Suh Sam. Saffer  Naveen Kumar Adla Department of computer science  Texas A & M University ? commerce Commerce, Texas ? 75429  Sang_Suh@TAMU-Commerce.edu   DOI 10.1109/ICMLA.2008.123     groups  (clusters).  The  clustering  problem  has  been addressed in many contexts and by researchers in many disciplines;  this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering  is  a  difficult  problem  combinatorial  and differences  in  assumptions  and  contexts  in  different communities  have  made  the  transfer  of useful  generic concepts and methodologies slow to occur [2].

Hierarchical  clustering  is  one  of  the  most frequently used methods in unsupervised learning. Given a  set  of  data  points,  the  output  is  a  binary  tree (dendogram) whose leaves are the data points and whose internal  nodes represent nested clusters of various sizes.

The  tree  organizes  these  clusters  hierarchically,  where the hope is that  this hierarchy agrees with the intuitive organization  of real-world  data.  Hierarchical  structures are ubiquitous in the natural world [5].

There  are  two  general  approaches  to hierarchical  clustering:  top-down  and  bottom-up.  The top-down approach  starts  with  a  cluster  containing  all points that  is recursively split  until  enough sub clusters have  been  created.  Heckel  et  al.  [10,  11]  use  this approach on vector fields where each point has a position and a vector. The cluster with the highest error value is then split  into two clusters recursively so that  the error values of the remaining clusters decrease with each split.

The bottom-up approach starts with all points as individual clusters and merges the two clusters with least difference until one big cluster has been formed from all clusters.  Telea and  van Wijk [10] use this  approach  to simplify complex vector fields using an elliptic similarity function.  They merge the pair  of vectors with the least position,  magnitude  and  direction  differences  until  all vectors have been merged into one single vector.

Conceptual clustering is used to summarize the result.  It  enhances  the  value  of  existing  databases  by revealing  patterns  in  the  data.  These  patterns  may be useful for understanding  trends,  for making  predictions of  future  occurrences  from  historical  evidence,  or  for synthesizing  data records into meaningful  clusters.  The hybrid  conceptual  clustering  [3] is used to handle both the  incremental  and  non  incremental  problems  for clustering  successfully  but  it  is  computationally expensive moreover can be applied on small data sets. In past  decades,  many  conceptual  clustering  algorithms have  been  proposed  which  can  automatically  acquire knowledge  or  concepts  from  large  amounts  of information acquired from experience or observation [1, 7,  8,  9].  Concepts  in  COBWEB  are  represented  by probabilistic expressions and are acquired by using four learning  operators  and  an  evaluation  function  called category utility. But the category utility used in original COBWEB has  a  bias  to  prefer  larger  size  classes  in concept  hierarchy.  This  bias  produces  some  spurious intermediate  nodes  in  concept  hierarchy  (classification tree). These nodes make tree deeper and complex, so we  can?t understand concepts within the nodes of tree easily [9]  This  paper  presents  an  efficient  non-metric measure  called  HAC  (Hierarchy  of  Attributes  and Concepts)  for clustering  of categorical  as  well  as  non- categorical(quantitative)  data  through  which  the proximity and  relationships  between data  items can  be identified  3. Approach HAC  is  both  a  hierarchical  and  conceptual  clustering system that organizes data so as to maximize inference ability. This algorithm implement clustering by discovering  substructures  in  database  which  compress the original data and represent structural concepts in the data. Once a substructure is discovered, the substructure is used to simplify the data by replacing instances of the substructure with a pointer to the substructure definition.

The  discovered  substructures  allow  abstraction  over detailed structures  in  the  original  data.  Iteration  of the substructure  discovery process constructs  a  hierarchical description  of  the  structural  data  in  terms  of  the discovered  substructures.  This  hierarchy  provides varying  levels  of  interpretation  that  can  be  accessed based on the specific data analysis goals.

HAC  accepts  database  of  structured  data (concepts)  as  input.  This  type  of  data  is  naturally represented  using  a  graph.  The  graph  representation includes  labeled  vertices  with  vertex  id  numbers, attributes on X-axis and downward directed edges. Each vertex represents a concept and the value of that concept is  given  by  the  directed  edges  (usually  map  to  the attribute?s  value  on  X-axis  or  to  some other  concept).

With this graph  we can make a concept table for every attribute in the database and this table will have all the concepts and their value which are relevant according to the attribute.  Ultimately with  the help of these concept tables we can get a table in which each record will have an  attribute  name,  its  value  and  relationship  with different concepts. Each attribute in this table represents a cluster.  In  the following we give a  brief summary of how HAC works.

3.1. Algorithm 1. Make concept tables for different concepts by  grouping logically related attributes into concepts.

2. Make  a  hierarchy  graph  with  different  levels using the concept tables from step 1 where each level or concept is meaningful.

For  example  in  Figure  1  concept  D12  has  a  name wheat allergy which is perfectly meaningful since, it has got four attributes (Gluten, Oats, Barley, and Rye) under  it,  which  are  causes  for  D12.  In  the  example explained below we used two concept tables for attributes ?Diseases? and ?Food category?.

3. Make a ?Cluster Point Table? which will have attribute name, attribute value and relationship with different concepts. Attribute name is basically the name of cluster; Attribute value will give the value of cluster which is a combination of different concepts. Attribute values can be generated by using following steps: a) Let totalNum= Total number of attributes in cluster point table; b) Concept_1=total number of concepts in first concept table; c)Concept_2=total number of concepts in second concept table; d) totalNum= Concept_1 * Concept_2; e) For i=0 to totalNum e)Vi  = total  number  of records  under  different  combination of C1 (j, j+1---m) and C2 (k, k+1----n) Here,  V  (i,  i+1----totalNum) are  different  clusters  or  attributes in Cluster Point Table.

f) C1  (j,  j+1---m)  are different  concepts of  concept  table1 g)  C2  (k,  k+1---m)    are  different  concepts of concept table2  4. From the Cluster Point table and Concept tables (generated from step 1 through step3) we can generate rules.

In the following example, Figure 5 is a ?Cluster  Point Table?, cluster V4 or attribute V4 has value of 6 for concept    D12 and C4. Thus, the rule generated is ?there are  6  patients  with  ?Gluten?  or  ?Oats?  or  ?Barley?  or ?Rye?  Foods  (concept  C4)  can  cause  wheat  allergy (concept D12)?.

ID Disease Name Causes Id  1 Acute sinusitis K1,K2,K3,K4 2 Anaphylaxis K5,K6,K7,K8,K9,K10,K11,K12,K13,K14,K15,K16  3 Penicillin allergy K6  4 Latex allergy K17,K18  5 Peanut allergy K6,K19,K20,K21,K22,K23,K24,K25,K26,K27,K28,K29,K30,K31  6 Mold allergy K32 7 Nickel allergy K21,K29,K33,K34,K35,K36,K37,K38,K39  8 Dust mine allergy K40  9 Asperigillosis K29,K41,K42,K4,K44 10 Soy allergy K45,K46  11 Shellfish allergy K47,K48,K49,K50,K51,K52,K53,K54,K55,K56  12 Wheat allergy K57,K58,K59,K60 ? ? ?  ? ? ????.

20 Food allergy  K6,K7,K8,K9,K10,K11,K23,K24,K45,K46,K47,K4, K49,K50,K51,K52,K53,K54,K56,K57,K58,K59,K6 0,K62,K63,K64,K65K66,K67,K68,K88,K89,K90,K 91,K92,K93  Table 1.Attribute table for Allergy diseases  k1 k 2 k3 k 4 k5 k 6 k7 k 8 k9 k 11k 12 k 13k 14k 15k 16k 17 k 18k 19k 20k 21k 22k23k 24k 25 k26k 27k 28k29k 30 k 31k 32k33 k 34k 35k36k 37k38 k 39k40k 41k 42k 10 k 43k44k 45k46 k 47k 48k 49 k50k 51k 52k 53k54 k55k 56k 57 k58k59 k60k61 k62 k63k 64k 65k 66k67 k68k 69  D4  D5  D6  D7  D8  D9  D10  D11  D12 D13  D14  D15  D16 D17  D18  K70 k 71  k 72 k 73 k74  k 75  k 76 k77  k 78  k 79 k80 k 81  k 82  k 83 k84  k 85 k 86 k87 k 88  k 89 k90  D1 D2 D3  D20  D19  HIRERACHY OF HAC FOR DISEASES  Figure 1 HAC of Disease and Causes  Causes  D is or de r     3.2 Case Study: Clustering Using the HAC This  is  an  example  between  various  allergy  diseases and food categories in an allergy database. First a  chart  of  various  concepts  is  formed  in  which  each concept will have allergy disease name as its value. Note that it could include multiple entries.

3.2.1 HAC1 In Table 1 which is an attribute table for allergy  disease, the attribute names are mapped with its values for reference purposes.

Cause ID Cause  K1 cold virus K2 bacterial or fungal K3 deviated nasal septum K4 nasal polyps K5 Drugs K6 Peanuts K7 tree nuts K8 Milk K9 Eggs  K10 Fish K11 Shellfish K12 Insect stings from bees  ??? . ???..

K93 Mushrooms Table 2. TACR for Allergy Diseases  The concepts D1 through D20 in the TACR for the  attribute  ?Allergy  diseases?  shown  in  Table  2 summarize the concepts in the HAC hierarchy of Figure 1  that  hold  among  different  attributes  and  concepts  of diseases.

Note  that  the  root  concept  D20  embraces  all concepts  and  attributes  of  ?Food  related  allergy diseases.?  Food Categor y ID  Food Category  Food  ID  C1 Dairy F1,F2,F12,F17,F21,F36,F54 C2 Seafood F3,F4,F73,F74,F75,F76,F77,  F78 C3 Poultry F18,F40,F48,F26,F10,F30 C4 Grains F7,F16,F29,F33,F50,F68,F69  ,F70,F8 C5 Nuts F5,F90,F84,F91,F93 C6 Fruits F32,F37,F71,F72,F81,F82,F8  5,F86,F87,F89,F92,F95 C7 Vegetables F6,F53,F55,F58,F67,F80,F83 C8 Bakery F11,F13,F14,F20,F43,F45,F5  C9 Drinks F9,F15,F24,F25,F35,F39 C10 Fat items F22,F28,F41,F5 C11 Seeds F42,F60,F61 C12 Leafyand  Salad vegetables  F52,F57,F64,F65,F79,F88  C13 Junk foods F19,F23,F27,F31,F38,F49,F4 4,F46,F47,F94  C14 Spices F34,F56,F62,F63,F66 Table 3. Attribute table for Food   3.2.2 HAC2  Similarly  we can  build  the  HAC structure  for another attribute ?Food category? as shown in Figure 2.

The  hierarchy  shows a  conceptual  relationship  among the values and concepts related to the attribute ?Foods.? For this purpose the attribute table in Table 3 is used.

The concepts C1 through C14 in the TACR for the  attribute  ?Food  Category?  shown  in  Table  4 summarize the concepts in the HAC hierarchy of Figure 2 showing the relationships among different  values and concepts associated with Food Category.

Food ID Food values  F1 Eggs F2 Milk F3 Fish F4 Shellfish F5 Tree nut F6 Beans F7 Wheat F8 Gluten F9 Alcoholic drinks F10 Beef F11 Bread F12 Butter ? ???  F95 Cherry Table 4. TACR for Food Category  Using  the  TACRs  for  the  selected  attributes,  Diseases and  Food  Category  in  this  case,  a  graph  can  be constructed  to represent  clusters  at  concept  levels.  The graph  is  shown  in  Figure  3.  Each  point  in  the  graph represents a concept that is formed by a combination of attribute  values.  Let?s  call  this  point  in  the  graph  a Concept  Cluster  Point  (CCP).  Since  the  cluster  point represents a high level concept, it naturally converts to a rule  that  matches  with  a  concept.  Furthermore,  the support  of  each  rule  can  be  given  by calculating  the number of contributing entries in the original  relational table to form the concept.

Conceptual Points  Support Concepts (diseases)  Concepts (food category)  V1 5 D5 C5 V2 2 D10 C5 V3 6 D11 C2 V4 6 D12 C4  V5 2 D13 C1 ------ --- ----- ---- V15 1 D20 C6 V16 1 D20 C7  Table 5. Cluster Point Table  In  Table  5  above,  the  CCPs  V1 through  V9  each represent a concept cluster representing a high level concept associated with departments and degrees with a support  value.  Hence the  next  step is  to convert  these CCPs into characteristic rules. To help this process, the CCP graph  in  Figure 3 is used. Note that  each CCP is associated  with  an  appropriate  support  value  which represents  the  weight  to  support  the  converted  rule representing the concept.

Each  CCP  in  Figure  3  represents  rules regarding how many people affected with specific allergy affected  by  food  category  and  concepts.  A  rule  can directly be generated from the cluster point table with the support from the attribute tables and TACRs. The cluster point table is shown as cluster point graph, each point in the  graph  represents  rule  associated  with  support.  For example,  if  we want  to query how the  milk  allergy is affected by dairy products. In this example, the milk  allergy has  D13 and  the  dairy product  is  C1,  both the combination  of  D13  and  C1  represents  V3  that  has support 5.

4. Implementation We  have  used  a  medical  database  which  contains information about patient causes and food types.

This is generated syntactically based on the case studies found in the websites [13, 14]. We used 2 concept tables for implementation of our algorithm;  first concept table is  for  attribute  ?Allergy  diseases?  and  second  concept table is for attribute ?Food categories?.

Each  concept  table  will  have  a  different hierarchy  level  for  respective  attributes,  example  in Concept table for attribute ?Allergy disease? concept D1 (Acute sinusitis) represents hierarchy level of cold virus, bacterial or fungal, deviated nasal septum, nasal polyps.

Similarly concept table for the attribute ?Food categories? represents different hierarchy level of degrees. Using  f1 f2 f3 f4 f5 f6 f7 f8 f9 f11 f12 f13 f1 4 f1 5 f1 6 f1 7 f1 8 f1 9 f2 0 f2 1 f2 2 f2 3 f2 4 f2 5 f2 6 f2 7 f28 f29 f30 f31 f3 2 f3 3 f3 4 f3 5 f3 6 f3 7 f3 8 f3 9 f4 0 f4 1 f4 2f10 f4 3 f4 4 f4 5 f46 f47 f48 f49 f50 f5 1 f5 2 f5 3 f5 4 f5 5 f5 6 f5 7 f5 8 f5 9 f6 0 f6 1 f6 2 f6 3 f64 f65 f66 f67 f68 f6 9 f7 0 f7 1  C1  C2  C3  C4  C 5  C 6 C 7C8  C9  C 1 0  C11  f7 2  f7 3  f7 4  f7 5  f7 6  f7 7  f78  f7 9  f8 0  f81  f8 2  f83  f84   f8 5   f8 6  f8 7  f8 8  f8 9  f9 0  f9 1  f9 2  f9 3  f94  f9 5  f96  c1 2  c1 3  C1 4  Food category  Figure 2   HAC for Food and Foodtypes  Fo od Ty pe  D1 D2 D3 D4 D5 D12D10 D11  C1  C  C3  C6  C7  C on  ce pt  s o f F  oo d  C at  eg or  ie s  Graph between concepts of Allergy Diseases on X-axis and concepts of Food categories  onY-axis.V1 to V12 have different numeric values.

V1 V2  V3  V4  V15  V5  V16  C4  C5  ?  ? C15  D1  ? ?.

Concept of allergy diseases  Figure 3. Cluster Point Graph     these two concept tables we made ?Cluster Point Table? which  has  all  the  possible  clusters,  each  cluster  is  a combination  of  ?Allergy  disease?  attribute  and  ?Food categories? attribute.

We used non-numeric or categorical data for our clustering  algorithm.  This  algorithm is implemented in ?JAVA? with a simple user interface which makes it very easy to use. User just needs to select different concepts of different  attributes,  concepts  are  dynamically generated from  concept  tables  in  database.  After  selecting  the concepts the user needs to press the ?Submit? button that will  display  the  result  or  you  can  say  rules  for  our ?Cluster  Point  Graph?  on  an  additional  results  page.

?Cluster Point Graph? represents all the clusters possible from different combinations of different concepts.

5. Result Depending on the concept tables the results are  generated in the form of rules. Each row in the ?cluster point table? represents a cluster that takes a form of rule.

The  total  number  of  rules  depends  on  the  number  of concept tables. Here we are using two concept tables that have generated rules has follows:  1.  The  two  concept  tables  used  are  Allergy Diseases  and  Food  Categories.  The  sample  rules generated such as:  a)  Most  likely,  the  persons  are  affected  by specific allergy due to specific food category.

b)  The  total  number  of  persons  with  specific values of different concepts.

From the  user  perspective the  user  selects  the disease  and  food  category  then  it  shows  the  resulted cluster value from cluster  point  table. If the user  select Concept ?Milk Allergy? and Concept ?Dairy Products? if you submit the query then it will generate the rule as  ?There are 5 persons affected by ?Milk Allergy? due to ?Dairy Products? or either way we can generate the rule or  there  are  45  persons  with  different  symptoms  are affected. The sample result is shown in Figure 4.

2.  Furthermore,  the  algorithm  can  be implemented on three concept tables. These generates a rules  are  based on the  concept tables and  input  tables.

The HAC generates different rules based on the concept tables  with  different  combinations  of  concepts.  Each concept  table  represents  conceptual  hierarchies  of categorical  attributes.  This  algorithm  specifies  the clustering on categorical attributes on the concept tables to derive the association rules in the form of cluster point table.

6. Conclusion In  this  paper,  we  studied  the  hierarchical  conceptual  clustering  applied  on  structured  databases.

We have given a new method of HAC with conceptual clustering  to  explore  categorical  data.  The  main contributions of the paper are to develop HAC algorithm which  is  applied  on  categorical  attributes  instead  of traditional  algorithms  which  apply the  distance  metric measures.  The results show that  the data is categorized using  hierarchical  conceptual  clustering  with  HAC.

There are numerous types of clustering techniques most of  these  techniques  are  applicable  only  on  the unstructured  data.  Sometimes,  there  is  a  need to apply clustering on categorical attributes which is not suitable to apply on it.  So, the non-metric measures are used to perform  clustering  on  the  categorical  attributes  which represents  the  closest  proximity  between  the  data attributes. HAC is  used  to  represents  databases  in  the form concept tables for categorical  data  which contains the concepts formed on the domain. This technique can be applied on any of the fields which have structure data.

Figure 4. Sample output screen of Cluster Point table     The information  is  extracted using  the  HAC algorithm from structured data.

The structured data is applied on input and the results  formed  are  rules  extracted  from  the  data.

Clustering  is  important  for  both  types  of  data.  The modern  data  mining  mechanisms  are  used to apply on the  data.  From  a  machine  learning  standpoint,  this research  has  been  greatly  influenced  by  work  in conceptual  clustering.  HAC  seeks  classifications  that maximize  a  heuristic  measure  (as  in  conceptual clustering systems) and uses a search strategy abstracted from incremental systems such as UNIMEM [8].

7. Future Work Our algorithm can be effective in the medically  related  areas  to  allergic  disease.   Implementing  this algorithm with multiple concept tables can be a potential extension  of  the  approach  in  our  case  we  have implemented  only  on  two  concept  tables.  Another important  enhancement  of  this  algorithm  can  be  its implementation on other  domains in medicine and also domains apart from medical areas.

8. Acknowledgement This  research  has  been  partially  supported  by  L-3  Communication  Corporation,  ComCept  Division under Project Corvus.

9. References [1]  Douglas  H.  Fisher,  ?Knowledge  Acquisition  Via Incremental  Conceptual  Clustering?,  University  of California,  Machine  Learning,  Volume 2,  Issue  2,  pp.

139-172, CA, USA, 1987.

[2] A.K. Jain, M.N. Murty, P.J. Flynn , ?Data Clustering: A Review?, ACM Computing Surveys  (CSUR),  Volume 31,  Issue 3,         pp. 264 - 323 ,  September 1999 [3] Jungsoon Park Yoo, Chrisila,C.P., & Sung Yoo. "A Hybrid  Conceptual  Clustering  System", Proceedings  of the  1996  ACM  24th  Annual  Conference  on  Computer science, pp. 105-114, 1996 [4]  Fei  Wu.,  Georges,G.,  ?Gradual  clustering Algorithms?,  Seventh  International  Conference  on Database Systems for Advanced Applications,2001.

[5] Sudipto Guha1, Rajeev Rastogi and Kyuseok Shim3, ?ROCK: A Robust Clustering Algorithm for Categorical Attributes?, IEEE  International  Conference  on  Data Engineering, "Information  Systems", Volume  25, Number 5, pp. 345 ? 366, 2000.

[6] Sang C.Suh, Sam I. Saffer, Nikil Goel, ?Generating Meaningful Rules Using Attribute Concept Hierarchy ?, Artificial  Neural  Networks  in  Engineering,  pp.  1-6, 2006.

[7] E.  A. Freigenbaum, H. Simon,  ?EPAM-like models of recognition and learning?, Cognitive Science, Volume 8, pp. 305 - 336, 1984.

