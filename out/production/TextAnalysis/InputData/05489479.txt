Comparison between Adaptive and Non-Adaptive HRBF Neural Network in  Multiple Steps Time Series Forecasting

Abstract? This paper compares the performance of adaptive and non-adaptive learning approaches of the Hybrid Radial Basis Function (HRBF) neural network in multiple steps time series forecasting. The HRBF was trained by using the Adaptive Fuzzy C-Means Clustering (AFCMC) and Exponential Weighted Recursive Least Square (e-WRLS) algorithms. Both approaches were set to produce up to 25 steps ahead forecasting on two time series data: Mackey Glass and Set A Data from Santa Fe Competition. The performance of both approaches in multiple steps ahead forecasting was measured using Mean Square Error Test and Coefficient of Determination Test between the actual and forecasted data for the 25 steps ahead forecasting. Results show that both approaches perform comparatively equal for shorter forecasting distance. However for longer forecasting distance (10 steps ahead onwards), the adaptive approach performs significantly better to compare with non-adaptive approach.

Keywords - adaptive; non-adaptive; HRBF; time series forecasting

I.  INTRODUCTION The study on time series forecasting has started long  time ago. Yet until today, this field still captures researches? interest to explore its possibilities. Research in time series forecasting has develop impressively since the emergence of Autoregressive Integrated Moving Average (ARIMA) model by Box and Jenkins. To date, various methods were introduced from Regression analysis [1], Artificial Neural Networks (ANN) [2], Fuzzy Logic (FL) [3] and Genetic Algorithms [GA] [4]. Among them, the computational intelligence technique such as ANN, FL and GA are getting more attention in time series forecasting because they are non-linear in nature and able to approximate easily complex dynamically system. ANN for instance, demonstrates promising performance in various time series forecasting [5], [6], [7].

Studies show most ANN training algorithms use to solve time series forecasting problem are implemented in non- adaptive approach. In non-adaptive approach, ANN is trained by using the actual data from the system to be forecasted. Throughout training, the ANN will update its parameters according to the training data. Once the ANN  reaches optimum condition, the training process is stopped.

Then the optimized ANN will be used to estimate the forthcoming output based on the current received inputs.

The main drawback of non-adaptive approach is that the ANN parameters need to be re-estimated from time to time.

This is essential in order to sustain the forecaster?s reliability especially if the system to be forecasted is non- stationary and displays different pattern over times. The problem is how to determine when the retraining should be conducted: before or after the forecaster produces unacceptable error?  To solve this, the adaptive learning approach is proposed. In adaptive approach, a continuous learning is imposed, meaning that the ANN is constantly adjusting its parameters based on the recent input and output. Therefore the forecaster is always been supplied with the current information of the system to be forecasted without the need for retraining.

This paper compares the performance of adaptive and non-adaptive learning approaches of HRBF neural network on two time series data: Mackey Glass and Set A Data from Santa Fe Competition. This paper is organized as follows. A brief description about the Hybrid Radial Basis Function (HRBF) neural network and the learning algorithms used for training are given in Section II. Section II also describes the time series data and the evaluation tests used to measure the performance of the HRBF forecaster. The results and discussion were presented in Section III. Section IV concludes the findings.



II. APPROACH AND METHODS The HRBF Neural Network is a modification of the  Radial Basis Function (RBF) [8]. It differs from the RBF by the linear connections that exist between input nodes and output nodes. Similarly to RBF, the HRBF neural network has three layers: an input layer, a hidden layer with a non- linear RBF activation function and a linear output layer.

Each layer has its own nodes where the nodes in input layer are connected to the nodes in hidden layer and nodes in hidden layer are connected to the nodes in output layer via linear weight. There are two parameters: the HRBF centres in hidden nodes and weights between the hidden nodes and   DOI 10.1109/ICCRD.2010.177     the output nodes, that must be updated during training to produce the optimize network. Two algorithms: Adaptive Fuzzy C-Means Clustering (AFCMC) and Exponential Weighted Recursive Least Square (e-WRLS) are used to update the centre and weight of the HRBF neural network.

The AFCMC algorithm is a modification of Fuzzy C-Means Clustering Algorithm to overcome the dead centre, local minima and centre redundancy: common problem in the Fuzzy C-Means Clustering Algorithm [9]. To estimate the weight between the hidden nodes and output node, the Exponential Weighted Recursive Least Square (e-WRLS) is used [10].

To compare the forecasting performance of adaptive and  non-adaptive approaches, two HRBF networks are constructed using Borland C++ Builder 6. The adaptive approach is constructed in such a way employs online learning whereas the non-adaptive approach employs offline learning. The multiple steps ahead (MSA) forecasting were attained by using iterative technique. In iterative technique, the network forecasts one step ahead (OSA), and then uses that forecast to forecast another step ahead, and so on. For example, consider an ANN receives input vectors m(t=1), m(t=2), m(t=3) and m(t=4), and produces OSA forecasting at m(t=5). The MSA prediction at t=6, is achieved by feeding the OSA forecasting at m(t=5) as input to the ANN while removing the output m(t=1) from the input vector.

Similarly, to obtain the MSA forecasting at t=7, the forecasted output at t=6 will be used as input to the ANN while removing the oldest data from the input vector that is m(t=2). This procedures is repeats to obtain the MSA forecasting for t=8, 9,10 and so on.

A. Data The forecasting performance of the RBF trained with  two algorithms described above is evaluated by using two time series: Mackey-Glass nonlinear time series and Set A Data from the Santa Fe Competition. The forecasting based on time series produced by the Mackey-Glass equation is regarded as a criterion for comparing the ability of different predicting method and is used in many time series forecasting researches [11], [12]. The Mackey-Glass equation is a time-delayed differential equation proposed as a model of white blood cell production by Mackey and Glass. The Mackey-Glass equation is given by:  10 (1 )1 ( ) t s  t t s t s  x x x  x (1)  Where ? = 0.2, ? = 0.1, and s is delayed time. In this research, s is set to 17 in which the equation exhibits chaotic behavior with a fractal dimension. A total of 1000 data were used and display in Fig. 1. The Set A Data from the Santa Fe Competition were recorded from a Far-Infrared-Laser in a chaotic state. These data were chosen because they are a good example of the complicated behavior that can be seen in a clean, stationary, low-dimensional non-trivial physical  system for which the underlying governing equations dynamics are well understood. The Set A Data from the Santa Fe Competition are displayed in Fig. 2.

B. Evaluation Tests The Root Mean Square Error (RMSE) and Coefficients  of Determination (R2) are used as measurement of derivation between actual and forecasted values. The R2 value denotes the close degree between actual and forecasted value and are varies, which 1 indicates that the predicted data and the actual data are identical. The RMSE and R2 tests are defined in the following respectively:   21 ?( ( ) ( )) d  a  n  t n  RMSE y t y t n  (2)         ?( ( ) ( )) 1 [ ]  ( ( ) )  d  a  d  a  n  t n n  t n  y t y t R  y t y (3)     where na  and nd  are the first and the last measurement data, n is the number of data used in the measurement: n = (nd - na+1) , y(t) and (t) are actual and forecasted value at time t and y  is the average actual value, respectively.

Figure 1. Mackey Glass Data               Figure 2.  Set A Data from Santa Fe Competition

III. RESULTS AND DISCUSSIONS For the reason that the selection of input lag and the  number of HRBF center have strong impact on the forecaster performance, the forecaster undergoes two analyses, first to determine the best input lag and second to determine the correct number of HRBF center. The analysis to determine the best input lags for all data is conducted by fixing the HRBF centers at 10 and varies the input lag from (t-1) to (t- 1)(t-2)(t-3)?(t-x) where the maximum number of x is 10% out of the total available data. The input lags which produces the highest R2 values for all steps ahead then undergoes the analysis to determine the best number of HRBF center. This analysis is conducted by increasing the number of HRBF center one by one until it reaches 10% out of the total available data. For each approach, the structure that produces the best forecasting performance (lowest RMSE values and highest R2 values) for all steps ahead forecasting is selected as the best structure. From these analyses, the Mackey Glass data requires (t-1)(t-2)(t-3)?(t-40)(t-41)(t-42) and 22 centres while SantaFe data requires (t-1)(t-2)(t-3)?(t-14)(t-15)(t-16) and 10 centres.

The purpose of the experiments in this study is to  compare the performance of adaptive and non-adaptive approaches in multiple steps ahead forecasting. Therefore both approaches are set to produce up to 25 steps ahead forecasting. The analysis began by setting the HRBF with the best input lags and centre obtained in the optimization analysis before. For adaptive learning, as the new data available, the HRBF was allowed to update its parameters.

At the same time it uses the updated parameters together with the recent input data to generate forecasting output.

Slightly different, for non-adaptive learning, the data were divided into two parts: 500 for training and another 500 for testing. The HRBF was trained using the training data repeatedly and the training is stop when it produces the optimum performance. The optimized HRBF then was used to forecast the 500 testing data by using the parameters obtained during training and the recent input data.

To examine the performance of adaptive and non- adaptive approaches, the MSE and R2 measurements of the real and forecasted data from 501 to 900 (400 data) were conducted.  Table 1 shows the MSE and R2 obtained by both approaches on Mackey Glass and Set A Data. It can be said that for both data, the performance of adaptive approach is comparable or superior to compare with non-adaptive approach for all steps ahead forecasting. Particularly in long distance forecasting (10 steps ahead onwards) the adaptive approach shows better performance. The MSE plots in Fig. 3 supports these observations, in which when the forecasting distance increases, significant different in MSE reading between adaptive and non-adaptive approaches for both data were recorded which MSE values obtained by adaptive approach are smaller.

By taking 0.6 as the lowest acceptable R2 value, we can  conclude that both adaptive and non-adaptive approaches are able to perform good forecasting for all 25 steps ahead for Mackey Glass data. However for Set A Data, both approaches can only perform up to 5 steps ahead forecasting.

Fig. 4 displays the actual and forecasted values for 1, 5, 10, 15, 20 and 25 steps ahead forecasting on 500 Mackey Glass Data. Fig. 5 displays the actual and forecasted values for 1 and 5 steps ahead forecasting on 500 Set A Data from Santa- Fe Competition.



IV. CONCLUSION This paper compares the performance of adaptive  learning and non-adaptive learning of HRBF neural network in multiple steps ahead time series forecasting. The analyses on two time series data: Mackey Glass and Set A Data from Santa-Fe competition show that the adaptive approach outperform the non-adaptive approach especially in long distance forecasting. Besides that, the continuous learning of the adaptive approach produces a forecaster which has the recent information on the system to be forecasted. This will make the adaptive forecaster be implemented in real live easily without the need to retraining.

