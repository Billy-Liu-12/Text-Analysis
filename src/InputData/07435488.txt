A new closed frequent itemsets mining algorithm  based on GPU

Abstract?Vertical data format is an important structure in  closed frequent itemsets mining. All closed frequent itemsets can be found by simply using the operations of ?and? and ?or?. But it consumes huge amount of storage space, especially in the case of large size data set. This paper proposed an algorithm for mining closed frequent itemsets based on a new data structure deriving from the vertical format. This new data structure can contribute to save storage space by using a multi-layer index. When dealing with large data sets with the acceleration of GPU, this algorithm can obtain a high speed. Our experimental results show that our algorithm uses much less computation time than other similar methods.

Keywords?data mining, closed frequent item sets, vertical data structure, GPU

I. INTRODUCTION Closed frequent item sets mining is an important part of  frequent item sets mining, which can compact the data size[1][2] without any loss of information since closed frequent item sets contain frequencies of all the frequent itemsets. The methods for mining closed frequent itemsets can be classified into three categories: Apriori based[3], FP based[4][5][6] and vertical data format based[7][8] algorithms. In order to accelerate the speed, parallel and distributed technology was introduced to the data mining field [9][10]. One of the famous distributed environments is the cloud computing [11].

GPU was originally used to accelerate the image processing. It contains multiple processing units and can handle several data sets in parallel. Hong Tao Bai et al.[12] presented an algorithm named CG for mining closed frequent itemsets on GPU.  The algorithm maps data to bit vectors, and uses the index tree to organize the vertical data sets. CG stores indexes in the main memory so as to accelerate the speed of searching the index tree. But the index tree just indexes the data items, and the length of bit vector of each item set is fixed. George Teodoro et al.[13] proposed an algorithm for mining closed frequent item sets based on GPU and Multi- core CPU. The algorithm changes the data set into a multilevel projecting tree and then builds a node matrix for each level.

This paper proposes an algorithm for mining closed frequent item sets based on MFCIBD[8] algorithm. The algorithm can handle both density and sparse data sets in the  platforms including GPU and CPU. Our experimental results show that our algorithm uses much less computation time than other similar methods.



II. CONCEPTS AND DEFINITIONS  A. closed frequent item sets Let I={item1, item2,?,itemn} be the set of items, and  D={t1,t2,?,tm} be a database consisting of m transactions, where ti (i=1,2,?,m) is a subset of I. Suppose X is a subset of I, the support count of X, which is denoted as supcount(X), is defined as the number of item sets in D that contain X,. The support rate of X is the ratio of support count of X to the number of item sets in D. The goal of closed frequent item sets mining is to find all the subsets whose support rate is larger than a user defined threshold (minsup).

Closed frequent item sets are a special kind of frequent itemsets which contain all the information of all frequent item sets using much less memory space [1].  To define the closed frequent item sets, the following two functions f (X) and g(X) are used.

Let Ii ? DT ? and Ii ? then f(T};)={ tiTtIi ???? ,| }. Let DT ? and IX ? , then g(X)={ Dt ? | tiXi ??? , }.

B. Vertical data format Originally, a data set of transactions is shown in Table 1.

Table 2 is an example of vertical data format, where each entry is in {Item, Tlist} format. Here, Item is the item name, and Tlist is a binary vector which indicates the set of transactions containing the item. Suppose there are n transactions in the data base, Tlist consists of n bits. If the item is included in the kth transaction, the kth bit of Tlist is equal to 1.

TABLE I.  SAMPLE DATA BASE  Tid Item set Tid Item set Tid Item set 1 B,C,H 4 A,C 7 A,B,E,D 2 C,D,G,F 5 B,G,F 8 A,E 3 B,C,D,E 6 A,B,C,H 9 A,D,E,F   DOI 10.1109/CBD.2015.54    DOI 10.1109/CBD.2015.54     TABLE II.  VERTICAL DATA STRUCTURE  Item  Tlist Item  Tlist A:5 000101111 E:3 000000111 B:5 101011100 F:2 010010001 C:5 111101000 G:2 010010000 D:4 011000101 H:2 100001000  In the vertical data structure, length of each bit vector is equal to the number of transactions in the data base. Huge amount of storage space will be required when size of the database is very large. To overcome this shortcoming, we propose a new data structure to partition large data base.

C. GPU and OpenCL GPU is a special device used to process images. Because  its capability of parallel processing, now it is widely used in the field of high performance computing.

CUDA and OpenCL are the two popular GPU programming languages. OpenCL has the merit of CUDA and what?s more it is open to all the devices it supports, including Intel, AMD and even some DSP. With another open project- MPI[14][15],  OpenCL has become a popular program language in parallel and distributed computing.



III. MULTI-LEVEL VERTICAL DATA STRUCTURE In this section, we present a new data structure named  multi layer vertical (MLV) data structure based on the vertical data format.

A. The organization of multi vertical data structure Multi layer vertical dataset (MLV) divides vertical data  into several layers, and each layer is a table of indexes of the next layer.

Definition 3 (Bit vector group)  A fixed length of bits is called the bit vector, denoted by Bits(n), n is the length of bit vectors. Several bit vectors form a bit vector group.

Definition 4 (Transaction group) Let D be a transaction database, the number of transactions is denoted as |D|. Let g be a positive integer. We partition the transactions in D into [|D|/g] groups, here [x] is the ceiling function of x. Obviously, each group consists of From the first transaction, every g transactions.

We define the operation roof(a/b) as the smallest integer larger than a/b, namely roof(a/b) =[a/b]+1 where [a/b] is the integral part of a/b.

MLV can completely represent the vertical data structure. In vertical data structure each item has a bit vector of length |D|. But in MLV the length of each bit vector is not fixed, it depends on the number of transactions containing this item.

There are several bit vector groups in MLV, each group is also called a layer. Every bit vectors in a group has the same length, but different groups may have different number of bit vectors. Suppose there are k layer in a MLV, the length of bit vectors in the i-th layer is written as len(i), 1<i<k. Suppose there are G(i) bit vectors in the i-th layer, let BV(j,i) be the first j bit vectors in the i-th layer, 1 ( )j G i? ?  , count_G(i) be the number of ?1? bits in all the G(i) bit vectors,  count(BV(j,i)) be the number of ?1? bits in BV(j,i), then  count_G(i)= ( )   ( (j, i)) G i  j count BV  = ? .

Character 1: In the MLV with k layers, the first layer has only one  bit vector. In the following layer, the number of bit vectors is the number of ?1? bits in all the bit vectors in its previous layer, namely, G(1)=1,G(i)=count_G(i-1), 2 i k? ? .

Character 2: The support of each item is the number of ?1? bits of all bit vectors in the k-th layer, i.e.

supcount({item})=count_G(k), item I? .

The bit vector in the first layer is called the root bit vector. Each item has one or more layer of bit vectors. Those bit vectors illustrate the transactions containing item. MLV divides the transactions into different groups in the layers. In the first layer, the transactions in database is divided into [|D|/len(1)] groups. In the following layer, the number of bit vectors is the number of ?1? bits in all the bit vectors in its previous layer.

Theorem 1: Suppose a MLV has k layers, the length of bit vectors in the i-th layer is len(i) leni, 1<i<k, then this MLV  can represent at most  ( ) k  i len i  = ?  transactions.

Proof: Since for each item, supcount({item})=count_G(k), then the total number of bits in the last layer of MLV is the maximum support for the item.

Since in each layer, the number of bit vectors is the number of ?1? bits in all the bit vectors in its previous layer, namely, G(i)=count_G(i-1), 2 i k? ? , the maximum number of bits in the last layer is ( ) _G(k 1)len k count? ? . Similarly, for the other layers except the first one, the maximum number of bits is (i) _G(i 1)len count? ? , 2 i k? ? . Therefore, the maximum number of bits in the k-th layer is  count_G(k)= ( ) _G(k 1)len k count? ? = ( ) ( 1) _ ( 2)len k len k count G k? ? ? ? =?.. =  ( )  k  i len i  = ?   Q.E.D  Therefore, this MLV can represent at most  ( ) k  i len i  = ?  transactions.

B. Constructing the MLV MLV is a projection of the original transaction database.

For each item, length of its MLV is not fixed, the more frequently this item appears, the longer its MLV is. In this paper, we present an algorithm to build the MLV of all the items by only once scan on the database.

Most of the closed frequent item sets mining algorithms require multiple times of scans on the database, this shortcoming limits the use of these algorithms. The vertical data format will waste large storage space when handling sparse database. For instance, suppose there are 250 thousand transactions in database D, an item xD appears only in one transaction in D, therefore item x requires 250 thousand bits     (roughly 30Kb) inx vertical data format. Suppose we use an MLV with three layers, and length of bit vector in each layer is 64, then item x requires only 64+64+64=192 bits  Scanning the database once can get the MLV for all the items. The MLV obtained may be different with a different scanning order on the transactions. But the scanning order on the transactions does not affect the accuracy of the result if the transactions are completely scanned. The following theorem shows how to select the bit to be updated.

Theorem2: Let  Integer n, a and x are integers. Suppose n can be divided by a, and r is the residue of x divided by n (r<n). Then the residue of x divided by a is equal to that of r divided by a, i.e. mod(x ,a)=mod(r ,a).

Proof:  Let n=a.b, a and b are integers, and 1<b<n.. Since r is the residue of x divided by n, there exists an integer m such that x=m.n+r=m.a.b+r. Therefore we have,  mod(x, a)=mod(m.a.b+r, a)=mod(r, a) Q.E.D  Framework of the algorithm for constructing the MLV is  as shown in Algorithm 1.

Algorithm 1: build_MLV Input:  D: Trasaction databaseD, minsup: The shreshold; k, :  number of the layers in MLV: len[i]: the length of bit vectors in layer i, (i=1,2,?,k);  Output: MLV: BEGIN Int product=1; FOR i=2 to k do  Product=product*len[i] END For each transaction in D do  Product1=product; Tid=transaction id  END For each item in transaction do  For j=1 to k-1 do In the last bit vector of level j  If bit in roof(tid/product1)= = 1 then Product1=product1/len[j] ; Continue;  Else Add a new bit vector in level j+1 Set bit in roof(tid/product1)=1 Product1=product1/len[j]  End if End for  End for In level k, set the mod(tid/len[k])-th bit in last bit vector tid/lenk as 1; For each item in D do  If count_G(k)<minsup then Delete the item END END FOR  End Taking the data set in Table 1 as an example, the final MLV constructed is shown in Fig1.



IV. THE CLOSED FREQUENT ITEM SETS MINING ALGORITHM ON GPU  Based on MLV structure, we propose an algorithm MVCG (Multi level Vertical frequent Closed item sets mining on GPU) for mining closed frequent item sets.

Let the number of ?1? bits in the j-th layer be count_G(j), then the support count of this item has a limitation of   _ ( j) ( ) k  i j c o u n t G le n i  = +  ? ?  accord to theorem 1 and the characters of MLV. Therefore we calculate   _ ( j) ( ) k  i j c o u n t G le n i  = +  ? ?  at each layer, if the result is less than the minimal support then delete it from the candidate sets immediately. In order to accelerate the speed, the minimal number of each layer can be calculated beforehand and stored in an array.

To accelerate the processing speed, our algorithm can be implemented on GPU since it has much more logical processing units and higher speed than CPU. Since operations on bit vectors has low data dependencies, our algorithm MVCG can be parallelized and implemented on GPU efficiently without much overhead of communication between processors.

Our algorithm MVCG is based on a directed item set graph (DISG) [8] which is expressed by the vertical data format. In DISG, each node represents a data item. If support of the item set composed by two items is larger than the minimal support, then there will be a directed edge form the node of item with a larger support to the other one. We map the bit vectors to GPU memory and then use the bit operations to detect the candidate closed frequent item sets.

The algorithm MVCG is based on the depth first strategy.

MVCG is as shown in Algorithm 2.

Algorithm 2: MVCG Input:  DSIG, : the directed item set graph; minsup: The shreshold; k:  number of the layers in MLV ; len[i]: the length of bit vectors in layer i, (i=1,2,?,k)  Output: FCI  closed frequent item sets  BEGIN FCI=NULL;candidate=null; FOR EACH connected sub-graph in DSIG Item_node= the first node in the connected sub-graph ADD {item_node} to  candidate; IF (find_GUP()) load_to_GPUmemory(candidate);  End IF While candidate is not empty TestC=last item set in candidate; IF (last vector of TestC has no adjacent vector) Add TestC to FCI; ELSE isfc=1; FOR each adjacent node of last vector of TestC vector_a= the item of the adjacent node  TestIS={vector_a}? TestC IF ( TestIS is a frequent item set) ADD TestIS to candidate; END IF IF (TestIS has the same support with TestC) Isfc=0;  END IF END FOR IF(isfc=1)  add TestC to FCI;     END IF END IF Delete TestC form candidate; END WHILE END FOR Return FCI; END BEGIN

V. EXPERIMENTAL RESULTS AND ANALYSIS To test the effectiveness and performance of our proposed  algorithm MVCG, we test it by a series of experiments on data sets generated by the IBM data generator[16]. Two datasets are generated, their sizes are listed in Table 3. All the experiments were carried out on a PC with 32GM memory, Intel i7 CPU, WINDOWS XP operating system, and coded using VC++.

TABLE III.  TESTING DATA SET  DATA SET SIZE TRANS ITEMS LEN T1000I10 2230M 1000k 10000 40  We compared our algorithm  MVCG with CFPL[7] and MFCIBD[8].

In the fig. 1 and fig. 2, the testing dataset is a sparse data set. From fig. 1, we can see that MVCG requires less time than the other two algorithms. And MVCG is even more efficient with smaller minimal supports. From fig. 2, we can see that speed of MVCG is about 3 to 5 times faster than CG with the acceleration of GPU. The efficiency of CG decreases when dealing with large size data sets.

Fig. 1. Computation times with respect to the minimal supports for testing dataset                 Fig. 2.  Computation times on GPU with respect to the minimal supports for testing dataset

VI. CONCLUSION An algorithm MVCG for detecting the closed frequent  item sets is presented. MVCG algorithm uses new data structure deriving from the vertical format. In the algorithm, variable length bit vectors are used to represent the items. This new data structure can contribute to save storage space by using a multi-layer index. When dealing with large data sets with the acceleration of GPU, this algorithm can obtain a high speed, especially on large size sparse data sets. Our experimental results show that our algorithm uses much less computation time than other similar methods.

