Ordered Segment for Classification of Big Data

Abstract?This paper presents a new, simple, and efficient data structure, namely, the o  ? rdered s  ? egment (OS): a mono dimensional  string array that we have been using in our classification of big data. The essential idea in construction of OS is to make use of the redundancies that abound user-data. OS enables us to performs efficient retrieval, insertions and deletions of data. The theoretical and experimental observations show that the method presented is more practical than existing ones considering the use of dynamic string sets for the classifications of huge user-files.



I. INTRODUCTION  In a previous work [3], we introduced a new method that classifies the keys (i.e., strings) of large-scale user-files of the customary form: f = {(ki, vi)|i = 1, ? ? ? , n} where ki and vi denote the key and key value, respectively. The necessity of our method is dictated by the resolution of two major prob- lems: fast lookup and compact representation. Using automata we can achieve fast lookup by determinization and compact representation by minimization. For providing information for the recognized keys, one can use the transducers(i.e., automata with outputs) [8], [7]. However, we proposed a competitor to transducers that combines automata and machines learning theories. Our solution is to represent the keys in a finite- state automaton and the output values in a decision tree, respectively.

In order to explain intuitively the benefits of our classifica- tion method, we give a very simple example in the following.

Let V = {Asia,Europa} be the output (or target) values of three following countries: K = {Iran,Iraq,Ireland}. In order to determine the output values of any element of K one can learn the decision tree based on the mutual information; if the key (of K) ends by ?n/q? then retrieve ?Asia? else ?Europa?.

The contributions of this paper is the amelioration of our introduced method, i.e.,(1) Optimization of the size of the data structures of the classifier, and (2) Time-Reduction of the classifer.

Example 1: Let us consider profit as the target attribute of the Left-Table of Figure 1. A decision tree corresponding to this dataset, shown by way of three If-Then rules, has 4 leaf nodes, where, the set of the leaf nodes (i.e., {up,down}) has 6 characters, whereas their storage in a decision tree costs 12 characters. Consequently, there is room to gain 50% of the amount of space for storing these nodes.

Fig. 1. First table: The profit trends of 10 slow-and-fast foods. Second table: The counterpart of the first one i.e. each key is made up by the concatenation of the first characters of three first strings of its corresponding row in the left table.

Age CPa Type Profit old no CK down midlife yes CK down midlife no HB up old no HB down new no HB up new no CK up midlife no CK up new yes CK up midlife yes HB down old yes CK down  Key Profit onC down myC down mnH up onH down nnH up nnC up mnC up nyC up myH down oyC down  aCP (Competition), HB (hamburger) and CK (Chelo?Kabab: Irano-Azeri hum).

Fig. 2. A (6,10)-automaton for recognizing the keys of the second table, along with the decision rules of these two tables.

4 5  m  n  o  n  y  n  y  H  C  C  If (Key=?new?) OR (Key[1]=?o?) Then Profit = ?up? If (Key =?midlife?) OR (Key[1]=?m?)Then If (key = ?yes?) OR (Key[2]=?y?) Then Profit = ?down? Else Profit = ?up? If (Key=?old?) OR (Key[1]=?o?)Then Profit = ?down?  The rest of this paper is devoted to OS and its impact in performing above contributions. Section 2 presents the preliminary considerations The ordered segment is introduced in Section 3. Using the ordered segment in both preprocessing and processing of the classification is illustrated in Section 4.

Evaluation and experiments are outlined in Section 5.



II. PRELIMINARY CONSIDERATIONS  We assume that the reader to be familiar with the theory of finite automata as presented in standard books, e.g., [5], [10].

A string is a sequence of zero or more symbols from an alphabet ?. In this paper, we use string, word, and key interchangeably. The set of all strings over ? is denoted by ??.

The length of a string x is denoted by |x|. The empty string, the string of length zero is denoted by ?. The ith symbol of a string x is denoted by x[i]. A string w is a suffix of x if x = uyw, for w ? ??.

DOI 10.1109/ICMLA.2013.54    DOI 10.1109/ICMLA.2013.54    DOI 10.1109/ICMLA.2013.54    DOI 10.1109/ICMLA.2013.54     To avoid confusion between keys like ?be? and ?bee?, let us add a special end-marker symbol, ?#?, to the end of all keys, so no prefix of a key can be a key itself.

An acyclic finite-state automaton is a graph of the form g = (Q,?, ?, q0, F ) where Q is a finite set of states, ? is the alphabet, q0 is the start state, F ? Q is the accepting states. ? is a partial mapping ? : Q ? ? ?? Q denoting transition. If a ? ?, the notation ?(q, a) = ? is used to mean that ?(q, a) is undefined. Let ?? denotes the set containing all strings over ? including zero-length string, called the empty string ?. The extension of the partial ? mapping with x ? ?? is a function ?? : Q ? ?? ?? Q and defined as follows:  ??(q, ?) = q  ??(q, ax) = {  ??(?(q, a), x) if ?(q, a) ?= ? ? otherwise.

A finite automaton is said to be (n,m)?automaton if |Q| = n and |E| = m where E denotes the set of the edges (transitions) of g.

The property ?? allows fast retrieval for variable-length strings and quick unsuccessful search determination. The pessimistic time complexity of ?? is O(n) w.r.t. a string of length n.

We distinguish two types of records of the user-file: good and no-good, w.r.t. the classification. A good record (GR) has at least one non-null string which is not preceded by the commentary symbol. Below is an example of three GRs, along with % as the default commentary symbol.

aime C01 % The first singular person of the % present tense of the indicative mode.

aimes C02 % The second singular ...

aime C03 % The third singular ...

Same key with different key-values may be scattered in user-file. If any, such key is called the synonymous key, as the word ?aime? in the above records. The preprocessing phase of our work, in addition to other tasks described below, will be in charge to collect the different key-values of the synonymous keys into the new key values e.g., C01|C03, where | ?? ? denotes the delimiter symbol.

In this paper, we will only deal the input files of two fields, namely above f . Note that this is not a restriction, because the generalization of our method is straightforward i.e. Let fu = {(ki, vi,1 ? ? ? vi,m : i = 1 ? ? ? p} be the input. If learning with respect to a particular field (say j) is requested, proceeds as follows for all records of fu. First, forms the new keys (nks) as follows: {nki = ki,1| ? ? ? |ki,m?1 : i ?= j}. Then report the pair of (nki, vi,j) into f .

Example 2: Letting ?Profit? the target attribute of Second-Table of Figure 1, the first pair of f is (?old|no|CK?, ?down?).



III. ORDERED SEGMENT  A segment is either one string or the concatenation of the strings of the same length (say q). A segment with q as its representative length will interchangeably be denoted by q- segment and Sqi , where i stands for ith segment inserted into OS.

An ordered segment (OS) is either one q-segment or the concatenation (denoted by  ? ) of m? q-segments preserving  TABLE I. THE LENGTH (FIRST ROW) AND THE NUMBER (SECOND ROW) OF THE SUFFIXES OF THE FRENCH?S VERBS.

1 2 3 4 5 6 7 8 9 10 11 12 13 14 1 9 39 166 312 294 205 108 63 14 6 3 2 1  the total order w.r.t. q i.e.,  OS = m?? i=1  S j i for j = m1 < m2 < . . . < m  ?.

For implementation reason, OS is initialized by the end-marker symbol i.e., OS[0] = ?#?. However, if the empty string is inserted into OS, 1-segment is asserted by OS[1] = ?#?. Let BS denotes a bit-string of size ?m  ?  ? asserting the existence of  the segments of OS. It is defined as follows: When Sji exists in OS BS[j] = 1.

We write SP to refer to the set of the start positions of the segments in OS. We say that an input-string z of length q occurs in OS (noted by z ? OS) if ? a q-segment (i.e., BS[q] = 1) and z must be a suffix of q-segment.

Example 1: Let OS = ##nt#ument#ision#ession#iration# containing five q-segments (i.e., q= 1, 3, 6, 7, 8). Only 6- segment has two suffixes. Others have just one suffix. The values of BS and SP are ?010100111? and {1, 2, 5, 11, 24}, respectively.

The order relation of OS allows us to prepare an ef- ficient search function called Search(z) for knowing if z ? OS or not. This is done using another prepared function LocalSearch (LS) for knowing if z is a string of a segment of OS or not. Let start and end stand for the start and end positions of a segment of OS. We write nz = end?startq to refer to the number of the strings in a segment. The function LocalSearch(z,start,end,q) returns the triple (p,nz , tag). The value of tag is true/false. The true value means that p is the location at which z occurs. If tag=false, p will be used for the insertion of a z into OS. If tag=false and if nz = 1, the function CreateSegment is invoked for the creation of a new segment. LocalSearch performs at most nz string comparisons between z and any string of Sqi .

Example 2: Let z = ?ument#?. z ? OS i.e., ?S6 =  ?ument#ision#?. Suppose z (=sion#). z ?? OS since BS[5] = 0. On the contrary for asserting z(= jsion#) ?? OS, we need to detect two mismatches. The first one is done via (z[i=0]=?j?) ?= (w[0]=?u?). Because of this mismatch q ? i = 6-0 = 6, six characters are skipped for reaching the second suffix for examination. This time mismatch occurs, too.

In view of above discussions, we claim that LocalSearch works correctly. The trade-off between the search time and the space cost of LocalSearch is reasonable: In our exper- iments, we didn?t find nz dramatically big compared to the size of the set of keys.

Example 3: For the set of French?s verbs (of 212,115 keys with 12.5 as the average length), Table I shows that max(nz) = 312 for |z| = 5.

Now, we are ready to define Search(z) which is only used in the insertion mode of our work. Let c stands for the number of x-segments of OS where x <= q(= |z|) i.e., the     number of 1-bits of BS until and including q. Letting POS = |OS|, Search(z) is defined as follows:??????  ?????  (1, 1, true) if ((q = 1) ? (OS[1]= ?#?) (1, 0, false) if (q = 1) ? (POS = 1)) (POS, nz, false) if q > m? (SP [c], 0, false) if BS[q] = 0 LS(z, SP [m ? 1], POS, q) if q = m? LS(z, SP [c ? 1], SP [c], q) otherwise  .

Lemma1: Search(z) works correctly.

Justification: The correctness is based on four cases.

1) q = 1, z must be ?#?. Recall that the end-marker symbol is added to the end of every key. So 1 is its right place in OS. If OS[1] ?= ?#?, then there is a need (indicated by tag= true) to create 1-segment. If not, tag=true is returned.

2) q > m? means that z is new string (tag = false). So its q-segment has to be created along with the insertion of z at available position of OS, namely POS.

3) BS[q] = 0 means that a new segment must be created, too. It remains to find its right place for preserving the total order. This is done by setting p = SP [c] e.g. z = ?nts#?, c = 2, SP [2] = 5.

4) q-segment already exists in OS. If q = m?, then start = SP [m ? 1] and end = POS. If not i.e., 1 < q < m?, then start = SP [c ? 1] and end = SP [c]. In both cases, LocalSearch returns the desired triple.

If we neglect the marginal space and time costs for select- ing the start position of Sqi , it follows that:  Lemma2: The pessimistic time complexity of Search(z) is ?(nz ? q) < O(q + POS) i.e., less than the time cost of KMP (Knuth-Morris-Prat)?s method [12].



IV. USING OS  The ordered segment is used in both preprocessing and processing of the string classification. The preprocessing is composed of five principal modes: (1) Insertion, (2) Deletion, (3) Retrieval, (4) and (5) Saving/Restoring the data structures to/from file. In the two above first modes, the acquisition of new key-values is performed for determining the data structures including the following ingredients: (1) ?: The length of the longest key , (2) OS constructed incrementally, and (3) a hash table of the keys of the cleaned file (say f.c), where each key is associated with numerical value ranging from 1 to |OS| indicating the places of the key-values (including the new ones) in OS.

The constitution of f.c is performed in two steps. In step1, user-file, f is read along with preliminary tasks: (1) removing the blank records, (2) attribution of unknown symbol, namely, ??? for those keys of with no associated key values. So, we can determine the number of the good records. This number is used as the maximum size of the hash table of the second step in charge of the acquisition of the new key values. So, we will not to face with the processing of dynamic hash table.

The second step is based on the refinement process which works as follows. Given two key values of v1 and v2, both associated with same key of f , if v1 and/or v2 contains at least  one delimiter-character (defined by user, the default value is |), we speak out the set of key values, presented in our work by the long string. The new key value (v) is obtained according to one of the four following cases which also allows us not collect the repeated keys of the synonymous, identical records of f into cf .

1) If v1 = String and v2 = String, then if v1 = v2 then v = v1 else v = Sort1(v1, v2)  2) If v1 = Set and v2 = String, then if v2 ? v1 then v = v2 else Sort2(v1,v2).

3) If v1 = String and v2 = Set, then if v1 ? v2 then v = v1 else sort2(v2,v1).

4) If v1 = Set and v2 = Set, then v = v1 or Sort3(Union(v1, v2)) depending on v1 = v2 or not.

Sort1 is based on the comparison of two strings. In per- forming Sort3, first a long string corresponding to the union of v1, v2 is calculated. Then the strings of this long string is reported into a table (say TVC). At the end sorting is performed by the built-in function qsort, more precisely, this task is performed by qsort(TVC, n, sizeof(char *), cmpstringp), where n is the number of strings stored in TVC. For Sort2, first the string of the first argument is stored into TVC, Then the string of the second argument. Finally, sorting by qsort is performed. In doing so, the new values is collected in the lexicographical order. Hence, the cost of set-equality of above case 4 is the cost of the string comparison.

Example 3: Add the pair (onC, almost down) to Second-Table of Figure 1. So, a unique ambiguity class ?almost down| down? must be assigned to key ?onC?. Now the number of good record is 10.

In the machine learning community, instead of acquiring a new value (e.g. above ?down|almost down?) so-called ?majority vote? (i.e. only the most common value is selected [11]). This vote has a drawback: it leads to lose other values which is not acceptable in our work as in some areas (e.g. medical, natural language processing).

In the processing phase, the ordered segment is used in (1) the leaf nodes of the decision trees and (2) in the calculation of the entropy. As for (2) since the total entropy of an attribute, with respect to a target attribute (e.g., ?up? or ?down?) is a weighted sum of the conditioned entropies; given all possible values of the attribute (which must be calculated efficiently.

This is done by OS). As for (1) the following example illustrates the benefit of OS in reducing the size of the decision tree.

Example 4: Figure 3 shows the decision tree of the second table of figure 1, where the numbers of the leaf nodes indicate the locations of the target values in OS = #up#down#.



V. EVALUATIONS AND APPLICATIONS  Our method has been written in the C language. We used the following inputs: (1) French irregular infinitive verbs, (2) French inflectional verbs, (3) French geographical data, (4) Nationality words in English, and (5) Brown lexicon in     1 : omn  0 : 4 2 : yn 0 : 1  0 : 4 0 : 1  o m  n  y n  Fig. 3. The decision tree of the second table of Fig. 1. the numbers 1 and 4 of the leaf nodes indicate the locations of the target values in OS = #up#down#.

English.

Input 1: French irregular infinitive verbs  French linguists divided the French infinitive verbs of the third group (fv3 - irregular ones) into 60 classes ranging from 23 to 82 [1]. Suppose, we are interested in determining the class- number of any verb of fv3. An obvious solution is to use the longest common suffix of each class established by linguists.

For instance, one can say that, if a verb (of fv3) ends in ?- e?tir? then the key-value is 26, and so on. But, our classification beats such ?onerous? classification by providing a cheap one: If the fourth character from right-to-left (b4) of a recognized verb is ?e?? then the output value is 26. Another path?solution is (b4 e? b6 q kv 24) meaning that if b4=?e?? and b6=?q? then the output value is 24. Our experiment done on fv3 with 363 (p) verbs outputs a (310,652)?automaton, a decision tree of 109 leaves and a decision tree of 60 output values stored in OS.

Input 2: French inflectional verbs  We manually entered 5508 infinitive verbs from the book [1] into a file. Then we wrote a program for the generation of all conjugated forms cfs, where each cf is associated with a simple-code referring to the morpho-syntactic information corresponding to the current cf. For instance, C01 is a simple- code that stands for the first singular person of the present tense of the indicative mode. the morpho-syntactic information.

The output is another file (say fv1) of 539,784 records. Each record is composed of four fields: (1) The cf (called also inflectional verb e.g., ?ai?); (2) The simple-code (e.g., C01); (3) The infinitive form of cf (e.g., ?avoir?); and (4) The number of class of the (e.g., 01) that ranges from 01 to 82, except that of 21 that doesn?t exist [1].

The followings are examples of the composite-code obtained after the invocation of the acquisition process.

aime C01|C03|C41|C43|C63 abandonnes C02|C42|C63 abstenons C04|C64 tiens C01|C02|C63 sommes C04|C02|C42|C63  Table II shows the statistic on the size and the number of pairs of the input file (f) before and after the invocation of the acquisition process. The input file (f) is composed of 3,945,935 characters and 539,784 verbs. The acquisition  TABLE II. FIRST, THE INPUT FILE OF 539,784 ENTRIES IS REDUCED TO THAT OF 212,115 ONES. THE LATTER CONTAINS 54517 AND 157,598, COMPOSITE AND SIMPLE CODES, RESPECTIVELY. THEN, AMONG 212,115 CODES, ONLY 169 (COMPOSED OF 118 AND 51 NEW AND OLD CODES, RESPECTIVELY) ARE LEARNED FOR REPRESENTING THE LEAF NODES OF  THE DECISION TREE.

size n size? n? leaf nodes 3,945,935 539,784 3,284,026 54517+157,598 118+51  TABLE III. THE CLASSIFICATION OF 54517 COMPOSITE CODES OF FRENCH INFLECTIONAL VERBS INTO 6 CLASSES ACCORDING TO THE NUMBER OF SIMPLE CODES (NSC). TOTAL INDICATES THE NUMBER OF  COMPOSITE CODES OF A CLASS.

NSC 2 3 4 5 6 7 Total 43816 5448 50 5170 26 7  process reduces f to another file of 3,284,026 characters. In the new file, the total number composite and simple codes are 157,598 and 212,115 respectively. From 212,115 codes, only 169 ones are stored into Info-array. 169 learned codes is composed of 118 composed and 51 simple codes, respectively.

Table III shows the information on the classification of 54517 composite codes of French inflectional verbs into 6 classes according to the number of simple codes (NSC), where Total indicates the number of composite codes of a class.

Input 3: French geographical data  The departments of France are administrative divisions. The 100 French departments are grouped into 22 metropolitan and four overseas regions. This input file includes 38198 locality- names (e.g., Paris), each of which is associated with a simple numeric code indicating the department (e.g., 75). Despite the simplicity of the contents of this input, in addition to the representation of 38198 locality-names, and their codes, there is still room to perform the space-optimization due to the acquisition of the new data for learning the decision tree.

Table IV shows the classification of composite-codes in 13 classes noted from A to M, where each class has same number of alternated department-codes.

Example 5: The first class of Table IV, namely A, has 805 keys (e.g., Abancourt), where each information corresponding to the keys is composed of only two alternated department- codes (e.g., 59|60).

Observe that, the less is the number of the alterations of the learned codes the high is the number of different locality- names. This qualitative information is a valuable ingredient of knowledge that can be used for speeding up the retrieval time  TABLE IV. ACQUISITION OF 1408 COMPOSITE CODES CORRESPONDING TO FRENCH CITY AND VILLAGES. NSC STANDS FOR  THE NUMBER OF DEPARTMENT-CODES.

NSC Total Example 2 805 Abancourt 3 279 Fours 4 98 Artigues 5 56 Vaux 6 21 Castillon 7 14 Mons 8 11 Bagneux  NSC Total Example 9 11 Montigny 10 5 Le Pin 11 3 Saint-Loup 12 2 Beaulieu 13 2 Sainte-Marie 14 1 Sainte-Colombe 15 0     TABLE V. POSSIBLE CODES ASSOCIATED WITH THE NATIONALITY  WORDS.

Abbr. Meaning Examples a adjective Azeri, Pakistani c country Azerbaijan, U.S.(A.) f people Azeris p person Austrian  Ab. Mean. Examples q a|c Lichtenstein x a|f French, English y a|p Dann, Finn z a|p|f Swiss  of the keys. This can be done by dividing the set of keys into general and exceptional subset of keys. In [4] we provided a framework that combines the default logic [6], [9] the automata theory and machine learning. In that work, the output values are represented by the decision trees. By devising a similar framework it is possible to construct two automata and two decision trees associated with two mentioned subsets.

The last class of Table IV, namely M, has only one key (i.e., Sainte-Colombe) but its learned key-value has 14 alteration values i.e.,  Sainte-Colombe 05|16|17|21|25|33|35|40| 46|50|69|76|77|89  Input 4: Nationality words  When talking about people and things from a particular coun- try, one of the following three types of words is used: (1) An adjective indicating the country, such ?Irish? in ?Irish cafe??; (2) A noun referring to a person from the country, such as, ?Irishwoman. If a dash is used, the key is treated as unknown; and (3) A noun preceded by ?the? which refers to all the people of that country, such as ?the Irish?.

Any word referring to a particular country, its injection in a term (e.g., Irish-baked, French-government-owned), or their various combinations (e.g., French-English-Scottish, Franco- Japanese) is called a nationality word.

The information corresponding to a nationality word is noun (or country name), adjective, person, people or four others shown in the Table V. In a previous work [2] done on an input of all known nationality words, the number of leaf nodes of the learned decision tree is 117 with many repetitions because only 8 output values (i.e., a,c,f,p,q,x,y,z see Table V) are necessary for being stored into OS.

Input 5: Brown lexicon This lexicon contains 61620 English words, where each of which is associated with 41 syntactic values. The acquisition process applied to this input outputs 401 new syntactic values. Table VI shows the distribution of these new values where the each of which has 7 alternative syntactic values.

436 CD|DT|JJ|NN|PDT|RB|VB 437 DT|FW|LS|NN|NNP|PRP|VB 438 DT|IN|RB|RP|UH|WDT|WP 439 FW|IN|NN|NNP|RB|RP|VBD 440 IN|JJ|NN|RB|RP|VB|VBP 441 IN|NN|NNPS|POS|PRP|VB|VBPZ 442 JJ|NN|RB|VB|VBD|VBN|VBP  TABLE VI. THE DISTRIBUTION OF 442 SYNTACTIC VALUES OF BROWN LEXICON. NSV STANDS FOR THE NUMBER OF SYNTACTIC  VALUES.

NSV 1 2 3 4 5 6 7 Total 41 119 141 82 39 13 7  It is worth to mention that according to our experiment using traditional decision tree would necessitate to represent the strings of 3887 leaf nodes, where this is reduced in our work to 442 strings of OS.



VI. CONCLUSION  The ordered segment scheme has been proposed that en- ables us to reduce the size of the data structures necessary for learning the decision trees. Since the Search function of our method is competitive, hence it is reasonable to claim that the ordered segment is also useful for the time complexity of the classification. User data-file is not necessary a dataset.

Hence, the preprocessing of our work can independently used for forming a dataset (our cleaned file f.c) along with the data structures corresponding to f.c which latter can be used in forming the automata and learning the decision trees, with better performance both from space and time requirement.

Finally, the automatic acquisition of the new key values are valuables knowledge that can be used in various applications.

