

Abstract? Data mining is the process of extracting hidden patterns from data. With the explosion of data at a tremendous  rate, data mining is essential to extract useful information.

Association rule mining is a method of finding correlation  relationships among large set of data items. A rule is  characterized as sensitive if its disclosure risk is above a certain  confidence value. Sensitive rules should not be disclosed to the  public, as they can be used to infer sensitive data and provide an  advantage for the business competitors. Techniques for hiding  association rules are limited to binary items. But, real world data  consists of quantitative values. In this paper, a method to hide  fuzzy association rule is proposed, in which, the fuzzified data is  mined using modified apriori algorithm in order to extract rules  and identify sensitive rules. The sensitive rules are hidden by  decreasing the support value of Right Hand Side (RHS) of the  rule. A framework for automated generation of membership  function is also proposed. Experimental results of the proposed  approach demonstrate efficient information hiding with  minimum side effects.

Keywords ? Association Rules; Data Mining; Fuzzy Logic;  Sensitive Rule; membership function;

I. INTRODUCTION  Data mining is the process of extracting useful knowledge from large databases. However, data mining also poses a threat to privacy and information protection if not used properly. Association rule analysis is a popular tool for discovering associations among large amount of data. Useful hidden information could be easily exposed using this kind of tool. Information privacy is essential to prevent private data from being available to others. Once private data is released, it will be impossible to prevent misuse[7]. Therefore, the protection of sensitive hidden information has become a critical issue to be resolved  Privacy preserving data mining which involves getting valid data mining results in addition to hiding sensitive information has been receiving attention in the research community. Consider the case of a health drink reseller who purchase health drink at low price from two companies, Horlicks and Complan. Reseller also grants the companies access to his customer database. Complan supplier may misuse the database to mine association rules related to the Horlicks, inferring facts like ?People who buy Milk also buy Horlicks?. Using this information Complan supplier offers a discount coupon on milk on purchase of Complan. Hence, sales on Horlicks drops steeply and Horlicks supplier will not be able to offer his promised discounts. This enables Complan to monopolize the health drink market which results in the hike of health drink prices. As a result, reseller may start losing his business. This scenario emphasis need for research on hiding sensitive knowledge.

Techniques of hiding association rules can be classified into two broad categories [5]. -- distortion based technique and blocking based technique. In distortion based technique, the data is distorted such that the support and confidence of sensitive association rules is reduced below threshold. Here threshold refers to minimum value of support and confidence below which the association rule becomes uninteresting. This technique has side effects of ?Lost Rules? and ?Ghost Rules?.

Lost Rules refers to undesirable hiding of items and association rules that are not sensitive. Ghost rules are non- genuine association rules which become part of association rules set. Distortion based technique reduces these side effects while maintaining a linear time complexity with dataset size.

This technique also poses a serious bottleneck in some specific situations like medical database where deleting a part of dataset may infer to a wrong prescription.

Blocking based technique is characterized by introducing uncertainty without distorting the database. It also suffers from side effects of lost item, lost rule and ghost rule.

Initially, rule hiding techniques proposed by Vassilios et al. [3] were distortion based algorithms and side effects of these algorithms were high. Duraiswamy et al. [4] described an algorithm called Sensitive Rule Hiding. In this algorithm sensitive rules with single antecedent and consequent were clustered. Each rule is modified to reduce its confidence.

When all sensitive association rules are hidden, clusters are converted into a modified database. This technique shows high side effects both in terms of ghost rules as well as loss of non- sensitive rules. Yuhong et al. presented FP-tree based method for inverse frequent set mining [6]. In this algorithm after extraction and pruning of frequent itemset, FP-tree is constructed, which is later converted into many versions of modified database. The strengths of this technique is its efficiency and availability of multiple versions of  modified database. Number of released databases was characterized by the number of non frequent items chosen. This technique is focused on hiding sensitive items only. Further, it has the side effect of large number of lost rules. Chih-Chia proposed novel algorithms - Frequent Hiding Sensitive Frequent Item & Frequent Hiding Sensitive Association Rule[8][9]. Each transaction in dataset was assigned a weight based on its support for a sensitive rule. All transactions in dataset are first sorted by weight in descending order. Transactions are then modified till the confidence of sensitive association rules fall below the given threshold. Most of the studies proposed concentrated on hiding association rules associated with binary items without giving importance to its quantity.

However, many transactions in real world applications have quantitative values. For a diabetes patient, the quantity of the attribute sugar in blood is more important than the presence or absence of sugar.

A New Method for Preserving Privacy in Quantitative Association Rules using  DSR Approach with Automated Generation of Membership Function  K. SathiyaPriya,          G. Sudha Sadasivam,                   N. Celin,  Dept. of CSE,          Dept. of CSE,              Dept. of CSE,  PSG College of Technology,               PSG College of Technology,       PSG College of Technology,  Coimbatore,             Coimbatore,               Coimbatore,  India -641 004            India -641 004              India -641004  sathya_jambai@yahoo.com    sudhasadhasivam@yahoo.com       n_celin@yahoo.com     Some work has been done to discover association rules from quantitative data using fuzzy set concepts. But, only limited research papers are available in the field of hiding fuzzy association rule in quantitative data. Hiding quantitative rule can be done by increasing the support of Left Hand Side (LHS) of the rule which in turn decreases the confidence of the rule[1].

Fuzzification of support and confidence framework with variable number of fuzzy membership function and decreasing the support can also be used for quantitative association rule hiding[3]. However both the approaches require the membership function to be predefined and are usually built by human experts. In absence of expertise, the membership functions cannot be accurately defined which reduces system performance[11]  This paper proposes a learning method to derive membership functions automatically. Further the paper also presents a method for preventing extraction of useful association rules from quantitative data by decreasing the support of the rule. The support of a rule A B is decreased by decreasing the support count of itemset AB which is achieved by decreasing the support value of B on Right hand Side(RHS) of the rule. This is done until either support or confidence value of the rule goes below minimum support or minimum confidence value respectively.

The rest of this paper is organized as follows. Privacy preserving fuzzy association rule hiding in quantitative data is described in Section II. Approach to derive membership function automatically is detailed in section III. The method to hide useful fuzzy association rules is described in Section IV.

Experimental results are given in Section V.



II. PROBLEM STATEMENT  An association rule is defined as an implication X Y, where both X and Y are defined as sets of attributes (interchangeably called items). Here X is called as the body (LHS) of the rule and Y is called as the head (RHS) of the rule. It is interpreted as follows: ?for a specified fraction of the existing transactions, a particular value of an attribute set X determines the value of attribute set Y as another particular value under a certain confidence?. For instance, an association rule in a supermarket basket data may be stated as, ?In  20% of the transactions, 75% of the people buying butter also buy milk in the same transaction?; 20% and 75% represent the support and the confidence, respectively. The significance of an association rule is measured by its support and confidence.

Support is the percentage of transactions that contain both X and Y and confidence is the ratio of the support of  X UY to the support of X.

Let  I ={ i1, i2, i3} be the complete item set where each ij (1 ?  j ?  m) is a quantitative attribute. Given a database  D= {t1, t2,?., tn} where each tj is a  transaction with attributes I and the fuzzy sets associated with attributes in I, our goal is to find out some interesting useful association rules.

Let X ={ x1, x2,?,xp} and Y = {y1, y2,?.., yq} be two large itemsets. Then, the fuzzy association rule is given as follows:  A?B  where A={ f1, f2,?fp} and B = {g1, g2,?.. gq} and fi    ? {the fuzzy regions related to attribute xi}  g j   ? {the fuzzy regions related to attribute yj} X and Y are subsets of I and are disjoint. A and B contain the fuzzy sets associated with the corresponding attributes in X and Y[2].

In a classical set or crisp set, the objects in a set are called elements or members of the set. An element x belonging to a  set A is defined as x ? A. A characteristic function or  membership function ?A(x) is defined as an element in the  universe U having a crisp value of 1 or 0. For every x ? U,  The membership functions for crisp set can take a value of 1or 0, the membership functions for fuzzy sets can take values in the interval [0,1]. The range between 0 and 1 is referred to as the membership grade or degree of membership. A fuzzy set A is defined as:  Where ?A(x) is a membership function belonging to the interval [0,1].  So, the problem can be stated as, ?Automatic generation of membership function for the fuzzy set, mining fuzzy association rules and hiding the sensitive association rule by decreasing the support of item on right hand side of the rule until confidence goes below minimum confidence?.



III. ALGORITHM FOR GENERATING MEMBERSHIP  FUNCTION AUTOMATICALLY  The procedure for automated generation of fuzzy membership function is detailed in this section. The data are clustered into classes. Membership functions are then generated from these classes[10][11]. The algorithm is detailed as follows:  Step 1. Consider a data set with n transactions. If the domain of all attributes is same and has limited values then for each transaction the values of all attributes are averaged and the transactions are sorted in ascending order of the average value else go to step 2.

Step 2. The difference  between adjacent values of a particular attribute in all transactions in the sorted data is determined. The difference as shown in equation (1) will provide a way to calculate the similarity between adjacent values.

The difference for a set of transactions  is:  , for i=(1,2,3, n-1),                (1) Where yi and yi+1 are adjacent values in the sorted data.

Step 3. The similarities between adjacent values are  determined using equation (2) and are mapped into real numbers between 0 and 1.

(2)  Where diffi is the difference between adjacent data, ?s is the standard deviation of diffi, and C is the control parameter and is used to determine the shape of the membership function.

Step 4. The data is then grouped according to similarities.

A threshold value, ?, divides adjacent values into classes. The number of classes determines the number of membership  iii yydiff ?= +1  ?? =  otherwise,0  ,*for *  1 si s  i  i  Cdiff C  diff  s ?  ?  ( ) ?  ? =  A.for0  A,for1  x  x xA?  ( )( ) ( ) [ ]{ }1,0,|, ??= xAxxxA AA ??  2011 World Congress on Information and Communication Technologies 149    functions. If the similarity (si) is greater than the threshold value, then the two adjacent values belong to the same class, otherwise the values are divided into different classes as represented in equation (3)  (3) where Ci and Ci+1 denote two distinct classes for the same  input or output parameter.

Step 5. Membership Function is defined for each class.

One of the simplest membership functions is the triangular membership function, and is used for the remainder of the equations. Triangular membership function for class j consists of three points, the central vertex point, bj, and the two endpoints, aj and cj. as shown in fig. 1.

Figure 1. Triangular membership function  The central vertex point for each class is determined using the formula:  \              (4)  Where j represents the j th  class, ymin, represents the first data index for this class, i.e., data yi, through yk fall into class j, and ymax,  represents the ending data index within that class.

The left and right endpoints of the membership function, aj and cj, are obtained using equation (5) and (6).

(5)  (6)  Where  is the threshold value

IV. ALGORITHM FOR HIDING SENSITIVE FUZZY  ASSOCIATION RULES  In a quantitative database, if a critical rule X Y needs to be hidden, its confidence value is decreased to a value smaller than the minimum confidence value. One way of decreasing confidence value is decreasing the support value of an item Y at RHS, and the other way is increasing the support value of item X at LHS.

Our approach decreases confidence value of a rule, by decreasing the support value of RHS item. If the value of item in RHS  is greater than 0.5 and value of item in LHS then its value is subtracted from 1. Abbreviations used in the proposed algorithm are given as follows:  D  : Initial database with n transaction data C  : Cleaned database with n transaction data F  : Fuzzified database  X  : A set of predicting items TL     : Transactions belong to a LHS item  TR     :Transactions belong to a RHS item U     :  Rule Rh     : sensitive rule Input: (1)  Source database D, (2) Minimum support value (min_support), (3) Minimum confidence value (min_confidence).

Output: A transformed database D? so that useful fuzzy association rules cannot be mined.

Algorithm DSR: 1. Cleaning of database, D C 2. Fuzzification of the cleaned database, C  F;  3. Calculation of  support value for all items,  where f ? F, in fuzzified database F.

4. IF all f (support) < min_support THEN EXIT; // there isn?t any rule 6. Find large 2-itemsets from F; 7. FOR EACH X?s large 2-itemset //find all rules  Find R = {Rules from itemset X}; //for X= {i1, i2}, rules are i1  i2, i2  i1.

Compute confidence of the rule U;  IF confidence (U) > min_confidence and sensitive THEN  Add the rule U to Rh; end//if  end//end of FOR EACH //Hides all rules in Rh 8.  FOR EACH U in Rh  {//until no more rule can be hidden FOR EACH TR  of rule{  if TR >0.5 and TR > TL TR = 1 - TR  end // if end // FOR EACH.

Re-calculate confidence value of rule U if rule U(confidence) > min_confidence FOR EACH TR of the rule if TR = 1.0 TR = 0.0  end// if end // FOR EACH else go to step 9  end //if 9. Transform the updated database F to D? and output updated D?; 10. end An illustration of the working of the proposed algorithm is  as follows Step 1: The database as in Table1 is cleaned by  substituting the unknown values by zero, and eliminating the redundant records. In case of multiple records having the same id the last one is taken.

Table 1.  Sample data with 5 attributes  A B C D E  T1 3 ? ? 2 1  T2 14 5 10 4 2  T3 12 9 8 5 3  T4 10 8 10 6 4  T5 13 4 11 8 9  1i1i  i1  C,CELSE  ,C,THEN)(IF  ++  +  ??  ?>  ii  iii  yy  yys ?  Data  Fuzzy  Values   ai ci ak ck  150 2011 World Congress on Information and Communication Technologies    Table 2. Cleaned data  A B C D E  T1 3 0 0 2 1  T2 14 5 10 4 2  T3 12 9 8 5 3  T4 10 8 10 6 4  T5 13 4 11 8 9  Step 2: Fuzzification The cleaned database as shown in table 2 is fuzzified using  triangular membership function given in equation (8) into 3 regions Z, O, B as shown in fig 2. The fuzzified data is shown in table 3.

(8)  Where a  is the left end of the triangle, b is the peak of the triangle and c is the right end of the triangle (values are the corresponding x axis values)  Fig 2. Triangular Membership Function used  Step 3: Calculate the support count of each attribute region, R  on the transactions data by summing up the fuzzy values of all  the transactions in the fuzzified transaction data as in table 3.

Step 4: Check whether count of each attribute is greater than  or equal to the predefined minimum support value. If an  attribute satisfies the above condition, put it in the set of large-  2 itemsets (L2). Consider the minimum support is set to 2.3  and minimum confidence to 70%. The regions Bz, Co and Dz  are have their support value greater than minimum support, so  are considered in forming the rules and finding the  corresponding confidence value. The rules  can  be   Bz Co,  Co Dz, Bz Dz, Co Bz, Dz  Co, Dz  Bz. Consider  Bz Co is a critical rule to be hidden and the support of the  rule is calculated as shown in table 4.

Step 5: For each large 2 itemsets, based on user specified minimum confidence value, rules are extracted. Confidence value of  A B rule is computed as follows:  The confidence value is calculated for the rule Bz Co  Step 6: To hide a critical rule, its confidence value is decreased by decreasing support(AB). In order to hide the rule Bz Co, the  support (BzCo)  is reduced by subtracting the transaction value of Co from 1 when the value of Co is greater than 0.5 and corresponding Bz?s value. Using this procedure the support values of transaction T3 and T4 are reduced as shown in table 5.

Now the confidence is  As the confidence is still greater than minimum confidence, in those transactions that have Bz and Co value as 1, Co is replaced with 0 as shown in T2 of table 6. The confidence value after the modification is calculated as  As the confidence value is less than the predefined confidence value the rule Bz Co is hided.  The modified values replace the original fuzzified values in the fuzzification table as shown in table 7. Defuzzification using centroid method is done on the modified values to get back quantitative values using the equation (9).

Table 4. Fuzzy values of Bz and Co  Bz Co Support  T1 0.0 0.0 0.0  T2 1.0 1.0 1.0  T3 0.2 0.6 0.2  T4 0.4 1.0 0.4  T5 0.8 0.8 0.8  Count 2.4  2.4  Table 5. Modified T3 and T4  Bz Co Support  T1 0.0 0.0 0.0  T2 1.0 1.0 1.0  T3 0.2 0.4 0.2  T4 0.4 0.0 0.0  T5 0.8 0.8 0.8  Count 2.4  2.0  Table 6. Modified T1  Bz Co Support  T1 0.0 0.0 0.0  T2 1.0 0.0 0.0  T3 0.2 0.4 0.2  T4 0.4 0.0 0.0  T5 0.8 0.8 0.8  Count 2.4  1.0  The  defuzzified values  are shown  in  table 8.

(9)  Where  X is the quantitative value, n is the number of regions, xi is the center point of that triangle, ?(xi),corresponding membership value in that triangle.

5 10 15       20 Quantity  Membership value  z  o b  2011 World Congress on Information and Communication Technologies 151    Table 3. Fuzzification of transaction data  Transaction A B C D E  n Az Ao Ab Bz Bo Bb Cz Co Cb Dz Do Db Ez Eo Eb  T1 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.0 0.2 0.0 0.0  T2 0.0 0.2 0.8 1.0 0.0 0.0 0.0 1.0 0.0 0.8 0.0 0.0 0.4 0.0 0.0  T3 0.0 0.6 0.4 0.2 0.8 0.0 0.4 0.6 0.0 1.0 0.0 0.0 0.6 0.0 0.0  T4 0.0 1.0 0.0 0.4 0.6 0.0 0.0 1.0 0.0 0.8 0.2 0.0 0.8 0.0 0.0  T5 0.0 0.4 0.6 0.8 0.0 0.0 0.0 0.8 0.2 0.4 0.6 0.0 0.2 0.8 0.0  Count 0.6 2.2 1.8 2.4 1.4 0.0 0.4 3.4 0.2 3.4 0.8 0.0 2.2 0.8 0.0  Table 7. Modified Fuzzy values  Transaction A B C D E  n Az Ao Ab Bz Bo Bb Cz Co Cb Dz Do Db Ez Eo Eb  T1 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.0 0.2 0.0 0.0  T2 0.0 0.2 0.8 1.0 0.0 0.0 0.0 0.0 0.0 0.8 0.0 0.0 0.4 0.0 0.0  T3 0.0 0.6 0.4 0.2 0.8 0.0 0.4 0.4 0.0 1.0 0.0 0.0 0.6 0.0 0.0  T4 0.0 1.0 0.0 0.4 0.6 0.0 0.0 0.0 0.0 0.8 0.2 0.0 0.8 0.0 0.0  T5 0.0 0.4 0.6 0.8 0.0 0.0 0.0 0.8 0.2 0.4 0.6 0.0 0.2 0.8 0.0  Count 0.6 2.2 1.8 2.4 1.4 0.0 0.4 1.2 0.2 3.4 0.8 0.0 2.2 0.8 0.0  Table 8. Defuzzified table  A B C D E  T1 3 0 0 2 1  T2 14 5 0 4 2  T3 12 9 8 5 3  T4 10 8 0 6 4  T5 13 4 11 8 9

V. EXPERIMENTAL RESULTS  Experimental results were taken using Wisconsin Breast Cancer dataset from UCI Machine Learning Repository [14]. The dataset consists of one id attribute, nine quantitative attributes and one categorical    attribute. This algorithm was implemented using nine quantitative attributes which are mapped to three fuzzy sets each. Three rules were randomly selected for hiding. Experimental results were taken with membership function given by expert and automatically generated membership function.

i) Using membership function provided by experts  Figure 3. Number of rules vs minimum support  Fig. 3 shows the number of generated rules and hidden rules for varying values of support with a constant minimum confidence of 50 when quantitative data is fuzzified using membership function values supplied by the experts. As DSR method is used the number of rules hidden for increased values of support is less. In previous work [1], it changes according to the support value.

Figure 4. Number of rules vs minimum confidence  Fig. 4 shows the number of generated rules and hidden rules for varying values of confidence and a constant minimum support of 50.

Figure 5. Rules lost after hiding a set of three rules  152 2011 World Congress on Information and Communication Technologies    Fig. 5 shows the number of rules lost as a side effect of hiding three rules is less in proposed method than in previous work[1].

ii) Using Automated Generation of  Membership  Function(AGMF)  Experimental results in Fig. 6 show the number of generated rules and hidden rules for varying values of support with a constant minimum confidence of 50. Fig. 7 shows the number of generated rules and hidden rules for varying values of confidence with a constant minimum support of 50 when quantitative data is fuzzified using membership function values generated by the proposed algorithm.

Figure 6. Number of rules under different minimum support  Figure 7. Number of rules under different minimum  confidence  Figure 8. Rules lost after hiding a set of three rules  Fig. 8 illustrates that the number of lost rules is less in the proposed approaches, DSR and DSR with auto- generated membership function, when compared to the previous work [1]. Further the DSR method decreases the support so that no ghost rules are produced. From the results it is inferred that automatic membership function generation provides consistent rule hiding even in the absence of expertise.



VI. CONCLUSION  In this paper, we proposed a learning method to derive membership functions automatically for numeric data and presented a method for preventing extraction of useful association rules from quantitative data by decreasing the support of the RHS of the rule. Unlike previous approaches which mainly deals with association rules in binary database, our approach deals with hiding the association rules in quantitative database. Experimental results demonstrate that the proposed approach is more efficient as it facilitates better rule hiding and  minimizes the number of lost rules and ghost rules. Also, this approach makes minimum modification of data. To further minimize the side effect and modification to database genetic algorithm can be used.

