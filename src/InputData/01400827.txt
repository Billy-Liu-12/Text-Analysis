2004 IEEE International Converence on Systems, Man and Cybernetics

Abstract - Association rule has evolved fiom the primitive form of single dimension infratransaction fa  the form of multi-dimension intertransaction. The challenge for mining multi-dimension intertransaction rules is the formidable search space. Researchers hove propo.sed various methods to handle this problem, such as restricting the number of dimensions, confining sea.Vch space in a small window, etc. These methods unavoidably hove negative impact on mining result and they are less efective when the number of dimensions and the length of rule are really large. Moreover, all these methods ,ire derived @om the Apriori algorithm and have common weaknesses: time consuming and redundancy caused by the iterative nahire of the Apriori algorithm. To approcich this problem from a dyerent angle, we propose to use (he singular value decomposition technique(SVD). With SID, the multi-dimension intertransaction rules can be easily identified  Keywords: data mining; information analysis.

1 Introduction The algorithm for mining association rules, initially  suggested by Agawal, Imielinski and Swami in 1993 [I], has been widely used in many industries, such as supermarket, banking, stock market, etc. To fulfill vari ,m requirements in different applications, association rule has evolved into a wide variety of types. The primitive association rule looks lie ?customers buying beer are most likely to buy diaper too?. This kind of rules is called singledimensional boolean association rule. ?single- dimensional? means only one attribute, item name, is considered; ?boolean? means we only care about if a item appears io a transaction, but not about other aspects, such as the purchase quantity. The association rule has evolved in several directions. ?Multidimensional association rule ? [ I I ,  12, 131 and ?sequential association rule?[2, 5 ,  6, 7, 8, 9, IO] are two major directions attracting many attenticns.

A typical multidimensional association rule looks like ?students aging from 20 to 29 are likely to pay by credit card?. In this example, three attributes occupation (student), age (from 20 to 29) and payment habit @ay by  ? 0-7803-8566-7/04/$20.00 0 2004 IEEE.

Kwok-ping Chan Dept. of Computer Science, University of Hang Kong  kpchan@csis.hku.hk  credit card) are involved. A typical sequential association rule looks like ?customer is most likely to buy badminton after he has already bought racket?. The multidimensional association rule and the sequential association rule are able to provide more useful and meaningful information than the traditional association rule. Recently, researchers tried to mine more complex rules, such as multidimensional sequential association rule [5 ,  21 and multidimensional intertransaction association rule [U].

Typical examples are as follows.

An example for multidimensional sequential rule is ?if a  customer of an Internet Service Provider (ISP) is young, then most likely he has the following purchase behaviors: fmt, subscribe to a 100-hour free trail package; second, subscribe to a 15-hour/month package; third, subscribe to a 3O-hour/month package; finally, subscribe to an unlimited package?. Two attributes, customer age and the type of service package, are involved. However, only one attribute, the type of service package, is involved in the description of the purchase behaviors. The other attributre, customer age, is only used to identify a particular group of customers who follow the purchase pattem. An example for multidimensional intertransaction association rule is ?if the humidity is high in day 1,  and the temperature is high in day 2, then most likely there is high rainfall in day 3?. Three attributes are involved in the rule. Actually, multidimensional intertransaction association rule can capture cross-attribute association relationship in a temporal space. This is very meaningful considering it can be used to predict the value of an attribute based on the previous values of all attributes.

Typical examples include daily meteorological report, daily trading record of stock market, etc.

It is reasonable to think all attribute values occurring over a period of time actually form one kind of circumstance, in which the current value of one particular attribute develops. Inspired by this analysis, we propose a new kind of association rules which can reflect the association relationship between the circumstance and the value of an attribute. We refer to this kind of association rules as circumstance-oriented association rule. A typical example looks like, ?if the temperature is in range of A in day 1; the humidity is in the range of B in day 2; ...; the     visibility is in range of Z in day n-1; then the wind will be strong in day n?. Compared with multidimensional intertransaction association rule, more dimensions and transactions can be dealt with in the circumstance-oriented association rule. Therefore, the search space will he very large. It is a big obstacle. In this study, we use Singular Value Decomposition (SVD) technique to tackle this problem.

The remainder of this paper is organized as follows.

Section 2 presents a formal description of the problem.

Section 3 introduces some related researches so that readers can have a better understanding of our algorithm.

Section 4 analyzes the problem we will face during establishing the circumstance-oriented association rules.

Section 5 presents the solution to the problem. Section 6 shows the experimental results and related analysis.

Conclusion is given in section I.

2 Problem Statement Let S=<sl ,sz , . . . s ,  > be n consecutive observations of  one object. Each observation is characterized by m attributes (al,az...a,} . An element of S ,  s i ,  is  represented as {ai,& ,...a;}. p consecutive observations in S, s,=(al,a I 1  z,... a,},...,sp=(al,aZ,...aP_}, I P P  can be  thought of as one kind of circumstance. Our purpose is to mine interesting rules which reflect the association relationships between the circumstance and the value of the jth attribute in the @+l)th observation ap+l,l r j  sm.

3 Related Researches In this section, we would like to briefly review some  researches about mining sequential rules, multidimensional rules, multidimensional sequential rules, and multidimensional intertransaction rules.

In 1995, Agrawal and Srikant introduced the concept of sequential association rule and suggested the AprioriSome and the AprioriAll algorithm [2]. The sequential association rule is usually mined out from a special database, called sequence database. The sequence database can be derived from a transaction datahase by reorganizing transaction records to track the purchase history of each individual customer. Srikant and Agrawal proposed the GSP algorithm to mine sequential pattern in 1996 [SI. In this method, hash-tree technique was used.

Based on the GSP algorithm, Zaki developed the SPADE algorithm by introducing lattice-theoretic technique in 2001, which can effectively reduce the search space.

Garofalakis, Rastogi and Shim introduced the concept of regular expression into miniig sequential pattern and developed a family of algorithms, called SPIRIT. By using this algorithm, user can interact with the miniig process. The mining results will be more suitable to users? needs.

Multidimensional association rule, as another important research topic, has also attracted many research efforts.

The main challenge for mining multidimensional association rule is the large search space caused by the mnltidimentionality and huge numher of possible values of attributes. Srikant and Agrawal in [7] dealt with the problem by f ie ly  partitioning the values of attributes and then combining adjacent partitions as necessary. The main contribution of [7] is that it proposed an algorithm to optimally distribute values into individual subsequences so that more interesting rules can be discovered. In [8, 91, Kamber and Pei ef ai put constraints on attributes to reduce the search space. Fukuda, Yasuhiko and Morimoto concentrated on miniig rules in a two-dimension space in [IO]. In a relatively small multidimensional space, they can identify a continuous region satisfying user-specified confidence threshold. The continuous region is called admissible region. The admissible region is usually formed by merging some adjacent cells. Therefore, the association rules have a compact representation. On the contrary, the rules mined out in other study were represented in a ?discrete? manner. Also, they visualized the association d e s  in their study. Therefore, users can get an intuitive observation on the rules mined out. Based on the observation, users can even interact with the mining algorithm. The major pitfall of this approach is that it is only capable of mining two-dimension association rule.

Pinto et ai. attempted to combine the two concepts ?multidimensionality? and ?sequence? in [l l] .  The rule mined out looks like (attribute-I, attribute-2,. . .attribute- m, description). For example, we have (Age=Young, Education=University, [subscribe to a 100-hour free trail package - subscribe to a 15-hourimonth package - subscribe to a 30-hourimonth package -+ subscribe to an unlimited package]). This means, if a customer is young and his education status is high, then most likely he tend to follow the purchase behaviors described in the square brackets. They implemented the algorithm by embedding multidimensional information into sequences or by integrating efficient sequential pattern mining algorithm and mnltidimentional analysis method. However, these methods have difficulty in dealing with high dimensionality and long sequence, since the simple integration of these methods does not works well. On the other hand, only one attribute, ?service package?, is concerned in the description part. Hence, this kind of rules cannot reflect the cross-attribute association relationships , Strictly speaking, they are not multidimensional rule.

Lu and Feng defined the concept, ?multidimensional intertransaction rule? in [12, 131, which is able to reflect cross-attribute association relationships. They used a sliding window (single dimensional window for mining single dimensional case; multidimensional window for mining multidimensional case) to confine the search space. With the window, each record has a relative address.

4 Problem Analysis All these studies discussed above used Apriori-lie  algorithm, which is based on the anti-monotone property: if any length k pattem is not frequent in the database, its length (k+l) super-pattem can never be frequent. 'The essential idea of Apriori-like algorithm is to iteratively generate the set of candidate itemsets of length (k+l) fiom the set of frequent itemsets of length k. Hence, Apriori- l i e  algorithms is inherently time-consuming. 'The situation becomes worse when dealing with multidimensional sequential case. In researches mentioned in section 3, the following measures have been taken to alleviate the problem: bucketing values of quantitative attribute, putting constraints on attributes, confming searching scope, etc. These measures weaken the power of the mining algorithm. Their effect is also limited when the number of dimension is really large ,and the sequence is really long.

Apiori-like algorithm has another weakness. We take the algorithm in [I21 as an example. Assume t k r e are two sequences mined out, a,,aj,a: and a:,ab,a,k 1 Si,j,k Sn, I rq,r,s cm. Superscripts i, j and k represent time points at which observations are taken; subscriptl; q, r and s represent the indices of attributes. Two association rules can be derived from them, a\ andaj -a: ;ind  a: and a6 +a:. The former implies that 06 occurs first;  a! occurs second; then a: occurs. The latter implies lhat  a i  occurs first; a i  occurs second; then a t  oc(:ur.

However, in real life, the following story may happen: ab is hound to occur as long as a\ and a! have already occurred in any order. The Apriori-like algorithms are unable to deal with such kind of problem. These two sequences may be missed during mining process if their respective support counts cannot reach the threshold, exen if the sum of their support counts may satisfies the threshold requirement. On the other hand, it will be redundant if both of them get into final rule set.

5 Solution Undoubtedly, we need a technique other than Apriori-  like algorithm to break the bottleneck posed by multidimensionality and long sequences. In this study, we use the SVD technique to tackle this problem. In malrix theory, any arbitrary rectangular matrix W ( M x N )  n-ith different entities on the rows and columns can be decomposed into 3 matrices. Among them, two u e rectangular matrices with their column vectors being orthogonal to each other. They are called lei? and right singular matrix and usually denoted by U and V. l'he remaining one is a diagonal matrix, denoted by S, whose diagonal elements are non-negative singular values soned in descending order. The diagonal matrix represents a nsw  space, called semantic space. The row vectors of W are projected onto the orthogonal basis formed by the column vectors of the right singular matrix V, similarly, the column vectors of W are projected onto the orthogonal basis formed by the column vectors of the lei? singular matrix U. W can be completely reconstructed from U, V and S .  However, W is usually approximated by the most important R factors, ignoring smaller, less important factors. This can be expressed as W =W = USVT (1).

where, U (MxR) left singular matrix with vector  S :  (RxR) diagonal matrix of singular values  V (RxN) right singular matrix with row vectors  R ~ I ~ ~ ( M , N )  order of decomposition, the rank of W.

In (I)  Wis the best rank-R approximation to W.

Detailed explanation can be found in [14].

Actually, SVD transforms the high-dimension discrete  (MxN) matrix into a low-dimension continuous vector space S (RxR), also called semantic space in language model field. A row vector in the original matrix can be expressed as U,&' in the new space; a column in the  original matrix can be expressed as SVT. That is, uiS and  Sv: represent the positions of the i" row and the j" column of the original matrix in the new space.

Essentially, SVD operation breaks down the original relationships between rows and columns into linearly independent factors. Many of them are less significant and can be omitted. We keep the most interesting R factors, i t ,  R dimensions in the S space, which reflects the principal structural associations hidden in the original matrix. The original matrix, i.e., a 2-D relationship table, is usually very large and sparse. In addition, it can only provide a primitive description about the relationships between the rows and columns. SVD operation can easily get rid of the above deficiencies. In semantic space S, the number of dimensions, R, is much less than M and N.

As discussed in the above description, we can use SVD technique to captures the major structural associations hidden in original W, although less meaningful factors are ignored. This is because the associations between vectors in the semantic space are determined by the overall pattern hidden in W instead of specific trivial details.

Therefore, we can avoid the interference caused by trivial details.

The purpose of our study is to find interesting association mles. An association rule consists of two parts, the antecedent part and the consequent part. An association mle embodies one kind of causality. A traditional association rule looks like AIAAZA...AA,+B, Ai, l  Si Sm and B are attribute-  ui,l Si SM  s, t S 2  8.. .  BSIL > 0  vi, l  Si SN     value pairs. The antecedent part A l A A 2 A . . . A A m describes one kind of circumstance, in which the consequent part B develops. Using conjunctive attribute- value pairs to describe the antecedent part (i.e., the circumstauce) has a number of weaknesses. First, to f i d rules with long antecedent part, the miniig time will be very long. Second, the sequence of attribute-value pairs in antecedent part are order sensitive. That is, different permutations of attribute-value pairs have different meanings. However, in real life, the consequence is usually associated with what events have already happened, but not with the order in which those events happened. One typical example is the case of mining students? examination records. Assume that we are interested in those rules which reveal the relationship between exam results and whether a degree should be awarded; students who pass all course exams will be awarded an academic degree; totally three courses are required to he taken by students in any order. According to the mining algorithm described in [12]. We may fmd rules ?Coursel-pass, Course2-pass and Course3-pass, then degree-awarded?; ?Course3-pass, Course2-pass and Coursel-pass, then degree-awarded?. Essentially, the two rules reflect the same association relationship between the exam results and the degree-awarding decision. A student will he awarded the degree as long as he passes the three courses, regardless of the order in which he takes the three courses. Actually, taking the order into account may make it more difficult to find intrinsic associations. In essence, all the above three weaknesses are caused by the iterative nature of the Apriori-like algorithm-finding the length (k+l) frequent itemset based on length k frequent itemset.

To find long frequent itemset, the process will repeat many times. Additionally, the order of the elements in the itemset has to be preserved during the whole mining process [S, 12, 131.

Based on the above discussion, we propose the following SVD-based mining algorithm to find circumstance-oriented association rules. The can be described as follows.

(1) divide observation sequence S=<s, ,s2, . . . sn >into (n-Z+l) subsequences by passing a sliding window of size Z through the whole sequence.

(2) Cluster the subsequences into categories, each of which represents a kind of circumstance.

(3) Construct a MxN matrix W. Each column represents a circumstance. Each row represents an attribute. If an attribute is categorical, then each possible categorical value is represented by a row. If an attribute is quantitative, then we discretize the attribute into a few intervals. Each interval is represented by a row. Each entry represents the occurrence frequency of a particular value of an attribute in a certain circumstance.

(4) Decompose the mahix into U, V and S .  Calculate the dot product of between the i-th row of U$? and the j-th column ofv,S??, which indicates the extent of  association between the i-th attribute value and the j-th circumstance. If the value satisfies a user-specified threshold, the association will be collected as rule.

Given a sequence of observations, we evaluate and assign it to a particular class. Then we retrieve the rules database to see if there are any association rules whose antecedent part can match with this circumstance class. If so, the consequent part of this matched rule will tell what may happen next.

As illustrated above, the challenge posed by multidimensionality and long sequences can be easily tackled in the semantic space.

The circumstance-oriented rules have a different look than traditional association rules. In left hand side it is a circumstance; in the right hand side it is the consequence which develops in the circumstance. Actually, the circumstance represents a class of observations which have similar features. We will present an example in section 6.

6 Experiments In this study, we use meteorological data to test the  rules mined out. The meteorological data is obtained from hm://uwv.!uuni.nlivoorkd/index enp.html (Daily values, On-line time series of Dutch stations) which was produced by the Royal Netherlands Meteorological Institute. Specifically, we use the meteorological data recorded during 1981-2002 at the Maastricht peek) station (station number 380). The data from 1981 to 2000 is used as training data; the data of 2001 is used to determine an appropriate value for R the data of 2002 is used as test data. The data is provided in text format.

Totally, there are 16 attributes in each observation.

STN - station-number =06 ...

(23S=DeKooy,260=De Bilt,280=Eelde,290=Twenthe,3 1 O=Vlissingen,380 =Maastricht)  YYYYMMDD =date DDVEC = prevailing wind direction in degrees (360=North, 180=South,27O=West, @calm)  FG = daily mean windspeed in 0.1 mis FHX = maximum hourly mean windspeed in 0.1 d s  .FX =maximumwindgustinO.lm/s TG =daily mean temperature in 0.1 degrees Celsius TN = minimum temperature in 0.1 degrees Celsius TX = maximum temperature in 0.1 degrees Celsius SQ = sunshine duration in 0.1 hour (-1 for <0.05 ) SP=percentage of max. possible sunshine duration DR =precipitation duration in 0.1 hour RH = daily precipitation amount in 0.1 mm (-1 for  PG =daily mean surface air pressure in 0,l hPa VVN = minimum visibility NG = cloud cover in octants (9=sky invisible)  -  <0,05 mm)     Except station number (STN) and date (YYYYMMDD), there are 14 meteorological attributes.

All of them are quantitative attributes except cloud cover (NG). We partition the domain of the attribute wind direction (DDVEC) into 9 intervals, i.e., 045,  45-90, 90- 135, 135- 180, 180-225, 225-270, 270-315, 315-360 and calm. The domain of the remaining 13 quantitative attributes is partitioned into 6 intervals. Finally, there are 87 independent attributes. These attributes form a ?vocabulary ?. A weather condition is described with these ?words? in the vocabulary.

6.1 Window size  To use the SVD technique, fust we construct a matrix.

Each row represents an attribute mentioned above. Each column represents a circumstance. To create various circumstances, we fmt produce all possible subsequences of observations by moving a window through the sequence of observations. The total number of the subsequences depends on the sue of the window. For example, if there are 6 observations in the sequence md the window size is 3, then totally 4 subsequences can be generated. More importantly, by setting window size io a value, say Z, we mean the current attribute value is mainly associated with the previous Z observations.

6.2 Clustering observation subsequences  The meteorological records contain both quantitative and categorical attributes. We use the k-prototypes algorithm, suggested by Huang in [21], to c h t e r observation subsequences. The main feature of the k- prototypes algorithm resides in its capability of clustering objects with both quantitative and categorical attributes.

Assume that the dissimilarity between two mixed-type objects X and Y, which are described by attributes A;,A;;. .Ai,A;+, ;. .A: can be measured by  j=l j=p+l  where, the weighty is used to strike a balance between the quantitative attributes and the categorical attributes. It is determined empirically. In out experiment, y is 0.9.

And,  If the sliding window size is 2, then every subsequence consists of Z observations, and each observation consists of m attributes. Therefore, Zxm attributes are involved in a subsequence. We use the Zxm attributes as the attributes of an observation subsequence when clustering.

The procedure for clustering is as follows.

( I )  Select k initial classes;  (2) Allocate an object to the class which is the nearest to it according to (3). Update the mean of this class after each allocation;  (3) After all objects have been allocated to clusters, retest the dissimilarity of objects against the current means. If an object is found such that its nearest mean belongs to another class rather than its current one, reallocate the object to that class and update the means.

(4) Repeat step 3 until no object has changed classes after a full cycle test of the whole data set.

The sliding window s u e  is 20, tberefore the number of subsequences of the training data totals 365 (Day) x20 (Year) -20 (Window Size) +I =7281. We partition these subsequences into 100 clusters, representing 100 circumstances.

6.3 SVD processing  Using the k-prototypes algorithm, we get a matrix which has 87 rows and 100 columns. The value in each cell represents occurrence times of a particular attribute value developed in a certain circumstance.

To determine an appropriate value for R, we conducted the following experiment. By using SVD technique, we produce a series of semantic spaces by changing R from 2 to 28 with the step size of 2. In each of these semantic spaces, we select 100 most interesting association rules and test the prediction rate of these rules on the data of 2001. Based on the test result, we determine the value of R. As shown in Figure-1, the trajectory increases quickly in the initial stage but levels off after point, R=22. Hence, in our study, we set R to 22.

6.4 Mining results  We calculate the dot product of the ith row of U ~ S ? ~  and the jth column ofvjS?/?, representing the extent of association between the ith attributes and the jth circumstance. We select the most interesting association rules to form the final rule set.

Some examples of rules are shown in Table-]. Each circumstance is represented by a cluster center.

6.5 Application  We tested the rules on the meteorological data of Year 2002. We moved a sliding window of sue 20 over Observation sequence to form circumstances. We measure the Euclidean distances between each circumstance and the center of individual clusters. Find the shortest one. If the shortest Euclidean distance satisfies a user-specified threshold, then the circumstance is assigned to the corresponding cluster. There are totally 7,800 possible rules. The higher the extent of association between a circumstance and a result, the higher its predication rate  31 73    upon application. The prediction rate of the whole rule database will decrease as more rules are admitted, as shown in Figure-2 (solid line).

7 Conclusion In this study, we proposed the circumstance-oriented association rules. We used the SVD technique to deal with high dimensionality and long sequence. The experimental results showed that the approach is promising.

