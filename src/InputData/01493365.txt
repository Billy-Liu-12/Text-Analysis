?A Subjective Distance for Clustering Security Events

Abstract-It is well known that intrusion detection systems overload their human operators by triggering per day thousands of alarms most of which are false positives. A clustering method forwarded by CIaus Julisch is considerably effectual in eliminating the fahe positives and finding the root causes. Eut there may, according to the variance related to the operators? knowledge and experience, exists a gap between the nature of the event clusters and what the operators obtained from the resulted clusters. A subjective distance, different from the objective distance defined by Julisch, i s  foharded in this paper to fill the gap by the means of controlling the clustering process with the subjective distance.

1. INTRODUCTION Intrusion detection systems (IDS), as a new and potent  approach to protect computer systems, are increasingly deployed in response to attacks against enterprise networks [9]. However, there appears another difficult problem with the use of IDS: A great number of alarm messages are generally triggered which turn out to be a burden of the human operator. It is common for an IDS to trigger thousands of alarms per day, up to 99% of which are false positives [6].

Association rules between adjacent alarms are mined and then they are used to implement anomaly detection on the IDS alarms [7]. According to the work described in that paper, alarms that are consistent with these association rules are deemed ?normal? and are then discarded. Clifton and Gengo [SI used episode mining to help construct the filtering rules.Claus Julisch and his cooperators using a clustering approach to identify the root cause [ l ,  2, 51. Their work should be emphasized here with respect to the effect of their clustering method. In fact, we forwarded a new computer language (TTT Language) in which their work was assimilated for security log analysis [13]. Relatively more detailed discussion about their work will be given in the next sub-section.

A.

To cluster the events, a distance between two events must  be defined in advance. In practice, distance is easy to define for numerical attributes, but categorical, time, or string  The distunce defined by Ciaus Julisch  Supported by the National High-Tech Research and Development Plan of China under Grant No. 2003AA148020  0-7803-901 5-6/05/$20.00 02005 IEEE.

attributes give rise a problem when being defined the distance of [12]. Unfortunately, alarm messages can contain all of these attribute types.

In Julisch?s work, similarity or distance can be defined in a uniform manner using taxonomy. By way of illustration, Figure 1 shows how taxonomy of the IP address, port, and time attribute can be obtained. The taxonomy plays a basic role in the clustering method. It can be seen in Figure 1 (c, d) that the taxonomy of the attribute time can be constructed in two ways. In fact, the domain of almost every attribute can be classified this way.

ANY-IF ANY-PORT  ANY-DAY-OF-WEEK ANY.DAY-OF-MONTH  J 1 1  J 1 1  ...... (4 h0 ... h23 h0 ... h23  (c)  Figure 1. Taxonomy of several kinds ofattributes  Let A, be an alarm attribute, alarms are defined as tuples over the Cartesian product IT Isi+,dom(Ai). A tree I;. is called a taxonomy tree if it is the taxonomy on the elements of domain(Ai). There are 4 examples of taxonomy trees in Figure 1. For two nodes x, y i n 5, x is called a parent ofy, and y a child of x if there is an edge x - y in E.. Furthermore, x is called a generalization of y, if T, contains a path from x t o y  (in symbols: x a y ) .  If x is a parent of y ,  then x certainiy is the generation of y. Finally, x ~ x  is trivially satisfied.

These definitions can be illustrated with the taxonomy tree of Figure l(a). Node ?ANY-IP? is a parent of node ?DMZ? while ?DMZ? is a child of ?ANY-IP?. And ?ANY-IP? is a generalization of ?ANY-IP?, ?DMZ?, and ?ipl ?, respectively.

Based on the definition ?generalization?, the distance between two nodes in st taxonomy tree can be defined. The distance between x and y is the number of edges between x andy, ifx is a generation ofy, or i fy  is a generation ofx. But the distance between two nodes is undefined if the relationship of generalization does not exist between them.

A vector, every element of which is a node from the corresponding taxonomy tree, is also called an alarm. It is different from en ordinary alarm, for its elements are probably not taken from its attribute domain. A cover of a set of alarms b,, yz, ..., yn) is ?an alarm x, which is a generalization, but as special as possible, of each alarm in the set. The example is also from Figure l(a, b). Given a set of 3 alarms (DMZ, SO), (ip3, 801, and (FIREWALL, PRIVATE), then the cover of the set is (DMZ, PRIVATE). Although the alarm (ANY-IF, ANY-PORT) is the generalization of each alarm in the set, it is not the cover of the set because it is not special enough. So the distance of a set of alarms is defined as the average distance between its cover alarm and each of its member alarm. The distance of the alarm set just mentioned with three members is: (1+2+1)/3 = 413.

The clustering problem forwarded by Claus Julisch can be now described as:.finding a set of alarms in all the alarms triggered, satisfying at the same time the requirement that the number of the set members is greater than or equal to a given threshold while the distance of the set is minimal.

Though Julisch?s method of clustering with the distance defined by himself is effectual in eliminating.false positives and forming an event overview with high quality, there is an inherent deficiency in the distance definition. I f  a generalization alarm is got as a cluster, it is then the representative of all the alarms it covers. If the proportion among the alarms does not match what it is considered to be, then the cluster tortures the nature o f  among the events with loss of information to some extent when presented to human operators.

Figure 2 shows a simple example in this case. There are altogether 210 primitive events (listed in (b)), and the taxonomy trees of source IP address and destination IP address are constructed as shown in (a) and (c), respectively.

According to Julisch?s clustering problem with a given threshold 100, two results can be independently obtained, and the results are shown in (d) and (e), respectively. But which is a good result and which is a bad one? Julish?s method is not able to answer the question. In fact, if S1, according to the operator?s knowledge and experience,? is more offensive than S2, then the second result will be better, for i t  will help the operator get more precise information about the alarms in the cluster. After getting the cluster (S, D1, 1 10) in the second result, he wiIl assume it as a matter of course that S1 attacked D l  much more times than 52 did.

This is nearly the nature that the triggered alarms suggested.

But if S1 and $2 are, according to the operator, equally offensive, then the second result is not a good one. So the problem is how to get the good result according to the operator?s knowledge and experience. To quantitatively and  systematically solve this problem is the main purpose of this paper.

(SI, D2,70) (52, DI, 30) SI  (b) Primitive alarms  (d) The first clustering result (e) The second clustering result  Figure 2. Two possible results o f  Julisch?s method  B. Other related work To define and use a subjective distance is not new.

Subjective distance measures are based upon user beliefs or biases regarding relationships in data, such as an approach utilizing Bayes Rule to revise prior beliefs [3], and a systematical approach to subjectively measure the interestingness in knowledge discovery [4]. But the purpose and method to define and use a subjective distance in this paper are quite different from those of their work.

11. SUBJECTIVE DISTANCE The subjective distance of a cluster is defined similar to  that of an objective distance described above. But an additional concept - the subjective proportion - should be taken into consideration. A subjective proportion is the proportion, among the child clusters, which is in the human operator?s mind. I f  a subjective proportion of child clusters of A l l  in Figure 3 is 0.4: 0.4: 0.1, then it means that the operator thinks that A21 and A22 appear in alarms almost equally frequently and that they both appear far more frequently than A23 does. Accordingly, the objective proportion among its child clusters, for instance, should be 10: 5: 5, namely 0.5: 0.25: 0.25.

A .  Another approach to get the objective distance Remember that the distance of a cluster (namely a node  with all the alarm elements it covers) within a taxonomy tree is the average number of edges counted from the alarm members to the cover. But we will define it another way with its meaning not changed.

Definition 1. The objective distance of a cluster in a taxonomy tree is the sum of 1 and the frequency-weighted sum of the objective distances of all its child clusters; and the objective distance of each leaf cluster is 0. if the proportion among the frequencies with which the child cluster appears is PI: pz:  ... p,,, and the objective distances of all its child clusters are dl, d,, ..., d,,, respectively, then the objective distance of the cluster is:     do = I + 2 b r - d , )  (1) 1=1  The objective distance in the above definition is defined recursively. It will be  attained level by level from the 0- distance leaf clusters to the root cluster. And the constant number 1 implies that the distance between the cluster node and the child cluster node is 1. A simple example shown in Figure 3 will illustrate the definition. The nodes A31, A32, A33, A34, A35 are leaves; therefore objective distances of these clusters (if they are looked on as clusters), according to the definition above, are all 0. And the objective distance of leaf A22 in  the second level is 0 as well. But the distance of the cluster A21 is: 1 + (0 X 0.4 + 0 X0.2 +- O X  0.4) = 1.

Similarly, the distance ofthe cluster A 2 3  is: 1 + (OX 0.6 + 0 X 0.4) = 1. And finally, we can get the distance of the root cluster A1 1 as 1 + (1 X0.5 f OX0.25 + 1 X0.25) = 1.75.

I A l l . 2 0 ?  I  Figure 3. Another objective distance definition *Numbers after a coma mean the times repeated  Considering the distance definition of Julisch, we can work out, based on all the primitive alarms (the leaf ones), thedistanceoftheclusterAl1: ( 2 x 4  + 2 X 2 + 2 X 4 + 2 X 3 + 2 X 2 + 5 X 1)/20 = 35/20 = 1.75. This result is the same as the above result worked out using our new definition.

It can be seen that with the new definition, the distance of a cluster is obtained level by level from the leaf to the node that represents the cluster. It is this way that the subject distance will be defined in the next sub-section.

B. Subjective distmce The subjective distance of a cluster is defined similar to  that of an objective distance defined above. The concept of subjective distance is based on the concept of subjective proportion described at the beginning of Section 11. We also take the cluster of A l l  as an example. The objective proportion among its child clusters is 10: 5: 5, namely 0.5: 0.25: 0.25.

distances of all the child clusters are d, ,  d2, ..., d,,, respectively, then the subjective distance of the cluster is:  The definition of the subjective distance of a cluster is quite similar to that of the objective distance. in each definition, the distance is obtained from the bottom to the top level by level. Each step deals with two kinds of distance.

The first kind is obtained from those contained in the child clusters and these distances are assimilated with a weight into the parent cluster.

The second kind is the distance generated during the course of using the parent cluster to represent all its child clusters. There is difference between the two definitions. For the objective one, the constant number ?1? i s  simply added for the reason that from the lower level to the upper level next to it, the number of edges is always 1 .  But in the case of the subject distance, the difference between the subjective proportion and the objective proportion i s  measured.

After the subject proportions are placed into the views of the nodes shown in Figure 3, a taxonomy tree with nodes, objective proportions, and subjective proportions can be got, as shown in Figure 4. The subjective distance of A21 is ((0.5-0.4)2 + (0.1-0.2)2 + (0.4-0.4)*)?? + (0 X 0.4 + 0 X 0.2 + OX0.4) = 0.1414. And similarly, we can get the subjective distances of A22, A23 as 0, 0.5656, respectively. Therefore, we are finally able to get the distance of the root cluster A1 1 as ((0.2-0.5)? + (0.4-0.25)2 f (0,4-0.25)2)?n + (0.1414XO.5 f 0 X 0.25 + 0.5656 X 0.25) = 0.579.

Figure 4. The subjective distance definition.

*the numbers mean the subjective proportion.

C. Synthetic distance After two kinds of distances, objective and subjective,  ate defined, we can combine them together to get an improved distance definition.

Definition 2. The subjective distance of a cluster is the sum of two parts: the first part is the second-order Euclidian distance between the subjective proportion and the objective proportion among its child clusters; the second part is the  child clusters; and the objective distance of each leaf cluster is?0. If the subjective proportion of a cluster is PI: pz: ... pn;  Definition 3. The synthetic distance of a cluster in a taxonomy tree is the weighted sum of its objective distance and its subjective distance, the sum of whose weight is I , And the synthetic distance of a generalization alarm is the  objective distance of a cluster is do whose weight is (r, and fiequency-weighted sum Of the distances Of its sum of the synthetic distance of its elements. If the  the objective proportion is q l :  q2:.  ... qn; and the subjective     subjective distance of the cluster is d,, then the synthetic distance is:  d =ad,  +(I-a)d, (3 1 In this definition, we suppose that there is a coefficient Q that we know. But how can we get it? How to choose the value of this coeficient will be discussed later.

If the distance in Julisch?s clustering problem is replaced with the synthetic distance defined above, then we will easily solve the problem show in Figure 2. Suppose that the subjective proportion between S1 and 52 is 0.8: 0.2, and that between DI and D2 is 0.3: 0.7. It can be easily got that the subjective distance of the first resulted cluster (SI, D, 150) is 0 f ((0.8-0.3)2 + (0.2-0.7)2)?2 = 0.707 and thus the synthetic distance is 1.707. Similarly, the synthetic distance of the second cluster (S, Dl,  110) is 1.103, So the second cluster is better. Supported by this analysis, we can retain the second cluster and discard the first one. The choice made is satisfactory in that after obtaining the second cluster in Figure 2, the operator will get the information that S attacks D1 for 110 times. Based on his knowledge that the proportion between S1 and S2 is 0.8: 0.2, he can estimate that $1 attacked D1 for about 88 times while S2 attacked D1 for 22 times or so. This is nearly the nature of the alarm cluster in which SI appeared 80 times and S2 appears 30 times. Analogously, after getting the first cluster (S 1 ,  D, 1 50) in Figure 2, the operator will guess according to his knowledge that D1 and D2 appeared approximately 45 times and 105 times, respectively. But this is quite apart from the nature of the cluster in which D1 and D2 appeared 80 and 70 times, respectively. With this example, we know that our subjective distance really works.

The subjective distance, one may think, is of no use if the human operator ?drills down? into the cluster to see the alarms as specific as he wants. But this is not consistent with the purpose of ?clustering? which is applied to decrease the great amount of data to a smaIl number of clusters. Besides, the number of alarms triggered is generally very large which makes it almost impossible to study the alarms or clusters one by one or in a considerably low level.

D. Getting the biases and belieji of operators It seems that so far, we have solved the problem that  Julisch encountered. But how can we obtain the subjective distance if all the subjective proportions are unknown. Our first intuition is to let the operator input the proportions in his mind into the system and edit them whenever he changes his mind about the proportions. This seems easy and perfect, but it is another burden on the operator. After all, our purpose is to help the operator, not to make more trouble for him.

Based on the observation that nodes with more descendants generally appear more frequently (but it is not always true, and in some circumstances, it is quite the contrary), we can decide the proportions by counting the descendant leaf nodes. By this mean, we can get the  proportion among A3 1, A32, A33 in Figure 4 as 1 : 1 : 1 ,  that between A34 and A35 as 1: 1 ,  and that among A21, A22, A33 as 3: 1: 2. But the proportions obtained this way may be quite different from the subjective proportions in the operator?s mind. Therefore, we should have a better approach.

Using the historical data to trace the subjective proportion is another approach. After studying the historical data for a considerable period of time, the subjective proportion will be close to that the historical data of events presents. The effect of an event is closely related to the time when it occurred. An approximate relationship between the time and the degree of effect of a historical event on the subjective proportion, for instance, is shown?in Figure 5.

Figure 5.  Different weight of historical data  The point to is a time point when the operator investigated the alarms most recently, and T is the period of time within which the events are taken into account. Pis a parameter to be determined. Of course this is only an example and we can draw other kinds of lines with the same trend. In order to make our system leam the subjective proportions from the historical data, we would define a 6 - function first. Let a be an alarm, and n be a node in a taxonomy tree, define  1, n f a , 0, n e  a.

6 (a)= (4)  And then we can, according to the relationship shown in Figure 5 ,  get the weight of any node n in the taxonomy trees:  where t(a) is the time when alarm a occurred. With the weight of every node, which is trained from the history data, the proportions can be obtained. These proportions are used as approximations of the subjective proportions.

There is much to do about how the values of parameters B and Tare selected and how the shape of the line or curve is determined in Figure 5. Furthermore, we can combine these methods for an improved approach. For instance, historical data can be used to obtain the approximate proportions; and these proportions can be adjusted by the human operators whenever they want to. But this is out of     the scope of this paper. In this paper, we suppose that the subjective proportions have been obtained before being used,  Tree  111. EXPERIMENTS AND CONCLUSIONS  We took a set of 19462 alarms to test the effect of the subjective distance on the clustering results. Three taxonomy trees have been constructed in advance (see Table I . )  and the subjective proportions have been manually input, too.

Data rype Number of Number of layers nodes  SourceIP AtlackType  DestinationlP  Character 6 172 Character 5 1 80 Character 2 13  After the objective distance is replaced with the synthetic one, we can get the clusters one by one using Claus Misch?s method with different values of the parameter U .

The corresponding results are shown in TabIe 2.

U  Number of clusters  Numberof prim a l m s  Numbermean of layers Objective  TABLE 11. USING SYNTHETIC DISTANCE IN CLUSTERING  1.0 0.9 0.S 0.7 0.6 0.5 21 24 25 25 24 24  76 85 8s 9 s  I05 120  1.842 1.861 1.860 1.92s 2.033 2.107  1.842 1.861 1.860 i 1.925 2.033 2.107 distance mean  Subjective distance mean  i 1.384 1.015 0.912 0.860 ? 0.769 0.732  With the definition of subjective distance, we have  improved the clustering method that Claus Julisch forwarded.

The new method can solve the problem, indicated in Figure 2, which cannot be solved with the old method. A subjective distance will make the human operator believe that, given the cluster, what he sees is the nature of the event alarms, and thus will help save his time that otherwise he would spend to ?drill down? into the cluster to see more detailed information.

So far as we know, other clustering problems will probably be improved with a subjective distance similar to that we define in this paper. One aspect of our future work will be to generalize the subjective distance and apply it in more clustering problems. How to get the parameters in Figure 5 i s  another aspect of our future work.

