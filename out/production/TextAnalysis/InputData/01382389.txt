Proceedings of the Third Intecnational Conference on Machine Learning and Cybernetics, Shanghai, 26-29 August 2004

Abstract: Comparison of time series is a key issue in data mining of  time series database. Variation or extension of Euclidean distance is generally used. However Euclidean distance will vary much when time series is to be stretched or compressed along the time-axis. Dynamic time warping distance has been proposed to deal with this case, but its expensive computation limits its application. lo this paper, a novel distance based on a new linear segmentation method of time series is proposed to avoid sneh drawbacks. Experiment results in this paper show that the proposed method achieves significant speedup UP to about 20 times than Dynamic lime warping distance without aenuacy decrease.

Keywords:  warping distance  1. IntMduction  Time series; Dynamic Time Warping; Segmented time  Time series database is a set of time series, each of which is an order list of real values measured at equal intervals. Sometimes, we connect all the set of time series to be a very long time series for convenience (hereafter, we simply call them time series or sequences). In recent years, lots of work has been done on data mining of time series.

Das et al [ l ]  have introduced how to find the association rule from time series, Debregeas and HebrialI21 proposed a cluster algorithm for large amount of time series database, Keogh and Pazzani [3] presented a scalable classification algorithm for time series database. The foundation of all the work above is comparison of time series, in which Euclidean distance or its variation is typically used.

However, Euclidean distance can be an extremely brittle distance measure [4], it may be vary much when time series is to be stretched or compressed along the time-axis.

Dynamic Time Warping Distance (DTWD) can fix the gap of Euclidean distance effectively. It allows time series to be stretched or compressed along the time-axis; moreover, it can compare the similarity of time series with different lengths. Consider figure 1, A) and B) illustrate  point-to-point matching relationship between two time series when computing Euclidean distance and DTWD. ~.

However, the com- putation of DTWD is too time-consum ing to be used in  . I D x ) s a 4 o I o Q I  time series mining.

Therefore, various kinds of algorithms have been proposed  --I to accelerate the ~ ........ ILW ..,... ~ ~ ~ ~ . i . . Y . . ~ ~ ~ i  0 , 0 2 0 3 1 ~ 1 0 1 1  1~~ ...... L..-~~.~, Figure1 A)Euclidean distance require computing of one-to-one point match B)Dynamic DTWD kf-91.

time warping find the best match In this paper, we  propose a novel linear segmentation technique of time series, and defme Feature Points Segmented Time Warping Distance (FPSTWD) based on it. The FPSTWD algorithm takes advantage of the fact that we can efficiently approximate most time series by a linear segmentation. Our proposed method speeds up DTWD by a large constant, which depends on the compressed ratio of time series after linear segmentation. Besides, our method outperforms Euclidean Distance in accuracy and with the cost of a little speed decrease.

The rest of this paper is organized as follows. Section 2 contains a brief introduction of the classical DTWD algorithm. Section 3 introduces a new linear segmentation technique of time series, called Feature Points Segmentation (FPSegmentation) and defines FPSTWD based on it. In Section 4 we experimentally compare FPSTWD, DTWD and Euclidean distance on several real world datasets. At last, brief conclusions will be given in section five.

Following, we defined some notations used in this paper as shown in Table 1.

2. Dynamic time warping distance  DTWD is used extensively in matching of voice, audio  0-7803-8403-2/04/$20.00 a2004 IEEE  mailto:miningant@hotmail.com mailto:fofeir@etang.com mailto:yfhu@fudan,edu.cn     xi  al  Time series 0 Null time series The 1 th element in time series X  - IF1 Length of time seriesx  -  Table 1 Some notations used in this paper  , Notation I Definition Notation Definition I  - 2s I Segmentation of time series x I Dbarc DP L PdjStancefunction P =1,2,???,? medical simals. It is firstly introduced to data mining cumulative  community by Bemdt and Clifford [lo]. DTWD is a robust measurement which allows time series to be stretched or compressed along the time-axis and can compare the  , similarity of time series with different lengths. Let us give a brief definition of DTWD and its dynamic programming solution.

Definition 1 Given any two time series, ? and j? , DTWD is defined as follows:  D,(o,o)=O, D,(Zo)=D,(o,7)=-, Dw(,?, s) = Dhe (head(*?),head(?))  I Dw(%rest(7)), 0, (resr(9, j9, { 0, (rest(.?), resf(?)) + min DTWD can be calculated efficiently using a dynamic  programming technique [ l l ]  based on recurrence relation yw(i, j) , whose time complexity is O(I 2 I ? I y I) .

Definition 2 Given any two time series 2 and y ,  the recurrence relation yw(i,  j)(i=1,2;..,I?I, j = 1 , 2;..,1 TI) for .? and y isdefinedasfollows:  , .

r,(i,i) = Dhc(l?i, Y j )  The dynamic programming algorithm fills in the table of  The rest part of time series after  Time series ?s elements from to the  Dynamic Time Warping Distance  Iistances as the computation proceeds. Figure 2 illustrates the process. The last element yw(l 2 1.1 j I) in the table is the final DTWD. In the computing process, we  can also get the row 5 DTWD between  ?[l:i] and y ron I  which is stored row 4 in the most top  cell of the i-th mw i column. At the row 2 same time, we  get the DTWD hehueen and roiv I  ?[I: j] which is stored in the mOSt left cell of the j-th  col I col 2 c d  3 Figure2 Cumulating distance table between i =< 3,4,3 >and j=<4,5,6,7,6,6>  row.

3. Linear segmentation and FPSTWD  DTWD is not suitable for data mining of large data set because of its expensive computation. By a new linear segmentation of time series, we proposed a new distance which can be regard as approximation of DTWD. The new distance, called Feature Points Segmented Time Warping Distance (FF?STWD), reduces the distance computation greatly, and keeps the same accuracy as DTWD.

According to physiological experiment, human?s optical system divides smooth curve into several l i e  segments,     Proceedings of the Third lnternationd Conference on Machine Laming and Cybernetics, Shanghai, 26-29 August 2004  1 7 7 A G f i 7 R  Figure3 Root mean square difference between original and segmented time series with three segmentation methods.

among which the most impressive point in time series at the first sight is the time series? extreme points [12]. According this result, we compress a time series by selecting some of its extreme points, called Feature Points, and dropping out the other points. By interpolating with these Feature Points, we get an approximation of a time series.

Definition 3 Feature Point of a time series 2 is the point that fits the following two conditions:  1) It must be the extreme points of the time series, and the ratio between the length of pink-holding and the length of time series must be larger than a certain threshold C.

2) Remark 1 The explanation of parameter C: it?s the  influential factor of the extreme point, which depends on application expert, the length of time series and the end user. The value of parameter C is typically between 0.001-0.1.

Remark 2 The meaning of parameter C: In stock technical analysis, William Index W%R and Random Index KDJ are computed using the maximum and the minimum value during 12 days and 9 days. Parameter C can also be defined as the duration of pink-holding (e.g., 12 or 9).

Feature Point Segmentation algorithm (FPSegmenta- tion) is used to select Feature Points and produce an approximation of a time series. We describe it as follows:  It is the first or last point of the time series.

Algorithm FPSegmentation (2, C, fS ) (1) Data preprocess: perform moving average and -  normalization to time series X to eliminate some noise;  set denoted by S;  - (2)  (3)  Select extreme points fmm time series X into a  Select Feature Points from S into a set denoted  by FPSet; (4) Connect all Feature Points from FPSet orderly,  we get a segmentation series is  of time series 2.

Only one pass through a time series is enough for  FPSegmentation algorithm. It takes linear time and constant memory. It?s time complexity is O(I 1 I )  .

Keogh and Pazzani [4] have proposed a Piecewise Aggregate Approximation (PAA) algorithm to segment time series, and Pram and Fink [7] have presented an Important Points based time series segmented algorithm (we call it IPSegmentation for short in this paper). We use ten data sets which are burst, hurstin, chaotic, danvin.

earthquake, leleccm, ocean, powerplant, speech and tide to compare three algorithms (length of time series vary from 1020 to 5oooO). Figure 3 illustrates m t  mean square difference between original and segmented time series with three methods, which measures the quality of segmentation or approximation. In this experiment, IPSegmentation can?t segment earchquake and tide datasets efficiently. No matter how to change its parameters, only very few line segments can be achieved, so we exclude these two datasets in Figure 3. From Figure 3, we can see FPSegmentation outperforms other two methods on most datasets. Besides, three methods have the same time complexity.

Based on the FPSegmentation algorithm, we define the Feature Point Segmented Time Warping Distance (FPSTWD) as follows.

Given any two time series 2 and y , which be is  and ys respectively after segmentation, the FPSTWD between .? and is defined as follows:  -  Definition 4  D , ( O , O )  = 0, 0, (2 ,O) = 0, (0, p ) = -3, D,QS.7S)=Db&l .YI  ) -s -s  where  Park etc.[S] have also defined segmented time warping distance, but which have a severe limitation: thenumber of segments of two time series must be equal. FPSTWD can compare with two time series whose numbers of segments are different, which ensures the best performance of segmentation instead of giving up segmentation quality to pursue the same number of segments.

4 J Ai  Cluster Dendrogram Cluster Dendrogram  Figure 4 A) hierarchical cluster with Euclidean Distance B) hierarchical cluster with FPSTWD  The time complexity of FPSTWD is O(I is II 7? I), which is a large constant times smaller than O(I 2 11 7 I) of DTWD. This constant depends on the compression ratio of FPSegmentation. The time complexity will reduce 25 times when compression ratio up to 808, 100 times when 90%.

4. Experiments  In data mining applications we typically have one of the following two situations [13].

a) Whole match Give a query sequence?, it needs to find the most similar sequence in time series database with same length or all the sequences that the distance between them is smaller than a certain threshold E ,  b) Subsequence match: Given query sequencex , y is a sequence much long than 2 .It needs to find a subsequence of 3 which is most similar with 2 or the distance between f and j is smaller than a certain threshold E .

For these two issues, two experiments are designed to compare the efficiency and accuracy of Euclidean Distance, DTWD and FPSTWD.

4.1 Experiment I: Clustering  - -.

Cluster experiment can be used to compare the performance of three distances on whole match. We cluster with Euclidean Distance, DTWD and FPSTWD to compare the cluster time and quality. We use hierarchical cluster method with system control dataset provided by eamonn (http://www.cs.ucr.eddu/-eamom). This dataset have 600 samples, each contains 60 points. In total, there are 6 classes, and 100 samples in each class.

Table 2 illustrates the cluster time and the numbers of correct cluster with above three distances.

Table 2 Cluster with three distances Distances Cluster Time Correct clusters  328.7s  FPSlWD 15.3s  In figure 4, we show the result of cluster with ten time series samples in which samples 1-5 are from class one and samples 6-10 from class two. As the result, FPSTWD outperforms Euclidean Distance greatly.

Although it has shortest time when using Euclidean Distance, the result of cluster is worst. When using DTWD or FPSTWD, they show almost the same accuracy but the latter?s speed has improved nearly 21 times than the former.

4.2 Experiment Ik Subsequence Search  From the result of cluster experiment, we can see that FPSTWD does better than both Euclidean Distance and DTWD on whole match problem. Following, we?ll compare the performance of subsequence match with three distances.

Experiment task is described as follows: Given the query sequence? , and 7 is a time series much longer in length than ? , it need to find a subsequence of which is most similar with ? . When using Euclidean distance, we can use multi-dimensional index to accelerate subsequence match.

However DTWD doesn?t obey the triangle inequality, the similar index techniques can?t be used. Here we use sequential scan and slide window technique to match the   http://www.cs.ucr.eddu/-eamom   Proceedings of the Third Intemational Conference on M a c h e  Learning and Cybernetics, Shanghai, 26-29 August 2004  subsequences. The experiment dataset we utilized is the Earthquake dataset which is provided by eamonn (http://www.cs.ucr.edd-eamonnf) which contains a time series with 4096 points. The query sequence comes from the following way: select a 100-length subsequence in random from Earthquake series, and warp this subsequence at some position along the time-axis. We take w as warp parameter, let w=5, 10, 15 get three subsequences used in our experiment.

Table 3 illustrates the result of the accuracy and the run time in experiment with Euclidean Distance, DTWD and FPSTWD.

Table 3 Subseauence match with three distances Distance Match accuracy Match measurement  Although it is the fastest in speed, Euclidean Distance has the worst accuracy. Compared with DTWD, FPSTWD has almost the same accuracy but 20 times faster than it.

5. Conclusions  The contribution of this paper is to propose a novel Feature Point Segmentation of time series, and to define a modification of DTWD based on it, which called FPSTWD.

The FPSTWD method produces an approximation of time series to achieve a large constant times speed-up than DTWD, and with no loss of accuracy.

We experimentally demonstrated our approach on several real world datasets and showed a speedup of one to  Debregeas.A, Hebrai1.G. ?Interactive interpretation of Kobonen maps applied to curves?, Proceedings of the and Data Mining, New York, pp. 179-183, August 1998.

Ke0gh.E. Pazzani.M, ?An enhanced representation of time series which allows fast and accurate classification, clustering and relevance feedback?, Knowledge Discovery and Data Mining, New York, pp. 239-241, August 1998.

Keogh.& Pazzani.M, ?Scaling up Dynamic Time Warping for Data mining Applications?, Proceedings Discovery and Data Mining, Boston, pp.285-289, August 2000.

Park& Kim& and Cbu.W, ?Segment-based approach for subsequence searches in sequence databases?, In Proceedings of the 16th ACM Symposium on Applied Computing, Las Vegas, pp. 248-252, November 2001.

Kim.S, Park.S, and Chu.W, ?An index-based approach for similarity search supporting time warping in large sequence databases?, In Proceedings of 17th ICDE, Heidelberg, Germany, pp. 607-614, April 2001.

Pratt.K.B, Fink.E, ?Search for patterns in compressed time series?, International Journal of Image and Graphics, Vol. 2, No.], pp. 89-106.2002.

Rabiner.L, Juang.B.H, ?Fundamentals of speech recognition?, Prentice Hall, Englewood Cliffs, 1993.

Vullings.H.J.L.M, Verhaegen.M.H.G, and Verbrugge n.H.B, ?ECG Segmentation Using Time Warping?, Advances in Intelligent Data Analysis, pp. 275-285, 1997. two orders of magnitude.

Acknowledgements  [lo] Berndt.D.J, CliffordJ, ?Using dynamic time warping to find patterns in time series?, In Working Notes of the Knowledge Discovery in Databases Workshop, Washington, pp. 359-370, July 1994.

[ll] Bemdt.D.J, Cli0rd.J. ?Finding patterns in time series: A dynamic programming approach?, Advances in Knowledge Discovery and Data Mining, AAAUMIT, pp. 229-248, 1996.

We are grateful to Ke0gh.E. and Fo1ias.T. for their provided datasets at The UCR Time Series Data Mining Archivelhttp://www.cs.ucr.edu/-eamonflSDMNindex.ht ml].

