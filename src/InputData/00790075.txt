1999 IEEE lntemational Fuzzy Systems Conference Proceedings  August 22-25, 1999, Seoul, Korea

Abstract  In this paper, we introduce a novel technique, called FARM, for mining fuzzy association rules. FARM employs linguistic terms to represent the revealed regularities and exceptions. The linguistic representation is especially useful when those rules discovered are presented to human experts for examination because of the affinity with the human knowledge representations. The definition of linguistic terms is based on fuzzy set theory and hence we call the rules having these terms fuzzy association rules.

The use of fuzzy technique makes FARM resilient to noises such as inaccuracies in physical measurements of real-life entities and missing values in the databases. Furthermore, FARM utilizes adjusted difference analysis which has the advantage that it does not require any user-supplied thresholds which are often hard to determine. In addition to this interestingness measure, FARM has another unique feature that the conclusions of a fuzzy association rule can contain linguistic terms. Our technique also provides a mechanism to allow quantitative values he inferred from fuzzy association rules. Unlike other data mining techniques that can only discover association rules between different discretized values, FARM is able to reveal interesting relationships between different quantitative values. Our experimental results showed that FARM is capable of discovering meaningful and useful fuzzy association rules in  an effective manner from a real-life database.

Keywords: data mining, knowledge discovery in databases, fuzzy association rules, linguistic terms, interestingness measure.

linguistic representation makes those rules discovered to he much natural for human experts to understand. The definition of linguistic terms is based on fuzzy set theory and hence we call the rules having these terms f u u y association rules.

Unlike other data mining algorithms (e.g. [ l ,  111) which utilize user-supplied thresholds to identify interesting associations, FARM employs an objective interestingness measure, called adjusted difference [2-5], to mine fuzzy association rules. The use of this technique has the advantage that it does not require any user-supplied thresholds which are often hard to determine. Furthermore, FARM also has the advantage that it allows us to discover both positive and negative association rules. A positive association rule tells us that a record having certain attribute value (or linguistic term) will also have another attribute value (or linguistic term) whereas a negative association rule tells us that a record having certain attribute value (or linguistic term) will not have another attribute value (or linguistic term).

Many data mining algorithms (e.g. [ I ,  111) require the conclusions of rules to be crisp and hence quantitative values cannot be inferred from those rules. To be more effective, FARM is able to deal with class boundaries that are fuzzy and to associate qualitative attribute values with quantitative values. This provides a mechanism for FARM to allow quantitative values be inferred. Such mechanism equipped our technique with a unique feature that interesting associations between different quantitative attribute values can be revealed whereas other data mining techniques can only discover association rules between different discretized intervals.

1. Introduction 2. Related Work  An important topic in data mining research is concerned with the discovery of association rules [I] .  An association rule describes an interesting relationship among different attributes and we refer to such relationship as an association in this paper. Existing algorithms (e.g. [ I l l )  involve discretizing the domains of quantitative attributes into intervals so as to discover quantitative association rules.

These intervals may not be concise and meaningful enough for human experts to easily obtain nontrivial knowledge from those rules discovered. Instead of using intervals, we introduce a novel technique, called FARM @uzzy - Association Rule Miner), which employs linguistic terms to represent the revealed regularities and exceptions. The  An example of an association rule is ?90% of transactions that contain bread also contain butter; 3% of all transactions contain both of these items.? The 90% is referred to as the confidence and the 3%. the support, of the rule. Let I = { i l ,  i2, .... i,,,) be a set of binary attributes called items and The  a set of transactions. Each transaction t E T i s  represented as a binary vector with t[k] = 1 if t contains item ix and t[k] = 0, otherwise, fork = 1, 2, ..., m.

An association rule is defined as an implication of the form X a r where X c I ,  Y c I ,  and X n Y = +. The rule X * Y holds in T with support defined as Pr(X U Y) and confidence defined as Pr(Y I X). An association rule is interesting if and only if its support and confidence is greater than some user-  0-7803-5406-0/99/$10.00 ?1999 IEEE Ill-I217    supplied threshold. Association rules of such type are often referred to as boolean association rules. Since boolean association rules are defined over binary data, they are rather restrictive in many different areas and hence a lot of recent effort has been put into the mining of quantitative association rules 1111.

Quantitative association rules are defined over quantitative and categorical attributes. In [ 111, the values of categorical attributes are mapped to a set of consecutive integers and the values of quantitative attributes are first discretized into intervals using equi-depth partitioning, if necessary, and then mapped to consecutive integers to preserve the order of the valueslintervals. And as a result, both categorical and quantitative attributes can be handled in a uniform fashion as a set of <attribute, integer value> pairs. With the mappings defined in [ 111, a quantitative association rule is mapped to a set of boolean association rules. After the mappings, the algorithms for mining boolean association rules (e.g. [l]) is then applied to the transformed data set.

For the mining algorithms such as that described in [ 1, 111 to determine if an association rule is interesting, its support and confidence have to be greater than some user- supplied thresholds. A weakness of such approach is that many users do not have any idea what the thresholds should be. If it is set too high, a user may miss some useful rules but if it is set too low, the user may he overwhelmed by many irrelevant ones.

Furthermore, the intervals in quantitative association rules may not he concise and meaningful enough for human experts to obtain nontrivial knowledge. F u u y  linguistic summaries introduced in [I21 express knowledge in linguistic representation which is natural for people to comprehend. An example of linguistic summaries is the statement "about half of people are middle aged." In addition to fuzzy linguistic summaries, an interactive top- down summary discovery process which utilizes f u u y  is-a hierarchies as domain knowledge has been described in [9].

This technique aims at discovering a set of generalized tuples such as <technical writer, documentation>. In  databases which consist of both quantitative and categorical attributes.

3. FARM for Mining Fuzzy Association Rules  A first-order fuzzy association rule can be defined as a fuzzy association rule involving one linguistic term in its antecedent; a second-order fuzzy association rule can be defined as a fuzzy association rule involving two linguistic terms in its antecedent and a third-order fuzzy association rule can be defined as a fuzzy association rule involving three linguistic terms in its antecedent, etc. To perform search more effectively, we propose to use an evolutionary algorithm. FARM is, therefore, capable of mining fuzzy association rules in  large databases by an iterative process.

3.1. Linguistic Terms  Given a set of records, D, each of which consists of a set of attributes J =  ( I , ,  I z ,  ..., In}, where I , ,  I., ..., I ,  can be quantitative or categorical. For any record, d E !D, d[IJ denotes the value i, in  d for attribute I ,  t J. For any quantitative attribute, I ,  E J, let dom(f,) = [ lv ,  U,] c 93 denote the domain of the attribute. A set of linguistic terms can be defined over the domain of each quantitative attribute. Let &,, r = I ,  2, ..., s, be linguistic terms associated with some quantitative attribute, I ,  t J. 4, is represented by a fuzzy set, L,,, defined on dom(f,) whose membership function is pL,  such that  The fuzzy sets L,, r = 1, 2, . . ., sv are then defined as  for all i, E dom(f,). The degree of compatibility of i, t dom(f,) with some linguistic term &, is given by U ,  (i,,).

' Ly,' . '  contrast to association rules which involve implications between different attributes, fuzzy linguistic summaries and ~ For ~ any categorical attribute, I ,  E J, let  different attributes. The idea of implication has not been taken into consideration and hence these techniques are not developed for the task of rule discovery.

can define a set of]inguistic terms, &,, = 1, 2, ..,, m,, for IvE Jwhere &, is represented by a fuzzy set, L,,, such that  The aoolicabilitv of fuzzv modeling techniaues to data L", =+ mining hai'also been discussed in [SI- Civen'a series of ' Y ,  fuzzy sets, a,, 2 2 ,  .. ., a., conditional (context-sensitive) F~~~ c - M ~ ~ ~ ~  (FCM) method is &le to reveal the rule.

Using the above technique, we can represent the original attributes, J, using a set of linguistic terms, L= { &  based models within a family of patterns by considering I v = 1, 2, where S, = m, for their vicinity in  a feature space along with the similarity of categorical attributes. Each linguistic term is represented by the values assumed by a certain conditional variable a fuzzy set and hence we have a set of fuzzy sets, L = ( L ,  I (context) [SI. Nevertheless, the conditional FCM method v =  1, 2, ..., n, r =  1, 2, ..., S,]. Given arecord, d t D, and can only manipulate quantitative attributes and it is for this a linguistic term, &, E L, which is represented by a fuzzy reason that this technique is inadequate to deal with set, L,, E L, the degree of membership of the values in 4  n, r = 1, 2. ...,  Ill-1218    with respect to L ,  is given by p b , , ( d [ I v ] ) .  The degree,  A4,, ( d ) ,  to which d is characterized by L,, is defined as A&,(d) = ~ & , ~ ( d [ / ~ l )  If A&,(d)=l, d is completely characterized by the term 4,. If A&, ( d )  = 0 ,  d is undoubtedly not characterized by the term L,,. If O <  kLw, ( d )  < 1 ,  d is partially characterized by the term f,,. If d [ / J  is unknown, ALv, ( d )  = 0.5 which indicates that there is no information available concerning whether d is characterized by the term f,, or not.

In fact, d can also be characterized by more than one linguistic terms. Let U, be a subset of integers such that q =  { v I .  v2, _.., v,) where v I ,  v2. ..., v, t { 1, 2, _.., n ] ,  v I  # v2 # . . . # v, and I@ = m 2 1, We further suppose that Jq be a subset of Jsuch that Jq = {/" I v E q ] .  Given any Jp it is associated with a set of linguistic terms, Lv,. r = 1, 2, _.., sv where sq = n s v  . Each Lv, is defined by a set of linguistic  terms, L,,,,,LV2, ..... hmFm E L. The degree, A4,, ( 4 ,  to which d is characterized by the term Lpu is defined as  =q  If I dLpq6 I> 1.96 (the 95 percentiles of  the normal  distribution), we can conclude that the association between Le and f,,,, is interesting. If d > +1.96, the presence  of Le implies the presence of &,. In other words, it is more likely for a record having both Le and 4,. We say that Le is positively associated with 4,. If dLm6 <-1.96, the absence of L* implies the presence of 4,. In other words, it is more unlikely for a record having L# and &, at the same time. We say that Le is negatively associated with  4u6  4,.

3.3. Formation of Association Rules  If the association between Le and is found to be interesting, there is some evidence for or against a record having f,,,, given it has Lw Based on an information theoretic concept known as mutual information, a confidence measure, called weight of evidence, to represent the uncertainty of the fuzzy association rules is defined in p-51 as  3.2. Identification of Interesting Associations  In order to decide whether the association between a linguistic term, L*, and another linguistic term, f,,,,, is interesting, we employ the adjusted difference [2-5] which is defined as  where zLpqvub is the standardized difference [2-51 given by  e is the sum of degrees to which records are expected Lw%  to be characterized by &and and is calculated by VV ZdexL,,+  (3) eLpqb = ,=I  "ill=, 3 %exL,,ub and yLpqh is the maximum likelihood estimate [2-51 of the  variance of zLmc and is given by  associated with &, whereas the weight of evidence is negative if L* is negatively associated with f& Based on this confidence measure, a fuzzy association rule is in the form of  L@ Lpq[wL.b j .

Since L* is defined by a set of linguistic terms, L,,,,,,Lv,, ,.... Gm,, E L, we have a high-order fuzzy  association rule, L,,,,, A L,,>, A. . .AL" ,"~~ LPq[wLMc j where v l .  v2, ..., v,  E q.

3.4. The FARM in Details  First of all, a set of first-order fuzzy association rules is found using adjusted difference analysis. After these rules are discovered, they are stored in RI .  RI  is then used to generate second-order rules which are, in turn, stored in R2.

R2 is then used to generate third-order rules that are stored in R, and so on for 4th and higher order. The details are given in Fig. I .  The terminate function in Fig. 1 implements the following termination criteria: (i) terminate when the best and the worst performing chromosome differs by less than 0.1%; (ii) terminate when the total number of generations specified by the user is reached; and (iii) terminate when no more interesting rules can be identified.

For the evolutionary process, FARM encodes a complete set of fuzzy association rules in  a single chromosome in such a way that each gene encodes a single rule. Specifically, given the following m-th order rule,  111-1219    A,, A L,,,, A... A LvmTm a LPy[wLm6 1, it is encoded in FARM by the allele given in Fig. 2.

rules or within one.

depicted in Fig. 5.

An example of it is graphically  I ) 2) 3) begin 4) t = O ; 5 )  Populutlun[r1 = lnitidize(R,,d; 6 )  firness(Pupulation[tI): 7 )  while not terminute(Population[t]) do 8) begin  RI = (first-order fuzzy association rules); for(m = 2; I R,II 5 minnrles; m + +) do  9) t = t + l ; IO) 11) fit"ess(Popul~tl"n[tJ); 12) end 13) 14) end  15)  Population[t] = replace(Populotion[r - 11);  R,n = decuddthe fittest individual in Populotion[t]);  Fig. 1 .  Algorithm FARM.

[TI FI ...... Fl Fig. 2. An allele representing a m-th order fuzzy association rule.

3.5. Initialization of Populations  FARM generates different sets of m-th order rules by randomly combining the (m - 1)-th order rules discovered in the previous iteration. The details of the initialization process are given in the initialize function in Fig. 3. The chrom;.aIle/e, in Fig. 3 denotes the j-th allele of the i-th chromosome. The rund,(R) function returns a m-th order allele constructed by randomly combining in elements in  R.

In our experiments, popsize was set to 30 and the number of alleles in each chromosome was set to nalleles = IRm-lI.

I )  population initialize(Rwd 2) begin 3) R =  (allconjunctsin theantecedentofallrs R- t ) ; 4) 5) begin 6) 7) chrom,.allelej = rond,(R); 8) end 9) return uchrom, :  for (i  = I :  i <popsize; i + +)do  for (r = I ;  j L nalleles; j + +) do  IO) end Fig. 3. The inriulize function  3.6. The Genetic Operators  The genetic operators used by FARM are implemented in the reproduce function shown in Fig. 4 .  The select function uses the roulette wheel selection scheme [71 to select two different chromosomes, chroml and chroml, from the current population. These two chromosomes are then passed as arguments to the crossover function.

The crossover(chroml, chromz) function uses the two- point crossover operator [7]. The crossover points are randomly chosen so that they can either occur between two  (b) after E ~ O S S O Y ~ ~ Fig. 5 .  An example of a two-point crossover (the think borders indicate the rule boundaries.)  The mutation function, which is different from the traditional mutation operator [71, is given in Fig. 6. The random function returns a real number between 0 and 1 and the constant pmutation contains the mutation rate.

mutotion(nchrom) begin  R = (all conjunct, in the antecedent of all r E R*,); for (r = 1 ; j 5 nolleles; j + +) do begin  if random <prnutation then nchrom.allelej = rond,dR);  end end  Fig. 6. The murotion function.

The steady-state(Popu/ation[t - 11, nchrom,, nchrom,) function in reproduce produces a new population, Population[t], by removing the two least-fit chromosomes in Population[t - 1 1 and replacing them with nchrorn, and nchrom2 while keeping the rest of the other chromosomes intact.

3.7. Selection and The Fitness Function  To determine the fitness of a chromosome that encodes a set of m-th order rules, FARM uses a performance measure defined in terms of the probability that the value of an attribute of a record can be correctly predicted based on the rules in  R = RI U R2 U _.. U U {rules encoded in  Ill-1220    the chromosome being evaluated). The details of predicting the value of an attribute will be given in Section 4. If the prediction is correct, we can increment an accuracy count associated with the chromosome whose fitness is being evaluated by one. By putting each of the N records in the database to the test, we define the fitness measure of each chromosome to be: (value of the accuracy count) t N .

4. Inferring Previously Unknown Values Using Fuzzy Association Rules  Given a record, f E dom(IJ x ... x dom(1,) x ... x dom(I,,), let f be characterized by n attribute values, ai, .__, g, ..., a,, where a, is the value to be predicted. Let 4, p = 1, 2, ..., s,, be the linguistic terms corresponding to the class attribute, Iy. We further let 1, be a linguistic term with domain dom(ll,)=(L,I,Lp2....,L,S~ ) .  The value of a, is given by the value of lr To predict the correct value of I,, FARM searches the association rules with Lpq E dom(1,) as consequents. For any combination of attribute values, a, p e cp, o f f ,  it is characterized by a linguistic term, Le, to a degree of compatibility, 1% ( I ) ,  for each k E { 1,2 ,  . .., s,J.

Given those rules implying the assignment of I&,,, L* ~L,9[wL,c] ,  for all k E ( G (1,  2, ..., ss), the evidence for or against such assignment is given by  W L  a = wLmQ ' 1 Q (f) (6) k E 5  P< v  Suppose that, of then  - 1 attribute values excluding a,, only some combinations of them, a[ll, __., a,,l, .__, acm with a ,  = (a, I i E { 1, 2, ..., n) - { p ) ) ,  are found to match one or more rules, then the overall weight of evidence for or against the value of 1, to be assigned to Gq is given by  R  In case that I, is categorical, lp is assigned to if w , > w g , g = 1 , 2  ,..., s b a n d g * c  (8)  where s> (5 s,) is the number of linguistic terms implied by the rules. a, is therefore assigned to ipc E dom(1,).

If I, is quantitative, a novel method is used to assign an appropriate value to ar Given the linguistic terms, Lpl ,L  p2,...,Lps, , and their overall weights of evidence,  wl.w2,  ..., w let pi ( i , )  be the weighted degree of SP ' DM membership of i,, E dom(1,) to the fuzzy set Lpur U E { 1, 2, ..., s,). pi," ( i , )  is given by  u i D u ( i , ) = w u  . p ~ ~ ~ ( i , )  (9) where i, E dom(1,) and u = I ,  2, ..., sr The defuzzified  value, F-'( U L,,), which provide an appropriate value for  a, is then defined by  SY  U = l  where p k u u ( i )  =max(p>(i) ,ph(i))  for any fuzzy sets X and Y. For quantitative predictions, we use roof-mean- squared error as a performance measure. Given a set of test records, D, let n be number of records in D. For any record, r E D, let [ I ,  U ]  c 3 denote the domain of the class attribute.

We further let t, be the target value of the class attribute in r and o, be the value predicted by FARM. The root-mean-  5. Experimental Results  In order to evaluate the effectiveness of FARM, we applied it to a real-life database concerning with the agriculture business in mainland China. The database contains data obtained from a survey about the economic situations of 280 villages in 1992. The scope includes production process, organizational structure, and working capital, etc. This database consists of 280 records and each record is characterized by 167 attributes. There are 99.6% of records having missing values in at least one of the attributes. As an illustration, let us consider attribute Capital-of-transporfion in detail. We define the linguistic terms Very-low, Low, Moderate, High, Very-high, and Extremely-high for Capital-of-transportation (Fig. 7).

0 0, 0.1 10 ,m rm rm Capl.~ol.fr.n.p"l'f"n  Fig. 7.

transportation.

Definition of linguistic terms for attribute Capital-of  Using the linguistic terms described in Section 3.1, we applied FARM to the database. Among the fuzzy association rules discovered by FARM, the following rules are particularly interesting.

Investment-in-consmrcrion = Veq-high  Capitul-of~g~iculture~ = Veq-high  bvesrmenr-in-consmrcriun = Veq-high A Copiral-of-agriculrure = High  a Cnpilul-of-rrons,o~"ti~" = High [ 1.531  C ~ p i r a l - u / - l r a n s p o r l i ~ ~  = High [1.17]  s C~,irrrl-qf-rr~*sporrotion = High 13.511  The first one says that very high investment in construction tends to introduce high capital of transportation  Ill-1221    whereas the second one says that very high capital of agriculture is associated with high capital of transportation.

Based on these two rules, it is reasonable that both of these two factors is related to high capital of transportation. It is exactly what the third rule says. The fact that the weight of evidence of the third rule is substantially greater than the weight of evidence of the first and the second rules means that the capital of transportation is more likely to he high when both the investment in  construction and the capital of agriculture are very high at the same time.

Let us consider the following fuzzy association rule as well.

1ncome-of;ndumy = Very-low A Capirol-of-curnmerce-wdlfood-dr-beveroge = Very-low A Capi ra l -o~comrnerce -and- fuud-&-6~?~ ,~~~- [~~~)  = Very-low  Copiral-of-rmnsporrorion = Moderole [-4.80]  This rule states that there will not even he moderate capital of transportation when the income of industry and the overall and the self used capital of commerce and food & beverage are very low. This rule is an example of negative association rules. It should he noted that existing algorithms (e.g. [ I ,  111) are unable to discover negative associations. The ability of FARM to mine negative association rules is another unique feature of it.

Among the attributes in the database, one of them, called Capital-oftransportation, is identified as the class attribute for further experimentation. Of the 280 records, 220 are randomly selected for training and the others are used for testing. The attribute Capital-oftransportation is quantitative and the predictions on this attribute are therefore of quantitative values. Unfortunately, many data mining techniques (e.g. [ I ,  111) which can only classify a record into appropriate category are unable to give quantitative values as predictions. As a result, they are not readily applicable to this task. On the contrary, by representing attribute Capital-oftransportafion with a set of linguistic terms, FARM is able to produce predictions which are of quantitative values. The root mean squared error calculated by (11) over the class attribute Capital-of transportation for the database is equal to 4.5%. In other words, the predictions produced by our algorithm deviated from the target values by 4.5% in average.

6. Conclusions  We presented a novel algorithm, called FARM, which employs linguistic terms to represent the revealed regularities and exceptions in this paper. The definition of linguistic terms is based on fuzzy set theory and hence we call the rules having these terms fuzzy association rules.

Unlike other algorithms which discover association rules based on the use of some user supplied threshold such as minimum support and minimum confidence, FARM employs adjusted difference analysis to identify interesting associations among attributes without using any user supplied thresholds. FARM also has unique features that it  is able to discover both positive and negative associations and it uses a confidence measure, called weight of evidence, to represent the uncertainty associated with the fuzzy association rules. Furthermore, FARM has another unique feature that quantitative values can he inferred from fuzzy association rules. This allows interesting associations between different quantitative values to be revealed.

7. References  R. Agrawal, T. Imielinski, and A. Swami, ?Mining Association Rules between Sets of Items in Large Databases,? in Pror. of the ACM SIGMOD Int?l Con$, Washington D.C., May 1993, pp. 207-216.

W.-H. Au and K.C.C. Chan, ?An Effective Algorithm for Discovering Fuzzy Rules in Relational Databases,? in Proc. of the 1998 IEEE Int?l Con$ on F u u y Systems, Anchorage, Alaska, May 1998, pp. 1314- 1319.

K.C.C. Chan and W.-H. Au, ?An Effective Algorithm for Mining Interesting Quantitative Association Rules,? in Proc. of the 12th ACM Symp. on Applied Computing, San Jose, CA, Feb. 1997, pp. 88-90.

K.C.C. Chan and W.-H. Au, ?Mining Fuzzy Association Rules,? in Proc. of the 6th ACM Int?l Conf on Information and Knowledge Management, Las Vegas, Nevada, Nov. 1997, pp. 209-215.

K.C.C. Chan and A.K.C. Wong, ?A Statistical Technique for Extracting Classificatory Knowledge from Databases,? in [IO], pp, 107-123.

U.M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R.

Uthurusamy (Eds.), Advances in Knowledge Discovery and Data Mining, AAAWMIT Press, 1996.

D.E. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Learning, Addison- Wesley, 1989.

K. Hirota and W. Pedrycz, ?Linguistic Data Mining and Fuzzy Modelling,? in  Proc. ofthe 5th IEEE Int?l Conf on Fuuy Systems, New Orleans, LA, Sep. 1996, pp. 1488-1492.

D.H. Lee and M.H. Kim, ?Database Summarization Using Fuzzy ISA Hierarchies,? IEEE Trans. on Systems, Man, and Cybernetics - Part B: Cybernetics, vol. 27, no. 4, pp. 671-680, Aug. 1997.

[IO] G. Piatetsky-Shapiro and W.J. Frawley (Eds.), Knowledge Discovery in Databases, AAAYMIT Press, 1991.

I l l ]  R. Srikant and R. Agrawal, ?Mining Quantitative Association Rules in Large Relational Tables,?? in Proc. of the ACM SIGMOD lnt?l Conf, Monreal, Canada, June 1996, pp. 1-12.

[121 R.R. Yager, ?On Linguistic Summaries of Data,? in [IO], pp. 347-363.

