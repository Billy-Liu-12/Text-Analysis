A Predictive Tool for Nonattendance at a Specialty  Clinic

Abstract? The field of data analytics has recently garnered significant attention as a means of improving service, outcome and cost in healthcare. Health informatics tools to date are largely rules-based, static in knowledge-gathering capability, and are not well incorporated within standard clinical processes. We introduce a multivariate analysis tool, built at the user-client interface, directly from data extracted from thousands of EMRs, for automated decision making. The predictive algorithms created to date have been implemented in a variety of clinical scenarios, including ER triage of chest pain, selection of optimal diagnostic testing, and management of chronic illnesses. This technology has now been applied to prediction of patient compliance with scheduled appointments in a medical specialty clinic.

Approximately 16% of scheduled VA patients do not show for their scheduled appointments for Gastroenterology clinic.  This results in misallocation of provider resources and inefficiencies in health care delivery. The improvement in quality of care, patient outcomes and cost is potentially immense.

Keywords-multivariate analysis; big data analytics, clinic nonattendance

I. INTRODUCTION Informatics applications, automated for instant accrual and analysis of actual clinical data, leading to true knowledge management, for measureable improvement in business processes, is the game changer in the healthcare industry.

CIOs in hospital systems and insurers across the nation are collaborating with IT entities to build successful evidence- based models [1].

Healthcare informatics tools have been recently developed which marry clinical evidence-based data, collected in real time, to a data analytics e infrastructure that aggregates, assembles and analyzes that data, resulting in true value-added to service, outcome and cost. Prior applications of the system presented in this paper have included a predictive tool for emergency room patients with indeterminate chest pain [2].

These patients are routinely and needlessly admitted, undergo excessive testing, and result in greater than 5 billion dollars per year in unnecessary expenditures.

Such predictive tools, which are physician designed, customizable, automated, multivariate probabilistic systems,  within a generic e infrastructure, and functionalized by big data extracted directly from EMRs, for practicing clinicians, may lead to a virtually unlimited number of applications.

Given their physician pedigree, these applications are conceived and incorporable within clinical processes that are already accepted within traditional medical practice, and represent an innovative example of ?brick and click? convergence in health care.



II. NON-ATTENDANCE AT A SUBSPECIALTY MEDICAL CLINIC Medical clinics are all faced with the recurrent problem of appointments that are not kept by patients and not cancelled prior to the scheduled time- the so-called ?no show?. Such incidents, which are common and cumulative, create extreme inefficiencies in cost and quality of care delivered. Indeed, the issue has garnered significant attention within the Upstate New York VA area of operations- VISN 2- with a published figure of an average 23, 750 no show appointments during each of four consecutive quarters in 2008/2009 [3]. This problem has persisted.

To overbook each clinic for a certain number of ?no shows?, estimated at 15% for most clinics, and ranging between 13.6% and 23.1%, is not a good use of resources, and may lead to increased waiting times should all patients attend [4-5].

Telephoning all patients or SMS messaging before their appointments, either by an actual staff member or by an automated system, leads to only nominal reductions in no shows [6-8]. Labor intensive changes are often necessary.

Studies to date have attempted to identify patient demographic and behavioral characteristics that are linked to nonattendance at medical subspecialty clinics. These include waiting times for an appointment, time of day, doctor shopping behavior, female gender and age [9-11].

Solutions to this problem typically address one or two variables only, require branch-tree guidelines, rely on ?point totals?, or are difficult to integrate within existing automated clinic processes [12-13].

What is needed is a multivariate, real time, automated, updatable and scalable solution that is available at any PC     interface. Such an approach is the hallmark of informatics- using prior events and multiple patient characteristics to predict patterns of patient behavior. Predicting such behavior will, in turn, permit the administrator to more elegantly devise an appointment schedule that is accommodative and efficient, to optimally meet the needs of both the patient and the facility.

Automated Bayesian probabilistic models (BNs) are well suited to multivariate analysis, and are advantageous in the context of systematic review. BNs are known for their transparency and are designed to deal with uncertainty; hence, they are attractive in complex modeling problems. The probabilistic inference capability of BNs facilitate predictions about unobserved data that could allow for filling of data gaps.

In addition, BNs, when incorporated within machine learning technology, support complex optimizations [14]. Machine learning algorithms facilitate the aggregation and processing of vast amounts of complex data quickly and easily, and automatically detect and promote significant relationships between variables.



III. OBJECTIVE To develop a reliable predictive tool to assess the likelihood of future appointment compliance in a medical subspecialty clinic.



IV. METHODOLOGY A series of queries were selected, composed of demographic, clinical and administrative features selected from CPRS/Vista (EMR) records of show and no show patients from the Gastroenterology clinic at the Stratton VA Medical Center in Albany, New York [Table 1]. The data was entered into the EMR in real time during the clinic visit.

A consecutive number of patients scheduled over a prescribed period of time were selected for the overall study. Each query,  together with an answer extractable by a VISN 2 IT specialist, from each of the patient records, along with their attendance history (outcome) represents a complete data set, which are used in the training, testing and validation segments of the study. The data was placed in an automated multivariate on- line matrix. The data was completely de-identified, thereby fulfilling all HIPAA requirements.

A total of 6,176 data sets were extracted from CPRS/Vista, representing all GI clinic appointments over a one-year period.

Data sets were excluded from the study for multiple reasons, including administrative cancellations, duplicated appointments, unnecessary indications, case referrals to other facilities and incomplete data entries. The remaining 4,774 sets, representing 669 no shows, and 4,105 shows, constituted the study data base.

The data sets were divided into a ?training? phase for functionalizing the tool, comprised of a random 50% of the ?no show? patients and an equal number of ?show? patients (334/334), for a total of 668 patients, and a ?test? phase, comprised of 25% ?no show? patients added to a number of ?show? patients that mirrored the overall clinic proportion of 1:6:: no shows:shows (168/1008), for a total of 1176 patients.

The remaining 25% of ?no show? data sets were reserved for further validation phases. Each ?training? phase and ?testing? phase, together, created a single ?patients analysis?.

The VA support specialist provided an XL file that contained the data sets, representing each patient on a row, with the outcome and the various determinants (answers to a set of variables) regarding that patient along that same row. Each column occupied a different determinant. The VA IT specialist, with access to the database, performed a SELECT statement on the data set to create the appropriate format.

The statistical relationship between each variable answer and each of the two outcome alternatives, ?show? and ?no show?, is represented by the term ?likelihood ratio? (LR). A LR=1 represents neutrality, or no apparent effect of that variable answer on the likelihood of one outcome over another. A LR between 0 and 1 represents a negative association with that outcome, while a LR greater than 1 represents a positive association.  The further from 1 a LR is, be it less or greater than 1, the more statistically significant the LR is on the probability scoring of the outcome alternatives. The software automatically calculates the LRs for the patient data sets randomly selected for that ?training phase?, as a prelude to a patients analysis. LRs for each variable and its answers, and each outcome, are instantaneously available for review on the site [Table 2].

The web site, which aggregated and assembled the de- identified data, has antivirus, encryption, firewall and password protection. All information was backed up on a regular basis. The entire protocol and the web site received prior approval by the Information Security and Privacy officers at Albany Stratton VA Medical Center, and the VA Institutional Review Board.

The predicted likelihood for each of the patients in the ?test? phase to show or no show for an upcoming appointment, based on LRs created in the ?training? phase, were represented by a probability ?score?, the result of automated analysis of the test data set. The score is a whole number between 0 and 100. The higher the score, the more likely is the outcome ?show?. The score for each patient (data set) was stored for comparison with the known result.

An intensive seven step process that serves as a ?roadmap to validation? has been published [14]:  1. Preliminary modeling 2. Global modeling 3. Naive modeling 4. Focused modeling 5. Manual modeling 6. Cross-Validation 7. Documentation  These steps were applied:   A) Utilizing the unique functionality of the software, the data sets were randomly parsed again and again, at the user-client interface, as separate patients analyses, or ?runs?, each containing a unique training set and testing set. Data sets were used for either training or testing within a single run, not both.

B) Each run was saved and could be reviewed alongside  the others, data set for data set if so desired, to demonstrate overall reliability and validity of the functionalized predictive tool, and to detect internal inconsistencies in the modeling.

C) For each test run, statistical results were generated  and displayed on the site. Employing this instantaneous iterative process, one can initiate the  process of designating a predictive ?threshold score? for the entire test set, which maximized the number of no shows classified accurately, while minimizing the total number of patients meeting the threshold score, thereby maximizing sensitivity and specificity.

D) A receiver-operator-characteristic (ROC) curve was  plotted for each test set (run) to calculate classification accuracy, thereby determining the optimal threshold score by the feature of interest- predicting the no show patient population. The curves were calculated by comparing the predicted values for the feature of interest to the known results in each test set, on a case specific basis. [Graph 1]

V. RESULTS AND DISCUSSION A total of seven ?patients analyses? were generated from the data base; their optimal ?designated threshold? scores, as calculated by ROC curve, are listed [Table 3]. Listed adjacent to the threshold scores are two endpoint statistical results available on the site, which were optimized as well by the ROC- calculated threshold score:  1. Percentage (and number) of the 168 total no show  appointments in each test set predicted correctly.

2. Percentage (and number) of the 1176 total  appointments (both show and no show) in each test set that fell at or below the designated threshold.

The narrow range of calculated designated threshold scores (87-91) supports the reliability of the data base.

The internal validity of the tool may be judged by the repetitively similar results among all seven independent analyses: almost 65% of the no shows patients were identified within the approximately 40% of the study population that fell below the designated threshold score.

Multiple runs have resulted in a ?percentage no shows predicted correctly? in the 60 -65% range,   approximately 4 fold greater than the 16% no show rate in the overall study population (p<.0001). These results demonstrated the ability to successfully identify the majority of patients at risk for not showing for an appointment by automated EMR-based multivariate analysis alone.

A ?post-analysis? process may follow the probability scoring- the personal telephone contacting of   those patients whose score falls below the designated threshold, by clinic personnel, so as to reinforce their compliance. If only 35-40% of scheduled patients need to be telephoned, representing 7-8 patients of 20 scheduled for a clinic session, significantly less time will be expended, resulting in significant improvement in administrative efficiency. This approach is considerably more focused than indiscriminant SMS messaging and automated telephone calls.

Thus, the calculated threshold score, which, alone, identified those patients likely not to show for an appointment at a rate exceeding the expected no show rate by four-fold, may be followed by a human process to further optimize service, outcome and cost.

This study incorporates objective data retrieved directly from electronic medical records, to predict behavioral patterns.

Such a determination generally requires end points that are less rigorous in statistical methodology. Incremental improvement in predictability will be facilitated by the automated machine learning functionality which permits aggregation, assembly and analysis of unlimited additional  data sets. As more data sets populate the variable answer categories, LRs attain greater significance, and are increasingly capable of detecting more subtle nuances in patient behavior, and improvement in predictability. To quote from a 2009 AHRQ symposium, ?To not only answer the questions we cannot answer today, but to answer the questions we cannot envision today?.

