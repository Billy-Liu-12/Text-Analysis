Fuzzy-based Methods for Privacy-Preserving Data Mining

Abstract As more and more organizations are collecting and sharing data about their customers, there is a growing concern about violation of customer privacy. While some of the sharing is for the benefit of general public such as to understand disease behavior in medical research, individuals are concerned about violation of their privacy. The middle ground is found through privacy- preserving data mapping. Here, sensitive attributes of data are mapped to another domain so that original values are not revealed and yet the original associations are retained. In this paper, we compare a set of fuzzy- based mapping techniques in terms of their privacy- preserving property and their ability to retain the same relationship with other fields. In particular, our contribution is on four fronts: (i) modification of the fuzzy function definition; (ii) introducing seven ways to combine the different functional values for a data item into a single value; (iii) using several similarity metrics to compare the original data with the mapped data; (iv) measuring the effect of mapping on derived association rule. The paper presents preliminary results in this direction and proposes future work in this area.

Key Words:  association rules, data correlation, data mapping, sensitive data, similarity measures   1. Introduction   With the increased data collection and data analysis activity in all aspects of life, there is a fear of losing individual privacy [1, 2, 3]. More importantly, organizations are increasingly collaborating to collectively analyze the data that they have collected.

Even in such collaborations, individual member organizations are cautious about sharing sensitive attributes of their data with others. One alternate is to map sensitive attributes of data to another domain such that its relationship with other attributes remains unaltered (e.g., association with other non-sensitive attributes) and providing the altered data for sharing [1]. For example, when U.S. Census Bureau periodically collects data from the public, it provides privacy by only asking users for a  range (e.g., salary range) rather than specific salary. This also encourages individuals to provide such information [9, 10, 11].

However, there are other situations where the data collector (e.g., hospitals, insurance companies, credit card companies, etc.) have the exact data about their clients but they cannot share some of the data attributes (e.g., social security number, date of birth, etc.) due to their own privacy policies or privacy polices enforced by a Federal agency (e.g., HIPAA, FERPA). However, such sharing may benefit to identify underlying problems or relationships among a problem and the associated attributes of an individual with those problems. For example, if certain population is suffering from severe depression, then the underlying causes could be found by identifying attributes that they all share. These attributes could be maintained by individual organizations that may consider them as private.

In such cases, one of the solutions that has been suggested is to perturb or map the data [1]. While such mapping should not enable the receiving party to derive the original values from the mapped values, they should also be able to retain the same association with other attributes as the original data. Such challenges also frequently arise when a data owner decides to offload the data mining activity to a third party such as a cloud operator. Here, the data owner needs to provide data to the cloud operator with a risk of losing privacy over the sensitive data. So, it is best for the data owner to transform the sensitive fields and provide the modified data to the cloud operator. However, there should be a straight forward and computationally simple means for the data owner to map the association rules derived from the modified data to those that apply to original data.

In summary, the problem of privacy-preserving data mining deals with two conflicting issues during the mapping: (i) mapping should not reveal the original data value (ii) Mapped fields should retain their original relationship with other attributes.

Several approaches have been suggested for this mapping [1, 3, 5, 6, 7]. In particular, recently, fuzzy mapping has been suggested to preserve privacy [5, 6, 7].

Here, the sensitive value range is partitioned into different segments and a function is defined on each segment. In   DOI 10.1109/ITNG.2011.68     this way, a given data value may be mapped to different values depending on which of these functions are applicable to it. From these values, the authors randomly pick a value.

In this paper, we expand on their work [5, 6, 7] by proposing different means to combine these functions instead of randomly picking up one of the values. We determine the efficacy of each of the combining functions based on their correlation between the original data and the final mapped values.

The paper is organized as follows. In section 2, we provide a brief overview of the previous work. Section 3 describes our extension to the previous work. Section 4 summarizes some results from the extended functions.

Finally, section 5 summarizes the contribution of the paper and explains scope for future work.

2. Previous work   One of the earliest work in the privacy-preserving data mining is by Agrawal and Srikant [1]. Here, the authors investigate how different privacy preserving perturbations affect the association rules. In particular, they investigate how the original data distribution can be estimated based on the perturbed data. They have considered three types of perturbation: Value class membership where every data value corresponding to a class (e.g., bin in a histogram) is assigned the same value. They also look into value distortion where data is perturbed by a random number.

They determined that such random perturbation with Gaussian distribution is most effective. The random perturbation idea was further explored by Kargupta et al [2]. They observe that random perturbations do not necessarily preserve data privacy.  Clifton et al summarize different techniques for privacy preserving [3]. Here, some high-level techniques are suggested for solving the problem. In a more limited context of encrypted data mining, Singh et al suggest the use of Jaccard similarity function to derive relationships between attributes [4].

Our work mainly concentrates on three recent papers [5, 6, 7]. Here, the authors propose a fuzzy-based mapping to map sensitive numerical data to another domain for privacy-preservation. Similarly, they propose a decision-tree based approach for mapping categorical data values. In this paper, we concentrate on the numerical data and fuzzy-based mapping.

Let us take a brief look at their method. If the sensitive field values are in the range min-max, then this range is divided into k fuzzy sets. Each data value is mapped into one of these five fuzzy sets. In order to distinguish one value of the set from another, a numerical affinity (they refer to it as intensity) term is used. In other words, numerical data is mapped into different fuzzy sets, yet retaining their value in terms of an affinity value.  In order  to show the efficacy of their mapping, they compute a correlation coefficient that relates the original value to the fuzzy set and the intensity. Their mapping functions are defined as follows.

f1(x)  = 0.99   if x=min = (m2-x)/(m2-min) if min < x < m2 = 0.0   if x ? m2  fi(x) = 0.0   if x ? mi-1 = (x-mi-1)/(mi-mi-1) if mi-1 < x < mi = 0.99   if x=mi = (mi+1-x)/(mi+1-mi) if mi < x < mi+1 = 0.0   if x ? mi+1  fk(x) = 0.0   if x ? mk-1 = (x-mk-1)/(max-mk-1) if mk-1 < x < max = 0.99   if x = max  Here, k is the number of fuzzy sets, min and max are  the minimum and maximum values of x, respectively, and m1, m2,?, mk are the mid points of the k fuzzy sets. In other words, (min?m1?m2) is fuzzy set 1, (m1?m2?m3) is fuzzy set 2, ?, (mk-1?mk?max) is fuzzy set k. Each function determines the affinity of a data value to each fuzzy set. Based on the above definition, it is clear that a data value may belong to one or more fuzzy sets.

To be more specific, let us take an example set of data values in the range (0 to 100) with k = 3.  Here, min=0, max=100, m1=25, , m2=50, and , m4=75. So (0..50) is fuzzy set 1, (25..75) fuzzy set 2, and (50..100) fuzzy set3, with mid points of 25, 50, and 75, respectively. If we consider x=5, it is clearly in fuzzy set 1. As per the above mapping f1(5) = 45/50 or 0.9. However, x = 45 falls in two fuzzy sets 1 and 2. Here, f1(45) = 5/50 or 0.1 and f2(x)=20/25 or 0.8.  Further, to distinguish elements in one fuzzy set with another, the authors add the corresponding fuzzy set number to the affinity value. For example, for x=5, the mapped value will be 1+ f1(5)  or 1.9. Similarly, x=45 may be mapped to either 1.1 or 2.8. The authors do not state whether the choice between these is random, the highest, the lowest, or the average.

In order to ensure that the mapping does not lose the relationship of this mapped sensitive attribute with other attributes, the authors compute a correlation coefficient between the original data and the mapped value.

However, they do not investigate the degree of privacy offered by the resulting mapping.

In this paper, we extend this work by modifying the mapping function. We also propose several methods to determine the final mapped value when a data value belongs to different fuzzy sets.  In addition, we compare these methods in terms of the resulting association rules they produce and the similarity between the original data and the mapped data, in each case.

3. Proposed mapping   When we look at the above function, it may be observed that when values lie in the min-m1 or mk-max, they are mapped to only one fuzzy function. Yet, the above mapping function maps them to different affinity values. In some sense, affinity is a proxy to the probability with which a data value is likely to belong to a fuzzy set. So if a data value belongs only to one fuzzy set, its affinity to that set should be 1.0. If we assume that the range of each fuzzy set is equal (i.e., m1-min = m2 ? m1 = max-mk = mi+1-mi), then we may observe that the total affinity being 1 is valid for all ranges of x except the ones in 0..m1 and mk..max, where k is the number of fuzzy functions. To rectify this deficiency, we suggest the following mapping function.

f1(x)  = 1.0   if min ? x < m1 = (m2-x)/(m2-m1)  if m1  ? x < m2 = 0.0   if x ? m2  fi(x) = 0.0   if x ? mi-1 = (x-mi-1)/(mi-mi-1) if mi-1 < x < mi = 1.0   if x=mi = (mi+1-x)/(mi+1-mi) if mi < x < mi+1 = 0.0   if x ? mi+1  fk(x) = 0.0   if x ? mk-1 = (x-mk-1)/(mk-mk-1) if mk-1 < x < mk = 1.0   if mk ? x ? max  The new function overcomes the deficiency of the  earlier method.

These functions basically assume equal-sized ranges.

However, this may not always be feasible. To see the need for non-uniform ranges, we need to go back to the basis on which the ranges of fuzzy functions have been defined in the first place. Suppose a data owner has run association rules on the original data and found that the ranges of interest for x are: 0-20, 10-40, 20-60, and 80- 100. For example, it was found that persons in the age 0- 20 and in the range 80-100 are more prone to accidents; similarly, persons in the range 10-40 are more prone to depression; and persons in the age 20-60 are more prone to ocular disease. In this case, it makes logical sense to define the fuzzy functions in line with the ones identified by the association rules. Accordingly, in this example, we could define four fuzzy functions as follows: f1: [0,20] [0,1.0];f2:[10,40] [0,1.0];f3:[20,60] [0,1.0];f4:[80,100]  [0,1.0]. The mid points of these four functions are m1=10, m2=25, m3=40, and m4=90, respectively. Here, the fuzzy functions are defined independently depending on the underlying association rules. We should notice that the range of values 60-80 are not covered by any of the four functions. So we define a fifth fuzzy function: f5:[60,80]  [0,1.0] with m5=70.   In case, some of the x  ranges are not covered by any of the defined ranges, then we need to define additional fuzzy functions to cover these ranges also. In this example, the fuzzy functions would be as follows.

f1(x)  = x/10   if 0 ? x < 10 = (20-x)/10  if 10  ? x < 20 = 0.0   if x ? 20 f2(x)  = (x-10)/15  if 10 ? x < 25 = (40-x)/15  if 25  ? x < 40 = 0.0   if x ? 40 f3(x)  = (x-20)/20  if 20 ? x < 40 = (60-x)/20  if 40  ? x < 60 = 0.0   if x ? 60 f4(x)  = (x-80)/10  if 80 ? x < 90 = (100-x)/10  if 90  ? x < 100 = 0.0   if x ? 100 f5(x)  = (x-60)/10  if 60 ? x < 70 = (80-x)/10  if 70  ? x < 80 = 0.0   if x ? 60  Of course, there are several variations of these. For  example, we could replace the linear function used here with a non-linear mapping function. However, due to space limitation, we do not discuss these alternatives in this paper.

Having defined the fuzzy functions, the next step is to map the functions into appropriate values. Using the method in [5,6,7], we can convert each function value by adding a distinct integer for the affinity value. For example, if we consider x=15, f1(x)= 0.5 and  f2(x)= 0.33.

These values are represented as 1.5 and 2.33, respectively, by the previous work. The question now is how to convert this value into a single value. Since earlier work did not suggest any particular method for combining these two functions into a single mapped value, we suggest the following seven methods.

(i) Arithmetic average: Take the average of the different values. In the above example, the mapped value would be (1.5+2.33) or 1.915.

(ii) Normalized average: If we consider the affinity as a probability, then we should first normalize the affinity values so that they sum to 1.0. In this case, 0.5 and 0.33 will be normalized to 0.5/0.83 and 0.33/0.83 or 0.60 and 0.40, respectively. We can now take the weighted average (1.60*0.6+2.4*0.4)  or 2.0.

(iii) Weighted average: Take weighted average of different values. For example, in the example, take weighted average of 1.5 (with a weight of 0.5) and 2.33 (weight of 0.33). This will be (1.5*0.5+2.33*0.33)/0.83 or 1.83.

(iv) Higher affinity value: Take the value with higher affinity. In the example it would be 1.5.

(v) Random pick: Randomly pick one of the values. In the example, it would be either 1.5 or 2.33. But this seems     like the least desirable alternative.

(vi) Maximum value: Pick the maximum value. For example, between 1.5 and 2.33, pick 2.33.

(vii) Minimum value: Pick the minimum value. In the above example, pick 1.5.

Another important extension that we propose is the metrics by which the relationship between the original data and the mapped data are compared. The earlier authors suggested correlation coefficient as a method. But we extend it by proposing the use of other similarity measures [8]. In particular, we choose the following measures, in addition to the correlation coefficient. First, we define the following:  a = b = c = d = ? e=?   Pearson?s correlation coefficient:  /    (1) Jaccard similarity measure:  (2)  Dice similarity measure:   (3)  Cosine similarity measure:   (4)  4. Results   In order to check the efficacy of the proposed mapping, we have evaluated the methods using several data sets available at the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/).

Since the previous paper have chosen the Adult set (http://archive.ics.uci.edu/ml/datasets/Adult) with 32561 instances, we start with this set.

We have conducted two types of tests to evaluate the effect of mapping on data mining. First, we have computed the similarity of the original data to the mapped data. For this we have used the four similarity measures mentioned above. Second, we have compared the association rules derived from the mapped data with the ones derived from the original data. In the following, we summarize our results.

4.1. Similarity measures   In order to compare the similarity of the original data with the mapped data, we have used the four metrics  defined in (1)-(4).  Here, we summarize the results for the 7 mappings.

First, consider the correlation coefficient measure with the original mapping suggested by the authors as well as the ones derived by our mapping. We have evaluated the correlation with all seven combining methods.. We consider three function with ranges: f1 ranging from 0-50, f2 ranging from 25-75, and f3 ranging from 50-100 with mid points as 25, 50, and 75 respectively.  The results are summarized in Table 1. Row R1 represents the correlation coefficient with earlier mapping [7]. Row R2 represents results with our mapping. It should be noted that the two mappings defer in the regions 0-50 (due to f1) and 50-100 (due to f3).  Not surprisingly, the minimum value choice (M7) and the random choice (M5) have the lowest correlation coefficients in both mappings. In addition, it may be observed that correlation with our mapping is smaller than that of the earlier mapping [7]. When we are attempting to hide the data from the data miner for privacy purposes, it is best to have small correlations between the original and the mapped data. So we claim that the privacy offered by our mapping is better than the earlier scheme [7]. It may also be observed that the maximum choice (M6) has the highest correlation and hence won?t be so suitable for preserving privacy.

Let us now look at other similarity measures--- Jaccard similarity (J), Dice similarity (D), and Cosine similarity (C). These are summarized below. Interestingly, all the proposed similarity measures show results similar to the correlation coefficient measure. However, the variation is not as distinct as the correlation. This means that we need to do further investigations to determine the right similarity measures for this mapping.

M1 M2 M3 M4 M5 M6 M7 R1 0.88 0.89 0.94 0.84 0.61 0.97 0.56 R2 0.73 0.90 0.81 0.75 0.54 0.94 0.21 J1 0.05 0.06 0.06 0.06 0.05 0.07 0.04 J2 0.06 0.05 0.06 0.06 0.06 0.07 0.05 D1 0.10 0.11 0.11 0.11 0.10 0.12 0.08 D2 0.11 0.10 0.11 0.11 0.11 0.12 0.09 C1 0.96 0.99 0.99 0.98 0.96 0.99 0.95 C2 0.97 0.98 0.98 0.98 0.95 0.99 0.93 Table 1. Similarity of mapped data with original data computed with original and proposed mappings   In the current case, the original ranges values of age range from 1-100 while the mapped ones range from 1-4.

Thus, in computing the similarity measures, using (1)-(4), the P values (original values) will be much higher than the Q values (mapped values). To ensure that both are in the same range, we normalize them and recomputed the measures. The metrics for the normalized values are shown in Table 2. These are prefixed with N to indicate that they are derived from normalized values. Obviously,     the correlation coefficient is unaltered with the normalization. But there is a significant difference in the values of other metrics. But the overall relative difference among the measures remains the same as before. We are currently investigating this aspect and attempting to determine which normalization helps us better understand the similarity.

M1 M2 M3 M4 M5 M6 M7 NR1 0.88 0.89 0.94 0.84 0.61 0.97 0.56 NR2 0.73 0.90 0.81 0.75 0.54 0.94 0.21 NJ1 0.95 0.97 0.97 0.92 0.81 0.94 0.63 ND1 0.98 0.98 0.99 0.96 0.89 0.97 0.77 NC1 0.98 0.98 0.99 0.96 0.90 0.996 0.81 NJ2 0.89 0.76 0.78 0.94 0.92 0.81 0.99 ND2 0.94 0.86 0.88 0.97 0.96 0.90 0.997 NC2 0.97 0.90 0.92 0.99 0.97  0.91 0.998 Table 2. Similarity measures with normalized values for both original and mapped data  4.2. Effect on derived association rules  One of the primary motivations for doing the suggested mapping is to hide sensitive attribute information from the data miner. To be more specific, let us take a scenario where the data owner collects data (e.g., credit card company) and intends to derive association rules by data mining the data. Due to lack of expertise and computational resources, the data owner outsources the data to an outside agency (e.g., cloud operator). However, to protect the privacy of the sensitive attributes (e.g., Age in Adult data set), those attributes are mapped to another domain. When the data miner receives the modified data, it derives association rules (for example) corresponding to the presented data and returns them to the data owner.

The data owner now remaps the mapped sensitive attributes in the association rules back to the original domain. This process is illustrated in Figure 1. Only the remapped rules are meaningful to the data owner.

However, the main question that arises is: how accurate are the remapped association rules? In other words, did the mapping affect the semantics of the association rule mining? If so, to what degree? This is another measure of success of the privacy-preserving mapping. Here, we summarize the results we obtained with adult data set considered above.

Figure 1. Privacy preserving data mining process  For simplicity, we continue to consider age alone as the sensitive attribute. Suppose we have picked the random choice for mapping. Then, the association rules derived from the adult data set using Weka [12] are shown in Figure 2. Each rule has LHS and RHS. It also specifies how many records satisfy LHS (i.e., support) and how many satisfy both LHS and RHS. The number of RHS/number on LHS is referred to as the confidence.

That is also shown for each rule. The sets only shows those rules involving the age attribute (e.g., 9, 12, etc.).

Figure 2. Subset of rules derived with random choice  function.

Data owner Data Miner  Original data  Modified data  Mapping  Modified data  Association RulesAssociation  Rules Re-mapped Association  Rules  Reversing mapping  9. age='(1.77055-2.5137]' education=HS-grad 6737 ==> native- country=United-States 6199 conf:(0.92) 12. age='(1.77055-2.5137]' education=Some-college 5098 ==> native-country=United-States 4685 conf:(0.92) 13. age='(1.77055-2.5137]' education=HS-grad income=<=50K 6003 ==> native-country=United-States 5515    conf:(0.92) 15. age='(1.77055-2.5137]' education=HS-grad hours-per- week='(25.5-50]' 5500 ==> native- country=United-States 5052 conf:(0.92) 17. age='(1.77055-2.5137]' education=Some-college income=<=50K 4464 ==> native-country=United- States 4097    conf:(0.92) 18. age='(1.77055-2.5137]' education=HS-grad hours-per- week='(25.5-50]' income=<=50K 4922 ==> native-country=United-States 4509    conf:(0.92) 20. age='(1.77055-2.5137]' education=Some-college hours-per- week='(25.5-50]' 3601 ==> native- country=United-States 3294 conf:(0.91) 25. age='(1.77055-2.5137]' income=>50K 3668 ==> native- country=United-States 3328 conf:(0.91) 26. age='(2.5137-3.25685]' 5212 ==> native-country=United-States 4705 conf:(0.9) 27. age='(2.5137-3.25685]' hours- per-week='(25.5-50]' 4200 ==> native-country=United-States 3789 conf:(0.9)     Now, suppose the data owner is provided with these rules, he needs to map them back to the original domain for age attribute. Since the data owner knows both the original values and the mapped values, the conversion should not be difficult. For example, when we select one particular rule, say age='(1.77055-2.5137]' education=Some-college 5098 ==> native-country=United-States 4685    conf:(0.92)  This can be mapped to the original domain as: age={17-71} education=Some-college  ==> native- country=United-States Table 3summarizes the results with the seven mappings.

Sl# Type  Age LHS RHS RHS/  LHS 1 Original  data 17-37.5 4275 3905 0.91  2a Arithmetic mean  2 6453 5949 0.92 2b 17-53 6453 5949 0.92 3a Normalized  1.5 3934 3590 0.91 3b 17-35 3934 3590 0.91 4a Weighted  average 1.875- 2.406  6074 5598 0.92  4b 17-49 6074 5598 0.92 5a Higher  affinity 1.521- 2.140  5428 4992 0.92  5b 17-44 5428 4992 0.92 6a Random  1.771-  2.514 5098 4685 0.92  6b 17-71 7221 6673 0.924 7a Maximum 2-2.5 5428 4992 0.92 7b 17-44 5428 4992 0.92 7a Minimum  1.771-  2.514 4815 4413 0.924  7b 17-71 7221 6673 0.924 Table 3. The support and confidence summary with  original data and the seven mappings  5. Conclusion and Future work   Privacy-preserving data mining has become an important issue in today?s highly information analysis based research and marketing. This is an issue not only when data mining needs data mining requires data from different organizations (sources) but also when data mining is delegated to a third-party such as a cloud operator. While much work is done in terms of K- anonymity [9], L-diversity [10], and t-closeness [11].

While the initial work in this area started with data perturbation, the fuzzy-mapping approach is reasonably new [5,6,7]. In this paper, we have expanded their initial work in three fronts: (i) modified the fuzzy function definition; (ii) introduced seven ways to combine the different functional values for a data item into a single  value; (iii) used several similarity metrics to compare the original data with the mapped data. The results reported are preliminary in nature. Further work needs be done to test the sensitivity of these mappings to different types of data with distribution distributions.

6. References  [1] R. Agrawal and R. Srikant, ?Privacy-Preserving Data Mining,? Proc. ACM SIGMOD Conf., Dallas, TX, USA, 2000, pp. 439-450.

[2] H. Kargupta, S. data, Q. wang, and K. Sivakumar, ?Random-data perturbation techniques and privacy- preserving data mining,? Knowledge and Information Systems, Vol. 7, No. 4, May 2005, pp. 387-414.

[3] C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M.

Zhu, ?Tools for Privacy-preserving Distributed Data Mining,? ACM SIGKDD Explorations Newsletter, Vol. 4, No. 2, 2002, pp. 28-34.

[4] M.D. Singh, P.R. Krishna, and A. Saxena, ?A Privcay- preserving Jaccard Similarity function for Mining Encrypted Data,?  IEEE TENCON 2009 Proc., 2009, pp.

1-4.

[5] V. Vallikumari, S.S. Rao, K.V.S.N. Raju, K.V.

Ramana, and B.V.S. Avadhani, ?Fuzzy-based approach for privacy preserving publication of data,? Intl. J.

Computer Science And Network Security, Vol. 8, No. 1, 2008, pp. 115-121.

[6] E. Poovammal and M. Ponnavaikko, ?An Improved Method for Privacy Preserving Data Mining,? 2009 IEEE IACC, 2009, pp. 1453-1458.

[7] E. Poovammal and M. Ponnavaikko, ?Preserving Micro data Release: categorical and Numerical Data,? 2009 IEEE SETIT, March 2009, pages 5.

[8] S. Cha, ?Comprehensive Survey on Distance/Similarity Measures Between Probability Density Functions,? Intl. J. Mathematical Models and Methods in Applied Sciences, Vol. 1, No. 4, 2007, pp.

300-307.

[9] L. Sweeney, ?k-anonymity: a model for protecting privacy,? Int. J. Uncertainty, Fuzziness, and Knowledge- Based Systems, Vol. 10, No. 5, 2002, pp. 557-570.

[10] A. Machanavajhala, D. Kifer, J. Gehrke, and M.

Venkitasubramanian, ?l-Diversity: Privacy Beyond k- Anonymity,? ACM Trans. Knowledge Discovery from Data, Vol. 1, No. 1, 2007.

[11] N. Li, T. Li, and S. Venkatasubramanian, ?t- closeness: Privacy Beyond k-Anonymity and l-diversity,? IEEE 23rd Intl. Conf. data Engineering, ICDE 2007, 2007, pp. 106-115.

