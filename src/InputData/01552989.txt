Efficient Method of Combinatorial Item Set Analysis Based on Zero-Suppressed BDDs

Abstract  Manipulation of large-scale combinatorial data is one of the important fundamental technique for web information retrieval, integration, and min- ing. In this paper, we propose a new approach based on BDDs (Binary Decision Diagrams) for database analysis problems. BDDs are graph-based rep- resentation of Boolean functions, now widely used in sys- tem design and verification area. Here we focus on Zero-suppressed BDDs (ZBDDs), a special type of BDDs, which are suitable for handling large-scale sets of com- binations. Using ZBDDs, we can implicitly enumerate combinatorial item set data and efficiently compute set op- erations over the ZBDDs. We present some encouraging experimental results of frequent item set mining prob- lem for practical benchmark examples, some of which have never been generated by previous method.

1. Introduction  Manipulation of large-scale combinatorial data is one of the fundamental technique for web information retrieval in- tegration, and mining[16]. In particular, frequent item set analysis is important in many tasks that try to find inter- esting patterns from web documents and databases, such as association rules, correlations, sequences, episodes, clas- sifiers, and clusters. Since the introduction by Agrawal et al.[2], the frequent item set and association rule analysis have been received much attentions from many researchers, and a number of papers have been published about the new algorithms or improvements for solving such mining problems[7, 9, 17].

In this paper, we propose a new approach based on BDDs (Binary Decision Diagrams) for database analysis problems. BDDs are graph-based representation of Boolean functions, now widely used in system design and verifica- tion area. Here we focus on Zero-suppressed BDDs (ZB- DDs), a special type of BDDs, which are suitable for han- dling large-scale sets of combinations. Using ZBDDs, we  can implicitly enumerate combinatorial item set data and efficiently compute set operations over the ZBDDs.

For a related work, FP-Tree[9] is recently received a great deal of attention because it supports fast manipulation of large-scale item set data using compact tree structure on the main memory. Our ZBDD-based method is a similar ap- proach to handle sets of combinations on the main memory, but will be more efficient in the following points:  ? ZBDDs are a kind of DAGs for representing item sets, while FP-Trees are tree representation for the same objects. In general, DAGs can be more compact than trees.

? ZBDD-based method provides not only compact data structures but also efficient item set operations written in a simple mathematical set algebra.

We present some encouraging experimental results of fre- quent item set mining problem for practical benchmark ex- amples, some of which have never been generated by previ- ous method.

Recently, the data mining methods are often discussed in the context of Inductive Databases[4, 12], the integrated processes of knowledge discovery. In this paper, we place the ZBDD-based method as a basis of integrated discov- ery processes to efficiently execute various operations find- ing interest patterns and analyzing information involved in large-scale combinatorial item set databases.

2. BDDs and ZBDDs  2.1. BDDs  BDD is a directed graph representation of the Boolean function, as illustrated in Fig. 1(a). It is derived by reducing a binary tree graph representing recursive Shannon?s expan- sion, indicated in Fig. 1(b). The following reduction rules yield a Reduced Ordered BDD (ROBDD), which can effi- ciently represent the Boolean function. (see [5] for details.)  ? Delete all redundant nodes whose two edges point to the same node. (Fig. 2(a))  Proceedings of the 2005 International Workshop on Challenges in Web Information Retrieval and Integration (WIRI?05)     c  b  a  c cc  b  1 001 1 1 1  10 0 0 0  0 0   1 1 1  1 1   F  c  b  a  0 1        F  (a) BDD. (b) Binary tree.

Figure 1. BDD and binary tree: F = (a? b)? c .

x   f  jump  f f1f0  xx 00 11  f1f0  x 0 1  share  (a) Node deletion. (b) Node sharing.

Figure 2. Reduction rules of ordinary BDDs  ? Share all equivalent sub-graphs. (Fig. 2(b))  ROBDDs provide canonical forms for Boolean functions when the variable order is fixed. Most research on BDDs are based on the above reduction rules. In the following sec- tions, ROBDDs will be referred to as BDDs (or ordinary BDDs) for the sake of simplification.

As shown in Fig. 3, a set of multiple BDDs can be shared each other under the same fixed variable ordering. In this way, we can handle a number of Boolean functions simul- taneously in a monolithic memory space.

Using BDDs, we can uniquely and compactly repre- sent many practical Boolean functions including AND, OR, parity, and arithmetic adder functions. Using Bryant?s algorithm[5], we can efficiently construct a BDD for the re- sult of a binary logic operation (i.e. AND, OR, XOR), for given a pair of operand BDDs. This algorithm is based on hash table techniques, and the computation time is al- most linear to the data size unless the data overflows the main memory. (see [14] for details.)  Based on these techniques, a number of BDD packages have been developed in 1990?s and widely used for large- scale Boolean function manipulation, especially popular in VLSI CAD area.

b  a  0 1      b  aa 0 01   F1 F2 F3 F4  F1 = a ? b F2 = a ? b F3 = b F4 = a ? b  Figure 3. Shared multiple BDDs.

2.2. Sets of Combinations and ZBDDs  BDDs are originally developed for handling Boolean function data, however, they can also be used for implicit representation of sets of combinations. Here we call ?sets of combinations? for a set of elements each of which is a combination out of n items. This data model often appears in real-life problems, such as combinations of switching de- vices(ON/OFF), fault combinations, and sets of paths in the networks.

A combination of n items can be represented by an n-bit binary vector, (x1x2 . . . xn), where each bit, xk ? {1, 0}, expresses whether or not the item is included in the combi- nation. A set of combinations can be represented by a list of the combination vectors. In other words, a set of combina- tions is a subset of the power set of n items.

A set of combinations can be mapped into Boolean space by using n-input variables for each bit of the combination vector. If we choose any one combination vector, a Boolean function determines whether the combination is included in the set of combinations. Such Boolean functions are called characteristic functions. The set operations such as union, intersection, and difference can be performed by logic op- erations on characteristic functions.

By using BDDs for characteristic functions, we can ma- nipulate sets of combinations efficiently. They can be gener- ated and manipulated within a time roughly proportional to the BDD size. When we handle many combinations includ- ing similar patterns (sub-combinations), BDDs are greatly reduced by node sharing effect, and sometimes an exponen- tial reduction benefit can be obtained.

Zero-suppressed BDD (ZBDD)[13, 15] is a special type of BDDs for efficient manipulation of sets of combinations.

ZBDDs are based on the following special reduction rules.

? Delete all nodes whose 1-edge directly points to the 0- terminal node, and jump through to the 0-edge?s desti- nation, as shown in Fig. 4.

? Share equivalent nodes as well as ordinary BDDs.

Notice that we do not delete the nodes whose two edges point to the same node, which used to be deleted by the  Proceedings of the 2005 International Workshop on Challenges in Web Information Retrieval and Integration (WIRI?05)      x  Jump  f f  Figure 4. ZBDD reduction rule.

S(abc): abc S 000 0 100 1 010 1 110 0 001 0 101 0 011 0 111 0  S(abcd): abcd S 0000 0 1000 1 0100 1 1100 0 0010 0 1010 0 0110 0 1110 0 0001 0 1001 0 0101 0 1101 0 0011 0 1011 0 0111 0 1111 0  0 1  a a  b  c  d        b bb  c        S(abcd) S(abc)  S(abc) S(abcd)  0 1  a  b     BDD ZBDD  Figure 5. Example of ZBDD effect.

original rule. The zero-suppressed deletion rule is asymmet- ric for the two edges, as we do not delete the nodes whose 0-edge points to a terminal node. It is proved that ZBDDs are also gives canonical forms as well as ordinary BDDs un- der a fixed variable ordering.

Here we summarise the features of ZBDDs.

? In ZBDDs, the nodes of irrelevant items (never cho- sen in any combination) are automatically deleted by ZBDD reduction rule. In ordinary BDDs, irrelevant nodes still remain and they may spoil the reduction benefit of sharing nodes. (An example is shown in Fig. 5.)  ? ZBDDs are especially effective for representing sparse combinations. For instance, sets of combinations se- lecting 10 out of 1000 items can be represented by ZBDDs up to 100 times more compact than ordinary BDDs.

? Each path from the root node to the 1-terminal node corresponds to each combination in the set. Namely, the number of such paths in the ZBDD equals to the number of combinations in the set. In ordinary BDDs, this property does not always hold.

Figure 6. Explicit representation by ZBDD.

??? Returns empty set. (0-termial node) ?1? Returns the set of only null-combination.

(1-terminal node)  P .top Returns the item-ID at the root node of P .

P .offset(v) Selects the subset of combinations each of which does not include item v.

P .onset(v) Selects the subset of combinations in- cluding item v, and then delete v from each combination.

P .change(v) Inverts existence of v (add / delete) on each combination.

P ? Q Returns union set.

P ? Q Returns intersection set.

P ? Q Returns difference set. (in P but not in Q.)  P .count Counts number of combinations.

Table 1. Primitive ZBDD operations  ? When no equivalent nodes exist in a ZBDD, that is the worst case, the ZBDD structure explicitly stores all items in all combinations, as well as using an explicit linear linked list data structure. An example is shown in Fig. 6. Namely, (the order of) ZBDD size never ex- ceeds the explicit representation. If more nodes are shared, the ZBDD is more compact than linear list. Or- dinary BDDs have larger overhead to represent sparser combinations while ZBDDs have no such overhead.

Table 1 shows the most of primitive operations of ZB- DDs. In these operations, ?, 1, P.top are executed in a con- stant time, and the others are almost linear to the size of graph. We can describe various processing on sets of com- binations by composing of these primitive operations.

Proceedings of the 2005 International Workshop on Challenges in Web Information Retrieval and Integration (WIRI?05)    Data name #I #T avg|T | avg|T |/#I T40I10D100K 942 100,000 39 4.14% mushroom 119 8,124 23 19.32% BMS-WebView-1 497 59,602 2 0.40% basket 13,103 41,373 9 0.06%  Table 2. Statistics of typical benchmark data.

3. ZBDD-based Database Analysis  In this section, we discuss the method of manipulating large-scale item set databases using ZBDDs. Here we con- sider binary item set databases, each record of which holds a combination of items chosen from a given item list. Such a combination is called a tuple (or a transaction).

For analyzing those large-scale tuple databases ef- ficiently, basic problems of data mining, such as fre- quent item set mining[3] and maximum frequent item set mining[6], are very important and they have been dis- cussed actively in last decade. Recently, graph-based meth- ods, such as FP-Tree[9], are received a great deal of attention, since they can quickly manipulate large-scale tu- ple data by constructing compact graph structure on the main memory. ZBDD technique is a similar ap- proach to handle sets of combinations on the main mem- ory, so we hope to apply ZBDD-based method effectively in this area.

3.1. Property of Practical Databases  Table 2 shows the basic statistics of typical benchmark data[7] often used for data mining/analysis problems. #I shows the number of items used in the data, #T is the number of tuples included in the data, avg|T | is the aver- age number of items per tuple, and avg|T |/#I is the av- erage appearance ratio of each item. From this table, we can observe that the item?s appearance ratio is very small in many cases. This is reasonable as considering real-life problems, for example, the number of items in a basket pur- chased by one customer is usually much less than all the items displayed in a shop. For another example, the number of links from one web page is much less than all the web pages in the network. This observation means that we of- ten handle very sparse combinations in many practical data mining/analysis problems, and in such cases, the ZBDD re- duction rule is extremely effective. If the average appear- ance ratio of each item is 1%, ZBDDs may be more com- pact than ordinary BDDs up to 100 times. In the literature, there is a first report by Jiang et al.[10] applying BDDs to data mining problems, but the result seems not excellent due to the overhead of ordinary BDDs. We must use ZBDDs in stead of ordinary BDDs for success in many practical data mining/analysis problems.

Figure 7. ZBDD vector for tuple-histogram.

3.2. Tuple-Histograms based on ZBDDs  A Tuple-histogram is the table for counting the number of appearance of each tuple in the given database. In practi- cal databases, the same tuple often appears many times. For example, ?BMS-WebView-1? in Table 2 includes 59,602 records, and the most frequent tuple appears 1,533 times in the records. The top 10 frequent tuples appears 8,404 times in total. (Shares 14% in the records.)  Here we present a method of representing tuple- histograms by using ZBDDs. Since ZBDDs are rep- resentation of sets of combinations, a simple ZBDD distinguishes only existence of each tuple in the databases. In order to represent the numbers of tu- ple?s appearances, we decompose the number into m-digits of ZBDD vector {F0, F1, . . . , Fm?1} to represent inte- gers up to (2m ?1), as shown in Fig. 7. Namely, we encode the appearance numbers into binary digital code, as F0 rep- resents a set of tuples appearing odd times (LSB = 1), F1 represents a set of tuples whose appearance number?s sec- ond lowest bit is 1, and similar way we define the set of each digit up to Fm?1.

In the example of Fig. 7, The tuple frequencies are de- composed as: F0 = {abc, ab, c}, F1 = {ab, bc}, F2 = {abc}, and then each digit can be represented by a sim- ple ZBDD. The three ZBDDs are shared their sub-graphs each other.

Now we explain the procedure for constructing a ZBDD- based tuple-histgram from given tuple database. We read a tuple data one by one from the database, and accumu- late the single tuple data to the histogram. More concretely, we generate a ZBDD of T for a single tuple picked up from the database, and accumulate it to the ZBDD vector.

The ZBDD of T can be obtained by starting from ?1? (a null-combination), and applying ?Change? operations sev- eral times to join the items in the tuple. Next, we compare T and F0, and if they have no common parts, we just add T to F0. If F0 already contains T , we eliminate T from F0 and carry up T to F1. This ripple carry procedure continues until T and Fk have no common part. After finishing accu-  Proceedings of the 2005 International Workshop on Challenges in Web Information Retrieval and Integration (WIRI?05)    Figure 8. Tuple- and pattern-histogram.

mulations for all data records, the tuple-histogram is com- pleted.

Using the notation F.add(T ) for addition of a tuple T to the ZBDD vector F , we describe the procedure of generat- ing tuple-histogram FT for given database D.

FT = 0 forall T ? D do  FT = FT .add(T ) return FT  When we construct a ZBDD vector of tuple- histogram, the number of ZBDD nodes in each digit is bounded by total appearance of items in all tuples. If there are many partially similar tuples in the database, the sub-graphs of ZBDDs are shared very well, and com- pact representation is obtained. The bit-width of ZBDD vector is bounded by log Smax, where Smax is the appear- ance of most frequent items.

Once we have generated a ZBDD-based tuple- histogram, it is easy to extract the set of frequent tu- ples which appears more than ? times. By encoding the given threshold ? into binary code, we can compose an al- gorithm of bit-wise arithmetic comparison between ? and FT based on ZBDD operations. After execution of those ZBDD operations, the result of frequent tuples can be ob- tained as a ZBDD. The computation time is almost linear to total ZBDD size.

3.3. Pattern-Histograms based on ZBDDs  In this paper, a pattern means a subset of items included in a tuple. A pattern-histogram is the table for counting the number of appearance of each patterns in any tuple in the given database. An example is shown in Fig. 8.

In general, a tuple of k items includes 2k patterns, so computing a pattern-histogram is much harder than comput- ing a tuple-histogram. In many cases, it is difficult to gener-  Figure 9. ZBDDs for a tuple and all sub- patterns  ate a complete pattern-histogram for a practical size of tu- ple database. Therefore, conventional methods extract only frequent patterns which appears more than ?-times, for a given thresholds ?, within a feasible computation time and space[7].

Using the ZBDD-based data structure, we may have more compact representation than previous methods, as a number of similar patterns can be shared in ZBDDs, and in some cases, this makes possible to generate complete pattern-histograms which have never succeeded in previous methods. Figure 9 shows a ZBDD for a tuple T = abcde with five items and a ZBDD representing a set of all 32 pat- terns P = {1, a, b, c, d, e, ab, ac, bc, cd, abc, . . . , abcde} in- cluded in T . Clearly we can see that 2k patterns in a k- item tuple can be represented by only k nodes of ZBDDs.

As well as generating tuple-histograms, we can generate pattern-histograms by accumulating such a single ZBDD P for a set of patterns one by one, Here we summarise the pro- cedure for computing a pattern-histogram FP from a given database D as follows.

FP = 0 forall T ? D do  P = T forall v ? T do  P = P ? P.onset(v) FP = FP .add(P )  return FP  Unfortunately, ZBDDs grows larger as repeat- ing accumulations, and eventually may overflow the memory for some large examples. While tuple- histgrams are bounded by the total items in the tu- ples, pattern-histograms are not bounded and so many patterns will be generated.

However, if we have succeeded in generating a ZBDD- based pattern-histogram for a given instance, we can enjoy  Proceedings of the 2005 International Workshop on Challenges in Web Information Retrieval and Integration (WIRI?05)    very powerful data processing by using efficient ZBDD op- erations. It is interesting and important how large-scale in- stances we can generate complete pattern-histograms. The experimental results will be shown in later section.

In addition, we present an alternative procedure for gen- erating ZBDD-based pattern-histograms. We can generate a pattern-histgram FP from a complete tuple-histogram FT .

FP = FT forall v ? FT do:  FP = FP .add(FP .onset(v)) return FP  We have not determined which algorithm is faster in prac- tical environments. Anyway, the final form of ZBDD vec- tors must be the same if the two algorithms are computing for the same instance.

3.4. Utilities of Tuple/Pattern-Histograms  Once we generate tuple-/pattern-histograms using ZB- DDs, various operations can be executed efficiently. We show several examples in this section. Suppose that we have obtained F : {F0, F1, . . . , Fm?1}, the ZBDD vector repre- senting a tuple- or pattern-histogram.

? We can efficiently extract a subset of tuples/ patterns including a given item or sub-pattern P .

S = ?  Fk forall v ? P do:  S = S.onset(v).change(v) return S  Inversely, we can extract a subset of tuples/ patterns not satisfying the given conditions. It is easily done by computing  ? Fk ? S. After extract-  ing a subset, we can quickly count a number of tu- ples/patterns by using a primitive ZBDD operation S.count. The computation time is linearly bounded by ZBDD size, not depending on the amount of tu- ple/pattern counts.

? For given ?, we can extract all frequent tuples/patterns appearing more than ? times. Computation time is al- most linear to the ZBDD size. Repeating this proce- dure with different ??s, we can determine the threshold ?m to pick up the top m frequent tuples/patterns. Af- ter generating ZBDD-based histograms, it is quite easy to extract frequent sets with different ??s, while previ- ous methods need almost recomputing again for each ?.

? From ZBDD-based histograms, we can efficiently calculate indexes, such as Support and Confi- dence, which are often used in probabilistic/ statistic analysis and machine learning area.

Data name #T total|T | |ZBDD| Time(s) T10I4D100K 100,000 1,010,228 552,429 43.2 T40I10D100K 100,000 3,960,507 3,396,395 895.0 chess 3,196 118,252 40,028 1.4 connect 67,557 2,904,951 309,075 58.1 mushroom 8,124 186,852 8,006 1.5 pumsb 49,046 3,629,404 1,750,883 188.5 pumsb star 49,046 2,475,947 1,324,502 123.6 BMS-POS 515,597 3,367,020 1,350,970 895.0 BMS-WebView-1 59,602 149,639 46,148 18.3 BMS-WebView-2 77,512 358,278 198,471 138.0 accidents 340,183 11,500,870 3,877,333 107.0  Table 3. Generation of tuple-histograms.

ZBDD nodes Time(s) #Pattern 513,762 214.0 (> 2G)  Table 4. Pattern-histogram for ?mushroom?.

A feature of ZBDD-based method is to construct power- ful data structure on the main memory, and we can interac- tively execute various queries to the database. Moreover, it is very interesting that the queries can be specified by math- ematical set operations.

4. Experimental Results  4.1. Generation of Tuple-Histograms  For evaluation of our method, we conducted experiments to construct ZBDD-based tuple- and pattern-histograms for typical benchmark examples[8] used in data min- ing/analysis problems.

We used a Pentium-4 PC, 800MHz, 512MB of main memory, with SuSE Linux 9. We can deal with up to 10,000,000 nodes of ZBDDs in this machine. Table 3 shows the results of generating tuple-histograms. In this table, #T shows the number of tuples, total|T | is the total of tuple sizes (total appearances of items), and |ZBDD| is the num- ber of ZBDD nodes for the tuple-histograms. We can see that tuple-histograms can be constructed for all instances in a feasible time and space. The ZBDD sizes are almost same or less than total|T |.

4.2. Generation of Pattern-Histograms  Next we tried generating pattern-histograms for the same benchmark set. Within an available memory space (up to 10,000,000 ZBDD nodes), we succeeded in constructing a complete pattern-histgram only for ?mushroom?, which is a  Proceedings of the 2005 International Workshop on Challenges in Web Information Retrieval and Integration (WIRI?05)    Threshold ? Time(s) #Pattern 81 22.60 91,273,269 40 67.96 295,117,613 16 244.06 1,176,182,553  8 494.05 1,983,493,667 4 891.31 (> 2G) 1 1,322.48 (> 2G)  Table 5. FP-Tree-based method for ?mush- room?.

relatively small instance (Table 4). In this case, the pattern- histogram requires about 65 times more ZBDD nodes than the tuple-histogram for the same data.

The ?mushroom? pattern-histogram is implicitly repre- senting at least 2,000,000,000 patterns. (The counter over- flows the range of 32-bit integers.) The number of ZBDD nodes are 4,000 times smaller than number of patterns. This shows a great benefit of compression ratio obtained by ZB- DDs.

To compare with a previous method, we applied a fre- quent pattern mining program based on FP-Tree[9], to ex- tract the set of frequent patterns appearing more than ? times, for the same example ?mushroom?. The results are shown in Table 5. For smaller ??s, more patterns are ex- tracted, and the computation time increases up to hundreds or thousands of seconds. Notice that the FP-Tree-based method only extracts a set of frequent patterns for a given ?, but does not generates a complete histogram for all pos- sible patterns. Our ZBDD-based method generates a com- plete histogram for all patterns in 214 seconds, and it corre- sponds to computing frequent pattern sets for all ??s at once.

Based on ZBDD data structure, we need only 48 second of additional time to extract frequent pattern sets for all differ- ent ??s from 1 to 100, namely, only 0.48 second needed for each extraction in average. The result shows that ZBDD- based implicit method is especially effective for handling a huge number of patterns.

4.3. Utility of ZBDD-Based Histograms  We conducted another experiment of the set operations on ZBDD data structure. First we generate a ZBDD for S, a set of all the patterns contained in ?mushroom?, and then compute S.onset(v) for an item v. We tested this onset op- eration for all different 119 items, and only 0.10 second needed for each operation in average. The other primitive operations, such as offset, change, union, intersection, etc., are in the almost same range of computation time. Conse- quently, ZBDD-besed implicit method is very powerful for representing huge number of patterns and efficiently apply- ing various set operations for database analysis.

Data name #Tall #Tdone ratio% |ZBDD| Time(s) T10I4D100K 100,000 43,395 43.40 9,968,062 1,711 T40I10D100K 100,000 740 0.74 9,863,736 123 chess 3,196 703 22.00 8,242,212 919 connect 67,557 2,095 3.10 9,146,429 2,502 mushroom 8,124 8,124 100.00 513,762 214 pumsb 49,046 61 0.12 7,018,198 89 pumsb star 49,046 288 0.59 8,343,418 375 BMS-POS 515,597 9,837 1.90 9,679,161 266 BMS-WebView-1 59,602 17,757 29.79 9,372,436 134 BMS-WebView-2 77,512 39,045 50.37 9,515,386 1,113 accidents 340,183 133 0.04 8,394,811 223  Table 6. Pattern-histograms for sampling data.

Table 6 shows the results for generating pattern- histograms for other larger instances. Here we cannot gen- erate complete pattern-histograms for all tuples, but we can construct them for a part of tuples in the database. In this ex- periment, we started from first line of the data file, and stopped at the line just before memory overflow. The ta- ble shows the number of tuples we completed. The par- tial results are still meaningful as sampling computation.

For smaller or medium size of instances, we can gener- ate pattern-histograms for more than 20% of tuples in the database. Here the tuples are selected in a determinis- tic manner, but we may shuffle the order of tuples in real applications.

5. Conclusion  In this paper, we presented a new method of using ZB- DDs for database analysis problems. Our work is just start- ing now, and we have many future works to be consid- ered, such as ZBDD variable ordering problem for reduc- ing graph size, and more efficient implementation of ZBDD set operations.

We expect that it would be too memory-consuming to construct ZBDDs of the complete pattern-histograms for the large-scale benchmarks, besides ?mushroom?. How- ever, hopefully we will be able to handle those practical size of databases by using well-known improvement tech- niques, such as preprocessing of pruning not frequent items and patterns, or handling only maximum item set data[6], etc. ZBDD-based method will be useful as a fundamental techniques for various processing of database analysis, and will be utilized for web information retrieval and integra- tion.

