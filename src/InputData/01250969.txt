The Rough Set Approach to Association Rule Mining

Abstract  In transaction processing, an association is said to ex- ist between two sets of items when a transaction containing one set is likely to also contain the other. In information retrieval, an association between two sets of keywords oc- curs when they co-occur in a document. Similarly, in data mining, an association occurs when one attribute set occurs together with another. As the number of such associations may be large, maximal association rules are sought, e.g., Feldman et al (1997, 1998).

Rough set theory is a successful tool for data mining. By using this theory, rules similar to maximal associations can be found. However, we show that the rough set approach to discovering knowledge is much simpler than the maximal association method.

Keywords: Rough Set, Data Mining, Knowledge Dis- covery in Databases.

1 Introduction  Consider the analysis of supermarket basket data where associations like ?82% of customers who buy spaghetti also buy Italian sauces? may be found. On the other hand, in information retrieval, an association between the keywords ? bridle ways ? and ? jogging paths ? means they co-occur in several documents. One method of data mining is to seek to identify association rules by which we can infer the exis- tence of one attribute set from another. Generally, the num- ber of such associations may be large. For example, from a (single) record ? bright sunshine, water sprinkler off, ex- ternal temperature drop, thermostat flips, room temperature increase ? a large number of associations may be discov- ered: ? water sprinkler off, room temperature increase ? is  associated with ? bright sunshine ?; etc. Only some of these reflect insights into our world.

While regular association rules are based on the notion of frequent sets of attributes which appear in many records, maximal association rules are based on frequent maximal sets of attributes which appear maximally in many records.

While the regular association rule X ? Y for attribute sets X and Y means that if X then Y (with some confidence), the maximal association rule X ? Y means that if X max- imally then Y maximally (Feldman et al 1997, 1998). We can also apply this to documents for information retrieval.

For maximal associations, there is only one maximal as- sociation, e.g., with more records it might be possible to identify one between ? external events: bright sunshine, wa- ter sprinkler off, external temperature drop ? and ? internal events: thermostat flips, room temperature increase ?.

Rough set theory is a useful tool for data mining. By using this theory, rules that are similar to maximal associ- ations can be found. However, we show that the rough set approach to discovering knowledge is much simpler than the maximal association method. We focus on information retrieval.

Let D be a document collection containing documents d1, d2, ..., dN . The vocabularies of collection D and docu- ment d are denoted by V D and V d, respectively.

In order to illustrate the Feldman method, this paper uses the following example.

Example 1.1 (Feldman et al 1997) There are 10 articles referring to ?corn? which also refer to USA and Canada, and other 20 different articles concern ?fish? and the countries USA, Canada and France. We can write  {USA,Canada,corn}=V di for i = 1, 2, ..., 10; {USA,Canada,France,fish}=V dj for j = 11, 12, ..., 30.

This paper is organized as follows. Section 2 discusses     the support documents of a keyword set. Sections 3-6 intro- duce partitioning of the indexing vocabulary of terms and the definition of maximality, and then discuss maximal as- sociations. Finally, we introduce the rough set approach to association rule mining.

2 The Support Documents of a Keyword Set  Let V D = {t1, t2, ..., tn}, where t are keywords. Let X ? V D be a subset of the collection vocabulary. Denote XD = {d|X ? V d}, i.e. the set of documents in which elements of X occur. That is, in an information table, we say that a document d supports a given set of terms or key- words X if X ? V d. The strength of X in the information table, denoted by stg(X), is the number of documents d supporting X:  stg(X) = |{d|X ? V d}| = |XD|.

An association between X and Y is an expression of the  form X ?? Y , where X and Y are sets of terms/keywords; the strength of the association stg(X ?? Y ) is the strength of X ? Y , i.e., the number of documents supporting X ? Y  stg(X ?? Y ) = stg(X ? Y ) = |(X ? Y )D|, and the confidence of the association cfi(X ?? Y ) is  stg(X?Y ) max(stg(X),stg(Y )) =  |(X?Y )D| max(|XD|,|Y D|) .

An association rule is a rule of the form X ? Y , where X and Y are sets of terms; the strength of the association rule stg(X ? Y ) is  stg(X ? Y ) = stg(X ? Y ) = |(X ? Y )D|, and the confidence of the rule cfi(X ? Y ) is  stg(X ? Y )/stg(X) = |(X?Y )D||XD| .

Example 2.1 For example 1.1, it can be found that asso-  ciations (with the given cardinalities) are {USA,Canada} ?? {fish} with confidence |({USA,Canada}?{fish})D|  max(|{USA,Canada}D|,|{fish}D|) =  max(30,20) = 66%, {USA,Canada,France}??{fish} with confidence |({USA,Canada,France}?{fish})D|  max(|{USA,Canada,France}D|,|{{fish}D|) =  max(20,20) = 100%,  {USA,Canada}??{corn} with confidence |({USA,Canada}?{corn})D|  max(|{USA,Canada}D|,|{corn}D|) =  max(30,10) = 33%.

Feldman et al argue that this confidence is too low  to indicate a strong connection between USA-Canada and ?corn?. Of course, this is an application-dependent judge- ment.

Also, association rules are {USA,Canada} ? {fish} with confidence  |({USA,Canada}?{fish})D| |{USA,Canada}D| = 20/30 = 66%,  {USA,Canada,France}?{fish} with confidence |({USA,Canada,France}?{fish})D|  |{USA,Canada,France}D| = 20/20 = 100%, {USA,Canada}?{corn} with confidence  |({USA,Canada}?{corn})D| |{USA,Canada}D| = 10/30 = 33%.

Again, this confidence is judged to be too low to rep- resent the strong connection between USA-Canada and ?corn?.

Therefore, Feldman et al introduce the definition of max- imality. An example of a maximal association rule is  {USA,Canada}?{corn} and it has ? confidence ? 10/10=100% since whenever USA-Canada appear maximally without any other country (in and only in documents d1-d10), ?corn? also appears maximally without any other goods (also in and only in documents d1-d10).

3 Partitioning the Indexing Vocabulary  For the definition of maximality, an underlying taxon- omy ? of terms is used. Then the ?interesting? correlations between terms from different categories can be obtained.

Let A = V D be partitioned to classes T1, T2, ..., TK .

We denote the partition by A/? : T1, T2, ..., TK ; or A/? = {T1, T2, ..., TK}, where ? is the corresponding equivalence relation of the partition such that a?b for a, b ? A if and only if a and b are in the same class, and Tk ? 2A;Tk ?= ?;Ti ? Tj = ? when i ?= j;A = ?Kk=1Tk. The partition is called a taxonomy. Each class is called a category.

Example 3.1 For example 1.1, the vocabulary of terms A can be partitioned as follows: A/? = {T1, T2}, where T1 = countries = {USA,Canada, France}, T2 = topics = {corn, fish}. The taxonomy is {countries, top- ics}, and countries and topics are categories.

4 Maximally Supported Sets  From a given underlying taxonomy ? of attributes, the definition of maximality can be introduced, and ?interest- ing? correlations between terms from different categories can be obtained.

For a given subset X ? A (X ?= ?), we can find a unique decomposition X = X1 ? X2 ? ... ? XK such that X1 ? T1, X2 ? T2, ..., XK ? TK , where Tk (k = 1, 2, ...,K) are categories of ? . We call Tk the corresponding category of Xk.

Given a category Tk, for an Xk ? Tk (Xk ?= ?) and document d, we say that d supports Xk or Xk occurs in d if Xk ? V d ? Tk. The support/occurrence collection of Xk in the document collection D, denoted by (Xk)D, is the sub-collection of documents supporting Xk:  (Xk)D = {d|Xk ? V d ? Tk}.

This set Xk of terms can also be denoted by a taxonomy pair {Xk : Tk} to indicate its category. The strength stg(Xk) is equal to the number of documents supporting Xk:  stg(Xk) = |{d|Xk ? V d ? Tk}| = |(Xk)D|,     and pair {Xk : Tk} can be denoted by {Xk : Tk}(Xk)D with its support collection (Xk)D added when (Xk)D ? D.

We call Xk a clause co-occurring in (Xk)D.

Now for an Xk ? Tk (Xk ?= ?) and document d, we say that d maximally supports Xk if Xk = V d ? Tk. The max-support collection of Xk in the document collection D, denoted by (Xk)D,max, is the sub-collection of docu- ments maximally supporting Xk: (Xk)D,max = {d|Xk = V d ? Tk}. This set Xk of terms can also be denoted by a taxonomy pair {Xk : Tk} to indicate its category. The max- strength msg(Xk) is equal to the number of documents maximally supporting Xk:  msg(Xk) = |{d|Xk = V d ? Tk}| = |(Xk)D,max|, and pair {Xk : Tk} can be denoted by {Xk : Tk}max(Xk)D,max with its max-support collection (Xk)D,max added when (Xk)D,max ? D. We call Xk a sentence co-occurring in (Xk)D,max.

Example 4.1 Continue example 1.1.

For T1 = countries, the following 2 sentences and their  co-occurrence collection can be found: {{Canada, France, USA} : countries}max{d11-d30} {{Canada, USA} : countries}max{d1-d10}  For T2 = topics, the following 2 sentences and their co- occurrence collection can be found: {{corn} : topics}max{d1-d10} {{fish} : topics}max{d11-d30}.

Given a taxonomy ? , for a given X = X1?X2?...?XK (X ?= ?; Xk ? Tk for k = 1, 2, ...,K; and so there is at least one k such that Xk ?= ?) and document d, we say that d supports X if Xk ? V d ? Tk for all k. The sup- port/occurrence collection of X in the document collection D, denoted by XD, is the sub-collection of documents sup- porting X; XD = {d|Xk ? V d ? Tk; k = 1, 2, ..., K}.

This set X of terms can also be denoted by a vector of taxonomy pairs {Xk : Tk} in a Cartesian product space 2T1 ? 2T2 ? ...? 2TK to indicate the component categories.

The strength stg(X) is equal to the number of documents supporting X:  stg(X) = |{d|Xk ? V d ? Tk; k = 1, 2, ..., K}| = |XD|, and the vector can be denoted as  ({X1 : T1}, {X2 : T2}, ..., {XK : TK})XD  with its support collection added when XD ? D. We call X a clause co-occurring in XD.

Now for an X = X1 ? X2 ? ... ? XK (where Xk ?= ? and Xk ? Tk for k = 1, 2, ...,K) and document d, we say that d maximally supports X if Xk = V d ?Tk for all k.

The max-support collection of X in the document collection D, denoted by XD,max, is the sub-collection of documents maximally supporting X:  XD,max = {d|Xk = V d ? Tk; k = 1, 2, ..., K}.

This set X of terms can also be denoted by a vector of taxonomy pairs {Xk : Tk} in a Cartesian product space 2T1 ? 2T2 ? ...? 2TK to indicate the component categories.

The max-strength msg(X) is equal to the number of docu- ments maximally supporting X:  msg(X) = |XD,max|,  and the vector can be denoted as  ({X1 : T1}, {X2 : T2}, ..., {XK : TK})maxXD,max  with its max-support collection added when XD,max ? D.

We call X a sentence co-occurring in XD,max.

Example 4.2 For example 1.1, sentences for the taxon- omy are  ({Canada, France, USA} : countries, {fish} : topics)max{d11-d30} ({Canada, USA} : countries, {corn} : topics)max{d1-d10}.

5 Maximal Associations  A maximal association between V and W is an expres- sion of the form V ?? W , where V and W are sentences from 2 different categories. The strength of the associa- tion is msg(V ? W ), and confidence of the association is msg(V ? W )/max(msg(V ),msg(W )).

Example 5.1 For example 1.1, the following maximal associations can be found:  {Canada, France, USA} : countries ?? {fish} : topics with strength msg = |{d11-d30}| =  20 and confidence 20/ max(20, 20) = 1 = 100% {Canada, USA} : countries ?? {corn} : topics with strength msg = |{d1-d10}| =  10 and confidence 10/ max(10, 10) = 1 = 100%  6 Maximal Association Rules  A maximal association rule is an expression of the form V ? W , where V and W are sentences from 2 dif- ferent categories. The strength of the association rule is msg(V ?W ), and confidence of the association is msg(V ? W )/msg(V ).

Example 6.1 For example 1.1, the following maximal association rules can be found:  {Canada, France, USA} : countries ? {fish} : topics with strength msg = |{d11-d30}| =  20 and confidence 20/20 = 1 = 100% {Canada, France, USA} : countries ? {fish} : topics with strength msg = |{d11-d30}| =  20 and confidence 20/20 = 1 = 100% {Canada, USA} : countries     ? {corn} : topics with strength msg = |{d1-d10}| = 10 and confidence 10/10 = 1 = 100%  {Canada, USA} : countries ? {corn} : topics with strength msg = |{d1-d10}| =  10 and confidence 10/10 = 1 = 100%  7 Rough Set Approach  Using the rough set method (Pawlak 1991, Bell Guan 1998, Guan Bell 1998), we can much more easily dis- cover similar knowledge to maximal association rules. For a given sentence, we use the theory to recognize its sup- port/occurrence documents. Now, an information table can be designed for sentences as follows.

D\2T1 | T1 T2 ... TK d1 | T1 ? V d1 T2 ? V d1 ... TK ? V d1 d2 | T1 ? V d2 T2 ? V d2 ... TK ? V d2 ... | ... ... ... ...

di | T1 ? V di T2 ? V di ... TK ? V di ... | ... ... ... ...

dN | T1 ? V dN T2 ? V dN ... TK ? V dN  .

For example, the information table for Example 1.1 can be designed as follows:  D\2Tk | T1 = countries T2 = topics d1 : d10 | {Canada, USA} {corn} d11 : d30 | {Canada, France, USA} {fish}  The Information Table for Example 1.1  Then it can be found that partitions D/countries is  {Canada,USA}D11, {Canada,France,USA}D12, where D11 = {d1 : d10}, D12 = {d11 : d30};  D/topics is {corn}D21, {fish}D22, where D21 = {d1 : d10}, D22 = {d11 : d30}; and  D/countries ? topics is ({Canada, USA} : countries, {corn} : topics){d1 : d10} ({Canada, France, USA} : countries, {fish} : topics){d11 : d30} That is, we find the same associations/co-occurrences as  the maximal ones discovered in Examples 5.1. However, as these examples show, the rough set approach to discover knowledge is much simpler than the maximal association method.

8 Conclusion  While regular association rules are based on the notion of frequent sets of attributes which appear in many doc- uments, maximal association rules are based on frequent  maximal sets of attributes which appear maximally in many documents. Moreover, while the regular association rule X ? Y means that if X then Y (with some confidence), the maximal association rule X ? Y means that if X max- imally then Y maximally.

Feldman et al argue that the regular concept of confi- dence is too low to indicate strong connections, and they introduce maximal associations to improve the quality of mined association rules.

By using rough set theory, rules that are similar to max- imal associations can be found. However, we demonstrate that the rough set approach to discover knowledge is much simpler than the maximal association method.

