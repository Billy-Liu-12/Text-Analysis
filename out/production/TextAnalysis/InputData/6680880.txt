Combining Top-Down and Bottom-Up: Scalable Sub-Tree Anonymization over Big  Data using MapReduce on Cloud

Abstract?In big data applications, data privacy is one of the most concerned issues because processing large-scale privacy-sensitive data sets often requires computation power provided by public cloud services. Sub-tree data anonymization, achieving a good trade-off between data utility and distortion, is a widely adopted scheme to anonymize data sets for privacy preservation. Top-Down Specialization (TDS) and Bottom-Up Generalization (BUG) are two ways to fulfill sub-tree anonymization. However, existing approaches for sub-tree anonymization fall short of parallelization capability, thereby lacking scalability in handling big data on cloud. Still, both TDS and BUG suffer from poor performance for certain value of k-anonymity parameter if they are utilized individually. In this paper, we propose a hybrid approach that combines TDS and BUG together for efficient sub-tree anonymization over big data.

Further, we design MapReduce based algorithms for two components (TDS and BUG) to gain high scalability by exploiting powerful computation capability of cloud.

Experiment evaluations demonstrate that the hybrid approach significantly improves the scalability and efficiency of sub-tree anonymization scheme over existing approaches.

Keywords-Big data; cloud computing; data anonymization; privacy preservation; MapReduce

I. INTRODUCTION Cloud computing and big data are two disruptive  trends at present, imposing significant impacts on current IT industry and research communities [1, 2]. Cloud computing elastically provides massive computation power and storage capacity via utilizing a large number of commodity computers together, enabling users to deploy big data applications cost-effectively without heavy infrastructure investment.  To exploit the advantages offered by public cloud platforms, more and more big data applications have been moving into cloud, including a variety of privacy-sensitive applications like health care data and transactional data storing and processing.

Consequently, how to protect the privacy of these data sets is a big challenge. Indeed, numerous potential customers are still hesitant to take advantage of cloud due to privacy and security concerns [3]. Privacy is one of the most concerned issues in the big data applications that involve multiple parties, and the concern aggravates in the context of cloud computing although some privacy issues are not new [1]. Hence, data privacy issues need to be addressed urgently before data sets are analyzed or shared on cloud.

Data anonymization, extensively studied and widely adopted [4], is an effective way for data privacy preservation. Data anonymization refers to hiding identity and/or sensitive data for owners of data records. Then, the privacy of an individual can be effectively preserved while certain aggregate information is exposed to data users for diverse analysis and mining. Sub-tree anonymization scheme is widely adopted to anonymize data sets for privacy preservation, producing a good trade-off between data utility and distortion. There are two ways to accomplish sub-tree anonymization, i.e., Top-Down Specialization (TDS) and Bottom-Up Generalization (BUG). So far, a series of approaches have been proposed for TDS or BUG [5, 6, 7, 8]. However, data sets in big data applications on cloud have become so large that it is a big challenge for existing sub-tree anonymization algorithms to anonymize such data sets in a scalable fashion, due to their lack of parallelization capability. Still, both TDS and BUG suffer from poor performance for certain value of k-anonymity parameter if they are utilized individually, where k-anonymity privacy model [9] is adopted. Specifically, TDS is preferred when k is large while BUG is favorable when k is small.

MapReduce [10], a large-scale data processing framework, have been integrated with cloud to provide powerful computation capability for applications, e.g.

Amazon Elastic MapReduce (EMR) service [11]. We leverage MapReduce on cloud to address the scalability problem in our approach. As the MapReduce computation paradigm is relatively simple, it is still a challenge to design proper MapReduce jobs for TDS and BUG.

In this paper, we propose a highly scalable hybrid approach that combines TDS and BUG together for sub- tree anonymization over big data. The approach automatically determines which component is used to conduct the anonymization when a data set is given, by comparing the user-specified k-anonymity parameter with a threshold derived from the data set. Both components TDS and BUG are developed based on MapReduce to gain high scalability by exploiting powerful computation capability of cloud. Having designed MapReduce based TDS in [12], we only present the MapReduce algorithmic design of BUG herein. Experimental evaluation demonstrates that the hybrid approach significantly improves the scalability and efficiency of sub-tree data anonymization over existing approaches.

The major contributions of this paper are three folds.

Firstly, we propose a hybrid approach to improve the   DOI 10.1109/TrustCom.2013.235     scalability and efficiency of sub-tree data anonymization via automatically choosing TDS or BUG. Secondly, a group of innovative MapReduce jobs are designed for BUG to concretely conduct the computation in a highly scalable fashion. Lastly, experimental evaluations demonstrate that the hybrid approach improves the scalability and efficiency of sub-tree anonymization scheme over existing approaches.

The remainder of this paper is organized as follows.

The next section reviews related work, and analyzes the problems in existing sub-tree anonymization approaches.

In Section III, we briefly present the preliminary concepts for our approach. Section IV elaborates algorithmic details of MapReduce jobs for BUG, and Section V formulates the hybrid approach. We empirically evaluate our approach in Section VI. Finally, we conclude this paper and discuss future work in Section VII.



II. RELATED WORK AND PROBLEM ANALYSIS  A. Related Work Privacy preservation on data has been extensively  investigated and fruitful progress has been made by research communities [4]. We briefly review the related work as follows.

A bulk of privacy models and anonymization approaches have been put forth to preserve the privacy- sensitive information in data sets. k-anonymity [9] and l- diversity [13] are two basic and widely-adopted privacy models to measure the degree of privacy-sensitive information disclosure against record linkage attacks and attribute linkage attacks, respectively. Other privacy models like t-closeness [14] and m-invariance [15] are also proposed for various privacy attack scenarios. Several anonymizing operations are leveraged to anonymize data sets, including generalization [5, 16, 17], anatomization [18], slicing [19], disassociation [20], etc. In this paper, we leverage generalization which replaces some domain values with a parent value in the taxonomy tree. Roughly, there are four generalization schemes [4], namely, full- domain [21], sub-tree [5],  multidimensional [16] and cell generalization [17].

Our research herein concentrates on the sub-tree generalization scheme. Unlike multidimensional or cell schemes, sub-tree scheme can produce consistent anonymous data that can be directly used by existing data mining and data analysis tools. This scheme offers a good trade-off between data utility and data consistency. Thus, this scheme has been extensively explored. Top-Down Specialization (TDS) [5, 6, 7, 12] and Bottom-Up Generalization (BUG) [8] are two ways to fulfill the sub- tree scheme.  Most exiting algorithms exploit indexing data structure to assist the process of anonymization.

Specifically, TIPS (Taxonomy Indexed PartitionS) for TDS and TEA (Taxonomy Encoded Anonymity) index for BUG. Although indexing data structures can speed up the process of data anonymization, these approaches often fail to work in parallel or distributed environments like cloud systems because the indexing structures are centralized.

Mohammed et al. [6] proposed a TDS approach which, however, mainly concerns privacy protection against other parities rather than scalability issues. Still, this approach only employs information gains as the search metric, resulting lower data utility than centralized ones.  Our previous work [12] leverages MapReduce to accomplish the intensive computation required in big data anonymization via TDS. But TDS probably performs slower than BUG when k-anonymity parameter is small.

Scalability and efficiency of anonymization algorithms for privacy preservation has drawn attention of researchers.

R-tree indexing, scalable decision trees and sampling techniques are introduced to achieve high scalability and efficiency [22, 23]. However, the proposed approaches aim at multidimensional scheme, thereby failing to work for sub-tree generalization. MapReduce has been widely adopted in various data processing applications to boost scalability and efficiency [24, 25, 26]. Following this line, we also leverage MapReduce to advance scalability and efficiency in our research on big data anonymization.

B. Problem Analysis In this section, we analyze the problem of utilizing  Top-Down Specialization (TDS) or Bottom-Up Generalization (BUG) alone for sub-tree generalization, and the scalability problem of existing BUG approaches.

At present, existing TDS and BUG approaches are developed individually for sub-tree generalization scheme.

Both of them lack the awareness of the user-specified k- anonymity parameter. In fact, the values of the k- anonymity parameter can impact their performance.

Intuitively, if parameter k is large, TDS is more suitable while BUG will probably get bad performance. The case is reversed when k is small. A simple example is described below to demonstrate the above intuition.

Assume that a data set has 10 records with the attribute Education that needs generalization for privacy preservation. The taxonomy tree of this attribute and attribute value of records are depicted in Fig. 1. At one extreme, let k be set as 2. In this case, TDS has to specialize several domain values to achieve 2-anonymity while BUG will do nothing as the data set is already 2- anonymity. At other extreme, let k be set as 5. In such a case, TDS will do nothing to achieve 5-anonymity while BUG has to conduct generalization. It can be seen from the example that selecting TDS or BUG according to k significantly impacts the performance of the sub-tree anonymization scheme.

As such, it is promising to develop a hybrid approach that encompasses TDS and BUG as two components so  Education # of Recs.

Junior 2 Senior 2  Bachelors 3 Graduate 3  Any_Education  Secondary University  Junior Senior Bachelors Graduate  Figure 1. Education taxonomy tree and records.

that the high scalability and efficiency can be gained regardless of valuing of the k-anonymity parameter. The key to the hybrid approach is how to design a user-friendly method to automatically determine which component should be chosen. Although a domain expert is able to determine which approach is preferred to conduct anonymization manually according to the value of parameter k, ordinary users in the cloud probably fail to do this due to their lack of background knowledge.

As to BUG, the existing approach in [8] exploits indexing data structure to promote efficiency, thereby falling short of high scalability and parallelization in cloud environments. Thus, it is worthwhile investigating how to develop BUG algorithm with MapReduce in order to improve the scalability and efficiency. A promising way is to conduct generalization operations in parallel. As MapReduce only provides primitive programming model, how to develop MapReduce jobs to conduct the computation required by data anonymization is still critical in the whole design and needs intensive research.

Above all, the problem we attempt to address is how to design scalable and efficient BUG algorithm based on MapReduce and how to automatically select a component for the proposed hybrid approach according to parameter k.



III. PRELIMINARY  A. Sub-Tree Generalization Scheme To facilitate subsequent discussion, we briefly  introduce the sub-tree generalization scheme as background knowledge. Table 1 lists some basic symbols and notations. We assume there is one sensitive value in one record like medical diagnosis, as more sensitive values will not affect our discussion. The leaf node values of a taxonomy tree TTi are original attribute values of records in D. We use QI as the acronym of quasi-identifier. The quasi-identifier group is abbreviated as QI-group [27].

Without loss of generality, we adopt k-anonymity [9] as the privacy model in this paper, i.e., for any ??? ? ???, the size of ??	(???) must be zero or at least k, so that a quasi-identifier will not be distinguished from other at least k-1 quasi-identifiers.

In sub-tree generalization scheme, all child values of a  non-leaf node or none in a domain hierarchy are generalized to the node. Two operations can be employed to accomplish this scheme, i.e., generalization for BUG and specialization for TDS, respectively. A generalization operation is to replace a domain value with its parent in a taxonomy tree while a specialization operation is to replace a domain value with its all child values. Formally, a generalization is represented as ??: ????(?) ? ? while a specialization is represented as ????: ? ? ????(?), where ? ? ???? is a domain value and the set ????(?) consists of all child domain values of ? . We leverage the concept anonymization level [12] to capture the degree of anonymization. Specifically, anonymization level, denoted as ??, is a vector of domain values sets, i.e., ?? = ???1, ??2, ? , ??? ?, where ??? , 1 ? ? ? ? , is the cut of ??? . A cut of a tree is a subset of values in the tree that contains exactly one value on each root-to-leaf path [4].

To guide the selection of the best operations in the anonymization process, the goodness of a candidate generalization or specialization is measured by a search metric. We leverage the information/privacy trade-off as the search metric for our approach, i.e., the Information Gain per Privacy Loss (IGPL) for TDS and the Information Loss per Privacy Gain (ILPG) for BUG, respectively [4]. We briefly describe how to calculate the value of ILPG subsequently. Interested readers can refer to [12] for IGPL calculation or [4] for more details.

Given a generalization ??: ????(?) ? ?, the ILPG of the generalization is calculated by  ??!	( ??) = ??( ??)/(!	( ??) + 1).  (1) The term ??( ??) is the information loss after  performing ??, and !	( ??) is the privacy gain. Both of them are computed via statistical information derived from data sets. Let "# denote the set of original records containing attribute values that can be generalized to #.

|"# | is the number of data records in "# . Let ?("# ) be the entropy of "# . Then, ??( ??) is given by  ??( ??) = $ %|"? ||"? |& ?("? )?????? (?) ' ?*"? -.  (2) Let ??( ??) denote the anonymity after performing ??, while ?? ( ??) be that before performing ??. Then,  the privacy gain from ?? is calculated by !	( ??) = ??( ??) ' ??( ??).  (3)  B. MapReduce Basics MapReduce is a scalable and fault-tolerant data  processing framework that is capable of processing huge volume of data in parallel with many low-end commodity computers [10]. In general, a MapReduce job consists of two primitive functions, Map and Reduce, defined over a data structure named key-value pair (key, value).

Specifically, the Map function can be formalized as Map: (k1, v1)  (k2, v2), i.e., Map takes a pair (k1, v1) as input and then outputs another intermediate key-value pair (k2, v2). These intermediate pairs are consumed by the Reduce function as input. Formally, the Reduce function can be represented as Reduce: (k2, list(v2))  (k3, v3), i.e., Reduce  TABLE I. BASIC SYMBOLS AND THEIR MEANINGS  Symbol Definition D a data set containing data records m number of attributes r a data record, . ? ? and . = ?01, 02, ? , 0? , ?0?,  where 0? ,1 ? ? ? ?, is an attribute value, and sv is a sensitive value.

Attri the ith attribute of a data record TTi the taxonomy tree of the attribute Attri  DOMi the set of all domain values in TTi SV the set sensitive values qid a quasi-identifier, ??? = ??1, ?2, ? , ?? ?, ?? ????? , 1 ? ? ? ?.

QID the set of quasi-identifiers, ??? = ????.1, ???.2 , ? , ???.? ?  QIG(qid) quasi-identifier group containing all records with     ALGORITHM 1. BUGMR DRIVER.

Input: data set D, anonymization level ??0, anonymity parameter k.

Output: final anonymous data set ?4.

1: Initialize the values of search metric ILPG for each generalization   ?? ? 5 ??6?6 =1 with respect to ??0, via job ILPG Calculation; 2: while 7 ??, ?? ( ??) < 8 3:       Find the best generalization ??9??? out of all the active ones; 4:      Label ??9??? as INACTIVE to perform ??9??? on the current  anonymization level; 5:       if  ; ?? ? >	>??( ??9??? ) is labeled as INACTIVE; 6:     Insert a new generalization ????@ : ????(?) ? ? , where ????(?) = {?? | ??A : ????(??) ? ?? , ??A ? >	>??( ??9??? )}; 7:          Remove all generalizations in >	>??( ??9??? ) 8:       end if 9:     ???+1 B ???; Update ILPG values for all active generalization  candidates in ???+1 via ILPG Calculation; 10:  end while 11:  Generalize ? to ?4 in terms of ??? , via job Data Generalization;  takes intermediate k2 and all its corresponding values list(v2) as input and outputs another pair (k3, v3). Usually, (k3, v3) list is the results which MapReduce users attempt to obtain. An instance running Map function is called Mapper, and that running Reduce function is called Reducer, respectively. Between Map phase and Reduce phase exists a Shuffle phase, during which the intermediate key-value pairs are sorted according to keys.



IV. BOTTOM-UP GENERALIZATION USING MAPREDUCE  We mainly elaborate Bottom-Up Generalization using MapReduce (MRBUG) in this section. Basically, a practical MapReduce program encompasses Map and Reduce functions, and a Driver that coordinates the macro execution of MapReduce jobs. Thus, we describe the Bottom-Up Generalization MapReduce Driver in Section

IV.A to present the basic process of bottom-up generalization. Section IV.B and IV.C present the MapReduce jobs in detail.

A. Bottom-Up Generalization MapReduce Driver Basically, Bottom-Up Generalization (BUG) approach  of anonymization is an iterative process starting from the lowest anonymization level. The lowest anonymization level contains the internal domain nodes in the lowest level of taxonomy trees. Each round of iteration includes four major steps, namely, checking the current data set whether satisfies the anonymity requirement, calculating the ILPG, finding the best generalization and generalizing the data set according to the selected best generalization candidate.

Calculating the ILPG and generalizing the data set involve accessing a large number of data records, thereby dominating the scalability and efficiency of bottom-up generalization. An existing approach [8] utilizes indexing data structure and retaining statistic information to improve the efficiency. But the approach suffers from poor scalability and efficiency in a big data scenario. Still, the approach fails to be adapted into MapReduce since MapReduce does not support indexing data structure.

As such, we propose to develop innovative MapReduce jobs for the ILPG computation. As the notion of anonymization level is introduced to describe anonymization status of a data set, it is unnecessary to generalize the data set concretely in each round in regards to efficiency. Instead, we abstractly generalize the data set over the current anonymization level. After the final anonymization level is obtained, we anonymize the data set in a one-pass MapReduce job. Algorithm 1 presents the Bottom-Up Generalization MapReduce (BUGMR) driver.

We detail Algorithm 1 as follows. Firstly, ILPG values of all generalizations are initialized (line 1). Line 2 checks whether the current anonymized data set satisfies the k- anonymity requirement. Line 3 finds the best generalization ??9??? with the highest ILPG value and Line 4 generalizes this generalization by labeling it as INACTIVE. That a generalization is labeled as INACTIVE means the generalization will not be considered any more in following rounds, abstractly fulfilling anonymization on  the data set. Let >	>??( ??) denote the set containing generalization ?? and its all siblings in the domain taxonomy tree. When the generalizations in >	>??( ??) are all labeled as INACTIVE, a new higher level generalization should be inserted to replace these inactive ones (lines 5, 6 and 7). Note that this is a remarkable difference from TDS. Line 9 updates the privacy gain of each active generalization as the performing ??9??? probably changes the anonymity of the data set. Also, information loss computation is required if a new generalization has been inserted. As the last step, line 11 concretely anonymizes the data set according the final anonymization level.

Lines 1 and 9 require ILPG calculation that involves accessing to the original data set and computing statistic information over the data set. Line 11 also needs processing the whole data set. We leverage MapReduce to conduct the intensive computation in these situations.

Specifically, we design a couple of innovative MapReduce jobs: job ILPG Calculation for accomplishing the computation required in lines 1 and 9, and job Data Generalization for achieving the final concrete anonymization in line 11. The ILPG related MapReduce job is elaborated in Section IV.B, and job Data Generalization is in IV.C, respectively.

B. ILPG Calculation Job The ILPG Calculation job is responsible to ILPG  initialization in line 1 of Algorithm 1 and ILPG update in line 9. The computation required in ILPG initialization is quite similar to that of ILPG update. The Map function of the ILPG Calculation is depicted in Algorithm 2, while the Reduce function is presented in Algorithm 3. In Algorithm 2 and 3, the symbol ?#? is used to identify whether a key is emitted to compute information gain or anonymity loss, and ?$? is to differentiate the cases whether a key is for computing ??(????) or ??(????).

Algorithm 2 is detailed as follows. Let NGSet denote the set of newly inserted generalizations. For ILPG initialization, NGSet is the set of all the initial generalizations with respect to ??0 , while for ILPG     ALGORITHM 4. DATA GENERALIZATION MAP & REDUCE.

Input: Data record (??. , .), . ? ?; final anonymization level ??4.

Output: Anonymous record (.4, ?C???).

Map: 1: For each attribute value 0? in ., find its generalization in current ??: ??? . Let ?? be the parent in ??? , and ?? be 0? itself or ?? ?  child that is also 0?? ancestor; 2: Construct quasi-identifier .4 = ??1, ?2, ? , ?? ? , where ?? =  E?? , if ???  is ?????FG,?? , C. @.

I, 1 ? ? ? ?; emit (.4, ?C???).

Reduce: For each .4, ??? B $ ?C???; emit (.4, ???).

updates, it is set by { ????@ } if a new generalization is inserted in the iteration of Algorithm 1. Line 1 of Algorithm 2 transforms an original record into its anonymized form according to the current anonymization level, for the sake of being counted. To compute |"?|, |("? , ?0)|, |"? | and |("? , ?0)| in (2) for information loss calculation, line 2 emits the key-value pair to the Reduce function for information loss computation if this pair is a new generalization candidate. Note that the information loss of a generalization will not be affected when we perform other generalizations or insert a new generalization, while privacy gain will probably be impacted as the anonymity of the data set will change.

Line 3 of Algorithm 2 aims at figuring out the anonymity of the data set before performing a generalization, i.e., ??( ??), while line 4 emits key-value pairs to obtain the anonymity after performing a generalization, i.e., ??( ??) . As ?? ( ??) is unique globally, we just emit the current quasi-identifier ??? for statistics. As to ??( ??) , potential anonymous quasi- identifiers for ??? will be emitted for computing ??( ??) for different active generalization candidates. After obtaining ??( ??) and ?? ( ??), we can update privacy gain for each generalization in terms of (3).

The Reduce function described in Algorithm 3 mainly aggregates the statistical information to calculate information loss and privacy gain. Lines 1 to 5 calculate information loss in terms of (2). Due to that the key-value pairs are sorted by MapReduce before being fed to Reducer workers, the Reduce function can compute  information loss for generalizations in sequence, without requiring large amount of memory to retaining statistical information. Therefore, the Reduce function is highly scalable for calculating information loss.

The essential of computing anonymity of a data set is to find out the minimum QI-group size. Lines 6 to 10 aim at calculating privacy gain. The Reducer workers find out the locally minimum QI-group size before and after performing a generalization in parallel. Then, we can obtain the globally one in the driver program through comparing the outputs of Reducer workers. As such, the ILPG Calculation Reduce function is highly scalable for both information loss and privacy gain computation. After obtaining information loss and privacy gain, we can calculate ILPG values according to (1).

C. Data Generalization The original data set is concretely generalized for data  anonymization by a one-pass MapReduce job, i.e., Data Generalization. Details of Map and Reduce functions of the data specialization MapReduce job are described in Algorithm 4. The Map function emits anonymous records and its count according to the current anonymization level.

The Reduce function simply aggregates these anonymous records and counts their number. An anonymous record and its count represent a QI-group, and the QI-groups constitute the final anonymous data sets.



V. HYBRID APPROACH FOR SUB-TREE ANONYMIZATION  A. Combining Top-Down Specialization and Bottom-Up Generalization Now that the MapReduce version of Bottom-Up  Generalization (MRBUG) has been developed in the last section, the two components, i.e., MRTDS [12] and MRBUG, are ready for the proposed hybrid approach of sub-tree anonymization over big data. In terms of the problem analysis in Section II.B, we need to determine which component is used to anonymize data after the anonymity parameter k is specified by a user. It is promising that the hybrid approach can automatically give out a threshold K such that if 8 J K, MRTDS is selected, otherwise MRBUG is selected. Formally, we define this threshold as Workload Balancing Point.

Definition 1 (Workload Balancing Point) An anonymity value of a data set, denoted as K, is defined as workload balancing point if it satisfies the condition that the amount of computation of anonymizing the data set to K-anonymous required by MRTDS is equal to that by MRBUG.

ALGORITHM 2. ILPG CALCULATION MAP.

Input: Data record (??. , .), . ? ?; anonymization level ??, NGSet.

Output: Intermediate key-value pair (8?L, ?C???).

1: For each attribute value 0? in ., find its generalization in current ??: ??? . Let ?? be the parent in ??? , and ?? be 0? itself or ?? ?  child that is also 0?? ancestor; 2:  If ??? ? ?	>??, emit (??? , ?? , ?0?, ?C???); 3: Construct quasi-identifier ??? = ??1, ?2, ? , ?? ? , where ?? =  E?? , if ???  is ?????FG,?? , C. @.

I, 1 ? ? ? ?; Emit (????, $, #?, ?C???);  4: For each ? ? [1, ?], replace ?? in ??? with its parent ?? if ?? = ?? , producing the resultant quasi-identifier ???4 ; emit (????4, ?? , #?,?C???).

ALGORITHM 3. ILPG CALCULATION REDUCE.

Input: Intermediate key-value pair (8?L, ????(?C???)).

Output: Information gain ( ??, ??( ??) ) and anonymity ( ?? ,  ?? ( ??)), ( ??, ?? ( ??)) for generalizations.

1: For each 8?L, ??? B $ ?C???; 2: For each key, if 8?L. ?0 O #, update statistical counts: 3: |("? , ?0)| B ??? , |"? | B ??? + |"? | , |*"? , ?0-| B ??? +  |*"? , ?0-|, |"? | B ??? + P"? P; 4: If all sensitive values for child ? have arrived, compute ?("? ); 5: If all children ? of parent ? have arrived, compute ?("? ) and  ??( ??); emit ( ??, ??( ??)); 6: For each key, if 8?L. ?0 = #, update anonymity: 7: If 8?L. ? = $ and ??? < ?? ( ??) , update current anonymity:  ?? ( ??) B ???; 8: If 8?L. ? O $: 9:   If ??? < ?? ( ?? ), update potential anonymity of ?? :?? ( ??) B ???; 10: Emit ( ??, ?? ( ??)) and emit ( ??, ?? ( ??)).

Once the workload balancing point K is identified, it is easy to choose which component to be employed. If 8 > K, MRTDS is selected because MRBUG will incur more computation, whereas MRBUG is selected if 8 < K.

Figuring out the exact value of K is difficult since K heavily depends on some properties of data sets, like data distribution and skewness. However, it is unnecessary to get the exact value because the performances of MRTDS and MRBUG make little difference when k is valued around K. As such, we roughly estimate the value k according to the size of the data set and taxonomy trees.

B. Workload Balancing Point Estimation To roughly estimate the workload balancing point, we  assume that the values of an attribute are evenly distributed. Our basic idea is to estimate K according to the layering of taxonomy trees. Let H be the highest height among taxonomy trees. To facilitate the estimation, other taxonomy trees with height less than H are modified by making their height H. A string of dummy nodes are attached to their leaf nodes, in order to increase tree height.

An example is demonstrated in Fig.2 to illustrate the above process. The tree ??2 has the highest tree height two. As??1 has height less than two, dummy nodes (dashed circles in the right part of Fig.2) are added after modification. The height of modified version of ??1 is also two.

The data records in a data set D are logically partitioned by the domain value nodes in taxonomy trees.

Let Lj denote the jth layer of the taxonomy forest. The number of domain values of ??? on Lj is denoted as Nij.

The data set can be partitioned into R ??6??=1 QI-groups in regard to the domain values on level Lj. For instance, the data set is partitioned into 4 groups (2*2=4) on L1 in shown in Fig.2, and 8 groups (2*4=8) on L2. Since we assume data sets are evenly distributed, the average anonymity of data set with respect to Lj is K6 =|?|/ R ??6??=1 , i.e., the average QI-group size.

To roughly identify K, we narrow down the interval where K is located. Firstly, the computation required by MRTDS and MRBUG to achieve K6 -anonymous on level Lj are estimated as follows. The performances of each round in both MRTDS and MRBUG are mainly dominated by the computation of the anonymity of data sets in the loop. Further, the computation required in one round of MRTDS and MRBUG, are roughly equal. Let  CUnit denote the computation required in one round of MRTDS or MRBUG. In MRTDS, performing a specialization operation will launch IGPL update and incur CUnit computation. So, the total amount of computation to specialize D to Lj, denoted as 6??> can be estimated by  6??> = $ $ S??? T ?????=16?=1 .   (4) In MRBUG, unlike MRTDS, performing a  generalization operation possibly does not trigger ILPG update. Generally, several operations can launch ILPG update and incur CUnit computation. On average, we assume 1 UV operations can do this, where 0 ? U ? 1 .

Then, the total amount of computation to generalize D to Lj, denoted as 69S	 can be estimated by  69S	 = $ $ S??? T W T ?????=1X'1?=6 .  (5) The value of j that make 6??> equal to 69S	 must be  located in interval [J-1, J], where J satisfies the condition: Y??> J Y9S	 and Y'1??> ? Y'19S	 . Once J is identified, we can estimate that the workload balancing point K lies within [KY , KY'1]. Let Z be the average branch factor of the taxonomy forest. As K varies exponentially with respect to j, where 1 ? 6 ? X, we estimate the workload balancing point at the middle position between KY and KY '1 by the following formula:  K = KY + |?| T (1 Z? (6 '1)V ' 1 Z?6V ).  (6) Once the workload balancing point is estimated, the  hybrid approach can easily determine which component to be chosen, via comparing K with k-anonymity parameter.



VI. EXPERIMENTAL EVALUATION  A. Experiment Settings To evaluate the effectiveness and efficiency of the  hybrid approach, we compare it with MRTDS [12] and MRBUG. We denote the execution time of the three approaches as THyb, TTDS and TBUG, respectively. In general, THyb is similar to TTDS if k is larger than K, while THyb is similar to TBUG if k is less than K. Estimating K incurs overheads, yet it is minor compared with the computation conducted in MapReduce jobs.

Our experiments are conducted in a cloud environment named U-Cloud. U-Cloud is a cloud computing environment at University of Technology Sydney (UTS).

The system overview of U-Cloud has been depicted in Fig.3. The computing facilities of this system are located among several labs in the Faculty of Engineering and IT, UTS. On top of hardware and Linux operating system (Ubuntu), we install KVM virtualization software [28] which virtualizes the infrastructure and provides unified computing and storage resources. To create virtualized data centers, we install OpenStack open source cloud environment [29] which is responsible for virtual machine management, resource scheduling, task distribution and interaction with users. Furthermore, Hadoop clusters [30] are built based on OpenStack to facilitate MapReduce computing paradigm and big data processing.  Figure 2. An example of modifying the height of taxonomy trees.

TT1 TT2 TT1 TT2  (Original) (Modified)  L0  L1  L2     All approaches are implemented in Java and standard Hadoop MapReduce API. The Hadoop cluster consists of 20 VMs with type m1.medium which has 2 virtual CPUs and 4 GB Memory. Each round of experiment is repeated 20 times. The mean of the measured results is regarded as the representative. We utilize the Adult data set and its generated data sets like [12].

B. Experiment Process and Results We measure the change of execution time THyb, TTDS and  TBUG with respect to anonymity parameter k. The size of data set is set as 1000 MB. Equally, the data set contains 1.1?107 data records, which is big enough to evaluate the effectiveness of our approach in terms of data volume or the number of data records. Parameter U is set as 0.5.

Fig. 4 demonstrates the change of THyb, TTDS and TBUG with respect to k ranging from 0 to 1.1?107. For conciseness, k is indicated by Exp which is the exponent of the scientific notation of k, i.e., k = 1.1*10Exp. So, Exp ranges from 0 to 7. We can see from Fig.4 that the execution time of the hybrid approach is kept under a certain level, while both MRTDS and MRBUG incur high execution time when k is small and large, respectively.

Further, the right part of the curve of THyb is near to TBUG, while the right part is near to TTDS. This is because the hybrid approach utilizes MRTDS and MRBUG as components to conduct concrete computation.

As a conclusion, the experimental results demonstrate that the hybrid approach significantly improves the  performance of sub-tree anonymization over existing approaches regardless of the k-anonymity parameter.



VII. CONCLUSIONS AND FUTURE WORK In this paper, we have investigated the scalability issue  of sub-tree anonymization over big data on cloud, and proposed a hybrid approach that combines Top-Down Specialization (TDS) and Bottom-Up Generalization (BUG) together. The hybrid approach automatically selects one of the two components via comparing the user- specified k-anonymity parameter with workload balancing point. Both TDS and BUG have been accomplished in a highly scalable way via a series of deliberately designed MapReduce jobs. Experimental results have demonstrated that the hybrid approach significantly improves the scalability and efficiency of sub-tree data anonymization compared with existing approaches.

In cloud environment, the privacy preservation for data analysis, share and mining is a challenging research issue due to increasingly larger volumes of datasets, thereby requiring intensive investigation. Based on the contributions herein, we plan to further explore the next step on scalable privacy preservation aware analysis and scheduling on large-scale datasets.

