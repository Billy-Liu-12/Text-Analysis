Optimization Algorithm of Association Rule Mining Based on Reducing the Time  of Generating Candidate Itemset

Abstract?There are some problems about some optimization algorithms of Apriori such as they consume large memory space although they reduce the numbers of database scanning, or the problem about the difficulties to realize programming. This paper presents an Apriori?s optimization algorithm. The algorithm first uses the order character of itemsets to reduce the times of comparison and connection when it connects and generates the candidate itemsets, then compresses the candidate itemsets according to the following situation: whether the number of element "a" in the frequent K-itemsets is less than K. Through the experiment, it is proved that the algorithm can not only realize programming easily but also improve the efficiency of mining association rules.

Keywords-Data mining; Association rule; Apriori algorithm;  Candidate itemset; Frequent itemset

I.  INTRODUCTION Association rule is an important branch of data mining  research. It can find the relationship of project and its attribute or can find the relationship of attribute and attribute. For association rules mining, the most classical algorithm is Apriori algorithm. Firstly, it finds frequent itemsets, and then produces association rules by the frequent itemsets. In order to avoid the disadvantages of Apriori algorithm needing repeatedly scanning database and producing a large number of frequent itemsets, scholars put forward the improvement methods of Apriori algorithm. Through research and analysis, most improvement of the Apriori algorithm is remaining some problems. One is that it solved the problem of the multiple scanning of the transaction database, yet it takes more time in some other aspects. Another is that some algorithms are simple in methodology, but it is difficult to implement by programming or even impossible to achieve. The literature [1] proposed an improved algorithm of association rules based on the tree data structure. Each node of the tree is formed by the item and item?s transaction list, sibling is ordered in accordance with the support count of subset increasing order from left to right, each node with a pointer to TID list of transaction which itemsets corresponding to node contain. Finally, the algorithm mergers transactions which have same TID to find the frequent itemsets.

Although the algorithm scans the database only once, but it takes a lot of time to compare one by one to find the item with same TID. The literature [2] proposed an array-based optimization algorithm for mining association rules. The algorithm uses one-dimensional array to count the  Candidate 2-itemsets. This method only needs to scan the database once, however, it will consume more memory space to store, and there may be a large number of worthless elements in the established array, which also affected the efficiency of the scanning array. The literature [3] proposed a method that splitting each record, then saving deposit items to a binary tree. This method also scans the database only once, but it requires a lot of work in the split process, the programming is more complicated.

To solve the above problem, we propose an improved algorithm based on reducing transaction, the algorithm is not only more efficient than the Apriori algorithm and can be easily programmed.



II. IDEA OF THE IMPROVED APRIORI  Wherever Times is specified, Times Roman or Times New Roman may be used. If neither is available on your word processor, please use the font closest in appearance to Times. Avoid using bit-mapped fonts if possible. True- Type 1 or Open Type fonts are preferred. Please embed symbol fonts, as well, for math, etc.

A. The property of the classical Apriori Algorithm After studying we found that the properties of the  Apriori Algorithm are as follows: (1) All nonempty subsets of a frequent itemset must  also be frequent.

The property used to compress the search space. It can  delete the candidate items which inconformity with the property, in order to reduce the quantity of the candidate itemsets which need to participate in scanning the database for cumulative support.

(2) When the Apriori algorithm generates frequent (K+1)-itemsets, the number of the set of frequent K- itemsets is must more than k[4], that is, |LK| >k.

Proof: the set of frequent (K+1)-itemsets Ix = {i1, i2,?,ik+1} must be (K+1) frequent K-itemsets. if the number of items in the frequent k-itemsets, LK, is less than K+1, then there is no frequent ?k+1?-itemsets in the transaction database that be digged.

Example: frequent 3-itemsets, I=?A,B,C? ,by the property (1),that is that All nonempty subsets of a frequent itemset must also be frequent, must have altogether 3 frequent 2-subsets,that is, AB?AC and BC .so the number of itemsets must not less than 3 in L2,i.e. |L2|>2.

(3) If the number of element "a" in the frequent K- itemsets, Lk , is less than K, then "a" may not be included in frequent (K+1)-itemsets.

Moreover, we find that the Apriori Algorithm needs lots of judgment for connecting as follows: to judge whether the front K-1 items of the two K-itemsets are same; another, to judge the last item whether different. The operations of judgment and connection will occupy most of the time when the program is running. So, the running efficiency of Apriori Algorithm may be improved, if it can be reduced the times of judgment of conditions and the times of executing connection.

The Apriori algorithm assumes the items within every record is sorted in lexicographic order, so that candidate itemsets generated by it are ordered, and to compare elements of corresponding position among the candidate itemsets are ordered also, the generated frequent itemsets so such. Therefore, we can use the orderly characteristics among itemsets to reduce the times of connections when the Apriori algorithm is executing, thus to improve efficiency of the algorithm operating.

B. Improving the Apriori Algorithm On the basis of the above properties, we can propose an  improving algorithm based on transaction reduction, the algorithm can be described as follows:  Input: database, D, of transactions; minimum support threshold, min_sup.

Output: L, frequent itemsets in D.

Main: (1)L1 = {large1-itemset}; (2)if ?L1?<2  end ; (3)for(k=2; ? Lk+1 ? <k+2;k++);//By the second  property, if ?Lk-1?<k, it impossibly generates frequent k-itemsets, so we can assume the cyclic boundary values by using the property.

(4){ { Delete(Ik,k,Lk,Jk) }//By the third property, we  can delete the frequent itemsets which impossibly generate higher dimensionality.

(5) Ck=apriori_gen (Jk-1?min_sup);//to find Jk after handled Lk, then perform the function of apriori-gen(Jk-1, min_sup), generate candidate itemsets,Ck;  (6)for all transactions t?D do begin (7){Ct=Subset(Ck,t);} // get candidate itemsets, that is,  the subset of t.

(8) For all transactions c?Ct   do (9){ c.count++;} (10)end; } (11)Lk={ c?Ck?c.count?min_sup};} (12)Answer=UkLk;  Procedure apriori_gen(Jk-1?min_sup) //the method  of generating candidate itemsets, Ck, by Jk (1) For all items I1?Jk-1 (2) { For all items I2?Jk-1 (3)  {if ((I1[1]=I2[1]) ?  (I1[2]=I2[2]) ? ? ? ?I1[k-  2]=I2[K-2]??  (I1[k-1]<I2[k-1]))  do (4)      c=I1 ? I2;//connect two itemsets.

(5)      else break;// by the ordered property of itemset,  the later itemsets of I2 can not be merged with I1.

} } (6)if has_infrequent_itemset(c,Jk-1)  (7) delete c;//delete infrequent itemset (8) else Ck=C1 ? {c};//to incorporate c into Ck  Procedure has_infrequent_itemset(c,Jk-1)//the idea of  clearing away candidate itemsets which the subsets are infrequent itemsets  (1) for all (k-1)-subset s of c (2)   if  s?Jk-1   return true; (3)   else  return false; Procedure Delete(Ik,k,Lk,JK) (1)mincount=min?Lk(b)? //to count the number of  every element in Lk ,where b?Ik,Ik?Lk (2)while((Ik ? ? )&&(mincount< k) (3){ for all items a?Ik (4)   if ?Lk(a)?< k (5)   Ik=Ik-{a};    Jk=Lk-{P};//to delete all frequent  itemsets, P, of containing element, a, in Lk } return Jk;  The above algorithm reduces the times of judgment for  connecting, at the same time ,it deletes the subsets of impossibly generating higher frequent itemsets before connecting higher candidate itemsets, like this, it can reduce the cost of connection , so the efficiency of algorithm is improved. Furthermore, comparing with the Apriori algorithm, it only adds the subprogram, Delete(Ik,k,Lk,Jk),to the fourth step of main program, and adds breaking out of an iteration statement to the fifth step of the subprogram, apriori_gen(Jk-1?min_sup), these are prone to programming and implementation, and no additional storage space.



III. EFFICIENT ANALYSIS AND EXPERIMENTAL VALIDATION  A. Efficient analysis of the algorithm We use the following table 1 which shows the frequent  itemsets L2 to analyze the efficiency of the new algorithm.

Minimum support is set to 2.

TABLE I.  L2 FREQUENT ITEMSETS  Itemsets Support count (I1,I2) 4 (I1,I3) 4 (I1,I5) 2 (I2,I3) 4 (I2,I4) 2 (I2,I5) 2   First of all, when the Apriori algorithm determines the  itemsets whether can be connected,(I1,I2)must be compared with five itemsets, however, the updated algorithm will exit the loop after (I1,I2) is judged to be unable to connect to (I2,I3),at this time,(I1,I2) has only compared with three itemsets. For the L2 frequent itemsets, the Apriori algorithm needs fifteen times in comparative and judgment, the updated algorithm needs only nine times, it is nearly less half of work than the Apriori algorithm.

Secondly, the Apriori algorithm join to generate a candidate set C3, the join result is C3 = {{I1,I2,I3},{I1,I2,I5},{I1,I3,I5},{I2,I3,I4},{I2,I3,I5},{I2,I 4,I5}}.

According to the updated algorithm, since only one I4 in the L2,the number is less than two, so we can first removed (I2,I4) from the L2 before connection, so that we have C3={{I1,I2,I3},{I1,I2,I5},{I1,I3,I5},{I2,I3,I5}}.Thus we don?t need to find the subsets of (I2,I3,I4) and (I2,I4,I5),and no need to judge whether each subset is frequent itemset, clearly no need to pruning. Here the updated algorithm has reduced the time of comparing and connecting of candidate item, that can improve the efficiency of the mining.

B. Experimental validation In order to compare the efficiency of the two algorithm  from different aspects, I wrote the procedures for the two algorithms. Programs were running on Celeron CPU 2.66GHz, 80G HDD, 512M RAM, Matlab software. The data for mining is 11 specialty course grade of 135 students.

Support counts were taken 5, 7, 9, 11, 13. In order to avoid the influence of the system speed, I got an average time by repeatedly running the program with the same support count. Comparison of the efficiency shown in Figure 1.

From Figure 1 we can find that the efficiency of the two algorithms is in the relatively small difference with a high support, but the new algorithm?s efficiency is increased very significantly when the support is reduced.

Next, the two programs running on different number of records with a same support count, I got an average time of running the program several times with the same record number. Comparison of the efficiency shown in Figure 2.

From Figure 2 we can find that the efficiency of the two algorithms is in the relatively small difference with a small number of records, but the new algorithm?s efficiency is increased very significantly with a large number of records .



IV. CONCLUSION  To solve the problems of some other Apriori?s optimization algorithms, this paper presents an Apriori?s optimization algorithm based on reducing transaction. The algorithm is prone to programming and implementation, and no additional storage space. The experimental results show that the new algorithm more efficient than the classical Apriori algorithm. Obviously, it is a practical and efficient algorithm for mining association rules.

