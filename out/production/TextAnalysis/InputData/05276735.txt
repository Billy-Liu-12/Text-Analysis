

Abstract?The open source paradigm is giving rise to new methodologies, competences and processes that need to be in- vestigated both from the technical and the organizational point of view. Many organizations are investigating the possi- bility to adopt open source software or migrate their systems to open frameworks also in critical environments. In this pa- per, we shows how the assurance has been elevated as a pri- mary design requirement for organizations wishing to adopt open source products, and we describe the experience of a big telecommunication player in the process of implementing an assurance evaluation platform.

Index Terms?Assurance, Security, Open Source, Tele- communication.



I. INTRODUCTION  Software Assurance (SwA) is a complex concept that in- volves different stages of a software development process and may be defined differently depending on its focus, as for instance software quality [1,2], security, or dependabil- ity. In the past, assurance has been seen as the activity of reducing the information risk, improving, at the same time, the quality of data given to management and decision mak- ers. The concept of assurance is then associated to different tasks, such as risk assessment, information systems secu- rity, internal audit, and customer satisfaction surveys, all concentrated on specific aspects of the workflow they are applied to.

In Computer Science, the term assurance is referred to all activities necessary to provide enough confidence that a software product will satisfy its users? functional and non- functional requirements. In this paper, we focus on security and dependability (S&D) assurance, intended as the activity aimed at increasing the level of confidence that a software product is operating as intended and is free of faults. In a traditional, lifecycle-based software development process (see Fig. 1), assurance includes a number of tasks to be car- ried out by developers and testers along the software life- cycle. A number of standards have been defined to specify which security requirements a product should satisfy, while assurance standards specify how to collect and provide the evidence that it does [3].

Recalling that assurance activities are process-oriented, Fig.

1 shows the security activities mapped on a traditional wa-  terfall-based development process. They cover all the phases of the process, starting from the Requirements and Use Cases definition, where specific tests analyze the ful- filment of security requirements and the presence of possi- ble abuse cases [4], and looking for interactions between a system and one or more actors, where the results of each interaction are harmful to the system. Then, a general risk analysis is fulfilled in parallel with the Architecture and Design phase. Furthermore, the set of test cases is enriched with risk-based security tests, created not directly by the product properties and functionality, but modelling possible security threats and attacks, probing the application behav- iour in such critical situations.

Following the workflow, during the Code phase, specific tools are exploited to calculate the sets of product metrics that are able to assess code quality, dependability, perform- ance, and the like. Finally, the results of the implemented test cases are examined throw an exhaustive Penetration Testing [5]. Once an application is released, it is evaluated using a penetration testing as part of the final acceptance test. In this context, security consultants typically test secu- rity requirements of the product by simulating an attack by a malicious user; such tests involve an active analysis of the system for any potential vulnerability that could result from incomplete or wrong system configurations.

Of course, cooperative and agile development processes, like the ones used for open source, do not lend themselves to all assurance tasks showed in Fig. 1. In this scenario, the definition of assurance mechanisms for open source solu- tions is a difficult task. Some approaches in the past have been provided in the context of big open source projects, such as Linux, where a patch-based approach (Section 2)  Claudio A. Ardagna1, Massimo Banzi2, Ernesto Damiani1, Member, IEEE, Fulvio Frati1 and Nabil El Ioini3   1Dipartimento di Tecnologie dell?Informazione (DTI), Universit? degli Studi di Milano Via Bramante 65, Crema (CR), 26013, Italy  e-mail : {claudio.ardagna,ernesto.damiani,fulvio.frati}@unimi.it 2 Telecom Italia - Technology & Operations Innovation Architecture and Quality dep.

Via Zambra, 1 ? 38100 Trento Italy e-mail : massimo.banzi@telecomitalia.it  3 Free University of Bozen-Bolzano Largo Adolph Kolping, 3 ? 39100 Bolzano ? Italy  e-mail : nabil.elioini@unibz.it  An Assurance Model for OSS Adoption in Next-Generation Telco Environments      Fig. 1: Assurance tasks in a traditional, lifecycle-based development proc- ess           has been adopted for the definition of assurance tasks.

In this paper, however, we focus on the problem of defining assurance tasks for open source products in mission-critical context, such as telecommunication (Telco) applications.

We consider a Telco environment, since it is one of the most challenging in which the adoption of the open source paradigm may be successful and play an important role.

Also, in complex environments, existing assurance tasks are not suitable because: i) traditional approaches (see Fig.

1) are not applicable to a chaotic and unstructured software development process like the open source one, and ii) patch-based approach involves the community only without considering the final users.

In current big Telco players, OSS components are downloaded and embedded in existing solutions (critical or not) when needed; here, no many cares are given to prob- lems involving quality and security. In the last few years, some of these Telco players (including TelecomItalia (TI)) are trying to move from such an ?opportunistic? approach to Open Source Software (OSS), to a more formalized one.

A strategy on how approaching OSS to ensure quality is currently under development and spans through three main branches: i) the evaluation of the actual (quantified if pos- sible) value that opening an internally developed platform can have; ii) the definition of a full governance procedure that allows Project Managers to decide the approach to OSS, related to the criticism and the characteristics of the application they have to implement; iii) the creation of a community of peers (Tier One Service Providers within the TeleManagement forum) that share experience, skills, pos- sibly also software, and overall approaches towards OSS in an Open Source Working Table.

The drivers for all these initiatives are: ensure software quality, the reduction of Total Cost of Ownership (TCO) and the flexibility and dynamicity of solutions implemented using OSS components.

The remainder of this paper is organized as follows. Sec- tion 2 introduces a patch-based approach for security and dependability assurance in huge OSS projects. Section 3 discusses a new approach to assurance process in the con- text of critical Telco scenario. Section 4 provides a case study based on the introduced Telco environment. Finally, Section 5 presents our conclusions.



II. SECURITY AND DEPENDABILITY ASSURANCE IN HUGE OSS PROJECTS: LINUX EXPERIENCE  Nowadays, OSS and its components play an important role in the enterprise ICT infrastructures. However, although the adoption of OSS software is permeating the entire distrib- uted systems, its adoption for complex mission-critical ap- plications, such as telecommunications and embedded sys- tems, is still quantitatively and qualitatively less successful than it could be, even in presence of detailed adoption guidelines. Relatively few companies in fact do not use open source products and technologies at all, but project managers working on complex systems still perceive barri- ers that limit their use, including security and license topics [6,7]. A further complicating factor is the difficult to estab- lish a process-based assurance model, since the open source paradigm is based on a cooperative community-based code  development, where code changes rapidly over time and unambiguous specifications may simply not be available. In this context, OSS community works and acts with its par- ticular workflow that cannot be perfectly modelled. As a consequence, OSS has fostered a new development style based on a heterogeneous mixture of existing methodolo- gies and new development processes. It does not provide any standard criteria to select activities for the different projects; instead, it is up to the developers to agree on which methodology is more suitable for them [8].

An important requirement, which might facilitate the de- ployment of OSS within enterprise frameworks and in mis- sion critical applications, is then the design and develop- ment of innovative test- and model-based assurance metrics for OSS evaluation, which map the intrinsic characteristics of open source on the assurance process. Of course some huge OSS projects (e.g., Linux) have developed their own assurance tasks, adopting a patch-based approach to com- pensate for the lack of requirements and design documenta- tion.

Security assurance activities for OSS code could then be performed at several points in the code life cycle [9]. Con- tributions to major OSS projects like Linux are strictly monitored and must meet quality standards; here, we are interested in the assurance process used to keep these stan- dards. Of course, different OSS projects will use different assurance procedures, but some conditions are verified for all OSS projects. Upon submission, a contribution to an OSS project must be well-formed, that is, coded and pack- aged according to well-established OSS conventions. The first assurance activity is usually to check for novelty and interest of the contribution, that is, the properties (either functional or non-functional) it would add to the project.

These checks are usually made by core members of the community (by the subsystem maintainers in the case of the Linux kernel). Once a contribution is accepted into an OSS project, it will be tested and reviewed by the project?s com- munity, to become part of the project?s mainstream code. In the specific case of Linux, the process is two-tiered (see Fig. 2): if the subsystem or project containing the new con- tribution is then picked up by a Linux distribution like SuSE, it will be subject to that distribution-specific assur- ance procedure. Typical assurance activities performed at distribution level include standards-compliance (for exam- ple, LSB and POSIX), stability and robustness testing. It should be noted that the assurance process described above    Fig. 2: The two- and three-tiered assurance process of big OSS projects [20].

(see Fig. 2) can also be made three-tiered by adding a user- specific assurance activity at adoption time. In the case of Linux, this assurance procedure is coarser-grained, as adopters retain control over the inclusion of each specific subsystem in the distribution, in the form of patches, but, of course, not over individual contributions to subsystems.

Regression is always possible, that is, the adopter can al- ways return to a previous version of the subsystem if an update does not meet the adopter?s quality or dependability standards. Some adopters prefer to entirely delegate secu- rity and quality assurance to their preferred distribution; others try and influence the OSS product evolution at both design and assurance time.1 However, in critical contexts, assurance must be standard- ized and focused to the customer?s needs to meet the re- quirements of companies adopting the software. In general, it is possible to identify two types of OSS adoption ap- proaches which involve assurance activities: the adoption of existing OSS vertical solutions, or the exploitation of OSS horizontal solutions to create new vertical services.

The former case (i.e., vertical solution) implies two differ- ent analysis areas. Looking at the administrative department or the overall IT infrastructure, the adoption of vertical so- lutions is possible and successful. In the literature, is well- acknowledged how the migration, as for instance, from Mi- crosoft Office to OpenOffice.org package, and from Win- dows to Linux systems, is successful and used as a leverage to reduce contract and license cost. By contrast, looking at frameworks typical of Telco companies, such as Opera- tional Support Systems, that represent systems directly managing the telecom network, and Business Support Sys- tems (often referred as OSS/BSS), that manage customers processes, the overall specificity, criticality and complexity of them could represent a barrier for the adoption of spe- cific OSS implementations.

The latter case (i.e., horizontal solution) describes the trend to participate in the development community, adopting horizontal frameworks over which new and re-engineered vertical services are developed. Following that philosophy, Banzi et al. in [9] describe the strategy adopted by Tele- comItalia Technology Department towards open source software. In particular, they describe the approach and ex- perience in starting the WADE project, an extension of the JADE open source framework [10] for the development of interoperable intelligent multi-agent systems. TelecomItalia coordinates the open source community involved in WADE project, with the interaction of other Telco players, to pro- duce a framework that satisfies the needed security and functional requirements and that will be exploited to build new vertical services.

The interaction with Telco companies is a fundamental as- pect in the development of open OSS/BSS systems, making the patch-based assurance tasks discussed above not useful in practice. In that context, the need of a solution (described in Section 3) that is applicable for OSS and involves the   1 In the telecommunication sector, Carrier Grade Linux (CGL) defines a set of specifications as well as some assur- ance criteria which must be met in order for Linux to be considered ?carrier grade? (i.e., ready for use within the telecommunications industry).

software adopters arises. In this scenario, it is also impor- tant to note that the interaction with Telco companies and OSS community is greatly dependent on the size of the Telco player: the bigger the company, the easier to have corporate agreements with big software vendors, the less probable the adoption of OSS solutions will be.



III. OSS ASSURANCE IN THE TELCO SECTOR  Three different types of assurance can be defined focusing on the telecommunication sector: security assurance, aimed at preserving and verifying the security requirements, which are at the basis of the software, dependability assur- ance, representing the activities focused on verifying the robustness and reliability of a systems, and quality assur- ance [11], in particular with respect to possible mainte- nance actions. In the following, we focus on the security and dependability aspects of the assurance tasks.

A. OSS Assurance in the Telco Sector: the Requirements  The path for the adoption of OSS in Telco companies, and in general in large organizations, needs particular care.

S&D assurance plays an important role, since a certification of security and dependability properties of a particular OSS might remove most of the barriers in the migration or in the implementation of new systems. To give such a certifica- tion, till not formalized in recognized standards, it is impor- tant to establish some principles and metrics that could help in the evaluation.

Assurance tasks are applied to community activities to cer- tify that all the security requirements are implemented and that the developers group is acting promptly and effec- tively. Fig. 3 depicts the definition of assurance tasks in OSS mission-critical applications. In particular, as soon as a new version of the software has been released, forums and blogs are exploited by the developers to discuss the overall assurance of the product based on the security re- quirements.

Then, data collected after the discussion are used as the ba- sis for the next development phase. In particular, discussion outcomes are used in a new cycle of development phase, resulting in the implementation of a new software proto- type. A set of assurance metrics are finally applied to the prototype to evaluate and certify the assurance properties of the code. After metrics evaluation, the assurance tasks are applied iteratively.

In particular, S&D assurance for OSS is then based on col-     Fig. 3: Assurance tasks definition in mission-critical OSS           lecting a shared set of metrics that has to be identified and applied to the software under examination (see Section 4.1). These metrics must ensure that the community and the OSS products have a minimum level of acceptability by Telco companies, in relation with the criticalities of the so- lution in which to embed the OSS, and evaluating the skills and the participation level in the development group. A measure of the overall quality of the OSS products is also important, to certify that a minimum level of quality is al- ready ensured by the OSS application (see Section 4.2).

This measure can guarantee that the adoption of an OSS application will not imply too effort for the organization, or too risks in its integration within developed solutions. The quality analysis needs to verify the accordance with well- established coding-standards and the respect of the security requirements. Finally, a deep analysis is necessary to verify the adaptability of the different type of OSS licenses within the areas of the business process typical of Telco compa- nies, to avoid violating copyright or restrictions.

B. OSS Management  Moving from a ?just use it? approach to a more ?strategic? one means having a great care to S&D as well as Quality Assurance aspects.

In particular, the Telco business process is based on eTOM (enhanced Telecom Operations Map) [12], released by the TeleManagement Forum as an update of the original TOM model, and includes a hierarchy of process definitions, of- fering a structure and a model to understand and develop areas of the process. Also, it is applied by Service Providers (SP) as a reference and a basis for internal and external dis- cussion around business needs and interoperability, as well as by Suppliers and others as a means of understanding and discussing SP behaviour and requirements.

A survey of OSS components embedded within TelecomI- talia Support Systems, classified according to eTOM model (see Table 1), gives an idea on how pervasive can be their distribution within the overall eTOM process framework.

This can be either a good signal, in the sense that an uncon- trolled use leads to a homogenous distribution of OSS, but also a worrying one, since OSS can be applied in critical contexts where a careful check of dependability and secu- rity assurance are a must.

The eTOM model is also important in the management of licenses and Intellectual Properties Rights (IPR). Different processes and areas of the process imply different levels of visibility and customization of the adopted OSS code. This leads to a careful analysis of the license types and the area where they are integrated to ensure the consistency of the adopted OSS code with respect to the declared license.

Commercial tools like the ones released by Black duck Software [13] give a good level of assurance on such legal aspects. The high cost of ownership of such frameworks raises the need of an assurance metric that could give an assurance about this legal aspect. According to the specific service in which the OSS component is embedded, special care has to be taken in verifying the suitable licenses. An analysis of the distribution of license types adopted with respect to the eTOM Process Areas is reported in Table 1.

Then, further researches must be dedicated to Quality As- surance, since the ability to estimate maintenance costs of an embedded OSS component is clearly important. Metrics for such estimation derive directly from software engineer- ing principles like coupling, cohesion, cyclomatic complex- ity and compliancy to coding standards.

However, the selection is also driven by internal develop- ers? and managers? skills, which are used to drive the work in a protected environment. In the OSS case, developers need to learn how to work in a community environment in which technical skills and relational capability play an im- portant role. It is important to understand people working style within the community and, accordingly to the ap- proach selected for the specific OSS component, behave consequently.

The style of relationship with the community, in fact, has to be guided by the criticism of the solution the OSS compo-  Table 1 The distribution of OSS usage within eTOM Business Process Framework in TelecomItalia               nent is going to be embedded in.

Accordingly to this, in fact, it can be decided to:  ? just skill people on the product to be able to work on the code in case of critical bugs fixing;  ? ignite the community with developers for enhance- ments or bugs fixing to acquire competence on the code, but also to provide significant contributions to the code base to be ready to continue the developing outside the community, in case of frictions or unex- pected behaviour;  ? join the board to have influence over the product roadmap. Again the criticism of the OSS component is the driver and, in that case, the company could decide to invest in the selected OSS, enhancing its functionalities, since no suitable commercial com- ponents are available or its customization costs are too high.

In particular, the last point has to be considered when the investment is raising to a significant level. If the company wants to have the highest Return of Investment (ROI), once ensured that problems with the licenses and internal skills are overcome, the best approach is to operate directly on the open source community environment in implementing the necessary functionalities. This could be an alternative to the internal development of the code, which takes advan- tages by all possible contributions from the community.

An other important requirement is to protect the organiza- tion against sudden events within the company itself (criti- cal bugs fixing, changes in the scheduling of internal solu- tions) or the community. This can be achieved by negotiat- ing privileges with the community, such as implementing internally certain features in protected development branches, where the commit control is delegated only to the company: the code is always open, it is visible by all, and everyone, if authorized, can contribute to the specific func- tionality. Following that approach, the code is ready for merging to the final trunk, but the company investment is protected. Concluding, the community environment over- laps the company one only for specific purposes.



IV.  CASE STUDIES  The following Section describes the assurance model de- veloped by TI in collaboration with academic institutions.

This model has been exploited to evaluate open source products for their adoption within the eTOM Framework.

Our research does not focus on OSS components managed by well structured and stable communities, for which an assurance evaluation already exists (i.e., Linux), but rather to components developed by small active communities. In this case, ad-hoc quality and S&D assurance models be- come necessary to evaluate the suitability of OSS products from the point of view of the organization that wants to in- vest on them.

A. Collecting Metrics on OSS S&D  The first step in the development of an assurance model is the definition of a set of metrics for the evaluation of OSS that will be used to choose the best products that fit Telco requirements. The problems faced by analysts are princi- pally related to the lack of reliable information to build a  complete set of metrics. In particular, in literature is not available a framework of metrics commonly accepted as a reference, but a number of independent projects (e.g., in [9] and [14]) provide their own metrics, each one concentrated on a specific aspect. Also, there is a lack of information on OSS, such as the number of releases, number of core de- velopers, number of released patches, or the discussion threads typology. Even though important portals like SourceForge [15], Freshmeat [16], and the OW2 consor- tium [17], release data about the OSS they host, these data are semantically different and do not permit cross-portal evaluations. For example, the simple definition of ?close? for a bug is subject to different interpretations, or the im- portance given to the number of downloads could vary if the community considers more relevant the quality of a product rather than its diffusion.

Along with traditional OSS evaluation and selection frame- works [21,22], TI adopted FOCSE (Framework for Open source Critical Systems Evaluation) [18], a framework de- veloped by University of Milan based on a set of general purpose security-related metrics. FOCSE includes some specific metrics expressing capabilities in responding to continuous changes in security threats, and is then suitable for evaluating open source security frameworks. The pro- vided metrics analyse OSS focusing on multiple specific areas: i) Generic Application, ii) Developers Community, iii) Users Community, iv) Software Quality, v) Documenta- tion and Interaction support, and vi) Integration and Adaptability with new and existing technologies.

Furthermore, the Qualipso Project [14] has been contacted to share knowledge and experiences about the forthcoming Qualipso set of OSS evaluation metrics. The project is aimed at defining and implementing technologies, proc- esses and policies to facilitate the development and adop- tion of OSS components. Here, an important aspect is to guarantee the same level of trust traditionally offered by proprietary software.

As a result of this joint effort involving TI, University of Milan, University of Bolzano, and different OSS communi- ties (board of OW2 and Apache.org), TI selected a set of metrics, modified them in accordance to its context and needs, and started to collect data using them. Currently, a TI internal group is working towards the application of the above metrics to OSS, taking ahead the initiative within the TeleManagement Forum to involve other big Telco Players.

B. Quality and S&D Assurance  The level of quality required for the implemented software arises with respect to the criticality of the environment it is going to be embedded in. The criticality and complexity of Telco systems (e.g., for OSS/BSS systems) require the analysis and control of software quality during the whole development process (ensured by the quality or assessment levels of the factory or of the partner companies or ven- dors). Because of the specificity of the OSS process, such controls are concentrated on the assessment of the code quality, rather than enlarging the analysis to the other de- velopment phases. A check on the quality of the OSS com- ponents can be performed by just verifying the adoption of simple coding rules using ABC metrics or complexity           evaluating tools. Also the compliancy to J2EE (Java 2 En- terprise Edition) specifications can be verified.

However, the main problems arise when checking security [6,7], dependability and license compliancy to internal re- quested standards. In the case of OSS, there are no design documents where information on the structure of the prod- uct can be found, thus no test cases are available or easily deployable. In addition, only solutions based on costing re- verse engineering processes are possible. Another alterna- tive is the use of proprietary parsing tools, such as Fortify [19], to check the presence of security flaws, or BlackDuck [13], to bolster software licensing compliance.



V. CONCLUSIONS  Open Source Software plays an important role in today?s enterprise ICT infrastructures. However, in the context of complex mission-critical applications, OSS adoption is still limited and insufficient, even in presence of detailed adop- tion guidelines. Among the others, a limiting factor to OSS adoption is that software security assurance activities are traditionally interleaved with development ones; this makes difficult to establish a process-based assurance model for OSS, since the open source paradigm is based on a coop- erative community-based code development, where code changes rapidly over time and unambiguous specifications may simply not be available. In this paper we argued that, due to its lack of a formal development process, OSS re- quires decoupling assurance from development. Here, we put forward the idea that assurance must be standardized and focused to the customer?s needs to meet the require- ments of companies adopting the software. To this aim, it is important to establish some principles and metrics that could help in the definition and modelling of assurance tasks. Our industrial (Telco) case studies confirm that OSS assurance should rely on measuring a consistent set of met- rics that can be reverse-engineered from code rather than requiring the availability of design documentation.

To conclude, the assurance process discussed in this paper can provide, on the one side, a benefit for the communities and companies that wish to adopt an OSS solution, and, on the other side, a means to self protect companies from pos- sible problems arising from OSS adoption.



VI. ACKNOWLEDGEMENTS  This work was partly founded by the European Commis- sion under the project SecureSCM (contract n. FP7- 213531) and by the Italian Ministry of Research under FIRB TEKNE (contract n. RBNE05FKZ2_004).



VII. REFERENCES  [1] B. Boehm, J. Brown, M. Lipow, and G. MacCleod, Characteris- tics of Software Quality, NY, American Elsevier, 1978.

[2] B. Kitchenham and S.L. Pfleeger, ?Software quality: the elusive target,? IEEE Software, 13(1):12?21, January 1996.

[3] E. Damiani, C.A. Ardagna, and N. El Ioini, Open Source Systems Security Certification, Springer, December, 2008.

[4] J. McDermott and C. Fox, ?Using Abuse Case Models for Security Requirements Analysis,? in Proc. of the 15th Annual Computer Security Applications Conference (ACSAC '99), Washington, DC, USA, December 1999.

[5] B. Arkin and S. Stender and G. McGraw, ?Software Penetration Testing,? IEEE Security and Privacy, 3(1):84?87, 2005.

[6] C. Cowan, ?Software security for open-source systems,? IEEE Security & Privacy, 1(1):38?45, January-February 2003.

[7] C. Payne, ?On the security of open source software,? Info Systems Journal, 12:61?78, 2002.

[8] J. Feller and B. Fitzgerald, Understand Open Source Software De- velopment, Addison-Wesley, 2002.

[9] M. Banzi, G. Bruno and G. Caire, ?To What Extent Does It Pay To Approach Open Source Software for A Big Telco Player?,? In Proc. of the IFIP WG 2.13  Working Conference On Open Source Systems, Milan, Italy, September 2008.

[10] JADE (Java Agent DEvelopment Framework), available at: http://jade.tilab.com/, 2009.

[11] I. Stamelos, L. Angelis, A. Oikonomou, and G.L. Bleris, ?Code quality analysis in open source software development,? Info Sys- tems Journal, 12:43?60, 2002.

[12] Business Process Framework (eTOM), available at: http://www.tmforum.org/browse.aspx?catID=1647, 2009.

[13] Manage Open Source Software ? Black Duck Software, available at: http://www.blackducksoftware.com/, 2009.

[14] Qualipso - Trust and Quality in Open Source systems, available at: http://www.qualipso.org/, 2009.

[15] SourceForge.net: Open Source Software, available at: http://sourceforge.net/, 2009.

[16] Freshmeat.net, available at: http://freshmeat.net/, 2009.

[17] OW2 Consortium, available at: http://www.ow2.org/, 2009.

[18] C.A. Ardagna, E. Damiani, and F. Frati, ?FOCSE: An OWA-  based Evaluation Framework for OS Adoption in Critical Envi- on Open Source Systems (OSS 2007), Limerick, Ireland, June 2007.

[19] Fortify Software, available at: http://www,fortify.com, 2009.

[20] B. Weinberg, ?The Open Source Development Process,? avail-  able at: www.embedded-computing.com/departments/osdl/2005/1,  [21] OpenBRR, A Framework for Evaluating Open Source Software,: www. openbrr.org, 2009.

[22] Davide Taibi, Luigi Lavazza, and Sandro Morasca, ?OpenBQR: a framework for the assessment of OSS,? in Proc. of The Fourth 2008), Milan, Italy, September 2008.

