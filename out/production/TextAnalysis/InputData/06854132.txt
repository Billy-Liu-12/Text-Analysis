A NETWORK OF COOPERATIVE LEARNERS FOR DATA?DRIVEN STREAM MINING

ABSTRACT  We propose and analyze a distributed learning system to classify data captured from distributed and dynamic data streams. Our scheme consists of multiple distributed learners that are interconnected via an exogenously-determined net- work. Each learner observes a specific data stream, which is correlated to a common event that needs to be classified, and maintains a set of local classifiers and a weight for each local classifier. We propose a cooperative online learning scheme in which the learners exchange information through the network both to compute an aggregate prediction and to adapt the weights to the dynamic characteristics of the data streams. The information dissemination protocol is designed to minimize the time required to compute the final prediction.

We determine an upper bound for the worst-case misclas- sification probability of our scheme, which depends on the misclassification probability of the best (unknown) static ag- gregation rule. Importantly, such bound tends to zero if the misclassification probability of the best static aggregation rule tends to zero. When applied to well-known data sets ex- periencing concept drifts, our scheme exhibits gains ranging from 20% to 70% with respect to state-of-the-art solutions.

Index Terms? Big Data, Stream Mining, Data-Driven Application, Concept Drift, Online Learning, Classification, Networked Learners  1. INTRODUCTION  Recent years have witnessed the proliferation of data-driven applications that exploit the large amount of data captured from distributed data sources. Examples of such applications include surveillance, network monitoring, smart grids, social multimedia, and patient monitoring. However, the effective utilization of such high-volume data also involves significant challenges that are the main concern of this work. First, the statistical properties of the data can evolve in time. Second, the privacy, communication, and sharing costs make it diffi- cult to collect and store all the observed data.

The material is based upon work funded by the US Air Force Research Laboratory (AFRL). Any opinions, findings, and conclusions or recommen- dations expressed in this article are those of the authors and do not reflect the views of AFRL.

The work of Luca Canzian and Mihaela van der Schaar was partially supported by the NSF grant CCF 1218136.

To address these challenges, in this work we propose an online learning scheme [1] in which a set of distributed learn- ers, interconnected via an exogenously-determined network, observe different data streams and exchange pre-processed information to classify a common event and to adapt their configurations to the dynamic characteristics of the data streams. Specifically, each learner maintains a set of local classifiers and a weight for each local classifier, and generates a weighted local prediction about the common event based on the locally observed data. The weighted local predictions are exchanged and combined by each learner using a majority rule to compute the final prediction. After the final prediction has been generated, the learners observe the label ? the true value of the event to be classified ? and exploiting such infor- mation they update their local weights adopting a Perceptron learning rule [2].

We determine an upper bound for the worst-case misclas- sification probability of our scheme which depends on the misclassification probability of the best (unknown) static ag- gregation rule. Importantly, the misclassification probability of our scheme tends to 0 if the misclassification probability of the best static aggregation rule tends to 0. Since in the pres- ence of concept drift [3] (i.e., non-stationary data streams) it is highly unlikely that the misclassification probability of the best static aggregation rule tends to 0, we also extend such an asymptotic result considering assumptions that are more appropriate in the presence of concept-drifting data streams.

When applied to well-known data sets experiencing concept drifts, our scheme exhibits gains ranging from 20% to 70% with respect to state-of-the-art solutions.

Much work has been done in the past decade on the devel- opment of online ensemble learning techniques [4, 5, 6]. An online version of Adaboost [7] is described in [8], and similar proposals are made in [9] and [10]. Weighted majority [11] maintains a collection of given learners and their weights, pre- dicts using a weighted majority rule, and decreases (in a mul- tiplicative manner) the weights of the learners in the pool that disagree with the label whenever the ensemble makes a mis- take. Modified versions of weighted majority are proposed in [12] and [13]. [14] proposes a scheme based on two online en- sembles, one used for system predictions, the other one used to learn the new concept after a drift is detected.

All the above learning techniques consider a centralized scenario, in which the learners observe the same data and can      be centrally retrained. The present study is related to these works and exploits a learning scheme which is similar to that adopted by the weighted majority schemes, but it is focused on a distributed scenario, in which the learners observe dif- ferent data streams and are connected via an exogenously- determined network, which constrains their communication capabilities. In fact, our learning scheme is proposed and evaluated not only for its prediction accuracy, but also for its capability to generate timely predictions in a distributed envi- ronment.

The rest of this paper is organized as follows. Section 2 presents our formalism, framework, and algorithm for dis- tributed online learning. Section 3 characterizes the predic- tion delay of the proposed system and proves a bound for the misclassification probability of our scheme. Section 4 presents the empirical evaluation of our algorithm on several data sets. Section 5 concludes the paper.

2. THE PROPOSED COOPERATIVE DISTRIBUTED LEARNING SCHEME  We consider a set of L learners and we divide time into slots.

At the beginning of the n-th time slot, each learner i observes a multi-dimensional instance or feature vector x(n)i ? Xi, which is correlated to a common and unknown label y(n) ? {?1, 1}. The task of each learner is to predict the label y(n).

Each learner i is equipped with a set {f (n)i,k } of Ki local classifiers. Each local classifier f (n)i,k : Xi ? {?1, 1} gen- erates the local prediction s(n)i,k ? f  (n) i,k [x  (n) i ] at time slot n.

The classifier f (n)i,k can either be a pre-trained static classifier or an incremental classifier that varies with time n [15]. In both cases, we assume that its form is given so that its design is not the focus of this work: our emphasis will be on how to aggregate the local predictions made by the classifiers. We denote by K ?  ? i Ki the total number of local classifiers in  the system. In addition to the set of classifiers, we assume that learner i maintains a set of Ki weights, one weight for each of its local classifiers. We denote by w(n)i,k the weight that refers  to classifier f (n)i,k in time instant n. We define the contribution  C (n) i of learner i to the final prediction in time instant n as  C (n) i ?  Ki? k=1  w (n) i,k s  (n) i,k  We assume that the learners are connected via an exoge- nously determined network G, which is defined as the set of links among pairs of learners. We say that there is a link (i, j) between learners i and j if they can communicate di- rectly. The distance di,j between i and j is defined as the minimum number of links which separates i from j. The di- ameter D(G) ? maxi,j di,j of the network G is the maximum among all the distances.

We consider a minimum diameter spanning tree G of the original network G [16], i.e., among all the acyclic connected networks obtained by cutting some links from G, G has the smallest diameter. If D(G) is even there is a unique learner ? which we refer to as sink learner ? whose distance from the other learners is at maximum D(G)/2. If D(G) is odd there are two linked learners ? which we refer to as sink learn- ers ? whose distance from the other learners is at maximum (D(G) + 1)/2. We define the depth ?i(G) of learner i in G as the distance between i and the farther sink learner, we have maxi ?i(G) = ?D(G)2 ?, where ?z? denotes the smallest integer equal to or larger than z. If i and j are linked and ?j(G) = ?i(G) + 1 we say that i is the parent of j and j is a child of i. We denote by N i the set of children of i.

The proposed cooperative distributed learning scheme ini- tializes the weights w(1)i,k = 0, ? i, k, and in each time slot n is described through the following five sequential phases: 1) Observation phase. Each learner i observes the data x(n)i and computes its contribution C(n)i .

2) Exchange of the aggregate contributions. We divide this phase into ?D(G)2 ? stages. For each stage s = 1, . . . , ?D(G)2 ?, each learner i having depth ?i(G) = ?D(G)2 ?+ 1? s sends to its parent the message m(n)i = C  (n) i +  ? j?N i m  (n) j , where  m (n) j is the message i received in the preceding stage from its  child j ? N i.

3) Computation and exchange of the final prediction. Each sink learner computes the final prediction y?(n) adopting a weighted majority rule [8, 11, 12, 13],  y?(n) = sgn ( w(n) ? s(n)  ) (1)  where w(n) ? (w(n)1,1 , . . . , w (n) 1,K1  , w (n) 2,1 , . . . , w  (n) L,KL  ) ? ?K and s(n) ? (s(n)1,1 , . . . , s  (n) 1,K1  , s (n) 2,1 , . . . , s  (n) L,KL  ) ? {?1, 1}K are the weight and local prediction vectors, respectively, w(n) ? s(n) ? ?Li=1 C(n)i is the inner product between w(n) and s(n), and sgn(?) is the sign function (we define sgn(0) ? 1). The final prediction y?(n) is then spread in the network through D(G)??D(G)2 ? stages in which each learner forwards y?(n) to its children.

4) Feedback phase. The learners observe the label y(n).

5) Weights update phase. Each learner i compares y?(n) with y(n) and use this information to update the weights w(n)i,k , k = 1, . . . ,Ki, of its local classifiers. Specifically, we ap- ply the Perceptron learning rule [2] to the aggregation rule (1), obtaining the following update rule  w (n+1) i =  ??? ??  w (n) i,k if y?  (n) = y(n)  w (n) i,k + 1 if y?  (n) ?= y(n) and s(n)i,k = y(n) w  (n) i,k ? 1 if y?(n) ?= y(n) and s(n)i,k ?= y(n)  (2)  Learner i maintains the same weights if the final prediction agrees with the observed label, y?(n) = y(n). If disagreement     occurs, then learner i increases by one unit the weights of its classifiers that agree with the label, and decreases by one unit the weights of its classifiers that disagree with the label. Every other learner in the network implements a similar strategy.

Notice that w(n)i,k is always an integer number, ? i, k, n.

3. PERFORMANCE  In this section, we evaluate the performance of the proposed learning scheme.

In Subsection 3.1 we characterize the prediction delay ? the time to output the final prediction ? and we show that for a large class of networks the proposed information dissemi- nation protocol is optimal ? it minimizes the prediction delay.

In Subsection 3.2 we analyze the misclassification proba- bility ? the number of prediction mistakes per instance ? and we prove an upper bound for the misclassification probability of our scheme that depends on the misclassification probabil- ity of the best (unknown) static weighted majority aggrega- tion rule. Importantly, the resulting bound tends asymptoti- cally to 0 if the misclassification probability of the best static aggregation rule tends to 0.

3.1. Prediction delay In many stream mining applications it is vital to take timely decision based on timely predictions. In a distributed envi- ronment, the time required to compute the final prediction y?(n) is constrained by the prediction delay T (G), i.e., the time needed to spread the required information in the network.

We consider a positive and monotonically increasing link delay function f : N ? ?+.1 We interpret f(x) as the time required to transmit x bits over a link. Alternatively, f(x) can be interpreted as a cost, e.g., the energy required to transmit x bits over a link or the price to pay to access the information of another learner. We denote by xboo and xint the number of bits ? included overhead bits ? required to transmit a Boolean value and an integer number, respectively.

Proposition 1 characterizes the prediction delay TP (G) for the proposed scheme.

Proposition 1 The prediction delay TP (G) of the proposed scheme is  TP (G) = ? D(G)  ? f(xint) +  ( D(G)?  ? D(G)  ?) f(xboo)  Proposition 1 shows that the prediction delay depends only on the diameter of the minimum diameter spanning tree network G and hence increases slowly in the number of learners L.2 Notice the proposed dissemination protocol is  1The proposed information dissemination protocol can be generalized considering link-dependent delay functions fi,j , for each link (i, j).

2[17] proves that the diameter of a random acyclic network grows as O(  ? L).

not simply a matter of networking, it exploits the particular structure of the proposed aggregation and learning rules, (1) and (2), to efficiently combine data at intermediate learners.

Proposition 2 shows that the considered information dis- semination protocol allows to minimize the prediction delay for the class CDP of diameter-preserving spanning tree net- works, i.e., for each network G such that D(G) = D(G).

Acyclic networks are an example of such networks.

Proposition 2 Let P? an information dissemination protocol such that all learners are able to compute the final prediction (2). If G ? CDP then T P? (G) ? TP (G)  3.2. Misclassification probability  We denote by q(n)(x(n)1 , . . . ,x (n) L , y  (n)) the probability that the learners observe the instances x(n)1 , . . . ,x  (n) K and the la-  bel is y(n). As in [3], we refer to a particular probability dis- tribution qc as a concept, we say that the concept is stable if q(n) is an independent and identically distributed process with q(n) = qc, ?n, whereas we say that at time instant n there is a concept drift if q(n+1) ?= q(n).

Given the sequence of N instances and labels  DN ? ( x (n) 1 , . . . ,x  (n) K , y  (n) ) n=1,...,N  ,  we denote by PO(DN ) the misclassification probability of a learner that combines the local predictions of all the classifiers in the system with the optimal static weight vector wO that minimizes its number of mistakes,  PO(DN ) ? min wO   N  N? n=1  I{sgn ( wO ? s(n)  ) ?= y(n)}  We remark that the computation and adoption of wO  would require to know in advance, at the beginning of the first time slot, the sequences of local predictions s(n) and labels y(n), for every time slot n = 1, . . . , N .

Moreover, we denote by P (DN ) the misclassification probability of a learner if all the learners adopt the proposed scheme,  P (DN ) ?  N  N? n=1  I{sgn ( w(n) ? s(n)  ) ?= y(n)}  where w(1)i,k = 0 and w (n) i,k evolves according to (2), for each  learner i = 1, . . . , L and classifier k = 1, . . .Ki.

Theorem 1 determines an upper bound for P (DN ) in  terms of the unknown benchmark PO(DN ).

Theorem 1 For every sequence of labeled instances DN , the misclassification probability P (DN ) is upper bounded by  B(DN )? (1+ ? K)PO(DN )+2  ? (K +  ? K)PO(DN )  N + K  N     Importantly, notice that the bound B(DN ) is valid for any time horizon N and for any sequence of labeled instances DN . As a particular case, if the time horizon tends to infinity and PO(DN ) tends to 0, the misclassification probability of our scheme tends to 0 as well.

Corollary 1 If limN?+? PO(DN ) = 0, then  lim N?+?  P (DN ) = 0  Corollary 1 can be useful if the concept is stable, but it is not useful if there is concept drift because the accuracies of the classifiers and, consequently, the optimal weight vec- tor wO can change consistently from one concept to another.

Now we generalize the result of Corollary 1 considering an assumption that is more realistic if there are concept drifts.

We denote by DNc a sequence of Nc instances and labels generated by the concept qc. We say that the concept qc is learnable if, ?DNc ,  lim Nc?+?  min wOc   Nc  Nc? n=1  I{sgn ( wOc ? s(n)  ) ?= y(n)} = 0  That is, the concept q(n)c is learnable if there exists a static weight vector wOc whose asymptotic misclassification proba- bility, over the instances and labels generated by that concept, tends to 0.

Theorem 2 If DN , for N ? +?, is generated by a finite number of learnable concepts and a finite number of concept drifts occurred, then  lim N?+?  P (DN )? 0  We remark that Corollary 1 requires the existence of a unique weight vector, wO, whose misclassification probabil- ity over the labeled instances generated by all concepts con- verges to 0; whereas Theorem 2 requires the existence of one weight vector for concept, wOc , whose misclassification prob- ability over the labeled instances generated by concept qc con- verges to 0.

4. SIMULATIONS  In this section we evaluate empirically the performance of our scheme and compare it with the ensemble learning techniques listed in Table 1. For each scheme we adopt the parameters used in the corresponding paper. We consider three data sets widely used by the literature dealing with concept drift, that refer to real-world problems: in R1 the task is to detect a network attack [10, 14, 18, 19]; in R2 the task is to detect if the price of the energy will increase or decrease [14, 20, 21]; and in R3 the task is to classify the forest cover type of a particular area [10, 20, 22, 19]. For a detailed description of  Table 1. The considered schemes and their percentages of misclassifications in the data sets R1-R3  Name and Reference PerformanceR1 R2 R3 Average Majority, [18] 3.07 41.8 29.5  Adaboost, [7] 5.25 41.1 57.5 Weighted Majority (WM), [11] 0.29 22.9 14.1  Blum?s variant of WM, [12] 1.64 37.3 22.6 TrackExp, [13] 0.52 23.1 14.8 Our scheme 0.23 14.4 4.1  the considered schemes and data sets, we refer the reader to the cited references.

For each data set we consider a set of 8 logistic regression classifiers [23]. The training and testing procedures are as follows. From the whole data set we select 8 training data sets, each of them consisting of Z sequential records. Z is equal to 5, 000 for the data sets R1 and R3, and 2, 000 for R2. Then we take other sequential records (20, 000 for R1 and R3, and 8, 000 for R2) to generate a set in which the local classifiers are tested, and the results are used to train Adaboost. Finally, we select other sequential records (20, 000 for R1 and R3, 21, 000 for R2) to generate the testing set which is used to run the simulations and test all the considered schemes.

Table 1 reports the final misclassification probability in percentages (i.e., multiplied by 100) obtained for each data set for the considered schemes. The schemes that update their models (WM, Blum?s variant of WM, TrackExp, and our scheme) outperform the static schemes (average major- ity and Adaboost); in fact, the latter do not adapt to changes in concept. Importantly, in all the considered data sets our scheme outperforms the other schemes and exhibits perfor- mance gains ranging from 20% (R1) to 70% (R3) with respect to WM, the second best scheme.

5. CONCLUSION  We proposed a distributed online ensemble learning scheme to classify data captured and pre-processed by multiple dis- tributed local learners. We designed an efficient information dissemination protocol to spread the required information in the network. We rigorously determined a bound for the worst- case misclassification probability of our scheme which de- pends on the misclassification probability of the best static ag- gregation rule. Importantly, this bound tends asymptotically to 0 if the misclassification probability of the best static ag- gregation rule tends to 0. Simulation results show that, when applied to well-known data sets experiencing concept drifts, our scheme exhibits performance gains ranging from 20% to 70% with respect to state-of-the-art solutions.

6. REFERENCES  [1] J. Kivinen, A. J. Smola, and R. C. Williamson, ?On- line learning with kernels,? IEEE Trans. Signal Process., vol. 52, no. 8, pp. 2165?2176, 2004.

[2] F. Rosenblatt, ?The perceptron: a perceiving and rec- ognizing automaton,? Tech. Rep., Cornell Aeronautical Laboratory, 1957.

[3] I. Zliobaite, ?Learning under concept drift: an overview,? Tech. Rep., Vilnius University, Faculty of Mathematics and Informatics, 2010.

[4] Z. Haipeng, S. R. Kulkarni, and H. V. Poor, ?Attribute- distributed learning: Models, limits, and algorithms,? IEEE Trans. Signal Process., vol. 59, no. 1, pp. 386? 398, 2011.

[5] T. Shinozaki, Y. Kubota, and S. Furui, ?Unsupervised acoustic model adaptation based on ensemble methods,? IEEE J. Sel. Topics Signal Process., vol. 4, no. 6, pp.

1007?1015, 2010.

[6] V. H. Nascimento and A. H. Sayed, ?On the learning mechanism of adaptive filters,? IEEE Trans. Signal Pro- cess., vol. 48, no. 6, pp. 1609?1625, 2000.

[7] Y. Freund and R. E. Schapire, ?Experiments with a new boosting algorithm,? in Proc. ICML, 1996, pp. 148?156.

[8] W. Fan, S. J. Stolfo, and J. Zhang, ?The application of AdaBoost for distributed, scalable and on-line learning,? in Proc. ACM SIGKDD, 1999, pp. 362?366.

[9] H. Wang, W. Fan, P. S. Yu, and J. Han, ?Mining concept- drifting data streams using ensemble classifiers,? in Proc. ACM SIGKDD, 2003, pp. 226?235.

[10] M. M. Masud, J. Gao, L. Khan, J. Han, and B. Thurais- ingham, ?Integrating novel class detection with clas- sification for concept-drifting data streams,? in Proc.

ECML PKDD, 2009, pp. 79?94.

[11] N. Littlestone and M. K. Warmuth, ?The weighted ma- jority algorithm,? Inf. Comput., vol. 108, no. 2, pp. 212? 261, Feb. 1994.

[12] A. Blum, ?Empirical support for winnow and weighted- majority algorithms: Results on a calendar scheduling domain,? Mach. Learn., vol. 26, no. 1, pp. 5?23, Jan.

1997.

[13] M. Herbster and M. K. Warmuth, ?Tracking the best expert,? Mach. Learn., vol. 32, no. 2, pp. 151?178, Aug.

1998.

[14] L. L. Minku and Y. Xin, ?DDD: A new ensemble ap- proach for dealing with concept drift,? IEEE Trans.

Knowl. Data Eng., vol. 24, no. 4, pp. 619?633, 2012.

[15] D. Shutin, S. R. Kulkarni, and H. V. Poor, ?Incremental reformulated automatic relevance determination,? IEEE Trans. Signal Process., vol. 60, no. 9, pp. 4977?4981, 2012.

[16] M. Bui, F. Butelle, and C. Lavault, ?A distributed al- gorithm for constructing a minimum diameter spanning tree,? J. Parallel Distrib. Comput., vol. 64, no. 5, pp.

571?577, May 2004.

[17] G. Szekeres, ?Distribution of labelled trees by diame- ter,? Lecture Notes in Math., vol. 1036, pp. 392?397, 1983.

[18] J. Gao, W. Fan, and J. Han, ?On appropriate assump- tions to mine data streams: Analysis and practice,? in Proc. IEEE ICDM, 2007, pp. 143?152.

[19] K. Bache and M. Lichman, ?UCI machine learning repository,? Tech. Rep., University of California, Irvine, School of Information and Computer Sciences, 2013.

[20] A. Bifet, G. Holmes, B. Pfahringer, and E. Frank, ?Fast perceptron decision tree learning from evolving data streams,? in Proc. PAKDD, 2010, pp. 299?310.

[21] M. Harries, ?SPLICE?2 comparative evaluation: Elec- tricity pricing,? Tech. Rep., University of New South Wales, School of Computer Science and Engineering, 1999.

[22] N. C. Oza and S. Russell, ?Experimental comparisons of online and batch versions of bagging and boosting,? in Proc. ACM SIGKDD, 2001, pp. 359?364.

[23] D. S. Rosario, ?Highly effective logistic regression model for signal (anomaly) detection,? in Proc. IEEE ICASSP, 2004, vol. 5, pp. 817?820.

