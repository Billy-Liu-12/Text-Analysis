<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedings

Abstract: The pmliferation of online information sowes has led to an increased nse of wrappers for extracting data fmm Web sources. A key problem with the existing wrappers is that the wrapped rnle learned fmm the examples is only adaptive for the specific website. Io this paper, we propose a novel approach, DBFinder, to discover interest data blocks fmm a set of Web pages. It is a key step in the data extraction. The p m c w  of DBFinder consists of two phases: semi-supenised wrapping and unsupervised wrapper. The goal of the first phase is to learn the wrapped rules for the specific website.

The goal of the second phase is to popularize the wrapped rules for other websites in the same domain with the sample website. WO kinds of data mining techniques, frequent sub-tree mining and association rule mining, are used to accomplish such a goal. To demonstrate the feasibility of our appmach, some detailed experiments are conducted. We have also applied our approach In a real application, which is a comparisonshopping agent.

Keywords: association rule mining; comparisonahopping * 1. Introductiou Data extraction; wrapper; fquent  sub-tree mining; There is a tremendous amounts of information available on the Web, but much of this information is not in a form that can be easily used by other applications. The reason is that Web data sources are intended to be browsed by humans, and are not computed by applications. As a consequence, extracting data from Web pages and making it available to computer applications remains a complex and relevant task.

Data extraction from HTh4L is usually performed by software modules called wrappers. In most cases, examples are used to ?lea?? how the data of interest is presented in the sample pages. An essential step is using the textual surroundings of the data to generate a wrapper. A key problem with the existing wrappers is that the wrapped rule learned from the examples is only adaptive for the specific website. Can the knowledge be also adaptive for any new website in the same domain with the example website? This is the goal we attempt to accomplish.

In this paper, we develop a novel approach called DBFmder to discover interest data blocks from a set of Web pages. The discovery of interest data blocks is a key step in the data extraction. DBFinder takes advantage of two kinds of data mining techniques, frequent sub-tree mining and association rule mining. Because most target pages in a website are generated by a template, the frequent sub-tree mining algorithm can be used to discover such a template from the parsing trees of the pages. For example, the pages about different products in an e-business website usually have the similar format (template). Association rule mining algorithm is used to learn the knowledge from the sample pages. Then, DBFinder applies the knowledge to identify the similar content in the target website.

The key contributions of our work are as follows:  + A novel approach called DBFinder is presented to discover interest data blocks from a set of Web pages.

DBFmder adopts the divide-and-conquer algorithm to learn the wrapping rules.

+ we apply the frequent sub-tree mining algorithm %? discover !he template of pages in a website. We call it    discover !he template of pages in a website. We call it website-level mining. As far we know, it is the fmt time that frequent sub-tree mining is introduced into the domain of data extraction.

We apply the association rule mining algorithm to discover the frequent itemsets from the pages co l lecy from the sample websites. Then the knowledge can be used to guide DBFinder to discover the similar content from the target website. We called it domain-level mining.

+ The associufion model of panem free (AMPT) is proposed to calculate the association value between the pattern free (F?T) and the association repository (AR).

2. Related Work Alberto Laender (11 presents a taxonomy for grouping 0-7803-8403-2/04/$20.00 WW4 IEEE the various Web data extraction tools. The taxonomy is based on the main technique used by each tool to generate a wrapper, what let us to the following groups of tools: 1) Wrapper induction tools. Tools such as STALKER [2], W E N  [3] are representative of this approach. 2) HTML-aware Tools. Some representative tools based on such an approach are RoadRunner [41, XWRAF? [51. 3) h g u a g e s  for Wrapper Development. Web-SQL 161 is a declarative query language that is capable of locating selected pieces of data in HTML pages. 4) NLP-based I Tools. Representative tools based on such an approach are WHISK [7]. 5) Modeling-based Tools. Tool such as DEByE [SI is representative of this approach. 6) Ontology-based Tools[9].

P. B. Golgher [lo] inmduces how to use a pre-existing data repository to automatically generate examples and allow full automated example based data extraction. They propose an altemative strategy that uses a source repository ,fo identify similar data in the target sites and automatically assemble examples for extracting data from that site. Their approach provides buman-independent bootstrapping for example-based data extraction on the Web. However, the source repository needs to be generated in advance from a legacy database or by using a previously existing wrapper.

Moreover, it is a basic requirement in their strategy that the intersection between the data available in the source repository and the data available in the target sites be non-empty.

3. A d a t i o n  Model of Pattem Tree 3.1 Problem Statement Tbmugh the observation of a large amount of e-shops, we conclude the following empirical facts: 1) For a specific product, the discrepancy of its price is insignificant over different websites. 2) The pages about different products are usually generated by a template in a website. We say that these pages are similnr, meaning that either the structure or content of the pages are similar. Moreover, there are many websites using &lt;TABLE&gt; to layout their pages. The information of a product is included in one or more dABLE&gt;. 3) Some key HTML tags, such as cTABLE&gt;, &lt;TR&gt;, 4D&gt;, form a tag hierarchy. Thus, the data block can be. converted into a parsing tree. 4) For some features, such as ?price?, we fmd it remains the same over different parsing trees. Such a feature is regarded as field  feature. Otherwise it is regarded as value feature. 5 )  In a specific domain, the interest data blocks collected from different sites often share a large number of common feathers.

26-29 August 2004 Based on the above observation, we define the following data structures.

[Definition: Interest Ceu] Interest cell, denoted bx node(f,v) , refers to the object to be. wrapped. Thereint0.f    node(f,v) , refers to the object to be. wrapped. Thereint0.f refers to wrapped field and v refers to the corresponding value.For example, (price, $4280) is an interest cell.

Here, we mainly extract the fields such as name, image, price, and performance. We use a pre-existing dictionary to identify the name of the product. According to HTML tag &lt;img src=?*?&gt;, the image can be identified. A pattem matching method is applied to identify the price. At last, the textual information in the data block is regarded as the performance of the product.

petinition: Dah Block] Data blocz refers to the minimum &lt;TABLE&gt; that comprises all the interest cells. Figure 1 is a typical example for data block..

We denote a data block as a tree T=(V, E). T is the set of nodes, and E the set of branches. There are two kinds of nodes: tag nodes and text node. Here we only concern the key tag, such as &lt;TABLE&gt;, &lt;Tb, a&gt;, and so on. The size of T, denoted ITI, is the number of nodes in T. Branch e = ( v , , v y ) c  E meansthatnode~~isachildofv.

We say that a tree S=(V,, E,) is a subtree of T=W, E), denoted as S + T  , provided 1) V, C V  , 2) e=(vx ,Vy)E  E ,  if and only if node vy is the child of node v.. A subtree of size k is also called a k-subtree.

Figure 1. an example for data block [Definition: Associalion Repository] Association repository refers to the set of frequent itemsets discovered from the data blocks. Association repository is denoted as L = [ l ,  I 1, is a frequent itemset, 1 5 i 5 n J .

There is a large amount of semantic information bidden in the data blocks paring from the pages. Applying a stemming algorithm and removing stop words in the stop-list, keywords can be extracted from the data blocks.

Then, the texts in the data block are fed to an association rule mining algorithm that takes the word as item and the data block as transaction, generates a set of frequent itemsets (AR).

[Definition: Paftem Dee] Pattem tree refers to the template used to generate the pages in a website.

Most interest data block, which is wrapped from a website, are generated by a template. In reverse, it is 26-29 August 2004 possible to discover the template from' a large number of data blocks by using some data mining techniques.

We denote pattern tree as a tree S .  let tree T be a data block. if tree S occurs on T, denoted as S +T, we say that T is coverrd by S .

3.2 Interest Measure A frequent sub-tree mining algorithm is applied to discover the template from the data .blocks. The mining process would generate some candidate pattern tree. In order to evaluate the candidate pattem tree, we define two interest measures: support degee and association probability..

+ SupportDegree  Let 6 T(S)=1 if S + T ,  and &amp;(S) = O  otherwise.

The support of, a sub-tree S in the forest (the set of data blocks) is defined as ~ u p p o r r ( S ) = ~ ~ , S , ( S ) .  Let p be a user-specified minimum support value. A sub-tree is frequent if the condition sup porr(S) 2 p is satisfied.

The support of candidate pattern indicates its occurrence frequency in the data blocks.

A d a t i o n  Probability We use another form, an n-dimensional vector X,  to represent the association repository L. The dimension of vector X is the number of frequent itemsets in L. Each entry xi refers to the weight of frequent itemset li . The vector X is denoted as X = (x ,  , x2 ,..x,) . Thereinto, m x ( a j  . ~ ~ P P O W J ~ I I  x)) m    m x j  = W ( l j  I X) = sup pon(l, I X) . J=l  (1) where W(l i  I X) refers the weight of frequent itemset li in the association repository, and sup port(1, I X) refers-to the support value of frequent itemset l i  io the association repository. support(l,[j] I X) refers to the. support value of frequent item l i [ j ]  in the association reposit&amp;. The parameter m refers to the number of frequent items in the itemset f i  . The' parameter a is a position factor, whose value is decided by the occurrence of l i [  j ]  in the frequent sub-tree.

The explicit meaning of equation (1) is as follows: i) In the association repository, the weight of frequent itemset I i  is linear to the support of l i ;  ii) the frequent item occurred in the frequent sub-tree would promote the weight Let Q(S) refers to all the data blocks covered by S .

of l i .

An association rule mining technique is applied to Q(S), and generates a set of frequent subset, denoted by L'.

Correspondingly, L' can be expressed with a n-dimensional vector E Y = { y , ,  yz ,  '. . , yn ] .Thereinto, m E@, ~suppon( l , [ j l~~) ) y ,  =W( l ,  IY)=support(l, IY)"=' (2) m Then, suppose the angle between vector X and Y is 0 , the association probability between X and Y, denoted by p r ( X , Y ) ,  is calculated as follows.

The candidate patkm tree with the greatest p r ( X , Y ) value is'regarded as the pattern tree for the website.

4. DBFinder: A Stepwise Learning AppFoaeh Given some user-labeled examples, the goal of DBFinder is to conclude the wrap rules of the specified website and then popularize it to other websites in the same domain. The problem of DBFinder generation can be represented as follows: Given a Web pages P containing a set of implicit objects, determine a mapping1 W that populates a data repository R with the objects in P. The rest consists of two phases: Semi-Supervised Wrapping (SSW): Given any other pages P' similar to P (pages P' and P are taken from the same website S ) ,  the mapping W must also be capable of recognizing and extracting data from paeg P' .

Given any other pages P' similar to P (pages P are taken from a website S ' ,  distinct frbm S ,  hut whose objects belong to the same domain of those present in P), the mapping W must also be capable of recognizing and extracting data from paeg P' .

We use the term similar in a very empirical sense, meaning that both the structure and the content of the pages are similar.

Thus, the process of DBFinder contains two steps: SSW and USW. In the fmt  step, DBFinder receives as input a set of example pages. Using a GUI, the user hierarchically decomposes the document, outlining its interest regions and describing their semantics. From the examples, DBFinder generates panerns m e  (PT) .-that indicate the structure and the textual surroundings of the objects to be extqcted. These PT are then applied to guide * U n s u p e ~  wrapping (USW): 26.29 August 2004 the DBFinder to extract the interested objects from a target pages. Then, the texts in the data block are fed. to an association rule mining algorithm that takes the word as item and the data block as transaction, generates a set of all frequent itemsets (association repository, AR). ~n the second step, the frequent sub-tree mining (PFTM) plays important role in DBFmder. First, PFTM receives as input, a set of pages collected from the target website, distinct k m the example websites. Second, we applied our proposed    the example websites. Second, we applied our proposed association mode of panem trek, (AMPT) to calculate the association probability of the sub-trees ?discovered by PFTM and generate the pattern tree for the target site.

Moreover, to accurately and reliably extract price data is one of the key problems that must be solved by a scalable comparison-shopping tool. For example, suppose there are several numbers in a data block, how to select the proper number as the price? Here we use a verification matrix C to do this job. The verification matrix is defmed as follows: The enhy ci.j refers to the price of the #j product in ##i website. The row vector denotes the price of different products in the same website. The column vector denotes the price of the same product in different website.

Suppose that the distribution of price fluctuation should obey Gauss distribution: Then the verification matrix C is applied to pick the proper price from the noisy data block.

4.1 Semi-supervised Wrapping (SSW) Algorithm: SemiSupervisedWrap Input: n (n&lt;lO) training sample websites, m (m4) training sample pages in each sample website.

Output: a) data repository R b) n panem frees: c) L association repository; d) C :  verification matrix The semi-supervised wrapping process is detailed as follows.

1) DBFinder converts the sample page into a parsing tree, a representation that reflects its HTML tag hierarchy. The parsing tree is displayed in a tree control. Using a GUI, the user hierarchically decomposes the document, outlining the boundary of interest data block and describing their semantics.

2) By comparing the HTML structure of m data blocks, DBFinder generates a pattem tree that handle structural mismatched found among the m data blocks. The panem tree indicates the structure and the textual sumundings of the objects to be extracted.

3) The extraction patterns free is applied to guide DBFinder to wrap data from other pages collected from the same website.

4) After finishing learning from the n training sample websites, DBFinder obtains a set of data block. There is a large number of textual information hidden in the data blocks. We apply a Chinese word segmentation tool to segment the texts into words. Taking the words as items and  the data blocks as transactions, an association rule mining algorithm (such as Apriori or FP-tree algorithm) generates a set of all frequent itemsets (association repository) 5) DBFinder generates the verification matrix C by using the above wrapped data.

4.2 Un-Supervised Wrapping (USW) First, we introduce frequent sub-tree mining in brief.

Frequent subt-ree mining, which discovers frequent sub-trees as pattems in a forest, is in important data mining problem with broad applications, including web structure mining, extracting pattems from XMUHTML documents, and so on. Because the interest data block in one website are generated by a template, one would like to discover the template (frequent sub-tree) by u&amp;g a frequent sub-tree mining algorithm. Please refer to.[ll] for details.

The unsupervised wrapping algorithm is detailed as follows.

Algorithm: UnSupervisedWrap Input: i) S? : target website; ii) L association panems repository: iii) C :  verification matrix Output i) data repository R ii) patterns trees for S? : iii) updated verification matrix.

1 )  Data preprocess and data cleaning. A (lata cleaning process is applied to the pages collected from the target website, such as using the verification matrix to verify the price in the candidate data block. Then we obtain a subset    price in the candidate data block. Then we obtain a subset of pages containing the interest data block.

2) Frequent sub-tree mining. The subset of pages is parsing into document trees. The PFTM algorithm takes as input the document trees and generates a complete set of frequent sub-trees sorted by its support value. Then, the n former sub-trees with high support value, denoted by Y = { Y , , Y , , . . . Y , J ,  are selected from the set of frequent sub,trees.

3) For each frequent sub-tree 5 (Ui E Y) , we use 26-29 August 2004 equation (3) to calculate the association probability of Yi , me frequent sub-tree y, with the maximum association rate* denoted by Pr(Y,)=argmaxcwx.y,)). is regarded as outperforms the unsupervised wrapper by an average of ahout 10 percents. The results show that all sites, except for 139shop, have a preferable precision rates (at least 0.74) and recall rates (at least 0.62). It demonstrates the iilj..l thepuffem frees for the target website S? .

4) The puttem tree is applied to guide DBFinder to wrap data from the pages collected from the target website.

5 )  Update the verification matrix C.

5. Experiment Analysis To demonstrate the feasibility of our approach, we have conducted three kinds of experiments. The first is to calculate the precision and recall of DBFinder. The second is to automatically identify the field-value from the data blocks by using DBFinder. The third is to apply DBFinder to a comparison-shopping system called Ego.

5.1 PrefiSionlRecall of DBFinder We apply two measures widely used in evaluating the performance of IR systems, precision and recall rate, to the following experiments and verify the quality of our proposed methods. We write a band-coding wrapper in advance. Regards the records extracted by hand-ceng wrapper as total records, measure of precision and recall are defined in equation (5) and (6).

(5) (6) To test the precision-recall of DBFmder, we use the data we have collected from some Chinese popular websites in the domain of mobile phone. The data?is divided into two groups. Each goup contains the data collecfed from 10 mobile phone websites. The fxst is fed to the semi-supervised wrapper. The second is fed to the unsupervised Wrapper.

Table 1 shows the precision-recalls for semi-supervised wrapper. From table I ,  we can see. that the highest recall (showji) is 0.92 and the lowest recall (cnool) is 0.63. We check the pages collected from showji and fmd that each data block includes three a B L E &gt;  and the format tends to be unique. However, the data block in cnool consists of some noisy tables and the position of price is far from that of the product. These two factors depress the rate of precision and recall.

Table 2 shows the precision-recalls for unsupervised w r a p r .  The average precision is 0.83 and the average ?recall is 0.71. We can see that the semi-supervised wrapper #of correctlyxtracted records #of extractedrecords #of correctlyxtractedrecords #of total records P =  Precision= R=Recull= feasibility of our proposed approach. The precisiodrecall of 139shop. 0.63/0.52 is not perfect. By tracing the pages collected from 139shop, we found that the data block consists of too many noisy anchors and images, such as    ?anchors of related news?. Moreover, the position of specification is far from that of the product. The noisy features included in the irrelated anchors degrade the precision/recall rate.

Table 1: the Recision-Recall for Semi-supervised Wrapper I Site I ~ o t a l  I extra- I cone~tlv I P I R ,I Table 2 the Recision-Recall for Unsupervised Wrapper I site I 5.2 Automatic Identify (field, value) 26-29 August 2004 Figure 2 shows an example for pattern tree, which is discovered from www.showii.com. This pattem tree covers 562 pages in the website. From figure 2, we can see that there are three &lt;TABLE&gt; in the pattern tree. Three red flag make our method be applicable to general Web pages instead of restricting to tabular pages, we will apply generalization and specialization processes to merge 01 split content blocks based on HTML. document object model.

"*" represent the values corresponding.to the fields: image, product, and price.

We regard the text node, such as performance, product, and price, as field. The feature field remains the same over all the interest pages in a website. -According to this character, we can automatically identify the field and its value.

5.3 Application in the comparison-shopping agent We have applied DBFiner technology into a real application, Ego (http://202.38.215.1:8080/esearch), which is a comparison-shopping agent. Ego visits over one hundred of hand mobile sites, extract product information and summarize the results for the user. Figure 3 shows the CUI of Ego. The user can input a keyword, such nokia  8250, in the edit box. The detailed information, such product, image, price, and performance, are displayed in 6. Conclusions In this paper, we present a novel approach, DBFmder, to discover interest data blocks from a set of Web pages.

The process of DBFinder consists of two phases: semi-supervised wrapping (SSW) and unsupervised wrapper (USW). In the fmt phase, SSW features a CUI that allows the user to label the sample pages. In the second phase, USW automatically discovers the interest data blocks by using the knowledge learned from the sample pages and from the test pages. No training data will be given to USW. According to the previous experiments, we can conclude that our proposed methods are feasible to discover interest contents from web pages.

