ANGELS for Distributed Analytics in IoT

Abstract?The current global emphasis on ?Internet of Things (IoT)? have highlighted the extreme importance of sensor-based intelligent and ubiquitous systems which are more commonly known as ?cyber-physical systems.? The technology has the potential to create a network of smart devices and things to an extent that has never been envisaged before, far outnumbering the number of devices connected in the Internet as we know today.

The sheer number of such connected ubiquitous devices is likely to give rise to a hitherto unforeseen volume of data of different types with a demand for execution of analytical algorithms over the data. On the success of these analytic processes will depend the actual ?smartness? of the ?Intelligent Infrastructures? which now form the crux of the IoT paradigm. We have seen the advent of cloud-based paradigms to analyse the data in a data-parallel fashion within large data centres which now form the basis of the ?big-data? problem. But apart from the servers in the data centres, we potentially have a huge pool of compute resources if we think about the smart devices in and around our homes collectively, which remain relatively idle. In this paper, we present a proposal with some emulated experimental results where we claim that in an IoT framework, the smart devices such as mobile phones, home gateways etc. can be utilised for execution of data- parallel analytic jobs. This is effectively a work-in-progress and it is acknowledged that there will be further challenges for real devices. Future research will attempt to consider these challenges.

Keywords?cyber-physical; ubiquitous systems; analytics; par- allel execution; black-box; mobile grid

I. INTRODUCTION The inevitability of the ?Internet of Things? (IoT) was  underpinned by Neil Gross back in 1999 when he wrote the famous article [1] in Business Week where he said - ?In the next century, planet earth will don an electronic skin. It will use the Internet as a scaffold to support and transmit its sensations.

This skin is already being stitched together.? He was writing about a futuristic scenario which now-a-days seems more of a reality. Cyber-physical systems are not figments of imagination any more and worldwide numerous researchers are dedicating their efforts to the development of this networked infrastructure of smart objects, ranging from furnitures, appliances within a home or office, cars or buses and other means of transport, healthcare devices, etc. As a result, new complicated appli- cations and services encompassing several domains such as e- Governance, energy & utilities, waste management, healthcare, transport systems and many more will come into effect within the next few years. Many significant initiatives have been taken in different countries regarding the development of such services [2]. The vision includes mobile devices, such as phones and sensors to be an integral part of this system as these devices will act as the primary sources of data. The services mentioned before will require precise analysis of the data collected through the ubiquitous mobile devices in order to be effective for the IoT paradigm. It is obvious that the  volume of data will be astronomical which will require huge computing infrastructures for analysis.

The data which will be accrued through the smart devices serving a variety of applications in several domains are inher- ently heterogeneous and this mandates an extremely important role for the middleware fabric in the IoT frameworks. The IoT framework can also be viewed as a large computational grid involving devices and computational resources which follows a cycle of ?sense ? extract ? analyse ? respond?, where data are sensed at the devices, extracted and analysed at the middleware and application level triggering back a response to the devices. The analysis primarily happens on computing resources spread across the globe in large data centres. However, there is a scope of utilising the smart devices that are already part of the IoT framework. An enormous amount of computing power is spread across millions of such devices which include home gateways, routers, and most of all - smart phones and mobile devices. These devices, collectively known as edge devices often remain idle and it has been proposed in a very recent research proposal [3] that it may be possible to execute certain sections of the IoT cycle on such devices, thereby extending the computation to the edges of a compute cloud.

In this paper, which is a work in progress, we explore the idea of utilising smart edge devices for performing certain portions of the data analysis tasks in IoT. We present the architecture of an IoT framework which will include servers and commodity compute nodes along with smart devices as computational resources. We call these devices ANGELS or Available Network Gateways in Edge Locations for Sensors and attempt to show that these devices, if integrated properly, can appear as angels for distributed analytic processing in IoT frameworks. We articulate on the various aspects of using these devices as compute nodes, such as data-parallel computation and capacity-based partitioning of data where data will be partitioned based on the capacity of the available devices.

The rest of the paper is organised as follows: in Section II, the background and related works are discussed and the main motivations behind this work and potential challenges are discussed in Section III. Section IV discusses the proposed architecture and different aspects of using the edge devices for computation. We present some experimental results to understand the framework?s behaviour when running in low bandwidth networks in Section V and discuss them. A conclu- sion and future work is presented in Section VI.



II. BACKGROUND AND RELATED WORK The work presented in this paper is related to several  IoT frameworks which try to leverage the computing power spread across numerous mobile devices in order to address the problem of analysing massive data volumes.

A resource provisioning framework for a mobile Grid  2014 IEEE World Forum on Internet of Things (WF-IoT)     architecture has been implemented in [4] by utilising the com- putational capabilities of nearby devices. The mobile devices in this work are treated as service providers and the framework addresses energy-aware resource management and uncertainty handling for ensuring application QoS in highly dynamic and unpredictable environments. The authors also refer to data and task parallelism exploitation, job check pointing to estimate the remaining time to complete a job. Moreover, the framework harnesses the power of heterogeneous mobile Grids and presents a real implementation of a use-case in the healthcare domain.

Another notable effort in the area of computation on mobile devices is Serendipity [5] where jobs are distributed amongst nearby mobile devices with the aim to reduce the job completion time and/or conserving the device energy.

According to this proposal, a mobile device may execute a task locally or may request the service of a nearby device based on the exchange of some meta-information. The authors envisage three possible characteristics of the mobile network, namely (i) a predictable network with a control channel for co-ordination, (ii) a predictable network without any control channel and (iii) an unpredictable network.

More recently, the researchers at Berkeley have added the capability of adding android devices to the computing pool via BOINC [6] in order to harness the ubiquitous mobile devices for large-scale computation. This has enabled users of smart phones to donate their idle computing power voluntarily to various intense projects which require idle cpu cycles.

Researchers have earlier worked towards an efficient scheduling policy and pricing strategy for these edge devices which are constrained in nature in terms of cpu, memory and bandwidth. Notable among these are [7], [8] and [9] which talk about game-theory based incentive offers for the owners of the devices.

However, none of the frameworks we have studied and discussed consider the capacity of the devices before distribut- ing the tasks and the related dataset. The Fog Computing paradigm [3] we have mentioned before will largely depend on the efficient execution of tasks on edge devices and the edge devices referred in this proposal are mostly low-capacity systems with limited cpu, memory and network bandwidth.

Further, the edge devices are of unpredictable nature because of their mobility. It is our belief that the resource pool will comprise numerous such edge devices along with fully powered server-class systems and in such a scenario, we believe, that data must be partitioned based on the capacity of the devices in a proportional manner so that the weakest node will also be able to contribute to the computing pool. In this proposal, we have presented a novel partitioning scheme while using HTCondor [10] as the middleware fabric over a cluster of heterogeneous nodes including edge devices. The HTCondor framework has been in use for a long time and is well-known within the Grid community for high-throughput jobs. Recently, there has been some work towards adapting it for high-frequency computing [11] which makes HTCondor more suited to the IoT domain. This, along with the match- making capability of Condor makes it an attractive framework for adoption in IoT analytics. Further, the recent stress on data- parallelism has resulted in the inclusion of Hadoop Distributed File System(HDFS) [12] support inside Condor so that familiar big-data techniques can now be incorporated. Our experimental results show that such an architecture can indeed be useful for  data analysis in the context of Internet of Things.



III. MOTIVATIONS AND CHALLENGES Two factors act as main motivations behind this work and  in this section we discuss these factors and the challenges therewith.

Firstly, according to a report released by the International Data Corporation (IDC) [13], the mobile phone market across the world grew by 6% during the second quarter of 2013 and a total of 432.1 million mobile phones were shipped worldwide, out of which 237.9 million were smart phones. Globally, the number of smartphones has already surpassed 1 billion and is expected to double by 2015 [14]. Apart from the smartphones, the smart city initiatives predict extensive use of other mobile devices such as home energy gateways, smart meters and other smart and mobile devices, each equipped with one or more processors and memory units. Thus there is already an abundance of computing power spread across the world which is going to increase in a dramatic fashion, and this explosion is not so distant in the future.

Secondly, the energy cost for running the data-centres has been ever-increasing, the state of which has been outlined in [15]. According to Gartner, the energy cost has increased from 10% of the IT budget for an organisation in 2006 to 50% in 2011. Further, the energy rate for powering a data-centre is based on the industrial rate which is much higher than the consumer rate at which the edge devices owned by consumers will operate. One of the advantages in the vision of using consumer smart devices for computing is that the energy cost will be significantly less.

However, there are significant challenges which are to be overcome and we try to highlight them in the following paragraphs.

(a) Edge devices such as the smart phones have mobility as  one of their major characteristic which make them volatile as compute resources.

(b) Using the Internet as the media for distributing data to the edge devices will cost the edge device owner in terms of network data usage and also affect the battery of the device. The challenges in this respect are - (i) how to reduce the cost of communication and (ii) how to preserve the battery power.

(c) The edge device should only be used during its idle period without affecting the user experience and hence the challenge is to sense idle time in real-time and allocate job and distribute data optimally.

(d) The edge devices are constrained in terms of cpu and memory and are heterogeneous in terms of hardware and software flavours which implies that - (i) the job scheduling system should be able to consider the device capability and (ii) a common middleware framework is required for job distribution and execution.

We are attempting to address the challenges individually  and as a start we are creating the framework necessary for execution of jobs/task on edge devices depending on an allocation and scheduling policy which takes into consideration the capability of the nodes.



IV. EDGE DEVICES AS ANGELS FOR IOT Any IoT framework which hosts a cyber-physical system  is expected to cater to diverse analytical application charac- teristics such as periodicity, data volume, real-time or near- real-time constraints. In order to support such computational  2014 IEEE World Forum on Internet of Things (WF-IoT)     demands, parallel and distributed processing in form of cloud computing frameworks is deemed as essential. In this section, we describe the architecture of our proposed framework which is capable of parallel execution of analytical jobs over a set of heterogeneous nodes which may include edge devices.

This framework includes a partitioner entity which takes into account the computational capabilities of the nodes that are part of the resource pool and uses this information to partition the dataset into smaller subsets based on the node capabilities.

Our goal is to show that this approach allows even the weakest nodes to participate in a given analysis task which forms the basis of the fog computing paradigm proposed in [3].

In this paper, we consider a class of applications which can be executed in a data-parallel fashion, that is, applications for which the input data set can be split into several subsets and multiple instances of the same application can be executed in parallel with different subset as the input. Thus, the entire dataset is processed by several smaller worker processes on dif- ferent compute nodes. The philosophy is similar to the concept of map-reduce proposed by Dean and Ghemawat in [16] which is adopted in the open-source Hadoop framework [17] except that the conventional map-reduce frameworks remain agnostic about the capabilities of the compute nodes, and further, any application must be re-written to conform to the map-reduce paradigm.

In our work, we assume the existence of a combiner application which can collect the outputs produced by the multiple analysis processes and combine them into the final output. This can be compared to the reduce phase of a map- reduce paradigm where the user is expected to provide a script or program to collate the final unified output. This allows us to execute existing analytical algorithms as black boxes without having to rewrite the code to fit into an execution paradigm.

Figure 1 depicts the architecture of our proposed distributed computing framework which incorporates a data partitioner and a combiner. The data partitioner assumes the job to be data parallel and schedules it on all available nodes. The execution time of the application on a given node is assumed to be dependent on the input data size it must process. The partitioner module divides the dataset into smaller subsets and distributes them to the worker nodes along with the application to be executed.

Fig. 1: Introducing Data Parallelism  In the fog computing paradigm, the compute resource pool will be composed of heterogeneous resources such as sensor gateways, personal laptops, play-stations, smart-phones etc.

One of the major challenges with respect to the complete realisation of a compute platform on top of such devices  is the management of intermittent unavailability of the edge devices which are volatile in nature. The unavailability can be a result of a device failure or a link failure, or both. For reasons of simplicity, we have temporarily assumed that the edge devices and links are available throughout the duration of the experiments. We shall consider node and link unavailability at a later stage during the course of this research work. In this paper, we try to establish that for data parallel applications in the context of IoT, the effective utilisation of the devices will depend on appropriate partitioning of the entire dataset and their distribution to the compute nodes based on the capacity of the nodes.

To fulfil this objective, we designed a partitioner module which is capable of partitioning the input data set based on the capability of the available nodes in terms of their cpu, memory and communication bandwidth. The goal of this partitioning is to minimize the make-span of the job. The partitions are then distributed to the compute resources and scheduled for execution. Authors in [18] have proposed a data partitioning method based on computational capacity of participating nodes in a Hadoop environment. Capacity measurement itself being an involved research area in computing science, the authors have used a very simple metric for calculating capacity of a node. The metric is a linear function of CPU speed, network latency for movement of the data from a central position to the participating node, memory (cache and main memory) capacity of the node, and also the complexity of the algorithm involved.

The input data set is then partitioned according to the ratio of capacity values of the nodes, so that the node with highest capacity gets the highest load of computation. The authors have applied their method on a map-reduce application and showed that the resultant make-span for the job was better compared to the make-span in raw Hadoop settings. In this paper we use a data partitioner which is an adaptation of this basic data partitioning approach.

We have used the well-known HTCondor framework for submission and execution of jobs on available compute nodes.

But the architecture differs from the traditional Condor execu- tion system in that it has a data partitioner module which is capable of splitting the data file based on the capacity of the available nodes. The combiner module is fairly rudimentary and can execute basic combiner scripts such as file concate- nations submitted by the user. Based on the number of data files (or partitions), jobs are scheduled on number of nodes to be executed in parallel. Each job on a given node executes on its specific partition and produces some result which is finally combined using a combiner script provided by the job- submitter.

The detailed architecture of the proposed framework is shown in Fig. 2 where we have a cluster of server class systems connected through HTCondor and also a set of edge devices as part of the combined resource pool. Any job, submitted to the framework can be distributed over any number of resources selected from the pool, including edge devices. As of now, these devices are not able to use the pool as consumers by offloading part of their jobs to other nodes, but we consider this as one of the future enhancements.



V. EXPERIMENTAL RESULTS We conducted our experiments in a distributed infrastruc-  ture managed by HTCondor. We used an Intel Xeon series 4- CPU server (each with eight cores), 2.0GHz clock and 128GB  2014 IEEE World Forum on Internet of Things (WF-IoT)     Fig. 2: Detailed framework architecture  RAM on which a private cloud platform was set up using OpenStack [19]. The virtualized cloud contained 12 machine instances dedicated for the experiment, out of which four ma- chines were configured to be high-end with 4GB memory and a single-core virtual CPU with 2 GHz clock speed. The other eight machines were configured to emulate low-powered edge devices, each having 1GB RAM and single core with 1 GHz clock. We also used traces collected from real mobile handsets and replayed the traces on the low-powered nodes to properly emulate an edge device. The collection and playback of traces was based on the concept provided by Dinda and O?Hallaron in [20]. The original PlayLoad tool [21] was slightly enhanced to support playback of traces from edge devices and a snippet of such playback is shown in Fig. 3. Other than this trace playback, this HTCondor-based experimental set-up had no other application load.

Fig. 3: Playback of mobile workload trace  We conducted several experiments on this set-up using two different type of applications - one computing the standard deviation of a large set of numbers and the other performing a text search within a large document.

For the standard deviation test-case, we used a parallel implementation of the algorithm for a large set of numbers, the  count of which was varied from 100000 to 100000000. Each set of numbers was divided into sub-sets of two different sizes by the partitioner, the larger of which contained approximately twice the count of the smaller sub-set. We submitted the jobs to the HTCondor cluster such that the jobs with smaller input set were scheduled on the low-powered edge device emulation nodes and the jobs with the larger input set were scheduled on the high-powered nodes. We compared the make-span with the result obtained from the experiments without the partitioner involved, and the comparison is shown in Fig. 4(a)  For the text search experiments, we used an application which searched for the occurrence of a string within a set of large files which vary in size. We used two different sets of files, where each file in one set was approximately 500KB and each file in the second set was approximately 276KB. We varied the number of files to be used in the experiments and the files were chosen randomly from each set. As was done in the case of the previous test-case, we executed this set of experiments with and without the partitioner involved. When the partitioner was involved, as before, the low-powered nodes were scheduled with the jobs with smaller files as input and the high-powered nodes were scheduled with the jobs with larger files as input. The make-span was compared and the result is shown in Fig 4(b).

All the experiments were executed multiple times and the mean result is presented in Fig. 4.

(a) Make-span optimization for Standard Deviation computation  (b) Make-span optimization for Text Search  Fig. 4: Make-span minimization with partitioning  It can be concluded from both set of experiments that within an IoT framework, participating nodes can be better utilized thus affecting the job execution scenario in a positive manner if data can be partitioned based on the capacity of the nodes.

We have also performed a set of rudimentary experiments  2014 IEEE World Forum on Internet of Things (WF-IoT)     using a set of real edge devices (android smartphones) of varying capabilities and have been able to obtain a basic result which is shown in Fig. 5. The figure shows three different graphs, each corresponding to the average makes-span using different set-ups, namely a purely server-based set-up, a purely edge-device set-up and a heterogeneous mix of server and edge-devices. It can be seen that for obvious reasons, the make- span on the servers is the minimum, far out-performing the make-span on the edge-devices. But a moderate result can be obtained on the heterogeneous set-up with a combination of edge-devices and servers. We can argue, that this may form the basis of a scheduling cost model based on the preferences and restrictions from the users? point of view. A user, or a large organisation with sufficient budget may choose to opt for the best performance and may wish to execute all their jobs on the server cluster. On the other hand, another user with a moderate budget may choose to sacrifice the latency in favour of cost and select the resources in the edge-devices pool which are offered at a lesser charge.

Fig. 5: Mape-span comparison in different clusters

VI. CONCLUSION AND FUTURE WORK In this paper, we have proposed a novel framework of het-  erogeneous computing nodes which includes resources ranging from large server-class systems to low-powered edge-devices such as smartphones, home energy gateways etc forming the basis of the fog computing paradigm [3]. We argue that most of these edge devices remain idle for large part of a day and cumulatively can contribute to data-parallel computation in the context of IoT where the alternative massively parallel processing frameworks may pose certain restrictions. We also note that the role of the partitioner and scheduler are extremely important in such scenarios. As of now, we have used a static scheduler and we are working towards a dynamic scheduler which will be able to consider dynamic availability patterns.

We have also mentioned about a cost model for scheduling based on the user requirement for latency and budget consider- ations and have done some basic work in this area. The current framework for executing user jobs on real mobile devices is rudimentary in nature, but is able to prove the concept. We plan to extend this framework to support real user requirements.

We have used Condor for our experiments as the resource awareness features of Condor make it more attractive within an IoT context. When we mention the fog computing paradigm, we are talking about utilizing the abundant computing power of ubiquitous devices and gateways which reside on the edge of the network, not just data centres at the core. Previously, researchers have highlighted the use of gateway devices for various IoT scenarios such as home infotainment [22], low  cost remote healthcare [23] and home energy [24] - each of which speak about the requirement of harnessing this abundant and ubiquitous computing power. One of the most important aspects in this scenario is the is the ubiquity and volatility of the edge devices, the network of which is not a controlled one. The dynamic scheduler we are working on must be able to cater to the fact that the gateways and mobile devices can be switched off or disconnected from the network any time and failure is to be accepted as a norm and not an exception.

Consumption of battery power and network bandwidth usage are the primary concerns for most edge-device owners.

We think that using low-cost communication protocols such as the Constrained Application Protocol (CoAP) [25] may offer some advantages in terms of bandwidth usage as well as the battery consumption related to data transfer. Furthur, an incentive-based scheme offering benefits to users contributing their devices to the resource pool may also be attractive. There are hurdles in the course of this research, but we hope to overcome them in order to realise the full potential of the fog paradigm.

