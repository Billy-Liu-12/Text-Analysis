A study of mining certain itemsets from uncertain

Abstract?Association rule mining is an important data  analysis method for discovering associations within data.

Recently, some researchers have extended association rule  mining techniques to imprecise or uncertain data. However,  the question arises as to how we can mine relevant and  interesting patterns from uncertain data. Additionally, using  the ?-count, the summation of a large number of itemsets with  very small support may induce irrelevant associations. To this  end, this study proposes a new approach to discover relevant  patterns from uncertain data. This approach is based on the ?-  cut method allowing us to filter out the irrelevant patterns with  small support. Furthermore, a correlation measure, also  known as lift, is used to augment the support-confidence  framework for association rules. Next, we develop an  algorithm to discover relevant and interesting association rules  from uncertain data. Experimental results from the survey  data show that the proposed approach can help us to discover  interesting and valuable patterns with high correlation.

Keywords?uncertain data; data mining; fuzzy association rules;  fuzzy set.



I.  INTRODUCTION  The mining of association rules in transaction data-bases has been demonstrated to be useful and technically feasible in several application areas, such as for market basket analysis [6, 7, 8], image mining [12], recom-mender systems [25] and in the medical domain [27]. Agrawal et al. [1] first introduced the problem. They de-fined it as the finding of all rules from transaction data satisfying the minimum support and the minimum con-fidence constraints. In short, an association rule mining algorithm works in two steps: (1) generating all frequent itemsets that satisfy the minimum support; and (2) gen-erating all association rules that satisfy the minimum confidence from the already discovered frequent item-sets.

The fuzzy set theory has been widely used to discover association rules. Fuzzy sets facilitate the handling of numerical attributes by avoiding crisp and arbitrary transitions between classes. Fuzzy set theory [31] is primarily concerned with quantifying and reasoning using natural language, where words can have ambiguous meanings. Delgado et al. [14] considered fuzzy set theory to be an optimal tool for modeling the imprecise terms and relations commonly employed by humans in communication and understanding. This technique has been used for various  applications, such as finding fuzzy association rules from quantitative transactions (see Hong et al. [18, 19, 20]), and finding fuzzy association rules from both quantitative and categorical attributes by dividing them into various linguistic values (see Hu et al. [22, 23]). However, the above works were all focused on discovering patterns from certain data, rather than un-certain data. Dubois et al. [16] investigated techniques to identify and evaluate associations in a relational database that are expressed by fuzzy if-then rules.

Extensions of the classical confidence measure based on the ?-cut de-compositions of the fuzzy sets are proposed in order to address the problems associated with the normalization in scalar-valued generalizations of confidence. The analysis by ?-level differentiates between strongly and weakly supported associations and identifies robustness in an association.

Recently, some studies have extended the association rule mining techniques to imprecise or uncertain data [9, 10, 15, 28, 29]. Chen and Weng [9] proposed a new approach to discover association rules from imprecise or-dinal data.

Although this work is interesting, the expressive power of this model is limited, because it can not handle other types of uncertain data, such as categorical or numerical data.

Djouadi et al. [15] proposed a generalized possibilistic relational model and discovered association rules under conditions of imprecision and vagueness. However, in this study only numerical data are represented by possibility distributions, categorical and ordinal data are not involved.

Chui et al. [11] discovered frequent itemsets from uncertain data using a probabilistic framework which associates the various items of transactions with existential probabilities.

Un-fortunately, they only processed categorical data represented by existential probabilities without considering other data types, such as ordinal data.

The possibility theory is closely related to the fuzzy set theory [31]. Possibility theory is more suitable for the expression of human opinions, judgments and decisions which are characterized by uncertainty. Weng and Chen [30] proposed an approach for mining association rules from uncertain data. In their study, possibility theory is used to handle uncertain data. That is, an item in a transaction is represented by a possibility distribution. Furthermore, two measures are computed from these values, support and deviation measures. A pattern is considered good if its support is high but its deviation is low; low deviation means the pattern is more certain and believable. However, Djouadi  National Chung Hsing University, Taichung, Taiwan, Nov.16-18, 2012     et al. [15] suggested that when using the ?-count, the summation of a large number of itemsets with very small support may induce irrelevant associations. Therefore, the question that arises immediately is how we can discover certain, frequent and highly associated itemsets from uncertain data. To this end, we attempt to combine both these theories and then discover fuzzy association rules from uncertain data. Furthermore, we propose a new approach which applies ?-cut to eliminate the itemsets with very small support and then generate certain, frequent and highly associated itemsets from uncertain data.

The rest of this paper is organized as follows. The problem definitions are given in Section 2. The proposed algorithm and an example are illustrated in Section 3.  In Section 4 survey data from a case study are used to demonstrate the usefulness of the proposed algorithm.

Conclusions and future work are discussed in Section 5.



II. PROBLEM DEFINITION  In this section, we define the problem of discovering certain, frequent and highly associated itemsets from uncertain data. First, the effect of multiple elements with small membership values is discussed. Next, several items used in the proposed algorithm are introduced. Finally, we define the membership degree for each different item. The ?- cut method is then applied to first eliminate the itemsets with small support leaving only certain, frequent and highly associated itemsets. Finally, we generate fuzzy association rules from those highly associated itemsets.

First, we use an example provided by Martin-Bautista et al. [26] to illustrate the effect of multiple elements with small membership values. The table below gives the count of datasets for each type, their membership values in X and Y, and the results of that intersection. Measuring confidence  with the ?-count yields conf(X?Y) = (1000*0.01) / (1+999*0.01) = 0.91. Thus a high measure of confidence in the association is produced, even though only one record that significantly satisfies X is able to minimally satisfy Y. From the above example, we know that when using the ?-count, the summation of a large number of itemsets with very small support may induce irrelevant associations. Here we apply the ?-cut approach to address this problem.

TABLE I.  A DATA SET WITH SMALL MEMBERSHIP VALUES  count X(x) Y(y) min(X(x), Y(y))  1 1.00 0.01 0.01  1 0.01 1.00 0.01  998 0.01 0.01 0.01   The concept of the ?-cut for a fuzzy set means a subset  made of those elements whose membership is greater than or equal to ?. A fuzzy predicate expresses the degree to which the arguments satisfy the predicate. The concept of a fuzzy set extends the notion of a regular crisp set in order to express classes with ill-defined boundaries, corresponding in particular to linguistic values such as ?poor?, ?good?, and so on. Within this framework, there is a gradual rather than  sharp transition between non-membership and full- membership. In the following, we will introduce the fuzzy set, and then illustrate how to apply ?-cut to discover those itemsets with high association.

Definition 1. Suppose we have a universe of discourse X in  a quantitative domain, where each element x belongs to X.

Then, a fuzzy set F is characterized by a membership  function mF(x), which maps x to a membership degree in  interval [0, 1]. An ?-cut of a fuzzy set is an ordinary set of  elements with membership grade greater than or equal to a  threshold ?, 0 ? ? ? 1. Thus an ?-cut of a fuzzy set F is  characterized by F?={ x ?X; mF(x) ? ?}[24].

Definition 2. Let IT={it1, it2, ?, itm} be a set of all items. A  v-item is denoted as (iti,  ik  ik  i  i  i  i  x  p  x  p  x  p ??? ?     1 ), where iti  ?IT is the item name and  ik  ik  i  i  i  i  x  p  x  p  x  p ??? ?     1  is the  possibility distribution of iti. Here, each xik?X is a possible  value of iti and pik ?[0, 1] stands for the possibility of xik.

Related to using possibility theory to represent uncertain  data, please refer to our previous study [30].

Definition 3. For category ci and category cj, let sim CC  (ci, cj)  denote the similarity between category ci and category cj. In  this study, the CC similarity matrix SimCC stores the  similarities between all categories.

Assume that we have a category v-item ai = (iti,  ik  ik  i  i  i  i  x  p  x  p  x  p ??? ?     1 ) and a category r-item bj =(icj, fj). Let  simr(ai, bj) denote the similarity between xir, the rth-value of  ai, and bj, where 1 ? r ? k. Then, simr(ai, bj) is given as follows:  ? ? ? ??  ? otherwise,0  and  if,),( ),( jirjijir  CC  jir  fxicitfxsim basim .

Definition 4. Assume that we have a number v-item ai = (iti,  ik  ik  i  i  i  i  x  p  x  p  x  p ??? ?     1 ), a linguistic r-item bj =(icj, fj), and  a membership function ( jf  FS ), where )(xFS jf  denotes  the membership degree to which x belongs to fj. Let simr(ai,  bj) denote the similarity between xir, the rth-value of ai, and  bj for 1 ? r ? k. Then, simr(ai, bj) is given as follows:  jiirfjir icitxFSbasim j ??  if ),(),( .

Let supr(ai, bj) denote the degree to which xir, the rth-  value of ai matches bj, where 1 ? r ? k. There are two factors affecting supr(ai, bj); one is how certain xir is and the other is how similar xir is to bj. Therefore, supr(ai, bj) can be defined  National Chung Hsing University, Taichung, Taiwan, Nov.16-18, 2012     as the product of xir?s possibility and the similarity between xir and bj. Furthermore, let sup(ai, bj) be the degree to which ai matches bj. Since there are in total k supr(ai, bj) values, we define sup(ai, bj) and dev(ai, bj) as the average and standard deviation of these k values, respectively. In addition, to avoid generating itemsets with irrelevant association, we apply ?- cut to eliminate the itemsets with very small support.

Therefore, when sup(ai, bj) is larger than or equal to the user-  specified threshold ?, let ),( ji basup ?  and ),( ji badev ?    be the degrees sup(ai, bj) and dev(ai, bj), respectively.

Definition 5. Given user-specified threshold ?, the  following are the formal expressions for supr(ai, bj), sup(ai,  bj), dev(ai, bj), ),( ji basup ?  , and ),( ji badev ?  .

kricitbaimspbasup jijirirjir ????? 1 and  if ,),(),(  ji  k  r jir  ji icit k  basup basup ??  ? ?  if , ),(  ),( 1 ,      2 )),((),( ),(  k  basupbasupk badev  k  r  k  r jirjir  ji  ? ?? ???  (0,1] },),({),( ??? ??? jiji basupbasup ,  }),(|),({),( ?? ?? jijiji basupbadevbadev .

There are several different inference and composition techniques. The most common and simplest method is the ?min?max? technique. The ?min?max? method is used in this study. The Min and Max operators infer the supports and deviations of the itemsets, respectively.

Definition 6. Given a user-specified threshold ?, assume  that we have a v-itemset A={(it1, v1), (it2, v2), ?, (itm, vm)},  and an r-itemset B={(ic1, f1), (ic2, f2), ?, (icn, fn)}(n ? m).

Assume that we can find i1, i2, ?, in, such that ji  a  matches  bj, for 1 ? j ?n. Let sup ? (A, B) denote the degree to which A  contains B, where all sub-itemset with support greater than  or equal to ?. Now, sup ? (A, B) can be defined as follows:  ),(Min),( 1 ji n  j basupBAsup j ??  ?? .

Additionally, dev ? (A, B) can be defined as follows:  ),(Max),( 1 ji n  j baevdBAevd j ??  ?? .

Definition 7. Given a user-specified threshold ?=0.3,  assume that we have a database DB formed from a set of  transactions. Let v-itemset Ai be the i-th transaction in DB,  denoted as Ai={(it1, v1), (it2, v2), ?, (itm, vm)}, where ai=(iti,  vi) could be a category v-item, number v-item. Suppose we  have an r-itemset B={(ic1, f1), (ic2, f2), ?, (icn, fn)}(n ? m),  where bj=(icj, fj) is an r-item. Now, the support of B in  database DB, denoted as )(BsupDB ?  , can be defined as  follows:  ||/)),(()( DBBAsupBsup DBsid sidDB ? ??  ?? ,  where |DB| denotes the number of transactions in database  DB.

The deviation of B in database DB, denoted as )(BdevDB ? ,  can be defined as follows:  |)/(|)),(()( BDBsid sidDB DBBAdevBdev B? ?? ??  ,  where |DBB| is the subset of transactions in the DB containing itemset B with support greater than or equal to a threshold ?.

Note that we use |DBB| as the denominator when  computing )(BdevDB ? in Definition 5. This is because  ),( BAdev sid ?  is meaningless if transaction Asid does not  contain r-itemset B. Since ),( BAdev sid ?  can only be  applied to these |DBB| transactions, we use |DBB| as the denominator.

Traditionally, the support and confidence measures are used to access the validity of an association rule. However, Chen et al. [5] considered these two measures to be insufficient for filtering out uninteresting association rules.

To tackle this weakness, a correlation measure can be used to augment the support-confidence framework for the association rules. The correlation analysis, named the lift, is a simple correlation measure that is used to access the occurrence between the itemsets, whether independent or dependent. Since we are attempting to discover frequent, certain and relevant itemsets from uncertain data, we apply correlation analysis, named lift, to measure the correlation between the itemsets and then generate certain and interesting association rules.

Definition 8. Given four user-specified thresholds ?sup, ?dev,  ?lift, and ?, an r-itemset B is frequent if )(BsupDB ?  is no  less than ?sup; it is frequent, certain, and relevant (or FCR) if  it is frequent and )(BdevDB ?  is no larger than ?dev. Let B be  a FCR r-itemset, where B = X ? Y and X ? Y=?. Now, the  confidence of the rule X?Y, denoted as conf(X?Y), is  defined as )(BsupDB ?  / )(XsupDB ?  , and the correlation lift  of the rule X?Y, denoted as lift(X?Y), is defined as  )(BsupDB ?  / ( )(XsupDB ?  ? )(YsupDB ?  ) or conf(X?Y)  / )(YsupDB ?  . Given the confidence threshold ?conf, and the  correlation threshold ?lift, if conf(X?Y) ? ?conf, and  lift(X?Y) ? ?lift, then X?Y holds in the database D.



III. ALGORITHM FOR MINING CERTAIN ITEMSETS FROM UNCERTAIN DATA  In this section, we introduce an Apriori-like algorithm, named the FCRIM (Frequent, Certain, and Relevant Itemset Mining) algorithm, to discover fuzzy association rules from uncertain data. The FCRIM algorithm was developed by modifying the well-known Apriori algorithm [1, 2] to mine fuzzy rules from uncertain data.

National Chung Hsing University, Taichung, Taiwan, Nov.16-18, 2012     The proposed algorithm is composed of three phases, as shown in Fig. 1. In the first phase, we apply the membership functions and the threshold ? as given in Section 2 to transform the original database into a new database. Unlike the UDM approaches, those itemsets with small support will be eliminated, to avoid generating irrelevant itemsets. In the second phase, a level-wise approach is used in this study to  iteratively generate candidate r-itemsets of k items ?  kC , and  then find frequent r-itemsets of k items ? kL  from the new  database, which is composed of relevant itemsets only. The  maximum deviation ?dev is used to determine FCR r-itemsets  of k items c  kL ,?  . To proceed to the next level, we generate a  candidate set ?  1?kC  from ? kL  and repeat. In the final phase,  the fuzzy association rules are generated from the FCR r-  itemsets c  kL ,?  . In the following, we present and explain in  detail the three subroutines in each phase.

Input: A database, DB; membership functions ( jf  FS ); a  predefined ?-cut threshold ?; a predefined minimum  support ?sup; a predefined maximum deviation ?dev.; a  predefined minimum confidence ?conf; a predefined  minimum correlation ?lift.

Output: A set of fuzzy association rules  Method: // Phase 1 Call the Sup_Transform Subroutine  (1). For each transaction Transform each v-item data into r-items;  Remove the itemsets with support smaller than the  ?-cut threshold;  Store these results as a new transaction in a new  database ?  TD .

// Phase 2 Call the FCRItemsets_gen Subroutine  (1). For each r-item ?  rjic , , calculate its support.

(2). Check whether the support of each r-item ?  rjic ,  is no  less than the minimum support ?sup. If it is, put it into  the set of frequent one-itemsets ( ?  1L ).

(3). Check whether the deviation of each r-itemset in ?  1L is no larger than the maximum deviation ?dev. If  it is, put it into the set of FCR one-itemsets ( cL ,1  ? ).

(4). Generate candidate set ?  1?kC  from ? kL .

(5). Compute the supports of all r-itemsets in ?  1?kC  and  determine ?  1?kL .

(6). Compute the deviations of all r-itemsets in ? kL  and  determine c  kL ,   ? ? .

(7). If Lk+1 is null, go to phase 3; otherwise, set k = k + 1 and repeat steps (3)?(6).

// Phase 3 Call the FAR_gen Subroutine  (1). Generate fuzzy association rules from all FCR r-  itemsets with the two thresholds ?conf and ?lift.

Figure 1.  The FCRIM algorithm

IV. EXPERIMENTAL RESULTS  We conducted several experiments to evaluate our approach and the performance of the proposed algorithm. A total of 490 pieces of valid survey data were collected for a previous study [30]. The same data set is again used in this study in our evaluation of the proposed FCRIM algorithm and to further compare the difference in performance between these two algorithms. These algorithms were implemented using the Sun Java language (J2SDK 1.3.1) and run on a Notebook computer with a single Intel Centrino 1400 MHz processor and 512MB of main memory using the Windows XP operating system. Neither multi-threading technology nor parallel computing skills were used in our implemented programs.

There are two methods for the acquisition of membership functions: (1) querying experts [18, 20]; (2) application of machine learning techniques [3, 19, 21]. In most existing studies [18, 20] involving fuzzy data mining the focus is on the design of mining algorithms by assuming that the membership functions are given, because this can streamline the presentation of the paper and enable us to focus on the design of the mining algorithms. For the same reasons, the values of the five membership functions, matrix SimCC-T, and matrix SimCC-L  were the same as the previous study [30].

We perform several experiments. In the first experiment, we investigate how the run time of the FCRIM algorithm changes as we vary the minimum support value. In the second experiment, we investigate the number of patterns for different ?-level thresholds. However, the UDM algorithm may generate irrelevant itemsets, because of the summary of itemsets with small support. In addition, the support- confidence framework used by the UDM algorithm may generate association rules without correlation. To handle this problem, the FCRIM algorithm uses ?-cut to eliminate the itemsets with small support and then applies the lift threshold to discover interesting rules from itemsets with high correlation.

In the first experiment, we are interested in investigating how the run time changes as we vary the minimum support value. Therefore, we first fixed the database size at 490, with a maximum deviation at 0.2, and varied the minimum support. As can be seen in Fig. 2, it is apparent that the run time increases as the minimum support value decreases. This is especially true when the minimum support becomes very small; the run time increases sharply. These results are consistent with the results obtained from previous association mining algorithms [18, 20]. Furthermore, we focus on studying performance differences between the UDM algorithm [30] and the proposed FCRIM algorithm.

Note that the UDM algorithm does not consider the ?-cut factor, while the proposed one does. We set the database size at 490 and vary the minimum support from 0.30 to 0.50.

From the results shown in Fig. 2, it can be seen that the  National Chung Hsing University, Taichung, Taiwan, Nov.16-18, 2012     proposed FCRIM algorithm, under the threshold ?=0.3, performs slightly better than the UDM algorithm. This result is quite reasonable, because the proposed FCRIM algorithm only computes the relevant itemsets. The UDM algorithm, however, which does not apply an ?-cut in order to eliminate itemsets with small support, requires additional computation time for those irrelevant itemsets.

The second experiment was designed to investigate the number of patterns for different ?-level thresholds. In this experiment, we set the database size at 490, the minimum  support thresholds ?sup to 0.50, and varied the ?-level from 0 to 0.5. Fig. 3 shows the accumulative numbers of patterns in  ?  1L and ?  2L  for different ?-level thresholds ?. The number of patterns decreases with the threshold ? value. This is especially true when the threshold ? becomes very large.

Transaction Size=490,  MaxDev=0.20, ? =0.3           0.30 0.35 0.40 0.45 0.50  Support  R un  tim e  (S ec  on d)  FCRIM approach  UDM approach    Figure 2.  Run time vs. minimum support  The Proposed FCRIM algorithm Transaction Size=490, Minsup=0.50, Maxdev=0.20        0 0.1 0.2 0.3 0.4 0.5  ? -cut  N um  be r  of L  ar ge  I te  m se  ts  L2  L1    Patterns vs. ?-cut (The proposed approach)

V. CONCLUSION  Association rule mining is an extremely popular data  mining technique that can discover relationships between  data. Association rule mining algorithms, due to their  practical usefulness, have been used for a variety of  applications and data sets; however, using the ?-count, the  summation of a large number of itemsets with very small  support may induce irrelevant associations. This study  proposes a new approach to address this drawback, de-  signed to generate certain, frequent and highly associated  itemsets from uncertain data.

This study has made several contributions. First, we  proposed a new approach which applies ?-cut to eliminate  the itemsets with very small support. Given the ?-cut  threshold, we can prune irrelevant sets from frequent  itemsets during the generating frequent itemsets phase.

Second, during the generating association rules phase, a  correlation threshold is used, named lift, to obtain inter-  esting and highly correlative association rules from pat-terns.

Experimental results from the survey data show the  feasibility of the proposed mining algorithm.

There are several issues that can be addressed in future  research. First, in this study we assumed that membership  functions were known in advance. In the future, we hope to  adopt the use of other data mining technologies, such as  clustering [13, 17], to obtain membership functions. Experts  would not then need to assign these in a pre-processing  phase. In addition, it is assumed that experts have assigned  the ?-cut and lift thresholds. In future, we will attempt to  automatically infer the ?-cut and lift thresholds from the raw  data, avoiding the acquisition bottleneck. Moreover, Ayd?n  and G?venir [4] suggest that it is better to learn the user  specific rules of interest rather than the generic interesting  rules. Therefore, integrating the interest factors for each user  into association rules mining is worthy of future study.

Finally, since we use the ?-count, the summation of a large  number of itemsets with very small support may induce  irrelevant associations. In this regard, it would be helpful to  design a more efficient algorithm to address this issue.

