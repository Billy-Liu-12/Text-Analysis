~

Abstract - Confronted by an increasingly competitive environment and chaotic economy conditions.

businesses are facing with the need to accept greater risk. Businesses do not become insolvent overnight, rather many times creditors, investors and the financial community will receive either direct or indirect indrcations that a company is experiencing financial distress. Thus, this paper analyzed the ability of AVICENA in classifying business insolvency performance events. Neural networks (Multi layer Perceptron - Backpropagation) setves as a classifier mechanism while Apriori algorithms (Auto Association Rules) supports the decision made by the neural networks, in which rules are generated The conventional model in predicting business performances, called as Altman- Z Scores model is used for performance comparison.

Keywords - Neural Networks, Business Insolvency, Apriori Algorithms, Discriminant Analysis, Financial Ratios.

1. INTRODUCTION  The essence of business failure is the inability of owners to sustain their business from financial perspective. Thus, faced with insufficient profits or losses over a sustained period. the business owner is left with little choice.but to cease operations [2][4]. It is a major concern among managers, stockholders and creditors. Business insolvency modeling is a subject of great interest to financial practitioners and researchers.

It allows for timely decision to be made relative to the reallocation of resources more efficiently.

'  Being able to forecast potenti2 failure provides an early warning mechanism so that an appropriate adjustment in resource allocation can take place[8].

Most of-the research works in this area implement statistical model and financial analysis. Comparison with one of this method is done through performance analysis.

This paper will discuss the implementation of hybrid intelligent algorithms .as an alternative mean and improving decision-making processes in modeling business insolvency. The paper is organized, as follows, the next section, will highlight classifier techniques, association rules extraction, experimental  173 0-7803-7565-3/02/$17,00 02002 IEEE.

design and results. Finally, conclusion concluded this paper in the last section.

2. CLASSIFICATION USING MULTI LAYER PERCEPTRON-BACK PROPAGATION  Literally, neural networks are also referred as neuro- computers and connectionist networks. It is a massively paralleldistributed network processor that has a natural propensity for storing experiential knowledge and making it available for use[7].

Learning algorithm is a function of which-to modify the synaptic weights of the network in an orderly fashion so as to attain desired design objective[ I].

The Multi Layer Perceptron with back-propagation learning algorithm is depicted below (Figure 1.0):  Start: Initialize input vectors x(n) , weights, output 0.

learning parameters, error threshold  Do until terminafion criterion = True  v: (n) = 5 w,,(i)(n)yy-i) (n) y: (n) = 1/1+ e  ,=O (-"$I)(") / C)  yg(n)  = x ,  (n )  else  if@=^) or neuron j is an output layer. then  end if  S; = f b ~ ( n , o ,  (n)(l -o i (n) ) ]  J!. =j[i:.(n)(~- y: . (n)x6: t l (n)wF I (n)  if1 = lor  neuron j i s j r s t  hidden node then  v f  (n) = 0) ( n )  Errorsignal, E , @ )  = d j ( n ) - o j ( n )  w:,(n) = w:,(n)+a[w:,(n)-w:,(n-I) j+77~1(n)y:(n)yj- ' (n)  epoch --f counfer + I Loop End:  Figure 1.0: MLP Backpropagation Algorithm  This algorithm is a supervised leaming technique where the network is considerably learned sufficiently if the error rate between desired and actual error is minimized. In neural learning adaptation, the aim is to    train the network to achieve a ?balance? between the ability to recall perfectly pattern that has been learned and to give a reasonably good output responses 15).

3. ASSOCIATION RULES EXTRACTOR USING APRIORI ALGORITHM  The Apriori algorithm detects correlation between two or more fields in a data record, or among sets of values in a single field [2]. The purpose of the algorithm is to discover association rules of the following form:  P-Q,i t :P,  A P ~  A...AP, g Q ,  AQ, A..AQ? Figure 2.0: General Asskiation Rules  Apriori discovers patterns in the form of so-called large itemsets &=1,2 ,...), which is essentially the sets of items that are often associated within individual record in the database. The generated rules are calculated based on minimum support and confidence.

Assumed that the association rule given X - y a n d  minimum support and confidence are calculated as depicted below:  Support = O(x , T = total transaction IT1 . .

Figure 3.0: Support Level  Figure 4.0: Confidence Level  Support measures the frequency of the occurencing patterns while confidence indicates the strength of the rules implication. The flow of the algorithm is depicted below (Figure 5.0):  Fl= ffrequent I-item sets) K=2.

While(Fk.i is not empty) Call Ch=AprioriGen(FK.J For all transaction in T  End Fk=(c in C, s.t c.count >=min.support)  Subset (Cb  Loop Answer = usets(Fk)  Public Function ApriariGen Ffi-1)) join Ft l  with .Cl=(il.i2, ... .IbJ and C2=(jl,j2 ,... jk.Jjoined  Evaluate min. confidence new candidate, C = (il,i2, ... I k ~ j t J  Add C into table structure End Function  ip=jp f a r p  = I to k-1  Figure5.0: Apriori Algorithm Pseudo Code  The algorithm started by finding all sets of possible items that have transaction support above minimum support [2]. I t e a t s  with minimum support are called  large itemsets. Later, this itemsets are used to generate association rules.

4. PROTOTYPE DESIGN & RESULTS  For experimental works and testing, the prototype named as A VICENA is developed using Visual Basic ver. 6.0. This prototype runs under Windows platform using Pentium 800 Mhz and 128 RAM.

Figure 6.0: AVICENA Main Screen  In this prototype, there are six modules involved:  0 Adaptive Classifer Module 0 Rules-Extraction Module  Data Entry & Pre-Processing Module  Administration Support Module Reporting Module  In this paper, only three main modules will be discussed @re-processing, adaptive classifier and rules- extractor).

4.1 Feature Input Vector & Pre-Processing  The financial ratios and macroeconomics data were used as input data. The input parameters are chosen through several references and financial experts advise[1][3][4][8]. These parameters are shown below  * Working CapitabTotal Assets 0 Retained EarningfTotal Assets 0 Eaming before Income TaWrrotal Assets e Total Sales  total Assets e Total Debt I Total Assets 0 InflationRate e Inter-Bank Rate 0 Operationalsize  o Fim?sAge e TypesofIndustry  . 0 National Gross Domestic Product  Initially, these values are converted through binarization and symbolization processes. Later, these values are then normalized using Linear Scaling method:  Figure 7.0: Data Normalization     where D is original dataset and X is pre-processed value.

4.2 Adaptive Classifier Module  This module implements MLP-Backpropagation neural network. The learning parameters (momentum rate, leaming constant, firing angle, error tolerance, sampling, hidden nodes needed and maximum epoch) are predetermined by user.

Figure 8.0: Adaptive Classifier GUI  The training iteration is terminated if either maximum epoch or error tolerance achieved. The initial weights are seeded either using Nguyen-Widrow normalization or random -0.05 to 0.05 weights initialization. The Nguyen-Widraw normalization algorithm is shown in Figure 9.0  Start: Calculate p ,scale factor for n input nodes and p hidden nodes p = 0 .7" f i Set random initialization weights value to vq Compute Euclidean length ofj" column of v, lvjl  ,b (old) Update all the weights, vr = - Ibil  Use a bias input, vq = random(- p , p ) End:  Figure 9.0: Nguyen-Widrow Normalization  The data is separated into training set and testing set.

Training set provides knowledge for model's generalization, while testing set is used in validating the generalization performances upon previously m n  data. The accuracy of these sets are measured through:  x IOU correct per Paining num of training set  Correct Training (?A) =  The processing time taken during leamiog process depends to the complexity of problem space.

4.3 Rules-Extractor Module  This module provides rules-based explanation to the particular classify result. The Apriori algorithm is  chosen to chunk out the rules hidden in the financial database.

Figure 10. Rule Extractor GUI  The main purpose of this rule is to support or deny result derived from adaptive classifier module [6] .

Initially, during rules formation, the interesting itemsets are converted into binary & symbolical codes in database table. Later, Syntax-Matching Algorithm is employed for a better rules interpretation. It enables user to understand how the result was derived.

4.4 Experimental Result  The AVICENA is implemented with 300 business data, which consists of 180 healthy firm and 120 distressed firms. Several experiments were executed and the best result profile is shown in Table 1.0  Dataset I 300 Epochs 15000 iterations  11-6-1  Lkaming Rate I 0.12 Momentum  Table 1.0: The Experimental Result  The predictor module will integrate the neural networks generalized model with rules that has been extracted by Apriori algorithm. For performance comparison p q ~ ~ s e s ,  based on prior research works, the Altman Z-Score model is used. Using the same dataset, it shown that AVlCENA gives a comparable result with 86.5 percent classification accuracy, supported by 89.3 percent of rules accuracy, compared to Altman's Z-Score model with 79.7 percent of classification accuracy.

5. CONCLUSION  Financial related data is ultimately chaotic in nature.

The ability of neural networks in discerning chaotic pattem provides a bright future in predicting business insolvency. Integrated with data mining technology, Apriori algorithm is used to generate association rules.

These rules will infer on how neural network derived the results. Thus, it will neutralize the risk of wrongly    class@ cases and eliminate black-box nature in neural networks decision making process. The prototype shows promising result in classifying business insolvency.

6.ACKNOWLEDGEMENT  The author would like to convey appreciation to Registrar of Businesses & Companies and Bank Negara Malaysia for data given. Personal thanks to Miss Chua Boon Lay from CAIRO. UTM KL and Dr Simon Scott from API'M for their supports and guidance. Also many thanks to Mr. Mohd. WIZ Mohd. Hassin for his effort in integrating interface agent to the prototype.

7. REFERENCES  [ l]Agarwal.A. Neural Networks and Their Extensions for Business Decision Making: PhD Dissertation, College of Applied Mathematics, The Ohio State University (1993).

(2lAgrawal.R and Srikant R. Fast Algorithm for Mining Association Rules, 2bh Conference on Very Large Database Analysis, Santiago, Chile( 1994).

[3]Altman.E . Corporate Financial Distress and Bankruptcy 2nd Edition, John Willey, New York.

(1995).

[4]Anderson.P. The EconomvAsAn Evolving Conrplex System, Addison-Willey. Redwood City, CA (1998).

[5]Aziz .et al. Neural Networks Application in Chaos Theory: Business Failure Prediction Modeling, Td Conference of Information Technology in Asia 2001, Kuching, Sarawak (2001).

[6]Chua B.L .et al. Intelligent Database by Neural Network and Data Mining, Artificial Intelligence Application in Indust, 99, Kuala Lumpur (1999).

[7]Haykin.S. Neural Nemorks: A Comprehensive Foundation, Springer, New York (1994).

[S]lsmail.S .Pengenalan Pengurusan Kewangan, Dewan Bahasa & Pustaka, Kuala Lumpur (1998).

