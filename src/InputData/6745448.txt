Bandwidth-Aware Data Placement Scheme for Hadoop

Abstract?We are living in a data rich era. The size of the data is increasing exponentially. Social networking applications, Scientific experiments, etc. are the major contributors of Big Data.

The data can be structured, semi-structured or unstructured.

Big Data management solutions can be implemented in-house in the organization or it can be stored in cloud. Whether it is stored in-house or in cloud, the placement of data is very important. In general, users demand the availability of data whenever they request for it. There are many parameters that effect the data retrieval time in Hadoop. Among them, this paper pays attention to the available bandwidth. To minimize the data retrieval time, the data must be placed in a DataNode which has the maximum bandwidth. We have proposed a solution for bandwidth-aware data placement in Hadoop by periodically measuring the bandwidth between clients and DataNodes and placing the data blocks in DataNodes that have maximum end- to-end bandwidth.



I. INTRODUCTION  According to National Institute of Standards and Technol- ogy (NIST) definition, ?Big data is where the data volume, acquisition velocity, or data representation limits the ability to perform effective analysis using traditional relational ap- proaches or requires the use of significant horizontal scaling for efficient processing?.

Hadoop[1] is an open source framework for Big Data analysis. It can process both structured and unstructured data.

Hadoop is the backbone of many successful players in Internet like Yahoo, Facebook, etc. [2]. The two main components of Hadoop are MapReduce and Hadoop Distributed File System (HDFS). HDFS is the storage layer of Hadoop and MapRe- duce is the programming paradigm. HDFS follows a master slave architecture, consisting of one NameNode and multiple DataNodes. The files are broken into fixed size blocks. The blocks are replicated and distributed on multiple DataNodes.

The block size and replication factor can be changed by the cluster administrator. DataNode reports the blocks stored in it, to NameNode periodically. NameNode is the coordinator of HDFS. NameNode keeps metadata about the data in DataN- odes. The metadata consist of size, location and replicas of the blocks.

When a client approaches the NameNode, to write a block into the Hadoop cluster, the NameNode sends the DataNodes? addresses to the client and the client copies the data block into the DataNodes in a pipeline fashion. Here the number of DataNodes depends on the replication factor set by the administrator. The selection of DataNodes by the NameNode  is done in a random manner. The client then writes the data block to the DataNode and reads from the DataNode given by the NameNode. The placement of data blocks effects read and write performance.

The main property of block placement policy of Hadoop is rack-awareness. The rack-aware policy considers the fact that network bandwidth available between nodes in the same rack will be greater than nodes in different racks. In a data center, different racks may have different network bandwidth. Some- times the available bandwidth from the client and DataNode provided by NameNode may be less than that of many other DataNodes available in the cluster. So we have proposed a modification, in which the selection of DataNodes depends on bandwidth between client and DataNodes. When a client request for DataNodes to place the data block, the bandwidth between the client and DataNodes are compared. DataNodes with maximum available bandwidth are chosen for placement of data blocks.

After placement of data, the bandwidth between the client and DataNodes are measured, and if it found some other DataNodes with more bandwidth available than the existing, then the data block will be copied from the existing DataN- ode to DataNode with maximum available bandwidth. But every time, the cluster must satisfy the default HDFS block placement policy.



II. PROBLEM STATEMENT  In Hadoop, the default data placement strategy chooses DataNodes randomly by satisfying the HDFS?s block placement policy. The default replication factor is 3. If there are sufficient number of racks, the default replica placement policy [1] is to place the first replica in the DataNode in one rack, second replica on a different DataNode in the same rack and third replica on a DataNode in a different rack. This is the rack aware placement policy of Hadoop. If the replication factor is more than three, it has to follow the HDFS?s placement policy that no DataNode contains more than one replica of a data block and no rack contains more than two replica of a data block, provided there are sufficient number of racks available.

Since the DataNode selection for the block placement is random, the network bandwidth of the allotted DataNode may be less than the maximum available bandwidth. Sometimes, the block may be placed in a DataNode with minimum bandwidth and it is accessed more frequently. At the same time, there may be DataNodes with greater bandwidth and having less  2013 IEEE Recent Advances in Intelligent Computational Systems (RAICS)     load. We have implemented a scheme which places blocks in Hadoop cluster in a bandwidth-aware fashion.

Bandwidth-Aware Data Placement in Hadoop can be for- mulated using Integer Linear Programming (ILP) as:  Let D1, D2, D3.., DN are the DataNodes in the cluster, B1, B2, B3..., BN are the blocks to be placed in the cluster, w is the block size, r is the replication factor. Let the binary variable yij = 1 if block Bj is placed in DataNode Di and bi is the bandwidth between the DataNode Di and the client.

Maximize N?  i=1  M? j=1  biyij  Subjected to  1) N?  i=1  yij ? r, ? j = 1..M  2) w.

M?  j=1  yij ?Mi, ? i = 1..N where Mi is the memory  in DataNode Di,for i = 1..N

III. LITERATURE REVIEW  There are many research groups working in the area of Big data. Developing frameworks and designing efficient algorithms for big data processing are hot topics in this area. Hadoop[1] is an open source framework for large scale distributed processing of data. The inspiration for development of Hadoop came from two Google papers, namely Google File System (GFS) [3] and MapReduce [4].

The two primary components of Hadoop are Hadoop Distributed File System(HDFS) [5], [6] and MapReduce [4].

HDFS is the storage layer of Hadoop and MapReduce is the programming paradigm of Hadoop.

The block placement policy of Hadoop [1] is rack-aware.

But the DataNode selection is random. The default scheme does not consider network bandwidth of DataNodes as a se- lection criteria. Therefore, clients may get lesser performance than deserved.

Hadoop splits the file to be stored, into fixed size blocks, replicates the blocks and distributes in the cluster. The block size and replication factor are determined by the cluster administrator. Because of this approach Hadoop can provide high performance, high availability and reliability. Here the replication factor of each and every block is same. Figure 1 shows the architecture of HDFS. ERMS [7] provides an elastic replication policy to get better performance. It classifies the data into hot and cold classes with respect to access frequency.

The hot data is replicated more, while keeping minimum number of cold data.

Nitesh Maheshwari [8] et.al proposes a dynamic energy efficient data placement and cluster reconfiguration algorithm for MapReduce framework. This algorithm dynamically re- configures the cluster based on the current workload. It turns cluster nodes on, when the average cluster utilization rises above the administrator specified thresholds, and off, when the utilization falls below the specified threshold.

Fig. 1. HDFS Architecture  Jiong Xie et.al [9] addresses the problem of placing data across nodes in such a way that each node has a balanced data processing load. Given a data intensive application running on a Hadoop MapReduce cluster, this scheme adaptively balances the amount of data stored in each node.

CoHadoop [10] provides a solution for colocating related files in HDFS. It allows application to control where data are stored. Here applications specify related files and CoHadoop colocates these files in HDFS and thus improve the efficiency.

Workload-aware replica selection and placement algorithm proposed by Ashwin Kumar et.al [11] minimizes the total resources used in a distributed environment by colocating related data items. They minimized the average number of machines that are involved in processing a query. Jacob Lev- erich et.al [12] modifies Hadoop to allow scale-down of oper- ational clusters. This work addresses the issue of optimizing energy efficiency of Hadoop. Green HDFS [13] proposes data- classification-driven data placement. GreenHDFS is an energy- conserving, hybrid, logical multi-zoned variant of Hadoop.



IV. BANDWIDTH-AWARE DATA PLACEMENT SCHEME  In Hadoop, the files to be stored in HDFS are splitted into blocks. The block size is defined as dfs.block.size property in hdfs-ste.xml. The default block size is 64 MB and replication factor is 3. We have set the block size as 128MB. Rack- awareness is the main characteristic of Hadoop data placement.

But the selection of DataNodes to place the block is random.

We have proposed a scheme, that selects DataNodes in a rack based on the available network bandwidth. Experiments show that this give improved efficiency.

In Hadoop, When writing data, the client requests the NameNode to nominate a suite of DataNodes to host the block replicas [5]. The number of DataNodes depends on the replication factor. The selection of DataNodes will be in random fashion. The client then writes data to the DataNodes in a pipeline fashion.

In our proposed solution, at the time of writing data, the DataNodes are selected based on bandwidth. In a cluster,     different DataNodes may have different bandwidth. Iperf is used to measure bandwidth. Iperf is an open source package for measuring bandwidth between different computing nodes.

Bandwidth between HDFS client and different DataNodes are measured periodically using iperf. These bandwidths are com- pared and DataNodes with highest bandwidth are chosen. If there are more number of DataNodes with highest bandwidth, then among them the DataNodes are selected randomly.

We have setup a Hadoop cluster and the time to retrieve data from DataNodes is measured. The time taken in default HDFS and the time taken in our modified scheme are mea- sured. It has been found that our scheme outperforms the default HDFS. Since we store our data blocks in DataNodes with highest bandwidth, the data retrieval time is observed to be minimum. But, at the time of writing to HDFS, it takes more time than the default HDFS, since bandwidth between HDFS clients and available DataNodes need to be measured and compared. But Hadoop is designed for analytical processing, in which writes are infrequent and reads are frequent. Since this scheme gives higher performance while reading, we find that our solution is efficient.

One important thing we have taken into account is the load distribution. The default Hadoop evenly distributes the data among the DataNodes in the cluster and thus gives good read performance. Since we are distributing data based on bandwidth, there is chance for overload in some DataNodes while others are free. Our system ensures that no DataNode is overloaded, while others are starving for data. We have set a threshold and minimum value for the number of blocks to be stored in each DataNode. This value depends on the capacity of DataNodes in the cluster. Before copying the data block, the DataNodes having load less than threshold value are considered for bandwidth comparison.



V. EXPERIMENTAL SETUP  We have implemented our Hadoop Cluster with one node as NameNode, eight nodes as DataNodes and four nodes as HDFS clients. JobTracker and Secondary NameNode run on the NameNode itself. TaskTrackers run on corresponding DataNodes. We compared default data placement of Hadoop with our implementation of Bandwidth-Aware Data Placement.

The time needed to copy a block from DataNodes to the clients is measured in both case. It has been found that the time taken in our implementation is always less than or equal to the default random placement in Hadoop. Node with Intel core i3 2.40 GHz processor, 4 GB RAM, 500 GB hard disk is chosen as NameNode and nodes with Intel Core 2 Duo 2.20GHz processor, 2 GB RAM, 250GB hard disk are chosen as DataNodes and clients. The operating system in all these machines are Ubuntu 12.04. The bandwidth between each client and DataNodes are measured periodically using the open source tool iperf. master is the name of the NameNode, client1, client2, client3, client4 are the four clients, and slave01, slave02, slave03, slave05, slave11, slave12, slave13 and slave 14 are the DataNodes. We have repeated ourexperiments more than 10 times.



VI. RESULT  We have implemented a Hadoop cluster with one Na- meNode and eight DataNodes. A number of clients were  Fig. 2. Time in seconds to transfer 64MB data block to client3.

given permission to access the cluster. The bandwidth matrix between clients and DataNodes at a particular instance is shown in Table I.

TABLE I. BANDWIDTH MATRIX  Client1 Client2 Client3 Client4 Slave01 941 40.8 79.8 31.9 Slave02 941 41.4 79.7 33.1 Slave03 941 93.5 93.1 42.8 Slave04 941 93.6 93.4 80.3 Slave11 93.8 94.1 94.1 93.4 Slave12 93.5 94.1 94.1 93.6 Slave13 93.7 94.1 94.1 92.7 Slave14 93.7 94.1 94.1 93  Initially a file is copied to the Hadoop cluster using copyToLocal command. Hadoop splits the file into fixed size blocks of size 128MB, replicated at a factor of 2 and dis- tributed among the DataNodes. The file blocks are accessed from the clients and the access time is measured. Available bandwidth between client and DataNodes are measured using iperf. The DataNodes with maximum bandwidth from the client are identified and the data blocks are copied to the DataNodes with maximum bandwidth. After copying from the existing DataNodes, the data block is deleted from the current DataNode. While copying to the new DataNode certain conditions should be satisfied. The conditions are  1) A block bi should not be copied to a DataNode that already contains bi.

2) After copying the block, all the replicas of the block should not be in the same rack ( If there exist more than one rack).

3) The load should be equally distributed among the DataNodes.

Figure 2 shows the time in seconds to transfer 64MB data block to a client and Figure 3 shows the time in seconds to transfer 124MB block to another client. Our experiment shows that, to copy a 64MB block in HDFS to the HDFS using copyToLocal command, it took time between 2.2 Seconds to 7.695 Seconds. But in our setup it takes only 2.2 seconds every time. To copy a 124MB block HDFS takes 3.3 Seconds to 12.45 Seconds. But in our scheme it takes 3.3 Seconds only.

We have considered the case where some DataNodes are     Fig. 3. Time in seconds to transfer 124MB block to client1.

overloaded, while others are starving for data. Therefore we have proposed a modification by setting a threshold value and a minimum value for the number of blocks to be stored in each DataNode. Before copying data to the DataNodes, DataNodes with less than the threshold value are considered for bandwidth comparison and thus for copying data.



VII. CONCLUSION  In this Big Data world, developing tools for processing large amount of data is a hot area of research. Among the data processing frameworks available, Hadoop has a major role. There is a significant amount of work ongoing on the performance improvement of Hadoop. We have proposed a scheme to improve the performance of Hadoop by Bandwidth- Aware Data Placement. In this, the DataNodes to store a block are chosen based on the network bandwidth. Our experiments show that, data transfer time in our Bandwidth-Aware Data Placement Scheme gives better performance than Hadoop. We have considered the problem of load balancing among the DataNodes by fixing a threshold on the number of blocks on each DataNode. DataNodes with current number of blocks greater than threshold value are not considered for further data placement, if there exist other DataNodes with number of blocks less than threshold value.

There are many parameters that effect the data retrieval time in Hadoop. Among them, this paper pays attention to the available bandwidth. Our future research direction is to model the system with more parameters that effect the retrieval time in Hadoop inorder to improve the performance.

