Time Related Association Rules Mining with Attributes

Abstract? We propose a method of association rule mining using Genetic Network Programming (GNP) with time series processing mechanism and attribute accumulation mechanism in order to find time related sequence rules efficiently in asso- ciation rule extraction systems. We suppose that, the database consists of a large number of attributes based on time series.

In order to deal with databases which have a large number of attributes, GNP individual accumulates better attributes in it gradually round by round, and the rules of each round are stored in the Small Rule Pool using hash method, and the new rules will be finally stored in the Big Rule Pool. The aim of this paper is to better handle association rule extraction of the database in many time-related applications especially in the traffic prediction problem. In this paper, the algorithm capable of finding the important time related association rules is described and experimental results considering a traffic prediction problem are presented.



I. INTRODUCTION  One of the most common tasks of data mining is to detect  relationships or associations between categorical variables in  large databases. This relationship can be represented as asso-  ciation rules. An association rule has the form of (X ? Y ), where X represents antecedent and Y represents consequent.

The association rule ?X ? Y ? can be interpreted as the set of attributes indicating X is likely to also satisfy Y .

Association rule mining aims at discovering association  relations or correlations among attributes encoded within a  database [1]. The most popular model in association rule  mining is Apriori algorithm [2]. This algorithm measures the  importance of association rules with two factors: support and  confidence. Chi-squared value can also be used in association  rule mining. Brin et al. suggested to measure the significance  of associations via the chi-squared test for correlation used  in classical statistics [3].

The conventional database used in GNP data mining  [4] is transaction-related, which means that every tuple in  the database is related with one transaction. A database  transaction is a unit of interaction with database management  systems or similar systems that are treated in a coherent and  reliable way.

Although traditional rules without time series can tell how  interest events happen together, it can not tell at what time  the event will happen or how long the event will last. The  time series here can help us to predict the events in the time  domain more accurately.

We have already proposed a method of time-related asso-  ciation rule mining [5] using Genetic Network Programming  Graduate School of Information, Production and Systems, Waseda University; Email: zhy836@toki.waseda.jp; weiwei@fuji.waseda.jp; k.shimada@aoni.waseda.jp; mabu@aoni.waseda.jp; hirasawa@waseda.jp  (GNP) to improve the efficiency and effectiveness of rule  extraction. In this paper we extend the original algorithm  and propose a mechanism in order to find time related rules  more efficiently in an associate rule extraction. The major  point of this paper are as follows:  ? The database is time-related considering the real-time  factor into consideration. Then, the same attribute now  has different meanings at different time points.

? Time delay tags are used for the connections of the  judgment nodes, for example ?A(t = p)? means the judgment node A at time p. Therefore, searching the  basic data for calculating the confidence, support and  chi-squared value becomes two dimensional search.

? The conception of round is introduced in order to  systematically and efficiently explore the search field.

Each round has its corresponding sub attribute set and  the Small Rule Pool(SRP), the rules in the SRP of each  round will be checked for overlap and only the new one  will be stored finally in the Big Rule Pool(BRP).



II. GENETIC NETWORK PROGRAMMING(GNP)  In this section, Genetic Network Programming(GNP) is  briefly reviewed [6],[7]. GNP is a sort of evolutionary  optimization techniques, which uses directed graph structures  as solutions. The basic structure of GNP is shown in Fig.1.

The graph structure(penotype) of GNP includes three kinds  of nodes: start nodes, judgment nodes and processing nodes.

Judgment nodes are the set of J1,J2,..., which work as if-  then type logical decision making functions. On the other  hand, processing nodes are the set of P1,P2,..., which work  as certain kind of action/processsing functions. The concrete  roles of these nodes are predefined and stored in the library.

Once GNP is started up, firstly the execution starts from  a start node; consequently the next node to execute is  determined according to the connection and if-then judgment  result of the current node.

The genotype expression of GNP node is shown in Fig.2.

This describes the gene of node i, then the set of these  genes represents the genotype of GNP individuals. NTi describe the node type, NTi = 0 means node i is start node,  NTi = 1 represents node i is judgment node and NTi = 2  represents node i is processing node. IDi is an identification  number, for example, NTi = 1 and IDi = 1 means node  i is J1(Judgment node with ID 1). Ci1,Ci2,..., denote the connections of node i. di and dij are the delay time required  to execute the processing of the nodes and transition between  nodes.

Start  P 1  P 2  P 3  J 1  J 2 J 4  J 5  J 3  : Sta rt Node  : P rocessing Node  : Judgment Node  Fig. 1. The basic structure of GNP individual  NTi IDi d i Ci1 d i1 Cij d ij......

node gene  connection gene  node i  Fig. 2. Gene structure of GNP (node i)

III. TIME RELATED ASSOCIATION RULE MINING  USING GNP  A. Structure of Database  The database we handle here is no longer transaction-  based, but time series-based, i.e., the tuples in time series  database represent each time point instead of each transac-  tion. Another important feature of the database is that the  attributes of the database are not restricted to simply ?0?  or ?1?, but could be continuous real numbers. In traditional  cases ?0? or ?1? represents the meaning such as ?happen?,  ?not happen? or ?contain?, ?not contain?, but in the real  world, the attribute is not always so simple, they could be  continuous, especially in time-related systems. Database we  used here is like Table I. The Time in Table I represents the  time unit, it can be one second, one minute, one hour and so  on, its concrete meaning is related to the concrete problem  to concern.

According to the range of the continuous values of the at-  tributes, we divide the continuous values to three categories,  i.e., Low, Middle and High. Supposing that the Middle  threshold is 4 and the High threshold is 7, the attribute  A = 9 is ranked as A?High, i.e., (A?Low, A?Middle, a ? High)=(0, 0, 1). So Table I is converted to Table II.

B. Structure of Rules  Let Ai(?)(t = p) be an attribute in a database at time p and its value is 1 or 0. Ai(?) represents Ai(Low)/Ai(Middle)/Ai(High). The proposed method ex- tracts the association rules as follows:  (Aj(?)(t = p) = 1) ? ? ? ? ? (Ak(?)(t = q) = 1) ? Am(?)(t = r) = 1) ? ? ? ? ? An(?)(t = s) = 1) (briefly, Ap(?)(t = p) ? ? ? ? ? Ak(?)(t = q) ? Am(?)(t = r) ? ? ? ? ? An(?)(t = s)) Here, p ? q ? r ? s, the first t always equal 0, other time points are the relative time shifts from the first attribute.

TABLE I  DATABASE BEFORE DISCRETIZATION  Time A1 A2  0001 8 3  0002 4 4  0003 8 1  0004 2 9  TABLE II  DATABASE AFTER DISCRETIZATION  Time A1 A2 Low Middle High Low Middle High  0001 0 0 1 1 0 0  0002 0 1 0 0 1 0  0003 0 0 1 1 0 0  0004 1 0 0 0 0 1 Middle threshold=4; High threshold=7;  For example: A1(Low)(t = 0) ? A2(Low)(t = 6) ? A3(High)(t = 22) means that A1 is Low at time 0 and A2 is Low at time 6, then A3 becomes High at time 22.

This kind of rules can find time related relations between  attributes and can be used in the prediction problems.

C. GNP for association rule mining with time series  Association rule mining with time series is an extension  of the GNP based data mining [4] in terms of treating time  related rules.

GNP individual examines the attribute values of database  tuples using judgment nodes and calculates the measurements  of association rules using processing nodes. Attributes and  their values correspond to judgment nodes and their judg-  ments in GNP, respectively. Therefore, the connections of  nodes are represented as association rules. The measurements  include support and Chi-squared test. Judgment node deter-  mines the next node by a judgment result of (Yes/No). Fig.3.

shows a basic structure of GNP for time-related association  rule mining. P1 here is a processing node and is a starting  point of association rule mining. Each Processing node has  an inherent numeric order (P1, P2, ...) and is connected to a judgment node. Yes-side of the judgment node is connected  to another judgment node. No-side of the judgment node is  connected to the next numbered processing node. The total  number of tuples moving to Yes-side at each judgment node  is calculated for every processing node, which is fundamental  for calculating association rules.

In the proposed method, the examination should consider  the attribute dimension and also the time dimension, thus the  method is two dimensional. That is, not only the attribute but  also the corresponding time delay should be considered: For  example, as described in Fig.4: the judgment is not merely  executed row by row, but the procedure is like the following:  firstly judge the tuple at time 0000, and according to GNP  individual structure of Fig.4, first A1(Low) is judged and if the value of A1(Low) at time 0000 is  ?1?, then move to the next judgement node named A2(High). Then, due to the time delay T =2 from A1(Low) to A2(High), we check the value of A2(High) at time 0000+2=0002. If the value  306 2008 IEEE Congress on Evolutionary Computation (CEC 2008)    N A1=1P 1 A2= 1 A3 =1 A4 =1  P 2  a b c d  P 2 P 2 P 2  T= 0 T= u T= v T= x T= y  Time d ela y  : Yes-side connection : No-side connection  : possib le connection T: Time D ela y  : P rosessing Node : Judgmen t Node : possib le position  Fig. 3. The basic structure of individual  of A2(High) at time 0002 is ?1?, continue the judgment likewise, if not, execute another turn of the judgment which  begins from time 0001, 0002, 0003, . . . , until the end of  database.

N A1(Low)  =1P 1 A2(H igh)  =1 A3(M id)=   A4(H igh)  =1  a b c d  T= 0 T= 2 T= 1 T= 3 T= 2  Time d ela y  Time A1 A2 A3 A4  Low Middlle High Low Middle High Low Middle High Low Middle High  0000 1 0 0 0 0 1 1 0 0 0 1 0  0001 1 0 0 1 0 0 0 1 0 1 0 0  0002 0 1 0 0 0 1 1 0 0 0 1 0  0003 1 0 0 0 0 1 0 1 0 1 0 0  0004 1 0 0 1 0 0 0 1 0 0 0 1  0005 0 1 0 1 0 0 1 0 0 0 1 0  0006 0 0 1 0 1 0 0 0 1 0 0 1  0007 1 0 0 0 1 0 0 1 0 1 0 0  0008 0 1 0 1 0 0 1 0 0 0 1 0  0009 1 0 0 0 1 0 0 1 0 1 0 0  Fig. 4. Search method of time related data mining  D. Extraction of association rule  The total number of the search from the processing node  moving to Yes-side at each judgment node is calculated  for every processing node, which is a starting point for  calculating association rules. In Fig.4, N is the number of  the total search, and a, b, c and d are the number of the  search moving to the Yes-side for each judgment node. The  measurements are calculated by these numbers. The proposed  method measures the significance of associations via the  chi-squared test for correlation used in classical statistics.

For example, if we change the connection of P1 node from  ?A1(Low) = 1? to ?A2(High) = 1?, we are able to calcu- late the support of A2(High), A2(High)?A3(Mid) and so on, and as a result, chi?squared value can be calculated. We can repeat this like a chain operation in each generation. As  a result, we obtain the values for measuring the importance  of the rules. Now, we define important association rules as  the ones which satisfy the following:  ?2 > ?2min, (1)  support ? supmin, (2) , where, ?2min and supmin are the threshold of the minimum  chi-squared and support value given by supervisors. In this  definition, if the rule ?X ? Y ? is important, then, X ? ?Y,?X ? Y,?X ? ?Y, Y ? X, Y ? ?X,?Y ? X and ?Y ? ?X? are also important rules. If necessary, we can also use confidence value in the definition. The extracted  important association rules are stored in a pool all together  through generations in order to find new important rules.

E. Attribute Accumulation Mechanism  Conventional method extracts association rules using the  whole attribute set without sub attribute sets and rounds.

When the whole attribute set is large, then, which attributes  are used for initializing individuals will influence the effi-  ciency of the whole evolution process.

In order to deal with databases which have a large number  of attributes, in the attribute accumulation mechanism, GNP  individuals accumulate better attributes in it gradually round  by round, where each round is a sequence of generations.

The attribute accumulation mechanism proposed here first  randomly selects a small attribute set of size s from the whole  attribute set of size S(S ? s), then applies GNP based data mining algorithm using GNP individuals generated  exclusively from the chosen attribute set and finally stores  the extracted association rules in the corresponding Small  Rule Pool(SRP) using hash functions. This whole procedure  is called Round 0.

After the processing of Round 0, we get the corresponding  SRP(0). For each of the rules stored in SRP(0), we check its overlap and sum up the count of the appearance of  each attribute in the chosen attribute set, and using these  records sort the attributes from the most frequently used  one to the least one. The top 20% of the attributes will be remained in the chosen attribute set. The attribute set of  the next Round 1 is then composed of the top 20% of the attributes and attribute set randomly chosen from the original  whole attribute set. Using the newly generated set, Round 1 searches the important association rules and stores the newly  generated rules in the corresponding SRP likewise.

The similar procedure is repeated Round and Round until  the final condition is satisfied. The procedure is shown in  Fig.5.

F ina l R ound  Da ta M ining  Big At t r ibute Set :  672 at t r ibutes  Data M ining  Sub Set Size: s  r a ndom  Small Rule Pool 1  Sort, Hash  Top 20% Attributes  Sub Set Size: s  20% + r a ndom  Small Rule Pool i  Sort, Hash  Top 20% Attributes  Da ta M ining Sub Set Size: s  20% +r a ndom  Small Rule Pool N  Sort, Hash  Top 20% Attributes  Big Rule Pool  Hash  Check Overlap  R ound i  R ound 0  Fig. 5. Attribute accumulation mechanism  F. Rule Pool and Hash function  As mentioned before, there are two kinds of Rule Pools:  Small Rule Pool(SRP), and Big Rule Pool(BRP). They both  2008 IEEE Congress on Evolutionary Computation (CEC 2008) 307    use hash functions to facilitate the speed of the search and  judge overlap. The hash function we used here is defined by:  HVr = (asumr + tsumr mod Tshift) mod BN, (3)  asumr = ? i?I  {Ini}, (4)  tsumr = ? i?I  {Delayi}. (5)  The symbols are as follows:  HVr : the hash value of rule r.

I : the set of attributes which is contained in rule r.

Ini : the index of the attribute i.

Delayi : the delay time of attribute i.

asumr : the sum of the attribute index of rule r.

tsumr : the sum of the attribute delay time of rule r.

Tshift : the number of shifts to differentiate the rule with  the same sum of attributes but different sum of delays.

BN : the total number of hash buckets.

In the small rule pool(SRP), we use the Eq.(3), Eq.(4) and  Eq.(5) to map the rules to the corresponding buckets of SRP.

SRP is actually a mapping mechanism from the rule to its  relevant bucket in the form of hash tables.

Big Rule Pool(BRP) also employs the same hash function  with SRP. Therefore, at the end of each round, we are able  to check the rules in the buckets of SRP and BRP with the  same hash value. Using this algorithm, the new rules are  finally stored in the result pool?Big Rule Pool(BRP). The  procedure of checking the overlap is shown in Fig.6.

When an important rule is extracted by GNP, it is checked  whether an important rule is new, i.e., whether it is already in  SRP or not. If the rule is new, it is stored in the SRP. At the  end of each Round, every rule in the SRP should be checked  on whether it overlaps with the rules in BRP, and only the  rule never presents in the BRP before can be considered as  a real new rule. The appearance frequency of attributes are  calculated using the rules in the BRP.

Hush Index Con ten ts  bucket 0 r u les with hu sh va lu e 0  bucket 1 r u les with hu sh va lu e 1  bucket 2 r u les with hu sh va lu e 2  bucket 3 r u les with hu sh va lu e 3  ...... ......

bucket h r u les with hu sh va lu e h  ...... ......

bucket BN r u les with hu sh va lu eBN  Big Ru le P ool  bu cket 0 in SRP l  bu cket 1 in SRP l  bu cket 2 in SRP l  bu cket 3 in SRP l  bu cket h in SRP l  bu cket BN in SRP l  check  over la p  ........

........

Sma ll Rule Pool l  Fig. 6. Checking the overlap of BRP and SRP(l)  G. Fitness and Genetic Operator  When a new rule is generated, the rule like ?A ? A ? A? is considered useless in the original GNP based data  mining method. However, taking account of the time series  algorithm, even the same attribute has different meanings at  different time points, so the rule like : Ai(?)(t = p) ? ? ? ? ? Ai(?)(t = q) ? Ai(?)(t = r) ? ? ? ? ? Ai(?)(t = s), where p ? q ? r ? s, has its meaning. However, the number of this kind of rules  should be controlled, since too many rules of this kind would  harm the evolving process and produce a large number of  GNP individuals with the same attribute during the following  generations. Now, we define the concept of multiplicity.

Multiple rules here mean: the rules which contain many  different attributes in addition to the conventional interest.

Therefore, fitness function of GNP is defined as:  F = ? r?R  {?2(r) + 10(nante(r) ? 1) + 10(ncon(r) ? 1)  +?new(r) + ?mult(r)}.

The symbols are as follows:  R : set of suffixes of important association rules which  satisfy Eq.(1) and Eq.(2) in GNP individuals.

?2(r) : chi-squared value of rule r.

nante(r) : the number of attributes in the antecedent of  rule r.

ncon(r) : the number of attributes in the consequent of rule r.

?new(r) : constant defined as  ?new(r) =  { ?new, if the rule r is new  0, otherwise ?mult(r): constant defined as  ?mult(r) =  ?? ?  ?mult, if the rule r has many  different attributes  0, otherwise  ?2(r), nante(r), ncon(r), ?new(r) and ?mult(r) are con- cerned with the importance, complexity, novelty and diversity  of rule r, respectively. At each generation, GNP individuals  are replaced with new ones by the selection policy and other  genetic operations. We use four kinds of genetic operators:  ? Crossover: The uniform crossover is used. Judgment  nodes are selected as crossover nodes with the crossover  rate. Two parents exchange the gene of the correspond-  ing nodes.

? Mutation-1: The connection of the judgment nodes is  changed randomly by mutation rate-1.

? Mutation-2: The function of the judgment nodes is  changed randomly by mutation rate-2.

? Mutation-3: The time delay between the judgment nodes  is changed by mutation rate-3. The mutation range  depends on the concrete problems to solve.

The individuals are ranked by their fitness and upper 1/4  individuals are selected. After that, they are reproduced four  times, then four kinds of genetic operators are executed  to them. These operators are executed for the gene of  judgment nodes of GNP individuals. All the connections  308 2008 IEEE Congress on Evolutionary Computation (CEC 2008)    of the processing nodes are changed randomly in order to  extract rules efficiently.



IV. SIMULATIONS  In this section, the effectiveness and efficiency of the  proposed method is studied by a simple traffic simulation.

A. Traffic Simulator  The traffic simulator used in our simulations is a 7?7 road map model like Fig.7, i.e., each link has the same length, all  cars have the same speed for simplicity, and the shape of the  total road map is like a grid network.

#N1 #N2 #N3 #N4 #N5 #N6 #N7  #S1 #S2 #S3 #S4 #S5 #S6 #S7  #W2  #W1  #W3  #W4  #W5  #W6  #W7  #E2  #E1  #E3  #E4  #E5  #E6  #E7  :represent car #** : represent O/D name  : represent link from crossroad W2N4 to W2N5  : represent link from crossroad W2N5 to W2N4  : represent crossroad W3N4  Fig. 7. Road map model  TABLE III  EXAMPLE OF OD (ORIGIN/DESTINATION)  O D #N1 #N2 #N3 #N4  #N1 . . . 7 1 8  #N2 12 . . . 7 5  #N3 8 0 . . . 6  #N4 2 1 9 . . .

TABLE IV  PARAMETER SETTING FOR EVOLUTION  Number of parameters value  Number of judgment nodes 100 Number of processing nodes 10 Number of attributes 672 Number of time units 800 Number of generations per Round 50 sub attribute set size 100  The generation of cars from each starting point is based on  O/D (Origin / Destination) shown in Table III. For example,  in Table III, the ? #N1? is the name of a starting/end point,  numeral 12 in the table means that car traveling from the  point named ?#N2? to the point named?#N1? has the traffic flow of 12 vehicles per time unit. The car traveling  from the starting point to itself is forbidden here.

The parameter setting of the proposed data mining is  presented in Table IV. Attributes here are the candidates  of judgment node functions, for example, an attribute  named?W4N6, W4N7(Low)? can be interpreted as the situ- ation that the link ?W4N6, W4N7? has low traffic. We have 7? 8? 2=112 links here in our simulator and each link has two directions, so 112?2 = 224 links in total. What?s more, each link has 3 categories (Low/Mid/High), thus we have  224?3 = 672 attributes. Time units in Table IV represent the number of total unit times in our database. Simulator runs for  5000 time units, but, removes the first and last 500 hundred  time units for the consideration of stabilization. Taking the  samples every 5 time units, i.e., (5000-500-500)/5= 800, thus  we use 800 time units in the simulation.

B. Simulation results  1) Simulation 1: In simulation 1, the number of rules  stored in the Big Rule Pool(BRP) is compared between  the proposed method and the conventional method without  attribute accumulation mechanism. Each round has the same  number of generations of 50 and the chosen set size is set  to 100 for first simulation.

0 200 400 600 800 1000 1200  Round  N u  m b  e r  o f  A s s o  c ia  ti o  n  R u le  s  data mining with Attribute Accumulation the conventional one  Fig. 8. Comparison of the number of rules between the proposed method and conventional method  Fig.8 shows the number of rules obtained in the BRP  versus round number. In the conventional one in Fig.8,  GNP individuals are randomly initialized from the whole  attribute set at the beginning of each ?round?. We can see  from Fig.8 that the proposed method can extract important  association rules efficiently, especially, when compared with  the conventional one.

The rule extracted is like the followings:  W4N5, W4N6, Low(t = 0) ?  W4N5, W3N5, High(t = 9) ? W3N5, W3N6, High(t = 11)  The above rule means that the link on the map named  ?W4N5, W4N6? has low traffic at time 0, then the link named ?W4N5, W3N5? will probably have high traffic  2008 IEEE Congress on Evolutionary Computation (CEC 2008) 309    volume at time 9, and the link named ?W3N5, W3N6? will also possibly have high traffic volume at time 11.

#N1 #N2 #N3 #N4 #N5 #N6 #N7  #S1 #S2 #S3 #S4 #S5 #S6 #S7  #W2  #W1  #W3  #W4  #E 2  #E 1  #E 3  #E 4  : r epr esent link fr om cr ossr oa d W4N5 to W4N6  : r epr esent link fr om cr ossr oa d W4N5 to W3N5  : r epr esent link fr om cr ossr oa d W3N5 to W3N6  Fig. 9. Rule and map  As Fig.9 describes, this rule represents the trend that  more cars will choose the link ?W4N5, W3N5? and ?W3N5, W3N6?, which was triggered by the past low traffic volume of the link ?W4N5, W4N6? besides them.

According to this information, we can adjust our routing  algorithm more accurately.

2) Simulation 2: The aim of the second simulation is  to study the relations between the chosen attribute set size  and the performance of the algorithm. With other parameter  setting being unchanged, the attribute set size of 25, 50, 100,  125, 150, 200, 400, 672 has been studied in turn. The result  is shown in Fig.10.

0 200 400 600 800 1000 1200  Round  N u m  b e r  o f A  ss o ci  a tio  n R  u le  s          Fig. 10. Number of rules in case of changing the attribute size  From Fig.10 we can see that the performance of the  attribute set size 672 is almost the same as the result of  the conventional in Fig.8, since the 672 is the total attributes  size.

From the Fig.10 we can also see that both too large or  too small attribute set size will harm the performance of the  algorithm and the best solution should be selected according  to the concrete problems. In our cases, the best solution is  obtained when we use the attribute set of size 50.

3) Simulation 3: The third simulation is to explore the  relations between the generation size per each round and the  performances of the algorithm. With other parameter setting  being unchanged , the attribute set size has been set to 50  and the performance of the algorithm with generation size  of 25, 50, 100 and 150 are compared. The result is shown  in Fig.11.

The average number of finding new rules per one genera-  tion in each case is shown in Fig.12. Since the time consumed  in each generation is almost the same with each case, the  number in Fig.12. actually represents the time complexity of  each case.

0 100 200 300 400 500  Round N  u m  b e  r o  f a  ss o  ci a  tio n  r u  le s  50 150 25 100  Fig. 11. Number of rules in case of changing the generation size           Test cases using different generation size  A v e  ra g  e   n u  m b  e r  o f  e x tr  a c te  d  ru le  s p  e r  g e n e ra  ti o n  The average number of generation size 25  The average number of generation size 50  The average number of generation size 100  The average number of generation size 150  Fig. 12. Average number of rules extracted per generation  The larger generation size certainly contributes to find-  ing more rules of the whole algorithm, however, the time  complexity increases. Considering this trade-off and that the  different round has different convergence rate, the fixed size  of generations per round is not a good method, which should  be studied more in the future.



V. CONCLUSION  In this paper, a method of association rule mining using  Genetic Network Programming with time series processing  310 2008 IEEE Congress on Evolutionary Computation (CEC 2008)    mechanism and attribute accumulation mechanism has been  proposed. The proposed method can extract important time-  related association rules efficiently. Extracted association  rules are stored temporarily in Small Rule Pool(SRP) and  finally all together in Big Rule Pool(BRP) through rounds  of generations so as to find new important rules. These rules  are representing useful and important time sequences used  in the real world. We have built a simple road simulator and  examined the effectiveness and efficiency of our algorithm.

The results showed that our proposed method extracts the  important time-related association rules in the database ef-  fectively and the attribute accumulation mechanism improves  the performance considerably. These rules are useful in time-  related problems, for example, traffic prediction. We are now  studying further improvement of our method in terms of  the combination of the proposed method with optimal route  algorithm.

