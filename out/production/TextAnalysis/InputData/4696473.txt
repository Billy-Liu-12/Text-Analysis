Efficient Mining of Frequent Closed Itemsets without Closure Checking

Abstract  Most existing algorithms for mining frequent closed  itemsets have to check whether a newly generated itemset is a frequent closed itemset by using the subset checking technique. To do this, a storing structure is required to keep all known frequent itemsets and candidates. It takes additional processing time and memory space for closure checking. To remedy this problem, an efficient approach called closed itemset mining with no closure checking algorithm is proposed.

We use the information recorded in a FP-tree to identify the items that will not constitute closed itemsets. Using this information, we can generate frequent closed itemsets directly. It is no longer necessary to check whether an itemset is closed or not when it is generated.

We have implemented our algorithm and made many performance experiments. The results show that our approach has better performance in the runtime and memory space utilization. Moreover, this approach is also suitable for parallel mining of frequent closed itemsets.

Keyword: Association rule, closed itemset, closure checking, data mining   1. Introduction Data mining is an important research field for finding  information in a large volume of data [13]. The function of data mining is to find important information that can be used to make decides and action plans. Data mining has already been applied extensively in various industries.

Association rule mining is a useful data mining technique to find frequent itemsets and generate useful association rules [12]. Generating all frequent itemsets  [1-3], [15-16] in brute force is not an efficient task, so many closed itemsets [4-10] and maximal itemsets [11] approaches were derived. However, the information of maximal itemsets is incomplete such that association rules cannot be generated directly. Frequent closed itemsets can solve the problems that frequent itemsets and frequent maximal itemsets have. A frequent itemset is closed if none of its proper supersets have the same support. All closed frequent itemsets contain complete information to generate association rules.

However, most known frequent closed itemset mining algorithms must check the closure at the end of the process or during the process [4-6], especially for the algorithms using the horizontal dataset directly. The closure checking examines whether a newly found itemset is a subset or a superset of an already found frequent closed itemset with the same support. For this purpose, it is necessary to create a structure to store all frequent closed itemsets and closed itemset candidates.

The closure checking step of the existing closed itemset mining algorithms is computational expensive and requires additional memory space for generating, storing and removing non-closed itemsets.

Our work completely eliminates the closure checking step during the closed itemset generation. We propose an algorithm called Closed Itemsets Mining with No closure Checking (CIMNC) to directly produce frequent closed itemsets without closure checking and unnecessary storage structure. CIMNC won?t generate unnecessary conditional FP-trees [4] if possible. We only use an attribute called record in the node of FP-tree to keep necessary information in each branch of the tree such that redundancy can be avoided. Especially, only frequent closed itemsets are produced and each one is produced exactly once. Since CIMNC can generate frequent closed itemsets directly in each processor, it is also suitable for   DOI 10.1109/ISDA.2008.46         parallel mining.

2. Related work The FP-growth method [2] is a depth-first and  divide-and-conquer algorithm. In this method, a structure called FP-tree is used to obtain a compact representation of the original transactions. Every branch of the FP-tree represents a transaction composed of the subset of frequent items. The nodes along the branches are stored in decreasing order of the frequency of all frequent items. Compression is achieved by overlapping itemsets which share prefixes of the corresponding branches to build the FP-tree. The FP-tree has sufficient information to mine complete frequent patterns. Each node in the FP-tree has three fields: item-name, count, and node-link. The frequent itemsets can be found from the FP-tree quickly without having to scan the database on the disk frequently. A frequent-item header table is built to make traverse the tree more easily. All frequent items are stored in the header table in decreasing order of their frequency. Each item points to its occurrence in the tree via a head of node-link. Nodes with the same item are linked via node-links. Each entry in the header table has two fields: item-name and head of node-link.

The FP-growth method scans the database only twice.

In the first scan it finds all frequent items and inserts them into the header table in decreasing order of their counts. In the second scan, the root of FP-tree is created with ?null.? The set of frequent items in each transaction is inserted into the FP-tree as a branch. If an itemset has the same prefix with another itemset already in the tree, this part of branch will be shared. A count in a node stores the number of the item which appears in this path.

When a transaction is inserted into a new branch, the count is updated. After all nodes are linked from the header table, the FP-tree is completely constructed. The next step is to find all frequent itemsets. It collects all the patterns which a node participates by starting from its head in the header table and following its node-link. The mining process starts from the bottom of the header table.

Paths with the same prefix item in the FP-tree construct the conditional pattern base of the prefix item with its support. Frequent items in the conditional pattern base construct the conditional FP-tree of the prefix item. It keeps constructing the conditional FP-tree until a single path is found. Frequent itemsets with the same prefix are generated by the single path.

The CLOSET+ algorithm [6] is based on the FP-tree and uses the two-level hash indexed result tree to store frequent closed itemsets for closure checking. When it finds a single path in the conditional FP-tree, it must  perform subset checking to check if it should generate the closed itemset candidate with a prefix itemset from all known frequent closed itemsets. If the prefix itemset is a subset of a known frequent itemset and has the same support, the itemsets of this prefix itemset will not be generated. On the other hand, the closed itemset candidates are generated and then it must check the closure in the result tree to determine if they are really frequent closed itemsets. CLOSET+ needs to do many times of subset checking and closure checking. Since the result tree is searched many times, it takes a lot of time.

3. Proposed algorithm: CIMNC  A. Main Concept of CIMNC Mining itemsets in bottom-up order of item supports is  the property of FP-tree. One can not find supersets of the found frequent closed itemsets by using this property. If it can avoid generating the subsets of known frequent closed itemsets, frequent closed itemsets can be generated directly.

According to the properties of FP-tree and closed itemset, it is easy to find that if an itemset is a subset of the other known itemset and both of their prefix items have the same support, they are both found in the same path. Therefore, if a branch has more than two items that have the same support, it may generate subsets with the same support. In order to avoid generating these subsets, it should keep off items which have been processed with the same support in the same path and avoid constructing them again.

A record is used in CIMNC to identify if an item has been processed before. If the nodes of an item have the same item in the record, it means the item has completed the process. Using this idea, subsets with the same support won?t be generated. Thus, it can speed up the run time by not building the conditional FP-tree for invalid items.

B. The CIMNC Algorithm Based on CLOSET+, CIMNC has seven steps: Step 1: Scan the database to find the counts of all items. Find  all frequent items by using the min_sup. Sort these items in a decreasing order of their supports. Build the header table with item-name and head of node link fields.

Step 2: Scan the database again to build the FP-tree, which has  four fields: item-name, count, node-link and record, according to the order of the header table. Each node with the same item-name is linked together.

Step 3: According to the order of items in the header table,  each item is used as the prefix item one at a time. If all nodes of the prefix item do not have the same items in their records, get all paths containing the prefix item being linked from the header table. When getting a path, the records in this path are noted if the prefix item is a leaf of the tree. Then set the support and record of the prefix node as the support and records of all items in the path to form the conditional pattern base.

Step 4: Prune the items which have the same item in their  records and the items which are not frequent from the conditional pattern base. Then, use the remaining items to build the header table. Finally, create the conditional FP-tree with the header table. Set the next item in the header table as the prefix item. Use Step 5 to process the conditional FP-tree. Repeat Step 3 and Step 4 until the last item of the header table is processed.

Step 5: According to the order of items in the header table of  the conditional FP-tree, each item is used as the prefix item one at a time. Repeat Step 3 and Step 4 to create the conditional FP-tree for each prefix item until the conditional FP-tree becomes a single path.

Step 6: Note the records for this path and obtain all itemsets  whose prefix items have no item in their records. It can get closed itemsets from the single path with the prefix items of the conditional FP-trees which have been processed before.

Step 7: After processing the last item in the original header  table, it generates all frequent closed itemsets.

C. Two Lemmas of CIMNC If the support of a prefix item is equal to the parent  items which have the same support as the prefix item, they will be constructed completely when the prefix item generates the conditional pattern base. These items have already been processed. In order to know which items have been processed in advance, our method uses records to note items that have the same support as their child items in the same branch. Using an array as a record in a node of FP-tree will waste much space. Instead, the linked list technique is used to store items. When considering an item if it is necessary to build the conditional FP-tree or closed itemset with this item, one can simply check if the records in all nodes with this item are all have the same items. If they all have the same item, it is unnecessary to process because it has been  done before. So itemsets generated by this item are not closed.

Lemma 1. If all nodes of an item have the same items in their records, itemsets generated by this item are not closed.

After building the FP-tree, each item is considered as a prefix item following the order of items in the header table. When it searches the related paths of a prefix item by node-links of the header table, the records of these paths are completed.

The way to note the record is shown as follows. When the node-link of a prefix item is linked to the first node from the header table, it can find the first path which contains the prefix item. When searching this path upward to look for items in the path, it can check if its child nodes have a total count that is equal to its count. If their counts are not the same, it won?t note anything.

Otherwise, if the node has only one child node, it can note the item and record its child node in its record. If the node has more than one child node, it should check if any node has the same items in item-name or records. If each branch has the same items, it will note the item in the record of the node. Otherwise, nothing is noted. Repeat this process to the root until each node of the prefix items of the header table has been processed. If a node of a prefix item is not at the bottom of the path, it means this path has been noted before.

Lemma 2. CIMNC won?t generate non-closed itemsets or miss any closed itemsets.

D. An Example of applying CIMNC The database in Table 1 is used to present a simple  example for CIMNC. After scanning the database, it finds all frequent items with min_sup=2. They are a:3, c:4, f:4, m:3, p:3, b:3. Then sort these items with support in decreasing order to get f:4, c:4, a:3, b:3, m:3, p:3.

When transactions are inserted into the FP-tree, items in each transaction will be sorted by the order as shown in Table 1. To find each item in all branches easily, a header table is created with the sorted items in Fig. 1.

Table 1 A sample transaction database               Fig. 1 The global FP-tree for Table 1.

After scanning the database again, the global FP-tree  is built in Fig. 1. All nodes which have the same item-name are linked from the header table. After constructing the FP-tree, it can be traversed to find all frequent closed itemsets. According to the FP-growth method, it can take item p as a prefix itemset to get two paths, fcamp and cbp, by using the node links of item p in the header table. When a node is linked, it will search the path to find what items are in this path. At this time, it will note items in the record of each node if a node has the same support as the items below it.

Fig. 2 The recorded global FP-tree.

In Fig. 2(a), it notes p in the record of item m because  item m has the same support as prefix item p in the path fcamp. Similarly, item c has a record a in its node. In the path cbp, it notes p in the node b and notes pb in the node c. The conditional pattern base of prefix item p has fcam:2 and cb:1 to create the conditional FP-tree shown in Fig. 3(a). The conditional FP-tree only contains frequent items and it also has a header table. We can see only one path in this tree. Following the bottom-up order in the header table, we first make item m as a prefix item, and find what items are above it. At this time, we note the  record in each node of this tree, as shown in Fig. 3(a). It can find a frequent closed itemset cfamp:2 in this tree with prefix m. Then it makes item a as a prefix. Because it has an item m in its record of the only one node, one knows it has been mined with prefix m. It won?t generate itemsets with prefix pa. Similarly, the prefix pf won?t be used neither. Finally, item c is the last item and its record is empty. So we can find cp:3 as a frequent closed itemset. Because c is the last item and the support of c is equal to the support of p, p:3 is not a closed itemset. At this time, all frequent closed itemsets with prefix p have been found.

Fig. 3 The conditional FP-tree.

Then it makes item m as a prefix of the global FP-tree.

When searching the linked node of item m, it notes the records for nodes with item m having no child. There are two paths with prefix m, fcam and fcabm. In Fig. 2(b), the node m in path fcam has a child, so it is unnecessary to note records in this path. In path fcabm, it notes m in node b, notes a in node c and adds m to node c. The conditional pattern base containing fca:2/p and fcab:1 can form a conditional FP-tree as shown in Fig. 3(b). Then note the records in the tree when it makes item a as a prefix item.

It can find a frequent closed itemset fcam:3, and itemsets with prefix items c and m are not generated. Because f is the last item and the support of f is equal to the support of m, m:3 is not a closed itemset. At this time, all frequent closed itemsets with prefix m have been found.

The third item b is used as a prefix item. It can get three paths, fcab, fb and cb. Each one of the paths fcab and cb has a child and the supports in path fb are not the same, so it is unnecessary to note records of the tree. The conditional pattern base, fca:1/m, f:1 and c:1/p, builds the conditional FP-tree as shown in Fig. 3(c). According to the header table, item c is the first prefix item. It is unnecessary to note records here because no support is the same in each path. It can find two paths fc:1 with record m and c:1 with record p. Only item c is frequent         and the records of two paths are not the same, so cb:2 is a frequent closed itemset. Since f is the last item of the header table and it has no record, fb:2 is a frequent closed itemset. Because f is the last item and the support of f is not equal to the support of b, b:3 is a frequent closed itemset. At this time, all frequent closed itemsets with prefix b have been found.

Because prefix item a has only one path and it has a record m, it is unnecessary to create the conditional FP-tree with prefix item a. The prefix a will not generate any closed itemset.

For prefix item c, it has two paths, fc and c. The conditional pattern base, f:3/am, and the other path have nothing, so it is unnecessary to create the conditional FP-tree for prefix item c with item f. And c:4 is a frequent closed itemset.

Finally, the last item f has no record, so f:4 is a frequent closed itemset. At this time, the mining process is completed.

E. Parallel Method CIMNC can be used in a parallel manner to mine  frequent closed itemsets because it can generate frequent closed itemsets directly in each node. Due to the paper length, we won?t discuss our parallel method here.

4. Experimental results  A. Environment and Datasets Our method uses the horizontal database and FP-tree  to find closed itemsets. CLOSET+ and FPclose are two popular algorithms that are appropriate to compare with our method. We know the purpose of using FP-array in FPclose is to accelerate the generation of FP-tree. Since arrays take up a large amount of space, FPclose is not a good candidate for comparison. Therefore, CLOSET+ is the most suitable one.

The CIMNC algorithm was implemented with Java programming language. In order to compare it with the CLOSET+ algorithm, we also implemented CLOSET+ in Java. Our experiments were performed on a personal computer of Intel Pentium 4 640 series, 3.2GHZ processor and DDR2 533MHz 2GB main memory. The experiments? datasets are produced by the IBM dataset generator [17].

B. Experiment Result and Discussion The dataset T10I4D10K was used to run two  algorithms CIMNC and CLOSET+. The results of setting the average sizes of the potentially large itemset as 4 with the minimum supports from 0.4% to 2% are  shown in Fig. 4(a) while the results for the minimum supports from 2% to 20% are shown in Fig 6(b).

T10I4D10K   0.4 0.8 1.2 1.6 2  Minimum Support(%)  Ti m  e( s)  CLOSET+ CIMNC   (a)  T10I4D10K  0.2 0.4 0.6 0.8  1.2 1.4  2 5 10 15 20  Minimum Support(%) Ti  m e(  s)  CLOSET+ CIMNC   (b)  Fig. 4 The experiment result on T10I4D10K. (a) With smaller min_sup. (b) With larger min_sup.

In Fig. 4(a), one can see the execution time of our  method is better than CLOSET+. When the minimum support is lower, the performance of our method gets better than CLOSET+. Because the number of closed itemset candidates is very big when the minimum support is very low, CLOSET+ needs more time to compare a lot of itemsets for closure checking. Since CIMNC does not need to compare many itemsets, it can get better performance in lower minimum supports.

When the support increases, the number of candidates becomes smaller. Then the run time of CLOSET+ approaches the run time of CIMNC.

In Fig. 4(b), one can see the performance of CLOSET+ is better than CIMNC when the minimum support is near 10%. Because the number of candidates is very small and most itemsets are 1-itemset and 2-itemset, the time for closure checking becomes much less. Since CIMNC still needs to generate the records, it would take a little more time than CLOSET+. We know the time of generating records is based on the size of tree. Since the tree becomes smaller as the minimum support is larger than 10%, the performance of CIMNC is very close to CLOSET+.

T10I4D10K      0.4 0.8 1.2 1.6 2 5 10 15 20  Minimum Support(%)  M em  or y(  M B)  CLOSET+ CIMNC   Fig. 5 Memory consumption on T10I4D10K.

Fig. 5 shows the memory consumption on  T10I4D10K. The performance of CIMNC is 1.3 times better than CLOSET+ on average. Because CIMNC does not need to store candidates, it takes less memory space.

Although noting records take up some memory space, it is still less than the space of storing all candidates.

Besides, the storage used to store candidates may be larger than the original FP-tree in the worst case. Since not every record needs to note items, CIMNC takes less space than CLOSET+. In this figure, the line drops fast when the minimum support is from 5 to 10 and 15 to 20.

This is because that the frequent items are reduced quickly, so the tree becomes very small. When the minimum support reaches 20, the required memory space drops to near 0. The reason is that the number of frequent items becomes very small and only frequent 1-itemsets can be found, such that less memory space is needed for the FP-tree.

5. Conclusions and future work In this paper, an efficient approach called CIMNC is  proposed to mine frequent closed itemsets without the need of closure checking. CIMNC has several advantages over other approaches. First, it is not necessary to do closure checking. However, it still can achieve the effect of subset pruning and reducing the number of conditional FP-trees. Because CIMNC doesn?t generate any candidates, it is not necessary to store itemsets in the memory. It can output frequent closed itemsets directly and is suitable for parallel mining.

After implementing the CIMNC algorithm, we have studied its performance to compare with CLOSET+ for large databases. The results of performance study show that our method outperforms this well-known approach.

Further improvements on the record mode are in the list of our future work. A simple format will be used to  note the records to avoid keeping a long string in the record, and to check if they have the same items quickly.

Acknowledgement  This work was supported by the National Science Council, Taiwan, under Grant No. NSC95-2221-E-035- 068-MY3.

