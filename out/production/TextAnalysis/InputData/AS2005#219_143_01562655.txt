Utilize Fuzzy Data Mining to Find the Travel Pattern of Browsers

Abstract  With the traveling records of browsers, one can  analyze the preference of pages, further understand the  demands of consumers, and promote the advertising  and marketing. In this study, we use Maximum  Forward Reference (MFR) algorithm to find the travel  pattern of browsers from web logs. Simultaneously,  experts are asked to evaluate the fuzzy importance  weightings for different webs. At last, we employ fuzzy  data mining technique that combines Apriori algorithm  with fuzzy weights to determine the association rules.

From the yielded association rules, one can be  accurately aware of the information consumers need  and which webs they prefer. This is important to  governmental institutions and enterprises. Enterprises  can find the commercial opportunities and improve the  design of webs by means of this study. Governmental  institutions can realize the needs of people from the  obtained association rules, make the promotion of  policy more efficiently, and provide better service  quality.

Keywords: Data Mining, Maximum Forward  Reference, Fuzzy set theory.

1. Introduction  It is difficult to design a website that meets the need  of consumers? browsing habits. There are some  problems existing in the present webs, for example, the  contents, frame and browsing path of webs are all  decided according to the designers? willing not the  browsing habits of most uses. In this study, we use the  records of browsing to further understand the  interesting and demand of customers and then feedback  it to the decision-makers to improve the web design.

From the association rule of data mining we can know  what the most users need, and which pages users prefer.

To the governmental institutions and enterprises, it?s  the very important information, because governmental  institutions can better understand the need of people  and take more convenient measurement, and  enterprises can know how to get more commercial  chances.

This paper applied fuzzy set theory on exports  weights and combined data mining algorithms to  achieve the following purposes:  (1)Finding the association rule of web pages the  users prefer from the records of browsing;  (2)Using the above association rule to improve the  design of web to gain more chances of trading;  (3)Improve the governmental institutions? webs to  make more convenience for people to get useful  information.

2. Related Work  2.1  Data mining  Data mining combines the statistics and artificial  intelligence to find out the rules that contained in the  data, letters, and figures and so on by sorting and  analyzing.

There are many methods of data mining including  Classification, Estimation, Prediction, Affinity  grouping, Clustering and Description. Among these,  Affinity grouping can discover the high frequency  pattern, and discover which things appeared frequently  and simultaneously.

2.2 Fuzzy Set Theory  Fuzzy Set Theory was firstly presented by Professor  L.A.Zadeh in California University in 1965.[13] It  transforms the meaning and spoken description into  fuzzy set instead of general set, then studies and deals  with subjective and undefined data with membership  functions, quantify the data and then transform it into  The Project Supported by Zhejiang Provincial Science Foundation of China (601081)  and Key Lab of Information Processes of Jiangsu Province(Suzhou University)     useful information through systemic fuzzy  operation.[14]  According to the principle of fuzzy set intersection,  some scholars put forward min-operand algorithm [2]  in order to find out the mini among several triangle  fuzzy number. But the purpose of the max-operand  algorithm is finding out the max among the several  triangle fuzzy number. In this paper we find out the  min-supported items with fuzzy set max-operand  operation, and gather these filtered items as a large  item sets. Next we get the large items intersection by  combining each two large items with min-operand, and  then take the results as the candidate item sets.

2.3 Maximum Forward Reference  When the user wants to find the interesting  information, he or she will shift one page to another  page, and if the user backs the page, we suppose that he  or she is just for convenience not for browsing. So we  just mine the Forward Reference Sequence of Access  Patterns, and we take the back browsing as the  finishing of Forward Reference Path, and we call this  Forward Reference Sequence as Maximum Forward  Reference. [4][5][8][9][10]  When uses browse the web, the browsing path will  be kept on the web log in the server. We can analyze  uses? action on the website through the browsing path.

And also we can mine the Maximum Forward  Reference from web logs.

3. Methods and steps  There are two parts in the Apriori Algorithm; the  first part is scanning data base to find out the support of  every item then filtering the Minimum support item  according the given Minimum support; the second one  is setting Minimum Confidence, the main purpose is  checking the association rule. We use fuzzy max-  operand to compare with two triangle fuzzy items on  filtering the above Minimum support and Minimum  confidence.

On the process of filtering large item sets in Apriori,  we must combine each two low power large itemsets to  generate high power candidate itemsets. The process of  combination is finding the intersection of two triangle  fuzzy number, so we use fuzzy min-operand to deal  with the intersection to get a new one. The study bases  on Apriori algorithm of data mining technology, and  uses Maximum Forward Reference to analyze the  browsing path to take out the pages users are most  interested in, then combines Fuzzy Set Theory, adds  the fuzzy weight, calculates the weight between each  two candidate item sets with fuzzy min-operand just  like using exports weight dealing with triangle fuzzy  items, at last, compares the items with min-support and  min-confidence with fuzzy max-operand.

Now we can find out the association rule of each  pages of web. To the governmental institutions, it can  advance the performance of serving; to the enterprises,  it can improve the design of web and provide more  useful information according to the browsing action  and the interesting information of users.

The process of this web mining including: coding,  extracting original data, giving weight by exports,  transforming the pages into triangle fuzzy numbers  according to the exports weight, calculating the support,  giving minimum support, filtering candidate itemsets to  get large itemset, combining the large itemsets as  candidate itemsets, giving minimum confidence,  checking minimum confidence and minimum support,  then forming the association rule.

4. Example  According to the above algorithm, we take the web  logs of one web sever as example to explicate the  whole steps of generating the association rule.

Step 1: Coding  There are seventeen pages in our website,  default.htm, product.htm, enterprise_intro.htm and so  on. We code A, B, C?Q as the page of the above  seventeen pages.

Step 2: Extracting original data  In the web log of server, some user?s browsing path  is {A,B,C,B,H,B,C,D,C,F,C,D,E,D,C,G,C,B,H,I,J,A,K,  L,M,L,N,L,P,O,Q}. We get the Maximum Forward  Reference Sequence in the browsing path in the table 1.

Table 1 the MFReference Sequence of the browsing path  NO The results of mining  1 ABC  2 ABH  3 ABCD  4 ABCF  5 ABCDE  6 ABCD  7 ABCG  8 ABC  9 ABHIJ  10 AKLM  11 AKLN  12 AKLPOQ     We sort all users? Maximum Forward Reference  Sequence with above method and store them in the  database.

Step 3: Giving weight by exports  We ask exports to evaluate the website, and  according to the weight we divide the pages into five  groups, very important, important, common,  unimportant and extraordinary unimportant, just  shown in table 2.

Table 2 the weight of pages  Page Weight The NO. of page  very important A,B,C,H,K,L  important D,E,I,N  common F,G  unimportant J,M  extraordinary unimportant O,P,Q  Step 4: Transforming the pages into triangle fuzzy  numbers according to the exports weight  We transform the pages into triangle fuzzy numbers  according to the exports weight as table 3.

Table 3 the triangle fuzzy number of pages? weight  Page Weight Triangle Fuzzy Number  very important (0.75,1,1)  important (0.5,0.75,1)  common (0.25,0.5,0.75)  unimportant (0,0.25,0.5)  extraordinary  unimportant  (0,0,0.25)  Step 5: Calculating the support  We calculate every page?s support according to the  Maximum Forward Reference Sequence in table 1.

Firstly, we count up the appearing times of every page,  the result as in table 4.

Table 4 the appearing times of pages  Pages  Time  s  Pages  Time  s  A 12 I 1  B 9 J 1  C 7 K 3  D 3 L 3  E 1 M 1  F 1 N 1  G 1 O 1  H 2 P 1  Q 1  Secondly, we calculate the proportion of the  appearing times of every page in all records, and  multiply the corresponding fuzzy weight, the result is  the fuzzy support of every page. The process of  transforming is in the table 5.

Table 5 transforming the item support into fuzzy  support  Ite  m  The  proportion of  item  appearing  times  Fuzzy  weight  Fuzzy  support(SX)  A 12/12=1 (0.75,1,1) (0.75,1,1)  B 9/12=0.75 (0.75,1,1) (0.563,0.75,0.75)  C 7/12=0.583 (0.75,1,1) (0.437,0.583,0.583)  D 3/12=0.25 (0.5,0.75,1) (0.125,0.188,0.25)  E 1/12=0.083 (0.5,0.75,1) (0.042,0.062,0.083)  F 1/12=0.083 (0.25,0.5,0.75) (0.02,0.042,0.062)  G 1/12=0.083 (0.25,0.5,0.75) (0.02,0.042,0.062)  H 2/12=0.167 (0.75,1,1) (0.125,0.167,0.167)  I 1/12=0.083 (0.5,0.75,1) (0.042,0.062,0.083)  J 1/12=0.083 (0,0.25,0.5) (0,0.02,0.042)  K 3/12=0.25 (0.75,1,1) (0.188,0.25,0.25)  L 3/12=0.25 (0.75,1,1) (0.188,0.25,0.25)  M 1/12=0.083 (0,0.25,0.5) (0,0.02,0.042)  N 1/12=0.083 (0.5,0.75,1) (0.042,0.062,0.083)  O 1/12=0.083 (0,0,0.25) (0,0,0.02)  P 1/12=0.083 (0,0,0.25) (0,0,0.02)  Q 1/12=0.083 (0,0,0.25) (0,0,0.02)  Step 6: Giving the Minimum Support  Here we suppose the percentage of Minimum Support  is 30%, and multiply it by the important triangle fuzzy  number (0.5 0.75 1) , the result is the Minimum  Support (SMIN), so  SMIN=30 ? (0.5,0.75,1) (0.15,0.225,0.3).

Step 7: Filtering the candidate itemsets to get the  large itemset  We take the max-operand operation of the fuzzy  support from step5 and the minimum support from  step 6 to get the minimum support filtered items and  gather them as large itemsets. We take page A as  example to explain the process of the filtering. From  step 5, we can know the support of page A,  SA=(0.75,1,1), the minimum support  SMIN=(0.15,0.225,0.3), and according to the triangle  fuzzy operation we can know SA SMIN,.

From the above example we can know that page A  can become one of the large itemsets by minimum  support filtering. According to the above process of  calculating, we can get 1-large itemset is {A, B, C}.

Step 8: Combining the large itemsets as candidate  itemsets     We can get the intersection of large items by  combining the each two large items with triangle fuzzy  min-operand. We call the result of candidate as 1-  large itemset.    We take the page A and page B as  examples, the intersection of SA and SB is I,  I(a ,b ,c)=(0.563,0.75,0.75).

According to the above operation, we can get 2-  Candidate itemset by taking triangle fuzzy min-  operand operation of each two large items of 1-large  itemset. Then repeat the step 7and step 8 until no other  candidate itemsets can be generated; we can get all  combination of large items and support shown in table  6.

Table 6 the combination and support of large items  Single large item  Support A (0.75,1,1)  B (0.563,0.75,0.75)  C (0.437,0.583,0.583)  The combination  of  two large items  Support  AB (0.563,0.75,0.75)  AC (0.437,0.583,0.583)  BC (0.437,0.574,0.583)  The combination  of  three large items  Support  ABC (0.437,0.574,0.583)  Step 9: Giving the Minimum Confidence  Here we suppose the percentage of minimum  confidence is 40%, and multiply it by the important  triangle fuzzy number (0.5, 0.75 1) , the result is the  minimum confidence, so CMIN=40 ? (0.5,0.75,1)  (0.2,0.3,0.4).

Step 10: Checking the confidence to get the  association  During the course of checking, we use conditional  probability C=Prob(Y|X)=P(X Y)/P(X). If the  probability of Y minimum confidence on the  condition of X, an association rule is generated which  accords with minimum confidence. If there is an  association rule exists between X and Y, it can be  expressed as If X Then Y, means that if X appeared, Y  will appear too. In the operation results of our example,  we get the combination of {AB,AC,BC,ABC}, so  there are five kinds of association rule.

IF A then B; IF A then C; IF B then C,  IF A then B and C; IF A and B then C,  Among the above association rules, take IF A then  B as example, on the condition of A, the probability of  B is:  Prob(B|A)=P(A B)/P(A)=9/12=0.75  Then we multiply the Prob(B|A)=0.75 by the  triangle fuzzy number of the intersection of A and B  calculated by fuzzy minimum operator:  0.75? (0.563,0.75,0.75)=(0.422,0.5625,0.5625)  So we get the confidence of rule IF A then B is:  (0.422,0.5625,0.5625)  We separately calculate the conditional probability  and confidence of other combinations and checking  them with the minimum confidence supposed in step 9.

We use fuzzy maximum operator to check them, firstly,  we get the two maximum triangle numbers, secondly,  compare the similitude between maximum and triangle  fuzzy numbers. The results are shown in the table 7.

Table 7 the possible association rules and its  confidence  A sso  ciatio n  R u  le  C o  n d  itio n  al  P ro  b ab  ility   C o  n fid  en ce  M in  im u  m   C o  n fid  en ce  E x  istin g  asso ciatio  n   ru le  O r n  o t  IF A then  B 0.75  (0.422,0.563,0.563  )  (0.2,0.3,0.4  ) Yes  IF A then  C 0.583 (0.255,0.34,0.34)  (0.2,0.3,0.4  ) No  IF B then  C 0.778 (0.34,0.447,0.454) (0.2,0.3,0.4 Yes  IF A then  B and C 0.583 (0.255,0.335,0.34)  (0.2,0.3,0.4  ) No  IF A and  B then C 0.778 (0.34,0.447,0.454)  (0.2,0.3,0.4  ) Yes  In this example we finally get the following three  association rules:  IF A then B; IF B then C; IF A and B then C  We take ?IF A then B? as an example, this rule  means that if user browses page A, he or she will  browse page B probably. , on the other words, it means  that the relation between page A and page B is very  close. To the users, there are useful information  existing on page A and page B, so the probability of  continuing visiting on page A and page B is very high.

To the enterprises, if they know the rule, they must  strengthen the convenience between page A and page B,  in order to make more convenience for users.

5. Conclusion  If we want to run enterprises web and governmental  institution web successfully, we must know the demand  of clients. The study uses web logs in the server,  present a feasible fuzzy data mining approach, analyzes  the interests and the habits if users, and helps the  decision-makers to improve the webs. The process of  web mining presented here includes the following steps:  coding, extracting original data, giving weight by     exports, transforming the pages into triangle fuzzy  numbers according to the exports weight, calculating  the support, giving minimum support, filtering  candidate itemsets to get large itemset, combining the  large itemsets as candidate itemsets, giving minimum  confidence, checking minimum confidence and  minimum support, then forming the association rule.

6. References  [1] Berry, J. A. Michael and S. Linoff Gordon, ?Data  Mining Techniques: for marketing, sales and customer  support,? John Wiley & Sons,Inc.,1997.

[2] T. N. Chuang and J. Y. Kung, ?A new approach for  the fuzzy shortest path problem Department of   on Fuzzy Systems and Knowledge Discovery  (FSKD'02), vol. 1, pp. 381-384, Nov. 18-22, Orchid  Country Club, Singapore,2002.

[3] M. C. Drott, ?Using Web Logs to Improve Site  Design,? Proceedings on the Sixteenth Annual   pp.43-50, 1998.

[4] M. N. Garofalakis, R. Rastogi, S. Seshadri, K. Shim,  ?Data Mining and the Web: Past, Present and Future,?  Proceedings of the second international workshop on  Web information and data management, pp.43-47,1999.

[5] Han, J. Pei, J. Mortazavi?asl B ., Zhu, H. , ?Mining  Access Patterns Efficiently From Web Logs,? Proc.

2000 Pacific-Asia Conf. On Knowledge Discovery and  Data Mining(PAKDD?00), Kyoto, Japan, April 2000.

[6] Jiawei, Han, Micheline Kamber, ?Data mining  concepts and techniques,? Morgan Kaufmann  Publishers,2001.

[7] J. M. Mendel, Fuzzy logic systems for engineering:  a tutorial, Proceedings of the IEEE, 83 pp.345-  377,1995.

[8] M.-S. Chen, J.Han, P.S. Yu, ?Data Mining : An  Overview from a Database Perspective?, IEEE  Transactions on Knowledge and Data Engineering,  Vol.8, No.6, pp.866-883, 1996.

[9] M.-S. Chen, J.S. Park, P.S. Yu, ?Data Mining for  Path Traversal Patterns in a Web Environment?, IEEE  Proceeding of the 16 th  ICDCS, pp.385-392, 1996.

[10] M.-S. Chen, J.S. Park, P.S. Yu, ?Efficient Data  Mining for Path Traversal Patterns?, IEEE  Transactions on Knowledge and Data Engineering,  Vol.10, No.2, pp.209-221, 1998.

[11] Woon, Y. T., Jacobsen, M., Hector, G.. M., U.

Dayal, ?From User Access Patterns to Dynamic  Hypertext Linking," Fifth International World Wide  Web Conference, Paris, France, 1996.

[12] X. Ye, J. A. Keane. ?Mining Association Rules  with Composite Items?,Systems, Man, and Cybernetics.

Computational Cybernetics and Simulation. IEEE   [13] L. A. Zadeh, ?Fuzzy Sets?, Information and  Control, Vol.8, pp. 338-353. 1965.

[14] L. A. Zadeh, ?The concept of a linguistic variable and its  application to approximate reasoning, ? Information Science,  Vol. 8. 199-249 (I), 301-357 (II),1975.

