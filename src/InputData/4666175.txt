A Heuristic Approach for Fast Mining Association Rules in Transportation  System

Abstract   This paper proposes a heuristic algorithm for fast mining association rules by multidimensional scaling (MDS). It takes the similarity measurements as the MDS proximities and develops a practical MDS model to generate decentralized configuration of points that represent the stops on vehicle routes. This algorithm extends the SMACOF algorithm by the steps of grouping and join. The experiments show that the novel algorithm has much higher efficiency than the Apriori algorithm especially when mining association rules of long patterns in transportation system.

1. Introduction   Association rules mining is a significant and thriving research field in data mining and knowledge discovery. It finds interesting relationships among itemsets in a given set of data items. The most influential algorithm for mining association rules is the Apriori algorithm proposed by Agrawal et al. (1994). It employs the iterative approach on each level which searches for frequent k- itemsets from frequent (k-1)-itemsets. Two major steps of the Apriori algorithm are join and prune where the Apriori anti-monotone property is used. Although this classical algorithm can discover all association rules under certain support, it has two pitfalls: one is the generation of huge candidate itemsets in the case of large database; the other is the repetitive scans of database.

Many researches on the variations of the Apriori algorithm have been carried out to improve its efficiency in the literature (Han et al., 2000). The hash based technique produces smaller candidate itemsets which is particularly effective on reducing the quantities of candidate 2-itemsets (Park et al., 1995). The transaction compression and scan reduction techniques are developed to decrease the size of transaction database to be scanned and the number of database scans (Han et al., 1995; Park et al., 1995). The variations of the Apriori algorithm also  involve data partitioning (Savasere et al., 1995), data sampling (Toivonen, 1996), dynamic itemset counting (Brin et al., 1997), etc. Moreover, approaches such as matrix, probability and parallel computing are applied to achieve better performance (Chen et al., 2003; Ye et al., 2006).

The applications of association rules mining have covered a wide range of fields, such as business transactions, etc. With the rise of geographic information system for transportation (GIS-T), the demands for data mining in transportation networks increase rapidly. One characteristic of mining association rules in transportation system is that the number of data item is large and the discovered rules are usually in long patterns. In other words, the vertical dimension of data item is high and the level of found rules is also high due to the large amount of nodes and arcs of transportation networks. For example, mining association rules of traffic flows in an urban area to examine congestions on road sections always includes the flow information on several hundred crossing points.

Moreover, mining association rules of trip overlapping provides benefits for the promising car pooling service.

This type of application again contains hundreds of trip stops which denote the data items.

Real-time transportation service and on-the-road logistics optimization with uncertainties require high efficiency in data mining. However, the Apriori algorithm is costly in mining long pattern association rules in transportation system. The amount of candidate itemsets generated from the join step of the Apriori algorithm could be very large and it will also increase the computation cost of prune step especially when mining long pattern rules in large transportation database. This paper proposes a novel MDS-H algorithm (Multidimensional Scaling Heuristic algorithm) for fast mining association rules. It is much more effective than the Apriori algorithm and can save much computational time to satisfy the needs for real-time or near real time transportation services.

The proposed MDS-H algorithm employs the methodology of multidimensional scaling which is a   DOI 10.1109/FSKD.2008.332     powerful tool for exploring and analyzing the relationships of objects. Previous research has applied the multidimensional scaling for visualization of association rules mining (Xiao et al., 1999). However, the visualized results by Xiao et al. (1999) could only provide general and rough rules from the perspectives of users and the presentation of clustering points has limits of discovering more complicated association rules. The MDS-H algorithm proposed by this paper can solve the above problem by the decentralization of points and search for long pattern rules much more effectively.

2. Methodology  2.1. Multidimensional scaling   Multidimensional scaling (MDS) is a methodology that takes the measurements of proximity pairs as inputs and represents configuration of points as distances in m- dimensional space.  This transformation is defined by a representation function f(pij) with which the configuration distances dij(X) satisfy as closely as possible. The sum of errors between f(pij) and dij(X) is called the raw stress ?r which is the most common loss function in MDS (Borg et al., 2005).

? ?= )j,i(  ijijr )]X(d)p(f[?              (1)  In function (1), pij is the proximity between object i and j. The proximity can be similarity or dissimilarity of data pair. f(pij) is the MDS model specifying how the proximities are mapped into configuration distances. X is the coordinates of points in m-dimension space and dij(X) is the Euclidean distance between point i and j.

The objective of MDS computation is to minimize the stress, such as the raw stress or stress-1 (Kruskal, 1964):  ? <  ?= ji  ijijijr ])X(d[Min)X(Min ???     (2)  In practical research, dissimilarity ?ij is usually used as a proximity measurement and weight ?ij is defined to identify the missing values of dissimilarities.

2.2. MDS-H algorithm   The MDS-H algorithm (Multidimensional Scaling Heuristic algorithm) for fast mining association rules extends the SMACOF algorithm (De Leeuw, 1977, 1988; Borg et al., 2005). The SMACOF algorithm (Scaling by Majorizing a Complicated Function) is a powerful stress minimization technique by iterative majorization.

Proximity measurements in our algorithm are derived from vertical co-occurrence of items so as to represent the degrees of association among items. A proximity value can be similarity or dissimilarity of the co-occurrence of items. For similarities, a higher score indicates that the item pair is more similar. For dissimilarities, a larger  number reveals that the items are more dissimilar.

However, if the dissimilarities are taken as the input matrix, the specific association rules are not easy to be dug out from the output configuration of the clustering points. Conversely, the similarity as proximity yields disperse configuration where more associated items are far apart. It provides better opportunity to distinguish associated items, but the similarity model still needs to be tailed to produce more regular pattern that leads to effective digging.

One special characteristic of MDS can be employed to improve this similarity MDS model. In the case of constant proximities, the optimal MDS solution in two dimensions consists of points that lie on concentric circles (De Leeuw et al., 1984). In three dimensions, the points equally spread on the surfaces of concentric spheres (Buja et al., 1994). Figure1 (a) gives an illustration of 2-D case.

(a)                                                (b)  Figure 1. (a) Two-dimensional MDS solution for constant proximities with 30 points (Borg et al., 2005); (b) Two-dimensional MDS solution for two categories of constant proximities with 30 points.

Some beneficial patterns can be inferred from the  features of constant proximities. If there are two categories of constant proximities, the points in two- dimensional MDS solution not only show the trait of concentricity, but also have the property of two groups of radius. Figure 1 (b) represents the 2-D configuration of 30 points where the constant proximities of one category are five times larger than the other. The point pairs with higher constant proximities have large radius and spread on the outer circles. Therefore, the set of points with high proximities can easily be distinguished from the lower ones.

In the MDS-H algorithm of association rules mining, a proximity value denotes the similarity measurement of co-occurrence between a pair of item vectors. Thus, the values of similarities vary much in a given database and can not be in two constant categories initially. However, note that the similarities smaller than minimum support count (defined as minsup) can be viewed equally because the itemsets with support counts lower than minsup are not frequent itemsets. In other words, similarities lower than minsup can be minified as a small constant so as to generate the distinguishable configuration where points     with this small constant lie on near concentric circles with small radiuses and points with higher similarities lie far apart on the outer circles.

The MDS model of the MDS-H algorithm can be expressed in functions (3) and (4).

? = ???= m  1a jaiaij nj,i1xxs                     (3)  ??  ? ? ?  < ??  = supminsIf1 supminsIf10s  )s(f ij  ijij ij  ?  (4)  In function (3), sij is the similarity of item i and item j.

n is the number of individual items. Suppose items are sorted in lexicographic order, then item i indicates the i-th item. m is the size of row records in a given dataset. xia denotes the existence of item i in the record of row a, value 1 for existence and value 0 otherwise. The definition of similarity represents the co-occurrence in each dimension of m-dimensional item vectors. It can also be considered as support count of item pairs. Function (4) is a transformation of similarities where the parameter ? is larger than 1 so as to magnify the similarity higher than minsup.  ? is usually 3 to 7 in order to separate the two categories of points far enough. The small constant is defined as 1 so that the points of non-frequent items could be near the origin.

The following two major steps of association rules mining are based on the decentralized output configuration of points generated by the above MDS model. One step is called the grouping; the other is the join step which is different from the Apriori algorithm.

The objective of grouping in the MDS-H algorithm is to reduce the opportunity of the Apriori?s self join among non-frequent candidate itemsets. In the output configuration X, the distances among non-frequent itemsets are small while the distances among frequent itemsets are large. The grouping takes the average distance of non-frequent item pairs where f(sij) equals to 1 as a threshold to build up groups. The points of frequent 1-itemsets within the extent of threshold distance are categorized into the same group. An itemset that contains any two items in the same group is non-frequent with high confidence. Therefore, the grouping avoids large redundant computation of the generations and judgments of non-frequent candidate itemsets in the Apriori algorithm.

The join step in our algorithm searches for a basic frequent itemset and joins one more item in the groups at each iteration of frequent level k. This basic frequent itemset is considered as a root association rule. It is searched by the descending distances (radiuses) from points of frequent 1-itemsets to the centroid of non- frequent 1-itemset points. The threshold to stop adding frequent 1-itemset points into the basic frequent itemset depends on both the variation rate of radiuses and the support count.  The joins of the basic frequent itemset and  the groups are very effective to search deep down to further level of frequent itemsets by the constraint that the items in candidate frequent itemsets are not in the same group. Therefore, this join step with the heuristic root frequent itemset and group constraints saves large volume times of database scans.

2.3. Implementation procedures   The procedures of the MDS-H algorithm are as follows: 1) Define the minimum support count as minsup. Scan  all the transaction records in the database to obtain frequent 1-itemsets L1 and non-frequent 1-itemsets NL1.

2) Calculate the similarities sij by the function (3) and perform the transformation f(sij) by the function (4) with the parameter ?=5.

3) Set the threshold of stress difference ? =10-6 and the size of output dimension as 2 or 3. Run the SMACOF algorithm and obtain the configuration X.

4) Calculate the average distance d? from the configuration X where f(sij)=1. Check the distance dij where item i and j all belong to L1.  If dij<d?, then item i and j are put in the same group. If dij>d?, then item i and j are put in different groups. Make sure that the items in groups G are not overlapped.

5) Figure out the centroid c of all points in NL1.  Check the distance dic where item i belong to L1 and c denotes the above centroid c. Sort these distances in descending order. Add item i in L1 into the basic frequent itemset one by one from the largest distance to smaller ones until the support count is lower than minsup.

6) Refine the basic frequent itemset according to the variation rate r of dic in descending order. If r>10t where t>1, then it is considered as a sharp change in r. The items before the sharp change remain in the basic frequent itemset, otherwise removed.

7) Suppose the basic frequent itemset is frequent k- itemset Lk. Join the Lk with the item in G to generate candidate frequent (k+1)-itemsets Ck+1 with the constraints that the item in G is not in the same group with items in Lk. Scan the database to obtain Lk+1.

8) k++. Perform self join of Lk to gain Ck+1 with the constraints that the k-th item of itemset i is smaller than the k-th item of itemset j and they can not be in the same group. Scan the database to obtain Lk+1. Repeat this step until Lk+1 is empty. Put out the result of Lk.

3. Experiments in transportation system   The data source of our experiments is the vehicle routes database of a third party logistics. The dataset contains 9473 records and each record denotes a vehicle route with 2 or 3 dozen stops in an urban transportation network in daily logistics. There are altogether 128 different stops (customer nodes) in 9473 routes. The task of our experiments is to search for association rules of     customer nodes in this dataset and compare the efficiency and accuracy of the MDS-H algorithm with the Apriori algorithm. The programs of the two algorithms run in the JBuilder environment and the SQL Server database.

Figure 2 compares the performance of the two algorithms under the conditions of different support levels by using the entire dataset. When the support level is high, both algorithms are less time-consuming because the number of iterations is small. However, the efficiency disparities of the two algorithms get larger as the support level falls.

The MDS-H algorithm takes near constant time to discover long pattern rules and shows much greater efficiency than the Apriori algorithm. Figure 3 (a) shows the two-dimensional MDS configuration of all 128 points with minsup=3000. Note that more than 80% of the points lie so close to the origin that they are almost overlapped as a point in this figure. The basic frequent itemset on this support level is {34, 36, 39, 88, 92, 95}. Though the item {55} satisfies the support count constraints, it is not included in the basic frequent itemset because there is a sharp change in the variation rate of radiuses. Figure 3 (b) represents a more dispersive configuration due to the smaller minsup. The MDS-H algorithm as a heuristic approach not only has the advantage of little computation time for the need of real time transportation service, but also has very high accuracy in the association rules of long pattern discovered. In the final results of the MDS-H algorithm on different support levels, the longest frequent k-itemsets Lk (one L12 when minsup =4000, one L15 when minsup =3500, one L15 when minsup =3000, and two L15s when minsup =2500) generated by the MDS-H algorithm are exactly the ones that generated by the Apriori algorithm.  A slight difference in the result is that seven L16s are discovered in the MDS-H algorithm while eight L16s are generated in the Apriori algorithm when minsup =2000. Although it is a near optimal solution when minsup gets lower, the computation time of 10 seconds in this algorithm is very attractive compared to 4382 seconds in the Apriori algorithm.

4000 3500 3000 2500 2000  minimum support count  t im e/  s  the Apriori algorithm  the MDS-H algorithm   Figure 2. Performance comparison on different support levels     (a)     (b)  Figure 3. Two-dimensional MDS configurations of 128 points with different minimum support count minsup: (a) minsup =3000; (b) minsup =2000.

Mining association rules of stops (customer nodes) in logistics routes provides beneficial supports for the decisions of vehicle routing problem (VRP) especially when the daily geographic distribution of customer nodes is uncertain but varies not much within certain traffic zones. While the VRP is a NP-hard problem, the discovered association rule of customer nodes can be utilized as an appropriate initial solution for VRP. Further searches for optimal solution of VRP can be carried on by inserting or replacing other nodes nearby.

4. Conclusions   The MDS-H algorithm proposed by this paper employs the methodology of multidimensional scaling for fast mining association rules. It develops a novel MDS model of similarities and generates distinguishable output configuration of points. The SMACOF algorithm is extended to search for high level frequent itemsets by the     steps of grouping and join.  The experiments of mining association rules of customer nodes in transportation system are performed and the results indicate that the MDS-H algorithm is much more effective than the Apriori algorithm especially in the long pattern mining.

