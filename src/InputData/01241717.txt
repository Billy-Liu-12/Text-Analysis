

Proceedings o f the  2003 IEEE Internstionel Conference on Robotics &Automation  Taipei, Taiwan, September 14-19, 1003  Trajectory Sonar Perception Richard J. Rikoski and John J. Leonard  Marine Robotics Laboratory Massachusetts Institute of Technology 77 Mass Ave., Cambridge, MA 02139  {rikoski, jleonard)@mit.edu  AbstracbThis paper describes a new data association technique for the interpretation of wide-heam sonar mea- surements. The goal is to group sets of returns that originate from the same surface of an object. We consider the case of a moving observer that obtains range and hearing mea- surements of curved and/or faceted objects with a binaural sonar operating in the specular wavelength regime. Rather than projecting sensor data into a Cartesian space before processing, we operate on a ?raw? representation in terms of range, hearing, amplitude, and time. A binary geometric constraint is applied to pairs of consecutive measurements to rule out impossible assignments. A measurement flow model is proposed for validating triples of measurements.

The performance of these techniques is illustrated via a set of experiments using a wide-beam 500 kHz binaural sonar system, demonstrating effective perceptual grouping and mapping with sonar echoes originating from a set of objects, despite the presence of navigation error.

Fig. 1. Odyssey 111 AUV with SAS sensor.



I. Introduction  Reliable, sonar based perception is crucial if robots are to perform useful tasks in the ocean. Undersea sonar data, however, is not easy to interpret. The dominant approach for undersea sonar processing is based on ?imaging?.

Undersea sonars are often designed to create as large an aperture as possible, resulting in narrow beampattems.

These beams can then be steered, either mechanically or electronically, to produce a visual representation of the scene - an image. Most interpretation is either perform manually by human operators, or automatically by image processing algorithms such as shadow detection. Common examples of imaging undersea acoustic sensors include side-scan sonars, forward-look sonars, and mechanically- scanned sonars.

This paper considers sonar interpretation in the context of an alternate framework that is not based on conven- tional imaging. Rather, we advocate a geometric approach based on the interpretation of echoes from a wide-beam sensor obtained from multiple vantage points.

We believe the geometrical, wide-beam approach to sonar is interesting for several reasons. From a scientific perspective, this model holds a closer relationship to hypothesized models of bat and dolphin echolocation [I].

Bats and dolphins demonstrate astounding feats of sonar-  based prey tracking and obstacle avoidance using wide sonar beams and adaptive sensing and motion strategies.

Mechanisms of bio1,ogical echolocation remain poorly un- derstood, however, the ?sensor design? principles at work are clearky different from typical undersea commercial sonars.

From a technical perspective, for many problems it is impossible to build a large enough aperture to allow effective imaging at desired frequencies. One motivating scenario for our work is the detection of buried mines us- ing a synthetic aperture sonar (SAS), in the generic ocean array technology sonar (GOATS) concept [7]. Figure 2 shows an example set of received signals obtained from a dual line m a y  SAS system, mounted on an Odyssey 111 AUV as shown in Figure 1. Figure 3 shows detector output for these waveforms.

Previous work in synthetic aperture sonar (SAS) pro- cessing is related to the approach taken in this paper.

However, in most work in SAS the implicit goal is to produce an ?image? of the scattered field. A difficult issue in SAS processing is to account for navigation error of the sensor [23]. Signal processing techniques used to form images rely on very accurate positioning information. Methods have been developed to extract short-term accurate position information directly from the data (e.g. using digital phase correlation analysis [71).

0-7803-7736-2/03/$17.00 02003 IEEE 963  mailto:jleonard)@mit.edu   SAS-15_6_2002_16_11, pings 1201 through 1300 1320r   z 1260 9 . 5  0 ,240  I220  ,200  10 20 30 40 50 60 70 60  range (meten)  Fig. 2. IW pings of input data for an eight-element line may. wilh pings occunng roughly three times per second. The data was acquired by an AUV operating in about 20 meters water depth. Most of the visible echoes in this image correspond to reflections from the bottom andlor sea surface.

However, there are also many echoes corresponding to objects on the sea bonorn (suppons for an undersea cable.)  1300-  1290 ~  1260-  1270 -  1260 ~  1250 ~  1240-  1230 -     t, * * * *  *  ** t  *  *  i f  * * *  2**2 f , f  x t * * * " *  2000 3000 4000 5000 6000 7000 8000 9000 10000  Fig. 3.

develop methods by an autonomous underwater vehicles (AUV) would be able to perform segmentation/perceptual grouping of this type of data.

Tokens extracled from raw data by thresholding the low-pass filtered, rectified output of a beamformer. The motivation for this paper is to     In our approach, we consider sensor navigation error as an intrinsic part of the processing. We seek to develop sonar interpretation methods that are tolerant to significant levels of navigation error.

One of the key issues in a geometrical approach to sonar data interpretation is the correspondence problem.

The goal is to associate measurements obtained from multiple vantage points with the same featurelobject in a scene. Previous approaches have considered the corre- spondence problem in conjunction with the object clas- sification and mapping problems [17]. There are several problems with this type of approach. Typically, only a very small set of models can he used (e.g. point features, planar features, cylinders of known radius). Methods that attempt joint associatiodclassificatiodmapping can encounter extreme levels of computation complexity [17], especially when navigation error is present.

In a specular wavelength regime, the received signals consist of a set of discrete echoes. For example, one early model for acoustic echo formation was presented by Freedman [SI. Basically, Freedman?s method predicts that when a sonar pulse is incident on a generally smooth but possibly faceted object, the returned waveform will be comprised of a discrete number of image pulses, which are time-delayed and attenuated replicas of the incident pulse. This simplified physical model of the sonar sensing process is based on the geometrical acoustics high-frequency approximation of acoustic scattering.

For land robotics applications, several researchers have designed sonar interpretation methods using static or scanning sonar m a y s  of various configurations. Exam- ples include work by Barshan and Kuc [Z], Bozma and Kuc [41, Kleeman and Kuc [121, Peremans et  al. (191, and Heale and Kleeman [IO]. These methods have been very successful for various tasks such as land robot nav- igation and mapping. In general, however, these methods decompose the environment into a few simple geometric primitives, such as points, planes, and cylinders. In our work, we seek to define more general methods that can apply to mapping, navigation, and detection tasks in less structured undersea environments.

In this paper we describe a technique for associating sonar echoes obtained from multiple vantage points before feature modelling is attempted. The key idea is basically one of continuity. We develop constraints on how mea- sured range and bearing can change when curved objects are observed from multiple vantage points. Flat surfaces and point objects represent limits of infinite and zero curvature.

The structure of this paper is as follows: Section I1 motivates the representation of sonar measurements in terms of ?echo trajectories? with an example from a  tank experiment. Section 111 describes the sensor and signal processing to extract returns from sonar signals.

Sections IV and V present a binary constraint and a ?measurement flow? model that, when combined together, provide a method for effective segmentation before mod- eling. Section VI illustrates the use of the segmentation technique for mapping and classification with navigation uncertainty. Finally, Section VI1 concludes the paper with a discussion of future research issues.

11. Representation  Many approaches transform data into a Cartesian frame at a very early level. For example, Figure 5 shows a Cartesian projection of a set of sonar returns obtained from 25 positions with a 500 kHz binaural sonar system in a testing tank. We believe that this representation obscures the natural temporal structure of the data, and instead advocate visualization of the data as a sequence of raw measurements tokens. These raw measurement tokens can he thought of as points in an appropriately dimensioned space. The different axes in such a representation could be range, azimuth angle, elevation angle, amplitude, and time. Figure 6 shows the same measurements with range as a function of time (sensor position). Our hypothesis is that, with this representation, the correspondence of measurements can be more easily ascertained. We believe that it is easier to find regularities [20], [21], [15] in such spaces (?measurement trajectories?), rather than by looking for structure in a Cartesian representation of the data (Figure 5 ) .

To properly take advantage of this temporal struc- ture, the robot must have a representation of where it was when it made the measurements. Towards this end, we employ techniques for concurrent mapping and localization (CML) that incorporate both temporal and spatial correlations [ZZ]. By providing the robot with an explicitly correlated history of its positions, it can properly accommodate sensor and navigation uncertainty when transforming measurement trajectories into features in world coordinates.

111. Sensor Processing  A binaural sonar [I41 was used to measure the range and hearing to targets. A binaural sonar is a simple line array with a central transmitting transducer and two receiving ?ear? transducers. Detection was performed using the method employed by Kuc [14]. First, the signal was rectified, logarithmically compressed, and low-pass     Fig. 4. Image of tank scene with triangle and cylinders  ..

* *  -.

,  c : I:  Fig. 5 .  Sonar measurements displayed in a Cartesian projection.

Detected returns are back-projected along the sensor line of site 10 create a map from time-of-flight values. The correspondence of different reNrnS is unclea.

.,i  D l l  . * I  . . . . . .

. . . .

. .  . ( . . .

. . . . - . .  .. .... : .. . t : ; ' . . * . . . .

filtered to yield the filtered log-envelope. Then, the signal was thresholded. Upcrossings that were preceded by a period without upcrossings were used to determine the times of flight (TOFs) for the left and right sensors, denoted Ti and T,. Correspondence between sensors was found by constraining the difference in TOFs to be less than 2Dfc, where 2 0  is the separation between the sensors and c is the speed of sound.

Using Ti and T,, ranges and bearings were determined as in [14]:  Using the above approach, the raw waveform is reduced to a set of measurement tokens, with each token being a range and bearing measurement.



IV. A Binary Constraint  Assuming the robot has measurement tokens, the next step is rule out impossible correspondences. This step attempts to determine whether two measurements could be paired using only geometric ,constraints. This is anal- ogous to the binary constraints employed in visual object recognition [9].

Previous work in robotics, such as Barshan and Kuc 121, has considered the design of novel array con- figurations to perform classification of different feature types, such as comers vs. planes. Rather than considering a finite set of feature types, we seek to associate mea- surements that originate from the same object for a more general object model (i.e., curves), before classification is performed.

The key issue is the relationship between the number of degrees of freedom of the unknown feature vs. the the number of degrees of freedom that a e  constrained by the sensor measurement. We consider a two dimensional en- vironment, and a sonar which provides range and bearing measurements of objects. We denote the sensory degrees of freedom by m, and the number of degrees of freedom of the feature by n.

We consider the case of measuring curved objects in a two-dimensional environment, in a specular wavelength regime. In such an environment, with each sonar measure- ment we can associate a "contact point" (x, y) and a local curvature p .  We designate the local center of curvature as (xc,yc). Points can be represented by 'the limiting case when p = 0. Planes are the limiting case when p + m.

With range and angle measurements from a single loca- tion only, curvature cannot he estimated; the feature state is only pmially observable from a single measurement.

The robot can only use the two geometric degrees of freedom, so ml = 2, and n = 3.

A second measurement with m2 degrees of freedom must lie in some region of the ma-dimensional measure- ment space. How well the second measurement can be predicted depends on n - ml. If n - ml = 0, then a second measurement of the feature from a new location can he fully predicted.

If n - ml > 0, there are n - mi unconstrained degrees of freedom. A second measurement from a new location cannot be fully predicted. For this case, if ma < n -ml,  the number of unconstrained degrees of freedom exceeds the number of degrees of second measurement, and no strong constraints can be imposed on it (exempting special circumstances, such as a stationary robot in a static environment). However, if ms > n - mi, or n < ml+mz, then the second measurement can he constrained to lie upon some function in measurement space. If it is assumed that m1 = mz = m, then if m < n < Zm, given a prior measurement it is possible to predict some function that a second measurement must lie on.

For the most general case, if (k - l )m  < n < km, then a minimum of k - 1 measurements are needed to find a constraint function for the kth measurement of a feature. In general, to avoid a combinatorial explosion, it is preferable to design a sensor such that 2m > n.

We now consider the application of these general principles to the case of a binaural sensor in a 2-D environment with curved objects. Given an initial robot position, an initial range and bearing measurement to a surface, and a second robot position, a pair-wise constraint test can be applied as follows. p i s  the unknown variable in this 2D analysis. First, the state of the circle is calculated as a function of the unknown variable p:  Xc(p)  = Xt.1 + (T i  + P )  COS(& + 01) (3)  Y&) = yT1 + (TI + P )  sin(& + Q I )  (4) Then, a predicted measurement is made using  (.c(P), Y c ( P ) , P ) :  t a b )  = J ( z c  - z,# + (Yc - Y d 2  - P ( 5 )  1 - 0 2  (6) & ( p )  = a r c t m ( L  Y - Y 7 2 Xc - XP2  assuming that rC does not equal zr2.

value it is a function of the unknown variable: The innovation is calculated, hut instead of having a  The Mahalanobis distance also becomes a function of the unknown variable p.

Y(P) = v(P)rs(P)- iv(P)  ( 8 ) If the minimum value of ~ ( p )  is below an appropriate  threshold, the robot cannot d e  out a possible correspon- dence between two measurements. At this stage, the robot is not trying to accurately assign correspondence, it is merely trying to eliminate the most unlikely correspon- dences.

If objects are assumed to be locally curved, then sequential observations of such objects can utilize this curvature constraint.



V. A Measurement Flow Model  Although the binary constraint from the previous sec- tion can rule out some correspondences, it does not yield very good results on its own. To improve its performance, its output is passed to a function which tests threesomes of measurements.

From a Lagrangian perspective, a measurement can be predicted as a Taylor series expansion of substantial derivatives. (This is similar to the derivation for optical flow [ill).

DT At2 D z ~ Dt 2! Dt2 T i  = To +At- + -- + h.0.t. (9)  (10) D(Y Dt  ( ~ 1  = (YO + At- + h a t .

In the above example, we assume a two dimensional environment, where T is the measured range, and (Y is the measured hearing. The first and second substantial derivatives are defined as [181:  Assuming a locally curved feature with an unknown curvature p and an unknown center of curvature (xC, yc), the measurement model is:     -x- -x + V A t  cos(8)- y y + V a t  sin(8) v - v+vat e e + s e  -v_ v i s e  .

8 - O+eAt  xc - x - -  =-cos(O+a) (IS) ar - -  ax Jcxc - XI2 + (Y. - Y)2  (14)  Assuming a static feature and a water column with = 0, the first substantial constant properties, such that  derivative in range can be reduced to:  Similarly, the second substantial derivative can be shown to be:  (17) D2r D C I - = Vsin(a)- - Vcos(a) .

Dt2 Dt  From the binary constraint, there exist pairs of mea- surements which could have originated from a single object. When three measurements are found which are jointly compatible from a binary perspective (ie pass three binary tests), the above constraint is used to test all three measurements together.

Stating with three measurements (TO,CYO), ( T ~ , c Y I ) .

and ( T Z , ~ Z ) ,  a parabola is fitted in range to find the first and second substantial derivative:  t; - 2tltZ + Z t O t l  - t; to - ti T 2  ( to  - tl)(tO - t Z ) ( t Z  - tdT ?  + ( t z  - tl)(tO - t z )  Using least squares, the slope of the three bearing measurements is found:  This leads to a hypothesis test of the form  If each measurement in a threesome exists in no other threesomes, that threesome initializes a trajectory.

While [9] maintains multiple hypotheses, this implemen- tation eliminates any hypothesis at this stage with any ambiguity, to limit hypothesis growth. Future implemen- tations will mainlain niure hypotheses, but will also have a more advanced sensor which uses spectral information for pruning.

Vi. Experimental Results  Once a measurement trajectory has been extracted, the data is used for concurrent mapping and localization using methods presented in 1221, including consistency testing with the spatiotemporal Mahalanobis distance, curvature estimation, multiple vantage point initialization, and batch update, as in [22]. In this section, we illustrate the extraction of trajectories and their use for CML for two experiments conducted in a testing tank with a binaural sonar mounted on the robotic gantry shown in Figure 4.

The data for experiment I is shown above in Figures 5 and 6. In this experiment, the sensor moved past a triangular target and two point objects (fishing bobbers).

The side of the triangle was mapped, and the two fishing bobbers were tracked and mapped, as shown in Figure 8).

The data for experiment 2 is shown in Figures 9 and IO. This experiment was fully ?autonomous?, in the sense that the desired sensor motion was computed online in response to the sensor data. The robot adaptively fixated on a cylinder using a reactive sensing strategy [ 5 ] ,  [6].

After detecting the cylinder, the sensor drove toward it and began to circle it, while periodically scanning backwards to map two point objects located behind it. The extracted measurement trajectories are shown in Figure 11 and the The algorithm concurrently estimated the curvature and center position of the cylinder, the (x, y) positions of the point objects, and the sensor trajectory (Figure 12).

ViI. Conclusion  Using geometric and dynamic constraints, it is possible to make strong statements ahout corresvondence without -  (2to - 6, - tz)ao + ( z t ,  - t o  - t z )a l  + ( I t z  - t o  - t,)a2 knowing what type of feature is being observed. Com- putational issues associated with a brute-force search for correspondence are circumvented. The method has been successfully applied for data segmentation. Scenes that  Da - -- Dt q t ;  + t :  + t ;  - t o t 1  - to t2  - t l t 2 )  (20)     .-. I  . . .

. .  . .  . . . . . . .  . . . .  . .  . . . . .  . . .  . .  . .  . . .  . . . . .  . . . . . . . . .  . . .  . . .  . . . . . .  . . . .

?.

. .

. . .  . . .  . .  . . . . . . .  . .  . . . .  . . . .  . . . .  . . .  .:. . .  . . . . . .  . . . .  . . . . .  . . .  . . . . . . . . .  .:. . . . . . . . . . . . . . . . . . . .  ...... . . .

. .  . .

. .  .: . . .  . . . . . . . . . . . . . .  . . . .  . . . . . . . . . .  . . . . . .  . . . . . . . . . .

I I m 2s a .Io -40 -I -20 -10

I..sdlima,~ (Irnssap  Fig. 7. Extracted measusement trajectories for experiment I .  (compare with Figure 6.

Fig. 10. Range VI. time for detected r e m s  for experiment 2. Returns that are not grouped into a mjectary are discarded.

-0.5  O i I  -5 4 -8 -2 lrnMonirnl  Fig. 8. Estrmated tralectory and map for experiment 1  +*c* **+$ * * ++ + * * ?* + +++ +* + ++  +:* *++  .++ + ?6 +& - - * * *#+  +:+ * I  A*+-&s * *+  + + +  *+ 2 ++: + + + + *  +  ++  ti+ i  i f  t *  .,o 4 -2 0 1 1 6 (I 10 I2 (1 16  -,e,*  Fig. 9. Canesian projection of detected returns for experiment 2.

i -yI 4 0  .I .a -10 ,Wa*Ium,_  Fig. 11. Extracted measusemem trajectories far experiment 2.

I S  6  Fig. 12. Raw data, estimated sensor uajecton; and object locations far experiment 2.

appear complex and hard-to-interpret when considered via Cartesian projection are much easier to explain us- ing segmented echo trajectories. The system incorporates automatic fixation, which we  believe is an essential part of this type of sonar interpretation approach. This has been applied, for example, to good success in Kuc's work on object recognition [14]. The problem of balancing multiple fixations is an unexplored problem (for example, observation of known objects to provide good navigation vs. observation of unknown objects for mapping).

Future work will address (1) 3-D tracking, (2) the incorporation of spectral information, and (3) extension to rough surfaces. The primary motivating application for this work, detection of undersea buried mines via low- frequency synthetic aperture sonar, is inherently a 3-D problem. Recently, we have obtained a large amount of data at the GOATS 2002 experiment, using a synthetic aperture sonar that provides this information via use of two, eight-element arrays. The formulae presented in this paper apply in two dimensions; the three dimensional equivalents are presently being derived and tested, and initially results are very promising.

The issues of exploiting spectral information and cop- ing with rough surfaces are inter-related. The study of echo reflection from rough surfaces has been studied by Bozma and Kuc [3]. The matching of new data to previ- ously mapped features (for recognition andlor navigation purposes) is tremendously important. This paper has not addressed this issue, hut it is anticipated that the trajectory segmentation method will be a valuable tool for early processing as input to recognizing previously mapped features.

