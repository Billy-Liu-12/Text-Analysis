

Abstract   Frequent Itemsets are the sets that most likely  occurring together. This paper propose a high efficient implementation for frequent itemsets generation and Support calculation based on a systolic array architecture through only one scan of the database. A parallel item-delivering method is introduced to accelerate the generation procedure. Analysis of simulation results illustrates that our method is much more efficient than the software algorithm and other hardware implementations.

1. Introduction   At the Age of Big Data, 2.5 quintillion bytes of data[1] are created each day and a great many mining methods were introduced to analyze this data. For the flexibility of the  software implementations, most of the mining methods are software based. However processing a myriad of data in a serial software solution is not efficient as we investigate several data mining algorithms and find that there is a parallelism in these algorithms, which made it accessible to expedite the performance when implemented in parallel with the hardware.

A multitude of transactions were made each day, in supermarkets or online mobile application stores, and mining these transaction data and putting the items which occur concurrently together will help to promote a better user experience for the customs, thus it's significant to analyze the frequent itemsets. Basically, there are two fundamental algorithms for frequent patterns mining: Apriori [2] and frequent pattern growth(FP-growth) [8]. The Apriori is a classic algorithm for learning association rules and sometimes referred to as "Market Basket Analysis", its purpose is to find associations between different sets of data. The processing steps for Apriori include generating candidate itemsets, computing the support and prune  the itemsets. These steps are required to iterate multiple times for the new itemsets are generated from it's priori ones. To avoid the costly candidate set generation method in Apriori, a novel frequent-pattern tree(FP-tree) structure is proposed. Based on the  FP- tree, the FP-growth algorithm is developed, which reduces the scans over the database and is more efficient than the Apriori algorithm when implemented in a serial software-based method. Though the Apriori involves a time-consuming generation method, the parallelization in the algorithm provides the possibility to enhance the performance by exploiting a parallel method.

There are a couple of implementations of the Apriori based on the CPU method. In [10] a parallel apriori algorithm for the symmetric multiprocessing computer is proposed, based on  the trie data structure[11]. In [13] Utility Weighted Score(UW- Score) is introduced to accelerate association rule mining. With the increasing demands in the game industry, the GPU is boosting its processing capacity.

Several attempts have been made to accelerate the frequent patterns mining with a GPU method. In [14] a OpenCL based GPU-FPM is proposed with a speed-up ratio of 14.857 and a  CUDA based implementation is introduced in[13], which performs 18.65X faster than a pure CPU method.

Another commonly used reconfigurable architecture for parallel computing is the FPGA based method.

Though the GPU compensates for the lack of parallel ability of the CPU method, it has confines and is not so customizable as the FPGA. Most significantly, the FPGA requires a much lower power consumption than the CPU or GPU, which helps to cut down the cost economically and environmentally. As the modern FPGA is becoming increasingly faster and cheaper with more logic gates, we suppose that the FPGA platform will play a more essential role in the age of reconfigurable computing, so we implement a FPGA based mining method.

978-1-4673-0174-9/12/$31.00 (<;)2012 IEEE 1114 ICALlP2012     Parallel Data Mining with the Apriori Algorithm on FPGAs was proposed in [3]. For the processing method involves stalling the systolic array when a new frequent itemset is generated, several cycles are wasted. When the size of the itemset grows larger, the waste is even greater. Hardware implementation of the FP-growth algorithm was introduced in [7]. FP-growth is much more efficient than the Apriori, but still two scans over the database is required. Based on the parallel item-delivering method we proposed earlier, only one scan over the database is needed and no stall is required, so our approach is faster.

This paper is organized as follows. In Section II, we review the conception of Apriori Algorithm and Systolic Arrays. The hardware implementation is described in Section III. Result simulation is presented in Section IV and Section V concluding this work.

2. Reviews of the Apriori and Systolic Arrays   As is common in association rule mining, given a set of itemsets, the Apriori algorithm attempts to find subsets which are common to at least a minimum number C of the itemsets[5]. Frequent itemsets are extended one item at a time, which is also know as candidate generation, and the frequencies of candidates is called the supports.

Table 1. A transaction database Transaction Items 1 {1,2,3} 2 {2,3,4} 3 {3} 4 {1,2}   Take the transaction database in Table 1 for  example, assuming a support threshold of 1. When the frequent itemset generation method is called for the first time, it generates the itemsets of length 1, which is illustrated in Table 2. Itemset {1}  appeared in Transaction 1 and 4, so the support of itemset {1}  is 2.

The next step is to generate a list of all 2-pairs of the frequent items, as shown in Table 3. Itemset }2,1{  is subset of Transaction 1 and 4, so the support is 2.

Table 2. L1 Itemset Support {1} 2 {2} 3 {3} 3 {4} 1    Table 3. L2 Itemset Support {1,2} 2 {1,3} 1 {2,3} 2 {2,4} 1  {3,4} 1   The Systolic Array was first described in 1978 by  H. T. Kung and Charles E. Leiserson[6]. It is a scalable and efficient hardware architecture for parallel computing. The architecture is an arrangement of a set of interconnected and independent processors or processing elements (PEs) and data is delivered synchronously from one PE to its adjoined one, as shown in Fig 1.

Fig 1. Illustration of a 1-D Systolic Array  Unlike sending the data_in simultaneously to all the  processing units, data_in is passed from one PE to another when the PE completed processing the data and stored the result in its local register.

3. Hardware Implementation   In our implementation, each item is presented with a unique ID, which is an 8-bit number, and an itemset contains these IDs. We assume that the items in each itemset are arranged in an ascending order. For the system is based on Systolic Array architecture, all the items are placed in a linear memory, spiltting them into different itemsets by adding a itemset-end mark. There is also an all-items-end mark that is introduced, which informs a PE that the entire transaction of items have been streamed through the unit.

Table 4. Illustration of the Data organization  Itemset Item Note 1 1 254 Itemset-end mark  2 4 254 Itemset-end mark  ... ...

K 34      254 Itemset-end mark  255 All-items-end mark    A. System Architecture    Fig 2. Illustration of Our Architecture   At each clock, a item from the memory is pushed  into the system and it will be delivered through all the systolic PEs with the coming cycles. Once a PE receives an item from its previous unit, it computes the Support and generates new Frequent Itemsets if necessitated. All these calculations are implemented in hardware parallelly and could be completed in a single clock, hence the system is much more efficient than the software methods. Only one scan is required in our architecture, so the overall time for generating new Frequent Itemsets and computing Support is nT , n for the amount of items placed in the memory and T for the time consumed by a FPGA clock cycle. After the calculation, another cT  time is required to place the result to the data bus, c for the number of Frequent Itemsets. But it's negligible compared to the  items.

A fast but brute force way of frequent pattern mining in hardware is to put all the possible frequent itemsets in the PEs in advance, so no more generating procedures are needed. But it requires numerous logic cells, and it's impossible for  a FPGA chip to contain so many cells when the database is large. Our implementation takes advantage of the 'brute force way': some of the PEs are filled with the unique items in advance and others are left blank, the new frequent itemsets are generated from the prefilled PEs. For example, a database contains items ranging from 1 to 100, we can assign the first 100 PEs of the pipeline with the numbers 1 to 100. These PEs are for sure frequent itemsets. Another advantage of the implementation is that we can split the database by the initial items of the itemsets and process them concurrently.  If we split the database into 10 sub- databases and increase the number of the pipelines to 10, the system could be 10x faster than the non-split one.

B. Systolic Array Design The implementation of the PEs in the Systolic Array  is the most essential part of the system's architecture.

Two main goals of PE's are to archive:  1)  Generate new frequent itemsets(if needed)  2)  Calculate the Support   For the generating part, it involves in substantially time consuming computation when to be done with software methods.

foreach d_itemset in database//K times { foreach f_item in frequent_itemset//m times { foreach d_item in d_itemset//d times { if(d_item==f_item) index++; else if(index==size(frequent_itemset)-1) { //Generate new new new_itemset; for(i=0;i<size(f_item)-1;++i)//m times again new_itemset[i]=f_item[i]; new_itemset[size(frequent_itemset)]=d_item; } } } }  Fig 3. Pseudo code for new Frequent Itemsets Generation   In the software method, each item is picked from  the database and compared with the items from a existing frequent itemset. If a itemset from the database matches the frequent itemset until the penultimate one, a new frequent itemset will be generated. Presuming that each line of the code could be finished in a single CPU cycle, the overall cpu cycles are approximately 2Kdm .

Compared with the software procedure, our hardware implementation only requires cn +  FPGA clock cycles as mentioned in System Architecture, which is a immense enhancement towards the software solution. The parallelity in the for loops of the software method made it possible to achieve the algorithm in hardware by exploiting the systolic array architecture.

When the PE fetches a new item from the pipeline, it will compare the incoming item with the item in the local register in a indexed position. If the items match,     the index will move to the next position, as is shown in Fig 4 .

Fig 4. If the items match, the index will move to next position   When they mismatch, which means it's not a subset,  resetting the index would tackle the situation. For the followed items streamed to the PE are greater than the first item in the memory, the index will maintain zero in the subsequent cycles of this transaction.

In the implementation proposed in [2], the condition when to generate new frequent itemsets takes a long time to decide. Assuming the local memory comprises items ,54,72}{3,4,11,42 , all the fetched items match until the penultimate one, which is 54 in this example.

When the item of ID 73 arrives, a mismatch occurs, as shown in Fig 5. It's manifest that a new frequent itemset }73,54,42,11,4,3{  is necessary. There is also a stalled Systolic Array that is introduced in [2]. A stall signal is produced by the PE that detected the new frequent itemset. Unlike the items, it passed through the pipeline backward. The preceding PE fetches the stall signal and halts passing items, which spares a extra cycle for generating new frequent items.

Fig 5. Detecting a new frequent itemset in [3]     Fig 6. Illustration of new frequent itemset generation   In our approach, we proposed a parallel item- delivering method, as shown in Fig 6. The detection of a new frequent itemset is more efficient in our architecture. If the index is greater than  the number of the items in the PE, when a new item of the transaction comes, a new frequent itemset, which is a union of the preexisted items in the PE and the incoming item, should be generated. The union is delivered to the followed PEs through the Deliver_Out. If a empty PE fetches such Deliver_Out signal, it will place the items from the Deliver_In in the local register. To avoid the union being duplicated a multiple times, when the items from the Deliver_In are the same as the items in the register of a non-empty PE, the PE will block the delivering. For example,  there is itemset }4,3{  in the local register and  }4,3{  have already appeared in this transaction, so the index moves to the third position, where no item is placed. When the item 11 comes,  a new frequent itemset }11,4,3{  is detected. The index remains unchanged, so if item 17 comes, itemset  }17,4,3{  will be delivered the same way as itemset }11,4,3{ .

The Support calculation is not so complicated as the generating method. But it's still a time-costing procedure if implemented with the software algorithm.

foreach d_itemset in database//K times { foreach f_item in frequent_itemset//m times { foreach d_item in d_itemset//d times { if(d_item==f_item) index++; else index=0; if(index==size(frequent_itemset)) {support++;index=0;} } } }  Fig 7. Pseudo code for Support calculation  In the software method, if the items in a frequent  itemset match the coming items until the last one, then the Support will be increased by one. The overall cpu cycles for this method is approximately Kdm . While in our hardware implementation, no more cycles are required for the Support calculation, as it could be easily merged into the PE and calculate  parallelly with the generating method.

When an all-items-end mark is streamed into the pipeline, both the generating method and the Support calculation should be completed. So when the mark is delivered to a PE, it places the Support value and the items' ID in it's memory to the result data bus. The end mark is delivered to the PEs sequentially, the same way as a normal item, hence there are no data conflicts while pushing out the results.

4. Results in Ideal Case   As mentioned in Hardware Implementation, the  total cycles for frequent itemsets generation and support calculation in our approach are n ( c is neglected). While the software method requires  )1( mKdm +  CPU cycles.

Presuming that the number of the items in the  database is 1000, we have the simulated results of ideal case in Table 5. Fig. 8  provides a more visual perspective. The blue line, which is the cycles required by the software method, is rising rapidly with the increase of the itemset length. While the cycles required by our hardware implementation is a constant, which is 1000 in this example. When the item length extends to 8, the software method consumes 72 times more cycles than the proposed. So it's conspicuous that our approach is more efficacious than the software algorithm.

Table 5. simulation results in ideal case Itemset length  Software cycles  Proposed  2 6000 1000 4 20000 1000 6 42000 1000 8 72000 1000     Fig 8. Cycles required compared with the software method   5. Conclusion   In this paper, a fast frequent itemsets generation and support calculation method has been proposed based on the systolic array architecture. The hardware implementation utilizes the parallelism in the Apriori algorithm and separates the computation into an array of PEs. A parallel item-delivering method which only requires one scan over the database is proposed to boost the generation phase and it's verified that the implementation has superior efficiency compared to the software procedure and other hardware implementations.

As is presented in the result, the FPGA based configurable computing architecture could lead to a performance leap as long as there is parallelism  to exploit in the algorithm. So our future works will focus on how to distinguish the parallelism part from an algorithm and implement it with FPGAs.

6. Acknowledgment   This work was supported in part by National Natural Science Foundation of China (NSFC) under Grant No. 61001161, Innovation Program of Shanghai Municipal Education Commission No.12YZ024, and Leading Academic Discipline Project of Shanghai Municipal Education Commission under Grant No.

J50104.

