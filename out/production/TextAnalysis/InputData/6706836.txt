

Abstract? Online change detection in datastreams has attracted many researchers and is becoming a very hot topic whose relevance will further increase with research on Big Data.

Concept drift is induced by changes in stationarity of the process generating the data caused by faults, time variance of the environment and inaccuracy of the change detection mechanism. Here, we propose a recurrent auto-associative Encode-Decode machine trained to reconstruct input data. The generated residual is then inspected for structural changes with a Change Detection Test (CDT). Although any CDT can be used, in the paper we focus the attention on the Hierarchical Intersection of Confidence Intervals change detection test for its capability of controlling false positives with a two layered test and an online version of the Lepage Change Point Model. Once concept drift is detected, the designed Encode-Decode machine, globally acting as an Encode-Decode CDT, is retrained on new data to detect subsequent changes.



I. INTRODUCTION ensor networks produce a huge amount of data whose validity must be inspected before any decision can be taken on the measurements. Datastreams are, in fact,  prone to concept drift, namely changes that might affect the process generating the data providing an apparently consistent but wrong datastream. Concept drift is associated with faults affecting the transducing electronics and/or the sensor datapath as well as changes in the environment, possibly characterized by a time variant nature.

Wrong data, even if partly sound, introduce relevant side effects on the application deigned to receive and process the input datastream.

Many examples of applications addressing concept drift can be found in the related literature, which mainly focus on classifiers. For instance, [1] shows how concept drift badly impacts on the classification performance and adaptive mechanisms must be envisaged to react to the change. [2] [3] tackle this problem with an active approach: once a change is detected in the incoming data through a CDT, the   Manuscript received on Feb. 28, 2013. This work was supported partly by the FP7 EU Project-i-SENSE Making Sense of Nonsense, Contract No:, INSFO-ICT-270428, the National Natural Science Foundation of China (Nos.

61273136, 61034002), and visiting professorship of Chinese Academy of Sciences.

Cesare Alippi is with Politecnico, di Milano, Italy and The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, China. Li Bu and Dongbin Zhao are with The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. E-mail: cesare.alippi@polimi.it, bulipolly@gmail.com, dongbin.zhao@ia.ac.cn.

classification accuracy drops and the classifier needs to undergo reconfiguration.

The main difference between an active classifier and a passive solution is the presence of a CDT inspecting features or residuals for concept drift. In turn, this implies that, in addition to the accuracy performance of the classifier, the method is also interested in minimizing detection latency and, possibly, it provides an estimate of the instant of time the change occurred [4]. Traditional approaches based on classic textbook tests, e.g., the T-test and the F-test, are effective but require some prior information about the process generating the data and are not suitable for an online analysis. Alippi et al.

proposed in [5] a change detection method called Computational Intelligence-based CUSUM (CI-CUSUM) which operated sequentially and handles multidimensional samples. Thanks to the central limit theorem the CDT is pdf-free and the due parameters are learned from the training set. Another effective CDT based on the Intersection of Confidence Intervals (ICI) rule has been provided in [6], characterized by a low computational complexity. Hawkins et al. introduced a general Change Point Model (CPM) method adapting traditional statistic tests [7], subsequently extended to datastreams [8] and prior-free cases [9]. Based on their contributions, Ross et al. [4] extended the above work to deal with changes affecting the mean and the variance of a stream of data within an online framework. [17] [18] introduce a different method with Adaptive Plot (AP) which uses nonconventional high order nonlinear neural units with adaptable quasiperiodical forcing input for approximation and detection of changes in complex dynamical systems.

Gustafsson suggested in [10] to model the datastream with a linear time invariant autoregressive AR model and compute the residual discrepancy between real and estimated values. A CDT is then used on the one-step ahead prediction residuals.

A residual-based approach has been also considered in [16].

Although these methods are effective, most of them require the datastream to meet the independent and identically distributed hypothesis.

The aim of this paper is to develop a novel and effective change detection test which operates in the residual framework. Differently from the literature, which makes use of one-step or k-step ahead prediction models we focus on a recurrent linear machine providing a regularization of incoming inputs at the same instant of time. The regularization machine is strongly inspired by the auto-associative Encode-Decode learning machine suggested in [11] and used here to generate a residual sequence. The machine reconstructs ? not predicts- the incoming data based on the learned model. The residual is then inspected for  A Prior-Free Encode-Decode Change Detection Test to Inspect Datastreams for Concept Drift  Cesare Alippi, Fellow, IEEE, Li Bu, Dongbin Zhao, Senior Member, IEEE  S         changes with a generic CDT, here chosen to be the hierarchical H-ICI CDT [12] and the Lepage CPM one [4].

The outcome auto-associative machine combined with a CDT generates a new CDT, called Encode-Decode CDT.

Compared to predictive methods modelling data with an AR model, the suggested machine is more effective in terms of detection performance and works with a lower latency. The i.i.d hypothesis for the residual is requested as per the predictive models and the machine is configured to match such hypothesis. Moreover, a whitening mechanism can be considered, e.g., those suggested in [4]. It should be pointed out that inputs can be nonlinear features extracted from the signal, hence enriching the expressive power of the linear machine.

The structure of the paper is as follows. Section II introduces the auto-associative Encode-Decode machine to be used for residual generation. Section III shows how abrupt and drift type of concept drift are processed by the designed machine and their presence persists in the residual for subsequent change inspection. Experimental results are given in Section IV.



II. THE ENCODE-DECODE MACHINE In the following, we briefly introduce the recurrent  Encode-Decode machine suggested in [11] and show how the SVD (Singular Value Decomposition) decomposition technique can be integrated within the framework to reduce its computational complexity.

Let ??ktx be the zero mean input vector at time t , and introduce the linear recurrent machine    1?= +t x t y ty W x W y                            (1)   where ??sty represents the inner state and  ,??x s kW , ,??y s sW are the parameters matrices.

Here ( 1)= +s k q , where q is the memory depth of the machine. As with [11] we require (1) to satisfy the constraints    1?  =  =  T t x t  T t y t  x W y  y W y .                                  (2)   (2) guarantees that the current input and the previous state  can be reconstructed given the state at time t . Sufficient conditions to design the machine have been proposed in [11], which require the columns of xW to be orthogonal to those of  yW , while T x xW W  and  T y yW W must be projector matrices  applied to vectors tx  and ty , respectively. ty , yW and xW are defined as    1, ,..., ,...,0 0  T T T T T  q t t tty x x  ? + ?  ? ? ? ?= ? ? ? ?  (3)  , , ,  ,, ,  0 0 ;  k kq k k k k  y x kq kkq kq kq k  I W W  I ? ? ? ?  = =? ? ? ? ? ? ? ?? ?  (4)   where ,0? ? is a rectangular zero matrix of ? rows and ? columns and ,? ?I the identity matrix of order ? . We comment that yW  operates a k steps right shift and that the above machine can reconstruct the input vector tx without any information loss.

To reduce the complexity of the Encode-Decode machine since s can be a large number, we resort to the use of a SVD for ty as follows. Construct at first matrix ,? sX for each row vector ty , 1,...,?=t  and compute the SVD    , , , ,? ? ? ?= ? T  s s s sX U V .

Keep the first p singular values and the associated eigenvetors to compose V , an ?s p matrix so that  ,= T  p pV V I .

Now, ty can be transformed to T  t ty V y= and by  multiplying TV to the left of (1) we have that  1 1 T T T  y yt tV W V W VVy y? ?=  holds when p ? rank(?? ,s ). We finally obtain    yt =V T Wx xt +V  T WyV yt?1.                   (5)   It should be commented that (5) represents an approximate  expression when p < rank(?? ,s ), i.e., when we remove not null eigenvalues. The closer p to the rank(?? ,s )  the better the approximation.

Define = T  x xW V W  and = T  y yW V W V , then (5) can be rewritten as    1?= +x ytt ty W x W y                                  (6)   and the reconstructed input vector is   = T  t x tx W y .                                        (7)  Let?s refer to Fig. 1. After the SVD, which introduces a  reconstruction loss, the Encode-Decode machine changes from the left configuration to the right one characterized by a         reduced complexity. The quality of the reconstruction can be evaluated by inspecting the reconstruction residual at time t    ,( )? = ? = ? T T  t t t x s s tx x W I VV y .                 (8)  As has been noted, the value of p  has an obvious effect on  the residual quality. The higher the p , the better the achieved reconstruction ability. When p is equal to s , our method degenerates to the original error-free Encode-Decode machine depicted in the left part of the figure.

It is obvious that p plays a main role in the reconstruction ability of the machine. Since, a suitable choice for p shall remove the noise in the datastream and move it to the residual, we select here the p  maximizing the whiteness of the reconstruction residual. More specifically, we compute the autocorrelation function of the residual up to time ? on a validations set and select    p = arg min p=1,...,s  etet?? t=1  N ?  ? =1  T ?  .



III. THE ENCODE-DECODE CDT FOR DETECTING CHANGES In this section we show how the SVD-based  Encode-Decode machine can be used to build a sophisticated change detection test operating at the residual level.

A. Detecting Changes with the Designed Encode-Decode Machine (8) presents the difference between reconstructed and real  values, namely the residual. Given the particular structure of xW , (8) can be rewritten as   , ,( )? = ? = ? T  t t t s s k s tx x I VV y .

If we focus on the first component of the error vector ? t , we obtain the point-wise reconstruction error te    1= = =?  s T  t i i t i  e a y a y   where ia is the i-th entry of the first row a of the matrix  ,( ) T  s sI VV? .

1) Abrupt Perturbation Case  Consider an abrupt perturbation ( )? ?=t affecting the input at time pt , then ( ) ( )? ?= +x t x t , t > pt . Once the perturbation completely propagated through the machine, the residual becomes    , 1 1  ? ?? = =  = + = +? ? s s  t i i i t i i  e a y a e e    where  ? ? =  = ? s  i i  e a is the expected error for the machine:  following an abrupt type of concept drift the residual error contains the propagated perturbation.

2) Linear Drift Perturbation Case In the case where the perturbation drifts over time with a  linear model ( )? ?= dt t , the perturbed input vector becomes ( ) ( )? ?= + dx t x t t , t > pt . Once the perturbation  completely propagates through the machine, the residual becomes    , 1 1  ? ?? = =  = + = +? ? s s  t i i i t i i  e a y a t e e    TW Vx  tx  ty  TWV x  tx  TV W Vy  -1ty  ?  - +  + +  te  TWx  tx  ty  Wx  tx  Wy  -1ty  ?  - +  + +  te =      Fig. 1. The transformation from the initial recurrent machine to the Encode-Decode SVD-reduced machine         where  ? ? =  = ? s  i i  e a t is the expected error.

From the above derivation, we can see that perturbations affecting input data propagate to the residual through the machine with a gain depending on coefficients coming from the SVD decomposition: a change detection test has material to detect the above perturbations.

B. H-ICI CDT and Lepage CPM The residual can be inspected with any CDT method. Here,  we consider the H-ICI CDT suggested in [14] and the Lepage CPM provided in [4].

H-ICI CDT operates at two levels to reduce the false positive rate. Since the first-level CDT has to guarantee prompt detection abilities, the ICI-based CDT [6] characterized by a low computational complexity is chosen.

When detecting a change (either a real concept drift or a false positive detection), the method provides an estimate t  of the change time. The second level CDT is then introduced to control false positives. More specifically, the second level CDT partitions the datastream in two data sets characterizing the states of the process before and after the supposed change of time t . Then, a multivariate hypothesis test based on the Hotelling?s T square statistic [15] is executed.

The Hotelling test confutes or confirms the concept drift detection proposed by the first level CDT and its outcome is the final one.

As an additional CDT we consider here the Lepage test CPM-LP [4]. In particular, CPM-LP evaluates the ranks of the observations when t  points are observed. The rank of the i th observation at time t is defined as    ( ) ( ) ?  = >? t  i i j i j  r x I x x   where I is the indicator function. Then the Mann-Whitney test statistic U [7] is computed on the ranks to detect changes in location and the Mood test statistic M is used to detect changes in scale. In order to monitor changes both in location and scale, a combined statistic 2 2= +L U M  is used.

When the t th observation is received, Li,t (i is a point in the datastream) is evaluated at each feasible sample with the stream split in two sets (before and after the considered samples) to generate the previous and the following data sets.

The maximum value L of the Li,t sequence (1< i < t ) is then compared with a given threshold th : a change is detected when L ? ht .

When a change is detected the methods are reconfigured on data instances related to the new state.

C. Designing the Encode-Decode CDT The Encode-Decode CDT is composed by the  Encode-Decode SVD-based machine followed by a CDT to detect changes in the residuals. Even if any CDT can be  considered, we will refer here to the H-ICI CDT and the CPM-LP tests. The structure of the Encode-Decode CDT is shown in Fig. 2.

tx  te  TW Vx  tx  ty  TWV x TV W Vy  -1ty ?  -+  + +     Fig. 2. The Encode-Decode CDT

IV. EXPERIMENTAL SESSION The reference application comes from the data acquired  from the hybrid wired-wireless monitoring system deployed on the Alps to monitor a potential rock collapse [12]. Data, here temperature, are sampled every 5 minutes and sent to a remote control station for subsequent processing (the deployment also considers tiltmeter, accelerometer and strain gauge sensors).

The optimal Encode-Decode machine, characterized by k =1 and q =3, is trained on the first 3000 samples. p =2 is selected as presented in Section II as the one maximizing the whiteness of the residual on the validation set, here composed of 1000 samples. After training, our machine becomes operational and a perturbation (abrupt or drift with different values) is injected randomly around sample 1000. In the following figures, the upper plot presents the initial error-free signal (solid line, blue color) and the perturbed one (dotted line, red color). The lower plot refers to the point-wise residual between the reconstructed value and the perturbed one. The pink vertical line represents the start time of the change occurrence, the black one shows the instant of time where the Encode-Decode CDT detected it, and the cyan vertical line refers to the CPM-LP [4] detection. The gamma parameter of H-ICI CDT is 0.5, ARL0 in CPM-LP is set to 40000.

Fig. 3 shows the case where an abrupt perturbation occurring around point 1000 affects the signal. Then the Encode-Decode CDT and CPM-LP are used to detect the residual generated by the Encode-Decode machine, respectively. Detections are shown in the lower plot. Both methods detect the change but CPM-LP introduces some false positives.

0 500 1000 1500 2000 2500 -5     Samples  D at  as et  0 500 1000 1500 2000 2500 -0.2  -0.1   0.1  0.2 Encode-Decode  Abrupt=1  ARL0=40000  Samples  R es  id ua  l     Fig. 3. An abrupt change occurring around point 1000 affects the sensor measurements. (In the upper plot, the blue line represents the initial data, and the red line shows the data with the added change. In the lower plot, the pink vertical line represents the time of the change occurrence, the black one represents the detection of the Encode-Decode CDT and the cyan one that of the CPM-LP test)   0 500 1000 1500 2000 2500 -5     Samples  D at  as et  0 500 1000 1500 2000 2500 -0.2  -0.1   0.1  0.2 Encode-Decode  Drift=2  ARL0=40000  Samples  R es  id ua  l     Fig. 4. A linear drift affects the sensor measurements. (In the upper plot, the blue line represents the initial data, and the red line shows the data with the added change. In the lower plot, the pink vertical line represents the start time of change occurrence, the black one is the detection of the Encode-Decode CDT and the cyan line that of the CPM-LP)   In Fig. 4, a linear drift is injected around sample 1000 to the true signal. The detections of the ICI-CDT and CPM-LP are shown in the lower plot. Initially, the impact of the change is small, hence hard to be detected by the CDTs. After enough samples, the H-ICI CDT gets enough confidence to detect the change and sets an alarm. CPM-LP is faster here (lower latency) but introduces some false positives.

To give a more comprehensive analysis we compared the Encode-Decode machine with the best AR model designed on the signal and contrasted the two residuals with the H-ICI CDT and CPM-LP. The reference application is that referreing to the mountain temperature, whose framework was previously introduced. Results are given in Table I where each cell provides false positives (FP) and false negative (FN)  rates as well as the detection latency (L) when an existing change is detected  for 100 runs. The average value is given with its standard deviation within parenthesis.

It appears that CPM-LP performs very well in terms of false negatives but introduces some false positives despite the careful choice of ARL0 whereas the suggested Encode-Decode machine is always to be preferred than the prediction model based on AR.

V? CONCLUSIONS The paper presents a new mechanism for generating, given  a datastream, a residual sequence to be inspected for potential concept drift. The method is based on an auto-associative recurrent machine whose computational complexity is controlled with a SVD decomposition. A CDT is then mounted on the residual to detect changes. The outcome is a novel change detection test we name Encode-Decode CDT. It is shown that abrupt and drift perturbations are propagated to the residual and can be detected by a CDT. Both the H-CDT and Lepage CPM change detection tests have been considered to inspect the residual for concept drift detection.

The method, applied to a real application shows the effectiveness of what proposed.

