new algorithm of maximum frequent itemsets based  on FP-tree for mining multiple-level association rules

Abstract?Discovering maximum frequent itemsets is a key problem in data mining. In order to overcome the deficiencies of Apriori-like algorithms which adopt candidate itemsets generation-and-test approach, we propose a new algorithm ML_DMFIA which based on DMFIA to mine maximum frequent itemsets in multiple-level association rules. ML_DMFIA utilizes FP-tree structure and up- down progressive deepening searching idea which can avoid making multiple passes over database and does not generate candidate itemsets, consequently, it reduces CPU time and I/O time remarkably. Our performance study shows that ML_DMFIA is more efficient than ML_T2 algorithm for mining both long and short frequent itemsets in mining multiple-level association rules.

Data mining; multiple-level; FP-tree; ML_DMFIA

I.  INTRODUCTION Association rules is an important KDD research issues [1,  2, 3] first presented by Agrawal, which task is to discover the hidden association relationship between the different itemsets in database. It is the most important step and technique for finding the frequent itemsets in association rules, because all frequent itemsets are considered implicitly in the maximum frequent itemsets, we can convert the issue of discovering the frequent itemsets to the issue of discovering the maximum frequent sets. More and more people have focused on maximum frequent itemsets recently, they have presented many algorithms, such as MaxMiner [4], DMFI [5], DMFIA [6], Pincer-Search [7], GenMax, MinMax, SmartMiner, FpMax etc.

With deepen research in mining association rules and it exists hierarchy and taxonomies in most concepts in real life, users maybe not discover meaning patterns by only researching detail data in transaction databases, but they may find meaning patterns in higher level of concepts hierarchy.

Furthermore, though the patterns which obtained from some hierarchy can be used for one user but nothing for another, consequently, association rules should provide efficient methods for mining multiple hierarchy, then the idea of data mining in multiple-level association rules is presented.

Current algorithms about multiple-level association rules include: ML_T1LA, ML_TML1, ML_T2LA [8] etc, they are mostly based on Apriori algorithm which have two main aspects of disadvantages about scanning database repeatedly and candidate itemsets generation-and-test. Once there are  many taxonomy items in concept hierarchy and the frequent itemsets are longer, the disadvantages are more evident. FP- tree is composed and informative structure only frequent 1- items will have nodes in the tree, and the tree nodes are arranged in such a method that more frequently occurring nodes will have better chances of node sharing than less frequently occurring ones, the algorithms based on FP-tree takes exactly two scans of the transaction database, it converts scanning transaction database to scanning FP-tree in memory which can avoid making repeated passes on database. In this paper, we develop a new algorithm named ML_DMFIA by utilizing characteristics of DMFIA which adopts FP-tree structure and up-down progressive deepening searching idea in discovering maximum frequent itemsets, it can prune subsets of longer maximum frequent itemsets when algorithm running in early stage. Experiments prove that ML_DMFIA is more preponderant than ML_T2.



II. PROBLEM STATEMENT  A. Frequent Itemsets and Maximum Frequent Itemsets Let I={i1,i2,?,im} be a set of m distinct items. A  transaction T is defined as any subset of items in I. A transaction database D is a set of transactions like T. A transaction T is said to support an itemset X?I if it contains all items of X. The fraction of the transaction in D that support X is called the support of X, denoted as support(X).

An itemset is frequent if its support is above some user defined minimum support threshold. Otherwise, it is infrequent.

If all supersets of frequent itemsets F are infrequent itemsets, then F is denoted as a maximum frequent itemsets, all sets of like F are called maximum frequent sets (or MFS for short), which stores all maximum frequent itemsets discovered.

Maximum frequent candidate set (or MFCS for short) [5, 6, 7], which is the smallest itemset, its sets of subset includes all the current frequent itemsets known, but it does not include any infrequent itemsets. Obviously MFCS is a superset of MFS at any time of algorithm running. When algorithm terminates, MFCS and MFS are equal. We can possibly discover some maximum frequent itemsets in early passes according applying MFCS. Earlier discovering maximum   DOI 10.1109/CSSE.2008.835    DOI 10.1109/CSSE.2008.835     frequent itemsets can reduce the number of candidate itemsets which would be generated, therefore it can decrease CPU and I/O time. If the maximum frequent itemsets discovered are long, the algorithm?s performance is more excellent. The initialization situation of MFCS only includes one itemset, which includes all items in transaction database.

Obviously, all frequent itemsets are subset of maximum frequent set, therefore, the issue of discovering frequent itemsets can be converted to the issue of discovering maximum frequent itemsets.

B. Concepts of Multiple-level Association Rules The hierarchical tree is a hierarchical relationship tree  which is from common concepts to concrete concepts [8] as shown in Fig. 1. The data mining of multiple-level association rules discover association rules from every hierarchy. Firstly, we encode hierarchical tree, the method is as follows: we encode root node of every hierarchical tree as a sequence digits, then we encode every tree?s node by every level, the code of sub node is encoded which combines code of the father node and the sequence digits according to the sub node?s position in sub tree, the encoded hierarchical tree is shown in Fig. 2. Then all items in transaction database would be replaced by its corresponding code in the encoded hierarchical tree, and form the hierarchy information encoded transaction table T[1], as shown in Tab. 1.

TABLE 1. T[1] TID Transaction 001 111, 121, 211, 221 002 111, 211, 222, 323 003 112, 122, 221, 421 004 111, 121, 421 005 111,122,211,221,413 006 211, 323, 524, 413 007 323, 524, 713    C. Frequent Pattern Tree FP-tree FP-tree is a special prefix tree [9], it consists of a frequent  item header table, one root labeled as ?NULL?, and a set of item prefix subtrees as the children of root. Each node in the item prefix subtree consists of four fields: node-name, node- count, node-link and node-parent. Each entry in the frequent item header table (or Ftable for short) consists of three fields: item-name, item-sup and item-head, item-head is a pointer pointing to the first node in the FP-tree carrying the node- name. Based on this definition, given a transaction database DB and a support threshold minsup, we have the following FP- tree construction steps: (1) Scan DB once. Collect L, the set of frequent items, and the support of each frequent item. Sort List in support-descending order as LF, the list of frequent items.

(2) Scan DB again. Select all frequent items in every transaction, sort them according to the order of LF then form the corresponding itemsets by combining the ordered frequent items in every transaction, and insert them to FP-tree respectively.



III. TACTIC OF MINING MAXIMUM FREQUENT ITEMSETS Property 1 If an itemset is infrequent, all it superset must be infrequent.

Property 2 If an itemset is frequent, all it subset must be frequent.

Property 3 If X={x1,x2,?,xm-1,xm} is an infrequent itemset, and Xi={xj|xj?X,j?i} maybe frequent itemset.

The bottom-up search algorithm only uses the property 1, which discovers the frequent-1 itemsets L1,then discover frequent-2 itemsets by using L1, repetitively until can?t find the frequent itemsets. The up-down search algorithm only uses the property 2, which begins from the only itemsets(it includes all items in L1), it reduces some candidate itemsets in every pass. If k-itemsets is infrequent in pass k, then check all (k-1)-itemsets in next pass; If k-itemsets is frequent, all its subsets are frequent itemsets according property 2.

Consequently, it can discover all maximum frequent itemsets.

The bottom-up search tactic is suitable for the situation when maximum frequent itemsets are short, but the up-down search tactic is suitable for the situation when maximum frequent itemsets are relatively longer.

We employ the up-down search tactic, which uses the MFCS to store the up-down information. It counts the support of every itemsets in MFCS respectively, if the itemsets is frequent itemsets, then it will be added to MFS that have been generated; Otherwise, generates new candidate itemsets by removing one item in the itemsets stated above. The new    PC  --------  Computer  Laptop  IBM HP Legend Haier  Figure 1. the hierarchical tree  Model Mainboard   --------    111 112 141 142  Figure 2. the encoded hierarchical tree  12 13     itemsets just generated should check whether its supersets are in MFS and MFCS or not before being considered as a new candidate itemsets, if the supersets exist, the new itemsets talked above is not a member of MFCS, then it will be pruned; Otherwise, adds the new candidate itemsets in MFCS.



IV. ML_DMFIA ALGORITHM Input: the FP-tree of DB, frequent item header table Ftable, and the minimum support threshold (minsup) which defined by user; the list of frequent items LF (set LF = {1,2,3,?,k}).

Output: the MFS includes all maximum frequent itemsets.

(0)For (lv=1;lv?MAX_LEVEL;lv++) //lv is a variant which  represents corresponding level in multiple-level association rules; MAX_LEVEL is a constant which represents the maximum level in multiple-level association rules.

(1) MFSlv=?; (2)MFCS=LF={1,2,3,?,k}; //MFCS is the maximum frequent  candidate sets in DB, MFCS is different in every level.

(3) while (MFCS??) do begin (4)   for (i=k; i>0;i??) do begin (5)     MFCSi= {c|c?MFCS and item i is the last item in c}; (6)     MFCS=MFCS?MFCSi; (7)     Call ComputeCount(FP-tree, Ftable, MFCSi); //  Accumulates every itemsets?s support in MFCSi respectively.

(8)     for all m?MFCSi do begin (9)       if m.support?minsup then (10)        MFSlv = MFSlv?m (11)      else (12)        for all item e?m do (13)          if m?{e} is not subset of each element in MFSlv and  MFCS then (14)            MFCS=MFCS?{m?{e}}; (15)     end (16)   end (17) MFS= MFS?MFSlv (18) end Lemma 1 Given a transaction database DB and a support threshold minsup, the support of every frequent itemsets in DB can be derived from DB?s FP-tree.

Rationale. Based on the FP-tree construction process, for each transaction in DB, its frequent item projection is mapped to one path in the FP-tree. Given a frequent itemsets X={x1,x2 ,?xn}, and item xi (1?i?n) has ordered by support-descending in DB. According the node-link of item xn, we can find all nodes marked as xn in FP-tree, and according the node-parent of item xn, we can discover all paths that include item xn as the last item. For every path p that includes nodes from root to node v which marked as xn, the support of node v (or node- countv) indicates transaction number that includes path p. If x1,x2,?,xn are all in path p and it shows that path p includes X, so the number of transactions which include p is node- countv. Therefore, we can accumulate the support of frequent itemsets by the method stated above, the total number is support of X.

ML_DMFIA employs the function ComputeCount to count the support of every itemsets in MFCSi, which based on the Lemma 1, because all items from the itemsets in MFCSi have ordered by support-descending, consequently, it is convenient to confirm number of the path which include the exact itemsets.

Figure 3.  FP-tree based on T[1]  The following example shows how to figure out MFS by using ML_DMFIA, given a transaction database DB denoted as T[1], let the minimum support threshold be 3(i.e., minsup=3) and the maximum level be 3 in the hierarchical tree, take the third level in multiple-level association rules as an example, the process as follow:  First, constructs FP-tree in DB, as shown in Fig. 3, then generates MFS3 and MFCS by using ML_DMFIA, the contents of MFS3 and MFCS are as follows when ML_DMFIA runs: (1)MFS3=?; MFCS= {{111,211,121,221,131,231}} ; (2)MFS3=?;  MFCS={{111,211,121,221,231},{111,211,121,131,231},{ 111,211,121,221,131},{111,211,221,131,231},{111,121,22 1,131,231},{211,121,221,131,231}};  (3)MFS3={{111,211,121,221,131}}; MFCS={{111,211,121,231},{111,211,221,231},{111,121, 221,231},{211,121,221,231},{111,211,131,231},{111,121, 131,231},{211,121,131,231},{111,221,131,231},{121,221, 131,231},{211,221,131,231}};  (4)MFS3={{111,211,121,221,131}}; MFCS={{111,211,231},{111,121,231},{211,121,231},{11 1,221,231},{211,221,231},{121,221,231},{111,131,231},{ 211,131,231},{121,131,231},{221,131,231}};  (5)MFS3={{111,211,121,221,131}}; MFCS={{111,231},{211,231},{121,231},{221,231}, {131,231}};  (6)MFS3={{111,211,121,221,131},{111,231},{211,231}}; MFCS =?.

In the first level of multiple-level association rules, every item in DB is similar to form of {1**}, {2**} etc, and in the second level every item is similar to form of {11*}, {12*} etc.

root  111:5  211:4  121:4  221:4  231:1  131:3 231:1  231:1  211:1  131:1  231:1  111:5  211:5  121:4  221:4  131:4  231:4     The process of discovering MFS in the first and the second level is similar to discovering MFS in the third level, first, ML_DMFIA constructs the FP-tree in the first and the second level and generates MFS1 and MFS2 respectively, it combines MFS1, MFS2 and MFS3 to a complete MFS at last, hence, we realize to discover the maximum frequent sets in multiple-level association rules. ML_DMFIA can implement paralleled in the processing on constructing FP-tree and figuring out MFS.



V.  INTRODUCTION To study the performance of the proposed algorithm,  ML_DMFIA algorithm and ML_T2 algorithm are implemented and tested on the computer with 512M main memory, Pentium 4-2.4GHz CPU and Windows XP operation system. We employed the test database similar to that described in [5], the transaction database includes 8124 pieces of transactions, it records 23 kinds of attribute of mushroom, we extracted 6000 pieces of transactions to test in sample database at randomized. The transaction database is converted into an corresponding encoded transaction table according to the information about the generalized items in the item hierarchy table denoted like T[1]. The maximal level of the concept hierarchy in the items table is set to 3. As shown in Fig. 4, it indicates the difference execution time between the ML_DMFIA algorithm and the ML_T2 algorithm under the difference minimum support, the lower the minimum support (i.e., the candidate itemsets is much more), the longer CPU execution time runs, the ML_DMFIA algorithm performs to be shorter execution time in the same support. As shown in Fig. 5, it indicates the different number of itemsets which would be calculated between the ML_DMFIA algorithm and the ML_T2 algorithm in the processing of algorithm execution, the ML_DMFIA algorithm counts less itemsets under the same support.

5 10 20 40  minsup(%)  ??(?)  ML_T2 ML_DMFIA   Figure 4. execution time       5 10 20 40  minsup(%)  ???  ML_T2 ML_DFMIA   Figure 5. itemsets number

VI.  CONCLUSION We propose a new algorithm for mining maximum  frequent itemsets in mining multiple-level association rules, ML_DMFIA makes full use of the advantage about FP-tree structure for calculate the support of frequent itemsets and the up-down progressive deepening searching tactic, experiments show that ML_DMFIA is faster and more effective than other algorithms in mining multiple-level association rules.

