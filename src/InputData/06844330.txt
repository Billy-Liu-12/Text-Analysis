Some Special Issues of Network Security Monitoring on Big Data  Environments

Abstract? Big Data possesses profound information of our society, and therefore, it impacts numerous aspects of human society, with a large amount of data from large-scale heterogeneous network environments, we should analyze some special issues of network security monitoring on Big Data environments. This paper propose data cleaning for various types of data sources and analysis Big Data on network security through security event on multiple associations rules. This study provides some ideas for network security monitoring on Big Data environments.

Keywords?Big Data; association analysis; mining; network security

I. INTRODUCTION Big Data is usually so large and complex, and it has  become an emerging hot topic in network security fields. How to deal with lots of safety data which are produced by heterogeneous network security devices, how to analyze and coordinate such Big Data network events must be studied to date [1-3].

We need to study network security monitoring system on Big Data environment, timely analysis of Big Data processing, and analysis heterogeneous behavior of various types of security incidents, adjust the security policy to dynamically adapt to network security requirements.

The remainder of the paper is organized as follows. Section 2 summarizes the new requirements of network security monitoring for Big Data. In Section 3, the system model is proposed, and then some key issues of the scheme are discussed in Section 4. Finally, conclusion is given in Section 5.



II. NEW REQUIREMENTS OF NETWORK SECURITY MONITORING FOR BIG DATA  2.1 Features of Big Data Big Data, what means large amounts of data sets which  cannot be captured by general software tools in timely [3].Big Data features include four levels: first, the huge volumes of data from the TB( terabyte) level, jumped into the PB(petabyte) level; Second, various data types, including network logs,  videos, pictures, geographical location information, etc.; Third, the value of low density, large amounts of data may be useful only for very few; fourth, fast processing speed, should follow second law. This last point is different of the traditional data mining techniques.

In the RSA 2012 Conference, there have been many information security companies which analyze Big Data, some of them change analytics methods based on the technical aspects of Big Data, and some focus on Big Data analysis based on the application level. For network security industry itself, its amount of data generated is also growing more and more quickly, showing all the major characteristics of Big Data [4].

2.2 new requirements of network security monitoring Prediction is the core of Big Data scientific problems. At  present academic circles mainly concern two class prediction problems, one is the trend prediction, the other is missing information prediction.  Trend prediction is refers through things and some basic properties of the information and the early trend analysis, forecast the trajectory of development of things and ultimately influence. Missing information forecasts assume we observe the real information is only part of the information on this basis, explore how to use this information to predict the information was not observed.

The security technologies such as IDS(Intrusion Detection System), IPS((Intrusion Prevention System), firewall and anti- virus technology and other technologies are already relatively mature, but in cloud computing, internet of things, network security showing a new demand, network anomaly detection must adapted to the new direction of development of Big Data[5].

The age of Big Data, network security monitoring systems need to meet several requirements. First, we must find abnormal alarm as soon as possible. This can take early measures to avoid or mitigate the impact on services. This is actually an application of trend forecasting. Secondly, we must make a correct diagnosis of alert information from the massive, extract the real, non-redundant information, in order to find out the root of the problem, and to solve the problem.

Project Supported by Youth Scientific Research Fund of Guangdong: No.

2012lym_0088.

DOI 10.1109/DASC.2013.30    DOI 10.1109/DASC.2013.30    DOI 10.1109/DASC.2013.30     Sensitivity and reliability is a pair of contradictory of network security monitor in Big Data environment, and at the same time, the detection system?s network level and performance decide their information acquisition and analysis limitations. We obtained information on these alerts, it is inevitable there will be some missing, and it can be applied to Big Data missing information predict, to get a true picture of network attacks or abnormal.

Big Data can give full play to its externality and generate much larger than the sum of the huge value through fusion with some related data cross. For network security monitoring in Big Data environment, the most important step is the association of events. There are many researches on traditional event correlation, such as rule-based correlation, Bayesian network inference, model-based reasoning, filtering, case- based reasoning artificial neural network reasoning [6].

These correlation methods are generally used for a single anomaly detection system, rather than for the entire network security domains (including network devices, security devices and subnets hosts, etc.), which makes monitoring method lack of global integrity from the entire network. Therefore, we believe the development of network security detection needs to adapt to this change in Big Data environment. New researches should consider from the architecture, algorithms.

And we should study on data cleaning, as far as possible without loss value of data and reduce the scale of core data.



III. MODEL OF NETWORK SECURITY MONITORING  SYSTEM IN BIG DATA ENVIRONMENT  3.1 New research of network security monitoring in Big Data When various security and network devices and host  systems put into operation, safety-related data volume will increase rapidly, they form huge amounts of data and alarm event, and these event data reflects the several features of Big Data, if the lack of a strong event association analysis ability, it will lead to some critical safety information and alarm events are flooded by low value or worthless alarms, some of the global, affecting major issue will be ignored, causing serious security incidents. As can be seen, the research of network security monitoring system model and related algorithms in Big Data environment is very meaningful.

In response to questions, there are some aspects of network security monitoring system in Big Data environment need to be considered:  Collection and preparation of security event data is established the primary task of the overall architecture. In the vast amounts of data source comprehensive data needed to ensure data quality and timeliness comprehensive model is the basis for the entire system. Data collection includes the entire network system include of network devices (routers, switches, etc.), security devices (firewalls, IDS, anti-virus, etc.), the host server's logs and event information, alarm information.

The age of Big Data, the data is widely available, we just lack of ability to extract knowledge from massive data. The  raw data obtained from the data source and data integrity, consistency and correctness are very difficult to be guaranteed. For network security monitoring system, data efficiency, effectiveness and scalability is very important.

Therefore, through the standardization and integration of security incidents, security event data can be manipulated in a convenient format on the basis of the standard data, removing redundant and outdated data.

The fundamental purpose of Big Data collection is extract useful knowledge from the raw data based on demands. Then we apply it to specific areas. By the previous step process, standard data correlation and integration is an important part of safety monitoring system, through event correlation, the system can find the particular security key events related to the behavior, and further judge the actual harm produced by this behavior.

Network security quantification and visualization in real time: Through standardization and related security events processing, monitoring system can be applied to a specific algorithm security events in real-time quantification of the risk values, and graphically described. When the security behavioral risk quantification value reaches a certain threshold, the monitoring system should be able to provide some mechanism for automatic defense and risk reduction, or provide some means to assist the Security technicians respond quickly.

3.2 System model About network security monitoring system, security  industry researchers put forward many models and algorithms, but due to the initial construction of the heterogeneous network, security technology makes a variety of security devices missing information layer interoperability and reduce overall operational efficiency of the system , increased security event detection and response times. And under the environment of Big Data, massive security events flooded with unreliable information, so that these security incidents become worthless.

So, the algorithm has some adaptability problems, such as high time complexity of the algorithm, the algorithm accuracy is low, etc., unable to handle Big Data.

In view of the need to develop new security situation, it is necessary to make further research on network security monitoring system, in order to provide an efficient, standard system framework. We propose security event monitoring system model in Big Data environment consists of four major modules, the structure shown in figure 1.

? Big Data collection module:  For the current network security system, common source of information for the collection of data is to collect the most primitive data. These data include the information source traffic data, event logs, and security logs. The research shows a simple algorithm of Big Data sets can produce better results than complex algorithms on small data sets.

? Big Data integration modules:  Event Collector module collected mostly messy data, various information sources report different data format to     describe different, which gives the system detects network behavior inconvenience, we deal with this through the integration modules, this module will filter raw data, redundant processing, and according to the classification rules to classify the data processing. Since unstructured data characteristics of Big Data, the work is a long way to go. Here we need to study Big Data cleaning filters and quality management techniques.

? Big Data analysis modules:  This module is the key to the whole system, the processed data is only removes the redundant and for the entire monitoring system is still the initial data. We need to analyze the core event data according to the events of the network environment, system services and event status. Faced with an increasingly expansive mass data, the traditional association rule mining method has failed to meet people's needs, so it is very important to research of association rules in Big Data sets.  The knowledge base for typical security loopholes, typical safety behavioral pattern and scene etc., when time after the incident, we can be mapped to the system structure and determine the nature of incident and the location of event.

The difficulty in this module is the representation of knowledge association algorithm and background in knowledge base, we will present some ideas on this analysis, we solve the problem from the parallel association rule and flow rule and other aspects of mining Big Data sets.

? Big Data Interpretation modules:  The analytic results for data mining and give a visual output of statistical analysis, and then we predict the development trend of network behavior.



IV. CORRELATION ALGORITHMS  Big Data scale can be large, but should ease to use them, which requires good data structure. Data with related internal clearly and easy to get, so researchers and the general developers can freely access the data and analysis them.  For security monitor system, the most important thing is to coordinate its core processing and association analysis. After the collection and integration of all duplicate and similar events, we use unified data format conversion definitions describe all events, and then, the most important thing is to correlate analysis.

We can find the correlation of Big Data through mining association rules. Association analysis generated rules with confidence. We hope that these rules are useful, but not an accidental phenomenon, so for the universality of the rules we need to have an exact measurement.

Fig 1 structure of the framework  Network security monitoring systems correlation algorithm involves several aspects. First of all, need to consider the  Big Data Collection  Raw Data structured   semi-structured unstructured  Syslog  SN M  P  SM TP  O PSEC  C isco  D atabase  Log File  A nother N  SM  TC P/IP  AVVPNIPSSevSW RTDBFWIDS  X M  L  Machine learning   Statistics   Data Mining  Big Data Integration Big Data Extraction  Core Data (Standardized)  Filer; Aggregation; Correlation; Normalization  Event-DB  Visualization, Evaluation, Quantization, Prediction  Knowledge-DB  Traffic rules base on wavelets.

Inter- related rules  Fuzzy constraint correlation  Big Data Analysis  Big Data Interpretation     relationship between the different items of audit records of the same monitor device, which we call rules correlation and in this paper, we use fuzzy constraint correlation algorithm based on prerequisites and consequences of security event. Secondly, because it is the whole network system security monitoring, the network follow information between the associated devices is very important, therefore, we need to be able to study traffic rules between kinds of devices. The last one, we should consider the relevance of data from different devices and network audit records between traffic data, which we call inter- related rules correlation [6].

4.1 fuzzy constraint correlation algorithm Accordingly, we propose to identify the prerequisites (e.g.,  existence of vulnerable services) and the consequences (e.g., discovery of vulnerable services) of each type of security event [6].

Definition 1:  A security event type is expressed as a triple EV (E, P, C): event name, prerequisites and consequences, P (E) denotes the set of prerequisites of the security event type E and C (E) denotes the set of possible consequences of the security event type E. The prerequisites and consequences may be expressed by atom predicates and may be expressed by logic formulae which are joint with a set of predicates. Event association rules base is automatically generated by SQL query statements (SELECT-FROM-WHERE) offline, and then event alerts are correlated using rule matching online.

Our method is based on the observation that in a series of security events, the events are usually not isolated, but related as different stages of the event sequence through pretreat from Big Data, with the early ones preparing for the later ones. We can import some known field knowledge as links of different security events.

Definition 2:  Security event instance e1 prepares for security event instance e2, if there exist p P(e2) and c C(e1), e1.end time < e2.begin time and c h p, then we call e1 and e2 can be correlated. The h indicates some known prerequisite.

Through researches, the correlation algorithm as definition 2 may result flood security event data [peng ling ].We use and improve the method of definition 2, by introduce constraint term, we reduce the result amounts of correlation.

Definition 3:  for security event instance e1 and e2, u1,u2,...,un are the attributes of e1 and v1,v2,...,vm are the attributes of e2, if e1.end_detectTime<e2.begin_detectTime,n=m and e1.u1=e2.v1  ... e1.un=e2.vm, then we call e1 and e2 can be constrain correlated. That is exist predication Pr, for c C(e1),p P(e2),c=Pr(u1,u2,...,un),p=Pr(v1,v2,...,vm),(c,p)?C(e1)?P(e2),The n we call there are causal relationships between e1 and e2, and there are strict binary causal relationship R in set C(e1)? P(e2).

With Big Data, for the faultiness of security software and security hardware, there are a flood of missing and false alerts of security event in heterogeneous & autonomous distributed systems, they brings the imperfection of security event. On the other hand, the increasingly complex, stealthy and distributed features of attack methods & technologies, especially distribute attacks from multi-source address have made new challenge of correlation based on prerequisites and consequences. A mountain of experiment data show it is difficult to ensure the attributes of correlation event can satisfy definition 3 severely, so it?s hard to result accurate correlations. We develop fuzzy constraint correlation algorithm, it can improve performance of correlation based on prerequisites and consequences in condition of various security threats. Use fuzzy system can solve above problem preferably and find the potential correlation relationship base on prerequisites and consequences of security events.

Base on fuzzy theory, we import binary fuzzy causal relationship R~  of C (e1)?P (e2) to describe the relationship of security event e1 and e2. R~  Is fuzzy set in C (e1)? P (e2), we use membership function ),(~ pcR?  to denote it. Membership function ),(~ pcR?  gets value in close interval [0, 1], the value express the membership grade of ordered pair (c,p) on fuzzy set R~ .

Definition 4:  for security event instance e1 and e2, A1={u1,u2,...,un} is the set of attributes of e1 and A2={v1,v2,...,vm} is the set of attributes of e2, B1={u1,u2,...,uq} and B2={v1,v2,...,vq} are base attributes set of e1 and e2, q n, q m ,B1? A1,B2? A2, if e1.end_detectTime< e2.begin_detectTime,e1.u1=e2.v1 ...

e1.uk=e2.vk,k n, k m, B1?{u1,u2,...,uk},B2?{v1,v2,...,vk}, then we call e1 and e2 can be fuzzy constrain correlated. That is exist predication Pr, for c C(e1),p P(e2),c=Pr (u1,u2,...,un) , p=Pr (v1,v2,...,vm),(c,p) ? )2(eP  ~  )1(eC ~  ? .We call there are fuzzy causal relationships between e1 and e2, and there are fuzzy binary causal relationship R~ in set C(e1)? P(e2).

The notion of membership grade is formally defined as follows:  ),min(0.................................

),(   ),(  ),(  ),(~  mnkq  pcMat  i Wi  k  j j vjuW  q  i i viuW  pcR  ???  ? ?  ? ?  ? ???  (1)  ui,vi is corresponding attribute of c=pred (u1,u2,...,uk) and p=pred (v1,v2,...,vk).

Mat(c,p) is the number of matched attributes of c and p.

W(ui,vi) is the weight of attribute ui and vi, (ui,vi) [0,1]  We introduce the notion of W (ui,vi) as follow:         ??? ???   ?   ?  ? ?  (2)  For base attribute ui,vi,W(ui,vi) {0,1} and for non-base attributes ui,vi, the value of wi get from known knowledge, wi  [0,1].The support grade function ),(~ PCRSup  of fuzzy binary relationship R~  in set C(e1)?P(e2) is specified formally through the following Definitions:   pi P(B),cj C(A),i [1,m],j [1,n] and support grade function ),(~ PCRSup gets value in open interva (0,1).

MAT C,P express the number of matched elements of set C and P. when value of ),(~ PCRSup  bigger than  threshold of support grade Tsup, Tsup?(0,1), we figure there exist fuzzy binary causal relationship R~  in set C(e1)? P(e2).

4.2 Traffic rules base on wavelets.

Big Data must depend on distributed systems and  mechanisms. We know that distributed security monitor systems models are always characterized by high false alarm rates. It has been convincingly demonstrated and confirmed by many studies that network traffic signals, such as the time series of number of bytes or packets arriving at a network device, exhibit fractal properties such as self-similarity, burst, and long-range dependence (LRD) [5].

However, wavelet based model combines the advantage of the tree structure for fast and simple synthesis with the ability to simulate scaling behavior such as long-range dependence, another prominent property of network traffic.

We propose a wavelet-based distributed model for Big Data security monitor system, this model provide a different view of it. It not only analysis the traffic flowing in wavelet domain over individual nodes, but also investigate traffic patterns across multiple distributed nodes in a network domain.

That is to say, it adapts to the requirements of Big Data.

The wavelet tool organizes the data into strata via corresponding coefficients of wavelet decomposition. The lower strata contain very sparse filtered information that can be thought of as sophisticated aggregations of the original data.

We refer to that part of the representation as the low-frequency representation. In contrast, the very high strata in the hierarchy capture fine-grained details of the data, such as spontaneous variations. These are referred to as the high-frequency strata.

We derive from a given signal x three kinds of output signals, which based on wavelet analyses.

? The Low frequency: part of the signal, obtained by synthesizing all the low-frequency wavelet coefficients at the low frequency levels. The L-part of the signal should capture patterns and anomalies of very long duration: several days and up.

? The Mid frequency: part of the signal, obtained by synthesizing the wavelets coefficients at the middle frequency levels.

? The High frequency: part of the signal is obtained by synthesizing the wavelet coefficients in the first few frequency levels. Most of the data in the H-part consists of small short-term variations, variations that we think of as ?noise? and do not aid us in our anomaly detection objective. We can set to zero all coefficients whose absolute value falls below a chosen threshold to decrease ?noise?.

Through choose proper mother wavelet and proper threshold, we can make the signal have exquisite part characteristic at different frequency strata which can distribute attack signs clearly. The mid and high frequency components of the signal can expose short-lived attacks such as DOS, and the low frequency always discuss anomalies of long duration.

We focus on short-lived attacks, the ?local deviation? in the high frequency representation exposes the beginning and end of short-lived events and the local variability in the mid frequency filters expose their duration.

On top of decompose the signal to different frequency, we analyses the different frequency signal to discuss the attack behaviors. It is useful for identifying anomalies from Big Data.

On the other hand, we noticed that the traffic behaviors on topologically related links are related. Big Data provides a large number of relevant data, we use our wavelet analysis method to observe traffics on related network nodes and find that if an attack occurred, some decomposed frequency on different network nodes can display the fact similarly. This phenomenon explains that comparing traffic flows on multi- link is useful for identifying anomalies.

4.3 inter-related rules correlation base on sequence pattern Big Data definitely and desperately desires the support  from network security, especially when real time or near real time applications are demanded. We should consider the relevance of data from different devices and network audit records between traffic data, which we call inter-related rules correlation. Sequence pattern correlation is to dig out the correlation between different records.

When different attacks take on, often leaving all traces of these different devices in the network logs and traffic information to be reflected, and produce Big Data. So we correlate between the rules and dig out the model of abnormal events scene. We focus on the relationship between analytical data. During inter-related rules, the same need to pre-set the minimum confidence and minimum support.

Inter-related rules Correlation predict anomaly base on known abnormal events sequence. The difference between these events is sub-events at different time. Association rules between sequential patterns are looking for relevance of time  ),(  ),( ),(  ),min(   ~  ~ PCMAT  pc PCSup  mn  k kkR  R  ? ?? ?     between events. Therefore, we can also see the event timing analysis with time as the key attribute for the association analysis.

In data mining, there are many algorithm related to sequential pattern mining like Apriori, GSP, Prefix-Span and so on. We study the abnormal network behavior patterns with them.



V. CONCLUSION  Data is the most important thing of information age. The core competitiveness of countries will largely depend on speed and capacity of transfer data into information and knowledge,  especially depend on the technical capabilities of Big Data.

This paper presents some ideas for network security  monitor system on Big Data environment, and analysis the behavior of a large number of heterogeneous types of security incidents. We focus on the core problem of the system on Big Data environment: correlation algorithms and knowledge representation.

We organize the Big Data through data cleaning, data integration and data reduction and then get the core data. We analysis the correlation algorithm of core data, mainly on fuzzy constraint correlation algorithm based on prerequisites and consequences of security event, traffic rules base on wavelets and inter-related rules correlation base on sequence pattern. In  the original technology accumulation conditions, we build the prototype system that can respond to some typical events, there are still a lot needs to be perfect, correlation algorithms and knowledge indicated that they needed further consideration.

