Pattern Recognition, Informatics and Mobile Engineering (PRIME) February 21-22

Abstract?Association rule mining is one of the most important and well-researched techniques of data mining, that aims to induce associations among sets of items in transaction databases or other data repositories. Currently Apriori algorithms play a major role in identifying frequent item set and deriving rule sets out of it. But it uses the conjunctive nature of association rules, and the single minimum support factor to generate the effective rules. However the above two factors are alone not adequate to derive useful rules effectively. Hence in the proposed algorithm we have taken Apriori Algorithm as a reference and included disjunctive rules and multiple minimum supports also to capture all possible useful rules. Although few algorithms [4][5] are dealing the disjunctive rules and multiple minimum supports separately to some extent, the proposed concept is to integrate all into one that lead to a robust algorithm. And the salient feature of our work is introducing Genetic Algorithm (GA) in deriving possible Association Rules from the frequent item set in an optimized manner. Besides we have taken one more add-on factor ?Lift Ratio? which is to validate the generated Association rules are strong enough to infer useful information. Hence this new approach aims to put together the above points to generate an efficient algorithm with appropriate modification in Apriori Algorithm so that to offer interesting/useful rules in an effective and optimized manner with the help of Genetic Algorithm.

Keywords-Apriori; Genetic Algorithm; Lift ratio; Multiple Minimum Support;  Disjunctive Rules

I.  INTRODUCTION  A. Association rule mining in Data Mining: Data mining is the task to mining the useful meaningful  information from data warehouse. It is the source of inexplicit, purely valid, and potentially useful and important knowledge from large volumes of natural data [8].The selected knowledge must be not only precise but also readable, comprehensible and ease of understanding.

There are a many of data mining task such as ARs, sequential patterns, Classification, clustering, time series, etc., and there have been lots of techniques and algorithms for these tasks and different types of data in data mining. When the data consist continuous values, it becomes hard to mine the data and some special techniques need to be prepared. Association rule basically use for finding out the useful patterns, relation between items found in the database of transactions [9].

Association rule mining generally experimented to find all rules that satisfy user-specified minimum support and minimum confidence constraints [3].

The important factor that makes association rule mining practical and useful is the minsup. It is used to limit the number of rules generated. However, using only a single minsup implicitly assumes that all items in the data are of the same nature and/or have similar frequencies in the database. This is often not the case in real-life applications. In many applications, some items appear very frequently in the data, while others rarely appear. If the frequencies of items vary a great deal, we will encounter two problems:  1. If minsup is set too high, we will not find those rules that involve infrequent items or rare items in the data.

2. In order to find rules that involve both frequent and rare items, then minsup to be kept very low. However, this may produce too many rules.

So when one common support is fixed as minimum support for all the items, the rules which are not frequent occur but majorly contributing towards profit may get lost without notice.

For example, in a supermarket transaction data, in order to find rules involving those infrequently purchased items such as food processor and cooking pan (they generate more profits per item) very minimum support needs to be set ; but due to this the unwanted and rare items will not be get pruned. Hence fixing multiple minimum support for each items have become significant.

B. Conjunctive and Disjunctive rules: Association rule mining deals conjunctive rules majorly. A  con-junctive association rule is an implication in the form of X  Y, where X (the antecedent rule) and Y (the consequent rule) are sets of items, and X?Y =?. But using disjunctive rules, extensive rule sets which are very much useful in mining the dataset can be found out effectively.

At times disjunctive rule sets are also preferred to infer interesting rules. For example ideal rule set for the below query ?If classes B or C or D are committed, what is the chance that A is also committed?? would be    B OR C OR D A.

C. Apriori Algorithms and Genetic Algorithms: The Apriori Algorithm an influential algorithm for mining  frequent item sets for Boolean association rules.

Apriori Algorithms works on the below two factors,  i). Generate all large item sets that satisfy minsup. ii).

Generate all association rules that satisfy minimum confidence (minconf) using the large item sets.

Two user-defined thresholds for association rules are called minimal support and minimal confidence. Supports of an association rule is defined as the percentage/fraction of records that contain XUY to the total number of records in the database or repository. Confidence C of an association rule is defined as the percentage/fraction of the number of transactions that contain XUY to the total number of records that contain X. If s and c exceed minimal support and minimal confidence values, respectively, then the association rule X ?Y must be induced.

In the proposed approach Apriori approach to find out the frequent item sets and incorporate Genetic Algorithm to derive the association rules from it.

Besides support and confident factors are not adequate to validate the rule sets. Hence here another factor i.e. Lift- is suggested to analyse and validate the effectiveness of the rules.

Because confident? only focuses on the antecedent not the consequent.

D. Lift Ratio A high value of confidence suggests a strong association  rule. However this can be deceptive because if the antecedent and/or the consequent have a high support, we can have a high value for confidence even when they are independent. A better measure to judge the strength of an association rule is to compare the confidence of the rule with the benchmark value where we assume that the occurrence of the consequent item set in a transaction is independent of the occurrence of the antecedent for each rule. This benchmark can be found out from the frequency counts of the frequent item sets. The benchmark confidence value for a rule is the support for the consequent divided by the number of transactions in the database. This enables to compute the lift ratio of a rule. The lift ratio is the confidence of the rule divided by the confidence assuming independence of consequent from antecedent. A lift ratio greater than 1.0 suggests that there is some usefulness to the rule. The larger the lift ratio, the greater is the strength of the association. With the lift value, the importance of a rule can be validated in an effective manner. However no minimum lift in the settings similar to minimum support or minimum confidence can be set. The lift is a value between 0 and infinity. A high value of confidence suggests a strong association rule.

A better measure to judge the strength of an association rule is to compare the confidence of the rule with the benchmark value where the assumption is that to assume the occurrence of the consequent item set in a transaction is independent of the occurrence of the antecedent for each rule. The benchmark can be found out from the frequency counts of the frequent item sets. The benchmark confidence value for a rule is the support  for the consequent divided by the number of transactions in the database. The lift ratio is the confidence of the rule divided by the confidence assuming independence of consequent from antecedent. A lift ratio greater than 1.0 suggests that there is some usefulness to the rule. The larger the lift ratio, the greater is the strength of the association.

Confidence and Life factors are calculated as below,  Ain  items  thecontaining ons transactiof No.

C andA in  items  theof all containing ons transactiof No.Confidence    A ofSupport AUC ofSupport    ons transactiof no. Total items consequent  thehaving ons transactiof No.Confidence Expected  Hence  Confidence Expected ConfidenceLift  The above factor can also be included while validating any rule set.

E. Disjunctive Rules: Let X = {i1, i2...in} be a set of items. XC = {i1 AND i2  AND ? AND in} or simply {i1i2...in}  is a conjunctive term of X, and XD = {i1 OR i2 OR ? OR in} is a Disjunctive term of X. The possible rule is of one of the following types, involving conjunctive and disjunctive terms from the set of items X U Y| X ? Y = ?[2][5].

TABLE I.

Type Support Confidence   Xc?? Yc s = P(XC U YC) c = P(YC | XC) Xc ??YD s = P(XC U YD) c = P(YC | XD) XD ??Yc s = P(XD U YC) c = P(YD | XC) XD ??YD s = P(XD U YD) c = P(YD| XD)   F. Rule sets List: XY Z ??VW          - type XC ? YC XY Z ?V OR W          - type XC ? YD X OR Y OR Z ? VW                - type XD ? YC X OR Y OR Z ? V OR W        - type XD ? YD The number of rules that are found by the Associations  mining function can be reduced by using rule filters if the number of frequent item sets is high. Rule filters are a powerful way to limit the amount of rules to be generated or the content of the rules. This parameter determines the maximum number of items that occur in an association rule. In the above table maximum rule length is 5 and maximum antecedent allowed is 3; the maximum consequents allowed are 2. But in the example the filters are not used as the number of frequent items are only 3(A, C, E).

G. Multiple Minimum Supports: In many data mining applications [4], some items appear  very frequently in the data, while others rarely appear. If minsup is set too high, those rules that involve rare items will not be found. To find rules that involve both frequent and rare items, minsup has to be set very low. This may cause combinatorial explosion because those frequent items will be associated with one another in all possible ways. The disadvantage of support is the rare item problem. Items that occur very infrequently in the data set are pruned although they would still produce interesting and potentially valuable rules.

The rare item problem is important for transaction data which usually have a very uneven distribution of support for the individual items.

E.g., Consider four items A, B and C in a database. If the minimum support count is 10 %, then we may lose the rule set AB if it had support 7% .But assume now we have multiple minimum item supports are  MIS (A) = 20%  MIS (B) = 3%  MIS(C) = 4%  And their actual supports: {A 18%, B 4%, C 3%}  Then the rule AB is not discarded as it satisfies the rule min (MIS (A, B))>=min (Support (A<B)).

Hence there could be a modification in Apriori algorithm accordingly.



II. PSEUDO CODE FOR THE PROPOSED ALGORITHM  Input: A set  of n transaction data T , a set of p items to be  purchased , each item ti, with a minimum support value mi, i=1 to p , and a minimum confidence value.

Output: A set of association rules in the criterion of the maximum  values of minimum supports.

Procedure:  Step 1: Calculate actual support of each item tk,  k=1..p. Derive Stk (actual support) Step2: If stk>= mtk  (min_predefined_min_support), populate in Large item set Li  Step 3: Generate candidate item set for Li and find out support Sik.

Step 4: If sik >=mik then populate in L i+1.

Step 5: If L r+1 is null then Stop else repeat step 3  and 4. This will give Frequent Item Set (FIS).

Step 6: Generate bit pattern for FIS for all  possible LFH and RHS rule sets.

Step 6:  Construct all possible rule sets  (Disjunction and conjunction) as per proposed rule guides in Rule sets List.

(The separate procedure to generate Disjunctive and conjunctive rule is given below)  Step 7: Calculate confident and Lift factors to validate effective rules.

Step 8: Output the rules which are greater than minimum confident and Lift greater than or equal to 1.

H. Generation of Disjunctive and conjunctive rules (Step 6): Step 1: Create function whose parameters are  Dataset, list_of_antecedents-A , list_of_consequent ?C List of A and C can be generated using the following conditions using Genetic Algorithm.

Min (A) =Cnt (FIS)-[Cnt (FIS)-1] Max (A) =Cnt (FIS)-[(Cnt (FIS)-(Cnt (FIS)-1))] Example, If Frequent Item Set (FIS) =3 then Maximum Antecedes=2 and Minimum Antecedents =1 This holds true for consequents as well, hence Min(C) = Cnt (FIS)-[Cnt (FIS)-1] Max(C) = Cnt (FIS)-[(Cnt (FIS)-(Cnt (FIS)-1))]   [Note: A- Antecedent; C-Consequent; Cnt- number of frequent item set Bit pattern for the frequent item set along with operators are like in Table VI.

And the function returns interesting rules as per Rule sets like in Table VIII]  Step 2: Find out allowed antecedents (A) and Consequent(C) Step 3:  For each Item set A and for each item set C, a) Create an offspring when bit pattern (A) is not equal  to bit pattern(C).

b) If Bit pattern (A) and/or Bit pattern(C)>=  min_predefined_min_support then return the rule A C c) Else Prune the rule.

Step 4: Return all valid rules

I. Example: An example is given to demonstrate the proposed algorithm [3]. Assume that there are 10 transactions shown in dataset.

Each transaction consists of TID- Transaction ID and items purchased.

TABLE II.

TID Items 1 ABDG 2 BDE 3 ABCEF 4 BDEG 5 ABCEF 6 BEG 7 ACDE 8 ABE 9 ABEF 10 ACDE      Predefined minimum support for each items are as follows (mtk).

TABLE III.

Item A B C D E F G Min_sup 0.4 0.7 0.3 0.7 0.6 0.2 0.4   Actual support values of all items are as follows (stk=ck/n)  TABLE IV.

Item A B C D E F G Support 0.7 0.8 0.4 0.5 0.9 0.3 0.3   The actual support values are compared with the predefined  minimum values. Only A, B, C, E and F satisfy the condition stk >= mtk .

So L1= {A, B, C, E, F}. Next candidate set can be generated from L1 for 2 item sets based on the support as follows,  TABLE V.

2 Item A,C A,E B,E C,F Support 0.4 0.6 0.7 0.2   The actual support of A and C are 0.6 and 0.4; and the  minimum of their minimum support is 0.4.Similarly the support for other items set found out. Hence Support of each item in the above table is compared with the min. of minimum predefined support.  Only {A, C}, {A, E}, {B,E} are holding good for this condition.

Now L2 = {{A, C}, {A, E}, {B, E}}.

Now generate C3 for 3 item sets, resulting L3= {A, C, E} hence, FIS = {A, C, E}.Iterations will not proceed further as L3 is null.

The possible association rules can be generated as per below table, First column in the below table denotes whether it is Antecedent or Consequent; 1-Antecedent 0-Consequent.

TABLE VI.

Antecedent/Consequent A C E 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1     J. Bitwise items storage: In order to read and scan the item sets for the calculation,  each item needs to get encoded with respect to the transaction into bits.

Here the encoding style could be 1 for presence of item in transaction and 0 for absence.

K. Bit pattern for Items:  TABLE VII.

Item Transaction ID Bit Pattern Count A {TID1,ITD3,TID5,  TID7,TID8,TID9, TID10}  1010101111 7  B {TID1,TID2,TID3, TID4,TID5,TID6, TID8,TID9}  1111110110 8  C {TID3,TID5,TID7, TID10}  0010101001 4  D {TID1,TID2,TID4, TID7,TID10}  1101001001 5  E {TID2,TID3,TID4, TID5,TID6,TID7, TID8,TID9,TID10}  0111111111 9  F {TID3,TID5,TID9} 0010100010 3 G {TID1,TID4,TID6} 1001010000 3     The following possible rules can be generated as per Rule sets List 1,  ?If A is bought then C and E also bought?  A??CE ?If A is bought then C or E also bought ?  A?C or E Similarly the below possible rules can be derived,  Confident = Support (AUC)/Support (A)  Lift = Support (AUC)/Support(C)  Where A-Antecedent C-Consequent  TABLE VIII.

Rule Confident Lift Antecedent Symbo  l Conseq  uent  E ?  AC 0.444444444 1.111111  C+E ?  A 0.666666667 0.952381  A ?  CE 0.571428571 1.428571  AE ?  C 0.666666667 1.666667  A ?  C+E 0.857142857 0.952381  E ?  A+C 0.666666667 0.952381  A+E ?  C 0.4 1      A+C ??  E 0.857142857 0.952381  C ??  AE 1 1.666667  CE ??  A 1 1.428571  AC ??  E 1 1.111111  C ??  A+E 1 1   If predefined minimum confident is 0.75 then the rules whose confident <0.75 can be pruned .Hence the result set is as follows,  TABLE IX.

Rule Confident Lift Antecedent Symbol Consequent  A ?  C+E 0.85714285 7 0.952381  A+C ?  E 0.85714285 7 0.952381  C ?  AE 1 1.666667  CE ?  A 1 1.428571  AC ?  E 1 1.111111  C ?  A+E 1 1   From the above table it is inferred that rules having confident greater than minimum confident and lift ratio for the same is almost 1 or more. This confirms that all these rules have high dependency between antecedent and consequents and thus are strong and useful rules.

L. Genetic Algorithm: Genetic Algorithm (GA)[1]  incorporates Darwinian  evolutionary theory with sexual reproduction. GA is stochastic search algorithm modelled on the process of natural selection, which underlines biological evolution. GA has been successfully applied in many search, optimization, and machine learning problems.GA works in an iteration manner by generating new populations of strings from old ones. Every string is the encoded binary, real etc., version of a candidate solution .An evaluation function associates a fitness measure to every string indicating its fitness for the problem. This type of representation is relative to position. Presence of 1 at ith position indicates occurrence of the item in transaction[i].

Similarly presence of 0 at jth position indicates absence of item in transaction[j].

For example,  Bit pattern for A can be given as 1010101111 based on its availability in the transactions in table V. Hence conjunction and disjunction of few rules can be evaluated and its relative count could be calculated as follows.

M. Boolean Operation on bit pattern for few rules:  TABLE X.

Items Operation Result Count A and C {1010101111} and  {0010101001} {001010100 1}   A or C {1010101111} or {0010101001}  {101010111 1}   (A or C) and E  ({1010101111} or {0010101001}) and {0111111111}  {001010111 1}   N. Genetic operators:   Genetic Algorithm uses genetic operators [7] to generate the offspring of the existing population. This section describes three operators of Genetic Algorithms that were used in GA algorithm: selection, crossover and mutation.

1) Selection: The selection operator chooses a chromosome in the current population according to the fitness function and copies it without changes into the new population.GA algorithm used route wheel selection where the fittest members of each generation are more chance to select.

2) Crossover: The crossover operator, according to a certain probability, produces two new chromosomes from two selected chromosomes by swapping segments of genes.

3) Mutation: The mutation operator is used for maintaining diversity. During the mutation phase and according to mutation probability, 0.005 in GA algorithm, value of each gene in each selected chromosome is changed.



III. CONCLUSION This paper proposed an integrated algorithm for useful and  effective association rule mining to capture rare but not frequent items; using generic algorithm to derive all possible conjunctive& disjunctive rules sets using genetic algorithm; lift factor to analyse the strength of derived rules. This approach is novel because  Genetic Algorithm is used in generating rule set  An integrated approach is proposed in combining  Multiple minimum support  Conjunction and disjunction rule generation  Lift factor to validate the result set

IV. FUTURE WORK The major challenge in this approach is ?time taken?. In  future it is planned to integrate UML model /multi level data mining to analyse the dataset based on their hierarchy before they get into the algorithm. Besides planning to identify the redundant item sets in the early stage to avoid the time taken during rule set generation. And there is also a plan to compare the proposed algorithm with other existing algorithms if any [6] to validate the robustness and effectiveness. The scope of      including negative rules into the proposed algorithm is also lined up in the future plans.

