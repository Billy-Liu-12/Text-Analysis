A Clustering Based Approach for Domain Relevant Relation Extraction

Abstract: Most existing corpus based relation extraction  techniques focus on predefined relations. In this paper, a clustering based method is presented for domain relevant relation extraction including both relation type discovery and relation instance extraction. Given two raw corpora, one in the general domain, one in an application domain, domain specific verbs connecting different instances are extracted based on syntactic dependency as well as a small set of domain concept instance seeds. Relation types are then discovered based on verb clustering followed by relation instance extraction. The proposed approach requires no predefined relation types, no prior training of domain knowledge, and no need for manually annotated corpora. This method is applicable to any domain corpus and it is especially useful for knowledge-limited and resource-limited domains. Evaluations conducted on Chinese football domain for relation extraction show that the approach discovers various relations with good performance.

Keywords:  Relation extraction; relation type discovery; verb clustering; domain verb extraction; information extraction  1. Introduction  With the abundance of information available over the Internet, there is an increasing need for building and updating domain knowledge base automatically for NLP related applications such as IR, IE, MT, summarization and QA systems. Terms, as the lexical units of a domain, are the most fundamental units of knowledge. Yet they are not as useful unless their relations are also known.

Suppose a binary relation is represented by a three tuple <R_Type, CTm, CTn> where R_Type indicates the relation type, CTm and CTn represent the two concept terms having the relation type R_Type. The identification of binary relations involves two parts. The first part is to identify the relation types such as <Participate_in, Team, Match> which represents the fact that a Team can participate in a Match. The second part is to identify relation instances such as [?Participate in?, ?China?,    ?Asian Cup?] to indicate that the China Team actually participated in the Asian Cup. Most relation extraction algorithms extract instances of predefined relation types by either using contextual information or internal information [1-3]. Relation instance extraction techniques are mainly pattern-based or classifier-based.

Currently, in mid-level ontology constructions, the focus is on fixed relation types such as hypernums and kind-of relations which are generally applicable to all domains [1]. The focus of this work, however, is on mining relation types and relation instances that are relevant to a specific application domain such as the sports domain.

It is not easy to discover new relation types without supervised training in a specific domain. Some prior domain specific knowledge is required in new relation type discovery and such dependency makes the technique difficult to be applied to different domains.

The challenge in this work is to discover domain relevant relation types and to extract relation instances without specifying their types in advance when an application domain corpus is provided.

In this paper, a novel approach for domain relevant relation extraction based on verb clustering is proposed.

Aside from a domain corpus and a general corpus, the only input required is a small set of concept term instances as seeds. After bootstrapping of more concept instances, different types of relations are discovered using information in HowNet, followed by relation instance extraction. Compared to traditional relation extraction techniques, the proposed approach requires no predefined relation types, no prior training of domain specific knowledge, and no need for manually annotated corpora. Thus it is applicable to any domain specific corpus. It is especially useful for knowledge-limited and resource-limited domains.

The rest of this paper is organized as follows.

Section 2 presents related works. Section 3 describes the design of the algorithms. Section 4 presents the experiments and evaluations. Section 5 is the conclusion.

2. Related works  Relation instances can be extracted using direct context, indirect context, or internal information.

Direct context refers to the context information where a relation is explicitly represented or embedded.

Thus, extractions can be done through pattern matching, association rule mining, classification, and statistical measurement, etc.. For instance, pattern-based techniques [1] are applied to find instances of hypernym relations. However, recall using pattern-based methods is low because fixed patterns do not have high occurrences in corpora. To improve recall, some researchers [4] take WWW as the corpora and use search engines directly such as Google Search to obtain more instances.

Automatic Content Extraction (ACE) has held several evaluations and competitions on relation detection between entities. Classification algorithms, especially the SVM algorithm [5], were shown to be effective in the evaluations of ACE. The focus of ACE is, however, on relation instance extraction with known relation types.

Indirect context refers to context information which does not directly represent a relation, yet can be used to identify relations. For example, comparison of context of different concepts can be used to induce a relation instance. Hierarchical clustering algorithms [2] and Formal Concept Analysis (FCA) using context collocations [6] are applied to concept relation extraction to identify relations that satisfy partial ordering relations such as kind-of relation.

Internal information is also used for relation extraction in some studies such as ?Semantic Interpretation? [3]. It identifies the semantic relations held among concept components using sense disambiguation for each component of a complex term.

Most relation extraction techniques are dependent on predefined relation types based on subjective and manual work. Davidov et al. [7] introduced a novel method for relation discovery without the need for predefined relation types. It uses the Google search engine to identify patterns with high frequencies. The algorithm presented in this paper is inspired by Davidov?s work. But the approach and the data used are quite different.

3. Algorithm Design  The algorithm is proposed based on the fact that verbs are the most fundamental units to represent relations, especially relations to identify instances. All relation types and relation instances in this algorithm are extracted from a raw domain specific corpus CorpusD. A general domain corpus CorpusG serves to collect some statistical information for extracted verbs only. The proposed method consists of 4 steps listed below.

Step 1: Given a small set of concept term instances as seeds associated with different concepts, more concept instances are extracted from CorpusD  Step 2: Domain verbs associated with the extracted  concept instances having statistical significance in CorpusG are extracted using syntactic information.

Step 3: Relation types are discovered based on verb clustering using semantic closeness as similarity measure based on HowNet.

Step 4: Relation instances are extracted based on patterns associated with different relation types.

Details of each of the above steps are described in the following sub-sections.

3.1. New Concept Instance Extraction  Concepts are represented by domain specific terms.

Concept terms can be identified using terminology extraction techniques [8-10] which can be used directly for this work. Even though terms are lexical units and can represent concepts, the same term can be used to represent different concepts in different context or in different domains. In this study, the terms concept term and concept are used interchangeably because the specific concept a term represents is identified by their associations with other verbs and concept terms.

The set of concept term instances CTList takes the form of [CTm, CT_Instmi] for each entry where CTm is a concept term and CT_Instmi is its i?th instance. CTList serves as seeds which are manually constructed. They can be very small because they are only used for bootstrapping to find more concept term instances before relation type extraction takes place.

The New Concept Instance Extraction Algorithm (NCIE) is given below.

(1) For each concept term instance CT_Instmi in CTList, mark CT_Instmi in the domain corpus CorpusD as a non-divisible lexical unit.

(2) Identify all coordinate/parallel relation COO(wi, wj) from CorpusD  using a dependency parser. For each COO(wi,   wj), if (wi?CTList) and (wj?CTList), [CTm, wj ] is a new instance candidate where CTm is the corresponding concept term of wi. For example, ?????(China) is a given instance of the concept term ?Team?. ??????? ???????????????(China and Australia will play a warm-up match in Guangzhou) is a sentence in the corpus which indicates the coordinate relation between ?? ??(China) and ???????(Australia).

Based on the dependency parser, COO(?? ?(China), ?????(Australia)) is then identified. Consequently, [Team, ????? ??(Australia)] is considered a new concept term instance candidate.

(3) For each new concept instance candidate wj, suppose there are M different CTm for m=1,...,M. If a majority of the wj belongs to a single CTm, wj is considered a new instance of CTm. The majority calculation Maj(wj) is based on the following formula.

? =  = M  m jm  jmF j  wF  wF )Maj(w m   )(  ))((max  arg (1)  Where Fm(wj) is the number of times wj takes the concept CTm. If Maj(wj) is smaller than a threshold TM,  wj is filtered out.

(4) Suppose the function RP(Maj(wj)) gives the rank position of wj in the extracted concept instances. Rank all the wj by RP(Maj(wj)) and the top NNCI number of candidates are considered new concept instances and are added to the CTList. NNCI is an algorithm parameter to be determined experimentally.

3.2. Domain Verb Extraction  The domain verb extraction algorithm, referred to as VE, extracts verbs having certain dependency relations with concept instances described below.

(1) For each concept term instance [CTm, CT_Instmi] in CTList, mark all CT_Instmi in CorpusD as a non-divisible lexical unit.

(2) Segment the remaining text in CorpusD.

(3) Identify subject-verb relations SBV(VSBV,  CT_Instmi) and verb-object relations VOB(VVOB, CT_Instnj) using a dependency parser. For each SBV(VSBV, wSBV) and VOB(VVOB, wVOB) pair that occurs in the same sentence, if  VSBV = VVOB = Vk, Vk is a domain verb candidate for a relation type candidate <Vk , CTm, CTn>. For example, in the sentence ?????????????????(China lost to Australia in warm-up match). SBV(?? ??(lose to), ?????(China)) and VOB(?? ??(lose to), ???????(Australia)) pair are figured out by using the dependency parser. Since ?????(China) and ???? ?? ?(Australia) are instances of concept term ?Team?, <????(lose to), Team, Team> is considered a relation type candidate.

(4) Obtain termhood measure of Vk as TH(Vk) defined by the ratio of frequency FreD(Vk) in CorpusD to frequency FreG(Vk) in CorpusG as shown below   )( )()(  kG  kD k VFre  VFreVTH =         (2)  (5) Use the rank position RP(TH(Vk)) to sort all   the extracted verbs Vk. The top NVE number of items are considered domain verbs where NVE is an algorithm parameter.

3.3. Verb Clustering Based Relation Type Discovery  Verbs are the most important lexical units to represent relations. A set of verbs with similar meaning and usage represents the same relation type. Relation types can be discovered based on verb clustering.

The Relation Type Discovery algorithm (RTD) is based on verb clustering without giving the number of clusters in advance. For a given pair of concept terms CTm and CTn, suppose there are Qmn number of relation type candidates  <Vq , CTm, CTn>, q=1, ?, Qmn. The exclusive clustering algorithm similar to the one used in [11] clusters the set of Vq to obtain a set of verb clusters VCmn. Each VCk ?VCmn is a verb cluster which contains a set of verbs with similar meaning. VCk is considered a synset of a relation type. As a result, each <VCk, CTm, CTn> is a discovered relation type (VCk=R_Typek). For example, <????(lose to), Team, Team> is a discovered relation type. Where ????(lose to) is a name of the relation type which contains a set of verbs (????(lose to), ????(lose out to) and ????(be defeated by)) with similar meaning to represent the same relation.

For two verbs Vi and Vj in RTD, the similarity function Sim(Vi, Vj ) used in clustering is calculated using semantic information provided by HowNet [12] as  ji  S ji NN  NVVSim +  = 2),(            (3)  where NS denotes the number of identical sememes in the DEFs (the concept definition in HowNet) of Vi and Vj , Ni and Nj denote the number of sememes in the DEF of Vi and Vj, respectively.

3.4. Relation Instance Extraction  The relation instance extraction algorithm, referred to as RIE, extracts relation instances described as follows.

Given a discovered relation type <VCk, CTm, CTn>, where VCk ?VCmn, and Vkq ?VCk, a relation instance [Vkq, CT_Instmi, CT_Instnj] is extracted if SBV(Vkq, CT_Instmi) and VOB(Vkq, CT_Instnj) occur in the same sentence.

Each extracted relation instance candidate RC_Inst = [Vkq, CT_Instmi, CT_Instnj], is further ranked by the confidence value ConV(RC_Inst) as the product of the confidence values of all its elements given as  )InstConV(CT)InstConV(CT )ConV(VInst)ConV(RC  njmi  kq  __ _  ?  ?=       (3)  The confidence value of a concept term instance is defined below        (4) where its value is one if the concept term instance is a concept term instance seed. Otherwise, it is proportional to its reversed rank by Maj(CT_Inst). Similarly, the confidence value of a verb is defined as a fraction of its reversed rank by termhood TH(Vkq) as given below  )(1  + +  = VE  kqVE kq N  )V-RP(THN )ConV(V       (5)  4. Experiment and Discussion  4.1. Data Preparation  The experiments are conducted on Chinese text.

The domain corpus CorpusD is 7.2M in size consists of 4,748 Chinese football news articles downloaded from the Sina web site (www.sina.com.cn). The general corpus CorpusG is 4.1M in size from Peoples Daily Newspaper in January 1998. The small set of concept instances as seeds are shown in Table 1 which consists of 79 instances of only 4 concepts in the football domain.

Table 1. Instances Used for Experiments  Concept Instance Number Example Player Chinese  players 26 ??  (Zong Lei) Coach Chinese  coaches 5 ??  (Duikovic) Team Asian  teams 44 ???  (China) Match   Famous cups  4 ??? (Asian Cup)   Four separate sets of experiments are conducted on  new concept instance extraction, domain verb extraction, relation type discovery and relation instance extraction.

In each set of experiments, cascading errors caused by the former steps including the use of the applied tools (such as Chinese word segmenter and dependency parser) are not excluded. Evaluations thus reflect real data including cascading errors.

A simple verb extraction algorithm called VEPos is used as the baseline for comparison. VEPos is the same as the proposed VE given in Section 3.2 except that in Step 3, it first identifies two concept instances CT_Instmi and CT_Instnj in a sentence. Then, if there is only one verb Vkq between them, Vkq is considered a domain verb candidate for the relation<Vkq, CTm, CTn>. All subsequent steps using the result from VEPos will be given a subscript label including RTDPos and RIEPos.

The focus of evaluation is on precision as it is important to identify correct relations so as to prove the usefulness of the method. As some relations may not be  explicit and are thus difficult to measure, recall is not explicitly measured in this paper.  However, the threshold values of the algorithms for ranking are indications of recall in some extent.

4.2. Evaluation on New Concept Instance Extraction  Each extracted concept instance [CTm, CT_Instmi] can be measured in two ways. In the more strict precision measure, the instance is correct if both CTm and CT_Instmi are correctly matched. In the loose precision measure, the instance is considered correct if CT_Instmi is an instance of the domain although it does not necessarily match the concept CTm. Figure 1 shows the performance of the proposed algorithm for new instance extraction in terms of precision with different number of extracted new concept instances. NCIEStrict and NCIELoose indicate the evaluation using strict precision and loose precision, respectively.

0 20 40 60 80 100 120 140 160 180 200         Pr ec  is io  n  Extracted New Concept Instances (NNCIE)  NCIELoose NCIEStrict   Figure 1. Performance on New Instance Extraction  As shown in Figure 1, NCIEloose and NCIEStrict achieve 90.2% and 85% in precision, respectively, when the number of extracted new concept instances NNCIE reaches 200. Figure 1 also shows that the performance declines quite slowly with increased NNCIE. The figure indicates that the NCIE algorithm is efficient and relatively stable for new concept instance extraction.

4.3. Evaluation on Domain Verb Extraction  Figure 2 shows the precision of the proposed VE algorithm and the baseline algorithm VEPos for domain verb extraction by using only the set of concept instance seeds. An extracted verb is considered correct if it is a specific verb of the football domain. As shown in Figure 2, VE achieves 86% precision when the threshold of the extracted domain verbs NVE reaches 100. VE performs 6% better than VEPos which translates to improvement of precision of over 7.5%. It is interesting to know that VEPos still achieves 80% precision when NVE reaches 100        indicating that the proposed algorithm can extract domain verbs efficiently even without any syntactic information. Of course, VEPos should have less recall because verbs are extracted only if they exist singularly between two concept instances. It should be noted that the decline in performance of both algorithms are very slow once NVE reaches 60.  In practice, verb varieties are not as much as named entities and noun related concept terms. Thus, there is no expectation of a large NVE in any real application.

0 20 40 60 80 100         Pr ec  is io  n  Extracted Domain Verbs (NVE)  VE VEPos  Figure 2. Performance on Domain Verb Extraction with Seed Concept Instances Only  The number of extracted verbs should be directly affected by the number of concept instances used. To measure the effect of the newly extract concept instances to verb extraction, Figure 3 and Figure 4 show the results of using VEPos and VE with different numbers of extracted new concept instances.

0 20 40 60 80 100         With top 200 NCI With top 150 NCI With top 100 NCI With top 50 NCI Without NCI  Pr ec  is io  n  Extracted Domain Verbs (NVE)   Figure 3. Performance of VEPos  Figure 3 shows that the baseline VEPos algorithm is much more sensitive to the number of concept instances used. The higher the number of concept instances is, the higher the precision is evidenced by the blue curve showing that top 200 (including the given instances) is at  the top and the one using only the seed instances is at the bottom. The main reason is that the statistical information is more complete when using more instances which greatly help the performance of domain verb extraction. As shown in Figure 3, VEPos, when using 200 new extract concept instances, it achieves 91% precision when NVE reaches 100. Compared to the performance of VEPos without new instances which is 80% in precision, the improvement is over 13%.

Figure 4, however, shows a seemingly different picture for VE. Firstly, Top 100, Top 150, and Top 200 have basically the same performance shown as a merged line (blue colored line). Top 50 is the worst. The one with only seed instances is actually the best. The algorithm is syntactic-based and verbs are thus syntactically related to these concept noun instances in the first place. In other words, not much of any more evidence is needed when it is syntactic based. In fact the noises introduced by automatically extracted concept term instances can be counter productive compared to manually selected ones. However, when the number of verbs increases, all the 5 lines converge. This is again because there are only a limited number of domain specific verbs. In fact, there is little room for improvement because using seed instances can achieve precision of 91% at the low end when NVE is 100 and 97.5% at the high end when NVE is around 40.

0 20 40 60 80 100         With top 200 NCI With top 150 NCI With top 100 NCI With top 50 NCI Without NCI  Pr ec  is io  n  Extracted Domain Verbs (NVE)   Figure 4. Performance of VE  4.4. Evaluation on Relation Type Discovery  Evaluation on relation type discovery is conducted by considering each verb in a relation type cluster. For each relation type <VCk, CTm, CTn> extracted from RTD, VCk is a verb cluster. The evaluation of RTD is done through manual examination of each verb Vkq in VCk by two joint criteria: (1) if it is the right domain verb for CTm and CTn, and (2) if it is in the right verb cluster.

Only if both are considered correct, the verb is considered a positive case in the precision calculation.

As RTD uses exclusive clustering, each verb is counted only once in the precision calculation. To evaluate the second criterion, a manually prepared answer set is prepared to group all the verbs into different semantic classes using the extracted verbs from the VE algorithm with pairing to all the 4 seed concept terms. As a result, 40 manually clustered verb groups are identified to serve as the answer set, labeled as VCA where each cluster VCAi ? VCA for i=1,?, 40.  Different similarity threshold values used in the clustering algorithm can give different precisions. Due to limit of the paper, data shown here are taken using similarity value of 0.3 as its threshold which gives the best performance for using only the seed concept instance when the algorithm gives 47 clusters.

Figure 5 and Figure 6 show the result of using RTDPos and RTD with different number of extracted new concept instances. For RTDPos, as shown in Figure 5, the best performer is basically the Top 50 and the one using only seed instances. But the overall performance of this baseline algorithm is not so good because the precision is 57% when NVE is 100. The fact that more instances give more declines in performance is due to the nature of the algorithm which has no regards to syntactic structures.

Thus when there are more extracted instances, more noises are introduced.

0 20 40 60 80 100        With top 200 NCI With top 150 NCI With top 100 NCI With top 50 NCI Without NCI  Pr ec  is io  n  Extracted Domain Verbs (NVE)  Figure 5. Performance of RTDPos On the contrary, more extracted concept instances  can indeed improve performance of RTD. Similar to Figure 4, Top 100, Top 150, and Top 200 also have overlapped performance as a merged blue colored line in Figure 6. In fact the overall performance of RTD is much better than RTDPos. It achieves 76% precision by using new instances when NVE reaches 100, 57% at the same point for RTDPos with improvement of 33.3%. The reason for the improvement is that the noises introduced by the extracted new instances are weeded out when syntactic information is used.

0 20 40 60 80 100         With top 200 NCI With top 150 NCI With top 100 NCI With top 50 NCI Without NCI  Pr ec  is io  n  Extracted Domain Verbs (NVE)   Figure 6. Performance of RTD  4.5. Evaluation on Relation Instance Extraction  Experiments for relation instance extraction are conducted using RIE only because previous steps have shown that syntactic information is important. RIE is evaluated by precision. For an extracted relation instance [Vkq, CT_Instmi, CT_Instnj], it is considered correct if it represents a meaningful relation of the application domain.

0 50 100 150 200 250 300 350 400         Pr ec  is io  n  Extracted Relation Instances (NRI)  Without NCI With top 50 NCI With top 100 NCI With top 150 NCI With top 200 NCI  Figure 7. Precision of RIE Figure 7 shows the results of using RIE with  different numbers of extracted new concept instances.

This figure shows two important points. First, the more instances the algorithm uses, the better the precision is which indicates that using more extracted concept term instances can lead to better performance in relation instance extraction. The second point is that the higher the number of instances is, the more relation instances can be extracted. The one using only the seed instances can extract only 59 relation instances whereas with the extracted concept instances, many more relation instances are extracted. Top 200 can extract up to 400        relation instances. This means that using additional instances can really improve recall. Even though the performance degrades when NRI riches 60 from about 75% downwards, all of them are stabilized once NRI reaches 150 to about 66%.

Table 2 shows the number of new relation instances that are extracted not directly using the seed concept instances. The higher the number is, the higher the ability of the algorithm to identify new concept instances and new relation instances. It clearly shows that the ability to extract new concept term instances can lead to the identification of more relation instances that does not involve the seed concept instances.

Table 2. Extracted NRI Using RIE  NNCI None Top  Top  Top  Top  NNRI 0 39 122 190 206  4.6. Error Analysis  Experiments for domain relevant relation extraction show that the proposed approach has very good performance with limited resources. However, there is still room for improvement. Error analysis shows that there are three types of errors.

The first problem is caused by cascading errors from Chinese segmentation and dependency parser. In the field of sports, personal names are used quite frequently which can cause problem in segmentation.

This problem cannot be totally avoided using this approach as almost all dependency parsers for Chinese requires segmentation and PoS tagging.

The second problem is caused by identified verbs that are not domain relevant. For example, in the instance [??(found), ??(we), ??(problem)], ?? ??(found) is not a domain specific verb. It is identified wrongly because the cross domain validation (with the general domain) is not effective. This problem can be reduced somewhat if a general domain verb list can be provided. However, the solution may not be as easy as it sounds. Even though ????(found) is not a domain specific verb in the field of sports, it may be quite domain relevant in other fields such as in a science field.

Thus finding a list of general domain verbs is not as easy as it seems.

The third problem is caused by identifying verbs that are not appropriate for binary relations, yet there is no method in this algorithm to identify them. For example, [??(hope),???(Vladimir) ??(Li Yan)] is not complete as a binary relation. Unlike English where there are conjunctive words to mark the boundaries of phrases and clauses, many of them has to be determined by context in Chinese. This problem can be reduced if a list of such verbs is available. Or the  algorithm has to have the ability to identify binary relations, perhaps with a full parser.

5. Conclusion  In conclusion, this paper presents a verb clustering based approach for domain relevant relation extraction.

Aside from a small domain corpus, a small general corpus, and HowNet, the only input required in this study is a small set of concept instance seeds. Not only can it extract relation instances, but also discover new relation types based on verb clustering. The proposed approach requires no predefined relation types, no prior training of domain knowledge, and no need for manually annotated corpora.

Four sets of experiments for new concept instance extraction, domain verb extraction, relation type discovery and relation instance extraction are conducted on the Chinese football domain, respectively. It achieves 91% and 76% in precision for domain verb extraction and relation type discovery, respectively. The improvement is 33.3% on relation type discovery by using new concept instances. The algorithm has a much better recall when more concept term instances are used.

Results demonstrate that the proposed approach performs well for domain relevant relation extraction.

When applying to a different domain, the only work required is to prepare a small set of seed concept instances. For languages which have limited resources, this approach provides a fast and simple way to obtain relations on concept terms and relation instances for application-oriented ontology construction.

The algorithm can be further improved by making use of more information on verb behavior. More detailed experiments are needed to fine tune the clustering algorithm for different sizes of the extracted instances to achieve optimal performance for the algorithm as a whole. It is also important to incorporate terminology extraction algorithms to obtain more concept terms and investigate the scalability of the algorithm when there are more concept terms in question. Methods to automatically or semi-automatically extract concept term instances should also be explored.

Acknowledgements  The work described in this paper was partially supported by the Hong Kong Polytechnic University under CERG Grant B-Q941 and Central Grant: G-U297.

The first author was a research assistant at the Hong Kong Polytechnic University while working on this project.

