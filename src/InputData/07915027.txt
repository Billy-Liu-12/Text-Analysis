Analysis and Comparison of HUPID and FHIM  Algorithm for Dynamic Databases

Abstract? High utility itemset mining provides more useful and realistic results than frequent pattern mining   because of its ability to consider statistical correlation and semantic significance among the items. The state of art algorithms designed for mining high utility itemsets always consider the database as static. If they are used for dynamic databases for the same purpose, database is rescanned from the beginning for each update in data. If there is a provision to add new data to the previous analysis results,  existing and newly generated data can be efficiently handled and mining can be made more effective with reduced overhead of  database scans for dynamic databases.

This paper compares performance of HUPID-Tree algorithm over the state of art algorithm FHIM for mining high utility itemsets from dynamic databases and proves that HUPID-Tree algorithm performs better in terms of space and time because it uses incremental mining strategy and local itemset pruning technique.

Keywords? High utility itemset mining; Static and Dynamic Databases; Incremental Mining Strategy.



I.  INTRODUCTION In data mining, algorithmic processes are applied for  discovering useful and hidden information from the large databases. The purpose of recent researches in this field is to discover interesting patterns, mainly frequent patterns and high utility patterns. In real databases, it is not sufficient  to find interesting patterns only on the basis of occurrence frequencies. There is a great need to consider quantities (internal utilities) and importance (external utilities) of the items simultaneously. In real world, data is continuously generated and in case of distributed databases, data from the various sites is added to the central databases periodically. If the state of art algorithms for mining high utility itemsets are used for real and dynamic databases, keep considering the database as static and with each update in data, rescans the database from the beginning [17]. Time overhead of rescanning the database increases with each update in data and becomes a time consuming activity for the large sized databases.

Hence dynamic databases require a provision to add new data to the previous  results to handle existing and new data effectively. ?Incremental Mining Strategy? fulfills all  these requirements. It uses a tree structure to store the information about database and patterns. After the construction of tree, even if the database size increases, the tree is updated only with that incremented data and the mining process can be immediately started. Thus it reduces unnecessary database scans [12].

Though incremental utility mining strategy finds important items from static as well as dynamic databases with characteristics, it is not easy to find high utility patterns because downward closure property does not hold i.e. a super pattern of a low utility itemset can be a high utility itemset.

Hence low utility itemsets cannot be eliminated in advance.

To maintain this property ?Over Estimation Method? was applied in the previous researches [15]. But it still generates large number of candidate patterns which degrades the performance in mining. Because over estimated utility of candidates is calculated by adding the utilities of the transactions which include that candidate. It adds utilities of items which are not included by their super patterns. It results in extending run time of the whole mining process due to the large number of generated candidates.

We must decrease the number of candidates to improve the performance in mining. This problem can be resolved by using the ?Reduced Over Estimation? method of discarding the items which are globally as well as locally unpromising [12].  It reduces search space and also the number of candidates.

All these issues associated with high utility itemset mining with dynamic databases can be rectified with the use HUPID-Tree (High Utility Patterns in Incremental Databases Tree) algorithm. It uses incremental mining strategy for static as well as dynamic databases and also uses the reduced over estimation method for pruning search space.

This paper illustrates the comparative study of HUPID-Tree algorithm and the state of art algorithm FHIM [17] (frequent high utility itemset mining) mainly for dynamic databases. It compares the time and space required for both the above mentioned algorithms and proves that HUPID-Tree algorithm performs better than FHIM in both the aspects.

Remaining sections in this paper are as follows.

Earlier work done is described in section 2. Section 3 contains  College of Engineering Pune, India. Dec 19-21, 2016     analysis and comparison of HUPID-Tree and FHIM algorithms, with the explanation of their respective work flows. Experimental set up and results are discussed in section 4 and the contribution is concluded in section 5.



II. RELATED WORK High utility itemset mining has emerged as an  alternative approach for frequent pattern mining [7]. The Apriori-based Two-phase algorithm was suggested by Liu Y, Liao W-K, and Chaudhary AN which uses TWU based over estimation method but still generates large candidates [15]. To solve the issues with two phase algorithm  UP-Growth [14] and Up-Growth+ [3], IHUP [16] were designed. IHUP uses incremental mining strategy, constructs tree with single database scan. It extracts all the high utility itemsets. But, for longer transactions and low minimum utility threshold, generate many candidates. Potential high utility is used in Up- Growth to reduce candidates in mining. Up-Growth+ further uses different techniques like discarding local unpromising items and decreasing local node utility.

Fast update approach based FUP-HU was proposed in 2012 [2]. It was faster than the two-phase batch mining method. It uses existing as well as new data for classification of the patterns. If the patterns are from existing and new data, and TWU values more than or equal to the minimum utility threshold are classified as the first type. If patterns are only from the existing data and their TWU values are more than or equal to the minimum utility threshold are classified as the second type. If patterns are from the new data only and  TWU values are more than or equal to the minimum utility threshold are classified as the third type and patterns in the forth type are having TWU values less in both existing and new data.

Ashok Kumar Das, Jayakrushna Sahu, A. Goswami proposed various algorithm for high utility itemset mining in ? An Efficient approach for mining association rules from high utility itemsets? in 2015. They consider utility confidence for mining and generate non redundant set of association rules from HUIs. But all these algorithms will always treat the databases as static.



III. ANALYSIS AND COMPARISON OF  HUPID-TREE AND FHIM ALGORITHM  A. Work flow of HUPID-Tree algorithm               Fig. 1.  Workflow of HUPID-Tree algorithm  B. Algorithm : HUPID-Tree  [12]   Input: Transactional database DB, incremented database db, minimum utility threshold ?.

Output: High utility itemsets                                                Fig. 2.  HUPID-Tree algorithm  C. Algorithm : FHIM [17]   Input:  Database D,  minimum utility threshold minutil.

Output: High utility patterns.

For each new transaction do N = NR  /* NR is the root node */ Sort transaction items i in their current sorting order For each i with quantity q do If no child Ni under N with Ni.Name = i then Create Ni as a child under N Set Ni.Name := i, Ni.Max := q, Ni.PU := 0 Else if q >Ni.maxqty  then Ni.maxqty := q If i is the end of the transaction then Update information about Ni in TIList Table with TU of T N :=  Ni If T is the end of db or DB then Call Restructuring (Tree) If user requests for mining then HUI  := ?, PFI := ?  /* PFI is the prefix itemset */ Call Miner (Tree, PFI, HUI) Remove itemsets with utility < minimum utility from HUI   Procedure Restructuring (Tree) For each entry from the TIList Table do Read path in Tree with the help of E.link Sort path in the decreasing order of TWU For each item ip in the path do Calculate PU (ip) If no child Nip under N with Nip.Name = ip then Create   Nip as child for N Set Nip.Name = ip, Nip.Maxqty := q, Nip.PU := PU(Nip) Else if q > Nip.Maxqty then Nip.Maxqty := q If Nip  is the end of transaction then Update information about Nip in TIList Table with TU of T N = Nip     Procedure Miner (Tree, PFI, HUI) //CPT Conditional pattern tree, CPI Conditional prefix itemset, CPB Conditional pattern base For each Header Table item i from the bottom with i.TWU ? minimum utility  CPT := ?,CPT := ?, CPI := PFI For each N with N.Name = i do Extract path up to NR starting from N If global tree then Calculate Support (path) Else Support (path):= N.Support Add information of path in CPB with Support (path), N.PU Create CPT without unpromising items in CPB Add CPI in HUI Call Miner (Tree, PFI, HUI) /* Recursive call */                                                           Fig. 3.  FHIM algorithm   D. Analysis and comparison of HUPID-Tree and FHIM  Figure 2 and 3 illustrates the algorithm for HUPID-Tree and FHIM algorithm respectively. FHIM is the state of art algorithm for discovering high utility itemsets. It considers support of the generated candidates to extract the actual desirable high utility patterns. As we are comparing its  performance with HUPID-Tree for dynamic databases which does not extract high utility patterns on the basis of minimum support of the itemsets, the minimum support value is set to 1 for FHIM.

Fig. 4 Reverse preorder traversal in sub trees of root in  FHIM algorithm  It uses downward closure property of TWU of itemsets to generate candidates. When TWU value of an item is greater than or equal to the minimum utility threshold, it is appended with the remaining items in itemset subsequently and super patterns are generated and checked for their TWU values.

Pictorial representation of this process is as shown in figure 4 above. When FHIM is used for dynamic databases, it treats the database as static and even with a small increment in data it scans database from the beginning. As size of the database increases, algorithm spends more time in rescanning and mining performance with respect to time and space degrades.

Utility construct process in FHIM takes O(s log s) time where s is the minimum support and binary search algorithm is used to get an element from the list. Complexity of FHIM is proportional to the cost of total candidates generated. Thus it is equal to O (Can FHIM) where Can FHIM = generated candidate patterns [17].

HUPID-Tree algorithm uses a tree structure to maintain the information about database and patterns. The tree is restructured to bring the items with higher utility in the upper part of the tree to make mining process easy. Restructured tree is ready for mining but after this, if the database size gets incremented, instead of building the tree again, it is updated only with that incremented data and again after restructuring, mining process can be started. It reduces space because the tree is built with single database scan and also requires less time due to its incremental nature and  reduced time overhead of database scans.

The whole process in HUPID-Tree algorithm can be divided into four phases 1) To build global tree with single database scan 2) To update the tree with incremented data 3) Candidate pattern generation and 4) High utility itemset mining. Complexity of the HUPID-Tree depends on the number of items in the transactions. If the longest transaction contains Nm items, in the worst case scenario HUPID-Tree construction complexity is O (N0 * (Nm +1)) Where N0 = no.

of transactions in the original database. The generated tree has N0 paths in worst case. TIList will also have N0 entries. Thus for each entry, path is extracted. Suppose the length of the extracted path is equal to Nm the algorithm spends O (N0 *(Nm  Calculate TWU value of every item by scanning D C = {x| x such that TWU(x) ? minutil} Sort C in ascending order of TWU Discard  the items whose TWU < minutil; Construct utility list UL such as UL = {UL(x)|TWU(x) ? minutil} //Build the EUCS (Estimated Utility Co-occurrence) structure for each item x? C  if (SUM(UL(x).iutils) ? minutil) Write {x}, {x}.utility, {x}.support; // High utility 1-itemset  if (SUM(UL(x).iutils) + SUM(UL(x).rutils) ? min util) Set tail = ? for each item y ? C, x ? y from left to right if there exists (x, y, v) ? EUCS such that v ? min util Compute X = {x}  {y}; Compute UL(X) = Construct (?,?,UL(x),UL(y)); Compute tail = tail  UL(X); Call Research (x, tail, min util); Remove UL(X) from UL;   Procedure Construct (UL (P), UL (Px), UL (Py)) Set UL (Pxy) = ? Set Pxy.EU = 0; // Expected utility of Pxy for PUEP strategy Set eu = 0; // Expected co-occurrence utility of Pxy for PUCP strategy if |Pxy| = 3 for each element ex ? UL(Px)  if there exists ey ? UL(Py) and ex.tid == ey.tid if UL(P) ? ?  Find e ? UL(P) such that e.tid == ex.tid; Compute exy = (ex.tid, ex.iutil + ey.iutil ? e.iutil, ey.rutil); Compute Pxy.EU = Pxy.EU + ex.iutil + ex.rutil;  else Compute exy = (ex.tid, ex.iutil + ey.iutil, ey.rutil); Compute Pxy.EU = Pxy.EU +ex.iutil +ex.rutil; Compute eu = eu + e.itil + e.rutil; // For PUCP strategy if |Pxy| = 3  Add exy to UL(Pxy); if |Pxy| == 3 Add eu to PUCS a; return UL(Pxy);  Procedure  Rsearch (a, tail, minutil) if (tail == ?)  return; for each Px ? tail from right to left if (SUM(UL(Px).iutils) ? min util) Write Px, Px.utility, Px.support if SUM(UL(Px).iutils) + SUM(UL(Px).rutils) ? min util) Set tailPxy = ? ; for each Py ? tail with x ? y from left to right  if (JOIN(a, Px, Py,min util)==true) Compute Pxy = Px  Py; Compute UL(Pxy) = Construct(a, P, Px, Py); Compute tailPxy = tailPxy  UL(Z);  Call Rsearch(a, tailPxy,min util);       +2)) time for restructuring the tree.  Candidate generation phase with Nh items, requires execution time of O (Nh * N0 *(Nm +1)). If Nc are the no. of candidates generated from current database. High utility pattern identification process requires time of O (Nc * N0) [12].



IV. EXPERIMENTAL SET UP AND RESULTS In this section, performance of HUPID-Tree  algorithm is compared with the state-of-art algorithm FHIM.

Both the algorithms were implemented in Java. Experiments for evaluation were performed on a 3.3 GH Intel Quad Processor with 8 GB RAM and run with Microsoft Windows 8. Performance evaluation was conducted on the ?Superstore sales? data available on internet in the excel sheet format.

Dataset contains 1000 transactions and 199 unique items.

FHIM algorithm always treated the database as static.

Hence for each update in data, database is needed to be scanned from the beginning which increased the time overhead of rescanning the already scanned data. Hence the time to scan the dataset became directly proportional to the number of transactions and items in the dataset. The problem of large number of candidate generation associated with the high utility itemset mining persists with the FHIM because it generates candidates by using down-word closure property of TWU values of the items. But in HUPID-Tree algorithm even after the construction of the tree, when the database was increased, the tree got updated only with that incremented data and reduced the time overhead of rescanning the dataset. It pruned the search space for the global promising items by discarding local unpromising items which eventually resulted in generating less number of candidates as compared to FHIM.

Figure 5  and 6 below shows the improvement in performance of HUPID-Tree  over  FHIM. Figure 5 shows that when the threshold value is high the candidates generated in both the systems are more over the same but as the minimum utility threshold is decreased, FHIM generates more candidates and increases search space as compared to the HUPID-Tree.

Fig. 5. Number of generated candidates in HUPID and FHIM  The performance of HUPID-Tree and FHIM algorithm with respect to time is shown in figure 6 below.

When the minimum utility  threshold is gradually decreased from 30% to 10%, time required for mining HUIs increased in  both the systems but HUPID-Tree algorithm took  less time due to the use of incremental mining strategy and and also occupied less space due to the capability of generating less number of candidates.

Fig. 6. Performance comparison with varying minutil threshold (%)

V.  CONCLUSION   FHIM and HUPID-Tree are the high utility itemset mining algorithms.  But when we use both these algorithms for dynamic  databases HUPID-Tree algorithm performs better because of its incremental mining nature  which stores information about the database and patterns in a tree which is updated with the incremented data with increase in database size whereas FHIM spends more time in rescanning the database from beginning with each update  because it always considers the database as static. Hence for large sized dynamic databases HUPID-Tree takes less time for mining HUIs.

Reduced over estimation method is used to discard locally and globally unpromising items,  results in reducing the candidates for HUPID-Tree. Hence HUPID-Tree takes less space and time as compared to FHIM for mining.

