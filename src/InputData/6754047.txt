NIM: Scalable Distributed Stream Process System on Mobile Network Data

Abstract?The amount of 3G MBB data has grown from 15 to 20 times in the past two years. Thus, real-time processing of these data is becoming increasingly necessary. The overhead of storage and file transfer to HDFS, delay in processing, and etc make off- line analysis inefficient. Analysis of these datasets are non-trivial, examples include personal recommendation, anomaly detection, and fault diagnosis. We describe NIM - Network Intelligence Miner, which is a scalable and elastic streaming solution that analyzes MBB statistics and traffic patterns in real-time, and provides information for real-time decision making. The design and the unique features (e.g., balanced data grouping, aging strategy) of NIM help not only the network data analysis tasks but also other applications like Intelligent Transportation System (ITS), etc.

Keywords-telecommunication; big data; stream computing;

I. INTRODUCTION Nowadays, the number of users accessing the Internet  via 3G/4G cellular data network by mobile devices (e.g., smartphones, tablet computers and datacards) has multiplied every year. Consequently, the amount of mobile broadband data (MBB data) grows more than 3 times on a yearly basis. For example, for a typical major city in China, the amount of MBB data per day was about 30TB to 40TB by the end of 2012. Capturing the big dataset becomes more difficult and off-line processing is unrealistic. Due to the high commercial demand for understanding mobile traffic and network patterns in real-time (e.g., network abnormal/quality monitoring, spatial-temporal marketing), a streaming system that can process increasing MBB data becomes increasingly valuable.

Stream systems are suitable for online analytical applica- tions and monitoring that require timely processing of big data.

StreamBase[2] and InfoSphere Streams[1] are two examples of commercial systems. They provide rich libraries of tools and SQL-like language support. InfoSphere Streams is a high-performance computing platform that enables users to develop and reuse applications to rapidly ingest, analyze and correlate multiple information sources. StreamCloud[4] is a scalable and elastic data streaming system, which provides subqueries dispatching and efficient parallelization strategies.

Yahoo! S4[11] and Twitter STORM[15] are two open source software, offering distributed, scalable and partially fault- tolerant computation. The design of S4 is derived from a combination of MapReduce and the Actors model, and is current at an early development stage. STORM, on the other hand, is language independent, and provides the construction  TABLE I DATA-PLANE AND CONTROL-PLANE INFORMATION  Data-plane Info. Control-plane Info.

Attribute Example Attribute Example Attribute Example  UTC1(s) 1290959544 Inner  IP  Protocol Type 6 Setup Time 1290959543  UTC2(ms) 386200 Source IP 110.75.1.3 SGSN IP 220.206.144.33  Total Length of Packet 1470 Destination IP 172.27.13.100 SGSN TEID 340942606  Outer  IP  Protocol Type 17 Inner  TCP  Source Port 80 RNC IP 10.242.239.57  Source IP 220.206.144.33 Destination Port 4097 RNC TEID 34020  Destination IP 10.242.239.57 Inner  UDP  Source Port ?  Outer  TCP  Source Port ? Destination Port ?  Destination Port ? DPI  Analyze  Results  DPI mark DPI  Outer  UDP  Source Port 2152 App Class Web Browsing  Destination Port 2152 App Software HTTP  GTPU TEID 34020 App Protocol HTTP  of topologies to transform intermediate streaming data. We have chosen to use STORM to implement our demo system.

We focus on processing 3G mobile broadband data in the streaming paradigm. Operator captured a large-scale dataset, including binary IP packets with complete payload and UMTS-compliant signaling messages from one commercial, city-wide 3G UMTS network in China, over a 7-day pe- riod of 2011. The user sensitive data had been removed for privacy protection. We are interested in both data-plane and control-plane information in the IP packets, as shown in Table I. Most of the data-plane information can be extracted directly from the binary IP packets, while the DPI results are generated by a deep packet inspection (DPI)[7] module.

Control-plane information is joined and correlated with a specific Radio Resource Control (RRC) connection. RRC connection is used by a User Equipment (UE) to send/receive data to/from the Internet[3][13]. There are a lot of signaling messages transferred during a RRC connection. We generate the full control-plane information by combining four types of signaling messages that belong to one RRC connection.

Control-plane includes information as follows: (1) Setup Time or the timestamp indicating when the RRC connection is established; (2) Radio Network Controller IP address (RNC-  Fig. 1. MBB Data Processing Schematic Flow   DOI 10.1109/ICDMW.2013.79    DOI 10.1109/ICDMW.2013.79     IP) and Serving GPRS Support Node IP address (SGSN-IP), identifying an RNC and a SGSN respectively. Both RNC and SGSN are equipment nodes in a 3G mobile network; (3) Radio Network Controller Tunnel End point ID (RNC-TEID) and Serving GPRS Support Node Tunnel End point ID (SGSN- TEID), which collectively identify a unique RRC connection.

Finally, we join data-plane with control-plane information according to their separate timestamp, in order to create a structured record for each binary IP packet. Many different types of applications can be implemented based on the struc- tured records, such as network traffic statistics, user pattern modeling and traffic prediction. This network data processing scenario, demonstrated in Fig. 1, can be implemented as both off-line process[6] based on Hadoop[5] and on-line process based on any streaming systems. The off-line process needs high data storage capacity and large amounts of time for data transfer. Due to these limitations, the final results will be delayed for at least one day. In order to improve the efficiency of this scenario, we instead design a streaming solution. The on-line process encounters several challenges:  ? Parallelization of end-to-end solution: Differ from Hadoop-based solution, stream-based solution requires that all the data processing steps should run in parallel so that real-time results can be presented.

? In-memory data management: As correlation analysis approach is in-memory operation and in stream-based process data are arriving sequentially. An appropriate data structure is important to cache incoming data. Meanwhile, to delete outdated data, an effective aging strategy is crucial for memory resource management.

? Analysis Accuracy: To guarantee reasonable accuracy, flow-based grouping strategy is necessary in both DPI and correlation analysis. Moreover, Internet Packet (IP) Fragmentation reassembly must be carried out to ensure the performance of DPI module.

In response to these challenges, we propose a stream-based solution - Network Intelligent Miner (NIM). NIM is designed to preprocess binary IP packets in 3G mobile broadband network while the packets are transferred at line rate. As soon as data is preprocessed, statistical analysis is carried out immediately. We take STORM[15] for an example to deploy NIM. In summary, as demonstrated in Fig. 2, NIM has the following main modules: (1) Edge adapter receives binary IP packets from the network and dispatch them to distributed components in Information extraction module.

In the demo, we simulate the real binary IP packets flow by reading data files from disks and sending out packet by packet. (2) Information extraction is responsible to parse each IP packet, and then divide the results into two groups, named data group and signaling group. (3) DPI Analysis iden- tifies the application type of each packet in data group, and then outputs decoded data-plane information. (4) Signaling Correlation joins four types of signaling messages from the signaling group, and outputs control-plane information. (5) Data-signaling Correlation joins control-plane information  with data-plane information to provide structured data records.

(6) Applications implements includes statistic analysis and traffic prediction based on the joined results. The experiment results in Section 3 show that DPI ratio and correlation ratio of the real-time NIM are nearly identical to the off-line analysis, while the processing time by NIM is only 33% of that on Hadoop without counting the overhead to transfer to HDFS (about 8 hours for only 1.1 TB data).



II. TECHNICAL SPECIFICATION  In regard to the challenges mentioned previously, we apply some unique features in the design of NIM?s modules as follows:  ? Balanced Data Grouping. Data grouping is important in NIM for parallelization and accuracy. In DPI Analy- sis, Signaling Correlation, Data-Signaling Correlation modules, dispatching data with different strategy is very important, hence all the tasks can work respectively at the same time. Data dispatching strategy is dependent on the specific application tasks. Take Data-Signaling Correlation module for example, data is divided into uplink and downlink portions, because the correlation methods for uplink and downlink are different. In general processing steps, round-robin strategy is employed to evenly dispatch data to avoid heavy load on signal node.

? Aging strategy. Signaling Correlation and Data- Signaling Correlation modules will cache the data in memory until the matching rules are fulfilled. In order to efficiently use the limited memory resource, we design a hierarchical concurrent hash table structure to cache data, and a specifically designed aging strategy to delete outdated data. The aging strategy keeps a sliding window with two time-stamp thresholds, one to trigger the aging process and the other to define the range of outdated data to be deleted. The hierarchical concurrent hash table structure supports effective searching and matching for joining.

? DPI Mechanism. Deep Packet Inspection (DPI) module identifies the application of data packets with high accu- racy. It maintains a knowledge base of hundreds of appli- cations, and maps each five-tuple flow to an application based on payload patterns. Five-tuple flow is identified  Fig. 2. Architecture of NIM     TABLE II PERFORMANCE OF NIM VS. OFF-LINE HADOOP IMPLEMENTATION  NIM Hadoop Execute Time 7 h 58 min 24 h 23 min DPI Ratio 88.9% 91.7% Correlation Ratio 61.9% 62.4%  by five parameters: Source IP address, Destination IP address, Source port, Destination Port and Layer 4 Proto- col (TCP/UDP/ICMP). The continuity of each five-tuple flow is crucial for DPI Analysis, because DPI module identifies application by a series of packets in the same flow. Comprehensive tests indicate that the efficiency of DPI module is not high due to the incontinuity and fragment IP packets in each flow. In order to improve the efficiency and accuracy of DPI Analysis module, Outer IP process and Five-tuple process submodules act as a special data flow grouping strategy, such that each unique five-tuple flow will be dispatched to one task of DPI process submodule. Moreover, Outer IP process submodule uses an IP Fragmentation Reassembly algo- rithm to recover five-tuple information for each fragment IP packet to improve the DPI efficiency.



III. PERFORMANCE  We present the performance tests of STORM and compare the performance of NIM and our previous off-line procedure based on Hadoop.

A. System-Level  We have tested STORM with both the local and distributed cases to create a benchmark, the results are quite helpful for all applications running on STORM. All measurements were made on HUAWEI U2285, a hardware configuration comprising 2 Intel Xeon X5670 CPUs (each has 6 2.93GHz cores), 48GB RAM, 1 Gigabit Ethernet. SLES 11 x64, jdk 1.6.0.29, zeromq 3.2, jzmq, and STORM 0.8.1 were installed.

The default tuple size is 64 bytes. The most important results are as follows: (1) The tuple throughput of distributed case is about 0.9 millions/second. (2) The acker mode heavily decreases the performance, the tuple throughput drops from 0.9 to 0.15 millions/second. (3) The total parallelism equal to the core of CPU will get best performance, and parallelism of 6 achieves about 3.5 times tuple throughput. (4) Byte throughput of 300 to 600 bytes tuple is better than that of smaller tuple, and the testcase of large tuple(than 1500 bytes) sometimes causes tuple loss. (5) With the same parallelism, the performance of one JVM is better than multiple JVMS, since the tuples are not transferred among JVMS.

B. Application-Level  We compare the performance to process MBB dataset on NIM with Hadoop. We use half a day of MBB data about 1.1 TB, from one commercial, city-wide 3G UMTS network in China for testing. The user sensitive data had been removed by operators for user privacy protection. The cluster has 11  Fig. 3. Online Statistical Analysis Results  computers of U2285 in both cases. The off-line procedure on Hadoop consists of data collection, storage, data mergence, data transfer to HDFS and follow-up essential data processing tasks. Though each task can run in parallel, all tasks have to run sequentially and save temporary results to HDFS.

Correspondingly, NIM can process MBB data at line rate and execute all the processing tasks described in Section 1 in parallel as pipeline processing, and output analysis results in real time. Experimental results in Table II indicate that besides the advantage of only 33% execution time1, NIM uses round- robin scheduler, proper parallelism and grouping strategy to guarantee that DPI ratio and correlation ratio are very close to that on Hadoop. The differences in ratios are insignificant for operators to make decisions in network resource management, priority schedule, and etc.



IV. APPLICATION SCENARIOS  NIM can provide statistical methods, and deliver real-time analysis results based on structured data flows arising in streaming mode. These real-time results help operators to make quick response according to network status. Besides, data mining algorithms such as clustering and prediction can also be implemented in NIM. In this demo, we demonstrate two cases - statistical analysis and traffic prediction. Moreover, NIM is flexible to add new applications.

A. Statistical Analysis  The structured data consists of timestamp, IP traffic volume, application protocol, RNC IP, RNC TEID, etc. We discover user pattern and network feature by analyzing the multi- dimension data.

We use Pentaho BI Suite[12], an open source business intelligence and analytics platform, to visualize the results in histogram, curve or pie chart. The Application module of NIM generates statistical analysis results and sends them to Pentaho, and the new-coming analysis results from Application module will refresh the graphs presented on Pentaho UI periodically.

Fig. 3 shows an example of Traffic Distribution based on Application. The top 3 applications of traffic volume are web  1Execute Time is the addition of Collection Time, Mergence Time, Transfer Time and Processing Time.

Fig. 4. Performance of ANN model  browsing (38%), streaming (21%), P2P (10%). IM and Email applications only contribute 2% and 1% to the total traffic, respectively. Our DPI Analysis module can identify over 90% of total traffic (9% is labeled as Unknown). The distribution of application-based traffic varies with different time, e.g., midnight, work hours and busy hours after dinner. Based on the real time traffic patterns, the operators can deploy proper network resource scheduler to improve user experience, which is an important Key Performance Indicator (KPI) for operators.

B. Traffic Prediction  Besides statistical analysis, data mining algorithms such as clustering and prediction can also be implemented in NIM. We take the network traffic prediction for example, which is significant in many domains, including conges- tion control[8], abnormal traffic detection[10] and network bandwidth allocation[14]. We implement the classic ANN algorithm[16], which is a non-linear, non-parametric and data driven modeling approach to predict short-term traffic. It can utilize the data and let the data determine the structure and parameters of a model without any restrictive parametric mod- eling assumptions. We train an ANN model with a historical network traffic dataset which has 1440 samples per day at granularity of minutes. The ANN model predicted the next minute?s traffic on network by 3 previous values. Generally, predict model must be retrained according to specific applica- tion situation. In order to improve the prediction accuracy, we retrain the ANN model every day. Fig. 4 shows the experimental result on one day?s MBB data. The predicted traffic value is close to the real one, and the mean is 0.056.



V. DISCUSSION AND CONCLUSIONS  Nowadays, telecommunication operators are encountered by big data challenges, i.e., continuous and heterogeneous data collected in real-time from both their customers and network devices. It is becoming increasingly important for them to analyze this big data effectively and in real-time, in order to provide personalized products and services, network operation optimization, and etc. All these are crucial for their revenue increase. With NIM, operators and other third party service providers can mine user behavior in 3G network by processing their raw network dataset. User behavior model is valuable for various business applications, such as rec- ommendation, customized services and network optimization.

Based on real-time results produced by NIM, operators can characterize specific user behavior in network in real time.

Additionally, many other analysis (e.g., RNC based analysis, time series pattern of every application or user) can be made in Application module. Moreover, NIM matches the challenges of parallelization, in-memory data management, and analysis accuracy with unique features of balanced data grouping, aging strategy and DPI mechanism. The design and unique features of NIM will be helpful for not only network data analysis but also other applications. For example, balanced data grouping is efficient in dispatching data. It will be helpful for Intelligent Transportation Systems (ITS)[9], which involves multiple interactions with vehicles. Aging strategy is useful for high speed data analysis with limited memory. Meanwhile, the system-level measurement results of STORM are quite helpful for applications running on STORM, and the application- level measurement results show that DPI ratio and correlation ratio of NIM are identical to the off-line analysis, while consumption on NIM is only 33% of that on Hadoop without counting the overhead of file transfer, etc. However, current STORM-based NIM has some limitations on performance im- provement and application implementation. To better support the real-time analysis of large MBB data, we plan to design an innovative stream system named StreamSMART (a Self- Monitoring and Automatic Recovery Technology streaming system) to support new features, such as stateful components, hot-pluggable components, components transfer, load-balance and fault-tolerance, etc.

