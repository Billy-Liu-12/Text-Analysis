Web Page Recommendation based on Markov Logic Network

Abstract-Recent research initiatives have addressed the need for improved performance of Web page recommendation  accuracy that would profit many applications, e-business in  particular. Different Web usage mining frameworks have been implemented for this purpose specifically Association rules and  clustering. Each of these frameworks has its own strengths and  weaknesses. An approach based on Markov Logic Network is proposed to do Web page recommendation, which take full use  of four kinds of characteristics. The experiments show that the  approach can achieve high accuracy on Web page recommendation.

Keywords-Web page recommendation; Markov Logic Network

I. INTRODUCTION  The immense volume of online infonnation covering almost all types of applications makes the web susceptible to a wide range of infonnation discovery and retrieval tools.

Web applications today are driven to provide a more personalized experience for their users. Therefore, it is extremely important to be one step ahead of web users when it comes to predicting next accessed pages. For instance, knowing the user's browsing history on the site grants us valuable information as to which one of the most frequently accessed pages will be accessed next. Also, it provides us with extra infonnation like the type of user we are dealing with and the user's preferences as well. Some widely used data mining methods to achieve the goal are association rule mining, clustering, and so on.

Association rule mining is a major pattern discovery technique[I]. The original goal of association rule mining is to solve market basket problem but the applications of association rules are far beyond that. Using association rules for Web page recommendation involves dealing with too many rules and it is not easy to find a suitable subset of rules to make accurate and reliable recommendations[2,3].

Clustering groups user sessions into clusters based on similarity between common acivities. It aims at dividing web sessions into groups where the distance between clusters is maximised while the distance between sessions within the same cluster is minimized. The clustering methods partition data objects into a number of homogeneous groups based on their similarity. Clustering methods do not classify user sessions directly [4,5] , but will help build classification models if data objects are properly clustered.

In this paper, an approach based on Markov Logic Network is proposed, which takes full advantage of the log of web users, the cluster characteristics of web pages, and the content characteristics of web pages to recommend related web pages to web users. We begin by briefly reviewing the necessary background on Markov networks, first-order logic and Markov Logic Networks. We then describe our proposed approach to Web page recommendation, report on experiments, and conclusion.



II. WEB PAGE RECOMMENDATION  Markov logic network can depict various kinds of features and do inference, so it is used to judge the relativity between two different pages, and then, do page recommendation in this paper.

A. Markov Networks  A Markov network (also known as Markov random field) is a model for the joint distribution of a set of variables  X = (XpX2,??,XJE % [6]. It is composed of an undirected graph G and a set of potential functions fA . The graph has a node for each variable, and the model has potential function for each clique in the graph. A potential function is a non-negative real-valued function of the state of corresponding clique. The joint distribution represented by a Markov net- work is given by  P(X = x) = -II ?k(X{k}) (1) Z k  Where X{k} is the state of the eh clique (i.e., the state of the variables that appear in that clique). Z , known as the partition function, is given by Z= LXExIIk?k(X{k})' Markov networks are often conveniently represented as log linear models, with each clique potential replaced by an exponentiated weighted sum of features of the state, leading to  P(X = x) = -expeL Wj?(x)) (2) Z j  A feature may be any real-valued function of the state.

This paper will focus on binary features, ? (x) E {O,1}. In the most direct translation from the potential-function fonn (Equation 1), there is one feature corresponding to each    possible state X{k} of each clique, with its weight being log?k(x{k})' This representation is exponential in the size of the cliques. However, we are free to specify a much smaller number of features, allowing for a more compact representation than the potential-function form, particularly when large cliques are present. Markov Logic Network takes advantage of this.

B. First-Order Logic  A first-order logic base (KB) is a set of sentences or formulas in first-order logic. Formulas are constructed using four types of symbols: constants, variables, functions, and predicates. Constant symbols represent objects in the domain of interest. Variable symbols range over the objects in the domain. Function symbols represent mappings from tuples of objects to objects. Predicate symbols represent relations among objects in the domain or attributes of objects.

C. Markov Logic Network  A first-order KB can be seen as a set of hard constraints on the set of possible world: if a world violates even one formula, it has zero probability. The basic idea in Markov Logic Network is to soften these constraints: when a world violates one formula in the KB it is less probable, but not impossible. The fewer formulas a world violates, the more probable it is. Each formula has an associated weight that reflects how strong a constraint it is: the higher the weight, the greater the difference in log probability between a world that satisfies the formula and one that does not, other things being equal.

Definition A Markov logic network (MLN) L is a set of pairs (F;, Wi) , where F; is a formula in first-order logic and Wi is a real number. Together with a finite set of constants C = {cpc2,,.? 'C1CI} , it defines a Markov network ML,c (Equation land 2) as follows:  (1) ML,c contains one binary node for each possible grounding of each predicate appearing in L . The value of the node is 1 if the ground predicate is true, and 0 otherwise.

(2) ML,c contains one feature for each possible grounding of each formula F; in L . The value of his feature is 1 if the ground formula is true, and 0 otherwise.

The weight of the feature is the Wi associated with F; in L.

Thus there is an edge between two nodes of ML,c iff the corresponding ground predicates appear together in at least  one grounding of one formula in L. An MLN can be viewed as a template for constructing Markov networks. From Definition 1 and Equation 1 and 2, the probability distribution over possible worlds X specified by the ground Markov network ML,c is given by   1 F P(X = x) = -expeL wini(x)) (3)  Z i=1 where F is the number formulas in the MLN and  ni (x) is the number of true groundings of F; in X . As formula weights increase, an MLN increasingly resembles a purely logical KB, becoming equivalent to one in the limit of all infinite weights.

Eq. (3) defmes a generative MLN model, that is, it defines the joint probability of all the predicates. In our application of Web page recommendation, we know the evidence predicates and the query predicates a prior. Thus, we turn to the discriminative MLN. Discriminative models have the great advantage of incorporating arbitrary useful features and have shown great promise as compared to generative models. We partition the predicates into two sets,  the evidence predicates X and the query predicates Q.

Given an instance X , the discriminative MLN defines a conditional distribution as follows:  P(q I x) = --exp(L Lwigj(q,x)) (4) Z  x(W) ieFQieGj  Where FQ is the set of formulas with at least one grounding involving a query predicate, Gi is the set of ground formulas of the ith first-order formula, and Z  x ( w)  is the normalization factor. g j (q, x) is binary and equals to 1 if the /h ground formula is true and 0 otherwise.

D. Features  In this paper, we define the query predicates as IsRecommendationPage(p 1 ,p2), which means whether p2 is the recommendation page of pI. In this paper, four different kinds of features are used to judge whether one page can be taken as the target page's recommendation page. These features are described by predicates and formulas, which are showed in Table 1.

TABLE I. FEATURES USED IN EXPERIMENTS  Feature Description Cooccurrence(p I ,p2) The cooccurrence number of two pages ,such  as p I and p2, in visit log is higher than the threshold.

ContentCorrelative(p I ,p2) The contents of two pages are correlative.

SameCluster(pl,p2) The two pages belong to the same cluster.

UriSimilar( pI ,p2) The UrIs of two pages are of similar pattern.

E. Weight Training  The state-of-the-art discriminative weight learning algorithm for MLN's is the voted perception algorithm[8].

The voted perception is gradient descent algorithm that will first set all weights to zero. It will iterate through the training data and update the weights of each of the formulas based on whether the predicted value of the training set matches the true value. Finally, to prevent overfitting, we will use the    average weights of each iteration rather than the final weights. In order to train the data using the voted perception algorithm, we must know the expected number of true groundings of each clause. This problem is generally intractable,and therefore, the MC-SAT algorithm is used for approximation. Refer to Singla and Domingos[7] for a more detainled discussion of the weight training algorithm.

F. Inference  Inference in MLN requires reasoning with both probabilistic and deterministic dependencies. Traditionally, MCMC algorithms have been used for inference in probabilistic models, and satisfiability algorithms have been used for pure logical systems. Since a MLN contains both probabilistic and deterministic dependencies, neither will give good results. In our exprements, the MC-SAT algorithm will be used to determine the values of query predicates. The MC-SAT is an algorithm that combines MCMC and satisfiability techniques, and therefore performs well in MLN inferences. Refer to Poon and Pedro Domingos[9] for a more detailed discussion of the inference algorithm.



III. EXPERIMENTS  The real-world data from diverse domains are collected and used to evaluate the performance of our approach from the following 3 aspects: (1) The overall accuracy of this approach; (2) Effect of different characteristics; (3) Effect of different inference.

