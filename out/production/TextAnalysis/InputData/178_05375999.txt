Study on the Discovery Algorithm of the Frequent Item Sets

Abstract?Data mining technology is an interdisciplinary  which has developed rapidly at home.It involves  database,statistics,artificial intelligence,machine learning and  other fields.The popularity of computer use produced a large  amount of data.Data mining utilize scientific to deal with large  volume of data.There are variety use of application of data  mining technology and it will play more and more major role  in all areas of our future society.Association rule mining is the  main research of data mining,while the discovery of frequent  item sets is the core issue of association rule  mining.Consequently,this article focuses on the discovery of  frequent item sets algorithm and draw a conclusion on some  steps for association rule mining.It also have brief analysis of  classical algorithm about Apriori ,point to the key steps of  association rule mining and when put forward an improved  algorithm:PS algorithm.

Keywords-Apriori algorithm;data mining theory;association  rule

I. INTRODUCTION  Data mining association rule mining is an important research content, it is to find the link in a given set of data sets between the project process. However, in a large number of mining association rules, Apriori algorithm is the most basic and the most famous one. Core idea of the algorithm is based on frequent item set theory, a recursive method, the purpose is to dig out from the database of support and trust those who are not less than a given minimum support threshold and minimum confidence threshold associated with rules. Apriori algorithm is usually divided into two steps [8]: (1) based on degree of support, resulting in frequent item sets; (2) based on credibility, generate strong association rules, the core is to generate the frequent item sets by (1). The lack of Apriori algorithm is  to need to scan the database several times, the number of items of the candidate set is more and memory utilization is low, thus affecting operating efficiency.

In order to facilitate quickly dug frequent itemsets out from the transaction database,, from the Apriori algorithm to find frequent item sets, this paper proposes a simple, practical and effective mining method. First, the level of the transaction database is mapped to the vertical transaction database, and then construct a transaction database according to the vertical tree, breadth-first search through the whole tree traversal search to find the transaction database to find frequent item sets.



II. CLASSICAL FREQUENT ITEMSETS DISCOVERY  ALGORITHM  A. The type of Mining Association Rules  Association rules is a simple, practical analysis of the rules is to describe things in one item at the same time between the emergence of the knowledge model of the law.

More precisely, the number of association rules describe the item by quantifying the appearance of pairs of objects A and B. The most classical algorithm is the Apriori association rules algorithm, which first dig out all the frequent itemsets, and then by the frequent item sets generated association rules, association rules in data mining applications is very wide.

Association rules would be classified according to different angles, which may include the following types:  (1) According to the rules dealing with the value of the type of points, mainly Boolean association rules and quantitative association rules. Boolean association rules dealing with values are discrete, species-oriented, rules to consider is the items associated with the absence, it shows the relationship between variables; quantitative association rules can be associated with multi-dimensional and multi- layer correlation The combination of the numeric fields for processing, its best line of dynamic segmentation, or directly to the raw data processing, of course, quantitative association rules can also include types of variables.

(2) rule-based level of abstraction to the data points, mainly single-layer association rules and multi-level association rules. Mining association rules can be carried out at different abstraction layers, if the rules do not involve different levels of items or property are of a single association rules; the other hand, if there are multiple levels of abstraction rules focus on the items or attributes, for the multi-level association rules.

(3) according to the rules of data involved in the peacekeeping to points, mainly one-dimensional association rules and multi-dimensional association rules. In the one- dimensional association rules in the data related to only one- dimensional, while the multi-dimensional association of course, is involved in multiple dimensions of data.

In the properties of association rules, support and credibility can be relatively straightforward to describe the nature of association rules. As can be seen from the definition of association rules, any given set of things in the two items, which exists between the association rules, only  2009 International Asia Symposium on Intelligent Interaction and Affective Computing  DOI 10.1109/ASIA.2009.45     attribute values are different. If you do not take into account the rules associated with the degree of support and credibility, then things in the database can be found in the infinite number of association rules. In fact, people generally only meet a certain degree of support and credibility interested in association rules. Therefore, in order to find meaningful association rules, need to set two thresholds: minimum support and minimum confidence, which provided that the association rules must satisfy minimum support; the latter provides for association rules must satisfy the minimum can be reliability. Generally referred to meet certain requirements (such as a larger degree of support and credibility) rules for the strong rule.

Association rule discovery to go through the following steps: first connection data for data preparation; second, for a given minimum support and minimum confidence, using data mining tools provided by the association rules discovery algorithm; Finally, visualizing, understanding, assessment of association rules.

The core issue of mining association rules is to find the largest itemset.

B. The Process of Mining Association Rules  Association rule mining task is to dug out all the strong rules according to the given minsupport and minconfidence in the transaction database D,. At this point the problem of mining association rules can be divided into two sub- problems [1]:  (1) found that all the support for not less than the minimum support of item sets, namely, frequent sets, also known as large itemsets. This sub-issue is the most important, most expensive and, therefore, committed to improving the algorithm is mainly found in frequency of collection efficiency.

(2) The use of frequency set to generate association rules.

For each frequency a set of L, found in all of its non-empty set, for any nonempty subset of X, there may be association  rules X ? (LX), calculation of the credibility of this association rules: support (L) / support (X ), if the support (L) / support (X) ? ? (minimum confidence), then the output of  association rules X ? (LX).

The first sub-problems, namely, to identify all data sets  (transaction database) D in all the frequent sets, association rules mining is the core issue is a measure of the standard association rule mining algorithm; second sub-problems, namely, obtained according to the frequent item sets and a given minimum level of confidence associated rules, you can solve them, is relatively easy. Therefore, all current assoc iation rule mining algorithms are proposed for the first sub- problems.

In Figure 1 [7], the algorithm is a frequent item set for the search algorithm, the algorithm of association rules generated for the two algorithms, R for mining association rules out of a collection. User specified minimum support from the algorithm is a search out all the frequent item sets, through a given minimal credibility, as well as by a search algorithm for frequent item sets out the association rules derived set of R, and the user with a collection of association  rules R interaction to explain the results of the excavation and evaluation.

Figure 1 The basic steps for mining association rules  C. Apriori Algorithm  Apriori algorithm [5] is generated Boolean association rules mining frequent item sets required for the basic algorithm, but also a very influential association rule mining algorithm. Apriori algorithm uses a method called the step by step in the iterative search, k-items used to search for k +1- itemsets. First, find the frequent 1 - itemsets collection that denoted L1. L1 is used to find frequent itemsets 2 - a collection of itemsets L2, and L2 is used to find L3, so go on, until the frequent k-itemsets is empty. Here in the first k- cycle, the process created in the first set of candidate k-item set of Ck, Ck in the each item set is only one item on two different frequency belongs to Lk-1 set to be a (k-2) - connections generated. Ck the items in the set is used to generate the candidate set of frequent sets, the final set of Lk-frequency must be a subset of Ck. Ck in the each element required to verify the transaction in the database to determine whether to join Lk. A database scan to find each Lk. In order to improve efficiency of the algorithm, Apriori algorithm is put forward the following properties.

The nature of a focus on any one of a frequent item should also be a subset of frequent itemsets [3].

The nature of the Apriori algorithm to reduce the use of a subset of those non-frequent itemsets candidate set, less involved in the scan the database for total support for the candidate item set quantity.

Here's an algorithm Apriori algorithm.

Input: data set D, the minimum support technical degree  minsupport; Output: All the frequent itemsets  Steps:  Ll=Find_Frel(D, minsupport);  For(k=2; Lk-1??: k++)  {  Ck=appriori_gen(Lk-1);  for  t?D {  Ct=subset(Ck?t); For  c?Ct  {  c.count++;  }}  D Algori  thm 1  Algori  thm 2  R  User Interface     Lk={ c?Ck| c.count ?minsupport}; }  Of which: (1) function Find_Frel (D, minsupport), whose role is to  traverse a database D, according to the given value of minimum support minsupport, find all the frequent 1 item sets.

(2) Lk for large k-item sets, (those with minimum support k-item sets) collection;  (3) Ck as the set of candidate k itemsets, that is a potential large-scale collection of k-itemsets;  (4) function appriori_gen (Lk-1), whose role is to use have been drawn in front of a large k-1 itemsets Lk-1 obtained a collection of candidate k itemsets collection. The algorithm is as follows:  appriori_gen(Lk-1)  {  Ck=?;  For each Lk-1?in k-1 item sets Ii {  for each Lk- in k-1 item sets Ij  {  if  ( Ii[1] =Ij[1]and Ii[2] =Ij[2]and ?and Ii[k-2] =Ij[k-  2]and Ii[k-1]<Ij[k-1] )  {  c=Ii Ij;? Ck=Ck {c};?  }}}  for all item sets c Ck? { For all length of c for k-1 s  { if(s?Lk-1)  from Ck to delete c;  }}}  (5) function subset (Ck, t), whose role is to demand contained in the transaction t belongs to all the set Ck of candidate k-itemsets.



III. PROJECT SET ALGORITHM TO IMPROVE THE CLASSIC  Apriori association rules algorithm is the most commonly used method, this study can effectively generate frequent item sets, but some of its shortcomings: (1) to find frequent item sets, it will generate a large number of candidate itemsets; (2) The need for multiple scans database; (3) When the minimum support changes, the need to re-excavation.

Generally speaking, due to the knowledge generated by data mining (eg, rules, etc.) the number too large, leading to a large knowledge base of users to easily lost and can not find truly useful knowledge. And are generally used for data mining databases are very large, carrying out data mining, we need a very long time to scan the database, in particular, the use of Apriori algorithm, some may even deteriorate the  efficiency of data mining. Apriori algorithm is the biggest drawback is that at each stage of the candidate itemsets generated, are to be scanned a database record of the original transaction data calculated degree of support for candidate itemsets, making for a long execution time, efficiency is very low. And when support for change, we must also re- implementation of the Apriori algorithm to generate frequent itemsets meet the requirements.

A. Classical Itemsets Algorithm Improved  PS algorithm [4] is a new mining algorithm, and completely divorced from the Apriori algorithm framework.

PS algorithm is a quick and smooth implementation of the efficiency of association rule mining algorithm, which contains the following features: only need to scan the database once, which can greatly reduce the I / O access time; algorithm structure is clear and simple; can be achieved first found a collection of various items , then the user inputs the minimum degree of support to increase the flexibility of mining, that is, any user can change the minimum support without having to re-scan the entire database; implementation of the efficiency of stable and will not end with support for change, which will affect the efficiency of its implementation; can be used in incremental mining; does not require pre-treatment of the database.

PS algorithm is the main operating rules fairly quick and simple, the main steps: reading things in the database D, each of a transaction record, record directly to the sum of goods to the projects themselves dismantling, which is directly obtained in the corresponding set of transaction records All sub-set (except the empty-set), for example, ABC records for this transaction can be disassembled out of ABC, AB, AC, BC, A, B, C subset of seven, followed by a collection of these sub-sets based on the length of storage of In the different results in the table and do count action, if this collection already exists in the corresponding results in the table, then the set of counts plus one; if does not exist, then the set of join, and set the initial value of 1. After the completion of the above actions, the dismantling of this sum be considered the end of the transaction log. Therefore, when scanning the database D once after things, that means the dismantling of all of the transactions are completed. Finally, just waiting for user input minimum support and minimum confidence, we can generate frequent item sets and association rules. Algorithm pseudo-code is as follows:  PS Algorithm  Input: transaction database D  Output: set of all items  (1) scan D;  (2) Result_Table RT;// The number of RT from the D,  to determine the total number of all items  (3) For all transaction t contains D do begin  (4) Analysis Elements(transaction t );// Find a subset  of transaction records for all  (5) For all item i do // i on behalf of a certain subset of  transaction records  (6) m=length(i);  (7)  If(i contains RT m)     (8)   i.count++;  (9)  Else  (10)  Add I to RT m;  (11)  i.count=1;  (12) End  (13) End  B. Comparison of the Improved Algorithm and the Pre?  algorithm  PS algorithm to verify the feasibility and efficiency in the implementation, carried out a series of comparative experiments. Experimental environment for the Windows Server 2003, Intel Pentium Processor 1.70GHz and 256MB of memory, PS algorithm is achieved using Microsoft VB 6.0, is used to test the database is generated by the IBM generator.

As can be seen from Table 1 when the minimum support higher [6], commodities appear in the needs of the greater number of transactions, so to find the frequent item sets are relatively reduced; and when support for change is low, the product appears in the transaction The number of times you need less, so dig out the frequent item sets will be increased, of course, takes time also increased. Apriori algorithm in the case of increasing degree of support for the test database running time spent in the corresponding fewer. PS algorithm is the smallest degree of support prior do not enter the premise of an excavation until after the completion of excavation based on user defined minimum support to find frequent item sets, so PS algorithm will not end with the size of support for change, affect the overall efficiency in the implementation. Therefore, in a variety of support for PS algorithm, the overall implementation of the efficiency is better than Apriori algorithm.

TABLE 1 PS ALGORITHM AND APRIORI ALGORITHM IN THE EFFICIENCY OF DIFFERENT SUPPORT DEGREES COMPARISON (UNIT: SECONDS)  PS algorithm and Apriori algorithm is the most important differences are as follows: For the transactions handled directly by the database records began in the first turn down a deal to the last record, the transaction data, the number of direct summation occurs, support and the calculation of confidence by the whole set of database records and projects the number of individual terms, do not need to repeatedly scan the database in order to achieve set of all segments of the project related information.

For the new record is concerned, do not need to re-scan the entire database, just need to be addressed in the new record, and then connect the record before the processed information items can be set for all calculations of support.

Suppose there are N transactions in the data records, and records of all transactions in all there are L items, additional transaction m records, N is much larger than m; generally Apriori algorithm is an algorithm must be based on each new record time, to re-scan that contains all the database records new record, while the PS algorithm is simply to do only deal with new records and then connect the original profile. If the  calculation of the general algorithm's time complexity of the formula is expressed as ? (L2 (N + m)), then the right PS in terms of time complexity of the algorithm, it can be expressed as ? (N + m). From these two formulas can be seen, similar to the Apriori algorithm in all the more the number of records in the database for a long time, its time complexity will be spent with the amount of data indexed to the size of L increases, while the PS algorithm as a way of dealing with records Single record processing, so the time complexity is not with the overall record of changes in the amount of change, and the PS algorithm is the processing time increases in the record real-time processing, there is no need to spend some extra time for data pre-processing. But the PS algorithm in storage space, but it will cost several times more than the Apriori algorithm for large storage space, so PS algorithm is a kind of storage space in exchange for mining of time there.



IV. CONCLUSIONS  In recent years, data mining technology has aroused great concern in the IT industry, which is rapidly growing volumes of data and the growing contradictions between the meager amount of information the inevitable result.

This article focuses on how to improve the efficiency of association rule mining algorithm on the core issue in depth and meticulous research. Proposed rules for the operation of a relatively quick and simple algorithm: PS algorithm. The algorithm scans the database only when the scan once, read things in the database records, transaction records directly to find the corresponding can be set for all their own. Therefore, high efficiency, quick and easy. Faced with data mining and association rule mining boom of the hot research and broad market prospect, this paper has said is very limited, and many issues remain to be studied further. Although the PS algorithm as compared with the Apriori algorithm is more efficient, but this is the space for the price. I believe there are other and better improved algorithm, pending further study.

