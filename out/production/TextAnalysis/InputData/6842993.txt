

Abstract: Data transfer is a big overhead for cloud workflows due to pay-as-use business model of cloud environment. In such environment, the cost arising from data transfers between resources as well as execution costs must also be taken into account during scheduling based upon user?s Quality of Service (QoS) constraints.

In this paper, we present Priority based Genetic Algorithm BCHGA to schedule workflow applications to cloud resources that optimize the total cost of workflow within the user?s specified budget. Each workflow?s task is assigned priority using bottom level (b-level) and top level (t-level). To increase the population diversity, these priorities are then used to create the initial population of BCHGA. The proposed algorithm is simulated in java and evaluated with synthetic workflows based on realistic workflows from the different areas by considering the pricing model of cloud service provider like Amazon. The simulation results show that our proposed algorithm has a promising performance as compared to Standard Genetic Algorithm (SGA).

Keywords: Cloud Computing, Workflow, Scheduling, DAG, Genetic Algorithm, b-level, t-level.

INTRODUCTION  Cloud computing delivers hardware infrastructure and software applications as services on demand over Internet through virtualization [1, 2]. It adopts a market- oriented business model where users are charged for consuming cloud services such as computing, storage, and network services like conventional utilities in everyday life (e.g. water, electricity, gas, and telephony) [3] on a pay-as-you-go basis.

Workflow scheduling is one of the key challenging issues in the cloud workflow systems. It allocates suitable resources to workflow tasks such that the execution can be completed to satisfy objective functions imposed by users [4].

There are two major types of scheduling for grid workflows: best-effort based and QoS constraint based scheduling [5]. These scheduling algorithms attempt to minimise the execution time, ignoring other factors such as the monetary cost of accessing resources. But, as Cloud computing adopts ?market-oriented business model?, so there is another important parameter other  than the execution time, i.e., cost of accessing resources [6]. Usually, faster resources are more expensive than the slower one. Therefore, scheduling algorithms applicable in grid workflow scheduling cannot be directly applied over cloud workflow applications [7].

In this paper, we proposed Budget Constrained Priority based Genetic Algorithm (BCHGA) to schedule applications to cloud resources that optimize the total cost ( sum of execution cost and data transfer cost) for running the workflow and also minimize the execution time under the budget constraint. The remaining paper is organized as follow: the related work done in the area of workflow scheduling for distributed computing is presented under title: Related Work. The workflow scheduling model used in experiment is explained in section: Workflow Scheduling Model. The Standard Genetic Algorithm (SGA) and proposed BCHGA are discussed in Section titled Standard Genetic Algorithm and Proposed Algorithm respectively. The proposed BCHGA is evaluated and compared with SGA in section Performance Evaluation and the paper is concluded in section Conclusion and Future Work.

RELATED WORK  Workflow scheduling is classical NP-complete problem.

The major grid workflow scheduling algorithms have been classified into two basic categories which are best- effort based scheduling and QoS constraint based scheduling [5]. In traditional community based computing paradigms, best-effort based scheduling strategies based are often applied to only minimize the execution time without considering the monetary cost since resources are shared freely among system users.

Many heuristic algorithms such as Minimum Execution Time, Minimum Completion Time, Min-min, and Max- min are used as candidates for best-effort based scheduling strategies [8]. Many researchers used Genetic Algorithm (GA) for task assignment. The fitness function of GA is developed to encourage the formation of the solutions to achieve the budget and deadline constraint time minimization of workflow execution in grids while meeting a specified budget for delivering results [9]. A Hierarchic Genetic Scheduler [10] is developed for improving the effectiveness of the single population genetic based scheduler in the dynamic grid environment for scheduling independent jobs. The authors considered the bi-objective independent batch job scheduling problem with        makespan and flowtime minimized in hierarchical mode. Furthermore, a two phase algorithm, called H2GS [11] has been proposed for task scheduling in heterogeneous processor networks. The first phase implements a heuristic list based algorithm, called LDCP to generate a high quality schedule. In the second phase, this schedule is injected into the initial population of GA, which proceeds to evolve shorter schedules. In [12], the author embedded the elitism method into GA to generate the shorter schedules as well as to decrease the computation time to find the sub- optimal schedule as compared to basic GA. The authors further extend their work by improving sub-optimal results using Simulated Annealing (SA) [13] by considering the multiprocessor systems.

For cloud workflow systems, mainly QoS- constraint based scheduling strategies based on market- oriented business model are required. A compromised- time-cost scheduling algorithm has been proposed to accommodate transaction-intensive [14] and instance- intensive [15] cost-constrained workflows in cloud respectively by compromising execution time and cost with user input enabled on the fly. The algorithm cut down the mean execution cost by over 15% whilst meeting the user-designated deadline or shortens the mean execution time by over 20% within the user- designated execution cost. A market-oriented hierarchical scheduling strategy [16] has been developed for instance intensive workflow applications, to do the workflow scheduling at two levels in cloud environment. A package based random scheduling algorithm has been presented as the candidate service- level scheduling algorithm and three representative metaheuristic based scheduling algorithms including GA, Ant Colony Optimization (ACO) and Particle Swarm optimization(PSO) were adapted, implemented and analyzed as the candidate task-level scheduling algorithms under the different QoS constraints.

However, all these work do not consider different pricing model of cloud environment. Saeid et al., [17] proposed two workflow scheduling algorithm for cloud environment: one-phase algorithm, IC-PCP and two-phase algorithm, IC-PCPD2. Both algorithms have a polynomial time complexity for scheduling large workflows under deadline constrained. The author considered different type of pricing model for simulation. So we used Genetic Algorithm to schedule workflow applications to cloud resources by considering the pricing model as specified by Amazon [18]. In this paper, we focus on minimizing the execution cost and time while meeting the user specified budget for delivering the result.

WORKFLOW SCHEDULING MODEL  A workflow application is modelled by a Directed Acyclic Graph (DAG), defined by a tuple G (T, E),  where T is the set of n tasks {t1, t2,......,tn}, and E is a set of e edges, represent the dependencies. Each ti ? T, represents a task in the application and each edge (ti..........tj) ? E represents a precedence constraint, such that the execution of tj ? T cannot be started before ti ? T finishes its execution [19]. If (ti, tj) ? T, then ti is the parent of tj, and tj is the child of ti. A task with no parent is known as an entry task and a task with no children is known as exit task.

Basic Definitions  Bottom level (b-level). The b-level of a task is the length of the longest path from the task to a leaf task [13]. The b-level of node is calculated as:  (1) where wi is the average execution time of the task on the different computing machines. succ(ti) includes all the children tasks of ti. dij is the data transmission time from a task ti to tj. If a task has no children, its b-level is equal to the average execution time of the task on the different computing machines.

Top-level (t-level). The t-level of a task of DAG is defined to be the length of the longest path from the task to the entry task without considering the execution time of  that task [13] and is given by the following equation:  (2) where wi is the average execution time of the task on the different computing machines. pred(ti) includes all the parent tasks of ti. dij is the data transmission time from a task ti to tj. For entry task i.e. a task has no parent, its t- level is equal to zero.

Estimated Completion Time (ECT). The ECT is a n x m matrix where ECTi,j shows the estimated completion time of a task ti on the machine mj. The users are charged based upon the number of time intervals that they have used the particular machine. All computation and storage services of service provider are assumed to be in the same physical region, so the average bandwidth between the different available machines is roughly equal [17].

An Illustrative Example  Consider a DAG with 11 tasks as shown in Figure 1.

Each edge weight of DAG represents the data transmission time between the tasks.Table I shows the expected completion time of various tasks on three different machines. b-level and t-level of all tasks is calculated using equation (1) and (2) respectively. Then the tasks are sorted in descending order of b-level and in ascending order of t-level to decide the order of execution of all the tasks (Table II).The tasks are sent to different machines according to their order of execution for completion of workflow application. Figure 2 and 3 shows the schedules generated according to b-level and t-level of DAG respectively.

Fig. 1:  A Sample DAG   Machines  M1 M2 M3  T1 3 5 1 T2 2 3 1 T3 3 5 1 T4 2 3 1 T5 2 3 1 T6 2 3 1 T7 2 3 1 T8 4 6 2 T9 3 5 1 T10 2 3 1 T11 5 7 3   Table  1: ECT Matrix       Fig. 2: Schedule according to b-level     Fig. 3: Schedule according to t-level  Parame t- ers  Tasks  AvgEC T  b- leve l  t- leve l  Order of Executio n accordin g to b- level  Order of Executio n accordin g to t- level  T1 3 16 0 2 1  T2 2 17 0 1 2  T3 3 14 0 3 3  T4 2 13 0 4 4  T5 2 11 5 5 5  T6 2 8 6 7 6  T7 2 10 7 6 7  T8 4 4 12 9 10  T9 3 3 11 10 9  T10 2 2 10 11 8  T11 5 5 12 8 11   Table 2:  b-level and t-level of DAG   STANDARD GENETIC ALGORITHM (SGA)  Standard Genetic algorithm (SGA) is a specific class of evolutionary algorithms inspired by evolutionary biology. Any solution in the search space of the problem is represented by an individual or chromosome [20]. A genetic algorithm maintains a population of individuals that evolves over generations towards the better solutions through a repetitive application of genetic operators such as crossover, mutation and selection [21]. The quality of an individual in the population is determined by a fitness-function. The fitness value indicates how good the individual is compared to others in the population [22].  For Budget constrained scheduling problem, SGA defines a fitness function as:  (3)  where c(I) is the total cost of  an individual, I and B is the user specified budget for scheduling the workflow application. An individual is fit if the value of F(I) < 1, otherwise the individual is not included into the population.

The pseudocode for Standard Genetic Algorithm (SGA) is given as:  T2 T5 T10 T11  T3 T6 T9  M1:  M2:  M3:  T4 T7 T8 T1  T1 T5 T11 T10  T3 T7 T8  M1:  M2:  M3:  T4 T6 T9 T2  T1 T2 T3 T4  T8  T5 T7  T10 T9  T6  T11      5 1 3 1  5 3  1 3        Pseudocode for SGA 1. BEGIN 2. Create an initial population consists of randomly  generated solutions.

3. While termination criteria is not met do 4. Evaluate the fitness of the individual in the  population using equation (3).

5. Apply the selection operator to select the parent  from the population 6. Apply the crossover operator on the selected  parent using crossover probability Cr to create the children.

7. Apply the mutation operator with probability Mr on the newly created children.

8. Validate each child according to the fitness function.

9. Add the valid child to create the new population 10. end while.

11. END  To increase the population diversity of SGA, we proposed Budget Constrained Priority based Genetic Algorithm.

PROPOSED ALGORITHM  We proposed BCHGA, in which bottom level and top level of workflow tasks are used to assign priority to different workflow tasks. The pseudcode of BCHGA is given below Pseudocode for BTGA  1. BEGIN  2. Calculate the b-level and t-level of all the tasks of workflow using the equations (1) and (2).

3. Create the initial population of BCHGA as for all the individuals, firstly, the priority of each task is set equal to the total of its b-level and a random number which is generated in the range of  its (t-level/2, -t-level/2). Then all the tasks are assigned to the available machines according to their priority. Each individual is encoded using the 2-d encoding.

4. While termination criteria is not met do  5. Evaluate the fitness of the individual in the population using equation (3).

6. Apply the selection operator to select the parent from the population  7. Apply the crossover operator on the selected parent using crossover probability Cr to create the children.

8. Apply the mutation operator with probability Mr on the newly created children.

9. Validate each child according to the fitness function.

10. Add the valid child to create the new population  11. end while.

12. END   PERFORMANCE EVALUATION  In this section, we present our simulations of l the proposed algorithm. To evaluate the workflow scheduling algorithm, we used five synthetic workflows based on realistic workflows from diverse scientific applications, which are:   Montage: Astronomy CyberShake: Earthquake Epigenomics: Biology LIGO: Gravitational physics SIPHT: Biology   The detailed characterization for each workflow  including their structure and data and computational requirements can be found in [23]. Figure 4 shows the approximate structure of a small instance of each workflow. The DAX (Directed Acyclic Graph in XML) format for all these workflows are available at [24], from which we have chosen three sizes for our experiment, i.e., Small (about 50), Medium (about 100 tasks) and large (about 1000 tasks).

Experiment setup  For our experiment, we have simulated a cloud environment in java The processor speeds of VM?s are selected randomly in the range of 1000-5000 MIPS and price of using these VM?s is set within a range of 2-10 basic units such that fastest VM is roughly five times more expensive than the slowest one. The average bandwidth between these is roughly equal [17].To evaluate the impact of time interval on our algorithm, we consider long time interval equal to one hour like Amazon [18].

Performance Metrics  The performance metric chosen for the comparison is Normalized Schedule Length (NSL). The NSL of a schedule is calculated as:           where Mc is the execution time of the same workflow by executing all the tasks on the fastest VM, according their precedence constraints.

For assigning the budget, first we define the cheapest schedule as scheduling each workflow tasks on the fastest VM, according their precedence constraints, considering all data transmission cost as zero. Thus the execution cost of this fastest schedule, denoted by Cf, is a lower bound for the budget of executing workflow.

So, the budget for whole workflow is defined as:   Budget= ? * Cf  where ? is a budget factor in range from 1.5 to 5 .

For GA, the following parameters are set:  Parameter Value Initial population 10 Crossover Probability (Cr)  0.7  Mutation probability (Mr)  0.1  Maximum Generation 50      Fig. 4: Structure of Various Workflows [23]   Experiment Result  As GA is a stochastic algorithm, so each algorithm is run for 10 times for each workflow and average value of  NSL is used for comparing BCHGA, and SGA.  Figure 5 shows the average NSL of scheduling large workflows with BCHGA, and SGA with time interval equals to one hour. It shows that BCHGA outperforms than the SGA in all cases.  It is clear from the Figure 5(a) and 5(e) that average NSL for Montage and Cybershake is high as compared to other workflow structures as both of these workflow structure consist of large number of tasks with smaller execution time on fastest VM at the second row, thus increasing the overall execution cost of the workflow. For scheduling small and medium size workflow, we are getting the similar graphs.

(a) Montage      (b) Epigemonics     (c) SIPHT       1.5 2.5 3.5 4.5 N  SL ---  --- >  ?--------->  BCHGA  SGA       1.5 2.5 3.5 4.5  N SL  --- ---  >  ?--------->  BCHGA  SGA       1.5 2.5 3.5 4.5  N SL  --- ---  >  ?----------->  BCHGA  SGA           (d) LIGO    (e) CyberShake  Fig 5: The NSL of scheduling workflows with BCHGA, and SGA with the time interval equals to 1 hour.

CONCLUSION AND FUTURE WORK  In this paper, we have presented Budget Constrained Priority based Genetic Algorithms, BCHGA to schedule applications to cloud resources that minimizes the execution cost while meeting the Budget for delivering the result. Each workflow?s task is assigned priority using bottom level and top level. These priorities are then used to create the initial population of BCHGA.

The proposed algorithm is evaluated with synthetic workflows that are based on realistic workflows with different structures and different sizes. These algorithms also consider the pay-as-you-use pricing model of current commercial cloud like Amazon. The comparison of proposed algorithms is done with SGA under same budget constraint and pricing model. The simulation results show that our proposed algorithms have promising performance as compared to SGA. In future we intend to improve our work for the real cloud environment including other QoS constraints and comparison can be made with other meta-heuristic techniques like PSO and ACO etc.

