<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Scrutinizing  Frequent Pattern Discovery Performance

Abstract Benchmarking technical solutions is as important as the solutions themselves. Yet many fields still lack any type of rigorous evaluation. Performance benchmarking has al- ways been an important issue in databases and has played a significant role in the development, deployment and adop- tion of technologies.

To help assessing the myriad algorithms for frequent itemset mining, we built an open framework and testbed to analytically study the performance of different algorithms and their implementations, and contrast their achievements given different data characteristics, different conditions, and different types of patterns to discover and their con- straints. This facilitates reporting consistent and repro- ducible performance results using known conditions.

1 Introduction Mining for frequent itemsets is a canonical task, fun- damental for many data mining applications and is an in- trinsic part of many other data mining tasks. Mining for frequent itemsets is the major initial phase for discovering association rules. Associative classi?ers rely on frequent itemsets. These frequent pattern are also used in some clus- tering algorithms. Finding frequent items is also an inher- ent part of many data analysis processes. Many frequent itemset mining algorithms have been reported in the last decade. From the famous Apriori algorithm[1], many ex- tensions and sophisticated implementations have been sug- gested. Recently, new approaches relying on intricate data structures have been introduces claiming to outperform the apriori-based techniques. Some algorithms model transac- tions horizontally. Others transpose vertically the transac- tions. Some techniques traverse the pattern search space top-down, Others favour a bottom-up strategy. The puzzling reality is that most of these authors, when publishing their work claim to outperform, with their new method, the rest of the pack, supporting their claim with experiments care- fully planned. Unfortunately, given some conditions and datasets, it is very dif?cult to know which algorithm is the most appropriate. A recent study [18] has shown that with real datasets, Apriori, the oldest algorithm for mining fre- quent itemsets, outperforms the newer approaches. Do we then need any of these new sophisticated approaches? An analysis done recently for a workshop on frequent itemset mining[7] demonstrates the importance of ?ne and clever implementations of algorithms, making the selection of an appropriate approach even more perplexing.

What has rarely been directly reported is that when dealing with extremely large datasets, discovering frequent itemsets is an impossibility for most algorithms. The prob- lem is reduced to ?nding the set of frequent closed itemsets or the set of frequent maximal itemsets. A frequent itemset X is closed if and only if there is no X ? such that X ? X ?

and the support ofX equals to the support ofX ?. A frequent itemsetX is said to be maximal if there is no frequent item- set X ? such that X ? X ?. Frequent maximal patterns are a subset of frequent closed patterns, which are a subset of all frequent patterns. Finding only the closed item patterns reduces dramatically the size of the results set without loos- ing relevant information. From the closed itemsets one can derive all frequent itemsets and their counts. Directly dis-  covering or enumerating closed itemsets can lead to huge time saving during the mining process. The set of maxi- mal frequent itemsets is found, in general, to be orders of magnitude smaller in size than the set of closed itemsets, and the set of closed itemsets is found, in general, to be or- ders of magnitude smaller in size than the set of all frequent    ders of magnitude smaller in size than the set of all frequent itemsets [5]. While we can derive the set of all frequent itemsets directly from the maximal patterns, their support cannot be obtained without counting. Again, many algo- rithms have been proposed to ?nd these types of patterns.

Nonetheless, the exact thorough comparison between pro- posed approaches is still lacking and researchers as well as developers are still perplexed when it comes to selecting an appropriate approach for mining a given dataset.

The state of affairs is even more complex since there is also the issue of expressing constraints on the patterns to discover. While some algorithms cannot treat these con- straints and a post-pruning is necessary, others can handle 1084-4627/05 $20.00 ? 2005 IEEE during the mining process some types of constraints. Dif- ferent types of constraints can be enforced on the patterns to discover: monotone and anti-monotone[12]. These con- straints are expressed using aggregations on descriptors of items such as price, weight, height etc. of an item in a trans- action. Yet again different claims are made [13, 4] but a rig- orous comparison between constraint-based itemset mining algorithms has never been reported.

We propose a framework and a performance testbed to compare any frequent pattern mining algorithm given dif- ferent datasets and dataset characteristics, and providing different parameters and constraints on the patterns to dis- cover. The reporting obtained provides a consistent and pre- cise analysis to discriminate among the approaches given speci?ed conditions.

2 The benchmarking testbed The testbed consists of a collection of real datasets, such as the UCI dataset collection [14], the world- cup98 weblog [16], the ?mi collection [7], and synthetic datasets generated by the IBM QUEST data generator [11], as well as an interface (API) allowing the attach- ment of a variety of algorithms. Some representatives of this set of algorithms are: The Apriori implemen- tation from [3], Closet+[15], ChARM[17], FPMAX[9], GenMAX[8], MAFIA[5], MaxMiner[2], FP-Growth[10], COFI+[6], dualminer[4], and other implementations shared in the ?mi forum [7]. The testbed also includes a collec- tion of pre-computed tests and benchmarks, and a graphical user interface to tune the available parameters and specify constraints on the patterns to discover.

Input GUI Meta data - on support Output GUI Algorithm 2 . . . Algorithm nAlgorithm 3Algorithm 1 API Testing Engine densedense SparseSparse - on itemset form data Synthetic Real - on meta data - all  - maximal - closed definition Parameter definition Constraint db Benchmark Reporting Performance Result and    Result and Data generator data 3 Value to the community The workshop on Frequent Itemset Mining Implemen- tations held in conjunction with the IEEE International Conference on data Mining in 2003 and 2004 brought to- gether eminent researchers working on various issues re- lated to frequent itemset mining. The agreement of the attendees was that the research community needs reliable means to rigorously analyze algorithm performance and verify claims. Given the experimental algorithmic nature of frequent itemset mining, it is crucial that other researchers be able to independently verify the claims made by authors of new algorithms [7].

Another important issue raised is the issue of providing a common set of databases for testing frequent itemset min- ing. We intend to make our data collection as well as the benchmarking system as part of the ?mi shared repository [7]. The signi?cance of our performance benchmarking system is measured by the interest expressed by researchers in the ?eld of frequent itemset mining and data mining as a whole. We expect the testbed to have a signi?cant impact in the community and would constitute an initial stage to- wards de?ning a framework for benchmarking algorithms for other data mining tasks.

