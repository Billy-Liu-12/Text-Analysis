Regression-Based Fusion Prediction for Collaborative Filtering

Abstract?Existing memory-based collaborative filtering tech- niques predict the unknown preference by taking weighted average of ratings by similar users on the active item or ratings of similar items by the active user, which just make use of the predictive power of ratings located in the row or column of user-item matrix corresponding to the active user or the active item. Due to sparsity, it is possible that some highly similar users have not rated the active item or some highly similar items have not been rated by the active user, resulting in they contributing nothing to the prediction. In this paper, first we propose improved regression-based methods to model the prediction of individual rating for the unknown preference. Then we propose regression-based fusion prediction(RBFP) algorithm, which adopts two-stage linear regression technique to exploit the predictive power of these unrated but highly similar items and these highly similar users who have not rated the active item. We have conducted extensive experiments, especially, we have investigated the sensitivity of parameters over the time, performance variation with the size of memory space available.

Having done comparisons with some popular recommendation algorithms, we can conclude that our proposed methods can indeed improve the performance of collaborative filtering.



I. INTRODUCTION With the explosive growth of the amount of content avail-  able on the web, customers are suffering the problem of information overload, which has motivated the development of recommendation system. This system aims at recommending ones from a tremendous number of items to a user that might interest him/her, based on his/her historical behaviors, item- s?attributes and some other information. Collaborative Filtering (CF), as the most successful recommendation techniques, has been very popular in both academia and industry. Because it is easy-to-implement and highly effective, memory-based CF has been adopted by many commercial systems such as Amazon.

However, conventional CF methods also encounter a number of challenges, such as data sparsity, scalability, cold-start and so forth [23].

When predicting an unknown preference, memory-based CF first measures similarities between the active user and other users (user-based), or, between the active item and other items (item-based), to select some neighbors. Then it makes prediction by taking weighted average of ratings of these neighbors. This kind of methods just make use of the predictive power of ratings located in the row or column of user-item matrix corresponding to the active user or the active item.

User-based( [10], [19]) methods select neighbors only from users who have rated the active item, while item-based( [21], [12]) methods select neighbors only from items that have been rated by the active user. However, in practice, users who have rated the active item or items that have been rated by the active user only take, on average, a small proportion of the  whole users or items, so these algorithms have poor robustness against data sparsity. In order to alleviate sparsity, similarity fusion(SF) [25] algorithm combines ratings of similar items and ratings by similar users with ratings by similar users on similar items to make prediction. However, user-based and item-based algorithms as well as SF all neglect the information from some highly similar users who have not rated the active item by chance and some highly similar items that have not been rated by the active user.

In this work, when making prediction for the unknown preference, we think these highly similar but unrated items and users that are highly similar but have not rated the active item can also provide helpful information. These information can be used to enhance robustness against sparsity and improve predictive reliability. If some users have not rated the active item, we will exploit the predictive power from her ratings on some items that are highly similar to the active item. If some items have not been rated by the active user, we will exploit the predictive power from their ratings by some users who are highly similar to the active user. First, we propose improved regression-based methods to exploit the predictive power from ratings by similar users on the active item or ratings of similar items by the active user, then we adopt two-stage regression technique to model the prediction of individual rating of highly similar items by some users who have not rated the active item and ratings by highly similar users on some items that have not been rated by the active user. We fuse predictions from four sources: similar items that have been rated by the active user, similar items that have not been rated by the active user, similar users who have rated the active item, similar users who have not rated the active item, to form the final prediction.

Additionally, many traditional CFs aim at predicting the relevance accurately for all of the user-item pairs, so they often adopt predictive accuracy metric to evaluate their algo- rithms. However, as pointed by [4], errors committed by the predictions for irrelevant user-item pairs will not be perceived by users. Besides the traditional metric RMSE, we adopt two new metrics inspired by [4] to evaluate our algorithm. We have conducted extensive experiments and obtained evidences to show that our algorithm outperforms some popular CFs.

The remainder of the paper is organized as follows. In section II, we summarize related work about recommendation techniques. In section III, we introduce several popular col- laborative filtering methods. In section IV, we propose our new method RBFP. In section V, we provide an experimental evaluation of our methods and comparison with algorithms introduced in III, in terms of several metrics. Finally, we conclude our work in section VI.

DOI 10.1109/CLOUDCOM-ASIA.2013.88    DOI 10.1109/CLOUDCOM-ASIA.2013.88

II. RELATED WORK Collaborative filtering techniques can be categorized into  memory-based methods, model-based methods and hybrid methods.

Memory-based methods compute the similarity between users (user-based) or items (item-based) to select neighbors and make prediction by taking weighted average of ratings of neighbors. Similarity measure is critical to this kind of methods. Similarity measure between users often adopt Pear- son correlation coefficient [19] or vector cosine [3]. [21] pro- poses adjusted cosine similarity while [12] adopts conditional probability-based similarity to measure the similarity between items. [5] computes similarity between users by assigning greater weight to items that are more similar to the active item so that the active user can select different neighbors for different active item. [13] employs linear combination of predictions made by user-based and item-based approach respectively to predict the missing ratings in user-item matrix.

Model-based methods try to address data sparsity and scalability problems that memory-based methods encountered.

Clustering techniques are widely used by CF to overcome scalability challenge. Based on known ratings, [22] applys clustering algorithms to partition the set of users while [15] partitions the set of items, then the prediction are computed independently within each cluster. ClustKNN [18] computes the similarities between the active user and surrogate users who are derived from centroids of each user cluster and then takes weighted average of ratings of surrogate users to make prediction. [7] adopts Bregman co-clustering to simultaneously partition the set of users and items, which can scale well with large dataset and also can adapt to changes in the user- item matrix more effectively. Some dimensionality reduction techniques are used to find low-dimensional representations for users or items so that better cluster structure can be found based on these new representations. [26] maps all users and items into a shared low-dimensional space by solving involved trace minimisation problem, and then clusterings items and users based on their shared low-dimensional representation so that each user and item can be affiliated with multiple subgroups. Eigentaste [8] conducts PCA on a submatrix which consists of ratings by all users for all items in the gauge set to obtain new representations for every user. [2] constructs a user graph in which every vertex corresponding to a user and every edge weight is the similarity between two users, then adopts Normalised Cut algorithm to obtain new representations for all users. To alleviate the sparsity problem, matrix factorization are used, such as Regular Singular Value Decomposition (RSVD)( [6], [16]), Weighted Non-negative Matrix Factoriza- tion (WNMF) [27], Probabilistic Matrix Factorization (PMF) [20]. [9] constructs user graph and item graph according to external information such as demographic information and items genre information and unifies this two graphs regularized problem with WNMF of user-item matrix to improve the recommendation accuracy.

Content-based methods [17] can provide recommendation for cold-start items and users based upon elaborate description of items, which is often difficult for multi-media product.

Content-Boosted CF [14] uses output of naive Bayesian classi- fier as content-based prediction and then fills these predictions in the missing values of the rating matrix and it makes predictions over the resulting ratings matrix. Queveo.tv [1], a  TV program recommendation system, gives user a selection of programs, some of them are content-based recommendations, while others are collaborative recommendations.



III. BACKGROUND This section briefly presents problem definition and sev-  eral popular collaborative filtering algorithms which will be compared with our methods.

A. Notations and Problem Definition Supposing there are m users and n items, ratings by users  on items can be represented as a m?n matrix R = (ru,i)m?n, called user-item matrix. If ru,i ?= 0, it is a known rating by user u on item i, otherwise it is an unknown rating, which means user u did not rate item i. In this work, we try to predict the unknown ratings in user-item matrix. When making prediction for unknown rating by user u on item i, we call user u as the active user and item i as the active item.

U and I denotes all the users and all the items, respectively.

Ui denotes the set of users who has rated item i. Iu denotes the set of items that have been rated by user u. Let Uij = Ui  ? Uj , which denotes the set of users who has rated both  item i and item j. Iuv = Iu ?  Iv , means these items that have been rated by user u as well as by user v. nij = |Uij | means the cardinality of set Uij . nuv = |Iuv| means the cardinality of set Iuv . r?u denotes the mean of all the known ratings that user u has given. r?i denotes the mean of all the known ratings of item i. We put the definitions of some other notations in the Appendix.

B. user-based and item-based CF User-based and item-based approaches first compute the  similarities between users or items to select neighbors, and then make prediction by applying weighted average of ratings of neighbors. Pearson correlation coefficient(PCC) is common- ly used to measure the similarity between users. PCC between user u and user v is:  Corr(u, v) =  ? i?Iuv (ru,i ? r?uvu )(rv,i ? r?uvv )??  i?Iuv (ru,i ? r?uvu )2 ??  i?Iuv (rv,i ? r?uvv )2  With some new notations in the Appendix, PCC can also be written as follows:  Corr(u, v) = Luvuv? LuvuuL  uv vv  User-based methods ( [10], [19]) predict the unknown ratings as follows:  r?u,i = ru +  ? v?Uk1i  Corr(u, v)(rv,i ? rv)? v?Uk1i  |Corr(u, v)| (1)  Uk1i consists of k1 users who have rated item i and are the most similar to user u. If |Ui| < k1, then Uk1i = Ui.

[21] proposed adjusted cosine measure for estimating the similarity between item i and item j:  ACosine(i, j) =  ? u?Uij (ru,i ? r?u)(ru,j ? r?u)??  u?Uij (ru,i ? r?u)2 ??  u?Uij (ru,j ? r?u)2  The item-based method [21] predicts the unknown rating as follows:  r?u,i =  ? j?Ik2u ACosine(i, j)ru,j? j?Ik2u |ACosine(i, j)|  (2)     where Ik2u consists of k2 items that have been rated by user u and are the most similar to item j. If |Iu| < k2, then Ik2u = Iu.

C. Similarity Fusion  Wang et al [25] proposed Similarity Fusion(SF) algorithm by using as much information available from user-item matrix as possible to obtain better prediction in sparse matrix contexts.

Let SUR = {rv,i|v ? UNi }, SIR = {ru,j |j ? INu } and SUIR = {rv,j |v ? UNi , j ? INu }. Similarity Fusion predicts the unknown ratings as follows:  r?u,i = ? rv,j  W v,ju,i (rv,j ? (r?v ? r?u)? (r?j ? r?i)) (3)  W v,ju,i =  ?????????????  Cosine(u,v)?(1??)? rv,i?SUR Cosine(v,u)  rv,j ? SUR ACosine(i,j)(1??)(1??)?  ru,j?SIR |ACosine(i,j)| rv,j ? SIR  Sim(u,i;v,j)?? rv,j?SUIR Sim(u,i;v,j)  rv,j ? SUIR 0 otherwise  where  Sim(u, i; v, j) = |ACosine(i, j)|Cosine(u, v)? ACosine(i, j)2 + Cosine(u, v)2  Cosine(u, v) denotes the cosine of angle between two row vectors of user-item matrix corresponding to user u and v.

D. Regularized SVD Among matrix decomposition-based CF, regularized singu-  lar value decomposition(RSVD) [6] is a really popular algo- rithm. In this model, every item and every user are presented as K-dimensional feature vectors, such as useru and itemi.

Predictions are made as follows:  r?u,i = user T u itemi  These feature vectors are estimated by minimizing the sum of squared residuals, one feature at a time, using gradient descent with regularization:  eu,i = ru,i ? r?u,i useru,k+ = lrate ? (eu,iitemi,k ? ?useru,k) itemi,k+ = lrate ? (eu,iuseru,k ? ?itemi,k)  where lrate is learning rate and ? is regularization parameter.



IV. OUR METHOD In this section, first, we propose improved regression-  based collaborative filtering methods, and then we introduce regression-based fusion prediction(RBFP) algorithm.

A. Improved Regression-based CF Because Pearson correlation coefficient can indicate the  fitness level of the linear regression equation between two variables, so when we adopt PCC similarity, we can apply weighted average of predictions made by some regression equations. Assuming av?u and bv?u are the coefficients of regression equation in which user v corresponds to explanatory variable and user v corresponds to respond variable, then:  bv?u = Luvuv Luvvv  , av?u = r?uvu ? bv?ur?uvv  Instead of using KNN strategy to select neighbors, we think all users who have rated the active item could provide some useful information for prediction of the unknown preference.

However, as many literatures mentioned, it will decrease the accuracy because of much noise from many less correlative neighbors. We will use exponentially weighted average to make prediction in order to weaken the influence from less correlative neighbors. In addition, in order to avoid false high correlation by few co-rated items, we adopt significance weighting( [10], [13]), which means the similarity would be:  sim(u, v) = min(?1, |Iuv|)  ?1 Corr(u, v)  then, we predict unknown ratings by following formula:  r?u,i =  ? v?Ui |sim(u, v)|?1(av?u + bv?urv,i)?  v?Ui |sim(u, v)|?1 (4)  where a larger ?1 can lower the weight assigned to the prediction made by less significant regression equations.

We propose user-based regression method above. Analo- gously, we can propose item-based regression method:  r?u,i =  ? j?Iu |sim(i, j)|?2(aj?i + bj?iru,j)?  j?Iu |sim(i, j)|?2 (5)  where  bj?i = Lijij  Lijjj , aj?i = r?  ij i ? bj?ir?ijj  sim(i, j) = min(?2, |Uij |)  ?2 Corr(i, j)  Corr(i, j) is PCC between item i and item j, which can be written as:  Corr(i, j) = Lijij? LijiiL  ij jj  Note, when ?2 = 1, it is similar to the method mentioned in [21]. [24] also adopts linear regression to predict unknown ratings and proposes a suboptimal but compute-efficient weight assigned scheme to aggregate the prediction made by good predictors. Different from [24], we adopt simpler exponential weight assigned scheme.

B. Regression-Based Fusion Prediction  ?? ??  ?? ? ?  ?? ???? ??  ??  ??  ??????? ??  ??????? ????  Fig. 1: RBFP     When we predict the preference of user u to item i, we can rearrange the columns and rows of user-item matrix for the sake of visualization of our idea. We can first relocate rows corresponding to users who have rated item i so that the distance from row u to these rows is proportional to the similarity between user u and these users. Then we relocate rows corresponding to users who have not rated item i, so that the more similar to user u these users are, the more close to row u the corresponding rows are. Analogously, we can rearrange all columns. Fig.1 gives a simple example of the real user-item matrix. The gray cells represent the corresponding ratings are unknown. The green cells represent those ratings by the most similar 4 users who have rated item i, of which user-based method takes weighted average to make prediction. The blue cells represent ratings of the most similar 4 items that have been rated by user u, the item-based will use their information to make prediction. Similarity fusion algorithm argues that ratings by similar users on similar items may provide extra helpful information, which utilizes the information from the purple cells and the green as well as the blue ones to make prediction.

Due to sparsity, it is possible that some highly similar users towards user u have not rated item i. For example, user u2 is highly similar to the active user u because they have assigned similar ratings for many co-rated items. However, user u2 have not rated item i resulting that it contributes nothing to predict the rating by u on i, according to user-based and item-based as well as similarity fusion method. However, we think user u2 can still provide some useful information for prediction because she has rated item i1,i2,i3 and i4 ,which are highly similar to the active item i, we can use her ratings on these similar items to approximate her ratings on item i. Although some users have not rated the active item, we think they can make contribution to prediction on the condition that they have rated some items that are highly similar to the active item. In other words, we will mine the useful information for prediction from these red cells.

??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ???  ???  ???  ???  ???  ??  ??  ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  Fig. 2: Predictive Information  Fig.2 exhibits the heatmap of a real user-item matrix from dataset MovieLens ml-100k. It shows the distribution of predictive information embedded in every cell of user- item matrix. Pixel value of cell (v, j) is |sim(u, v)sim(i, j)| if rv,j ?= 0, 0 otherwise. We can find that at the top and bottom of Fig.2, there are many highlights, which just shows that although some user have not rated the active item, they can contribute to the prediction based on their ratings on some  similar items. Note, these similar items might have been rated by the active user or not, so we can find highlights distributed discontinuously along the horizontal direction.

In order to combine prediction made by these ratings by similar users on highly similar items with that made by regression-based methods proposed above, we propose two- stage linear regression technique. If user v is similar to the active user u, he/she can make prediction based on his/her ratings on similar item j towards the active item i. Mathemat- ically, we can formulate it as follows:  P v,ju,i = av?u + bv?u(aj?i + bj?irv,j)  Here, we have done regression twice , as shown the black solid arrow in Fig.1, so we weight this individual prediction with  W v,ju,i = |sim(u, v)sim(i, j)| Nk3i denotes the set of k3 items that are the most similar to the active item i. Specially, we think positive relevant and negative relevant items or users can play roles for prediction with the same importance from mathematical perspective. So :  Nk3i = {j|rank(|sim(i, j)|) ? k3}, in addition, Uvj/i denotes the set of users who have rated item j but have not rated the active item i,  Uvj/i = {v|rv,i = 0, rv,j ?= 0} Now, we can propose the user-based RBFP as follows  r?Uu,i = ?1  ? v?Ui |sim(u,v)|  ?1 (av?u+bv?urv,i) ?  v?Ui |sim(u,v)| ?1  +(1? ?1) ?  j?Nk3 i  ? v?Uv  j/i (W v,ju,i )  ?1P v,ju,i ?  j?Nk3 i  ? v?Uv  j/i (W v,ju,i )  ?1  Analogously, we can find many highlights in the left and right of Fig.2, which shows that although some items which are similar to the active item might have not been rated by the active user, they can make contribution to prediction if they have been rated by some users who are highly similar to the active user. Note, these similar users may have rated the active item or not, so the highlights are discontinuous along the vertical direction. We propose the item-based RBFP:  r?Iu,i = ?2  ? j?Iu |sim(i,j)|?2 (aj?i+bj?iru,j)?  j?Iu |sim(i,j)|?2  +(1? ?2) ?  v?Nk4u ?  j?Iv/u (W v,j u,i )  ?2Qv,ju,i ?  v?Nk4u ?  j?Iv/u (W v,j u,i )  ?2  where  Qv,ju,i = aj?i + bj?i(av?u + bv?urv,j)  Nk4u = {v|rank(|sim(u, v)|) ? k4}, Iiv/u = {j|ru,j = 0, rv,j ?= 0}  Finally, we can combine user-based with item-based RBFP linearly to obtain the final prediction:  r?u,i = ?3r? U u,i + (1? ?3)r?Iu,i

V. EXPERIMENT In this section, we conduct experiments to locate optimal  parameters settings of our methods and conduct comparisons between our proposal and other collaborative filtering tech- niques that have been introduced in section III.

A. Experiment Setup and Evaluation Methodology We use MovieLens ml-100k as our experimental data set.

This data set consists of 100,000 ratings by 943 users on 1682 movies. These ratings take value from 1 (lowest rating) to 5(highest rating). Each user rated at least 20 movies. We adopt 5-fold cross validation, which means the data set is divided into five disjoint splits. One split is used for test and the rest are used for training, in turn. We always report the average results, respectively in terms of several evaluation metrics discussed in the following.

There are many metrics to evaluate the performance of recommendation system, which can be divided into three classes: predictive accuracy metrics, classification accuracy metrics, and rank accuracy metrics [11]. Cacheda et al [4] takes predictive accuracy metrics MAE and classification accuracy metrics Precision and Recall together into account and obtain two new metrics, GIM and GPIM. GIM computes the absolute errors committed by the prediction on the relevance of the user-item pairs that are really relevant and GPIM computes that are thought to be relevant according to the prediction of recommendation system. Analogously, in this paper, we compute ordinary RMSE, GPIR and GIR. GPIR computes errors committed by the prediction for the pairs which are relevant thought by recommendation system. GIR computes errors committed by the prediction for truly relevant user-item pairs. We consider user-item pairs are truly relevant if the actual rating is 4.0 or above and those pairs are thought to be relevant if the predictive rating is 4.0 or above. In addition, we can make an assumption that, only when the predictive rating is greater than 4.0, would the item have the chance to be recommended to the user.

First, we let test denote the set consisting of all the pairs (u, i) in the test set, then  TP = {(u, i)|ru,i ? 4, r?u,i ? 4, (u, i) ? test}  FN = {(u, i)|ru,i ? 4, r?u,i < 4, (u, i) ? test}  FP = {(u, i)|ru,i < 4, r?u,i ? 4, (u, i) ? test}  RMSE =  ???? 1|test| ? (u,i)?test  (ru,i ? r?u,i)2  GPIR =  ???? 1|TP ?FP | ? (u,i)?TP ?FP  (ru,i ? r?u,i)2  GIR =  ???? 1|TP ?FN | ? (u,i)?TP ?FN  (ru,i ? r?u,i)2  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??  ? ??  ? ??  ? ??  ? ??  ? ??  ?  ? ??  ? ??  ? ??   ? ? ?  ??  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ???	??????  ???	??????  ??????????  ??????????  Fig. 3: Impact of parameters settings on RMSE(?3 = 0)  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??  ? ??  ? ??  ? ??  ? ?  ? ??  ? ??  ? ??  ? ? ?  ??  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ???	??????  ???	??????  ??????????  ??????????  Fig. 4: Impact of parameters settings on GPIR(?3 = 0)  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  ? ??  ? ??  ? ??  ? ??  ? ?  ? ??  ? ?  ??  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ??????????  ???	??????  ???	??????  ???	??????  ??????????  ??????????  Fig. 5: Impact of parameters settings on GIR(?3 = 0)  B. Sensitivity of Parameters In order to locate optimal parameters settings of our  method, we have conducted a series of experiments. Note, we fix ?1 = 30 and ?2 = 70 throughout this paper.

First, we investigate the impacts of parameter settings on item-based RBFP. ?2 varies from 0 to 1 with a step value of 0.05, ?2 varies from 1 to 6 with a step value of 1. We set k3 = 10 or k3 = 30. Fig.3 shows the result for the metric RMSE. We can observe that when ?2 takes value from 0.5 to 0.65 with ?2 = 5 or ?2 = 6, RMSE reaches its minimum value. In the same way, we can fix the optimal range of ?2 to be from 0.45 to 0.55 when ?2 = 5 and k4 = 30 according to the metric GPIR(Fig.4). According to GIR(Fig.5), we can eventually fix the optimal value of ?2, ?2 and k4 to be 0.55,5 and 30, respectively. We can observe that when we set parameters to their optimal values, RMSE and GPIR can be improved obviously compared with their value with ?2 = 1.

At the same time, GIR still stays close to its minimum value.

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??  ? ??  ? ?  ? ?  ? ??  ? ??  ? ??  ? ??  ? ??  ? ??  ? ??   ? ? ?  ??  (a) RMSE  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??  ? ??  ? ?  ? ??  ? ??  ? ??  ? ??  ? ?  ? ? ?  ??  (b) GPIR  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??  ? ?  ? ??  ? ??  ? ??  ? ??  ? ?  ? ??  ? ??  ? ?  ??  (c) GIR  Fig. 6: Variation of the performance of RBFP with ?3  ? ? ? ? ? 	 ? ? ? ? ??  ? ??  ?  ? ??  ? ??  ? ??  ? ??  ? ?   ? ? ?  ??  ???????????? ???????????? ???????????? ???????????? ??????????? ????????????  (a) RMSE  ? ? ? ? ? 	 ? ? ? ? ??  ? ??  ? ??  ? ??  ? ?  ? ??  ? ??  ? ??  ? ??  ? ? ?  ??  ???????????? ???????????? ???????????? ???????????? ??????????? ????????????  (b) GPIR  ? ? ? ? ? 	 ? ? ? ? ??  ? ??  ? ?  ? ??  ? ??  ? ??  ? ??  ? ?  ??  ???????????? ???????????? ???????????? ???????????? ??????????? ????????????  (c) GIR  Fig. 7: Variation of the performance of RBFP with ?2 and time((?3 = 0)  Note, when ?2 = 1, we neglect the information from some highly similar items which have not been rated by the active user. Then we can make a conclusion that the information from similar but unrated items can be very helpful to enhance the performance of recommendation system. Similar experimental results and analyses of user-based RBFP can be obtained and conducted, we fix the optimal value of ?1, ?1 and k3 to be 0.5, 5 and 10, respectively.

We can get the final prediction by linearly combining user-based RBFP with item-based RBFP, so it is essential to investigate the impact of ?3. We let ?3 vary from 0 to 1 with step value of 0.05, Fig.6 shows the variation of RMSE, GIR and GPIR with ?3, respectively. As depicted in Fig.6, we can benefit from the combination. Finally, we set the optimal value of ?3 to 0.5.

? ? ? ?? ? ?? ? ?? ? ?? ? ? ? ?? ? ??  ?????  ? ??  ? ??  ? ??  ? ??  ? ??  ? ??  ? ?  ? ?  ? ??  ? ??   ?? !? ?"  ??????????  Fig. 8: Variation of rating density with time  We continue to investigate the effect of data sparsity on the performance of our methods. Different from the widely- used Given strategy, we change the sparsity level of dataset by setting some time points and abandoning ratings occurred after these time points, then we can obtain different subsets. Fig.8 presents the variation of user-item matrix?s density with these time points. Then we conduct experiments to investigate the  variation of optimal parameters settings of our methods under different sparsity level. Again, we adopt 5-fold cross valida- tion and report the average results. First, we investigate the sensitivity of parameters of item-basd RBFP to data sparsity.

We set ?2 = 0.55, k4 = 30, and let ?2 vary from 0 to 8 with an increment of 0.2. We plot the RMSE(Fig.7(a)), GPIR(Fig.7(b)) and GIR(Fig.7(c)) versus ?2 under different sparsity level. As shown in Fig.7(a) and Fig.7(c), we can observe all curves tend to be very flat if ?2 takes value from 5 to 6. That means the optimal or suboptimal performance can be obtained when we set ?2 from 5 to 6 without considering the sparsity or the time.

Besides, GPIR can achieve its optimal or suboptimal results when ?2 takes value from 3 to 4 under different sparsity level.

It is very crucial to the work of parameters tuning, because we do not need to retune the parameters settings although the time is elapsing and the density of user-item is changing.

Similar experimental results of user-based RBFP have been obtained, which shows that ?1 can also keep constant although data sparsity keeps changing over time.

C. Comparisons We have conducted experiments to compare the result of  our methods with the results achieved by selected CF methods.

First, we conduct comparisons under the lowest sparsity level, which means we did not abandon any single rating. We report the averages over 5 splits. Except that SF?s parameters are suggested in [25], for every method, we adopt cross validation to fix their optimal parameters settings, so that those evaluation metrics achieve their optimal value simultaneously as possible as it can. Then we conduct comparisons with their parameters fixed at the their optimal values. For user-based, we find its optimal performance by varying the size of the neighborhood.

For RSVD, we adopt early stopping strategy and set lrate, ? to which have been used by [6], our initialization is also the same     TABLE I: Comparisons of performance under the lowest sparsity level  Method RMSE GPIR GIR Parameters user-based 0.9644 0.8520 0.8394 k1 = 70  SF 0.9631 0.8391 0.8675 ? = 0.7, ? = 0.7, N = 50 RSVD 0.9284 0.8141 0.8448 K = 15, lrate = 0.001, ? = 0.02 RBFP 0.9453 0.7895 0.8111 k3 = 10, k4 = 30, ?1 = 0.5, ?2 = 0.55, ?3 = 0.5, ?1 = ?2 = 5  MR-RBFP 0.9528 0.7887 0.8253 MR = 0.0000001  ? ? ? ?? ? ?? ? ?? ? ?? ? ? ? ?? ? ?? ?????  ? ??  ? ??  ? ??  ? ?  ? ??  ? ??  ? ??  ? ??  ?  ? ??  ? ??   ? ? ?  ??????????  #!?$%&'!?( ?) ?* +)?  (a) RMSE  ? ? ? ?? ? ?? ? ?? ? ?? ? ? ? ?? ? ?? ?????  ? ??  ? ??  ? ?  ? ??  ? ??  ? ??  ? ??  ? ?  ? ??  ? ??  ? ? ?  ??????????  #!?$%&'!?( ?) ?* +)?  (b) GPIR  ? ? ? ?? ? ?? ? ?? ? ?? ? ? ? ?? ? ?? ?????  ? ?  ? ??  ? ??  ? ??  ? ??  ? ?  ? ??  ? ?  ??????????  #!?$%&'!?( ?) ?* +)?  (c) GIR  Fig. 9: Comparisons of performance under different sparsity level  with [6]. As there are 80,000 ratings in the training set, if we do not hope the number of unknown parameters exceeds the number of training instance, the maximum number of features in RSVD will be 30. We have examined the performance with K to be {5,10,15,20,25,30}, and found the performance would not be improved when K > 15.

One drawback of our methods is that it may cost too much memory space. If we save all similarities and regression coefficients of every user-item pair, we need 9289370 memory unit for MovieLens ml-100k even if we have utilized the sym- metry of similarity. However, if we do not save the similarity and regression coefficient when the corresponding similarity |sim(i, j)|5 or |sim(u, v)|5 is less than a threshold MR and set them to 0, we can save much memory resource. So we have conducted experiment to examine how the performance of our methods is affected under limited memory resource. We term this consideration as Memory Restrict RBFP(MR-RBFP).

Here, we report the performance with MR = 0.0000001.

In Table.I, the last column shows the parameters settings of every algorithm. We can observe that our methods significantly improve GPIR and GIR compared with all other methods while RMSE is worse than RSVD. Because items have chance to be recommended by our methods have more reliable(lower GPIR) prediction, errors of our methods are less visible to users. On the other hand, for truly relevant user-item pairs, our methods can predict their relevance more accurately(lower GIR). We can recommend users more items that they are really interested in. So our methods can provide more wonderful experience for users and increase their confidence in recommendation system.

Another interesting phenomenon is that although MR-RBFP need 2482216 memory units, which is 26.72% needed by RBF- P, its performance do not get much worse, even some of them get better such as GPIR. It indicates that given limited memory resource, maybe we happen to have abandoned some noisy information, which may in turn improve the performance.

Then, we compare our methods with selected algorithms under different sparsity level. We fix the parameters settings of every method as the last column of Table.I without retuning them. In Fig.9, we can observe that as more ratings occurred  with the time, performance of all methods get better. And our methods can outperform all other algorithms in terms of GPIR and GIR under almost all sparsity level, but be outperformed by RSVD in terms of RMSE. So we can conclude that, always, our methods can generate more satisfactory recommendation for users than some popular algorithms.



VI. CONCLUSION In this work, we try to exploit information from some  highly similar items which failed to be rated by the active user and highly similar users who have not rated the active item to improve the quality of prediction. We have conducted extensive experiments to confirm parameters settings of our methods and compare our methods with several popular CFs.

As demonstrated by the experiment evidence, our methods can indeed improve the performance of recommendation system.

Especially, our methods can decrease errors perceived by users significantly and recommend users more items that they are really interested in. So our methods can provide more wonderful experience for users and increase their confidence in recommendation system. Furthermore, parameters settings of our methods need not be retuned although the time is elapsing and the density of user-item is changing.

ACKNOWLEDGEMENTS This work was supported in part by the National Natural  Science Foundation of China under Grant 61175065 and the the Science and Technological Fund of Anhui Province for Outstanding Youth under Grant 1108085J16.

