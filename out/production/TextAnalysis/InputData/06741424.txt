Edge-Preserving Denoising Method Using Variation  Approach and Gradient Distribution

Abstract? This paper proposed an image denoising technique that can enhance the quality of image by using a variational approach and image gradient distribution. First, in order to remove the noise, we consider the variational approach for the energy functional that satisfies an edge-preserving regularization property. Here, we propose a new variational functional that can be implemented by adding a new gradient distribution term in a given energy functional that locally controls the extent of denoising over image regions according to their gradient magnitudes. And by using the fundamental lemma for the calculus of variations, we derive the Euler-Lagrange equation for true image that can achieve the minimum of a devised functional.

Next, we considered the procedure that this equation can be solved by using a gradient decent method, which is one of the dynamic approximation techniques. Through various experiments, we can demonstrate that the proposed method can preserve the edges while removing noise better than existing techniques.

Keywords? Image denoising technique, Edge-preserving regularization, Variational approach, Euler-Lagrang equation, Dynamic approximation method, Image Gradient distribution, Hyper-Laplacian distribution, Nonparametric density estimator.



I.  INTRODUCTION Image enhancement is the preprocessing of image to  improve the interpretability or perception of information in images for human viewers and to provide a better input for other automated image processing techniques. The principal objective of image enhancement is to modify attributes of an image to make it more suitable for a given task and a specific observer. During this process, one or more attributes of an image are modified. The choice of attributes and the way that they are modified are specific to a given task. Moreover, observer-specific factors, such as the human visual system and the observer?s experience, will introduce a great deal of subjectively into the choice of image enhancement methods [1- 2].

Image enhancement is generally used in the following three cases: noise reduction from image, contrast enhancement of the very dark and bright image, and highlight the edges of the objects in a blurring image. Noise reduction is the process of removing noise form a signal or an image. In general, images taken with both digital camera and conventional film cameras will pick up noise from a variety of sources. Therefore, it is  required that the noise is removed for many further uses of these images. Contrast enhancement is acquiring clear image through brightness intensity value redistribution. That is, this is enhancing features as stretching interval between dark and brightness area.  De-blurring process is to restore the sharp images via image de-convolution such as Wiener de- convolution.

Here, we are mainly interested in various noise reduction techniques. Many methods have also been proposed to remove noise from a digital image without spoiling it [3-5]. These can broadly be classified into the following two categories: spatial domain methods and frequency domain methods. In spatial domain techniques, they directly deal with the image pixels.

Different types of techniques used in spatial domain are the total variation, anisotropic diffusion, bilateral filter, mean filter, median filter, and Wiener filter. In frequency domain methods, the image is first transformed into frequency domain using various transformation methods such as Fourier transform or Wavelet transform. The filtering methods very often used in Fourier frequency domain are ideal low pass filter with cutoff frequency, Butterworth low pass filter, and Gaussian low pass filter. On the other hand, the filtering methods very often used in Wavelet frequency domain are VisuShrink, Sureshrink, BayesShrink, NeighShrink and Smooth Shrink.

Recently, several studies have been proposed to remove the noise using image gradient histogram. Krishnan and Fergus [6] describe a de-convolution approach that is several orders of magnitude faster than existing techniques that use hyper- Laplacian priors. Cho et al. [7] present an alternative de- convolution method called iterative distribution reweighting which imposes a global constraint on gradients so that a reconstructed image should have a gradient distribution similar to a refrence distribution. Zuo et al. [8] proposed a texture enhanced image denoising method by enforcing the gradient distribution of the denoised image to be close to the estimated gradient distribution of the original image.

In this paper, we propose a new variational functional that can be implemented by adding a new gradient distribution term in a given energy functional that locally controls the extent of denoising over image regions according to their gradient magnitudes. And by using the fundamental lemma for the calculus of variations, we derive the Euler-Lagrange equation for true image that can achieve the minimum of a devised     functional. Next, we considered the procedure that this equation can be solved by using a gradient decent method, which is one of the dynamic approximation techniques.

Through various experiments, we can demonstrate that the proposed method can preserve the edges while removing noise better than existing techniques.



II. VARIATIONAL APPROACH FOR DENOISING PROBLEM  A. Denoising Prolem First, we consider the general problem of recovering  unknown clean image    from noisy observed image   . In many computed imaging applications, unknown image is related to observed image through a linear model of the form  (1) where   is to be the additive white Gaussian noise with zero mean and standard deviation  , and   is a linear operator defined on        depending on image. For simplicity, we assume that     .

B. Variational Approach  .Here, we want to recover the regularized true image   from noisy observed image   . One popular approach to image denoising is the variational approach, in which the denoise problem is represented by an energy functional [9-12].  In this case, the denoising problem can be achieved by minimizing a criterion of the functional form representing the edge- preserving regularization:  ? ,           (2)  where   is an open bounded set in   ,          is the modulus of the gradient of      , and    is a regularization parameter which balances the influence between two terms of formula (2).

Here, the choice of the function ? as an edge-preserving regularization function is assumed to be an even function of class ??    . Common examples of regularizations function ? with some of their properties are given in the following table 1.

TABLE I.   SOME REGULARIZATION FUNCTIONS  Name of Function  Function      Convexity  Derivative   Tikhonov t    Yes 1  Total variation t Yes 1 2t Perona & Malik  1  exp   t   No exp   t German & McClure  t 1  t  No  1  t Hebert & Leahy lo   1  t  No 2 1  t  Green lo  cosh ??   Yes  ta h  ?? 2??   The first function is quadratic and corresponds to the Tikhonov standard regulation which is obviously not edge- preserving. The second function leads to the minimization of the total variation of    x  which is common regularizing  criterion. The third function called anisotropic diffusion or Perona-Malik diffusion is used most frequently in the noise removal. The second to fifth functions define the representative edge-preserving regularization functions.

In this case, we should try to find an image      that minimizes the given criterion of functional          . This will be given as a solution of Euler-Lagrange equation with respect to the unknown image f   . Therefore, using the calculus of variation, the image f     minimizing the regularized energy functional          can be derived by the following Euler- Lagrange equation:  {     (         )  iv {? ? ? f   ? ? f   ?      }  0,  ?  ?(f   ) ?n??  0,               ? ? .

(3)  where  ?  represents a vector normal to the boundary ?  of  .

and " iv" stands for the divergence operator.

Furthermore, the numerical solution of the Euler-Lagrange equation (3) can be obtained by using a gradient-decent method, or equivalently, by using a dynamic scheme wherein t is an artificial time parameter;  {       ?f  , ?  (       t,   )  iv {? ? ? f  ,  ? ? f  ,  ?     t,   } ,  t,   ?  0,? ? ? ?n??   t,    ?  0 .

(4)  The variational approach for edge preserving regularization considered so far has the following two problems. First, this algorithm smooth well for small variation occurred due to noise, but does not restore well edges with low contrast that will generate a low gradient modulus. Second, the first term of variational model plays a role to ensure a little of difference between noise image and restored image. Therefore, in order to denoising a heavy noisy image, the second term should be a lot of smooth. But, a smoothing performs well, the PSNR value of the restored image is a tendency to worse. Consequently,  in order to obtain a good restored image from the noise image, it is required  an additional term, which can be restored edges with local low-contrast, and also  it  requires the method that can select properly the degree of noise smoothing constant depending on the nature of the image. In order to improve these problems, we propose in the next section the addition of new term with the density function of gradient magnitude.



III. PROPOSED METHOD  A. Estimation of Gradient Density Function The most critical factor of image denoising problem with  edge preserving is the gradient of the image. Because the strength of the edge in the image can be generally represented by the size of the gradient computed at each pixels of an image.

For example, the image gradient histograms for original Lena image and for Lena image with the additive white Gaussian noise are respectively given as the following Figure1.

Identify applicable sponsor/s here. If no sponsors, delete this text box.

(sponsors)      Figure 1.  Example of a gradient histogram for Lena image  We first consider the problem of estimating non- parametrically a probability density function for gradient distribution of noisy image. Let             be a gradient magnitude computed at position   ,  1, ,  , and   is the number of pixels in the image. The most familiar density estimator is based on the histogram:  h    ?      ?        , where  ?  is the center of the bin in which observation    lies, is the bin width, and  { 1   ? (  ,   )  0            othe  ise .

Given a histogram, the estimator for the probability density function is defined by  ?           .                                         (5)  But, there are some drawbacks to the histogram density estimator: they are discontinuous property, dependence on bin size and bin origin, and disregard of information from location of datum within a bin.

Hence, we will consider other estimation method of the density function that can improve these problems. This is a kernel density estimator. Take the histogram, but replace bin function with something else:  ?      ?  ,               (6)  where        is the kernel function, normalized to unity: ?             1.

Usually we interested in kernels of the form       ,  where   is called the bandwidth. Indeed this may be used the definition of kernel. The kernel estimator for the probability density function is then:  ?       ?     .                 (7)  Here, the choice of kernel   is not crucial but the choice of bandwidth   is important. Basically, the optimal smoothing bandwidth is given as   ,  where    ?        ,    ?          and ?           .

Second, we consider the problem of estimating a probability density function for gradient distribution of original image. Unfortunately, one often does not know a prior what the gradient distribution should be. As previous works appeared to model the distribution of gradient magnitude, we will also parameterize a gradient magnitude distribution using a generalized Gaussian distribution. This is given by      exp       ,                         (8)  where the shape parameters  ,   determine the shape of distribution. In the most image restoration algorithms, gradients are assumed to be independent for computational efficiency. Hence, given gradient samples   , ,   , we can estimate the shape parameters  ,   of an original gradient distribution by maximizing the log-likelihood function:  [ ?,  ?]      ax ,  ? l                             (9) But, since we could not compute the estimator  ? ,  ? analytically, we may use a numerical method to calculate the estimate. We use the Nelder-Mead optimization method. By the way, for various natural images,   and   will generally have a relatively narrow range. Hence, we preset a range of the two parameters, and then search for the pair   ?,  ?  which satisfies the equation (9). Specifically, we let  ? ?  0.0 ,   and   ? ?  0.02,2 .

Consequently, we have the estimated original gradient distribution given as follows:  ?     ?  ?   ? exp(  ?  ?)  Finally, as we can see from the example of gradient histogram for the Lena image, gradient values for noise are located in the middle area of the graph. Therefore, our main idea is to make the gradient distribution of denoised image as close as possible to the gradient distribution of original image.

To do this, we can penalize the Euclidean distance between ?   and      by adding a new term to the energy functional in Eq. (2).

B. New Noise Functional Model Therefore, our new model is characterized by adding new  regularization term into a given criterion functional (2). This is given as  ?                     ?   ?    ?                      .           (10) Then, the functional        is minimized with respect to     . If we take a derivative of        with respect to     , we obtain the following Euler-Lagrange equation     {        iv {?  ? ? f   ? ? f   ?      }  ??  iv{2( ? ?      ?   ? ?      ? ) ??  ? ? f   ? ? f   ?  ?? ? f   ? ? f   ?         0,    ?  ? f ?n??  0,               ? ? .

(11)  where  ?  represents a vector normal to the boundary ?  of  , and   ?     and  ?     stand for  respectively the derivatives of gradient density functions of restored image and true image as given by:  ?       ?       ,  ?       ? ?  ?     ?  ? ?  exp(  ?  ?)  .

Furthermore, the numerical solution of the Euler-Lagrange equation (11) can be obtained by using a gradient-decent method, or equivalently, by using a dynamic scheme wherein t is an artificial time parameter;  {         (  t,        )  iv {? ? ? f  ,  ? ? f  ,  ?    t,   }  ??  iv{2( ? ?    t,   ?    ?    t,   ? ) ??  ? ? f  ,  ? ? f  ,  ?  ? ? f  ,  ? ? f  ,  ?     t,     0,    ?  ?(f  ,  ) ?n??  0,                                                            ? ? .

0,  (12)  Finally, to discretize the equation in   t,   , we use a finite difference implicit scheme. We recall first the usual notations: let h  be the space step, ?t  be the time step, and (xi, yj) ih, jh  be the grid points, for  1 ? i, j ? M . Let   ,???? ?????,   ,????  be an approximation of    t, x, y , with   ? 0 , 0   0. The finite differences are  ? x  i,j   i,j   i  ,j, ?+x  i,j   i+ ,j   i,j, ? y  i,j   i,j   i,j  , ?+  y  i,j   i,j+   i,j.

The algorithm is given as follows: knowing  i,jn , we compute i,jn+  by the following discretization and linearization of equation (12) in   x, y ;  i,jn+   i,jn  ?t ? ?, ?    i,jn   i,j  {?? x  h (? ?(?  x fi,jn  )   h (?  y fi,jn  )   h ? x fi,jn  ?(? x fi,jn  )   h ? +(fi,j  n  fi,j? n )   h  ? )  ?? y  h (? ?(?  x fi,jn  )   h (?  yfi,jn  )   h ?  yfi,jn  ?(f i  ,jn  fi? ,jn )   h  ? +(? yfi,jn )   h  ?  )}    {  ??x  h  (    (   ?(?(?  x  i,j  )  h2 (?  y  i,j  )  h2 )  (?(?  x  i,j  )  h2 (?  y  i,j  )  h2 )  )     (   ? (?(?  x fi,jn  )   h (?  yfi,jn  )   h ) (?(?  x fi,jn  )   h (?  yfi,jn  )   h )  )       ( ? x fi,jn  ?(? x fi,jn  )   h ? +(fi,j  n  fi,j? n )   h  ? ))  ?? y  h  (    (   ?(?(?  x  i,j  )  h2 (?  y  i,j  )  h2 )   (?(?  x  i,j  )  h2 (?  y  i,j  )  h2 )  )       (   ? (?(?  x fi,jn  )   h (?  yfi,jn  )   h ) (?(?  x fi,jn  )   h (?  yfi,jn  )   h )  )       ( ? yfi,jn  ?(f i  ,jn  fi? ,jn )   h  ? +(? yfi,jn )   h  ?  ))}                        (13)  This linear system is solved by an iterative method. Finally, the principle steps of our algorithm are given as follows:   Our Algorithm: Iterative Noise Reduction  1. Initialize   0,  n 2. Compute the density function of  gradient and its derivative for original image  ?     ?  ?   ? exp(  ?  ?) ,  ?       ? ?  ?     ?  ? ?  exp(  ?  ?) .

3. Iterate on   0, 1, , 4. Update the density function of  gradient and its derivative for noise image  ?       ?       ?       ?         5. Solve the PDE in  n  from (13) to obtain  n+  7. Check whether the solution is stationary. If not,     1  and repeat.



IV. EXPERIMENTAL RESULTS In this section, we provide experimental results in order to  demonstrate the effectiveness of the proposed method in comparison to a few existing methods quantitatively. First, we have comparatively investigated the efficiency of the various noise reduction methods for an images corrupted with the Gaussian white noise. Second, we have conducted the experiment that is able to compare the performance between the proposed technique and existing techniques for noise reduction of grayscale images.

A. Comparison of Various Denoise Method The performance of the various noise reduction methods were  tested on standard image Barbara and Elaine. Here, to compare their performances, we use an image corrupted with the Gaussian white noise of different standard deviation   such as  ,??      ,??    0,   , where the standard deviation  ?s are taken with 5, 10, 15, 20, 25 for simulation purpose. And we have compared with different methods Tikhonov (TH), Total variation (TV), Perona & Malik (PM), German & McClure (GM), and Hebert & Leahy (HL). For all these methods, the performance is measure qualitatively and quantitatively by using the widely used metric Peak signal to noise ratio (PSNR) for measuring noise reduction. This measure is defined as follows:  20 lo         ,  where MSE is the mean square error between the original image ,??  and the noise reduced mean  ?  ,??  with size M?  .  The PSNR values for different methods and different standard deviations for Barbara and Elaine image are represented graphically in the figure 2 and figure 3.

Figure 2 PSNR values for different methods and noise levels for Barbara.

Figure 3 PSNR values for different methods and noise levels for Elaine  Here, we note that the total variation method is considered as the best way to remove noise than the other methods.

B. Performance of Proposed Method In order to show that the proposed method has better  performance than the existing methods, we have conducted the experiments for three images. These are Barbara, Camera man, and Lena images. And TV (Total Variation) is the best denoising method of conventional methods was used as the second term in variational energy functional model. The experimental results for these are given in the following figure 4.

(a) Barbara Image     (b) Camera man          (c) Lena  Figure 4 Experimental results for three images From the experimental results, we note that the proposed method can provides better noise reduction than the existing methods.



V. CONCLUSION In this paper, we propose a new image enhancement method that  uses variational approach and edge-preserving regularization. First, we consider the characters of a various regularization functions in the energy functional that satisfies an edge-preserving noise reduction.

Second, we propose a new variational functional that can be implemented by adding a new gradient distribution term in a given energy functional that locally controls the extent of denoising over image regions according to their gradient magnitudes.

From the experimental results, we note that the proposed method can provides better noise reduction than the existing methods. And we note that the total variation method is considered as the best way to remove noise than the other conventional methods.

