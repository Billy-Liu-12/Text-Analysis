Mining and Representing Rare Association Rules through the Use of Genetic

Abstract?Whereas the extraction of frequent patterns has focused the major researches in association rule mining, the requirements of reliable rules that do not frequently appear is taking an increasing interest in a great number of areas. This field has not been explored in depth and most algorithms for mining infrequent association rules follow an exhaustive search methodology, which hampers the extracting process because of the size of the datasets.

The importance of discovering patterns that do not fre- quently appear in a dataset and the promising results obtained when using evolutionary proposals in the field of frequent pat- tern mining motivates the evolutionary proposal for discovering rare association rules presented in this paper. Here, a context- free grammar is described and applied to adapt individuals to each particular problem or domain. The use of both an evolutionary approach and a context-free grammar reduces the memory requirements and provides the possibility of extracting any kind of rules, respectively. The experimental study shows that this proposal obtains a set of reliable infrequent rules in a short period of time.

Keywords-Rare Association Rule; Infrequent Rule Mining; Grammar-based Evolutionary Algorithms

I. INTRODUCTION  The mining of association rules is a technique whose  purpose is the extraction of close relations between patterns  from datasets. The discovery of such relationships, which  can be represented as a relation ?IF antecedent THEN  consequent?, within a vast amount of data could greatly  help in the decision-making process. Both the antecedent  and the consequent are sets of conditions that do not have  any attribute in common. The meaning of an association rule  is that if its antecedent is satisfied, then it is highly probable  that its consequent would be also satisfied.

The first algorithm proposed for the extraction of this kind  of relations was presented by Agrawal et al. [1]. This well-  known algorithm, called Apriori, works into two phases.

While in a first step is used for discovering patterns that  frequently appear in a dataset, in the second phase it obtains  the relationships between those patterns previously mined.

The main objective is to discover reliable relations that  frequently appear in a dataset.

Most algorithms in this field are based on this Apriori  proposal, where the computation time, the memory require-  ments and the extraction of categorical relations are its main  limitations. These limitations have been studied in depth by  the research community. Han et al. [2] proposed the FP-  Growth algorithm, whose aim is the discovery of association  rules in a more efficient way. To this end, a tree structure  for storing information about frequent patterns was the main  innovation. In such a way, FP-Growth works on this structure  instead of the dataset. Recently, different researchers have  focused their studies in evolutionary proposals, so a large  number of evolutionary algorithms (EA) for mining frequent  association rules have been proposed [3] [4] [5].

Despite the mining of frequent association rules is the  main motivation of most researchers, there are situations  where it is interesting to discover abnormal or unusual  behaviour in datasets, extracting rare or infrequent patterns,  i.e. those that do not follow the trend of the majority.

Communication failure detection is an important field where  this kind of associations becomes interesting. In [6], an  infrequent pattern mining proposal was presented for real  time detection of intrusive or anomalous packets in wireless  networks. Medicine is another field where rare or infrequent  association rules play an important role in the recognition of  patients who suffer a particular disease that does not often  occur.

The first approaches for mining infrequent association  rules consisted in extracting very low frequency of occur-  rence patterns by means of a low threshold, which was used  in Apriori to discard infrequent patterns. However, due to  the number of candidate patterns, the use of a low threshold  drastically increases its execution runtime. Other proposals  consisted in adjusting the previously existing frequent pat-  tern mining algorithms as Apriori-Infrequent [7].

Different proposals have been presented for mining in-  frequent association rules. One of them, called Apriori-  Inverse, was proposed by Koh and Rountree [8]. Similarly  to Apriori, this algorithm works into two phases. The first  one consists in the discovery of those patterns that appear in  the dataset more frequently than a minimum threshold but  less than a maximum. The second step is to discover reliable  association rules over the patterns previously mined. Another  algorithm, called ARIMA, was presented by Szathmary et     G = (?N , ?T , P , S) with: S = Rule ?N = {Rule, Antecedent, Consequent, Comparison, Categorical Comparator,  Categorical Attribute Comparison, Numerical Comparator, Numerical Attribute Comparison} ?T = {?AND?, ?! =?, ?=?, ?<=?, ?<?, ?>=?, ?>?, ?name?, ?value?} P = {Rule = Antecedent, Consequent ;  Antecedent = Comparison | ?AND?, Comparison, Antecedent ; Consequent = Comparison | ?AND?, Comparison, Consequent ; Comparison = Categorical Comparator, Categorical Attribute Comparison |  Numerical Comparator, Numerical Attribute Comparison ; Categorical Comparator = ?! =? | ?=? ; Numerical Comparator = ?<=? | ?<? | ?>=? | ?>? ; Categorical Attribute Comparison = ?name?, ?value? ; Numerical Attribute Comparison = ?name?, ?value? ;}  Figure 1. Context-free grammar for both categorical and numerical association rules expressed in Extended BNF notation  al. in [9]. This algorithm starts by discovering the minimal  rare patterns, i.e. those infrequent patterns that comprise  frequent subsets. Then, based on these minimal rare patterns,  ARIMA extracts all the possible supersets that appear at  least once in the dataset. Finally, similarly to every Apriori-  based approach, this algorithm searches for reliable relations  between those patterns previously discovered.

Consequently, a major shortcoming of these proposals for  mining rare association rules is their high computational  time requirements. Since they are exhaustive search algo-  rithms, the growth of the dataset size causes an exponential  increase of the computational time and the memory require-  ments. Additionally, these algorithms mine very infrequent  association rules since no minimum frequency threshold is  applied over the whole rule. Finally, it should be noted that  existing proposals obtain rare association rules in categorical  domains, so numerical attributes have to be discretized in a  previous step. These shortcomings have not been studied  in depth in this field. Therefore, considering the promising  results obtained in [5], this paper presents a grammar-  based evolutionary proposal for the extraction of infrequent  association rules. The strength of using grammars in the  association rule mining field is the possibility of adapting  the grammar to each specific problem, which allows of  obtaining association rules in both numerical and categorical  domains. Furthermore, the use of an evolutionary schema  overcomes the computational time and memory requirement  shortcomings. To analyse its effectiveness, we compare this  approach to other exhaustive search algorithms in the rare  association rule mining field, showing that it obtains rare  and reliable relations between patterns in a pretty efficient  way.

This paper is arranged as follows: Section 2 describes the  model for mining rare association rules; Section 3 presents  the datasets used in the experiments, the experimental set-up  and the results obtained; finally, some concluding remarks  are outlined in Section 4.



II. MINING RARE ASSOCIATION RULES  The drawbacks of the existing proposals in mining as-  sociation rules were overcomed by using a grammar-based  evolutionary proposal [5]. Regardless of the dataset size and  the domain of its attributes, the use of both grammars and  an evolutionary model provided reliable rules that comprised  patterns in any domain and in an efficient way. As mentioned  above, the strength of using a grammar in any field and,  particularly in association rule mining, comes from its ability  to be adapted to each specific problem.

In this proposal, each association rule is represented  by means of a tree-structure with the help of a context-  free grammar (CFG). The use of tree-structures allows of  representing rules with different sizes and shapes. Further-  more, the use of CFG determines the syntax constraints and  the domains under application. The proposal defines each  individual by a genotype, designated by the tree-structure,  and a phenotype, representing the rare association rule.

A CFG is defined as a four-tuple (?N , ?T , P , S), where ?T and ?N represent the alphabets of terminal and non- terminal symbols, respectively, having these alphabets no  items in common, i.e. ?N ? ?T = ?. P is defined as the set of production rules, comprising a number of  production rules of the form ? ? ? where ? ? ?N , and ? ? { ?T ? ?N }?.

Each individual represents a sentence generated by the  grammar and defined by means of a tree-structure where  the root is the symbol S. A derivation process is carried  out starting from the start symbol of the grammar to obtain  indviduals. A number of steps is performed by using the set  P of production rules. To avoid trees which are too deep, the  number of production rules used in the derivation process  must be previously predefined by the data mining expert.

Figure 1 shows a sample grammar used for mining asso-  ciation rules over both numerical and categorical datasets.

Each association rule may comprise a number of condi-  tions concatenated by the operator ?AND?. The number  of conditions that may appear in each association rule is  not prefixed but it depends on the number of derivations  performed. The minimum number of conditions is the only  2011 Third World Congress on Nature and Biologically Inspired Computing 87    restriction imposed by the grammar, i.e. both the antecedent  and the consequent should be composed of at least one  condition. Finally, it is noteworthy to mention that two  logic operators are available for each categorical condition,  whereas four logic operators are provided for numerical  conditions. However, since grammars can be adapted to each  specific problem, the one in Figure 1 could be also adapted  for mining rules with only one condition in the consequent  or even for mining conditions with only the equal logic  operator.

A. Evaluate Individuals  The process of evaluating each individual is a major issue  because of the large number of them that it is possible  to extract in a specific problem. Different researchers have  described some objective measures for evaluating associ-  ation rules [10]. Two of the most important and widely  used measures in this field are support and confidence.

The former is defined as the proportion of the number of  transactions including the antecedent and consequent in a  dataset. The latter is defined as the proportion of the number  of transactions that include the antecedent and consequent  among all the transactions that comprise the antecedent.

In this proposal, whereas the support measure is used to  discover rules that do not frequently appear in a dataset, the  confidence is used to obtain reliable association rules.

In opposition to Apriori-based algorithms, the EA de-  scribed in this paper does not require two phases to mine  rules. In this algorithm, each rule is evaluated according  to a fitness function, which is defined in Equation 1, and  whose goal is to search for infrequent rules, i.e. those that  do not exceed a maximum support threshold. The fitness  values available are shown in Figure 2. Despite rules with  a support value belonging to the interval obtain the same  fitness value, a new way to properly differentiate between  them is required. In such a way, the best individuals, i.e.

those with the maximum fitness function values, are ranked  according to the confidence measure. Thus, among those  rules with the maximum fitness function values, the most  reliable ones will be considered the best.

Fitness =  { 1 if 0 < support ? Max 0 otherwise  (1)  A major difference between the proposed algorithm and  any Apriori-based one is that, whereas the former searches  for rules that do not exceed a maximum support threshold,  the latter searches for patterns that do no exceed this  threshold. This search leads to the mining of very infrequent  rules since the support of a group of patterns is always  greater or equal to the support of each of these patterns.

For example, having two infrequent patterns A and C, their  support values are always greater or equal to the support  value calculated for the rule A ? C.

Figure 2. Fitness function  B. Genetic Operators  To obtain new individuals in every generation of the  evolutionary process, the proposal described in this paper  uses two genetic operators: crossover and mutation.

Crossover. This genetic operators swaps the highest sup-  port condition in one parent for the lowest support condition  in other parent. Therefore, this genetic operator enables us  to obtain an individual whose conditions have a frequency  of occurrence lower than at least one of the parents.

Mutation. The main goal of this genetic operator is the  discovery of rules with a lower support than the original one.

In such a way, the highest support condition in an individual  is mutated to obtain a new one with a lower support. This  genetic operator provides two possibilities: (1) to obtain a new complete condition, replacing the highest one; or (2) to replace the value of a terminal symbol within the highest  support condition.

C. Algorithm  The EA proposed follows a generational schema, as  depicted in Figure 3. Here, a pool of individuals with  a predefined size is used. The purpose of this pool is  to maintain the best rules discovered in the evolutionary  process. In each generation, this pool is updated with those  individuals that exceed a minimum quality threshold, i.e.

the fitness function value must be greater than zero and the  confidence must be greater than the minimum confidence  threshold.

In each generation, once new individuals are obtained with  the above described genetic operators, individuals from the  population and the last pool are united in a new auxiliary  population and then, they are ranked according to the confi-  dence measure. As mentioned above, only those individuals  with a fitness function distinct from zero are kept in mind.

The main objective is to fullfill the pool, i.e. to select the  n more reliable individuals, n being the maximum pool  size as previously set by the data miner. The algorithm  proposed avoids to keep in the pool those individuals that  88 2011 Third World Congress on Nature and Biologically Inspired Computing    Start  Generate individuals  Evaluate individuals  Individuals are selected as parents and then crossed and  mutated with a probability  The new individuals, the population and the pool are combined into a new single  population Individuals are ranked using confidence  The updating process includes the best individual in Pool  Pool is initialized  # individuals reached?

Yes  No  Algorithm finished ?

End  Return the pool  Yes  Evaluate individuals  No  Context-free grammar  Figure 3. The flowchart for the proposed algorithm  represent the same rule. Notice that the same rule could  be represented by different genotypes, e.g. the rules (A  AND B)? C and (B AND A)? C. Both rules provide different genotypes even when they represent the same rule.

Therefore, a specific procedure is carried out to guarantee  that the pool of individuals contains distinct infrequent rules,  i.e. those that are the most reliable ones. Starting from a new  rule to be added to the pool, this procedure analyses each  condition within the rule, checking if there is a rule in the  pool that comprises the same conditions.

Finally, once the number of generations is reached, the  algorithm finishes and the pool of individuals is returned, the  best rules discovered in the evolutionary process are given  to the data miner.



III. EXPERIMENTAL STUDY  In this section, a complete analysis of the effectiveness  of this proposal compared to other existing proposals for  mining rare association rules is carried out. All the exper-  iments in these studies were performed on an Intel Core  i7 machine with 12GB main memory and running CentOS  5.4. In addition, all the proposals for mining rare association  rules were written in Java. JCLEC1 [11], a Java library  for the evolutionary computation, was used in the proposal  presented in this paper.

A. Experimental set-up  In the experimentation stage and in order to analyse  the performance of our proposal, a set of executions were  performed using different datasets, which were chosen with  1JCLEC is available for download from http://jclec.sourceforge.net  different sizes and number of attributes: automobile perfor-  mance dataset (Autom) with 392 instances and 8 numeri-  cal attributes, vote dataset (V ote) with 435 instances and  17 categorical attributes, Wisconsin breast cancer dataset  (WDBC) with 683 instances and 11 numerical and cate-  gorical attributes, and finally, zoo dataset (Zoo) with 102  instances and 17 categorical attributes. It is noteworthy that  since exhaustive search algorithms in this field require an  enormous computational time, they are hardly maintain-  able when using huge datasets comprising large amount  of attributes, so not very large datasets are used in this  experimental stage.

Since evolutionary proposals have a set of parameters,  such as population size, pool size, number of generations,  crossover probability, mutation probability, maximum sup-  port threshold and minimum confidence threshold, we have  carried out a number of experiments in order to obtain the  optimal parameters, i.e., those that allow us to obtain the  best results. The parameter configuration was adopted after  performing several tests using different rank values for each  parameter. Notice that these parameters are not particular-  ized for every dataset. The best results for our approach are  obtained with a population size of 50 individuals obtained  using a CFG with a maximum derivation size of 24. The  evolutionary process is carried out along 50 generations. In  this process, new individuals are obtained with a probability  of 0.70 for the crossover operator and 0.14 for the mutator.

The best individuals, i.e. those that exceed certain quality  thresholds are kept in a pool of size 20. These thresholds are  0.90 and 0.40 for the confidence and the maximum support,  respectively.

On the other hand, exhaustive search algorithms for  mining rare association rules only require two parameters:  the support and confidence thresholds. In order to carry out  a fair comparison, the algorithms used in the experimental  stage are executed with the same confidence threshold, i.e.

0.90 for the confidence and a support threshold of 0.40.

B. Comparing different algorithms  In this section, a comparison between existing exhaustive  search algorithms and the proposal based on the CFG is  carried out. A major advantage of the proposal presented  in this paper is the ability of discovering rare association  rules without requiring any preprocessing step. With a  simple grammar transformation, it is possible to extract rules  over any domain and using different logic operators. Since  the new proposal can be executed over original datasets,  Figure 4 shows a set of rare association rules mined using  the original Wisconsin breast cancer dataset. As is shown,  very reliable rare association rules are discovered.

For a fair comparison, and since existing proposals for  mining rare association rules use an exhaustive search  methodology over categorical datasets only, those that com-  prise numerical attributes were previously preprocessed with  2011 Third World Congress on Nature and Biologically Inspired Computing 89    Rare association rules over numerical attributes Support Confidence  IF Mitoses > 2 THEN Id <= 8097263 0.124 1.000 IF Unif Cell Size > 2 AND C Thickness > 4 THEN Sing Epith Cell Size >= 2 0.317 1.000 IF Unif Cell Size > 4 AND Mitoses > 2 THEN Class! = Benign 0.102 1.000 IF Class = Malignant AND Normal Nucleoli >= 2 THEN Id < 5418720 0.289 1.000 IF Normal Nucleoli >= 2 AND Unif Cell Size >= 4 THEN Unif CellShape >= 2 0.263 1.000 IF Unif Cell Size > 4 AND Clump Thickness > 4 THEN Unif Cell Shape >= 2 0.224 1.000  Figure 4. Examples of rare association rules over a numerical dataset  equal-width discretization techniques. Tables I, II, III and IV  show the average support, the average confidence, the  number of rules mined and the average runtime for each  algorithm, respectively, where D?N states that the dataset D was discretized into N intervals.

Table I AVERAGE SUPPORT VALUES OBTAINED WITH DIFFERENT DATASETS  Average support Dataset Apriori-Inv ARIMA Apriori-Inf Proposal  Autom? 5 0.013 0.013 0.015 0.236 Autom? 10 0.007 0.007 0.008 0.201 Autom? 15 0.006 0.006 0.007 0.178 V ote 0.032 0.043 0.036 0.252 WDBC ? 5 0.004 0.004 0.004 0.233 WDBC ? 10 0.004 0.004 0.004 0.249 WDBC ? 15 0.004 0.004 0.004 0.257 Zoo 0.051 0.056 0.062 0.209  Focusing on Table I, the results show that exhaustive  search proposals for mining rare association rules obtain  rules with a very low support since the threshold is used for  discard patterns instead of rules. On the other hand, the set of  rules mined with the proposal presented provides infrequent  rules whose support values tend to the middle of the range  (0.0, 0.4], which is the interval used to determine if a rule is rare. Analyzing the exhaustive search algorithms, notice that  Apriori-Infrequent obtains an average support greater than  Apriori-Inverse. The latter obtains rules from the infrequent  itemsets mined in the classical Apriori algorithm, so these  rules comprise at least one condition with a support value  greater than the threshold. Studying the performance of the  ARIMA algorithm, it should be noticed that its results are  very similar to those obtained by Apriori-Inverse, since their  difference is only in the minimal itemsets.

Table II AVERAGE CONFIDENCE VALUES OBTAINED WITH DIFFERENT DATASETS  Average confidence Dataset Apriori-Inv ARIMA Apriori-Inf Proposal Autom? 5 0.997 0.996 0.997 0.998 Autom? 10 0.999 0.999 0.999 0.996 Autom? 15 0.999 0.999 0.999 0.997 V ote 0.988 0.978 0.988 0.985 WDBC ? 5 0.999 0.999 0.999 0.996 WDBC ? 10 0.999 0.999 0.999 0.991 WDBC ? 15 0.999 0.999 0.999 0.980 Zoo 0.998 0.996 0.996 1.000  Studying the confidence measure, it should be noted  that all the proposals used in the analysis obtain reliable  rules, with an average confidence above 0.978, as shown  in Table II. Therefore, it is possible to assert that all the  algorithms perform equally well for this measure.

Table III AVERAGE NUMBER OF RULES OBTAINED WITH DIFFERENT DATASETS  Average number of rules Dataset Apriori-Inv ARIMA Apriori-Inf Proposal  Autom? 5 2925.0 8519.0 1206.0 20.0 Autom? 10 7836.0 15505.0 3300.0 19.2 Autom? 15 6021.0 12248.0 2837.0 20.0 V ote 32.0 63253.0 24.0 18.8 WDBC ? 5 20378.0 61436.0 6199.0 19.3 WDBC ? 10 16851.0 47855.0 6365.0 18.9 WDBC ? 15 21489.0 49881.0 8410.0 17.3 Zoo 815.0 159598.0 368.0 20.0  According to Table III, where the average number of rare  association rules mined is outlined, it is noteworthy that  the grammar-based proposal allows of obtaining an uniform  set of rules (between 17 and 20 rules). On the contrary,  exhaustive search algorithms obtain an heterogeneous set of  rules depending on the datasets used. Notice that huge sets of  rules become hardly manageable, e.g. using the Zoo dataset,  the number of rules mined is 159598, which is hardly  understandable for the data miner. It represents an important  advantage of the proposed algorithm, since it provides the  user with an adequate set of rules easily understandable.

Table IV AVERAGE EXECUTION TIME REQUIRED FOR DIFFERENT DATASETS  Time (sec)  Dataset Apriori-Inv ARIMA Apriori-Inf Proposal Autom? 5 60.350 293.208 1.240 0.773 Autom? 10 350.179 2505.419 6.894 0.737 Autom? 15 207.264 2270.975 8.559 0.859 V ote 0.293 11113.984 0.166 0.883 WDBC ? 5 1821.290 2966.342 14.611 1.290 WDBC ? 10 865.962 8398.223 20.829 1.318 WDBC ? 15 1257.343 7127.010 28.627 1.488 Zoo 0.629 8669.034 0.304 0.494  Finally, focusing on the runtime for each algorithm (see  Table IV), notice that the new proposal has an average  execution time much lower than those obtained by other  algorithms. In exhaustive search algorithms, the execution  90 2011 Third World Congress on Nature and Biologically Inspired Computing    time is not uniform, but depends directly on the dataset  used. For instance, using ARIMA, the execution time may  vary from 293 to 11113 seconds. On the contrary, the use  of an evolutionary strategy allows of mining rules in a  uniform period of time, at most one second, regardless of the  dataset used. As it is depicted in Table IV, the shortcoming  of exhaustive search algorithms is overcomed by the new  proposal, obtaining rare association rules in a significantly  better execution time for most datasets.



IV. CONCLUSION  The mining of rare association rules has not been studied  in depth and existing algorithms in this field mainly use  exhaustive search methods. This methodology is the main  drawback of these algorithms, which are hardly maintain-  able, specially when using huge datasets comprising a large  number of attributes. Additionally, these algorithms obtain  rare association rules only over categorical domains, so  numerical values must be discretized first.

In this paper, a grammar-based evolutionary proposal  for mining reliable rare association rules was presented.

In this proposal, each individual is represented as a tree-  structure based on a CFG, which provides expressiveness  and flexibility, and allows both categorical and numerical  attributes to be defined. Since most existing proposal for  mining association rules, and particularly rare association  rules, are based on exhaustive search methodologies, the use  of grammars provides a number of advantages. Grammars  allow to constraint the search space, reducing the search  cost necessary to find solutions. Furthermore, the use of an  evolutionary solution allows of decreasing the computational  time. Finally, it should be noted that the proposal presented  in this paper does not divide the mining process into two  steps, i.e. the first one for mining patterns and the second  one for mining rules among the patters mined previously, as  the exhaustive search models do.

Focusing on how many rules are mined, regardless of the  dataset used, the number of rules returned is close to the  size specified by the data miner. These results show that the  proposal discovers a small set of rules unlike the existing  algorithms, which obtain some huge sets of rare association  rules, resulting in a collection that is hardly understandable.

Finally, the execution time tends to be constant, in oposition  to exhaustive search algorithms, where a vast amount of time  is required.

