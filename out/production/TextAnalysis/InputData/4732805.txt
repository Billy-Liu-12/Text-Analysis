A Knowledge Acquisition Method for Missing Data

Abstract   Survey data provide rich source of knowledge.

However, a survey database normally contains missing  data.  This paper proposes a rough set based  unconventional knowledge discovery method to explore  missing data.  It presents an experiment on a student  teaching evaluation database.

1. Introduction   Survey data provide rich source of knowledge.

However, a real-world survey database rarely contains  complete entries of each survey question for all of the  attributes.  Normally, questionnaires are often partially  completed by the participants.  The possible reasons for  missing data could be numerous, including negligence,  deliberate avoidance for privacy, ambiguity in mind, and  aversion.

The incompleteness of data is often viewed as a  negative aspect of real-world databases.  One of the  convenient solutions to dealing with incomplete data is to  eliminate from the data set those records that have missing  values [6].  This approach ignores potentially useful  knowledge hidden in the incomplete data.

The second solution to dealing with missing data is to  estimate the missing value in the data item.  In general  cases, one may use some expected value in the data item  based on statistical measures [4].  However, distributions  of data in surveys are commonly unknown.  Imputation  and use of an expected value for a particular missing data  item in these cases might be misleading [1].

The third approach to dealing with missing data is to  use generic ?unknown? for all missing items and treat  incomplete data as complete data [2].  However, few  studies of this approach rise above making all missing  values equivalent.

The fourth approach to dealing with missing data is to  treat missing data as non-deterministic data [8].  The  missing data item is replaced with two data items, and  each data item has its value attached with a probability.

The major problem of this approach is the estimation of  the probabilities of the values for the missing data.  Since  the records with missing items and the records without  missing items often come from different populations.

The above four conventional approaches to dealing  with missing data place their focal points on the side of  complete data, but fail to take into account the knowledge  about the missing data.  This study places the focal point  on discovering knowledge about missing data.  It uses a  rough set rule induction approach to discovering  knowledge about the missing data.  Rough set theory [11]  is a fairly new, but is a promising approach for knowledge  discovery from databases [3,5,13].  It is used for this study  because survey data are discrete, it requires few  assumptions more than the data set itself, and the rule  induction process is relatively easy to understand.  The  rest of the paper is organized as follows.  Section 2  proposes a set of prototypes of knowledge pertinent to  missing data in the form of association rules.  Section 3  provides a brief overview of the rough set rule induction  method.  Section 4 presents the knowledge discovery  results on a real-world student teaching evaluation  database using the rough set method.  Finally, Section 5  gives conclusions.

2. Knowledge Prototypes   A knowledge prototype is the description of an  interesting pattern of the data in investigation.  This  section discusses non-trivial knowledge prototypes  pertinent to missing data, which go above simple  descriptive statistics of missing data such as missing  percentages and missing distributions.  In this study, a  knowledge prototype is represented by a generalized  association rule that describes the relationship of missing  data.  Four knowledge prototypes about missing data are  proposed as follows.

(1) Complementing ? Complementing is knowledge about  certain attributes that have missing values at the same  time.  The knowledge prototype in the association rule  form is   if  (?1 is ?) [and (?k is ?)] then  (?p is ?)  2008 International Symposium on Knowledge Acquisition and Modeling  DOI 10.1109/KAM.2008.177     with  ?    (1)   where ? indicates the missing value, ? is attribute, ?p is  the attribute in investigation, [ ] is a repeat item and can be  null, and ? is the evidence.  The larger ? is, the stronger  the evidence would be.  Cut-off values can be used to  filter massive rules inducted by the rule induction  machine.  The selection of these values always depends on  the insight of the individual case.

(2) Clashing - Clashing is knowledge about two attributes  that do not have missing values at the same time.  The  knowledge prototype in the association rule form is   if  (?1 is ?) then  (?p is not ?)  with  ?    (2)   where ?p is the attribute in investigation.

(3) Hiding ? Hiding is knowledge about records with a  certain value in one attribute that have missing values in  the attribute in investigation.  The knowledge prototype in  the association rule form is   if  (?1 is a1) then  (?p is ?)  with  ?    (3)   where a1 is the value of ?1 and could be a range of values,  ?p is the attribute in investigation.

(4) Disclosing ? Disclosing is knowledge about records  with a certain value in one attribute that do not have  missing values in the attribute in investigation.  The  knowledge prototype in association rule form is   if  (?1 is a1) then  (?p is not ?)  with   ?    (4)   3. Rough Set Method    Rough set theory was developed in the early 1980s  [9,10].  It concerns itself with classificatory analysis based  on approximation of sets.  Rough sets techniques have  advantages over statistical methods in that they typically  deal with categorical discrete data which do not meet with  statistical assumptions.  Numerical data must be  discretized in order to apply a rough set technique.  In  comparison with other association rule induction  techniques, rough set techniques require few assumptions  more than the data set itself.

Here, we briefly overview the rough set rule induction  method with emphasis on missing data, and refer to [7,11]  for comprehensive reviews of rough set theory.  Suppose  we have a student teaching evaluation survey shown in  Table 1.  The database is called decision table, or  information system.  The example decision table has two  observations, or objects.  Each object is described by three  attributes.  The last attribute in this table denotes the  decision and is called decision attribute.  The other  attributes are referred to as condition attributes.

Table 1. Example of survey database  No. Textbook Feedback Course  1 Good Timely Good  2 Poor Delayed Poor    Let S be the decision table, ? be attribute, C be the set  of condition attributes, D be the set of decision attributes,  ? be logical formulas built from ??C; values of ?; and  logical connectives (and, or, not), and ? be logical  formulas built from ??D; values of ?; and logical  connectives.  A decision rule ??? is admissible in S if  |???|S??.  Decision rules admissible in Table 1 are the  following.

if       (Textbook is Good) and (Feedback is Timely)  then Course is Good  with Support 1 (of 2), Accuracy 1, Coverage 1   if       (Textbook is Poor) and (Feedback is Delayed)  then Course is Poor  with Support 1 (of 2), Accuracy 1, Coverage 1   The support of a decision rule is the number of objects  that match the rule.  Accuracy is defined as the number of  objects that match the rule divided by the number of  objects that match the condition, and Coverage is defined  as the number of objects that match the rule divided by the  number of objects that match the decision.  Support,  accuracy, and coverage are used to assess the creditability  of the rule.  The general form of decision rules is   if   (condition-1) and (condition-2) and ...

then  (decision-1) or (decision-2) or ...

with  support, accuracy, coverage   Suppose there are missing data in the database, as  shown in Table 2.  The question mark (?) in Table 2  indicates the missing value.  To find the pattern of missing  data, we rearrange the table, as shown in Table 3.

Table 2. Example of survey database  No. Textbook Feedback Course  1 Good Timely Good  2 Poor Delayed Poor  3 ? Timely Good     Table 3. Example of survey database  No. Feedback Course Textbook  1 Timely Good Good  2 Delayed Poor Poor  3 Timely Good ?

Using the rough set rule induction method, we can  have the following rules, if we keep the object with  missing data in the table.

if      (Feedback is Timely) and (Course is Good)  then (Textbook is Good) or (Textbook is ?)  with Support 2(of 3), Accuracy 0.5,0.5, Coverage 1,1   if     (Feedback is Delayed) and (Course is Poor)  then Textbook is Poor  with Support 1 (of 3), Accuracy 1, Coverage 1   Since these rules do not have a decision context, they  are called association rules in this study.  We are  particularly interested in the first association rule that is  related to missing data.  Apparently, as long as the last  attribute has a missing value, there normally is  inconclusive conclusion in rules.  Given the fact that there  certainly is a missing value in Textbook, we can perceive  knowledge about the missing data based on the rule.  We  rewrite the part of the rule that is specifically relevant to  the missing value as follows.

if       (Feedback is Timely) and (Course is Good)  then  (Textbook is ?)  with  Support 1 (of 3), Accuracy 0.5, Coverage 1   An interpretation of this rule is: the value in Textbook  is missing when Feedback is Timely and Course is Good,  with 0.3 support, 0.5 accuracy, and 1 coverage.  Note that  such an association rule does not lend itself to estimation  of missing values; rather, it reveals knowledge about  missing data in relation to other data items of the database.

4. Experiment   In this section, we present a real-world case study that  applies the proposed approach to demonstrate knowledge  discovering on missing data.  Survey methods of student  opinions of professors have been widely used at  universities to evaluate the teaching performance of  professors.  The data used in this study came from a  survey of student opinions of professors at a Canadian  university.  In this case, twenty one questions describe the  characteristics of a professor?s performance.  Each  question is rated on a five-point scale for students to  answer.  A high mark for a question indicates a positive  answer to the question.  As twenty one questions were  related to the evaluation of effectiveness of teaching for a  class session, twenty one attributes were consisted for  knowledge discovery, as listed below.

?1: The instructor explains difficult concepts clearly and  understandably.

?2: Class sessions appear to be carefully planned.

?3: The instructor conveys strong interest and enthusiasm.

?4: Students are encouraged to express their views and  participate in class.

?5: The instructor shows a genuine concern for student  progress.

?6: The instructor stimulates students to think for  themselves.

?7: Effective use is made of examples and illustrations.

?8: The instructor speaks in a way which can be clearly  understood.

?9: The instructor makes it clear how each topic fits into  the course.

?10: This course was a positive learning experience.

?11: Classes are held regularly to an agreed schedule.

?12: The various parts of the course are effectively  coordinated.

?13: Course requirements are communicated clearly and  explicitly.

?14: Tests and assignments are reasonable measures of  student learning.

?15: Where appropriate, student work is graded promptly.

?16: Where appropriate, helpful comments are provided  when student work is graded.

?17: There is close agreement between stated course  objectives and what is taught.

?18: Test and assignments provide adequate feedback on  student progress.

?19: The instructor is willing to schedule consultation  time with the students.

?20: The text book(s) and course material are useful.

?21: In comparison to other instructors, this instructor is  an effective teacher.

Data of 2312 incomplete records were collected.  The  rough set software system used for rule induction was  ROSETTA [12].  ROSETTA is a well developed software  package of rough set toolkit [5].  It provides a variety of  rule induction functions as well as a good user interface,  and is easy to use.  The experiment went through the  following steps.

Step 1.  Format the data to comply the format of  ROSETTA (similar with Table 3).

Step 2.  Make replications of the data set for rule  induction.  We made 21 replications from the data  set for the 21 attributes in investigation.  For each  set, the attribute in investigation was treated as the  decision attribute for rule induction and was placed  into the last column of the decision table.  For each     replication, we made another data set by replacing  all non-missing value in the attribute in  investigation with the generic value (Non-Missing)  for inducting clashing and disclosing knowledge  prototypes.

Step 3.  Induct association rules.  For each of the  replication date sets, we applied the rough set rule  induction machine to obtain association rules.

Johnson?s algorithm and Holte?s 1R algorithm (see  [7] for details) were used to generate two sets of  association rules for each data set.  Johnson?s  algorithm produced rules with logical connectives,  while Holte?s 1R algorithm produced rules with  single conditions.  We found that Holte?s 1R rules  were easy to filter, while the rules from Johnson?s  algorithm were useful for further justification.

Step 4.  Filter association rules and extract knowledge.

We used the knowledge prototypes (1) through (4)  to filter the sets of association rules.  This process  could be manpower intensive as it always depends  on the data miner?s special interests.  Finally, we  interpreted the filtered association rules and  discovered the evidences of missing data hidden in  the database.

By filtering and examining the rules inducted, pieces of  knowledge pertinent to the missing data in this database  were discovered, as summarized below.

(1) ?15 and ?16 had a strong complementing relationship.

If a record had a missing value in the question related  to grading, then it was more likely to have a missing  value in the question related to comments (with  support 822 (of 2312), accuracy 0.88).

(2) ?15 and ?21 had a moderate hiding relationship.  If a  record had higher than 4 for the question related to  grading, then it was more likely to have a missing  value in the question related to ranking the teacher  (with support 215 (of 2312), accuracy 0.24).

(3) ?15 and ?19 had a moderate hiding relationship.  If a  record had less than 3 for the question related to  grading, then it was more likely to have a missing  value in the question related to consultation (with  support 203 (of 2312), accuracy 0.31).

(4) ?2 and ?3 had a strong disclosing relationship.  If a  record had higher than 4 for the question related to  class plan, then it was more likely not to have missing  value in the question related to the teacher?s  enthusiasm (with support 1247 (of 2312), accuracy  0.84).

(5) ?16 and ?19 had a relative strong disclosing  relationship.  If a record had higher than 4 in the  question related to helpful comments, then it was more  likely not to have missing value in the question related  to consultation (with support 793 (of 2312), accuracy  0.42).

(6) ?13 and ?21 had a strong disclosing relationship.  If a  record had lower than 3 for the question related to the  clarity of requirements, then it was more likely not to  have missing value in the question related to ranking  the teacher (with support 1089 (of 2312), accuracy  0.65).

(7) ?17 and ?18 had a strong clashing relationship.  If a  record had a missing value in the question related to  the clarity of course objectives, then it was more likely  not to have missing value in the question related to the  provision of feedback (with support 988 (of 2312),  accuracy 0.87).

5. Conclusions   In the knowledge acquisition literature, incomplete  data are commonly subject to ?cleansing?, and knowledge  concealed in missing data is often overlooked.  This study  proposes a framework of discovering knowledge on  missing data.  Complementing, clashing, hiding, and  disclosing are prototypes of knowledge about missing  data.  Following these knowledge prototypes, the  association rules generated by rough set rule induction  machine can be filtered for knowledge discovering.

Through the real-world case, it has been demonstrated that  this framework is effective for discovering knowledge  about missing data.  Furthermore, our experience shows  that the rough set rule induction technique is a powerful  tool for knowledge acquisition in this aspect.

In the knowledge acquisition process, new concepts  must be constructed through demystifying the data.  We  conclude that useful knowledge can be discovered from  missing data.  A good knowledge acquisition practice shall  provide manifold perspectives on the entire original data  set.

Acknowledgement   The first author is supported in part by Grant 312423  from the Natural Sciences and Engineering Research  Council of Canada (NSERC).

