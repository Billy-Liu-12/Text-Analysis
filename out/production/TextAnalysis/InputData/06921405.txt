ASSESMENT OF APRIORI AND ENHANCED APRIORI ALGORITHMS IN  MINING ITEMSETS FROM THE KDD DATABASE

Abstract: In this paper, the best way to mine the frequent item sets is proposed. Apriori and Enhanced Apriori algorithms are explained here.

These both algorithms are compared and analysed to find the best one in terms of time complexity and I/O Transaction.

Keywords: Candidate generation, Frequent Itemsets, Transaction_Size, Threshold

I. INTRODUCTION  Data mining also known as Knowledge Discovery in Database(KDD). The function of data mining is to summary interesting knowledge from the large database[11].

From the study of distracted patterns, decision-making process can be done minimally [1].

Association rule is based mainly on discovering frequent item sets. Association rules are frequently used by retail stores to assist in promotion, publicity, inventory control, predicting errors in telecommunication network[2].

Traditional Apriori algorithm represents the candidate generation approach. It generates candidate (k+1) itemsets based on frequent k-itemsets[3].

Enhanced Apriori algorithm is proposed to overcome the drawbacks of Traditional Apriori algorithm.

This algorithm reduces the review time by cutting down non-essential transaction records.



II. TRADITIONAL APRIORI ALGORITHM  Apriori employs an iterative approach known as a level wise search, where k-itemsets are used to explore (k+1)-itemsets. First, the set of frequent 1-itemsets is found by scanning the database to accumulate the count for each item, and gathering those items that indulge least support.

The resultant set is denoted by L1. Next, L1 is used to uncover L2, the set of recurrent 2- itemsets, which is used to find L3, and so on, until no more recurrent k-itemsets can be created. The discovery of each Lk requires one full examine of the database. To improve the effectiveness of the level- wise generation of recurrent itemsets, an essential property called the Apriori property, offered is used to reduce the search space. [4]    A. Apriori property All nonempty subsets of a frequent itemsets must also be  frequent. A two-step process is used to find the frequent itemsets: join and prune actions.

1. The join step: To find Lk a set of candidate k-itemsets is generated by joining Lk-1 with itself. This set of candidates is denoted Ck.  [5]  2. The prune step: The members of Ck may or may not be recurrent, but all of the recurrent k-itemsets are incorporated in Ck. A scan of the record to determine the count of each candidate in Ck would result in the  determination of Lk (i.e., all candidates having a count no less than the minimum support count are frequent by definition, and therefore belong to Lk). [6]To reduce the size of Ck, the Apriori property is used as follows. Any (K-1)- itemset that is not frequent cannot be a subset of a frequent k-itemset. Hence, if any (K-1)-subset of a candidate k- itemset is not in Lk-1, then the candidate cannot be recurrent furthermore and so can be removed from Ck.[7]   B. Description of the Traditional Apriori algorithm :  Input: D, Database of transactions, min_sup, minimum support threshold.

Output: L, frequent itemsets in D Method: (1) L1=find_frequent_1-itemsets(D); (2) for(k=2; Lk-1??; k++){ (3) Ck=apriori_gen(Lk-1, min_sup); (4) for each transaction t?D{ (5) Ct=subset(Ck,t); (6) for each candidate c?Ct (7) c.count++? (8) } (9) Lk={ c?Ck |c.count?min_sup } (10) } (11) return L=UkLk ;  Procedure apriori_gen (Lk-1:frequent(k-1)-itemsets) (1) for each itemset l1? Lk-1{ (2) for each itemset l2? Lk-1{ (3) if(l1 [1]= l2 [1])? (l1 [2]= l2 [2]) ???(l1 [k-2] =  l2 [k- 2]) ?(l1 [k-1]< l2 [k-1]) then { (4) c=l1?l2; (5) if has_infrequent_subset(c, Lk-1) then (6) delete c; (7) else add c to Ck ; (8) }}} (9) return Ck;  Procedure has_infrequent_subset (c: candidate k-itemset; Lk-1:frequent(k-1)-itemsets) (1) for each(k-1)-subset s of c { (2) if s ? Lk-1 then (3) return true; } (4) return false; C. Example    Let?s look at a concrete example, based on the textile transaction database, D, of Table 1.1. There are nine transactions in this database, that is, |D| = 9. We illustrate the Traditional Apriori Algorithm using following steps.

Table 1.1. Experimental data     D. Generation of Frequent Itemsets Using Traditional Apriori Algorithm   Following steps explain the generation of candidate item set and frequent item set for the above transaction table 1.1.where minimum support count is 2.

Step 1: Scan D for count of each candidate               Step 2: Evaluate candidate support count with least support count   Itemset Sup.count  [a] 6 [b] 8 [c] 6 [d] 3 [e] 2         Step 3: Generate C2 candidate from L1   Itemset [a , b] [a , c] [a , d] [a , e] [b , c] [b , d] [b , e] [c , d] [c , e] [d , e]   Step 4: Scan D for count of each candidate    Step 5: Compare candidate support count with minimum support count   Itemset Sup.count [a,b] 5 [a,c] 4 [a,d] 2 [a,e] 2 [b,c] 4 [b,d] 2 [b,e] 2   Step 6: Generate C3 candidate from L2   Itemset [a,b,c] [a,b,e] [a,b,d]   Step 7: Scan D for count of each candidate   Itemset Sup.count [a,b,c] 3 [a,b,e] 2 [a,b,d] 2     TID List  of item_IDs  T100 a,b,e  T200 b,d  T300 b,c  T400 a,b,d  T500 a,c  T600 b,c  T700 a,b,c,d  T800 a,b,c,e  T900 a,b,c  Itemset Sup.count [a] 6 [b] 8 [c] 6 [d] 3 [e] 2  Itemset Sup.count [a,b] 5 [a,c] 4 [a,d] 2 [a,e] 2 [b,c] 4 [b,d] 3 [b,e] 2 [c,d] 0 [c,e] 1 [d,e] 0    Step 8: Compare candidate support count with minimum support count   Itemset Sup.count [a,b,c] 3

III. ENHANCED APRIORI ALGORITHM  Traditional Apriori algorithm generates large number of candidate sets for large database. So it consumes more cost[8]. To avoid this, Enhanced Apriori Algorithm is introduced which reduces the size of the database. In this proposed system we introduce a variable Transaction_Size(TS) which contains the number of items in individual transaction. If the Transaction_Size is less than threshold value, that transaction alone will be deleted from the database[9].

A. Description of the algorithm  Input: D: Database of transactions; min_sup: minimum support threshold  Output: L: frequent itemsets in D  Method: 1) L1=find_frequent_1-itemsets(D); 2) For(k=2;Lk-1??; k++){ 3) Ck=apriori_gen(Lk-1, min_sup); 4) for each transaction t?D{ 5) Ct=subset(Ck,t); 6) for each candidate c?Ct 7) c.count++; 8) } 9) Lk={ c?Ck |c.count?min_sup }; 10) if(k>=2){ 11) delete_datavalue(D, Lk, Lk-1); 12) delete_datarow (D, Lk); } 13) } 14) return L=UkLk ;  Procedure apriori_gen(Lk-1:frequent(k-1)-itemsets) 1) for each itemset l1? Lk-1 { 2) for each itemset l2? Lk-1 { 3) if(l1 [1]= l2 [1])? (l1 [2]= l2 [2]) ???(l1 [k-2]= l [k-2]) ?(l1 [k-1]< l2 [k-1]) then { 4) c=l1 ?l2; 5) for each itemset l1?Lk-1 { 6)  for each candidate c ?Ck { 7)   if l1 is the subset of c then 8)    c.num++; }}}}} 9)  C'k={ c?Ck |c.num=k}; 10) return C'k; Procedure delete_datavalue (D:Database; Lk: frequent (k)- itemsets; Lk-1: frequent(k-1) - itemsets) 1) for each itemset i ?Lk-1 and i ? Lk{ 2)  for each transaction t?D{ 3)   for each datavalue?t{ 4)    if (datavalue=i) 5)     update datavalue=null;  6) }}  Procedure delete_datarow (D: Database;  Lk:frequent(k) - itemsets) 1) for each transaction t?D{ 2)  for each datavalue?t{ 3)   if(datavalue!=null and datavalue!=0 ){ 4)    datarow.count++; }} 5)  if(datarow.count<k){ 6)   delete datarow;} 7)}   B. Example of Algorithm Following steps show the generation of frequent  itemset for table 1.1 using Enhanced Apriori Algorithm.

Generation Of Frequent Itemset Using Enhanced Apriori Algorithm  Step 1 :                          TID List  of item_IDS TS  T100 a,b,e 3  T200 b,d 2  T300 b,c 2  T400 a,b,d 3  T500 a,c 2  T600 b,c 2  T700 a,b,c,d 2  T800 a,b,c,e 4  T900 a,b,c 3  Itemset Sup.count [a] 6 [b] 8 [c] 6 [d] 3 [e] 2  Itemset Sup.count  [a] 6  [b] 7  [c] 6  D1  C1 L1    Step 2:          Step 3:

IV. COMPARISION BETWEEN APRIORI AND ENHANCED APRIORI ALGORITHM  We have performed the comparison of Apriori and Enhanced Apriori algorithms for different set of instances and confidence. This comparison is shown in the below graph.

The above Fig.1 shows that the time taken to execute the Enhanced Apriori Algorithm is less compared with Apriori for any Confidence level. Thus the performance of Enhanced Apriori Algorithm is an efficient and scalable method for mining the complete set of frequent patterns[10].



V. CONCLUSION  In this paper, the enhanced algorithm not only optimizes the algorithm of reducing the size of the candidate set of k- itemsets, Ck, but also reduces the I / O spending by cutting down transaction records in the database. The performance of Apriori algorithm is optimized so that we can mine association information from massive data faster and better.

The performance analysis is done by varying number of instances and confidence level. The efficiency of both algorithms is evaluated based on time to generate the association rules.

From the above examination it can be done that the Enhanced Apriori Algorithm is the best way to find the frequent item sets.



VI. REFERENCES   [1] Margret H. Dunham, S.Sridhar, ?Data mining Introductory and advanced topics?, Pearson Education,Second Edition,2007.

[2] Agrawal, R, Srikant, R, 1994, ?Fast algorithms for mining association rules in large databases?, Proc. of 20th Int?l conf. on VLDB: 487-499.

[3] C. Gyorodi, R. Gyorodi. ?Mining Association Rules in Large Databases?. Proc. of Oradea EMES?02: 45-50, Oradea, Romania, 2002.

TID List  of item_IDS  TS  T100 a,b 2  T200 b 1  T300 b,c 2  T400 a,b 2  T500 a,c 2  T600 b,c 2  T700 a,b,c 3  T800 a,b,c 3  T900 a,b,c 3  Itemset Sup.count [a,b] 5  [a,c] 3 [b,c] 5  Itemset Sup.count  [a,b] 5  [b,c] 5  TID List  of item_IDS TS  T100 a,b 2  T300 b,c 2  T400 a,b 2  T600 b,c 2  T700 a,b,c 3  T800 a,b,c 3  T900 a,b,c 3  Itemset Sup.count  [a,b] 4  [b,c] 4  Itemset Sup.count  [a,b,c] 2  D2  C2 L2  D3  C3 L3     [4] M., Suraj Kumar Sudhanshu, Ayush Kumar and Ghose M.K., ?Optimized association rule mining  using genetic algorithm Anandhavalli Advances in Information Mining? , ISSN: 0975?3265, Volume 1, Issue 2, 2009, pp-01-04  [5] Han, J, Pei, J, Yin, Y 2000, ?Mining Frequent Patterns without Candidate Generation?,  Proc. of ACM-SIGMOD.

[6] Daniel Hunyadi, ?Performance comparison of Apriori and FP-Growth algorithms in generating association rules?, Proceedings of the European Computing Conference.

[7] Goswami D.N. et. al. ?An Algorithm for Frequent Pattern Mining Based On Apriori?,  (IJCSE) International Journal on Computerm Science and Engineering Vol. 02, No. 04, 2010, 942-947  [8] Ms Shweta and Dr. Kanwal Garg ?Mining Efficient Association Rules Through Apriori Algorithm Using Attributes and Comparative Analysis of Various Association Rule Algorithms?, International Journal of Advanced Research in Computer Science and Software Engineering Volume 3, Issue 6, June2013.

[9] Pulari.s.s et al, ?Understanding Rule Behavior through Apriori Algorithm over Social Network Data?, Global Journal of Computer Science and Technology Volume 12 Issue 10 Version 1.0 May 2012.

[10] ?Fast Algorithms for Mining Association Rules?, IBM Almaden Research Center, 650 Harry Road, San Jose, CA 95120.

