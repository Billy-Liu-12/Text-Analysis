EDP-ORD: Efficient Distributed/Parallel Optimal  Rule Discovery

Abstract?Association rule discovery algorithms generate all rules satisfying minimum support and confidence thresholds.

These techniques yield too many rules and are infeasible when the minimum support is low. Recently, Li [1] proposed the Optimal Rule Discovery (ORD) algorithm that discovers a family of rule sets that maximizes a range of interestingness metrics, other than the commonly used confidence metric. In addition, the discovered optimal class association rule set is the minimum subset of rules with the same predictive power as the complete class association rule set. Moreover, ORD is significantly more efficient than association rule discovery independent of the data structure and the implementation. Due to the existence of huge amounts of data, it is important to investigate efficient methods for distributed/parallel mining of rules. In this paper, we propose EDP-ORD an efficient distributed/parallel extension of the ORD algorithm. We theoretically disclose a relationship between locally large and globally large rules and use it in reducing the number of generated rules and the exchanged messages at each site/partition. Moreover, we empirically compare EDP-ORD with a na?ve distributed/parallel ORD version on five benchmark datasets. The experimental results shows that the reduction in number of generated rules at each site can reach 44% while the reduction in total size of exchanged messages can reach 58%.

Keywords- data mining; association rule discovery; rule-based classifiers; distributed rule discovery; parallel rule discovery

I. INTRODUCTION The term data mining is often used as a synonym for the  process of extracting useful information from databases. Data mining is the application of specific algorithms for extracting structure from data. Rules are among the most expressive and human-understandable representation of knowledge, so rule discovery has been a major issue in data mining [1].

Association rules discovery is the task of inferring rules, which states that certain values occur with other values above a certain frequency in data with some pre-specified certainty.

Association rule discovery generates all rules satisfying some constraints, but yields too many rules and is infeasible when the minimum support is small. Optimized rule discovery is an efficient alternative that generates a smaller set of rules by pruning redundant rules. Classification rule mining aims to discover a small set of rules in the database to form an accurate classifier. For association rule mining, the target of mining is not predetermined, while for classification rule mining there is one.

ORD [1] is an optimal class association rule mining algorithm that prunes the candidate rules according to an interestingness metric and is independent of the data presentation.  In addition, the discovered optimal class association rule set is the minimum subset of rules with the same predictive power as the complete class association rule set [2].

The development of distributed/parallel algorithms for efficient mining of associative classification rules has its importance because many large databases are distributed in nature. In addition, mining association rules in huge databases (or data warehouses) may require substantial processing power, and a distributed/parallel system is a possible solution. This motivates us to extend the centralized ORD to a distributed optimal rule discovery for mining associative classification rules in a horizontally partitioned database. We adapt a local pruning strategy at every site that efficiently finds the optimal rules when compared to a na?ve approach.

It has been well know that the major cost of mining rules is the computation of the frequently occurring patterns. In a distributed scenario, locally large patterns can be easily computed but they are not necessary be globally large. One possible solution is to broadcast all counts of all patterns no matter they are locally large or small. This is a na?ve solution that might lead to passing huge number of messages.

The main contribution of our work is that we disclose a relationship between ORD locally large and globally large rules and explore it to generate a smaller set of candidates at each site and reduce the number/size of messages to be passed. In addition, experiments are conducted to study the reduction achieved.

The rest of the paper is organized as follows: in section II we survey the related research; in section III we outline the definitions, notations, and the original/centralized ORD algorithm; in section IV we present a na?ve ORD extension (NDP-ORD), the ORD local pruning theorem and its proof, and the developed EDP-ORD; in section V we detail the experimental setup and results; in section VI we conclude the paper and discuss future research.



II. RELATED WORK The benefits of mining association rules and its wide  applications have led to several proposals for fast mining of association rules [3].

It is widely recognized that the set of association rules can rapidly grow to be unwieldy and that it contains redundancy.

[4]  present a framework for association rule mining based on the concept of closed frequent itemsets. The set of all closed frequent itemsets can be orders of magnitude smaller than the set of all frequent itemsets.

One type of optimal rule set is k-largest rule sets, which contain the top k rules measured by an interestingness metric [5].However, the top k rules may come from the same section of data and leave some records in a data set uncovered by rules.

The problem of not reasonably covering the data set exists in other optimal rule sets, such as the SC optimality rule set [6] and rule sets defined by all confidence and bond [7].

The definition of optimal rule sets in [1] is a special constraint rule set with a zero confidence improvement, which consists of rules whose confidences are greater than confidences of all their simpler form rules. A PC optimality rule set [6] post prunes the constraint association rule set with a zero confidence improvement. The definition of optimal rules in ORD [1] very close to this definition and considers covering the data set.

With the rapid development of the Internet/Intranet, distributed databases have become a broadly used environment in various applications [8]. The algorithms for distributed mining of association rules can be divided into two classes.

One that focuses on data partition optimization for a centralized database so as to enhance the search efficiency, and the other considers a setting where the data is arbitrarily partitioned horizontally among the parties and focuses on parallelizing the communication [8]. The second approach is a more appealing solution for systems which are naturally distributed over large expenses, such as stock exchange and credit card systems. Fast distributed mining of association rules (FDM) [9] algorithm belongs to the second class of distributed association rule mining.



III. ORD: OPTIMAL RULE DISCOVERY Considering a relational data set D with m attributes, the  following definitions hold:  ? A record, T, is a set of attribute-value pairs. All the records in D are categorized by a set of classes C = {c 111, c 222, ?.,c kkk}, |C| = k;  ? A pattern, P, is a subset of a record. An l-pattern contains l attribute-value pairs. For simplicity, we use uppercase letters (e.g. P and Q) to stand for patterns and lowercase letters (e.g. a; b; . . .) to stand for an attribute-value pair. We abbreviate P U Q as PQ and P U a as Pa.

? An association rule is an implication P? Q, where P ? Q = ?  ? A classification rule is an implication P? c, where  c ? C  ? The support of pattern P, sprt(P), is the ratio of the number of records containing P to the number of  records in D. The support of implication P? Q, sprt(P? Q) = sprt(PQ).

? The support count of a pattern, cnt(P), is the number of records in D containing P, i.e. cnt(P) = sprt(P) x |D|.

? The cover set of pattern P, cvr(P), is the set of IDs of records containing P. The cover set of implication P? Q, cvr(P? Q) = cvr(PQ).

? ?c stands for a special class occurring in a record where c does not occur, where sprt(?c) = 1 ? sprt(c).

Similarly sprt (?P) = 1 ? sprt (P).

? Many interestingness metrics have been proposed to measure interestingness of rules [10]. A rule with a higher value in a metric is more interesting than a rule with a lower one. ORD theorem and corollaries apply when Interest is defined by confidence, odds ratio, lift (interest or strength), gain, added-value, Klosgen, conviction, p-s (or leverage), Laplace, cosine, certainty factor, or Jaccard. Each metric defines an optimal rule set. The following Interest metrics are used in our classification study [1]:  o )( )()(  Psprt PcsprtcPconfidence ??  o ||||)(  1||)()( CDPsprt  DPcsprtcPLaplace ?  ???  o )(  )()()( cPsprt  csprtPsprtcPconviction ?  ???  ? A rule is a strong implication whose both support and interestingness are not less than given thresholds.

? Given two rules P? c and Q? c, where P ? Q, we say that the latter is more specific than the former and the former is more general than the latter. That is, cvr(Q) 	 cvr (P), and cvr (Q? c) 	 cvr (P? c).

Therefore, the removal of a specific rule from a rule set does not reduce the coverage of that rule set.

? A rule set is optimal with respect to an interestingness metric if it contains all rules except those with no greater interestingness than one of its more general rules.

Let X be a pattern where X ? ?, and let c be a class. PX is a proper super pattern of P. PQ is a super pattern of P. When Q = ?, PQ = P and PQX = PX. PQX is a proper super pattern of P. P?X is a pattern with the following support:  sprt(P?X) = sprt(P) ? sprt(PX). Further, we have sprt(?(PX)) = sprt (?PX)+ sprt (?P?X) + sprt (P?X).

ORD Theorem (Antimonotonic property): If sprt(PX?c) = sprt(P?c),  then rule PX? c and all its more-specific rules will not occur in an optimal rule set defined by an Interest metric.

ORD Corollary-1 (Closure property): If sprt(P) = sprt(PX), then rule PX? c for any c and all its more specific rules do not occur in an optimal rule set defined by an Interest metric.

ORD Corollary-2 (Termination property): If sprt(P?c) = 0, then all more-specific rules of the rule P? c do not occur in an optimal rule set defined by an Interest metric.

See [1] for proofs of ORD theorem and corollaries. The practical implication of the above theorem is that once sprt(PX?c) = sprt(P?c) is observed, it is not necessary to search for more specific rules of PX? c, for example, PQX ? c. Those more specific rules will not be in an optimal rule set.

Rule PX? c is removed since it is not in an optimal rule set either.

The practical implication of Corollary-1 is that, once sprt(PX) = sprt(P) is observed, it is not necessary to search for rules with PQX as their antecedent for any Q. Those rules will not be in the optimal rule set.

The practical implication of Corollary-2 is that once sprt(P?c) = 0 is observed, it is not necessary to search for more specific rules of P? c. Those more-specific rules will not be in an optimal rule set. Rule P? c is kept since it may be in an optimal rule set.

The ORD-Pruning function detailed next is the direct application of ORD theorem and its corollaries.

A. Itemset Tree and Support Counting Tree Recently, the Itemset Tree (IST) data structure has been  introduced as a representation of a transaction file [11][12] and is used for efficient ad-hoc mining queries. In addition, its use is extended for association rule mining [3]. The main advantage of the IST representation is that the database is read into a data structure that can fit in memory which speeds up its access instead of accessing the file on an external storage device.

In the proposed work, we adapt the IST as a data structure to be used for support counting in the ORD algorithm Originally, the IST is used for association rule mining that has no class information available. In the proposed work, we use the IST for mining association classification rules. The node structure and the tree construction algorithm are modified to reflect the existence of class information.

In the process of finding all the frequent patterns, we are not interested in the non-supported items. The non-supported items are the items that have a support less than the user- specified minimum support. The IST is cleaned after its construction (traversed for removing the non-supported items) [3].  The resulted tree is called the Support Counting Tree (SCT). SCT has a reduced size, where the number of nodes in the tree and the number of items within a node are reduced.

B. Centralized Optimal Rule Discovery (ORD) A pattern is frequent if its support is not less than the  minimum support. A pattern is potentially frequent (i.e.

candidate) only if all its sub-patterns are frequent.

Let CAl be the candidate rules at the l-th iteration (i.e. l- pattern rules), and Ll be the frequent rules kept after ORD pruning of CAl . Ll, CAl are represented by a linked list of items; where an item is [l-pattern P, a set of the pattern classes]; and a pattern class is (class c, cnt(Pc)). CLASS is a linked list of (class c, cnt(c)).

There is pruning in the candidate generation function (CandidateGen) detailed below. In addition, after counting the support of candidates ORD-Pruning is applied. Because of the possible skewed distribution of classes, a single global support is not suitable for a variant rule targeting different classes. In ORD pruning, it is suggested to use a recall threshold instead of a global support. The recall of rule P? c is defined as sprt(Pc)/sprt(c). The recall is the support in the data subset containing c.

In the ORD algorithm detailed in Fig. 2, any interestingness metric discussed above can be used as a rule-selection criterion and the output rule set is an optimal rule set defined by that metric. We have to consider maximum length for the generated rules to stop the candidate generation process for large number of items.

An association discovery algorithm searches for all frequent patterns, however ORD pruning significantly reduces candidates for searching. The set of ORD candidates is a very small subset of frequent patterns. This trend is more evident when the minimum support is low. Therefore, ORD has significantly less computational complexity than association rule discovery.

Consider the dataset in Fig. 1 where a, b, and c are items and y and z are classes. Assume that the minimum recall is 0, i.e. it is required to generate all rules.

Generating all patterns without ORD pruning we have the following seven candidates: [a, (y,3)(z,1)], [b, (y,3)], and [c, (y,2) (z,1)] at the first-level ; [a b, (y,2)], [a c, (y,2)( z,1)], [b c, (y,1)] at the second-level;[a b c, (y,1)] at the third-level. In this case, the total number of rules is ten.

Applying ORD, the first-level candidates are used to prune the second-level candidates as illustrated in Fig. 1, where a crossed class is removed and a boxed class is terminated. y in candidates (a b, y) and (b c, y) is terminated because of sprt(a b?y)=0 and sprt(b c? y)=0 (ORD Corollary-2). Both y and z are removed in candidate (a c, y z) since sprt(a c) = sprt(c) holds (ORD Corollary-1). After rules have been formed, candidates (ab, ?), (ac, ?) and (bc, ?) are removed. As a result, their super candidate will not be generated, and the candidate generation process stops at the second-level. In this case, the total number of rules is only seven (3 rules less).

Function CandidateGen (Ll) returns CAl+1 for each pair of candidates (Pl-1s, Cs) and (Pl-1t, Ct) in Ll insert candidate (Pl+1, C) in CAl+1, where Pl+1  = Pl -1st and C = Cs ? Ct for all Pl ? Pl+1  if candidate (Pl, Cl) does not exist in Ll then remove (Pl+1, C) and return else C = C ? Cl endfor if the target set C of (Pl+1, C) is empty then remove the candidate endfor     Function ORD-Pruning (CAl) ? is the minimum recall for each candidate (P, C) in CAl for each c C // test the frequency individually if sprt(Pc) / sprt(c) ? ? then remove c from C // test the satisfaction of ORD Corollary-2  elseif sprt(P?c)= 0 then mark c terminated endfor if C is empty then remove candidate (P, C) and return for each (l-1)-level subset P' ? P // test the satisfaction of ORD Corollary-1 if sprt(P) = sprt(P') then empty C // test the satisfaction of ORD Theorem  elseif sprt(P?c) = sprt(P'?c) then remove c from C endfor if C is empty then remove candidate (P, C) endfor

IV. DISTRIBUTED/PARALLEL OPTIMAL RULE DISCOVERY In this paper, we propose a novel extension for the ORD  algorithm in a distributed/parallel scenario. It is assumed that the database is horizontally partitioned into n sites/partitions, and it is required to mine the same optimal rules as if the whole database is located in a centralized location.

We first introduce a na?ve extension to the ORD algorithm in the distributed case. Then, we adapt the local pruning suggested in [9] for efficient distributed ORD. The local pruning is originally suggested for association rule mining and a global support threshold is used. However, as mentioned in section III, the ORD algorithm mines associative classification rules and uses a recall threshold. The recall of rule P? c, is defined as sprt(Pc)/sprt(c).

A database D, has |D| records that are distributed into n sites {S1, S2, ?, Sn }, i.e. D is horizontally partitioned into n partitions {D1, D2, ?, Dn} of size |Di| each, such that  ||||    ?  ? n  i iDD . The global support count of a class c equals the  summation of its local support counts at the n sites    ?  ? n  i i ccntccnt  )()( .

Apriori [13] and its distributed extension [9] mine all globally large association rules (where there is no target class) that satisfy certain minimum support threshold, s. That is, the algorithm finds all rules (P? Q), such that cnt(PQ) ? s x |D|;  where  ?  ? n  i i PQcntPQcnt  )()(  and cnti(PQ) is the local support  count of pattern PQ at site Si.

On the other hand, ORD and its distributed extension (we propose) mine all globally large classification rules that satisfy minimum recall threshold, ?. That is, the distributed ORD algorithm finds all classification rules (P? c), such that  cnt(Pc) ?  ? x cnt(c); where  ?  ? n  i i PccntPccnt  )()( .

Let L be defined as the globally large classification rules, where ?  l lLL ?  and Ll is defined as the globally large l-  patterns in L (i.e. classification rules having l-items in the antecedent). In addition, let CAl be defined as the candidate set at the l-th ORD iteration; i.e. CAl = CandidateGen(Ll-1).

A. NDP-ORD: Na?ve Distributed/Parallel ORD For comparison, we outline a na?ve distributed extension of  ORD as detailed in Fig. 3. At each iteration, the algorithm generates the candidate sets CAl at every site by applying the CandidateGen function on the set of large patterns Ll-1 found at the previous iteration. Every site then computes the local support counts of all these candidate patterns and broadcast them to all the other sites. Subsequently, all the sites can find the globally large patterns Ll for that iteration, and then proceed to the next iteration.

Consider the same centralized dataset is horizontally partitioned between two sites as follows.

S1  S2  The 1-candidates generated at S1  are  [a, (y,1) (z,1)], [b, (y,1)], [c, (y,1)(z,1)], and the 1-candidates at S2  are   [a, (y,2)], [b, (y,2)], [c, (y,1)]. After broadcasting the local support counts, S1 and S2 have the same 1-candidates support counts [a, (y,3)(z,1)], [b, (y,3)], [c, (y,2) (z,1)]. The 2-candidates generated at S1 are [a b,(y,1)],  [a c, (y,1)(z,1)],  [b c, (y,1)], and the 2-candidates at S2 are [a b,(y,1)], [a c, (y,1)],   [b c, (y,0)].

After broadcasting the local support counts S1 and S2 have the same 2-candidates support counts [a b, (y, 2)], [ac, (y,2) (z,1)], [b c, (y,1)]. Since the same support counts are available at both sites, the ORD Prunes the same rules.

B. EDP-ORD: Proposed Efficient Distributed/Parallel ORD As proofed in [9], there is an important relationship  between large/frequent patterns and the sites in a distributed database: every globally large pattern must be locally large at some site(s). If a pattern P is both globally large and locally large at a site Si, P is called gl-large at site Si. The set of gl- large patterns at a site will form a basis for the site to generate its own candidate sets. Two monotonic properties can be observed from the locally large and gl-large patterns. First, if a pattern P is locally large at a site Si, then all of its subsets are also locally large at site Si. Secondly, if a pattern P is gl-large at a site Si, then all of its subsets are also gl-large at site Si.

Notice that a similar relationship exists among the large patterns in the centralized case.

Following is an important theorem based on which an efficient technique for candidate sets generation in the distributed case is developed. We assume that initially every site Si (i =1 to n) locally count the local support counts for all classes cnti(cj) (for j =1 to k), and broadcast those counts to the other sites. Therefore, the global support count for each class cnt(cj),  j =1 to k,  is available.

a   b   c   y a        c   z a   b        y a        c   y b       y     Algorithm: ORD  Input:  data set D, min-recall ?; min-interestingness ? Output: an optimal rule set R  1:  Set R = ?; l = 1; CA1 = initialize to empty; IST = initialize to empty  //Count support of 1-pattern candidate classification rules 2:   for each record in D 3:      for each item (P, c) in the record 4:              search for the item P in CA1 5:              if found then increment cnt(Pc) by 1 6:                    else insert item(P, c) in CA1 and set cnt(Pc) to 1 7:      increment cnt(c) by 1 in the CLASS list 8:      insert the record in the IST end for  9:  L 111 = ORD-Pruning(CA1)  //Build the support counting tree (SCT) 10: SCT = using L 111 remove the non-supported items form IST and set the guiding information bits  11:  Form and add rules (P? c) (from L 111) to R if the rule satisfies min- interestingness ? and remove terminated cs.

12: l =2; CA2 = CandidateGen(L1)  13:  while CAl is not empty 14: Count support of CAl using SCT 15:  Ll = ORD-Pruning (CAl)  //Form and add rules to R that satisfy min-interestingness ? 16: for each (P, C) in Ll 17: for each c in C 18: add rule P? c to R if it satisfies min-interestingness ? 19:  if c is terminated then remove c from C  20: l ++; CAl = CandidateGen(Ll-1) end while  21:  Return the rule set R  a   b   c   y a        c  z a   b        y a        c   y b       y  ?   (a, y z)                   (b, y)                    (c, y z)   (a b, y)                (a c,y z)     (bc,y)   (a b c, y)  ?   (a, y z)                   (b, y)                    (c, y z)   (a b, y)              (a c,y z)    (b c,y)  Figure 1. ORD Pruning Example  ORD Local Pruning Theorem: If a classification rule (P? c) is globally large, there exists a site Si, (1 ? i ? n), such that P and all its subsets are gl-large at site Si.

(P? c) is globally large if  )()( ccntPccnt ??  (P? c) is locally large at site Si if n ccntPccnti )()( ??  proof  If )()( ccntPccnt ??   is to hold,  where  ?  ? n  i i PccntPccnt  )()( , and   ? ?  n  i i ccntccnt  )()( . Let the  local support count of rule P? c at site Si cnti(Pc) = ai  for i = 1 to n; and let the global support count for the class c, cnt(c) = Bj.. Then the rule (P? c) is globally large, if and only if,  ???  ?  n  i j  i  B a  cPrecall  )( . Assume a1 = a2 = ? = an = A,  and the above summation is equal exactly to ?; in this case  n B  A j ?  ?   . If the summation recall(P? c) is to be greater  than ? and/or an arbitrary ax is to be less than A, there should be at least one ai (at site Si ) that is greater than  A.

Figure 2. Centralized ORD Algorithm  In this case, the rule is considered locally large at that site.

Therefore, rule (P? c) is locally large at site Si, if and only if,  n ccntPccnta ii )()( ???  .

end of proof Let GLi denotes the set of gl-large patterns at site Si, and  GLi(l) denotes the set of gl-large l-patterns at site Si.  It follows from the above theorem, if rule (P? c) ? Ll, then ???site Si, such that all (l-1)-subsets of the rule ? GLi(l-1). The straightforward set of the candidates generated at the l-th ORD iteration CAl = CandidateGen(Ll-1). However, the l-pattern candidates generated from (l-1) gl-large itemsets at site Si CGi(l) = CandidateGen(GLi(l-1)). Since GLi(l-1) 	 L(l-1) then CGil  CAl . Let ? n  i lil CGCG  )(  ? ? , represent the candidate sets  generated from the gl-large items at all sites. Then we have CGl 	 CAl and the number of candidates in CGl could be much smaller than the number of candidates in CAl . The difference     between the two sets depends on the distribution of the classes in the n sites. If a class distribution is uniform, rules associated with this class will belong to almost every GLi(l) and the difference between CGl and CAl will be negligible. However, if a class distribution is normal, rules associated with this class will belong to few sites and the difference between CGl and CAl will be significant.

Let X ? Ll (the set of all large l-patterns). It follows from the above theorem that, there exists a site Si such that all (l-1) subsets of X are gl-large at Si. Hence X ? CGi(l), the candidates generated at the l-th iteration at Si, and therefore  X ? CGl. We can conclude that Ll  	 CGl. The above theorem forms a basis for an efficient generation of the candidate sets as follows.

1) Every site Si at the l-th ORD iteration locally generates the candidates CGi(l) from its gl-large patterns of previous iteration GLi(l-1) and at the same time counts the candidates? local support.

2) Every site collects the support counts of its candidates from other sites and sums the global support of those candidates to find its gl-large patterns GLi(l).

3) Based on GLi(l) the next iteration candidates can be generated.

Based on ORD local pruning theorem, some candidates in CGi(l) can be pruned before count exchange starts. If a candidate is not locally large at site Si, there is no need to count its global support because that candidate is either small or will be locally large at some other site. Every site is responsible to find the global support only for its locally large candidates.

However, a candidate could be locally large at more than one site. The next step is added to the outlined steps above:  1.1) Prune CGi(l) to find the locally large candidates LLi(l).

We can notice that, in order to supply the support count exchanges of step 2, each site must have two sets of support counts. For local pruning, Si has to find the local support counts of its CGi(l). In addition, Si has to find the local support counts of other sites candidates (LLj(l) j ? i).  A simple solution is to separate the counting steps but that would degrade the performance. Another solution is to let every site Si broadcasts its gl-large GLi(l) set at the end of each iteration. Then at the beginning of the next iteration, every site could generate all candidates for all sites and perform all the counting in one step as detailed in the algorithm Fig. 3. Note that broadcasting a message delivers the same copy of the message to every site.

While, in exchanging messages, a request message is first sent that contains the required patterns? support and the response message includes only the requested counts to the asking site.

Crafting the exchanged messages reduces the required communication bandwidth as illustrated in the experiments.

Consider the same horizontally partitioned dataset above.

The 1-candidates generated at S1  are [a, (y,1)(z,1)], [b, (y,1)], [c, (y,1)(z,1)], and at S2  are   [a, (y,2)],  [b, (y,2)], [c, (y,1)]. S1 and S2 request the counts of its generated candidates only after this step S1 has the candidates [a, (y,3)(z,1)], [b, (y,3)], [c, (y,2) (z,1)] and S2 has  the candidates [a, (y,3)],  [b, (y,3)], [c, (y,2)].

Note that the candidates (a, z) and (c, z) are not maintained by S2 and therefore the exchanged message sizes and the  computational complexity of the following iterations are reduced.

In the na?ve case, every local support count of every pattern is broadcast from every site to every other site, i.e the size of the exchanged message for that pattern is O(n2), where n is the number of sites. However, if the efficient ORD is applied, the best case scenario is that every pattern is found to be locally large at one site only and its local support counts are sent to that site reducing the size of the exchanged messages for that pattern to O(n). An upper-bound pruning could be performed after local pruning (step 14 at Fig. 3) and before exchanging the counts. For this pruning, every site has to send the individual local support counts (at the different sites) of its gl-large patterns in the broadcast message (step 17 at Fig.3). At site Si.

at the l-th iteration, an upper bound for the global support count of a locally large pattern (P? c) ? LLi(l) is    ??  ?? n  ijj ji PccntPccntPccnt  ,1 )(max)()( ; and  }1|||)(min{)(max ???? lQPandQQccntPccnt jj . If this upper bound is less than )(ccnt? the pattern is pruned from LLi(l) .



V. EXPERIMENTAL RESULTS In this section, we empirically evaluate the performance of  the proposed EDP-ORD in comparison with the na?ve extension of ORD in five data sets from UCML repository [14] described in Table I. We do not specify the type of optimal rule set since the same candidate set generates an optimal rule set defined by any interestingness metric discussed in Section III.

In addition, we employ the minimum recall threshold, which is a ratio for an individual class. A pattern is frequent if it is frequent in at least one class. An empirical estimation of the complexity for a distributed rule-discovery algorithm is the number of candidates it searches and the exchanged message sizes.

The sizes of the datasets in our study range from 150 records to 4177 records and have number of attributes in the range from 4 to 38. We compare the searched candidates for the two algorithms and the total exchanged messages size for different values of minimum recall and when the number of sites n is 2, 3, and 4. Table II shows the searched candidates by the two versions of distributed ORD algorithms (N for na?ve E for Efficient) at each site, while Table III shows the total exchanged messages size. The results show that the local pruning has significantly less computational complexity than the na?ve. The number of candidate sets found in ED-ORD at each site is reduced to 20-44% of that in ND-ORD. The total messages size in ED-ORD is reduced to 16-58% of that in ND- ORD. The reduction in the number of candidate sets and message size in ED-ORD is significant. The performance gain of ED-ORD is very important in distributed/parallel systems in which the communication is an important performance factor.

This shows that ED-ORD becomes more effective when the system is scaled up.

Algorithm: NDP-ORD @ Si  Input: a data set Di, min-recall ?; min-interestingness ? Output: an optimal rule set R  1: Set R = ?; l = 1; Construct IST for Di 2: Generate CAi1, the candidate 1-pattern rule set at Si and count their local support 3: Count the local support for all classes in CLASS cnti(cj)  j = 1,?, k 4: Broadcast the 1-pattern rule set and the classes? local support counts  5: ? n  i iCACA   ? ? ;  L1 = ORD-Pruning(CA1 )  6: SCT = Clean IST and set the guiding information bits 7: Form and add rules (from L1) to R that satisfy min-interestingness ? 8: l=2; CA2 = CandidateGen(L1) 9: while CAl is not empty 10:    Count local support (using SCT) of CAl patterns 11:    Broadcast local support counts of CAl candidates 12:    Sum the local supports of CAl patterns to find their global support 13:     Ll = ORD-Pruning(CAl) 14:     Form and add rules (from Ll) to R that satisfy min-interestingness ? 15:     l++; CAl = CandidateGen(Ll-1) end while 16: return the rule set R  Algorithm: EDP-ORD @ Si  Input: a data set Di, min-recall ?; min-interestingness ? Output: an optimal rule set R  1: Set R = ?; l = 1; Construct IST for Di 2: Generate CGi1, the candidate 1-pattern rule set at Si and count their local support 3: Count the local support for all classes in CLASS cnti(cj)  j = 1,?, k 4: Broadcast the classes? local support counts to compute its global counts 5. LLi1 = locally prune CGi1 and keep only the locally large 1-pattern rules  (P? c) is locally large at Si if n ccntPccnti )()( ??  6: Exchange LLi1 to collect the candidates? global support 7: GLi1 = ORD-Pruning (LLi1)                              // GLi1 is the gl-large 1-pattern set  8: Broadcast GLi1; Find ? n  x xGLGL   ? ?  9: SCT = Clean IST and set the guiding information bits 10: Form and add rules (from GL1) to R that satisfy min-interestingness ?  11: l=2; for x = 1 to n CGx2 = CandidateGen(GLx1); ? n  x xCGCG   ? ?  12: while CGl is not empty 13:  Count the local support (using SCT) of CGl patterns 14:  LLil = locally prune CGil and keep only the locally large l-patterns at Si 15:  Exchange LLil to collect the candidates? global support 16: GLil = ORD-Pruning(LLil)                      // GLil is the gl-large l-pattern set  17: Broadcast GLil ; Find ? n  x xll GLGL  1? ?  18: Form and add rules (from GLl) to R that satisfy min-interestingness ?  19:  l++; for x = 1 to n CGxl = CandidateGen(GLxl) ; ? n  x xll CGCG  1? ?  end while 20: return the rule set R  Figure 3.  Na?ve Distributed/Parallel ORD Algorithm  Figure 4. Efficient Distributed/Parallel ORD Algorithm     TABLE I. DATASETS  Dataset Iris Breast Cancer  Anneal Car Evaluation  Abalone  # records 150 699 798 1728 4177  # attributes 4 10 38 6 8  # classes 3 2 6 4 29  TABLE II. AVERAGE NUMBER OF RULES  (a) n = 2 min recall  Iris N Iris E Abal N  Abal E  Total N Total E reduction (%)  0.1 46.5 38.8 2056 1349 2470.3 1953.4 20.92458  0.2 35.2 25.5 749 439 1408.2 1091.9 22.4613  0.3 31.7 20.9 425 267 1077.6 691.4 35.8389  0.4 27.2 15.5 374 146 892.4 496.1 44.40834  0.5 26 14.3 344 108 451.6 267.9 40.67759  (b) n = 4 min recall  Anne.

N  Anne.

E  Car N Car E  Abal.

N  Abal. E reduction (%)  0.1 879.2 832.1 365.5 209.

2001 1607 20.54372  0.2 578.8 534.8 114.8 74.3 590 389 30.04637  0.3 450 412.1 72.8 53.7 381 125 28.74936  0.4 358.8 310 48.7 38.8 338 147 33.88095  0.5 293.7 254.8 45.8 37 328 140 20.91444  TABLE III. TOTAL MESSAGES SIZE  (a) n = 2 min recall  Iris N Iris E Abal.

N  Abal.

E  Total N  Total E reduction (%)  0.1 245 120 20945 16445 28703 23995 16.40102  0.2 158 70 11693 8289 18148 13653 24.76844  0.3 155 59 9415 5891 15310 8170 46.63571  0.4 129 47 9641 3491 13078 5430 58.47887  0.5 129 47 8971 2281 3253 2248 30.90445

VI. CONCLUSION AND FUTURE WORK In this paper, we proposed and studied an efficient and  effective distributed/parallel extension of the optimal rule discovery, ORD, algorithm. We assumed a horizontally partitioned dataset and a message passing communication model. We considered a single class as a consequence but the algorithm can be easily applied for rules with a pattern as the consequence.

We theoretically proofed a relation between locally large and globally large patterns that is used for local pruning at each  site to reduce the searched candidates.  We derived a locally large threshold using a globally set minimum recall threshold.

Local pruning achieves a reduction in the number of searched candidates and this reduction has a proportional impact on the reduction of exchanged messages. The performance study has demonstrated that EDP-ORD generates a much smaller set of candidate sets and requires significantly smaller amount of messages when compared to a na?ve extension NDP-ORD.

This shows that EDP-ORD is a scalable distributed efficient and effective technique for ORD in large databases.

We implemented only local pruning, however we discussed an upper-bound pruning that can help in achieving further reduction. Future extensions include studying upper-bound and polling-site pruning [9], and extending the algorithm in case of vertically partitioned data set. In addition, we are interested in studying robust rule-based classifiers [15] and privacy issues in data mining.

