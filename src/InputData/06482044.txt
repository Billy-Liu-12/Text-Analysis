A Dynamic Load Balancing Strategy for generating  Association Rule Mining under a Grid Environment

Abstract? the parallel and distributed systems represent one of the important solutions proposed to ameliorate the performance of the sequential association rule mining algorithms. However, parallelization and distribution process is not trivial and still facing many problems of synchronization, communication and workload balancing. In this paper we limited our study to the workload balancing problem. In this paper we propose a dynamic load balancing strategy of association rule mining algorithm under an environment of a grid. This strategy is built upon a hierarchical grid model with three levels ? Super Coordinator, Coordinator, processing nodes ?. The main objective of our strategy is to reduce the complexity of the distributed association rule mining algorithms.

Keywords? Association rule mining, Load balancing, Grid computer, APRIORI algorithm

I.  INTRODUCTION The fast growing of collect and storage data technologies  has far exceeded our human ability for comprehension without powerful tools of Data Mining. Different techniques of data mining are widely used in several domains to analyze and extract useful knowledge.

Association rule technique is one of the most important data mining techniques. In the literature, we found many sequential association rule mining algorithms. Unfortunately, almost of this sequential association rule algorithms suffer from a high computational complexity which derives from the size and the distribution of the enormous data set.

Grid computing is recently regarded as one of the interesting platforms for data and computation intensive applications like Data Mining. That is why implementation association rule mining algorithms under such environment seems to be promising.

The parallel and distributed algorithms caused many problems of synchronization, communication and workload balancing. We limit our work to the workload balancing problem, which consists of distributing tasks and data to different sites in order to have nearly the same workload in everyone.

During the implementation of parallel or distributed algorithms, the resources can be used in a bad way. Many load  balancing algorithms are proposed using two methods, static (before execution) and dynamic (during the execution).

The load balancing problem becomes more complex in a grid than in a traditional distributed system. The distributed systems assure the stability and the homogeneity of resources better then a grid environment which the apparition and the desperation of the resources can be fast and abrupt in the same time.

In this paper we propose a dynamic load balancing algorithm applied to the association rule algorithm ?APRIORI? under an environment of a grid. The rest of the paper is organized as follows: section2 describes the existed distributed association rule mining algorithms, section3 develops some load balancing algorithms applied to some distributed association rule algorithms, and in section4 we define our dynamic load balancing strategy. Experimental results obtained from implementing this strategy are shown in section5. Finally, we conclude this paper with some perspectives of our work. .



II. DISTRIBUTED ASSOCIATION RULE MINING ALGORITHMS The association rule is one of the interesting techniques of  data mining that has attracted the attention of many researchers. This technique permits to find intelligible rules trough an amount set of data.

Considering the transactional database D, an association rule has the form X => Y, where X and Y are two itemsets and  X Y=?. The support?s rule is the probability of the apparition of the two itemsets X and Y in the same transaction.

The confidence of the rule is the conditional probability that a transaction contains Y given that it contains X.

An item is the number of the apparition of a database?s attribute; this item is frequent if its support is higher than or equal to a pre-determined minimum support. A rule is strong if its confidence is greater than or equal to a user specified minimum confidence.

The extraction of the association rule mining follows two steps: (1) the first step consists of finding all frequent itemsets that occur at least as frequently at the fixed minimum support and different approaches are proposed: (a) All item sets  Technologies of Information and Telecommunications (SETIT)     generation: APRIORI [2], DIC [4], APRIORI TID [2]?,  (b) Maximum item set generation: Max Miner [3], Max Clique [11], Max Eclat [11]?. , (c) Closed item set generation: Close [13], Closet[14], Clomaint[8]? (2) The second step consists of generating strong rules from these frequent itemsets.

It is true that association rule mining algorithm has a simple statement, but the first step is computationally intensive because of the phenomenal number of generated itemsets [6]. Many sequential algorithms for finding large itemsets have been proposed in the literature and most of them use ? APRIORI ? as fundamental algorithm [2].

Parallelism of sequential itemsets generating algorithms can play an important role in improving the execution time.

This kind of algorithms follows two main paradigms of parallelism: (1) Data repartition and (2) Tasks repartition.

Many parallel algorithms for finding itemsets have been proposed in [12] and we can find the pioneers ones: Count Distribution CD [1], Data Distribution (DD) [1], Hybrid Distribution (HD) [1]?.



III. LOAD BALANCING PROBLEM FOR PARALLEL ASSOCIATION RULE MINING ALGORITHMS  In general, Work load balancing is the assignment of work to processors in a way that maximizes application performance.  In this part we cite some of algorithms of load balancing for parallel association rule algorithms.

In [9] the IDD algorithm is an amelioration of the Data Distribution algorithm (DD) which is a parallelization of the Apriori algorithm. This algorithm solve the communication model problems of the DD algorithm that use an all-to-all communication, by using an virtual circle topology of processors to ameliorate the performance and to reduce the communication?s costs, which is based on an asynchrony communication pear to pear between neighbors of the topology. Each processor disposes of two tampons: SBuf to send the data and RBuf to receive the data. Each processor initiate an synchronic operation of sending data to its right neighbor using SBuf, and an synchronic operation of receiving data from the left neighbor using RBuf. During these operations, each processor owns the transactions in the SBuf and calculates the assigned candidate?s support.

The type of the load balancing in this algorithm is static and is limited to the candidate?s partition.  For this, we calculate for each item the number of candidates itemsets where the item is the prefix. After, in a system of p processors, the algorithm distributes equitably in p parts the prefix itemsets. Then, each processor generates locally and stores its itemsets. In this approach, when the number of the candidate?s itemsets beginning with the same item accedes a threshold value, it will be very difficult to have equitable repartitions. To solve this problem the second candidate item is considered in the partitions.

The IDD algorithm can?t guaranty a good load balancing by assigning the same number of candidates to all the  processors. In fact, the prefix items that are assigned to each processor and which have a higher support can receive more requests of calculation than the others. This generates an unbalance that can increase considerably when the number of processors is very higher comparing to the number of item sets.

The LFP-Tree algorithm [10] is a load balancing algorithm applied to the PFP-Tree algorithm (Parallel FP-tree) [15] which is an amelioration of the FP-Growth algorithm [7].

The type of load balancing used in the LPFP-Tree algorithm is dynamic. The strategy used in LPF-Growth algorithm follows an equitable repartition of the FP-Tree structure over different nodes. For this, an FP-Tree branches migration strategy engenders the conditional databases migration, especially when a tree is very huge and very profound. For this, in the LFP-Tree algorithm the execution time in each node depends on the number of items in the tree.

The load is calculated for each item using a formula based on the depth (Lj). Each processor sends its local load information to the coordinator node in order to detect eventual unbalancing case. The suppression of the redundant braches of the structure by regrouping in one node reduces the memory space storage. Otherwise, the experimental results show that the value of threshold depth influences on the algorithm performances. In fact, when the threshold depth is lower, an important number of small conditional databases must be stored, this increases the work load; and when the threshold depth is higher, the load node is not balanced.



IV. PROPOSED GRID MODEL A In our study we model a grid as a set of n sites (clusters)  managed by a super coordinator. Each site owns a set of worker nodes and a coordinator node.

The super coordinator assures the following functions:  ? Initial distribution of the global database to each site of the grid;  ? Collection of the state load information from all the coordinators site;  The coordinator of each site assures the following operations:  ? Collect the local state load information from the worker?s coordinator nodes;  ? Calculate and send the global load to the super coordinator of the grid;  ? Decide of the transaction?s migration and/ or the candidate?s migration :  o Candidate?s migration: in intra-site (locally) transfer the candidates from the up loaded node to the under loaded node.

o Transaction?s migration: in inter-site (globally) when all the site nodes are overloaded then we decide to transfer a part of the transaction?s     partition to another site respecting the following conditions:  ? The less loaded site;  ? The nearest site with a least cost of communication.

The worker nodes assure the following operations:  ? Maintain their local load information;  ? Send their local load information to their coordinator;  ? Execute the load balancing decision plan sent by their coordinator.

Figure 1.  PROPOSED GRID MODEL  Notations: G= (S1, S2, S3? Sn)  represents the set of the sites of the grid G.

Si= (NNi, CNi, Memi, Stori, Bandi, Pi) represents the parameters of the site Si; With:  NNi: number of nodes in the site Si.

CNi: coordinator of the site Si.

Memi: total memory size of the site Si.

Stori: storage capacity of the site Si.

Bandi: bandwidth of the site Si.

Pi= (N, M) represents parameters of the partition i of the site Si; With: N: number of items.

M: number of transactions.

A. Load estimation In our approach, we define three load states: under loaded,  medium loaded, up loaded.  In addition, we assign a numeric value to each state as follows:  Under loaded (1): the grid resource is inactive or down loaded.

Medium loaded (2): the grid resource is midway loaded.

Up loaded (3): the grid resource is overloaded.

According to the proposed grid model, we define the load state over three levels: worker nodes, coordinator nodes and super coordinator.

Worker nodes: the node load is calculated following the  length of the file (size n); this file contains the candidate?s itemset. For this, we define two thresholds (low and high) and we distinguish three cases:  Case1: If file= not empty and n <= low then load= 1 Case2: If file= not empty and low<n<high then load= 2 Case3: If file= not empty and n>=high then load= 3  Coordinators: the site load is calculated as the average of the state load information sent by all the workers nodes of the site i. We distinguish the following cases:  Case1: If 1 =< average <= 1.5 then load= 1 Case2: If 1.5 < average < 3 then load= 2 Case3: If average =3 then load= 3  Super coordinator: the grid load is estimated as the average of the state load information collected from each coordinator site. We distinguish there cases:  Case1: If 1 =< average <= 1.5 then load= 1 Case2: If 1.5 < average < 3 then load= 2 Case3: If average =3 then load= 3   B. Proposed strategy The associative rule mining algorithms are characterized by  their dynamic nature. In fact, this kind of algorithms has a workload that is unpredictable during the computation, which is due to the high degree of correlation between itemsets generated at each iteration. Hence, an unbalance workload is detected. To correct this unbalance, we choose to develop a dynamic load balancing strategy based on the extraction frequent itemset algorithm APRIORI.

According to the proposed grid model, we distinguish two cases: intra-site load balancing (between the worker nodes of the same site) and inter-site load balancing (between the grid sites).

1) Intra-Site load balancing: Consists of transfer the candidates from an overloaded node to another site less loaded, respecting the following constraint:  Load i,k > Load j,k + CCN i,j,k                             (1)  With: Load i,k: the estimated load of the source node i of the site k.

Load j,k: the estimated load of the target node j of the site k.

CCN i,j,k: the communication cost between the node i and the node j of the same site k.

2) Inter-Site load balancing: when all the nodes of a site are overloaded, we decide to transfer a part of the transaction?s partition, that contribute in the calculation of the candidate?s support (the transactions that contain the candidate?s item) to another site less loaded and with a less communication cost.

Load i,k > Load j,p + CCS k,p                               (2)  With:     Load i,k : the estimated load of the source node i of the site k.

Load j, p: the estimated load of the target node of the site p.

CCS k,p: the communication cost between the site k and the site p.

Otherwise the cost of the intra-site transfer is less  important than the cost of the intra-site transfer communication, that?s why we privilege the local load balancing to the global load balancing.

C. Load balancing strategy Our strategy follows two global phases: initialization phase  and execution phase.

1) Initialization phase (Before the execution) ? The global transaction?s data base is partitioned equitably  by the super coordinator over all the grid sites, by dividing the number of the transactions by the number of the grid site.

? Determination and duplication of the candidates 1-itemset over all the grid sites.

? Each coordinator site partitioned the 1-itemsets candidates over their worker nodes, by dividing the total number of the candidates by the total number of the worker nodes.

Each candidate is stored in the file of the worker node.

? Initialization of the load to the value 1(under loaded) for all the grid nodes.

2) Execution phase (During the execution)  Repeat  Each node: ? Calculates the k-itemsets candidate?s support from the  portioned transactional database.

? Sends the result of the calculated k-itemset?s support to  his coordinator.

Each coordinator: ? Sends the candidates k-itemsets support to the super  coordinator.

The super coordinator: ? Determines the frequent k-itemsets (support > min  support).

? Generates then duplicates the k-itemsets candidates over  all the sites.

Until all itemsets founded.

In parallel; The following operations are invoked during the generation of the candidates: ? Each node sends his local load information to his  coordinator.

? Each coordinator updates then sends the load vector of his  worker nodes to the super coordinator.

? The super coordinator is responsible of the detection of  the eventual load unbalancing cases  according to the following algorithm :  o Calculation of the load average of each site.

o For each site verifier the following conditions : If a site is up loaded (load=3) then If exists another site less loaded with a minimal communication cost then transaction?s migration.

Else (the site is not overloaded) If a node is overloaded (load=3) then If exists another node of the same site less loaded with a minimal communication cost then Candidate?s migration.



V. EXPERIMENTATIONS We evaluate the performances of our strategy by using  the grid simulator ? Gridsimtoolkit-4.2 ? [BUM 02] under the operating system ? Windows XP SP2 ?. In addition, for the generation of the frequent itemsets, we build a database that contains 6 items and 50000 transactions.

First, we implement a paralleled version of the algorithm APRIORI without load balancing. For this, we realize different experimentations, using several parameters (#items, #transactions and Min support), shown in table 1.

Table 1: parameter?s configuration   Experimentation 1:  In this case, we consider a topology of: 1 Super Coordinator, 3 sites and 6 nodes, using the different parameter?s configuration shown in table 1. The obtained experimentations are represented in the following graphs.

Figure 2.  GTDB (6 items and 10000 transactions)  Global Transactional Data Base MIN SUP  #Items #Transactions 6 10000 10, 20, 30, 40 6 25000 10, 20, 30, 40 6 50000 10, 20, 30, 40      Figure 3.  GTDB (6 items and 25000 transactions)     Figure 4.  GTDB (6 items and 50000 transactions)  Experimentation 2: In this second case, we consider a topology of:  1 Super Coordinator, 4 sites and 8 nodes, using the same parameter?s configuration.

The obtained experimentations are represented in the following graphs.

Figure 5.  GTDB (6 items and 10000 transactions)     Figure 6.  GTDB (6 items and 25000 transactions)     Figure 7.  GTDB (6 items and 50000 transactions)

VI. CONCLUSION In this paper, we presented the distributed data mining  generalities, and then we detailed the technique of association rule mining. Then, we presented different strategies used in the load balancing. Then, we defined our load balancing approach, following a hierarchical grid model with three levels ? Super Coordinator, Coordinator, Worker nodes ?.

Finally, in order to show the advantages of our strategy, we simulate our strategy by using ? GridSim ? with different experimentations and manipulating different parameters (the minimal support, the number of transactions, the number of sites, and the number of nodes??). The results obtained showed the reduction of the execution time of the extraction of the associative rule mining.

Our work offer many research perspectives, that is why we present the most interesting:  ? Follow a policy that assures the fault tolerance of the nodes, especially the super coordinator node and the coordinator nodes.

? Implementation of another extraction itemsets approach like the close frequent items.

? Implementation of our strategy in a reel grid.

