

Published by the IEEE Computer Society  Big Universe, Big Data: Machine Learning and Image Analysis for Astronomy Jan Kremer, Kristoffer Stensbo-Smidt, Fabian Gieseke, Kim Steenstrup Pedersen, and Christian Igel, University of Copenhagen  Modern astronomy  requires big data  know-how, in  particular, highly  efficient machine  learning and image  analysis algorithms.

But scalability is not  the only challenge:  astronomy applications  touch several current  machine learning  research questions.

will provide far greater data volumes. Another promising future survey is the Large Synop- tic Survey Telescope (LSST), which will de- liver wide-field images of the sky, exposing galaxies that are too faint to be seen today.

A main objective of the LSST is to discover transients, objects that change brightness over timescales of seconds to months. These changes are due to a plethora of reasons, some of which might be regarded as unin- teresting while others will be extremely rare events that can?t be missed. The LSST is ex- pected to see millions of transients per night that need to be detected in real time to allow for follow-up observations. With a stagger- ing 30 Tbytes of images being produced per night, efficient and accurate detection will be  a major challenge. Figure 1 shows how data rates have increased and will continue to in- crease as new surveys are initiated.

What do the data look like? Surveys usu- ally make either spectroscopic or photometric observations (Figure 2). Spectroscopy mea- sures the photon count at thousands of wave- lengths, and the resulting spectrum allows for identifying chemical components of the ob- served object and thus enables determining many interesting properties. Photometry takes images using a charge-coupled de- vice (CCD), typically acquired through only a handful of broadband filters, making photom- etry much less informative than spectroscopy.

Although spectroscopy provides measure- ments of high precision, it has two drawbacks: it  One of the largest astronomical surveys to date is the Sloan Digital Sky Survey (SDSS; www.sdss.org). Each night, the SDSS telescope produces 200 Gbytes of data, and to this day close to a million field images have been acquired, in which more  than 200 million galaxies, and even more stars, have been detected. Upcoming surveys  B i g  D a t a    March/aprIL 2017 www.computer.org/intelligent 17  isn?t as sensitive as photometry, meaning that distant or otherwise faint objects can?t be measured, and only a few objects can be captured at the same time, making it more expensive than photometry, which allows for acquir- ing images of thousands of objects in a single image. Photometry can capture objects that might be 10 times fainter than what can be measured with spec- troscopy. A faint galaxy is often more distant than a bright one?not just in space but also in time. Discovering faint objects therefore offers the potential of looking further back into the history of the universe, over timescales of billions of years. Thus, photometric observations are invaluable to cosmologists, as they help in understanding the early universe.

Once raw observations have been acquired, a pipeline of algorithms needs to extract information from them. Much of image-based astron- omy currently relies to some extent on visual inspection. A wide range of measurements are still carried out by humans but need to be addressed by automatic image analysis in light of growing data volumes?examples include 3D orientation and chiral- ity of galaxies, and the detection of large-scale features, such as jets and streams. Challenges in these tasks include image artifacts, spurious ef- fects, and discerning between merg- ing galaxy pairs and galaxies that happen to overlap along the line of sight. Current survey pipelines of- ten have trouble correctly identifying these types of problems, which then propagate into the databases.

A particular challenge is that cos- mology relies on scientific analyses of long-exposure images. As such, the in- terest in image analysis techniques for preprocessing and de-noising is natu- rally great. This is particularly impor- tant for the detection of faint objects with very low signal-to-noise ratios.

Automatic object detection is vital  to any survey pipeline, with reliabil- ity and completeness being essential metrics. Completeness refers to the amount of detected objects, whereas reliability measures how many of the detections are actual objects. Max- imizing these metrics requires ad- vanced image analysis and machine learning techniques. Data science for astronomy is a quickly evolving field gaining more and more interest.

Large-Scale Data Analysis in Astronomy Machine learning methods can un- cover the relation between input data (galaxy images) and outputs (physical properties of galaxies) based on input- output samples, and they?ve already proved successful in various astro- physical contexts. For example, Daniel Mortlock and colleagues1 use Bayesian analysis to find the most distant quasar  Figure 2. The spectrum of galaxy NGC 5750 (black line), as seen by the SDSS, with the survey?s five photometric broadband filters u, g, r, i, and z, ranging from ultraviolet (u) to near-infrared (z). For each band, the galaxy?s brightness is captured in an image.

u g r i z  3,000 4,000 5,000 6,000 7,000 8,000 9,000 10,000 11,000         No rm  al ize  d flu  x  Fi lte  r r es  po ns  e   Wavelength (Angstroms)  0.5  0.4  0.3  0.2  0.1  Figure 1. Increasing data volumes of existing and upcoming telescopes: Very Large Telescope (VLT), Sloan Digital Sky Survey (SDSS), Visible and Infrared Telescope for Astronomy (VISTA), Large Synoptic Survey Telescope (LSST), and Thirty Meter Telescope (TMT).

Da ta  ra te  (b yt  es /n  ig ht  )        VLT (1998)  SDSS (2000)  VISTA (2009)  LSST (2019)  TMT (2022)  90 TB  30 TB  315 GB 200 GB  10 GB    18  www.computer.org/intelligent IEEE INTELLIGENT SYSTEMS  B i g  D a t a  to date. These extremely bright objects form at the center of large galaxies and are very rare. Bayesian comparison has helped scientists select a few most likely objects for re-observation from thousands of candidates.

In astronomy, distances from Earth to galaxies are measured by their redshifts, but accurate estimations require expensive spectroscopy. Get- ting accurate redshifts from photom- etry alone is an essential but unsolved task for which machine learning methods are widely applied.2 How- ever, they?re far from being on a par with spectroscopy.

Another application is the measure- ment of galaxy morphologies. Usu- ally, we assign a galaxy a class based on its appearance (Figure 3), tradi- tionally via visual inspection. Lately, this has been accelerated by the cit- izen science project Galaxy Zoo,3 which aims to involve the public in classifying galaxies. Volunteers have contributed more than 100 million classifications, which allow astro- physicists to look for links between galaxies? appearances (morphology) and internal and external proper- ties. Several discoveries have been made through the use of data from  Galaxy Zoo, and the classifications have provided numerous hints to the correlations between various pro- cesses governing galaxy evolution. A galaxy?s morphology is difficult to quantize in a concise manner, and automated methods are high on the wish list of astrophysicists. There ex- ists some work on reproducing the classifications using machine learn- ing alone,4 but better systems will be necessary when dealing with the data products of next-generation telescopes.

A growing subfield in astrophysics is the search for planets outside our solar system (exoplanets). NASA?s Kepler spacecraft has been searching for exoplanets since 2009, observing light curves of stars?that is, measur- ing a star?s brightness at regular in- tervals; the task is then to look for changes in the brightness, indicating that a planet might have moved in front of it. If this happens with reg- ular duration and decrease in bright- ness, the source is likely to be an exoplanet. While automated software can detect such changes in bright- ness, the citizen science project Planet Hunters has shown that the software does miss some exoplanets. Also, de-  tecting Earth-sized planets, arguably the most interesting, is notoriously difficult, as the decrease in bright- ness can be close to the noise level.

For next-generation space telescopes, such as the Transiting Exoplanet Sur- vey Satellite (TESS), scheduled to launch in 2017, algorithms for de- tecting exoplanets need to be signifi- cantly improved to more reliably detect Earth-sized exoplanet candi- dates for follow-up observations.

There are also problems that could directly affect our lives here on Earth, such as solar eruptions that, if headed toward Earth, can be dan- gerous to astronauts, damage satel- lites, affect airplanes, and, if strong enough, cause severe damage to elec- trical grids. Several spacecraft moni- tor the sun in real time to watch for these flares, and while the ultimate goal is a better understanding of the sun, the main reason is to be able to quickly detect and respond to solar eruptions. The continuous monitor- ing is done by automated software, but not all events are detected.5 Solar eruptions are known to be associated with sunspots, but the connection isn?t understood well enough that sci- entists can predict the onset or mag- nitude of an eruption. There could be a correlation with the complexity of the sunspots, and understanding this, as well as how the complex- ity develops over time, is crucial for future warning systems. While sci- entists are working toward a solu- tion, for example, through the citizen science project Sunspotter (https:// www.sunspotter.org), no automated method has yet been able to reli- ably and quantitatively measure the complexity.

This glimpse of success stories and open problems is by no means ex- haustive; a much fuller overview of machine learning in astronomy ap- pears elsewhere.6  Figure 3. An example of two morphology categories: (a) the spiral galaxy M101 (credit: NASA, European Space Agency (ESA), K. Kuntz (Johns Hopkins University), F. Bresolin (University of Hawaii), J. Trauger (Jet Propulsion Lab), J. Mould (National Optical Astronomy Observatory), Y.-H. Chu (University of Illinois, Urbana), and Space Telescope Science Institute (STScI)), and (b) the elliptical galaxy NGC 1132 (credit: NASA, ESA, and the Hubble Heritage Team (STScI/Association of Universities for Research in Astronomy (AURA))-ESA/Hubble Collaboration).

(a) (b)    March/aprIL 2017 www.computer.org/intelligent 19  Astronomy Driving Data Science Three examples from our own work show how astronomical data analysis can trigger methodological advance- ments in machine learning and image analysis.

Describing the Shape of a Galaxy Image analysis doesn?t only allow for automatic classification?it can also inspire new ways to look at morphol- ogy.7,8 For instance, we?ve examined how well one of the most fundamen- tal measures of galaxy evolution, the star-formation rate, could be pre- dicted from the shape index, which measures the local structure around a pixel going from dark blobs over valley-, saddle point-, and ridge-like structures to white blobs. It can thus be used as a measure of the local mor- phology on a per-pixel scale (Figure 4).

The study showed that the shape in- dex does indeed capture some funda- mental information about galaxies, which is missed by traditional meth- ods. Adding shape index features re- sulted in a 12 percent decrease in root-mean-square error (RMSE).

Dealing with Sample Selection Bias In supervised machine learning, mod- els are constructed based on labeled examples?that is, observations (im- ages, photometric features) together with their outputs (also referred to as labels, such as the corresponding red- shift or galaxy type). Most machine learning algorithms are built on the assumption that training and future test data will follow the same distri- bution, which allows for generaliza- tion, enabling the model built from labeled examples in the training set to accurately predict target variables in an unlabeled test set. In real-life ap- plications, this assumption is often violated in what we refer to as sample  selection bias. Certain examples are more likely to be labeled than oth- ers due to factors such as availability or acquisition cost regardless of their representation in the population.

Sample selection bias can be very pro- nounced in astronomical data,9 and machine learning methods have to address this bias to achieve good gen- eralization. Often, we only initially have training datasets from old sur- veys, while upcoming missions will probe never-before-seen regions in the astrophysical parameter space.

To correct the sample selection bias, we can resort to a technique called importance-weighting. The idea is to give more weight to exam- ples in the training sample that lie in regions of the feature space underrep- resented in the test sample and, like- wise, give less weights to examples whose location in the feature space is overrepresented in the test set. If these weights are estimated correctly, the model we learn from the training data is an unbiased estimate of the model we would learn from a sample that follows the population?s distribu-  tion. The challenge lies in estimating these weights reliably and efficiently.

Given a sufficiently large sample, a simple strategy can be followed: using a nearest neighbor-based approach, we can count the number of test ex- amples that fall within a hypersphere whose radius is defined by the dis- tance to the Kth neighbor of a train- ing example. The weight is then the ratio of the number of these test ex- amples over K. This flexibly handles regions that are sparse in the train- ing sample. In the case of redshift estimation, we could alleviate a selec- tion bias by utilizing a large sample of photometric observations to deter- mine the weights for the spectroscop- ically confirmed training set.10  To measure how well we approxi- mated the true weight, we used the squared difference between true and estimated weight, that is,  L x x p x x, ? ? d , x S   train  train  ?? ? ? ?( ) ( )( ) ( ) ( )= ? ?  where Strain is the training sample, b and ??  are true and estimated weight,  Figure 4. Shape index. From left to right, the original image of a galaxy merger, the scale-space representation of the galaxies, the curvedness (a measure of how pronounced the local structure is), the shape index, and finally the shape index weighted by the curvedness. The shape index is defined as ?? ??(( ))(( )) == ??S x y? , ; 2 ?tan 1  (( )) (( ))?? ?? ++ ???? ????  ??  ???? L L L L L4xx yy xy xx yy  2 2 , where ?? (( ))(( )) == ?? ?? ??(( ))++L x y I G x y, ; *x y n m n mn m x y, ;??(( )) is the scale space representation of the image I, G is a Gaussian filter, and s  is the scale. The curvedness is defined as ?? ??(( ))(( )) == ++ ++C x y L L L, ; 1 2 2xx xy yy2 2 2 2 .

The image shows the Antennae galaxies as seen by the Hubble Space Telescope (credit: NASA, ESA, and the Hubble Heritage Team (STScI/AURA)-ESA/Hubble Collaboration).

20  www.computer.org/intelligent IEEE INTELLIGENT SYSTEMS  B i g  D a t a  respectively, and ptrain is the training density. The nearest-neighbor estima- tor achieved similar or lower error compared to other methods. At the same time, the estimator?s running time is three orders of magnitude lower than the best competitor for lower sample sizes. Furthermore, it can scale up to millions of examples (code is available at https://github.

com/kremerj/nnratio).

Scaling-Up Nearest-Neighbor Search Nearest-neighbor methods are not only useful for addressing sample se- lection bias, they also provide excel- lent prediction results in astrophysics and cosmology?for example, they?re used to generate candidates for qua- sars at high redshift.11 Such meth- ods work particularly well when the number of training examples is high and the input space is low-di- mensional, making them a good choice for analyzing large sky sur- veys in which objects are described  by photometric features (such as the five broadband filters in Figure 2).

However, searching for nearest neigh- bors becomes a computational bottle- neck in big data settings.

To compute nearest neighbors for a given query, search structures such as k-d trees are an established way to ac- celerate the search. If input space di- mensionality is moderate (say, below 30), runtime can often be reduced by several orders of magnitude.

While approximate schemes are valuable alternatives, we?re usually in- terested in an exact nearest-neighbor search for astronomical data. In this context, massively parallel devices, such as GPUs, show great prom- ise. Unfortunately, nearest-neighbor search based on spatial data struc- tures can?t be parallelized in an ob- vious way for these devices. To this end, we developed a new tree struc- ture that?s more amenable to mas- sively parallel traversals via GPUs (Figure 5).12,13 The framework can achieve a significant runtime reduc-  tion at a much lower cost compared to traditional parallel architectures (code available at http://bufferkdtree.

readthedocs.io). We expect such scal- able approaches to be crucial for up- coming data-intensive analyses in astronomy.

Physical versus Machine Learning Models A big concern data scientists meet when bringing forward data-driven machine learning models in astro- physics and cosmology is the lack of interpretability. There are two differ- ent approaches to predictive model- ing in astronomy: physical modeling and data-driven modeling. Building physical models, which can incorpo- rate all necessary astrophysical back- ground knowledge, is the traditional approach. These models can be used for prediction, for example, by run- ning Monte Carlo simulations. Ide- ally, this approach ensures that the predictions are physically plausible.

In contrast, extrapolations by purely  Figure 5. Nearest-neighbor searching. (a) The buffer k-d tree structure depicts an extension of classical k-d trees and can be used to efficiently process huge amounts of nearest-neighbor queries using GPUs. (b) Runtime comparison given a large-scale astronomical dataset with n training and m test examples. The speedup of the buffer k-d tree approach using four GPUs over two competitors (brute force on GPUs and a multicore k-d tree-based traversal using four cores/eight hardware threads) is shown as solid black lines.12,13  leaf structure  buffers  top tree (device)  (host) (host)  (device)  (host)   2E6 4E6 6E6 8E6 10E6  Ru nt  im e  (s )  Ru nt  im e  (s )  Ru nt  im e  (s )  sp ee  d- up  m 4E6 8E6 12E6 16E6 20E6  m  8E6 16E6 24E6 32E6 40E6  m  bufferkdtree(4) brute(4)  kdtree(8)  n = 2?106 n = 4?106  n = 8?106    1,000  1,500  2,000  2,500   sp ee  d- up  bufferkdtree(4) brute(4)  kdtree(8)  2,000 4,000 6,000 8,000  10,000 12,000   sp ee  d- up  bufferkdtree(4) brute(4)  kdtree(8)    March/aprIL 2017 www.computer.org/intelligent 21  data-driven machine learning models could violate physical laws. Another decisive feature of physical models is that they allow for understanding and explaining observations. This in- terpretability of predictions typically isn?t provided when using a machine learning approach.

Physical models have the draw- backs that they?re difficult to con- struct and that inference can take a long time (such as in the case of Monte Carlo simulations). Most im- portantly, the quality of the predic- tions depends on the quality of the physical model, which is typically limited by necessary simplifications and incomplete scientific knowledge.

In our experience, data-driven mod- els typically outperform physical models in terms of prediction accu- racy. For example, a simple k near- est-neighbors model can reduce the RMSE by 22 percent when estimat- ing star formation rates.14,15 Thus, we strongly advocate data-driven models when accurate predictions are the main objective. And this is in- deed often the case if, for example, we want to estimate properties of ob- jects in the sky to quickly identifying observations worth a follow-up in- vestigation or to conduct large-scale statistical analyses.

Generic machine learning meth- ods aren?t meant to replace physical modeling because they typically don?t provide scientific insights beyond the predicted values. Still, we argue that if prediction accuracy is what matters, we should favor the more accurate model, whether it?s interpretable or not. While the black-and-white por- trayal of the two approaches might help illustrate common misunder- standings between data scientists and physicists, it is of course shortsighted.

Physical and machine learning model- ing aren?t mutually exclusive: physical models can inform machine learning  algorithms, and machine learning can support physical modeling. A simple example of the latter is using machine learning to estimate error residuals in a physical model.7  Dealing with uncertainties is a ma- jor issue in astronomical data analysis.

Data scientists are asked to provide error bars for their predictions and to think about how to deal with in- put noise. In astronomy, both input and output data have (non-Gaussian) errors attached to them. Often, these measurement errors have been quanti- fied (such as by incorporating weather conditions during observation), and it?s desirable to consider these errors in the prediction. Bayesian modeling and Monte Carlo methods simulat- ing physical models offer solutions, but they don?t often scale for big data.

Alternatively, we can modify machine learning methods to process error bars, as attempted for nearest-neighbor regression by modifying the distance function.11  Getting Started on Astronomy and Big Data Most astronomical surveys make their entire data collection, including derived parameters, available online in the form of large databases, pro- viding easy entry points for computer scientists wanting to get engaged in astronomical research.

The Galaxy Zoo website (https:// www.galaxyzoo.org) provides data with classifications of approximately 1 million galaxies. It?s an excellent resource for developing and testing image analysis and computer vision algorithms for automatic classifica- tions of galaxies.

Much of the Kepler data for exo- planet discovery is publicly available through the Mikulski Archive for Space Telescopes (http://archive.stsci.

edu/kepler). These include light curves for confirmed exoplanets and false  positives, making it a valuable dataset for testing detection algorithms.

Having been monitored continuously for years, there?s an incredible amount of imaging data for the sun, from ar- chival data to near real-time images.

One place to find such information is the Debrecen Sunspot Data archive (http://fenyi.solarobs.unideb.hu/ESA/ HMIDD.html). These images allow for the development and testing of new complexity measures for image data or solar eruption warning systems.

Within the next few years, im-age analysis and machine learning systems that can process terabytes of data in near real time with high accuracy will be essential.

There are great opportunities for making novel discoveries, even in da- tabases that have been available for de- cades. The volunteers of Galaxy Zoo have demonstrated this multiple times by discovering structures in SDSS im- ages that have later been confirmed to be new types of objects. These volun- teers aren?t trained scientists, yet they make new scientific discoveries.

Even today, only a fraction of the images of SDSS have been inspected by humans. Without doubt, the data still hold many surprises, and upcom- ing surveys, such as LSST, are bound to image previously unknown objects.

It won?t be possible to manually in- spect all images produced by these surveys, making advanced image anal- ysis and machine learning algorithms of vital importance. Researchers could use these systems to answer questions such as how many types of galaxies there are, what distinguishes the dif- ferent classes, whether the current classification scheme is good enough, and whether there are important sub- classes or undiscovered classes. These questions require data science knowl- edge?rather than astrophysical knowledge,    22  www.computer.org/intelligent IEEE INTELLIGENT SYSTEMS  B i g  D a t a  yet the discoveries will still help astro- physics tremendously.

In this new data-rich era, astron- omy and computer science can bene- fit greatly from each other. There are new problems to be tackled, novel dis- coveries to be made, and above all, new knowledge to be gained in both fields.

