Result Evaluation of Transaction and

Abstract?In this paper we proposes an efficient  approach based on apriori algorithm. We use density minimum support so that we reduce the execution time.

Our approach supports the zonal minimum support, by  this approach we can store the transaction on the daily  basis, then we provide three different density zone based  on the transaction and minimum support which is low(L),Medium(M),High(H). Based on the zonal  support we categorize the item set for pruning. So our  approach is useful for pruning the data zone wise,  because the support categorization is not same in all the  places, it must be categorized by the population visitors.

So the main aim is to classify and detection  automatically density wise. Our algorithm provides the  flexibility for improved association and dynamic  support.  Comparative result shows the effectiveness   of  our algorithm.

Keywords ?  Zonal Di stri bution, Minimum   Support,  Frequent Pattern, apriori algorithm   1. INTRODUCTION    Frequent item set mining algorithms have been  investigated for a long time, such as Apriori [1], FP-  growth [2], Eclat [3], Tree-Projection [4], H-Mine  [5], DHP [6],frequent pattern analysis is also  achieved with mobile computing and grid  computing[7][8][9].

The essence of frequent item set mining is to  discover frequent subsets from a set of item set. In  our study, we propose an efficient approach to  discover frequent superset, improved association and  dynamic Minimum support. The importance of data  mining is increasing exponentially since last decade  and in recent time where there is very tough  competition in the market where the quality of  information and information on time play a very  crucial role in decision making of policy has attracted  a great deal of attention in the information industry  and in society as a whole.

In this paper we provide a different way of  analysis and evaluation based on density and zonal  minimum support. We also provide the comparison  from our technique to the previous technique and  show the effectiveness.

We provide here an overview of executing  data mining services. The rest of this paper is arranged as follows: Section 2 introduces related  work; Section 3 describes about the proposed  work; Section 4 shows the result analysis; Section 5 describes Conclusion.

2. RELATED WORK    In 2010 Ashutosh Dubey et al. [10] proposed a  novel data mining algorithm named J2ME-based  Mobile Progressive Pattern Mine (J2MPP-Mine)  for effective mobile computing. In J2MPP-Mine,  they first propose a subset finder strategy named  Subset-Finder (S-Finder) to find the possible  subsets for prune. Then, they propose a Subset  pruner algorithm (SB-Pruner) for determining the  frequent pattern. Furthermore, they proposed the  prediction strategy to determine the superset and  remove the subset which generates a less number  of sets due to different filtering pruning strategy.

Finally, through the simulation their proposed  methods were shown to deliver excellent  performance in terms of efficiency, accuracy and  applicability under various conditions.

In 2011, Avrilia Floratou et al. [11] proposed  a new algorithm called FLexible and Accurate  Motif DEtector (FLAME). FLAME is a flexible  suffix-tree-based algorithm that can be used to  find frequent patterns with a variety of definitions  of motif (pattern) models. It is also accurate, as it  always finds the pattern if it exists. Using both  real and synthetic data sets, we demonstrate that  FLAME is fast, scalable, and outperforms  existing algorithms on a variety of performance  metrics.

In 2011, Shawana Jamil et al. [12] focus on  focus on investigation of mining frequent sub-  graph patterns in DBLP uncertain graph data  IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India    using an approximation based method. The frequent  sub-graph pattern mining problem is  formalized by  using the expected support measure. Here an  approximate mining algorithm based Weighted  MUSE, is proposed to discover possible frequent sub-  graph patterns from uncertain graph data.

In 2011, Ashutosh Dubey et al. [13] propose a  novel DAM (Define Analyze Miner) Based data  mining approach for mobile computing environments.

In DAM approach, we first propose about the  environment according to the requirement and need  of the user where we define several different data  sets, then DAM analyzer accept and analyze the data  set and finally apply the appropriate mining by  computing environment or the applications which  support the DAM miner on the accepted dataset. It is  achieved by CLDC and MIDP component of J2ME.

In 2011, Ashwin C S et al. [14] proposed an  apriori- based method to include the concept of  multiple minimum supports (MMS in short) on  association rule mining. It allows user to specify  MMS to reflect the different natures of items. Since  the mining of sequential pattern may face the same  problem, we extend the traditional definition of  sequential patterns to include the concept of MMS in  this study. For efficiently discovering sequential  patterns with MMS, we develop a data structure,  named PLMS-tree, to store all necessary information  from database.

In 2011, K. Zuhtuogullari et al. [15] observe that  an extendable and improved item set generation  approach has been constructed and developed for  mining the relationships of the symptoms and  disorders in the medical databases. The algorithm of  the developed software finds the frequent illnesses  and generates association rules using Apriori  algorithm. The developed software can be usable for  large medical and health databases for constructing  association rules for disorders frequently seen in the  patient and determining the correlation of the health  disorders and symptoms observed simultaneously.

In 2012, Preeti Khare et al. [16] discusses that  importance of data mining is increasing exponentially  since last decade and in recent time where there is  very tough competition in the market where the  quality of information and information on time play a  very crucial role in decision making of policy has  attracted a great deal of attention in the information  industry and in society as a whole. They use density  minimum support so that they reduce the execution  time. A frequent superset means it contains more  transactions then the minimum support. It utilize the  concept that if the item set is not frequent but the  superset may be frequent which is consider for the  further data mining task. By this approach they can  store the transaction on the daily basis, then they  provide three different density zone based on the  transaction and minimum support which is  low(L),Medium(M),High(H). Based on this  approach they categorize the item set for pruning.

In 2012, Nikhil Jain et al. [17] discuss about  Association rule mining. They suggest that  association rule play important rule in market data  analysis and also in medical diagnosis of  correlated problem. For the generation of  association rule mining various technique are  used such as Apriori algorithm, FP-growth and  tree based algorithm. Some algorithms are wonder  performance but generate negative association  rule and also suffered from Superiority measure  problem. They proposed a multi objective  association rule mining based on genetic  algorithm and Euclidean distance formula. In this  method we find the near distance of rule set using  Euclidean distance formula and generate two  class higher class and lower class .the validate of  class check by distance weight vector.

In 2012, Ruchita Gupta et al. [18] present an  efficient range partitioning method for finding  frequent pattern from huge database. It is based  on key based division for finding the local  frequent pattern (LFP). After finding the partition  frequent pattern from the subdivided local  database, they then find the global frequent  pattern from the local database and perform the  pruning from the whole database.

In 2012, Sachin sohra et al. [19] suggest that  discover a frequent pattern of size 100, e.g., {a1,  a2, ?, a100}, one needs to generate 2100 which  is approx 1030 candidates. Candidate Test incurs  multiple scans of database: each candidate. To  remove the above drawback, they present an  improved non candidate single and multiple  association approach for mining medical  databases. The developed approach generates  association rules for determining the relationships  among the diseases observed synchronously. The  generated association rules are too significant for  making early diagnosis for the correlated diseases.

Some types of diseases can have triggering effects  on different kinds of diseases. The symptoms and  diseases which have stronger effect on each other  can be determined and interpreted .

3. PROPOSED WORK   Our proposed approach is based on apriori  algorithm [1] which is shown below. The  procedure is better understood by the flowchart  which is shown in figure1.

Apriori Algorithm [1]    IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India    Step 1: Scan the transaction database to get the  support S of each 1-itemset, compare S with  Minimum Support (MS), and get a set of frequent 1-  itemsets, L1.

Step2: Use L k-1 join L k-1 to generate a set of  candidate k-item sets. And use Apriori property to  prune the non-frequented k-item sets from this set.

Step3: Scan the transaction database to get the  support S of each candidate k-item set in the final set,  compare S with MS, and gets a set of frequent k-item  sets, Lk.

Step5: For each frequent item set l, generate all  nonempty subsets of l.

Step6: For every nonempty subset s of l, output the  rule " s => (l-s)" if confidence C of the rule " s => (l-  s)"                                                              Yes      No                    Figure 1: Flow Chart for Apriori Algorithm  In our approach we can select the data set from  the master list. Then we find the frequency of the  data set, and then we have two options of finding  the final patterns first is single minimum support  and second is the multiple minimum support.

Then we calculate the minimum support and  record the duration. Same thing will be performed  for the multiple minimum support and record the  time. Then we apply the zonal minimum support  as shown in figure 2. Our approach automatically  sense the zone and according to the zone  minimum support is decided and final prune  based calculation is achieved in different zones  which is much more faster and better reduction  support in time.

Figure 2: Zonal Minimum Support    For better understanding we provide the  examples in the result analysis section.

4. RESULT ANALYSIS    For explaining the result we consider the  dataset as shown in figure 3. Then we find the  frequency as shown in figure 4. Then we find the  final pattern based on single and multiple support  as shown in figure 5, figure 6 and figure 7.  Then  zonal density is  auto selected according to the  final pattern obtained from the pruning set as  shown in figure 8. As we earlier discuss that  higher density is selected in the case of item set is  grater and equal to 201 and it is less than or equal  to 500. Then we recorded the actual time for  single multiple support, multiple support and  DMS as shown in table 1 and Table 2 and the  graph of figure 9 and figure 10. The comparison  shows the effectiveness of our approach.

Compare S with Minimum  Support (MS), and get a set  of frequent 1-itemsets, L1.

Use L k-1 join L k-1 to  generate a set of candidate k-  item sets.

Final set, compare S with  MS, and gets a set of  frequent k-item sets, Lk.

For each frequent item set l,  generate all nonempty  subsets of l.

Candidate  Set=Null  s => (l-s)" if confidence C of  the rule " s => (l-s)  IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India       Figure 3: Dataset     Figure 4: Frequency       Figure 5: Minimum Support    Figure 6: Final Pattern based on single support of         Figure 7: Final Pattern based on multiple supports  of 50, 60, and 70       Figure 8: High Density Selected  IEEE - 31661  4th ICCCNT - 2013 July 4 - 6, 2013, Tiruchengode, India       Figure 9: Execution speed (Compare1)      Figure 10: Figure 9: Execution speed (Compare1)   Table 1: Execution Time in single MS   Compare1  filename file size time  MS  Time  DMS  Time  Zonal  ab2.txt 38 13 21 27  main.txt 4122053 370 387 392     Table 2: Execution Time in multiple MS              5. CONCLUSION    In this paper we proposes an approach in the  direction of zone or density wise distribution , so that  we can estimate frequent pattern which is more  accurate and less time consuming. Our approach  provides a greater computation in a less time. For this  we provide several computation results based on  tables. We also show some result analysis in a  comparative way, which shows that our approach is  better and efficient.

