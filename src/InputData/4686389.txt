An Effective Algorithm for Simultaneously Mining Frequent Patterns and Association Rules

Abstract-Within the area of association rules mining, previous algorithms, e.g., FP-Growth and Apriori, have been generally accepted with high appraisals respectively. Most of these algorithms decompose the problem of mining association rules into two subproblems: find frequent pattern and generate the desired rules. Therefore, such a decomposition strategy cannot but bring delay problem when the size of database is considerable and makes user unbearable in a system where the required feedback time is rigor. To solve the problem, we catch a deep insight of FP-Growth algorithm and propose an effective algorithm by utilizing the FP-tree, called AR-Growth (Association Rule Growth), which can simultaneously discover frequent itemsets and association rules (AR) in a large database.

It is analyzed in theory that our algorithm is correct and association rules generated by the algorithm are complete. The experiments show that the output of the AR sequence generated by AR-Growth is closely linear with the elapsed runtime, instead of the sudden eruption in FP-Growth.

Keywords-Association Rules; AR-Growth; FP-tree; Linear Generate  1. INTRODUCTION  Association rule (AR) mining has many important applications in real life. Association rule shows relationships among sets of items in a transaction database. An association rule represents an interesting relationship written as ,read as if A occurs, then B likely occurs. The probability that both A and B occur is called the support, and written as count (AB).

The probability that B occurs given that A has occurred is called the confidence. The association rule mining problem is to find all association rules above the user-specified minimum support and minimum confidence.

Association rule discovery has been an active research area since its introduction in (Agrawal, Imielinski and Swami 1993) [1, 2]. From that time on, the process of mining association rules is decomposed into two separate steps: 1) Find the frequent patterns or frequent itemsets with a minimum support; 2) Use the frequent itemsets to generate association rules that meet a confidence threshold. The decomposition thought is unanimously adopted by followers of the research direction, and most researches only focus on mining frequent patterns because of the straightforwardness in generating the desired rules by using frequent pattern.

The FP-Growth algorithm proposed by 1. Han et al. can be regarded as a landmark in mining frequent pattern.

Subsequently, the improvement algorithm on it and its representational variations, e.g., top-down FP-Growth (TD-FP- Growth) [7] and QFP-Growth [8], well up substantially. The TD-FP-Growth searches the FP-tree in the top-down order, as opposed to the bottom-up order of previously proposed FP- Growth. QFP-Growth preferentially mines frequent pattern with high frequency by using the technology of temporary root.

Both variants need not generate conditional pattern base and sub-FP-tree.

All these methods and improvements are based on the above decomposition strategy, and only confined to the first step for finding frequent pattern. When the strategy is thrown into a on-line system, where users require a real-time feedback, even need to make some adjustment to some algorithm parameters, an fatal delay issue must be brought about. To solve it, on catching a deep insight into FP-Growth and its several variations, we propose an effective algorithm based on a top-down traversing order of the FP-tree, called AR-Growth where the generation of association rules can be incorporated in the process of mining frequent patterns. In the algorithm, all association rules divided into four types according to the functionality of association rules in application for real transaction database, e.g., marketing database.

Three of the four kinds of association rules are ones with single consequent, the generating process of which is embedded into our proposed algorithm. Most applications, which are used for devising market strategy by utilizing association rules in some fields including sales promotion, Web-page re-organization, personalization, and service recommendations, only need rules with single consequent. On the contrary, the remaining forth divided association rules (with multiple consequent) is treated to be inferior and optional, not put into our algorithm together with the former three types, but can be generated by combination of the former three rules afterwards. The strategy can also reduce the complexity of mining because the rules with multiple consequent are sparse as compared with single consequent.

The rest of the paper is organized as follows. Section 2 introduces the preliminaries in association rule mining, section 3 two FP-tree based algorithms: FP-Growth and TD-FP- Growth. Section 4 proposes our FP-tree-based association rules     It  (Xl ...) U PSIS (Xl x2 ...)...PSIS (Xl X2 ...Xm-IXm) U PSIS  PSIS (Xl ...) firstly is covered, and then PSIS (Xl X2...), PSIS  THE TRAVERSING RESULT IN TWO KINDS OF ORDERS  Figure 1. FP-tree ofexample database  TABLE I  Header Table~  Traversing The sequence of resulting itemsetsOrder  m3,mb1,mba1 ,mbae1,mbaefl ,mbafl ,mbe1,mbefl,  down-top mbfl ,ma2,mae2,maet2,mat2,me2,met2,mt2,b4, ba2,bae2,baet2,baf,be3,bet2,bt2,a4,ae4,aef4,af4,e5, ef4,f5  f5,e5,ef4,a4,ae4,aef4,af4,b4,ba2,bae2,baet2,bat2,  top-down be3,bet2,bt2,m3,mb1,mba1,mbae1,mbaefl,mbafl, mbe1,mbefl ,mbfl ,ma2,mae2,maet2,mat2,me2, mef2,mf2  denoted as PSIS (Xl X2 ...xm). PSIS (Xl ) represents all of the  itemsets containing XI, and PSIS (;'1 X2 ) all of the itemsets containing X2 and not Xl.

Property 3.1 (Itemset Partition) See from the outermost, PSIS  PSIS (Xl X2 ... Xm - I xm), while the TD-FP-Growth by the top- down order and the reversing traversing order.

(Xl X2 X3 ...) followed, finally PSIS (Xl X2 ...Xm-IXm) and  form, e.g., Xl and the nonexisting form, e.g., ;2 ), one ofwhich  (Xl X2 ... Xm -1 xm) constitutes the whole itemsets, and the intersection ofany two PSISs equals 0.

Both FP-Growth and TD-FP-Growth search itemsets based on the division in the order from high frequency item to low.

But there exists a differentia in the traversing order. The original FP-Growth traverses PSISs by the down-top order, Le.,

III. FP-TREE BASED ALGORITHMS: FP-GROWTH AND TD- FP-GROWTH  Han et al. proposed a compact data structure called frequent pattern tree, or FP-tree [5] in short, which is an extended prefix-tree structure storing crucial, quantitative information about frequent patterns. To ensure that the tree structure is compact and informative, only frequent length-1 items will have nodes in the tree, and the tree nodes are arranged in such a way that more frequently occurring nodes will have better chances of node sharing than less frequently occurring ones.

The relative experiments have showed that such a tree is compact, and it is sometimes orders of magnitude smaller than the original database. Subsequent frequent-pattern mining will only need to work on the FP-tree instead of the complete data set.

algorithm, AR-Growth. Section 5 presents our performance study, Section 6 related work. Section 7 summarizes our study and points out some future research issues.

Consequently, two FP-tree based algorithms: the originally prepared FP-Growth and the later TD-FP-Growth come forth.

The core of search technique employed in these mining algorithms is a partitioning-based, divide-and-conquer method.

The difference in them we observe and are interested in lies in the traversing order. To interpret the phenomenon better, we give a definition ofpartition set ofpattern.

Definition 3.1 (Partition Set of Itemset (PSIS)) Given the set of all itemsets, we make an recursive division on the whole set according to a priority order of items (a series with the existing

II. PRELIMINARIES  Let I={xI,x2, ... ,XN} be a set of items. An itemset (also called a pattern) is a non-empty subset of I. A transaction is an itemset. We say that a transaction Y supports an itemset X if Y~X. For brevity, an itemset {Xkb Xk2, ... , Xkm} is written as XkIXk2 ...Xkm in this paper.

Let D be a database of transactions. The frequency of an itemset X, denoted as freq (X), is the number of transactions in D that support X. The support of X, denoted as supp (X), is  defined as jreq(X) , where IDI is the number of transactions IDI  in D. X is a Frequent Itemset (FI) if support(X) ~ 0, where 0(0 ~ 0 ~ 1) is a user-specified minimum support threshold. Let F be the set of all FIs.

An Association Rule (AR) is defined as an implication of  the form X::::::> Y, where X and Y are itemsets, X '* 0 and xn Y=0. Let r = X::::::> Y. We call X the antecedent ofr and Y the consequent of r. The support of r, denoted as supper), is defined as supp (X U Y) and the confidence of r, denoted as  conf(r), is defined as su.:~~~~) .Given F, it is straightforward to generate the set of all ARs that are no less than ~. Similar to the use of 0, ~ is a user-specified minimum confidence threshold, where 0 ~ ~ ~ 1, and used to generate ARs with confidence no less than~.

Example 1 Given a FP-tree of example database as Figure 1, Table I presents the result of traversing the FP-tree in down-top and top-down order.



IV. AR-GROWTH (ASSOCIATION RULES GROWTH)  In this section, we formally propose AR-Growth algorithm that injects the generation of association rules into the recursive top-down traversing process of FP-tree, where all association rules are firstly divided into four types.

( ??.X2) U PSSCR (...X3) U PSSCR (...Xm-l) U PSSCR (...xm) constitutes the complete SCR set, and the intersection of any  two PSSCRs equals 0.

C. AR-Growth and a Illustration  Based on the above lemmas and properties, we propose the following algorithm for directly generating SCRs by FP-tree.

To facilitate the description of the algorithm backbone, it is noticed that unnecessary detailed parameters have been omitted.

A. Taxonomy  To be incorporated into the original top-down traversing process of FP-tree and then directly generate association rules, the complete ARs are firstly divided into three kinds of single consequent rule (SCR) and a kind of multiple consequent rule (MCR) else. Only SCRs are embedded into AR-Growth. The definitions ofthree kinds of SCR are given out in Table II.

B. A Divide-and-conquer Technique ofSCR and its Incorporation  Definition 4.1 (Partition Set of SCR (PSSCR?: Given the set of all SCRs, we make a recursive division of the complete set according to an upward containing relationship of each item, one of which denoted as PSSCR (...Xk). For instance, PSSCR ( ..?X2) represents all of the SCRs that are composed of X2 and the items of higher frequency, which appears in the antecedent or the consequent of SCR.

The definition ofthe PSSCR division is similar to the above PSIS. The differentia is that the division conditional items embrace at least two existing forms of item, because two items and over can construct a SCR. Thus, the parameter of all PSSCRs listed below starts from X2.

Property 4.1 (SCR Partition) In the outermost, PSSCR  Rule Type Definition Confine  1. Single consequent rule SCRI 2. The frequency of every antecedent item is less than  the frequency of the single consequent item.

1. Single consequent rule SCRII 2. The frequency of every antecedent item is greater  than the frequency of the single every consequent item.

1. Single consequent rule  SCR III 2. The frequency of some antecedent item is greater than the frequency of the single consequent item, the rest less than.

TABLE II. THE DEFINITIONS OF THREE KINDS OF SCR  Algorithm 1 (AR-Growth: Directly Mining SCR with FP-tree by AR fragment growth).

Input: FP-tree, a minimum support a , a minimum confidence  <;.

Output: The complete set of SCRs.

Method: call AR-Growth (root, null).

Procedure AR-Growth (ROOT Q, FPgrefix a, int[] cross)llthe across array records the items which have crossed before the growth fragment (1){ (2) for each item ai in Q, in the header of Tree, from the high frequency item to the low do {Ilmining three types of SCR from multipath FP-tree (3) if supp(ai) > a, generate pattern p = ai U a with support = ai.support and put it into hash table for retrieval when generating SCR afterwards; (4) else return; (5) retrieve the SCRI's antecedent support suppaSI; the unite set of the SCRI's antecedent and consequent is just p, denoted as SUPPSh its support equals ai.support.

(6) if SUPPSI IsuppaSI ~ <; generate the SCRI: a ~ ai; (7) retrieve the SCRII's antecedent P-I (P - PI, refered to the head item of P) support suppasn; the unite set of the SCRII's antecedent and consequent is just P, denoted as SUPPsn, its support equals ai.support.

(8) if sUPPsn Isuppasn ~ <; generate the SCRII: P-l ~ P; (9) the SCRIII's antecedent is just p, denoted as suppaSIIh its support equals ai.support (10) for each item Ci in the cross array do (11) { (12) generate p+ = p append Ci, the equivalent of the unite set of the SCRIIl's antecedent and consequent (13) retrieve the support of P+ as SUPPSIII (14) if SUPPSIII IsuppaSIII ~ <; generate the SCRII: p~ Ci; (15) } Ilfor end (16) ifTreep;t 0 (17) then call AR-Growth(Treep, p,cross[]); (18) join ai into the cross array; (19)} II for end (20)}  From the algorithm, we can see that the generation of SCR is a divide-and-conquer process in the top-down order, similar to the top-down FP-Growth. The FI generated in every recursive is put into a hash table for the retrieval of the necessaries used to afterward generate the relative SCRs.

Let us examine an example.

Example 2 According to the FP-tree given by the above example 1, we present a resulting dual candidate sequence (a sequence of the dual relation written as (FI:the SCRs generated concurrently in the same program segment)) generated by AR- Growth under the conditions of zero minimum support and zero minimum confidence, and "null" representing that no SCR is generated. The dual candidate sequence is (f: null) (c: null) (cf: c => f, f => c) (a: null) (ac: a => c, c => a) (acf: ac => f, cf => a) (af: a => t: f => a, af => c) (b: null) (ba: b => a, a => b) (bac: ba => c, c => ba) (bacf: bac => t: acf => b) (baf: ba => t: af => b, baf~ c) (bc: b => c, c => t: bc => a) (bcf: bc => t: cf => b, bcf ~ a) (bf: b => t: f => b, bf => a, bf => c) (m: null) (mb: m => b, b => m) (mba: bm => a, ba => m) (mbac: mba => c, bac => m) (mbacf: mbac => t: bacf ~ m) (mbaf: mba => t: baf => m, mbaf => c) (mbc: mb => c, bc => m, mbc => a) (mbcf: mbc => f, bcf => m, mbcf => a) (mbf: mb => f, bf => m, mbf => a, mbf => c) (rna: m =>a, a =>m, rna => b) (mac: rna =>c, ac =>m, mac => b) (macf: mac => f, acf => m, macf => b) (maf: rna => t: af ~m, maf => b, maf => c) (mc: m => c, c => m, mc => b, mc => a) (mcf: mc => f, cf => m, mcf => b, mcf => a) (mf: m =>f, f =>m, mf~ b, mf =>a, mf =>c).

Lemma 4.1 (Completeness and Correctness of AR-Growth) Given a FP-tree of database, a minimum support 0, and a minimum confidence C;, all SCR candidates can be held and some will be placed into the result set if their support is greater a and their confidence greater than c;.

Rationale Based on the above Property 4.1, AR-Growth is devised into a recursive function for mining the PSSCRs lied in the different partition layer. Therefore, we only need to prove that a SCR partition set in the outermost layer is completeness.

For example: PSSCR (...Xk) considered, when every unint set of SCRIs' antecedent and consequent, unite set of SCRIls' antecedent and consequent, and antecedent of SCRIlls in the PSSCR, one-to-one mapped to all SCRIs, SCRIls and SCRIlls in the PSSCR, is traversed, the top-down-FP-Growth-like algorithm frame adopted by AR-Growth can ensure that the other components used for generating all SCRIs, lIs, Ills in the PSSCR have been available in the corresponding PSSCR recurrence and all corresponding SCRs in the program fragment can be examined.

The AR-Growth algorithm integrates AR into the FP- Growth-like frame. Therefore, it not only remains the efficiency of FP-Growth, but proposes an instant model for mining association rule. The discussion on the mining strategy ofMCR is placed in Section 4.5.

D. The Resulting SCR Sequence ofAR-Growth  The SCR sequence generated by AR-Growth is sorted by PSSCR (...X2) PSSCR (...X3).' .PSSCR (...Xm-l) PSSCR (...xm) in the outermost. The output order can satisfy logic and rationality when users linearly scan the results from a data mining system as below.

1) The SCRs between the high frequency are first received.

Under normal circumstances, The SCRs among the high  frequency are also more critical and useful than among the low frequency.

2) Because, in the resulting SCR sequence mined out in the order of PSSCR (...X2) PSSCR (...X3) ?..PSSCR (...Xm-l) PSSCR (...xm), the quantity of the front PSSCR is less and the quantity of the sequential PSSCRs doubly increase in theory, the SCRs with the lower item can be faster added in later.

E. Multiple Consequent Rule (MCR)  In most applications, MCR has been nonsignificant and treated as an alternative with additional function. Even if MCR is required in some cases, it is still worthwhile to discuss if MCR should hold the same treatment (also injected into AR- Growth algorithm) as SCR, Because whether MCR exists depends on the existence of the relative multiple SCRs (Lemma 4.2), in other words, the loss of a certain SCR result in the miss of some involved MCRs. Moreover, even if MCR are presented, some solutions are difficult to carry out.

Lemma 4.2 Given three rules (a MCR and two SCRs, denoted as SCRI and SCR2, with the same antecedent, the unite set of the two SCRs' consequent is just MCR's) and a confidence threshold c;. The relative MCR is not generated if conf (SCRl)< c; or conf (SCR2)< c;.

Balancing the complexity of AR-Growth and the completeness of the resulting AR set and, and Considering the dependent relation between MCR and SCR, the generation of MCR is located behind SCR, and corresponding Method 4.1 for producing MCR by the combination of SCRs.

Method 4.1 Given two SCRs with the same antecedent, denoted as AntscR' the unite set of the two SCRs' consequent UConSCR, and a confidence threshold c;. A MCR, AntscR => UConSCR, is generated if the confidence of the MCR is greated than c;.



V. EXPERIMENT  In this section, we present a performance comparison of AR-Growth with the FP-Growth which implements the original mining strategy. All the programs are written in MicrosoftlVisual C++6.0 and performed on a Pentium 4 1.8GHz PC with 512Mb RAM running on Window XP. It is noted that the algorithm framework of the AR-Growth is devised to be the same as the FP-Growth for the fairness of the comparison.

We report experimental results on two synthetic data sets.

The first one is TIO.I4.DIOOK with lK items. In this data set, the average transaction size and average maximal potentially frequent itemset size are set to 10 and 4, respectively, while the number of transactions in the dataset is set to 100 K. The second synthetic data set we used is T25.I20.D100K with 10 K items. It is a sparse dataset. The average transaction size and average maximal potentially frequent itemset size are set to 25 and 20, respectively. There exist exponentially numerous frequent itemsets in this data set when the support threshold goes down. There are also pretty long frequent itemsets as well as a large number of short frequent itemsets in it. It contains abundant mixtures of short and long frequent itemsets.

