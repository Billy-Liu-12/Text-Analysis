Developing a Scientific Image Retrieval System with Prediction Capability

Abstract?Observing scientific images allows scientists to  have better understanding on Earth. For example, remote sensing images are applied to help monitoring ocean and climate change. These images will be stored in database and may be retrieved later for reference purpose. The possible retrieval methods may be to give keywords or a query image to the system to get desired images. However, scientists sometimes might want the scientific image system be smart, that is, they want the system to present some images that can predict future variations.

Currently, the retrieval methods can not achieve the previous requirement. This paper proposes an intelligence scientific image retrieval system based on content-based image retrieval. While retrieving, this system can exploit the spatial relationship between the objects in query image, and then retrieve images that their spatial semantic are similar to the query image.

Moreover, the spatial association rules are also mined and are then used as a basis for retrieving additional images for prediction purpose. The experiments demonstrate that the images retrieved by the proposed system are more accurate, and the system can also predict the future variations.

Keywords?content-based image retrieval, spatial association rules mining

I.  INTRODUCTION Scientific images such as remote sensing images are  collected at an ever-increasing pace and are made available to the public. One can build a database system to store scientific images and retrieve them later for research reference.

Traditional keyword-based queries and content-based image retrieval technology are two common methods to retrieve images. In traditional image retrieval, users want the retrieved images are very close to the queries; however, this is not enough for scientific image retrieval. While retrieving scientific images, users may even want the system to provide prediction information. Currently, the mentioned retrieval methods can only get images that are similar to the queries but could not provide prediction information. In order to get effective scientific image retrieval results, the retrieval technology must be improved. The method of keyword-based queries is not suitable since it cannot be used for more elaborate queries. In this paper, content-based image retrieval technology is thought an adequate way to retrieve scientific images.

There are several studies that are proposed for content- based image retrieval strategies [9]. These strategies usually use low-level features such as color, texture and shape to calculate the similarity between images. In order to retrieve extra images that can provide prediction information, this paper develops a scientific image retrieval system that content-  based image retrieval and inter-transaction association rules mining methods are employed to achieve the above goals.

Before retrieving images, our proposed system will use a spatial reference model to help to build a spatial transaction database. Next, the inter-transaction association rules algorithm is applied to get spatial variation patterns.

While querying images, the system retrieves images based on low level features and objects? spatial relationships extracted from query image. Next, the system will get additional images according to the mined variation patterns for future variation trends prediction. The experiments reveal the retrieved images are more like the query image since the spatial semantics are considered during retrieval.

The remaining parts of this paper are organized as follows.

Section 2 describes the problems of traditional content-based image retrieval. Section 3 introduces our proposed algorithm and experimental evidence is provided in section 4. At last, section 5 concludes this paper.



II. RELATED WORKS  A. Content-based Image Retrieval Advances in multimedia technologies have led to huge  archives of images in diverse applications such as medicine, remote sensing, and entertainment applications. To exploit the full benefit of the explosive growth of image data, there is an urgent demand to develop efficient techniques for storage, browsing, indexing and retrieval. In recent years, automatic indexing and retrieval based on image content has become more desirable for developing large volume image retrieval applications [7]. The examples of content-based image retrieval are QBIC (Query by Image Content) by IBM, and VisualSEEK by Columbia University.

In content-based image retrieval, color, shape and texture are the main features both humans and computers used to recognize images. Most content-based image retrieval techniques will compute and store each image?s feature vector in the image database. While retrieving, a query image is given, and the feature vector of the query image is computed and then is taken to be compared with the feature vector of each image stored in the image database. An image is retrieved if its feature vectors are similar to the feature vectors of query image.

Weighting Euclidean distance is used to measure how a certain image closes to the query image:  ? ?= i  iii tqTQ ?, , (1)  2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks  DOI 10.1109/I-SPAN.2009.133     where Q is query image and qi is low level feature of Q. T is a certain image in database and ti is low level feature of T. wi is the weight factor.

B. Scientific Image Advances in technology have enabled scientist to collect  scientific data and scientific image from observations and simulations at an ever-increasing pace. Data analysis tools or image processing systems become very important to scientist.

In order to describe our proposed scientific image retrieval system, Argo images are downloaded and used as our experimental data in this paper. Argo is a global array of 3,000 free-drifting profiling floats that measures the salinity and temperature of the upper 2,000 m of the ocean [1]. The monthly ocean salinity and temperature images are made freely available to members of the International Argo Project and the national contributing programs (http://www.argo.ucsd.edu, http://argo.jcommops.org). Fig. 1 shows a monthly salinity image, and a monthly temperature image downloaded from Argo.

For the scientist to benefit from these scientific images collecting capabilities, it is becoming clear that semi- automated techniques, such as the ones in data mining, must be applied to find the useful information in the data. Data mining helps extract the spatial semantics in images and define a spatial transaction database which allows spatial association rules to be discovered and hence enhance the retrieval effectiveness.

C.  Spatial Transactions Inter-transaction association rules mining [4, 8] is  employed for discovering spatial variation patterns. However, association rule mining algorithms assume that a finite set of disjoint transactions are given as input to the algorithms [3, 6], and there is no explicit finite set of transactions in an ocean image. This study adopts the strategy proposed in [6], where the spatial transaction is defined around the instances of a special reference feature. Taipei is chosen as the reference site and concentric circles are used to define neighboring regions to the reference site. Fig. 2 shows this reference centric model.

The salinity or temperature variations are extracted first from each image. The variations within the concentric circles are treated as a single transaction.

The concentric circles are also used to annotate the location of the salinity or temperature variations. The sub-zones defined by the concentric circles represent different distances and directions to the reference site. For example, sub-zone A2 is in the east-northeast sector far from Taiwan. In fact, the concentric circles model helps not just defining a single transaction but a spatial transaction.



III. SCIENTIFIC IMAGE RETRIEVAL AND MINING STRATEGY A database is built to store Argo ocean salinity and  temperature images. In this paper, salinity or temperature variation is called an object and will be cut from image according to its color. In order to annotate the location of each object, a reference model, a set of concentric circles, is applied to each image before objects are cut. Thus, each object?s spatial information is maintained, and a spatial transaction is  obtained. The spatial transaction attributes are quantitative and need to be mapped to several intervals. Following are the steps to get salinity and temperature variation patterns.

A. Quantitative Attribute Transformation First, each quantitative attribute needs to be transformed  into binary attributes.

B. Frequent Inter-transaction Itemsets Discovery Next, the inter-transaction items and frequent inter-  transaction itemsets can be found by applying apriori-like algorithm. One can find the details of the apriori-like method in [5, 10].

C. Variation Patterns Generation After frequent inter-transaction itemsets being discovered,  the salinity and temperature variation patterns can be generated.

D. Scientific Image Retrieval Previous sections describe how to build the image database  and its corresponding spatial transaction database. This section describes the process of how to retrieve the scientific image.

The objects (salinity and temperature variations) need to be extracted from query image according to their color before retrieval works starting.

A set of concentric circles is applied to the query image the same time to help annotate location to objects cut from query image. Now, the object spatial location is its coordinate  )sin,cos(),( ?? ii rryx = .  may be the inner circle radius or the outer circle radius .

ir  1r 2r ?  is the angle to x-axis.

From above descriptions, an object can be represented by ( )yxc ,, , where c  is the color of the object. x and y are the coordinate of the object.

Assume an object q  in the query image is represented by its feature vector ( )qqq yxcq ,,= , and ( )ttt yxct ,,=  is an object in an image. Euclidean distance is used to measure the distance between these two objects:  ,, tqcolor cctq ?=  (3)  ,, tqtqlocation yyxxtq ?+?=  (4)  where color  tq,  is color distance and location  tq,  is the location distance between two objects. Two objects are similar if their color and location are close enough. That is, two objects are similar if the color distance is less than a pre- defined threshold  and location distance is less than threshold .

colorT  locationT  The target image in a database is similar to the query image if the total number of similar objects is greater than the threshold . For example, there are six objects in the query image and the threshold is set to 60%, and the target image is similar to query image if at least four objects in the target image are close to the objects in the query image.

imageT     The above descriptions illustrate how the system retrieves images according to the query image?s color feature and objects? spatial location. The following example explains how to get extra images to predict future variation trends.

Example. Assume there are total n objects { cut from the query image.

}  }  nooo ,...,, 21  Step 1. Choose one object  each time and the variation  pattern that its antecedent part is  will be selected. For  example, assume  is the selected object, then all the  variation pattern has the form  will be selected. The consequent part Y may be any possible objects.

io  io  io Yoi ?  Step 2. Repeat step 1 until each object in {  is checked.

nooo ,...,, 21  Step 3. Get 2, 3, 4, ..., and n objects and select all variation patterns that their antecedent parts that match the selected objects.

Step 4. Repeat step 3 until all combinations of object pairs are checked.

Step 5. Based on the selected variation patterns, list the images according to the consequent part of the pattern. For example, if  is the selected pattern, the images match the consequent part Y  11 Yo ? 1 will be retrieved.



IV. EXPERIMENTAL RESULTS AND DISCUSSION This research downloaded ocean salinity and temperature  images from 2001/01 to 2007/12. An image database was built comprising these images. An object is defined as either a salinity variation or a temperature variation and one can get all the objects in a certain image according to their color. A set of concentric circles was used as a reference model as it allows objects? location information can be easily defined. That is, the location information was annotated to its corresponding object.

The same monthly salinity and temperature variations are defined as a single transaction.

While getting salinity and temperature variation patterns, the maxspan window size is set to 6 months. The minimum support is set to 25%, and the minimum confidence is set to 70%. Table I shows part of the discovered inter-transaction association rules. For example, the rule, H1SRL(0) -> A2SRL(3), means that if salinity rose from 0.05 psu to 0.15 psu in the area that is in the west-south sector near Taiwan, then salinity will rise from 0.05 psu to 0.15 psu in the east sector far away from Taiwan the next 3 months.

The experiment adopted salinity image of January 2007 as the query image. Fig. 3 shows that there were a total of 8 variations cut from the query image. The threshold  of measuring the color distance between objects is set to 5,  is set to 200, and  was set to 60%. Fig. 4 shows partial results of image retrieval. Only images that both color and spatial semantics are similar to the query image were retrieved. One can see that the object ?salinity rose little  (SRL)? can be found in H1 sub-zone in Fig. 3. According to the salinity variation pattern ?H1SRL(0)->A2SRL(3)?, the system can retrieve images to predict future salinity variations.

Fig. 5 shows that the extra salinity image of 2007/04 was retrieved according to the variation patterns.

colorT  locationT imageT

V. CONCLUSIONS As we can see that if the spatial semantics are not  considered during retrieval, the system will get a lot of images that are similar to the query image according to colors. In this case, users have to manually browse the retrieved images, which is inefficient. And the most important thing is if the system cannot provide information of future variation trend, it is much harder to monitor the ocean environment. Therefore, inter-transaction association rules algorithm is employed to discover salinity and temperature variation patterns that are used to obtain additional images for prediction purpose. The experiments show that images similar to the query image in both color and spatial semantics are retrieved. Additional images are also retrieved for prediction usage. These two results makes retrieval system more valuable.

