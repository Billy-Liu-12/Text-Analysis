Equating Interestingness of Causal Rules via Graded Response Theory

Abstract  Multi-database mining has attracted a lot of attention because it is an important research topic for large com- panies that have many branches to generate powerful in- sights that lead to benefits. However it is difficult for exist- ing algorithm to generate both global and local patterns and compare interestingness of patterns because there is no unified measures in data mining area. This paper pro- poses a method of equating interestingness of patterns for extracting and comparing both global and local patterns via unified measure Latent trait based on Graded Response Theory.

1. Introduction  Past decade, data mining has attracted a lot of attention because it is an important research topic to generate pow- erful insights that lead to benefits. Multi-database mining recently has been also considered as an important research because many large companies that have many branches have distributed multiple databases. Although many multi- database mining algorithms have been proposed[6, 19], their techniques are based on mono-database mining tech- nique so that it is impossible to extract local patterns, that is, only global patterns can be extracted. Global patterns have been regarded as great insights while local patterns have been ignored because of lacking in statistical signif- icance. For example, support, one of the most fundamental measures, is a impeditive measure for extracting local pat- terns.

Additionally many useful measures have been proposed[1, 8] in order to measure interestingness of patterns. However respective measures have their own in- terestingness so that we often encounter the interpretational problems. Because there is no measure to describe the uni- fied interestingness of patterns, each interestingness differs much from the others. It is really important for decision  makers to extract and compare global patterns and local patterns. Comparability of information enables users to identify similarities and differences between two databases, while consistency does the same between periods for each database. We address these issues by introducing Latent trait as an unified measure of capturing interestingness of patterns in order to extract both global and local patterns and compare interestingness of these patterns.

In this paper, we concentrate on the patterns presented by the Causal rules[20] that is extended model of Association rules for dealing with quantitative and categorical items and introduce a framework of equating interestingness of pat- terns based on Graded Response Theory (GRT)[14] which is an extended model of Item Response Theory (IRT) for extracting both global and local rules by the unified mea- sure.

IRT is a mathematical model in educational testing for studying individual responses. The aim of IRT is to ob- tain fine estimates of Latent trait called ability. This is an attractive model to predict the probability of each correct response as a function of the Latent trait and some parame- ters. Latent trait is a powerful unobserved factor of measur- ing interestingness of derived rules as an unified measure- ment and specify the features of derived rules. Latent trait is estimated by the EM algorithm[7] with some parameters.

These parameters are also significant as well as Latent trait in terms of capturing the features of rules.

Graded Response Theory[14] which is the extended model of IRT can be applied to Causal rule mining[20].

From this application, both global and local rules can be generated and compared to to identify similarities and dif- ferences among these rules.

This paper is organized as follows. In the section 3, Item Response Theory for analysis of Association rules is intro- duced. In the section 4, we present Graded Response The- ory for analysis of Causal rules. In the section 5, we present an equating procedure of Causal rules. Experimental results are presented in Section 6.

2. Preliminary  Let I be a finite set of items, and DB be a set of transac- tions, called a database, where each transaction T is a set of items such that T ? I . Each database has a unique identifier i, called database ID, is denoted by DBi and each transac- tion has a unique identifier i, called Transaction ID (T ID), is denoted by Ti. We denote subsets of I , called item-sets, by X, Y and items of X and Y by X1, X2, X3, ? ? ? and by Y1, Y2, Y3, ? ? ? respectively.

In this paper, an item-set X means not only the subset of I but also the event that a transaction contains all items in the set X , and Pr(X) denotes the probability that a trans- action contains the set X .

We consider an item-set Y such that Y = {Y1, Y2, ..., Yn}. Let Yij represent a presence or an absence of an item Yj in a transaction with TID = i, that is, Yij = 1 if Yj ? Ti and Yij = 0 if Yj /? Ti.

An item response data with TID = i for given an item-set Y , denoted by Ti,Y , is represented as a binary vector, i.e., Ti,Y = (Yi1, Yi2, ..., Yin). Remark that Ti ? Y = {Yj |Yij = 1, j = 1, 2, ..., n}. For example, consider an item-set Y = {Y1, Y2, Y3, Y4, Y5}. The item response data T4,Y = (1, 0, 0, 0, 1) indicates that the transaction with TID = 4 contains items Y1 and Y5, but does not contain items Y2, Y3, and Y4.

3 Latent Trait of Association Rule  We presume that there is a Latent trait between item-sets X and Y . Let ? be a Latent trait that is an unobserved factor of measuring the underlying ability and ?X represent the ability of an transaction that contains all items in X . That is, Dx has an inherent unobserved variable, Latent trait ?X , and this ?X dominates the probability of occurring an item Yj .

Let pj(?X) and qj(?X) represent the probabilities of the presence and the absence of an item Yj ? Y in DX respec- tively as follows:  pj(?X) = Pr(Yj |X),  qj(?X) = 1 ? pj(?X) = Pr(?Yj |X).

The interestingness of an Association rule X ? Yj is mea- sured by the conditional probability of Yj given X . The measures ? for evaluating interestingness of an Association rule is defined as follows:  ?(X ? Yj) = Pr(Yj |X).

Because there is a Latent trait between item-sets X and Y and the Latent trait ?X of DX dominates the probability of occurring Yj , the conditional probability can be represented  as a function of ?X . Therefore pj(?X) represents the inter- estingness of an Association rule.

The probability of that a transaction with TID = i whether contains an item Yj can be represented briefly as follows:  f(Yij |?X) = pj(?X)Yij qj(?X)1?Yij .

For an item response data Ti,Y = (Yi1, Yi2, ? ? ? , Yin), trans- lating process into a joint probability model based on the local independence assumption results in the following:  f(Ti,Y |?X) = n?  j=1  pj(?X)Yij qj(?X)1?Yij .

Logarithmic likelihood function of the above probability log L(Ti,Y |?X) is illustrated as follows:  n?  j=1  [Yij log pj(?X) + (1 ? Yij) log qj(?X)] .

The parameters ?X is estimated by maximization of the above Logarithmic likelihood function.

IRT is a prominent mathematical model in educational testing for studying individual responses. The aim of IRT is to obtain fine estimates of Latent trait called ability. This is an attractive model to predict the probability of each cor- rect response as a function of the Latent trait and some pa- rameters. There are three IRT models proposed in [3, 13], one parameter model (1PL), two parameter model (2PL) and three parameter model (3PL) and there are Item Re- sponse Functions (IRF) that represent the probability of the presence of an item Yj for each model. The IRF of two parameter model is defined as follows:  pj(?X) =  1 + exp(??aj(?X ? bj)) (2PL)  where aj is the discrimination parameter, bj is the difficulty parameter, ? is a scaling factor and ?X is the ability level.

The parameters aj , bj and ?X are estimated by maximiza- tion of the above Logarithmic likelihood function. We apply the IRF of two parameter IRT model to Association Rule Mining for measuring interestingness of the rules. A scal- ing factor is 1.7 for normal ogive IRT model with two pa- rameters, while a scaling factor is 1.0 for logistic IRT model with two parameters[3, 13].

The IRF for Association Rule Mining represents the con- ditional probability of Yj given X where ?X is the La- tent trait of causing the event yj . These parameters aj , bj and ?X could be generated from the database by the EM algorithm[7].

In our perspective, the higher the absolute value of the discrimination parameter is, the more interesting the rule is.

The Fisher information for an item Yj is defined as follows:  Ij(?X) = ?2a2jpj(?X)qj(?X).

The discrimination parameter aj for an item Yj is notice- ably significant in terms of augment the information. There- fore the parameter aj is applied for measuring interesting- ness of the rules.

The parameter bj represents how much the occurrence of X relates the occurrence of each of items in a set of alterna- tives, i.e., causal relationships between X and each of items could be measured.

The most important and fascinating factor is the param- eter ?X that represents the Latent trait. By estimating the parameter ?X , the responses of each rule could be pre- dicted. When the three parameters are reasonably accurate, the predictive property will be assured. The parameter ?X represents the interestingness of the rules. The higher the ability level is, the more interesting the rule is. We can say that these parameters are descriptive measures for de- rived rules. Item Characteristic Curve (ICC) is a graph of Item Response Function and a visual tool of illustrating the choice probability of each items.

4 Latent Trait of Causal Rule  A Causal rule proposed in [20] is an implication of the form X ? Y where X and Y are sets of categorical vari- ables with X?Y = ?. For each categorical item Xi, R(Xi) called range consists of finite order categorical items. We assume that X is a conjunction of explanatory categorical items Xi and Yj is a target item. By adapting Graded Re- sponse Theory which is extended model of IRT, interesting insights from Causal rules could be derived such as influ- ence and interestingness of categorical items. Let Xi be categorical variable that has K ordered value as follows:  Xi = 0, 1, 2, ? ? ? , k, ? ? ? , K ? 1 The probability of Xi = k is defined as follows:  p(Xi = k|?Xi) = pik = p?ik(?Xi) ? p?ik+1(?Xi),  where p?ik(?Xi) represents the probability of that Xj ? k.

Note that p?i0(?Xi) = 1 and p  ? iK(?Xi) = 0. The probability  p?ik(?Xi) for 2PL logistic model is defined as follows:  p?ik(?Xi) =  1 + exp(??ai(?Xi ? b?ik)) .

Let Mi be the categorical response data matrix. By the local independence condition, the probability of an obser-  vation Mi is illustrated as follows:  p(Mi|?Xi) = n?  j=1  K?1?  k=0  pjk(?Xi ) xjk .

Logarithmic likelihood function of the above probability is defined as follows:  log L(Mi|?Xi) = n?  j=1  K?1?  k=0  xjk log pjk(?Xi ).

The parameters ai, b?ik and ?Xi are estimated by maximiza- tion of the above Logarithmic likelihood function. The Fisher information for a target item Yj is defined as follows:  Ij(?Xi) = ? 2a2j  K?1?  k=0  rk pjk(?Xi )  where  rk = (p?jk(?Xi)q ? jk(?Xi) ? p?jk+1(?Xi)q?jk+1(?Xi))2  Let ??X be an estimated Latent trait of X for a target item Yj . The estimated Latent trait ?? is regarded significant as much as a discrimination parameter. Hence an estimated Latent trait is one of criteria for measuring the interesting- ness of derived Causal rules.

5. Equating Procedure  In this section, we propose an equating procedure of Causal rules based on a scale conversion of Latent trait by estimated parameters and an Anchor item-set for generating global rules and for applying an equating algorithm of rules.

5.1 Scale Conversion  We have applied a linear scale conversion method even though there are many conversion methods in Latent class analysis. Linear conversion can be used in terms of a math- ematical model as follows;  ? ? j = k?j + l,  a ? j =  k  aj ,  b ? j = kbj + l,  where k ?= 0. The coefficient k and l are called conversion coefficient and estimated by the EM algoritm. The above linear conversion as an equating procedure is mathemati- cally correct model. After the linear scale conversion, the probability of ?  ? j , denoted by p  ? j(?  ? j), is as follows;     p ? j(?  ? j) =  1+exp(??a?  j (?  ? j ?b?  j ))  = 1 1+exp(?? 1k aj(k?j+l?kbj?l))  = 11+exp(??aj(?j?bj)) = pj(?j)  Let us assume that there are two estimated parameters for an item. The estimated parameters can be normalized by the following equation,  b ? j ? Ave(b  ? j)  SD(b?j) =  bj ? Ave(bj) SD(bj)  ,  where Ave is average and SD is standard division. Then we have the following equation,  b ? j =  SD(b ? j)  SD(bj) bj + Ave(b  ? j) ?  SD(b ? j)  SD(bj) Ave(bj).

Therefore the conversion coefficient k and l is defined as follows;  k = SD(b  ? j)  SD(bj) ,  l = Ave(b ? j) ? kAve(bj).

5.2 Anchor Item  In order to apply the equating procedure based on the linear scale conversion, a common item-set, a set of items that belong to all databases which are about to analyze, has to be generated. We call these items Anchor items and item- sets Anchor item-sets. An Anchor item-set A is defined for given databases as follows:  A = {I(DB1) ? I(DB2) ? ? ? ? ? I(DBi) ? ? ? ? I(DBn)}, where I(DBi) is all items of the database DBi. Generated rules from an Anchor item-set are extracted as global rules.

5.3 Expected A Posterior  The Bayesian modal includes a likelihood function and a prior distribution for the parameters. From Bayesian the- ory, we could extract that the posterior distribution is pro- portional to the product of the likelihood and the prior dis- tribution as follows:  g(?X |yj) ? g(yj|?X)g(?X) where g(?) is a density function. Expected A Posterior de- noted by EAP is used as the expected value of the posterior probability distribution for Latent trait for given parameters.

The EAP is usually the mean of the posterior distribution of a Latent trait.

Table 1. Equating Algorithm for Causal rules  Input :D?Database DB1 and DB2 :yj?Target item  Output :A list of Causal rules with a, b?, ??  (1) for each database (2) for each explanatory categorical item (3) Estimate a and b? by the EM algorithm (4) for a set of anchor items (5) Generate conversion coefficient k and l (6) for each anchor item (7) Convert a and b? by k and l (8) Estimate ?? given converted a and b?  (9) Output  6. Experiments  We have performed analysis of Direct Marketing data distributed for the KDD CUP in 1998. These experiments are for deriving results of equating procedure for Causal rules analysis based on the Graded Response Theory. Due to the space limitation, we represent the only result of RFA 2, RFA 3 and RFA 4. Suppose a Causal rule has three categorical items for a set X of categorical items, i.e., X = {X1, X2, X3}. The domains for categorical items X1, X2, X3, and Y are X1 = {F, N, A,L, S}, X2 = {1, 2, 3, 4}, X3 = {D, E, F,G}, and Y = {Donor}. The domain of the first categorical item X1 in RFA 2 is {L}, while the domain of X1 in RFA 3 is {F,N,A,L,S}. Be- cause all donors belong to the category {L} in RFA 2, it is impossible to make easy comparisons of interestingness of Causal rules.

Table 2. Estimated Parameters from RFA 2 a b?1 b  ? 2 b  ?  X2 1.3879 -0.4418 0.32633 1.0544 X3 1.3290 -1.3588 0.1566 1.3619  Table 2 shows the estimated parameters of each categor- ical item from the data of RFA 2. Although the higher dis- crimination parameter is, the more significant the categori- cal item is, there is hardly difference between the item dis- crimination parameters for X2 and X3 so that categories X2 and X3 are regarded as much the same categorical items.

Table 3 shows the estimated parameters of each categor- ical item from the data of RFA 3. The most significant cat- egorical item is X2. Although the most insignificant item is X1, interesting insights could be derived.

Table 3. Estimated Parameters from RFA 3 a b?1 b  ? 2 b  ? 3 b  ?  X1 0.9051 -2.4254 -1.8401 0.7861 0.8022 X2 1.7536 -0.3730 0.3209 1.0399 ?? X3 1.0379 -1.5361 0.1417 1.4760 ??  Figure 1. Item Characteristic Curve  Figure 1 depicts the ICC of X1 from the estimated pa- rameters from the data of RFA 3. The category N could not be an attractive category because its highest probability is not high enough. The fact that the highest item difficulty parameter of X1 is a category S indicates that people who belong to category S are likely to be Donor. The category L is attractive category in terms of both item difficulty param- eter and probability so that the people who belong to this category are potentially attractive Donor.

In order to convert Causal rules from RFA 2 into rules from RFA 3, the Equating Algorithm can be applied. The set of anchor items A is {X2, X3} for this conversion.

Table 4. Anchor Items RFA 2 RFA 3  a b? a b?  X2 1.3879 -0.4418 1.7536 -0.373 0.3263 0.3209 1.0544 1.0399  X3 1.329 -1.3588 1.0379 -1.5361 0.1566 0.1417 1.3619 1.476  Ave ? 0.9923 ? 1.0669 SD ? 0.1726 ? 0.1782  Table 4 shows standard deviation and average from RFA 2 and RFA 3. From SD and Ave, conversion co- efficient k and l are generated as follows:  k = 0.930083, l = 0.006828.

Table 5 shows converted parameters from RFA 2. From the converted parameters, Latent trait of Causal rules can be estimated from the parameters.

Table 5. Converted Parameters of RFA 2 a b?1 b  ? 2 b  ?  X2 1.4922 -0.4041 0.2517 0.9875 X3 1.4289 -1.2569 0.1525 1.2735  Table 6 shows that interesting comparable Causal rules from RFA 2 and RFA 3. The rules from the data of RFA 2 and RFA 3 have converted to compare the effects of the same promotions that have done in different years, 1996 and 1997. Both promotions are about NK . The peo- ple who belong to category 4 of X2 and category D of X3 react to the promotion NK . NK represents the promotion that mailings are blank cards with labels. Therefore the pro- motion NK succeed for category 4D.

Table 6.

RFA 3 EAP RFA 2 EAP  1 S4D 1.711 ? ? 2 ? ? L4D 1.569 3 S4E 1.251 ? ? 4 A4D 1.243 ? ? 5 N4D 1.073 ? ? 6 S3D 0.994 ? ? 7 S4F 0.963 ? ? 8 ? ? L4E 0.936 9 ? ? L3D 0.929  10 N3D 0.879 ? ?  We apply the Equating Algorithm to the data of RFA 3 and RFA 4 for comparing effects of different promotions that have done in the same year. The data of RFA 3 is about the promotion of NK , while the data of RFA 4 is about the promotion of TK . TK represents the promotion that mailings have thank you printed on the outside with labels. Table 7 and 8 show that estimated parameters of the data RFA 4 and converted parameters respectively. The conversion coefficient k is 0.7838 and l is 0.0645 for this conversion.

Table 7. Estimated Parameters from RFA 4 a b?1 b  ? 2 b  ? 3 b  ?  X1 0.8888 -2.4236 -1.8159 0.8170 0.8336 X2 1.7310 -0.3805 0.3189 1.0420 ? X3 1.0490 -1.5235 0.1360 1.4735 ?     Table 8. Converted Parameters of RFA 4 a b?1 b  ? 2 b  ? 3 b  ?  X1 1.1339 -1.8352 -1.3589 0.7049 0.7180 X2 2.2084 -0.2337 0.3145 0.8813 ? X3 1.3383 -1.1297 0.1711 1.2195 ?  Table 9 shows that interesting comparable Causal rules from RFA 3 and RFA 4. The people who belong to the category N4D react to the promotion NK . On the other hand, there are no differences between promotions NK and TK for categories S4D, A4D and S4E.

Table 9.

RFA 3 EAP RFA 4 EAP  1 S4D 1.711 ? ? 2 ? ? S4D 1.640 3 S4E 1.251 ? ? 4 A4D 1.243 ? ? 5 ? ? A4D 1.163 6 ? ? S4E 1.146 7 N4D 1.073 ? ? 8 S3D 0.994 ? ? 9 S4F 0.963 ? ?  10 ? ? S3D 0.915  7. Conclusions  We proposed a method of equating interestingness of Causal rules for extracting and comparing both global and local patterns via unified measure Latent trait based on Graded Response Theory. Our approach can help decision makers to compare interestingness of Causal rules. An ad- vantage of this approach is ability of dealing with quanti- tative and categorical items for analyzing global and local patterns in data mining application area. We plan to extend our research for analysis of time series data.

