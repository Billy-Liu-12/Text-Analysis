Research and Improvement of Apriori Algorithm for  Association Rules

Abstract?With the development and the wide application of DBMS, large-scale database system is popularized in daily life.

Data mining is a process of fetching valuable or important information from magnanimous database. Association rules mining is one important research topic of data mining area.

Above all most important of all is research on increment association rules mining. In order to renew association rules effectively, the paper introduces the idea of Apriori algorithm; meanwhile it has already analyzed the classic association rule algorithm FUP and IUA, it pointing out its advantages and disadvantages. Finally, it also gives narrative to another improved NIUP and NFUP algorithm. NFUP algorithm joins strong large itemsets into small quantitative of candidate itemsets based on strong large itemsets concept, and adopts early pruning strategy to cut down the times of scanning database.

Keyword Data mining; Association rule; Apriori algorithm; Frequent item sets; Fast Update(FUP) algorithm

I.  INTRODUCTION The association rule reflects the related relationship  between the database and data item, frequent items are found in association rule mining applications in key technologies and procedures. People have done a lot of research on frequently items? mining algorithm, Apriori[1] algorithm by R. Agrawal which is the most influential and representative. The presentation of these algorithms is the minimum support for mining database and carried out under the same conditions.

However, as time goes on, mining the size of the database may be swelling or need to remove part of the records. Therefore, how to renew the association update rule from the changed data of the database efficiently has a very important value, which called incremental mining association rules.



II. ASSOCIATION RULE AND APRIORI CORE ALGORITHM  A. Description of Association rule The description of the problem: Set I={i1?i2?...?im}  is a collection of m different projects, given a transaction database D, each transaction T in which D is a group of items I set, that is T I, T has a unique identifier TID. If X is a subset of I, and X T, we call a transaction T contains X. An association rule is a implicate of the X=>Y, in which X,Y T, and X?Y=?. The conditions of association rules are set up according to: ?it has a minimum supports, that is, in  transaction database D, there are at least s% of the services included in X?Y; ?it has minimal credibility c, that is, in the transaction database D contains c% of X affairs, also containing Y. Given a transaction sets D, the issue of mining association rules is that have support and confidence given by the user, respectively, greater than the minimum support and minimum confidence of association rules, in other words, generate a strong rules. Mining association rules can be broken down into the following two questions:  ? Identify the smallest degree items supported by all users in database, which is called frequent items, constantly, referred as non-frequent items. The number of projects of a project contained is known as the length of the project.

? The use of frequent items generate association rule.

For each frequent items A, if the B A, B??, and support(A)/support(B)>minconf, there are association rules B=>(A-B). Most of the research currently focuses on the first question above.

B. Apriori core algorithm Agrawal sets an important way(Apriori algorithm) which  can make a customer transaction database mining of association rule in 1994. Its core is based on two-stage recursive algorithm of frequent items? thinking. Algorithm?s basic idea is to identify all the frequent sets whose emerging is same as predefined minimum support at least. Frequent item generates strong association rule, which must satisfy minimum support and minimum confidence. Apriori ideas is a brief description of the core algorithm is that algorithm has two key steps: connecting step and the pruning step.

? Connecting step: In order to identify the Lk (a frequent k set), a candidate k-items (CK) can be generated by Lk-1 and its connections, which elements of Lk-1 can be connected.

? Pruning step: Ck is a superset of Lk whose members may or may not be frequent, but all the frequent sets are included in Ck. If scanning database, each count of a candidate in Ck can be determined, also Lk(frequent candidates whose count is not less than the minimum support count). However, Ck may be large, its calculation amount also be lots. For compression of Ck, the Apriori may be used: any non-frequent (k-1)-     items can be not subsets of frequent k-items.

Therefore, if (k-1) items of a candidate k-items is not in Lk, then the candidate can not be frequent, which can be deleted from Ck. This test of subsets can be finished rapidly by using all frequent items of the hash tree.

This approach requires repeated scanning the large transaction database, that is, if the frequent items include no more than 20 items, then scanning the transaction database 20 times may be needed, that requires a lot of I/O load. It may generate a large number of candidate sets and need to repeat to scan database, which is the two major shortcomings in Apriori algorithm.



III. INCREMENTAL UPDATE OF ASSOCIATION RULE The association rule reflects the related relationship  among the data of database, of which discovering frequent items for mining association rule is the key technology and steps. People has done a lot of research on frequently items mining algorithm, such as Apriori, AprioriTid algorithm by R.

Agrawal which are the most influential and representative ones. The ways of Algorithm is offered in the same conditions of smallest in the mining database and supports. However, it may be encountered in practice, the size of the database mining is ever-expanding over time or remove the part of record, otherwise it need to adjust the minimum support in order to gather gradually in the interested frequent items. Therefore, how to update the derived association rules from new database is a very important, that is the so-called incremental mining association rules.

Generalized association rule on the issue is the problem to mine new association rule based new DB which can be generated through plus (or minus) updated database db to original database DB. Association Rules of incremental updating has three main issues: ?given minimum support and minimum confidence level, how to generate the db?DB link rules when a new data sets add to the old DB database; ?given minimum support and minimum confidence level, how to generate the DB-db association rules when delete data sets from the old database db; ?given database DB, how to generate a database of association rules in DB when the minimum supports and degree of changed. Two of the more classic algorithm are as follows: FUP and IUA algorithm.

A. The basic idea of FUP algorithm  For any k(k?1) items, if its DB and db are the frequent items, they must be frequent items; if its DB and db are non- frequent items, then they are certain non - frequent items; if it is a frequent items only in the DB(db), its support count should be added to the support of db(DB) in order to determine whether it is the frequent items. FUP[2] algorithm assumptions has been preserved in the found DB frequent items  LiL U ni 1== (n is number of the largest element of L of elements). It needs to a scan DB and db for many times. In the  first scanning, the algorithm scans db at first, the L1 in the db?DB is still credited element L1? in frequent items, and generates a candidate frequent sets C1, whose element for the frequent does not contain in the L1; then scanned DB to determine whether the C1 is the frequent items in the db?DB, and credited element belong to db?DB frequent items to L1?.

Before kth(k>1) scanning, generating Lk-1? with candidate frequent k items Ck by Apriori_Gen function, and remove the element of Lk, that is, Ck=Ck-Lk, pruning Lk, which matching with X? Lk,. If it exists  & Y? Lk-1 ?Lk-1, then X is certainly not frequent k items of the db?DB, it should be deleted in Lk; then scan db, credited remained frequent items of Lk belong to db?DB to Lk', recording support number of Ck in the db; finally scanning DB, records support number of the elements of Ck in DB. When finished scanning, credited element of frequent items of db?DB in Ck to Lk. Algorithm will be finished when Lk and Ck are space-time.

Function Analysis: FUP algorithm using mining results of the original database, i.e. frequent items L, nth scans to DB and db, and finally gets frequent items L? of DB?db, so the efficiency of algorithm FUP is much higher than DHP algorithm and Apriori algorithm. However, FUP algorithm has its disadvantages, although this algorithm uses mining results of the original database sets DB, but when renewing the database, need to repeat scanning the original database DB, matching the candidates, so we will spend a lot of time to deal with the enormous size of the candidates, a waste of time when updating in the association rules of FUP algorithm.

B. the basic idea of IUA algorithm IUA[3] algorithm uses a unique candidate frequent item-  set to generate algorithm iua_gen, that generates smaller frequent items before scanning the DB for each time, thereby enhancing the efficiency of the algorithm. It also requires frequent items i  n i lUl 1==  mined DB in the last time can be  used in this time. Because of the discovery of association rules, it is need to adjust constantly the minimum support and minimum confidence to gather interest in association rules, the result of the algorithm has very important significance. The basic framework of the IUA algorithm is same as Apriori algorithm, need for multi-times scanning database DB scan.

Because of s' <s, all the frequent k items (Lk) in the new minimum support is still frequent items k. Therefore, every time to scan the transaction database D to calculate support count of k candidate items, it would not be necessary to consider again candidate k items of the corresponding Lk. If wish to avoid re-generating the corresponding k candidate items again, we can consider the adoption of a strategy for time against space, as long as preserve (Ck-Lk) in the Apriori algorithm each time. According to this characteristic, IUA algorithm will have divided a new support s' of all frequent k(k?2) items into 3 categories: ? For each frequent k items    c=(i1, i2,..., ik), pj(1?j?k), there is (ij)?L1; ? For each frequent k items c=(i1, i2,...,ik), pj (1?j?k), there is (ij)?L1"; ? For each frequent k items c=(i1, i2,...,ik), there must be two non-empty subsets c1 and c2, making c1?c2=c, c1?c2=?, and c1<L1, c2 <L1". In search of bottom-up process of IUA, kth frequent items generate (k+1)th of all the candidate frequent items, and then calculate degree of support for the candidate frequent items to obtain its frequent items until it is empty.

Function analysis: ? IUA algorithm, same as Apriori algorithm, use primarily the "any non-empty items of one frequent items must be frequent items". According to this nature, for any item i, if i is not any one of j(j<k) element of items, then i must not be element of k-items. In the IUA algorithm step-by-step cycle, each function called an iua_gen through the splicing function will obviously not have been the frequent k-items of k-Project integration for the candidate k- items C3k elements, which increase computing capacity to iua_gen pruning, as well as the time complexity of algorithm.

?In association rule updating, for the k-items mining, IUA algorithm noted that the frequent use of the existence of k- items collection Lk, being not aware of " any non-empty items of one frequent items must be frequent items ", the new arising from the frequent (k-1)- items a collection of items Lk-1' which to be used. IUA has been due to take full advantage of the mining results and the use of an effective candidate frequent items generation method, and the adoption of a strategy for time in space, because this significantly reduces the candidate at all levels of frequent items, which improve the association rules? update efficiency. Because of the limitations of Apriori framework, the main existing drawback is as follows: many times? scanning to the database, and a large number of candidates to be needed.



IV. NIUA ALGORITHM AND NFUP ALGORITHM  A. NIUA algorithm The basic framework of NIUA algorithm is the same as  the IUA agreement algorithm and Apriori algorithm, for k=1,2, , , m, a strategy used to generate candidate k-items Ck, and Ck is to scan the database to determine which k-items are frequent items. The difference between NIUA algorithm and the traditional incremental updating algorithm is as in follows:  ? because s' <s, so all the old minimum s of frequent k- items in the new minimum s' is still under frequent k- items. Therefore, in scanning the database D for each visit to calculate the candidate k-items the support of a few hours, there is no need for the project Lk again.

NIUA algorithm in generating candidate k-items Ck is not including items Lk.

? When NIUA algorithm generates candidate k-items Ck, not only use the existing frequent k-items Lk, but also fully uses new (k-1)-items Lk-1. Compared with the IUA algorithm, NIUA algorithms make good use of the apriori-gen function, repeating the original approach of Lk-1, so NIUA compared with Apriori algorithm has only a limited improved efficiency.

B.  NFUP algorithm The basic idea of NFUP algorithm is similar to the FUP  algorithm. Their difference is shown in follows: FUP algorithm using the original database to set DB mining results, that is, frequent items L?s need for DB and db scan for n times, getting final frequent items L' of DB?db; And algorithm NFUP just scan DB for one time and db for several times. NFUP algorithm can improve efficiency by less scanning to DB's I/O operations. Apriori algorithm for db verifies whether the elements of L is he frequent item of db?DB, and generates the frequent items Ldb, then verifies whether elements of Ldb is the frequent items of db?DB through scanning of DB.

However, the premise of NFUP algorithm is frequent items known metadata DB and the support of elements.

Therefore, the theoretical NFUP efficiency is far more than that of FUP. In order to compare the two algorithms, the actual operation comparison will be shown in below. Hardware environment: the CPU is Intel p4 2.4 GHz; memory is DDR 1.0 GB. Software environment: Windows 2000 Server operation system, a programming language is Matlab 7.1. The original data DB exist in Boolean matrix form, which is nine project including 10 000 record. The new data base has 500 records (about 850 KB). Results? comparison between NFUP and FUP is shown in figure 1, minimum support degree in the 20 percent and 80 percent.

Figure 1 The comparison of the execution time among same database algorithms  From figure 1, for the same database and support circumstances, the execution time of NFUP algorithm is reduced by 50% than FUP algorithm. NFUP algorithm is much fast than FUP algorithm when the support degree in 0.2 and 0.6.



V.  CONCLUSIONS Now some algorithm of some existing frequent items has  some missed questions, such as many candidate items, big space. The algorithm may reduce the mining efficiency when increasing scan db frequent items. Although algorithm is simple, its process carries on more effective pruning. This paper brings in some knowledge about association rule, especially discussing the classic association rule of algorithm and mainly pointing out the analysis and conclusion of the FUP  Minimum support degree  The execution tim e(in seconds)    and the IUA. Also two improved algorithm have been discussed in order to help the study of negative association rules for incremental updating.

