

Abstract- Association rule mining, which is a data mining technique, finds interesting association or correlation relationships among a large set of data items. Current association rule mining tasks can only be accomplished successfully only in a distributed setting, which will require integration of knowledge generated from the multiple data sites. Most existing architectures for mining in such circumstances require massive movement of data resulting in high communication overheads leading to slow response time. These challenges are heightened when we have extremely large data sizes in multiple heterogeneous sites. Moreover, most existing algorithms and architectures are only moderately suitable for real- world scenarios. There is therefore an urgent need for improved architectures that will explore the capabilities of software agents? paradigms in order to improve on the existing systems. This work therefore introduces an adaptive architectural framework that mines association rules across multiple data sites, and more importantly the architecture adapts to changes in the updated database giving special considerations to the incremental database with the X-Apriori algorithm. The results integration agent also adapts to changes in the results sites considering the data size; size of the agents; size of intermediate results; bandwidth, and other computational resources at the data servers. The proposed system promises to reduce communication and interpretation costs, improve autonomy and efficiency of distributed association rule mining tasks.

Keywords: Adaptive Systems, Distributed Association Rule Mining, Distributed Data mining, Distributed Databases, Knowledge Integration, Mobile Agents

I. INTRODUCTION All over the world, hardware development, especially in terms of large space storage has recently enabled many organizations to build large storage database and also collect large volumes of data. Those organizations desire to extract useful information from the ultra large amount of data as traditional methods will be able to handle such data. Association rule mining (ARM), first proposed in [1], tries to find frequent patterns, associations, correlations, or casual structures sets of items or objects in transaction database, relational database, etc. The idea  is to find out the relation or dependency of occurrence of one item based on occurrence of other items. Quite a number of algorithms and architectures have been proposed in this area but none could be seen to fit real- life situations and efficiently respond to unforeseen changes in the system with time.

Distributed data mining (DDM) is the semi-automatic pattern extraction of distributed data sources. Extracting valuable knowledge from raw data produced by distributed parties, in order to produce a unified global model may present various challenges related to either the huge amount of managed data or their physical location and ownership. DDM requires two main decisions about the DDM implementations: A distributed computation paradigm (message passing, remote procedure calls (RPC), mobile agents), and the used integration techniques (Knowledge probing) in order to aggregate and integrate the results of the various distributed data miners.

The new distributed computation paradigm has been evolved as software agents are now widely used. Mobile agents are any relatively autonomous entity able to perform actions in an environment perceived by it. They are threads of control that can trigger the transfer of arbitrary code to a remote computer. Mobile agents? paradigm has several advantages: Conserving bandwidth and reducing latencies while also, complex, efficient and robust behaviors can be realized with surprisingly little code. Mobile agents can be used to support weak clients, allow robust remote interaction, and provide scalability.

Therefore, in this research, we introduce an adaptive distributed association rule mining (DARM) architecture that mines across dynamic and distributed databases while adapting to unforeseen changes in the underlying model and the entire system.



II. LITERATURE REVIEW This section gives a brief review of some important existing works in distributed data mining, distributed association rule mining and other related fields and concepts.

A. Data Mining (DM)  Data mining (DM) has become an important research area [2]. In [3] data mining is defined as a powerful new technology with great potential to help companies focus on the most important information in the data they have collected about the behavior of their customers and potential customers. DM involves the use of sophisticated data analysis tools to discover previously unknown, valid patterns and relationships in large data set.

i. Distributed Data Mining (DDM) Distributed data mining refers to the mining of distributed data sets. The data sets are stored in local databases hosted by local computers which are connected through a computer network [4] & [5]. When data mining is undertaken in an environment where users, data, hardware and the mining software are geographically dispersed, it is called distributed data mining. Typically, such environments are also characterised by heterogeneity of data, multiple users and large data volumes [6]. Data mining takes place at a local level and at a global level where local data mining results are combined to gain global findings. Typical DDM algorithms involve local data analysis from which a global knowledge can be extracted using knowledge integration techniques [7].

Several DDM systems have been proposed in the literature. New methods for mining vast amounts of heterogeneous data from several data sources are emerging all the time [8]. It is widely recognized that the set of association rules can rapidly grow to be unwieldy, especially as we lower the frequency requirements [9].

Many current data mining tasks can be accomplished successfully only in a distributed setting [10]. A recent work EMADS only concentrated on agent based data classification but not agent based association rule mining [11]. In [12] data transfer costs which are estimate of the time needed for data to be transferred from the data site to the DARM server is enormous and it is hard to select an appropriate ARM method when no algorithm fits all.

Also most existing algorithms are only moderately suitable for real-world scenarios [13].  A comprehensive review of issues and challenges in current agent-based DARM has been done in [14].

ii. Categorization of DDM Models  There are predominantly two architectural models used in the development of DDM systems, namely, client server (CS) and software agents. The ?agents? category can be further divided on the basis of whether the agents have the ability to migrate in a self-directed manner or not (i.e. whether the agents exhibit the characteristic of mobility or not). The Client/Server model uses the remote procedure call (RPC) mechanism in the communication between the clients and the server. The major drawback in the CS-based DDM model is that huge amount of data sets migrate form the data sources locations to the DM sever to accomplish the required  DM process. This results into a considerable waste in the network bandwidth and consequently a big increase in latency [15]. The agent-based model is a popular approach to constructing distributed data mining systems and is characterized by a variety of agents coordinating and communicating with each other to perform the various tasks of the data mining process. Agent technology is seen as being able to address the specific concern of increasing scalability and enhancing performance by moving code instead of data and thereby reducing the communication overhead incurred in the CS model. A mobile agent does not waste the bandwidth, because the agent migrates to the server. The agent performs the necessary sequence of operations locally, and returns just the final result to the client. A typical mobile agent-based DDM process begins with a client request for a DM process. The client determines the required data severs for the DM process and multicasts a set of mobile agents data miners MADMs. The MADMs migrate to the data servers and perform the data mining operations locally and return the final results (knowledge) to the client. Finally, the client uses a knowledge integration (KI) program to integrate the DM results from the different MADMs.

B. Association Rule Mining (ARM) ARM is the discovery of associations or connections among objects. Since its inception, association rule mining has become one of the core data-mining tasks and has attracted tremendous interest among researchers and practitioners. ARM is undirected or unsupervised data mining over variable-length data, and it produces clear, understandable results. The frequent itemset is the itemset that is included in at least minsup transactions.

The association rules with the confidence at least minconf are generated in the second step. In [16], there is a border that separates the frequent item sets (FIs) from the infrequent ones- thus, the problem is restricted on finding that border. The Apriori algorithm iteratively identifies FIs in data by employing the ?downward closure property? of itemsets in the generation of candidate item sets, where a candidate (possibly frequent) item set is confirmed as frequent only when all its subsets are identified as frequent in the previous pass.

There have been many algorithms developed for mining frequent patterns, which can be classified into two categories: Candidate-generation-and-test with Apriori and its variants as the most popular, and also Pattern- growth methods with FP-Growth method and its variants.

The Apriori algorithm performs repeated passes of the database, successively computing support-counts for sets of single items, pairs, triplets, and so on. The Apriori algorithm achieves good reduction on the size of candidate sets. However, when there exist a large number of frequent patterns and/or long patterns, candidate generation-and-test methods tend to produce very large numbers of candidates and require many scans of the database for frequency checking. Since, the number of database passes of the Apriori algorithm      equals the size of the maximal frequent itemset, it scans the database k times even when only one k-frequent itemset exists. The major drawback is that if the dataset is very large, the required multiple database scans can be one of the limiting factors of the Apriori algorithm.

Many algorithms have been proposed, directed at improving the performance of the Apriori algorithm, using different types of approaches. A second category of methods, pattern-growth methods, such as FP-growth have been proposed [17]. These algorithms typically operate by recursively processing a tree structure into which the input data has been encoded. FP-growth uses two data structures, the FP-tree and a header table, in which to store the input data. FP-growth is a very fast algorithm but has some drawbacks. The first is that FP- growth can have significant storage requirements as FP- trees are repeatedly generated. Secondly, the large number of links makes it difficult to distribute the tree.

These disadvantages are particularly significant with respect to dense data sets.

C. Agents Agents are defined in [18], as computer software that are situated in some environment and are capable of autonomous action in this environment in order to meet their design objectives. Intelligent agents [18, 19] are defined as agents that can react to changes in their environment, have social ability (communication) and the ability to use computational intelligence to reach their goals by being proactive. Agents are active, task- oriented, modeled to perform specific tasks and capable of autonomous action and decision making. By combining multiple agents, in one system, to solve a problem, the resultant system is a Multi-Agent System (MAS) [18]. These systems are comprised of agents that individually solve problems that are simpler than the overall problem. They can communicate with each other and assist each other in achieving larger and more complex goals. The Foundation for Intelligent Physical Agents (FIPA), is a non-profit making international organization dedicated to promoting the industry of intelligent agents by openly developing specifications to support interoperability amongst agents and agent-based systems.



III. SYSTEM DESIGN A multi-agent based architecture called AMAARMD (Adaptive Multi-Agent Architecture for Association Rules Mining in Distributed Databases) is proposed to handle DARM tasks in an adaptive manner by benefiting from the mobile agent paradigm. Since the size of the data to be migrated in the DARM process is usually huge, our architecture will overcome the communication bottleneck by using intelligent agents? paradigm. The proposed architecture will be characterized by a given distributed data mining task being executed in its entirety using the mobile agents. In general, this can be expressed as m mobile agents traversing n data sources. In the proposed architecture, one mobile agent called MAARM  (Mobile-Agent-Based Association Rule Miner) is deployed to each of the data sites (figure 1).

Figure 1: The Proposed Architecture ? AMAARMD.

The proposed DARM system is not user-initiated as it is with existing systems and architectures, even though it may also be initiated by the user if the need arises. The Distributed Association Rule Mining Initiation Agent (DARMIA) initiates the mining process based on current and prevailing circumstances in the DARM environment.

DARMIA invokes the Association Rule Mining Coordinating Agent (ARMCA), which is the main coordinating agent resident in the agent zone (AZ) of the DARM server. The ARMCA creates the MAARM, which clones itself to each of the data sources. The ARMCA later creates an additional mobile-agent called the Results Integration Coordinating Agent (RICA) for optimization of the knowledge or results integration between all the data sources.

Initiation Stage: Association rule mining is initiated at the DARM Server by the DARMIA depending on the rate at which new transactions are generated at a particular site. The DARMIA monitors all sites in the distributed system for significant increase in database transactions. It does not have to wait for the user to initiate the mining. This is done exactly whenever there is a 5% increase in the number of transactions in a particular data site. For example, if the transactions in a particular data site increases from 1,000,000 to 1,050,000, the DARMIA adaptively initiates a fresh mining process instead of waiting for the user initiation process which may not happen over a period of time.

Association Rule Mining Stage: For the very first mining task, the DARMIA invokes the ARMCA (resident in the agent zone) to multicast MAARMs (Mobile Agent-Based Association Rule Miners) equipped with either the traditional Apriori or the FP- Growth algorithms depending on the size of the data at each data source to quickly generate the frequent item sets. For subsequent mining tasks, the ARMCA deploys the Extended Apriori (X-Apriori) algorithm proposed in this work. The X-Apriori algorithm does not need to  Optional User Initiation      nsSE /=  generate new frequent patterns by doing repeated scans of the entire database again but uses the already known frequent patterns in the previous mining as input for the new task. ARM is performed locally by the MAARMs at each of the data sources concurrently after which the result is kept by the MAARM agent while only the result information is passed to the MARRs (Mobile Agent- Based Result Reporter), which are new agents created by each MAARM, so as to reduce the size of agents and massive data movement in the system. The MARRs report only results information after the mining process to the ARMCA. After this the MARRs are killed by the ARMCA.

Knowledge Integration Stage: Knowledge integration is optimized at the data sources by using a new approach - agent-based distributed knowledge integration (ADKI) as opposed to Incremental Knowledge Integration which does not take into consideration the size of the agent, size of the results, and bandwidth [20]. Formal methods for achieving these are major considerations in this research. Here, the MARRs report the results to the ARMCA at the agent zone. This knowledge or results integration will be carried out by the Results Integration Coordinating Agent (RICA), which is a new single mobile agent created by ARMCA for the purpose of performing the optimized results integration. RICA knows exactly which result j to integrate with result k first, second and so on. RICA integrates the results of two data sources at a time. This process is repeated until all integrated results are resident in a specific data source. Adaptation of results integration agent to prevailing circumstances during knowledge integration at results or knowledge sites was based on the intuitive principle that a new knowledge integration task having the same characteristics as a given number of previous tasks provides a basis for estimating the response time of the new task. The estimation is based on a statistical metric computed over the response times of previous knowledge integration tasks with similar characteristics, except for the first knowledge integration task. This means information about all knowledge integration at various times are kept for future use and similarity matching. The criteria for two or more knowledge integration tasks to be considered similar are defined on the basis of such factors as result size, operating system, processor speed, available percentage of CPU, memory and virtual memory and network bandwidth. The correlation co-efficient is proposed in this work for the similarity matching and estimating the time for knowledge integration at the result sites. Values are between -1 and +1.

The standard error (SE) for the method is: where s is the standard deviation of the sample and n is the sample size.

Results Migration Stage: only the overall integrated mining results are migrated back to the DARM requesting server through the RICA.

A. Modeling the Adaptive Mobile Agent Association Rule Miner (AMAARM)  An agent can be viewed as satisfying an ordered set of goals to achieve some overall objective. The agent takes a sequence of actions in order to satisfy the next goal in the set. Adaptation can be viewed as changing the goal set. The effect of the change can be a new set of actions to achieve the same overall objective as before, or it may even result in a new overall objective if the original objective cannot be achieved anymore in the current environment. In the proposed model, the AMAARM consists of two components, a Mechanism and an Adapter. The Mechanism is the interface of the MAARM to the environment. They contain sensors that periodically sense the environment parameters and report their findings to the Mechanism. It also contains effectors that can take actions to change the environment the agent is in. The Adapter is the component that decides whether adaptation is necessary and if yes, how best to adapt to the current environment. The Mechanism senses the environment through the sensors, analyses them, and creates a view of the environment called a percept. The percept is passed on to the Adapter, which uses it to decide whether adaptation is necessary or not.

If adaptation is needed, a new set of goals is passed on to the mechanism, which then transforms the set of goals into a set of actions to be carried out, and then carries out the actions. The effectors are used to make any environment change specified in an action.

B. Algorithm Consideration for the Proposed Architecture  In the proposed architecture, the very first mining by the system will be based on the state-of-the-art Apriori algorithm [21], which is a breadth-first search algorithm with candidate generation., to test for the comparatively sparse databases. Likewise, the state-of-the-art depth- first search partitioning algorithm pattern growth method, FP-Growth algorithm will also be used for comparatively dense databases [17]. The choice of algorithm to be embedded into mining agent - MAARM by the coordinating agent - ARMCA for the very first mining task would be determined by the size of the dataset at each data site. For the purpose of this work, the entire dataset would fall into two categories: either sparse dataset (data size interval 1) or dense dataset (data size interval 2). Subsequent mining tasks are done with the extended Apriori (X-Apriori) algorithm proposed in this work (figure 2).

Figure 2: Allocation of X-Apriori algorithm for  subsequent mining tasks.

AR MC  X-Apriori  New Transactions at h d i  Frequent Patterns from Each Data  Site assign      Algorithm: X-Apriori function X-Apriori (Dt : a transactional database, s: a support threshold), returns a set of frequent itemsets S;  1: if first_mining then 2: begin: 3: k := 1; (Note that a k-itemset represents a set of k items) 4: F ? an empty set for holding the identified frequent itemsets; 5: generate all candidate k-itemsets from Dt ; 6: while (candidate k-itemsets exist) do 7: determine support for candidate k-itemsets from Dt ; 8: add frequent k-itemsets into F; 9: remove all candidate k-itemsets that are not sufficiently  supported to give frequent k-itemsets; 10: generate candidate (k + 1)-itemsets from frequent k-itemsets  using ?downward closure property?; 11: k:= k + 1; 12: end while 13: KnownFrequentItemsets ? F; 14: return (KnownFrequentItemsets); 15: end if first_mining 16: else 17: if |NewTransactions| = 0.05* |Dt| then 18: Subsequent_mining 19: begin: 20: NewFrequentItemsets:= 0 21: k:= 1 22: NewCandidateSet:= (all 1-itemset) 23: NewFrequentItemsets = FrequentItemsets in  NewCandidateSet 24: While (NewFrequentItemsets ? 0) do 25: determine support for candidate k-itemsets from  NewTransactions ; 26: add frequent k-itemsets into F; 27: remove all candidate k-itemsets that are not sufficiently  supported to give frequent k-itemsets; 28: generate candidate (k + 1)-itemsets from frequent k-itemsets  using ?downward closure property?; 29: NewFrequentItemsets ? F;  30: k:= k + 1; 31: End While 32: NewFrequentItemsets := Max(KnownFrequentItemsets ?  NewFrequentItemsets) 33: KnownFrequentItemsets := NewFrequentItemsets 34: Return all subsets of elements in KnownFrequentItemsets   The X-Apriori algorithm presented here does not have to scan the entire database when new transactions are added to the database. It only adaptively mines the incremental database whenever five percent additional transactions were added to the database. Information about the known frequent item sets is stored at any point in time. The union of this and the new frequent item sets generated from the added transactions gives the frequent item sets in the updated database at any point in time. For subsequent mining, the new frequent item sets generated from the updated database will always become the known frequent item sets. Performance of the system will tremendously improve with time as the system learns and stores relevant information for optimized movement of the integration agent.. Moreover, whenever a data site is down during the mining process. The ARMCA uses the results from the other sites for DKI.

Also, whenever a result site is down during the KI process, the RICA integrates the results of the last site visited with the next result site. If it is the first result site, another instance of RICA is initiated by ARMCA to the next result site. If it is the last result site, the state of RICA in the second to the last result site is returned.



IV. CONCLUSION AND FUTURE WORKS  In this work, an adaptive architecture for mining association rules in distributed databases using mobile agents? scenarios involving two state-of-the-art algorithms and an improved one is proposed. The proposed architecture is adaptive in nature and also system initiated. Efficient integration of mining results at the result sites will also be achieved. This will greatly save data communication costs by drastically reducing movement of massive data in the system. There is no need for the usual massive data movement in global knowledge integration as only the final results are migrated to the DARM server. The architecture ensures that the response time for DARM tasks is improved each time the mining is repeated. The architecture is system initiated and has the capacity of adjusting to current, prevalent and unforeseen circumstances that may arise over time in the life of the system. The system - AMAARMD will be implemented with Java and all agents will be created in JADE environment.  Agent characteristics, agent functionalities, protocols, communication, coordination and co-operation will all be done under JADE, which is a standard agent based development platform that is robust, scalable and secure.

It is believed that the system will  help to discover new, hidden, previously undiscovered patterns in these sites leading to a dynamic improvement in business yield and turnover. Future works will treat details about the adaptivity of the mining agent and the implementation of the architecture proposed in this work.

