A Recommendation Algorithm Using Multi-Level Association Rules

Abstract  Recommendation systems predict user?s preference to suggest items. Collaborative filtering is the most popular method in implementing a recommendation system. The collaborative filtering method computes similarities between users based on each user?s known preference, and recommends the items preferred by similar users.

Although the collaborative filtering method generally shows good performance, it suffers from two major problems - data sparseness and scalability. In this paper, we present a model-based recommendation algorithm that uses multi-level association rules to alleviate those problems. In this algorithm, we build a model for preference prediction by using association rule mining.

Multi-level association rules are used to compute preferences for items. The experimental results show that applying multi-level association rules is effective, and performance of the algorithm is improved compared with the collaborative filtering method in terms of the recall and the computation time.

1. Introduction  Recommendation systems predict a user's preference and suggest items by analyzing the past preference information of users. The data used for recommendation can be stored as a preference matrix that represents each user's preference for each item. The preference of a user can be obtained by either explicit or implicit rating. The explicit rating means that a user provides his or her preference of an item on a numerical scale. Implicit rating means that user's actions such as purchase of an item or the click on a web page is interpreted as preferences.

Items may be a simple set in one level, or may be organized into a hierarchical category structure with multi-levels, like classification of goods in a department store.

The collaborative filtering is widely used as a recommendation algorithm. It first finds users who have similar preference with the target user, and predicts preference of the target user based on preferences of the similar users. GroupLens[9] and Ringo[12] were the first recommendation systems using CF algorithms. GroupLens recommended Usenet news articles based on user?s ratings, and used Pearson correlation as similarity measure. Ringo  recommended music by using weighted average of ratings of restricted number of similar users. Also, there have been many researches for performance analysis and improvement of recommendation systems. Breese[3] compared CF with clustering model and Bayesian model.

Helocker[6] tested various similarity measures including Pearson correlation, Spearman correlation, vector similarity, and entropy. He also applied various weighting schemes such as similarity weighting, significance weighting, and variance weighting. To reduce computing time, dimensionality reduction methods using SVD(singular value decomposition) were proposed by Billsus[2] and Sarwar[11]. Combination of collaborative filtering method with content-based or knowledge-based approach were suggested by Balabanovic[1], Burke[4], and Nguyen[8]. Lin[7] and Sarwar[10] applied association rule mining technique to collaborative recommender systems.

The collaborative filtering is a memory-based algorithm. Although it generally shows good performance when sufficient explicit preference information is given, it suffers from two major problems ? the data sparseness and the scalability. When the number of known preferences is very small ? in other words, the user-item preference matrix is very sparse ? performance of recommendation can be very poor, since it becomes difficult to find similar users. This is a critical problem because in practical applications, such as recommending items in a web shopping mall, the number of known preferences (for example, purchasing an item) is very small compared to the total number of items. Also, due to the similarity computation between users, computation time for recommendation increases as the number of users grows. This scalability problem may also be a critical problem for practical applications with millions of users.

In this paper, we present a model-based recommendation algorithm that uses multi-level association rules to alleviate those problems. In this algorithm, we build a model for preference prediction by using association rule mining. Multi-level association rules are used to compute preference for items that are not covered by the single-level association rules due to the data sparseness. We compared performance of the suggested algorithm with that of the collaborative filtering algorithm and single-level association rule algorithm in terms of the accuracy and the computation time.

2. Recommendation using multi-level association rules  2.1. Association rule mining  Association rule mining is to search for interesting relationships between items by finding items frequently appeared together in the transaction database. If item B appeared frequently when item A appeared, then an association rule is denoted as A ? B (if A, then B). The support and confidence are two measures of rule interestingness that reflect usefulness and certainty of a rule respectively [5].

Support, as usefulness of a rule, describes the proportion of transactions that contain both item A and B, and confidence, as validity of a rule, describes the proportion of transactions containing item B among the transactions containing item A. The association rules that satisfy user specified minimum support threshold (minSup) and minimum confidence threshold (minCon) are called strong association rules.

In our approach, each user?s preference is represented as a boolean vector ? 1 means that the user prefers the item. Then we regard each user?s preference vector as a transaction, and search for association rules among items.

2.2. Recommendation using association rules  Recommendation using association rules is to predict preference for item k when the user preferred item i and j, by adding confidence of the association rules that have k in the result part and i or j in the condition part.

Sarwar[10] used the rule with the maximum confidence, but we used the sum of confidence of all rules in order to give more weight to the item that is associated with more rules.

Recommendation using association rules describes as follows. Let P be the preference matrix of n users on m items. In this matrix, pij is 1 if the user i has preference for the item j, and 0 otherwise. Let A be an association matrix containing confidence of association rules of m items to each other. The matrix A is computed from P. In this matrix, aij is confidence of association rule i ? j. Then the recommendation vector r for the target user can be computed from the association matrix A and the preference vector u of the target user as equation (1). The top-N items are recommended to the target user based on the values in r.

Aur ?= . (1)  2.3. Recommendation using multi-level association rules  In recommendation using association rules, if the amount of available preference information is small, then the number of strong association rules would also be small, and consequently the association matrix becomes very sparse. Actually, in case the purchase data is used as preference of users, the number of applicable association rules is very small because each user usually purchases only small number of items. In this case, it is impossible to predict preference for most of items and performance of recommendation becomes very poor. To overcome this problem, we present a recommendation method using additional information ? the association rules between higher-level categories ? if items are organized into a hierarchical category structure.

We first find the category ci to which the preferred item belongs. If there is a category association rule of the form ci ? cj, then we give certain amount of preference to all items that belong to category cj.

Recommendation using multi-level association rules describes as follows. Let Ck be a category relation matrix that represents the inclusion relation between lower level(k-1) category and higher level(k) category (level 0 category means the item). In this matrix, Ck(i,j) is 1 if category i in level k-1 belongs to category j in level k, and 0 otherwise. Using this matrix, the preference matrix Pk and the preference vector uk of the target user for level k category is computed as follows:  kk CCCPP ????= ...210 (2)  kk CCCuu ????= ...210 (3)  In equation (2), elements of Pk for k? 1 are not binary.

If a user has preference to multiple items in a category, it can be greater than 1. The association matrix Ak for level k category is computed from Pk. It consists of confidence of association rules between categories. Note that all diagonal elements of Ak should be 1 to give preference to other items in the same category the user preferred. In other words, the confidence of association rule ci ? ci is always 1 for level k ? 1. From pre-computed association matrices and category relation matrices, we can compute the recommendation vector r as follows:  ( )1...

=?????++  ???+??=  ? kkkk  ...?  ??  ?T1 T k  T  CCAu  CAuAur (4)  In equation (4), ?k is the weight to preference computing by level k association rules, and the sum of weights is 1. The weights for the best recommendation are determined empirically. Each predicted preference of all level categories is normalized to [0.5, 1] through sigmoid function respectively.

3. Experiment and Results  3.1. Dataset  We used two separate datasets for the experiments. The MovieLens[13] is a set of ratings to movies. The users rated each movie with 0 to 5 integer values. We selected the users who rated at least 20 movies, which become a set of about 100,000 ratings from 943 users on 1682 movies. MovieLens dataset are organized into two levels ? there are 18 categories (genres) as higher level of items (movies). A movie belongs to one or more genres. We assumed that the explicit ratings for items are not generally given, so converted the original ratings into preference of binary form. To reflect user?s rating scale, each rating was converted to 1 if the rating is greater than the user?s average rating, and 0 otherwise.

The KDD Cup 2000[14] domain contains clickstream and purchase data from Gazelle.com, a legwear and legcare web retailer. We selected a set of 2,295 purchase data from 793 users on 253 items. KDD dataset consists of three category levels ? there are 39 items as category level 1 item, and 2 items as category level 2 item. Each level?s item belongs to one of higher level items.

3.2. Experimental method and metric  We divided dataset into 80% of training set and 20% of test set, and averaged the results of 5 trials with different test set (5-fold cross validation). To measure accuracy of recommendation, we hided one preference data for each user in test set and recommended top-N items with highest predicted preference based on remaining preference information. Accuracy is computed as the ratio of correct prediction. If the hided item is actually recommended ? contained within the top-N recommendation list, it?s called hit. We used the Recall, the overall number of hits over the total number of preferred items in test set (the number of ?1?s in matrix P), as the accuracy measure.

The first experiment is the performance comparison between two different methods of applying association rules ? using a rule with the maximum confidence and using the sum of confidences, when more than one association rules are available. The second experiment is the performance comparison among simple frequency method(SF), collaborative filtering method(CF), single- level association rule method(AR+), and multi-level association rule method(MAR). The simple frequency method is the basic recommendation method that recommends the most popular top-N items to all users by counting overall preferred frequencies for each item from the preference matrix. In CF, the cosine similarity was used as a similarity measure, and the number of similar users was set to 20 (which was the best among 10, 20, 30,  40, and 50). In AR+, we used all available association rules because applying higher minSup and minCon to select strong rules make the number of applicable association rules decreased rapidly, and causes poor performance due to sparseness of dataset. In MAR, we used up to level 1 category information for MovieLens dataset and up to level 2 category for KDD dataset. MAR showed better performance as minSup and minCon thresholds for high-level categories are set to higher values. We set both thresholds to 80% for two datasets respectively in this experiment.

In all of experiments, we used N = 10, 20, 30, 40, and 50, as the number of items to be recommended and measured Recall for each N respectively. All experiments were performed on Pentium-4 running at 1.8GHz, 1Gbytes of memory, and Windows 2000 operating systems.

3.3. Results  3.3.1. Applying methods of association rules. We compared the two different methods of applying association rules. AR-MAX is the method of applying the maximum confidence rule, and AR+ is the method of applying the sum of confidence of all available rules. The results show that AR+ outperforms AR-MAX by 20% for MovieLens dataset and by 7% for KDD dataset in all cases of top-N. This result means that the item associated with more rules is more appropriate to recommend.

3.3.2. Performance of various algorithms. Figure 1 and 2 show the results of four different recommendation algorithms for two datasets.

For the MovieLens dataset, when we computed the recommendation vector in MAR, we used ?0 = 0.9 and ?1 = 0.1 as the weight for each level. MAR showed relatively good performance for small values of ?1. From empirical results, We understood that higher level category information (genre) in the MovieLens domain is less closely related to lower level (movie). In Figure 1, the result shows that MAR achieved 2.5%, 1.2%, 1.3%, 1.8%, and 2.0% higher accuracy for each value of top-N compared with AR+. This result shows that the application of multi-level association rules is effective. MAR showed somewhat less performance compared with CF when N is less than 20, but showed higher accuracy by 1.5%, 5.4%, and 8.6% when N is more than 30. Performance of CF becomes relatively poor as N increases because the CF method can?t predict preference of many items due to data sparseness.

Figure 2 shows the result of the KDD dataset. We used ?0 = 0.6, ?1 = 0.3, and ?2 = 0.1 as the weight for each level. MAR outperformed AR+ by average 90% for all top-N and CF up to 43% when N is more than 30. In the      CF method, performance was almost the same when N is more than 30. It also revealed the sparseness problem of CF. Especially, AR+ shows less performance than SF for all top-N. The KDD data set was so sparse that the number of association rules was very small.

0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  Top10 Top20 Top30 Top40 Top50  R ec  al l  SF CF AR+ MAR  Figure 1. Performances of four recommendation algorithms for the MovieLens dataset   0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4  0.45  0.5  Top10 Top20 Top30 Top40 Top50  R ec  al l  SF CF AR+ MAR  Figure 2. Performances of four recommendation algorithms for the KDD dataset  3.3.3. Recommendation time. The computation times for recommendation for 10000 users were 0.501 sec for CF, and 0.011 sec for MAR in case of MovieLens dataset, and 0.072 sec for CF and 0.00037 sec for MAR in case of KDD dataset. The experimental results with 20000 and 30000 users also show that the model-based method MAR took almost constant time, but time of memory-based method CF increases as the number of users grows for two dataset respectively.

4. Conclusion  In this paper, we present a model-based recommendation algorithm that uses multi-level association rules to alleviate the sparseness and scalability problems in memory-based recommendation. In this algorithm, we build a model for preference prediction by using association rule mining. Multi-level association rules are used to compute preferences for items that are  not covered by the association rules between items due to the data sparseness.

Through the experiments using MovieLens and KDD dataset, it is shown that applying multi-level association rules increases recommendation accuracy compared with applying single-level association rules only. The suggested algorithm also shows better performance compared with the basic collaborative filtering as the number of recommendation increases in a sparse environment.

5. References  [1] M. Balabanovi and Y. Shoham, ?Fab: Content-Based, Collaborative Recommendation?, Communication of the ACM, vol. 40(3), 1997.

[2] D. Billsus and M.J. Pazzani, ?:Learning Collaborative Information Filters?, In Proceedings of the Fifteenth  [3] J.S. Breese, D. Heckerman, and C. Kadie, ?Empirical Analysis of Predictive Algorithms for Collaborative Filtering?, In Proceedings of the Fourteenth Annual Conference on Uncertainty in Artificial Intelligence , 1998.

[4] R. Burke, ?Integrating Knowledge-Based and Collaborative filtering Recommender System?, Proceedings of the Conference on Artificial Intelligence for Electric Commerce, 1999.

[5] J. Han and M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaurmann Publishers, 2000  [6] J.L. Herlocker, J.A. Konstan, A. Borchers, and J. Riedl, ?An Algorithmic Framework for Performing Collaborative Filtering?, In Proceedings of the Conference on Research and Development in Information Retrieval , 1999.

[7] W. Y. Lin, S. A. Alvarez, and C. Ruiz, ?Collaborative recommendation via adaptive association rule mining?, Int.

Workshop Web Mining for E-Commerce, 2000.

[8] H. Nguyen and P. Haddawy, ?DIVA: Applying Decision Theory to Collaborative Filtering?, Proceedings of the Conference on Artificial Intelligence for Electric Commerce, 1999.

[9] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J.

Riedl, ?GroupLens: An Open Architecture for Collaborative Filtering of NetNews?, In Proceedings of CSCW, 1994.

[10] B.M. Sarwar, G. Karypis, J.A. Konstan, and J.T. Riedl, ?Analysis of Recommendation Algorithms for E- Commerce?, ACM Conference on Electronic Commerce, 2000.

[11] B.M. Sarwar, G. Karypis, J.A. Konstan, and J.T. Riedl, ?Application of Dimensionality Reduction in Recommender System-A Case Study?, In WebKDD 00-Web-mining for E- Commerce Workshop, 2000.

[12] U. Shardanand and P. Maes, ?Social Information filtering: Algorithms for automating ?word of mouth??, In Proceedings of ACM CHI?95 Conference on Human Factors in Computing Systems, 1995.

