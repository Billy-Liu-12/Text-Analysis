The Application of FP-array in Network Learning Mining

Abstract?For the large visit of the network learning system and the difficulty of analyzing the correlation of learning behaviors, a high-performance mining algorithm based on FP- array is proposed. The paper also analyzes the advantages and disadvantages of FP-max based mining algorithm. This proposed algorithm could be used to the correlated data mining of the network learning behaviors to obtain the visit frequency of the learning resources, which helps to provide important reference to the improve the network learning system.

Keywords-Association Rule; Max Frequent Pattern; Frequent Item Set; FP-array

I. INTRODUCTION With the popularity of computer network, network  learning system attracts more and more users for its resource share, open system and easy collaboration. But there are many personality differences among users such as different learning objectives, different learning abilities, different knowledge base and different learning habits. This increases the difficulty to the construction of network learning resource.

Applying association rules to personality learning could help learners' commonness and personality. We can conclude learners' learning manners and habits by studying the visit manners and frequency of users' access to learning resources; we can make judgment to abnormalities too.

This paper proposes an algorithm based on FP-array for max frequent item sets mining, which can used to study users' behaviors in the network mining learning process. This algorithm could help construct the network learning resource.



II.  FP-MAX BASED ALGORITHM  A.  Basic concept Let the set of items I={I1,I2,?,In}, transaction database  D=<T1,T2,?,Tn>, here T ? I. If X includes K elements and X ? D, X is called k-itemset.

For each X, if its support number is not less than the given threshold value m, X is called Frequent Pattern (FP) or Frequent Item Set (FIS).

If X is an FIS and any of its supersets is frequent, X is Max Frequent Pattern (MFP) or Max Frequent Item Set (MFIS); the set composed of all the MFPs is called Max Frequent Set (MFS).

In Frequent Pattern tree (FP-tree), each node is composed of node name, node count, node list and parent pointer. In order to traverse the tree easily, header table is constructed by item name and item list head. The item list head points to the first node with the same name in FP-tree[1].

B. FP-Max based mining algorithm of FP-Tree The key of FP-Max based mining algorithm is to find all  MFPs and divide this process into FP-Tree construction and FP-Tree mining.

The advantages of this algorithm are: (a) implement the most time-consuming Frequent Item (FI) calculation by a simple search on FP-tree, (b) use divide-and-conquer strategy to create FP-tree for the different prediction sets given by users, and (c) determine FI according to the two given threshold values: confidence degree and length [2].

The disadvantages of this algorithm are: (a) new FIs may be generated and the original FIs may be increased when the minimum support threshold value remains unchanged, and (b) when creating FP-tree, more traversal time is needed during the two scans of the data set [3].



III. MFI MINING ALGORITHM BASED ON FP-ARRAY  A. FP-array construction [4, 5] 1) Matrix construction. Suppose that each column value  of the matrix represents one or more compressed stored records, where there are no duplicate columns in the matrix.

If all transactions refer to N items totally, the length of the column vector is N; if an item occurs in one transaction, the bit will be 1, else it will be 0. Now there are 5 items C1, C2, C3, C4, C5, if the present transactions are C1 and C4, the column vector corresponding to the present transactions is 10010. If there exist the same columns in the matrix, the weight value of the column vector plus 1; add the calculated column vector into the association matrix as a column, the weight value of this column is 1. The weight value of each column represents the occurrence times of the transaction in the database.

2) Calculate the support number of each item. Remove all the rows of non-frequent item according to the given minimum support threshold value; sort FP-array according to the descending order of the support number.

If the item sequence is C1, C2, C3, C4, C5, the transaction database D can be seen in Table I.

?    TABLE I.  TRANSACTION DATABASE D  TD T1 T2 T3 T4 T5 T6 Itemsets C1C2 C2C3C5 C1C4 C1C3C4 C2C3 C2C5  FP-array is as follows:  ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ?  ?  ?               C C C C C  TTTTTTeWeightValuberSupportNum    B. FP-array based algorithm for mining MFIS Sort the support degrees according to the ascending order  and process the sorted items like: (a) calculate the projection matrix B of the item k currently being processed, remove the columns, whose elements are all 0, from the row where item k is in, (b) remove the rows, which are below the row where item k is in and whose support degree count is less than minimum support degree, and (c) merge the same columns and add their weight values.

Suppose that the minimum support threshold value is m, for each column vector Pi of matrix B, if Pi in MFS is not the subset of an element, there are three cases [6, 7]: (a) if counti ?m, add Pi into MFS, where counti is the weight value of Pi, (b) if counti?m and other column vectors Pj includes Pi, add their weight values into counti, and (c) if it is not neither counti ? m nor counti ? m, firstly calculate the items included in Pj and Pi, then calculate the intersection P of Pj and Pi, the weight value of P is the sum of counti and countj; if the weight value of P is larger than or equal to m and P is not the subset of an element in MFS, add P into MFS.

The details of the algorithm are as follows [8-11]: Input: FP-array, the minimum support threshold value m  and the frequent items number M of the transaction database D;  Output: MFS of D; MFS =? (? is null); for(k=M; k?=2; k--) //Process each item k according to the descending order of the //support degree { Calculate the projection matrix B of item k; for(i=1; i?=h; i++) //h is the column number of B if (Pi is not the subset of elements in MFS) //Process each column vector Pi if(Pi.count?=m) //Pi.count is the weight value of the column Pi { MFS = MFS?Pi; if (all Pi are 1)  return; } else //Consider the relationship of the weight values of columns //including Pi and the minimum support number, add Pi into //MFS at the same time; { count = Pi.count; for( j = 1; j <= h; j++ ) if ( i! = j ) and ( Pi	Pj == Pi ) count += Pj.count; if ( count?=m )  {  MFS = MFS?Pi;  if(Pi are all 1)  return; } else //If the weight value of the intersection P is larger than or //equal to m and P is not the subset of elements in MFS, add P //into MFS; { for( j=1; j?=h; j++) if (i != j) { P = Pi	Pj; Calculate the support number Pcount of P; If (Pcount?=m) and(P is not the subset of elements in MFS) MFS = MFS?P; } } } } If all Pi are 1, it means that it's impossible to generate  new MFIS, the mining process is over.



IV. ASSOCIATION OF MINING LEARNING BEHAVIORS  A. Data Processing Table II is the learning behaviors data from 1438 learning  records between March and June in 2010.

TABLE II.  LEARNING BEHAVIORS DATA  User Visited Resource Type Times User1 Text Resource 17 User1 Video Resource 8 User2 Task Driving 14 User2 Follow Me SBS 23 User3 Experiments 7 User3 Chapter Exercises 13 User4 Video Resource 11 User4 Follow Me SBS 16 User4 Combine Examination 5   Obviously, the data above are all the raw data, which are  not convenient to process. We need preprocess the raw data before data mining. After analysis, we know that users are also interested in the study resources of other classes when they are online learning, even if some users only learn about one class. So we should firstly find the learning events whose network learning resource is larger than a given threshold value. Suppose that the threshold value is 2, we can obtain 805 meaningful records after preprocessing the 1438 records in the data table, where there are 322 records with high learning frequency . We also find 9 learning manners which are most frequently used from the preprocessing [12].

Table III shows the 9 learning manners.

TABLE III.  MAIN LEARNING RESOURCES  SourceTypeCode Type MiningCode C1 Text Resource 1 C2 Video Resource 2 C3 Task Driving 3.

C4 Follow Me SBS 4 C5 Experiments 5 C6 Chapter Exercises 6 C7 Combine Exercises 7 C8 Chapter Examinations 8 C9 Combine Examinations 9   We use association rule algorithm to mine the  relationship of different learning behaviors and adopt C# to process it. The mining results of learning behaviors data can be seen in Table IV.

TABLE IV.  PART TRAINING SET FOR NETWORK LEARNING BEHAVIOR MINING  Subject ActionCode DMCodeExSet TD SQL Query C1C3C7 {1,3,7} T1 Create Table C1C4C9 {1,4,9} T2 OOP C3C4C8 {3,4,8} T3 ? ? ? ?  B. Association Rule Mining using FP-array based Algorithm We could obtain 103 training data after processing the  data above, the minimum support degree is 20%. Run FP- array based algorithm program to get the frequent 1-itemsets, sort the frequent 1-itemsets according to the descending order of the support degree and clip the itemsets (which means removing the non-frequent 1-itemsets)[13]. The details of the process are as follows:  1) The file name of the training set is LAI.DAT.

Suppose that the record sum, the width of itemset and the minimum support degree are 103, 9 and 64 respectively.

The candidate itemsets after sorting and clipping are as follows:  {2 4 7 8} {2 4 5 9} {2 4 5 7} {4 7 8}  There will be only 6 1-itemsets:<2>, <4>, <5>, <7>, <8> and <9> left after clipping (the data are resorted).

2) Calculate FP-array. Each column of the matrix represents one or more compressed records after clipping:   3)  Calculate frequent item set. The number of the  calculated frequent itemset is 13: {5} = 81 {9} = 67 {9 5} = 52 {2} = 50 {2 5} = 45 {2 9} = 41 {2 9 5} = 38 {7} = 30 {7 5} = 27 {7 9} = 25 {8} = 20 {8 5} = 12 {4} = 4 If the minimum support degree is 20%, the frequent  itemset number will be 16, where the number of 3-itemsets is 7.

C. Mining Results We use FP-array based algorithm to mine the 14530  learning records between January 2009 and December 2010 in the learning behavior database, and find 5 types of most frequently visited learning resources successfully. Table V shows these 5 types of learning resources.

TABLE V.  MINING RESULTS USING FP-ARRAY BASED ALGORITHM  Type Tag Code C2 Task Driving SBS 2 C3 Video Resource 3 C4 Follow Me SBS 4 C5 Chapter Examination 5 C9 Combine Examination  9    D. Experimental results and Analysis In this experiment, we compare FP-max based algorithm  and FP-array based algorithm. Here CPU is Intel I5 2.7 GHz, the memory is 2 GB, the operation system is Windows7, the test database is LAI database and the program is implemented by C#. LAI database includes 14530 records, which recorded different users' learning behaviors. The performance of FP-array based algorithm and FP-max based algorithm under different minimum support degrees is compared in Fig. 1.

Figure 1.  Performance compare of FP-max based algorithm and FP-array based algorithm  As can be seen from Fig. 1, the mean performance of the proposed algorithm is better than FP-max based algorithm when the itemset is very huge and sparse. In addition, the change amplitude of the proposed algorithm's execution time is very small under different minimum support degrees; the execution time is just 0.4 seconds more when the minimum support degree increases from 1% to 20%. This shows that the proposed algorithm has better stability and scalability [14-15]. The computation of FP-array based algorithm will be very huge when the data set is very dense.



V. CONCLUSIONS FP-array based algorithm proposed in this paper doesn't  need to add new transactions into the transaction database constantly, so the count of the original frequent items or new generated frequent items remains constant when the  2 0 3 45 2 3 41 4 3 0 32 17 17 4 5 45 32 0 3 5 24 7 2 17 3 0 7 26 8 3 17 5 7 0 4 9 41 4 24 26 4 0 2 4 5 7 8 9   ?    ??  ?   ??  ??   ???  ??   ???  ??   ???  ??    ?  ? ?  ??????????????  ? ? ? ? ?  ? ? ? ?   !"#?$%  !"#$???&    minimum support threshold value is unchanged. And the construction of FP-array only needs one scan of the database [16]. We learn from large amount of experiments that the construction of FP matrix doesn't generate many conditional pattern matrixes; it has much higher time efficiency and saves storage space.

