

Influence and Conditional Influence?  -New Interestingness Measures in Association Rule Mining  Guoqing Chen School of Economics and Management  Tsinghua University, Beijing 100084, China  De Liu*, Jiexun Li** * Center for Research on E-Commerce, University of Texas at Austin, TX 78712, USA ** School of Economics and Management, Tsinghua University, Beijing 100084, China  A&UU  This paper diprusses the issues of interestingness in association rule mining. F i i  a rule is possibhl redundant or misleading even if it possesses high degrees of confidence and support. Seeond, Bssociation rules do not r e k t  the ef?& of negatively influential faetn Such problem are related to confidence deviation. In this paper, therefore, two new measures of interestingness, namely influence and conditional influence, are introduced to represent the ef?& of the antecedent on the consequent. Furthennore, the mining algorithm are extended accordingly sueh that certain redundant rules can be eliminated and negatively iaauential des  may be dipeovered.

Kqrwora3  association rule, interestingness, influence, conditional influence  1.  INTODUCTION  Associon rule mining as one of the important aceas of data mining- first introduced by Agrawal et al. [l] and is meant to discover the association between daerent attributes in large databases. An association rule reflects the presence of some sets of items, given the presence of other items, and is of the firm: XsY, where X and Y are two sets of items, XnY=0. Usually, a rule X s Y  can be obtained if its degree of support @supp(XaY)) and degree of confidence (Dcox@bY)) are equal to or greater than the given thresholds, minsupp and mincod. That is, Dsupp(XsY) =  where X is a set of items (or mterchangeably referred to as itemset) in the database T, is the number of transactionS that contain X, and m is the total number of mnsmions in T.

In recent years, many e&& have been made on association rule mining in various ways [2-71. It has been noted that the rules discovered upon the above tiuesholds may not be all usell or meaninfl. Intenzhgness measures as well as domain knowledge are deemed necessary in further filtering the rules so as to discover the knowledge for decision-making [8]. Interedngness covers a spectrum of semantics, and existing studies have addressed a variety of issues and concerns such as redundancy, conflict, novelty, simplicity, improvement, etc. [9-111. This paper, however, focuses on two issues related to confidence deviation and introduces new interestingnessmeasuresintennsofinfluence.

In the first place, a rule may be regarded redundant even if it has high degrea of confidence and support For instanm, consider [AaB hn.+80?!] which meets minsupp and minconf If Dsupp(B) is also SO%, then rule [AsB Dco&80%] can be regarded as a dundant and unintemthg rule for B is independent  IIWI 114 >- & y P  and ea=w = llxyll I llXll2 minconf,  of A. S i a r l y ,  with rule [A-B Dconf;80?!], rule [ A W B Dco&80?h] may not surprise us either. On the other hand, the rules like [A-B Dm+lOO%] or [AaB Dconf=40??!] iook more interesting. In many cases, such a kind of conliden= deviation is more liiely to intrigue us.

Second, association rules do not reflect the effect of negatively  influential facts. A negatively influential rule reflects the decrease in h n f  due to the existence of certain items in the antecedent of the rule. For example, if Dconf(AWB) < DcoflAsB), one may think of C to have a negative effed on the degree of conference for rule A b B ,  as Dconfcould be greater without C, otherwk.

Confidence deviation in association rules has been observed and studied for years. For instance, P-S, defined as Dsupp(XaY) - Dsupdx)Dsupp(Y), is an interestingness measure for rules defined by Shapii in 1991 [12], which represents the difFerence between the real number of transactions containing XY in the database and the expected number based on the assumption of independent events.

Lift, Mt(XqY) = hni7 ,XsY)  / DsuppO, an inmestinpess measure used in Intelligent Minerof IBM [ 131, also called interest or strength in some l i t e m ,  represents the difference between kquences of Y with and without the condition of X. A-V (Added Value), A-V(X=Y) = Dconf(X~Y) - DsupPO, is a similar measure to Lift [14]. Bayado and others intmdud another interesthgness measure, improvement, to eliminate the rules that can be substituted for simpler and stronger ones [15]. Improvement, dehed as impmvement@*Y) = min(VX?cX, Dmr@sY) - Dconqx?~Y)), is meant to promote the strength for all rules.

Though dealing with the cofidence deviation, the presented Influence measures distinguish themselves from others by representing the e m  of the antedent, as well as of the subset of the items in the a n d e n t ,  on the consequent of a rule, in both positive and negative directionS.

2. INFLUENCE AND CONDITIONAL INFLUENCE  2.1 Notions In order to describe the effect of the antecedent on the consequent,  two new interestingness measures, namely influence and conditional influence, are introduced as follows.

Definition 1: Letm = IlX@l,ficylx) =jio??, where X,Yd and XnY=0, the influence of association rule XsY is defined as:  Partly supported by ?Tiation?s Outstanding Young Scientists Funds? ofChina (No. 79925001), the Bilateral Scientific and Technological Cooperation Between China and Flanders (A2) and Tsinghua?s Soft Science Key Project on &Commerce.

0-7803-7293-X/011$17.00 0 2001 lEEE 1440 2001 IEEE International Fuzzy Systems Conference    whmMfi -Y)  can be reganled as the non-mnditional contrast between positive and negative facts, whilem?Q"-W) as the contmst with condition X. The change of the conbast caused by X can reflect the influence of X on Y.

It can be easily seen that the antecedent lacks association with the consequent, when influence equals 0; the antecedent is positively associated with the consequent (positive influence), when influence is positive; and the antecedent is negatively associated with the consequent (negative influence), when influence is negative.

Definition 2: On the condition of X, conditional influence of itemset Z on itemset Y is defined as:  InIuenceG Y J X )  = InJuence(xz, r)-Ijruence& r) = lnJuence(xz r)-lnJuencefl* r)  Lkonf(X2 r)/Dconf&XZ 3 -,U = log Dconffl a r)/Dconf(X 3  Definition 2 states that (1) conditional influence of Z on Y is the difference between influence of X Z  on Y and that of X on Y; (2) h m  conditional influence, it is clear and intuitive to see that influence can reflect confidence deviatiow and (3) especially when X = 0  (given Il0ll= ITl), conditional influence degenerates to influence. That is to say, influence is a special form of conditional influence.

Similar to influence, Z has positive influence on Y with condition X, when influence(Z,qw > 0; Z has negative influence on Y with condition X, when influence(z;y1X) < 0; and Z has no influence on Y with condition X when influence(Z,qX) = 0. Notably, based on conditional influence, which measures the influence of an item or itemset in a rule, decision-makers will be able to identi& items with positive, negative, and no influence, and then screen out interesting des.

2.2 Properties of Influence Property 1: (Negathe Symmetry) the influence of the  antecedent on the negation of the consequent is the negation of the influence of the antecedent on the consequent, i.e.,  Intluen*3~-Muen**Y).

Proof:  Influence@+ +Infuenceps7u  = log f(ylx)l f i .(-y I m + log f ( ~ v ( x ) l f ( y  I x) f ( V  l f r ( -Y )  f ( - U  1 f ( Y )  = logl= 0  U  Property 2: The influence of X on Y changes in accordance with IWI, IlXll, IMI, or 1'11 in the following manner: (1) With others unchanged, influence haeases when llxyll  in-  (2) With others unchanged, influence decreases when  (3) With others unchanged, influence decreases when \yl\  (4) With others unchanged, influence increases when I'll imxeases.

Proof:  increases;  increases;  By definition, we have  Apparently, IlXYll t -Mwce. t ; IN1 t =Influence 4 ; llyll t a ~ u e n c e  .I ; 11 t -Muen= t ; Wl, llxll, IMI, llxrll all change in the same proportion, Muence keeps unchanged.

U  Furthermore, it can be observed that influence is a non-linear function of Dcod. In Fig. 1, the thick curve and the thin one represent, respectively, the change on condition of DsuppO = 0.5 and that on condition of DsuppO = 0.3.

The change of influence is non-hear with the DcomaY).

When influence is positive, the higher the confidence, the the influence i n c p  on the contrary, when influence is negative, the lower the confidence, the faster the influence decreases. Especially, when coddence reaches 1, i.e. the rule becomes a positive logic rule, influence reaches k, when contldence reaches 0, i.e., the rule becomes a negative logic rule, influence reaches --. This change is easy to understand in that an inmaw of fhquency h m  80% to 90% is often considemi more interedng than that h m  50% to 60%, for the former is more seldom encounted and therefore more significant to decision makers.

From the shape of the curves we can see that the curve of Dsupp(X=3W.5 is symmetric with ~ g a r d  to DcOnqX~Y)=50?/6, which means that if Y is distributed in the database with frequency 500/4 with condition X, the change fhm 50% to 40% and that h m 50% to 60% are to the same extent but in the opposite direction.

Furthermore, it can be pmved that the difkrence of influence between the curve of Dsupp(x==Y) = 0.5 and that of Dsupfl=Y)=OS is ked. In this case, the difkence is  0 3/(1-0.3) 0.510-0.5)  1og-  2.: 1 I  -2. -2 5 t Dconf (X=>Y)  Fig. 1 Change of Influence with Dco@aY)     2.3 Influence and Other Measures Muence and Conditional Influence reflect a very different  semantics from other inkzestingness measures.

While Dsupp and Damf, respectively, reflect the significance and  strength of itemsets in the database, influence describes the deviation of confidence. An association rule with high Dsupp and high h n f may not possess high influence.

Like P-S, lift, etc., influence can reflect the association between the antecedent and the consequent of a rule. If t hm does not exist any association, then the rule is considered to be of no interest. But, an advantage of (conditional) influence is that it can measure the influence of not only the antecedent but also the subsets of the items in the antecedent on the consequent.

Furthem% (conditional) influence is advantageous over improvement. Firsf impmvement is a linear hction of confidence, while influence is nonlinear, which can reflect different effects of confidence deviation from di&mt original values (e.g., a change in Dconf fiam 0.5 to 0.6 may be viewed differently than that h m  0.8 to 0.9). N e q M f l 7 Y )  rather thanJ?o is used in influence so as  ' to reflect symmetry.

3. ASSOCIATION RULE MINING BASED ON INFLUENCE  3.1 Influence in Association Rule Mining Consider a rule with three measures in form of:  <X*Y, support, confidence, influence Without loss of generality, positive influence is discussed in the  mining process. That is, given the thresholds, minsupp, minconf and inflevel (iuence level), a rule will be obtained with its Dsupp 2 minsupp and h n f 2  mincoe and will be regarded interesting with its Muence 1 inflevel. Correspondingly, conventional algorithms can be extended by incoprating the influence measures into the mining process as shown in algorithm 1.

Algorithm 1  forall large k-itemsets lb k22 do begin  consequent} ;  end;  Hi={consequents of rules fiom Ik with one item in the  call ap-gemles(lbH,);  procedure ap-gemles(lk: large k-itemset, H,: set of m-item consequents)  if&>m+l) then begin H,,,+i=apriori-gen(H,); forall h,,,+l E H,+i do begin  DconeDsupp (I@hUpp (Ik-h,+i); influence=logwconP( 1 -Dsupp(hmcl))/( 1 - iwconf  2 minconf && influence 2 inflevel) then  output rule (Ik-h,+J + hi+i with support=Dsupp(lk), confidence=Dconfi  D ~ n f ) f l D ~ ~ p p ( h ~ + ~ ) l  else if (Dconf minconf) delete h,,,+l fiom H,+I;  end;  call ap-gemles(lk, H,+i); en&  3.2 Conditional Influence in Association Rule Mining Based upon conditional influence, a rule with a low influential  subset of the antedent is regarded u n i n t e h g  and will be filtered out. More concretely, given a threshold, cinflevel (conditional influence level), the d e  X a Y  whose itemsets of the antecedent are of suificient influence will be regarded as interesting:  where R is the rule set.

Sice Dmnf(=Y) = DsuppolyDsupP(0) =Dsupp(Y), and if  S = X, then intluence(S,\rlX) = influence&Y) = influence(X3Y).

This means that Influence is a special case of Conditional Muence.

Furthenno% the mining algorithm can be extended in an analogous manner to that with Influence.

It is worth mentioning that conditional influence enables us to h d negatively influential rules, which ~ f l ec t  the absence of some itemsets, given the presence of other items. The rule X s Y  whose itemsets of the antecedent are of sufficient negative influence will be regarded as interesting:  m m  (inJuence(S, Y I X  - s)) I cinfevel I o SCXY-S*YER  where R is the rule set.

4. EMPLE AND PRELIMINARY EXPERIMENTS  4.1 An Example Consider a transaction dataset as shown in Table 1. On one hand,  given minsupp=25% and minconHO0/0, eighteen association rules can be discovered h m  the dataset. Further, if inflevel4.1 is imposed, eleven rules, such as pBaD, Dsupp=42.860/4 DcmF60.00?4~ influence=;-O.22], [ W D ,  Dsupp=42.860/6, h1+75.00?/0, influend.OS], etc., are eliminated. Furthermore, given cinflevel=O.l, another two rules, [AB-E, Dsupp=28.57%, Dcot+lOo.OO%, min(influence(S,\rlX-S))=O] and [ h D , Ds~pp-42.86Y' Doot+lOo.W/o, min(infl~ence(S,\rlX-S))=O], are filtered out (if DconflJ=Y)=Dco~=Y)=lW/~ where X'cX, conditional influence is 0).

On the other hand, with threshold cinflevel (minimal negative influence) = -0.15, we can disoover four negatively influential rules, such as P a D ,  Dsupp=42.86%, DConf-60.00?/0, max(iiuence(S,\rlX-S)) = -0.221, etc.

Table 1 Dataset TID I Item Set # I  I A D E  #I ~ A C D E  1     Experiment 1 Experiment 2 Experiment. 3  1000 10000 100000  number of transaction 0.01 0.03 0.05 high middle low  density of data  -A- [inflevel] -.- [cinflevel] Fig. 2 Experiment Results  4.2 Preliminary Experiments Preliminary experiments have been carried out to examine the  measures in relation to the degree of support, density of data and number of transactions (see Fig. 2). The results have revealed that cinflevel can reduce the number of rules rernarkabl~ that the denser the data, the higher the percentage of the eliminated rules; and that the computational complexity of (conditional) influence does not increase as the number of transactions increases.

5 CONCLUDINGREMARKS  In order to describe confidence deviation in association des, two interestingness measures, namely influence and conditional influence, have been introduced in this paper. Respectively, they can desaibe the influence of the antecedent, as well as subsets of the items in the antecedent, on the consequent of a rule. By incorporating the two measures in the mining process, unintemting rules can be eliminated so as to avoid redundant and less influential rules. Moreover, influence can be repFesented in a non-hear manner.

