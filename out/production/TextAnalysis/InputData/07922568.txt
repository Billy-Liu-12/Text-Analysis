2169-3536 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Abstract?With the advent of big data era, complex opti- mization problems with many objectives and large numbers of decision variables are constantly emerging. Traditional research about multi-objective particle swarm optimization (PSO) focuses on multi-objective optimization problems (MOPs) with small numbers of variables and less than four objectives. At present, MOPs with large numbers of variables and many objectives (greater than or equal to four) are constantly emerging. When tackling this type of MOPs, traditional multi-objective PSO algo- rithms have low efficiency. Aiming at these multi-objective large- scale optimization problems (MOLSOPs) and many-objective large-scale optimization problems (MaOLSOPs), we need to explore thoroughly parallel attributes of the particle swarm, and design novel PSO algorithms according to characteristics of distributed parallel computation. We survey the related research on PSO: multi-objective large-scale optimization, many-objective optimization, and distributed parallelism. Based on the aforemen- tioned three aspects, the Multi-Objective Large-Scale Distributed Parallel PSO and Many-Objective Large-Scale Distributed Par- allel PSO methodologies are proposed and discussed, and the other future research trends are also illuminated.

Index Terms?particle swarm optimization (PSO), multi- objective optimization, many-objective optimization, large-scale optimization, distributed parallelism.



I. INTRODUCTION  Many complicated scientific and engineering problems can be transformed into optimization problems. With the contin- uous development of big data technologies, more and more complex optimization problems are emerging, which have relatively more objectives and large numbers of variables. Par- ticle swarm optimization (PSO) can tackle lots of real-world  This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grant No. 61303001, in part by the Special Program for Applied Research on Super Computation of the NSFC-Guangdong Joint Fund (the second phase), in part by the Foundation of Key Laboratory of Machine Intelligence and Advanced Computing of the Ministry of Education under Grant No. MSC-201602A, and in part by the National Supercomputer Centers in Tianjin and Guangzhou. (Corresponding authors: Zhihan Lv, Bin Cao )  Bin Cao, Jianwei Zhao, Shan Yang and Xinyuan Kang are with the School of Computer Science and Engineering, Hebei University of Technology, Tianjin, 300401, China; Key Laboratory of Machine Intel- ligence and Advanced Computing (Sun Yat-sen University), Ministry of Education; Hebei Provincial Key Laboratory of Big Data Calculation, China. (email: caobin@scse.hebut.edu.cn; 201422102003@stu.hebut.edu.cn; 201532103005@stu.hebut.edu.cn; 201522102032@stu.hebut.edu.cn)  Zhihan Lv is with the Department of Computer Science, University College London, 66-72 Gower Street, London WC1E 6EA, United Kingdom. (email: z.lu@ucl.ac.uk)  Xin Liu and Kai Kang are with Hebei University of Technology, Tianjin, 300401, China. (email: xinliu10@163.com; kkang2000@sina.com)  complicated optimization problems [1], especially the non- smooth optimization problems, resulting in more and more attention from the academia and industry. Traditional research on PSO has mainly focused on multi-objective optimization [2], [3], large number of decision variables (we also call this kind of problems large-scale optimization problems which mean the number of decision variables is up to 103 magnitude) [4], distributed / parallel computing [5], respectively. However, research of PSO on ?distributed parallelism + large-scale optimization + multi-objective / many-objective optimization? is relatively rare.

First, in real life, there are a number of multi-objective optimization problems (MOPs) [3] which have large amounts of decision variables and these decision variables may strongly correlate with each other. When tackling these multi-objective large-scale optimization problems (MOLSOPs), traditional PSO has low efficiency. Therefore, designing novel methods of analysis, decomposition and optimization for addressing MOLSOPs is of great significance.

Next, MOPs composed of greater than or equal to four objectives are called many-objective problems (MaOPs) [6].

Traditional PSO algorithms address MOPs mostly according to the Pareto non-dominance in order to obtain the optimal so- lution set [7]. Nevertheless, traditional Pareto non-dominance based methods are not applicable to MaOPs [6]. Therefore, it is extremely urgent to design novel PSO algorithms with the aim of tackling the many-objective large-scale optimization problems (MaOLSOPs).

Third, when the number of decision variables of MOPs is huge and the objective number is large, the time consumption of serial algorithms will be tremendous. In virtue of distributed parallel computing [8], the operation time can be significantly reduced. In addition, PSO has potential high parallel attributes.

Consequently, there is important significance to study dis- tributed parallel PSO algorithms for solving multi- / many- objective large-scale optimization problems (M/MaOLSOPs).

Finally, studying how to use the above algorithms to solve real-life optimization problems is of important significance. In the real world, optimization problems may exist in many fields [9], [10], [11], [12], [13], a certain number of which are very suitable to be resolved through swarm intelligence and evolu- tionary algorithms. Unlike some complex algorithms [14], due to its simple structure, PSO can be easily implemented and is commonly used to tackle complicated optimization problems, such as the 2D plane deployment problem of wireless sensor    2169-3536 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2017.2702561, IEEE Access  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2  networks (WSNs) [15], [16], etc.

In summary, this paper will review related research on PSO  as follows: ? multi-objective large-scale optimization; ? many-objective optimization; ? distributed parallelism.

Based on the above overview, we will propose and discuss the future research trends. The remainder of our paper is organized as follows. Section II describes related research on PSO algorithms for multi-objective large-scale optimiza- tion. Correlated studies of many-objective optimization are illuminated in Section III. Followed in Section IV is the description on distributed / parallel PSO algorithms. Next, the future research trends are proposed and discussed in Section

V. Finally, the conclusion of our paper is provided in Section VI.



II. MULTI-OBJECTIVE LARGE-SCALE OPTIMIZATION  Lots of researchers have studied multi-objective small-scale and single-objective large-scale PSO algorithms [1], [4], [17], however, less attention is paid to multi-objective large-scale PSO algorithms [18], where ?large-scale? means that the number of decision variables is up to 103 magnitude.

Coello et al. [19] proposed a multiple objective PSO (MOPSO), which was on the basis of Pareto non-dominance; Chen et al. [20] studied the local search based multi-objective optimization algorithm. However, the above algorithms did not involve large numbers of variables. To tackle large- scale optimization problems, cooperative coevolution (CC) framework [21] was introduced to PSO [7]. CC framework [21] decomposes a large-scale problem to several small-scale problems, via the ?divide-and-conquer? methodology, and it exhibits relatively better performance for large-scale global optimization problems (LSGOPs). Li and Yao [17] made use of CC framework, and the proposed new cooperative coevolv- ing PSO (CCPSO2) performed well in tackling complicated multimodal single-objective functions with the dimensionality up to 2000. Ling, Li and Cao [22] put forward the graph-based differential grouping. Existing grouping methods applicable to decompose large numbers of variables also include: random grouping [23], Delta method [24], dynamic grouping [17], differential grouping [25], global differential grouping [26], etc. The foregoing methods have been only used to solve the global optimization problems (GOPs) which is single- objective. How to use the foregoing methods to tackle MOPs remains to be studied. Cooperative coevolutionary general- ized differential evolution 3 (CCGDE3) [27] employed fixed grouping to decompose large numbers of variables, which could deal with MOLSOPs with up to 5000 variables. Ma et al. [28] proposed decision variable analyses (DVA), which could optimize 1000-dimensional MOLSOPs. Cao, Zhao et al.

[29] put forward a cooperative coevolutionary multi-objective evolutionary algorithm to tackle MOLSOPs. Nevertheless, the above two methods have not been applied to PSO. By adopting adaptive velocity updating strategy, adaptive velocity PSO (AV-PSO) [30] achieved better performance when optimizing GOPs composed of as many as 4000 variables, yet no further  exploration on MOLSOPs was conducted. Put forward by Qiu et al. [18], by using random grouping, cooperative co- evolution MOPSO (CCMOPSO) could tackle MOLSOPs with 1000 variables. Liang et al. [31] proposed multiobjective dynamic mutli-swarm PSO (DMS-MO-PSO), and applied it to solve bi-objective optimization problems, which could obtain good optimization performance when the number of variables reaches five hundred. PSO has the disadvantage of premature convergence, accordingly, many improvement measures were put forward, such as the following: Jie et al. [32] and Shen et al. [33] studied multiple swarms; Fang et al. [34] considered the interaction strategy; Tang et al. [35] explored the adaptive adjustment of the inertia weight; Li et al. [36] introduced the historical memory strategy, etc. However, the studies mentioned above have not been further explored and extended to MOLSOPs.



III. MANY-OBJECTIVE OPTIMIZATION In MaOPs, the dimensionality of the objective space is  high, the visualization approach [37] of which differs that of MOPs. By means of mapping the high dimensional objective space into a 2D polar coordinate plot, He et al. [37] put forward a visualization method for MaOPs. Moreover, the proportion of non-dominated solutions increases, resulting in low selection pressure in populations containing limited number of individuals and traditional Pareto non-dominance based methods can not make effective selection of solutions.

Li et al. [6] surveyed many-objective evolutionary algo- rithms (MaOEAs) and pointed out that MaOEAs included seven main classes: relaxed dominance based, diversity- based, aggregation-based, indicator-based, reference set based, preference-based, and dimensionality reduction approaches. In the work of [6], the authors also illuminated a multi-objective PSO with preference-based sorting (MOPSO-PS) which was proposed by K.-B. Lee and J.-H. Kim for tackling DTLZ test suite with seven objectives and less than thirty variables, a two-step searching method based on PSO which was presented by H. Hirano and T. Yoshikawa for solving MaOPs with two to ten objectives and five hundred items (variables), and a reference point based multiobjective differential evolution and particle swarm optimization (MDEPSO) which was described by U.K. Wickramasinghe, R. Carrese and X. Li for tack- ling the airfoil design problem with six objectives and ten variables, etc. However, these PSO algorithms, which could solve MaOPs, were serial optimization algorithms and not used for solving many-objective large-scale optimization problems (MaOLSOPs) with up to one thousand variables. Deb et al.

[38] adopted the reference point based approach. Cheng et al.

[39] explored the strategy of reference vector. Wu et al. [40] indicated that preference information can greatly influence the optimization performance. Wang et al. [41] proposed an improved two-archive algorithm (Two-Arch2), which was capable of tackling MaOP with as many as 20 objectives.

Gong et al. [42] devised an objective decomposition based many-objective evolutionary algorithm, which could better ap- proximate the Pareto optimal front by decomposing the MaOP into several subproblems with fewer objectives as well as in- tegrating an aggregated objective to each subproblem. Xiao et    2169-3536 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2017.2702561, IEEE Access  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 3  al. [43] introduced the global ranking based approach. Zheng et al. [44] developed the information separation methodol- ogy, which exploited the convergence information and the distribution information to enhance the selection pressure and the population distribution, respectively. However, the afore- mentioned inspirations have not been combined with PSO.

Hu et al. [45] described the parallel cell coordinate system (PCCS) and applied it to multi-objective PSO. PCCS could be scarcely influenced by the number of objectives [46]. When the number of objectives was no more than ten, regardless of solving MOPs [47] or MaOPs [46], PCCS could achieve good performance. However, its applicability with respect to large numbers of variables requires further study. Zhang et al.

[48] illustrated the clustering based variable analysis method, whose results were more accurate and stable compared with Pareto based DVA [28]. Combined with CC framework and fast tree based non-dominated sorting strategy, MaOLSOPs with up to ten objectives and five thousand variables can be effectively optimized by this method [48], however, PSO was not taken into consideration. Therefor, from the studies mentioned above, we could get a conclusion that the many- objective large-scale PSO might be one of the future focuses in PSO study areas.



IV. DISTRIBUTED PARALLELISM  In usual, the decision variable number of complicated optimization problems is huge, and if only a serial algorithm and a single personal computer are used, it is likely that the complicated optimization problems can not be solved because of memory overflows, etc., or that satisfactory results can not be obtained in tolerable time. At this time, adopting distributed parallel processing techniques [8] will undoubtedly accelerate the resolving speed for the optimization problems.

The foregoing cooperative coevolutionary PSO algorithms has actually implied the ?divide-and-conquer? parallel ide- ology, nevertheless, they are not implemented in parallel in allusion to specific hardware. Only properly designing dis- tributed parallel algorithms according to the characteristics of particular hardware, software, algorithm and optimization problem can exert the potential parallel computing abilities of algorithms and machines to the greatest extent. The parallelism realization approaches incorporate memory sharing parallelism and distributed parallelism, etc. Gong, Chen et al. [8] reviewed distributed evolutionary algorithms (including distributed PSO algorithms) and pointed out that distributed evolutionary al- gorithms were mainly composed of two types of models: population distributed model and dimensionality distributed model. The former is consisted of master-slave model, island model, cellular model, hierarchical model, pool model, etc.; and the latter is composed of coevolution model, multi-agent model, etc. Cheng et al. [49] proposed an algorithm, denoted distributed differential evolution with multicultural migration, in which, the adopted population migration strategy could better maintain the population diversity, whereas PSO was not aimed at. Cao, Zhao et al. [29] presented a distributed algorithm with the help of Message Passing Interface (MPI), however, the integration of PSO required further exploration.

Fig. 1. A roadmap for future research trends.

For single-objective small-scale optimization problems and multi-objective small-scale optimization problems, there have been some distributed parallel PSO researches, which included the works of L. Vanneschi, N. Nedjah, J. Zhang, S.N. Omkar, et al. Dali et al. [50] realized GPU based PSO parallel algo- rithm, and further put forward the distributed version. Tan et al. [51] systematically researched on the GPU implementation of parallel PSO algorithms. Zhang et al. [1] reviewed some parallel PSO algorithms which included the multicore (mul- tiprocessor) based PSO and GPU based PSO algorithms, etc.

Cao, Li, Zhao et al. [52] proposed a Spark-based cooperative co-evolution PSO algorithm. McNabb et al. [53] explored the effect of the population size and communication topology to the optimization performance of PSO, and through represent- ing topology structure by directed graph, discussed selection strategy of topology structures under diverse objective function complexities and communication costs. Gardner et al. [54] came up with a new method SEPSO, which conducted multiple generations of evolution and only partially selected several individuals to perform fitness evaluation. However, the PSO algorithms mentioned above did not make further specialized exploration for M/MaOLSOPs.



V. FUTURE RESEARCH TRENDS We combine the above three types of methods, and present  the future research trends as the following: 1) Multi-objective large-scale distributed PSO algorithms. 2) Many-objective large-scale distributed PSO algorithms. 3) Designing dis- tributed algorithms according to various hardware and soft- ware environments. 4) Applying novel algorithms to tackle real-world MOLSOPs and MaOLSOPs. A feasible research roadmap is illustrated in Fig. 1.

A. Multi-Objective Large-Scale Distributed Parallel PSO  By combining the two kinds of methods mentioned above: multi-objective large-scale optimization and distributed par-    2169-3536 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2017.2702561, IEEE Access  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 4  allelism, the Multi-Objective Large-Scale Distributed Parallel PSO can be proposed. Traditional MOEAs have not focused on addressing the variable decomposition of MOLSOPs and the parallel implementation of algorithms. With the increment of variable number, the problem complexity and optimization time consumption are in growth correspondingly. Optimizing all variables as a whole, traditional serial approaches have low operation efficiency and poor optimization effect. By carrying through analysis, decomposition and grouping of variables, better optimization performance can be achieved following the ?divide-and-conquer? strategy. In order to more efficiently solve MOLSOPs with respect to operation time and opti- mization performance, the distributed parallel structure can be adopted, combined with the multiple population mechanism, more thorough exploration can be conducted to each objec- tive and parallelism resources will be taken full advantage of; meanwhile, by analyzing the large number of variables, variable property can be identified, and variables can be further decomposed through extending the preceding grouping meth- ods, then, optimization of variable groups can be conducted under CC framework; finally, novel multi-objective large-scale distributed PSO algorithms can be devised. We believe that ?large-scale? and ?small-scale? are two relative concepts but not absolute ones. With the developing of distributed and parallel computing technologies, the definition of ?large-scale? will develop and change in the future, and the ?large-scale? at present may be regarded as ?small-scale? in the future. This will bring new opportunities and challenges to the study on Multi-Objective Large-Scale Distributed Parallel PSO.

B. Many-Objective Large-Scale Distributed Parallel PSO  We can present the Many-Objective Large-Scale Distributed Parallel PSO. For MaOPs, the dimensionality of the objective space is relatively high and the population selection pressure is low, thus, traditional Pareto non-dominance based methods are unapplicable. To this issue, we can design new many- objective large-scale distributed parallel PSO algorithms ac- cording to the characteristics of seven kinds of main MaOEAs which are categorized as relaxed dominance based, diversity- based, aggregation-based, indicator-based, reference set based, preference-based, and dimensionality reduction approaches [6]. For instance, the reference set can be considered, nev- ertheless, how to construct and update the reference set and how to estimate the individuals require further exploration. As the individual similarity is low in the high-dimensional space, the neighborhood strategy can be exploited; the adoption of multiple population strategy contributes to full exploration of all objectives and adequate utilization of parallelism resources.

Pareto non-dominance based variable analysis methods are hardly suitable for MaOPs, for which, designing non-Pareto based variable analysis mechanisms will be a research trend.

In addition, the novel many-objective large-scale distributed PSO algorithms can absorb the advantages of the traditional mathematical theories and methods.

C. Designing Distributed Algorithms According to Various Hardware and Software Environments  We can design and implement new distributed PSO al- gorithms based on various hardware and software environ- ments, including various high performance computing (HPC) environments and cloud computing environments. PSO has potential parallel attributes, which facilitate the design of distributed algorithms. Multi-layer structure (e.g. objective, variable group and population individual) may contribute to the comprehensive utilization of computation resources, significantly reducing operation time. Different distributed parallel architectures (e.g. master-slave model, island model, cellular model, hierarchical model, pool model, etc.) have their advantages and disadvantages, hence the selection and combi- nation of different distributed parallel architectures demands experimental study and exploration.

More communication will greatly reduce the operation effi- ciency of the parallel algorithm, and the less communication hardly ensures the optimization performance. Thus, efficient communication topology is a crucial factor to ensure the opera- tion efficiency and optimization performance of the distributed algorithms. In order to ensure the optimization quality, com- munications among distributed computation resources ought to be guaranteed. Specifically, the communication topology needs to be elaborately devised and the communication contents should also be carefully selected.

A candidate distributed parallel architecture is illustrated in Fig. 2, in which, on the basis of multiple populations, variable groups and particle swarm decomposition, a threefold parallel structure is constructed. Specifically, the decompositions can be as follows:  ? The original M/MaOLSOP is decomposed according to the objectives. Each subpopulation optimizes a single objective and a main population is in charge of all objec- tives. Thus, simultaneously, M + 1 populations optimize the target M/MaOLSOP.

? Through analyzing, decomposing and grouping, the large number of variables are separated to multiple groups; accordingly, each population is decomposed to a number of species, each of which corresponds to a variable group.

? Finally, individuals in each species can be further decom- posed to multiple sets, each of which contains one or more individuals and is allocated to a single computation resource.

Additionally, based on a distributed parallel structure, exper- imental simulation can be conducted to construct a specific efficient communication topology.

A viable approach is to use supercomputers for algorithm development and testing. Various heterogeneous computing models are worth exploring, including CPU + GPU, CPU + MIC (Many Integrated Core), etc. Intel?s MIC and some other many-core processor technologies are developed. Intel?s up-to-date Knights Landing Xeon Phi processor, for instance, can be used as a main processor, which differs from the preceding Knights Corner in that the latter can only be used as coprocessors. Both of the foregoing processors can be used for HPC. FPGA (Field Programmable Gate Array) may be    2169-3536 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2017.2702561, IEEE Access  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 5  Fig. 2. Illustration of a distributed parallel architecture.

also useful. In addition, MPI can also be considered, which is a useful programming tool for distributed parallelism. Spark and Hadoop may be potential tools for big data. The new algorithm based on Spark may be one of the future research focuses. The novel algorithm needs to be optimized according to the characteristics of hardware, software, algorithm and optimization problem so as to maximize the potential opti- mization performance of machine and algorithm.

D. Tackling Real-World M/MaOLSOPs  The foregoing algorithms can be applied to address real- world optimization problems. For the real-world applications, we should design and improve the PSO algorithms according to the characteristics of the specific optimization problems.

In the following, we take the WSN deployment problem as an example to elaborate. Traditional research on deployment optimization of WSNs [16] is mainly focused on 2D plane.

However, in fact, real-world WSNs usually exist on com- plicated 3D terrains or in complex 3D spaces. The WSN deployment optimization problems can be transformed into the M/MaOLSOPs. Consequently, using the foregoing algorithms to tackle the deployment optimization problems of WSNs in complicated 3D environments has more practical significance, and we can improve the foregoing algorithms according to the characteristics of specific optimization problems.

In addition, we can explore the use of an approximated separable objective function to replace the original non- separable objective function of optimization problem and we  can also conduct the decomposing operation according to the characteristics of the optimization problem and the priori knowledge.



VI. CONCLUSION  With the fast development of distributed parallel comput- ing technologies and the the coming era of big data, many complicated problems can be transformed into M/MaOLSOPs.

Therefore, the research on distributed parallel PSO for multi- objective and many-objective large-scale optimization has important research significance. In this connection, we sur- veyed related research on PSO algorithms: multi-objective large-scale optimization; many-objective optimization; and distributed parallelism. Then the Multi-Objective Large-Scale Distributed Parallel PSO and Many-Objective Large-Scale Distributed Parallel PSO methodologies are proposed and disscussed, and the other prospective research trends are also presented and discussed. The difference between the MOPs and MaOPs is that the number of objectives is different.

However, the selection of optimization strategies may be different. The research on designing multi-objective large- scale distributed parallel PSO algorithms can be first con- ducted; then, integrating novel variable decomposition and optimization strategies, we can study the many-objective large- scale distributed parallel PSO algorithms for tackling MaOL- SOPs. When the objective number is large and the number of variables is huge, the optimization process will be extremely time-consuming. Based on the distributed parallel strategies,    2169-3536 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2017.2702561, IEEE Access  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 6  the optimization tasks can be allocated to large amounts of computation units, which can effectively improve the running efficiency.

