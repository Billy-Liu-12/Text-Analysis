An Evaluation of Approaches to Classification Rule Selection Frans Coenen and Paul Leng

Abstract In this paper a number of Classification Rule evaluation measures are considered. In particular the authors review the use of a variety of selection techniques used to order classification rules contained in a classifier, and a number of mechanisms used to classify unseen data. The authors demonstrate that rule ordering founded on the size of an- tecedent works well given certain conditions. Keywords: Classification rule evaluation measures.

1. Introduction Classi?cation Association Rule Mining (CARM) is based on the observation that a subset of the Association Rules (ARs) generated by Association Rule Mining (ARM) algorithms can effectively be used for the purpose of clas- si?cation [2]. ARs [1] are rules of the form    where and  (Antecedent and Consequent) are disjoint subsets of a set of binary valued attributes de?ned by the input data set. In the case of Classi?cation Rules (CRs) the variable is a unary subset of a set of classes de?ned with respect to the input data. The notation  and  will be used to indicate respectively the antecedent and consequent (class) of a rule .

Once a classi?er has been established (usually presented in the form of a list of rules), regardless of the methodology used to generate it, there are a number of proposed mech- anisms for using the resulting classi?er to classify unseen data. These can be itemised as follows (given a particular case): 1. Best Rule: Select the ?rst ?best? rule that satis?es the given case according to some ordering imposed on the rule listing. The ordering can be de?ned according to many different ordering schemes, including: (a) CSA: Combinations of con?dence, support and size of antecedent, with con?dence being the most signi?cant factor. Example CARM sys- tems that use CSA ordering include CBA [7], and (only during the early stages of processing) CMAR [6]).

(b) WRA: The weighted relative accuracy which re- ?ects a number of rule ?interestingness? mea- sures as proposed in [5].

(c) Laplace Accuracy Laplace accuracy measures as used in PRM and CPAR [8].

(d)  Testing:  values as used, in part, in CMAR [6].

An alternative to CSA, that has not been considered in the literature to date is to make use of the size of the antecedent as the most signi?cant factor followed by con?dence and support, i.e. ACS ordering.

2. Best  rules: Select the ?rst best K rules that satisfy the given case and then select a rule according to some averaging process as used for example, in CPAR [8].

?Best? in this case is de?ned according to an imposed ordering of the form described in 1.

3. All rules: Collect all rules in the classi?er that sat- isfy the given case and then evaluate this collection to identify a class. One well known evaluation method in this category is Weighted  (WCS) testing as used in CMAR [6].

In this paper we compare the above satisfaction/ordering techniques which are described in some further detail in the following two Sections. The evaluation of the techniques is carried out using a number of sets of CRs, generated us- ing the Apriori-TFPC CARM algorithm which is brie?y re- viewed in Section 4. The evaluation is discussed in detail in Section 5 and some conclusions offered in Section 6.

2. Rule Ordering As noted in the introduction to this paper ?ve different rule ordering strategies are considered here, four established strategies and one new strategy. Each is described in more detail in the following ?ve sub-sections.

(ICDM?04) 0-7695-2142-8/04 $ 20.00 IEEE 2.1. CSA ordering The con?dence-Support framework remains very com- mon amongst current ARM algorithms. Given a CR, , the support for  () is the proportion of occurrences of the set    in the input data compared to the num- ber of records in the input. The con?dence of  ( ) is then given as . CSA (Con?dence, Sup- port, size of Antecedent) ordering is de?ned as follows: 1. Confidence: A rule  has priority over a rule  if       .

2. Support: A rule  has priority over a rule  if    and     .

3. Size of antecedent: A rule  has priority over a rule  if    ,    and     .

Given that con?dence values are normally calculated as real numbers it is unusual to have CRs with identical con- ?dence values other than in the case of ?100% con?dence rules?. Where 100% rules are found the associated sup- ported value ?comes into play?. The size of the antecedent is seldom used in CSA ordering.

It should be noted that CARM algorithms that use the support/con?dence framework, usually also make use of user de?ned minimum support/con?dence threshold val-    ues during the CR generation process. Consequently rules contained in the ?nal classi?er will be such that  and    .

2.2. Weighted Relative Accuracy (WRA) The use ofWRA (Weighted Relative Accuracy) was pro- posed in [5] as a unifying mechanism for determining CR expected accuracy. The idea is that the WRA measure is a synthesis of a number of rule ?interestingness? mea- sures. The WRA for a rule  is calculated using the identity Where relative accuracy is equal to  .

The term ?relative? is used in the sense that the support for a rule is compared with its expected support ? a con- cept not dissimilar to the idea under-pinning  testing. A negative relative accuracy indicates that the accuracy asso- ciated with  is less than the ?xed rule   . So that rules with a low ?generality? (i.e. a low  value) are not given a high accuracy measure the support value for the rule antecedent is used to weight the relative accuracy:   .

2.3. Laplace Accuracy The Laplace expected accuracy estimate, given a rule , is de?ned in [8] as follows:    where  is the number of classes. Note that in this case support is de?ned as the actual number of records (in the training or test set) that contain    or .

2.4.  Testing  testing is a well known statistical technique used to determine whether two variables are independent of one an- other by comparing a set of observed values () against a set of expected values () ? values that would be expected if there were no association between the variables. A value is calculate using the identity:    where  is the number of observed/expected values (this is always  in the case of CARM). If the result is above a given critical threshold value then it can be said that a relationship between the variables exists, otherwise there is no relation- ship. For CMAR a critical threshold value of  was used (this value has also been used in this paper).

2.5. ACS or Specificity ordering In this paper it is proposed that a good alternative order- ing to CSA (as described above) is ACS ordering (size of Antecedent, Con?dence and Support) which is de?ned in a similar manner to CSA (see above) but with size of an- tecedent placed ?rst. The intuition behind this ordering is that more speci?c rules should be ?triggered? before more general rules are attempted. For example we may have a classi?er, ordered using CSA, comprising two rules as fol- lows: # Rule Conf.

1    %  % Given a case  this would be classi?ed, using ?best ?rst? case satisfaction, as belonging to class  when in- tuitively class  would be more likely to be the correct class. ACS ordering thus ensures that speci?c rules have a higher precedence than more general rules so that in the above example the class  would be returned. It should be noted, however, that for ACS to work well a high con?dence threshold value should be used. An appropriate mechanism to prevent overfitting must also be incorporated.

(ICDM?04) 0-7695-2142-8/04 $ 20.00 IEEE 3 Classification In the introduction to this paper three alternative case/record classi?cation mechanisms were identi?ed. Two of these, ?best k? and ? testing? are brie?y discussed be- low so as to provide some necessary further detail (?best ?rst? has the obvious interpretation).

3.1. Best  Testing The intuition behind ?best  testing? is that ?one cannot expect that any single rule can perfectly predict the class label for every example satisfying its body? [8]. Given a    case  to be classi?ed the best  approach is as follows: (1) obtain all rules that satisfy ; (2) keep only best rules for each class, or all rules if there are less than  rules for a particular class; (3) for each group determine some average expected value to be maximised (e.g. con?dence, size of antecedent, Laplace accuracy,  value); (4) Select the class associated with the best average. In [8] a value of was suggested as an appropriate value for.

3.2. Weighted  Testing Weighted  Testing is used in a number of CARM algo- rithms, such as CMAR [6], to classify data by considering entire groups of rules that satisfy a given case. With respect to CMAR, given a case  to be classi?ed, the procedure commences by ?rst collecting all rules that satisfy . Then if the consequents of all rules are identical, or only one rule is found, classify case according to the consequents; other- wise group rules according to class and determine the com- bined effect of the rules in each group (the class associated with the ?strongest group? is then selected). The strength of a group is calculate using the WCS (Weighted  Squared) value. The class associated with the group of rules with the highest WCS value is then selected as the class to be allo- cated to the case.

4. Apriori-TFPC The Apriori-TFPC classi?cation rule generation algo- rithm is founded on the Apriori-TFP (Total From Partial) ARM algorithm [4]1. This algorithm generates frequent sets that are placed as nodes in a set enumeration tree. To eval- uate the above approaches a number of variations of the al- gorithm were created, each re?ecting one of the identi?ed approaches.

Uniquely, in Apriori-TFPC CRs are generated as part of the ?frequent set identi?cation process?. As the tree is 1Apriori-TFP and Apriori-TFPC my be obtained from http://www.csc.liv.ac.uk/ frans/KDD/Software.

developed nodes in branches whose root represents a clas- si?er are tested for their appropriateness as classi?cation rules using a con?dence threshold (to evaluate the different techniques considered in this paper this can equally well be achieved using a  threshold, Laplace accuracy or a WRA measure). If a node represents a suitable CR, the rule is placed in a list and the node not processed any fur- ther. Nodes are also pruned during the generation process according to a user supplied support threshold. This tree pruning is intended to prevent overfitting.

The different ordering and case satisfaction techniques considered in this paper can be combined into eleven differ- ent variations of Apriori-TFPC (see Table 1). With respect to ACS ordering, note that tree pruning is still carried out according to con?dence. In the case of experiments using    ?best K? techniques was set to .

5. Evaluation Experiments were conducted using a range of data sets taken from the the UCI Machine Learning Repository [3].

The chosen datasets were discretized using the LUCS-KDD DN software2, where appropriate continuous attributes were ranged using ?ve sub-ranges. The experiments were run on a 1.2 GHz Intel Celeron CPU with 512 Mbyte of RAM running under Red Hat Linux 7.3.

The ?rst set of evaluations undertaken used a con?- dence threshold value of % and a support threshold value of % (as used in the published evaluations of CMAR [6] and CBA [7]). The results are presented in Table 1 where the best accuracy obtained for each of the data sets is highlighted in bold print. The row labels describe the key characteristics of each data set: for example, the la- bel  denotes the ?adult? data set, which includes 48842 records in 2 classes, with attributes that for the experiments described here have been discre- tised into 131 binary categories.

It should be noted that the datasets were rearranged so that occurences of classes were distributed evenly through- out the datasets. This then allowed the datasets to be divided in half with the ?rst half used as the training set and the sec- ond half as the test set. Although a ?better? accuracy ?gure might have been obtained using Ten-Cross Validation, it is the relative accuracy that is of interest here and not the ab- solute accuracy.

From Table 1 it can be seen that with a % con?dence threshold the proposed ACS ordering worked reasonably well but not as well as was hoped. It is surmised that this is probably because many speci?c rules with relatively low con?dence were given a high precedence over higher con- ?dence but more general rules. The last four columns of 2The LUCS-KDD DN is available at http://www.csc.liv.ac.uk/ ?frans/KDD/Software/LUCS-KDD-DN/.

(ICDM?04) 0-7695-2142-8/04 $ 20.00 IEEE Table 1 show the results of a further set of experiments con- ducted using a con?dence threshold of %. In this case best results were obtained using ?best ?rst? and ACS. ACS with ?best ?rst? also produces the greatest number of best accuracies (10 out of 22). The experiment also illustrated that by reducing the overall number of rules (by increasing the con?dence requirement) the ?best ? approach deteri- orated.

Data Set Best first Best  first All Best first Best  first CSA ACS WRA Lap.  CSA ACS WRA Lap.  WCS CSA ACS CSA ACS adult.D131.N48842.C2 76.1 76.1 65.2 76.1 32.8 76.0 76.3 57.8 76.1 33.7 76.1 80.7 76.1 80.9 76.4 anneal.D106.N798.C6 85.5 85.5 68.4 83.7 59.1 79.4 79.5 69.2 82.2 42.3 80.7 88.0 85.5 89.5 89.5 auto.D142.N205.C7 12.7 19.6 54.9 48.0 19.6 13.7 13.7 32.4 43.1 12.7 20.6 13.7 12.7 12.7 19.6 breast.D47.N699.C2 98.0 98.0 81.1 96.6 83.1 93.4 93.4 72.2 91.7 88.5 98.0 98.0 98.0 98.0 97.1 con4.D129.N67557.C3 65.8 65.8 37.3 65.8 61.1 65.8 65.8 62.4 65.8 65.9 65.8 65.8 65.8 65.9 65.9 glass.D52.N214.C7 49.5 38.3 34.6 46.7 13.1 42.1 42.1 26.2 43.0 13.1 13.1 32.7 36.4 46.7 45.8 heart.D53.N303.C5 49.7 54.3 57.6 55.0 55.0 53.0 53.0 56.3 55.0 55.0 55.0 43.0 54.3 29.8 29.8 hepatitis.D58.N155.C2 71.4 79.2 67.5 79.2 20.8 80.5 80.5 70.1 79.2 28.6 61.0 64.9 79.2 53.2 53.2 horseCol.D94.D368.C2 67.9 78.2 83.7 77.8 62.5 70.7 70.1 78.3 66.8 51.1 62.5 60.9 77.1 47.8 58.7 iono.D172.N351.C2 81.7 91.4 76.0 87.4 84.6 77.1 88.0 62.9 82.9 69.7 62.9 91.4 91.4 66.3 94.3 iris.D23.N150.C3 94.7 94.7 93.3 93.3 93.3 92.0 92.0 93.3 92.0 89.3 94.7 89.3 94.7 88.0 88.0 led7.D24.N3200.C10 67.1 57.2 32.9 66.6 26.0 66.2 66.3 31.9 66.8 19.1 73.8 63.4 64.6 64.1 64.1 letRec.D106.N20000.C26 44.2 34.9 16.9 42.4 28.1 41.0 41.2 8.1 41.3 25.6 38.1 28.6 29.1 28.5 28.4 mushr?m.D127.N8124.C2 96.0 89.1 47.5 46.7 88.4 71.1 69.7 66.9 69.8 85.6 53.1 96.2 89.1 82.0 81.9 nursery.D32.N12960.C5 80.0 74.4 70.6 80.0 70.6 69.8 69.9 70.3 70.6 68.6 85.3 89.6 87.2 87.6 88.3 pageBl?ks.D55.N5473.C5 89.8 89.8 79.6 89.8 3.4 89.8 89.8 68.5 89.8 5.4 2.0 89.8 89.8 89.8 89.8 penDig.D90.N10992.C10 79.5 40.6 33.1 78.1 49.9 54.4 54.8 35.2 55.0 46.8 70.8 83.0 79.3 71.0 71.2 pimaInd.D42.N768.C2 74.2 74.2 76.0 74.5 65.1 71.3 73.7 66.9 70.6 62.0 70.6 76.0 76.8 73.7 73.7 ticTacToe.D29.N958.C2 66.6 66.0 65.8 66.0 65.8 64.3 51.4 54.9 64.9 65.8 78.9 69.1 66.2 55.9 55.7 wave.D108.N5000.C3 66.2 61.1 62.5 66.4 62.5 57.8 58.3 60.0 58.7 60.0 77.6 76.4 67.8 66.0 66.8 wine.D68.N178.C3 70.8 82.0 86.5 92.1 92.1 67.4 67.4 71.9 80.9 84.3 91.0 70.8 83.1 27.0 28.1 zoo.D43.N101.C7 88.0 80.0 54.0 62.0 74.0 70.0 74.0 58.0 62.0 62.0 92.0 86.0 78.0 66.0 66.0 Average 71.6 69.6 61.1 71.6 55.0 66.7 66.9 57.9 68.6 51.6 64.7 70.8 71.9 63.2 65.1 Table 1 Classification accuracy (  )    6. Conclusion In this paper a number of alternative rule ordering and case satisfaction strategies have been considered. Four es- tablished ordering strategies were examined. In addition the authors proposed a ?fth strategy, ACS, where more speci?c rules are given a higher precedence than less speci?c rules (but using con?dence as the most signi?cant factor for tree pruning during the generation process).

The principal ?ndings of the evaluation are as follows: (1) there is no overall best ordering suited to all the data sets used in the experiments, (2) the ?best ?rst? case satisfaction mechanism works better than ?best ? in all the data sets tested, (3) ACS ordering produces the best result provided that a relatively high con?dence threshold is used (a thresh- old of % is suggested), (4) for lower con?dence thresh- olds (% to %) CSA and Laplace ordering coupled with a ?best ?rst? case satisfaction produced good results.

