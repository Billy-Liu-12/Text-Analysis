TRIAS ? An Algorithm for Mining Iceberg Tri-Lattices

Abstract  In this paper, we present the foundations for mining fre- quent tri-concepts, which extend the notion of closed item- sets to three-dimensional data to allow for mining folk- sonomies. We provide a formal definition of the problem, and present an efficient algorithm for its solution as well as experimental results on a large real-world example.

1 Introduction  With the observation that Formal Concept Analysis (FCA) [13, 5], a mathematical theory for deriving concept hierarchies from data, provides an elegant framework for reducing the effort of mining association rules [9, 14, 12], a new research area emerged around 1999 which became known as closed itemset mining in the data mining commu- nity and as iceberg concept lattices in FCA.

Independent of this development, Formal Concept Anal- ysis has been extended about ten years ago to deal with three-dimensional data [8]. This line of Triadic Concept Analysis did not receive a broad attention up to now. With the rise of folksonomies as core data structure of social resource sharing systems, however, the interest in Triadic Concept Analysis increased again.

With this paper, we initiate the confluence of both lines of research, Triadic Concept Analysis and closed item- set mining. In particular, we give a formal definition of the problem of mining all frequent tri-concepts (the three- dimensional version of mining all frequent closed itemsets), and present our algorithm TRIAS for mining all frequent tri- concepts of a given dataset.

The paper is organized as follows. In the next section, we introduce folksonomies and social resource sharing sys- tems and motivate our conceptual clustering approach for  this kind of data. In Section 3, we discuss Triadic Formal Concept Analysis and provide in Section 4 a formal defini- tion of the problem of mining frequent triadic formal con- cepts; in Section 5, we introduce our TRIAS algorithm. Sec- tion 6 comes up with a real-world application, the folkson- omy of the bookmark sharing system del.icio.us, and con- cludes with experiments on the effectiveness and efficiency of the algorithm.

2 Motivation: Conceptual Clustering of Folksonomies  Social resource sharing systems on the web, such as the shared photo gallery Flickr1, the bookmarking system del.icio.us,2 or our own system BibSonomy3 (see Figure 1) have acquired large numbers of users within less than two years. The reason for their immediate success is the fact that no specific skills are needed for participating, and that these tools yield immediate benefit for each individual user (e.g. organizing ones bookmarks in a browser-independent, persistent fashion), without too much overhead. The core data structure of a social resource sharing system is a folk- sonomy. It consists of assignments of arbitrary catchwords ? called ?tags? ? to resources by users. Thus it consists of three sets U, T, R of users, tags, and resources, resp., and a ternary relation Y between them. Folksonomies have thus one dimension more than typical basket analysis datasets (which consist of the two dimensions ?items? and ?transac- tions?). A formal model for Folksonomies as well as an overview of related work can be found in [6].

Our algorithm solves the problem of frequent closed itemset mining for this kind of data. It will return a tri- ordered set of (frequent) triples, where each triple (A, B, C) consists of a set A of users, a set B of tags, and a set C of re- sources. These triples ? called (frequent) tri-concepts in the  1 http://flickr.com 2 http://del.icio.us 3 http://www.bibsonomy.org  0-7695-2701-9/06 $20.00  ? 2006    sequel ? have the property that each user in A has tagged each resource in C with all tags from B, and that none of these sets can be extended without shrinking one of the other two dimensions. They are thus the three-dimensional version of closed itemsets.

We can additionally impose minimum support con- straints on each of the three dimensions ?users?, ?tags?, and ?resources?. In the dyadic case, they equal the minimum support and minimal length thresholds from association rule mining. By setting higher values, we can focus on the largest conceptual components of the folksonomy before having a more detailed look with lower thresholds.

3 Triadic Concept Analysis  Inspired by the pragmatic philosophy of Charles S.

Peirce with its three universal categories [10], Rudolf Wille and Fritz Lehmann extended Formal Concept Analysis in 1995 with a third category [8]. They defined a triadic for- mal context as a quadruple K := (G, M, B, Y ) where G, M , and B are sets, and Y is a ternary relation between G, M , and B, i. e., Y ? G ? M ? B. The elements of G, M , and B are called objects, attributes, and conditions, resp, and (g, m, b) ? Y is read ?object g has attribute m under condition b?. A triadic concept of K is a triple (A1, A2, A3) with A1 ? G, A2 ? M , A3 ? B, and A1 ? A2 ? A3 ? Y such that none of its three components can be enlarged with- out violating this condition. This is the natural extension of the definition of a formal concept4 to the triadic case.

Lehmann and Wille present in [8] an extension of the theory of ordered sets and (concept) lattices to the triadic case, and discuss structural properties. This approach initi- ated research on the theory of concept trilattices.5 With the rise of social resource sharing systems on the web, triadic data became recently interesting for many researchers. In particular, one needs knowledge discovery and information retrieval methods that are able to handle very large datasets.

In [11], we discussed how to compute association rules from a triadic context based on projections. A first step to- wards truly ?triadic association rules? has been done in [4].

4 The Problem of Mining all Frequent Tri- Concepts  We will now formalize the problem of mining all fre- quent tri-concepts. We start with an adaptation of the notion of ?frequent itemsets? to the triadic case.

Definition 1. Let F := (U, T, R, Y ) be a folkson- omy/triadic context. A tri-set of F is a triple (A, B, C) with A ? U , B ? T , C ? R such that A ? B ? C ? Y .

4 In terms of association rules: a closed itemset together with all its related transactions, see [13, 5] for details. 5 See http://www.bibsonomy.org/tag/triadic+fca  Figure 1. BibSonomy displays bookmarks and bibliographic references simultaneously.

As folksonomies have three dimensions which are com- pletely symmetric, one can establish minimum support thresholds on all of them. The general problem of mining frequent tri-sets is then the following:  Problem 1 (Mining all frequent tri-sets). Let F := (U, T, R, Y ) be a folksonomy/triadic context, and let u-minsup, t-minsup, r-minsup ? [0, 1]. The task of min- ing all frequent tri-sets consists in determining all tri-sets (A, B, C) of F with |A||U| ? u-minsup, |B||T | ? t-minsup, and |C| |R| ? r-minsup.

This is actually a harder problem than the direct adapta- tion of frequency to one more dimension: In classical fre- quent itemset mining, one has a constraint ? the frequency ? only on one dimension (the number of transactions). Thus the equivalent triadic version of the problem would need two minimum support thresholds only (say u-minsupp and t-minsupp). However, this seems not natural as it breaks the symmetry of the problem. Hence we decided to go for the harder problem directly (which equals in the dyadic case the addition of a minimal length constraint on the itemsets).

The lighter version with only two constraints is then just a special case (e. g., by letting r-minsupp:= 0).

As in the classical case, our thresholds are antimonotonic constraints: If (A1, B1, C1) with A1 being maximal for A1 ? B1 ? C1 ? Y is not u-frequent then all (A2, B2, C2) with B1 ? B2 and C1 ? C2 are not u-frequent either. The same holds symmetrically for the other two directions.

With the step from two to three dimensions, however, the direct symmetry between monotonicity and antimonotonic- ity (which results in the dyadic case from the dual order isomorphism between the set of concept extents and the set of concept intents) breaks. All we have in the triadic case is the following lemma which results (via the three quasi- orders defined in Section 3) from the triadic Galois connec- tion [1] induced by a triadic context.

Lemma 1 (cf. [8]). Let (A1, B1, C1) and (A2, B2, C2) be tri-sets with Ai being maximal for Ai ? Bi ? Ci ? Y , for  0-7695-2701-9/06 $20.00  ? 2006    i = 1, 2.6 If B1 ? B2 and C1 ? C2 then A2 ? A1. The same holds symmetrically for the other two directions.

As the set of all frequent tri-sets is highly redundant, we will in particular consider a specific condensed represen- tation, i. e., a subset which contains the same information, namely the set of all frequent tri-concepts.

Problem 2 (Mining all frequent tri-concepts). Let F := (U, T, R, Y ) be a folksonomy/triadic context, and let u-minsup, t-minsup, r-minsup ? [0, 1]. The task of min- ing all frequent tri-concepts consists in determining all tri- concepts (A, B, C) of F with |A||U| ? u-minsup, |B||T | ? t-minsup, and |C||R| ? r-minsup.

Sometimes it is more convenient to use absolute rather than relative thresholds. For this case we let ?u := |U | ? u-minsupp, ?t := |T | ? t-minsupp, and ?r := |R| ?r-minsupp.

Once Problem 2 is solved, we obtain the answer to Prob- lem 1 in a straightforward enumeration as {(A, B, C) | ? frequent tri-concept (A?, B?, C?) : A ? A?, B ? B?, C ? C?, |A| ? ?u, |B| ? ?t, |C| ? ?r}.

5 The TRIAS Algorithm for Mining all Fre- quent Tri-Concepts  Our algorithm for mining all frequent tri-concepts of a folksonomy F := (U, T, R, Y ) is listed as Algorithm 5.1.

A prior version was used for analysing psychological stud- ies [7]. That application varied from TRIAS as it aimed at an iterative pruning of the data set. Furthermore, it did not take into account any frequency constraints.

We let Y? := {(u, (t, r)) | (u, t, r) ? Y }, and we identify U , T , and R with natural numbers, i. e. U = {1, . . . , |U |} (and symmetrically for T , R). In both its outer and its inner loop, TRIAS calls the pairs of sub- routines FirstFrequentConcept((G, M, I), ?) and NextFre- quentConcept((A, B), (G, M, I), ?). These two routines provide an enumeration of all frequent dyadic concepts (A, B) of the formal (dyadic) context (G, M, I). The con- text is passed over as input parameter. FirstFrequentCon- cept returns in (A, B) the first concept of the enumeration.

NextFrequentConcept takes the current concept (A, B) and modifies it to the next concept of the enumeration. This way, we compute all frequent maximal cuboids in the rela- tion Y by consecutively computing maximal rectangles in the binary relations Y? and I , resp, whereas the condition in line 10 of Algorithm 5.1 checks if the rectangle layers form a maximal cuboid. Note that A ? (B?C)Y? trivially holds, because of A = I Y? and (B ?C) ? I . Hence only ??? has to be checked.

6 This holds in particular if the tri-sets are tri-concepts.

TRIAS(U, T, R, Y, ?u, ?t, ?r) Y? := {(u, (t, r)) | (u, t, r) ? Y } (A, I) := FirstFrequentConcept((U, T ? R, Y? ), ?u) repeat  if |I| ? ?t ? ?r then begin (B, C) := FirstFrequentConcept((T, R, I), ?t) repeat  if |C| ? ?r then if A = (B ? C)Y? then output(A, B, C)  until not NextFrequentConcept((B, C), (T, R, I), ?t) endif  until not NextFrequentConcept((A, I), (U, T ? R, Y? ), ?u) Algorithm 5.1: The TRIAS algorithm  FirstFrequentConcept(K, ?) A := ?? B := A?  if |A| < ? then NextFrequentConcept((A, B), K, ?)  endif return (A, B)  Algorithm 5.2: The FirstFreqentConcept function  NextFreqentConcept((A, B), (G, M, I), ?) while defined(i) begin  A := (B ? i)? if |A| ? ? then  D := A?  if B <i D then B := D return true  endif endif i := max(M \ B ? {1, . . . , i ? 1}  end return false  Algorithm 5.3: The NextFreqentConcept function  For computing all (frequent) maximal rectangles in a bi- nary relation, one can resort to any algorithm for computing (iceberg) concept lattices. The enumeration can be done in any convenient way. For the inner and the outer loop, one could use different algorithms for that task.

In our implementation we equipped the NEXTCLOSURE algorithm [3, 5] of the fourth author with frequency pruning for implementing the FirstFrequentConcept and NextFre- quentConcept routines (see Algorithms 5.2 and 5.3, resp.) for both the outer and the inner loop. This algorithm has the advantage that it needs almost only the space for the data in main memory.

0-7695-2701-9/06 $20.00  ? 2006    NEXTCLOSURE computes concepts in lectic order. This means that, for a given concept (A, B), NEXTCLOSURE computes the concept (C, D) whose intent D is the next set after B in the so-called lectic order. The lectic order on sets is a total order and is equivalent to the lexicographic order of bit vectors representing those sets.

To find the next concept we define for B ? M and i ? M : B ? i := (B ? {1, . . . , i ? 1}) ? {i}.

By applying the closure operator X ?? X ?? to B ? i the algorithm computes for a given B the set D := (B ? i)??.

This is the lectically next intent, if B <i D holds, where B <i D means, that i is the smallest element in which B and D differ, and i ? D.

The method NextFrequentConcept adopts this idea and additionally checks if the computed extent A := (B ? i)? fullfills the minimal support criterion before computing the intent D := A?. This is done in line 5 of Algorithm 5.3 by considering the extent A only if it is large enough.

6 Evaluation  In order to evaluate our approach, we have analyzed the popular social bookmarking system del.icio.us. For detect- ing communities of users which have the same tagging be- haviour, we ran the TRIAS algorithm on a snapshot con- sisting of all users, resources, tags and tag assignments we could download (cf. [6]) that were entered to the system on or before June 15, 2004. The resulting folksonomy consists of |U | = 3, 301 users, |T | = 30, 416 different tags, |R| = 22, 036 resources (URLs), which are linked by |Y | = 616, 819 triples.

As a first step, we ran TRIAS on the dataset without re- stricting the minimum supports (i. e., ?u := ?t := ?r := 0).

The resulting concept tri-lattice consists of 246, 167 tri- concepts.

We then investigated the concepts which contain more than one user, tag and resource, i. e., with ?u := ?t := ?r := 2. There were 1, 062 such tri-concepts. Figure 2 shows two examples. They may be exploited further for extracting re- lations between tags or for recommending a user to get in touch with the other one, as they both use the same termi- nology for the same URLs and are thus likely to be on a similar line of thought.

As in the dyadic case, the size of the result may grow exponentially in the worst case. Biedermann has shown in [2] that the concept tri-lattice of the triadic context of size n ? n ? n where only the main diagonal is empty has size 3n. In typical applications, however, one is far from this theoretical boundary. Therefore we focus on empirical evaluations on a large scale real-world dataset.

For measuring the runtime and the number of frequent concepts we have evaluated the performance of TRIAS on the del.icio.us dataset described before. From the base set  A fischer gnat B css design web C http://www.quirksmode.org/  http://webhost.bridgew.edu/etribou/layouts/ http://www.picment.com/articles/css/funwithforms/ http://www.alistapart.com/articles/sprites/  A bibi poppy B women cinema film C http://www.reelwomen.org/  http://www.people.virginia.edu/?pm9k/libsci/womFilm.html http://www.lib.berkeley.edu/MRC/womenbib.html http://www.beaconcinema.com/womfest/ http://www.widc.org/ http://www.wftv.org.uk/home.asp http://www.feminist.com/resources/artspeech/media/femfilm.htm http://www.duke.edu/web/film/pioneers/ http://www.womenfilmnet.org/index.htm#top http://208.55.250.228/  Figure 2. Examples of frequent tri-concepts of del.icio.us         100000 200000 300000 400000 500000 600000  N o.

of se  ts  |Y |  Dec Jan Feb Mar Apr May Jun  Frequent Tri-Concepts  ? ?  ? ?  ? ?  ?  ? Frequent Tri-Sets  + +  + + +  +  + +  Figure 3. Number of frequent tri-sets vs.

number of frequent tri-concepts  we created monthly snapshots as follows. F0 contains all tag assignments performed on or before Dec 15, 2003, to- gether with the involved users, tags, and resources; F1 all tag assignments performed on or before Jan 15, 2004, to- gether with the involved users, tags, and resources; and so on until F6 which contains all tag assignments per- formed on or before June 15, 2004, together with the in- volved tags, users, and resources. This represents seven monotonously growing contexts describing the folksonomy at different points in time. For mining frequent tri-sets and frequent tri-concepts we used minimum support values of ?u := ?t := ?r := 2 and measured the run-time of the im- plementations on a dual-core Opteron system with 2 GHz and 8 GB RAM.

Figure 3 shows the number of frequent tri-concepts ver- sus the number of frequent tri-sets on the logarithmically scaled y-axis, whereas the x-axis depicts the number of  0-7695-2701-9/06 $20.00  ? 2006          100000 200000 300000 400000 500000 600000  tim e  in se  co nd  s  |Y |  Dec Jan Feb Mar Apr May Jun  triadic NEXT CLOSURE  ?  ?  ?  ?  ?  ?  ?  ? TRIAS  + +  + +  + +  +  +  Figure 4. Runtime of triadic NEXT CLOSURE and TRIAS algorithm on del.icio.us datasets  triples in Y ? which grows from 98,870 triples in Dec 2003 to 616,819 in June 2004. What can be seen is the massive increase of frequent tri-sets in June 2004 while the num- ber of frequent tri-concepts grows at a different level. This can be explained when looking further on the size of the tri-concepts found which also grows from month to month, since more and more users appear and start agreeing on a common vocabulary. Especially such large concepts as shown in Figure 2 do not appear until June 2004 but they are responsible for the steep increase of frequent tri-sets.

Overall one can observe that the number of frequent tri- sets of every snapshot is always at least one magnitude of size larger than the number of frequent tri-concepts. Conse- quently, computing frequent tri-sets is much more demand- ing than computing frequent tri-concepts ? without provid- ing any additional information.

A comparison of the speed improvement gained from not computing all tri-concepts with an algorithm like NEXT CLOSURE and afterwards pruning the non-frequent con- cepts but using the TRIAS algorithm for directly mining frequent tri-concepts is shown in Figure 4. The logarith- mically scaled y-axis depicts the runtime of the algorithms in seconds while the x-axis shows again the size of the Y re- lation. One can see that computing all tri-concepts is more than one magnitude more expensive than mining only the frequent tri-concepts one is interested in.

With the results seen we can conclude that the TRIAS algorithm provides an efficient method to mine frequent tri- concepts in large scale conceptual structures.

Acknowledgement. Part of this research was funded by the EU in the Nepomuk project (FP6-027705).

