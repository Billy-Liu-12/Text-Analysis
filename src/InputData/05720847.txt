Application of the Model_Multi based on Apriori algorithm in Supporting System

Abstract?The paper mainly discussed the Application of the  Model_Multi based on Apriori algorithm in Supporting  System of Medical Decision. Model_multi is the exploring  model of the multi-dimension relational rule. It is used to  explore the knowledge from the present database so that the  manager of the hospital can manage the hospital through the  explored knowledge. The Aprior algorithm calculation of the  relational rule is applied to this model. Get multidimensional  association rules by calculate frequently predicate sets, has  good scalability to handle large amounts of data, when the  dimension is not too large, and different values for each  dimension is not too much, multi-dimensional array can  achieve dimensional predicate?s I / O.

Keywords- Apriori algorithm; Model_Multi model;  Multi-dimensional association rule mining model;Supporting  System of Medical Decision;  When we have to mine the data in the data warehouse, By definition, such storage is multidimensional, following the multi-dimensional rational database terminology, we recognize each property of the database or data warehouse of each dimension as a predicate, so that we can mine the multidimensional association rules, here we have established Model_Multi model. Model_Multi model is based on association rules in the multidimensional association rules, multidimensional set of association rules not only consider the link between the item set and also consider dimensional constraints of the items set. Next to work on association rules, each predicate in the rule only appear once, we consider them as not repeated predicates. This  kind of association rules is called inter-dimension association rule.

I? DESCRIPTION OF THE CONCEPTION Assume that the database D, where each record T has  a unique identifier TID, including three parts of the form (Tid, d_inf, item-set); which, Tid is the unique identifier of the record; d_inf is the recording dimension information, it is a m-dimensional vector (d1, ..., dm), and di in dimensional attribute called Di on the value set is item-set. Each record in each dimension Di, all take a single value. Each dimension Di corresponds to one-dimensional word called pi, it can be dimensional name.

Multidimensional association rules has the following form: p1(X?v1) ? p? ? k(X?vk) q(X? ?v1) ?  q(X?v2)  (s%? c%)   ? p1(X ? v1) ? p? ? k(X ? vk) ?  q(X ? v) (s%?c%)   ?  Where, k ? m, s%, c%, respectively, express the supporting degree and the confidence degree of the rules, supporting degree of the rules reflect what percentage of the record should be the rule covered. The confidence degree of the  rules reflect the credibility of the rules.

Type ? contains duplicate predicates, called mixed-dimensional association rules. Type  doe? s not contain duplicate predicates, called inter-dimensional association rules.

First the supporting degree and the confidence degree of the rules should be given separately to meet the minimum supporting degree-Smin and minimum confidence threshold-Cmin, this rule is called strong rules.

DOI 10.1109/ICMTMA.2011.144     Satisfy the minimum supporting threshold is called frequent predicate sets.

In this paper, we use 10502 records from the database of the hospital to run model Model_Multi, in the multi-dimensional association rules mining, we do not like before, just one-dimensional association rule mining searches in the frequent item sets, but we search frequent predicate sets. K-predicate set is one set that include k conjunctive predicates. We use a similar approach with the Apriori algorithm demand multidimensional frequent predicate sets, and similar items used set of markers. With Lk to describe the set of the frequent k-predicate sets.

The generational algorithm of the frequent predicate set and the generational algorithm of the frequent item sets are the same. The first step when scanning a database, we calculate all the supporting degree of the single predicate in the database and make not less than the minimum supporting degree-Smin of the predicate set to form single-dimensional frequent predicate sets, called L1.

Then repeat the scanning of the data sets, the first k scans generated when the length k frequent predicate sets called Lk. When the (k +1) th scanning begin, the first length generated from Lk (k +1) candidate set Ck +1 , then based on the minimum support Smin for pruning, removing unqualified candidates predicate set, at last we generate Lk +1, until no frequent item sets generated, the final set of frequent item sets is  Lk. Use the following two properties to prune, to reduce the number of candidates by the predicate set.

The first property: one superset of any non-frequent predicate set must also be non-frequent predicate set.

The second property: one subset of any frequent predicate set must be frequent predicate set.

Multidimensional association rules mining is divided into two parts: first request multidimensional frequent predicate sets, and then generate multidimensional association rules by multidimensional the frequent predicate sets.



II.   GENERATION OF MULTIDIMENSIONAL FREQUENT PREDICATE SET  The following steps to construct frequent predicate  set: 1)  Scan the database once, make the predicate  verbs that not less than the minimum supporting degree Smin to compose single-dimensional frequent predicate set.

2)  Connected step: generate candidates for the predicate set  Find all the different combinations of the set of predicate dimensionality in descending order according to the dimension, and the results for the candidate predicate set called table C. To find Ck, Ck-1 connect with itself to produce the set of candidate k-item set .

3)  Pruning step: generate frequent predicate set L = Ck ? Lk  Ck is a superset of Lk that its members may or may not frequent, but all the frequent k-predicate sets are included in the Ck.

Scan the database to determine the count of each candidate item in Ck , and determine Lk (that is, by definition, the count is not less than the minimum supporting degree count of all the candidate Smin is frequent, and thus belong to Lk).



III. GENERATE FREQUENT PREDICATE SETS BY THE MULTI-DIMENSIONAL ASSOCIATION  RULES Once find the frequent predicate sets from the  transaction of the database D, we can produce their strong association rules according to the sets. For the confidence degree, we can use the following formula, where the conditional probability that count with the predicate support.

Confidence (AB) = P (A | B) = (A ? B). Count / A.count  Which, (A  B). Count is the predicate set A  B ? ? contains the number of records, A.count is the number of records containing A. According to this formula, association rules can be generated:  1)  Predicate for each frequent set L, generate L of all non-empty subset.

2)  For each L, a non-empty subset s, if L.count / s.count ? Cmin, then output Rule "s (L-s)".



IV.  INTRODUCED EXAMPLES In this case the minimum supporting degree Smin =  20%, generate the largest number of predicate sets of 5, that is, the number of predicates.

1)  Generate L1 Find the set of all one-dimensional predicate. All  items are candidate members of C1 to calculate the corresponding support is greater than or equal to the minimum supporting degree Smin.

C1 = (disease, etiology, previous disease history, age, region). When the disease predicate value is 491.901, supporting degree 0.31 ? 0.2, so the disease (491.901,0.31) is frequently 1 - predicate set. The same disease (492.07,0.23), disease (493.903,0.30), disease (519.803,0.34), etiology (1104,0.57), etiology (1106,0.27), etiology (1101,0.35), previous diseased history (o493.903 , 0.60), age (40 ... 50,0.52), region (101,0.60) ... ... are all the frequent 1 - predicate set.

2)   Generate L2 Connection: C2 = L1 ? L1 = ((disease, etiology), (disease,  previous diseased history), (disease, age), (disease, region), (etiology, previous diseased history), (etiology, age), (etiology, region), (previous diseased history, age), (previous diseased history, region), (age, region)).

Pruning: Each predicate correspond to specific value. Scan the  database to determine the C2 set?s supporting degree of each candidate predicate, calculate its supporting degree is> = minimum support Smin, and we should delete which does not meet the conditions, determine the frequent 2 ? predicate verb sets L2, which has minimal supporting degree from the C2 set in the degree of candidate 2 -predicate verb. For example, disease?s values is 491.901, age is 40 ... 50 when the value of supporting degree is 0.26 ? 0.2, so keep in the L2. Last generate L2 = ((disease, 491.901, age 40 ... 50, 0.26), (disease, 491.901, etiology 1104, 0.25), (disease 493.903, past diseased history o493.903, 0.28), (disease, 493.903, region 101, 0.27), (etiology 1101, previous diseased history o491.90110, 0.27), (etiology 1102, region 102, 0.35) ... ...) as shown in  Table 1:  3) Generate L3 As described information above to connect, pruning,  and finally generate L3 shown in Table 2:  4)  C4 = ?, algorithm is terminated, to find all the frequent predicate sets.

According to frequent predicate sets, generate rules.

First of all, calculate reliability according to the formula Confidence (AB) = P (A | B) = (A  B). Count / A.count? .

In this case, specify the minimum confidence degree Cmin = 70%, the output confidence degree is greater than Cmin, rules as shown in Table 3:     According to the above rules may draw the following conclusions:  Disease = chronic bronchitis ? age = 40 ... 50 Disease = chronic bronchitis ?etiology = smoking, Disease = bronchial asthma? previous diseased  history = bronchial asthma, ... ...

Region = Rail East  disease =?  bronchial asthma ?  previous diseased history = bronchial asthma, Previous diseased history = bronchial asthma  ?  disease = bronchial asthma ? region= Rail East, Previous diseased history = bronchial asthma region= ? Rail East ? disease = bronchial asthma,  Previous diseased history=smoking 20 years etiology =smoking? disease = chronic bronchitis,?  Etiology =smoking disease= chronic bronchitis ?  ?Previous diseased history=smoking 20 years, Previous diseased history =smoking 20 years  disease=chronic bronchitis ?Etiology =smoking,? ... ...

From the results above, it can be seen that we can dig a lot of valuable information from the large number of available data, we can dig out the rules to adjust the hospital's work and do some preventive work, For example, in some area, we found a large number of people get such kind of disease, we can carry out prevention of this area, or if we found in a certain period of time the number of such kind of disease has increased, While carry on the prevention, we also have to adjust the hospital drugs management and so on.



V.  CONCLUSIONS This model uses the method similar to Apriori algorithm, calculating multidimensional association rules by the frequent predicate verb set, has good scalability, it can deal with large data, when the number of dimensions is not very large, and different values for each dimension is much, multi-dimensional dimensional array can achieve predicate verb?s I / O. In the practice, the number of frequent predicate sets is not very big, if the maximum length of frequent item sets is k, we need scan the database k+1 times at best. If we scan the database once needs n times I / O operation, the total number of I / O operations is (k +1) n times.

