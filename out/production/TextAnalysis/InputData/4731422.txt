Method of Chinese Grammar rules automatically access based on mining  association rules

Abstract?Grammar rule set is often used in natural language processing. Usually, rule set can only be gained in linguistics materials artificially. In this paper, through study on the using states of grammar rules in natural language processing, we propose a method, with using a typical way of data mining ? mining association rules, of exploring Chinese grammar rules in real corpus environment. And we build Chinese grammar rule database using the rules explored by this method.

Compare the result in this method with the traditional artificial way, we find this method has better availability.

Keywords- chinese grammar;  data mining

I.  INTRODUCTION NLP(Natural Language Process) systems such as  information retrieval, text classification, and machine translation, are all closely related with syntax and lexical analysis. Since relationships is only considered between the neighboring words, Chinese lexical analysis usually can be achieved using the rule-based or statistic-based ways. While, because Chinese grammar structure is relatively complex, analysis of them not only needs to consider non-adjacent words, it is also necessary to consider the sub-structure, with make it is difficult to solve the problem using a simple statistical manner. Thus, Chinese grammar analysis are always involved with rule-based method. However, according to some rules like Zapf Law[1], besides some common rule there also contain a large number of non- common rules. Common rules can be obtained by refer to the research results of linguists, but when facing so many non- common rules and catchwords grammar rules which emerge continually, we need a method to find these rules automatically. This paper aims to study ways of Chinese grammar rules automatic acquisition using related methods in mining association rules, and make the rules available through optimization methods.



II. THE DEFINITION OF CHINESE GRAMMAR RULES  For better expression of grammar rules and make the mining work easier, we made some form of expression provisions. In the academic study, modern Chinese is usually divided into some levels like morpheme, morpheme unit, word, phrases, small sentence, and sentence[2]. Since word  which is made of morpheme and morpheme unit is the smallest independent grammar units used in language, in order to facilitate treatment, this paper will also take the word as the smallest unit of grammar rules, and define grammar rule base on words: a grammar rule is a solid construction of grammar words and filled parts, in which grammar words are the stable parts that support framework of grammar rule, and filled parts are the variable composite in sentences use the grammar rule excepting the grammar words which do not affect the grammar rule, sometimes them can be empty. In accordance with the definition above, grammar rule can be expressed with regular expression like follows:  <grammar rule>:=<filled part>{<grammar word><filled part>}*  <grammar word>:=<word> <filled part>:={<word>}* There are two types of expression for typical grammar  rules, one type use specific words, such as ??????? ?  ????????????stands for filled part? .Another type use POS replace words of same kind, such as ?pronoun?verb?noun?, ?number + noun? ,etc. When analysis Chinese grammar, the latter type is relatively more general, therefore we mainly discuss mining of grammar rules in the latter type.



III. MINING MODEL DESCRIPTION As shown in Figure 1 below, grammar mining model  consist of two knowledge base and three major steps.

In the model, raw corpus is the sentence set in real  language environment, including a large number of sentence of varying length, which contains rich syntax information and is the main target of mining. Grammar rule base is used for grammar rules set storage. Because a lot of I/O operations are needed when using the base, it should be well designed and following points should specifically be noted[3]:  Rule redundancy ? Rule redundancy can be divided into two categories: the rule-contained redundancy and dead-rule redundant. The existence of rule redundancy will affect base?s storage and efficiency. The grammar rule base should have redundant-clear function.

2008 International Symposium on Computer Science and Computational Technology  DOI 10.1109/ISCSCT.2008.68      Figure 1.  Grammar Rules Mining System Model  Rule inconsistent inspection ? In addition to rule redundant, the rules in base may cause a number of inconsistencies, these rules may affect the normal operation of the system and the correctness of the results. Rule inconsistent includes conflict rules, redundant-regulation rules, cycle rule chain, and other types. The base should also have inconsistent-inspection and inconsistent-processing functions.

Process of grammar rule mining from raw corpus, as  shown in Figure 1, includes three main steps: Pretreatment work like choose proper sentences from raw  corpus base and lexical analysis.

Use association rule mining methods, and mine the  original grammar association rules from corpus after step 1.

Use automatic or manual verification methods, find the  real grammar rules which is available from original rules set.

A. Pretreatment on raw corpus We do statistics on a big set of raw corpus about length  of sentence, and select one result as table 1 following: The results above show clearly that: Chinese sentence  usually contains 2 to 11 words, open-test on more sentences shows that sentences with these length occupy majority, about 82%-90% of all. Thus we can restrict the mining object on the set of sentences which contains 2 to 11 words.

For the number of longer sentence which may contains longer syntax rules is so small that those sentences can be ignored. Then do lexical analysis, such as split words and mark POS, on the chosen sentences, and get POS string for further mining.

TABLE I.  RELATIONSHIP BETWEEN LENGTH OF SENTENCE AND SENTENCES COUNT  length of sentence sentences counts 1 6 2 20 3 97 4 318 5 503 6 636 7 523 8 382 9 243  10 150 11 89 12 42 13 32 14 15 15 7 16 4    B. Association rules mining There exists similarity between grammar rule and other  data about exist form[4], thus in theory, we can find grammar rules from sentences through association rule mining methods just like from other data. Firstly, some association rule mining concepts are introduced here[5]. In a service-base D, for each object transaction T(like POS string), assuming X, Y as two different items in the transaction(like words in the POS string), Support or Confidence is often used to quantify the appearance possibility of the data. Support(X) reflects the probability that item X appears in base D. While Confidence(X=>Y) stands for that if there is a rule(like grammar rule) X=>Y, how much is the probability that the transaction T which contains item X contains item Y as well. There are formulas of the two concepts:  support(X=>Y) = support(X?Y) confidence(X=>Y)=support(X?Y)support(X) ?100% if support(X=>Y) equal or larger than minsupport(a  number stands for minimum support, usually according to the number of transactions in the base), and confidence(X=>Y) equal or larger than minconfidence(defined just like minsupport), then rule X=>Y is called strong rule. Strong rule is the final target an rusult in association rule mining work.

There are a lot of association rule mining algorithm, in which we choose Apriori algorithm which is used widely.

Apriori creates new designate item options with the big item set from last loop,  computes the support of options when scans data, and get big item set in the end. It overcome the waste of time and space appears in scanning data which AIS     and SETM algorithm do when they create designate item options, and do a better job than them.

Sentences in real language environment will be transformed to POS string, if take a POS string for a transaction T, sentences in the base can be regarded as transaction set D. Then grammar rules which use POS for word can be expressed as association rule, such as:  Example 1: association rule 1=m ==> 2=q stands for there is a quantity q after a number in position 1 of a sentence. This association rule expresses the grammar rule ?number + quantity?.

Example 2: association rule 1=r ==> 2=v 8=n stands for the grammar rule ?pronoun + verb?noun?  Examples above just reflect one to one relationship between association rule and grammar rule, but there are many problems in real mining work:  Sometimes several association rules reflects the same grammar rule, such as 1=m ==> 2=q and 2=q==> 1=m, they are seemed as difference rules when do mining, in fact they stands for the same grammar rule ?number + quantity?.

If range the mining result with the level of support or confidence, it will appear that many rules are combined, such as 1=n 2=n ==> 4=v, which really reflects the combination of rule ?noun + noun? and ?noun?verb?, and these rules have appeared in a high level rank.

Because of some POS itself has low support, related association rules ranks low in the result. If only high rank rules are selected, the final result probably is the collection of the most common rules and their combinations, which leads to poor result of data mining.

C. Grammar rules mining In order to solve problems exist in association rule  mining, further grammar rule mining should be done base on the result of association rule mining. Usually, there are many-to-one relationships between effective association rules and grammar rules, it means that one grammar rule may come from several association rules. Usefulness of association rule mining result has a close relationship with the sort parameters, besides confidence which is mentioned earlier, there are many sort parameters such as lift, leverage, conviction and so on. Experiments show that leverage is more suitable for two-words rule mining, lift is for more than two words rules, while conviction and leverage are better choices for long sentences which contains long distance rules.

So we combine these parameters and use them in proper situation, raise the method of grammar rule mining base on association rule mining, as following steps:   1) Filtering rules. Before sorting:  There are redundancy and interference in the result, which need to be moved out. First of all, combine association results reflects the same grammar rule, leave only respective position relationship between words, then remove disturbers. Disturbers mainly rise from combination of general grammar rules. Thus if a rule contains only the other simple rules, remove it from the rule set.

2) General grammar rule mining: No matter which sort parameter is chosen, general rules  always  appear in higher position of sort result, so we choose top 20 for target. If the sentence has less than 7 words, leverage is chosen for sort parameter to mining two-word rule, then we put the result into an original rule set S. Lift is chosen for multi-word rules, and put the result into S if they do not in S. With the sentences have more than 7 words and less than 11 words, we first use lift to mine multi-rules, put the result into S if they do not in S. Then confidence is used for long sentences, we put the result into S if they do not in S.

3) Rare grammar rule mining:  Rare grammar rule always appears after general and combination ones in the sort result, and usually has few words. We mainly choose sentences contain less than 7 words for mining and use straightly use leverage-sort for two-words rule mining while lift-sort for multi-words mining.

Results of association rule mining transform to original  grammar rule set S after process above. If grammar rule base already exists, through incremental-adding from S, it will be expanded gradually.



IV. EXPERIMENTS AND RESULTS In order to study how much we can learn about grammar  rule mining from association rule, some experiments are conducted to seek answer. We choose 87 modern Chinese grammar rules from linguistics monographs[6][7][8], research their using condition in real-life corpus, sort them with statistics possibility from high to low, and acquire a basic grammar rule-set. This set is used as normal set and compared with other experiment result. If a rule belongs to normal set, it is called effective rule. We design two experiments below, to test our mining method.

Experiment 1: Effect on mining result with different  corpus  Target: Research what difference the mining results show  with corpus having different source background or different volume.

Corpus 1: 3072 sentences (PKU sentences base) Corpus 2: 836 sentences (net page set A) Corpus 3: 2753 sentences (net page set B) Corpus 4: 22156 sentences (excerpt of novel) Results in Table II:  TABLE II.  EFFECTIVE RULES FROM DIFFERENT CORPUS  Corpus 1 2 3 4  Sentences 3072 836 2753 22156  Effective rule  47 25 34 49         Conclusion: Compare result on corpus with different  volume, we can find that if corpus contains more sentences, more effective rules will be found. While if the difference is corpus background, it show another view. Sentences in PKU base are selected, cover a large number of grammar rules, while net pages and novel are relatively oral corpus, large number of sentences contain only minority general rules. But we find some new rules do not in normal rule-set, which reflects the fact that there are differences between catchphrases rule set and normal rule set.

Experiment 2:  different result mining on different length sentences  Target: Research effect to mining result caused by different sentence length  Corpus 1: 526 sentences contain less than 11 words Corpus 2: 328 sentences contain more than 11words Result : Corpus 1 contains 41 effective rules; corpus 2  contains 18 effective rules Conclusion: Long sentences show worse result than short  ones, for they always contain combine rules of small ones, this made both long and short rule difficult to be found. On the other hand, short sentences have advantage of number, much more than long ones. Thus corpus collection should mainly base on short sentences.



V. CONCLUSIONS AND SUMMARY Feasibility of the method of grammar rule mining base on  association rule mining by our experiments. Technology about use data mining on natural language process also show it?s power by the experiments. Corpus from different background show different rule-set, so our method need corpus contains sentences with same background. If further work shows differences between rule-set, we can do better on combined corpus. In addition, through researches on experiment result, we find that use frequency of rules have statistic relationship with it?s length, further study may shows more about this. Another kind of mining mission use words instead of POS express grammar rules, this kind of  work do help on not only grammar rule mining but also on high level natural language process work such as syntax or semantics, which has high research value too.

Feasibility of the method of grammar rule mining base on association rule mining by our experiments. Technology about use data mining on natural language process also show it?s power by the experiments. Corpus from different background show different rule-set, so our method need corpus contains sentences with same background. If further work shows differences between rule-set, we can do better on combined corpus. In addition, through researches on experiment result, we find that use frequency of rules have statistic relationship with it?s length, further study may shows more about this. Another kind of mining mission use words instead of POS express grammar rules, this kind of work do help on not only grammar rule mining but also on high level natural language process work such as syntax or semantics, which has high research value too.

