Efficient Sanitization of Informative Association Rules with Updates

Abstract-We propose here an efficient data-mining algorithm to sanitize informative association rules when the database is updated, i.e., when a new data set is added to the original database. For a given predicting item, an informative association rule set [16] is the smallest association rule set that makes the same prediction as the entire association rule set by confidence priority. Several approaches to sanitize informative association rules from static databases have been proposed [27]- [28]. However, frequent updates to the database may require repeated sanitizations of original database and added data sets.

The efforts of previous sanitization are not utilized in these approaches. In this work, we propose using pattern inversion tree to store the added data set in one database scan. It is then sanitized and merged to the original sanitized database.

Numerical experiments show that the proposed approach out performs the direct sanitization on original and added data sets, with similar side effects.

Keywords-privacy preserving data mining, informative association rules, maintenance

I. INTRODUCTION  In the past decade, data mining has developed into an important technology of identifying patterns and trends from large quantities of data. Successful applications of data mining have been demonstrated in marketing, business, medical analysis, product control, engineering design and scientific exploration, among others. While all of these applications of data mining can benefit commercial, social and human activities, there is also a negative side to this technology: the threat to data privacy. For example, through data mining, one is able to infer sensitive information, including personal information, or even patterns from non- sensitive information or unclassified data.

Privacy-preserving data mining, is a novel research direction in data mining and statistical databases, where data mining algorithms are analyzed for the side effects they incur in data privacy [25]. There have been two types of privacy concerning data mining. The first type of privacy, called output privacy, is that the data is minimally altered so that the mining result will not disclose certain privacy. Many techniques have been proposed for the output privacy [1],[6]-  TZUNG-PEI HONG Department of Electrical Engineering  National University of Kaohsiung, Kaohsiung, Taiwan Email: t  [9],[20]-[21],[23],[25]. For example, perturbation, blocking, aggregation or merging, swapping, and sampling are some alternation methods that have recently been proposed. The second type of privacy, input privacy, is that the data is manipulated so that the mining result is not affected or minimally affected [10]-[12],[15],[24]. For example, the reconstruction-based technique tries to randomize the data so that the original distribution or patterns of the data can be reconstructed. The cryptography-based techniques like secure multiparty computation allow users access to only a subset of data while global data mining results can still be discovered.

In output privacy, given specific rules or patterns to be hidden, many data altering techniques for hiding association, classification and clustering rules have been proposed. For association rules hiding, three basic approaches have been proposed. The first approach [9], [23], [26] hides pre-selected rules one rule at a time. It first selects transactions that containing items in a pre-selected rule. It then tries to modify transaction by transaction until the confidence or support of the pre-selected rule fall below minimum confidence or minimum support. The modification is done by either removing items from the transaction or inserting new items to the transactions. The second approach [19]-[21] deals with groups of pre-selected restricted patterns or association rules at a time. It first selects the transactions that contain the intersecting patterns of a group of pre-selected restricted patterns. Depending on the disclosure threshold given by users, it sanitizes a percentage of the selected transactions in order to hide the restricted patterns. The third approach [27] deals with hiding certain constrained classes of association rules. Once the proposed hiding items are given, the approach integrates the rule selection process into the hiding process. It hides one rule at a time by calculating the number of transactions required to sanitize and modify them.

However, databases may be updated frequently or occasionally. It is non-trivial to maintain the hidden association rules when the database is updated. New rules and/or already hidden rules may arise and need to be hidden.

In this work, we are interested in improving the efficiency of   Page 331    hiding informative association rules when the transaction database is updated, i.e., when a transaction data set is added to the original database. This problem is referred to as the maintenance of hiding informative association rules.

One possible approach to the maintenance problem is to re- run the hiding algorithms on the whole updated database.

However, this approach has some obvious disadvantage. All the computation done initially at sanitizing the original database is wasted and has to be computed again from scratch.

Therefore, more efficient algorithms for hiding informative association rules, utilizing the information from the old sanitization process, are quite desirable.

In this work, we propose using pattern inversion tree to store the added data set in one database scan. It is then sanitized and merged to the original sanitized database.

Numerical experiments show that the proposed approach out performs the direct sanitization on original and added data sets, with similar side effects.

The rest of the paper is organized as follows. Section 2 presents the statement of the problem and the notation used in the paper. Section 3 presents the proposed algorithm for the maintenance of sanitizing informative association rule sets that contain the specified predicting items. Section 4 shows an example for the proposed algorithm. Section 5 shows the experimental results of the performance and various side effects of the proposed algorithm compared with direct sanitization approach. Concluding remarks and future works are described in section 6.



II. PROBLEM STATEMENT  A. Informative Association Rule Sets The problem of mining association rules was introduced in  [2]. Let I = { i1, ji2 *...*, in } be a set of literals, called items.

Given a set of transactions D, where each transaction T in D is a set of items such that T c I, an association rule is an expression X > Y where X c I Yc I and X n Y = s0. The X and Y are called respectively the body (left hand side) and head (right hand side) of the rule. An example of such a rule is that 90% of customers buy hamburgers also buy Coke. The 90% here is called the confidence of the rule, which means that 90% of transaction that contains X (hamburgers) also contains Y (Coke). The confidence is calculated as X U Y 1/1 X 1, where IX is the number of transactions containing X and IXcAl is the number of transactions containing both X and Y. The support of the rule is the percentage of transactions that contain bothX and Y, which is calculated as X U Y |/N, where N is the number of transactions in D. In other words, the confidence of a rule measures the degree of the correlation between itemsets, while the support of a rule measures the significance of the  correlation between itemsets. The problem of mining association rules is to find all rules that are greater than the user-specified minimum support and minimum confidence.

As an example, for a given database in Table 1, a minimum support of 33% and a minimum confidence of 70%, nine association rules can be found as follows: B=>A (66%, 100%), C=>A (66%, 100%), B=>C (50%, 75%), C=>B (50%, 75%), AB=>C (50%, 75%), AC=>B (50%, 75%), BC=>A(50%, 100%), C=>AB(50%, 75%), B=>AC(50%, 75%), where the percentages inside the parentheses are supports and confidences respectively.

Table 1: Database D TID Items  T | ABC  T2 ABC  T3 ABC  T4 AB  T5 A  T6 AC  However, mining association rules usually generates a large number of rules, most of which are unnecessary for the purpose of prediction. For example, given predicting itemset P = tC for prediction, the rule set that contains only two rules C=>A (66%, 100%), C=>B (50%, 75%), will generate the same predicted itemset Q = tA, B] as the nine association rules found from Table 1. Therefore, an informative association rule set [16] can be informally defined as the smallest association rule set that makes the same prediction as the entire association rule set by confidence priority.

Formally, given an association rule set R and a predicting itemset P, we say that the prediction for P from R is a sequence of items Q. Using the rules in R in descending order of confidence generates the sequence of Q. For each rule r that matches P (i.e., for each rule whose antecedent is a subset of P), each consequent of r is added to Q. After adding a consequence to Q, all rules whose consequences are in Q are removed from R.

The following is the definition of informative association rule set: Definition Let RA be an association rule set and RA' the set of single-target rules in RA. A set R, is informative over RA if (1) R, C RA', (2) \/ r E R,, there does not exist r' E R, such that r' c r and conf(r')> conf(r), and (3) V r" E RA' -R,, 3 r E R, such that r" = r and conf(r") <conf(r).

From this definition, the informative association rules are basically single target rules such that there is no subset rule with higher confidence and for any non-informative single- target rule, there is an informative association rule with higher confidence.

Page 332    B. Problem Description The objective of data mining is to extract hidden or  potentially unknown and interesting rules or patterns from databases. However, the objective of privacy preserving data mining is to hide certain sensitive information so that they cannot be discovered through data mining techniques [1],[4]- [12],[18]. In this work, we are particularly interested in improving the efficiency of hiding informative association rules when the transaction database is updated, i.e., when a transaction data set is added to the original database.

Assuming new added data set is given, we propose an algorithm to efficiently Sanitize Informative association rules with Updates (SIU). More specifically, given a transaction database D, minimum support, minimum confidence, a set of predicting items X, a sanitized transaction database D', and a new data set A: , the objective is to minimally modify the updated database (D+ = D + A: ) such that no informative association rules containing X on the left hand side of the rule will be discovered.

As an example, for a given database D in Table 1, a minimum support of 33%, a minimum confidence of 70%, and a hidden item X= {C}, if transaction T1 is sanitized from ABC to C, and transaction T6 is sanitized from AC to C, then the following rules that contain item C on the left hand side will be hidden: C=>A (330%, 500%), C=>B (330%, 500%). However, four rules B=>C (33%, 66%), AB=>C (33%, 66%), C=>AB (33%, 50%), B=>AC (33%, 66%) are lost and a new rule A=>B (50%, 75%) is added as side effects. The sanitized database D' is shown in Table 2.

Table 2: Databases before and after sanitization TID D D' T1 111 001 T2 111 111 1 T3 111 111 T4 110 110 T5 100 100 T6 101 001  Table 3: New data set A TID A  T7 101 T8 101 Tg 110  When a new data set A in Table 3 is added to the database D, if transaction T6 is sanitized from AC to C and T7 is sanitized from AC to C by directly sanitizing the updated database D+ using DSC algorithm in [28], then the following rule containing item C on the left hand side will be hidden: C=>A (44%, 66%). However, two new rules are generated A=>B (77%, 71%) and AC=>B (33%, 75%). There is no hiding failure and no lost rule.



III. PROPOSED ALGORITHM  In order to hide an association rule, X=>Y, we can either decrease its supports, ( X |/N or X U Y I/N ), to be  smaller than pre-specified minimum support or its confidence  (I X U Y |/| X |) to be smaller than pre-specified minimum confidence. To decrease the confidence of a rule, two strategies can be considered. The first strategy is to increase the support count of X, i.e., the left hand side of the rule, but not support count ofX u Y. The second strategy is to decrease the support count of the itemset X u Y. For the second strategy, there are in fact two options. One option is to lower he support count of the itemsetX u Y so that it is smaller than pre-defined minimum support count. The other option is to lower the support count of the itemset X u Y so that X U Y |/| X is smaller than pre-defined minimum  confidence. In addition, in the transactions containing both X and Y, ifwe decrease the support of Y only, the right hand side of the rule, it would reduce the confidence faster than reducing the support of X. In fact, we can pre-calculate the number of transactions required to hide the rule. If there are not enough transactions exist, then the rule cannot be hidden. To decrease support count of an item, we will remove one item at a time in a selected transaction by changing from 1 to 0. To increase the support count of an item, we will add one item by changing from 0 to 1. We will adopt the second strategy of decreasing the support count of the itemset X u Y, i.e., sanitize the transactions that contain the itemsetX u Y.

In order to hide informative association rules, we will consider hiding association rules with 2 items, x=>z, where x is a predicting item and z is a single large one-item. In theory, informative rules may have more specific rules that contain more items, e.g., xY => z, where Y is a large itemset.

However, for such rule to exist, its confidence must be greater than the confidence of x=>z, i.e., conf(xY=>z) > conf(x=>z) or IxYzl > conf(x=>z) * IxYl. For higher confidence rules, such as conf(x=>z) = 1, there will be no more specific rules.

In addition, once the more general rule is hidden, the more specific rule might be hidden as well.

To reduce the number of database scanning in generating large or frequent itemsets in association rule mining, a one- scan of database method was proposed in [14]. The basic idea is to construct a tree structure, called Pattern tree (P-tree) and a frequency list which contains the frequency counts of each item in one database scan. The pattern tree is then restructured to a compact Frequent-Pattern tree (FP-tree) proposed by [13], which can store more information in less space. A FP-tree based pattern growth method (FP-growth) is used to find all the large tiemsets from the FP-tree.

In [28], we proposed a Pattern-Inversion tree (PI-tree) based on the pattern tree to sanitize informative association rules with one database scan. A PI-tree is similar to a P-tree except the following. Each node in a PI-tree contains three fields: item name (or item number), number of transactions containing the items on the path from the root to current node, and list of transaction ID that contains all the items on the path from the root to current node. For example, the PI-tree for the  Page 333    six transactions in Table 1 is shown in Figure 1. The frequency list is L = <(A:6), (B:4), (C:4)>.

Figure 1 Pattern Inversion Tree for Database in Table 1  The construction of a PI-tree contains two steps. In step one, we read transactions one by one from database. Each transaction is sorted according to item name (or item number) and inserted into the PI-tree. The frequency list is updated accordingly. In the second step, we sort the frequency list according to item support counts first. Then the PI-tree is restructured similar to the first step. Each branch of the original PI-tree is sorted according to the new frequency list and inserted to a restructured PI-tree. We will adopt the proposed PI-tree and DSC algorithm [28] to store and sanitize informative association rules.

To sanitize the informative association rules of updated database D+ , there are two possible approaches. One approach is that we can re-run any hiding algorithm on the updated database D+ directly. The second approach is to process the newly added data set A: incrementally and combined it with the sanitized result of original database D'.

For second approach, an informative association rule in D does not have to be an informative association rule in A , and vise versa. However, if all informative association rules in D and in A are sanitized, then all informative association rules are sanitized in the updated database D+. We will adopt the second approach to sanitize the informative association rules.

Based on the strategies described above, we propose a data- mining algorithm for the maintenance of sanitizing informative association rules, SIU. The basic steps of the algorithm are described as follow.

Algorithm SIU Input: (1) a sanitized database D', i.e., pattern inversion  tree PI', and frequency list L' (2) min support (3) min confidence (4) a set of hidden itemsX  (5) added data set A:  Output: a sanitized database D+', D = D + , where rules containing items ofX on LHS will be hidden  1: Build the Pattern Inversion Tree, PiA+ for A according to L' and new items in A  2: Build sorted frequency list La+ for 3: Sanitize all informative association rules of the form: U:  x - y in A according to La+, to obtain PiA+' and La' 4: Update frequency list L', by adding L 'to L'  5: Merge PI-tree PI+' to PI' 6: Restructure PI' according to L' 7: Output sanitized database D+';

IV. EXAMPLE  Using the same example database D and sanitized database D' with minimum support of 330% and minimum confidence of 70% in Table 2, when the data set A shown in Table 3 is added, the result of running proposed SIU algorithm is as follows.

In step one, the pattern inversion tree PIA+ for A has two branches, root- A:3 -C:2:[T7, T8], root- A:3 -B:1:[Tg]. In step two, the sorted frequency list La <(A:3), (C:2), (B:1)> is built. In step 3, to hide C=>A (66%, 100%), transaction T7 is sanitized from AC to C. The sanitized PIA+ ' tree has three branches, root - A:2 - C:1:[T8], root - A:2 - B:1:[Tg], and root - C: 1: [T7]. In step 4, the updated frequency list for D+ is L' = <(A:6), (C:6), (B:4)>. In step 5, the merged PI' tree has 3 branches, root - A:6:[T5] - B:4:[T4,Tg] - C:2:[T2 T3], root - A:6:[T5] - C:1:[T8], and root - C:3:[TI, T6, T7]. In step 6, the restructured PI' tree according to L' remains unchanged. The sanitized database D' hides C=>A (33%, 50%). There are no new rules generated, no hiding failure and one lost rule BC=>A (22%, 100%).



V. NUMERICAL EXPERIMENTS  In order to better understand the characteristics of the proposed SIU algorithm numerically, we perform a series of experiments to measure various effects and compare with the direct sanitization DSC algorithm proposed in [28]. The following effects are considered: time effects, side effects, database effects and item ordering effects. For time effects, we measure the running time required to hide one and two predicting items, i.e., one and two informative association rule sets respectively. For side effects, we measure the hiding failure, new rules generated and lost rules. The hiding failure side effect measures the number of informative association rules that cannot be hidden. The new rule side effect measures the number of new rules appeared in the transformed database  Page 334    but is not in the original database. The lost rule side effect measures the number of rules that are in the original database but not in the transformed database. The database effects measure the percentage of altered transactions in the database.

The item order effects examine the previous effects when the order of predicting item is changed.

The experiments are performed on a PC with AMD 1.99 GHz processor and 1 GB RAM running on Windows XP operating system. The data sets used are generated from IBM synthetic data generator. The sizes of the data sets range from 5K to 25K transactions with average transaction length, IATLI = 5, and total number of items, II = 50. For each data set, various sets of association rules are generated under various minimum supports and minimum confidences. The minimum support range is from 3% to 10%. The minimum confidence range is from 20% to 40%. Total number of association rules is from 6 to 178. The number of hidden rules ranges from 3 to 16, which in percentage over total association rules is from 9% to 66%. The number of predicting items considered here is one and two items.

sanitized database with one data set scanning using pattern- inversion trees. Example illustrating the proposed algorithm is given. Numerical experiments are performed to show the time effects, database effects, and side effects of the algorithm and compared with direct database sanitization algorithm. It can be seen that the proposed SIU algorithm out performs the direct sanitization algorithm DSC in processing time with similar side effects. In the future, we will consider the problem of efficient maintenance of privacy for other types of rules and patterns when databases are updated.

Multiple Updates   -: 400  0v:' 200 O' 10k 15k 20k 25k  Data Size  _-* I-Item-SIU _ I-Item-DSC  2-Item-SIU  = 2-ltem-DSC  Figure 2 shows the processing times required to maintain the sanitized informative association rules under multiple updates for proposed SIU algorithm and direct sanitization algorithm DSC in [28]. Multiple updates mean more than one data set is added to the original database. For example, IDI = 10k, A: = 5k, and A is added to the D three times. The processing time required to sanitize 10k is 35.78 seconds to hide one item and 65.92 seconds to hide two items. Adding 5k data set, SIU algorithm requires 50.68/95.6 seconds and DSC algorithm requires 92.22/177.7 seconds for hiding one item and two items respectively.

Figures 3 and 4 show the various side effects of SIU and DSC algorithms hiding one recommended item. There are about the same percentage of rules to be hidden for both algorithms. There is very few hiding failure using SIU or DSC algorithm. There are about 0.5% of new rules generated for each 5k data set and about 10% of association rules are lost for each 5k data set for SIU algorithm. There are about 3% ofnew rules generated and about 5% of association rules are lost on the average for DSC algorithm. Figure 5 shows the percentage of transactions altered using SIU and DSC algorithms. Even for different database sizes, the percentages of altered transactions remain almost constant, about 7.5% for SIU and 9% for DSC with one recommended item. This indicates that the processing time should increase proportionally as the size of dataset increases. This implies both algorithms have similar side effects.



