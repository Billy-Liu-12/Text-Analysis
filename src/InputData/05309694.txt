Feature-Based Probabilistic Data Association (FBPDA) for Visual Multi-Target Detection and Tracking

Abstract? Uncertainties in the sensor data such as mea- surement noise, false detections caused by clutter, as well as merged, split, incomplete or missed detections due to a sensor malfunction or occlusions (both due to the limited sensor field of view and objects in the scene) make multi-target tracking a very complicated task. Thus one of the big challenges is track management and correct data association between detections and tracks. In this contribution we present an algorithm for visual detection and tracking of multiple extended targets under occlusions and split and merge effects. Unlike most of the state-of-the-art approaches we utilize low-level information integrating it in a unified approach based on a threshold- free probabilistic conception. The introduced scheme makes it possible to utilize information about composition of the measurements gained through tracking of dedicated feature points in the image and resolves data association ambiguities in a soft decision using a globally optimal probabilistic data association approach. Beside existence evolution consideration we also exploit the spatial and temporal relationship between stably tracked points and tracked objects, which along with ob- servability analysis, allows us for reconstruction of compatible measurements and thus correct track update even in cases of splits, merges and partial occlusions of the tracked targets.

Index Terms? multitarget tracking (MTT), data association, split and merge handling, stereo video, environment perception, lateral vehicle perception, vehicle side monitoring, side-looking cameras, 6D vision, occlusion handling

I. INTRODUCTION Most Bayesian target tracking methods, such as the  Kalman filter [1], are based on filtering of successive sensor measurements. This requires robust detection of the tracked targets as well as correct data association. However, in many applications both target detection and data association are very complex tasks due to uncertainties in the data. In addition to the standard problem of noisy (i.e. inaccurate) measurements, one has to cope with incomplete or missed detections, false detections due to clutter, and wrong asso- ciations between tracks and detections. Another common effect is the incidence of multiple detections evoked by one target (split) or the fusion of multiple targets to one detection (merge). Similar effects may emerge due to partial or complete occlusion of the targets. For an implementation of a robust tracking system an appropriate data association method which can effectively handle all of the above- mentioned effects is therefore essential. In this contribution  The authors are with the Fraunhofer Institute for Information and Data Processing (Fraunhofer IITB), Fraunhofer Str.

1, 76131 Karlsruhe, Germany, http://www.iitb.fraunhofer.de/ {michael.grinberg, florian.ohr, juergen.beyerer} @iitb.fraunhofer.de  we propose a data association scheme based on tracking of dedicated feature points for enabling of a robust multi- target object detection and tracking under occlusion and split and merge effects. Our method allows to compute affiliation probability of each point to the currently tracked objects.

This knowledge is utilized in the data association step for a weighted combination of measurements obtained from point clouds to a single statistically most probable measurement which is then used for the object?s state innovation. Addi- tionally, a scheme for explicit observability modeling and propagation is proposed.

The paper is structured as follows: Section II summa- rizes related work, Section III deals with the observability modeling, in Section IV, an overview of the application and the overall object tracking framework is given, Sections V- VIII give a detailed description of each step of the proposed Feature-Based Probabilistic Data Association Algorithm, in Section IX, the experimental setup and results are presented.

Finally, a short summary is given in Section X.



II. RELATED WORK  Most of the video-based object tracking applications uti- lize background estimation methods for extraction of moving image blobs, which are then tracked using methods such as the mean shift or CAMSHIFT algorithms [2], [3], [4]. Avail- ability of the depth information (e.g. from stereo process- ing) makes it possible to track objects in three-dimensional space using estimates of their centers of gravity (CoG). In both types of applications though, possible confusion of neighboring objects may cause tracker failure. Further major challenges are occlusions and false detections (clutter). In particular, applications which can not utilize background estimation (e.g. video-based object tracking performed from a moving platform) suffer from these effects. One of the major problems hereby is that the tracker presupposes object existence and observability and does not account for their uncertainty. This problem was studied thoroughly in the radar tracking literature [5], [6], [7], [8].

In the past few decades several algorithms for multi-target tracking have been proposed. Probabilistic Data Association (PDA) [5], [6] as well as Joint Probabilistic Data Association (JPDA) [9], [10] proposed by Bar-Shalom et al. aim at uti- lizing all sensor measurements taking into account statistical distribution of errors and clutter. Mus?icki et al. proposed in [7], [11] an approach that allows for representation of the uncertainty of the target existence, and for integration of  Proceedings of the 12th International IEEE Conference on Intelligent Transportation Systems, St. Louis, MO, USA, October 3-7, 2009  TuAT2.3     track initiations into the PDA framework (Integrated Prob- ability Data Association, IPDA). The combination of JPDA and IPDA resulted in the Joint Integrated Data Association (JIPDA) algorithm [8] which was shown to be effective also for multi-sensor data fusion [12], [13].

All mentioned algorithms were developed to cope with distant target tracking applications using radar, LIDAR or sonar sensors. Thus they were designed under the assump- tions that a target may be represented by it?s center of gravity, that a target may cause at most one detection, and that a detection may be evoked by at most one target.

When tracking extended targets, one has to deal with split and merge effects which are not handled by standard approaches. Those effects were tackled in research on visual tracking. Kumar et al. [14] proposed a method which copes with split and merge effects by evaluating the associations between the combined detections and tracks, and choosing the ones of maximal probability based on distance between contours of the resulting image blobs. However, even with identified split or merge events it is not possible to perform an appropriate update step. Instead, prediction is used for further processing until a resolution can be made. Gen- ovesio et al. propose in [15] to create virtual measurements that always allow for an appropriate update. Thereby the most probable association is used. For splitting of joint measurements evoked by several tracks, they propose to use the k-means algorithm, which may become problematic when merged objects have unequal dimensions. Furthermore, gating failures arising when in case of a merge the CoG of the joint measurement does not lie within the gate of one or more corresponding tracks lead to measurement rejections as well as to missing or wrong splits as shown in Fig. 1.

Fig. 1. Example of measurement rejection due to gating failure in the case of merged targets: CoG of the joint measurement z1 does not lie within the gates of the tracks x1 and x3.



III. MODELING THE TRACK?S OBSERVABILITY  Another important point is object observability. Mostly it is assumed to always be given. Occlusions if any are modeled and handled as measurement noise (varying object dimen- sions) or as a sensor malfunction (missing detections). Direct coupling (or equalization) of observability and existence leads to the existence-based track termination after several tracking cycles. For coping with this problem we propose an observability treatment scheme utilizing a grid-based object representation with occupancy and occlusion modeling for each cell. In addition to the two Markov chains that are used  for modeling target?s dynamic state and existence evolution we consider the observability probability as a third Markov chain. This allows for a dedicated observability and occlusion handling and thus decoupling of existence and observability.

Besides, we utilize knowledge gained by tracking dedicated feature points in the image for an appropriate formation of the measurements from initial point clouds for efficient handling of partial occlusions as well as split and merge effects. Additionally, in our contribution we combine the advantages of the described approaches. Measurements are combined in a statistically optimal way to account for association uncertainty. Global optimality of association be- tween multiple detections and multiple targets is achieved by creating composite measurements for track updates in the context of maximization of the global association probability.

In the standard IPDA and JIPDA algorithm, two cross- coupled Markov chains are used for target state propagation (cf. Fig. 2). One Markov chain propagates the Gaussian  Fig. 2. Two cross-coupled Markov chains used in the IPDA algorithm  probability density function (pdf) of the target?s dynamic state which is parameterized by its state estimate x? and the error covariance matrix P?. The second Markov chain models the probability mass function (pmf) of the target?s existence.

In [11], two types of Markov chains are proposed for the target existence modeling. The first type has two states: one of the target being existent at time step k (denoted in the following as ?) and the second one of the target being non- existent at time step k (denoted as @). The second type of existence Markov chain has three states: target is existent and observable (denoted in the following as ?), target is existent but not observable (denoted as 6?) and target is non- existent, i.e it is a phantom object (denoted as P) as depicted in Fig. 3(a). The Markov chain of the first type can be derived from the Markov chain of the second type by bundling the two first states as shown in Fig. 3(b). It is also possible to bundle the two last states (i.e. to model occluded targets as not existent, cf. Fig 3(c)) as done in [13]. This leads to the existence-based track termination of occluded objects.

As in [8], [16], [12], [13], most researchers are content with considering a Markov Chain with two states. In our ap- proach, we explicitly consider target?s observability. Contrary to other approaches, we model it as a separate Markov chain (cf. Fig. 3(d), Fig. 4) hereby decoupling object existence and observability. For this aim we exploit a grid based object representation which allows us to build appearance and occlusion maps for each object and thus explicitly compute occlusion degree and observability probability for each tracked object. Further details on this procedure are     (a) (b)  (c) (d)  Fig. 3. Markov chain based modeling of object existence and observability.

The three possible track states ?, 6? and P (object existent and observable, object existent but not observable and object non-existent (phantom track)) can be bundled in different ways. The two umbrella states are visualized with ? and @.

Fig. 4. Three cross-coupled Markov chains used in the FBPDA  given in Section V-C.



IV. OVERALL SYSTEM DESCRIPTION  The video-based object tracking framework which is taken as a basis for this work has been built at Fraunhofer IITB in the course of the EU funded project APROSYS [17]. The goal was detection of imminent side collisions to enable timely activation of novel occupant protection systems [18].

The sensor system under consideration here is a side-looking stereo video camera [19]. Ego-motion estimation and com- pensation is done using vehicle odometry data which was shown to deliver sufficient accuracy even for the structure- from-motion task [20].

Many useful constraints and assumptions being utilized in the applications developed for the front view do not apply to the side-looking perspective. Other than in the majority of such applications, neither symmetrical appearance nor re- strictions about possible object locations and motion profiles (e.g. relative to the tracked lane markings) can be assumed.

As Fig. 5 illustrates, many different object orientations have to be taken into account. Combined with a large variety of object types, this makes it extremely challenging to detect and track objects based on their appearance in real time. For  Fig. 5. Typical traffic scene observed by a side looking camera  the realization of a side-looking video system we thus had to choose a generic approach to achieve a robust and reliable object detection. Object hypotheses are therefore generated from the depth maps which are the result of stereo process- ing. After extracting a depth map, road location is estimated and then points belonging to the road are eliminated. Spatial clustering of the remaining three-dimensional points delivers initial point clouds which are used as an input in the data association step.

Due to the noisy depth extraction process, combined with well known problems of stereo vision systems such as diffi- culties of depth estimation in homogeneous image regions and gross depth errors in regions with regular patterns, the results of clustering may vary from frame to frame leading to split and merged object measurements. One of the possibilities of coping with this problem on the lowest level is the utilization of optical flow for feature tracking in the image and using of the resulting 2-D or 3-D motion patterns for hypotheses generation [21], [22], [23]. This how- ever, can not be applied effectively for handling of merged stationary objects or objects with similar motion profiles. Yet, for data association this additional low-level information is very useful and may be utilized for successful resolution of the data association problem and for stabilization of tracking. In our algorithm we estimate the probabilities of the affiliation of the tracked points to the tracked objects and use them for both data association and object tracking.

For detection and tracking of the feature points we use a 3-D point tracking system similar to the one proposed in [23]. Up to 3000 feature points are tracked simultaneously in 3-D space using Kalman Filters. Their six-dimensional state vectors [x, y, z, vx, vy, vz]T are estimated from their image coordinates and displacement (optic flow) as well as stereo depth measurements. The measurement vector is thus [u, v, d]T with image coordinates (u, v) and feature depth d.

After elimination of the ground points, remaining points are clustered to point clouds which give detections for object tracking. For performing the association between point clouds and tracks and for track state propagation we propose to use the Feature-Based Probabilistic Data Association algo- rithm (FBPDA) which is described in the following sections.

FBPDA consists of four major steps: time forward prediction, association between detections and tracks, reconstruction of composite measurements from associated point clouds and     innovation. These four steps are described in Sections V, VI, VII and VIII respectively. For effective noise handling as well as for handling of split and merged point clouds FBPDA provides affiliation probabilities of each point to the current tracks. These affiliation probabilities are exploited in the course of updating tracks? position, dynamics and dimensions.

Object parameters are estimated using an Extended Kalman Filter. Internally, objects are modeled as cuboids with a centroid (x, y, z), dimensions (l, w, h) and geometri- cal orientation ?, motion orientation ?, speed v, acceleration a and yaw rate ??. This corresponds to the Constant Yaw Rate Model with Acceleration, which has proved to deliver the best performance in the case of a side-looking system [24]. Due to the fact that often only a part of an object is visible to the sensors, orientation of the object?s motion may differ from the estimated geometrical orientation. Object?s geometric orientation and dimensions are updated taking into account the occlusion information as described in Section VII.

Figure 6 illustrates principal architecture of the imple- mented framework.

Vehicle dataStereo?image acquisition  Ego?motion estimation Correnspondence search  L?R Correnspondence search  k??k?1  3D?reconstruction Optic flow  Point?tracking in?3D  Ground plane?estimation,?elimination of ground points  Object tracking: Compensation of the ego?motion Prediction of objects??new state  Association between point clouds and existing tracks Building of compatible measurements  Estimation of the new object parameters  Object detection,?clustering of point clouds  Fig. 6. Overall framework for visual object detection and tracking

V. TIME FORWARD PREDICTION  At each time step, after the ego-motion compensation, we start by predicting the new track attributes. This includes prediction of the track?s dynamic state as well as prediction of it?s existence and observability probabilities.

A. State prediction  The FBPDA state prediction of a track is identical to the common Extended Kalman Filter prediction.

B. Existence prediction  The time forward prediction equations for the existence and non-existence probabilities pxk|k?1(?) and p  x k|k?1(@) of  a track x are:  pxk|k?1(?) = p x(? ? ?) ? pxk?1|k?1(?)  + px(@? ?) ? pxk?1|k?1(@) (1) pxk|k?1(@) = 1? p  x k|k?1(?)  with pxk?1|k?1(?) being the a-posteriori existence probability from the last frame and px(? ? ?) and px(@? ?) denoting the persistence and the birth probabilities of a track x. The last two factors are used for modeling the spatial distribution of the target birth and death probabilities. This makes it possible to account e.g. for the fact that at the borders of the field of view and at far distances the birth probability is higher than right in front of the sensors.

C. Observability prediction  For the computation of the observability probability and for the reconstruction of occluded measurements we use a grid-based 3-D representation of the targets. For each track xi, we define a 3-D grid with the origin at its centroid. The orientation of the grid is aligned with the track?s orientation.

Using this representation of predicted objects it is possible to calculate their appearance masks in the camera image MxiA (u, v) ? {0, 1} by projecting the occupied grid cells into the image. The Appearance Probability Mask Mxip(A)(u, v) for each track is given by  Mxip(A)(u, v) = p(A xi(u, v)) = MxiA (u, v) ? p  xi k|k?1(?) (2)  where Axi(u, v) is the event of the track xi appearing at the image position (u, v) and pxik|k?1(?) is the predicted existence probability of the track xi. By overlaying the appearance probability masks of all the objects lying in front of the object xi we get the occlusion probability map for the respective object in the new frame. The occlusion probability pxi(6?, u, v) at each pixel (u, v) is calculated as  pxi(6?, u, v) = p( ?  xr?XiO  Axr (u, v)) (3)  with XiO being set of the objects lying at the pixel posi- tion (u, v) in front of the object xi. After the occlusion probability map for an object is built, we can estimate the occlusion probability pxi( 6?, c) of the object?s grid cells. This is done by projecting the cell centers into the image and grabbing the corresponding value of the occlusion proba- bility map. Fig. 7 illustrates the grid-based determination of the occlusion probability. Based on these probabilities we can calculate the observability transition probabilities pxi(???), pxi(??6?), pxi(6???) and pxi(6??6?) of a track and predict it?s observability probability and occlusion probability in the new frame:  pxk|k?1(?) = p x(???) ? pxk?1|k?1(?) (4)  + px(6???) ? pxk?1|k?1(6?) (5) pxk|k?1(6?) = 1? p  x k|k?1(?) . (6)

VI. DATA ASSOCIATION BETWEEN DETECTIONS AND TRACKS  Given multiple active tracks and multiple detections there are often several assignment possibilities being more or less probable. Unlike other methods such as GNN, FBPDA does not choose one of these hypotheses for the innovation of a track, but considers all assignment possibilities in a soft decision. The complexity of the algorithm would grow     Fig. 7. Grid based estimation of object?s occlusion probability. The occupied cells of the half-occluded car are marked in the top view in different shades of blue dependent on their occlusion probability. Occlusion probability is calculated from the occlusion map which is shown in the lower part of the Figure. The occluding car has existence probability of pk(?) = 0.8  exponentially with the number of targets and point clouds.

This is a NP-hard problem [25]. For reduction of the total computational costs we introduce track clustering as a pre- processing step using a gating scheme similar to the one proposed in [8]. In the following, the disjunct track subsets can be processed independent from each other.

A. Assignment hypothesis definition  Assignment hypotheses between point clouds and tracks are modeled as a bipartite graph with edges e : (x ? X 7? z ? Z) between elements of the set of targets X and elements of the set of detections Z. We define the set X={X ?,xB , c?} as the aggregation X ?={x1,x2, ...,xn} of the n current tracks plus two special elements xB and c? representing a so far not known object and a clutter  source and the set Z={Z ?, z?, z 6?, z@} as the aggregation Z ?={z1, z2, ..., zm} of the m current point clouds plus three special elements z?, z 6? and z@. The element z? stands for erroneously missed detection caused by sensor failure, z 6? represents the correct absence of a detection because of occlusion of the target and z@ the correct absence of a detection because of the target non-existence. Assignments between two special elements are prohibited. A valid assign- ment hypothesis can thus contain six types of edges e:  ? xi 7? zj : assumption that point cloud zj has been caused by the track xi  ? xB 7? zj : point cloud zj has been caused by a so far not known object  ? c? 7? zj : assumption that point cloud zj has been caused by clutter  ? xi 7? z 6?: track xi did not cause a point cloud because it is not observable  ? xi 7? z@: track xi did not cause a point cloud because it does not exist  ? xi 7? z?: track xi did not cause a point cloud because of a sensing error  Fig. 8 illustrates four valid assignment hypotheses for the case of n = 2 tracks and m = 2 point clouds.

Fig. 8. Examples of valid assignment hypotheses  B. Calculation of the assignment hypothesis probabilities  The probabilities of the six edge types are calculated in analogy to [13]:  p(e =(xi 7? zj)) = (7) pxik|k?1(?) ? p  xi k|k?1(?) ? p  zj (TP |xi) ? (1? pzj (FP )) p(e =(xi 7? z 6?)) =  pxik|k?1(?) ? (1? p xi k|k?1(?)) (8)  p(e =(xi 7? z?)) = pxik|k?1(?) ? p  xi k|k?1(?) ? p  xi(FN) (9)  p(e =(xi 7? z@)) = (1? pxik|k?1(?)) ? p  xi k|k?1(?) ? (1? p  xi(FN)) (10)  p(e =(xB 7? zj)) =  (1? ?  i  pzj (TP |xi)) ? (1? pzj (FP )) (11)  p(e =( c? 7? zj)) =  (1? ?  i  pzj (TP |xi)) ? pzj (FP ) (12)  with pzj (FP ) being the probability that a clutter-caused point cloud appears at the position of zj , pxi(FN) the false negative probability for the track xi and pzj (TP |xi) being the likelihood function obtained from the Kalman filter.

With (7)-(12) it is now possible to calculate the probability of an assignment hypothesis E = {e1, .., eq} by:  p(E) = q?  a=1  p(ea) (13)  C. Calculation of the association probabilities  The association probabilities ?xizj are calculated as the sum of all assignment hypothesis probabilities including the edge e = (xi 7? zj) divided by the sum of the probabilities of all assignment hypotheses assuming track xi as existent:  ?xizj =  ? {E|e=(xi 7?zj)?E} p(E)? {E|e=(xi 7?z@)/?E} p(E)  . (14)     ?xiz0 is the probability of the event that no point cloud originated from track xi. It is calculated analogously to (14).



VII. HANDLING OF SPLIT AND MERGE EFFECTS AND RECONSTRUCTION OF COMPATIBLE OBJECT  MEASUREMENTS  For handling of the possibility of split and merge events in the course of data association, one option is to allow the assignment of a set of point clouds to one track or a set of tracks to one point cloud, respectively. This would make it possible to identify splits and merges but would not allow to make an appropriate update since there is a one-to-one association necessary for doing so. Another possibility would be to create virtual measurements from the original measure- ments by splitting and merging them using predicted states of the tracked objects as as shown in Fig. 9. This approach  Fig. 9. Creation of virtual measurements for possible split and merge events  would maintain one-to-one matchings between objects and associated point clouds and would allow to update the track?s state after creation of compatible state measurement. The disadvantages of the method are ambiguous partitioning of original measurements in case of merging targets and explod- ing number of feasible associations. Furthermore, when using a centroid-based tracking approach, in the case of split and merged targets the resulting measurement?s CoG might not lie inside the gating ellipse of the targets? tracks as shown in Fig. 1. Another problematic case is the position update of a target which is partially occluded (due to either other objects in the scene or restricted field of view of the sensors).

If target position is updated based on the CoG of the point cloud, it will cause a shift of the track?s centroid and induce an impulse which will introduce bias to the estimated track?s state.

To avoid such problems we reconstruct for each detection- to-track association the track?s centroid and orientation using stably tracked points. We hereby utilize information about the affiliation of the tracked points to the tracks independently of the currently occurred splits and merges. The reconstructed centroids can then be used instead of the CoGs of the corresponding point clouds for the computation of the state measurement for each track.

A. Determination of the point-to-track affiliation probabili- ties  The affiliation probability p(xi 7? pq) of a point pq to a tracked object xi is determined based on the association probability ?xiz of the point cloud z containing pq to that  object. For realization of a memory effect we filter the affiliation probabilities using a gain constant g ? [0, 1]:  pk(xi 7? pq) = g ? ?xiz + (1? g) ? pk?1(xi 7? pq). (15)  Initialization of a point is done with  p( c? 7? pq) = 1, p(xi 7? pq) = 0 ?xi. (16)  B. Point cloud based reconstruction of the track?s position and orientation  For the reconstruction of the track centroid pO from an associated point cloud we first calculate the CoG pCoG of the stably tracked points of this point cloud both in the current and previous frame. Hereby we are weighting the points? 3-D positions with their track affiliation probability (known from the previous frame). Having computed pCoG in both current and previous frames, we can for each tracked point pq reconstruct the vector (??????pCoGpO)q pointing from the CoG to the object centroid pO in the current frame using knowledge about the relative orientation of this vector regarding the vector ??????pCoGpq in the previous frame (cf. Fig. 10). Building a  Fig. 10. Object position reconstruction based on spatial relationship to stably tracked points  weighted sum of the resulting vectors (??????pCoGpO)q according to the affiliation probability of the respective points pq we get the new position of the track?s centroid with respect to the considered point cloud. The track?s new orientation can be obtained in the same way. Together those parameters form the reconstructed measurement of the point cloud. All these measurements weighted according to the association proba- bilities of the corresponding point clouds build a composed measurement which is then used for the innovation of the Kalman Filter responsible for the track?s dynamics.

C. Grid-based reconstruction of the track?s extent  The extent of a track is obtained in a similar way. We create one composite measurement from all point clouds associated to the track. This is done using the grid repre- sentation of the track which is aligned according to its new position and orientation gained through the innovation of the track?s dynamics. The points of each associated point cloud are sorted into the grid. Thereby points of a point cloud contribute to the occupancy value of the grid cell according to their affiliation probability to the track and the association probability of the point cloud. For each cell c its current occupancy value o at time step k with respect to the track     xi is computed according to  oxik (c) = m?  j=1  ( ?xizj ?  l? q=1  p(xi 7? pq) )  (17)  with m being current number of point clouds and l being the number of points pq belonging to the point cloud zj and falling into the cell c. The grid is updated using this occupancy values. To avoid an update of the occupancy value of an occluded cell with 0, we filter the occupancy values of the cells using their occlusion probability. For this purpose we use the recursive filter depicted in Fig. 11. For each cell  Fig. 11. Recursive filter used for filtering of cell occupancy probability  c its filtered occupancy value o?k(c) at time step k is given by  o?xik (c) =p xi k (?, c) ? o  xi k (c) + (p  xi k (6?, c)) ? o?  xi k?1(c) (18)  with pxi(?, c) = 1? pxi( 6?, c). (19)  Object?s geometric orientation and dimensions are ob- tained using a RANSAC based estimation of the main visible object surface in the top view and fitting a rectangle with this orientation into the ground projection of the points. Together, these parameters form the resulting composite measurement which is then used for the innovation of the track?s geometric orientation and its dimensions.



VIII. STATE, EXISTENCE AND OBSERVABILITY INNOVATION  In the innovation step, all three Markov chains are updated.

The innovation of the target?s physical attributes corresponds to the standard Extended Kalman Filter innovation. For maintaining the centroid position obtained from the grid based object extent computation as the reference point to be tracked, we switch to this point as a new reference point at the end of each frame. This prevents the object dimensions from jittering due to the one-sided changes of the visible object extent (e.g. in the case of a target entering the field of view). The a-posteriori probability of the track existence is calculated as the sum of the probabilities of all assignment hypotheses assuming track xi as existent divided by the sum of the probabilities of all possible hypotheses:  pxik|k(?) = ? {E|e=(xi 7?z@)/?E} p(E)?  {E} p(E) . (20)  The observability update is done analogously to the existence innovation.



IX. EXPERIMENTAL RESULTS  The algorithm has been validated with both simulated and real data. For our simulations we defined several scenarios that caused problems for the standard approach such as splitting and merging point clouds, objects entering and leaving the field of view (FoV) and occlusion scenarios.

These scenarios were simulated using a tool which generated point clouds with pre-defined parameters and behavior. Fig.

12 shows a very simple scenario of an overtaking car passing the FoV of the camera-carrying vehicle. Left column shows performance of the original filter. At the beginning, when the object is entering the FoV and ?growing? in the image, the center of gravity of the visible points becomes slower causing erroneous underestimation of the target?s velocity followed by a sudden acceleration when the entire object becomes visible. Splitting of the point cloud into two parts causes the track to decelerate rapidly and then to accelerate again as soon as the complete object is detected again. Finally, at the end of the sequence, while the object leaves the FoV of the cameras, the CoG of the visible points becomes slower again causing the track to decelerate and to partially remain in the FoV. Contrary to this behavior, FBPDA manages to always  Fig. 12. Split scenario: FBPDA (right) vs. standard approach (left)     maintain the correct object velocity and even to correctly track it when it?s almost completely outside of the field of view of the sensors (right column).

Similar effect can be observed in the case of an occlusion caused by another object in the scene. Fig. 13 shows a plot of the object?s lateral position obtained by the original approach (red) and FBPDA (blue) vs. the ground truth (black). Compared to the standard association and tracking scheme which leads to considerable corruption of the posi- tion (and velocity) estimation and even termination and re- initialization of the track, FBPDA manages it to correctly update tracks? parameters through multiple merges, splits and occlusions.

Fig. 13. Overtaking car scenario with occlusion, plots of the lateral position and velocity: original approach (red), FBPDA (blue) and ground truth (black).



X. CONCLUSION  In this contribution we have presented an algorithm for visual detection and tracking of multiple extended targets which is capable of coping with noisy, split, merged, in- complete and missed detections. The proposed Feature-Based Probabilistic Data Association approach resolves data associ- ation ambiguities in a soft threshold-free decision based not only on target state prediction but also on the existence and observability estimation modeled as two additional Markov Chains. This process is supported by a grid-based object rep- resentation which is used for the detailed occlusion analysis.

For the correct estimation of the desired object parameters, low-level information about measurement composition is utilized which is gained through tracking dedicated feature points in the image and 3D space. Along with the occlusion analysis, spatial and temporal relationship between the set of stably tracked points and the object?s centroid is exploited for the reconstruction of the desired object characteristics from the data even in case of detection errors due to limited field of view, occlusions, noise and sensor malfunction. For tracking applications that have to cope with the above-mentioned effects, our algorithm offers a much needed enhancement which has the potential to greatly increase detection and tracking performance and overall system robustness.

XI. ACKNOWLEDGEMENTS  The authors gratefully acknowledge the contribution of Dr.

Dieter Willersinn, Prof. Mohan Trivedi, Dipl.-Inf. Michael Mai, and all members of the APROSYS Task Force at the Fraunhofer IITB. We would also like to thank Mr. Ron Tal and the anonymous reviewers for the valuable comments.

