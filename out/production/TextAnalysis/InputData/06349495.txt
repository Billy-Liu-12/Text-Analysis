Knowledge Discovery with a Subset-Superset

Abstract?Data Mining provides a useful insight on   finding  frequent patterns.  Data mining is an inter-disciplinary field,  whose core is at the intersection of machine learning, statistics  and databases. In this paper we proposed an efficient method for  knowledge discovery which is based on subset and superset  approach.  In this approach we also use dynamic minimum  support so that we reduce the execution time. A frequent superset  means it contains more transactions then the minimum support.

It utilize the concept that if the item set is not  frequent but the  superset may be frequent which is consider for the further data  mining  task.  By this   approach we can also find improved  association, which shows that which item set is most acceptable  association with others. A frequent subset means it contains less  transactions then the minimum support. It utilizes the behavior  that the less count may be frequent if we attached the less count  with the higher order set.  Here we also provide the flexibility to  find multiple minimum supports which is useful for comparison  with associated items and dynamic support range. Our algorithm  provides the flexibility for improved association and dynamic  support.  Comparative result shows the effectiveness   of   our  algorithm.

Keywords ? Data Mining, KDD, Dynamic Minimum   Support,  Frequent Pattern, Super Set approach

I. INTRODUCTION   Data mining is a treatment process to extract useful and interesting knowledge from large amount of data. The knowledge modes data mining discovered have a variety of different types. The common patterns are: association mode, classification model, class model, sequence pattern and so on.

Frequent item set mining algorithms have been investigated for a long time, such as Apriori [1], FP-growth [2], Eclat [3], Tree-Projection [4], H-Mine [5], DHP [6], and so on.

The essence of frequent item set mining is to discover frequent subsets from a set of item set. In our study, we propose an efficient approach to discover frequent superset, improved association and dynamic Minimum support.

Data mining is a process to extract potentially useful information and knowledge from a large, noise, vague and random data that people don?t identify [7]. In light of such a   goal,   applying   the   appropriate   data   mining and approaches like artificial smart, set theory and statistics, we analysis the data, describe the model and the regulation through visual tools or regulations. With this approach, the policy maker can use the related knowledge to support the decision-making process; domain experts can use it to amend the existing knowledge system; meanwhile, we can also put this as a new knowledge and transfer it into the appropriate knowledge storage organization.

According to Yawei Wang [8] data mining has characteristics as follows: (1) discover models that can reflect system local characteristics and laws; (2) forecast the   trends   automatically   and   discover  the "new" knowledge; (3) win a lot of rules and be updated timely.

In the today?s scenario in day to day life the database is growing very faster. So that to minimizing information probability for prune is the best option in data mining.

Our proposed approach provides a direction in this way, so that we can reduce the transactions and also we operate with dynamic minimum support. The data mining (DM) and knowledge discovery in databases (KDD) movements have been based on the fact that the true value is not in storing the data, but rather in our ability to extract useful reports and to find interesting trends and correlations. The set of DM processes used to extract and verify patterns in data is the core of the knowledge discovery process. These processes involve data selection, data preprocessing, data transformation, DM, and interpretation and evaluation of patterns. Various researchers have made suggestions that domain knowledge should lead the DM process [9].

We provide here an overview of executing data mining services. The rest of this paper is arranged as follows: Section 2 introduces Knowledge Discovery; Section 3 describes about problem domain; Section 4 shows the recent scenario; Section 5 describes the Proposed Work. Section 6 discuss about the result. Section 7 describes Conclusion and outlook.



II. KNOWLEDGE DISCOVERY   This process model provides a simple overview of the life  cycle of a data mining project. Corresponding phases of a data  mining project are clearly identified throughout tasks and  relationships between these tasks. Even if the model doesn't  indicate it, there possibly exist relationships between all data  mining tasks mainly depending on analysis goals and on the  data to be analyzed. Six main phases can be distinguished in  this process model.

? Business understanding - concerns the definition of  the data mining problem based on the business  objectives.

? Data understanding - this phase aims at getting a  precise idea about data available, identifying possible  data quality issues, etc.

? Data preparation - covers all activities meant to build  the dataset to analyze from the initial raw data. This  includes cleaning, feature selection, sampling, etc.

? Modeling - is the phase where several data mining  techniques are parameter and tested with the  objective of optimizing the obtained data model or  knowledge.

? Evaluation - aims at verifying that the obtained  model properly answers the initially formulated  business objectives and contributes to deciding  whether the model will be deployed or, on the  contrary, will be rebuilt.

? Deployment - is the final step of the cyclic data  mooning process model. Its target is to take the  obtained knowledge, put it in a convenient form and  integrate it in the business decision process. It can go,  upon the objectives, from generating a report  describing the obtained knowledge to creating a  specific application that will use the obtained model  to predict unknown values of a desired parameter.



III. PROBLEM DOMAIN    In today?s era data mining is used in very wide sense. There  are several researches in this area. We concentrate mainly on  the problem of minimum support. If we apply multiple  minimum supports in the data mining service it will be helpful  in various application area. For example if we want to  compare four different minimum support of four different  location. If you enter only one minimum support at a time,  then the comparison you perform is manual. If your  application supports multiple minimum supports then the  above work is very easy and comparative study can be done.

Then a problem of subset and superset also arises in  previous research. Some algorithm considers the upper  limit by which we may loose those items which are not  considered because of the lower rank. But if we  concentrate on sub set then all those values which are of  lower rank also considered.



IV. RECENT SCENARIO    In 2010 Ashutosh Dubey et al. [10] proposed a novel data  mining algorithm named J2ME-based Mobile Progressive  Pattern Mine (J2MPP-Mine) for effective mobile  computing. In J2MPP-Mine, they first propose a subset  finder strategy named Subset-Finder (S-Finder) to find the  possible subsets for prune. Then, they propose a Subset  pruner algorithm (SB-Pruner) for determining the frequent  pattern. Furthermore, they proposed the novel prediction  strategy to determine the superset and remove the subset  which generates a less number of sets due to different  filtering pruning strategy. Finally, through the simulation  their proposed methods were shown to deliver excellent  performance in terms of efficiency, accuracy and  applicability under various system conditions.

In 2011, Avrilia Floratou et al. [11] proposed a new  algorithm called FLexible and Accurate Motif DEtector  (FLAME). FLAME is a flexible suffix-tree-based  algorithm that can be used to find frequent patterns with a  variety of definitions of motif (pattern) models. It is also  accurate, as it always finds the pattern if it exists. Using  both real and synthetic data sets, we demonstrate that  FLAME is fast, scalable, and outperforms existing  algorithms on a variety of performance metrics.

In 2011, Shawana Jamil et al. [12] focus on focus on  investigation of mining frequent sub-graph patterns in  DBLP uncertain graph data using an approximation based  method. The frequent sub-graph pattern mining problem is  formalized by using the expected support measure. Here n  approximate mining algorithm based Weighted MUSE, is  proposed to discover possible frequent sub-graph patterns  from uncertain graph data.

In 2011, Ashutosh Dubey et al. [13] proposed a novel  algorithm named Wireless Heterogeneous Data Mining  (WHDM). The entire system architecture consists of three  phases: 1) Reading the Database. 2) Stores the value in  Tbuf with different patterns. 3) Add the superset in the list  and remove the related subset from the list. Finally we  find the frequent pattern patterns or knowledge from huge  amount of data. They also analyze the better method or  rule of data mining services which is more suitable for  mobile devices.

In 2011, Ashutosh Dubey et al. [14] propose a novel DAM  (Define Analyze Miner) Based data mining approach for  mobile computing environments. In DAM approach, we  first propose about the environment according to the  requirement and need of the user where we define several  different data sets, then DAM analyzer accept and analyze  the data set and finally apply the appropriate mining by  computing environment or the applications which support    the DAM miner on the accepted dataset. It is achieved by  CLDC and MIDP component of J2ME.

In 2011, Ashwin C S et al. [15] proposed an apriori- based  method to include the concept of multiple minimum supports  (MMS in short) on association rule mining. It allows user to  specify MMS to reflect the different natures of items. Since  the mining of sequential pattern may face the same problem,  we extend the traditional definition of sequential patterns to  include the concept of MMS in this study. For efficiently  discovering sequential patterns with MMS, we develop a data  structure, named PLMS-tree, to store all necessary information  from database.

In 2011, K. Zuhtuogullari et al. [16] observe that an  extendable and improved item set generation approach has  been constructed and developed for mining the relationships  of the symptoms and disorders in the medical databases. The  algorithm of the developed software finds the frequent  illnesses and generates association rules using Apriori  algorithm. The developed software can be usable for large  medical and health databases for constructing association rules  for disorders frequently seen in the patient and determining the  correlation of the health disorders and symptoms observed  simultaneously.

In 2011, Reeta Budhani et al. [17] study and proposed about  extracting useful insights from large and detailed collections  of data. With the increased possibilities in modern society for  companies and institutions to gather data cheaply and  efficiently, this subject has become of increasing importance.

This interest has inspired a rapidly maturing research field  with developments both on a theoretical, as well as on a  practical level with the availability of a range of commercial  tools. They proposed a novel Reconfigurable Character based  Token Set Pruner (RCBTSP) for heterogeneous environment

V. PROPOSED WORK   In this paper we proposed an efficient approach for knowledge  discovery which is based on subset superset concept with  dynamic chances of minimum support.

For this we first introduce our proposed approach with a  sample example for expanding the approach.

Apriori visits each transaction when generating a new  candidate sets; FP-Growth does not Can use data  structures to reduce transaction list. FP-Growth traces the  set of concurrent items; Apriori generates candidate sets  FP-Growth uses more complicated data structures &  mining techniques. So we uses FP-growth pattern tree.

Our proposed methodology deals on different dataset  which is applicable to mine huge amount of data. We do  not concentrate on candidate key generation it also helps  to save memory space and also the execution time is  increases.

Algorithm 1: Data Reading  Input: {i1?i4, p1, p2?pn ?tn}  Output: {i1?.t2?.tn}    Step 1: [Read the data]  for(i=0; i<=k-1; i++)  {  if(a[i]length!=null)  {  read[i];  } }    Step 2: [enter the character to find the pattern]  Go to Algorithm 4.

Step 3: [For Finding Association and Frequent pattern]  Go to Algorithm 2.

Algorithm 2: Mining Association  Input: DB, Dynamic MS  Output: FP-Tree    Step1: Discover all frequent item sets L1,L2?.Ln ,  using FP- growth, Lk(k=1,2?n) set of all frequent i-  item set.

Step 2: Scan DB & count all frequent items.

Step 3: Create null root & set as current node.

Step 4: For each Transaction T  Sort T?s items.

For each sorted Item I  Insert I into tree as a child of current node.

Connect new tree node to header list.

Algorithm 2: FP-growth Algorithm  FP-Growth  Input: FP-Tree, f is (frequent item set)  Output: All frequent patterns    Step 1: if FP-Tree contains single Path P  then for each combination of nodes in P  generate pattern f is combination  else for each item i in header  generate pattern f is i    Step 2: construct pattern?s conditional cFP-Tree  if (FP-Tree)= 0)  then call FP-Growth (cFP-Tree, pattern)  Algorithm 1: Pattern Generation  Input: {i1?i4, p1, p2?pn ?tn}    Step 1: find pattern (Sk+1)  {  for (i=0; i<=k-1; i++)  {  Sring tokenizer ab[i] =new String  Tokenizer(string,"ch")  list=ab[i];  }  }  append list; }}      Table 1: FP-growth Example                                                                                    For better understanding we produce a very simple example:    Table 2: Sample Example    Table 3: Pattern data    Pattern Data   10,20  10,20,30  10,20,30,40,50    Then we calculate the frequency of the item set which is  shown in table 4.

Figure 1: Header Table      Table 4: Item Frequency    Frequency Items  4 10  3 10,20  2 10,20,30  1 10,20,30,40,50    Table 5: Final Prune    Final Prune   10,20  10,20,30    Subset and Superset: A set "A" is a subset of B, if and  only if every element of A is also an element of B, and is  denoted by A ? B.

10 10,20 10,20,30 10,20,30,40,50  TID  Items bought           (Ordered) Frequent Items  100  {f, a, c, d, g, i, m, p} {f, c, a, m, p}  200  {a, b, c, f, l, m, o}  {f, c, a, b, m}  300   {b, f, h, j, o}  {f, b}  400   {b, c, k, s, p}  {c, b, p}  500   {a, f, c, e, l, p, m, n} {f, c, a, m, p}  {}  f:4 c:1  b:1  p:1  b:1 c:3  a:3  b:1 m:2  p:2 m:1  Header Table   Item   Frequency-Head f 4 c 4 a 3 b 3 m 3 p 3                         Example:  A = {a,e,i,o,u}, B = {a,b,c,d,e,f,g,h,...........,z} All the  elements in the set A are in set B.

a ? A and a ? B  e ? A and e ? B  i ? A and i ? B  o ? A and o ? B  u ? A and u ? B  ???A ? B [Read as A subset of B]    The above statement is also expressed as B contains A this is  written as B ? A and read as B is super set of A. If we  consider the superset of 10, 20, 30 then we get the value of 10,  20,30,40,50. Means we get those values which are not in the  frequent list but if those items are considered with the subset  then it may be frequent. If we consider the subset then it may  be the subset which is not frequent will be considered and may  be frequent with the other higher order associated items. So in  our approach we can deduce the higher order result as well as  the lower item set. After combination of those items we can  find the better combination of item set and the mixed  frequency is greater than the previous individual transactions.

This phenomenon is shown in Figure 2 and Figure 3.



VI. RESULT AND COMPARISON    The below shows the occurrences of each item set.

Figure 2: Item set vs. Occurrences    The below figure shows if we add higher occurrence with  lower occurrence item set, then the occurrence of lower item  set is increased.

Figure 3: Item set vs. Occurrences (Mixed)    Table 6: Transaction Info    File Name Transaction Time in Second 1.txt 57 4 2.txt 67 5 3.txt 94 4 4.txt 110 4 5.txt 125 5       Figure 4: Transaction Details    As shown in the figure 4 the transaction details are  provided according to the transactions used in the table 6.

We can observe that for different transactions, there is a slight  change in the time. If we change the minimum support  dynamically then we observe a below time than the total  time/2 which is shown in table 6. So we can prove that in  dynamic minimum support we can achieve higher  computation in less time.



