An Approach to Prediction of Precipitation Using Gini Index in SLIQ Decision Tree

Abstract? Prediction of rainfall is the essential problem to be solved. The variation in the rainfall is primarily attributed to its association with Humidity, Temperature, Pressure, Wind Speed and Dew Point etc. Several works have been done in this field over the past few decades. An accurate prediction of rainfall events can aid in accurate financial planning of the economy of nation. The unpredictable natural disasters like floods and droughts not only affected the economy of a country but also the lifestyle of people of the countryside.  Data mining is a influential approach which helps in extracting hidden information from huge databases and allows decisions to be taken on knowledge mining basis.  This paper highlights Supervised Learning in Quest (SLIQ), decision tree algorithm using Gini Index in order to predict the precipitation with an accuracy of 72.3% and is completely based on the historical data. The decision tree is constructed and the classification rules are generated.

Keywords- Data Mining; Soft Computing; Decision Tree; Meteorology; Prediction; Precipitation; Rainfall; SLIQ;

I.  INTRODUCTION Rain is a form of liquid precipitation whereas snow, hail  and sleet are non-liquid forms of precipitation. The thick layers of clouds when the temperature of cloud is higher than melting point of water [8]. Condensation of atmospheric water vapor makes drops of water heavy enough to fall on the surface of earth.

Prediction of weather has been one of the most interesting, complex, challenging and exploring domain since the dawn of the civilization. The researchers tried to forecast the meteorological characteristics using various methods but it has not been succeeded. Later it is found that data mining, a newly developed method can be successfully applied in prediction of precipitation. Data mining is a promising tool for data analysis to find patterns and relationships in data that may be used to make valid predictions. Some commonly used Data mining tools are artificial neural networks, genetic algorithms, rule induction, nearest neighbor method and memory-based reasoning, logistic regression, discriminate analysis and decision trees.

Here we applied a SLIQ (Supervised Learning in Quest) [1,4] decision tree algorithm which provides the maximum accuracy in prediction of precipitation for rainfall.

The rest of the paper is organized as follows: Section II provides background information about the Decision Trees.

In section III, a brief description on SLIQ Decision tree is provided. In section IV, the procedure for the selection of the root node in the decision tree is described, whereas section V discusses the performance measures of the model and finally  in section VI, the results that are generated by the model are displayed.



II. DECISION TREE Decision tree is one of the most powerful, popular, fast  and easy to implement technique for knowledge discovery and data mining to find useful patterns in science and technology from large and complex bodies of data [1-3], [9,10]. Hence theoreticians and practitioners continuously are practicing techniques to make the process more accurate, efficient and cost effective. Initially Decision trees are used in decision theory and statistics. Decision trees are also effective tools in Data mining, Text mining, Information retrieval, Machine learning and Pattern recognition.

The essence of a decision tree lies in splitting the data sets into branches thus originating an inverted decision tree with root node at the top. The object of analysis is a one dimensional display reflecting in the root node in the decision tree interface. Decision trees can be constructed for continuous and categorical data sets, shown in Fig.1. The values in the input field are used in estimating the likely value in the target field which is an outcome or response of the variable to be predicted.

Let us consider the data set which is comprised of parameters (Humidity, Temperature, pressure, Wind Speed and Dew point) and class label as given in Table I and the final obtained decision tree is shown in Fig. 1.

In order to predict the weather corresponding to prediction of rainfall, decision tree algorithms in data mining plays a crucial role as these algorithms give the accurate predictions.

So, here we applied a SLIQ decision tree algorithm in order to predict the rainfall and the entire prediction is based on the historical data.



III. SLIQ DECISION TREE ALGORITHM SLIQ is a decision tree classifier designed to classify large  training data. The data is sorted prior to the algorithm is executed. All the other classifiers sort the data at each node which is found to be costly. SLIQ is an efficient classifier which avoids sorting at each node, the data which is sorted at the beginning of the algorithm is allocated a separate memory location for each attribute and this list is called class list. The data entered in the class list has a class label and this class label becomes node in decision tree and it has the attribute value and it points to the data item in class list. For each attribute, it scans the corresponding sorted list and calculates Gini Index values of each distinct value of all the nodes in the frontier of the decision tree simultaneously.

After the Gini Index values have been calculated for each   DOI 10.1109/ISMS.2013.27     attribute, one attribute is chosen for a split for each node in the current frontier, and they are expanded to have a new frontier. This scanning continues until the new nodes are attained.

TABLE I.  TRAINING DATASET   Humidity Temperature Pressure Wind Speed Dew Point Class  100 27 1012 5 24 Rain 100 27 1013 6 23 No Rain 100 27 1014 5 23 No Rain 100 26 1014 6 22 Rain 100 26 1013 6 23 No Rain  94 26 1013 6 21 No Rain 100 24 1014 8 21 No Rain  88 24 1013 8 16 No Rain 88 23 1012 5 16 No Rain 94 23 1011 5 16 No Rain    A. Splitting Criteria Initially the training data is taken and then sorting it  completely for every attribute at the beginning of the tree growth phase [2]. Initially we consider the attribute Humidity and class label to find the best split point.

Whenever there is a change in the class label then immediately find the midpoint of the changed class labels and repeat the procedure until it reaches end as shown in Table. II.

From the Table II (a) it is clearly visible there is a change in the class label at 9th position so here we are taking the midpoint of 8th, 9th class label values i.e., midpoint (100,100)=100 and for the Humidity attribute there is only one split point because class label is changing at only one position. Repeat the procedure for all attributes and find the split points for every attribute. The same procedure is repeated for the rest of the attributes as shown in Table II (b), Table II (c), Table II (d), Table II (e) respectively.

TABLE II.  DATASET SORTING ON HUMIDITY, TEMPERATURE, PRESSURE, WIND SPEED AND DEW POINT  Humidity Class 88 No Rain 88 No Rain 94 No Rain 94 No Rain  100 No Rain 100 No Rain 100 No Rain 100 No Rain 100      Rain 100      Rain    (a) SPLIT POINT FOR ATTRIBUTE HUMIDITY   Temperature Class 23 No Rain 23  No Rain 24 No Rain 24 No Rain 26 No Rain 26 No Rain 26      Rain 27 No Rain 27 No Rain 27      Rain    (b) SPLIT POINT FOR ATTRIBUTE TEMPERATURE   Pressure Class 1011 No Rain 1012 No Rain 1012      Rain 1013 No Rain 1013 No Rain 1013 No Rain 1013 No Rain 1014 No Rain 1014 No Rain 1014      Rain    (c) SPLIT POINT FOR ATTRIBUTE PRESSURE   Wind Speed Class 5 No Rain 5 No Rain 5 No Rain 5      Rain 6 No Rain 6 No Rain 6 No Rain 6      Rain 8 No Rain 8 No Rain    (d) SPLIT POINT FOR ATTRIBUTE WIND SPEED   Dew Point Class 16 No Rain 16 No Rain 16 No Rain 21 No Rain 21 No Rain 22      Rain 23 No Rain 23 No Rain 23 No Rain 24      Rain  (e) SPLIT POINT FOR ATTRIBUTE DEW POINT   Fig. 1. Gini Index based SLIQ Decision Tree.

Split point Values    26.5     1012.5       Split point Values  Split point Values  5.5    Split point Values   21.5 22.5   23.5     Split point Values              Now take the split point and divide it into less than and  greater than equals to order and then calculate the Gini Index for that split point and repeat the process for all the split points.

Now compare all the split point?s Gini index values, the value which is maximum is the best split point for that attribute as shown in Table III.  The info value obtained for the attribute is to be subtracted from the Gini index value of class label in order to obtain the gain value for that attribute and as it follows:   Gini Index(V)=Gini Index(D)-infov(D)              (1)   In the second level take temperature and class label and  repeat this procedure for all the attributes and finally we will get the best split points for all the attributes and choose the maximum Gini Index value and that itself is the root node and based on the threshold value of the root node generate the tree and repeat the procedure till it is terminated with unique class label.



IV. PROCEDURE FOR FINDING NODES In the construction of the decision tree Gini index is  evaluated at every successive midpoint of the attribute values. However, the efficiency of SLIQ decision tree algorithm can be improved by evaluating Gini index only at midpoints of attributes where the class information changes.

The algorithm is given as follows.

function decision tree construction 1. Read training data D 2. Take the class label attribute and calculate the Gini  Index for class label  ? =  ?= N  i iPIndexGini   21                                   (2)  Gini Index of attribute is calculated as  ? ? = =  ? ?  ? ? ?  ? ?= N  j  N  i ij PPInfo  1 1  21                                (3)  3. Take the attribute V from D and sort it in ascending order  4. Take the corresponding class labels and attribute values as a pair  5. Perform splitting              For Splitting Let V be then attribute list Vi  be the set of values in attribute V Vi+1  be the changed class value for attribute V   Splitting point=midpoint(Vi, Vi+1)                 (4)   6. If there are N splitting points for the attribute then the  maximum gain value is considered as the best splitting point.

Splitting point=Maximum Gain value for attribute    (5)   7. The attribute with maximum Gini index value is taken  as root node.



V. PERFORMANCE MEASURES A. Accuracy  Classifier accuracy is the ability to predict correctly the class label of new or previously unseen data. The test data is given as input to the decision tree and thus the output is generated. The predicted value is compared with the training dataset class label, and if the results are correct, it is experimentally proved.

Accuracy=Correct predictions / (correct predictions +  incorrect predictions)                          (6)  B. Redundancy The final tree may contains some unwanted data as it  increases memory so de-allocate it we are using tree pruning technique which finally produces minimized decision tree i.e., the final tree doesn?t contains any redundant data.

C. Scalability This algorithm takes N input attributes and N number of  classes as an input and produces the minimized decision tree followed by pruning techniques.

D. Rules for Decision Tree Once the decision tree is constructed, there is a  possibility that the tree is very large to understand. Hence, to simplify the understanding of the large decision tree the rules are generated.

If [(dew-point < 21.5)] Then (Prediction = norain)   TABLE  III     GINI INDEX BASED SPLIT VALUE FOR VARIOUS ATTRIBUTES Humidity Temperature Pressure Wind Speed Dew Point  Split Value Gini Index Split Value Gini Index Split Value Gini Index Split Value Gini Index Split Value Gini Index  100.0 0.053 26.0 0.0533 1012.0 0.008 5.0 0.0333 21.5 0.08 26.5 0.0156 1012.5 0.0185 5.5 0.0333 22.5 0.01 27.0 0.0134 1014.0 0.0185 6.0 0.0333 23.5   0.142 7.0 0.02     If [(dew-point >= 21.5) and (wind-speed < 7.0) and (pressure < 1012.5)] Then (Prediction = rain)  If [(dew-point >= 21.5) and  (wind-speed < 7.0) and (pressure >= 1012.5) and  (dew-point < 22.5)] Then (Prediction = rain)  If [(dew-point >= 21.5) and  (wind-speed < 7.0) and (pressure >= 1012.5) and  (dew-point >= 22.5) and  (wind- speed < 5.5)] Then (Prediction = norain)  If [(dew-point >= 21.5) and  (wind-speed < 7.0) and (pressure >= 1012.5) and  (dew-point >= 22.5) and  (wind- speed >= 5.5) and  (temperature < 27.0)] Then (Prediction = norain)  If [(dew-point >= 21.5) and  (wind-speed < 7.0) and (pressure >= 1012.5) and  (dew-point >= 22.5) and  (wind- speed >= 5.5) and  (temperature >= 27.0)] Then (Prediction = rain)  If [(dew-point >= 21.5) and  (wind-speed >= 7.0)] Then (Prediction = norain)

VI. RESULTS Gini index is generally used to measure the inequalities among the statistical data and its frequencies. So far, its use has been permitted for the analysis of wealth and income of the economically advanced countries. Due to the inequalities present in the probabilities, there may be some error. But, irrespective of its limitation present it has a wide variety of applications in statistical analysis.

Gini index is used here for the construction of decision tree where the roots and sub-roots are classified based on gini index. The use of Gini index for the rainfall analysis is quite apt because of the irregularities present in the statistical data of precipitation. The precipitation data used does not follow an order or in other words a sequential path.

This may be due to the inequalities of the present attribute with former attribute. This may change to a great extent or to some extent depending on the Mother Nature.

In this paper, the analysis has been made to test the efficiency of Gini index in the prediction of rainfall by constructing a decision tree. It has been found in Table-IV, the distinction between the success rate of prediction and time. From the Fig. 2 (a), it can be analyzed that the rate of success in prediction of precipitation follows an irregular path which reflects the behavior of Gini index. It can also be observed that the maximum efficiency obtained is 78.05% for a time span of 5 years data set. The average efficiency has been found to be 72.3% for the entire 14 year data set which are considered here. Though, this contributes a decent efficiency or success rate, the other methods of backpropagation neural networks [6,7] [11-14], linear discriminate statistical analysis [15] and J48 are analyzed to select the best performing method of prediction of precipitation using decision trees.

TABLE  IV RESULT SHOWING THE ACCURACY, ERROR RATE AND TIME OF RESPONSE  Data (Years)  No. of Records  Average Testing Accuracy (%) Error Rate  Time of Response  1 365 69.62025 0.3037975 2 2 727 73.41772 0.2658228 2 3 1092 77.21519 0.2278481 3 4 1458 65.82278 0.3417721 3 5 1823 78.05907 0.2194093 4 6 2188 74.68355 0.2531645 4 7 2553 75.94936 0.2405064 5 8 2919 72.99578 0.2700422 6 9 3281 72.99578 0.2700422 6  10 3638 67.08861 0.3291139 6 11 3997 71.72996 0.2827004 8 12 4264 72.99578 0.2700422 9 13 4627 70.04219 0.2995781 9 14 4992 70.46413 0.2953587 10     (a) AVERAGE TESTING ACCURACY     (b) ERROR RATE     (c) TIME OF RESPONSE   Fig. 2. ACCURACY GRAPH (a) YEAR VS ACCURACY, (b) YEAR VS ERROR  RATE, AND (c) YEAR VS TIME OF EXECUTION.

Some experiments have been conducted on real data to analyze the accuracy of the tree. We have used the dataset from the accuweather.com of Indian Meteorological Department. The goal is to predict the precipitation for rainfall. The dataset consists of 1 to 15 years of data from the year 1997 to 2012 containing 365 to 4992 examples.

Published results for this dataset are: 64.3% accuracy for backpropagation, 58% for a linear discriminant and 68.6% for J48. Using the same training and test sets, the average accuracy using SLIQ with Gini index is 72.3%.



VII. CONCLUSION Water is indispensable for the life on this planet. So  rainfall becomes the significant aspect that a nation must rely for the development of its economic prosperity. The variation in the rainfall is primarily attributed to its association with Humidity, Surface Temperature, Sea Level Pressure, and Wind Speed, Dew Point etc. Previously many techniques have been applied in prediction of precipitation using the approaches such as Neural-networks, Artificial Intelligence, and Fuzzy-Logic, which didn?t give the accurate results. So, we applied decision tree method using SLIQ to implement the precipitation prediction model. This model outputs results whether rain falls or not based on the climatic data obtained from meteorological department. It is observed that Decision Tree method achieves closer agreement between actual and estimated rainfall. SLIQ method gives higher accuracy rate when compared to other prediction models.



VIII. FUTURE ENHANCEMENTS In this paper, we highlighted Gini Index based SLIQ  decision tree algorithm, which gives maximum accuracy and in future implementation various other decision tree algorithms like CART, SPRINT, ELEGANT, EC4.5 with additional parameters can be developed.

