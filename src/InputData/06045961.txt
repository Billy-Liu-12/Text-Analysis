Optimization of Privacy Preserving Mechanisms in Homogeneous Collaborative

Abstract?This article focuses on optimization of cryptographic mechanisms used in association rules multiparty mining algo- rithms with preserving data privacy. The major part of attention is focused on increasing the performance because the computation expense can be prohibitive when applying to large databases. We introduce how to use a Common Decrypting Key for commutative encryption in Secure Set Union to improve performance. As an example of the above mentioned mechanism application, the article presents a new algorithm of mining association rules on horizontally partitioned data with preserving data privacy - CD- KSU (Secure Union with Common Decrypting Key). CDKSU is an application of the Common Decrypting Key for a commutative encryption in a Secure Set Union. This algorithm is compared to the KCS scheme (referenced as HPSU also) since they are both based on FDM. As far as the performance optimization is concerned, the application of Elliptic Curve Cryptography versus Exponential Cryptography is presented as well. We believe that this is the first description of application of the Elliptic Curve Pohlig-Hellman Cipher. The system implementing given algorithms is described and subjected to performance tests.

Finally, the results of these tests are presented and analyzed.



I. INTRODUCTION  In the modern business, success depends on collaboration and partnership. Collaborative data mining becomes highly important, because of the mutual benefit the partners gain.

Collaboration occurs among companies that have conflict of interests or compete against each other on the market. During collaboration multiple parties want to conduct data mining on a data set that consist of all the parties? private data, but neither party wants the other parties or any third party to learn much about their private data. It makes data privacy mechanisms extremely important. The performance expense of this mechanisms, however, can be prohibitive when applying to large databases. This article focuses on optimization of  cryptographic privacy preserving mechanisms in association rules mining algorithms on horizontally partitioned data.

A. Related works  There is a great interest in research on privacy-preserving data mining [1]?[4]. There have been proposed privacy pre- serving algorithms for different data mining applications, including clustering [5]?[8], association rules mining on ran- domized data [9], [10], association rules mining across multi- ple databases [11], [12], Bayes classification [13]?[16], deci- sion trees on randomized data [2], frequent pattern mining [17] and collaborative filtering [18]. Additionally, several privacy preserving solutions have been proposed for simple primitives that are very useful for designing privacy preserving data mining algorithms. These include computing scalar products [11], [19]?[23] and finding common elements [2], [22]. The Secure Multiparty Computation paradigm provides crypto- graphic solutions for protecting privacy in any distributed computation [24], [25]. Works most related to ours are [12], [26], [27]. We have improved Secure Sum scheme [26] and created a new algorithm similar to KCS (Kantarcioglu and Clifton Scheme) [12] (referenced as HPSU also [28]) and based on FDM [27]. We have not come across any study dealing with the Ecliptic Curve Cryptography (ECC) used in multiparty data mining.

B. Our contribution  We have demonstrated that it is possible to increase perfor- mance focusing on optimization of cryptographic mechanisms used in the given algorithms. Of all the elements of protection, encrypting has the highest computation expense, but contrary to distorting input data, it does not disturb the results. Previous research in mining association rules on horizontally partitioned data deal with commutative [12], [28], [29] and homomorphic   DOI 10.1109/ARES.2011.58     encryption [30]. They all describe the use of exponential ciphers. It is recommended to substitute exponential ciphers with methods based on Elliptic Curve Cryptography [31], [32].

In this article, the application of Elliptic Curve Cryptography (ECC) versus Exponential Cryptography is presented. We introduce the manner of using a Common Decrypting Key (CDK) for commutative encryption in a secure union to improve performance as well. As an example of the usage of the above mentioned methods, we have presented our own algorithm CDKSU (Secure Union with Common Decrypting Key). This algorithm is compared to KCS [12], since they are similar and both based on FDM [27]. The system imple- menting given algorithms is subjected to performance tests.

The comparison of the tests results shows the performance benefits that stem from the use of CDK and ECC.



II. HOMOGENEOUS COLLABORATIVE ASSOCIATION RULES MINING WITH DATA PRIVACY PRESERVING.

The introduction to the association rules multiparty mining algorithms with preserving data privacy can be found in [28], [33]. They are essential, if multiple parties want to find association rules in a data set that consists of all the parties? private data, but neither party is willing to disclose its private data to the other parties or any other parties.

There have been two main approaches for privacy preserv- ing in multiparty association rules mining. One is a random- ization approach [9], [10] in which the privacy of data cannot be always fully preserved while achieving the precision of the results [34], [35]. The other is a cryptographic approach mostly using SMC (Secure Multiparty Computation) [25], [26]. Most efficient privacy preserving solutions can be often designed for specific distributed computations. We focus on SMC-based association rules mining algorithms on horizontally partitioned data in the cryptographic approach. This task is also known as a heterogeneous collaborative association rule mining [12], [28], [33]. By using CDK for a commutative cipher, we have improved a Secure Set Union method [26] commonly used in such algorithms. We have designed a new multiparty association rules mining algorithm CDKSU as an example of an algorithm using CDK. This algorithm is based on FDM and uses a commutative encryption with CDK.



III. CRYPTOGRAPHIC PRIVACY PRESERVING MECHANISMS IN A HOMOGENEOUS COLLABORATIVE ASSOCIATION  RULES MINING.

A. Commutative encryption  An encryption algorithm is commutative if given encryption keys K1, . . . ,Kn ? K, for any m in domain M , and for any permutation i, j, the following two equations hold [26]:  EKi1 (. . . EKin (m) . . .) = EKj1 ( . . . EKjn (m) . . .

) ? m1,m2 ?M such that m1 6= m2 and for given k, ? < 12k  Pr [ EKi1 (. . . EKin (m1) . . .) = EKj1  ( . . . EKjn (m2) . . .

)] < ?  B. Commutative encryption with common decryption key  We have come up with a new method of defining a CDK (Common Decrypting Key) for a commutative encryption. For a commutative encryption E you can determine CDK, if for the given decrypting keys K1, . . . ,Kn ? K it is possible to determine such a common key Kd that, when using it to decrypt D for every message m in domain M and for every permutation i, j, the following equation is hold:  DKd ( EKj1  ( . . . EKjn (m) . . .

)) = m  Key Kd is called the Common Decrypting Key.

C. Pohlig-Hellman exponential commutative cipher  We used Pohlig-Hellman encryption scheme with modulus shared among parties [36]. For given finite field GF (p) where p is prime, ? operation in it, field element m and integers e, d such that ed = 1 (mod (p? 1)), we know that med = m1+k(p?1) = m1 ? 1 = m. Based on exponentiation in such finite fields there are two operations defined: encryption me = n, and decryption nd = m. Element m is the plaintext message and pair {e, d} is the secret key. It satisfies equations given in III-A because for every a and b the equation (ma)b =  ( mb )a  is held. Thus Pohlig-Hellman cipher is commutative.

Let?s assume that we have a pair of keys {e, d} satisfying  the conditions from III-B: K1 = {e1, d1} and K2 = {e2, d2}.

For each pair like that (in the same field GF (p)) the following equation is true: ((me1)e2)d1d2 = m. This case can include any number of keys. Thus, by multiplying all the decrypting keys we will get CDK.

D. Elliptic curves cryptography  This work presents the use of ECC in association rules multiparty mining algorithms with preserving data privacy.

Smooth elliptic curves that were used had points that had integer coordinates in finite fields Zp. When referring to elliptic curve further, we will have in mind this type of smooth curve. Introduction to elliptic curves and their usage in cryptography can be found in [37]. In order to use elliptic curves cryptography we have to encode our plaintext data as points on some given elliptic curve E over a finite field Zp. We use a probabilistic algorithm given by Kolbitz at the beginning of the Elliptic curve cryptosystems chapter in [38].

1) Elliptic Curve Pohlig-Hellman cipher: The Elliptic Curve Pohlig-Hellman cipher is described in [39]. It works exactly like the Pohlig-Hellman cipher, except for the fact that the multiplicative group of integers modulo p is replaced by the additive elliptic curve group.

E. Secure Sum and Product  The secure sum is often given as a simple example of a secure multiparty computation [26], [40]. The secure product works just like the sum except that the addition is replaced by multiplication and subtraction by division. Assuming three or more parties and no collision, the following method securely computes the sum of values from the individual sites.

F. Multiparty calculation of Common Decrytping Key  Using a multiparty secure product calculation method one can determine CDK for Pohlig-Hellman and Elliptic Curve Pohlig-Hellman ciphers. When using this method, if all other sites agree, CDK can be revealed to one of the designated sites, but the secret encrypting keys that belong to these sites won?t be revealed.

G. Calculating Secure Set Union using encryption with CDK  Using a commutative encryption described in the previous chapter, one can securely calculate the union of sets belonging to many parties without revealing the originator of the partic- ular element. Each party that takes part in the process, has its own encrypting key. If every l site has its own private set Zi, then by calculating the set union, we mean calculating  ?l i=1 Zi  One special type of site has been designated ? Site D. It is responsible for decrypting data, initializing the computation of a CDK, and it is the only site that knows its value. Because of that, the communication should be conducted in such a way, that it has no contact with other sites? data encrypted by all the sites, which at the same time do not belong to the result.

Computation on fully encrypted data will be conducted by the rest of the sites that do not have the access to the CDK.

1) Each party encrypts its own data set and sends it to the next party. When the next party receives data from the previous party, it enciphers it again using its own encrypting key and sends it to another party.

2) This process is repeated until all the data sets are encrypted by all the parties. Then, among the parties which are not Site D, the calculation of the union of sets of encrypted values is conducted.

3) Using multiparty Secure Sum algorithm the CDK is calculated.

4) The resulting union is sent to Site D, which deciphers it and then sends to the other parties.

The use of the CDK reduces the number of expense operations required in order to obtain the result. It is worth mentioning, that analogically one can conduct the computation of intersection of the sets  ?l i=1 zi.



IV. CDKSU ALGORITHM  Our CDKSU algorithm (Secure Union with Common De- crypting Key) conducts multiparty association rules mining algorithms on horizontally partitioned data. It preserves data privacy in semi-honest model [41]. It assumes that the parties involved will honestly follow the protocol, but can later try to infer additional information from whatever data they receive through the protocol. The algorithm is similar to KCS (HPSU), and differs mainly in the way it safely determines the union of locally supported itemsets without revealing the originator of the particular itemset. Despite that privacy protection in this algorithm is based on the same concept (except for CDK which is described in a separate section).

Let us assume that a transaction database DB is horizontally partitioned among n ? 3 sites (namely S1, S2, ..., Sn). Each  site has a private transaction database DB1, DB2, ..., DBn where DBi resides at site Si. The itemset X has the local support count of X.supi at site Si, if X.supi of the transac- tions contains X .

1) Generation of locally large itemsets.: Candidates to be recognised as locally large (frequent) itemsets are generated using Apriori property [42], from the intersection of the list of locally large itemsets from a previous operation with the list of globally large itemsets from previous operation, so from these locally large itemsets, which were recognised as globally large.

In the first iteration these are all one element itemsets. Parties locally prune candidates and leave out only locally large itemsets. In order to hide the number of locally large itemsets, fake sets are added. The number of fake itemsets is randomly generated from a Uniform distribution in such a way, that the final number of the locally large itemsets does not exceed the number of the candidates. We do not have to concern about fake item set content because when calculating a secure union they are encrypted. Its items have simply got uniform random identifiers and one of them has random identifier from a range dedicated for fake items. Without reducing the security of the algorithm, it allows to reject fake sets after decrypting the element of the union.

2) Secure determination of the union of locally large item- sets.: When using the method described in III-G locally large itemsets union is safely designated. In order to do this, commutative cipher with CDK is used. Each site has a secret key, which enciphers elements. Each itemset is enciphered by each site. Next,the union of sets of itemsets that belongs to each party is calculated, as described in III-G. In order to hide the number of parties that possess the given itemset, the union of sets that belongs to the parties assigned an even ordinal number are calculated by one of the parties, and the parties that are assigned an odd ordinal number are calculated by another party, the results are then summed up. The obtained set of all the itemsets is decrypted by Site D in order to get a plaintext result. Sets that are left after rejecting the fake sets are candidates for globally large itemsets. Fake itemsets can be recognised, because they include an element with an identifier assigned to false sets. It allows to reject the false sets as soon as the element from the union are deciphered.

3) Secure determination of globally large itemsets.: In or- der to check if the set X is globally large, it is checked whether its exceeding support which equals X.sup ? s ? |DB| =?n  i=1 (X.supi ? s ? |DBi|) is nonnegative. That means it meets the global support threshold. It is explained in details in [12]. Exceeding the support of every candidate for globally large itemset is calculated by using Secure Sum algorithm described in III-E. On its basis, new globally frequent itemsets are designated.

4) Secure determination of strong association rules.: Out of globally large itemsets all the possible association rules are designated. Next, analogically to the computation of globally large itemsets exceeding support, exceeding confidence of rules is designated using Secure Sum described in III-E.

Exceeding confidence of rule X?Y for the party Si equals     ?n i=1 (XY.supi ? c ?X.supi), where XY.supi means a local  support for the set X ? Y , and c is the minimal support threshold. Rules that meet minimal support threshold are sent to all the sites as a result.

The algorithm used in the semi-honest model is not fully secure under the definitions of secure multiparty computation.

It should be pointed out, that similar to KCS it reveals the number of itemsets having a common support between sites (.e.g. party No. 2, 4, and 6 all support some itemset.) without revealing the content of these itemsets. By comparison, in computation with a trusted third party this information is not revealed.



V. IMPLEMENTED SYSTEM  For research purposes, the system has been implemented in Java. Such implementation allows to compare efficiency of each algorithm without favoring any of them. The system consists of a set of multithreaded components corresponding to the building blocks used to build the multiparty data mining algorithms. The blocks are connected in a declarative manner (using the Inversion of Control container), so that data flows are created. All connections are defined in configuration files to enable the implementation of new algorithms. It is possible to define local and network connections between components to build real multiparty systems. All algorithms have been built in the same framework, and any differences in the implementation correspond exactly to the differences in the algorithm logic. Even those elements in which the algorithms differ have been built, as far as possible, from the same components and using exactly the same technology.



VI. PERFORMANCE TESTS  In order to compare the efficiency of implementations of algorithms performance tests were conducted. Additionally the performance of CDKSU algorithm with exponential Pohlig- Hellman cipher (PH) against CDKSU with Elliptic Curve Pohlig-Hellman (ECPH) cipher was compared.

A. Test Environment  The system in the present test configuration consisted of four sites. Each party had two computers (Microsoft Windows XP Professional SP3; IntelCoreTM2 Quad 2.66GHz; 2GB RAM; HD: 250GB, SATA2, 7200rpm, 16MB cache) ? one reserved for the database (Oracle 11g), and the second for the system engine. Computers were connected to the LAN with a throughput of 80.0 Mbits / sec.

B. Test data sets and parameters  Performance tests were conducted on a randomly generated test data. It was generated in such a way that it resembled the sales transaction data which is typical of the data analyzed in the process of discovering association rules. A periodical exponential pseudorandom generator was used. It favored groups of elements that simulated sales transactions. The datasets with 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4 and 1.6 milions of transaction were prepared. The number of possible elements  of the transaction for all data sets is 100 and the maximum number of elements in a single transaction is 30. On average transactions includes 15 elements. Each of the data set has been uniformly distributed between the four parties. We ran tests with a various minimal support threshold. Preliminary tests confirmed that the minimum certainty threshold of a rule certainty has negligible impact so we run all the test with fixed 70% threshold.

Due to the large, variable number of random distorting data, each measurement was performed in two versions. Pessimistic case was with the maximum amount of distorting data and optimistic with the minimum.

When comparing the performance of the CDKSU algorithm with the exponential Pohlig-Hellman cipher (PH) against the CDKSU with the Elliptic Curve Pohlig-Hellman (ECPH) cipher encryption parameters were selected according to the guidelines from [31], [32], [43] to provide a similar protection for both algorithms. It corresponds to the protection afforded by a conventional 112-bit symmetric algorithm:  ? Elliptic Curve Pohlig-Hellman cipher (ECPH) with prime239v1 parameters (239b prime) [31], [43].

? Pohlig-Hellman cipher (PH) with a 2048b key.

C. Test results  The diagrams below shows the results of comparative performance tests. It should be noted that in addition the functional tests were also performed.

Fig. 1. Comparison of CDKSU algorithm with exponential cipher against CDKSU with elliptic curve cipher. Pessimistic execution time with 15% minimal support threshold, versus input data set size.

1) Comparison of CDKSU algorithm with the exponential cipher against CDKSU with the elliptic curve cipher.: All performance tests have shown that the use of ECC greatly speded up the algorithm. Performance gain is not linear and depends both on the size of the input set and the minimum support threshold. This is clearly shown especially in figures 1 and 2 illustrating the pessimistic case. There is also visible that when using encryption based on elliptic curves the efficiency of the entire algorithm depends mainly on the size of the input data set. It appears that the minimum support threshold have much less impact. Reducing the productivity gap with the increase in the size of the test set resulted from the increasing databases overload. This was caused by the fact     Fig. 2. Comparison of CDKSU algorithm with the exponential Pohlig- Hellman cipher (PH) against CDKSU with the Ecliptic Curve Pohlig-Hellman (ECPH) cipher. Pessimistic execution time versus minimal support threshold.

Input data set has 800k transactions.

that the database hard drives were not designed for parallel access.

Fig. 3. Comparison of CDKSU with KCS. Pessimistic execution time versus data set size. The 2048b Pohlig-Hellman cipher was used together with a 15% minimum support threshold.

Fig. 4. Comparison of CDKSU with KCS. Pessimistic execution time versus minimum support threshold. The 2048b Pohlig-Hellman cipher was used together with the data set with 800k transactions.

2) Comparison of CDKSU with KCS.: On most charts, it appears that CDKSU algorithm has better performance than KCS. Especially figure 3 shows the difference between KCS and CDKSU very clearly. It illustrates the pessimistic case where the number of candidates is equal to the maximum number of locally large itemsets with frequent fake sets. All the fake locally sets are part of the union and are decrypted.

CDK significantly reduces the cost of decryption. With the largest test sets, for all algorithms an exponential curving of the characteristics is visible due to the system working near the performance limit. Optimistic tests differed slightly. The optimistic outcome, however, is not very interesting. Data that were well selected for the analysis will have much more in common. Figure 4 shows differences in pessimistic execution times, as well as the asymptotic decrease of the execution time depending on the minimum support threshold, which is a typical feature of association-rule discovery algorithms based on the Apriori algorithm. Execution times to a small extent depend on the size of the input data set size because of the fixed number of possible elements of the transaction. The number of possible elements of the transaction determines the number of candidates in the first round. Their number is so large that it determines the execution time.



VII. CONCLUSION Tests have shown that the efficiency of the applied crypto-  graphic algorithm contributes to the efficiency of the whole algorithm to a great extent. The tests have shown a great increase in the efficiency of the CDKSU algorithm when compared with KCS, which is due to the use of CDK. Also the tests have shown an increase in the speed of processing by 2 to 6 times in the pessimistic case of the CDKSU algorithm due to the use of ECC. As it was expected, elliptic curve cryptosystems are more computationally efficient than the exponential cryptosystems. The computational cost of the encryption based on the curves (with the protection equivalent to 112-bit symmetric encryption algorithms) is approximately six times smaller [32]. Although elliptic curve arithmetic is slightly more complex. It was not clear how this affected the efficiency of the whole data mining algorithm, especially the efficiency of CDK. Such increase in the efficiency is crucial, since in the production environment, the input data sets can be much bigger. To our knowledge, this is the first paper describing the practical use of the Elliptic Curve Pohlig- Hellman cipher and its implementation tests. Also, we have not come across any study dealing with the ECC used in the multiparty data mining. In further research, the prospect of the use of elliptic curve homomorphic ciphers seems to be interesting. The execution time is difficult to predict not only because of the arrangement of the input data, but the considerable influence of random data used to conceal the data structure belonging to one party as well. The efficiency of the mentioned algorithms has not been fully tested. Closer attention should be devoted to the influence of the arrangement of the input data and the efficiency of the algorithms whose data are real and not artificially generated should be tested.

