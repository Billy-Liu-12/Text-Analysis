

<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">SECOND IEEE Multitarget Tracking in Clutter: Two Algorithms for Data Association Using BPNN and LVQNN M. Daneva Absfract4n this paper two algorithms for data association in the context of multiple target tracking on non- manoeuvring aircrafts using Back-Propagation Neural Network (BPNN) and Learning Vector Quantization Neural Network (LVQNN) are presented. The performances or the algorithms are compared with those of the standard method for data association based to the nearest-neigbhnur rule by Monte Carlo experiment and by using real radar data records.

Index Term-neural networks, radar data processing

I. INTRODUCTION Radar data processing in automatic systems for air traffic control (ATC) obtains information about the aircraft's spatial location, speed and acceleration, beading angle, etc. Multiple target tracking (MTl') procedures use the radar information obtained from several radar scans.

The MTT system includes the following element: sensor data processing and measurement formation; correlation and data association; track initiation, confirmation, and deletion; track filtering and prediction; gating procedure.

The algorithms for data association (DA) in M l T  occupy an impoltant place in automatic systems for radar data processing for ATC. The purpose of the DA algorithm is to classfy the received radar measurements to the available tracks in the presence of clutter during the MTT process using the estimated kinematic parameters of the aircrafts provided by the tracking filter [l], [2]. As a part of the total set of algorithms for MlT, the DA algorithms can be probabilistic and heuristic [2]. The first are based on statistical methods, and the second are based on the artificial intelligence approach and in particular on the neural networks (NNs). The main differences between them are first, the heuristic algorithms can do their functions without a priori knowledge about the statistics of the input data, and second - they are "model-free". An important quantity to each DA algorithm is to ensure high percentage of correct decisions (associations or c~assifications) PCC PA) . It reflects onto the safety level in ATC and the flight safely too. The accuracy of the algorithm for DA and the accuracy of the estimate provided by the tracking filter reflect to a great degree to M. D. Author is a W.D. student with the Dept. Of Radiocornmi- cations, Faculty of Communications and Communicational Technologies, Technical University of Sofia, 8 KI. Ohridski sv., 1000 Sofia, Bulgaria (telephone: +359 02 965 32 97, e-mail: mimidan@ttu-sofiabg).

0-7803-8278- 11041$20.00 02004 IEEE 92 pCc PA) [I]. The accuracy of a neural DA algorithm depends on the choice of the most appropriate neural architecture, the learning paradigm, the pattern formulation, the accuracy and convergence of the training algorithm and the NN's initialization method [3]-[5].

The used in practice neural DA algorithms for MTT usually are realized on a classification principle to use the capacities and main advantages of the NNs more completely. Suitable for association problems are the recurrent NNs as the Hopfield network, the associative memories, recurrent autoassociative NNs, Elman network, adaptive resonawe theory NNs, as well as some self- organizing networks - Kohonen maps, SARDNET (Self-  Organizing Feature Map for Sequences), etc. The use of Multilayer Perceptrons (MLPs) for autoassociation leads to relatively good results, because the separation surfaces in this case are always closed surfaces. The Radial Basis Functions NNs can be used in this case too. The feedforward NNs, as well as the recurrent NNs can be    feedforward NNs, as well as the recurrent NNs can be used for classification purposes. MLPs are the traditional NNs for classification. They have relatively good generalization performance, and are the closest NNs to the optimal Bayesian classifier, which ensures the probability of correct classification of approximately 81.51 %. The LVQNNs ensure Pcc ('?A) close lo this for the Bayesian case, and which generally appears a hit lower than this for MLPs, but in case of highly non-linear separation boundaries even can exceed it [3]-[SI.

In this paper two algorithms for DA in the context of MTT, one using BPNN and one using LVQNN are presented. They are designed for tracking on non- manoeuvring targets in ATC systems using single secondary surveillance radar, and are realized i n M a r m " 191 environment. Their performances are compared with these of the standard DA algorithm based on nearest neighbour rule (Nearest-Neighbour DA, " D A ) ,  that uses position only radar data [l]. A Monte Carlo (MC) verification of the results is done. An illustrative example using real radar data is shown. The proposed algorithm perfom relatively high PCC (%) - higher than this of NNDA.

11. INPUT DATA, NN ARCHITECTURE, AND BASIS STEPS OF THE ALGORITHMS Two versions of each proposed algorithm are presented.

The basic version use as input data the actual and predicted target positions in polar coordinates range p in nautical miles, azimuth angle 0 in rad, and altitude h in feet, target identification codes, and reflection coefficient [IO]. The extended version uses in addition information about the amplitude of the received signal, measured from the output of the quadratic detector of the receiver in dB.

The algorithms are denoted by BPNNDA (BPNN Data Association) and LVQNNDA PVQNN Data Association) for the case with no amplitude information included, and by BPNNDAAM (BPNNDA with Amplitude Measurements) and LVQNNDAAM (LVQNNDA with Amplitude Measurements) for the case using additional amplitude information. The training set contains the predicted positions of all existing targets, identification codes, and reflection coefficients for BPNNDA and LVQNNDA versions, and, in addition, the predicted amplitudes for BPNNDA and LVQNNDAAM versions.

The training set in the both cases includes simulated data for false targets too. The predicted positions of the targets are obtained by BPNN tracking fdters with model (prediction) order of three for one-step-ahead prediction without [ll] and with additional amplitude information included. The testing set contains the measured values of all the targets? parameters listed above and false measurements too. The tme and false measurements of one and the same target of interest have identical target identification codes, so that the DA algorithm must recognize them and to pass for next processing by the tracking filter and for track update only the measurements, which can be used with the highest convenience. In this context the reflection coefficients and the amplitude . information are used as additional features to distinguish the true measurements of a target from the false. Also, the  target identification codes are used to distinguish the aircrafts each to other.

The neural architecture for BPNNDA and BPNNDAAh4 includes fully coMected multilayer feedfonvard neural network with single hidden layer with hyperbolic tangent activation functions in the input and hidden layer, and linear output layer. The numbers of neurons in the layers are 5-12-5 and 6-156 for the first and the second case, respectively. The Marquardt- Levenberg training algorithm [4], [9] is used. It ensures the highest training convergence and minimum number of    the highest training convergence and minimum number of epochs with relatively good approximation of the error?s minimum than the other training algorithms for BPNN.

The numbers of input and output neurons for LVQNNDA and LVQNNDAAM versions of the algorithm are the same as in BPNNDA and BPNNDAAM cases. The number of competitive neurons in the both of versions is equal to the number of existing tracks of targets, chosen as Q = 6 by reason of available hardware to perform the computations.

.

The basic steps of the algorithms are as follow.

A. BPNNDA and BPNNDAAM algorithm: Step 1. NN Initialization: Random initialization of the weights with minimum bound m&lt;bvl [I21 foI BPNNDA, and by the Shimodaira?s method, variant c [ 121 for BPNNDAAM case. These methods are chosen as the ClOSeSt to the oplimal case among seven weight initialization methods, included the usual random weight initialization in two variants - in[-0.05,0.05] and in [-1,1], the Russo?s metbod, the Statistically Controlled Activation Weight Initialization (SCAWI) method, the Nguyen-Widrow method, and the Nguyen-Widrow-Russo algorithm [4], [5 ]  by separated experiment.

Step 2. Input Data Preprocessing: The normalization coding (NC) which distributes the input data in the interval [4 .9,0.9]  to avoid the high nonlinearly zones of the neurons? activation functions IS] for BPNNDA, and the same NC after Discrete Cosine Transform @CT) through the form DCT-IV [9] for BPNNDAAM.

Step 3. Training data set presentation, set k = 0, where k is the epoch?s number.

Step4. k = k + l .

Step 5. Forward computations: Compute the net internal activity levels and the output signals of all the neurons in the layers according the Mquardt-Levenberg algorithm.

Sfep 6. Error back-propagation: Compute the weight adjustments and the vectors of local error gradients for the output and the hidden units by the same training Sfep 7. Go to steps 4 to 6 to perform the iterations till the error minimum is found or the maximum number of epochs or the maximum learning rate is reached.

algorithm.

Step 8. Compute the local and global error function.

Step 9. Testing set presentation.

Step 10. Actual classification @A) and compute the errors for scan k.

Sfep 11. Data postprocessing: Inverse normalition coding (INC) for BPNNDA; INC and inverse DCT for BPNNDAAM.

Step 12. k = k + 1: Repeat cyclically the steps 2 to 11 till the track deletion criterion, the missed data for a given track for six consecutive radar scans [I31 is satisfied.

B. LVQNNDA and LVQNNDAAM algorithm: Step 1. NN Initialization - The usual initialization for  LVQNN, which sets of the competitive neurons? weights equal to the center-vectors of the classes, and sets the weights of the linear neurons as small random numbers Step 2. Input Data Preprocessing: DCT and NC in Sfep 3. Training data set presentation, set k = 0.

Step 4. Compute the distances between the pattern vector and the Voronoi?s vectors 141, [9] for a training examule a bv ~41.

[4 .9 ,0 .9]  for both of LVQNNDA and LVQNNDAAM.

. . , Rg = R, @$).V(?)). (1) Step 5. Determine the closest Voronoi?s vector V(?*)to the input vector by the maximum output signal y, =P$).V(J). (2) Step 6. Adaptation of V 6.1:    Step 6. Adaptation of V 6.1: for correct classificatioc and V(?)(k+l)=V(?)(k)-p(Pk)(k)-V(?)(k))  (4) for incorrect classification [9] till the maximum number of epochs is reached. The learning rate is denoted by p..

Step 7. Testing set presentation.

Step 8. Actual classification @A) and compute the errors for scan k.

Step 9. Data postprocessing: INC and inverse DCT for both of LVQNNDA and LVQNNDAAM.

Step IO. k = k + 1 : Repeat cyclically the Step 2 to Step 9 till the same track deletion criterion is satisfied.

The maximum number of epochs is k,,  = 100 for the both of versions; the learning rate is 0.07 for LVQNNDA and 0.1 for LVQNNDAAM. These values are chosen as the closest to the optimal case by separated e.xperiment.

The input data preprocessing and postprocessing techniques for all the versions of the algorithm are chosen as near optimal among six variants, included NC in [-1,1] , NC with zero mean and unity variance [9], and the same methods with DCT before NC by separated experiment.

The used track deletion criterion is standard for seconday surveillance radar systems [13].

The proposed algorithm for tracking on multiple targets may easily to be realized in software implementation on Windows or on Unix platforms using high-level algorithmic language, e.g. C, Ctc ,  Java, or other object-oriented computer languages, as the critic with respect to the time procedures can be realized using digital signal processors, or by hardware too. The main advantages of the hardware realization are simplicity and shorter codes, faster operations, much more accurate results, and possibilities to achieve high level of parallelism, 111. EXPERIMENTAL RESULTS Simulated and live data for six tracks of non- manoeuvring targets, chosen in random way are used to form the training set for the computer modelling. The live data from neighbour targets are recorded from the plot extractor?s output of Monopnlse Secondary Surveillance Radar CMSSR-401 [lo] with sampling time T=10 s, i. e.

the radar data are extracted and recorded before their processing by the tracking algorithm in the radar system.

The Live tracks with length of 90 consecutive scans are shown in Fig. 1. The recorded radar measurements are from tme and false targets. In this case false measurements are received only in scans k = 30 and k = 50. The live tracks are used as prototypes to model the tracks for the MC simulations, as follow. After polar to Cartesian  transform to equalize the dimensions of the coordinates, the measurements from the first and the last radar scan, are connected with straight line and spaced with scan time T to form the trajectory of non-manoeuvring target. The track TI is modelled using the first and the last point of the section with constant altitude and the first and the last point of the section with varying altitude. Next each track is corrupted with Gaussian noises, added directly to each coordinate to model the measurement errors according to the target kinematic model. The cumulative distribution _* - - e.;?- i?..

-*.-- * . ~- I im Fig. I .  Live tracks used in the experiments.

function of the noises is verificated by chi-square test with significant level a = 0,05. Next the tracks are transformed back in polar coordinates and then they are processed by the algorithm under the test. By this way only true radar measurements are modelled: Next a number of false measurements for each track for a scan are modelled for    measurements for each track for a scan are modelled for each MC run. Their locations are modelled as uniformly distributed in the validation regions (the gates) of the tracks. These validation regions are next used only for the standard ? D A  algorithm. In this case the expected number of false returns within the gate of a track is 0.03.

Next using a gating coefficient of three, the probability of at least one return falling within the gate volume is approximately 0.24. Any number of false measurements (false plots) in each scan is equiprobable [l], [2].

The parameters for comparison by MC runs are the averaged number of epochs k , the averaged fmal training error E/in, the averaged values of PCC (??) during the training and DA stages, denoted by F p ( % )  and F g  (%) , and the averaged percentages of misdetections FMisde,(!%) and miscorrelations FmisCor (%) [I]. The theoretical number of arithmetic operations addition Z and multiplication x ,  and the total number of arithmetic operations required for data processing of one track for one scan by each proposed algorithm with included number of epochs, are presented in Table 1. The results from 50 MC runs and for one run using real radar data for the same tracks are presented in Table 2 and Table 3, respectively. The computational costs during the MC runs are estimated by the averaged CPU time r,pu and number TABLE I NUMBER OF ADDIllUNS AND MULllPLlCATlUNS FUR EACH ALGORITHM A t g o r i h  k z x Total BPNNDA 1 372 723 1095 BPNNDAAM 1 485 1123 1608 LVQNNDA 100 4% 1n 510 LVQNNDAAWr lm 379 387 784 of FLoat Opelatiom Per Second (FLOPS) j i ~ m ~ ~  for data processing of a l l  tracks for scan k. The performances of all the algorithms for the MC runs are shown in Fig. 2 and Fig. 3, respectively. The resdts show that better quality of DA's performance appears by BPNNDA and BPNNDAAM versions of the algorithm. The percentage of correct classifications during the training and testing phases of the DA algorithm using BPNN is 100 % in all considered cases, while with LVQNN it is a bit smaller.

The pattern vector extended by the amplitude slightly decreases FE'"(%) for LVQNN case. Using LVQNN in case of close spaced tracks of targets, it is possible to  obtain nomro  value of ~ m i 8 , ,  (%) when the NN decide that no one of the received plots (true or false) from a given target cannot be used for track update, but it occurs rarely - in less than 0.01 % of the cases. It is due to the facts first that the LVQNN performs the nearest-neighbour rule in neural variant, and second, the amplitude signals of close spaced targets have similar values. The last does not confuse the nehvork of the BPNNDAAM version. By the different kind of LVQNN's initialization, it performs smaller initial training ermrs than BPNN. The training error's final values (at the end of training) of the LVQNNDA and LVQNNDAAM algorithm are smaller ...,...... .......................................................

99.

Fig. 2. MC simulations results: percentages of correct decisions during the training and testing phases ""i\ 0.1 D J 1 IO k 100 Fig. 3. MC simulations results: averaged values ofthe fmal trainingerr0r and the number of epochs than these with BPNNDA and BPNNDAAM are, due to the longer training (slower training convergence and more iterations required). Besides that the BPNN's learning    algorithm allows to stop the training when the early stopping criterion is met, which approximates the error minimum more roughly than using LVQNN, so that the training e m x  is higher. So, despite the higher computational complexity of BPNN and BPNNDAAM, they need less time to perform the DA than LVQNNDA and LVQNNDAAM. The averaged CPU time in MTUE for data processing in BPNN case is near than this of " D A .  Because of the lower clutter density in the case when real data are used, the LVQNNDA and LVQNNDAAM achieve 100 % of correct classifications for training and testing phase (Table 3 and Fig. 4) too.

Since in the first few scans there are no false plots, and due to the greater KF's tracking errors the tme radar measurements fall out of the track gates, than zero values of Ptest for the " D A  algorithm are obtained. All proposed algorithms outperform the classical NNDA, and due to the greater KF's tracking errors the true radar measurements fall out of the track gates, than zero values of for the " D A  algorithm are obtained. All proposed algorithm outperform the classical " D A approach with standard recursive KF to form the TABLE I1 MONTE CARLO SIMULATIONS RESULTS Algorithm 5 F&amp; P%~A) @Y%) FL&amp;A) &amp;&amp;) b u  %LOPS LVQNNDA 100 0.obos 99.99 99.97 0.00 0.001 1 .58 25855 LVQNNDAAM 100 0,0010 99.98 99.93 0.00 0.006 1.61 27023 BPNNDA o o.ooa4 i0o.m 1oo.m 0.00 0.000 0.37 1802900 BPNNDAAM 0 0.0029 100.03 1oo.m 0.00 0.000 0.50 312XiOO NNDA - - - 94.36 1.19 0.000 0.35 22801 TABLE 111 RESULTS USING REAL DATA Algorithm E E&amp; @TA) F&amp;*tA) P.i,ddA) %5CO&amp;) fcpu %LOPS BPNNDA 0 0.0025 100.03 loom 0.00 0.000 0.37 18M900 BPNNDAAM 0 0.0027 100.03 1oo.m 0.00 0.000 0.50 312sM)O LVQNNDA 100 0.0004 100.03 100.03 OBI 0.000 1.58 ' 25855 LVQNNDAAM 100 0.0002 1oo.m 1oo.m 0.00 0.000 1.61 27023 NNDA - - - 91.85 7.78 0.000 0.31 8906 PERFORMANCE COMPARISON FTHE DA ALOORITHMS DEPPND ON THE Usm TRACKING FILTER TABLE IV Filtsr DAalgolithm E.%i @Y%) FgpA) Hajtd2%) &amp;it&amp;) TCPU %l.Ops BFNNDA 0.0024 lOOa0 1M)RO 0.00 0.003 0.37 1802900 LVQNNDA 013035 999 99.m 0.00 . 0.001 1 .S8 25855 BPNNDA 0.0154 100 99.97 0.00 0.m 0.40 2198800 Kalmanfikr LVQNNDA .0.243 99.9 98.63 0.00 0.061 1.67 25741 NNDA - - 94.35 1.19 0.m 0.35 22801 B F "  filer extrapolated positions of the targets. Because of the worse KF's tracking accuracy during the first few scans before the region of convergence, the true plots from the targets appears out of the gates of the tracks, so that false plots can be used for track formation. In this case nomro values of Pm,sde, occur. By the BPNN filter ( B P W ) [I31 the moment when the filter enters in convergence almost does not affect to the quality of the proposed DA algorithms.

An experiment of 50 MC runs is provided for the BPNNDA and LVQNNDA algorithms using the extrapolated by KF position of the targets instead these - Fig. 4.

data Percentages of correct decisions for data association using real obtained by the BPNNF Thus the performances of the neural algorithms for data association with respect to the used tracking accuracy of the filter are investigated and compared. The results are presented in Table 4 and Fig. 5.

The results show that the tracking accuracy of the filter effects onto the quality of training and the quality of data association too. This effect is expressed more strongly in the LVQNNDA version of the algorithm. The values of    the LVQNNDA version of the algorithm. The values of F z ( % )  and FE(!%) for the LVQNNDA version using the extrapolated by KF positions (LVQNNDA-KF) are lower than these for the BPNNDA version in the same case (BPNNDA-KF). AISO Fm,,,,,(!%) in this case is increased, which is undesilable effect. Despite this, the tracking accuracy of the algorithm obtained during the data association process is better than this of the standard NNDA algorithm. The improvement in FE(%) is averagely of 4.31 % for LVQNNDA-KF and 5.61 % for BPNNDA-KF. The increasing of the DA's error is expressed more hardly during the first few radar scans, where the KF's tracking error has the greatest values. It is seen in Fig. 5 ,  that the functions of F s ( % )  for the LVQNNDA-KF version are similar to these obtained by the " D A  algorithm during the time. This is completely natural phenomena, because the LVQNN appears as nearest neighbour's implementation in neural variant. The extrapolated positions are one and the same for both the NNDA and the neural algorithms. And yet, due to the N"s ability to be trained, better results are obtained 1 10 k I00 Fig 5.

the used tracking filter Percentages of corned decisions for data association depend on during the DA process. The values of the training error at the end of training for LVQNNDA-KF are increased of about two orders and these of BPNNDA-KF - of about one order greater than these of the cases using BPNNF.

The results from this experiment shows clearly the importance of achieving high tracking accnracy of the BPNNF in MTT, and relatively not a little improvement of the percentages of correct classifications using NN in the developed tracking algorithms, compared with the standard ? D A  approach. And yet, due to the NN?s ability to be trained, better results are obtained during the data association. The values of the final training error for LVQNNDA-KF are increased of about two orders, and these of BPNNDA-KF - of about one order greater than these of the cases using B P N N F .  A l s o ,  using KF the neural algorithms for data association need more CPU time and FLOPS to perform the classification. The results from this experiment shows clearly the importance of achieving high tracking accuracy of the BPNNF in MTT, and relatively not a little improvement of the percentages of correct classifications using NN in the developed tracking algorithms. The results from the experiments to investigate the performances of B P N N D A ,  B P N N D A A M , LVQNNDA and LVQNNDAAM algorithms show that the BPNN and LVQNN can effectively to be used in such algorithms, because they ensure high quality of training and averagely more than 97 % of correct classifications during the testing, e.g. during the tme data association This percentage of correct classifications exceeds the percentage achieved by the standard NNDA algorithm, with average CPU time commensurable with it?s of the ? D A  algorithm.



IV. CONCLUSIONS In this paper two algorithms for data association in the context of MTT using BPNN and LVQNN are designed, evaluated and compared with the classical ? D A approach. Two versions of each algorithm are presented - without and with additional amplitude information included. The experimental results show that these algorithms work efficiently in different environment and produce average more than 97 % of correct decisions, which are more than these of the standard NNDA approach produce. The improved quality of MTT process will affect positively onto the level of safety and tmstwoahiness in ATC. One future research will extend    tmstwoahiness in ATC. One future research will extend the DA logic of the algorithms for manoeuvring case.



V. ACKNOWLEDGMENT The author thanks to Mr. Balarev and Mr. Bojkov with ATSA Sofia Airport for kindly placed real radar database used for the experiments.

