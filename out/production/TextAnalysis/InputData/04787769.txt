COMPARING AND IDENTIFYING COMMON FACTORS

Abstract- This paper is initiated from the observation of existing research work which is related in frequent Item Set mining algorithms such as MAFIA, FP -Growth, Transaction Mapping (TM) and ECLAT(Equivalence CLAss Transformation). As per the study of above mentioned algorithms all the items are counted then its maximal sets are reordered separately. The algorithms are executed with the limitation of candidate key generation and the candidate keys are generated after the frequent item set generation.

The common features are identified. As per the observation, the three common factors total processing time, total number of transactions and dataset scanning and accessibility are taken. The results are compared and critically commented in this paper.

Keywords: Algorithms, association rule mining, data mining, frequent itemsets  1. INTRODUCTION Data mining refers to extracting or mInIng  knowledge from large amount of data. In recent years the data mining is so important due to advent ofpowerful data collection and storage tools, the raw data is so abundant that manual analysis is no longer possible. Data mining, the extraction of the hidden predictive information from large database is a powerful new technology with great potential to analyze important information in the data warehouse. The term 'data mining' refers to the finding of relevant and useful information from databases. Data mining and knowledge discovery in the databases is a new interdisciplinary field, merging ideas from statistics, machine learning, databases and parallel computing. In data mining various techniques and algorithms are used to increase its efficiency and its performance. [4] In this paper frequent itemset algorithms in association rule are analyzed to determine the common factors and to determine which frequent itemeset algorithm increase the efficiency in the performance and operational level.

2. ASSOCIATION RULE MINING Association rule is an example of data  mining task that fits in the descriptive model of data mining. The use of Association rules enables to establish association and relationships between large unclassified data items based on certain attributes and characteristics.

Association rule define certain rules of associativity between data items and then use those rules to establish relationships.

Let J={iI,i2, .... i m} be a set of items and let D be a database having a set of transactions where each transaction T is a set of items such that T C 1. each transaction is associated with an identifier called TID. An association rule is an association relationship of the form:X=>Y, where X C J, Y C J and X n Y= <I> ? The support of rule X => Y is defined as the percentage of transactions containing both X and Y in D. The confidence of X ~ Y is defined as the percentage of transactions containing X that also contain Y in D. The task of association rules mining is to find all strong association rilles that satisfy a minimum support threshold (min_sup) and a minimum confidence threshold min_cont). A set of  items referred to as an itemset. The occurrence of frequency of an itemset is the number of transactions that contain the itemset. The number of transcactions for the itemset to satisfy minimum support, if satisfies then it is a frequent itemset. The problem of association rule mining is to discover association rules that satisfy min_sup and min_conf. Mining association rules consists of two phases.

In the first phase, all frequent itemsets that satisfy the min_sup are found. In the second phase, strong association rilles are generated from the frequent itemsets found in the first phase. Most research considers only the first phase because once frequent itemsets are found, mining association rules is trivial.[4]  The basic terminologies[17] are used to search the association rules among a given data set. The various types of notations and terms are used in search of association rule. The important notations and their meanings are:  ? D: Database of transactions ? Ti: Transaction in D ? S: Support ? a: Confidence ? X, Y: Itemsets ? X=>Y: Association rules ? L: Set of large itemsets ? 1: Large itemset in L ? C: Set of candidate itemsets ? P: Number ofpartitions  2.1 Data Representation Two types of database layouts are employed in  association rules mining:[11] horizontal and vertical. In the traditional horizontal database layout, each transaction consists of a set of items and the database contains a set of transactions. For vertical database layout, each item maintains a set of transaction ids (denoted by tid) where this item is contained. This layout could be maintained as a bitvector also. Eclat uses tidsets. Mafia uses compressed bitvectors. Table 1, Table 2, and Table 3 show examples for different types of data representations.

tid items  1. 2,1,5,3  2. 2,3  3. 1,4  4. 3,1,5  5. 2,1,3  6. 2,4  Table 1: Horizontal Representation  items tid  1. 1,3,4,5  2. 1,2,5,6  3. 1,2,4,5  4. 3  5. 1,4  Table 2: Vertical Representation  items bitvector  1. 101110  2. 1 1 00 1 1  3. 110110  4. 001000  5. 100100  TABLE 3 Vertical Bitvector Representations  2.2. Methods to Discover Association Rules  Problem decomposition: The problem of mining association rules can be decomposed in to two sub problems:  ? Find all sets of items (itemsets) whose support is greater than the user-specified minimum support.

Such itemsets are called frequent itemsets.

? Use the frequent itemsets to generate the desired rules.

Downward closure property: Any subset of a frequent set is a frequent set.

Upward closure property: Any superset of an infrequent set is an infrequent set.

Maximal Frequent set: A frequent set is a maximal frequent set if it is a frequent set and no superset of this is a frequent set.

Border set: An itemset is a border set if it is not a frequent set, but all its proper subsets are frequent sets.

This paper in Chapter 3 discusses various mining algorithms which are used for frequent Item set, Chapter 5 describes the factors identified for first level key generation which is used to construct fp tree and frequent Set Generation,Chapter 6 describes the factors involved in this paper, Chapter 8 contains the experimental result which is used to compare the above frequent set algorithms.

3. OVERVIEW OF FREQUENT ITEMSET ALGORITHMS IN ASSOCIATION RULE.

Association rule mining [12] [13][ 14] is a very popular data mining technique and it finds relationships among the different entities of records (for example, transaction records). The introduction of frequent itemsets in 1993 by Agrawal et alit has received a great deal of attention in the field of knowledge discovery in data mining. One of the first algorithms in association rules mining was the Apriori algorithm [4] which generates more candidate item set for minimum support count. The Apriori algorithm employs the anti-monotone property-if an itemset is not frequent, any superset of it cannot be frequent either. The Apriori algorithm employs an iterative approach known as level wise (breadth-first) search, where k itemsets used to explore (k+1) itemsets. The frequency of an itemset is computed by counting its occurrence in each transaction and one full scan of dataset. This pruning technique however becomes less useful for some real applications where the supports of interesting item set are extremely small, such as medical diagnosis, fraud detection among others. Apriori algorithm suffers from two nontrivial costs.

? It may need to generate a huge number of candidate sets.

? It may need to repeatedly scan the database and check a large set of candidates by pattern matching.

Many variants of the Apriori algorithm[4] have been developed, such as hash based technique ,sampling, direct hashing and pruning (DHP), dynamic itemset counting (DIC), Partition algorithm, etc.

An interesting method in this attempt that over come the above drawbacks is called Frequent Pattern Growth, or simply FP-Growth[4], which adopts a divide and conquer approach to decompose the mining problem into a set of smaller problems and uses the frequent pattern (FP-tree) tree data structure to achieve a condensed representation of the database transactions , it mines all the frequent itemsets by recursively finding all frequent l-itemsets in the conditional pattern base that is efficiently constructed with the help of a node link structure. When the dataset is large, it is unrealistic to construct a main memory based FP_tree. FPgrowth* [3] uses an array technique to reduce the FP-tree traversal    time. In FP-growth-based algorithms, recursive construction of the FP-tree affects the algorithm's performance.

Eclat [15] is the first algorithm to find frequent patterns by a depth-first search and it has been shown to perform well. It uses a vertical database representation and counts the itemset supports using the intersection of tids.

This implementation represents the set of transactions as a (sparse) bit matrix and intersects rows to determine the support of item sets. The search follows a depth first traversal of a prefix tree. The main difference between the Eclat and FP-growth algorithm[18] is how the transaction database is stored in memory. Eclat keeps item covers in memory, while FP-growth saves all transactions into FP- tree which is a tree-like data structure. Each non-root node of the FP-tree contains a counter and is labeled with the name of a certain frequent item (frequent l-itemset). In order to build the FP-tree, the FP-growth algorithm first detects frequent items and orders them in support ascending order. Frequent items of each transaction are then saved into FP-tree in reverse order as a path, by incrementing counters in existing nodes of the path and creating missing nodes with counters set to 1. In that way, nodes closer to the root node correspond to more frequent items, and are more likely to be shared by many transactions, yielding a smaller FP-tree .Unfortunately; Eclat and FP-growth can't be employed for larger transaction databases which don' fit into main memory.

Although some techniques have been proposed for solving this problem (e.g., the partitioning of the database), these techniques are often infeasible.

In TM algorithm,[11] it Scans the database and identifies all frequent-l itemset. The transaction tree is similar to FP-tree except that there is no header table or node link. The transaction tree can be thought of as a compact representation of all the transactions in the database. Each node in the tree has an id corresponding to an item and a counter that keeps the number of transactions that contain this item in this path. From the transaction tree it constructs the transaction interval lists.

The lexicographic tree in a depth first order keeping only the minimum amount of information necessary to complete the search.

Mafia [2][7] use the vertical database layout and the intersection to achieve a good performance. The search strategy of the algorithm integrates a depth-first traversal of the itemset lattice with effective pruning mechanisms that significantly improve mining performance. Mafia implementation for support counting combines a vertical bitmap representation of the data with an efficient bitmap compression scheme. It isolates the effects of individual components search space pruning techniques such as parent equivalence pruning and superset checking are very Beneficial in reducing the search space and adaptive compression/projection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets.

MAFIA highly optimized for mining long itemsets and on dense data. The only difference is that they use the compressed bitmaps to represent the transaction list of each itemset. However, their compression scheme has limitations especially when tids are uniformly distributed.

4. COMPARING THE ALGORITHMS The various factors used to compare  which algorithm is most suitable for the data set. The various factors are:[17]  ? Target: Algorithms should generate all association rules and these rules should satisfy the support and confidence level of the data set.

? Type: Algorithms may generate the regular or advanced association rules such as the multiple- level association rules, the quantitative association rules, generalization association rules or constrained based association rules.

? Data Type: Algorithms generate the association rules for various types of data such as plain text and categorical data.

? Technique: use the common techniques such as Apriori, Sampling or partitioning for generating the association rules.

? ltemset Techniques: Itemsets can be counted in various ways. Choose such technique so that all itemset are generated collectively and then counted.

? Transaction Techniques: For counting the itemsets, database of the transaction is scanned.

Algorithms count all the transactions that are present in entire data set, a particular sample, or a particular partition.

? Itemset Data Structure: Generally all the algorithms use hash tree data structure to store the candidate item sets, and their counts. A hash tree is a search tree where each branch that is taken from a level is determined by applying a hash function. A leaf node in the hash tree consists of all the candidates that are hash to it. All the candidates that are present in a leaf are stored in sorted order.

? Transaction Data Structure: All the transactions are represented in a flat of a TID list that is viewed as an inverted file. Generally, all the transactions are encoded by the numbers, letters or symbols.

? Architecture: Algorithms are proposed by sequential, parallel, and distributed architecture.

? Parallelism Techniques: Algorithms use parallelism by two way either data parallelism or task parallelism.

5. IDENTIFIED FACTORS From the frequent itemset algorithms  some common factors identified. These factors are  ? All the algorithms are used for frequent item set approach  ? The maximum frequent item sets are determined using candidate keys  ? All the frequent item sets are determined then transactional mapping, FP tree and Classes are generated using association rule.

? All the algorithms are used to count the items then reorder according to the frequent item sets  ? The candidate key generation and tree index manipulations are common for all the algorithms    Table 6.Total processIng tIme for Connect data  Table 5 Total processing time for mushroom data  Figl. Total processing time for mushroom data       Miimum -..pport 0/0  Minimum ...pport     i 25  f   J 10   I:: J 100    Fig 2.Total processing time for Connect data  Support (%) FP growth Eclat TM 90 0.093 0.062 0.046 70 0.109 0.046 0.046 30 0.187 0.094 0.078 15 1 0.828 0.734 5 30.89 28.703 27.031  Support FP growth Eclat TM (%) 90 2.109 1 0.937 80 8.468 5.39 5.031 70 53.172 37.625 36.89 60 272.531 204.015 202.531  6. FACTORS INVOLVED IN THIS PAPER.

From the observation of identified factors from  the above frequent itemset mining algorithm 3 factors are taken in this paper and criticized. The 3 factors are  1. Total processing time (run time) : It is the total time of reading time of a dataset, sorting time, reordering time , pruning time, FP tree construction time and frequent item set manipulation time  2. Data base scanning and accessibility: It gives how many times the dataset is opened or scanned and the each element is accessed.

3. Number of transactions: The occurrence frequency of an itemset is the number of transactions that contain the itemset.

7. DATASET SELECTION The datasets[5] used in this paper (table 4) is used  by various Data mining experts in their research.The elements in the datasets which are represented in the numeric format, easy to evaluate the processes, which involved in those mining concepts. These datasets consists of frequent itemset in each record level. In record level they are separated by special identification. The elements are separated by space. The original values of Mushroom, Connect and Tl 014DlOOk datasets observations represented by its index values using mining concepts. The frequent items and its associative datasets are easy to calculate and represented as a flat file (or) text file. The dataset which are used for the evaluation contains following characteristics.[5]  The dataset TI014DI00k dataset is a sparse data with short frequent itemset patterns. Thus nodes in the itemset tree will have small tails and few branches. This artificial dataset was created using the data generator from IBM Almaden. The Mushroom and Connect datasets are real data which are dense datasets .They are characterized by very long itemset patterns that peak around 10-25 items.

Data #items Transactio #transactions n length  TI014DI00k 1000 10 100,000 Mushroom 120 23 8124 Connect 130 43 65,557  Table 4. Characteristics of experiment data sets  These datasets and its domain theory are available from VCI Machine Leaming Repository [5].

8. EXPERIMENTAL RESULT AND ITS INTERPRETATIONS  The frequent itemset algorithm implemented with using C++ programming. The implemented results are viewed critically in different levels. The same datasets are adopted for all the algorithms and results are discussed below.

8.1 Total processing Time . This processing time of FP growth, ECLAT and  TM algorithms is compared with the result of datasets mushroom, Connect and TI014DI00k.

Support (%) FP growth Eclat TM 5 0.64 0.421 0.312 1 5.625 5.687 2.39 0.5 7.718 9.234 4.515 0.2 9.906 11.906 7.468 0.1 11.562 13.109 9.187 0.05 16.359 16.046 10.64 Table 7.Total processing time for TI014DI00k data  The results presented in table4, table 5 and table 7, and fig 1, fig 2 and fig 3 shows the total processing time of the compared algorithms on mushroom, TI014DI00k and Connect dataset with different minimum supports represented by percentage of the total transactions. Under largest minimum support and smallest minimum support TM is faster than FP growth, and Eclat.

! 12  f': Go  I 6 ""'  0.5 0.2 0.1 0.05  Minimum Support  Fig 3.Total processing time for TI014DIOOk data  8.2 Number of Transactions The dataset processed to determine the frequent  item set. While scanning the database and the calculation of frequent item elements of each process implemented separately. The factors are listed  Frequent item set generation and sorting process are executed individually  The transaction process are executed in each level therefore the number of transactions are increased in certain level which creates an impact in the process level each transactions are manipulated in the processor. If the transactions are reduced automatically the processor tasks also can be reduced.

8.3 Data Base Scanning And Accessibility The above algorithms read or scans the database  one time and ordering it in another time. And also it opens the database or access the dataset multiple times to determine the order of frequent itemset.The comparison with the results ofTM, ECLAT and FP growth algorithms, the total processing time of the algorithms for minimal set is high in compare with high level.

The comparison process contains accessibility, comparison and indexing therefore the process utilization also increased. The memory are used frequently, the memory refreshment also effectively handled using pointer destructor concepts. Under small minimum supports, FP-Growth runs faster than Eclat while running slower than FP-Growth Under large minimum supports.

TM algorithm runs faster than both algorithms under almost all minimum support Values. On average, TM algorithm runs almost 2 times faster than the faster ofFP- Growth and Eclat.

9. CONCLUSION We used 3 datasets in our experiments. The dataset TI014DIOOk data is synthetic data with short frequent patterns. The Mushroom and Connect datasets are real data which are dense in long frequent patterns. These datasets were downloaded from http://fimi.cs.helsnki.fi/testdata.htmland http://miles.cnuce.cnr.it/::palmeri/datam/DCI/dataset.php.

Some characteristics of these data sets are shown in Table 4. We take the concepts from TM, ECLAT and FP growth algorithms and we compared these algorithms with their implementations. They were compiled in Visual C++. This paper focuses on algorithmic concepts rather than on implementations. For the above algorithms, the total processing time, Data base scanning and accessibility and Number of transactions is different for different  implementations. We downloaded the Eclat and fp-growth implementations from Goethals implementation. Data structures (set, vector, and multisets) and libraries (std) used are the same and only the algorithmic parts are different.

