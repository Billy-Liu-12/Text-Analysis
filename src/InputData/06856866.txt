Image Information Mining: an Accelerated Bayesian Algorithm  for Data Fusion of SAR Big Data

Abstract The paper presents a knowledge-driven content-based information mining Bayesian algorithm for data fusion of SAR Big Data. The method combines, at pixel level, the unsupervised clustering results of different number of features with a user given semantic concept. The combination has as goal to calculate the posterior probability that allows the final search. The proposed interactive learning method is able to learn different user semantic la- bels, which can be used to retrieve related images with a few user interactions, greatly optimizing the computa- tional costs and over performing existing similar systems in various orders of magnitude.

1 Introduction The total amount of Earth Observation (EO) data gener- ated is growing every day in exponential way. Being so, the only way to exploit more efficiently the existing EO Big Data archives is developing faster and more effi- cient new systems, technics and concepts for Content Based Image Retrieval (CBIR).

In CBIR the search engines can be divided by their methodology in three main categories:  Query by Example (QE): QE engine uses one image for querying the data base and based in one fea- ture returns a ranking of the content. An example of this type of engine is GeoIRIS [1].

Relevance Feedback (RF): these systems allow the user to refine their queries by specifying between interactions a set of relevant and a set of non-relevant images. A multimedia application of this type of search engine is IKONA [2].

Image Information Mining (IIM): It is com- posed by Interactive Learning (IL), which requires as RF the participation of the users, and probabilistic re- trieval. The Knowledge-driven Information Mining (KIM) system presented in [3] for example supported user interaction via web frontend to adaptively intro- duce application-specific interests. In KIM the user in- troduces semantic interpretation of the content which was interactively linked with hierarchical Bayesian net- works to a completely unsupervised content-index. Us- ing the result of this stochastic link, the user can query the database for relevant images and obtain a probabilis- tic ranking of the entire image archive as an intuitive information representation.

The use of probabilities offers us the advantage to fuse features from different sources and instruments. But the  merging comes related with some complexity problems that must be overcome.

In this paper we present a new implementation of KIM algorithm based also on feature fusion and Bayesian networks for probabilistic retrieval. New theoretical and technical approaches have been implemented to over- pass the scalability limitations derived from previous KIM implementations.

The paper is organized as follows. In section 2, an over- view of the algorithm is shown. Section 3 explains theo- retical aspects taken into consideration in the posterior probability calculation, and the scalability issues that rise with the merge of features. Section 4 presents the implemented different approaches for querying the da- tabase. Following, Section 5 presents some query ex- amples and computation times. Finally, Section 6 offers concluding remarks.

2 Hierarchical Model for Infor- mation Representation  The information can be represented via multilevel hier- archical model, as it is shown in Figure 1. The first three levels form the not real time image analysis part which is in charge of feature extraction processes and unsuper- vised clustering algorithmic. For the preliminary tests  Figure 1: System hierarchical levels.

EUSAR 2014  ISBN 978-3-8007-3607-2 / ISSN 2197-4403 ? VDE VERLAG GMBH  Berlin  Offenbach, Germany    intensity and Weber?s law descriptor [4] were used. In later tests with the fusion of features from optical data multispectral information pixel values were added.

The features are extracted at pixel level and after k- means unsupervised clustering. A probability density function (PDF) vector is generated calculating the his- togram of the occurrence of the clustering classes inside the image. At the end of not real time processes the cal- culated PDFs are stored in a database.

In the third level the user interaction enters in scene. A frontend for the user is presented as query by example interface as is shown in Figure 2. There, the user can introduce positive and negative examples about the spe- cific semantic he/she is looking for and do a search by similarity or probability of the label in the archive.

Figure 2: User interface for browsing database, interac- tive learning and querying. The user can interact with the query image or over the probability map to give pos- itive and negative examples. To refine the label it is pos- sible to load as query image the ones shown as result to increase the diversity of the classes in the label defini- tion.

3 Algorithm Overview With the positive and negative examples introduced by the user, it is possible to use a simple Bayesian network to perform the probabilistic learning by means of hy- perparameters. As it has been mentioned before, the searches in the database are done via posterior proba- bilities. We can calculate posterior probabilities as  ( | ) =  ( | )  ( | ) (1) which can be also expressed applying Bayes? formula as  ( | ) = ( ) ( | ) ( | )( )  (2) Being ( ) the prior probability of the semantic label , ( | ) the probability of the classes in the data, ( | ) the probability of the classes in the label which  can be expressed as the PDF of the classes updated with the user inputs, and  ( ) the prior of signal classes as  ( ) = ( | ) ( ) (3) 3.1 Feature Merging and Scalability In most of the cases using a unique feature is not enough to characterize a strong user-specific semantic  . To allow the stochastic link of different features or models the assumption of full statistic independence must be taken into account.

In [3] the full statistical independence assumption was made over the features resulting in  ?| = |   ( | )  ? (4) As a result a relatively fast computation of the posterior probabilities was possible only if the model number used was restricted to two. The limitation was set be- cause of the computational complexity has a polynomial increasing with the model number.

=  (5) 3.2 Posterior Probability Statistical Inde-  pendence The presented algorithm introduces a new statistical as- sumption, where the statistical independence is en- hanced to include the posterior probability    ( | ) = ( | ) ( | ) ? (6)  In this way computation complexity maintains linear permitting the introduction of more features for the us- er-specific semantic label definition.

= =  (7) In Section 5 some performance results are presented in the form of querying time, comparing the results for dif- ferent retrieval methods and used statistical assump- tions.

EUSAR 2014  ISBN 978-3-8007-3607-2 / ISSN 2197-4403 ? VDE VERLAG GMBH  Berlin  Offenbach, Germany    4 Query Methods Two different query methods can be performed using the presented algorithm. The first one uses the sum of posterior probabilities of each image in the database to rank them from highest to lowest. With this method the user is able to look for images with the highest probabil- ity to have the requested semantic label inside.

A good example of use case for this method would be a user with an initial image of a city looking for images with trees. In this image there would be some trees in the streets and some others in a park. Putting a couple of positive examples over the trees and making a search the user would get as result for his/her query images of forest or great parks full of trees. All of them, images with a very high probability of having trees inside.

The second method relies on vector similarity to rank the database images. The similarity measure in this case is done by the comparison among the posterior proba- bility PDF of the querying image and the PDF of classes of the images in the database. In this way, instead of pure image similarity among the classes PDF, we are introducing the user-specific semantic as a very strong factor that reshapes query image class PDF powering up the classes related with the requested semantic.

The difference factor with the other method is clear in- specting the query results. The first one returns images  with higher probability of having the user defined label.

The later, offers images similar to the query image in shape and in label probability.

5 Results and Evaluation In this section some preliminary results of the system are presented. These results are on one hand related to the quality of the images returned and on the other hand related to system performance taking into account the query response time.

5.1 Query Examples In Figure 3 some query examples are presented. The first image corresponds to the query image; the second one is the visualization of the posterior probability in map form. This map represents posterior probabilities of a given user-specific semantic. The map is a grey scale representation of the pixel posterior probabilities of the image, being black means probability 0 and white 1. For usability purposes probabilities above 0.9 are drawn in red. The next images are the first ranked results.

Example a) shows a query looking images with the us- er-specific semantic of the river. For this search only two positive examples were introduced by the user. Al- so notice that the ranking was done by similarity.

Figure 3: Different query examples using SAR image features. The table shows three query cases for different user concepts, showing first the query image, after that the posterior map of the query and finally the results.

EUSAR 2014  ISBN 978-3-8007-3607-2 / ISSN 2197-4403 ? VDE VERLAG GMBH  Berlin  Offenbach, Germany    Example b) presents a query searching the user-specific semantic tree. As it can be appreciated, the query image has lines of trees along some streets and a bunch of them among residential buildings. In that case the user introduced again two positive and one negative example to get correct results for her/his query. The results, ranked in this case by the label probability level in the image, show in the first places images of parks or areas in the city close to parks where the concentration of trees is greater.

The third query example looks for railways as user- specific semantic. This was the hardest label to define.

Starting from the railway image shown in Figure 3c, it was necessary not only to give positive and negative examples over this initial image but to continue refin- ing the query, analysing partial and intermediary query image results via mainly negative examples in order to strengthen and limit the label. As in the previous case, the ranking was made using the probability of the label in the images.

5.2 Querying Times As mentioned before the system presented extends the search capabilities of existing KIM system speeding up the querying processes. Table 1 summarizes some of the performance tests that have been done.

Table 1:  System query performance time for different statistical assumptions, query ranking types and model number. First row is used as threshold and corresponds to an emulation of the original KIM implementation.

The difference among the performance in the case of four models using the new statistical assumption is four orders of magnitude better.

The first row matches the characteristic of the already existing KIM system. Thus, the first row is used as threshold to measure the impact of the newly intro- duced concepts. Using the same theoretical assump- tions applied to the original KIM, the developed search and ranking procedure performs one order of magni- tude faster than the original for the queries with one and two models; and two orders of magnitude faster for the four model query. Introducing the posterior proba- bility statistical independence we can see that the per- formance time in vector similarity methods maintains  constant as the size of probability matrix only depend on the model number. On the other hand for the poste- rior probability method we have an enormous speed up factor of one order of magnitude for single model case and of two orders of magnitude for the dual model case. These practical results confirm the theoretical re- sults exposed in section 3 of this paper.

6 Conclusions We have presented a new implementation of a KIM al- gorithm. For comparison purposes the original KIM methods have been implemented. Based on them, we have developed new search methodologies and theoreti- cal probabilistic assumptions which outperform in speed the original ones. The algorithm acceleration was achieved thanks to the simplification of the operation complexity from polynomial to linear. As future works a comparison and evaluation of the obtained results are planned. The introduction of a bigger variety of features for the user-specific semantic definition is also planned.

Theoretically the use of a higher quantity of models would improve the quality and the robustness of the la- bel definition. The introduction and fusion of data fea- tures from other type of images (Optical, Multispectral, Multitemporal) is also planned.

