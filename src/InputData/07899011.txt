

Abstract  The breast cancer is one of the most popular cause of death among women. It is also one of the diseases that can be cured and has high healing chances when it is detected in the early stages [1]. Detecting the cancer and differentiating between the diagnosis that affirm whether a patient has breast cancer or not has been considered as a big challenge.

In order to have an accurate diagnosis, Support Vector Machine (SVM) and Artificial Neural Network (ANN) have been selected in many research papers to solve this problem with high classification accuracy. In this paper the breast cancer diagnosis is addressed using SVM and ANN combined with feature selection. The feature selection is based on the correlation coefficient of each feature against the target class where different feature subsets are used. The model is tested on the popular Wisconsin Diagnosis Breast Cancer (WDBC) dataset to conduct the experiments. 10- Fold Cross validation has been used for data partitioning while developing the model and the outcome indicates better classification accuracy. As for comparison between SVM and ANN, empirical studies outcome indicated that SVM outperformed ANN with classification accuracy of 97.14 and 96.71 respectively.

Keywords: Support Vector Machine, Artificial Neural Network, feature selection, Breast cancer diagnosis, classification, Machine Learning.

1.  INTRODUCTION Scientists and researchers have conducted several experiments and researches regarding breast cancer diagnosis due to the spread of breast cancer within a large number of women which led to the loss of many lives. The development of medical techniques confirmed the possibility to survive and recover from the disease when detected in its early stages. The evolution of the field of medicine and technology has led to the availability of a huge amount of data stored and made available to  researchers which contributed to the innovation and uses of several techniques to detect the symptoms of this disease.

After tumor discovery, the challenge radiologists and doctors face is how to distinguish between a benign and malignant tumor to take appropriate actions. The development of machine learning made it possible to build a model that can learn and diagnose the tumor based on past diagnosis collected from patients. Breast cancer analysis methods and techniques have been improved over the last ten years and many automated classification models have been developed over the past few years. Results vary from one technique to the other. Comparing different models help find a model that achieve high accuracy.

Many methods were proposed to solve this classification problem. Two of the widely used classification algorithms used to solve this problem are ANN and SVM [2]. Other earlier work in this area have been done on the same dataset used in this paper. A study in [3] used SVM with Radial Basis (RBF) and Polynomial functions as the kernel functions for the classifier and achieved 97.13%. The other two papers used ANN one used [4] ANN back propagation with genetic algorithms and in the first cleaning process of data where it gave 100% accuracy meanwhile the second cleaning process of data gave 83.36% accuracy, the second paper [5] used Feed forward neural network model and backpropagation learning algorithm with momentum and variable learning rate and the study proved that multilayer neural network is quicker than one layer neural network.

Moreover, other studies for breast cancer have been done where they used [6] SVM with RBF kernel function and F-Score feature selection and they achieved a high result of 99.51 %. Another study [7] used decision tree modeling algorithms and has been compared with results that was achieved by radial basis function kernel support vector machine (RBF- SVM) and SVM was the highest in accuracy for both Training 99.976%  and Testing 96.635%.

Furthermore, in another paper [8] they used SVM with three    types of different kernel functions, linear, polynomial and RBF, with genetic programming, and when increasing number of runs, the result for each class increases giving 97.67 for malignant and 99.78 for benign after 100 runs. In another study [9] experimented ANN by training for feed forward neural network using island model based differential evolution algorithm and it achieved 99.97%.

However, another study compared SVM and ANN for breast cancer diagnosis [10] and ANN achieved higher result. Also another study [11] experimented with SVM, ANN , Decision Trees and ensemble of those methods and the ensemble gave the best accuracy.

In this paper we propose to use SVM and ANN combined with features selection to build a classification model of the breast cancer diagnosis to determine whether the tumor is benign or malignant. The features were selected using the correlation coefficient between each feature and the target variable to form feature subsets to choose the combination that gives best results. The experiments have been carried out using Weka and tested using 10-fold cross validation combined with use of optimal parameters.

Results from empirical work indicated that SVM showed better performance results on classifying the samples with 97.1388 % accuracy compared to ANN that achieved 96.7096 % accuracy.

The remaining part of this work is organized as follow. Section 2 and 3 contains the proposed machine learning techniques SVM and ANN respectively. Section 4 contains empirical studies that include dataset description, experimental setup or methodology, and the adopted optimization strategy or parameter search strategy. Section 5 presents the results while section 6 contains the conclusion and recommendation emanating from this work.

2. Support Vector Machines SVM is a widely used machine learning method. It is part of a more general category of machine learning techniques which is kernel methods. Kernel methods use a kernel function which allows it to generate a non-linear decision using linear methods, as well as classifying data with no obvious distribution [4]. Kernel methods are used to construct a hyperplane by dividing the attribute space. It classifies the data using the support vectors which are the instances that outline each hyperplane [12].  SVM is used widely in biometrics due to its ability to process high dimensional and diverse sources of data such as gene expressions[13].

SVM is based on the classifying the data set into different classes based on the class membership by using hyperplane. If there were multiple hyperplanes the best one is the one who is as far as possible from the data point. The goal of it is to point the new data into the right class. This is called the linear classifier [14].

To illustrate it supposes there were dataset consists of group of triangles and circles. The hyperplane is going to separate the sets into two classes as shown in figure 1.

However, what if the data sets don?t permit linear classifier? What if the application that uses SVM as part of it requires a more intense tool rather than simple linear classifier?

Here they come up with the non-linear classifier, which maps the data into a higher dimensional space and then uses the simple linear classifier [20].

The SVM algorithm is used when the data contains two classes exactly where the classification is done by defining a hyperplane that separates the samples belong to one class A form those belong to the other class B. It is necessary to find the best line where many lines can be found from different angles, this can be confusing which one to choose, therefore the best hyperplane is the one has as large margin as it can be. The hyperplane can be described as wide line or two parallel lines with maximum distance where there is no data point between them. The best distance is between the nearest two points each from different class or when many points can be found on the edges or closer where the interior points can be ignored in some cases. The closest data points to the hyperplane are the support vectors.

2.1 Advantages of Support Vector Machine   ? Able to work with linear and nonlinear data.

? SVM supports different kernel functions.

? It returns a unique solution to a problem[15].

2.2 Disadvantages of Support Vector Machine   ? The duality feature in SVM limits the user to deal with the data as two classes.

Figure 1: Illustrate how the hyper-plane classify data sets into two classes    ? The algorithms of SVM are complex and need computational power and for sure more memory space.

3. Artificial Neural Network  Artificial Neural Network was inspired from the human neural networks. ANNs could be valuable tools. By the end the 80?s most of the institutes start using ANNs for different purposes  Neural networks in general contains of at least two physical elements, Neurons which are the process element and a weighted link to connect these elements together.

There are three types of neurons, input neurons, hidden neurons and output neurons.

Input neurons receive stimuli from element outside the network, while output neurons use their produced output externally. On the other hand, hidden neurons are placed between input and output neurons. Hidden neurons receive the input from other neurons in the network and its produced output is used as an input for other neurons. All neurons, except for the input neurons, receives an input from its neighboring neurons and then process the data to produce an output. Different Neural networks can be constructed depending on the way the neurons process the data and the way they are connected to each other.

Neurons can construct multiple layers to create what is known as the Multilayer Perceptron (MLP) which is the most popular type of neural networks. In MLP neurons are grouped into layers. The first layer is the input layer which contains input neurons and sends inputs to nodes and the last layer is the output layer which contains output neurons. They represent the overall input and output of the network. Between these two layers lays one or more hidden layers which contains hidden neurons. Each node in the input layer has directed connections to nodes in the hidden layer.

As mentioned above neurons process some inputs (stimuli) and produces some output. The processing of inputs is done by an activation function. Input neurons activation function is considered a relay function since it relays the external input to hidden neurons. However, hidden neurons uses simple linear function or logistic functions which are bounded and continues to compute the stimuli?s weighted sum. A bias value is added as weight parameter in order to avoid a zero weighted sum which happens when all the hidden neurons produce an output of zero. However, by adding the bias parameter the weighted sum in this case will equal to the bias instead of zero. [16] [17]   Figure 2: Illustration of MLP Neural Network Structure   Each signal (input value) multiplied by a weight.

Neuron sums all the input value that is multiplied by weight (weighted inputs) with threshold, then the transfer function processes the summation result. The result of the transfer function passes to be the desired output.

The model of Neural Network consists of input and output layer, input layer with two inputs and only one output. Each signal (input value) is multiplied by a weight.

Neuron sums all the input values that are multiplied by weight (weighted inputs) with threshold, then the transfer function processes the summation result. The result of the transfer function passes to be the desired output.

Perception is one of the neuron types which uses step function as transfer function and without hidden layer.

The step function has input as the summation of all the input values that are multiplied by weight (weighted inputs) in addition to threshold value as equation (1). The output takes either 1 or 0, 1 for inputs above threshold and 0 for others as shown in the equation (2).  y k .

(1)  0,1, (2)   3.1 Advantages of Artificial Neural Network:   ? Ability to attain complex nonlinear relationships between data points whether if these data points are dependent or not of each other.

? Flexibility in processing real time data and computations in parallel, which is perfect for some business in the market where the data in the environment is dynamically changing.

? Not demanding high sophisticated statistical training.

3.2 Disadvantages of Artificial Neural Network:  ? The "Black Box" nature of neural networks, where  the function base for the solution is not known which makes it hard to solve a problem if an error has accrued and never sure if an over fitting of data has been happened.

? Expensive implementation due to its training computation.

? The experimental based development model.

4.0 Empirical Studies 4.1 Description of dataset WDBC dataset was collected as samples of clinical cases that were reported by Dr. Walberg periodically. The data was grouped in a database that reflects its chronological grouping. The group?s samples spans from January 1989 until November 1991. The total number of instances is 699.

The dataset contains 11 attributes, which are described in table 1 below. [18]  Table 1: Attributes description  Attribute Type Values  Sample Code Number Numeric No range  Clump Thickness Numeric 1-10  Uniformity of Cell Size Numeric 1-10  Uniformity of Cell Shape Numeric 1-10  Marginal Adhesion Numeric 1-10  Single Epithelial Cell Numeric 1-10  Bare Nuclei Numeric 1-10 Bland  Chromatin Numeric 1-10  Normal Nucleoli Numeric 1-10  Mitoses Numeric 1-10  Class Nominal 2: benign 4: malignant  From this dataset, we are trying to classify whether the case is benign or malignant depending on the features that was mentioned on the table above.

4.1.1 Statistical Analysis of the Dataset: The statistical analysis of the dataset is presented in table 2 below. The mean, median, standard deviation, maximum and minimum values of the dataset are presented.

Table 2: Statistical Analysis of the dataset Feature Mean Median Standard deviation  Sample code number 1071704.099 1171710 617095.73  Clump thickness 4.418 4 2.816 Uniformity of cell  size 3.134 1 3.051  Uniformity of cell shape 3.207 1 2.972  Marginal adhesion 2.807 1 2.855 Single epithelial  cell size 3.216 2 2.214  Bare nuclei 3.545 1 3.644  Bland chromatin 2.438 3 2.438  Normal nucleoli 2.867 1 3.054  Mitoses 1.589 1 1.715   The correlation coefficient is also calculated to describe the relationship between each attribute and the class or target attribute in table 3 below.

Table 3: Correlation between each Attribute and the Target attribute   Attribute pair Correlation coefficient  (1 , Class) 0.080225647 (2 , Class) 0.716001362 (3 , Class) 0.817903735 (4 , Class) 0.818793951 (5 , Class) 0.696800206 (6 , Class) 0.68278453 (7 , Class) 0.827032968 (8 , Class) 0.757083568 (9 , Class) 0.713585324  (10 , Class) 0.423318119   4.2. Experimental Setup The experiments are carried out using SMO SVM and Multilayer Perceptron ANN in Weka. The algorithms were applied on a dataset that has contained 11 attributes with 669 instances with no missing values. The values of the class attribute have been changed to nominal values instead of numerical values. The values are changed from 2 (for benign) and 4 (for malignant) to Benign and Malignant respectively. The classifiers are first experimented using different set of attributes based on the correlation coefficient between the attributes and the target attribute with the optimum parameters. We used both 10-Fold Cross Validation and direct partitioning to achieve better accuracy.

4.3. Optimization strategy The SVM classifier parameters are run by choosing different values for each parameter. First four kernel    functions are tested one at a time. The kernel functions are Polynomial function, Normalized Polynomial function, PUK function and RBF function. The PUK function resulted with better accuracy percentages. The same procedure is applied with the rest of the attributes and also with ANN classifier where many values were tested then the classifier was set to the ones that achieved better results.

The SVM and ANN final optimal parameters results are shown in tables 4 and 5 below.

Table 4: Optimum parameters for the proposed SVM model   Parameters Optimal Value chosen C 1  Omega 1.3 Sigma 1  Random Seed 1 Epsilon(? ) 0.0  Kernel PUK.

Table 5: Optimum parameters for the proposed ANN model  Parameters Optimal Value chosen  Hidden Layers i  Learning Rate 0.3  Momentum 0.1  Training Time 100  Seed 0  Validation Size 0  Validation Threshold 10  5 Results of Investigating the Effect of Feature Selection on the Dataset  Using the correlation coefficient of table 3 we can select the features as follows and compare the effects on the results.

Table 6: Results of different features subset   Features Selected SVM ANN All 97.1388 % 96.7096 %  7,4,3,8,2 96.5665 % 96.7096 % 7,4,3 95.422  % 95.7082 % 7,4 95.1359 % 94.7067 % 7 91.1302 % 89.2704 %   The table shows the results of the classification of  both classifiers SVM and ANN that has been tested on different feature?s subsets. The subsets were selected by using the correlation coefficient of each feature against the  class target. First both classifiers were run on all ten features. The second run was on the half of the features which is five features, where features with the highest correlation coefficient are picked. The third run was on the three best features, the fourth on two best features and the last was on the best feature.

The results show that the SVM has high performance when using the whole features while the ANN performance is equal when using the full set of features and half the subset of the features.

Table 7: Results of using the best options based on the optimal parameters obtained   SVM ANN  97.1388 % 96.7096 %  It is observed that SVM achieved slightly better  classification accuracy with 97.1388% than ANN.

Table 8: SVM confusion matrix   Predicted --> Benign Malignant  Benign 442 16 Malignant 4 237   Table 9: ANN confusion matrix  Predicted --> Benign Malignant Benign 443 15  Malignant 8 233  From the confusion matrices for SVM and ANN, it is observed that SVM prediction of Malignant class is slightly better than ANN.

Figure 3: SVM ROC graph for class Benign        Figure 4: SVM ROC graph for class Malignant     Figure 5: ANN ROC graph for class Benign      Figure 6: ANN ROC graph for class Malignant     5.0 Conclusion and recommendation This paper compared two models to classify Wisconsin Diagnosis Breast Cancer dataset. The models are built using two different classification techniques which are Artificial Neural Network and Support Vector Machine combined with features selection and 10-Fold Cross Validation. By using the data partitioning and finding the optimal parameters, the classification tasks has been run using different combination of feature subsets. Based on results achieved, both SVM and ANN are observed and compared by means of classification accuracy. SVM showed better performance results on classifying the samples with 97.1388 % accuracy compared to ANN that achieved 96.7096 % accuracy. It was also noticed that the best accuracy was achieved by both techniques when all the available features were used, which is an indication that there were interrelationship among the features with one supporting the other to make the entire system achieved better outcome.

Further experiments could be done as future work by using different techniques of feature selection, such as Info Gain, to possibly improve the classification accuracy. Also the effect of different data partitioning method could be investigated in future researches.

Reference [1] ?Breast Cancer: Integrative Treatment Program |  CTCA.? .

[2] C. Chen, ?Curriculum Assessment Using Artificial  Neural Network and Support Vector Machine Modeling Approaches: A Case Study,? Jan. 2010.

[3] S. V. G. Reddy, K. T. Reddy, V. V. Kumari, and K.



V. Varma, ?An SVM Based Approach to Breast Cancer Classification using RBF and Polynomial Kernel Functions with Varying Arguments,? vol. 5, no. 4, pp. 5901?5904, 2014.

[4] A. Adam and K. Omar, ?Computerized Breast Cancer Diagnosis with Genetic Algorithms and Neural Network Keywords?:?  [5] K. U. Rani, ?Parallel Approach for Diagnosis of Breast Cancer using Neural Network Technique,? vol. 10, no. 3, pp. 1?5, 2010.

[6] M. F. Akay, ?Support vector machines combined with feature selection for breast cancer diagnosis,? Expert Syst. Appl., vol. 36, no. 2, pp. 3240?3247, 2009.

[7] A. M. Elsayad, ?Diagnosis of Breast Cancer using Decision Tree Models and SVM,? vol. 83, no. 5, pp.

19?29, 2013.

[8] K. Menaka and S. Karpagavalli, ?Breast Cancer Classification using Support Vector Machine and Genetic Programming,? pp. 1410?1417, 2013.

[9] H. Thazin, T. Thein, K. Mo, and M. Tun, ?A N A    PPROACH F OR B REAST C ANCER D IAGNOSIS,? vol. 6, no. 1, pp. 1?11, 2015.

[10] E. Edriss, E. Ali, and W. Z. Feng, ?Breast Cancer Classification using Support Vector Machine and Neural Network,? vol. 5, no. 3, pp. 1?6, 2016.

[11] G. Zorluoglu and M. Agaoglu, ?Diagnosis of Breast Cancer Using Ensemble of Data Mining Classification Methods,? vol. 1, no. 3, pp. 318?322, 2015.

[12] S. Peddabachigari, A. Abraham, and J. Thomas, ?Intrusion Detection System Using Support Vector Machine and Decision Tree,? Int. J. Comput. Appl., vol. 3, no. 3, pp. 40?43, 2010.

[13] A. Ben-Hur and J. Weston, ?A user?s guide to support vector machines.,? Methods Mol. Biol., vol.

609, pp. 223?239, 2010.

[14] ?Support Vector Machines (SVM).? .

[15] L. Auria and R. A. Moro, ?Support Vector  Machines (SVM) as a Technique for Solvency Analysis,? in DIW Wochenbericht, 2008, no.

August.

[16] K. C. Gupta, ?Neural Network Structures,? Neural Networks RF Microw. Des., pp. 61?103, 2000.

[17] C. Stergiou, ?Neural Networks.? .

[18] ?UCI Machine Learning Repository: Breast Cancer  Wisconsin (Original) Data Set.? [Online].

Available: https://archive.ics.uci.edu/ml/datasets/Breast+Cance r+Wisconsin+(Original). [Accessed: 29-Sep-2016].

