Mining Generalized Fuzzy Association Rules via Determining  Minimum Supports

Abstract: Association rule mining is based on the assumption that users can specify the minimum-support for mining their databases. It has been identified that setting the minimum support is a difficult task to users. This can hamper the widespread applications of these algorithms. This paper proposes a method for computing minimum supports for each item. It therefore will run the fuzzy multi-level mining algorithm for extracting knowledge implicit in quantitative transactions, immediately. More specifically, our algorithms automatically generate actual minimum-supports according to users? mining requirements. In order to address this need, the new approach can express tow profits includes computing the minimum support for each item regarding to characteristic for each item in database and making a system automation. We considered an algorithm that can cover the multiple level association rules under multiple item supports. We experimentally examine the algorithms using a dataset, and demonstrate that our algorithm fittingly approximates actual minimum-supports from the commonly-used requirements.

Keywords: Fuzzy data mining; minimum confidence; multiple minimum supports; membership functions; association rule.

1. Introduction In information age, people face more and more  information problems such as data saving, organizing and indexing etc. These problems have the characteristic as more complication in hierarchy, more spacious in working space, faster in time and more abroad and far- reaching in results and influences. Data mining is a new field in data treating. It is a process to find models, outlines and educing values from data set. It is a cross- discipline, dealing with database technique, machine learning, statistics, neural network, knowledge engineering, high performance calculation etc. and is widely used in industry, agriculture, commerce, business and iatrical etc [1].

Association rule mining finds interesting association or correlation relationship among a large data set of items [2]. The discovery of interesting association rules can be of help in decision making process. Market basket analysis is considered as a typical example of association rule mining. In market basket analysis, customers buying  habit is analyzed for finding association between different items customers put together in their shopping cart. Two different items, A and B, in an itemset are assumed to have a relation if they are purchased together in the same transaction [3]. In this case, it can be considered as if one customer buys A is the reason he/she buys B and vice versa. More two items are purchased together in the same transaction, more they have stronger relation. The discovery of such associations can help retailers develop marketing strategies by gaining insight into which items are frequently purchased together by customers [3].

Recently,  the  fuzzy  set  theory  [4] has  been  used more and more frequently in intelligent systems because of  its simplicity and  similarity to human reasoning [5].

Several  fuzzy  learning  algorithms  for  inducing  rules from given sets of data have been designed and used  to good effect with specific domains [6], [7]. As to  fuzzy data  mining,  Hong  and  Kuo  proposed  a mining approach  that  integrated  fuzzy-set  concepts with the Apriori mining algorithm [8] to find interesting itemsets and fuzzy association rules in transaction data with quantitative values.

However, these mining algorithms are mostly based on the assumption that users can specify the minimum support appropriate to their databases, and thus referred to as the Apriori-like algorithms [9], [10]. Han et al [11] have pointed out that setting the minimum support is quite subtle, which can hinder the widespread applications of these algorithms. Our own experiences of mining transaction databases also tell us that the setting is by no means an easy task. With existing algorithms that presume a single minimum support, the best that one can do is to apply such algorithms at the lowest minimum support specified and filter the result using the other minimum supports. This approach will generate many candidates that are later discarded [12]. Hong and et al proposed a method for Multi-level fuzzy mining with multiple minimum supports [13], [14] but in this issue user must be specified minimum support for each item.

Ehsan Vejdani Mahmoudi*, Vahid Aghighi**, Masood Niazi Torshiz***, Mehrdad Jalali****, Mahdi Yaghoobi***** *  Young Researchers Club, Mashhad Branch, Islamic Azad University, Mashhad, Iran, e.vejdani@mshdiau.ac.ir  **   Department of computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, vd.aghighi@gmail.com *** Department of computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, niazi@mshdiau.ac.ir  **** Department of computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, jalali@mshdiau.ac.ir ***** Department of Electrical Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, yaghobi@mshdiau.ac.ir    Furthermore, taxonomic relationships among items often appear in real applications. For example, wheat bread and white bread are two kinds of bread. Bread is thus a higher level of concept than wheat bread or white bread. The information needed by decision makers in some applications is not necessary to be detailed to the primitive concept level, but at a higher one. For example, the association rule ?bread ?milk? may be more helpful to decision makers than the rule ?wheat bread? juice milk?. Discovering association rules at different levels may thus provide more information than the one at a single level [15], [16].

Basically, fuzzy mining algorithms first used membership functions to transform each quantitative value into a fuzzy set in linguistic terms and then used a fuzzy mining process to find fuzzy association rules. This paper consists two phases. First phase, computing minimum supports for each item in database with its own features. In the second phase, starting fuzzy multiple level mining algorithm with multiple minimum supports of items for extracting implicit knowledge from transactions stored as quantitative values.

The remaining parts of this paper are organized as follows. Multiple level mining and compute minimum support for each item discussed in Section 2. The proposed algorithm modified framework multiple level fuzzy mining with multiple minimum supports is described in Section 3.  Numerical simulations are shown in Section 4. Conclusion is given in Section 5.

2. Preliminary In this section, we explain the concept of multiple  level mining. Afterward, we illustrate how one can compute minimum support for each item.

2.1 Mining multiple level association rules  Previous studies on data mining focused on finding association rules at a single concept level. Mining association rules at multiple concept levels may, however, lead to discovery of more general and important knowledge from data. Relevant item taxonomies are usually predefined in real-world applications and can be represented as hierarchy trees. Terminal nodes on the trees represent actual items appearing in transactions; internal nodes represent classes or concepts formed from lower-level nodes [17]. A simple example is given in Fig.

1.

In Fig. 1, the root node for ?Food? is at level 0, the internal nodes representing categories (such as ?Milk?) are at level 1, the internal nodes representing flavors (such as ?Chocolate?) are at level 2, and the terminal nodes representing brands (such as ?Kaleh?) are at level 3. Only terminal nodes appear in transactions. Han and Fu proposed a method for finding level-crossing association rules at multiple levels [16]. Their method could find flexible association rules not confined to strict, pre-arranged conceptual hierarchies. Nodes in predefined taxonomies are first encoded using sequences of numbers and the symbol ?*? according to their positions in the hierarchy tree [13]. For example, the internal node ?Milk? in Fig. 1 is represented by 1**, the internal node  ?Chocolate? by 11*, and the terminal node ?Pegah? by 111. A top-down progressively deepening search approach is used and exploration of ?level-crossing? association relationships is allowed [13].

Fig. 1: The predefined taxonomy  2.2 Computing the multiple minimum support A variety of mining approaches based on the Apriori  algorithm were proposed, each for a specific problem domain, a specific data type, or for improving its efficiency [18]. In these approaches, the minimum supports for all the items or itemsets to be large are set at a single value. Liu et al. proposed an approach for mining association rules with non-uniform minimum support values [19].

In reality, however, there are many good reasons that the minimum support is not uniform. First, deviation and exception often have much lower support than general trends [12]. For example, rules for accidents are much less supported than rules for non-accidents, but the former are often more interesting than the latter. Second, the support requirement often varies with the support of items contained in an itemset. Rules containing bread and milk usually have higher support than rules containing food processor and pan. Third, item presence has less support than item absence. Fourth, the support requirement often varies at different concept levels of items [15], [16]. Fifth, hierarchical classification like[20] requires feature terms to be discovered at different concept levels, thereby, requiring a non-uniform minimum support. Finally, in recommender systems [21], recommendation rules are required to cater or both big and small groups of customers. In general, rules of high support are well-known to the user, and it is the rules of low support that may provide interesting insights and need to be discovered [12]. Hong et al proposed multiple level fuzzy mining with multiple minimum supports [13], [14]. In their method; user must be specifying minimum support for each item. But, it has been recognized that setting the minimum support is a difficult task to users.

This can hinder the widespread applications of these algorithms. In this paper we propose a method for computing minimum support for each item with own characterize in databases. There are significant criteria for computing minimum support like, the number that each item happened in database and sum of values for each item in database. For example, suppose the number that item A happened in database is 10 and sum values is 20    and also the number that item B happened in database is 2 and sum values is 20. Clearly in mining process item A valuable than item B. We computing minimum support for item B until this item can?t satisfying minimum support. As mentioned above, we suggested in (1) as below: _ ( ) = ?? ?     (1)  Let I = {i1, i2, ..., im} be a set of items and D = {t1, t2, ... , tn} be a set of transactions. N is total number of transaction data. T is the number that each item happened in database. Si is sum values of an item in database D. P is constant digit with respect to the interval [0, 1].

3. The Proposed Algorithm The proposed algorithm modified framework multi-  level fuzzy mining with multiple minimum supports [13], [14]. The proposed mining algorithm integrates fuzzy set concepts, data mining and multiple-level taxonomy to find fuzzy association rules in a given transaction data set. The knowledge derived is represented by fuzzy linguistic terms, and thus easily understandable by human beings. In spite of proposed algorithm [13], [14] which user must be specified minimum support for each item, we computed minimum support for each item with own characteristics. Minimum supports are computed by a pre-processing on all items. Since, in real world applications, like applications which work on transactional data of chain stores, items have different quantities. Hence, using different minimum supports for each item in order to mining association rules is an efficient idea. The minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset, while the minimum support for an item at a higher taxonomic concept is set as the minimum of the minimum supports of the items belonging to it [13]. The proposed fuzzy mining algorithm first encodes items (nodes) in a given taxonomy as Han and Fu?s approach did [16]. It then filters out unpromising itemsets; the count of a fuzzy region is checked to determine whether it is larger than support threshold. In this phase, a set of membership functions are used to transform the quantitative transactions into fuzzy values. The proposed algorithm then finds all the large itemsets for the given transactions by comparing the fuzzy count of each candidate itemset with its support threshold.

Input: A body of n quantitative transaction data D, predefined taxonomy with the primitive items, a set of membership functions, P is constant digit with respect to the interval [0, 1], and a minimum confidence value ?.

Output: A set of fuzzy association rules.

Step 1) Encode the predefined taxonomy using a  sequence of numbers and the symbol ?*?, with the lth number representing the branch number of a certain item at level l.

Step 2) Translate the item names in the transaction data according to the encoding scheme.

Step 3) Compute minimum support for each item in (1):  min_sup(I ) = ?? ?    (1) Let I = {i1, i2, ..., im} be a set of items and D = {t1,  t2, ... , tn} be a set of transactions. N is total number of transaction data. T is number of occurrence an item in the database. Si is sum values of an item in database D. P is constant digit with respect to the interval [0, 1].

Step 4) Set k = 1, where k is used to store the level number being processed.

Step 5) Group the items with the same first k digits in each transaction   and add the amounts of the items in the same groups in . Denote the amount of the j-th group  for   as .

Step 6) For each group , transform the quantitative value   of  in each transaction datum   into a fuzzy set  represented as, + +  ? +   using specified membership functions in Step 3, where  I=l to n, h is the number of fuzzy regions for  ,  is the lth fuzzy region of  , 1 <   < ?, and  is `s fuzzy membership value in region .

Step 7) Collect the fuzzy regions (linguistic terms) with membership values larger than zero to form the candidate set ; Calculate the scalar cardinality  of each fuzzy region  in the transaction data by (2):  count = ? f    (2)  Step 8) Check whether the value  of each region  in   is larger than or equals to the threshold , which is the minimum of minimum supports of the primitive items descending from it. If  satisfies the threshold, put it into the large 1-itemset  for level k.

That is, = { | ? , 1 ? ? }.

Step 9)  If k reaches the level number of the taxonomy, go to Step 17 to find association rules; otherwise, if  is null, set k = k + 1 and go to Step 4; otherwise, do the next step.

Step 10) Generate the candidate set   from , , ? ,  to find ??level-crossing?? large itemsets. The generated candidate set   has to satisfy following conditions:  a) Each 2-itemset in  must contain at least one item in .

b) The two regions in a 2-itemset may not have the same item name.

c) The two item names in a 2-itemset may not be with the hierarchy relation in the taxonomy.

d) Both of the support values of the two large 1- itemsets comprising a candidate 2-itemset must be larger than or equal to the maximum of the minimum supports of the two large 1-itemsets.

Step 11) Do the following sub steps for each newly formed candidate 2-itemset s with regions (s1, s2) in  :    a) Calculate the fuzzy value of s in each transaction   as = ? , where  is the membership value of region  in . Assume the minimum operator is used for intersection, then =  ( , ).

b) Calculate the scalar cardinality of s in all the transaction data as  = ? .

c) If counts is larger than or equals to the maximum of the minimum supports of the items contained in it, put s into .

Step 12) Set r = 2, where r is used to represent the number of regions stored in the current large itemsets.

Step 13) If  is null, then set k = k + 1 and go to Step 6; otherwise, do the next step.

Step 14) Generate the candidate set  from  in a way similar to that in the Apriori algorithm [22]. That is, the algorithm first joins  and , assuming that ? 1 regions in the two itemsets are the same and the other one is different. There is a difference from the Apriori algorithm in that the supports of all the large r-itemsets comprising a candidate (r + 1)-itemset I must be larger than or equal to the maximum of the support thresholds of these large r-itemsets. Store in  all the itemsets with all their sub-r-itemsets in  and satisfying the above conditions.

Step 15) Do the following sub steps for each newly formed (r+1)-itemset s with regions ( , , . . . , ) in  : a) Calculate the fuzzy values of s in each transaction  as, where is the membership value of region  in .

Assume the minimum operator is used for intersection, then (3) follow as: =     (3)  b) Calculate the scalar cardinality of s in all the transaction With in (4): = ?     (4)  c) If  is larger than or equals to the maximum of the minimum supports of the regions contained in it, put s into .

Step 16) Set r = r + 1 and go to Step 13.

Step 17) Construct the fuzzy association rules for all  large q-itemset s containing regions ( , , . . . , ),  ?  2, by the following substeps: a) Form all possible association rules by (5) as  follows: ? ? ?   ? ? ?  ?  ?  , = 1   (5) b)  Calculate the confidence values of all  association rules by (6): ?? ?? ? , ? ? ?   (6) Step 18) Output the rules with confidence values larger  than or equal to the predefined confidence value .

Note that since the hierarchical relationship of the items in a candidate 2-itemset has been checked in Step 10, the candidate 3-itemsets will not need to be checked for it according to a lemma in [15]. All the large itemsets will thus exclude the hierarchical relationship of items.

4. Numerical simulations To evaluate our work we have compared our algorithm  with two previously proposed approaches: Mining Fuzzy Multiple-Level Association Rules from Quantitative Data [23] and Multi-level fuzzy mining with multiple minimum supports [13]. The experiments were implemented in MATLAB R2008b on a computer with Intel Core(TM) 2 Duo Processor 2.66GHz and 4 GB main memory, running the Microsoft Windows 7 operating system. We used Dataset [24] with a total of 64 items and 10,000 transactions. The dataset [24] contained quantitative transactions about the products sold in the chain store. The parameters in three algorithms were set as follows: the minimum confidence was set 0.5 for three algorithms, the defined minimum support for algorithm [23] was set 2.1, and for proposed algorithm in [13] minimum supports must specified by expert user, which is a very difficult task. The minimum supports for our approach is computed by (1). The value of constant P was set 0.27*10-6, as mentioned in (1).

The number of association rules along with different number of transactions was extracted for three algorithms and the result is shown in Fig. 2. It?s clear that our proposed method produces equal rules in contrast with the algorithm in [23] in the interval of 6000 to 8000 transactions, but it remarkably produces more rules after 8000 transactions. The reason is that we consider the items characteristics for determining the minimum support and as a result we expect to obtain more association rules.

It is also clear that the proposed method generates fewer rules in comparison with algorithm in [13] in the interval of 6000 to 8000 transactions. But, it doesn?t mean that the algorithm in [13] is better than our approach because, the minimum supports are specified by an expert user and thus it may lead to better results accidentally. On the other hand, our method has much better result in producing more association rules after 8000 transactions as you can see in Fig. 2.

Fig. 2: The number of association rules along with different numbers of  transactions   6000 7000 8000 9000 10000  N um  be r  of a  ss oc  ia tio  n ru  le s  Number of transactions  The Proposed algorithm in [23]  The proposed algorithm  The proposed algorithm [13]    Furthermore, the number of association rules along with different values of confidence threshold is shown in Fig. 3. The number of transactions for the three algorithms is constant and equal to 9500. It can be easily seen that the number of rules is decreasing as we increase the confidence threshold value. It is also vivid that the proposed method has much more association rules than the others. In what follows, we will show that our algorithm has also better accuracy in spite of generating more association rules.

Fig. 3: the number of association rules along with different values of  Confidence threshold   Figure 4 shows the accuracy of algorithms along with different numbers of transactions. The number of transactions is again considered constant and it is equal to 10000. The accuracy means that how much an extracted rule is appeared in our data base transactions. Regarding this definition, our proposed algorithm has much more accuracy in the interval of 8000 to 10000 in contrast with the other two approaches. But, it has less accuracy in comparison with algorithm in [13] and the same accuracy with algorithm in [23]. As previously mentioned, the minimum support is determined with an expert user which makes it a difficult task and may sometimes lead to better results.

Fig. 4: Accuracy along with different numbers of transactions  The Execution times are calculated for the three algorithms and it is shown in Fig. 5. The execution time of the proposed method is equal to its value for the algorithm in [23] but is less than its value for the algorithm in [13] in the interval of 6000 to 8000 transactions. But, the execution time is higher for the proposed method in the interval of 8000 to 10000 transactions as the number of association rules increases.

For demonstrating the performance of our approach we define a new parameter which is a proportion of total number of rules to execution time. This parameter is called time ratio and is discussed in more details in the next paragraph.

Fig. 5: execution time of algorithms   The time ratio along with different values of  confidence threshold is obtained for the algorithms and is shown in Fig. 6. Note that the number of transactions is again equal to 10000. As you can see, the proposed method has lower time ratio among the other two approaches. This means that our algorithm has the best overall performance.

Fig. 6: time ratio along with different values of Confidence threshold  5. Conclusions When users have stated their mining requirements for  frequent itemsets, the term ?frequent? has already been a         0 0.2 0.4 0.6 0.8  N um  be r  of a  ss oc  ia tio  n ru  le s  Confidence  threshold  The proposed algorithm in [23]  The proposed algorihtm  The proposed algorithm in [13]    6000 7000 8000 9000 10000  A cc  ur ac  y  Number of transactions  The proposed algorithm in [23]  The proposed algorithm  The proposed algorithm in [13]        6000 7000 8000 9000 10000  Ex ec  ut io  n tim  e (s  ec on  d)  Number of transactions  The proposed algorithm in [23]  The proposed algorithm  The proposed algorithm in [13]  0.5  1.5  2.5  3.5  4.5  0 0.2 0.4 0.6 0.8  T im  e ra  tio  Confidence threshold  The proposed algorithm in [23]  The proposed algorithm  The proposed algorithm in [13]    threshold from a fuzzy viewpoint. However, existing Apriori-like algorithms still require users to specify the actual minimum-support appropriate to the databases to be mined. Unfortunately, it is impossible to specify the minimum-support appropriate to the database to be mined if users are without knowledge concerning the database.

On the other hand, even though a minimum-support is explored under the supervision of an experienced miner, we cannot examine whether or not the results are really what the users want. In this paper, we have proposed mining algorithm integrates fuzzy set concepts, data mining and multiple level taxonomy to find fuzzy association rules in a given transaction data set and also it consists two phases. First phase, computing minimum supports for each item in database with own features and in the second phase, starting fuzzy multiple level mining algorithm with multiple minimum supports of items for extracting implicit knowledge from transactions stored as quantitative values. Our mining strategy is different from existing Apriori-like algorithms because our mining strategy allows users to specify their mining requirements in commonly used modes and our algorithms automatically earned the specified threshold into actual minimum-support (appropriate to a database to be mined). Thus, Our approach have two profits includes computing the minimum support for each item regarding to characteristic for each item in database and making a system automation. To evaluate our approach, we have conducted some experiments. The results have demonstrated the effectiveness and efficiency of our mining strategy.

