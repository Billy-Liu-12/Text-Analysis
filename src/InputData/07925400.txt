From Social Media to Public Health Surveillance: Word Embedding based Clustering Method for

Abstract?Social media provide a low-cost alternative source for public health surveillance and health-related classification plays an important role to identify useful information. In this paper, we summarized the recent classification methods using social media in public health. These methods rely on bag-of- words (BOW) model and have difficulty grasping the semantic meaning of texts. Unlike these methods, we present a word embedding based clustering method. Word embedding is one of the strongest trends in Natural Language Processing (NLP) at this moment. It learns the optimal vectors from surrounding words and the vectors can represent the semantic information of words. A tweet can be represented as a few vectors and divided into clusters of similar words. According to similarity measures of all the clusters, the tweet can then be classified as related or unrelated to a topic (e.g., influenza). Our simulations show a good performance and the best accuracy achieved was 87.1%.

Moreover, the proposed method is unsupervised. It does not require labor to label training data and can be readily extended to other classification problems or other diseases.

Keywords?Unsupervised Classification, Public Health, Twit- ter, Social Network, Big data, Surveillance, Word Embeddings, Word2Vec, Machine learning, Natural Language Processing, Clustering Process, Similarity Measure

I. INTRODUCTION  Disease monitoring and tracking is of tremendous value, not only for containing the spread of contagious diseases but also for avoiding unnecessary public concerns and even panic [13]. Traditional public health surveillance is often limited by the time required to collect data. For example, the influenza surveillance system of the Center for Disease Control and Prevention (CDC) collects data from health departments, healthcare providers, clinics, professionals, health laboratories, and emergency departments [5]. This introduces about one-to- two week reporting delay [12] [20].

Social media platforms (such as Twitter, Facebook, Reddit,  Tumblr, Pinterest and Instagram) have seen unprecedented growth in the era of big data. For example, Twitter, one of the most popular social network websites, which has been growing at a very fast pace. It has 284 million monthly active users, and 500 million tweets are sent per day [51]. Users often share their feelings, thoughts, activities, opinions and random details of their lives on social networks. Several studies have  been demonstrated using social media as a low-cost alternative source for public health surveillance and health-related classi- fication plays an important role to identify useful information [11].

TABLE I RECENT CLASSIFICATION APPROACHES IN PUBLIC HEALTH  Author Year Health Topic Approach Lampos et al.[30] 2010 influenza I:KS Scanfeld et al.[44] 2010 antibiotics I Achrekar et al.[1] 2011 influenza I:KS Collier et al.[7] 2011 influenza II:SVM/NB Aramaki et al.[15] 2011 influenza II:SVM/NLP Heaivilin et al.[25] 2011 dental pain I:KS Krieck et al.[29] 2011 disease outbreaks I:KS Paul et al.[38] 2011 syndromic I Prier et al.[37] 2011 tobacco/smoking I:LDA Signorni et al.[47] 2011 H1N1 II Speriosu et al.[50] 2011 public mood III West et al. [42] 2012 drinking I Salathe et al.[46] 2012 health perceptions III:PMI/SWN Chew et al.[6] 2013 H1N1 I:KS Kanhabua[28] 2013 disease outbreaks I:KS Myslin M [35] 2013 tobacco/smoking II:NB/KNN/SVM Copper al.[22] 2014 mental health II Huang et al.[26] 2014 tobacco/smoking II:NB Dai et al.[11] 2015 influenza II:NB/NLP Ofoghi et al.[36] 2016 public mood II:NB, III:FN Xiang et al.[52] 2016 health concerns III  Category: (I) keywords-based (II) learning-based (III) lexicon-based Methods: LDA: latent dirichlet allocation, NB: naive bayes, SVM: support vector machine, KS: keywords/terms statistics KNN: k nearest neighbors, NLP: natural language processing PMI: pointwise mutual information, SWN: SentiWordNet FN: FrameNet

II. RELATED WORK  The recent approaches in public health are summarized into three main categories: keywords-based approaches, learning- based approaches and lexicon-based approaches (Table I).

1) Keywords-based Approaches: Most earlier studies rely  on the keywords analysis such as word occurrences and word frequency. Lampos et al. [30] detected flu-related keywords to track influenza rates in the U.K. The flu-related keywords were used to learn a flu-score according to the weights of the     keywords in each document. Culotta et al [10] collected flu- related keywords from Twitter and analyzed the correlation with national health statistics. Achrekar et al. [1] performed a similar study to collect tweets using flu-related keywords.

They then counted the number of tweets at each time step per keyword to predict flu trends. Scanfeld et al. [44] inves- tigated antibiotic abuse or antibiotic overuse. In their work, they tracked the tweets that mentioned antibiotics to find the antibiotics-related tweets. Heaivilin et al.[25] evaluated whether Twitter users broadcast information relating to dental pain and assessed the content of the information being commu- nicated. A representative sample of tweets was collected using keywords/terms search. Prier et al.[37] used Latent Dirichlet Allocation (LDA) to analyze terms and topics from the entire dataset as well as from a subset of tweets created by querying general, tobacco use-related terms. The study of [42] was to examine the extent to which individuals tweeted about problem drinking, and to identify if such tweets corresponded with time periods when problem drinking was likely to occur. Tweets were identified that contained words reflective of problem drinking. Chew et al. [6] focused on the diversity in keyword lists for dynamics of change in circulated tweets for H1N1 virus. More similar studies are [1], [47], [54].

These methods rely on the keyword analysis and disregard  context, grammar and even word order. They cannot suffi- ciently capture the complex linguistic characteristics of words [49].

2) Learning-based Approaches: These approaches have  been intensively studied during the past decade, which re- quire labeled data for training. Naive Bayes, k nearest neigh- bors (KNN), maximum entropy, and support vector machines (SVM) have been applied to a lot of health classification problems and achieved satisfactory results. Signorni et al.

[47] employed a SVM classifier to determine the flu-related tweets. They then used the classified tweets to track the public sentiment with respect to H1N1 activities. Collier et al. [7] developed two supervised classifiers (SVM and Naive Bayes) to classify tweets for bio-surveillance. Unigrams, bigrams and regular expressions were used for feature selection. Myslin M [35] built machine learning classifiers using Naive Bayes, KNN, and SVM algorithms to classify tobacco-related tweets for sentiment analysis towards tobacco. Huang et al. [26] investigated e-cigarettes related tweets for public health men- tions and smoking cessation mentions by using Naive Bayes machine learning methods.

Our previous work [11] presented a hybrid classification  method that combines NLP preprocessing, rule-based classi- fiers and machine learning classifier. Our experimental results achieved a better performance than any single approach. The method improves the classification process because it takes advantage of the multiple approaches. The Naive Bayes model is used for the machine learning classifier, which assumes that all features are independent. It is computationally efficiency, but it avoids the contextual meanings of words.

In summary, the learning-based approaches suffer from the  limitation of labeling training datasets, which requires experts  to read the tweets and ascertain the category to which they belong. For a large-scale twitter data, it is difficult to manually label the large-scale training tweets. Therefore, it will be not easy to apply on other diseases.

3) Lexicon-Based Approaches: The other direction is  knowledge-based, which is also called a dictionary method or knowledge-based method. It is considered to be a part of the unsupervised learning method. Speriosu et al. [50] used label propagation to incorporate labels from knowledge about word types encoded in a lexicon, which does not need annotated labels for training. Salathe et al. [46] proposed an unsupervised classification method for evaluation in health perceptions. The method combines PMI with a lexicon called SentiWordNet.

Ofoghi et al. [36] implemented a simple unsupervised baseline emotion classier using a lexicon-based vector model form the FrameNet. However, the performance of these approaches depends on the lexicons [8].

4) Word Embedding Based Approach: Unlike other ap-  proaches in public health, we present a word embedding based clustering method. Word embedding is the one of the strongest trends in Natural Language Processing at this moment. It learns the continuous vector representation of words from context words and the vectors can represent the semantic information of words. A tweet can be represented as a few vectors and divided into clusters of similar words. According to similarity measures of all the clusters, the tweet then can be classified as related or unrelated to a topic (e.g., influenza).

Our approach is unsupervised and does not require annotated data.



III. RESEARCH DESIGN AND METHODOLOGY A. Architecture of Word Embedding Based Clustering Classi- fication Figure 1 shows the architecture of the proposed method,  which involves the following 3 steps: ? Step 1: NLP preprocessing - Social media are informal, less structured, contain misspellings and nontextual in- formation. NLP preprocessing is recommended to clean data for further analysis [11].

? Step 2: Clustering process - This step divides a tweet into clusters of words. Not all words in a tweet are helpful for classification. Some words actually distract identifying the topic and these words introduce bias. It is insensitive and fuzzy to use all words of a tweet for classification. However, it is too sensitive to use every single word.

? Step 3: Similarity measure - It identifies whether one of the clusters is related to flu according to cosine similarity measure. In this study, we consider if one of clusters is related to flu, the tweet then is related to flu.

B. NLP preprocessing Tweets contain various noisy contents such as hash tags,  slangs, abbreviations, links, etc. (Table II) and need to be tokenized or normalized, which is called text preprocessing [11]. It involves the following:    Fig. 1. Architecture of Word Embedding Clustering Classification  ? Throw away special characters, punctuations, digits, HTML tags, quote, additional spaces, URLs and replies to users (@usernames) - They often appear in tweets, but do not contain any information for identifying topic.

? Capitalization, case folding - convert all words to lower case  ? Correct spelling mistakes ? Nested words - filtering words by length.

? Stopwords removal - stopwords (such as prepositions, articles, a, is, the, with etc) have a high frequency of occurrence in the tweets. They do not carry much meaning and are not typically related to topic classifi- cation. Classifiers on average are more accurate without stopwords [24].

TABLE II TWEETS CONTAIN NOISY CONTENTS  Feeling so miserable :( Having a flu fever Did not go to school DD: I will stay home, do some gentle stretching and nourish myself with herbal teas or veggie juices.

Turkey sandwich @__@, anyone?

https://t.co/DZ.u #_# Let?s go @panthers! So excited to watch the Super Bowl!!! #SB50  C. Word Embedding Model The word embedding model we used in this research is  Word2Vec [32] [33]. It is an open source deep learning toolkit from Google based on word analogies that probes the finer structure of the word vector space. Once a word embedding model is created, each word in a tweet can be represented as  a continuous space vector. For example, one can input a word (e.g., influenza) to the model, it returns a vector like this:  [-0.09220404 0.17788577 -0.15402232 -0.0221551 0.12370043 -0.11695234 -0.10891347 -0.02606416 0.12587149 0.11295457 0.05856625 0.09467842 0.08716864 0.0077392 -0.11854415 -0.13117599 0.11624993 0.10040938 -0.03850672 -0.17260635 -0.08380257 0.08499301 -0.01977218 -0.07082637 0.16041237 -0.10684048 -0.10911188 0.03601867 0.05466199 0.03672563 0.63015562 0.07612631 0.10935818 -0.08508652 0.16213417 0.15687755 0.01537053 0.32331052 -0.08125523 -0.10982797 0.12150883 -0.01701115 0.00365523 0.00532982 -0.0067344 -0.02842223 0.02850888 0.16477957 0.10853034 0.18133394]  The vectors catch semantic relationships between words [4] [9] [21] [33]. We collected a few words of 4 different topics (food, sports, weather and animals), then plotted their vectors in Figure 2. Since these vectors are high dimensional, we use a dimensionality reduction algorithm t-SNE [31] to visualize them in 2D [2].

Fig. 2. words of different topics in a vector space  We can see that the words are clustering together with topics in a vector space. Our clustering process is inspired by this.

A tweet can be divided into clusters of words, then identify whether each cluster is related to flu.

D. Clustering Process This process is unsupervised, it divides a tweet into clusters  of words (Figure 3). The algorithm is adapted from Chinese Restaurant Process (CRP) [3] of Dirichlet Process. The algo- rithm reads word by word from a tweet. The first word is added to the first cluster. The succeeding word has 2 options: add to existing cluster/clusters or add to a new cluster according to the similarity measure (equation 1) and an updated probability.

Cosine similarity is a measure of similarity between two non- zero vectors of an inner product space that measures the cosine    of the angle between them. Two vectors are highly similar if their cosine similarity value is approaching 1.

sim(A,B) = ?n  i=1(AiBi)??n i=1A  i  ?n i=1B  i  (1)  where A and B are the vectors of length n  Fig. 3. Divide a tweet into clusters of words  Algorithm: Clustering Process  t: an array of vectors that represents a tweet n: number of clusters p: probability  1) n = 1 2) p = 1/(1 + n) 3) append the first vector t[0] to the first cluster v1 4) loop the remaining vectors in t  a) generate a random variable r between (0, 1) b) if r < p  i) add a new cluster, n = n+ 1 ii) update p iii) append the current vector t[i] to a new cluster  c) else i) compute similarity sj between t[i] and each  existing cluster vj ii) append t[i] to the cluster vj where sj = max(s1, s2, ..., sj)  5) return all clusters v1, v2, ..., vj  The number of clusters varies in different tweets. By prac- tice, most cases end up with 3-5 clusters for a tweet, which satisfies our purpose of extracting topics. For example, the first tweet in Table II can be divided into the clusters of words in Table III.

TABLE III CLUSTERING PROCESS  # Cluster of words C1 Feeling so having did not go  I will stay do some gentle stretching myself  C2 flu fever school C3 miserable C4 nourish herbal teas veggie  E. Similarity Measure to Identify Related or Unrelated  We use similarity measure to identify whether the clusters of words are related to flu. We denote C (Cluster Vector) as the aggregation vector of a cluster. Averaging word embeddings of all words in a text is widely used to aggregate text embeddings [16] [19] [53]. Following this recommendation, one can calculate C by averaging all vectors in the cluster.

We then choose a topic word, this topic word should obviously indicate a topic (e.g., influenza). We denote T as the vector of the topic word. One can calculate a similarity score from topic vector T and the cluster vector C (equation 1). For example, we use the vector of flu as topic vector Tflu. We then compute the similarity score s between Tflu and each cluster C (Table IV).

TABLE IV SIMILARITY MEASURE FOR EACH CLUSTER  # Similarity Score s1 0.134835 s2 0.590763 s3 0.106400 s4 0.122449  We use ?i ? {0, 1} to indicate the ith cluster whether related to flu. We denote ? as similarity threshold. If si >= ? , ?i = 1,else ?i = 0. Table V shows an example when ? = 0.5  TABLE V IDENTIFY EACH CLUSTER  # Related?

?1 0 ?2 1 ?3 0 ?4 0  Since we consider if one of clusters is related to flu, the whole tweet is related to flu. ?1??2??3??4 = 1. Therefore, this tweet is related to flu.



IV. EVALUATION AND RESULTS  A. Datasets  1) Test Set: We collected 2, 270 tweets through Twitter APIs and manually labeled them for testing our classifier.

1, 070 tweets are labeled as related to flu, the other 1, 200 tweets are labeled as unrelated to flu.

2) Pre-trained Vector Set: The quality of the word vec- tors increases significantly with amount of the training data.

Google?s pre-trained vector set [23] is used for our research purpose. It constructs a vocabulary from the training text data (Google News dataset) and then learns vector representation of words. The pre-trained word2vec model contains 3 million words.

B. Evaluation The performance of the proposed method can be evaluated  by four criteria calculated as the following equations:  Accuracy = TP+ TN  TP+ TN+ FP+ FN (2)  In addition to accuracy, precision and recall are the most common measurements to evaluate classifiers.

Precision = TP  TP+ FP (3)  Recall = TP  TP+ FN (4)  The F1 measure is defined as the weighted harmonic mean of precision and recall:  F1 = 2 ? Precision ? Recall Precision+ Recall  (5)  where TP is the number of correctly classified as related tweets, TN is the number of correctly classified as unrelated tweets, FP is the number of false classified as related tweets, FN is the number of false classified as unrelated tweets, as defined in the Table VI.

TABLE VI CONFUSION MATRIX  Predicted Related Predicted Unrelated Actual Related TP FN Actual Unrelated FP TN  The proportion of correctly classified observations is the estimated classification rate. The higher this proportion, the better the classifier. We evaluated the proposed method on 3 different similarity thresholds ? .

TABLE VII EVALUATION OF WORD EMBEDDING CLUSTERING METHOD  ? Precision Recall F1 Accuracy 0.8 99.6% 41.5% 65.2% 65.2% 0.7 99.6% 47.7% 64.5% 75.3% 0.6 96.2% 75.6% 84.6% 87.1% 0.5 77.1% 95.7% 84.7% 84.6% 0.4 55.1% 99.5% 70.9% 55.1% 0.3 48.9% 99.9% 65.7% 50.8%  The higher thresholds ? (0.7 and 0.8) have better precisions, but increase FN (the number of false classified as unrelated tweets), therefore, recalls get down. On the contrary, The lower thresholds ? (0.3 and 0.4) have better recalls, but increase FP (the number of false classified as related tweets).

A superior algorithm should tradeoff between precision and recall. F1 measure is defined as the weighted harmonic mean of precision and recall. It shows excellent performance (F1 and accuracy) when ? = 0.5 and 0.6.

C. Comparison with Supervised Naive Bayes Method We also applied the same dataset on the classical Naive  Bayes classification method for baseline mechanism compari- son. We implemented the Naive Bayes classifier with Python and scikit-learn machine learning library [45]. The dataset was randomly divided into a training set (75%), and a testing set (25%). The Table VIII shows the results of performance.

Our proposed method is better than the standard Naive Bayes method when ? = 0.5 and 0.6. The classical supervised Naive Bayes classification method is better than our proposed method when ? < 0.5 and ? > 0.6  TABLE VIII PERFORMANCE OF NAIVE BAYES METHOD  Classifier Precision Recall F1 Accuracy Naive Bayes 73.4% 76.4% 74.9% 75.6%

V. CONCLUSIONS In this paper, we summarize the existing classification  approaches in public health. The approaches such as keywords or related words analysis, word occurrences analysis do not capture semantic similarity beyond a trivial level. Moreover, the approaches of supervised learning methods are difficult as it requires the labor intensive process of manually labeling a large corpus of training tweets. Furthermore, handcrafted patterns and external sources of structured semantic knowledge cannot be assumed to be available in all circumstances and for all domains in lexicon-based approaches.

We present a word embedding based clustering method for  health-related classification using social media. Unlike other common approaches in public health, our method is based on word embeddings. The vectors of word embeddings are able to represent the semantic information of words. A tweet can be divided into clusters of similar words according to semantic similarity. According to the similarity measure of the clusters of words, the tweet can be classified.

We evaluated the performance in terms of precision and  recall. The higher threshold ? get better precision. The lower threshold ? gets better recall. The algorithm gets good trade- off between precision and recall when ? = 0.5 and 0.6.

We also evaluated the performance in F1 and accuracy. The performance is excellent when ? = 0.5 and 0.6. We compared the proposed method to classical supervised Naive Bayes classification method. Our proposed method is better than the standard Naive Bayes method when ? = 0.5 and 0.6.

Our method is unsupervised and it does not require labors  to label data for training. It can be readily extended to other classification problems or other diseases. Once the temporal disease-related tweets are collected through the proposed clas- sification method, we can use distance-based outliers method [13] for detecting outbreaks.

