A Breadth-First Search Algorithm for Mining Generalized Frequent Itemsets

Abstract   Mining generalized association rules is one of important research area in data mining. If we use the traditional methods, it will meet two basic problems, the first is low efficiency in generating generalized frequent itemsets with the items and levels of taxonomy increasing, and the second is that too much redundant itemsets? support are counted. This paper proposes an improved Breadth-First Search method to mine generalized association rules. The experiments on the real-life data show that our method outperforms the well-known and recent algorithms greatly.

1. Introduction   Recently, many researchers [1] [2] [3] [4] focused on Mining generalized association rules (GARM) in transaction databases. In GARM, a taxonomy(is-a hierarchy) over the items is available, such as in supermarket scenario, ?bread? can be classified into ?white bread? and ?wheat bread?, and ?wheat bread? is-a ?bread?. In real life, it is possible that itemset {wheat bread, milk} is infrequent, but {bread, milk} is frequent. suppose 90% customers buy bread and milk at the same time, here 90% is the {bread, milk}?s support, and the associated rule like ?2% of customers who buy wheat breads also buy milk?, here 2% is the confidence of the rule. Like the association rule mining, the first step of GARM is to find generalized frequent itemsets. If we use traditional algorithms directly, we will meet with several problems. The first one is the outstanding inefficiency of mining algorithms. This is because traditional methods only mine frequent itemsets from leaf level. In GARM, we have to mine all levels? items including the leaf and generalized items, and the number usually is the double of leaf items. Secondly, the traditional algorithms will waste lots of time to calculate the support of redundant or unnecessary itemsets, such as one itemset including ancestor item and its descendant  item. To address these problems, this paper proposed the SET_BFS method based on Set Numeration Tree which take advantage of the characteristic of taxonomy data. Experiments with real-life data show that our method outperforms the well-known and recent algorithms greatly.

This paper is organized as follows. Section 2 is problem statements and term definitions related to the generalized frequent itemsets. In Section 3, the SET_BFS method and optimization rules are proposed.

The detail SET_BFS algorithms are given in Section 4.

In Section 5, by experiments, we compare our algorithms with the well-known and recent algorithms.

The study is concluded in the last section.

2. Problem Statement  2.1 Term definition  To compare with the existed work conveniently, in our statement, we followed some descriptions in [2] [3]. Let I= { i1,i2,?,im } be a set of distinct items. T= { t1,t2,?,tn }, ti is the unique identifier of one transaction, represents the ith transaction, then a transaction is represented with a set of items (a subset of I) , and we call this horizontal transaction database, such as the table in left side of Figure 2. A transaction set including random itemset IG can be represented as TG= {ti | IG? ti, ti? D}. So the transaction sets corresponding to each item of I can be noted as  D= {Ti1 | i1 ? I}, such as the table in right side of Figure 2.

We call this vertical transaction database.

The item of taxonomy can be depicted by Directed Acyclic Graph.

Definition 1 Taxonomy-? We use DAG=(V?E) to depict taxonomy. V is the set of all item nodes and E is the set of all edge. v0 represents the root node, and each node represents an item. For any simple path P=(v0,v1,? ,vn), which represents the relationship of ?is-a?. Then vn-1 is the parent item of vn?vn is the child item of vn-1. v0??,vn-1 are the ancestor items of  International Symposium on Computer Science and its Applications  DOI 10.1109/CSA.2008.26   International Symposium on Computer Science and its Applications  DOI 10.1109/CSA.2008.26     vn,. In contrast, v1,?,vn  are the descendant items of v0.

For any items x, y, z, if x and y are the children of z, then x and y are brother items. The depth of item v refers to the level of v located in taxonomy data. If depth(vi) equals to depth(vj), we call vi and vj sibling items. An item without any children called leaf item.

The items, except root and leaf items, are called interim items or generalized items.

Figure 1 is an example of taxonomy ?, X, Y and Z are generalized items. Next, we give the definition of generalized item, itemset and their corresponding operations.

Fig.1. Taxonomy data of I   Fig.2. Horizontal (left) and vertical (right) database  Definition 2 Generalized Itemset In taxonomy ?, we call itemset IG Generalized Itemset which do not include one item and its ancestor or its descendant items at the same time. Any generalized itemset IG?s support is defined as supp(IG)?|TG| / |T|. If |TG| / |T| ? ?min, (represents the minimal support ? , then generalized itemset IG is frequent. Here |TG| is the transaction counts, which include IG, and ?(IG) is the support of IG.

For example, in Figure 1 and 2, AB, XD and XZ are generalized itemsets, but DZ and AY are not, that is because Z is the parent of D, and Y is the ancestor of A.

From the items composed of associated rule, a rule can be classified into different types.

Definition 3 Generalized Association Rules  (1) The same level generalized association rules (SL AR) {A => B | A, B? ?, A ? B= ?,A, B? ?, and (? g1 ? A, ? g2  ? B, depth(g1)= depth(g2)} (2) The cross level generalized association rules (CLAR) {A => B | A, B? ?, A ? B= ?, and (? ? g1 ? A?? ? g2 ? B, ancestor(g1)= g2 or ancestor (g2)= g1 ?, and?? g1 ? A?? g2 ? B, depth(g1) ? depth(g2)}  The above itemset definition related with taxonomy ? changed the set operations greatly, to manifest these changes, we give some new definitions of operations based on taxonomy ? such as belong to, union and intersection.

Definition 4 The ?? operation between two generalized itemsets Given items i1 and i2, if i1 is ancestor of i2, then we say i1 ?? i2, that is because, from the taxonomy ?, we can see i1 is the generalized item of i2, and if i2 is frequent , then i1 also frequent, furthermore, ??i1?? ??i2?. Given generalized item i1 and generalized itemsets G, if ? i2 ? G, i1 ??  i2, and then we say i1 ?? G. Given generalized itemsets G1 and G2, if ? i1 ? G1, ? i2 ? G2, i1 ?? i2, and then we say G1 ?? G2.

Definition 5 The ?? and ?? operations between generalized itemsets Given generalized itemsets G1 and G2, let G= G1 ?? G2, then ? i1 ? G, we have i1 ?? G1 or i1 ?? G2. Let G= G1 ?? G2, then ? i1 ? G we have i1 ??  G1 and i1 ??  G2.

For example, AC ?? BC= ABC, AZ ?? XD= AD, the corresponding transaction set: DAD= DAZ ? DXD= (DAD ? DAE) ? (DAD ? DBD)= {135} ? {15}= {15}, and AC ?? BC= C, AD ?? XD= XD.

Definition 6 Ancestor-Descendant generalized itemset Given itemset X1, X2 ? I, if |X1|= |X2| and X1.itemi= X2.itemi?0? I< |X1|?, X1.itemj= ancestor?X2.itemj? ?i< j? |X1|?, then we say X1 is the ancestor itemset of X2.

For example, in Figure 1, YZ is the ancestor itemset of AD, and AZ is the ancestor itemset of AE.

2.2 The limitation of recent algorithms  Most of traditional generalized frequent itemset mining is Apriori-based algorithms. To deal with the low efficiency of traditional methods, Hipp. J [3] provided an algorithm called PRUTAX. The goal of this method is to traverse the lattice in such a way that all frequent itemsets are found but as few infrequent itemsets as possible are visited. they use Set Enumeration Tree structure and Right-most Depth-first Search strategy. PRUTAX improve efficiency an order of magnitude than previous approaches. However, this method has not made use of the characteristic of taxonomy, treating the generalized items the same as leaf items.

After that, Sriphaew. K [2] provided a new method named SET for mining generalized frequent itemsets.

With vertical database format, their method enumerates all generalized frequent itemsets using Left-most Depth-first search. The Set Enumeration Tree starts with an empty set. Then add all generalized frequent child in the second level of the taxonomy ?. Form the second level of enumeration tree, the children (next level) of any itemsets are generated in two manners.

Firstly, they generate all tax-based child itemsets (based on parent-child relationship). Each generalized child itemset is generated by replacing the right-most items of those itemsets with one of their children (if exists). Secondly, they generate all join-based child itemsets (based on subset-superset relationship) by joining those itemsets with all of their siblings that have higher orders. This process recursively occur until no new generalized itemsets are generated. Finally, a complete itemset enumeration tree is constructed. The experiment results show that SET outperforms the PRUTAX [3] by an order of magnitude or more. But the depth-first search limited the infrequent itemset?s identify which motivate our improvement of this algorithm.

3. SET_BFS Method and Optimized Rules  3.1 Main idea  To make up the disadvantage of the above methods, we use the following strategies.

(1) We still use tax-based and join-based operations to construct child nodes of enumeration tree of frequent itemsets like SET.

(2) In searching, we use Breadth-first search instead of Depth-first search which can guarantee all of it?s (k- 1) itemsets have been generated before generating a k- itemset, which can be used to avoid counting supports of infrequent itemsets.

(3) In optimization, we extend the Apriori-property to taxonomy, which can be used to prune many infrequent itemsets.

(4) In calculating the support, we still use vertical transaction database instead of horizontal transaction databases like SET.

To illustrate SET_BFS method clearly, we use the taxonomy in Figure 1, transaction database in Figure 2, and suppose the minimal support ??1/6. The process is depicted in Figure 3, and the number represents each itemset?s generating order.

Fig.3. An example of the SET_BFS algorithm  Step 1: We starts with an empty set ?, then compute all items in the second level of the taxonomy ?, there are two items Y and Z, the Supp(Y)=1 and Supp(Z)=2/3. All of the two items are frequent, and be added into the second level of enumeration tree in Figure 3, with Z in the right side of Y. Otherwise, discard all infrequent items of them.

Step 2: After generating the itemsets of second level, we start to generate the third level?s itemsets.

The children of any itemsets are generated in two manners. Firstly, to each itemsets of second level, we generate all join-based child itemsets(based on subset- superset relationship) by joining those itemsets with all of their siblings that have higher orders, such as Y, we join Y with its sibling Z, and then we have YZ.

Optimization rules(descript in 3.2) are used to identify whether YZ is frequent or not. If YZ does not satisfy with all optimization rules, then we compute supp(YZ), if YZ is frequent, then add it into the enumeration tree as Y?s child, otherwise discard YZ.

Secondly, we generate Y?s tax-based child itemsets X and C (based on parent-child relationship), by using optimization rules to identify whether X and C is frequent or not. if these two itemsets do not satisfy with all the optimization rules, then compute supp(X) and supp(C), and add all the frequent itemsets into the enumeration tree as Y?s child, otherwise discard the infrequent itemsets. The children itemsets are added from left to right. Since the method is BFS, the next action is to deal with the same level of Z, we also do it join-based first and tax-based second, as a result, D and E are added as the children of Z.

Step 3: We recursively deal with all itemsets in the fourth level and so on, and finally we get a completed enumeration tree with all frequent itemsets.

3.2 Optimization rules  For the convenient to depict SET_BFS method, we choose appropriate minimal supports that make all candidate itemsets are frequent in Figure 3. But in real- life transaction database, there may have many infrequent itemsets. Based on the characteristic of     taxonomy and the generated frequent itemsets, we have following three optimization rules.

Observation 1 When generating any candidate k- itemset, all of its frequent (k-1)-itemsets have been generated. In figure 3, we can see, when generating CAB, the BFS method guarantees all of its frequent 2- itemsets CA, CB and AB have been generated in advance.

Optimization 1 To a k-candidate itemset, if there exists one infrequent (k-1) sub-itemset, then the k- candidate itemset is infrequent.

For example, in Figure 3, 3-candidate itemset ZCB have (3-1) sub-itemset {ZC, ZB, CB}, if one of them is infrequent, then ZCB infrequent.

Observation 2 When generating any candidate k- generalized itemset, all of its frequent (k-1)- generalized itemsets have been generated.

Optimization 2 To a k-candidate generalized itemset, If there exists one infrequent (k-1) sub- generalized itemset, then the k-candidate generalized itemset is infrequent.

In fact, optimization 2 is the extension of optimization 1 based on the taxonomy ?.

Observation 3 When generating any candidate k- generalized itemset, all of its frequent ancestor generalized itemsets have been generated.

In Figure 3, we can see, when generating generalized itemset XD, all of its ancestor generalized itemsets {YD, ZX} have been generated, and all of its |XD|-1 sub-generalized itemsets {X, D, Y, Z} have been generated.

Optimization 3 To a candidate k-generalized itemset, if there exists one infrequent ancestor k- generalized itemset, then this candidate k-generalized itemset is infrequent.

These three optimization rules have fully taken advantage of the generated frequent ancestor itemsets and the generated sub-frequent itemsets, which reduced many infrequent itemsets support counting, and the efficiency improved greatly.

4. Algorithms for mining generalized frequent itemset   Now we give our algorithm more detail, it includes SET_BFS, IsFrequent and COMPARE. SET_BFS is the main algorithm. IsFrequent algorithm is used to identify whether one itemset is frequent or not.

COMPARE algorithm can be used to identify whether one itemset is the ancestor of another itemset or not.

Algorithm 4.1 SET_BFS A Breadth-first search algorithm for mining generalized itemsets; Input: The original transaction database D(1); The minimal support ?minsup; Taxonomy ?;  Output: Frequent set-enumeration tree F; The k-frequent itemsets: LL(k) , ( k= 1, ?, |?| ); The explanation: D(2) is a vertical transaction database transformed from D(1); Q is a FIFO queue used to store the frequent nodes of enumeration tree F; N represents a node fetched from Q; B represents the current node?s siblings; C represents current node?s descendants in taxonomy ?.

Start: 1? Generate D(2) from D(1); 2? Create F?s root node ? ; 3? FOR (each C, C is one child of ? on ?) { 4?      IF (Support(C) ? ?minsup) THEN { 5?          ?.addchild(C); 6?          LL(k).put(C); 7?          Q.addlast(C); 8?      }//end IF 9?   }// end FOR 10? WHILE (!IsEmpty(Q)) { 11?       N = Q.getfirst(); 12? FOR (each B, B is one brother of N on ?) { 13?       U = N ?? B; 14?       IF (IsFrequent (U)) THEN { 15?           F.addchild(U); 16?           LL(k).put(U); 17?           Q.addlast(U); 18?        }//end IF 19?    }//end FOR 20?    FOR (each C, C is a child of N on ?) { 21?         IF (IsFrequent (C)) THEN { 22?             F.addchild(C); 23?             LL(k).put(C); 24?             Q.addlast(C); 25?         }//end IF 26?     }//end FOR 27? }//end WHILE Algorithm 4.2 IsFrequent(N) To identify whether itemset N is frequent or not Input: The candidate k-itemset (k ? 1); Output: If itemset N is frequent, then returns TRUE, otherwise returns FALSE; The explanation : M is any (k-1)-itemset of N; P is one element of LL(k-1)( (k-1)-frequent itemset); Start: 1? IF (k>1) { 2?     FOR (each M, M is a (k-1)-subset of N) { 3?          IF (!(M ? LL(k-1))) THEN {return  FALSE;} //Applying optimization 1; 4?     } //end FOR 5?    flag = FALSE; 6?   FOR (each M, M is a (k-1)-set of N) {     7?       Flag= FALSE; 8?       FOR(each P, P is a (k-1)-set from LL(k-1)) { 9?            IF (COMPARE(P,M)) THEN {flag =  TRUE; break;} // Applying optimization 2; 10?    }//end FOR 11?    IF (flag= FALSE) THEN break; 12? }//end FOR 13? IF (!flag) THEN {return FALSE;} 14? IF (Support(N) ? ?minsup) THEN {return  TRUE;} 15?   ELSE return FALSE; //if N is infrequent; 16? ELSE {return TRUE;} //If k=1, return TRUE; Algorithm 4.3 COMPARE(I2,I1) To identify whether I2 ?? I1 or not; Input: Taxonomy ?; Itemsets I1 and I2; flag (the result flag: TRUE or FALSE); Output: If I2 is I1?s ancestor, then the result is True, otherwise False; Start: 1? FOR i=1 to |I1|  { 2?     ancestors?I1?={I1.itemi}; 3?     WHILE (parent?I1.itemi?? root) { 4?         ancestors?I1?= ancestors?I1?? parent?  I1.itemi? 5?      }//end WHILE 6? }//end FOR 7? FOR j=1 to |I2|  { 8?     ancestors?I2?={I2.itemj}; 9?     WHILE (parent?I2.itemj?? root) { 10?        ancestors?I2?= ancestors?I2?? parent  ?I2.itemj?; 11?    }//end WHILE 12? }//end FOR 13? SORT(ancestors?I1?); 14? SORT(ancestors?I2?);  //Arrange by lexicographically; 15? flag=TRUE; 16? FOR k=1 to | ancestors?I2?|{ 17?    IF exist ancestors?I2?.itemk not in  ancestors?I1? THEN return FALSE; 18? }//end FOR  5. Performance study   To evaluate the efficiency of our algorithm, we deploy many experiments and compare the performance with the well-known and current generalized frequent itemsets mining methods. Among the well-known method, we choose CUMULATE [4].

Since the SET [2] is an improved method based on PRUTAX [3], we select SET algorithm as the recent  algorithm to compare. We finished the experiments on a HP DL380 G3 server with duo Xeon 2.8 GHZ CPU and 2GB main memory running Windows Server 2003.

We use JAVA language to implement all the algorithms. The databases DB1 and DB2 we used for the experiment are real-life financial transaction databases from a large commercial bank. The characteristics of two transaction databases are summarized in Figure 4.

Databases Number of Transactions Number of Items  Max Length  of items  Level of Taxonomy  Distribution of items  DB1 About 250K 165 8 5 Balanced  DB2 About 360K 165 10 5 Skewed Fig.4. The transaction databases for experiment  In Figure 4, the database DB2 is an item-skewed transaction database where the proportion of some items is very high, while the items in DB1 are item- balanced relatively. Our experiments work on these two transaction databases.

Fig. 5 By different minimum support on DB1   Fig. 6 By different transaction number on DB1  Group one-DB1 used We first examine the algorithms performance with respect to different minimum support thresholds 2%, 1%, 0.5%, 0.25% and 0.1%. To clarify the performance result, we use logarithmic coordinate for running time label. In Figure 5, the result shows that the efficiency of SET_BFS improved an order of magnitude and one time respectively compared with CUMULATE and the SET  without any loss of the frequent itemsets. When support equals to 0.1%, the running time of SET_BFS is only 3.58% of CUMULATE and 62.16% of SET. The curve of Figure 5 also shows, with the support descending, the     SET_BFS will have better performance than other two algorithms.

In Figure 6, we studied the performance with different transaction scale 50k, 100k, 150k, 200k and 250k, and the minimal support equals to 0.1%. The experiment result shows that SET_BFS outperforms other two algorithms greatly. When then transaction number is 150k, the running time of SET_BFS is only 3.44% of CUMULATE and 59.35% of SET. With the transaction database scale increasing, SET_BFS algorithm has more advantage. From the above experiments, we can see that the SET_BFS algorithm can easily extend to large-scale transaction database mining.

Fig. 7  By different minimum support on DB2   Fig. 8 By different transaction number on DB2  Group two-DB2 used. We test our SET_BFS algorithm with the same minimal support setting and similarly transaction number setting on DB2, which is item skewed. The curves of Figure 7 and Figure 8 show, when the minimal support equals to 0.1%, the running time of SET_BFS is only 8.37% of CUMULATE and 41.27% of SET. When the transaction number is 240k, the running time of SET_BFS is only 7.75% of CUMULATE and 43.38% of SET. That means SET_BFS algorithm still has great advantage than the  two algorithms with skewed item transaction database. At the same time, the experiment results told us that the efficiency of the three algorithms can be influenced a little by the items distribution, but the SET_BFS has less impact than other two algorithms.

6. Conclusions and future work   After analysis the limitation of the current method in mining generalize frequent itemsets, this paper proposed a new method call SET_BFS algorithms, which improved the mining efficiency of generalized frequent itemsets greatly. On one hand, this method leverages character of the taxonomy. On the other hand, it applies optimization rules to identify many infrequent itemsets instead of counting their support.

Comparing with the well-known Apriori-based algorithms and the latest algorithms, SET_BFS algorithm can outperform by improving an order of magnitude and one time respectively without any loss of the frequent itemsets.

As the efficient method, SET_BFS algorithm can be applied to other research areas with taxonomy such as maximal and closed generalized frequent itemsets mining, which will be our future work.

