Adaptive Intrusion Detection with Data Mining*+

Abstract  - A major constraint of an anomaly-based intrusion detection system (IDS) lies in its inability to adapt to the changes in normal user behavior patterns and to distinguish these changes from intrusive behavior.

To overcome these obstacles, the normal profile must be updated at regular intervals. The naive approach of ex- haustively recomputing the normal profile is often not viable and can incorporate patterns of intrusive behavior as normal. W e  address technical issues and present an adaptive data mining fmmework for  anomaly detection.

W e  employ a sliding window approach and use only the audit data inside that sliding window to update the pro- file. Instead of performing an exhaustive update, we use some heuristics to decide when to update. Experimental results using real network tmfic data (containing simu- lated intrusion attacks) demonstrate the effectiveness of the proposed framework.

Keywords: Anomaly detection, fuzzy association rules, sliding window, audit data.

1 Introduction Intrusion detection can be defined as identifying  unauthorized use, misuse, and abuse of computer sys- tems by both inside and outside intruders. There are many categories of network intrusions. Examples in- clude SMTP (SendMail) attacks, password guessing, IF' spoofing, buffer overflow attacks, multiscan attacks, d e nial of service (DOS) such as ping-of-death, SYN flood, etc. The goal of a network-based intrusion detection system (IDS) is to identify patterns of known intru- sions (misuse detection) or to differentiate anomalous network activity from normal network traffic (anomaly detection). Data mining methods have been used to build automatic anomaly detection systems that profile the normal system activities so that abnormal activi- ties can be detected by comparing the current activities with the profile (8, 9, 61.

*0-T803-T952-7/03/$17.00 F 2 0 0 3  IEEE.

IThis work was partially sponsored hy National Science Foun-  dation Grants CCR-0085749 and CCR-9988524 BS well BS Army Research Laboratory Grant DAAD 17-01-C-0011 and Office of Naval Research Grant N00014-01-1-0678.

Association rule mining [l] is a very popular data min- ing technique used to  extract multi-feature correlations from a database table. Lee and Stolfo IS] extended the basic association rule algorithms to  capture consistent behavior in program execution and user activities to form a normal profile. Subsequent system activities are analyzed to mine frequent patterns. This new pattern set is compared with the normal profile to compute devi- ations to generate alarms in case of intrusive behaviors.

Fuzzy logic was integrated with association rule mining to detect network intrusions in [9].

A major problem with such IDSs is that they can issue false alarms when there are modifications in the normal system behavior. The IDS must be capable of adapting to these changes and the normal profile must be updated at regular intervals. One straightforward approach is to generate a new normal profile with each set of new au- dit data. This approach is not computationally feasible and can cause the system to incorporate patterns of in- trusive behavior as normal. We discuss some technical issues that need to be addressed to  develop an adaptive IDS. Instead of using existing association rule update techniques [5,4] directly in our work, we have chosen to present a general framework for an adaptive data min- ing system that is appropriate for our domain. We have used this proposed framework to achieve adaptability within our existing IDS [9]. The adaptive IDS can adapt to  changing system environments or user behavior pat- terns. A collection of intrusion data was generated in the Department of Computer Science and Engineering, Mississippi State University over two months and this data has been used to evaluate the adaptive IDS.

2 Background and related work Association rule mining [l] is a very important data  mining technique. A typical example of an association rule mined from audit data can be f t p  + get[.4, ,I, which implies 40% (confidence) of the time when the user uses the f t p  command, the get command is also invoked and doing so constitutes 10% (support) of the commands issued by the user. The Apriori algorithm [Z] is one of the standard algorithms for association rule mining.

mailto:mahmood@cse.msstate.edu   Data mining methods have been applied to audit data in order to compute models that  can capture intrusive and non-intrusive behavior. Lee and Stolfo [7] utilized association rule mining and frequent episode mining to mine rules from system audit data to form a normal pro- file. Any subsequent system activities are analyzed to mine frequent patterns and the new pattern set is com- pared with the normal profile. Similarity functions are used to evaluate deviations and any significant deviation would signal abnormal activities.

Partitioning quantitative audit data into intervals may cause sharp boundary problems during mining.

Two adjacent data values may he mined as two differ- ent types (normal/abuormal) for having different sup- port values. Consequently, an intrusive pattern with a small variance may remain undetected. To overcome this problem, fuzzy data mining was employed for intru- sion detection in (91 where quantitative features are cate- gorized.into categories having fuzzy membership values.

Feature selection plays a critical role in applying data mining techniques to audit data. A particular set of fea- tures might have a relationship only with the signatures of a particular intrusion type and not others. Rules con- taining irrelevant features may be misleading to some extent. A minimized set of features is also required to reduce the computational requirements for real-time intrusion detection. Some important feature selection research in intrusion detection has involved the use of empirical knowledge [8],  genetic algorithms [3], and sta- tistical and rule-based methods [lo].

Association rules discovered from a transaction database may become invalid if the underlying data changes over time. The Fast Update (FUP) [4] alge rit,hm is an incremental algorithm that uses the frame- work of Apriori and can maintain association rules when transactions.are added to the database. It updates the support counts of the original large itemsets in t.he mod- ified database and removes itemsets whose support fall below the minimum threshold. On the other hand, it creates new candidate itemsets and itemsets that gain enough support are added to the original large itemsets.

A more general technique called FUP2 was described in [5] that can also handle deletions and modifications of transactions in the database. For deletions, FUPZ works as a complementary algorithm of FUP. The general case of modification is treated as insertions followed by dele- tions. The incremental update problem has also been studied in [ll], [12], and [13] .~  3 Adaptive intrusion detection A major shortcoming of current IDSs that employ  data mining methods is that they can generate a series of false alarms in'cases of noticeable systems environ- ment modifications. To overcome this limitation, an IDS must be capable of adapting to the changing con- ditions typical of an intrusion detection environment.

For example, in an academic environment, the behavior patterns at the beginning of a semester may he differ- ent from the behavior patterns at the middle/end of the semester. If the system builds its profile based on the audit data gathered during the early days of the semester, then the system may generate a series of false alarms at the later stages of the semester.

System security administrators can tune the IDS hy adjusting the normal profile, but it may require frequent human intervention. The main purpose of using data mining techniques in computer intrusion detection is to automate the detection process. Since normal system activities may change because of modifications to work practices, it is important that an IDS should have auto- matic adaptability to new conditions. Such adaptability can be achieved by employing incremental mining tech- niques that use real time data (log of audit records) to continually update the profile.

The naive approach of regenerating the normal, pro- file with the new audit data is not computationally fea- sible. Any deviation of the current usage profile from the normal profile can either.represeiit an intrusion or a change in behavior. In case of a change in system behavior, the base profile must be updated in order to avoid false positive alarms in the future. If the system tries to make a change to  the base profile every time it sees a deviation, there is a potential danger of incorpo- rating abnormal activities into the profile. Therefore, the IDS must be able to  adapt to the normal changes while still recognizing abnormal activities. If both in- trusive behavior and changes in normal behavior occur during a particular time interval, the problem becomes more complicated. There are also additional issues that need to be addressed. Theys tem should adapt to rapid changes as well as gradual changes in system behavior.

Selecting the time interval at which the update should take place is also an important issue. If the interval is too long, the system may miss some rapid changes or short-term attacks. If the interval is too small, the system may miss some long-term changes.

We consider two problems as the major issues in de- veloping an adaptive IDS. One is to select the time when the update should be made. The other is to select a mechanism to update the normal profile. To tackle the first issue, we can continually measure the similarity be- tween each day's activity and the profile and utilize this similarity trace. If the similarity stays above a threshold.

level and an abrupt change is not encountered, then the behavioral pattern is taken to  he a reflection of normal activities and the profile needs to be updated with the current data. If the similarity goes below the thresh- old level or an abrupt negative change is encountered, then the behavioral pattern is taken to be a reflection of some kind of anomalous acti\r-ities and the profile does not need to be updated. This is illustrated in Figure 1. The activities before point t l  are considered to be    normal and the profile does not need any update. The activities between tl and ta represent some abnormal behavior and the profile does not need to be updated.

Again, between ts  and til, there is a sharp change in sim- ilarity that represents abnormal behavior and no update is made. Though the similarity between t5  and t 6  r e mains positive, because of sharp negative change we do not need to update the profile assuming some abnor- mality. We are assuming that behavioral change occurs gradually, not abruptly. Although this approach will not be effective against stealth attacks (a very slow, gradual attack), it is likely to be effective against most attacks.

----!

Figure 1: Change of similarity with time  3.1 The architecture of an adaptive IDS In this section, we present an architecture for the  adaptive maintenance of the profile rule set that can overcome the need for recomputation of the rules with- out sacrificing the detection capabilities. The profile rule set can be updated by adding new rules, deleting old rules, or by modifying existing rules (changing sup- port and confidence). This flexible framework exploits the rules generated during the earlier stages.

It is not computationally feasible to archive audit data for a long time. Therefore, we employ an overlapping sliding window approach to update the base profile. The central idea behind the sliding window approach is the concept of a time window, an interval of time outside of which audit records are assumed to be too old to characterize the current behavior. The time window therefore acts to  filter out outdated audit data and to build a profile based on only recent data that reflects the recent system activities.

We maintain two itemsets, large itemsets and near- large itemsets. As time goes on, a large itemset may start losing its support and a near-large itemset may start gaining support. We discard some large itemsets (losing support in subsequent time windows) in the pro- cess and include some new ones. Though we maintain both the large and near-large itemsets, we only use the rules derived from the large itemsets to compute the similarity. This facilitates the updating process in case of gradual behavior changes.

~   Figure 2: Architecture of an adaptive intrusion detec- tion system  Figure 2 presents an architecture for our framework.

The process begins with an initial set of audit data.

Genetic algorithms are used off-line for feature selection and tuning the fuzzy membership function parameters.

Then fuzzy association mining is applied to mine rules into a normal profile. During each time window, the audit data in the incremental part is mined and com- pared with the profile rule set. If there is a sharp nega- tive change in similarity or the similarity goes below a threshold, abnormal behavior is signaled and the profile is not updated. If there is a gradual negative change or positive change in the similarity with the similarity staying above the threshold, the profile will be updated with the audit data in the current time window.

3.2 Updating the profile It is imperative that we select a technique to update  the profile rule set that minimizes the amount of recom- putation. The efficiency of previously reported methods [4, 5 ,  11, 12,  131 relies heavily on the separation of the added transactions and deleted transactions. That re- quires database recovery and maintenance of database logs. Retention of these logs is not feasible for intru- sion detection. Instead of using any of these techniques directly in our adaptive framework, we have chosen to present a generic framework for an adaptive data mining system that is appropriate for our domain.

3.2.1 Candidate itemsets generation We maintain two itemsets in our framew-ork. In ad-  dition to the large itemsets L = { L 1 , L z , .  . . ,L,}, we also define near-large itemsets N = {NI, N z : .  . . , N,}.

The near-large itemsets are itemsets for which the s u p ports are less than a higher threshold but greater than a lower threshold. Let Smi, and .Ski, be two s u p port thresholds where Smi, > Skin. Then, formally, Li = { X i l s x ,  2 %in} ,  NI = {X~lsx, < &in},  and for i > 2, N, = {XilS,,,,n > sx, 2 Ski,}.

With this changed notion, the candidate itemsets generation becomes slightly different from Apriori's ap- proach. Instead of using only Lk-l (as in Apriori), we use Lk-1 U Nk-1  to generate the candidates Ck for the next iteration using Ch = CL-, *CL_, = { X u Y l X ,  Y E CL-l, / X  n YI = k - 2}, where CL-, = Lk-1 U N k - 1 .

3.2.2 Prob lem definition  In Figure 3, let [ t o ,  t l ,  t?, . . . , tn-l ,tn,  t,+i, t,+z,. . .] be a sequence of times where each interval [ti..t,+l] has equal length. Let any sequence [ti, t , + l ,  ti+?, . . . , ti+,-l,ti+,] form a sliding t i m e window of n intervals. Let D; be the set of database transactions during the interval (ti-l..t,]. Then at any instance of time ti, the active window consists of a database 'Di represented by U;ziDi-k .  When this active t,ime window progresses to the next interval, the active database goes through an update, a set of transactions is added to the active database and a set of transactions is deleted. Formally, when the active window reaches t.he instance t i ,  D; is added and D;-n is deleted. We can write 'Di = ( ' D - 1  -D,-,)UD,. The set of unchanged transactions that are contained in both the previous and current active window database canbedenoted by'Di-lU'DD; ='Di-l-Di-, ='Di-Di .

Let &, and Sx, be the support count of an itemset X in database Dj and active window database 'D; respectively. Then, 8.y. = S.y;-, - Sx ,_,, + Sx,.

lo 4 '2 . % 1.1 1" I"+, I"+*  ~ .I .

I t-  D, 4 ' 4 ' 0"  4------- Current Window at time f,,,2 ------* Figure 3 Sliding Window for Incremental Databases  Let L j  and N3 be the set of large itemsets and near- large itemsets respectively in database Dj.  Let C, and Ni be the set of large itemsets and near-large item- sets respectively in the active window database 'D;. Let Lkj and Nk. be the large k-itemsets and near-large k- itemsets respectively in database Dj.  Let Ck,, Nk<, and Cki be the large k-itemsets, near-large k-itemsets, and candidate k-itemsets respectively in the active window database 'D,. The update problem is then t,o find the large itemsets Ci at each instance of time ti and also to calculate Sx. for each X in Ci.

3.2.3 The update process The update mechanism is performed in the Apriori  framework. The process starts by aggregating the large itemsets from 'D,. Then at each subsequent interval, the updated database from the active window is considered to update the large itemsets.

At time ti, in each iteration k, a candidate k-itemset Ck, is generated from Ck, U Nk, as described in Section 3.2.1. But the difference is in generating the large k- itemsets. Ck, is generated using Ck,-l generated in the previous window. Let X be a candidate k-itemset in the current active window database. There can be two possibilities with X .  X can be large in the previous active window database i.e., X E Ck,_, or X is not large in the previous active window database i.e., X  If X E Cki->, some large itemsets can lose the mini- mum support. In this case, the unchanged part of the active window database -Di-n) does not need to be scanned and there can be four possibilities. Depend- ing on one of these possibilities, we can decide which database needs to  be scanned.

If X is in both the incremental and outdated databases, i.e., X E Li nLi-,, then neither the in- cremental database Di nor t.he outdated database Di-,'needs to be scanned.

If X is in the outdated database but not in the incremental database i.e., X E Li-n - Li, then the incremental database Di needs t o  be scanned but the outdated database Di-, need not be scanned.

If X is in the incremental database but not in the outdated database, i.e., X E Li - Li-,, then the outdated database Di-, needs to  be scanned but the incremental database D, need not be scanned.

If X is neither in the incremental database nor in the outdated database, i.e., X 6 Li U Li-,,, then both the incremental database Di and the outdated database Di-, need to be scanned.

If X Ck,-,, some new itemsets can become large.

But this is only possible if X is large in D; or not large in Di-,. Further, to reduce computations, we make an assumption that if an itemset is not at least near-large in the previous active window database, then it can not be large in the new active window database even if it is large in Di or not large in Di-,.

For each X from the above cases, we calculate Sx. = S X - ~  - SX,_, + Sxi. If Sx, 2 I'D;l x &,in, then X is added to  Cki. Otherwise if Sx, 2 I'Dil x SAin, then X is added to Nki. So depending on these two situations, we throw away some old large itemsets and include some new ones. At each iteration, the next thing to  do is to generate the complete near-large itemsets. Some near large itemsets are already generated along with the large itemsets. For the others, we calculate eh, - Ck, and generate Nk as defined in Section 3.2.1.

4 Implementation and results We used a set of network audit data to test the effec-  tiveness of our system. Real network data was collected from the departmental server. The data was sanitized and preprocessed to extract meaningful and useful in- formation. We then used a genetic algorithm module to select relevant features. Finally we implemented our system and tested it with the preprocessed audit data.

4.1 Data collection The network traffic data was collected over a 10-week  period in the summer of 2000 starting from 07/10/2000 to  09/15/2000 using the tcpdump utility. The server (disney) used for data collection is the general mail and web server of the Computer Science Department a t  Mis- sissippi State University. This particular time of the year was selected because of the changing network ac- tivities that would be likely to occur in the audit data.

There are no classes for three weeks in August and there is a long weekend for Labor Day. The first week?s data contains an audit of network traffic without any simu- lated attack activity. This period began the week af- ter classes began for the second summer session. The assumption was that the network activity would settle down after one week into the semester. Data was col- lected for two hours each day from 1O:OO AM to 1200 PM. The second and third weeks? data contains audit data with simulated portscan attacks. Table 1 gives the description of the generated attacks.

Table 1: Descriptions of simulated portscan attacks  07/19/2000 (Wed) 07/20/2000 (Thu) 07/28/2000 (Ri)  4.2 Data preprocessing Once the data were collected, the next step was to  preprocess the binary tcpdump data into meaningful audit data. Though we collected data for all seven days of a week, we used only the weekdays? data in our experiments. A sanitizing program, downloaded from http://ita.ee.lbl.gov/html/contrib/sanitize.html, was modified to extract the following timestamped con- nection level information: source and destination IPS, source and destination port numbers, Flags (SYN, FIN, RESET, PUSH) and size of transferred data. Then the timestamped data was partitioned into overlapping in- tervals to extract meaningful features. An interval size of 4 seconds was selected with overlaps of 2 seconds. The features that were extracted from each interval are the  number of different source and destination IPS, num- ber of different source and destination ports, number of SYN. FIN, RESET, and PUSH flags. and amount of transferred data. Genetic algorithms were then used to select the appropriate feature subset and to optimize the associated fuzzy membership functions. The data from 07/11/2000 (Tuesday), 07/18/2000 (Tuesday), and 08/01/2000 (Tuesday) were used as the baseline, nor- mal, and abnormal data, respectively. The features that were selected are the number of different source IPS, number of different source ports, number of SYN flags, number of PUSH flags, and amount of transferred data.

4.3 Implementation of the adaptive IDS The preprocessed data (only with the selected fea-  tures) from the first week were used to build the base profile using a modified version of our earlier system 191.

Three different fuzzy functions were used to calculate the membership values: Z, II. and S functions, respec- tively for the LOW, MEDIUM, and HIGH categories.

We used 0.2 and 0.8 as the threshold values for support and confidence respectively.

After the initial profile is built, the system uses a sliding window over new data. Each day?s data is mined to compute the similarity with the base profile. We modified the non-commutative similarity function used in our previous work 191 to yield the following similarity function for calculating the similarity between two rules:  where,  Then the following aggregate function is used to com- pute the similarity between two rulesets RSI and RS2:  where.

and I RS1 1 and I RSz 1 are the total number of rules in RS1 and RS2, respectively.

We measure the similarity between a particular day?s activity and the base profile. If there is a sharp negative change (more than 30%) in similarity or the similarity goes below a threshold, audit activity for that day is flagged as having anomalous activity. Consequently we skip that day and do not include that day in the sliding window. If there is a gradual negative change in the sim- ilarity with the similarity staying above the threshold, we include that day in the sliding window and update   http://ita.ee.lbl.gov/html/contrib/sanitize.html   the base profile according to the updating framework presented in section 3.2. We do the same if there is a positive change in similarity and the similarity stays above the threshold.

For example, let d&+l . . . dk+n form a sliding win- dow of n days. Let the similarity between the base profile and the rules mined from &+,,+I be sim and the similarity on the previous occasion be si?. If sim 2 sim? t 0.7 and sim > threshold, we change the sliding window to  dlc+ldk+~.  . .&+,+I and update the base profile. We do the same if sim 2 sin? and sim ?> threshold. If sim < si? * 0.7 or sim < threshold, we flag out dk+n+l and the sliding window remains . . . da+n. If the activity from the next day dk+n+2 is found to be normal, then the we change the sliding window to  dk+ldk+2.. . dk+ndk+n+2,  4.4 Experiments Several experiments were performed with the preprc-  cessed audit data. The first experiment was conducted to evaluate the effectiveness of the adaptive system. The thin line in Figure 4 shows the daily similarity values produced by the adaptive system with a sliding window size of 5 days and? a similarity threshold of 0.5. Abnor- mal behavior is indicated by a low similarity value  Figure 4: Change of similarity values with our adaptive system and with an exhaustive update  Intrusion attacks occurred on day #S (07/19/00), day #9 (07/20/00), day #15 (07/28/00), and day #17 (OS/Ol/OO) as indicated by the dotted vertical lines in Figure 4. The intrusions on days #S and #17 were de- tected, but intrusions on days #9 and #15 were not. At- tacks on days #9 and #15 were launched less frequently (Table 1) to see whether these small attacks can be de- tected or not. There were three additional days where there were sharp negative changes in the similarity. One was on day #Z0 (08/04/00). That was the day for the final exam of the summer semester. One was on day #31 (08/21/00). That was the day when the classes started for the fall semester. The last one was on day #41 (09/04/00). That was the Labor Day. The sharp changes in similarity in those three days did indicate anomalous behavior although those were not attacks.

For example, it is natural that there would be higher network traffic on the first Monday of the semester than the previous Friday. The abnormal behavior on day #6 (07/17/00) could not however be explained or traced back to  a specific cause.

The next experiment was conducted to  observe the effects of exhaustively updating the profile without re- gard to  the degree and direction of changes using the same sliding window size and similarity threshold as in the first experiment. The thick line in Figure 4 shows the similarity values produced hy this experiment. If we compare both lines in Figure 4, it  is evident that if we incorporate each day?s activity in the profile (even if it  is abnormal), there are an increased number of false alarms. For example, the activities on days #11 (07/24/00), #22 (OS/OS/OO) ,  and #44 (09/07/00) were flagged as abnormal even though there were no ab- normal behavior (to the best of our knowledge). On the other hand, the abnormal behavior on day #31 (08/21/00) could not he detected.

The next experiment was conducted to observe the effects of not updating the profile (the initial profile is used continuously). The thick line in Figure 5 shows the similarity values produced by this experiment. If we compare both the lines in Figure 5 ,  i t  is evident that if we do not employ an adaptive system, the system accu- racy will fall. For example, our adaptive approach could detect the abnormal behavior on day #17 (OS/Ol/OO) and day #31 (08/21/00). However, if the system is not allowed to  adapt, these intrusions are not detected.

i  Figure 5:  Change of similarity values with our adaptive system and with no update  The next experiment was conducted to  observe the ef- fects of different sliding window lengths. Figure 6 shows the daily similarity values produced by the adaptive sys- tem with sliding window lengths of 5 ,  4, and 3 days. A sliding window of 4 days or 3 days could not detect the abnormal behavior on day #31 (OS/Zl/OO): Moreover, the similarity values on average were lower with smaller window length. The observations led us to a conclusion that for this data, a sliding window of 5 days is more suitable than a sliding window with either 3 or 4 days.

- m y  mcdor ... .. . lday mcdow ->day mndol  Figure 6: Change of similarity for the adaptive system with different sliding window lengths  5 Conclusion We presented an adaptive framework for an intru-  sion detection system that uses fuzzy association rule mining. We introduced technical issues that need to he addressed to develop an adaptive intrusion detection system. The framework was supported by some encour- aging experimental results. We showed that false alarms are issued if the profile is not changed at  all or is always changed regardless of the traffic pattern. There was one occasion when our new system issued a false positive that we could not explain. One drawback of the data collection process was that we assumed that the first week?s data (that was used to build the initial profile) represented normal activities only. There was no way knowing if abnormal behavior had occurred. If it did, it was incorporated as a part of the normal behavior.

There are some issues that we plan to investigate in the future. We worked with only a single profile. In an actual working environment, it would he necessary to develop different profiles for different times of the day or different periods of the week (e.g. weekends). For example, we can have two different profiles for a sin- gle day, one for daytime hours, one for nighttime hours.

Again, we have not addressed the problem where a time window contains both intrusive data and non-intrusive data (representing a behavioral change). We need to perform some drill-down operations to individual rules to distinguish between intrusive and non-intrusive pat- terns. There is also another area in which adaptation could be applied. The system performance is sensitive to the fuzzy parameter values. The system in its cur- rent status, works with a static set of fuzzy membership function parameters determined at the Keginning. But these values could also be tuned dynamically.

