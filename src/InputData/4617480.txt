Finding Causes of Software Failure Using Ridge Regression   and Association Rule Generation Methods

Abstract   An important challenge in finding latent errors in software is to find predicates which have the most effect on program failure. Since predicates have mutual effects on each other, it is not a good solution to analyze them in isolation, without considering the simultaneous effects of other predicates on failure. The aim is to detect those predicates which are best bug predictors and meanwhile have the least effects among themselves. To achieve this, Recursive Ridge regression method has been applied.

In order to determine the main causes of program failure, the association rule generation is used to detect those predicates which are most often observed with bug predictors in faulty executions. Based on the detected predicates, the faulty paths in control flow graph are introduced to the debugger.

Our empirical results on two well-known test suites, EXIF and Siemens imply that the proposed approach could detect main causes of program failure with more accuracy.

1. Introduction   It is a difficult and time consuming task to localize latent semantic bugs within a program code. To resolve the difficulty automatic debugging methods have been introduced [1], [2]. In a dynamic approach, a program behavior is determined by analyzing the value of predicates, appearing in the program code, in several executions of the program. Since bugs may appear at any time in a program execution, statistical methods can be best applied to analyze the values of the program predicates and construct a model of its behavior. Bugs are most often nondeterministic, unpredictable and may appear at any time in a program execution. The behavior of an erroneous program is unpredictable and uncertain. Therefore, when modeling the run time behavior of a program suspicious to error, uncertainty and randomness in the program state should be considered.

Statistical debugging approaches tend to improve software quality by collecting information about the  program behavior and analyze the collected information to identify the misbehaviors that are highly predictive of subsequent program failure. To collect such information, extra code is inserted before each predicate within the program code. This process is called instrumentation [2]. During the program execution, the number of times each predicate is observed to be true or false is counted.

A major step in a program bug localization process is to find those predicates that have the highest impact on the program failure and are the best bug predictors.

Since there might be too many predicates in a program, it would be beneficial to employ feature selection algorithms for detecting predicates with relatively higher impacts on the program failure [3]. These kinds of predicates are addressed as bug predictors. In order to localize bug predictors in a program, the program is executed many times. In each execution of the program the effect of the predicates on the program results is analyzed to detect effective bug predictors. The effect of predicates on the program results can be analyzed by constructing a linear combination of the predicates, weighted by different coefficients.

The problem is how to estimate the best answer for the weight of the predictor in the linear combination.

To achieve this, a logistic regression method [13] is conventionally applied [4], [5]. A major difficulty with applying a na?ve regression method is that the predicates have to be linearly independent. On the other hand within a program the predicates may be dependent on each other. Therefore, it is observed that na?ve regression methods are not applicable, in this context [6]. To resolve the difficulty Ridge regression method, considering the predicates dependencies, has been applied [7].

Ridge regression considers simultaneous effects of predicates on the program results. This is highly applicable when there are multiple bugs in the program.  In Ridge regression method to analyze the effect of a predicate on the program results the predicate variable is varied while the others remain constant. In this way, independent predicates that are the best candidates for bug prediction are found. An association rule analysis [8] is then applied to find those predicates which are most often observed   DOI 10.1109/SNPD.2008.133    DOI 10.1109/SNPD.2008.133     together with each of these bug predictors in the program failures and the execution of each of these predictors, rather than the first and the last one, leads to the execution of another one in most of the faulty executions of the program. Finally to determine the faulty paths, the program control flow graph is searched for the paths connecting the associated predicates. Since these paths most often lead to the faulty executions of the program, they most probably include the cause and effect of the failure.

The remaining parts of this paper are organized as follows. In section two the previous works which have been done in this context are presented. In section three we describe our proposed approach. Empirical results in two case studies are shown in section four. Finally, conclusion and future works are presented in section five.

2. Related Work   Behavioral modeling is a key to software bug localization. A program behavior can be modeled through analyzing its state in different runs. In each successful and unsuccessful run of the program, information indicating the program status is collected.

The collected information is applied to construct a statistical model of the program behavior, in successful and un-successful runs [2][4][9]. The model may be used as a mean for localizing bugs in the program.

There has been an increasing interest in statistical debugging techniques over the past few years [1], [2], [3]. These techniques apply statistical methods to identify those program predicates that may be the root causes of the program failures [9]. To achieve this, ranking models have been introduced. In an approach presented in [6], [10] predicates are ranked in the order of their effects on the program faults. However, due to ignoring the false value of predicates, the ranks are not determined appropriately. To resolve the difficulty, both the true and false values of the predicates observed in correct and incorrect executions of the program are applied to construct the ranking model [2].

However, a major difficulty with this approach is that it considers predicates in isolation. In an approach presented in [1], to analyze the combinational effect of predicates on the program failures all the statically dependent predicates are combined. However, there may be statically independent predicates, simultaneously, effecting the program failure.

Independent predicates are considered in an approach presented in [3]. In this approach predicates are clustered based on the similarity on their value in different executions of the program, and then all the predicates appearing in a same cluster with a bug  predictor are considered as predicates in faulty paths.

However, the similarity of the values of a set of predictors to a bug predictor is not an acceptable reason for selecting them as the bug causes.

When finding the causes of the bugs within a program, the simultaneous effect of the predicates on the program failure has to be considered. Logistic regression method has been used to isolate the causes of bugs causing the program failure [4], [5]. However, a major difficulty is that Logistic regression cannot be applicable when there are multiple correlated bugs [6].

The performance of this method declines significantly when there is strong multicollinearity amongst the program predicates. The important issue is to consider the effect of the predicates on each other and on the success and failure of the program, at run time. To achieve this, in this paper a new approach based on recursive ridge regression and association rule generation is proposed. In this new approach:  1. Ridge regression method, described in section 3.1, is applied to analyze the simultaneous effect of predicates on each other and on the program results  2. Applying an association rule generation method, described in section 3.2, to select those predicates which are in the same faulty path as the bug predictors detected when applying recursive Ridge regression method   3. The proposed approach   The main structure of our proposed approach is shown in Figure 1. The approach has three main phases: Bug predictor selection, associated predicate detection and faulty paths construction. These phases are described in detail in the following section.

3.1. Bug predictor selection   The aim is to select the most effective predicates, amongst highly related predicates, as bug predictors.

But important issue here is that many predicates could be strongly correlated to program failures; however, debuggers prefer to focus on a small subset of predicates which dominates the program results before conducting in-depth analysis and expensive experiments with a larger set of predicates. Automated discovery of this small subset (feature selection), therefore, is highly desirable [12]. In order to find this small subset, a classifier should be able to select features that are both relevant and NOT redundant.

Feature selection using filtering methods such as correlation coefficient ranking is obviously not the best     choice; because they score the importance of features independently, ignoring the correlations among them for feature selection [21].

because they score the importance of features  independently, ignoring the correlations among them for feature selection [21]. We use a Ridge regression classifier to generate scores for features in the selection process. Ridge regression classifier tends to penalize redundant features. This may be the reason that recursive ridge regression is more effective other than statistical classifiers, in selecting predicates. Our experiments imply that, given a small subset of predicates, most other relevant predicates are redundant in the sense of predicting program failure. In most of cases the nested predicates have multicollinearity with each other. The existence of multicolinrearity is not limited only to these nested branches. Our empirical studies have shown the existence of multicollinearity between predicates that have not any control or data dependency.

The recursive procedure for selecting bug predictors is shown in algorithm 1 in Figure 2.

3.1.1. Analysis of Ridge Regression  The training data consists of ? pairs of?????????? ??,?????????? ??,?,?????????? ?, where ???????? ? ????	 ? 	 ???? represents the values of the ? predicates in the ?Th execution, and ? ? ? ???	?? is the class label that means program failure or passing. We use vector ?? ? ???	 ? 	 ??? to represent the parameters of the  linear classifier. Term weights in ridge regression are determined by the minimization of its loss function,   Algorithm 1. Recursive procedure for bug predictors Selection  1. Let ? be the initial number of predicates and ? be the number of bug predictors we want to get.

2. While (? ? ?)  a. Train the classifier and get predicates weights ?? b. Delete the predicate with the smallest weight in absolute value and set????  ?? !.

(In our evaluations, we choose t=8)  Figure2. The algorithm shows recursive procedure for selecting bug predictors.

defined as:  "## ?$%? ? ?????????& ? '    ?(? )*??*? ?  + ?? ? ? + ??,?,??,(? ? '?(? ) + ?,??,(?            (1)   To minimize "##  we need to set its partial derivative with respect to each term weight ?-to zero, which yields: + ??- ??? ? ? + ??,?,?,(??(? ? ? ?)?-             (2)   Thus  ?- ? + %./01/&2?+ + ./0./343 5/6783675/67  9                       (3) The weight of the :th feature (predicate) can be  computed as ?q in equation 2. Now focusing on the second term in the numerator of the above formula.

Notice + ??-??,?(?  is the dot-product of two ?feature vectors?, reflecting the similarity between predicates ; and : in the ? executions, which can be replaced by token?<???;= :?, and that + ??-??,?,?(? ? <???;= :??, reflects how much the correlation and the weight of predicate ; jointly deduct the weight of predicate?:. To be clearer, we can write the above formula as  ?- ? + %./01/&2?+ >???,=-?43 83675/67 9                     (4)  With the second term, however, the redundant predicates would be penalized and elimination of predicates during the recursive process has the effect of boosting the remaining predicates that are correlated to the eliminated ones. In other words, the iterative process has the effect of boosting the weights for relatively non-redundant predicates in the remaining set [11].

Pr og  ra m  M   In st  ru m  en ta  tio n  Figure 1. An overview of the proposed approach  A ss  oc ia  te d   pr  ed ic  at es    Ridge regression  Associated predicate detection  Faulty paths construction  Apriori Algorithm  B ug   pr  ed ic  to rs    Bug Predictor Selection   Pr ed  ic at  es in  fo rm  at io  n  Control flow graph     3.2. Associated predicate detection   The aim of association rule generation is to find interesting relationships among different items [8]. In our application, the items are the program predicates and the goal is to find predicates that are most often observed with effective bug predictors (i.e. detected in previous phase) in faulty executions. To achieve this, Let P= {p1, p2,?, pd} be the set of all predicates and F= {f1, f2,?, fN} be the set of all faulty paths which include predicates. For simplicity, a binary representation has been used, as shown in Table 1, where each row represents a faulty path and each column corresponds to a predicate. Each predicate is represented as a binary variable. Based on its presence or absence in a faulty path its value would be ?1? or ?0? respectively.

An association rule is an implication expression of the form X ? Y , where X and Y are disjoint sets of predicates, i.e., X?Y = ?. The strength of an association rule can be measured according to the support and confidence metrics which are defind as follows:  Table 1. a binary representation of predicates in faulty paths  Path ID P1 P2 ..... Pd 1 1 0 ... 1 2 0 1 ... 0 ... ... ... ... 0 N 0 1 ... 1   Where N is the total number of paths and @?A? called  support count of set d is the number of faulty paths which contain the subset d (i.e. d is a set of predicates).

Support measure reflects the significance of a rule and Confidence measure reflects how reliable the prediction is made by the rule. For a given association rule X ? Y , the higher is the confidence, the more likely it is for Y to be present in paths that contain X.

A path, which is a collection of one or more predicates, is the fundamental unit of association rule.

If a path contains k predicates, it is called a k-path. The association rule analysis can be stated formally in our application as follows:  Given a set of faulty paths T, find all rules having support ? minsup  and confidence ? minconf, where minsup and minconf are the respective minimum support and minimum confidence thresholds.

Thus, a common strategy adopted by many association rule mining algorithms is to decompose the association rule mining problem into two major subtasks:  1. Generating Frequent set of predicates. Find all sets of predicates that satisfy the minsup threshold. These sets are called frequent sets of predicates. All these sets should contain at least on bug predictor.

2. Rule Generation. Extract high confidence association rules from the frequent sets of predicates found in the previous step. These rules are called strong rules. The rules with more bug predictors have more chance to be selected in this stage.

Since performing these subtasks is computationally expensive (i.e they have exponential complexity) the Apriori principle and Hash trees [20] are applied in order to simplify the process.

After detecting the most often observed predicates with bug predictors in faulty executions, the faulty paths in control flow graph which connect those predicates are shown to the debugger in order to inform him about the main causes of bugs (i.e. the third phase) [3].

4. Experiments   In this section evaluation result of the proposed method on two case studies, are presented. Our aim in this section is to show how ridge regression could detect multiple bugs in two test suites, EXIF and Siemens simultaneously. We also describe how association rule analysis may help the debugger to find main causes of program failure by inspecting less amount of program code.

4.1. Evaluation setup   The evaluation of the proposed method has been done on Siemens and EXIF test suites. We get Siemens test cases from Software Artifact Infrastructure Repository (SIR) [14],[15] and EXIF program is provided by Ben Liblit [16]. The instrumentation framework is based on CBI infrastructure [9].

In order to experiment with ridge regression, SPSS tool [17] have been employed. For association rule generation based on Apriori algorithm we used Rapid Miner [18]. The experiments were conducted on a 2.81 GHz Pentium(R)-4PC with 1.6G Ram running Linux RedHat 9 with gcc 3.3.3.

4.2. EXIF Case study   The first evaluation has been done on EXIF 0.6.9 test suite. EXIF is a program for image processing.

There are three potential bugs in this program that  Support, s(X?Y)=B?CDE?F                       (5)   confidence, c(X?Y)=B?CDE?B?C?                  (6)      make it to crash. For evaluating our proposed method in finding 3 bugs, we compared our results with Liblit reports [9]. The results show that the proposed method could localize all these three bugs in the program that have been reported before. We use 1523 runs including 1416 successful and 107 failing runs. During 1523 executions of EXIF, by employing recursive ridge regression method for performing feature selection, a number of predicates are selected as bug predictors.

After ranking the predicates based on their coefficients in ridge linear combination, the first three predicates are:  1) strlen (val)==NULL in exif_entry_get_value() function  2) sizeof(JPEGSection)*(data->count-2) <0 in jpeg_data_set_exif_data() function  3) (data->ifd[4])->count is FALSE in exif_data_save_data_content() function    Table 2. The third bug predictor and top 2 associated predicates that show the casue of the bug  in EXIF   It is shown that the first and second predicates  directly show the main cause of program crash, but the third one is not the main cause of failure and instead of that its high ranked associated predicate  is the main reason for the fault. This reveals the importance of using associated predicate detection phase in finding the main causes of program failure. As an illustration we describe how the third bug of EXIF has been detected.

Manipulating a thumbnail in the Canon image causes crash in the software. The predicate o + s > buf_size, is ranked as the third bug predicator in the feature selection process. When this condition is true, the program neglects to allocate a chunk of memory, which crashes the program in the next stage. The code of exif_mnote_data_canon_load  is shown in figure 3.

Notice that whenever the predicate o + s > buf_size is true, n->entries[i].data is not malloced. If the condition o + s > buf_size  is true in Figure 3.(b), then the memory allocation to the pointer n->entries[i].data in Figure 3.(b) would be skipped. The program crashes  when the rest of code reads from n->entries[i].data without checking if the pointer is valid. The code segment in Figure 3.(a) is the location where the program reads from n->entries[i].data which causes a software crash.

(a)                                                  (b) Figure 3. The third cause of failure in a code segment of EXIF  As shown in Table 2, "(data->ifd[4])->count is FALSE" predicate is detected as a bug predictor but this predicate is not the main root of bug. The main root is "o + s > buf_size is TRUE" predicate that is detected as a ranked one associated predicate to bug predictor in associate predicate detection phase.

4.3 Siemens case study  Siemens test suite contains seven programs. For each program, the Siemens suite provides its test cases and several faulty versions with manually injected faults.

Each faulty version of the program used in our experiments has exactly one fault injected [19]. Our experiments on Siemens case study reveals that despite most of bugs could be detected directly from bug predictors, but 16 bugs in this test suite is localized only using associative predicates. In total, 80 bugs from 130 bugs were localized in this test suite; witch is competitive with the previous work in this area that has found 79 bugs [3]. Table 3 shows more quantitative measures on the effectiveness.

Table 3. Number of buggy application variants in experiments, and number (percentage) of bug predictors and associated predicates that help in finding the main cause of failure  Application Variants Number of bug predictors  Number of associated predicates  print_tokens 7 7 0 print_tokens2 10 10 0 replace 31 27 4 Schedule 9 7 2 schedule2 9 8 1 tcas 41 36 5 tot_info 23 21 2 Overall 130 89% 11%  predicate Function File:Line Predicate type  (data->ifd[4]) ->count is FALSE  exif_data_save_data _content()  libexif- 0.6.10/libexif/exif- data.c:358  Bug predictor  o+s>buf_size is TRUE  exif_mnote_data_ canon_load()  libexif- 0.6.10/libexif/cano n/exif-mnote-data- canon.c:230  Associated predicate  i == j exif_entry_get_value ()  libexif- 0.6.10/libexif/exif- entry.c:645  Associated predicate  exif_mnote_data_canon_load (...) {   ...

for (i = 0; i < c; i++) { ...

if (o + s > buf_size) return; ?.

n->entries[i].data = malloc (sizeof (char)* s); ...}?}   Function exif-mnote-data- canon-save{ ? for (i = 0; i < n->count; i++) { ...

memcpy(*buf + doff,n ->entries[i].data, s); ...

}}      5. Conclusion and future work   The first novelty of this paper is applying recursive ridge regression for selecting most effective bug predictors of software. Using this method it is possible to consider the simultaneous effect of program predicates on each other and meanwhile on program result. This method eliminates the multicollinearity among the predicates which has not been studied in previous works.

The second novelty of the paper is employing association rule generation technique to find the main causes of program failure by introducing the faulty paths in control flow graph which contain bug predictors and associated predicates.

For future work other classification techniques could be applied in order to select the most effective one. Other debugging approaches such as slicing methods [9] could be employed in order to localize the causes of bugs more accurately.

6. References  [1] P. Arumuga Nainar, T. Chen, J. Rosin, and B. Liblit, ?Statistical debugging using compound Boolean predicates?, In proceeding of International Symposium on Software Testing and Analysis, London, 2007, pp. 5-15.

[2] C. Liu, X. Yan, L. Fei, J. Han, and S.P. Midkiff, ?Sober: Statistical model-based bug localization?, In10th European Software Eng.Conf./13th ACM SIGSOFT Int?l Symposium Foundations of Software Engineering, Lisbon, 2005, pp. 286- 295.

[3] L. Jiang, and Z. Su, ?Context-aware statistical debugging: from bug predictors to faulty control flow paths?, In twenty- software engineering, Atlanta, 2007, pp. 184-193.

[4] B. Liblit, A. Aiken, X. Zheng, and M.I. Jordan, ?Bug isolation via remote program sampling?, In Proceedings of the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation, San Diego, 2003, pp.

141?154.

[5] A. Zheng, M.I. Jordan, B. Liblit, and A. Aiken, ?Statistical debugging of sampled programs?, In Advances in Neural Information Processing Systems, Vancouver and Whistler, 2003, To appear.

[6] B. Liblit, M. Naik, A. Zheng, A. Aiken, and M.I. Jordan, ?Statistical Debugging in the Presence of Multiple Errors?, In Pittsburgh, 2006, pp. 1105 ? 1112.

[7] S. Chatterjee, A. Hadi, and B. Price, Regression Analysis by Example, third edition, Wiley press, New York, 2000.

[8] P. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining, Addison-Wesley press, USA, 2005.

[9] B. Liblit, ?Cooperative Bug Isolation?, PhD thesis, University of California, Berkeley, 2004.

[10] B. Liblit, M. Naik, A. Zheng, A. Aiken, and M. Jordan, ?Scalable Statistical Bug Isolation?, In Int?l Conference Programming Language Design and Implementation, Chicago, 2005, pp. 15-26.

[11] P. Alquier, ?Iterative feature selection in least square regression estimation?, Mathematics Subject Classification, Version 1 ? 11, 2005.

[12] G. Forman,? an extensive empirical study of feature selection metrics for text classification?, Journal of Machine Learning Research, 2002, pp. 1289-1305  [13] A. Genkin, D. Lewis, D. Madigan, ?BBR: Bayesian Logistic Regression Software? ,http://www.stat.rutgers.edu/~madigan/BBR/ ,2005.

[14] G.R.H. Do, S. Elbaum, ?Supporting controlled experimentation with testing techniques?, An infrastructure and its potential impact Empirical Software Engineering: An International Journal, 2005, pp. 405?435.

[15] G. Rothermel, S. Elbaum, A. Kinneer, and H. Do, ?Software-artifact infrastructure repository?, http://sir.unl.edu/portal ,2006.

[16] EXIF, http://www.cs.wisc.edu/cbi/pldi-2005/exif/complete /index.xml.

[17] Ridge regression in SPSS, http://www.spsstools.net/Syntax/RegressionRepeatedMeasur e/RidgeRegression.txt  [18]  RapidMiner, http://rapidi.com/content/  [19] M.J. Harrold, and G.  Rothermel, ?Aristotle Analysis System-Siemens Programs?, http://www.cc.gatech.edu/aristotle/Tools/subjects/  [20] R. Grossman, C. Kamath, and V. Kumar, ?Data Mining for Scientific and Engineering Applications?, Tutorial at SC2001, 2001.

[21] Fan Li, and Yiming Yang, ?Analysis of recursive gene selection approaches from micro-array data?. Journal of Bioinformatics, 2005, 21(19), pp.3741-3747.

