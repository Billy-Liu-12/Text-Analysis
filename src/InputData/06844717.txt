Location-Based Analysis of Developers and Technologies on GitHub

Abstract?GitHub is a popular platform for collaboration on open source projects. It also provides a rich API to query various aspects of the public activity. This combination of a popular social coding website with a rich API presents an opportunity for researchers to gather empirical data about software devel- opment practices. There are an overwhelmingly large number of competing platforms to choose from in software development.

Knowing which are gaining widespread adoption is valuable both for individual developers trying to increase their employability, as well as software engineers deciding which technology to use in their next big project. In terms of a developer?s employability and an employer?s ability to find available developers in their economic region, it is important to identify the most common technologies by geographic location. In this paper, analyses are done on GitHub data taking into account the developers? location and their technology usage. A web-based tool has been developed to interact with and visualize this data. In its current state of development, the tool summarizes the amount of code developers have in their public repositories broken down by programming language, and summarizes data about programmers using specific programming languages. This allows website visitors to get an immediate picture of the programming language usage in their region of interest. Future research could expand this work to technologies beyond programming languages such as frameworks and libraries.



I. INTRODUCTION  The software development landscape consists of a confus- ingly large number of competing platforms. Selecting which technologies to learn and use for development is a challenge for software developers, whether they be developers in training or experienced professionals. It has also become increasingly important for developers to be able to demonstrate their profi- ciency in a technology through code samples or open source projects. Recruiters are interested in using this information to make quicker and better informed decisions about whom to hire.

The technologies and skills relevant in the local job market depend on the location. Therefore, the emphasis for this study has been placed on acquiring and analyzing the data for specific locations. To make the problem concrete, data was collected for Victoria and Vancouver, BC. However, the project source code is general and can be used for any geographic location. For specificity, in this paper, we will refer to data collected for Victoria, BC. For example, perhaps Node.js is popular in San Francisco, but if it is not used by many companies in Victoria, BC., it is less likely to provide a return on time invested learning it for developers interested in jobs in Victoria.

Social coding websites such as GitHub [1] have become popular in recent years. As of its fifth birthday on April 10, 2013 GitHub had 3.5 million users and 6 million repositories [2]. Since much of the activity on GitHub is public, it is a large source of information on what technologies are being used in the open source community. This paper begins by reviewing the literature concerning analyzing GitHub data, and motivates the usefulness of a tool to sift through this data to determine which software development technologies are most popular in specific regions. It is important for employers to know the available pool of talent within their region, and it is also important for developers to have knowledge of the most commonly used technologies in their region. The tool developed is discussed, and then a preliminary evaluation of its usefulness is provided.



II. RELATED WORK  Thung et. al. [3] studied the network structures that develop in social coding, particularly on GitHub. A key point they make is that ?social coding enables a different experience of software development as the activities and interests of one developer are easily advertized to other developers.? This means that by aggregating this data, one can build a picture of the interests of groups of developers, including technologies used. Two of their research questions are: 1)?Which projects are the most influential?? and 2) ?Which developers are the most influential?? They answered these questions by building up a project-project graph and a developer-developer graph.

Nodes in the project-project graph were the GitHub projects, and they had an edge between them if two developers worked on both projects. The weight of the edge was increased if there were more developers who worked on both projects. The developer-developer graph worked similarly; developers had an edge between them if they worked on the same project, with higher weight if they worked on multiple projects together.

The PageRank algorithm was used on each of these graphs to find the most influential projects and developers.

Farah et. al. [4] have begun development of a tool for discovering software components on GitHub that meet de- velopers? specified requirements. Usually, ?software engineers must make comprehensive searches to select candidate com- ponents, study their documentation (when it is available), and then build tests to determine whether or not the component meets the search criteria. This work can be as or more expensive than the work of developing new components.? A tool that automates this process would have to be capable of   DOI 10.1109/WAINA.2014.110    DOI 10.1109/WAINA.2014.110     analyzing technologies used in software repositories, which is information that would also be relevant to the task of selecting popular software development technologies. Combined with Thung et. al.?s analysis of influential projects and developers, this could allow extraction of the technologies used in the most influential projects and by the most influential developers.

The tool developed for this paper and described in the Experiment section uses data queried directly from the GitHub API. This is the only source of which we are aware for the detailed programming language information used in the tool.

However, it is useful to know that there is a service called GHTorrent developed by Gousios and Spinellis [5] that mirrors much of GitHub?s data, including ?commits to the projects? repositories and events generated through user actions on project resources.? It provides a persistent, offline MongoDB and MySQL store and web interface to this data. It is intended for use in empirical research related to software repositories.

Part of the reason that the GHTorrent project is important is that GitHub?s full data is estimated to be on the terabyte scale [5] but API users are limited to 5000 requests per hour.

This makes it impossible for the full GitHub data set to be downloaded.

The use of social media by programmers has been studied by Singer et. al. [6]. The social media channels they stud- ied included the profile aggregation sites Masterbranch and Coderwall. These sites provide a ?meta-profile? by combin- ing information from users? profiles on other sites including GitHub, BitBucket, SourceForge, LinkedIn and Stack Over- flow. Combining profiles across services leads to very rich data sets providing deeper insights into technology usage in software development.

Singer et. al. conducted a number of questionnaires and interviews with both software developers and recruiters fre- quenting profile aggregation sites. From their study they found that one of the main reasons programmers gave for opting into one or more profile aggregators is ?they are curious about technology, passionate to learn, and always trying to improve themselves as developers.? Some also liked features such as badges that show technologies they have experience with because it is a way to demonstrate their expertise to potential recruiters.

Singer et. al. found that recruiters also liked profile aggre- gation services because they provide additional information for assessing potential job candidates. It was found that ?when evaluating a developer, recruiters first filter by skills, using skill lists provided by many web-based profiles.? Recruiters with a technical background also reported looking through candidates? open source projects to see if they use best practices such as unit testing. One interviewee was quoted as saying ?I always look to see if they?re writing tests, as a key.

If they?re not, I don?t wanna hire them.?  Capiluppi et. al. [7] have also studied how social web services such as GitHub can be used by employers to evaluate potential candidates for technical jobs. They concluded that interpreting a developer?s online presence ?is a matter of summarizing them in a concise, comprehensible, correct way.

Metrics and signals about online activity should therefore be open, verifiable, and reproducible.? They also make recommen- dations related to other services such as LinkedIn and Stack  Overflow, which may be useful for future work on this project.

The tool discussed in this paper is motivated and guided by the past work discussed above. It provides new features and results not addressed in earlier studies, in particular it targets specific geographic economic zones. This is important because employers often indicate they are unable to find employees with specific skills while new graduates and even seasoned developers can find it difficult to secure local employment (cf., Canadian Coalition For Tomorrows ICT Skills [8]).



III. DATA ACQUISITION  All data collected for the project came from GitHub?s public API [9]. It returns JSON data which is stored in a MongoDB [10] database. As stated earlier, the tool described here can be used in any geographic region, but the data acquired for this study was for Victoria, BC, a city in Canada.

A. Location Accuracy  Reliably determining a developer?s location based on the free-form text included in the location field of a developer?s profile required some trial-and-error experimentation. The is- sue is that developers might enter that information in many formats. The GitHub search API allows keywords to be passed for the location. Being too specific in the search (ex: ?Victoria, BC, Canada?) causes users who list alternative forms such as ?Victoria, British Columbia? or ?Victoria, BC?, or ?Victoria, Canada?, etc. to be missed. Therefore, the search is done on just ?victoria?, but this returns results from Victoria, Australia and other unwanted places.

To solve this problem a post-processing step was added to filter users further based on location. At first a white- listing approach was attempted. This meant the system had a list of possible variations on the name Victoria, BC, Canada.

However, extensive logging was done to trace how well this worked, and it was found that a large number of users from Victoria, BC, Canada were being filtered out due to small variations from the strings in the white list. Since the location field is free-form there is a huge variety of possible variations that cannot be anticipated.

Therefore a different approach was taken. Instead of using a white-list, a black-list was developed. This list contained ?stop-words?: if any of these words is found in the location, the user is filtered out. The potential users were examined and all the stopwords such as ?Australia?, ?Melbourne?, and so on were identified. This approach is simpler than trying to have a white-list with every single possible variation, and it was decided to err on the side of including a user who should not be, rather than excluding a user who should be included.

B. Data Download  The initial script developed to gather data from the GitHub API ran serially, user by user. It took well over half an hour just to do the approximately 3500 API calls to retrieve information for Victoria, BC users. This was made worse by the fact that one out of every two or three such runs of the script would crash due to a network or server problem while accessing the GitHub API. This made the process far too tedious to enable an effective and repeatable data product.

Therefore there were two goals for improving the download process: speed it up and make it handle errors. These goals were achieved by making the script multi-threaded. Usernames are put on a synchronized queue that worker threads pull from and then execute the necessary API calls to process the user.

Python is not truly multi-threaded due to the Global Interpreter Lock [11]. However, the lock is released around blocking I/O operations such as network communication. This allows many API calls to be made at once. Ten threads (configurable) were used, and the same 3500 API calls that were taking over 30 minutes were completed in about 3 and a half minutes. This made it much easier to gather new data. The process was also made more robust. Now when an error occurs during an API call, the user being processed goes back on the queue to be processed again later.

One effect of the massive increase in data download speed is that the GitHub API rate limit is easily reached. It is not reached when processing Victoria, but it is when processing the much larger developer community in Vancouver. The limit is 5000 API calls per hour. A back-off mechanism was also added to the worker threads so that they will automatically handle this, allowing the process to continue running as long as needed without manual intervention. The 5000 API call limit can be reached in about 5 minutes. The GitHub API reponses contain HTTP headers indicating how many calls are left and what time the limit will be reset. If a worker finds that the quota has been used up, it checks the reset time and sleeps until then (plus a small buffer period).



IV. DATA ANALYSIS  The core of the analysis provided by this application is the list of developers by location and the aggregation of program- ming languages used across a developer?s public repositories.

This information is not available from the GitHub API directly, but the needed data elements are stored by the application in a database which can be queried. This data then enables analyses such as:  1) Searching for a location such as Victoria, BC, Canada, and getting a list of the developers along with details about them available through the GitHub API, such as company, real name, etc.

2) Retrieving a developer?s programming language us- age across repositories.

3) Determining programming language popularity in a specific geographic location using aggregated met- rics; either by number of developers using the lan- guage or by the amount of code in their repositories.

4) Querying for a list of developers in a location who use a specific language.

These analyses help meet the needs of both developers and recruiters as outlined in the Related Work. In particular, Singer et. al.?s [6] findings provided much guidance as to what features programmers and recruiters are most interested in seeing when exploring data from GitHub. For example, feature 3 can help developers discover technologies they should learn for their location, and feature 4 above helps recruiters filter by skills. The tool provides a language summary page per developer, including a link to the developer?s GitHub profile.

From there the recruiter can check their code for best practices,  breadth of experience, and so on. Each of these analyses has accompanying visualizations which are discussed in the next section.



V. VISUALIZATION  Web-based bar chart graphics and paginated, sortable, filterable data tables are the primary means of visualization in the web application. These visualizations are well-suited for the data analysis described in the previous section. Examples of two types of visualizations (Figures 1 and 2) are given below. Visualizations of a similar nature have been developed to support each of the analysis tasks mentioned in the Analysis section.

Fig. 1. An example data table visualization showing JavaScript developers in Victoria, BC, sorted by amount of code in their public repositories.

Fig. 2. An example bar chart visualization showing the top 10 most used programming languages in Victoria, BC based on number of developers. The vertical axis is the number of developers using the language.



VI. EVALUATION  To obtain feedback on the usefulness of the existing analysis, the URL for the project site was provided to a group of software developers at the University of Victoria, and a group of employers in Victoria, BC. This was an informal, exploratory evaluation.

A. Developer Feedback  A handful of software developers were shown the project and asked their opinion. Most found the site engaging, often because they could see developers that they recognized in their location. One reviewer found the use of people?s real names a bit intrusive at first, but the vast majority of the developers felt this was a ?must-have? feature.

Some developers felt that it would be nice to have a convenient way to compare multiple developers at once in the same visualization. There was also interest in finding other developers with similar interests in programming languages, projects and technologies in general.

B. Employer Feedback  An e-mail was sent out to several contacts at local em- ployers around Victoria. One interesting response came from a local Victoria company specializing in assembling dedicated enterprise software teams.

They responded: ?Interesting. I can see some uses alright.

If we?re trying to find a JS developer it would be interesting to search by developer type and location and retrieve a sample of their code and put it through static analysis to see how they faired, and if they were ok grab the email address they list.

Then drop them an email. Something like, I can see that you are a Github contributor who has Javascript experience and good code...?.

They also responded that the ?other use I can see is promoting our open source project via email invite.? This comment is particularly interesting because part of our original motivation for exploring the GitHub API was to find local open source software projects. In the future we will seek further feedback from other local businesses, to make the tool even more useful.

C. Future Evaluation  Further feedback will be sought on the usefulness of this project from local companies. This will help refine the set of features which will be most desirable by those people who can get real value from the software.

Additionally, Google analytics will be included in the site so that a more quantitative study of usage patterns can be made.

This may also reveal what users are finding most interesting, or parts of the user interface that cause them to lose interest.



VII. KNOWN LIMITATIONS  A. GitHub Search API  A remaining challenge is the fact that the user search API will only return 1000 users. This is enough for Victoria, but not for larger cities such as Vancouver. Another scheme will  need to be developed to acquire the user list. One possibility is using data from the GHTorrent Project [5]. It monitors the GitHub public event timeline and stores the data. It provides both a MongoDB and MySQL interface for querying this data.

It does not include the detailed language usage information that this project needs, but it may be useful for querying users in a location if appropriate patterns can be found. For example, using the MySQL interface a query such as:  SELECT * FROM users WHERE LOWER(LOCATION) LIKE ?%vancouver%?;  could be used for a case-insensitive search for all locations containing Vancouver, and then the regular post-processing with stop-words can be applied.

B. Forks vs External Repositories  The current data collection process only considers code in repositories that a developer owns. This means that if a developer contributes to a repository that they do not own, without creating a fork, this contribution will not be included in their metrics. Conversely, if a developer forks a large project they will get credit for all of the code in that repository, even though they did not write it.

Therefore, to make the metrics more accurate, it would be necessary to extract data from developers? contribution activity, not projects owned. This is another area where the GHTorrent project may prove useful in the future.

C. Proprietary Software Development  Since this tool only analyzes public repositories on GitHub, it does not obtain a full picture of a region?s software devel- opment activity. This is because many developers only work on proprietary code which would not be in public repositories.

One way to obtain information on the type of technologies used within this development community is through analysis of job postings, which is the subject of a separate study.



VIII. FUTURE WORK  The tool needs a web administrative interface so that it can be configured to collect data for an arbitrary geographic location with stop-words selected from a menu and persisted to a database, rather than being hard-coded. In the current version of the tool, some manual editing of configuration files is needed to collect data for other locations.

There are several features that could still be added to this project. One is the ability to find similar developers. This might be implemented as a ?Find similar developers? button on the developer information page. Calculating this similarity would involve adding some machine learning algorithms. Initially the similarity could just be based on using the same languages.

Later it could take into account the amount of code in each language, developers ?starring? the same repositories, following the same people, etc.

It would also be interesting to investigate the LinkedIn API and see if it would be possible to acquire more information about developers from there. A big challenge would be linking GitHub and LinkedIn accounts, but it might be possible using     email addresses or the combination of name and location, though that would be less reliable because there could be many ?John Smith?s in a large city.

Another area for improvement, that ties into suggesting to developers strategic technologies to learn, would be to dig deeper into the use of tools, libraries and frameworks. This is more challenging because it is not data available through the GitHub API. It would require analyzing the code repositories of developers. For example, it might be possible to look at import/include statements as well as project configuration files such as Ruby gemfiles, Python pip requirements files, Java maven build files, etc. This would require quite a bit of programming effort to account for all of the different languages. Also, it would be a truly ?big data? task to do full source code parsing on every user?s projects for larger geographic regions. If the data could be acquired though, it would allow a much more fine grained search of developers with specific qualifications. Employers could essentially enter the information from their job posting to find qualified indi- viduals.



IX. CONCLUSION  GitHub is by far the most popular platform for open source collaboration, and it has a rich API. In this paper we demonstrated how this can be used to obtain detailed information about software development in specific geographic locations. Other papers have demonstrated how to extract in- formation about social networking but this is the only paper to our knowledge which has attempted to characterize developer activity by geographic location.

The importance of identifying developers? geographic loca- tion is especially important because employers often bemoan the lack of qualified local developers, sometimes resorting to foreign workers and outsourcing. Meanwhile, some developers find it difficult to find local jobs. Therefore, it is critical to highlight the available local skills to employers and allow developers to learn which skills will be in greatest demand.

This information is also useful to educators in their selection of programming languages and frameworks used in university and college curricula so that they can give graduating students the best skill set possible to meet local labour market demands.

Identifying the most commonly used programming lan- guages and frameworks is a difficult task because there are a dauntingly large number of competing platforms to choose from in software development. However, often the choice between technologies to be employed in a project is not which is the ?best? technology, but which technology is most likely to lead to a product supported by a large pool of available developers during both the development stage and later in the maintenance stage. This tool helps answer that question.

The web-based tool discussed in this paper is only a first step towards identifying software development technology by region. It characterizes the most commonly used languages by both amount of source code and number of developers using that programming language. Much more could still be done. A deeper analysis of the contents of the repositories could identify libraries, frameworks, and other components of software systems. Code metrics could also be run on  the contents of repositories, identifying occurrences of code duplication and other code quality factors.



