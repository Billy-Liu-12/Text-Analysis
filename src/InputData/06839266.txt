To improve Association Rule Mining using New  Technique: Multilevel Relationship Algorithm

Abstract - Mining the Data is also known as Discovery of Knowledge in Databases. It is to get correlations, trends, patterns, anomalies from the databases which can help to build exact future decisions. No one can assure that the decision will lead to good quality results. It only helps experts to understand the data and show the way to good decisions. An objective is to make rules from given multiple sources of customer database transaction. It needs increasingly deepening knowledge mining process for finding refined knowledge from data. Earlier work is on mining association rules at one level. Though mining association rules at various levels is necessary. Finding of interesting association relationship among large amount of data will helpful to decision building, marketing, & business managing. For generating frequent item set we are using Apriori Algorithm in multiple levels so called Multilevel Relationship algorithm (MRA). MRA works in first two stages. In third stage of MRA uses Bayesian probability to find out the dependency & relationship among different shops, pattern of sales & generates the rule for learning.  This paper gives detail idea about concepts of association mining, mathematical model development for Multilevel Relationship Algorithm (MRA) and Implementation & Result Analysis of MRA and performance comparison of MRA and Apriori algorithm.

Keywords - Apriori Algorithm, Association rule, Bayesian Probability, Data mining, Multilevel learning

I. INTRODUCTION  Machine Learning deals with the design of programs that can learn rules from data, adapt to changes, and improve performance with experience. In addition to being one of the initial thoughts of Computer Science, Machine Learning has become vital as computers are expected to solve increasingly complex problems and become more integrated into daily lives. These include identifying faces in images, autonomous driving in the desert, finding relevant documents in a database, finding patterns in large volumes of scientific data, and adjusting internal parameters of systems to optimize performance. Alternatively methods that take labeled training data and then learn appropriate rules from the data seem to be the best approach to solve the problems. Moreover, it needs a system that can adapt to varying conditions which is user- friendly by adapting to needs of their individual users, and also can improve performance over time[1].

Association rule mining concept has been applied to market domain and specific problem has been studied, the management of some aspects of a shopping mall, and an architecture that makes it possible to construct agents capable of adapting the association rules has been used.

Dr. Parag Kulkarni Head, R&D,  EklaT Research Lab.

Pune, India  parag.india@gmail.com  A shopping mall is a cluster of independent shops, planned and developed by one or several entities, with a common objective. The size, commercial mixture, common services and complementary activities developed are all in keeping with their surroundings. A shopping mall needs to be managed and, the management includes solving incidents or problems in a dynamic environment[2].

As such, a shopping mall can be seen as a large dynamic problem, in which the management required depends on the variability of the products, clients, opinions. Aim is to develop an open system, capable of incorporating as many agents as necessary, agents that can provide useful services to the clients not only in this shopping centre, but also in any other environment such as the labor market, educational system, medical care, etc.

Data mining refers to extracting knowledge from large quantity of data. Interesting association can be discovered among a large set of data items by association rule mining.

The finding of interesting relationship among large amount of business transaction records can help in many business decisions making process, such as catalog plan, cross marketing and loss leader analysis[3]. However, previous work has been focused on mining association rules at a single concept level. There are applications, which need to get associations at multiple concept levels.

Real world problem can be expressed in term of mathematical model and mathematical solutions can be found out.

Following stages represents the process for solving the real world problems.

? Study of basic concepts for mathematical modeling ? Mathematical Modeling of the system (MRA) ? Implementation & Result analysis of MRA  Thus, the goal of this paper is to verify working of mathematical model developed for multilevel association rule mining. Multilevel Apriori algorithm and bayesian probability estimation is not combined in any of the previous work. It is the novel move towards the mining association rule.

Efficiency of original Apriori algorithm has been increased due to multilevel architecture.

This paper is organized as follows: Section 2 describes the concept of association mining. Section 3 describes the proposed Multilevel Relationship Algorithm (MRA) models.

In Section 4 we present the architecture of Multilevel Relationship Algorithm (MRA). In Section 5 we present experimental results on the proposed model. Finally, in the last section some conclusions are stated and perspectives for future work are discussed.



II. ASSOCIATION RULE  Mining association rule is finding the interesting association or correlation relationship among large set of data items.

Many industries are becoming interested in mining association rule from their database as massive amount of data constantly being collected & stored in database. Relationship among the business traction records can help to design catalog, loss leader analysis, cross marketing & other business decision making process. The discovery of such association can help retailers to develop marketing strategies by gaining insight into which items are frequently purchased together by customers. This information can increased sale by helping retailers to do selective marketing & plan their shelf space.

One of the motivating examples for association rule mining is marker basket analysis[4].

Market basket analysis is useful for retailers to plan which item to put on sale at reduced price. If customer tends to purchase shirt of Bombay dyeing and jeans of Levis together, then having a sale on jeans may encourage the sale of shirt as well as jeans. Buying patterns reflects which items are frequent associated or purchased together. These patterns are represented in the form of association rules. For example, customer who purchase shirt-Bombay dyeing also tends to buy jeans Levis at the same time is represented in association rule (2.1) below.

Shirt-Bombay dyeing ? jeans-levis [supp=2%, conf=60%]                            (2.1)  Rule support & confidence are two measure rules. They respectively reflect the usefulness and certainty of discovered rules. A support of 2% for association rule means that 2% of all transactions under analysis show that shirt-Bombay dyeing and jeans-levis are purchased together. A confidence of 60% means that 60% of customers who purchased shirt-Bombay dyeing also bought jeans Levis. Typically, association rule are considered interesting if they satisfy both a minimum support threshold and a minimum assurance threshold. Such threshold can be located by users or area expert.

Let I= {i1, i2, i3????.???id} set of all items in  dataset T= {t1, t2, t3?....?????......tn} set of all  transactions Each transaction ti contains a subset of items chosen from I. A transaction tj is said to contain an itemset X if X is subset of tj.

Association rule is an implication of the form of  X ?Y, where X ? I, Y? I & X ?Y = ? The rule X ?Y holds in the transaction set T with support s, where s is percentage of transactions in T that contain X U Y.

The rule X ?Y has confidence c in the transaction set T if c is percentage in transactions in T containing X which also contain Y. i.e Support (X ?Y) = P (X?Y)                   (2.2) Confidence (X ?Y) = P (Y|X)                         (2.3) Rules that satisfy both minimum support threshold (min_sup) and a minimum confidence threshold (min_conf) are called strong.

Itemset is nothing but set of items. If it contains n item is a n-itemset. The set {shirt-Bombay Dyeing, jeans-levis} is 2 itemset. The occurrence of itemset is the number of transactions that contain the itemset. This is known as frequency or support count of the item set. It satisfies lowest  amount of support if the occurrences frequency of itemset is greater than or equal to the product of min_sup & total no of transactions in T. If an itemset satisfy the minimum support then it is frequent itemset. Association mining has two steps process. In first step, find all frequent item sets. All of these item sets will arise at least as frequently as a pre-determined minimum support count. In second step, generate strong association rules from the frequent item sets and must satisfy lowest amount of support and minimum confidence. The overall performance of mining association rule is determined by the first step[5].



III. MULTILEVEL RELATIONSHIP ALGORITHM  To improve the mining of association rules new mining algorithm has been developed as Multilevel Relationship Algorithm which works in three stages. In first two stages it utilizes apriori algorithm for finding out frequent itemsets.

Third stage of MRA uses bayesian probability to find out the dependency & relationship amongst different shops and generates the rules for learning.

Let the system S be represented as  S =  {I, O, fs | ? s } I =  Input Datasets  O = Output Patterns  O = fs(I)  ?  ? s fs :  I ?  O be ONTO function Objective was to find out pattern of sale from given dataset of three different shops for particular time period.

Input dataset  I = {X,Y,Z} such that X = {x1,x2,x3} , Y = {y1,y2,y3}  and Z = {z1,z2,z3}   Success output O = {P(X0|Y0), P(X0|Z0), P(X1|Y1), P(Y1|Z1)???.. } Multilevel Relationship Algorithm is applied on given input dataset i.e. I={X,Y,Z} where X = {x1,x2,x3}, Y = {y1,y2,y3} and Z = {z1,z2,z3}.

First stage gives Level 1 association amongst items in the same shop using knowledge base. It is called as local frequent itemsets generated in first phase.  During second stage it uses individual knowledge base and level 1 association that was generated in stage I from same shops to find out the frequent item sets i.e. x1(0), x2(3), x3(1)??etc. It is called as global frequent itemsets[6].

Stage 1:  At first stage it find out Level 1 association amongst items in the same shop i.e. internal relationship between the same item types i. e. x1(0??.n), x2(0???n), x3(0??..n) within the Cloth shop (X) i.e. O = fs(X). It find out internal relationship between the same item types i. e. y1(0??.n), y2(0???n), y3(0??..n) within the Jewelry shop (Y) i.e.

O = fs(Y). Also it find out the internal relationship between the same item types i. e. z1(0??.n), z2(0???n), z3(0??..n) within the Footwear shop (Z) i.e. O = fs(Z).

Stage 2:  During second stage it uses individual knowledge base and level 1 association is generated in stage 1 of same shop to find out the frequent item sets i.e. x1(0), x2(3), x3(1)??etc is called as global frequent itemsets.  It gives sets of frequent item sets for the Cloth shop for different items i.e. Fx as O = fs(x1,x2,x3). It gives sets of frequent item sets for the Jewelry shop for different items i.e. Fy as O = fs(y1,y2,y3). And also gives with sets of frequent item sets for the Footwear shop for different items i.e. Fz as  O = fs(z1,z2,z3).

Stage 3: It is necessary to determine dynamic behavior of Fi for particular season. External Dependencies amongst Items Xi Yi??... Xn Yn has been found with Bayesian probability.

New patterns are generated by Bayesian probability through which learning rules are predicted & interpreted.

Working of Multilevel Relationship Algorithm Let the sale of Item X at Cloth shop affects sale of item Y at  Jewelry shop and item Z at Footwear.

1. Apriori association mining algorithm is applied on each  item in cloth shops separately i.e. Jean(X0), Tshirt(X1), Shirt(X2) and so on from the given large item sets. It was applied at two levels / phases in the same shop[7].

2. After applying Apriori algorithm at first level for different support value it provide with the internal dependency amongst individual items & generate the individual knowledge base i.e. x1(0) ?  x1(1), x2(0) ? x2(1), x3(0) ?  x3(1) ?....etc. It is called as local frequent itemsets generated in first phase.

3. At second level Apriori algorithm was applied on newly generated individual knowledge base to find out the frequent item sets i.e. x1(0), x2(3), x3(1)??etc. It is called as global frequent itemsets.

4. It provided with sets of frequent item sets for the Cloth shop for different items i.e. Fx.

5. Similarly the algorithm is applied on Jewelry shop(Y) & Footwear shop(Z) to determine frequent itemset on different items.

6. First Level output of Apriori algorithm provided internal association amongst the items i. e.  y1(0) ? y1(1),y2(0) ?y2(1),y3(0) ?y3(1) & z1(0) ?z1(1), z2(0) ?z2(1), z3(0) ?z3(1)......etc for Jewelry & Footwear shop respectively.

7. Second level input of Apriori algorithm provided from newly generated individual knowledge base, the frequent item sets i.e. y1(0), y2(3), y3(1), z1(1), z2(5)  8. It gives with sets of frequent item sets for the Jewelry & Footwear shop for different items i.e. Fy & Fz.

9. The context is generated under uncertainty in the form of frequent item sets Fx, Fy & Fz. System constraints applied here are sale of items in a day, week, month or any particular season. This context is refereed as Fi which is not constant, i.e. it changed seasonably.

10. Hence it is necessary to determine dynamic behavior of Fi for particular season.

11. External Dependencies amongst Items  Xi ?Yi?.Xn ?Yn is found with Bayesian probability.

12. New patterns are generated by Bayesian probability though which learning rules could be predicted & interpreted.



IV. ARCHITECTURE OF MRA    Fig. 1 : MRA Architecture Diagram  Figure 1 shows the flow diagram which depicted the development of Multilevel Relationship Algorithm (MRA).

Multilevel Relationship algorithm worked in three stages.

In first two stages it utilized association rule mining algorithm for finding out frequent itemsets. Datasets of three shops i.e.

Cloth, Jewelry & Footwear were given as an input to the stage I and Level 1 association between individual items had been found out.  Level 1 association between individual items was given as an input to stage II and frequent itemsets had been found out. These frequent itemsets had generated new sale context. In stage III it used bayesian probability to find out the external dependency & relationship amongst different shops, pattern of sale and generated the rules for cooperative learning.  The algorithm consists of three sub modules: MRA Stage I, MRA stage II, Interdependency Module   MRA Stage I:  At first stage it finds Level 1 association amongst items in the same shop i.e. Internal relationship between the same item types i. e. x1(0??.n), x2(0???n), x3(0??..n) within the Cloth shop (X)  i.e.

O = fs(X) = fstage_I_algorithm_apriori (X)  ? O=fstage_I_algorithm_apriori{x1(?.n)}={x1(0) ?x1(1),x1(3) ? x1(2)?}  O=fstage_I_algorithm_apriori{x2(0?n)}={x2(2) ?x2(4),x2(2) ? x2(4)?}  O=fstage_I_algorithm_apriori{x3(0?n)}={x3(0) ?x3(3),x3(1) ? x3(5)?}    MRA Level 1 finds internal relationship between the same item types i. e. Y1(0??.N), Y2(0???N), Y3(0??..N) within the Jewellery shop (Y) i.e.

O = fs(Y) = fstage_I_algorithm_apriori(Y)  ? O=fstage_I_algorithm_apriori{y1(0.n)}={y1(1) ?y1(3),y1(2) ?y1(5)} O=fstage_I_algorithm_apriori{y2(0.n)}={y2(0) ?y2(1), y2(3) ?  y2(7)} O=fstage_I_algorithm_apriori{y3(0.n)}={y3(2) ?y3(3),y3(1) ?  y3(4)}  MRA Level 1 also finds internal relationship between the same item types i. e. z1(0??.n), z2(0???n), z3(0??..n) within the Footwear shop (Z)   O = fs(Z)  = fstage_I_algorithm_apriori(Z)        ? O= fstage_I_algorithm_apriori{z1(0?..n)} = {z1(0) ?z1(2), z1(2) ? z1(4)?}  O=fstage_I_algorithm_apriori{z2(0?.n)} = {z2(1) ?z2(4), z2(1) ? z2(3)?}  O= fstage_I_algorithm_apriori{z3(0?.n)} = {z3(0) ?z3(3), z3(2) ? z3(5)?}  MRA Stage II: During second stage it uses individual knowledge base and level 1 association is generated in stage 1 of same shop to find out the frequent item sets i.e. x1(0), x2(3), x3(1)??etc is called as global frequent itemsets. It gives sets of frequent item sets for the Cloth shop for different items i.e. Fx as below.

O = fs(x1,x2,x3)  O=fphase_II_algorithm_apriori{x1,x2,x3}  ={x1(0) ?x2(1),x2(3) ?x3(2), x3(0) ?x2(2).?..} MRA Stage II gives sets of frequent item sets for the Jewelry shop for different items i.e. Fy as below O = fs(y1,y2,y3)  O=fphase_II_algorithm_apriori{y1,y2,y3}  ={y1(0) ?y2(1),y2(3) ?y3(2), y3(0) ?y2(2)??} MRA Stage II also gives with sets of frequent item sets for the Footwear shop for different items i.e. Fz as below O = fs(z1,z2,z3)  O= fphase_II_algorithm_apriori{z1,z2,z3}  ={z1(0) ?z2(1), z2(3) ?z3(2), z3(0) ?z2(2)??} MRA Stage 3: Interdependency by Bayesian Probability It is necessary to determine dynamic behavior of Fi for particular season. External Dependencies amongst Items Xi ?Yi??Xn ?Yn is found with Bayesian probability.

New patterns are generated by Bayesian probability through which learning rules are predicted & interpreted. Dependency between itemsets of Cloth shop (Fx) and Jewelry shop (Fy) is find out as | |  1, 2, ? | 1, 2, . .1, 2. . | 1, 2. . 1, 2. .1, 2 ? .

Bayesian probability finds out interdependency between itemsets of Jewelry shop (Fy) and Footwear shop (Fz) as | | 1, 2, ? | 1, 2, . .  1, 2. . | 1, 2. . 1, 2. .1, 2 ? .

Bayesian probability also finds out interdependency between itemsets of Footwear shop (Fz) and Cloth shop (Fx) as  | | 1, 2, ? | 1, 2, . . 1, 2. . | 1, 2. . 1, 2. .1, 2 ? .

Three cases are possible for the system to find out interdependencies and for the correct prediction of learning rules.

Case 1: Sale of items in Footwear shop (Z) depends on sale of items in Jewelry shop(Y) and it is in turn depends on sale of items in Cloth shop (X). That means, X is a cause of Y and Y is a cause of Z.  It can be represented by following model:    Three nodes are connected serially. X & Z were independent given the intermediate node Y.  | , | || |  Result is an increase in sale of items in Cloth shop (X) causes increase in sale of items in Jewelry shop (Y) which in turn cause increase in sale of items in Footwear shop (Z)[11].

Case 2: Sale of items in Footwear shop (Z) & Jewelry shop (Y) depends on sale of items in Cloth shop (X). That means X is a cause of Y and Z.  Two child nodes are independent given the parent. Y & Z are independent given the parent node X.  It can be represented by following model:       Three nodes are connected as shown in above model. Y & Z are independent given the parent node X.  | , | | | |  Result is increase in sale of items in Cloth shop (X) cause increase in sale of items in both the shops i.e.  Jewelry shop (Y) & Footwear shop (Z) [11].

Case 3: Sale of items in Footwear shop (Z) depend on sale  of items in Cloth shop (X) and Jewelry shop (Y). That means X & Y are the causes of Z. A node has two parents that are independent unless child is given i.e. an event may have independent causes. It can be represented by following model:       X & Y are independent giving the child node Z.  | , | | ,| | , | Result is increase in sale of items in Cloth shop (X) &  Jewelry shop (Y) cause increase in sale of items in the  X   Y   Z    X  Y   Z  Z    YX        Footwear shop (Z) provided sale of items in Cloth shop & Jewelry shop does not depend on each other [11].



V.  EXPERIMENTAL RESULTS  The experimental results that have been obtained through implementing MRA and Apriori algorithm are presented in this section. Multilevel relationship algorithm applied for finding the frequent itemset and external dependency amongst them. It comes up with pattern which can be further useful for leaning in cooperative system. The results obtained for strength, support and interdependency of itemsets for both the algorithms. Performance of Apriori and MRA has compared for these factors i.e. strength, support and interdependency.

Dataset Organization Association mining data is generally obtained from databases created for other uses and manipulate into a suitable representation through pre processing techniques. The resulting dataset is expressed as items that they contain.

Experiments have been conducted datasets of Cloth, Jewellery and Footwear shops. Each data sets have the five attributes i.e. Transaction ID, Item, Brand, Quantity and date of purchase.  Dataset contains various items with different brand purchased with diverse quantity during the specified period by the customers. Snap shots of each data set is given in following table.

Table 5.1: Cloth Shop (X)  Transaction ID Item Brand Quantity Date  1 Shirt Bombay Dyeing 3 16/10/2012  1 Jeans Denis 1 16/10/2012  2 Jeans Peter England 2 17/10/2012  2 Tshirt Pepe Jeans 1 17/10/2012  3 Shirt Pan America 2 18/10/2012  3 Tshirt Being Human 1 18/10/2012  4 Jeans Levis 2 19/10/2012   Table 5.2: Jewellery Shop (Y)  Transaction ID Item Brand Quantity Date  1 Bracelet Nakshtra 3 16/10/2012  1 Ear Rings Gitanjali 2 16/10/2012  2 Pendant Asmi 2 17/10/2012  2 Bracelet Gilli 2 17/10/2012  3 Diamond Ring TBZ 1 18/10/2012  3 Ear Rings Asmi 2 18/10/2012  4 Ear Rings Nakshtra 2 19/10/2012    Table 5.3: Footwear Shop (Z)  Transaction ID Item Brand Quantity Date  1 Chappals Lakhani 2 16/10/2012  1 Shoes Woodland 1 16/10/2012  1 Sandles Bata 2 16/10/2012  1 Chappals Paragon 1 16/10/2012  2 Sandals Action 1 17/10/2012  2 Shoes Symphony 2 17/10/2012  3 Shoes Lee Cooper 2 18/10/2012  Following Graphs show the result comparison between Apriori and MRA.

Fig. 2: Comparison of Apriori & MRA in terms of item strength with support for cloth shop                        Fig. 3: Comparison of Apriori & MRA in terms of item strength with  support for footwear shop                       Fig. 4: Comparison of Apriori & MRA in terms of item strength with support for jewellery shop               Fig. 5: Comparison of Apriori & MRA in terms of time (ms) & support for  cloth shop                              Fig. 6: Comparison of Apriori & MRA in terms of time (ms) & support for footwear shop                       Fig. 7: Comparison of Apriori & MRA in terms of time (ms) & support for jewellery shop     Fig. 8: Percentage Interdependency among the three shops   The experiment results show that MRA performs better than the Apriori algorithm towards improvement of mining association rule. Fig. 2, 3 and 4 shows comparison of Apriori & MRA in terms of item strength with support for cloth, footwear and jewellery shop respectively. Item relative strength for minimum support count of MRA is always greater than Apriori algorithm. Increase in minimum support count decreases the item relative strength for both MRA and Apriori algorithms. Fig. 5, 6 and 7 shows comparison of Apriori & MRA in terms of time (ms) & support for cloth, footwear and jewellery shop respectively. Time required by MRA is always less than the time required by Apriori algorithm. As number of support increases it decreases the time requirement for both MRA and Apriori algorithms.  Fig.

8 shows sale of items in Footwear shop depends on sale of  items in Jewelry shop and it is in turn depends on sale of items in Cloth shop and interdependency is 0.29 (as discussed in Case 1).  Fig. 8 shows sale of items in Footwear shop & Jewelry shop depends on sale of items in Cloth shop and interdependency is 0.24 (as discussed in Case 2). Fig. 8 also shows sale of items in footwear depends upon sale of items in jewellery and cloth shop and dependency is 0.19 (as discussed in Case 3).  Simple Apriori algorithm shows only the frequent itemsets in each shop independently. It does not provide the internal dependency amongst individual items and cannot find out local frequent itemsets.  Due to this, external dependencies are not found out between different shops and become unable to find out the learning rules and pattern of sale. Hence, there is need to develop modified approach which would enable to give internal & external dependencies along with the learning rules. Multilevel Apriori algorithm and bayesian probability estimation gives the expected results.

CONCLUSION  In this paper we proposed an efficient new Multilevel Relationship Algorithm. This is new approach applied to the set of data from different shops for finding frequent item sets and finding external dependencies amongst them. It comes up with patters which can be further useful for learning in cooperative algorithms. The classical apriori algorithm widely used for association rule mining. Though this algorithm is good to find the frequent item sets with minimum support it does not provide with dependencies between different frequent itemsets.  The main contribution of this paper is that Multilevel Apriori algorithm and Bayesian probability estimation has not combined in any of the previous work.

Two passes of algorithm has been performed for more accuracy and efficiency. New pattern are generated by Bayesian probability through which learning rules are predicted and interpreted. This multilevel approach is especially beneficial when efficiency required is important such as in computationally intensive applications that must be run frequently. Our experiment results show that MRA performs better than the Apriori algorithm towards improvement of  mining association rule. We are planning to extend our approach so that it can extract the more rules with their interdependencies and can facilitate further cooperative learning.

