Rough Set Based Attribute Reduction and Extension Data Mining

Abstract   In the data base of information system, usually there are some attributes which are unimportant to the decision attribute, and some records that disturb the decision making. In this paper, reducing the condition attributes based on the matter-element theory and rough set method, calculating the importance to the decision attribute for each condition attribute after reduction, and data mining the association rules based on the reduced attributes, then extension transforming the rules according the importance of each attribute, that come up with more reliable knowledge of extension transformation and more effective solutions.

1. Extenics fundamental   The theory and methods of extenics is using the extension transformation and extension knowledge to change the target or condition of the problem, so that solves the incompatible problem.

1.1. Basic information of extenics   Extenisc represents the matter, case and relation of the world as matter-element, case-element and relation- element, it calls them base element, they are the basic information of extenisc.

Matter-element is represented as R=(N,c,v), it is a combination of matter N, character c and value v.

One matter could have several characters, if matter N has n characters: c1, c2, ?, cn and corresponding value: v1, v2, ?, vn, then it can be represented as:   Similar to those definitions on multi-dimension matter-  element, extenisc has the definition of case-element and relation-element.

1.2. Extension transformation   Extension transformation is the tool for solving the  problem. It can turn the unknowable problem into knowable problem, turn the unfeasible problem in feasible problem, turn the false proposition into true proposition and turn the incompatible problem into compatible problem.

Extension transformation is turning one object into another one, it is turning base element u into base element v, and it can be represented as:  Tu=v   1.3. Extension information   Extension information is the information that is used to solve the incompatible problem. Base element in extenisc, including matter-element, case-element and relation- element, is the basic information of extension information.

Transformation in extenisc is transforming the information, so that transforming the incompatible problem into compatible problem.

Extension information = base element + extension transformation  The basic information in extension information is static description, but transformation of the information has the character of variety. It must be using the extension transformation and variable information to solve the incompatible problem.

1.4. The basic knowledge of extenisc   The basic knowledge of the extenisc is extended  formulas. The conductive theory in extenisc is that extension transformation Tu leading the corresponding conductive transformation Tv, and that relation can be represented as transformation implication formula, it is called variable knowledge:  (Tuu?u?)?(Tvv?v?), or Tu?Tv   1.5. Extension knowledge   Extension knowledge is the knowledge being used to solve the incompatible problems. Extended formula in  Second International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2008.64   Second International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2008.64   Second International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2008.64     extenisc is the basic knowledge of extension knowledge.

The transformation implication formula of the conductive theory in extenisc is variable knowledge and the association function in extenisc discretizing the incompatible problem. They are composing the extension knowledge:  Extension knowledge = extended formula + transformation implication formula + association function  The implication formula of extended formula in extension knowledge is consistent with the generation formula in AI. It is still static.

The transformation implication formula in extension knowledge is a classical variable knowledge, it is more valuable knowledge for solving a incompatible problem.

So extension knowledge has the character of variable knowledge.

2. Extension data mining   Data mining means mining knowledge from data. The data is static, and it stands for the fact, so the knowledge mining from the data is static too.

2.1. The concept of extension data mining   Extension data mining that mining extension knowledge is the extension of data mining. Data mining can acquire knowledge (condition?result), extension transforming the condition and conducting transforming the result can acquire variable knowledge (extension knowledge):  Tcondition?Tresult It calls this variable knowledge as extension data  mining.

2.2. Extension data mining theory   Theorem 1: for two classes of rules A?P                 (1) B?N                 (2) A??ai?B=?bj  If existing the condition transformation Tcondition: Tcondition(B) =A           (3)  And existing the result transformation Tresult (the conducting transformation of Tcondition):  Tresult(N) =P           (4) Then extension transformation rules (variable  knowledge) T(B)=A?T(N)=P      (5)  also: if T(B)=A then T(N)=P  Theorem 2: for two rules of the same class A?P  C?B?P If existing extension transformation  T(B)=A Then extension transformation  T(B)=A?P         (6) also  if T(B)=A then P   2.3. The process of extension data mining   In extension data mining theory, the steps of extension data mining theory are:  Step 1: Using data mining method to acquire the classification rules for classification problem: formula (1) and (2).

Step 2: Confirm the existing extension transformation in the condition and result of the rules, that means finding out the extension transformation for formula (3) and (4).

Step 3: Using theorem 1 and 2 to acquire extension knowledge (5) or (6).

3. Rough set method of attributes reduction   Mostly the theory of attributes reduction is using the theory of rough set and information. Attributes reduction means reducing the redundant attributes of data base in the condition of not descending the capacity of classification  3.1. Attribute dependency   In data table, the Dependency on the condition attribute  C of the decision attribute D is defined as: ?(C,D)=|Posc(D)|/|U|  |Posc(D)| is the amount of the elements of the positive domain Posc(D).

3.2. Attribute importance   1) Definition of attribute importance C,D attribute set A, C is condition attribute set, D is  decision attribute set, a C, the definition of the importance of attribute a on D is:  SGF(a,C,D)= ?(C,D)- ?(C-{a},D) ?(C-{a},D) is the dependency on the decision attribute  set D of the condition attribute set C after reducing attribute a, SGF(a,C,D) is the proportion of the objects which can not be classified properly after reducing the attribute a in condition attribute set C.

2) The property of SGF(a,C,D) ? SGF(a,C,D)  [0,1].

? if SGF(a,C,D)=0, then the attribute a can be reduced,  because the information in C-{a} still can be classified properly.

?  SGF(a,C,D)?0, then the attribute a can not be  reduced, because the information in C-{a} can not be classified properly any more.

3.3. The process of the attribute reduction   1) Calculate the equivalence set of the condition attribute set (C-{Ci});  2) Calculate the equivalence set of the decision attribute set D;  3) Calculate the positive domain Pos(C-{Ci},D); 4) Calculate the dependency ?(C-{Ci},D); 5) Calculate the importance of Ci: SGF (C-{Ci},D); 6) Reducing the attributes of which the importance is 0.

4. Rough set based attribute reduction and extension transform of the rules   Data base is widely used in information systems.

Classifying the objects into equivalence sets according the decision attribute in data base, hope that identify each decision class by condition attributes, and generate decision rule for each class. Mostly, there are some attributes in data base that are unimportant for the learning task, and hope for finding out a minimum correlative attribute set that have the same capacity of classifying the decision attribute with the whole condition set, and the rules generate from the minimum attribute set are more simple and make more sense.

After getting the minimum attribute set, acquire knowledge by data mining, and the knowledge is static.

Extension transforming the condition and conductive transforming the result can acquire the variable knowledge, and that is extension knowledge: Tcondition ?Tresult. In fact, there are some bad data in data base that affect the quality of data mining, and come up with the rules which are not so reliable, so we must capture the mostly problem when we solve the problem by extension transformation. Now, choose the attribute according the importance which is calculated during the process of attribute reduction, transforming the most important attribute. Because the more the importance, the more support from data, and not being disturbed by noise so easily, so that guarantee the veracity of extension transformation, this method can get more chance to solve the problem directly, and improve the efficiency of the solution.

5. Application instance   Weather information table has four condition attributes (outlook, temperature, humidity, windy) and one decision attribute (play):  TABLE 1 WEATHER INFORMATION TABLE    5.1. Attribute reduction   1) Calculate the positive domain of the condition attributes to decision attribute when reduced one condition attribute:  Pos(C-{outlook})(D)={2,5,9,10,11,13}?U Pos(C-{temperature})(D)=U=PosC(D) Pos(C-{humidity})(D)=U=PosC(D) Pos(C-{windy})(D)={1,2,3,7,8,9,10,11,12,13}?U It shows that attributes temperature and humidity is  omissible to the decision attribute, but not at the same time, and attributes outlook and windy is not omissible to the decision attribute, so:  core(C)={outlook, windy} 2) Calculate the positive domain after reducing the  attributes temperature, humidity at the same time: Pos(C-{temperature,  humidity})(D)={3,4,5,6,7,10,12,13,14}?U It shows {temperature, humidity} is not omissible at  the same time.

3) Just can reduce one of the attributes {temperature,  humidity} each time, so there are two reductions: redD(C)={{outlook, temperature, windy},{outlook,  humidity, windy}} In the calculation of the instance, it shows that the  attribute reduction of the information table is reducing the unnecessary or unimportant attributes in the condition attribute set in the condition of not descend the capacity of classification for the decision attribute. Generally speaking, the reduction of the condition attributes is not just one and only, it may exist several reductions.

5.2 Extension data mining   Choosing the reduced attribute set {outlook, humidity, windy} for rules mining and extension transformation:     1) Calculating the importance to decision attribute for each condition attribute  SGF(outlook,C-{temperature},D)=?(C- {temperature},D)-?(C-{outlook,temperature},D)=5/7  SGF(humidity,C-{temperature},D)=?(C- {temperature},D)-?(C-{temperature,humidity},D)=5/14  SGF(windy,C-{temperature},D)=?(C- {temperature},D)-?(C-{temperature, windy},D)=5/14  2) Rules mining outlook=overcast ==> play=yes outlook=sunny and humidity=normal ==> play=yes outlook=rainy and windy=FALSE ==> play=yes outlook=sunny and humidity=high ==> play=no outlook=rainy and windy=TRUE ==> play=no 3) Extension transformation according to the  importance As the result of the calculation above, the condition  attribute (outlook) is more important than the rest two attributes (humidity and windy) to the decision attribute (play), so considering transform the attribute weather first while solve the problem by extension transformation often can solve the problem more directly.

If extension transforming the rule outlook=rainy and windy=TRUE ==> play=no which acquired above:  (T1(outlook=rainy)=(outlook=overcast)) and (windy=TRUE) ==> T(play=no)=(play=yes)  and (outlook=rainy) and  (T2(windy=TRUE)=(windy=FALSE)) ==> T(play=no)=(play=yes)  Although both of the transformations can change the decision attribute, playing when the weather turns to overcast from rainy is more reasonable than when it turns to no wind from windy.

6. Conclusions   In the data base of information systems, there usually exists some attributes which are unimportant to decision attribute, people hope to find a minimum correlative attribute set which has the same capacity of classification for the decision attribute, the rules generate from the minimum attribute set is simpler and making more sense.

And then extension transforming the condition and conductive transforming the result, acquire the variable knowledge, it is called extension knowledge. In fact, there are some bad records in data base that affect the quality of the data mining, making some rules not so reliable, so we must capture the main problem when we are solving the problem by extension transformation. This paper introduce selecting method of extension transforming attribute according the attributes? importance calculated during the process of the attribute reduction, this method guarantee the veracity of extension transformation, and improve the efficiency of the solution.

