Sliding-Window Filtering with Constraints of Compactness and Recency in  Incremental Database

Abstract    In true-life the database is changed continually in many applications. Incremental mining technique has been developed to avoid rescanning database for knowledge discovery. Recent and compact constraints also are developed for frequent patterns mining. We store the database with a time-vertical bitmap representation, therefore the supports of frequent pattern and recent pattern can be computed fast. Link and bitmap are adopted, so a mass of running time can be saved during incremental mining process. Besides, to mine more efficiently in the incremental database, two concepts of recency and compactness are introduced into sliding-window filtering (denoted as SWF). In essence, an incremental database is divided into several partitions, and a filtering threshold is employed in each partition to handle candidate itemsets generation under constraints of recency and compactness. By employing SWF with constraints of compactness and recency, user satisfactory CFR- patterns (compactness, frequency and recency) can be discovered. Experimental result shows that the running time can be reduced.

Keyword: sliding-window filtering, constraint, incremental mining  1. Introduction   Sequential pattern was first proposed by R.Agrawal as an important KDD research branch [1]. Main task of  *This work is supported by the Natural Science Foundation of Hebei Province P.R.China, NO. F2008000888.

sequential pattern mining is to discover the temporal patterns and the sequential patterns. Some research works which discover frequent sequential pattern have been done in incremental database. Algorithm FUP[2] was proposed to update the association rules when new transactions are added to the database by D.Cheung and J.Han. Algorithm FUP is based on the framework of Apriori and designed to discover the new frequent itemsets iteratively. Algorithm FUP2 [3] extended from Algorithm FUP was proposed by Cheung D W and Lee S D. The existing association rules are updated when transactions are added and deleted from the database.

FUP2 is equivalent to FUP in the case of insertion, however, a complementary algorithm of FUP in the case of deletion. FUP2 avoids re-running the association rule mining algorithm on the whole updated database. Another FUP-based algorithm, call FUP2H, was also designed to utilize the hash technique for performance improvement. But a new frequent itemset Lk is generated in the data subsets, k scans of the database are needed by FUP-based algorithms. So an algorithm based on sliding-window filtering (denoted as SWF)[4] for incremental mining of association rules was proposed by Chang-Hung Lee and Cheng-Ru. Essentially, by partitioning a transaction database into several partitions, algorithm SWF employs a filtering threshold in each partition to deal with the candidate itemsets generation.  SWF can reduce the amount of candidate itemsets efficiently.

Owing to generating the small number of candidate itemsets, the scan reduction technique[5] can be applied efficiently.

Various constraints of user-specific to improve mining efficiency were proposed. Sliding window, maxgap, mingap and maxspan called universal constraints[6] were employed in mining sequence patterns. After time attribute was introduced into   DOI 10.1109/NCM.2008.78     transactions, concepts of compactness and recency[7] were cited under CFR-postfixspan algorithm for sequential pattern mining by Yen-Liang Chen and Ya- Han Hu, but they only were adapted to the fixed database. When the new sequence was added or the old sequence was deleted, the database will be rescanned.

How to represent sequential pattern is a key problem in mining frequent patterns. Bitmap based binary format was employed by Josh-ua Ho. The most powerful feature of SPAM is bitmap data structure for counting sequence supports[8]. Then semi-vertical bitmap representation was presented in SPADE which was a vertical database by Sujeevan Aseervatham et al[9]. The speed of counting supports was improved by using semi-vertical bitmap representation.

Many candidate itemsets were generated by SWF algorithm, but they weren?t demanded by user. In this paper compact and recent constraints will be introduced into SWF in incremental mining. So the compact frequent recent itemsets can be obtained by user-specific. And the time-vertical bitmap which employs binary format will be developed for the database representing. The running time can be reduced for counting compact and compact recent supports.

The rest of the paper is organized as follows: the section 2 discusses the construction of time-vertical bitmap. Section 3 describes algorithm CR-SWF by an example. Section 4 shows the experimental result.

Finally, a conclusion is given in Section 5.

2. Construction of time-vertical bitmap   Let S=<(b1, t1), (b2, t2), . . . , (bn, tn)> be a sequence with time attribute. A data sequence is sorted first by time, then by alphabet. Let I =<(I1,tI1),(I2, tI2). . .(Is, tIs)> be a subsequence of S. Let m_span be the user- specified maximum span and tR be the user-specified minimum recent threshold.

P is a compact frequent pattern(CF-pattern) if tIs- tI1?m_span and P?s support is no less than a predefined minimum frequent support threshold, denoted as F. P is a compact recent pattern (CR-pattern) if tIs-tI1? m_span and P?s recent support is no less than a predefined minimum recent support threshold, denoted as R. If P is CF-pattern and CR-pattern, then P is CFR- pattern (compactness, frequency and recency ).

2.1. Construction   A time-vertical bitmap is defined as follows: ?.It consists of a header table and item tables.

?.The header table has two fields: p_partition and p_link: p_partition records the number of items? partition and p_link is linked the item of sequence.

?.The item table has five fields: s_item, s_sid, s_bit, s_time, s_link: s_item records the name of the item.

s_sid is the identifier of sequence. The length of bit is equivalent the sequence?s, the bit of item bi is set to one, the rest are set to zero. s_time records timestamps of item bi. All items of the same s_sid are linked in s_link.

Based on the definition, construction algorithm of time-vertical bitmap is as follows: Algorithm 1: Time-vertical bitmap construction Input: sequence database DB of partitions n.

Output: time-vertical bitmap TVB Method: 1. Create the header table: the p_link is labeled as  ?null?.

2. Scan the database, create the item table of the first item in sequence database and the item table is linked behind the header table.

3. for (i=1;i<=n;i++) 4. Call insert_function(TVB,Pi) 5. end insert_function(TVB,Pi): 1.P is the pointer of pointing first item in TVB.

2.For each item bj?Pi 3.{While(P!=null) 4. {If item bj=P.s_item then 5. {Item bj?s detail information is recorded in item  table of item bj.

6.   P points the first item of TVB.

7.      j++; } 8.  Else if item bj >P.s_item then 9.         P++; 10.     Else { create item table of item bj.

11.         item bj is inserted before P.s_item.

12.         P points the first item of TVB.

13.           j++;}} end while 14.  create item table of item bj.

15.  item bj is inserted behind all items.

16.  P points the first item of TVB.

17.     j++; } 18. end  All items of the database are linked in the time- vertical bitmap by the dynamic link. The dynamic link is much more convenient than the ordinal table in the case of insertion or deletion. The running time can be reduced for counting compact and compact recent supports. So the total running time can be reduced effectively.

Table1. A sequence database  partition sid sequence P1 1 <(a,1),(c,3),(d,6),(e,10),(f,10),(     b,15) > 2 <(b,7),(d,9),(f,14)> 3 <(a,10),(e,13),(d,17)>  P2 4 <(a,5),(b,10),(f,10),(d,13),(e,1 5)>  5 <(a,15),(b,17),(c,18),(f,20),(e, 22)>  6 <(b,11),(f,19)> P3 7 <(a,14),(d,16),(e,17),(f,20)>  8 <(a,10),(b,13),(d,14),(f,16)> 9 <(a,7),(f,9),(d,13)>   The partition P2 of table 1 is shown in Figure1. The  number of partition is 2. For item a s_item, s_sid, s_bit, s_time are a, 4 and 5, {10000} and {10000}, 5 and 15 respectively. So do the other items. All items of the sequence 4 are linked in s_link. Owing to being restricted by space, the part of time-vertical bitmap is given.

p_partition p_link   s_item s_sid s_bit s_time s_link a 4 10000 5  5 10000 15   s_item s_sid s_bit s_time s_link b 4 01000 10  5 01000 17 6 10 11    s_item s_sid s_bit s_time s_link c 5 00100 18   s_item s_sid s_bit s_time s_link d 4 00010 13  s_item s_sid s_bit s_time s_link e 4 00001 15  5 00001 22   s_item s_sid s_bit s_time s_link f 4 00100 10  5 00010 20 6 01 19 null  Figure 1. Data storage representation  2.2. An example   Give a time-vertical bitmap of database DB (shown as figure 1). For counting compact support value, iff (tm-t1?m_span) ?(s_sid of items are same), the count is added by 1. For counting compact recent support value, iff (I is a compact subsequence in S) ?(tm?tR) , the count is added by 1.

Consider the partition P2 of database shown in figure 1, tR=11 and m_span=9. The compact support count of the sequence<(a)(b)> is 2 (in the data sequences 4, and 5), while the compact recent support count of the sequence <(a)(b)>is 1 (in the sequence 5 ).

The subsequence <(a,5),  (b, 10)> contained in the  sequence 4 cannot be counted, because the timestamp of item b is smaller than tR.

3. Sliding-Windows Filtering with compactness and recency (CR-SWF)   By dividing the database into n partitions, Algorithm CR-SWF processes orderly each partition under considering the compact constraint. Then compact frequent and compact recent filtering thresholds are used in each partition to deal with candidate itemsets.

3.1. Processing original database procedure  Algorithm 2: processing original database Input: original database with time-vertical bitmap Output: compact frequent recent large k-itemsets 1. n = the number of partitions, CI=? ,  1, n k 1, n kdb P==? 2.begin for k = 1 to n  // 1st scan of db1,n 3.  begin for each 2-itemset I ?  Pk 4.   if ( I?  CI) 5.     f.count=n_cf(I), r.count=n_cr(I) ; 6.     I.start=k ; 7.    if ( f.count ? kF  |P|? ??? ?  && r.count ? kR |P |? ??? ? ) 8.      CI = CI ?  I; 9.   if ( I ?  CI ) 10.     f.count + =n_cf(I), r.count + =n_cr(I); 11.    if ( f.count < m=I.start,k mF P  |P |? ??? ?   r.count <  m=I.start,k mR*P  |P |? ?? ?   ) 12.   CI = CI ? I; 13.  end 14.end 15. keep C1,n2 in main memory; 16. scan reduction technique[5].

17. f.count =0, r.count=0 where I ?  C1,nh (h?2); 18.begin for k = 1 to n   //2nd scan of db1,n 19.   for each itemset I ?  C1,nh 20.    f.count + =n_cf(I), r.count + =n_cr(I); 21. end 22. for each itemset I ?  C1,nh 23. if ( f.count ? 1,nF |db |? ??? ?  && r.count ? 1,nR |db |? ??? ? ) 24.   Lh = Lh ?  I; 25. end  In algorithm 2, each partition is processed under compact and recent constrains from Step 2 to Step 12.

C stands for candidate itemset, L stands for large itemset. n_cf(I) and n_cr(I) are the number of compact itemset Ic and compact recent itemset Icr in Pk     respectively. The total number of each compact itemset Ic and compact recent itemset Icr are recorded in f.count and r.count respectively. And the starting partition of itemset I is recorded in I.start. Itemsets which meet constraints and support thresholds will be kept in CI.

After the scan reduction technique is employed, C1,nh s (h ? 3) are saved in CI. By the last scan of database, compact frequent recent itemsets are generated.

Consider the original database shown in table 1.

First, the database is divided into three partitions P1, P2 and P3. The minimum support thresholds of frequency and recency (F and R ) are set to 0.4. The maximum compact span is set to 9 (m_span=9) and the minimum recent time is set to 10 ( tR=10).

During partition P1 is handled, each candidate 2- itemset whose f.count ?2( 0.4*3? ?? ? ) and r.count ?2( 0.4*3? ?? ? ) will be save into CI. Similarly, after scanning partition P2 ? the support thresholds of itemsets which generated from the P1 are 3( (3 3)*0.4? ?+? ? ). The support thresholds of new itemsets which generated from P2 are 2( 0.4*3? ?? ? ). After the P3 is processed orderly, the support thresholds of itemsets which generated from P1 are 4( (3 3 3)*0.4? ?+ +? ? ). The generated 2-itemsets are shown in table 3. Finally, after scanning the database from P1 to P3, seven 2-itemsets of those eight candidate 2-itemsets meet the constraints and the support thresholds. The large 2-itemsets are {ad,ae,af, bf, de, df, ef, }. Large k-itemsets are shown under the table 3.

Table 2. Candidate 2-itemsets after scanning P1  C2 start f.count r.count a,e 1 2 2 b,f 1 2 2 d,e 1 2 2 d,f 1 2 2   Table 3. Candidate 2-itemsets generated after  orderly scanning partitions P2 and P3 C2 start f.count r.count a,d 3 3 3 a,e 1 4 4 a,f 2 5 4 a,b 2 3 3 d,e 1 4 4 d,f 1 6 6 e,f 2 3 3 b,f 1 6 6   Compact recent large k-itemsets in original database are{a},{b},{d},{e},{f},{a,d},{a,e},{af},{bf},{de},{df} , {ef}, {adf},{bdf}.

Table 4. Sequences which are added partition sid sequence P4 10 <(a,6),(f,13)>  11 <(c,5),(f,11),(b,19)>  12 <(f,3),(a,7),(c,10)> P5 13 <(b,12),(d,15)>  14 <(d,4),(b,10),(f,13),(c,20)> 15 <(b,6),(c,10),(e,11),(f,14)>   3.2. Processing incremental database procedure  Algorithm 3: processing incremental database Input: incremental database with time-vertical bitmap Output: compact frequent recent large k-itemsets 1.Original database = dbm,n= ?k=m,nPk; 2.New database = dbi,j=?k=i,jPk; 3.Database removed ?? = ?k=m,i?1Pk; 4.Database added ?+ = ?k=n+1,jPk; 5.dbi,j = dbm,n ??? +?+; 6.loading Cm,n2 of dbm,n into CI where I ?  Cm,n2 ; 7.begin for k = m to i ? 1 // one scan of ?? 8.  begin for each 2-itemset I ?  Pk 9.    if ( I ?  CI && I.start ? k ) 10.     f.count?= n_cf(I), r.count?=n_cr(I); 11.      I.start = k + 1; 12.    if ( f.count < m=I.start,n mF  |P |? ??? ?? ??   r.count <  m=I.start,n mS |P |? ??? ?? ?? ) 13.     CF = CF ? I; 14.   end 15. end 16.  Call Algorithm 2; 17.  end  In the algorithm 3, the total number of compact itemset Ic and compact recent itemset Icr  are subtracted respectively in deleting partitions. Itemsets which don?t meet constraints or support thresholds are removed.

Then the algorithm 2 is called for adding partitions. By some updating operations, the partition P1 is removed from the original database db1,3 and new partitions P4, P5 are added. The result is shown in table 5 and table 6.

Table 5. Compact frequent recent 2-itemsets  after deleting partition P1 C2 start f.count r.count a,d 3 3 3 a,f 2 5 4 a,b 2 3 3 d,f 2 4 4 e,f 2 3 3 b,f 2 4 4   Table 6. Compact frequent recent 2-itemsets  after adding partitions P4 and P5 C2 start f.count r.count a,f 2 7 5 b,d 5 2 2 b,f 2 7 7 c,f 4 4 4     d,f 2 5 5 Large k-itemsets of compactness and recency after scanning incremental database are {b},{d}, {f}, {af}, {bf},{cf},{df}.

4. Experimental result   The experiment was performed on Intel Core(TM)2 2.2GHz with 2GB memory, running on Windows XP. We use synthetic data to form database.

We use three datasets,T.I.D100K.C10%, T.I.D100K.

C30%, T.I.D 100K.C50% in the experiment where T is the mean size of a transaction, I is the mean size of potential maximal large itemsets, D is the number of transactions in units of K, and C is the correlation between items in terms of percentage. To conduct expediently the experiment, recent minimum support and frequent minimum support are set to the same value.

From the figure 2, the number of candidate itemsets is increasing along with the support thresholds reducing gradually. Apparently, CR-SWF outperforms SWF under different support thresholds. Because the inputted data is stored with time-vertical bitmap, and the compact and recent constraints are employed in CR-SWF, a lot of dissatisfactory candidate itemsets can be avoided generating. So the running time can be saved.

0.1 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.2  support thresholds  e x e c u t i o n  t i m e ( s e c )  SWF CR-SWF  Figure 2. The performance comparison between CR-SWF with time-vertical bitmap and SWF   5. Conclusions   In this paper, the inputted data are represented with time-vertical bitmap in the incremental mining algorithm. The time-vertical bitmap employs link and bitmap. Link is beneficial to handle data in the case of insertion or deletion. And the running time of  computing frequent support and recent support can be reduced effectively. By employing constraints of recency and compactness, large numbers of dissatisfactory candidate itemsets can be avoided generating. The experiment result shows that algorithm CR-SWF outperforms algorithm SWF when the database is mined incrementally. The size of produced candidate sequential base can be much smaller than traditional mining algorithm along with supports reducing, so the time spending is much less.

6. References  [1] R. Agrawal and R. Srikant, ?Mining sequential patterns?,  In Proc.11thICDE, Tai Pei, China, 1995, pp.3-14.

[2] Cheung D W and J.Han el a1, ?Maintenance of  discovered association rules in large databases: An incremental updating approach?, The 12th IEEE pp.106-114.

[3] D. Cheung, S.D. Lee, and B. Kao, ?A General Incremental Technique for Maintaining Discovered Association Rules?, Proceedings of the Fifth Advanced Applications, Melbourne, Australia, 1997, pp.185-194.

[4] Chang-Hung Lee, Cheng-Ru Lin and Ming-Syan Chen, ?Sliding-window filtering: An Efficient Algorithm for Incremental Mining?, Proceedings of the tenth management Atlanta, Georgia, USA, 2001,pp. 263-270.

[5] J.-S. Park, M.-S. Chen, and P. S. Yu, ?Using a Hash- Based Method with Transaction Trimming for Mining and Data Engineering, 1997, 9(5):813- 825.

[6] Jian hua Li and Xiao feng Wang, ?Mining Sequence Patterns with Universal Temporal Constraints?, MNI- MICRO SYSTEMS, 2005, 26(6): 1004-1009.

[7] Yen-Liang Chen and Ya-Han Hu, ?Constraint-based sequential pattern mining: The consideration of recency and compactness?, Decision Support Systems,2006, 42(2): 1203-1215.

[8] Joshua Ho, Lior Lukov, and Sanjay Chawla, ?Sequential Pattern Mining with Constraints on Large Protein Data COMAD 2005b, Hyderabad,India,2005.

[9] Sujeevan Aseervatham, Aomar Osmani, and Em manuel Viennet, ?bitSPADE: A Lattice-Based Sequential Pattern Mining Algorithm Using Bitmap Representation?, Proceedings of the Sixth (ICDM'06), 2006, pp. 792-797.

