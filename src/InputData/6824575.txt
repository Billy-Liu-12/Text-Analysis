Pushing the Limits in Event Normalisation to Improve Attack Detection in IDS/SIEM Systems

Abstract?The current state of affairs regarding the way events are logged by IT systems is the source of many problems for the developers of Intrusion Detection Systems (IDS) and Security Information and Event Management (SIEM) systems. These problems stand in the way of the development of more accurate security solutions that draw their results from the data included within the logs they process. This is mainly caused by a lack of standards that can encapsulate all events in a coherent way. As a result, correlating between logs produced by different systems that use different log formats has been difficult and infeasible in many cases. In order to solve the challenges faced by Correlation Based Intrusion Detection Systems, we provide a platform for normalising events1 into a unified super event loosely based on the Common Event Expression standard (CEE)[1] developed by the Mitre corporation[2]. We show how our solution is able to normalise seemingly unrelated events into a unified format.

Additionally, we demonstrate queries that can detect attacks on collections of normalised logs from different sources.



I. INTRODUCTION  A. Event Sources  Security and operations related events can occur in a variety of places within a network environment. Generally, every computerised device is a potential source for events. Since Security Information And Event Management (SIEM) and Intrusion Detection Systems (IDS) aim to detect unauthorised intrusions into a network environment, they generally oper- ate on the events produced by network-enabled devices. A network-enabled device can further be subdivided into hosts and other low-level hardware. A host on its own has again multiple sources for events on different levels of operation, i.e. on the operating system level and the software level[3].

Operating Systems A fundamental event source on a host  is the operating system. Its core, i.e. the system kernel, has the highest privileges and can therefore provide valuable information on the current system state as well as all kind of operations performed on the system. This includes, but is not limited to, the hardware configuration and state, allocated system resources and many types of security-related operations, such as authentication and authorisation.

Software Applications generate nearly endless events relating to as many different conditions and are therefore another rich source for event information gathering.

1All events that are supported by the system. Events currently not supported can be processed once the knowledge base is updated to know about their specifications.

Hardware This category encompasses devices that are not host computers in the usual sense, i.e. they run with a static software configuration delivered by a pre-installed firmware. Devices that fall into this category are network infrastructure devices, such as routers or switches, and peripherals, such as printers or VOIP telephones. Event information from infrastructure devices are especially valuable for SIEM/IDS systems, because they control access to nodes in the network.

B. Event Persistence  Event sources use different mechanisms and formats for persisting events. The employed mechanisms are usually the persistence of events directly into files, databases or the delegation of persistence to a remote server (e.g. a Syslog server). Persisting events to a Database (SQL based) results in a structured format and is therefore preferred for SIEM/IDS systems. However, application developers generally use files (i.e Log files) to record their application?s events because databases increase the application?s complexity and dependen- cies. Log files provide a challenge in the sense that, often, no real structure is provided because there is typically only a single stream of characters. Therefore, the serialisation of multiple events, each with a variety of attributes, is not trivial and usually not common between different event sources.

There are differences on how multiple event logs are separated in a single file and how a single event is represented as a character stream. The following subsections take a closer look on these two issues related to the persistence of events in files.

In order to include multiple event logs into a single file, they have to be separated in such a way that a user can identify all individual events that were serialised as logs into the log file.

There are a number of common strategies to implement this separation.

Line-by-Line Separation A popular way of separating event  records is to put one event per line. This can be observed in e.g. log files of Syslog or Apache HTTP Server.

Examples for line-separated log lines can be seen in Listing 1 and 2.

Listing 1: Excerpt of a Syslog log file taken from Honeynet COTM 34[4] Feb 11 13:23:41 combo xinetd: xinetd startup succeeded Feb 11 13:23:42 combo sm: sendmail startup succeeded Feb 11 13:23:43 combo sm: sm-client startup succeeded Feb 11 13:23:45 combo sa: spamd startup succeeded   DOI 10.1109/CBD.2013.27     Listing 2: Excerpt of an Apache log file taken from Honeynet COTM 34 69.246.7.31 - - [14/Mar/2005:11:12:43 -0500] "GET /  scripts/..%252f../winnt/system32/cmd.exe?/c+dir HTTP/1.0" 404 1041 "-" "-"  67.170.0.153 - - [14/Mar/2005:14:10:36 -0500] "GET / scripts/root.exe?/c+dir HTTP/1.0" 404 1041 "-" "-"  Delimiter Separation A more general way of separating event records is to use a delimiter. An event record can then simply be extracted by splitting the file stream at these delimiters. To prevent collisions with text content in the event records, a delimiter should be a character sequence that is not present in the log events. The previously mentioned new line separation is a special case of this mechanism, i.e. it uses new line (\n) as a separator.

This delimiter is illustrated in Listing 3.

Listing 3: Separation of lines with newline characters (\n) in Syslog Feb 11 13:23:40 combo kernel: ip_tables: (C) 2000-2002  Netfilter core team\n Feb 11 13:23:41 combo xinetd: xinetd startup succeeded\  n  Another common delimiter string is the usage of double new lines (\n\n), when single event records are dis- tributed over multiple lines. One example of this pattern can be seen in Listing 4.

Listing 4: Separation of lines with doubled newline characters (\n\n) in SAP NetWeaver logs ...

MSG_TXT="OS Collector is not running" MANDT="" SAPUSERID="" EXTLID=""  .\n \n OLD_ALERT NAME="\###\NW1_NWT_00\OperatingSystem\OS_Collector\  State" ...

Pattern Separation Although new lines and doubled new lines are the most common schemes for separating events, other, more complex cases exist as well. One such excep- tion are log formats that separate their lines by predefined patterns, such as the Tomcat application server. In this log format each event starts with a line that specifies its date and origin. All following lines then give additional infor- mation about the event, such as importance, ip address of hosts involved, et cetera. The distinction between them is only possible by looking at the format of the first group of lines until the start of the next group. Listing 5 shows an excerpt from an Apache Tomcat log file.

Listing 5: Log files from a Tomcat application server Feb 10, 2012 11:44:49 AM org.apache.coyote.

AbstractProtocol pause INFO: Pausing ProtocolHandler ["ajp-bio-8009"] Feb 10, 2012 11:44:49 AM org.apache.catalina.core.

StandardService stopInternal INFO: Stopping service Catalina  Structuring Other exceptions are formats that use structures to incorporate multiple events into one stream. A popular use for this is to serialise events with the help of XML Objects. e.g Microsoft?s event log format, as shown in Listing 6.

Listing 6: Logs from Microsoft Event Viewer <Event xmlns="http://schemas.microsoft.com/.../events/  event"> <System> <TimeCreated SystemTime="2013-04-08T13 :55:07.653212000Z"/> <EventRecordID>1541105</EventRecordID>  </System> </Event> <Event xmlns="http://schemas.microsoft.com/.../events/  event"> <System> <TimeCreated SystemTime="2013-04-08T13 :55:07.653212000Z"/> <EventRecordID>1541104</EventRecordID>  </System> </Event>  Event Record Serialisation The serialisation of a single event in a file stream is another issue in the persistence of events. Basically, an event log can be in any format, but people came up with a number of standards to improve interoperability and simplify automated processing of log files. Regardless of these standards, there is still a magnitude of log sources that use their own format for an event log. Generally, there are three categories of event log formats, which are as follows.

Structured In a structured log format, every information  has a clear location and meaning. Every piece of infor- mation has a machine-readable value and specifically no natural-language phrases, as shown in the example in Listing 7. Having logs in a structured format can be seen as the best case, as it does not require complex parsing and allows to extract information fast and effi- ciently. Examples for such fully structured formats are the common standards CEE[1] and Intrusion Detection Message Exchange Format[5]. Further examples in the field of web server logging are the Common/Combined Log Format[6] (CLF) and Extended Log Format[7].

Two fully structured application logs are e.g. from iptables[8] or SAP NetWeaver.

Listing 7: Structured log from Apache 67.170.0.153 - - [14/Mar/2005:14:10:37 -0500] "GET /  c/winnt/system32/cmd.exe?/c+dir HTTP/1.0" 404 1041 "-" "-"  Unstructured In an unstructured log format, the infor- mation is not organised in dedicated fields, but it is rather written as natural language phrases, as shown in Listing 8. This log format can often be found in smaller application logs, where there is not much attention paid to the machine-readability of log files, but rather for informational purposes for the user. One example for unstructured log information is the MSG field in Syslog. Syslog itself is a log protocol and writes out messages in a structured format, but its message field can contain arbitrary information from the application using the Syslog protocol. By looking at Syslog log files, it turns out that many applications are passing unstructured text as part of the MSG field.

Listing 8: Unstructured log from sshd Accepted password for root from 59.120.2.133 port  57019 ssh2     Semi-Structured A semi-structured log format contains both fully structured information and unstructured parts. Basically, semi-structured formats have all their information organised in dedicated fields, but there are some fields which do not contain structured data, i.e.

they contain natural-language phrases. Examples for semi-structured log formats are Syslog and Snort[9] Syslog output, as shown in Listing 9.

Listing 9: Semi-structured log from Syslog [1:2003:8] MS-SQL Worm propagation attempt [  Classification: Misc Attack] [Priority: 2]: {UDP } 64.126.26.10:3123 -> 11.11.79.83:1434  Single-Line vs. Multi-Line Often a single event is repre- sented using multiple log lines (i.e. separated by new line characters). This can be done in two cases, firstly when an event is meant to be read and interpreted by a human administrator and can not be expressed in a reasonably sized single log line. In this case the log is formatted into multiple lines that are all persisted at once as a single event. Second case is true when an event is logged over a period of time. An example is when a download is occurring and the application creates a new log every time the process has progressed by 10%. Another more concrete example is the Sendmail[10] application which creates multiple logs for representing a single event.

There can be other logs inserted in the meantime, so not all logs relating to a single event are persisted at once, as is the case with formatted logs. Applications such as Sendmail often include a Relational Identifier that allows for different logs to be added up and create a coherent representation of a single event. Examples for multi-line logs can be seen in Listing 10 and 11.

Listing 10: A multi-line event with a weak structure TIME:00:00:00 DATE:00:00:0000 MSG:System X is having longer than expected delays  serving pages CAUSE: Network Device 1 has lost connection to the  network ACTION: System administrator(s) were informed through  admin@server.serv STATUS: System X shall await maintenance  Listing 11: A multi-line event with a strong structure OLD_ALERT NAME="\###\Java Instance: NW1_NWT_00\Java Heap Memory  \Memory of server0\Size Local Objects" LAST_STAT_CHNG_AT=1349087960 LAST_STAT_CHNG_BY="  ALJSFLIB" MSG_CLASS="SAP-T100" MSG_ID="CCMS_AGENT 035" MSG_TXT="&1 &3 > &2 &3 last reported Value above  threshold" TYPE0=INT4 VAR0="753770" MANDT="" SAPUSERID="" EXTLID=""  .

C. Challenges in Event Normalisation  The above structure of a persisted event shows the variations in log files. The nature of these formats and the differences be- tween them make normalisation a challenging task. Following is a list of selected major challenges.

Level of details Comparing different log formats, the lim- itations of individual log formats becomes clear. For example, Windows Event Log can be considered to be structured in favour of software debugging, and while CEE offers limitless arbitrary fields to be added to it, it does not provide a standardised method of logging even the most basic debugging related events.

Missing Structure There are various log formats, such as Syslog or Snort, that are partly or completely unstruc- tured. This unstructured information is a challenge in event normalisation, because it cannot be directly mapped to event fields. One of these examples is the MSG field in Syslog.

Completeness Even when information in a log format is completely structured, an isolated event often does not provide enough information to be interpreted correctly.

Examples for missing information are details about the log producer, the source and target of an activity and sometimes even the exact time when the event was observed2.

D. Motivation  Having a look at the variety of log formats used by event sources, it is self evident that there is no clear standard for logging and no agreement on what information is necessary to make a log useful for log analysis. Existing SIEM systems on the market, like Splunk[11], ArcSight[12], Prelude[13] and RSA envision[14], do not widely use standardised formats or use standards that are only focused on alert (i.e. events solely focused on system and network security) representation.

In fact, ArcSight has created its own format which is not widely used. Recognising the considerable effort already in place to solve this issue[15], [16], [5] and to provide a meaningful contribution to this effort, we look at a vast array of such SIEMs in order to build a proposal based on the now discontinued standardisation efforts[1] driven by Mitre and its partners in the CEE specification. Our aim is to better define the needs of separate sections of the IT industry and the logs they produce in order to better integrate them within a single all encompassing format and in the hopes of reaching a single and highly regulated log format in order to aid with the needs of network security and operational monitoring systems. In this paper we focus on the current capabilities of our system in its current state and speculate about its future capabilities in the Future Work section.

E. Related Work  As the normalisation of events is an ongoing topic especially for the purpose of incident management, there is a lot of effort in providing standardised formats for the persistence of event data, especially for vendors in the IDS domain.

Various working groups, such as Incident Object Description and Exchange Format Working Group (IODEF WG) and the Extended Incident Handling Working Group (INCH WG) and The MITRE Corporation, have provided standards for  2Syslog does not provide the year in the time field of its log lines     incident serialisation, such as the Incident Object Description and Exchange Format (IODEF)[16], the Intrusion Detection Message Exchange Format[5] (IDMEF). The problem with these incident formats is their limitation to cover alerts only.

However, if security breaches have to be analysed further by inspecting postmortem activities, normal and usually non- critical activities, like accessing a file become more interesting.

Looking at the side of log management in general, this can help to overcome limitations in the incident formats. Actually, there are a few approaches for log normalisation attempts that originated from software products, as well as standardisation institutions. Examples for formats from software products are ArcSights Common Event Format (CEF), which was proposed as a standard in a white paper[15] by Hewlett-Packard. The ArcSight format introduces a flat hierarchy of properties and is composed of a set of typical event properties. Two examples that are limited to web servers are the Common Log Format and the Combined Log Format[6] (CLF), which were both introduced with the Apache web server. Two more generic approaches for event formats are given by MITRE, which propose the two specifications Common Event Expression[1] (CEE) and the Cyber Observable eXpression[17] (CybOX).

The CEE is a promising format, because it provides a basic set of common event properties and can further be easily extended with more event properties, as needed. The CybOX format on the other hand, is a very complex format that covers most activities one could imagine into one big format.

Nevertheless, the CybOX format seems too bloated to be effectively used in a production environment. In addition to standardisation bodies, researches have investigated ways to normalise events in the most efficient way. Avourdiadis and Blith[18], [19] propose the fusion of existing XML-based formats, such as IODEF, IDMEF and the Format for INcident Information Exchange[20] (FINE), into one database. In this database, a core section holds common data between incident messages and an extensible section can hold additional non-common data from various formats. The mapping of XML elements to database fields is described by an XML document.

The limitation of incident messages in XML formats is a big limitation in this approach, because formats like Syslog are not fully structured and therefore make it hard to map all available information. The authors do not mention how to solve the mapping of unstructured data.

F. Contribution  The main drive behind this research has been to provide a solution for a SIEM/IDS system being developed at the Hasso Plattner Institute, called the Security Analytics Lab (SAL)[21].

The purpose of the SAL project is to build a system that can provide deeper monitoring and analytics for systems across the network. One element necessary for the functioning of the system is its ability to read arbitrary log files and to generate unified events that incorporate all the information gathered from those logs while adding more information where relevant and possible. This paper demonstrates a working example of an event/log unifying system that is capable of using human knowledge as well as information embedded inside  the logs in order to produce a normalised event representation model. It can be used to correlate between events produced by different sources inside a network. The process of creating and populating these events with accurate event information, using Named-Group Regular Expressions (NGRE) and a knowledge base, is described. The system provides the possibility of detecting simple and complex attacks across an array of different applications often using simple SQL queries run on unified representations of the different log types. The Honeynet Challenge 34 (HN34)[4] package with 260k log lines was used to demonstrate the possibilities the new system provides.

G. Terminology 1) Event: An event generated by a computer. For the purposes of this paper  the focus is mostly on events generated by network enabled devices.

2) Event Representation Model (ERM): The way in which an event is  represented and persisted. Often events are expressed by the systems? developers by outputting human readable string stating the various properties of the event that has occurred.

3) Unified Event Representation Model (UERM): A unified ERM which is ideally a superset of all ERMs.

4) Log: (e.g. Syslog) A concrete way of persisting events for future consumption.

5) Object Log Format (OLF): A concrete implementation of a UERM, based on CEE[1] and designed as part of this research.

6) Operating System (OS) 7) HoneyNet Challenge (HN) 8) Named-Group Regular Expression (NGRE)

II. EVENT NORMALISATION  Throughout this paper, the format, syntax and method of persistence of an event is referred to as a Unified Event Representation Model (UERM). Often, mapping elements from one UERM to another can be imperfect. This can be because the two models do not have a logical connection between some elements within them, or, that an element in one model simply does not exist and is not represented by the other. As a result, high flexibility while maintaining a unifying structure is a requirement of any modern and standardised log format. CEE has been able to provide this flexibility by allowing templates (profiles) to be laid on top of what is called the Core Profile[22]. The Core Profile of CEE consists of the most basic elements which are deemed absolutely necessary for any log entry. These elements include information about the event producer, the time the event has occurred and more. Leveraging this layout, software vendors are able to design their own profiles and lay them on top of the core profile of CEE. Having considered many possible UERMs[cee][cef][iodef][idmef][cybox] for use with the SAL system, problems were found with each UERM that prevented its use. Among these problems are the lack of openness for the UERM (i.e. new fields could only be added by the vendor) and missing essential features/elements (e.g. lack of support for common security fields such as the CVE[23]) needed to encapsulate other UERMs like Syslog, Apache log, etc. In the end, CEE was selected as it was an open UERM and aspires to become a world-wide standard. During the development process of the SAL platform, it became more and more clear that SAL needed far more features and elements than CEE was able to provide. At the same time, massive changes to the CEE standard were performed regularly, which made it hard to rely     on for normalisation. As part of this paper, an extension for persisting security events is proposed and the design decisions and process will be outlined. Examples are given in order to demonstrate the way such a UERM would be used to encapsulate legacy and modern log formats. Throughout this paper, a security event is defined as an event that encapsulates any event that is related to the CIA (Confidentiality, Integrity and Availability) of the system it represents.

A. Extracting Event Information from Logs  The complexities of automatically extracting relevant infor- mation presented in a log line that is written by a human are apparent early on. The main issues arise from dealing with unstructured content often written by humans and meant to be consumed by humans. Listing 12 is an example of such a log.

Listing 12: Natural language used in log line [Sun Mar 13 22:11:45 2005] [error] [client 220.110.29.27]  client sent HTTP/1.1 request without hostname (see RFC2616 section 14.23): /  Although some parts of the log can be said to be loosely structured, parts like ?client sent HTTP/1.1 request without hostname (see RFC2616 section 14.23): /? provide important information which, if understood by a machine, could lead to automatic discovery of patterns relevant for security analysis. A solution that has been implemented by current SIEM systems is to analyse all logs that have the same type together. This method has clear deficiencies. One example is the emission of important cross reference information from the analysed dataset. If a given log produced by one app has a connection to another log line produced by another app, then this information will be ignored. In order to overcome this challenge, a log format was designed that could encapsulate most (if not all) other log formats. The idea is to perform analysis on a single unified set of structured log information as opposed to separated sets of log lines each with their own format. In order to be able to read logs from the source and to understand and convert them into another format, regular expressions with named capturing groups were used. NGREs were first introduced by Perl and have recently (Java 1.7) been added to the standard Java API. By using NGREs, it is possible to extract every bit of information from a log line while intelligently assigning them to their mapped attribute within the unified log format. An example of a complex log line produced by the Apache application is shown in Listing 13.

Listing 13: Example of an Apache access log 141.89.226.146 - - [16/Apr/2013:17:05:28 -0400] "GET /static  /jquery/bmi.html?height=175&weight=75 HTTP/1.1" 200 958 "http://small-tools.com/" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0"  Apache is an easy example when it comes to extracting information from logs, as it presents its information in a struc- tured manner. By reading the details of Apache?s Combined Log Format specification, it is possible to write a single NGRE capable of matching all possible outputs of one of the most widely used web servers in the world. In Listing 14, one  NGRE capable of handling virtually all access logs generated by the Apache web server is presented. Although it may look complicated, it is important to remember that this line needs only to be written once, and thereafter it can be used by millions of users, none of which would need to know what a NGRE is or how it operates.

Listing 14: Regular expression used to process log lines generated by Apache (?:(?<network.srcIpv4>(?:[0-9]{1,3}\.){3}[0-9]{1,3})|(?<  network.srcIpv6>[:\-0-9a-fA-F]+?)|(?<network.srcHost >.+?)) - (?:-|(?<user.username>.+)) \[(?<time>.*)\] \"(?<application.cmd>(?<application.http.method>[A-Z]+) \s(?:(?<application.proto>.*?)://)?(?<network.fqdn >[?/]*?)(?:\:(?<network.dstPort>d+))?(?<file.path>/.*?) ?(?:\?(?<application.http.queryString>.*?))?(?: HTTP /(?<application.http.version>[0-9\.]+)?))\" (?< application.http.status>\d+) (?<application.len>\d+)(?: "(?:-|(?<application.http.referrer>.*))")?(?: "(?:-|(?<application.http.userAgent>.*))")?

After applying the named regular expression from Listing 14 to the log in Listing 13, we end up with the list of key-value pairs shown in Table I.

TABLE I: Key/Value pairs of matched fields in the Apache log  Key Value network.srcIpv4 181.77.240.127 time 16/Apr/2013:17:05:28 -0400 application.http.method GET network.fqdn - network.dstPort 80(default value) file.path /static/jquery/bmi.html application.http.queryString height=175&weight=75 application.http.version 1.1 application.http.status 200 network.ether.len 958 application.http.referrer http://small-tools.com/ application.http.userAgent Mozilla/5.0 ... Firefox/20.0  It is trivial in most modern programming languages to convert such a list to a structured object in a highly efficient manner. In Section IV, some basic performance benchmarks are given to provide a general idea regarding the feasibility of the methods used in this paper. A more comprehensive and fair comparison would require using multiple implementations from different programming languages and their frameworks running over neutral hardware, and is hence outside the scope of this paper.

B. Building New Events From a Normalised Event  In the previous section the process of extracting logical objects from arbitrary events, through matching them with NGREs was demonstrated. In this section the process of building a unified event from the processed events is described.

1) Defining Static Fields: The results of NGRE matching highly depends on the event instance being matched. The more information inside the event, the more details can be extracted and mapped to their representative values in the new unified log format. In instances where considerable informa- tion is missing from the event instance, human knowledge can greatly help in adding the missing information. In order to facilitate this idea, a subsystem was developed with the purpose of adding human knowledge to a unified event. This system (knowledge base), uses a table to store this information     alongside the NGREs used to match the event being processed.

Once a match is made, the information in the knowledge base is used to help build the instance of a unified event.

Information extracted from an event using NGREs can be different for two events of the same type. These fields are referred to as dynamic fields. In addition to these, there are those produced by a human and stored in the knowledge base alongside the NGRE. These fields are constant for two or more instances of the same event and hence, are referred to as static fields. Producing these fields requires the system developers to analyse a representative instance of a given event and to include as much applicable information about the instance as possible. This information should be applicable to all instances of the event. As an example, fields such as ?time? and ?producer? can not be specified as static fields, since they differ from one instance to another.

2) Defining Event Tags: In order to help with broader analytics tasks performed on logs, CEE has included a number of tags[24] for developers to be able to tag an event with generic and broad labels. These tags operate in much the same way as browser bookmark tags or tags used for organising emails. Logs can be tagged with fields such as ?domain? for which one possible value would be ?web?. This single tag can then be used to measure the amount of web related traffic as a percentage of total network traffic. One simple way to assign these tags to arbitrary logs is to use the knowledge base. As events are matched, preset tags can be applied to newly created OLF-events. Currently the system supports all CEE tags while adding one more for more specific use cases.

3) Creating Common Log Entries: The process of creating a common log format requires a deep understanding and precise mappings of the supported log formats which are to be normalised into a single format. One of the more challenging conversions is that of Syslog to OLF. This is because of Syslog?s inherently simple structure combined with virtually limitless complexity of its message (MSG element). In conduct- ing tests for normalisation of Syslog to OLF, application spe- cific interpreters where developed for supported log producers which outputted Syslog. The listings in Section II show how regular expressions have been written for a number of real- life log entries. For testing the efficiency of our approach, we attempted to convert most out of 252k Syslog lines (only single line logs) to corresponding OLF-events that can later be used for the purpose of correlation.



III. ATTACK DETECTION USING OLF  The proposed object log format consists of hundreds of fields each mapping to a different aspect of some event.

Where possible, duplicates have been eliminated and attributes from different logs are mapped to a single field in the OLF.

Technical details irrelevant to this paper have been omitted in the interest of saving space. In this section, a summary of the tests and processes ran on a dataset taken from the Honeynet Challenge number 34 (HN34) is presented. The HN34 challenge contains a number of separate log files from a variety of systems used across a network. Table II provides more details regarding the logs contained within  the HN34 challenge. Overall, HN34 consists of over 260k log lines spread across multiple log files and produced by an assortment of systems, utilised by the network. Below is a listing of the types of attacks present within these logs. This information was taken directly from the results[25] of the challenge and was only slightly reworded.

1) ICMP Ping Scans 2) MS-SQL Worms 3) Web Application Exploits on IIS 4) SMTP Relaying 5) Trojan traffic (false positive) 6) Malformed HTTP requests 7) RPC Port Mapping 8) SSH Mapping 9) Port Scanning  10) Various HTTP related attacks  TABLE II: Log files present in the HN34 challenge  Service Log file # of Logs HTTP Server access log 3554 HTTP Server error log 3692 HTTP Server ssl error log 374 IPTables Firewall iptablesyslog 179752 Snort IDS snortsyslog 69039 *nix syslog maillog 1172 *nix syslog messages 1166 *nix syslog secure 1587 All All 260336  After processing the logs from the HN34 challenge using the knowledge base, the resulting dataset consists of over 260k records produced from these logs. Using this normalised dataset, the SAL is able to detect a variety of attacks target- ing systems it monitors. One advantage of using normalised events, is that it is now possible to write one programming module or a simple SQL query to detect an attack (e.g web server mal-request, directory traversal) across all software that is effected by it. If a vulnerability effects both Microsoft IIS and Apache web server, one module can use the normalised dataset to handle both. And if NGINX is added to the mix of web-servers used in the network, then that too will be handled by the same module without the need to add or edit a single line of code in the correlation module. To better demonstrate the ease in detecting attacks over OLF, the following examples for detecting SSH, E-Mail and Web attacks are provided.

A. SSH Attacks  An example is provided in order to show how attack detec- tion operations on a SIEM system can become more efficient and enable the system to perform equivalent calculations faster as a result of the simplification, structuring and the greater completeness of information embedded within the UERM model (by a knowledge base) used in the system proposed. In this example, a successful SSH brute-force attack is detected using a single SQL query. Listing 15 shows the log lines (timing information has been omitted due to size constraints) produced during such an attack.

Listing 15: Logs representing events during an ultimately successful SSH brute-force attack Failed password for root from 10.1.3.137 port 52345 ssh2 ... x1000     Failed password for root from 10.1.3.137 port 50345 ssh2 Failed password for root from 10.1.3.137 port 51328 ssh2 Accepted password for root from 10.1.3.137 port 56235 ssh2  After having gone through the normalisation process, the log lines above are converted into their UERM format. Running the SQL query in Listing 16 will allow for the SSH Brute- force attack presented to be detected.

Listing 16: SQL statement used to detect successful SSH brute-force attacks SELECT NET_SRC_IPV4 FROM SAL.EVENT WHERE PRODUCER_APPNAME LIKE ?ssh%? AND TAG_ACTION LIKE ?login? AND TAG_STATUS LIKE ?succeeded? AND NET_SRC_IPV4 IN ( SELECT NET_SRC_IPV4 FROM SAL.EVENT WHERE PRODUCER_APPNAME LIKE ?ssh%? AND TAG_ACTION LIKE ?  login? AND TAG_STATUS = ?failure? GROUP BY NET_SRC_IPV4, USR_NAME, (YEAR(TIME) * 365 +  DAYOFYEAR(TIME)) HAVING COUNT(EVENT_ID) > 20 ORDER BY COUNT(EVENT_ID))  It is important again to note that the same query can be applied to other applications with little change in order to detect brute-force attempts at their login prompts. Changing the name of the application within the query will show the results for that application and omitting the name and grouping by it will return all login attacks against all applications within the dataset provided to the SIEM application.

B. SMTP Attacks  Another example shows how a common SMTP relay attack can be detected. Here, the regex in Listing 17 is applied to the log shown in Listing 18. As the match occurs, the knowledge base populates the UERM using the tags displayed in Listing 19. Once the event, in its new form, is stored in the database, the query in Listing 20 is able to detect the attack.

Listing 17: A regex designed to parse events relating to the Sendmail mail application (?<time>\w+\s+\d+\s+\d+:\d+:\d+)\s+(?<producer.host>\S+)\s  +(?<producer.appname>sendmail)(?:\((?<producer.module> .+)\))?(?:\[(?<producer.processId>\d+)\])?:\s(?< relation.commonId>\w+):\sruleset=check_rcpt, arg1=<?(?< application.smtp.receiver>.*?)>?, relay=.*?, reject=.*?

Relaying denied. IP name lookup failed \[(?<network.

srcIpv4>(?:\d{1,3}.){3}\d{1,3})\]  Listing 18: A log representing a smtp relay attempt on Sendmail that resulted in a failure Jan 30 08:01:47 combo sendmail[26701]: j0UD1OP0026701:  ruleset=check_rcpt, arg1=<china9988@21cn.com>, relay =[211.190.205.93], reject=550 5.7.1 <china9988@21cn.com >... Relaying denied. IP name lookup failed [211.190.205.93]  Listing 19: Additional tags automatically added to the normalised event by the knowledge base {"tag_object": ["email"], "application_proto": ["smtp"], "tag_domain": ["app", "net"], "tag_status": ["failure"], "tag_service": ["email"], "tag_subject": ["rule", "auth"], "tag_producer_type": ["application_log"], "tag_action": ["alert", "violate", "relay"]}  Listing 20: A simple SQL statement capable of detecting failed relays to the SMTP server SELECT * FROM SAL.EVENT WHERE TAG_STATUS = ?failure? AND  APPLICATION_PROTOCOL = ?smtp? AND TAG_ACTION like ?% relay%?  C. HTTP Attacks  Similar to the way some SMTP and SSH attacks were detected in the previous examples, using the strings shown in Listing 21[26] can aid in detecting malicious requests to a web server. It is worth noting that due to the normalisation of events to the OLF, these scans can be run on a network using many different web servers. This would mean in the case of a web-hosting company running Apache web server, Microsoft IIS, NGINX or other web servers, such attacks can be detected across all of these platforms as long as their logs can be processed and converted by the SAL.

Listing 21: Selection of patterns commonly seen in malicious requests often sent to web-servers "eval(", "concat", "union+select", "(null)", "base64_", "/  localhost", "/pingserver", "/config.", "/wwwroot", "/ makefile", "crossdomain.", "proc/self/environ", "etc/ passwd", ".exe", ".sql", ".ini", "/.bash", "/.svn", "/.

tar", " ", "<", ">", "/=", "...", "+++", "/&&", "?", ":", "[", "]", "../", "127.0.0.1", "loopback", "%0a", "%0d", "%22", "%27", "%3b", "%3c", "%3e", "%00", "%2e%2 e", "%25", "union", "input_file", "execute", "mosconfig ", "environ", "scanner", "path=.", "mod=.", "binlar", " casper", "cmswor", "diavol", "dotbot", "finder", " flicky", "jakarta", "libwww", "nutch", "planet", " purebot", "pycurl", "skygrid", "sucker", "turnit", " vikspi", "zmeu"

IV. DESIGN DETAILS  Figure 22 shows the outcome of a performance review using the HN34 log collection. The review is partially biased as the measurements can change from system to system and from dataset to dataset. It is therefore only provided for reference. Details of the hardware and software are given, plus simple techniques used to boost the performance to the levels achieved during the tests.

1) Hardware: Dell R820 Server, 2 CPU (12 cores), 64GB RAM. Running VMware ESXi 5.1 (hosting debian 6.0)  2) Software: Java 7 SE, SAP HANA columnar in-memory database.

3) Notable Java Libraries used: named-regexp[27], Apache Com-  mons BeanUtils[28], Apache Commons Net[29], Hibernate[30] (with JPA2.0[31] support)  Listing 22: Performance measurements on the dev system Starting operations...

Persisting events...

Total number of lines read: 261502.0 Total number of lines matched: 259720.0 Total number of lines matched (ni): 256230.0 Total number of lines matched (i): 3490.0 Percentage of matched logs: 99.32% Percentage of matched logs (ni): 97.98% Number of regexes applied: 117 Total time elapsed in milliseconds: 109006 Finished processing... Bye-bye!

In order to speed up the process of finding the correct regex for a given log, we utilise a priority queue. The queue is sorted so that the most often matched regexes are at the top of the queue and are checked for first.

Fig. 1: Layered view of the process of normalising events  Database  RegEx matcher extracts relevant information from the logs  Create UERM (OLF), Populate with extracted information from the event  Populate unified event with Knowledgebase information and apply Tags  Log File Log File Log File  Additionally, the application uses a multithreaded approach with one thread reading the contents of a log file and pushing the logs to a queue. The queue is then accessed by multiple worker threads. Each worker thread will attempt to match a regex against the log it has retrieved from the queue. Once a match is found, information within the log is extracted and inserted into an OLF which is later persisted to a database.

Figure 1 demonstrates the steps taken to normalise the events.



V. CONCLUSION  When looking at possible improvements to IDS/SIEM sys- tems, the need for better event representation stands out most.

Two main avenues for regenerating more complete unified events from their initial representations are the ability to ex- tract as much information as possible from the event represen- tation being interpreted, while adding human knowledge about the particular event to the unified representation. Although most systems attempt to tokenise existing representations of events to reproduce them in analytically friendlier formats, this task remains excessively complicated. Adding support for new log formats often takes considerable efforts for development and deployment to existing systems (often via heavy version upgrades). Named-group regular expressions can make the normalisation process for logs considerably easier. While they can be written to include some logic (e.g. that a field may have been omitted from a given instance of a log), they also allow the application to extract key-value pairs from the log line. The keys can be the fields (or mapped to them) from the UERM used by the system. For the purposes of the SAL Knowledge base, a UERM was built based on the CEE standard. Unifying logs is not an easy task and has been attempted by many vendors of SIEM systems in the past with varying degrees of success. The proposed new approach for unifying events aims to lessen the time and effort it takes to expand a SIEM system?s event normalising operations while creating far more complete and intelligent events for the system?s analytical purposes.



VI. FUTURE WORK  At present, in order to find the correct regex against a log line, the system runs the line against a list of regexes until a  match is found. This approach performs well for the volume of logs and the number of regexes used to process them.

However, as the computational complexity of this approach is O(n2) in the worst case, more efficient methods that directly select the correct regex for a given log are preferred.

Another improvement can be to gather context information from previous log lines produced by various software installed on a host. This information can be used to cross complete UERMs produced from logs of different software. As an example, if a host is determined to have ?server-1? as its hostname, this field can be added to system events from that host or to firewall events from another host.

