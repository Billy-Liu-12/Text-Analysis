Classification by Bagged Consistent Itemset Rules

Abstract  Associative classifiers that utilize association rules have been widely studied. It has been shown that as- sociative classifiers often outperform traditional clas- sifiers. Associative classifiers usually find only rules with high support values, because reducing the min- imum support to be satisfied increases cOlnputational cost. However, rules with low support but high confi- dence may contribute to classification. We have pro- posed an approach to build a classifier composed of almost all consistent (100% confident) rules. The pro- posed classifier was extended by introducing item re- duction and bagging in order to relax the constraint of consistency, which resulted in slightly increased perfor- mance for 26 datasets from the UCI machine learning repository.

1. Introduction  Associative class(fiers, which integrate association mining and classification, have been extensively stud- ied as a new classification approach [5, 4, 9]. Accord- ing to previous studies [5, 4, 9], high classification ac- curacies have been achieved by using associative classi- fiers compared with the classification accuracies of tra- ditional classifiers such as C4.5 [7] and RIPPER [2].

CBA [5], the pioneer of associative classification, builds a classifier from a set of association rules. The ruleset consists of rules with higher support values than a given threshold called minimum support. Confident rules with low support are not used in CBA mainly be- cause such rules cost more than the others.

We have proposed an associative classifier in which a bottom-up approach is taken for gathering rules [8].

In CCIC [8], 100% confident rules are used regardless of their support values. CCIC showed the best results for several datasets [6]. However, the restriction of con- sistency may too strong to produce more general rules.

We therefore relaxed the constraint of consistency in order to have noise-tolerant classifiers. Bagging [1] is a widely used method for coping with this problem.

Bagging uses a large number of resampled training in- stance sets to strengthen weak learners. Bagging with CCIC enables "partially consistent rules" to be obtained because some instances are lost in the resampled sets.

Another way to reduce bad affection due to the limited training instances is to remove useless items. We con- sider also to remove such redundant items.

2 Methodology  In this section, we describe the base classifier CCIC and then a redundancy-removing version and the bagged version.

2.1 Problem setting  Let D be a dataset, I == {II, 12 , , In} be the set of all items in D, and C == {Cl' C2, , Ck} be the set of the class labels. We refer to a pair (X, c) E D of an itemset X ~ I and a class label C E C as an instance.

For simplicity, we also call X instance. A rule r is writ- ten in the form r : A ---+ c, where A ~ I and C E C. If A ~ X holds, we say that "itemset A covers (explains) instance X" or "rule r : A ---+ C covers (explains) in- stance X." Let Dc denote the family of itemsets of the instances whose class label is C (positive instances), and let Dc be itemsets of the remaining instances (negative instances). If itemset A does not cover any instance of Dc, then A is said to be consistent (against Dc). For an instance set S, let R(S) denote the set of common items seen in every instance of S, that is, R(S) == nxE S X.

CCIC is an associative classifier to use a subclasss family n of consistent and maximal instance subsets S of positive instances [8]. For class c, a subclass S (~ Dc) is defined as a subset that satisfies the following:  1. R(S) is consistent.

2.2 Rule extraction procedure  An example:  For an illustrative dataset (Table 1), there are two CCls for not-play class and five CCls for play class (Table 2). Here, each rule corresponds to one subclass (e.g., #1 rule corresponds to S == {I, 2, 4}) and each itemset in the condition part shows one CCI (e.g., #1 rule shows R(S) == {sunny, humid}).

2. S is maximal, that is, no instance in De can be added to S while keeping consistency of R(S).

Here, R(S) is called Consistent Common ltemset (CCI) in class c (E C) if S is a subclass of c. The family of the subclasses for class c is denoted by ne . The set of all subclasses over all classes is denoted by n (== UeEC ne). Finding n is equivalent to finding all CCl's.

We employ a randomized algorithm [3] to econo- mize the computational cost of enumerating all mem- bers of n.

For a given parameter t, the algorithm executes t scans for all positive instances. Each scan is made according to a random order, that is, a permutation a == (aI, a2, ... , alDel) randomly chosen. According to order a, the positive instances are merged into S (ini- tialized by the empty set) in order, as long as the addi- tion does not break the consistency of R(S). Otherwise 2.4 eCCIC: a classifier using redundancy-  removed rules  the positive instance is skipped. Because of the fact that the merging process does not make R(S) larger than before, in the set inclusion relation, and the fact that all positive instances are scanned, it is guaranteed that one subclass is necessarily found by one scan. Here, the dataset is assumed to be consistent in the weakest sense, that is, all of the positive instances themselves are assumed to be consistent to the negative instances.

We may find the same subclass for different a's. Thus, the duplicated subclasses are removed in the last stage.

For example, #1 and #2 rules are obtained by al == (1,2,4,3,5) and a2 == (3,5,1,2,4) (There are many other orderings.).

We build a classifier from the obtained CCls relying on the following belief (Note that all of the rules are 100% confident to the training set.):  In order to satisfy both of these at the same time, we in- troduce a score to evaluate a rule and sum up the scores of rules that explain a given instance. Here, the score of a rule is measured by its coverage rate of positive in- stances. We classify an instance into a class with the highest score, that is the sum of the scores of rules cov- ering the instance. The concrete procedure is as follows.

Let us consider classifying a (class unknown) in- stance with an itemset A. Let SA,e be the set of sub- classes S (E ne ) whose R(S) is included in A, that is, SA,e == {S E ne I R(S) ~ A}. Then our classification I?? A - ~ lSI Hru e IS wntten as c - arg maxeEC L...JSESA,e TDJ' ere,  ISI/IDel (0 < ISI/IDel :::; 1) is the score of subclass S (or equivalently CCI R(S).

A tie-break is resolved by assigning it to the class with the largest population. If none of the rules are matched, the largest class is also chosen.

1. Rules with larger coverage rates are more reliable.

2. Class assignment by a larger number of rules is more reliable.

2.3 Classificationplay play play play play play play play play  not-play not-play not-play not-play not-play  x {sunny, hot, humid, windless}  {sunny, hot, humid, windy} {rainy, cool, normal-humidity, windy}  {sunny, mild-temperature, humid, windless} {rainy, mild-temperature, humid, windy}  Table 1. An illustrative dataset.

{overcast, hot, humid, windless} {rainy, mild-temperature, humid, windless}  {rainy, cool, normal-humidity, windless} {overcast, cool, normal-humidity, windy} {sunny, cool, normal-humidity, windless}  {rainy, mild-temperature, normal-humidity, windless} {sunny, mild-temperature, normal-humidity, windy}  {overcast, mild-temperature, humid, windy} {overcast, hot, normal-humidity, windless}   ID  Table 2. CCls extracted from Table 1.

1 {sunny, humid} --+ not-play 2 {rainy, windy} --+ not-play 3 {windless, normal-humidity} --+ play 4 {overcast} --+ play 5 {rainy, windless} --+ play 6 {mild-temperature, normal-humidity} --+ play 7 {sunny, normal-humidity} --+ play  CCls are consistent and the corresponding sets of in- stances are maximal. In other words, a CCI holds the common properties seen in a maximal set of positive instances but not seen in any negative instance. In this sense, they are one of most compact and reasonable ex- pressions of positive instances. However, in practice, some redundant items can be included in such a CCI.

This is mainly due to the lack of a sufficient number of    positive instances. When the number of possible items is large and the number of instances explained by a CCI is small, there are, in general, some redundant items in the CCI. By the word "redundant", we mean that some of items can be removed while keeping consistency.

Therefore, we propose a classifier (eCCIC classifier) that uses the redundancy-removed rules. In order to re- move the redundant items from a CCI, we examine each item in a random order as a candidate for removal. As long as the removal does not hurt the consistency, we remove it. Otherwise we leave the item. A processed CCI is referred to as an eCCI (an economized CCI).

2.5 Bagging  It is also known that a classifier is sometimes overly trained so as to fit training instances only (over-fitting).

This happens when the classifier is too flexible com- pared with the size of the training instance set. CCIC is a collection of rules, so it can have large flexibility.

To avoid such an over-fitting, a combination of many (weak) classifiers is known to be effective. A typical strategy is to make some copies of the training set by resampling and to average the results, so that the vari- ance of the classifier is reduced. Such an approach is called bagging [1]. Therefore, we adopt a bagging tech- nique with CCIC. The classification is made by majority voting of the results of these classifiers. We refer to this bagged CCIC classifier as CCICbag.

3 Experiments  We conducted an experiment to evaluate the perfor- mance of CCIC and its successors. According to the lit- erature [5, 4, 9], we used 26 datasets from the VCI Ma- chine Learning Repository [6]. A summary of datasets is shown in Table 3.

Every instance in the dataset was converted into an itemset. Numerical attributes were discretized by 5 bins. Here, the intervals of specifying the bins were taken so as to make the populations of the attribute values equal in each attribute. Negative instances that break the consistency of any positive instance are re- moved in order to keep the consistency of the dataset in a weakest sense. The number of iterations in finding CCICs was set to t == 1,000 and the number of copies was set to K == 100.

We compared the results obtained by using the orig- inal CCIC [8], eCCIC (classifier with redundancy- removed rules), CCICbag (bagged version of CCIC), and eCCICbag (bagged version of eCCIC). We also present the accuracies of C4.5 [7], RIPPER [2], CBA [5], CMAR [4] and CPAR [9] as competitors. All  Table 3. Summary of the datasets.

dataset #attr. #attr. #attr. #inst. #Classes maj. class  (cat.) (num.) (%) anneal 38 32 6 898 6 0.76 austra 14 8 6 690 2 0.56 auto 25 10 15 205 7 0.33 breast 10 10 699 2 0.66 cleve 13 6 303 2 0.54 crx 15 6 690 2 0.56 diabetes 8 8 768 2 0.65 german 20 13 7 1000 2 0.70 glass 9 9 214 7 0.36 heart 13 13 270 2 0.56 hepati 19 13 6 155 2 0.79 horse 22 15 7 368 2 0.63 hypo 25 18 7 3163 2 0.95 iono 34 34 351 2 0.64 iris 4 4 150 3 0.33 labor 16 8 8 57 2 0.65 led7 7 7 3200 10 0.11 lymph 18 15 3 148 4 0.55 pima 8 8 768 2 0.65 sick 29 22 7 2800 2 0.94 sonar 60 60 208 2 0.53 tic-tac 9 958 2 0.65 vehicle 18 18 846 4 0.26 waveform 21 21 5000 3 0.34 wine 13 13 178 3 0040 zoo 16 16 101 7 0041  of their results are taken from reference [9]. This is al- lowed because the experimental conditions are almost the same.

3.1 Accuracy of CCIC  The results obtained by using CCIC are shown in Ta- ble 4. The best score is indicated in boldface. The ac- curacy is obtained by lO-fold cross validation. The col- umn #CCls is the average number of CCls. The column 'drop' is the average ratio of test instances that are not matched with any rule. The bottom row #bests shows the number of datasets for which CCIC recorded the best accuracy. In total, CCIC was the third best in accu- racy but was the best in number of wins (8/26).

Table 4. Accuracy comparison of CCIC and existing classifiers.

dataset C4.5 RIPPER CBA CMAR CPAR CC1C #CCls drop anneal 0.948 0.958 0.979 0.973 0.984 0.966 128.0 0.02 austra 0.847 0.873 0.849 0.861 0.862 0.877 714.6 0.00 auto 0.801 0.728 0.783 0.781 0.820 0.787 334.2 0.07 breast 0.950 0.951 0.963 0.964 0.960 0.964 266.5 0.00 cleve 0.782 0.822 0.828 0.822 0.815 0.828 584.9 0.00 crx 0.849 0.849 0.847 0.849 0.857 0.875 716.8 0.00 diabetes 0.742 0.747 0.745 0.758 0.751 0.723 833.6 0.01 german 0.723 0.698 0.734 0.749 0.734 0.748 1635.6 0.00 glass 0.687 0.691 0.739 0.701 0.744 0.705 193.0 0.09 heart 0.808 0.807 0.819 0.822 0.826 0.837 548.0 0.00 hepati 0.806 0.767 0.818 0.805 0.794 0.827 270.3 0.01 horse 0.826 0.848 0.821 0.826 0.842 0.845 601.3 0.02 hypo 0.992 0.989 0.989 0.984 0.981 0.972 183.4 0.01 iono 0.900 0.912 0.923 0.915 0.926 0.923 999.7 0.00 iris 0.953 0.940 0.947 0.940 0.947 0.933 35.0 0.02 labor 0.793 0.840 0.863 0.897 0.847 0.833 77.0 0.04 led7 0.735 0.697 0.719 0.725 0.736 0.729 153.1 0.00 lymph 0.735 0.790 0.778 0.831 0.823 0.810 260.6 0.05 pima 0.755 0.731 0.729 0.751 0.738 0.732 829.2 0.01 sick 0.985 0.977 0.970 0.975 0.968 0.941 438.1 0.01 sonar 0.702 0.784 0.775 0.794 0.793 0.836 1655.2 0.00 tic-tac 0.994 0.980 0.996 0.992 0.986 0.989 268.9 0.00 vehicle 0.726 0.627 0.687 0.688 0.695 0.703 1715.2 0.00 waveform 0.781 0.760 0.800 0.832 0.809 0.802 2944.7 0.Q2 wine 0.927 0.916 0.950 0.950 0.955 0.961 407.8 0.00 zoo 0.922 0.881 0.968 0.971 0.951 0.891 8.8 0.11 average 0.8334 0.8293 0.8469 0.8522 0.8517 0.8476 #best~ 5 I 7 5 8    3.2 Improvement of CCIC  The results obtained by using successors of CCIC are shown in Table 5 and Figure 1. In comparison to CCIC, both eCCIC and CCICbag showed better accuracies in about half of the 26 datasets. However, the improved datasets are different between them. As a result, the child of both successors, eCCICbag, was best.

Fig. 1 shows the improved rates of eCCIC and CCICbag in comparison to CCIC. The horizontal axis is the relative data size, that is, the number of instances per class and per attribute. In Fig. 1, the classification rate of CCIC is taken as one and the rates of eCCIC and CCICbag are plotted as ratios to it. For datasets with a relatively small number of instances (see left- hand side of the plot), the eCCIC approach improved the accuracy, while CCICbag did not. On the other hand, for datasets with a relatively large number of in- stances (see right-hand side), CCICbag is better than eCCIC. The results are consistent with our intentions to have introduced item reduction in eCCIC and bagging in CCICbag. We had a similar plot as Fig. 1, if the hor- izontal axis was replaced with the number of instances.

That is, bagging reduced a bad affection caused by too many small rules.

Table 5. Accuracy comparison of CCIC, eCCIC, CCICbag and eCCICbag.

dataset #i/#C/#a CCIC eCCIC CCICbag eCCICbag anneal 3.9 0.966 0.969 0.964 0.968 austra 24.6 0.877 0.871 0.875 0.874 auto 1.2 0.787 0.802 0.777 0.792 breast 35.0 0.964 0.964 0.966 0.966 cleve 11.7 0.828 0.834 0.834 0.838 crx 23.0 0.875 0.875 0.875 0.874 diabetes 48.0 0.723 0.717 0.744 0.742 german 25.0 0.748 0.745 0.754 0.761 glass 3.4 0.705 0.682 0.710 0.692 heart 10.4 0.837 0.841 0.837 0.837 hepati 4.1 0.827 0.839 0.846 0.833 horse 8.4 0.845 0.845 0.858 0.861 hypo 63.3 0.972 0.974 0.972 0.974 iono 5.2 0.923 0.920 0.926 0.926 iris 12.5 0.933 0.933 0.933 0.933 labor 1.8 0.833 0.850 0.853 0.870 led7 45.7 0.729 0.728 0.732 0.732 lymph 2.1 0.810 0.831 0.810 0.845 pima 48.0 0.732 0.729 0.746 0.746 sick 48.3 0.941 0.942 0.944 0.945 sonar 1.7 0.836 0.841 0.808 0.798 tic-tac 53.2 0.989 0.989 0.976 0.975 vehicle 11.8 0.703 0.690 0.690 0.694 waveform 79.4 0.802 0.803 0.841 0.839 wine 4.6 0.961 0.966 0.977 0.972  0.9 0.891 0.933 0.871 0.961 average 0.8476 0.8505 0.8507 0.8557 #bests 5 8 11 13  4 Conclusion  We have improved the original CCIC by introduc- ing item reduction and bagging. Experimental results showed that both techniques worked well so that CCIC  1.1 eCCIC 0  CCICbag x  1.05 0 x Q)  ~ DO x"E 0 x x Q) DE Q) x>e xc.. X DE  0.95  0.9 ............._---J---'---a.-..........................._----'---"' ..................................

10 100  #instances / #classes / #attributes Figure 1. Improvement rates of eCCIC and CCICbag.

was successfully taken over by eCCICbag. The im- proved accuracy was only 0.8%, but eCCICbag was the best of all 9 classifiers both in number of wins and in averaged classification rate. In future works, we will in- vestigate the relationship between the classification per- formance and the parameters, including the number of classifiers of bagging and the number of iterations for the rule extraction process. We will also consider an- other ensemble learning approach, such as boosting.

