Efficiently Mining Maximal Frequent Itemsets

Abstract We present GenMax, a backtrack search based algorithm  for mining maximal frequent itemsets. GenMax uses a num- ber of optimizations to prune the search space. It uses a novel technique called progressive focusing to perform maximality checking, and diffset propagation to perfarm fast frequency computation. Systematic experimental com- parison with previous work indicates that different methods have varying strengths and weaknesses based on dataset characteristics. We found GenMax to be a highly efJicient method to mine the exact set of maximal patterns.

1 Introduction Mining frequent itemsets is a fundamental and essential  problem in many data mining applications such as the dis- covery of association rules, strong rules, correlations, multi- dimensional patterns, and many other important discovery tasks. The problem is formulated as follows: Given a large data base of set of items transactions, find all frequent item- sets, where a frequent itemset is one that occurs in at least a user-specified percentage of the data base.

Many of the proposed itemset mining algorithms are a variant of Apriori [2], which employs a bottom-up, breadth- first search, that enumerates every single frequent itemset.

In many applications (especially in dense data) with long frequent patterns enumerating all possible 2 m  - 2 subsets of a m length pattern (m can easily be 30 or 40  or longer) is computationally unfeasible. Thus, there has been recent interest in mining maximal frequent patterns in these ?hard? dense databases. Another recent promising direction is to mine only closed sets [9,11]; a set is closed if it has no superset with the same frequency. Nevertheless, for some of the dense datasets we consider in this paper, even the set of all closed patterns would grow to be too large. The only recourse is to mine the maximal patterns in such domains.

In this paper we introduce GenMax, a new algorithm that utilizes a backtracking search for efficiently enumerating all maximal patterns. GenMax uses a number of optimizations to quickly prune away a large portion of the subset search space. It uses a novel progressive focusing technique to eliminate non-maximal itemsets, and uses diffset propaga- tion for fast frequency checking.

We conduct an extensive experimental characterization of GenMax against state-of-the-art maximal pattern min- ing methods like MaxMiner [3] and Mafia 141. We found that the three methods have varying performance depend- ing on the database characteristics (mainly the distribution of the maximal frequent patterns by length). We present a  -  ACTW ACDW.ACTW  systematic and realistic set of experiments showing under which conditions a method is likely to perform well and un- der what conditions it  does not perform well. We conclude that while Mafia is the best method for mining a superset of all maximal patterns, GenMax is the current best method for enumerating the exact set of maximal patterns. We fur- ther observe that there is a type of data, where MaxMiner delivers the best performance.

2 Preliminaries and Related Work The problem of mining maximal frequent patterns can  be formally stated as follows: Let 1 = { i l ,  2 2 , .  . . , i m }  be a set of m distinct items. Let 23 denote a database of trans- actions, where each transaction has a unique identifier (tid) and contains a set of items. The set of all tids is denoted ?7- = { t l ,  t 2 ,  ..., tn} .  A set X C Z is also called an item- set. An itemset with k items is called a k-itemset. The set t ( X )  C 7, consisting of all .the transaction tids which contain X as a subset, is called the tidset of ?l. For con- venience we write an itemset { A ,  C,  W }  as ACW. and its tidset { 1 , 3 , 4 , 5 }  as t ( X )  = 1345.

4 ACTW ACDW,ACTW  1 ACTW A.C.D.1.W A.C,D,T,W CDW AC,AT. AW, AC, AD, AT, AW.

ACTW CD,CT,CW, CD.CT.CW,DT.

4 ACDW  ADW. ATW. CDT, 6 CDT CDW. COW, CTW  0-7695-1 119-8/01 $17.00 0 2001 IEEE 163  mailto:kgouda@csce.kyushu-u.ac.jp mailto:cs.rpi.edu   Backtracking Search GenMax uses backtracking search to enumerate the MFI. We first describe the backtracking paradigm in the context of enumerating all frequent pat- terns. We will subsequently modify this procedure to enu- merate the MFI.

Backtracking algorithms are useful for many combina- torial problems where the solution can be represented as a set I = {io,Zl ,  ...}, where each ij is chosen from a fi- nite possible set, Pj. Initially I is empty; it is extended one item at a time, as the search space is traversed. The length of I is the same as the depth of the corresponding node in the search tree. Given a partial solution of length 1 , I[ = {io, il, ..., i l - l } ,  the possible values for the next item il comes from a subset Cl C_ Pl called the combine set.

If y E Pl - Cl, then nodes in the subtree with root node I1 = {io, i l ,  ..., i l - 1 ,  y} will not be considered by the back- tracking algorithm. Since such subtrees have been pruned away from the original search space, the determination of Cl is also called pruning.

//Invoke as FI-backtrack(@, F I ,  0) FI-backtrack(Il, C I ,  1 ) 1.

2. 11+1 = I U {z} //also add 1 i + 1  to FI 3. Fi+1 = {y : y E Ci and y > z} 4. C I + ~  = FI-combine ( Z I + ~ , P I + ~ ) 5 .  FI-backtrack(li+l.  CL+^, 2 + 1) //Can 11+1 combine with other items in Cl?

F1-combine(Il+l, Pi+l) 1. C = 0 2.

3.

4.

5. return C  for each z E CI  for each y E P,+, if Z I + ~  U {y} is frequent  C = C U {y}  Figure 2. Backtrack Algorithm for Mining FI Consider the backtracking algorithm for mining all fre-  quent patterns, shown in Figure 2. The main loop tries ex- tending I /  with every item z in the current combine set C L .

The first step is to compute I ~ + I ,  which is simply I1 ex- tended with z. The second step is to extract the new possi- ble set of extensions,  PI+^, which consists only of items y in Cl that follow z. The third step is to create a new com- bine set for the next pass, consisting of valid extensions. An extension is valid if the resulting itemset is frequent. The combine set, Cl+1, thus consists of those items in the possi- ble set that produce a frequent itemset when used to extend 4 + 1 .  Any item not in the combine set refers to a pruned sub- tree. The final step is to recursively call the backtrack rou- tine for each extension. As presented, the backtrack method performs a depth-first traversal of the search space.

Example 2 Consider the full subset search space shown in Fig- ure 3. The backtrack search space can be considerably smaller than the full space. For example, we start with IO = 8 and CO = Fl = { A ,  C,  D,  T ,  W } .  At level I ,  each item in CO is added to IO in turn. For example, A is added to obtain I1 = { A } .  The possi- ble set for A, Pl = {C,  D,  T ,  W }  consists of all items that follow A in CO. However, from Figure 1, we find that only AC, AT,  and AW are frequent (at min_sup=3), giving C1 = {C, T ,  W } .  Thus the subtree corresponding to the node AD has been pruned.

Related Work Methods for finding the maximal elements include All-MFS [ 5 ] ,  which works by iteratively attempt- ing to extend a working pattern until failure. A random- ized version of the algorithm that uses vertical bit-vectors  was studied, but it does not guarantee every maximal pat- tern will be returned. The Pincer-Search [7] algorithm uses horizontal data format. It not only constructs the candidates in a bottom-up manner like Apriori, but also starts a top- down search at the same time, maintaining a candidate set of maximal patterns. This can help in reducing the number of database scans, by eliminating non-maximal sets early.

The maximal candidate set is a superset of the maximal pat- terns, and in general, the overhead of maintaining it can be very high. In contrast GenMax maintains only the current known maximal patterns for pruning.

MaxMiner [3] is another algorithm for finding the max- imal elements. It uses efficient pruning techniques to quickly narrow the search. MaxMiner employs a breadth- first traversal of the search space; it reduces database scan- ning by employing a lookahead pruning strategy, i.e., if a node with all its extensions can determined to be frequent, there is no need to further process that node. It also em- ploys item (re)ordering heuristic to increase the effective- ness of superset-frequency pruning. Since MaxMiner uses the original horizontal database format, it can perform the same number of passes over a database as Apriori does.

Depthproject [ I ]  finds long itemsets using a depth first search of a lexicographic tree of itemsets, and uses a counting method based on transaction projections along its branches. This projection is equivalent to a horizontal ver- sion of the tidsets at a given node in the search tree. Depth- Project also uses the look-ahead pruning method with item reordering. It returns a superset of the MFI and would re- quire post-pruning to eliminate non-maximal patterns. FP- growth [6]  uses the novel frequent pattern tree (FP-tree) structure, which is a compressed representation of all the transactions in the database. It uses a recursive divide-and- conquer and database projection approach to mine long pat- terns. Nevertheless, since it enumerates all frequent patterns it is impractical when pattern length is long.

Mafia [4] is the most recent method for mining the MFI.

Mafia uses three pruning strategies to remove non-maximal sets. The first is the look-ahead pruning first used in MaxMiner. The second is to check if a new set is subsumed by an existing maximal set. The last technique checks if t ( X )  C t (Y) .  If so X is considered together with Y for extension. Mafia uses vertical bit-vector data format, and compression and projection of bitmaps to improve perfor- mance. Mafia mines a superset of the MFI, and requires a post-pruning step to eliminate non-maximal patterns. In contrast GenMax integrates pruning with mining and re- turns the exact MFI.

3 GenMax for efficient MFI Mining There are two main ingredients to develop an efficient  MFI algorithm. The first is the set of techniques used to remove entire branches of the search space, and the second is the representation used to perform fast frequency compu- tations. We will describe below how GenMax extends the basic backtracking routine for FI, and then the progressive focusing and diffset propagation techniques it uses for fast maximality and frequency checking.

The basic MFI enumeration code used in GenMax is a straightforward extension of FI-backtrack. The main ad- dition is the superset checking to eliminate non-maximal itemsets, as shown in Figure 4. In addition to the main steps     Level O(A.C.D.T.W)      A q T W  5  Figure 3. SubseVBacktrack Search Tree (nzinsup= 3): Circles indicate maximal sets and the infrequent sets have been crossed out. Due to the downward closure property of support (i.e., all subsets of a frequent itemset must be frequent) the frequent itemsets form a border (shown with the bold line), such that all frequent itemsets lie above the border, while all infrequent itemsets lie below it. Since MFI determine the border, i t  is straightforward to obtain FI in a single database scan of MFI is known.

//Invocation: MFI-backtrack(@, FI, 0) MFI-backtrack(li, Ci, 1) 1 .  for each z E Ci  3.

4.* S.* 6.

7.* if C~+I  is empty 8.*  10.

2 .  Il+l = I U  {x} A+1 = {y : y E Cl and y > z} if 1~+1 U Pi+1 has a superset in MFI  CL+^ = FI-combine ( 4 + 1 ,  Pi+1) return Nall subsequent branches pruned!

if 1/+1 has no superset in MFI 9. * MFI= MFI U l i + 1  else MFI-backtrack(ll+l, ci+1, 1 + 1) Figure 4. Backtrack Algorithm for Mining MFI(* indicates a new line not in FI-backtrack)  in FI enumeration, the new code adds a step (line 4) after the construction of the possible set to check if Zl+1 U Pl+1 is subsumed by an existing maximal set. If so, the current and all subsequent items in Cl can be pruned away. After creating the new combine set, if it is empty and I/+l is not a subset of any maximal pattern, i t  is added to the MFI. If the combine set is non-empty a recursive call is made to check further extensions.

Superset Checking Techniques: Checking to see if the given itemset combined with the possible set P/+l is subsumed by another maximal set was also proposed in Mafia [4] under the name HUTMFI. Further pruning is pos- sible if one can determine based just on support of the com- bine sets if Il+1 U 4 + 1  will be guaranteed to be frequent. In this case also one can avoid processing any more branches.

This method was first introduced in MaxMiner [3], and was also used in Mafia under the name FHUT.

Reordering the Combine Set: Two general principles for efficient searching using backtracking are that: 1) It is more efficient to make the next choice of a subtree (branch) to explore to be the one whose combine set has the fewest items. This usually results in good performance, since it minimizes the number of frequency computations in FI- combine. 2 )  If we are able to remove a node as early as possible from the backtracking search tree we effectively prune many branches from consideration.

Reordering the elements in the current combine set to achieve the two goals is a very effective means of cutting  A1D.T.W.C) DIT.W.CI  ADTiW k l I I . -  ADWlC1 ADC ATWIC) ATC a'WC DTWic) DTC DWC  , .  1 ADWC ATWC TWC ,'  Figure 5. Backtracking Trees of Example 2  down the search space. The first heuristic is to reorder the combine set in increasing order of support. This is likely to produce small combine sets in the next level, since the items with lower frequency are less likely to produce fre- quent itemsets at the next level. This heuristic was first used in MaxMiner, and has been used in other methods since then [1,4, 1 I].

In addition to sorting the initial combine set at level 0 in increasing order of support, GenMax uses another novel reordering heuristic based on a simple lemma  Lemma 1 Ler I F ( x )  = { y  : y E PI, xy  is notfrequent }, denote the set of infrequent 2-iternsets that contain an item x E F1, and let M (x) be the longest maximal pattern con- taining z. Then ( M  (.)I < IF1 I - IIF(x)l .

Assuming Fz has been computed, reordering CO in de- creasing order of I F ( z )  (with x E CO) ensures that the smallest combine sets will be processed at the initial lev- els of the tree, which result in smaller backtracking search trees. GenMax thus initially sorts the items in decreasing order of IF(.) and in increasing order of support.

Example 3 For our database in Figure 1 with min-sup = 2, I F ( x )  is the same of all items x E 4, and the sorted order (on support) is A ,  D, T ,  W, C. Figure 5 shows the backtracking search trees for maximal itemsets containing prefix items A and D. Un- der the search tree for A,  Figure 5 (a), we try to extend the partial solution A D  by adding to it item T from its combine set. We try another item W after itemset ADT turns out to be infrequent,     and so on. Since GenMax uses itemsets which are found earlier in the search to prune the combine sets of later branches, after find- ing the maximal set ADWC,  GenMax skips ADC. After finding ATWC all the remaining nodes with prefix A are pruned, and so on. The pruned branches are shown with dashed arrows, indicating that a large part of the search tree is pruned away  Theorem 1 (Correctness) MFI-backtrack returns all and only the maximal frequent itemsets in the given database.

3.1 Optimizing GenMax Superset Checking Optimization  The main efficiency of GenMax stems from the fact that it eliminates branches that are subsumed by an already mined maximal pattern. Were it not for this pruning, Gen- Max would essentially default to a depth-first exploration of the search tree. Before creating the combine set for the next pass, in line 4 in Figure 4, GenMax check if Il+1 U Pl+1 is contained within a previously found maximal set. If yes, then the entire subtree rooted at Il+l and including the el- ements of the possible set are pruned. If no, then a new extension is required. Another superset check is required at line 8, when Il+1 has no frequent extension, i.e., when the combine set Cl+1 is empty. Even though Il+l is a leaf node with no extensions it may be subsumed by some maximal set, and this case is not caught by the check in line 4 above.

The major challenge in the design of GenMax is how to perform this subset checking in the current set of maximal patterns in an efficient manner. If we were to naively imple- ment and perform this search two times on an ever expand- ing set of maximal patterns MFI, and during each recursive call of backtracking, we would be spending a prohibitive amount of time just performing subset checks. Each search would take O( IMFII) time in the worst case, where MFI is the current, growing set of maximal patterns. Note that some of the best algorithms for dynamic subset testing run in amortized time O( & log s )  per operation in a sequence of s operations [8] (for us s = O(MF1)). In dense do- main we have thousands to millions of maximal frequent itemsets, and the number of subset checking operations per- formed would be at least that much. Can we do better?

The answer is, yes! Firstly, we observe that the two sub- set checks (one on line 4 and the other on line 8) can be easily reduced to only one check. Since Zl+l U P L + ~  is a su- perset of Zl+1, in our implementation we do superset check only for 11+1 U E?,+,. While testing this set, we store the maximum position, say p ,  at which an item in Il+1 U Pl+1 is not found in a maximal set M E MFI. In other words, all items before p are subsumed by some maximal set. For the superset test for I ~ + I ,  we check if 11~+1 I < p .  If yes, Z L + ~  is non-maximal. If no, we add it to MFI.

The second observation is that performing superset checking during each recursive call can be redundant. For example, suppose that the cardinality of the possible set Pl+l is m. Then potentially, MFI-backtrack makes rn re- dundant subset checks, if the current MFI has not changed during these m consecutive calls. To avoid such redun- dancy, a simple checkstatus flag is used. If the flag is false, no superset check is performed. Before each recursive call the flag is false; it becomes true whenever Cl+1 is empty, which indicates that we have reached a leaf, and have to backtrack.

// Invocation: LMFLbacktrack(0, Fl ,  0,O) // L M F 4  is an output parameter LMFI-backtrack(4, Cl, LMFIl,  E ) 1 .

2.

3. Pl+1 = {y : y E Ci and y > z} 4. if Il+1 U Pl+1 has a superset in LMFIi 5. return //subsequent branches pruned!

7 .  Cl+1 = FI-combine (Il+l, Pl+l) 8. if Cl+1 is empty 9. if has no superset in LMFIl 10.

1 I .* 12. LMFI-backtrack(Il+l, Cl+1, LMFI1+1,1+ 1)  for each z E Cl Il+l = I U {z}  6.  * LMFIl+1 = 8  L M F 4  = L M F 4  U I ~ + I else LMFIl+1 = { M  E LMFIl : z E M }  13.* LMFIi = LMFIl U LMFI1+1 Figure 6. Mining MFI with Progressive Focus- ing (* indicates a new line not in MFI-backtrack)  The O(& log s )  time bounds reported in [8] for dy- namic subset testing do not assume anything about the se- quence of operations performed. In contrast, we have full knowledge of how GenMax generates maximal sets; we use this observation to substantially speed up the subset checking process. The main idea is to progressively nar- row down the maximal itemsets of interest as recursive calls are made. In other words, we construct for each invocation of MFI-backtrack a list of local rnaxirnal frequent itemsets, LMFI l .  This list contains the maximal sets that can po- tentially be supersets of candidates that are to be generated from the itemset I l .  The only such maximal sets are those that contain all items in Il. This way, instead of check- ing if 11+1 U P,+l is contained in the full current MFI, we check only in LM FI1 - the local set of relevant maximal itemsets. This technique, that we call progressive focusing, is extremely powerful in narrowing the search to only the most relevant maximal itemsets, making superset checking practical on dense datasets.

Figure 6 shows the pseudo-code for GenMax that incor- porates this optimization (the code for the first two opti- mizations is not show to avoid clutter). Before each in- vocation of LMFI-backtrack a new LMFIl+1 is created, consisting of those maximal sets in the current LDIFIl that contain the item z (see line 10). Any new maximal itemsets from a recursive call are incorporated in the current L M F I l at line 12.

Frequency Testing Optimization So far GenMax, as described, is independent of the data  format used. The techniques can be integrated into any of the existing methods for mining maximal patterns. We now present some data format specific optimizations for fast fre- quency computations.

GenMax uses a vertical database format, where we have available for each item its tidset, the set of all transaction tids where it  occurs. The vertical representation has the fol- lowing major advantages over the horizontal layout: Firstly, computing the support of itemsets is simpler and faster with the vertical layout since it involves only the intersections of tidsets (or compressed bit-vectors if the vertical format is stored as bitmaps [4]). Secondly, with the vertical lay- out, there is an automatic ?reduction? of the database be- fore each scan in that only those itemsets that are relevant    to the following scan ofcthe mining process are accessed from disk. Thirdly, the vertical format is more versatile in supporting various search strategies, including breadth-first, depth-first or some other, hybrid search.

//Can 11+1 combine with other items in Ci?

FI-tidset-combine(li+ 1 ,  Pi+ 1 ) 1. c=0 2. for each y E R+I 3.* y? = y ? 4.* 5.* if It(y?)l 2 minsup 6.

7. returnC  t (y?)  = t (h+d n t ( y )  c = c U {y?} Figure 7. FI-combine Using Tidset Intersec- tions (* indicates a new line not in FI-combine)  Let?s consider how the FI-combine (see Figure 2) routine works, where the frequency of an extension is tested. Each item z in Cl actually represents the itemset 11 U {z} and stores the associated tidset for the itemset I1 U {z}. For the initial invocation, since 11 is empty, the tidset for each item z in Cl is identical to the tidset, t (z) ,  of item z. Before line 3 is called in FI-combine, we intersect the tidset of the ele- ment 11+1 (i.e., t ( 1 l U { x } ) )  with the tidset of element y (i.e., t(1l U (9))). If the cardinality of the resulting intersection is above minimum support, the extension with y is frequent, and y? the new intersection result, is added to the combine set for the next level. Figure 7 shows the pseudo-code for FI-tidset-combine using this tidset intersection based sup- port counting.

In Charm [ 1 I ]  we first introduced two new properties of itemset-tidset pairs which can be used to further increase the performance. Consider the items z and y in C1. If during intersection in line 4 in Figure 7, we discover that t ( z )  - or equivalently t ( I i+l)  - is a subset of or equal to t ( y ) ,  then we do not add y? to the combine set, since in this case, z always occurs along with y. Instead of adding y? to the combine set, we ada it to Il+l. This optimization was also used in Mafia [4] under the name PEP.

Diffsets Propagation Despite the many advantages of the vertical format, when the tidset cardinality gets very large (e.g., for very frequent items) the intersection time starts to become inordinately large. Furthermore, the size of in- termediate tidsets generated for frequent patterns can also become very large to fit into main memory. GenMax uses a new format called diffsets [ 101 for fast frequency testing.

The main idea of diffsets is to avoid storing the entire tidset of each element in the combine set. Instead we keep track of only the differences between the tidset of itemset 11 and the tidset of an element z in the combine set (which actually denotes 1l U {z}). These differences in tids are stored in what we call the diffset, which is a difference of two tidsets at the root level or a difference of two diffsets at later levels. Furthermore, these differences are propagated all the way from a node to its children starting from the root.

In an extensive study [ 101, we showed that diffsets are very short compared to their tidsets counterparts, and are highly effective in improving the running time of vertical methods.

We describe next how they are used in GenMax, with the help of an example. At level 0, we have available the tidsets for each item in F1. When we invoke FI-combine at this level, we compute the diffset of y?, denoted as d(y?) instead  // Can l l + 1  combine with other items in Cl?

FI-diffset-combine(l+l, A + 1 ) 1. c=0 2. for each ?/ E Fj+l 3. y f  = y 4. if level == 0 then d(y ? )  = t(ll+l) - t(y) 5.

6. if u(y?) 2 minsup 7.

8. return C  else d(y?)  = d(y)  - d(Ii+1)  c = c U {y?} Figure 8. FI-combine: Diffset Propagation  of computing the tidset of y as shown in line 4 in Figure 7.

That is d(y ? )  = t ( z )  - t(y). The support of y? is now given as (~(y ? )  = a(.) - ld(y?)l. At subsequent levels, we have available the diffsets for each element in the combine list. In this case d(y?) = d(y)  - d(z),  but the support is still given as cr(y?) = a(z) - ld(y?)l. Figure 8 shows the pseudo-code for computing the combine sets using diffsets.

GenMax: 1. Compute FI and F2 3.

4.

5. MFI = @ 6.

7. returnMF1  Compute I F ( z )  for each item z E F1 Sort F1 (decreasing in I F ( z ) ,  increasing in a(.))  LMFI-backtrack(@, F l ,  M F I ,  0) / h e  diffsets  Figure 9. The GenMax Algorithm Final GenMax. Algorithm The complete GenMax algo- rithm is shown in Figure 9, which ties in all the optimiza- tions mentioned above. GenMax assumes that the input dataset is in the vertical tidset format. First GenMax com- putes the set of frequent items and the frequent 2-itemsets, using a vertical-to-horizontal recovery method [lo]. This information is used to reorder the items in the initial com- bine list to minimize the search tree size that is generated.

GenMax uses the progressive focusing technique of LMFI- backtrack, combined with diffset propagation of FI-diffset- combine to produce the exact set of all maximal frequent itemsets, MFI.

4 Experimental Results Past work has demonstrated that Depthproject [ 11 is  faster than MaxMiner [3], and the latest paper shows that Mafia [4] consistently beats Depthproject. In out experi- mental study below, we retain MaxMiner for baseline com- parison. At the same time, MaxMiner shows good perfor- mance on some datasets, which were not used in previous studies. We use Mafia as the current state-of-the-art method and show how GenMax compares against it.

All our experiments were performed on a 400MHz Pen- tium PC with 256MB of memory, running RedHat Linux 6.0. For comparison we used the original source or ob- ject code for MaxMiner [3] and MAFIA [4], provided to us by their authors. Timings in the figures are based on total wall-clock time, and include all preprocessing costs (such as horizontal-to-vertical conversion in GenMax and Mafia).

The times reported also include the program output. We believe our setup reflects realistic testing conditions (as op- posed to some previous studies which report only the CPU time or may not include output cost).

Benchmark Datasets: We chose several real and syn- thetic datasets for testing the performance of the the al-     Database 1 I ( A L (  R chess I 76 I 37 I 3,196 connect mushroom pumsb* 71 I7 pumsb 71 I7  67,557 8,124  49,046 49,046 100,000 100,000  MPL 23 (20%) 31 (2.5%)  22 (0.025%) 43 (2.5%) 27 (40%)  13 (0.01 %) 25 (0.1%)  Figure 10. Database Characteristics: I denotes the number of items, A L  the average length of a record, R the number of records, and M P L  the maximum pattern length at the given min-sup.

gorithms, shown in Table IO. The real datasets have been used previously in the evaluation of maximal patterns [ 1,3, 41. Typically, these real datasets are very dense, i.e., they produce many long frequent itemsets even for high val- ues of support. The table shows the length of the longest maximal pattern (at the lowest minimum support used in our experiments) for the different datasets. For exam- ple on pumsb*, the longest pattern was of length 43 (any method that mines all frequent patterns will be impracti- cal for such long patterns). We also chose two synthetic datasets, which have been used as benchmarks for testing methods that mine all frequent patterns. Previous maxi- mal set mining algorithms have not been tested on these datasets, which are sparser compared to the real sets. All these datasets are publicly available from IBM Almaden (www.almaden.ibm.com/cs/quest/demos.html).

While conducting experiments comparing the 3 different algorithms, we observed that the performance can vary sig- nificantly depending on the dataset characteristics. We were able to classify our benchmark datasets into four classes based on the distribution of the maximal frequent patterns.

Type I Datasets: Chess and Pumsb Figure 1 1  shows the performance of the three algorithms  on chess and pumsb. These Type I datasets are character- ized by a symmetric distribution of the maximal frequent patterns (leftmost graph). Looking at the mean of the curve, we can observe that for these datasets most of the maximal patterns are relatively short (average length 1 1 for chess and 10 for pumsb). The MFI cardinality figures on top center and right, show that for the support values shown, the MFI is 2 orders of magnitude smaller than all frequent itemsets.

Compare the total execution time for the different algo- rithms on these datasets (center and rightmost graphs). We use two different variants of Mafia. The first one, labeled Mafia, does not return the exact maximal frequent set, rather it returns a superset of all maximal patterns. The second variant, labeled MafiaPP, uses an option to eliminate non- maximal sets in a post-processing (PP) step. Both GenMax and MaxMiner return the exact MFI.

On chess we find that Mafia (without PP) is the fastest if one is willing to live with a superset of the MFI. Mafia is about I O  times faster than MaxMiner. However, notice how the running time of MafiaPP grows if one tries to find the exact MFI in a post-pruning step. GenMax, though slower than Mafia is significantly faster than MafiaPP and is about 5 times better than MaxMiner. All methods, except MafiaPP, show an exponential growth in running time (since  the y-axis is in log-scale, this appears linear) faithfully fol- lowing the growth of MFI with lowering minimum sup- port, as shown in the top center and right figures. MafiaPP shows super-exponential growth and suffers from an ap- proximately O( IMF11 ') overhead in pruning non-maximal sets and thus becomes impractical when MFI becomes too large, i.e., at low supports.

On pumsb, we find that GenMax is the fastest, having a slight edge over Mafia. It is about 2 times faster than Mafi- aPP. We observed that the post-pruning routine in MafiaPP works well till around 0(104)  maximal itemsets. Since at 60% minsup  we had around that many sets, the overhead of post-processing was not significant. With lower support the post-pruning cost becomes significant, so much so that we could not run MafiaPP beyond 50% minimum support.

MaxMiner is significantly slower on pumsb; a factor of 10 times slower then both GenMax and Mafia.

Type I results substantiate the claim that GenMax is an highly efficient method to mine the exact MFI. It is as fast as Mafia on pumsb and within a factor of 2 on chess. Mafia, on the other hand is very effective in mining a superset of the MFI. Post-pruning, in general, is not a good idea, and GenMax beats MafiaPP with a wide margin (over 100 times better in some cases, e.g., chess at 20%). On Type I data MaxMiner is noncompetitive.

Type I1 Datasets: Connect and Pumsb* Type I1 datasets, as shown in Figure 12 are characterized  by a left-skewed distribution of the maximal frequent pat- terns, i.e., there is a relatively gradual increase with a sharp drop in the number of maximal patterns. The mean pattern length is also longer than in Type I datasets; it is around 16 or 17. The MFI cardinality is also drastically smaller than FI cardinality; by a factor of l o4  or more (in contrast, for Type I data, the reduction was only lo2).

The main performance trend for both Type I1 datasets is that Mafia is the best till the support is very low, at which point there is a cross-over and GenMax outperforms Mafia. MafiaPP continues to be favorable for higher sup- ports, but once again beyond a point post-pruning costs start to dominate. MafiaPP could not be run beyond the plotted points. MaxMiner remains noncompetitive (about 10 times slower). The initial start-up time for Mafia for creating the bit-vectors is responsible for the high offset at 50% support on pumsb*. GenMax appears to exhibit a more graceful increase in running time than Mafia.

Type I11 Datasets: T1014 and T40110 As depicted in Figure 13, Type I11 datasets - the two  synthetic ones - are characterized by an exponentially de- caying distribution of the maximal frequent patterns. Ex- cept for a few maximal sets of size one, the vast majority of maximal patterns are of length two! A.fter that the number of longer patterns drops exponentially. The mean pattern length is very short compared to Type I or Type I1 datasets; it is around 4-6. MFI cardinality is not much smaller than the cardinality of all frequent patterns. The difference is only a factor of 10 compared to a factor of 100 for Type I and a factor of 10,000 for Type 11.

Comparing the running times we observe that MaxMiner is the best method for this type of data. The breadth-first or level-wise search strategy used in MaxMiner is ideal for     maximal itemset distribution chess Dumsb  ' MaxMiner - MafiaPP * GenMax 0 a  , 0' . Mafia *     p 4000 m  3000 e IL 2000    0 5 10 15 20 25 -. .

70 65 60 55 50 45 40 35 30 25 20  MaxMiner *' ' ' ' t 100000 ,  Mafia * - 1000 .

100 .

10 .

t  1 1 100 90 80 70 60 50 40  Length Minimum Support (%) Minimum Supporl(%) Figure 11. Type I Datasets (chess and pumsb)  maximal iternset distribution connect pumsb'   $ 2000  ; 1000   -500 1 , , , , , , , 1 . loo0  0 5 10 15 20 25 30 35 40 Length  Figure  -  E F - .- I-  12.

100 90 80 70 60 50 40 30 20 10 0 Minimum Support (%)  Type II Datasets (connect and  50 45 40 35 30 25 20 15 10 5 0 Minimum Support (%)  pu msb*)  maximal itemset distribution T1014D100K T40llODlOOK  TlO(0 025%) --f 35000 , 7 I I I , 1  30000 T40(07125%) 0 .

0 0 0 ~ 0     0 2 4 6 8 10 12 14 16 18  Length    >. 20000  t 10000  U  2 15000 U    1- 0.16 0.14 0.12 0.1 0.08 0.06 0.04 0.02 0     E F d 100 -   Minimum Support (%) Minimum Support (%) Figure 13. Type 111 Datasets (T10 and T40)  maximal iternset distribution mushroom  mushroom(9.1%) ---c mushroom(0.075%) ----e---- p    g 10 E  I-"  F 2 1 - MaxMiner -e-  MafiaPP * GenMax o GenMax' *  -  Mafia 4 1 0 5 10 15 20 25 10 1 0.1 0.01  Length Minimum Support (%) Figure 14. Type IV Dataset (mushroom)  vcly Uuarly S G a l L l l  LIGGS, UllU W l l G l l  LllC a V c l a g G  l l I ~ A l l l l a l  pal- L U  gG1 LIIGII IlG;qUGIILY. U 1 1  LIIG ULllt;l l lUllU Vt;ll lLill  I l lGLll- tern length is small. Horizontal methods are better equipped to cope with the quadratic blowup in the number of fre- quent 2-itemsets since one can use array based counting  ods spend much time in performing intersections on long item tidsets or bit-vectors. GenMax gets around this prob- lem by using the horizontal format for computing frequent     2-itemsets (denoted Fz),  but it still has to spend time per- forming O( (F2 I) pairwise tidset intersections.

Mafia on the other hand performs O( IF1 1 2 )  intersections, where FI is the set of frequent items. The overhead cost is enough to render Mafia noncompetitive on Type I11 data. On TI0 Mafia can be 20 or more times slower than MaxMiner.

GenMax exhibits relatively good performance, and it is about 10 times better than Mafia and 2 to 3 times worse than MaxMiner. On T40, the gap between GenMax/Mafia and MaxMiner is smaller since there are longer maximal patterns. MaxMiner is 2 times better than GenMax and 5 times better than Mafia. Since the MFI cardinality is not too large MafiaPP has almost the time as Mafia for high supports. Once again MafiaPP could not be run for lower support values. It is clear that, in general, post-pruning is not a good idea; the overhead is too much to cope with.

Type IV Dataset: Mushroom Mushroom exhibits a very unique MFI distribution.

Plotting MFI cardinality by length, we observe in Figure 14 that the number of maximal patterns remains small until length 19. Then there is a sudden explosion of maximal pat- terns at length 20, followed by another sharp drop at length 21. The vast majority of maximal itemsets are of length 20.

The average transaction length for mushroom is 23 (see Ta- ble IO), thus a maximal pattern spans almost a full transac- tion. The total MFI cardinality is about I O 0 0  times smaller than all frequent itemsets.

On Type IV data, Mafia performs the @st. MafiaPP and MaxMiner are comparable at lower supports. This data is the worst for GenMax, which is 2 times slower than MaxMiner and 4 times slower than Mafia. In Type IV data, a smaller itemset is part of many maximal itemsets (of length 20 in case of mushroom); this renders our pro- gressive focusing technique less effective. To perform max- imality checking one has to test against a large set of maxi- mal itemsets; we found that GenMax spends half its time in maximality checking. Recognizing this helped us improve the progressive focusing using an optimized intersection- based method (as opposed to the original list based ap- proach). This variant, labeled GenMax?, was able to cut down the execution time by half. GenMax? runs in the same time as MaxMiner and MafiaPP.

5 Conclusions This is one of the first papers to comprehensively com-  pare recent maximal pattern mining algorithms under realis- tic assumptions. Our timings are based on wall-clock time, we included all pre-processing costs, and also cost of out- putting all the maximal itemsets (written to a file). We were able to distinguish four different types of MFI distributions in our benchmark testbed. We believe these distributions to be fairly representative of what one might see in prac- tice, since they span both real and synthetic datasets. Type I is a normal MFI distribution with not too long maximal patterns, Type I1 is a left-skewed distributions, with longer maximal patterns, Type I11 is an exponential decay distri- bution, with extremely short maximal patterns, and finally Type IV is an extreme left-skewed distribution, with very large average maximal pattern length.

We noted that different algorithms perform well under different distributions. We conclude that among the current  methods, MaxMiner is the best for mining Type I11 distri- butions. On the remaining types, Mafia is the best method if one is satisfied with a superset of the MFI. For very low supports on Type I1 data, Mafia loses its edge. Post-pruning non-maximal patterns typically has high overhead. It works only for high support values, and MafiaPP cannot be run be- yond a certain minimum support value. GenMax integrates pruning of non-maximal itemsets in the process of mining using the novel progressive focusing technique, along with other optimizations for superset checking; GenMax is the best method for mining the exact MFI.

Our work opens up some important avenues of future work. The IBM synthetic dataset generator appears to be too restrictive. It produces Type I11 MFI distributions. We plan to develop a new generator that the users can use to produce various kinds of MFI distributions. This will help provide a common testbed against which new algorithms can be benchmarked. Knowing the conditions under which a method works well or does not work well is an impor- tant step in developing new solutions. In contrast to pre- vious studies we were able to isolate these conditions for the different algorithms. For example, we were able to im- prove the performance of GenMax? to match MaxMiner on mushroom dataset. Another obvious avenue of improving GenMax and Mafia is to efficiently handle Type I11 data. It seems possible to combine the strengths of the three meth- ods into a single hybrid algorithm that uses the horizontal format when required and uses bit-vectors/diffsets or per- haps bit-vectors of diffsets in other cases or in combination.

We plan to investigate this in the future.

