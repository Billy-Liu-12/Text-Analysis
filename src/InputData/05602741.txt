SICE Annual Conference 2010  August 18-21, 2010, The Grand Hotel, Taipei, Taiwan

Abstract?Recently, an evolutionary algorithm named Genetic Network Programming with Estimation of Distribution Algo- rithm (GNP-EDA) has been proposed and applied to extract classification rules for solving traffic prediction problems. The measures such as the support, confidence and ?2 value are adopted to evaluate the interestingness of a large number of rules extracted from traffic databases in the above data mining method.

In data mining, many other measures have been proposed to evaluate the interestingness of association patterns. These measures usually provide different and conflicting results. Many studies investigate that the effects of different measures depend on the concrete applications. We rarely know what measures are the appropriate ones for the traffic prediction application.

Therefore, a novel approach to select the right measure for the classification rule mining has been proposed in this paper. The simulation results show that the proposed interestingness measure selection approach is a powerful tool to select the right measure for the traffic prediction application, leading to the increase of the classification accuracy.

Keywords?Interestingness Measure, Classification Rule Min- ing, Genetic Network Programming, Estimation of Distribution Algorithm, Traffic Prediction.



I. INTRODUCTION  Generally, association rule mining [1] and classification rule mining [2] are the two most popular techniques in data mining. Both of association rules and classification rules are represented as if-then type rules. However, there are some differences between them. Association rules are generally used as descriptive tools, which give the association relationships to the specific application experts, while classification rules are used for predicting the unseen testing data. Therefore, the evaluations of the two type of rules are different. Association rules are typically evaluated by the application experts, while classification rules are evaluated by the classification accuracy of testing data.

In order to discover the strongly correlated rules, many kinds of measures have been proposed to evaluate the inter- estingness of patterns, such as famous support and confidence [1]. However, there are so many measures proposed and different measures have different properties which usually lead to different and conflicting results. Some studies investigate that there is no optimal measure which is better than others in all applications [3][4]. Therefore, given a specific application, finding the appropriate measure becomes the essential problem in data mining.

Some authors have studied intensively to analyze different interestingness measures used by data mining and select the appropriate one for given applications. As one of the most famous approaches, Tan et al. proposed a method to help the selection of right measure from the list of 21 measures [3].

Moreover, Lenca et al. proposed a different approach which uses an Multiple Criteria Decision Aid (MCDA) method on 20 classical interestingness measures with users? objectives.

However, both of them focus on selecting the right measure for association rule mining, in which the users need the specific application experts to provide the expected results or objectives. In Tan et al.?s paper, the proposed method is based on the hypothesis that the expected ranking of rules is provided by ?-coefficient. Lenca et al. assume two scenarios, where the experts accept or refuse the appearance of a certain number of count-examples1 to find appropriate measures.

However, in classification rule mining, the most important point to evaluate the quality of rules is the classification accuracy. Therefore, there usually is not expert which could provide the expected results. For classification rule mining, given a specific application, the interestingness measure which can provide the highest classification accuracy would be the appropriate measure.

Recently, as an extension of Genetic Network Programming (GNP) [5][6][7], a novel evolutionary algorithm called GNP with Estimation of Distribution Algorithm (GNP-EDA) has been proposed and applied to classification rule mining to find time-related classification rules for solving traffic prediction problems [8][9][10]. In this algorithm, three measures like support, confidence and ?2 value cooperate to evaluate the interestingness of classification rules. Support and confidence are the two most frequently used measures in data mining.

However, we rarely know what measures are the appropriate ones for the traffic prediction application. Therefore, the appropriate measure is necessary to be found.

In this paper, a novel interestingness measures selection ap- proach is proposed for classification rule mining. The proposed approach is studied in the specific traffic prediction applica- tion. With the right selection of interestingness measures, the better rules could be discovered from the traffic databases,  1Given two attributes X and Y , the count-examples denote the count of itemsets that if X is true, then Y is false.

PR0001/10/0000-1969- 1969 -    TABLE I THE CONTINGENCY TABLE OF X AND Y .

Y ?Y X nXY nXY nX?X n  XY n XY  n X  nY nY N  N : the total number of tuples.

nX : the number of tuples where X is satisfied.

n X  : the number of tuples where X is not satisfied.

nY : the number of tuples where Y is satisfied.

nXY : the number of tuples where X and Y are satisfied.

n XY  : the number of tuples where X is satisfied but Y is not.

n XY  : the number of tuples where X and Y are not satisfied.

which lead to a higher classification accuracy.



II. INTERESTINGNESS MEASURES  As powerful tools, interestingness measures are widely used in data mining. Measures can be used to discover the interesting patterns and rank/filter them according to the scores of interestingness. For a given rule X ? Y , various measures are usually defined using the frequency counts as shown in Table I. Recently, many interestingness measures have been proposed for discovering and filtering rules in data mining.

Table II presents a list of widely used measures studied in this paper.

TABLE II LIST OF INTERESTINGNESS MEASURES.

Measure Formula  Support nXYN  Confidence nXYnX Laplace nXY +1nX+2  Conviction nXnY n XY  N  Piatetsky-Shapiro?s measure (PS) nXY ? nXnYN Lift nXYNnXnY Certainty Factor (CF) nXYN?nXnYnXN?nXnY All-confidence nXYmax{nX ,nY } Cosine nXY?nXnY ?2 value  ? AllCells  (Observation?Expectation)2 Expectation  Support and confidence are the most two famous and frequently used measures in data mining. Support is useful to prune the uninteresting rules [11][12], while confidence is often used to measure the accuracy of extracted rules [3] and estimate the classification results [2]. However, the major drawback of support and confidence is that they usually tend to generate a large quantity of rules.

Some studies have investigated that both generality and reliability should be included in a good measure, where support and confidence are generally used to represent them, respectively [13]. For example, Bayardo et al. [14] proved that many well-known measures such as laplace, conviction, gini and lift are monotone functions of support and confidence. In this paper, we restrict the list and select the most widely used  laplace [15][16], conviction [17], Piatetsky-Shapiro?s measure (PS) [18], lift [19][20] and certainty factor (CF) [21] as representatives of such measures.

Some other interestingness measures studies the null- transaction2, which is normal in large databases. All- confidence [22] is emerging as a kind of such measures with respect to null-transaction. Another widely-used measure is cosine (also called IS measure) [13].

Another category of measures have been proposed for measuring deviation from statistical independence, such as ?2  value [19] and Pearson?s correlation coefficient (?-coefficient) [23]. However, since ?2 = ?2/N and it is easier for ?2 value to set the significance level, ?2 value is selected to study as the representative of such measures.



III. THE PROPOSED APPROACH  This subsection describe the proposed approach for se- lecting the appropriate interestingness measure for the traffic prediction application.

A. Time-related classification rules for traffic prediction  A novel algorithm called Genetic Network Programming with Estimation of Distribution Algorithm (GNP-EDA) based classification rule mining has been proposed [8][9][10]. The effectiveness and accuracy of the proposed algorithm have been proved in a traffic prediction system. The GNP-EDA is used to extract time-related classification rules from the traffic databases. The average traffic flow of each section is discretized to Low, Mid or High and saved in the traffic databases. The form of attributes saved in the traffic database can be denoted as Ai(?), where Ai represents the road section and ?(? ? {Low,Mid,High}) represents the class of the traffic flow. The time-related classification rules can be discovered with the following form: Ai(?)(t = ta) ? ... ?Aj(?)(t = tb)? Ac(?)(t = tc).

Here, ta, tb and tc are the time points which satisfy the condition: ta ? ... ? tb ? tc. This kind of time-related classification rules can represent the relationships between different attributes with different time points, which can be used to do the classification for traffic prediction [8][9][10].

B. Roles of interestingness measures  In the GNP-EDA based classification rule mining algorithm, interestingness measures play important roles, where various measures are used for discovering, evaluating and ranking rules. In the previous research, support, confidence and ?2  value measures are combined for rule extraction. However, we rarely know whether such measures are the appropriate ones for the traffic prediction problem. Therefore, various measures are necessary to be considered in the algorithm.

To solve the above problem, we propose an approach for se- lecting the appropriate measure in this paper. The flowchart of the appropriate interestingness measure selection approach is shown in Fig. 1. In this approach, the interestingness measures  2Null-transaction denotes the transactions that do not contain any of the object itemsets. In Table I, n  XY represents the number of null-transaction.

- 1970 -    Start  End  Rule Extraction  Rule Pool  List of Measures  Evaluation of Rules  1 m ||M  ??  Rank Rules  Classification  Comparison of Classification  Accuracy  support, confidence  Roles of measures  ??  1 m ||M  ????  Fig. 1. Flowchart of proposed approach.

play important roles. Firstly, support and confidence are used to evaluate the interestingness of candidate classification rules.

After the rule extraction step, each interestingness measure from Table II is selected to evaluate the interestingness of extracted rules and rank them. The selected measure also plays an important role in the classification step. The measure which can provide the highest classification accuracy for unseen testing data is the appropriate interestingness measure for the traffic prediction. The details of the procedure are described below.

C. Rule extraction  An evolutionary algorithm named Genetic Network Pro- gramming with Estimation of Distribution Algorithm (GNP- EDA) [8][9][10] is applied to find classification rules. The detail of the method can be found in the cited papers. In the rule extraction step, two famous measures, i. e. , support and confidence are applied to evaluate the candidate rules and prune the uninteresting rules. The reason why support and confidence are chosen is that support and confidence are powerful tools to prune the uninteresting rules by calculating the statistical probabilities [1][3][14]. The rules satisfied the following conditions are extracted and saved in the rule pool.

support ? supportmin, (1)  confidence ? confidencemin, (2) where supportmin and confidencemin are the thresholds for pruning the uninteresting rules.

Since GNP-EDA is a kind of evolutionary algorithm, the rule extraction is done iteration by iteration until a predefined fixed number of rules are discovered. Taking the road section Ac as an example, there are three corresponding sets of rules whose consequent attribute is Ac(Low), Ac(Mid) or Ac(High). GNP-EDA extracts a fixed number (Nf ) of rules for each consequent attribute.

D. Rank rules  As described above, the classification rules are extracted based on the thresholds of support and confidence. Even if the rules can be evaluated by these two measures, there are still a large number of rules saved in the rule pool. Therefore, adopting the other measures to rank and filter the discovered rules is quite necessary and essential in our task. In the proposed approach, we study the measures list in Table II to evaluate the extracted rules and rank them.

Let M denotes the set of suffixes of interestingness mea- sures, and m ? M. The ranking mechanism of the proposed approach is described as follows. When evaluating and ranking two rules r1 and r2 by measure m, r1 has higher rank order than r2 if and only if:  ? m(r1) > m(r2); or ? m(r1)=m(r2), but confidence(r1) >confidence(r2);  or ? m(r1)=m(r2) and confidence(r1)=confidence(r2), but support(r1) >support(r2); or  ? m(r1)=m(r2), confidence(r1)=confidence(r2) and support(r1)=support(r2), but r1 is a generalized rule3  or has fewer attributes in its antecedent part comparing with r2.

Using the above ranking mechanism, all rules saved in the rule pool are sorted by each measure, which will be used for later classification.

E. Classification  For a target road section Ac, there are three corresponding sets of rules whose consequent attribute is Ac(Low), Ac(Mid) or Ac(High). We denote the three corresponding sets of rules as Rc(?), ? ? {Low,Mid,High}. In order to predict the traffic flow of the road section Ac of L time points later at the current time point CT, which is called L-step prediction, the rules whose Prediction Span (PS) is equal or larger than L (PS ? L) would be valid for providing the useful prediction information for the the road section Ac.

Definition 1 (Prediction Span (PS)): The time difference between the last attribute of the antecedent part and the consequent attribute of a rule is called Prediction Span.

After all the rules are ranked by a selected measure, a subset of the rules with the highest scores of interestingness by the selected measure is picked up from the rule pool. Given road section Ac whose traffic is to be predicted, the three sets of rules Rc(Low), Rc(Mid) and Rc(High) are selected from the rule pool. We select the top ? (coverage threshold) rules with the highest scores of interestingness and saved in the corresponding subsets R?c(?).

After obtaining the three sets of rules R?c(?), we use these rules to predict the traffic flow by calculating the average matching degree with the testing data. Trivially, given a rule r ? R?c(?), if the antecedent part of the rules matches the testing data, we assign the consequent attribute of rule r to  3For r1 with the form of X ? Y and r2 with the form of X? ? Y , r1 is a generalized rule with respect to r2, if and only if X ? X?.

- 1971 -    prediction result. Since there are many rules in the subset of rules R?c(?), multiple rules are used for classification. To decide which label a testing data should have, an average matching degree mechanism is adopted in this paper.

Let m ? M denote the interestingness measure used for ranking the rules and m(r) denotes the value of rule r by measure m. Num(?) denotes the number of rules in R?c(?).

R?cm(?) indicates the set of suffixes of the rules in R?c(?) whose antecedent part matches with the testing data. For given testing data d, the average matching degree of data d with rules in R?c(?) is calculated as follows.

Match?(d) =  ?  r?R?cm(?) m(r)  Num(?) , (3)  The values of Match?(d) of three classes (*) are compared, where the class with the highest average matching degree is the classification result.

The classification results are compared with the actual testing data for calculating the classification accuracy. Dif- ferent selection of the interestingness measures would lead to different classification accuracies. After the comparison, the appropriate measure for the traffic prediction application could be found.



IV. SIMULATIONS  In this section, the interestingness measures shown in Table II are studied in the traffic prediction application. The proposed approach is adopted to find the appropriate measure from the 10 famous measures in the list for the traffic prediction application.

The evolutionary algorithm GNP-EDA is carried out to mine the classification rules from the traffic databases. Two simulations are carried out based on different settings of Nf 4, i.e., 200 and 300.

The thresholds of support and confidence in rule extraction are defined as follows, supportmin = 0.03, confidencemin = 0.8.

The structure of the rules is time-related, where there exist time differences between different attributes of the rules. 1- step prediction (L = 1) is carried out for traffic prediction.

The classification accuracy is calculated by checking whether the classified results satisfied the actual results as shown in Eq. (4). The classification accuracy is composed of training accuracy and testing accuracy, where testing accuracy would guide us to find the appropriate measure.

Accuracy = Number of testing examples correctly classified  Total number of testing examples , (4)  10 interestingness measures in Table II are used to rank the extracted rules and make a comparative study. As a result, the appropriate measure for the traffic prediction application could be obtained.

4For target road section Ac, we mine Nf classification rules for each set of Rc(Low), Rc(Mid) or Rc(High) whose consequent attribute is Ac(Low), Ac(Mid) or Ac(High).

A. Simulation results  We start by analyzing various measures with different coverage thresholds (?). The role of the analysis is to rank the rules using each selected measure.

The classification accuracy of the interestingness measures with different values of coverage threshold (?) are shown in Fig. 2 and 3, which are the average over 10 different trials of rule extraction. Moreover, the ranking of testing accuracies of the measures listed in Table II is shown in Table III.

B. Simulation analysis  Results showed that different measures provide different classification accuracies for the same set of rules, and the classification accuracies would also be different for different coverage thresholds. Summarizing the two simulations with different Nf , we could find that Laplace could provide the highest classification accuracy in testing data, which means that Laplace is the appropriate interestingness measure for the traffic prediction application presented in this paper. Con- fidence, conviction, lift and CF provide similar accuracies in both training and testing, since conviction, lift and CF are the functions of confidence. On the other hand, we could find that ?2 value used in the previous research [8][9][10] is not the appropriate measure for the traffic prediction application since it can not obtain the highest accuracy. The rest measures provide much worse results because of the misleading ranks.

On the other hand, an extended analysis is done between the training accuracy and testing accuracy. Based on these comparison, we could find that the ranking of Laplace in the training data is just in the fifth, but it achieves the best performance in the testing data, while some other measures such as confidence, conviction, lift and CF could get the higher accuracy than Laplace in the training data, but achieve worse accuracy in the testing data. The reason for such a phenomenon is that Laplace could extract more general rules using the training data, which could provide better performance in the testing data. Some other measures pay much more attentions to the specific rules, which causes the overfitting problem.

Moreover, the values of interestingness evaluated by mea- sures play another important role in our model for the traffic prediction problem. The accuracies by different measures may be different in the testing, even if the same rankings of rules are achieved in the training. Such phenomenon could be found from the comparison among confidence, conviction, lift and CF in Fig. 2(a) and 2(b). The training accuracies of them are the same, but the testing accuracies are different.

Analyzing all measures listed in Table II as a whole, we introduce four properties of interestingness measures that should be considered in classification rule mining.

P1 Measure m could help to discover the rules with high classification accuracy on the training data.

P2 The rules evaluated by m should not be too specific to cause overfitting, which makes the low classification accuracy on the testing data.

- 1972 -    TABLE III RANKING OF TESTING ACCURACIES OF INTERESTINGNESS MEASURES LISTED IN TABLE II. (UNIT: %)  Measure Support Confidence Laplace Conviction PS Lift CF All-confidence Cosine ?2 value  Nf=200 Ranking 9 4 1 4 7 3 2 10 8 6  Accuracy 79.03 87.35 88.22 87.35 80.32 87.51 87.55 78.79 80.21 82.44  Nf=300 Ranking 7 2 1 2 8 2 2 10 9 6  Accuracy 82.46 87.16 88.52 87.16 80.55 87.16 87.16 79.31 80.22 82.54           20  25  30  35  40  45  50  55  60  65  70  C la  ss if  ic at  io n  A cc  ur ac  y  Coverage threshold  The highest accuracy (Confidence, conviction, Lift, CF)  Laplace Support  PS All-confidence  Cosine ?2 value  Confidence, conviction, Lift, CF  (a) Training accuracy           20  25  30  35  40  45  50  55  60  65  70  C la  ss if  ic at  io n  A cc  ur ac  y  Coverage threshold  The highest accuracy (Laplace)  Laplace Support  PS All-confidence  Cosine ?2 value  Confidence, Conviction Lift CF  (b) Testing accuracy  Fig. 2. The classification accuracies using different interestingness measures with Nf = 200.

P3 The range of interestingness values evaluated by measures is to be limited, such as (0, 1), (-1, 1), etc.

P4 Measures should distinguish the positive and nega- tive correlations of X and Y.

From the simulations we could find that an appropriate measure can usually provide a good training accuracy. On the other hand, it does not mean that the measure with the highest training accuracy can ensure the highest testing accuracy, since the overfitting problem may happen. Therefore, P1 and P2 should be studied based on different applications.

The reason why P3 is important is that if the range of inter- estingness values is limited, the overfitting problem could be relatively avoided. Taking ?2 value5 as an example, the range of values is in (0, +?). The rules having large interestingness values are considered to be more important than some other rules with small values, even if they are evaluated above the threshold of significance level. Such phenomenon will cause the overfitting problem in classification rule mining. For the property P4, a good measure should distinguish the positive and negative relationships of X and Y, since the ranking of rules will be confused, which leads to a bad performance of classification.

The simulations showed that the selection of the appropriate  5The threshold of ?2 value is set at 3.84 with the 95% significance level, or 6.63 with the 99% significance level.

measure is an essential problem in classification rule mining. It should be noticed that the best coverage threshold (?) should be studied and the appropriate number of rules should be selected to achieve the best classification performance through the evaluation by the appropriate measure. In our simulations, the highest testing accuracy can be found where laplace is selected and ? is set at 30.



V. CONCLUSIONS  An interestingness measure selection approach has been proposed in this paper. This approach focuses on selecting the appropriate measure for classification rule mining, which could not be solved by some previous studies. The proposed approach is applied to GNP-EDA based classification rule mining for solving traffic prediction problems. A list of 10 famous measures is studied by the proposed approach. The simulation results show that the proposed approach is a pow- erful tool. With the selection of the appropriate measure for the specific traffic prediction application, it has been found that the classification accuracy will be increased. In this paper, we found that laplace measure is the most appropriate measure for the traffic prediction. Based on the study, this paper proposed four properties of interestingness measures for classification rule mining, which are helpful to analyze the interestingness measures.

This work can also be extended to the other applications and classification rule mining methods, which is helpful to analyze  - 1973 -             20  25  30  35  40  45  50  55  60  65  70  C la  ss if  ic at  io n  A cc  ur ac  y  Coverage threshold  The highest accuracy (Confidence, conviction, Lift, CF)  Laplace Support  PS All-confidence  Cosine ?2 value  Confidence, conviction, Lift, CF  (a) Training accuracy           20  25  30  35  40  45  50  55  60  65  70  C la  ss if  ic at  io n  A cc  ur ac  y  Coverage threshold  The highest accuracy (Laplace)  Laplace Support  PS All-confidence  Cosine ?2 value  Confidence, Conviction, Lift, CF  (b) Testing accuracy  Fig. 3. The classification accuracies using different interestingness measures with Nf = 300.

various measures and select the most appropriate measure, leading to the increase of the classification accuracy.

