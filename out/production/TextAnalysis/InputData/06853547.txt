FAST AND ROBUST BOOTSTRAP METHOD FOR TESTING HYPOTHESES IN THE ICA MODEL

ABSTRACT  Independent component analysis (ICA) is a widely used tech- nique for extracting latent (unobserved) source signals from observed multidimensional measurements. In this paper we construct a fast and robust bootstrap (FRB) method for test- ing hypotheses on elements of the mixing matrix in the ICA model. The FRB method can be devised for estimators which are solutions to fixed-point (FP) equations. In this paper we develop FRB test for the widely popular FastICA estimator.

The developed test can be used in real-world ICA analysis of high-dimensional data sets seen e.g. in big data analysis, as it avoids the common obstacles of conventional bootstrap such as immense computational cost and lack of robustness.

Moreover, instability and convergence problems of the Fas- tICA algorithm when applied to bootstrap data are prevented.

Simulations and examples illustrate the usefulness and valid- ity of the developed test.

Index Terms? bootstrap, FastICA, hypothesis testing, independent component analysis  1. INTRODUCTION  Independent component analysis (ICA) [1] is a widely used multivariate analysis technique with applications in many diverse fields. Up to date, the methodological (estimation) framework of ICA is mature and very well developed, yet the inference (hypothesis testing) framework of ICA is still in its infancy. In many ICA problems, not all source signals are present in all recording mixtures. Propagation of a source signal may be limited to a few sensors in the vicinity of the source-of-interest and sensors farther apart may not observe that source (MEG is a good example of such sensing modal- ity). Therefore tests for hypotheses on the coefficients of the mixing matrix are needed to investigate contribution of a spe- cific source signal-of-interest onto a specific mixture variable which in turn reveals sparsity of the ICA mixing matrix. Such tests can have variety of applications as is outlined in [2, 3].

In this paper, we develop hypothesis tests on the coefficients of the mixing matrix of the linear ICA model using a fast and robust bootstrap (FRB) [5, 6, 7] scheme. The FRB method is applicable for any estimator that can be represented in form of fixed-point (FP) equations. Here we develop the method  for the widely popular FastICA estimator [1, 4].

Recall that in the linear ICA model, the observed random  vector, x ? Rd is a linear mixture of unobserved random source vector s = (s1, . . . , sd)? possessing statistically inde- pendent components (IC?s), i.e.,  x = As = a1s1 + ? ? ?+ adsd, (1) where A = (a1 ? ? ? ad) is the unknown full rank d ? d mix- ing matrix whose coefficients aij = [A]ij represent the con- tribution of the jth source sj onto the ith mixture variable xi (i, j ? {1, . . . , d}). Given a data set X = (x1 ? ? ? xn) of n i.i.d. random vectors from the ICA model (1), the goal is to estimate the unknown demixing matrix W = A?1 = (w1 ? ? ? wd)?, whose (transposed) row vector wi is the ith demixing vector. The data x is centered, i.e. has zero mean, which also implies that E[s] = 0. A limitation of ICA is that for identifiablity of the demixing matrix (up to sign, scale and permutation ambiguity of the demixing vectors), at most one source is allowed to possess a Gaussian distribution [1].

Furthermore, due to scaling ambiguity, we can adopt the con- vention that the sources are of unit variance, i.e., E[s2i ] = 1 for i = 1, . . . , d. Above, we have assumed that the number of mixtures equals the number of sources. This is not a lim- itation since the dimensionality of x can be reduced e.g., by Principal Component Analysis (PCA).

In this paper, we develop bootstrap tests for hypothesis H0 : aij = 0 vs H1 : aij ?= 0. Bootstrap is a modern sta- tistical inference tool based on data resampling and it has be- come an increasingly important tool in modern data analysis; see text-books [8, 9, 11] for more details. For example, a con- ventional bootstrap test of level ? rejects the null hypothesis if the 100(1 ? ?)% confidence interval formed by the boot- strap distribution of a?ij does not contain 0. Such a method is computationally impractical for high-dimensional (HD) data since it requires that the FastICA estimator A? = W??1 is cal- culated for several thousands of HD bootstrap samples. On the other hand, tests developed in [2, 3] based on the asymp- totic behavior of FastICA estimator perform poorly when the sample size is of the same magnitude as the dimension. More- over, for real-world data, the ICA model can be at best only approximately true, and thus validity of tests based on asymp- totic results can be questioned. Another problem is instability and convergence problems of the FastICA algorithm when ap-      plied to high-dimensional data sets. The developed FRB test avoids these problems: it is fast to compute, more robust and avoids the common convergence problems as the estimator need not be (re)computed for each bootstrap sample.

The paper is organized as follows. In Section 2, the FRB method and the FastICA estimator are reviewed. It is also shown that the FastICA estimator can be expressed as a so- lution to FP equation. Conventional bootstrap hypothesis test (e.g., [8, 9]) using FastICA estimator is described in Section 3 followed by a construction of FRB hypothesis test in Sec- tion 4. Section 5 provides simulation examples and Section 6 concludes.

Relations to prior work: References [2, 3] construct tests based on asymptotic (normality) approximation of Fas- tICA estimator. Up to our best knowledge, this paper provides first contribution of bootstrap tests for purposes of testing hy- potheses on elements of the mixing matrix.

2. PRELIMINARIES  2.1. The FRB method  Let ??n ? Rm be an estimator of parameter of interest ? ? Rm based on data set X = (x1 ? ? ? xn). Throughout the paper, X? = (x?1 ? ? ? x?n) denotes a bootstrap sample which is ob- tained by resampling with replacement from the columns of

X. Compared with the conventional bootstrap, the fast and ro- bust bootstrap method [5, 6] is computationally efficient and robust to outliers. It is applicable for estimators ??n ? Rm that can be expressed as a solution to a system of smooth FP equations ??n = Q(??n;X), where Q : Rm ? Rm. The boot- strap replicated estimator ??  ? n then solves ??  ? n = Q(??  ? n;X  ?), where the functionQ is same as above but now dependent on the bootstrap sample X?. Then, instead of computing ??  ? n, we  compute the approximation  ?? 1? n = Q(??n;X?), (2)  which is considered as a one-step estimator of ?? ? n with initial  value ??n. In conventional bootstrap, one uses the distribution of ??  ? n to estimate the sampling distribution of ??n. Since the  distribution of the one-step estimator ?? 1? n does not accurately  reflect the sampling variability of ??, but typically underesti- mates it, a linear correction is applied as follows:  ?? R? n = ??n +  [ I??Q(??n;X)  ]?1( ?? 1? n ? ??n  ) , (3)  where ?Q (?) ? Rm?m is the matrix of partial derivatives w.r.t. ??n. Then under sufficient regularity conditions, ??  R? n  will be estimating the same limiting distribution as the actual bootstrap replications ??  ? n do. In most applications, ??  R? n is not  only much easier to compute than ?? ? n, but numerically more  stable and robust; see [5, 6, 7] for details.

2.2. FastICA  Let us first recall the principles of the deflation-based Fas- tICA, hereafter referred to as FastICA. We then show that Fas- tICA estimator can be expressed as a solution to a FP equa- tion. Our derivations and notations follow [10].

Let C = E[xx?] denote the positive definite symmetric d ? d covariance matrix of x. We define the inner product in the vector space Rd as ?w,v? = w?Cv. FastICA demix- ing vector w (a transposed row vector of the demixing ma- trix) is defined as a maximizer of a non-Gaussianity measure |E[G(w?x)]|, where G can be any twice continuously differ- entiable nonlinear and nonquadratic function with G(0) = 0; see [1, Chapter 8]. We write g = G? and g? = G?? for the 1st and 2nd derivative of G respectively, where g is referred to as the ICA nonlinearity. Then at the kth deflation stage, the maximum of |E[G(w?x)]| is searched under the unit-norm constraint ?w?2 = w?Cw = 1 (which implies unit variance of the sources) and orthogonality-constraint with the previ- ously found demixing vectors, i.e., ?w,wi? = w?Cwi = 0.

Thus at the kth deflation stage, the FastICA estimator wk maximizes the Lagrangian  L(w;?1, . . . , ?k) =  |E[G(w?x)]| ? ?k (w?Cw ? 1)?  k?1? i=1  ?iw ?Cwi,  where ?1, . . . , ?k are the Lagrange multipliers. Hence the so- lution wk, needs to verify the following estimating equation (obtained by setting the gradient of the Lagrangian w.r.t. w to zero)  E [ g(w?k x)x  ]? ?kCwk ? k?1? i=1  ?iCwi = 0,  where ?i?s are found to be ?i = E [ g(w?k x)(w  ? i x)  ] . This  equation can be rewritten as FP equation  wk =  ?k ??k?1C?1mk, (4)  where mk = E[g ( w?k x  ) x] and  ??k?1 = I? k?1? i=1  wiw ? i C = I?  k?1? i=1  ?wi, ??wi  is an orthogonal projection operator that project onto the or- thogonal complement of the subspace (of the inner product space) spanned by the previously found demixing vectors w1, . . . ,wk?1.

3. THE CLASSICAL BOOTSTRAP TEST FOR ICA  Suppose the FastICA algorithm is run to find an estimate of the demixing matrix W?, thus giving an estimate of the mix- ing matrix as A? = W??1. Let us recall some properties of     FastICA that need to be considered when constructing a boot- strap procedure. First, recall from [10] that the accuracy of W? is heavily influenced by the extraction order of demixing vectors. In other words, the distribution of W? differs from one specific order of source extraction to another. Hence it is important that for each bootstrap sample X?, the extrac- tion order of the sources remains the same as for the original FastICA demixing matrix estimator W?. The chance of main- taining the same order of extraction can be increased by using the original W? as the initial guess for the FastICA algorithm when applied for the bootstrap sample X?. Nevertheless, if the order of extraction is different from W?, one should dis- card the case and run the FastICA algorithm again for a new bootstrap sample. Note that as the dimension d of the data in- creases, the probability of discarding bootstrap samples tends to increase as well. Second, due to ICA ambiguities, the sign of the demixing vectors may differ. Thus, after verifying that the same extraction order was found when running the algo- rithm for the bootstrap sample, one needs to fix the signs of the demixing vectors to match the signs of W?. Third, when applied to bootstrap data, it is not uncommon that the FastICA algorithm exhibits convergence problems. In such cases, an- other bootstrap sample needs to be drawn, until the algorithm converges to a non-singular solution (with right extraction or- der).

Considering the above obstacles and given that several thousands bootstrap samples are needed for hypothesis test- ing, it is clear that the conventional bootstrap does not provide a feasible solution especially for high-dimensional real-world data sets.

4. THE FRB TEST FOR ICA  Based on equation (4), at finite samples, the FastICA esti- mator of demixing vector w?k solves the FP equation w?k = Q(w?k;X) where:  Q (w?k;X) = 1 ??k  ???k?1C? ?1  m?k,  ???k?1 = I ? ?k?1  i=1 w?iw? ? i C? and m?k = EFn  [ g ( w??k x  ) x ] .

Here a notation of the form EFn [q(x)] (resp. EF?n [q(x ?)])  for some function q denotes sample averages over data set x1, ? ? ? ,xn (resp. bootstrap data x?1, ? ? ? ,x?n), i.e., EFn [q(x)] =  n  ?n i=1 q(xi). The one-step estimator as in  (2) is now  w?1?k =  ???k ????k?1(C?  ? )?1m??k, (5)  where C?? = EF?n [ x?x??] is the sample covariance matrix  based on the bootstrap sample X?, m??k = EF?n [g ( w??k x  ?)x?] and ????k?1 = I ?  ?k?1 i=1 w?  R? i (w?  R? i )  ?C??. The FRB estimate is then  w?R?k = w?k + [I??w?kQ(w?k;X)]?1 ( w?1?k ? w?k  ) , (6)  Algorithm 1 The FRB test based on FastICA Input: Data set X, FastICA estimate W? based on X, number of bootstrap samples B, level ? of the test. Output: confidence intervals for aij .

1: Compute the FastICA FRB replicate of demixing matrix W?R? = (w?R?1 ? ? ? w?R?d )? based on bootstrap sample X? as explained in I-IV.

2: If W?R? is close to singular, repeat Step 1.

3: Compute the bootstrap mixing matrix A?R? = (W?R?)?1.

4: Repeat Steps 1?3 until B bootstrap estimates A?R?1 , . . . , A?R?B  are formed.

5: Construct 100(1? ?)% bootstrap confidence interval (CI). Re-  jectH0 if the CI does not contain 0.

where ?w?kQ(w?k;X)  =  ??2k ???k?1C?  ?1 ((  ??kI? m?kw??k ) M?k ? m?km??k  )  and M?k = EFn [g ?(w??k x)xx?]. Note that FRB approach  avoids the computation of the FastICA demixing matrix W??  for each bootstrap sample X?; instead one needs to proceed as follows:  I. Compute the FRB estimate w?R?k from equation (6).



II. Orthogonalize w?R?k w.r.t. the previously estimated demixing vectors:  w?R?k ? ????k?1w?R?k .



III. Normalize the result:  w?R?k ? w?R?k / ? (w?R?k )?C?  ? w?R?k .



IV. Perform the above steps for all demixing vectors and construct the FastICA FRB replicate of demixing matrix as W?R? = (w?R?1 ? ? ? w?R?d )?.

The procedure for constructing the FRB test of level ? for the elements of A? is explained in the Algorithm 1. In step 5 of the algorithm, 100(1??)% bootstrap confidence intervals (CI) can be obtained by percentile method as follows: first the bootstrap values of a?ij are sorted in an increasing order and then L = ?B/2?th and U = (B ? L)th largest values are taken as the lower and upper limits of the interval respectively, where B denotes the number of bootstrap samples [9].

5. EXAMPLE  We generate n = 1000 samples from the ICA model (x = As), where the source distributions are as follows: s1 has a Laplace distribution, s2 has a t-distribution with 5 degrees of freedom, s3 follows a logistic distribution and source s4 has a Gaussian distribution. All distributions have zero mean and     0.6 0.7 0.8    0.7 0.8 0.9    0.5 0.6 0.7 0.8 0.9    0.7 0.8 0.9 1    0.9 1 1.1    ?0.1 0 0.1    0.4 0.6 0.8    0.6 0.8 1    0.6 0.7 0.8    0.5 0.6 0.7 0.8    0.2 0.4 0.6    0.9 1 1.1    ?0.05 0 0.05 0.1    0.4 0.5 0.6    0.3 0.4 0.5 0.6    0.8 0.9 1    (a) Conventional bootstrap  0.6 0.7 0.8    0.7 0.8 0.9    0.5 0.6 0.7 0.8 0.9    0.7 0.8 0.9 1    0.9 1 1.1    ?0.1 0 0.1    0.4 0.6 0.8    0.6 0.8 1    0.6 0.7 0.8    0.5 0.6 0.7 0.8    0.2 0.4 0.6    0.9 1 1.1    ?0.05 0 0.05 0.1    0.4 0.5 0.6    0.3 0.4 0.5 0.6    0.8 0.9 1    (b) Fast and robust bootstrap Fig. 1. Obtained bootstrap distributions and the 95% confi- dence intervals. The null hypothesis is only accepted for a41 and a22 (the elements in light gray) in both methods.

unit variance. The elements of the mixing matrix A4?4 are randomly drawn from Unif(0.3, 1), except that a41 = [A]41 and a22 = [A]22 are set to zero to avoid any contribution of the 1st (Laplacian) and the 2nd (t5-distributed) source signals onto the 4th and 2nd mixture variables (x4 and x2) respec- tively.

We then run the conventional bootstrap and FRB hypothe- sis tests of level ? = 0.05 for elements of A. Both tests were constructed using B = 10000 bootstrap samples and tanh as the nonlinearity for the FastICA estimator. The results are in conformity with the considered A, i.e., the null hypothe- sis is only accepted for a41 and a22 in both methods. Figure 1 shows the respective bootstrap distributions where a41 and a22 are depicted in light gray. Below, the obtained confidence intervals for these two mixing coefficients are given based on the conventional bootstrap (CB) and the FRB method:  a41 a22 CB -0.0424, 0.0670 -0.0898, 0.0818  FRB -0.0406, 0.0668 -0.0883, 0.0839  Next let us investigate the power of the test. For this pur- pose, we generated samples from the ICA model where the mixing matrix was randomly generated except that (2, 2) ele- ment a22 = ? with the initial value set to ? = 0, conforming  0 0.05 0.1 0.15 0.2 0.25  0.2  0.4  0.6  0.8       gauss  tanh  pow3  Fig. 2. The observed probability of detection of FRB tests using gauss (solid line) tanh (dashed line) and pow3 (dotted line) nonlinearities. Note that while all the three nonlinearity have maintained close to the set PFA (1%), the gauss and tanh have provided steeper power curves than pow3.

with the null hypothesis H0 : a22 = 0. Then ? was increased in magnitude and the observed probability of detection (PD), i.e., proportion of correct rejections, as a function of ? were calculated. The obtained power curve of the FRB tests using gauss (solid line) tanh (dashed line) and pow3 (dotted line) nonlinearities are shown in Figure 2. The level (i.e., probabil- ity of false alarm) was ? = 0.01 and the number of generated samples (for each fixed ?) was 300. As can be seen gauss and tanh can be recommended in this setting since they have provided steeper power curves and better maintained the set PFA level (when the null is true). More specifically while the obtained PFA for pow3 is 0.027, nonlinearities gauss and tanh have provided PFA equal to 0.011 and 0.018 respec- tively. These results are in conformity with the fact that gauss is well suited for super-Gaussian sources (the case of this set- ting), tanh is a good general-purpose nonlinearity and pow3 is recommended for sub-Gaussian sources [4].

To illustrate the impracticality of conventional bootstrap in real-world HD data analysis problems, we calculated the bootstrap CI?s of mixing matrix for the 122-channel MEG data given in [1, Ch. 22]. We used an identical computing system for both methods. While the conventional bootstrap failed in providing the bootstrap CI?s in a reasonable time (taking several days to compute), the FRB method provided the bootstrap CI?s in just over one hour.

6. CONCLUSIONS  The proposed FRB test has a great potential of being used in a wide range of applications where ICA model is commonly applied. Classical bootstrap method is virtually impossible to apply, while the fast and robust bootstrap provides significant benefits in reducing the computational costs, offering stabil- ity and robustness. Hence, it facilitates processing of large volume and high-dimensional data sets using bootstrapping.

7. REFERENCES  [1] A. Hyva?rinen, J. Karhunen, and E. Oja, Independent Component Analysis, John Wiley & Sons, New York, 2001.

[2] S. Shimizu, A. Hyva?rinen, K. Yutaka, P.O. Hoyer, and A. J. Kerminen, ?Testing significance of mixing and demixing coefficients in ICA,? in Proc. Int. Conf. Inde- pendent Component Analysis (ICA 2006), Charleston, SC, USA, 2006, pp. 901 ? 908.

[3] E. Ollila and H.-J. Kim, ?On testing hypotheses of mix- ing vectors in the ICA model using FastICA,? in Proc.

IEEE Int. Symposium on Biomedical Imaging (ISBI?11), Chicago, USA, Mar. 30 - Apr. 2 2011, pp. 325 ? 328.

[4] A. Hyva?rinen, ?Fast and robust fixed-point algorithms for independent component analysis,? IEEE Trans. Neu- ral Networks, vol. 10, no. 3, pp. 626?634, 1999.

[5] M. Salibian-Barrera, Contributions to the Theory of Ro- bust Inference, Unpublished Ph.D. Thesis, University of British Columbia, Department of Statistics, 2000.

[6] M. Salibian-Barrera and R. H. Zamar, ?Bootstrapping robust estimates of regression,? The Annals of Statistics, vol. 30, pp. 556?582, 2002.

[7] M. Salibian-Barrera, S. Van Aelst, and G. Willems, ?Fast and robust bootstrap,? Statistical Methods and Ap- plications, vol. 17, pp. 41?71, 2008.

[8] B. Efron and R.J. Tibshirani, An Introduction to the Bootstrap, Chapman and Hall, New York, 1993.

[9] A.C. Davison and D.V. Hinkley, Bootstrap Methods and their Application, Cambridge Univ. Press, Cambridge, 1997.

[10] E. Ollila, ?The deflation-based FastICA estimator: sta- Processing, vol. 58, no. 3, pp. No.3, 2010.

[11] A. M. Zoubir and D. R. Iskander, Bootstrap Techniques for Signal Processing, Cambridge University Press, Cambridge, 2004.

