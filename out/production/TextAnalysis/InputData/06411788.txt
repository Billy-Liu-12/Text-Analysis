Recognition of Utterances with Grammatical

Abstract-To realize a voice-interactive CALL system, it is necessary to recognize the learner's utterance correctly including the grammatical mistakes. In this paper, we proposed methods for improving recognition accuracy of speech with grammatical mistakes. T he proposed method is based on the method that uses n-gram model trained from sentences that are generated using grammatical error rules. We introduced two improvements to the previous method: one is the utterance discrimination to avoid introducing errors into correct utterances, and the other one is optimization of language model where probability of grammatical mistakes in the generated training text is optimized using the score of utterance discrimination. As a result, we obtained 0.92 point improvement, which is 12% error reduction.

Index Terms: speech recognition, interactive CALL system, grammatical mistakes, language model

I. INTRODUCTION  With the progress of globalization in recent years, popu? lation of English learners has been increased. Among vari? ous English learning methods, Computer-Assisted Language Learning (CALL) system is one of the most promising learn? ing methods [l]. Most CALL systems focus on training for reading, writing and listening, and a few commercial CALL systems provide with training method for speaking. However, conventional CALL systems with speaking practice focus on training of pronunciation or intonation. To improve conversa? tion skills, it is necessary for learners to practice conversation in a real dialogue. To realize the conversation practice using computer, several voice-interactive CALL systems have been developed [2], [3], [4], [5]. We are now developing an inter? active CALL system of English for Japanese learners.

Speech recognizer is used to recognize the learner's utter? ance. Here, there are two problems for recognizing language learners' utterances. The first one is that pronunciations of learners are different from those by native speakers, and the difference greatly depends on the learner. The second problem is that the utterances made by the learner inevitably contain grammatical mistakes, which are not assumed in ordinary speech recognizers.

The first problem can be solved using acoustic models for non-native speaker [6], [7], [8]. To improve the recognition accuracy, speaker adaptation technique was also proposed for non-native speech recognition [9]. For the second problem, Kweon et al. proposed a rule-based method that expands a network grammar so that utterances with popular mistakes  can be accepted [3]. Ito et al. used grammatical error rules similar to the privious method to generate sentences containing grammatical mistakes, from which an n-gram model is trained [4]. Anzai et al. improved the error rules for generating training sentences [5].

In this paper, we introduce two improvements into speech recognition method based on n-gram trained from generated sentences. The first one is introduction of utterance discrimi? nation, which determines whether the input utterance contains grammatical mistakes or not before performing speech recog? nition. The second one is optimization of language modeling.

If the input utterance has many grammatical mistakes, we need to use a language model trained from sentence with many mistakes; if the input utterance is grammatically correct, grammatical errors in the training data may introduce recog? nition errors. Therefore, we developed a method to estimate how erroneous the input utterance is, and choose the optimum language model to recognize the input utterance.

I I. N-GRAM TRAINING FROM GENERATED SENTENCES  A. Interactive CALL system with pre-exercise In this work, we assume a dialog with a CALL system  with pre-exercise [3], where the learner first studies words and grammars used in the conversations in the lesson, then the learner actually converses with the CALL system. Pre? exercises make it easier for learners to produce speech when using the system. In addition, assuming a pre-exercise before the dialogue session with the system had the effect of sup? pressing off-task utterances by the learners [3].

As we assume a pre-exercise before the conversation with the CALL system, we can expect the learner to respond to the system using the same expressions as those appearing in the pre-exercise. Therefore, we assume there is a "correct" sentence to be uttered by the learner at a certain situation. We refer to such a sentence, a correct sentence expected to be uttered by a learner, as the target sentence. In a real session, however, not all user utterances match the target sentences. We refer to a sentence actually uttered by a learner as the uttered sentence. An uttered sentence often contains grammatical and lexical mistakes. The uttered sentences are recognized using the speech recognizer, and the recognition results often have recognition errors. We call the result of the automatic speech recognition as the recognized sentence.

A target I I am an office worker. I work at a car company. sentence I'm an office worker. I work at a car company.

Applied by probability Pe  '-1 Corpus-based error rules  work at ? work to at office worker ? work man a?an Sentence  generator  , Sentences  with/without errors  Generic error rules  worker ? workers work ? worked  or Thesaurus-b-as?dl error rules  work ? study car ? automobile  I am an office worker. I work at a car company.

I'm a office worker. I work to at a car company.

I am an office workers. I work at a car company.

I'm a work man. I worked at automobile company.

Fig. 1. Language model generation  B. Sentence generation and n-gram training Next, we explain how to train the n-gram language model  for recognizing the input utterance [4], [5]. Basically, we prepare an n-gram utterance by utterance, assuming that we know the target sentence of the utterance beforehand. Figure 1 shows the procedure of language model training.

First, we prepare grammatical error rules that are frequently made by Japanese learners. We prepare three kinds of rules: the corpus-based error rules extracted from the transcription of English utterances spoken by Japanese speakers [10], the generic error rules such as confusion of singular and plural, and the thesaurus-based error rules generated from Word Net.

Then the rules are applied to the target sentences by probability Fe (thus the sentence is unchanged by probability 1- Fe), and a sufficient amount of sentences are generated. Finally, a back? ofl N-gram is trained from the generated sentences.

I I I. UTTERANCE DISCRIMINATION AND LANGUAGE MODEL OPTIMIZATION  A. Overview There are two issues in the previous framework. One is  the tradeoff between coverage of error rules and recognition accuracy. We need to incorporate more and more error rules to obtain high coverage, but it raises perplexity of the n-gram and deteriorates the recognition performance. The other issue is how to determine Fe. Fe should be high when recognizing utterances with many mistakes, but if the utterance has no grammatical mistakes, high Fe just increases recognition error rate.

To solve the above two problems, we introduce two im? provements. The first improvement is the utterance discrimi? nation to determine whether the input utterance contains any words that are not in the target sentence. We use acoustic score as a feature of the discrimination. If the utterance is judged  Input Speech  .l s t+)  / Generated  I Generated  I text 11111 text P,=O.02 P,=O.50  --?  The target sentence I The recognized sentence S<B  .:\ ...

Result  Fig. 2. Overview of the proposed method  to be correct, we do not perform any further recognition. As this discrimination is independent from the sentence genera? tion, this method prevents the sentences without grammatical mistakes from recognition errors caused by the grammatical error rules. The second one is the optimization of language model. In this method, we first prepare many n-gram models trained from generated sentence sets with different Fe. When recognizing the input utterance, the best language model is selected using the acoustic score difference. Figure 2 shows the overview of the proposed method.

B. Discrimination of utterance with mistakes  First, we explain the input utterance discrimination. The discrimination is based on acoustic score (log-likelihood).

We calculate score of the input utterance twice, once using phone recognition without linguistic constraint, then using the grammar that accepts only the target sentence. Let the recognition scores calculated by these processes be Lp and Lt, respectively. Then we calculate the acoustic score difference  (1)  Figure 3 shows histogram of utterances with and without grammatical mistakes. We can see that correct utterances have smaller score difference. Therefore we use S as a feature of the discrimination. An input sentence is classified as "correct" when the score difference S is smaller than the threshold e.

If sentence is classified as correct, the target sentence was used as the recognition result. Otherwise, the utterance was recognized using the speech recognizer with the n-gram.

We carried out an experiment to investigate the effectiveness of the utterance discrimination. The experimental conditions are shown in Table I. The test utterances were collected by the following procedure: first, learners were asked to memorize the English target sentences, then utter the sentences by only seeing the Japanese translation of those sentences. Word accuracy of the uttered sentences with respect to the target sentences was 88.3%. The probability Fe was determined a      [ I 10   0 10  ? i"-?  correct wrong  j :i -?-if?f---l]?,. ,:l:._-i\ , 20 30 40  S 50 60 70 80  Fig. 3. Histogram of utterances with and without mistakes with respect to acoustic score difference S  TABLE I EXPERIMENTAL CONDITIONS  Acoustic model  Acoustic feature  Decoder  Number of generated texts Test utterances  512-mixture 5-state HMM trained using the ERJ database MFCC, 6.MFCC, 6.6.MFCC, 6.pow, 6.6.pow Julius 4.1.2 0.08 100,000/target sentence  441 utterances spoken by 15 speak? ers (14 male and 1 female)  posteriori so that the best word accuracy was obtained on the test set.

Figure 4 shows the word accuracy given by the proposed method. The leftmost part of Fig. 4 shows the word accuracy when all utterances were recognized using the n-gram. As shown, we could obtain an improvement of 0.48 point when setting e to the value around 12.

C. Optimization of language model In the previous method, the n-gram language model for rec?  ognizing the utterances with mistakes were trained using the generated sentences with fixed error probability Fe. However, the optimum value of Fe differs from utterance to utterance.

Figure 5 shows the word accuracy for four utterances with respect to the error probability Fe for generating training sentences. Figure 5 (a) shows the result for correctly uttered utterances (A and B) where the lower Fe gave better results.

Figure 5 (b) is that for utterances with mistakes (C and D)   92.5   ? 91.5 .li!

90.5  Fig. 4.

-5 o 5 10 e  15 20 25  Word accuracy with respect to the threshold e   V) "0 0 3: Q;  4-0 .? :0 co .0 2 c..

+-' :::> .s-:::> 0  100 f---------------, 65 A-?   B-- o 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5  Output probability of error words  (a) Utterances without mistakes  90 I-----f+-l-?f_' 65 c--  0.5 0.45  0.4 0.35  0.3 0.25  0.2 0.15  0.1 0.05  a  0-- o 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5  Output probability of error words  (b) Utterances with mistakes  Fig. 5. Word accuracy with respect to Pe  . . . ... . .

??????? ? .............................. .... .................. P " ???????????????????????  :I!. ... ? ? ...... ; ... ; ... ;.:.:? ... .;: .. :; ..................... .............................. .

???? ??????????????? ??? 1JII!' ?? ,. .......... ? ?? ? ?????????????????????????????????????? . .  ?.r. . . .

:::::.? :::????? ?::::t::::::?::::?:::::?::::::::::::::::::::::::::::::::: " . .

,??:????5:; ????? =: ?????????? ; ?????????????????????? a  . . ......... ....... .... ............................................................

? ..&., ?  20 40 60 80 100  Fig. 6. Acoustic score difference S vs. the optimum error probability (0.01 ?0.50)  where the maximum accuracy was obtained with higher Fe.

These results suggest that the word accuracy can be improved if we can choose a language model trained with sentences with appropriate error probability.

We use the acoustic score difference S for prediction of the optimum error probability. As explained above, S becomes smaller for sentences without mistakes. Figure 6 is a scatter plot of S and the optimum error probability for each utterance, as well as the result of linear regression. We used the result of linear regression for estimating the optimum Fe.

This framework is a similar approach to the language model selection. In the researches of spoken dialogue, language models are selected depending on dialog state [11], [12]. Our method is different from these approaches, where the language model is optimized using the input utterance. This kind of    93.5   92.5  ?j 92 c:r  (j ? 91.5   90.5  -10  Fixed -? Pro osed --  -5 o 5 10 15 20 25 30 e  Fig. 7. Word accuracy using the language model optimization  language model optimization is new attempt compared with the conventional language model adaptation schemes.

We carried out an experiment for confirming the effective? ness of the error probability estimation method. The evaluation data was the same as that in the previous section, and 15-fold cross validation (opened for each speaker) was performed for estimating the linear regression coefficients. We prepared 10 language models using Fe = 0. 0 1,0.02, . . .  ,0. 10. When the estimated Fe was larger than 0.10, the model trained with Fe = 0. 10 was used, because the model with larger Fe gave less word accuracy even for utterances with many grammatical errors.

Figure 7 shows the results, where the red line shows the result when Fe = 0. 08, and the green line is the result when Fe was predicted using linear regression. We can see that the proposed method improved the word accuracy constantly com? pared with the fixed error probability. The best result was 0.44 point better than the method with fixed error probability, and 0.92 point higher than the result when utterance discrimination and language model optimization were not used.



IV. CONCLUSION  In this paper, we proposed methods for improving recog? mtIOn accuracy of speech with grammatical mistakes. The proposed method is based on the method that uses n-gram model trained from sentences that are generated using gram? matical error rules. We introduced two improvements to the previous method: one is the utterance discrimination to avoid introducing errors into correct utterances, and the other one is optimization of language model where probability of grammat? ical mistakes in the generated training text is optimized using the score of utterance discrimination. As a result, we obtained 0.92 point improvement, which is 12% error reduction.

As we could improve the word accuracy, there is still more room for further improvement. If we could perfectly choose the error probability of the language model, the word accuracy raises to 95.1 %, that is 1.8 point higher than the above result.

We still need to improve language modeling, as well as the acoustic modeling.

