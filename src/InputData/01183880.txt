Investigative Profiling with Computer Forensic Log Data?and Association Rules

Abstract  Investigative profiling is an importanr activity in com- purer forensics that can narmw the search for one or more computerperpetrators. Data mining is a technique rhar has produced good results in providing insight into large vol- umes of data. This paper describes how the association rule data mining technique may be employed to generate profilesfrom log data and the methodology used for the in- terpretation of the resulting rule sets. The process relies on background knowledge in the form of concept hierarchies and beliefs. commonly available from, or attainable b l  the computer forensic investigative team. Results obtained with the profiling system has identifed irregularities in computer logs.

1 Introduction  Computer Forensics undertakes the post-mortem, or ?after-the-event? analysis of computer crime. Of particu- lar importance is the requirement to successfully narrow the potentially large search space often presented to investiga- tors of such crimes. This usually involves some form(s) of guided processing of the data collected as evidence in order to produce a shortlist of suspicious activities. Investigators can subsequently use this shortlist to examine related evi- dence in more detail 161.

Investigative profiling is an important activity in com- puter forensics that can significantly narrow the search for the perpetrator and reason about the perpetrator?s behaviour.

This is analogous to criminal profiling which focuses on es- tablishing personality characteristics of an offender in order to identify the type of person involved in the crime under investigation (e.g., arson). Profiling can also aid in identify- ing the type of activity the perpetrator is engaged in e.g., e- mail authorship analysis may identify the educational level or gender of the offender and may. consequently, be able to establish if an e-mail has been masqueraded [8].

Data Mining is employed to analyse large data sets, as  0-7695-1754-4/02 $17.00 0 2002 IEEE 11  might occur in a typical computer forensics investigation, in order to discover potentially useful, previously unknown regularities within data. In contrast to other, more conven- tional technologies, it has been able to produce good results on large data sets where both incompleteness and noise may be present, e.g., [9].

Data mining for the more specific purpose of construct- ing personal profiles has been used in the context of cus- tomer personalisation. Here, marketing content and ser- vices are tailored to an individual on the basis of knowl- edge about their preferences and behaviour. Applications include content-based and collaborative filtering-based rec- ommendation systems, customer profiling [2, 1, 131, fraud detection [IO], web browsing activities [7, 18, 23, 171.

Content-based recommendation systems model the link be- tween data content and a person?s preferences for that con- tent whereas collaborative recommendation systems model the link between a person?s preferences and other persons? preferences for the given data content [15. 191. Customer profiling is growing in importance in e-commerce. Both factual and individual behavioural information are derived from the customer?s e-transactional history. The personali- sation of web browsing activities for the purpose of improv- ing the user?s access to the web has also attracted interest recently. Techniques for the modeling of the user?s web access behaviour are varied including; the use of a page content interestingness metric (N-grams) for capturing a user?s interests [7], web page navigation dependencies for page predictive pre-fetching [181. web page clustering for deriving aggregate user profiles [17], sequential web page patterns for discovering negatively-correlated components within a web site structure [23]. However, most web per- sonalisation applications deal with aggregate or classes of user profiles rather than individual user profiles.

In this paper, we describe techniques to profile and anai- yse computer forensic data. We use a combination of ex- isting techniques not yet employed in this application do- main, modified where necessary to accommodate the partic- ular environment. In Section 2, we introduce the elements    used in our approach to computer forensic profiling. Further details are given in Section 3 about data preparation and the need for guiding the investigative process. Section 4 describes the algorithms we use .and how they have been adopted for our needs. Tests performed on actual computer log data are detailed in Section 5 .  followed by our conclu- sions in Section 6.

2 Background to Investigative Profiling  An offender profile consists of two components, namely the factual component and behavioural component. The factual profile (FP)  consists of factual background knowl- edge about the offender such as their name, employee sta- tus, computer user name@), relationships with other em- ployees and organisations etc. The behavioural profile ( B P )  incorporates knowledge about an offender?s crime scene-related behaviour. Behaviour profile knowledge is derived from a variety of sources namely, log file transac- tions, header and body of e-mails, telecommunications call- record data patterns and so on.

The behavioural profile, BP,  can be modeled in differ- ent ways. For example, a B P  can be represented as a union of sub-profile hierarchies (PH,) such as, authorship profile, software application usage profile, log-in profile etc, or  B P t  Uf? PHj A profile hierarchy is a knowledge representation scheme using a hierarchy of multi-slot frames, similar to a concept hierarchy (described in Section 3.1). that characterises a be- havioural profile.

Alternatively, BP can also be modeled as a set of asso- ciation rules:  B P c  {RJi =l.2; . . .  N } Here, the rule attributes can be obtained from the raw data andor selected from the profile hierarchy nodes. For exam- ple, the rule ?If user X is a system administrator, then the application Y = nmap (a stealth port scanner) executed may he a valid rule in a system administrator profile (as- suming that port scanning, as used in hisher current job context, is employed for system hardening), but probably not in a finance contractor profile.

In this paper we study user behavioural profiles derived from event data in log files. These profiles are conveniently represented by a set of implications or association rules {&ti = 1,2,. . . N }  of the form  R; : antecedent + consequent These rules provide an intuitive and declarative way to  describe user behaviour [IO]. For example, the rule Ro : (Stamype = admin) A (DayOfWeek = tuesday) A (Application = database) j (Access = valid) states that ?Administration staff that work on Tuesday have  a valid access to a database application?. Note that an asso- ciation rule indicates the presence of some correlation he- tween the rule?s antecedent and consequent, hut does not necessarily imply any causality.

2.1 Profiling with Association Rules  Association rule generation has been one of the most successful techniques in data mining. It originated as a tool for discovering sets of items that occur together in supermarket basket data [4]. Since then, it has evolved to address a multitude of other types of problems, to a point where it can even be used for purposes such as multi-dimensional inter-transaction mining [16]. Suppos- ing 1 = {il,i2,. . . ;in} is a set of items occurring in a data set, an association rule can be expressed by the for- mula A * B : (s:~): where A; B 2 1 are groups of items of size ka and kB, respectively, where ka + ka 5 m and A n  B = 0. We refer to the combined collection of items in A and Bas an ifemset of length k = k~ +LB. The variables s and o express support and confidence percentages for the rule, where support Y indicates how frequently the items in A and B occur together in  the data, while confidence c is the conditional probability P(B1A) where the probability P ( z ) is estimated using the support percentage of the set z. For example, the rule (breudAbutter) + ( m i l k )  : (15%, 70%) produced from a supermarket transactional database states that customers that buy bread and butter together are also 70% likely to purchase milk, with 15% of the total number of records supporting this claim.

One of the potential uses for associations is the build- ing of rule sets that describe behavioural data [2, 1.31. This may be data collected about people or the operation of some systems. Often in computer forensic investigations. this in- formation could be found in log files on a computer sys- tem. The rule sets generated from this data can be con- sidered to describe a profile contained within the data set.

Profiles produced this way, however, are usually not com- plete. The support percentage parameter used in associa- tion mining introduces loss into the rule set. This is because only data that occurs frequently enough (that is. satisfies a pre-defined minimum support) is used in the rule generation process. In the forensic sense, however, this is not necessar- ily a disadvantage. Regularities that are not picked up in the profile due to not satisfying support may he looked at as non-habitual and can be investigated as contrary to regular behaviour, if necessary.

Another important aspect of forensic profiling is that a user profile is generated using available evidence and does not change once produced. Additional evidence may be added later, hut this should be regarded as the incomplete- ness of initial evidence rather than the evolution of an exist- ing profile. In this case, the profile should be re-generated.

Recognising temporal segments, or evolution within a pro- file, however. is quite important and analysis of such phe- nomena can be a major part of the profile evaluation pro- cess.

2.2 Deviation in Association Rule Profiles  One of the first steps in a computer forensic investigation is to look for unusual events. For example, if an attacker gains super-user privileges on a computer system, he may use them to perform actions not normally instigated by the real super-user(s). This would clearly be a deviation from the super-user profile as supported by data up to the time of intrusion. There are two ways this may be evidenced in the data and the profile generated on the full data set:  1. As data entries with not enough support to be repre- sented as association rules: In order to find such en- tries, there must exist a mechanism for the investigator to query the data set for entries not fitting the profile.

2. As association rules making up pan of the profile: It would hence be important to identify this section of the profile as being anomalous, or at least different from other parts of the profile. Assigning a temporal scope to rules making up the profile could help an investiga- tor recognise that something potentially unusual may have occurred at a certain time in the life of the system being investigated.

There are, of course, caveats to the above. The attacker may have covered hislher uacks, for example, by removing en- tries from the log files. If he/she was thorough, he/she may have only removed entries corresponding to hisher own ac- tions, or. alternatively. may have removed all records. or every record stored during the period of the criminal activ- ity. In this case, the lack of evidence may warrant further investigation.

3 Building Profiles  The data obtained for computer forensic investigations are usually information stored on computers and networks.

They range from system log files to databases, personal user files and other items that may be located on a computer. To build a profile for a particular user, many of these items may need to be examined both individually and as a collection of interrelated items with potential relationships existing he- tween recorded activities. Profiling algorithms are there- fore expected to be of varying complexity. A simple algo- rithm may produce rules based on the sporadic occurrences of data observed in a single file, another may be required to recognise temporal dependencies or causal relationships in user activity recorded across several files.

Since computer forensics undertakes the post-mortem analysis of computer crime. much of the analysis is done off-line. Therefore, emphasis is more often on effectiveness than efficiency in order to produce a smaller set of targeted conclusions, and reduce overall human investigation time.

For example, it is preferable to achieve a low rate of false negatives at the expense of increased computational time and number of false positives.

Much of the information found on a computer is ex- pected to be in a format not suited for immediate analysis.

An investigator must facilitate this by providing details on the subsets of data intended for analysis, their format and conversion requirements, and available background knowl- edge. Some of this can be achieved through automated means. Filtering, the removal of unwanted information and the aggregation of separate data items are some of the more important activities during this stage of the analytical pro- cess.

3.1 Concept Hierarchies and Beliefs  Background knowledge in data mining is popularly ex- pressed in the form of concept hierarchies and is often used in the rule generation process [21, 1 I]. The hierarchies con- vey a generalisation of concepts from node to root (which is usually the concept any) and can be represented as a set of parent-child relationships in  a data file. An investigator may be prompted with a set of node level concepts found in the data and asked to abstract it to higher level ones ac- cording to hidher liking. This hierarchy, which is generally domain-dependent in forensics investigations, can then he used in the mining process to produce a profile that con- tains rules with elements at an arbitrary level of abstraction.

There should be no requirement for a concept hierarchy to be complete for profiling to operate correctly. A set of hier- archy fragments is often more desirable as it helps to avoid over-generalisation by not including very high level con- cepts in the search process.

Concept hierarchies may be employed in two different ways during profile generation. In a drill-down approach, rules are initially generated for high concept levels. Interest- ing high-level rules can he further investigated by descend- ing the concept hierarchies for some attributes. In a drill-up approach..a larger number of rules are produced with a po- tentially low support level requirement using the attribute values present in  the data. By ascending concept hierar- chies, higher level rules with increased support levels may be obtained.

Evolution within a profile is an important indicator of potentially irregular activities. A profiling algorithm is ex- pected to be able to attach temporal tags to rules indicat- ing intervals of validity if so required. Concept hierarchies, therefore. must accommodate such functionality. This hap-     -- -D- I 1  I IDD- I  Figure 1. Data flow diagram of the profiling process.

pens at two levels - changes in the structure of concept hier- archy over time, and changes in the position of a leaf node value over time.

In addition to using hierarchical abstraction of attribute values, investigators may have pre-conceived beliefs about a case being investigated. A separate collection of rules can be used to describe a set of such beliefs. These can be used to focus the investigation by searching for specific regulari- ties in profiles, or may also be used to reduce the profile by discarding rules that are defined as trivial [I] .  Furthermore, the use of these rules may allow a post-processing algorithm to identify rules that contradict existing beliefs.

4 The Profiling Process  The data flow diagram in Figure 1 describes the data, rules and processes used for profiling purposes. It incorpo- rates references to background knowledge such as concept hierarchies and beliefs, and the final conclusions resulting from the forensic analysis (detailed in Section 4.2).

4.1 Basic Profile Generation Algorithm  The association mining algorithm implemented for forensic analysis is designed to generate a profile using a single input file. Depending on the desired level of back- ground knowledge to be employed. three approaches can be distinguished:  Generating rules with no concept hierarchies and be- liefs. This method is likely to produce a large set of rules that may require extensive user analysis [ I ] .

Generating rules with concept hierarchies hut no be- liefs. This solution allows for production of high-level rules andor  generalisation of lower level rules permit- ting both drill-down and drill-up.

Generaling rules with concept hierarchies and beliefs.

This permits the same possibilities as above. as well as  filtering made possible by the availability of existing beliefs.

The usual steps of data filfering, data conversion, and, when background knowledge is used, the creation of con- cept hierarchies and beliefs precedes profiling.

The association mining algorithm MZIS-c matrix to !ternsets using concepts) we employ, shown in Algorithm 1.

is a version of the classic Apnori association mining algo- rithm [ 5 ] .  Note that the algorithm is not a new, improved implementation, and was mainly selected because it suits our analytical environment. Its novelty lies in the fact that it performs binary mining in memory in conjunction with concept hierarchy ascension. Details of this process are out- lined below.

Let A = (Al, Az, . . . ,At} be a set of I attributes. Each attribute Ai, i = 1, . . . , I ,  can take on a discrete set of mu- tually exclusive values. Let a record T be a conjunction of values taken from each available attribute. Let B be a col- lection of n records. In this finite collection, each attribute Ai may take on a finite number of discrete values. Let the number of these values be denoted by mi for attribute A;.

The total number of distinct attribute values that appear in B is then E:=, mi. Let W = { H l , H 2 , .  . . , H N }  be a set of domain-dependent concept hierarchies or attribute fax- onomies. Each concept hierarchy H j , j  ? (1 ,2 , .  . . , N }  in the concept forest is formulated as a direct acyclic graph (DAG), with none, one or more hierarchies assigned to each attribute A;, i = 1,. . . , 1 .  Concept hierarchies are structurally similar to profile hierarchies discussed in Sec- tion 2. The main difference is that each pair of adjacent nodes in a DAG H,  represents an "is-a" or generalisation- specialisation relationship, rather than multi-slot frame pro- file content relationship. Examples of concept hierarchies are the IP (Internet Protocol) domain name hierarchy, the functional directory of an organisation, etc. Leaf nodes in concept hierarchies belonging to attribute A,  therefore generally (but not necessarily) represent values occurring in R Non-leaf-nodes in concept hierarchies represent higher level abstractions of leaf-nodes and can not be values that occur in the original data. Denote the collection of con- cept hierarchies- with these leaf-nodes removed by I@ = {HI, H z ; .  . . , H N } .  Let m; denote the number of non- leaf concept nodes defined in all hierarchies for a!tribute Ai in & or equivalently, the number of nodes in W. Let m = Et=, m i  + iii, be the length of a binary vector U = { b l > .  . . , bm} where bit bi 6 {O; 1) uniquely corre- sponds to an attribute value or concept occurring in ]R U 8.

Require that bits corresponding to values and concepts of a given attribute be consecutive, with concepts having higher indexes than attribute values. That is,     Let M : T + U he a mapping of an actual record T in R to a hinary vector v such that each attribute value and its higher level concepts in corresponding hierarchies are represented by 1 in U with all other values set to 0. Let the function attr(b,) for hit b, E U return the attribute Ai, j E {l> . . . ~ l } ,  to which bi was mapped to. According to the consecutiveness requirement above this means that if uttr(6i) #uttr(bj)forsomepair(i;j) E 11; . . .  :rn},and i < j .  then the indexes for all hit-pairs for the two attributes involved will exhibit the same less than relationship. This property is utilised in the algorithm below.

Aleorithm 1: MZIS-c - Inputs: An ( n  x m) bit-matrix M; an (m x m) concept relation- ship bit-matrix C: rninsup E [0,1] Outputs: A collection of itemsets 2 satisfying minsup,  2 = Uk I X

I. Initialise *:=I 2. For each column t=t ,...,  2.1. Initialise support ~ . P ~ : = Z : = ~  b,..bij6{o.iJ 3. Add I-itemaets I ;  toz where n u p . / n i m s n s u p 4. Increment k .  Stop if k>l ,  otherwise for the current k:  o f  .U.

4. I. Initialise k-ilemret count count.:=o 4.2. Generate potential k-itemsel from existing (k-i)-itemseU by  finding next pair { I : - '={; :  ,..., < ~ - ' J J - ' = { ~ ~  ,..., J J so that I;=$?. a d ,  ..., k - 2 ,  s : - '< i ; - ' ,  and 9 F - l  i s  not in a concept rel&ship with 9 f - l  4.3. For potential itemset l~j={~~,...,~~-',,~-'} calculate support sup in .U by counting the rows where all bits appearing in I:, are ret.

countk 4.4. I f  3upin?mlnaup, add I:> into z as a k-itemref and incremem  4.5. Go to Step 4. I until all potential k-itemrets are found.

5. S t o ~  if covntl =o. otherwise 00 to S t e ~  4.

An extension to the Apriori algorithm in M2IS-c is the incorporation of concept hierarchy values into the mining process by including them in the hinary mapping'. This is desirable in cases where individual values may not have enough support to he represented in a profile, hut their higher level equivalents have. A consequence of this ap- proach is the introduction of potential itemsets with both child and parent concepts present. Itemsets containing such pairs express trivial relationships and need to be pruned as they dilute the final rule set. The removal of itemsets containing child-parent pairs is an additional feature of the modified algorithm used in the profiling process. This en- sures that the maximum length of any itemset produced is limited to the number of attributes 1 in the original data set. Child-parent relationships can he represented by a hit- matrix with ones indicating relationship and zeroes not2. As this lookup can be achieved in a single step. we refer the  'Note that the use of memory for storage of the main bit-mauix may be problematic for large data seis OD non-spcialised systems.

2A single matrix would suffice for this purpose. Individual matnces for each atuibute could be preferable for memory efficiency as ones can only  reader to the original article for discussion of the complex- ity of the algorithm [ 5 ] .

4.2 Profile Analysis Algorithms  The generation of profiles is only the first step in an in- vestigation. Algorithms for analysing the profiles need to he provided and utilised either interactively or by automated means. Some of the functionality required can he described by the following list:  Filtering profiles. This process allows investigators to reduce the profile set to concentrate on subsets that may he of higher interest. It can be guided by a pre- viously defined set of beliefs about the expected he- haviour of the profile. Rules complying with beliefs may automatically he dropped, while rules in contra- diction with beliefs may be assigned higher priority in the investigative process.

Contrasting raw darn ru profiles. This produces a list or summary of data entries that deviate from the pro- file. It is generated for data that did not have enough support to he part of the profile, hut convey potentially unexpected information different from the profile.

Generating intra-profile contrasts. This means finding rules in a profile that are in contradiction with other rules in the same profile. These rules may indicate a shift in  behaviour, whose causes may need to be inves- tigated. To measure difference between rules, a dis- tance metric will he required.

We propose a simple profile analysis algorithm to measure the degree of anomalies in the profile elements.

4.3 A Metric for Profile Element Distance  One of the more interesting and complex issues in the analysis of a profile is the discovery of contradicting ele- ments within the profile. These contradictions may he iden- tified both at the itemset level and in the final ruleset. In this paper, we concentrate on contradictions in itemsets, using a Manhattan distance based metric that makes differences easy to detect. For example. some of the characteristics of a particular person may he repeated in several itemsets with only a single attribute value being different. This difference can he attributed to:  Repetition. In this case, the attribute represents a value (for example, day of the week), that indicates that the same set of characteristics is valid for multiple occa- sions.

appear along the diagonal in (m, +wi,) x (m. +e,) subsets for atmibutes A , , i = l ,  ..., I .

Generalisation. The attribute value has heen replaced by the higher level concept that retains the same set of characteristics, hut possibly with larger support.

Contradiction. The attribute value is in contradiction with another, potentially pre-defined as a belief. For example, auser may he allocated a parlicularcomputer but the profile indicates the use of a different one.

The recognition of the occurrences of these differences may be automated. Some may be combined (repetition) or discarded as unimportant (generalisation or trivial beliefs).

Others may require inspection by investigators to decide if they are worth following up. Algorithm 2 (Irem$er& itemxet & f a m e )  describes the calculation of a metric that indicates the closeness or similarity of two k-itemsets by comparing their elements. It employs the attr()  function defined prior to presenting Algorithm 1 and assumes that the itemsets to be compared are represented by bits from the hit-vector U format defined there. Because of the consecutiveness re- quirement, it follows that the hits at position o in a k-itemset he in three distinct relationships:  1. They may belong to different attnbutes A, # A,.

2. They may belong to the same attribute A, and he the  same attribute value or concept, or have a child-parent relationship.

3. They may belong to the same attribute A, but he dif- ferent valueslconcepts with no relationship.

Algorithm 2: IS2IS-dist Inputs: K-itemsets I, = ( b : ,  . . . , b i }  and Ij = (g , .  . . ,q}; an (m x m) concept relationship bit-matrix C; attribute function attr (b) Outputs: Distance d E [0, , . . , k + 11  1. Initialised := 0 2. Foro := 1 to k  2.1. If attr(bp) # &?(by). set d := k + 1 and stop 2.2. If (bp # b;) A (b: not in  child-parent relationship with b y ) ,  increment d  It can be seen that distance d of Algorithm 2 can he less than the length of the itemset k only if the same attribute valuelconcept is found duplicated (i.e. equals or is in a con- cept relationship with) at least once in the two itemsets he- ing compared. It also follows that the total number of such duplicates found and d equals k, with d = 0 only if the re- spective elements of the two itemsets are the same or are in  a concept relationship. Thus, the metric is a non-negative in-  Figure 2. Example time slice of past and cur- rent user login information as obtained by ex- ecuting the UNIX last command.

hold nil values for attributes not originally in  the itemset, then comparing this itemset with the data record the same way as comparing two I-itemsets. The difference between Algorithm 2 and this modified version is that d is not in- cremented for attributes where the itemset holds a nil value.

This limits d to a maximum value of k.

5 Data, Experiments and Results  To evaluate the profiling methodology proposed in this paper, a number of experiments have been performed. Both Algorithms 1 and 2 have been implemented as well as IS2DAT-dist. As input, log files captured by executing the UNIX last command were used, which searches the wtmp system log file and lists past and current user login informa- tion for a computer. An example output from executing the last command is shown in Figure 2.

Note that the data used in our experiments are actual log data recorded by a UNIX-based computer set up as a server with remote login access. However, in order to preserve anonymity. the data attribute name instances have been modified. Furthermore, there was no implication of inappropriate behaviour in the data set.

Of several columns of information generated, six at- tributes were copied or composed into a table containing formatted input. Some filtering was performed at this stage to remove incomplete (current) and non-user (e.g. shut- down) logins. The table, using additional higher level con- cepts from attribute hierarchies, was then mined to produce a profile containing association rules. Intra-profile and data- to-profile contrasting was then performed.

The distance metric of IS2IS-dist and IS2DAT-dist was employed to produce reports for both contrasting methods.

5.1 Intra-Profile Experiments  Intra-profile contrasts were calculated only for itemsets teger 2 E [0, . . . , k+ 11. from which only values 0; d < k * .  . .

of the same length. For example, in one test, from about 2000 original data records, approximately 2200 itemsets  are or interest.

A similar algorithm can be devised to calculate the  distance hetween a k-itemset and a data record (IS2DAT- with than element were produced, Intra-profile con.

dist)3. This can he achieved by expanding the itemset trasting produced roughly 43000 distances that were less  'This algorithm is not presented due to its similarity to AlgonUlm 2. than the lengths of the itemsets being compared. Although     this is a far smaller number than what it potentially could have been, it is still more than what can be perused manu- ally. To rcduce this set further, additional strategies need to be devised. One option is to prioritise attributes. That i h , i f  difference is measured only in a particular attribute that may not be carrying imponant information (such as day of the week), then pairs exhibiting distance only in such at- tributes may be dropped. Similarly, a strategy may be em- played to drop contrasts that are too "high". That is, the distance metric for a particular itemset length may be re- garded as high, even though it satisfies the initial constraint of being less than the length. This may, for example, render all distances produced for 2-itemsets unnecessary. Finally, focusing techniques may be provided to filter the distances for certain attributes or attribute values. One of the more interesting contrasts produced by IS2IS-dist during testing was the I-distance pair  io : (User = pedru) A (Origin = v i iunl i ) 11 : (User = pedro) A (Origin = adeluide)  which indicates that the same user has been logging in from two very different geographic locations. Further inspection of this contrast revealed that the user in question left his place of work in Adelaide for another i n  Miami while still regularly accessing his old Adelaide account.

5.2 Data-to-Profile Experiments  The filtering requirement to reduce the set of distances to  manageable proportions becomes even more evident with data-to-profile contrasts. Without pre-processing, each itemset needs to be compared to every data record, po- tentially producing a much larger result set than for intra- profile contrasts. This is partly due to the fact that a number of records are not included in the profile due to unsatisfac- tory support. Each of these records could produce small dis- tances to itemsets similar to it that made it into the profile.

As in the case of intra-profile contrasts. measures can be taken to reduce the final result set. In addition to the strate- gies outlined in Section 5.1, duplicate records may be re- moved by post-processing the results. Also, data-to-protile distances may be zero, if a particular data record was one of those used to generate the itemset it is being compared to.

These distances should also be pruned from the results.

Figure 3 shows some of the distances from a test calcu- lated for a particular itemset of length 5 (top row). Non- zero distances up to a maximum value of 2 were allowed in order to list contrasts where difference is present in  not too many attributes. Duplicates were removed and as men- tioned, some attributes were sanitised to remove contiden- tial information from the data. The itemset contains gen- eralised concepts for both the User and Origin attributes, while Durarion is represented by concepts categorising a  Figure 3. Example data-to-profile distances from ISZDAT-dist for a sample profile element and a collection of data records, ordered by User for readability  potentially large number of discrete values. From the def- inition of the metric, valueslconcepts in the same hierar- chy have a distance of zero, which explains the diversity of rows of (non-generalised) values in the data having similar distances. For readability, we give here some of the concept relationships from the otherwise rather large hierarchies that exist for User and Origin:  {mar,milo,pedro, s tuor t }  c lecturer.

{*.cs.x?/u.edu.au, 188.191.47.*) c cs.xyu.edu.au C  zyu.edu.au c adelaide.

{ *.tnt2.tow.net.au, 198.twun0103.twn.net.ou) C  ISP.adelaide c adelaide.

Using this information, the first data row with d = 1 shows that user Clyde is not a lecturer. whilst for lecturers viuz and pedru. who log onto university computers, we can ob- serve that the same w t m p  login information is valid for sev- eral weekdays other than Monday.

Figure 3, as is, contains superfluous information. De- pending on the support used in mining the profile, some or most of the data records contribute to itemsets gener- ated by the algorithm. Comparing a k-itemset to data that contributes to another k-itemset is a repetition of compar- ing an itemset with another. Crosschecking a data record against every other k-itemset prior to calculating a distance would, however, be even less cost-effective. Instead, a strat- egy of producing distances in a matrix form for k-itemsets, k = 2:.  . . ~ 1. then discarding rows with at least one zero in it, would be a better solution. Alternatively, a separate algorithm may parse the data set to locate individual occur- rences of records that d o  not contribute to any itemset of a given length, and then run the contrasting algorithm against this filtered data set only. This is indeed the requirement proposed in Section 4.2 for data-to-profile contrasting.

6 Conclusions and Future Directions  The initial implementation of the profiling analysis pro- cess described in this paper has resulted in promising results capable of identifying irregularities in computer logs that can serve as useful evidence in computer crime investiga- tions. Protile analysis, however, forms only a pan of the in- vestigative process and relies heavily on expert knowledge.

It is therefore best perceived as a component in a larger col- lection of tools designed to aid the forensic investigator.

The profiling tool presented in this paper presents further opportunities for enhancement. One such area is the han- dling of multiple log information in a single process. Multi- dimensional mining may offer a solution for this problem, with some interesting work already found in the literature [16, 201. Alternatively, it may be possible to ?flatten? sev- eral logs into a sequence of ?events?, for which more tradi- tional sequential mining techniques can be applied. Further improvements may be achieved by replacing the mining 81- gorithm used in protiling. One obvious candidate is the attribute-oriented induction technique [ 141. This technique compacts a collection of records into a generalised relation, or a conjunction of generalised records where individual at- tribute values are replaced by higher level concepts by as- cending concept hierarchies. One of the advantages of this technique is that the final rule set incorporates information about every record in the original data set. Further work is also to be carried out in the intelligent presentation of results, notably in the provision of appropriate visual inter- pretation of the profiles and its potential contrasts. Contrast measures currently used are itemset-specific. Deriving dis- tance measures for rules. such as the value distance metric (VDM) [221 may yield better results in identifying discrep- ancies. Some of the better known data mining interesting- ness measures [12], or variations of, may also be adopted for this purpose.

