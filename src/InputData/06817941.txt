

Abstract?Support Vector Machine (SVM) has been used to classify data and extensively explored in various fields. Instead of using original data as model inputs, we proposed here SVM modeling based on a nonlinear-mapping approach. Such a nonlinear data mapping for the SVM increased the hyperplane margin space, decreased the structural risk minimization (SRM), and thus improved the performance of SVMs in respect to image classification accuracy. The proposed approach was tested to classify vegetation cover for typical grassland in Northern China based on Landsat ETM+ data. The performance of SVMs with the nonlinear data mapping approach was evaluated against that without data mapping, and also compared to similar studies using different approaches as well. The results indicated that, in terms of image classification accuracy, the proposed method achieved the best result (82.7% with kappa =0.80).

Keywords- image classification, support vector machine, data mapping,  vegetation cover

I.  INTRODUCTION Support vector machine (SVM) has been introduced as a  new technique for solving a variety of learning, classification, and prediction problems [1, 2, 3], and SVM-based approaches have also been extensively applied in the classification of remote sensed data [4]. Unlike other classifiers, SVM is a state- of-the-art learning algorithm having a good theoretical foundation in statistical learning theory [5]. SVM fixes decision functions based on structural risk minimization (SRM) instead of minimization of the misclassification on the training set to avoid overfitting. It performs on binary classification problem by looking for maximal margin hyperplanes in terms of a subset of the input data (also referred to as support vectors) between different classes [6, 7]. Artificial neural network (ANN) is also a well-known learning machine; however, empirical testing showed that in most cases SVM performance was better than that of ANN. Moreover, compared to other classifiers, SVM-based models are less sensitive to training samples, which may be very important factor when there is no sufficient training samples available.

A number of studies have been reported in applications of remote sensed image classification using SVM-based classifiers [8]. Nemmour and Chibani [9] investigated their applicability to classify hyper-spectral images for land cover change detection. Huang et al. [10] developed an automated method consisting of training data automation (TDA) for SVM (TDA-SVM method) to map forest cover using IKONOS. The novelty of TDA-SVM lies in its automatic generation of  training data using input satellite images and existing land cover products. In general, investigations on SVM have been focusing on SVM kernel selection, parameter optimization, and feature selection. Few studies targeted at data mapping, namely an effective data preprocessing, to build an optimized structure of SVM models.

Furthermore, the classified result can be further improved by association rules based on association rules derived from prior expert knowledge. A good case in example is the work done by Hu that association rules could classify IRIS data which proved effectiveness in comparison with other classification methods [16]. We also discussed the application of association rules in improving classification accuracy.

The objective of this study was to classify remote sensing images using SVM models, when reference samples are regarded as insufficient by traditional classifiers such as ANN or other supervised classifiers. We proposed the approach by combining nonlinear mapping functions and SVM and applied it to classify remote sensed images. A case study of classifying grassland vegetation cover was taken to illustrate the principle, processes, and application of the approach.



II. METHODOLOGY In SVM, the input data is viewed as two sets of cases  (denoted as 1 or -1, indicating that any case can be classified as positive or negative case) in an n-dimensional space. Building a SVM model is to find a separating hyperplane in n- dimensional space to maximize the margin between the two sets of cases and thus derive a classification machine for new input cases. Theoretically, a reasonable separation is achieved by the maximum-margin hyperplane that has the largest distance to the neighboring data points of both classes, since the larger the margin the lower the generalization error of the classifier.

In most cases, the input data may not be linearly separated by a hyperplane. In building an effective SVM model, a key concern is to select an appropriate kernel which maps the input vectors through SVM kernel into a very high-dimensional feature space in which data can be linearly separated. Among the kernels, Radial basis function (RBF) is a popular one that has been widely adopted in SVM models and was selected in this study.

We tried to classify vegetation cover from remote sensed data using SVM models with ground reference data for training     and testing. Instead of building SVM models directly from original reference data, a nonlinear data mapping was applied to scale all the input variables (image bands) to a larger deviation. The procedures generally consisted of four major phrases: data preparation and preprocessing, nonlinear data mapping, building SVM models with the mapped data set, and applying SVM models to the image data to derive vegetation cover for the complete study region. The following will explain the procedures in detail.

A. Data preparation and preprocessing The first phrase, reported in a previous work [11], generates  two matrixes, I and II. Matrix I produced the training dataset in the form of 348 x 8 (SampleID, 6 bands, and type of Bio-S- class) while Matrix II produced the testing dataset in the form of 118 x 8, where 348 and 118 are the sample sizes for the training and testing dataset respectively, SampleID is the sequential number of each sample, ?six bands? are the 6 reflective bands of Landsat images, and ?type of Bio-S-class? refers to one of 21 Bio-S-classes. All the samples belonging to each of the 11 Bio-classes (defined in Table 1) were clustered on Bio-class basis and grouped into several subclasses if the spectral variations within the Bio-class were larger than a given threshold [11]. These subclasses were both spectrally and biologically accounted, so they were referred to as Bio-S- classes.

TABLE I.  GRASSLAND VEGETATION CLASSIFICATION SYSTEM BASED ON THE BOTANIC TYPES  class (Bio- class)  Community type Vegetation type  1 Cleistogenes squarrosa Typical steppe 2 Stipa grandis Typical steppe 3 Achnatherum splendens Meadow 4 Stipa krylovii Typical steppe 5 Artemisia frigida Typical steppe 6 Carex pediformis Meadow steppe 7 Carex spp. Meadow 8 Caragana microphylla Typical steppe 9 Leymus chinensis+ Stipa  baicalensis Meadow steppe  10 Leymus chinensis Typical steppe 11 Salsola collina (Chenopodium  glaucum) Typical steppe    B. Applying nonlinear data mapping on original data The template is used to format your paper and style the text.

All margins, column widths, line spaces, and text fonts are prescribed; please do not alter them. You may note peculiarities. For example, the head margin in this template measures proportionately more than is customary. This measurement and others are deliberate, using specifications that anticipate your paper as one part of the entire proceedings, and not as an independent document. Please do not revise any of the current designations.

We applied a nonlinear mapping on the original input dataset (Matrix I and II), intending to make it easier to separate the samples labeled with different Bio-S-classes, and to minimize SRM of SVM models. We proposed the following functions to convert an original value x to a new value x?:  | | / . .vy x x s d= ?            (1)  and ' 2  vx y=                   (2)  where yv is an intermediate variable, x?R is the value of the variable V (in Matrix I or II) for a Bio-S-class labeled sample,  and x  and s.d. are the mean and standard deviation of V for all the training samples labeled by the same Bio-S-class, respectively. The above mapping functions were implemented on all of the elements in Matrix I to make a new matrix (Matrix I?) which was then used to build SVM classifiers. Similar mapping was implemented on Matrix II to generate a new matrix (Matrix II?) for testing purpose.

Mapping of the first variable in Matrix I, Band 1, for Bio-S-  class c10d1, is illustrated in Figure 1. The mean of c10d1 ( x ) and the standard deviation (s.d.) of the variable V for all the training samples labeled as c10d1 are 0.44 and 0.03, respectively. The original samples were mapped to the intermediate variable yV (Figure 1(a)) through Eq. (1) and the new values for the samples were obtained by Eq. (2) as shown in Figure 1(b).

Figure 1.  Nonlinear data mapping of the input data of training samples  (labeled as c10d1)  C. Build and test SVM-based models A kernel function and kernel parameters are required to  design an SVM. We chose the RBF kernel function (see supplemental materials) in this study and the parameters to be optimized include the penalty parameter C and the kernel function parameters, namely gamma (?).

A grid algorithm, or cross-validation, was adopted to select appropriate values for ? and C. Specifically, the values for ? and C were systematically changed from low to high. For each combination of ? and C, considering the possible side effect caused by the uneven size of positive case and negative case, the method proposed by Huang and Du [12] was employed, by setting the ratio of penalties for different classes (positive and negative) with the inverse ratio of the training class size of positive to negative. This weighted SVM could compensate for the undesirable effects caused by the uneven training class size.

We used the libsvm software [13] to implement the above algorithm for the training and testing purposes. As there were 21 Bio-S-classes, 21 SVM RBF-kernel models were fit and the parameters (? and C) were optimized.

D. Applying nonlinear data mapping on original data To evaluate the models, the cases in Matrix I? and Matrix  II? were tested with each Bio-S-class as priori class to examine the classification result and generalization ability of the built models. The i-th SVM (i =1, 2, ?, 21) was then applied, one by one, to the mapped sample cases (in Matrix I? and Matrix II?). It is possible that some cases could be assigned with more than one Bio-S-classes after looped through all the i-th SVMs.

Also it is possible that for some cases they are not assigned to any Bio-S-class because they were classified as the negative one by all of the SVMs during the iterative assignment process.

In both cases, given the input vector x (x?Rd) of an unknown sample s and its possible destination yi ? {1, 2, ?, k}, s will be ultimately assigned to the class that has the largest decision function determined by g(x) through Eq. S7 (see Supplemental material). The same assignment process was applied to the whole image (Img I, or the processed Landsat images) whose reflective bands were processed by the proposed mapping functions on a pixel basis. The pixels belonging to the same Bio-class were merged to derive the vegetation cover for the study region.



III. RESULTS A case study of classifying vegetation cover based on  remotely sensed images is used to test the proposed approach.

The study region, Xilingol River Basin, situated 43?26?? 44?29?N and 115?32??117?12?E, is one of the typical steppe zones in northern China (Figure 2) (Li, et al., 1988). For this  purpose, Landsat Enhanced Thematic Mapper (ETM +) images covering the study area were used to derive vegetation cover.

Cloud-free single-day images were identified for the study area for the period between April 2004 and October 2004. Two scenes of Landsat ETM+ on 14 August, 2004 covering the whole region were obtained and then preprocessed.

Topographic map and Digital Elevation Model (DEM) were used as ancillary data. In addition, ground samples, as reference data, were collected simultaneously in late August.

Inner Monglia  P.R. China  Xilin River Basin  Chagan Lake  Maodeng  N  Xier  Xilinhot  Bayanbaole  0 30 km   Figure 2.  Study region  TABLE II.  THE CONFUSION MATRIX FOR THE TRAINING DATA  Map class Reference class Total User?s (%) 1 2 3 4 5 6 7 8 9 10 11 1 21   1        22 95.5 2 1 107 1 2 1 1   2 2 1 118 90.7 3   7    1     8 87.5 4  3  52      2  57 91.2 5     10     1  11 90.9 6 1     6      7 85.7 7       2     2 100 8    1    15  1 1 18 83.3 9    1     7   8 87.5  10  4 1 2 1  1 1  60 1 71 84.5 11  2  1      2 21 26 80.8  Total 23 116 9 60 12 7 4 16 7 68 24 348 Producer?s  (%) 91.3 92.2 77.8 86.7 83.3 85.6 50.0 93.8 100 88.2 87.5  Overall accuracy (for the first reliable class): 88.5%; Overall Kappa: 0.86   The spectra of the training samples located in Img I (6 bands) showed high variation, even for those samples labeled by the same Bio-class, which is very unfavorable in image classification. After a two-step hierarchical clustering analysis  was performed on the samples to derive Bio-S-classes (the first calculated Euclidean distance to measure the similarity between difference samples while the second clustered the samples into Bio-S-classes with an appropriate threshold).

Most vegetation types (Bio-class) having high variations of spectral reflectance were separated into two or more sub- classes. For example, the training samples of Bio-class 4 (i.e., Stipa krylovii) were further divided into 3 sub-groups (Bio-S- classes) which had little within-group spectral variations among the samples while high variations between sub-groups were observed (c4d1, c4d2, and c4d3). The Bio-class 1, 5 and 11 had 2 Bio-S-classes each. The Bio-class 10 was further divided into 3 Bio-S-classes and the Bio-class 2 had 4 Bio-S- classes. Bio-class 3, 6, 7, 8 and 9 had no sub-classes since little spectral variations were observed among the samples.

0.00 400.001.00 0.400.600.80 200.00  0.00  10.00  20.00  y  x  y = | x - xk | / s.d. x = y 2  0.00 2.001.00  0.00  0.50  1.50  1.00  x  (a) (b)  (c)  x = y 2  c10d1 others  3.00   Figure 3.  Data mapping of all the samples for c10d1  The 6 variables corresponding to the reflective image bands (band 1, 2, 3, 4, 5, and 7) of the samples (training and testing) were undergone a nonlinear mapping using Eqs. (1) and (2) with the parameter values of x  and s.d.. Compared with the original values in Matrix I, the mapped values in Matrix I? were highly scaled which presented larger deviation in terms of data distribution for each variable. Figure 1 shows the original normalized distribution of a variable (band 1, horizontal axis x) of training samples labeled as c10d1 (Figure 1(a)) and the mapped value distribution of the variable, presented by horizontal axis x? (Figure 1(b)). Figure 3 presented the mapped result for all the samples labeled as c10d1. Specifically, the value of variable v of any sample s in Matrix I? is more likely to demonstrate larger deviation from the mean value of v ( x ) if s is not labeled as the Bio-S-class. Conversely, it is more likely to show proximity to x  if s is actually the Bio-S-class.

For example, the 32nd sample (s32) in Matrix I? was labeled as c10d1 and the 33rd (s33) was c8d1. Compared with the original data before mapping, the deviation of first variable of s33 from the mean value of c10d1 (0.51) was greatly scaled while the deviation of the variable of s32 kept relatively stable after data mapping. The mapped values of the training samples (Matrix I?) were used to fit SVM models. To classify all training  samples, the SVM OVA (one-versus-all) method was applied to make multi-category classifier. The statistical result of the modeled Bio-class vs. the real Bio-class of the training samples is shown in Table 2. It could be seen that the accuracy of SVM model for the training data set achieved a good fitting result with 88.5% samples correctly classified (kappa = 0.86).

To further test the generalization ability of each SVM model, the 116 testing samples were used to verify the model effectiveness. Each of the samples in the testing dataset was assigned to the class that has the largest value determined by the function g (x) (Eq. S7). Though this accuracy test showed a lower correct classification result (82.7% and kappa = 0.80) than that of the trained dataset (88.5%, kappa=0.86), the accuracy is still higher than those of the similar investigations, including the one that we did to classify the vegetation cover using HFC (Hybrid fuzzy classifier) classifier (80.2%, kappa=0.77) [11], or other studies conducted in the same region (less than 81.7%) [14, 15].

Instead of applying the original data to fit SVM models, we designed nonlinear mapping functions to scale the original input data into a new data set which showed performance improvement in image classification. The reason can be seen from the fact that the growing rate (xi?/ xi) increases very fast when the original data (xi) locates far from the mean value ( x ) of any input variable, especially when it is located outside the range of xi ?s.d. (Figure 1). The rapid increase of the growing rate denotes that any to-be-classified sample (corresponding to a pixel in image), if it is not labeled as the current Bio-S-class, will deviate much faster from the mean ( x ) than that labeled as the Bio-S-class in terms of the value of the current variable (xi). In other words, the mapping functions help variable aggregation of samples labeled as the same Bio-S-class while promote the variable deviation of samples labeled as different Bio-S-classes. Compared with the original input data, the new data set could lower the within-class variations and increase the between-class variations. Moreover, the range of any input variable was scaled after data mapping. For example, the Bio- S-class c10d1 was mapped from the original data to the after- mapped data (Figure 3). The range of the first variable (Band 1 of the input data) across all the testing samples was 0.42~0.98.

It was nonlinearly scaled from 0 to 324.0 after the mapping (Figure 3a and 3b). This data scaling through the mapping functions increased the effectiveness of sample separation if the new data set is used to fit SVM models. Compared with the data deviation of the between-class samples, the within-class samples showed more aggregation. For instance, in the SVM testing process for c10d1, most testing samples that are actually labeled as c10d1 are clustered around the original point with only a few exceptional samples, while most other samples that are not c10d1 are far from the original point (Figure 3c).

Though the results indicate that there is an inherent clustering capability for within-class samples after the data mapping, a detailed mathematical explanation is yet to be studied for building SVM models.

To further confirm the assertion that our suggested approach, namely training SVMs with data mapping, have better generalization ability than the traditional SVMs without data mapping, we compared the histograms of the classification     outputs for the two types of SVMs. As shown in Figure 4, the classification outputs from the common approach mostly concentrate near the origin, indicating that the margins between the positive and the negative samples are very narrow. In contrast, most classification outputs of the current suggested approach are distributed relatively far from the origin point.

This experiment further proves that the current suggested one can increase the margin space of SVM hyperplane and is better in achieving the generalization ability of SVM models.

1 2 3 4 5 6 7 8 9 10            0.2 0.4 0.6 0.8 1.0 1.4 1.6 1.8 >2.0  SVMs with data transformation SVMs without data transformation   Figure 4.  Histograms of classification outputs on the testing dataset,  respectively by SVMs with data mapping and SVMs without data mapping  Note for Figure 4: For each case in the testing dataset, the classification output was calculated by the decision function, namely Eq. S9, of the i-th SVM (i=1, 2, ?, 21) where i corresponds to the identity of the Bio-S-class assigned to the current testing case.



IV. CONCLUSION In respect to the advantages of SVM models over others  [9], this paper tried to employ it to classify vegetation cover from Landsat ETM+ images. We designed nonlinear data mapping functions to map the original input data into a new data set. Instead of directly simulating SVM models with the original data, the mapped data was used to fit a series of RFB- based SVM models which were applied to classify remote sensed images. Both primitive analysis and case study revealed that such a mapping could efficiently scale the value range of input data, resulting in a remarkable aggregation of samples with the same class labeled and a large deviation of samples labeled differently. Our proposed approach can be viewed as a kind of data preprocessing. However, since the approach showed effective in increasing the margin space of SVM hyperplane, it could be naturally integrated in most SVM models. Results also demonstrated that by combining the data mapping and SVM, the classification accuracy was improved a lot compared that without the mapping (from 78.5% with kappa = 0.74 to 82.7% with kappa = 0.80). This result is acceptable in most similar work but the space of improvement is still expected. As mentioned in the introduction section, the SVM-based classification result can be further improved or  refined by other advanced classification approaches such as association rule based methods [16]. Therefore, further work can integrate association rule based models can the current proposed one to make more accurate result.

