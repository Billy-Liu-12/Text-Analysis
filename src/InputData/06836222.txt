Utilizing Confidence Bounds in Failure Mode Effects  Analysis (FMEA) Hazard Risk Assessment

Abstract- The objective of this contribution is to provide a review and suggest possible extensions of the Failure Mode  Effects Analysis (FMEA), Hazard Risk Assessment (HRA) [2) and to demonstrate the importance of these tools to general  probabilistic design for reliability (PDfR) [8). FMEA was first  introduced in the 1960s by the U.S. National Aeronautics and  Space Administration (NASA) and is currently used  extensively across many industries. FMEA is useful in  understanding the failure modes of various products,  qualifying the effects of failure and aiding in the development  of mitigation strategies. It is a useful tool in improving quality,  reliability, and the maintainability of designs, and is a critical  component in risk management strategies and evaluations.

This is, actually, the approach of the prognostics and health  monitoring/management (PHM) engineering. Failure mode  effects and criticality analysis (FMECA) [1) is an extension of  (FMEA). While FMEA is a bottom-up, inductive analytical  method which may be performed at either the functional or  piece-part level, FMECA extends FMEA by including a  criticality analysis that is aimed, like PDfR is, at charting the  probability of failure modes against the severity of their  consequences. The result highlights failure modes with  relatively high probability and severity of consequences,  allowing remedial effort to be directed where it will produce  the greatest value. FMECA tends to be preferred over FMEA  in space and North Atlantic Treaty Organization (NATO)  military applications, while various forms of FMEA  predominate in other industries. Being extensions of the  FMEAs, FMECAs add severity and probability ranking  aspects to the problems of interest. This is accomplished  through an appropriate HRA - an engineering process of  where the risk of an event is quantified by examining the chain  of the preceding events, starting with, e.g., the failure mode,  then stepping through to the end effects. The approach allows  quantification of risk through the use of probabilistic risk  analysis (PRA) and is addressed and discussed in detail.

Failure oriented accelerated testing (FOAT) [9) could and  should be viewed as an important constituent part of the effort.

It is shown that care must be taken to establish the appropriate  probabilities, to identify the statistical independence of the  random variables of importance, as well as to assess the  trustworthiness of the available or obtained data. It is  indicated that an important drawback of the FMEA is the lack  of pure operational (field) failure data. These data are  frequently utilized from the computerized maintenance  management system (CMMS) software, which does not always  provide a true snapshot of the Mean Time Between Failures  (MTBF) or other critical characteristics of the product. This  results in the situation that personal judgment plays a large  part in the development of the FMEA. Several papers have  been published recently on development of Fuzzy FMEA  methodologies (see, e.g., [7)). This application of fuzzy logic to  Hazard Risk Analysis will allow additional uncertainty and   Kara Fuller University of North Florida  Jacksonville, FL 772-341-7376  karalfuller@gmail.com  inaccuracy to be modeled throughout FMECA development,  leading to a more robust decision making with consideration of  various uncertainties.

TABLE OF CONTENTS  1. INTRODUCTION ........................................... 1 2. HUMAN ERROR AND BIAS ?.?.?.?.?.?.?.?.?.?.?.?.?. 2 3. DATA CONCERNS ???????????????????????????????????????? 2 4. CONFIDENCE BASED METHODOLOGY ??????? 2 5. FMEA PROCESS AND LIMITATIONS ?????????? 3 6. CONFIDENCE INTERVAL DETERMINATION4 7. EXAMPLE AND DISCUSSION ???????????????????????? 5 8. CONCLUSION AND FUTURE WORK ???????????? 6 9. REFERENCES ............................................... 6 10. BIOGRAPHY ?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?.?. 6  1. INTRODUCTION  Failure Mode Effects Analysis (FMEA) is used extensively throughout industry in order to improve system reliability and aid in risk assessment. It was utilized as early as the 1960s by the U.S. National Aeronautics and Space Administration (NASA) on programs such as the Apollo, Viking, Voyager and Skylab explorations. The process was also adopted early on by the Society for Automotive Engineers (SAE) in 1967. The use of FMEA spread rapidly to other industries during the 1970s and subsequent years, and is now utilized in a variety of industries including military, semiconductors, healthcare, and the food service industry. FMEA is useful in understanding the failure modes of systems or products, qualifying the effects of failure, and aiding in the development of mitigation strategies. It is a useful tool in improving quality, reliability, and the maintainability of designs, and is a critical analyses component in risk management. FMEA can be used as a tool to utilize in order to establish a risk management policy [10]. The FMEA approach has been further tailored to meet the different needs of various industries and users which have resulted in several types of FMEAs, such as:  ? design FMEA, ? process FMEA, ? service FMEA, and ? software FMEA.

There are several benefits to a well-executed FMEA, which include:  ? improved quality, reliability, and customer satisfaction,  ? cost savings due to early identification and mitigation of failure modes,  ? capability to document corporate and engineering knowledge in a formal manner,  ? focus on a pro-active prevention strategy, and ? greater understanding of potential risk and  subsequent mitigation plans.

Unfortunately, FMEA also suffers from several drawbacks and can become problematic. Literature discusses various types of problems associated with the FMEA process and proposes several solutions. Speaking in broad terms, these problems can be categorized into groups, to include (but not limited to):  ? human error and bias due to qualitative aspects of portions of the analysis, and  ? data concerns.

2. HUMAN ERROR AND BIAS  As mentioned, one of the chief drawbacks of an FMEA is the potential for human error. Frequently the analysis is performed by utilizing a team, and is therefore impacted not only by individual subjectivity and bias but also team dynamics. The error is in part dependent on the experience of team members in failure analysis and system familiarity as well as known cognitive biases. Thus, it is possible to have a limited or flawed analysis just based on human error.

This situation is frequently compounded when little data regarding failure mode occurrence and/or effects are known, thus requiring even additional sUbjectivity. One proposed method to mitigate this risk is to incorporate the right mix of team members, including the customer, engineers, operators, maintainers, and management; however, while these measures are recommended, they do not necessarily reduce human error [2,4]. Integration of FMEA within a large quality control system or culture with in-process audits performed can further reduce this risk (assuming that the larger corporate culture does not introduce its own set of bias). There are many other sources of human error, which is a study within itself.

The criticality determination utilized does not take uncertainty into account, or incorporate sample size or data confidence. For example, the MTBF is determined which drives the probability aspect of criticality - however the analysis does not account for the probabilistic nature of MTBF. Several attempts to incorporate uncertainty into the criticality factor have been proposed to include Fuzzy logic.

These are discussed further, and then an alternate strategy is proposed based on statistical confidence bounds.

3. DATA CONCERNS  Data is frequently available for use within FMEA process, although often in the form of maintenance records and not true failure data. The data frequently data does not provide clear indication of which failure mode or mechanism resulted in the failure, or provide information about suspensions. Additionally, the data must be manipulated to fit the analysis. Finally, in many cases data is simply not available - or a small sample is. For example, consider the case of a critical aircraft longeron that, if failed, will very likely result in a crash, once the failure progresses to a catastrophic state. Maintenance data indicates only a few cases where this component is in a failed state. In this case the FMEA would identify this failure mode with severe consequences (aircraft loss), however with a very low probability of occurrence. However, how much confidence can be placed in this estimate? It is likely that most engineers would perform additional analysis such as damage tolerance assessments in determining the true risk of this failure mode - however consider the case where a large number of failure modes fit this criterion. In that case, ranking these failure modes appropriately is critical m determining where resources should be spent first.

4. CONFIDENCE BASED METHODOLOGY  These sources of error (human and data) have the potential to proliferate inaccuracies throughout the entire FMEA process, possibly resulting in a flawed conclusion. These errors can be manifested most specifically when the practitioner is deciding how to rank failure modes and develop the associated risk mitigation strategies. Addressing the potential inaccuracies inherent to the process as utilized in practice is multi-faceted and complex, and should strike a balance between theory and practical application.

Though solving these problems is important, it is also important to understand the relative uncertainty within an FMEA analysis. This uncertainty is inherent in the probabilistic and random nature of system failure and repair, and is also impacted by error during the process. The intent of this discussion is not to attempt to address all these areas of concern, but rather to focus on the providing greater insight into potential error within the failure mode ranking during FMEA (given its impact on ultimate risk mitigation strategies). The intent is, furthermore, to provide an elegant and statistically simple method of understanding and representing possible uncertainty. This allows the practitioner to make a more informed decision regarding failure modes or possible additional investigation.

Further, this study aims at providing a solution that does not require a large amount of additional data or assumptions - thus being useful to the practitioner. In short, more complicated mathematics without practical and robust methods to estimate the associated variables does not    improve the quality of a FMEA. Finally, this discussion will provide a practical example of how the proposed methodology can be applied to a real world problem.

5. FMEA PROCESS AND LIMITATIONS  The process for conducting a FMEA starts with describing and understanding the product along with its intended functions. These functions are then further analyzed in order to identify how the system or component can fail a function.

Once functional failures are identified the next step is to identify failure modes, which can be defmed as specific ways a component/system fails to perform its intended function. Every failure mode has several associated data fields to include a failure rate, local through end item effects and any supporting data. Methodologies such as Reliability Centered Maintenance (RCM) have extended FMEAs to include criticality. During the Failure Mode Effects and Criticality Analysis (FMECA), criticality is defined as the probability of a failure mode occurring as well as the cost of occurrence in terms of safety, cost and environmental effects. RCM utilizes the criticality ranking combined with a Hazard Risk index (HRI) matrix in order to identify which failure modes require mitigation. Additional analysis is also conducted in order to identify cost effective maintenance or engineering strategies (to include redesign). Regardless of which process (FMEA or FMECA) is utilized an effective method for ranking failure modes is needed.

The FMEA process is a group of activities intended to identify and evaluate potential failures and the related effects. Several strategies to enhance the FMEA have been proposed ranging from automation, expert system application as well as causal reasoning [10]. One criticism of FMEAs are the weakness of the process in terms of risk evaluation with fuzzy logic being utilized as a fix [10].

Traditionally, FMEAs utilize a Risk Priority Number (RPN) in order to rank and evaluate the associated risk level of failures and to further prioritize follow on actions/mitigation.

The RPN is calculated by multiplying the severity, occurrence and detectability together. Severity is tied to the effects and is an assessment of the failure on the end unit (airplane, customer, process) and occurrence is a measure of likelihood of the failure mode occurring - often represented by Mean Time Between Failure (MTBF). Finally, detect is a measure of the ability to control the associated failure mode [10]. One of the main differences in a FMECA is that "detect" is not utilized. These measures would be estimated by experts or by empirical methods (if possible) and a RPN would be obtained. During FMECA similar methods would be utilized to establish a criticality.

Even though the RPN has been accepted as an input to risk management through representation on a HRI matrix, there are several drawbacks with this simplistic method. Some of   the drawbacks include that these metrics are not weighted (thus equal importance) and that various combinations can result in the same RPN. It is thus feasible to obtain the same RPN for a low and high risk - thus resulting in both risks being targeted for mitigation [10]. Additionally, this approach assumes these numbers are deterministic and uncertainty is not modeled. Uncertainty not only stems from potential data or human error in variable selection, but also the complexity of modem systems. Chin et al [3] further points out that especially during the conceptual design phase little to no data regarding the entire product or system is available thus limiting quantitative analysis.

Thus, during this phase the design is largely dependent on human expertise and heuristic knowledge [3]. The FMEA plays an important role during the early design phase in order to improve the reliability and thus cost of the system.

However, difficulties arise due to the limited information and potential interaction of various failure modes [3].

Figure 1 illustrates an example of a HRI as implemented in FMECA, which forms the basis of the proposed approach of this paper. The color coding indicates the associated risk of a failure mode - as determined by the customer or another stakeholder. During the process the criticality is determined and annotated in the appropriate box as a point estimate.

The HRI further assumes that each block is a discrete element and that a failure mode cannot span multiple risk categories (and is a deterministic value).

Figure 1: Generic Hazard Risk Index (HRI)  Frequent  Probable  Occasional  Remote  Class I  Severity  Class Class II III  Class IV  Improbable L--___ ""'----__ -'--__ ----1 __ -.I  FMEAs and/or FMECAs are described in natural language terms such as "likely, high risk, or performance degradation", introducing additional subjectivity.

Researchers have proposed fuzzy logic as an apparent method to represent approximate information and uncertainty while still generating decisions [3]. Even though Fuzzy Logic has been successfully applied to the FMEA process researchers and practitioners frequently run into combinatorial rule explosion, which results in a large number of rules even in the case of a small three input fuzzy problem. Tay and Lim proposed utilizing a guided rule reduction system (GRRS) as a generic approach of rules reduction [10]. The approach reduces the number required to the most important sets. As shown the number of important sets can be reduced, however the concern still remains that these have to be estimated. How sensitive is the proposed approach to human error, a question that    remains unanswered in literature?

The various research performed has proposed several strategies in order to address limitations of the FMEA process as currently implemented in practice. Even though these approaches are valid, they are generally tailored to specific situations (conceptual design) or analysis structure (team approach). Thus, in order to be effectively adopted in the engineering community and eventually other communities or aspects of each organization a more standard methodology - that overcomes the limitations of FMEA is needed.

The following section will illustrate an example based on utilizing the Exponential distribution. This assumption will be relaxed in future research, however the proposed concept remains the same. It should be noted that this methodology can be applied to many different problems using a number of distributions and metrics. Both the distribution and the metric of choice should be considered in the context of a given problem.

6. CONFIDENCE INTERVAL DETERMINATION  Currently, when calculating HRI matrices, there are multiple limitations due to inflexibility in the design of the HRI. The proposed methodology suggests using a confidence interval approach to quantify the true implications of a failure mode. The methodology converts the HRI matrix to a plane, versus discrete elements such that the results from calculating these confidence intervals for occurrence and severity can be plotted. The approach results in a more realistic picture of what is likely to happen rather than a deterministic selection, thus supporting probabilistic design for reliability.

The methodology also incorporates sample size and data quality which is especially useful in reliability engineering. Reliability data is notorious for being limited or messy, so a range bound by a set of confidence limits becomes more practical than a finite risk assessment. As data becomes more conclusive these limits will tend to shrink and increase in accuracy of severity prediction.

Confidence intervals are utilized frequently to represent an interval at some confidence level of a population parameter [5]. Since confidence intervals reflect the data used to calculate them, the confidence interval approach more accurately depicts the collected knowledge about a chosen issue or failure mode. When there are reservations about data integrity, quality or quantity, we would expect the confidence to be larger; a large confidence interval provides a better picture of what is realistic based on the information that we do have. This methodology could be further applied in situations where there is no data - by making use of similar mechanisms and a confidence leverage factor discussed further in this section.

Confidence bounds should not be considered as a worst casel best case scenario, but rather interpreted as a specified confidence that the random variable in question will fall between the lower and upper bounds. That is if we were to replicate a certain experiment independently 100 times, creating a sample of 100 to represent our population for this metric, and our alpha, or acceptable statistical significance coefficient was .05, then when the experiment is replicated the metric of choice will fall between the lower and upper bounds approximately 95 out of every 100 times.

If the random variable in question exhibits a constant failure rate the Exponential distribution is frequently assumed.

Using the proposed methodology, a confidence limit is adopted to predict a range of certainty for a chosen parameter.

When calculating a confidence interval using the exponential distribution the X2 (chi-square) statistical distribution is utilized. The notation used is  X p,d (1)  where p indicates the confidence coefficient (or alpha value), and d designates the degrees of freedom.

Then assuming that the random variable in question follows an exponential distribution we can use the confidence interval can be calculated as such:  (2)  Where if XJ, X2, ? . ?  , Xn are individual observations of the random variable, a is the confidence level that we have chosen, and n represents the total number of failures. The approach can be adopted to both axes of the HRI matrix, to include severity and probability.

Confidence Intervals for Small Sample Sizes  Constructing confidence levels with limited or without data is possible in the same way that HRI matrices have been constructed in the past. The result of using the confidence bounds rather than a matrix design would result in a larger confidence bound representing the true range of uncertainty.

If no data is available, it has been common practice to use similar structures as a basis, or to run simulations of the systems. Other approaches make use of an HRI from a similar component and use it for this component. With the confidence interval approach it is possible to add an uncertainty leverage factor. For example if the assumption is made that the new component would follow the same characteristics of the comparison component only a 5% margin of error could be used (increase the confidence    interval by 5%). In contrast if confidence was lot that the two components would follow the same characteristics, the confidence bound could be increased by 300 %. For illustrative purposes this paper will focus on criticality variables or probability of occurrence and severity.

7. EXAMPLE AND DISCUSSION  In this example the analysis is performed early during the design process with limited quantitative failure or maintenance data available. Thus, the team relies on the subjective opinion of a cross-disciplinary group of engineers. Each individual is asked to estimate how many occurrences of the respective failure mode will occur in 500 hours of operating time, along with the associated severity in terms of dollars. The following data is produced. The assumption is made that each unit operated 500 hours.

Table 2: Input Data  Number of Severity  Occurrences  Engineer 1 5 $40k  Engineer 2 2 $15k  Engineer 3 0 $40k  Engineer 4 10 $35k  The MTBF is frequently utilized as a metric of reliability within engineering. Several other metrics have been proposed to replace MTBF - which the authors concur with - however that discussion is beyond the scope of this paper.

Additionally, as stated before this approach could be extended to those metrics.

The assumptions of using the exponential distribution as a basis for the confidence interval requires that the operating hours are independent exponential random variables. Each failure is inherently independent of another, and failures are typically assumed to have an exponential distribution of failures times as follows the well-known bathtub curve.

MTBF can be calculated by utilizing total population operating time divided by the number of failures or  MT B F = _--=L=--O--, p _e _ra_t _in""g_T_im_e __  Total Number of Failures  = ----u- = 117.7 hours  (3)  Next, the confidence interval can be calculated. Where in the case of our example Xi indicates the amount of time each engineer considered when estimating the total number of failures, and r indicate the number of failures.

(4)  77.0 <8MTBF< 202.0   Then applying the confidence interval, we are 95% confident that the true population MTBF falls between 77 and 202 hours.

As mentioned before based on the context in which confidence intervals are applied, an applicable methodology and distribution should be used. In the case of cost associated with this failure mode it has been noted that the distribution of cost of repairs tend to follow a normal distribution. Furthermore, since a limited number of observations are available we select a derivation for a confidence interval that can be applied to small sample sizes. Thus, assuming a normal distribution, a confidence interval for a small sample can be calculated [5].

i+ t?...:.... - Fn  $32 500 + 2.776 (5951.19)  , - ,f4  (5)  (6)  $15,979.5 :::; Ilcost of repair s:::; $49,020.5 (7)  Using this methodology we are 95% confident that the true mean for the population of all failures for this failure mode would be between $15979.5 and $49020.5. Due to the small sample size, there is a large range of uncertainty in the true cost of repairs, but we at least know what the average cost of this repair would approximately be.

Figure 3: Example HRI with Confidence Interval  o    o 10k 20k  Severity (in dollars)  50k  As can be seen from the relevant axes chosen in Figure 3, this failure mode would be considered high risk. The figure further supports that there is a large amount of uncertainty regarding the severity, measured by cost in this example - with much less uncertainty regarding the frequency of occurrence. Thus, one possible take-away could be to develop a mitigation strategy that controls the cost (or severity in this case) versus reducing the number of failures.

8. CONCLUSION AND FUTURE WORK  This study presented a simple, yet important methodology for understanding error within an FMEA and/or FMECA analysis. The study demonstrated a new approach for creating HRI matrices that reduced bias and more accurately depicts risk. The methodology was demonstrated with an example to include a small data set. By applying the confidence interval based approach to risk quantification additional insight into the uncertainty regarding the failure mode results in more robust decision making. Future work includes expanding the methodology to other parts of FMEA analysis.

9. REFERENCES  [1] Blanchard, B. S. (2004). Logistics engineering and management (6th ed.). Upper Saddle River, N.J.: Pearson Prentice Hall.

[2] Carlson, C. S. (2012). Effective FMEAs: achieving safe, reliable, and economical products and processes using failure mode and effects analysis. Hoboken, N.J: Wiley.

[3] Chin, K., Chan, A., & Yang, J. (2008). Development Of A Fuzzy FMEA Based Product Design System. The International Journal of Advanced Manufacturing Technology, 36(7-8), 633-649.

[4] Konstandinidou, M., Nivolianitou, Z., Kiranoudis, C., & Markatos, N. (2006). A Fuzzy Modeling Application Of CREAM Methodology For Human Reliability Analysis.

Reliability Engineering & System Safety, 91 (6), 706-716.

[5] Mendelhall, W., Scheaffer, R., Wackerly, D. (2008).

Mathematical Statistics with Applications (7th ed.).

Belmont, CA: Thomson Higher Education.

[6] Phuong, N., & Kreinovich, V. (2000). Fuzzy Logic and its Applications in Medicine. EI Paso: University of Texas at EI Paso.

[7] Shirouyehzad, H., Badakhshian, M., Dabestani, R., & Panjehfouladgaran, H. (2010). Fuzzy FMEA Analysis for Identification and Control of Failure Preferences in ERP Implementation. Journal of Mathematics and Computer Science, 1(4), 366-376.

[8] Suhir, E. (2011, April 1). Are current Qualification practices adequate? A novel approach to predicting - and improving - device failure rates.(QA MODELING). Printed Circuit Design & Fab, 14, 6.

[9] Suhir, E. (2013). Failure-Oriented-Accelerated-Testing (FOA T) and Its Role in Making a Viable Device into a Reliable Product. Circuits Assembly, 228. Retrieved September 10, 2013, from   http://www.circuitsassembly.com/cms/component/content/a rticle/228-20 13-articlesl1480 I-reliability  [10] Tay, K. M., & Lim, C. P. (2006). Fuzzy FMEA With A Guided Rules Reduction System For Prioritization Of Failures. International Journal of Quality & Reliability Management, 23(8), 1047-1066.

10. BIOGRAPHY  Marc Banghart is a lead reliability engineer with Wyle Incorporated  supporting several Reliability Information Analysis Center (RlAC)  contracts. His area of focus is  Reliability Centered Maintenance  (RCM), reliability modeling,  optimization, and sustainment  engineering. Marc started his career in the United States Air Force working on F-I5 aircraft.

After leaving the Air Force, Marc held several positions  in Systems Engineering performing radar analysis and  systems engineering activities. He holds a Bachelor of  Science degree in Computer Science (Troy State University) and a Master of Science degree in Systems  Engineering (Southern Methodist University) .  He is  currently pursuing a PhD in Industrial and Systems  Engineering, with a focus on reliability from Mississippi  State University. Marc is an active participant in several  professional organizations including ASQ and IEEE.

Kara Fuller is a Business Intelligence Analyst at Digital  Risk. She holds a Bachelors of  Science from the University of  Central Florida in Statistics.

Kara has worked as a Statistical  Data Analyst in the Reliability engineering field on various  projects spanning aerospace and  the financial sector. She is currently pursuing a Master's  in Business Administration from the University of North Florida.

