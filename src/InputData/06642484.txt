Extracting and enriching workflows from text

Abstract  This paper is on a workflow extraction framework which allows to derive a formal representation based on work- flows from textual descriptions of instructions, for instance, of aircraft repair procedures from a maintenance manual.

The framework applies a pipes-and-filters architecture and uses NLP (Natural Language Processing) tools to perform information extraction steps automatically. In detail, the paper presents on the step of anaphora resolution to enrich the workflow extracted so far. We introduce a lexical ap- proach and two further approaches based on a set of asso- ciation rules which are created during a statistical analysis of a corpus of workflows. The results of the approaches are compared to each other. For the evaluation, we use 37 workflows which have been created by a human expert.

1 Introduction  Traditionally, workflows are ?the automation of a busi- ness process, in whole or part, during which documents, information or tasks are passed from one participant to an- other for action, according to a set of procedural rules? [23].

Recently, a broader notion is emerging, where a workflow describes any flow of activities in the sense of an instruction whose execution is supported automatically. For instance, a repair instruction for an aircraft can be described by a work- flow including some activities. The workflow participants are one or several technicians who conduct the repair activ- ities. This is not any more a classical workflow supporting a business process.

However, the notion of a workflow for such an instruc- tion provides many benefits: Graphical workflow modelling languages can be used to visualize the instructions making them easy to understand. Workflow management systems can be used for workflow execution providing a step-by- step guidance for the users. The workflow execution can be tracked easily to fulfill regulatory requirements with re-  spect to quality management, traceability issues etc. The workflows can be reused and adapted to new situations.

This can be supported by reasoning methods like those of case-based reasoning (CBR) [2]. Recently, process-oriented Case-Based Reasoning (POCBR) emerged as a new branch of CBR [16]. This field of research investigates new rea- soning approaches to handle procedural knowledge. Sev- eral approaches for retrieval [4, 18, 11] and adaptation [15] of workflows have been presented.

Workflow modelling is a laborious task that consumes a lot of human effort for different artifacts. A workflow con- sists of a control-flow and a data-flow. A set of activities combined with control-flow-structures like sequences, par- allel or alternative branches, and loops forms the control- flow. In addition, activities consume resources and create certain products which both can be physical matter (such as cooking ingredients or a screw) or information. The data- flow describes the interaction of activities with resources and products. Automated assistance can be achieved by transforming textual descriptions of instructions into for- mal workflow models. A large amount of such instruction texts from different domains is readily available, e.g., on cooking recipes, on computer-how-tos or on the process- ing of an order from a customer. Recently, the extraction of workflows from text has been investigated in research on process-oriented Case-Based Reasoning (POCBR) [21, 5].

Workflow extraction has to face several challenges. It has to identify the activities and to organize them in a control-flow. Further, the control-flow has to be enriched with the data-flow. Frequently, the data-flow has to be completed since the textual description of the data-flow is incomplete due to the human economy of language. For instance, the references from a component of an aircraft to its constituents are not expressed explicitly in the text even if the constituents have been mentioned before. Fur- ther, the extraction process has to fulfil non-functional re- quirements like robustness and scalability. The issue of domain-dependency requires special attention. On the one hand side, a framework for workflow extraction should     cover several domains to create some impact. On the other hand, some components of the extraction process need to be domain-specific to achieve valuable results. An optimal balance between both is a non-trivial research goal.

This paper presents a novel, extensible pipes-and-filters framework for the extraction of workflows from textual pro- cess descriptions in an arbitrary domain. This paper is orga- nized as follows. In the next section we describe the pipes- and-filters framework. The third section presents how the framework is applied to set-up a sample domain. The subse- quent section introduces the data-flow creation with a focus on anaphora resolution approaches. In an evaluation, dif- ferent anaphora resolution approaches are compared. The paper closes with a discussion of related work, a short con- clusion and an outlook on future work.

2 Workflow extraction framework  Systems which process natural language need to be ro- bust and scalable. A large corpus of frameworks for generic NLP (Natural Language Processing) tasks exist. We have developed a generic framework on top of these that is ded- icated especially to workflow extraction from text. It fo- cusses on the workflow specific structures and operations.

The capabilities of the framework include the identification of activities, organizing them in a control-flow, and enrich- ing the control-flow by a data-flow. The framework is based on a pipes and filter architecture [25], i.e., it consists of sub- sequent extraction components called filters. The architec- ture of the framework is domain independent. However, some of the particular filters are domain specific. The lan- guage in process descriptions has a specific style, e.g., the steps are in the correct order and mainly active voice is used [13]. For instance, aircraft maintenance manuals are writ- ten in simplified technical English which is a controlled lan- guage whose rules are defined in a specification [1].

2.1 Workflow representation  The target of workflow extraction is a formal represen- tation of the workflow in a workflow description language [23]. We have chosen an XML-based language [17] that is part of the CAKE1 system. It is a block-oriented work- flow description language: The control-flow can contain sequences, XOR-, AND-, LOOP-blocks. These building blocks cannot be interleaved but they can be nested. In addition an activity has a set of semantic-descriptors, re- sources and products. A semantic descriptor is for exam- ple the name of the task or additional information which describes ?how? a task should be performed, e.g., ?for 10 minutes?. Resources and products contain a set of seman- tic information, these describe additional information about  1Collaborative Agile Knowledge Engine  Figure 1. Sample workflow for cooking rocket pasta with vegetable.

the resources, e.g., amounts or if a resource should be pre- processed like ?chopped?. Fig. 1 shows a sample workflow which was extracted of the recipe of Listing 1. The rounded rectangles are the activities, the grey rectangles are the prod- ucts, and the grey ovals are semantic-descriptors. The first activity is ?saute? with the resources ?onion? and ?green pepper?. In addition, it contains the semantic-descriptors ?In a large skillet? and ?until tender?. The activities ?saute?, ?add?, ?boil?, ?add? and ?mix? are aligned in a sequence.

The data-flow of it is not complete as it only contains re- sources.

2.2 Information extraction software  Our framework uses the NLP software SUNDANCE (Sentence UNDerstanding ANd Concept Extraction) devel- oped by Ellen Riloff [19]. SUNDANCE performs the usual NLP task like tokenization or part of speech tagging but we use SUNDANCE , because it has good balance between coverage and robustness.

SUNDANCE has been inspired by the conceptual depen- dency theory published by Roger C. Schank [20]. The the- ory aims at illustrating how people think and process infor- mation. It is based on three kinds of concepts, the nominal, the action, and the modifier. A sentence or a thought can be represented by these three types of concepts. Nominals are those things that can be thought of without the need for relating them to other concepts. It is usually used to rep- resent things or people. The concept of an action is what a nominal is doing. These actions are usually represented by a verb. The last type of concept is the modifier, which specifies properties of a nominal or an action. A sentence is built of one or more concepts and a concept may depend on another one to get the whole meaning [20].

SUNDANCE allows to specify extraction patterns for the system called case frames [6]. These patterns are similar to the concepts described in the concept dependency theory.

The SUNDANCE parser assigns syntactic roles (subject, di- rect object, and indirect object) to text snippets based on a heuristic. Then the SUNDANCE information extraction en- gine tries to fill a case frame as follows. Each case frame specifies a trigger phrase. If the trigger phrase is detected     in a sentence, then the according case frame is activated.

This means that the activation functions of the frame try to match the specified linguistic patterns with the syntactic roles. A slot specifies a syntactic role whose content is to be extracted from the text. A filled case-frame can be mapped to a task. The trigger phrase is the task-name and the filled slot contains a list of products- or resources-names.

2.3 Extraction pipeline  The framework is based on a pipes and filters [25] ar- chitecture. Such an application is a sequence of filters which are connected by pipes. A filter is a self-contained element which performs a data-transformation-step on the data-stream. The pipes channel the data-stream from the output of a filter to the input of the subsequent filter. A data-stream is sent through this pipeline and each filter is applied to the stream. Filters can be added or deleted with- out affecting the other filters in the pipeline.

While a classical data-stream is pulsed using bits or bytes, our case-stream uses cases as a pulse. A case is the smallest unit which can be processed by a filter. At the be- ginning of the pipeline, the case initially consists of the tex- tual process description. While the case passes through the pipeline it is enriched with additional structure. At the end of the pipeline we have a complete case consisting of the textual process description and the formal workflow repre- sentation.

Our framework extents the original pipes and filters ar- chitecture. We allow two different types of filters. The first one, the so called local filters operate with a focus on one case. The second one, the window filters collect a part of the case-stream (e.g 5000 cases) and operate on that. The model of a window filter is necessary, because the framework pro- cesses a stream of cases which is potentially infinite. The intention is to use statistical methods for a larger number of textual process descriptions. The statistical approaches benefit from the pipes and filter principle because we use them on processed data. This intermediate data is the result of the preceding steps of the extraction pipeline. It contains less noise and has more structure then the raw input-data.

The filters are hand-crafted by analysing the textual pro- cess descriptions. We refrain from using machine learning techniques to create the filters because the effort to create a training-set is higher than the effort to build the filters by hand.

3 Workflow Extraction  The following section describes the different subtasks of- does workflow extraction. We describe the subtask by using the cooking domain as sample domain. Fig. 2 illustrates the respective pipeline with a sequence of filters. The filters can  not be classified by means of subtasks, e.g., the main task of the ?AND Extractor?-filter is to detect a parallel control- flow but it also creates new activities.

Figure 2. Overview of the extraction pipeline for the cooking domain.

3.1 Linguistic analysis  In the first filter, the linguistic analysis we use the SUN- DANCE natural-language-processing-system [19] to per- form the standard language processing. During this pro- cessing the recipe text is split into sentences (End of sen- tence detection). In the next step the sentences are divided into tokens (tokenization). At the end the tokens are tagged with their part-of-speech and syntactic role (subject, direct object, etc.). SUNDANCE uses a set of heuristics to per- form these tasks.

3.2 Recognition of activities  They use pattern-matching to extract the activities. The first pattern (?Direct Object Pattern?) searches for filled case-frames with a verb phrase in active voice and direct object as slot. The second pattern (?PP Pattern?) is a filled case-frame with an active verb phrase and a prepositional phrase. If no case-frame can be filled, it is checked whether a verb or two verbs combined by a conjunction is at the beginning of the sentence, for instance ?Cover and cook.?.

Sentences like this are quite difficult because they do not fit in a normal grammatical context. Therefore a special pat- tern (?Two Verbs + Conjunction?) is needed for this struc- ture.

3.3 Recognition of resources  The ?Resource list extractor? extracts the resources and the ?Numeric value extractor? extracts the related amounts.

The resources are cleaned using a stoplist (?Clean resources using stoplist?). The step ?Mine & apply anaphora rules is explained in section 4. We assume that the noun phrases which are related to activities are resources. This leads to a quite high recall for the resources but the precision is too low because a lot of items which are not a resource or product are extracted by the filters, for instance cookware     or tools. After analysing the data we discovered that most tool are used with an indefinite article (?a skillet?) while resources usually have no article or definite article. For re- sources with an indefinite article we check if we find a cor- responding item in the ingredients list, if so it is considered as resource. In the case we find no corresponding item we eliminate that resource.

3.4 Building the control-flow  Currently our system is able to extract a sequential, par- allel (?AND Extractor?) or disjunctive control-flow (?XOR- Extractor?) for process descriptions of the cooking domain.

Extraction of a sequential control-flow is a straight forward procedure. Usually textual descriptions describe a process sequentially [13]. For the extraction of disjunctive of dis- junctive or parallel control-flow we analysed the process de- scriptions and looked for patterns which suggest a control- flow. We found that a small number of patterns occurs very frequently which facilitates the extraction of a non- sequential control-flow. There are different types of pat- terns. A very simple pattern is for example the keyword ?occasionally?. In a sentence like ?Cook, stirring occa- sionally for about 10 minutes.? we can extract the activ- ity?cook? and ?stir? which are performed in parallel. In- structions which force to choose one of two ingredients in- duce a disjunctive control-flow. The sentence ?Add butter or margarine?, e.g., suggest two activities ?add? with ei- ther ?butter? or ?margarine? as ingredient. These two ac- tivities are on alternative paths. We found also some pat- terns which use the additional structure which was provided by the description authors. The authors usually divide the descriptions into steps and we preserve this information dur- ing the extraction process. If we find the keyword ?Mean- while? as first word of such a step, we can deduce that the activities of the previous step and the activity of the step in which ?Meanwhile? was found are executed in a parallel control-flow.

4 Data-flow creation and evolutive anaphora resolution  The data-flow describes the flow of resources and prod- ucts through the workflow. The creation of a data-flow is a complex problem which is tied to the linguistic problem of anaphora resolution. An anaphora is a linguistic entity which indicates a referential tie to some other entity in the same text [22]. An evolutive anaphora is an anaphoric ref- erence to an object that has been destroyed or created [10].

In workflow terminology, this is a reference to resources that have been consumed by an activity. For example, the object ?dough? is created by the activity ?mix flour, water and yeast?. In the context of workflow extraction anaphora  resolution is the determination of the activity in which an object is created. The resources consumed by that activity are called constituents. In the above sample, ?flour?, ?wa- ter? and ?yeast? are the constituents of the anaphoric ref- erence ?dough?, produced by means of the activity ?mix?.

Now, we introduce our method which is used to resolve evo- lutive anaphoras in workflows. We use data-mining tech- niques to mine anaphora-rules which enables us to deter- mine the activity an anaphora is referring to. The left side of an anaphora-rule is a set of constituents and the right side contains the anaphora.

Listing 1. Sample recipe in XML format <r e c i p e> < t i t l e>Rocket P a s t a wi th v e g e t a b l e< / t i t l e> <r e s o u r c e s><r e s>D i t a l i< / r e s> <r e s>r o c k e t< / r e s><r e s>Water< / r e s> <r e s>h e r b s< / r e s><r e s>on ion< / r e s> <r e s>o l i v e s< / r e s><r e s>mushrooms< / r e s> <r e s>g a r l i c< / r e s><r e s>oregano< / r e s> <r e s>g r e e n p e p p e r< / r e s> < / r e s o u r c e s> <s t e p s><s t e p>In a l a r g e s k i l l e t , s a u t e on ion and g r e e n pe pp e r u n t i l t e n d e r . Add g a r l i c mushrooms , o l i v e s and oregano .< / s t e p> <s t e p>B o i l w a t e r . Add d i t a l i .< / s t e p> <s t e p>Mix t h e cooked v e g e t a b l e wi th t h e d i t a l i and t h e r o c k e t .< / s t e p> < / s t e p s> < / r e c i p e>  Listing 2. Sample transactions for workflow in figure 1.

WorkflowId , T r a n s a c t i o n T i m e ,{ I t e m s } 0 ,0 ,{ D i t a l i , r o c k e t , water , he rbs , onion ,  mushrooms , g a r l i c , oregano , g r e e n p e p p e r } 0 ,1 ,{ onion , g r e e n pe pp e r } 0 ,2 ,{ g a r l i c , mushrooms , o l i v e s , o regano } 0 ,3 ,{ w a t e r } 0 ,4 ,{ d i t a l i } 0 ,5 ,{ r o c k e t }  4.1 Mining anaphora-rules  We use a method for sequential pattern mining that was presented by Agrawal [3] to mine anaphora-rules. We are going to introduce the problem . We derive workflow trans- actions with the fields workflow-id, task-position and the items used in the transaction. The mining of anaphora-rules precedes the extraction of control-flow, therefore the work- flow is sequential at this stage. Quantities are omitted. An item-set is a non-empty set of items. A sequence is an or- dered list of item-sets A set of items can be mapped to a     set of contiguous integers. Let o = (o1, o2, ..., om) be an item-set where oi is an item. Let s = (s1, s2, ..., sn) be a sequence where si is an item-set A sequence ?a1, a2, ..., an? is contained in another sequence ?b1, b2, ..., bm? if there ex- ist integers i1 < i2... < in such that a1 ? bi1 , a2 ? bi2 , ..., an ? bin . A workflow supports a sequence s if s is contained in the workflow-sequence for this workflow. The support for a sequence is defined as the fraction of work- flows in total which support this sequence. The problem of mining sequential patterns is to find the maximum se- quences which have a certain user-specified minimum sup- port. By restricting the length of the sequential pattern to two item-sets, we get anaphora-rules. In addition we create a transaction with an item-set corresponding to the ingredi- ent list and the transaction-time zero. Listing 2 displays the transactions which were created from the workflow in Fig.

1. It assumes that the workflow has the id 0. The items at the transaction at time 0 are extracted from the correspond- ing ingredient list of the original recipe. For the details of the sequential pattern mining algorithm we refer to the orig- inal paper [3]. In addition, the sequences of the sequential patterns do not need to be maximal. The algorithm delivers a set of anaphora rules with a corresponding support value.

The minimum support value which is used is 0.005. This value is domain dependant and must be tuned during the adaptation of the filter for a new domain.

Listing 3. Top 10 patterns by support value.

0 . 0 2 5 : <i t em = b u t t e r ><i t em =dough> 0 . 0 2 4 : <i t em = b u t t e r ><i t em = mix tu re> 0 . 0 2 4 : <i t em = f l o u r ><i t em = b a t t e r > 0 . 0 2 1 : <i t em =eggs><i t em = b a t t e r > 0 . 0 2 1 : <i t em = f l o u r ><i t em =dough> 0 . 0 1 8 : <i t em = y e a s t ><i t em =dough> 0 . 0 1 6 : <i t em = b ak i n g powder><i t em = b a t t e r > 0 . 0 1 6 : <i t em = b u t t e r ><i t em = b a t t e r > 0 . 0 1 5 : <i t em = g a r l i c ><i t em = mix tu re> 0 . 0 1 5 : <i t em = v a n i l l a ><i t em = b a t t e r >  4.2 Creation of data-flow  The rule-set is improved by using two observations about evolutive anaphoras which:  1. Anaphoras are not enumerated in the resource list.

2. Constituents of an anaphora are used before the anaphora or are part of the resource list.

The first observation enables us to delete a lot of wrong rules. The algorithm creates rules whose right side contains items which are initial resources. Initial resources are all the resources which are not produced by an activity in the workflows. Usually textual process descriptions contain a  Figure 3. Illustration of OPM, ARM and FMS.

list with the initial resources. In the domain of cooking this is the ingredients list, in the aircraft maintenance domain it is the list of parts needed to perform a reparation. All rules whose right side contains such an initial resource are omit- ted. The second observation is essential for the application of anaphora-rules. During the application, first a candidate list is generated by selecting all the rules whose right side is matching the anaphora then we check if the second ob- servation holds. All rules for which the second observation does not hold are dropped from the candidate list.

The creation of the data-flow begins with extraction of the first use of a resource. In a second step, the products of the activities have to be determined. It is necessary to per- form anaphora resolution to detect the correct products. At the end, the resources of the activities are completed with the products of the respective preceding activity. We imple- mented three different approaches which we are going to introduce.

One pattern method (OPM) (see Fig. 3) is based on the observation, that a lot of anaphoras contain the token ?mix- ture?. This approach searches for resources which contain this token. If such a resource is found, we performe a back- ward search for the name-giving resource of a mixture e.g.

?flour? is the name-giving resource of ?flour mixture?. For those activities it is checked, if they contain multiple re- sources. A sole product name-giving resource + ?mixture? is created for that activity. At the end, the data-flow is com- pleted by copying the products as resources to the next ac- tivity. For Fig. 3 the resource ?flour mixture? is found at the activity ?knead?. After deleting the token ?mixture? we get the resource ?flour?. We search for the resource ?flour? in the preceding activities and find it at the activity ?combine?. This activity uses four resources. We assume     Recipe POPM PARM PFMC ROPM RARM RFM FOPM FARM FFM Mexican Egg Bake 0.55 0.55 0.55 0.67 0.67 0.67 0.61 0.61 0.61 Classic Thumbprint Cookies 0.58 0.37 0.37 0.32 0.29 0.29 0.41 0.33 0.33 Cranberry Glazed Roast Pork 0.48 0.46 0.52 0.31 0.31 0.33 0.38 0.37 0.41  Table 1. Results of the evaluation for selected cases.

now, that the activity combine produces the product ?flour mixture?  Anaphora-rule method (ARM) (see Fig. 3) includes OPM in addition it iterates over all activities, starting at the first. For each resource of the activity, it is checked, if there is an association rule with a matching right side. If such a rule is found, it is looked if one of the previous activities has a matching resource for the left side of the rule. We assume then that the anaphora enters the workflow at the activity where the left side of the rule is found. Therefore we add the right side of the rule(the anaphora) as sole product of that activity. In the case that multiple rules are found, the one with the best support value is chosen. In Fig. 3 the search for a right side of a rule resulted with the resource ?dough?. When a match is found, the algorithm searches the preceding activities for the resources of the left side of the rule ?flour, eggs, water?. These resources are linked to the activity ?combine?. Although the activity has more resources than the left side of the rules enumerates (the re- source ?olives? is not included in the rule) the sole product ?dough? is created for the activity ?combine?.

Filter method (FM) includes ARM A domain specific list of items is added this list is used to filter out items which are incorrectly extracted as resource. In the cooking domain this list is used to filter out cooking ware.

5 Evaluation  This section describes our hypothesis and our evaluation approach. The performance of the different methods was measured using the standard evaluation functions Precision, Recall and F-measure [12]. We tested the following three hypotheses:  1. The data-flow created by OPM has the best precision in comparison to ARM and FM.

2. The data-flow created by ARM has a better recall than OPM.

3. The data-flow created by FM has the highest F- measure in comparison to OPM and ARM.

5.1 Experimental Set-up  The experiment was performed on a set of 37 recipes.

These recipes were selected randomly from a set of 36 898 recipes which were crawled from a cooking community website2. A human expert modelled the data-flow for the recipes in the test set. This serves as the golden standard for the evaluation. This evaluation aims at the data-flow therefore the expert got the control-flow which was auto- matically extracted as framework for the golden standard workflow. This approach eliminates the paraphrasing and granularity problem of the control-flow. The paraphrasing problem is the problem that the same process can be de- scribed by different workflows. The granularity problem is the problem of handling the different levels of abstraction which can be used to formalize a process using a workflow.

The expert was allowed to use all resources and products that she thought should be in the data-flow, even if they were not mentioned in the text. So we got a semantically correct data-flow. The only constraint was that the expert was not allowed to use synonyms for products which were mentioned in the original recipe texts. If a product was men- tioned in the text, this term must be used in the data-flow.

This restriction should reduce the paraphrasing problem for the data-flow. We adapted recall, precision, and F-measure to our scenario. Every activity in the golden standard work- flow had per definition a corresponding activity in the evalu- ated workflow. We are handling the elements in the products and resources sets separately, if a product is missing once in the input and once in the output set, it counts twice even if it?s the same item. We are going to define the evaluation function formally.

Let T and T ? be sets of activities of the workflows W and W ?. W ? is the golden standard workflow. Each activity ti ? T has a corresponding activity t?i ? T ? which are equal except for the resource and product sets. Let Ii and I ?i be resource sets and Oi and O?i product sets for the activities ti and t?i. The precision for an activity ti ? T is defined as:  precision(ti) = | Ii ? I ?i | + | Oi ? O?i |  | Ii | + | Oi | The recall for a activity is defined as:  recall(ti) = | Ii ? I ?i | + | Oi ? O?i |  | I ?i | + | O?i | 2www.allrecipes.com     P R F1 OPM 0.5127 0.3034 0.3812 ARM 0.4828 0.3124 0.3793 FM 0.4892 0.3130 0.3817  Table 2. Summary of the average results for the three methods for precision (P), recall (R) and F1-Measure(F1).

This leads to the evaluation functions for a workflow:  precision(W ) =  | T | |T |?  i=1  precision(ti)  recall(W ) =  | T | |T |?  i=1  recall(ti)  The F1 measure is defined as:  F1(W ) = 2 precision(W ) ? recall(W ) precision(W ) + recall(W )  5.2 Results  Table 2 and Table 1 show that the results for the three methods are very close. The best average precision is achieved by OPM. For 7 instances the application of addi- tional filter (ARM) reduces the precision compared to OPM.

The best average recall is performed by FM. We examine the instance of the ?Mexican Egg Bake? recipe for which the results are equal for the three methods. This can happen in case there has not been found any matching association rule nor any cookware item has been filtered out by the stop- list. For the sample of the ?Classic Thumbprint Cookies? recipe, a wrong association rule is chosen, therefore the pre- cision and the recall is lower for ARM and FM as it is for OPM. A very interesting instance the one of ?Cranberry Glazed Roast Pork?. There we see a drop in precision from OPM to ARM. First a wrong rules is used in ARM which is corrected by FM, which ended in a higher precision for FM.

The values of the recall might raise the question, how it is possible that a filter step produces a higher recall. Since the filter step is preceding the association rule mining step in the pipeline, we can get a different set of association rules.

If the rule mining step would precede the filter step, then in- deed the results would show a higher precision but a recall which cannot be higher than before the filtering.

6 Discussion  The results of the data-flow-evaluation are promising given the complexity of the data-flow-creation. Although  the results of the previous section indicate that the bene- fit of the statistical anaphora resolution is low compared to the result which was achieved with the simple approach of OPM. We used a simple lexical distance to decide whether a product or a resource are equal. This distance led to the problem that two items are classified as not equal even if they are semantically very close. For example ?broth? and ?soup? would be classified as unequal. The use of a seman- tic distance should improve our results. Therefore in reality the results of ARM and FM should be better than the mea- surements of the evaluation. The results of OPM should not differ because this approach strictly relies on a lexical com- parison. The evaluation shows, that our approach can not fully distinguish between an anaphora and a cooking tool.

Therefore we need a list of cooking tools to differentiate be- tween a cooking tool and an anaphora but we don?t need a complex ontology.

7 Related work  We are going to present related work of different re- search areas. The area of statistical anaphora resolution had been approached by computer linguists. Gasperin and Briscoe [8] applied an statistical approach for anaphora res- olution in biomedical texts. They built a system which was based on the naive-Bayes classifier. Markert et al. [14] pre- sented an approach that was based on the number of results of a search engine query. The queries were build with all possible antecedents for that anaphora and the anaphora it- self they were embedded in sample phrases e.g. ?fruits such as apples?. The TellMe [9] system allows the user to define procedures trough utterances in natural language that are interpreted by the system and transformed to formal work- flow steps. In comparison to our system, the process of the TellMe system is interactive; the user might get feedback from the system and can specify her input. Zhang et al.

[24] describe a method to extract processes from instruc- tional text. In contrast to our approach, their process models do not follow the workflow paradigm, as their control-flow is strictly sequential and they are not supporting a data-flow.

Friedrich et al. [7] developed a system to extract a formal workflow representation of a textual process descriptions.

To avoid noise, a manual preprocessing step is applied. Our approach is capable to process textual content as it is. The work of Dufour-Lussier et al. [5] is very similar to ours.

They extract a tree representation of recipes from text. In contrast to our method, the focus is on food components that are transformed by cooking activities to other food compo- nents. The TAAABLE ontology is applied to resolve ref- erences in the text by matching sets of food components, e.g. ?blueberry? and ?raspberry? with ?fruits?. They pre- sented in [5] an evaluation for the data-flow. Their system delivered very good result. However, the test set was not     representative and they were only counting the first occur- rence of a product within a recipe.

8 Conclusion and future work  This paper adresses the problem of workflow extraction from textual process descriptions and presents a framework to support the development of extraction applications by a pipes-and-filters architecture. The framework is illus- trated by an application to the cooking domain. Multiple data-flow-creation approaches are evaluated with a focus on the anaphora resolution problem. Three different anaphora resolution approaches are presented. Two approaches are based on association rules which were created during an analysis of the corpus of workflows. The experimental eval- uation uses workflows as a golden standard which have a se- mantically correct data-flow created by a human expert. The performance measures are precision, recall, and F-measure.

The results show that the data-flow has been completed slightly by anaphora resolution. However, the anaphora resolution methods should be improved by the use of fur- ther semantics. It is promising that the method with the most sophisticated semantics (the FM method) achieved the highest value of the F-measure. The successful application in the cooking domain highlights that a pipes-and-filters framework is a good means to combine domain-specific and domain-independent filters. In future, we are going to im- plement an evaluation based on a taxonomical distance. We expect our approaches to achieve better assessments when using this intelligent semantical distance. To prove that our approach is not limited to cooking recipes, we are going to implement a new domain.

9 Acknowledgements  This work was funded by the German Research Founda- tion, project number BE 1373/3-1.

