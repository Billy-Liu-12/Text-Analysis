Updating of Association R u b  Dynamically

Abstract  1. Introduction  Data miniiig has recently attracted n 1:irgc ntiiounl of at- tcntioti duc to its widr: application. In pnrlicnlar, associaticin rulc is an Iiiiportiliit type of kttowlcdgc which caii be (lis- covcrcd I'roin lnrgc datnbascs. Associalirm rulcs have becn widcIy used in arcas likc marketing, dccision support and slnl-c layout rlcsign [3]. A n  cxatnple of association IIIIC is UREAO + MII,JC. II it is tliscovcrerl [tom il supcrinor- ket trntisaction datitbnsc, it niay rncan [tiat "whcti pcoplc huy brcnd, they usunlly also buy milk". ncsides binary aiitl categorical data, sninc tlatabascs inay atsi) contain qiriiiititii- tivc, or nutncrical dnta. Much work has been done for dis- covering associaliun rulcs ~ U O I  such quantitative databases [ 10, 12,71. Ii'aconccptiial hierarchy is available for Ihednta itcrris ill the dniahase, thcn gcneralixrl, or miil~iple-lcvcl as- suciation rdes can be discovered [$, 6, $1. A gctieidizcrl, or rii~rltiple-lcvcl association ruic may contain iterris rrt)Ii1 different lcvels ol' the conccplual liicrarchy.

Assume we tinvc a tlntabasc and soiiie association rulcs discovcrcd from tliis datnblbnsc. Now, i f  soinc new tlaia comes to thc database, wc will need 10 update thc set or the discovered tlssnciation rulcs. Onc simple way is to ruii an associalion rulc niitiirig algiiritiirri ovcr thc increiiientcd dutabasc to gct thr: new scl of associatiun tulcs. How-  0-7696-0490-5/00 $10.00 0 2000 11';lCK  cvcr, this approaclr is tiot clficient. To :idrlrcss this proh- Icm, wc cxplnre soiiic incremental associalion rulc ininitrg tcchniques to avoid tlie rcdundant work of thc wholc tnin- ing proccss ovcr tlic incrcmcnted databasc. Rccctitly, thci-c trnvc hccn soinc studies on tlic ii~crcmcntal rriitiing of asso- ciation rtrlcs. Cheung ct al. dcvclopcrl an approach known as t11c PUP algorithm [4]. Thc FIJP nlgoritlm in:ijtily in- corpornics thc classical Icvel-wise Apriori algorilliin 1 I ] to tirid largc iteinscts and thcir srrpport m i i t i t s  i n  h e  origintll as well as incremen~al datebascs. It dctnonstratcs goad pcr- forinnnce ovcr pnrely Apriori Lccliniquc. 'I'tionins ct al. dc- velopcd another approticti which ninkcs use of thc n q p f i v e border (if thc otigind rlntahasc [ l  1 I. Ti incrcmentalIy tip- dates thu ncgativc Iiorclcrs whcn ii set of ncw tmnsactious is avai lablc. Although [his ;rrltlitioiial iiifolniation nllows more clficicnt algorithm to hc q>plicd, it  induccs a constdcrahle amount of overticad i n  calculating thc ricgativc honlzr. Wc proposc a new algorittitri f'or inci~cmcnial mining of  asso- ciation rtilcs I ~ ~ s c t l  on dynntnic coirti1ing. Brit) et al. has dcvclopcd a dynaniic coiriiting tccliniquc ktiowri ns Ilic Dy- iiainic Itcrriscl Counting (])IC) l i )~  Ixge itcinsct cotiriting i t r  n sirrgle diltahwc. Dircct applicaiion ni' DIC iii incrc- mental ul~dating is not cflicicnl since nvailablc inrmnation storcd in thc original diitabasc is trot useh~l. We still i m d  to count thc original datalriisc again and Icsult i i i  long corripu- taliond tiiric. Our new nlgorithtr~, called thc I131CLM i l lgo- rithm and its variniir, tlic IDIC-I nlgorithm, can clriciently conduct increinentd iniiiitig 01' association tulcs based on dynamic counting. Morcover, i t  avoids tltc ovcrticad ill- curred i n  the prcvious algorilhrn bawd 011 negative bordcrs [ 1 I ] .  Wc have condiiclctl extcrisivc cxpciiments to comparc oiit nlgorithtns with the FUP algorithm. The rcsults illus- trate ttint our two nlgorithnis bnvc bcttcr pcrlbrmniicc 0ve.r the FUP dgoritbtn.

a4    2. Problem description  2.1. Mining of association rides  Assume we havc ii  set oi litcrnls cnllcd itcms. Lct DB hc a datahasc of transactions, where each tranwicctiun con- tains a set of difkrent numhcr of items. An association rule is an implication of the Tom X + Y, where X and Y are itcmsets slid X n Y = @. Wc call an itemset containing li items il bitemset. Thc associarioii rule X 3 Y holds in D B  with corifidence c if c% or thc transactions in DB that contain X also contain Y .  Thc association ride X + Y has support s i n  DD if s% of the transactions in UU contain X U Y. Givcn ii minimum conlidcncc threshold Of and a minimum support tbresholtl a,, the problcm of  minirig as- sociation rules is tu find out al l  thc associalion rulcs whosc confidence and siipport arc liirgcr than thc rcspcclivc Ihrcsli- olds. For an ilcmsct X, its support is defined siniilarly R S  the percentage of transactions in DD which contain X. Givcn a minimum support tlircsliold 8,, an iteinsct X is largc if its support is no less than 8,. The prohlcin of mining asso- ciation rulcs is retluccd to thc problem (if finding all largc itemscts for a prc-dcrcrmined minimum support [ 3 ] .  This is duc to  thc fact that discovcring hrgc itcinsets in n databasc requires most of the computational time used in rnitiing as- sociation rules. Association rules can be easily found once a set of large itemsets are availablc.

2.2. Incrcmental mining of association rulcs  Let Luu be tbc set of large itcrnscls in the rlatabasc UU, s be the ~ninimuin support, and D be the nuniber of tmns- actions in DB. Assumc Lhilt fnrcach X G L ~ H ,  i l s  support ctliinl which is  thc nuinhcr of transactirins in D3 containing X, is available. Suppose wc gnrhcr n set or ncw additional transnctions db. The problem of incrc~ncntal mining is to find all itcrnscts having support s in thc ncw datahasc, i.e., DB U til).

Idet d be the number of transactions in clb. With rcspcct to the same mitiimum support s, an itemset X is large in the updatcd database DL1 U db if the supporl of X in DU U rlb is no less than s, i.e., X.sztpportuu >_ a x ( D  + d) ,  where X . s u p p n r l u ~ ~  dcnotcs the support counts for itenisct X in D B  U (1-4, In tlie following, we use X.siipportnn atid A'.supp~rt,~~ to rcprcscnt the support counts of an iteinsct X in LIB and rlb, rcspcctivcly. Similarty, wc dcnotc with Ldb and LUJI the scl of largc ilcmscts in db aiid JIB U db rcspcctivcly. Thiis thc csI;cncc of incrcimcntiil mining of :is- socialion rulcs is tu find tlic set Lan. Note [hat an itcmsct in L ; D ~  inny no1 bc an itemset in Luo.  Also, fln itcinsct not i t )  Lan, inay becoinc ZL largc ilcmsct i n  L ~ J J ,  3. Our ne-w approach  3.1. Chalicngcs and motivation  Dynainic counting tecliniquc lins bccn cxptorcd by Brin ct al. whr) dcvcloped the DIC algotitlim for itcmsct C O I I ~ I - ing in  a single database (2 1. W M c  Apriori rcquircs the sanx tiuniber of pnsses rhrough thc dalnbasc as the size of the tiiaximuin large itemsets, dynamic counting all(iws canrli- dates of various sizes to hc counlcd at thc same tiiiie in  each pass. This rcsiilrs in thc rediiccd nurnhcr of passes ttirough tlic database.

One pcevioiis work for incrcmcntnl association rule niin- ing is the FUP algorithm 141. It is mainly based on h e Apriori nlgorithtn snd nch icvcs sat is factory performaim.

In cach itcralion of FUP, only cwididate itemscts of one sizc arc hnndlcd. It is pcrforincd by innking one pass ovcr tlic incrancnt db and otic pass over the. original datslbasc LIB. Thcrcforc, thc number of passes ovcr thc original databiisc cquals ttic sizc of the highest ordcr ikmscls to bc uprlatcrl. To rcducc thc 1mscs over tlie Dl l ,  we ctcvcl- opcd two ncw Incrcmcntal Dynamic Iteinsct Counting algo- rirhms, thc IDIC-M ;itid thc IDIC-I, which are bnscrl on dy- namic counting. In both algorithtns, we compicss thc passcs over dlr perlortnctl in  the FUP aigorilhin by dyniumic coiinl- ing tcchniqiic. 011 the othcr hand, witboii~ cliccking lor cach k-itcmset crrntlidntc found immcdiatcly aftcr onc pass through db agaiast !In, B lot niore canrlirlntcs arc gcncratcd in c i d l  o f  thc next pass through rlb atid Iiencc, thc total ex- ecutioii time used to scan cl6 inny incrcesc. A h ,  ii  Ixgc aiiiount uf candiriatz itcmsets are gcncratcd afkr scanning dh. Two diffcrcnt mcthuds arc used respectivcly to handle this problem. In thc IDIC-M nlgorilhm, wc compress tlic passes ovcr DB by q~lply dyiiainic counting tcchnique. Wc iillow o n l y  thc k-itcmscts with al l  its size k - 1 subscts be- ing largc i n  DJ? U d b  to bc counted in DLI. This nicms that tlic candidales ncluslly hcing countcd i n  DTl arc rc- ducctl to only ttic csscnlinl oncs and thcit iirc not tou many of them. Howcvcr, note that it may nccd to pcrforin inorc than one passes ovcr DD. 1r1 ttie ottict' variant algorithm, IDIC-I, we pcrforrn exactly onc scan ovcr Dn to count all the cnndirlate itemscts gencratcrl lrorn rlb. While some cx- cessive cendiilntcs inay lie countcd, tlic nurnhcr of p;isscs over Dl3 is gunrantccd to bc ininitnuin. By using cithcr o f our proposed dgoritbins, it  is cxpcctctl !ha1 Ihc cxcciition timc savcd in scatining Dl3 should bc rnucli larger than thc incrcased tiinc i n  cuunting the extra candidatcs in db.

Note that in thc IDICM algrlrithm, i t  is riot cfficicnt if wc apply ihc original DIC algorithm tlircclly i n  counling DB Tor our incroncnlal coiiiiting prohlcin. Since, for the original DIC dgoritlitii, wc have to start counting only I - itemsets i n  the first. interval and cannot starl counting k- itctnscts until ttic k-tti interval. This litnitalion is not dcsir-     ahlc in our case since we already know the candidntcs to hr: clicckcd in DII. Actually, oncc we havc discovcrcd all po- tcntial LUD c d i d a l c s  auter scanning db, wc can just make onc pass through DB tu chcck the counts of all thosc can- didatcs. One possible drawback for such approach is that a large amoutit of itnncccssary caodidatcs may be counted in DD, causiiig considcrablc overhead. In contrast, 0111' lDIC-M algorilhm will start counting any cantlitlates in DD as soon as i t  is provcn eligible (i.e., it has all its subsets be- ing large in DI3 U &). For cxatnplc, if an 4-ilcmsct has d l four of its six-3 subsets being large in Luo ,  we can start counting it irnmediatcly in thc first interval of D B  insicad or counting it in thc fourth intcrval.

Rcniember that Lhc major tnrgct of the PUP algorithm is to tnininiize the tmmbcr ol' caiidirlnte itcmscts to hc gcnci+- alcd and countctl. This is donc hy priming the candidalcs in cnch pass through rlh and UH. On [tic other hand, oitr two algoritlinis allow cxlra candidail: itctiisets to hc gcncrntcd horn rlb, while the crficicncy is maintaitictt by thc rciiuccd passcs through DLI. UsueIly, ii  lnrgc amount of candidates are generatcd from db and we tiwc to IIC cflicicni wticn we count thosc candidatcs iii DD. Our two variant algoritluns try to deal with this probleni in two dil'l'crcnt ways. Also notc that wc cannot trivially incnrpolatc DIC into Ihc FUI' algoritlini, sincc DIC is not n level-wise algorithm and can- not he used dircctly in plocc of Apriori i t r  FUP,  3.2. Revicw of the DIC nlgorithin  Since o u r  algorithin will tnnkc use of  the DIC algoriihm [Z], wc hs t  givc a bricf r l e s c r i p h ~  of lhc DIC dgorithni.

In tho DIC algorittitn each itcinsct is classilicd as onc of the following categories:  m confirmed-large : an ilcmsci wc liavc fitiislied count- iIig that cxcccds thc support thrcshol~l.

e confirrnctl-sniall ; an itcinset wc have finished count- irig that is hclow lhc support Ihreshold.

I suspected-largc : an itcrnsct wc arc still countiiig ttiat cxccctls ttic support thtcshold,  + suspected-small : an itemsct wc :Lrc stilt counting ttiat is bclow thc support thrcshold.

Ttic DIC algoritlini works as follnws:  1 .  All the I-itcmscls arc marked suspcctcd-small. All other itcinscls arc unmarkcd.

2 .  Rcarl M transactions (whcrc M i s  a predetermined in- tcrval size). For each transaction, iiicrcmcnl thc ro- spcctive counters for the itemsets inarkcd suspcctccl- largo or suspected-small,  3. If n suspected-small iternset has B count that excccds thc support thrcshold, turn it into a suspcc:tc:d-largc.

If any irntnediatc supei-sct of it has all of its subscts as r:onfirmctl-large or suspcctcd-lmgrgc, add a new countcr Fur it and mark it suspccted-small.

4. IF n suspected-small (or suspected-large) iternset has becn countd  through all the transactions, mark it confirmed-small (or confirmed-large) and stop counliiig il.

thc hcginning.

5. 11' wc arc at the cnd of thc transaction lilc, rcwinrl to  6. If any suspected-large or siispcctcd-small ilcmscis rcmnin, go to Step 2.

What DIC does is just to create possible new candidaic itemsets nt every I(rl-trmisxtion interval. Notc that foi, thc Apriori algorithm, new candidatc itcinsets c m  be crcatcd only at the end or i i  pass through the datnbasc.

3.3. The IDIC-M ulgorithm  Wc. proposc a new algorithln, the I I W - M  algorithm, For iiicrcinc~iinl mining bnscd nn dynamic iternset counting.

Lemnin 1 An itcmsct X is in L ~ J I J  only if II is  eilhcr in Lnn or in L d b  or i n  h o h  L u , ~  and LIfc. It m a n s  thnt all large itciiiscls in tlic tipdntcd rlntnbasc, i.c., Lljll must bc iiiclutlcrl in l l , ~ ~  U Ldh,  Prod. If X is neither in  L D ~  nor  L ~ B ,  thcn ,Y.suppo'ol.tnn < s x L, and Xr.~tipport~rb < s x d. There- fore, X.supportnn + X ' . . s u ~ i u r . f , l ~  < s x (U + [ I ) .  Then X is mi in L L ~ J , . ! ~  Thc IDIC-M algoritIim works as rnllnws:  1 .  Scan the dh  Scan lhc incrctnent clb nnct use Il1C to find all itcinscts which arc large in rlh, i.c., L ~ ~ b ,  For cnch X in rccord its support in dlr as X'..wrpprnrt~~~,.

2. Considcr itcmscts in Lijlj For each iteinsct x' in LUB,  if X . s u p p o l . 1 ~ ~ 1  + X'.support,jr, 1 s x (IJ + d), i t  is added tu the set or largc itcniscls in rhc updated databasc DB Udh, i.c., L ~ I I ~ ,  with tlic updated count. Nolc that thc itcrnscts wc cxaniiiic in this step already iiicludcs all ilcmscts in Lnn n Lnb which can be shown In ttic followiiig.

Lcmma 2 All itemsets in L a j ~  n L n b  are cxstnined in Stcp 2 ofthe IDICM algoritliin.

I'rooL lyroin !hc dcscription, wc check e x t i  ilcmscls in LDB if we have its cuuiit X.suppnr.t,lb (Any itemset in Lj,tg we alrcady hnvc i ts cotint X.szippm.t,jn). For all itemsets in LClb we should liavc lhcir counts in db froin     Colisider itcmscts in  L D , ~  - L,la CIicck all iteinscts i n  L ~ J J ~  - -. L u n ,  i.e., thosc itcmcts that arc lnrgc in 110 hut n n i  lergc it1 db and nut already largc in LJB U rlb, by scanning db cincc to updatc thcir counts. For each itcriisct X in Lull - L d b  -. L L ; ~ ,  add it into L~J , ,  with the tipdated count il? X . . w p p o r t ~ ~ ~ ~  + X.siippo~t,.jb 2 s x ( j >  + ti). Note that this slcp is ncccssary as wc did not kcep all the counts for thosc iictnscis which iirc not lnrgc in db.

F,xample 2 Notc that wc only kccp the cniunts o f some small itciiiscts i t t  rllr. Say, in Stcp I ,  wlicn wc are cotititiilg db, wc find itcmets (2,3}, {3,4) and {Z,?} to hc lwgc in L(fb and we start to c~iiint itcrri- set ( ~ ~ 3 ,  d}. IIowcvcr, wc finally find that {2)  3,4) is stnall i n  db. Thcii we will havc tlic count for itctn- sct {2,3,4)  cven il is not large in L d h .  On !hc othcr tiand, if  wc find wic of thc itcniscts {z, 3), {3, d} and {Z, 4) to hc small in rlh, wc will not try to count itcni- set { 2 , 3 , 6 )  and so will tiot tiavc the count I?m itcrnset  Example 3 Assuiiic a dalnbasc Dl3 with sizc D = 100000 is updated with an incrcriicnt db with sizc d = lOUII, whcre 8, is 1%. Let 11, 12, 1, hc tlircc itcmsch in Lull with supports 11 .siqportj~p, = 1005, IAmipportDIJ = 1007 and I n m p p r t , l o  = 1008, respcctivcly. Also, assiiinc [lint alkr  Slcp 2, we lind 13 IO bc a lnrgc itcinsct in rlL with I~ , s i~ppo&,  = 17, whilc 11 nucl 1, nrc sriinl! i n  db. We do not havc the support count I?m . I ,  in dlr but wc havc rhc count for 12 in  d l ~  EIS I~.suppm.t,l~, = 8, which is possihlc for an itctnscl not in I,,lb as wcn froin tlic prcvious cxamplc.

Now, as 1, is in I , ~ I B  but not in I,(//, and L u D ,  so we  ( 2 9 %  4).

have to c o w  it oncc in Siep 3 .  Though 1, is in J,an and not in Ldh, it is ni)t countcd in Stcp 3 since it  is i n  Lljn.  11 ineans that 1, is already hnntllcd in Stcp 2 .

Similarly, 13 is not countcd in Step 3 neither, sincc it  is in hoth LUU and Ad,, and is  already lmdlcd in  Stcp 2.

4.  Consider items& in L d b  - L,JH  In this stcp, wc dctcrminc wliicli itcinscts in Ldb - L I ~ S  - LIJU arc largc in I) B U d b .  We do this by apply- ing a dynamic counting techiiiquc, similar lo the DIC algorithm, tr) Dn. Beforc counting, each k-itcmsct in L d b  - Lun, which tias all its possiblc size (12 - 1)- subscts k i n g  in L ~ J U ,  is added to the candidate sct t n  bc counted, providcd that it is not alrcarly in  Lun.

Note that m y  k-itcmsct ciiii contain at most k subsets of s i x  k ~ 1. All I-ireinscts i n  Lrlb  - L J ~ ] ~  - Lun itre also addctl to tlie candidatc scl. The counts ot? all the candidates are ini1idinxl with their supports in dh. Af- ter thc couiiting iir cach interval is finished, iicw l a ~ ~ g e itetiiscis arc idciitilictl and adtlcd to LIJU with the up- rlatctl suppork Ncw canilidalcs arc gcneratcd froin Lur1 hy il functirin qwiori-gert, rlevcloped hy Agrawnl ct al., which rakes as inpiit tlie sct of all largc (k - 1)- iternscis and rcturiis a supcrsct of thc set of all large k-itwisers [ 11. Tbesc new candidatcs arc then addcd to the cnnditlatc sets il i t  is not al~catly i i i  Lull. Con- tinuc thc proccss unril thew are lit) mow candidates to he counted.

Example 4 Assumc we now have in Ll,n I-itemscts (I}, (2)  arid {3}, 2-itcmscts {1,2}, {2,3) ,  { 5 , 6 } , {li,7) and j5.7). Also, nssume that we have itctii- S C I S { ~ ) ,  [1,3},{1,2,3}and{ii ,6,7}ii iLdb. I i iStep 4, wc start to count  { 1,3} i n  the first intcrvnl bccnusc ithns2 olits I-subsets {I) end 13) in Ltjll. Similarly, wc xiari to count { 5 , 6 , 7 }  sincc its 3 2-subscts { S ,  6).

( f , 7 )  and {5,7} are iii Lun .  ??he I-itenisct (4) is also countcrl in ttic Lit st  intcrviil. If wc lind {1,3} to hc largc after, say, counting thc lirst intcrval, thea wc will start to count {1 ,2 ,  3} in  thc sccoiid inicrval, as all 3 d i t s  3-subscis {I,  2}, {Z, 3) and {1,3} arc now large i n  L ~ J D .

Lcmmn 3 All potcniial Lr,u candidates are cxamincd by thc IDIC-M algorithm.

Proor. After tlic abovc Ibiir stcps, we haw cliccked all ~ h c  ilcinsets in L1,ij n &,, L ~ o  and L d { , .  That IS  all itcm- sets in Llln U J,,dt, tinvc already heen examincd. We havc covcrcd all potcntinl T,r;u candidatcs, by Lcmina 1 .U  Notc that although thc abovc lcininas arc similar to thnsc inlmrluccd i n  [41, thcy givc a more clcar vicw of what CAII bc covcrwl iii cach steps or our algorirhins.

3.4. ExpcriIncntal rcsults For algorithm IDIC-M  Sevcral sets of expcrimonts wcrc conducted to coriiparc tlic 1131CM algorithm with thc FUP algorithm and t t i G  piirc DIC algorilhtn. Note that each data poinl in ttic cxperimen- tal rcsul tr is oblained frwm thc average vnlue ovcr 10 wials.

Thc synthesis data uscd in all the cxperiments arc geiicratcd folluwing ttie tcchniqucs i n  [43.

Table 1.  Parameter table.

Wc use the nota~ion Tx.ty.Drn.dn to deriiitc R dnlabnse cif sixe U = lOOOir i  i s  updated with at1 iiicrcment with size d = 1OOl)u ,  wliilc /TI = x and ] I )  = y. In wir expcIiinctits conipiiring thc IDIC3l nlgoI'ithTl1 iizid the FUP algorithm, D and d wcre chosen in siniilitr way iis hi [4], and IT/ = IO,  We generated (U + d )  transactions by otic raiidoiii scctl.

Then, thc Brsr D trimsaclions arc slorcrl for Db! and the ollrcrs ibr db. Notc that in [lie sccoiid sct ofcxperimcrits in Scctirm 3.4.2,  Di? and db wcrc gcncrated scparntcly wirh different rniidom sccds. For our IDICN algorithm, thc PUP nlgorithm and thc DIC nlgciritliin, fhcir exccution time spccdup nttios over p r c  Apriori algoriitirn arc calculnlcd to cvalualc their perliirtnancc. Nntc thiit piirc Apriori al- gnrithrii hcrc nicans applying thc Apriori nlgorithtri o i~cc 0vc.r tho updalcd r la~basc .  WC first cuiiihinc the original dntiihasc nntl tlic iiicreiiietital dntabasc into ii new iiprlatcd dntalmc. ?'lien, [lie Apriori algorillitri is applictlo11 this IICW updatctl database to ohlain thc ncw hrgc iteniscis wc want.

Spccdup ratio (lata poiiir on (lie curve ApriorifiUIC-M i s ciilciilelcd by dividing ttic cxecution time of the piire Apii- ori algorirhin with Ihc execution tiiiic of  ttic IDIC-M n i p - sittiin.

111 7 4, IL/ = 2000 ;illd N "' 1000.

3.4.1 IDIC-M versus PUP for diffcrent supports  Thc I D I C N  algorilli~n and ttic FUP algorithiti werc lcstcd for different 0,  ranging from 0.01 to 0.05, with t1pdiWd rlorahasc T10.14.D100.d 1 which is similar to the one iiscd in [4]. Tlic intcrval sizes lor counting db niid DU WCIX fixzd nl t 000 and 10000, respcctivcly.

The rcsiilt is slzown in Figurc 1 .  The 1DIC-M iilgorithm clearly has a bettcr exccution tinic specdup ratio for iilt sup- ports tcstcd. Notc that, our algoritlitri has n subsiantinl ;id-  Minimum Support  Figure 1. IDIC-M and FUP for different sup- ports,  vantngc over the FUP algorithm whcn thc niiriirnuni suplmt.1 threshold is sct at at R rclativcly Iiighcr value. Tlic spccrfup ratio orthe IDTCN algorithm is morc tiinn I .5 tiiiies highcr than thc PUP algorithiti when 0, = 0.02. 'I'hc IDIC-M nl- gririthin is inorc [$an 8 litiics hstcr than the pt1r.e Apriori algfirithtil at th is  support rhrcshofd ~ l u c .  Wc can sec Lhiit whcn the Support tbrcshold i s  low, [tic 1DIC.M ;ilgoritIim docs r i o t  IIRVC ;I vcry signiticant nrlvanmgc ovcr [tic 1'UP al- gorithm. Sitice D vcry hrgc nuitihcr ol' candidate itetriscts nre c x p e c ~ t l  to he gcncmtcil from db i n  this citsc, we can oliscrvc ttint 1131C-M ni;ty not hc vcry clricicnr in dealing with those large oiiiouni CII' catididatcs.

3.4.2 IDIC-M vcrsiis FUI' for diffcrcnt incremcntnl sixes  Wc haw donc two scts nT cxpwimculs to camparc tlic pcr- formancc o f  tbc. Il>IC_M algarithm with tlic E'UP a l p r ihrn ror dil'rcrcnt incrcmcntnl s i x ,  d, ranging from IO00 to 500U0, with DU fixcd at 100000, i.c., TIO.I4,1~100,dn.

8, is  lixctl at 0.0 15. For thc firs1 sct orexpcrimcnrs, ttic DD and rib arc gencratcd as tisual using thc snmc mndotn sceil.

Whilc for ttic sccontl sct ofcxpcrimnts,  the DI3 and (!.!I arc gonernlctl scparatcly using dilfcrcnt random sccds.

The rcsults for lirst sct orexpcrimcnts arc shown in Fig- iirc 2. 'I'he IDIC-M illgoritlim outpcrforins thc FUP nlgn- rithtn l o r  dl incrctiiental sizcs testcd. I1 works well cspc- cinlly when ilic incrcincntal sixc is smnll. 'I'hc greatest ad- vantngc of our algorithm ovcr [tic PUP algorithtn was ob- tained when d = 1000, wlierc the speetliip rrtrio of I D C M is iilrout 7.3 and tllc s p d i l p  ratio uf FU1' is ;\bout 4. WC scc tlrc trend that ils thc iticrcniental size continues to in-  thc FUP algorithm rlecrcasc. 'I'tiis i s  diic to the fhct that wlicri thc incrctriciital size is large relalive t o  the origin;II dutabasc sizc, the vaIuc of thc known infrmiation ahout h e  CFC'  IS^, I. (lie pcrformaiiccs of both the 1131C-M algorithm and     8 7  I 7 I I ApriorillDlC-M -  AprioriiFUP ---x---  ApriorillUIC-M I--* - Apriori/FUP  lncremental Slro (thousands)  Figure 2. IDIC-M and FUP for different incre- mental sizes (with the same random seed).

origiiial databasc will be lowcr. This cxperiincnl caii sim- ulatc situiltiuns whcrc the incortiiiig data nrc having similar pnttcrns to the original databasc.

3.4.3 IDIC-M versus DIC for diffcrcnt incrcmental sizes  Expcrirncnts weic done to cotnpilrc the pcrfoitnancc of thc IUICM algorithni with thc DIC algorithm for different in- crcmcntol sixc, 11, ranging horn 10000 to 50000, with LIB fixcd at 50000, i.c., TlO.I4.D50.tln. 0, i s  fixed at 0.015.

Wc are cspccially interestcd in the situation that wbcn the incrcmcntal sizc is relntivc largc comparcd to tlie origi~ial database sizc. Note that what we mean 1)y DIC here is that we applied the DIC algnrilhtii oncc ovcr tlie updated dalahnsc.

0 ,- I  $ 3 n 3 V  U? R 2 t   ' Aprl&l/lOIC-M'- AorioritDlc ---x---  I I I , I 10 20 30 40 60  lncremental Size (thousands)  Figure 4. IDIC-M and DIC for different incre- mental sizes.

I I I 1 5 10 25 50  lncrernerilal Slzo (thousaotla)  Figure 3. IDIC-M and FUP for different incre- mental sizes (with different random seeds).

The resi~lls l'or sccond set of cxpcriinctits arc shown in Figtire 3. Tlic IDIC-M nlgoritlim also ouipcrrorms llic FUI' nlgorihm for nil iiicrcniental sizes teslcd. Our algorithm has R considcrabte advi>ntage ovcr the FUP nlgoritlirii except wlieii thc incrcrncnral size is iicar to 10000. 'I'hc greatest ;ul- vantagc of our algorithm ovcr ttic FlJP algorithtn was also ohlaineil at rl = 1000. Note that thc curvc of the TDIC-M algoii~li~n convcrgcs to n h i g h  v a l w  than thc ciirvc of FLIP docs. Also, note that nur IDIC-M algorithm is much better chm the PUP algolilhtn in this sihiation wbcre thc origi- nal ilatahasc and ttic incrcmcntd datatusc wcrc gcncrntd by diffcrcnt random sccds. Thc situation sitnulatcd by this cxperiinciit does cxist in  rcal lili: when c3ch hatch of iicw incoming d a h  havc a tlifrcrcnt transaction IxitEcni.

l'hc rcsults Tor ttic cxpcriincnts arc shuwii in  Pigum 4.

Although tlic advntitagc i s  tlecrcasing with ihc increincn- tal s i x ,  niir IDIC-M algorithin outpcrfornis the DIC nl- gorirhni for all incrcmentnl sizcs testcd with consider;lblc nmoiin~. The dccrcasing pcrlbrinnncc of IDICM is due t o tlic lcss significanl of known iiiforniation nhout tlic original dalahasr: as incrcincnt hccorucs largcr. Since DYC is not an iticlcmcntsl inining algorihm, i t  can maintain a rdativcly stc idy advanlagc ovcr Ihc Apriori algorithm. Prntn the rc- stilts, wc can concludc that the advantage of our  IDIC-M al- gorithm over thc FUP algoriihtn is no1 only corilrihuted by the iisc of tlyiiarnic couiitiiig tcchniquc, but also ihe wliolc design of our IDIC-M algorithni.

33 .  A variant algorithm: the 1I)IC-I algorithm  We now iiilroducc a variatit algorittim to tlic IDIC-M al- gorilhtn, callcd llic IDIC_l algorilhm. Whilc thci-c niay bc inorc ilian one passcs thrr~iigb Dl3 in Llic IDIC-M algorithm, thc I D l C l  algorithm giiarniitccs a singlc pnss ovcr the DLI.

Thc first three slcps of lhc IDIC-I dgorithtn arc cxactly thc sniiie 21s lhc IDIC-M algorittim. ?'tie Stcp 4 of thc TDIC_I algoritl~in works as follows:  In this stcp, we clemmine which itcmsets in  L r l b - J J ~ j U -     L r l ~  are largc in D R  U dtr. Instcad of applying a dynamic counting techniquc as iii the IDIC-M algorilhni, wc Colin1 al l  thcsc cmditlate itcrnscls in onc pass over DB. After the counting Is finished, new large itemscts are idcntiiicd and addctl to LUD with the updakd supports.

Notc that all the lerntnns i n  thc previous subsection nlso npplics in thc TDIC-I algorithm, which mcitiis that all potcn- tial Lun candidates are exrrtnincd by the IDIC-I nlgorilhm.

3.6. Experimciital results for algorithm InIC-l  Scverat scts of expcrinrcnts were conductcd to coitiparc tlic TDIC-I algorithm with thc FUP algorithm and the pure DIC algorithm. The data uscd i n  this suhscclion for tcst- ing the IDIC-I algorithm is sirniler to that uscrl to tcsI the IDICM algorirhm in Section 3.4.

3.6.1 IDlC-1 versus FUP for different supports  The IDIC-1 algorithm and the FUP algorithm arc tcstctl for dirkretit 8, rangcd from 0.01 to 0.05, with uptfntcd tlalahase 1'10.I4.DIOO.dI which is similar to ibc nnc uscd in 141. l h c intcrval sixcs h r  counting rlb m l  IIU wcrc lixcd ni  1000 2nd 10000, rcspcciivcly.

Figure 5. IDIC-1 and FUP for different sup- ports.

Thc rcsult is shown i n  Figttrc 5. The IDIC-I algorithiri clearly has a bcttcr execution tirnc specitup ratiu for all sup- ports testcd. Note that, our algorithm hns a stcady advan- tage ovcr Lhc FUP algorithm at dirfcrctit rniiiiinuin suppnrt tliIcsholds. l ' l i c  differcnuc hctwecn tlic speedup r d o  of' ttic IDIC-I algorilhni ancl that of the FUP algorithln i s  itiorc tlian 3 for all thc supports lcstcd. Connp:ircd to thc 1DIC-M algorithtn, wc can say that tile IDIC-1 algorithm is ruiich inore cnicicnt in  dcaling with thc largc niirnber o !  canili- date itcmscts gencratcd from dh when thc support threshold is  low. It ntso has R good pcrfnrinancc whcn tlie support ibrestnold is high.

3.6.2 IDIC-1 versus FUP for diffcrent incrcmeiitaf sizes  Wc tiavc dnnc two sets 0 1  experimcnls to comparc the pcr- foi4mancc of Ihc 1131CJ algorithm with thc FUP nlgoritlirn l'or different incrcnietital s i x ,  d, ranging froti) 1000 to 50000, with U B  fixed RI 100000, i.c., TIO.I4.D100.dn. 8, is iixcd at 0.015, For the first set of cxpcrinicnts, h e  D D and db wc gcnernted as u s t [ ~ I  using tha satlie riundom seed.

While for thc secund SCI alcxpcritncnts, the U B  and rllr arc gcncrated scparnlely using dilfcrent random sccds.

I ApriotitlDIC-1 '-1-  Apriori/FUP - - -x---  Incremental S1m (thousands)  Figure 6. IDIC..I and FUP for different incre- mental sizes (with the same random seed).

Thc rcstilts for lirst sct ofcxpcritnctits arc shown in FIg- urc 6. The. II>IC_I algorithin clcarly outpcrt'ortiis thc FUP algorittiin Tor all incrcnicntal siics tcstctt, cspccially whcti thc incrcn~ciital s i x  is sitinli. Thc grcatesi advantagc or our algorithm ovcr thc PUP algorithm was ol>tainctl whcn d = 1000, whcrc llie spccdup ratio of IDIC-I is rn(~rc  than twice Ihc sl~ccrlup ratiu of FUP. Wc also scc the trend tha! a s Ihc iticremcntal sizc contiiiucs to incrcasc, tlic pcrrortnnnccs of' htrth the IDK-l algoriLhin and the 1:UP afgorillm (IC- i: rcasc ,  'The rosults for sccotid sct of cxpcritiicnis arc shown in Figure 7. Tlic 1DIC-I algorithtn also oulperi'ormt; ttic FUP algoritlitn for all incrcmcntiil sizcs tcslcrl. Notc that tlic curve ol' thc IDICLI nlgiiIitIiin again cutivergcs to A higher valuc than t h  curvc olFUP does.

3.6.3 IDIC-1 V C ~ S I I S  DIC for tliffcrcnt incrctncntal sixcs  Expcrimctirs woru done to colnparc the pcrforinnnca of the IL31C-I atgorithm with tlie DIC i~lgoritlun lilt. tlii'ibrctit in- crcincntal size, r l ,  ranging lioin 10000 to 50000, with l?Ll fixed nt 50000, i.c., TIO.I4.D50.dti. 0 ,  is l ixcd at 0.015.

The rcsults Car ttic cxperiincrits arc shown i n  Figure 8 .

SItdar lo thc resulls lor the IDICM algorithm, ttic advan-     Figure 7. IDIC-f and FUP for different incre- mental sizes (with different random seeds).

0 P  2 3 4 n 10 d z   0 I I I I 10 20 30 40 50  Incremental Sire (thousands)  Figure 8. IDtC-t and DIC for different incre- mental sizes.

tage of thc IUIC-I algorithm is decrcasing with the incre- mental sizc. Our IDIC-I algorithm shows significant ad- vantage uvcr the DIC algorithm. Wc ciln havc ttic conclu- sion similar to the IDIC-M algorithm that dynamic ctiunl- iiig tcchnique is not the only coiisc of the efficiency or niir IDIC-I algorithm.

4. Conclusion  In this paper, we propose iiew incrcmcntd updating al- gmilhms, the IDICM and the IDIC-I, 10 handle the prob- lem of incrcmcnlnl association rule mining using dynaiiiic counting tcchnique. We describe in dclaits our new a l p rithins sild illustralcs how dynamic coutiling works effi- ciently in this problcm. We have fiilly imptctnctitcd our algorithms. Gxpcrimcntal results show that oiir ncw dgo- rithrns have supcrior pcdormancc in cornparison with an- other remit  incrcineiilal irprlating algarittini, thc PUP nlgo- rithin. Olhcr than binary or cntcgorical assuciatim rules, the  incremcntid .mining of qm~tttitative :iss(Jciiition rulcs is also wrxth stirdying. As new incoiming data miiy a fkc l  thc data distribution pattern o f  thc rwiginnl database, new rliscrctiza- tion may havc to bc done 011 the incrcmcntcd database.

Hence, Ihc updating of tlie discovcred quantitativc nssoci- iltioti rules will bc morc complicnted. Aiiuther possiblc rc- search lopic Is thc incrcmental mining of association rulcs in a distrihutcd cnvironment.

