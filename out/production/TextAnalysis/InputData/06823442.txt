Distributed FP-ARMH Algorithm in Hadoop Map  Reduce Framework

Abstract? Evolution of Cloud computing technology over the Internet and drastic increase in data size and intensity (Big Data) persuade Map Reduce and distributed file systems like HDFS (Hadoop Distributed File System) as the paradigm of choice for distributed data mining applications. With size and complexity of data growing every day, distributed data mining algorithms has to be designed to handle Big Data in compatible with the latest technology available on distributed computing.

Earlier research activities in data mining comprises, focus on increasing the performance for single task computing algorithms rather than distributed computing which would provide more fast and scalable environment for processing large datasets. Existing algorithms in the field of distributed frequent pattern data mining includes, TPFP-tree, BTP tree, and CARM. But these algorithms suffer from unbalanced workload management among its clusters. In this paper, a novel algorithm, named Association rule mining based on Hadoop (ARMH) has been proposed to utilize the clusters effectively and mining frequent pattern from large databases.

Hadoop distributed framework helps in managing the workload among the clusters. The ARMH was implemented in hadoop using Map Reduce programming paradigm.

Keywords: Data Mining, Distributed Computing, Hadoop, Map Reduce

I.    INTRODUCTION   Cloud Computing is the organized way of expressing different computing concepts which involves constituting large number of computers to use their resources such as computing efficiency, storage capacity and different services  for variety of application. It provides unlimited storage and computing power at low cost. Thus this became the platform for storing and processing large and intense data know as Big Data. Hence cloud computing became the platform for many parallel and distributed data mining applications.

Hadoop is the java based workload management framework which handles data intensive distributed applications.

Hadoop creates clusters on commodity hardware and executed the application using the programming paradigm called Map Reduce. Map Reduce is the programming paradigm for parallel processing of large dataset. Hadoop  Distributed file system and Map Reduce were derived from Google File System and Google Map Reduce.

The main objective of data mining is to discover knowledge from large databases. The discovered knowledge helps in decision making.  Some of the basic data mining topics are association rule mining (Agarwal et al., 1993), sequential pattern mining (Agarwal and Srikanth, 1995), clustering (Ester et al., 1996) and classification (Bayardo., 1997).  The most important and popular topic in data mining is frequent pattern generation.  The basic concept of frequent pattern mining is to discover patterns from database that are more frequent than the specific threshold. As per association rule is defined as X => Y, where X and Y are the set of items.

There are two main primitive algorithms in frequent mining are Apriori algorithm (Agarwal et al., 1993) and Frequent pattern growth approach (Han et al., 2000).  The Apriori ? like method suffers from two main problems. One is main memory has to be large to hold all candidate item sets.

Second it scans the database multiple times. So inorder to overcome this J. Han (2) published his research work introducing a new structure for storing data - Frequent Pattern tree (FP-tree) where transactions are stored in tree structure in a compressed format. Then using FP growth algorithm, frequent item sets has been discovered from databases.

But increase in database size and intensity affects the computation efficiency and takes long time to execute. Also demand for memory was the main concern in case of single task computing because to mine large databases more memory is required to handle large number of item sets especially when the threshold is low. These constraints led the researches to concentrate on Parallel and Distributed computing. ARMH algorithm utilizes the various resources available in different cloud services providers using hadoop distributed framework and discovers the frequent pattern from large databases. The algorithm has the efficiency and scalability to handle the increase in database as long as the resources are available in the cloud.  Cloud resources can be sourced from different service providers instead of depending on singular source. Network latency would be the main concern when sourcing from different providers.



II.   RELATED WORK   There are two research areas which has been concentrated in this section. They are association rule mining and parallel and distributed frequent mining. Also cloud computing and hadoop distributed file system along with programming paradigm Map Reduce were the emerging trends in parallel and distributed computing.

A.  Association rule mining   The famous association rule mining algorithm apart from Apriori (1) is FP- Growth (2). FP-Growth was proposed by J. Han (2) is a tree data structure called Frequent Pattern tree and algorithm for mining, FP-Growth. The algorithm scans the data base twice to form FP-tree. The first scan on the database gets the support count of each item. Based on this, header table is constructed containing the name of items, support count and node-links of the first node referencing to the node in the Frequent Pattern tree having the exact item name.  The item sets present in the header table are sorted in higher to lower order. During the second database scan, the item sets in each transaction are processed in header table order i.e. arranged in decreasing  order of support count.  In each transaction, item not in header table are removed and remaining is processed in header table order. These items are inserted into Frequent Pattern tree. The Frequent Pattern tree starts from root node labeled as empty (null), item-prefix set of sub trees and header table. The node of the Frequent Pattern tree includes item-name, no of occurrences (support count) and node- reference. In order to insert a transaction A, in FP-tree, T, we have to check whether T has a same child n, i.e. n item- name is same as the item set name of the first occurred element of A. If a node is present the count of n is incremented by one. If the node is not available, create a new node, containing the item name exactly as n. The no of occurrences of new node is set to one and parent link is linked with T, also its node link is linked to other nodes containing similar item name. The above procedure is repeated until all elements in A is inserted into Frequent Pattern tree. Once Frequent Pattern tree is constructed, Frequent Pattern Growth algorithm is employed to construct conditional FP tree. Conditional pattern base is retrieved from conditional Frequent Pattern tree by repeating the procedure in recursive manner. Using Frequent Pattern tree and Conditional pattern base required frequent patterns are mined.  The fig 1 below shows the FP-tree generation for the sample transactions.

B. Distributed and Parallel Association rule mining.

To increase the performance of association rule mining, researchers have tried to parallelize the mining process over more than one machine or processer.

In [14], the author has experimented Apriori-like method over multiple processors. They have implemented the proposed algorithm over processors of count 128 in order to obtain parallelized computing for improvement in reliability and efficiency. Intelligent data distribution (IDD) has been proposed to take care of the data distribution among multiple processors and algorithm named hybrid distribution (HD) to manage the load balance. In [13], author has proposed an algorithm called parallel FP-tree (PFP-tree), in this method author has implemented the PFP on message passing multiprocessor system. The database is divided into multiple sub sets based on the number of processors. Each processor builds their own FP-tree by exchanging only the necessary information among them.

But these multiprocessors approach slowed down because of expense of the machines. There are several approaches proposed in the field on grid computing ( 3, 4, 5, 6, 7) some based on clusters (8,9,10)  and some based on share nothing parallel machines (11) to parallelize the mining process on large databases. During the mining operation data transmission among nodes involves four a parallel  environment. There are several demons that performs the operation in hadoop.

Name node, Secondary  Name node,  Datanode,  Job tracker and Task tracker. Namenode is the master node that controls the whole hadoop cluster. Data node is the slave node in which  the data would be stored and processed. Master node contains  metadata  information. All  the information  about the  cluster  would  be stored in namenode.  Datanode which stores the data would send the information  to the namenode at  specific  interval  reporting  its  status  with respect to the type of  data stored, amount of  space consumed ,  operating functionality etc. Fig 2 shows the basic architecture diagram of hadoop distributed file system.  A Job  tracker accepts the job  from  the client and executes them via Tasktracker. The job obtained  from  the  client  is divided and passed to Task tracker  for  execution  based  on  its  processing  limit,  slot availability  and  data  availability. The  Jobtracker  has  the responsibility of  maintaining  the  software specification to the slave node, scheduling the task tracker and monitoring it and recovery  process  during the failure.It also provides the statistics  and  diagonistic   information  to client.  The task- tracker executes the job as  separated java process and as the whole  the  result is collected  and  delivered to the client by Job tracker.

layers, the  transport layer,  networking layer,  physical layer & data link layer, and the combination of  session layer , presentation layer  and application layer. Each of these layers uses its own protocols. The information packing from source and unpacking at the target end leads to increase in transmission expense. Also the transmission on physical network is time consuming especially when dealing with Big Data.

C. Cloud Computing  Cloud computing is the trending technology that have been used in many fields like web technology, biology, finance data analysis etc.,  It is a set of  network enabled service, which provides scalability, high performance, Quality of service, inexpensive computing power on demand in a simple and pervasive way. Conceptually, cloud provides computing platform or IT infrastructure to the users in which desired application can be executed. For Hadoop to be implemented in cloud, Platform as a service model has to be provided by the cloud providers. PAAS provides the computing platform in which hadoop distributed file system can be created and desired algorithm can be implemented using Map Reduce programming model.

D. Hadoop and Map Reduce  Hadoop Distributed File System is an open source software framework to  process  high  intensive  data applications in    Fig 2. Hadoop Distributed File System Architecture    The programming model used in Hadoop is Map Reduce is inducted from functional programming. The programming model implies two functional primitives. 1) Map 2) Reduce.

The Map Reduce functioning is based on (Key, Value) pairs. The processing of Map Reduce (i.e. input and output) would be based on key and value pairs.

The two primitives Map and Reduce has the following signature:   [ ]( ) [ ]( ) [ ]( )v3k3,v2k2,:reduce,v2k2,v1)(k1,:map ??  The map function operates on input (k1,v1)  pair and produces the intermediate result (k2,v2). This (k2,v2) form the input to the reduce task  and finally output would be produce as another key and value pair ( k3,v3) . The Fig 3 shows the basic data flow diagram of Map Reduce programming model.

Fig 3. Basic Data Flow Diagram of Map Reduce

III. EXISTING METHOD    In (12), the author proposed an algorithm called CARM (Cloud Based Association Rule Mining), contains two important algorithms, High Workability Distributed FP- Mine (HD-Mining) and Fast Distributed FP-Mine (FD- Mining). In CARM, the author did not implement database dividing approach.  The main purpose of High Workability Distributed Mine algorithm increases the utilization of cloud virtual nodes for mining the database that contains large number of frequent pattern mining. The main limitation of conventional algorithms to mine large database is the limitation of memory availability at the single computer.

High Workability Distributed Mine would combine all existing memory present in different cloud nodes to mine the large database to find the frequent pattern. Since cloud computing technology has the capability to provide the required computation power and unlimited storage facility.

The another algorithm Fast Distributed FP-Mine focused on  quick mining of association rules by utilizing the memory available at the cloud virtual nodes. During execution FD- Mine would be invoked first since it occupied large memory and running performance is specified at high priority. But if Fast Distributed FP-Mine fails due to lack of memory (i.e. ) not able to achieve the task, then HD-Mine would be invoked. Finally algorithm would return frequent pattern.

Since HD-Mine is the Frequent Pattern based algorithm, workload distribution to different virtual nodes of cloud is based on the header items in header FP table. The conditional Frequent Pattern tree is mined from conditional FP pattern base. The mining of conditional FP-tree to obtain the frequent pattern would be done on separate node based on its availability.

The conditional FP-tree is compressed and sent to other nodes to avoid the amount of data transmitted in the network. The main difference between FD-Mine and HD- Mine is that how the distribution of header items in header table is made among the node. In FD-Mine to minimize the amount of data transmission the FP-tree is duplicated in each idle nodes. This minimize the amount of data transmitted between the node which makes the mining process faster than HD-mine.  But there is no proper mechanism to manage the workload among the nodes. This becomes the main drawback since the nodes would take different execution time to mine the database as the result some nodes would be very busy and other nodes would be free based on the execution time.



IV. PROPOSED  METHOD    In parallel and distributed computing environment, efficient association rule mining involves efficient and scalable design of algorithm and less transportation of data in the available network.  Hadoop distributed file system offers an efficient and scalable workload management environment in which instead of data being transmitted to the computation section, the computation is performed in the location of the data itself. In this way no data is transmitted among the network which reduces the network latency drastically. Also only the information required for the computation is transmitted in the network and management of the nodes in the distributed environment is done effectively.

A. Frequent Pattern Tree Storage Model  Even though Frequent Pattern tree is the condensed form of stored data, Frequent Pattern tree would be large when threshold of support is less especially in large databases. For example refer Fig 4.  The FP-tree is constructed for the transaction specified in the figure. The minimum support count is set as 2. The transaction in the table is already arranged as per the maximum support threshold. Once the FP-tree is constructed, normally there would be many     parameters associated with the FP-tree like item prefix sub- tree as sub node of the root node and the frequent item header FP table. Each field (node) in item prefix sub-tree has three fields, namely item-name, count and node-link.

Fig 4 Frequent Pattern tree for Support Threshold 2  The item-name registers which item the node represents, count has the transaction occurrences represented by portion of trace reaching this node and node-link links to the subsequently node in the Frequent Pattern tree carrying the similar item set name, or null if there is none. Likewise for frequent item header table has two fields, one is item name and another is head of node-link which points to the initial occurring node of the Frequent Pattern tree carrying the item set name.

The additional information present in FP-tree helps in mining process, but in parallel and large environment these additional information become the burden during processing and change of information among the nodes. So in this paper an array data structure has been proposed to hold the FP-tree structure. Representing the tree in this array format would help us to store only minimum information required for frequent mining process, also transmission and handling of data among different nodes in hadoop would also be so efficient.  The data structure is represented as below  Node = {label, count, index of parent node}   Combination of all the nodes in the array would provide the required FP-tree.

Fig 5 Array Data Structure to corresponding FP-tree.

The Fig 5 shows the array data structure for the FP-tree mentioned in Fig 4.

B. Proposed Algorithm for Parallel and Distributed Mining  The main challenge in designing an algorithm based on FP- tree is the way of handling the large number of frequent patterns. The proposed ARMH algorithm is simple and flexible so that it can be easily implemented using the Map Reduce programming model. In Map Reduce, the operation on the map function would be executed in parallel across the database. The large database would be divided and stored in HDFS. On each of the subsets of database, the map function would operate at the same time and produces the intermediate result.

Fig 5 Prefix Path Sub-trees ending in specific item sets.

Fig 6 Conditional FP-tree for the item set ?e?.

Algorithm:  Name : ARMH Input : A transaction database and Minimum Threshold Output:Frequent patterns  // Load the database into HDFS.

//Constructed from Distributed database in HDFS.

1.   Array-FP tree = getFP-tree (Transaction Database)  // Prefix Path Subtree from Distributed Array?FP tree.

2.  Prefix Path Subtree = getSubtree(Array-FP tree).

//Construction of Frequent pattern  3. Frequent Pattern = getFP(Prefix Path Subtree)  //Conditional FP tree from Organized Prefix Path Subtree  for each frequent items.

3.1 Conditional FP-tree=getCFP( Prefix Path Subtree)  //Construction of Frequent Pattern from CFP tree.

3.2 Frequent pattern=getPattern(Conditional FP-tree)     The large database has to be stored in hadoop distributed file system. The mining of frequent pattern involved three map-reduce jobs back to back.  In the first job, the map- reduce portion takes the raw database as input and ends up in producing the FP-tree in array data structure format.

Once the FP-array data structure is available it becomes the input for the second map reduce job. The second map- reduce job reads the array data structure as input and produces condition pattern base as output for all the item sets presents array data structure.  The third map reduce job would take the condition pattern base as input and produce frequent pattern corresponding to the item set to which the conditional pattern base has been created.

In third map-reduce program, the map job would produce the conditional FP-tree for conditional pattern base and reduce job would produce frequent pattern from the  corresponding conditional FP-tree. The conditional FP-tree is also stored in array data structure.  The Fig 5 shows the individual trees for each item sets present in the array data structure (i.e) Prefix Path Sub-trees ending in specific item sets.  From the prefix path sub-tree ending in specific item sets conditional FP-tree for that specific item sets would be calculated. The Fig 6 show the conditional FP-tree for the item set ?e? present array data structure.



V. EXPERIMENTAL RESULTS    To calculate the performance of ARMH algorithm, data set was generated using IBM?s Quest synthetic data generator.

The experiment was computed on multi node hadoop cluster and configuration of individual nodes with 320GB of disk storage, Intel Xeon e5620 2.4GHz Quad core CPU and 4 GB of RAM.

To compare the performance of ARMH algorithm, we selected BTP-tree. BTP-tree and Tidset based Parallel FP- tree are the most efficient algorithms that can perform parallel computing in Grid systems. Both algorithms adopt the strategy on database divide and conquer approach.  But BTP-tree is faster than TPFP-tree. CARM algorithm doesn?t divide the database but it distributes the database in cloud environment among the nodes. The Fig 7 shows the comparison of two algorithms ? BTP-tree and ARMH between Execution time (sec) and Number of transaction.

Fig 7 Execution time (sec) Vs Number of Transaction  The BTP-tree, TPFP-tree and CARM works well for medium size databases. But as the database size increases drastically the performance of above three algorithm increases exponentially. But in case of ARMH which is designed in compatible with Map Reduce paradigm shows greater performance and efficiency. In BTP-tree and TPFP- tree which is based on construction of FP-tree individually for the divided databases and combining the results involves lot of information has to be shared among the nodes and performance suffers because the design is not based on Map Reduce paradigm.

Fig 8 Execution Time (sec) Vs Number of Nodes  Fig 8 shows the graph between Execution time and Number of Nodes keeping the fixed transaction of size 1000k. The BTP-tree performance did not elevate as the number of nodes increases i.e execution time becomes saturated. This is because BTP-tree has to communicate between the nodes for the construction of FP-tree which increase the communication overhead as the node increases. On the other hand, ARMH algorithm execution time decreases as the number of nodes increases thus increasing the performance.



VI. CONCLUSION  In this paper we proposed ARMH (Association Rule Mining on Hadoop) algorithm which utilizes the hadoop cluster effectively to obtain the frequent pattern from large databases. The database is divided and stored in hadoop cluster and operation on it performed using map reduce programming model. Other existing algorithms like BTP- tree and TPFP-tree uses the divide and conquer technique but workload balancing is not done effectively. Using hadoop workload among the cluster nodes are done effectively. Even though ARMH algorithm requires exchange of data among the nodes but constructing three steps of map reduce operation and presence of intermediate memory makes the process simple and effective. Both the models were implemented in hadoop using map reduce model to test the performance. Based on the results ARMH is effective than BTP-tree in terms of scalability and performance.

