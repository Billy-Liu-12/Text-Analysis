Nonlinear Hebbian Rule: A Statistical Interpretation

Abstract Recently, the extension of Hebbian learning  to nonlinear units has received increased attention.

Some sucmsful applications of this learning rule have been reported as well; however, a hdamental understanding of the capability of this learning rule is still lacking. In thls paper, we pursue a better understanding of what the network is actually doing by exploring the statistical characteristics of the criterion function and interpreting the nonlinear unit as a m i l i t y  integral transformation. To improve the capQl>llity of the nonlinear units, data preprocessing is suggested. A better data preprocessing leads to the development of a hm layer network which consists of linear units in the first layer and nonlinear units in the second layer.

The linear units capture and filter the linear aspect of the data and the nonlinear units discover the nonlinear effects, such as clustering and other general nonlinear associations among the variables.

Several potential applications are demonstrated through the simulation results given throughout this paper.

1. Introduction The objective of unsupervised learning is to  discover features or regularities in a set of training data without teacher signals. Often, a learning rule is designed to transform a set of unlabeled vector data {x' E R"; i = 1, 2, ..., m} into another (lower) dimensional set to gain insight and understanding about important features in the data without biasing the results by imposing preconceived structures. If the information in the data is adequately captured by linear relations among the variables, a learning rule may be developed based on covariance (correlation) among the variables. For example, one-layer linear feed?orward neural networks employing Hebbian- type learning have been proposed to project data onto the directions of maximum variances, known as principal components (Qa, 1982; see also Hassoun et al., 1993). However, certain topological relationships among the variables may not be  adequately captured by such linear relations (Softky and Kammen, 1991; Taylor and Coombes, 1993).

Examples of problems which require the discernment of topological relationships in the input data are to handle this class of problems, commonly found in pattern recognition, clustering, and filtering applications. Oja et al. (1991) extended the Hebbian learning to nonlinear units. This extension has drawn increased attention (Softky and Kammen, 1991; Shapuo and Rugel-Bennett, 1992; Taylor and Coombes, 1993; Oja and Karhunen, 1993) and applications (Oja et. al., 1991; Karhunen and Joutsensalo, 1993; Oja and Karhunen, 1993); however, it remains theoretically unclear what the network is actually doing.

In this paper, we explore the statistical characteristics of this learning rule using the probability integral interpretation. The results reveal a better understandmg of the processing capabilities of the network and its potential applications. Our findings provide analytical justification to the previously reported applications of using nonlinear units for extracting sinusoidal signals buried in noise. As suspected by previous works, we show that the nonlinear units are indeed capable of capturing nonlinear relationshp among the input variables.

For some applications, such as clustering, data preprocessing is necessary to either scale the data or remove linear structures in the input data. This preprocessing suggests the use of a tsamlayer network which is capable of extracting both linear and nonlinear structures in the data.

2. Hebbian Learning in Nonlinear Units As mentioned above, Qa et al. (1991)  generalized the stable form of Hebb's learning rule to nonlinear units. One of their learning rules for a single unit has the following form  Aw=q, [I-wwT]L(y)x (1) where: q k  W : wight vector.

: learning rate at step k.

X : input pattern.

0-7803-1901-X/94 $4.00 01994 IEEE 1247    y = wT x : projection of the input patterns onto the  L(y) : learningsignal.

weight vector.

The L(y) x term is the realization of a nonlinear version of Hebb's rule and the w wT L(y) x term serves as the stabilizer of Hebb's rule. The learning rule in (1) may be considered as a constrained w e n t  ascent algorithm by letting  V J =  L ( Y ) X  (2) Depending upon the nonlinearity involved in the learning signal, a criterion function for (1) may be synthesized For example, if the learning signal is assumed as L(y) = tanh(y) [l - tanhv)], then the appropriate criterion function is J = tanh*(y).

Noticing that if the output of the nonlinear unit is z = tanhb), the learning rule in (1) may be perceived as a w e n t  algorithm to solve an optimization ("izat ion) problem with the ob~ective function being the variance of the output (Oja et al., 1991).

Consider the outputs of a unit, z, and assume that they are governed by a probability density function Hz). Here, the criterion function maximized by Hebb's rule may be written as  --oo  subjectto WT w = l (3)  Applying constrained w e n t  ascent [as in (l)] with J as in (3) and using the chain rule leads to the following learning rule  (4)  where the constant term has been absorbed into qu The stochastic approximation version of (4) may be written as  Aw= qk (I- W wT)Z---X dz dY  Note that the learning signal in ( 5 )  is given by  dz ~ ( y ) = z - .  xz is a linear function ofy, say z = y , dY  dz then - = 1 and the learning rule is reduced to the  simple Hebbian rule for a linear unit.

dY  For the case of linear units, the @ective function in (3) has an obvious interpretation, i.e., projection of the input patterns in the directions of maximum variances, known as the principal components. The same cfiterion function applied to nonlinear units, on the other hand, does not have an apparent meaning. Note that both h e a r  and nonlinear learning rules are seeking a set of weight parameters such that the outputs of the unit have the largest variance. The nonlinear unit, however, constraints the output to remain within a bounded range, e.g. z = tanh(y) limits the output within [-1, 11. The restriction of the nonlinear unit outputs si@cantly distinguishes nonlinear units from their linear counterparts and dramatically affects the mechanism of variance maximization. For linear units, the learning rule pushes the weight vector to favor components ofthe input vectors (or their linear combinations) having the largest variance regardless of the shape of the distribution function, p(z). On the ather hand, due to the restriction of the nonlinear outputs, nonlinear learning will produce outputs with a U-shape distribution in order to maximize the output variance. Thus, the variance maximization obJective in the criterion function drives the learning rule to prefer a wight vector w such that the output z is distributed near the extremes -1 and 1. As an example, suppose z follows a standard beta distribution (the beta distribution is chosen because it has various shapes depending on its parameters)  where B(p, q) is the beta function  The mean and variance of distribution (Johnson and Kotz,  E[z]=- P P+4  var(z)= P+4 (P+1I2 (p+q+1)  (7)  this standard beta 1970) are given as  (9)  Consider three beta distributions, as shown in Figure 1, with the following parameters: (1) p = q = 3, (2) p = q = 1, and (3) p = q = 0.5. The mean of each of the     3 distributions is equal to 0.5, where the variance are equal to 0.0536,O. 1667, and 0.2222, respe&vely.

in a uniform distribution within the interval [0, 11 ( R o w ,  1984). For example, consider the case ofy having a standard normal distribution given by,  0 0.2 0.4 0.6 0.1 1  Figure 1. Beta distribution with the following parameters: (1)p = q = 3, (2) p = q = 1, and (3) p = q = 0.5.

Note that the U-shape distribution, p = q = 0.5, has the largest variance compare to the others. The criterion function in (3) forces the learning rules in (4) and ( 5 )  to prefer t h s  U-shape distribution.

3. Probability Integral Transformation and Nonlinear Units  The nonlinear units, in addition to restricting the output to withm a certain range, also transform the probability density of the weighted sum y = wT x into other probability density functions.

The probability density function of the output, z, is determined by the probability density function of the input vector, the weight vector, and the shape of the activation function. In the following discussion we show how the shapes of activation functions govern the behavior of the learning rule.

Consider a single unit with the following output relation  where w) is a nonlinear function bounded within [0, 11. Clearly, z takes on values in the interval -1 I z I 1. If a) is chosen as a monotonic increasing function on [0, 11, then w) may be interpreted as a cumulative (probability integral) distribution function. Hence, the output of a nonlinear unit in (10) may be perceived as a linear projection transformation (with projection vector w) of a multivariate random variable x into a univariate random variable y and followed by a probability integral transformation of y into z. If y is randomly distributed with probability density function p(y) and cumulative distribution function w), then the probability integral transformation I)@) o f y  results  the probability integral transformation ofy  results in z being umformly distributed in [-1, 11. On the other hand, i f y  is not normally distributed, then z will not follow a uniform distribution.

Consider input vectors x E R" where each component is generated by a different probability distribution. The restriction on the nonlinear output causes the learning rule (4) and (5 ) ,  in order to maximize the output variance, to seek a weight vector, w, such that p(z) has a U-shape distribution (deviates away fiom a uniform distribution). The learning rules will suppress the components of x (or their linear combinations) that follow a normal distribution (because they generate a uniformly distributed z) and intensify those which depart from normality and produce U-shape distribution of z. The nonlinear activation function (the probability integral transformation) together with w play the role of shaping the distribution of z. On the contrary, the linear neuron does not involve a probability integral transformation to change the structure of output distributions. Hence, whatever linear combination of components of x that produces the largest variance is preferable by the linear learning. Shapiro and Prugel-Bennett (1992) also observed the important role of the shape of the activation function.

To illustrate the sigtllficance of the type of activation function used, consider input vectors consisting of 2 components, a pure sinusoidal x1 = sin@); where t is uniformly distributed within [0, 2x1 and a gaussian random component xz with zero mean and unit variance. The probability density and the cumulative distribution functions of x2 is represented by Equations (1 1) and (12), respectively.

The probability distribution function of x1 can be easily shown ( R o w ,  1984) to be     (13)  g (Xl)  = - Z J q -  This distribution is known as the arc-sine distribution (Johnson and Kotz, 1970), and the corresponding cumulative distribution function is given by  1 . _ I#( xl)= - sin '( x, ) + 0.5  x The shape of the probability density functions of x1 and x2 are shown in Figure 2a. Accordingly, the activation functions using (12) and (14) are shown in Figure 2b.

0.6 h J  0.4  0.2  we wish to extract x1 from the input signal. In this case, x2 may be suppressed by transforming it into a uniform distribution, and xt may be intensified into a U-shape distribution using the probability integral transformation in (12). To avoid the integratton calculation, an approximation to the cumulative normal distribution may be obtained by using a cumulative logistic distribution (Johnson and Kotz, 1970), z = tanhgy). For simplicity we select a logistic distribution with f3 = 1. For a better approximation, f3 may be adjusted such that the difference from cumulative normal distribution is less than one percent (see Johnson and Kotz, 1970).

Since the two components of each input vector have different scales (variances), a preprocessing calculation is necessary using their standard  xi = x i  deviations, x', =-, where cy is the standard  deviation of xi. The result of the training is shown in Figure 3a.

= I  1  2 1 0 1 2 3  X  Figure 2a. Probability density function of x1 from Equation (13) and x2 from Equation (1 1).

-3   -  20 40 (0 10 100  3 2 1 0 1 2 3 X  Figure 2b. Activation functions constructed from probability density functions of x1 and x2 from Equation (14) and ( 12), respectively.

Depending on which component of x is interesting, an activation function can be selected to enhance (or suppress) either x1 or x2. If (12) is chosen as the activation function then x1 and x2 produces z with a U-shape distribution and a umform distribution within [-1, 11, respectively. Similarly, the opposite effect occurs with the selection of (14) as the activation function. To demonstrate this behavior, a set of 100 training samples is generated and a nonlinear unit is trained using the learning rule in ( 5 )  with a constant learning rate q = 0.01. Suppose  Figure 3a. The result of nonlinear unit training using the activation function in (12) to extract the sinusoidal signal.

Similarly, to extract x2 we can use a probability integral transformation in (14). Figure 3b shows that the nonlinear unit is capable of extracting the gaussian component.

3 ,  I  3 -  U 20 40 (0 to 100  Figure 3b. The result of nonlinear unit training using activation function in (14) to extract gaussian signal.

This result agrees with some early applications for sinusoidal signal extraction ( q a  et al., 1991; Karhunen and Joutsensalo, 1992; Qa and Karhunen, 1993). In these applications, the inputs to the network are L successive lags of samples x(k) = [x(k), x(k+l), ..., 4k+L-1)IT. Sigmoidal type functions %re chosen for the activation functions.

Similar to the previous examples, the sigmoidal signal drives the learning rule to find projection vectors that suppress the gaussian or near gaussian signals and enhance the U-shape distributed signals, i.e. the sinusoidal signals. Note that either the input data or the activation functions need to be scaled to produce the desired results.

4. Clustering Applications and Linear PCA Preprocessing  The fad that Hebbian learning in a saturating nonlinear unit tends to yield an output clustered at saturation extremes leads to a natural application for data clustering. To demonstrate the capalnlity of nonlinear units for data clustering, forty samples of 2-Qmensional data are generated as shown in Figure 4. The data are generated from uniform distributions with 1 I x2 I 2 for both classes and 0 I x1 I 0.5 and 0.5 I x, I 1 for class I and class 11, respectively.

c 2 X 0 X  t o Class II  0 0.2 0.4 0.6 0.8 1  X1  Figure 4. Forty samples of 2-dimensional data from 2 classes.

The data represent two class populations. In this problem we are interested in finding a projection that indicates a clear separation betwen the two classes.

We should not use the class labeling in the training, but it is of course interesting to compare that labeling with any structure found by Hebbian learning in a nonlinear unit. To produce more than 1 cluster, the learning should move away from a projection that produce a unimodal (or gaussian-   type) pattern by applying a cumulative normal distribution as the activation function. Data clustering often has little to do with any linear (covariance) structure in the data By preprocessing the data with a linear PCA network this linear structure may be removed. The idea is to carry out a linear transformation--rotation, location, and scale change--to eliminate all the location, scale and correlational structures. This preprocessing leads to a -layer network architecture (see Figure 5 ) where the first layer is a linear PCA network, e.g.

Sanger's network (Sanger, 1989), which removes linear structure in the data and the second layer is a nonlinear unit which is responsible for extracting nonlinear structures. The variance scaling in between the two layers is essential to assure that the inputs to the nonlinear unit has the same scale. The linear layer and the variance scaling implement the following transformation:  v=S-; U(x-E[x]) (15) where U is a matrix composed of eigenvectors of the covariance matrix of the input vectors, and S is the corresponding diagonal matrix of eigenvalues.

'igure 5. A two-layer network with linear PC L units in the hidden layer and a nonlinear PCA unit in the output layer.

The learning rule in (5) ,  with a constant learning rate q = 0.01, is used to train the nonlinear unit. Agam, for a fast computation an activation function z = tanhw) is utilized to approximate the cumulative normal distribution function. The initial value of the weight vector, w, of the nonlinear unit is set equal to the might vector of the first principal component of the linear PCA to provide nonlinear learning with a good starting point. The projection plots of the first and second principal components  (o,=u:x;i=1,2) of the linear PCA outputs are shown in Figure 6a and 6b, respectively. Notice that linear PCA is distracted by components with large variances and fads to provide genuine clusters.

Figure 6c shows the plot of the outputs of the nonlinear unit, z = tanh(wT v). The nonlinear unit is capable of learning a projection vector, w, that provides good data clustering. For comparison, Figure 6d shows the plot of the outputs of the nonlinear unit with variance scaling but without the  linear PCA preprocessing, z = tanh(w~ i); XI, = 3.

The result demonstrates the necessity of having the linear network removes all linear structure More feeding the data into nonlinear units.

Q i  y xm, -2 -1  p( x w  up@, -2 -1 0 1 2  -1 -0.5 0 0.5 1  , w m p m q m ,  (d) -1 -0.5 0 0.5 1  Figure 6. Data clustering using projections to (a) the first principal component of the linear PCA network, (b) the second principal component of the linear PCA network, (c) the first principal component of the nonlinear unit with a linear PCA preprocessing, and (d) the first principal component of the nonlinear unit without a linear PCA preprocessing  5. Conclusion We have demonstrated the behavior of  nonlinear units by employing a probability integral transformation interpretation of the unit activation function. This approach leads to a better understanding of the learning caphlities of the nonlinear units. Two-layer networks with linear units in the hidden layer are proposed to enhance the caplnlity of nonlinear units. The hidden layer extracts all linear structure in the input data and allows the nonlinear units to exclusively manipulate the nonlinear information. The approach also suggests and justifies potential applications of Hebbian learning in nonlinear units for signal extraction and data clustering.

