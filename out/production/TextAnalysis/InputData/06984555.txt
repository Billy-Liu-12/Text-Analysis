An Integer Linear Programming Scheme to Sanitize Sensitive Frequent Itemsets

Abstract?In this paper, we propose a novel approach to address the frequent itemset hiding problem, by formulating it as an integer linear program (ILP). The solution of the ILP points out the transactions that need to be sanitized in order to achieve the hiding of the sensitive frequent itemsets, while the impact on other non-sensitive itemsets is minimized. We present a novel heuristic approach to calculate the coefficients of the objective function of the ILP, while at the same time we minimize the side effects introduced by the hiding process. We also propose a sanitization algorithm that performs the hiding on the selected transactions. Finally, we evaluate the proposed method on real datasets and we compare the results of the newly proposed method with those of other state of the art approaches.

Keywords-Privacy preserving data mining, frequent sensitive itemset hiding, integer linear programming.



I. INTRODUCTION  Privacy preserving data mining (PPDM) [1], [2] is the scientific field that investigates techniques to preserve the privacy of data and patterns. A classification of PPDM tech- niques can be found in [3]. Knowledge hiding [4], a subfield of PPDM, aims at preserving the sensitive patterns included in the data that are going to be published. Knowledge hiding is usually obtained by a process known in the literature as the data sanitization process [5]. As a result of this process, sensitive knowledge can no longer be inferred, while the utility of the database is maintained as much as possible.

We focus on knowledge hiding in the context of frequent itemset mining [6]. The set of frequent itemsets are usually sought during the first phase in a significant number of data mining techniques. Therefore, if the frequent itemsets associated with sensitive information are hidden, the loss of privacy of this sensitive information is prevented.

The technique that we propose falls in the category of frequent itemset hiding techniques that are based on the  creation of a linear program. The solution of the linear program determines the changes that must be made in the database, so as to accomplish the hiding of the sensitive frequent itemsets. In the work of Kagklis et al. [7] it is presented a taxonomy of linear programming techniques used for hiding.

The rest of the paper is organized as follows. Section II provides an overview of the related work. In Section III, we state the specific problem and give all the necessary background. In Section IV, we present the ILP formulation, the heuristic for calculating the coefficients, and the pro- posed sanitization method. In Section V, we demonstrate the experimental results of the proposed methods, in comparison with previous related works. Finally, Section VI concludes our work.



II. RELATED WORK  Clifton and Marks [8] are among the first researchers who deal with privacy preservation issues in the field of data mining and propose data-obscure techniques in order to prevent sensitive patterns from being discovered.

Later, Atallah et al. [9] make two concrete and significant contributions. Firstly, they prove that the optimal solution of the frequent itemset hiding problem is NP-hard and secondly they propose a greedy heuristic algorithm that turns 1?s into 0?s in the database in order to hide the sensitive patterns.

Sun and Yu [10] introduce a greedy border-based ap- proach for hiding sensitive frequent itemsets. They propose a heuristic algorithm that takes advantage of the housekeeping between maximally non-sensitive and minimally sensitive frequent itemsets, giving an accurate and efficient hiding solution. Moustakides et al. [11] rely on the border revision theory presented in [10] to build an algorithm that imple- ments the ?maxmin? criterion. Basically, the algorithm hides   DOI    DOI    DOI 10.1109/ICTAI.2014.119    DOI 10.1109/ICTAI.2014.119    DOI 10.1109/ICTAI.2014.119    DOI 10.1109/ICTAI.2014.119    DOI 10.1109/ICTAI.2014.119    DOI 10.1109/ICTAI.2014.119    DOI 10.1109/ICTAI.2014.119     sensitive itemsets by eliminating items in such a way that the side effects to the minimum support itemsets in the positive border are minimized. The results are of similar accuracy, but they are produced in a much more efficient way than the results in the original border-based algorithm.

Menon et al. [12] were the first to introduce an integer linear programming formulation of the frequent itemset hiding problem. The solution of the ILP indicates which transactions need to be sanitized in order to conceal the sensitive patterns. The sanitization process is executed sepa- rately and independently of the linear programming solution.



III. DEFINITIONS AND PROBLEM DESCRIPTION  A. Definitions  Let I = {i1, i2, ..., in} be a set of items. Any nonempty subset of I , X ? I , is called an itemset.

An itemset consisting of k items is called a k-itemset.

Let D = {T1, T2, . . . , Tm} be a set of transactions, where each transaction Ti is considered to be an itemset. A transaction Ti contains an itemset X , if and only if X ? Ti.

The support count of an itemset X in D, denoted as ?D(X), is defined as the number of transactions containing X in D, whilst the frequency of an itemset X in D, denoted as freqD(X) = ?D(X)/|D|, is the fraction of transactions that support itemset X in D.

An itemset X is large or frequent in D, if and only if its frequency in D is at least equal to the minimum frequency threshold minf . Equivalently, X is frequent, if and only if ?D(X) ? ?min, where ?min = minf ? |D|.

The set of all frequent itemsets, denoted as F , is defined by F = {X ? I | freqD(X) ? minf }.

Frequent itemsets that the data curator wants to conceal, are called sensitive itemsets and are denoted as S, where S ? F . Additionally, the set of all the sensitive itemsets and their supersets in F is de- noted as SS , where SS = {X ? F | ?Y ? S, X ? Y } and S ? SS ? F . Given the set of sensitive itemsets S, we de- fine the set of minimal sensitive itemsets Smin, that is given by Smin = {X ? S | ?Y ? S, X ? Y }. The revised set of frequent itemsets, denoted as F? , is given by F? = F ? SS .

By its definition, the revised set of frequent itemsets F? is the ideal set of itemsets that would still remain frequent after hiding the sensitive itemsets. The ideal case is when only the sensitive itemsets and their supersets are concealed.

It is desirable for sensitive itemsets to get concealed, while their supersets are inevitably concealed, due to the antimonotonicity property of support ?X,Y ? I,X ? Y ? ?D(X) ? ?D(Y ).

B. Problem Description  Given a database D = {T1, T2, ..., Tm}, a minimum support count threshold ?min, and a set of sensitive frequent itemsets S ? F , the frequent itemset hiding problem involves reducing the support of the sensitive itemsets below  ?min, by sanitizing selected transactions in database D, so that itemsets in S cannot be mined from the sanitized database D?. In other words, we want to conceal the itemsets in S, whilst having the minimum impact on the utility of the database.



IV. PROPOSED METHOD  In this section, we describe the proposed method. Firstly, we present the formulation used to model the frequent item- set hiding problem. We start from the method proposed by Leloglu et al. [13] by referring to it as the Coefficient-Based Max-Accuracy (CBMA) method that builds on the method in [12] referred to as the Max-Accuracy (MA) method. We use a problem formulation similar to this presented for the CBMA method, which comprises an improvement over the one used in the presentation of the MA method. Next, we introduce a new heuristic for calculating the coefficients of the objective function. We will refer to the proposed tech- nique as the Heuristic Coefficient-Based Approach (HCBA).

Finally, we present the proposed sanitization method.

A. Linear Programming Formulation  The frequent itemset hiding problem is modeled with the ILP shown in Fig. 1. Each variable vi and coefficient ci corresponds to a transaction Ti, whilst each constraint corresponds to a sensitive itemset in Smin. A constraint contains a variable if the corresponding sensitive itemset is supported by the corresponding transaction. The linear system has |D| variables and |Smin| constraints.

Equation (1) is the objective function of the ILP, that minimizes the number of transactions sanitized. Equation (2) dictates that more than ?D(X)??min transactions support- ing each sensitive itemset have to be sanitized, in order to conceal all sensitive itemsets. Equation (3) imposes that the variables vi can only take binary values.

The solution of the linear program indicates which trans- actions need to be sanitized. The coefficients can be viewed as the cost of selecting specific transactions for sanitization.

The objective of the ILP is to minimize the total cost, while achieving zero hiding failure. Assigning a different cost to a different transaction can have a great impact on the set of transactions selected for sanitization and consequently on the quality of the sanitized database D?.

B. Heuristic Coefficient Computation  For the CBMA method, the value of a coefficient is equal to the number of non-sensitive frequent itemsets that would stop being supported, if the corresponding transaction is san- itized by using Algorithm 1. The sanitization of a transaction is accomplished by removing the item contained by most of the sensitive itemsets supported by the corresponding transaction. If the value of a coefficient is high, it means that the number of affected non-sensitive frequent itemsets     min ?  ?i: Ti?D civi, (1)  s.t .

? ?i,j:  Xj?Ti?D  vi ? ?D(Xj)? ?min + 1, ?Xj ? Smin (2)  vi ? {0, 1},?i : Ti ? D (3)  Figure 1: The ILP Formulation.

supported by the corresponding transaction, would be also high after the sanitization.

In the proposed heuristic, the coefficient computation is based not only on how many non-sensitive frequent itemsets, but also on how much these itemsets are affected by the sanitization process. For a transaction Ti, let us define the set of non-sensitive frequent itemsets that would stop being supported and refer to it as Ai. This set represents the set of affected non-sensitive frequent itemsets that will be sanitized, if transaction Ti is sanitized using Algorithm 2.

Although for two transactions, Ti and Tj with i 	= j, |Ai| = |Aj | might hold, this does not guarantee that they are equally prone to introducing side effects. One of them might support more itemsets with frequencies closer to the frequency threshold that are more likely to become infrequent. Therefore, a different cost should be assigned to each one of these transactions.

We present a heuristic that attempts to capture how many non-sensitive frequent itemsets in Ai are likely to become infrequent. For this purpose, we define a new parameter Thr , which is calculated as follows. Let j? be the item to be removed, according to the sanitization Algorithm 2. For each iteration in the block (lines 3 - 22) of Algorithm 2, the currently maximum frequency itemset among the sensitive ones in Si, containing item j?, is identified. Then, the value of this parameter is given by:  Thr = argmax ?X?Si|X?j? ?=?  freqD(X)?minf . (4)  Basically, this parameter quantifies the difference between the maximum frequency among itemsets in Si and the frequency threshold minf . We use it to estimate which itemsets in Ai, that contain the items to be eliminated, might become infrequent after transaction Ti is sanitized.

Among the affected non-sensitive frequent itemsets in Ai, there are itemsets that if their frequencies is de- creased by Thr , they would become infrequent. We will refer to this set of itemsets as endangered item- sets and denote their set as Ei. Note that |Ai| ? |Ei|, ?Ti ? D. However, a tie could still occur, if two or more transactions have equal |Ai| and |Ei| set sizes.

To break ties, we use an additional parameter, which we call the pricing parameter, which is given by:  Pi = ?  ?X?Ei (1? freqD(X)). (5)  Algorithm 1 Intelligent Sanitization Algorithm [12] 1: for transactions Ti ? D : Ti is to be sanitized do 2: identify all sensitive itemsets Si supported by  transaction Ti 3: while Si 	= ? do 4: calculate fj = |{X ? Si|j ? X}|, ? items j in Ti 5: remove item j? = argmax j{fj} 6: update Si = Si ? {X ? Si|j? ? X} 7: end while 8: end for  The lower the frequencies of the endangered itemsets in a transaction are, the higher the value of the pricing parameter is. The coefficients for our HCBA method are given by:  ci = |Ai|+ ( log2 |D|  ) |Ei|+ Pi, ?i ? [1, ..., |D|]. (6)  In simple words, a higher cost is given to transactions with non-sensitive frequent itemsets that are likely to become infrequent. Because, even with the endangered itemsets, it is not enough to always break ties, an additional pricing among the endangered itemsets is considered.

C. Improved Sanitization Algorithm  In Section IV-A, a way for accurately selecting which transactions should be sanitized, was presented. Neverthe- less, no hiding has taken place on the database yet. To conceal the sensitive itemsets, a sanitization method needs to be applied. The MA and CBMA methods use the so-called Intelligent Sanitization Process, shown in Algorithm 1, to sanitize the selected transactions.

According to the intelligent sanitization algorithm, if two or more items have the same maximum support count in Si, the sanitization process picks randomly the item to be removed. For example, if only one sensitive itemset is supported by transaction Ti, all items have the same support count in Si and an item is picked randomly. Based on this observation, we propose an enhanced version of the intelligent sanitization process, which uses a series of criteria to break any number of ties that may occur.

The proposed sanitization method is presented in Al- gorithm 2. It follows the same steps as the intelligent sanitization algorithm (lines 4 - 8), but deals with almost any possible tie that might occur. For each transaction Ti chosen for sanitization, the set of sensitive itemsets Si ? Smin supported by this transaction is identified. Then, the item j? that appears in most itemsets in Si is selected. If a tie occurs among items, then the item contained in the fewest itemsets of the revised frequent set F? supported by this transaction (lines 9 - 15), is removed. If a tie occurs again, the item with maximum frequency is eliminated (lines 16 - 18). Lastly, if two or more items made it so far, then an item is selected randomly to be removed. After item j? is selected, that should be eliminated, the sensitive itemsets containing item j? are removed from Si. This process is repeated until Si is left empty.

Algorithm 2 Improved Sanitization Algorithm 1: for transactions Ti ? D: Ti is to be sanitized do 2: identify all sensitive itemsets Si supported by  transaction Ti 3: while Si 	= ? do 4: calculate fj = |{Y ? Si|j ? Y }|, ? items j in Ti 5: calculate j? = argmax j{fj} 6: calculate numf = |{fj = fj?}|, ? items j in Ti 7: if numf = 1 then 8: remove item j? = argmax j{fj} 9: else  10: identify C = {j|fj = fj?}, ? items j in Ti 11: calculate gj = |{Y ? F? |j ? Y ? Ti, ?j ? C}| 12: update weight wj = wj + gj 13: calculate j? = argminj?C{wj} 14: if |{j ? C|wj = wj?}| = 1 then 15: remove item j? = argminj?C{wj} 16: else 17: identify M = {j ? C|wj = wj?} 18: remove item j? = argmax j?M{freqD(j)} 19: end if 20: end if 21: update Si = Si ? {Y ? Si|j? ? Y } 22: end while 23: end for

V. EXPERIMENTS AND RESULTS  We evaluated the proposed method on real datasets, using different parameters such as the number/size of sensitive itemsets to hide. In this section, we also present the datasets used with their special characteristics, the selected parame- ters and the experimental results. Our code was implemented in Python. We used the PyFIM extension module by Chris- tian Borgelt [14] to efficiently mine the set of frequent itemsets. All experiments were conducted on a PC running Windows 7 with an Intel Core i5, 3.20 GHz processor.

The integer linear programs were solved using IBM ILOG CPLEX 12.6 [15].

All datasets used for evaluation are publicly avail- able in the FIMI repository (http://fimi.ua.ac.be/data/). The BMS1 and BMS2 datasets contain stream data from the Blue Martini Software, Inc. and were used for the KDD Cup 2000 [16]. The retail dataset is a market basket dataset from an anonymous Belgian store (reported in [17]).

The kosarak dataset was provided by Ferenc Bodon [18] and contains anonymized click-stream data of a Hungarian online news portal.

A. Evaluation Methodology  We evaluated our proposed method (HCBA) and com- pared the results with the MA and the CBMA methods, by using metrics such as the number of side effects introduced, the percentage of information loss and the execution time.

Information loss is the ratio between the sum of the absolute  differences in the frequencies of frequent itemsets in the sanitized database and the sum of all the frequencies of itemsets in the original database:  IL(D,D?) =  ? X? ?F  |freqD(X)? freqD?(X)| ?  X? ?F freqD(X)  . (7)  The number of side effects (SE) introduced by the ap- plication of the sanitization process can be measured by SE (F? , F ?) = |F? | ? |F ?| ? 0, where |F? | is the number of itemsets in the revised set of frequent itemsets F? , whilst |F ?| is the number of itemsets in the set of frequent itemsets F ? mined from the sanitized database D?.

We point out that the time needed for any preprocessing related to sparsity, frequent itemset mining and calculation of the metrics is not included in the execution time, as it equally applies to all techniques, regardless of the used algorithm.

B. Experimental Results  In Table I, the number of side effects (SE), the time and the information loss performances are given for hiding 10, 20 and 50 sensitive itemsets on real datasets. If we examine the result table carefully, it is deduced that in almost all of the cases the proposed method outperforms the previous works in terms of the side effects introduced and of the information loss.

As far as the time complexity is concerned, there is an increase in the execution time, which is explained by the additional operations required in order to calculate the coef- ficients. However, the overhead is not prohibitive. Observe that the execution time increases linearly with respect to the number of sensitive itemsets.

Lastly, it is also assumed that memory required by CPLEX to solve the integer programs is available. Exploiting the sparsity of the constraint matrix passed in CPLEX plays a major role. In most cases, a low percentage of transactions support sensitive itemsets. This is equivalent to solving a problem with a fairly reduced size compared to the original.



VI. CONCLUSIONS  In this paper, we presented a novel approach to mini- mize both side effects and information loss when hiding sensitive itemsets in transactional databases. The proposed solution has a good quality, while maintaining a decent level of scalability. The frequent itemset hiding problem is modeled by using integer linear programming. A heuristic is introduced, so as to further exploit the coefficients of the objective function. An improved sanitization approach is also exhibited. Finally, we conduct several experiments and compare the proposed method with previously published relative works. For the evaluation, different performance metrics were used.

Table I: Experimental results for the datasets.

