May 12, 2010 17:39 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-3: F1655

Abstract?Mining frequent itemsets is very important for mining association rules. However, because of the inherent complexity, mining complete frequent patterns from a dense database could be impractical, and the quantity of the mined patterns is usually very large. It is hard to understand and make use of them. Maximal frequent patterns contain and compress all frequent patterns, and the memory needed for saving them is much smaller than that needed for saving complete patterns. Thus it is greatly valuable to mine maximal frequent patterns. In this paper, the structure of a traditional FP-tree is improved and an efficient algorithm for mining maximal frequent patterns based on improved FP-tree and array technique, called IAFP-max, is presented. By introducing the concept of postfix sub-tree, the presented algorithm needn?t generate the candidate of maximal frequent patterns in mining process and therefore greatly reduces the memory consume, and it also uses an array-based technique to reduce the traverse time to the improved FP-tree. The experimental evaluation shows that this algorithm outperforms most exiting algorithms MAFIA, GenMax and FPmax*.

data mining; maximal frequent pattern; improved FP-tree; array technique

I. INTRODUCTION  Mining association rules is an important research field on KDD presented firstly by those people, e.g. R. Agrawal.

Rules represent the interesting associations or relations between item sets in database. Mining frequent patterns is the fundamental and essential part in many data mining applications, such as the discovery of association rules, sequential patterns, and so on. Apriori algorithm[1] and its improved ones are mostly adopted to mine frequent item sets in the past researches. All these algorithms make use of the character ?all subsets of frequent pattern are frequent?, but generate plenty of candidate item sets in mining process, and need to scan the original database many times, thus the mining efficiency is cut down. Therefore, people such as Jiawei Han presented an algorithm without candidate generation?FP-growth[2], which only need to scan database twice:  frequent 1-item sets are gained in the first scanning database, and in the second time non-frequent item sets in original database are filtered with frequent 1-item sets and the FP-tree is built, then the complete frequent patterns are mined by performing recursively mining method in FP-tree.

Experiments show that FP-growth is about an order of magnitude faster than Apriori.

The drawback of mining complete frequent itemsets is that if there is a large frequent itemsets with size l, then almost all 2l candidate subsets of the items might be generated. However, since frequent itemset are upward closed, it is sufficient to discover only all maximal frequent itemsets. In addition, there are some mining applications which only need to discover maximal frequent patterns, not to discover complete ones, thus it is greatly significant to mine maximal frequent patterns. The previously presented representative algorithms for mining maximal frequent patterns are MaxMiner[3], DepthProject[4], MAFIA[5], GenMax[6] and FPmax*[7], etc.

MaxMiner extends Apriori to mine only ?long? patterns (maximal frequent itemsets). To reduce the search space, it performs not only subset infrequency pruning such that a candidate itemsets that has an infrequent subset will not be considered, but also a ?lookahead? to do superset frequency pruning. Though superset frequency pruning reduces the search time dramatically, it still needs many passes to get all long patterns. DepthProject performs a mixed depth- first/breadth-first traversal method and also use both subset infrequency pruning and superset frequency pruning. In the algorithm, the database is represented as a bitmap. Each row in the bitmap is a bitvector corresponding to a transaction, each column corresponding to an item. Experiments show that it outperforms MaxMiner by at least an order of magnitude. MAFIA is similar to DepthProject, also uses a bitmap representation, where the count of an itemset is based on the column in the bitmap (called ?vertical bitmap?). To get the bitvectors for any itemset, the bitvector and-operation ? need to be applied on the bitvectors of the items for any itemset. Besides subset infrequency pruning and superset frequency pruning, the pruning technique called Parent Equivalence Pruning is also used in MAFIA. GenMax also uses a vertical representation of the database. However, for each itemset, it stores a transaction identifier, or TIS, rather than a bitvector. The algorithm takes a novel technique called progressing focusing to maximality testing. This technique maintains a set of local maximal frequent itemsets, LMFI?s. The newly found FI is firstly compared with itemsets in LMFI. Most non-maximal FI?s can be detected by this step, thus reducing the number of subset tests.

FPmax* extends the earlier algorithm FPmax, it only scans all FP-tee once by using array technique and uses MFI-tree to store all already discovered MFI?s, adopts efficient method for subset testing. Experimental evaluation shows     May 12, 2010 17:39 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-3: F1655  that FPmax* outperforms MAFIA and GenMax in many cases, especially for datasets with short average transaction length and long average pattern length.

In this paper, an efficient algorithm, called IAFP-max, for mining maximal frequent patterns based on improved FP- tree and array technique is proposed, the algorithm improves the conventional FP-tree and by introducing the concept of the postfix sub-tree, avoids generating the maximal frequent candidate patterns in mining process and therefore greatly reduces the memory consume, it also uses an array-based technique to reduce the traverse time to the improved FP- tree. So it greatly improves the mining efficiency and saves the cost in time and space.



II. PROBLEM DESCRIPTION  Let I = {i1,i2, ,im} be a set of literals, called items. Let database T = {t1,t2, ,tn} be a set of transactions, where each  transaction tj(j=1,2, ,n) is a set of items such that tj ? I.

Each transaction is associated with a unique identifier, called TID. Let P be a set of items (or a pattern), a transaction t is said to contain P if P ? t. The support of P is the number or the percentage of transactions in the database that contain P.

P is frequent if the support of P is no less than a user defined minimum support threshold (min_sup).

Definition 1.  Let I be a frequent pattern, if there is not another frequent J which J ? I, I is called a maximal frequent pattern.

A. Improved FP-tree  FP-tree and conditional FP-tree built by FP-growth algorithm need to generate in a top-down order, but the mining process of frequent patterns employs the bottom-up strategy. Because of the recursively generation of conditional FP-tree, both FP-tree and conditional FP-tree need to be able to traverse in two directions, the nodes in these trees require plenty of pointer, thus a great deal of memory is required for saving FP-tree and conditional FP- tree.

Improved FP-tree (IFP-tree) is similar with FP-tree and each node in IFP-tree consists of four fields: item, count, ahead and next. Where item registers which item this node represents, count registers the number of transactions represented by the portion of the path reaching this node, ahead links to the left child or the parent of the node, and next links to the right brother of the node or the next node in IFP-tree carrying the same item, or null if there is none. We also define two arrays: nodecnt and link, and link[item] registers a pointer which points to the first node in the IFP- tree carrying this item, nodecnt[item] registers the support count sum of those nodes in IFP-tree which carry the same item.

In comparison with FP-tree, IFP-tree doesn?t contain the path from root to leaf-node, contains fewer pointer than FP- tree in mining process, so may greatly save cost in memory.

The construction method of IFP-tree is similar with that of FP-tree, the difference from FP-tree exits in the process of inserting frequent itemsets in each transaction into IFP-tree.

In this paper, we don?t adopt the method of recursively  performing the procedure, insert_tree ([p|P], t), but employ a dynamic pointer to complete it. The algorithm for constructing IFP-tree as follows:  Procedure  FP-tree_construct (T, min_sup) 1) Scan T and count the support of each item, derive  a frequent item set (F) and a list (L) of frequent items, in which items are ordered in frequency-descending order;  2) The root of IFP-tree is created and labeled with ?root?;  3) For  each transaction t T  do  {  Frequent item set It= t  F, in which items are listed to St according to the order of L, define a dynamic pointer (p_current) which points to root ; For each item k  St  do  { If  there is a child(u) of p_current, and u.item =  k.item Then  u.count =u.count +1; Else  create a new child (u) of p_current,  and u.item= k.item, u.count = 1;  }  } 4)  Traverse IFP-tree in a root-first order and transfer  the pointers of ahead and next, count the sum of nodes? support carrying the same item and then list together.

On the step 3), the ahead points to the left child of nodes and the next points to the right brother of nodes. After the step 4), the ahead points the parent of nodes and the next points to the next node in IFP-tree carrying the same item.

Then in IFP-tree, there is no path from a node to its children or to its brothers.

For example, let transaction database T be illustrated by TABLE I, and the minimum support (min_sup) be 4, then we can get the list (L) of frequent items, L = {(c,6) (f,6) (a,5)  (b,4) (m,4) (p,4)}, then IFP-tree is illustrated by Fig. 1.

TABLE I. TRANSACTION DATABASE  T  TID Item Set St  t1 a b c f m o  c f a b m  t2 a c f q d  c f a  t3 a f h m b f a b m  t4 b c k s p c b p  t5 f a c d i m p c f a m p  t6 f h j r  f  t7 a f c e l p m n c f a m p  t8 d c g b k p c b p  B. Postfix Sub-tree  Firstly let a order ( ) be the order of the list L, that is, the support descending order of frequent items. Let the letters (i,j, ,k) denote items in database, then i is called the minimum item and k is called the maximum item if i j  k.

May 12, 2010 17:39 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-3: F1655  Figure 1. IFP-tree of transaction T.

Definition 2.  Let the letters (ik, ,i1[k 1]) denote items and ik i1, P be a path from root to the node N in IFP-tree. If there exits a child node N of the node N and the items (ik, ,i1) appear the sub-path from N to N in order, that is, the item ik corresponds to the node N and i1 corresponds to N , then P is called the path with the postfix of the item sets {ik, ,i1}, the support count of the node N also is called the base count of P.

Definition 3. All paths with the postfix of the item sets {ik, ,i1} in IFP-tree contain  root, accordingly these paths form a sub-tree ,called the sub-tree with the postfix {ik, ,i1}, and labeled with PT(ik, ,i1).

Let M be a node in PT(ik, ,i1), the sum of  base counts of those paths with the postfix  {ik, ,i1} which pass through the node M is called the support count of the node M. In this paper we define an integer array PT(ik, ,i1).nodecnt[ ] to register the support count of all nodes in PT(ik, ,i1) carrying the same item.

Lemma 1. Let M be a node of PT(ik, ,i1) and M1, ,Mj(j 1) be the children of M in the sub-tree PT(ik, ,i1), then the support count of M equals to the sum of support count of M1, ,Mj.

Lemma 2.  If the item im is a node of PT(ik, ,i1), the support count of the pattern { ik i1, im} equals to the value of PT ik i1 .nodecnt[im].

The two mentioned lemmas can be proved according to the definition2, definition3 and the description of IFP-tree.

Due to the lack of space, we omit this part.

Let k be an item in frequent item sets F, the postfix sub- tree PT(k) can be built by traversing IFP-tree in bottom-up order. The detailed description of this method is the following: All paths from root to node k in IFP-tree form a sub-tree, in which the support count of each leaf-node equals to that of corresponding node in IFP-tree, and the support count of each inner node (except root) equals to the sum of support count of its children, then we delete all leaf-nodes, thus achieve the sub-tree PT(k).

The process of building PT(m) is the following: firstly, each node in IFP-tree whose value of item is m is  retained in PT(m), the support count of each inner node (except root) is initialized to be zero. Secondly, for each node, we summate the support count of its children. For example, the support count 3 of the node (a,3) equals to the sum of support counts of its children: (b,1) and (m,2), TABLE II shows the result. Finally delete all leaf-nodes. The PT(m) is illustrated by Fig. 2.

TABLE II. SUPPORT COUNTS OF PT(M)?S CHILDREN  item nodecnt  c 3  f 4  a 4  b 2  Figure 2. The Example of PT(m).



III. MINING  MAXIMAL PATTERNS  A. An Array Technique  The main work done in the mining process is traversing the postfix sub-tree to count the support of itemsets and constructing new postfix sub-tree, Recall that for each item i of conditional PT(x), two traversals of PT(x) are needed for constructing the new sub-tree PT(k,i). The first traversal finds all frequent items and their counts of support, the second traversal constructs the new sub-tree PT(k,i). In this paper, we use the array technique presented by reference [7].

The following example will explain the idea. In TABLE I, supposing that the minimum suppoet is 4, after the first scan of the original database, we sort the frequent items as c:6,f:6,a:5,b;4,m:4,p:4. During the second scan of the database we will construct PT? and an array A?, this array will store the counts of all 2-itemsets. All cells in the array are initialized as 0.

In A?, each cell is a counter of a 2-itemset, such as , A?[b,c] is the counter for itemset {b,c}. During the second scan for constructing the tree PT?, for each transaction , first all frequent items in the transaction are extracted. Suppose these items form itemset I, To insert I into PT?, the items in I are sorted according to the order in the header of PT?. When we insert I into PT?, at the same time A?[i,j] is incremented by 1 if {i,j} is contained in I. After the second scan , array     May 12, 2010 17:39 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-3: F1655  A? keeps the counts of all pairs of  frequent items, as shown in table (a) of Fig. 3.

Therefore ,for each item i in PT?, the array A?makes the first traversal of PT? unnecessary, and PT(i) can be initialized directly from A?. For the same reason, from a sub- tree PT(x), when we construct a new PT(x,i), for an item i, a new AX {i} is calculated. During the construction of the new PT(x,i), the array AX {i} is filled. For example, the cells of array A{b} is shown in table (b) of Fig. 3.

Figure 3. Two Array Examples  B. Algorithm Description  As shown in Fig. 2, we can mine the local maximal frequent pattern (LMFPm) in which m is the maximal item, that is {(f,a,m),4}, by examining whether each item of PT  m .nodecnt[item] in the TABLE II is no less than min_sup or not. The support count of LMFPm is the minimum of that of all items in LMFPm.

The idea of IAFP-max is introduced as follows: for each item i in L, we build PT(i) and mine LMFPi, then combine all local maximal frequent patterns to gain the ultimate result. According to the correctness of FP-growth method, we can conclude that IAFP-max returns all and only the maximal frequent patterns in the given dataset. The following is the main procedure of algorithm:  Procedure  IAFP-max (IFP-tree, L, min_sup) {   MFPs= ? ;  //MFPs is the set of all maximal frequent patterns; For each  i  L do { PT(i)= PT_construct ( IFP-tree, i); Mine LMFPi from PT(i); MFPs = MFPs  LMFPi; } } In the step of MFPs  LMFPi, if LMFPi ? MFPs  MFPs keep changeless, else insert LMFPi into MFPs, then performs subset-checking:  if there is a pattern I ? MFPs, and I ? LMFPi, then delete I from MFPs.

Let the items in L be ranked into 1 k, and 1 ? i ? k. The following is the procedure of constructing PT(i):  Procedure  PT_construct (IFP-tree, i ) {  for j = 1 to i-1 do link[j] = null and nodecnt[j] = 0;  for each node N in link[i] do {  basecnt = N.count;   // basecnt is the base count let M be the parent of node N; while  (M.item ? 1) do  { if   M isn?t in link[M.item]  Then insert M into link[M.item] and M.count = basecnt;  else M.count = M.count + basecnt; nodecnt[M.item] = nodecntp[M.item] +  basecnt; let M be its new parent again; }  } }  By using the algorithm, the set of maximal frequent patterns is as follows: { { (c,f,a), 4 }, {(b),4 }, { (f,a,m), 4 }, { (c,p), 4 } }.

C. Algorithm Optimization  The construction of postfix sub-tree PT(i) is the key step of mining process, decides the mining efficiency of IAFP-max. There are two optional traversal orders while building all PT(i) (i F): the original order of L or the reverse order of L. In this paper, we adopt the former, that is, the items with large support count are built earlier than those with small support count.

If the postfix sub-trees are built in the original order of L, because i LMFPi, i?MFP, LMFPi ? MFPs, so in the step of MFPs  LMFPi, we can omit testing whether LMFPi ? MFPs or not and directly insert LMFPi  into MFPs, then go to the step of subset-checking. If the reverse order of L is adopted, it is likely to exist LMFPi ? MFPs, so we needn?t insert LMFPi  into MFPs. However, in many practical mining applications, Let i,j  F, i j, the probability of LMFPi ?  LMFPj is not very large. For example, as shown by Figure 1, a b, but LMFPa = {(c,f,a),4}, LMFPb = {(b),.4}, LMFPa ?  LMFPb.

Otherwise, if the original order of L is adopted to construct PT(i), the construction process doesn?t transform the structure of IFP-tree, therefore the storage of IFP-tree and the construction of PT(i) can be carried out in a same kind of data structure and avoid repeatedly constructing and deleting PT(i) in the mining process. Consequently, avoid the waste of the efficiency in time and space and greatly improve the performance of the proposed algorithm.



IV. EXPERIMENTAL EVALUATION  The experiments were conducted on 2.1 Ghz Pentium with 512 MB of memory running Microsoft Windows XP.

All codes was compiled using Microsoft Visual C++ 6.0. We used the dense dataset Connect-4 and the sparse dataset     May 12, 2010 17:39 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-3: F1655  downloaded form a websit, and compared the algorithm IAFP-max with GenMax, MAFIA and FPmax*.

Fig. 4 shows the experimental results for the datasets Connect-4 and . As shown in the part (a), we can know that IAFP-max outperforms greatly GenMax and MAFIA for high levels of minimum support.  IAFP-max is  about one to two orders of magnitude faster than GenMax and MAFIA for all levels of minimum support.

The part (b) of Fig. 4 gives the experimental results for the dataset . The results show that IAFP-max outperforms others algorithms and is the fasterst one. IAFP- max is about one to two orders of magnitude faster than GenMax and MAFIA for all levels of minimum support.

Figure 4. (a) comparison in Connect-4    (b) comparison in

V. CONCLUSIONS  In this paper, an efficient algorithm, called IAFP-max, for mining maximal frequent patterns based on improved FP-tree and array technique is proposed, the algorithm improves the conventional FP-tree and by introducing the concept of the postfix sub-tree, avoids generating the maximal frequent candidate patterns in mining process and therefore greatly reduces the memory consume. It also uses an array-based technique to reduce the traverse time to the improved FP-tree. Therefore it greatly improves the mining efficiency in time and space scalability. Experimental results show that this algorithm is indeed very effective.

