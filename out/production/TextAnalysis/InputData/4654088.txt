Probability-based incremental association rule discovery algorithm

Abstract   In dynamic databases, new transactions are  appended as time advances. This may introduce new association rules and some existing association rules would become invalid. Thus, the maintenance of association rules for dynamic databases is an important problem. In this paper, probability-based incremental association rule discovery algorithm is proposed to deal with this problem. The proposed algorithm uses the principle of Bernoulli trials to find expected frequent itemsets. This can reduce a number of times to scan an original database. This paper also proposes a new updating and pruning algorithm that guarantee to find all frequent itemsets of an updated database efficiently. The simulation results show that the proposed algorithm has a good performance.

1. Introduction   Data mining is one of the processes of Knowledge Discovery in Database (KDD) that is used for extracting information or pattern from large database.

One major area of data mining is association rule mining [1] that discovers hidden knowledge in database. The association rule mining problem is to find out all the rules in the form of   X => Y, where X and Y ? I are sets of items, called itemsets. The association rule discovery algorithm is usually decomposed into 2 major steps. The first step is find out all large itemsets that have  support value exceed a minimum support threshold and the second steps is find out all the association rules that  have  value exceed a minimum confidence threshold.

However, a database is dynamic when new transactions are inserted into the database. This may introduce new association rules and some existing association rules would become invalid. As a brute force approach, apriori algorithm may be applied to  mining a whole dynamic database when the database has been changed. However, this approach is very costly even if small amount of new transactions is inserted into a database. Thus, the association rule mining for a dynamic database is an important problem. Several research works [6, 7, 8, 9] have proposed several incremental algorithms to deal with this problem. Review of related works will be introduced in section 2.

In this paper, a new incremental algorithm, called probability-based incremental association rule discovery, is introduced. The goal of this work is to solve the updating problem of association rules after a number of new records have been added to a database.

Based on probabilistic approach, our incremental algorithm predicts infrequent itemsets that have capable of being frequent itemsets after a number of new records have been added to a database. That infrequent itemsets is called expected frequent itemsets. Our algorithm can reduce a number of times to scan an original database. As a result, the algorithm has execution time faster than that of previous methods.

2. Previous work   An influential algorithm for association rule mining is Apriori [2]. Apriori computes frequent itemsets in a large database through several iterations based on a prior knowledge.  Each iteration has 2 steps which are a joining step and a pruning step. For a frequent itemset, its support must be higher than a user- specified minimum support threshold. The association rule can be discoverd based on frequent itemsets.

For dynamic databases, several incremental updating techniques have been developed for mining association rules. One of the previous works for incremental association rule mining is FUP algorithm that was presented by Cheung et al [3]. The major idea of FUP is re-using frequent itemsets of previous  International Symposium on Computer Science and its Applications  DOI 10.1109/CSA.2008.39   International Symposium on Computer Science and its Applications  DOI 10.1109/CSA.2008.39     mining to update with frequent itemsets of an incremental database based on the concepts of Apriori.

Furthermore, negative border approach is presented by Toivonen [5], Thomas et al [6] and Feldman et al [8]. The  negative border approach is  an incremental mining algorithm based on FUP. The border itemset is not a frequent itemset but all its proper subsets are frequent itemsets. The approach need to keep a large number of border itemsets in order to reduce scanning times of an original database.

To reduce memory space, Hong et al [9] and Amornchewin et al[10] propose a new approach. The approach maintains both frequent itemsets and expected frequent itemsets. An expected frequent itemset is not a frequent itemset but is expected to become a frequent itemset when a new database is added to an original database. In order to guarantee that all frequent itemsets can be found when a new database is added to an original database, the approach can only allow very small size of an incremental database to insert into an original database.

Similarly, the proposed method in this paper also keeps not only frequent itemsets but also expected frequent itemsets from an original database. Unlike the previous works, this paper proposes a new technique for predicting expected frequent itemsets. Here, the principle of Bernoulli trials is used to predict the expected frequent itemsets. The expected frequent itemsets obtained from the proposed technique has lesser members than the border itemsets and the expected frequent itemsets obtained from the previous technique. This work also proposes a new updating algorithm that guarantee to find all frequent itemsets of a dynamic database efficiently.

3. Probability-based Incremental Association Rule Discovery Algorithm   When a dynamic database is inserted new transactions, not only some existing association rules may be invalidated but also some new association rules may be discovered. This is the case because frequent itemsets can be changed after inserting new transactions into a dynamic database. Therefore, an association rule discovery algorithm for a dynamic database has to maintain frequent itemsets when new transactions are inserted into the dynamic database.

The task of an association rule discovery algorithm for a dynamic database can be divided into three tasks.

The first task is to update support count of existing frequent itemsets. The second task is to prune existing frequent itemsets that have support count below a minimum support threshold after updating the database. The third task is to discover new frequent itemsets that have support count equal or above a  minimum support threshold after updating the database.

In this section, we describe our algorithm into 2 subsections. Firstly, probability-based expected frequent itemsets is presented. Secondly, updating frequent and expected frequent itemsets is introduced.

3.1 Probability-Based Expected Frequent Itemsets   For our algorithm, an original database, which is a database before being inserted new transactions, is firstly mined to find all frequent itemsets that satisfy a minimum support count, denoted koriginal.  Furthermore, the proposed algorithm also predicts and keeps expected frequent itemsets that may become frequent itemsets if new transactions are inserted into the original database.

Our assumption for the new algorithm is that the statistics of new transactions slightly change from original transactions and the maximum number of new transactions that be allowed to insert into an original database is available.   According to the first assumption, the statistics of old transactions, obtained from previous mining, can be utilized for approximating that of new transactions. Therefore, the new algorithm uses support count of itemsets obtained from previous mining to approximate the probability of infrequent itemsets in an original database that may be capable of being frequent itemsets when new transactions are inserted into the original database.

Here, the process of inserting m transactions into an original database of n transaction can be considered as (m+n) Bernoulli trials, which are (m+n) sequence of identical trials. Each itemset has its probability of appearing in a transaction, denoted by p, i.e., the probability of success. According to the principle of Bernoulli trials, the probability of the number of an itemset to appearing in (n+m) transactions, denoted by P(x), can be found by the following equation:  xmnx )p(p x  mn )x(P ?+?????  ?  ? ?? ?  ? + = 1     ,  where p is the probability of  an itemset appearing in a transaction, m is a number of new transactions, and n is a number of transactions of an original database.

Thus, if k is a minimum support count after inserting new transactions into an original database, the probability of an itemset to be a frequent intemset in an updated database can be obtained as the following equations:  ( ) ( )itemitem kxPkxP <?=? 1            (1) Here, an expected frequent itemset is an itemset  that is not a frequent itemset but has its probability to be a frequent intemset greater than Probpl. Probpl is a threshold constant specified by users.  Probpl indicates the minimum confidence level that a promising     frequent itemset will be a frequent itemset after inserting new transaction into an original database.

3.2. Updating frequent and expected frequent  itemsets  When new transactions are added to an original  database, an old frequent k-itemset could become an infrequent k-itemset and an old expected frequent k- itemset could become a frequent k-itemset. This introduces new association rules and some existing association rules would become invalid. To deal with this problem, all k-itemsets must be updated when new transactions are added to an original database. The notation used in this section is given in Table1.

Table 1. The notation for Updating frequent and expected frequent itemsets algorithm  DB Original database db Incremental Database UP Updated database k Number of  itemset ? Minimum support ? Minimum Expected Frequent Ck Candidate k-itemset Fk Frequent  k-itemset EFk Expected Frequent k-itemset    Here, a new updating frequent and expected frequent itemsets algorithm shown in Figure 1 is proposed in this paper. The algorithm consists of three phases. The first phase is updating 1- frequent and expected frequent itemsets, i.e. line1-3. The second phase is repeatedly updating the other frequent and expected frequent itemsets by using only an incremental database, i.e. line 6-11. The third phase is scanning an original database, i.e. line 13-22.

The First phase is updating 1- frequent and expected frequent itemsets. According to our propose, the 1- candidate itemsets of an updated database, i.e. UPC1 , can be found by combining the 1-candidate itemsets of an original database, i.e. DBC1 ,   with the 1-candidate itemsets of an incremental database, i.e. dbC1 . Then, the support count of UPC1  can be updated by scanning only an incremental database. Then, the result of this phase is consist of  1-frequent and expected 1-itemsets of an updated database.

The second phase has 2 major steps which are a generating k- incremental candidate itemsets step and an updating support count of k- incremental frequent and k- incremental expected frequent itemsets  step for k greater than or equal to 2. For k=2, the 2- incremental candidate itemsets are easily obtained by joining UPF1 with UPF1 . For k>2, the algorithm is firstly find k-  candidate itemsets of an incremental database, i.e. dbkC , by joining dbkF 1-  with dbkF 1- . Similar to Apriori algorithm, the k- candidate itemsets of an incremental database can be the updated frequent itemsets, i.e. UPkF , only if the subsets of the k- candidate itemsets of an incremental database must be in the (k-1 )- updated frequent. Thus, the k- incremental candidate itemsets, will keep only the k- candidate itemsets of an incremental database whose subsets of the k- candidate itemsets are in the (k-1) - updated frequent intemsets.

This can prune the k- candidate itemsets of an incremental database that can?t be the k- updated frequent intemsets.

Algorithm1 : Updating  frequent and expected  frequent itemsets Algorithm   ( )  ( ) ( ) ( )  ( ){ } ( ){ }  scanDB_Tempclear.

doend.

kk.

UP,XcandscanDB_TempXXEFEF.

UP,XcandscanDB_TempXXFF.

doend.

db,XcDB,XcUP,Xc.

doscanDB_TempXallfor.

scanDB_TempXallforDatabaseOriginalScan.

do)mk(andscanDB_Temp(while.

k.

ifend.

doend.

kk.

scanDB_Tempofitemsetimummaxtheism//.

)scanDB_Temp,mreturn(itemsetkUpdate.

ItemsetCandidateGenerate.

dok;F;kfor.

else.

kk.

itemsetUpdate.

kif.

k.

EF,F:Output  counttheirandEF,F,C,,,,k,db,DB:Input  UPUP k  UP k  UP k  UP k  UP k  UP k  k  k  k  UP k  UP k  UP k  DBDBDBDBUPUP            +=  ?<????=  ????=  += ?  ? ???  =  +=  ?  ++??=  += ?  = =  ???     Figure 1.  Updating frequent and expected frequent itmesets Algorithm  When any k-itemsets are not in the union set of the original k-frequent and the original k- expected frequent itemsets, but is in the k- incremental candidate itemsets, their support counts need to be specially updated. This is the case because their support counts obtained from an original database are not available.

Here, their support counts in an original database are assumed to be equal to the sum of 1-DB?  and their support counts from an incremental database. If any k- itemsets have support counts below updated min support count, i.e. ?UP, the k-itemsets can?t be the k- updated frequent itemsets. On the other hand, if any k- itemsets have support counts above or equal to an          Average of execution time (sec.)  3% 4%  Minimum support threshold (%)  T10I4D10  FUP Borders Probability-Based  updated min support count, the k-itemsets are likely to be the k-updated frequent itemsets. Thus, the k- itemsets, which have support counts above or equal to an updated min support count, are set aside for finding their true support counts from an original database.

At the third phase, an original database is scanned to find true support counts for the k-itemsets that are likely to be the k-updated frequent itemsets. The support counts of the likely k-updated frequent itemsets are found and updated by scanning an original database. Then, all k- updated frequent itemsets and k-updated expected frequent itemsets are found.

4. Experiments   To evaluate the performance of probability-based incremental association rules discovery algorithm, the algorithm is implemented and tested on a PC with a 2.8 GHz Pentium 4 processor, and 1 GB main memory.

The experiments are conducted on a synthetic dataset, called T10I4D10K. The technique for generating the dataset is proposed by Agrawal and etc. [1]. The synthetic dataset comprises 110,000 transactions over 100 unique items, each transaction has 10 items on average and the maximal size itemset is 4.

Firstly, the proposed algorithm with Probpl = 0.06 used to find association rules from an original database of 10,000 transactions. Then, the same sizes of incremental databases, i.e. 10% of the original database, are added to the original database for 100 trials.  For comparison purpose, FUP and Borders algorithm are also used to find association rules from the same original database and the same incremental databases. Figure 2 and Table 2 show the average of execution time for FUP, Borders and our approach. The results also show that the proposed algorithm has much better running time than that of  FUP.

Table 2.   Average of Execution time   Average of Execution time for 100 trials  Min_sup (%) FUP Borders Probability-Based  3% 3195.6939 2660.9297 2354.24533  4% 2274.4477 2087.8636 1931.19147                          Figure 2.  The execution time of  FUP, Borders and the proposed algorithm  5. Conclusion   We have proposed probability-based incremental association rule discovery algorithm. Assuming that the two thresholds, minimum support and confidence, do not change, the algorithm can guarantee to discover all frequent itemsets. From the experiment, our algorithm has better running time than that of FUP and Borders algorithm. In the future, further researches and experiments on the proposed algorithm will be presented.

6. References  [1] R. Agrawal., T. Imielinski, and A. Swami, ?Mining association rules between sets of items  in large databases?, In Proceeding  of the ACM SIGMOD Int'l Conf. on Management of Data  (A CM SIGMOD '93), Washington, USA,May 1993, pp. 207-216.

[2] R. Agrawal and R. Srikant, ?Fast algorithms for mining association rules?, In Proceedings of 20 th Intl Conf. on Very Large Databases (VLDB'94), pages487-499, Santiago, Chile, September 1994, pp. 478 -499.

[3] D. Cheung, J. Han, V. Ng, and C. Y. Wong, ?Maintenance of discovered association rules in large databases: An incremental Data Engineering, February 1996, pp. 106-114.

[4] D. W. Cheung, S.D. Lee, B. Kao, ?A General incremental technique for maintaining discovered association rules? , In Proceedings of the 5 th Intl. Conf. on Database Systems for Advanced Applications (DASFAA'97), Melbourne, Australia, April 1997, pp. 185-194.

[5] H. Toivonen. ?Sampling Large Databases for Association Large Data Bases,  September 1996,pp. 134-145.

[6] S. Thomas, S. Bodagala, K. Alsabti, and S. Ranka, ?An efficient algorithm for  the incremental updation of association rules in large databases? , In Proceedings of the 3rd Intl. Conf.

on Knowledge Discovery and Data Mining (KDD'97), New Port Beach, California, August 1997, pp. 263-266.

[7] C.C. Chang, Y.C. Li and J.S. Lee, ?An efficient algorithm for incremental mining of association rules?, Proceedings of the 15th international workshop on research issues in data engineering: stream data mining and applications (RIDE- SDMA?05), IEEE, 2005.

[8] R. Feldman, Y. Aumann, and O. Lipshtat. ?Borders: An efficient algorithm for association generation in dynamic databases?,Journal,Intelligent Information System, 1990, pp. 61- 73.

[9] T.P. Hong C.Y. Wang and Y.H. Tao, ?A new incremental data mining algorithm using pre-large itemsets?, Journal, Intelligent Data Analysis, Vol. 5, No.2, pp. 111-129, 2001.

[10] R. Amornchewin and W. Kreesuradej, ?Incremental association rule mining using promising frequent itemset Information, Communications and Signal Processing,  Dec. 10- 13 2007, pp.1-5.

