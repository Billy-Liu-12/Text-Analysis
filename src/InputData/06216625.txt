Learning Invariants Using Association Rules  Technique

Abstract? Dynamic invariant detection is the identification of properties of programs by analyzing execution traces.

Traditional dynamic invariant detectors, such as Daikon, use naive techniques based on verification of predefined invariant forms. Unfortunately, this may discard many useful knowledge such as relationship between variables. This kind of knowledge can be helpful to understand hidden dependencies in the program.

In this paper, we propose to model invariant detection as a machine learning process. We intend to use learning algorithms to find out correlation between variables. We are particularly interested by association rules since they are suitable to detect such relationship. We propose an adaptation to existing learning techniques as well as some pruning algorithms in order to refine the obtained invariants. Compared to the traditional Daikon tool, our approach has successfully inferred many meaningful invariants about variables relationship.

Keywords-component; dynamic invariant detection;Daikon; Machine learning; Association rules;

I.  INTRODUCTION Many studies showed that maintenance is the most costly  activity in the software development cycle [Gru 05]. In engineering in general, maintenance has the following meaning: an activity, such as tests, measurements, replacements, adjustments and repairs, intended to retain or restore a functional unit in or to a specified state in which the unit can perform its required functions [Apr 08]. In software engineering, most of these activities require a good knowledge of the program. This can be made by using reverse engineering techniques. Reverse engineering is the process of analyzing a subject system. In fact, its main goal is to help to understand the program.

In order to obtain better development cost, it is judicious to automate the reverse engineering task. Invariants are good tools for understanding and debugging programs [Sto 06, Ren 06, Lor 08, Per 09]. They can help in preventing programmers from making errors when changing the code.

Because invariants are frequently missing in programs documentation, methods for detecting them are needed in many contexts. Over the past decade, researches on automatically detecting invariants have contributed towards addressing the  issue [Ern 07]. Techniques for finding invariants have been investigated in several specific areas such as software reverse engineering [Sto 06] and debugging programs [Per 09]. In fact, many tools have been developed to infer invariants using static and dynamic analysis. For instance, authors in [Nim 02] use the source code of the program as the only entry by examining it and reporting meaningful invariants. This technique has a number of limitations. In fact, it cannot report proprieties of programs using language features, such as pointers [Ern 07].

Dynamic analysis runs the program, examines the executions (data traces) and report proprieties over those executions. This technique is the most used to detect invariants since it can produce proprieties from a real execution of the program [Ern 07]. Furthermore, some language features, such as pointers, could not be generated by the static technique.

Many tools have been, since, proposed. We can cite the DIDUCE tool [Han 01] which generates invariants for only one variable; IODINE [Han 05] which extracts likely design pattern from hardware designs. Daikon [Ern 07] has added new optimizations to the invariant detection techniques. It detects several kinds of invariants (such as linear relationship ( baxy ?? ), ordering ( yx ? ), containment ( yx? ), sortedness ( x is sorted) [Ern 07]). Moreover, it filters the reported invariants. In other words, Daikon prunes the useless invariants, such as redundant and abstract invariants (variables not related one to another; for example, time and temperature) [Ern 07]. Finally, Daikon can detect invariant for many programming languages (such as C/C++, Java and Perl) [Ern 07].

Despite these tools knew some success, especially Daikon, some useful knowledge might be discarded. For instance, associations between variables are not really considered except linear relationship between numerical variables (that may not be relevant). This kind of knowledge may help programmers to understand or detect hidden dependencies in the program. For example, the relationship between the parameters of a method and its returned value could provide a good knowledge about its axiomatic semantic. If there is no relation between the parameter and the returned value, one can conclude the method has a side effect. The programmer can hence enhance his program to avoid that.

In this work, we are mainly interested by detecting relationships between variables. For that, we propose to model the invariant detection process as a machine learning process.

Since we are interested by generating invariants about association between variables, we have adapted the association rules technique to generate such knowledge by analyzing execution trace data. Compared to those detected by Diakon, the results of our approach can successfully detect hidden relationships between many variables.

The rest of the paper is organized as follows. In section 2, we give an overview of invariant detection technique. Section 3 presents association rules and some of their concepts and algorithms. Section 4 details how to generate invariants using association rules technique. Section 5 describes a case study in order to illustrate our approach; it also presents a comparison with Daikon results. Finally, section 6 gives a conclusion and presents future works.



II. INVARIANT DETECTION TECHNIQUE An invariant is a property that should be preserved during a  program execution. ? 32 ??? xy ?, ?array  is sorted? are such examples of invariants.

There are many kinds of invariants: global and local ones.

By global invariant, we mean properties that hold on every point of the program. Hence, such invariant can only consider global variables. Local invariants hold only on some points of the program. This category includes among others pre and post-conditions of methods. It can consider global variables, method arguments and returned values.

Invariants can be found either by using static analysis or by dynamic analysis. For the first technique, authors such as [Nim 02] examine the source code to obtain meaningful proprieties (invariant). Dynamic invariant detection discovers invariants (more precisely, likely invariants) of programs by analyzing their execution traces. The last technique is more useful. On the one hand, it can produce proprieties from complex program types (such as pointers). On the other hand; it infers proprieties (invariants) from real program executions.

Daikon [Ern 07] is one of the most used tools for invariant detection. It takes a program, instruments it and then executes it in order to generate an execution trace. This one is analyzed to verify if some predefined-form invariants hold over some points of the program. The verification is quite simple: Daikon takes an invariant, say baxy ??  (x and y are variables, a and b are constants), and verifies it over the execution trace.

Although dynamic invariant detection is considered as a machine-learning problem by the authors of Daikon [Ern 99]; learning algorithms have not been used properly. The approach that is used by Daikon can be considered as naive since it only verifies some known forms of invariants. Consequently, many useful invariants are simply discarded.

In this paper, we argue that invariant detection is no more than a data mining process. This allows us to use all the power of symbolic learning algorithms in order to infer invariants that classical detectors are unable to find out. Among possible invariants, relationship between variables can be of great use.

Suppose a method m with formal arguments a, b and c. If theses ones are correlated in the precondition of m, then one can conclude that the design of m is inefficient since the correlation is synonym of input redundancy. In addition, if the precondition of m does not involve c, then one can conclude that c is unnecessary for m. Finally, correlation between global variables and formal arguments on one hand and the return value on the other hand may tell a lot about what the method does.



III. ASSOCIATION RULES Machine learning is the process of constructing models of  reality from data [Alp 04]. Many techniques have been proposed to deal with the different tasks, such as classification and clustering. One of the techniques used to discover relations between variables in a database is association rules. These ones, first introduced in 1993 [Agr 93], are used to identify relationship among a set of items in a database. It was first used to describe dependencies in the supermarket business data such as the presence of some items in a transaction implies, with a certain probability, the presence of other items in the same transaction. An example of such an association rules is the statement that 90% of transactions involving the purchase of coffee, bread and sugar also involve the purchase of milk.

In addition of the above example, association rules are employed today in many application areas including Web usage mining, intrusion detection [Taj 09], biometrics and classification tasks.

In this section, we will first provide preliminary definitions about association rules. Then, we outline the most used algorithm for mining association rules: Apriori.

A. Useful concepts ? An item (or literal) is a binary attribute of a database  ? An itemset ? 	nIIII ,...,, 21?  is a set of literals. A k- itemset is an itemset with  elements.

? The Support of an itemset is defined as:  nstransactiodatabase Icontainingnstransactio  ISup ?)(  In other words, the support is the proportion of data that contain the itemset I.

? An association rule YX is to be read as the following: when X  occurs, then Y  occurs with certain probability (called confidence). X and Y are itemsets.

? Confidence of an rule is defined as  ? ? ? ?? ?XSup YXSupYXConf ,?   The confidence of the association rule YX is a percentage value that shows how frequently Y occurs among transactions containing X.

B. Generation of association rules Mining association rules can be taken into the following  two sub-problems :  ? Generate frequent itemsets: generate itemsets with support above a minimum threshold, called minSup.

? Generate association rules: from these frequent itemset, generate all association rules with confidence above a minimum threshold, called minConf.

C. The Apriori algorithm Apriori algorithm, developed by Agrawal in [Agr 94], is by  far the most well known association rules algorithm [Ans 09].

Apriori relies on the property that an itemset can only be frequent if and only if all of its subsets are frequent. First, Apriori calculates the support of all the 1-itemsets and finds which ones exceed the threshold (minSup); these are called frequent itemsets. Then it combines these ones to form candidates (potentially frequent) 2-itemsets, calculate their support and determines which ones are frequent. It continues by combining frequent 2-itemsets to form 3-itemsets, calculating their support and determining which ones are frequent and so forth.

After the generation of the frequent itemsets, Apriori can now generate the association rules. First, for every frequent itemset, it generates all the possible rules. Then, it filters them with the minimum confidence threshold.

In this work, we are interested by relationships between boolean and/or integer variables. Other data types will be considered in later works. Apriori algorithm can only handle binary variables. An adaptation of this algorithm is hence necessary in order to infer useful associations between variables. In the next section, we describe how to generate association rules (considered as invariants) from the execution traces using a modified Apriori algorithm.



IV. THE PROPOSED APPROACH In order to generate invariants about relationships between  variables, we have used the association rules techniques, in particular, the Apriori algorithm provided by Weka tool [Hal 09]. This work deals with object oriented programs (in particular, java programs but the proposed approach can be applied to object oriented language). The generated rules considers global variables (class attributes), call parameters (for public methods) and method returns if any. We aim to generate invariants for every public method entry and exit (pre and post-conditions). Global invariants can also be considered.

A. Instrmenting the program In order to generate trace executions, the program is first  instrumented. Instrumentation is the process of adding new instructions to the program in order to capture variables? values at runtime [Ern 07]. This operation can be carried out in many ways, in our approach we chose to use aspect-oriented programming because of its simplicity and efficiency. In fact, we have created an aspect to add the needed instructions in order to capture variables? values during the execution of several points of the program (entries and exits of methods).

The instrumented version of the program is then executed over a given set of tests in order to generate an execution trace.

Of course, the richer is the set of tests the better are the generated (candidate) invariants. The generated trace (called trace database) is used as input to Apriori algorithm in order to infer association rules (invariants).

B. Generating association rules Once trace database is created, Apriori algorithm is used to  generate association rules. Weka [Hal 09] is a free and open source software that can be used for discovering association rules. It includes many machine-learning algorithms and can be used as an API in order to refine the obtained results or to add an implementation of a new learning algorithm.

We have used the Apriori algorithm provided by Weka to generate association rules. We are only interested by generating class association: rules which contain one item in the consequent part. We have used the classification association rules proposed by [Liu 98] and implemented by Weka.

However, as all classifiers, this algorithm requires a target variable, called class variable. Thus, a target variable must be selected before the generation of class association rules. We select the return value of the methods (if any) as a class variable. Otherwise, we generate class association rules by choosing, each time, a variable (global variable or method parameter) as a variable class. For example, given the method void m(int a) in a program with two global variables : x and y, we generate class association rules by choosing x, y and a as class variables.

On the other hand, this algorithm can handle continuous (or numeric) attributes. It discretizes these attributes by mapping them to a set of attributes: (attribute, integer value) [Liu 98].

For example, if, in an execution, we find x=5, classic Apriori algorithm could not handle it because it requires binary values.

Apriori algorithm as implemented by Weka proceeds as follows: it considers ?x=5? as a variable (as a string), then, it tests if x=5 is true, then, it add 1 to the count of x=5. After the examination of the data traces, we may have the following result: (x=5, 6), where 6 is the count of the execution where x equals 5. Then, it divides, 6, the count of ?x=5?, to the number of executions to obtain the support of ?x=5?. With this technique, this algorithm would be able to handle the numeric variables and hence applicable to our problem.

The use of class association rules instead of classic association rules could enhance the result in many ways. On the one hand, this would make the generated rules clearer, more explicit and easily comprehensible (they could be like production rules). On the other hand, limiting the generation of rules with only one variable in the right part instead of several variables will decrease the complexity of time and memory by reducing the number of generated rules.

The result of this step gives us rules such that everyone contains only one value per variable, for example:  2253 ?????? rcba . Thus, the number of rules can be important. This is exactly why a post-processing is necessary in order to refine the results and produce a small set of likely useful invariants. The obtained rules have either to be    merged (if they are very elementary) or simply discarded if implied by other rules (weak rules).

C. Result enhancement Due to the richness of the trace executions, a large number  of association rules can be generated. It is not convenient for a human being to sustain such rules. The validation of the generated knowledge by the user requires a post-treatment, in particular, an enhancement step. This is why we developed some techniques to enhance the result by pruning useless rules and reducing the number of the rules. These techniques are described below.

1) Merging rules a) Merging right  In this enhancement, we are interested by the combination of right parts of association rules. For example, if we have the rules 3211 : vzvyvxR ???? and the rule  4212 : vzvyvxR ???? , (where 321 ,, vvv  are the values of variables zyx ,,  respectively), we combine the rules 1R  and  2R since they have the same antecedent part to obtain the rule ? 	4321 ,: vvzvyvxR ???? .

The general scheme of merging right parts is as follows.

Let 0111 ...: YyDxDxR nn ?????  and  1112 ...: YyDxDxR nn ?????  be two rules. Then, they will be merged in order to produce a new rule R that replaces both of them 1011 ...: YYyDxDxR nn ?????? .

The new rule is more useful than the merged ones: their support and confidence are above the minimum thresholds, minSup and minConf. In fact, the support of R is  )(/),,...,( 101 dbsizeYYDDN n ?  (such that ),,...,( 101 YYDDN n ? is the number of transactions which  values are given by 101 ,,..., YYDD n ? for yxx n ,,...,1 respectively, db is the database). Obviously, this support is bigger than the one of R1 or R2. The confidence is also increased since it is given by ),...,(/),,...,( 1101 nn DDNYYDDN ? (which is, for example, bigger than ),...,(/),,...,( 101 nn DDNYDDN ).

b) Merging left In this enhancement, we apply the same merging as the  precedent except that we act on one variable on the left side.

For instance, if we have the rules 3211 : vzvyvxR ???? , and the rule 3411 : vzvyvxR ???? , (where 321 ,, vvv are the values of zyx ,, respectively), we combine the rules R1 and R2 to obtain the rule ? 	 3421 ,: vzvvyvxR ???? .

The general scheme of merging left part is the following.

Let YyDxDxR nn ????? ...: 111   and  YyDxDxR nn ????? '  112 ...: be two rules. Then a new rule R is created in order to replace them, it is given by:  YyDDxDxR nnn ?????? '  11 ...: . The new rule can be more or less useful than the merged ones. The support of R,  given by )(/),,...,( '1 dbsizeYDDDN nn ?  is bigger than both the supports of R1 or R2, respectively given by:  )(/),,...,( 1 dbsizeYDDN n and )(/),,...,( '  1 dbsizeYDDN n .

However, the confidence of R can increase or decrease depending the distribution of values in nD , 'nD and/or Y. For  example, if 'nn DD ?  is empty then it can be easily shown that the confidence of the new rule is bigger than the smaller confidence (it is hence acceptable since its confidence is bigger than the threshold). Let us now take an example in which the confidence of R is smaller than the smallest confidence.

Suppose two rules YDR :1 and  YDR ?:2 ):( YDDR ??  such that ? ? ? ? 3,, ??? YDNYDN , ? ? ? ? 4??? DNDN , ? ? 4, ??? YDDN  and ? ? 6???DDN . Hence, confidence(R1)=confidence(R2) whereas confidence(R)=2/3.

Therefore, this enhancement can only be applied if the resulting rule has a higher confidence than the fixed threshold.

2) Pruning useless rules Once these enhancements are fully applied on the generated  rules, the results can be in a rough state. Some rules need to be pruned or simply deleted.

First, conditions about variable?s domain values are removed. In other words, if a rule contains a condition xDx? such that xD is the domain of x (computed from the trace database) then the condition is removed from the rule. In addition, a rule, which all conditions have been removed but at most one, is also removed.

After that, weak rules are deleted. A rule is said to be weak if it is implied by another one. Weak rules can be safely removed because they do not bring new knowledge. The general scheme for the definition of a weak rule is the following: let R be a rule given by YyDxDx nn ??? ,...,11  and R' be a rule given by: YyDxDx nn ??? ''11 ,...,  such  that: ''11 ,..., nn DDDD ?? . Here, R is weak and can be removed (since it does not bring a new knowledge). However, if R and R' are defined respectively by: YyDxDx nn ??? ,...,11  and  ',...,11 YyDxDx nn ??? such that 'YY ?  then R' is said weak and can be removed.



V. CASE STUDY To illustrate the proposed approach, we applied it on a  simple, but illustrative example.

A. Case description This considered program consists of managing two stacks  in one table The first stack accepts values in [6..9] while the second stack accepts values in [0..5].

The program defines the following methods:  ? push1(int x) returns 1 when x in [0-5] and the stack not full, 0 if else.

? push2(intx) returns 1 when x in [6-9] and the stack not full, 0 if else.

? int PopP1() returns 0 when P1 is empty, 1 if else.

? int PopP2() returns 0 when P2 is empty, 1 if else.

This program contains three global variables; int[] stack : the table containing the two stacks; int p1and int p2; the pointer of the stack 1 and the stack 2, respectively. Since our approach supports only integer values, only p1 and p2 will be considered as global values.

B. Test suite To generate execution traces, we need to execute the  program. If the target program has a set of test case, we could just use them. Otherwise, we can generate a test suite either by some automated method (by generating randomly values or by using a grammar for the generation of the test suite) or manually by creating a specifically test suite. For our example, we have manually created the test suite in order to obtain a rich data traces. The test suite tries to cover the most possible executions of the program. This test suite is described below:  ? Create new table of 10  ? Push correct values to stack 1 and stack 2: values from 0 to 5 go to stack 1 and values from 6 to 9 to stack 2.

The return value is 1.

? Empty both the stacks.

? Push incorrect values: values from 6 to 9 go to stack 1 and values from 0 to 5 to stack 2. 0 will be returned.

? Push randomly generated values to the two stacks.

C. Results The application of our approach onto the program gave us  the following results.

1) Results of our approach The application of our approach has given many invariants  (58 invariants). In some points, no invariant were detected.

This means that variables in these points are independent. As an example, we present here only invariants about the exit of the method ?int pushP2(int)?. These results are described in Figure 1.

a) Discussion  As shown in Figure 1, many invariants about relationship between variables have been inferred by our approach.

These results show us that some important and meaningful invariants are inferred by our approach. For instance, the invariant (1) which means that if the argument of the method pushP2(int) is in [0-5] and p2 is different from p1 then the method return 1. This invariant reflects the stacks program behavior since the method pushP2(int) require the non- emptiness of the table and only values from 0 to 5.

Furthermore, the invariant (6) shows that pushP2(int) returns 0 if the values to be pushed are in [0-5] and p1=0 and p2=9.

These invariants reflect also the behavior of the program because only values in 0-5 are accepted.

It can be noted that some useless invariants have been generated, in particular, the invariants (4). These invariants are dependent of the test suite used to generate the trace.

2) Results of Daikon We have also used Daikon onto the stacks program with the  same test suite used with our approach. After the application of Daikon on the program described above, lot of invariants have been inferred (over than 1000 invariants) which make it impossible to cite all of them here. We have chosen only some invariants (from 116 invariants) of only one point: pushP2(int).

These invariants are presented in the Figure 2.

a) Discussion  The results of Daikon show us that it has inferred some useful invariants of the program. This is due to the grammar used by Daikon to infer invariants.

From these invariant, some important invariant can be cited, in particular, the invariant (1) which means that the method pushP2(int) returns only the value 1 or 0 (i.e. the domain of return). Other meaningful invariants are reported by Daikon, for instance, the invariants (2) and (3). In fact, the invariant (1) shows that the values of the stack at the pointer p2 are in [0-9] which is true since we push only values from 0 to 9.While the invariant (3) indicates that size of the stack doesn?t change at the exit of the method  pushP2(int).

We can see that the results obtained by daikon do not cover all the invariants of the program. In fact, Daikon was not able to generate invariants about variables relationship, for instance, between the argument and returned value. Anyway, Daikon does not consider any relationship involving more than three variables (where the relationship here consists of a regression).

Our approach has proven that it is able to generate invariants among variable. This kind of invariants may offer  Int pushP2(int):Exit   { p2 in [4-8] and Arg0 in [0- 5] and p1 = 0 --> ret = 1 } { Arg0 in [1- 9] and p2 in [4- 9] --> p1 = 0 } { Arg0 in [1-5] and ret = 1 --> p1 = 0 } { p2 in [6, 7, 9] --> p1 = 0 } { p2 = 9 and Arg0 in [6-9] and p1 = 0 --> ret = 0 }  Figure 1 Results of our approach  Figure 2 Results of Daikon  pushP2(int):::EXIT (1) return one of { 0, 1 } (2) this.stack[this.p2] one of { 0, 9 } (3) size(this.stack[]) == orig(size(this.stack[])) (4) this.p2 > return (5) return <= orig(arg0) (6) return < size(this.stack[])-1 (7) orig(arg0) <= size(this.stack[]) (8) (return == 1)  ==>  (this.p1 one of { 0, 1 })    new knowledge of the program (for an analyst). However, it has to be considered as a complementary tool of Daikon since this one can discover other kinds of knowledge not covered by our approach.



VI. CONCLUSION AND FUTURE WORKS Recent studies showed that automating some maintenance  tasks would reduce the cost of program development. In fact, developers have proposed, hence, several tools to automate them, such as invariant detection.

In this paper, we proposed a new approach for generating new kind of program invariants. We have been interested in generating invariants about relationship between variables.

While considering this problem as a machine learning process, we proposed to use learning techniques (association rules) in order to infer such invariants.

We also proposed a modified version of Apriori algorithm in order to deal with continuous (numerical) data. The implementation of our approach (partially based on the Weka tool) has given useful invariants about associations between variables. These invariants could help programmers to understand the programs behavior and even improve them.

The proposed approach can be enriched in many ways. For instance, because only integer values are supported, generating invariants for other types of data would be gainful. It can also be enhanced by adding more optimization techniques in order to prune more useless invariants. Furthermore, we are working on applying other techniques of machine learning (such as decision trees) to infer other kinds of invariants.

