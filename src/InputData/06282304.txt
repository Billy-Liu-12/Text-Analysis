Mining High Dimensional Association Rules by

Abstract? Association rule mining aims at generating association  rules between sets of items in a database. Now a day, due to huge  accumulation in the database technology, the data are  representing in the high dimensional data space. However, it is  becoming very tedious to generate association rules from high  dimensional data, because it contains different dimensions or  attributes in the large data bases. In this paper, a method for  generating association rules from large high dimensional data is  proposed . It constitutes three steps, 1) pre-processing and  generalizing the data base; 2) it generates large frequent k-  dimension set using user supplied support value which is more  feasible than the traditional approach; and 3) generating strong  association rules using confidence. It can be seen from  experiments that the mining algorithm is elegant and efficient,  which can obtain more rapid computing speed and sententious  rules at the same time It was ascertained that the proposed  method is proved to be better in support of generating association  rules.

Keywords- Association rule mining, high dimensional data,  support, confidence, data mining.



I.  INTRODUCTION  Association rule mining is one of the vital functionalities for discovering interesting associations, frequent patterns, correlations, and other relationships among huge amounts of business transactional data, with vast potential for real life applications. The problem of discovering association rules was introduced in [1]. Given a set of transactions, where each transaction is a set of items, an association rule is an expression of the form X=>Y; where X and Y are sets of items. An example of an Association is ?30% of transaction that contain X also contain; df2% of all transaction contain both of these items?. 30% is called confidence and 2% is support of the rule.

Association rule mining is a two step process. In first step finding all frequent itemsets; in second step generating strong association rules from frequent itemsets.

Association rule mining finds interesting correlations among a large data set of items [1], [2]. In a market basket analysis it might be discovered association rules from transactional data bases which are involving sets of items using Apriori [1]. In general Apriori is used as an influential algorithm for mining frequent itemsets for generating association rules. There is a lot of research and development in this regard. However, in a relational data base, additional information may also have correlation on set of items. Many  practical transactional databases are multidimensional in nature and some of the attributes are multivalued which poses great challenge to apply knowledge mining process.

Association rules can be classified as single and multidimensional association rules are based on number of predicates appearing in the rule. With the changes in the data base technology many organizations are now moving towards high dimensional data storage. There are numerous data repositories which stores the data in different dimensions.

Mining association rules on these data bases are challenging issues. There is a need to find association rules on high dimensional data, a more effectively for different applications and decision making.

Considering each data base attribute as a dimension, it can therefore be interesting to mine ARM on multiple dimensions.

Relatively there is a constant progress in mining multidimensional association rules form data bases.

Association rule mining involving number dimensions can be referred to as high dimensional association rules. In this paper, the problem of generating large frequent k-dimension set for mining high dimensional association rules on data bases are defined. The databases containing both quantitative and numerical data attribute. In this paper, a novel approach is proposed to generate frequent k-dimension set and to find association rules on high dimensional data efficiently. In summary, the main contribution of this works is  1. Proposing a novel approach with efficient data storage  structure for generating frequent k-dimension set.

2. Mining high-dimensional association rules from the  generated set.

3. Theoretical analysis of the proposed algorithm.

The rest of paper is organized as follows. Section 2  summarizes basic preliminaries on high dimensional association rules. The proposed approach is discussed in section 3. Experimental analysis is presented in section 4 and conclusions are given in section 5.



II. BASIC PRELIMINARIES  A. Problem statement  There are many research papers which discussed the association rule mining over transactional databases which contain single and multi dimensional datasets. The existing proposals do not extract the hidden knowledge on high     dimensional data. The proposed work of this paper addresses the issue of high dimensional data sets very effectively by generating frequent k-dimension set for high dimensional association rules.

B. Basic definitions  Let I = {i1, i2, i3?.im} be a set of items and D be a transaction database D= {T1, T2, T3?.Tn}.

Definition : The association rule A=>B is true in D, with support s and confidence c. Support s is defined as , percentage of transactions in D, that contain both A and B (AUB), in transaction D. Confidence c is the percentage of transactions in D, containing A that also contains B.

Support (A=>B) = P (AUB)  Confidence (A=> B) = P (B|A) =P (AU B)| P (A)  The problem is to find all associations rules that satisfy user-specified minimum support and minimum confidence constraints.

The concept of ARM [3] was first introduced with the popular Apriori algorithm. The improvement of the algorithm for mining association rules has the target of numerous studies to obtaining AR from transactional databases. The best known Apriori is proven better performance on 2-Dimensional transactional data base. Many other algorithms are designed and developed in parallel with Apriori to find AR from 2-D transactional data bases. Since the introduction of AR problem in [1], there has been considerable work on designing algorithms for mining rules. This work was subsequently extended to finding association rules over multidimensional dataset. There is a considerable growth in analyzing and developing techniques for mining multi dimensional association rules. Now it is focusing on designing and developing techniques for high dimensional association rules.

The ARM problem was first address in Apriori algorithm [1]. It employs level wise iterative approach to find all frequent itemsets. Database is scanned once to generate all frequent 1- itemset L1 according to user specified minimum support threshold. L1 is used to find frequent 2- itemsets L2, by applying intra-dimensional join condition. This is repeated until no more frequent itemsets is generated. Once all frequent itemsets are discovered, association rules are generated according to the second step in the process of association rule mining. The Apriori property states that ?If any k length pattern is not frequent, its super pattern of length (k+1) is also not frequent in the database? and achieves good performance, by reducing candidate itemsets in every iteration. Numbers of researchers have presented many modified methods based on Apriori property.

C. Mining High Dimensional Association rules  A high dimensional association rule can be of the form  Year (1998)? Location (Delhi)? Buy (Beer)? Buy (Diaper)?

Cars (2) {sup=30%, conf=80%}  This rule means that in the year 1998 customers in Delhi who buy beer and buy diaper together and having 2 cars with support 30% of total transactions and those customers in Delhi who buy beer have a confidence or probability of buying  diaper together and having 2 cars of 80% are generated as association rules.

Mining these kinds of rules from different data sources are time consuming. It requires a common data representation known as high dimensional data set.

D. High Dimensional Dataset  The given dataset D consists of n transactions D= {T1, T2, T3?.Tn}. Each transaction Ti consists of m number of attributes (d1, d2, d3 ? dm), in which dj represents jth dimension or attribute and some attributes may have multivalued categorical values. The record i can be expressed as value combination (vi1, vi2, vi3, vim), where vij represents ith record and jth dimensions, 1< i< n, 1< j< m. High dimensional association rules contains large database with more dimensions. The process of constructing high dimensional data set is explained in the next section.

First and foremost is to understand and analyse these large amount data for effective decision making. A study on mining large databases is presented in [4]. Generally, in a gene expression microarray data set, there could be tens or hundreds of dimensions, and in a customer purchase behaviour data set, there may be up to hundreds of thousands of merchandizes, each of which is mapped to a dimension. Analysing these data sets posses major challenges i) attribute selection, ii) the curse of dimensionality. These challenges are better described in [5], [6], and [7]. Attribute transformation [8] and attribute decomposition [9] are the two approaches to address these challenges. The complexity of many existing data mining algorithms is exponential with respect to the number of dimensions [5]. With increasing dimensionality, these algorithms soon become computationally intractable and therefore inapplicable in many real applications. The detailed description about the data structure used and process of generating high dimensional association rules are explained in next section.



III. PROPOSED WORK  In this section, the process of generating association rules on high dimensional data is described. Generation of association rules on high dimensional data using basic Apriori algorithms is a time consuming process, since it takes only two-dimensional data as input. It is difficult to bring down the high dimensional data to two dimensional data. In this section, a new approach of taking high dimensional data as input and producing the association rules as output is elucidated.

The mining process involves  ? Pre processing and Preparing the data.

? Generating frequent k-dimension set  ? Candidate generation  ? Prune phase  ? Generating association rules  The detailed description the process is explained in the remaining part of the section.

A. Preprocessing and Preparing the data  Before starting the mining process, the data sets must be preprocessed. Preprocessing includes data cleaning, integration, transformation, and data reduction and preprocessing can substantially improve the quality of mining result and time required for the mining.

The basic step in generating association rules is preparing data in appropriate manner. It is very important because the data base may contain combinations of nominal attributes or quantitative attributes.

In case of nominal attributes, it contains a finite number of possible values. For example color can be Red, Blue, and Green. The nominal attributes are replaced by color1, color2, color3 in place of Red, Blue, and Green. In case of quantitative attributes, it contains numeric data like age, income, and price.

This can be replaced by their respective suffix values in the data base. Some attributes has quantitative values which are discretized as some nominal attributes with certain limit on range.  For example the attributes ?age? can be considered as young, middle and old with corresponding suffix values as A1= young, A2= middle and A3= old. These can be transformed and replaced in the data base. Partitioning and discretizing the data into intervals will convert raw data into equivalent binary values. The partitioning procedure better explained by [10].

SQL based natural joins or view operations can be used to combine the dimensions when they are identifiable with a unique key. Some times, for some applications requires binary domain values for attributes and these are replaced by binary values in place of numeric data values. The procedure for combining dimensions was described in [11]. The same algorithm with some necessary modifications is used as shown below.

1) Procedure combine dimensions  1. Select all dataset tables of T1...Tm from each table where  (T1 = Table1) And?..(Tm = Tablem).

2.  Select all dimension d1, d2,?..dm of T1,?..Tm from  each table.

3.  Combine these dimensions into general table in one to  one relation.

4. For each row added to general table assign a unique  Reference id.

SQL based natural join or view operations can also be used  to combine these dimensions into general table when each dimensions of table referred with a unique key. However it becomes tedious when there is no key reference. The common data structure used is shown in Table 1.

TABLE 1 DATA STRUCTURE FOR HIGH DIMENSIONAL DATA    Ref.ID D1 D2 D3 D4 D5 ???? Dn  1 a11 a21 a31 a41 a51 ???? an1  2 a12 a22 a32 a42 a52 ...??.. an2  3 a13 a23 a33 a43 a53 ???? an3  .. .. .. .. .. .. ???? ..

M a1m a2m a3m a4m a5m ????. anm  B. Generating frequent  k-dimension set  In this section, the process of finding all frequent dimension sets is described. In the literature there exist many algorithms for generating association rules [4]. However they suffer with curse of dimensionality and support only few data set values.

CHARM [4] for generating closed associative patterns in gene expression data. However real world applications consists of collection of multivariate data values like categorical, nominal and quantitative attribute values. The existing algorithms are not considering these data values. In this paper a new approach is proposed for generating high dimensional association rules on multivariate data sets. We used a modified Apriori approach for generating frequent k-dimension set instead of using the basic Apriori,. It is because the basic Apriori restricted to few dimensions and doesn?t support multi domain data values. In this proposed approach the modified Apriori is used for generating high dimensional association rules, which support high dimensions and multivariate data sets.

At this stage, the already prepared above mentioned data set is used. This data set contains partitioned quantitative attributes, and created combinations of intervals of the quantitative attributes. This combination, along with those values of categorical attributes, collectively forms the frequent dimension sets.

The algorithm is described as follows:  Function: Generating Large Frequent K-Dimension Set  Input: Transposed table T, support level minsuppot  Output: complete set of frequent dimension set values  1. count = 0;  2. capacity = LargeDimension.capacity;  3. size = LargeDimension.size;  4. set[i] = LargeDimension.set[i];  5. support = LargeDimension.support;  6. LK = frequent k-Dimensionsets  7. For each reference id in table 1 to table m do  8. for k = 2 to Fk-1 ? 0 do  9. Ck = Can_gen(Lk-1)  10. for all reference Rid ? D do  11. Ct = subset(Ck, t)  12. for all candidates, c ? Ct  do c.count++  13. end for; End for  14. Lk = {c ? Ck | c.count ? minsup} ; end for  15. Answer = ?k{Lk}  Let Lk represents the set of frequent k-dimension set and Ck the set of Candidate set for k-dimension set. The algorithm makes multiple passes over the data base each pass consists of two phases. First the set of all frequent (k-1) ?dimension set, Lk-1 is found in the (k-1)  th pass, and it is used to generate the  candidate dimension set Ck. It ensures that Ck is a superset of     the set of all frequent k-dimension sets. After this, the procedure again scans the data base to determine which of the dimension set are frequent to produce Lk. If Lk becomes empty the procedure terminates.

C. Candidate generation  Starting with a frequent candidate set, all such frequent dimension sets are generated in the procedure given as follows.

Function Candidate_generation (Lk-1) is described as following two functions.

Candidate generation used to generate k-dimension set. For this first it needs to generate superset for all frequent k- dimension set described as follows.

Function: Largedimensionset-combine (set1, set2)  It used to combine frequent k-dimension sets Lk into candidate set Ck  Input: set of all frequent k-dimension sets ( Lk )  Output: Candidate Set (Ck)  1. Result = new Largedimensionset (set1.size + set2.size);  2. set i,j to 0;  3. For each set, i < set1.size and j < set2.size  4. if set1.set[i] == set2.set[j] then set  result.set = set1.set [i++];  5. else if set1.set[i] > set2.set[j] then  result.set = set2.set [j++]  6. else result.set= set1.set[i++];  7. while ((i < set1.size) or (j<set2.size))  8. Ck= set1.size ?  set2.size  9. return (Ck)  Function: largedimensionset_prune (Ck-1)  It used to prune the candidate set elements by comparing with support values that are not satisfying minsup limit.

1. For each Ck; pruneDuplicates(ArrayList v)  2. for each  i = 0 to size,  3. for each j = i + 1 to  size;  4. if (((Dimen.set)v.get(j))== ((Dimens.set)v.get(i))) then  5. prune (v.set(j, v.get(v.size() - 1)))  6. if Ck.support <support then delete  7. LargeDimensionSet in Lk-1;  8. Return (Ck )  The above algorithms are explained as follows: Given Lk- 1, the set of all frequent k-1dimensions, the candidate generation is a super set of all frequent k-dimension sets. It has the following steps.

1)  Combine phase Lk-1is combined with itself to find Lk; a set of candidate  k-dimension set. It is denoted by Ck. It is a lexicographically ordered k-1dimension are the same and the attributes are different.

2) Prune phase: Of all the (k-1) subsets of the attributes, Lk-1 subsets which  do not satisfying the above rules are deleted. In the above example, the prune step will delete the set a1, b1, c1 since its subset b1, c1 is not in L2.

Prune the attributes further in a frequent k-dimension set at each iteration step which is not satisfying the user specified interest measure ?support?.

D. Generating Association Rules  It is the second phase of association rule mining. Here the basic Apriori algorithm is used to generate association rules from the frequent set. It generates the rules using another user specified parameter ?min_confidence? which affects the generation of rules. Once the frequent attributes from the high dimensional data have been found, it is straight forward to generate strong association rules which satisfying both minimum support and confidence. This process is going to generate all Association rules which are above the confidence value.



IV. EXPERIMENTAL ANALYSIS  In this section, the performance of the proposed approach is evaluated based on two commonly used metrics support and elapsed time with respect to three factors namely the number of frequent dimension set, no of strong rules generated, and dimensionality(D). The elapsed time is measured as the time duration (in mille seconds) to generate all frequent K- dimension set. The synthetic data generation process and their evaluations are outlined below.

A.  Synthetic dataset generation  The synthetic data generator described in [12] provides the basic model of the generator used in the present work. The dataset generated by the method of [12] is non-hierarchical, or flat, consistent with the original problem formulation. In the present work, however the necessary enhancements were made to the dataset generation algorithm, with an additional parameter being the number of attributes/dimensions, number of instantaneous records. Parameters and specifications for the synthetic hierarchical data generator are listed in Table 2. In all other respects the modified data generator assumes the same behavior as in [12].

TABLE 2: PARAMETERS OF THE SYNTHETIC DATA GENERATOR  Parameter description  T Average transaction size  I Average size of frequent dimension  M Number of transactions in data base  D Number Dimensions  Two synthetic data sets and two real data sets are employed in evaluation as shown the Table 3. These data sets are collection of quantitative, categorical and numerical data values. The data size is varied from different data sizes and     default is at 100 K and the data set dimensionality varies from 100 to 1000 according to their data set dimensionality.

Real data sets CPWine and SAGE, which is obtained from the UCI machine learning repository and thoroughly preprocessed and replace integer and real data values with integer and binary values. This CPWine data set contains of 7130 dimensions and 178 instantaneous records and SAGE contains 12533 dimensions and 215 instantaneous records.

Using this we generated interesting association rules with varying support and confidence values.

TABLE 3  DATA SET DESCRIPTIONS  Data set name Dimensions No of records  T100-AT10-I100-P50-AP5 100 1000  T1000-AT10-I100-P50-AP8 1000 100,000  CPWine 7130 178  SAGE 12533 215  B. Evaluation on synthetic data set  The graphs shown in Figure.1 and Figure 2 depict the execution times of association rules on high dimensional data with varying combinations of parameter values.

Figure 1.  Performance on synthetic data sets with varying minsup values              Figure 2.  Performance on synthetic data sets with varying minsup values  Figure.1shows the performance on D=100 and D=1000  dimensions with varying support values. It is observed from  figure1 and figure2 that as the support values are increasing the  elapsed time and k-dimension set values are decreasing. From  Figure. 2 it is observed that as the support values are increasing  the frequent k-dimension set values are decreasing. It is also  observed that with support values from 0.4 to 0.8 there is  sudden decrease in frequent k-dimension set.

C. Evaluation on real data set  At lasts the performance of the proposed approach on real data sets were evaluated. Here the data set CPWine containing 7130 dimensions and 178 instantaneous records and SAGE containing 12533 dimensions and 215 records. The results with varying support values are shown in Figure.3.

From the Figure.3, it is observed that as the support values decreases the elapsed time for generating frequent k-dimension set values are increasing. It is also observed that the elapsed time also greatly increasing as the support values decreases.

Figure 3.  Performance on CPWine  and SAGE Data sets  D. Number of Frequent K-dimension sets  Figure 3 shows elapsed time for generating frequent K- dimension set on CPWine and SAGE data sets. The numbers of frequent K-dimension sets generated for the data sets with varying support values are shown Table 4.

TABLE 4: FREQUENT K-DIMENSION SET GENERATION                Form Table 4 it is observed that the number of frequent k- dimensions sets generated is decreased as the support values are increased.

As we can see, in all the experiments we conducted the runtime will be more when the support values are minimum.

As the support values are increasing the elapsed time is gradually reducing. The reason is the generations of frequent k- dimension sets are more when support values are low and it reducing when support values are increasing.

E. Generating Association Rules  The number of interesting association rules generated with varying confidence values on CPWine data set are shown in the Table 5. As the confidence values increases the number of rules and elapsed time are decreasing.

Support Frequent K-Dimension sets  CPWine SAGE  0.2 10000 83945  0.4 900 10689  0.6 130 9673  0.8 100 909  1.0 6 146          0.2 0.4 0.6 0.8 1.0  Minimum  S upport  E la  p s  e d  T im  e (  m s  )  for D = 100  for D = 1000          0.2 0.4 0.6 0.8 1.0  Minimum S upport  F re  q u  e n  t K  - D  im e  n s  io n  S e  t  for D =  100  for D =  1000         1.0 0.8 0.6 0.4 0.2  Minimum S upport  E la  p s  e d  T im  e (  m s  )  for D =  7130  for D =  12533     TABLE 5  RESULTS ON CPWINE DATA SET.

Confidence Number of rules  generated  Elapsed time  in ms  0.2 37520 641  0.4 31110 500  0.6 18300 141  0.8 8230 78  1.0 5860 47

V. CONCLUSION  Association rule mining now a day?s focusing considerable interest in the research community. In this paper, an approach for mining association rules on high dimensional data is discussed. Many data sets contain both quantitative and numerical attribute values. The quantitative data values are better dealt with partitioning method and different dimensions are combined into a master table where effective frequent k- dimension set can be easily generated. From the experimental results presented, based on synthetic datasets, it is seen that the performance of the proposed algorithm is decreasing as the support values are increasing.  As the future work, it can be extended to reduce the data sets dimensionality, redundant rules in frequent pattern mining.

