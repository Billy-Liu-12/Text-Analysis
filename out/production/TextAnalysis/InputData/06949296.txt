Speeding up Frequent Itemset Mining Process on  XML Data using Graphic Processor

Abstract?XML technology is being extensively used for data exchange between applications on web and hence mining these documents becomes an important area of research. Since XML is extensively used in web, efficient methods are required for knowledge discovery from the enormous collections of XML documents. Also some advanced tools and technologies are required to effectively handle this scalable data. A methodology is proposed to deal with handling such scalable XML data with the help of high performance and low cost computing, the GPU.

This paper aims to parallelize the pre-processing stage of deserialization and sorting to make the dataset favorable for mining.

IndexTerms?XML mining, High performance computing, Frequent Pattern mining, parallel processing.

INTRODUCTION With the abundant amount of information available on the World Wide Web (WWW), extraction of useful knowledge from the web has become a major issue and as a result has gained significant attention among researchers in data mining and knowledge discovery areas. Extensible Markup Language (XML) has emerged as the dominant standard for describing and exchanging data on the web. XML data mining becomes a complex task because of the flexible nature of structural and semantical xml data. This makes mining from XML document a challenging task compared to traditional association rule mining in relational databases.

Since, last decade we experienced anexponential increase in the amount of publicly available data. Nowadays, E- commerce is becoming more and more popular and eases of selling and purchasing in online mode has attracted the end users. This again adds up to the amount of data available on web. With the enormous amount of data stored in databases and other repositories, there isextensive need to develop powerful means to acquire knowledge from this structured data. This knowledge can be used for decision making in complex business problems and other areas of research. XML (Extensible Markup Language) was first presented by The World Wide Web Consortium [1] to systematize the data exchange format over the web and at the same time achieve interoperability between diverse technologies and tools involved.

As a result extracting knowledge from XML data repositories turned into a very important and necessary characteristic.

More efficient ways to traverse the data needs to be developed to get the desired information. Many algorithms are developed for traversing but need to be equipped to handle scalable data.

Most of the algorithms to mine XML data proposed till date rely on customary relational databasewith an XML interface.

Classification, Regression, Decision Rules, Decision trees, Clustering are the many more approaches which are adapted in data mining. Among them, association rules[2] have been found to be useful especially in the area of discovering interesting relations in very large data sets. From a large data set correlation among different are found.Applying XML mining using association was first introduced by Braga et al.

[3]. From research it is evident that the approaches used so far rely on an Apriori-like candidate set generation-and test approach. However, this approach is found to be time consuming and costly, especially when the dataset is very large. This paper proposes the improved and parallelized version of FP Growth algorithm [4] which generates frequent itemset without candidate generation and overcomes the drawback of traditional Apriori[2] algorithm. The parallelism is incorporated in pre-processing stage so as to make the dataset favorable for mining. This considerably speeds up the mining process and hence takes care of the scalability issue.

The paper is organized as  follows:  Section  2  describes the background, section 3 elaborates the Related  Work,  Section 4  describes  Proposed  work (Parallelizing preprocessing of Association  Rule  Mining  on XML data).  Section 5 describes implementation details.  Section 6 discusses experimental results and performance analysis and Section 7 includes conclusion and future scope.

BACKGROUND A. Frequent Pattern Growth Approach Frequent patterns are mined from an FP-tree using a method called FP-growth. All the node-links from the header table are traversed to generate complete frequentpatterns.  The general idea is to create conditional pattern bases depending on the support threshold and in turn generate rules based on minimum confidence.

The limitation of the algorithm is that it can mine only the set of items for which path expression can be written.  Because of the complexity and irregular structure of XML, implementing     FP-growth on XML dataset poses a problem as compared to structured data. Identifying the mining context becomes difficult in such case.

B. Graphics Processing Unit The GPU provides a means to exploit massive amount of parallelism with even a single processor. The GPU has a significantly different design than a CPU. A GPU has many more processing cores than a CPU. Each processing core can manage many threads at once. A thread is a sequence of programmed instructions or operations. The processing unit?s scheduling system manages the threads. The scheduler on a GPU can handle millions of threads, each of which can be charged with processing a separate row from a table.

Thousands of such threads can then be scheduled to execute simultaneously. Different from multi-core CPUs, the cores on the GPU are virtualized, and GPU threads are executed in SIMD (Single Instruction, Multiple Data) and in turn are managed by the hardware. This is advantageous in speeding up and simplifying the parallel processing since programs are unconscious about physical cores and rely onhardware for thread management. In current scenario, the computation power of GPU is an order of magnitude higher than multiple core CPU. In past several attempts have been made to speed up the mining process by using multiple processors , simultaneous multithreading processors and using shared as well as distributed memory. The motivation behind using GPGPU(General purpose graphical processing unit) is it is very cost effective in comparison to the earlier methods used for parallel processing. We design a GPU-CPU co-processing algorithm, with the basic mining operations done on the CPU and parallelizing work such as pre-processing sorting of itemset done on the GPU.

RELATED WORK Extensive study of literature on XML mining as well as Association rule mining suggests that lot of work is done separately both on xml mining as well as frequent itemset mining. But there is still scope for parallelizing both the processes in amalgamation with High Performance Computing.

This is the need of the hour since scalable data need to be handled efficiently in order to address the issue of computational speed In [5],the authors propose an improved framework for mining xml documents using XQuery and Apriori based approach.

The algorithm was not efficient in terms of time factor but worked well but work well for one transaction file.[6] uses a hierarchical approach HILoP (Hierarchical layered structure of PairSet). The use of such data structure avoids numerous XML data scans to mine Association Rules from a Collection of XML Documents. Cross filtering algorithm have been presented to mine frequent patterns. It greatly reduces the number of candidate set. As mentioned earlier, complexity and irregular structure of XML dataset poses problem for mining.

This is dealt with in [7] by the use of XSL and XSLT. With the help of these tools in preprocessing of the input XML documents, the complex and unstructured XML document is  transformed into simple and regular XML document. Ashraf Abazeed et. al. [8] discussed (MFLEX), the modified FLEX algorithm using two different parse techniques DOM and SAX. The performance comparison of the two parsing methods showed that SAX outstrips DOM in term of time.

MiningTree-based association rule mining from XML documents is done in[9] by Mirjana Mazuran et.al. Structural and content related information on XML document is given.Without using any Apriori based restrictions; the algorithm mines frequent association and also stores the mined informationback in XML format. Because of this, the knowledge extracted can be effectively usedto gain information with the help of querylanguages for XML.Authors proposed a better theoretical structure on association mining rule on XML with semantic limitations [10]. Taking into consideration the ordered property of XML data, they have used minimal hedge and minimal transaction to capture the semantic limitations. [11] uses XPath-like languages for querying graph databases, by focusing on their articulateness and complexity of queryevaluation. Authors concluded that XPath is unfairly overlooked as potential query languages.

PROPOSED WORK The focus of this paper is to compare the time taken in pre- processing of XML transaction as compared with that of deserialization process on structured XML data. The XML transactions are usually of the format:                   Figure 1. An XML Transaction  Step 1: A large character array is used to read the XML file.

Step 2: Find out the starting index of each transaction i.e. the end index position of the tag <Transaction> These are the starting positions for each transaction. We note down these positions in a separate variable. Let the starting indices for the above xml files are as follows:  129, 1103, 1198 Note that there are 2 transactions but 3 indices are noted down. The last index always points to the end of the last transaction.Thus first transaction is between indices 129 ? 1103, second transaction between 1103 ? 1198.

Again note that lines ?</Transaction><Transaction>? appear at the end of the last transaction and is in the range of the  <Transactions> <Transaction> <Item>pencil</Item> <Item>paper</Item> </Transaction> <Transaction> <Item>pear</Item> <Item>napkins</Item> <Item>mobile</Item> </Transaction> <Transactions> </Transaction> </TransactionSet>     indices of the first transaction. However, this gets conveniently ignored during the next few phases.

Step 3: In the next phase we pass the large character array and indices to the GPU and the GPU kernel is invoked. Blocks and threads are spawned on the GPU in such a manner that each block has 100 threads and each thread handles a unique transaction. So, if there are 1000 transactions, a total of 10 blocks will be spawned and each block will have 100 threads.

Thus we will have 10*100 = 1000 threads.

Each thread handles its own transaction. In this way all transactions can be processed simultaneously.

Once in the GPU, each thread then works on each set of transactions as indicated by the indices. Thus, there is no overlapping of search domains.

Step 4: Each thread in the GPU then locates and saves the Item mentioned between the tags <Item> and </Item>.

In our case, thread 1 will work on transaction between indices 129 ? 1103 while thread 2 will work on the transaction between indices 1103 ? 1198.

An example is illustrated as below: The first transaction has 2 items: pencil & paper.

The second transaction has 3 items: pear, napkins and mobile.

Step 5: Once located, the item is then converted into a number by adding up all its ASCII values and storing this sum in a 2D integer array representing all the transactions. This mapping is then stored in another variable for reconversion back into the original string at a later stage.

Alternate mapping strategies may be used as well. In our mapping, the mapping produced is as follows:         Figure 2.Mapping of Integer Array   The resulting 2D integer array generated can then be passed on to the PSP algorithm.

PSP Algorithm (Parallel sorting in pre-processing)  The approach used for parallel programming is using the high parallel computing platform CUDA [12]. CUDA (Compute Unified Device Architecture) [3] enables users to write scalable multi-threaded programs for CUDA enabled GPUs which suffice the purpose of handling scalable data. The CUDA code implemented for sorting an array is done in the following way: The initial input is read into a 2D character array. The frequency of each character is then found through a scan of the 2D array. The characters that do not meet the minimum threshold support count are eliminated from the array. This 2D integer array is then flattened into a 1D integer array as shown in the code below. This array is passed on to the GPU for sorting.

The GPU addresses the flattened array as:        Figure 3.The GPU address of the flattened array   where left=the starting index of the part of the array and right= the end index of the  part of the array. In this manner, the different blocks in the GPU do not use the same location in the array thus making all the blocks work on disjointed sets of the flattened array.

1000 blocks, each with a single thread inside it, are called. The blockId is used to determine the starting position inside the 1D array and blockId + Y is used to determine the ending point.

Each block, knowing its starting and ending point, sorts that small part of the huge 1D array and writes the sorted section to the empty 1D array that was previously created in the same starting and ending position as the original array. The empty array is thus populated with the entries of the original array but sorted in ascending order. Blank spaces have the value of 10000 whereas the characters which were retained have their values as: ( ASCII value+ support count of char*122). This is then converted back into character array.

EXPERIMENTAL DETAILS To achieve scalability and handle large datasets we have used graphic processor in collaboration with CPU. The current dataset was tested on Intel Xeon E5-2620 (6 cores, 12 threads, and clock speed of 2GHz), RAM: 15 GB GPU: Tesla K40c (GDDR5 SDRAM). The driver used was the NVIDIA driver for Ubuntu 10.04(CUDA compilation tools, release 5.0, VO.2.1221) with CUDA support driver version NVIDIA-SMI 331.67.The transactions used were synthetically random generated. The algorithm is tested on 100, 1K, 10K, 50K, 100K , 500K and 1000K transactions respectively.

Table 1 and Figures 4 present the speedups gained by using the GPU for the pre-processing time to transfer the data to and from the GPU to the host device. This is bus independent of the machine. While full optimizations were turned on for the C version the GPU-based implementation outperformed it. A clear increase in performance can be observed with the increase in the number of transactions.

However, it is evident from the diagram in figure 4 that the GPU-based implementation does not match the CPU implementation for very small data sets. From the plot it can be seen that for 10.000 transactions nearly all the time is spent on the GPU. This time span also includes the calling overhead for invoking the GPU kernel. Because of the memory bound GPU- based implementation; there are more memory accesses than floating point operations.

BENCHMARK AND RESULTS We analyzed performances and quality results of our algorithm on different size of synthetic datasets ranging from 100  pencil: 1530 paper:1662 pear:1424  napkins: 1756 mobile:1555  intidx=blockIdx.x*Y+threadIdx.x; int left=idx; int right=left+Y-1;     transactions to 1000K transactions. CPU and GPU-CPU based setup were both utilized for the experimental evaluation.

It was found that as the number of transactions goes on increasing the time complexity of CPU increases and GPU performance surpasses the CPU remarkably. Table below shows the time variations on different set of transactions.

TABLE 1: COMPUTATION TIME OF CPU and GPU   No.Of Transcations CPU Time (in ms) GPU Time (in ms)  100 0.192192 0.376576 1000 1.695328 0.38656 10K 16.387903 0.553888 100K 163.564575 7.825824 500K 797.225464 40.896511 1000K 1418.807251 82.272163     Figure 4. Performance of CPU and CPU-GPU  CONCLUSION AND FUTURE WORK We have directed our focus in efficiently mining XML information. Scalability is a major issue in handling large datasets and up to certain level we have succeeded in addressing this issue with the help of parallel processing. The pre-processing stage of deserialization and sorting the resultant dataset have been successfully parallelized.

Experimental results show a great speed up in terms of handling large amount of data.

Future work on the research includes extending the parallel approach in mining frequent itemset process at various levels.

We also plan to incorporate the above model on GPU-CPU clusters to achieve a new level of scalability. We will also inspect how the basic ideas in our framework can be applied to other applications and programming models.

ACKNOWLEDGEMENT This work is supported by the CUDA Centre of Excellence (CCOE), IIT Bombay.

