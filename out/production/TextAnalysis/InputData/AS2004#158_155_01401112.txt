<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">2004 IEEE

Abstract - This poper describes fast olgorifhms for extrocfing f u z q  ossociofion rules $-om dofobose. The objecfive of the olgorifhm is to improve the compufafionol time of mining and to reduce the extracted redundant rules for the octuol opplicofion. 112 this poper, for exfrocling f i iuy  ossociafion rules, i f  is assumed tho1 conclusion port of lhefuzq rule is specijed in odvonce, i.e. before sfortirig mining computotion. This ossuinpfion corresponds to actualproblems, e.g. diagnostics problem of the process, quolity control action of monufocturirig, oiid so on. The olgorifhm is based on the Apriori algorithm for rule exfraction of fhe specified oufputfield or ourput fuzzy set. From the resulfs of numeiicol experimenfs, fhe algorithm is found fo be effective compared uifh the coriventioiiol method in terms of computofioiiol time.

Keywords: Soft computing, fuzzy association rule, data mining, database, modeling.

1 Introduction In data mining approach, the quantitative attributes should be appropriately dealt with as well as the Boolean attributes. Especially in manufacturing area, quantitative atttjbutes such as state of process, condition of manufacturing, and measured quality of products, are necessary for quality control, manufacturing management, planning, and decision of strategy. In order to deal with the quantitative attributes in mining association rules, algorithms based on the generalized association rules that handle the continuous attributes as the Boolean vector by partitioning into several intervals are proposed[l][2].

Though several methods were also proposed to improve the computational time, the results through the algorithms were still time consuming and complicated to the user.

Fuzzy association rules approaches are proposed to overcome such disadvantages based on the fiuq set[3-6].

These approaches were based on fuzzy extensions to the classical association rules mining by defining support and confidence of the fuzzy rule. Though the mining results are easy to understand by human operator, two drawbacks are still remained for applying such fuzzy approaches to the actual problems. One is the computational time for mining from database, and the other is redundant rules extraction.

This paper describes fast algorithms for extracting fuzzy association rules from database. The objective of the algorithm is to improve the computational efficiency of data mining and to reduce the redundant rules extracted for the actual application. In this paper, I propose a basic algorithm based on the Apriori algorithm for rule extraction of the specified output field. For extracting fuzzy association rules, it is assumed that the conclusion part of the fuzzy rule is specified in advance, i.e. before starting mining computation. This assumption corresponds to actual problem, e.g. diagnostics problem of the process, quality control action of manufacturing, and so on. For example, in the fault diagnosis problem, the conclusion part of required rule is specified as the  symptom of the fault. The rules that express the causes of the fault are acquired from the database in which tbe measured data are stored. According to the assumption of rule specification, the basic mining algorithm, i.e. Apriori algorithm, can be improved.

2 Extraction of fuzzy association rules    2 Extraction of fuzzy association rules 2.1 Fuzzy association rules Fuzzy association rules extraction is employed as the following steps. Let F = {P,Q,r)  denote the fuzzy itemset which consists of fuzzy sets in different attribute, where P, Q, and T denote the fuzzy sets. Support of the itemset F is defined as: where x p  denotes the transaction of the database, and pF ( x p )  denotes the membership value calculated by the product operation of each item(Fuzzy Set) in F, and m * 0-7803-8566-7/04/$20.00 0 2004 IEEE.

denotes the total number of transactions in database. It is obvious that the definition is equivalent to the well-known ?Boolean mining problem? when the itemsets consist of ?crisp sets.? From the support value, confidence of the fuzzy association rule G &gt; H is calculated by: c(G 9 H )  = s(G U H)/s(G) (2) where G and Hare fuzzy itemsets. Fuzzy association nile is extracted when these values of the rule are more than pre-defined minimal support and pre-defined minimal confidence. When we apply the mining algorithm to the actual huge problems, the support calculation is critical calculation concerning the number of query to the datahase. The itemset which bas the value greater than predefined threshold is called ?frequent itemset.? One of the main problems of mining fuzzy association rules is how efficiently find the ?frequent itemsets? from the database.

2.2 The Apriori algorithm The Apriori algorithm is essential and effective method for finding the frequent itemsets. The basic idea is that the frequent itemset should contain the subsets of frequent itemsets. Owing to this characteristic, frequent itemsets can be compounded from the smaller frequent itemsets one afler another. Let k-itemset denote an itemset having k items. Let Lr represent the set of frequent k- itemsets, and C, the set of candidate k-itemsets. The algorithm to generate the frequent itemsets is as follows: AI) Ck is generated by joining the itemsets in Lk+ A2) The itemsets in Ck which have some (k-l)-subret A3) The support of itemsets in Ckis calculated through that is not in Lk.1 are deleted.

database scan to decide Lk.

It should be noted that the plural fuzzy sets defined in fhe same attribute cannont be included together in the same itemset. Afler LI is decided first through database scan, the above AI-A3 procedures are iterated until Lk becomes empty set. The association rules are extracted by combining the decided frequent itemsets to calculate the confidence of the rule.

3 Data mining of specified output Generally, data mining techniques are applied and studied for finding unexpected rules from huge database or dataware house, e.g. in marketing problem or basket analysis. The system using mining algorithm is constructed under assumption that there is always no useful relation in the attributes in database. However, in manufachuing system application, the output field ,or output set is often obvious according to the objectives of  the mining system application. For example, the measured quality variable or the process control variable is usually target output for manufacturing process analysis. In this paper, it is assumed that the conclusion part of the fuzzy rule is specified in advance, i.e. before starting mining computation, from the above viewpoint. According to the assumption, redundant calculation for extracting trivial rules can be reduced.

The specified output is defined as the attribute in datahase or fuzzy set. When the attrihute of conclusion part is specified, the mining problem becomes a kind of    part is specified, the mining problem becomes a kind of modeling problem. In other hands,? when the fuzzy set of conclusion part is specified, the mining problem is like a difficult query problem to the database. It should he noted that the following formulation of algorithm can also be applied to the ?Boolean mining problem.? 4 Algorithms I propose two improved algorithms of the Apriori algorithm by utilizing the above described assumption of the rule output specification. Though the confidence of the association rules are calculated finally after all decision of frequent itemsets in traditional data mining approach, the basic idea of my proposal is that the confidence of the rule can be calculated after each step A3 in the Apriori algorithm and used for pruning the redundant itemsets.

4.1 Algorithm utilizing confidence change In addition to the basic Apriori algorithm, the following procedures are employed for b 2  as: A4) The association rules are decided by calculating the confidence of k-rule based on 4 and Lk.1.

A5) The k-itemsets in Lk which correspond to the rule of ?trivial confidence? are deleted. Where the ?trivial confidence? is defined that the confidence value U is less than predefined threshold and U is less than any confidence of the subset (k-l)-Nle.

Where k-rule denotes the rule that has k attributes including specified conclusion part. Where the ?subset rule? denotes that the itemset corresponding to the rule is subset of the itemset of larger rule and the conclusion parts of both rules are the same set. The concept of the procedure is that the confidence of rule should increase by increasing the number of condition sets. In other words, the procedure is based on the heuristics that the combination of sets in condition part which deteriorates the confidence value will become redundant in the following iterations. It should be noted that the confidence calculation in each iteration does not lead to the increase of calculation time.

4.2 Reduced DB scan algorithm I expand the above algorithm in order to reduce the number of database scan for calculating the support, i.e.

necessary problem in terms of computational time improvement in fuzzy data mining. The idea of the expansion is to calculate the support of ktl itemsets containing conclusion part set together with k itemsets in k-th iteration. By this advanced calculation, confidence of (k+l)-rule can be calculated and utilized for pruning the redundant rule and itemsets in k-th iteration. Furthermore, the number of database scan can be reduced by more than one pass.

Let Mk represent the set of frequent k-itemsets excluding the specified output, and Dk the set of candidate k-itemsets for Mk. Let Nk represent the set of frequent k-  itemsets including the specified output without fail, and E k the set of candidate k-itemsets for Nk. For easy explanation, it is assumed that the output is specified as the fuzzy set denoted as F. The algorithm to extract the fuzzy association rule through generating the frequent itemsets(b1) is as follows: B1) Dk is generated by joining the itemsets in Mk.1.

B2) The itemsets in Dk which have some (k-])-subset that is not in Mk., are deleted.

B3) Ek+l is generated by joining the itemsets in Dk With the set F o f  specified conclusion part.

B4) The itemsets in E, which have some k-subset that is not in Nk are deleted.

B5) The support of itemsets in Dkand Ek+, is calculated through database scan to decide hfk and N~+I.

B6) The confidence of @+I)-rule is calculated based on    B6) The confidence of @+I)-rule is calculated based on Mk and Nk+,.

B7) The k-itemsets in Mk which correspond to the condition part of the rule with ?/3 trivial confidence? are deleted. The &amp;+I)-itemsets in which correspond to such the rules are also deleted.

Where the ?ptrivial confidence? is defined that the confidence value a is less than predefined threshold and U+ p is less than any confidence of the subset k-rule in Nk.

Where /3 is a predefined parameter(O&lt; /3 Cl). At first step(k=l), D, is generated as all fuzzy sets in condition part. E, is set by F. E2 is generated by joining DI with F.

The support of itemsets in D,, El,  and E2 is calculated through database scan. The confidence values of I-rule and 2-rule are calculated. After these calculations, the above BI-B7 procedures are iterated until Nk+l becomes empty set. Owing to the alogorithm, the number of database scan is reduced by more than one pass.

5 Numerical experiments I develop the fuzzy mining system and evaluate the proposed algorithms through numerical experiments. I apply the system to ?abalone data? available from the UCI Machine Leaming Repository. The abalone data set consists of 4177 measured data with 1 nominal attribute and 8 continuous attributes as shown in Tahle.1. In the experiments the nominal attribute is transformed to the continuous attribute. Table 2(a) shows the statistics and the fuzzy partition information of attributes is summarized in Table 2(b). The range of fuzzy partition is set wider than the actual data distribution for performance evaluation. The fuzzy partition example is shown in Fig. 1.

I use two types of fuzzy sets wirh different width.

Although it is better to use the factor such as ?interesting? for pruning the derived rules, I apply the native association rule extraction for proposed algorithm evaluation.

Table I. Abalone data Table 2. Statistical information and fuzzy sets settings (a) Range information of abalone data 1x11 x2 I 13 I x4 1 x5 I x6 I x7 1 x8 1 y Min I 0 10.075 \0.055 1 0.00 I 0.002 I 0.001 1 Max1 2 IO.815 10.650 I 1.13 I 2.826 I 1.488 10.760 I 1.005 I 29 0.001 10.002 1 (b) Fuzzy sets settings 0 x2 0 x2 2.0 0.0  Figure 1. An example of fuzzy partition 5.1 Results of algorithm utilizing confidence chanl:e The algorithm utilizing confidence change is applied to the minimg problem on condition that the output field is specified The minimal support is set as 0.2.The results by standard Apriori algorithm are shown in Fig.2.

At arround 4* itemset calculation, much waste computation is employed. From the results, it can be seen that the waste computation should be reduced.

The results by proposed algorithm with changing threshold value of confidence is shown in Fig.3. The reduction rates of the waste support calculation compared with the Apriori algorithm are confirmed as shown in Fig.3. Figure 4 shows the number of extracted d e s .  At the threshold value 0.7, the result is the same as conventional Apriori algotithm. However, the number of rules are reduced at the other threshold value. From the results, some improvement of computational efficiency 8s confirmed.

1 2 3 4 5 6 7 8 9    1 2 3 4 5 6 7 8 9 ,trmrt shr Figure 2. Results by Apriori algorithm 3 [  I I 0.50 0.55 0.60 0.65 0.70 Threshold Vabe of Confdolcs Figure 3. Reduction of support calculation 0.50 0.55 0.60 '0.65 . 0.70 Threshold Value of Conmiice Figure 4. Pruning results by prop 5.2 Results of reduced DB scan algorithm The reduced DB scan algorithm is applied to the mining problem on condition that the output fuzzy set is specified. The 5th set of the larger sets defined in the output attribute is selected as the output fuzzy set. The minimum support is set as 0.2. The minimum confidence is set as 0.6. The parameter p i s  changed to eval+te the performance of proposed algorithm. The 'results are evaluated compared with mining by traditional database scan (Utilizaing Confidence Change).

Figure 5-8 show the results of the nqer ica l experiments. From the results, computational time is drastically reduced. Furthermore the pruning parameter can control the computational efficiency. The low value of the parameter leads to highly reduction of redundant rule generation for computation. Figure 6 shows that the the number of frequent itemsets are reduced. This also contributes the reduction of computaion in candidate generation and subset pruning. Figure 7 shows that the completely same rnles can be extracted in efficient computational time. Figure 8 also shows the algorithm can reduce the number of database scan.

Result of Tradithal Scan ..__. 4............................

ProposcdMclhcd i 0 0.2 0.4 0.6 0.8 I Parameter vakx Figure 5. Reduction of support calculation 0 02 0 4  0 6  08 I Paramefervabuc Figure 6. The Number of frequent itemsets - 3 s .

P 2 30 B P 25 b $0 1 I5 I : z 10 . .._ . - ............................... t , Resub ofTradaanal Scan ProposedMethod Sd -______ Rcsuh ofTra&amp;al Scan 4 ..............................................................

0 0.2 0.4 0.6 0.8 I Parameter V a b Figure 8. The number of database scan In order to evaluate the performace, let us confirm the results under appropriate parameter setting. Though the appropriate parameter is different according to the objectives of application, the value is set at 0.5 in this paper. Figure 9 shows the reduction of calculated itemsets.

At first iteration, proposed algorithm need much computation compared with the traditional scan method.

However in proceeding iterations, computational time are reduced by pruning mechanism. Figure 10 shows the    number of frequent itemsets decided at each iteration. The stored itemsets is also reduced.

From these experiments, the proposed algorithm are found to be effective in terms of the computational efficiency and redundant rule pruning.

................................................................................................

............................................................................ ~ ~ t P r o p c d M c U a d  ~ ...I Traradlona,Sca,J : i 0 2 4 6 8 IO Database k a o Figure 9. The number of candidate itemsets GR;o.51 0 2 4 6 8 10 Database kan Figure 10. The number of frequent itemsets W0.5) 6 Conclusions In this paper, I propose fast algorithms for extracting fuzzy association rules of the specified output field from database based on the Apriori algorithm. Through the numerical experiments, the algorithms are found to be effective compared with the conventional method in terms of computational time and redundant rules pruning.

In future, I will apply the algorithm to more complicated and large actual problems.

