Support Vector Data Description for Image Categorization From Internet Images

Abstract  Training a classifier for object category recognition using images on the Internet is an attractive approach due to its scalability. However, a big challenge in this approach is that it is difficult to automatically obtain sets of negative samples that are guaranteed to be free of positive samples. In this paper we propose to address this challenge with a Support Vector Data Description (SVDD) classifier. An SVDD classifier does not need negative images in training. It computes a hypersphere around the potentially good images in the feature space and uses this boundary to distinguish images of target visual category from outliers. Evaluation on standard test sets shows that we are able to achieve competi- tive classification performance using the contaminated training images from the Internet without the need for large datasets of negative examples.

1 Introduction  Recently, learning object categories from images on the Internet has gained attention in the computer vision community [1, 4, 7]. Compared to the conventional ap- proach that uses training samples collected manually, learning from the Internet images seems much more scalable. Given any visual category, we could submit the category name to an Internet image search engine, such as Google Image Search, and then thousands of images are available for training.

However, although it is rather easy to obtain positive images from Internet, it is nontrivial to obtain accept- able sets of negative images. We can type ?car? in a search engine and expect to receive images related to cars. But it is difficult to explicitly search for images that do not contain cars. One may consider typing sev- eral random nouns in the search engine and using the  returned images as negative images for training. How- ever, we need to manually check these images to make sure that there are no instances of the target category in them. Otherwise the positive samples labeled as neg- ative will contaminate the classifier. Due to this issue, conventional two-class classifiers, such as SVM, may not work well for the problem of training classifiers us- ing Internet images.

We note that what is important in decision making at test time is the boundary between positive data and neg- ative data. Thus, if we can define a boundary of positive data, it can be used as a classifier. This is called a one- class problem in machine learning. Following this line of thought, in this paper we propose to train an image classifier using only the positive samples returned by the image search engine. Our contribution is to show that we are able to obtain competitive classification re- sults using the disparate training images from the Inter- net without the need for large datasets of negative ex- amples.

The background of the proposed approach is pre- sented in Section 2. Implementation details are de- scribed in Section 3. Finally, we present the experimen- tal results in Section 4.

2 Approach  As discussed in Section 1, we formulate the prob- lem of learning an object category from Internet im- ages as a one-class problem. The object category we are interested in is called the target class and the images not belonging to this category are called outliers. Our goal is to train a classifier that could estimate a bound- ary useful for separating images of the target class from the outliers. In this paper, this is achieved by using the Support Vector Data Description (SVDD) classifier in- troduced by Tax and Duin [6]. To make this paper more self-contained, we now summarize their approach in the     rest of this section. For the mathematical details of this approach please refer to Tax and Duin?s seminal paper [6].

Suppose we are given a dataset {x1, ...,xN} ? X , where N is the number of samples, and X is the train- ing set. The main idea of SVDD is to obtain a spheri- cally shaped boundary around the training dataset such that the sphere can enclose as many samples as possible while having minimum volume. The sphere is charac- terized by its center c and radius square R > 0. The minimization of the sphere volume is achieved by min- imizing its square radius R2. To improve the generality of the classifier, some remote samples in the training set are allowed to be located outside the sphere, but larger distances to the center should be penalized. Thus slack variables ?i ? 0 are introduced and the minimization problem is formulated as  minR2 +  N?  N? i=1  ?i (1)  subject to????xi ? 1N? ????2 ? R2 + ?i and ?i ? 0 (2)  where ?i accounts for possible errors and the parameter ? controls the trade-off between the hypersphere vol- ume and the errors. If xi is within the sphere or on the boundary, there is no error and the corresponding ?i is equals to 0; otherwise, ?i > 0 is the squared distance from xi to the boundary of the sphere.

Using Lagrangian multipliers, we obtain the dual problem  min ?  ? i,j  ?i?j(xi ? xj)? ?  i  ?i(xi ? xi) (3)  subject to  0 ? ?i ?  N? and  ? i  ?i = 1. (4)  Solving the dual optimization problem yields ?i. If xi is within the sphere, the inequality constraint in (2), ?xi ? c?2 < R2 + ?i, is satisfied and the correspond- ing Lagrangian multiplier, ?i, is zero. Otherwise, for xi on the sphere (?i = 0) or beyond the sphere (?i > 0), the equality constraint ?xi ? c?2 = R2 + ?i has to be enforced and the Lagrangian multipliers will become non-zero, i.e., 0 < ?i < 1N? or ?i =  N? . All sam-  ples xi with positive ?i are called Support Vectors of the SVDD.

Given a new sample z, we compare its distance to the center of the sphere with the radius of the sphere R.

If z lies inside the hypersphere, it belongs to the target class; otherwise, z is classified as an outlier.

Note that in (3), x only appear in the form of inner products with other points. Hence, the inner product (xi ? xj) can be replaced by a kernel function  k(xi,xj) = (?(xi) ? ?(xj)). (5)  In a way analogous to the Support Vector Classifier, a flexible boundary description can be obtained by choos- ing an appropriate kernel function.

3 Implementation Details  This section describes the implementation of our ap- proach. We first discuss the bag-of-word image rep- resentation and our similarity measurement. Then, we describe the kernel used in our approach as well as its properties and the method used to choose the parame- ters in our experiments.

Image Representation. For a given image, we first extract PCA-SIFT descriptors [3] after converting it to gray scale. The PCA-SIFT descriptors are then vector- quantized using a pre-computed visual word codebook including 1000 visual words. Finally, each image is represented by a histogram of the visual words. To compare two histograms H1 = (x1, x2, ..., xk) and H2 = (y1, y2, ..., yk), we use the ?2 distance, which is defined as  D(H1,H2) =  k? i=1  (xi ? yi)2  xi + yi . (6)  Kernel and Parameters Selection. We use the ?2  kernel [8] in the SVDD framework. There are two free parameters to adjust: the kernel width ?2 and the trade- off parameter ? in (1).

The parameter ? is an upper bound on the fraction of training points outside the estimated region and a lower bound on the fraction of support vectors. A large ? allows more points to be assigned outside the sphere, which corresponds to a larger rejection rate and a larger number of support vectors. To select the best ?, we con- struct a validation dataset, which includes 1000 back- ground images. The ? with the lowest false positive rate on the validation dataset is selected as the optimum value. Note that in contrast with two-class classifiers, the validation dataset does is not involved in the train- ing but it is only used to select an optimal parameter.

The kernel width ?2 influences the complexity of the boundary and the number of the support vectors.

Tax and Duin [6] show that for very small value of ?2, (3) is optimized when all samples become support vec- tors with equal ?i = 1N . With the increase of ?  2, the    boundary is smoother; the volume of the enclosed re- gion is increased; the number of support vectors de- creases. Given a ?, we initialize ?2 with a small value (0.1 in our experiments). Now the SVDD has a large number of support vectors. When we increase ?2, the fraction of the support vectors decreases. The optimal ?2 is selected when the fraction of support vectors first reaches the specified ? (recall that ? is the lower bound on the fraction of support vectors). Beyond this point, the volume of the sphere may be too large and we will risk enclosing too many outliers.

4 Experiments  4.1 Datasets  Our experiments used part of Fergus?s ICCV?05 datasets under the same setting as in [1], plus our own datasets. The resulting dataset contains seven differ- ent object categories. Five of these are from Caltech datasets: Airplane (A), Car Rear (C), Leopard (L), Face (F), and Motorbike (M). Two additional categories are Guitar (G) and Wrist Watch (W). For each category, three subsets of data were compiled and they are de- scribed as follows:  1. Caltech test set: [2] It was manually gathered and the pose of the object is quite constrained within these frames. This subset will be used as the test set in the classification experiments.

2. Google raw set: It consists of a large number of images returned by Google?s image search using the category name. It may be contaminated by im- ages unrelated to the category and the proportion of good images ranges from 18.1% to 63.4%. De- tails about this dataset are given in [1]. This sub- set will be used in the Search Engine Improvement tests.

3. Google training set: We obtain this dataset with a similar method to Fergus?s Google validation set [1]. We translate seven category names into five languages (German, French, Dutch, Italian, and Chinese) and then use them along with the English version as queries for Google Image Search. The top 20 images are downloaded and images in dif- ferent languages are combined into a single train- ing set. Thus this training set contains 120 images for each category. This subset will be used to train the classifiers in our approach.

Table 1. Comparison of the proposed approach with other weakly supervised training approaches.

pLSA [1] TSI [1] SVDD [2] [5] Supervision None None None Label Label  (A) 24.7 15.5 15.7 7.0 11.1 (C) 21.0 16.0 20.5 9.7 8.9 (F) 20.3 20.7 16.2 3.6 6.5 (G) 17.6 31.8 10.5 (L) 15.0 13.0 12.3 10.0 (M) 15.2 6.2 13.5 6.7 7.8 (W) 21.0 19.9 17.7  4.2 Classification Experiments  In these experiments, classifiers are trained using the Google training set. For each category, images in the Caltech test set are mixed with an equal number of im- ages from the Caltech background set [2]. The task is to correctly classify each image as belonging to the class or as background image.

The results of this experiment are illustrated in Ta- ble 1, compared with other weakly supervised learning approaches. Within three models trained from Google images, SVDD achieves the best performance in four categories and TSI-pLSA in three categories. For ?Air- plane?, SVDD performs almost as well as TSI-pLSA.

We attribute the superior performance of TSI-pLSA to their use of spatial information. Indeed, compared to the pLSA approach, which also employs the bag-of-words image representation, our approach is competitive.

4.3 Search Engine Improvement Experiments  In [1], the images in the Google raw set are manu- ally labeled as Good, Intermediate and Junk based on their relativeness to the specific category, where Good images show dominant object without major occlusion while Junk images are totally unrelated to the category and the Intermediate images are those in between. In tests, we take the Good images as positive images and the Intermediate and Junk images as negative images.

The trained models are used to re-rank the images in the Google raw set. We then compare the trained models to Google Image Search by the recall-precision curves.

In Figure 1, we compare the precision at 15% re- call for the raw Google images, SVDD, pLSA and TSI- pLSA. SVDD achieves significant improvement over raw Google Image Search on precision in most cate- gories and achieves higher precision than pLSA in four categories.

Figure 1. Improvement in precision at 15% recall over raw Google ranking with SVDD, in comparison with pLSA model and TSI-pLSA model [1].

Figure 2. Top ranked images by Google Image Search for the ?Guitar? category.

Figure 2 and Figure 3 compare the top 20 images returned by the Google Image Search and those by the SVDD respectively. The colored letters in the top-left corner of each image show the ground-truth labels: ?G? in green = Good image; ?I? in blue = Intermediate im- age; ?J? in red = Junk image. Notice the improved im- age quality when compared to the raw Google images in Figure 2, with 15 good images in SVDD re-ranked set vs. ten good images in Google raw set.

Figure 2 and Figuer 3 compare the top 20 images returned by the Google Image Search and those by the SVDD respectively. The colored letters in the top-left corner of each image show the ground-truth labels:  5 Conclusion and Future Work  We proposed an approach for learning object cat- egories from Internet images in a weakly supervised manner. This is achieved by the Support Vector Data Description, which uses the smallest hypersphere around the target class in the feature space transformed by a ?2 kernel as a boundary to distinguish the images  Figure 3. Top ranked images by the SVDD classifier trained from our Google training set for the ?Guitar? category.

of the target class from outliers. The results are com- petitive with state-of-the-art pLSA model. Though both the pLSA approach and the SVDD approach can learn from contaminated training data, they provide different solutions to this problem. The pLSA approach focuses on coherence among visual words while SVDD empha- sizes consistency in the transformed space. It would be interesting to see if we can combine these two methods into a single framework and thus obtain benefits from both.

