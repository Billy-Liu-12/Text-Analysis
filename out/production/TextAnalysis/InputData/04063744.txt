An Effective Hypergraph Clustering in Multi-Stage Data Mining of  Traditional Chinese Medicine Syndrome Differentiation

Abstract   Traditional Chinese Medicine is mysterious for its special diagnosis and treatment. In TCM, Syndrome differentiation is the method of recognizing and diagnosing diseases or body imbalances in TCM. In this paper, we first give a hierarch model of differentiation syndrome in Traditional Chinese Medicine According to the model data mining procedure is designed to complete it. Given special data mining schema and character of high-dimensional data sets, we introduce hypergraph based on greedy algorithm in cluster and similarity measure during clustering stage. Finally, the experiment shows that the hypergraph clustering is correct and efficient, which in return could be important for association rules and diagnosis.

1. Introduction   Traditional Chinese Medicine (TCM) had been known for more than 5000 years in which formed a special system to diagnose and cure illness in ancient China. Syndrome differentiation is the method of recognizing and diagnosing diseases or body imbalances in TCM. It involves analysis and synthesis of symptoms data obtained by the four examination methods. This enables the doctor to determine at which stage the disease has been developed, its location, and the degree of opposing force between the body resistance and the pathogenic factors otherwise known in TCM as the evils. Syndrome decides diagnosis, diagnosis decides medicine, and Medicine decides curative effect. So, syndrome differentiation is the key to doctor in TCM. On the basis of ?National key Technologies R&D Program in the 10th Five-year Plan?, we designed a five-tier model for syndrome differentiation of children pneumonia. We are trying to find syndrome differentiation criterion through clustering and association. In TCM, there are  thousands of data objects with several hundreds of dimensions.

KDD (Knowledge Discovery in Databases) is a process to find correct, novel and potentially useful knowledge[1]. There are some clustering algorithms in KDD, such as CLARANS[2], DBSCAN[3], BIRCH[4], STING[5], WaverCluster[6], DenClue[7] and CLIQUE[8]. Although all of them can find clusters, they may be involved in trouble with high- dimensional data. Besides, correlation can not be described by distance similarity. To solve it, we need to explore a more general type of clustering to measure the distance between two objects.

Graph theory is effective for high-dimensional space. According to [9], each data item is represented as a vertex and related data items are connected with weighted hyperedges in a hypergraph model. A hyperedge represents a relationship (affinity) among subsets of data and the weight of the hyperedge reflects the strength of this affinity.

Graph-based clustering has two different procedures.  One is partitioning algorithm, through which a graph is partitioned into unconnected sub- graphs. The other is agglomerate algorithm, through which sub-graph is connected to be one or satisfying ones.

The paper presents a greedy algorithm to realize sub-graph connection for graph clustering. The rest of the paper is organized as follows. Model of TCMSD is presented in section 2. Section 3 introduces clustering model and theory of hypergraph.  In Section 4 the proposed algorithm based on greedy. Results from TCM are given in Section 5 and section 6 deals with Conclusions.

2. TCMSD  2.1. Model of TCMSD   0-7695-2702-7/06 $20.00  ? 2006    Syndrome differentiation is the method of recognizing and diagnosing diseases or body imbalances in TCM. It involves analysis and synthesis of the clinical data obtained by the four examination methods. This enables the doctor to determine at which stage the disease has been developed, its location, and the degree of opposing force between the body resistance and the pathogenic factors otherwise known in TCM as the evils.

Figure 1. Five-tier model of a disease in TCM   2.2. Raw data from TCM   The Case Report Form (CRF) is an important tool used in clinical trials. It captures a required record of data and other information for each patient during a clinical trial as defined by the clinical protocol. The data are stored electronically in database, and usually each subject has at least one CRF.

There are 78 attributes in raw data. Figure 2 shows a set of 3 objects with 11 attributes. We can see that domain of data is in [-1, 3]. Because values are discrete, there are only four values, in which -1 represents null, and 0,1,2,3 represent degree of an attribute (symptom).

-1.5  -1  -0.5   0.5   1.5   2.5  A 5_ L1  A 5_ L2  A 5_ L1  A 5_ L2  A 5_ L1  A 5_ L2  A 5_ L1  A 5_ L2  A 5_ L3  A 5_ L4  A 5_ L1  attributes  v al u e  -1.5  -1  -0.5   0.5   1.5   2.5     Figure 2. Raw data   2.3. The data mining schema   Syndrome is interpreted as collection of different symptoms, and each symptom have different weighted value at different syndrome. First, we can find  syndromes (clusters) via cluster process. When object (value) clusters are completed, we can acquire symptom (attribute) clusters through computing symptoms? probability in each syndrome. Specialists need to rename the clusters because of unsupervised procedure. Then, three-grade symptoms based on syndromes (clusters) can be built through association process: differential symptoms, primary symptoms and secondary symptoms. Finally, criterion of syndrome for diagnosis can result from cluster and association.

According to the above description, we can confirm the schema of data mining.

Figure 3. The 4-stage data mining process   3. CLUSTERING ANALYSIS MODEL  3.1. Clustering analysis and its model   The aim of cluster mining is to confirm syndrome.

There are two steps: Object clustering, generalized clustering process, generate clusters via clustering algorithm; Attribute computing, statistical symptoms, acquire probability of each syndrome in a cluster. Thus, each cluster is called syndrome. Syndrome is named by the expert. Because of symptom (attribute) cluster and high dimension, we have a hypergraph method to complete.

Figure 4. Clustering process    3.2. Hypergraph algorithm   symptom symptom symptom symptom  syndrome syndrome      RDB  CRF CRF  CRF      cluster  cluster1      association  differential  primary secondary      classify  diagnosis  cluster2  0-7695-2702-7/06 $20.00  ? 2006    Hypergraph algorithm for clustering related items consists of the following two steps[9]. During the first step, the weighted hypergraph H is constructed to represent the relations among different items and sub- graphs come into being. During the second step, a hypergraph agglomerate algorithm is used to combine sub-graphs until algorithm terminates.

The choice of distance function has great implications on the meaning of similarity, and this is particularly important in subspace clustering because of computational complexity. Hence, we need a distance function that makes measuring of the similarity between two objects in high dimensional space meaningful and intuitive, and generating an efficient implementation.

Definition 1 Assumed vectors x ( 1x , 2x ,?, nx ) and y ( 1y , 2y ,?, ny ) are the two objects,? maxi and mini  represent max value and min value on attribute i? i is integer and ni ??1 ?.

n  )Attributereedegrepresentsiattributeif,yx(; ii yx   Attributereedegnonrepresentsiattributeif,yx0 yx1  )y,x(sim  n  1i  ii minmax  ii  ii  ii  ? =  ? ? ?  ?  ? ? ?  ?  ?  ? ? ?  ?  ? ? ?  ?  ?  ? ? ?  ?? =  = ?  ???  ???  (1) If similarity satisfies the use specified threshold, we  can divide the two objects into one group.

4. Hypergraph clustering based on Greedy algorithm   4.1. Greedy algorithm   A greedy algorithm repeatedly executes a procedure which tries to maximize the return based on examining local conditions, with the hope that the outcome will lead to a desired outcome for the global problem. In some cases such a strategy is guaranteed to offer optimal solutions, and in some other cases it may provide a compromise that produces acceptable approximations.

Typically, the greedy algorithms employ simple strategies that are simple to implement and require minimal amount of resources.

4.2. Algorithm implementation   Step 1 Construct hypregraph Calculate the similarity between a single source  node and all of the other nodes in a graph. When similarity is greater or equal to given threshold, hyperedge is established and sub-graphs are generated.

Algorithm: construct initialization of hypergraph Input:   (1) clusterNum: number of cluster;  (2) threshold: threshold of similarity.

Output:  (1)matrix: mapped hypergraph;  (2)arcWeight: weighted queue of arc; (3)clusteResult: initialized hypergraph.

Procedure: Begin 1.scan database and begin to construct initialized hypergraph; 2. for(i=1; i< transNum; i++) 3.   for(j=0; j<i; j++){ 4.   computer similarity between trans(i) and trans(j) basedon  formula (1); 5.   if sim>=threshold 6.     arcWeight.addNewArc(sim, i, j); matrix[i][j]=1; 7.     else continue; 8.   } 9. for(i=1; i< transaction num; i++) 10.  subCluster[i]->push_back(i); end  Figure 5. Construct initialized Hypergraph Step 2 Greedy algorithm Add an edge that connects sub-graphs. The path  should have maximum similarity among all the paths.

Figure 6(a). Generate sub-graphs   Figure 6(b). Combine sub-graphs  Figure 6. Hypergraph clustering process The algorithm has time complexity O(|n|2). Merging  sub-clusters procedure is described as following.

Algorithm: merge sub-clusters via greedy algorithm Input:   (1)clusterNum: number of cluster;  (2)matrix: mapped hypergraph; (3)arcWeight:: weighted queue of arc;  Output:  clusterResult: result of clustering Procedure: begin  0-7695-2702-7/06 $20.00  ? 2006    1   for(i=0; i<arcWeight.size(); i++){ 2      fetch the first element of arcWeight; 3       If (subCluster[cor->i].size <transNum*0.1 &&  subCluster[cor->j].size()< transNum*0.1){ 4   combine all elements of subCluster[cor->j] into  subCluster[cor->i]; 5   Delete subCluster[cor->j] from subCluster; 6     } 7  delete cor from arcWeight; 8    } 9     merge sub-clusters from bottom to up; 10     i=0; 11    While( the number of sub-clusters <= clusterNum){ 12       find the maximum similarity with subCluster[q] 13       If(such q exits ) 14           merge subCluster[q] into subCluster[p]; 15       delete subCluster[q]; 16       i++; 17    If none of the two subClusters can be merged 18      return the function; 19    } End  Figure 7. The based greedy cluster algorithm  5. Experimental Evaluations  5.1. The results of cluster analysis   The procedure uses a 1.5GHz Pentium IV PC with 1GB of main memory, running Windows 2000 professional. All algorithms are coded in Visual C++ 6.0. There are 6576 data of children pneumonia are collected from the 15 hospitals.

Most of these patients have experienced several unknown syndromes, and each syndrome includes some symptoms, such as high fever, cough, red tongue etc. All patients in the used dataset were under drug treatment. Because of too many data, we just describe some main symptoms of the one of all patients.

Table 1. Original dataset used for clustering Object value  symptom 0 1 2 3 1 Fever    high  cough  medium tongue body  red tongue  coating yellow  complexion  pale color of  phlegm yellow  sound of phlegm  ring in the  throat    perspiration  some headache  yes pulse  smooth ??  Tip: There is only one value in each symptom.

When num of clusters=4 and similarity threshold=0.75 in hypergraph clustering, the first result of clustering (object clustering) is described in Table.2.

Table 2.Result of clustering No of cluster Number of objects  Cluster1 3045 Cluster2 2011 Cluster3 842  Tip:  Except for the above data, there are 148 objects need to be judged as outliers.

5.2. The data mining results after clustering  using hypergraph method   We acquire some important attributes through computing attribute probability in each cluster.

According to experience and above results, the expert gives names of cluster (so called syndrome) shown in Table.3.

Table 3. Rename the syndromes No of cluster Name of syndrome  Cluster1 Yin and xu pneumonia Cluster2 Phlegm and hot pneumonia Cluster3 Wind and cold pneumonia   5.3. Performance evaluations   When we attempt to cluster using k-means algorithm, clique and hypergraph algorithms under the same condition, we find clique algorithm can not be executed when number of dimension exceed 10.

Results are shown as table 4 when number of dimension is 40. Accuracy of the three algorithms is obtained with expert?s verification.

Table 4. Comparison of three cluster algorithms Algorithm Run Time(second) Accuracy k-means 189 57% clique - -  greedy hypergraph 206 92% We can observe from the figure 8 that the run time  of greedy algorithm tends to increase as the number of records. However, greedy algorithm is obviously faster than traditional hypergraph and graph algorithm.

1000 2000 3000 4000 5000 6000  number of records  r u n  t i m e  ( s e c o n d ) Graph  Hypergarph  Greedy Hypergraph   Figure 8. Run time with number of records   6. Conclusions   0-7695-2702-7/06 $20.00  ? 2006    Because TCM data is different from medical data, we analyze it with special method or model. It is important to design the appropriate hierarchy model.

Based on it, we can complete it via data mining methods. Considering traditional clustering algorithms handle TCM data unsatisfactorily, the paper presents a hypergraph based on greedy algorithm for clustering procedure. Experimental results demonstrate correctness and efficiency of our algorithm.

Acknowledge   This research has been supported by the National key Technologies R&D Program in the 10th Five-year Plan of China Grant No 2004BA721A05.

