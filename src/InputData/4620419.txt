MINING MULTILEVEL ASSOCIATION RULES WITH DYNAMIC CONCEPT  HIERARCHY

Abstract: Association rule mining has attracted wide attention in  both research and application areas recently. The mining of multilevel association rules is one of the important branches of it. In most of the studies, multilevel rules will be mined through repeated mining from databases or mining the rules at each individually levels, it affects the efficiency, integrality and accuracy. In this paper, a novel method is proposed to improve this situation by analyzing the rules mined from primitive concept level to obtain multilevel rules. The proposed method also supports dynamic concept hierarchies.

Keywords: Rule mining; Association rules; Multi-level association  rules; FP-tree; Concept hierarchy  1. Introduction  Association rule mining is introduced by Agrawal et al.

[1], which finds interesting association or correlation relationship among a large set of data items. With the increasing amounts of data stored in real application system, the discovery of association relationship attracts more and more attention. Mining for association rules can help in business decision making, and the development of customized marketing programs and strategies.

Taking market basket analysis as example, the mining problem can be described as: (1) given a database D of transactions, each transaction is a list of items; (2) find all rules that correlate the presence of one set of items with that of another set of items. Agrawal and Srikant proposed the Apriori [2] algorithm for fast association rule mining.

Apriori finds all rules of form X Y which satisfy some given support and confidence threshold parameters, where X, Y ? I, X Y=  ?  ? ? , and I = {i1, i2, ?, im} be a set of unique items in the database D. The support denoted by P(X Y) is the percentage of transactions in D that contain X Y. The confidence denoted by P(Y|X) is the percentage of transactions in D containing X that also contain Y. For example, ?sunshine-bread daisy-milk  [support=2%, confidence=60%]? represents ?60% of the customers who purchased sunshine-bread also bought daisy-milk, and 2% of all transactions under analysis show that sunshine-bread and daisy-milk were purchased together.?  ? ?  ?  However, for many applications, it is not always easy to find strong association rules (satisfying the minimum support and confidence) among data items at low (primitive) levels of abstraction due to the sparsity of data in multidimensional space. The reason has been discussed in [3]. Several algorithms have been proposed for mining of multilevel association rules [3, 4, 5, 6, 7, 8], the unsolved problem are: (1) lack of adequate support for dynamically required hierarchies; (2) algorithm accuracy and efficiency cannot satisfy real application requirements; (3) the association between different concept levels may be missed.

In order to address the above problems, our strategies are as follows: first, we mine from the prime data items using FP-growth [9, 10] to get the association rules of atomic level, called atomic rules. Then we mine multilevel rules which can be further classified to two types: the same-level rules with antecedent and consequent at the same level of concept hierarchy, and the cross-level rules with antecedent and consequent at different levels of concept hierarchy. The multilevel rules are mined based on analyses of the rules mined from atomic level, instead of using traditional methods which mine from database again.

Therefore, it has a good potential to reduce the computational complexity and I/O cost while accurately exploit same-level and cross-level association rules. In addition, our proposed method supports multiple hierarchies which can be dynamically constructed according to the input of user knowledge. The encoding scheme in [3] is adopted to group the association rules generated from atomic level.

The rest of the article is structured as follows. Section 2 introduces the novel method of mining multilevel association rules. In Section 3, the mining with dynamic       concept hierarchy is discussed. Section 4 further discusses issues including the calculation of rule support, the mining of multilevel association rules at specific levels, and the mining of a special kind of rules as a tradeoff between the mining of specific patterns and that of commonsense.

Finally, we conclude our work in Section 5.

2. A method for mining multilevel association rules  A method for mining multilevel association rules is introduced in this section, which first utilizes the FP-growth [9, 10] to mine from the prime data items to get the association at the atomic level (atomic rules).

When using the FP-growth algorithm at the process of constructing FP-tree, it is necessary to have an encoding scheme to encode the items according to the concept hierarchies given. We adopted the encoding scheme from [3], which uses an encoded string to represent a position in a hierarchy. This scheme is convenient for merging (or removing) the items according to their identical prefixes of encoding, and requires less bits than that used in the corresponding object identifier.

For the simplicity of discussion, we use an abstract example to explain how the encoding scheme works.

Example 1: Figure 1 shows a part of the food concept hierarchy from a shopping transaction database.

food  milk bread  skim 2% white whole wheat  DairyLand Lucern Wonder Safeway  ... ...

... ...Lv3  Lv2  Lv1  Lv0    Figure 1. An example of concept hierarchy   Suppose table 1 is the encoding table, then the item ?Wonder whole wheat bread? can be encoded as ?243?, in which the first digit ?2? represents ?bread? at level-l, the second digit ?4? for ?Whole wheat (bread)? at level-2, and the third digit ?3? for the brand ?Wonder? at level-3. The generalized items ?milk? and ?skim milk? can be encoded as ?1**? and ?11*? respectively. So we can merge the items ?121? and ?122? and represent the merged item as ?12*?. This merging method is useful for the rule analysis in the later stage.

Table 1. An example of encoding table  milk bread skim 2% white 1 2 1 2 3  Whole wheat DairyLand Lucern Wonder Safeway 4 1 2 3 4   The rest of the work consists of two major steps: (1)  generating new candidate high-level association rules through grouping and merging the atomic rules; (2) calculating the support and confidence of each rule, and selecting only strong rules. These two steps are iteratively executed until no more high-level relations can be found.

Before going to the details of the method of generating multilevel rules, we shall first introduce the concept of FP?-tree and its corresponding constructing method, and the method for calculating support and confidence of candidate rules.

FP?-tree is a higher concept FP-tree transformed from its lower level concept FP-Tree. The idea of FP?-tree is originally adopted from [7], but we use a different method for the construction. We use FP(l)-tree to denote the FP?-tree at the concept level l.

Figure 2 shows the algorithm of constructing FP (l)-tree given the FP-tree of atomic level and the support threshold of level l. In step 1, the form of items in header table as well as the nodes in FP-tree is changed to that of level l by replacing the digits which represent the lower levels with ?*?. The second step is to remove the items and nodes which do not satisfy given threshold, from the header table and FP(l)-tree. The final step is to adjust the FP (l)-tree by removing the repeated items and nodes, and fine-tune the remaining by the form of traditional FP-tree.

Algorithm 1 Input: FP-tree of atomic level, the support threshold  s of level l.

Output: FP(l)-tree.

Method: 1. Change all the items in the header table and all the  nodes in the FP-tree of atomic level into the form of level l.

2. For each item in the header table, if its support does not satisfy s, then remove it and its relative nodes from the header table and FP(l)-tree respectively.

3. For each item in the new header table, merge the identical ones and relative nodes in the FP(l)-tree.

(a) Remove the recurrent items and relative  nodes, and cumulate the support counts to keep ones respectively.

(b) Sort the items in the header table and nodes in the FP(l)-tree in descending order.

(c) Adjust the node-links and path-links in the FP (l)-tree.

Figure 2. Algorithm for constructing FP(l)-tree  Example 2: Figure 3 shows a FP-tree at the atomic  level, and we can get the FP(2)-tree in figure 4.

Figure 3. FP(3)-tree (atomic level)     Figure 4. FP(2)-tree   In order to avoid rescanning the database, we calculate the support and confidence of candidate rules from FP (l)-tree instead of the original database.

The algorithm (Fig. 5) is for computing the supports and confidences of candidate rules from FP(l)-tree. In step (a), we find some corresponding items in a single rule from FP(l)-tree. It is not possible to find the identical items from the nodes in FP(l)-tree if the rule is of cross-level, and in this case we just need find the nodes belong to the lower concept level of the item and get the support of the item by accumulating the support count of each such nodes.

Algorithm 2 Input: Candidate rule-set R1, FP(L)-tree for each  concept level, support threshold s and confidence c at each concept level.

Ai - the antecedent of rule ri?R1 represents; n - the total transactions; im - the item which has the lowest concept  level among the items in ri; FP(l)-tree - the corresponding FP-tree of the  concept level of im.

Output: The confirmed rule-set R1.

Method:  For each rule ri, if its support and confidence are NULL, calculate its support and confidence by following steps:  (a) Start from the head (in header table) of im, and follow its node-links and located paths in FP(l)-tree to find all other items, which belong to the lower concept levels of the items in ri  (b) Calculate the support counts of ri and Ai in each path which item im derives, and sum them respectively to get the support count si of ri and the support count si? of Ai.

(c) If si/n s and s? i/si? ? c, then keep the rule ri in the R1 and delete the corresponding rules which have the same group ID if they are atomic rules; else delete ri from the R1.

{}  243:4 111:1  Figure 5. The algorithm for computing the support and confidence of candidate rules   Example 3: Suppose there is a rule ?2** 11*? based  on the encoding shown in Table 1, and the support count threshold and confidence threshold of level-2 is 3 and 0.5 respectively. We have the following steps to compute its support and confidence using the FP(2)-tree in Example 2.

?  (a) We start from the head of ?11*? (in the header table) and follow node-links of ?11*? to find the node ?24*? and ?21*? in the paths which ?11*? derives, because 2** is not existed in FP(2)-tree and ?24*? and ?21*? belong to it.

(b) We find ?24*: 7? and ?21*: 3?, and take 3 + 7 = 10 as the support count of 2**. Therefore, the support count of rule ?2**? 11*? is 5, and the confidence is 5/10=0.5. This rule satisfies the thresholds, so it is what we want.

The method of generating multilevel rules from atomic rules is shown in Fig. 6. Suppose we have obtained atomic rules using FP-growth algorithm. First, we generate the candidate high-level rules from the atomic rules. This is implemented by grouping and merging the low-level rules according to their encoding. The grouping is carried out  {}  24*:7 11*:2  12*:1 11*:5  21*:3  12*:2  Header Table  Item  frequency  head  24*    7  11*    7  21*    3  12*    3  112:1  123:1  111:3 112:1  244:3  112:1211:2  123:2 211:1  Header Table  Item  frequency  head   243     4  111     4  244     3  112     3  211     3  123     3       based on the matching degree defined below.

Definition 1: For any two given items of length n (n ?  2): A = a1a2?an, and B = b1b2?bn, the matching degree of item is calculated by:  ??  ? ? ? =  = ? otherwise                     , 0  ba   , )b,m(a )B ,A(MI  n  1 11ii  ?  ?= n1 ii21 )B,A(MI)R,R(MR  (1)  Where m(a, b) (a?A, b?B) is the matching function of two bits in items, and it is calculated by   ba      ,  1 ba      , 0  )b a,( m ? ? ?  = ?  =               (2)  Definition 2: For any two given rules of total n (n ? 2) items in antecedent and consequent: R1: A1, A2, ?, Ai Ai+1, Ai+2, ?, An, R2: B1, B2, ?, Bi ?  Bi+1, Bi+2, ?, Bn, the matching degree of rule is calculated by  (3) We will choose rules which have the maximum  matching degree to group together. This grouping method is recursively applied until no more rules can be further grouped. The atomic rules that cannot be grouped into any group will be output directly because they may represent rare or special knowledge. Within each group, we generate the same-level or cross-level rules by merging the rules in it.

The key idea of merging method as shown in Example 1 is to try to make a maximum intersection among the similar items. We shall use this idea in algorithm 3. After the candidate generation is done, the next task is to verify their eligibility by calculating the support and confidence using the method introduced in algorithm 2. We can obtain the higher level rules from verified rules by executing the generation and verification process iteratively. The algorithm is given in figure 6.

Algorithm 3 Input: Association rules of atomic level R0, FP(l)-tree  for each concept level, support threshold s and confidence c at each concept level.

Output: Candidate rule-set R1.

Method: 1. Group the rules in R0 according to the amount of  the antecedents and consequents. The amount of the antecedents and consequents of each rule in a group should be uniform.

2. For each group which got in the step 1, if it only includes one rule, delete it and store its rule in rule-set R1; else make sub-grouping through matching the items of each rules. The grouping principle is as follows: (a) The rules in a group should have the  maximum matching degree of rule.

(b) If the rule cannot group with other rules, it can be stored in R1.

3. For each sub-group, make a maximum intersection to corresponding items of each rule to generate new rule, and then remove the identical items in new rule, if its antecedent or consequent is null, delete it and store all original rules in R1, else sign it and all original rules with group ID and store them in R1.

4. Get the verified rules from R1 by algorithm 2.

5. Replace the rules in R0 with new rules in R1, and  repeat step 1~4 to generate new rules, until no rule can be grouped together.

Figure 6 Algorithm of generating multilevel rules  Example 4: Suppose we have obtained the following  atomic rules from the database of Example 1 using FP-growth algorithm:  Rule 1: 243? 111,       Rule 2: 244? 112 Rule 3: 256? 125,       Rule 4: 257? 128  Obviously, the rule 1and 2 can be grouped together, because the antecedents and consequents of rule 1 and 2 have the same prefix ?24? and ?11? respectively. With the same spirit, rule 3 and 4 can also be grouped together for the identical prefix ?25? and ?12? in their antecedents and consequents respectively. Rule 1 and 3 cannot be grouped together although they have the same prefix ?2? and ?1?, because their matching degree of rule is not the highest in the current rule-set.

Therefore, we can merge rules 1, 2 and 3, 4 respectively to obtain the following two rules:  Rule 5: 24*? 11*,       Rule 6: 25*? 12* If the above rules are confirmed to satisfy the  threshold through algorithm 2, the process will be continued to generate new rules from them for the identical prefix ?2? and ?1? and so the candidate rule ?2**? 1**? will then be generated and its eligibility be further verified.

As a summary, given a concept hierarchy H with k (k 2) levels, the process of mining multilevel rules can be carried out through the following steps:  ?  1. Mining association rules from the atomic level using FP-growth algorithm;  2. Generate all possible new candidate multilevel rules from the above rules;  3. Obtain the strong rules by confirming the support and confidence of candidate rules using algorithm 2.

The step 2 and 3 are executed iteratively. As a result, the entire set of multilevel association rules generated by our approach is in the form of       ]c,s[    I,...,I,II,...,I ,I n2i1ii21 jn j  2i j  1i j i  j  j  ++ ++?  )nm1(I mjm ??  ?  (4)  Where  is an item at jm-th (0 < jm< k) level of H, and both s and c satisfy the threshold of level J = max (j1, j2, ?, jn).

3. Mining with dynamic concept hierarchy  Most of the recent research works for mining multilevel association rules don?t support dynamic concept hierarchies [3, 4]. However, it is necessary to mine the multilevel association rules according to the different valid organization of items. For example, supermarket managers may want to categorize sales items based on their location in the store. This requires to find rules of the form ?prime location in row 1 prime location in row 2?, which would tell the store that buyers who buy items which are displayed in the first row tend to buy items which are displayed in the second row. Quite often, it can?t satisfy the requirement of real-application with pre-defined concept hierarchies stored in database. Therefore, a dynamic concept hierarchy which can adaptively update with the real-time requirement would be very useful.

Our strategy is to design a user guide to guide the users to construct the concept hierarchy based on their knowledge and requirement, which utilizes the user interface and interactive operations to provide a convenient environment for user to describe their desired association relationship. Once the construction of concept hierarchy is completed, the system will automatically encode the items referred in the concept hierarchy, through the encoding scheme adopted from [3]. In this way, the concept hierarchy can be naturally connected to the related items. Therefore, the multilevel association rules mined by our system can be varied flexibly based on different views of user.

4.   Discussion  4.1 The calculation of rule support  The other issue is some inaccuracy may exist in the computation of support and confidence, because we compute them from the FP-tree, but not from the original database. The FP-tree is the compress version of original database by filtering the infrequence single items.

Therefore, the inaccuracy comes from the compression of FP-tree making toward the database. However, this inaccuracy usually very small and acceptable, and for many applications finding the relationship represented by rule is much more important than seeking for the accurate support and confidence.

4.2 Multilevel association rules at specific levels  In many situations, user does not need all the multilevel rules to be generated at once, to avoid display unnecessarily too many rules. The following algorithm is designed to generate the candidate association rules at user specified level.

Algorithm 4 Input: Association rules of atomic level R0, the  target concept level l1and l2 (0<l1, l2<k).

0 ~ k-1 - the range of concept level.

Output: Candidate rule-set R1 associates concept  level l1and l2.

Method: 1. If l1=l2=k-1, go to step 3, else for each rules in  R0, transform the antecedent and consequent to the form of target concept level l1 and l2 respectively by the following steps: (d) Change the uninterested digit (for the  antecedent: from (l1-1)-th digit to (k-1)-th digit; for the consequent: from (l2-1)-th digit to (k-1)-th digit) of each item to ?*?.

(e) Remove the identical items or rules.

2. Transform the antecedent and consequent to the  form of target concept level l2 and l1 respectively, the method is similar with that of step 1.

3. Store the rules in R1.

Figure. 7 Algorithm of generating candidate association rules at user specified level  4.3 The tradeoff between commonsense and specific patterns  For the decentralization of data in multidimensional space, the association rules mined from data of the atomic level is too specific for the real application, and the generation of strong rules is also very difficult. Therefore, the mining of multilevel association rules is studied by many researchers to get the rules at high concept levels.

However, strong associations discovered at higher concept levels may represent common sense knowledge, which is too generalized to be used in real application. With this understanding, we can make a tradeoff between the two kinds of rules. The cross-level rules can be viewed as a kind of tradeoff in some sense, but they only associate the items of different concept levels. For example, if we want to know ?main varieties of bread main varieties of milk?, it is difficult to obtain this kind of rules from current association rule mining approaches, because few people  ?       will purchase several varieties of bread and several varieties of milk in a transaction. This kind of rules can be useful in representing which kinds of bread have strong relations with which kinds of milk. Our algorithms can be extended to mining this kind of rules.

Example 5: Suppose A and B are generalized items, A={a1, a2, ?, am}, B={b1, b2, ?, bn}, am and bn are items of the low level concept. There are following strong rules:  Rule 1: ai1? ?  ?  bj1 [s1, c1], Rule 2: ai2 bj2 [s2, c2], ? Rule k: aik bjk [sk, ck].

Suppose the rule A?B is confirmed to be strong, and  ai1, ?, aik?A, bj1, ?, bjk?B, and the top two rules satisfy a given threshold. So we can merge them as ?ai1, aj2? bj1, bj2?. Of course, the threshold can be determined by user.

The result rule represents that ai1 or ai2 in A are frequently purchased with bj2 or bj2 in B.

5.  Conclusion  We proposed the approach of mining multilevel association rules by merging and grouping the rules at atomic level, which improves the mining efficiency without making the additional deviations to the FP(l)-tree, while realizing the mining of cross-level association rules. Further more, this approach can support dynamic hierarchies based on different views of organizing items, which allows different users get their desired association rules from customized point of view. We also discussed the issues of the calculation of rule support, multilevel association rules at specific levels and the tradeoff between commonsense and specific patterns and suggested possible solutions.

The proposed approach can be used to develop an association rule mining system. By introducing the dynamic feature of construction of concept hierarchy, it can also be encapsulated as a learning component and integrated with the knowware system introduced in [11, 12] to provide the knowledge source for other intelligent components.

Acknowledgements  This work was supported in part by the Macao Science and Technology Development Fund under Grant 048/2006/A.

