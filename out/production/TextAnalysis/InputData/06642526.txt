Adaptive Association Rule Mining for Web Video Event Classification

Abstract  Due to the popularity and development of social net- works and web video sites, we have witnessed an exponen- tial growth in the volumes of web videos in the last decade.

This prompts an urgent demand for efficiently grasping the major events. Nevertheless, the insufficient and noisy text information has made it difficult and challenging to mine the events based on the initial keywords and visual fea- tures. In this paper, we propose an adaptive semantic as- sociation rule mining method in the NDK (Near-Duplicate Keyframes) level to enrich the keyword information and to remove the words without any semantic relationship. More- over, both textual and visual information are employed for event classification, targeting for bridging the gap between NDKs and the high-level semantic concepts. Experimental results on large scale web videos from YouTube demonstrate that our proposed method achieves good performance and outperforms the selected baseline methods.

Keywords: Web Video Event Classification, Adaptive As- sociation Rule Mining, Near-Duplicate Keyframes (NDK).

1. Introduction  Due to the fast advancement of multimedia technologies, the number of web videos has been growing explosively in the past decade. In China, there are many video-distributing web video sites emerged in the past several years like Y- ouKu, TuDou, etc. It is easier for the users to get a large number of relevant web videos about ongoing incidents or events through search engines or video sharing websites.

Generally, many users prefer to watch web videos, rather than from the news documents, to get the most updated s- tatus or progress of major events and hot topics. Moreover, most of the users first want to know the major events and  then to construct their relationship in minds. However, it is still a challenge for the users to grasp the major events after a glance at the search results. In fact, it is really daunting for the users to view from one video to another one to select the hot topics (events of interests), not to mention for them to manually summarize the videos after watching all of them at the same time. This is not only highly time consuming but also difficult for them, especially for the unfamiliar top- ics. Therefore, it is becoming critical to automatically group relevant web videos together.

To mine events, both visual and textual information con- tain rich information. Generally speaking, for visual infor- mation, important shots might be frequently inserted into videos as a reminder or support of viewpoints, while useful visual information is usually embedded in them. According to visual content information, these duplicate keyframes can be classified to groups, where each group is called an ND- K (near-duplicate keyframe)[10] group. NDKs are useful information to mine videos with similar contents. Howev- er, for the textual information, web videos generally con- tain much less text information than traditional documents, because the number of user-supplied text information (title and tags) is limited. Moreover, even with titles and tags, they still exhibit noisy, ambiguous, and sometimes incom- plete features. To make matters worse, the users might add irrelevant hot terms (words) to attract the attention. As a result, the discriminative capability of text characteristics is exacerbated in the web scenes. This motivates us to explore the grouping of semantic related terms together through an adaptive association rule mining (ARM) method. It is be- lieved that making use of the grouped terms to find the statistics and distribution characteristics in near-duplicate keyframe group can improve the performance of event clas- sification to enhance their robustness.

In this paper, we propose a novel framework, which dis- covers the statistics and the distribution characteristics of     the grouped terms in clustered keyframes for web video event classification. In our proposed framework, an adap- tive association rule mining method is first developed to address the issues related to the noisy data and the scarce textual information. Second, transitive closure is applied to group the terms together, while the semantic relationship- s between terms help better bridge the gap between NDKs and the high-level semantic concepts. Finally, three clas- sifiers are used to evaluate the NDK-level event similarity with the assistance of the textual information that are more stable than the single terms. Moreover, both terms and ND- Ks with relatively low frequencies are still considered as useful information in the experiments, while the web videos without duplicate content information are taken as noise.

The rest of this paper is organized as follows. Section 2 gives a brief overview of the related work. The details of the framework for web video event classification is discussed in Sections 3. The experiments and results are presented in Section 4. Finally, Section 5 concludes this paper.

2. Related Work  2.1 Topic Detection and Tracking  The goal of topic detection and tracking (TDT) is to de- tect new topics and track the known events in text news streams, while an event is something that happens at a spe- cific time and place, along with all the necessary precondi- tions and unavoidable consequences [3]. In fact, web video event classification is considered to belong to the task of T- DT. In the text research areas, much work [5, 6, 8, 25, 32] has been done about TDT. There are also many research studies about TDT in the multimedia research areas. For example, topics are tracked with visual duplicates and se- mantic concepts [9, 16]. The concept of near-duplicate keyframes (NDK) has abundantly used in real applications [23, 31]. An NDK is a set of similar keyframes but with certain variations induced by the acquisition times, light- ing conditions, and editing operations [10]. NDK detec- tion is to calculate the keyframe similarity among videos.

The retrieval of NDKs plays an important role in measur- ing video clip similarity and tracking video shots of multi- lingual sources [10, 20, 29, 35]. With the assistance of NDK constraints, news stories are clustered into topics by constraint-based co-clustering [30].

Recently, a very popular trend is to integrate both tex- tual and visual information for web video event classifica- tion. For example, a trajectory-based approach presented in [2] is used to discover, track, monitor, and visualize web video topics. With textual correlation and keyframe match- ing, topic clusters are grouped in [4] and news stories from different TV channels are linked in [34]. Topic discovery is deployed by constructing the duality between stories and  textual-visual concepts through a bipartite graph [17, 29].

Events are discovered by text co-occurrence and visual fea- ture trajectory in [28].

2.2 Association Rule Mining (ARM)  Association rule mining (ARM) is known to discover in- teresting and useful co-occurring associations among data in large databases [1, 22], and has also been widely adopted in multimedia research to bridge the semantic gap between low-level multi-modal features and the concepts of interest.

The number of discovered association rules in a data mining application is typically huge, which makes it difficult for the users to identify those rules that are of particular interest to them. This calls for the need to remove the insignificant rules so that more interesting rules can be utilized.

There are three categorized interestingness measures for generating and selecting rules: objective measures, subjec- tive measures, and semantic measures as described in [7]. In [13], the authors mentioned that the objective measures can be calculated based on probability, statistics, distance, or in- formation theory, while most of the criteria depend only on the data characteristics. The objective measures can be used to prune the rules for web image clustering, as instructed in [19]. On the other hand, an approach is introduced in [11] to aggregate a set of objective interestingness measures using the Choquet integral as the aggregation operator to find the most interesting association rules. A interestingness analy- sis system (IAS) is developed to assist the users in finding unexpected rules from a set of discovered association rules [15]. A ShotRank notion is introduced in [33] as a measure of subjective interestingness measure for a video browsing and summarization system. The authors in [12] introduced the utilization of Multiple Correspondence Analysis (MCA) as a utility-based semantic measure for association rule gen- eration.

Though ARM has been utilized in many applications, it has not been utilized in finding the associations of the visual features of NDKs. This motivates the study of using the distribution characteristics information of terms in NDKs to improve the performance of event classification, especially an adaptive association rule mining approach.

3. Proposed Framework  This paper proposes a novel framework that performs web video classification via the use of an adaptive associ- ation rule mining (ARM) method for semantic relationship detection. The proposed framework is illustrated in Fig- ure 1. As can be seen from this figure, it consists of three stages, namely data preprocessing, adaptive association rule mining, and classification.

Figure 1. The proposed web video event clas- sification framework.

In the data preprocessing stage, near-duplicate keyframes (NDKs) are first detected from keyframes of the web videos. For the visual data sets, to ensure good performance of NDK detection between videos, local points are detected with Harris-Laplace and are described by SIFT [18]. The public available tool proposed in [36] is adopted to detect the NDKs. The detected NDKs are further grouped to form clusters by transitive closures.

As NDKs have the unique property of identifying similar events, all NDKs are considered as the features. For the textual data sets, the terms extracted from titles and tags are used as textual features. Due to the noisy user-supplied tag information, special characters (e.g., #, >, ?, |) are first removed, and then text words are pruned by word stemming, Chinese word segmentation, and so on. Finally, all features and the class labels are combined to form an indicator matrix with instances (i.e., NDKs) as rows and the categories of variables (i.e., Terms) and the concepts (or class labels) as columns.

In the adaptive association rule mining stage, to better discover the association patterns from the noisy terms, an adaptive association rule mining method is first develope- d, where an adaptive support value is selected for different lengths of items according to the F1-score value calculated by the classifiers. Next, transitive closure is used to com- bine the related terms to groups.

In the classification stage, every NDK is grouped into  the event with the largest similarity. In order to prove the effectiveness of the proposed method, the K-Nearest Neigh- bor (KNN), NaiveBayes (NB), and Support Vector Machine (SVM) classifiers are applied to calculate the similarity be- tween each NDK and the class, respectively.

3.1. Adaptive Association Rule Mining  Hot terms are frequently appeared in related videos. S- ince semantic related terms usually carry useful informa- tion, they can be used to group related videos, even with similar themes but different visual content. However, due to multi-language, multi-semantics, polysemy and synonyms problems, highly related web videos might be annotated with different words. There are numerous frequently ac- companied terms that convey useful information, and thus it makes sense that semantic related terms can be used to i- dentify related web videos together. For this purpose, ARM is applied to improve the performance by pruning the noise and strengthen the important terms and their semantically related words with higher weights.

T =< T1, T2, T3, . . . , Tn) > (1)  Let T be a set of terms (as shown in Equation (1)). We first use the traditional ARM to get the candidates of k- itemsets as shown in Table 1. Next, let Ti and Tj be two Terms. The rationale is that the more common videos they contain, the more similar they are. Due to the different fre- quencies of the terms, taking the frequency as the support value might lose a large number of Non-Hot Words which may contain useful information. Therefore, to capture the support value, the Jaccard coefficient is adopted to measure the similarity between Ti and Tj , as shown in Equation (2).

Support(Ti, Tj) = |Ti  ? Tj |  Min(Ti, Tj) (2)  where |Ti ?  Tj | is the number of overlapped videos, and Min(Ti, Tj) is the minimum number of videos contained in Ti and Tj .

Since there are different frequencies in the term pairs, us- ing the same threshold value may be improper. In order to find the best support value for different lengths of items, the support value distribution range is first divided into 10 seg- ments (0.1 to 1.0) as shown in Figure 2, with the horizontal and vertical axes representing the support and F1-score val- ues, respectively. Then, the support values are sorted in an ascending order without the duplicate values for the train- ing data set. In each iteration, a different threshold value is applied to the training data set. Finally, the one with the highest F1-score (evaluated by the classifiers) is selected as the support value. For example, in Figure 2, the value of the 9th (0.9) interval is chosen as the threshold value as it achieves the highest F1 score.

Figure 2. Adaptive support value selection.

Table 1. Frequent itemsets from adaptive ARM  1-Items 2-Items ? ? ? N-Items T1 T1, T2 ? ? ? T1, T2, T3 ? ?? T2 T2, T3 ? ? ? T5, T6, T7 ? ?? T3 T5, T6 ? ? ? T11, T12, T13 ? ?? ? ? ? ? ? ? ? ? ? ? ? ?  Common terms between two term groups (Gi and Gj) denote that they are still high correlated. If the score is above a certain threshold value, they can be regarded as similar, denoted as Gi ? Gj . This is a symmetric mea- sure, which also implies that Gj ? Gi. For certain cases, there may also be relationships among term groups even if they have no common videos. This is because that they rep- resent the same theme of the videos. Hence, if Gi ? Gj and Gj ? Gk, then we assume that there exists the associ- ation Gi ? Gk. Therefore, the transitive closure is used to combine related term groups together.

3.2. Classification  After obtaining the grouped terms (Gi), the correlation between grouped terms Gi and near-duplicate keyframe groups NDKj can be expressed in the form of matrix as shown in Table 2, which is represented in a 2-dimensional NDK-Term matrix (NT), where each element NT ij in NT is defined in Equation (3).

NT ij = F (i, j) ?  N(j) ? log N  D(Gi) , (3)  where F (i, j) is the frequency of term group Gi appeared in NDKj ,  ? N(j) is the frequency of all the term groups  appeared in NDKj , D(Gi) is the number of NDKs that contain Gi, and N is the total number of NDKs.

Next, data instances are split into a training set and a test- ing set. For each class, one half of the data set are randomly selected as the training set, while the other half are taken as the testing set. The main reasons of this process can be shown as follows. On one hand, the splitting is able to mit- igate any bias caused by the particularly chosen instances;  Table 2. Training dataset after terms grouping  G1 ? ? ? GN Class NDK1 NT  1 ? ? ? NTN1 0  NDK2 NT 2 ? ? ? NTN2 1  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  On the other hand, each class being properly represented in both training and testing sets could be guaranteed.

Finally, in order to prove our proposed adaptive ARM is an effective method, three popular classifiers are used. WE- KA [26, 27] provides the implementations of these three classifiers, namely K-Nearest Neighbor (KNN) where K=3, Native Bayes (NB), and Support Vector Machine (Sequen- tial Minimal Optimization) (SVM).

4. Experiments and Results  4.1. Data Set Information  We use the data set given by [28] for evaluation, which consists of 19,972 web videos and 803,346 keyframes.

These videos are from YouTube and most of the videos were collected in May 2009. The topics are selected based on the top 10 news happened during 2006 to 2009 as recommend- ed by CNN, TIMES, and Xinhua. We select 14 hot topics shown in Table 3, which basically cover different charac- teristics of topics for the experimental evaluation. For ex- ample, topic ?Virginia tech massacre? only spans for one month from April to May of year 2007. However, the top- ic ?California wildfires? happened periodically for sever- al years, when the content is relatively homogeneous. To ensure fairness, those events having fewer than five web videos are regarded as noise and pruned out. Therefore, 10,716 videos, 35,555 NDKs, and 41,814 terms are used as the data set in the experiments. The detailed information of the dataset is listed in Table 3. Each topic is composed of several events. Take topic ?Russian President Election? as an example, where it contains 6 events: ?election relat- ed news?, ?Putin and Medvedev news?, ?Election Day?, ?Comment After Election?, ?Medvedev sworn in news?, and ?Medvedev president video?. For the ground truth, we collected the data by searching each topic from Wikipedia and Google, and then manually decided the ground truth.

4.2. Evaluation of The Framework  The Precision (P), Recall (R), and F1 measure (F1) are selected to evaluate the performance of event classification, as defined in Equations (4), (5), and (6).

Precision = |B+i | |Ai| (4)     Table 3. Dataset information  ID Topic Videos# NDK# Terms# Events# 1 Beijing Olympics 1,098 4,593 4,861 17 2 Mumbai terror attack 423 1,741 1,569 5 3 Russia Georgia war 749 2,823 2,316 7 4 Somali pirates 410 1,405 2,178 5 5 Virginia tech massacre 683 1,865 1,621 2 6 Israel attacks Gaza 802 3,087 3,546 4 7 Beijing Olympic torch relay 652 2,448 1,949 12 8 Sichuan earthquake 1,458 4,963 4,806 6 9 California wildfires 426 1,631 3,025 6 10 London terrorist attack 784 2,183 4,228 5 11 Oil price 759 2,486 3,814 5 12 Myanmar cyclone 613 2,698 1,624 4 13 Kosovo independence 524 969 1,593 5 14 Russian president election 1,335 3,930 4,684 6  Total 10,716 35,555 41,814 89  Recall = |B+i | |Bi| (5)  F1 = 2? Precision?Recall Precision+Recall  (6)  where B+i is the number of correctly grouped positive videos for cluster Ai, and Bi is the number of positive sam- ples in the ground truth.

To fully evaluate our framework, we first evaluate the performance of the proposed adaptive ARM method with three classifiers(KNN, SVM, NB). In order to be fair to the other classifiers, the original features and default parameter setting in WEKA are used. Next, the comparison is con- ducted among the results of the adaptive ARM method a- gainst two baseline methods, namely the simplified versions of the proposed methods in [8] and [28]. The performance comparison of the F1-score values is presented in Figure 3, with the abscissa and ordinate representing the topics and F1-score values, respectively. Due to the trade-off between Precision and Recall, a better F1-score value is usually con- sidered as the better performance to demonstrate the accu- racy of a framework. Hence, the focus of the performance comparison is on the F1 measure.

Tables 4, 5, and 6 show the Precision, Recall and F1- score values of fourteen topics for each classifier by using the original single term, term clustering method in [32], and our proposed framework with the adaptive ARM method, respectively. For each topic, the best Precision, Recall and F1 are highlighted in bold in these tables. As can be seen from these three tables that the average precision values of our proposed framework are higher than the other two methods in most of the instances. However, the single ter- m approach gets a better average Recall value, since it is inevitable that there are missing words with useful informa- tion. Moreover, our framework obtains better F1-score val- ues than the other two methods, with the average maximum  Figure 3. Comparison of F1-scores.

value up to 54% in Table 5.

The method of text feature trajectories in [8], demon-  strates that text information alone is not enough for event classification. In [28], its performance is better than the method in [8]. However, it can be seen that its perfor- mance is still not good enough. Because it misses those low-frequency terms and NDKs, while they contain a large number of web videos information. The visual feature tra- jectory of NDKs is not consistent. Hence, the authors in [28] attempt to use term co-occurrence to compensate the defects for visual information. However, the frequent pat- terns miss some information for event classification too.

Figure 3 shows the F1-score performance comparison.

It is clear to see that our proposed framework achieves promising results compared to both baseline methods since the F1 values of our proposed framework are significant- ly higher. It is even more encouraging to see that the best result reaches 67%, with similar time and space complex- ities. This can be inferred from the results that an impor- tant event is often accompanied with a set of representa- tive terms. Hence, semantic related terms are good cues for grouping related videos into events. The proposed method can be easily extended to a huge data set, though it may in-     Table 4. Performance comparison - KNN  Topic TFIDF (KNN) CC (KNN) [32] Association Rule (KNN)P R F1 P R F1 P R F1 1 0.41 0.44 0.42 0.48 0.39 0.43 0.65 0.37 0.47 2 0.31 0.52 0.39 0.34 0.50 0.41 0.42 0.50 0.46 3 0.55 0.24 0.34 0.64 0.25 0.36 0.55 0.38 0.45 4 0.32 0.54 0.40 0.41 0.60 0.49 0.40 0.58 0.48 5 0.69 0.80 0.74 0.71 0.79 0.75 0.71 0.78 0.74 6 0.40 0.72 0.52 0.44 0.61 0.51 0.48 0.62 0.54 7 0.34 0.53 0.42 0.48 0.51 0.49 0.57 0.25 0.35 8 0.55 0.40 0.47 0.46 0.35 0.40 0.64 0.39 0.49 9 0.49 0.45 0.47 0.67 0.31 0.42 0.56 0.71 0.63 10 0.21 0.75 0.33 0.33 0.67 0.45 0.32 0.67 0.43 11 0.23 0.78 0.35 0.45 0.46 0.46 0.62 0.55 0.58 12 0.33 0.62 0.43 0.39 0.57 0.46 0.39 0.59 0.47 13 0.84 0.50 0.62 0.75 0.38 0.50 0.80 0.48 0.60 14 0.30 0.50 0.38 0.32 0.53 0.40 0.83 0.33 0.47  Average 0.43 0.56 0.45 0.49 0.49 0.47 0.57 0.51 0.51  Table 5. Performance comparison - SVM  Topic TFIDF (SVM) CC (SVM) [32] Association Rule (SVM)P R F1 P R F1 P R F1 1 0.53 0.44 0.48 0.62 0.38 0.47 0.68 0.36 0.47 2 0.31 0.46 0.37 0.42 0.49 0.45 0.44 0.63 0.52 3 0.49 0.17 0.25 0.68 0.30 0.41 0.60 0.35 0.44 4 0.34 0.59 0.43 0.40 0.55 0.46 0.46 0.59 0.52 5 0.69 0.80 0.74 0.71 0.79 0.75 0.65 0.61 0.63 6 0.49 0.67 0.56 0.47 0.64 0.54 0.54 0.62 0.58 7 0.47 0.48 0.47 0.59 0.53 0.56 0.65 0.42 0.51 8 0.51 0.30 0.38 0.69 0.49 0.58 0.46 0.27 0.34 9 0.50 0.55 0.53 0.70 0.32 0.44 0.88 0.52 0.65 10 0.22 0.68 0.33 0.34 0.74 0.46 0.32 0.69 0.43 11 0.30 0.63 0.41 0.56 0.59 0.57 0.63 0.71 0.67 12 0.31 0.60 0.41 0.40 0.66 0.50 0.47 0.61 0.53 13 0.83 0.49 0.61 0.82 0.42 0.55 0.90 0.51 0.65 14 0.34 0.63 0.44 0.43 0.50 0.46 0.48 0.64 0.55  Average 0.45 0.53 0.46 0.56 0.53 0.51 0.58 0.53 0.54     crease the time complexity in the training phase for more textual information processing. However, it can reduce the space complexity as the dimension of the textual informa- tion is smaller. Compared to the traditional Adaptive ARM in [14, 21, 24], on one hand, we take F1-score values to evaluate the results to consider both the Precision and Re- call values; on the other hand, the method of calculating the support value takes into account the characteristics of tex- tual information about web videos. That is, high-frequency and low-frequency terms may also have a high relationship due to different writing habits of web users.

5. Conclusion  With the fast development of the Internet, it becomes an pressing need for the users to be able to quickly find out the major event. Considering the distinct characteristics of the web video, namely the limited features, the unavoid- able NDK detection problem, and the noisy and less text in- formation, web video event classification has always been a challenging task. In this paper, a novel adaptive ARM- based framework is proposed for web video event classifica- tion, which applies the proposed adaptive ARM method to address the noisy and less textual information issues. Nex- t, semantic textual information is used to help better bridge the gap between NDKs and the high-level semantic con- cepts. Moreover, both textual and visual features with rela- tively low frequencies are considered useful information in our proposed framework.

