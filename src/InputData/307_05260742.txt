Maintaining Pre-large FUSP Trees for Record Deletion

Abstract   In the past, a pre-large fast-updated sequential pattern tree (pre-large FUSP tree) structure was proposed to effectively handle newly inserted customer sequences for data mining. Since data deletion also commonly occurs in real applications, in this paper, we thus propose a maintenance algorithm for pre- large FUSP trees when records are deleted from the mined database. Pre-large sequences act like buffers and are used to reduce the movement of sequences directly from large to small and vice-versa when records are deleted. Experimental results also show that the proposed pre-large FUSP-tree maintenance algorithm for record deletion has a good performance when compared to the batch maintenance algorithm.

1. Introduction   Mining sequential patterns was first proposed by Agrawal et al. in 1995 [4], and is a non-trivial task. It attempts to find customer purchase sequences and to predict whether there is a high probability that when customers buy some products, they will buy some other products in later transactions. The sequential patterns may, however, become invalid when new customer sequences occur or old customer sequences are removed. Sequential patterns that do not originally exist may emerge as well. Designing appropriate maintenance algorithms for it is thus important.

Conventional approaches may re-mine the entire database to get correct sequential patterns for maintenance. Lin et al. proposed the FASTUP algorithm [11] to maintain sequential patterns by  extending the FUP algorithm [3]. Cheng et al.

proposed the IncSpan (Incremental mining of sequential patterns) algorithm for efficiently mining sequential patterns from a tree structure [5]. Lin et al.

also modified the FP-tree structure [6] and designed the fast updated sequential pattern tree (FUSP tree) to efficiently handle newly inserted customer sequences [10]. Hong et al. then proposed a pre-large FUSP-tree maintenance algorithm [8] for record insertion based on the pre-large concept [7].

In addition to record insertion, record deletion is also commonly seen in real-world applications. In this paper, the pre-large FUSP-tree maintenance algorithm for record deletion is thus proposed. It can be shown to have a better performance than the original batch maintenance algorithm for record deletion.

2. Review of Related Works   Mining association rules is the basic technique for  data mining [1][2]. Han et al. proposed the Frequent- Pattern-tree (FP-tree) structure for efficiently mining association rules without generation of candidate itemsets [6]. The FP-tree mining algorithm consists of two phases. The first phase focuses on constructing the FP tree from the database, and the second phase, called the FP-growth procedure, focuses on deriving frequent patterns from the FP tree. A Header_Table is also kept to record the frequent items and their links to the tree.

Mining sequential patterns is much harder than mining association rules since the former must consider both itemsets and sequences. In the past, the concept of pre-large sequences was used to mine sequential patterns in an incremental way [7]. A pre-   DOI 10.1109/NISS.2009.194    DOI 10.1109/NISS.2009.194    DOI 10.1109/NISS.2009.194    DOI 10.1109/NISS.2009.194     large sequence is not truly large, but nearly large. A lower support threshold and an upper support threshold are used to realize this concept. The upper support threshold is the same as the minimum support used in the conventional sequential-pattern mining problem.

The support ratio of a sequence must be larger than the upper support threshold in order to be considered large.

On the other hand, the lower support threshold defines the lowest ratio for a sequence to be treated as pre- large. A sequence with a support ratio below the lower threshold is thought of as a small sequence. The pre- large sequences act like buffers and are used to reduce the amount of rescanning the database.

When records are deleted from a database, the following two situations may occur.

1. All of the records from an old customer are deleted. This will also delete the corresponding customer sequences. The number of customer sequences thus decreases.

2. Parts of the records from an old customer are deleted. This will not change the number of customer sequences. Some itemsets are, however, removed from the existing customer sequences, thus decreasing the counts of some sequential patterns.

Considering an original customer sequences and the deleted customer sequences in terms, the nine cases illustrated in Figure 1 may occur [12].

Large sequences  Original database  New transactions  Case 1      Case 2      Case 3  Case 4      Case 5      Case 6  Case 7      Case 8      Case 9  Original customer sequences  Deleted customer sequences  Case 1      Case 2      Case 3  Case 4      Case 5      Case 6  Case 7      Case 8      Case 9  Pre-large sequences  Small sequences  Large sequences  Pre-large sequences  Small sequences  Figure 1: Nine cases arising from the original database and the deleted records   When large and pre-large sequences are kept, all the  above cases except case 9 can be easily handled. It has been formally shown that a sequence in case 9 cannot possibly be large for the entire updated database as long as the number q of deleted customers (with all their records are deleted) is smaller than a safety bound shown below [12]:  , )(  u  lu  S dSS  q ?  ?  where q is the number of deleted customers, d is the number of customer sequences from the database, Su is the upper threshold, and Sl is the lower threshold.

3. The Pre-Large FUSP Tree Structure   The adopted pre-large FUSP-tree structure is shown in Figure 2. It consists of both the Header_Table and the Pre_Header_Table, with links to the tree. The Header_Table keeps the large 1-sequences and the Pre_Header_Table keeps the pre-large 1 sequences, respectively sorted in the order of their frequencies.

There are two kinds of relations in the tree as in [5].

One is the sequence-extended sequence (SES), marked as s and the other is itemset-extended sequence (IES), marked as i. The former represents sequences and the latter represents itemsets.

{root}  a:5  b:3  c:2  g:1 g:1  e:1  b:1  c:1  a:1  g:1  e:1  b:1  c:1  g:1  e:1 i  s s s s  s i  i  s  i  s  s  i s  s  Header_Table  Item Frequency  Link a             6 b             5 c             4 g             4  Pre_Header_Table  Item Frequency  Link e             3   Figure 2. An example of Pre-large FUSP trees   4. The proposed maintenance algorithm   The detail of the proposed maintenance algorithm is described below. The global variable, c, is used to accumulate the number of deleted customers since the last re-scan of the entire updated database.

The Pre-large FUSP-tree maintenance algorithm for record deletion: INPUT: A set of large and pre-large itemsets in the  original database D consisting of (d-c) customer sequences, its corresponding Header_Table, Pre_Header_table and Pre- large FUSP tree, a lower support threshold Sl, an upper support threshold Su, and a set of t deleted customer sequences transformed from deleted records.

OUTPUT: A new pre-large FUSP tree after the deleted records are processed.

STEP 1: Calculate the safety bound f as follows:     .)(  u  lu  S dSSf ?=  STEP 2: Count the number q of deleted customers (with all their records are deleted) from the t deleted customer sequences.

STEP 3: Scan the deleted customer sequences to get all the 1-itemsets  and their counts.

STEP 4: Divide the 1-itemsets in the deleted customer sequences into three parts according to whether they are large, pre-large or small in the original customer sequences.

STEP 5: For each 1-itemset I which is large in the original customer sequences, do the following substeps (Cases 1, 2 and 3): Substep 5-1: Set the new count SU(I) of I in  the entire updated database as: SU(I) = SD(I) - ST(I),  where SD(I) is the count of I in the Header_Table (original database) and ST(I) is the count of I in the deleted customer sequences.

Substep 5-2: If Su ?  SU(I)/(d-c-q), update the count of I in the Header_Table as SU(I), and put I in the set of Reduced_Items, which will be further processed in STEP 8;  Otherwise, if S1 ?  SU(I)/(d-c-t) < Su, remove I from the Header_Table, put I in the head of Pre_Header_Table with its updated frequency SU(I), and keep I in the set of Reduced_ Items;  Otherwise, I is small after the database is updated; remove I from the Header_Table and connect each parent node of I directly to its child node in the Pre-large FUSP tree.

STEP 6: For each 1-itemset I which is pre-large in the original database, do the following substeps (Cases 4, 5 and 6): Substep 6-1: Set the new count SU(I) of I in  the entire updated database as: SU(I) = SD(I) - ST(I).

Substep 6-2: If Su ?  SU(I)/(d-c-q), I will be large after the database is updated; remove I from the Pre_Hedaer_Table, put I with its new frequency SD(I) in the end of Header_Table, and put I in the set of Reduced_ Items;  Otherwise, if S1 ?  SU(I)/(d-c-t) < Su, I is still pre-large after the database is updated; update I with its new frequency SD(I) in the Pre_Header_Table and put I in the set of Reduced_ Items;  Otherwise, remove I from the Pre_Header_Table and connect each parent node of I directly to its child node in the Pre- large FUSP tree.

STEP 7: For each deleted record with an item J existing in the Reduced_Items, subtract 1 from the count of J node at the corresponding branch of the Pre-large FUSP tree.

STEP 8: For each 1-itemset I which is neither large nor pre-large in the original database but small in the deleted transactions (Cases 9), put I in the set of Rescan_Items, which is used when rescanning the original customer sequences in STEP 9 is necessary.

STEP 9: If c + q ?  f or Rescan_ Items is null, then do nothing;  Otherwise, do the following substeps for each 1-itemset I in the set of Rescan_Seqs: Substep 9-1: Rescan the original customer  sequences to decide the original count SD(I) of I.

Substep 9-2: Set the new count SU(I) of I in the entire updated database as:  SU(I) = SD(I) - ST(I).

Substep 9-3: If Su ? SU(I)/(d-c-q), I will  become large after the database is updated; put I in the Branch_Items and insert I to the end of the Header_Table according to the descending order of their updated counts; Otherwise, if S1 ? SU(I)/(d-c-t) < Su, I will become pre-large after the database is updated; put I in the sets of Branch_Items, and insert I in the Branch_Items to the end of Pre_Header_Table according to the descending order of their updated counts.

Otherwise, do nothing.

Substep 9-4: For each original customer sequences with a 1-itemset J existing in the Branch_Items, if J has not been at the corresponding branch of the Pre-large FUSP tree for the     customer sequences, insert J at the end of the branch and set its count as 1; Otherwise, add 1 to the count of the node J.

STEP 10: If c + q > ?, then set d = d - c - q and c = 0; Otherwise, set c = c + q.

Note that in STEP 8, a corresponding branch is the branch generated from the large and pre-large 1- itemset in a transaction and corresponding to the order of sequences in the databases. Based on the pre-large FUSP tree, the desired large sequences after records are deleted can be determined by using the FP-growth- like approach as proposed in [6].

5. An Example   In this section, an example is given to illustrate the proposed deletion algorithm for maintaining the sequential patterns based on pre-large FUSP trees when records are deleted. Assume a database has three attributes, Cust_id, Trans_times, and Trans_items.

Table 1 shows a database to be used in the example. It contains 8 customers, sixteen records and 7 items, denoted a to g.

Table 1. The sixteen records with eight customers  Cust_id Trans_times Trans_items 1 1998/01/01 a 1 1998/01/20 b 2 1998/01/11 c, d 2 1998/02/02 a 2 1998/02/11 e, f, g 3 1998/01/07 a, h, g 4 1998/02/09 a 4 1998/02/19 e, g 4 1998/02/23 b 5 1998/01/05 b 5 1998/01/12 c 6 1998/01/05 a 6 1998/01/13 b, c 7 1998/01/01 a 7 1998/01/17 b, c, d 8 1998/01/23 e, g   The records in Table 1 are thus transformed into  customer sequences and shown in Table 2.

Table 2. The transformed customer sequences  Cust_id Trans_items 1 <(a)(b)> 2 <(c, d)(a)(e, f, g) 3 <(a, h, g)> 4 <(a)(e, g)(b)>  5 <(b)(c)> 6 <(a)(b, c)> 7 <(a)(b, c, d)> 8 <(e, g)>   Assume Sl is set at 30% and Su is set at 50%. The  pre-large FUSP tree is then formed from the database, with the results the same as that in Figure 2.

Assume the two records shown in Table 3 are deleted. Initially, the global variables c is at 0.

Table 3. Two deleted records Cust_id Customer sequence  2 <(c, d)> 8 <(e, g)>   The safety bound is calculated as:  .2.3 5.0  8)3.05.0()( =?=?= u  lu  S dSSf  Since all the records with the customer 8 is deleted from the customer sequence, the variable q is thus set at 1. The deleted two records are thus scanned to get all 1-itemsets with their counted, and each 1- itemset are individually processed according to whether they are large (appearing in Header_Table), pre-large (appearing in Pre_Header_Table) or small in the original customer sequences. The final results after STEP 7 are shown in Figure 3.

{root}  a:5  b:3  c:2  g:1 g:1  e:1  b:1  a:1  g:1  e:1  b:1  c:1  s s s  s i  i  s  i  s  s  i  s s  Header_Table  Item Frequency  Link a             6 b             5 c             3 g             3  Pre_Header_Table  Item Frequency  Link e             2   Figure 3. The final updated pre-large FUSP tree   The variable c is thus set as c = c + q = 0 + 1 = 1.

The new value of c will be used for processing next deleted records.

6. Experimental Results   Experiments were made to compare the performance of the batch construction algorithm [10]     and the pre-large FUSP maintenance algorithm for handling deleted records. When records were deleted, the batch FUSP-tree construction algorithm constructed a new FUSP tree from the updated database. The process was executed whenever records were deleted. The Pre-large FUSP tree maintenance algorithm maintained the pre-large FUSP tree structure with both large and pre-large 1-itemsets  The experiments were performed on an Intel x86 PC with a 3.0G Hz processor and 512 MB main memory, running the Microsoft Windows XP operating system. The synthetic datasets were generated by the IBM data generator [9]. 10,000 customer sequences were used to construct an initial FUSP tree and a Pre-large FUSP tree. The value of the upper support threshold and the lower support threshold were set at 4% and 2%, respectively. Each time, the last 100 customer sequences from the last updated database were used as deleted records for the experiments. The execution times obtained from both the batch FUSP-tree construction algorithm and the pre-large FUFP tree maintenance algorithm for deletion of records were compared. Figure 4 shows the execution times required by both the algorithm for processing each 100 deleted records.

Figure 4. The comparison of the execution time   In Figure 4, it easily observed that the execution  time by the proposed approach was much less than that by the batch FUSP-tree construction algorithm for handling deleted records. The effectiveness of the pre- large FUSP tree maintenance algorithm for record deletion is thus acceptable.

7. Conclusions   In this paper, we have proposed the pre-large FUSP tree maintenance algorithm for record deletion based on the pre-large concepts. It can reduce the rescanning  of the original customer sequences if the deleted customer sequences do not exceed the safety bound.

The pre-large FUSP tree is extended from the FUSP tree, which is similarly to the FP tree. When the customer sequences are deleted, the proposed maintenance algorithm processes them to maintain the pre-large FUSP tree. It first partitions 1-itemsets into nine parts according whether they are large, pre-large or small in the original customer sequences and in the deleted customer sequences. Each part is then processed in its own way. The Header_Table, Pre_Header_Table and the Pre-large FUSP tree are correspondingly updated whenever necessary. From the experimental results, the proposed maintenance algorithm has a better performance than the batch FUSP-tree construction algorithm.

8. References  [1] R. Agrawal, T. Imielinksi and A. Swami, ?Mining association rules between sets of items in large database,? The ACM SIGMOD Conference, pp. 207-216, Washington DC, USA, 1993.

[2] R. Agrawal, T. Imielinksi and A. Swami, ?Database Knowledge and Data Engineering, Vol. 5, No. 6, pp. 914- 925, 1993.

[3] R. Agrawal and R. Srikant, ?Fast algorithm for mining Large Data Bases, pp. 487-499, 1994.

[4] R. Agrawal and R. Srikant, ?Mining sequential patterns,? Engineering, pp. 3-14, 1995.

[5] H. Cheng, X. Yan and J. Han, ?IncSpan: incremental mining of sequential patterns in large database,? The ACM and data mining, pp.527-532, 2004.

[6] J. Han, J. Pei and Y. Yin, ?Mining frequent patterns without candidate generation,? The 2000 ACM SIGMOD 2000.

[7] T. P. Hong, C. Y. Wang and S. S. Tseng, ?Incremental data mining for sequential patterns using pre-large sequences,? The fifth world multi-conference on Systemics, Cybernetics and Informatics, pp. 543-548, 2001.

[8] T. P. Hong, H. Y. Chen, C. W. Lin and S. T. Li, ?Incrementally Fast Updated Sequential Pattern Trees?, The Cybernetics, 2008.

[9] IBM Quest Data Mining Project. 1996. Quest Synthetic Data Generation Code. From: http://www.almaden.ibm.com/ cs/quest/syndata.html.

[10] C. W. Lin, T. P. Hong, W. H. Lu and W. Y. Lin, ?An Incremental FUSP-Tree Maintenance Algorithm,? Applications, Vol. 1, pp. 445-449, 2008.

[11] M. Y. Lin and S. Y. Lee, ?Incremental update on sequential patterns in large databases,? The Tenth IEEE     Intelligence, pp. 24-31, 1998.

