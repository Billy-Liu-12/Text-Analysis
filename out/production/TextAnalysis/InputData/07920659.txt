Semi-Supervised Probabilistics Approach for

Abstract?The growing use of informal social text messages on  Twitter is one of the known sources of big data. These type of  messages are noisy and frequently rife with acronyms, slangs, grammatical errors and non-standard words causing grief for natural language processing (NLP) techniques. In this study, our  contribution is to target non-standard words in the short text and propose a method  to  which  the  given  word  is  likely  to be transformed. Our method uses language model probability  to characterise the relationship between formal and Informal- word, then employ the string similarity with a log-linear model to includes features for both word-level transformation and local  context similarity. The weights  of  these  features  are  trained by employing maximum likelihood framework using stochastic gradient descent (SGD) to hypothesise the better clean feature  for a given informal short text. Experiments were conducted on a publicly available Enlish-language tweet and the approach is able to normalise inflected words in an online social network.

Index Terms?Informal Short Text Messages, User-generated  Context(UGC), Social Media Text, Natural Language Processing, Stochastic gradient descent (SGD), Online Social Network.



I. INTRODUCTION  The appearance of online communities provide an oppor-  tunity for people to interact and share mutual communication  that goes beyond geographical boundaries. One of the most  active online communities is Twitter1. According to recent  statistics, about 200 million tweet was posted per day com-  pared to 65 million  in  the  previous  year  and  the  number  is  still  growing  [1].  The  length  of  a  tweet  cannot  exceed  140 characters but when usernames or URLs are part of  posted text - the overall average length of characters goes  beyond 140 characters. Messages from Twitter have shown to  have utility in many applications like sentiment analysis [2],  emergency assistance [3], and event discovery [4]. However,  the quality of messages varies significantly, ranging from high-  quality traditional newswire-like text to meaningless writing  styles. These messages contained informal information2 such  as typos, acronyms, misspelling errors, and emoticons - which  degrade the performance of natural language processing (NLP)  tools [5], [6], [7]. To reduce this impact, efforts have been  made  by  researcher  to  adopt  machine  learning  (ML)  and   1http://internetlivestats.com/twitter-statistics/ 2short text that has no meaning? Out-of-Vocabulary    information retrieval (IR) to transform the textual content in  social media text to canonical standard form [8], [9], [10], [11],  [12], [13]. However, due to little available training data, rapid  language changes, and high-dimensional feature space - it is  very difficult to make sense of the conversational messages  posted to online social media [14], [15], [16]. Perhaps, the  most successful systems are pipeline architecture that em-  ploys statistical language models with Levenshtein distance  to generate handcraft feature engineering to spellcheck and  normalises rare words in social media text [17], [18], [7],  [19]. The extracted features are inefficient and time-consuming  in formalising new features for every task or identify the  canonical form of the inflected word in the text. However, a  natural question to ask is how to normalise set of informal  short text embedded in messages posted to online social  media?

This study demonstrates a different method that use local  context  to  compute  similarity  metrics  between  string  can-  didates and the language model which arguably allow rich  representations for the observed sequence to estimate target  based  on  the  previous  distribution.  We  use  minimum  edit  distance  and  a  language  model  to  estimate  weight  vector  (e.g., features) during training. It is a lightweight probabilistic  method that relies on a language model and calculates the  similarity between target domain and homogeneity within a  given dataset. Then, we train the model towards a desirable  function in a maximum-likelihood, employing Stochastic Gra-  dient Descent (SGD) algorithms [20] for parameter estimation  to recompose noisy texts. This will help to normalise inflected  words and identify classes of orthographic transformation that  form coherent linguistic styles and improve communication  patterns of a person?s social context about her social behaviour.

The remaining part of this article is succinctly summarised as  follows. In a concise manner Section 2, describe previous  work related to online social media text. Section 3, introduces  our  methodology  to  normalise  the  task  to  generate  target  language sentence  for  informal short  text  in  the conversa-  tional  messages  posted  to  online  social  media.  Details  on  how the model was implementation with the testing dataset  are discussed in section 4. Finally, the performance of the  proposed model, conclusion and motivation for future work    2017 Conference on Information Communications Technology and Society     n  n ?   t n  |  were reported in section 5 and 6 respectively.



II. RELATED WORK    The text is a dominant form communication in today?s  hyper?connected world, which is used to unfold our mature  social behaviour. It is the means by which user create short  messages posted on online social media per second so as to  share and reach a mutual understanding. [7] proposed methods  that focussed on normalising single token between input and  output language sentence but excluded multi-word token lol  (?laugh out loud?). [25] use noisy channel model (NCM),  while [26] machine translation (MT) for spelling correction  based on annotated dataset. The work  finds  target  words  that fit the context with translation models (favouring words  that are similar to the input language sentence). The method

III. METHODOLOGY  In this section, we present a discriminative proposition to  transform sets of input language sentence S in a collection  of document D into its desirable output T . This enables us  to effectively rewrite part of the arbitrary features in UGC  (e.g., tweets) by leveraging on the flexibility of log-likelihood  model to calculate the weight feature in predicting the target  language given the input language sentence.

A. Model  The finite set of possible language sentences in D is  given as S = {s1, s2, ? ? ? } (e.g., tweets) and target language  T = {t1, t2, ? ? ? } (standard English). We denote the vocab- ularies of possible source and target language as VD and VT respectively. Thus, we express the conditional probability  P (t|s, ?), which is used to estimate input-source and target language sentence as follows:  used in this study alike to a noisy system but unlike prior  work,  no  labelled  data  is  needed.  [23]  and  [24]  proposed P t|s; ?) = exp ? T f (s, t) (1)  normalisation techniques that improve parsing and machine  translation respectively.

[29] manually identify several irregulars in social media  text using the supervised noisy channel. Each feature vector is  parametrised with a scalar value so that all legal information in  the are uniformly fit. Then, we estimated the scalar parameters  using expectation maximisation (EM). The approach achieved  an excellent result from among the others. [30] address the  use of string edit distance to distinguish and estimate closely-  related candidate orthographic forms and then decode the  meaning of the input messages using a language model, while  [31] mine ?exception dictionary? as a strong word feature to  extract interesting information in the text.

[17] extract noisy feature pairs using search snippets de- signed in Google, then trained with discriminative undirected  probabilistic model [32] to estimate P (t|s), which is the character-based translation model. The work was further ex- tended by adding a feature that allows visual priming, an offline spell-checker on local context [33]. [24] capture text  semantic meaning incorporate with edit distance using random  walk architecture. The majority of these techniques are devel-  oped with the aspiration of annotation data and no available  data to train unstructured social media text and therefore they  are unsuccessful in learning feature weights based on a log-  likelihood framework. Although, the normalisation techniques  were criticised in [22], who claims that it strips away important  social connection with respect to the conversational messages  The first step is to find a target language sentence t based on the input source language sentence s that maximises prob- ability  P (t|s) = P (s|t)P (t) =  nN P (sn|tn)P (tn|tn   1).  In  order to find the best possible correct lexical representation,  we cannot employ the usual dynamic programming algorithm,  because the quadratic cost in the size of the target language  vocabulary multiple by the cost of computing the normalised  probability value P (tn|sn), resulting in a prohibitive time  complexity of O(|VT ||VS |2N ).

So, we consider two approach in finding the target sentence  as shown in Algorithm 1. The first is to simply apply the  proposal distribution with linear complexity in the size of the  two vocabularies. However, this Algorithm is not identical to  P (t|s) because of the denominator factor of Z(t) in Equation 3. We apply the proposal distribution for selecting the best  target word, then apply similarity measure only within the  two string. The total cost is O(|VS |T 2N ), where T is define as the number of target word sentences we consider; this will  asymptotically approach P (t|s) as T ? |VT |.

We make a Markov assumption, so that the probabilistic  mapping between the input source and output target lan-  guage, P (t|s) decomposes across the elements of the sentence P (t|s) =  nN P (tn|sn). This means that the feature functions  f (s|t) must be decompose on each (sn, tn) pair. Specifically, we then rewrite log-linear model in Equation 1 as  N exp ?T f sn, tn     posted to online  social media.  However, in this  study, we  adopt the same normalisation principles in [34] to generate  P (t|s; ?) = n   n=1  Z tn (2)  a feature represenation for textual content in social media text  by aligning the weight features with minimum edit distance  and language model. The weight vector is navigated with the  Z tn   =   exp  ?T f   s, tn  s   (3)  alignment value using the log-linear model with maximum likelihood calculation on the dataset, which is used to enu-  In summary, the combination of Equation (2) and (3): N  exp ?T f s , t merate and rewrite fragments of social text to desirable target-  language.

n     n P (t s; ?) =  exp ?T f s, t n=1  (4) n    s , t  j=1  j  k  k   ? ?  ?  where the f (s, t) is the weight feature associated with each arbitrary sequence of words from input and output language  as: ?L(?)  n n   j  j   j sentence (sn, tn). In general, the weight feature in Equation 4 can be any real numbers and to improve generation efficiency,  ??k =  j=1  fk  s , t ? j=1 t?T  P t|s ; ?    (10)  we assume that all the weights are non-positive.

B. Training of Model  Given  a  training  set  that  consists  of  N  instances,  T =  ? fk  sj , tj   ? ??k  C. Optimisation Method  Stochastic gradient descent (SGD) is applied as an opti-  { j  j ?N j=1 , where s  j and tj are the source and target language misation technique to approximate the gradient (e.g., weights  sentence respectively, we consider employing maximum like-  lihood to estimation learn the log linear model in Equation 4.

We express the likelihood on the basis of the conditional prob-  feature vector) of the objective function given in Equation 9.

The SGD use approximate gradients estimate from subsets  of the training data and updates the weights of the features  ability of output target given input sentences nN  P {tj |sj } dynamically. In contrast to Sequential Monte Carlo (SMC) as  that marginalised over all possible transformations as  N  P (tj |sj ) =      P tj |sj ; ?j   (5) j=1    Therefore, the log likelihood function becomes  N  L(?) =    log P tj |sj ; ?j   (6) j=1  The goal is to find the optimal parameters ?? of the log linear model by solving the following optimisation problem  a training algorithm [34] that uses the probability distribution  to estimate weights of all features randomly from subsets of  the training social media data. However, exploiting SGD to  find local optima and normalised large label space is difficult  because the objective function in Eq.9 are not uni-model  distributed. So, obtaining minimum parameter values by em-  ploying probability distribution to normalise the dimension of  the feature space will slow down the weight updating process  and weights of the features will moved away from zero.

Instead, we used SGD approximates the gradient iteratively  for each training samples by taking replicated steps until local  minimum ? is attained as follows:  ?? = arg max L ?    ?     (7)  ?(k+1) = ?k + ?k  ?  ?? (L(j, ?) ?  ? ?2)  j   (11)  = arg max      log P tj |sj  where k is the iteration counter and ? is the learning rate,  ? k j  which is designed to decrease as the iteration process proceeds.

where ? denotes the weight parameter.

Our resolution is to modify the objective function in Equa-  tion 6 to include the regularisation term, which prevents  optimised parameter from becoming too large (and in par-  One straightforward solution to update weight of each features  j and solve the problem arising from 2-order regularisation-  term to consider a sub-gradient at zero and use the following  update equation:  ticular prevents parameters values from diverging to infinity).

A common regularisation term is the 2-norm of the parameter ?(k+1) = ?k + ?k  ?L(j, ?) ?k sign(? k ) (12)  values, that is, j j ??j  ? 2 j  l?l =     ? 2 (8)  j  where  sign(x) = 1  if  x > 0,  sign(x) = ?1  if  x < 0,  and sign(x) = 0 if x = 0 as discussed in [35].

The actual learning rate scheduling methods has a signifi-  where l?l is simply the length or Euclidean norm, of a weight vector ?; i.e., l?l =  "\ k ?  2 . The modified objective function  is  n  cant relationship on the convergence speed in training SGD.

Our typical choice of learning rate scheduling described in  [36] and implemented in this study:   L(?) =    log P tj |sj ; ? ? l?l j=1    (9)  ?k =     ? k0 + k (13)  = L(j, ?) ?      2    2 k k  where ? > 0 is the relative weights of the two terms used in Equation 8 chosen to validate the model. This allows  equilibrium on the regularisation of a term during training  data, while the primary term defined the likelihood of the  training sample to measures the fitness of ? parameter and  the secondary term measure the penalty function. Thus, the  partial derivative with respect to parameter ?k  is calculated  where ? can either be a constant or decay gradually.

The configuration process of the SGD based on the learning  rate is coded using python-library [37]. Thus, the larger the  random sampling from the training set then the slower SMC  will attain local minimum and the longer it takes to converge.

D. Similarity Measure  We define te ? De, where De is a dictionary of possible correct words, and si of  the  source  language  in  tweets.

The similarity alignment ? te, si    between input and output    length(te )  language sentence as    ? te, si   =    LCSRatio te, si    EditDistance te, si    (14)

V. NORMALISATION  Not all the informal short texts extracted from Twitter re-  quire normalisation. However, the question on how to ascertain  which words to normalise continues to be an open research  question. Following [7], we develop a words dictionary that where LCSRatio(te, si) =  length(LCS(te,si )) and LCS(te, si) is the Longest common subsequence between te and si.

The Longest Common Subsequence Ratio (LCSRatio) [38]  of two string (e.g input  and  output  language  sentence)  is  the ratio length of their LCS and the length of the longer  string. Because the corresponding dictionary term in social  media text will always be longer than the non-standard token,  the denominator of LCSR is calculated as the length of the  dictionary term.

Consonant skeletons in [25] used edit distance based on the  canonical definition and the informal word token in the source  language sentence. So, the Levenshtein distance between the  consonant skeletons is small then ? te, si will be high. How-  ever, the intuition behind using EditDistance is an example  through the following example. Consider a nonstandard word  ?ppl? that catch the correct form ?people?. The canonical  definition using method in [25] give ?good? and ?guide? as  LCSRatio as 0.5 with respect to ?gud?, while with respect to?good? as 1 less than ?guide?as 2 with respect to ?gud?.

In conclusion, the similarity measure of two inflected words  corresponding to the target value is higher compared to ?gud?  and ?guide? respectively.

E. Features  We employ word-level transformations and string similarity  using Levenshtein Levenshtein distance to find the best rep-  resentation for the given input as described in Algorithm 1.

Primary, we measure the upper bound characters in the input  source and output sentence to capture the lexical alignment,  e.g. luv/?love?. We only consider word-level transformation  features that occurred during training. Secondly, we measure  the detected features similarity using the method in [30] to  determine target represenation that is likely closer to the input  text. We use this similarity to create binary features that could  indicate whether words in an input source sentence can be  mapped to correct lexical sentence. We used the output as a  feature to find relationship between the target t and the given  input s, so that posterior probability P (t|s) as described in Section III-A can be compute easily.

includes targets language to normalise OOV3 words and no  attempt is made to normalise source strings that are equivalent  or match any word in the observed sentence. As with other  comparable approaches, our method was able to normalise rife  words like ?SYL? into ?See you later?. The set of IV4 words  containing 336 words as discussed in [39] and with GNU  Aspell dictionary5 that contain 97, 070 words was used. From this dictionary, we follow the approach described in [33] to  remove all words that have minimum significant meaning (e.g.,  words with the countless than 20 occurrences are excluded).

All single tokens in the tweets like slang, abbreviation are  treated as IV, except a, i, rt, #brunette, #ootd, #blonde associated  with the tweets are deleted. This is the effectiveness of the  model from attempting to normalise the inflected word in a  given social media text.

A. Language Modeling  We use language modelling as an alternative to estimate fea-  tures similarity in a social media text based on the perplexity  and trained over the sequence in the datasets as illustrated in  Algorithm 1. We create open-vocabulary LMs with annotated  dataset from the Edinburgh Twitter [40] and LexNorm 1.1  [19]. Therefore, for each corpus, the n-gram models is trained  on each target word in the sample corpus dataset. Hereafter, we  calculate perplexity based on the held-out of the sample from  the sub-dataset to find textual meaning. The resulting output  is employed to generate features representation as illustrated  in Algorithm 1 when computing the weighted function in the  log-linear model.

B. Parameters  SGD require two parameters: the number of samples s  represented as features and the nested expected target denoted  as t as defined in Eq. 11. So, we obtain equal quality  improvement as  the  number  of  iteration  units  increase  at  k = 10000 and L = 2 as regularisation terms and find little  relative improvement with ? parameters.



VI. EVALUATION RESULTS  A. Datasets  For this study, we required only tweets containing short text

IV. IMPLEMENTATION DETAILS AND DATA messages. We used the Twitter streaming API and used the    The methodology in this paper was implemented in Jupyter  notebook environment running Python 2.7  for  characteris-  ing and identifying the chain of orthographic in social me-  dia text that corresponds map to target values using semi-  supervised statistical approach. The system has the capacity  to process the roughly large amount of informal short texts  per hour and the implementation details are available at  https://github.com/dupsy/emnlp2016.git.

most popular topic trend include news (e.g., #PanamaPapers),  entertainment (e.g., #SonyHack), computer (e.g., #datasecu-  rity) and politics (e.g., #NorthKorea, #china, #russian, #re-  alDonaldTrump, #whitehouse) to collect tweet. The rate of  tweets that can be collected with Twitter Streaming API is   3Out-of-vocabulary 4In-vocabulary 5http://aspell.net/ 6https://dev.twitter.com/streaming/public     ?  Algorithm 1: Pseudo-code for feature representation  Tk ? T , where tk denotes a single observed input source language consisting of a sequential token s1, s2, ? ? ? , sm and m = |Tk |;  Uj ? U , is the unigram from tk ; Bj ? B, is the bigram representation generated from Tk ;  input :  For A = { a1, a2, ? ? ? , an  ? represents the set  of observed sequences such as slang, abbreviation and others in the input string;  t = { t1, t2, ? ? ? , tn  ? is the comparable target  value [39]  output: fB si, si+1  denote frequence wi, wi+1 arises in B, which is denoted as a bigram, while fu si    calculates the occurences of si ? T known as a unigram the value of si.

foreach sequential element ai  in tk  do  ?smh? is normalised to somehow but following the IV words  in [39] and slang annotations9 assert the standard form as  shake my head and this the evident from input tweet sentence  example like ?smh gf?. The Figure.1a demonstrates the ability  of our approach to obtain noisy features and find appropriate  interpretation that could used to make sense of the communi-  cation process on the Internet through feature weights.

Our strategy comes from the flexibility of modelling infor-  mal short text messages aligning it to real word-level based  on features representation to derive the lexical similarity in  context to train the parameteristic weight function without the  used of annotated data. The quadratic complexity of large  space dataset for normalisation task with dynamic program-  ming was overcome using SGD.

B. Metrics  Earlier work has proposed normalisation techniques for  identifying  informal  messages  by  focusing  on  finding  the  f1 = P si | si?1  = fB  si,si  1 ,si = ai; correct linguistic styles that map an input tweets sentence [19],   f2 =   LCSRatio ai,ti     fu  si     ;  [19] using a machine learning metric such as precision, recall  and F-score. Recall determined the number of noisy features in   EditDistanceUGC ai,ti     feature?vector= { f1, f2  ?   end         limited per hour. The tweets are retrieved as a JSON format,  which is very simple and easy to be parsed as each line of  this format represents an object [41]. However, the returned  tweet by the Streaming API contains many attributes of the  tweets, such as text, URLs, hash-tags and associated Twitter  structure7. In total, we collected about 650Megabytes of tweets  from 22nd of February 2016 to 26th February 2016, while  we restricted the collection with tweets ? containing 22, 210  arbitrary textual content and after removing redundancy (e.g.,  unnecessary information). Furthermore, public Streaming API  provides access to 1% of all public tweets but access to the  tweets sent by protected account are not part of the sample.

The meaning of the arbitrary features of words in the dataset  is not available, so we use the language model jointly with  similarity measure as discussed in Section V-A to generate  the corresponding target.

In addition, Twitter datasets are not permitted to be dis-  tributed publicly without prior approval8. In order to evaluate  our approach, we create our own Twitter content via the  Streaming search API to ensure we play by the rules. There-  fore, testing the performance of the proposed approach with  other research studies will be unrealistic objective because  there is no openly accessible corpus. In close analysis with  LMML11 and LexNorm1.1 datasets [17], [42] revealed some  inconsistencies in annotation or interpreting the text in the  input sentence (for example, smh and 2 are normalised to  ?you? or ?to?, but the words are left unnormalised), while  7http://support.gnip.com/sources/twitter/data format.html 8https://twittercommunity.com/t/twitter-and-open-data-in-academia/51934  the social text that is formalised correctly; precision establishes  quantity which is correct and f-score is the statistical average  of precision (P) and recall (R).

C. Result  To infer knowledge and address the presented difficulties  of making meaning with online social media text through  discriminative learning. Firstly, we conduct an analysis dispo-  sition of noisy features with our tweets dataset. Predominantly,  we calibrate the distribution of noisy features per UGC (e.g.,  tweet message)  and plot  the proportion  at  which they  oc-  curred for the entire dataset. In a uniform distribution, around  12.5% of tweets have 50% or more noisy features presented  in Figure.1a. We further analysed the informal text in our  datatset e.g., Twitter and randomly selected 414 of the text  and analysed the category the inflected word to determine the  phenomena that our normalisation system needs to deal with.

We identified 20% token instances of rare words in tweets and  broke them down into to as to understand the occurrence of  noise word in the dataset, as listed in Table I.

TABLE I: Assessment of Noisy Features   Category Ratio  Abbreviation 48.6% Slang 26.3%  Letters & Numbers 10.38% Letter 5.36% Others 10.34%    ?Abbreviation? and ?Slang? are cited as artifacts that par-  ticipating individuals create in sharing opinion on the Inter-  net (e.g., swin to ?see what i mean? or lol to ?laugh out  loud?) as described in [39]. ?Letter and Numbers? it refers  to  instances  where  one  or  two  letter  are  missing/extra  or   9http://www.internetslang.com/trending.asp        (a) Distribution of Noisy Features (b) Visualising Features Vectors  Fig. 1: Noisy Features distribution in English Twitter dataset     misspelled letters  or  number  exchange  (e.g.,  luv  to  ?love?  or 2mor to ?tomorrow?), however the corresponding target  language can be found easily from Algorithm 1 discussed  in Section III-A. ?Others? is the remainder of the instances,  which predominately occupy space between the features and  need to be deleted (e.g., thenewcastlesun to ?the new castle  sun?). This heuristic discovery help CFI as a strategy to  predict and recognise the user?s behaviour with respect to their  communication pattern.

D. Visualising the Training Feature Vectors  We explore the likelihood of viusalising any given input  tweets si formalised to the canonical form wi as described in Eq.1. This help to observe the input tweets s clusters and pairs target t clusters association up hierarchically based on  the weight parameters f(tn | sn) as discussed in Eq.4. The unambiguous distribution of words in the feature representa- tion based on counting frequencies of occurrences of noisy symbol sequences used in the training is shown in Figure.1b.

The plot in Figure 1b is the multiple pairwise of the features  vector pattern in the dataset that has the most weight, which  is employed to learn a representation to transform each rife  word in tweets into the desired enumerated target.

E. SGD Performance  We evaluate the effectiveness of our feature vectors with  the log-linear model using an SGD algorithm on the Twitter  dataset. The feature vectors used in this experiment were  based on bigram and edit-distance measurement that outline  the arbitrary symbols to their clean grammatical meaning. To  eschew some superiority to SGD algorithms over the regular-  isation terms of the precision in estimating the ? parameter,  the L2 norm describes in Eq.8 was used when controlling  the regularisation strength on ? to estimate ? parameter. We use the exponentially decreasing learning rate as described  in Eq.12 by starting ? = 0.5 and ?0 = 1.0, where k is the  iteration counter. Experiments were conducted until 100, 000 training instances were observed before attaining convergence  with the final learning rate. In Figure 2, we show the evaluation  metrics. To recompose given noisy features in a given tweets,    we utilised the feature vector as described earlier to construct a  confusion matrix, so as to test the effectiveness of our Twitter  dataset. The bigger iteration values give better precision but  decrease the recall as shown in Figure. 2a and 2b.  While  Figure. 2c describes that a small amount of regularisation  significantly has no influence on the model?s performance,  although SGD training took about 145 seconds on  Intel  Core i7-2630QM processor to train the richer feature vector  in the log-linear model. Generally, as the iteration number  increases, the precision score improves while recall decreases  significantly. Thus, we achieve 37.5% for f-score, 42.3% for  precision and 38.10% for recall for nomalising rife words for  a given tweet documents.



VII. CONCLUSION AND FUTURE WORK  In this paper,  we introduce  a semi-supervised analytical  approach for normalising arbitrary features embedded in the  social text. This improves the quality of messages retrieved and  provides better insight to make sense of online communication  processes with respect user?s behaviour. The competence of  our proposition comes from adopting minimum similarity  measures and a language model to develop features representa-  tion, then exploit the contextual features to train the equivalent  feature weights of unknown datasets such as Twitter. However,  the technique issues with the large dataset were overcome with  stochastic gradient descent (SGD) that efficiently trains L2-  regularised log-linear models. Future work may consider using  deep learning architecture as a recurrent neural network ap-  proach for formalising and recomposing rife words (e.g. non-  standard language) social media text. We intend to investigate  the adaptations of the deep learning with a self-supervised  dictionary, if it can formalise representation to normalise and  mimic understanding with near-human accuracy the textual  content posted to online social media per seconds.

