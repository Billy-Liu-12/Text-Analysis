

Abstract: The effective representation and amalgamating  extraction method of frequent itemsets in distributed databases is important to improve the result of distributed association rules mining. The common methods are inefficient due either to higher number of database scan or to larger amount of candidate itemsets for communication. Based on discussing the relation between the concept of pruned concept lattice (PCL) and the representation of frequent itemsets, the Closed Frequent Itemsets of PCL is defined. UMPCL_I, an approximate amalgamation and extraction method of frequent itemsets in horizontally partitioned databases based on multiple PCL, is proposed. The main ideas of this method are using a frequent concept to represent some few of frequent itemsets, and using a local support slightly lower than global support to prune sub-lattices before been amalgamated to decrease the size of exchanged messages. The theoretic analysis and experiment show that such method is efficient.

Keywords: Data Mining; Distributed; Frequent itemsets; Pruned  concept lattice  1. Introduction  Frequent itemsets extraction is pivotal to association rules mining (ARM)[1,2], which is intended to capture a certain type of relation among items. Soon after his proposing of ARM in [2], Agrawal introduced a fast algorithm for extracting frequent itemsets[3,4] defined by the threshold of support. We could save the itemsets, supports of which are larger than the user-specified minimum support threshold, denominated by frequent itemsets, and remove the infrequent itemsets. Because the produce of frequent itemsets based on support constrain is download closure, the algorithm with support measurement is effective.

Data from the different data sources faces the system of association rules mining along with the sharply increase in data scale and the widely popularizing of Internet technology. On the other hand, considering the feasibility  and privacy preserving of data mining, the data mining system would initiatively divide the large centralized database into several sub-databases to develop distributed algorithm. In a word, distributed association rules mining is a natural evolution of ARM technology, motivated by the need of scalable and high performance systems. Many algorithms of ARM in distributed databases have been proposed in the past few years[5-10], but, to the best of our knowledge, most of them are the parallelized version of sequential algorithms, which couldn?t be efficient enough.

According to the latest studies, the main challenges that researchers faced nowadays are the particularities of the target datasets, i.e. ?large, noisy, of unknown generation laws, of high dimensionality, distributed?, which do not allow the conventional methods to be applied. So it?s urgent to develop new strategy and techniques for distributed ARM. As the key process of distributed ARM, in this paper we are interested in the most computationally expensive phase, i.e. the global frequent itemsets extraction in multiple databases, during which all of the frequent itemsets are extracted. The reason why the process of frequent itemsets extraction is computationally complex is the exponential size of candidate itemsets.

The Formal Concept Analysis (FCA) proposed by Wille (1982)[11,12] is an efficient implement of data analysis, which has many important applications in software engineering, machine learning etc. As the core data structure of FCA, concept lattice and the corresponding graph represent a concept hierarchy, reveal the generalization/specialization relationship between concepts, which have been shown to have many advantages in the field of knowledge discovery from large database. For association rules mining, the rule reflects the relations between itemsets in database, when as embodied in the inclusion (or approximate inclusion) relation of transactions.

One of the key advantages of the FCA-like mining lays in the fact that thanks to the closure properties only patterns of maximal size are extracted, the exploration/interpretation burden for analyst is reduced and the overall efficiency is      increased. Therefore we can conclude concept lattice offers an appropriate framework for distributed ARM[13]. The reason why no distributed association rules mining algorithm based on concept lattice was suggested in the past few years may lie in the huge size of lattices.

In this paper, we introduce UMPCL_I, a distributed extracting frequent itemsets method powered by FCA.

Based on analyzing the relation between the concept lattice and representation of frequent itemsets, we prune infrequent concept from the concept lattice. A frequent concept implicates numbers of frequent itemsets due to the closure property, i.e. only patterns of maximal size are extracted, so the exploration/representation burden of results is reduced. And then we particularly discuss the extraction of Closure Frequent Itemsets (CFI) in distributed databases based on multiple pruned concept lattices. The distributed databases in our model are horizontally partitioned databases.

This paper is organized as follows: Section 2 recalls basic definitions related to the ARM and FCA, while section 3 describes the relation between the pruned concept lattice and frequent itemsets extraction and corresponding properties. In section 4 the UMPCL_I algorithm and its experimental results in section 5 are given. Finally, we draw some conclusions.

2. Basic definitions  The formal statement of association rules mining is following: Let I = {i1, i2, ? , im } be the attributes set in a given database TD. An itemset X is a subset of I. A transaction T of TD is also a subset of I, which is associated with a unique transaction identifier TID. Suppose X?I, we say the transaction T includes or satisfies the items X iff X?T. The association rule is the implication of the form X?Y, where X?I, Y?I, and X?Y=?. A frequent itemset X means at least s% of transactions in TD satisfy X.

Definition 2.1 A formal context K= (O, D, R), where O is the set of objects (transactions in database, denoted by numbers) and D is the set of items (attributions in database).

The relation R is given by the matrix of its incidence relation, where oRd means that object o has attribute d.

Moreover, R gives rise to two mappings: for an A?O, f(A) = {m?D|?g?A, gRm}, while for B?D, g(B) = {g?O|?m?B, gRm}. The pair of functions reduces a Galois connection between P(O) and P(D). A formal concept C of context K is a pair (A, B) with A?O, B?D, where f(A) = B, g (B) =A. We call A the extension and B the intension of concept (A, B).

C(K) denotes the set of all concepts of the context K.

Definition 2.2 C(K) is partially ordered by extension inclusion: for C1 = (A1, B1) and C2 = (A2, B2), C1 ? C2 ? A1  ? A2 ( ? B1 ? B2 ). C1 is called sub-concept of C2, while C2 is super-concept of C1. This partial order is used to generate the lattice, named concept lattice.

A database TD can be regarded as a formal context K = (O, D, R), where O is the set of transactions and D is the set of attributes. Apparently, for a formal concept C = (A, B), ?x?A,x??B, ? x satisfies x?.

Definition 2.3 A concept C = (A, B) is a frequent concept (or frequent node in lattice) if the number of its extension is larger than |U|*s and its intension isn?t null, and contrariwise, C is an infrequent concept. |U| is defined as the number of transaction, and s is user specified support threshold.

We can find that each frequent itemset F corresponds with a frequent concept C of concept lattice L, i.e.

F ? int(C).

Definition 2.4 For an itemset I, we call I? the support set of I. For a concept C = (A, B), we call the set of itemsets I(C) = {X| X?=A, X?D) the Closure Itemsets (CI) generated by C, denoted CI(C = (A, B)) or CI(C).

Unless the confusion of ideas was brought we don?t expand the CI to the set of individuals. According to the above definitions, we can extract all the frequent itemsets by using concept lattice model when a database TD is given.

3. Multiple PCL and the frequent itemsets extraction problem  Concept lattice is representation form of concepts and their relations of context, which are corresponding each other. One of the particular benefits brought by FCA and concept lattice is the reduction in the itemsets? number because only patterns of maximal size are extracted due to the closure property of concept. Therefore, the concept lattice model is appropriate for distributed association rules mining, which attracts a large number of researchers[13,14].

Now, many crafty algorithms are proposed to find all the pattern/rules satisfying some criteria. However, such algorithms are expensive in the condition of large database, and the clou of data mining is to find the patterns interesting users, while not all. So in the process of ARM based on concept lattice, we can only save the frequent concepts, and remove the infrequent concepts from lattice when it is constructed. The process of removing the infrequent concept from lattice is named pruning, and the new lattice which infrequent concepts are removed named pruned concept lattice (PCL).

In the following, we discuss the problem of frequent itemsets extraction based on multiple PCL, and propose an efficient algorithm of closure frequent itemsets extraction.

Property 3.1 Any super-concept of a frequent concept is frequent too, and vice versa.

Definition 3.1 Given K = (O, D, R) and corresponding lattice L(K). The new lattice, removed the infrequent concepts (except null concept) and corrected the sub/super-concept relations, is named Pruned Concept Lattice of the context K, denoted PL(K).

From the definition mentioned above, we can call the closure itemsets generated by C of PL(K) the Closure Frequent Itemsets, denoted CFI(C).

Definition 3.2 Given a global context K = (O, D, R) and local context K1 = (O1, D, R1), K2 = (O2, D, R2). We call K1 and K2 the same domain context if O1?O, O2?O, which are sub-context of K. If O1?O2=?, we call K1 and K2 the same domain and disjoint context. Furthermore, if O1?O2=O simultaneously, we say K = K1+K2.

Definition 3.3 For a given global context K and its sub-context K1 ? Kn, let K=?Kj. We will call frequent itemsets L of K the global frequent itemsets and frequent itemsets Li from Ki the local frequent itemsets.

Theorem 3.1 ?X?L, ? i,X?Li? Proof . (Reduction to absurdity) This theorem indicates that if X is a global frequent  itemset, there is at least a site Ki, such that X must be local frequent itemset at site Ki.

Lemma 3.1 If Lk is global frequent k-itemsets and Lki is local frequent k-itemsets of site Ki, it is sure that Lk??Lki, and L? L? i.

Lemma 3.2 For every frequent itemset F of K, there is a concept C of PL(K) which intension is the superset of F.

Furthermore, we can conclude that there is a concept C = (A, B) of pruned concept lattice PL(Ki) induced by some sub-context Ki, and F?CFI(C).

Definition 3.4 Given a context K = (O, D, R) and two concepts C1=(A1, B1), C2=(A2, B2). Concept C1 intension includes concept C2 if B2?B1, denoted C1>intC2. Here C1 is the intension inclusion of C2.

Definition 3.5 If K1 and K2 are the same domain context, and K=K1+K2. Their corresponding pruned concept lattices are PL(K1) and PL(K2) respectively. Let MPL= PL(K1)+PL(K2). For a concept C1 of PL(K1) and concept C2 of PL(K2), let C3= C1?intC2=(A1?A2,B1?B2). If there is no super-concept of C1 in PL(K1) and super-concept of C2 in PL(K2) intension include C3, C3?MPL. Then we call the operation C3=C1?intC2 the intension join, and the C3 is the result of the intension join operation by C1 and C2.

Thus, we have given all of the basic theories needed by the frequent itemsets extraction based on multiple PCL.

For a large context K, we can horizontally partition it into several small sub-contexts, and implement a distributed mining algorithm on these sub-contexts. We could use a  slightly lower local support to construct, prune each local sub-concept lattice, and amalgamate local lattices to get MPL which is a good approximation of concept lattice L induced by global context K. An extreme case is that the local support is 0.

4. Algorithm for frequent items extraction  The main idea of frequent itemsets extraction based on multiple PCL is that we horizontally partition the global context into several local contexts firstly. Then we construct and prune the lattice derived from each sub-context, and amalgamate them to get the amalgamated lattice MPL.

We explain the amalgamation process of two pruned concept lattice PL(K1) and PL(K2), which is easy to be extended to more. We insert the concept Cj = (Aj, Bj) of PL(K2) into another lattice PL(K1) according to breadth_first visiting sequence beginning with the full concept. The insert operation means intension join of Cj and every concept Ci1 = (Ai1, Bi1) of PL(K1). The insert process would generate three kinds of concept for MPL:  (i) Inherited concept If Bj?Bi1=? or there is no super-concept Ci2 of Ci1  which is the intension inclusion of (Bj?Bi1) then Ci1 is an Inherited concept, which is a member of MPL remained intact.

(ii) Modified concept If Bi1?Bj then there is a new concept Ci1?=(Ai1?Aj, Bi1),  which is also a member of MPL, created by modifying the concept Ci1.

(iii) New concept If there is no intension including relations between Cj  and Ci1 and there is no super-concept Ci2 of Ci1 which are the intension inclusion of Cnew then Cnew is a member of MPL, here Cnew=( Ai1?Aj, Bnew), Bnew = Bj?Bi1.

In the following, we will give the frequent itemsets extraction algorithm based on multiple pruned concept lattices (UMPCL_I).

Input: K1, K2 Output: MPL, and corresponding CFI Begin for each sub-context K1, K2 do construct corresponding concept lattice and prune  to get the PL(K1), PL(K2) end for for each Cj=(Aj,Bj) in PL(K1) do insert Cj into PL(K1) and prune end for generate all the CFI of MPL End      5. Experimental evaluation of the algorithms  The performance of this method was compared with the frequent itemsets extraction algorithm based on Apriori.

The experiments were done in JAVA on a Windows2000 PC station (Pentium IV 1.7 GHz with 256M of RAM) using a subset of some grade database which was regarded as global context K. This dataset is made out of 200 records over a set of 19 distributes with an average of 6 distributes per record, and was partitioned equably into two part, each has 100 records and 19 distributes. The global and local support was set the same at several threshold levels for the sake of comparison. The graphs drawn in Fig.1 and Fig.2 summarize our findings.

Figure 1. The decrease in the number of representation of  frequent itemsets   Figure 2. The slight loss of CFI in MPL   Figure 3. The time comparing between UMPL_I &  Apriori_gen  As can be seen from the graph, the number of closure frequent itemsets extracted by using UMPCL_I algorithm is slightly less than the number by using algorithm based on  concept lattice, and much less than the number of representation by the direct application of Apriori algorithm to distributed databases. The larger the support threshold, the less the difference between the algorithms based on multiple pruned and unpruned concept lattices.

In the case of large scale database, people would pay more attention to the validity of knowledge, while not the maturity reached at any cost. So we can say the extreme exactitude or maturity is unnecessary, on the contrary, the approximation is the essential of data mining. The pruning technique is an efficient method which can obtain the approximate maturity but obviously reduces the size of result of data mining process.

6. Conclusions  We studied an efficient algorithm for frequent itemsets extraction in distributed databases. This method reduces the number of frequent itemsets representation at each site effectively by using the Closure Frequent Itemsets representation and pruned concept lattice. Concept hierarchy is a convenient tool of data analysis and the representation of knowledge. Pruned concept lattice has been shown to have many advantages in the field of knowledge discovery from large databases and distributed databases. This paper proposes a global frequent itemsets extraction method by using pruned concept lattice model in distributed databases, where all the local frequent itemsets in each site were represented as pruned sub-lattices. The experimental evidence shows that, on the average, the UMPCL_I algorithm is much done in the approximately self-contained representation of global frequent itemsets, and obviously decreases the number of representation of global and local frequent itemsets at the same time. Some open problems remained to be done following this work are three. First problem is discussing the more general dividing strategy of a large database. Second, we will quantitatively analyze the degree of loss of global frequent itemsets during the amalgamation of pruned concept lattices. Finally, we would study the topic of the association rules mining based on multiple pruned concept lattices, and further tests using larger datasets are necessary to fully understand the behavior of UMPCL_I algorithm.

Acknowledgements  This paper is supported by the Youth Scientific Research Foundation of the AnHui University of Finance & Economics under Grant No. ACKYQ0637ZC.

