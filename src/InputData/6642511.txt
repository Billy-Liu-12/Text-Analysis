Author Attribution on Streaming Data

Abstract? The concept of novel authors occurring in streaming data source, such as evolving social media, is an unaddressed problem up until now. Existing author attribution techniques deals with the datasets, where the total number of authors do not change in the training or the testing time of the classifiers. This study focuses on the question, ?what happens if new authors are added into the system by time??. Moreover in this study we are also dealing with the problems that some of the authors may not stay and may disappear by time or may re- appear after a while. In this study stream mining approaches are proposed to solve the problem. The test scenarios are created over the existing IMDB62 data set, which is widely used by author attribution algorithms already. We used our own shuffling algorithms to create the effect of novel authors.  Also before the stream mining, POS tagging approaches and the TF- IDF methods are applied for the feature extraction. And we have applied bi-tag approach where two consecutive tags are considered as a new feature in our approach. By the help of novel techniques, first time proposed in this paper, the success rate has been increased from 35% to 61% for the authorship attribution on streaming text data.

Keywords?data mining; big data;  text mining; natural language processing; POS Tagging; authorship attribution; author recognition.



I. INTRODUCTION The impact of social networks brings an increasing demand on the studies of streaming data mining. The dynamic and evolving social network structure can only be handled by a dynamic approach to the data mining. The classical approaches can be efficient on the static data sets like a static data set of training where all the classes and labels are visible to the classifier and classifiers are not tolerant to the changes on the dataset. On the other hand, the social networks and web content is evolving like a living organism and everything, including the data, classes, content, labels are open to the changing.

This study focus on the author attribution problem on the evolving social media. For example in a web page, users can enter their comments and the number of comments and commenters may change by the time. Some novel authors may appear while some others are disappearing. Also another challenging problem is catching the reappearance of the  authors, instead of classifying them as a new author. Besides, any classical classifier, which can classify the authors for an unchanged environment, this study goes further and tries to expand the classical classifiers to work on a dynamic environment by using the stream mining approach.

This paper starts with a background study on the related work, and briefly explains the overview of the problem and solution proposed. Three different stream mining tools, are implemented and fine tuned for the author attribution over IMDB62 dataset. Details of the data set and feature extraction technique text mining and a novel technique to simulate the streaming data, the reshuffling are explained in the chapter IV Experiments.  Besides the stream mining tools and shuffling algorithms, also another important part of this study is the feature extraction from the dataset to recognize the authors.

During the feature extraction, TF-IDF and POS tagging approaches are implemented and they have been used in a mixed manner.



II. RELATED WORK Authorship attribution is one of the study fields since late 19th century [1]. During the last decade, this scientific field has been developed substantially taking advantage of research advances in areas such as machine learning, information retrieval, and natural language processing. The main idea behind statistically or computationally-supported authorship attribution is that by measuring some textual features we can distinguish between texts written by different authors [2].

Most recent works on the author recognition studies shows a high success up to 90% [3].  Moshe Koppel et al. have used TF-IDF feature extraction method along with the cosine measure in their paper [3].

Differences to many other data mining applications are usually in the first stages of the data mining process, such as feature extraction from the text of the document [4].

In this paper we focus on authorship attribution in the case of novel authors are added into the database by time. The approach of new authors is related with the stream mining [5] where the data source is changing by time and new classes are added to the classification algorithm. Masud et al. [6] propose a  497IEEE IRI 2013, August 14-16, 2013, San Francisco, California, USA    classification and novel class detection technique called  ECSMiner that is a multi- class classifier and also a novel class detector. It uses an ensemble of models to classify the  unlabeled data and detect novel classes. However, this  approach does not consider the issue of recurring class.

ECSMiner identifies recurring classes as novel class. As a  continue to the work of previous work, Masud et al. [7] proposed detecting the recurring and novel classes in concept-  drift data streams.

In the stream mining studies, Masud et al. [7] indicate that the data stream is divided into equal sized chunks, and the data points in the most recent data chunk are first classified using the ensemble. When the data points in a chunk become labeled (by human experts), that chunk is used for training a classification model. Since the number of models in each ensemble is fixed, the newly trained model replaces the existing model(s) in each ensemble. Also in this approach the ensemble size of L classification results, are kept per class for further classifications, even if all the members of the class are disappeared. By keeping this information, the stream mining classifier can decide if the class is a novel class or a reappearing class. Another parameter value can be set on the stream mining classifiers is the K, which can be rewritten as number of pseudo points per classifier, where pseudo point is  the summary of each classifier. For example, if the stream  mining approach utilizes a K-means clustering algorithm in the core, the pseudo point would be a region of feature space  defined by the hyperspace corresponding to the centroid and  radius.

In this paper, it is first time the author recognition in dynamic  environments like blogosphere or web site commenters. The  approach in this paper is also extending previous work on a  static database with using LDA approach [8] to a dynamically  changing database and recognizing the new authors  successfully.



III. OVERVIEW OF THE APPROACH This study focus on the authorship attribution on the streaming data. The web comments are collected into a data set in a streaming manner. So new comments arrives by the time. And each time there is a possibility of a new author arrive to the system. The over view of the system is demonstrated on Figure 1, the text content is passing through a NLP guided feature extraction layer and stream mining techniques are applied over the extracted features with the probability of novel classes (new authors) and recurrence of the authors.

Fig. 1. Overview of study  During this study, natural language processing approach has been applied into the preprocessing phase of the data mining.

Figure 2 demonstrates the deployment diagram of the natural language processing (NLP) phase.

Fig. 2. Deployment of modules  After fetching the data from the data source, the text mining layer starts its execution and applies three different feature extraction methods:  ? Pos-Tagging and using the count of tags ? TF-IDF and using the TF-IDF values for each of the  words ? Tag-n-gram is the n-gram of the consecutive tags  Unfortunately the hardwares in the study environment was not qualifying the requirements for the feature extraction of all the terms in data source which is 139,434 for IMDB data set. The solution is getting the most important terms by sorting the  Stream Mining  Streaming Data  Text Mining  POS Tagger  F1: Tag Count  F2: TF-IDF  F3: Tag-n-gram  Classifier     information gain of each term. This study limits the number of features for the datasets by 300 terms with the highest information gain.

Another approach for the feature extraction from the natural language data set is the POS tagging which is again was not possible with the current hardwares for the large data set. The solution, we have applied is the map-reduce approach to divide the datasource into smaller files and process each file seperately and than merge the results into a single file.

Furthermore whe have applied a third feature extraction method which is the bigram of the tags which we have got from the result of POS tagging. The motivation of bigram tags is catching some phrases of the authors for attribution of the authorship.

In the POS-Tagging approach, we have used the Stanford POS Tagger [9] which has 48 different tag types fitting the terms in our corpus. Besides the tagging we have also extracted the bi- tags, which is the consecutive two tags merged together similar to the bigram approach. The number of bigram tags in our corpus is 1,687 and again we have limited this number with the top most 50 of the bigram tags.

Also in the stream mining studies, the shufflement of the data source is important. For example the number of novel authors in the data chunk is one of the major parameters for the success rate of the stream mining algorithm. This study also focus on the several reshuffling approaches and measures the success rates depending on the reshuffling of the datasourse.



IV. EXPERIMENTS We have implemented our approach onto two different data sets: IMDB62. Table 2 demonstrates the features of the datasets.

TABLE I. SUMMARY OF DATASET  IMDB62 Authors 62000 Texts per Author 1000  In the IMDB62 database, there are 62 authors with a thousand of comments for each of the authors. The database is gathered from the internet movie database1 which is available for the authors upon request [10].

Feature Extraction The data source in this study is in textual format which makes a challenge to extract features suitable for the classifiers. One approach is using the term frequency ? inverse document frequency, TF-IDF, which is mainly built on the number of occurance of terms in documents and their appreances in the most of the documents.

The other approach we have implemented is the POS-Tagging.

The idea of tagger is getting each token from the text and   1 Internet Movie Database : www.imdb.com    outputting the possible tags for English like noun, verb, plural noun, adjective, etc. [9].

After the tagger finishes its execution, the tag-n-gram layer processes each and every consecutive tag and produces the n- gram possibilities. For example if n = 2 than each consecutive couple of tags are considered as a feature and their number of occurrences will be counted to output the feature vector.

The execution of NLP layer is demonstrated on the below example: Sample sentence: ?Thomas A. Anderson is a man living two lives. ? (from the comment on the movie Matrix 1999) After the execution of tagger: ?NNP Thomas  NNP A.  NNP Anderson  VBZ is  DT a  NN  man  VBG living  CD two  NNS lives  ? , where NNP is the proper singular noun, VBZ is the verb 3rd ps. singular present, DT is the determiner, NN is the noun, VBG is the verb gerund, CD is the cardinal number and the NNS is the plural noun. The unigram tag feature extraction would be as below: NNP: 3, VBZ: 1, DT: 1, NN: 1, VBG:1, CD:1, NNS: 1 The bigram tags are the features extracted from consecutive two tags which are:  NNPNNP: 2, NNPVBZ: 1, VBZDT: 1, DTNN: 1, NNVBG: 1, VBGCD: 1, CDNNS: 1  The main purpose of this project is the author recognition.

Besides the pure term frequency (TF) or normalization with inverse document frequency (TF-IDF), some of the author writing styles can be recognized. For example if the author has some words in their writings which are more frequent than the other authors, than these features will help to recognize the author.

On the other hand, some styles can not be detected by the unigram terms only. For example, the data sources is the comments on the movies in IMDB, and an author using the name of movie more frequently will not be able to get recognized, since the movie names, characters or actors are different in each time for each movie. Instead the term frequency approach will count each movie name separately.

In an approach like tagging, all the movie names are either considered as noun or proper noun and if a writer is used to write the name of movie in the comment for example, tagging will count these features. On the other hand, the term frequency will not use the relation between different comments from the same author since the name of movie differs in the comments.

Another example is the determiners. Most of the term frequency approaches do not consider the determiners or conjunctions, instead they are considered as stop words by the term frequency approach. In a tagging approach all these words are taken into account and besides their positions on the text are also considered by using the tag-n-gram. For example a frequently used DT NN pattern, which is a determiner + noun usage can be a key feature to recognize some of the authors, since some authors uses this pattern more frequently than the rest. Or using the tagger, where the term frequency can count these words as stop words and do not take into consideration, can recognize an author using more conjunctions. Even the form of proper nouns would determine the author. For example the sentence quoted from the movie Matrix would be rewritten     as ?Neo is a man living two lives? where Thomas A. Anderson  is the real name of Neo, a character in the movie. And the writing preferences of the authors would be easily recognized by using the unigram tag or bigram tags.

Also the success rates over the data sources, proves the fact of tagging. Tagged versions have at least 8 to 10 percent increases on the overall success.

During the classification, after the feature extraction the classification algorithms use the numerical values gathered from the text. The feature extraction is done in the below manner:  Algorithm : Feature Extraction Methods  1. Ti??TF-IDF of Termi 2. IGi? Information Gain (Ti)  3. Tagi  ?PCount(OS-Tagging of Termi  4. Bigram-Tagi??Concatenate ( Tagi , Tagi+1)  5. V1 ?TOP50(Sort (IG1, IG2 , ? , IGn))  6. V2 ?TOP(Sort (Tag1, Tag2 , ? , Tag48))  7. V3 ?TOP50(Sort (Bigram-Tag1, ? , Bigram-Tagn))  8. V4 ?V2  V3  9. V5 ?V1  V2 V3  The algorithm demonstrates the extraction of 5 different feature vectors in this study. V1 is bag of word, V1 and V2 can be considered as single methods applied for feature extraction. V3 is applied project the characteristics of phrasel features. V4 is the unification of NLP approaches and finally V5 is the unification of all possible feature extraction methods in this study.  The success rates of each execution is pre-calculated with SVM library on weka and only the results with better success are taken into consideration.

TABLE II. SUCCESS RATES OF FEATURES  Merge Approach Success Rate V1 (TF-IDF) 42% V2 (Unitags ) 49% V3 (Bitags) 42% V4 (Unitags + Bitags) 56% V5 (TF-IDF + Unitags + Bitags) 71%  The main purpose of this project is the author recognition.

Besides the pure term frequency (TF) or normalization with inverse document frequency (TF-IDF), some of the author writing styles can be recognized. For example if the author has some words in their writings which are more frequent than the other authors, than these features will help to recognize the author.

On the other hand, some styles can not be detected by the terms only. For example, the data sources is the comments on the movies in IMDB, and an author using the name of movie more frequently will not be able to get recognized, since the movie  name is different in each time. Instead the term frequency approach will count each movie name separately.

In an approach like tagging, all the movie names are either considered as noun or proper noun and if a writer is used to write the name of movie in the comment for example, tagging will count these features. On the other hand, the term frequency will not use the relation between different comments from the same author since the name of movie differs in the comments.

Another example is the determiners. Most of the term frequency approaches do not consider the determiners or conjunctions, instead they are considered as stop words by the term frequency approach. In a tagging approach all these words are taken into account and besides their positions on the text are also considered by using the tag-n-gram. For example a frequently used DT NN pattern, which is a determiner + noun usage can be a key feature to recognize some of the authors, since some authors uses this pattern more frequently than the rest. Or using the tagger, where the term frequency can count these words as stop words and do not take into consideration, can recognize an author using more conjunctions.

Also the success rates over the data sources, proves the fact of tagging. Tagged versions have at least 2 to 4 percent increases on the success.

A. Reshuffling During the implementation, the data sources are manipulated to give the effect of new authors are arriving into the system. Four different ways of reshuffling has been experimented on the IMDB62 dataset and the results show that there is no effect of the way authors arrives on the system over the error rates.

TABLE III. SUCCESS RATES OF RESHUFFLING  Reshuffling i ii iii iv  FP 38,47 38,43 38,4 13,06 FN NaN 11,52 15,3 72,24 NC 0 460 229 2071 Err 47,36 46,6 46,9 45,3 F1 19,01 21,44 22,02 13,64  Where FN stands for false negative, FP stands for false positive, NC stands for the number of novel classes, Err stands for the error rates and F1 stands for the F-1 scoring. In the Table 2 there are also four different reshuffling algorithms.

They are listed as below:  i) The data is considered as it is and each author had 1000 comments consecutively  ii) Only 52 authors got the comments at the beginning and rest 10 authors are attached to the end of the file.

iii) In the first 10000 instances we have only 52 classes/labels. In the next 5000 instances we inject 100 instances of a new class along with the first 52 classes.

iv) In the first 10000 instances we have only 52 classes/labels. For the following 5000 instances, we     inject 1000 instances of a new class, where 200 instances per each 1000 chunk, along with the first 52 classes.

B. Processing Text Data The second data set in this study is the collection of comments on the internet movie database (IMDB62) and comments are collected in English natural language. Aim in this study is the author attribution depending on the comments of the authors.

We have applied two approaches to the feature extraction from the data set IMDB62  i) Term Frequency - Inverse Document Frequency (TF- IDF) [3]  ii) Parts of Speech Tagging (POS-Tag)[9] In the TF-IDF approach, a statistical feature is extracted depending on the occurrences of the terms. This approach is useful for author attribution but the number of features extracted is 142,912 and the data processed in this case is 62,000 records x 142,912 feature for each record, which requires a high amount of computation and memory. Instead we have calculated the information gain through the entropy and selected the top most 50 words for each of the comment.

In the POS-Tagging approach, we have used the Stanford POS Tagger [9] which has 48 different tag types fitting the terms in our corpus. Besides the tagging we have also extracted the bi- tags, which is the consecutive two tags merged together similar to the bigram approach. The number of bi-tags in our corpus is 1,687 and again we have limited this number with the top most 50 of the bi-tags.

After the feature extractions, we have experimented the success rate of features by using classical data mining tools. We have experimented the success rates of some variations of features with support vector machine (SVM) [10] on WEKA [10].

Experiments showed that the success rate of getting TF-IDF approach alone has a success rate of 42\%, using the POS tagger alone has 49\% success and using bi-tags alone has a 42\% success. After getting these success rates, we have merged multiple approaches together and experienced merging tags and bi-tags together. In this case the total number of features is 48 + 50 = 98 and the success rate increases to 56\%.

Finally we have merged all three approaches, which are TF- IDF, tagging and bi-tags and the total number of features are considered as 50 + 48 + 50 = 148 in the given order and the success rate has increased to the 71\%.

Depending on these success rates, we have decided to use the three feature extraction methods together in the rest of the IMDB studies.

Fig. 3. Histogram of Tags in corpus  After the pos-tagging, some of the tags have a higher usage while some are rarely used by the authors. Using a rare tag frequently can be clue to recognize the author.

Fig. 4. Histogram of bi-tags in corpus  Histogram of the bi-tag values among 62000 documents in the dataset is given as in Figure XXX. We have 1687 bi-tag features among all the documents in the dataset.



V. EVALUATION The chunk size increase has an effect on the error rates.  Table 2 covers the same algorithm [5] with the same shuffling ?c? from the Table 1 and demonstrating the difference on the error:     Fig. 5. The decrease on the error rates depending on the chunk sizes  The algorithms starts with building the initial ensemble of models L with the first M labeled data chunks[7].

Also experiments show that the parameters of K and L has no effect in our case.

Fig. 6. In both algorithms, L-Parameter has no effect.

Fig. 7. Effect of K-Parameter  Also three different algorithms has been experimented during this study:  i) ECSMiner (EM) [5] ii) DXMiner (SC) [6] iii) Wang (CL) [7]  We used the following performance metrics for evaluation: Mnew = % of novel class instances misclassified as existing class, Fnew = % of existing class instances Falsely identified as  novel class, OTH = % of existing class instances misclassified as another existing class, ERR = Average misclassification error (%)(i.e., average of OTH, Mnew and Fnew). We build the initial models in each method with the first three chunks.

Starting from chunk four, we first evaluate the performances of each method on that chunk, then use that chunk to update the existing models. The performance metrics for each chunk are saved and averaged for each method to produce the summary result.

The results show that the error rates varies by the algorithm.

TABLE IV. SUCCESS RATES FOR EACH OF THE ALGORITHMS  EM SC CL Fnew 4.03 1.91 0.0 Mnew 100 99.55 99.21 ERR 65.56 64.07 65.43  The table XXX holds the baseline application with high error rates. After applying the optimization approaches like in the chunk sizes, L-Parameter, and using the reshuffling.

TABLE V. SUCCESS RATES AFTER OPTIMIZATION  EM SC CL Fnew 0.0217 0.003 0.003 Mnew 99.84 99.261 99.697 ERR 39.57 41.48 61.203  The increase of success rate for the ECSMiner has been increased from 35% to 61% by the techniques proposed here.



VI. CONCLUSION This paper, first time addresses the problem of authorship attribution on streaming data mining. Three text mining techniques are applied on the feature extraction phase and the study shows that the base-line implementations for the algorithms are not yielding satisfactory results. After applying the techniques developed during this study, the success rate has been increased from 34-35% to 61%.

This study might be important for the future studies on the field by putting some new ideas on the streaming data mining over the text data source. Also applying similar techniques over the other text data sources would be challenging like the blogs which hold messy data and unbalanced number of instances for each of the author.

