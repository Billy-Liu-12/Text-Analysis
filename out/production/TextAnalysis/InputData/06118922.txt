Multi-relational Algorithm for Mining Association Rules in Large Databases

Abstract?Multi-relational data mining enables pattern mining from multiple tables. The existing multi-relational mining association rules algorithms are not able to process large volumes of data, because the amount of memory required exceeds the amount available. The proposed algorithm MR- Radix presents a framework that promotes the optimization of memory usage. It also uses the concept of partitioning to handle large volumes of data. The original contribution of this proposal is enable a superior performance when compared to other related algorithms and moreover successfully concludes the task of mining association rules in large databases, bypass the problem of available memory. One of the tests showed that the MR-Radix presents fourteen times less memory usage than the GFP-growth.

Multi-relational data mining, association rules, frequent itemsets mining, relational database.



I.  INTRODUCTION Traditional data mining algorithms do the processing by  taking into account that the data is ordered in a single structure, generally a file or a table. This limitation makes it difficult to use those algorithms, for example, in a relational database made up of various semantically related tables [1].

Multi-relational data mining algorithms come as a viable proposal to the limitations of traditional algorithms, making it possible to extract patterns from multiple  registers in a direct and efficient manner, without the need of transferring data to a single  table [2] [3]. Nevertheless, available memory space of the equipment being used may not be sufficient to process the mining of large volumes of data.

Due to this, the performance and use of memory space of such algorithms become an inherent worry for the prospection of large repositories.

This work presents as an original contribution, a multi- relational algorithm for the extraction of association rules focused on its use with large relational databases. This proposal takes into account limited available memory space, since the objective of this work is the mining of large data volumes. To deal with such a restriction, the concept of partitioning the database to subdivide it into units of a size  which can be allocated in memory is used to enable the processing. Moreover, the multi-relational mining algorithm had a satisfactory performance which enabled a timely analysis of the databases. The basis of this work was the PatriciaMine traditional algorithm [4].

This work is organised in the following manner: section II presents the state of the art; section III details the development of the work, describing concepts, data structures and the rest of the information about the proposed algorithm; section IV presents the comparative tests which were done, as well as a discussion about obtained results; lastly, section V presents the conclusions.



II. STATE OF THE ART In this section some of the principal traditional and multi-  relational algorithms available in literature are presented.

Among the association rule mining traditional algorithms.

A. Traditional algorithms The PG (Pattern-Growth) approach and its principal  algorithm, the FP-growth, have been used in numerous studies turned to improving the original algorithm or to propose new efficient methods for the extraction of knowledge. These studies are, most of the times, focused on the development of new data structures that are more efficient than the original FP-tree, or even, turned to presenting solutions which are effective in both dense and sparse databases [5].

The H-Mine [6] algorithm has a structure called H-Struct which favours sparse data mining, requiring only two passes through the database for the construction of its structure.

Although the H-Mine has improved performance, mainly with sparse databases, the FP-growth is even more efficient with dense databases.

The Opportune Project is a hybrid algorithm which extends the functions of the FP-growth and the H-Mine, processing patterns by means of a FP-tree or H-Struct according to the density of the set of data [7].

On the other hand, the PatriciaMine algorithm has a new structure called Patricia-trie, or Radix-tree, which reduces   DOI 10.1109/PDCAT.2011.56    DOI 10.1109/PDCAT.2011.56     the space needed in memory to store a tree by compressing the nodes. With this structure, the algorithm has a good performance with sparse and dense databases, being more efficient than the Opportune Project algorithm [4].

B. Multi-relational algorithms Multi-relational algorithms for mining association rules  use different approaches to represent and extract patterns. A first approach comprises algorithms based on logic, also known as inductive logic programming (ILP) algorithms.

The principal characteristic of this approach is that the data and patterns are represented as datalogs, which are written in first order logic [3].

The most widespread ILP algorithm for mining association rules is the WARMR [8] which functions based on the Apriori [9] algorithm. Another ILP algorithm found in literature is the FARMER [10] which is similar to the WARMR, but is more efficient in the use of ordinate trees for the organisation of frequent items.

There are multi-relational algorithms based on the function and structure of the data using traditional techniques, principally the Apriori and the FP-growth. The intention for that approach is to extend the traditional mining algorithms, which work adequately with the extraction of patterns from a single table, adapting them to a multi- relational context so as to directly enable pattern processing on relational databases. Among the algorithms that extend the Apriori are the Apriori-Group [11] and the AprioriMR [12].



III. THE DEVELOPED WORK - MR-RADIX ALGORITHM The multi-relational algorithm proposed in this work is  called MR-Radix which extends the PatriciaMine algorithm to enable the mining of association rules in large relational databases. The proposal uses the Radix-tree data structure, also referenced to as Patricia-trie, to represent the database.

Such a structure is efficient in its mining algorithm performance and in its use of memory space since it uses 75% (seventy-five percent) less space than the FP-tree used in many PG approach algorithms [4].

The Radix-tree structure is an alternative for mining dense or sparse relational databases since the problem of repository sparseness tends to increase the size of the structure, which is partially overcome by compressing the nodes.

The FP-growth and other derived algorithms use a bottom-up strategy, starting from the node sheets up to the top of the structure [13]. The algorithm proposed in this work does the mining using a top-down strategy, that is, frequent patterns are extracted by searching the Radix-tree from its roots to its node leaves. With this strategy a considerable performance gain is obtained, since there is only one Radix-tree and the whole process is done based on this global structure, eliminating the extra processing load of constructing intermediate and temporary structures. Besides this, the Radix-tree algorithm has an iterative strategy to explore the tree, where a performance gain is also obtained since the computational cost of successive recursive calls is eliminated.

A. Proposal for a relational itemset model To mine data from multiple relational tables, itemset  representation becomes a bit more complex because a larger number of information has to be stored due to the multiplicity of data sources. That has motivated this proposal for a representation model called relational itemset which extends the traditional itemset concept to include information which would enable patterns from relational databases to be identified.

Fig. 1 shows the schema of a relational itemset containing k items with indexes which vary from 0 to k-1.

Each relational item is made up of three identifying fields: Table, which registers the name of that item?s source table; Attribute?s Name, which stores the identification of the column associated to that item; Attribute?s Value, which represents the contents of the Name of the Attribute column to a given register from the source table. To facilitate the visualisation of a relational item, when convenient, the following notation will be used: Table.AttributeName = AttributeValue.

B. Radix-tree Structure The structure of a Radix-tree or Patricia-trie (Practical  Algorithm To Retrieve Information Coded In Alphanumeric) differs to the standard trie because it is capable of compressing nodes. The compression is done by clustering the nodes that share the same branch and, consequently, have the same value for the support counter.

C. ItemMap The structure of the ItemMap (IM) proposed in this work  is to optimize the representation of relational items in the Radix-tree, since otherwise an item relational would need substantial memory space for its storage in the node structure.

An example of the above is the relational item ?Inpatient.Hemorrhage = Yes?. Considering that each character occupies one byte in memory, the space needed to store that item would be 22 (twenty-two) bytes, not including the ?.? and ?=?. As the quantity of nodes in a structure is generally high, just the space needed to store items would occupy a substantial amount of available memory. The IM is used to map a relational item in an index; as said index is stored as a whole which occupies only four bytes, a sizeable memory gain is achieved.

Figure 1.   Relational itemset model.

With that strategy, the structure does the mapping between the relational item representation and the internal representation used by the Radix-tree. The IM has a field which stores the relational item representation and another field which registers the index corresponding to that item in the ItemList (IL). Fig. 2 shows this relationship between the IM and the IL.

D. Description of the proposal The execution of this work?s proposal can be divided into  two stages: the construction of the Radix-tree and the mining of frequent patterns. These stages are described below.

1) Constructing the Radix-tree The construction of the Radix-tree stage needs two  complete sweeps through the database to obtain its frequent items to formulate their representation in the referred structure.

The Radix-tree construction algorithm is an iterative version for the route and extraction of frequent itemsets. The idea of that algorithm is the successive generation of patterns which share the same prefix, that is, the algorithm selects each item from the IL in a decreasing order, according to the support value, and extracts all the frequent itemsets that start with the selected item. A collection of nodes that share a given item I, which are connected by means of the linked list which comes from the IL and is called a t-list(I), makes up a subtree having its ascendants.

2) Mining for frequent patterns A mining process first generally consists of the  construction of a subtree having node leaves containing item

I. This procedure can be done efficiently since the IL has a t- list(I) which makes up a list linking all the nodes that contain I.

The MR-Radix algorithm uses the top-down strategy; therefore, the generation of that subtree can be done with pointer manipulation operations. Still in this stage, it is interesting to point out that the IL structure is also updated according to the adjustment of the subtree, since the ancestral nodes were previously processed, making the altering of its respective IL inclusions possible. With that, itemsets relative to the subtree are generated. The described procedures are successively repeated so that new subtrees can be generated.

Figure 2.  ItemMap and ItemList.

E. Partitioning strategy for the MR-Radix To be able to mine large databases, a strategy of  partitioning the proposed algorithm was implemented. Said strategy consists of the subdivision of databases in the memory into allocatable and analysable portions, which would make possible the processing of large volumes in stages.

The strategy consists of the algorithm trying to read the database registers and so construct the Radix-tree, until it is identified that there is no more possible available memory to allocate the structure. In this way, a portion which is read is then considered as a partition and has its mining done individually. This procedure is repeated until the entire database has been processed, creating as many partitions as is necessary.

The functioning of the MR-Radix algorithm partitioning strategy is succinctly represented in Fig. 3.

Phase 1 in Fig. 3 consists of the generation of frequent local itemsets, obtained from the mining of individual partitions. Still in this phase, those local itemsets are processed to form a set of global candidates. To optimise the analysis of the patterns in this set, which is done in Phase 2, a differentiated representation of said patterns is proposed.

Besides the actual itemset, the pattern also presents two fields: accessed partitions and accumulated support.

The accessed partition field stores a register of partitions in which the pattern is considered as being locally frequent.

The accumulated support field represents the sum of support values, corresponding to the referred pattern in the partitions in which it is frequent, that is, those indicated in the accessed partitions field.

The use of such fields optimises the second partitioning phase, since a pattern count is not necessary in partitions where the patterns were already frequent. The support of each pattern must be verified only in those partitions which are not in the list of accessed partitions. On concluding the count of the support in the remaining partitions, the pattern has the value of the global support in its accumulated support field. That way, frequent global itemsets are obtained, delimiting only the global candidate itemsets having an accumulated support value superior to the pre-established minimum.

Figure 3.   Partitioning strategy.



IV. PERFORMANCE STUDY The study comprised an analysis of the MR-Radix  algorithm, comparing it to correlated algorithms, so as to verify its contribution in practical terms.

A. Databases and test parameters The tests consisted of applying the algorithms to  relational databases, to obtain measurements of execution time and the amount of memory used in processing frequent patterns.

The databases that were used are characterised as being relational bases containing real data that were supplied by professionals in their respective contexts, by means of computational systems registration or similar.

The first database, called BT, consists of a set of registers that store information about a Tumour Bank from a hospital in the interior of the State of S?o Paulo, Brazil. Among the stored information, those related to patients and their respective extracted cancerous samples can be highlighted, as well as the more detailed clinical information supplied on forms by the health professionals. Said database is the responsibility of the Database Group of the Instituto de Bioci?ncias, Letras e Ci?ncias Exatas da Universidade Estadual Paulista (IBILCE/ UNESP).

Another database, called CENSUS, has a sample of the population census done in the United States in the year 1990.

This repository is public and is available at the UCI Machine Learning Repository1. To simplify any mining work, the database had already been pre-processed, having all its data discretizised and free from imprecise and null values.

Table I shows information referring to the databases BT and CENSUS, including the volume of data processed in the tests.

B. Comparative study of the multi-relational algorithms In this section the results relative to the comparative  analysis of the multi-relational algorithms MR-Radix, AprioriMR and GP-growth are presented. In a previous work, the AprioriMR algorithm was implemented in a fDMMR tool [12]. This algorithm was chosen to enable a comparison of the MR-Radix to an algorithm representative of the CGT approach.

Based on the original GFP-growth algorithm [5] and to enable the preparation of the tests, this work also constructed and developed this algorithm by adding a version of it to a fDMMR tool. For the construction and mining stages of the FP-tree, part of the code-fonts from the FP-growth algorithm, implemented by Frans Coenen, were reutilised.

The first analysis to be discussed refers to the application of Multi-relational algorithms on a BT base, to collect respective execution times. Fig. 4 shows the values of execution times in a logarithm scale of the tests done on the BT database.

The graphic evidences the greater efficiency shown by the MR-Radix algorithm in comparison to the AprioriMR.

1 Available at http://archive.ics.uci.edu/ml/. Accessed on 7th May, 2011.

The proposed algorithm is two orders of magnitude faster than the algorithm based on Apriori. The inferior performance of the AprioriMR can be explained by the fact that it is based on a CGT approach, which causes, during processing steps, a high number of patterns to be analysed. It should also be pointed out that the algorithm makes various accesses to the disc, depending on the quantity of stages needed to produce frequent patterns. On the other hand, the MR-Radix does only two of those accesses, independent of the number of patterns to be generated.

Execution times for that database could not be collected for the GFP-growth algorithm, since, for all the support values utilized, there was a problem of insufficient principal memory. An addendum is made that, to verify the quantity of necessary memory, a specific test was done, extending the machine?s available memory.

From the results it was noted that, for a support value of 30% (thirty percent), the GFP-growth algorithm needed more than an extra 300 MB (three-hundred megabytes) of memory. This characteristic is due to the fact that said algorithm, as it is based on FP-growth, has a low performance when used in sparse databases, such as the BT repository. With that, it was observed that the FP-tree generated in the tests had many nodes and branches, besides requiring a considerable memory size for its representation.

Moreover, the MR-Radix algorithm shows little execution time variance in relation to different support values, which can be seen as a beneficial characteristic, since it has a good capacity to deal with a growing number of frequent items. The same behaviour, however, is not seen with the AprioriMR algorithm, since, as support values reduce, it takes more processing time. This characteristic is not exclusive to the AprioriMR as it occurs with other algorithms derived from the Apriori [5].

TABLE I.  DATABASES USED IN THE TESTS  Databases Table Number of columns Number of attributes  BT Sample 13,100 31 Urology_Kidney 60 60 Patient 3,647 18  CENSUS Data 2,458,359 68    Figure 4.  Execution time ? BT repository.

As to memory use, with performances diagrammed in Fig. 5, the MR-Radix algorithm with its use of a Radix-tree data structure manages to substantially compress the database. On the other hand, the AprioriMR algorithm, even when applied to medium sized databases ? such as the BT ? produces a high number of candidate itemsets which require a large memory space to store and manipulate the patterns being processed.

In the extreme case of this analysis, with a support of 0.5% (half percent), it was verified that the algorithm proposed in this work occupied close to 1,600 KB (one thousand, six-hundred kilobytes) while the AprioriMR occupied more than 63,000 KB (sixty-three thousand kilobytes).

With the GFP-growth algorithm, once again it was not possible to collect the values of utilised memory as the algorithm did not conclude processing. Since the amount of memory available was limited at the beginning of the test, it was not sufficient to effectively mine all the analysed support values.

C. Comparative study: mining large volumes of data In this subsection, the performance of multi-relational  algorithms is assessed in situations that involve the mining of a large database, in which the processing frequently needs a space in the principal memory that is superior to that available in the equipment, thus needing the adoption of strategies, such as partitioning, which would enable the mining to be concluded.

In the following tests, it was considered that the principal memory was limited to 42 MB (forty-two megabytes). The intention of the measurement was to verify up to which support values the multi-relational algorithms have the capacity to do the mining within that memory limit.

The multi-relational algorithms used in this stage are the same ones that were used in the previous tests: AprioriMR, MR-Radix and GP-growth. The differential of this test is that it was opted to analyse the MR-Radix algorithm in its standard version in comparison to its version which has the strategy of partitioning the database, called MR-Radix- Partition, to differentiate the reading and analysis of the tests and graphics.

It is worth mentioning that, to do the test, minimum support values were used, varying from 10% (ten percent) to up to 90% (ninety percent), to show the behaviour of the analysed algorithms along the whole range of support values.

The results obtained from this study can be seen in Fig. 6, in which is shown the execution times of the algorithms mentioned in relation to the CENSUS base.

As can be observed, the MR-Radix-Partition algorithm was the only one to conclude the processing of frequent patterns for all the support values that were applied. The rest of the algorithms suffered, at some moments, from the problem of insufficient memory to conclude the mining. The MR-Radix algorithm, because it did not implement the partitioning strategy, did not have its time measured for support values below 30% (thirty percent). GFP-growth performance measurements could not be collected for values below 80% (eighty percent). On the other hand, the  AprioriMR concluded the processing in only one of the tests, with a support of 90% (ninety percent). Besides that, this last one was the algorithm which took the most time to execute the mining task.

The performance of the MR-Radix-Partition and MR- Radix was practically equal up to the support value of 40% (forty percent). This is due to the fact that the MR-Radix- Partition, at the higher support values, behaves in a similar way to the MR-Radix, as the partitioning strategy is not activated in those situations. Such behaviour occurs because the version with the partitioning strategy is capable of identifying that there is sufficient memory to process the entire database so, therefore, does not do the partitioning.

The GFP-growth algorithm only had its performance measured with the two highest support values, 80 and 90% (eighty and ninety percent), since there was a shortage of principal memory. With these cases, their execution time was slightly less than with the MR-Radix and MR-Radix- Partition algorithms.

The division of the CENSUS database into partitions was necessary for support values lower than 30% (thirty percent), due to insufficient memory space. In these cases, as shown in Fig. 7, only the MR-Radix-Partition algorithm succeeded in executing the conclusion. For example, for a minimum support value of 10% (ten percent), the algorithm subdivided the base into two partitions of a sufficient size so that their respective representation could be allocated in the principal memory. For each of the partitions, the algorithm then did the mining for frequent local itemsets and, at the end, joined such itemsets to obtain a set of frequent global patterns.

The second step of the scalability analysis consisted of a study of the use of memory by above mentioned algorithms, when applied to the CENSUS base. Such results can be seen in Fig. 7 where collected metrics are graphically shown.

The AprioriMR algorithm once again had a poorer performance than the rest of the multi-relational algorithms.

Measuring this algorithm was only possible with the highest support value, 90% (ninety percent) since, for all other conditions, the processing could not be concluded due to insufficient principal memory.

The GFP-growth algorithm also used a larger amount of memory, even with the highest support values, than the other algorithms MR-Radix and MR-Radix-Partition. While the MR-Radix, for example, needed 2,250 KB (two thousand, two hundred and fifty kilobytes) for a support value of 80% (eighty percent), the GFP-growth needed 31,000 KB (thirty one thousand kilobytes). That is, the MR-Radix used fourteen times less memory than the GFP-growth.

The behaviour, in terms of memory use of the MR-Radix and MR-Radix-Partition algorithms, was similar at all levels of analysed supports. As already mentioned, this happens because the MR-Radix-Partition has the capacity of identifying available memory space, partitioning the database only when necessary.

It was seen that, for lower support values where only the MR-Radix- Partition algorithm concluded the processing, the amount of memory used remained relatively constant. This is because the algorithm creates partitions which occupy all of the available memory space. Thereby, each partition is     optimised to contain the largest possible number of registers, which, consequently, results in a lower number of partitions and also a lower number of accesses to the disc.

Compared to the GFP-growth, the MR-Radix-Partition and MR-Radix algorithms stand out, principally with the optimised use of the memory. With the execution time comparative tests, it was noted that the GFP-growth had a slightly superior performance, though memory usage was high when compared to the algorithm proposed in this work.

The proposed algorithm produced results that allied low execution time to a better use of the memory.



V. CONCLUSION The MR-Radix algorithm had a superior performance  with execution time and used memory when compared to other multi-relational proposals. Inclusion of the database partitioning strategy in that algorithm made it possible to prospect data from large repositories, such as CENSUS, in which the principal memory space needed to process the data was higher than the space available in the equipment. Results show that, for low support values, only this approach was able to extract knowledge from that repository. That being so, this work presents a significant and original contribution as the proposed algorithm was able to overcome the available memory space problem and do the mining of multi- relational data from large data repositories.

