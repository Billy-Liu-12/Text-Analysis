The Application of Semantic-based Classification on  Big Data

Abstract? Sensory networks are scale-free environments that connect entities remotely but with noticeable tendency among its participating Sensors. The increasing size of data sets and the lack of algorithmic methods that are effectively manage such huge data collections led to growing demands of new techniques to handle big data?s side-effects. In this research, a new ontology- based categorization methodology is proposed. The novelty of this research stems for its focus on modularizing the classification task into multi-layer framework to group data in sensory networks. The three-layer framework assumes that large datasets of sensory networks are heterogeneous. Therefore, an ontology- layer could be created to identify semantic interpretation of data and semantic relationships with other domains? data.

The goal of this research is to provide a technique that facilitates extracting ontological patterns, which enhance the semantic interpretation of such pool of knowledge. Furthermore, the proposed framework facilitates integrating different heterogeneous sources of knowledge into a single one.

Keywords? Big Data Classification; Mining Big Data; Classification of Large Datasets

I.  INTRODUCTION One of the most important changes in the twenty-first  century that are currently being felt by our societies is the profound impact of globalization and information technology; huge electronic linkages and interconnections have been created among societies to form networks, which have been developed to connect different entities via virtual links.

Most sensory networks are scale-free; a set of sensors are connected to a sink that collects timely data and send it to some destination server. While sinks could be considered as a bottleneck entity, self-routing features of sensors minimizes such risk. Therefore, sensory networks produce huge data that need to be managed in terms of access, storage, retrieval, and many other aspects. Such collection is called big data as it is accumulating in an exponential rate.

The natural tendency of entities, within sensory networks, permits managing such big data storage using data mining analytical tools. In fact, it is getting more and more difficult to  build faster processors. The hardware industry keeps on increasing the number of processors, cores, or graphics card, and also invests into improved storage technologies. However, all these investments are in vain; if we lack algorithmic methods that are able to efficiently utilize additional processors or memory features.

This paper presents a framework of applying a modified version of ROLEX-SP classifier [1]. The new classifier has been developed to classify data from different domains of knowledge. The idea is to construct three layers for connecting classifiers from different domains semantically. This way, the proposed framework can guarantee abstracting concepts (class labels) as representatives of some group of knowledge to create semantic connections among knowledge sources. The advantages of the proposed framework is to facilitate connecting, capturing, and accessing relevant information from large datasets of sensory data as an application of ontology- based classifiers.



II. LITERATURE REVIEW The term ?Big Data? has been first introduced to reflect the  daily increasing of data created by different information systems. Last year, a talk by Usama Fayyad [2] presents some statistics about internet usage reported by well-known market leaders such as: Google?s queries, Tweeter?s tweets, daily Facebook? updates, and YouTube?s views. He showed that the estimated growing of data on the internet is about 40% per year.

Because Clouds and Smart devices play a significant role in increasing the data storage on the internet and rising new issues and challenges in, identifying new strategies to managing such large datasets became more crucial. For instance, J Bughin [3] showed the need to think about new strategies about how to prepare organizations for the challenging of the continuous growth of data warehouses. Thus, resolving big data issues is an essential component of management decision making requires new capabilities, as well as organizational and cultural change.

D. Laney [4] studied the big data phenomena. He concluded some aspects of managing it. The first one is that our existing tools cannot process such volumes as its size continues increasing. The second observation focused on the harmony among data objects; the big data is a collection of heterogeneous data that makes it difficult to analyze. And finally, the researcher observed that obtaining timely data is difficult in terms of accuracy and complexity.

W. Fan et al [5] discusses these three conclusions and showed that they demand cost-effective, innovation forms of information processing for enhancing insight understanding and decision making.

The application of big data solutions takes place in different domains, which makes it an important issue nowadays. For example [6, 7]: customer personalization in business domain, response time in technology domain, DNA analysis in health domain, and many examples in the domain of smart cities.

The usefulness of mining big data in enhancing life in developing countries has been studied in [8]. Researchers proposed a strategy to come with innovative methods and techniques for analyzing real-time digital data to detect early emerging vulnerabilities, assembling free and open source technology toolkit for analyzing real-time data and sharing hypotheses, and establishing an integrated and dedicated network to conduct an approach at country level.

Researchers in [9] described the main opportunities big data offers to developing countries such as: Early warning, Real- time awareness, and Real-time feedback. The big data mining revolution is not restricted to the industrialized world, as mobiles are spreading in developing countries as well. It is estimated than there are over five billion mobile phones, and that 80% are located in developing countries.

Finally, researchers in the field of big data analysis benefit from the revolution of open source software. Popular examples of open sources are: Apache Hadoop [10], Apache Hadoop related projects [11], Apache S4 [12], and Storm [13]. In big data mining, there are many open source initiatives. The most popular are the following: Apache Mahout [14], R [15], MOA [16], Vowpal Wabbit [17], Pegasus [18], and GraphLab [19].



III. METHODOLOGY This research illuminates three aspects of big data:  hetereouginity, volume, and relationship among its contents. In fact, providing solutions to thsese issues will positively affect accessing, managing, and retrieving data from a large sets of information. Figure 1 shows the proposed Design Model.

Divide-and-Conquer is one of the most usable strategies in computer science for many algorithmic purposes and data managements. The goal of this research is to divide the huge data collection into domain-specific collections and divide the classification task into mainly three layers. The first layer represents homogeneous data that have been collected from a specific domain of knowledge. The second layer abstracts the ontological aspects of the layer below. And finally, the abstract layer (at the top) represents the controller part that manages connections among different domains.

A. Homogeneous Data Layer At this layer, the huge source of data is divided into domain  specific sources of knowledge. Clustering of different types of data is widely applicable in data mining tools. The aims of having this level are to minimize ambiguity among heterogeneous data and, therefore, to enhance the accuracy of retrieving relevant information.

Figure 1 Layered Classification-Model    Next, every dataset of domain knowledge is attached a classifier. The classifier, in this context, acts as a pointer that classify incoming information (for example: query) under one or many knowledge entities. The most important issue that rises during the application of domain specific classifiers is the multi-class classification feature; guarantee that some information might be related to more than one domain of knowledge. Applying this feature might resulted in redundant data storage, but, on the other hand, it enhances the accuracy and performance, and minimizes ambiguity (False Positives)  For this purpose, a modified version of ROLEX-SP classifier [1] has been developed in which both issues were handles. ROLEX-SP is a domain specific textual classifier that constructs lexical syntactic patterns to increase the accuracy of textual classifiers. Thus, the first layer will consist of a classifier on the top of a homogeneous domain specific sub- dataset.

B. Ontology Layer At this layer, a set of relationships and reasoning are kept.

Ontology is an ?Explicit specification of conceptualization?.

This layer represents a shared vocabulary that distinguishes a domain of knowledge from all other domains. In addition, this layer provides the lower one (homogeneous data layer) the reasoning about classifying data in some given domain.

To simplify the implementation, a set of relations has been defined for every domain of sensory data. Such definitions act     the source of ontology. However, the correctness of the ontology source plays a significant role in producing high performance classifiers.

Ontology layer facilitates connecting different domains of knowledge as it formally defines these relations. Abstracting this layer facilitates modularity and, therefore, connectivity with other domain knowledge through the application of the control layer at the top of the proposed framework.

The formal description of connectivity among different domain can be specified as follows: given the facts ji DYDX ??? , where X and Y is related to different domains (i, j): define the function ? as a mapping relation between both domains such as:  ])()()(:[ ?? ??? YXDODO ji ? , where )( iDO is the set of representative ontology of the domain iD .

In fact, there are many other relations that could be formally described and implemented using ontology-based models.

Therefore, the learning and training part of classifiers is responsible to handle such relations  C. Control Layer (Access Layer) This layer facilitates accessing data by receiving queries or  commands, identify relevant domains using the information from ontology layer, and retrieve as accurate as possible information. The process here is bidirectional; the control layer passes commands to the ontology layer and received hits from the ontology layer. The ontology layer passes the relationships of different domains to the below classifier, which, in turn, filter out relevant knowledge using information at ontology layer.

The implementation of the control layer requires standardizing the data storage and structure among all existing domains to ensure the ability of merging results in a good fashion. Also, the control layer might provide variety of services according to the information from bottom layers.

These services include, but not limited to, displaying classified results, query expansion, and data summarization.



IV. IMPLEMENTATION In this section, an explanation is provided for implementing  the proposed framework. Figure 2 shows four elementary tasks to implement the three-layer design: 1) Data analysis and relation enrichment, 2) Constructing Semantic patterns, 3) aggregating classification patterns, and 4) Building domain classifiers.

A. Semantic Features The Application of semantic principles in data mining is  done by formulating a set of rules that allows computer programs to make decision by understanding input data. Our proposed framework analyzes a set of input scenarios to extract rules that formulate the semantic features of actions. The entries represent relationships among attributes in a specific category of knowledge [1]. Specifically, domains of knowledge  are modeled as ontology model that facilitates understanding its role in some given context.

Figure 2 Flow diagram of Implementation Tasks    Semantic Features are background information for learners (Classifiers), which reduces ambiguity and expands learner?s knowledge and understanding. Although, features of domain knowledge complicate the categorization of information in big data warehouses, it provides a valuable source to classify data under its relevant class of knowledge.

While semantic features are the source of related entities, relation module maps attributes with semantic relations. For instance, relation module models relations such as cause-effect, transitive-relation, part-of, and many others relations.

In this research, each category of knowledge is assigned a a set of semantic features and relations for the purpose of classifying incoming data according to the specifications of the classification tool ROLEX-SP [1].

B.  Semantic Patterns Pattern is a structured representation of features that, when  combining all features? values, recognizes an instance (or more) of data. Thus, we are studying the values of the extracted features to come with a pattern of data that, of course, frequently appears in the datasets. A semantic pattern has been proposed in the past to extract relations among concepts such as synonyms, Hearst [20]. In this research, we used to extract Hearst-like patterns to construct rule-based classifiers.

Semantic patterns are more robust in representing class properties than basic feature since they do not bias toward frequent terms [21]; resulted in feature imbalance problem. On the other hand, semantic patterns are able to represent more than one domain of knowledge in the same pattern just like multi-feature representation. Our hypothesis, in this research, is to measure the capability of semantic patterns to increase the coverage as well as the accuracy of rule-based classifiers and, at the same time, reduce classification errors resulted in term and multiple features.

C. Aggregation of Classification Patterns It is normal to produce large number of semantic patterns  from a large pool of data. The huge number of generated patterns affects the efficiency of classifiers negatively. Thus, there is a need to minimize the total number of representative patterns. For this reason, patterns are aggregated according some features such as: Coverage, transition, conjunction, disjunction, and co-existence of patterns.

Aggregation module is responsible to filter-out redundant patterns. This function plays a significant role in minimizing the complexity of the classification task. On the other hand, extracting aggregation rules is not simple; requires intelligent learning algorithms. In this context, big data warehouses provide a rich training set of data. By training data from a specific domain of knowledge, eliciting such relations becomes feasible.

D. Multi-Classifiers Construction The formulation of the proposed multi-classifiers  framework relies on the assumption that heterogeneous data is a combination of different homogonous ones [22]; in other words, a combination of data from different domains.

According to this assumption, construct a classifier for each domain. Then, find the relationship between classifiers, so that knowledge from different domains could relate to each other.

The relationship among different classifiers can not be modeled using semantic relations; instead it is an ontology mapping that relates information from different domains.

This research constructs a set of rule-based classifiers in which each of them consists of a set of association rules to classify sensory data. In addition, an abstract module has been constructed to model the relationships among classifiers themselves. Thus, during classification of data, for example, our classifier was able to connect temperature with water volume.



V. CASE STUDY Consider the scenario in which a smart irrigation system is  seeking for information from different sensors that generates heterogeneous data. Further, consider every sensor has an independent dataset that describes information, facts, experiments and much other relevant information. However, data managers are intended to add new knowledge, modify existing ones, or even delete expired or wrong facts from each dataset, given that all datasets are kept in a single huge pool (i.e. warehouse). Thus, the collection is heterogeneous as it describes different descriptive information for different sensors.

One might query for ?water volume?. According to the design of the layered classification, there would be a classifier for ?temperature? that is fully supported by ontology- description of air temperature, land temperature, humidity, and conductivity. Such information has been extracted using the system described in Figure 3 as a source of relevant knowledge. The water volume classifier will expand the query with related data from different sensors.

Figure 3 Automatic Irrigation System Architecture   In order to enrich the mining process with useful  information about ?water volume?, the top layer uses the information from ontology layer to connect different sources.

As a result, it found the relationship between ?water volume? and ?temperature?, for example, which allow computing or predicting future need.



VI. CONCLUSION This paper presents a framework to automate multi-layered  classification algorithms for the purpose of resolving organization issues of big data collections. The goal of the proposed framework is to facilitate connecting, capturing, and accessing relevant information from large and heterogeneous datasets of sensory data as an application of ontology-based classifiers. Furthermore, descriptions of implementation modules have been provided to reason about the proposed idea.

The paper presents, too, a case study on detecting relationships among different domains of knowledge to make the proposed framework understandable.

Future work is planned to experiment this idea, including: discovering aspects of heterogeneities from different real-world domains of knowledge, proposing a standard metadata description for structuring heterogeneous datasets, studying the possibility to formally define heterogeneity and its related classifiers, and orthogonal aspects of data.

