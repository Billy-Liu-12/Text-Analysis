Efficiently Mining Maximal Frequent Sets

Abstract  We present Metamorphosis, an algorithm for mining Maximal Frequent Sets (MFS) using novel data transfor- mations. Metamorphosis efficiently transforms the dataset to Maximum Collapsible and Compressible (MC2) format and employs a top down strategy with phased bottom up search for mining MFS. Using the chess and connect dataset [benchmark datasets created by Univ. of Califor- nia, Irvine], we demonstrate that our algorithm offers bet- ter performance in mining MFS compared to dGenMax (an algorithm that offers better performance compared to other known algorithms) at higher support levels. Fur- thermore, we evaluate our algorithm for mining Top-K maximal frequent sets in chess and connect datasets. Our algorithm is especially efficient when the maximal fre- quent sets are longer.

1. Introduction  Mining frequent itemsets is a fundamental and essential operation in many data mining applications including dis- covery of association rules, strong rules, correlations, se- quential rules, episodes, multi-dimensional patterns [6]. In general, frequent itemset mining problem is formulated as follows: Given a large database of transactions, our task is to identify frequent itemsets, where frequent itemsets are those itemsets that occur in at least a user-specified per- centage of the database [10].

Most of the current itemset mining algorithms are vari- ants of Apriori and it has been demonstrated that such al- gorithms are inadequate on data sets with long patterns [4]. As Apriori based algorithms employ a pure bottom- up, breadth first search, mining a frequent pattern of length m require mining all its 2m ? 2 subsets, which would be computationally expensive if m is very large (> 30).  Hence, there has been recent interest in mining  Maximal Frequent Sets (MFS). MFS are frequent itemsets whose supersets are infrequent and all its subsets are fre- quent.

Recent approaches to MFS mining include Pincer-Search [7] algorithm that uses a mixed search strategy to enumer- ate MFS. MaxMiner [4] performs a breadth first traversal of the search space with look-ahead. GenMax [10] uses vertical data representation and tidset intersections to mine quickly the MFS. dGenMax[10] is an improved version of GenMax which uses a novel vertical data representation called diffsets that only keeps track of differences in the tids of a candidate pattern. DepthProject [3] utilizes depth first search of a lexicographic tree. It employs a transaction projection mechanism for counting the support of itemsets quickly. Mafia [5] uses three pruning strategies to remove non-maximal sets. They are look-ahead pruning, superset frequency pruning, and parent equivalence pruning. A top- down algorithm proposed in [9] uses a novel concept of dominancy factor for efficiently mining MFS.

Our primary motivation in this paper is to demonstrate that it is possible to mine quickly the entire set of MFS by employing a top-down strategy with phased bottom-up search in dense domains. Additionally, we employ novel data transformation techniques to mine quickly the entire set of MFS.

The organization of the rest of paper is as follows:  In the next section we introduce the model, notations, and prun- ing properties used in our algorithm. Section 3 gives the implementation details of our algorithm in various phases.

In Section 4, we present our experimental results. Finally, in section 5, we conclude with a discussion of future work.

2. Model And Notations  The mining algorithm introduced in this paper presumes a dataset consisting of transactions that contain multiple items in each transaction. A set of items present in a trans- action is referred to as an itemset. We assume that the  Proceedings of the Seventh International Database Engineering and Applications Symposium (IDEAS?03)     items in the transaction are ordered sequence of numbers as per IBM artificial data set generator format [2].

Let  = {i1, i2, ?.im} be a set of distinct items. A set X is called an itemset. An itemset X with k items (Xk) is  succinctly referred as k-itemset.

A transaction, Ti = {x  |  = 1, 2?Ni; x }, where Ni  is the number of items in transaction Ti. A transaction Ti is said to support an itemset X  if and only if X  Ti. The support of an itemset X, denoted by Sup (X), is the total number of transactions in the dataset that supports X. The user defined minimum support is denoted as minsupport.

An itemset X (Frequent itemsets) if and only if Sup (X)  minsupport.

In order to assist in identifying the unique transactions, we define a hash value of transaction Ti as follows:  Let LogP be an array containing a set of logarithm of prime numbers. The hash value of transactions Ti, denoted as Hval (Ti), is defined as  Hval (Ti) =  = 1 Ni LogP [x ],  x  Ti.

We know that the product of prime numbers is unique and log (m*n) = log (m) + log (n). Hence, it can be easily verified that the computed hash values would be unique only for unique transactions. In earlier passes of the algo- rithm we collapse the duplicate set of transactions using computed hash values. For more details regarding hash value computation and its usage in collapsing duplicate transactions, the reader is referred to [8].

The dataset or transaction list, D, is an ordered set of triplet,  D = {(Ti, Ni, Supi) | i = 1, 2?L; where, Ti is the i  th transaction containing itemset x ; Ni is the number of frequent 1-items in Ti; Supi = Sup (Ti);  } Where L is the total number of unique transactions in the dataset.

Table 1 gives a bird?s eye view of the transaction list, D.

Table 1.  Transaction List, D TID Ti (x ) Ni Supi T1 1 2 3 4 5 5 1 T2 1 2 4 5 4 2 T3 1 2 3 5 4 1 T4 2 3 5 3 1 T5 2 3 4 3 1  Note: Sup (1) = 4; Sup (2) = 6; Sup (3) = 4; Sup (4) = 4; Sup (5) = 5  We define TSUP as the set of supports of transactions in D. That is,  TSUP={Supi, i=1, 2, 3?L}.

For example, the transaction list D in Table 1 has  TSUP={1, 2, 1, 1, 1}.

We denote NumF1 as the number of frequent 1-itemsets in the dataset at the user defined minimum support. The set of all frequent 1-itemsets (in ascending order of 1-item support) is denoted as  1 = {x |  = 1, 2? NumF1; Sup (x ) >=minsupport; Sup(xi)  Sup(xi+1) and i=1,2?(NumF1-1)}.

For the transaction list D in Table 1, assuming a user de-  fined minimum support of 3, NumF1 = 5 and 1 = {1,3,4,5,2}.

Similarly, the set of frequent 2-itemsets is denoted as 2.

As frequent 2-itemsets has just two items, each item in 1 will have set of other items (in 1) with whom it is fre- quent. We refer to this as set of extensions of an item, de- noted as Extension (x ). For the example in Table 1, as- suming a user defined minimum support of 3,  Extension (1) = {2, 5} as (1,2) and (1,5) are frequent.

Extension (2) = {3, 4, 5} as (2,3), (2,4) and (2,5) are fre-  quent.

Extension (3) = {5} as (3,4) is infrequent and Extension  (4) = {} as (4,5) is not frequent.

The maximum number of elements in Extension (x ) is  denoted as Maxlen. For the above example, Maxlen = 3 as Extension (2) has the maximum number of elements of 3.

To mine the MFS efficiently, we transform the transac- tion list D to a collapsed and compressed format. In this work, we refer to this format as Maximum Collapsible and Compressible (MC2) format. We now describe the nota- tions specific to this transformation.

Let us assume W as the Word Size of a computer. That is, for a 32-bit computer W=32 and for a 128-bit computer W=128.

We compress the itemsets in every W transactions of D to a single transaction using vertical bitmaps. Table 2 gives the vertical bitmap compression for the transaction list D in Table 1 with W=3. That is, Table 2 shows the bitmap equivalent for the items in every 3 transactions (i.e. NewT1 for T1, T2, T3 and NewT2 for T4, T5).

Table 2.  Vertical Bitmap Representation (W=3) NewTID Item1 Item 2 Item 3 Item  Item  NewT1 111 111 101 110 111 NewT2 000 110 110 010 100  Table 3 gives the decimal notations for the bitmaps in Table 2. We transform the dataset in Table 1 to Table 3 and refer it as MC2 (Maximum Collapsible and Compressible) format. Note that although we store the bitmaps in decimal notations as in Table 3, the numbers are internally stored in computer in binary form as in Table 2. Further, W is taken as 32 in the actual implementation though the illustrations in Table 2 and Table 3 has W=3.

Proceedings of the Seventh International Database Engineering and Applications Symposium (IDEAS?03)     Table 3.  Dataset in Maximum Collapsible and Compressible (MC2) format  NewTID Item  Item  Item 3 Item 4 Item 5  NewT1 7 7 5 6 7 NewT2 0 6 6 2 4  Our algorithm starts mining the MFS using the dataset in MC2 format. Now let us describe the notations specific to MC2 format. The transactions number i in MC2 format is referred as NewTi.

Bit (x , i) denotes the bitmap for item x  in transaction NewTi. Here, by bitmap we refer to the equivalent inte- gers stored for item x in MC2 format. For instance, in Ta- ble 3, Bit (3, 1) is 5 and Bit (5, 2) is 4.

The bitwise AND of all the items in an itemset Xk in transaction NewTi is denoted as AND (Xk, i). For instance, when k=2, AND (X2, i) = Bit (x1, i) & Bit (x2, i). Note that the operator & is a bitwise operator.

During the mining process, we check for infrequency of subsets of a k-itemset. For accomplishing this we hold a set of infrequent itemsets in a tree named as INF_Tree.

We store the MFS generated during the mining process in a Maximal List,  ML = {X | X  and (X  {x })  ;  1;} The itemsets in maximal list are stored in compressed  form, similar to the one shown in Table 3 with W=32.

We define the MFS of longest length as LM (Longest  Maximal) pattern.

For efficient mining our algorithm uses two pruning  properties namely, Apriori [1] and Reverse Apriori [7] for limiting the search space.

We define Top-K MFS mining problem as a set of K MFS of longest length. So, essentially the top-K MFS mined will have very low supports compared to all other MFS.

3. Implementation Of Metamorphosis  Our algorithm follows a top-down approach with phased bottom up search for mining MFS. In this section we de- scribe the algorithm in various phases.

3.1 Transaction List Generation  In the first pass, the algorithm scans the dataset and computes support for all 1-itemsets. The infrequent 1- itemsets are removed from further evaluation. In the sec- ond scan of the dataset, we compute the hash value for all frequent 1-itemsets in each transaction. Before we add a transaction to the Transaction List D, we check for unique- ness of transactions using hash values [8]. If unique hash value already exists we increment the support of corre- sponding transaction. Otherwise, we add it as a new trans- action in D. A sample transaction list, D is given in Table 1 (assuming a user specified minimum support of 2). We store the support value of transactions in TSUP.

While generating D, we store the support values of transaction in TSUP. After the transaction list, D is gener- ated; we make a pass over D to compute 2 and Maxlen.

3.2 MC2 format Dataset Generation  The algorithm converts the transaction list, D to MC2  format by compressing the dataset using vertical bitmaps  Metamorphosis (Data-set DB): Inputs: 1. Data Set, DB; 2. minsupport; 3. K (number of MFS desired), to be given only for Top-K MFS mining 1. 1 = {Frequent 1-itemsets} 2. For each Ti  DB do begin 3.      Hvali = =1  Ni LogP [x ]; 4.  Scan D and check for unique Hvali, if exists increment its support,  Otherwise, sort items in ascending order of support and add Ti to D 5.  End 6.  Scan D and compute 2 supports (frequent 2-item supports), Maxlen 7.  Convert D to MC2 format and write the result to NewDB 8.  ML={}; 9.  Initialize k to Maxlen 10.  For  k = Maxlen to 2 do begin 11.    Generate k-itemsets, check for maximality and infrequency of subsets using INF_Tree, 2 supports and  phased subset frequency checks 12.         For each NewTi  NewDB do begin Compute support of k-itemset by bit-wise AND operation and if the support crosses minsupport  requirement, and if no superset of it are frequent, add it to Maximal List, ML 13.        End 14.        If (Top-K MFS mining) do  15.           If  (ML has at least K maximal frequent set) go to step 18.

16.      decrement k by 2 17.   End 18.   Return Output  Figure 1. Pseudo-code for Metamorphosis Algorithm  Proceedings of the Seventh International Database Engineering and Applications Symposium (IDEAS?03)     (with W=32). Once the MC2 format dataset is generated, we discard the transaction list D. Table 3 gives a bird?s eye view of the dataset in MC2 format. For a machine with W=32, we can logically store vertical bitmaps of 32 transactions. This 32-bit number can be represented as 10 digit unsigned integer. Table 3 shows these vertical bit- maps in decimal form with W=3.

3.3 Subset Generations, and Itemset Pruning  As our algorithm follows a top down approach, we start with generating all itemsets of size, k equal to Maxlen.

Our algorithm generates k-itemsets recursively using the items in 1. For the k-itemset generated, we check whether it is subsumed by a previously generated MFS stored in ML. If so, we generate the next k-itemset from  1 and repeat the above procedure. Then we check for in- frequency of subsets for a k-itemset in three steps. In the first step, we check whether all 2-itemsets present in k- itemset are frequent. If not, generate a new k-itemset and repeat all of the above procedures. In the second step, we check whether the k-itemsets? subset is infrequent by us- ing the infrequent tree, INF_Tree. If infrequent subsets of a k-itemset are present in INF_Tree, generate a new k- itemset and repeat all of the above procedures. In the third step, we evaluate whether the k-itemsets? subsets are fre- quent in a phased manner. The details of phased subset frequency check are as follows:  1. In phase 1, we check for the frequency of first 4 and first 6 items present in the k-itemset. If it is found to be infrequent, we add the infrequent subsets to INF_Tree and repeat all of the above procedures.

2. In phase 2, we check for the frequency of first 8 and first 10 items present in the k-itemset. If it is found to be infrequent, we add the infrequent subsets to INF_Tree and repeat all of the above procedures.

3. In the next phase, we check for the frequency of first 12 and first 14 items present in the k-itemset. Subse- quently for first 16 and first 18 items present and so on till the number of items to be evaluated for subset frequency are less than k. If any of the intermediate phases of subset frequency evaluation fails (that is the subset is infre- quent), we add the infrequent subset into the infrequent tree, INF_Tree and repeat all of the above procedures.

4. Compute the support for the k-itemset as well as (k+1) itemset in a single pass. Add the frequent itemsets to ML if it is not subsumed by an existing MFS.

The phased subset frequency evaluation is a heuristics employed to identify the smaller infrequent nodes in the dense domain quickly.

All of the above procedures are repeated by decrement- ing k by 2 (as the support for a k and k+1 itemsets are  computed in a single pass) till 2. The pseudo-code for Metamorphosis is given in Figure 1. Lines 14 and 15 of the pseudo-code are used when mining Top-K MFS. In Top-K MFS mining, as soon as the total number of MFS crosses the user specified number of MFS (referred as K), our al- gorithm stops and outputs the result.

3.4 Support Counting  The support for an itemset, Xk is computed by perform- ing a bit-wise AND operation on all the items in the item- set Xk. The resulting number is converted to equivalent bi- nary number, say result, and the support is computed by using the position of 1?s in result and the TSUP values. For example, support for an itemset {1,3,5} is computed from Table 3 as follows:  From NewT1: AND ({1,3,5}, 1) = 7 & 5 & 7 = 5. Note that logically this operation would be treated in computer, as equivalent to 111 & 101 & 111. The equivalent binary notation for 5 would be 101. So, result=101. From position of 1?s in result, we can infer that the itemset {1,3,5} is supported by transactions T1 and T3 in the original transac- tion list D. As the support values of transaction list, D is contained in TSUP, the support of itemset {1,3,5} in NewT1 is the sum of TSUP1 and TSUP3, which is 2.

From NewT2: AND ({1,3,5}, 2) = 0 & 6 & 4 = 0. The equivalent binary notation is 000. So, result=0. As there are no 1?s in result, the support of itemset {1,3,5} in NewT2 is zero.

Hence, the support of the itemset {1,3,5} from Table 3 is the sum of the above two values, which is equal to 2. The results can be easily verified from Table 1.

3.5 Maximality Checking  As soon as a k-itemset is found frequent, after checking if it is subsumed by any other MFS, it is written to ML.

The Maximal List, ML stores the itemset in compressed bit-vector form similar to the example in Table 3 with W=32.

4 Experimental Results  All our experiments were performed on a 450MHz Pen- tium-III PC with 64MB of memory, running RedHat Linux 7.2. We use two benchmark datasets for experimentation viz. chess and connect. The characteristics of chess dataset include: 3196 transactions, 75 items and average transac- tion size of 37. The characteristics of connect dataset in- clude: 67557 transactions, 129 items and average transac- tion size of 43.

Proceedings of the Seventh International Database Engineering and Applications Symposium (IDEAS?03)     4.1 Evaluation of Metamorphosis for Mining All the Maximal Frequent Sets  For performance comparisons, we used the original source codes for GenMax [10] provided to us by their au-  thors. The timings reported in this paper include all pre- processing costs (such as time for horizontal-to-vertical conversion in GenMax and transaction collapsing, com- pressing in Metamorphosis) and doesn?t include the out- put time for displaying MFS for GenMax, dGenMax and Metamorphosis.

Figure 2 shows the performance comparison of Meta- morphosis against GenMax and dGenMax on chess and connect datasets. Note that the graphs are plotted for Metamorphosis Vs GenMax and Metamorphosis Vs dGenMax separately to improve the visibility. It is clearly evident from the graph that Metamorphosis outperforms GenMax at supports above 50% (cut-off not shown in the graph) and dGenMax at supports above 71% for the chess dataset. For the connect dataset, Metamorphosis outper- forms GenMax at support above 53% (cut-off not shown in the graph) and dGenMax at supports above 68%. At supports below this point Metamorphosis performs poorly  due to the fact that the Longest Maximal pattern size is far below Maxlen and the primary search strategy employed by Metamorphosis is top-down.

Figure 3 depicts the graphs of NumF1, Maxlen and LM pattern size against different minimum support levels. As  can be evident from the graph, the cleft between the NumF1 and Maxlen as well as Maxlen and LM Pattern Size grows faster as the minimum support decreases. The faster growth of the cleft explains why Metamorphosis per- forms poorly in mining all the MFS at lower support levels.

So, the real application domain of Metamorphosis is on those datasets for which the MFS are much closer to Max- len as well as NumF1.

4.2 Evaluation of Metamorphosis for Mining Top- K MFS on Benchmark Datasets  Figure 4 gives the mining time required for mining the Top-100 and Top-200 MFS on chess and connect dataset.

As can be evident from Figure 4, the time required for min- ing the Top-100 and Top-200 MFS are significantly lower compared to mining the entire set of MFS.

Figure 2. Performance Comparison of Metamorphosis Vs GenMax and dGenMax on chess and connect  chess        0.

0.

0.

0.

0.

Minimum Support  T im  e (  s e  c )  Metamo rphosis GenMax  chess  0.0  0.1  0.2  0.3  0.4  0.5  0.

0.

0.

0.

Minimum Support  T im  e (  s e  c ) Metamorp  hosis  dGenMax  connect       0.

0.

0.

0.

0.

Minimum Support  T im  e (  s e  c )  Metamor  phosis  GenMax  connect  0.0  5.0  10.0  15.0  20.0  0.

0.

0.

0.

Minimum Support  T im  e (  s e  c )  Metamorp hosis dGenMax  Proceedings of the Seventh International Database Engineering and Applications Symposium (IDEAS?03)     Top-K MFS mining holds promise on applications in which the total number of MFS generated is exponentially large and mining the entire set of MFS becomes difficult.

In general, the characteristics of Top-K MFS include (a) they have much lesser support compared to that of all other MFS, (b) they can be used for generating large number of association rules with very high confidence, especially for large number of items in antecedent of a rule.

5 Summary And Future Research Directions  In this paper we presented and evaluated Metamorpho- sis, an algorithm for mining MFS using novel data trans- formations.

A hybrid system that invokes the Metamorphosis algo- rithm at higher support levels and dGenMax at lower sup- port levels can be developed for mining in a real or pro- duction environment.

