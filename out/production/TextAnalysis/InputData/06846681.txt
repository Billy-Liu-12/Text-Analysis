A New Robust Watermarking Scheme Based on Features Classification Tree

Abstract?Digital watermarking technique is a common solution to image authentication and authorization. Numerous researches in this area use modification method to alter the pixel value or the coefficients of transform domain to succeed the watermarking purpose. In this paper, we propose a novel watermarking scheme using the concept of association rules to build a features classification tree and Chinese remainder theorem to embed the index of the tree instead of watermark?s native values, and via the inverse process the watermark extraction is accomplished. Additionally, it has application ability to any watermarking techniques in the same principle of modification method. Our experimental results show not only the robustness against different image processing attacks, but also the enlargement of capacity to progressively accept the gray scale watermark.

Keywords-digital watermarking techniques, association analysis, discrete cosine transform,  Chinese remainder theorem, features classification tree

I.  INTRODUCTION Watermarking techniques have developed vigorously  since the prevalence of Internet. From the very beginning, several researches in this field are inspired by Cox et al.?s spread spectrum technique [1] which hide watermark information into discrete cosine transform (DCT) domain, e.g., using the relation between prediction and true coefficients of DCT to extract the watermark bit stream [2], modification of statistical relation in certain number of DCT coefficients [3], and applying the Chinese remainder theorem (CRT) to adjust the DCT coefficients [4]. These researches keep the same character, retrieving the watermark without the provision of host image or correlation between watermarked and non-watermarked image, i.e., blind detection. Although they reach better robustness and blind detection, the capacity has just been sacrificed.

Association analysis [5-6] firstly introduced to watermarking techniques is using host image and watermark as database to exploit the association rules within them [7].

These data could be explored from pixel values or transform domain as long as having better symbolic meaning. A further research even makes use of compressed code of images to construct the rules [8]. The combination of association analysis and watermarking techniques, therefore, is built by these efforts; however, they meet the obstacles which are not blind detection.

The capacity of watermarking techniques and the character of blind detection are essential factors. They will lower down ease of use and usefulness, making inconvenience and limitation to the end users. The proposed scheme in this paper tries to fix these drawbacks. With the concept of association analysis, the features classification tree is developed and adapted to the CRT watermarking scheme, Jagdish et al.?s [4]. Comparing with [4], the robustness of our proposed scheme against image manipulations performs better in most of cases, and, most of all, it can allow the gray-scale watermark whose data size is much larger. And we believe the proposed scheme can be implemented onto most of watermarking techniques using modification method.



II. BACKGROUND  A. Association Analysis Association analysis is one important topic of data  mining. This technique exploits valuable and meaningful relationships among a big database, and then builds up association rules to represent the relationships.

Conventionally, to explain the association analysis will assume a transaction environment containing an item database I. Every product is an item belonging to item database, and every transaction has an identifier TID. As Table 1 shows, T1 as an itemset consists 3 items {A, B, D}, and T2 as another itemset consists 4 items {A, B, D, E}. We can find ?A, B??{D} is a 3-itemset association rule in this database, where  ?A, B??I, ?D??I, ?A, B???D?=?.

Therefore, in this example, ?A, B??{D} as an association rule implies it is a kind of potential consuming habit.

TABLE I.

TID Itemset T1 A, B, D T2 A, B, D, E T3 B, C, E  B. Chinese Remainder Theorem The CRT is briefly introduced below. Detailed  explanations can be referenced to [9-10]. Given a set of k moduli {M1, M2? Mk}, any two Mi are pair-wise relatively prime, k simultaneous congruences shown as (1), where Ri is   DOI 10.1109/IIH-MSP.2013.125    DOI 10.1109/IIH-MSP.2013.125     residue,  i=1, 2? k,  and the other two equations as followings:  Z?Ri(mod Mi), (1)  Ai M Mi  ?1?modMi?, (2)  Z? ?	 Ri MMi Ai k i=1 (mod M). (3)  In these equations, M=M1?M2?Mr, and Ai are calculated from (2). With the set of answers  {A1, A2? Ak}  this theorem can derive the answer Z from (3).

In this paper, we use the application of this theorem, inverse CRT. If we give only two moduli {M1, M2}, any integer Z can be represented by  Z=?R1, R2?, ?0<Z?M-1, where R1 and R2 are calculated from (1). For example, M1=3, M2=7, and M=M1?M2=21. Suppose Z=17, use inverse CRT to get a representation Z=?2, 3?.



III. PROPOSED SCHEME The proposed scheme embeds the indices of  classification tree into a host image to reach the purpose of watermarking techniques. Before elaborating the details of the procedures, we define the host image as X, watermark as W, and watermarked image as Y. They are represented in general way, pixel value, which ranged from 0 to 255.

A. Features Classification Tree As the association rule ?A, B??{D}  mentioned in  previous section, if one customer purchases two items A and B at the same time, it means the item D would appear in the customer?s shopping cart in very high possibility. For the same reason, we assume the l?l (in pixel value) sized blocks partitioned from X and W as many different customers, and after classifying these blocks by a number of proper features into the specific clusters, those blocks who belong to the same cluster will have similar shopping habits, that is, the appearance and texture. We define the features as below:  Feature 1: P= 1 m?n  Pm,nln=1lm=1 , (4)  Feature 2: A= tan-1 Gx Gy  , (5)  Feature 3: G=?Gx?+?Gy?. (6)  In these three Features, Pm,n is the pixel value of the block at location row???and column n, 1?m,n?l. Gx and Gy are calculated from the convolution of the pixels in the block and corresponding filter Fx and Fy, l is determined as 2 in the experiments, so the filters Fx and Fy are 2?2 blocks as shown in Fig. 1. Due to the fact that block size is 2?2, three features P, A, and G are respectively in the range, ?0?P?255, -??A??, 0?G?1020. Find the index of cluster to which a block belongs, please follow the algorithm below:  1. Find smallest i, 1?i?I, to satisfy ?P-0? ?255-0?? ?i  I  ? ,  2. Find smallest j,?1?j?J, to satisfy ?A-?-?? ??-?-?? ? ?j  J  ? ,  3. If G is smaller than tg, k is 1; otherwise, k is 2.

Figure 1.  Filters of Fx and Fy.

The whole concept of features classification tree is depicted in Fig. 2. Note that I?is the number of clusters at level 1 of the tree, and J and K are the number of clusters at level 2 and 3 respectively to classify each upper level node.

The threshold ??  is determined by experiments to decide whether it is an edge block, so level 3 is only two clusters, i.e., K=2. Finally, let the index be named as IB is calculated from (7):  IB=?i-1??J?K+?j-1??K+k. (7)   Figure 2.  Concept diagram of features classification tree.

B. Embedding and Extraction Previous section only introduces how a block is classified  into a certain cluster and gets an index. This section, embedding and extraction, will explain the blocks all at once.

Firstly, the watermark W?is partitioned into blocks to find all compatible indices as shown in Fig. 3. This process is called Match Watermark to Tree. In the meantime, the host image X proceeds L?L sized block partition, and every block is applied by DCT from spatial domain to frequency domain.

Subsequently, in embedding step, all of the indices IB are converted into a binary stream, and three ACs of all DCT blocks,???? ??? ??? ??? ??? ?? as shown in Fig. 4, are seemed as a AC sequence, and then use pseudo random number generator (PRNG) to rearrange the AC sequence. After all of above steps, one bit in the binary stream pairs with three coefficients in the AC sequence, and inverse CRT is  -1 -1  1 1  -1 1  -1 1 Fx Fy     executed on every bit embedding. Comparing with [4], we use 4?4 sized DCT block. Therefore, the AC value ranges from 510 to -510, and {M1, M2} is {16, 33} determined by experiments to reach better quality of watermarked image.

For detailed embedding process, please refer to [4].

Figure 3.  Concept diagram of embedding.

DC (1, 2) (1, 3) (1, 4)  (2, 1) (2, 2) (2, 3) (2, 4)  (3, 1) (3, 2) (3, 3) (3, 4)  (4, 1) (4, 2) (4, 3) (4, 4)  Figure 4.  Selection of three AC coefficients.

As to extraction, the indices of watermark blocks are returned from watermarked image Y just by inverse embedding process as shown in Fig. 5, but there is one thing should been noticed:  every bit in binary stream is decided by majority decision; that is the reason why one bit pairs with three AC coefficients.  Next, whole ?? ? ?  sized blocks partitioned from Y go through classification process.

However, they are not going to find the indices from the classification tree; instead, they will stay in the clusters to build the tree so that watermark blocks could use them as substitutions to reassemble the extracted watermark. In other words, one extracted index uses a certain number of blocks of Y staying in a certain cluster where exactly the same index refers to, and averages the pixels of the blocks into the same sized?? ? ? blocks. This process is called Reassemble Watermark. Something worth mention, not all of indices from extraction could find non-empty clusters in the classification tree. Therefore, the extraction algorithms will find two closest neighborhood clusters to do the linear interpolation in order to conjecture empty one.

Figure 5.  Concept diagram of extraction.



IV. EXPERIMENTAL RESULTS The proposed scheme uses several parameters all stated  as following: M1, M2, scale factor s, l, L, I, J, and tg; they are 16, 33, 4, 2, 4, 16, 8, and 92 respectively as results of experiments. All of these parameters are written in algorithm other than the exterior information for extracting watermark.

The images for experiments are shown in Fig. 6.

Figure 6.  (a) ??? ? ??? host image, (b) ?? ? ?? binary watermark, (c)  ? ? ?  binary watermark, (d) ? ? ?  gray-scale watermark.

The main points centered by the proposed scheme are blind detection and larger capacity of allowing gray-scale watermark by great means of association analysis. Fig. 7 shows watermarked images under different attacks, extracted watermark using [4], and extracted binary and gray-scale watermark using our proposed scheme. Table 2, furthermore, presents more detailed information between two schemes. In     the third column, the Tamper Assessment Function (TAF) percentages in bold style are the better performances than comparing scheme. Only in JPEG 75% attack, the TAF value is a little bit worse; yet, it is still clear enough for human visual system. Moreover, the table also shows Peak Signal- Noise Ratio (PSNR) of watermarked images in second row.

They are all above 43 dB which means very good quality in general watermarking techniques.

(a)    (b)    (c)    (d)    (e)   Figure 7.  (a) without attack, (b) crop, (c) brighten, (d) sharpen, (e) JPEG  75%  TABLE II.

Jagdish et al.?s Proposed scheme, binary  watermark  Proposed scheme, gray-  scale watermark  Watermarked image  46.0823 dB* 43.2259 dB 43.0923 dB  Without attack 2.0508% 0.5926%** 33.0826 dB Crop 3.1006% 2.0988% 15.3995 dB  Brighten 18.6768% 0.5926% 33.1610 dB Sharpen 7.1045% 4.8642% 22.3846 dB  JPEG 75% 4.9805% 8.1235% 19.0099 dB  *dB is the unit of Peak Signal-Noise Ratio (PSNR).

**% is the percentage calculated by Tamper Assessment Function (TAF).



V. CONCLUSION In this paper, a new idea of image?s features  classification tree is proposed to group similar blocks from both host image and watermark into a number of identical clusters, and, in extraction phase, only fetches the blocks from watermarked image as substitutions to simulate the appearance and texture of original watermark. According to experimental results, the goal of blind detection and acceptance of gray-scale watermark has been proved, and the ability against different attacks is even better than comparing scheme in most of cases. However, some other usual attacks such as rotation, scaling, and blurring are not involved in this paper. We will work them out in short future. What is more, the l?l  sized block partition could be slightly enlarged to increase the capacity; it is worthwhile to research indeed.

