Holistic SLA Ontology for Cloud Service Evaluation

Abstract?With the evolution of service computing ecosystems  and the promises of the Cloud, there is an increasing need for service evaluation and monitoring across a wide range of QoS dimensions. Although in the literature service monitoring is tightly coupled with Service Level Agreement establishment, existing approaches do not provide a holistic model for Cloud service evaluation. In this paper, we present an SLA ontology, encompassing the whole service lifecycle, in order to drive and improve the evaluation of services. We propose a common QoS ontology to express specifications, requirements and feedback.

Based on this, we introduce a symmetric representation of service monitoring information and human feedback, allowing a unified management of the service evaluation. Finally, the SLA ontology supports the profiling of users, enabling a refined reputation calculation through the dynamic consideration of customer segments.

Keywords?SLA ontology; cloud computing; QoS; service evaluation; user feedback; reputation

I. INTRODUCTION Service Computing has been around for some years now, and even if it cannot be considered as a new paradigm, a lot of research and standardization is still to be done. Cloud computing has revolutionized the way that IT services are delivered and consumed. Cloud service users are able to access on-demand virtualized computing resources and pay for their actual usage instead of buying their own computing infrastructure. This tremendous transformation of IT service provisioning implies considerable changes in the IT business models to adapt to this new ecosystem. To this end, one of the key challenges in the cloud computing area is the development of new models and techniques that assist the business relationship between user and provider during the whole service lifecycle.

Typically the relationship between service user and provider is regulated by a Service Level Agreement (SLA) that formally defines the quality level of the service to be delivered to the customer by the provider. Since SLA determines an a-priori agreement on the service quality, it is necessary that during service execution the fulfillment of service requirements, with respect to the corresponding SLA, is assured. Therefore, existing works have focused on the monitoring of system-level properties to check the compliance of service operation with SLA ([2], [3], [6]). Although these works use SLA as the main concept of quality assurance during the phases of service  selection, service negotiation and service execution, they do not provide a holistic model that spreads over the whole cloud service lifecycle.

In this paper we motivate the need to use a common Quality of Service (QoS) and SLA model that supports the processing of the user feedback to create a powerful reputation mechanism that could in turn be assistive in evaluating the cloud services.

In particular, we argue that the reputation is not a separate quality factor but represents the way all the QoS factors of a service are perceived by its current and past users. Our goal is to create an SLA ontology for services that enables the monitoring of QoS aspects both by using ?objective? software monitors as well as by exploiting the subjective knowledge coming from users feedback. This flexible model enables the evaluation of qualitative aspects of the services e.g. usability, support satisfaction etc. and provides an additional source of information for quantitative aspects.

Our work builds on existing models that attempt the creation of QoS models for the evaluation of cloud services ([8], [14]) and SLA models ([2], [5]) while it incorporates the user feedback as an assessment tool of cloud services. Moreover our ontology enables the classification of service users to allow the filtering of feedback in respect of requirements and user preferences.

In this paper, we present an SLA ontology, based on a QoS ontology representing the common QoS model used through the whole service lifecycle. The central concept of our ontology is the SLA concept which is directly connected with five key elements: Service, QoS Requirements, Role, Actor and Feedback. In that respect, SLA involves the agreement of different actors (playing a role, e.g.: consumer, provider) on the delivery and use of a cloud service according to the service requirements. Feedback is the evaluation enabler and according to our model, it could be either objective or subjective depending on its source.

The structure of this paper is as follows: In Section 2 we provide a high level view of our system model, in Section 3 we present the core contribution of this paper, in Section 4 we illustrate it through a scenario, in Section 5 we discuss the related work, and finally we discuss future works in Section 6.



II. SLA LIFECYCLE OVERVIEW Before going into more details, we need to present in this section an overview of the service lifecycle. This overview describes the basic assumptions of the underlying system   DOI 10.1109/CBD.2013.18     model upon which the SLA ontology will be used. A more detailed description of this work can be found in [7].

As we see in Fig. 1, the central concept that connects all steps of service lifecycle is an SLA ontology. In particular, the core service lifecycle starts with the Service Selection, involving the SLA ontology to specify the desired SLA and analyze the service recommended. The SLA Negotiation is the second step and uses the SLA ontology as a common ground for the different parties on which they can agree. The third step, the actual consumption of the Service is to be done according to the signed SLA. During the consumption, two additional steps are using the SLA ontology: Service Monitoring according the SLA Requirements, and Service Adaptation that has to be done in respect of these requirements. During and after the consumption, the Feedback Creation step is using the SLA ontology as a reference, in order to give consistent and well- defined feedback. These feedback are then sent to the Reputation Management that considers the feedback and the reputation according to the SLA ontology. Finally, the Reputation Management is used by the Service Recommendation that will help a consumer in his selection.

In the perspective of the evaluation, two steps are of particular interest: service monitoring and feedback creation. After the service onboarding, an actor (that may be the provider and/or a third party) is responsible to monitor the behavior of the service and check its compliance to SLA requirements. Since the monitored parameters represent quantitative QoS factors e.g. response time, throughput etc., we use the term objective feedback to refer to the values that we get from the monitoring of the measurable metrics. Beyond the objective evaluation of service, users are able to give their feedback on the performance of the service. User feedback are used in our model as an additional source of information to monitor the performance of the service with respect to SLA expectations.

In particular, this model is used from the service provider perspective to express the service specifications as well as to bind monitoring data with specific QoS aspects during service monitoring. From the user perspective, the same QoS model is used to define the user requirements and evaluate the service across different QoS dimensions. In this way, information about the service evaluation can be collected both through monitoring mechanisms and user feedback.

In the perspective of computing the reputation of the service, the aggregation of this heterogeneous information can be done in various ways based on the service evaluation method, for instance AHP (Analytic Hierarchy Process) method. As we?ll explain with more details in sections 3 and 4, we assume that user feedbacks are expressed in Lickert scale, which enables numeric representation and let us calculate the service reputation across different evaluation criteria. However, our model could be extended to support different metrics for obtaining user feedback e.g. linguistic terms. In that case the method for calculating the service reputation across the different QoS dimensions should be selected accordingly.

Since the investigation of different methods to calculate service reputation is out of the scope of this paper we leave the  extension of our model to support different metrics and different reputation methods as future work.

Service  Recommendation  SLA  T  Rep  Service  Monitoring  SLA  P  Feedback  Creation  SLA  C  Service  Selection  SLA  C  Rep  Reputation  Management  T  SLA Ontology  SLA  Negotiation  SLA  S  Rep  Service  Adaptation  SLA  P  Service  Consumption  SLA  S  SLARep  Re pu  ta tio  n  Re fin  ing  SLA Understanding  SL A  Re qu  ire m  en ts  Feedback  Reference  SLA Specification  SLA Constraints  Fig. 1 SLA-Centric Service Lifecycle  Finally, the SLA ontology has to incorporate the user profile, which is associated to the obtained user feedback. This concept helps in understanding the perception of users towards the various services and thus, contributes in building and selecting services according to customer perception [15]. In particular, associating user profiles to user feedback is necessary to calculate reputation across different customer segments. For instance, a service may be sufficient for the requirements of a freelancer but not for an SME and vice versa. Therefore it is necessary to filter the user feedback according to the user profile and the specific requirements and calculate accordingly the reputation of the service across the different customer segments. This concept is included in our SLA ontology to provide a holistic approach on the representation of user feedback.



III. SLA ONTOLOGY In this section, we present the main contribution of this paper, an SLA ontology designed to fully support feedback evaluation and reputation mechanisms. In the following, we present the different aspects of our ontology and how they fit together to create a detailed and meaningful design. The remainder of this section is organized as follows: we start by presenting the main concepts of the ontology and its general design and then we present in more detail the QoS, actor profile, and, feedback concepts.

binds  SLA  Service  defines  Service Monitoring  reliesOn  monitors  Role  defines  Feedback  characterizes  Objective Feedback  Actor  plays  involves  ConsumerProvider  givesActorProfile  has  Broker  Service Specification  describes  QoS Parameter Moniroting  QoS Requirements  QoS  defines  Subjective Feedback  Unmeasurable QosParameter  Measurable QosParameter  QoSParameter  has  Service Adaptation  adapts  monitors  influences reliesOn  relies on  Fig. 2 Ontology High Level Concepts  A. Main Concepts Before diving into the details of the ontology, we discuss its general design and the main ideas behind it. Fig. 2 shows the high level description of the ontology, the main concepts and their relations. The root concept of this representation is the SLA, which is linked to five essential concepts: Service, QoS Requirements, Role, Actor and Feedback. In order to keep the readability of the figure we have limited the representation of the relations to the main ones.

The relation between the SLA and the Service is a binding one; the SLA binds the execution of the service with respect to a set of constraints and it defines the policies to be respected in case of violation of the agreed QoS constraints. These constraints are defined in the SLA by the description of QoS Requirements. These requirements are compared at runtime to the service specifications with respect to QoS Parameters.

QoS parameters represent the QoS factors upon which a service can be evaluated. As already proposed in the literature [4], our ontology incorporates the service monitoring and adaptation concepts. In particular we assume that during the service execution, SLAs are monitored through a Service Monitoring mechanism that triggers Service Adaptation. Note that the service monitoring mechanism uses also the same  QoS Parameter concept, as used for service requirements and service specifications. The details of this fundamental QoS concept will be explained in the next subsection.

An SLA is typically established between two parties, formally defined as Actors, which may play different Roles (e.g., consumer, provider, broker and other third parties). For instance, a platform provider could play the role of the consumer for an SLA with an infrastructure provider, while in the same time being the provider or broker of a platform  service. Therefore, in the ontology we introduce the notion of roles which are played by the different actors involved in the service lifecycle. To this end, these roles are used at different steps of the service lifecycle to define the interaction of the actor with the service. In the beginning, during the SLA contract establishment, the role is used to define the relation of the actor to the service, during the service execution, the role can be used to define the actor which performs the monitoring of specific QoS parameters. For instance, system-level parameters, such as throughput or latency, could be monitored by the infrastructure provider, while application-oriented parameters, e.g. user satisfaction could be monitored by a third party, such as a cloud broker. Naturally, the definition of roles implies the description of actors to play them. To help their     representation in the proposed ontology, actors possess Actor Profiles, which describe the details of the actor (e.g., size of company). The actor profile will be discussed in more detail later in this section.

The last main concept is Feedback, which in our model represent the values across the different QoS parameters. In that respect, Feedback is characterized by the SLA that defines a basis upon which feedbacks can be provided and evaluated.

In our ontology, we distinguish two kinds of feedbacks: objective feedback and subjective feedback. Objective feedback are obtained via the collection of monitoring data which quantify the Measurable QoS Parameters during service execution. Subjective feedback correspond to the evaluation of Unmeasurable QoS Parameters by the different Actors. Note that certain QoS factor, (e.g. performance) could have both measurable parameters (e.g. latency, throughput) and unmeasurable parameters (e.g. customer satisfaction).

This symmetric consideration between measurable/ unmeasurable QoS Parameters and Objective/Subjective Feedbacks harmonizes their management.

Given this general overview of the proposed ontology, we will now explain in more detail the QoS, actor profile, and, feedback concepts.

B. SLA QoS Fig. 3 shows the QoS Part of the ontology. The root element of this part is the QoS concept that contains a set of QoSParameters. As already introduced, these parameters are of two main different types: measurable and unmeasurable QoS parameters. This distinction is used to identify parameters that can be automatically measured by software tools and parameters that require a human evaluation. In this perspective, a measurable QoS parameter relies on the measurement of a value, hence described by a Metric. On the opposite part, an unmeasurable QoS Parameter has to be estimated by a Quantification of the parameter value. This quantification has to be done according to a Scale that will allow the comparison of different evaluations of this parameter.

The QoS ontology defines a baseline for the requirement specification and evaluation of services. This idea is expressed through the different links that exist between the SLA and QoS concepts. The main link between them is the definition of QoS Requirements, described in the SLA contract and defining the constraints on QoS parameters that are to be respected during service execution. Additionally, the links to subjective and objective feedbacks define the evaluation of QoS parameters during the service execution. With these links we have described the relation between the SLA and QoS through the requirements, the use of this relation during the execution through the monitoring, and the exploitation of this relation after the service execution through the feedbacks and their use for selection of service.

Fig. 3 QoS Ontology fragment  C. Actor Profile The definition of the top-level concepts of the ontology described earlier, gives insight about the relations between the main concepts. As it has been introduced in the beginning of this section, the description of profiles of users is of specific interest for us in the perspective of providing advanced service selection, by considering the profile of Actors and their provided feedbacks.

Fig. 4 presents the profile of an actor in the proposed ontology. Note that actors are considered from the SLA standpoint, i.e. if a company is an actor, the actual employee of the company is considered to act on behalf of the company, which is the main actor according to SLA. The root concept of the proposed representation is the ActorProfile, which is organized according to two different aspects: Service-Related Profile and General Profile information. The general profile corresponds to general information about the type and the structure of the actor. In more detail, general profile contains two main concepts: the BusinessProfile which describes the type of the actor (Large Company, SME, Freelancer, etc.), and the structure of the actor with its different Departments (Engineering, Quality, Accounting, etc.) relying on Persons with different Functions inside these Departments. Note that, as explained earlier, an actor could play different roles during the service lifecycle. The general profile of the actors helps to represent the different sources of the feedbacks. Thus, each subjective feedback could be mapped to its source, in an effort to aggregate user feedbacks in a meaningful way. These service-unrelated parameters are specifically useful during the service selection process as they allow a better consideration of the feedback and a refinement of the reputation.

The service-related aspect of the actor profile is represented by its Service Experiences. A service experience correspond to one execution of a service and is described by a Start Date, an End Date, the Service executed, the Role(s) played by the actor and the SLA used for this service execution. Start Date and End Date can be used to assess the experience in the service by computing the duration of the experiences and their frequency. An experience is also characterized by its Context of Experience. The description of this context contains (non- exhaustively) the phase of the project/system related to the service (testing phase, validation, production, etc.), the type of context (private or professional), and the contracting role of the actor (whether he is only a contractor delivering a service to another entity or if he is the final user of the service).

As already explained, the Role of the Actor is essential in the sense that it clearly states if the Actor is consumer, provider, monitor, broker or any other stakeholder related to the execution of the service. This representation allows us to consider, in an integrated manner, service consuming and providing activities. This is specifically relevant in the case of providers that are themselves consumer of other services, allowing federating the expertise of the Actor across his different roles, thus providing a more complete and simpler way to consider actors profiles. The SLA is also a characterizing concept as it defines the general context of the service execution.

The feedback is obtained from the evaluation of an unmeasurable QoS parameter, by a person, who might be the actor or act on behalf of the actor, e.g. a company. The  evaluation of such parameter generates a subjective feedback that will in turn be used to evaluate the reputation of the service. Furthermore, it is worth to mention the presence of a link between the feedbacks and the service-related profile.

With this link, we argue that in order for an actor to benefit from a service-related profile (representing its experience), the actor has to provide feedback. In the case that the actor is passive, i.e., he does not provide feedback; his credibility will decrease, implying that his feedback will be less considered.

Since involvement could be also an indication of good reputation for an actor, this simple model aims to encourage users to become more active and provide their feedback in an effort to improve the accuracy of community-based service evaluation. In the next subsection we explain in more details the concept of feedback that has been already sketched.

D. Feedback The last main concept of the ontology is the feedback which performs evaluation on the service quality, reliability, performance and relevance. Thus evaluation is based on providing feedback about the actual execution of the service.

As it is depicted in Fig 5, feedback are characterized by the SLA to which they refer. This relation defines the fact that, at least for objective feedback, they have to be considered during the evaluation of the SLA. From the source point of view, feedbacks are given by actors of the service e e.g., consumer, provider etc. These feedback generate Feedback Influence that in turn influences the Reputation. The nature of the Reputation can be of two types: Service Reputation defining how the service has performed and has been perceived by the different  characterizes ActorProfile  Service Experience  Role Service  SLA  Start Date  End Date  BusinessProfile  Sector  Type  ? Large Company ? SME ? Freelancer ? ...

? IT ? Telco ? Healthcare ? Banking ? ...

? Private ? Professional  Context of Experience  characterizes  Project Phase  ? Test ? Production ? ...

Contractor?

? Contractor ? Final Client ? ...

Unmeasurable QosParameter  Feedback  Subjective Feedback  value  Department  Function  ? Management ? Exploitation ? Sales ? Engineering ? Quality ? Security ? ...

Person  accredits  Function gives  Evaluation  generates  characterizes  General Profile  Service?Related Profile  ? Manager ? Analyst ? Developper ? Architect ? ...

Type  Fig. 4 Actor Profile Ontology fragment     actors; it can also be Actor Reputation which provides insight on the reliability of the actor. This reputation can be used during the service selection process to match service specifications with service requirements.

SLA  Service  Feedback  characterizes  Objective Feedback  Subjective Feedback  Actor  Reputation  Feedback Influence  generates  influences  gives  Actor Reputation  Service Reputation  concerns  concerns   Fig. 5 Feedback Ontology Fragment  The ontology we have presented has been implemented in OWL with the help of Prot?g?. We have seen in this section how our approach unifies the different parts of the SLA and Service lifecycle in order to offer a holistic approach to the Service evaluation.



IV. ILLUSTRATING SCENARIO In this section, we illustrate our research by presenting a service selection scenario benefiting from our ontology.

Let?s consider a company C looking for a PaaS (Platform as a Service) to replace some its current physical platforms. As platforms are intended for the system engineering department, the company is looking for software architect oriented platforms and has defined a set of Service Requirements and Service Level Specifications. C has written the service requirements in Table 1 and has drafted the service level specifications according to the SMI model [17] in Table 2. In particular only four out of the seven categories proposed in SMI model are used and for each category one or more service quality attributes.

TABLE 1 SERVICE REQUIREMENTS SUMMARY  ? Provision of virtualized Platforms with specification: o 1x OS: Windows 7 or higher o 1x JDK 1.70.0_08 or higher o 1x UML designer software o 1x Java IDE o 1x SQL server o 16GB of RAM o 4 CPU cores o 120GB SSD  TABLE 2 SLA QOS CONTRAINTS  ? Agility: o Scalability: service should be able to offer up to  20 platforms; ? Assurance :  o Availability: 90% up-time; o Reliability: less than 1 fail/month;  ? Performance: o Service response time: connection to a platform  should not take more than a minute; ? Privacy:  o No data has to be available to external users; o Exclusive execution environment.

After searching for services matching the defined specifications, C has found different providers that seem to propose relevant services. In order to make a decision about which one will be used, our approach considers the reputation of offered services.

TABLE 3 USER 1 FEEDBACK  QoS Parameter Constraints Feedback Agility  Scalability should be scalable  Objective: up to 9 platforms were supported while 10 were requested (SLA requirement was 4) Subjective: 7  Assurance Availability 98% Objective: 98.5% Performance  Response time < 1 minutes Objective: < 1 minutes Subjective: 8 Usability Operability no constraint Subjective:3  TABLE 4 USER 2 FEEDBACK  QoS Parameter Constraints Feedback Agility  Scalability should be scalable  Objective: up to 40 platforms were supported while 50 were requested (SLA requirement was 20) Subjective: 4  Assurance Availability 99% Objective: 98.7% Performance Response time < 4 minutes Objective: < 2 minute Privacy  Data privacy Data encrypted with private SHA-1 Objective: Data encrypted with SHA-512  Data privacy Execution should be done on exclusive server  Objective: Execution servers were exclusively used for User 2.

Table 3 and Table 4 provide an insight on the feedbacks that have been provided by previous users of one of the services.

Subjective feedbacks are evaluated on a Lickert scale with values between 0 and 10, 10 being the best. Due to space limitations, we only considered a small set of parameters that     includes the ones presented as part of the service specifications in Table 2 with a few additional ones. Note that for some parameters, we might get both objective and subjective feedbacks, while for others we may get only subjective or only objective feedback.

In order to consider correctly the evaluation of the service provided by the previous consumer, C does not only require taking into account the evaluation, but also the details of the consumer that generated this evaluation, its profile. In our case C is an SME (with 5 main departments) working in the aeronautic sector, designing specific components of aircrafts.

Regarding the evaluators, User 1 is an SME working in the Healthcare sector and providing utility software for hospitals.

User 2 is a large company working in the aeronautic and astronautic sectors.

Using our ontology, the consideration of these two feedback can take a new dimension. To illustrate this we can compute a simple weighting of these feedback to obtain a reputation for each parameter, which will provide to C a clearer perception of the service. Here our focus is not to provide a complex reputation mechanism with the consideration of every parameter and dimension, rather than that it is to show one of the use of our ontology.

TABLE 5 FEEDBACK AGGREGATION EXAMPLE  Parameter User 1 User 2 Reputation Agility Scalability  6.792 Objective 5 7.5 Subjective 4 7 Similarity 0.2 1 Weighted 0.9 7.25 Performance Response Time  9.333 Objective 10 10 Subjective 8 / Similarity 1 0.5 Weighted 9 5  Table 5 presents an example of possible aggregation of mixed objective and subjective feedback. Objective scores are obtained by calculating the ratio between SLA requirement, request and measured result. The similarity indicates the similarity between the parameter value in the SLA and the value desired by C. The Weighted lines are subtotals giving the impact of user?s feedback on the parameter for the calculation of the reputation. For instance, User 1 scalability feedback were relatively low, but they were given of an SLA with a quite different value for this parameter, giving them a lower impact on the final reputation.

Along with objective and subjective feedback our ontology can help refining the reputation by considering the profile of evaluators.

TABLE 6 PROFILES SIMILARITY  User Type (0.4) Sector (0.6) Similarity C SME Aeronautic / User 1 SME : 0.8 Healthcare : 0.1 0.38 User 2 Large Company : 0.3 Aeronautic : 0.9 0.66  Table 6 presents a simple consideration of the profile to compute a similarity of the profile between C, User 1 and User 2. According to C preferences, it takes into account the type of user for 40% of the similarity measure and the sector of the user for 60%. Obviously we could consider more and/or more detailed elements if necessary. The resulting similarity measure can then be used to weight the general impact of users? feedback on the reputation, combined with intermediate results from Table 5. In our example, the similarity of sector between C and User 2 will give, in the end, a higher weight to User 2?s feedback.

We have shown in this example how our ontology can unify and drive the consideration of objective and subjective feedback, as well as the help users get more tailored and accurate reputation information.



V. RELATED WORK SLA modeling and evaluation have attracted the interest of researchers in the field of service-oriented computing during the last years. Initial works in SLA modeling (e.g. WSLA [9], WS-Agreement [12]) have focused on formal languages that enable the representation of SLAs for Web services. Other works have investigated the process of SLA negotiation [1] and provided frameworks and solutions for the bi/multi-lateral negotiation of SLA parameters. However, these works mainly focused on the description of SLAs and they do not propose a common model for evaluating QoS parameters from different sources, e.g. monitoring tools, user?s feedback etc. Our work goes one step further, since it attempts to monitor and update the evaluation of the SLA during the whole service lifecycle including the handling of user feedback to create and feed a meaningful reputation management system.

In SLA@SOI project, an approach to enable dynamic SLAs has been proposed [3]. The authors propose the binding of the SLA with a monitoring mechanism, which continuously monitors several Key Performance Indicators to check their compliance with respect to the SLA. SLA@SOI approach is based on a multi-level SLA hierarchy, where SLA parameters are decomposed in different KPIs according to the service layer [2]. Emeakoroha et al. [6] proposed also a mapping of low-level measurable metrics to high-level SLA parameters that are more relevant from the application perspective. They implement a framework that allows the monitoring of the low level metrics and their mapping to SLA parameters. Although these works adopt the idea of continuous SLA evaluation through monitoring mechanisms, they focus only on the measurable metrics and do not provide a holistic approach that considers the whole spectrum of service evaluation criteria.

The idea of using ontologies for SLA and QoS management has been applied in several existing works. Dobson et al. [5] provided a comprehensive literature review on existing ontology-based approaches for the QoS and SLA modeling in service-oriented architectures. In their work, they sketch the requirements and the basic concepts of the SLA and QoS ontology based on the existing QoS ontologies for Web services [5] [10] [11]. Their proposed solution reuses concepts regarding the design of the QoS and SLA model. Although we aim also to reuse, whenever appropriate, concepts and models     from existing ontologies, the focus of our work is to build a holistic SLA ontology for services evaluation. Therefore the QoS model to be used should be tailored to the specific aspects of service life cycle.

In that respect, the QoS model could be based on existing works in the field of cloud computing that focused on the development of cloud service evaluation models [8] to define a set of criteria upon which the comparison of different services can be done. These works are complementary to ours, since they provide a reference model to build the QoS ontology that includes a set of evaluation criteria for cloud service comparison. Finally, relevant to our work are also approaches that tackle the problem of cloud service evaluation and selection ([8], [14]). These approaches apply typically decision making methods to decide on the optimal service with respect to the requirements. Most of these works have focused on the evaluation of quantitative selection criteria, limiting thus their scope only to those criteria that can be directly measured. Recently it has been proposed in [13] a fuzzy-based approach for the consideration of both quantitative and qualitative metrics. Our work is also complementary to these efforts since our goal is to provide a theoretical basis and a common vocabulary upon which this decision making process can be applied. In particular, since the evaluation of qualitative metrics is a hard task, in this paper we have argued that the use of a service reputation mechanism that spans over the different selection criteria can be assistive in an effort to evaluate and integrate qualitative metrics during the service selection.



VI. DISCUSSION AND FUTURE WORKS In this paper, we have motivated the need for a holistic model, which connects all the lifecycle steps based on a common QoS ontology. To this end, we have presented an SLA ontology that introduces key concepts, such as Service, QoS Requirements, Role, Actor and Feedback which are tightly connected with SLA. Our ontology distinguishes between objective feedback coming from software monitoring and subjective feedback coming from the evaluation of users. We propose a symmetric handling of these two kinds of feedback and we demonstrate through a simple example, how objective and subjective feedback could provide input to a cloud service selection method. Furthermore, the ontology allows the profiling of users to enable the filtering of feedback according to their source.

Currently we assume that users feedback are expressed as numeric values in Lickert scale, and the aggregated feedback could be calculated as an average value. This aggregated value could be used as input to existing cloud selection methods [8], [14]. Besides, in future work we want to use the SLA ontology in order to enrich our ontology and build a more sophisticated reputation mechanism that considers the reliability of the feedback and its source, as well as reputation of other actors of the ecosystem. Furthermore, we want to explore other possible applications of our ontology, including SLA establishment, negotiation, service adaptation and selection.

