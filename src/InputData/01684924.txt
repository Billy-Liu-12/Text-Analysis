A SOM and Bayesian Network Architecture for Alert Filtering in Network Intrusion Detection Systems

Abstract With the ever growing deployment of networks and  the Internet, the inmportance of network security has increased. Recently, however, systems that detect irn- trusions, which are inmportant irn security countermea- sures, have been unable to provide proper analysis or an effective defense mechaniism. Instead, they have overwhelmed human operators with a large volume of irntrusion detection alerts. This paper presents a new approach for handlirng irntrusion detection alarms more efficieintly. We propose here an architecture for automated alarm filterirng based on classical method of clusterirng (Self-Organrizirng Maps) coupled with proba- bilistic graphical model (Bayesian belief networks) for determirinirg if the network is really attacked.

Keywords Network Security, Intrusion Detection, Clusterirng, Bayesian Networks and Alarms Filterirng.

1. Introduction With the ever growing deployment of networks and  the Internet, the importance of network security has increased. Over the past ten years, the number as well as the severity of network-based computer at- tacks have significantly increased [1]. As a conse- quence, classic computer security technologies such as authentication and cryptography have gained in importance. Simultaneously, intrusion detection has emerged as a new and potent approach to protect computer systems [3], [12]. In this approach, so-called Intrusion Detection Systems (IDSs) are used to mon- itor and analyze the events occurring in a computer system. The principal problem which discover the administrators when they install the (IDS) is the sig- nificant quantity of generated alarms. On a network of average size (one or two public classes C), sev- eral thousands of alarms are generated daily, making almost impossible the analysis of the results. The consequence is that the administrator is obliged to seriously re-examine with the rise his tolerance level, which will lead it to pass beside many real problems.

This problem, known as false positives, is a big bar- rier for intrusion detection tools to cross before their deployment can be practical. In this paper we sug- gest an approach for using data mining technology in the intrusion detection area. We claim that the best positioning for a data mining technology within an intrusion detection system is not as a detection en- gine, but rather as an analysis layer that will filter out the false positives. The outcome for our research was  an automatic process that consists of two steps. The first step aims at grouping similar standard behavior for external machines with destination to internal ma- chines using clustering algorithms like self-organizing maps [18]. The second step uses these information for determining if the network is really attacked and filter out the false positives using probabilistic tools like Bayesian Networks [16]. The outline of this pa- per is as follows. Section 2 discusses related works.

Section 3 describes our approach. Section 4 shows the experiments and the obtained results and finally section 5 concludes and presents our future works and perspectives.

2. Related work  The intuitively most appealing way of dealing with false positives is to build "better" IDSs, which trig- ger less false positives. This is a challenging endeavor because false positives are the result of multiple prob- lems. Examples of IDSs that are less prone to false positives include the embedded detectors technology by [31], a lightweight tool for detecting Web server attacks by [2], and a network-based IDS that focuses exclusively on low-level network attacks [27]. Alarm correlation systems [10], [11], [13], [29], [30] try to group alarms so that the alarms of the same group pertain to the same type (e.g., the same attack). In that way, they offer a more condensed view on the se- curity issues raised by an IDS [17]. Other researches use data mining approaches in order to discover as- sociation rules over alarm bursts [21]. Subsequently, alarms that are consistent with these association rules are deemed "normal" and get discarded. The risk of discarding true positives is not considered in this work, whereas bounding this risk is central to our ap- proach. concerning the use of Bayesian networks for higher level analysis (system resources, logs of users), let us cite the work of [19], [23], [25], [26]. [4], [5], [6] use the naive Bayesian network and decision tree for intrusion detection. The data used in these works is a set of benchmark data from KDD'99 which are appropriate to evaluate an intrusion detection sys- tem. For the temporal analysis of attacks, [28] uses a probabilistic graphical model (temporal tree). [8] implements other probabilistic graphical models very close to dynamic Bayesian networks (Hidden Markov models). Closer to our work (i.e., to rather propose a postprocessing with a current NIDS), [7] use a very simple bayesian decision rule on the logs of two NIDS, SNORT and Shadow.

0-7803-9521-2/06/$20.00 ?2006 IEEE. 3175    Figure 1. General description of our approach  3. Our approach 3.1. General functionality The goal of our system is to start from the alarms  generated by a NIDS, and to try to filter these alarms to determine if there were an attack on the network during a fixed lapse of time. Our system is com- posed of three components detailed in figure 1 [14].

In the first step (temporal preprocessing) we start by making a synthesis of the behavior of all the external machines to all the internal machines in a fixed tem- poral window. Starting from the principle that this behavior can be similar for several external machines (which would try the same kind of attack towards the same internal machine), or for several internal ma- chines, we thus will group these behaviors in a given number of behavior types (spatial preprocessing), by using a Self-Organizing Map (SOM), an usual tech- nique of unsupervised classification proposed by [18].

This information is then used to determine if a given internal computer is really attacked (classification)  3.2. Temporal preprocessing An attack is often characterized by a series of con-  secutive events trying to violate the security policy of a machine or a network. To detect such a scenario, we place ourselves in a pseudo-reality detection mode, by making a synthesis of the various types of alarms gen- erated by the NIDS during a mobile window of time for every couple (IPext, Pint) The length and the offset of the window were determined by an expert of the domain to have a good compromise between the minimal duration necessary to detect potential scenarios of attacks and a maximum duration be- yond which the system is drowned by alarms. Start- ing from the log issued by the NIDS, we calculate - for the considered window of time - the number of alarms of each type for each value of the couple (IPint , IPext). We do not take account the value of the external port (considered to be nonsignificant by our expert), nor the internal port or the protocol (very correlated with the type of alarm generated by the NIDS). The logs we used in our experiments con- tain 406 different types of alerts generated by SNORT [24]. At the end of this phase, we obtain a sum- mary [window 'Pext IPint Nalert1 ... Nalert4O6] of the behavior of each internal machine in our network gathered for each external machine in connection. To  take account of the average traffic of each internal machine we propose to normalize the data. First, we calculate the average of every type of alert for every (alert type= t(i,..T)JIPint (i.',) as shown by the following formula:  nN- alert-type(wi'nd(n), t, iaverage alert(t, i) = N (1)  where N is the number of mobile windows in which IPint is connected, T is the number of type of alerts and I is the number of IPint. Consequently, we can then divide every alert(t, i, wind(n)) by the calcu- lated average.

3.3. Spatial preprocessing 3.3. 1.Alarm Priority  Given that the various types of alarms issued by the NIDS are not all on the same level of importance, and the most indicative alarms are in general the least frequent, we propose to classify these alarms under 3 levels of priority: low, medium and high. With each level we associate a coefficient of priority in way to distinguish significant alarms from the others. The coefficients of priority are indicated by an expert of the domain and associated with a weighting coeffi- cient.

3.3. 2.Clustering In this part, we work starting from the number of  alarms of each type generated for each couple (IPext IPint), by supposing that this vector is a representa- tive behavior of each IPexternal in connection to each 'Pinternai. On the basis of the principle that this behavior can be similar for several external machines connecting to one or more internal machines, we used a technique of unsupervised classification to cluster these behaviors in a given number of behavior-types.

We used a self-organizing map [18] as clustering algo- rithm. In general, clustering seeks to group objects so that the objects within a given group/cluster are sim- ilar, whereas the objects of different group/cluster are dissimilar. SOMs accomplish two things, they reduce dimensions and display similarities. The way that SOMs go about organizing themselves is by compe- tition for representation of the samples. Neurons are also allowed to change themselves by learning to be- come more like samples in hopes of winning the next competition. The first step in constructing a SOM is to initialize the weight vectors. From there you se- lect a sample vector randomly and search the map of weight vectors to find which weight best represents that sample. Since each weight vector has a location, it also has neighboring weights that are close to it.

The weight that is chosen is rewarded by being able to become more like that randomly selected sample vector.

The quality of clustering using SOM are mainly  influenced by three essential parameters: (1) size of the map, (2) initialization of weights (codebook vec- tors) and (3) neighborhood functions. In this study,  0-7803-9521-2/06/$20.00 ?2006 IEEE. 3176    we used the Davies-Bouldin index (DB) as cluster- ing validation measure. This index is given by the following formula:  DB n  a Sn(Qi) + Sn(Qj) (2DR max (2) n iiA S(QiQJ)/=1  where n is the number of clusters, Sn average distance between the center of each cluster and the objects within this cluster, S(QiQj) intra-cluster distance.

Consequently, the ratio is small if the clusters are compact and far one from the other. The DB index will have a small value for a good clustering. After the choice of the best SOM, we proceed according to two approaches. In the first approach (Approachl), we calculate the distance between every vector obtained in the previous step and every cluster obtained in the map. This distance is in fact the distance between this vector and the (codebook) vector for each cluster in the map. At the end of this approach, the behavior of each IPext in target with each IPint in a tempo- ral window is represented by the distance vector cal- culated between this vector and the behavior-types (clusters). Consequently, for every IPint we calcu- late the sum of the distances between the vectors that contain IPint and each of clusters. We can thus make a synthesis [window -[Pint dist2clust1 ... dist2clustn] of the behavior-types (clust1 ... clustn) detected for each IPint independently of 'Pext to be able to com- pare the profile of two different internal machines.

In the second approach (Approach2), and for ev- ery IPint, we made a synthesis of the number of standard behaviors detected bound for this IPint in a temporal window. We obtain a synthesis [window IPint NBofclust, ... NBofclustn] of the behavior-types (clust1 ... clustn) detected for each IPint independently of 'Pext to be able to compare the profile of two different internal machines.

3.4. Classification The synthesis of the standard behaviors calculated  for every IPint is supposed to be representative of the various types of potential attacks aiming each in- ternal machine of the network during a fixed window of time. We propose in this last phase to use these information to determine if the network were really attacked (ATT = true or false). To implement this task of classification, we will restrict ourselves with Bayesian network models [22], [20]. Bayesian net- works are tools to reason with uncertain information in the probability theory framework. They use direct acyclic graphs to represent causal relations, and con- ditional probabilities (of each node given its parents) to express uncertainty of causal relations. The struc- ture of the Bayesian network is fixed in advance like the Naive Bayesian network, or given by an expert of domain, or learned from data. Similarly, the condi- tional probabilities can be obtained from an expert or learned from data.

In this work, we implemented different kinds of Bayesian networks for the two experts. These struc- tures are:  * Naive Bayesian Network (NB), * Tree Augmented Naive Bayesian Network (TANB), * Maximum Weighted Spanned Tree (MWST), * Multinet.

Naive Bayesian Networks (NB) [15] are very sim- ple Bayesian networks which are composed of DAGs with only one parent, representing the unobserved node, and several children, corresponding to observed nodes, with the strong assumption of independence among child nodes in the context of their parent. This model gave excellent results in many fields. How- ever, such an assumption is not always valid and can sully the results. The TANB [15] is another struc- ture similar to the NB but more elaborate because it does not propose any independence between the child nodes. The class node has no parents and the child nodes have at maximum two parents including the class node. The third structure MWST proposed by Chow and Liu [9]. This method seeks to find a max- imum weighted spanning tree. For the TANB and MWST, the structure are completely learned from data. For the parameters (conditional probabilities), we assume that every node is a continuous node that has a Gaussian(i.e. normal) probability distribution which supposes a continued values of attributes. We consider the characteristic vector of each IPinterne as input to determine the value of class (normal or attacks) as the maximum a posteriori of the class node probability (conditionnally to the observation of all the attributes nodes). This probability is directly obtained by using a classical inference algorithm in the network.

For the fourth kind of Bayesian network (Multinet), we created two Bayesian networks using the MWST algorithm. The first is created from normal data and the other from abnormal data. As the class node is not explicitely defined, we calculate the maximum a posteriori (MAP) of the class probability by using the following formula:  P(C = cjlA) c P(AIC = ci) x P(C = ci) (3) where P(A C = ci) is the likelihood of the evidence A calculated for each structure (normal and abnormal) and P(C = ci) is the prior probability of each class.

4. Experiments and results 4.1. Description of the Data We work starting from log files issued from NIDS  SNORT. These files include 32031 alarms gener- ated over a duration of 20 days from 20/11/2004 to 10/12/2004. These alarms correspond to 4638 exter- nal machines trying to connect 288 internal machines.

Alarms generated during these 20 days are of 406 dif- ferent types and they include 16 real attacks scenar- ios, some are of a few minutes, others lasting several days and the other are for normal scenario.

The scenarios of attack are distributed as:  * 4 scenarios brute force on POP3, * 3 scenarios crawler Web, * 2 scenarios Web IIS,  0-7803-9521-2/06/$20.00 ?2006 IEEE. 3177    * 2 scenarios scanner of vulnerability, * 1 scenario IIS attack against apache server, * 3 scenarios brute force against FTP server, * 1 scenario SNMP attack.

After implementing the temporal pre-processing phase we decomposed the base in two bases: learning base and testing base. The learning base contains 10 scenarios of attacks and the testing base contains six scenarios of attacks.

4.2. Spatial preprocessing As mentioned above, the data used for the exper-  iments in this phase are characteristic vectors sum- marizing the profile of every couple (IPext -Pint) in a fixed window of time. We conducted a series of experiments in three stages:  1. Normalization: in this stage we made two tests, one with normalization and other without normaliza- tion.

2. Weighting: as mentioned in the section 3.3. J.we classified the alerts with three level of importance and for every level we integrated a weighting coefficient.

Let a, b and c be these three coefficients, we made here four tests: . Without weighting (a= 1, b= 1 and c= 1).

. Weighting level 1 (a = 1, b= 2 and c= 3).

. Weighting level 2 (a = 1, b = 0 and c= 10).

. Weighting level 3 (a = 1, b= 10 and c= 100).

3. SOM parameters: . Size: we used several sizes (5*5, 10*10, 15*15,  20*20 and 25*25).

. Initialization: linear and random.

. Neighborhood function: gaussian, cutgauss, ep and buble1.

The first results obtained in this phase show that the best results correspond to un-normalized data with weighting level 1 and a map of size (5*5) with linear initialization and gaussian neighborhood func- tion.

By admitting that the codebook vector of each clus-  ter is representative of the data projected in this clus- ter, we can try to interpret the map by determining the most significant variables in each cluster (for in- stance, the first top 5 variables). As each variable corresponds to one specific alarm, we obtain the char- acteristic alarms of each cluster.

Table 1 gives the top 5 significative alerts for two clusters (5) and (22). The scenarios (13) and (15) are two web attacks against an IIS server and Apache server. The majority of points for these two scenar- ios are projected in the cluster (5). As we can see in the table 1, the first three top alerts of the cluster 5 are characteristics of Web attacks. The scenario (14) is a brute force against POP3 server. The majority of points are projected in the cluster (22). The first  1We admitted here the same conventions used in SOM- TOOLBOX implemented in Matlab.

Table 1. Top 5 alarms of clusters 5 and 22.

Alert rank | Cluster 5 1 WEB-IIS mem bin access 2 WEB-FRONTPAGE shtml.dll access 3 WEB-FRONTPAGE .... request 4 ATTACK-RESPONSES 403 Forbidden 5 POLICY FTP anonymous login attempt Alert rank Cluster 22 1 User incorrect POP 2 WEB-MISC http directory traversal 3 VIRUS .exe file attachment 4 VIRUS .pif file attachment 5 VIRUS .bat file attachment  top alert in cluster (22) is User tncorrect POP which is a sign of POP attack.

4.3. Classification We could directly use this map to perform a super-  vised classification by making the following assump- tion: every data projected in a cluster is classified as the more frequent situation also projected in the same location during the learning phase. With this strong assumption, we obtained the following results: (a) 84% of attack scenarios are mapped in relevant attack clusters and consequently are well detected, (b) 85% of normal scenarios are mapped in normal clusters (15% false positives) and consequently are filtered out. These results show us that the SOM clustering is able to regroup similar data and conse- quently to discover some interesting codebooks rep- resentative to attack scenarios or normal situations.

But this clustering do not gives us performances that will be expected by an network security expert. For this reason, we think that the last stage of our ar- chitecture (the classification phase) is quite impor- tant. As mentioned in the previous section , we led a serie of experiments on Bayesian networks for two approaches Approachl and Approach2. Tables 2 and 3 show the obtained results for the two approaches.

The hit rate is the percent of attacks classified as at- tacks, the filtered alarms is the percent of normal data classified as normals and consequently filtered out, and the PCC is the overall percent of correct classifi- cation. The PCC is not very significant in the prob- lem of intrusion detection because in the majority of cases, the normal data are much more numerous than the attacked data (for example in our case, the nor- mal data constitute 99% of the whole of data). Thus the ideal system of filtering is not that it gets higher PCC, but that can detect all the true attacks (hit rate=100%) and at the same time filter out most of all the normal alarms (alarm filtered-_ 100% or false positive 0%). Our results show that the Multirnet network is the most suitable for intrusion detection alarms filtering when it is applied for the second ap- proach (Expert2). Note that on these kind of struc- tures (Multinet), the prior probability of Class is very important, in special on the cases where the two like-  0-7803-9521-2/06/$20.00 ?2006 IEEE. 3178    Table 2. Results obtained for different structures of BN applied to the first approach (Approachl). PCC stands  for Percent of Correct Classification.

Algorithm Hit Rate Filtered Alarms PCC Naive 46% 88% 87.44% MWST 36% 97% 96.18% TANB 74% 89% 88.80%  Multinet 0% 100% 99.99%  Table 3. Results obtained for different structures of BN applied to the second approach (Approach2).

Algorithm Hit Rate Filtered Alarms PCC Naive 62% 88% 87.65% MWST 12% 98% 96.85% TANB 62% 83% 82.72%  Multinet 92% 64% 64.37%  Table 4. Influence of the prior probability of the class on classification results for the Multinet Bayesian network.

lihoods for the evidence vector (P(A/C = normal) and P(A/C = attack)) have close values.

Table 4 shows the influence of the prior probability on the results. It presents the classification results with the maximum a posteriori decision rule taking into account the prior probability of the class (P(C = normal) = 0.99 and P(C = attack) = 0.01) and with the maximum of likelihood decision rule (i.e. by considering that the prior probability is uniform). In this case, we can notice that the results are better (Hit Rate= 100% and Filtered Alarms= 76%).

5. Conclusion and future work We presented here an automated architecture for  filtering the alarms issued from a network intrusion detection system (NIDS). Our architecture, based on unsupervised classification and Bayesian networks, allows to determine if the network is really attacked.

While the filter only keeps 24% of false positive (Fil- tered Alarms=76%), it could detect all the real at- tacks (Hit Rate= 100%).

In the future, we intend to use a data base much richer on attack and some specialized Bayesian net- works taking into account the network characteris- tics (topology, types of server) in order to to improve the results. We will also use other classification al- gorithms like Support Vector Machines to compare  their results in the last of our architecture.

The last step will be the study of the adaptability  of our architecture, i.e. being able to automatically detect evolution of the context (new machines in our network, new alarms, new behaviors-type, ...) and taking them into account.

Acknowledgement This work was supported in part by the IST Pro-  gramme of the European Community, under the PAS- CAL Network of Excellence, IST-2002-506778. This publication only reflects the authors' views. The au- thors are thankful to Cedric Foll, security engineer in our "education board" for his expertise in intrusion detection and for data and help he provided us.

6. References [1] J. Allen, A. Christie, W. Fithen, J. McHugh, J.

Pickel, and E. Stoner. State of the practice of Intrusion Detection Technologies. Technical Re- port, Carnegie Mellon University. 2000  [2] M. Almegren, H. Debar and M. Dacier. A lightweight tool for detecting web server attacks.

Network and Distributed System Security Sym- posium (NDSS 2000), p 157-170, 2000.

[3] R. Bace. Intrusion Detection. Macmiillan Tech- nical Publishirng. 2000.

[4] N. Ben Amor, S. Benferhat, and Z. Elouedi.

Naive bayesian Networks irn Intrusion Detection Systems. Workshop on Probabilistic Graphical Models for Classification, 14th European Confer- ence on Machirne Learniing, 7th European Con- ference on prirnciples and Practice of Knowledge Discovery in Databases (ECML/PKDD'2003), Dubrovnik, Croatie, 11-23 Septembre, 2003.

[5] N. Ben Amor, S. Benferhat, Z. Elouedi and K.

Mellouli. Decisioin Trees and Qualitative Pos- sibilistic Inference: Application to the Intru- sion Detection Problem. European Conference of Symbolic and Quanrtitative Approaches to Rea- soning and Uncertairnty (ECSQARU'2003), Al- borg, Danemark, pp. 419-431, Juillet, 2003.

[6] N. Ben Amor, S. Benferhat, Z. Elouedi and F. Cuppens. Decisioin Trees and Qualitative In- ference for Intrusion Detection Systems. Inter- national Fuzzy Systems Association conference (IFSA2A003), Turquie, Juillet, 2003.

[7] D. J. Burroughs, L. F. Wilson and G. V. Cy- benko. Analysis of Distributed Intrusion Detec- tion Systems Usirng Bayesian Methods. Proceed- ings of IEEE International Performance Com- putirng and Communiication Conference, April, 2002.

[8] S. Cho. Incorporatirng Soft Computirng Tech- niques into a Probabilistic Intrusion Detection and Cybernetics, 32 (2), pp. 154-160, May, 2002.

[9] C. K. Chow and C.N. Liu. Approximating dis- crete probability distributions with dependence 3(14), pp. 462-467, 1968.

0-7803-9521-2/06/$20.00 ?2006 IEEE.

Max of likelihood Max a posteriori P(AIC) P(AIC)P(C)  Hit Filtered Hit Filtered Rate alarms Rate alarms  Approachl 84% 86% 0% 100% Approach2 100% 76% 92% 64%     [10] F. Cuppens. Managing alerts irn a multi- intrusion detection environment. In 17th An- nual Computer Security Applications Conference (ACSAC), p 22-31, 2001.

[11] 0. Dain and R. K. Cuningham. Fusirng heterge- nous alert streams irnto scenarios. In Proceedirngs of the Eighth (ACM) Conference on Computer and Communiications Security, pp. 1-13, 2001.

[12] H. Debar, M. Dacier, and A. Wespi. A Revised Taxonomy for Intrusion Detection Systems. An- nales des Te'le'communiications. 55(7-8), p 361- 378, 2000.

[13] H. Debar and A. Wespi. Aggregation and corre- lation of intrusion alerts. In 4th Workshop on Recent Advances irn Intrusion Detection (RAID 2001), LNCS. Springer Verlag, Berlin, p 85-103, 2001.

[14] A. Faour, P. Leray and C. Foll. Re'seaux bayesieins pour le filtrage d'alarmes dans les systemes de de'tection d'intrusion. In Ate- lier Modeles Graphiques Probabilistes, 5emes journe'es d'Extraction et de Gestion des Connais- sances (EGC 2005), pages 25-33, Paris, France, 2005.

[15] N. Freidman, D. Geiger and M. Goldszmidt.

Bayesian network classifiers. Machirne Learning, (29), pp. 131-163, 1997.

[16] F. V. Jensen. An introduction to Bayesian Net- works. Taylor and Francis, London, United Kingtom, 1996.

[17] K. Julish and M. Dacier. Miniing Intrusion De- tection alarms for actionable knowledge. In the edge Discovery and Data Miniing, p 366-375, 2002.

[18] T. Kohonen. Self-Organrizirng Maps. Series irn Information Sciences. Third Extended Edition, Berlin. Sprirnger, 2001.

[19] C. Kruegel, D. Mutz, W. Robertson and F.

Valeur. Bayesian Event Classification for Intru- sion Detection. In the Proceedings of the 19th Annual Computer Security Applications Confer- ence (ACSAC03), IEEE Computer Society, p14, Washington, DC, USA, December, 2003.

[20] P. Leray and 0. Francois. Re'seaux Bayesieins pour la classification - Methodologie et Illustra- tion dans le cadre du Diagnostic Me'dical. Re- vue d'Intelligence Artificielle, 18(29), pp. 169- 193, 2004.

[21] S. Manganaris, M. Christenen, D. Zerkleand and K. Hermiz. A Data Miniing analysis of RTID alarms. Computer Networks, 34-(4), p 571-577, 2000.

[22] J. Pearl. Probabilistic Reasoniing irn Intelligent Systems: Networks of Plausible Inference, Mor- gan Kaufmann, 1988.

tion for networks. Proceedirngs of Thirteenth Sys- tems Admiriistration Conference (LISA '99), pp.

229-238, 1999.

[25] S. L. Scott. A bayesian paradigm for design- ing Intrusion Detection System. Computational Statistics and Data Analysis (special issue on network irntrusion detection), 45, pp. 69-83, 2004.

[26] A. A. Sebyala, T. Olukemi, and L. Sacks. Ac- tive Platform Security through Intrusion Detec- tion Usirng Nave Bayesian Network for Anomaly Detection. In the proceedings of London Com- munications Symposium, 2002.

[27] R. Sekar, Y. Guang, S. Verma and T. Shanbhag.

A high performance network intrusion detection system. 6th ACM Conference on Computer and Communiications Security, p 8-17, 1999.

[28] A. Seleznyov. Temporal-Probabilistic Network Approach for Anomaly Intrusion. 12th Annual Computer Security Inrcident Handlirng Confer- ence, Chicago, 2000.

[29] S. Staniford, J.A. Hoagland and J.M. McAler- nay. Practical automated detection of stealthy portscans. In the ACM Computer and Commu- nications Security IDS Workshop, pp. 1-7, 2000.

[30] A. Valdes and K. Skinner. Probabilistic alert cor- relation. In the 4th Workshop on Recent Ad- vances in Intrusion Detection (RAID), LNCS.

Springer Verlag, Berlin, pp. 54-86, 2001.

[31] D. Zamboni. using internal sensors for computer intrusion detection. PhD Thesis, Purdue Univer- sity, 2001.

[23] R. S. Puttini, Z. Marrakchi and L. Me. A Bayesian Classification Model for Real- Time In- trusion Detection. AIP International Confer- ence, 659 (1), pp. 150-162, March, 2003.

