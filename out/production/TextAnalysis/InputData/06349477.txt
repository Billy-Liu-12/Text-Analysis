Identifying Context of Text Documents using Na?ve

Abstract-Huge amount of unstructured data is available  in the form of text documents. Ranking these text  documents by considering their context will be very useful  in information retrieval.

We propose classification of abstracts by considering  their context using Na?ve Bayes classifier and Apriori  association rule algorithm - i.e. Context Based Naive  Bayesian and Apriori (CBNBA). In proposed approach, we  initially classify the documents using Na?ve Bayes. We find  the context of an abstract by looking for associated terms  which help us understand the focus of the abstract and  interpret the information beyond simple keywords. The  results indicate that context based classification increases  accuracy of classification to great extent and in turn  discovers different contexts of the documents. Further this  approach can found to be very useful for applications  beyond abstract classification where word speaks very little  and lead to ambiguous state but context can lead you to  right decision/classification.

I INTRODUCTION  Given that enormous amount of unstructured data is  available on web sites, most of it is in the form text data.

Unstructured data constitutes text, images, audio data  etc. Reports, journals, news, research papers, magazines  contain unstructured data out of which most is textual.

Retrieving relevant data from such a huge store is a  challenging task. Hence classifying these documents  accurately and identifying their contexts is very  important. We must look beyond text in the documents  i.e. beyond text-centric classification. The words that  surround a term help us in understanding their context or  the situation in which that specific term is being used.

Also when certain words are used in combination, they  imply a different situation than the situation implied  when they are used separately. E.g.: ?load? indicates  weight, consignment or capacity, ?balance? indicates  stability, weighing scale but when ?load balance? occurs  together it implies bringing computer networks in  equilibrium and improving their performance. We call  this ?context? and use this fact to improve the accuracy  of classification.

Many techniques are available for text data  classification. Many researchers [1, 2, 3, 4] have  combined these techniques and have come up with good  results. Nevertheless, many a times we get irrelevant  results. This is due to the fact that classification is text-  centric that considers only frequency of occurrence of  words. Widely used techniques to classify text are Na?ve  Bayes, Support Vector Machines, k-nearest neighbour,  classification using clustering, Self-organizing Maps etc.

Association rule mining is also very frequently used to  find associated words.

We use Na?ve Bayes classifier to classify the  documents at first level. We then find different context  of each document by using Apriori-based association  rule mining technique to find the words which occur  together.

Section 2 describes literature survey which discusses  usage of Na?ve Bayes classifier and Apriori for text data  and related work, section 3 describes proposed  technique, and section 4 contains experimental setup and  results. We conclude in section 5.

II LITERATURE SURVEY  A. Na?ve Bayes Classifier for Text documents Text document classification widely uses Naive Bayes  classifier due to its ease of use and accuracy. Naive  Bayes classifier uses Bayes theorem [5]. The probability  that a test document td belongs to class C is given by  ( ) ( ) ( )[ ] ( )ddd tPCPCtPtCP /|| ?=  .

Since ( )dtP is same for all classes, it is ignored. But  { }nd XXXt ,,, 21 K=  where n is number of features or terms in case of a document. Thus, ( )CtP d |  is written as ( ) ( ) ( )CXPCXPCXP n ||| 21 ??? K .

Thus ( ) ( ) ( )? =  = n  i  id CXPCPtCP  || .

When the training database contains a set of text  documents, the documents have to be pre-processed.

Unnecessary and irrelevant words are removed by the    process of filtration and stems of remaining words are  obtained. Stemmed remaining words are said to be  document representatives and their weight is calculated  by finding the frequency of occurrence in the document.

This matrix of document (representing rows) versus  attributes (representing columns) is used for preparing  the model using Naive Bayes classifier.

B. Apriori Association Rule Algorithm for Text documents  To find frequently occurring items in transactions of a  database, Apriori Algorithm [6] is very widely used  because of its speed and ease of use. It scans through  every transaction adding one item to a frequent item set  at every step and builds possible list of n-frequent item  sets by pruning those candidates which do not have  specified support or lift. It uses the anti-monotone  property [7]. When text documents make up the  database, we need to convert the word frequencies into  binary form. Each sentence of a document or a single  document can be considered as a transaction.

C. Other Research Work SB Kim et al [8] have suggested different ways to  model the text better. They specify the ways to correct  skewed data and weight magnitude errors. To normalize  term frequency, they use multivariate Poisson model and  normalize as per document length. They combine these  normalized frequencies linearly as per the probability  that each document belongs to the document set. In  traditional model each term occurrence is given equal  importance. As a result, it gives unequal importance to  each document. Authors propose a model that gives  equal importance to every document, by normalizing  terms in each document thus giving less importance to  less frequently occurring terms in longer document. For  feature weighting, they consider weight of a term testing  positive for a class and also testing negative for that  class.

L.Yuan [9] uses multivariate Bernoulli model which  uses Boolean weights to indicate presence or absence of  a term in a document.

J.D.M. Rennie [10] propose usage of complement class  to improve the drawback of giving unequal importance  to document when one class has more training examples  than another. They also propose normalization of  classification weights. For this they use multinomial  Na?ve Bayes. To balance the skew, they propose using  data from all classes except from the class for which  probability is being calculated. For normalization of term  frequency they come up with a different technique. For  the words which always occur together, they propose to  combine them together and use them as just one word  else it would double up the weights.

Alan Chikinsky [11] proposes representing any text  document using his own vocabulary. He replaces  different phases and words that occur in text document  with other predetermined words and he claims that these  simple sentences capture the essence of the document,  thus helping us understand the context.

Garcia et al [12] use unique integer identifier to  represents a distinct word in all the document including  stop words. They construct item sets to find tern  association or Maximal Sequence Patterns using these  identifiers.

Moucek et al [13] propose classification of Czech  document using WEBSOM. They create word category  maps using input feature vector and then create clusters  according to document clusters. They classify documents  as well as words to given category.

McCallum et al [14] have used multivariate Bernoulli  model for text classification.

III CLASSIFICATION AND IDENTIFICATION OF CONTEXT  A document mD is represented by a feature vector  { }mnnmiimmm wtwtwtwtD :,,:,,:,: 2211 KK= At first level, all the documents are classified using  Na?ve Bayes classifier. We then find words that occur  together in at least 50% documents of each class by  using Apriori algorithm. Sat represents set of associated  words where each combination of words represents  context.

( )[ ] ( )[ ]{ }K,:,,,:,, 21 cwwwcwwwS rqpnmlat = We use this set of associated words in each class at  second level to determine different contexts of a text  document.

Fig.1. Algorithm to find context of a text document    Each document is looked for existence of associated  terms represented using Sat. A document may have  associated words from multiple contexts. Depending  upon the frequencies we interpret different contexts.

Thus it indicates that a document may belong to one  context more but also may belong to some other context.

Level I: Finding class of text documents in  test set  ? Using Na?ve Bayes for training and testing sets, determine the class of each  document from test set.

Level II: Finding context of text documents  in test set  ? Using Apriori association rule algorithm, find associated terms from  each document in training set for each  context type  ? For each document in test set, count occurrence of words from each set of  associated terms and arrange them in  non-increasing order  ? Context of that document will be given by these ordered counts      For e.g. consider a fragment from an abstract - ?Load  balancing is applied to the development of network-  based Intrusion Detection System (NIDS) to fit the  performance problem caused by traffic in high  bandwidth network.? This abstract contains two contexts  ? network load balancing and network intrusion  detection system (IDS).

When we apply Na?ve Bayes, it classifies a document  only under one class no matter by what fraction posterior  probabilities of other classes are smaller. By considering  the fraction by which other associated terms are smaller  we rank a document more into a specific context but also  little less into another context.

Thus if a document mD  represents two contexts 1c  and 2c , and if 21 cc > , we say context of mD  is 1c . If  2c  has weight not less than some x% of 1c , mD  is said  to have context 2c  as well. We have considered x to be  60.

Thus 21 ,ccDm ?  in that order. Algorithm is shown in  figure 1. Figure 2 shows a pictorial representation of a  text document having multiple contexts.

Fig.2. Pictorial representation of a text document having multiple  contexts  CN-Computer Network, OS-Operating System, LB-Load Balancing, IDS-Intrusion Detection System, KD-Kernel Design    IV EXPERIMENTAL SET UP AND RESULTS  We used 57 abstracts downloaded from IEEE explorer  and other websites having 2 different categories, namely  computer network and operating systems as training  documents. We selected around 680 attributes excluding  common words like ?the?, ?for?, ?it? etc. and stemming  the terms. We also removed noisy attributes which  occurred in very few documents. Remaining ones were  used as dimensions of document vector. 22 documents  were used as test documents. We used the matrix of  feature vs. document for classification using Na?ve  Bayes. Test documents were classified into 2 classes ?  computer networks and operating systems. We carefully  chose the test documents and made sure that they contain  terms from other class and context as well.

We extracted 8 sets of associated terms from 57  training documents using Apriori for 4 contexts ? 2 from  each class. Table 1 shows the associated terms and their  context.

With classification, test documents were classified as  in computer network class or operating systems class.

But upon usage of associated terms, it was observed that  some of the documents which were classified to be in  one class also were very close to other class. Following  table 2 has comparisons.

TABLE I  ASSOCIATED TERMS WITH THEIR CONTEXT   Associated Terms Context  Balance, load, network, result, scheme, simulate  Computer Network: load balancing  Attack, base, detect, intrusion,  network, system  Computer Network: intrusion  detection system  Base, detect, intrusion, load,  network, system  Computer Network: intrusion  detection system  Design, kernel, operating,  system  Operating Systems: kernel  design  Kernel, operating, perform,  system  Operating Systems: kernel  design  Kernel, operating, support,  system  Operating Systems: kernel  design  Base, memory, operating,  perform, system Operating Systems: memory  Hardware, memory, operating,  perform, system Operating Systems: memory    TABLE II  COMPARISONS OF CONTEXT SCORES OF SELECTED TEST DOCUMENT  Test  Doc  Class CN-  LB  CN-  IDS  OS-KD OS  Memory 3 CN 81% 100% 6% 43%  5 CN 78% 100% 42% 57%  13 CN 51% 100% 29% 61%  17 OS 28% 71% 100% 71%  20 OS 5% 68% 100% 52%    It is seen from table II that a document of one class may  have associated terms from other contexts. It may even  have certain keywords from contexts of other class. Test  document 3 and 5 have most of the associated terms  from IDS and LB contexts. Test document 13, even  though classified as CN is closer to OS-memory context  as well. Test documents 17 and 20 have maximum  associated terms from OS-KD context but at the same  time they have many associated terms from IDS context.

This shows that a document may have many contexts  and all the contexts of the documents must be captured.

Figure 3 shows a document may have different  contexts and it may belong to one context more than the  other one. Nevertheless, it may also belong to other  contexts. Figure 4 elucidates context and presents  documents in a new dimension.

Document  Classes  CN  IDS LB  OS  KD Memory  71%  71% 100%  28%       Fig.3. Comparison of contexts in different test documents         Fig.4. New dimension to test documents by discovering existence of  multiple contexts    V CONCLUSION  A document contains a set of words which are  interrelated to each other and carry meaning. Thus when  processing a text document, we must consider the  relationships between the words and the meaning they  carry together. Considering associated terms help us  understand the situation or the context of the documen  The results are encouraging. Using synonyms  improve the results as it will strengthen the associated  terms. We need to further work with larger dataset  can consider synonyms and ontology. Also positional  appearances of the associated terms could be considered.

We also need to work on techniques to represent the  context of text document. This technique could be used   0%  20%  40%  60%  80%  100% Test Doc 3  Test Doc 5  Test Doc 13Test Doc 17  Test Doc 20  CN- LB  OS-KD 0%  20%  40%  60%  80%  100%  Test  Doc   Test Doc   Test  Doc   Test  Doc   Test Doc     Comparison of contexts in different test documents    New dimension to test documents by discovering existence of  A document contains a set of words which are  interrelated to each other and carry meaning. Thus when  processing a text document, we must consider the  relationships between the words and the meaning they  onsidering associated terms help us  understand the situation or the context of the document.

Using synonyms will  improve the results as it will strengthen the associated  We need to further work with larger dataset and  . Also positional  appearances of the associated terms could be considered.

