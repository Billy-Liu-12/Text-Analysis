

Linguistic Modeling for Function Approximation Using Grid Partitions  Hisao Ishibuchi, Takashi Yamamoto, and Tomoharu Nakashima Department of Industrial Engineering, Osaka Prefecture University  1-1 Gakuen-cho, Sakai, Osaka 599-8531, JAPAN (hisaoi, yam& nakashi}@ie.osakafu-u.ac.jp  Absbrrcr  modeling of nonllnear fundons with many Laput variables. Our task la to extract a small number of comprehensible lingoisae roles from numerical data for describing nonlinear hndons in a human understandable manner. First we #bow the necessity of genera NI- La the handUng of aonllnear functions with many input vnriables. Next we compare B standard interpolation-bared huzy reasoning method with our uon-stmdnrd sped8elty-bared method When a rule base is a mlxinre of general and specific rules, different results are obtained ftom these two methods. Then we atend two perforounce measures (Le., confidence and support) of sasociatiou rules in data mlnlng to the care of Ungulatle rules. These two measures are wed for evalualing each linguirtie rule. The vllidlty of our f o l y  r e M 0 d g  method is dlsewed wing these measures Finally we show two genetlc algorithm-bared approaches to linguistic modeling. Oae is a role seleetlon method, and the other is B genetics-based machine learning (GBML) algorithm.

This paper discnues various issues related to unguistie

I. INTRODUCTION  For linguistically describing an unknown nonlinear function y = f (x) with n input variables, we use linguistic rules of the following form:  At : If x1 is AH and ... and x, is A, then y is Et, '(1) where xi is the i-th input variable of an n-dimensional input vector x = (xl ,_._, x n  ) , y is an output variable, k is a rule index, Ak. is an antecedent linguistic value for xi, and Bk is a consequent linguistic value. In this paper, we do not discuss the specification of antecedent and consequent linguistic values.

We assume that a set of linguistic values has already been given for each input (and output) variable. Examples of typical linguistic values sre shown io Fig. 1.

M"","""  l . 0 ~  ~  0.0 0.0 1.0  Fig. 1. Triangular membership functions of linguistic values (S: small, MS:  medium small, M medium, ML: medium lorge, and L large).

Linguistic rules for a two-input nonlinear function are usually written in a tabular form as in many applications of  fuzzy rule-based systems to control problems. While such a tahular form is easily understood by human users, it cannot scale up to highdimensional problems because the numher of rules in a tahular form expnentislly increases with the dimensionality of the input space. It is a troublesome task for human users to manually examine a large number of linguistic rules. Many antecedent conditions also deteriorate the interpretability of linguistic rules (i.e., it is difficult for human users to intuitively understand long rules with many antecedent conditions). Recently several approaches have been proposed for genersting interpretable fuzzy rule-based systems from numerical data [1-6]. The main issue in those studies is to find a good tradeoff (i.e., compromise) between accuracy and interpretability. Many studies use clustering techniques for finding a small number of fuzzy if-then rules with multi- dimensional antecedent fuzzy sets. When the linguistic interpretstion of each fuzzy if-then rule is required, single- dimensional antecedent fuzzy sets are generated h m  multi- dimensional ones by the projection to each axis of the input space. When similar singledimensional antecedent fuzzy sets are generated, they are merged for improving the interpretability of fuzzy if-then rules. In such a clustering- based approach, antecedent fuzzy sets are generated from numerical data without human howledge. On the contrary, we assume that a set of linguistic values has already been given for each input (and output) variable hy human users. This assumption means that .a fuzzy partition (i.e., information granularity) of the input (and output) space has already been given by human users. In Such a situation with human howledge, it may he a natural m y  to use the given linguistic values in antecedent and consequent parts of our linguistic rules. Our fuzzy reasoning and rule extraction methods in this paper are also applicable to more general cases where fuzzy partitions are to be determined from numerical data without human knowledge.

11. NECESSlTY OFGENERALRULES  We use linguistic rules of the form in ( I )  for describing an unknown nonlinear function y = f ( x )  with n input variables.

For simplicity of explanation, let us assume that the input space and-the output space am an n-dimensional unit cube [0,1]" and a unit interval [0,1], respectively. When we use the five linguistic values in Fig. 1 in the antecedent part, each linguistic value covers the following fraction of the domain m W a l  [0,1] of each input variable:  0-7803-7293-X/Ol/$I7.00 B 2001 IEEE 47 2001 IEEE International F u z y  Systems Conference  mailto:nakashi}@ie.osakafu-u.ac.jp   small 114, medium small 112, medium: 112, medium large: 112, large: 114.

Thus we can see that each linguistic value covers 215 of the domain interval [0,1] on the average where  Since each rule has n antecedent linguistic values, it covers (215)" of the ndimensional input space [O,l]" on the average when no "don't care" conditions are included. The number of linguistic rules required for covering the whole input space is roughly estimated as (512)".

The above discussion clearly shows that the number of linguistic rules exponentially increases with the number of input variables. Our trick for avoiding the exponential increase is to use "don't care" as an antecedent linguistic value in linguistic rules in (1). We represent don't care by a special memhersbip function whose membership value is always unity in the whole domain interval of each input variable (i.e., pdon~tcarr(x)=l  for Vx ). The number of antecedent conditions (excluding don't care conditions) is referred to as the rule length. Short rules have only a few antecedent conditions while long rules have many conditions. Short and long rules are refemd to as general and specific rules in this paper, respectively.

When we use general rules of the length m for the n-input nonlinear function (m << n) , each rule covers (215)"' of the whole input space [ 0, I]" on the average. Thus the number of linguistic rules required for covering the whole input space is roughly estimated as (5 /2)" ' ,  which does not depend on the dimensionality n of the input space @ut depends on the length m of each genera) rule). When m <<n , (5/2)'" is much smaller than (512)" .  This means that the whole input space can he covered by a small number of general rules. Of course, general rules do not always represent nonlinear functions very well. Thus some specific rules together with general rules may he required for linguistically describing nonlinear functions.

General rules are also preferred to specific rules fmm the viewpoint of the interpretability of linguistic rules. It is much easier for human users to intuitively understand general rules with only a few antecedent conditions than specific rules with many conditions.

2 / 5 = ( 2 x 1 1 4 + 3 x 1 / 2 ) + 5 .  (2)  111. SPECIFICITY-EASED FUZZY REASONING  Let us consider a rule base consisting of the following three linguistic rules:  RA : y is smal!, R, : If XI is small theny is medium,  (3) (4)  RC : If XI is small and x2 is small then y is large, ( 5 ) where "small", "medium" and "large" are linguistic values shown in Fig. 1. Our fuzzy reasoning task in this example is to estimate the output value y for any input vector x = (x  I , x2  ) using the three rules R A ,  RB and R ,  . For an input vector with small x, and smoll x2 (e.g., x=(O, 0)), all the three rules are applicable. Since many fuzzy reasoning methods are  based on interpolation techniques of applicable rules, the estimated output value may be a real number around 0.5 that corresponds to the interpolation of the consequent linguistic values of the three rules. In Fig. 2 (a), we show the nonlinear function obtained h m  the above three rules using the following simplified version of Takagi-Sugeno method  where q k  (x) is the compatihility grade of the linguistic rule Rk with the input vector x, and bk is a representative real number of the consequent linguistic value Bk . The compatihility 'grade pk (x)  is usually calculated by the product operation as  where phi(.) is the membership function of the antecedent linguistic value A h  .

The estimated output value for an input vector with small x, and small x2 (e.g., x =  (0, 0)) by our specificity-based fuzzy reasoning method [7,8] is a real number around 1.0 because the most specific rule (i.e., R C )  is mainly used for the estimation. Our fuzzy reasoning method is witteu as  P k ( X ) = P k I  ( x l ) x " ~ x ~ ' k r ( X n ) ~  (7)  N x 6 ( R k  , x ) . b x  ' P k  (X)  N x 6 ( R k  , X ) . P k  (X) k=l  j ( x )  = k=l (8)  where m(Rk ,x)  is a weight determined by the relative specificity level of the linguistic rule Rk . The value of 6 ( R k  ,x) becomes small when Rk includes more specific rules compatible with the input vector x. In this case, the weight of Rk is discounted in our fuzzy reasoning method.

The weight 4 ( R k  ,x)  is defined as  6 ( R k  ,x)= n ( l - P q  (X ) ) .  (9) R q  C R i  q*k  When no linguistic rule is included in Rk , # ( R k  ,x)  is specified as ) ( R k  , x )= l  hecause the weight of Rk should not he discounted in this case. In Fig. 2 @), we show the nonlinear function obtained 60m the three linguistic rules in (3)-(5) using our specificity-based fuzzy reasoning method.

(a) standard reasoniog. @) Our method.

Fig. 2. Comparison of t iny reasonkg results.



IV. FUZZlFlCATlON OF ASSOCIATION RULES  The concept of association rules [9] WBS used in many studies on data mining. Two measures (i.e., support and confidence) were used for evaluating each association rule X =Y using a transaction set D. The transaction set corresponds to the given training data because a bxnsaction corresponds to an input-output pair. The association rule X 3 Y is said to hold in the transaction set D with a confidence c if c (xl00 %) of transactions in D that contain X also contain Y. The association rule X s Y is said to have a supports in D i f s  (xl00 %) of transactions in D contain X and Y. For details of association rules, see [9] .

These two measures can be defined for our linguistic rule Rk in ( I )  using the given training data (xp. y,) , p =  1,2 ,..., m where x p  = ( x P l  ,..., x p n ) .  The confidence of the linguistic rule Rk can be defined as follows [IO]:  m c ( R k  ) =  b'k ( X p  ) . p k  ( Y p )  z b'k ( x p  ) *  (lo)  p=l LI where p ( x p  ) is the compatibility grade of the input vector x p  witb the antecedent part of R k  , and p k ( y p )  is the compatibility grade of the output value y, witb the consequent part of Rk . The denominator of (IO) corresponds to the number of input-output pairs that are compatible with the antecedent part of Rk , The numerator corresponds to the number of input-output pairs that are compatible with both the antecedent and consequent parts of Rk .

The support of Rk can be defined as follows [IO]: k .  (1 1) m s ( R k  ) =  z p k  ( X p  ) ' p k  ( Y p ) p=1  When both the antecedent and consequent parts of the linguistic rule Rk are specified by non-fuzzy concepts, these two definitions in ( I O )  and (11) are exactly the same as those used for association rules in data mining.

Let us illustrate these two measures using the nonlinear function in Fig. 2 (a) in the previous section. From this nonlinear function, we first generated 441 input-output pairs ( x p i ,  x p 2 ,  y,), p = 1, 2, _.., 441 where xp;  = 0.00, 0.05, ..., 1 .OO for i = I ,2  . That is, these training data were generated using a 21x21 grid of the two-dimensional input space [O,l]x[O, I ] .  Then we calculated the confidence c and the support s of each of the possible 62 x 5 linguistic rules using the training data obtained from Fig. 2 (a). For example,  If x l  is small then y is medium smull (c: 0.75, s:  0.1 I),  (12) If X I  is small and x2 is small  then y is medium (c: 0.54,s: 0.01). (13) We can see that the confidence of these intuitively acceptable rules is high. The nonlinear function in Fig. 2 (a) was actually obtained fmm the three linguistic rules in Section 3 using the standard interpolation-based fuzzy reasoning. The confidence c and the support s of those rules are calculated as  y is mal1 (c: 0.82, s: 0.82). (14) If x1 is smll then y is medium (c: 0.1 I ,  s: 0.02), (IS)  If XI is smull and xz is small then y is large (c: 0.00, s: O.OO), (16)  The confidence of the last two rules is very small. This suggests that the standard interpolation-based fuzzy reasoning may lead to counterintuitive results when a rule base consists of both general and specific rules.

When we use our specificity-based fuzzy reasoning method, the nonlinear function in Fig. 2 (b) is obtained fmm the above three linguistic rules. These three rules have high confidence for the nonlinear function in Fig. 2 (b). This suggests that OUT fuzzy reasoning leads to intuitively acceptable results.



V. LINGUISTIC RULE SELECTION  The main issue in linguistic modeling is to exhnct a small number of comprehensible linguistic rules from numerical data.

For classification problems, we have already formulated linguistic rule extraction as a three-objective combinatorial optimization problem [ll]. The objectives were to maximize the classification accuracy, to minimize the number of linguistic rules, and to minimize the rule length. We can formulate a similar three-objective problem for OUT function approximation problem.

As in tbe previous section, it is assumed that m input-output pairs (x,, y p ) ,  p = l ,  2,..., m are given for linguistic rule exhnction. Let Ki and Kg be the number of linguistic values given for the i-tb input variable ( i  = l,2, ..., n) and the output variable, respectively. Linguistic rules are generated by combining n antecedent and single consequent linguistic values as shown in ( I )  in Section I .  Since don't cure is used in addition to the K; linguistic values for each input variable x i , the total number of rules is N = (KI + I)x.. . x ( K ,  + 1)x KO.

Thus the total numher of rule sets is Z N .  Our task is to find a compact rule set S from these rules for linguistically describing the unknown nonlinear function y = f(x) .

The performance of the rule set S is measured by its approximation accuracy, the numher of rules, and the total rule length. Thus a three-objective problem is formulated as  where f l  (S)  is the total squared e m r  by S, f2 (S)  is the number of linguistic d e s  in S, and f3 (S)  is the total rule length of linguistic rules in S. More specifically, fi(S) is written as  Minimize f1 (S), fz (S),and f3 (S) ,  (17)  m  f l  (SI= cmx, ) - y p  t 2  12,  (18) where i ( x , ) is the estimated output by the rule set S for the input vector x p  , When the estimated output j( x p  ) cannot be calculated (i.e., when there are no compatible linguistic rules With the input vector x p  ), a pre-specified penalty value is used as the difference between the estimated output j( x p  ) and the target output y p  . In our computer simulations, the penalty value was specified as l j ( x p ) - y p  ( = I  when j ( x ,  ) could not be calculated. This penalty value is equal to  p 4     the width oftheoutput space [0,1].

When a rule selection method is applied to our three-  objective problem in (17), candidate linguistic rules have to be generated before rule selection. Let Scan&& be a set of candidate rules, 6om which a small number of linguistic rules are to be selected. When the number of input variables is not large, candidate rules can be generated h m  all combinations of antecedent and consequent linguistic values. On the contrary, all combinations cannot be examined in the case of nonlinear functions with many input variables. In this case, only a tractable number of candidate rules have to he generated using some tricks. For example, candidate rules can be specified as only general rules whose length is less than or equal to a pre- specified threshold value. The confidence and the support of linguistic rules can be used for prescreening candidate rules together with the constraint condition on the rule length.

When a set of candidate rules (i.e., Scandidate) is generated, any subset S of Scan&& can be represented by a binary string of the length Ncan&date as  where s k  = I  means that the k-th candidate rule Rk is included in the rule set S, and s = 0 means that R is not included in S ( k = 1,2 ,..., Nc,,*date ). Since each rule set is represented by a binary string, any multi-objective genetic algorithms [11,12] can be used for finding non-dominate rule sets with respect to the three objectives in (1 7).

(19)

VI. GENETICS-BASED MACHWE LEARNING  me performance of the rule selection method strongly depends on the choice of candidate rules. The prescreening of candidate rules can reduce the size of the search space. On the contrary, the search space of our genetics-based machine leaning (GBML) algorithm consists of all combinations o f antecedent and consequent linguistic values.

In our GBML algorithm, each linguistic rule Rk in ( I )  is coded by its n antecedent and single consequent linguistic values as Rk = AklAkZ . .. AknBk.  A rule set S is denoted by a concatenated string where each substring corresponds to a single linguistic rule. Initial rules are generated by randomly specifying their antecedent and consequent linguistic values.

Our GBML algorithm is implemented in the framework of  multi-objective genetic algorithms [11,12]. The number of linguistic rules is adjusted by a crossover operation. In the current version o f  our GBML algorithm, we use a kind o f  one- point crossover in Fig. 3 for adjusting the numher of linguistic rules and mixing up the order of linguistic rules in each string.

Antecedent and consequent linguistic values are replaced with another ones by a mutation operation.



VII. CONCLUDING REMARKS  We discussed linguistic modeling of nonlinear functions using linguistic rules. Due to the page limitation, we only  showed the outline of OUT approach. Simulation results will be reported in the presentation at the conference.

Parent 1  Parent 2  Fig. 3. A kind of one-point crossover with different cutoff points.

