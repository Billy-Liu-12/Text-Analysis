Trends in Quantitative Association Rule Mining Techniques

Abstract?Association rule mining (ARM) techniques are ef- fective in extracting frequent patterns and hidden associations among data items in various databases. These techniques are widely used for learning behavior, predicting events and making decisions at various levels. The conventional ARM techniques are however limited to databases comprising categorical data only whereas the real-world databases mostly in business and scientific domains have attributes containing quantitative data.

Therefore, an improvised methodology called Quantitative As- sociation Rule Mining (QARM) is used that helps discovering hidden associations from the real-world quantitative databases.

In this paper, we present an exhaustive discussion on the trends in QARM research and further make a systematic classification of the available techniques into different categories based on the type of computational methods they adopted. We perform a critical analysis of various methods proposed so far and present a theoretical comparative study among them. We also enumerate some of the issues that needs to be addressed in future research.

Index Terms?Association Rules; Quantitative Association Rules; Clustering; Fuzzy; Evolutionary approach; Information theory.



I. INTRODUCTION  With the passage of time and advances in technology, the nature and volume of data changed remarkably. Due to numerous information sensing and information gathering devices and techniques, the modern databases are no more alike the market-basket databases where classical association rule mining techniques can be applied. Most modern databases (in domains like business, health-care, stock-market, bioinfor- matics etc.) are larger in size, dimensions and contain attributes that are quantitative in nature. Therefore, to handle quanti- tative data and mine meaningful association rules in multi- dimensional quantitative databases better ARM techniques became a necessity. Henceforth, the concept of Quantitative Association Rule Mining was coined. Then onwards a good number of QARM techniques has been proposed in recent decades. These techniques follow different trends w.r.t. time and need, and have their own advantages and limitations when applied in different quantitative databases.

In this paper, we try to articulate various trends followed in QARM research since the inception of the concept in the pioneering work by R. Srikant et al. [1]. We present a com- prehensive study of various QARM approaches and analyze a few techniques from each one of them. To begin with, we  discuss the background of ARM and QARM techniques in the following section.



II. BACKGROUND  An explicit definition of the ARM problem was given by Agrawal et al. [2]. From the perspective of analyzing market- basket data; for a set of items I = {I1, I2, I3, ....., Im} and a database of transactions D = {t1, t2, t3, ...., tn} where each transaction ti ? I ; the ARM problem is to identify all interesting Association Rules (AR) of the form X?Y where X ? I , Y ? I are actually the non-empty frequent- itemsets and X ? Y = ?. All such AR, satisfying either or both the two thresholds of rule interestingness viz. minimum support and minimum confidence; are considered relevant and informative [3]. Support of an association rule is calculated as the percentage of records containing X ? Y to the total number of records in the database. Confidence is the strength of the implication in a rule; it is calculated as the percentage of records that contain Y if they contain X.

QARM is an improvised form of association rule mining applied to databases containing both quantitative and categor- ical attributes. Alike as an AR, a Quantitative Association Rule (QAR) is formally an implication of the form X ? Y. The left side of the implication is called antecedent and the right side is called succedent (also, consequent). Both these cedents (also called attribute sets) may be comprised of a single attribute trivial cedent, or multiple attributes non-trivial cedent. Unlike a conventional AR, in a QAR both quantitative and categorical attributes may participate as any of the cedents and the common measures of rule interestingness i.e. support and confidence can be applied to it. Other measures available for evaluating the quality of a QAR are Lift, Leverage, Conviction, Gain, Certainty-Factor etc. which are widely discussed in [4] and [5]. If both the left and right side of a QAR has trivial cedent, it is called single dimensional QAR else it is multi- dimensional. An example of a multi-dimensional QAR is given below:  Salary [40k ? ? ? 50k]?Married : [Y es] ? NumLoans : [2] (1) In this QAR, Salary and NumLoans are Quantitative at-  tributes whereas Married is a nominal Categorical attribute (with categories Yes & No). It is a positive QAR as the consequent is positively correlated with the antecedent. Sim- ilarly, negative rules represented as X ? ?Y may also be       discovered, that associate the presence of X to the absence of Y in the rule. The antecedent X and consequent Y of a negative QAR may consist of one or more attributes and accordingly may be single or multi-dimensional. Importantly, for a QAR to be negative either antecedent part or consequent part or both of them have to be negated. Following are some examples of negative QARs, with negation  1) within the antecedent : X2 ? ?[q1, q2] ? Y1 ? [r1, r2] ? Y2 ? [s1, s2] .

2) within the consequent : X1 ? [p1, p2] ? Y1 ? [r1, r2] ? X2 ? ?[q1, q2] ? Y2 ? [s1, s2].

3) within both antecedent & consequent : X1 ? ?[p1, p2] ? X2 ? [q1, q2] ? Y2 ? ?[s1, s2].

Here, X1, X2, Y1 and Y2 are quantitative attributes and ?[Lb, Ub] means those intervals other than [Lb, Ub] where Lb & Ub mean the lower and upper bound of an interval [6].

With these concepts to start with we may move on to present the research trends in QARM in the next section.



III. QARM: TRENDS & TECHNIQUES Since inception of the problem, numerous contributions  are made using different approaches to mine QARs. Each approach follows a trend and has several techniques within it.

Each such technique has its own pros and cons when applied in different scenario. To have a quick glimpse of the trends in QARM, we classify these techniques into certain categories  QARM Techniques  Partitioning  Clustering  Fuzzy Info-Theoretic  Statistical  Centroid Based Density Based  Variance  Distribution Analysis  Evolutionary  Mean Median  Standard Deviation  Fig. 1. Classification of QARM techniques  based on the computational techniques (or approaches) they adopted (shown in Fig:1). To have a better comprehension of the same, we review the prominent techniques under each category and discuss their merits and limitations.

A. Partitioning Approach  Srikant and Agrawal in their pioneering work [1] introduce the partitioning approach to convert quantitative attributes into boolean attributes by partitioning large range of quantitative data into disjoint intervals and then map each (attribute,  interval) pair to a boolean attribute interpreting it as a market- basket item. They also identify the min-support and min- confidence problem lying within this approach. The min- support problem says, if the count of intervals for a quantita- tive attribute is high, the support for individual intervals may be low and so a few QARs comprising this attribute may not be detected for lacking minimum support. To overcome this bottleneck, if interval-size is increased to reduce the number of intervals the approach still suffers from information loss in terms of confidence. This information loss multiplies with the increase in interval size because some QARs comprising this attribute may not be detected for lacking minimum confidence.

Moreover, the number of rules generated goes very large and the rule-mining process becomes time consuming as well.

In [7] Chan and Au pointed out another weakness of the partitioning approach that lies in the task of deciding appro- priate thresholds for rule evaluation measures. If thresholds are very large, a user may not discover some useful rules and if thresholds are very small, the user may get confused by many irrelevant rules. They suggested an objective interest- ingness measure, called adjusted difference that requires no user-supplied thresholds. Fukuda et al. [8] use computational geometry that seem to enhance the partitioning approach.

They present optimized interval generation in linear time on sorted data. However, while dealing large databases, sorting of each numeric attribute is a costly affiar and occupy large space in memory. Therefore, they propose the randomized bucketing idea to discover optimized ranges for partitioning quantitative attributes in huge databases. Commonly used partitioning methods either follow equal-width or equal-depth (also equal-frequency) intervals. Li et al. in [9] clarified that the equal-width and equal-depth partitioning methods hardly consider both value similarities and densities simultaneously.

So they present an adaptive partitioning approach that merges smaller intervals to form larger intervals, repeatedly. Their unsupervised partitioning approach initially distributes quanti- tative attribute value in a different interval and merge adjacent similar intervals using a certain criterion considering both value similarities and densities of quantitative attributes.

Recently, Dancheng et al. [10] introduce a concept that performs discretization using self-adaptive approach. This approach generates better and reasonable partitions that gives high confidence ARs thereby guaranteeing relatively high sup- port. To find rules, this technique pre-computes the conditional probability density curves of association between the quantita- tive attributes. Next, it includes some wide ranges as partitions that have values adjacent to the peak of the curve. Such values help finding QARs having high confidence and wider range helps finding QARs having higher support. Finally, these partitions are used for apriori association rule mining. Though self-adaptive based technique helps in discovering stronger QARs thereby enhancing rule support & confidence, however it is limited to reveal single numeral to nominal implications only.

1) Discussion: The techniques using Partitioning approach are prone to suffer from Support-Confidence conflict and many     rules problem because reasonable range or interval detection is a challenge in partitioning. Majority of the research works are inclined towards solving this issue. In addition, the use of user-given thresholds as rule interestingness measure is common throughout most of these techniques that ultimately drives the overall quantity and quality of mined rules. QAR mining using partitioning approach also takes higher execution time and mostly yields single dimensional positive QARs.

B. Clustering Approach  Clustering is an effective alternative to find meaningful quantitative regions for the discovery of association rules in quantitative databases. An efficient hierarchical clustering algorithm is proposed by Chien et al. in [11] relying upon variation of density to generate intervals for mining QARs.

DRMiner [12] is a QARM technique that uses the notion of density to handle quantitative attributes. It fairly finds positive multi-dimensional association rules and because of the density measure it can avoid trivial and redundant rules. DBSMiner [13] aims to scale up well for high dimensional quantitative association rule mining using the notion of density-connected.

The N -dimensional quantitative search space is divided into multiple grids of rectangular units using equal-frequency par- titioning of every attribute such that no such unit apparently overlaps. In the grid, intersection of one interval from each attribute is performed to form cells containing records. A cell is considered dense if quantity of records in it exceeds a user defined threshold. Finally, connected-high-density cells are united to form clusters. Based on dense grid, Junrui et al. [14] proposes another method MQAR (Mining Quantitative Association Rule) that can solve the support-confidence con- flict as well as can help to get rid of the noise and redundant rules. MQAR uses a FP-tree [15] like DGFP-tree that helps to mine association rules in high dimensional databases. The DGFP-tree compress the database effectively and hence there is no need of scanning the database many times. MQAR uses a novel grid and density based clustering to cluster database using dense subspaces in the tree. MQAR is scalable in dealing with high dimensional databases. Miller and Yang [16] identify the flaws of the equal depth partitioning method and present a technique that suggests to discover clusters in the quantitative attributes and use the resultant clusters as itemsets for finding boolean association rules. A further extension of this idea can be found in the work of Tong et al [17] where they improved the partitioning method by taking into account the relations among attributes all together. Initially, they form clusters using quantitative attributes. Next, they map each cluster into the domain of the quantitative attribute. Thus, these projections return overlapped intervals which they consider reasonable and assert to be a good resolution to the min-support and min-confidence issues in partitioning approach.

1) Discussion: The techniques using Clustering approach mostly concentrate on reasonable interval generation using the concept of variation of density or dense regions. They also try to reduce the support-confidence conflict and eliminate useless, redundant rules. The simpler clustering techniques are  straightforward while the complex ones viz. [12], [13] and [14] uses concepts like hyperplanes, dense-grids etc. Not all cluster- ing techniques are fairly scalable for high dimensional cases but most of them yield single as well as multi-dimensional QARs. Use of min-sup, min-conf thresholds is common but some techniques require the users to specify other thresholds.

The rules generated by the techniques from this approach are however only positive.

C. Statistical Approach  Various statistical measures (such as mean, median, variance etc.) are also applied in QARM. Aumann et al. [18] contribute towards QARM research by providing a new statistical theory for defining quantitative association rules. They considered the distribution of the continuous data via standard statistical measures. This technique yields positive multi-dimensional quantitative association rules at the expense of larger database scans and has a feature of generating meaningful sub-rules.

Kang et al. [19] propose another way of mining QAR using statistical measures but with a thin influence of the parti- tioning approach. They adopt a two step process. Firstly it pre-processes all quantitative attributes to convert them into binary attributes and next convert back the binary association rules into QARs. The first step focuses on domain partition of quantitative attributes by selecting the partitions whose collective standard deviations is smaller. Once partitions are ready, binary association rule (BAR) mining is used. Finally, the post-processing step integrates the BARs to reconvert them into corresponding QARs.

1) Discussion: Statistical approach uses various statistical measures to analyze distributions or to determine reasonable intervals for frequent itemset generation. The bipartition tech- niques usually suffer from uneven distributions of values into intervals resulting uninteresting QARs. Hence, measures like standard deviation came into use. However, rules generated by statistical techniques are positive and multi-dimensional but rule-generation is costly due to greater number of database scans.

D. Fuzzy Approach  Sometimes, detected intervals of attributes participating in a QAR may not be precise or meaningful for analysts to unleash non-trivial knowledge with ease. Instead of using intervals, if linguistic terminologies could be used to represent certain associations, frequent patterns etc. then knowledge discovery could be more easier. Some applications may cosider an AR interesting if only it discovers association amid some useful concepts, such as regular customer, low salary and new house [20]. Such concepts may be modelled using fuzzy concept using fuzzy set theory. The rules having these terms are called fuzzy association rules and the approach is con- sidered as Fuzzy QARM approach. Zhang [20] formulates a method to mine rules containing 1) crisp values, 2) intervals and 3) fuzzy terms. It employed equal frequency partition with fuzzy concept to handle quantitative and categorical at- tributes. For discovering frequent item-sets it uses an extended     Apriori algorithm. Gyenesei [21] assigns each quantitative attribute with several fuzzy sets (instead of sharp intervals) that characterize the attribute. Fuzzy support, fuzzy confidence and fuzzy correlation are used as interestingness measures.

Importantly, this method may suffer from anomalies if fuzzy sets are not well chosen. In an another attempt [22] numerical attributes are converted to fuzzy binary attributes and employs efficient thread based mechanism for mining the quantitative rules quickly. Recently, Zheng et al. [23] proposed a generic Optimized Fuzzy Association Rule Mining (OFARM) method which is easy to extend for continuous data. It optimizes the partition points for fuzzy sets, where a multiple objective function is used. A two-level iterative method is used to generate association-rules. In addition to MinSup & MinConf, this method uses one of the newer effective measures for evaluation of association rules, called the Certainty Factor.

1) Discussion: In classical fuzzy techniques, linguitic ter- minologies for defining partitions was the idea but the modern ones, convert the quantitative data into fuzzy sets and partition points are used to divide neighbouring fuzzy sets. One problem with classical fuzzy QARM techniques is that they do not opti- mize the selection of partition points and use Extended Apriori which takes higher exec-time as dimensions increases. But, the modern fuzzy techniques take care of it. The fuzzy QARs using newer techniques are strong, positive and comprise at most two dimensions within antecedents and one dimension in the consequent. However, these techniques may even suffer from the Support-Confidence conflict if the thresholds are not wisely chosen.

E. Evolutionary Approach  The QAR mining problem is also treated with evolutionary algorithmic (EA) approach by different researches in due course. The most popular type of EA is the genetic algorithm (GA) that has found utilization in QAR mining. Recent research on QAR mining witnesses the use of multi-objective evolutionary algorithms too. Alatas? et al. [6] proposes a genetic algorithmic strategy for both positive and negative QAR mining. With the help of 1) adaptive mutation probability, 2) uniform operator and 3) an efficient fitness function; their method is capable to mine QARs without taking any thresholds and without data preparation. QuantMiner [24] is a GA based approach that follows a set of rule templates while mining rules. A template is nothing but a preset format of a QAR.

It may be selected by the user or may be system computed.

QuantMiner finds reasonable intervals in ARs dynamically, by optimizing the support count and rule-confidence.

The QARM research also encompases multi-objective evo- lutionary algorithm. The ARM process can be considered as a multi-objective problem instead of a single objective in which the rule evaluation measures may have different objectives [4]. Kaya et al. [25] proposes two novel methods to optimize QARs. They use three important criteria; support, confidence and amplitude as thresholds. Recently, Martin et al. [26] proposes a new multi-objective evolutionary approach  for mining a smaller set of +ve and -ve QARs with better comprehensibility and lower cost of computation.

1) Discussion: Evolutionary algorithms often perform well in finding approximate solutions to all types of problems using mechanisms inspired by biological evolution. The GA approach has the specialty to mine both positive and negative QAR without discretizing attributes at prior. Hence, it takes lesser database scans and also yields rules with optimized sup- port and confidence. Multi-objective evolutionary techniques are result of recent research that try to reduce the cost of mining and optimize the number of positive and negative QARs generated without compromising rule interestingness.

F. Other Approaches  There are several approaches (other than those which are classified above) that try to solve quantitative association rule mining in their own ways. Cheng et al. in [27] highlight that another combinatorial explosion problem may get triggered by the task of combining the adjacent intervals of a quan- titative attribute to increase support and detect meaningful intervals. To address this combinatorial explosion problem using information-theoretic approach, they introduce the MIC (Mutual Information and Clique) framework to inspect the mutual information (MI) between every attribute pairs and establish a MI Graph representing attributes having strong informative relationship w.r.t. a pre-defined threshold. Thus, each frequent item-set is represented by a Clique present in the MI Graph. In this method, the attribute sets and their corresponding intervals to be combined (or joined) can be reduced effectively. Li et al. [28] extends a grid-based QAR mining method using meta-rules that store data tuples in linked lists where QAR mining is executed. In meta-rule guided association rule mining, some syntactic or semantic constraints are specified in the form of rules.

Nemmiche and Guillaume [29] introduce another different method for mining optimal positive and negative QARs. They state that irrespective of the fact whether an AR is +ve or -ve; the use of support and confidence as rule interestingness mea- sures is not sufficient for optimal QAR generation. Therefore, in their method they used tables to summarize the trend of variable interactions, thereby highlighting the zones that are interesting. Moreover, the method also introduces a new rule semantic of the form influential(s) ? Influenceable(s) and an impact measure Influence that analyses variable behavior and guarantees that rules of higher potential will be discovered discarding the irrelevant ones.

1) Discussion: The above techniques are applied on QAR mining without having much influence from the general ap- proaches. They have their own unique way of dealing with QAR mining problem. Most of these techniques strive to mini- mize the many-rules generation and irrelevant-rules generation problem. The metarule guided technique tries to find multi- dimensional rules and is linearly scalable to database size and dimensions. The next technique deploying impact measure usage has capability to mine both positive and negative QAR     TABLE I SUMMARY OF DIFFERENT QAR MINING APPROACHES  Approach Advantages Disadvantages Rule Dimen- sion  Use Sup. & Conf.

Other Thresh- olds  Discret- ization  No. of Scans  (-)ve Rules  Partitioning [1], [7]?[10]  Easier to understand and implement  Information Loss, many rules, redundant rules, Sup-Conf Conflict  Single ? ? ? Multiple ?  Clustering [12]?[14]  Reasonable Interval Generation (strive to get best clusters as intervals)  Often lacks High Dimensional Scalability, Require Many Thresholds  Multiple ? ? ? Multiple ?  Statistical [18], [19]  No Misleading Rules, Generates Sub Rules  Larger Database Scans, Uneven Distributions appear in Partitions  Multiple ? ? ? Multiple ?  Fuzzy [20], [21], [23]  Interprete intervals as fuzzy terms, Discover rules having crisp values also  Require fuzzy thresholds, Execution time increases in case of higher dimensions  Multiple ? ? ? Multiple ?  Evolutionary [6], [25], [26]  Mine +ve & -ve rules without discretization, Optimize Support and Confidence, Maximise rule comprehensibility  Comparatively difficult to implement, higher computational cost  Multiple ? ? ? Multiple ?  Information- Theoretic [27]  Reduces combinatorial explosion of intervals that appear in most partitioning techniques  Not much effective in smaller databases  Multiple ? ? ? Multiple ?  which are potentially pertinent. However, most of these tech- niques needs min-support and min-confidence thresholds to find relevant rules and hence are prone to Support-Confidence conflict.



IV. SUMMARY  Different QAR mining approaches discussed above is sum- marized in Table I and the proportion of contributions w.r.t the approaches is shown in Fig 2. We can observe from Table I that every QAR mining technique has its pros and cons. Despite several differences in the context of dealing quantitative data, the use of support and confidence as rule- interestingness measures is common throughout most of the approaches. The use of newer rule evaluation measures (as stated in [4] and [5]) are also found in several modern QARM techniques.

Table I also highlights that there are a few approaches dealing with negative association rules and no technique is capable of mining QAR in single database scan. However, techniques from all approaches other than those from partition- ing are capable of mining rules of more than one dimension. In addition, discretization or data preparation is another common step for all techniques except the few using EA. Information loss due to discretization is prominent using partitioning.

26%  21%  11%  9%  15% 18%  Partitioning 26% Clustering 21% Fuzzy 11% Statistical 9% Evolutionary 15% Others 18%  Fig. 2. Proportion of contributions in various QARM approaches.



V. CONCLUSION  QARM techniques are essential for discovering knowledge from the real-world databases that contain high volume of quantitative and categorical data. In recent decades, different     QARM techniques found applications in various domains [30].

Therefore, a large number of research works are contributed towards efficiently solving the problem of QAR mining. In this work, we highlight various trends in QARM research and present a comprehensive study on various approaches with their relative merits and limitations. To conclude it can be stated that from the broad variety of techniques in existence no particular technique seems to be suitable for application in all domains because the appearance, size and nature of data belonging to different domains vary. Moreover, current solutions may be considered inadequate because there are several issues pertaining to the available QARM techniques which we identify and enlist below:  1) Inability to mine both Positive and Negative QARs.

2) Failure to generate efficient multi-dimensional QARs.

3) Dependence on proper selection of thresholds for gen-  erating rules.

4) Redundant, uninteresting and misleading rules genera-  tion.

5) Poor scalability of the mining technique w.r.t database  dimensions and volume.

6) Large database scans to generate frequent itemsets and  mine rules.

7) High computational cost or execution time.

Further works are required to address these issues and thus  bring in novel scopes for future researches in the QARM scenario.

