

Abstract? Information Security field has seen a paradigm  shift from a traditional silo approach to an integrated approach in collection, dissemination and analysis of structured and unstructured information for overall information protection and digital crime investigation goals. Digital crimes have become a big problem due to large number of data access, insufficient threat analysis techniques and growing size of storage capacity for investigating agencies. Since threat detection projects involve processing of large volume of uncertain information and to reduce uncertainties in the detection process, the analyst has to evaluate a large volume of data collected from different sources and network threat related databases. Being a data intensive analysis and detection, for improved analysis and detection, there is a need for these data to be harmonized and integrated along with the visualization technique for displaying large amount of data at once by incorporating information from various sources and variety of threat detection criteria?s (e.g., threat types, attacker behavior and motive, effects of the threat on resources).

Data Fusion and Integrated visualization of data distribution bars and rules, visualization of behavior and comprehensive analysis, maps allow investigating agencies to analyze different rules and data at different level, with any kind of anomaly. The primary aim of this study deals with have a front end or upstream approach towards an effective dynamic data fusion (DF)-based analysis and detection procedures along with visualization technique for network forensic investigation and threat analysis. Thus such procedures would be able to detect different network trends and patterns and integrate various intrusion datasets from different sources. As a practical approach, the model has been implemented in identification, analysis and detection for IP Spoofing as an illustrative example.

The application in this study shows that this approach can increase the efficiency of forensic digital investigation by dynamic data integration and incorporation of existing intrusion detection system based information in the network threat investigation and analysis.

Keywords? Data Fusion, SOM, Network threats, Network Forensics, Cyber Crime, Digital Evidence.



I. INTRODUCTION Cyberspace is termed as a pool of systems that are interconnected at a large scale. Such systems are comparatively large, complex and distinct. These systems are deployed in and specifically designed to meet the needs of the organization. So each organization comprises of its unique process of accessibility and connectivity [2]. The massive use of the  internet is due to its nominal cost and the usage of users without any login details unintentionally leads to cyber-crimes at a higher rate in the IT world. Web services are vulnerable to two types of attacks, i.e. attack during data transmission and attack by an intruder which may take any form that may jeopardize activities at a web server [2][4][14][23]. The commonly occurring attacks in network security are: DoS, Cyber stalking, SYN flooding, Spam, hacking, theft, etc [8].

Intrusion identification, detection capability is an elusive goal [7][14] [15], requires a concerted effort that applies different techniques to deal with it effectively.  Also, the quick analysis and response to detecting intrusion is an essential feature but its performance is affected by the huge amount of data obtained from organizations.

In our research paper we have shown the methodology of data fusion along with visualization techniques to handle multiple sources of data in forensic investigation of intrusion identification and analysis. A Fusion based Digital Investigation tool proposed in our previous work [18][20] based on Joint Director Laboratories (JDL)[6][8][12] has been already developed  and experimented in the crime case studies [21][22]. Our study, we explore the possibility of extending our investigation model to handle voluminous data in intrusion identification, detection and analysis.



II. NETWORK FORENSICS INVESTIGATION AND  ITS CHALLENGES  Network forensics is the science of busting cyber criminals [3].

It makes use of evidences that are proved scientifically correct and then making use of such evidences for analysis, experiments, derivations accusations etc. to support the judiciary councils in the court of Law. The objectives are [2][3][4] [5]:  ?  Descriptive reports of cyber-crimes.

? Correlate, interpret, and predict adversarial  actions and its influence.

? Make use of the existing data to be used by  further criminal bureaus [16].

The ultimate goal  must furnish proofs to provide sufficient evidence to allow the criminal to be legally punished. The process of detecting threats and analyze them is a time- consuming activity because enormous data is generated from different sources and it is important that all data be centralized in order to produce a thick and accurate scenario of the case.

Another major issue in this area is how to rapidly collect and normalize digital evidence [11] from different sources that include firewalls, routers and IDS. Feature selection and ranking plays a major role in network forensics, because the removal of unwanted features can improve the accuracy of identifying the trivial information and henceforth increasing the computational accuracy for detections. In cases where there are no useless features, concentrating on the most significant factors improves the performance of the detection process with respect to the accuracy of detection in various remarkable ways. The major challenges network forensics investigation faces are [7][15][16][19]  ? finding, categorizing and arranging volume of data ? Sustaining data based on discovery.

? Recovering files ? Controlling  on-site investigations ? Hiring expertise  To meet these requirements there requires productive tools and techniques to detect and uphold against crimes. Data Fusion [6][8] as well as Data Visualization [9][10] is a technique that decreases the complexity of data. Moreover, the visualization structure may reveal the data structure, peculiar patterns to investigators [13] [14][15] [23]. These procedures will help is facilitating the forensic investigations.



III. FUSION BASED DIGITAL INVESTIGATION TOOL Forensic investigations are those that deal with scientific tools for investigating crimes. Every forensic department have their own strategies depending upon the density of the case [7][16]. A digital investigation tool motivated by Data fusion model proposed by Joint Director Laboratories (JDL) [6][8][12][17]has been already developed [18][20] by categorizing and merging the digital investigation activities into data fusion techniques.  The above said tool function as a supporting tool to existing computer forensic investigation tools and extend the capabilities for solving various computer frauds and cyber-crime case.



IV. EXPLORING DATA FUSION AND SOM VISUALIZATION FOR NETWORK FORENSIC INVESTIGATION - A CASE STUDY  ANALYSIS The most targeted entities across the globe when it comes to network threats are the financial, government sectors and banking systems. So, banking system is studied as a case study that uses the computing technology to perform the tasks related to the customer and organization. Cheque clearance, Money deposit & withdrawals, loan applications, ID updations are the day to day tasks that are performed in the bank. Since this information is of utmost confidentiality, the data must be centrally located with the provision of the updated secured technologies. In this regard, each bank structures its own system in order to make sure that the transactions are done systematically and also ensures that there exists no such malicious activity that can dissatisfy the customer. Howsoever, some intruders always intrude in trying to change the secured structure of the system. In this work, we explore the possibility of extending our investigation model to handle multiple  sources of data in intrusion identification, detection and analysis with the application of Data Fusion [6][8][12] and Data Visualization [9][10][21][23]. Data fusion is a concept of fusing or merging the data from different sources in order to produce accurate and high quality information [8] [12]. The objective is data cleaning (removing insignificant information), data transformation (where raw data is converted into useful information) and to create data components (where data is broken into smaller components for better analysis) [17].

Along with data fusion since digital crimes is becoming a big problem due to large number of data access and insufficient forensic investigation analysis techniques, SOM based visualization due to its potential of mapping high dimension data into low dimension is used for displaying large amounts of data at once [9][10[13]. Data fusion integrated with visualization of data distribution bars, rules, behavior, comprehensive analysis, maps can allow forensic investigator to analyze different rules and data, with any kind of anomaly in them.

One of the reputed nationalized banking system data from its network management system has been collected for our study.

Since we don?t work on the binary information, we make use of Forensic Toolkit to sketch the seized hard disk drive. From this hard disk, the files are extracted and analyzed for data fusion. As we are dealing with network intrusion identification and analysis, our main focus is to prepare a dataset with attributes that characterize network traffic behavior.   FTK toolkit is used to [1] to collect all the files. The further investigation of network intrusion identification, analysis using Fusion based digital investigation tool is summarized as follows: A. Data Collection & Preprocessing  Data preprocessing is the process of analyzing raw data for data cleaning and reduction so that the output produced is of high quality. Data cleaning requires:  ? The raw data collected from the source ? Knowledge of  o  Important data o Unimportant data.

Here in our study the connection term implies to the data packets that have malicious. Using expert knowledge, some unique features are extracted [4][23] that shows the features differentiate attacks from the normal data packets. Such features are classified into two categories:  ? Those data packets that are related to data portion.

? Those data packets that imply the connection details  which is inherited from header section of the packet.

The other group of feature is further categorized as:  ? Categorization of attributes of the current connection for example duration, type, protocol, flag, etc.

? Categorization of attributes of number of similar connections based on the knowledge gained from history of past connections that can result into an aggregate of the no. of connections from the same host or belonging to the same service at a given time frame or within the frame of predefined number of past connections.

? Categorization of attributes based on the information about the content of connection packets which has a relevance to be treated as intrusion.

Analysis at this level takes into account the generalized categorization of attributes which would be enough to describe network traffic and filters out the required data for further processing.

B. Low-level fusion This process of fusion consists of data reduction and data transformation. The data that passed through the pre- processing are first aligned to a common format. This alignment facilitates the comparison and further processing of multiple data that originate from different sources. The alignment stage of the data originating from different types of network management system sources (servers, routers, firewalls) requires the following information:  ? Raw data ? A common reference format to which the data should  be aligned During the alignment, relevant features are extracted from the raw data to form an abstract description of the raw data. Data originating from different sources are likely to possess different kinds of features. A source that observes network traffic [3][4] in general knows little more about the host than its network address [2][4][5]. If the observed host is the target of an attack, the data originating from this source may include for instance detailed information about the application or process that was targeted by the observed event. The reference format is designed in such a way that it will provide enough room for these different kinds of features to be represented.

Different observations of data by the sources can refer to one and the same event. If multiple data pass through data preprocessing, this results eventually in multiple (aligned) data referring to a single event, thus being a single event. If source address, destination address, and URL address of the two data are the same and the timestamps of two data are close, then it is concluded that two data are linked and further on treated as a single event. After all the data has been collected, cleaned and reduced data is transformed into a structured form (numerals) for forensic investigation Table1.

TABLE I. DATA TRANSFORMATION OPERATIONS  Date Converts into readable format  Time Converted into seconds and initialized with numeric values  Source Ip sips are concatenated and initialized into a numeric values  Destination Ip dips are concatenated and initialized into a numeric values  Attack Category  Characterized by their manifestations, which might or might not include damage and subsequently substituted with numerical values.

Service Names Converted into numeric  C. High-level fusion This level of processing measures the relations between the objects. The objects in previous level are data. The  relationships between the data are called event aggregations.

Because single event may not be significant, but the aggregation of single data may reveal the attack [2][12][17].

The data are aggregated on the basis of three things source, target, and attack category. When there occurs a network intrusion, the lists of attacks occur in a sequence. Intruders come with a set of tools trying to achieve a specific goal [4][9]. The choice of the tools used in this process depends upon the environmental situations of the described system.

Two types of results can be obtained by the detection procedure.

? Data that together make up an attack ? Data that together represent the behavior of a single  attacker The data file obtained after this level of processing is shown in Fig 1.

Fig.1. Data File  D. Decision level fusion In this level processing, the analysis is done by assessing the current situation and identification of threats by using Neural Network Tool Box of MATLAB to implement visualization into forensic digital investigation.  One of the neural network models that is used for modeling and clustering data is the Self Organizing Map (SOM). The data in this concept is based on untrained set. The infrastructure of SOM is described as: Input layer which is completely connected with the output layer unit and each unit in the input layer represents an input signal. The resultant obtained is to cluster or categorize similar patterns. It performs the following steps [9][10][23]:  ? Finding the matched weights: When the units of the input layer compete with the units of the output layer, the units are matched and those weights are considered.

? Weights monitoring: Once these weights are matched, its surrounding units are shifted to the next input layer pattern.

The data file to be processed using this toolbox has to be in correct format. The column headings should be the first line and each data should start at a new line, as shown in Fig 1.

These data are treated as Input pattern in SOM. For each entered data, the dimensions must be separated by spaces. But for the learning purposes the attribute names are converted into numeric values. The learning process is repeated up to default no of iterations until satisfactory (exact) results are obtained. A map is generated after this process in such a way that the original data remains unchanged. The map helps in inspecting possible correlations revealed by comparing the values in the input data. In this case study study since our attempt is to identify, detect and visualize IP spoofing threats the following logic has been implemented.

1. Set sip = Source_IP_Address (p) 2. If sip ? Internal database  Then write ?Intrusion? Else if sip ? External database  Then write ?Intrusion? Else no intrusion  Exit 3. Intrusion detected 4. Write Date of event, Time of event,  Source_IP_Address, Dest_IP_Address  onto the Forensic Log book.

5. End.

Two separate databases are maintained, an internal database that maintains a list of IP addresses that are internal to the banking network, and an External database that maintains all the IP addresses which are granted access to the network resources. The source IP address is compared with the content of the internal database and External database. If the IP address belongs to the internal database, then it is considered as an attempt for intrusion This is because usually an internal IP addresses cannot come to an external port. Similarly, if there is a mismatch in the IP address with any of the external database entries then it is also treated as an intrusion because an unknown IP address has attempted an entry into the network. In either of the cases, once intrusion is suspected appropriate entries are made into the forensic log such as date of event, time of event, source IP address, and destination IP address, which can be further used during evidence report analysis.



V. THE SOM TRAINING ALGORITHM USED FOR THE CASE STUDY ANALYSIS  Step 1: In the input layer, where the network connection is layered, the properties are laid down. This unit will facilitate the SOM initiation to train the units.

Step 2: In-depth explanation of SOM is described Step 3: Initialization of the units in the output layer where every neuron will be assigned by a value randomly.

Step 4: The entire process is controlled by the parameters to signify differences in networks.

Step 5: Each unit is considered as a winning neuron.

Step 6: The uniqueness of the winning neuron along with the existing neurons among the neighborhood is updated.

Step 7 The above last two steps are repeated abundantly (training length) till results are obtained.



V. RESULT ANALYSIS The data file is processed using Neural Network Tool Box of MATLAB. The processing time and number of learning iterations is by default taken by the tool. During operation, the total 22000 data has been divided into testing data and training data. In the learning process, the neurons are moved to characterize the sample data as closely as possible. When a testing sample is tested by SOM, and its winning unit is located, it is symbolized as normal if it matches with the winner and flagged intrusion and if it satisfies the threshold limit. The results of analysis are then brought under discussions to generate results.

Fig .2. Component Map            Fig.3. Sample hit   Fig.4. Neighboring weight distances  In figure 2 the component maps (weight input 4 & 5) the different colors(light yellow, dark yellow, light orange, dark orange) shows the sips of other sources, black color describes the sips of bank. This describes majority of the sips are clustered as yellow and dark yellow marked as intrusion needs further attention as it is done at the same time on the same day which is clear from 2nd  and 3rd  component maps.  Figure 3 shows the no of sample hits based on the algorithm. Figure 4 in the third map where the dark orange portion highlighted in    the yellow region identifies the neighboring weight distance that has to be adjusted in the learning phase. SOM Visualization and training algorithm [9][10][13][23] works better since network threats are evolving day by day and Forensic database often contains voluminous and uncertain crime cases. Therefore, to make the detection observable in future, an integrated approach of data fusion along with neural network training algorithm incorporating visualization technique will work better.



VI. FORENSIC LOGBOOK The forensic Log book which is a record keeping system has been augmented into the architecture is used for analyzing the forensic data. The term forensics refers to the post-mortem analysis of evidence but in the context of network we refer the analysis of evidence as network forensics [3][4][15]. The digital information captured are maintained in the log book with a designed format like date of event and time of the event, Intruder and target IP address, name of event and status of event, source of data request (for authentication). A timestamp is introduced which denotes or implies a network threat.



VII. USER INTERFACE The Investigation tool also provides mechanism for the investigators to analyze. The tool categorizes the user?s activity and the units. The network administrator and network forensic experts can communicate with the forensic log book through user interface.



VIII. FEASIBILITY As the approved and input weights are the two participants in the case study, the problems the courts are having are in dealing with the difference between the literature and legal evidence. For a case to be discussed in the court, we discuss the three requirements like [3][4][5][7][16] (a) Authentication, (b) Results showing the best proofs (c) Exceptions from the proofs. Authentication refers to the truthiness. As per the investigator?s view, they will seek something that they can demonstrate to others long after the event itself is over i.e. the Evidence Log File. The primary goal is to identify the features that will have the capacity to fulfill the needs of the Law enforcement agencies in gathering the data and securing the continuity of computer intrusions in order to present in the court for proving the crime.



IX. CONCLUSION Maintaining profiles, tracking and seizing cyber suspects should be the most important area of research [19]. The anonymous concept in the networking?s have always encouraged criminals to mislead the performance which creates difficulties for the court authorities to prove the identity of the criminal. Network forensics has given opinion of increase of crimes performed by    computer terminals, a device that maintains all the database of the proofs of crimes.

To effectively combat such types of threats, its not just about investigating and coming to conclusions about a crime but what is more important to prosecute and administer justice,  according to the law of the land. Also, the evidence gathering process in a computing environment, by their nature is technical and different to other forms of evidence gathering.

Data fusion along with visualization techniques promises to signify the preventions that can be taken for the future of cyber-crimes.  Future work of our project remains on the design of fusion algorithms and visualization techniques that can handle new kind of network threats so that digital information technology remains as a platform for well beings.

