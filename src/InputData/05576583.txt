Mining Perfectly Sporadic Rules with

AbstractA sporadic rule is an association rule which has low  support but high confidence. It is divided into two types:  perfectly and imperfectly sporadic rules. In this paper, we  describe an efficient algorithm to mine perfectly sporadic rules  by proposing a problem of mining perfectly sporadic rules  with  two thresholds and developing a MCPSI (mining closed perfectly  sporadic itemsets) algorithm to find perfectly sporadic itemsets  with two thresholds.

Unlike the previous approaches, the development of MCPSI  algorithm is based on the pruning of the closed itemset lattice,  therefore efficiency of the algorithm can be improved via  reducing a search space and removing redundant imperfectly  sporadic rules with two thresholds. Experiments comparing  MCPSI to Apriori-Inverse on the same databases also proved this  conclusion.

Keywords: Rare Association Rule; Perfectly Sporadic Rule;  Perfectly Sporadic Rule with Two Thresholds

I.  INTRODUCTION  A sporadic rule is an association rule which has low support  but high confidence (named rare association rule). These rules  rarely occur but they are very valuable in many cases [3-6].

Koh, Rountree, and OKeefe [3-4] have splited sporadic rules  into two types including perfectly sporadic and imperfectly  sporadic.

An association rule BA ?  is called a perfectly sporadic  rule for maxSup and minConf if:  ??

??

?

<???

<?

??

maxSup.)(sup,  maxSup, B) sup(A  inConf,)(conf    xBAx  mBA    An association rule BA ?  is called an imperfectly  sporadic rule for maxSup and minConf if:  ??

??

?

????

<?

??

maxSup.)(sup,  maxSup, B) sup(A  inConf,)(conf    xBAx  mBA  In [3], authors have developed the Apriori-Inverse  algorithm derived from the Apriori algorithm to discover  perfectly sporadic rules. As having reasonable complication  level compared with other frequent itemset finding algorithms,  Apriori and Apriori-Inverse thereafter might not be an efficient  algorithm to mine perfectly sporadic rules. Thus, in this paper  we introduce a more efficient algorithm to mine perfectly  sporadic rules by developing mining sporadic rules as follows:  ??

??

?

<???

<??

??

maxSup.)(sup,  maxSup, B) sup(A minSup    inConf,)(conf    xBAx  mBA    Where minSup, maxSup (minSup < maxSup), minConf are  below minimum support, above minimum support and  minimum confidence respectively. The three thresholds are  user-defined values. In this paper, such rules are called  perfectly sporadic rules with two thresholds.

minSup is needed to be added by reasons that support of  every association rules is always positive and it supports to  develop a new algorithm for finding perfectly sporadic  itemsets.

To minimise itemsets with too low support, Apriori-Inverse  algorithm in [3] only finds perfectly sporadic itemsets whose  supports are not less than minAS (minimum absolute support).

The value of minAS depends on specific databases. By adding  below minimum support minSup, we can conclude that the  mining perfectly sporadic rules can be considered as a specific  case of the above mining of perfectly sporadic rules with two  thresholds when minSup is chosen equal to minAS.

Unlike the approach in [3], the MCPSI algorithm for  finding perfectly sporadic itemsets with two thresholds was  developed under the approach of the CHARM algorithm [8],  which is one of the most effective algorithms for finding  frequent itemsets from transaction databases. The CHARM  algorithm is implemented on the closed itemsets lattice.

CHARM explores both itemset space and tidset space, and uses  depth-first exploration of the Itemset-Tidset tree to find all the  closed frequent itemsets that included maximal closed frequent  itemsets. Like CHARM the MCPSI is also implemented on the  closed itemsets lattice, therefore its search space for perfectly  sporadic itemsets is reduced  and many redundant perfectly  sporadic rules are removed.

Experimental results also show the efficiency of MCPSI  algorithm in term of comparison with Apriori-Inverse on the  same synthetic and real databases. In all experiments, the  978-1-4244-5326-9/10/$26.00 2010 IEEE  running times of the MCPSI algorithm is less than ones of the  Apriori-Inverse algorithm, and the set of closed perfectly  sporadic itemsets with two thresholds is smaller than one of    perfectly sporadic itemsets.

The structure of the paper is as follows: Following the  Introduction Section, Section 2 will discuss some important  properties of perfectly sporadic itemsets with two thresholds.

This will serve as the base to propose an algorithm to find  closed perfectly sporadic itemsets with two thresholds in the  next section. Section 3 will present the algorithm and prove its  soundness and completeness. Section 4 followed will introduce  some experiments to evaluate performances of the proposed  algorithm, and experiments to compare the MCPSI algorithm  with the Apriori-Inverse algorithm. Some conclusions will be  raised in Section 5.



II. PERFECTLY SPORADIC ITEMSET WITH TWO THRESHOLDS  Suppose that D ? (O, I), where I = {i1, i2,..., in} is the  universe of items, and O = {t1, t2,..., tm} is the universe of  transactions, called a transaction database. Let X ? I, sup(X)  be the support of X, that is a number (or percentage) of  transactions in D containing X. An association rule is a  conditional relation among itemsets X  Y, where X ? I, Y ?

I, X? Y = ?. X is referred to as an antecedent of the rule and  Y as a consequent. The confidence of an association rule  conf(X  Y) is a number (or percentage) of transactions in D  containing X, given that they also contain Y [1,2]. Let minSup,  maxSup, minConf be below minimum support, above  minimum support, and minimum confidence respectively, these  values are user-determined with a range in (0, 1].

Definition 1. X is called a perfectly sporadic itemset with  two thresholds if:  minSup ? sup(X) < maxSup,  and  ?x ? X, sup(x) < maxSup  X is called a maximal perfectly sporadic itemset with two  thresholds if it is not a subitemset of any perfectly sporadic  itemset with two thresholds.

The following definitions and Property 1 are developed  directly from the related definitions and properties in [7].

Definition 2. (Data mining context) A data mining context  is a triple D  = (O, INF, R), where O is a set of transactions,  INF is a set of items which are infrequent for maxSup but are  frequent for minSup in I, and R ? OxINF is a binary relation.

Each couple (t,i) ? R  denote the fact that the object t?O is  related to the item i ? INF.

Definition 3. (Galois connection) Let D = (O, INF, R) be    a data mining context. For O ? O and I ? INF, we define:  f:  2O  2INF  f(O) = {i?I | ?t? O, (t,i) ? R}  g:  2INF  2O  g(I) = {t?O | ?i ?I, (t,i)?R}  f(O) is a set of items associated with all transactions of O,  and g(I) is a set of transactions related with all items of I. The  couple of applications (f,g) is a Galois connection between the  power set of O and the power set of INF.

The operator h = fog  in  2INF , and h = gof  in 2O  are Galois  closure operators.

Property 1. (Galois connection and Galois closure  operator) For I, I1, I2 ? INF and O, O1, O2 ? O, we have :  (1) I1 ? I2 ? g(I1) ? g(I2)    (1) O1 ? O2  ?  f(O1) ? f(O2)  (2) I ? h(I)         (2) O ? h(O)  (3) h(h(I)) = h(I)        (3) h(h(O) = h(O)  (4) I1 ?I2 ? h(I1) ? h(I2)     (4) O1 ? O2 ? h(O1)? h(O2)  (5) h(g(I)) = g(I)          (5) h(f(O)) = f(O)  (6) O ? g(I) ? I ? f(O)  Property 1 is similar to the relative properties in [7]. The  proof of this property is quite simple therefore not mentioned  here.

Definition 4. Let X be a perfectly sporadic itemset with  two thresholds, X is called a closed perfectly sporadic itemset  with two thresholds if it is a closed itemset, i.e., h(X) = X,  where h is the Galois connection defined above.

Property 2. Perfectly sporadic itemsets with two thresholds  have the Apriori property, i.e., subset of a perfectly sporadic  itemset with two thresholds is a perfectly sporadic itemset with  two thresholds.

Proof. Asume that X is a perfectly sporadic itemset with  two thresholds and X ? X, we have to prove that X is a  perfectly sporadic itemset with two thresholds.

Since X ? X  => minSup ? sup(X) < sup(X). On the other  hand, for all x ? X => x ? X, so sup(x) < maxSup, and hence  sup(X) ? sup(x) < maxSup. From that point, we have X is a  perfectly sporadic itemset with two thresholds ?

From this property we have: all supersets of X which is not  a perfectly sporadic itemset with two thresholds is not a  perfectly sporadic itemset with two thresholds.

Remark.

- When minSup = O     , where O  is the number of  transactions of D  then mining perfectly sporadic rules with  two thresholds becomes mining perfectly sporadic rules  defined in [3]. When minSup = minAS, where minAS is  determined in the Apriori-Inverse algorithm then mining  perfectly sporadic rules with two thresholds become mining  perfectly sporadic rules specified in the Apriori-Inverse  algorithm.

- According to the Definition 1, a perfectly sporadic itemset  with two thresholds is an infrequent itemset for the above  minimum support maxSup but is a frequent itemset for the  below minimum support minSup. In accordance to the  Definition 4, a closed perfectly sporadic itemset with two  thresholds is a closed frequent itemset for support minSup.

Property 3. The support of a perfectly sporadic itemset  with two thresholds is equal to the support of a smallest closed  itemset containing it, i.e. sup(X) = sup(h(X)).

The proof of Property 3 is similar to the proof of related  property in [7] so it is not mentioned here.

Property 4. If X is a maximal imperfectly sporadic itemset  with two thresholds then X is a closed itemset.

Proof. Assume that X is a maximal perfectly sporadic  itemset with two thresholds. According to the Property 1 - (2),  we have X ? h(X). Based on the Property 3 and X is a  perfectly sporadic itemset with two thresholds so that  minSup  ? sup(h(X)) = sup(X) (i).

On the other hand, for all x ? h(X), sup(x) < maxSup is  obvious because h(X) ? INF and since the definition of INF  (ii).

From (i) and (ii), we have h(X) is a perfectly sporadic  itemset with two thresholds contained X. Since X is a maximal  perfectly sporadic itemset with two thresholds so X = h(X)?

Property 5. There is no difference between the association  rules generated from perfectly sporadic itemsets with two  thresholds and those generated from maximal perfectly  sporadic itemsets with two thresholds.

Proof. We only need to prove that each perfectly sporadic  rule with two thresholds can always be generated from a  maximal perfectly sporadic itemset with two thresholds.

Let A  B be such rule, then A?B is a perfectly sporadic  itemset with two thresholds and A  B is an association rule    for the minimum support minSup and the minimum confidence  minConf. According to [7], A  B is generated from a  maximal frequent itemset for minSup.

Without losing generality, we can assume that A ? B is a  maximal frequent itemset for minSup, and we will prove that  A?B is a maximal perfectly sporadic itemset with two  thresholds.

If it is not the case then ?C ? A?B, C is a maximal  perfectly sporadic itemset with two thresholds, hence it implies  that minSup ? sup(C) < sup(A?B) < maxSup and C is a  maximal frequent itemset for minSup containing A?B. This  contradicts the above assumption about A?B ?

These properties above are the basis for developing an  algorithm in the section below.



III. THE MCPSI ALGORITHM  A. MCPSI overview  The MCPSI algorithm is developed under the approach of  the CHARM algorithm [8]. It finds perfectly sporadic itemsets  with two thresholds by: Based on the search space including  items that are frequent for below minimum support minSup but  infrequent for above minimum support maxSup, the MCPSI  algorithm finds closed frequent itemsets for minSup using  depth-first exploration of the Itemset-Tidset tree likes the  CHARM algorithm [8]. All itemsets, which are not perfectly  sporadic itemsets with two thresholds or not closed, will be  removed by applying one of  the four Itemset x Tidset pairs as  follows:  Assume that I1 x g(I1) is a node on a branch of a search tree  (g is the Galois connection defined above), and I1 x g(I1) is  combined with  I2 x g(I2) node on another branch of the same  level in the tree, then there are four following situations:  If g(I1) = g(I2) then g(I1 ? I2) = g(I1) ? g(I2). This property  implies that we can replace every occurrence of I1 by I1 ? I2  and g(I1) is replaced by g(I1 ? I2). I2 will be removed from  father consideration.

If g(I1) ? g(I2) then g(I1 ? I2) = g(I1)?g(I2) = g(I1) ? g(I2).

Thus, we can replace every occurrence of I1 by I1 ? I2, but  since g(I1) ? g(I2) we can not remove I2.

If g(I1) ? g(I2) then g(I1 ? I2) = g(I1)?g(I2) = g(I2) ? g(I1).

Thus, we can replace every occurrence of I2 by  I1 ? I2, and  I1  will be kept.

If g(I1) ? g(I2) then g(I1 ? I2) = g(I1)?g(I2) ? g(I2) ? g(I1).

In this case, no itemset can be eliminated; both I1 and I2 lead to  different closed itemsets.

In short, MCPSI algorithm can be briefly described as  follows:  It is started by creating a set of items and a set of  tidsets of data mining context D . These items are  infrequent for maxSup but frequent for minSup.

MCPSI-EXTEND function returns the set of closed  perfectly sporadic itemsets with two thresholds.

CHARM-PROPERTY function tests the support of  itemsets for minSup and check whether itemset-tidset  pairs sastify the four properties of the itemset-tidset  above.

B. MCPSI algorithm  MCPSI ALGORITHM(D ? I x O, minSup, maxSup):  1. Nodes = {Ij x g(Ij) : Ij ?I  ??g(Ij)?< maxSup ??g(Ij)??

minSup}  2. MCPSI-EXTEND(Nodes, C)    MCPSI-EXTEND(Nodes, C):  3. for each Xi x g(Xi) in Nodes  4.    NewN = ? and X = Xi  5.    for each Xj x g(Xj) in Nodes, with k(j) > k(i) //k is a  function for sorting items in Nodes  6.         X = X ? Xj and Y = g(Xi) ? g(Xj)  7.         CHARM-PROPERTY(Nodes, NewN)  8.    if  NewN ? ?  then MCPSI-EXTEND(NewN)  9.    C = C ? X  // if X is not subsumed    CHARM-PROPERTY was developed as in [8].

Proposition 1. MCPSI algorithm is sound.

Proof. We need to prove that every itemsets found out by  the MCPSI algorithm is closed perfectly sporadic itemsets with  two thresholds. In fact the MCPSI comprises two stages:  In the first stage (line 1), the search space to mine closed  frequent itemsets with two thresholds are created. All the items  in the search space are ordered.

In the second stage (line 2), MCPSI-EXTEND(Nodes,C)  function is called. This function will find closed frequent  itemsets for minSup but infrequent for maxSup in Nodes by  applying the approach of the CHARM-EXTEND function in  [8]. CHARM-PROPERTY function tests the support of    itemsets for minSup and check whether itemset-tidset pairs  sastify the four properties of the itemset-tidset above. Thus  MCPSI-EXTEND returns the set of itemsets called C  containing closed itemsets whose support is equal to or greater  than minSup and smaller than maxSup. Hence these itemsets  are closed perfectly sporadic itemsets with two thresholds  according to the Definition 1 ?

Proposition 2. MCPSI algorithm is complete.

Proof. We need to show that every perfectly sporadic rule  with two thresholds is generated from a sporadic itemset found  by this algorithm.

Obviously, according to the Property 5, a perfectly sporadic  rule with two thresholds is generated from a maximal perfectly  sporadic itemset with two thresholds and according to the  Property 4, this itemset is a maximal closed perfectly sporadic  itemset with two thresholds. The MCPSI algorithm finds such  itemsets ?



IV. EXPERIMENTAL RESULS  In order to evaluate the performance of the MCPSI  algorithm, we compared the performance of MCPSI algorithm  with that of Apriori-Inverse algorithm in [3] for finding out  perfectly sporadic itemsets with two thresholds from several  synthetic and real databases. Real databases are available from  [10]. All experiments were performed on a Lenovo-IBM  Codual 2.0ghz with 2GB of memory, running Windows Vista.

MCPSI and Apriori-Inverse were coded in C++.

A. Experiment on synthetic database  The purpose of this experiment is to evaluate the  performance of the MCPSI algorithm over a large range of data  characteristics. We generated synthetic databases based on the  principle proposed by Agrawal R., and Srikant R. [1,2].

The synthetic databases simulate transactions in the  retailing environment with some defined parameters. To  generate the synthetic databases, we takes the following  parameters: |D| is the number of transactions, |T| is the average  size of the transactions, |L| is the number of frequent itemset,  and |I| is the number of items. The first step, the size of the next  transaction is picked from a Poisson distribution with the mean  set to the average size of the transactions. Then we fill the  transactions with items. Each transaction is assigned a series of  potentially frequent itemsets. The complete detail can be found  in [1,2]. Table I shows the characteristics of the synthetic    databases.

TABLE I.  THE CHARACTERISTICS OF THE SYNTHETIC  DATABASES  No Database  # of  Items  (I)  # of  Transactions  (D)  The average  size of the  transaction (T)  1 T5I1000D10K 1 000 10 000 5  2 T10I1000D10K 1 000 10 000 10  3 T15I1000D10K 1 000 10 000 15  4 T20I1000D10K 1 000 10 000 20  5 T25I1000D10K 1 000 10 000 25  6 T30I1000D10K 1 000 10 000 30  To compare the performance of MCPSI algorithm with that  of Apriori-Inverse algorithm, we produce  two programs to  simulate these algorithms. Table II shows the performance of  the MCPSI algorithm for finding closed perfectly sporadic  itemsets with two thresholds, and the performance of the  Apriori-Inverse algorithm for finding perfectly sporadic  itemsets in the same synthetic databases with minSup and  maxSup are appropriately chosen, which minSup = minAS. As  we know, when minSup = minAS the mining perfectly  sporadic itemsets with two thresholds will become the mining  perfectly sporadic itemsets according to the Apriori-Inverse  approach.

TABLE II.  PERFORMANCE OF THE MCPSI AND APRIORI-INVERSE ALGORITHM ON THE  SYNTHETIC DATABASES  No Database minSup maxSup  Apriori-Inverse Algorithm MCPSI Algorithm  # of perfectly sporadic Time (sec)  # of closed perfectly  sporadic Time (sec)  1 T5I1000D10K 0.0005 0.01 3588 67.695 1767 62.015  2 T10I1000D10K 0.0005 0.01 1696 38.691 1272 37.928  3 T15I1000D10K 0.0005 0.01 955 23.917 846 22.681    4 T20I1000D10K 0.0005 0.01 610 15.614 576 14.890  5 T25I1000D10K 0.0005 0.01 416 10.463 397 9.688  6 T30I1000D10K 0.0005 0.01 347 8.048 334 7.627  TABLE III.  PERFORMANCE OF THE MCPSI AND APRIORI-INVERSE ALGORITHM ON THE  T5I1000D10K DATABASE  minSup maxSup  Apriori-Inverse Algorithm MCPSI Algorithm  # of perfectly sporadic Time (sec) # of closed perfectly sporadic Time (sec)  0.0005 0.01 3588 67.695 1767 62.015  0.001 0.01 757 50.388 714 47.899  0.005 0.01 224 6.865 224 6.585  0.001 0.1 1702 78.553 1438 75.256  0.005 0.1 374 20.492 374 19.787  0.01 0.1 152 4.435 152 4.321  TABLE IV.  PERFORMANCE OF THE MCPSI AND APRIORI-INVERSE ALGORITHM ON THE  REAL DATABASES  Database  # of  Items  (I)  # of  Transactions  (D)  minSup maxSup  Apriori-Inverse Algorithm MCPSI Algorithm  # of perfectly  sporadic  Time  (sec)  # of closed  perfectly sporadic  Time  (sec)  Soybean 76 47 0.1 0.5 4275 2.246 154 0.312  Zoo 43 101 0.1 0.5 203 0.187 56 0.094  Bridge 220 108 0.1 0.5 63 0.074 42 0.104  Teaching AE 104 151 0.1 0.5 13 0.031 12 0.015  Flag 310 194 0.1 0.5 235 0.515 210 0.443  Mushroom 118 8124 0.1 0.5 1273 43.028 387 34.336  Experimental results show that the MCPSI algorithm is  more effective than Apriori-Inverse algorithm not only in terms  of running time but also in terms of the number of closed    perfectly sporadic itemsets with two thresholds found. For  visualizing correlations between the closed perfectly sporadic  itemsets with two thresholds and perfectly sporadic itemsets  found in the synthetic databases, the Fig. 1 is presented in  following graphs:           T5I1000D10K T10I1000D10K T15I1000D10K T20I1000D10K T25I1000D10K T30I1000D10K  # of perfectly sporadic # of closed perfectly sporadic    Figure 1. Number of closed perfectly sporadic itemsets with two  thresholds and perfectly sporadic itemsets found on the synthetic databases  For the T5I1000D10K database, Table III shows the  performance of the MCPSI algorithm for finding closed  perfectly sporadic itemsets with two thresholds, and the  performance of the Apriori-Inverse algorithm for finding  perfectly sporadic itemsets with appropriate minSup and  maxSup.

When we have done two algorithms many time with  different minSup and maxSup values on the T5I1000D10K  database appeared cases, in which the number of perfectly  sporadic itemsets are equal to the number of closed perfectly  sporadic itemsets (when minSup = 0.005, maxSup = 0.01;  minSup = 0.005, maxSup = 0.1; minSup = 0.01, maxSup  0.1),  but  the running time of MCPSI  algorithm is less than the  running time of Apriori-Inverse algorithm.

B. Experiment on real database  We chose six real databases from the UCI Machine  Learning Repository [10] and converted them to transaction  databases. Table IV  shows the characteristics of the databases,  and the result of the MCPSI and Apriori-Inverse algorithms.

The experimental results show that MCPSI is better than  Apriori-Inverse not only on the synthetic databases but also on  the real databases.



V. CONCLUTIONS    The paper has proposed a more effective algorithm  (MCPSI) to find perfectly sporadic itemsets for perfectly  sporadic rules by proposing  problem for mining perfectly  sporadic rules with two thresholds where the finding of  perfectly sporadic rules in [3] becomes a special case of this  problem.

MCPSI algorithm was developed from CHARM algorithm  [8]. The soundness and completeness of MCPSI has been  proved in the paper. In other says, MCPSI was developed  based on Galois connection of the closed itemsets therefore  narrowing down the search space of perfectly sporadic rules  with two thresholds and removing redundant perfectly sporadic  rules with two thresholds. This conclusion has been supported  by experiments of MCPSI and Apriori-Inverse algorithms on  the same transaction databases. MCPSI algorithm has shorter  running time and find less perfectly sporadic rules with two  thresholds compared to Apriori-Inverse algorithm, meaning  that MCPSI algorithm is more effective and remove more  redundant perfectly sporadic rules with two thresholds.

The complete set of rare association rules is often huge.

Hence, a question for our future research is that we need to find  ways to generate useful perfectly sporadic rules with two  thresholds from closed perfectly sporadic itemsets with two  thresholds.

