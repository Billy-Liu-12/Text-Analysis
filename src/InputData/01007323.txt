A Fuzzy AprioriTid Mining Algorithm with  Reduced Computational Time

Abstract Most of wnventional data mining algorithms identify the  relation among transactions with b i n q  values. ltansactions with quantitative values are, however, commonly seen in mal world applicaiions. In the past, we proposed a fuzzy mining algorithm based on the ApMn approach to explore interesting %owledge from the transactions with quantitative values This paper pmposes another new fumy mining algorithm based on the Aprioni appmach to rmd fuzzy associatiou rules fnnn given quantitative transactions Each item uses only the linguistic term with the maximum cardinality in later mining processes, thus making the number of fuzzy regions to be processed the same as that of the original items. The algorithm therefore focuses on the most important linguistic terms fur reduced time complexity.



I. INTRODUCnON  In data mining researches, inducing association rules from transaction data is the most commonly seen [5][12]. Most of the previous research works can, however, only handle transaction data with attributes of binary values. In  real-world applications, transaction data are usually composed o f ' quantitative values. Designing a sophisticated data-mining algorithm to deal with different types of data tums a challenge in this research topic.

Fuzzy set theory [14] is being wed more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning [ l l ] .  Several fuzzy learning algorithms for inducing rules from given sets of data have been designed and used to good effect with specific domains.

In [9], we proposed a mining approach that integrated fuzzy-set concepts with the Apriori mining algorithm [4] to find interesting itemsets and fuzzy association rules in transaction data with auantitative values. This mper ProDoses  the data in a supermarket of a department store show the feasibility of the proposed mining algorithm.

11. NOTAnON  In this paper, the fuzzy concepts are used in the AprioriTid data-mining algorithm to discover useful association rules from quantitative values. Notation used in this paper is first stated as follows.

n: the total number of transaction data; m: the total number ofanributes; D(') : the i-th transaction dahrm, 1 s is n; A : the j-th attribute, 1 5 j s m; 1 ~ ~ 1 :  thenumberoffuayregionsforAj;  R  v y ) :  the quantitative value o fAj  f o r D ( i ) ;  fj): thefuzzy set convertedfrom v f ) ; f $ )  : the membership value of vy) in Region R countg : the summation of f$)  for i= l  to n; c o u n t y  : the maximum count value among count ,k  values, k=1 to ( ~ ~ 1 ;  , RY : the- region of Ai  with c o u n t y a : the predefined minimum support level; A : the predefined minimum confidence value; C,: the set of candidate itemsets with r attributes (items); C?, : the temporary set for recording the jiuq values of  L ,  : the set of large itemsets with r attributes (items).

: the k-thfuzzy region ofA j ,  1 s k s I A  1;  r-items in each data;  111. THE PROPOSED FUZZY DATA-MINING ALGORITHM . .  . .

another new fuzzy m i & z  algorithm based on the AprioriTid approach [41 to find fuzzy assc&tion rules from given quantitative transactions. It i s  capable of transforming quantitative vaIues in transactions into linguistic t e n s ,  then filtering them, and finding association rules. Each item uses only the linguistic term with the maximum cardinality in later  processes, thus m.&j,,g the number of fuzzy re@ons to he proca& the Same as that of the items, The algorithm therefore focuses on the most important linguistic terms for reduced time complexity. Experimental results from  The proposed fuzzy mining algorithm first transforms each quantitative value into a set with hnguistic terms using membership functions. The algorithm then calculates the  cardinality of each linguistic ten on all the transaction data using the temporary set F, . Each attribute uses only the linguistic term with the maximum cardinality in later mining processes, thus keeping the number of items the same as that of the original attributes. The mining process based on fuzzy Counts i s  then Performed to find fuzzy association rules. The  0-7803-7293-x101/$17.00 B 2001 IEFE 360 ZOO1 IEEE International Fuzzy Systems Conference    detail of the proposed mining algorithm is described as follows.

The Algorithm: INPUT: A body of n transaction data, each with m attribute  values, a set of membership functions, a predefined minimum support value a , and a predefined confidencevalue E. .

OUTPUT: Aset of fuzzy associate rules.

STEP 1: Transform the quantitative value v f )  of each  transaction datumD('), i=l to n, for each attribute AI, j=1 to m, into a fuzzy set f !) represented as:  using the given membership functions, where R1 is the k-th fuzzy region of attribute A,, fji) is 4 ) ' s fuzzy membership value in region R p  , and I (=/A~/) is the number of fuzzy regions for A,.

including all the pairs STEP 2: Build a temporary set ( R j k ,  f j ) )  of each data, where l s i s n , 1 L j s m, 1 d k s / A j / ,  and fji) L 0.

STEP 3: For each region RA stored in Cl, c a l c u l ~  its scalar cardinality for all the transactions from C, :  STEP 4: Find c o u n F  = MkY(Eountj,), k d  for j=  1 to m, where  I A ~ ~  the number of fuzzy regions forAj .  Let R j  he the region with counl;.w for attribute Ai . R,- will he used to represent this attribute in later mining processing.

STEP 5:  Check whether the county  of each $", j=l to m, is larger than or equal to the predefined minimum support valuen. If R,"" is equal to or greater than the minimum support value, put it in the set of large 1-itemsets (LI). That is,  L I =  k k o u n l ; n ~ + a , ~ s j s m } .

STEP 6: Set r=l, where r is used to represent the number of items kept in the current large itemsets.

STEP 7: Generate the candidate set C,,, from L,. Restated, the algorithm joins L, and L, under the condition that r-1 items in the two itemsets are the same and the other one is different. Store in C,,, the itemsets which have all their sub-r-itemsets in L,.

STEP 8: Build an empty temporary set c,+, .

STEP 9: Do the following substeps for each newly formed  (r+l)-itemset s with items (s1, s2, ..., s,+,) in G + 1 :  (a) For each transaction datum di), calculate  its fuzzy value on s as:  f;') = f$)Af / : )A ... ,if,(') ,.I using cr , where f: is, the fuzzy membership value of D'" in region si. If the minimum operator is used for the intersection,  then f!) -hfb ft).

(b) Store the pair (s, f!)) of Case i in Fr+,,  where 1 s  i 5 n, fy"' # 0.

(c) set count, = 5 f?) using c,+~.

(d) If count, is larger than or equal to the  predefined minimum support value Cl, put s in L,+l.

STEP 10 IF L,+l is null, then do the next step; otherwise, set r=r+l and repeat STEPS 7 to 10.

STEP 11: Construct the association rules for all large q-itemset s with items (s,, s z ,  ..., sq  ), q s 2 , using the following substeps:  .+l  ,-I  '-1  (a) Form all possible association NI= as follows: s,A...As~.~Ask+,A...As~ + st , k = l  toq.

association rules using: @) Calculate the confidence values of all  fy i-1  i(f:)A ... A f:-)L, f:.)lA...Af(i)) $8 i-1  STEP 12: Output the rules with confidence values larger than or equal to the predefined confidence threshold A .

After STEP 12, the rules constructed are output and can act as the meta-knowledge for the given transactions.



IV. ANEXAMPLE  In this section, an example is given to illustrate the proposed data-mining algorithm. This is a simple example to show how the proposed algorithm can he used to generate association rules for course grades according to historical data concerning students' course scores. The data set includes 10 transactions, as shown in Table L  Each case consists of five course scores: Statistics (denoted ST), Database (denoted DB), Object-Oriented Programming (denoted OOP), Data Structure (denoted DS), and Management Information System (denoted MIS). Each course is thought of as an attribute in the mining process.

Assume the fuzzy membership functions for the course scores are as shown in Figure 1.

In this example, each attribute has three fuzzy regions: Low, Middle, and High. Thus, three fuzzy membership values are     produced for each course score according to the predefined membership functions. The transaction data in Table I are first bansformed into fuzzy sets, with the results shown in Table 11.

1 )  86 1 77 ) 86 71 68 2 1  61 ) 79 I 77 I 80 89 I 3 1  84 1 89 1 79 I 89 86 I * I  7? I Sfi I 70 I Ild I 67  6 65 77 I 8 6  61 87 10 yw,  i !

59 63 69 73 78 85 90 100 Smre  Fig. 1. ?he membership function used in this example.

TABLE n ~~~SVISTRANSFORMUFROM7HEDIV*INTABLEI  Ca.Na ST DB OOP us MIS L M H L M H L M H L M H L M H  1 0 0  0.0 0.7 0.0 07 0.0 0 0  0.0 0.7 0.0 0.8 0.0 0.1 0.5 0 0  61 87 71 80 75 86 63 64 84 86 75 65 87 88 79 79 63 85 89 63  2 0.8 0.0 0.0 0.0 0.5 0.1 0.0 0.0 0.9 0.0 0.7 0 0  0.0 0.4 0.2 3 0.0 0.1 0.5 0.0 0.0 0.9 0.0 U.0 0.1 0.0 0.5 0.1 0.0 0.0 0.9 4 0.0 1 0  0.0 0.0 0.0 0.1 0.0 0.5 0.1 0.0 U.1 05 0.7 0.0 0.0  The temporary set C, is built as shown in Table 111. The region with the highest count among the three possible regions for each attribute is chosen for usage in the later mining process. In this example, ?High? is chosen for DB, OOP and MIS, and ?Middle? is chosen for ST and DS. The number of items chosen is thus the same as that of the original attributes, meaning the algorithm will focus on the important items, and the time complexity could thus be  reduced.

Assume in this example, a is set at 2.0. Since the count values of ST.Middle, DB.Middle, OOP.High, DS.Middle, and MIS.High are all larger than 2.0, these items are put in L I .  Cz and Fz is then built in Steps 7 to 10, and two itemsets, (DB.High, DS.Middle) and (OOP.High, DS.Middle), are kept in Lz. No itemsets are put in Ls. Assume the confidence A is set at 0.70. The following three rules are thus output to users:  1. If the ware of Database is high, then the score of Data Structure is middle, with a confidence value of 0.71;  2. If the score of Object-Oriented Programming is high, then the score of Data Structure is middle, with a confidence value of 0.70;  3. If the score of Data Structure is middle, then the score of Object-Oriented Programming is high, with a confidence value of 0.72.

These three rules are thus output as meta-knowledge concerning the given transactions.



V. EWERIMFATS  Apart of the customer purchase data from a supermarket of a department store in Kaohsiung, Taiwan, were used to show the feasibility of the proposed mining algorithm. A total of 1508 transactions were included in the data set. Each transaction recorded the purchasing information of a customer. Execution of the mining algorithm was performed on a Pentium-PC. The relationship between numbers of large itemsets and minimum support values for A =0.3 are shown in Figure 2.

From Figure 2, it is easily seen that the numbers of large itemsets decreased along with an increase in minimum support values. This is quite consistent with our intuition. The curve of the numbers of large 1-itemsets was also smoother     than that of the numbers of large 2-itemsets, meaning that the minimum support value had a larger influence on itemsets with more items.

I / 5 1 0 1 r m 6 a  I  w u m  s u m  valve  Fig. 2. The relationship between numbers of large itemsets and minimum support values.



VI. CONCLUSION AND m R E  WORK  In this paper, we have proposed a fuzzy data-mining algorithm based on the AprioriTid approach to process transaction data with quantitative values and discover fuzzy association rules among them. Each item uses only the linguistic term with the maximum cardinality in the mining processes, thus making the number of fuzzy regions to be processed the same as that of the original items. The algorithm therefore focuses on the most important linguistic terms for reduced time complexity. The rules mined out exhibit quantitative regularity in large databases and can be used to provide some suggestions to appropriate supervisors.

The proposed algorithm can also solve conventional transaction-data problems by using degraded membership functions. Experimental results with the data in a supermarket of a department store show the feasibility of the proposed mining algorithm.

Although the proposed method works well in data mining for quantitative values, it is just a beginning. There is still much work to be done in this field. Our method assumes that the membership functions are known in advance. In [6-81, we also proposed some fuzzy learning methods to automatically derive the membership functions. In the future, we will attempt to dynamically adjust the membership functions in the proposed mining algorithm to avoid the bottleneck of the acquisition of membership functions.

