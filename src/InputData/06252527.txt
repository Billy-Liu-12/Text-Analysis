Self-Reorganizing TSK Fuzzy Inference System with BCM Theory of Meta-Plasticity

Abstract?The usage of online learning technique in neuro- fuzzy system (NFS) to address system variance is more prevalent in recent times. Since a lot of external factors have an effect on time-variant datasets, these datasets tend to experience changes in their pattern. While small changes (?drifts?) can be handled by the traditional self-organizing techniques, major changes (?shifts?) are not handled. Thus, there is a growing need for these systems to be able to self-reorganize their structures to adapt to major changes in data patterns. Hebb?s theory for learning in NFSs, proposed that synaptic strengths could be determined by a simple linear relation of the pre- and post- synaptic signals. However this theory resulted in a unidirectional growth of synaptic strengths and destabilized the model. The Bienenstock-Cooper-Munro (BCM) theory of learning resolves these problems by incorporating synaptic potentiation (associa- tion or Hebbian) and depression (dissociation or anti-Hebbian), which is useful for time-variant data computations. There are two popular methods for fuzzy rule representation, namely: Mamdani and Takagi-Sugeno-Kang (TSK) model. Mamdani model focuses on interpretability and compensates on accuracy. Rules are created by associating an input fuzzy region to an output fuzzy region. However, the TSK model associates an input fuzzy region to a linear function/plane making it more accurate than the Mamdani model. Current TSK models like SAFIS, eTS, and DENFIS attempt to strike a balance between the accuracy and interpretability of the model. However, most of the models utilize offline learning algorithms and require multiple passes of the data samples. Furthermore, the models that use online learning mainly employ Hebb?s theory of incremental learning.

This paper proposes a neuro-fuzzy architecture that uses the BCM theory of online learning with extensive self-reorganizing capabilities. It also uses a first-order TSK model for knowledge representation, which allows for an accurate output calculation.



I. INTRODUCTION  Neuro-fuzzy systems (NFSs) are developed to imitate the function of the neurons of the human brain. It makes use of fuzzy logic to represent inexact and subjective information.

The use of these NFSs has significantly increased over the recent years, especially for online data.

Online learning was implemented in networks that had the ability to self-organize its structure to arrive at a reasonable representation. However, self-organizing techniques are not very effective for time-variant systems, as the pattern of the dataset can change with time. Thus, it is important for networks to be able to re-organize its knowledge in real- time environments, which allows the network to adapt its own  structure to the changing patterns of input datasets.

In order to learn the fuzzy rules for these time-variant  datasets, there are two classical approaches that are used. The first one was introduced in 1949 by Hebb [1], who proposed that the synaptic strength could be determined by a simple linear function between the pre-synaptic and post-synaptic sig- nals. However there were many problems with this theory [2].

The most important of them being the loss of information due to the saturation of synapses. BCM theory of learning was later introduced by Bienenstock-Cooper-Munro [3], and provided for both associative and dissociative learning. This made it an attractive model for time-variant online learning systems.

Since its introduction, BCM theory of learning has been shown to effectively use synaptic potentiation (association) and depression (dissociation) in its mathematical framework for learning [4].

A. Online Learning with Self-Reorganization  Online reasoning and learning are increasingly being used in NFS today. Online learning in NFSs is studied in two forms - time variant and time invariant. These two differ in the characterization of their underlying system dynamics and the duration of the temporal space involved, and accordingly different strategies for each case face different knowledge acquisition objectives [5].

Time-variant systems can acquire knowledge by self- reorganizing its structure. The changes in data patterns with time in time-variant systems can be classified into two major categories - drifts and shifts. Drifts are small changes in the data set, although the same pattern is retained. Shifting, on the other hand, refers to a change in the pattern of the data set.

To handle complex time-variant data with significant shifting properties, the system needs to continuously self- reorganize itself to adapt to the changing patterns of the data streams [4]. Therefore, it is essential that the learning system is able to incrementally process such data streams. In other words, an online learning system requires a learning algorithm that only need to use the data samples once [4].

Some dynamic NFSs are not fully online. DENFIS [6] normalizes data before learning and assumes that the lower bound and upper bound of the data set are known [7]. One of the recent NFSs that actually uses online reasoning techniques  U.S. Government work not protected by U.S. copyright  WCCI 2012 IEEE World Congress on Computational Intelligence June, 10-15, 2012 - Brisbane, Australia IJCNN    Fig. 1. Sliding threshold using BCM learning (adapted from [4])  is eTS [8], which recursively updates its structure by creating new rules when the existing rule-base is not representative enough. On the other hand, SeroFAM [4] starts with dormant nodes and links. With exposure to more data, the network organizes and re-organizes its structure by creating new nodes and rule links.

B. Synaptic Plasticity  1) Hebbian Learning: In 1949, Hebb deduced that mem- ories are formed by synaptic mechanisms that strengthened connections when co-incident pre-synaptic and post-synaptic activities occur [1]. This theory was later supported by various neurobiological evidences of long-term synaptic potentiation (LTP) [9]. By Hebb?s theory, repeated activity will increase the synaptic strengths ms. This can be modeled by (1).

?ms(t) ? y(t) ? xs(t) (1)  where ms represents the synaptic efficacy of the sth synapse, and xs and y respectively represent the pre-synaptic input to and post-synaptic output activation level of the sth synapse.

Although Hebb?s theory was well received during that period, the major problems of the theory soon became evident.

Some of these problems are described below [2].

? All modifications were positively affecting the synaptic  strengths, which resulted in a unidirectional growth.

? Since the synaptic weights were perpetually growing, the  synaptic weights would reach saturation limits making the model unstable.

This monotonic behavior makes Hebbian plasticity less useful in computational learning.

2) BCM Theory of Meta-Plasticity: In order to correct the problems that were present in Hebbian?s Theory of compu- tational learning, other theories were suggested. One of the significant theories was BCM by Bienstock-Cooper-Munro [3]. In BCM theory, a sliding threshold was conceptualized to prove the synaptic stability. The sliding threshold ?m is illustrated in Figure 1.

Based on the BCM theory of learning, repeated activity between neurons will increase the strength of distinct synaptic  areas. However these strengths had to be regulated in an asso- ciative and dissociative manner. This would help in developing selectivity and reducing the loss of information. BCM offered a new concept of a sliding threshold mechanism (which is an improvised version of the fixed threshold theory of Cooper- Lieberman-Oja theory [10]), which allowed the maintenance of stability of the excitation levels of the synapses.

BCM is based on the following three assumptions [11]: ? The change in synaptic weights is directly proportional  to the pre-synaptic activity.

? The change in synaptic weights is also directly pro-  portional to the non-monotonic function ? of the post- synaptic activity y. For a relatively low y, the synaptic weight ms decreases and for larger y, it increases. The cross-over point (? = 0), is called the sliding threshold ?m.

? The sliding modification threshold ?m is itself a non- linear function of the time-weighted history of the post- synaptic activity y.

Thus, it can be concluded that the synaptic weight ms at time t can be defined by (2).

ms(t) = ? ? ?(y(t), ?m(t)) ? xs(t)? ? ?ms(t? 1) (2)  where ? represents a constant learning rate, and ? represents a time decay constant. The non-linear activation function ? can be defined in (3).

?(y(t), ?m(t)) = y(t)(y(t)? ?m(t)) (3)

II. SELF-REORGANIZING TSK ARCHITECTURE  The proposed network architecture is an online learning NFS with 6 major neural layers (see Figure 2), namely: Input layer, Input Fuzzy Layer, Case Layer, Normalization Layer, Consequence Layer and Output Layer. The structure of the network is similar to ANFIS [12]. The network re- ceives inputs and outputs in the form of vectors I(t) = [x1, . . . , xi, . . . , xN1 ] and O(t) = [y1, . . . , ym, . . . , yN2 ]. The flow of data through the six layers is illustrated in Figure 2.

The network primarily operates in two modes: forward reasoning (forward propagation) and learning (backward prop- agation). For simplicity, the network is discussed for N2 = 1.

SeroTSK performs its reasoning and learning processes in an interleaved manner wherein the calculation of outputs is based on the rules that have been learnt thus far. Being an online learning and reasoning system, the model initially computes the output at the N1 + 1th time frame based on the first N1 input records. When the actual value at time N1 + 1 is known, SeroTSK performs its learning process and shifts its input window to the next N1 records beginning at time frame 2. This process is continued until all the input records are covered.

A. Forward Propagation  The mathematical descriptions of each layer during the forward reasoning process are described in detail below.

L2(1)(1) L2 (1)  (j) L2 (1)  (p1) L2 (i)  (1) L2 (i)  (j) L2 (i)  (pi) L2(N1)(1)  L3(1) L3(k) L3(K)  L1(1) L1(i) L1(N1)  L2(N1)(pN1)  L4(1) L4(k) L4(K)  L5(1) L5(k) L5(K)  L6(N2)  Layer 1 Input Layer  Layer 2 Input Fuzzy Layer  Layer 3 Case Layer  Layer 4 Normalized  Layer  Layer 5 Consequence  Layer  Layer 6 Output Layer  L6(1)  FO R  W A  R D  P R  O P  A G  A TI  O N  ( SE  C TI  O N  II -A  ) O u  tp u  t C  al cu  la ti  o n  C o  n se  q u  en ce   P  ar am  et er  s D  et er  m in  at io  n  N o  rm al  iz at  io n  Fu zz  y R  u le   M  an ag  em en  t Fu  zz if  ic at  io n  Action Performed  B A  C K  W A  R D  P R  O P  A G  A TI  O N   (S  EC TI  O N  II -B  )  Layers  Fig. 2. SeroTSK Architecture - Forward Propagation (Section II-A) and Backward Propagation (Section II-B)  1) Layer 1 - Input Layer: Each node in this layer L1(i)  is activated when the input signals are received. There are as many nodes in this layer as the input dimension. Each node then sends this input signal to the next layer for further processing. The mathematical output oI(i) of the ith node in this layer is calculated based on (4).

oI(i) = xi (4)  where xi represents the ith element of the input vector I(t), and i = 0, 1, 2, . . . , N1.

2) Layer 2 - Input Fuzzy Layer: Each node in this layer L2  (i) pi represents the pthi membership function of the i  th input node. The output oII(i)pi of the pthi membership function node in this layer is computed using (5) and (6).

oII(i)pi = ? (i) pi (o  I(i)) (5)  ?(i)pi (x) = e  ?(x?vpi )  2?2pi (6)  where oI(i) represents the output of the ith node in layer 1, ? (i) pi (x) represents the Gaussian membership function with vpi  as the centroid, and ?pi represents the standard deviation of the pthi node in layer 2 of the i  th input, and i = 0, 1, 2, . . . , N1.

3) Layer 3 - Case Layer: This layer consists of the fuzzy  rules. Each rule is made up of two parts: the rule premise and the rule link. The rule premise represents the IF statement of the rule. The rule premise is generated by combining unique subspaces of the different inputs. The fuzzy ?min? operator is  used to activate the set of premise nodes, relevant to the given input vector I(t). The output oIIIk of k  th node in this layer is computed using (7).

oIIIk = min i=1 to N1  (o II(i) pi,k  ) (7)  where oII(i)pi,k represents the output of the p th i node in layer  2 that is connected to the kth rule node in layer 3. Each fuzzy rule also has a rule link rk associated with it. This link specifies the degree with which the rule is connected to a node in layer 4.

4) Layer 4 - Normalization Layer: This layer consists of one node per rule link. Each node k in this layer normalizes the output from node k in layer 3 by (8). Normalization of the rule firing strengths allows the fuzzy rules to be more independent of each other. This provides better rule selectivity and therefore a more accurate representation of the output.

oIVk = oIIIk ? rk?K  j=1(o III j ? rj)  (8)  where oIVk represents the output of k th node of layer 4, oIIIj  represents the output of jth rule node (layer 3), rj represents the strength of the synaptic link of the jth rule, and K represents the total number of rules.

5) Layer 5 - Consequence Layer: Each node corresponds to a single rule node. Each node in this layer uses the inputs from the input layer and the output from the normalization    Initialize Network Parameters  Input Fuzzy Clustering  Fuzzy Rule Management  Calculated Output  Forward Reasoning  Input Dataset  Backward Propagation  Update Consequence Parameters  Create and Update Fuzzy Rules  Actual Output  Fig. 3. Processes involved in SeroTSK  layer. The output of kth node in this layer is given in (9).

oVk = o IV k ?  N1? i=0  (ci ? xi) (9)  where ci represents the coefficient (consequence parameter) of the ith input variable and oIVk represents the normalized output from kth node in layer 4. The consequence parameters are trained using the Kalman filter algorithm [13].

6) Layer 6 - Output Layer: This layer receives inputs from the consequence layer and produces the predicted output for the given inputs. The output oV I of the node in this layer is given in (10).

oV I =  K? j=1  oVk (10)  where oVk represents the output of the k th node of the  consequence layer (layer 5).

B. Backward Propagation  During the backward propagation process, the network performs various learning processes as shown in Figure 3.

These processes are discussed in the following sections.

1) Reorganizing of Fuzzy Memberships: Self-reorganizing online clustering involves two major decisions: creation of nodes and merging existing nodes. In order to implement these decisions, most networks use a fixed distance threshold, which helps to manage the cluster creation and merging processes.

However SeroTSK computes a spatio-temporal spread ? of the data space, which was proposed in SeroFAM [4] and is given by (11). Thus by using this method, the decisions of creation  L3(k) L4(k) L5(k) Synapse Link rk  Post-synaptic Signal  Premise/Rule Node (Layer 3)  Normalization Node (Layer 4)  Consequence Node (Layer 5)  Fig. 4. Flow of pre-synaptic and post-synaptic signal between rule layer and consequence layer  and merging of clusters are dynamically adjusted according to the temporal movements.

?(t) = 2?  ? M?(t)  F (t) ? M(t) F (t)   (11)  where M?(t) = ?t i=0 ?  i(xi) 2, M(t) =  ?t i=0 ?  ixi, xi repre- sents the ith element of the input vector I(t), F (t) =  ?t i=0 ?  i, ?i = ?t?i and ? represents the forgetting factor.

The network also uses the stability of a cluster to decide on the update policy of these clusters. The stability is calculated as shown in (12). A higher stability indicates that a cluster is a better representative of the data points around it. Thus more stable clusters are lesser affected by new data points and therefore merge other centroids towards itself.

Sj(t) = t? i=0  (?i ? ?(t)j ? xi) (12)  where ?j(t) represents the soft classification of [ ?z i=1  1+(t?vj)2 1+(t?vi)2 ]  ?1, z represents the number of existing clusters, vi represents the centroid of the ith cluster and xi represents the ith element of the input vector I(t). This process has been explained in more detail in [4].

2) Learning of Fuzzy Rule Base: Once the input member- ship functions have been reorganized, the next stage in the backward propagation process is to update the fuzzy rule base and the rule links based on the actual output for the given inputs. Thus, the rule base is scanned to find the ?winning? rule, i.e. the ideal premise node for the given input. The rule links associated with this rule is then learnt using the BCM theory, wherein rule strengths are regulated (as compared to the Hebbian approach in which it always increases) in an associative and dissociative manner. For the calculation of the rule link potential using the BCM approach, two basic inputs are required, namely: a pre-synaptic and a post-synaptic signal. As shown in the Figure 4, the pre-synaptic signal is obtained from the premise/rule node of the associated rule and the post-synaptic signal is obtained from the Gaussian membership value of the error obtained. The calculation of this error membership is described in Section II-B4. The sliding treshold ?j and the potential for the jth rule link are calculated using (13) and (14) respectively [4].

?j(t) ?  ?t t?=0  ( ?2j (t  ?) ? ?t?t? )  ?t t?=0 (?  t?t?) (13)    Pj(t) =  Homosynaptic? ?? ? ?(?j(t), ?j(t? 1)) ? fj(t)?  Heterosynaptic? ?? ? ? ? Pj(t? 1) (14)  where fj represents the pre-synaptic signal produced by premise node, ?j represents the post-synaptic signal, ? repre- sents the uniform decay factor which is equal to 1 ? e ? 1/G (where G is the half-life) and the homosynaptic function ? is defined by (15).

?(?j(t), ?j(t? 1)) = ?j(t)(?j(t)? ?j(t? 1)) (15)  3) Tuning of consequence layer parameters: The tuning of the consequence parameters is performed in layer 5 and is a primary part of the backward propagation process. Rules selected in Section II-B2 are triggered by invoking the learning processes of its corresponding normalization and consequence nodes. The consequence nodes are acted upon using the Kalman filter algorithm [13], and results in the fine-tuning of the coefficients of the consequent linear function (a line) used to represent the relevant rule.

The Kalman filter algorithm uses two inputs - the degree and the error. The degree represents the output of Layer 4 defined in (8) of the Forward Reasoning Process in Section II-A, and the error is the difference between the actual and the predicted output. The learning constant l (16) for the network has been set at a pre-defined value of 2.0.

The algorithm has three main phases, namely: initialization phase, computation of the S vector (see (17)) and computation of the revised coefficients of the consequent linear function (i.e. line that is used to represent the rule).

During the initialization phase, the weight factor associated with the error is given by (16).

w = (oIV )l ? e (16)  where oIV represents the output as defined in (8) from the normalized node of the corresponding rule, l represents the learning constant (set to 2.0), and e represents the difference between the desired and computed output.

The second process involves the computation of the S matrix, for which the algorithm uses equations (17) and (18).

S = (1000? I(N1+1)M )? T1 (17)  T1 = ( V T ? V  ) ?  ( 1 +  N1? k=1  (xk) 2 +   (oIV )l  ) (18)  where vector V represents [1 x1 x2 . . . xN1 ], x1 . . . xN1 represent the inputs to the network at layer 1 and IN1+1M represents a square identity matrix of dimension N1 + 1.

Once the S matrix is computed, the change in each con- sequence parameter ?fWi where i = 0, 1, 2, . . . , N1 + 1 is computed using (19).

fWi =  N1+1? j=1  (Sij ? Vj) (19)  where Vj represents the jth element of V and Sij represents the element at row i and column j in matrix S.

This allows the coefficients of the consequent linear function associated with each rule to be tuned according to the error that it had generated during the forward reasoning process.

4) Computation of Error Membership: As mentioned in Section I-B2, the BCM learning algorithm requires a pre- synaptic and a post-synaptic signal. The proposed network uses the output of the premise rule layer node in layer 3 (7) as the pre-synaptic signal, while the post-synaptic signal is obtained by computing the membership degree of the error generated by a rule at time t. The error is computed using (20).

ek(t) = o d(t)? oVk (t) (20)  where od(t) represents the desired output, and oVk (t) represents the output of the kth rule node computed during forward propagation (see (9)).

A Gaussian membership function [14] is used to model the error distribution of each rule node. The mean of the error distribution is set at 0 so as to ensure that a zero error results in a post-synaptic signal of 1. The standard deviation ?k(t) represents the standard deviation of the error distribution of the kth rule node is computed using (21).

?k(t) =  ? {?k(t? 1)}2 +  {ek(t)}2 t+ 1  (21)  where ek(t) represents the error at time t obtained from (20).

The post-synaptic signal of kth rule node at time t is  computed using (22).

?k(t) = e  ( ?{ek(t)}   2?{?k(t)}2  ) (22)  where ek(t) represents the error at time t obtained from (20).

The higher the error, the lower is the membership value and  therefore the lower is the post-synaptic signal being propagated backward. Therefore, a higher post-synaptic membership value also suggests that the particular rule has higher accuracy (lower error). The synapse link rk of the corresponding rule is adjusted accordingly using the BCM algorithm. Thus, rules with higher accuracy will have higher weights in computing the network output.

C. System Parameters  SeroTSK uses four parameters that need to be adjusted according to the nature of input dataset. These parameters have been provided so that the user can control the behaviour of the system.

1) Maximum number of clusters (zmax): After the inputs are sent into the first layer of the proposed network, they are fuzzified into appropriate membership values of the member- ship functions (see Section II-A). In order to control and main- tain the number of clusters that are created in the fuzzy layer, SeroTSK provides a parameter called ?maximum clusters?. By changing the value of this parameter, the desired level of the granularity of fuzzy approximation can be obtained. The use of a larger value is commonly applied when a finer degree of granularity of fuzzy approximation is desired.

2) Half Life (G): This parameter defines the half-life decay constant for the input data set, which represents the period after which the rule strength becomes half of its original value.

This process allows the network to focus more on recent rules while computing the output. Thus under stronger time-varying conditions, the half life G should be set to a smaller factor.

Furthermore, the half-life decay constant G can be used to compute the computationally friendly forgetting factor ?. The exponential decay factor for BCM systems is equivalent to the forgetting factor ? in ANFIS [12]. This forgetting factor ? is computed according to (23).

? = e ? ln 2/G = 0.5  1/G (23)  3) Representation Gain (?): With the help of an effective rule management system, which creates updates, merges and deletes rules, SeroTSK remains effective with large datasets.

The strengths of the rules are moderated by using a simple constant called ?representation gain?. New rules are created only if the creation results in an increase in gain of represen- tation, which is greater than the pre-defined ?representation gain? threshold. This is illustrated in (24).

fnew ? fmax > ? (24) where fnew is the representation power after creation of the rule, fmax is the maximum firing strength (maxk?1...K(oIIIk )) and ? is the pre-defined representation gain.

4) Minimum Potential (?): The proposed network performs ?pseudo-pruning? of rules, which is an online state selection (on-off) mechanism to prioritize the rule base. It uses a threshold called the ?minimum potential? (?) as the selection criteria to extract the minimum number of the best rules. The selection takes places by using only the top ? percent of the rules, and deactivating the rest of them. Thus in order to increase the focus on fewer rules, ? should be set lower.

Using this approach, growing rule links are not discarded off from the system immediately. This is done primarily because they are likely to reach up to the selection criteria in the near future. However in the long run, it is not feasible to accumulate these rules, and therefore a rule is permanently deleted if it has not been activated in its last two half-lives.

D. Comparison with SeroFAM SeroFAM [4] is a five layered online NFS with an archi-  tecture similar to the one proposed in this paper. SeroFAM uses the Mamdani model of rule representation and the BCM theory of learning. The major differences between the two architectures is highlighted in the subsections below.

1) Rule Representation: As described earlier, SeroFAM uses the generalized Mamdani method of rule generation. This model represents rules by a creating a mapping between an input fuzzy region and an output fuzzy region, which provides a good degree of interpretability. However SeroTSK uses the Takagi-Sugeno-Kang model, which represents rules using a first degree equation. Thus SeroTSK uses a lesser number of rules to represent a dataset and also provides a higher degree of accuracy. This results in a significant improvement in performance of the model as compared to SeroFAM.

TABLE I EXPERIMENTAL SCHEDULE FOR ONLINE NEURO-FUZZY SYSTEMS  Year Model Type Reference S&P 500 Mackey Glass 2012 SeroTSK TSK this paper Yes Yes 2010 SeroFAM Mamdani [4] Yes Yes 2006 SAFIS TSK [16] Yes Yes 2005 Simpl eTS TSK [17] - Yes 2004 eTS TSK [8] - Yes 2002 DENFIS TSK [6] Yes - 2001 EFuNN Mamdani [18] Yes -  2) Backward Propagation: Another significant difference in the structure of SeroFAM and SeroTSK is in the backward propagation process, which is used for the BCM learning. In SeroFAM, the synaptic strength gets adjusted during the BCM process according to the membership of the actual output at that time instant. However in SeroTSK, the re-calculation of the synaptic strength is based on the error membership degree (as computed in Section II-B4).



III. EXPERIMENTAL ANALYSIS & BENCHMARKING  This section of the report focuses on the experimental analysis that was conducted on the proposed architecture.

Extensive analysis has been conducted on the model, and the results of some of these are highlighted in this section.

In order to perform a performance comparison with other similar models, the comparison metric Non-Dimensional Error Index (NDEI), which is the Root Mean Squared Error (RMSE) divided by the standard deviation of the actual output [15], has been computed as shown in (25).

NDEI =  ?  ??t?1 t?=0{y?(t? + 1)? y(t? + 1)}2  t (25)  The datasets that would be used for the experimental anal- ysis section are Standard & Poor?s 500 (S&P 500) index and the Mackay Glass Chaotic Time Series dataset. The author has also summarized an experiment schedule as shown in Table I, listing various NFS?s that have been analyzed against the same datasets as the ones that will be used in this report.

A. Analysis using S&P 500 Index  The S&P is a free-floating capitalization-weighted index of the prices of 500 large capital common stocks actively traded in the United States of America. The S&P 500 Index Time Series dataset consists of real-world data based on 60 years (between January 3, 1950 and March 12, 2009) of the stock market index data. Thus there are 14,893 records with the daily index prices. The variation in the prices is illustrated using the graph as shown in Figure 5.

For the purpose of this experimental analysis on the S&P 500 dataset, the parameters for SeroTSK have been set at the values as shown in Table II. The analysis on the S&P-500 dataset was performed based on the simulation of the daily forecasts of the index. The proposed NFS attempts to predict the output values based on the input vectors as shown below.

I(t) =  [ y(t? 4) y(t? 3) y(t? 2) y(t? 1) y(t)  ] O(t) =  [ y(t+ 1)  ]              0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000  S& P   D  ai y  In d  ex P  ri ce    Observation Time (t)  Fig. 5. S&P 500 daily index prices from January 3, 1950 to March 12, 2009  TABLE II PARAMETER VALUES - S&P 500 ANALYSIS  Symbol Parameter Value Used G Half-Life 111 ? Minimum Potential 0.8 ? Representation Gain 0.5  zmax Max Number of Clusters 24  The results of the experimental analysis are presented in the Table III. While SeroTSK results in an NDEI of 0.0199, it used an average of 20.54 rules per record. The two peaks in the dataset that can be noticed at a time-period of 12500 and 14500 are predicted with extreme accuracy, providing further proof that this system can easily adapt to shifts in the dataset, which is very common in financial related datasets.

From the results described in Table III, it can be noticed that the proposed architecture outperforms the Mamdani based approaches of SeroFAM [4] and EFuNN [18] by fair margins.

Apart from producing a better NDEI than these two models, SeroTSK uses almost 10 and 100 rules lesser than them respectively. This is mainly because of the use of the Takagi Sugeno Kang model of rule representation, which results in lesser number of rules than the Mamdani model [19].

On the other hand, it performs comparably with DENFIS [6]. Although DENFIS uses a lot lesser rules on average to produce a comparable accuracy rate, it must be noted that DENFIS is not a fully online system. As discussed in Section I-A, an online system is one that yields an output by only one pass of the input data. However DENFIS normalizes the data before its learning process, and therefore requires prior knowledge of the lower and upper bounds of the data set [6]. Considering the growing scale in volume of activity in trading systems (and other real time time variant systems), it would be highly in-efficient to recompute all historical information multiple times. Thus SeroTSK, which is a fully online system with self-reorganizing capabilities, does not require any prior knowledge of the dataset on which it is performing the analysis.

TABLE III ANALYSIS RESULTS - S&P 500  Model Type Reference No of Rules NDEI SeroTSK TSK this paper 20.54 0.0199 SeroFAM Mamdani [4] 29.90 0.0272 DENFIS TSK [6] 6.00 0.0200 EFuNN Mamdani [18] 114.30 0.1544  TABLE IV PARAMETER VALUES - MACKEY GLASS ANALYSIS  Symbol Parameter Value Used G Half-Life 100 ? Minimum Potential 0.8 ? Representation Gain 0.5  zmax Max Number of Clusters 10  B. Analysis using Mackey Glass Dataset  The Mackey-Glass chaotic time series was initially proposed as a physiological control model for the production of white blood cells. This experimental dataset follows the differential delay equation shown in (26).

d[y(t)]  dt =  0.2? y(t? ?) 1 + y(t? ?)  ? (0.1? y(t)) (26)  where t represents the current time and t ? ? represents an ?older? point in time. As ? gets bigger (i.e. the rate of change depends on older values of y(t)), the solution y(t) goes from kind of periodic, to quasi-periodic, to completely chaotic. The pattern followed by the dataset is shown in Figure 6.

0.2  0.4  0.6  0.8   1.2  1.4  0 500 1000 1500 2000 2500 3000 3500  M a  ck e  y G  la ss  C h  a o  ti c  S e  ri e  s V  a lu  e s  Observation Time (t)  Fig. 6. Mackey Glass Chaotic Time Series Dataset  Following the benchmarking tests in [8], [4], the author generated 6000 observations of the Mackey Glass Chaotic dataset by the Runge-Kutta method using a step-size of 0.1 and a delay co-efficient ? = 17. The observations from 201 ? t ? 3200 and 5001 ? t ? 5500 were used for training and testing respectively in the benchmarking process, and it follows a uniform distribution in the range of [0.4,1.4].

For the purpose of this benchmarking process, the parame- ters for SeroTSK have been set to the values that are mentioned in Table IV. The input and output vectors that are used for the system are as follows: I(t) =  [ y(t? 18) y(t? 12) y(t? 6) y(t)  ] O(t) =  [ y(t+ 85)  ] The results of the benchmarking process are summarized in  the Table V. The most noticeable fact is that SeroTSK is able to produce a better degree of accuracy than most alternative online self-reorganizing systems like SeroFAM [4], eTS [8], SAFIS [16] and RAN [6]. Furthermore, the average number of rules used by SeroTSK is much lesser as compared to the other NFSs (almost 50% of the number of rules used by SeroFAM - the next best system). With an average of 7.45 rules that are used for the computation of the outputs for the dataset, SeroTSK produces an NDEI value of 0.325. The number of    TABLE V ANALYSIS RESULTS - MACKEY GLASS DATASET  Model Type Reference No of Rules NDEI SeroTSK TSK this paper 7.452 0.325 SeroFAM Mamdani [4] 13 0.345 eTS TSK [8] 99 0.356 Simpl eTS TSK [17] 21 0.376 SAFIS TSK [16] 21 0.380 RAN Neural Network [6] 113 0.373  rules that are used in the computation of the output for each record is depicted in Figure 7.

0 500 1000 1500 2000 2500 3000  N u  m b  e r  o f  ru le  s u  se d  in S  e ro  TS K    Observation Time (t)  Fig. 7. Number of rules - Mackey Glass Chaotic Dataset

IV. CONCLUSION  Neuro-fuzzy systems that have been developed in the past have mainly employed offline learning techniques. Those that use online learning algorithms techniques tend to self- organize themselves in order to accommodate the small changes (?drifts?) in the patterns of the data. However, this becomes inefficient when a larger change (or a ?shift?) in the pattern takes place.

The report proposed SeroTSK fuzzy network that uses the BCM learning algorithm, which allows for both associative and dissociative learning. This prevents the network from learning in a uni-directional manner, and avoids the saturation of the synaptic weights. The proposed network also has the capability of self-reorganization, which allows it to adapt to even larger variations (?shifts?) in the pattern of the dataset.

The proposed network also uses the Takagi-Sugeno-Kang model [19] for representation of rules in the system. This allows the network to produce accurate outputs as compared to the traditional approach of using the Mamdani model [20].

Apart, the TSK model also allows for a lesser number of rules to be required for the representation of the data.

SeroTSK has been derived from the five-layered SeroFAM [4], which is also an online self-reorganizing NFS. However the architecture of the two models differ significantly, espe- cially in the Backward Propagation process, wherein the re- organization of neurons is performed. Moreover, the use of the TSK method of rule representation makes SeroTSK more accurate than SeroFAM, while maintaining lesser number of rules in the system.

With all of the features mentioned above implemented in the network, the proposed architecture is extremely effective even on time-variant datasets, which generally have larger changes  in their patterns. The results of the experimental analysis on this network have also shown significant improvements in the accuracy of the prediction of time-variant datasets as compared to other existing neuro-fuzzy systems.

