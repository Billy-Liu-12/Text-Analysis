A Classification Algorithm based on an Association Rule of Multiple Frequent Item-sets

Abstract: It is necessary to discrete datasets firstly if you want to data mining an association rule of datasets consisting of many categorical and numeric attributes by a traditional algorithm. However, in view of the versatility, the applications of the traditional algorithm are limited. This paper propose a new algorithm called ARMFI(Association Rule of Multiple Frequent Item-sets) which can data mining an Association Rule from datasets consisting of many categorical and numeric attributes directly and completely, and overcome disadvantage of the traditional algorithm. The result has been proofed that the ARMFI shows better performances than the traditional algorithm 0  Key Words: Data mining, ARMFI, Frequent Item-sets, Frequent Regions, Classification,  1. Introduction  Classification algorithms, as a major technology of data mining be applied in the field of protection have been admitted extensively 1 Especially in the recent years, classification algorithms based on an association rule have been attract increasing attentions.

In their early stages, a classification algorithm do the data mining by creating a classification rule having higher classification precision with the use of a Min- support and Confidence of the association rule, which called CBA classification method 2 However, the CBA classification method face a missing data problem because that the Min-support was used in CBA classification method. If let the Min-support to be very low, the efficiency of the algorithm will be reduced.

For this reason, a classification method called CAEP 3was proposed which establish a single foreign model EP (emerging pattern) for non frequent item- sets to deal with the missing data problem due to the Min-support.

DOl 10.1l09/HIS.2009.271   Meanwhile, another classification method called CMAR 4 based on FP-growth algorithm was also proposed. CMAR can deal with the problem that it can not be solved with a rare item by using Hash algorithm and reduce the occurrence of over fitting through the settlement of the parameter.

As will be appreciated from the foregoing, classification algorithms base on a relevant regulation will offer a more accurate classification algorithm than a decision tree algorithm C4.5. However, the classification algorithm base on a relevant regulation also have its disadvantage such as it can not analysis the data consisting of numeric attributes directly if the data does not discrete firstly. It is difficult to provide a high accuracy of deriving from a classification rule because that the data regions are limited so that the data outside of the data regions will be lost.

In addition, there are another two difficult problems on discretion of data.

One of which is a Min-support problem which happens when the regions of discrete data are so narrow that tuples included on individual data are reduced and the parallel granularity of data will become too narrow, as a result, support level becomes low.

Another one of which is a Min-confidence problem which happens when the regions of discrete data are so broad that the parallel granularity of data will become too broad, as a result, confidence level becomes low even though the support level is improved.

In order to deal with these two problems, this paper propose a new concept for deriving a classification rule from numeric attributes datasets, numeric attributes frequent datasets and numeric attributes data at same time.

By combing CAEP classification algorithm with said concept, this paper also propose a classification algorithm called ARMFI which base on a relevant regulation especially effective to a dataset consisting of numeric attributes.

Besides having advantage of classification algorithm based on a relevant regulation mentioned  IEEE ~computer  society    above, The ARMFI also can deal with the problems happened in discrete datasets consisting of numeric attributes and give a performance better than the traditional classification algorithms.

As to the detail about the ARMFI, It will be described as follows.

2. Frequent Item-sets and Frequent Regions  Hereby we will give a definition of the frequent item-sets and frequent regions used in the classification algorithm called ARMFI. In the database D, we call frequent item-sets which have a high support more than Min-support in each transaction (t) as frequent item-sets.

In order to traverse frequent item-sets consisting of numeric attributes, it is necessary to expand the apriori algorithm firstly. Suppose the frequent item- sets have two type of format, one of which consisting of character attributes called character item-sets and another one of which consisting of numeric attributes called numeric item-sets. At the first, Suppose the attribute associated with the character item-sets are As, and the value of which are v", the character item-sets can be described by(As" v" ),for the same reason, the numeric item-sets can be described  bye An" Vm).

the transaction (t) are converted and described as  t = {AS', vSll ..,(Asns, VSns HAm, vml .. ,(Anmn, vnmn)} ,If the value of the numeric item-sets does not considered, the transaction (t +) are converted and described as  t+ = {(Asl, VSl) .. ,(Asns, Vsns) (Ani) .. ,(Anmn)}.

After the converting, frequent item-sets f which having high support than Min-support to be seek by traversing the data converted. Then, pay attention to the attributes An, of all of the numeric item-sets in derived frequent item-sets f and extract regions with high density of numeric item-sets value Vm from transaction item-sets t consisting of frequent item- sets f. In another words, to derive the regions according to the equation below should satisfy the specified density standard,  Hereby, the condition Ii < U i , An, E f also needs satisfied. We call the regions derived as frequent regIOns.

In the processes of traversal frequent regions, a parameter called (Permissible Range) is necessary for judging whether the numeric item-sets in the transaction item-sets consisting of frequent item-sets meet a standard of the frequent regions. The parameter called (Permissible Range) is a specified  value Iii for defining the standard of the frequent  regIOns.

Hereby, a method for how to evaluate the frequent regions will be discussed as follows. To compare reciprocally each item Vn, one by one and resulting the Ln, , Then Combine reciprocally each item one by  one which satisfies equation Ln, ::::; Iii and generating  neighborhood aggregate Ef(t) from transaction item- sets t.

Ej(t) = {t'E D,!\VAni E flv'ni -vnil::::; Lit}U{t}  When (Am, Vni) E t ,Set up neighborhood aggregate E(t) from all transaction item-sets t to ESj,If the product set that meet the requirement Ef(ti) ,Ef(~)(Ef(ti) E ESj and E ESj Ef(~)) not  null, Then Ef(ti) and Ef(~) all can be directly  connected, besides discretional Ef(ti) and Ef(~) set  corresponds to ESj , The equation (2-1) exist:  E j ((t] (i--> j?)' E j (t2 (i--> j) ), E j (tm (i--> j) ). ..... (2 - 1)  When according to equation (2-2) directly connected, Ef(ti) and Ef(~) will connection.

Get maximum frequent candidate Cf under this  neighborhood aggregateESj, Cf = Ej(t) E ESjIEj(t)  (s are mutually connected in ESj ).

When the tuple>Min_support that included in  generated frequent candidate item-sets Cf , It is called frequent item-sets Ff, The region is called frequent  region Idf surrounded by maximum and minimum of frequent item-sets Ff each numeric attributes An, .

{I ICf l . }Fj = Cj lDT ~ Mzn sup ( 2 - 3)  Idj = {[mine vn,),max( Vn,)]IAn, E 1} (2 - 4) tEFj tEFj  Now, For example such as figurel and figure2 to illustrate the solution of frequent region, Assume Min_support is 4, Dots as shown in figure is transaction item-sets t, As shown in figure 1, The range of each item-sets in transaction item-sets t according with (Permissible Range) L1;.

Namely, In frequent candidate item-sets generated by transaction item-sets tmutually connected, The tuple is 5, Namely, The tuple>Min_support (4), Frequent candidate item-sets is 5, According with the definition described above, Therefore, Can get frequent region of numeric item-sets Item; Item}.

The rectangular region in figure 1 is a frequent region of numeric item-sets Item; Item}.

"'j  Frequent Region  Itemj  Figurel. Existent Frequent Region  Same reason, According to the above steps, On frequent candidate item-sets, Generated by transaction item-sets t mutually connected as shown in figure2.

We can obtained the tuple is 3, Also, The tuple< Min_support(4), According to the definition described above, At this moment, The numeric item-sets Item; , Item} has no frequent region.

Iternj  Null Frequent Region ?  Item,  Figure2. Non existent Frequent Region   3. An algorithm for Extracting Frequent Regions  Further describing for an algorithm how to derive frequent regions after extracting them will be introduced in detail.

At the first, an algorithm for deriving frequent regions from frequent item-sets Fjl with single attribute will be described.

When the Ffl made up character item-sets only,  Extraction process very simple, No longer discussion.

When the Ffl made up numeric item-sets, Use the  method described above to extracting the frequent region, Must be paid attention, Set up corresponding fast index while extracting frequent candidate item- sets, For traversal time saving, When N = IDI ,The time complexity is the biggest, It isO(Nlog N).

Secondly, Frequent item-sets Ff(iJ(1 ?: 2) of multi - number attributes will be described, Can be obtained by the monotonicity of support, If every numeric item- sets has no frequent region in frequent item-sets Ffl,  The frequent item-sets Ffl has no frequent region.

Based on the reason, All numeric attributes in frequent item-sets Ffl directly solving as same as  frequent candidate item-sets Cf ,Pruning the frequent candidate item-sets from I = 1, Then cutting the frequent region that unsatisfied with Min_support, At the same time, Efficient extracting frequent region, Following, Use Apriori algorithm correlate with numeric item-sets extracting the frequent region will be described.

Firstly, Set up attributes sets f(/) that contained in frequent item-sets Ff(i) and with I tuple, Extracting unitary (singleness attributes) attributes frequent  region by all attributes An, and L1; of f(/) ,Then, Make up each frequent regIOn extracting I dimensional frequent region.

Because extracting I dimensional frequent item- sets Ff(i) need using frequent item-sets Ff(i - 1)  and Ff' (i -1) ,If ~f(/-l)nf(/-l)1=1-2) then f(/) = {f(I-l)Uj(l-l)} ( Ani E 1(1) ), Extracting unitary  frequent region by each numeric attributes, Set every numeric item-sets An, with Id{An,} on f(!), And get  directly product PIdf(l) = AmE0f(l) {Id(An,)} and distribute number for each tuple. Because any tuple    (Cj:Class, t :Element of class sets,Dj:Element set of class, e: Item-sets).

Secondly, GR will be introduced, GR is a conception between set and item-sets on class level, Mainly reflect the related relation between class and class, Expressed rate of this class relative to the frequent item-sets in that class, Regard item-sets e as  of Pldr(l) also possibly on frequent region related with f(/) , So If(l)mf(l) is a candidate frequent item-sets. At this moment, Pruning the tuple of tuple number<Min_support in If (l) mf (I) , The neighborhood  aggregate of transaction item-sets t satisfY Ef(l)mf(l) = {t'E Ef(l)mf(l) I /\liA" E f(l)lv'" -v,,1 s;~} ,frequent candidate item-sets Cf(l)I11f(l) = Ef(l)mf(l) E ESf(l)mf(l)IEf(l)mf(l)  (s are mutually connected in ESf(l)mf(l) ), Extracting  neighborhood aggregate Ef(l)mf(l) from aggregate  ESf(l)mf(l) .

When the tuple>Min_support includes in frequent candidate item-sets Cf(l)mf(l) ,The region surrounded  by maximum and minimum of frequent item-sets Fr, Every numeric attributes An, is frequent region Idf .

Increase progressively I , Repeated course described above, The extractive algorithm of frequent region Idf will be described.

Apply this algorithm, The highst time complexity local is neighborhood aggregate ?ret) that extracted from transaction item-sets t, If the number of transaction item-sets t is N, Then maximum time complexity is O(N 2 ).

4. Creating the Classification Rule  This paper will introduce how to creating the classification rules from many aspects such as SUP(support), GR(growth rate) and AS (aggregate score).

At the first, SUP will be introduced. The SUP hereby introduced have same means as we said usually, i.e., the ratio of elements included in frequent item- sets of item-sets Dj and elements included in item-sets of Dj. It can be calculated for the formula shown as follows.

sup ci (e) = I(t E Di ,e <;;;  IDi I t~  ...... (4 - 1)   the object, the calculated for the formula shown as follows.

{  supc,(e)  supc',(e) sup c' ,(e) * 0 GR(e) = (4 - 2)  00 sup c' ,(e) = 0, sup c,(e) * 0 Third, AS will be introduced, Set the transaction of  extracted class Cj as EP (Emerging Pattern) from item-sets e ,When the SUP and GR all exceeded threshold and GR threshold> 1, Can extracting rule that is:  (If the item-sets e included in transaction item-sets then class Cj included in transaction item-sets).

Namely, (e-C).

For verify confidence of derivative rule, Introduce the concept ofAS realize the verification of confidence, The calculated for the formula shown as follows (GR threshold> 1),  GR(e) AS(e) = * SUPci(e) (4 - 3)  GR(e) + 1  Set up the sets of EP is E(CD, Base on t, The AS summation is score of Cj, calculated for the formula shown as follows,  score(t,C) = L AS(e) (4 - 4) e<;;;t,eEE(C)  Because the proportion of score of each class Cj is different, For the standardization score, The rate of the score as base score, Accuracy and regulatory in order to be classified, Introduce the concept of normalize score, The calculated for the formula shown as follows,  ratio score(Ci) normalize score(Ci) = ..... .4 - 5  - base score(Ci)  5. Experimentation and Application  Cell variation bring out a high probability of becoming cancer is a well know fact. However, there are a great variety of causes bring out cell variation, how to find the causes is expected by all of the medical experts.

Hereby, An experiment based on the classification rule for datasets relating to cell variation will be described as follows. The datasets include a group of clinical data with 690 records and 102 attributes.

At the first, To organize and clean the clinical data as shown in Tablel is needed.

Tablel.Attribute table  Descriptor Meaning  Sum of the positive Pi PEOC PC+ Sum of the negative Pi PEOC PC- The area ofthe van Vdwarea der waals surface Vdw vol Van der waals volume LogP(o/w) Log ofthe octanol  / water partition coefficient  And then, It also necessary to discrete Activity attributes because the classification for the data having numeric attributes can not be done directly, According to the medicine expert opinion. The discredited Activity attributes are shown as follows in Table 2.

Table 2.Aiscretized Activity attributes  Class Region  Inactive Activitr-99 Low -99<Activity<-99 Medium O<Activity<3 High <3Activity  Using the algorithm proposed in this paper can derivate classification rule shown as follows.

Exl: logeo/w): [1.69-2.63] ---+Class: Inactive [Support=0.63, Growth rate=4.0l, Aggregate score=0.50]  Ex2: PROE]C+: [0.65-1.11], PROE]C-:[-l.ll i 0.65] ---+Class: Inactive [Support=O.72, Growth rate=1.46, Aggregate score =0.432] ---+Class: Inactive  Take Activity attributes as an example, the high value of aggregate score calculated shows a useful relevant regulation, i.e. with referring to the tablel.

(If the water affinity small, the molecular size small and the electric charge also small, then the cell variation rate low).

6. Conclusion  A detailed describing and experiment about a classification algorithm called ARMFI proposed in this paper have been done. The experiment shows a conclusion that the classification algorithm called ARMFI can be applied to a lot of fields and provide useful knowledge.

However, For the further optimization of the relevant regulation, There are still many problems remaining, achievements about them is expected.

