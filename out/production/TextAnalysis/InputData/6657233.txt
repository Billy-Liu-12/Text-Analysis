Detecting Insider Threats: a Trust-Aware Framework Federica Paci?, Carmen Fernandez Gago?, Francisco Moyano?

Abstract?The number of insider threats hitting organizations and big enterprises is rapidly growing. Insider threats occur when trusted employees misuse their permissions on organizational assets. Since insider threats know the organization and its processes, very often they end up undetected. Therefore, there is a pressing need for organizations to adopt preventive mechanisms to defend against insider threats.

In this paper, we propose a framework for insiders identifi- cation during the early requirement analysis of organizational settings and of its IT systems. The framework supports secu- rity engineers in the detection of insider threats and in the prioritization of them based on the risk they represent to the organization. To enable the automatic detection of insider threats, we extend the SI* requirement modeling language with an asset model and a trust model. The asset model allows associating security properties and sensitivity levels to assets. The trust model allows specifying the trust level that a user places in another user with respect to a given permission on an asset. The insider threats identification leverages the trust levels associated with the permissions assigned to users, as well as the sensitivity of the assets to which access is granted. We illustrate the approach based on a patient monitoring scenario.

Index Terms?insider threats, security requirements, trust relationships

I. INTRODUCTION  As reported by the 2011 CyberSecurity Watch Survey, 21% of cyber crimes were committed by insiders [1]. However, the 46% of the respondents thought that damage caused by insider attacks was more severe than damage from outsider attacks.

In fact, insider attacks can cause significant damage to the affected organizations e.g loss of money, loss of reputation, or loss of customers, among others. As defined by CERT [2], an insider is ?a current or former employee, contractor, or business partner who has or had authorized access to an organization?s network, system, or data and intentionally exceeded or misused that access in a manner that negatively affected the confidentiality, integrity, or availability of the organization?s information or information systems?. Insider attacks are more difficult to detect because they are trusted employees who have legitimate and often privileged access to critical or valuable assets, and have knowledge of the organization and of its processes. Thus, to defend from insider threats, preventive measures need to be taken that detect and assess the risks associate with insiders rather than reactive measures after the attack has been conducted.

In this paper, we present an approach to assist security engineers in the detection of insider threats during the early security requirements analysis phase of a socio-technical sys- tem development life cycle. Our approch is complementary to other threats identification approaches that rely on the analyst level of expertise such as risk assessment. With our approach, the security engineer can identify automatically the insider threats that exist in a given organization and permission setting and assess the associated risks. The approach consists in first modeling in the SI* requirements modeling language [3] the system stakeholders, their goals, their assets, the security properties (e.g confidentiality, integrity, availability) that stakeholders want to hold for their assets, the permissions that the stakeholders have on assets, and delegation and trust of permissions relationships among them. Trust of permission relationships represent the belief of the grantor of a permission on an asset that the grantee will not misuse it: an agent can be either trusted with a permission or distrusted. The level of trust associated with an agent with respect to a granted permission is crucial to assess the risk of the agent being an insider threat: the lower the level of trust associated with a permission is, the higher is the likelihood that the agent will misuse the permission.

To support the automatic detection of insider threats, we extend the SI* requirements modelling language proposed in [4] with an asset and trust model. The asset model associates with assets a sensitivity value that represent how valuable the asset is for the owner. The trust model associates different levels of trust (e.g. high, medium and low trust) with a permission granted to an agent rather than a single binary value (trusted, not trusted) as currently supported by the SI* language. Based on the sensitivity and trust levels, we define a set of rules to automatically identify insider threats to an asset and prioritize them based on the risk associated with the threat. The risk associated with the insider threat is given by the likelihood that the threat occurs that is quantified by the trust level associated with the permission granted to the insider agent, and the cost of the permission being misused that is quantified by the sensitivity of the asset being harmed.

The rest of the paper is organized as follows. Section II introduces a running example taken from the healthcare domain. We introduce the SI* framework and its extensions proposed in [4] in Section III. We present the asset and the   DOI 10.1109/ARES.2013.22     trust model in Section IV and the process to identify and prioritize insider threats in Section V. We discuss the related work in Section VI and outline future work in Section VII.



II. RUNNING EXAMPLE - PATIENT MONITORING  To illustrate our framework, we use a patient monitoring scenario from the eHealth case study proposed in the NESSoS European project 1. The scenario involves five main actors. Pa- tient is monitored by a smart T-shirt which measures medical data (e.g., heartbeat rate, blood pressure, etc.) and transfers them to the Hospital?s computer system. When the patient?s condition is abnormal, the doctor makes a diagnosis and produces a prescription. The patient receives his prescription and requests the drug delivery service to the pharmacy. The Hospital provides medical services to patients. The hospital monitors patients? health and manages patients? data, which are stored in the hospital?s computer. When the patient has some problems, the hospital assigns a doctor to diagnose the patient. The Pharmacy is responsible for managing drugs and provide them to the patients. All the information about drugs is stored in the pharmacy?s computer. The Pharmacist works for the pharmacy and is responsible to provide drugs to be delivered according to the prescription received from the patient. The prescription information is stored in the pharmacy?s computer. Finally, the Drug manager works for the pharmacy and is responsible to manage the drugs. All the drugs? information is also stored in the pharmacy?s computer.



III. THE SI* MODELING FRAMEWORK  The SI* modeling language [3] has been proposed to capture security and functional requirements of socio-technical systems. SI* is founded on the concepts of agent, role, service, and relations such as AND/OR decomposition and means-end.

An agent is an active entity with concrete manifestations and is used to model humans as well as software agents and organizations. A role is the abstract characterization of the behavior of an active entity within some context. The term service is used to denote a goal, a task and a resource. A goal captures a strategic interest that is intended to be fulfilled. A task represents a particular course of actions that produces a desired effect. It can be executed to satisfy a goal. A resource is an artifact produced/consumed by a goal or a task.

AND/OR decomposition is used to refine a goal, while means- end identifies goals that provide means for achieving another goal or resources produced or consumed by a goal/task.

SI* also captures social relationships (e.g., delegation and trust) for defining the entitlements, capabilities and objectives of actors. Originally, a delegation marks a formal passage of responsibility (delegation execution) or authority (delegation permission) from an actor (delegator) to the actor receiving the responsibility/authority (delegatee) to achieve a goal or to provide a resource. Trust is a relation between two actors representing the expectation of one actor (trustor) about the capabilities of the other (trustee) ? trust execution, and about  1http://www.nessos-project.eu/  the behavior of the trustee with respect to the given permission ? trust permission.

TABLE I PERMISSIONS ON RESOURCE  Permission Type Description (Possible)  Affected Sec.

Property  Access (low-level)  Actor only has the permission to access/read/use the resource. Confidentiality  Modify (medium-level)  Actor can change the content of the resource. Integrity  Manage (high-level)  Actor has the permission to modify the resource, delegate permissions to other actors and modify permissions to other actors.

Availability  In order to support the identification of threats at organiza- tional level, in [4] SI* has been extended to represent different types of actors? permissions on resources and different types of relationships between resources. Goals and resources are considered as assets that need to be protected because they bring value to organizations. In order to specify how an asset needs to be protected, we use the concept of security requirement defining a specific security property, such as confidentiality, integrity, and availability. The permission type granted on a resource determines the type of actions an actor can perform on a resource (see Table I). Thus, a permission type might yield to the violation of a specific security property if the actor misuses the actions granted by a permission type.

Moreover, a given permission granted on a resource can be extended to other resources that are related to the resource by the relations reported in Table II.

TABLE II RELATIONSHIPS BETWEEN RESOURCES  Relationship Description store in captures a situation where an informational resource is stored  in a physical resource part of indicates that a resource consists of other resources.

require denotes that a resource might require another resource to function.

In order to allow the analysis of SI* models, the semantics of SI* has been defined in the Answer Set Programming (ASP for short) paradigm which is a variant of Datalog with negation as failure and disjunction. This paradigm supports specifications expressed in terms of facts and Horn clauses, which are evaluated using the stable model semantics. Here, SI* models are encoded as sets of facts. Rules (or axioms) are Horn clauses that define the semantics of SI* concepts. To support the formalization in ASP, the DLV inference engine is used. Table III summarizes the predicates to formalize an SI* model in ASP.

Example 1. Figure 1 shows the SI* model for the Patient Monitoring scenario. The model consists of five roles: the Hospital, the Patient, the Pharmacy, the Pharmacist, and the Drug Manager. Patient (Role) can be played by three agents Bob, Kate, and Jane. The Patient (Owns) the re- sources Patient data and Prescription. It delegates to the Hospital the manage permission on Patient data, and it     Fig. 1. Example of SI* model - Patient Monitoring Legend: The circles denote roles or agents, the ovals denote goals, while the rectangles represent resources. Dp a, and Dp ma represent delegation of permission relation where the permission type is access and manage respectively. Similarly,Tp a, and Tp ma represent trust of permission relation where the permission type is access and manage.

Services that are considered assets are labeled with the security property that should be satisfied and their sensitivity level.

TABLE III PREDICATES FOR ASP SI* FORMALIZATION  Goal model service(Service:s) goal(Goal:g) resource(Resource:r) actor(Actor:x) agent(Agent:a) role(Role:p) play(Agent:a,Role:p) provide(Actor:a, Goal:g) own(Actor:a, Goal:g) own(Actor:a, Resource:r) subgoal(Goal g1, Goal:g) means end(Resource:r, Goal:g) means end(Goal:g, Resource:r) Resource model stored in(Resource:r, Resource:r1) part of(Resource:r, Resource:r1) require(Resource:r, Resource:r1) Permission model permission(Actor:a, Resource:r, PType:pt) del perm(Actor:a, Actor:a1, Resource:r, PType:pt) trust perm(Actor:a, Actor:a1, Resource:r) Security requirements and Threats model secure req(Resource:r, SProperty:sp) secure req(Goal:g, SProperty:sp, Resource:r) threat(Actor:a, Resource:r, SProperty:sp) threat(Actor:a, Goal:g, SProperty:sp, Resource:r)  delegates the access permission on Prescription to the Pharmacy. The Pharmacy has the intention (Request) to fulfill the goal Sell drug which is (AND-decomposed) into subgoals Manage drug and Provide drug: the fulfillment of  Manage drug is delegated to the Drug Manager while the fulfillment of Provide drug is delegated to the Pharmacist.

The Pharmacy (Owns) the resource PComputer. It grants to Drug Manager the manage permission on PComputer and the access permission on Prescription to the Pharmacist.

The Hospital (Role) has an intention (Request) to fulfill the goal Provide medical service which is (AND-decomposed) into subgoals Monitor patient, Manage patient data, and Diagnose. Some goals can produce or consume resources.

For example, the goal Diagnose requires the resource Patient data and produces the resource Prescription. The Hospital (Owns) the resource Smart T-shirt and delegates to the Patient the manage permission on it.



IV. SI* EXTENSIONS  In this section we present the two main extensions that we propose to SI*: asset model and trust model.

A. Asset Model  We consider an asset a service for which the owner specifies the sensitivity and a security property that expresses the need of protecting the service. We introduce a predicate sec req(s,sp,p) to specify the security property sp that should be preserved for a service s owned by a role p. Similarly, to denote that that a security property sp should be preserved for a specific instance of a service s, service instance(s, a, p), we introduce the predicate sec req(service instance(s, a,     p),sp,a,p). We also introduce the predicate sensitivity(s,sl,p) to indicate that a service s owned by role p has sensitivity level sl, and the predicate sensitivity instance(service instance(s, a, p),sl,a,p) to associate a sensitivity level sl to an instance of the service s owned by the agent a playing the role p. To denote at organizational level that a service is an asset, we introduce the predicate asset(s, p) where s is a service and p is the role who owns it. Instead, the predicate asset instance(service instance(s, a, p),a,p) holds when an instance of a service s is an asset.

TABLE IV FORMALIZATION OF SI* EXTENSIONS  Asset model sec req(Service:s, SProperty:sp,Role:p) sec req instance(ServiceInstance:si, SProperty:sp,Agent:a,Role:p) asset(Service:s, Role:p) asset instance(ServiceInstance:si, Agent:a,Role:p) sensitivity(Service:s, SLevel:sl, Role:p) sensitivity instance(ServiceInstance:si, SLevel:sl, Agent:a,Role:p) asset(S,P) ? sec req(S,SP,P) ? sensitivity(S, SL, P) Trust model trust perm(Role:p, Role:p1, Service:s, PType:pt) trust perm instance(Agent:a, Agent:a1, ServiceInstance:si, PType:pt, TLevel:tl)  In our model we distinguish between two types of assets: direct and indirect assets. Direct assets are services for which a security property and a sensitivity level are explicitly modeled in the SI* model, while indirect assets are services for which the security property and the sensitivity level is determined based on the relations with other services. The identification of indirect assets is based on a set of rules (reported in Table V) that consider the relations among resources - stored in, part of and require - and the relationship means end among the resources and the goals that requires the resources to be fulfilled. We assume that if an asset is related to a service by one of these relations, the same security property should hold for the asset and service (axioms S1-S9) and that the two assets should have the same sensitivity level (axioms S10- S13). If the direct asset is related to another direct asset only the security property is propagated to the other asset.

Example 2. In Figure 1 Prescription is an medium sensitive asset for the Patient, who requires that Confidentiality of Prescription is preserved. Since Prescription is stored in PComputer, also the Confidentiality of PComputer needs to be preserved.PComputer is an indirect asset which has the same sensitivity of Prescription.

B. Trust Model  The SI* trust model is very simple since it supports only binary trust values: either an agent is trusted or is distrusted for a given permission on a resource. However, in real scenarios trust is not a binary value but an agent can be assigned different levels of trust. The different values of trust depend very much on the used definition, being the latter very much dependent on the context. There is no a standard definition of trust. However, usually, a trust relationship holds between two agents: a trustor (the one who places trust) and a trustee (the one performing a given action and to who(m) the trustor places trust in). In this  TABLE V AXIOMS FOR IDENTIFYING INDIRECT ASSETS  Indirect Assets Identification  S1 sec req(R, SP, P ) ? store in(R1, R) ? sec req(R1, SP, P )  S2 sec req(R, integrity, P ) ? store in(R1, R) ? sec req(R1, confidentiality, P )  S3 sec req(R1, SP, P )? part of(R1, R)?sec req(R, SP, P ) S4 sec req(R, integrity, P ) ? require(R1, R) ?  sec req(R1, integrity, P )  S5 sec req(R, availability, P ) ? require(R1, R) ? sec req(R1, availability, P )  S7 sec req(G,SP,R, P ) ? secure req(R, SP, P ) ? means end(G,R)  S8 sec req(G, confidentiality, R, P ) ? secure req(R, confidentiality, P ) ?means end(R,G)  S9 sec req(G1, SP,R, P ) ? subgoal(G1, G) ? sec req(G,SP,R, P )  S10 sensitivity(R, SL, P ) ? store in(R1, R) ? sensitivity(R1, SL, P )  S11 sensitivity(R, SL, P ) ? part of(R1, R) ? sensitivity(R1, SL, P )  S12 sensitivity(R, SL, P ) ? require(R1, R) ? sensitivity(R1, SL, P )  S13 sensitivity(G,SL, P ) ? means end(G,R1) ? sensitivity(R1, SL, P )  paper, we define trust as the expectation that the trustor places on the trustee on a specific context for performing a specific task. The context in our case is a permission that is granted to the trustee on a given asset. The trust level is important to determine the likelihood that the trustee will misuse the granted permission to harm the asset.

Our intention is to extend SI* with a trust model that asso- ciates a trust level with a trust of permission relation between two agents. The trust levels are then translated into trust labels that are used to define insider threats identification rules, which determine if an agent misuses a granted permission on an asset and the risk associated to the threat.

First, we assume that trust levels can be represented in two forms: labels - e.g. Very Good, Good, Neutral, Bad, Very Bad- and numbers in the interval [0, 1], as in the trust model proposed in [5]. Then, the second important step to define a trust model for SI* is to set a way to derive trust values.

The assignment of trust values can be done in a discrete way by using for example 0 for representing non-trust at all; 1 for representing total trust and 0.5 for representing an intermediate value. The way of calculating trust can be made in a more accurate way by using some kind of mathematical or statistical functions. For our purpose, the way trust values are calculated is not very relevant. J?sang provides a comprehensive review on trust models [6]. We assume that some trust values are already assigned to trust of permission relationships between agents in the SI* model and that these values are leveraged by the organization stakeholders in order to compute trust values for pairs of agents for which such relationships are not explicitly modelled. Thus, to determine the trust level that an agent A places on another agent B regarding how B will behave with respect to a granted permission, we leverage the trust of permission relationships that other agents have with A and B. Incorporating a trust model in SI* thus requires not only to extend trust of permission relationships with trust     values and permissions but also to add the following rules: ? Derivation rules - generate a trust value for agents A and  B given the trust values that other agents trusted by A have in B  ? Resolution rules - resolve potential conflicts that may arise from applying the derivation rules  ? Transformation rules - specify how to translate trust values to trust labels.

We formally introduce these rules as follows.

1) Derivation and Resolution Rules: These rules aim to  exploit trust levels associated with trust of permission relation- ships present in an SI* model in order to compute trust values for trust of permission relationships not explicitly represented in the model. These rules are supported by the concept of trust evaluation. This concept and those of trust statement, and linear and consensus functions are introduced in [7].

Definition 1 (Trust Evaluation). A trust evaluation is a func- tion F : E ? E ? C ?? TD, where E is a set of agents, C is a set representing the context in which the trust evaluation can take place, and TD is the trust domain.

Note that the definition is generic and applicable to different settings and for different purposes. In this paper, the output of this function is the trust value in the extended trust perm relationship that measures quantitatively the expectation of an agent about the behaviour of another agent with respect to a given permission. In this work, we instantiate the context C as the permission granted to the trustee on a given asset. Before we introduce these extensions, trust perm relation did not reflect this quantitative measurement, since it was an atomic relationship: either it was present in the SI* model or not.

Once the requirement engineer has designed the SI* model of the socio-technical system and its instances, there might appear two types of relationships configurations. Depending on the configuration that we have there might be two different types of trust evaluation functions. We may use a linear trust function, or a consensus trust function. Yet before providing their formal definitions, we need to define what a trust statement is.

Definition 2 (Trust Statement). A trust statement is an element (Trustor, T rustee, Context, V alue) ? E ? E ? C ? TD, where E is the set of all entities in the system; C is a set representing a context; and TD is a Trust Domain.

Trust of permission relationships are a particular in- stance of trust statements where Context is the per- mission granted to the trustee on an asset instance and V alue is the trust level placed by the trustor in the trustee for the permission. To represent trust statements we have introduced the predicate trust perm instance(A, A1,asset instance(service instance(S,A,P)), PT, TL). Trust statements can form trust chains. Linear and consensus trust functions evaluate trust over these chains, as defined next.

Definition 3 (Linear Trust Function). A linear trust function is a function,  f : ??  n=2  n? ?? ? TD ? ? ? ? ? TD ?? TD, that calculates the trust  level associated to a path or chain of trust statements, such that f(v1, . . . , vn) = 0 if, and only if, vi = 0 for any i ? {1, . . . , n}, where vi ? TD and TD is a trust domain.

Definition 4 (Consensus Trust Function). A consensus trust function is used to calculate the trust level associated to a set of paths or chains of trust statements. It is defined as,  g : ??  n=2  n? ?? ? TD ? ? ? ? ? TD ?? TD, where TD is a trust  domain and  1) g(z1, . . . , zi?1, zi, zi+1, . . . , zn) = g(z1, . . . , zi?1, zi+1, . . . , zn) if zi = 0  2) g(z) = z  As a consequence of applying these functions to an SI* model, an agent might end up holding several trust of per- mission relations with a given agent. However, it would be optimal if an agent only holds one value for any other agent of the system. Resolution functions could solve this.

Definition 5 (Trust Resolution Function). A trust resolu-  tion function is a function, f : ??  n=2  n? ?? ? TD ? ? ? ? ? TD ??  TD, such that f(v1, . . . , vn) ? max(v1, . . . , vn) and f(v1, . . . , vn) ? min(v1, . . . , vn), where vi ? TD and TD is a trust domain.

Basically, given a set of trust values, the resolution function produces one unique representative trust value that is upper bounded by the maximum and lower bounded by the minimum of the original trust values. Derivation and resolution rules rely on functions to compute the trust values. For this purpose, different functions could be used (e.g. maximum, minimum, arithmetic or geometric means).

2) Transformation Rules: Once we obtain the final numeric values for every trust of permission relationship, transforma- tion rules must be used in order to translate these values, which are in an interval [a, b] ( [0, 1] is the chosen one in this case) into a label in a given set of labels that forms a trust scale [5].

Definition 6 (Trust Scale). A trust scale for a given context c ? C is composed of an ordered set Lc of trust labels Lci , where i ? Ic, that represent discrete trust meanings; and a trust evaluation that is an increasing function, f : Lc ? (0, 1], such that f(Lcnc) = 1.We denote x  c i := f(L  c i ) and x  c 0 := 0.

Example 3. Let us consider the SI* model illustrated in Figure 1 that shows the patient monitoring scenario. Let us suppose that the agent Bob (playing the Patient role) wants to determine the level of trust with which he can grant the access permission on its asset Prescription to Ellen (playing the Drug Manager role). Since Bob has no direct trust relationship with Ellen we need to evaluate the trust value that Bob places in Ellen based on the following trust chain: trust perm instance(Bob, Pharmacy Saint Claire, asset instance(service instance(Prescription,Bob,Patient), Bob, Patient), access, very good) ;     Fig. 2. Process to Identify Insider Threats  trust perm instance(Pharmacy Saint Claire, Ellen,asset instance(service instance(Prescription,Bob,Patient), Bob, Patient), access, good). Note that Ellen has access to the instance of Prescription owned by Bob because it is stored in the instance of PComputer owned by Pharmacy Saint Claire on which Ellen has been granted manage permission with good trust level and having the manage implies the access permission. Let us assume that the trust scale and the trust evaluation function are defined as follows:  ? Very good ? 1 ? Good ? 0.8 ? Neutral ? 0.6 ? Bad ? 0.4 ? Very Bad ? 0.2  Let us also assume that in order to compute the trust value that Bob can place in Ellen for the access permission we use the product as consensus function. Thus, the trust level for Ellen is 1 * 0.8 = 0.8 which corresponds to label Good. Thus, we can add to the SI* model formal- ization the following trust of permission relationship be- tween Bob and Ellen: trust perm instance(Bob, Ellen, as- set instance(service instance(Prescription,Bob,Patient), Bob, Patient), access, good).



V. IDENTIFYING POTENTIAL THREATS  In this section we present the steps to follow for the process for identifying insider threats (see Figure 2).

A. Build SI* Model  This step aims to create an SI* model, which captures all the stakeholders of the system modeled as agents, the role that they play inside the organization, their goals, tasks and resources, the relations between resources, and the delegation and trust relationships among the roles. To enable the auto- matic detection of insider threats, we need to translate the graphical SI* model into formal specifications in ASP (see SectionIII).

Example 4. The SI* model in Figure 1 is produced during this step. A snapshot of the formalization of the model in ASP is reported in Table VI.

B. Identify Critical Assets  This step aims to identify those services in the SI* model that are assets. First, direct assets are identified by labelling the critical services with the security property that the role owning the service wants to hold for it, and with the service?s  TABLE VI ASP FORMALIZATION FOR SI* MODEL  role(patient) role(hospital) goal(provide medical service) goal(monitor patient) goal(diagnose) ..........

resource(monitoring data) resource(patient data) resource(prescription) resource(computer) resource(smart t shirt) ..........

means end(diagnose,prescription) resource(smart t shirt) del perm manage(smart t shirt,patient) del perm manage(hospital,smart t shirt) own(hospital,smart t shirt) del perm manage(patient data,hospital) own(patient,patient data) role(pharmacy) ..........

own(pharmacy,pcomputer) del perm manage(pcomputer,drug manager) ..........

del perm access(prescription,pharmacy) own(patient,prescription) del perm access(pharmacy,prescription) ..........

agent(kate) agent(bob) play(kate,patient) play(bob,patient)  sensitivity level (see Section IV). Then, the indirect assets are determined based on the set of rules in Table V.

Example 5. In Figure 1 there are three direct assets owned by the Patient role: Prescription, Patient Data, and Moni- toring Data. The Patient requires confidentiality to hold for Prescription, availability should hold for Patient Data, while integrity should be satisfied for Monitoring Data. Smart T- Shirt, HComputer, PComputer, Diagnose, Manage Pa- tient data, Monitor Patient, and Provide Drug are indirect assets. For example, PComputer is an indirect asset because the asset Prescription is stored in PComputer and thus the confidentiality of PComputer needs to be preserved.

Similarly, the goal Diagnose is an indirect asset because it is linked to the asset Prescription by a means end relation, and thus also the confidentiality of the goal needs to hold.

C. Determine Permissions on Assets  This step determines the permissions that roles are granted on assets. The permissions are assigned to roles based on a set of axioms that take into account if a role is the owner of a resource and of the relations between resources - stored in, part of and require. The axioms assume the     TABLE VII ASP RULES TO INSTANTIATE THE SI* MODEL  Istantiating Assets A1 sec req instance(service instance(S,A, P ), SP,A, P )? sec req(S, SP, P ) ? service instance(S,A, P ) ? instance(A,P ) A2 sensitivity instance(service instance(S,A, P ), SL,A, P )? service instance(S,A, P ) ? instance(A,P ) ? sensitivity(S, SL, P ) A3 asset instance(service instance(S,A, P ), A, P )? sec req instance(service instance(S,A, P ), SP,A, P )?  sensitivity instance(service instance(S,A, P ), SL,A, P ) Istantiating Permissions A4 permission instance(A, service instance(S,A, P )? permission(P, S, PT ) ? instance(A,P ) ? service instance(S,A, P )  owner of a resource has the highest permission on a resource (i.e., manage) or that a role with the manage permission on a resource can delegate any permission type on the resource to another actor. In addition, if a role has a manage permission on an resource which stores another resource, s/he then has the manage permission also on the stored resource. Last, if a role has a permission on a resource, then s/he has the same permission on each subpart of the resource. For a complete list of the axioms, we refer the reader to [4].

Example 6. The Patient has delegated the access permission to the Pharmacy on Prescription, and thus the Pharmacy has the access permission on Prescription. Moreover, the Pharmacy has the manage permission on PComputer and thus it has also the manage permission on Drug Info and Prescription that are stored in PComputer. The Pharma- cist and the Drug Manager are granted by Pharmacy the manage permission on the PComputer. In addition, the Phar- macist also gains access permission on the Prescription from the Pharmacy. Since the Drug Manager has manage permission on the PComputer and Prescription is stored in PComputer,Drug Manager has manage permission on Prescription.

D. Instantiating the SI* model  This step instantiates the SI* organizational model. We only report the axioms to instantiate the elements of the SI* model that are relevant for the insider threat identification. A complete list of the ASP rule to instantiate an SI* model can be found in [8]. In the following, we introduce the rules to instantiate assets, agents? permissions on assets and the trust of permission relations between agents.

1) Instantiate Assets: Each instance of an asset is identified with its sensitivity level. The identification is based on the rules given in Table VII. A1 states that if a security property holds for a service at organizational level, this property should hold for each instance of that service. A2 associates a sensitiv- ity level to an asset instance: the asset instance has the same sensitivity of the asset at organizational level. A3 determines if a service instance is an asset: a service instance is an asset if there is a security property that holds for the service instance and the service instance has sensitivity level.

Example 7. Prescription is an asset owned by the role Patient. The Patient role is played by the agents Bob, Kate, Jane, thus each of them owns one of the following instances of Prescription:  ? asset instance(service instance(Prescription,Bob,Patient), Bob,Patient),  ? asset instance(service instance(Prescription,Kate,Patient), Kate, Patient),  ? asset instance(service instance(Prescription,Jane,Patient), Jane, Patient).

2) Istantiate Permissions on Assets: This steps identifies the permissions that agents have on assets. A4 states that an agent playing a role inherits the permissions that the role is granted on assets.

Example 8. The Pharmacy role delegates the manage permission on PComputer to role Drug Manager. Since the Pharmacy is played by the agent Pharmacy San Raffaele, and the Drug Manager is played by agents Ellen and Mary, Ellen and Mary are granted the manage permission on the instance of PComputer owned by Pharmacy San Raffaele.

3) Istantiate Trust of Permissions relation: In this step the trust of permission relationship between agents owning assets and agents having permissions on their assets are identified.

This implies to determine the level of trust that the owner places in the other agent for the granted permission: the trust value can be already given or it can be computed based on a trust chain as described in Section IV.

Example 9. At organizational level the Pharmacy trusts the role Drug Manager with the manage permission on Prescription. This relationship needs to be instantiated for each instance of Prescription asset and each agent play- ing the Pharmacy and Drug Manager roles. Let suppose that we want to instantiate the trust of permission relation- ships for the Prescription instance owned by Bob - as- set instance(service instance(Prescription,Bob,Patient), Bob, Patient). Bob trusts good both Pharmacy Saint Claire and Pharmacy San Raffaele with the access permission on asset instance(service instance(Prescription,Bob,Patient), Bob, Patient). On their turn, Pharmacy San Raffaele and Pharmacy Saint Claire places the following trust levels in the agents Dr Alex and Dr Stefano for the access permission on asset instance(service instance(Prescription,Bob,Patient, Bob, Patient)): ? trust perm instance(Pharmacy Saint Claire, Dr Ste-  fano,asset instance(service instance(Prescription,Bob, Patient), Bob, Patient), access, neutral)  ? trust perm instance(Pharmacy San Raffarele, Dr Alex,asset instance(service instance(Prescription,Bob, Patient), Bob, Patient), access, good)     The trust of permission relations between Bob and Dr Alex and Bob and Dr Stefano can be computed as described in Example 3. As result of the computation the following trust of permission relationships can be added to the ASP formalization of the SI* model: ? trust perm instance(Bob, Dr Stefano, as-  set instance(service instance(Prescription,Bob,Patient), Bob, Patient), access, neutral) and  ? trust perm instance(Bob, Dr Alex, as- set instance(service instance(Prescription,Bob, Patient), Bob, Patient), access, good).

E. Detecting Insider Threats  We assume that an agent A is an insider for a given asset S when two conditions hold:  a) A is granted a permission PT on the asset S that is sufficient to violate the security property associated with S;  b) The agent who owns the resource S does not fully trust A with permission PT .

We introduce a threat predicate to specify when an agent is an insider for a given instance of an asset and the risk associated with the insider threat.

Fig. 3. Risk Levels  Typically, the risk associated with a threat is given by the probability that a threat occurs and the severity of the threat. Here, we determine the level of risk associated with the threat initiated by an agent A based on two dimensions: the sensitivity of the asset S and the trust level with which A is granted the permission PT . The sensitivity quantifies the cost of the threat by A, while the trust level quantifies the likelihood that the threat occurs. Intuitively, higher is the sensitivity of the asset S, higher is the damage for the organization. Similarly, higher is the trust level, lower is the likelihood that the agent will misuse the granted permission [9].

Figure 3 is an example of how the risk level of a threat can be determined based on sensitivity and trust levels. The rows of the table represent the trust levels, while the columns represent the sensitivity levels. Each entry of the matrix specifies the risk level for a given combination of sensitivity and trust levels.

The risk level can assume one of the following values: Low, Moderate, High, Extreme. How trust and sensitivity relates to each other depends on the organization?s policy and should not be fixed beforehand.

The identification of the insider threats and their risk level is based on a set of axioms reported in Table VIII. Due to the lack of space, we list only the axioms to detect insider threats to assets? confidentiality, integrity and availability with extreme risk level. Axioms T1.a - T1.c identify insider threats to confidentiality: the insider has access permission on the asset being harmed and the owner of the asset places very bad, bad or neutral trust level in the insider for the granted permission. Axioms T2.a - T2.c allow to detect insider threats to integrity: in this case the insider needs to be granted a modify permission on the asset and the owner places very bad, bad or neutral trust level for the granted permission. Axioms T3.a - T3.c identifies insider threats to availability.

The modeling and the reasoning based on the above axioms are supported by the SI* tool which is an Eclipse plug-in equipped with a DLV engine. The tool interface allows to draw an SI* model which is automatically translated into ASP specification. The tool also allows to input the rules for insider threat identification so that the problem of identifying insider threats is the same as checking a DLV program that formalize the SI* model and the axioms.

Example 10. Let us assume we want to determine all the possible insiders for the instance of Prescription asset owned by the Patient Bob. The reasoning reports the following insiders:  ? threat(Dr Stefano,asset instance(service instance(Prescription, Bob, Patient),Bob,Patient), confidentiality, moderate)  ? threat(Dr Alex,asset instance(service instance(Prescription, Bob, Patient),Bob,Patient), confidentiality, moderate)  ? threat(Ellen,asset instance(service instance(Prescription, Bob, Patient),Bob,Patient), confidentiality, moderate)  ? threat(Mary,asset instance(service instance(Prescription, Bob, Patient),Bob,Patient), confidentiality, high)  ? threat(Ellen,asset instance(service instance(Prescription, Bob, Patient),Bob,Patient), availability, moderate) threat(Mary,asset instance(service instance(Prescription, Bob, Patient),Bob,Patient), availability, high)  Dr Stefano and Dr Alex are two insiders which represent a moderate risk to the confidentiality of Prescription instance owned by Bob because they have been granted access permission on the asset instance and they are trusted good for such permission by Bob. Ellen and Mary are insiders to both the confidentiality and the availability of Prescription asset owned by Bob because the following conditions hold: ? the asset instance is stored in the instance of PComputer  owned by the Pharmacy Saint Claire and Pharmacy San Raffaele  ? Pharmacy Saint Claire trusts good Ellen with the man- age permission on the instance of PComputer owned by the Pharmacy San Raffaele  ? Pharmacy San Raffaele trusts bad Mary with the man- age permission on the instance of PComputer owned by the Pharmacy San Raffaele  ? Ellen and Mary thus have the same permission on the Prescription asset owned by the Patient Bob stored in     TABLE VIII AXIOMS FOR IDENTIFICATION OF INSIDER THREATS  Insider Threat to Confidentiality  T1  a threat(A1, asset instance(service instance(S,A, P ), A, P ), confidentiality,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), confidentiality, A, P ) ? permission instance(A1, service instance(S,A, P ), access) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ), access, very bad) ?A1 ?= A b threat(A1, asset instance(service instance(S,A, P ), A, P ), confidentiality,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), confidentiality, A, P ) ? permission instance(A1, service instance(S,A, P ), access) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ), access, bad) ?A1 ?= A c threat(A1, asset instance(service instance(S,A, P ), A, P ), confidentiality,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), confidentiality, A, P ) ? permission instance(A1, service instance(S,A, P ), access) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ), access, neutral) ?A1 ?= A  Insider Threat to Integrity  T2  a threat(A1, asset instance(service instance(S,A, P ), A, P ), integrity,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), integrity, A, P ) ? permission instance(A1, service instance(S,A, P ),modify) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ),modify, very bad) ?A1 ?= A b threat(A1, asset instance(service instance(S,A, P ), A, P ), integrity,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), integrity, A, P ) ? permission instance(A1, service instance(S,A, P ),modify) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ),modify, bad) ?A1 ?= A c threat(A1, asset instance(service instance(S,A, P ), A, P ), integrity,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), integrity, A, P ) ? permission instance(A1, service instance(S,A, P ),modify) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ),modify, neutral) ?A1 ?= A  Insider Threat to Availability  T3  a threat(A1, asset instance(service instance(S,A, P ), A, P ), availability,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), availability, A, P ) ? permission instance(A1, service instance(S,A, P ),manage) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ),manage, very bad) ?A1 ?= A b threat(A1, asset instance(service instance(S,A, P ), A, P ), availability,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), availability, A, P ) ? permission instance(A1, service instance(S,A, P ),manage) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ),manage, bad) ?A1 ?= A c threat(A1, asset instance(service instance(S,A, P ), A, P ), availability,extreme)? asset instance(service instance(S,A, P ), A, P ) ? sec req instance(service instance(S,A, P ), availability, A, P ) ? permission instance(A1, service instance(S,A, P ),manage) ? sensitivity instance(service instance(S,A, P ),very high, A,P ) ? trust perm instance(A,A1, asset instance(service instance(S,A, P ),manage, neutral) ?A1 ?= A  the instances of PComputer owned by Pharmacy Saint Claire and Pharmacy San Raffaele respectively  ? having the manage permission on an asset implies to have also the access permission on an asset  ? Ellen and Mary are trusted Bob good and bad with the manage permission on the instance of Prescription owned by Bob  ? manage permission is sufficient to violate the availability of a given asset while the access permission is sufficient to violate the confidentiality of an asset.



VI. RELATED WORK  Several proposals have attempted to include security analy- sis into the requirement analysis process. Among goal-oriented approaches, van Lamsweerde extends KAOS by introducing the notions of obstacle [10] and anti-goal [11] in order to anal- yse the security concerns of a system. KAOS obstacle captures an undesired state of affairs that might harm safety goals (i.e., hazard) or threaten security goals (i.e., threat), while KAOS anti-goal captures the intention of an attacker. The authors propose a formal framework to identify the obstacles to a goal in a given domain properties and to generate resolutions to  those obstacles. Liu et al. [12] propose an extension of the i* framework [13] to identify attackers, and analyse vulnera- bilities through actor?s dependency links. In this framework, all actors are considered as potential attackers. Therefore, their capabilities are analysed and possible damages caused by actors are assessed. In Li et al. [14], the authors proposed a formal framework to support attacker analysis. Similarly, Elahi et al. [15] propose i* extensions to model and analyse the vulnerabilities affecting systems requirements. Matulevic?ius et al. [16] extend the Secure Tropos [17] language to support modelling of security risks and their countermeasures. For that purpose, the authors analyse the concepts and syntax of Secure Tropos and propose some extensions in order to fill the gap required to align this language with the Information System Security Risk Management (ISSRM) model.

Our approach, unlike the previous approaches, supports an automatic reasoning to identify possible insider threats based on the model formalization which can provide a valuable input (i.e. list of prioritized threats) to these frameworks in order to perform further risk assessment.

Other works focus on integrating risk analysis into the requirement analysis process. SQUARE [18] and SREP [19]     are two similar processes that support risk assessment as an explicit step to identify security requirements. Asnar et al. [20] propose a concrete methodology, namely the Goal- Risk framework, to analyse and model security problems. The methodology relies on SI* requirements modeling language to capture stakeholders? goals, risks that might threaten the goals, and countermeasures required to mitigate the unacceptable risks. In [4], Asnar extended SI* with the possibility of spec- ifying permissions and relationships on resources. Based on these extensions, they propose a reasoning to identify threats to resources that occur because roles representing classes of stakeholders of a system misuse their privileges. In our work, we extend this work by adding an asset model and a trust model to identify agents - instances of stakeholders of the system - that may cause harm to organizational assets and to prioritize them based on the risk for the organization.

Li et al. [21] propose a security analysis that verifies that a set of security properties like availability and safety are satisfied while delegating access to resources to partially trusted principals. Similarly to us, they consider that delegating permissions on resources to not fully trusted entities can be a source of threats.



VII. CONCLUSION AND FUTURE WORK  This paper proposes a framework to support security engi- neers in identifying insider threats during the security require- ments analysis phase of a socio-technical system development life cycle. Our framework provides security engineers with a reasoning that automatically produces a list of possible insiders for organizational assets and the risk they may represent to the organization. The reasoning determines if an agent is an insider for an asset and the risk he/she brings about, based on the sensitivity of the asset, the security property specified for it, the permission assigned to the agent on the asset, and the level of trust the asset owner places in the agent for the granted permission. Once the insider threat is identified, the organization is responsible for taking the necessary countermeasures.

We are aware that our framework has some limitations.

First, the validity of the results of the reasoning strictly de- pends on the quality and completeness of the SI* model, which in turn depends on the level of expertise of the requirements engineer. Second, the visual notation of SI* might not scale well for complex application scenarios.

We are planning to evaluate the strengths and limitations of our framework by conducting a controlled experiment where master students and professionals apply the framework to a real industrial application scenario.

ACKNOWLEDGEMENTS  This work has been partially funded by the European Commission through the FP7 project NESSoS under grant agreement number 256980. The third author is funded by the Spanish Ministry of Education through the National F.P.U.

Program.

