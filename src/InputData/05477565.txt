A Fuzzy Weight Algorithm for Mining Infrequent Association Rules

AbstractThe paper introduces the conception of significance  and presents a new algorithm?a fuzzy weight algorithm with  multiple supports for mining association rules, which is based  on fuzzy-comprehensive evaluation and the algorithm of  multiple minimum supports. The new algorithm takes support  and significance into consideration at the same time when large  itemsets are produced, making the filter criterion more  reasonable and not missing items with high significance but  low supports.

Keywords-data mining; association rules; weight algorithm  with multiple supports; fuzzy-comprehensive evaluation

I.  INTRODUCTION  In the domain of data mining, Apriori algorithm is the  most typical algorithm to mine association rules. Users must  set two important parameterssup (minimum support) and  conf (minimum confidence) before they make use of Apriori  algorithm [1]. Mining association rules can be divided into  two phases: (1) in a transaction database, finding maximum  large itemset that is composed of those items, the supports of  which are not smaller than minimum support; (2) association  rules are induced from the large itemsets found in the first  phase. The first phase is the key step in the process of mining  association rules. Therefore, how to get maximum large  itemset reasonably becomes a hot spot researched by many  scholars [2].

The choice of minimum support decides whether  association rules are useful [3]. Generally speaking, most  algorithms of mining association rules only set a single  minimum support. But items with different natures can not  be described comprehensively only by a single minimum  support. For example, in order to mine association rules  containing items with low supports, we must make the  minimum support become low enough. But many    meaningless association rules related to items with high  supports will be produced. On the other hand, if we make the  minimum support become high enough, we will miss  important association rules related to items with low supports  [4].

To solve the dilemma mentioned above, scholars have  presented many algorithms with multiple supports for mining  association rules, which can set different minimum supports  for different items and can mine association rules related to  important items with low supports [5]. However, those  algorithms do not involve certain natures of items and these  natures can not be reflected only by supports; therefore some  potential association rules will be missed.



II. AN ALGORITHM WITH MULTIPLE SUPPORTS FOR  MINING ASSOCIATION RULES  Obviously, setting a single minimum support for  different items is not reasonable. In order to mine more  useful association rules, setting different minimum supports  for different items is necessary [6]. Based on Apriori  algorithm, B.Liu and other scholars presented an algorithm  with multiple supports for mining association rules, which is  named MSM algorithm for short [7].

The difference between MSM algorithm and Apriori  algorithm is the definition of minimum support. In MSM  algorithm, minimum support of an association rule is defined  as the minimum value of minimum supports of all items  appearing in the association rule. The minimum support of  an item is defined as minimum item support, which is named  MIS for short. In MSM algorithm, we can set high minimum  supports for items appearing frequently and set low  minimum supports for items that is important but appears  infrequently. MSM algorithm can be described as follows [8]:  (1) Computing the support of every item, marked as Sk  (k= 1,,m);  (2) For the kth item, comparing values of Sk and MISk  (k= 1, ?,m), if Sk?MISk (k= 1,?,m), the item is put into  large 1-itemset L1. L1= {tk|Sk?MISk (k= 1,?,m)}, the kth  item is marked as tk;  (3) Assuming the length of an itemset is marked as r;  (4) For (r= 1; Lr? ? ; r++};  (5) Producing candidate (r+1)-itemset Cr+1 from Lr. The  support of every item in an itemset of Cr+1 is not smaller than    the maximum value of minimum supports of related items.

The process of producing Cr+1 is similar to that of Apriori  algorithm;  (6) Computing the support of every itemset in Cr+1,  marked as S1k;  (7) To every itemset in Cr+1, comparing its support and  the maximum value of minimum supports of related items, if  the former is not smaller than the latter, the itemset will be  put into Lr?1;  (8) Through the loop computation, maximum large  itemsetL will be obtained;  (9) If CONk? conf, the association rule is effective; or  else, remove it. The confidence of the kth association rule is  marked as CONk.

From MSM algorithm, it can be concluded that when we  compute L1, because of multiple supports, important items  with low supports will not be missed. When we compute  _____________________________________  978-1-4244-5265-1/10/$26.00 2010 IEEE  Lk+1 from Ck?1(k? 1), if the support of an itemset in Cr+1 is  not smaller than the maximum value of minimum supports of  related items, the itemset will be put into Lk+1. This process  can be seen in step (7).

However, some itemsets containing important items with  low supports are still removed too early. For example, in a  transaction database, we can assume the support and  minimum support of DVD are 0.4 and 0.3 respectively; the  support and minimum support of TV set are both 0.1. When  we make use of MSM algorithm, DVD and TV set will be  put into L1 at the same time; when we compute L2, the  support of itemset {DVD, TV set} is smaller than 0.1  (because the support of TV set is 0.1), but the maximum  value of minimum supports of related items is 0.3. So the  itemset {DVD, TV set} will be removed and we can not  mine any association rules related to TV set.

Since the profit of 100 pieces of bread is smaller than that  of a TV set, losing an itemset containing valuable items so  easily does not accord with users purpose. The reason is  that taking support as the single criterion to produce large  itemsets can not represent all natures of items that are  concerned by users.

Although MSM algorithm can mine association rules    related to items with low supports, it is bound to miss  association rules related to important items with low supports.

Because it only takes support into consideration, but does not  involve other natures of items.



III. A FUZZY WEIGHT ALGORITHM WITH MULTIPLE  SUPPORTS FOR MINING ASSOCIATION RULES  In order to overcome disadvantage of the algorithm  above, based on MSM algorithm, we present a new  algorithmfuzzy weight algorithm with multiple supports  for mining association rules, which is named FWMSM  algorithm for short. Compared with MSM algorithm,  FWMSM algorithm takes support and significance into  consideration at the same time. Significance, which involves  multi-attribute of an item, represents the importance of an  item. Some attributes are quantitative and others are not  quantitative but only a fuzzy conception.

Fuzzy-comprehensive evaluation, making use of fuzzy  set theory, can be applied in evaluating complex objects with  multi-attribute [9]. Therefore, fuzzy-comprehensive  evaluation can be used to compute significance of items. To  an evaluation problem, following parameters are involved:  evaluation factor set U?{u1,u2,?,um}, evaluation set V?  {v1,v2,?,vn}, evaluation factor weight b?{W1,W2,?,Wm}.

Process of fuzzy-comprehensive evaluation can be described  as follows: (1) specifying values of related parameters; (2)  computing fuzzy product of U?V; (3) giving a value for  every element in evaluation set, c? {c1,c2,? ,cn}; (4)  computing significance. Through the process, significance of  the kth item can be transformed to a numerical value?  signif(ik), which is a comprehensive evaluation value and can  reflect multiple natures of items. So it can be used as weight  value in FWMSM algorithm.

Similar to MSM algorithm, in FWMSM algorithm,  minimum support is still the threshold to judge whether an  itemset in Ck can be put into Lk. Assuming the kth item is  marked as ik, I= {i1,i2,i3,?, im} represents an itemset; MIS(ik)  represents minimum support of ik; sup(ik) represents the  support of ik; and signif(ik) represents significance of ik.

Assuming the ith transaction is marked as ti, ti= <TID, T>,  TID represents transaction No., n represents the number of  transactions in the transaction database, and T I? . Only if  ( sup) signif ( ) ( )    k k  k k  i I i I  n i MIS i  ? ?

?? ?  , can it be put into large  itemsets. FWMSM algorithm can be described as follows:    Algorithm: FWMSM algorithm  Input: a transaction database, MIS(I) and signif(I)  Output: maximum large itemset  1. k= l;  2. M= {{a}| a?I}, n= transaction.count;  3. for all transactions t?Database D  4. for all items c? t  5. if c?M then  6. c.count++;  7. L1= (c | c.count c.signif? c.MIS);  8. while (Lk? ? ) do  9. k++;  10. Use the function of Apriori_gen(Lk-1) to generate  candidate k-itemset, Ck;  11. for all transactions t?D do  12. Ct= subset(Ck, t);  13. for all candidates c?Ct do  14. c.count++;  15. end  16. Lk= {c?Ck | c.count c.signif? c.MIS};  17. end  18. Answer=  k  LU .

Algorithm: Generate_candidate(Lk-1)  1. Insert into Ck;  2. Select p.item1, p.item2, ??, p.itemk-1, and q.itemk-1  3. form Lk-1 p, Lk-1 q  4. where p.item1= q. item1, ??, and p.itemk-2= q.itemk-2  and p.itemk-1 < q.itemk-1;  5. for each itemset c?Ck do  6. for each (k-1)-subset s? c do  7. if(c[item1]? s) or ((c[item1]? s) and (c[item1].MIS=    c[item2].MIS))  8. if (s?Lk-1)  9. Delete c from Ck;  10. end  11. end  12. end  13. end  14. Return Ck.

Algorithm: Subset(Ck, t) procedure  1. for each itemset c?Ck  2. if c? t  3. Ct= U{C};  4. end  5. end  6. Return Ct.

In FWMSM algorithm, from the third row to the seventh  row, L1 is produced. M represents items that users are  concerned with in the transaction database. From the tenth  row to the eighteenth row, L is produced. In order to reduce  scan time, Ct is used to analyze whether Ck exists in Lk-1. In  the eighteenth row, large itemsets produced before is saved.

Procedures of Generate_candidate() and Subset() are used to  deal with reduction of candidate itemsets and related subsets.



IV. EXPERIMENTS: THE CASE OF FWMSM ALGORITHM  In order to illuminate FWMSM algorithm more clearly,  in this section we will use a case to analyze it. Taking  commodity X for example, we will demonstrate the process  of computing significance. For every commodity,  businessmen not only attach importance to its profit, but also  pay attention to brand effect and other soft profits. When  we use fuzzy-comprehensive evaluation to compute  significance of X, profit and brand effect can be chosen as  evaluation factor set, U= {profit, brand effect}. Of course,  we can also choose other factors to constitute evaluation  factor set. Evaluation set consists of five evaluation grade, V  ? {excellent, good, common, bad, awful}. The weight value  of profit and brand effect can be marked as a? {0.85, 0.15}.

At last, a quantitative value for every element in evaluation  set is given, c? {1, 0.7, 0.5, 0.3, 0.1}. We can assume 20  percent of X have ?bad grade? profit, 80 percent of X  have ?awful grade? profit: A profit? (0/excellent, 0/good,    0/common, 0.2/bad, 0.8/awful). Similarly, Abrand effect ?  (0.1/excellent, 0.2/good, 0.5/common, 0.1/bad, 0.1/awful).

So we can get a fuzzy matrix:  0 0 0 0.2 0.8  0.1 0.2 0.5 0.1 0.1  R =  ? ?? ?? ?

The comprehensive evaluation of X can be described as  follows: b= a?R= (0.015, 0.03, 0.075, 0.185, 0.695). And  significance of X can be described as follows: d= cbT=  0.1985.

Commodity information and transaction records in the  transaction database are described in table I and table II  respectively.

Firstly, through scanning table II, we can compute the  support of every commodity. Secondly, we compute the  product of nsupport and significance of a commodity,  which is described in nsupportsignif column of table III.

Thirdly, for every item, comparing the values of  nsupportsignif and MIS, if nsupportsignif ? MIS, the  item is put into large itemsets. Similar to Apriori algorithm,  L1 is produced, and then, C2L2C3L3?are produced  subsequently. Finally, maximum large itemset contains {B,  C} and {B, E}. So association rules and their confidence can  be described in table IV. Assuming minimum confidence is   , two association rules are produced: C?B and E?B.

From the result, we can see commodity C, which has low  support and high significance, is put into L2 and is contained  in association rules. However, if we make use of ordinary  MSM algorithm, those association rules containing C, will  be missed.

TABLE I.  COMMODITY INFORMATION  commodity No. significance MIS  A 0.05 0.2  B 0.15 0.3  C 0.4 0.2  D 0.05 0.4  E 0.2 0.2  ? ? ?      TABLE II.  TRANSACTION RECORDS  transaction No. transaction items  001 ABD  002 ABE  003 BC  004 AE  005 BDE  ? ?    TABLE III.  PROCESS OF PRODUCING L1  item signif nsupport nsupport signif MIS L1  A 0.05 3 0.15 0.2 B  B 0.15 4 0.6 0.3 C  C 0.4 1 0.4 0.2 E  D 0.05 2 0.1 0.4 -  E 0.2 3 0.6 0.2 -    TABLE IV.  ASSOCIATION RULES  association rules confidence  B?C 25%  B?E 50%  C?B 100%  E?B 66.7%

V. CONCLUSION  FWMSM algorithm can be used to produce subject-  oriented, more useful association rules. It mainly has three  characters: (1) fuzzy-comprehensive evaluation is used to  compute significance, which can comprehensively reflect  natures of item with multi-attribute; (2) when maximum  large itemset is produced, support and significance are taken  into consideration at the same time, making the filter  criterion more reasonable; (3) under the subject users are  concerned with, important items with low support will not be  missed easily.

