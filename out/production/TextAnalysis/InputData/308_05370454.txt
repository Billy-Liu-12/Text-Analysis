The Optimization of Apriori Algorithm Based on Directed Network

Abstract?Association rule mining is an important topic in data mining field. On the basis of the association rule mining and Apriori algorithm, this paper proposes an improved algorithm based on the directed network. It reduces consumption and improve the efficiency of algorithms by reduce scanning datasets and improving the efficiency of the pruning step. Finally, this paper gives an experiment to analyze and compare the difference between the two algorithms and the result shows that the improved algorithm promotes the efficiency of computing.

Keywords-association rule; Apriori algorithm; Directed Network; Distance Matrix; Path

I.  INTRODUCTION Association rules mining was first proposed by Agrawal,  Imielinski, and Swami [1] [2]. And it finds interesting relationships among itemsets in a given set of data items.

Apriori is an influential algorithm for mining frequent itemsets for Boolean association rules [3]. Apriori employs an iterative approach known as a level-wise search. However, it may repeatedly scan the dataset for pattern matching and generate a huge number of candidate itemsets in the case of large database [4].

There are many scholars have advanced some improved algorithm to resolve the disadvantage of the Apriori algorithm [5][6][7][8].In this paper we implemented an improved algorithm for Apriori based on directed network. The rest of the paper is organized as follows. Section 2 introduces Apriori algorithm. Section 3 introduces the directed network and presents our improved algorithm. Section 4 presents the experimental results of the improved algorithm and analyzed its performance. Section 5 summarizes the paper.



II. APRIORI ALGORITHM Let D the task-relevant data, be a set of database  transactions where each transaction T is a set of items, called Tid. Let I= {I1, I2,?, Im} be a set of items. An itemset contains k items is a k- itemset. If a k-itemset satisfies minimum support (Min_sup) then it is a frequent k-itemset, denoted by Lk. Firstly Apriori algorithm generated a set of candidates, which is candidate k-itemsets, denoted by Ck. If the candidate itemsets satisfies minimum support then it is frequent itemsets.

Description of the algorithm:  (1)Suppose a minimum support threshold(Min_sup) and a minimum confidence threshold  (Min_conf)[9]?  (2)Scan the dataset, candidate 1-itemsets, C1, and the number of occurrences of each item is determined. The set of frequent 1-itemsets, L1, is then determined, consisting of those candidate 1-itemsets in C1 having minimum support. The algorithm uses L1 ? L1 to generate candidate 2-itemsets, C2.

(3)Scan the dataset again, frequent 2-itemsets, L2, is then determined, consisting of those candidate 2-itemsets in C2 having minimum support. Candidate 3-itemsets, C3 is then generated by L2 ? L2.

(4)Repeatedly scan the dataset, compare the support count of each candidate in Ck-1 with Min_sup, and then generate Lk-1 , join Lk-1 ? Lk-1 to generate Ck until no more candidate itemsets.

A two-step process is used to find the frequent itemsets: join and prune actions.

a) The join step: To find Lk, Ck is generated by joining Lk-1 with itself if member l1 and member l2 are joined.

b) The prune step: The members of Ck may not be frequent.

A scan of the database to determine the count of each candidate in Ck, and use Lk-1 to remove a candidate k-itemset from Ck would result in the determination of Lk.

In many cases the Apriori candidate generate-and-test method reduces the size of candidate sets. However if mining a large set of database, the Apriori algorithm will produce overfull candidates of frequent itemsets, so the algorithm needs scan database frequently when finding frequent itemsets. And it will take more resource and time to accomplish one scanning.

So it must be inefficient.



III. ALGORITHM BASED ON THE DIRECTED NETWORK  A. Directed Network Graph [10] [11] is a sort of complicated non linear  structure. Graphs are used to solve problems in many fields, such as artificial intelligence, mathematics, physics, chemistry, biology and computer science.

A directed graph G = (V, E) consists of a finite set of V (V ??) of vertices and a finite set of E of edges that are ordered pairs of elements of V, denoted as V (G) and E (G). Each directed edges e=< vi, vj > of G has a number wij (wij>=0) is called directed network (or weighted graphs).

The distance matrix Dn?n= [dij] of the directed network G is defined as follows:  2009 Third International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2009.56   2009 Third International Symposium on Intelligent Information Technology Application  DOI 10.1109/IITA.2009.56     ? ? ?  ? ?=?=  else Evveedgedirectedw jiij ,,dij  (1)  The Path is the set of paths in the directed network G = (V, E), a path is defined as a road from vi to vj in a graph with directed edges.

B. The improved algorithm The improved algorithm only scans the dataset D once,  find the directed network G, where the set of vertices V register the itemset, namely V (G) =I; the set of edges E register the edges   which are composed by the pair of items in a transaction, E(G)= <Ii, Ij>; the weight of each edge is the support count of each edge which get when scan the dataset D; the set of paths P register the longest path in each transaction and its support count. We get the frequent itemsets by the distance matrix and path searching. By convention, the improved algorithm assumes that items within a transaction or itemset are sorted in lexicographic order.

Enter: dataset D, itemset I and the minimum threshold of support Min-sup.

Output: all the frequent itemsets L.

Method: (1) Scan the dataset D; // without frequent 1-itemset (2) G=(V,E),  Dn?n=[dij]?Path (3) for each dij { (4) if wij>=Min_sup then add dij to L2 (5)} (6) for (i=3;|Li-1|>1;i++){//more than one itemset in Li-1 (7)  Li= gen_freq(Path, Li-1, Min_sup);  ?get the frequent itemsets (8)} (9) return L=?i Li;  Procedure gen_freq (Path, Li-1, Min_sup)  // for join and prune (1)for each itemset l1?Li-1 (2) for each itemset l2?Li-1 (3)         if l1?l2 then{ (4)               l= (l1[1], l1[2],?, l1[i-1], l2[i-1]); //path (5)  if judge_frequent (l, Path) then (6)    add l to Li; (7)  else delete l ;  //prune (8)         } (9) return Li;  Procedure judge_frequent (l, Path) (1)if (l?Path)?(wl>=Min_sup) then  //find the path l and its support count (2)  return true; (3) else return false;  An example of the algorithms is given below. Suppose the  minimum support count Min_sup=2. Transaction dataset D is shown in Fig.1 (a). The algorithm is as follows.

First, the improved algorithm scans all the transaction records in the dataset to obtain G, D5?5 and Path (Fig.1 (b), (c), (d)). By comparing the weight wij in the D5?5 with the Min_sup, we can obtain frequent 2-itemset directly. Obviously the improved algorithm is not need to scan the dataset for frequent 1-itemset, so the efficiency to generate frequent itemsets is improved.

Then the candidate 3-itemsets is determined by L2?L2.

C3= {{I1, I2, I3}, {I1, I2, I5}, {I1, I3, I5}, {I2, I3, I4}, {I2, I3, I5},{I2,I4,I5}}. The support count of the path {I1, I2, I3} is 1 and it is also included in path {I1, I2, I3, I5}, so its total support count is 2, it is frequent. The path {I1, I3, I5} is just included by the path {I1, I2, I3, I5}, so its support count is 1, it is not satisfying the Min_sup, so it is pruned. All the support counts of the paths are listed in Fig.1 (d). The frequent 3- itemset L3 is determined.

The candidate 4-itemsets is determined by L3 ? L3, C4={{I1, I2, I3, I5}}. The support count of the path {I1, I2, I3, I5} is 1, not satisfying the Min_sup, so it is pruned. Then the algorithm is end.

Figure 1.  Example of the algorithm  The improved algorithm prunes the candidate itemsets by the paths of G, it need not scan the whole dataset repeatedly.

Therefore, the efficiency is improved by cutting down the times that spend on scan the dataset.



IV. EXPERIMENTS In order to evaluate the performance of the proposed  algorithm, we program with MATLAB [12] to realize the two algorithms. Then we compared them in the same condition.

The test condition is: P4 2.0 CPU; 1G DDR; 80G HD and Windows XP-sp2 professional OS. The data source of our experiments is one flight data of B737-300, contains 8352 records.

From Fig.2, we can know the comparative result of Apriori algorithm and the improved algorithm in the execution speed.

The minimum support is Min_sup=0.2. Under the same conditions, if the transactions in datasets are increasing, the executive time of Apriori algorithm and this algorithm will increase, but the slope of this algorithm is less than the slope of Apriori algorithm, the increaser of this algorithm is less than the increaser of Apriori algorithm. So the diffusibility of this algorithm is better than the diffusibility of Apriori algorithm.

Fig.3 compares the performance of the two algorithms under the conditions of different support levels by using 3000 transactions. When the support level is high, both algorithms are less time-consuming because the number of iterations is small. However, the efficiency disparities of the two algorithms get larger as the support level falls. The improved algorithm takes near constant time to discover frequent itemsets and shows much greater efficiency than the Apriori algorithm.

0 1000 2000 3000 4000 5000 6000 7000 8000            Transctions  E xe  cu tio  n tim  e( m  s)      DN Apri  Apriori    Figure 2.  Running time comparisons (Min_sup=0.2)  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1            Support (%)  E xe  cu tio  n T  im e(  m s)      DN Apri  Apriori    Figure 3.  Performance comparison on different support levels (transactions=3000)

V. CONCLUSIONS  The typical Apriori algorithm has performance bottleneck in the massive data processing. In this paper, our improved algorithm that based on directed network is proposed to mine the association rules from database. Our algorithm takes both efficiency and accuracy into account and it is proved and validated by experiment, so that we can mine association information from massive data faster and better.

