A Compression Algorithm for DNA that Uses  ASCII Values

Abstract- The properties of DNA sequences offer an opportunity to develop DNA specific compression algorithm. A lossless two phase compression algorithm is presented for DNA sequences. In the first phase a modified version of Run Length Encoding (RLE) is applied and in the second phase the resultant genetic sequences is compressed using ASCII values.

Using ASCII codes for eight bits ensures one-fourth compression irrespective of repeated or non-repeated behavior of the sequence and modified RLE technique enhances the compression further more. Not only the compression ratio of the algorithm is quite encouraging but the simple technique of compression makes it more interesting.

Keywords- Big data, Run length Encoding (RLE), ASCII, encode, decode, DNA, CUDA.



I. INTRODUCTION  Everyday 2.5 quintillion bytes of data is being created globally. This is called big data. Data sets grow in size in part because they are increasingly being gathered.  As data increases computational cost also increases for processing this data. The problem of storing large data generates two problems, the space required to store and the time for encoding and decoding. In recent couple of years 90% of data has been generated rapidly. To store and process data in an efficient way compression is the need of the day. File compression involves encoding information using fewer bits than the original representation. Compression techniques are closely related with type of files such as text, image, audio, and video. The techniques used to compress the data of text files may not be applicable for image or audio files. The different algorithms for compression have different characteristics. Few examples of compressors are WinZip, JPEG, MPEG, quantization that are already in place and very commonly used. Compression can be of two types either lossy or lossless. Lossless compression technique reduces bits by identifying and eliminating statistical redundancy. No information is lost in lossless compression. Examples of lossless compression preferably used for text data are gzip, Shannon-fano coding, Huffman coding, arithmetic coding, adaptive Huffman coding. Lossy compression reduces bits by removing redundant information from images, video, or  audio by discarding data that the human perceptual system cannot see or hear. Lossy compression can be applied to image, audio and video.  Lossless compression is used for text files such as DNA where every character is meaningful and hence any change means data does not remain useful.

The most commonly used human genomic data available in public database such as GenBank is a vast data and increasing exponentially. GenBank is a part of the International Nucleotide Sequence Database Collaboration, which comprises the DNA DataBank of Japan (DDBJ), the European Molecular Biology Laboratory (EMBL), and GenBank is provided by at NCBI (National Center for Biotechnology Information). These three organizations exchange data on a daily basis. Deoxyribonucleic Acid (DNA) is a molecule that encodes the genetic information.

DNA sequences are huge in size makes its compression a challenging task.  The DNA strand contains four nucleotide bases adenine, cytosine, guanine, and thymine. Therefore DNA sequences are the combinations of only four bases (A, C, G, T). DNA sequences convey meaningful information about diverse organisms. These biological sequences are either repetitive or non-repetitive but do not contain completely random data and therefore offers an opportunity for compaction. General text compression algorithms can have an adverse effect on the size of biological sequences.

Specific algorithms have been developed for compression of DNA sequences.

Plan of paper: This paper is organized as follows. Section II describes general compression algorithms. Section III describes related existing algorithms to compress genome data. Section IV explains the methodology of the proposed algorithms.

Section V illustrates results and discussions. Section VI concludes and offers a newer direction for future work.



II. GENERAL COMPRESSION ALGORITHMS  Considering the structure of DNA sequence particular methods are suitable. BioCompress and Biocompress-2 were the first DNA specific compression algorithms. Since then     many DNA compression algorithms have been developed such as Cfact, Gencompress, CTW+LZ, DNA Compress, DNAC, DNA sequitur, DNA Pack, DNABIT Compress.

Biocompress [1] is based on searching an approximate repeat and palindromes. Biocompress uses two bits to encode the non repeat subsequence. Biocompress-2[2] uses a Markov model of order two to encode the non repeat regions of the sequence. Cfact [3] searches for the exact repeats which are longest in the sequence. It builds the suffix tree of the sequence in the first pass and does the actual encoding in the second pass of the sequence. Non repeat regions of the sequence are encoded by 2-bits per symbol. Gencompress [4][5][6] searches the approximate repeats using edit operations such as mutation, insertion, deletion. CTW+LZ [7] encode the long repeats by substitution method. It encodes the short and non repeat regions of the sequence by context tree weighing. DNA Compress [8] employs the Ziv Lempel compression technique. It works in two phases. In the first phase it finds all the approximate repeats in the sequence including complimentary palindromes, using software Pattern Hunter [9]. In the second phase approximate repeats and non repeat regions of the sequence are encoded. DNAC [10] is a DNA compression tool which works in four phases. In first phase it builds a suffix tree to locate the exact repeats of the sequence. In the second phase all exact repeats of the sequence are extended into approximate repeats by dynamic programming. It extracts the optimal non-overlapping repeats from overlapping ones in the third stage. In the final stage it encodes all the repeats.

DNA Sequitur [11] is a grammar based compression algorithm. It uses a context free grammar to represent input data. DNA Pack [12] uses Hamming distance for repeat regions and complimentary palindromes of the sequence. It employs either CTW or arithmetic-2 compression for non- repeat regions. It uses a dynamic programming approach.

DNABIT [13] compress assigns binary bits for smaller segments of sequence to compress both repetitive and non- repetitive regions.



III. RELATED EXISTING ALGORITHMS  Run-length encoding (RLE) is a very simple form of data compression in which runs of data (that is, sequences in which the same data value occurs in many consecutive data elements) are stored as a single data value and count, rather than as the original run. For example: AAAAACCGGGTTTT is encoded using run length encoding as 5A2C3G4T

IV. PROPOSED ALGORITHM  Simplified approach is the art of this method.

A. Idea behind the Algorithm  Every DNA sequence is a combination of nucleotides {A, C, G, T} where each literal is named as BASE and encoded in two bits per base as follows A=00, C=01, G=10 and T=11.

Compression ratio is calculated as encoded bits per Bases (bits per byte unit).

Compression Ratio = Encoded Bits/Bases  B. Plan of Work  The algorithm works in two phases. In the first phase a modified version of the run length encoding is applied. In modified version of RLE the runs of data are stored in separate file and the index of the repeated character in another file instead of keeping one file of RLE sequence. In fact modified RLE acts as a bonus point in this compression out of the nature of the DNA sequence. Four files are used one for the intermediate output (data) second for storing the position or location of repeated character (index) third file stores the runs of data (count) and the fourth one for storing the final output data (output) after compression. Separate files are used for storing index and count in order to save space. The data file cannot have consecutive repetitive occurrences of any character more than twice. Though it was envisaged that the space saved by modified RLE is not significant as intermediate files are also introduced, yet it is essential to do so for the implementation of the second phase of the algorithm which is a core soul of the algorithm.

In the second phase data is encoded using the binary bits. This binary number is then converted to decimal number and corresponding ASCII value is stored in the output file. There are 255 ASCII characters in extended ASCII table and the maximum decimal number out of 8-bit binary code is also 255.

This algorithm has been verified on ubuntu linux version 11.04 using ?C? at computer service center, IIT Delhi.

Procedure to encode:  Calculate the length of every repeated character.

If a single character is present or there are two occurrences of the same character write the characters.

Otherwise write the character only once and its repetition and its index onto the second and third file in character format.

Group the characters into a string of length four.

Assign binary bits (0&1) for every base of DNA as explained below  A=00, C=01, G=10 and T=11 Convert this 8-bit binary into decimal number which in turn can be bound to an equivalent ASCII code.

Procedure to Decode:  740 2014 IEEE International Advance Computing Conference (IACC)    Method of decoding is just the reversal of encoding, i.e. first decode the ASCII code to decimal and in turn to binary.

Binary code is decoded to DNA sequence character and by making use of index file and count file the original data is achieved.

Read the ASCII character; convert this decimal number into binary number system.

Assign the base of DNA (A, C, G, T) for every two binary bits like  00=A, 01=C, 10=G and 11=T Write the characters in the output file upto the given index in the index file, then write the character number of times in the count file.

The single and double occurrences of a base is not encoded using modified RLE as it does not economize on saving on memory space because size increases for saving a base, its index and its count.

After encoding and decoding all the sequences the result is also verified in each case.

EXAMPLE Let us consider the sequence.

AGTGGAACTTTGGCAAGCTTTTGCGCGATGAGCTGC CTGCCCA After applying modified run length encoding AGTGGAACTGGCAAGCTGCGCGATGAGCTGCCTGC A The index file contains the corresponding ASCII values for the indexes and the repetition file contains the corresponding ASCII values for the number of times character is repeated Partition this data file into groups of four and assign the binary code AGTG GAAC TGGC AAGC TGCG CGAT GAGC TGCC TGCA 00101110 10000001 11101001 11100110 11100110 01100011 10001001 11100101 11100100 Calculate the corresponding decimal and the ASCII for this binary code. The decimal is represented as 46 129 233 9 230 99 137 229 228 which in turn is represented by ASCII characters as shown in the box.

.

Compression ratio of this example=9/43*8 =1.67

V. RESULTS AND DISCUSSIONS  For practical purpose, it has been tested on various length of DNA sequence starting from 1kilobyte, 10kilobyte, 100kilobyte, 1megabyte and finally upto 10 megabyte using modified RLE and then using the ASCII code technique.

The compression behavior clearly indicates that modified RLE has a lesser impact than the compression technique of using ASCII characters. As a mathematical explanation 25% compression is done straight as we are replacing one character to two bits and 8 bits to one ASCII code.  The rest 3% and 2% in the first case is achieved as a gain through modified RLE (MRLE). The compression results of Table I indicate that compression through MRLE is dependent on the nature of the data as it varies as the data increases while the compression through ASCII coding is a very consistent and independent of the nature of data.

TABLE I.     DATA SIZE AND REDUCTION AFTER COMPRESSION  Input data size  After modified  RLE (bytes)  Size After Compression to ASCII characters  Reduced to %  1 kilobyte 954 239 bytes 23.3% 10 kilobytes 9210 2.2 kilobytes 22.5% 100 kilobytes 94234 23 kilobytes 22.9% 1 megabyte  969993 236.8 kilobytes 22.8% 10 megabytes 9671294 2.3 megabytes   22.9%  The performance of the proposed method was verified on various real DNA sequences. The sequences used were three of human genes; HUMDYSTROP (human dystrophin gene), HUMHBB (human globin gene), HUMHDABCD (human sequence of contig); complete genome of mitochondria MPOMTCG and complete genome of vaccinia virus VACCG. The above input data has been taken from the website of NCBI [14].

Table II exhibit the result after applying modified RLE on  TABLE II.      PERFORMANCE OF ALGORITHM IN TWO PHASES ON DIFFERENT DNA SEQUENCES  Sequence Base Pair Sequence Size After applying modified RLE (KB)  Total of Index and Count File  (KB)  After final Compression  (KB) HUMDYSTROP 38770 38.9 32.8 5 8.2 HUMHBB 73308 72.6 61.2 9.1 15.3 HUMHDABCD 58864 58.3 49.6 6.8 12.4 MPOMTCG 186609 184.8 152.8 24.4 38.2 VACCG 191737 189.9 164.7 19.9 41.2  . ? ?c???  2014 IEEE International Advance Computing Conference (IACC) 741    the DNA sequence and subsequently the final compression on the sequences mentioned above.

The result in this again indicates that the compression is low when improved RLE is applied but increases significantly after applying the second phase of algorithm (ASCII compression).

As an experiment, a few runs were made using ASCII compression was applied first and then improved RLE was applied as can be inferred from the Table III. The reason for that could be the probability of repetitive occurrence of the ASCII code and that too for more than couple of times is quite low in comparison to the repetition of DNA sequence characters. As a result of it compression was not considerable.

TABLE III.     PERFORMANCE AFTER ALTERING THE TWO PHASES OF ALGORITHM ON DIFFERENT DNA SEQUENCES  Sequence Base Pair Sequence Size After applying ASCII Compression  ( bytes)  After applying modified RLE  (bytes)  Total of Index File and Count  file ( bytes)  HUMDYSTROP 38770 39876  9970   9934  26 HUMHBB 73308 74357  18589  18510 54 HUMHDABCD 58864 59706 14927 14819 78 MPOMTCG 186609 189274 47319 47286 28 VACCG 191737 194476 48620 48618 2  TABLE IV.     COMPARISON WITH OTHER DNA COMPRESSION ALGORITHMS (BITS/BASE)  Sequence  Base Pair DNA Compress Gen Compress Bio- Compress2 CTW+LZ DNA Pack RL-ASC  HUMDYSTROP 38770 1.911 1.923 1.926 1.918 1.900 1.68 HUMHBB 73308 1.789 1.820 1.880 1.808 1.777 1.68 HUMHDABCD 58864 1.795 1.819 1.877 1.821 1.739 1.69 MPOMTCG 186609 1.892 1.901 1.937 1.900 1.893 1.65 VACCG 191737 1.758 1.761 1.761 1.761 1.758 1.73  The compression ratios of some other DNA compression algorithms [14] have been compared with the given algorithm in the table IV. It can be noticed that data pertaining to MPOMTCG shows good result in particular using modified RLE (MRLE) and ASCII compression technique. It can be inferred from the table that the compression ratio of this algorithm is worthy.

Average compression ratio (Cr) =1.686 bits/base  Comparison of Running Time (in seconds)  From the above graph it can be seen that there is a subtle change in execution time in comparison to DNA Compress and GenCompress but it is much lower than CTW+LZ. The performance of the algorithm has been verified on the similar architecture and a speed of 2.1 GHz Core 2 duo processor using the HUMDYSTROP DNA sequence. The running time of the algorithm can be further improved by modifying it to do the compression of DNA sequence using system with more number of processors and using massively parallel interface. Since the DNA sequence conversion is into ASCII code, the length of the sequence can be partitioned at any level and hence the parallelism can be exploited to the maximum. As the compression of each part of the code is independent by the other parts of the code the algorithm can be easily modified to run on GPU (Graphics Processing Unit) using CUDA (Compute Unified Development Architecture) with C language.



VI. CONCLUSION AND FUTURE WORK  The beauty of the algorithm is that it is simple in understanding the logic and in turn easy to code.

Furthermore, on a non-repetitive DNA sequence, the size of DNA is reduced by one fourth immediately as four bases are encoded into a single ASCII value. This method can be  742 2014 IEEE International Advance Computing Conference (IACC)    extended for any other sequence that has variety of characters eight, instead of DNA sequence where four types of characters are used. In that case three binary bits can be used to represent each character. This way it ensures the 50% reduction. Authors suggest that Huffman coding can be used in a case of any variety of characters from four to eight in a case of any variety of characters from four to eight to optimize the sequence. Next, as modified run length encoding is also applied in first phase algorithm gives better results as the number of repeated bases increases.

