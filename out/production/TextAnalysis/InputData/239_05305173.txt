Research on Distributive Algorithm of Data Mining  with Association Rules

Abstract?A distributive data mining algorithm with association rules is presented in this paper, and the performance of layer matching algorithm is compared with Apriori?s by examples. The established algorithm of mining large itemsets mainly makes use of the thought of layer matching, it is divided to build up a kind of layering structure, and the data are divided finally. Each independent calculating process relatively related to the generating algorithm of the whole data mining large itemsets is separated, and different match algorithms are adopted to build local large itemsets. Result shows that the introduced algorithm has better mining speed and performance than Apriori algorithm by numerical cases, the number of systematic I/O is reduced greatly, the memory expenses are moderate. and it can avoid missed mining effectively.

Keywords-Data mining; association rules; large itemsets; layer matching

I.  INTRODUCTION Nowadays, data mining is the hotspot topic in data base  and artificial intelligence fields[1]. Association rules is one of the key technologies in data mining, which are mainly used to discover an interesting association or related contacts of huge data between itemsets. At present, many algorithms with mining association rules are given[2,3]. Apriori algorithm is the classic algorithm among them. For example, The AIS algorithm is presented by Agrawal, the DHP algorithm is presented by AprioriHybrid and Park, and the Partition algorithm is presented by Savadere etc., which are the main mining algorithms based on association rules of Apriori?s[4,5].

These algorithms mainly are made use of the step of joint and pruning by Apriori?s. In order to improve mining efficiency of algorithms, scholars also carried on the related research. Park and Chen etc. used the hash table to raise the mining efficiency of Apriori?s[6]. Srikant and Hans analyze the transaction compress technique. In order to reduce calculating times and raise the mining efficiency, a distributive data mining algorithm with association rules is presented in detail, and the performance of layer matching algorithm is compared with Apriori?s by examples in this paper. Result shows that the introduced algorithm has better mining speed and performance.



II. MINING PROBLEM OF ASSOCIATION RULES Mining problem of association rules need find the  association rules of minsup and minconf given by user. The analysis of the association rules can be breakn up two problems.

First, the problem of making use of frequency itemsets build all association rules of minconf, the below generated algorithm is given.

1? for all k-, l k?k?2?in L do 2? begin 3?   H1={ l k }? 4?   ap_genrules?l k?H1?? 5? end 6? ap_genrules?l k?Hm? 7? if k > m+1 then 8? begin 9?   Hm+1=Apriori_Gen?Hm?? 10?   for all hm+1?Hm+1 do 11?   begin 12?     conf=support?l k?/ support?l k - hm+1?? 13?     if conf?minconf then 14?        append?l k - hm+1?? hm+1 to rule set 15?     else 16?        delete hm+1 from Hm+1? 17?   end 18?   ap_genrules?l k?Hm+1?? 19? end  Secondly, all frequency itemsets of meeting minsup must be calculated in a transaction database. most research concentrationses are on this problem currently. It resolves to many new searches problem of large scale database. So the efficiency and accuracy are keys problems. the discussion and the corresponding algorithm are focus to research the problem in the paper.



III. PRESENTED MINING ALGORITHM  A. Calculating model of the algorithm Apriori algorithm is needed to scan the whole database  many times[7]. In order to reduce the algorithm spending of frequent scanning database and deal with the data skew and the partition quantitatively, a distributive matching algorithm in mining large itemsets with association rules is presented in     the paper, and the executive efficiency and performance of algorithm can be raised greatly. The algorithm mainly utilizes the partition thought of Partition dataase to establish a layer structure. It solves mainly the problem of efficient data distributing and data skew, and the close itemsets are separated from the database by the method of inverse clustering and inverse Hash. The information is distributed to different nodes by scan a time database, and the generating algorithm of the whole data minng large itemsets involves to every stand-alone calculating process is separate. Individual model is used to different layer, and the local large itemsets can be build by adopting different efficient matching algorithm. The layer matching algorithm is a kind of calculating method actually, and each independent calculating process relatively relate to the generating algorithm of the whole data mining large itemsets is separated by the algorithm. There are not many close coupling problems among modules. So it can be calculated by separate module, and only a little transaction data and instruction flow are passed. The calculating model of layer matching can be described as shown in Figure 1.

Data processing layer of figure 1 is correspondence to every  processed node, and it is an actual job layer. The data controlling layer are a controller and coordinator in the whole distributed process. Data accessing layer is database management system, and it can provide original transaction efficiently. It uses the data accessing layer access actual data, and the data is efficiently distributed to every terminal node.

It can be seen that each layer is not a pure customer and service concept from here, where the data processing layer must correspond every node to mining data, and gather the mining results of partition data to obtain large itemsets, then, get the final association rules according to the large itemsets.

The data accessing layer can utilize present large scale database management system, and they can provide original transaction flow for the data controlling layer. Therefore, the layer matching algorithm screens the concrete method of every layer. The different efficient algorithm can be matched for  different layer, and the corresponding algorithm flow is shown as.

(1) Establishing data input channel according to the processor, doing some work of various initialization, and preparing to read transaction data flow.

(2) According to the different of layer matching algorithm that solves the data skew to initialization variable, and sequence read transaction block in database.

(3) From (2), reading the first transaction in database, and marking the support counting is 1 according to the whole set of the transaction support the 1- itemsets, secondly, reading the second transaction. According to a set of the whole 1- itemsets, the k- itemsets can be gotten in the possible set one by one.

(4) In (3), if previous set not appears, then marking the support counting to 1, having already appear in previous set and having already been marked for the frequency itemsets, then jumping the itemsets and analyzing the next itemsets. If the itemsets have already appear in previous set, but the threshold value of the minimum support is dissatisfied, then the corresponding support counting add to 1.

(5) In like manner, dealing with the third, forth transaction in database, until the processing finishes all transaction block, then distributing every transaction to different processor in order to balance load and solve data skew.

(6) Processor solves the transaction oneself. If the whole transaction can be put into the memory, then it can adopt efficient algorithm to get global local itemsets, or the transaction is delayed to local disk. After all transaction accepted to complete from the controlling layer, it can generate the last local large itemsets.

(7) Data controlling layer is responsible for data communication between each node, at the same time, it maintenances global enumerate trees, it can communication with the data controlling layer when each nodes processing or finishing, and this is decided by the different matching algorithm. At last, the data controlling layer is responsible to merging all local large itemsets enumerate trees to generate the global large itemsets enumerate trees, i.e. the result large itemsets.

B. Advantage analysis of the algorithm performance According to the above describing, the main influence of  distributing transaction to different node is to balance load and eliminate data skew. So it is the key part of the algorithm.

Two kinds of different method are given in order to solve the problem of data skew, i.e. inverse clustering method and inverse Hash method. The clustering method is to gather the similar set, and it can embody their commonness. But at the time of the processing data skew exactly the opposite, the more difference set should be gathered all together, and the method is called inverse clustering method in the paper. The method of clustering oneself decides the computer realize based on the history data. So the method of inverse clustering needs the history data, too. The distributed transaction itemsets of all nodes must be gotten in the algorithm, and can calculate the Sn+1. A kind of direct method is to pass the calculating of Sn+1 to each node, collect the calculated result,  Data controlling layer  Reading data  Data processing layer  Data accessing layer  Original transaction flow  Access and distribute  Processing data  Figure 1. Calculating model of layer matching  TDB    inform all nodes save the node of the transaction, and the other node delete the transaction from the transaction set. The thought of inverse Hash method likes the inverse clustering method. According to the thought of Hash function generate a Hash value for each itemsets, and a node denotes a barrel. For separating similar itemsets, the itemsets can?t be calculated in Hash function and get the node, but be calculated in a random node or farthest nodes of distance biggest transaction.

Thereby, the algorithm can realize scatter among itensets.

Because the algorithm?s realization is begun from read transaction flow in database, and need scan database one time merely. It can get large 1- itemsets directly in the process of read. So the process is together the number of transaction in database the linear behavior, i.e. let the number of transaction database is n, then the time complexity of distributed transaction is O(n), the space complexity is O(1), and the total time complexity is O(n+n/k(p+n/k)?when the algorithm can ignore the imitation of network bandwidth. So, the algoithm can reduce searching cost, and its advantage is very evident.



IV. COMPUTING AND DISCUSSION In order to test computing efficiency of the algorithm, the  performance of layer matching algorithm is compared with Apriori?s. The test process is done based on the computer of 218M memory and CPU of 3.00GHz, and the corresponding data is generated by builder. The test database is T150.I10.D100. Part calculating scene of the introduced algorithm is shown in figure 2. At last, the corresponding calculated results are given in table ?.

TABLE ?. RESULT COMPARISON OF DIFFERENT ALGORITHMS  Itemsts support  itemsets number mining time/s Apriori presented Apriori presented  0.010 1645134 1645134 45.4 35.1 0.015 1266523 1266523 36.6 29.4 0.020 1077067 1077067 32.9 24.3 0.025 951504 951504 30.1 22.0 0.030 732210 732210 24.7 16.4 0.035 497471 497471 20.9 13.3 0.040 113578 113578 16.0 10.2 0.045 80992 80992 13.6 7.9 0.050 61701 61701 10.1 5.8 0.055 40335 40335 7.4 4.6 0.060 21390 21390 6.7 3.5  The test curves of different mining algorithms can be gotten in figure 3, and the corresponding results comparison of different algorithms mining efficiency is given in Table ?.

According to the figure 3, it can be seen from table4 the mining time is reduced of the algorithm with adding the support. At the same time, the cost time is less than Apriori?s for the same support with the operation is reduced. Thereby, the mining efficiency is higher by adopting the introduced algorithm than the Apriori?s obviously.

Based on the above analysis, the test example of generating dynamic set enumerate tree will be analyzed and discussed in the paper. Supposing the transaction allocation unit distribute the record to a node P, when P is receiving node, it transfers a record type to a tree node type, then insert this node in a created enumerate tree, all received records can be denoted as the node listing in Table ?.

TABLE ?. THE NODES LIST Number of item Support Item list  5 0 ABCMW 4 0 QBNL 4 0 ACWL 3 0 QBW 5 0 BCWKL 4 0 BCKL 3 0 WKL 6 0 ANMAKL 4 0 NAWK 3 0 ANM 4 0 ACWK  The final tree structure can be created, and the corresponding result is shown in Figure 4.

Figure 2. Calculating scene of the algorithm  Figure 3. Test curves of different mining algorithms  0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06            Support/%  T im  e/ s  Test curves of different mining algorithms     Apriori?s algorithms  introduced algorithms  3 2 ACW 3 2 ANM  4 1 ACWK  6 1 ANMAKL  5 1 ABCMW  4 1 ACWL  3 1 QBW 4 1 QBNL  2 2 QB 2 2 BC  5 1 BCWKL  4 1 NAWK  3 1 WKL  4 1 BCKL  Figure 4. Creating dynamic set enumerate tree structure

V. CONCLUSIONS The complexity of layer matching algorithm is greatly  reduced than the Apriori?s, which is simply in the same calculating platform. It is not necessary to overfull deal with data. So, the communication cost is saved among nodes, systematic run speed also is raised, and computer software for the configuration standard of engineering computer can be reduced. Because the algorithm is improved by the Apriori?s, and it has very good expansibility. Moreover, it has different calculating method for different layers. In order to bring the best effect, suited matching algorithm should be adopted according to the fact problem.

