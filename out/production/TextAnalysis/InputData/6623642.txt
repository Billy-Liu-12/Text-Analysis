Introducing an Intelligent MapReduce Framework for  Distributed Data Processing in Clouds

Abstract?The world of big data is in need of high levels of scalability and the question, how to effectively process large-scale data sets is becoming increasingly relevant. Furthermore the existing data management schemes do not work well when data is partitioned among numerous available nodes dynamically.

Approaches towards parallel data processing in cloud, which offer greater portability, manageability and compatibility of applications and data, are yet to be fully-explored. With this in mind, in this paper we would like to explore the possibility to evolve a new type of data processing approach that will efficiently partition and distribute data for clouds. For this matter, loosely- coupled associative techniques, not considered so far, can be the key to effectively partitioning and distributing data in the clouds.

Ability to partition data optimally and automatically will allow elastic scaling of system resources and remove one of the main obstacles in provisioning data centric software-as-a-service (SaaS).

Keywords?Distributed Computing, Parallel Processing, Hadoop Mapreduce, Cloud Computing, Neural Networks, Data Mining.



I.  INTRODUCTION The recent development of computing technology has  brought forward the ability of generating huge volumes of highly complex data. From high-dimensional images used in medical diagnosis to millions of multi-sensor data collected for the detection of disastrous events, these large-scale and complex data have become a common phenomenon today. This is consistent with Moore?s Law of exponential increase in computing power and solid-state memory [1]. Even though this was initially referred to the transistor counts within a processor, the effect of this law seems to be applicable in almost all areas of computing, including data generation and analysis. In essence, our existing capability to generate data seems to outstrip our capability to analyze it. The capabilities of existing applications for data mining and analysis so far have not achieved their fullest potential. This is mainly due to the algorithmic complexity of existing data mining applications [2]. With the advent of distributed computing, distributed data storage and processing capabilities have also contributed to the development of cloud computing as a new paradigm. This new trend of computing can potentially make it possible to achieve capability of conducting such large-scale data processing.

Nevertheless, existing data management and processing schemes are incapable of providing an efficient mechanism for  deployment within cloud. Some of the concerns include inadequate capability to parallelize data workload, security concerns as a result of storing data at an un-trusted host, and weak data replication functionality as described in [3].

One of the proposed solutions for the implementation of large-scale pattern recognition is distributed pattern recognition [4]. Distributed pattern recognition can be defined as an extension of existing pattern recognition approaches in which the recognition process is delegated across a distributed system.

Most of the initiatives on distributed pattern recognition have been focusing on providing distributed architecture for pattern recognition [5]. Consequently, this creates such a high dependency on hardware implementation. Hence, the issue of scalability in this context has yet to be solved. This is mainly due to inflexibility of the existing distributed pattern recognition schemes to be implemented across different architectural platforms and network environments, providing high capability for large-scale recognition deployments Although there is some existing research on the implementation of distributed approach for existing pattern recognition schemes, these studies merely focusing on manipulating the methods in which this particular algorithm performed its recognition function (from sequential to parallel mechanism) [6]. Furthermore, existing distributed approaches have yet to be able to reduce the computational complexity of their respective algorithms to be deployed in a distributed environment. The deployment of pattern recognition applications for large-scale data sets is an open issue that needs to be addressed. Several approaches have been proposed, including the various techniques such as data reduction [7], active learning [8] and distributed approach in pattern recognition [9]. Nevertheless, a common denominator for this is the algorithmic complexity of existing schemes. The neural network approach offers a promising tool for large-scale pattern recognition. However, there are also several issues related to its implementation. These include convergence problems, complex iterative learning procedures and low scalability with regards to the training data required for optimum recognition. Graph Neuron (GN) algorithm on the other hand has shown to exceed single-cycle learning and in- network processing capabilities [10]. In addition, it has been implemented in a number of pattern recognition applications in fine-grained networks [11]. In solving the scalability issue within pattern recognition applications, we intend to shift the recognition paradigm from being a sequential-based CPU-  2013 IEEE 12th  International Symposium on Network Computing and Applications  DOI 10.1109/NCA.2013.48     centric towards a parallel in-network approach. In-network processing paradigm concentrates on the delegation and distribution of processes over the body of a network, rather than utilizing single processing device or node.



II. GRAPH NEURON FOR SCALABLE RECOGNITION Graph Neuron (GN) is a pattern recognition algorithm that  implements a simple associative memory (AM) architecture, which provides a capability to recall patterns using similar or incomplete patterns. Associative memory architecture differs from conventional memory architecture in the sense that the store and recall operations on memory contents are based on the association with input value rather than based on the address of the memory content. Hence, associative memory- based pattern recognition algorithms are able to offer high recognition accuracy as compared to other algorithms which implement recognition using conventional memory architecture. In addition to its associative memory architecture, GN also follows some characteristics of graph-based pattern recognition algorithms [12]. However, GN implements in- network processing that solves the scalability issue (computationally prohibitive against an increase in the size and database of patterns) in other graph-based pattern recognition algorithms [13].

A. Crosstalk Issue in GN GN?s limited perspective on overall pattern information  would affect a significant inaccuracy in its recognition scheme.

As the size of the pattern increases, it is more difficult for a GN network to obtain an overview of the pattern?s composition.

This produces incomplete results, where different patterns having similar sub-pattern structure leads to false recall. In order to solve the issue of the crosstalk due to the limited perspective of GNs, the capabilities of perceiving GN neighbors in each GN is expanded in Hierarchical Graph Neuron (HGN) to prevent pattern interference. The underlying principle of HGN implementation is such that the capability of ?perceiving neighbors? in each GN within the network must be expanded. This is achieved by having higher layers of GN neurons that oversee the entire pattern information. Hence, it will provide a bird?s eye view of the overall pattern. Figure 1 shows the hierarchical layout of HGN for binary pattern with size of 7 bits.

Fig. 1. HGN with binary pattern of size 7 bits  The limitation of Graph Neuron (GN) on the crosstalk issue has brought forward the development of Hierarchical Graph Neuron (HGN). HGN extends the functionalities of GN algorithm for pattern recognition by providing a bird?s eye view of the overall pattern structure. It thus, eliminates the possibility of false recalls in the recognition process [14].

B. Distributed Hierarchical Graph Neuron (DHGN) HGN can be extended by dividing and distributing the  recognition processes over the network. This distributed scheme minimizes the number of processing nodes by reducing the number of levels within the HGN. DHGN employs the collaborative-comparison learning approach in pattern recognition. It lowers the complexity of recognition processes by reducing the number of processing nodes. In addition, as depicted in Figure 2, pattern recognition using DHGN algorithm is improved through a two-level recognition process, which applies recognition at sub-pattern level and then recognition at the overall pattern level [15]. Figure 2 shows a complete architecture of DHGN network. In this figure, a decomposition of binary image pattern ?K? into sub-patterns is illustrated. This decomposition is performed by the SI Module node.

Fig. 2. DHGN for distributed pattern recognition

III. EDGE DETECTING HIERARCHICAL GRAPH NEURON (EDGEHGN)  Graph Neuron based algorithms have been developed based upon two different concepts known as graph-matching and associative memory. These two concepts have given an added advantage in terms of scalability for GN-based algorithm implementations. GN has the ability to perform pattern recognition processes on distributed systems due to its simple recognition procedure and lightweight algorithm. Previous parts of this paper have analyzed GN, HGN, and DHGN. In this section, the algorithmic design of a newly proposed Edge Detecting Hierarchical Graph Neuron (EdgeHGN) algorithm for distributed pattern recognition scheme for large-scale data sets is presented. The proposed approach extends the scalability     of the existing DHGN implementation by reducing its computational requirements in terms of the number of neurons for recognition processes. EdgeHGN provides a capability for recognition process to be deployed as a composition of sub- processes that are being executed in parallel across a distributed network. Each sub-process is conducted independently from each other, making it less cohesive as compared to other pattern recognition approaches.

A. EdgeHGN Architecture Pre-processing is an important task that needs to be carried out before any recognition procedure. In our proposed EdgeHGN model, we reduce redundant data content for recognition by applying a Drop-Fall algorithm on the input pattern. This results in lesser number of processing neurons which in turn results in lower communication overhead within the scheme. In our approach, a drop-fall scheme will be applied to the pattern which ensures producing the least number of neurons. By applying a simple drop-fall algorithm, we can reduce number of redundant processing neurons in the binary character image while maintaining all character data bits. This approach is shown in figure 3 where a Descending-left drop-fall algorithm is applied on the input pattern reducing number of processing nodes for each EdgeHGN subnet significantly (total number of GN nodes are decreased from 49 to 39 in this example). This reduction will not only minimize communication costs but also having an edge detection feature within the scheme can improve recognition accuracy to a high degree. Furthermore, lesser number of neurons results in lower response time which is of high interest for real-time pattern matching problems.

Fig. 3. EdgeHGN progressively removes unnecessary nodes from the two- dimensional data representation  EdgeHGN adds a clustering mechanism in pattern recognition by dividing and distributing patterns into sub- patterns. Each of the sub-patterns undergoes a one-shot recognition procedure. The results of sub-recognition will cumulatively add up to obtain the actual recognition result.

Each processing node in clustered EdgeHGN configuration may perform recognition on each sub-pattern independently from other processing nodes. In this context, the node should be able to provide sufficient processing and storage capacity in order to conduct the recognition process. An important benefit of having this EdgeHGN cluster performed on a single processing node is such that it eliminates all the communication actions involved in EdgeHGN message passing model for distributed systems. For each sub-pattern recognition  process, each node only communicates back the corresponding index generated, therefore reducing the chances of recognition failures due to transmission or communication errors.



IV. ASSOCIATIVE MEMORY BASED MAPREDUCE MapReduce comes with its own issues and limitations. One  might think that the absence of a rigid schema automatically makes MR the preferable option over parallel database management systems. Existing MR implementations provide built-in functionality to handle simple key/value pair formats, but the programmer must explicitly write support for more complex data structures, such as compound keys.  In most MapReduce implementations, the map function conducts its operation assuming all related data is distributed vertically, i.e.

records being uniformly distributed across the network.

However, it is possible that some parts of the related records being stored at different physical locations. For instance, a large database table being split up into multiple sub-tables and stored among the cloud nodes. In addition to vertical distribution issue, another issue related to MapReduce function is that the operations produce numerous intermediary entities - between the map and reduce functions. These entities could be in the form of intermediate files. The contents of these files would need to be sorted before these are input to the reduce function. This system wide sort and redistribution incurs additional processing and communication costs. So it is safe to say that data fragmentation can affect MapReduce schemes focused on vertical splitting where data is partitioned based on the file structure, rather than horizontal splitting approach.

All the implementations of the MapReduce so far including the Hadoop version has interpreted data in a relational model and this limits its functionality when dealing with complex and unstructured data such as images. By having an associative key/value model, we can deal with data in any form and in any representation simply by using a pattern matching model which treats data records as patterns and provides a distributed data access scheme that enables data storage and retrieval by association. In this model, the map function takes EdgeHGN subnets as the key and the object itself as the value, performs sub-pattern matching, calculates bias index and emits a set of intermediate key value pairs as output. Intermediate keys are EdgeHGN subnets and intermediate values are associative arrays holding store or recall decisions for each subnet. It is worth noting that all map functions can be run and implemented in parallel. On the other hand, the class reducer works on EdgeHGN subnets as keys and intermediate associative arrays as values, calculates the final decision which in our implementation is based on a voting scheme and then emits the final store or recall decision.



V. SIMULATION AND RESULTS For our performance benchmarks, a Pseudo-distributed  Hadoop environment is set-up with default configuration settings but some changes are made to the settings to gain better performance, e.g. the max data chunk size is set to 256MB instead of 64 and heap size for task executer JVM is increased to 512MB for better memory allocation and garbage collection. In addition, the performance of Hadoop MR and newly proposed EdgeHGN based MR are compared against     one of the commonly used parallel database management systems called Vertica. The Vertica database is a parallel DBMS designed for large data warehouses. The main distinction of Vertica from other DBMSs is that all data is stored as columns, rather than rows. In figure 4, we can see performance of all three schemes while performing a simple task of a pattern search. In Vertica, a pattern search for a particular field is simply running a query in SQL which requires a full table scan:  SELECT * FROM Data WHERE field LIKE ?%XYZ%?;   On the other hand, the MR program consists of just a Map function that is given a single record already split into the appropriate key/value pair and then performs a sub-string match on the value. If the search pattern is found, the Map function simply outputs the input key/value pair to HDFS.

Because no Reduce function is defined, the output generated by each Map instance is the final output of the program.

Fig. 4. Comparing Distributed MapReduce, EdgeHGN based MapReduce and Vertica, performing alphanumeric pattern search on input data splits of 256MB in size.

As clearly shown here, Pseudo distributed MapReduce and EdgeHGN based MapReduce perform equally well. For some data input splits EdgeHGN even responds sooner in time and average response time looks better. Vertica performs the best here as we simply run a very simple query against the database.

One of the reasons that Hadoop performance and EdgeHGN performance are lower compared with Vertica is the fact that we are running both in a Pseudo-distributed mode and not in a fully distributed mode in a cluster where memory is allocated to the process independently. The other reason is that considering the limited number of data chunks that we process in both Pseudo distributed Hadoop and EdgeHGN based MR, Hadoop?s start-up costs can become the limiting factor in its performance. In fact for small queries, Hadoop startup costs can dominate the execution time. In our observations, we found  that it can take 1?2 seconds before all Map tasks have been started and are running at full speed.



VI. CONCLUSION AND REMARKS Existing cloud frameworks such as Hadoop MapReduce  involve isolating low-level operations within an application for data distribution and partitioning. This limits their applicability to many applications with complex data dependency considerations. This paper explored new methods of partitioning and distributing data in the cloud by fundamentally re-thinking the way in which future data management models will need to be developed on the Internet. Loosely-coupled associative computing techniques, which have so far not been considered, can provide the break through needed for a distributed data management scheme. Using a novel lightweight associative memory algorithm known as Edge Detecting Hierarchical Graph Neuron (EdgeHGN), data retrieval/processing can be modeled as a pattern recognition problem, conducted across multiple records within a single- cycle utilizing a parallel approach.

