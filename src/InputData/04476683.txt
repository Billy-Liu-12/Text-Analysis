A Novel Parallel boolean approach for discovering frequent itemsets

Abstract? Discovering association rules that identify relation- ships among sets of items is an important problem in data mining.

Finding frequent itemsets is computationally the most expensive step in a association rules discovery algorithms. Therefore, it has grasped significant research focus.

Most of the previous studies adopt Apriori-like algorithms, whom iteratively generate candidate itemsets and check their frequencies in the database. These approaches suffer from serious costs of repeated passes over the database.

To address this problem, we propose a new parallel method, called PARALLELTREESUPBDD-MINE, for reducing cost time to find frequent itemset discovery algorithms. The idea of PRALLELTREESUPBDD-MINE consists in using a Binary De- cision Diagram (BDD) and a prefix tree for representing both database and frequent itemsets. The proposed method requires only one scan over the source database to create the associated tree and BDD and to check discovered itemset supports. The originality of our work stands on the fact that the proposed algorithm extracts in a parallel manner the frequent itemsets directly from the TREESUPBDD.

We have tested our algorithm using different benchmark datasets and we have obtained good results.

Keywords: Data mining, Association rules, Frequent itemsets, Binary decision diagram, Parallel data mining.



I. INTRODUCTION  Finding frequent itemsets is one of the most investigated fields in data mining. The Apriori algorithm is the most established algorithm for frequent itemsets mining [1]. One of the most important problems in data mining is association rule mining. It requires very large computation and I/O traffic capacity. Several strategies for parallel frequent itemset com- putation were proposed by Agrawal and Shafer [2], including the CD algorithm. Recently, another algorithm called Data-VP was presented by Coenen et al. [9]. Our approach differs from CD and Data-VP in that it makes use of the TREESUPBDD structure.

For that reason several parallel mining algorithms have been developed [2], [10], [13], which can take advantage of the performance of the target machine, but these algorithms are optimized and developed for supercomputer platforms. PC clusters have become popular in parallel processing. They do not involve specialized interprocessor networks, so the latency of data communications is rather long. The main part of the distributed association rule mining algorithms is  based on Apriori algorithm but these algorithms suffer from the drawbacks of the Apriori algorithm. In this paper a new distributed association rule mining algorithm is proposed, which is based on TREESUPBDD-MINE algorithm developed in our team [5], aiming to cope with the bottlenecks draw- back of the Apriori algorithm. In this paper, we present a PARALLELTREESUPBDD-MINE?s implementation, where the data structure TREESUPBDD is generated by a parallel com- puter. A fundamental problem in parallel computing is how to partition a database in order to minimize communication between processes while keeping the loads balanced. Hence, we present a methodology for partitioning a data structure with guaranteed bounds on load-balancing and communication costs. The remainder of the paper is organized as follows : In Section 2, we present the TREESUPBDD structure. We also introduce the sequential algorithm TREESUPBDD-MINE used to generate frequent itemsets. Section 3 discusses parallel implementation of TREESUPBDD-MINE. Preliminary results on the practical performances of the proposed algorithm are presented in Section 4. Section 5 concludes the paper and points out future directions to follow.



II. TREESUPBDD-MINE ALGORITHM  Many works have addressed the problem of efficiently min- ing frequent itemsets [8]. One of the key problems is to find an appropriate data structure for representing the data during this process into main memory like transactions database and frequent itemsets. In the works of Salleb [11], [12], the author uses an extension of BDD having multi-terminal nodes, called Algebraic Decision Diagrams (ADD) as a data structure for representing and loading transactional datasets.

Our work uses TREESUPBDD structure [5] based on BDD to mine frequent itemsets without representing candidates and scans the database only once.

A. Binary Decision Diagram  A Binary Decision Diagram (BDD) is a graph-based repre- sentation of boolean functions. Functions are represented by a directed acyclic graph [3], [7]. BDD is a directed acyclic graph with 2 terminal nodes 1 and 0. A BDD represents a disjunctive normal form of a boolean function : each path from the root   DOI 10.1109/ICDMW.2007.111     Fig. 1. Associated binary tree to the function (a), Apply of the sharing of all the subgraphs (b) and BDD (c).

of a BDD to a leaf indexed by number 1 gives a conjunction of literals (where a literal is either a variable or the negation of a variable) that is true for that boolean function. Given a boolean function, it is possible to represent it by a canonical graph, using the following rules.

1) Choose an order on variables : x1 ? x2 ? ... ? xn ; variables appear in this order in all the paths of the graph and no variable appears more than once in a path.

2) Eliminate all the redundant nodes whose two edges point to the same node.

3) Share all equivalent subgraphs.

Operations (AND, OR, ...) on BDDs have been defined in [6]. A function graph can be reduced in size without changing the denoted function by eliminating redundant vertices and duplicate subgraphs.

We present in Figure 1(c) the corresponding BDD of the boolean function f(x,y,z)=(?x? y ??z)? (?y ? z)? (x? y), with the order of variables (x ? y ? z). In Figure 1(a), we present the associated function with a binary tree. Figure 1(b) presents the sharing of all the subgraphs.

B. TREESUPBDD structure  We propose a new structure, called TREESUPBDD (Tree Support Binary Decision Diagram), to represent frequent itemsets using a prefix tree and a modified BDD (called SupBDD). Any node of this tree represents a frequent itemset and have an index to identify ?implicitly? the associated transactions identifiers (TIDs). This index is a SupBDD (Support Binary Decision Diagram). The SupBDD represents the transactions identifiers (TIDs) for the corresponding itemset. That is, suppose the data for a given problem are encoded as bit vectors of length n. Then any subset of the vectors can be represented by a boolean function over variables yielding 1 when the vector corresponding to the variable assignment is in the set. In our case, any transaction can be encoded with b1b2...blog2(m) bits, where each bit bk is in {0, 1} and m is the total number of transactions. The first level of TREESUPBDD contains frequent 1-itemsets. For each node, we carry out the intersection of its SupBDD with the SupBDD of brothers nodes of same level to generate the  second level with new frequent itemsets. We can say that each level k of TREESUPBDD represents frequent k-itemsets.

The SupBDD of an itemset I is a reduced BDD (figure 2). Support Binary Decision Diagram (SupBDD) is a BDD  x  z y   ( b ) x  z y   ( a )   Fig. 2. SupBDD (b) Vs BDD(a).

with only one terminal node. The bit vectors themselves can have many elements equal to zero. In fact, our particular encoding to reduce BDD was chosen for this purpose. This motivates choosing a representation that exploits both forms of sparseness. Reduced BDDs are much like BDDs, except that we use a new reduction rule. That is, a node 0 can be omitted with the corresponding arcs. For sparse sets (vector with many 0), this condition frequently arises, and hence many arcs eliminations are possible. Formally, given a boolean function, it is possible to represent it by a canonical graph, adding the following rule for the three rules already presented.

? Delete rule: Eliminate the zero terminal node and the associated arcs.

Hence, with this structure TREESUPBDD, we represent both the transactions identifiers and the frequent itemsets. Further- more, we can compute the support without accessing database.

A large TREESUPBDD can be constructed by scanning the database where each different itemset is mapped to different locations in the tree; then the entries of the tree index is a BDD that gives ?implicitly? the actual count (i.e support) of each itemset in the database. The support of any itemset I can be computed using the following lemma :  Lemma 1: Support(I) = ?R  i=1 2 Nbsauti  Where  ? R represents all paths from the root to the terminal node 1.

? Nbsauti denotes the cardinality of the pruning nodes.

Proof 1: If nbSauti = 0, with i ? {1,. . . ,R}, all the nodes are represented. the support in B is equal to  R?  i=1  20 =20 ? R.

Hence, the property is true for nbSauti = 0.

Suppose that que the property is true for nbSauti = pi. We  obtain a support equal to R?  i=1  2pi .

With the next rank pi +1, we have one pruned node ; there will be thus two ways which will be added. the support becomes:     A T W  x  z   y  x  z   y  z  x  z   y y  z  C  x  z   y  T  x  z   y  C x  z   y y  z  T  x  z   y  T W  x  z   y  z  x  z   y y  z  W x   y  zz  W x   y  zz  Fig. 3. Left : First level of TREESUPBDD structure for the transaction database given by table I ; Right : Complete TREESUPBDD.

CH?  i=1  2pi ? 21.

However, we are 2pi? 21 =2p+1; we can conclude that  CH?  i=1  2pi+1 is true for p+1.

Table I represents a transaction database D. Having six  Tid items T1 A, C, T, W T2 C, D, W T3 A, C, T, W T4 A, C T5 A, C, T T6 C, D, T, W  TABLE I  A TRANSACTION DATABASE D  transactions, the transaction identifiers can be decoded with 3 bits (x, y and z). The Figure 3 left presents a first level of TREESUPBDD structure for the transaction database given by table I. This level represents frequent 1-itemsets.

The SupBDD of item A is given by Figure 3 left(1). The itemset A is frequent relatively to the threshold 3, since it appears 4 times in D Support(A) = 21 + 21 (the first 21  corresponds to the omitted variable y in the first path and the second one corresponds to the omitted variable z in the second path). For the itemset T , the support(T ) = 21 +20 +20 = 4, 20 corresponds to zero omitted variable in the path and 21  corresponds to the omitted variable y in the first path. We show the complete TREESUPBDD in Figure 3 right.

We present below (see algorithm 1) the algorithm TREESUPBDD-MINE that founds frequent itemsets. Nota- tions used by this algorithm are summarized in Table II. The first function Add-item used by algorithm 1 generates the  1In figure 3 left, we represent only the SupBDD?s of the item A and T.

X : an itemset.

T : a transaction from the database.

Li : a list of items.

TID : a transaction identifier.

X.nocc: number of occurrence of X.

XLf : child list of X.

SA : Result of AND operation between two SupBDDs.

cardA : support of SA.

X.work: Processor work.

taskid: Processor identifier.

IF : The set of frequent itemsets.

kIF : frequent k-itemset.

TABLE II  NOTATIONS USED IN ALL PROPOSED ALGORITHMS  different items. The second function remove-item founds the frequent 1-itemsets. The last function Create Tree builds the TREESUPBDD and generates the set of frequent itemsets.

Algorithm: TREESUPBDD-MINE1 Input: Database (D), minimal support (minsup) Output: TREESUPBDD : frequent itemsets Begin2  /* Step 1: reading and extracting the 1-itemsets */3 Foreach (Transaction T ? D ) do4  Foreach (X ? T ) do5 Add items(X , Li);6  End For;7  End For;8 /* Step 2: remove infrequent itemsets */9 Remove item(Li,minsup);10 /* Step 3: TREESUPBDD construction */11 frequent itemsets=Create Tree(Li, minsup);12 Return frequent itemsets;13  End14 Algorithm 1: Algorithm TREESUPBDD-MINE  C. Study of sequential complexity  In this section we study the temporal complexity of TreeSupBDD-Mine in worst of the cases (see algorithm 1). The complexity of the first step (line 4 up to 8) is on O(n2t ) (with nt is the number of transactions). In the second step (line 10) the complexity is O(ni) (with ni is the number of items). In the last step (line 12) The complexity is O(ni? (|f|2 + |R|)?2ni) (with |f| is the number of node in SupBDD f and |R| is the number of paths from the root to the terminal node 1). The global complexity of the algorithm 1 is on O(n2t + ni2  ni(|f|2 + |R|)) (for more details see [4]).



III. MINING PARALLEL FREQUENT ITEMS USING TREESUPBDD  In this section, we propose a new parallel association rules mining algorithm, titled PARALLELTREESUPBDD-     MINE, which is based on the TREESUPBDD-MINE algorithm.

We have implemented this algorithm on a cluster of PC?s. All experiments were carried out using high dimensional data and huge transactional databases. These data sets are composed of hundreds of thousands items. A special optimization step is added to achieve better load balancing with the goal of distributing the work fairly among processors for the mining process. In our sequential evaluation, we noted that the step of TREESUPBDD construction (step 3) is very expensive. This associated cost is about 99% of the total cost of all steps.

A. Evaluation study of different steps of TREESUPBDD- MINE  We present below an experimental study based on cost time for the different steps (step1 : extraction of 1 ? itemsets, step2 : generation of frequent 1 ? itemsets and step3 : TREESUPBDD construction) of the algorithm TREESUPBDD-MINE.

Database Step 1 and 2(%) Step 3 (%) Connect 10% 0.03% 99.97%  Mushroom 5% 0.14% 99.85% Pumsb star 20% 1.54% 98.54%  TABLE III  COST TIME FOR DIFFERENT STEPS.

B. Construction of the Multiple TreeSupBDD  The goal behind this step is to build in parallel the compact data structure called TREESUPBDD. This construction is done in a single step that do not requires any scan of the database.

The only scan of the database identifies the frequent 1-itemsets that is done sequentially (steps 1 and 2 of the TREESUPBDD- MINE algorithm). In order to enumerate the frequent items, we divide the 1-itemsets among the available processors.

Each processor is given an approximately equal number of 1 ? itemsets to analyze. As a result, the 1-itemsets is split in p equal partitions. Each processor locally construct the all associated k-itemsets to identify the frequent items. Hence, the determination of the global support is done in parallel manner where each processor is allocated an equal number of items to sum their global supports. To this end, we can estimate the global complexity on O(2ni /p) (with ni is the number of items and p the number of processors).

In figure 4, we see an example of built TreeSupBDD with two processors.

In this way, we avoid an additional cost to synchronize processors after calculating the support of each itemset, since we don?t compute the local support. Thus, each sub-tree is independent from the other sub-tree.

The parallel algorithm PARALLELTREESUPBDD-MINE is presented by Algorithm 2.



IV. EXPERIMENTAL RESULTS  We have already developed a prototype, called TREESUPBDD-MINE to discover frequent itemsets [5].

A T W  C T  C  T  T W  W  W  P1 P2  Fig. 4. Work carried out for each processor.

Algorithm: parallel TREESUPBDD-MINE1 Input: Transaction database, Minimal support  threshold (minsup).

Output: Set of frequent itemsets (IF ).

Begin2  If Master processor then3 /* Step 1: reading and extracting the 1-itemset4 */ Foreach (Transaction T ) do5  Foreach (X ? T ) do6 Add items(X , Li);7  End For;8  End For;9 /* Step 2: remove not frequent Itemsets */10 Remove item(Li,minsup);11 /* Step 3: Assignment the work to the12 workers */ Assignment(Li,nb processor);13 Foreach Worker processor do14  Send(Li);15  End for;16  End If;17 /* Step 4: create sub-tree TREESUPBDD for each18 processor */ Receive(Li);19 IFi = Create SubTree(Li, minsup, taskid);20 Send(IFi);21 If Master processor then22  Foreach Worker processor do23 Receive(IFi);24 IF=IF ? IFi ;25  End for;26  End If;27 return IF ;28  End29 Algorithm 2: Parallel Algorithm PARALLEL TREESUPBDD     Algorithm : Create SubTree1 Input: List of frequent 1-itemsets Li, minsup  and taskid Output: Sub-tree TreeSupBDD and their  frequents itemsets (IFi) Begin2  X = head of liste of frequent itemsets ;3 Foreach (X 6= ?) do4  Xsucc=X.next;5 XLf = ?;6 If (taskid == X .work) then7  kIF=kIF ? X;8 IFi= IFi ? kIF ;9 Foreach (Xsucc 6= ?) do10  SA=intersection(X.SupBDD,11 Xsucc.SupBDD); cardA=compute support(SA);12 If (cardA ? minsup) then13  insert(Xsucc, XLf );14  End If;15 Xsucc=Xsucc.next;16  End For;17 Create SubTree(XLf );18 Eliminate the last element of kIF ;19  End If;20 X=X.next;21  End For;22 return IFi;23  End24 Algorithm 3: Algorithm Create SubTree .

It has been developed in C language and it uses an adapted BDDs to represent frequent itemsets and to compute their supports. Our implementation relies on the buddy library : BuDDy - A Binary Decision Diagram Package (2). This free library can manage BDDs with a number of nodes up to 228, i.e., more than 250 million nodes. The parallel version have been implemented on a cluster of PC?s composed of 8 nodes with 3.0 GHz Pentium IV PCs connected with an ATM switch. Each node of the cluster is equipped with 512Mbytes main memory and run under Mandrake 10.0. All nodes of the cluster are connected by a 100Mbps FastEthernet. The communication primitives used by our proposed approach are part of the MPI (Message Passing Interface) communication library (3). MPI is a standard library that can be used to implement communication between distributed applications.

For our experimentations, we have used different dense and synthetic (4) databases. The description of these databases is given by the table IV.

The aim of the experiments is to study the performance of  2Available at: http://sourceforge.net/projects/buddy 3Available at: http://www.mhpcc.edu/training/workshop/mpi/main.html 4Available at: http://fimi.cs.helsinki.fi/data  DATABASES NUMBER OF NUMBER AVERAGE LENGTH TRANSACTIONS OF ITEMS OF TRANSACTIONS  MUSHROOM 8124 119 23 PUMSB STAR 49046 2088 51 CONNECT 67557 129 43 T10I4D100K 100000 1000 10  TABLE IV  CHARACTERISTICS OF DATABASES.

the parallel algorithm for real and sparse databases and for low thresholds. We report experimental results for different databases, different thresholds support and various number of processors. We evaluate the proposed approach in term of run time, speedup and efficiency.

A. Parallel run time  Figure 5 illustrates the run time variations for different type and size databases. From theses figures, we can conclude that  0.25     10  20  30  40  50  60  70  80  R un  tim e  (s )  minsup (%)  Connect  Parallel TreeSupBDD-Mine TreeSupBDD-Mine  0.25        0  1  2  3  4  5  6  7  8  9  10  R un  tim e  (s )  minsup (%)  Mushroom  Parallel TreeSupBDD-Mine TreeSupBDD-Mine  0.25     10  15  20  25  30  35  40  R un  tim e  (s )  minsup (%)  Pumsb_star  Parallel TreeSupBDD-Mine TreeSupBDD-Mine    0.05  0.1  0.15  0.2  0.25  R un  tim e  (s )  minsup (%)  T10I4D100K  TreeSupBDD-Mine Parallel TreeSuBDD-Mine  Fig. 5. Parallel run time vs sequential run time for different databases and different minsup?s.

the execution time for the parallel approach is better than the sequential one. Indeed, all the processors builds part of the tree TREESUPBDD in an equitable way. Hence, there is a reduction cost of construction of the sub-tree.

For the Mushroom, Connect, Pumsb star and T10I4D100K databases, we can compute frequent itemsets for low threshold.

B. Speedup study  We compute the scalability of the parallel application by executing them on 1, 4,... processors. The best speedup is between 6 and 7. This proves that parallelization is beneficially for each type of databases.

For each database, we executed our parallel algorithm on 2, 4 and 8 processors and we compare the mining time with the sequential algorithm. The speedup of the parallel version is shown in Figure 6. From these figures, we can see that the parallel version have obtained good speedups on most of the     tested datasets. The experiments show good speedups on real (dense) and synthetic (sparse) datasets. Speedup growth when the number of processor increase. We can justify this by the weak cost of the communication between processors. Indeed, the construction method leads to a natural parallelization, in the sense where each processor of a parallel architecture can construct locally its ordered structure. Once the local structures are constructed, a master processor can merge them to derive a global TREESUPBDD.

1.5  2.5  3.5  4.5  5.5  6.5  2  3  4  5  6  7  8  S pe  ed u  p  Number of processors  Connect 60% Connect 25%         2  3  4  5  6  7  8  S pe  ed u  p  Number of processors  Mushroom 5% Mushroom 0.1%         2  3  4  5  6  7  8  S pe  ed up  Number of processors  Pumsb_star 40% Pumsb_star 20%  1.5  2.5  3.5  4.5  5.5  6.5  2  3  4  5  6  7  8  S pe  ed up  Number of processors  T10I4D100K  T10I4D100K 0.25 T10I4D100K 0.025  Fig. 6. Speedups evolution for different databases and different minsup?s.

C. Efficiency study  Figure 7 illustrates the evolution of efficiency of our ap- proach. Based upon four figures, we can note the following remarks:  ? The efficiency is between 0.32 and 1 for different databases  ? The efficiency is more interesting in the case of dense databases that sparse ones.

? A good efficiency is obtained for threshold between 5% and 60%.

Indeed, each processor builds a sub tree of TREESUPBDD without need communication with other processor.



V. CONCLUSION  In this paper, we proposed a new parallel algorithm for mining frequent itemsets. The algorithm is built based on a canonical form called TREESUPBDD. The basic idea relies on the construction of TREESUPBDD in a parallel way. Indeed, the construction method leads to a natural parallelization, in the sense where each processor of a parallel architecture can construct locally its ordered structure. Once the local structures are constructed, a master processor can merge them to derive a global TREESUPBDD. Our experiments consistently showed that a better performance was obtained when applying PARALLEL TREESUPBDD- MINE as it performs in polynomial fashion. The results we achieve on real data sets were very promising and may also be compared with those obtained in the literature. An  0.6  0.65  0.7  0.75  0.8  0.85  0.9  0.95   2  3  4  5  6  7  8  E ffi  ca ci  ty  Number of processors  Connect 60% Connect 25%  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   2  3  4  5  6  7  8  E ffi  ca ci  ty  Number of processors  Mushroom 5% Mushroom 0.1%  0.5  0.55  0.6  0.65  0.7  0.75  0.8  0.85  0.9  0.95  2  3  4  5  6  7  8  E ffi  ca ci  ty  Number of processors  Pumsb_star 40% Pumsb_star 20%  0.6  0.65  0.7  0.75  0.8  0.85  0.9  2  3  4  5  6  7  8  E ffi  ca ci  ty  Number of processors  T10I4D100K  T10I4D100K 0.25 T10I4D100K 0.025  Fig. 7. Efficiency for different databases.

interesting research direction is therefore to find a distributed solution of this algorithm on a grid computing to see whether it can improve these performances.

