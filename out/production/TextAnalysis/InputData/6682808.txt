An Analysis of Vendor Lock-in Problem

Abstract-Big data storage is a considerable challenge for IT organizations. Cloud providers promote using cloud storage for this purpose. However, vendor lock-in problem prevents organi? zations to migrate toward cloud storage. An evident solution is to distribute redundant data across multiple cloud providers in order to increase the probability of access to data. This paper analyses such a solution that uses erasure coding as a method of distribution. We study the effect of system parameters such as failure rate, redundancy ratio and number of initial block on data access. We show that the probability of access to data varies logarithmically in terms of time and number of initial block.

Further increasing redundancy ratio is not always effective.

Index Terms-cloud computing; cloud network; vendor lock? in; reliability;

I. INTRODUCTION Today, the amount of data to be stored and produced  is increasing rapidly [1]. The problem of Big Data arises when the volume of data is so huge to manage on available systems. The content of large websites, social networks, com? plex physics simulation, and business informatics are classic examples of Big Data. Public cloud providers claim that they can handle Big Data of other organizations easily and with a reasonable cost in comparison to in-house solutions. These public clouds offer interesting options like dynamic capacity, pervasive access and high availability using replication [2], [3].

They introduce pay-as-you-go model for economic model [4].

In this model a user must pay relative to his usage (payment is not constant). Howerver, pay-as-you-go has another side.

Providers have no commitment to continue services with the same price. In this model cloud users are vulnerable to price increases or even providers going out of business. These con? cerns prevent some organization from adopting cloud storage.

In economics, this issue is called vendor lock-in [5].

An obvious method for vendor lock-in problem is based on distributing chunks of Big Data on various providers. This ap? proach relies on a new paradigm in cloud computing context, called Inter-Cloud. Informally Inter-Cloud is a set of clouds which compose a cloud (i.e. cloud of clouds) [6]. There are some works based on this idea like RACS which uses a proxy server as a broker to manage transactions between client and cloud providers [9]. STRATOS is another implementation of Inter-Cloud. It focuses on automatic cloud provider selection   Fatemeh Ghassemi Formal method Lab  School of Electrical and Computer Engineering University of Tehran  Tehran,Iran fghassemi@ece.ut.ac.ir  for resource allocation to process running on multiple cloud providers [7]. Another data management implementation is FRIEDA. To achieve various data management strategies it separates data control and execution. This data management is robust and elastic [8].

In this paper, we consider erasure coding as a method for spreading of data over multiple cloud providers. The designers of RACS system also apply erasure coding for this purpose [9].

They provide empirical evidence that a distributing mechanism based on erasure coding improve data access considerably in comparison to simple replication of data. However, there is no comprehensive analysis of the capabilities and potentials of this method. Here we provide a rigorous analytical model for this method. This model and derived analytical results give insightful view about the capacities of this method.

Our contribution in this paper is getting insight into the factors affecting the distribution of data across multiple cloud providers. We calculate the probability of access to data in terms of time, failure rate, redundancy ratio and number of initial blocks variations. Obtained results indicate that as the time progresses or number of initial block increases the probability of unavailability of data logarithmically reaches to one. The probability of unavailability of data decreases by increasing redundancy ratio. But when it reaches a specific value, there is no a significant decrease in the probability.

Increasing initial number of blocks of data also improves data availability when failure rate be less than a specific value. But it degrades data availability after failure rate exceeds. The rest of this paper is organized as fallows.

We describe vendor lock-in problem in section II. Section III introduces model and notation we used. In section IV we analyse effect of data distribution parameters (i.e. redundancy ratio, number of initial block and failure rate) on availability of data. In section VI we conclude our study and propose routes for future work.



II. VENDOR LOCK-IN PROBLEM For any time and from everywhere accessibility of huge  data, cloud storage is one of the best choices in today world. However, cloud providers guarantee high availability and reliability of data, but there are situations where client of     cloud provider may not be able to access its data. One of them is when vendor lock-in problem occurs.

Talking about cloud storage, it is said vendor lock-in occurs when accessing to data is impossible or very hard because of high cost. We clarify this concept in the following example.

Suppose a company stores its data (usually its volume is in order of Terabyte) on one cloud storage. This company access to its data every day by billion clicks. Each click consumes a little bandwidth (e.g. some kilobytes). Based on cloud cost model this company should purchase storage space. It must pay for consumed bandwidth as well. If cloud provider decides to increase bandwidth charge (e.g. increase one cent per each kilobyte) the company is faced with a terrible increase in its costs. It may not be cost-effective for company to continue using cloud storage. Such variations in financial decisions provide a monopoly for cloud provider over its clients. The more the volume of data, the higher risk of financial loss as well as the lower data accessibility. In addition to economic factors, political situation and other cloud provider policies can cause situations where data is available but not accessible to cloud user.

Replication is a solution for vendor lock-in problem. Client can use multiple cloud storage and distribute its data over them. The idea is known as sky computing [10]. Sky com? puting is part of more general idea called inter-cloud. Inter? cloud (or cloud of clouds) tries to achieve more availability, elasticity and better SLA using multiple cloud providers. In sky computing (or Multi -Cloud) several cloud provider are used and managed independently by a client. These cloud providers necessarily don't have information about one another [6].

The way data are distributed over cloud storages, the re? dundancy ration and how data are fragmented and some other environmental parameters like failure rate affect availability and access time of data. In the next sections we analyze this environment.



III. ENVIRONMENT MODEL AND NOTATIONS We consider a cloud environment composed of multiple  cloud providers. We want distribute a big file ? which is fragmented into m distinct initial blocks {b1, b2, ... , bm} on the cloud storages. For better distributing we use erasure coding instead of normally replicate blocks of file. This coding gets a file with m initial block as input and creates n (n ;::: m) shares X = {shl, Sh2' ... , shn} . File ? can be recovered if there exist any subset of shares with size m . In this model for simplicity we assume that  ? each share goes out independent from other shares (ac?  tually it is not true).

? the probabilistic distributions of this event for all shares  are the same.

? If one share goes out,it does not become available again.

We do not use the word failure for the event, because a share may does not fail but it is not accessible (e.g. because of high cost). For each share we define xshi i=1,2, . . .  ,n be a real random variable of the time in which could no longer   shares  -------.

-------.. ------------------------------------------------1 o 0 o 0 o 0 o 0 o 0 ------+-----------------, : o I 0 o 0 0 : I I  time  Fig. 1: Ascending order of time of unavailability of shares  access to ith share. So FXsh (t) = P(XShi < t) is the cumulative probability distribution function of XShi . By the above assumption Xsh, i=1,2, . . .  ,n are i. i. d. Thus we have:  We want to analyze availability of file ? when it is distributed and stored in this environment. For this purpose we define T be the real random variable equal to the time after which file ? cannot be recovered. In the next section we calculate the probability P(T < t) .



IV. ANALY SE AND RESULTS  We use probabilistic method to analyse availability of data when distributed across multiple cloud storages. As stated in previous section, T is a random variable which determine the time when the file ? is no longer recoverable. We define FT(t) = P(T < t) the cumulative probability distribution function of T.

A. Calculation of probabilistic distribution  To calculate FT(t) , we should accurately calculate the time . Based on erasure coding, the file is recoverable as long as a subset of shares with minimum size m exists.

We sort shares based on the time when they go out (or be inaccessible) then we call Xsh; the time at which ith share goes out. According to Fig. 1 it can be understood that the sequence, (Xsh(I)' XSh(2)' ... , XSh(n)) is a permutation of sequence,(xShllxsh2' ... ,Xshn). By progress in time, After XSh1, n - 1 shares have been remained. With the passing of XSh2 one other share goes out, thus there is n - 2 shares remaining. And so, after Xsh" n - i shares are remained. This induction implies that, xSh(n_m+l) is the time after which less than m shares is remained. So after this time file ? cannot be recovered. By definition of T at the end of previous section , it is understood that T is equal to xSh(n_=+l)'     To obtain xSh(n_m+l) , we need to define it (or XSh(i ) ) more accurately.xsh(.i) is equal to one of the Xshl' XSh2, ... , Xshn . As we stated in the above lines, the sequence (Xshl' XSh2' ... , XshJ is a permutation of (Xshl' Xsh2' ""XshJ but the sorted one. Thus XShl is mini? mum of {Xshl' XSh2, ... , Xshn} and Xshn is the maximum. Now we can accurately define XSh(i ) .

Definition 1. XShi is ith smallest {Xshl' Xsh2,,,,,Xsh,J . On the other hand, Order Statistics of {XSh1, XSh2, ... , Xsh.,J .

element of  XShi is ith  If Xl, X2, . . .  , Xn be n independent and identically dis? tributed ( i. i. d) random variables. And F(x) be the cumulative distribution function (cdt) of each of them, then the cdf of ith the order statistics of those variables is given by :  F(i)(X) = t (;) (F(x) ) j(l-F(x) ) (n-j) [11] (2) J=' Using (2), and also due to T is (n - m + l) st order  statistics of {Xshl' Xsh2,Xsh3, ... ,Xshn}, FT(t) is obtained from following expression:  FT(t) = t (n) (Fx(t) ) j  (1 -Fx(t) ) (n-j) (3) j=n-m+l J  The exponential distribution is a simple and suitable prob? abilistic distribution for time of failure and availability like events. [12]. We consider that, Xshi i=1,2, . . .  ,n have exponen? tial distribution with parameter >- which is the rate of failure to whole system (i.e. to each of shares). Finally the probabilistic distribution of time of availability of file ? is calculated as follows:  FT(t) = " n (n) (1 _ e-)"t) (e-)"t) n-j ?J=n-ml J  = e-Atn x [2:?=n-m+1 G) (1 -e-)..t/ (e- )"t) j] ---+  = e-)..tn x [2:?=n-m+1 G) (e)..t -l) j] (4)  B. Analyse the results In this subsection we analyse distribution of a big file on  multiple cloud providers. In order to evaluate the availability of such file , we write several scripts in Matlab to get insight of the behaviour of FT(t) which is calculated in 4. There are four important parameters, time of unavailability ( t), failure rate to whole system (>- ), number of initial blocks of file (n ) and redundancy ratio of using erasure coding ( r = .!!:. ) affect , m FT(t) . We plot variation of availability of big file (we call ?) in terms of these parameters.

In Fig. 2 the behaviour of FT(t) when t varies is presented.

in all charts the vertical axis represents the probability of file ? could not be accessed after time t and horizontal axis is time.

As can be seen, the probability of unavailability increases with the progress of time. All charts in Fig. 2 show that increasing in failure rate to whole system, also decrees the availability.

Charts of Fig. 2 are different in number of initial blocks and     (a) n=2,m=2  (e) n=3,m=3  (e) n=4,m=4  (g) n=5,m=5  ? 07 , ? 0.6 1 ? O? ? 04 <  (b) n=3,m=2  (d) n=5,m=3  (f) n=6,m=4  (h) n=7,m=5  ......... Iambda = 0.100000 ........... lambda = 0.200000 -- lambda = 0.300000 ........... lambda = 0.400000 _ lambda = 0.500000 -+-Iambda = 0.600000 ......... Iambda = 0.700000  lambda = 0.800000 -+-Iambda = 0.900000  (i) the legend:different .\  Fig. 2: Probability of unavailability in terms of time. Figures (a-h) are different in number of initial bloack and redundancy ratio     ? 0.7 i ? 0.6 ! !jO_5  ! 0.4 - ... -??1. " ?  , 1.2 1.4 16 1.8 2 22 2.4 26 28 3  redundancy ration  Fig. 3: The effect of redundancy ratio on availability. This chart is not smooth because of ceiling effect. t = 1 , A = 0.5  redundancy ratio. Generally, it can be understood that when redundancy ratio increases, the availability improves.

The effect of redundancy ratio is accurately presented in Fig.

3. This graph presents that the probability of ability to access to file ? before time t increases by increasing the redundancy ratio. But after a specific value (e.g. 2.4 in our examples) it does not have any significant effect. We can also understand, for practical probability of ability to access (more than 0.9 ) system is insensitive to number of initial block.

Another important result of this graph is that, it does not need to spend too much for redundancy to achieve high probability of access. The behavior of diagram shows that in specific interval (e.g. 1.4 to 1.6 in our diagram) little increase in redundancy can improve probability of access very much.

Number of initial blocks of file is also important. On the other hand, the way the file is fragmented can affect probability of access to file. This result is shown in 4. In this part of analyse we see an interesting result. In this figure by increasing number of initial block, probability of access decreases in different failure rates (i.e. more initial block has negative effect). But as redundancy ratio increases we see different behaviours in curves of each diagram.

For example in Fig.4d when failure rate is less than 0.5, the more initial block the higher availability. But when failure rate exceeds 0.5, less initial block provides higher availability.

Previous result is clearly presented in Fig. 5 the combined effect of failure rate and number of initial blocks on avail? ability. In this figure it is obvious that there is a threshold for failure rate. If system faces with a failure rate less than the threshold, increasing in number of initial blocks improves availability but after the threshold it has negative impact. It is worth mentioning that value of this threshold is highly related to redundancy ratio. We can increase redundancy ratio until remove the threshold.

In the charts of Fig. 6 we can see the effect of redundancy ratio on the threshold. These results show that by increasing redundancy ratio, threshold of failure rate goes ahead to the infinity. When redundancy ratio equals to 3 there is no threshold.

To distribute blocks of file on multiple cloud providers we should consider the environment features (especially failure   (a) r = ? = 1 (b) r = ? = 1.4  (c) r = ? = 1.8 (d) r = ? = 2  (e) r = ? = 2.4 (f) r = ? = 2.6  ?O,1 i ? 08 ? OS ? o,?  (g) r = ? = 2.8 (h) r = ? = 3  -+- lambda = 0.100000, t = 1.000000 -+- lambda = 0.200000, t = 1.000000 _ lambda = 0.300000, t = 1.000000 -- lambda = 0.400000, t = 1.000000 _ lambda = 0.500000, t = 1.000000 _ lambda = 0.600000, t = 1.000000 -+-Iambda = 0.700000, t = 1.000000 -+- lambda = 0.800000, t = 1.000000 -*- lambda = 0.900000, t = 1.000000  (i) the legend: different ),.

Fig. 4: Effect of number of initial blocks of file on availability.

The charts in this figure are different in redundancy ratio. t = 1 in all charts.

Fig. 5: the combined effect of failure rate and number of initial blocks on availability.r = ? = 2  (a) r = :;; = 2  (c) r = :;; = 2.4  (e) r = :;; = 2.8  ;"0,7 , ? o,e ! ? os ? o,?  (b) r = :;; = 2.2  (d) r = :;; = 2.6  (f) r = :;; = 3  --&--m= = 2 ......... m= = 6  m= = 10 -m= = 14 _m= = 18  (g) the legend: differ? ent .\.

Fig. 6: The Effect of redundancy ratio on failure rate threshold   rate). Then we should determine number of initial block and redundancy ratio based on required availability.



V. CONCLUSION AND FUTURE WORK  In this paper we analyse distribution of a big file on multiple cloud providers which is a solution for vendor lock-in problem.

We consider a big file with several initial blocks. To distribute this file in more reliable manner we use erasure coding. By this coding initial blocks redundant to shares and these shares are distribute over cloud providers. The whole file is recoverable as long as at least a subset of shares with minimum size exists.

Each of shares can become inaccessible.

For simplicity we assume that the event of inaccessibility occurs independently to each share and we share be inac? cessible it no longer become accessible. These assumptions are not true in practice. For example all shares those stored in the same cloud provider together become inaccessible. So the inaccessibility of them is dependent to each other. Second assumption also may be not true. When a share is inaccessible if it is corrupted, repair can bring it back. But if that share be inaccessible because of high cost it may no longer become accessible.

For the future work, we can ignore the simplicity assump? tion. Inaccessibility of shares which are in the same cloud storage is dependent to each other and independent from other shares those stored on the other storage. Moreover it can be considered that shares are repairable (but not in situations where cost is the reason of inaccessibility). For better intuition of vendor lock-in problem, the effects of cost variation on probability of availability of data must be investigated.

