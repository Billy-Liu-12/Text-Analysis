Combining Frequent 2-itemsets and Statistical  Features for Texture Classification in Wavelet

Abstract?This paper studies a new method of texture image classification using the combination of frequent 2-itemsets and statistical features based on the discrete wavelet transform (DWT). DWT is firstly used to decompose images into different scale subbands. Then features differentiating textures for classification are extracted from these subbands. Frequently occurring local structures in images are captured from the approximation regions of one-level DWT decomposition images in the form of frequent 2-itemsets, which contain both structural and statistical information. To reduce redundancy, the paper adopts a diamond-shaped structure as the sliding window to construct transactions. Statistical features of the detail regions are then calculated and combined with frequent 2-itemsets to classify texture images. The experiments are conducted on two texture image sets, and the results show the good performance of this method.

Keywords?Texture classification; frequent 2-itemset; discrete wavelet transform; feature extraction

I. INTRODUCTION As an important feature of images, texture reflects space  distribution of gray-scale mode and also gives attention to macrostructure and microstructure [1]. Because texture description can intuitively provide region smoothing, regularity and other characteristics and also be unsusceptible to outside influence, it plays a very important role in image analysis.

Texture classification is an enduring hot research area of image processing, resulting in a lot of texture classification methods, such as gray level co-occurrence matrix (GLCM), gray level run length (GLRL) method and autocorrelation function method [1-3]. Meanwhile, new theories such as fractal theory, Markov random field (MRF) and wavelet theory are gradually introduced into texture classification [4-6]. These theories and their combinations have obtained good results in texture classification. Spatial locality of wavelet performs noticeably well and is helpful to keep local details. Recent researches on texture analysis show that algorithms using multiresolution wavelet transform have achieved very good performance [7].

Extraction of appropriate attributes or features that differentiate textures is the crux of effectively solving texture  classification. Recently, using association rules as texture features gradually becomes a hot spot [8-11]. Applied to texture classification and image segmentation by Rushing et al.

[12, 13], frequently occurring local intensity variation in textures is used to construct association rules. Their experiment studies have shown that the accuracy rate of texture classification using association rules as texture features is higher than that of other methods using GLCM, GLRL, fractal dimension, MRF, and Gabor filter-based features. Then the wavelet domain association rules generated as texture features instead of the intensity domain association rules have appeared in [14]. And the experimental results show the effectiveness of that method. However, mining all frequent itemsets and interesting association rules is computationally expensive and requires large memory space. The relative frequency of similar local structures appearing in each of the images belonging to a certain class should be identical or similar. Furthermore, frequent itemsets are able to describe all the local structures of an image. Thus, a new texture classification method is proposed in this paper.

Discrete wavelet transform (DWT) is applied on each texture sample and we get an approximating low-pass subband and three detail high-pass subbands. In the process of feature extracting, frequent 2-itemset features are extracted from the approximation subband of one-level DWT decomposition.

Instead of mining all frequent itemsets and interesting association rules, our method only produces 2-itemsets to construct texture classification features and it can enhance temporal and spatial performance further. Because the approximation subband has only 1/4 amount of data as the original image, this reduce the time consuming greatly compared with [12]. Statistics of detail subbands are then employed as a part of texture features. In the process of classification, we use the distance measure as the classifier through comparing the different feature vectors of texture images obtained previously. Experimental results show that our method has high efficiency and can obtain good classification results.

The organization of the paper: Section II presents some of the basic theories and concepts; feature extraction and texture classification are introduced in Section III; texture classification experiments and results are discussed in detail in     Section IV; finally, conclusions and expectations are made towards the entire work of the paper.



II. DEFINITIONS AND IMPORTANT CONCEPTS  A. Discrete Wavelet Transform By applying DWT, an image is decomposed into four  subbands as shown in Fig. 1. These subbands are respectively marked as LL, HL, HH and LH, among which HL, HH and LH represent detail subbands, while LL corresponds to coarse level coefficients, known as approximation subband. The values or transform coefficients of each subband are essential characteristics for texture analysis and discrimination. DWT can be iteratively applied on the subband LL for multiresolution decomposition, which, however, is not required in our paper, for our study only processes one-level decomposed subbands. Due to the adoption of orthogonal wavelet decomposition, four subbands are independent of each other and redundant information does not exist among them.

Using all subbands to extract classification features seems essential. As a result, in this paper frequent itemset features are extracted from LL subband, while mean and standard deviation features are extracted from subbands of HL, HH and LH. The combination of these features is used for texture classification below.

LL HL  LH HH  Fig. 1. One-level DWT decomposition  B. Apriori Algorithm Finding frequent itemsets is the key step of mining  association rules, resulting in many related researches. Apriori algorithm proposed by R. Agrawal and R.Srikant [15] is a fundamental algorithm to mine all frequent itemsets. For the sake of clarity, some basic concepts used in the algorithm are introduced as followings.

Support. Let I be an itemset, 1 2{ , , , }mI I I I= . Let D be a set of database transactions in which each transaction T is a nonempty itemset such thatT I? . For a given itemset X, T is a transaction that contains X if and only if X T? . The support of X is defined as the ratio of the number of transactions which contains X to the total number of transactions of D.

Frequent itemset. Given an itemset X, if the support of X is greater than or equal to the user specified minimum support level, saying that X is frequent. A frequent itemset containing k items is called frequent k-itemset.

Apriori algorithm is based on a special category of properties called anti-monotonicity which means that if an itemset cannot pass a test, then all its supersets cannot also pass the test. An iterative approach known as a level-wise search is employed by Apriori, where k-itemsets are used to explore (k+1)-itemsets. First, the set of frequent 1-itemsets is found by  scanning the database to accumulate the count of each item and collecting those items that satisfy minimum support value.

Then, the result set denoted by L1 is used to find L2, the set of frequent 2-itemsets, which is used to find L3, and so on, until no more frequent k-itemsets can be found. It requires one full scan of database to find each kL .

As discussed above, Apriori algorithm is based on breadth- first, scanning the database at a time to find out each set of complete frequent k-itemsets. Only 2-itemsets are required in our study. Therefore, some modifications and restrictions are applied on Apriori algorithm so that the algorithm stops when all the frequent 2-itemsets have been generated. Compared with generating all the frequent itemsets, it can greatly reduce the mining time.



III. FEATURE EXTRACTION AND TEXTURE CLASSIFICATION  A. Extracting Frequent 2-itemset Features Usually, with the direct use of mining algorithm on gray-  level images or decomposed images, visual similar texture patterns produce few frequent itemsets, for two identical instances of a texture pattern appear similar seldom. This means that common structures in images will not be recognized by the mining algorithm, because itemsets standing for them are different in fact and would be discarded for not meeting the support condition. In addition, the absolute strength levels depend on light and do not provide any texture information.

Therefore, some efforts are made to process the obtained subbands so that such a texture structure can be preserved and the interference of absolute strength will be ignored, which is actually the quantization step in the following passage. Some concepts used in the task are defined ahead as follows:  Root pixel.  A pixel is exactly defined as a root pixel, if it is the center of the given diamond-shaped neighborhood with n pixels in the diagonal line. Thus, there exist 2( 1)N n? + root pixels in an image of size N N? . Fig. 2 is an example of a root pixel.

Transaction. Given a root pixel, each pixel in its neighborhood can map to an item. Then, a transaction is the set of items associated with a root pixel. So each root pixel corresponds to a unique transaction with all its neighborhoods in.

According to the method given in [12], the quantization process in the paper is conducted around the neighborhoods of each root pixel according to (1), where value is the value of the root pixel of the diamond-shaped area with diagonal lines of size n. Both the mean ? and the standard deviation ? are computed in these areas. Here c is a constant, and we select 0.3.

2 3 4   Fig. 2. An example of root pixel        value c Quantized value c value c  value c  ? ? ? ? ? ?  ? ?  ? ? ? = ? ? < < + ?  ? + ? (1)  Using an n n? sliding window to construct transactions can bring about much repetitive computation. For example, when n is equal to 3, 2-itemsets representing same related information appear and are calculated four times in different transactions.

Moreover, it is also found that long frequent patterns appears rarely even under the condition of a low support. Consequently, using fewer items to construct a transaction seems reasonable and essential. According to the above analysis, instead of the n n? rectangle, a diamond-shaped structure with the diagonal length of size n is designed as the sliding window to construct transactions. A sliding window with the diagonal length of size 3 is indicated by shading in Fig. 3. As a result, a transaction formed by this is a vector of size1 5? . Then using mining algorithm, frequent 2-itemsets and their supports can be generated from the database constructed from texture images.

As the mining algorithm used in this paper is executed with only 0 and 1 as input, it is still required to map each item into a vector composed of 0 and 1 values. According to the mapping method given in [14], quantized value 0, 1 and 2 are mapped to (100), (010) and (001) respectively. Then a transaction, which is a vector of size1 5? before mapping, is transformed into a vector of size1 15? .

2 0 2 1 0  0 2 0 2 1  1 1 2 0 2  2 2 0 2 1  1 0 2 1 2  Fig. 3. Sample image  The following example is helpful to understand the procedure more clearly. There exist 2(5 3 1)? + root pixels in the sample texture image of size 5 5? shown in Fig. 3. So a total of 9 transactions are to be formed when the sliding window moves through all the root pixels. Then every transaction is mapped to a vector consisting of only 0 and 1.

TABLE I shows the transaction database generated from the example image.

The Apriori algorithm discussed earlier is used to mining the transaction database created from the example image. Let minimum support value be 0.4. All the frequent 2-itemsets and their corresponding support values produced by the algorithm are recorded as shown in TABLE II.

When all the frequent 2-itemsets for an image are generated, the mining result is used to construct frequent 2-itemset features according to the following method. All possible combinations of two items both contained in the set of frequent 1-itemsets are enumerated according to the lexicographic order.

During the process, if the 2-itemset being enumerated is a  frequent 2-itemset, then record the support of it obtained from the above mining stage as the component's value, else zero is recorded, for infrequent itemsets do not contain or contain little classification information and even sometimes mislead the right classification. All these are done so that the whole components in different vectors can correspond with each other.

The features obtained here are defined as frequent 2-itemset feature vector (F2FV). It is easy to see that F2FV has a total of 2kC components where k is the number of frequent 1-itemsets.

TABLE I.  TRANSACTION GENERATION  Root pixel Quantized value Mapped value (I1, I2, I3,...,I15) 1 2 3 4 5 1 0 0 2 0 1 100100001100010 2 2 2 0 2 2 001001100001001 3 1 0 2 1 0 010001001010100 4 2 1 1 2 2 001010010001001 5 0 1 2 0 0 100010001100100 6 2 2 0 2 2 001001100001001 7 1 2 2 0 0 010001001100100 8 2 2 0 2 2 001001100001001 9 0 0 2 1 1 100100001010010  TABLE II.  THE RESULTS OF MINING FREQUENT 2-ITEMSETS  Frequent 2-itemset I3-I12 I3-I15 I12-I15 Support 0.44  0.44  0.44    B. Generation of Statistic Features Four subbands LL, HL, HH and LH can be obtained from  an original image according to DWT decomposition discussed in Section 2. The mean and standard deviation of the latter three subbands HL, HH and LH are respectively calculated according to the formulas given in (2) and (3).

1 1  ( , ) N N  i j  1mean p i j N = =  =  (2)  1 1  1 ( ( , )- ) N N  i j standard deviation p i j mean  N = = =  (3)  Where ( , )p i j is the transformed value in ( , )i j for any subband of size N N? . For any original image, there are six statistics obtained in total using the above procedure. The obtained features are denoted as statistic feature vector (SFV) which is further used to construct image classification features combined with frequent 2-itemsets extracted above.

For simplicity, we define the combination of F2FV and SFV as combination of feature vectors (CFV) and will use it to build texture features for classification. It's evident that the length of CFV here is 2( +6)kC .

C. Texture Classification For each DWT decomposition texture image, texture  features are extracted in accordance with the above-mentioned methods. Each texture image corresponds to a unique feature vector. For training classification, a classifier is firstly built using a fixed percentage of sample images from each texture class in the training phase. Then an unknown texture image from the image set, which is disjoint with the one for training, is determined to belong to the class possessing the shortest distance with it by using the minimum distance classification.

The distance measure used for comparing and retrieving the similar features is defined to be   ( , ) ( ( )- ( )) L  m x i  d m x f i f i =  =  (4)  Where m and x denote the features of known m-th texture image and the features of unknown texture image X respectively. L is the length of the feature vector, and ( )f i represents i-th component of features. Then the unknown texture is classified as m-th texture when ( , )d m x is minimum among all textures. For no training classification, texture samples with shortest distance will be recognized as a class.



IV. EXPERIMENTAL RESULTS AND DISCUSSIONS The experiments consist of two parts conducted with  texture image set I and texture image set II, respectively. Both F2FV and CFV are used as classification features for comparison. We adopt the diamond-shaped structure with the  diagonal length of size 3 as the sliding window and set minimum support value to be 0.02.

A. Experiments with Texture Image Set I The experiments are firstly done with 40 texture images,  each of size 640 640? , taken from Brodatz's album [16] shown in Fig. 4. Every image is regarded as a texture class. Then, a total of 640 sub-images are constructed by dividing each texture image into non-overlapping 16 texture images of size 160 160? . According to the methods proposed above, texture features are extracted from these sub-images for classification. During the process of training classification, 4 sample images for each type of texture (a total of 160 for all the classes) are used to train a classifier which is used to discriminate the other 480 sample images.

The detailed results for classification of texture image set I are showed in TABLE ?. It is clear to see that the excellent results are obtained with most of all the classes of texture images, while the results for D44 and D69 are little poorer.

Moreover, it is found that these sub-images with poorer results vary greatly in visual sense. Meanwhile, the classification results with training are generally higher than that with no- training, and it is equally true for all the methods for texture classification. The overall accuracy of the classification is calculated by summing success rates of all the classes and dividing the sum by the total number of classes in the test set.

Then, the overall accuracies with training are 94.1667% and 96.25% for F2FV and CFV respectively, while they are 84.9167% and 87.25% with no training. The experimental results indicate that using CFV as texture features generally tends to produce better classification results than using F2FV.

Fig. 4. Texture image set I. From left-right and top-bottom: D1, D103, D104, D105, D106, D15, D16, D18, D20, D21, D26, D34, D37, D38, D44, D47, D49, D50, D51, D53, D55, D56, D6, D64, D65, D68, D69, D70, D72, D76, D77, D78, D79, D82, D83, D85, D93, D94, D95, D96(The D* indicate textures from the Brodatz Album.)     TABLE III.  CLASSIFICATION RESULTS FOR TEXTURE IMAGE SET I (%, THE D* INDICATE TEXTURES FROM THE BRODATZ ALBUM.)  Texture images With training Without training F2FV CFV F2FV CFV  D1 100 100 89.1667 89.1667 D103 100 100 80 82.5 D104 100 100 82.5 80.4167 D105 75 83.3333 52.9167 67.5 D106 83.3333 100 49.5833 55.4167 D15 91.6667 100 63.75 70 D16 100 100 100 100 D18 100 100 99.1667 99.1667 D20 100 100 100 100 D21 100 100 100 100 D26 91.6667 100 94.1667 96.6667 D34 100 100 100 100 D37 100 100 98.3333 97.9167 D38 75 75 45.8333 54.5833 D44 66.6667 66.6667 40.4167 39.1667 D47 100 100 100 100 D49 100 100 100 100 D50 91.6667 91.6667 81.6667 81.6667 D51 100 100 78.3333 80 D53 100 100 100 100 D55 100 100 100 100 D56 100 100 92.9167 95.8333 D6 100 100 97.9167 97.9167 D64 100 100 86.25 90.8333 D65 100 100 94.5833 97.0833 D68 100 100 99.5833 100 D69 66.6667 66.6667 44.1667 47.0833 D70 91.6667 100 89.1667 90.4167 D72 75 83.3333 38.75 41.25 D76 100 100 100 100 D77 100 100 100 100 D78 100 100 79.1667 91.6667 D79 91.6667 100 68.3333 88.3333 D82 100 100 99.1667 100 D83 100 100 100 100 D85 100 100 90.8333 92.5 D93 66.6667 83.3333 74.5833 78.75 D94 100 100 87.5 86.25 D95 100 100 97.9167 97.9167 D96 100 100 100 100 Overall accuracy 94.1667 96.25 84.9167 87.25  B. Experiments with Texture Image Set II In order to evaluate the effectiveness of the proposed  method further, experiments are also conducted with 10 Brodatz texture images of size 512 512? obtained from [16, 17], as shown in Fig. 5. 50 subsamples of size128 128? were obtained by randomly subsampling every original texture image, resulting in a classification of 500 samples in total. In training classification, one fifth of all 500 sample images (10 samples for each type of texture) are used to train a classifier, while the remainder is used as test images. TABLE ? shows the results for classification of texture image set II in detail. We can see that the overall accuracy is 100% with training classification, 98.1592% with no training classification for CFV, which is better than that in the experiment study of [14].

Fig. 5. Texture image set II. From left-right and top-bottom: Brick wall (D94), Grass (D9), Gravel, Bark (D12), Herringbone weave (D15), Plastic bubbles (D112), Rough wall, Wood grain (D68), Hall (D25), Raffia (D84)  TABLE IV.  CLASSIFICATION RESULTS FOR TEXTURE IMAGE SET II (%)  Texture images With training Without training F2FV CFV F2FV CFV  Brick wall 100 100 93.3878 95.7551 Grass 100 100 97.551 98.898 Gravel 100 100 96.4898 98.2857 Bark 100 100 99.9184 99.8367 Herringbone weave 100 100 98.7755 100 Plastic bubbles 100 100 97.7969 99.7143 Rough wall 100 100 88.1613 89.102 Wood grain 100 100 100 100 Hall 100 100 100 100 Raffia 100 100 100 100 Overall accuracy 100 100 97.2082 98.1592

V. CONCLUSIONS AND EXPECTATIONS Owing to a wide range of applications, texture  classification has been a hotspot recently. This paper presents a new method for texture classification. The method extracts 2- itemset features and statistical features from different subbands based on wavelet decomposition, and uses the combination of them as texture classification feature vector. Compared with the method of directly generating association rules on an original image, computational complexity is greatly reduced.

The combined feature vector captures structural information as well as statistical information and can differentiate different texture images effectively. And the experiments verify that the proposed method can obtain encouraging results and has outstanding discrimination for texture images, even when the number of classes is large.

The feature vector constructed in this paper is believed to have a good performance on texture segmentation. Using the proposed method based on wavelet decomposition of original images for texture region segmentation is our next work.

