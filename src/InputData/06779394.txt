An approach towards comprehensive sentimental data  analysis and opinion mining

Abstract?The world wide web can be viewed as a repository of opinions from users spread across various websites and networks, and today?s netizens look up reviews and opinions to judge commodities, visit forums to debate about events and policies.  With this explosion in the volume of and reliance on user reviews and opinions, manufacturers and retailers face the challenge of automating the analysis of such big amounts of data (user reviews, opinions, sentiments). Armed with these results, sellers can enhance their product and tailor experience for the customer. Similarly, policy makers can analyse these posts to get instant and comprehensive feedback. Or use it for new ideas that democratize the policy making process. This paper is the outcome of our research in gathering opinion and review data from popular portals, e-commerce websites, forums or social networks; and processing the data using the rules of natural language and grammar to find out what exactly was being talked about in the user's review and the sentiments that people are expressing. Our approach diligently scans every line of data, and generates a cogent summary of every review (categorized by aspects) along with various graphical visualizations. A novel application of this approach is helping out product manufacturers or the government in gauging response. We aim to provide summarized positive and negative features about products, laws or policies by mining reviews, discussions,, forums etc.

Keywords?sentiment analysis; opinion mining; data visualization; review mining;

I.  INTRODUCTION Today the sheer volume of data being that is generated ever  is enormous and making any sense out of that data is a tedious task. However, constant efforts and research in this area have led the automation of the process to some extent. With this project, we aim to further this automation process. Using a combination of data aggregation techniques, NLP, linguistic analysis and popular visualization techniques we generate visually appealing and easy to understand graphs which provide summarized feedback. This is done by performing detailed sentiment analysis on the data. The fields of opinion mining and sentiment analysis are distinct but deeply related.

Opinion mining focuses on polarity detection [positive, negative or neutral] whereas sentiment analysis involves emotion recognition. Because detecting the polarity of text is often a step in sentiment analysis, the two fields are usually combined under the same umbrella[1].

The problem we are trying to solve is best described by considering a few scenarios. Consider the Google Nexus 7 tablet(7-inch, 16GB, Black). It has over 1,754 distinct reviews [2] on Amazon alone. Taking into account just one social media platform (let?s say Reddit), the quantity might grow by a digit or two[3]. In such a scenario, imagine a mobile manufacturer, say HTC. They launch their flagship product, the HTC X(hypothetically), which is an instant hit on the Internet with lots of end users posting positive reaction. But is there a way for the manufacturer to amass and individually examine hundreds of thousands of reviews, spread across the web and then use that data for the benefit of the organization?

Is it possible to analyze the sentiments of the user in what he wrote about the HTC X? How about analyzing not just the positive/negative quotient of the post (which isn't of much use because it done not tell why a statement is positive/negative), but also getting a summarized feedback on what users liked and disliked the about the HTC X?

Consider another scenario of the government of a country.

Say the government wants to connect to hundreds of thousands of people and analyze their views on a proposed policy. If they launch the discussion on a forum, would it be possible for the Government to manually analyze what exactly the users disliked about the policy or law and relevant metrics related to it? And what parts of the policy did the voters like (Example: Tax cuts)?  Or summarize the final, most popular suggestions out of those many reviews?

There has been significant research and progress in this area of sentimental data analysis and opinion mining. Walter Kasper and Mihaela Vela designed a very efficacious system to analyze the sentiments in Hotel reviews, in their paper titled ?Sentiment Analysis for Hotel Reviews?[4]. The system designed by us is able to provide answers to the above practical and generic scenarios, and could prove to be an excellent resource for enterprises, thought-leaders or anyone for that matter in the gathering, sentimental analysis, summarization and visualization of data related to their purposes. The system does not only take into account the holistic sentiment expressed in a review or even a sentence, but further breaks-down each review into sentences, and the sentences again into tokens, to analyze the sentiment corresponding to each relevant token individually, and then        calculates the overall sentiment as well, in a bottom-up fashion. The summary does not simply output the sentences as a whole, but directly the relevant features pointed out along with each corresponding sentiment.



II. RELATED WORK AND CHALLENGES  2.1 Related Work Summarizing sentiment and in particular summarizing  sentiment by extracting and aggregating sentiment over ratable aspects has been a very active area of research recently. The work of Matthew Feczko and Andrew Schaye[5] has demonstrated a multi-step methodology that combines cutting edge techniques in multi-document summarization, polarity classification and sentiment analysis. IT automatically synthesizes, filters, and summarizes user product reviews into a short list of positive and negative opinions as expressed in the reviews.

Xiaohui Yu and Yang Liu present an adaptive sentiment analysis model called S-PLSA+[6], which not only can capture the hidden sentiment factors in the reviews, but has the capability to be incrementally updated as more data become available. In S-PLSA+ model the parameters are estimated by maximizing an approximate posterior distribution such that the need to re-train the model from scratch each time as new reviews become available.

Cai and Spangler[7] focus on the "sentiment topics? associated with the sentiments. They present an end-to-end sentiment analysis framework which combines semantic based sentiment classification approaches with sentiment topic detection approaches in one system.

BalakrishnanGokulakrishnan in his paper[8] discusses an approach where a publicized stream of tweets from the Twitter micro blogging site are preprocessed and classified based on their emotional content as positive, negative and irrelevant; and analyses the performance of various classifying algorithms based on their precision and recall in such cases.

2.2 Challenges in Sentimental Analysis and Opinion Mining The first challenge faced while performing SA on data was  in respect with the veracity of the collected data i.e. the quality of the data. When collecting reviews or opinions posted by end users, it is difficult to verify the authenticity of that data. Some may post positive or negative opinions because of deep rooted brand loyalties. It is also important to make sure that the corpus that is being analyzed contains reviews or opinions form actual end users of the product and have not been posted with ulterior motives. We aim to overcome this problem by using lager data sets which have been gathered from trusted and well know sources on the internet.

Once the quality of the data being used has been satisfactorily established, the next major challenge is the analysis of this non standardized data. People have different ways of expressing opinions; they may or may not use correct grammar. Moreover, there is an ever increasing trend of using shorthand?s and acronyms at various online platforms. This is  major a challenge while trying to process natural language and analyzing sentiments.

Since the data collected is from such a wide variety of sources, it presents other, more fundamental challenges. The text that is gathered may or may not be in English. It is difficult to process any information that is not in English unless there are pre-existing linguist tools for the language. Even when the text gathered is in English, it may have some local influence (words form the local language, references etc). Spotting and successfully analyzing such occurrences is a complex task.

The other major challenges faced pertain to the sheer volume of data that is being gathered and applying the right preprocessing filters on this data for cleaning and pruning. We use a combination of efficient code and well established data transformation techniques to meet these challenges.



III. COMPREHENSIVE SENTIMENTAL DATA ANALYSIS The analysis is broadly classified into the following parts:  3.1 Parsing A natural language parser is a program that works out the  grammatical structure of sentences, and forms relations between different words occurring in the sentence to represent their usage and construction. For example, the subject and verb of the sentence, and further inside the subject, the nouns, verbs and adjectives used.

Most of the parsers available today are probabilistic, i.e., they build up a statistic model from real data, and many of which are trained via the Penn Treebank[9]. For this application, we utilized the Stanford Parser[10], which is also a statistical parser with a high accuracy rate, and written in Java itself. The parser provides Stanford Dependencies[11] output as well as phrase structure trees.

3.1.1 Steps in parsing Break a review into individual sentences 'S'.

Where S = {S1, S2, S3... Sn} for each sentence 'Si' S parse and tag the sentence into its linguistic tags corresponding to each token, as well as generating the dependency relations existing in the parse tree.

Let the set of tags generated for each statement Si S be T = {T1, T2, T3? Tn} Once all the dependencies are explored we need to take into account the relevant dependencies only and ignore others. Let the set of dependencies be represented by ?D? and the relevant dependencies by RD Where   D = {D1, D2, D3? Dn} and Di = {W1, W2} where W1 and W2 are words dependent on each other.

2014 IEEE International Advance Computing Conference (IACC) 607            Figure 1: List of Relevant Dependencies    Figure 2: Dependency Trees generated     Figure 3: List of all Dependencies     Let us take an example and see how it is being parsed.

?I love the phone because of the awesome battery but the screen is bad. Other features such as the speaker are average. Moreover the price when compared to others is low.?  The set of statement S = { I love the phone because of the awesome battery but the screen is bad, Other features such as the speaker are average, Moreover the price when compared to others is low }  The set of tags generated for each Si S is T  Where T = { ?I/PRP, love/VBP, the/DT, phone/NN, because/RB, of/IN, the/DT, awesome/JJ, battery/NN, but/CC, the/DT, screen/NN, is/VBZ, bad/JJ?,?Other/JJ, features/NNS, such/JJ, as/IN, the/DT, speaker/NN, are/VBP, average/JJ?,?Moreover/RB, the/DT, price/NN, when/WRB, compared/VBN, to/TO, others/NNS, is/VBZ, low/JJ? }  Out of all the available and generated dependencies in the Stanford Parser, after careful examination, we narrowed in on to the following types of dependencies that are relevant to our task.

3.2 Scoring Building upon WordNet[12], SentiWordNet[13] is a  lexical resource for sentiment analysis that has more sentiment-related features. It assigns to each synset of WordNet three sentiment scores regarding positivity, negativity, and objectivity, respectively. SentiWordNet has been used as the lexicon in recent sentiment classification studies. The scores we calculated were generated from the SentiWordNet text database, along with a semi-supervised learning procedure.

3.2.1 Scoring Algorithm 1) For a Word Wi describing a noun Ni, the score from SentiWordNet text file is obtained, considering the word as an adjective primarily.

2) i) If Wi matches with one or more entries in the ?Cont? attribute of the Feat_dB corresponding to a particular Ni, it implies that Wi has a negative implication. So, the score obtained in the above step is negated.

ii) If Wi was ?marked? (since it was also part of a Negative dependency), then also it has a negative  608 2014 IEEE International Advance Computing Conference (IACC)       implication as above, and the score obtained in Step-1 is negated.

3) If Wi is not present in the SentiWordNet database file as an adjective, i.e., the score returned is zero, then the score is looked up considering Wi as a verb. Since not all verbs are as influential as any adjective, the score will need to be checked against a certain threshold value (we used a score of 0.4 as a threshold). If Wi is not present in the text file at all, then any two of its synonyms (denoted as S1 and S2) are looked up in the Wordnet database. The scores corresponding to each of them is looked up.

The SentiWordNet text file is further updated as: SentiWordNet  { Wi, Score(Wi) }  Example: We need to calculate: Score (Awesome).

1) Look up ?Awesome? in the SentiWordNet text file as an adjective.

2) It was found. So, the Score (Awesome) = 0.75.

Another example: Let?s assume we found a certain dependency as: phone=[love] We need to calculate: Score (love) 1) Look up ?Love? in the SentiWordNet text file as an adjective.

2) It returned null. So, search for ?Love? as a verb again.

3) It was found. Now, since faint verbs like ?fight?, ?run?, ?walk? etc do not describe a noun as effectively as an adjective, we need to filter these by passing them through a certain threshold, say 0.4.

Since Score (love) =0.45971, the verb is strong enough to be considered influential.

So, Score (love)=0.45971.

3.3 System 1) Retrieve the list of nouns from Feat_db ( the pre- processed database, Figure 4 ). Let the list of nouns be denoted by N = { N1, N2, N3, ? , Nn }.

2) Parse sentence  as per Section 3.1.1(parsing).

3) , check if Di belongs to the set of Relevant dependencies as discussed in section 3.1.1 and proceed if relevant, else ignore it and check others.

i) Obtain Ti for W1 and Tj for W2 Di to verify if any one of Ti or Tj is a noun or not. If a noun is encountered(say W1), check its presence in the set N. If the noun is present (in part or in full), use that noun Ni present in N. This helps in maintaining uniformity of text. For example, W1 = Sound  Quality but N3 = Sound, so N3 will be used instead of W1 for a uniform structure.

ii) Check whether the tag of W2 is an adjective. If true, then further check if W2 is present in a Negative Dependency too. If true, then ?mark? it by a preceding asterisk. For some cases, verbs like ?love?, ?hate? etc may be treated as adjectives, to be accounted for in the scoring rules defined in Section 3.2 iii) Obtain Score(W2) as per the the rules in Section 3.2 iv) Put {Ni, Score(W2)} in to allScore(defined in Section 3.4) v) Repeat the above steps for all sentences Si  S   4) All the scores corresponding to every key in allScore are added, and the aggregate score is obtained corresponding to that key by dividing its sum by the number of scores present. The aggregate scores are stored in aggScore(defined in Section 3.4) Example for above: Consider a sample sentence: The phone is awesome. At such a low price, the phone is amazing.

The Hashmap corresponding to the above sentence would be formed as: {phone=[amazing, awesome], price=[low]}  Since the ?phone? has 2 definitions corresponding to it, the scores of the individual words are computed and averaged to give the final score for ?phone?  So, Score(phone)= [Score(amazing) + Score(awesome)]/2  Finally,{phone=0.5113636363636364, price=0.16957506617575857}    3.4 Data Structures used  A MultiMap(Guava[*] Structure) ?Multimap is a general way to associate keys with arbitrarily many values. In general, the Multimap interface is best thought of in terms of the first view, but allows you to view it in either way with the asMap() view, which returns a Map<K, Collection<V>>. Most importantly, there is no such thing as a key which maps to an empty collection: a key either maps to at least one value, or it is simply not present in the Multimap.?[!]  allScore< String, Double[ ] > allScore is a MultiMap that store all the score corresponding to a particular component(String)  [*] https://code.google.com/p/guava-libraries/ [!] https://code.google.com/p/guava- libraries/wiki/NewCollectionTypesExplained  2014 IEEE International Advance Computing Conference (IACC) 609     aggScore(HashMap<String, Double>)  aggScore is a MultiMap to store the aggre component in the input Statements.

Database ?feat_dB?  A pre-populated database that contains featur  Figure 4: Feat_dB database

IV. VISUAL ANALYTICS For visualizations, we used the Google  Java. The Google Chart API is a tool tha create visual charts in a variety of available charts, Bar Graphs, Google-o-meter[^]a formulated the HTTP request via a Java wra and the API returns a PNG static image chart. Following are some of the visualiz achieved for representative purposes.

Let us take an example and conside example:  ?The phone is good and awesome. The s The battery is awesome. The screen is coo super awesome, However the build quality low price, the camera is awesome. I r awesome fullhd screen.?    Figure 5: Screen Google-o-meter     egated score of a  res/components    S e Chart API[#] in at lets developers e formats like Pie and more. We apper of the API, of the requested  zations that were  er the following  speaker is okay.

ol. The screen is y is bad. For the really liked the   r  Figure 6: Phone  Figure 7: Price  Figure 8: Speake  [#]https://developers.google.com/char [^]https://google- developers.appspot.com/chart/intera       e Google-o-meter         Google-o-meter           r Google-o-meter      rt/  active/docs/gallery/gauge  610 2014 IEEE International Advance Computing Conference (IACC)    Figure 9: Battery Google-o-met      Figure 10: Camera Google-o-mete     Figure 11: Quality Google-o-meter      Figure 12: Percentage of mention      ter   er      ns  Figure 13: Overa  Figure 14: Senti

V. FUTURE WOR The visualizations generated  the immense possibilities of generated data structures, so directly in facilitating the deci some of the following possibili   ?We had incorporated a n  super-fast zoom. How strongly Such a query can be answer  for the camera(Fig. 10).

?Overall, how strongly did h product?? Such a query can be answe meter graph(Fig. 13)  ?Did he talk about the came negatively Or both? How man negative?? Such a query can be answer distribution graph for the came  We plan to tune our alg informal writing habits of user abbreviated words, misspelle instances can be countered available user-contributed data Dictionary, spell-correct, and m   We?d also use web cra database by scraping the late   ll Google-o-meter     ment distribution   RK AND APPLICATIONS d by our system are just some of representing the results in the as to make them applicable ision-making process. Consider ities:  ew kind of a camera having a did he talk about the camera??  red by referring the meter graph  he express his views about my  ered by referring to the Overall  era positively only? Or was it ny times positive and how many  red by referring to the Sentiment ra(Fig. 14)  gorithm to work for modern, rs which leads to incomplete or ed words and so on. Such  by making use of publicly abases or APIs like The Urban more.

awlers to keep refreshing our est reviews and opinions from  2014 IEEE International Advance Computing Conference (IACC) 611       popular portals, and dynamic graphs that would keep updating with newer values when available.

The algorithm would also become more efficient and lead to detailed results if we implement a self-learning system that would learn to include a new entity being talked about by most  users as a new feature of the product/service. For instance, if mobile phones release a new feature like ABC, and the ABC was talked about in say 20 odd reviews, we could include the noun ABC as a feature in our database of preexisting features.



VI. CONCLUSION We developed a web-based sentimental analysis system  that attempts to automatically extract the relevant features of anything to be analyzed, and summarize the sentiments corresponding to each feature, in a set of positive and negative points. It is simply an approach to make use of the vast amount of growing user domination on the Internet in reviewing important business decisions, policies, services etc by analyzing and visualizing the data in a user-friendly manner, to-the-point.

We aim to improve our system as discussed in the prior section, and also preparing many pilot tests to further enhance the summarization results of the system to grow in more detail.



VII. REFERENCES  [1] Erik Cambria, National University of Singapore Bjo?rn  Schuller,Technical University of Munich Yunqing Xia,Tsinghua University Catherine Havasi,Massachusetts Institute of Technology, ?New Avenues in Opinion Mining and Sentiment Analysis? Published in Intelligent Systems, IEEE  (Volume:28 ,  Issue: 2 ) [ISSN :1541-1672] pp 15-21 March/April 2013.

[2] Amazon. Internet:  http://www.amazon.com/Google-Nexus-Tablet-7- Inch-Black/product- reviews/B00DVFLJDS/ref=dp_top_cm_cr_acr_txt?showViewpoints= 1 Nov. 30, 2013 [ Nov. 30, 2013]  [3] Tim Weninger, Xihao Avi Zhu and Jiawei Han, ?An Exploration of Discussion Threads in Social News Sites: A Case Study of the Reddit Community? in the proceedings of the 2013 IEEE/ACM International Conference on Social Networks Analysis and Mining (ASONAM 2013), August 2013, Niagra Falls, Canada.

[4] Walter Kasper, Mihaela Vela, DFKI GmbHStuhlsatzenhausweg, ?Sentiment Analysis for Hotel Reviews? , published in Proceedings of the Computational Linguistics-Applications Conference, Jachranka, Poland, Polskie Towarzystwo Informatyczne, Katowice,  [5] Mathew Feczko, Andrew Schaye, M. Marcus , A. Nenkova, ?SentiSummary: Sentiment Summarization for User Product Reviews?in proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Vol 01 pp 265-271.

[6] Xiaohui Yu, Yang Liu, and Aijun An,?An Adaptive Model for Probabilistic Sentiment Analysis", in proceedings of IEEE/WIC/ACM Technology(WI-IAT), page 661-667. IEEE, (2010)  [7] Keke Cai, Scott Spangler, Ying Chen and Li Zhang, ?Leveraging Sentiment Analysis for Topic Detection?,in proceedings of the 2008 Intelligent Agent Technology - Vol 01 pp 265-271)  [8] Gokulakrishnan,B. Dept. of Comput. Sci. & Eng., Univ. of Moratuwa, Moratuwa, Sri LankaPriyanthan, P. ; Ragavan, T. ; Prasath, N.  ,?Opinion mining and sentiment analysis on a Twitter data stream? published in Advances in ICT for Emerging Regions (ICTer), 2012  [9] LINC Laboratory of the Computer and Information Science Department at the University of Pennsylvania. ?Parser?. Internet: http://www.cis.upenn.edu/~treebank/  [Oct. 30, 2013]  [10] Richard Socher, John Bauer, Christopher D. Manning and Andrew Y.

Ng. 2013. Parsing With Compositional Vector Grammars,  in the Proceedings of ACL 2013  [11] Marie-Catherine de Marneffe, Bill MacCartney and Christopher D.

Manning "Generating Typed Dependency Parses from Phrase Structure Parses". In LREC 2006.

[12] George A. Miller (1995). "WordNet: A Lexical Database for English." in Communications of the ACM Vol. 38, No. 11: 39-41.

