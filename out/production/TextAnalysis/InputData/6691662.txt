RELIABILITY OF ERASURE CODED STORAGE SYSTEMS: A GEOMETRIC APPROACH

Abstract?We consider the probability of data loss in an erasure coded distributed storage system. Data loss in an erasure coded system depends on the repair duration and the failure probability of individual disks. This dependence on the repair duration complicates the data loss probability analysis. In pre- vious work, the data loss probability of such systems has been studied under the assumption of exponentially distributed disk life and disk repair durations, using well-known analytic methods from the theory of Markov processes. Here, we assume that the repair duration is a constant and derive an upper bound on the probability of data loss by calculating the volumes of specific polytopes that are determined by the code. Closed form bounds are exhibited for some example codes.



I. INTRODUCTION  Erasure coded distributed storage systems are growing in popularity, driven in part by the availability of broadband networks, and the reduced cost of storage devices. In an erasure coded storage system, a block of k information symbols from some finite set is encoded into a block of n coded symbols by an (n, k) erasure code and the n code symbols are placed on separate disks. When a disk fails, it is repaired, i.e. redundant information in the code is used to recompute the erased symbol which is then placed on a replacement disk. Repair is essential for the reliability of the overall system. Data loss occurs or the system fails when the total number of failed disks at any time exceeds the erasure correcting capability of the code. If disks are repaired swiftly, the number of failed disks can be kept small on average, reducing the probability of data loss.

Equivalently, a data loss event requires that many simultaneous failures occur within a repair window, i.e. the time it takes to repair a single disk. The probability of this happening can be reduced by minimizing the repair duration.

A relatively recent and surprising result [4] in the area of erasure codes has been the derivation of an achievable lower bound on the amount of information that must be communi- cated in order to repair a failed node. It was shown in [4] that there exists an optimal tradeoff between the storage overhead and the repair bandwidth. The endpoints of this tradeoff are called the minimum storage (MSR) and minimum bandwidth regenerating (MBR) points. An immediate consequence of this result is that a single symbol in an (n, k) MDS erasure codeword can be reconstructed by communicating as little as a total of (n? 1)/(n? k) symbols from (n? 1) helper disks, the disks participating in the repair process. In other words,  the repair bandwidth, defined as the amount of information that must be read from each helper disk, can be as small as 1/(n?k) of each symbol of a codeword1. There has been much work in the area of repair efficient code design. Among many, we mention [6], the first explicit construction that achieves the MBR and MSR points for a certain set of parameters; [5] for optimal constructions based on Hadamard designs; [10], [8] for constructions that achieve points on the above tradeoff which outperform time sharing of the MBR and MSR points.

In previous works, it is assumed that the repair and failure durations are exponentially distributed random variables. The mean time between failures (MTBF) is then determined by analyzing a state transition diagram, where the system state is defined as the number of ?good? disks at a given time, see e.g. [7], [2], [3]. The reliability function R(t), the prob- ability that data is not lost until time t, is then estimated by exp(?t/MTBF). A recent contribution [1] uses a similar framework to study opportunistic repair.

In this work, we assume that the repair duration is fixed.

We then derive an upper bound on the probability of data loss, or equivalently, a lower bound on R(t). We find that the calculations can be reduced to that of calculating the volume of specific polytopes inside a cube in Rn.

As mentioned above, previous works assume an exponen- tially distributed repair time. If the repair time is chosen as the maximum time required to repair a disk (by assuming a full disk), then we are in effect studying worst-case repair sce- narios. The Markovian approach, though analytically tractable and elegant, hides much of the geometric character of the problem. Geometry has always played an important role in the analysis of communication systems and its role in the kind of failure analysis should provide complimentary insights into the failure mechanism. As we will see, our approach leads to interesting geometric observations about some polytopes that are fundamental to this problem.

The paper is organized as follows. A general lower bound on the reliability function is derived in Sec. II in terms of the volume of a suitably defined error region. Geometric characterization of the error region is carried out for specific example codes in Sec. III, where error graphs and an index- ing notation are introduced. This approach is generalized in  1Code symbols are assumed to be fragmentable into smaller ?atoms?     Sec. IV, simulation based validation results are provided in Sec. V, observations and conclusions are presented in Sec. VI.



II. UPPER BOUND ON THE PROBABILITY OF DATA LOSS  Code symbols from an MDS (n, k) erasure code are written to n disks. We assume that the probability of failure of an individual disk is known and is a constant across disks and across time, that the system has been started at time 0 with all n disks functioning, that disk failures occur independently, the disk failure process is modeled by a homogeneous Poisson process with rate parameter ? and the repair of a disk requires trep secs. Let Dt denote the event that data is not available after time t, i.e. a data loss event has occurred in the time interval (0, t). Our goal is to estimate P (Dt) or equivalently, the system reliability function R(t) = P (Dct ).

The i-th entry of the random vector MMM = (M1,M2, . . . ,Mn) represents the number of failures of disk2 i up to time t. By assumption, Mi follows a Poisson distribution with parameter ?. The failure instants of the i-th disk, provided that MMM =mmm = (m1,m2, . . . ,mn), are denoted by SSSi = (Si1, . . . , Simi)  3. Due to the assumption that the disk failures are modeled as a homogeneous Poisson process, the random variables Sij are independent and identically distributed uniformly over (0, t). Since an (n, k) MDS code is used, the data loss event Dt is equivalent to the event that more than (n ? k) disks fail in some interval of length trep secs. within (0, t).

A. A Bound on the Probability of Data Loss  Suppose that the failures happen at instants SSSi = sssi, i = 1, . . . , n. To know whether Dt occurs, we need to analyze all possible n-dimensional vectors (s1i1 , s2i2 , . . . , snin), with ij = 1, . . . ,mj , checking if any of these vectors represents a set of disk failure instants that causes data loss. Let R denote the set of all points within (0, t)n associated with a data loss event. More precisely,  R := {xxx ? (0, t)n : for some r > n? k ? xi1 ? xi2 ? . . . ? xir , xir ? xi1 ? trep} .

(1)  For n = 2 and k = 1, the error region R is illustrated in Fig. 1. The following proposition holds:  Proposition 1. The probability that there is no data loss in the interval (0, t), provided that MMM =mmm, mi > 0, i = 1, 2, . . . , n satisfies  Pmmm(Dct ) ?Pmmm((S11, S21, . . . , Sn1) ? Rc)m1m2...mn = =  ( 1? vol R  tn  )m1m2...mn .

(2)  Proof: First note that the equality in (2) follows from the fact that Sij are uniform random variables iid over (0, t). For the proof of the first inequality, note that Dct occurs if all n- dimensional random vectors (S1i1 , S2i2 , . . . , Snin) lie in Rc, the complement of R.

2To be precise Mi is the number of times node i fails, but we use the looser term disk instead of node.

3For simplicity, we consider the unordered failure times, i.e., not necessarily Si1 < Si2 < Si3, . . .. Given the failure times up to time t, we write the vectors in an arbitrary order.

If we define the events  Uj := { (S11, . . . , Sj,1, Sj+1,ij+1 , . . . , Sn,in) ? Rc, ?ij+1, . . . , in  } ,  for j = 0, 1, 2, . . . , n, and if we define m0 = 1 then Pmmm(Dct ) = P (Um00 ). The inequality in (2) will be proved by if we can show that  Pmmm(Dct ) ? P (Un)m0m1...mn .

We will do so by showing that Pmmm(Dct ) ? P (Uj)m1...mj for j = 0, 1, . . . , n, by induction on j.

As shown above, the base hypothesis j = 0 is true. Now suppose that Pmmm(Dct ) ? P (Uj)m0...mj . Then  Pmmm(Dct ) ? P (Uj)m0...mj = E[P (Uj |SSSj+2,SSSj+3, . . . ,SSSn)]m0...mj (a) = E[P (Uj+1|SSSj+2, . . . ,SSSn)mj+1 ]m0...mj (b)  ? E[P (Uj+1|SSSj+2, . . . ,SSSn]m0m1...mj+1 = Pmmm(Uj+1)m0m1...mj+1 ,  where (a) is due to independence and (b) is due to Jensen?s inequality.

With Prop. 1, we now proceed to bound the reliability. Let w(mmm) denote the weight, i.e. the number of nonzero terms, in mmm. Then  R(t) = P (Dct ) = n?  j=0  ? mmm:w(mmm)=j  Pmmm(Dct )P (MMM =mmm)  = n?k? j=0  ? mmm:w(mmm)=j  Pmmm(Dct )P (MMM =mmm) +  n? j=n?k+1  ? mmm:w(mmm)=j  Pmmm(Dct )P (MMM =mmm)  = n?k? j=0  ( n  j  ) (1? e??t)je??t(n?j) +  n? j=n?k+1  ? mmm:w(mmm)=j  Pmmm(Dct )P (MMM =mmm). (3)  The terms Pmmm(Dct ) with w(mmm) = n in the above equation can be lower bounded using (2). For cases where w(mmm) < n, a lower dimensional version of Prop. 1 applies. Let Rj denote the error region of a (j, j ? (n? k)) MDS code (j > n? k).

We have:  n? j=n?k+1  ? mmm:w(mmm)=j  Pmmm(Dct )P (MMM =mmm) ?  = n?  j=n?k+1  ( n  j  ) (1? e??t)n  ( vol Rcj  tj  )?jtj/(1?e??t)j .

Thus we can bound the probability of data loss in terms of the volume of the error regions R. In the next section, we study such regions for different values of n, k, t and trep.



III. ERROR REGIONS  A. Example: (n, k) = (2, 1)  As a very special example, we consider a system with only two disks (n, k) = (2, 1). The system fails until time t if, at some point, both disks fail within a time window of length trep.

The system remains working (Dct event) if, for any interval of length trep contained in (0, t), only one of the disks fail in such a interval (possibly more than one time). Alternatively, a Dct event occurs if, for all i and j, we have  |S1i ? S2j | > trep.

This shows that the error region for two disks is given by R = {(x, y) ? (0, t)2 : |x? y| ? trep}, illustrated below. In this case, by averaging (2) over all M1,M2 and applying Jensen?s inequality, we have:  P (Dct ) ? ( 1? trep  t  )2?2t2 .

0 t  t  tr  tr  R2  R1  Rc = R1 ?R2  Figure 1: Reliability region Rc  B. Example: n = k + 1  For this case, any two disk failure within an interval of length trep will cause data loss. The error region is therefore  R = {(x1, . . . , xn) ? (0, t)n : ?i ?= j s.t. |xi ? xj | ? trep} .

(4)  It is sometimes more convenient to work with Rc, given in this example by  Rc = {(x1, . . . , xn) ? (0, t)n : |xi ? xj | > trep for all i, j} .

(5)  Below is an illustration of region Rc in three dimensions (n = 3, k = 2). If we consider 0 ? x1 ? . . . ? xn,? t, the region Rc is a polytope determined by the linear equations????  ??? 0 ? x1 ? . . . ? xn ? t  xn ? xn?1 > trep ...

x2 ? x1 > trep.

(6)  Assuming that t > (n ? 1)trep, the region above is the simplex Vn in Rn given by the convex hull of the points p1, . . . , pn+1 described on top of the next page. The volume of such simplex is given by [9]:  vol Vn = (t? (n? 1)trep) n  n!

Figure 2: Illustration of Rc for the (3, 2) code, t = 1 and trep = 0.1. On the right, we show only one simplex, corresponding to one of the orderings of (x1, x2, x3).

Since there are n! possible orderings of (x1, . . . , xn), the total volume of Rc is  vol Rc = (t? (n? 1)trep)n. (7) Remark 1. For the above analysis to be valid, we require that t ? (n? 1)trep.

C. Example: (4, 2)-Code  The system fails if there is an interval of length trep that contains failure instants from at least 3 different disks. The error region R is most conveniently represented using 4-vertex graphs. Let (x1, x2, x3, x4) ? R4. We construct the undirected graph G = (V,E), V = {v1, v2, v3, v4} such that there is an edge (vi, vj) if and only if |xj ? xi| ? trep. By analyzing the edges of G, we can deduce if (x1, x2, x3, x4) is associated with a system failure. We illustrate in Fig. 3 some possible ?error? and ?no error? graphs. If the vector (x1, x2, x3, x4) is ordered,  v1  v2  v3  v4  (a) |x1 ? x2| ? trep and |xi ? xj | > trep  for all i ?= j, (i, j) ?= (1, 2), (2, 1)  v1  v2  v3  v4  (b) |x2 ? x3| > trep, |x1 ? x3| > trep,|x2 ? x4| > trep, |x1 ? x4| ? trep,|x1 ? x2| ? trep, |x3 ? x4| ? trep  Figure 3: Example of (a) ?no error? and (b) ?error? graphs.

the only possible no error graphs are listed in Fig. 4. Thus there are 4!5 = 120 possible graphs associated with a Dct (or ?no error? event). If we consider all the points in (0, t)4 associated with some of the graphs in Fig. 4, we have a region in R4.

The disjoint union of these regions, including the isomorphic graphs related to the different orderings of (x1, x2, x3, x4), gives us the region Rc.

We denote by vol G the volume of the region consti- tuted by all points in (0, t)4 that are associated to graph G. For example, from the previous subsection, we have vol G000 = (t? 3trep)4/4!. The following proposition gives the volume of Rc for the (4, 2)-code.

p1 = (t? (n? 1)trep, t? (n? 2)trep, t? (n? 3)trep, t? (n? 4)trep, . . . t) p2 = (0, t? (n? 2)trep, t? (n? 3)trep, t? (n? 4)trep, . . . t) p3 = (0 trep, t? (n? 3)trep t? (n? 4)trep, . . . t) p4 = (0 trep, 2trep, t? (n? 4)trep, . . . t)  ...

pn = (0, trep, 2trep, 3trep, . . . t) pn+1 = (0, trep, 2trep, 3trep, . . . (n? 1)trep)  The simplex Vn is given by the convex hull of {p1, . . . , pn+1}  v1  v2  v3  v4  (a) G000  v1  v2  v3  v4  (b) G100  v1  v2  v3  v4  (c) G010 v1  v2  v3  v4  (d) G001  v1  v2  v3  v4  (e) G101  Figure 4: ?No error? graphs of the (4, 2)-code.

Theorem 1. If t ? 3trep, the volume of Rc for the (4, 2)-code is given by:  vol Rc = t4 ? 24t2t2rep + 72t3rept? 64t4rep. (8)  Proof: Let G denote the set of all ?no error? graphs.

Since the regions associated to the elements in G are pairwise disjoint, we have  vol Rc = ? G?G  vol G = 4!(vol G000 + 3 vol G100 + vol G101).

The volume of G000 was already calculated above. The volume of G100 can be calculated as  vol G100 = vol R1 ? vol R2,where  R1 = { (x1, x2, x3, x4) ? (0, t)4 :  x1 ? x2 ? x3 ? x4 x3 ? x2 ? trep x4 ? x3 ? trep  } ,  R2 =  ??? ??(x1, x2, x3, x4) ? (0, t)4 :  x1 ? x2 ? x3 ? x4 x2 ? x1 ? trep x3 ? x2 ? trep x4 ? x3 ? trep  ??? ?? .

Similar to the volume evaluation of the simplex Vn, we have  vol R1 = (t? 2trep)  4!

and vol R2 = vol V4 = (t? 3trep)   4!

.

(9) Analogously,  vol G101 = vol R3 ? 2vol R1 + vol R2,where  R3 = { (x1, x2, x3, x4) ? (0, t)4 : x1 ? x2 ? x3 ? x4x3 ? x2 ? trep  } ,  vol R3 = (t? trep)  4!

.

Putting everything together, we have the desired formula.



IV. GENERAL FORMULAS  Inspired by the example of the (4, 2) we develop a general technique to calculating the volume of the error regions by means of the ?error? and ?no error? graphs. For an (n, k) code, we define the graphs Gb1,...,bl , where bl is a binary string of length l, as the graph with set of vertices v1, . . . , vl+1 such that there is an edge between vi and vi+1 iff bi = 1, and there are no other edges. Each of these graphs is said to be associated with the region  Rb1,...,bl = { (x1, . . . , xn) ? Rn :  0 ? x1 ? . . . ? xn xi+1 ? xi ? trep if bi = 1 xi+1 ? xi > trep if bi = 0  } .

From now on, we denote by G0i1j the graph Gb1,...bl with b1 = b2 = . . . bi = 0 and bi+1 = . . . bi+j = 1. The regions associated with the all-zeros graph G0i can be characterized in a manner similar to III-B (Lemma 1) and then we can use such characterization to calculate the volume of any graph of the form G0i1j (Lemma 2).

Lemma 1. Let 1 ? i ? n ? 1. The volume of the graph G0i is given by:  vol G0i = (t? itrep)n  n!

.

Lemma 2. Let Gb1,...,bt be the graphs defined above, for a system with n disks. Then:  vol G0i1j?i = j?  l=0  ( j  l  ) (?1)j+lvol G0i+j?l .

Proof: Consider the representation for the set of graphs G0i1j?i illustrated in Fig. 5. One can easily verify that the volume of a ?parent node? is the sum of the volume of its two sons. We have thus following recursion:  vol G0i1j?i = vol G0i1j?i?1 ? vol G0i+11j?i?1 .

Iterating the above recursion to eliminate all but the nodes  along the left edge of the graph representation leads to the desired result.

G?  G0 G1  G00 G01 G11  ...

...

...

...

...

Figure 5: Representation of the set of graphs G0i1j?i  Analogously to the (4, 2)-code case, we say that Gb1,...,bn?1 is an ?error? graph for the (n, k) code, if the regionRb1,...,bn?1 is a subset of the error region R. Any graph Gb1,...,bn?1 that is not an ?error? graph is defined as a ?no error? graph.

Combining lemmas 1 and 2, we have a formula that allows us to compute the volume of Rc of any (n, k) code.

Theorem 2. Let t ? (n ? 1)trep. The volume of Rc for an MDS code with parameters (n, k) is given by:  vol Rc = n?1? j=0  j? l=0  ?j  ( j  l  ) (?1)j+l(t? (n? l?1)trep)n. (10)  where ?j is the number of ?no error? graphs with j edges and n vertices.

We explicitly calculated the volume of Rc for some exam- ple codes. The results are shown in Table I. Thm. 2, combined with Prop. 1, immediately gives a bound on the probability of data loss of an (n, k)-code.

Code Volume of the error region Rc (4, 2) ?24t2t2rep + 72tt3rep ? 64t4rep + t4 (5, 2) ?120t2t3rep + 480tt4rep ? 540t5rep + t5 (5, 3) ?60t3t2rep + 300t2t3rep ? 570tt4rep + 390t5rep + t5 (6, 2) ?720t2t4rep + 3600tt5rep ? 4920t6rep + t6 (6, 3) ?360t3t3rep + 2340t2t4rep ? 5580tt5rep + 4740t6rep + t6 (6, 4) ?120t4t2rep + 840t3t3rep ? 2100t2t4rep + 1260tt5rep + 1492t6rep + t6  Table I: Explicit calculations of vol Rc

V. SIMULATION RESULTS  In order to assess the tightness of the bound given by Prop.

1, we simulated a system with 4 disks, encoded with the (4, 2)- code. In this case, we know exactly the value of vol R, and thus we can compare the simulation results with bound (2), for various values of (m1,m2,m3,m4). Due to the Poisson process assumption, the failure instants were drawn uniformly at random on (0, t). The experiments were run for 107 samples, t = 1, trep = 0.02 and trep = 0.01. Simulation results are exhibited in Tables II and III, in comparison with the upper bound for data loss derived from Prop. 1 and Thm. 1.



VI. CONCLUSIONS AND FUTURE WORK  The probability of data loss in an erasure coded storage system depends on the failure rates and repair durations of in- dividual disks. In previous work, error probability expressions are derived under the assumption that the repair duration is an exponentially distributed random variable. Here we derive  (m1,m2,m3,m4) Simulation Upper Bound (1, 1, 1, 1) 4.5898? 10?5 9.5425? 10?5 (2, 1, 1, 1) 6.4000? 10?5 1.9084? 10?4 (2, 2, 1, 1) 8.2000? 10?5 3.8164? 10?4 (2, 2, 2, 1) 1.1200? 10?4 7.6314? 10?4 (3, 2, 1, 1) 9.1000? 10?5 5.7241? 10?4 (2, 2, 2, 2) 1.7900? 10?4 1.5257? 10?3  Table II: Simulation Results for trep = 0.02  (m1,m2,m3,m4) Simulation Upper Bound (1, 1, 1, 1) 1.1800? 10?5 2.3928? 10?5 (2, 1, 1, 1) 1.6889? 10?5 4.7856? 10?5 (2, 2, 1, 1) 2.4410? 10?5 9.5709? 10?5 (2, 2, 2, 1) 3.3529? 10?5 1.9141? 10?4 (3, 2, 1, 1) 2.7119? 10?5 1.4356? 10?4 (2, 2, 2, 2) 4.1540? 10?5 3.8279? 10?4  Table III: Simulation Results for trep = 0.01  an upper bound on the probability of data loss under the assumption that the repair duration is constant. The relative tightness of the bounds derived here, along with comparisons to existing calculations based on [2], [3] remains an open issue for future work.



VII. ACKNOWLEDGEMENTS  Helpful discussions with Chao Tian, Vaneet Aggarwal and Robin Chen of AT&T Labs-Research are acknowledged.

Antonio Campello?s work, travel and stay at AT&T Labs- Research, Florham Park, NJ (where this work was carried out) was supported by FAPESP grant 2012/09167-2.

