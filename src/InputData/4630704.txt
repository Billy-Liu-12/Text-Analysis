

Abstract?Effective data distribution techniques can signifi- cantly reduce the total execution time of a program on grid computing environments, especially for data mining applica- tions. In this paper, we describe a linear programming formu- lation for the data distribution problem on grids. Furthermore, a heuristic method, named HDDS (Heuristic Data Distribution Scheme), is proposed to solve this problem. We implement the parallel association rule mining method and conduct the ex- perimentations on our grid testbed. Experimental results showed that data mining programs using our HDDS to distrib- ute data could execute more efficiently than traditional schemes could.



I. INTRODUCTION  s inexpensive personal computers and Internet access become available, much attention has been directed to grid computing [2, 3, 4, 8, 9, 15, 16, 26, 29]. The basic  goal of grid computing is to share the computing and storage resources all over the world via Wide Area Networks. In this way, computation jobs can be distributed to idle computers far away, probably in other countries. Moreover, remote data can be accessed for large-scale analysis.

Data mining is an emerging technology which is applied to many fields including bioinformatics, e-business, etc. Basi- cally, data mining is a data-intensive application, and it is time-consuming to execute data mining programs. In the past decade, a lot of efforts have been devoted to design efficient data mining algorithms. Furthermore, the parallelization of these algorithms has also been investigated. However, the previous work is focused on traditional parallel architectures, such as multiprocessors, homogeneous clusters, heteroge- neous clusters, etc. Little work is conducted on grid com- puting environments.

Traditional parallel data mining work assumes data is partitioned and transmitted to the computing nodes in ad- vance. However, it is also usually the case in which a large database is generated and stored in some station [12].

This paper is supported in part by National Science Council, Taiwan, under grants no. NSC 96-2221-E-029-019-MY3 and NSC 96-2218-E-007-007.

Chao-Tung Yang, is with High-Performance Computing Laboratory, Department of Computer Science and Information Engineering, Tunghai University, Taichung 40704, Taiwan, R.O.C. (corresponding author to provide phone: 886-4-23590415; fax: 886-4-23591567; e-mail: ctyang@thu.edu.tw).

Wen-Chung Shih, is with Department of Computer and Information Sci- ence, National Chiao Tung University, Hsinchu, 30010, Taiwan, R.O.C.

(e-mail: gis90805@cis.nctu.edu.tw).

Shian-Shyong Tseng, is with Department of Computer and Information Science, National Chiao Tung University, Hsinchu, 30010, Taiwan, R.O.C.

(e-mail: sstseng@cis.nctu.edu.tw).

Therefore, it is important to efficiently partition and distrib- uted the data to other nodes for parallel computation.

In this paper, we focus on the problem of data distribution for data mining applications on grids. It is formulated as a linear programming problem, and a heuristic algorithm is proposed to solve it. Our scheme is applied to one kind of data mining application, association rule mining. We implement the application with MPI directives, and execute them on our grid testbed, across three schools. Experimental results show that effective data partition can significantly reduce the total response time.

Divisible Load Theory (DLT) [1, 18, 19, 28] addresses the case where the total workload can be partitioned into any number of independent subjobs. This problem has been dis- cussed in the past decade, and a good review can be found in [17]. However, these previous models did not consider the memory storage constraint, which is critical for storing in- termediate data structures in data mining processes. In [20], a data distribution method was proposed for host-client type of applications. Nevertheless, it was not formulated as a linear programming problem. In addition, their method was an analytic technique, and only verified on homogeneous and heterogeneous cluster computing platforms, not for grid en- vironments.

Our major contributions can be summarized as follows.

First, we extend the linear programming formulation of this problem by considering memory constraints to be suitable for data mining applications. Second, this paper proposes a new heuristic algorithm to solve this problem. Finally, we im- plement the algorithm and apply it to data mining applications on our grid testbed. Consequently, experimental results show the obvious effectiveness of our approach. To the best of our knowledge, this is the first paper to formally formulate the data partition problem for data mining applications on grids.

The rest of this paper is organized as follows. Section 2 reviews the related background. In Section 3, we describe the system model and formulate the data partition problem. Next, our heuristic scheme is proposed in Section 4. Then, Section 5 shows the experimental results on our grid testbed. Finally, we conclude this paper in Section 6.



II. RELATED WORK  In this section, we review related background for our re- search. First, related work about data mining is reported.

Then, we introduce the concepts and techniques of grid computing.

A Heuristic Data Distribution Scheme for Data Mining Applications on Grid Environments  Chao-Tung Yang, Wen-Chung Shih, and Shian-Shyong Tseng  A      A. Data Mining  Due to the advances of information technologies, a tre- mendous amount of data have been generating by various kinds of applications. This is called the data explosion prob- lem. Moreover, we need to extract knowledge or patterns from these data. Therefore, automatic tools for data proc- essing and analysis are demanding.

Data mining, or known as knowledge discovery, is to ac- quire interesting knowledge from large-scale databases [27].

A typical architecture of a data mining system is illustrated in Figure 1. In this architecture, the Data Mining Engine utilizes various kinds of techniques to mine patterns from databases.

These techniques include association rule mining, classifica- tion, cluster analysis, etc.

Fig. 1. Architecture of a typical data mining system  The objective of association rule mining is to discover correlation relationships among a set of items. The well-known application of association rule mining is market basket analysis. This technique can extract customer buying behaviors by discover what items they buy together. The managers of shops can place the associated items at the neighboring shelf to raise their probability of purchasing. For example, milk and bread are frequently bought together.

The formulation of association rule mining problem is described as follows [14]. Let I = {I1, I2, I3, ?, Im} be a set of items, and D a database of transactions. Each transaction in D is a subset of I. An association rule is a rule of the form BA , where IA , IB  and {}BA . The  well-known algorithm for finding association rules in large transaction databases is Apriori. It utilizes the Apriori prop- erty to reduce the search space.

Classification is a kind of data analysis technique which can extract models from categorical data. For example, we can build a classification model to classify animals according a small training database. Classification can be described as a two-phased process [27]. In the training phase, a model is constructed by analyzing a predetermined set of small dataset.

Then, this model is utilized to conduct classification in the testing phase. The common methods of classification include decision tree induction, k-nearest neighbor classifiers, case-based reasoning, genetic algorithms, etc.

Cluster analysis is a process of grouping objects into groups or clusters, in order that the objects in the same cluster have high similarity, while the objects belonging to different groups have small similarity. There are many methods of clustering, including partitioning methods, hierarchical  methods, density-based methods, grid-based methods, model-based methods, etc.

As the rising of parallel processing, parallel data mining have been well investigated in the past decade. Especially, much attention has been directed to parallel association rule mining. A good survey can be found in [30].

B. Grid Computing  The concept of grid computing is first stated by Foster and Kesselman, and it has emerged as a promising technology [21, 22, 23, 24, 25]. However, it is a new field, and its standards and architectures are still investigated. Conceptually, grid environments are a type of distributed systems. However, it includes many unique characteristics. First, resources within the grid are shared without centralized controlling and coor- dination. Users access these resources via distributed proto- cols and mechanisms. Second, the protocols, standards and middleware are open. In other words, it is not a proprietary system. Finally, the performance of the grid is a critical issue.

Because the resource can be located all over the world in- terconnected by the Internet, it is necessary for the grid in- frastructure to provide good enough quality of service.

The architecture of the grid involves many standards. The well-known one is the Open Grid Services Architecture (OGSA). OGSA is a common specification, and its objective is to standardize the services used by users and applications of a grid. This standard primarily involves:  Program-to-program interface and messaging (SOAP) Data sharing (XML) Workload management (WS-Management) Other related specifications  Globus Toolkit. In the OGSA standard, specification for implementing is provided by OGSI. A common implemen- tation of OGSI is Globus Toolkit [10]. The software tools are provided by the Globus Project, and are used to build com- putational Grids and Grid-based applications. The toolkit includes software for security, information infrastructure, resource management, data management, communication, fault detection, and portability.

The Globus Toolkit consists of three components: Re- source Management, Information Services, and Data Man- agement. First, a resource management protocol is imple- mented by the Globus Resource Allocation Manager (GRAM). Second, the Metacomputing Directory Service (MDS) implements an information services protocol. Finally, a data transfer protocol is implemented by GridFTP. These protocols utilize the GSI security protocol to interconnection.

MPICH-G2. MPI is a message-passing interface library.

This standard is based on the discussion in the MPI Forums [5]. Participants include vendors, researchers, academics, software library developers and users. MPI offers portability, standardization, performance and functionality [6].

MPICH-G2 [5, 6] is an implementation of the MPI v1.1 standard, but it is Grid-enabled. It uses services of the Globus Toolkit? to interconnect multiple machines, which may     include different kinds of architectures. Existing parallelized programs written with MPI directives can be recompiled and executed on the Globus infrastructure [6].

Network Weather Service. The NWS (Network Weather Service) [7] is a distributed system that periodically monitors and dynamically forecasts the performance of various net- working and computational resources over a given time in- terval. This service utilizes a distributed set of performance sensors (network monitors, CPU monitors, etc.) from which it can gather system status information. It then uses numerical models to generate forecasts of what the conditions will be for a given time period. It also uses mathematical models to forecast each condition and the Mean Absolute Error (MAE) and Mean Square Error (MSE) rates. NWS is a widely used measurement tool for grid environments.

The HPC laboratory of Tunghai University has developed a GUI [11] which can display bandwidth statistics of their grid environments. This tool utilizes API provided by NWS, and depicts real-time bandwidth statistics in web-based graphic user interface, as shown in Figure 2. In this paper, these bandwidth statistics will be used to estimate the per- formance of each grid node.

Fig. 2. Bandwidth statistics extracted from NWS information

III. PROBLEM FORMULATION  In this section, the master/slave model for grid computing is described. Then, we present the linear programming for- mulation of the data distribution problem.

A. The System and Cost Model  Our system model and cost model are extended from the framework in [17]. The master/slave model for a grid is rep- resented by a star graph G = {P0, P1,?, Pn}, as shown in Figure 3. In this graph, P0 is the master node and the other n nodes, P1, ?, Pn, are slave nodes. In addition, there is a vir- tual communication link Li connecting the master node and the slave node Pi.

In our cost model, each node Pi is associated with a com- puting capacity Ci, a memory capacity Mi, and a disk storage capacity Di. Furthermore, each link Li is also associated with a transmission capacity Ti. In our linear cost model, it takes W  Ci time units for the slave node Pi to conduct computation on W units of data. Besides, it takes W Ti time units for link Li to transmit W units of data. In this model, we assume that the master can only communicate with one slave node at the same time.

P1  P0  P2  Pn  L1  L2 Ln  Fig. 3. The system model  B. Linear Programming Formulation  The goal is to minimize the total response time of a given workload W on the system. The Data Distribution Problem (DDP) can be formulated as a linear program as follows.

Minimize Tfinish, Subject to  0iW ni1 (1)  WW n  i i1 (2)  0DsW (3)  ii DsW ni1 (4)  ii MWDS )( ni1 (5)  finishTCWTW 1111 (6)  finishj  i  j j TCWTW 111 ni2 (7)  where Tfinish is the response time for the master node to finish executing the data mining application program. For simplicity, we assume Tfinish is a linear function.

Wi is the work load dispatched to the slave Pi.

s is the size of one unit data.

DS is a linear function which returns the size of the in- termediate data structure during data mining process.

This intermediate data structure is generated during the process of local computation. For example, in associa- tion rule mining, the intermediate data structure could be a hash tree for frequent itemsets. For simplicity, we assume DS is a linear function.

C. An Example  We describe an example to clarify the model and the problem formulation. The master/slave model for the exam- ple grid consists of four nodes, P0, P1, P2 and P3, as shown in     Figure 4. In this graph, P0 is the master node and the other three nodes are slave nodes. In addition, L1, L2 and L3 connect the master node to P1, P2 and P3, respectively. The total workload of this example database contains 256 transactions.

The related attributes are listed in Table I.

The objective is to minimize the total response time of a given workload of 256 transactions on the system. The data mining application is association rule mining. We try to par- tition the database into three subsets, and transmit them to the three slave nodes, respectively. However, inappropriate par- tition size or transmission order could affect the total execu- tion time. Therefore, a good distribution scheme is essential.

Fig. 4. An example grid  Table I. Parameters in the example grid  Node Attribute  P0 (Master)  P1 P2 P3  Ci 1.5GHz 2.0GHz 1.0 GHz 1.5 GHz Mi 1GB 512MB 512MB 256MB Di 80GB 80GB 40GB 40GB Li 1Mbps 256Kbps 512Kbps

IV. HDDS (HEURISTIC DATA DISTRIBUTION SCHEME)  The proposed heuristic algorithm is based on the per- formance of each slave node and each link to distribute the corresponding workload. In this section, the concept of per- formance ratio is explained first. Then, we present the heu- ristics which the algorithm is based on. Finally, the algorithm is formally described and illustrated by an example.

A. Performance Ratio  We propose to partition the workload according to the performance ratio of all slave nodes. Therefore, the effec- tiveness of this approach depends on the accuracy of esti- mating the performance ratio. To estimate the performance of each slave node, we define a Performance Function (PF) for a slave node j as  PFj (V1, V2, ?, VM) (8)  where Vi , Mi1 , is a parameter of the performance function. In more detail, the parameters could include CPU  speed, networking bandwidth, memory capacity, etc. In this paper, our PF for node j is defined as  PFj =  Snode i  j  Snode i  j  ii  B  B w  t  t w 21 1  1 (9)  where S is the set of all slave nodes.

ti is the execution time (sec.) of node i for some data mining application program, such as association rule mining.

Bi is the bandwidth (Mbps) between node i and the master node.

w1 is the weight of the first term.

w2 is the weight of the second term.

The Performance Ratio (PR) is defined to be the ratio of all performance functions. For instance, assume the PFs of three nodes are 1/2, 1/3 and 1/4, respectively. Then, the PR is 1/2:1/3:1/4; i.e., the PR of the three nodes is 6:4:3. In other words, if there are 13 transactions to be processed, 6 trans- actions will be assigned to the first node, 4 transactions will be assigned to the second node, and 3 transactions will be assigned to the last one.

B. Performance-Based Heuristics  Our algorithm is based on two heuristics to dispatch workload to slave nodes.

1. The total workload is divided in n chunks according to the PR of the n slave nodes.

2. Send the data chunk to the node with faster network bandwidth first. The network bandwidth is estimated by  Snode i  j  i  B  B .

In this paper, Bj is obtained from NWS (Network Weather Service) statistics [7]. Specifically, our network bandwidth estimation is extracted directed from [11].

C. Algorithm  Our algorithm is also a master/slave type of application. In the MASTER module, the total dataset is divided according to the PR of slaves, and the sub-datasets are transmitted ac- cordingly. In the SLAVE module, the sub-dataset is com- puted. The algorithm of our approach is described as follows.

Module MASTER 1. Initialization 2. Calculate performance ratio of all  slave nodes 3. Partition the total data according to  the PR 4. Get network bandwidth Bi of the link to  node i 5. Send data to slaves in non-increasing  order of Bi     6. Master could does its own computation work here  7. Gather results from all slave nodes 8. Print the results 9. Finalization   Module SLAVE 1. Receive data from the master node 2. Conduct data mining computation on its  local database 3. Send the result to the master  Without loss of generality, we assume the master node does not participate in computation in our algorithm. How- ever, the algorithm can be modified to utilize the computing power of the master node by remove the comment notation (//) in line 6.

D. An Example  To clarify our algorithm, we use the example in Figure 4 to go through the MASTER algorithm.

1. The master conducts initialization work.

2. The PR is obtained by equation (9), and is assumed to be  6:4:3.

3. The dataset is partitioned by 6:4:3.

4. The ratio of Bi values of three links is obtained from the  NWS information, and is assumed to be 4:1:2.

5. The data chunks are sent in the order: P1, P3, and then  P2, as shown in Figure 5.

6. The master collects results from slaves.

7. The master outputs the answer.

8. The master conducts finalization work.

For comparison, the partition sizes by different partition schemes are listed in Table II. In this table, ?EQ? means to distribute the workload to slaves equally, and ?CPU-Weighted? means to distribute the workload to slaves according to the ratio of CPU speed values of slaves. And, HDDS is our scheme.

Fig. 5. Example time line  Table II. The partition sizes by different partition schemes Node  Scheme P0  (Master) P1 P2 P3  EQ 256 85 85 86 CPU-Weighted 256 114 57 85  HDDS 256 118 79 59

V. EXPERIMENTAL RESULTS  To verify our approach, a grid testbed is built, and one type of data mining application programs is implemented with MPI (Message Passing Interface) to be executed on this testbed. To begin with, our grid environment is illustrated, and terminologies for our programs are described. Next, performance of our scheme is compared with that of other schemes on this grid, with respect to association rule mining.

Based on experimental results in this section, we could con- clude that our HDDS got performance improvement on pre- vious schemes for most cases.

A. Hardware Configuration and Terminology  We have built a grid testbed, which consists of one master and three domains. This testbed is illustrated in Figure 6. We have built this grid testbed by the following middleware:  Globus Toolkit 3.0.2 [10] Mpich library 1.2.6 [5, 6]  The hardware configuration of this testbed is shown in Table III.

Cluster 1 LZ  Cluster 2 THU  Cluster 3 HIT  Internet  Master  Fig. 6. The grid testbed  Table III. Hardware configuration Master  Host CPU Type CPU Speed RAM gamma3 Intel PentiumTM III 866MHz 512MB  Cluster 1: LZ (Li Zen High School) Host CPU Type CPU Speed RAM lz01 CeleronTM 900MHz 256MB lz02 CeleronTM 900MHz 256MB lz03 CeleronTM 900MHz 256MB  Cluster 2: THU (Tunghai University) Host CPU Type CPU Speed RAM beta1 CeleronTM 1.7GHz 512MB beta2 CeleronTM 1.7GHz 512MB beta3 CeleronTM 1.7GHz 256MB  gamma1 Intel PentiumTM III 866MHz 512MB gamma2 Intel PentiumTM III 866MHz 512MB  Cluster 3: HIT (Hsiuping Institute of Technology) Host CPU Type CPU Speed RAM  gridhit3 Intel PentiumTM 4 2.8GHz 512MB  In this experiment, the performance function and the per- formance ratio are the same as those defined Section 3. Be- sides, w1 is assigned as 1 and w2 is assigned as 0.5. Fur-     thermore, Ti for node i is obtained by executing Apriori, a representative algorithm for association rule mining, for input size 1000 transactions, while Bi for node i is obtained by NWS statistics [7, 11]. The resulting performance ratio is shown in Figure 7. For example, node 4 and node 5 have the same CPU speed. However, our HDDS assigns higher PR to node 4 because of its higher network bandwidth.

0.05  0.1  0.15  0.2  0.25  1 2 3 4 5 6 7 8 9  Node  R at  io CPU Ratio Performance Ratio  Fig. 7. Performance ratio of 9 slave nodes for our grid testbed  We have implemented one kind of data mining application programs in C language, with message passing interface (MPI) directives for parallelizing code segments to be proc- essed by multiple CPUs. For readability of experimental results, the description of our implementation for all pro- grams is listed in Table IV. In this table, ?cd_eq? means to distribute the workload to slaves equally, and ?cd_cpu? means to distribute the workload to slaves according to the ratio of CPU speed values of slaves. And, cd_hdds is our scheme. Our datasets are generated by the tool as in [14]. The parameters of the synthetic datasets are described in Table V.

Table IV. Description of our implementation for all programs AP Name Description  cd_eq Equal Data Partition cd_cpu CPU-Weighted Data Partition  Association Rule Mining (Count Distri- bution)  cd_hdds Our HDDS Data Partition  Table V. Description of our dataset Dataset Number of  Transactions Average Transac-  tion Length  Number of Items  D10KT5I10 10,000 5 10 D50KT5I10 50,000 5 10 D100KT5I10 100,000 5 10  B. Data Mining Application: Association Rule Mining  In this section, we implement the Apriori algorithm, and apply our HDDS to conduct data distribution. Specifically, the parallelized version of Apriori we adopt is Count Distri- bution (CD) [13].

Relative Performance for Different Dataset Sizes. First, execution time on the grid for the three schemes is investi-  gated. Figure 8 illustrates execution time of cd_eq, cd_cpu and our cd_hdds, with input size 10K, 50K and 100K trans- actions respectively. Experimental results show that our scheme got better performance than cd_eq and cd_cpu. In this case, our scheme for input size 100K transactions got 18% and 52% performance improvement over cd_eq and cd_cpu respectively.

From this experiment, we can see the significant influence of partition schemes on the total response time. In grid en- vironments, network bandwidth is an important criterion to evaluate the performance of a slave node. Cd_eq and cd_cpu are static data partition schemes. Therefore, they can not adapt to the practical network status. When communication cost becomes a major factor, our HDDS scheme would be well adaptive to the network environment.

Moreover, the reason why cd_cpu got the worst perform- ance can be contributed to the inappropriate estimation of node performance. In grid computing environments, CPU speed is not the only factor to determine the node perform- ance. A node with the fastest CPU is not necessary the node with optimal performance. This has been illustrated in Figure 7.

Speedup. In order to see how well our HDDS scheme speeds up, we keep the dataset constant to be D10KT5I10 and vary the number of nodes. Figure 9 shows that the response time of HDDS is decreasing as the number of nodes increases. This means our HDDS can choose available computing power to optimize its execution time. However, the curves of cd_eq and cd_cpu fluctuate as the number of nodes increases.

The Effect of Transmission Order. In this experiment, we address the effect of transmission order. As described in Section 4.2, Our HDDS sends data chunks in the decreasing order of link bandwidths. For comparison, we implement two schemes with different transmission order, cd_inc and cd_rand. In contrast to our HDDS, cd_inc sends data chunks in the increasing order of network bandwidths. On the other hand, cd_rand sends data chunks in the arbitrarily chosen order of network bandwidths. As shown in Figure 10, HDDS outperforms the other two schemes. The reason might be that our decreasing heuristic can reduce the overall waiting time of all slave nodes.



VI. CONCLUSION  In this paper, we have proposed a performance-based heuristic to solve the data partition problem for data mining applications, and have compared it with other algorithms by experiments for three types of application programs on our grid environment. In each case, our approach can obtain performance improvement on other schemes. In our future work, we will implement more types of application programs to verify our approach. Furthermore, we hope to study theo- retical analysis to find better solutions, and consider more status information.

