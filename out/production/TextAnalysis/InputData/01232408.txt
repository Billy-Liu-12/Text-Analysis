Proceedings of the 2003 IEEE  Workshop on Information Assurance

Abstract - This paper proposes a novel anomaly detection algorithm based on factor analysis and Mahalanobis distance.

Factor analysis is used to uncover the latent structure (dimensions) of a set of variables. It reduces attribute space from a larger number of variables to a smaller number of factors. The Mahalanobis distance is used to determine the ?simi1arity?of a set of values from an ?unknown?samp1e to a set of values measured from a collection of ?known? samples.

Combined with factor analysis, Mahalanobis distance is extended to examine whether a given vector is an outlier from a model identified by ?ffactors? based on factor analysis. In this paper, we present a factor analysis based network anomaly detection algorithm and apply it to DARPA Inirusion Detection Evaluation Data. The experimental results show that the proposed algorithm is able to detect network intrusions with relatively low false alarms.

Index terms - anomaly detection, intrusion detection, factor analysis

I. INTRODUCTION  Intrusion detection can be categorized into two broad categories: signature based and profile based. The signature-based approach (also called misuse detection) performs detection by searching network audit data for the matches of the ?signatures? of known attacks. Profile- based approach (also called anomaly detection) performs detection by searching the network audit data for deviations from the established profiles of normal behaviors of users and systems. Profiles of normal behavior can be built with a variety of techniques including statistical methods [2,3,4,5], association rules [7,8], neural networks [l], computer immunology [Y], and specification based methods [ 141.

As network attacks usually do something different from normal network activity, they should not comply with profiles. Usually the profile-based approach uses a collection of ?normal? measures on a set of statistics [3,4]  Dr. Wu and Dr. Zhang are with University of Arkansas at Little Rock. Dr. Wu works f o r  Information Science Department. Dr. Zhang works for  Applied Science Department. Email: (nxwu. ixzhangl I@.ualr.edu.. This work was partially supported by Acxiom Corp. under the contract 024-02 .

ISBN 0-7803-7808-3/03/$17.00 0 2003 IEEE  or features [7,8] to represent profiles. To determine whether an observed event is normal or not, the system examines its values on the statistics to see if they are different from those in the profile. If this is the case, the event is flagged as abnormal; otherwise, it is considered as normal. Techniques that used for judging the normality of an event include eBayes[ lo], sequence analysis[9], expert system, association rules and classification [8], and pseudoBayes estimators [7].

The profile can also be represented by a set of observations on a group of statistics, thus it is natural to view the profile as a multivariate data set. The task of examining the ?normality? of an observed event is equivalent to the one of examining whether the event is an outlier of the profile. Therefore, we can employ multivariate statistical methods to build the profile model and to detect events .that do not fit the profile model.

These events should correspond to the potential attacks.

In this paper, we propose a network anomaly detection a lgo r i thm based on factor analysis. Factor analysis is a statistical approach that can be used to analyze interre lationships among a large number of variables and to explain these variables in terms of their common underlying dimensions (factors). It involves finding a way of condensing the information contained in a number of original variables into a smaller set of dimensions with a minimum loss of information [12]. As a measurement, the Mahalanobis distance i s  s e d  in cluster analysis where scale independence is required.

The proposed algorithm employs factor analysis to reduce the dimensionality of a training data by capturing and retaining the important factors of data. The Mahalanobis distance is used to examine whether a sample vector fits the model of the training data. We apply the algorithm to network traffic data to detect intrusions. The algorithm has been evaluated based on the DARPA Intrusion Detection Evaluation Data. The results demonstrate that the algorithm is effective in capturing network attacks with relatively low false alarms and high detection rate.

The remainder of this paper is organized as follows: section 2 and 3 give a brief introduction to factor analysis and Mahalanobis distance. Section 4 presents an outlier detection algorithm based on factor analysis and Mahalanobis distance. Section 5 discusses the application   mailto:I@.ualr.edu   Proceedings of the 2003 IEEE Workshop on Information Assurance United States Military Academy, West Point, NY June 2003  of the algorithm to the network traffic analysis along with the experimental results. Section 6 contains related work and section 7 concludes the paper with open problems and future work.

11. FACTOR ANALYSIS  A .  Introduction  Factor analysis is used to uncover the latent structure (dimensions) of a set of variables. It reduces attribute space from a larger number of variables to a smaller number of factors.

Factor analysis has a variety of applications such as an assessment of underlying relationships or dimensions in the data, and the replacement of original variables with fewer, new variables.

Let x be the observable random vector with m variables Xl,X,,. ..,X, that have mean ,U and covariance matrix .

The factor model postulates that X is linearly dependent on a few unobservable random variables Fl,  F2, ..., F p , called common factors, and m additional sources of variation el, e2, ..., G, called errors, or specific factors.

The factor analysis model is [13]:  X, - p , = I , , F ,  tZ12F2  +...+ l,,,,F, + E , X,-,LL, =12,F, t l , ,F,  t . . .+I ,F,  + E ,  Xi - p m  =I,,? +lm2F2 +...+ lmPFp +E, , ,  or, in matrix notation  X - p = L F  + e  (1 ) The coefficient 1, is called the loading of the ith variable on the jth factor, so the matrix L' is the matrix of factor loadings.~The ith specific factor Ei is associated only with the ith . responsexi .  The p deviations XI - p , ,  X, - p 2 ; " , X m  -pm are expressed in terms of  m+p random variables FI, F2, ..., Fp, el, e2, . .., e,,, which are unobservable. If assume the unobservable random vectors F and e satisfy the following conditions:  E[F]=O, Cov(F)=E[FF'] = I  E[e] = 0, Cov(e) = E[ee'] = ? =  0 0 .. v, Cov(e, F) = E[eF' ] = 0  These conditions and the relation in (1) constitute the orthogonal factor model. The orthogonal factor model implies a covariance structure for X. From the model  (x-p) (X-p) '  =(LF +e)(LF +e)T = (LF +e)((LF)' + e r ) = LF(LF)' + e(LF)r + W e '  + ee7  so that  c =Cov(X) = E(X-p)(X-p)T = LE(FF ')Lr + E(eFr)Lr + LE(Fe') + E(ee') = LL' + ?

By (1) and (2), (X -p)Fr = (LF + e)F' = LFF ' + eFr , so Cov(X,F)=E(X-p)Fr =LE(FF')+E(eF')=L.

Thus, we can get covariance structure for the orthogonal factor model:  1. Cov(X)= U' + ?  or Var(X,)=If, +...+ I,L+Iy, Cov(X, ,A-,) = 1Jkl + ... + l J l m  COV(X,, F, 1 = lo  (3) 2. CovKF) = L or  The portion of the variance of the ith variable contributed by the m common factors is called the ith communality.

B. Methods ofparameter estimation  The principal component factor analysis of the sample covariance matrix S is specified in terms of its eigenvalue-eigenvector pairs ( ~ , , ~ ~ ) , ( ~ , , ~ * ) , . . . , ( ~ ~ , ~ ~ )  where A, > A 2  >...2il,. Let p<m be the number of common factors. Then the matrix of estimated factor  loadings {lij} is given by  The estimated specific variance are provided by the diagonal elements of the matrix S = LL' , so  L A  p, 0 ... 0 1  1 0  0 ... $,J  Communalities are estimated as  ip =i,:+$; +... ti,; ISBN 0-7803-7808-3/03/$17.00 0 2003 IEEE 109    Proceedings of the 2003 IEEE Workshop on Information Assurance United States Military Academy, West Point, NY June 2003  The principal component factor analysis can also be applied to the sample correlation matrix R. For the principal component solution, the estimated loadings for a given factor do not change as the number of factors is - - increased. For example, if p = l ,  i = [fi e , ]  and if p=2, i = [ f i 1 . & - 6 , ] ,  where (K,6,) and (&,&)are the first two eigenvalue-eigenvector pairs for S (or R).

The principal component method satisfies  z = L L ~ + O  = L L ~  C. Factor scores  Factor scores are estimates of values for the unobserved random factor vector Fj,j= l,...,n. That is, factor scores  f, = estimate of the values f j  attained by Since the unobserved quantities f j  and e, outnumber the observed x j ,  some approaches to estimating factor values have been proposed including the weighted least squares method and the regression method. Both approaches have two elements in common:  ($h case).

They treat the estimated factor loadings liiand  specific variances $, as if they were the true values.

0 They involve linear transformation of the  For simplicity, we only give the result of factor scores estimated by the principal component using least squares method.

Factor scores estimated by the principal component are generated using an un-weighted least squares procedure:  original data.

1 " n )=I  where SZ = - z x ,  is the sample mean.

111. MAHALANOBIS DISTANCE  The Mahalanobis distance is a useful way of determining the similarity of a set of values from an unknown sample to a set of values measured from a collection of known samples. Mahalanobis squared distance is a measure of statistical distance in multidimensional space. This statistic measures the distance from the centroid -- multidimensional equivalent of a mean, for a set of vector for each of the independent variables included in the analysis.

Let XI ,  x2, ..., x,, be a random sample from a population with mean vector p and covariance matrix X. The sample mean x and sample covariance matrix are  -  t ( X ,  -Z)(x, -QT - 1 "  1 x = - z x , ,  s=-  n )=I n - l ~ = t  Given an rn-dimensional vector v, the Mahalanobis distance between v and X is defined as  d ,  = (V - q T S - ' ( v - B  The larger the value of the Mahalanobis distance for a vector v is, the more likely the vector is to be a multivariate outlier.

One can think of the independent variables as defining a multidimensional space in which each observation can be plotted. Also, one can plot a point representing the means for all independent variables. This "mean point" in the multidimensional space is also called the centroid. The Mahalanobis distance is the distance of a vector from the centroid in the multidimensional space, defined by the correlated independent variables. If the independent variables are uncorrelated, it is the same i6 the simple Euclidean distance. Thus, this measure provides an indication of whether or not an observation is an outlier with respect to the independent variable values.

The Mahalanobis distance takes the sample variability into account. Instead of treating all values equally when calculating the distance from the centroid, it weights the differences by the range of variability in the direction of the sample point. There fore, the Mahalanobis distance constructs a space that weights the variation in the sample along the axis of elongation less than in the shorter axis of the group ellipse. Refer to the Mahalanobis boundary that has been superimposed on Figure 1 and this concept becomes much clearer. In terms of Mahalanobi measurements, sample 02 will have a substantially small distance to the mean than sample 01 since it lies along the axis of the group that has the largest variability. Thus, sample 01 is more likely to be an outlier.

Mahalanobis distances are calculated in units of standard deviation from the group mean. Therefore, the calculated circumscribing ellipse formed around the training data actually defines the one standard deviation boundary of that group. This allows the designing of a statistical probability to that measurement. In theory', samples that have a Mahalanobis distance of 3 or greater have a  ' Mahalanobis distance is distributed as  a chi-square statistic with degrees of freedom equal to the number of independent variables in the analysis.

ISBN 0-7803-7808-3/03/$17.00 0 2003 IEEE 110    Proceedings of the 2003 IEEE Workshop on Information Assurance United States Military Academy, West Point, NY June 2003  probability of 0.01 or less and can be classified as non- members of the group. Samples that have distances less than 3 are then classified as members. The determination of the cutoff value depends on the application and the type of samples.

F =  Figure I .  Mahalanobis distancc vs Euclidean distance  Iv. FACTOR ANALYSIS BASED ANOMALY DETECTION ALGORITHM  Factor analysis combined with Mahalanobis distance can be used to identify outliers from a model specified by the factors.

For a given set of n observations on m observed variables, we use a vector to represent the m observed variables of the i-th observation,  The n observations form an n-by-m matrix X, x,T = [ X R ' X , Z ' . . . ' X , m l  The sample covariance matrix is given as s = SEC:=,(., - 3 ( x ,  - qr  where X =[T,,TZ, ..., X,]' is the sample mean vector and X, the mean of column j .

The factor scores of X estimated by principal component are given by  * A A  (iTL)-l = X.L(LTL)'I  where i = [ f i l , f i 6 2 , - . - , K 6 p ] a n d  p is the number of common factors retrained.

In the proposed algorithm, the factor analysis is used to uncover the latent variables. It reduces attribute space from a larger number of variables, X,,X2, ..., &, to a smaller number of common factors F,,F2, ..., F,. The common structure of the given dataset can be better captured by the factor scores.

Factor Eased anomaly detection algorithm is shown as Figure 2:  activities output: the covariance matrix S, factor loadings L, and factor scores of X I .  Compute covariance matrix of X: s = x , ~  x X, ,  where X, = (x, -Y,xZ -51 ,..., xn -qT Do principal component decomposition of S to get its eigenvectors : S =V* ? *VT Pick the p common factors. An ad hoc rule to choose p  2.

3.

A A A  I 4. Compute the factor scores of X, : F = XZL(L'L)-l, I  (a) Algorithm for model construction  input: a sample vector v representing a test event, threshold for Mahalanobis distance d  output: decision on v 1. Compute the factor scores of v:  f ,  = (LrL)-'Lr ( V  -s?), where SZ is the column mean of x.

2. Computer Mahalanobis distance of v: d ,  = ( v  -SI)TS- ' (~  -X)  - 1  n  3. if d, > d , v is an abnormal event, otherwise, v is an normal event.

(b) Algorithm for anomaly detection  Figure 2: factor based anomaly detection algorithm  ISBN 0-7803-7808-3/03/$17.00 Q 2003 IEEE 111    Proceedings of the 2003 IEEE Workshop on Information Assurance United States Military Academy, West Point, NY June 2003

V. EXPERIMENTS  The proposed algorithm was applied to network intrusion detection. Given a dataset (so-called reference data) containing only normal TCP/IP connections and a test dataset containing some attacks in it, the algorithm is employed to learn the property of the normal activities in the training data by factor analysis, and then to detect abnormal activities in the test data. The performance of the algorithm is evaluated based on the detection rate, missed attack rate, and false alarm rate. The detection rate is measure as the percentage of attacks detected by the algorithm as abnormal events; the missed attack rate as the percentage of attacks missed by the algorithm; and the false alarm rate as the percentage of normal activity mistaken as abnormal ones by the algorithm. The experiments are based on DARPA Intrusion Detection Evaluation Data.

A.  DARPA intrusion detection evaluation data  DARPA Intrusion Detection Systems (IDS) Evaluation project is the first effort to provide data and methodology for off-line evaluation of intrusion detection systems. It was conducted by the Information System Technology Group of MIT Lincoln Laboratory, under DARPA I T 0 and Air Force Research Laboratory sponsorship. Details information can be found in [ 6 ] .  The project started from 1998 and continued in 1999. Today DARPA data sets are widely used as the benchmark for IDS evaluation. 1998 DARPA evaluation data contains seven weeks of training data and two weeks of test data. 1999 DARPA evaluation data contains three weeks of training data and two weeks of test data. Attacks in all training data are labeled. The test datasets of 1999 Evaluation contains of two parts collected at a gateway inside the mimic subnet and one outside the subnet respectively. Both training and test data are provided in several forms: UNIX BSM, tcpdump, and NT Data. We use tcpdump data for analysis.

B. Detecting abnormal activities of network traffic  1. Experiment Setup  Configuration of the experiments is shown as following: . Selection of the training data: We construct an attack-free dataset from 1998 training data by removing all the labeled attacks. We use it as the reference data of normal activity, and then apply the algorithm on 1999 test data to detect abnormal activities that do not comply with the property of the reference data.

ISBN 0-7803-7808-3/03/$17.00 0 2003 IEEE  Preprocess of data: For a network traffic dataset, a connection record is generated for each TCPAP connection based on a predefined schema  R={Ts, src.ip, src.port, dst.ip, dst.port, service, flag).

Ts gives the starting time of a connection. src.ip and src.port are source IP and port of a connection, and dst.ip and dst.port are destination IP and port. service gives the protocol type used in a connection such as ftp, smtp, etc. f lag  gives the status of a connection which can be open, close, reset, etc. A connection record is obtained only from the header of a TCP/IP connection.

We then apply association rules on the connection records. The obtained association rule set contains the frequently occurred patterns in the dataset. All the following discussion is based on the association rule sets. The reason we use the association rules instead of raw connection records is that the behavior patters in the dataset are better represented by the association rule set because the occurrence of an individual connection is often casual and can tell little about the property of other connections, while an association rule usually describes a common property shared by a set of connections. For instance a connection record of the form  (src.ip: 129.174.1 11.3,  src.port:3167, dst.ip:73.8.19.5, dst.port: 23, service: telnet, time: 15:23:12)  tells a fact that there is a telnet connection from 129.174.1 1 l.3:3167 to 73.8.19.5:23 at the time 15:23:  12. However an association rule of the form  src.ip: 129.174.1 1 1.3+ dst.ip:73.8.19.5, dst.port: 23, service: telnet, duration: 15:20:49- 15:29:03 [support = 10001  reveals an interesting pattern worthy of further investigation.

Three data mining algorithms are used including single-level association mining, multi-level association mining and feature selection. The rule set obtained by each mining algorithm captures the different characteristics of the data. Each rule set is then translated into a set of vectors, which is represented by a matrix. Total three matrixes are generated, one from each mining algorithm. The factor scores and associated factor loadings are then computed for each matrix. Details of the mining algorithms and the way to translate rules into vectors can be found in [7 ,8 ] .  For instance, the association rule of the above example is translated into the vector { 2 3 ,  telnet, 494, IOOO}, each field of which in order corresponds to the dstport,  service, duration, support     Proceedings of the 2003 IEEE Workshop on Information Assurance United States Military Academy, West Point, NY June 2003  Name Apache2 Back Dict Guessftp Guesspop Mailbomb Neptune Pod Portsweep Process Satan Smurf Teardrop telnet udpstorm Total  (a) Attack  respectively. For convenience, each service type is designated with a unique numeric service index. The service type telnet in the vector will be replaced wlth its index instead.

For the attack-free reference data, the factor loadings are computed and used as a model of normal activity patterns in the reference data. For the test data, the factor scores of each matrix are computed, and for each test vector v,  the mahalanobis distance between v and the centroid of the training data is computed. If the distance exceeds a predefined threshold, then the test vector is considered as abnormal. Only abnormal test vectors are output.

2. Experimental Results  We partition the detection results into three parts: ?true? attacks, false alarms, and missed attacks. A ?true? attack represents the alarm generated by the algorithm that is corresponding to a true network attack; A false alarm represents the one that is actually corresponding to normal network activity; A missed attack refers to a real attack in the test data that is missed because it is treated as normal activity by the algorithm.

Table 1 shows the detection result on 1999 DARPA inside test data and outside data. The significance level is chosen as d=lO. Each table contains the results of the test matrixes generated from the mining algonthms.

singleLevel refers to the matrix generated from the single- level association rule algorithm; multilevel refers to one generated from the multi-level association rule algorithm; featureSelect referes to one generated from the feature selection algorithm. Size gives the total number of test vectors in a matrix; trueNo gives the number of ?true? attacks detected by the algorithm. dRate gives the attack detection rate defined as dRate/(trueNo+missedNo).

falseNo gives the number of false alarms. f l u t e  gives the false alarm rate defined as falseNo/(size-trueNo- missedNo). missedNo gives the number of attacks in the test data are missed by the algorithm; mRute gives the missed attack rate defined as (I-dRate). The sum of trueNo and falseNo is the total number of alarms generated by the algorithm. The sum of trueNo and missedNo is the total number of real attacks in the test data.

attackNo   distribution o  ISBN 0-7803-7808-31036 17.00 0 2003 IEEE  (a) Experimental results on 1999 inside data  (b) Experimental results on 1999 inside data  Table 1: Detection results on 1999 DARPA test data  From Table 1. we can see that detection results on multilevel and featureSelection matrixes are better than that on singleLeve1 matrix. The latter has a higher rate of false detection and missed attacks, and contributes most part of false detection and missed attacks to the overall result. One reason is that the entire anomaly detection process is based on connection records, which contains information only from headers of TCP/IP connections.

When abnormality of an attack activity is not shown in the header but in the payload, the mining algorithms cannot capture them. Using only header information of a connection makes data preprocess faster and easy to handle the high-speed network traffic, however, at the risk of losing information of the payload. Another reason is that patterns extracted from the mining algorithms are not able to distinguish some attacks from normal activity.

detectedNo   he inside data     Proceedings of the 2003 IEEE Workshop on Information Assurance United States Military Academy, West Point, NY June 2003  Name Apache2 Back crashiis Guessftp Guesspop ipsweep mailbomb neptune  Portsweep process satan Smurf Teardrop telnet Total  Pod  AttackNo   detectedNo   (b) Attack distribution of the outside data  Table 2: Attack distribution of 1999 test data  Table 2 gives attack distribution in both inside and outside data, along with the names and number of detected attacks2. The first two columns Name and attackNo give the name and number of an attack in a test data, and detectedNo gives the number of a specific kind of attacks detected by the algorithm.

w. RELATED WORK In this section, we only present the related research work that applies statistical approach to anomaly detection.

Both NIDES[2] and EMERALD[3,4] employ a statistical method to measure the user and system behavior by a number of variables sampled over time, and then build profiles based on the variables of normal behavior. Then the real variables will be compared against profiles.

Deviations are considered as abnormal. Cabrera et al.

examined the application of statistical modeling for detecting novel attacks against computer networks [5]. By using Kolmogorov-Smirnov Test, they kmonstrate the difference between normal Telnet connections and attack embedded Telnet connections. Valdes et al. proposed eBayes technique to detect anomaly in network traffic [IO]. Defining a session as temporally contiguous bursts of TCP/IP traffic from a given IP, eBayes applied  ~  Here we only list the attacks in the test data that should be detected from header information.

ISBN 0-7803-7808-3/03/$17.00 0 2003 IEEE 114  Bayesian inference on observed and derived variables of the session to obtain a belief for the session over the states of hypothesis. Barbara et al. proposed a method based on pseudo-Bayes estimators to detect network anomaly that differs from normal network activity [7]. Pseudo-Bayes is effective in detecting network anomaly; however the parameter selection is an open problem. Ye et al.

presented a multivariate quality control technique, based on HotellingT2 and chi-square distance test, to detect intrusions by building a long-term profile of normal activities and using the norm profile to detect anomalies l151.



VII. CONCLUSION  This paper proposes a novel anomaly detection algorithm based on factor analysis and Mahalanobis distance. Factor analysis is used to characterize the normal network activities by uncovering the latent structure of them. It also reduces attribute space to a smaller number of factors. The Mahalanobis distance is used to determine the ?similarity? of network activities to the profiles. We applied the algorithm to the DARPA Intrusion Detection System Evaluation data and showed that the algorithm is effective in detecting network intrusions with tolerable false detection rate.

[ I ]  Ghosh and A. Schartzbard. A study in using neural networks for anomaly and misuse detection. In Proc. USENIX Security Symposium, 1999  [2] D. Anderson, T. F. Lunt, H.Javits, A. Tamaru, and A. Valdes. Detecting unusual program behavior using the statistical component of the next -generation intrusion detection system (NIDES). Technical Report SRI-CSL 95-06, SRI International, Menlo Park, CA, May 1995.

[3] P. Neumann and P. Porras. Experience with Emerald to Date. In First USENIX Workshop on Intrusion Detection and Network Monitoring, Santa Clara, California, April 1999.

[4] P. Porras and P.G. Neumann. Emerald: Event Monitoring Enabling Responses to Anomalous Live Disturbances. In the 1 gth National Information Systems Security Conference, Pages 353-365, Baltimore, MD, October 1997.

[5] Joao B. D. Cabrera, B. Ravichandran, and Raman K. Mehra. Statistical traffic modeling for network intrusion detection. In gh International Symposium on Modeling Analysis and Simulation of Computer and TelecommunicatIon systems, pages 466-473, 2000.

[6] Joshua W. Haines, Richard P. Lippmann, David J. Fried, Eushiuan Tran, Steve Boswell, Marc A. Zissman.

1999 DARPA Intrusion Detection System Evaluation: Design and Procedures. MIT Lincoln Laboratory Technical Report.

[7] Daniel Barbara, Ningning Wu, Sushil Jajodia.

Detecting Novel Network Intrusions using Bayes Estimators. In the 1'' First SIAM Conference on Data Mining.

[8] Daniel Barbara, Julia Couto, Ningning Wu, Sushil Jajodia. ADAM: Detecting Intrusion by Data Mining. Proceedings of the 2nd Annual IEEE Informtion Assurance Workshop, West Point, NY, 200 1 .

[9] S. Forrest, S. Hofmeyr, A. Somayaji, and T.

Longstaff. A sense of self for Unix Processes. In Proc. of IEEE symp. Security and Privacy, 1996.

[IO] A. Valdes and K. Skinner. Adaptive, model- based monitoring for cyber attack detection. In 3rd International Workshop on Recent Advances in Intrusion Detection (RAID 2000), pages 83-90, October 2000.

[ I l l  P.C. Mahalanobis. On Tests and Meassures of Groups Divergence I .  Journal of the Asiatic Society of Benagal, 26:541, 1930.

[12] Hair, R. Anderson, R. Tatham, and W. Black.

Multivariate data analysis with readings. New York: Macmillan, 3'd edition, 1992.

[13] R. J.  Johnson, D. W. Wichern, Applied multivariate statistical analysis (4'h ed.). New Jersey, Prentice Hall.

[14] R. Sekar, A. Gupta, J. Frullo, T. Shanbhag, A.

Tiwari, H. Yang, and S. Zhou. Specification-based anomaly detection: A new approach for detecting network intrusions. !in 4h ACM Conference on Computer and Communication Security, pages 265-274, Washington D.

C., Nov. 2002.

[I51 N. Ye, S. Emran, Q. Chen and S. Vilbert.

Multivariate Statistical Analysis of Audit Trails for Host- Based Intrusion Detection. IEEE Transaction on Computer, 51(7):81@820, 2002.

