A Weighted Frequent Itemsets Mining Algorithm  Based on Perpendicular Data Format

Abstract?mining frequent itemsets from a large dense type database may generate a large number of frequent itemsets, and it may generate redundant information in some cases. To address these problems, a weighted frequent itemsets mining algorithm based on perpendicular data format is proposed in this paper.

The algorithm uses constrains of support and weight together, and then by uses itemsets extension to mine weighted frequent itemsets which meet the support and weight constraints at the same time. In order to reduce the number of candidate itemsets, the algorithm used two methods, the first is pruned using property of weighted effectively extension, and the second is use hash table to store weighted non frequent binomial set.

Keywords- weighted sequential patterns; perpendicular data format; weighted frequent itemsets

I. INTRODUCTION Here are some problems in the process of mining frequent  itemsets from a large dense type database. It is that the process of mining may generate a large number of frequent itemsets. In order to get the solutions of these problems, Researchers proposed two methods. The first method is to mine frequent closed itemsets or maximal frequent itemsets. The maximal frequent itemsets includes information of all frequent itemsets, and its quantity is less than frequent closed itemsets. The algorithm Max-Miner[1] used dynamic sorting technology to pruning, it improves efficiency by reduces traversal space. The algorithm GenMax[2] uses perpendicular projection technology to store original data set, and uses progressive focusing technology to pruning non-maximal frequent itemsets.

The second method is to add correlative constrain to pruning uninteresting patterns effectively, and shrink search space.

The algorithm CAP[3] add the antimonotone constrain and the conciseness constrain into the process of mining frequent itemsets and use them to pruning, it improves algorithm?s performance. Pei et al.[4] proposed the conception of monotonicity, and sorting item appropriate, these make all kinds of constrains can use monotonicity property to mine. Ke Wang et al.[5] add the support constrain into mining process.

The algorithm LPMiner[6] add length decrease progressively constrain into mining process, in the process, LPMiner set minimum support as a variable, the variable is a function with pattern?s length decrease progressively. LPMiner easy to find frequent long pattern, it decreases generation of redundancy  short pattern effectively. The algorithm Wcloset[7] add weight constrain into process of frequent closed pattern mining.

Wcloset algorithm set different weight to each item, uses strategy of divide and rule to traverse FP tree bottom-up, and then mine frequent closed weighted pattern by detect weighted closed pattern. However, all of these algorithm just meet single constrain, they hard to meet user?s special requirement and their execution efficiency is not good enough.

In order to increase performance of algorithm and meet user?s special interest requirement, a weighted frequent itemsets mining algorithm based on perpendicular data format (WFI-PDF algorithm) is proposed in this paper. The WFI-PDF algorithm adds support and weight constrains into mining process. In the process the algorithm pruning according to property of weighted effective extension, this method can decrease generation of candidate itemsets. Meanwhile the algorithm uses hash table to store weighted infrequent binomial set to decrease further generation of candidate itemsets.



II. PROBLEM DEFINITION I={a1,a2,......,am} is the set of items, in the set, a1,a2,......,am  called item. Any nonvoid subset of I called itemsets, and the itemsets which include k items called k-itemsets. Level data format representation for data set is DB={T1,T2 Tn}, in the DB, each transaction has a unique identifier Ti(1 i n) and each Ti is subset of I. For the convenience of calculation, we use number 1,2??n to signify each transaction. Table I is level data format type data set.

TABLE I. LEVEL DATA FORMAT TYPE DATA SET  TID Transaction  1 a,c,e,f,h  2 a,c,e  3 a,b,c,d,e  4 b,c,d,e  5 b,c,d,f  6 a,g  This work is supported by the Natural Science Foundation of Hebei Province P. R. China under Grant No. F2015203326, and the Doctor Foundation of Yanshan University under Grant No. B671.

DOI 10.1109/IMCCC.2015.257    DOI 10.1109/IMCCC.2015.257     Each row of perpendicular data format data set is a two- tuples <item,tidset>, in the two-tuples, item represents a single item, tidset are set which include all transaction identifier belong to item. Table II is perpendicular data format representation corresponding to the table I.

TABLE II. PERPENDICULAR DATA FORMAT TYPE DATA SET  TID Transaction  f 1,4  d 3,4,5  b 3,4,5  e 1,2,3,5  a 1,2,3,6  c 1,2,3,4,5  As transaction subset, the number of appear time of itemsets I1 in the data set is n, the total number of transactions in the data set is N, then n/N is support of itemsets I1, noted as Sup(I1).The number of transaction identifier in tidset of each two-tuples in perpendicular data format data set is support of the tuples item, noted as Sup(item)=|tidset|,|tidset| is the number of transaction identifier. Each item of transaction data set is assigned a nonnegative integer as weight, noted as w(i), w(i) (0,1],i I. It is used w(i) to reflect the importance of each item in the data set, then weight of itemsets I1={i1,i2, ,in}(1 n m) is W(I1)=max{i1,i2, ,in}. The weighted support of itemsets I1 is WSup(I1)=W(I1)* Sup(I1). In the date set, noted minsup as minimum support and minweight as minimum weight which set by user, if the weighted support of itemsets I1 is WSup(I1)  minsup*minweight ,then I1 is weighted frequent itemsets, else I1 is weighted non frequent itemsets. However this constraint did not meet the closure properties, a itemsets is weighted non frequent, but its superset may be weighted frequent, so pruning process does not use this property directly.

The task of weighted frequent itemsets mining based on perpendicular data format is to mine all itemsets which?s weighted support not less than the product of minimum support and minimum weight; it is noted as minimum weighted support.

Definition 1 OrderedItem: the order of item by according to item?s support after descending order.

Scan data sets to get all the items, and according to item?s support diminishing order to sort items, if two items have same support, then sort them according to alphabetical order. For example, in data set of table I, the order of items is c,a,e,b,d,f,h,g. According to this order, the item in front of order is more than the item after, such as c>a.

Definition 2 MiniItem: each item in data set noted as a MiniItem.

Make extension of item which greater than MiniItem and combination of these items with MiniItem, then set of itemsets which?s support not less than minsup is noted as minimum item class of this minimum item. In the same time, record the  transaction?s identifier corresponding to these itemsets, noted as Tidset, it can calculated by intersect operate with Tidset.



III. WEIGHTED FREQUENT ITEMSETS MINING ALGORITHM BASED ON PERPENDICULAR DATA FORMAT(WFI-PDF  ALGORITHM)  A. Thought of Algorithm WFI-PDF algorithm based on the Apriori algorithm, it need  two steps to implement. First, find all weighted frequent itemsets which?s weighted support not less than the product of minimum support and minimum weight appointed by user, noted it as Lk, and then use weighted frequent pattern to generate all rule that meet the minimum confidence constraint.

Like other association rules algorithm, WFI-PDF algorithm makes improvement for the first step mainly. In the process of generate minimum item class Lk that corresponding to minimum item j, algorithm used the method of iterate search layer by layer, first, use all itemsets in the minimum item class Lk-1 joint item j to generate Ck, then pruning to reject itemsets which did not meet constraint, at last, got Lk.

Closure property does not deal weighted frequent itemsets with weight constraint effectively, a itemsets can be weighted frequent, but it?s sub-pattern may be weighted non frequent.

For this problem, this paper present property of effective weighted extension and use this property to pruning weighted candidate itemset.

The property of effective weighted extension(ewe): assume that minimum item i corresponding to minimum item class is Lk-1, according order of definition, set item j is the item just less than i, the corresponding candidate minimum item class Ck can generated by extend j with every itemsets Ii in Lk-1, then proceed frequent detection. If the product which is support of new generated itemsets Ij={Ii,j} multiply by maximum weight is less than minimum weighted support, then itemsets Ij and its superset all are not weighted frequent itemsets.

In order to reduce more candidate itemsets, store binomial set to hash table which did not meet property of effective weighted extension. The means is to check if binomial set combined by any two items is in hash table or not, if existed, then stop extend the itemsets.

Theorem 1: for the minimum item i, the minimum item class corresponding to i which k+1(k>1) candidate itemsets can mine by extend k-itemset and item i, and then iterate by layers to get all weighted frequent itemsets.

Proof: to extend item according by item?s order in the mine process, so obtain minimum item class corresponding to each minimum item successively. In process of generate minimum item class Lk corresponding to minimum item i, firstly, use all itemsets of minimum item class Lk-1 joint item i to generate Ck, and then get rid of itemsets which do not have property of weighted effective extension in Ck. Finally, use technology of search iterate by layers to catch all kinds of combination of all items, in the same time, catch all itemsets which no less than minimum weighted support, that are all weighted frequent itemsets.

minimum support(%)  ru nn  in g  t im  e( m  s)   minimum support(%)  ru nn  in g  t im  e( s)    B. Description of Algorithm Algorithm 1: WFI-PDF algorithm  Input: data set D, minimum support threshold value minsup, minimum weight minweight  Output: weighted frequent itemsets C  WFI-Mine(D,minsup,minweight)  (1)scan data set D and express D as perpendicular data format, noted it as VT; initialize Miniclass C as null; hash table H=null;  (2) according descending order of support to sort items, and delete items in VT which meet ewe;  (3) for each i do  (4) C=C Extend(VT,C,i,maxweight,H);  (5) end for  Subprogram: Extend (VT,C,i,maxweight)  Input: VT, minimum item i, minimum item class C corresponding to item i, maximum weight of all items maxweight  Output: minimum item class C corresponding to item i  (1) for each item j which more than i do  (2) Itemset=i j, Tidset=(j corresponding to Tidset i corresponding to Tidset);  (3) if Tidset.size*maxweight>=minsup*minweight then  (4) insert Itemset and Tidset into TempC;  (5) else H.hashkey=j, H.hashvalue=i;  (6) if Tidset.size*max(Itemset)>=minsup*minweight then  (7) output Itemset and Tidset.size;  (8) end for  (9) if C==  then return TempC;  (10) else {for any Itemset C do  (11) assume any item in Itemset is j  (12) if i and j not in H {  (13)Itemset1=Itemset i, TidSet=(Itemset Tidset i Tidset);  (14) if Tidset.size*maxweight>=minsup*minweight then  (15) insert Itemset1 and Tidset into TempC;  (16) if Tidset.size*max(Itemset1)>=minsup*minweight then  (17) output Itemset1 and Tidset.size;}  (18) end for  (19) return TempC;}  In algorithm 1, step 1 to scan dataset and use perpendicular data format to format it, in the same time, initialize minimum item class to null and assign null to binomial itemset H which  not meet property of weighted effective extension. In the step 2, catch all items meet condition on the basis of the perpendicular data format table, and delete tuple corresponding to weighted infrequent item which not meet condition in the perpendicular data format table. In the step 3-5, for each minimum item call function Extend() to breadth-first extend and generate minimum item class corresponding to minimum item.

The step 1-8 in subprogram Extend() to catch 2-itemsets contained item i by extend item i and each minimum item which greater than item i, and store 2-itemsets meet condition to minimum item class, in the same time, output itemsets which not less than minimum weighted support. In the step 9, if C is null, then return minimum item class of i, or else, extend item i and itemsets in the minimum item class C, catch minimum item class corresponding to i, finally, store and return minimum item class(step 10-19).



IV. THE ALGORITHM IMPLEMENTATION AND PERFORMANCE ANALYSIS  In this section, the paper sets data set and relative parameters to analyze algorithm performance by running time and scalability.

A. Running time analyze of WFI-PDF Algorithm Experiment measure execution efficiency of WFI-PDF  algorithm. In the first experiment, use true data set chess. The range of minimum support threshold set from 0.2% to 1.0%, meanwhile minimum weight set as 0.8 and 0.5, running time showed as Fig. 1. In the second experiment, use artificial data set T4I10D100K. The range of minimum support threshold set from 0.2% to 1.2%, increment is 0.2%, meanwhile minimum weight set as 0.8 and 0.5, running time showed as Fig. 2.

Experimental result showed WFI-PDF algorithm has higher efficiency.

Figure 1. Running time of WFI-PDF in chess  Figure 2. Running time of WFI-PDF in T4I10D100K     ru nn  in g  t im  e( m  s)   dimension number(k)  B. Scalability analyze of WFI-PDF Algorithm The scalability of WFI-PDF algorithm used another  experiment to measure. The minimum support threshold set as 0.25% and 0.5% in the artificial data set T4I10D100K.

Meanwhile minimum weight set as 0.8 and 0.5, the amount of transactions increase from 20K to 100K, scalability measurement result showed as Fig. 3. Running time is as the linear growth of the total number of transactions, it is proved that WFI-PDF algorithm has better scalability.

Figure 3.  Scalability of WFI-PDF in T4I10D100K

V. CONCLUSION In the paper, a weighted frequent itemsets mining algorithm  based on perpendicular data format (WFI-PDF) was proposed.

Firstly, the algorithm scan data set one time to transform transaction data set into perpendicular data format, then descending sort minimum item according to support, and extending among the items that probability of occurrence are higher. WFI-PDF is algorithm that could generate candidate itemsets, but candidate itemsets is generated by layers and from  bigger support to smaller support successively, the process of candidate itemsets generation would filter out many unnecessary weighted non frequent candidate itemsets. In the meantime, the property of effectively weighted extension and introduced of hash table which store weighted non frequent binomial set could reduce more candidate itemsets. WFI-PDF algorithm use minimum item and K-itemset to joint, in each minimum item, the weighted frequent itemsets is mined by pattern increment mode.

