Research and Implementation of MapReduce Programming Oriented Graphical  Modeling System

Abstract?Along with the beginning of the big data era, it becomes difficult to capture, store, search, share, transfer, analyze, and visualize bigger data using the traditional data processing applications. Therefore, the problem is very rigid for many larger companies and research institutes that how to correctly and efficiently extract useful information from the massive data .MapReduce is a programming model developed by Google for processing and generating large data sets in distributed environments. Hadoop, an open-source project, is used to implement Google MapReduce architecture which is wildly used by many large companies. However, it is difficult to program map-reduce functions for common users to solve real world problems because of the rigid pattern of the framework.

In this paper, we develop a graphic platform to help ordinary users in creating MapReduce application by dragging encapsulated components. We are particularly concerned with simplifying development and increasing efficiency.

Keywords- MapReduce, Hadoop, Graphical Modeling, Cloud Computing

I.  INTRODUCTION In recent years, with the significant advances in Cloud  Computing, the MapReduce programming framework has become an extremely popular method for developing distributed large-data processing application. MapReduce [1] is a programming model developed by Google for processing and generating large datasets that is amenable to a broad variety real-world tasks. It is easy for the user to utilize MapReduce to solve domain-specific problems.

The MapReduce framework splits a  larger-datasets processing work into some independent map task and assigned them to run on different machine, the task will output some temp result file stored in key-value format and then the framework send the different key-value pairs to different reduce task  by the key. The reduce processes the values with the same key and generates the final results.

Users only need to program the map and reduce function, and the framework provides an efficient runtime system that handles low-level mapping, resource management, and fault tolerance issues automatically regardless of the system characteristics or scale. Apache Hadoop [2], an open source implementation of MapReduce, is used by many corporations and institutions because of its scalable, economical, efficient, reliable features. MapReduce model is  used in many real-world issues such as large-scale indexing, distributed sort, count of URL access etc.

Although the MapReduce framework separates the data processing logic from the concrete distributed framework, and reduces the complexity of developing a distributed program. There exists some trouble before the common users can use the framework easily and efficiently to handle real- world issues in their domain-specific areas. Its two-stage data flow is extremely rigid. Users must convert real-world data processing flows info map-reduce data flow to utilize the framework. And it takes a period of time to train them to understand the MapReduce model in depth before they can write the real MapReduce programs.  Meanwhile, the MapReduce framework lacks an efficient tool to increase the level of code reuse and visual program. Every time they encounter the same type of issue they solved before, the framework does not have an easy way to reuse old code to solve new problems.

In this paper, we present a model driven and graphical modeling way to program MapReduce application, which is scalable and easy to use and implement a platform using Eclipse plug-in technologies and GMF platform. The platform can let the common users intuitively and graphically design a MapReduce application without actually writes MapReduce code. It will greatly reduce the difficulty of implement the MapReduce model to solve the domain- specific issues for the common users.



II. RELATED WORK  A. MapReduce Frameworks MapReduce application model is developed by Google  and first presented in 2004. A MapReduce program comprises a Map function that performs filtering and sorting, and a Reduce function that performs a summary operation.

The framework would run the tasks in parallel, manage all communications and data transfers between the various parts of system, provide redundancy and fault tolerance. Because of its various merits, many companies and research institutions have implemented the MapReduce framework in various platforms and various program languages.

Apache Hadoop, an open source implementation of MapReduce developed by Apache, is the most popular version in recent years. The Hadoop framework consists of a MapReduce implementation and a distributed file system   DOI 10.1109/CSE.2013.197    DOI 10.1109/CSE.2013.197     named HDFS [3], which is also an open source implementation of GFS [4], Google?s distributed file system.

Hadoop MapReduce framework consists of a master node named JobTracker and many slave nodes named TaskTracker. The JobTracker schedule and monitor the tasks which are running on the TaskTracker. Every task represents a map function or a reduce function.

There exist other implementations of MapReduce model on the different platforms, such as Phoenix [5], a shared- memory implementation of MapReduce model, Mars [6], MapReduce framework on graphic processors (GPUs) etc.

B. Pig Pig [7] is a high-level platform for creating MapReduce  programs used with Hadoop. The language used by this platform is called Pig Latin, Which provides a high level abstraction of data processing and also support UDF(User Defined Functions), used for data conversion or load/store data in a particularly  format. User can write data processing programs using Pig Latin and the platform will automatically transform it into MapReduce code, and run it on the Hadoop platform.

C. Hive Apache Hive [8] is a data warehouse infrastructure built  on top of Hadoop for data summarization, query, and analysis. It provides an SQL-like language called HiveQL while maintains full support for MapReduce. User can manipulate data in the Hive like in the traditional RDMS, without understanding the MapReduce model.

D. Other Platforms There exist other platforms, which are also built on top of  Hadoop to reduce the difficulty of program MapReduce code. Cascading [9] is an application framework for Java developers to simply develop robust data analytics and data management applications on Apache Hadoop, hiding the underlying complexity of MapReduce code.  Some domestic researchers also have presented papers on simplifying MapReduce usage, using the graphical modeling way [10].

All these platforms presented above provide various ways for users to use the MapReduce model to solve real- world issues, but all of them have two defects. First of all, they increase the learn time cost before users master the platforms to solve problems. Secondly, they don?t provide an easy way for the user to develop domain-specific MapReduce models to solve domain-specific problems.



III. THE MAPREDUCE PROGRAMMING ORIENTED GRAPHICAL MODELING SYSTEM   This paper presents a graphical modeling and graphical  program system for common MapReduce users to intuitively edit MapReduce model and use these models to processing large datasets. The users have not actual programming the map and reduce function and decrease the complexity of write, test, debug the MapReduce application.

We present five meta-models to abstract describe MapReduce application, and we also present some universal  models described by the meta-models to represent the universal data operation, job, map function, reduce function.

Using the Eclipse plug-in [11] and GMF [12] Technologies, we present a graphical way to edit MapReduce model and to develop MapReduce application. Therefore, users have a simple way to develop MapReduce application.

The MapReduce programming oriented graphical modeling system consists of four components, the MapReduce meta-model system, the MapReduce dynamic model lib, the code generation engine and the MapReduce application execution framework.

A. MapReduce Meta-model The MapReduce Application can be considered to be a  data flow which node represents a logical data operation and the arrow line represent the dependency relationship between the operations. So we present five meta-model to represent a completely MapReduce Application: the Operation meta- model, the Job meta-model, the Mapper meta-model, the Reducer meta-model, and the Parameter meta-model. Meta- model is the model which can describe the other models. We use the five meta-models to describe the MapReduce program. The relationships between the meta-models are shown in Figure 2.

Figure 1.  ???????? ??? ????	?????	?????	????????   1) Parameter meta-model:The parameter model is the abstract represent of the parameters, we use this model to represent the parameters which the Operation, Job, Mapper, Reducer needs.

2) Mapper meta-model:The Mapper model is the abstract represent of the map function of the job in the MapReduce application. User can define various Mapper model with the Mapper meta-model and the Parameter meta-model.

3) Reducer meta-model:The Reducer meta-model is the abstract representation of the reduce function of the job in the MapReduce application. User can define various Reducer model with the Reducer meta-model and the Parameter meta-model.

4) Job meta-model:The Job meta-model is the abstract representing of the job in the MapReduce application. A Job can consist of one or more Mapper, one or no Reducer and some Parameter.

5) Operation meta-model: The Operation meta-model is the abstract representation of the data operation in a MapReduce application.

A data operation is a logical concept, which does not really exist in the MapReduce code. It represents a complete operation, which users want to do with data sets, such as grep, sort, inverted index etc. An Operation can consist of one or more job, which depend on one another, and constitute a job DAG (directed acyclic graph) .The Operation meta-model is the most important part of the MapReduce meta-model system. A complete MapReduce application consists of one or more Operations, which depend on one another, and constitute an operation DAG (directed acyclic graph), the arrow line represents the dependency relationship between the Operations, as shown in Figure 2. Using the concept of Operation, we can transfer the data processing flow into an Operation chain, and finally a MapReduce application.

Figure 2.  ??????	??????? ????????  As described above, using the MapReduce meta-models, users can dynamical define a MapReduce model (an operation, a job, a mapper, a reducer) and set the attributes and dependency relationships of each models, then save the dynamical models into the model lib. When the users want to develop MapReduce application to process datasets, they can use the models in the model lib to constitute a MapReduce application, only to rewrite the necessary attributes, which are different from the last time. Also, they can save the model into the model lib too.

B. MapReduce Dynamic Model Lib MapReduce dynamic model is a model consisting of  MapReduce meta-models, which attributes can be set by user to represent a real-world data processing model. Using the Eclipse plug-in technology and the GMF technology, we build a platform for the user to add, edit, save, and use dynamic models.

This is the most important part of the platform, which we develop to implement MapReduce programming oriented graphical modeling approach. As shown in Figure 3, the user generates dynamic models through the graphical MapReduce Editor which is using to graphical generate, edit MapReduce model. After user define the structure of a dynamic model,  and defines its attributes such as the model?s name, the model?s ID, the model?s code template file etc. The user can save the new dynamic Model in the dynamic Lib through the Model Lib Manager. The Model Lib Manager persist the dynamic models user generated in the XML format. When the user starts to program the MapReduce model in the Graphical MapReduce Editor, the Editor will get all the information of the dynamic models the user have created and generate a graphical node on the editor to represent the semantic model. Then the user can use the dynamic models constitute data operation flow which they want to do with the datasets.

Figure 3.  ???????? ??	???????	???????? ????????? ??  C. Code Generation Engine The code generation engine finishes the work of transfer  the logical data operation flow into actual executable MapReduce code.

In the phrase of dynamic model generated, user should set the code template of the specific model, which is written in Xpand [13] language, the code generation engine will index the code template in the template lib, as shown in Figure 4. The code template acts the role which can extract the user-specific attributes of the model and translate into actual MapReduce code.

There are eight steps for the engine to translate the data operation flow to MapReduce code.

1) The engine would first traversal the data operation flow, and selects an operation node to translate.

2) There is a default operation code template in the code engine, the engine then generates a class file named by the name attribute of the node and write it?s primary structure.

Then the engine traversals all the job models the operation has and selects one to translate.

3) The engine will find the corresponding job code template by the ID attribute of the job model. Then, using the job code template, the engine will create a class file named by the name attribute of the job model and write it?s primary structure using the name and value attributes of the parameters the job model have. If the ID of the model is null or there don?t have a corresponding code template, there will return an error.

4) No matter the job model have one or more mapper model, the engine will find the corresponding mapper code template by its ID attribute and write a static class in the job file, also using the name and value of the parameters the mapper model have. If the ID of the model is null or there don?t have a corresponding code template, there will return an error.

5) If the job model have the reducer model, the engine will find the corresponding reducer code template by its ID attribute  and write a static class in the job class named by its name, also using the attributes of the parameters of  the reducer model. If the ID of the model is null or there don?t have a corresponding code template, there will return an error.

6) A complete job class has generated and the engine will go to step 2 to generate the next job, except that all jobs of the operation have been created.

7) After generating the operation and its job, the engine will go to step 1 to generate the next operation, except that all operations have been translated.

8) The engine will generate a driver class, which is the entrance of the whole application, and set the dependencies of the operations and the jobs in the class file.

At last, the engine will create a MapReduce Application which can run on Hadoop platform without write actual code. Programming MapReduce application in this way will promote the level if code reuse and the programming efficiency and reduce the time the user cost to manage the MapReduce model to solve real-world issues.

D. MapReduce Application Execution Framework The MapReduce application code generated by the  system is executable on the Hadoop platform. Using the Eclipse plug-in technology and interfaces supported by Hadoop, we develop a platform which can automatically submit the MapReduce application and monitor the progress and the result of the jobs.

E. System Architecture As shown in Figure 4, the MapReduce oriented graphical  modeling system has four components, the Hadoop job manager, the graphical MapReduce editor, the code generation engine, and the dynamic model manager. Using this system, users can create and edit MapReduce models on the graphical editor, save the models in the dynamic model lib through the dynamic model manager, translate the data operation flows into MapReduce code using code template engine and upload the MapReduce application to the Hadoop platform and monitor the job progress and result through the job manager.

In the ideal case, after the expert generate the necessary dynamic models and the corresponding code template in the specific domain. A common user who is not familiar with the MapReduce model and the Hadoop platform also can analysis the datasets using this system, only need to alter the necessary attributes of the models to adapt to different datasets.

Figure 4.  ???????? ??	??????????????	???

IV. CASE STUDY AND IMPLEMENTATION The MapReduce oriented graphical modeling system is  implemented using the Eclipse plug-in technology , the GMF modeling technology and  the MapReduce interface provided by the Hadoop platform. The system uses the Xpand to achieve the Model-to-text transformations and run the generated application on Hadoop cluster.

To show how to use our system to solve real-world issues, we now give a complete example. The csv (comma- separated value) format file is a common file format in the data analysis area. We will generate some necessary dynamic models using our system to show how to use the system to analysis the data, such as the common data operations, grep, group and topk.

Firstly, we generate the necessary mapper models, reducer models, job models and set the right attributes, and then we add the models into the model lib, set the corresponding code template. Then, using the dynamic models in the lib, we can create some logical data operations on the csv format dataset, which consists of series of job models which depends one another, as shown in Figure 5. At last, we can use the operation model to compose a data operation flow we want and set the right attributes, and then using the code generation engine, we finally get the MapReduce application; the Figure 6 shows the structure of the generated MapReduce code.

Figure 5.  ????????? ????????????	???????? ?????? ??? ?	???????   Figure 6.  ????	???	???????	?????????	??????????????????

V. CONCLUSION This paper proposes a MapReduce oriented graphical  modeling approach to program MapReduce application code and implement the system. We present a case study to show how to utilize the system to solve real-world issues. We conclude that the graphical modeling system not only increase the code reuses of the MapReduce code but also reduce the difficulty of the common user to handle the MapReduce model   to  solve the domain-specific problems.

In the future, we will continue our research in the following directions: 1) introduce the java application model and pig script model to utilize the Java class and Pig to improve the ability of system to solve various problems.2) add the function of attribute constraint and attribute validity verify before code transformation to the system to increase the efficiency of the graphical modeling.

