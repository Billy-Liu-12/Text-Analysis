Eager Learning in Two-Stages for  Precise and Complete Web

Abstract? We present a systematic approach to automatic web recommender systems based on Web usage mining in a first stage to learn user profiles, and a second data mining phase that is devoted to learning several accurate models for predicting user requests for each profile. Our approach differs from existing methods because it includes two separate learning phases: one to learn the user profiles, and another to learn a recommendation model. Most previous approaches do not include adaptive learning in a separate second phase, and instead base the recommendations on simple assumptions such as nearest profile recommendations, or deployment of pre-discovered association rules.

Index Terms?personalization, recommender systems, collaborative filtering, web usage mining, neural networks

I. INTRODUCTION Personalization aims to customize the interactions on a website depending on the user?s explicit and/or implicit interests. The move from traditional physical stores of products or information (such as grocery stores or libraries) to virtual stores of products or information (such as e-commerce sites and digital libraries) has practically eliminated physical constraints traditionally limiting the number and variety of products in a typical inventory. At the same time, the move from the physical to the virtual space has flattened the traditional three dimensional layout of products for which access is further facilitated thanks to the sales representative or librarian who know their products and their customers. As a result, the users can be overloaded by the huge number of options, most of which they may never even get to know. Hence, in both the e-commerce sector and digital libraries, Web personalization has become more of a necessity than an option. One of the most successful examples of personalization comes in the form of recommender systems.

Automatic Web personalization can analyze the data to compute recommendations in different ways, including:  (1) Rule-based filtering ? In this approach, used frequently to customize products on e-commerce sites such as Dell on Line , the user answers several questions, until receiving a customized result such as a list of products. This approach is mostly based on heavy planning and manual concoctions of a judicious set of questions, possible answer combinations, and customizations by an expert. It suffers from a lack in intelligence (no automatic learning), and tends to be static.

(2) Content-based or Item-based filtering ? This system recommends items deemed to be similar to the items that the user liked in the past. Item similarity is typically based on domain specific item attributes (such as author and subject for book items, artist and genre for music items). This approach has worked well for Amazon  [14], and has the advantage of easily including brand new items in the recommendation process, since there is no need for any previous implicit or explicit user rating or purchase data to make recommendations. However, this model is unable to include any element of surprise, meaning that it cannot capture interest in items that are different, and yet linked by some conceptual association.

(3) Collaborative filtering or user-based filtering ? Based on the assumption that users with similar past behaviors (rating, browsing, or purchase history) have similar interests, this system recommends items that are liked by other users with similar interests [19]. This approach relies on a historic record of all user interests such as can be inferred from their ratings of the items on a website (products or web pages). Rating can be explicit (explicit ratings, previous purchases, customer satisfaction questionnaires) or implicit (browsing activity on a website). Computing recommendations can be based on lazy or eager learning to model the user interests. In lazy learning all previous user activities are simply stored, until recommendation time, when a new user is compared against all previous users to identify those who are similar, and in turn generate recommended items that are part of these similar users? interests.

For example, K-Nearest-Neighbors (KNN) can be used to provide recommendations from the previous history of the K most similar users. Lazy models are fast in training/learning, but they take up huge amounts of memory to store all user activities, and can be slow at recommendation time because of all the required comparisons. On the other hand, eager learning relies on data mining techniques to learn a summarized model of user interests (a decision tree, clusters/profiles, etc) that typically requires only a small fraction of the memory needed in lazy approaches. While eager learning can be slow, and is thus performed offline, using a learned model at recommendation time is generally much faster than lazy approaches.  Several approaches to automatically generate Web recommendations based on previously mining user?s Web navigation patterns or ratings exist [1-4] [6] [17-20]. Probabilistic models, frequent itemsets, session clusters, or user profiles can form a user model obtained using data mining. Examples of previous profile modeling methods include Naives Bayes [7], association rules [9] and session clustering [3, 23]. In order to take into account     the inherent uncertainties in all the phases of Web personalization, Nasraoui and Petenes [23] presented a recommendation strategy based on Web usage mining based on clustering sessions and fuzzy approximate reasoning to recommend relevant URLs. Among the most popular methods, the ones based on collaborative filtering and the ones based on fixed support association rule discovery may be the most difficult and expensive to use. This is because, for the case of high-dimensional and extremely sparse Web data, it is difficult to set suitable support and confidence thresholds to yield reliable and complete web usage patterns. Similarly, collaborative models may struggle with sparse data, and do not scale well to the number of users [16].

In this paper, we investigate several single-step and two-step recommender systems. The Context Sensitive Approaches based on single-step Recommender systems (CSA-1-step-Rec) simply predict the URLs that are part of the nearest estimated profile as recommendations. The nearest profile prediction model simply bases its recommendations on the closest profile. The Context Ultra-Sensitive Approaches based on two-step Recommender systems (CUSA-2-step-Rec) first maps a user session to one of the pre-discovered profiles, and then uses one of several profile- specific URL-predictor neural networks (such as Multilayer Perceptron or Hopfield Autoassociative memory networks) in the second step to provide the final recommendations. Based on this classification, a different recommendation model is designed for each profile separately. Each neural network is trained to complete the missing URLs of several complete ground-truth sessions from a given profile, given as input several incomplete subsessions. This learning is analogous to completing some missing parts of a puzzle. The two-step recommendation method not only handles overlap in user interests, but also can mend the effects of some types of misclassifications in the first nearest profile assignment step, and even mend the effect of a coarse profile dichotomy due to the profile discovery stage.

The rest of the paper is organized as follows. In Section 2, we summarize our profile discovery using Web usage mining. In Section 3, we present the single-step profile prediction based recommendation process, and the two-step recommender system based on a committee of profile-specific URL-predictor neural networks. In Section 4, we present our experimental results using real web usage data, and finally, in Section 5, we wrap with our conclusions.



II. PROFILE DISCOVERY BASED ON WEB USAGE MINING Our approach is based on first extracting user profiles or ratings using a method, such as Web usage mining. In this case, the profile discovery can be executed offline by mining user access log files using the following steps:  (1) Preprocess log file to extract user sessions, (2) Categorize sessions by clustering, (3) Summarize the session categories in terms of user profiles,  After automatically grouping sessions into different clusters, we summarize the session categories in terms of user profile vectors, pi: The kth component/weight of this vector (pik) captures the relevance of URLk in the ith profile, as estimated by the conditional probability that URLk is accessed in a session belonging to the ith cluster.



III. DESCRIPTION OF THE SINGLE-STEP AND TWO-STEP RECOMMENDATION STRATEGY OPTIONS  Let U = {url1, url2, ?, urlNU} be a set of NU urls on a given web site visited in web user sessions sj, j = 1, ...., Ns, as defined in (1).

Let P = {p1, p2, ?, pNP} be the set of NP Web user profiles computed by the profile discovery engine. Each profile consists of a set of URLs associated with their relevance weights in that profile. The problem of recommendation can be stated as follows. Given a current Web user session vector, sj = [sj1, sj2, ?, sjNU], predict the set of URLs that are most relevant according to the user?s interest, and recommend them to the user, usually as a set of Hypertext links dynamically appended to the contents of the Web document returned in response to the most recent Web query. It may be useful to associate the kth recommended URL with a corresponding URL relevance score, rjk. Hence it is practical to denote the recommendations for current Web user session, sj, by a vector rj = [rj1, rj2, ?, rjNU]. In this study, we limit the scores to be binary.

A. Context Sensitive Approach Based on Single-Step Profile Prediction Recommender System (CSA-1-step-Rec)  A.1 Single-Step Nearest-Profile Prediction Based Recommender System  The most rudimentary approach to profile based Web recommendation is to simply determine the most similar profile to the current session, and to recommend the URLs in this profile, together with their URL relevance weights as URL recommendation scores. The similarity score between an input session, s, and the ith profile, pi, can be computed using the cosine similarity as follows,  UU  U  N  k k N  k ik  N  k kikine si  sp  sp S   1cos (1)  If a hierarchical Web site structure should be taken into account, then a modification of the cosine similarity, introduced in [3,4], that can take into account the Website structure can be used to yield the following input membership,  ine siN  k k N  k ik  N  l  N  k kuilweb si S  sp  sklSp S  UU  U U  cos   1 1 , ),(  max (2)  where Su is a URL to URL similarity matrix that is computed based on the amount of overlap between the paths leading from the root of the website (main page) to any two URLs [3], and is given by  1,max,1max ,1min),(  ji  ji u pp  pp jiS  (3)  We refer to the special similarity in (2) as the Web Session Similarity.

A.2 Single-Step Decision-Tree Based Profile Prediction Recommender System  The nearest profile prediction model makes the critical assumption that sessions in different profiles are linearly separated. While this may be applicable for certain web mining methods, it may not be true for others. In order to be able to reliably map new unseen sessions to a set of mined profiles, without such assumptions about the profiles or how they separate the sessions, we can resort to classification methods that     are not based on distance or similarity computations. In this paper, we explore both decision trees and neural networks for this task. Once trained, using the decision tree or neural network model to classify a new session is fast, and constitutes the single step of the recommendation process, since the classified profile is the recommendation set. The decision tree profile prediction model is very similar to the nearest profile prediction model. An input binary vector is presented as input to the decision tree [22] and a profile/class is predicted as the output. Each URL in the input vector is considered as an attribute. In learning, first the entire training data set is presented. An attribute value is tested at each decision node with two possible outcomes of the test, a branch and a sub-tree.  The class node indicates the class to be predicted.

A.3 Single-Step Neural Network Based Profile Prediction Recommender System  In the neural network [21] based approach of profile prediction, a feed-forward multilayer perceptron is used and is trained with Back-Propagation. The inputs (session URLs) and output (class or profile) to the prediction model remain the same as the ones described above. The neural network replaces the nearest profile classification. Hence the input layer of the network consists of as many input nodes as the number of valid URLs (i.e. NU nodes), an output layer having one output node for each profile (i.e. Np nodes), and a hidden layer with (NU+ Np) /2 nodes. The index of the output node with highest activation indicates the final class/profile.

B. Context Ultra-Sensitive Approach Based on Two-Step Recommender System with A Committee Of Profile-Specific URL-Predictor Neural Networks (CUSA-2-step-Rec)  The single-step Profile prediction recommendation procedure is intuitively appealing and simple. In particular, its implementation and deployment in a live setting is very efficient, essentially amounting to a look-up table. However, it has several flaws: (i) the degree of similarity between the current session and the nearest profile that is identified may not be taken into account, (ii) the above procedure does not take into account sessions that are similar to more than a single profile, (iii) it cannot handle sessions which are different from all known profiles, and (iv) the set of recommendations derive directly from the contents of a single (assigned) profile for all sessions assigned to this profile, without any further distinction between the specific access patterns. For this reason, we propose a two- step approach that in addition to exploiting the profile information, is able to recommend more highly personalized recommendations that depend not only on the assigned profile (user-to-user collaboration filtering), but also explicitly, on the input session itself (item-to-item collaboration filtering),.

B.1 Description of the Multi-Layer Perceptron URL-Predictor Neural Network  A Multilayer Perceptron neural network [21] can be used to predict the recommendation URLs. The architecture of this network, shown in Figure 1, is different from the network used in the profile prediction scenario of Section A.3. This is because the number of output nodes is now equal to the number of input nodes. The neural network is trained to complete the missing  URLs of several complete ground-truth sessions, given as input several incomplete subsessions. This learning is analogous to completing some missing parts of a puzzle. Each training input consists of a user sub-session (ss) derived from a ground-truth complete session S, while training by example teaches the network output nodes to conform to the remainder of this session (S-ss). This means that there is one output node per URL. Hence, the architecture of the network can become extremely complex.

Training such a network may prove to be unrealistic on large websites that may consist of thousands of URLs. To overcome this problem, a separate network is learned for each profile independently, with an architecture of its own. The number of input and output nodes depends only on the number of significant URLs in that profile, and possibly those related to its URLs by URL-level or conceptual/semantic similarity (e.g.

using Eq. (3)). The number of hidden nodes is set to the average of number of input and output nodes. Figure 1 shows the architecture of each URL-predictor neural network. There will be a committee of Np specialized networks of similar kind used in developing this URL recommendation prediction model, as illustrated in Figure 2. Each of these networks is completely specialized to forming the recommendations for a single profile, hence offering a local, more refined model.

Fig. 1. Architecture of a Profile-Specific URL-Predictor Multi-Layer Perceptron Neural Network used in CUSA-2-step-Rec  B.2 Learning the Profile-Specific URL-Predictor Neural Network Models  The URL-Predictor network for each profile is learnt independently with a separate set of training data. Learning each network involves presenting a sub-session consisting of some of the URLs visited by the user belonging to that profile as input and adjusting the network weights by back propagation to recommend URLs that are not part of the sub-session given as input, but which are a part of the ground truth complete session, as output of the network. For each ground truth complete session, we find all the sub-sessions for window sizes 1-10, and use them to generate independent training and testing sets.

Cosine similarity is used to map each sub-session to the closest profile, and the URL-Predictor network specialized for that profile is invoked to obtain the recommendations. A URL is considered to be recommended if its activation value exceeds a ?0.5? at the corresponding output node of the invoked network.

Fig. 2. Context Ultra-Sensitive Approach based on Two-Step Recommendation Process (CUSA-2-step-Rec) using a Committee of Profile-Specific URL-Predictor Neural Networks (Any URL-Predictor model can be substituted for the Multi- Layer Perceptron, e.g. a Hopfield network)  C. Recommendations Based On Autoassociative Memory Hopfield Networks  Hopfield networks are a special kind of recurrent neural networks that can be used as associative memory [21]. A Hopfield network can retrieve a complete pattern stored through the training process from an imperfect or noisy version of it. In some sense, a recommender system performs a similar operation, when it recommends certain URLs from an incomplete session.

Given Nurl fully connected (via symmetric weights wij between each two units i and j) neurons, each serving simultaneously as input and as output, and assuming that the activation values, xi, are bipolar (+1/-1), the optimal weights to memorize Np patterns, can be determined by Hebbian learning as follows  for allpN  p  p j  p iij xxw   ji (0, otherwise) (4)  During testing/recall, when a new noisy pattern xnew is presented as input, we set the activation at node i at iteration 0 to be xi0 = xnew-i, then the units are adjusted by iteratively computing, at each iteration t  url  j  N  j  t ij  t i xwx   1          (5)  until the network converges to a stable state. However, the desired behavior of recall in a Hopfield network is expected to hold only if all the possible complete session prototypes can be stored in the Hopfield network?s connection weights, and if these complete sessions do not interact (or cross-talk) excessively. Severe deterioration starts occurring when the number of patterns exceeds a certain fraction of the number of nodes:  Np > 0.138Nurl, (6) hence limiting a Hopfield recommender system to sites with a large number of URLs and yet very little variety in the user access patterns. This limitation is paradoxical in the context of large websites or transactional database systems. Our preliminary simulations with both a single global Hopfield network as well as several profile-specific Hopfield networks have resulted in low recall qualities since the network seemed to be able to memorize only very few stable states. However several profile-specific Hopfield networks perform better than one global network, but only for some of the profiles.



IV. EXPERIMENTAL RESULTS  A. Mining User profiles from Anonymous Web Usage Data  1703 web sessions accessing 343 URLs, extracted from log files of a university Web server, were used to generate training and testing sets. For each complete session considered as the ground- truth, all possible sub-sessions of different sizes are generated.

The test dataset forms an independent 20% of the sub-sessions.

Hierarchical Unsupervised Niche Clustering (H-UNC) [6] partitioned the web sessions into 20 clusters, each characterized by one of 20 profile vectors that were validated for consistency.

B. Comparative Simulation Results for CUSA-2-step-Rec, CUSA-2-step-Rec, and K-NN Collaborative Filtering  We used the following parameters in training the multilayer perceptron URL-Predictor neural networks: Maximum number of epochs = 2000, Learning Rate = 0.7 (for Input to Hidden layer) and 0.07 (for Hidden to Output layer), and a Momentum factor of 0.5.  The Collaborative filtering approach [16] is based on using K Nearest Neighbors (K-NN) followed by top-N recommendations for different values of K and N. First the closest K complete sessions from the entire history of accesses are found. Then the URLs present in these top K sessions are sorted in decreasing order of their frequency, and the top N URLs are treated as the recommendation set. We show only the best results obtained for K-NN at K=50 neighbors and N=10 URLs.

Figures 3 and 4, depicting the 20-profile averaged precision and coverage measures, show that the two-step profile-specific URL- predictor multilayer perceptron neural network recommender system (CUSA-2-step-Rec) wins in terms of both precision and coverage, particularly above input sub-session size 2. It may at first appear unusual that a recommendation strategy scores highly on both precision and coverage, and that an increase in precision did not seem to compromise coverage in any way.

However, by looking at the details of the design of the profile- specific URL-predictor neural network, we explain this relentless increase in precision by the fact that the neural network output is trained to predict only the URLs that the user has not seen before, i.e. ?S-ss?, where S is the complete session, and ss is the sub-session (URLs visited by the user). Clearly, as the sub-session size increases, more URLs are presented to the output of the neural network, making the prediction task easier, since fewer URLs need to be predicted compared to smaller input sub-sessions. Similarly, coverage increases, since with more input URLs, the neural network is able to predict more of the missing URLs to complete the puzzle. However, this does not happen at the expense of precision. On the contrary, giving more hints about the user in the form of more of the visited URLs makes the prediction task easier, and hence, will only result in more accurate predictions.

We notice that the single-step recommender systems (CSA-1- step-Rec) do not have this nice feature, i.e., precision and coverage will generally have opposing trends. The performance of k-NN fares competitively with all the single-step recommender strategies, but only for longer session sizes. This is not surprising, considering that k-NN can yield very accurate predictions, because it too is based on local context-sensitive     profile Number of Nodes (URLs)  Number of Sessions  Average Cosine similarity (Hopfiled)  Max Length  Median Length  models. However, k-NN is notorious for its excessive computational and memory costs, at recommendation time, in contrast to all the other investigated techniques. While lazy in the learning phase, involving nothing more than storing the previously seen cases, k-NN takes its toll during the recommendation phase, when it needs to compare a new session with all past cases to produce recommendations.

Table 1 summarizes the characteristics of the session lengths for each profile. The median session length for most profiles is larger than 5 and for six of the profiles (0, 3, 4, 5, 11, and 15), it is greater than 9. For these profiles, half of the sessions have length greater than or equal to 9. Moreover, because we generate a large number of subsession combinations from each session for testing, we end up with a reasonably large number of test sessions (in the hundreds), especially between session size 2 and 8. We notice from Fig. 3 and 4, that at longer session lengths (above 5), the quality of recommendations with CUSA-2-step- Rec -NN far exceeds that of k-NN. This can be explained by the fact that while the performance of k-NN eventually saturates and even starts decreasing beyond a certain session length, that of the CUSA-2-step-Rec ?NN approach can only improve, since each specialized network is essentially trained to complete the missing pieces (URLs) of a complete session, when given as input only some of the pieces. Hence, it is only natural in this context that when more pieces are shown, a specialized neural network is better able to predict the missing pieces. The degradation of precision that results from higher coverage in k- NN approaches is avoided because the neural networks in CUSA-2-step-Rec are trained to be precise, while excessive coverage is controlled thanks to the specialization of each NN to only one of the profiles. Finally, we note that, if all input sub- session lengths are taken into account, then it is clear that a combination of several different recommender strategies, each applied only within its optimal range of sub-session length, will outperform each one of the recommender strategies acting on its own. In fact, in this case, even the very simple CSA-1-step-Rec strategy based on nearest profile identification outperforms all other strategies for very short input sessions (< 2 URLs). This is crucial to the retention and guidance of users who may be in their very initial browsing stages.

Finally, in Table 1 ? column 4, we show the performance (averaged over all session lengths) of the CUSA-2-step-Rec approach when specialized Hopfield networks are used for each profile instead of the multilayer perceptron neural networks. It is important to note that, while testing both types of neural networks was performed in a similar fashion, training them was a different matter. The Hopfield networks in our context are analogous to auto-associative memory banks. Hence, they were trained to memorize each complete session, and not to complete missing parts of a complete sessions from a large number of incomplete subsessions as in the multilayer perceptron neural networks.

We notice that while some profiles can be handled using the Hopfield networks, the performance for many profiles is poor, even sinking to complete failure for profiles 10, 17, 18, and 19.

We attribute this failure to the excessive amount of cross-talk between the patterns to be memorized by the Hopfield networks for these profiles compared to the low number of nodes/URLs, especially in light of the constraint in (6). For example, as shown  in Table 1, the Hopfield network for profile 18 had to memorize a large number of patterns: Np = 65 training sessions in contrast with only Nurl = 5 nodes. We have also trained a single global Hopfield network for all profiles to predict the URLs of incomplete sessions. Note that in this case, the constraint in (6) is severely violated with Np = 1703 training patterns and Nurl = 343 nodes. Not surprisingly, the average similarity between the memorized and retrieved sessions, obtained in this case, was nil.

TABLE 1: SESSION PROPERTIES AND AVERAGE COSINE SIMILARITY BETWEEN COMPLETE SESSION AND SESSION RETRIEVED FROM AN  INCOMPLETE INPUT USING SEVERAL SPECIALIZED HOPFIELD NETWORKS (ONE PER PROFILE). THE SIMILARITY OBTAINED WHEN  A SINGLE GLOBAL HOPFIELD NETWORK WAS USED FOR ALL PROFILES WAS NIL.

0 189 106 .57 40 10 1 194 104 .4 40 6 2 171 177 .6 132 7 3 101 61 .18 40 10 4 134 58 .47 40 9 5 153 50 .13 132 10 6 104 116 .43 24 5 7 64 51 .62 23 7 8 139 134 .29 36 4 9 73 41 .31 25 3 10 134 95 0 19 4 11 98 185 .68 36 9 12 170 74 .26 132 5 13 136 38 .27 132 5 14 163 33 .28 31 6 15 86 51 .54 37 9 16 105 77 .3 132 2 17 23 68 0 6 1 18 5 65 0 3 1 19 24 120 0 10 2  Precision   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9   0 1 2 3 4 5 6 7 8 9 1  subsession size  Pr ec  is io  n  K-NN(K=50,N=10)  1-step Nearest Profile-Cosine 1-step Nearest Profile-  1-step Decision Tree  1-step Neural Network  2-step Profile-specific NN   Fig. 3. Precision Values for all recommendation strategies (CSA-1-step-Rec, CUSA-2-step-Rec, and K-NN)

V. CONCLUSIONS  We have investigated several single-step and two-step recommender systems. The single-step recommender systems (CSA-1-step-Rec) simply predict the URLs that are part of the nearest estimated profile as recommendations. The nearest profile prediction model simply bases its recommendations on the closest profile based on a similarity measure, hence favoring linearly separable profile classes. In order to be able to reliably map new unseen sessions to a set of mined profiles, without such assumptions about the profile separation, we can resort to more powerful classification methods. We explored both decision     trees and neural networks for this task. Once trained, using the decision tree or neural network model to classify a new session constitutes the single step of the recommendation process, since the classified profile is the recommendation set. The two-step recommender system (CUSA-2-step-Rec) first maps a user session to one of the pre-discovered profiles, and then uses one of several profile-specific URL-predictor neural networks in the second step to provide the final recommendations. A  different recommendation model specializes to each profile.

Coverage   0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  0 1 2 3 4 5 6 7 8 9 1  subsession size  C ov  er ag  e  K-NN(K=50,N=10)  1-step Nearest Profile-Cosine  1-step Nearest Profile-WebSession  1-step Decision Tree  1-step Neural Network  2-step Profile-specific NN   Fig. 4. Coverage Values for all recommendation strategies (CSA-1-step-Rec, CUSA-2-step-Rec, and K-NN)  The Hopfield auto-associative memory network is an alternative to the multilayer perceptron, and is trained to memorize a complete session. Our experiments confirmed that Hopfield networks can only form a reliable memory bank under severe constraints governing the relationship between the number of patterns to be memorized and the number of units in the network, and that unfortunately, these constraints are easily  iolated in typical real web usage environments. Nevertheless, several profile-specialized Hopfield networks in a CUSA-2-step- Rec framework performed better than a single network. The idea of using a separate network specialized to each profile provides an even higher level of context-awareness in personalization than the level already offered through collaborative filtering.

This modular design could be extended by replacing the URL- Predictor neural network modules by different learning paradigms that are faster to train, while not compromising the accuracy of predictions.

