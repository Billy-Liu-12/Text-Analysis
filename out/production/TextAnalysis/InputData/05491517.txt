An Approximation Algorithm for Privacy  Preservation of Associative Classification

Abstract-Privacy is one of the most important issues when the  data are to be processed. Typically, given a dataset and a data processing goal, the privacy can be guaranteed by the pre- specified standard by applying privacy data-transformation algorithms. Furthermore, the utility of the dataset must be considered while the transformation takes place. Such data transformation problem such that a privacy standard must be met and the utility must be optimized is an NP-hard problem. In this paper, we propose an approximation algorithm for the data transformation problem. The focused data processing addressed in this paper is classification using association rule, or associative classification. The proposed algorithm can transform the given datasets with O(k log k)-approximation utility comparing with the optimal solutions. The experiment results show that the algorithm can work effectively comparing with the optimal algorithm and the other heuristic algorithm. Also, the proposed algorithm is very efficient.



I. INTRODUCTION  Current IT business situation has shifted from product selling to service providing e.g. organizations instead of analysis the accumulated data by themselves, they tend to outsource such task to another data analysis service agency.

These service-oriented approaches can result in a better performance of the organization since they can focus on their specialties.

TABLE I A RELEASED DATASET  Postal Code Age Sex Disease 50211 1-25 Female Fever 50211 1-25 Female  Fever 50202 26-50 Male Flu 50202 26-50 Male Flu 50200 26-50 Male Cancer    One of the requirements for service-oriented approaches is  that the data are to be released from one organization to another. Therefore, the privacy issue should not be ignored.

Typically, identifiers such as ID or name of the individuals in the data should be removed or converted. However, the released data can still be ?linked? to other available data. For example, the dataset in Table I might be released from a hospital to a data analysis agent in order to build a classification model. Considering the dataset alone, one could misjudge that the privacy of the individuals in such dataset has  been preserved. However, if there is another dataset which is released publicly for voting purpose as shown in Table II, when an adversary wants to find the private information about ?Somchai? who lives in an area with postal code ?50200?, and his age is about 50 years-old, this adversary could link the two datasets together using postal code and age attributes.

Consequently the medical condition of ?Somchai? is disclosed.

TABLE II A PUBLIC DATASET  Name Postal Code Age Sex Manee 50211 19 Female Wanthong 50211 24 Female Tawan 50202 32 Male Sutee 50202 41 Male Somchai 50200 50 Male    k-Anonymity [1] is one of the most well-known privacy  models in which a dataset is said to satisfy the anonymity, if for every tuple in the dataset, there are other k-1 tuples which are in-distinguishable from given tuple in all ?linkable?, or quasi-identifier attributes. If a dataset does not satisfy the k- Anonymity condition, a data transformation algorithm will be applied until the condition is met. For example, we can suppress the dataset in Table I into a 2-Anonymity by transforming the postal codes to a * symbol as shown in Table III.

TABLE III A RELEASED DATASET  Postal Code Age Sex Disease * 1-25 Female Fever * 1-25 Female  Fever * 26-50 Male Flu * 26-50 Male Flu * 26-50 Male Cancer   However, the data utility of such transformed datasets needs  to be considered as well. The datasets should have its utility for the designate data processing which has been designed at the first place. In our running example, the transformed dataset should be able to serve the classification purpose.

This work was supported by National Electronics and Computer Technology Center (NECTEC), Thailand.

Unfortunately, the data transformation problem for the privacy preservation has been proven as an NP-hard problem [2]. Consequently, there are several heuristic algorithms proposed [3-5]. Such algorithms are generally different in terms of data processing purposes or characteristics of the given datasets which affects the transformation.

In this paper, we propose an approximation algorithm for the data transformation problem. The focused data processing addressed in this paper is classification using association rule, or associative classification. It means that the optimal transformed datasets for such problem should serve the associative classification effectively given the privacy condition. Our proposed algorithm can transform the given datasets with O(k log k)-approximation factor to the optimal algorithm. We also present the experiment results in term of the effectiveness and the efficiency issues comparing the proposed algorithm with the optimal algorithm and a proven heuristic algorithm.

The organization of this paper is as follows. Section II presents the formal definition of the data transformation problem. The proposed approximation algorithm for such the problem is presented in Section III. Our work is validated in terms of data utility and efficiency in Section IV. Finally, we present the conclusion in Section V.



II. PROBLEM DEFINITION  In this section, the basic notations of the problem and problem definition are presented.

Definition 1 (Dataset). Let a dataset D be a collection of tuples defined on a schema A, D = {d1, d2, ? , dn}. For each attribute Aj  ? A, its domain is denoted as dom(Aj). For each di ? D, di(A) = (di(A1),  di(A2), ?, di(Ak)), denoted as (di1, di2, ?, dik}. Note here that tuples in a table is not necessary to be unique.

Let C be a set of class labels, such that C = {c1, c2, ?, co}.

The class label of a tuple di is denoted as di.Class.

Definition 2 (Associative Classification). A literal p is a pair, consisting of an attribute Aj and a value v in dom(Aj). A tuple di will satisfy the literal p(Aj, v) if and only if dij = v.

Let a rule rl be: p?cm, where p is a literal and cm is a class label. The left hand side (LHS) of the rule rl is the conjunction (AND-clause) of the literals, denoted as rl.LHS. The right and side (RHS) of the rule rl is a class label, denoted as rl.RHS.

A tuple di satisfies the classification rule rl if and only if it satisfies all literals in rl.LHS, and has a class label cm as rl.RHS.

A tuple di which satisfies the classification rule rl is a called supporting tuple of rl. The support of the rule rl, denoted as sup(rl), is the ratio between the number of supporting tuples of rl and the total number of the tuples. The confidence of the rule rl, denoted as conf(rl), is the ratio between sup(rl) and the total number of tuples which satisfy all literals in LHS of the rl.

Given a dataset D, a set of class labels C, a minimal support  threshold (minsup), and a minimal confidence threshold (minconf), a set of classification rules R={r1, r2, ?, rq} can be derived.

Definition 3 (Quasi-Identifier). A quasi-identifier of the dataset D, denoted as QD, is the minimal subset of the attributes A that can re-identify the tuples in D by linking with external data.

Definition 4 (k-Anonymity). A dataset D with a schema A and a quasi-identifier QD satisfies k-Anonymity if and only if each tuple di ? D there exist k-1 other tuples in D such that dij = di1j = di2j = ? = dik-1j, for all Aj ? QD.

Definition 5 (Generalization). Let a domain dom*(Aj) = {P1, P2, ... , Pg} be a generalization of the domain dom(Aj) of an attribute Aj where ?Pjt = dom(Aj) and Pjt ? Pjt?, for jt ? jt?. For a value v in the dom(Aj), its generalized value Pjt in the generalized domain dom*(Aj) is denoted as ?dom*(Aj)(v).

Let ?G be a partial order domains, dom(Aj) ?G dom*(Aj) if and only if dom*(Aj) is a generalization of dom(Aj).

For a set of attributes A?, A? ? A, let dom*(A?) be a generalization of a domain dom(A?). A dataset D can be generalized to D* by replacing the values of di(A?) with generalized value ?dom*(A?)(di(A?)) to get a new tuple di*. The tuple di* is defined as a generalization of the tuple di.

For an attribute, the set of its generalization domains forms a hierarchy. Typically, we can derive hierarchies from the priori knowledge of the given data. An example of such hierarchies from a postal code is shown in Figure 1.

Figure 1. An example of postal code hierarchy.

Definition 6 (k-Anonymization). k-Anonymization is transformation of D into D? where D? is a generalization of D which satisfies the k-Anonymity property.

After the basic definitions are given, we present the problem of privacy preservation for associative classification as follows.

Problem Statement. Given a dataset D with a set of class label C, a quasi-identifier QD, a k value, a minsup, and a minconf for associative classification, find D? by anonymization such that D? satisfies k-Anonyity perperty, and the impact on the CFCM data utility [6] (defined in Definition 7) is minimized.

Definition 7 (CFCM). The frequency-based metric CFCM is defined as follows.

Where each fp is a frequency-pair of (p, cm) such that p is a literal on the attribute in the quasi-identifier QD, cm is a class label in which the support of the rule p?cm in D is no less than the minsup threshold.



III. PROPOSED APPROXIMATION ALGORITHM After the dataset transformation problem in the context of  associative classification is defined. In this section, we firstly, present the relation between an optimization problem on counting-based anonymization [2, 7] and the associative classification anonymization. Then, the O(k log k)-factor approximation algorithm is presented.

A. Counting-based and Associative Classification Anonymizations Relationship  Definition 8 (COUNT). Let Pi be a partition of data tuples resulting from an anonymization on a dataset D. COUNT(Pi) is the total number of the data values in Pi that must be replaced by a * in order for all tuples in D to be identical exclusively in each partition.

Note that from now on we will refer the transformation problem having the COUNT metric as the optimization goal as the counting-based anonymization.

Definition 9 (Optimal Solution). Let OPT(D) be a value of an optimal solution of our focused problem, i.e. the minimum numbers of * that must replace the data values in supporting tuples of FP in each Pi to achieve k-Anonymity. Subsequently, let CFCM(Pi) be the total number of the data values in the supporting tuples of FP in each Pi that must be replaced by a * in order for all tuples in D to be identical exclusively in each partition.

We can see that OPT(D) is the partitioning that results in minimal CFCM(D) among all possible partitioning. Also, given ?* as an optimal partitioning considering the CFCM utility metric, ? .

Lemma 1.  ? . . ,  where the minimum of the last term is considered from all the partitioning of the counting-based anonymity.

Proof. For each partition Pi in a dataset D, .  The rationale behind this is the number of * counted as a penalty in CFCM metric is at most the total numbers of them. When considering all the partition in ?*, it can be seen that ? ? , or  ? . Subsequently, we can see that the optimal solution of the associative classification anonymization problem on the counting-based metric is bounded by the optimal solution of the counting-based problem, or ? . . .

From Lemma 1, it can be seen that algorithms which can generate the optimal solution to the counting-based problem, can always generate the optimal solution for our focused problem. Furthermore, the approximation algorithm with ?- approximation to the counting-based problem will also generate the same ?-approximation for our problem.

B. Proposed Algorithm  We propose an approximation algorithm which can guarantee the upper bound of the solution with O(k log k) approximation factor. Such algorithm is based on the approximation algorithm for the set cover problem [8].

The proposed algorithm is presented in Figure 2, where the function d is a mapping from the given partition c to its maximum value-difference (in quasi-identifier attributes) between a pair of tuples.

Let ? be an empty partition.

Let D* be an empty dataset having schema and class  label the same as D.

Build C as a collection of all subset of D, for all c ?  C, k ? |c|  ? (2k - 1).

While D* ? D, For each c ? C, compute: |   |.

Select a c with the least cover.

D* = D* ? c.

? = ? ? {c}.

End While.

Let ?*=?.

Do,  Determine a pair of ci and cj ? ?* such that there exists a tuple d ? ci ? cj.

If |ci| or |cj| ? k , Remove the tuple d from the larger  set between |ci| and |cj|.

Else Replace ci and cj in ?* with ci ? cj.

While ? ? ?*.

For each c ? ?*, Insert the minimum number of * such that all tuples in c are identical.

End For.

Figure 2. Proposed approximation algorithm.

The proposed algorithm can be considered as a two-phase algorithm, i.e. partitioning phase and reduction phase. The first phase, partitioning, starts from the 1st line to the 10th line.

The rest is the second phase. The partitioning phase computes D* containing data tuples from the dataset D covered by the partition?. When the D* contains the same set of tuples as D, we obtain the partition which its subsets have [k, 2k-1]-sized cardinality. All the tuples will be contained in at least one subset. The reduction phase finds all the partitions which are    intersected. Thus, the intersection tuples are removed, if the size of the intersecting subsets are larger than k. Otherwise, the subsets are merged and the reduction is repeated until there is no intersection. Finally, a minimum number of data values in each partition will be replaced by * to achieve k-Anonymity.

The algorithm can achieve 3k(1+ln 2k)-approximation factor with regard to the optimal solution. The complexity of the first phase is O(n2k), while the second phase complexity is O(n3). Thus the computational complexity is dominated by the first phase, i.e. O(n2k). As stated in [9], k values are traditionally set at 3-4 in practices. Therefore, the algorithm can be efficient in practice.



IV. EXPERIMENT RESULTS  After we propose an approximation algorithm, in this section, we conduct the experiments to evaluate its effectiveness and efficiency. The effectiveness of the proposed algorithm is validated by the CFCM metric weighted to [0, 1]- range. For the efficiency, the execution time of the proposed algorithm is evaluated. Note that the results reported in all experiments are five-time-average results.

We evaluate our proposed work by using the ?breast? dataset from UCI repository. The dataset is pre-processed by removing the tuples with unknown values, and discretizing continuous attributes. Also, the identifier-number attribute is removed, resulted in 9 attributes of 683 tuples.

In our experiments, the associative classification approach proposed in [10] is applied. The approach starts by discovery a set of rules satisfying the pre-specified minsup and minconf thresholds from the training dataset using Apriori-based algorithm. Subsequently, the order between the rules will be determined. Generally, a rule will have the higher order, if it has higher confidence comparing with the other rules. If two rules have the same confidence, the rule with higher support will have the higher order. If the confidence and the support of two rules are both equal, the rule which is generated earlier will have the higher order. Given a data tuple without the class label, the rule-based associative classifier will classify the tuple using the highest-order rule which the tuple satisfies its LHS. The minsup and minconf is set at 30% and 50% respectively in these experiments.

The proposed approximation algorithm is compared with the optimal algorithm and a heuristic algorithm named ?Minimum Classification Correction Rate Transformation? (MCCRT) [5].

In brief, the optimal algorithm generates the set of all possible anonymity datasets from the given dataset.

Subsequently, it determines whether the transformed dataset satisfies the pre-specified k-Anonymity. For each k- Anonymity dataset, its CFCM is computed. The transformed dataset with minimum cost is selected as the output of the algorithm.

The MCCRT algorithm begins with sorting all quasi- identifier attributes using their classification-accuracy ascendingly. After the attributes are sorted as a sequence, the  algorithm selects the first attribute to start the transformation.

The transformation is performed in depth-first-search manner, i.e. it selects an attribute, and then transforms the dataset. If the dataset cannot satisfy the k-Anonymity by such attribute, the algorithm will select the next attribute from the sequence.

The complexity of the MCCRT algorithm is O(n log n), where n is the number of tuples in the dataset.

The experiments are conducted on a 2.00 GHz Intel Core 2 Duo PC with 3 gigabytes main memory running Mac OS X.

Our approximation algorithm and the two compared algorithms are implemented using Java SE 6 based on Weka Data Mining Software.

A. Effectiveness  In this section, we investigate the effectiveness in term of CFCM metric, i.e. how well the approximation algorithm damages the data utility for associative classification. The metric will be investigated when the parameters of the problem, i.e. k-value and the size of quasi-identifier (QD) has varied. When the size of quasi-identifier is varied, we fix the k value at 4. Meanwhile, the size of the quasi-identifier is set at maximum, when the k value is varied.

Figure 3. CFCM on the breast dataset when QD is varied.

Figure 4. CFCM on the breast dataset when k is varied.

0.0  0.2  0.4  0.6  0.8  1.0  1 2 3 4 5 6 7 8 9  C FC  M  Quasi-identifier Size  Approximation Optimal MCCRT   0.2  0.4  0.6  0.8   2 4 6 8 10 25 75 125 175 225 275 340  C FC  M  k  Approximation  Optimal  MCCRT    The performance of the proposed algorithm comparing with the other two algorithms when the size of quasi-identifier and the k value is varied is shown in Figure 3 and 4 respectively.

In Figure 3, it can be seen that all the three algorithms, i.e.

proposed approximation algorithm, optimal algorithm, and the MCCRT algorithm, generate the transformed datasets with almost the same CFCM when the size of quasi-identifier is varied. From Figure 4, we can see that the performance in term of CFCM of the approximation algorithm is almost the same as the optimal algorithm particularly when k value is low (? 25). The rationale behind this is the approximation factor which contains the k value. By the way, all the three algorithms generate the dataset with poor data utility when the k value is increased. These results are expectable since the algorithms are given the very strict optimization goal.

However, such high k values are rather not typically applied in practices as mentioned before. Note that it is also slightly better than the heuristic algorithm, MCCRT. We will investigate the efficiency of both algorithms further in subsequent section.

B. Efficiency  The efficiency in term of execution time of the proposed algorithm is evaluated in this section. More specifically, we investigate the efficiency of the algorithm when the size of the datasets is varied. We fix the k value at 4, while, the size of the quasi-identifier is set at maximum.

Figure 5. Execution time when |D| is varied.

From Figure 5, we can see that the execution time of the  proposed algorithm is significantly less than the execution of the optimal algorithm. However, it is still less efficient than the compared heuristic algorithm. However, such gap could be a trade-off in term of effectiveness in other cases. Since the heuristic algorithm can not guarantee the upper bound of the CFCM metric.



V. CONCLUSION  In this paper, an approximation data-transformation algorithm for privacy preservation in the context of associative classification has been proposed.  We have shown that the algorithm can achieve O(k log k) approximation factor in which when the k value is not high, such algorithm can perform almost as effective as the optimal algorithm. Also, the proposed algorithm is efficient as it can be executed much efficient than the optimal algorithm and almost as efficient as the heuristic algorithm.

In our future work, we will focus on extend the algorithm to work on the other privacy models which are based on the k- Anonymity e.g. t-closeness [11], which aims to maintain the distribution of the given dataset to provide privacy protection against particular attacks. Also, the algorithm will be improved in order to cope with ?on-line? environment where the data can be inserted at any time.

