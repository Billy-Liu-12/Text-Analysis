An Architectural Framework for Web Information

Abstract As the popularity of WWW explodes, a massive  amount of data is gathered by Web servers in the form of Web  access logs which are rich source of information for  understanding the Web users surfing behavior. Web Usage  Mining is an application of data mining algorithms to Web access  logs to find trends and regularities in Web users traversal  pattern. Web page prediction technique is an important research  area in web technologies. Mining is useful for web path traversal  pattern from web logs. Web traversal pattern mining discovers  most of the users access patterns from web logs. This  information can provide the routing suggestions for web users  such that suitable actions can be adopted. However, the web data  will grow speedily in the short time, and some of the web data  may be out of date. The user behaviors may change when old web  data in web logs is replaced by new data. Therefore, we must re-  discover the user behavior from the updated web logs but, it is  very time-consuming. In this work we present efficient    algorithms for web page prediction from large web logs visited by  a user. We assign a significant weight to each page based on time  spent by user on each page and visiting frequency on each page.

Keywords- Weighted Association Rule, Web path traversal, Web  usage mining.



I.  INTRODUCTION  It is not overstated to say the World Wide Web is the most  excited impacts to the human society in the last 15 years. Web  service providers want to find the way to predict the users  behaviors and personalize information to reduce the traffic  load. Web Usage Mining [1, 2, 3, 5, 6, 9, 12, 13] is the  automatic discovery of user access patterns from Web servers.

Organizations collect large volumes of data in their daily  operations, generated automatically by Web servers that are  collected in Web access log files.

Web usage mining involves the automatic detection of user  access patterns on one or more web servers. It is an application  of data mining algorithms to web access logs to find the trends  and regularities in web users navigation patterns.

There are many kinds of data that can be used in web  mining and can be classified into following five types [7].

Content of Web Page.

Intra-Page Structure of Web Page.

Inter-Page Structure of Web Page.

Usage Data.

User Profile.

Web mining can be divided into three research fields, i.e., web  content mining, web structure mining, and web usage mining.

Web usage mining is the application of established data  mining techniques to analyze Web site usage. That data will  be useful for a user to predict which Web pages will be  clicked based on previous behavior. In this paper we focus on  weighted association-mining method, which has been  successfully applied in the pages recommendation system that  has not been explored in previous studies because Weighted  Association Rule mining assigned the different weights to  each web page and improves the Association Rule Mining  (ARM) [23].

Cai et al. [10] and Tao et al. [11] proposed the schemes to  assign different weights to each web page to reflect their  importance but both models assume a fixed weight assignment    for each web page for all session in context of web usage  mining and page recommendation systems a page might have  different importance in different session.

In this paper, we propose a Page Weight-like algorithm for  correct web page prediction. Some of the existing systems  used for web traversal based on his or her navigational  behavior on the web. The proposed system will use visiting  frequency of a page, time spent on a page to assign a  quantitative weight to each page for a user. The instinct of this  approach is that the time spent on pages [4] and visiting  frequency are biasing factors to show the interest on a page.

The other systems give user recommendations related to a  navigation session or the user profile stored in the system.

Proposed system can improve the quality of web traversal  system.



II. RELATED WORK  Mobasher et al. [3] have presented WEBMINER, a new web  mining techniques to find out useful information from Web  server access logs. They offered transactions model for  various web mining such as discovery of association rules and  sequential pattern.

Spiliopoulou and Faulstich [14] determine fascinating  978-1-4244-6653-5/10/$26.00 2010 IEEE   01, 2010, India   web navigation patterns. In this approach, individual routing  paths are collected into an aggregated tree formation.

Uninteresting patterns are pruned and only patterns having the  desired characteristics are taken.

Chen et al. [15] projected two effective algorithms for  determining web traversal paths. FS (full-scan) solved  disagreement between traversal pattern and association rules  and SS (selective-scan) is able to avoid database scans in some  passes. But either model does not reflect the semantic impact  of different sequences except the statistical correlation of the  sequences.

H. Yao et al. [16] proposed a foundational approach to  mining item set utilities from databases. This approach allows  user preferences of item set as subjective values. The objective  value of an item is defined according to the information stored  in a transaction i.e. the quantity of the item sold in the    transaction.

From very large logs, Z. Chen et al. [17] proposed two  effective algorithms for finding maximal forward references  longest sequences of Web pages visited by a user without  revisiting some previously visited page in the sequence, and  their performance is relatively analyzed.

An efficient web traversal pattern mining algorithm based  on suffix array given by T. Jing et al. [18]. Essentially, a Web  access pattern is a sequential pattern in a large set of pieces of  Web logs, which is pursued frequently by users. Although  some attempts have been made to mine traversal patterns from  Web log, most of the research efforts try to employ techniques  of sequential pattern mining, which is based on generate-and-  test paradigm, involving multi scan of the entire dataset. They  present a novel approach based on suffix array for frequent  reference path generation. This algorithm has lower time and  space complexity compared with traditional approaches such  as Apriori. This algorithm is incremental in nature, involving  only one scan of the whole data set.

In [19] Yen et al. presented the modified  incremental  data mining algorithm for discovering web traversal patterns  when the user sequences are inserted into and deleted from  original database. This algorithm uses lattice structure to keep  the previous mining results such that just new candidate  sequences need to be computed. Hence, the web traversal  pattern can be obtained rapidly when the traversal sequence  database is updated. But it is unsuccessful when web site  structure is changed.

Zhou et al. [20] proposed high utility path traversal  pattern mining, which introduces the concept of utility into  path traversal pattern mining model. They explored a Two-  Phase algorithm that can discover high utility traversal paths  efficiently when was applied on a real-world Weblog  database.

A utility-based algorithm for web path traversal was  improved by C. F. Ahmed et al. [21]. They used a pattern  growth sequential mining to prune a huge number of  candidates. It effectively divides the search space by small  projected databases recursively using the divide and conquers  technique. Therefore, it saves several scanning of the whole  database which is required by the exiting algorithm.

All existing models recommend Web Path Traversal, but    no specific mechanism is developed to identify the specific  user and further recommending the Web Path based on  different users who have visited previously. The identified  limitations of such systems are as follows:  User identification based on IP Address  Recognition of Web Path Traversal based on user

III. PRELIMINARIES  The mathematical background required to develop and  evaluate the performance of proposed approach is explained in  the following section. Here we will discuss some preliminaries  such as Page Ranking and Weighted Association Rule.

A. Page Ranking  Page Rank [22] is a probability distribution used to represent  the likelihood that a person randomly clicking on links will  arrive at any particular page. Page Rank can be calculated for  collections of documents of any size. A PageRank of 0.5  means there are 50% chances that a person clicking on a  random link will be directed to the document. Assume a web  site of four pages: u1, u2, u3, u4. The initial approximation of  PageRank would be evenly divided between these four pages  so each document would begin with an estimated PageRank of  0.25.

If pages u2, u3, and u4 each only links to u1, they would  each confer 0.25 PageRank to u1 (PR(u1)) and given by (1).

PR(u1) = PR(u2) + PR(u3) + PR(u4)          (1)    Again, suppose page u2 also has a link to page u3, and page  u4 has links to all three pages. The value of the link-votes is  divided among all the outbound links on a page. Thus, page u  gives a vote worth 0.125 to page u1 and a vote worth 0.125 to  page u3. Only one third of u4s PageRank is counted for u1s  PageRank. In other words, the PageRank conferred by an  outbound link L() is equal to the documents own PageRank  score divided by the normalized number of outbound links.

In the general, the PageRank value for any page u can be  expressed by (2).

PR?u? = ? PR?v?L?v?

??B?

?2?

Where Bu is the set of all pages linking to page u and L(v)  is number  of links from page v.

The PageRank theory holds that even an imaginary surfer  who is randomly clicking on links will eventually stop  clicking. The probability, at any step, that the person will  continue is a damping factor d and it is generally assumed that  the value of damping factor will be set around 0.85 [8]. When  calculating PageRank, pages with no outbound links are   01, 2010, India   assumed to link out to all other pages in the collection. Their  PageRank scores are therefore, divided evenly among all other  pages. then page rank is defined  in (3).

PR(pi) = (1- d)/N  + d ?  ???M???

PR????

L????  (3)    where p1, p2pN are the pages and  M(pi) is the set of pages  that link to pi, L(pj) is the number of outbound links on page  pj, and N is the total number of pages  B. Weighted Association Rule  Weighted association rule is useful in some sense. For  example, the product, which has higher revenue margin,  should be paid more attention. Weighted Association Rule  (WAR) mining allows different weights to be assigned to  different items, and is a possible approach to improving the  ARM model in the web personalization process.

Greater weights are given to more important items, when  discover important but less frequent items. However, existing  models assume a fixed weight for each item, while in the  context of web usage mining a page might have different  importance in different sessions.

Given the transformation of user transactions into m -  dimensional space as vectors of weights of web pages, t=< (p1  ,w1), (p2 ,w2 ),...,(pm ,wm ) , where, the weight wi associated to  page pi is a non-negative real number to reflect the importance  of page pi. Item weight is a value attached to an item (page)    representing its significance. In this paper weight of page pi is  denoted as w(pi).



IV. THE  PROPOSED APPROACH  In the proposed approach, weight system exist in the  server side and all the information that are required to  calculate the weight of a web page can be derivative from  websites Web logs. We presume that web logs are  preprocessed and users session is identified. Since this  recommendation system is based on user navigation behavior,  so that the weight for each web page could be calculated based  on users previous visit to that page. When a user comes, the  system will first retrieve the users interest from the database.

If the user is new, the system will give a registration option for  the registration for that site. If the user is new, the system will  give an option for the registration for that web site. After the  registration whenever user visits first time there will be no  option for recommendation path traversal. The user can visit  on any page just by clicking on link found on that page and the  system will calculate the weight for each page based on users  navigation behavior. Now according to weight association rule  greater weight indicates the more interest on that page. The  proposed system will recommend web path traversal for that  web site based on weight associated with each web page.

Let U= {u1, u2 un} denote the set of web pages accessed  by a user and each of them is distinctively recognized by its  related URL. The weight can be calculated in number of ways.

The primary sources of data are server access logs.

The proposed approach consists of two algorithms  designed for finding Web path Traversal of Web pages visited  by a user.

A. FREQUENY BASED PAGE WIGHT ALGORITHM  The Frequency Based Page Weight (FPW) algorithm,  called FPW, is based on Visiting Frequency of a Web page.

The Visiting Frequency of a page u is the number of times that  a page visited after page v. There is an important feature that  can never be neglected is to calculate the Visiting Frequency  of a web page is the PageRank of that page. It is obvious that a  page with large in-degree has more probability to be visited  than a page with small one. The frequency weight (FW) is  defined in (4).

FW (u) = N????? ?? V???? ?? ? ???????T???? ?????? ?? ????? ?? ??? ?????  x PR (u)    (4)    Where PR represents the page rank of a particular page  and calculated with the help of (3). This algorithm will use (4)  for the calculation of weight of each web page and that weight  of a page will be equal to the frequency weight given in (5).

W(u) = FW(u)   (5)    The algorithm FPW is described as follows:                                B. FREQUENY AND TIME SPENT BASED PAGE WIGHT  ALGORITHM  The Frequency and Time Spent based Page Weight  algorithm (FTPW) is based on the Visiting Frequency and  Time Spent on a Web page.

Time spent on a page replicates the relative consequence  of each page, because a user generally spend more time on a  useful page and quickly skip to other page. The transfer rate  and web page size are two important factors used to calculate  the real time spent on a page. If we assume a steady transfer  rate of acquiring information from pages for a user, the time  Algorithm: FPW  Input: Web traversal path database.

Output: Weight for each page.

1 Calculate PageRank for each page (PRi) using (3)  2 Initially Set W(Pi)=0    3 Check the user is registered or not, if YES then  4       whether the user is first time visitor, if YES then  5  return W(Pi)  6    else  7      calculate FW(Pi) using (4)  8 SET   W(Pi) = FW(Pi)  9 return W(Pi)   01, 2010, India   spent on a page is inversely proportional to the degree of  information useful to user. The formula to calculate the  weight based on time spent on each page is given in (6).

TW?u? = T??? ????? ?? ? ???????/P??? S??? ????????U?T??? ????? ?? ? ???????/P???

S??? ????                  (6)    The Frequency and Time spent based page Weight  (FTPW) algorithm, uses both visiting frequency and time  spent on a particular page, as biasing factors. Frequency and  Time spent based page Weight can be calculated by the  formula given in (7).

W(u)=FW(u)+TW(u)  (7)    Where FW(u) is the weight of a page based on frequency  which can be computed from (4) and TW(u) is the weight of a  page based on time spent on a page which can be computed  from equation (6)  and finally W(u) is total weight of the page  based on frequency and time spent both.

The Pseudo code of FPW algorithm given as follows:

V. PERFORMANCE EVALUATIONS  The performance of the proposed approach in terms of  various parameters is discussed in this section.

A.  Data Set  We have evaluated the performance of proposed  algorithms by using the synthetic data set for different users to  calculate the weight of each web page. Consider the structure  of a web site consisting of four web pages namely A, B, C and  D and their respective interconnection shown by direct edges  as shown below in Figure 1.

Figure 1: Web Site Structure  The following factors are considered for performance  evaluation.

Outbound links which shows the out degree of nodes for  the graph of Figure1.

Page Rank (PR) shows the respective ranking of web page,  which can be calculated on the basis of the equation (3).

Number of visit shows the visiting frequency of each web  page by user, it can be decided on the basis data received  from web log.

Page Size defines the size of page on the basis of  information content of the web page, which can be  measured in bytes.

Time spent describes the resumption of a particular web  page by user in seconds.

The above parameters used in proposed experimental set  up for the Web Path Traversal, by considering the graph  mentioned in Figure1.

B. Evaluation Method  The attributes considering for the training data set for  each user of a web site is represented in terms of time spent on  each page and frequency. From these data sets we are    calculating the weight for each web page for respective web  site. The proposed approach uses Visiting Frequency and  Time Spent on a Web page as two parameters to measure the  weight of each web page.

To estimate the performance of the proposed two  algorithms i.e. FPW and FTPW, discussed in section IV based  on the above parameters involved in estimation.

C. Experimental Results  The performance of the proposed approach can be  evaluated by comparing the performance of FPW and FTPW  algorithms which differ in number of parameters considered  for experimentation. The comparison is made by taking the  attribute like Visiting Frequency in FPW, and further Visiting  Frequency and Time spent on a web page are clubbed together  in FTPW as another attribute. The experimental setup uses  five users and weights are plotted against various parameters.

Figure 2 shows the plot of Visiting Frequency v/s Weight of a  web page.

Figure 2: Plot between frequency and weight  Algorithm: FTPW  Input: Web traversal path database.

Output: Weight for each page.

1 Calculate PageRank for each page (PRi) using (3)  2 Initially Set W(Pi)=0  3 Check the user is registered or not, if YES then  4       whether the user is first time visitor, if YES then  5  return W(Pi)  6    else  7      calculate FW(Pi) using (4)    8            calculate TW(Pi) using (6)  9   SET   W(Pi) = FW(Pi)+ TW(Pi)  10   return W(Pi)  A  C  B    D   0.05  0.1  0.15  0.2  0 5 10 15 20  w  ei  gh  t  Visiting Frequency  User1  User2  User3  user4  User5   01, 2010, India     Using the weights calculated in Figure  the higher weight for more frequently visited  information in FPW algorithm the different  the scenario described in Figure 1 for all th  plotted in Figure 3.

Figure 3: Recommendation for Web Path Trave  Algorithm    The weight assigned to various pages  Visiting Frequency and Time spent on web  Figure 4.

Figure 4: Plot between (frequency + time sp    The Figure 5 gives the details of recomm  Traversal for different users by FTPW a  weights calculated by considering two para  and time spent in Figure 4 which indicates  for more frequently visited pages and in term  on web pages.

0.02  0.04  0.06  0.08  0.1  0.12    0.14  0.16  0.18  W  ei  gh  t  Web Pages  Us  Us  Us  Us  Us   0.2  0.4  0.6  0.8   1.2  1.4  W  ei  gh  t  FTPW (Frequecy  and  2 which indicate  pages. Using this  traversal paths in  e users have been  rsal based on FPW  by combining the  page is plotted in  ent) and weight  ended Web Path  lgorithm and use  meters frequency  the higher weight  s more time spent                            Figure 5: Recommendation W  Algo  Figure 6 shows the relative  on the synthetic data sets, in w  more efficient than FPW algor  performance of proposed a  increase the complexity of alg  and provide better Web Path Tr        Figure 6: Relative Access    The proposed FTPW algorithm  parameters which otherwise ar  FPW algorithm. A matrix dep  comparison between above two  parameters are performance ce  show that the performance o  increase the number of param  FPW algorithm to FTPW algori  The experimental results d  better and provides a methodo  optimized Web path traversal  past navigation behavior by c  page.

1 2A    cc  es  si  bi  lit  y  Ti  m  e  fo  r  M  or  e  re  qu  ir  ed  In  fo  rm  at  io  n  er1(A->C->D->B)  er2(D->B->A->C)  er3(D->B->C->A)  er4(C->B->A->D)  er5(B->A->D->C)  Time)  User1  User2  User3  User4  User5   0.2  0.4  0.6  0.8   1.2    W  ei  gh  t  Web Pages  eb Path Traversal based on FTPW  rithm    execution for FPW and FTPW  hich we can see that FTPW is  ithm. Hence, it is clear that the  lgorithm increases when we  orithm in terms of parameters  aversal in less time.

ibility time for FPW and FTPW  consists of clubbing of various  e not available in first proposed  icted in the Figure 7 describes  proposed algorithms. Here the  ntric and a comparison results  f the system improves as we  eters i.e. when we move from  thm.

rawn for FTPW algorithms are  logy for effective, efficient and  for various users based on their  omputing weight for each web  3 4 5  User  FTPW  FPW  User1(C->B->A->D)  User2(A->B->C->D)  User3(B->C->A->D)  User4(D->A->C->B)  User5(B->D->A->C)   01, 2010, India   Figure 6: Comparison Matrix

VI.  CONCLUSION & FUTURE WORK      Web Usage Mining have been used in improving Web site  design and marketing decision support, user profiling, and  Web server system performance. Web page prediction  technique is a very important role in web technologies. This  paper proposes efficient algorithms for web path  recommendation based on Weighted Association Rule. Two  factors frequency and time spent were used to decide the web  path traversal. The experimental results show that in the  proposed approach when we increase the number of  parameters for finding the web path the accuracy of the system  is enhanced drastically and FTPW produces more accurate  results than those achieved by FPW.

In the future, we shall improve the Web Path Traversal by  considering the parameter Data Transfer Rate to provide the  accurate Web Path traversal.

