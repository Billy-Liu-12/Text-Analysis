FDC R2R Variation Monitoring for Sensor Level  Diagnosis in Tool Condition Hierarchy

Abstract ? Tool behavior modeling and diagnosis is a big challenge in modern semiconductor fabrication, in particular for the foundry and analog companies with high product-mix and complicated technology nodes. Tool condition monitoring has been practiced by implementing the FDC (Fault Detection and Classification) system and analyzing large amount of real-time equipment data. This paper continues the work of tool condition hierarchy, where the excursions can be detected in one single overall tool indicator and are intuitively drilled down to the level of sensor groups. A R2R (Run-to-Run) variation monitoring technique is developed in order to correlate the tool faults with single sensor and thus completes the diagnostic gap of the hierarchy. The tool condition monitoring then becomes efficient and tool fault diagnosis can be systematically top- down.

Keywords ? FDC; run-to-run variation; SPC; tool condition hierarchy; tool fault diagnosis; recipe grouping; FDC profile synchronization

I.  INTRODUCTION In addition to the R&D advancement, IC makers also have  to invest huge capital in equipment procurement and IT systems implementation to meet with the continuously growing demands. It is therefore very critical to optimize te tool utilization and dynamic control plans. In particular, the ?big data? collected continuously during production are not efficiently analyzed to timely response and adapt to the dynamic changes. Nowadays the common practice for tool condition monitoring is to implement the Fault Detection and Identification (FDC) system. Current FDC practice requires data pre-treatments, including predefining temporal windows and calculating representative statistics, such as the average and variance, for every SVID (Status Variable IDentification) in each of the temporal windows. This often leads to dozens of control charts being monitored to detect the shifts/drifts in the FDC data. Apparently, it is not an efficient way for tool condition monitoring.

In 2002, Wang [1] makes a comprehensive survey of machine maintenance models, which are then categorized in terms of the maintenance policies, such as the age replacement policy and failure limit policy. As can be seen in the survey, maintenance models majorly aim at estimating the expected  life of tools and spare parts for preventive maintenance as well as predicting the unanticipated failure events for corrective maintenance. Most of these methods are model-dependent in terms of process physics or tool characteristics, and thus the maintenance policies are usually limited in certain area with specific data source. For example, the PM system for epitaxial layer growth based on the relation of temperature to the deposited thickness [2], the proportional hazard model for the lithography steppers [3] and the multilevel linear model for chamber matching [4]. However, there are more than hundreds of process steps in current semiconductor manufacturing environments. Moreover, the components inside process tools are of rather different physics and characteristics. Deploying maintenance models and policies and keeping them up-to-date would be very challenging.

Thieullen et al. [5] make a rather comprehensive survey on the tool health indicator and prognosis specifically applied to semiconductor manufacturing process in 2012. The topic can be generally referred to Prognostics and Health Management (PHM) of functioning equipment. As can be seen in their survey, data driven techniques are usually applied based on the data collected from daily operations. Empirical behavior models are thus built to monitor the tool conditions and/or to predict the potential tool faults in the near future. These data- driven techniques share one key feature in common by analyzing historical data from processing equipment and product information in certain operations or process areas.

Development of generic methods/algorithms for the whole fab seems to be impossible, considering the varying operating characteristics, processing physics and even failure modes.

Following the concept of consolidating multiple FDC SVIDs into one single indicator based on GMV (Generalized Moving Variance) to monitor the tool health [6], Blue et al.

[7][8] propose a hierarchical tool condition monitoring scheme to more efficiently detect and diagnose tool faults. Fig. 1 depicts a quick concept of constructing the tool condition hierarchy and diagnosing faults via the hierarchy. The first step to build the hierarchy is to cluster the SVIDs into meaningful grouping scheme. Once the similar sensors are gathered together in one group, the idea of GMV is again used to represent the group condition. PCA (Principal Component Analysis) is employed to generate a representative SVID from each group such that all the representatives can be consolidated into one indicator, i.e. the overall tool condition.

From the diagnostic point of view, the overall tool condition at the bottom is going to provide an overview of tool behavior. The hierarchy enables an intuitive breakdown of the excursion detected in the overall tool condition into the sensor groups based on its theoretical property. However, to make the hierarchy more applicable, the drilldown process should be extended to the sensor level, i.e. in terms of SVIDs [9]. Despite the fact that many univariate control charts already exist as mentioned at the beginning, the diagnosis remains inefficient and nonsystematic, in particular, when one SVID can be summarized into several univariate indicators. In order to close diagnostic gap in the hierarchy, a temporal R2R (Run-to-Run) variation at sensor level is proposed in this paper to replace the conventional summarized indicators.

In the following section we are going to describe in details on the proposed methodology sensor level diagnosis and a case study with real data will be demonstrated.



II. SENSOR LEVEL DIAGNOSIS Tool condition can be evaluated in terms of very different  data sources, such as MES (Manufacturing Execution System), FDC or even wafer metrology measurements. Among these sources, FDC data are collected continuously when wafers are processed inside the equipment and thus shall provide comprehensive information about not only the process but also the tool behavior. Therefore, most IC makers implement FDC systems in order to monitor process or equipment faults. In this research, FDC data also serves as the study vehicle and we are going to develop the sensor level diagnosis upon them.

Firstly we assume there are p sensors installed on one tool and thus p SVIDs, X1, X2, ?, Xp, will be collected when one wafer being processed on the tool. The collected FDC temporal data for wafer k is defined as WT(k):    ? ? ? ? ?  ?  ?  ? ? ? ? ?  ?  ?  =  k pn  k n  k n  k p  kk  k p  kk  k  p  kkk xxx  xxx xxx  n  kWT  XXX  ,2,1,  ,22,21,2  ,12,11,1    )( , (1)  where k jix ,  denotes the collected FDC observation of j th SVID  at ith time stamp for wafer k. The number of observations, i.e.

the sample size, of each SVID for wafer k is nk (i = 1, 2, ?, nk) and is usually not the same from wafer to wafer.

Under the original framework of tool condition hierarchy, the diagnosis of tool faults can be only drilled down until the sensor group level and thus the R2R variation of each sensor is proposed. Before going into the calculation of the R2R variation, there are two critical steps to proceed in advance in order to have a meaningful R2R variation. The two steps: recipe family grouping and FDC profile synchronization, will be introduced in the first two sub-sections followed by the concept of R2R variation.

Fig. 1. A quick catch of the construction and diagnosis flows of tool condition hierarchy.

93 ASMC 2014    A. Recipe Family Grouping FDC temporal profiles can only be compared when they  share regular patterns induced by similar recipe bodies. A recipe body should clearly define the targets (usually referred to set-points) of process states as well as regulate the behavior of tool signals. Consequently recipes are of very different patterns given different products and technologies, and are sometimes fine-tuned according to the run-to-run information or in order to match the tool capability. In high-mix, low- volume production environment, recipe management is a big and critical issue because IC makers have to efficiently setup appropriate recipes for operations and, at the same time, alleviate the impact of changeover. Since recipes are directly related to product designs, the recipe management becomes a confidential issue and is usually under central control in the companies.

From the FDC data perspective, not only the temporal profiles change significantly under different recipes, but also the number of SVIDs does. Some SVIDs collected under one recipe might be removed (or simply not collected) from another. In order to have the fair comparison at the level of FDC temporal profiles, recipe grouping should be done beforehand such that the detected excursion won?t be simply diagnosed as the difference among recipes. In this paper, this step has been done within our industrial partner in terms of the physical design of recipes. At the same time a mathematical/statistical grouping method is under investigation to facilitate the massive monitoring  B. FDC Temporal Profile Synchronization With the FDC data coming from similar recipe bodies, the  comparison among wafer-to-wafer FDC temporal profiles is not yet easy. The main reason is related to the IT infrastructure.

Current tools cannot perfectly handle the FDC data input/output interfacing and the production process at the same time, while the first priority is surely to keep the process running correctly and stably. Also the timestamps between database servers and the tools are not well synchronized [10].

This is causing missing values in FDC data and thus a DCQV (Data Collection Quality Value) is measured as soon as the FDC data of one wafer FDC are collected in order to monitor the data reliability and the process stability. Another reason is related to process characteristics because the process time would vary from one wafer to another based on the process characteristic. For example, the etching process will continue until the stop layer is reached and thus the process time might be different from wafer to wafer.

Given the reasons above, comparison among FDC temporal profiles will suffer fundamental pattern shifting issue such that again the detected excursion might not be meaningful.

Therefore a synchronization of FDC temporal data is needed.

Dynamic Time Wrapping (DTW) [11] is a technique for efficiently finding the alignment among shifted signals and has been used widely in many areas such as gesture recognition, robotics, speech processing and manufacturing.

Considering two temporal series with n and m observations respectively, an n by m cost matrix, typically in terms of Euclidean or Manhattan distance, can be constructed based on  all the possible alignments. An aligning path (can be also referred to a wrapping path) has to be subject to three more constraints: boundary conditions, continuity and monotonicity [12]. By minimizing the overall aligning cost via dynamic programming, the path can be found efficiently.

Fig. 2. An example of aligning (wrapping) path [12].

DTW works very well if only the time shift (on the x-axis) exists between two temporal series. However, in our main problem with FDC temporal profiles, local differences on the y-axis, i.e. the numerical magnitudes, of the series often occur and this causes the DTW algorithm ineffective. For example, two data points may share the same value but fall on different patterns such as one on the rising trend and another on the down slope. DTW might have the chance to align the two points together due to the identical values. Therefore, a modified algorithm, Derivative DTW (DDTW), is proposed [12] to take into account the shape information in terms of the first derivative of the temporal series. The main concept of DDTW is to replace the Euclidean/Manhattan distance in the cost matrix by the square of difference of the first derivatives between two data points.

Based on the characteristics of FDC temporal data, we observed that there are not only time shifts but also measurement changes. Therefore, DDTW is employed to synchronize the FDC data before calculating the R2R variation.

Assuming the temporal series of ith SVID across all wafers from one recipe family, R, are firstly collected from (1) and expressed as SVIDi(R):    ? ? ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ? ? ?  ?  ?  =  ,  ,  ,  ,2 ,2  ,2  ,1 ,1  ,1    )(  in  r in  in  r iii  r iii  i  x x  x  xxx xxx  SVID  r  R , (2)  94 ASMC 2014    where R is the collection of r wafers from the same recipe family and thus contains {WT(1), WT(2), ?, WT(r)}.

After DDTW being applied to (2), we get:    ? ? ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ? ? ?  ?  ?  =  r ininin  r iii  r iii  i  xxx  xxx xxx  SVID  , ,  ,  ,2 ,2  ,2  ,1 ,1  ,1  )(R  (3)  where ),,,max( 21 rnnnn ?= is the unique wafer process length after synchronization. In the following sub-section, the R2R variation will be calculated based on (3).

C. SVID Run-to-Run Variation The concept of R2R variation starts with expanding a group  of FDC temporal profiles of one SVID from a two-dimensional trend chart to a three-dimensional topography by adding the third axis ?wafer ID in processing sequence? as shown in Fig.

3. The topography can thus be viewed as a two-dimensional contour in Fig. 4 as well as the data arrangement in (3).

Fig. 3. Transforming a 2-D wafer-to-wafer FDC temporal profiles of the SVID ?ThrottleValve? into a 3-D topography.

To calculate the R2R variation, two consecutive wafers in the same recipe family are selected, for example, the WT(1) and WT(2) in R, and consequently the first two columns in (3) are used. The variances of all pairs of observations between the two wafers, i.e. ),var( 2,1  ,1 ii xx , ),var(  ,2  ,2 ii xx , ?, and  ),var( 2,  , inin xx are calculated. By taking the average of these n local variances, we get the first R2R variation of SVID i, denoted as:  ? =  = n  j ijijrr xxn  is  ,  ,  1,2 ),var(  1)(  (4)  The idea of R2R variation is to capture the local changes between two consecutive wafers from time to time. From the visualized example in Fig. 4, the first local variance is calculated from the pair of observations of two consecutive wafers at the first second of the process, given the FDC sampling rate is one observation per second. If the process lasts for 327 seconds, there will be 327 local variances from these two wafers. The R2R variation is calculated by taking the average of these local variances.

? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?  Process Tim e for O  ne Run  Wafer Run Sequence  local variance for 1st second  local variance for 2nd second  local variance for 327th second  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?    Fig. 4. The 2-D contour of FDC temporal profiles and the calculation of local variances. The R2R variation is calculated by taking the average of these local variances.

D. SPC on R2R Variation In order to detect the excursion of R2R variations,  Exponentially Weighted Moving Average (EWMA) is employed. EWMA control scheme [13][14] is well-known for process dispersion monitoring [15]. Let Zi,k denote the EWMA statistic of the R2R variation of SVID i of wafer k. Zi,k can be calculated as:  1,  ,2, )1()( ??+= kikrrki ZisZ ?? ,  (5)  where ? (0< ? ? 1) is the smoothing constant.

The steady-state EWMA control limits are defined as:  ? ??? ?  +=  UCL ,, isis L  and ,2 LCL ,, ?  ??? ?  ?= isis L  (11)  where ?s,i and ?s,i are the mean and standard deviation of in- control )(2 ,2 is krr ?s, and L determines the width of the control window. For a standard Shewhart control chart [16] and data following the normal distribution, the average run length (ARL) with 3? is known to be 370.4. Since )(2 ,2 is krr  is not likely to be the normal distribution, we may follow suggestions by [13] to use L=2.492, 2.703, and 2.86 with  95 ASMC 2014    corresponding ?=0.05, 0.1, and 0.2, respectively, for the EWMA control scheme to obtain approximately the same ARL=370.4. In this paper, after some experiments from the actual production data, we set ?=0.05 and L=4 for a lower false alarm rate acceptable to the semiconductor manufacturing practice. The setting of the EWMA control scheme should not be fixed across all tool types and situations and should be adjusted according to the natures of the tool processes, which in turn affect the false alarm rate.



III. EVALUATION OF CASE STUDY The FDC data to be evaluated are collected from an ETCH  tool, which are the same as the second case in [7]. Around 800 wafers of 31 SVIDs from one family of eight GATE recipes are analyzed. The FDC profiles are also synchronized by DDTW firstly. Following the hierarchical analysis in [7], we know there?s a big and obvious abnormal pattern in the overall tool condition as shown in Fig. 5. By looking into the conditions of four sensor groups: RF (11 SVIDs), temperature (3 SVIDs), gas (13 SVIDs) and pressure (4 SVIDs), the abnormal pattern in the overall condition can be directly identified as a fault from the gas group. To save the page in presenting the results of tool condition hierarchy, we simply put the overall tool condition and the gas group condition from here. For more details of the hierarchy, please refer to [7].

(a) Lot_125 Lot_126 Lot_127 Lot_128 Lot_130 Lot_142 Lot_145  Lot_14  Lot_21  Lot_125    (b)  Lot_125 Lot_126 Lot_127 Lot_128 Lot_130 Lot_142 Lot_145    Fig. 5. The simplied result from tool conditon hierarchy: (a) overall ecth condtion; (b) gas group condtion, with EWMA control limits: UCL as green and LCL as dark red if non-negative.

To further classify the root causes at the sensor level in gas group, the proposed R2R variation is calculated for the 13 SVIDs. Fig. 6 firstly visualizes the contours of all 13 SVIDs and provides an overall sketch. As can be seen, except the MFCflow2 (Mass Flow Controller) has no significant pattern, the other 12 SVIDs in gas group exhibit consistent abnormalities in accordance with the phenomenon in Fig. 5.

Fig. 6. A visualized overview for controus of all 13 SVIDs in gas group, where x-axis is the wafer ID and y-axis indicates the process time in one run.

R2R variations for these SVIDs are also calculated and monitored according to the proposed control scheme. In Fig. 7, we only demonstrate the R2R variation of MFCflow1 in contrast with MFCflow2 and others shall be monitored in the same fashion. After applying the EWMA control scheme, the R2R variation chart of MFCflow1 shows very similar pattern to the overall tool condition and gas group condition in Fig. 5(a) while the one of MFCflow2 seems not to account for this main excursion. It is known from MES that this dataset covers a complete PM cycle followed by a CM intervention for fixing the process drift. However, the process drift is not completely fixed until the end of the dataset. The big pattern here in Fig.

5(a) is confirmed to be the period that covers the practiced PM followed by CM intervention when the tool started to collect unusual FDC profiles. It also shows that the tool condition after the CM intervention remains unstable around the upper control limit. Particularly, the mass flow controllers display totally different temporal profiles compared to the wafers processed before/after the abnormal period.

96 ASMC 2014    (a)  (b)  Fig. 7. R2R variations of (a) MFCflow1 and  (b) MFCflow2, respectively.



IV. CONCLUSION AND FUTURE WORK The main contribution of this paper is to extend the  diagnosis of tool condition hierarchy into sensor level by proposing the R2R (Run-to-Run) variation of individual sensor.

Given the fact that monitoring the enormous amount of summarized indicators currently implemented in fab is inefficient and ineffective, the proposed R2R variation is based on the sensor temporal data and tries to capture/detect the variation from profile to profile. To robustly monitor the R2R variation, two preliminary steps have to be done in advance: recipe grouping and temporal profile synchronization, in order to avoid the false detection of excursions due to simply recipe changes or inconsistent data structures. The use-case further validates the effectiveness of R2R variation.

Nevertheless, recipe grouping based on physical definition will contradict against the advantage of ?recipe-independent? hierarchical monitoring scheme. Also data transformation via DTW or DDTW algorithm would surely cause information distortion or loss. It is our continuous goal to look for automatic recipe grouping mechanism with respect to the FDC profiles as well as to investigate the distortion after applying DDTW and improve the synchronization algorithms.

