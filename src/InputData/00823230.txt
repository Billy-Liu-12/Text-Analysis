Learning Capability in Fuzzy Petri Nets?

Abstract  Petri nets (PNs) have been used widely in modeling and analyzing many real applications such as computer, automatic control and management information system etc. The power of PNs comes from its ability to model and analyze the behaviors and states of systems (events) concurrently. Neural networks (?s), on the other hand, were developed to handle and solve many linear and nonlinear complex problems by forming an association (relationship) between its input and output training patterns. It will be advantageous if a learning capability is incorporated into a fuzzy Petri net (FPN) which has the capability of both systems. In this paper, a FPN model which has learning capability is proposed. The purpose of including a learning facility in FPNs is that many parameters of a fuzzy expert system, included in fuzzy production rules (FPRs), once when it has been modeled by a FPN could be tuned. These parameters including membership values, weights (local and global) and certainty factors etc. play important roles in capturing and representing complex domain expert knowledge. By comparing the artificial neural networks (ANN) with FPNs having learning capability, we have the advantages such as a) FPNs provide a transparent modeling and analyzing capability whereas ANN provides a black-box learning and no-analysis capability, b) FPNs representing a fuzzy expert system could be used to analyze the different inference states step-by-step; c) FPNs could tune parameters in a fuzzy expert system so that the overall system performance is improved. To achieve the above goals, we need to solve many problems such as how to model a FPR with a FPN so that parameters to be tuned are mapped onto this FPN, what modifications need to be done in order to make a FPN having a learning capability.

This paper will try to address these problems and issues.

1. Introduction FPN is a variation of traditional PN, which have the ability to model, represent and capture vague, imprecise, uncertain and fuzzy concepts. Many researchers have proposed different FPNs. In [I], the fuzzy neural network modeling the FPN is defined as having 7 tuple, while in [2,3] a high level FPN is defined as having 8-tuple. In these models the PNs have been modified to act like a neural network model which allows the PNs to have learning capability. The problem with these models is that  many complicated fuzzy production rules could not be modeled by FPNs. NN incorporated in these FPNs could not have a general learning capability as used in traditional Backpropagation. In this paper, a FPN model which has learning capability is proposed. The purpose of including a learning facility in FPNs is that many parameters of a fuzzy expert system, included in FPRs, once when it has been modeled by a FPN could be tuned.

The paper is arranged into different sections. In Section 2, different types of fuzzy production rules having parameters such as local weights and certainty factors which could enhance its representation power, are presented. Section 3 will concentrate on the FPNs which could model these production rules while in Section 4 a neural network learning algorithm which could be incorporated in the FPNs is proposed. Section 5 provides an experiment to demonstrate that the NN could be used to tune the parameters in FPNs. Finally a conclusion is given.

2. Fuzzy Production Rule and Its Reasoning Method  FPRs widely used by many researchers can be summarized to have three different forms: a simple FPR whose antecedent part has only one proposition; a conjunctive FPR whose antecedent part has two or more propositions connected by ?AND?; and a disjunctive FPR whose antecedent part has two or more propositions connected by ?LOR?. The consequent of these FPRs are assumed to have only one proposition. In the following paragraphs we will present the last two FPRs with local weights and certainty factors included.

A conjunctive FPR has the form o j R: IF VI is A, AND V, is A, ... AND V, is A, THEN U is B, CF,, h A i A , u , - J A n ,  LWi, LW2,--.9 LW,,  Given Facts : V, is A?,; V, is A?,,..., V, is A?, Conclusion: U is B with a degree of truth T,  where V,,V, ,... ,V, and U are variables; A,,A, ,..., A,, and B are the fuzzy values of the variables VI, V,, ..., Vn and U respectively; LW,, LW,, ..., LW,, are the local weights of each proposition in the antecedent part of the FPR, and h, is the threshold value for the relative degree of similarity between Ai and its given or observed fact Ati.

? This work is supported by the Hong Kong Polytechnic University Central Research Grant G-S724.

0-7803-5731-0/9!2!$10.00 01999 IEEE In-355    Similarly,a disjunctive FPR has the form of R: IF VI is A, OR V, is A, ... ORV, is A, THEN U is B,  CFR, AA)?LN?.,vhh Lw,, Lw2,-.., L w n , Given Facts : VI is A',; V, is A',, ..., V, is A', Conclusion: U is B with a degree of truth T.

When n=l each of these FPRs will be reduced to a simple FPR.

In order to draw a reasonable conclusion, first of all we have to determine the degree of similarities of a set of given facts with their corresponding propositions in the antecedent. A table which tabulates the relative degrees of similarity of all possible given facts with the hzzy set in the antecedent could be used. An example is given in the next paragraph to demonstrate such an approach. Furthermore, we will show how the degree of truth of the consequent is computed.

Written English Results from a Public Examination  Excellent very good  Good Satisfactory  Fair Pass Fail  'Sexcellem  1 .o 0.9 0.7 0.5 0.3 0.1 0.0  Fluent almost fluent quite fluent fairly good quite bad  Bad  Spoken English Results from a Public Examination  1 .O 0.9 0.7 0.4 0.2 0.1  RSnuenl  Fail I 0.0 'able 2: relative degree of similaril tY of  given facts with respect to a fuzzy term fluent  e.g., If X's written English is excellent and X's spoken  English is fluent then X's English is good,  If we are given the fact that Peter's written English is good and his spoken English is almost fluent, it is reasonable to draw the conclusion that Peter's English is good to a degree of truth 0.7 (assumed that LW,=l, LW,=1, CF=l in this case). It is because by the traditional method the antecedent will have a degree of truth 0.7 which is equal to Min(0.7,0.9) and the conclusion will also have a degree of truth 0.7 which is equal to  CF=0.7, h,=0.6,h2=0.5, LW,=0.9, LW,=O.8  Min(0.7,0.9)*CF. The two values 0.7 and 0.9 in Min(O.7, 0.9) are the relative degrees of similarity of the fuzzy term excellent with its given fact good and the hzzy termfluent with its given fact afmostfluent respectively which are obtained from the relative degrees of similarity as shown in tables 1 and 2. The following issues must be addressed when local weight and certainty factor are considered.

1.

2.

How can we make use of the local weight and the certainty factor of a conjunctive and a disjunctive FPR so that a reasonable conclusion can be drawn ?

Is there a general method to compute the degree of truth of the consequent of a FPR by taking the local weight and certainty factor into consideration? One criteria for such a general method is that the traditional method is a limiting case of it.

Let us assume that RSA; is the relative degree of similarity of a hzzy  term Ai in the antecedent of a FPR with its given fact A'i and RSA, 2 kAi for all Ai.

For a conjunctive fuzzy rule, the overall degree of truth of  the antecedent is given by following equation 1 :  The degree of truth T of the consequent is given by: T=RS, * CF  For a disjunctive fuzzy rule, the overall degree of truth of the antecedent is given by equation 2:  The degree of truth T of the consequent for this type of rule is also given by: T=RS,*CF  From the equations 1 and 2, one may notice that the local weights in the antecedent are used to adjust the relative degree of similarity so that they will compensate for any differences among themselves. When LW,, = LW, =...= LW, in either a conjunctive or disjunctive FPR, our method will reduce to the traditional one. Thus, our method generalises the traditional one.

3. Mapping Fuzzy Production Rules into Fuzzy Petri Nets    Fuzzy Petri Nets Many modelling methodologies have been devised  for different systems. Some of them are appropriate to model FPRs. In this paper a generalized fuzzy Petri net structure based on [4] is defined as a 14-tuple:  where P = {pI,p2 ,..., pn} denotes a set of places, T = {tl,t, ,..., t,,,> denotes a set of transitions, P n T = 0. Th ={ AI,&,, ..., As} denotes a set of threshold values. I(0): T+P" is the input (output) function, a mapping from transitions to bags of places. F = { fl, f2,. , . , fr} denotes a set of fuzzy sets. W={LW,, LW,, ..., LW,} denotes a set of local weights of FPRs. C={CFRl, CFw , ..., CF, > denotes a set of certainty factor of the rules. Mc(PxT) is a finite set of arcs which represents the local weights.

Nc(TxP) is a finite set of arcs which represents the certainty factor. f: N+[0,1] is an association function which assigns a certainty factor to an arc. a: P+F is an association function which assigns a fuzzy set to each place, and P:M+[O,l] is an association function which assigns a local weight to an arc. y: P+Th is an association function, a mapping from places to threshold values.

FPN=(P, T, Th, I, 0, F, W, C, M, N,f, a, P, y),  Mapping F u q  Production Rules into Fuzzy Petri Nets Let's take a type 2 rule as an example for illustration.

R: IF VI is A, AND V, is A2 THEN U is B, CFR,  Rule R is changed to the following representation: h,l,A,, LW,, LW,  Y(P,)=Lr Y(Pz)=L P(Pl tl)=LWI, P(pztJ=LW2, a(pl)=f ,, a(p,)=fz ( tokens representing fuzzy sets  of given facts),  The mappings for types 1 and 3 rules could be defined similarly. The Mapping FPRs into FPNs is shown in Figure 1.

(ti pd.=CFR  4. My Approach  In this section we present a learning algorithm in a FPN which is divided into initialization, presenting training examples, the feed forward computation and backward arc adjustment method. The feed forward computation is based on equations 1 and 2 presented in section 2 while the backward weight adjustment involves changing the traditional backpropagation learning algorithm.

Initialization Start with a FPN which represents a set of FPRs in fuzzy expert system, the arcs in FPNs represent the local weight and certainty factors as shown in Figure 1.

Presenting Training Examples Present the network with training examples. For each example presented to FPN, the following sequence of forward and backward computations are performed.

Feed Forward Pass In the FPN, the feed forward pass is same as firing a transition when each of the input places has a token in it.

The firing of a "OR" transition is expressed as:  and for an " AND" transition we have:  where LW,, = max[LWV I 1 < j < J], means the maximum value of local weights (LWs) among all J places which pass into a transition ti, and Out,, = max[Outj 1 1 < j < J] means the maximum firing output values (Out) among all J places which pass into a transition ti.

Backward Weight Adjustment In a FPN incorporated with a NN backpropagation learning method, the error calculated for the local weights (LWs) is not the same as for the certainty factors (CFs).

The adjustments to the arcs in FPN (CFs and LWs) of the network are presented as follows:  A CF,, = q 6, Ou?, else  A CF, = 0 and  where q , Sj and 6,  are the learning-rate parameter, the error rates in the layers j and k respectively.

5. An Experiment  In this experiment a set of FPRs representing the knowledge base of a fuzzy expert system for choosing a computer  m -357    professional is presented. 11 rules are extracted from the system. Two of them are presented as follows: R1 : If X excels in written English (LW=0.9)  and fluent in spoken English (LW=0.8) then X's English is excellent. (CF=0.7)  :If X attends a lot of extra-curricular activities FC?

(LW=0.7) or  X has excellent personal relationship (LW = 1 .O) then X's social skill is good. (CF=0.5)  These 11 rules when mapped into a FPN is shown in Figure 2. The different notations used in the Figure is listed as follows: Notation of the 14 input nodes is presented as follows: PL--Knowledge on Programming Language ( Coding Skill ); SA--Knowledge on Software Application; OS-- Knowledge on Operating System; MT--Knowledge on Machine Type; ECA--Extra-curricular Activities; PR-- Capability of Personal Relationship ; EW--Written English ; EO--Spoken English; CW--Written Chinese; CO-- Spoken Chinese; WE--Working Experience; PE--Public Education; INT--Interview; AT--Aptitude Test; wi-- the synaptic weights between layers; LW,-- the i* local weight of a FPR; CF--the certainty factor of a FPR; Ri-- the i* FPR.

The FPN is trained with a set of 15 records and the training data is shown in Table 4. The expected and the actual results after training the FPN is shown in Table 5.

The final weights (arcs in FPN) are presented in Table 3.

The results in Tables 3 and 5 demonstrate the FPN with  NN learning capability incorporated could be used to tune the local weights and certainty factors. The results are promising as shown in the actual output columns in Table 5 .

I  6. Conclusion In this paper a FPN model is used to model FPRs and a NN learning algorithm is incorporated. The FPN with a learning capability is more advantageous than the traditional ANN as a) FPNs provide a transparent modeling and analyzing capability whereas ANN provides a black-box learning and no-analysis capability; b) FPNs representing a fuzzy expert system could be used to analyze the different inference states step-by-step; c) FPNs could tune parameters in a fuzzy expert system so that the overall system performance is improved. The local weights and certainty factors of FPRs have been used to demonstrate the tuning capability of FPNs.

7. Reference  [l] S.I. Ahson, "Petri net models of fuzzy neural networks," IEEE Trans. On SMC, vo1.25, no.6, pp.

926-932, June 1995.

[2] H. Scarpelli, F. Gomide, and R.R. Yager, "A reasoning algorithm for high level fuzzy Petri nets," IEEE Trans. On Fuzzy Systems, vo1.4, No.3, pp.

[3] H .  Scarpelli, F. Gomide, "A high level fuzzy Petri net approach for discovering potential inconsistencies in fuzzy knowledge bases, " Fuzzy Sets System, vol. 64, pp. 175-193, 1994.

[4] D.S. Yeung and E.C.C. Tsang, "A multilevel wegithed fuzzy reasoning algorithm for expert systems", IEEE Trans. On SMC, Part A:  System and Human, vo1.28, no.2, pp149-158, Mar 1998.

282-294, August 1996.

a b Fig. 1 : Different types c  ,.

b  FPRs Mapping into F P N ~  (a) A simple FPR; :b) A FPR with an "AND' connective; :c) A FPR with an "OR" connective.

