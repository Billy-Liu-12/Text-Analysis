An Associative Classifier Using Weighted Association Rule

Abstract  New classification approach that use association rule mining and classification has become a significant tool for knowledge discovery. An important advantage of these classification systems is that, using Association Rule Mining (ARM) they are able to examine several features at a time.

While other state of art methods like decision tree or na?ve bayes classifiers consider that feature is independent of each other. Many applications can benefit from good classification model. Associative classifiers are especially fit to applications where the model may assist the domain experts in their decisions. There are many domains such as medical, where the maximum accuracy of the model is desired and hence the accuracy of the associative classifiers. In this paper, we propose a new framework (associative classifier) that uses weighted association rule mining (WARM). In any prediction model all attributes do not have same importance in predicting the class label. So different weights can be assigned to different attributes according to their predicting capability. We propose a theoretical model to introduce new associative classifier that takes advantage of weighted association rule mining. The model can be applied in any domain to improve the prediction accuracy.

Keywords: Associative Classifiers, Weighted Association Rule Mining, Association Rule Mining, Classifiers, Prediction accuracy  1. Introduction.

Applying the association rule mining for classification, improves the accuracy of the classification system. It integrates association rule mining problem into classification problem [9].

The traditional ARM was designed considering that items have same importance and in the database simply their presence or absence is mentioned. In several problem domains it does not make sense to assign equal importance to all the items particularly in predictive modeling system  where attributes have different prediction capability. For example in medical domain predicting the probability of heart disease, the attribute prior-stroke is having more impact than the attribute BMI (Body Mass Index). Other example in the context of stock market prices, some stocks have much higher value than others and might appreciate a lot more than other stocks in a comparable time period. In the supermarket context, some items like jewellery, designer clothes, etc. are of much higher value than trivia like bubblegum or candy.

Rules involving jewellery may have less support than those involving candy but are much more significant in terms of the revenue (and consequently profit) earned by the store.

Recent studies in the data mining community proposed the concept of weighted association rule mining to deal with the case where items are given weights to reflect their importance.

More weights can be assigned to these important attributes and according to their importance less weight to the other attributes. Assigning different weights to different attribute and using weighted association rule mining; the selection of significant item sets is steered to those item sets having relationship to high weight item [7]. Hence integrating WARM with classifiers may improve the prediction accuracy as the accuracy of the model depends on how strong rules are used for classification.

This paper proposes a new Weighted Associative Classifier (WAC) that generates classification rules using weighted support and Confidence framework. The na?ve approach is generating strong rules instead of weak irrelevant rules. We discussed the importance of weighted Association rule in classification problem.

In section 2, we have discussed the concept of association rule mining and weighted associative classifiers. In section 3 we described some new formulae and given new definitions for the same. In section 4, Downward closure properties for weighted version of association rule mining is being discussed. In section 5, conclusion and future work of this paper is given.

2.  Related Work.

2.1 Association Rule Mining.

Let I ={i1, i2, ? , in} be a set of n distinct literals called items.

D is a set of variable length transactions over I. Each transaction contains a set of items i1, i2, ? , ik ? I. A transaction has an associated unique identifier called TID. An association rule is an implication of the form A? B (or written as A ? B), where A, B ? I , and A ? B=?. A is called the antecedent of the rule and B is called the consequent of the rule. The rule X ? Y has a support s in the transaction set D if s% of the transactions in D contain X?Y. In other words, the support of the rule is the probability that X and Y hold together among all the possible presented cases. It is said that the rule X? Y holds in the transaction set D with confidence c if c% of transactions in D that contain X also contain Y. In other words, the confidence of the rule is the conditional probability that the consequent Y is true under the condition of the antecedent X. The problem of discovering all association rules from a set of transactions D consists of generating the rules that have a support and confidence greater than given thresholds. These rules are called strong rules, and the framework is known as the support confidence framework for association rule mining [14].

2.1.1 Weighted Association Rule Mining.  A weighted association rule (WAR) is an implication X?Y where X and Y are two weighted items. A pair (ij, wj) is called a weighted item where ij?I and wj?W is the weight associated with the item ij. A transaction is a set of weighted items where 0<wj<=1. Weight is used to show the importance of the item.

In weighted association rule mining problem each item is allowed to have a weight. The goal is to steer the mining process to those significant relationships involving items with significant weights rather than being flooded in the combinatorial explosion of insignificant relationships [7].

Wei Wang et al. proposed an efficient mining methodology for Weighted Association Rules (WAR) [10]. The authors have extended the traditional association rule-mining problem by allowing weights to be associated with each item to reflect the importance. In this paper WAR uses a two-fold approach where the frequent item sets are generated using standard association rule without considering the weight.

Post processing is then applied in the frequent item sets during rule generation. This paper focuses on how weighted association rule can be generated using weighting factors of the items included in generated frequent item sets. This method has been categorized as technique of post processing or maintaining association rule.

C.H.Cai et al have proposed a mining of association rules with Weighted Items. Among the three parameters: weights of items, support of itemsets and the confidence factor, a weighted support, which is product of the total weight of items in the itemset and the support of the itemset is chosen in weighted association rule. Downward closure property of the support measure in the unweighted case is not valid in this framework and previous algorithms cannot be applied.

The authors proposed, two new algorithms MINWAL (O) and MINWAL (W) to handle this problem. The proposed algorithm for mining weighted association rules is similar to the Apriori Gen Algorithm, but the detailed steps contain some differences. In the beginning large itemsets is generated with increasing sizes. However, since the subset of a large itemset may not be large, k-itemsets is not generated simply from the large (k -1) itemsets as in Apriori Gen. In order to extract such k-itemsets from the database, a new metric called the k-support bound has been used in the mining process. The algorithms MINWAL (O) is applicable to both normalized and unnormalized cases, and MINWAL (W) is applicable to the normalized case only.

Invalidation of the ?downward closure property? in the weighted setting has been solved in [7] using an improved model of weighted support measurements. The authors have prove that if an itemset {AC} is not significant then its superset say {ACE} is impossible to be significant hence no need to calculate its weighted support A new algorithm called WARM (Weighted Association Rule Mining) has been proposed based on this improved weighted support framework. The algorithm is both scalable and efficient in discovering significant relationships in weighted settings.

3. Problem Definition.

The problem definition consists of the terms and basic concepts to define attribute weight, record weight, weighted support and weighted confidence for associative classifiers.

Technique for Weighted Association Rule Mining is known as (WARM) and technique for associative classifiers is termed as Weighted Associative Classifier (WAC).

3.1 Associative Classifiers.

Given a set of cases with class labels as a training set, classification is to build a model (called classifier) to predict future data objects for which the class label is unknown.

Associative Classification is an integrated framework of Association Rule Mining (ARM) and Classification. A special subset of association rules whose right-hand-side is restricted to the classification class attribute is used for classification. This subset of rules is referred as the Class Association Rules (CARs). Recent studies propose the  2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009) 1493    extraction of a set of high quality association rules from the training data set, which satisfy certain user-specified frequency and confidence thresholds. Effective and efficient classifiers have been built by careful selection of rules, e.g., CBA, CAEP and ADT. Such a method takes the most effective rule(s) from among all the rules mined for classification. Since association rules explore highly confident associations among multiple variables, it may overcome some constraints introduced by a decision-tree induction method, which examines one variable at a time.

Extensive performance studies [11] show that association based classification may have better accuracy in general [9].

3.2 Weighted Associative Classifiers.

A weighted associative classifiers consists of training dataset T={r1, r2, r3?. ri?} with set of weight associated with each {attribute, attribute value} pair. Each ith record ri is a set of attribute value and a weight wi attached to each attribute of ri tuple / record. In a weighted framework each record is set of triple {ai, vi, wi} where attribute ai is having value vi and weight wi, 0<wj<=1. Weight is used to show the importance of the item.

Definition 1. Attribute Weight: Attribute weight is assigned depending upon the domain. For example item in supermarket can be assigned weight based on the profit on per unit sale of an item. In web mining visitor page dwelling time can be used to assign weight In medical domain symptoms can be assigned weight by expert doctor.

Example: Weight of different attribute in predicting the probability of Heart Disease is given in Table I. A synthetic database is given in Table II.

Table I. Weight of symptoms for heart disease (attribute weight).

Table II. Sample database for heart patient.

Definition 2. Attribute set weight: Weight of attribute set X is denoted by W(X) and is calculated as the average of weights of enclosing attribute. And is given by     Example: Consider the 3 attribute set  (Age , ?>62?), (Smoking_habits, ?yes?) and (Hypertension, ?yes?) which may become the antecedent of a rule.

{(Age,? >62?), (Smoking_habits, ?yes?), (Hypertension, ?yes?)} = 0.3+0.8+0.6= 0.66  Definition 3. Record weight/Tuple Weight:  Consider the data in relational table, the tuple weight or record weight can be defined as type of attribute weight. It is average weight of attributes in the tuple. If the relational table is having n number of attribute then Record weight is denoted by W(rk) and given by    Definition 4. Weighted Support: In associative classification rule mining, the association rules are not of the form X ?Y rather they are subset of these rules where Y is the class label. Weighted support WSP of rule X?Class_label, where X is set of non empty subsets of attribute-value set, is fraction of weight of the record that contain above attribute-value set relative to the weight of all transactions.

S.No. Symptoms Weights  Age<40 40<age<58 age>58 Smoking_habits=yes Smoking_habits=no Hypertension=yes Hypertension=no BMI<=25 26<=BMI<=30 31<=BMI<=40 BMI>=40  0.1 0.2 0.3 0.8 0.7 0.6 0.5 0.1 0.3 0.5 0.8  |X| ?  weight(ai) i=1 Number of attributes in X  W(X) =  R_ID Age Smoking_hab its  Hypertensio n  BMI  Heart_Disease  1 42 Yes Yes 40 yes  2 62 Yes No 28 No  3 55 No Yes 40 yes  4 62 Yes Yes 50 yes  5 45 No Yes 30 No  |rk| ?  weight(ai) i=1  Number of attributes in a record W(rk) =  1494 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009)    This can be given as  Here n is the total number of records.

Example: Consider a rule R (Hypertension=?yes?) ? Heart_Disease=?yes? then Weighted Support of R is calculated as :    Table III. Sample database with record weight.

Definition 5. Weighted Confidence: Weighted Confidence of a rule X?Y where Y represents the Class label can be defined as the ratio of Weighted Support of (X?Y) and the Weighted Support of (X).

4. Weighted downward closure property.

In this paper, instead of using support, a weighted support, discussed in [7] is used. The authors have proved that using weighted support the ?weighted downward closure property? retains.

5. Conclusion & Future Work.

This work presents a new foundational approach to weighted associative classifiers where attributes are allowed to have weight depending upon their importance in predicting the class labels. A Conceptual model has been presented that allows development of an efficient and applicable algorithm in future that can capture real-life situations and can produce more accurate classifiers such as in Medical data mining. It has already been proved that, by assigning weights to items and using WARM, the selection of significant itemsets is steered to those itemsets containing or having relationships to high weight items [7]. Hence using weighted Association Rule as a Classification rule will improve the classification accuracy. In future work one of existing associative classifiers is to be chosen or new algorithm needs to be developed that can be integrated with weighted association rule miner.

