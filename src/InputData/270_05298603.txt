Mining High-Level Features from Video using Associations and Correlations

Abstract?Association rule mining (ARM) has been studied in the areas of content-based multimedia retrieval and semantic concept detection due to its high efficiency and accuracy.

Two important processes in mining the association rules for classification are rule generation and rule selection. In this paper, a novel high-level feature detection framework using the ARM technique together with the correlations among the feature-value pairs is proposed. A new association rule mining (ARM) algorithm has been developed, where the N -feature- value pairs are generated using a combined measure based on (1) the existence of the (N -1)-feature-value pairs (where N is larger than 1), (2) the correlation between different N - feature-value pairs and the concept classes through Multiple Correspondence Analysis (MCA), and (3) the similarity repre- senting the harmonic mean of the inter-similarity and intra- similarity. The final association classification rules are selected by using the calculated harmonic mean of the similarity values.

The proposed framework enables the automatic discovery and generation of the N -feature-value pair association rules from the 1-feature-value pairs for classification. Experiment- ing with 15 high-level features (concepts) and benchmark data sets from TRECVID, our proposed framework achieves promising performance and outperforms three other well- known classifiers (Decision Trees, Support Vector Machine, and Neural Networks) which are commonly used for performance comparison in the TRECVID community.

Keywords-Association rule mining; Multiple Correspondence Analysis (MCA); Concept detection

I. INTRODUCTION  Association rule mining (ARM) has been used to auto- matically detect the high-level features (concepts) from the video data, with the attempt to address the challenges such as bridging the semantic gap between the high-level con- cepts and low-level features. For example, [1] [2] [3] have employed the ARM techniques in exploring knowledge from images. Utilizing ARM in order to generate the association rules from a list of feature-value pairs, two measures are considered in the traditional algorithms: support which is the proportion of transactions in the database that contain the feature-value pairs, and confidence which is a measure of the accuracy of the rule. A frequently used algorithm is Apriori [4]. The process of mining association rules could be summarized to two main steps: finding the frequent itemsets which satisfy the minimum support threshold, and generating rules using the frequent item sets which satisfy the minimum confidence threshold.

In [5], a semantic indexing and event detection framework for basketball videos was proposed. The authors developed the measures including temporal distance, temporal support, and confidence for video associations by using distinct features from image, audio, and caption text. The temporal distance is the temporal identification difference of the neighboring shots that contain these two items, and the upper bound that the temporal distance must comply with is the temporal distance threshold. If the temporal distance threshold is ignored, the temporal support and confidence would be considered as the same as the traditionally ones.

However, by using this threshold, the temporal support is defined as the number of times the association appears sequentially and each time this association appears, and the temporal distance between any two neighboring items should satisfy the given temporal distance threshold. The temporal confidence is defined as the ratio between the temporal support and the maximal number of possible occurrences of the association.

Another example applying ARM for multimedia retrieval is presented in [6], in which a multi-layer hierarchical framework for generic sports event analysis in sports video was proposed. The leaf nodes of the hierarchical tree are the extracted events from the video clips. The Apriori algorithm is used to mine the rules, in other words, the associations between these events are used to extract those concepts.

The hierarchical approach avoids the shot detection and clustering process that are the necessary steps in most of concept and event detection frameworks. At each level of the tree structure, only simple frame-based features are used to classify the video. Due to the fact that the number of frames to be processed are degraded level by level, the computational cost is reduced remarkably.

In [7], a hierarchical temporal association mining ap- proach was developed to automatically capture the optimal temporal patterns significant for characterizing the interest- ing events in soccer video. It adaptively determines the essential thresholds which are generally defined manually in the traditional association mining approaches. There are two considerations for the use of patterns. First, an event is characterized by both attribute type and its occurrence frequency, because several close views appear in a temporal window might indicate an interesting event in the soccer video. Second, given a reasonable size of temporal window,   DOI 10.1109/ICSC.2009.59     the appearance order of the pattern could be captured, which is important in characterizing a target event. For instance, a goal event could be following a penalty kick.

An extended Apriori algorithm was proposed to mine the temporal patterns.

In addition to detect the interesting events in sports video, the ARM technique has also been studied in the feedback systems [8], surveillance systems [9], and concept detection systems [10] [11] [12] [13] in various video types. In [10], a framework discovering the concepts from news TV broadcasts using the traditional ARM technique was proposed. After getting pure positive rules from all the positive instances, the negative instances are simply classified through these rules as fuzzy negative set and pure negative set. It discards all fuzzy negative training instances and uses the pure negative training instances to generate the pure negative rule set using Apriori as the way the positive rules are generated. In [13], the ARM technique was used to discover the relationship between concepts. The prediction value of the detector indicates the likelihood that the detector regards the presence of a certain concept. The association rules are combined with the prediction values as a ranking strategy to improve the detection accuracy on experimenting the TRECVID 2005 data.

In our previous study [11], the Multiple Correspondence Analysis (MCA) method was utilized as the rule generation mechanism in associative classification using the 1-feature- value pair rules. The approach assisted the classifiers to detect more positive instances in the testing data set without misclassifying too many negative instances of the investi- gated concepts while testing on the TRECVID 2007 data.

Further, we extended the method in [11] to identify the correlation between the 2-feature-value pairs and concept classes, and use both the 1-feature-value pair rules and 2- feature-value pair rules as the final rule set for classification in [12]. The pairs are generated by using the correlation only and all rules are used for classification since no selecting algorithm is applied to select the rules. Therefore the computational cost is large.

One way to reduce the complexity is to prune the feature- value pairs during generation. A traditional way as in Apriori is to delete the candidate N -feature-value pair if not all combinations of the (N -1)-feature-value pairs in the previous stage exist. For example, at the N=3 stage, in order to generate the set {A1, A2, A3}, all the subset {A1,A2}, {A1,A3}, and {A2,A3} have to be kept in the (N -1)=2 stage. After generating the association rules, rule selection is always applied before classification to improve the per- formance. The support, confidence, and length of each rule are most commonly used thresholds. For instance in [14], the strategy is the longer the rules, the higher the priority of the rules. If two rules have the same length, the rules are sorted according to their confidence values. If two rules have the same confidence value, then the rules are ranked  by their support values. A combined measure to select rules was introduced in [15]. The authors proposed a personalized association rule ranking method based on semantic similarity between the rules, the keywords assigned by user?s interests, and the statistical information like support, confidence, and chi-square value.

In this paper, a novel high-level feature detection frame- work is proposed which is facilitated with a new association rule mining (ARM) algorithm that considers a combined measure for feature-value pair rule generation and a sim- ilarity measure for association rule selection. Our proposed framework consists of three main stages, namely (i) the preparation of the training data set and testing data set, which includes low-level feature extraction, feature normalization, data splitting, and discretization; (ii) the generation of the N -feature-value pairs based on the (N -1)-feature-value pairs (when N is greater than 1), the correlation between the extracted low-level features and the concept classes, the similarity calculation, and rule evaluation using the training data set; and (iii) the selection of the rules and the final high-level feature detection (classification).

To evaluate our proposed framework, the high-level fea- tures from TRECVID 2007 and 2008 [16] are used to compare the performance between our proposed framework and the well-known decision tree classifier, support vector machine classifier, and neural network classifier. Overall, our proposed framework outperforms all the three classifiers.

Furthermore, it is important to mention that the proposed framework significantly outperforms the support vector ma- chine classifier, which is the most recommended classifier in the research community for performance evaluation using the TRECVID data sets.

This paper is organized as follows. The proposed frame- work and detailed discussion on each component are pre- sented in Section II. Section III discusses on the experiments as well as the result analysis. In Section IV, the conclusions of paper are given.



II. THE PROPOSED HIGH-LEVEL FEATURE DETECTION FRAMEWORK  This paper proposes a novel framework that performs high-level feature (concept) detection from video using the ARM technique together with the correlations among the feature-value pairs is proposed. In the proposed framework, a combined measure is used for association rule generation and a rule selection strategy is performed to optimize the final rule set for classification.

Our proposed framework is shown in Figure 1 which con- sists of three main stages. These three stages are separated in three boxes enclosed by the dash lines in Figure 1.

1) The first stage is data preparation. It includes (a) low- level feature extraction, (b) feature normalization, (c) data splitting, and (d) discretization.

Figure 1. The Proposed Framework  2) The second stage is N -feature-value pair rules gen- eration. It works based on (a) checking the existence of the (N -1)-feature-value pairs (where N is larger than 1) and getting the candidate N -feature-value pairs, (b) the correlation between the extracted low- level features and the concept classes through Multiple Correspondence Analysis (MCA) to identify the N - feature-value pairs as the rules that better represent each one of the investigated concepts, (c) the sim- ilarity of rules representing the harmonic mean of inter-similarity and intra-similarity of rules, (d) rule  evaluation through the training data set to get the threshold values for parameters automatically.

3) The third stage is rule selection and classification. Rule selection is processed in the following way that all the positive rules are stored and then the negative rules are selected by using the mean of the similarity of all negative rules. Then classification is done by using the final association rule set, where the concept class is determined by the majority class of the matched association rules.

A. The First Stage: Data Preparation  Since the shot boundary information has been provided by [16], the video shot boundary detection is beyond the scope of this paper, and the audio and visual features extracted in this paper are shot-based. Totally, 28 continuous numerical features that were used in [10] are extracted. The feature values are normalized to lie in the [0, 1] range, as introduced in [17], simply by subtracting the minimum value and dividing by the difference between the maximum and the minimum values. Then the data set is split into two parts, two-third of the data is used for training and one-third of the data is used for testing, and the cross-validation method ensures that each data instance in the data set would be tested at least once as in [12].

Due to the fact that the ARM requires the input data to be nominal, all the extracted features are discretized using the method discussed in [18]. The training data set is discretized into bins (partitions) which are then used to discretize the testing data set. If there is only one resulting partition by using the aforementioned method, another discretizaton process is executed by using the average values of the feature for the disparity measure to construct two partitions for that feature. Please note that all the partitions generated by the discretization process are called the feature-value pairs in our study.

B. The Second Stage: Rule Generation  After the features are discretized, the training data are ready for rule generation. As demonstrated in Figure 1, there are four steps at the rule generation stage. The method to generate the 2-feature-value pairs was discussed in [12], that after the 1-feature-value pairs have been generated, the 2- feature-value pairs are generated by pairing the 1-feature- value pairs according to whether both of the 1-feature-value pair rules were generated for the same class. However, this is not applicable to the N -feature-value pairs due to the large computational cost. Therefore, a pruning strategy is developed. That is, the possible candidate N -feature-value pairs are first listed, and then simply checking the existence of the (N -1)-feature-value pairs (where N is larger than 1) using the method introduced in Section I, the candidate N -feature-value pairs are pruned.

Next, MCA is utilized to calculate the correlation between the nominal feature-value pairs and the concept classes, and the N -feature-value pairs as the rules that better represent each target concept are discovered. For each rule, the inter- similarity is defined as the similarity between the rule and the data instances belonging to different classes; while the intra-similarity is the similarity between the rule and the data instances belonging to the same class. The harmonic mean of the inter-similarity and intra-similarity values are calculated as a further step to generate the N -feature-value pair rules. The threshold values for correlation and similarity information are gained by evaluating the candidate rules through the training data set. The details description is given in the Section Section II-D  C. The Third Stage: Rule Selection and Classification  Since the detection of the target concept is the main concern, the positive rules are more important. Moreover, for some concepts, there are much more negative rules than the positive rules. Therefore, the strategy is that all the association rules (positive rules) indicating the concept class are kept. Then by using the mean of the similarity values of all rules for the non-concept class (negative rules), the negative rules are ranked. Finally, the selected N -feature- value pair rules are used as the association rules for mining the high-level features (classification).

In [11] [12], the utilization of MCA to analyze the data instances described by a set of low-level features and high- level concepts has been explored. MCA is an extension of the standard correspondence analysis to more than two vari- ables [19]. Therefore, MCA can be extended to capture the correlation between the N -feature-value pairs and the target concept (class), and we are able to project the multimedia data into a new space using the first and the second principle components. The inner product of all possible N -feature- value pairs and the classes can be calculated and the angles between the N -feature-value pairs and the classes are used as a measurement to represent their correlations. The main idea of utilizing MCA is that the smaller the angle is, the higher the correlation is. Therefore, each feature-value pair will be assigned to one class (positive or negative) only, and the candidate N -feature-value pair rules are available for the classification/detection of the particular target concept.

D. The Details on Rule Generation and Rule Selection  The pseudo-code for generating the 1-feature-value pair rules is presented as follows. Assume that all the 1-feature- value pairs gained from discretization are considered as the candidate pairs (pair(1)s ), and S(1) is the total number of candidates. By applying MCA to calculate the angles between the pairs in pair(1)s and the classes classr (either classpos or classneg), the candidate 1-feature-value pair rules are available. Then the similarity of these association rules could be obtained. The positive 1-feature-value pair  rules whose angles are smaller than a certain threshold (threshold(1)1 ) and their similarity values are larger than another threshold (threshold(1)3 ) are selected. Similarly, the negative 1-feature-value pair rules whose angles are smaller than the threshold (threshold(1)2 ) and their similarity values are larger than the threshold (threshold(1)4 ) are selected.

Here, i is the index of the rules.

RULE-GENERATION (N=1)  1 i ? 1; 2 n ? 1; 3 for s ? 1 to S(1) 4 compute angle(1)s by applying MCA; 5 rules ? pair(1)s ? classr; 6 compute similarity(1)s of rules;  7 if angle(1 )s < threshold (1 ) 1 and  8 if similarity(1 )s > threshold (1 ) 3 then  9 rulei ? pair(1)s ? classpos; 10 i ? i + 1; 11 if angle(1 )s < threshold  (1 ) 2 and  12 if similarity(1 )s > threshold (1 ) 4 then  13 rulei ? pair(1)s ? classneg; 14 i ? i + 1; RULE-GENERATION FOR POSITIVE RULES (N>1)  1 n ? 2; 2 while (1) 3 if classr = classpos 4 for s ? 1 to S(n)pos 5 check pair(n)s ;  6 if pair(n)s ?= NULL then 7 compute angle(n)s by applying MCA; 8 rules ? pair(n)s ? classpos; 9 compute similarity(n)s of rules;  10 if angle(n)s < threshold (n) 1 and  11 if similarity(n)s > threshold (n) 3 then  12 rulei ? pair(n)s ? classpos; 13 i ? i + 1; 14 if pair(n+1)s is possible then 15 n ? n + 1; 16 if not possible then 17 break.

When n is greater than 1, a combination of those (n-1)- feature-value pairs that do not belong to the same feature but indicate to the same concept (class) is considered as a candidate n-feature-value pair, and S(n) is the total number of candidates which equals the sum of the number of the candidates for the positive class S(n)pos and the number of the candidates for the negative class S(n)neg . If all the combinations are considered, the computational cost is large.

Therefore, when n is greater than 1, the pair(n)s is checked first to reduce the computational cost.

RULE-GENERATION FOR NEGATIVE RULES (N>1)  1 n ? 2; 2 while (1) 3 if classr = classneg 4 for s ? 1 to S(n)neg 5 check pair(n)s ); 6 if pair(n)s ?= NULL then 7 compute angle(n)s by applying MCA; 8 rules ? pair(n)s ? classneg; 9 compute similarity(n)s of rules;  10 if angle(n)s < threshold (n) 2 and  11 if similarity(n)s > threshold (n) 4 then  12 rulei ? pair(n)s ? classneg; 13 i ? i + 1; 14 if pair(n+1)s is possible then 15 n ? n + 1; 16 if not possible then 17 break.

The idea is that all the subsets containing the (n-1)- feature-value pairs with the contribution on combining the n- feature-value-pair are kept at the previous step. Then for the candidate n-feature-value pairs, MCA is applied to calculate the angles and the similarity values are calculated to generate the n-feature-value pair rules for classr. The process will continue until no new candidate pairs are available. The pseudo-code for generating both the positive N -feature- value pair rules and the negative N -feature-value pair rules, when N is larger than 1, are presented.

After the N -length candidate rules have been generated, the inter-similarity and intra-similarity values are calculated to evaluate each rule. For a certain concept Cj , assume that there are Tjp positive data instances, Tjn negative data instances, Rkp N -feature-value pairs association rules generated for Cj , and Rkn N -feature-value pairs association rules for the non-Cj class. Here, ct1 is the counter of the event that all N feature-value pairs are matched, ct2 is the counter when only some of N feature-value pair are matched, and ct3 is the counter that none of the feature-value pair is matched. The intra-similarity and inter-similarity values of the rules are defined as follows. Please note that for the similarity values in our definitions, a larger inter- similarity value means that the rule is better, and a larger intra-similarity value also indicates the rule is better.

SIntra Rkp = (?  ct1 1 +  ? ct2  0.25 + ?  ct3 )  /Tjp;  SInter Rkp = (?  ct1 0 +  ? ct2  0.75 + ?  ct3 )  /Tjn;  SIntra Rkn = (?  ct1 1 +  ? ct2  0.25 + ?  ct3 )  /Tjn;  SInter Rkn = (?  ct1 0 +  ? ct2  0.75 + ?  ct3 )  /Tjp.

Ikp = 2 ? SInter Rkp ? SIntra Rkp (SInter Rkp + SIntra Rkp)  ;  Ikn = 2 ? SInter Rkn ? SIntra Rkn (SInter Rkn + SIntra Rkn)  .

Let Ikp ? [0, 1] and Ikn ? [0, 1], then the harmonic mean of the inter-similarity and intra-similarity values is calculated. The harmonic mean is adopted since the har- monic mean of a list of numbers tends strongly toward the least elements of the list when compared to the arithmetic mean (simple average). If the inter-similarity and intra- similarity values are large, the harmonic mean tends to mitigate the impact of the large values. If the inter-similarity or intra-similarity value is small, the harmonic mean tends to aggravate the impact of the small values.

At this stage, the correlation information (the angle val- ues) and the similarity information (the intra-similarity and inter-similarity values) for each N -feature-value pair rule have been obtained. Then all these candidate rules are evaluated through the training data set. As indicated earlier, a few threshold values need to be pre-defined in our proposed framework. The angle threshold is the one that achieves the highest accuracy when applying the generated rule set with different thresholds to evaluate the training data set.

Similarly, applying the generated rule set using different thresholds, the similarity threshold is the one which yields the highest accuracy. The candidate rules corresponding to the angle and similarity values that are larger than the threshold value are selected. From the experiments, the length of the rule N varies from 2 to 5. Please note that in order to reduce the computational cost, the same threshold was used for the positive and negative association rules in [12]. However, in this paper, we have successfully reduced the cost by pruning the feature-value pairs. Therefore, the thresholds of the angle (threshold(n)1 and threshold  (n) 2 ) and  the thresholds of similarity (threshold(n)3 and threshold (n) 4 )  for positive and negative rules are different and adaptively determined in this framework at each step of N .

The classification process is carried out as follows. For each target concept, each testing data instance in the testing data set will go through all the selected rules (i.e., N -feature- value pairs) so that the matched rules can be identified. The matched rules are those N -feature-value pairs that are found in the testing data instance. The classification for each testing data instance is determined by the majority class label of those matched N -feature-value pairs for the corresponding testing data instance. If there is a tie, meaning that there are equal numbers of matched positive rules and the matched negative rules, then the positive rules are more important     and thus considered as having a higher priority in the high- level feature detection (classification) process.

The same classification procedure is applied to all the concepts, in the manner that for each concept, the N -feature- value pair rules are generated and the selected association rules are used as the classification rules.



III. EXPERIMENTS AND RESULTS  Our proposed framework is validated using the video data available for the TRECVID high-level feature extraction task participants in 2007 and 2008. The high-level features with sufficient amounts of positive data instances to build useful training and testing data sets in our database are two-people, outdoor, building, vegetation, street, road, sky, hand, urban, waterscape, crowd, face, person, animal, and walking, whose descriptions can be found in [16].

The performance evaluation was conducted by compar- ing the proposed framework with the Decision Tree (C4.5 algorithm), Support Vector Machine (Sequential Minimal Optimization (SMO) algorithm), and Neural Network (Mul- tilayer Perception algorithm) classifiers available in WEKA [17]. Please note that the parameters of these classifiers are set to the default values that WEKA has. The same evaluation metrics (namely, the precision, recall, and F1- score measures as given in Equations (1), (2), and (3)) and the same data sets are used in the comparison, where TP, FP, and FN represent true positive, false positive, and false negative respectively. The 3-fold cross-validation approach is adopted to ensure that each data instance is tested in the experiments.

Recall = TP  TP + FN ; (1)  Precision = TP  TP + FP ; (2)  F1score = 2 ? TP  (TP + FN) + (TP + FP ) . (3)  The average precision (Pre), recall (Rec), and F1-score (F1) values from the three folds are presented in Table I. In these tables, the performance obtained from WEKA?s Deci- sion Tree (DT), Support Vector Machine (SVM), and Neural Network (NN) are given in columns 2 to 4 respectively; while the performance of our proposed framework (ARM) is shown in the last column.

From Table I, it can be clearly seen that comparing to the other three classifiers, the proposed framework that extracts high-level features from the video data using the ARM technique together with the correlations among the feature- value pairs achieves the promising results. Our proposed framework not only outperforms the DT, SVM and NN classifiers in the average F1-score which considers both recall and precision, but also obtains higher recall values  Table I PERFORMANCE EVALUATION FOR FIFTEEN HIGH-LEVEL CONCEPTS  Two-people DT SVM NN ARM Pre 0.51 0.00 0.44 0.37 Rec 0.19 0.00 0.25 0.80 F1 0.27 0.00 0.32 0.51  Outdoor DT SVM NN ARM Pre 0.59 0.59 0.53 0.45 Rec 0.39 0.37 0.48 0.77 F1 0.47 0.46 0.50 0.57  Building DT SVM NN ARM Pre 0.57 0.55 0.50 0.42 Rec 0.34 0.27 0.42 0.83 F1 0.42 0.36 0.46 0.56  Vegetation DT SVM NN ARM Pre 0.51 0.54 0.45 0.39 Rec 0.35 0.14 0.46 0.86 F1 0.42 0.21 0.45 0.53  Street DT SVM NN ARM Pre 0.55 0.58 0.49 0.47 Rec 0.50 0.47 0.49 0.80 F1 0.52 0.52 0.49 0.59  Road DT SVM NN ARM Pre 0.58 0.59 0.50 0.45 Rec 0.34 0.35 0.47 0.81 F1 0.42 0.44 0.48 0.57  Sky DT SVM NN ARM Pre 0.62 0.64 0.56 0.48 Rec 0.48 0.45 0.51 0.78 F1 0.54 0.52 0.54 0.59  Hand DT SVM NN ARM Pre 0.46 0.33 0.42 0.39 Rec 0.31 0.06 0.40 0.81 F1 0.37 0.10 0.41 0.53 Urban DT SVM NN ARM Pre 0.51 0.53 0.47 0.45 Rec 0.41 0.25 0.45 0.76 F1 0.46 0.34 0.46 0.56  Waterscape DT SVM NN ARM Pre 0.58 0.65 0.53 0.48 Rec 0.49 0.47 0.52 0.74 F1 0.53 0.54 0.52 0.58  Crowd DT SVM NN ARM Pre 0.54 0.78 0.50 0.39 Rec 0.32 0.03 0.49 0.87 F1 0.40 0.06 0.50 0.54  Face DT SVM NN ARM Pre 0.60 0.68 0.55 0.47 Rec 0.43 0.39 0.48 0.67 F1 0.50 0.50 0.51 0.55  Person DT SVM NN ARM Pre 0.54 0.61 0.48 0.43 Rec 0.39 0.32 0.45 0.77 F1 0.45 0.42 0.47 0.55  Animal DT SVM NN ARM Pre 0.62 0.66 0.57 0.48 Rec 0.49 0.50 0.54 0.79 F1 0.54 0.57 0.55 0.59  Walking DT SVM NN ARM Pre 0.56 0.59 0.53 0.51 Rec 0.52 0.57 0.52 0.82 F1 0.54 0.57 0.52 0.63     than the DT, SVM and NN classifiers when considering the accuracy of high-level feature detection. The recall values for positive class have been improved because we are able to identify more good association rules for positive class.

Although there is a little bit trade-off between precision and recall, the overall F1-score have been improved. These observations demonstrate that our proposed framework using the novel ARM algorithm based on both associations and correlations assists in the classifier to detect more positive data instances labeled with the target high-level features in the testing data set, and improves the classification accuracy of the selected association rules.



IV. CONCLUSION  In this paper, a novel high-level feature mining/detection framework utilizing the associations and correlations among the feature-value pairs and the target concepts is proposed.

A new association rule mining (ARM) algorithm has been developed due to its high efficiency and accuracy in the areas of multimedia retrieval and high-level feature (con- cept/event) detection. In our proposed new ARM algorithm, the N -feature-value pair rules are generated based on a com- bined measure from (1) the existence of the (N -1)-feature- value pairs (where N is larger than 1), (2) the correlation between different N -feature-value pairs and the high-level features (concept classes) through Multiple Correspondence Analysis (MCA), (3) the similarity value representing the harmonic mean of inter-similarity and intra-similarity, and (4) the evaluation of the rules using the training data to automatically get various thresholds. Then a rule selection strategy is performed to optimize the final rule set. The target concept class is determined by the majority class of the matched selected association rules. The video data from the TRECVID 2007 and 2008 video corpus is used to validate the detection performance of our proposed framework. The experimental results show that our proposed framework demonstrates promising results with better overall recall and F1-score performance over the DT, SVM, and NN classifiers that are are commonly used for performance comparison in the TRECVID community.

