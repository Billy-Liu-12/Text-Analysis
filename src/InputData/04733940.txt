Mining temporal patterns with quantitative intervals

Abstract  In this paper we consider the problem of discovering frequent temporal patterns in a database of temporal se- quences, where a temporal sequence is a set of items with associated dates and durations. Since the quantitative tem- poral information appears to be fundamental in many con- texts, it is taken into account in the mining processes and returned as part of the extracted knowledge. To this end, we have adapted the classical APriori [1] framework to pro- pose an efficient algorithm based on a hyper-cube represen- tation of temporal sequences. The extraction of quantitative temporal information is performed using a density estima- tion of the distribution of event intervals from the temporal sequences. An evaluation on synthetic data sets shows that the proposed algorithm can robustly extract frequent tem- poral patterns with quantitative temporal extents.

1. Introduction  The classical view of frequent sequential patterns min- ing (FSPM) [1] considers a large database of sequences D.

Each sequence s ? D is an ordered set of items with possi- ble duplications. The mining task consists in extracting the longest patterns that are sufficiently frequent, i.e. that can be found in a number of sequence of D above a predefined threshold.

The FSPM is strongly motivated by its application to knowledge extraction from customer purchase database [1], DNA sequences, web logs [15], medical time series [9, 16], etc. Most of these investigations have only considered a linear sequential notion of time. But, in some contexts, the quantitative temporal dimension of data provides fun- damental information that should be taken into account in the mining processes and returned as part of the extracted knowledge. For example, in web log analysis, the browsing patterns can be refined by the time spent to explore the web pages. The comparison between the quantitative time spent on a web page and the required time to browse its content  may be useful to decide whether some part of the informa- tion has not been read. In a medical context, the temporal information is crucial to diagnose the patients accurately.

This is obvious in situations ranging from diabetes mellitus to intensive care unit ECG monitoring and artificial venti- lation. For example, in [16] different kinds of cardiac ar- rhythmias could be discriminated thanks to the quantitative temporal intervals between events (chronicles models).

Some authors, e.g. Chiu et al. [6], propose to simulate event duration by the repetition of a same event having a fixed atomic duration. However, in some applications it is necessary to distinguish the repetition of events from a sin- gle occurrence of this event: for example, two apneas of 30s each should not be confused with a single apnea of 1min.

This distinction is only possible with a quantitative repre- sentation of the time information.

Unfortunately, discovering the quantitative temporal ex- tents of events is a difficult problem. The construction of the sequence of items should be intertwined with the construc- tion of representative durations. On the one hand, temporal sequence instances are required to construct the represen- tative duration between two events in a temporal sequence.

But, on the other hand, the durations are required to identify the temporal sequence instances. To tackle this problem, we propose to enhance the classical APriori algorithm to han- dle quantitative temporal extents of the items.

In section 2, we define the temporal sequence, the hyper- cube representation and temporal pattern. Then in section 3, we give some details about temporal pattern extraction task.

In section 4, the algorithms are presented and the section 5 presents the evaluations. Finally, we present related work in section 6.

2. Temporal sequences and temporal patterns  2.1. Temporal sequences  Definition 1. (Temporal sequence) A temporal sequence S is a set of temporal items, where a temporal item A, de- noted as A = (A, [l, u]), is a symbolic event A associated   DOI 10.1109/ICDM.Workshops.2008.18    DOI 10.1109/ICDMW.2008.16     with a non empty interval [l, u], where l, u ? R, l < u, are timestamps:  S = {(si, [li, ui])}i?Nn n, the number of temporal items, is called the dimension  of the sequence S .

Notice that the delay between two events is indirectly  given by the beginning instants of the event intervals, and that there is no assumption on their occurrence. In particu- lar, event-overlapping is possible.

The temporal sequences may represent several runs of a dynamic process that generates these events, or may be extracted from a sliding window over long temporal se- quences. In the latter case, the timestamps are translated in order to represent the relative time within the window (and not the absolute time). So, the temporal sequences can be compared with each other.

Definition 2. (Temporal sub-sequence) A temporal sub- sequence of S = {(si, [li, ui])}i?Nn , is a temporal se- quence S ? of dimension m < n, such that S ? = {(sj , [lj , uj ])}j?P (Nn), where P (Nn) is a subset of Nn.

Definition 3. (Symbolic signature) The symbolic signa- ture of a temporal sequence S = {(si, [li, ui])}i?Nn is the ordered sequence of the symbolic events : S = {si| li < li+1}i?Pn , where Pn is a permutation of Nn.

Example 1. (Temporal sequence) Let s = {(A, [1.1, 2.9]) , (B, [4, 7.8]) , (C, [2, 5.3])} be a tem- poral sequence. s can be graphically represented as in Figure 1. The example indicates that event A occurs at the time unit 1.1 and spans 1.8 time units. Then, B occurs at time unit 4 and spans 3.8 time units. In parallel, event C occurs at the time unit 2 and spans 3.3 time units. C overlaps A and B.

The symbolic signature of the s is s = {A,C,B}.

Figure 1. Representation of the temporal se- quence s from example 1.

Now, we introduce the hyper-cube representation of a temporal sequence. It will be used to formalize the pattern extraction principle.

Definition 4. (Hyper-cube) An hyper-cube H of dimension n is a geometrical volume in Rn. It is defined by the bounds (li, ui)i?N:  ?x ? Rn, x ? H ? ?i ? N, li ? xi ? ui.

Definition 5. (Hyper-cube representation of a temporal se- quences) Given a temporal sequence S of dimension n, the temporal bounds of S define a unique hyper-cube in Rn. The temporal bounds of the sequence items are deter- mined by the orthogonal projection along each correspond- ing timeline (axis of Rn).

If some symbolic event has several occurrences in a temporal sequence, all the related dimensions are distin- guished.

Example 2. (Hyper-cube representation of a temporal se- quence) Given the temporal sequence of example 1, Figure 2 shows the hyper-cube representation of s. The dimension of s is 3, then the representation belongs to R3. The first, second and third dimensions are the timelines that deter- mine the bounds of A, B and C respectively.

Figure 2. Hyper-cube representation of the temporal sequence (dimension 3).

This representation of temporal sequences is used to de- fine the similarity between two temporal sequences S1 and S2 as the normalized overlapping volume of their hyper- cube representations, i.e. the volume of the intersection of the representations of S1 and S2 divided by the volume of the biggest hyper-cube.

Definition 6. (Temporal sequences similarity) Let S1 and S2 be two temporal sequences, then the similarity between S1 and S2, denoted by sim(S1,S2), is defined as:  sim(S1,S2) =  8<: 0 if S 1 6= S2Qn  i=1 max(0,min(u i ,u  i )?max(l  i ,l  i ))  max( Qn  i=1 u i?l  i ,  Qn i=1 u  i?l  i )  if S1 = S2  where S1 = S2 ? ?i ? Nn, s1i = s2i max  ( 0,min(u1i , u  i )?max(l1i , l2i )  ) gives the size of the  intersection of two intervals. Then, the similarity is the product of these sizes over the maximum product of the in- terval sizes of S1 and S2, i.e. the normalized volume of the intersection. This function is not a metric, but assum- ing that intervals cannot be empty, it is easy to prove that the proposed similarity is a positive-definite and symmetric function.

2.2. Temporal patterns  Definition 7. (Temporal pattern) A temporal pattern is a temporal sequence (P = {(pi, [li, ui])}i?Nn ) that is the representative of a set of similar temporal sequences.

Similarly to Giannotti et al. [9], a pattern is a represen- tative. However, in [9], patterns are rules a t??b, meaning that the representative duration between events a and b is t. Our patterns provides the delay between events as well as the duration of events. Chronicles [8] or delta patterns [17] are not representatives. They just generalize the repre- sented temporal instances. In fact, the interval between two events gives the lower bound and the upper bound of the delay between these two events.

Definition 8. (Temporal pattern coverage) A temporal pat- tern P = {(pi, [lpi , u  p i ])}i?Nn covers an example S =  {(si, [lsi , usi ])}i?Nm , denoted S ? P , if the symbolic sig- nature of S contains the whole symbolic signature of P , i.e.:  ?f : Nn 7? Nm injective, ?i ? Nn, pi = sf(i)  If S ? P , then SP denotes the longest temporal sub- sequence of S such that SP ? P . Finally, the coverage of S by P is defined by:  covP(S) = sim ( P,SP  ) .

Example 3. If P = (A, [1, 3]), (B, [4, 5]), and S = {(A, [1.1, 3.4]) , (D, [1.5, 5]) , (B, [4.1, 5.3])}, then S ? P and S  P = {(A, [1.1, 3.4]) , (B, [4.1, 5.3])}. The coverage  is computed by:  (3? 1.1) ? (5? 4.1) max(2 ? 1, 2.3 ? 1.2)  ? 0.62  The temporal pattern coverage is null in two cases: (1) if P does not cover S, or (2) if at least one pair of corre- sponding temporal items do not overlap, i.e. ?i, [lpi , u  p i ] ?[  lsf(i), u s f(i)  ] = ?.

Definition 9. (Temporal pattern strict-coverage) A temporal pattern P strictly-covers a temporal sequence S , denoted S ? P , if S ? P and covP(S) 6= 0.

3. Temporal pattern extraction  Temporal pattern extraction aims at finding the interest- ing temporal patterns from a set of temporal sequences (de- notedD). In our approach, interesting temporal patterns are the longest patterns such that sequences similar to this pat- tern can be frequently encountered in D.

Definition 10. (Temporal pattern extraction) Let D = {si}i?Nm be a set of m temporal sequences, and fmin ? [0, 1] be the frequency threshold. Then, temporal pattern extraction consists in finding out the longest (i.e. with the highest dimension) temporal patterns {Pi}i?Np such that for each Pi the examples strictly-covered by Pi are fre- quent:  |{s ? D | s ? Pi}| m  ? fmin.

Example 4. (Temporal pattern extraction) Given the databaseD that contains the following temporal sequences:  s1 = (A, [1, 3]) , (B, [4, 5]) s2 = (A, [1.2, 3.3]) , (B, [3.8, 4.6]) , (C, [5.8, 6.7]) s3 = (A, [1.1, 3.4]) , (D, [1.5, 5]) , (B, [4.1, 5.3]) s4 = (A, [0.9, 2.6]) , (B, [4.1, 5.2]) , (C, [6.2, 7.3]) s5 = (A, [0.1, 0.8]) , (B, [4.2, 5.2])  Given a frequency threshold f = 0.5, there is only one fre- quent symbolic signature of dimension 2: (A,B). Then, temporal extents must be associated with each event, but several temporal patterns are possible:  ? ((A, [0.1, 3.4]), (B, [3.8, 5.3])) strictly-covers all the examples, but the mean coverage is low (? 0.36).

? ((A, [1.1, 3.1]), (B, [4, 5])) has a better mean cover- age (? 0.71), but does not strictly-cover s5.

Moreover, several temporal extents that strictly-cover the same set of temporal sequences can be computed for a tem- poral pattern. Our aim is to define a unique and representa- tive temporal extent for each interval of a temporal pattern.

Since, the distributions of temporal intervals can highlight such representative temporal extents, we propose a solu- tion to construct unique and representative temporal extents which relies on the estimation of the interval distributions.

Ex am  pl e  Id  E xa  m p le  I d  Figure 3. Interval distribution of A (left) and B (right).

For example, Figure 3 shows the distribution of A inter- vals and B intervals of the example 4 that can be used to extract the temporal extents. Clearly, temporal sequence s5 rises a problem: all the sequences seems ?similar? with re- spect to the B-intervals distribution, but s5 does not seem ?similar? to the others with respect to the A-interval dis- tribution. Consequently, the distribution of A-intervals in     the pattern having (A,B) as symbolic signature can not be inferred from all A-intervals. More generally, this shows clearly that the interval distributions of a pattern can not be inferred from the interval distributions of its subpat- terns. Therefore, interval distribution extraction is inter- twined with symbolic signature construction. This is the temporal pattern extraction issue to tackle.

At this point, the hyper-cube representation is helpful.

This representation allows to consider the distribution of the intervals for all temporal dimensions globally at the same time. In Figure 4, the frequency of temporal regions is out- lined with darkening color: the darker a region is, the more temporal sequences overlap this region.

Figure 4. Distribution of temporal sequences (A,B) represented by hyper-cubes.

Our proposition is based on hyper-cube distributions which can be approximated using density-based multidi- mensional clustering (e.g. EM algorithm [7]). Then, ex- tracted clusters are used to compute representative temporal bounds.

In our framework, we approximate distributions with Gaussian mixture models. Once computed, each Gaussian is associated with a possible temporal pattern. The tem- poral intervals to overlay over the symbolic signature are extracted from a Gaussian of the model by computing the bounds associated with an interval representing some ratio of the whole confidence. This is the temporal extent thresh- old. In our experiments, we have chosen 95% confidence intervals.

Figure 5 illustrates the Gaussian distribution estimation and the extracted temporal bounds. Two clusters repre- sented by ellipses are computed, so two temporal patterns are extracted. Each ellipsis axis gives the temporal bounds for the item associated with the axis dimension.

Note that it is easy to understand 2-dimensional tempo- ral sequence graphs and their distribution. For higher di- mensions, graphical representations are almost impossible to understand but the same reasoning can be done.

Figure 5. On the left, temporal sequences in- stances and Gaussians iso-density ellipsis.

On the right, the density estimation.

4. Framework and algorithms  Our framework is based on the APriori algorithm [1] to construct the longest frequent symbolic signatures. The main idea of this algorithm is based on the following prop- erty: every symbolic signature that covers a frequent sym- bolic signature is frequent. This property is helpful to prune a lot of candidates of size n knowing the infrequent sym- bolic signatures of size strictly inferior to n because if a symbolic signature of size n is covered by an infrequent symbolic signature then it is not frequent.

The algorithm, whose pseudo-code is given in Algorithm 1, iterates two stages, namely (1) the selection of frequent temporal patterns of dimension n, and (2) the generation of symbolic signature candidates of dimension n + 1 from those of dimension n. These two stages are detailed in the following sections. The process terminates when there is no more potential longer candidate or when the candidates are no longer sufficiently frequent.

The algorithm has been adapted to process hyper-cube representations of temporal sequences. In particular, the se- lection of frequent temporal patterns uses the distribution estimation approach to extract the temporal intervals (see section 4.2), and the candidate generation uses a priori con- straints enriched by temporal bounds (see section 4.3).

4.1. Main algorithm  The first step of the algorithm consists in constructing the frequent symbolic signatures of dimension 1. If an item (e.g. (A)) has less occurrences than fmin ? |D|, then it is not frequent and according to the APriori algorithm prin- ciple, it should not be taken into account. Then we enter in the main selection-generation loop. Assume that Ln, the set of symbolic signatures of dimension n, has been con- structed. As will be seen later, these symbolic signatures are good candidates to be frequent. The selection phase     aims (1) at verifying the frequency of generated candidates and (2) at constructing their associated temporal intervals.

Given p ? Ln, we first verify that the symbolic signature of p is frequent. Then, and only then, we can expect to find out temporal intervals using the density estimation of the interval distribution. The candidate selection function is detailed in the next section. This function returns a set of frequent temporal patterns that are added to Mn. Note that a symbolic signature can give rise to several temporal patterns (see Figure 5 for instance).

Once all symbolic signatures have been processed and if Mn is empty, then no temporal patterns of size n is frequent.

Thus, the result given by the algorithm is the set of frequent temporal patterns of size n? 1.

Algorithm 1: Temporal pattern mining algorithm (in- spired from the APriori algorithm).

Input: fmin: minimal support, D: temporal sequences database, d: random points density  Output: Mn: the longest frequent temporal patterns (of dimension n)  // Construct frequent symbolic signatures of dimension 1 in L1  L1=construct L1(D,fmin); n = 1; while Ln is not empty do  Mn = ?; for p ? Ln do  // Selection phase f = frequency(p); if f ? fmin then  Mn = Mn? selection(fmin, D, p, f , d); end  end if Mn is empty then  return Mn?1; end // Generation phase Ln+1=generateCandidates(Mn); n = n + 1;  end return Mn;  4.2. Candidate selection  Algorithm 2 details the candidate selection function.

This function aims at identifying the frequent temporal pat- terns inD that can be associated with some symbolic signa- ture p. There is two main tasks: (1) construct the represen- tative temporal bounds for p, and (2) prune the infrequent temporal patterns.

The main part of the algorithm consists in estimating the density function for the distribution of the hyper-cube rep- resentation of p instances. We use a Monte-Carlo approach  to estimate the density function. For each sequence s ? D that is covered by p, random points (vectors in dimension n) are uniformly generated inside the hyper-cube defined by sp. The number of points is proportional to the volume of the hyper-cube. Moreover, to deal with the curse of di- mensionality [2], this number is exponentially proportional to the dimension of the hyper-cube. The required number of points is given by the following formula:  nb = vol (sp) ? ddim(p) (1)  where d is a parameter of our algorithm that can be easily adjusted depending on the time values expected in intervals.

Algorithm 2: selection(fmin, D, p, f , d) Input: fmin: the minimal support, D: temporal sequences  database, p: symbolic signature, f : frequency of p, d: random points density  Output: M : set of frequent temporal patterns // Generation of representative points  for interval distribution for s ? D do  if p covers s then // nb: number of points to  generate  nb = vol (sp) ? ddim(p); add nb random points inside sp to hh;  end end // Extraction of frequent temporal  patterns from hh GaussianMixtureModel = EM(hh); for gm ? GaussianMixtureModel do  if f ? gm.prop ? fmin then pnew = temporal pattern(p, gm); M = M ? {pnew};  end end return M ;  The distribution of generated points, denoted hh in Al- gorithm 2, represents the distribution of the intervals. Then, algorithm EM [7] is used to estimate the Gaussian mixture model from these points. In the most general case, the den- sity function is:  f(x) = N? k=1  ck(2?)?d/2|?k|?1/2e? 2 (x??k)  t??1k (x??k)  where N is the number of Gaussians, ?k is the mean vector and ?k is the variance matrix of the kth Gaussian, and ck is the proportion of the Gaussian in the mixture.

In the EM algorithm the number of Gaussians N must be given, but the correct number of clusters is unknown.

Consequently, the algorithm is executed for several num- bers of clusters and the best mixture is selected. In practice, the normalized entropy criterion (NEC) is used to select the number of clusters between 1 and nb0.3 [4].

In addition, we assume that the intervals in a temporal pattern are independent. Consequently, the EM algorithm is constrained to extract Gaussians with diagonal variance matrices. This assumption reduces the computation cost.

Once, the Gaussian mixture model has been computed, the temporal patterns can be extracted. First of all, a Gaus- sian gm must have a sufficient proportion denoted ck in the mixture formula and denoted gm.prop in Algorithm 2. It means that if a symbolic signature has a frequency of f , then f ? gm.prop gives the number of temporal sequences strictly-covered by the temporal pattern associated with an extracted Gaussian gm. Such a temporal pattern is retained only if f ? gm.prop ? fmin.

Finally, the interval bounds are computed by:  [ ?k ?  ?  (2?)?d/2|?k|?1/2, ?k +  ?  (2?)?d/2|?k|?1/2  ] where ? is a parameter used to adjust the width of the  interval (currently fixed to 0.8).

Algorithm 3: generateCandidates(Mn) Input: Mn: set of frequent temporal patterns of dimension n Output: Ln+1: set of candidate temporal patterns of  dimension n + 1 // Generation of candidates for s ?Mn do  for i ? L1 do P = {s, (i, [??, +?])}; Ln+1 = Ln+1 + P ;  end end // Suppression of a priori infrequent  candidates for s ? Ln+1 do  if s is a priori infrequent then Ln+1 = Ln+1 ? s;  end end return Ln+1;  4.3. Candidate generation  Now, we present the candidate generation (see Algo- rithm 3). To generate only the potentially useful candidates, we extend the classical APriori constraint on symbolic sig- nature to a constraint that takes into account the tempo- ral intervals thanks to the hyper-cube representation. Let P = {(si, [li, ui])}Nn+1 be a temporal pattern of dimension n + 1. P may be frequent if every orthogonal projection  of its hyper-cube on each subspace of dimension n over- laps with at least one hyper-cube of Mn, the set of frequent temporal patterns of dimension n, i.e.:  ?l ? [1, n + 1], ?p ?Mn, sim ? (si, [li, ui])Nn+1?{l} , p  ? 6= 0  In the first phase of the generation, temporal patterns of dimension n + 1 are generated by concatenating an el- ement of Mn and an element of L1 (the set of frequent items). The element of L1 is associated with infinite tem- poral bounds. In a second phase, the a priori infrequent elements are pruned.

5. Evaluation  The algorithms have been implemented in MatLab v7.6 (R2008a)1. We have used the MixMod library [3] to com- pute Gaussian mixture models. Our experiments were per- formed on a bi-processor Pentium IV 3.6GHz, 2Go of RAM. To evaluate the properties of our algorithm, we have used synthetic data sets. The simulation process is flexi- ble enough to quantitatively evaluate several properties such as accuracy, computation time and robustness against the noise.

To our knowledge, there is no other algorithms for ex- tracting temporal sequences with quantitative temporal in- tervals that we could quantitatively compare with. In sec- tion 6, we present a qualitative comparison of our temporal pattern extraction method to other temporal sequence min- ing methods.

5.1. Data set simulation  The data simulation process generates random temporal sequences based on a temporal pattern prototype to which is added temporal noise and structural noise.

A temporal pattern prototype is a set of n quintuplets ({(Ei, ?bi , ?bi , ?di , ?di)}i?Nn ) whereEn is an event name, ?bn , ?dn (resp. ?bn , ?dn ) are the mean (resp. the standard deviation) of the generated begin instants and durations of En. This prototype specifies the temporal pattern to dis- cover ({(Ei, [?bi , ?bi + ?di ])}i?Nn ), and the standard devi- ation parameters quantifies the Gaussian distribution of the interval bounds. The larger the standard deviation is, the harder the temporal pattern extraction is. For the sake of simplicity, all standard deviations are equal to tN ? [0, 1].

This parameter quantifies the temporal noise in the data set.

In addition, some structural noise can be added. A struc- tural modification consists in randomly deleting an event or modifying an event name. sN ? [0, 1] is the ratio of struc- turally modified temporal sequences in the data set. Finally,  1Source code for the algorithm and the data generator available on-line: http://www.irisa.fr/dream/QTempIntMiner/.

(1)  (2)  (3)  (4)  (5)  (6)  (7)  (8)  (9)  (10)  Figure 6. Prototype (upper graph) and 10 gen- erated examples.

totally randomly generated temporal sequences are added to the data set with ratio rP ? [0, 1].

Figure 6 illustrates the temporal sequence generation process (nb = 10, sN = 0.1). The fourth sequence has been randomly generated (rP = 0.1), several sequences such as sequence number 8, have been structurally cor- rupted (sN = 0.1) and time bounds fluctuates due to the temporal noise (tN = 0.2).

In the following, the prototype used to generate the data sets (nb = 20) was {(Ek, [3k, 3k + 1])}k?Nn . When not explicitly given, the parameters take their default values n = 4, nb = 20, sN = 0 and tN = 0.2. For each set of parameters, 10 different data sets were generated to yield statistically significant results.

The accuracy (in [0, 1]) of the temporal pattern extrac- tion process is evaluated by the similarity value between the prototype and the best extracted temporal pattern (see Def- inition 6). This means that if the temporal pattern and the prototype share the same symbolic signature, then the ac- curacy is given by the relative common volume. Otherwise the accuracy will be set to 0. A non-zero accuracy points to a correct symbolic signature extraction (this is always the case with the basic parameters), thus the higher the accu- racy, the better the extracted temporal bounds.

5.2. Experiments and results  The results are organized as follow: first, we present evaluations of the computation time and the accuracy of the algorithm according to the parameters nb, n, tN and sN (linked to the temporal sequence representation). Then we  demonstrate the robustness of the algorithm in finding out the interesting temporal patterns in a large amount of tem- poral sequences. Finally, we highlight some properties on examples.

Computation time and accuracy Short computation time is a strong constraint on sequential pattern mining al- gorithms. The computation time of APriori is known to in- crease exponentially with the pattern size (i.e. the prototype dimension n). Moreover temporal bounds extraction in the selection phase is also time consuming. The number of ex- amples for the EM algorithm is proportional to dn, where d is a parameter (see eq. 1). Practically, the maximum di- mension of the extracted temporal pattern may be limited to have reasonable computation times.

Figure 7. Computation time (on the left) and accuracy (on the right) w.r.t. the prototype size.

The results (Figure 7, left) show that the computation time increases exponentially with the prototype dimension (n ranges from 2 to 5). For d = 4, the computation time ranges from 2?? to 3?41??. Figure 7 right gives the accu- racy. The accuracy decreases notably when the dimension increases. This comes from the fact that the accuracy is evaluate from the similarity: by definition the similarity computes the product of the relative sizes (lying in [0, 1]) of the intersection along each dimension of two hyper-cubes.

Experiments have been performed with six values of d from 1.5 to 6. We expected that the computation time should increase with d, while the accuracy should become better.

Practically, this is the case for d ? 3. However, we did not notice any statistically significant improvement of the accuracy for d ? 3. Nonetheless, the computation time is significantly higher, so we set d = 3 for the other experi- ments.

Figure 8 illustrates the computation time and the accu- racy with respect to the number of examples (nb ranges from 100 to 1000). On the one hand, the computation time increases linearly, and on the other hand, the accuracy re- mains quite the same. Thus, this experiment shows that our     algorithm is robust with respect to the database size.

Figure 8. Computation time (on the left) and accuracy (on the right) w.r.t. the examples number. Boxplots show the variances.

Finally, Figure 9 illustrates the accuracy with respect to the temporal noise. There is two parts in this graph: at the beginning, the accuracy increases, then it decreases when more temporal noise is added. The second part shows a normal behavior: the higher the temporal noise, the less ac- curate the temporal intervals. The dashed line highlights failures in pattern extraction (the symbolic signature could not be successfully extracted). This means that when the temporal variances become too high, the algorithm is no more able to reconstruct the symbolic signatures due to the difficulty to identify the correct Gaussian mixture models.

For tN = 0.6, it occurs only in 10% of the experiments, but for tN = 1 it occurs in 50% of the experiments.

We expected to obtain a very good accuracy and low variances when the temporal noise is low. But the first part of the Figure 9 shows the opposite. It can be explained by observing that many extracted intervals are shifted com- pared to the prototype intervals. This behavior is explained below.

We conclude from these experiments that (1) the algo- rithm extracts temporal patterns with accurate temporal in- tervals, and (2) in spite of the theoretical drawbacks (con- firmed by the experimental results), the computation time is reasonable.

Temporal interval enlargements and shifts For tem- poral interval extraction, we hypothesize that the interval distribution fits a Gaussian distribution. We identified two cases where this hypothesis is false. The first one occurs when the variance of the lower (or upper) bound of a proto- type interval is high compared to the duration of this inter- val (see Figure 10, left). In this case, the extracted temporal interval is larger than expected.

The second case occurs when the variance of the lower bound of a prototype interval is low compared to the vari- ance of its duration (see Figure 10, right). In this case, the  Figure 9. Accuracy w.r.t. temporal noise. The dashed line gives the accuracy mean com- puted with non-zero accuracies.

extracted temporal interval is shifted. In fact, the distribu- tion is not Gaussian anymore: it is rather exponential.

Figure 10. Two cases of inadequate inter- val extraction. Plain line rectangles show the temporal bounds extracted from the com- puted Gaussians (ellipsis). Dashed line rect- angles show the expected temporal bounds.

Knowing these possible behaviors is helpful to determine the assumption under which the extraction algorithm will be efficient. As a consequence, the data set must be such that the variance of interval lower bounds must be low but suffi- ciently high compared to their respective duration variance.

Robustness to structural and database noises In the previous experiments, database temporal sequences were corrupted with temporal noise only. In the present section, we keep some temporal noise (tN = 0.2) but we intro- duce structural noise in the temporal sequence generation.

The robustness to structural corruption can be assessed by varying the fmin parameter of the APriori framework. As-     suming that rP = 0, i.e. that there are only positive exam- ples (possibly corrupted) of the temporal pattern and, given fmin, we expect that the algorithm will be robust with re- spect to a structural noise equal to fmin.

Figure 11 illustrates the accuracy with respect to the structural noise level and fmin = 0.5. Temporal pattern extraction failures occur when sN ? 0.35 (only 1 failure out of the 10 trials for sN = 0.35). When sN = 0.5 tem- poral pattern extraction fails in more than half of the cases (6 failures out of 10 trials). This experiment confirms that when fmin is low the robustness of our algorithm against the structural noise is high.

Figure 11. Accuracy with boxplots w.r.t.

structural noise. The dashed line gives the mean of non-zero accuracies.

However, in real databases, positive examples of a tem- poral pattern are mixed (1) with positive examples of other temporal patterns and (2) with random irrelevant temporal sequences. Then, fmin must be sufficiently low both to find out the few positive examples of a temporal pattern, and to be robust against the structural noise. But, if fmin is too low, the computation time may hugely increase and irrele- vant patterns could be extracted.

To confirm this hypothesis, we have generated a more re- alistic data base containing 1000 temporal sequences with 80% of randomly generated sequences (rP = 0.8). Two different prototypes were used to generate relevant temporal sequences (10% each). Consequently, fmin must be lower than 0.1 (ratio of positive examples in the database per tem- poral pattern) to consider relevant temporal sequences as frequent, but due to additional structural noise (sN = 0.2), it must be lower than 0.1 ? (1 ? sN). Thus we choose fmin = 0.05. The experiment showed that our algorithm is able to find out at least one temporal pattern and the two temporal patterns in 65% of the trials with a mean accuracy of 0.33 and a mean computation time of 9?07??.

Additional properties Other experiments have been performed to illustrate interesting additional properties of our algorithm. For example, our algorithm can extract (1) temporal patterns with temporal items that overlap or (2) temporal patterns with twins, i.e. several identical events (associated with different intervals). Contrary to existing approaches, e.g. [8], these temporal patterns do not intro- duce difficulties to our algorithm thanks to the hyper-cube representation that separates the temporal information for each item. In the case of temporal patterns with twins, two dimensions can be separated if two representative temporal extents are extracted. This can be computed from Gaussian mixture models. For example, it can distinguish the two representative Gaussians of Figure 5.

6. Related work  Temporal sequence mining involves two different kinds of issues: FSPM algorithm with time constraints [14, 15], and temporal relation discovery [9, 11, 12, 17]. Hirate et al. [10] propose a generalized FSPM with the capability to handle two kinds of item interval measurements, item gap and time interval.

Time constraints approaches, make use of minimum and maximum gap values that must be defined as the gap con- straint by the user. Then the algorithms, such as SeqLog [14] or GTC (Graph for Time Constraints) [15], extract or- dered sequences of items that respects these gaps. How- ever, the algorithm do not discover the time constraints. The gaps are used to get rid of insignificant patterns and rules so as to reduce the number of generated patterns and rules.

Temporal relation discovery approaches use extended definitions of temporal sequences. In [11, 13], qualitative temporal relations on intervals, i.e. Allen temporal rela- tions, are associated with sequence items. Ho?ppner [11] propose a level-wise algorithm inspired from the APriori al- gorithm to extract efficiently both event sequences and tem- poral relations.

Chen et al. [5] or Quiniou et al. [16] propose an interme- diate representation of temporal sequences between qual- itative temporal relations and quantitative temporal con- straints. Chen et al. [5] uses the concept of fuzzy sets to extend the original APriori algorithm and PrefixSpan al- gorithm so that fuzzy time-interval sequential patterns are discovered from databases. Quiniou et al. [16] uses a first-order relational learning method to construct a graph of temporal constraints called chronicles.

The closest approaches to ours are [8, 9, 12, 17]. The temporal information associated with temporal sequences is represented by quantitative interval extents. In [9], Gian- notti et al. propose an extension of the sequence mining paradigm to linear temporally-annotated sequences, where each transition A ? B in a sequence is annotated with     a typical transition time t, denoted by A t??B. The notion of Delta-Pattern, proposed by Yoshida et al. [17] is quite similar to temporally annotated sequential patterns. Delta-  Patterns have the form A [0,3] ???B, denoting a sequential pat-  tern A ? B that frequently occurs in the data set with transition times from A to B that are contained in [0, 3].

The FACE system [8] adapted the APriori framework [1] to extract the temporal extents of the interval between two events as the enveloping interval of the temporal sequence instances intervals. As us, Giannotti et al. and Yoshida et al. [17] use a clustering method to extract the representa- tive values of the transitions. Yoshida et al. [17] provide an heuristic for finding some frequent Delta-Patterns but their method is not exhaustive. Giannotti et al. [9] pro- pose to combine a candidate sequence generation step with a clustering step, but do not provide details nor evaluations of their method. In both methods, the main issue of inter- twining a pattern growing method with temporal interval generation based on the analysis of interval distributions is not explicitly addressed.

7. Conclusions  In this paper we introduce a temporal extension of the classical sequential pattern mining which adds quantitative temporal information to patterns. Using a hyper-cube rep- resentation of temporal sequences, the temporal extents of pattern events can be globally extracted. We propose an algorithm that solves the issue of intertwining the interval distribution extraction and symbolic signature construction.

Our algorithm is based on the APriori algorithm and an approximation of the interval distribution. On the one hand, a variant of the APriori algorithm enables the extraction of the longest patterns in large temporal sequence database.

On the other hand, the use of Gaussian mixture models for approximating the interval distributions enables the extrac- tion of the representative quantitative temporal extents of a pattern.

As APriori our method is exponential with the size of the patterns but it remains linear with the number of sequences in the database. The practical efficiency of the method has been evaluated on synthetic data sets. The results show that while the pattern growth technique makes our algorithm ro- bust against the structural noise, the use of Gaussian mix- ture models makes it robust against temporal noise.

