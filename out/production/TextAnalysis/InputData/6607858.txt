Keywords-Relevance Feedback, Relevant Feature Extraction, Pattern Cleaning, Pattern Mining, .

Abstract?It is a big challenge to guarantee the quality of extracted features in text documents to describe user interests or preferences due to large amounts of noise. Over the years, pattern mining-based approaches to RF have attracted great interest to discover knowledge of user interest from text doc- uments. However, the data mining approaches often produce a large set of patterns, which include a lot of noisy patterns, reducing the effective use of pattern mining. In this paper, we present a novel pattern mining approach to RF. This approach mines patterns in both positive and negative feedback and then classifies them into clusters to find user-specific patterns. We also propose a novel pattern deploying method that effectively uses the discovered patterns for improving the performance of searching relevant documents. Experiments are conducted on Reuters Corpus Volume 1 data collection (RCV1) and TREC filtering topics. The results show that the proposed approach achieves promising performance comparing with state-of-the- art term-based methods and pattern-based ones.

posed approach by extracting features from RF to improve the performance of information filtering (IF). The experimental results, evaluated on Reuters Corpus Volume 1 data collection and TREC filtering topics, show that the proposed approach achieves promising performance comparing with state-of-the- art term-based IR methods and pattern-based ones.



II. PRELIMINARY DEFINITIONS  Let D be a training set, including a set of positive (relevant) documents, D+, and a set of negative (irrelevant) ones, D?. In this paper, all documents are divided into paragraphs. Thus, a given document d yields a set of paragraphs PS(d).

A. Frequent Patterns and Closed Patterns  Let T = {t1, t2, . . . , tm} be a set of terms which are extracted from positive documents D+. Given a termset X be a set of terms in a document d, i.e., X ? T , coverset(X) = {dp?dp ? PS(d),X ? dp}. Its absolute support  Supa(X) = ?coverset(X)? (1)  and its relative support  Supr(X) = ?coverset(X)? ?PS(d)?  (2)  A termset X is called frequent patterns if its supa or (Supr) ?min sup, a minimum support. Let X be a frequent pattern.

We call X be a closed pattern if there is no super-pattern Y ? X which Supa(X) = Supa(Y ).

B. Closed Sequential Patterns  A sequence X =< t1, . . . , tr > (ti ? T ) is an ordered list of terms. Let a sequence s1 =< x1, . . . ,xi > is a sub-sequence of another sequence s2 =< y1, . . . ,y j >, denoted by s1 ? s2, iff ? j1, . . . , ji such that 1 ? j1 < j2 . . . < ji ? j and x1 = y j1 ,x2 = y j2 , . . . ,xi = y ji . Given s1 ? s2, we usually say s1 is a sub-pattern of s2, and s2 is a super-pattern of s1.

A sequence X is called a sequential pattern if its absolute or relative support ?min sup. A frequent sequential pattern X is call closed if not ? any super-pattern X1 of X such that Supa(X1) = Supa(X).

C. The SPMining Algorithm  The SPMining algorithm has been developed in [18] for discovering closed sequential patterns in text documents, which was also used in several papers [17], [21]. SPMining simply used the well-known Apriori property to reduce the search space. A brief introduction of the SPMining algorithm is as follows.

Given a training set of documents D+, including positive documents D+ and negative documents D?, the SPMining algorithm firstly divides every document d ? D+ into a set of paragraphs PS(d). It then finds all closed sequential patterns that frequently appear in these paragraphs according to a support threshold min sup. In this work, we use the SPMining algorithm to efficiently mine closed sequential  patterns in both positive and negative documents of a training set.



III. DISCOVERING SPECIFIC PATTERNS  In this section, we explain the idea of finding specific patterns. We assume that frequent patterns have been already mined from positive documents, called positive patterns, using SPMining algorithm.

A. Relevant v.s. General Patterns  It is easy to understand that positive patterns capture the direct knowledge of user interest since they come from relevant documents of a user. However, it is not a good option for using all positive patterns to describe the user interest. This is because frequent patterns are solely generated based on their support. Thus, many positive patterns may capture general information that easily appear in various topics. Such patterns are likely noisy ones in describing user- specific relevance information.

Negative (i.e., non-relevant) documents typically contain irrelevant information w.r.t. user?s relevant documents. The intuitive idea of our work is to exploit non-relevant informa- tion in the negative documents to clarify between relevant and general information captured in positive patterns. To achieve this, we mine patterns from the negative documents, called negative patterns. We then classify positive patterns into specific and general patterns based on their appearance in positive and negative documents.

Figure 1. The relationship between positive patterns (non-broken line ovals) and negative patterns (dashed-line ovals) in a training set  According to Figure 2, positive and negative patterns over- lap each other because they capture common information.

in both the positive and negative documents. By examining the interrelating relationship between positive and negative patterns, positive patterns can be characterized into relevant and general patterns as follows:  Definition 1 (General patterns): A positive pattern p ? D+ is called general if ?q ? D?? p? q.

Let us consider positive patterns shown in Figure 2. Positive patterns F and I are general patterns since they are subsets of negative patterns G and J respectively.

The rest of positive patterns can be considered as relevant patterns because they never appear in the negative documents.

However, some relevant patterns may contain general terms that overlaps with negative patterns. Thus, we further classify the relevant patterns into specific relevant (or specific pat- terns) and weak specific relevant (or weak patterns) patterns as follows:  Definition 2 (Specific patterns): A positive pattern p?D+ is called specific if ?q ? D?? p?q = /0.

As shown in Figure 2, positive patterns A, and B are specific patterns.

Definition 3 (Weak patterns): A positive pattern p?D+ is called weak if ?q ? D?? p?q ?= /0.

In Figure 2, positive patterns C, D, F and I are weak patterns since we can find negative patterns E, H, G and J, such that, C?E ?= /0, D?H ?= /0, F ?G ?= /0, and I? J ?= /0.

B. Selecting Negative Offenders  It is not effective to exploit non-relevant information in a large number of negative documents which come from various unrelated topics. Here, we adopt the idea of selecting informative samples in the set of negative documents to reduce the negative space, called offenders [21], where an offender is a negative document which is close to user?s relevance.

As the high dimensionality of frequent patterns, it is inefficient to mine frequent patterns from negative documents for identifying the negative offenders. In this study, we propose a ranking function that scores negative documents quickly according to their relevance. Our scoring function uses all size-1 patterns in positive documents D+ to rank the negative ones. Let T be a set of all size-1 patterns in positive documents D+. Given a negative document nd ?D?, the score of the negative document nd can be calculated as the following function:  S(nd) = ? p?nd?T  supr(p) (3)  where Supr(t) is the relative support of size-1 pattern p.

According to (3), document nd is evaluated based on the total relative support of size-1 patterns found in the document.

Once the weights of negative documents were determined, we sort them in descending order, i.e., S(nd1) ? S(nd2) ? . . . ? S(ndm), where m = ?D??. Then, the top-k ranked doc- uments are selected as the offenders to replace the whole collection of negative documents. We evaluated various k values and empirically found that the best performance results in this data collection are achieved when k = ?D  +? 2 where ?D  +? is the number of positive documents in a training set. Thus, we fix this value for this experiment.

C. Pattern Classification Algorithm  Algorithm 2 illustrates the classification process. The in- puts of this algorithm include the pattern taxonomy PT+, a negative sample set D+, and a number of offenders k. The output of this algorithm is the updated trees of positive and  negative patterns. This algorithm begins to identify a set of offenders D?o f f from negative documents D  ? (Steps 1 to 5). It then calls PT Mining algorithm [18] to mine a set of patterns SP? for the offender set. Steps 8 to 11 perform classifying positive patterns pi to weak patterns WP and specific patterns SP by examining their relation with negative patterns npi, where pi is discarded if it is general (Step 10). Finally, both specific patterns and weak patterns are returned in Step 12.

Algorithm 1: Pattern Classification Input : A set of Positive Patterns SP+; a negative  document set D?; number of offenders K; Output: The sets of specific patterns SP and Weak  patterns WP respectively begin  Let T be a set of all size-1 patterns in D+;1 for each document nd ? D? do2  compute S(nd) according to Eq.(3);3  Let D? = {nd1,nd2, . . . ,ndm} in descending order;4 D?o f f = {ndi?ndi ? D?,S(ndi)> 0, i? K};5 SP? = PT Mining(D?o f f ),min sup) ;6 SP = /0, WP = /0;7 for each pattern pi ? SP+ do8  for each pattern np j ? SP? do9 if pi ? np j then SP+ = SP+?{pi};10 else if pi?np j ?= /0 then WP =WP?{pi};11 else SP = SP?{pi};  return SP and WP12 end

IV. RELEVANCE FEATURE EXTRACTION  A key question in pattern-based text mining is that what is the most desirable way to use patterns for solving a text min- ing problem. Although patterns are high-level features which capture semantic relationship between words, the direct use of frequent word patterns is ineffective in practice [17], [16].

The first first reason is that text patterns are too specific to appear in a document especially large patterns. The second one is the high dimensionality of frequent patterns, which often pose the efficiency challenge to a pattern-based model.

To improve the effective use of text patterns, we propose an alternative to use them for extracting low-level features (i.e., terms) which are more general than patterns for ranking a document?s relevance.

A. Term Weights by Specific Patterns  We first adopt the method for extracting low-level features (i.e., terms) based on frequent patterns proposed in [17] (also used in [21]). However, this method originally evaluates the term weights of documents based on their distributions in all closed patterns, which include many general ones with    high frequency. Such patterns often reduce the correctness of term weights. To eliminate the interference by the general patterns, we perform weighting terms by using all specific patterns (i.e., specific patterns and weak patterns).

Let Ri be a set of specific patterns in a positive document di ? D+, where i = 1 . . . ?D+?. For all terms t ? D+, the support (weight) of terms t can be evaluated according to the following equation.

weight(t) = ?D+?  ? i=1  ? t?p?Ri  Supr(p,di) ?p?Ri ?p?  (4)  where Supr(p,di) is the relative support of pattern p in document di and ?p? is its length.

B. Revision of Specific and General Features  Once relevant features were extracted, it is important to promote the weights to features which are specific for the positive documents to increase the discriminative power as well as decrease the weights of general features occurring in both the positive and negative documents.

To easily update the term weights, we partition all the extracted features into either specific features ST or general features GT based on their appearances in specific patterns SP and weak patterns WP. Let T S(WP) and T S(SP) be a set of terms in weak patterns WP and specific patterns SP respectively. We introduce the following rules to group the extracted features.

R.1 GT = {t?t ? D+, t ? T S(WP)?T S(SP)}  R.2 ST = {t?t ? D+, t ? (T S(SP)?T S(WP))?GT}  According to the classification rules, the rule R.1 is applied to group general features in weak patterns while the rule R.2 is used to extract specific features that can appear in specific and weak patterns.

Finally, we perform to revise the term weights according to the following equation:  w(t) = {  w(t)+?(t)?w(t) ; t ? ST w(t)???(t)?w(t)? ; t ? GT (5)  for all terms t ? D+, where ?(t) is the support function that computes the weight of term t based on its appearances in both positive and negative documents. The definition of the support function is as follows:  ?(t) = #n+t ?#n?t ?D+?  (6)  where #n+t and #n ? t are the numbers of positive documents  and negative documents containing the term t respectively.

According to Eq.(5), the weights of general features in GT  are declined based on their appearances in both positive and negative documents. The more the general features t appear in negative documents, the lower weights are assigned to the  features. Conversely, the weights of specific features in ST are automatically increased based on their appearances in positive documents.

To use the discovered knowledge for text search relevance, we apply them to a test document d according to the following equation:  weight(d) = ?T ?  ? i=1  w(ti)?? (ti,d) (7)  where T is a set of revised features, ? (t,d) = 1 if term t exists in the document d; otherwise ? (t,d) = 0. A high score assigned to the document d can imply that the document is relevant.



V. EXPERIMENTAL EVALUATION  A. Experimental dataset  The data set used in the experiments is Reuters Corpus Volume 1 (RCV1) [12]. This data collection consists of all and only English language stories proposed by Reuter?s journalists between 1996-08-20 to 1997-08-19, a total of 806,791 documents that cover very large topics and informa- tion. TREC (2002) has developed and provided 50 assessor topics for the TREC filtering track (i.e., R101 to R150) [15], aiming to building a robust filtering system. The TREC topics were developed by human assessors of the National Institute of Standards and Technology (NIST), called assessor topics.

According to [3], using at least 50 topics to evaluate an IR system is stable and sufficient for a good experiment.

Thus, this research uses RCV1 and the 50 assessor topics to evaluate the proposed approach, denoted Specific Pattern Mining (SPM).

B. Data Preprocessing and Measures  For each assessor topic, its data collection is split into two sets: a training set and a test set. All documents are marked in XML and some meta-data information. We remove all the meta-data information and perform a common basic text processing for all documents, including stop-words removal according to a given stop-words list and stemming terms using Poster Stemmer algorithm [9].

The effectiveness is measured by five standard IR metrics: The precision at the top 20 ranked documents (top? 20), F?=1 measure, Mean Average Precision (MAP), the break- even point (b/p), and Interpolated Average Precision (IAP) on 11?points. Precision (p), Recall (r), and F?=1 are calcu- lated by the following functions:  p = T P  T P+FP ,r =  T P T P+FN  ,F?=1 = 2pr p+ r  where T P is the number of documents the system correctly identifies as positives; FP is the number of documents the system falsely identifies as positives; FN is the number of relevant documents the system fails to identify.

C. Compared Methods  We group baseline methods into two main categories. The first category includes pattern-mining based methods. Some of them are based on closed sequential pattern mining, i.e., PTM [18] and PDM [17]. We also compare the performance of a well-known supervised pattern mining technique, dis- criminative patterns [4], because this kind of pattern mining directly results in a set of patterns, which are specific for a given data set. In the following, we briefly introduce the baseline methods.

? PTM [18]: This method mines all closed sequential  patterns from positive documents. Weights are attached to the closed patterns to score a document based on the total weight of discovered patterns in the document.

? PDM [17]: An effective method for term weighting based on frequent patterns. PDM originally uses closed sequential patterns mined in positive documents to weight low-level features for improving the topic filter- ing.

? Discriminative Patterns (DPs): This method was pro- posed to discover discriminative patterns for classifica- tion. It mines the classification patterns from a large collection of frequent patterns in a training set. As recommended by [4], we mine closed sequential patterns from positive documents to reduce redundancy and select the top closed patterns based on information gain (IG).

To compare the performance of DPs with PTM, we tried to use DPs to rank a document ranking rather than making binary decisions. For this purpose, weights are attached to the identified patterns based on their IG. A document d j is ranked according to the formula:  weight(d) = ?p?DP+ IG(p)?? (pi,d) (8) where ? (pi,d) = 1 if p? d;otherwise ? (pi,d) = 0.

We also deploy the results of DPs to weight terms in comparing with PDM and SPM. The underlying assumption is that specific patterns by DPs for a given topic would capture a set of important words in the topic.

For this purpose, we adopt the term weighting method proposed in [17] to extract low-level features based on DPs instead of closed patterns. Let DPi be a set of DPs in a positive document di ? D+, the support of terms obtained from the discovered patterns can be calculated as follows:  weight(t) = ?D+? ?  i=1 ?  t?p?DPi  Supr(p,di) ?p?DPi ?p?  (9)  for all terms t ? D+.

For all the pattern-based models, we set the minimum support threshold min sup = 0.2 (20% of the number of paragraphs in a document) since our experiments found that raising the threshold values results in lower performance since too many  patterns are eliminated. This value was also suggested in the experiments [18], [17].

For DPs, a threshold ? , defined as an instance coverage threshold, is used to select patterns. We tried many values to set the threshold for all the DPs models (Eq. (8) and Eq. (9)) Figure 2 illustrates the MAP performance of the DPs models associated with the threshold values.

Figure 2. Comparing the performance of DPs models respectively  The second category of the baseline approaches includes two state-of-the-art term-based methods in IR and text min- ing: ? Rocchio [7]: This supervised term weighting method  generates a Centroid for representing user profiles by ex- tracting terms from positive documents and performing to revise weights of the terms with negative documents.

The centroid c? of a topic can be generated as follows:  c? = ? 1?D+? ???d ?D+ ??d ?? ??d ?? ?? 1?D?? ???d ?D?  ??d ?? ??d ??  (10)  where ????d ?? be normalized vector for document d. ? and ? be a control parameter for the effect of relevant and non-relevant data respectively. According to [7], [2], there are two recommendations for setting the two parameters: ? = 16 and ? = 4; and ? = ? = 1.0. We have tested both accommodations on assessor topics and found the latter recommendation was the best one.

Therefore, we let ? = ? = 1.0.

? BM25 [10]: a well-known ranking function for scoring matching documents according to a given search query has been considered the state-of-the-art baseline in IR.

We use the BM25 function to estimate a weight of query term t extracted from positive document as follows:  W (t) = t f ?(k1+1) k1?((1?b)+b DLAV DL )+t f  ? log (r+0.5)  (n?r+0.5) (R?r+0.5)  (N?n?R+r+0.5) (11)  where N is the total number of training documents; R is the number of positive documents; n is the number of documents which contain term t; r is the number of positive documents which contain term t; t f is the term frequency; DL and AVDL are the document length and average document length, respectively; and k1 and b are    the experimental parameters. We use the BM25 with the parameters tuned in [21] (i.e.,k1 = 1.2 and b = 0.75).

For each topic, we choose top 150 terms in the positive documents based on t f ? id f values for all the term-based models.

D. Comparing against Pattern-mining based Models  Table I compares the performance of SPM against several baseline models. We can see that SPM is the best performing method on all assessor topics over the standard measures.

One interesting point revealed in this table is that closed patterns by DPs outperform closed patterns by PTM while the average total number of DPs used in an assessor topic (#F+) is less than by 50%. The improvements are also consistent in comparing with PTM (Seq. Ptrns). The results confirm that redundant and noisy patterns can reduce the effectiveness of pattern mining. However, the precision of DPs at high recall levels performs worse than PTM with closed patterns. This is suggested that DPs still miss some important patterns.

Another interesting point is that all the pattern-based models that use terms (i.e., PDM, DPs (term weights), and SPM) largely improves the performance in comparing with the models that use word patterns. This can be explained by the fact that terms are a basic unit of language that could be found in any document. Furthermore, it is interesting to notice that using patterns to weight terms can be considered an attractive approach to solve the low precision problem of frequent text patterns.

Let us compare the performance of DPs (term weights) with PDM. We can see that the DPs model slightly improve the overall performance in comparing with PDM. The average total number of terms by DPs is much less that that of PDM.

This illustrates that DPs can capture largely important words for these topics as well as eliminate many noisy words.

We also compare the performance of SPM with DPs (term weights). We can see that SPM achieves the best perfor- mance. There are two main reasons for the improvements.

The first reason is that DPs are based on a threshold (? ). As a consequence, it may miss some important words, caused by filtering out patterns which do not satisfy the threshold.

Conversely, SPM can benefit from larger vocabulary size, caused by carefully eliminating noisy patterns. The second reason is that DPs cannot deal with weak specific patterns formed by adding irrelevant terms. Such terms can increase the risk of irrelevant documents retrieved. With a weight revision method in SPM, the effect of general features could be largely reduced while the weights of specific features are promoted to increase their discriminative power. Our results also confirm that the best improvements are still obtained at the high recall levels (Figure 3), and are statistically significant (Table II).

Figure 3. Comparing the performance of SPM and pattern-based models  Figure 4. Comparing the performance of SPM with classical IR models  E. Comparing against Classical IR Models  As shown in Table I, we found that all the term-based models outperforms the models that use high-level patterns, where the Rocchio method perform over BM25 method for this data collection. This confirms that keywords remain important features for solving a text retrieval and mining problem. However, the performance results of comparison between the Rocchio and SPM demonstrate that specific fea- tures extracted from frequent word sequences whose semantic information is rich are more effective than the ones extracted from low-level documents because they frequently occur in the specific contexts of positive documents (i.e., sentences and paragraphs). Furthermore, the average total number of terms extracted by SPM is much less than the number of terms obtained by the traditional term-based methods.

The plotting of precision on precision-recall curve for the SPM and all the term-based methods on the assessor topics is illustrated in Fig. 4.



VI. CONCLUSION  In this paper, we have deal with the quality issue of discovered relevant features in text documents for describing user interests or preferences information. We present a novel pattern mining approach which mines patterns from positive and negative feedback and then classifies them into clusters    Table I COMPARING THE PERFORMANCE OF SPM AND SEVERAL PATTERN MINING-BASED METHODS  Methods top-20 MAP b/p F?=1 #F+  SPM 0.545 0.489 0.468 0.464 94.72 DPs (term weights Eq.(9)) with ? = 10 0.492 (+10.77%) 0.454 (+7.71%) 0.432 (+8.33%) 0.442 (+5.21%) 32.16  PDM 0.496 (+9.88%) 0.444 (+10.14%) 0.430 (+8.84%) 0.439 (+5.69%) 154.82 DPs (Eq. (8)) with ? = 15 0.445 (+22.47%) 0.385 (+27.01%) 0.395 (+18.48%) 0.397 (+16.88%) 51.88 PTM (Closed Seq. Ptrns) 0.406 (+34.24%) 0.364 (+34.34%) 0.353 (+32.58%) 0.390 (+18.97%) 199.16  PTM (Seq. Ptrns) 0.401 (+35.91%) 0.361 (+35.46%) 0.343 (+36.54%) 0.385 (+20.52%) 390.18 Rocchio (? = 1.0 and ? = 1.0) 0.490 (+11.22%) 0.440 (+11.14%) 0.411 (+13.87%) 0.435 (+6.68%) 150.00 BM25 (k1 = 1.2 and b = 0.75) 0.469 (+16.20%) 0.418 (+16.99%) 0.420 (+11.43%) 0.387 (+19.90%) 150.00  Table II p?VALUES FOR THE BASELINE METHODS COMPARING WITH SPM IN  ALL THE ASSESSOR TOPICS  Model top-20 MAP b/p F?=1 DPs (term weights) 0.0112 0.0017 0.0065 0.0018  PDM 0.0100 0.0025 0.0023 0.0026 Rocchio 0.0030 0.0036 0.0034 0.0074 BM25 0.0001 0.0005 0.0001 0.0008  to find specific patterns as well as remove noisy ones for a given topic. We also apply a novel pattern deploying strategy to improve the performance of frequent patterns in text. We evaluated the proposed approach by using it to discover high-quality features in relevance feedback for improving information filtering. Our results on RCV1 data collection and TREC filtering topics confirm that the best improvements are obtained by our approach compared to state-of-the-art term-based methods and pattern-based ones.

