PARALLEL FREQUENT ITEMSETS MINING ALGORITHM WITHOUT  INTERMEDIATE RESULT

Abstract: Mining association rules from large databases is an  important problem in data mining. FP-growth is a powerful algorithm to mine frequent patterns and it is non-candidate generation algorithm using a special structure FP-tree.  In order to enhance the efficiency of FP-grown algorithm, propose a novel parallel algorithm PFPTC to create sub FP-trees concurrently and a FP-tree merging algorithm called FP-merge which can merge two FP-trees into one FP-tree.

Also propose a new efficient algorithm QFP-growth , which can avoid bottleneck of FP-growth in generating a huge number of intermediate result .

Keywords: Data mining; association rules; parallel algorithm;  FP-tree  1. Introduction  A fundamental component in data mining tasks is finding frequent patterns in a given dataset[1,2,3]. Frequent patterns are ones that occur at least a user-given number of times (minimum support) in the dataset. They allow us to perform essential tasks such as discovering association relationships among items, correlation, sequential pattern mining[4]. Algorithms proposed in [1, 2, 4, 5, 6, 9] find all frequent sets in a dataset. The Apriori algorithm [1] accomplishes this by employing a bottom-up search. It generates candidate sets starting at size 2 up to the maximal frequent set size. At each pass, it determines which candidates are frequent by counting their occurrence. Due to combinatory explosion, this leads to poor performance when frequent pattern sizes are large. To avoid this problem, some algorithms output only maximal frequent sets [2, 3, 4].

Pincer-Search [4] uses a bottom-up search along with top-down pruning. Max-Miner [2] uses a bottom-up search with a heuristic to try to identify frequent sets as early as possible. Even though performance improvements may be substantial, maximal frequent sets have limited use in terms of association rule mining. A complete set of rules cannot  be extracted without support information of frequent subsets.

Almost all previous algorithms use the candidate set generate-and-test approach. FP-tree based mining [9] is an exception. It has performance improvements over Apriori since it uses a compressed data representation and does not need to generate candidate sets. However, FP-tree-based mining uses a complicated data structure and performance gains are sensitive to the database size.

In this paper, we propose a novel parallel algorithm to create sub FP-trees concurrently and a FP-tree merging algorithm called FP-merge which can merge two FP-trees into one FP-tree.

2. FP-growth algorithms  Han et al. proposed a data structure called frequent pattern tree or FP-Tree [9]. FP-growth mines frequent itemsets from FP-Tree without generating candidate frequent itemsets. FP-Tree is an extension of prefix tree structure. Only frequent items have nodes in the tree. Each node contains the item?s label and its frequency. The paths from the root to the leaves are arranged according to the support of the items with the frequency of each parent is greater than or equal to the sum of its children?s frequency.

The construction of FP-Tree requires two data scans. In the first scan, the support of each item is found. In the second scan, items within transactions are sorted in descending order according to the support of items. If two transactions share a common prefix, the shared portion is merged and the frequencies of the nodes are incremented accordingly.

Nodes with the same label are connected with an item link.

The item link is used to facilitate frequent pattern mining.

In addition, each FP-Tree has a header that contains all frequent items and pointers to the beginning of their respective item links.

Algorithm 1 (FP-tree construction)[9] Input: A transaction database DB and a minimum support      threshold ?.

Output: Its frequent pattern tree, FP-Tree Method: The FP-tree is constructed in the following steps.

1. Scan the transaction database DB once. Collect the set of frequent items F and their supports. Sort F in support descending order as L, the list of frequent items.

2. Create the root of an FP-tree, T, and label it as ?null?, for each transaction in DB do the following. Select and sort the frequent items in transaction according to the order of L.

Let the sorted frequent item list in transaction be [p|P], where p is the first element and P is the remaining list. Call insert_tree ([p|P], T).

Function insert_tree ([p|P], T) {If T has a child N such that N.item-name = p.item-name Then increment N?s count by 1; Else do {create a new node N; N?s count = 1; N?s parent link be linked to T; N?s node-link be linked to the nodes with the same item-name via the node-link structure;} If P is nonempty, Call insert_tree (P, N).

}  FP-growth partitions the FP-Tree based on the prefixes.

FP-growth traverses the paths of FP-Tree recursively to generate frequent itemsets. Pattern fragments are concatenated to ensure all frequent itemsets are generated properly. In this way, FP-growth avoids the costly operations of generating and testing of candidate itemsets.

As pointed out by the authors of FP-Tree, no algorithm works in all situations. The fact holds true for FP-Tree when the dataset is sparse. When the data is sparse, the compression achieved by the FP-Tree is small and the FP-Tree is bushy. As a result, FP-growth would spend a lot of effort to concatenate fragmented patterns with no frequent itemsets being found.

Algorithm 2 (FP-growth: Mining frequent patterns with FP-tree by pattern fragment growth)[9].

Input: FP-tree, and a minimum support threshold ? .

Output: The complete set of frequent patterns.

Method: call FP-growth(FP-tree, null).

Procedure FP-growth(Tree, ?) { if Tree contains a single prefix path P // Mining single prefix-path FP-tree  then for each combination (denoted as ?) of the nodes in the path P do generate pattern ?  ?  ?  with support = minimum support of nodes in ?; else   for  each item ai in Q, in the header of Tree  do { // Mining multipath FP-tree generate pattern ?  = ai ?  ?  with support =  ai .support; construct ??s conditional pattern-base and then ??s conditional FP-tree Tree? ; if Tree? is nonempty then call FP-growth(Tree?, ?); }  3. Parallel FP-tree Constructing Algorithm  As described above, it is obvious that Constructing FP-tree is the key step in FP-growth algorithm, FP-tree contains compressed message of frequent itemsets, it is easy to mining frequent itemsets from FP-tree. To construct FP-tree, we must scan data base twice, one for creating 1-itemset and one for build FP-tree. To mine useful information from database effectively, we needs to solve efficiency problem of mining,  when data quantity very large,  efficiency of mining algorithm become the key of mining problem, to increase efficiency of mining algorithm, developing parallel algorithm is an effective policy.

In this section we present a parallel algorithm PFPTC to construct FP-tree, and an algorithm to merge sub FP-trees.

First, an initial scan of the database identifies the frequent 1-itemsets. In order to enumerate the frequent items efficiently, then we divide the datasets among the available processors. Each processor is given an approximately equal number of transactions to read and analyze. As a result, the dataset is split in n equal sizes.

Each processor enumerates the items appearing in the transactions at hand. After enumeration of sub occurrences, a global count is necessary to identify the frequent items.

This count is done in parallel where each processor is allocated an equal number of items to sum their sub supports into global count. Finally, in a sequential phase infrequent items with a support less than the support threshold are weeded out and the remaining frequent items are sorted by their frequency.

To build sub FP-trees requires a second complete I/O scan from the dataset where each processor reads the same number of transactions as in the first phase. Using these transactions, each processor builds its own frequent pattern tree that starts with a null root, but need not to build head table and node link.

For each transaction read by a processor the item list is sorted in descending order according to their frequency.

These sorted transaction items are used in constructing the sub FP-Trees as follows: for the first item on the sorted transactional dataset, check if it exists as one of the children of the root. If it exists then increment the support for this node. Otherwise, add a new node for this item as a child for the root node with 1 as support. Then, consider the current      item node as the newly temporary root and repeat the same procedure with the next item on the sorted transaction. We need not to create head table and same node link for sub FP-Trees because it is only a local part of database, we can create head table and same node link after all sub FP-Trees are merged into on FP-tree.

Algorithm 3 (PFPTC: Parallel FP-tree Constructing Algorithm) Input: A transaction database DB and a minimum support threshold ?.

Output: Its frequent pattern tree, FP-Tree Method: The FP-tree is constructed in the following steps.

Suppose there are n processor p1, p2,?,pn; Divide database DB into n part DB1,? ,DBn with same size; Processor pj  scan DBj once.  And create total set of frequent items F and their supports. Sort F in support descending order as L.

for ( j = 1; j?n; j++) do ( concurrently) { processor pj  parallel scan DBj, construct FP-treej, do not create head table and node link; } while(n>1) do for ( j = 1; j?n; j=j+2) { processor pj parallel call FP-merge(FP-treej, FP-treej+1, int(j/2)+1 ); n=n/2;} Create head table and same nodes link for FP-tree1; Return FP-tree1; End; Algorithm 4 (FP-merge FP-tree merging algorithm, do not create head table and node link in result FP-tree ) Input: Two sub FP-trees Output: a merged FP-tree named FP-tree<result> Method: call FP-merge(FP-tree1, FP-tree2, result) Procedure FP-merge(FP-tree1, FP-tree2) { while FP-tree2 !=NULL, do { retrieve one item train in FP-tree2 from leaf to root; n=leaf?s count; Let the item train be [p|P], where p is the last element and P is the frontal list.

Call merge-insert ([p|P], FP-tree1, n).

Remove the item train from FP-tree2; } rename FP-tree1 as FP-tree<result>; } Algorithm 5 (merge-insert: insert a items train into FP-tree) Input: item trains, FP-tree node, count of trains Output: a merged FP-tree Method: call merge-insert (items train, node, support) Procedure merge-insert ([p|P], T, num) {If T has a child N such that N.item-name = p.item-name  N?s count= N?s count+num; Else do {Create a new node N; N?s count = num; N?s parent link be linked to T; } If P is nonempty, Call merge-insert (P, N, num); }  To explain the algorithm, we use an example with the transactions shown in Table 1. Let the number of available processors be 2 and the minimum support threshold set to 3.

Figure 1 shows two sub FP-trees: FP-tree1 and FP-tree2.

Figure 2 to Figure 4 show the merging procedure of FP-tree1 and FP-tree2.

Table 1. An example database DB  TID Items Ordered Items SubDB T001 f, a, c, d, g, i, m, p f, c, a, m, p DB1 T002 a, b, c, f, l, m, o f, c, a, b, m DB1 T003 b, f, h, j, o, p f, b, p DB1 T004 b, c, k, s, p c, b, p DB1 T005 a, f, c, e, l, m, n f, c, a, m DB2 T006 p, b, c c, b, p DB2 T007 c, f f, c DB2 T008 f, c f, c DB2    Figure 1. Two sub FP-trees: FP-tree1 and FP-tree2.

Figure 2. After moving (macf)1 from FP-tree2 to  FP-tree1   Figure 3. After moving  (cf)2 from FP-tree2 to  FP-tree1   Figure 4. After moving (pbc)1 from FP-tree2 to  FP-tree1  4. QFP-growth: mining frequent pattern without conditional FP-trees construction  FP-growth algorithm must generate a huge number of conditional FP-trees recursively in process of mining, it may take too much time and space. Can we avoid conditional FP-trees generation in frequent pattern mining?

To solve this problem, we develop QFP-growth, a extended FP-growth method for frequent pattern mining from FP-tree.

The algorithm is described bellow.

Algorithm 6 (QFP-growth: Mining frequent patterns with FP-tree by pattern fragment growth).

Input:  FP-tree , and a minimum support threshold ? .

Output: The complete set of frequent patterns.

Method: call QFP-growth(root, null).

Procedure QFP-growth(ROOT Q, FP_prefix ?) {for each item ai in Q, in top down order { // Mining multipath FP-tree sum all count of ai under Q  into ai .support; if ai .support>=? then { generate pattern ?  = ?  ?  ai  with suppor =ai .support; construct temp_root with ai?s child node; if temp_root has child then call QFP-growth(temp_root, ?); } if sum of count of temp_root?s child>=?  then call QFP-growth(temp_root, ?); } }  The improvement of QFP-growth algorithm:  1. Instead of building Conditional pattern-base and Conditional fp-tree, QFP-growth algorithm simply construct a dynamic temporary root, so it can improve performance and efficiency.

2. In FP-growth algorithm, ?generate pattern ? = ai ? ? with support = ai .support?; but in QFP-growth algorithm, ?generate pattern ? =? ? ai  with suppor =ai .support?, The frequent patterns are generated in order, so they can be used expediently. For example, By using FP-growth algorithm, frequent patterns mined from FP-tree in figure 5 are: f5, c5, fc4,a4, fa4, ca4, fca4, b4, cb3, m3, fm3, fcm3, fcam3, fam3, cam3, cm3, am3, p3,cp3. There is no order in the frequent patterns serial. And By using QFP-growth algorithm, the frequent patterns are: f5,fc4,fca4,fcam3,fcm3,fa4,fam3,fm3,c5,ca4,cam3,cb3, m3, cp3, a4, am3,b4,m3,p3. The frequent patterns serial is ordered descending by head table of FP-tree.

3. To avoid more Conditional FP-tree constructing, FP-growth algorithm have to check whether a sub-tree is a single path tree, But in QFP-growth , because of no conditional FP-tree constructed, there is no reason to      differentiate single path tree, so the algorithm is simplified.

4.The QFP-growth can be called  only in condition of  sum of count of temp_root?s child> minimum support this can reduce the call number of procedure evidently  Figure 5 to 7 show temporary root construction of example database.. Executing procedure of QFP-growth is showed in table 4.

Figure 5 temporary root after generating f4   Figure 6 temporary root after generating fc4   Figure 7 temporary root after generating fca3  5. Experiments and Results  The goal of the experiments is to find out the extent of different dataset properties that could affect the performance of QFP-growth and PFPTC algorithms and the relative performance compares with FP-growth algorithm.

Datasets are generated with the data generator by IBM QUEST. FP-growth is provided by the original authors.

Experiments are performed on a Pentium 4 1.8GHz PC with 512Mb RAM running on Window XP. All programs are complied with the same compiler. Experimental results show that QFP-growth is competitive. It is efficient and scalable for mining large databases or data warehouses. See figure 8 to 10.

Figure 8. Scalability of QFP-growth with respect to support  with single run       Figure 9. Memory Comparison           500k 1000k 1500k 2000k  Number of trasanctions  T i m e s ( S )  serial 4proc  8proc 16proc   Figure 10. Experiments result of PFPTC  6. Conclusion  In this paper, we have introduced an efficient parallel implementation of an FP-Tree constructing algorithm and an improved method QFP-growth for constructing frequent patterns from FP-tree. QFP-growth can generate frequent patterns without conditional pattern-base and conditional FP-tree generation, and the frequent patterns are generated in order. Our future research work is to use the method into implementation of SQL-based, highly scalable FP-tree structure, constraint-based mining of frequent patterns, sequential patterns, max-patterns, partial periodicity and other interesting frequent patterns mining.

