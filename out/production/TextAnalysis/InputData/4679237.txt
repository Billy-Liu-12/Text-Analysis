A Data Mining Model in Knowledge Grid

abstracted characteristics of heterogeneous data is from metadata information (MDI). MDI is the basis of information conversion between heterogeneous platforms. The value of MDI in DM-GRID is saved in metadata files using XML (Extensible Markup Language). Catalogue service technology LDAP (Lightweight Directory Access Protocol) can also be used to make metadata catalogue service, but under this condition particular storing pattern supported by LDAP will be needed to save metadata. Metadata catalogue shows a united virtual view of grid resources to terminal user. In fact, resources are accessed by integrated agent service and protocol conversion fixture. So metadata catalogue service is most important to realize resources decomposing and conversion from virtual to physical. It is because metadata catalogue service provides resources conversion that terminal user can access resources transparently in DM-GRID.

3) Broadcasting service.  The rules, regularities and patterns discovered from local sources of data are not always correct in other sources of data. Broadcasting service is in charge of communication among many different heterogeneous sources of data to discover the regularities that are globally useable.

4) Integrated agent service. It provides data access service to terminal user. Storage resources agent and integrated accessing agent are two functions of integrated agent service. Storage resources agent provides united accessing interface for advanced application to access distributed and heterogeneous storage resources and data duplications. Integrated access agent combines and computes  access results from different sources of data according to pre- determined rules based on storage resources agent.

5) Encapsulation fixture. It is also called protocol conversion fixture. Encapsulation fixture can convert requests from integrated agent into data access protocol supported by storage system.

This approach benefits from "standard" grid services that are more and more utilized and offers an open parallel and distributed knowledge discovery architecture that can be configured on top of grid middleware in a simple way.



III.  ACCESS PROCESS OF DM-GRID  The DAS (Data access service) is responsible for the search, selection (data search services), extraction, transformation and delivery (data extraction services) of data to be mined. On the basis of the user requirements and constraints, the DAS automates (or assists the user in) the searching and finding of data sources to be analyzed by the DM tools. The extraction, transformation and delivery of data to be mined are based on the Globus GASS (Global Access to Secondary Storage) services and also use the KDS (Knowledge Directory Service). When useful data are found, data mining tools can require some transformation, whereas the user requirements or security constraints can require some data filtering before extraction. These operations can be usually done after the DM tools selection.

Now we introduce the access process of DM-GRID.

1) Terminal user can customize mining task and bring  forward access request from united programming interface.

Storage resource agent parses the request and submits the result to metadata catalogue service for future processing.

2) Metadata catalogue service check the validity of request. If the request is valid, system will decompose the request to get interrelated access information including logical dataset, combined rules, safety-attribute and so on. Then metadata catalogue service selects appropriate entity set and all the information of interrelated storage system according to restrictions of that access information.

3) Task scheduler. It can establish the query task sequence of this access according to the information from metadata catalogue service. Then each query task will be delivered to storage system and executed through encapsulation fixture of corresponding data storage system.

4) If the task execution in local storage system is over, broadcasting service will broadcast the execution result to other storage systems in order to get the global query result.

5) Integrated access agent collects all the query results and integrates these results according to combination rules.

The integrated results will be returned to terminal user.



IV.  EXPERIMENTAL RESULTS AND DISCUSSION  A. Experimental Results PC cluster is ideal environment of experiment data  mining model in knowledge grid because of its advantage of performance price ratio [20].

Figure.2 The relation of execution time and number of nodes  (n=3,4,5,6;  s=3%)  The mining association rules are essentially to discover  association rules that have large support in large databases.

The concern of mining association rules is decomposed  into the following two steps: 1) Discover the large itemsets, i.e. The sets of itemsets  that have transaction support above a pre-determined minimum supports.

2)  Use the large itemsets to generate the association rules for the database.

The following example is an algorithm of association rules mining, Aprior, programmed with C language. The experimental environment has three clusters and six sources of data, where each cluster has two hosts. The databases used in our experiment are composed of synthetic data with 200,000 tuples and 1,000 items totally. We select different nodes of DM-GRID to participate experiment. The performance is shown in Figure 2.

B. Discussion From the experimental results, we can see that  computational efforts, communication traffic and their relationship are very important in the task processing of PC computing nodes. This is because that with increasing of CPU number, the utilized ratio and workload decreased accordingly, at the same time, expenditure of communication traffic increased rapidly. Since grid system subject by the principle of wooden-bucket, the high-performance computing nodes have to wait the low-performance components, which lead to a drop down of the whole performance.

Though grid is a dynamic infrastructure which requires dynamic updates and grid user?s request may arrive any time (may not be accepted by resource), new user?s job request will not change the knowledge grid. This is due to the fact that proportional resource sharing mechanism of Globus always allocates all the resource available capacity one-off to current competing users.

The Grid services are shifting from generic computation- oriented services to high level information management and knowledge discovery services. The DM-GRID system is a component for devising and providing those services. Whereas sharing and inheriting knowledge can be challenging [21]. The knowledge grid integrates and completes the data grid services by supporting distributed data analysis and knowledge  discovery and management services that will enlarge the application scenario and the community of grid computing users. Further, it will be a mechanism that can synthesize knowledge from data through mining and reference methods and enable search engines to make references, answer questions, and draw conclusions from masses of data [22]. The sciences rely on computers, but the benefits are two-way; each is driving the other forwards [23].



V. CONCLUSION  This paper has attempted to formulate data mining model in knowledge grid with the help of software architecture approach and proposed a data mining strategy. Researchers have shown great interest in grid computing. Grid is a distributed, heterogeneous, autonomic and synergetic environment. In this paper, we design DM-GRID based software architecture of a novel infrastructure for distributed and high-performance data mining in Grid environments. DB- GRID aggregates heterogeneous systems to form high- performance computing and mining environment, supports transparent access sources of data. The result of mining association rules shows that DB-GRID is feasible. Only this represents a first step, correlative technology gaps require further study and development.

