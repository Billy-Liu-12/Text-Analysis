<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">2004 IEEE

Abstract - In this work, we propose an adjustable step- size data-mining algorithm to discover Adaptive-Support Association Rules (ASAR) [7] @om data sets. Adaptive- support association rules are constrained association rules with application to collaborative recommendation systems. To discover association rules for recommendation systems, minimum conference and a specific target item in association rules are usually assumed and no minimum support is specified in advance.

Based on size monotonociry of associatian rules, i.e., the number of association rules decreases when the minimum support increases, on efJicient algorithm using adjustable step size for finding minimum support and therefore adaptive-support association rules is presented.

Experimental comparison with the fued  step size iterative approach shows that our proposed technique requires less computation, both running time and iteration steps, and will alwaysfind a corresponding minimum support.

Keywords: data mining, adaptive-support association rules, collaborative recommendation system.

1 Introduction Data mining has recently attracted tremendous amount of attention in the database, artificial intelligence and machine learning research because of its wide application in many areas, such as market basket analysis, prediction, decision support, financial forecast, world wide web and collaborative recommendation.

Collaborative recommendation (sometimes known as collaborative filtering) is a process by which information on the preferences and actions of a group of users is tracked by a system which then, based on the patterns it observes, tries to make useful recommendations to individual users. Many techniques have been proposed for collaborative recommendation over the past decade.

In addition to the classical linear correlation-based method [l  11, there are Bayesian classifier and Bayesian network model [SI, neural networks paired with feature reduction techniques [4], graph-theoretic approach [2], and data mining approach [7,8]. For the data mining approach, constraint-based association rules such as class association rules [SI and adaptive-support association rules [7] techniques have been proposed. In this work, we are particularly interested in improving the efficiency of discovering ASARs for collaborative recommendation systems.

For a given data set, the discovery of ASARs assumes that a target item, a specified minimum confidence and a desired range for the number of rules are given. It proceeds to discover association rules with the target item in the beads of the rules. Such that the number of rules is in the desired range and the rules have the highest possible support. In [7], an algorithm called ASARM is proposed to discover this type of rules. The algorithm is a variant of the CBA-RG [SI and therefore of the Apriori algorithm [l]. It differs from those two  algorithms in that frequent itemsets and rules are generated simultaneously. However, in the process of calculating minimum support in order to obtain desired number of rules, the ASARM algorithm uses a fixed step size iterative approach, which may not be quite efficient and might not he able to find the minimum support for    and might not he able to find the minimum support for some desired range of association rules. In this work, we propose an adjustable step size approach to calculate the minimum support and therefore ASARs. Experimental comparison with the fixed step size adjustment approach shows that OUI proposed technique requires less computation, both running time and iteration steps, and will always find a corresponding minimum support.

The rest of our paper is organized as follows.

Section 2 reviews the problem of the discovery of ASARs.

Section 3 presents the proposed data-mining algorithm.

Section 4 shows the numerical comparison with the fixed step size approach. A conclusion is given at the end of paper.

2 Problem Statement This section reviews the basic definition and terminology of association rules and adaptive-support association rules.

* 0-7803-8566-7/04/$20.00 0 2004 IEEE.

2.1 Mining of Association Rules The problem of mining association rules was introduced in [ l ] .  Let I = {i,, i,;.., i, } he a set of literals, called items. Given a set of transactions D, where each transaction. T is a set of items such that T I., an association rule is an expression X 3 Y where x E I ,  Y E  I ,  and x n Y = (. The X and are called respectively the body and head of the rule. An example of such a rule is that 90% of customers buy hamburgers also buy Coke. The 90% here is called the confidence of the rule, which means that 90% of transaction that contains x also contains Y.  The support of the rule is the percentage of transactions that contain both X and Y ,  In other words, the confidence of a u l e measures the degree of the correlation between itemsets, while the support of a rule measures the significanci: of the correlation between itemsets. The problem of miring association rules is to find all rules that satisfy a user- specified minimum support and minimum confidence.

As an example, assuming that we have a data set of visited web page as listed in Table I .  Given minimum support of 20% and minimum conference of 80%, the 28 association rules that satisfy these thresholds are listed in Table 2.

Table 1. Sample data set User ID 1 Visited web pages 1 I hd I j . l  - 4 " I -1 VRAF 2.2 Adaptive-Support Association Rules The problem of mining adaptive-support associalion rules was introduced in [7] .  It is a constrained associalion rule intended for collaborative recommendation systems.

For recommendation, a specific value of target item rnay he assumed. This target item is the item that will be recommended to users in a collaborative recommendation system. In addition, it is not necessary to mine an arbitrarily large rule set containing all rules above a minimum support level. In fact, a desired number (or ~ range) of rules is usually specified together with a specific given minimum confidence value, wherein no minimum support is specified. Therefore, the problem of mining ASARs can be described as follows: Input: Dataset T , targetltem, minconfidence, Nmin, ", Output: A set S of adaptive-support association rules such that the head of each rule is targetltem, the number of rules in S is in [N,,,;., Nmm], and the confidence of each rule is greater than or equal to minconfidence    to minconfidence Notice that the number of rules for a given minconfidence may he less than the desired range of rules [N,;,,, N,,]. In this case, all rules found will he output.

Furthermore, no rule outside S with confidence greater than or equal to the minconfidence has a higher support than a rule in S.

As an example, given a data set as in Table I ,  a target item V, a minimum confidence of 80%, and desired range of rules [5,10], the adaptive-support association rules that can be found are shown in Table 3.

Table 3. The adaptive-support association rules found from Table 1 3 The Proposed Algorithm This section describes the proposed algorithm, based on adaptive adjustment of minimum supports, to discover ASARs more efficiently. The adjustment of minimum supports in [7] has fixed step size, for example 1%. Based on the property that the number of rules decreases monotonically as support increases, we adjust the minimum supports based on the iterative Secant concept. Secant method is an iterative approach for finding the roots of non-linear functions. It assumes that the derivative of the function is unknown. Hence, two initial points are required to approximate the derivative of a function in looking for the root of an unknown function.

Depending on the midpoint of zero and support of target item, if the midpoint is assumed as the minimum support and it produces association rules that are greater than N,,  , then the midpoint and the support of target item are assumed to be the initial points. Otherwise, zero and the midpoint are assumed to he the initial points. If the number of association rules generated by the current initial minimum support lies in the desired range, ASARs are found. If the number of rules is not in the desired range, a third point is calculated from the first two points.

Then the second and third points are used as the new initial points. This process repeats itself until the correct minimum support is found. The proposed Secant-based algorithm is described as follows: Input: Output: Mfminimum support), ASARs 1. Right = support count of targetltem ; 2. Left = 0 ; 3. Mid = (Leff+Right)/2; 4. N = AR - F T ( T ,  targetltem, minCond, Mid) ; 5 .  N, =(Nmi, +N,,,)/2 ; 6.  if ( N E  (N,,, NmaX) )  returnMid; 7. if (N &gt; Nma) { 8. x,, =Right; 9. x , = M i d ; T, targetltem, minconjdence, N, N,, 10. } 11. if (N &lt; N,,,) { 12. x,, =Left; 13. X, = M i d ; 14. } 15. while (N gL (Nmin, NmaX)) { 16.

17.

18.

x2 = (x, , N I  - N ,  x,, - X, .No i N ,  . x,)/(N, -No 19. N = AR - FT(T,targetZtem, minCond, x 2 ) ; 20. if N = NI then xI = x2 21. e l s e i f N = N , , t h e n x , , = x , 22.

23. } 24. return x2; No = AR - F T ( T ,  targetltem, minCond, x,,) ; N I  = AR - F T ( T ,  targetltem, minCond, x,); else xg = xI , xl = x 2 4 Experimental Results    4 Experimental Results To show the efficiency of the proposed Secant-based technique for the discovery of adaptive-support association rules, we have implemented the algorithm in section 3 and compare it with the fixed step sire approach adopted in [7]. In our implementation, the FTAR in line 4 of the algorithm is an Apriori-based association rule module with fixed target item. For the fixed step size approach, we have implemented a program similar to ASARMl algorithm in [7]. But a major difference is that we do not generate frequent itemsets and rules simultaneously.

All programs are written in C and run on the same 1.7 GHz Pentium 4 PC with 512 MB of memory running Red Hat Linux operating system release 8.0.

We ran the algorithms on a data set called Assocmdb included in the XpertRule Miner software, which has two tables: Basket-Data.xls and Basket-Data-Test.xls. The former has 5,000 records of transactions dataset and the later has 4,970 records. In this dataset, there are IO different items and the average length of itemsets is 3.5135, with maximum itemset length 6 and minimum itemset length 1.

Figures 1 and 2 show the running time and number of steps required for desired rule range [ I ,  IO] respectively for both approaches. It can be observed that for small data sires, the performance of either approach is about the same for small range of rules. But the proposed Secant-based approach is more efficient when data size gets larger.

Compison  of Fixed and Secanr (N" time) Desiredmnge [l,101 - E 2wo I I I Data size (loo0 records) 1 Figure lRunning Time Comparison of Fixed and Proposed Secant Approaches for Desired Rule Range [I , Comparison of Fixed and Secant ("Jesteps) Desired m e  l1,101 2 20 01 10 z 1 2 3 4 S 6 7 8 9 10 Data sire (1wO records) Compuison ofFined and Secant (mn time) Desired range 120,301 - d 3WO 1 d 2000 .I loo0 E 1 - E o 1 2 3 4 5 6 Data size (5CQ records) a I Figure 2Number-of-Step Comparison of Fixed and Proposed Secant Approaches for Desired Rule Range [I , Figures 3 and 4 show the running time and number of steps required for desired rule range [ZO, 301 respectively for both approaches. When the desired range of rules is large, it can be observed that !he performance of Secant-based approach is obviously more efficient for any data sizes. In fact, the experiments have been cacied out on various data sizes up to 100,000 records with similar effects.

Figure 3Running Time Comparison of Fixed and Proposed Secant Approaches for Desired Rule Range 120,    1 Compuison oiFired and Secant (No-steps) Desired ran% 120,301 I I 0 '  I I I 2 3 4 5 6  Data size (SW records) I Figure 4Number-of-Step Comparison of Fixed md Proposed Secant Approaches for Desired Rule Range 120, In some cases, fixed step size approach might not be able to find the minimum support corresponding to a desired range of rules. This is due to  the fact that the number of rules corresponding to two consecutive guesses of minimum supports lie outside of the desired range. One is smaller than Nmi, and the other is greater than Nmm. To resolve this problem, step size must be refined in fixed step approach. However, no such problem occurs for the proposed Secant-based approach.

5 Conclusion Adaptive-support association rules are constrained association rules with application to collaborative recommendation systems. In this work, we have proposed an eficient data-mining algorithm for the discovery of adaptive-support association rules. Simulation results have demonstrated that its performance is more efficient than the fixed step size approach adopted in [7]. However, our implementations d o  not generate frequent itemsets and association rules simultaneously as in [7]. This may require further investigation for performance comparisons.

