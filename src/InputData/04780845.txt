Mining Negative Sequential Patterns for E-Commerce Recommendations

Abstract   Sequential patterns in customer transactional databases are commonly mined for E-Commerce recommendations. In many practical applications, the absence of certain item-sets and sequences could have important implications. Mining frequent sequences comprising not only the occurrence but also the absence of certain sequences will increase the accuracy of product recommendations. A sequential pattern containing at least one absent itemset is called a negative sequential pattern. In this paper, we formulate the problem of negative sequential pattern mining by introducing practical constraints and propose an algorithm called PNSP for the mining. The discovered patterns can then be more interesting and effective to use. The experimental results show that PNSP may discover negative sequential patterns for practical E-commerce applications.

1. Introduction   Sequential pattern mining is an important problem that finds out temporal relationships among item-sets in a sequence database [1, 5, 7]. The technique can be applied to many applications, including customer shopping sequences, medical treatment diagnosis, telephone calling patterns, DNA sequence analysis, and so on. A classic application of customer shopping sequences is to discover the itemsets (set of items) in future purchase after certain itemsets were bought. A discovered pattern may be <(MacBook, iPhone) (Xbox)>, which indicates that many customers who purchase MacBook and iPhone at the same time, would buy printing software at a later time. Discovering purchasing patterns of customers may assist the modeling of user behaviors for E-commerce recommendations, customer retention, or personalized services [2]. Many algorithms [1, 5, 7] have been developed for the mining of sequential patterns.

In general, frequent itemsets or sequences appearing in the database are the focus of frequent pattern mining. Actually, the absence of certain itemset may imply the appearance of other itemsets as well.

The absence of itemsets thus is becoming measurable in many applications [2, 6, 8]. The absence of an itemset in a discovered pattern is referred to as a negative itemset. Sequential patterns discovered in traditional mining are called positive sequential patterns. In contrast, if a sequential pattern contains at least one negative itemset, the pattern is called a negative sequential pattern. For example, a negative sequential pattern <(MacBook) ?(iPhone) (Xbox)> indicates that if iPhone is absent after the presence of MacBook, normally Xbox will appear. Practical applications call for the need of exploring patterns having negative itemsets, as illustrated in the following.

Example 1: Given a positive sequential pattern S1 = <(MacBook)(iPhone)(iPod)> and a negative sequential pattern S2 = <(MacBook)?(iPhone)(Xbox)> for an E- commerce recommendation. If one had bought MacBook, should the system recommend iPod or Xbox?

If iPhone was purchased after purchasing MacBook, the system may recommend iPod by referring to pattern S1, otherwise Xbox could be recommended by referring to pattern S2.

Example 2: Consider two negative sequential patterns S2 = <(MacBook)?(iPhone)(Xbox)> and S3 = <(MacBook)(iPhone)?(Xbox)> for an E-commerce recommendation. The occurrence of Xbox is highly dependent on the presence of iPhone in an antecedent transaction. Thus, given one has a purchasing sequence of MacBook ahead, an effective recommendation of Xbox can be provided by validating the subsequent occurrence of iPhone in one?s sequence.

The above two examples show that negative sequential patterns could assist product recommendation systems to make more accurate decisions. To our knowledge, only very few studies have described the mining of negative sequential patterns. This paper formulates the problem of  2008 IEEE Asia-Pacific Services Computing Conference  DOI 10.1109/APSCC.2008.183   2008 IEEE Asia-Pacific Services Computing Conference  DOI 10.1109/APSCC.2008.183     negative sequential patterns and presents an algorithm called PNSP for the mining of negative sequential patterns. The experimental results show that PNSP discovers negative sequential patterns efficiently.

The rest of the paper is organized as follows. In Section 2, we formulate the problem of mining positive and negative sequential patterns. The proposed algorithm is presented in Section 3. The experimental evaluation is described in Section 4. Finally, Section 5 concludes our study.

2. Problem Formulation   2.1. Traditional Sequential Patterns   Let ? = {?1, ?2, ?, ?n} be a set of literals, called items. A (positive) itemset I = (i1, i2, ?, im) is a nonempty set of m items such that I ? ?. Without loss of generality, we assume the items in an itemset are in lexicographic order. A sequence s = <e1e2?ek> is an ordered list of k elements where each element ei is a (positive) itemset. Sequence s is also called a positive sequence. The size of a sequence s, written as |s|, is the total number of elements in s. Sequence s is a size-k- sequence, denoted by ssize-k, if |s| = k. The total number of items in all the elements in s is called the length of sequence s. For example, <(a)(b)(c)>, <(a, b)(c)>, and <(a)(b, c)> are all sequences of length 3. The first sequence is size-3-sequence. The second and third sequences are size-2-sequences. A positive sequence ? = <b1b2?bp> is a subsequence of a positive sequence ? = <r1r2?rq> if there exist 1 ? t1 < t2 < ? < tp ? q such that b1 ? rt1, b2 ? rt2,? , bp ? rtp. Positive sequence ? p-contains positive sequence ? if ? is a subsequence of ?. For example, <(a)(b)(c, d, e)> p-contains <(a)(c, d)>.

Each positive sequence in a sequence database DB is referred to as a data sequence. The number of data sequences in DB is denoted by |DB|. The support of sequence s, denoted by s.sup, is the percentage of data sequences p-containing s in DB. The min_sup is the user specified minimum support threshold. If s.sup ? min_sup then sequence s is a frequent sequence, or called positive sequential pattern. A positive sequential pattern is called a positive l-pattern if its length is l, and is called a positive size-k-pattern if its size is k.

Given min_sup and the sequence database DB, the problem of sequential pattern mining is to discover the set of all positive sequential patterns.

2.2. Negative Sequential Patterns   In the mining of negative sequential patterns, the database is the same as that used in traditional sequential pattern mining. However, negative sequential pattern mining [3, 4] is more challenging  than traditional sequential pattern mining. Consider an example as follows.

Example 3: Give a DB having only one data sequence ds = <(a)(b)>, and  ?= {a, b}. Three positive sequences, <(a)>, <(b)>, and <(a)(b)>, can be discovered. The number of negative sequences may be infinite if no constraints were added. Negative sequential patterns can be formed by any combinations of negative and positive itemsets. Not that <(a)?(a) (b)>, <(a)?(ab)(b)> but also <(a)?(a)?(b)(b)>, <(a) ?(ab)?(a)?(b)(b)> can be patterns. The number of negative itemsets can be infinitely added. A negative sequence can be formed by adding one or more negative itemsets to a positive sequence. Many of the negative sequential patterns could be meaningless in reality.

Meaningful negative sequential patterns need more constraints. The first constraint is the size constraint.

To be reasonable, a data sequence cannot support a pattern whose size exceeds its size. In other words, the maximum size of negative sequences supported by a data sequence ds is |ds|. For example, the maximum size of negative sequential patterns supported by ds = <(a)(b)> is two. Negative patterns <?(ab)>, <?(ab)(b)>, <(a)?(ab)>, and <?(ab)?(ab)> can be supported by ds, but <(a)?(ab)(a)> and <?(ab)?(a) (b)> cannot. Note that <?(b)(a)> cannot be supported by ds because the (a) in ds has no antecedent itemset.

Similarly, <(b)?(a)> is not supported by ds because the (b) in ds has no successor.

The second constraint to increase the practicability of negative sequential pattern is the frequency constraint. Given 10 distinct items in ?, the total number of potential itemsets is 1023 = C(10, 1) + C(10, 2) + ?+ C(10, 10), where C(m, n) represents the number of combinations of choosing n items from m distinct items. Assume that 10 among the 1023 are frequent. If the maximum size of data sequences in DB is three, the total number of potential patterns is 10331 + 10332 + 10333. In fact, many of the combinations are uninteresting. The user is interested in the absence of certain ?frequent? itemsets in a negative sequential pattern. Thus, the negative itemsets to be considered in a negative sequential pattern should have enough frequency. The negative itemsets of those frequent ones are to be considered only. The total number of potential patterns changes into 201 + 202 + 203. A valid negative itemset ?X to form a negative sequential pattern is the negative itemset of a frequent itemset X, where X.sup ? min_sup.

The third constraint is the formation constraint. In a formation of a negative sequence, two or more negative itemsets could contiguously exist. However,     For example, given a data sequence ds = <(a)(b, c)(d)(c ,d , e)>, ds does not n-cover <(a, b)?(c, d)> since <(a, b)?(c, d)>.mp, that is <(a, b)>, is not p- contained in ds. Although ds p-contain <?(a)(c)>.mp, that is <(c)>, ds does not n-cover <?(a)(c)> because ds p-contains <?(a)(c)>.ce (i.e., <(a)(c)>). ds does not n- cover <(b)?(d)(c, d)> since <(b)?(d)(c, d)>.ce (i.e., <(b)(d)(c, d)>) is p-contained in ds. ds n-covers <?(d)(c)> but does not n-contain <?(d)(c)> since <?(d)(c)>.ce (i.e. <(d)(c)>) is p-contained in ds.

Finally, ds n-contains <?(b) (b)?(a)(c, d, e)> because all the conditions are satisfied.

few differences can be told between <(b)?(a)?(b)> and <(b)?(b)?(a)> since both refer to that (a) and (b) are missing after the occurrence of (b). The order of consecutive negative itemsets is trifling for many applications. We may use one negative itemset unifying the consecutive negative itemsets for the negative sequence. A negative sequence thus is defined to have no contiguous negative itemsets. Such negative sequences are more interpretable though some specific applications may allow consecutive negative itemsets.

The negative itemset of itemset I = (i1, i2, ?, im), denoted by ?I = ?(i1, i2, ?, im), is referred to the absence of I, where all the items in I are absent altogether. ?I is also called the inverse of I. The inverse of a negative itemset ?I is I itself. A positive itemset X n-contain a negative itemset ?Y if and only if Y ? X. A sequence ns = <e  The support of a negative sequence ns, denoted by ns.sup, is the percentage of data sequences in DB n- containing ns. Sequence ns=<e  1?e2??ek?> is called a negative sequence, where ej? is either a positive itemset or negative itemset, if (1) at least one element ea?, 1 ? a ? k, is a negative itemset, (2) every negative itemset ea?, 1 ? a ? k, ea-1? and ea+1? must be positive itemsets, and (3) the inverse of a negative itemset ea?, 1 ? a ? k, must be a  frequent itemset in DB. The total number of elements in a negative sequence ns is called the size of the negative sequence ns, written as |ns|. Negative sequence ns is a size-k-neg-sequence nssize-k if |ns| = k.

For example, give <?(a)(b)?(c)>, <?(a, b)(c)>, and <(a)?(b, c)>. The first negative sequence is nssize-3. The second and third sequences are nssize-2.

An ordered list of all the positive elements in a negative sequence ns is called the maximum positive subsequence of ns, denoted by ns.mp. That is, ns.mp is derived by removing all the negative elements in ns.

For instance, the maximum positive subsequence of <(a)?(b, c)> is <(a)> and that of <(b)?(c)(a)> is <(b)(a)>. Additionally, the counterexample of a negative sequence ns, written as ns.ce, is derived by replacing each negative itemset ea? in ns by its inverse ? ea?. For example, <(a)(b, c)> is the counterexample of <(a)?(b, c)>, the counterexample of <(c)?(d, a)(b)?(d)> is <(c)(d, a)(b)(d)>.

A data sequence ds = <d1d2?dv> n-covers a negative sequence ns = <e1?e2??ek?> if there exist integers p, q, r and ei? ? ?I in ns such that the two conditions hold: (1) ds p-contains ns.mp, (2) ? ei?1? ? dp ? ei+1? ? dr ? ei? ? ?dq ,where 1 ? i ?k, 1 ? p < q < r ? t. In addition, ds n-contains ns if ds n-covers ns but ds does not p-contain ns.ce. Note that if the first or the last element is a negative itemset, condition (2) is different. When the first element is negative, e2? ? dq ? e1? ? ?dp. When the last element is negative, ek-1? ? dq ? ek? ? ?dr.

1?e2??ek?> is a frequent negative sequence, or called negative sequential pattern, if and only if (1) ns.sup ? min_sup, and (2) ei? ? ?I in ns, ? ei?, ei?.sup ? miss_freq, where miss_freq is the user specified missing frequency threshold.

miss_freq assists a user to manage the interested number of negative itemsets. A negative sequential pattern of size k is called a negative size-k-pattern.

Given a sequence database DB, a minimum support threshold min_sup, and a missing frequency threshold miss_freq, the objective is to find out all the negative sequential patterns.

DB  miss_frq min_sup  Find all positive sequential patterns  Find all positive itemsets  Find all negative itemsets  Generate size-k candidates  Find size-k negative sequential patterns  NCk ? ?  Output Results  Yes  No  Phase 1  Phase 2 Phase 3 (Initially, k = 2)  k+1 < Max. size  Yes (k = k+1)  No   Fig. 1. PNSP algorithm: An overview.

3. PNSP: Positive and Negative Sequential Pattern Mining   We propose a new algorithm called PNSP (Positive and Negative Sequential Patterns mining) for mining both positive and negative sequential patterns. PNSP extends GSP [7] to deal with the mining of negative sequential patterns. Fig. 1 depicts the overall concept of PNSP algorithm, which consists of three phases.

Phase 1: Find positive sequential patterns. We use the GSP algorithm [7] to mine all the positive sequential patterns. All the frequent positive itemsets are discovered as size-1 frequent sequences. These itemsets are used to find all the negative itemsets     satisfying miss_freq in Phase 2, to generate candidate negative sequences, and to prune some candidate negative sequences. Fig. 2 shows an example of Phase 1 in execution. Given a database in Fig. 2(a), min_sup = 25%. Positive sequential patterns are listed in Fig.

2(c), 2(e), and 2(g).

<(d)>D5  <(a)(a)>D4  <(a, e)(a, b)(c)>D3  <(a)(a, b)>D2  <(a)(b)(c)>D1  SequenceSid  (a) Database DB (b) C1  <(c)> <(b)> <(a)>  1-sequence  (c) FS1  0<(c)(b)>  2<(a, b)> 0<(c)(c)>  2<(b)(c)> 0<(b)(b)>  0<(c)(a)>  2<(a)(c)>  0<(b, c)>  0<(a, c)>  0<(b)(a)>  3<(a)(b)> 3<(a)(a)>  Count2-candidate  (d) C2  <(a)(c)> <(b)(c)> <(a, b)>  <(a)(b)> <(a)(a)>  2-sequence  (e) FS2  0<(a)(a)(c)>  2<(a)(a, b)> 2<(a)(b)(c)>  0<(a)(a)(b)>  0<(a)(a)(a)>  1<(a, b)(c)>  Count3-candidate  (f) C3  1<(d)>  3<(b)> 4<(a)>  1<(e)>  2<(c)>  Count1-candidate  <(a)(a, b)> <(a)(b)(c)> 3-sequence  (g) FS3  min_sup: 25%   Fig. 2. An example for Phase 1.

Phase 2: Find all positive and negative itemsets.

Positive itemsets are used to generate all negative itemsets which satisfy miss_feq. The support of a negative itemset ?I of length one can be derived without scanning the database by ?I.sup = |DB| ? I.sup.

Phase 3 Mining negative sequential patterns.

Phase 3 is the core of PNSP. The phase makes multiple passes over the database and finds out negative sequential patterns. In each pass, every data sequence is examined to update the support counts of the n- contained candidate negative sequences. The size-2 candidate negative sequences are generated by permutations of positive and negative itemsets. The size-2 negative sequential patterns are determined after checking all the data sequences in the database. In succeeding passes, size-k candidate negative sequences are generated by appending a size-(k-1) candidate sequences with a positive or negative itemset. Again, the supports of these candidates are counted by a scanning of the database to determine the frequent ones. This process terminates when there are no negative candidates any more. Fig. 3 shows an example of phase 3 in execution. The two essential sub-processes candidate generation and support counting are described in Section 3.1 and Section 3.2, respectively. The method of n-cover Checking is presented in Section 3.3. In the following context, NCsize-k represents the set of negative candidate sequence of size k, FNSsize-k represents the set of frequent negative sequences of size k.

3.1. Candidate Generation PNSP generates candidate negative sequences  NCsize-k by 2 steps. The sequences in NCsize-(k-1) are appended with a positive or negative itemset to generate the set of NC  in the first step. Candidates  whose maximum positive subsequence is not frequent are deleted in the second step. Moreover, candidates having negative subsequences without enough n-cover counts in DB are also deleted in the second step.

(d) FSsize-3  (c) FSsize-1  <(a)(a, b)>  <(b)(c)>  <(a)(c)>  <(a)(b)>  <(a)(a)>  Size-2-seq.

00<?(a)(ab)>         Count CoverSize-2-neg-seq.

3<?(b)(b)>  0<?(a)(c)>  3<?(b)(a)>  <?(b)(ab)>  <?(b)(c)>  <?(a)(b)>  <?(a)(a)>      (a) FSsize-1  (b) NSsize-1  00<?(b)(a)(a, ab)>  11<?(b)(a)(c)>     Count CoverSize-3-neg-seq.

0<?(b)(a)(b)>  <?(b)(b)(c)>  <?(b)(a)(a)>    <(a)(b)(c)>  Size-3-seq.

(f) NSsize-2 (PN)  (g) NSsize-3 (PPN)  (j) NSsize-3 (PNP)  (i) NSsize-3 (NPN)  (h) NSsize-3 (NPP)(e) NSsize-2 (NP)  (b)  (c)  (a, b)  (a)  Itemset  11<(ab)?(a)>         Count CoverSize-2-neg-seq.

2<(b)?(b)>  0<(c)?(a)>  2<(a)?(b)>  <(ab)?(b)>  <(c)?(b)>  <(b)?(a)>  <(a)?(a)>      <(d)>D5  <(a)(a)>D4  <(a, e)(a, b)(c)>D3  <(a)(a, b)>D2  <(a)(b)(c)>D1  SequenceSid  (a) Database DB  min_sup: 25%      Count CoverSize-3-neg-seq.

2<?(b)(b)?(b)>  1<?(b)(a)?(b)>  <?(b)(b)?(a)>  <?(b)(a)?(a)>        Count CoverSize-3-neg-seq.

2<(a)(b)?(b)>  1<(a)(a)?(b)>  <(a)(b)?(a)>  <(a)(a)?(a)>    ?(b)  ?(a)  Neg. Itemset  00<(a)?(b)(c)>  00<(a)?(b)(ab)>  00<(b)?(a)(c)>         Count CoverSize-3-neg-seq.

0<(a)?(a)(ab)>  0<(a)?(b)(a)>  0<(a)?(a)(b)>  <(b)?(b)(c)>  <(a)?(b)(b)>  <(a)?(a)(c)>  <(a)?(a)(a)>       Fig. 3. An example for Phase 3  Appending Step. We generate NCsize-k by appending a sequence in NCsize-(k-1) with a positive or negative itemset. If the last element of a sequence in NCsize-(k-1) is a negative itemset, a positive itemset is appended to form a candidate; Otherwise, it can be appended with a positive itemset and a negative itemset to form two candidates. Using NC , instead of FNSsize-(k-1) size-(k-1), to generate NCsize-k in that negative sequential patterns defy the Apriori property [1]. FNSsize-(k-1) is not necessary a subset of FNSsize-k. For example, give ds = <(a)(b, c)(d, e)> and negative sequences <(a)?(d)> and <(a)?(d)(e)>. ds n-contains <(a)?(d)(e)> but does not n-contain <(a)?(d)>. <(a)?(d)> means that (d) does not occur after (a). <(a)?(d)(e)> means that (d) does not occur between (a) and (e). For this reason, if FNSsize-(k-1) cannot be used to generate the complete set of NCsize-k. Fig. 4 shows the process of candidate generation. Initially, all positive and negative itemsets have been found in Phase 2. The P denotes a positive itemset, N denotes a negative itemset. A P type element can be appended with a P and a N to form two candidates. An N type element can be appended with a P. All sequences of forms PP, PN and NP are obtained in pass 1. Note that PP type is the set of all size-2 positive sequential patterns, which are mined in Phase 1. Additionally, positive sequential patterns of all sizes size-k     (forms PPP, PPPP, and so on) are discovered in Phase 1. This process is repeated until no more new candidates are generated, or the size of candidates is bigger than the maximum size of data sequences that can support in DB.

FS  P  N  PP  PN  NP  PPP  PPN  PNP  NPP  NPN  ? ??  ? ?  ? ??  Pass 1 Pass 2 Pass k  Phase 2 Phase 3  Size 1 Size 2 Size 3  , ? , ? Size k+1   Fig. 4. Process of candidate generation  Pruning Step. Some candidates in NCsize-k can be pruned earlier before counting. By definition, if a data sequence ds n-contains a negative sequence ns, ds p- contain ns.mp. In other word, if the support of ns.mp is less than min_sup, ns cannot be frequent in DB. All the frequent maximum positive subsequences of the candidate negative sequences are the positive sequential patterns in DB. All these positive sequential patterns had been discovered in Phase 1 and can be used to prune a candidate negative sequences ns by checking the support of ns.mp. Additionally, we can exploit the properties of negative sequences to reduce the number of candidates. For example, a data sequence ds = <(a)(b, c)(d, e)(a)(c)> does not n-cover <?(a)(b)>. Therefore, ds cannot n-cover any candidate sequence with leading subsequence <?(a)(b)> because the first element of ds is (a). <?(a)(b)?> is called the n-prefix of nssize-j. In contrast, ds could not n-cover <(a)?(c)> but ds could n-cover <(a)?(c)(d)>, <(a)?(c)(d)(e)>, etc. The difference between <?(a)(b)?> and <(a)?(c)> lies in the last element. If the last element of the n-prefix is positive, we can use it to prune the candidate negative sequence. Similarly, if the last element of the n-suffix is positive, we can use it to prune the candidate negative sequence. Thus, ds = <(a)(b, c)(d, e)(a)(c)> cannot n-cover <(e)?(a) (c)>. ds cannot n-cover a negative sequence nssize-n = <e?1e?2?e?n-2e?n-1en?>, where e?n-2 = (e), e?n-1 = ?(a), e?n = (c) and n > 3, either. The <?(e)?(a)(c)> is called the n-suffix of nssize-n.

3.2. Support Counting   PNSP adopts a hash-tree structure like GSP for storing candidates to reduce the number of candidates that need to be checked for each data sequence.

Originally, the hash-tree in GSP is designed to store  candidates of the same length in the leaves. The leaf which a candidate should be placed in is the leaf reached by a consecutive hashing on the items of the candidate. Nonetheless, PNSP generates candidates of different lengths in each pass. Therefore, we modify the hashing procedure slightly to store the same prefixed candidates. If there are candidates of n different lengths, we building n hash-trees.

Candidates would be placed in the same leaf if their leading items, starting from the first item, were hashed to the same node. The next item is used for hashing when an interior node, instead of a leaf node, is reached. The candidates required for checking against a data sequence are located in leaves reached by applying the hashing procedure on each item of the data sequence. The support of the candidate is increased by one if it is n-contained in the data sequence.

3.3. Improvement by n-cover Checking   Checking whether a data sequence ds n-cover a negative sequence ns is improved as follows. A candidate negative sequence ns = <e?size-k 1e? ?e2 k?>, where ei? is a negative itemset, both ei-1? and ei+1? are positive. Let dj p-contain ei-1?. Checking ei? can be done in two steps. Step 1, we find the occurrence position of ei+1? from dj+2 to dt. If no such position can be found, ds does not n-cover ns. Step 2, we check whether ds p-contain ei? from dj+1 to dn. If no such ei? can be found, then ei+2? is checked. If di p-contains ei?, we go backward to find an ei-1? from di to dt. Finally, Step 1 and Step 2 are applied recursively so that ei? can be checked.

4. Experimental Results   Comprehensive experiments have been conducted to assess the performance of the PNSP algorithm, implemented by using Microsoft Visual C++ 6.0. All experiments were performed on an AMD 2800+ PC with 1GB memory, running the Windows XP. The datasets in the experiment, DB1 of C10.T2.5.S4.I1.25.

N10K.D100K and DB2 of C8.T8.S4.I4.N1K.D10K, were generated by the well-known method in [1].

Please refer to [1] for the details of the parameters.

Fig. 5 shows that the total execution times of mining DB1 using two different miss_freqs for various min_sups. The results of min_sup = 3% and 2% were similar because only few patterns satisfied miss_freq.

When min_sup was less than 1%, a large number of negative sequential patterns appeared so that the execution times were increased as  min_sup decreased.

When miss_freq was increased from 97 % to 97.5 %, the number of negative itemsets increased from 7 to 23. The number of candidates grows exponentially as     the number of negative itemsets multiplies quickly.

The reason in that candidate size-n negative sequences are composed of m negative itemsets. The number of these itemsets approximately equals to number of size- k positive patterns multiply by the number of size-(n-k) negative itemsets. For instance, if the number of positive itemsets is 23 and the number of negative itemsets is 7, the number of candidates of NPN type equals 343 (7?23?7). If the number of negative itemsets rises to 23, the number becomes 12161 (23?23?23). Therefore, the execution time increases exponentially.

Fig. 6 presents the total execution times of mining DB2 using different min_sups. When min_sup was decreased or miss_freq was increased, a large number of negative sequential patterns were discovered so that the execution times were increased.

C10-T2.5-S4-I2.5, |DB|=100K, N=10K    0.8 1 1.5 2 2.5 3  Minimum support (%)  T ot  al e  xe cu  tio n  tim e  (s ec  . ) miss_freq 97.5%  miss_freq 97%   Fig.  5. Effect of varying min_sup in DB1  C8-T8-S4-I8, |DB|=10K, N=1K    4 5 6 8 10  Minimum support (%)  T ot  al e  xe cu  tio n  tim e  (s ec  . ) miss_freq 75%  miss_freq 70%   Fig. 6. Effect of varying min_sup in DB2  5. Conclusions   In this paper, we have formulated the problem of negative sequential pattern mining for E-commerce recommendations. We improve the usefulness of the patterns by introducing three constraints. The proposed PNSP algorithm extends the GSP algorithm and discovers sequential patterns having multiple negative itemsets. PSNP utilizes the properties of negative sequences to speed up the discovery of negative sequential patterns. Additionally, the proposed n- contain technique may efficiently check whether a data sequence contains negative sequences having multiple  negative itemsets. The devised pruning technique is effective for reducing a large number of negative candidate patterns. The experimental results show that PNSP may discover negative sequential patterns for practical applications.

7. Acknowledgement   This work was supported partially by the National Science Council, Taiwan, under grant NSC-97-2221- E-035-064.

8. References   [1] R. Agrawal and R. Srikant, "Mining Sequential Patterns," Engineering, Taipei, Taiwan, Mar. 1995, pp. 3-14.

[2] S. C. Hsueh, M. Y. Lin, and K. L. Lu, "Mining Generalized Association Rules for Service Recommendations for Digital Home Applications," Intelligent Information Hiding and Multimedia Signal Processing, Taipei, Taiwan, Nov. 2007, pp. 631-634.

[3] N. P. Lin, H. J. Chen, and W. H. Hao, "Mining Negative Sequential Patterns," Proceedings of the 6th WSEAS Hangzhou, China, Apr. 2007, pp. 654-658.

[4] W. M. Ouyang, and Q. H. Huang, "Mining Negative Sequential Patterns in Transaction Databases," Proceedings and Cybernetics, Hong Kong, Aug. 2007, pp. 830-834.

[5] J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U.

Dayal, and M.-C. Hsu, "PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth," Engineering, Heidelberg, Germany, Apr. 2001, pp. 215-224.

[6] A. Savasere, E. Omiecinski, and S. Navathe, "Mining for Strong Negative Associations in a Large Database of Customer Transaction," Proceedings of the 14th IEEE Florida, USA, Feb. 1998, pp. 494-502.

[7] R. Srikant and R. Agrawal, "Mining Sequential Patterns: Generalizations and Performance Improvements," Extending Database Technology, Avignon, France, Mar.

1996, pp. 3-17.

[8] X. Wu, C. Zhang, and S. Zhang, "Efficient Mining of Both Positive and Negative Association Rules," ACM Transactions on Information Systems, Jul. 2004, Volume 22, Number 3, pp. 381-405.

