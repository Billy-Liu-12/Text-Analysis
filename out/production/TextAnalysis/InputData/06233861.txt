

Abstract? Most of the approaches in mining generalized association rules are focused in the extracting patterns stage, using extended transactions, and simple taxonomies. A great problem of these works is related to the generation of large amounts of candidates and rules. Beyond that, the use of taxonomies may generate some limitations like absence of formalism, problems of reuse and sharing.  In this sense, this paper proposes a new algorithm for mining generalized association rules. The originality of this work is on the fact of the generalization being done in the post-processing stage and under all levels of ontologies, which are structures used in a formal domain specification. Some relevant points are the specification of a new methodology of generalization, including a new method of grouping rules; and a new and efficient method for calculating both the support and confidence of the generalized rules.

Keywords - Generalized Association Rules, Ontologies, Post- Processing.



I. INTRODUCTION The mining association rules, introduced in [1], consists  in finding all possible associations from a massive amount of data. So, traditional algorithms, like Apriori, generate their rules based only on existing items in the database. This characteristic makes an excessive amount of rules will be generated, complicating the analysis of the user.

Considering this context, there are approaches that use domain knowledge, represented for example via taxonomies, in order to obtain more general rules, interesting and in smaller quantities, facilitating the user analysis. The mining generalized association rules was introduced by [2] and [3].

Taxonomies are applied in various areas of knowledge, and there are several definitions about the same. In computer science, they are widely known as hierarchies of items.

When analyzing the literature it is possible verify that they can be used at different stages of mining generalized rules.[2], [4], [5], [6], [7], for example, using the same during the extraction of patterns. On the other hand, [3], [8] are works that demonstrate the use of taxonomies before the patterns generation, in the pre-processing. Finally, [9], [10], [11], [12], are examples of approaches that attack the use of taxonomies during the post-processing, after the generation of association rules, focus of our work.

Although taxonomies can be applied in different steps, we can say that the majority of the works uses as presented by [2], where the ancestors are inserted into database  transactions. From these extended transactions, [2] applies an algorithm to extract the final set of rules, which can be composed of traditional rules and generalized rules. This methodology can be advantageous, however, the inclusion of ancestors results in the generation of many candidate itemsets, in addition, the algorithm ends up generating redundant patterns, making it extremely necessary to use specific measures to eliminate redundancies.

On the other hand, approaches like [10] show that generalizing during the post-processing can be more advantageous, because fewer rules are generated. Moreover, to generalize at this stage eliminates the need of measures to prune redundant rules, since the whole process is done based on the traditional patterns generated in the previous step.

The taxonomy concept is abstract, since is only associated to the question of hierarchical organization and not to how such organization must be computationally codified. Thus, because of absence of formalities, the implementation of taxonomy varies according to algorithm which it will be used. Then, one way of solving such problems may be obtained through the use of ontologies, since ontology is a formal and explicit specification of a shared conceptualization [13].

In this sense, the objective of this paper is to present the OntGAR algorithm for mining generalized association rules using ontologies in the representation of domain knowledge.

In our algorithm, the generalization is made in the post- processing stage, avoiding the generation of huge amount of itemsets candidates and redundant rules. Moreover, in our proposal, the generalization may be done at any level of ontology, not just from leaf nodes to parent nodes, like occurs in other works of the literature.



II. RELATED WORKS Aiming to obtain a more general knowledge, the  generalized association rules, which are rules composed by items contained in any level of a given taxonomy, were introduced by [2]. Considering the same assumptions made in the traditional association rules, a generalized association rule is an implication of the form A ? B, where A  I, B I, A ? B = 0 and no item in B is an ancestor of any item in A [10]. In this case, the support and confidence measures are also used and there are some important relations that hold these measures: (a) sup(A ? ) ? sup(A ? B); (b) sup(  ? B) ? sup(A ? B); (c) sup(  ) ? sup(A ? B); (d) conf(A     ?  )  ? conf(A ? B), where  indicates that is an ancestor of A and  indicates that   is an ancestor of B.

The work [14] is focused on the post-processing of results of data-mining algorithms as expressed in analytical reports. According them analytical report is a free-text document describing data, preprocessing steps, DM task settings and results. In this work they presenting a novel framework for semi-automatic generation and processing of analytical reports, which address these issues through the utilization of semantic web technologies. In [12] was proposed a new approach to prune and filter discovered rules. Using Domain Ontologies, they strengthen the integration of user knowledge in the post-processing task. In this paper an interactive and iterative framework is designed to assist the user along the analyzing task. Ontologies also may be used in the data preparation phase. For example they have been used to reduce the number of attributes to be considered by grouping attributes and/or their values according to certain semantic criteria (i.e. variable categorization)  [15], [16].

In [10] was proposed the GARPA approach, where generalized rules are obtained in the post-processing step, from a traditional rules set. In this algorithm, differently from proposed by [2], the inserting of taxonomy ancestors in the database transactions was not made. The generalization was done using a method of replacing rule items (leaf nodes of taxonomy) into taxonomy ancestors. From the quantitative point of view, that method is more advantageous than proposed by [2], because reduces both the amount of candidates itemsets and rules generated, dispensing the uses of measures for pruning redundant rules.

On the other hand, some researches have directed for the semantic. In this line, [11] proposed the NARFO algorithm for mining generalized association rules, using Ontologies for extract  similarity associations between items of a database. The authors perform the generalization using a parameter called minGen. However, the algorithm is limited, considering that generalizes only in a unique level of the ontology (leaf nodes to parents).



III. THE ONTGAR ALGORITHM The aim of our algorithm is to post-process specialized  association rules (AR) using ontologies in order to obtain a reduced and more expressive set of AR, facilitating the user?s comprehension. The Figure 4.1 illustrates all steps of our algorithm. The process of generating traditional association rules is based on Apriori algorithm [17], and it needs of an user-provided minimum support and minimum confidence parameters to run. Moreover, it needs of a minGen and a side parameters:  ? minsup, which indicates the minimum support; ? minconf, which represents the mininum confidence; ? minGen, which represents the mininum quantity of descendants in different specialized rules;  ? side, which represents the side of generalization; The minsup, minconf and minGen parameters are  expressed by a real value in the interval [0,1]. The side parameter is expressed by a string value left, right or lr, indicating the side of generalization.  The generalization can be done on one side of the rule (antecedent or consequent) or on both sides (lr: left right side). While the left side indicates relations between classes of items and specialized items, the right side indicates relations between the specialized items and classes of items. The lr side indicates relations between classes.

First the algorithm identifies each item, generating 1- itemsets (itemsets with size one). In this stage we created also a data structure composed by keys and values where items of the dataset and ontology ancestors, which are the keys, are linked at values, which are the transactions identifiers stored in a vector. The Figure 4.2 shows this idea.

Since the generalized rules are obtained in the post- processing stage and for each generalized one obtained a new scan in the database will be necessary, the data structure used in the calculating of both support and confidence of generalized rules avoids additional scans in the database.  In our algorithm rules are grouped in order to be replaced by a more general rule. Thus, each group can generate a unique generalized rule. In this sense, a function performs the grouping rules treatment, returning several groups of rules. The parameters used are: a set of rules to be grouped and the generalization side. Rules are grouped according to parents of their items and the side of generalization. When the side parameter is left or right, rules having the same elements in contrary of generalization side, and having elements with identical parents in the generalization side are placed in a same group.

Figure 4.1 ? Steps of the OntGAR Algorithm.

Figure 4.2 ? Items of the database and ancestors in a data structure.

For example, considering the Figure 4.3, suppose right as side parameter and the rules milk ? breadA, milk ? breadB, milk ? breadC. As all rules have same elements in antecedent side (contrary generalization side) and also their items have same parent in consequent side (generalization side), these rules will be grouped together.  When the side parameter is lr, rules having items with the same parents in both antecedent and consequent sides of the rule will be grouped together. For example, supposing the rules milkA ? breadA, milkB ? breadB, milkC ? breadC were generated, as all rules have the same parents in antecedent and consequent side, so these rules will be grouped.

An important point is that generalized rules can be generated without the uses of all descendants of an ancestor in a rule. In this sense, to avoid an over-generalization, a set of specialized rules contained in a group can be substituted by a more general rule only if a minGen parameter [11] was satisfied. Consider that the minGen value is 0.6 (60%), supposing bread represented at ontology by breadA, breadB, breadC, breadD and breadE. The rule milk ? bread will be generated even if there is no rule for each kind of bread in the current group, but only if 60% of descendants of bread are present in this specialized AR set.

In this sense, for avoid a semantic loss, the algorithm shows the items which have not participate in the generalization process. For example, suppose the item breadE is not present in the specialized AR set, the generalized rule are shown as milk ? bread (-breadE), indicating that the item breadE did not compose the generalization.

Figure 4.3 ? Types of Milk and Bread.

The calculating support is made based on occurrences of the ancestors contained in the generalized rules.

However, to avoid unnecessary new scans in the database we use the data structure shown in the Figure 4.2. For example, considering the rule milk ? bread, both antecedent and consequent sides are keys of the structure.

So, the algorithm verifies and counts the intersection of values stored in both vectors of these keys, which represents all simultaneous occurrences of kinds of milk and bread in the dataset transactions.  Figure 4.4 illustrates this process.

After the generation of all groups in a certain level, if there are generalized rules in the current level the generalization process will continue in the next levels, if this situation is true for all next levels, the generalization process will be done until one level below the root of ontology.

However, if there is no any generalized rule in a certain level, then it is impossible to generalize in the next levels.

So, the generalization process is finished.

Figure 4.4 ?Idea used in the calculating support of generalized rules.



IV. EXPERIMENTS This section shows some experiments of the OntGAR  algorithm. The main objectives of these experiments are to validate our work, comparing the results with other approaches, like GARPA and NARFO algorithm. In this validation, two different data sets were used. The first data set (DB-1) contains information about Years of study, Race or ethnicity and Sex, and was provided by Brazilian Institute of Geography and Statistics (IBGE). DB-1 contains 9997 transactions with 12 distinct items. The second data set (DB-2) contains a one day sale of a supermarket located in S?o Carlos city. DB-2 contains 1716 transaction with 1936 distinct items. Two ontologies were created, one for the DB- 1, called Ont-1 ontology, and other for the DB-2, called Ont-2 ontology. The Ont-1 was constructed contained one     level of abstraction, except for the root, and Ont-2 was constructed with four levels of abstraction, except for the root. As describe before, GARPA needs a specialized rule set, which was obtained here by the traditional Apriori mining algorithm, and a taxonomy set. Thus, two taxonomies were created, T-1 and T-2, one for each data set.

The T-1 taxonomy was constructed according Ont-1, and the T-2 taxonomy was constructed according Ont-2.

One test (test 1) was done and compared with NARFO and GARPA algorithms. Another test (test 2) was done considering only our algorithm. Test 1 compares the number of generalized association rules extracted by our algorithm in relation to rules generated by GARPA and NARFO.

In test 1 we used the sup-10% on GARPA and lrhs side of generalization, which correspond to lr side on OntGAR.

Besides, the rules used as input for the GARPA were extracted from the Apriori algorithm with the same parameters (minsup and minconf) used in the other two algorithms. The data set used was the DB-1, the ontology was the Ont-1, we set minGen parameter of both NARFO and our algorithm with 0.1 (10%, like in GARPA), minconf with 0.2, and minsup varying from 0.15 to 0.5, increasing it by 0.05. The aim of Test 1 is to confirm that our algorithm extracts fewer association rules in comparison to NARFO and GARPA.

With minsup = 0.15, our algorithm generates six rules against eighteen of NARFO and ten of GARPA (? 66,6% of reduction in relation to NARFO and ? 40% of reduction in relation to GARPA). With minsup = 0.25, four rules were generated by our algorithm against six of NARFO and eight of GARPA and only GARPA generated rules with minsup less than or equal to 0.3.

Figure 5.1 ? Test 1 (Comparison between NARFO, GARPA and our algorithm in relation to amount of rules generated).

As mentioned before our approach shows to the users all generalized rules, separated by level. In addition, it also shows the rules that were not generalized over the ontology levels. This functionality is very important, because it allows the user check the reduction of the rules in each level of generalization. In this sense test 2 checks the compaction rate that represent the percentage of reduction in the volume of rules used as input. For example, considering a total of 1800 rules obtained (generalized rules and non generalized  rules) from a total of 3500 rules, the compaction rate is 48,57% (((3500-1800) /3500) * 100). This was done to demonstrate the efficiency of our algorithm in the reduction of the amount of rules generated.

In this experiment we used the two datasets, DB-1 and DB-2 and the two Ontologies Ont-1 and Ont-2. The side value is ?lr?, both minsup, minconf were constant, respectively, 0.004 and 0.004, and minGen varying between 0.4 and 1.0, increasing it by 0.2. The results show that the compaction rate are very high, especially when values of minGen are low. This means that for high values of minGen the number of generalized rules decreases and consequently the number of traditional increases. The results are illustrates in Figure 5.2 and Figure 5.3.

According to Figure 5.2, when minGen is 0.2 the compaction rate in the rules obtained under the level one is approximately 78%, and when this measure is 1 the compaction rate is approximately 40%. The compaction rate under level two, considering minGen with 0.2, is approximately 95% in relation to level one, and 80% in relation to level two. Any rule was obtained in levels more than two. The Figure 5.3 shows very similar results.

In relation to the performance of OntGar, we done a specific experiment to analyze the time spent in the generation of the final result, comparing it with GARPA. In this experiment, called test 3, we used the DB-1 and the Ont-1. We set minGen parameter of OntGAR algorithm with 0.1 and the t parameter with 10% on GARPA, minconf with 0.2 in both algorithms, and minsup varying from 0.05 to 0.2, increasing it by 0.05.

In previous post-processing works the calculus of support of a generalized rule is normally done through new readings in the database. So, the number of new readings is directly proportional to the amount of generalized rules generated, affecting considerably the runtime of the algorithm.  Thus, test 3 was done with the minsup varying to demonstrate when the minsup decreases the number of generalized rules increases and the runtime of the algorithms also increases, mainly because of the calculating of support. However we can show that when this calculus is done like in GAPA, with new scans in the database, the runtime is very greater than the runtime of OntGAR, which uses the data structure mentioned above. Through the Figure 5.4 it is possible to verify that the runtime of GARPA is greater than OntGAR.

Figure 5.2 ? Test 2 (Experiment A - Verification of the compaction rate, using DB-1 and Ont-1).

Figure 5.3 ? Test 2 (Experiment B - Verification of the compaction rate, using DB-2 and Ont-2).

Figure 5.4 ? Test 3 (Comparison of the runtime of GARPA and OntGAR).



V. CONCLUSIONS This paper proposes the OntGAR algorithm, a new  algorithm for mining generalized association rules in the post-processing stage and under all levels of ontologies, which are structures used for a formal specification of the domain. The experiments have shown that the OntGAR algorithm does an efficient generalization treatment when compared with other two approaches. In the OntGAR the calculating of support and confidence of generalized rules is done avoiding unnecessary scans in the database, being faster than GARPA for example. Furthermore, our approach generalizes in all levels of ontology and not only in one, like NARFO for example. Considering that the works in mining generalized association rules are focused on steps like extraction patterns and pre-processing, our work is an improvement and an important contribution to the post- processing phase. Besides, the use of Ontologies in this task permits a greater formalism, power of reuse, sharing and inference over the domain explored.

