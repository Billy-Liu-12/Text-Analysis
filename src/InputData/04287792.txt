Generalized Association Rule Mining Algorithms based on Data Cube

Abstract  This paper defined a kind of multi-dimension data cube model, and presented a new formalization of generalized association rule based on data cube model.

After comprehending the weaknesses of the current generalized association rule mining algorithms based on data cube, we proposed a new algorithm GenHibFreq which was suitable for mining multi-level frequent itemset based on data cube. By taking advantage of the item taxonomy, algorithm GenHibFreq reduced the number of candidate itemsets counted, and had better efficiency. We also designed an algorithm GenerateLHSs-Rule for generating generalized association rule from multi-level frequent itemset.

Demonstrated through examples, algorithms proposed in this paper had better efficiency and less generated redundant rules than several existing mining algorithms, such as Cumulate, Stratify and ML_T2L1, and had good performance in flexibility, scalability and complexity and had new ideas on conducting the Generalized Association Rule Mining Algorithms in multi-dimension enviornment nad it also has great theroritical meaning and practical value..

1. Introduction  Association rule mining is one of the most researched areas in data mining, It was firstly advanced in the article written by Agrawal?Imielinski and Swami in 1993[1].And then many researchers did much hard work on the exploit of association rule mining, the design of algorithms, parallel association rule mining and quantitative association rule mining. They also tried their best to improve the efficiency, adaptability and applicability of the mining algorithms and popularize them. At present, some researches has associated the association rule mining with the data warehouse technique to study the generalized association rule mining, for example use the Apriori algorithms etc. [1],[2],[3],[4]. However less study of the generalized association rule mining concerning data cube has been put forward, moreover, some typical association rule mining studies all described the mining process using informalized or demonstrated ways, it is lack of support of formalized theories.

This paper presented generalized association rule formalized definition aiming at the weakness of the  current association rule formalized and the generalized association rule mining algorithms based on data cube; designed the data cube model and relevant algorithms.

2 Mining System of Generalized Association Rule Based on Data Cube  2.1. Association Rule Mining System Structure  This system structure of data cube association rule mining based on the data warehouse as Fig. 1.It contains four parts: Data warehouse, Working data cube, OLAP engine and Associated Rule Mining Engine.

Figure1. The structure of Associated Rule Mining  2.2 Data Cube Model  2.2.1 Data Cube. Data Cube is a description of multi-dimension data, it can be n-dimension, not be confined to 3-dimension. Data Cube is defined by dimensions and facts.

In the data cube, data organization is multi-dimension, each dimension contains several abstract layers defined by concept taxonomy. And one concept taxonomy defined one mapping sequence and mapped the bottom layer concept to the more general high layer concept. Concept taxonomy can be defined by value of the given dimension and produce dimension level . Therefore, data cube is the data of concept layer, multi-dimension, moderate collecting, it provides high quality data sources for association rule   DOI 10.1109/SNPD.2007.291    DOI 10.1109/SNPD.2007.291    DOI 10.1109/SNPD.2007.291    DOI 10.1109/SNPD.2007.291     mining. Furthermore, the abundant meta data stored in it (e.g. dimensions layer) makes the algorithms of mining pass through every layer and provides convenience for the generalized association rule mining.

2.2.2 Data Cube Model. At present, there are about 9 types and 3categories of typical multi-dimension data model: simple multi-dimension data model, structural multi-dimension data model and statistic object model [5],[6],[7],[8]. In order to adapt to the demanded of multi-level association rule mining, this paper adopts the structural data cube model based on partial order and mapping concept [9], this model has better expressing ability of the complex dimension level structure and it can indicate the complex level structure of the data cube model efficiently. The expression of the data cube model as follows:  Definition 1: n-dimension data model in the generalized association rule mining is a 3-dimension set, set ? ?strcount DMDR ,,?  ?1? ? ?ndddD ,,, 21 ?? is a dimension set , id is called dimension.

?2? countM is called measure attribute.

?3? ? ?? ? ? ?? ????? ,,,,, 21 nstrD ???? is called  dimension structure set, ? ??,i? define the structure of dimension id .

? ?imiii sss ,,, 21 ??? is a limited set group, among them each set )1( mjsij ?? is called dimension  id ?s one dimension level attribute; ?4?measure attribute  countM function depends on  dimension set D ? that is D there is function  countM between  )()()(: 1 countn MDOMdDOMdDOMF ???? ,among them )( countMDOM is the value domain of the measure attribute  countM .

This model has better expressing ability of the  complex dimension level structure and it can indicate the complex level structure of the data cube model efficiently. This paper discussed the generalized association rule mining in the formalization data cube based on this model.

2.3 The Formalization of Generalized Association Rule  The formalized description of multi -level  association rule in n-dimension set ? ?strDMDR ,,? is as follows:  Definition 2?Item is a 2-dimension? ?vd , ,itemset ? ?? ?)(,, dDOMvDdvdI ??? ?among them D is  the dimension ? )(dDOM is dimension d ?s value domain.

Definition 3 ? If item Ivdx xx ?? ),( , Ivdy yy ?? ),( ? suppose yx dd ? ? and  )( yx vChildv ? ? then we call y as x ?s father?s generation ?item x is the filial generation item of y ,record it as ),( xx vdxy  ???? .

Definition 4: If itemset IZ ? , IZ ?  ? ,  suppose Z and Z ?  contains same items ,also we can get Z  ? through using its?father?s generation item to  replace one or several items in Z ,then we call Z ?  as the father?s generation itemset of Z ,and Z is the filial generation itemset of Z  ? .

Definition 5 ? k-itemset ? ? IvdvdvdX ikikiiii ?? ),(,),,(),,( 2211 ? ? among  them kqp ??? ,1 ? iqip dd ? . ??XPr shows the number of transactions in original transaction database that contains the all items in itemset X,  ? ? ),,,(Pr 2211 ikikiiii vdvdvdFX ???? ? , among them F refers to the function dependence relationship from the dimension set D in multi -dimension set R to measure attribute  countM , set X is the support degree of )Pr()sup( XX ? .

Definition 6?Generalized association rule is an implication formula as YX ? ,among them  IX ? , IY ? , ???YX ? and Xx?? ? all Yx?? .the support degree of YX ? rule  is )sup( YX ? = ? ?YX ?sup ?confidence degree is )( YXconfidence ? = ? ? )sup(sup XYX ? .

The formalized definition of multi-level association rule based on n-dimension data cube laid a foundation for further study of the algorithms of mining generalized association rule based on data cube.

2.4 Mining of Generalized Association Rule  Two steps of Mining of Generalized Association Rule: first, to find the frequent itemset that have support greater than the user-specified minimum     support; second to produce association rule from the frequent itemset that have confidence greater than the user-specified minimum confidence.

2.4.1 Generalized Frequent ItemSet. During the process of generalized association rule mining, multi-level frequent itemset mining is still a difficult point for researchers. In order to improve the efficiency of mining of frequent itemset, this paper concluded two mining strategies of producing multi-level frequent itemset on the bases of summarizing the former algorithms to propose a new algorithm GenHibFreq which was suitable for mining multi-level frequent itemset based on data cube.

1. Item depth and itemset depth Two concepts this paper needed were given as  follows: Definition 8? if item Ix? ?it?s depth can be  expressed as )(xdepth . Suppose x ?  which is the parent item of x is not exist ?then )(xdepth =0? or )(xdepth = 1)( ?xdepth ? .

Definition 9 ? if itemset IX ? ? it?s depth )( Xdepth = }))(max({ Xxxdepth ? .

2. The Mining Strategies of Frequent Item Set The mining strategies of multi -level frequent  itemset can be concluded as two following categories: ?1?The k -itemset 1?kL can be got through  joining and pruning of candidate frequent (k-1)-itemset  kC ?then traverse transactions database to count the support of all the candidate k-itemset  kC ,delete those itemset that can not meet the  minimum support, get the frequent k-itemset kL ? ?2?While creating frequent k-itemset kL ,firstly  traverse transactions database to count the support of the candidate k -itemset  kC of the highest abstract level?i.e.? 0)( ?kCdepth ?delete those itemsets that can not meet the minimum support value,then count the lower abstract level candidate k -itemset, one level deep into another ,in the process of it, we can decrease the number of the candidate k -itemset that need count through deleting those parent itemset that can not meet the minimum support value.

Comparing the above two strategies ,we can find easily that those two strategies all need joining and pruning all the frequent (k-1)-itemset  1?kL to get all the candidate k -itemset ,The difference is that the computing ways are different that the traversing data base to compute the support of the candidate k -itemset in kC .

3. Algorithms OF Frequent ItemSet Mining In order to improve the efficiency of creating frequent itemset in data cube and decrease the number of the candidate item set that needs computing as far as possible, then put forward the GenHibFreq Algorithms which was according with strategy(2).

1) Basic idea of GenHibFreq Algorithms According definition 6, while counting the support  of itemset by generalized association rule mining based on data cube, it only needs accessing the relevant cell, not need to scan the whole data cube, it will decrease the number of the candidate itemset that needs counting as far as possible  2) GenHibFreq Algorithms Notation explanations are defined as follows:  hkC , : hkCc ,?? ? hcdepth ?)(  hkL , : hkLl ,?? ? hldepth ?)( L : Frequent itemset Description of GenHibFreq Algorithms: Input : n-dimension ? ?strDMDR ,,? ?user specified  minimum support value min_sup.

Output: n-dimension multi-level frequent L ? ???? Lhk ;0;1 ; ?Creating frequent 1-itemset 0,1L of  0?depth for every dimension; ? 1?h ;  While( ???1,1 hL ) do { For each 1-itemset  1,1 ?? hLl do For each 1-itemset iie {? is the filial  generation itemset of l } do { if ( ?? supmin_Pr ?totalcounte ) add  1-itemset e to hL ,1 ; }  ??h ; }  1L = h? hL ,1 ; ?For ( 2?k ;( ???1kL and nk ? ); ??k ) {  0?h ; repeat{  if ( 0??h ) { )(__ 0,10, ?? kk LAprioricandidategenC ;  0,kL =all candidates in 0,kC with minimum support;  } else     ),,,(__ 1,,1, ?? hkhhk LLhkHibfrequentgenL ; ??h ;  } Until( ???1,hkL );  kL = h? hkL , ; } ?Answer= kk L? ; Function ),,,(__ 1,,1 ?hkh LLhkHibfrequentgen  Input? hL ,1 hdepth ? frequent 1-itemset? 1, ?hkL 1??hdepth frequent (k-1)-itemset  Output? hkL , hdepth? frequent k-itemset ?Queue ??FIFO ; ??hkC , ?For each k-itemset 1, ?? hkLl do {  Enqueue k-itemset l to the end of FIFO ; }  while(? ??FIFO ) { Dequeue k-itemset },,,{ 21 kaaaA ?? from  the head of FIFO ; If ( hAdepth ?)( ) {  If ( hkL , consists of k-itemset },,,{ 21 kaaaA ?? ) continue;  Else Add k-itemset A to hkL , ; } For  ( 1?j ;( 1)( ??hadepth j and kj ? ); ??j ) { For each item iie {? is the filial generation  item of ja , also }}{ ,1 hLi ? do { Replace item ja in A with e ; if  ( ? ? supmin_},,,,,,,{Pr 1121 ??? totalcountaaeaaa kjj ??  ) Enqueue k-itemset  },,,,,,,{ 1121 kjj aaeaaa ?? ?? to the end ofFIFO ;  } }  } Answer=? hkL , ;  This algorithms made the number of the candidate itemset that needs computing reach the least,thereby it can improve the efficiency of creating frequent itemset from the data cube effectively.

2.4.2 Algorithms of Mining of Association Rule. In order to decrease the creatintg of the abundant rules and fit GenHibFreq Algorithms of multi-level frequent itemset mining based on data cube, we put forward asscoation rule GenerateLHSs-Rule which was composed of two parts , one is BorderLHSs, the other is GenerateRule . At first we use BorderLHSs Algorithms through reverse searching means to find the dividing line of LHSs , then we use Generate Rule Algorithms to create Association Rule, GenerateLHSs-Rule can decrease the creating of the abcundant rules eddiciently. Descriptions of these two Algorithms as follows.

1. BorderLHSs We can use the downward closure property based on  LHS of the association rule to find the dividing line of LHSst through reverse searching means of BorderLHSs(A) under the conditiong of the given minimum support value, Description of BorderLHSs Algorithms is follows:  [Input]: Frenquent Itemset A [Output]?Rule Condition?LHS?Dividing Lines  (LHSs) ? FIFO={A}; LHSs ?? ; ? while(FIFO ?? ) do{ ? Dequeue B from the head of FIFO; ? onBorder=TRUE? ? For each ( B -1)-subset C of B do {  if( confAPCP min_)()( ? ) then { onBorder=FALSE;  ? if (C is not in FIFO) then Enqueue C to the end of FIFO;  } }  ? if (onBorder==TRUE) then add B to LHSs ;  } Answer=? LHSs;  BorderLHSs(A) will decrease the complexity ecomously ,because once the item set of LHSs was found, the searching algorithms will stop searching other subset. Even in the worst condition, the complexity of this Algorithms is ? ?AO 2 .

2. GenerateRule Algorithms GenerateRule Algorithms was gotten through  deleting one frequent itemset LHSs and making it not cross with any superset or subset.

If m frequent itemset mAAA ,...,, 21 ?among them anyone itemset is the superset of )1( ?A layer of or subset of A. if  -(A)BorderLHSs(?B ))(1?mi iABorderLHSs? ?relative to any other rules , )( BAB ?? is irredundant.

Descriptiong of GenerateRule Algorithms is as follows:  [Input]?All Frequent Itemset L [Output]?Irredudant Association Rule AR ? For each A?L do { ? LHS(A) = BorderLHSs(A); ? For each C ?L such that C is a  )1( ?A -superset or a child itemset of A do { LHS(A) = LHS(A) -BorderLHSs(C);  } ? For each B?LHS(A) do {  add rule ? )( BAB ?? ?to AR ; }  } ? Answer= AR ;  This Algorithms gets the most least and irredundant association rule, the efficiency of the association rule numbet was improved greatly. Suposse the opetating time of every frequent itemset in set L is the same ,then the computing complexity of this Algorithms and the value of set L are linearly dependence.

3.Example Verification and Analysis  Sales transtional database as Table 1, sales has four attributes: transaction identifier tid, customer?s age, income and buys, age and income are all amount attribute ,buys is category attribute.

3.1 Sales Database and Working Data Cube  Designing working data cube relevant to tasks according to data cube model, suppose this data contains 3 dimensionalities: age, income, and buys.

Suppose 3-itemset  {?X (age,[20,29]) ,(income,[40k,49k]),(buys, Color  Printer)} ? according to definition 4 ? ?? (Pr FX ? age=[20,29],income=[40k,49k],buys=Color  Printer)=2? that is there are 2 transactions in the original transactional database contains all the items in itemset .

3.2 Creating Association Rule  If the minimum confidence value min_conf is 60%?according to GenerateLHSs-Rule Algorithms the Association Rule was created, it was shown as Table2.

Table 1. sales business data base tid age income buys 100 25 45k { IBM Laptop, HP Color  Printer } 200 28 40k { HP Desktop , Canon Color  Printer } 300 44 45k { IBM Desktop, HP  Desktop } 400 21 20k { HP Desktop , Epson b/w  Printer } 500 36 40k { IBM Laptop }  600 32 30k { HP Laptop, Epson b/w Printer }  3.3 Outcome Analysis  ?1?31 association rules have been created using general algorithms , and only create 16 association rules when using the algorithms in this paper ,so we can say our algorithms can decrease the reduntant rules efficiently.

? 2 ? The Cumulate ? Stratify and ML_T2L1 algorithms need larger store space and also have distinct limitation. However when counting the support of itemset using the a lgorithms of this paper, it only needs to access the relevant cell, not need to scan the whole data cube ,decrease the number of the candidate itemset that needs counting to improve the efficiency of the creating of frequent item set.

?3?BorderLHSs(A) algorithms can guarantee one time visting for every subset of A, once the itemset of the condition border LHSs was found, the searching algorithms weill stop searching all the subset to make  the complexity less than ? ?AO 2 , so it can decrease the complexity of this algorithms greatly.

4 Conclusion  This paper described a multi -dimension data cube model; put forward the formalized definition of the generalized association rule; and concluded two categories mining strategies of creating multi-level frequent itemset mining algorithms . GenHibFreqeh which was suitable for data cube, this algorithms used the abstract level among the itemsets adequately to     decrease the number of the candidate item set which needs counting to improve the efficiency of this algorithms, we put forward the Algorithms of mining of the Generalized Association Rule Based on Data Cube (GenerateLHSs-Rule) which can decrease the creating of the redundant rules efficiently. Experiment shows that the algorithms in this paper is superior to  Cumulate ? Stratify and ML_T2L1 on algorithms efficiency and creating of irredundant rules .At the same time ,this algorithms has good performance in flexibility, scalablicity and complexity .

This paper was supported by Nature Science Foundation of Jiang Su province(NO: BK2005021).

Table 2. Association Rule created by GenerateRule(L) Algorithms Multi-layer Association Rule Support  degree Confidence  degree (buys, Printer) ? (age, [20,29]) 3 75% (income, [40 k,49 k]) ? (buys, Computer) 4 100% (buys, Computer) ? (income, [40 k,49 k]) 4 66.7% (buys, Desktop) ? (age, [20,29]) 2 66.7% (age, [30,39]) ? (buys, Laptop) 2 100% (buys, Laptop) ? (age, [30,39]) 2 66.7% (buys, Desktop) ? (income, [40 k,49 k]) 2 66.7% (buys, Laptop) ? (income, [40 k,49 k]) 2 66.7% (age, [20,29]) ? (buys, HP Desktop) 2 66.7% (buys, HP Desktop) ? (age, [20,29]) 2 66.7% (buys, HP Desktop) ? (income, [40 k,49 k]) 2 66.7% (buys, IBM Desktop) ? (income, [40 k,49 k]) 2 100% (age, [20,29]) ? (income, [40 k,49 k]) ? (buys, Computer) 2 66.7% (income, [40 k,49 k]) ? (buys, Printer) ? (age, [20,29]) 2 100% (age, [20,29]) ? (income, [40 k,49 k]) ? (buys, Color Printer) 2 66.7% (buys, Color Printer) ? (income, [40 k,49 k]) ?(age, [20,29]) 2 100%  Reference  1. R. Agrawal, T. Imielinski, and A. Swami, ?Mining association rules between sets of items in large databases?, In Proc. of ACM SIGMOD Conference on Management of Data, Washington D.C.: ACM Press, 1993?pp.207-216.

2. G. Piatetsky-Shapiro, W. J. Frawley, Knowledge Discovery in Databases, Menlo Park, California: AAAI/MIT Press, 1991.

3. M. Chen, J. Han, and P. S. Yu, ?Data mining: An Overview from a Database Perspective?, IEEE Trans. on Knowledge and Data Engineering, 1996, 8(6) ,pp.866-883.

4. J. Han, M. Kamber, Data Mining??Concept and Technology, Bei Jing: China Machine Press, 2001.

5. R. Agrawal, A. Gupta, S. Sarawagi, ?Modeling Multi-dimensional databases?, In Proc. of the 13th International Conf. on Data Engineering, Los Alamitos, CA, IEEE Society Press, 1997,pp,105-116.

6. C. Li, X. S. Wang, ?A data model for supporting on-line analytical processing?, In Proc. of the 5th International Conf. on Information and Knowledge Managemen, New York, Springer-verlag, 1996,pp,81-88.

7. W. Lehner, ?Modeling Large Scale OLAP Scenarios?, In Proc. of the 6th International Conference on Extending Database Technology (EDBT'98), Valencia, Spain: Springer-verlag, 1998,pp,23-27.

8. T. B. Pedersen, C. S. Jensen, ?Multi-dimensional data modeling for complex data?, In Proc. of the 15th on Data Engineering, Los Alamitos, CA: IEEE Society Press, 1999,pp,336-345.

9. L I Jian zhong, GAO Hong, ?Mult idimensional Data Modeling for Data Warehouses?, Journal of Software,2000,11(7),pp,908-917.

