Privacy Preserving Association Rule Mining

Abstract  The current trend in the application space towards sys- tems of loosely coupled and dynamically bound components that enables just-in-time integration jeopardizes the secu- rity of information that is shared between the broker, the requester, and the provider at runtime. In particular, new advances in data mining and knowledge discovery, that al- low for the extraction of hidden knowledge in enormous amount of data, impose new threats on the seamless integra- tion of information. In this paper, we consider the problem of building privacy preserving algorithms for one category of data mining techniques, the association rule mining. We introduce new metrics in order to demonstrate how security issues can be taken into consideration in the general frame- work of association rule mining, and we show that the com- plexity of the new heuristics is similar to this of the original algorithms.

1 Motivation  In a dynamic, unstable and ever changing business en- vironment like that where enterprises conduct e-businesses, the old fashioned disclosure control and database inference protection techniques are inadequate to ensure complete data privacy. In a recent news article, fears were expressed for the online security of private information because a pharmaceutical company said that it had inadvertently re- leased over the internet the e-mail addresses of more than 600 of its customers who were on some special type of medication. Although this is an extreme example of di- rect disclosure, it signifies the multiple risks that companies may run into, if they do not consider seriously the risks of not securing the sensitive information that they manipulate.

For this reason, organizations should be able to evaluate the risk of disclosing information and proceed in adopting new more efficient approaches for information disclosure con- trol, in order to maintain their competitive edge in the mar-  ket.

The proliferation of new data mining techniques have in-  creased the privacy risks because now it is possible to effi- ciently combine and interrogate enormous data stores, avail- able on the web, in the search of previously unknown hid- den patterns. In order to make a publicly available system secure, we must ensure not only that private sensitive data have been trimmed out, but also to make sure that certain in- ference channels have been blocked as well. In other words it is not only the data but the hidden knowledge in this data, that should be made secure. Moreover, the need for making our system as open as possible - to the degree that data sen- sitivity is not jeopardized - asks for various techniques that account for the disclosure control of sensitive data.

Government agencies make their data publicly available  on the Web while some dot com companies sell their repos- itory of customer records collected over time to another company. In both cases there may be some sensitive in- formation that can be extracted by malicious users. The sensitive information can be extracted in the form of associ- ation rules with now popular association rule mining tools.

For example, a rule which tells us that if a female customer buys a certain perfume then she also buys Prosac. Although this seemingly generic rule does not contain any personal information, it jeopardizes the privacy of the female cus- tomers since knowing this rule, someone can sniff a Prosac using female customer. Some other rule could be very crit- ical for the company itself such as buying patterns of very rich customers.

Sensitivity of a rule is a semantic notion and it has a tem-  poral dimension too. For example, an internet based com- pany may give up selling hardware and may concentrate on selling books and videos. Therefore a rule relating the cus- tomer buying patterns of hardware may no longer be sensi- tive for that company.

For hiding sensitive rules, it is more desirable to replace  a real value by an unknown value instead of placing a false value. Consider a medical institution which will make some of its data public, and the data is sanitized by replacing ac-  Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    tual attribute values by false values. Misleading rules could be obtained from this sanitized data by using data mining tools. These misleading rules, when used for critical pur- poses (like diagnosis) may jeopardize patients? lives. There- fore, critical applications require that the sanitization pro- cess place unknown values instead of false values. Even for non-critical applications unknown values are preferable to false values when the data is going to be sold to another company. This is due to the fact that insertion of false val- ues would degrade the quality of the released data. It also is not desirable to apply a trivial algorithm that hides data by deleting randomly since it will hide lots of rules as a side effect, degrading the quality of the released or sold data.

In this paper, we provide a framework for associa-  tion rules when the data set contains unknown values and we propose an innovative technique for hiding rules (i.e., knowledge) from a data set using unknown values.

The rest of the paper is organized as follows. In Section  2 we present some background information and the nota- tion used in the rest of the paper. In Section 3 we introduce new metrics required for dealing with sensitive association rules. Section 4 provides an outline of the rule hiding pro- cess and demonstrates it by using an example. In Section 5, we present three algorithms that we developed for rule hiding and we comment on their performance. Section 6 presents some initial results from experiments that we have performed by using real data sets. Section 7 summarizes the related work in the area of privacy preserving data mining rules. Finally, we conclude our discussion in Section 8.

2 Background  Let I = fi1; ::; ing be a set of literals, called items. Let D be a database of transactions, where each transaction T is an itemset such that T ? I . A unique identifier, which we call it TID, is associated with each transaction. We say that a transaction T supports X , a set of items in I , if X ? T .

The support of X on the other hand is the percentage of transactions that contain X . We assume that the items in a transaction or an itemset, are sorted in lexicographic order.

An association rule is an implication of the form X )  Y , where X ? I , Y ? I and X \ Y = ;. We say that the rule X ) Y holds in the database D with confidence c% if jXUY j?100jXj = c (where jAj is the number of occurrences of the set of items A in the set of transactions D). We also say that the ruleX ) Y has support s% if jXUY j?100  N = s,  whereN is the number of transactions inD. Note that while the support is a measure of the frequency of a rule, the con- fidence is a measure of the strength of the relation between sets of items. Because the number of itemsets and associa- tion rules increases exponentially with the number of items in the database, we only consider association rules which have support and confidence higher than two user specified  thresholds: theMinimumSupport ThresholdMST andMin- imum Confidence ThresholdMCT.

In the context of the current work, we assume that an as-  sociation rule (and its corresponding large itemset thereof) is also characterized by yet another metric, which we call it, the sensitivity level. The sensitivity level of a rule de- notes whether the rule is sensitive or not. For the sake of this presentation, we assume that a rule whose support and confidence is below the MST and MCT is not sensitive. In other words, the sensitivity depends entirely on these two other metrics. In a general framework of sensitivity anal- ysis, we consider that other factors affect the sensitivity of the rule (i.e., the rule refers to products of third parties).

In our previous work [3, 9, 7] we have demonstrated how to hide a certain set of association rules which is consid- ered sensitive from the database by using the support and the confidence of these rules. It is straightforward that if we turn to 0 the 1-values that provide support to a large item- set, then the support of the corresponding rule decreases, and consequently the rule is not sensitive any more.

3 Privacy Preserving Association Rules  In order to extend the idea of association rule discovery to privacy preserving association rule mining, we need to make some modifications to the original setting. First, we need to introduce a new symbol in the alphabet of an item.

The possible set of values of an item in the new setting be- comes f0; 1; ?g. For example, the value in the ith position of a transaction is 1 if the transaction contains (or supports) the ith item and, the value is 0 otherwise. A ??? mark in the ith position of a transaction means that we do not have any information regarding whether the transaction contains the ith item or not. With the new approach that involves ??? marks, the definition of support should be modified. In- stead of a single value for the support of an itemset A, we have a support interval, [minsup(A);maxsup(A)] where the actual support of itemset A can be any value between minsup(A) and maxsup(A). The minsup(A) is the per- centage of the transactions that contain 1?s for all the items in A and maxsup(A) is the percentage of the transactions that contain either 1 or ??? mark for all the items in A.

The confidence formula should also be modified since it  will also have a degree of uncertainty. Instead of a single value for the confidence of a rule A ) B, we have a con- fidence interval [minconf(A ) B);maxconf(A ) B)], where the actual confidence of a rule A ) B can be any value between minconf(A ) B) and maxconf(A ) B). Given the minimum and maximum support values of itemsets AB and A, the minimum confidence value for a rule A ) B is, minconf(A ) B) = minsup(AB) ? 100=maxsup(A), and the maximum confidence value is maxconf(A ) B) = maxsup(AB) ? 100=minsup(A).

Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    Note that minconf(A ) B) = maxconf(A ) B), andminsup(AB) = maxsup(AB) when there are no un- known values (i.e., ??? marks) in the database. During the sanitization process, when we start placing ??? marks, the minimum and maximum values will start to set apart, and in this way, the degree of uncertainty for the rule, will in- crease.

4 Sensitive Association Rule Hiding  Given a set of rules R extracted from the database with a certain minimum confidence and support threshold, we assume that sensitive rules in R are determined by the ex- perts. The purpose of the rule hiding algorithms is to make the sensitive rules invisible to the association rule mining algorithms while giving as little harm as possible to the re- maining non-sensitive rules to keep the data quality as high as possible. In order to hide a rule A ) B, we can either decrease the support of the itemset AB below the minimum support threshold, or we can decrease the confidence be- low the minimum confidence threshold. This can be accom- plished by placing ??? marks in place of the actual values to increase the uncertainty of the support and confidence of the rules (i.e., length of the support and confidence inter- vals). Considering the support interval and the minimum support threshold (MST ) which is a point, we may have the following cases for an itemset A:  ? A is hidden when the minsup(A) is greater than or equal toMST,  ? A is still visible when maxsup(A) is smaller than MST,  ? A is visible with a degree of uncertainty when minsup(A) ? MST ? maxsup(A)  The same reasoning applies to the confidence interval and the minimum confidence threshold (MCT). Note that it is possible for the support of a rule to be above the MST, and for the confidence to have a degree of uncertainty and vice versa. Also, both the confidence and the support may be above the threshold.

From a rule hiding point of view, in order to hide a rule  A ) B by decreasing its support, the only way is to re- place 1?s by ??? marks for the items in AB. In this way, we will only change the minimum support value while the maximum support value will be the same. As we replace 1?s by ??? marks for the items inAB, the minimum support value of A ) B will decrease and after some point it will go below the minimum support threshold.

In order to hide a rule, A ) B, by decreasing  its confidence, we can replace both 1?s and 0?s by the ??? mark. The confidence interval of A ) B is  TID A B C D T1 1 1 0 1 T2 0 1 0 0 T3 1 0 1 1 T4 1 1 0 0 T5 1 1 0 1  Table 1. Sample Database of Transactions TID A B C D T1 ? 1 0 1 T2 0 1 0 0 T3 1 0 1 ?

T4 1 ? 0 0 T5 1 ? 0 1  Table 2. Sample Database of Transactions with Unknown Attribute Values  [minconf(A ) B);maxconf(A ) B)] and our aim is to decrease the minconf(A ) B) below the MCT.

Recall that minconf(A ) B) = minsup(AB) ? 100=maxsup(A). So we should decrease minsup(AB) and/or increasemaxsup(A). Theminsup(AB) can be de- creased by either placing a ??? mark in place of either A or B. If we place a ??? mark in place of A then minsup(A) will also decrease, which will cause an increase in the maximum confidence value, since maxconf(A ) B) = maxsup(AB)?100=minsup(A). For rule hiding, it would be desirable to keep the maximum confidence as low as pos- sible, and for this reason, it is better to place a ??? mark for B. In order to increasemaxsup(A), we should replace the 0 values for the items in A with a ??? mark. Note that this process may cause an increase in the maximum support values of other rules as a side effect.

A sample database of transactions is shown in Table 1.

The database consists of 5 transactions whose items are drawn from the set fA;B;C;Dg. For this database, when we set the minimum support threshold to 50% and the min- imum confidence threshold to 70%, the frequent (large) items are A, B, and D with supports 80%, 80%, and 60%, respectively. Frequent itemsets of size 2 are the AB, and AD with support 60%. The rules obtained from these large itemsets are A ) B, and A ) D both having 75% confidence. Table 2 shows a database with unknown attribute values. In case of unknown at- tribute values, we previously defined the concepts of min- imum support and maximum support, as well as the mini- mum confidence and maximum confidence. For example, minsup(A) = 60%, and maxsup(A) = 80%. When we set the minimum support threshold to 50%, we see that  Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    bothminsup(A) andmaxsup(A) are above the minimum support threshold. However, for item B, minsup(B) = 40%, and maxsup(B) = 80%, and minsup(B) is be- low the threshold whilemaxsup(B) is above the threshold.

Among the itemsets of size 2, minsup(AB) = 0%, and maxsup(AB) = 60%. By observing the rules, we note that minconf(A ) B) = minsup(AB) ? 100=maxsup(A) which is 0%, and maxconf(A ) B) = maxsup(AB) ? 100=minsup(A) which is 100%1.

5 Algorithms for Rule Hiding  We have built two algorithms for rule hiding. The first one focuses on hiding the rules by reducing the minimum support of the itemsets that generated these rules (i.e., gen- erating itemsets). The second one focuses on reducing the minimum confidence of the rules. We considered both sup- port and confidence reduction algorithms as two alternative approaches. Support hiding is adequate against an associa- tion rule mining algorithm that uses support pruning to re- duce the search space of rules which is usually the case for the currently available commercial products. However, al- gorithms that can efficiently extract high confidence rules without support pruning have recently been developed [6].

Therefore, we have also proposed an algorithm that hides rules by reducing their confidence. Based on the concepts of interval support and interval confidence that we intro- duced, we would like to reduce the minimum support and minimum confidence values below theMST, andMCT cor- respondingly by a certain safety margin SM. So, for a rule A ) B, after the hiding process the following inequali- ties should hold; minsup(A ) B) ? MST ? SM , and minconf(A) B) ?MCT ? SM .

5.1 Rule Hiding by Reducing the Support  This algorithm hides sensitive rules by decreasing the minimum support of their generating itemsets until the min- imum support is below the MST by SM. The item with the largest minimum support is hidden from the minimum length transaction. The generating itemsets of the rules in Rh (set of sensitive rules) are considered for hiding. The generating itemsets of the rules in Rh are stored in Lh (set of large itemsets) and they are hidden one by one by de- creasing their minimum support. The itemsets in Lh are first sorted in descending order of their size and minimum support. Then, they are hidden starting from the largest itemset. If there are more than one itemsets of maximum size, then the one with the highest minimum support is se- lected for hiding. The algorithm works like follows: Let Z be the next itemset to be hidden. Algorithm hides Z by  1Note that we may have division by 0  decreasing its support. The algorithm first sorts the items in Z in descending order of their minimum support, and sorts the transactions in TZ (transactions that support Z) in ascending order of their size. The size of a transaction is determined by the number of items it contains. At each step the item i 2 Z, with highest minimum support is selected and a ??? mark is placed for that item in the transaction with minimum size. The execution stops after the support of the current rule to be hidden goes below theMST by SM . An overview of this algorithm is shown in Figure 1 where the generating itemsets of all the rules specified to be hidden is stored in Lh. After hiding an item from a transaction, the algorithm updates the minimum support of the remain- ing itemsets in Lh together with the list of transactions that support them. The algorithm chooses the item with highest minimum support for placing a ??? mark with the intention that an item of high minimum support will have less side effects since it has many more transactions that support it compared to an item of low minimum support. The idea be- hind choosing the shortest transaction for removal is that, a short transaction will possibly have less side effects on the other itemsets than a long transaction. Consider the trans- actions in Table 1. If rule A ) B needs to be hidden, then we need to choose one of the transactions in fT1; T4; T5g.

When the shortest transaction, T4 among T1; T4, and T5 is chosen, then placing a question mark for either item A, or item B in T4 will only effect the rule A ) B. However, if we had chosen T1 or T5, then rules A ) D and B ) D would also be affected by a modification in the transaction.

5.2 Rule Hiding by Reducing the Confidence  We propose two approaches for rule hiding using con- fidence reduction. The first approach is based on replac- ing 1s by ??? marks, while the second approach replaces 0s with ??? marks. It is important to have these two dif- ferent approaches for the safety of the rule hiding. If we only used the first approach, then it would be obvious that all the ??? marks are actually 1?s. Therefore, the two ap- proaches should be used in an interleaved fashion for rule hiding via confidence reduction. The simplest way of In- terleaving could be to hide the first half of sensitive rules by the first approach and the second half using the second approach.

The first algorithm shown in Figure 2 hides a sensitive  rule r by decreasing the support of the generating itemset of r. The difference between this and the approach presented in Section 5.1 is that items in the consequent of r only, are chosen for hiding. This is due to the fact that by placing a ??? mark for the items in the antecedent of a rule r will cause the minsup(lr) (lr is the left hand side of the rule r) to decrease, leading to an increase in the maxconf(r), and this works against the rule hiding process which tries  Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    INPUT: a set L of large itemsets, the set Lh of large itemsets to hide, the database D,MST , and SM  OUTPUT: the database D modified by the deletion of the large itemsets in Lh  Begin 1. Sort Lh in descending order  of size and minimum support of the large itemsets Foreach Z in Lh f  2. Sort the transactions in TZ in ascending order of transaction size  3. N iterations = jTZ j ? (MST ? SM)? jDj For k = 1 to N iterations do f  4. Place a ? mark for the item with the largest minimum support of Z in the next transaction in TZ  5. Update the supports of the affected itemsets 6. Update the database, D  g g  End  Figure 1. Rule Hiding by Support Reduction  to decrease confidence values of sensitive rules. The hiding process goes on until the minsup(r) or the minconf(r) goes below the MST and MCT thresholds by SM . The al- gorithm first generates the set Tr of transactions that support r, and then counts the number of items supported by each transaction. Tr is then sorted in ascending order of transac- tion size. In order to select the item in which we are going to place a ??? mark, we consider the impact on the rest of the rules. As a heuristic, the algorithm places a ??? mark for the item with the highest support in the minimum size transaction because of the same reason as we described in the case of rule hiding when the support of the generating itemsets was reduced.

The second algorithm shown in Figure 3 hides a rule  r by increasing the maxsup(lr) via placing ??? marks in the place of the 0 values of items in lr. By increasing the maxsup(lr) will cause theminconf(r) to decrease. Given a rule r, the algorithm first generates the set T 0  lr of trans-  actions that partially support lr but that do not support rr (the right hand side of the rule r). Then the number of items in lr contained in each transaction is counted. The transaction t that contains the highest number of items in lr is selected for processing, in order to make the minimum impact on the database. The 0 values for the items of lr that are not supported by t is replaced by ??? marks to in-  INPUT: a set Rh of rules to hide, the source database D,MCT ,MST , and SM  OUTPUT: the database D transformed so that the rules in Rh cannot be mined  Begin Foreach rule r in Rh do  f 1. Tr = ft inD=t fully supports rg 2. for each t in Tr count the number of items in t 3. sort the transactions in Tr in ascending order of the number of items supported  Repeat until (minconf(r) < MCT ? SM ) f 4. Choose the first transaction t 2 Tr 5. Choose the item j in rr with the highest minsup 6. Place a ? mark for the place of j in t 7. Recompute theminsup(r) 8. Recompute theminconf(r) 9. Recompute the minconf of other affected rules 10. remove t from Tr  g 11. Remove r from Rh  g End  Figure 2. Rule Hiding by Confidence Reduc- tion (Algorithm 1)  crease the maxsup(lr). The confidence of the rule is re- computed and the algorithm stops when the minconf(r) goes below MCT by SM . In this method of rule hiding, we only consider the transactions that do not fully support rr. Otherwise, by replacing 0 values for the items in lr in the transactions that partially support lr and fully support rr, we will increase the maxsup(r) leading to an increase in the maxconf(r) which is not desirable. We choose the transaction that partially supports lr while supporting the maximum number of items in lr. In the best case, such a transaction will support jlrj ? 1 of the items in lr and in this situation only one of the 0 values will be replaced by a ??? mark, achieving in this way the desired increase in the confidence while making the minimum change on the rest of the rules.

5.3 Complexity of the Rule Hiding Algorithms  All the algorithms first sort a subset of transactions in the database with respect to the items they have or with respect  Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    INPUT: a set Rh of rules to hide, the source database D,MCT ,MST , and SM  OUTPUT: the database D transformed so that the rules in Rh cannot be mined  Begin Foreach rule r in Rh do  f 1. T 0lr = ft inD=t partially supports lr and t does not fully support rrg  2. for each transaction of T 0lr count the number of items of lr in it  3. sort the transactions in T 0lr in descending order of the calculated counts  Repeat until (minconf(r) < MCT ? SM orminsup(r) < MST ? SM )  f 4. Choose the first transaction t 2 T 0lr 5. Place a ??? mark in t for the items in lr that are not supported by t  6. Recompute themaxsup(lr) 7. Recomputeminconf(r) 8. Recompute the minconf of other affected rules 9. remove t from T 0lr  g 10. Remove r from Rh  g End  Figure 3. Rule Hiding by Confidence Reduc- tion (Algorithm 2)  to the particular items they support. Sorting N numbers is O(NlogN) in the general case, however in our case the length of the transactions has an upper bound which is very small compared to the size of the database. In such a case we can sort N transactions in O(N). The inner loop of the algorithm shown in Figure 1 executes jTZ j ? (MST ? SM)? jDj times, and the operations in the inner loop can be done in constant time. The algorithm shown in Figure 2 executes its inner loop jTrj?(minconf(r)?MCT+SM) times in order to reduce the minimum confidence of the sensitive rule r below the MCT by SM . The value of (minconf(r) ?MCT + SM) is the reduction needed in the minimum confidence represented as fraction. And this fraction multiplied by the number of the transactions sup- porting the rule to be hidden gives the actual number of iterations. For the algorithm shown in Figure 3, the inner loop is executed k times until the minsup(r) goes below  rule confidence 18 79) 31 76% 2 168) 4 79% 9 10 57) 33 83% 4 19 39) 27 77% 9 18 47) 19 35 53%  Table 3. Rules Selected for Hiding  MCT by SM . The minconf(r) is initially jTrjjT 0 lr j , and af-  ter k iterations the fraction becomes jTrjjT 0 lr j+k which should  be smaller than MCT ? SM in order for the rule r to be hidden. When we isolate k from this fraction, we obtain k < jT 0  lr j ? jTr j  MCT?SM . The operations in the inner loops can be performed in constant time with proper hash struc- tures.

6 Experiments  We used the anonymousWeb usage data of theMicrosoft web site created by Jack S. Breese, David Heckerman, and Carl M. Kadie from Microsoft. The data was created by sampling and processing the www.microsoft.com logs and donated to the Machine Learning Data Repository stored at University of California at Irvine Web site [8]. The Web log data keeps track of the use of Microsoft Web site by 38000 anonymous, randomly-selected users. For each user, the data records list all the areas of the Web sites that the user visited in a one week time frame. We used the training set only which has 32711 instances. Each instance repre- sents an anonymous, randomly selected user of the Web site and corresponds to the transactions in market basket data.

The number of attributes is 294 where each attribute is an area of the www.microsoft.comWeb site and each attribute corresponds to an item in the store in the context of market basket data. We cleaned the data by removing the instances with less than or equal to non-zero attribute values and the resulting data set contained about 22k transactions.

We have implemented the support reduction and the first  algorithm for confidence reduction, using the Perl program- ming language. We have also implemented a naive algo- rithm that hides a rule by replacing 1?s by ??? marks in a round robin fashion by selecting the next item from the next transaction with no particular preference. The naive algo- rithm is used as a base for comparison with the rule and support reduction algorithms.

As a first step, we run an Apriori based mining algo-  rithm on the data with support 0:1%. We then obtained the rules out of the resulting large itemsets with 50% minimum support. The minimum confidence and support values are  Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    10 20 30 40 50 Confidence (%)  0.0  0.2  0.4  0.6  C P  U t  im e  ( s e  c s )  CPU Time For Different Hiding Strategies  GIH CR CH  Figure 4. CPU Requirement  10 20 30 40 50 Confidence (%)          S id  e E  ff e c ts  Side Effects of Different Hiding Strategies  GIH CR CH  Figure 5. Side Effects  chosen with regard to typical minimum confidence and sup- port thresholds from the literature. Sensitive rules should be determined by the domain experts. We did not have the nec- essary domain knowledge, therefore we randomly selected 5 different (not necessarily disjoint) rules and assumed that they are sensitive in order to test the hiding strategies. The selected rule set to be hidden is provided in Table 3. In or- der to assess the performance of the hiding strategies, we performed experiments on a PC, running Linux operating system, with 512 MB of main memory, and a Pentium III processor that has a CPU clock rate of 500MHz.

In this exploratory study, we measured the CPU time re- quirement of the hiding strategies for different confidence values which is depicted in Figure 4. As can be seen from the figure, all the hiding strategies hide the given rule set successfully in less than a second that is considerably less than the time for mining which takes 57 seconds for 0:1% support. For various confidence values the GIH method (generating itemset support reduction algorithm Shown in Figure 1) and CH (Cyclic Hide) perform similarly while the CR (confidence reduction algorithm shown in Figure 2) hides the rules faster. However our main performance cri-  terion of the different algorithms is the side effects they in- cur on the database. We measure the side effects by sum- ming up the number of rules hidden unintentionally and the number of newly introduced rules. The performance of the hiding strategies in terms of the side effects are depicted in Figure 5. As can be observed from the figure, the CR causes the least number of side effects followed by GIR. CR and GIR outperform CH for all confidence values.

7 Related Work  The problem addressed in this paper is closely related to the inference problem in databases and the privacy preser- vation problem in data mining. Chang and Moskowitz [4] consider a solution of the database inference problem by using a new paradigm where decision tree analysis is com- bined with parsimonious downgrading. In their scheme, Chang and Moskowitz, propose that High decides what not to downgrade based upon the rules that it thinks Low can infer (i.e., by using decision tree analysis) and upon the im- portance of the information that Low should receive. Their objective then in developing this paradigm is to assign a penalty function to the parsimonious downgrading in order to minimize the amount of information that is not down- graded and to compare the penalty costs to the extra confi- dentiality that is obtained.

Clifton [5] investigates the techniques to address the ba-  sic problem of using non-sensitive data to infer sensitive data in the context of data mining. His goal is to accomplish privacy by ensuring that the data available to the adversary is only a sample of the data on which the adversary would like the rules to hold. In addition, Clifton shows that for classification purposes, the security officer is able to draw a relationship between the sample size and the likelihood that the rules are correct.

Agrawal and Srinkant [2] investigate the development of  a data mining technique that incorporates privacy concerns.

In particular, they consider the concrete case of building a decision tree classifier from training data in which the val- ues of individual records have been perturbed. Their goal is to use the perturbed data (acquired either by a discretization or by a value distortion technique) in order to accurately estimate the original distribution of the data values. By do- ing this, they are able to build classifiers whose accuracy is comparable to the accuracy of classifiers built with the original data.

Agrawal and Aggarwal [1] improve on the distribution  reconstruction technique presented in [2] by using the Ex- pectation Maximization (EM) method. The authors claim that EM is more effective than the currently available tech- nique in terms of the level of information loss. They also prove that EM converges to the maximum likelihood esti- mate of the original distribution based on the perturbed data  Proceedings of the 12th Int?l Wrkshp on Research Issues in Data Engineering: Engineering e-Commerce/ e-Business Systems (RIDE?02)    and that it provides robust estimates of the original distri- bution. Finally, they propose novel metrics for the quantifi- cation and measurement of privacy-preserving data mining algorithms.

A new class of privacy preserving techniques is intro-  duced in [3, 9, 7]. In particular Atallah et. al [3], Dasseni et.

al. [7] and Verykios et. al. [9] have considered the problem of privacy preserving mining of association rules. The au- thors have demonstrated how certain sensitive rules can be hidden by some data modification techniques and they have proposed efficient heuristics for solving this problem since Atallah et. al. [3] proved that the problem is NP-Hard. In the current work we are considering the same problem but instead of allowing random data modification, we have re- stricted ourselves to introducing ??? a special symbol that indicates that information is missing. Some changes to the original association rule discovery program are necessary for the introduction of heuristics based on this idea.

8 Conclusions  In this paper, we have presented a new set of concepts for making association rules sensitive, and we have extended the association rule mining process, in order to account for sensitive association rules. Association rules is one cate- gory of data mining techniques; other data mining tech- niques should also be considered for securing both data and knowledge in a virtual e-business environment that is open- ended and vulnerable to all kinds of different malevolent attacks. Our initial results indicate that deterministic algo- rithms for privacy preserving association rules are a promis- ing framework for controlling disclosure of sensitive data and knowledge. In the near future, we will investigate how probabilistic and information theoretic techniques can also be applied to this problem.

