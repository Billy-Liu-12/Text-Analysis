

Abstract ? Learning association rules and/or associative  classification rules has been extensively studied in data mining and knowledge discovery community. Associative classification rules are considered as constrained association rules.  Mining traditional association rules from transaction databases, however, has suffered some limitations. One of these limitations is that each transaction merely contains binary items with each item either present or absent in a transaction. Another limitation is that only positive association rules are discovered. Mining fuzzy association rules and discovering negative association rules have been developed to overcome these limitations, respectively.

In this paper, we briefly introduce fuzzy association rules and negative association rules and especially discuss and compare what negative association rules look like. Approaches to discovering fuzzy association rules and negative association rules are combined to propose a new interestingness measure for both positive and negative fuzzy association rules. With this interestingness measure, an algorithm for mining those rules is described. Also, the special forms of association rules are presented, called associative classification rules. The algorithm to mining positive and negative fuzzy association rules is extended to learn positive and negative fuzzy associative classification rules.

Index Terms?Positive and negative association rules, fuzzy association rules, associative classification rules

I. INTRODUCTION iscovering association rules from large databases has  been actively pursued since it was first presented in 1993 [1], which is a data mining task that discovers associations among items in transaction databases such as the sales data.

Such kind of associations could be "if a set of items A occurs in a sale transaction, then another set of items B will likely also occur in the same transaction". The basic format of an association rule looks like A B, where A and B are two disjoint sets of items, meaning that when A is bought in a transaction, B is likely to be bought as well in the same transaction. Application of such rules include cross-marketing, attached mailing, catalog design, store layout, etc. Currently mining traditional associations in "basket data" has been extended to discover associations among quantitative and categorical attributes [2], [16], and taxonomies hierarchies over attributes [10], [17]. The idea behind these extensions is   Manuscript received February 14, 2006.

Jianchao Han is with the Department of Computer Science, California  State University, Dominguez Hills, 1000 E. Victoria Street, Carson, California, 90747, USA, jhan@csudh.edu)  to transform the data representation to transactions.

One of limitations of traditional association mining is to  assume that the data to be mined are described by binary attribute values. Each tuple in the database corresponds to a transaction, which either contains a particular attribute (item present) or not (item absent). Some effort has been made to extend the binary attribute values to fuzzy attribute values in which each transaction may contain a particular item in some degree between 0 and 1 inclusive [5][6][9][11][12][20]. This results in the discovery of fuzzy association rules.

Another limitation of traditional association mining is that mining algorithms only search for positive associations like A B, while negative associations such as A ?B, ?A B, and ?A ?B are ignored. Mining negative association rules is important [7], but challenging, because absent items in a transaction are usually much more than present items, which leads the forbidden possibilities of associations among items [3][8][15][19].

Associative classification rules are a special format of association rules, where the right-hand-side of the rules is one of class labels. Some research has been made to find associative classification rules (or class association rules) by constraining the search space of association rules [4][13][14].

The main idea of finding associative classification rules is to first generate the frequent itemsets and then test if they imply a class in the database.

In this paper we combine the approaches of mining fuzzy association rules and negative association rules to propose an approach for mining both positive and negative fuzzy association rules. We will develop a rule interestingness measure for both association rules and present an algorithm to discover both positive and negative fuzzy association rules.

This algorithm is also extended to learn both positive and negative fuzzy associative classification rules.

The rest of the paper is organized as follows. We overview the approaches of association rules mining and discuss their extensions to fuzzy association rules in Section 2. The positive and negative association rules and related problems will be presented in Section 3. In Section 4, we propose the concept of both positive and negative fuzzy association rules as well as the rule interestingness measure, and describe our algorithm for mining those rules. In Section 5, the above algorithm is extended to find positive and negative fuzzy associative classification rules. The conclusion and our future work are described in Section 6.

Jianchao Han  Learning Fuzzy Association Rules and Associative Classification Rules  D   Sheraton Vancouver Wall Centre Hotel, Vancouver, BC, Canada July 16-21, 2006

II. CRISP ASSOCIATION RULES AND FUZZY ASSOCIATION RULES  A. Crisp Association Rules  The traditional crisp association rules, also called itemset association rules, were proposed in the basket data problem [1]. Given a database of customer transactions that consists of items purchased by a customer, we look for significant associations between items, for example, which items are always or often bought together with which items.  Let I={i1, i2, ? , im} be a set of items, where m is the number of items.

Let D be a database of transactions, where each transaction t is a set of items represented as a binary vector, with t[ik]=1 if t contains the item ik, and t[ik]=0 otherwise, for 1?k?m. Each transaction corresponds to a tuple in D. Assume X? I is a subset of items in I. A transaction t satisfies X if ik?X, t[ik]=1.

In a transaction database, an association rule is an implication of the form X Y, where X, Y ? I, I is the set of all items, and X?Y=?. This association rule means that the occurrence of all items in the subset X implies the occurrence of all items in the subset Y. The most common rule-interest measure is called support-confidence framework, where the rule-interest is measured by the support and confidence, which are defined as, for a rule X Y,  Supp(X Y) = Supp(X?Y)/|D|, Conf(X Y) = Supp(X?Y)/Supp(X),          (1)  respectively, where Supp(Z) is the number of transactions in D that contain all items in Z, and |D| is the total number of transactions in D.

With the user-specified support threshold (minsupp) and confidence threshold (minconf), the process of finding association rules can be decomposed into two steps:  1) Discovering all frequent itemsets: A subset X of I is called a frequent itemset if its support is at least minsupp; and  2) Generating association rules: For each frequent itemset X, construct rules of the form X-Y Y, where Y?X. If the confidence of a rule in such form is greater than or equal to minconf, then it is an association rule.

Currently many approaches to solving the basket data problem have been developed and efficient algorithms have been implemented. The classical solution exploits level-wise search to generate all candidate frequent itemsets and then prunes them [1][2][18]. The level-wise methods are based on the observation that if an itemset is frequent then all of its subsets are frequent. Thus, the basic idea is to evaluate 1- itemsets first, find frequent singleton itemsets, and then evaluate their supersets 2-itemsets, and so forth. Such evaluations are repeated until no frequent itemset is found or the size of the itemsets approaches some threshold.

B. Fuzzy Association Rules  In the fuzzy context, one can extend the Boolean values {0,1} (indicating absence and presence) to the interval [0,1].

Whether a tuple contains an item is characterized by the membership. Consider the grocery sales including Vegetable  and Fruit. Assume a customer buys Tomato. The degree of Tomato being Vegetable is 0.4 and the degree of Tomato belonging to Fruit is 0.5. The transaction with Tomato being bought should contribute support of 0.5 to the item Fruit, and 0.4 to the item Vegetable. Generally, the support of an itemset can be counted as follows: for every tuple in the database, take the product of the membership values of the attributes under consideration, and summate these numbers. Let the database be D and an itemset A={A1, A2, ? , Al}? I. The support of a transaction t?D to the itemset A can be defined as  ).()(),(  tttASupp i  l i AA =  == ???        (2) Taking the fuzzy logic AND as the well-known product, the  support of A from the database D is thus defined as  ,)()(),()(  ? ? ?? ? ? ? =  === Dt Dt Dt  l  i AA tttASuppASupp i?? (3)  where ?Ai(t) denotes the membership value of the item Ai in the transaction t. There are also other possibilities for the fuzzy AND as long as they are a triangular norm (t-norm for short). For simplicity, however, we use the product to calculate the itemset support because, given a transaction t={t1, t2, ? , tm} and the set of all items I={I1, I2, ? , Ik}, the support of I from the transaction t will be always 1 by the normalization assumption.

Therefore, the support of an association rule A B is defined as  , ||  )(  || )()(  D  t  D BASuppBASupp Dt BAx  x? ? ? ??==?  ? ?  (4)  and the confidence of the rule is therefore  .

)(  )(  )( )(  )( ?? ? ?  ? ?  ? ??==?  Dt Ax x  Dt BAx x  t  t  ASupp BASupp  BAConf ?  ?? (5)

III. POSITIVE AND NEGATIVE ASSOCIATION RULES As have been observed in [7][8][19], the rule-interest  measure for association rules under the support-confidence framework has some criticisms, one of which is that only the positive associations between attributes like A B could be discovered, but the negative correlations like A ?B, ?A B and ?A ?B could not be found. This is because only the positive examples are considered while the negation of items is ignored. However, negative associations are also very important in our daily life [7][19].  For example, in the application of supermarket, positive association rules suggest to place associated items together, while negative association rules can be used to separate items. The items without any associations should be arranged at last.

Recall the rule-interest measure defined in previous section.

Consider the association rule A B. Both support and confidence of the rule are defined by counting the number of positive transactions that explicitly contain the items in A and       B. That is, a transaction t is a positive example of an itemset X if X? t, and a positive example of a rule A B if X?Y? t. It is clear that the positive examples of A B are also positive examples of B A, and vice verse. The question arise what a negative example of an itemset X looks like. Intuitively, a negative example t of X can be understood as either t doesn't contain X, that is X ? t, or t doesn't contain any item in X, that is t?X=?. Existing approaches for mining negative associations avoid to answer this question [3][8][19]. In [8], only negative examples of association rules are considered, where a negative example of A B is a positive example of A ?B, and vice verse. In [3], a generalized negative associate rule is considered as a rule that contains a negation of an item, for example, A??B??C?D E??F is such a rule.

However, as the authors pointed out, deriving an algorithm to find such rules is not easy, since it would be necessary not only to consider all items in a transaction, but also all possible items absent from the transaction, which could be very expensive. Therefore, they limit to confined negative association rules in one of two forms: ?A B, and A ?B, where the negated itemset is the set of all negated items in the itemset. Taking this into account, we will assume a negative example t of X is a positive example of ?X such that all items in X are absent in t, that is, t?X=?.

The algorithm presented in [19] consists of two steps. First, all frequent and infrequent itemsets of interest are identified; second, positive association rules are extracted from the frequent itemsets, while negative association rules are extracted from the infrequent itemsets. The positive association rules are discovered as in the support-confidence framework [1] with a new measure called mininterest is added, where a rule A B is of interest only if Supp(A?B)- Supp(A)Supp(B)?mininterest. A rule A ?B is a valid negative rule of interest if A and B are disjoint and both frequent, A?B is an infrequent itemset, A??B is frequent, Supp(A??B) - Supp(A)Supp(?B) ? mininterest, and Supp(A??B)/Supp(A) ? minconf. The other forms of negative association rules including ?A B and ?A ?B can be discovered in the similar way. However, it is unclear how Supp(?B) and Supp(A??B) are calculated. As our understanding, Supp(?B) should be the number of positive examples of ?B.

The authors of [3] argue that the mininterest parameter introduced in [19] is a burden of users and would impact on the results when changed. They present another method using the correlation coefficient as measure of interestingness, which is well defined and not as sensitive to the dataset as the mininterest parameter. The correlation coefficient threshold could be specified by the user, or default value.



IV. FINDING BOTH POSITIVE AND NEGATIVE FUZZY ASSOCIATION RULES  In this section, we define both positive and negative fuzzy association rules with the assumption that transaction data are fuzzy, and propose an algorithm to discover them. We will use the support-confidence framework of association rules, which  means we need two thresholds: support threshold minsupp and confidence threshold minconf that are specified by the user, and the threshold may vary with positive and negative association rules. As observed in [3][19], another measure such as correlation coefficient threshold or rule-interest threshold can be easily added to the framework.

Assume ?x is the membership function of x for all x?I. For each transaction t?D, ?x(t) represents the degree that t contains the item x. The positive fuzzy association rules will be the same as the natural fuzzy extension of traditional crisp ones, while the negative fuzzy association rules will include the following three types: A ?B, ?A B, and ?A ?B. For completeness, we describe both positive and negative fuzzy association rules in this section.

For simplicity, the support of negative itemsets can be computed as follows: Let A and B be subsets of I,  ,))(1()()(  ? ?? ? ? =  ? ?==? Dt Dt  l  j AA ttASupp j??  and         ?? ? ? ? ?  ? =?=?  Dt Ax By yx tt  ABSuppBASupp ))(1()(  )()( ??  ?? .   (6)  A. Positive Fuzzy Association Rules  Recall that the support Supp(X) of an itemset X is defined as the percentage of the number of transactions in D that contains

X. Let A?I and B?I be two itemsets. With (4) and (5), the relationship A B is a positive fuzzy association rule, if the following conditions hold:  1)  A?B=?; 2)  Supp(A B) = Supp(A?B)/|D| ? minsupp; 3)  Conf(A B) = Supp(A?B)/Supp(A) ?minconf.

B. Negative Fuzzy Association Rules  Negative fuzzy association rules regard the relationships between presence/absence of some items and absence of other items. In practice, each transaction usually contains a small set of items although the whole item set might be huge. In order to avoid too many uninteresting negative rules, the authors of [19] argue that the items in the negated itemset should be also frequent. Following this line, let A ? I and B ? I, if A ?B, ?A B, or ?A ?B is a negative association rule, both A and B must be frequent, while A?B should be infrequent. Taking this into account, with definitions (4), (5), and (6), the three types of negative fuzzy association rules can be defined as below.

1)  A?B=?; 2) Supp(A)/|D| ? minsupp; 3) Supp(B)/|D| ? minsupp; 4) Supp(A?B)/|D| < minsupp; 5) A ?B is a negative fuzzy association rule, if 5.1) Supp(A ?B) = Supp(A??B)/|D| ?minsupp; 5.2) Conf(A ?B) = Supp(A??B)/Supp(A) ?minconf.

6) ?A B is a negative fuzzy association rule, if 6.1) Supp(?A B) = Supp(?A?B)/|D| ?minsupp; 6.2) Conf(?A B) = Supp(?A?B)/Supp(?A) ?minconf.

7) ?A ?B is a negative fuzzy association rule, if 7.1) Supp(?A ?B) = Supp(?A??B)/|D| ?minsupp; 7.2) Conf(?A ?B) = Supp(?A??B)/Supp(?A) ?minconf.

C. Finding Frequent and Infrequent Itemsets  Based on the algorithm proposed in [19], we develop an algorithm to discover both positive and negative fuzzy association rules in this subsection. The problem is resolved in two steps. In the first step, all the frequent itemsets and infrequent itemsets are generated, while in the second step, all positive fuzzy association rules are extracted from the set of frequent itemsets, and all negative fuzzy association rules are extracted from the set of infrequent itemsets. These steps are illustrated in the following procedures.

In Procedure 1, the set of frequent itemsets F and the set of  infrequent itemsets Q are initialized as empty. Then all frequent 1-itemsets are generated and stored in F1. Generally, all frequent k-itemsets are generated from frequent and infrequent (k-1)-itemsets for k?2. For this purpose, all k- itemsets in D are produced by the union of two frequent (k-1)- itemsets in Fk-1, and saved in Tk. The support of each itemset A?Tk is calculated, with which frequent and infrequent k- itemsets are produced by checking their support with the given minimum support threshold and saved in Fk. Then the procedure goes to next loop. This process proceeds until no more frequent k-itemsets can be generated.

D. Finding Both Positive and Negative Fuzzy Association Rules  Both positive fuzzy association rules and negative fuzzy association rules can be extracted from the set of frequent itemsets F and the set of infrequent itemsets Q, respectively, that is described in Procedure 2. In order to generate positive fuzzy association rules from F, each frequent itemset X?F is arbitrarily divided into two possible disjoint subsets A and B such that A?B=X. Then the confidence of A B and B A is calculated to see whether they satisfy the minimum confidence requirement so that the positive fuzzy association rules are generated.

On the other hand, three types of negative fuzzy association  rules are produced from the set of infrequent itemsets Q. To this end, each infrequent itemset Y?Q is partitioned into possible disjoint subsets A and B such that A?B=Y. To avoid many meaningless negative rules, infrequent A and/or B are filtered out. The confidence of ?A B, B ?A, ?A ?B, and  Procedure 1: Finding the set of frequent itemsets and the set of infrequent itemsets for association rules  Input: a database D; minimum support -- minsupp Output: the set of frequent itemsets F and the set of  infrequent itemsets Q (1) Initialization: F ?, Q ?; (2) Find frequent 1-itemsets F1 {frequent 1-itemsets};F F?F1; (3) Find frequent k-itemsets Fk=?; for (k=2; Fk-1?? ; k++)  do  Tk  the k-itemsets constructed from Fk-1; for each transaction t?D  do Tt k-itemsets in both t and Tk; for each itemset A?Tt  do if Supp(A)/|D| ? minsupp then Fk  Fk?{A}; F  F?Fk; Q  Q?Tk-Fk;  (4) return F and Q  Procedure 2: Finding both positive and negative fuzzy association rules  Input: a database D; minimum support -- minsupp; minimum confidence --minconf; the set of frequent itemsets F and the set of infrequent itemsets Q from Procedure 2  Output: All positive fuzzy association rules PFAR and negative fuzzy association rules NFAR  (1) PFAR ?; NFAR ?; (2) Extract positive fuzzy association rules in F  for each itemset X?F do for each subset A?X do B  X - A; if Supp(X)/Supp(A)?minconf  then PFAR  PFAR ? {A B}; if Supp(X)/Supp(B)?minconf  then PFAR  PFAR ? {B A}; (3) Extract negative fuzzy association rules in Q  for each itemset Y?Q do for each subset A?Y  do B  Y - A; if A?F? B?F then if Supp(?A?B)/|D|?minsupp  then if Supp(?A?B)/Supp(?A)?minconf then NFAR  NFAR ? {?A B}; if Supp(?A?B)/Supp(B)?minconf then NFAR  NFAR ? {B ?A}; if Supp(?A??B)/|D|?minsupp  then if Supp(?A??B)/Supp(?A)?minconf then NFAR  NFAR ? {?A ?B}; if Supp(?A??B)/Supp(?B)?minconf then NFAR  NFAR ? {?B ?A};  (4) return PFAR and NFAR       ?B ?A are computed. If the confidence is not less than the given confidence threshold, then a negative fuzzy association rule is generated. Note that A and B are arbitrary subsets of Y, hence the first two forms of negative rules also yield the possible negative rules A ?B and ?B A. Therefore, we conclude that Procedure 2 generates all possible three types of negative fuzzy association rules.



V. LEARNING BOTH POSITIVE AND NEGATIVE FUZZY ASSOCIATIVE CLASSFICATION RULES  Associative classification rules are a special subset of association rules whose right-hand-side is restricted to the class labels. Some algorithms to finding associative classification rules have been developed [4][13][14].

Following the lines of [14] and [4], we extend our algorithm presented in previous section to learn both positive and negative fuzzy associative classification rules. In classification, data attributes are partitioned into two categories condition attributes and decision attributes. For simplicity, in this section, decision attributes are converted into decision attribute-value pairs that are indicated as class labels. Thus, class labels are also items in the database, but separate from condition items.

In order to avoid too many classification rules to be formed, we constraint that the left-hand-side of classification rules must be frequent itemsets of condition attributes, or the negation of infrequent conditional itemsets. Similarly, the class labels that appear in the right-hand-side of classification rules must also be frequent 1-itemsets. To this end, positive and negative fuzzy associative classification rules are defined and the corresponding discovery algorithm is presented in this section.

A. Positive Fuzzy Associative Classification Rules  Let A?I be an itemset, and c? C be a class label. The relationship A c is a positive fuzzy associative classification rule, if the following conditions hold:  1)  A ?{c} is a frequent itemsets in D, that is Supp(A?{c})/|D| ? minsupp;  2) A  c is confident, that is Conf(A c} = Supp(A?{c})/Supp(A) ? minconf.

B. Negative Fuzzy Associative Classification Rules  Recall that for itemsets A ? I and B ? I, if A ?B, ?A B, or ?A ?B is a negative fuzzy association rule, both A and B must be frequent, while A?B should be infrequent. In classification rules, B is a class label, and negation of B doesn?t make sense in most applications. Thus, we only consider the format ?A c of negative fuzzy associative classification rules, where A is a frequent conditional itemset, {c} is a frequent class label, and A?{c} is infrequent.

Therefore, let A ? I and c?C be an conditional itemset and a class label respectively, ?A c is a negative fuzzy associative classification rule if the following conditions hold:  1) Supp(A) ? minsupp; 2) Supp({c}) ? minsupp; 3) Supp(A?{c})/|D| < minsupp; 4) Supp(?A?{c})/|D|  ? minsupp; 5) Conf(?A c) = Supp(?A?{c})/Supp(?A) ? minconf.

C. Finding Frequent Itemsets and Frequent Class Labels  To find associative classification rules, the frequent condition itemsets should be discovered. The algorithm of finding these itemsets can be adapted from Procedure 1, and is described in Procedure 3.

D. Finding both Positive and Negative Associative Classification Rules  Associative classification rules can be constructed by selecting the left-hand-side from frequent conditional itemsets the right-hand-side from the frequent class labels. If the union of the frequent conditional itemset and the frequent class label is still frequent, a positive association classification rule is found, while if the union is infrequent, a negative associative classification rule is discovered. The algorithm of finding both positive and negative associative classification rules is described in Procedure 4.

The main idea of Procedure 4 is as follows: 1) To construct positive fuzzy associative classification  rules, add each frequent class label c to each frequent itemset X such that the result X ?{c} is still frequent and then test if X c is a positive fuzzy association rule;  2) To construct negative fuzzy associative classification rules, add each frequent class label c to each frequent itemset Y such that the result X ?{c}is infrequent and then test if ?A c is a negative fuzzy association rule.

Procedure 3: Finding the set of frequent conditional itemsets for associative classification rules  Input: a database D; minimum support -- minsupp Output: the set of frequent conditional itemsets F and  the set of frequent class labels L (1) Initialization: F ?, L ?; (2) Find frequent class labels L  {frequent class labels}; (3) Find frequent 1-itemsets F1 {frequent 1-itemsets};F F?F1; (4) Find frequent k-itemsets Fk=?; for (k=2; Fk-1?? ; k++)  do  Tk  the k-itemsets constructed from Fk-1; for each transaction t?D  do Tt k-itemsets in both t and Tk; for each itemset A?Tt  do if Supp(A)/|D| ? minsupp then Fk  Fk?{A}; F  F?Fk;  (4) return F  and L       3) To construct complex negative fuzzy associative classification rules, a frequent itemset Y is partitioned into two subsets A and B, and the associations ?A?B c and A??B c are tested against the support threshold and confidence threshold.

Procedure 4 only finds the constrained associative classification rules. Step 2) discovers the positive rules that have all positive items in the left-hand-side, while Step 3) searches for the negative rules that have all negative items in the left-hand-side. Step 4) is optional, and can be used to find rules with the combinations of positive and negative items in the left-hand-side. Whether Step 4) should be included depends on the applications and their complexities.



VI. CONCLUSION We introduced existing approaches for both mining fuzzy association rules and mining negative association rules, and discussed the interestingness measure of such rules. By combining these methods, we proposed an interestingness measure for both positive and negative fuzzy association rules and presented an algorithm to discover these rules. The extension of this algorithm to learn fuzzy associative classification rules is also presented. Our future work will be concentrating on the improvement and implementation of the algorithms presented in this paper, and further to build fuzzy associative classifiers by pruning redundant associative classification rules and predicting incoming objects.

