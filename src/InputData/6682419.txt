Data Deduplication Cluster Based on Similarity- Locality Approach

Abstract?Human beings have entered the big data era, and the growing data bring huge challenges for data storage. Existing deduplication methods do not work adequately in many situations. Recently, the data deduplication cluster has become an important need of most commercial and research backup systems. Data deduplication cluster becomes popular in storage system for data backup and archiving. Many researchers focus on deduplication cluster by which to reduce more redundant data.  Especially block level deduplication cluster becomes popular. It is concerned to have two challenges: the chunk- lookup disk bottleneck problem and the data routing problem. A new solution is proposed for chunk-lookup disk bottleneck in our paper. The Approach of combining similarity with locality is applied to the deduplication cluster. At the same time, the bloom filter algorithm storing fingerprint is used to find more duplicate data between nodes. The system architecture and the details are provided. Finally, the experiment shows the system has a good performance.

Keywords?deduplication; similarity; locality; bloom filter; cluster

I.  INTRODUCTION Big data become heterogeneous and unstructured  growing day by day. The mass heterogeneous data generally use distributed storage technology. Since adopting distributed storage, data tend to be divided into several segments stored in different nodes. Many duplicate data backups appear.

Eliminate redundancy technology become important and inevitable. Data deduplication can reduce the storage expenses and achieve efficient management for data quality.

The data backup can increase the reliability of the data, but it brings the redundancy and occupies a lot of space.

Especially rapid growth of big data today, eliminating redundancy technology gets more attention. Deduplication technology is a kind of advanced data reduction approach.

There are advantages of reducing the amount of backup and the storage cost. Single deduplication server has been unable to meet the demand of big data. So the scalability is also the inevitable development direction. Clustered deduplication technology has received a broad attention from both academia and industry.

The rest of this paper is organized as follows. Section 2 introduces the deduplication knowledge, then Section 3  focuses on our deduplication cluster. Section 4 presents our experiment evaluation. Section 5 conclusions and future work are given.



II. DEDUPLICATION TECHNOLOGY Data deduplication is, quite simply, removing copies  (duplicates) of data and replacing it with pointers to the first (unique) copy of the data. Data deduplication is the process of examining a data set or I/O stream at the sub-file level and storing and/or sending only unique data [4].

A. Data Deduplication According to the data size, deduplication can be divided  into file-level, block-level and byte-level. Deduplication at file level guarantees that no duplicate file exists. Block level ensures that segments of duplicate data within a file could be detected. Byte level requires too much I/O operation.

Deduplication at block level can balance data reduction rate and the system expenses, so it is used widely. Deduplication at block level is also applied to clustered data deduplication.

Deduplication technology detects duplicate data segments with ?fingerprint?. The fingerprint uses hash functions such as MD5, SHA-1 to identify segments uniquely. There are two primary approaches for data deduplication: similarity-based deduplication and locality-based deduplication. Similarity- based exploits data similarity by extracting similar characteristics from backup stream. File similarity is a well- known approach. Locality in the context means that the chunks of a backup stream will appear in approximately the same order in other backup stream with a high probability.

B. Data Deduplication Technology Principle Data deduplication technique only stores one copy of  data whenever multiple copies of the same data block need to be stored. Backup application generally benefits the most from deduplication due to repeated full backups of an existing file system. A simple example of data deduplication is derived from an EMC video [6]. Data deduplication reduces the size of the stored data in Fig.1. Data deduplication technology recognizes that the files are duplicate and only stores the first one. When the files are divided into several segments, different files can recognize duplicate data segments. The basic principle of data deduplication technology is to filter the  Physical and Social Computing  DOI 10.1109/GreenCom-iThings-CPSCom.2013.409     same data segment, and only to store a pointer to point the stored data segment.

Document1.docx 6MB  Without de-dup 6MB  With de-dup 6MB  Document2.docx 6MB  Document_new.docx 6MB  6MB  0MB  6MB  1MB  =18MB  =7MB  AB  D E  C  F  A B C  D E F  A B C  D E G  Fig. 1 Data deduplication example [6]

III. DEDUPLICATION CLUSTER BASED ON SIMILARITY- LOCALITY  A single node deduplication system cannot fulfill the needs by enterprises and industry. Clustered deduplication system is the application of multiple cooperating deduplication system. Clustered deduplication makes the management easier, and reduces storage costs.

A. Bloom Filter Principle Bloom Filter was invented by Burton Bloom in  1970[15].It is consist of a long binary vector and a series of random hash functions. It judges whether an element belongs to a set or not. An empty Bloom filter is a bit array of m bits, all set to 0 initially. There must be k different hash functions defined, each of which hashes an element to one of the m array positions with a random distribution. To query an element (check whether it is in the set), to hash it to each of the k hash functions to get k array positions. If any of these k positions are 0, the element is definitely not in the set. If it is not, all k positions would have been set to 1 when it was inserted. But we may consider an element as the set?s member mistakenly. This situation is called false positive. See Figure 2.

0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0  x, y, z  w v  Figure 2  m=18 and k=3, representing the set{x, y, z}, the element w is not in the set{x, y, z}, v may be an element of the set or just a false positive (the bits have been set to 1 during the insertion of other elements by chance).

Bloom filters have a strong space and time advantages for storing fingerprint, so we use it to create fingerprint information for every node.  In our deduplication cluster, one node owns local fingerprint information and fingerprint summary of other all nodes. When one data segment comes, the node checks its local segment fingerprint information firstly. The node compares similarity between bloom filters of segments. If bloom filters of segments have more common 1, the two segments have more similar. The node accesses local block of this segment. If bloom filters of segments have not more common 1, the node checks fingerprint summary rapidly. When this segment is new in fingerprint summary, we will store this segment in this node. Otherwise, if the result of querying fingerprint summary indicates that other nodes have a high similarity copy of this segment, we check that node?s local fingerprint information to make sure that the segment is duplicate or high similar for the purpose of avoiding false positive. A false positive means that the data segment is not duplicate or high similar, but we misjudge it as a copy or high similar segment. The misjudged data segment should be not discarded.

B. Our Approach of Similarity-Locality When the backup stream comes, it is divided into many  segments (2MB) according to file size. A large file ( 2MB) is divided into many small segments. Many small files( 2MB) consist of a segment. A block (256MB) consists of several sequential segments. It can retain locality of data segments. Bloom filters store fingerprint, so two bloom filters of segments can compare similarity. When two segments have more numbers of common bits set 1, they have more similar.

Here we demonstrate our method using the Tanimoto similarity measure, which corresponds to the ratio of the number of common bits set to 1 to the total number of bits set to 1. It is given two fingerprint bloom filter vectors A and B.

SimT(A,B) = both AB  only A + only B + both AB   Only A means number of bits set 1 in bloom filter vector  A, only B means number of bits set 1 in bloom filter vector B, and both AB means number of bits set 1 in both bloom filter vectors A and B. The similarity value is in the range [0.0-1.0], and the larger value is the more similar. When similarity value is less than 0.8, our system considers the two bloom filters as different. We choose a segment fingerprint stored in the local fingerprint for each block, and each fingerprint summary has node ID information. Each block contains several contiguous segments and preserves their locality-layout, so we set a table storing segment fingerprint.

C. System Architecture and Implementation Deduplication cluster based on Bloom Filters aims at  achieving deduplication to reduce redundancy between nodes.

(1)     We use Bloom Filters to store fingerprint information for each node. The Similarity-Locality approach improves duplication elimination ratio and deduplication throughout in the nodes.

Using similarity algorithm calls corresponding block in the cache or on the disk, then we can check contiguous data segments in the block by locality to reduce accesses to the disk.

Data streams Segment partition  Segments  disk  Computing and storing fingerprint by bloom filter  disk  RAM  Fingerprint Summary Local Fingerprint  cache Block  RAM cache  Block  Local Fingerprint Fingerprint Summary  Block Block Block  Block Block Block  Block Block  Segment transfer Meta-Data Server  Meta-data read/write  Meta-data information feedback  Client  Node 1  Node n Deduplication Server  Meta-data information feedback  Fig. 3 System architecture  Our system architecture consists of three functional components in Figure 3, Client, Meta-Data Server, Deduplication Server.

? Client is responsible for gathering backup datasets and communicating with storage node and Meta-data Server to exchange information. At the same time, the client processes segmenting, computing fingerprint, storing fingerprint by bloom filter, and distributing segments to storage node.

? Meta-Data Server is to store and look up all fingerprints of files and segments.

? Deduplication Server is to eliminate duplicate data and store backup data. The system needs multiple storage nodes for parallel deduplication.

Fig.4 shows our clustered deduplication implementation process. For an incoming backup stream, files are segmented to be distributed to the nodes. When one data segment comes, it is checked for similarity in local fingerprint. If it is the same, the segment is not stored. If it is high similar, the system calls the corresponding block. When the data segment is low similar, it is checked for similarity in fingerprint summary. If the data segment has a high similarity, the system assigns the segment to the corresponding node. If it is not a high similarity, local node stores the segment fingerprint and updates fingerprint summary of other nodes.

Similarity in local fingerprint for the  input segment  Exist in local fingerprint?

Similarity in fingerprint summary  Exist in fingerprint summary?

Yes  Yes  No  No  Update local fingerprint and fingerprint  summary of others  Similar or Dup?

Dup Not store  Similar  Block In the cache?

Yes  No  Similarity in the block  Assign segments to other Node  Dup  Similar  Call from the disk  Fig.4 Clustered deduplication implementation

IV. EVALUATION Our system is tested for its duplicate elimination ratio and  throughput. The system accepts a small probability of false positive. The data sets are composed of files from a series of backups. For duplicate elimination ratio, we compare our system with two other situational systems, the similarity-based Extreme Binning and the locality-based ChunkStash System.

The incremental backup is used to test duplicate elimination ratio. For deduplication throughput, it is observed throughput of deduplication cluster as nodes increase. The experiment is benefit to evaluate our system performance.

A. Duplicate elimination ratio Figure 5 shows the duplicate elimination performance of  three systems under the incremental backup. We call our system SL_BloomFilter. As the backup size increases, SL_BloomFilter removes about 91%~98% duplicate data. The average elimination ratio is 94.5%. The average elimination rates of ExtremeBinning and ChunkStash are respectively 76.38% and 67.23%. Compared with Extreme Binning and ChunkStash, our system has a high elimination performance.

Extreme Binning only exploits file similarity, but it misses some duplicate data in the file and ignores locality of files.

ChunkStash exploits the inherent locality in a backup stream.

But when the data sets do not have locality, it will lose its advantages and find little duplicate data. Our system finds more duplicate data in the same data set. The system checks local fingerprint table of using similarity algorithm to find similar segments, and at the same time to use locality algorithm to detect duplicate segments in the node. When the system can not find similar segments in the node, and the system also checks fingerprint summary table to find more     duplicate data between nodes. The approach can eliminate more duplicate data and obtain high eliminate ratio.

Fig.5 The percentage of duplicate data elimination  B. Deduplication throughput Figure 6 shows deduplication throughput in our cluster  system and ExtremeBinning system. We can observe high throughput when the number of nodes increases. In our system, the total data streams have a parallel process, and the bloom filters decrease the query speed of fingerprint information.  The highest throughput is almost 2251MB/s.

When the nodes increase to 5, the throughput changes little.

Due to finding more fingerprint information and allocating more resource, the throughput of the system is affected. In ExtremeBinning system, at first the throughput is low, and the highest throughput is 1432MB/s, and the throughput increases slowly. When the nodes increase to 7, the throughput changes little. First the number of files is little, and it is difficult to find the similar files. The nodes increase later, and files information increase and find more similar files to improve throughput. Compared with ExtremeBinning system, our system has a high throughput. The similarity finds more similar segments. The Locality complements the similarity detection to find more duplicate segments and alleviates the disk bottleneck due to frequent accesses to on-disk index. Due to space and time advantages of Bloom Filters, it is benefit to store fingerprint information to speed up to query information.

Because of those reasons, our system achieves high throughput.

Fig.6 Deduplication throughput  Our system can boost the deduplication by caching more fingerprint information in RAM to reduce accesses to on-disk index. At the same time, using bloom filters in the cluster accelerate to communicate information. Therefore, compared with other system, high throughput and duplicate elimination ratio in our system is presented to provide good deduplication performance.



V. CONCLUSION AND FUTURE WORK In this paper, we present our deduplication cluster.

Results of the experiment show that the system optimizes duplicate elimination ratio and throughput. First, fingerprint summary based on bloom filters achieves information exchange between nodes. The similarity-locality approach eliminates redundancy in the node.  The similarity algorithm finds more duplicate segments by comparing bloom filters of segments. The locality of the backup stream is kept by grouping contiguous segments in the block to alleviate the disk bottleneck. The approach overcomes the shortcomings of existing approaches. The experiment shows that the system brings high eliminate ratio and throughput.

For our future work, the reasons of the good performance and the influences of other factors are considered. For example the false positive probability of bloom filters is considered. Bloom filters have many varieties, and the new approaches can be considered in our system for the future work. We also plan to apply our system to other deduplication application such as cloud storage.

