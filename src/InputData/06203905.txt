Verdict of Association Rule Using Systematic  Approach of Time Slicing for Efficient

Abstract-In Data mmmg, Association rule learning is a popular and well researched method for discovering interesting  relations between variables in large databases. The main task of  association rule mining is to mine association rules by using minimum support thresholds, which could be explicitly specified  by the users. Minimum support threshold is the one which differentiates frequently observed patterns from infrequent  patterns from large number of transactional databases. In  algorithms like association rule mining, sequential pattern  mining, structured pattern mining, correlation mining, and  associative classification, minimum support threshold is set up,  by the user, to uncover the frequent patterns. Detecting a  complete set of association rules is the desired aspect in data  mining. But whenever the user specifies minimum support  threshold, there is an ample chance of losing some association  rules. This may lead to incompatible decisions. To overcome this  problem, systematic algorithm has been proposed in this paper.

In this algorithm, the user is not allowed to specify any minimum  support threshold values to find the frequent patterns; instead  the system itself generates the minimum threshold values, thus  plugging the loophole of other algorithms. Using this approach,  the user is well aware of entire information aiding him to take  correct informed decisions. We also introduce the concept of  timing algorithm along with the systematic algorithm, which will  statically assign a unique value to each record of the  transactional database. This technique is mainly used to save  time by scanning through the entire transactional database only  once rather than making multiple scans. The benefit of one scan  database leads to better performance and minimization of time.

Keywords-Data mining, minimum support threshold, multiple scan, Systematic Algorithm, timing algorithm.



I. INTRODUCTION  Data mining has pulled in a great deal of attention in the information and communication technology and in the society in the recent years. It has an enormous power to turn a widely available data into useful information and knowledge. This information and knowledge, which is extracted from the raw data, can be used for many applications such as market analysis, telecommunication industry etc .. ,  The research on association rules has undergone a major progress for more than fifteen years in the data mining field.

Association rule mining [1] , [2] , [3] is the method, which is   widely used, to detect the association rules for any given set of transactional records with the help of support and confidence. The association rules can be found out by using logical evidence in the data. An association rule can only be accounted into consideration if only there is enough logical evidence in the data. This bearing of logical evidence can be found by the presence and absence of items during the mining. The main aim of using association rule mining technique is to find the associations between items in a certain transactional record. Finding association rules is totally based on the support and confidence models, where a minimum support (min_sup) has to be specified to start the search [I] .

There are many disadvantages in doing so. Firstly, if this support threshold is set high, then there will be a major chance of losing many frequent itemsets and when this threshold is set low, unnecessary frequent itemsets will appear. In addition to this issue, if an item sets passes a minimum support threshold then all its subsets will also pass this value. If this threshold value is removed, then we don't have any pruning opportunity, which results in exponential search space. For finding the frequent itemsets, it is required for making multiple scans throughout the database. This results in wastage of time and space when it is applied in the real world applications. This is another drawback in finding the association rules.

Based on the above drawbacks, we proposed an algorithm to deal with the above said issue, regarding the need for minimum support threshold. That is, this threshold value will not be given by the users. Instead it is being calculated accordingly with the help of proposed algorithm.

Here, we also introduce the concept of timing algorithm, which will statically assign unique values to each transactional record in the database. By using this concept we can retrieve the records from the database by making a single scan rather than making multiple scans. This will also saves a lot of time and also reduces the search space, which will be more when multiple scans are done.

A. Contributions a/This Paper  The main contributions of this work are as follows: ? We devise a new algorithm to systematic algorithm  with time slice to discover pattern in one scan     database. The proposed algorithm uses a milepost to fmd the occurrences of particular itemsets.

? To avoid the loss of association rule, we introduce systematic algorithm where the minimum support threshold has been generated for every itemsets based on the systematic rule proposed in this paper.

? Comparison of systematic algorithm with other existing algorithms shows that proposed algorithm gives better performance and minimization of time.

The remainder of the paper is organized as follows: Section 2 gives an overview of the basic concepts involved in association rule mining. Section 3 deals with the concept of two proposed algorithms to discover pattern in one scan database and also the parameters used in the algorithms.

Section 4 presents Experimental results along with the performance of the proposed algorithm compared to known algorithms. In Section 6 We summarize our research and discuss some future work directions.



II. RELA TED WORKS  It is a common convention that finding frequent item sets will give us the associative knowledge of the different items present in the transactional database. This knowledge in turn is useful for finding the associations between different pairs of items present in the transactional database. Recently, it is approved that infrequent itemsets are also useful in disinterring the knowledge that is not available in the frequent item sets and these infrequent itemsets are also considered as interesting [4] , [5] , [6] , [7] , and [8] . Many algorithms such as apriori [12] for example are does not provide a method for fmding the infrequent item sets as well as the negative associations between any items present in the given itemsets.

This is due to the reason that fmding these infrequent items and the negative associations will results in the exponential search space.

But attempts are made to find some of the infrequent association and one such approach is [9] . This approach proposed a generalized association using correlation.

Correlation is usually measured by the method of chi-square.

When the value of the chi-square's expected value is low, it is not possible to deduce the association accurately and hence results may be affected. This will be mainly based on the support threshold values. Hence the infrequent items that are present above this threshold only are possibly found. The ones that are below this threshold value will be automatically lost.

The constraints in fmding the infrequent items and the interesting association rules are select the measure for finding them and use this measure in finding them directly without processing the already found ones.

A. Association Rules  Association rule mining is the efficient method which is used in fmding the association rules. These association rules describe the associations between the attribute values of any  item set. They can be found by means of various methods among which support and confidence [10] , [11] will be considered as the optimized methods in finding them. The key to find the association rules is to fmd all the frequent item sets present in the given transactional record by means of the minimum support threshold. An association rule is best expressed by means of the expression X -> Y. it means that for any occurrence of item X present in the database there is relatively high probability of occurring the item Y. here X is called as antecedent and Y is called as the consequent. The strength of such rule can only be calculated by means of its support and confidence.

B. Support  Support is the one which is used to fmd the strongest association rules in the itemsets. It is the most widely used measure for finding the association rules. For any given rule X => Y, support will measure total number of transactions that contains both the items X and Y in percentage.

C. Confidence  Confidence is another approach for fmding the association rules. It implies the probability that any association rule will repeat itself in future transaction records.

Confidence measures the number of transactional records that contains item X that also contain Y in percentage.

D. Positive Association Rules  The normal convention in discovering the association rules is by means of any frequent itemsets that are present in the given transactional database. The rules that are normally obtained by means of using minimum support threshold and minimum confidence threshold are generally referred as the positive association rules and the rule is of the form ?A- ?B.

That means that they are capable of associating one element to the other element in a given set of transactional records.

E. Negative Association Rules  Contrary to the positive association rules described above, negative association rules are defmed as the rule that involves the absence of itemsets. For example, consider A => ?B, here ,?, indicates the absence of an itemset B in a set of given transactional records. The rules of the forms (A- ?B, ?A- B and ?A- ?B) are negative association rules [12] .



III. ISSUES IN FINDING ASSOCIATION RULES  A. Minimum Support Threshold  The minimum support threshold is the one which is used to find the frequent item sets for any given transactional records from a database. Many algorithms such as apriori, FP? tree etc. use this minimum support threshold in finding the frequent itemsets. This threshold value is pre-set by the users.

When the user has given a high threshold value for finding the frequent item sets, there will be situation where some of the      necessary frequent item sets will get lost. This will affect the decision making, when done from the obtained incomplete set of frequent item sets. And also, when the user pre-sets this threshold value very low, then an abundant frequent itemsets may arise. Many of these frequent items may be unnecessary in decision making. This leads to a problem of not making an optimized decision, so, if we want to get the required frequent item sets there is a need for setting the threshold value very precisely. But setting an accurate threshold value in the real time applications will be a difficult job for any user.

B. Multiple Scans across the Transactional Database  During the process of finding any frequent itemsets from the database, it will be obligatory for scanning the entire database more than once. This mUltiple scan of the entire database may usually results in two problems.

? Firstly, the searching for any item through the entire database may increase the search space exponentially.

There arises a need for lot of memory for each search of the database.

? Secondly, searching through the entire database may  increase the time taken to find the required item. Now-a-days, all the real world applications are mainly time efficient ones.

To overcome this issue, we proposed another algorithm called timing algorithm in which the time slice will be assigned statically and the main advantage of this algorithm is that entire database will be scanned only once.

Existing Work

IV. CONCEPT OF THE PROPOSED FRAMEWORK (SOLUTION TO THE ABOVE ISSUES)  Apriori Algorithm  Figure l.Proposed framework  A. Systematic Approach  To overcome the above said issues, we proposed a systematic algorithm to discover patterns using highest support values in the systematic table. This will take any dataset as input, and a systematic table (Table 1) is constructed for every transaction in the provided in the dataset. The systematic tables for every itemsets involved in the datasets are calculated by the following conditions:  Supp (A---> B) =supp (A) + supp (B) + supp (A UB) (1)  Supp (A---> ?B) =supp (A)-supp (A UB) (2) Supp (?A---> B) =supp (B) - supp (A UB) (3)  Supp (?A---> ?B) =1- supp (A)-supp (B)+supp(A UB) (4)  TABLEl  PRELIMINAR IES AND NOT A nONS IN THE PROPOSED FRAMEWORK  Notions Definition  TDB Any Real-time Transactional Database  Count(l) Count of Pattern T in TDB  an(I) The n I' transaction of pattern 1 in TDB sn(l) Position of pattern I in TDB  Supp: Positive Support of a Pattern 1 after its nIh milepost in the transaction  Supp.n Negative Support of a Pattern 1 before its nl' milepost in the transaction  PRn(l) The Pattern Ratio of particular pattern I  B. Algorithm  Parameters Included: TDB - transactional database, TID? transaction ill, PR - pattern ratio Initialization:  Time = Assigned Time / Total Transactions Pos = 0, Neg = 0; Input: Read the input from the transactional database (TDB) Output: Discover Patterns in one scan database Systematic Algorithm: For each transaction in the transactional database do:  Supp (A -> B) ? Supp (A) + Supp (B) + Supp (AUB)  Supp (A -> ?B) ? Supp (A) - Supp (AUB)  Supp (?A -> B) ? Supp (B) - Supp (AUB)  Supp (?A -> ?B) ? /- Supp (A) - Supp (B) + Supp (A UB)  Systematic Rule:  L: For each itemset generated from the systematic table do  Supp (A -> B) = Supp (A) + Supp (B) + Supp (AUB)  Supp (?A -> ?B) = 1 -Supp (A) - Supp (B) + Supp (A UB)  Loop [L] until no itemsets has been left in the systematic table Goto T.

Timing Algorithm:  T: For each of the itemsets in TID do Find the count of a pattern as Count (1, TDB) = {(transid, x) (transid, x)} Milepost of Negative Support:  Supp.n = n / (J (sn (1)), Where 1:::; n < Count (1) Milepost of positive support: Supp/ = [Count (1) - n) / [TD - (J (sn (I))), Where 1 ? n ? Count (1)  Find the Pattern Ratio:      PR I (I) = [Supp+n (I) _ Supp.n (I)] / MAX (Supp+n, Supp.n), where 1 S n S Count (I)  Begin If(PR> 0) Pos++ Else Neg++  End if  If(Pos > Neg) "Pattern Discovered" Else "Pattern Undiscovered" End if  End Table II.

SYSTEMATIC TABLE  Subsequent  Ancestor B ?B  A 01 G2  ?A G3 04  B. Filtering out Undiscovered Pattern from Systematic Table  With the help of the above defmed table it will be easy to find the systematic rules present in the given dataset. These systematic rules can be extracted by means of the following conditions: Supp (A-+ B) =supp (A) + supp (B) + supp (A UB) (5) Supp (?A-+ ?B) =l-supp (A)-supp (B)+supp (A UB) (6) In simplified form, the systematic rule is written as:  i) Gl > (G2, G3)  ii) G4> (G2, G3)  C. Timing Approach  All the transactions in the provided dataset are assigned a unique value statically, known as times lice. The advantage of this times lice is that entire database has been scanned only once. This results in better performance and minimization of time.

D. Pattern Reading  We will normally face a situation where reading a desired pattern from the list of transactions or finding the number of times the given pattern had occurred are necessary.

Count is the variable which will output the number of occurrences of the required pattern. A milepost is set up to keep track of the time slice value for each transaction. The position of the pattern and its corresponding milepost values are obtained to get the positive and negative support of a pattern. A pattern ratio is calculated based on the positive and negative support of a pattern. The pattern ratio which will be positive for a majority of item sets are recognized as the  frequent patterns and the pattern ratio which will be negative are considered as infrequent. This will eradicate the drawback of users specifying the minimum threshold value to find the frequent item sets and also multiple scan databases.

a) The cover of an item set I in TDB, denoted by count (I, TDB), consists of the set of transactions that support (X) Count (I, TDB) = {(transid, A) (transid, A) S D } b) The support of a pattern (I) before its nth milepost in transaction, denoted by Supp.n (I), is defined as:  Supp.n = n / (J (sn (I)), Where 1:::; n < Count (I)  c) The support of a pattern (I) before its nth milepost in transaction, denoted by Supp+", is defined as: Supp/ = [Count (I) - n} / [TD - (J (sn (I))), Where  1 S n S Count (I)  d) The Pattern ratio of pattern (I) at its nth milepost in transaction is defined as: PR n (I) = [Supp/ (I) - Supp.n (l)} / MAX (Supp+n, Supp.n),  where 1 S n S Count (I).



V. EXPERIMENTATIONS  The proposed algorithms, used to manifest the efficiency of the patterns and also to show the importance of using time slicing. The proposed algorithm has been applied on various datasets which are taken from the real-world domain.

A. Measuring Symptoms for Diseases  The association rules for the medical database have been considered that poses some symptoms of disease. The transactions for these are described in Table IV. We compare the association rules for already existing algorithm and the proposed algorithm and we prove that the proposed algorithm is efficient by improving performance and by minimizing time through single scan of entire transactional database with the concept of time slicing. This will helps in proficient decision makings.

TiD I       B. Implementation of the Proposed Work TABLE III  TRANSACTIONS OF THE MEDICAL DATASET  itemsels Time Slicing Skin-lesions, nerve-thickening , weight-loss 16.6666  Boil heads , poor-memory ,body-weakness 33.3333  Voice-change, body-weakness, weight-loss 50  Chronic-cough, weight-loss, voice-change 66.6666  Body-weakness, weight-loss, poor-memory 83.3333  Poor-memory, Boil heads ,skin-dryness 100  In fig 2, the frequent Itemsets are found by means of existing Apriori algorithm. The rules can be found out by user specifying the minimum support threshold value.

I TAANSACTIONAlDATAllASE  skin-lesions nerve-thickening weight-loss boiJheadspoor_memruybody_we&kness voice-change body-weakness weighl.-loss chronic-cough weight-loss voice-change  body-weakness weight-loss poor-rnemory poor_rnemotyboilheadsskin-dryness  Enter Support Threshold" ? fiNDING FREQUENT ITENSET  No.OfTnnsactions No.ofIterns " Items:   Aptiori  skin_lesions nelVe_thickening weight-loss boilheads poor-memory' body-weakness voice-change body-we&kness weight-loss chronic-cough weight-loss voice-change body-weekness weight-loss  poor-memotypoor-memotyboilheadsslcin-dryness No of Unique !tems Unique Items: skin-lesions nerve-thickening weight-loss boilheads poor-memory'  body.weakness voice. change chronic.cough skin.ruyness Subset" skin-lesions, nelVe-thickening. weight-loss, boilheads, poor-memory,  body-weakness, voice-chmge, chronic-cough, skin-dryness, skin_lesions ne",e_thickening, skin-lesions weight-loss, skin_lesions  boilheads, skin-lesions poor-memory, skin-lesions body-weakness, skin-lesions voice-chmge, skin-lesions chronic-cough, skin-lesions skin-dryness,ne",e-thickeningweigbt-Ioss,nerve-thickeningboilheacis, nerve_thickening poor_memory, nerve_thickening body_weakness, ?  Figure 2.Generation of Frequent Ttemset  In fig 3, generate the systematic table by using the conditions (1, 2, 3, and 4)  Rea:ilr(:U: ASsoBOORi.Jes SystermRUes ? rme? Ii?? Ext  GenerallngSystematicTabJe  [RANSACTI JN?DA11W p" -., .,.,., " ... ,1 "N? ,x ISllJflP!UY ,",""""",?w..",.;jtlm 1 1:?011'- ? _1 UUm2 CWm3 ? ....,,"""""'? j Tr? ? """""'?,.;jtl>, No.dllems: ch?,.;jtlm"'''''''' 18  Y=skiHesms ;y,,",",,,, ?rmsswe9ttlSSlMireIJD)I ,,"" """"",lID .. "",""," '"'"""""eM,..,.;jtl>,IID" x'...." 0 1  """""'?"""""' lX,IID" , 3 """'_,.;jtlmch? ,.;jtlm"''''''''?' Y=skiHesms ;Y',",""" we9ttlsSlMireIJD)IlM??S X=IMMOJI 0 3 ....,... 7I.=IM? 1 1 NodUrqJeUems: j Y=skiHesms ;y,,",",,,, U?IIems: X=?ss 0 3 '"'"""""eM,..,.;jtl>,IID" 7I.=?ssl 1 """""'?"""""' ch""?"""" Y=skiHesms ;y,,",",,,,  x'"""""' 0 1 TrillIDOOl:?ner'le-ttd:.erftJ lX,"'""", 1 3 ,.;jtlm  = Y=skiHesi:ns ;y,,",",,,, = ....... ?,.;jtlm  Figure 3.systematic table generation  In fig 4, we find the systematic rules with the help of the rules defmed above in the condition (5, 6) Read Input Association Rules Systematic Rules Comparision Time Slicing Graph Output Exit  Systematic Values  boil heads skin-lesions Q22 Q31 Q43 poor-memory skin-lesions Ql0 Q23 Q42 body-weakness skin-lesions Q23 Q31 voice-change skin-lesions Ql0 Q22 Q31 Q43 chronic-cough skin-lesions Q21 Q31  Show Systematic Rule  E31 pOOl-memOlY -} body-weakness B NOT poor-memory =) NOT body-weakness  boilheads =) poor-memory  !:II  NOTboilheads =} NoTpoor-memOlY body-weakness =) poor-memory NOTbody-weakness => NoTpoor-memory  Figure 4.Systematic rule generation  Read Input Association Rules SystematiC Rules Comparision Time Slicing Graph Output Exit  .5' C .......... lon of Aprlorl .. nd $yo_lit Rulo I!I-  Assocation Rules tlu"ough Apriori Algorithm  boilheads -) pOOl-memory pOOl-memory =) boilheads pOOl-memory =) body-weakness body-weakness =) weight-loss body-weakness =) poor-memolY voice-change =) weight-loss skin-lesions =) nerve-thickening skin-lesions =) weight-loss skin-lesions =) nerve-thickening weight-loss nerve-thickening :) skin-lesions nerve-thickening =) weight-loss nerve-thickening =) skin-lesions weight-loss weight-loss :) skin-lesions weight-loss =) nerve-thickening weight-loss :) poor-memOlY weight-loss =) body-weakness weight-loss :) voice-change weight-loss =) chronic-cough weight-loss =) skin-lesions nerve-thickening weight-loss :) poor-memory tPdy-weakness weight-loss =) body-weakness voice-change weight-loss :) voice-change chronic-cough boilheads =) pOOl-memory boilheads :::) body-weakness boilheads =) skin-dryness boilheads =) pOOl-memory body-weakness boilheads =) pool-memory skin-dryness pOOl-memory =) weight-loss pOOl-memory =) boilheads pOOl-memory =) body-weakness pOOl-memory =) skin-dryness pOOl-memory =) weight-loss body-weakness pOOl-memory =) boilheads body-weakness  Ilo1I  I  !:II  Assocation Rules through systematic Rule  poor-memory -) body-weakness NOTpoor-memolY =) NOT body-weakness boilheads =} poor-memory NOTboilheads =) NOTpoor-memolY body-weakness =) poor-memory NoTbody-weakness =) NOT poor-memory  Figure 5.Comparison of the proposed and existing framework  Comparison of algorithm is shown by graph.

Relldlnput Association Rules SystemllticRules Compllrislon TimeSKinQ GrllphOJtput":"'!:" :;,"'---------  ,.

__ l1llii"  u-  ,,-   ? s...obHt1  ,.

Apfiofi .

s...obHt2 .

s...obHt3  Figure 6.Minimum support threshold vs. Ttemset  Milepost Vs Pattern Ratio - "  Figure 7.Milepost vs. Pattern ratio     A comparison is being done between the nwnber of items present in the given transactional records and nwnber of systematic rules generated by using a certain support value.

Figure 9.Proposed framework results in better Performance and minimization of search space

V. CONCLUSION  Our proposed algorithm will be very efficient in fmding the association rules between the items of the provided dataset. The use of time slice also helps in avoiding the mUltiple scans across the database. This will leads to better perfonnance (search space), minimization of time and useful in effective decision makings.

