Associative Memory Using Ratio Rule for Multi-valued Pattern Association

Abstract- A novel learning algorithm, named ratio rule, for association of multi-valued patterns in a recurrent neural network is proposed in this paper. The learning is performed based on the degree of similarity between the relative magnitudes of the output of each neuron with respect to that of all other neurons The dynamics of the neural network functions as a line attractor as opposed to the,common concept of point attractor. The limit of the convergence region around the line of attraction is defined based on the statistical characteristics of the input patterns. Theoretical analysis of the associativity of the network with the ratio rule confirms the authenticity of its learning ability. The performance of the ratio rule on associativity and convergence of the recurrent network is evaluated by conducting several experiments on face images. It is observed that the ratio rule is suitable for retention, reconstruction, and restoration of learned patterns with varying face expressions.

1. INTRODUCTION  For more than a decade, neural network research has been considered important not only because it makes efforts toward explaining our intelligence, but also because it provides effective working models for solving wide range of practical problems. Numerous researchers (e.g. Rumelhart, Grossberg, Kohonen, and Hopfield) established the theoretical background in this field. The model they have developed: the multilayer perceptron trained with supervised backpropagation learning algorithm [I], the ART & ART- Map [2], the self-organizing Kohonen?s Map [3], and the Hopfield network [4], were theoretically [5] and experimentally [6] proven to be capable of solving many complex tasks [7].

One of the major goals of both biological neural network modeling and artificial neural networks research is to discover better learning rules to yield networks that can learn more difficult tasks, such as tasks that the brain can handle [SI. The principle of association formation has dominated our understanding of learning and memory since William James published ?Principles of Psychology? at the end of the nineteenth century [9]. A fundamental problem in associative memory concerns how memory is encoded by the neural network learning algorithm [lo].

An associative memory model can be formulated as an input - output system, as shown in Fig. 1. The input to the system can be an n dimensional vector a ?  R?  called the memory stimuli, and the output can be an L dimensional  vector b e  R L  called the memory response. The relationship between the stimuli and the response is given by b = f(a) , where f : R ?  - t R L  is the associative mapping of the memory. Each input - output pair or memory association (a, b) is said to be stored and recalled in the memory.

Fig. I. Block diagram of associative memory  In most models of associative memory, memories are stored as attracting fixed points at discrete locations in state space [4]. Fixed-point amactor may not be suitable for patterns, which exhibit similar characteristics such as face images with varying expressions. As a consequence, it may be more appropriate to represent the face expression images using a line attractor network [11][12].

In this paper, we propose a novel learning algorithm for a single layer recurrent neural networks suitable for multi- valued (or gray level) pattern association. The proposed learning algorithm involves minimizing the maximum distance of the statistical properties of the relative magnitudes of the state of two neurons to represent the synaptic weights between them. The dynamics of the neural network can function as a line attractor, which represents the statistical characteristics of the stored patterns.

11. LEARNING MODEL  Let?s consider the fact that there exist some relation between each neuron with every other neuron, and that relationship may be described by the ratiobf two neurons:  bS W(s)=- as  for stimulus-response (or input-output) pair (as,bs) and the  resultant memory W e ) ,  The term - represents the ratio bs a s  0-7803-7898-9/03/$17.00 02003 IEEE 2518  mailto:vasari)@odu.edu   =  where 1 is the covariance matrix. We usually find the value of  p that maximized In by differentiating it by the  component and setting the result to zero [13]:  ~ ~  b; b; by a i  a; a h  .b; b; b;  a; a; a h  (2) . .  . .  . .  . .  . .  . .

b a  h; b:  . as a; a h  .

7 h e  maximum likelihood estimation for p can be obtained by  Multiplying ( 5 )  on both 'left and right side by 1 and rearranging, we obtain the following maximum-likelihood estimation for U.

Equation (6) shows that the maximum likelihood estimate for the unknown population mean is just the arithmetic average of the training samples. Fig. 2 shows the weight graph illustrating the concept of training based on (6). A weight graph is a graphical representation of the relationship between the ith neuron and the jfh neuron for P patterns.

Utilization of the weight graph may help visualize the behavior of one neuron pair.

Fig. 2. Weight graph  Based on the above theory, the memory matrix for the N neuron network can he obtained as:  where X, E {1,256} can be the magnitude of the input at mrh neuron. The learning algorithm can be interpreted as the mean ratio between two neurons. The network architecture is a single layer fully connected recurrent neural network. The net output of the network can be computed as (Fig. 3):  I N N j.1  Net, = - ~ w , , x ,  where N is the number of neurons. The Net, can be thresholded considering the region of distance of the weight components in the weight graph shown in Fig. 2.

Fig. 3 .  Simplified madel afa  neuron with threshold function     That is, wS gives a linear approximation for all the  points-. In order to preserve each pattern, we need to find X;  X f  the region where the threshold can preserve each pattern. The dashed line in Fig. 2 is such a distance. Mathematical representation of the threshold function can be expressed as:  0:'" =f(NetYW)  opId if winL, 5 Net:' - o Y ' ~  5 winR, (9)  =i Net:" otherwise  where winL, and winR, are the window functions for thresholding. They can be expressed as:  I N N j=i  winLi = a - c T l j  I N N j=r  winRi = a  - c T r j  where a is a constant and 0 < a 5 I and Tb and Tij can be expressed as:  (12) TI = Min(w ,xj  - x i )  for I 5 i 5 N-  Tr-=Max(wijxj-xi)  J f o r l < i S N  (13)  The window width between winLi and winRi decides if the  should be updated or not. That is, winLi and w i d i  calculate the mean of the maximum distance from the approximate functions, which is also the maximum error from the approximate hnction of the xi and uses it as a function of threshold. Fig. 4 shows the activation function for each neuron.

t I   .:Id - winLi o:Id o:ld + winRi 4 b  Fig. 4. Window function for activation  111. ANALYZING THE ASSOCLATLVITY  The proposed leaming algorithm is defined as:  Given X = {x' : s = 1 ..P}, ideally, we would want  xo = f(WXP) if Xp is one of the trained patterns. So, let us assume:  r .  1  As a result, we could see that when  which also implies that if  or sufficiently close as defined in the threshold function (9), the leaming algorithm will be able to correctly recall the stored patterns.



IV. ANALYZING THE STABILITY  Before simulating and testing the new algorithm, it has to be verified that the new learning rule will be stable over a finite number of iterations. The energy due to a single neuron i is:  N  j=l Ei = ~ w i j x j o i     From (It?), we can derive the change in energy due to the update from opId to 0:''" as:  The first experiment tested the associativity of the network when the network is presented with partial data of trained patterns. On this experiment, the network is trained with 75  I N  I I N  face images of a person with different expressions. The 11 I I ] (19) performance of the network is tested by inputting a partially  cormpted trained image to the network. It can be observed in Fig..6 that the network is able to complete the missing part of  &Ei = - - ~ w . x . o n e ' " -  ( - - ~ w . . x . o ? ' ~ 'I J I 2 I=, 2 j 4  which can be simplified as I .. \ the test imaaes.

Now .we can consider 3 cases:.

(1) If winLi 5 Net?" 5 winRi ,  then by (9) and (ZO), AEi will become 0,  AE, = (a)(-)= 0 . .

(2) If (o?"- oYld)> winRi and according to (9), the  change in energy Mi from (20) will be less than 0, and  AE, =(+)(-I+)=- ( 3 )  lf(o:- - opld)<-winLi, and according to (9). the  change in energy mi from (20) will be greater than 0, and . ,  AEi =(-)(-I+)=+ Condition 1 and 2 clearly demonstrate that the network converges for every consecutive iteration. On the other hand, condition 3 states that when a neuron changes its state to a lower magnitude, the energy increases. But in the next iteration, it will have a tendency to go to higher magnitude or stay at the same level to capture its final state if the input pattem is closer to one of the trained patterns. Otherwise, if the input pattern is an untrained pattern, the network goes to an unstable state.



V. SIMULATIONS,  Simulations were performed on 64 x 64 = 4096 dimensional gray-level (256 levels) face images. The Camegie Mellon University (CMU) face expression variant database [14], which consists of 75 face expressions for 13 people, is used to measure the performance of ratio leaming algorithm. Examples of those faces can he seen in Fig. 5.

Fig. 6. Completing the missing pan ofthe faces  In the second experiment, we tested the performance of the network when noisy face images are inputted to the network.

The network is initially trained with 975 face imagcs of 13 individuals. Test images were made by cortupting the trained images with 30% salt and pepper noise. As it can be seen from Fig. 7 that at 30% salt and pepper noise, the pattern association becomes difficult for human. However, the network is able to associate the face correctly.

Fig. 7. Reconstruction of image from noisy data  The third experiment was conducted to test the associativity of the network when five images of a person were used for training. 975 face images (13 people with each having 75 expressions) were used for testing. Those face images belonging to the same person converge to the face of that person similar to the face expressions of the trained images.

On the .other hand. those face imaees not beloneine to that  I -  Pig. S.  64 x 64 dimensional facial images af.13 people from the CMU face expression variance database. person converge to local minima ofthe person that is trained. Fig. 8 shows three examples of such results.

Ibis. X. Con\ergcncc ?til network with dilt?erent penaii  lii ilic founh experiment we tested the recognition of a group of networks working together when each network is trained using samples of face expressions of a person. The setup of this experiment can be seen in Fig. 9. Thirteen networks, with each network learning five examples of a person, are utilized.

Test images were inputted to the network. When all the 13 networks converged, they are compared with the initial test input. The network with the minimum change gives the highest probability of the correct person. Table 1 shows the recognition of the network and it can be seen that the network is able IO recognize each person correctly without any error.

2-z y., X ?  Y %  Fig. 9. Anetwork, which compose 13 ratio memories

VI. CONCLUSION  A ratio rule based training algorithm for recurrent neural networks suitable for multi-valued pattern association has been presented in this paper. The ratio rule training involves minimizing the maximum distance of the statistical properties of the relative magnitudes of two neurons, which represent the synaptic weights of a neuron. The threshold function has been represented by the statistical characteristic of the input patterns. Theoretical analysis and empirical evidence of the neural network with ratio rule have shown that the network is stable and is capable of learning multi-valued images.

Furthermore, it is observed that the network is suitable for retention, reconstruction, and restoration of learned patterns with varying face expressions.

1 1 1 .

121.

~ 3 1 .

141.

151.

(61.

(71.

(81.

