Discovery of Interesting Association Rules from Livelink Web Log Data

Abstract  We present our experience in mining web rrsagepotrerns from a large collection of Livelink log dura. Livelink is a web-based product of Open Text, which provides automatic management arid retrieval of drfferenr @pes of information objects over an inrranet or extranet. We report our experi- ence in preprocessing raw log datu andposr-processing the mining results for  finding interesting rules. I n  panicular; we compare and evaluare a number of rule interestingness measures andfind that two of the measures that have not been used in association rule learning work very well.

1 Introduction  The use of internet technology permits organizations to generate and collect large volumes of electronic data in their daily operations. open Text?s Livelink is a web-based prod- uct that is designed to facilitate the storage, sharing and management of critical information and processes for an organization. We describe two challenges that we faced in mining Livelink usage patterns from a large volume of unique Livelink log files. The first challenge is preprwess- ing the raw log data to extract information that is relevant to our task. We present our techniques for preprocessing the log data. In particular, we describe the need for identifying information objects from log entries and methods for iden- tifying users and sessions from the logs. The second chal- lenge we faced is filtering the mining results to present rules or patterns that are potentially interesting. To find interest- ing rules, we use seven interestingness measures to rank the generated association rules, two of which have not previ- ously been used to evaluate association rules. Pruning tech- niques are also applied to eliminate rules that are considered   Aijun An Department of Computer Science  York University Toronto, Ontario M3J 1P3 Canada  aan@cs.yorku.ca  Gary Promhouse Open Text Corporation  Waterloo, Ontario N2L 525 Canada gary @ opentex t .com  redundant according to structural relationships among the rules and their interestingness values. To determine which interestingness measures work well in our application, we conduct evaluation of the seven interestingness measures by evaluating the topranking rules from each measure using the feedback from domain experts. We also compare these interesting measures by looking at the correlation between each measure and the $-coefficient that describes the corre- lation between the antecedent and consequent of a rule.

2 Livelink Log Files The log files used in our experiments contain Livelink  access data for a period of two months. The size of the data is 7GB. The data describe more than 3,000,000 requests made to a Livelink server from around 5,000 users. Each request corresponds to an entry in the log files. The entry contains: I .  the IP address the user is making the request from; 2. the cookie generated by the Livelink server on the user?s machine; 3. the time the request is made and the time the required page is presented to the user: 4. the name of the request handler in the Livelink program; 5. the name of the method within the handler that is used to handle the request; 6. the query strings that can he used to identify the page and the objects being requested, and some other information that are irrelevant to our task, such as the URL addresses that are useful for error-handling.

3 Data Preprocessing The objective of data preprocessing is to transform the  raw log data into the data that can be used for learning pat- terns. The following tasks are performed in the data pre- processing step of our project: identifying the user from each entry of the log files, identifying the information ob- jects that the user requests from each log entry, removing    noisy entries, which are the entries in which no interesting objects are requested, and finally grouping entries into ses- sions. We use IP addresses to identify users of Livelink.

Even though the same user can log into Livelink through different IP addresses, the chance for this to happen is con- sidered to be smaller than the chance that cookies are dis- abled because in almost all the time a user accessesLivelink from the desktop in hisiber office. Therefore, instead of us- ing cookies to identify users, IP addresses are used. The unique part of data processing in our project is object iden- tification. In previous works on web usage mining, it is the pages that were identified from log entries. At the begin- ning of this project, we identified all the pages involved in the log files. Because almost all of the pages in Livelink are dynamic, the number of such pages is huge'. However, the problem is not in the number of pages, but in the useful- ness of dynamic pages. When we analyzed the discovered patterns that describe access relationships among pages, we found that many of those patterns reveal the program pat- ferns within Livelink. For example, two pages are found to he always accessed together because one is the frame within the other, which is defined by the Livelink program. These patterns are not considered to be interesting by our domain experts. In addition, there could be great sirnilxities in the contents of different dynamic pages. Two dynamic pages may he considered to be different pages even though they contain the same set of information objects. In order to discover truly interesting and unexpected patterns, we con- ducted object identification from each dynamic page and build the session file based on the objects. An object could be a document (such as a PDF file), a project description, a task description, anews group message, a picture and so on.

Different types of objects have different domains of identi- ties. Based on the domain knowledge about Livelink. iden- tities of the objects being requested can be extracted from the parameters in the query string of the log entry. Most entries contain only one object, but some entries have zero or more than one object. We ignore all the entries with no information object. After objects are identified, we group the requests made by each user into sessions. In  our case, a session consists of a sequence of sets of objects requested by a ing le  user such that no two consecutive requesb are separated by an interval more than a predefined threshold.

In our experiments, the threshold is set to be IO minutes.

4 Learning Interesting Association Rules We implemented the Apriori algorithm [ I ]  to learn as-  sociation rules from the session file. An association rule describes the association relationship between information objects. For example, an association rule  (01; 02: u3) --t (&,os) [suppmt = 0.01 cvnfidence = 0.61  'we identified nearly 200.0W pages from the rwrrrnonth daa.

means that 1 % of the sessions contain objects 01; 02, u3: 04 and 05. and that 60% of the sessions containing 01; 02 and u3 also contain 04 and 05. The number of discovered asso- ciation rules depends on the support and coiifidence thresh- olds. On our data set, we found that the number of gener- ated rule is not affected much by changing the confidence threshold. However, the number of rules greatly depends on the support threshold. At low support regions, a very small change in support threshold can lead to a super expo- nential growth in the number of rules. Table I shows how the number of rules varies with the support threshold given a confidence threshold. To avoid missing interesting rules or generating too many rules, we set the support and confi- dence thresholds to be 0.0028 and 0.5, respectively, in our later experiments. The number of rules generated under this setting is 4556. Although 4556 is much less than 74,565 (which is the number of rules for the support threshold of 0.0025), there are still tm many rules and not all ofthem are interesting. Therefore, we are facing both the rule quantify and rule quality problems. To solve the problems, we rank the rules according to some interestingness measures and prune the rules according to both structural relationships of the rules and their degrees of interestingness.

4.1 Interestingness Measures The goal of data mining is to find patterns that are inter-  esting and relevant to the task at hand. Various interesting- ness measures have been proposed. They generally fall into two categories: objective and subjective [SI. Objective mea- sures are statistical measures whose values are calculated based on the data used in the mining process. Examples of objective measures include RI [6]  and IS [9]. Subjective measures can be defined according to the unexpectedness and actionability of the discovered patterns [8]. A rule is unexpected if it is surprising to the data analyst, and ac- tionable if the analyst can act on i t  to hisiber advantage. In our experiments, we use both objective and subjective mea- sures. Seven statistical measures are used as objective mea- sures to rank the generated rules. Subjective measures that measure the unexpectedness and actionability of rules  are^ used to verify the top-ranking rules produced by the objec- tive measures. Our objective of using subjective measures is to determine which objective measures are best suitable for our application. Given an association rule A + B, we use the following objective measures to the measure the in- terestingness of the rule:  1. Support and confidence (SC). Rules are ranked accord- ing to their support value as the main key and their confidence value as the secondary key.

2. Confidence and support (CS). Rules are ranked accord- ing to their confidence value as the main key and their support value as the secondary key.

Supponthresbold I 0.02 I 0.01 I 0.008 1 0.005 I 0.003 I 00028 I 0.0025 I 00023 I Numberofrules I 2 I 14 I 39 I 88 I 723 I 4556 1 74.565 [ 392,670 I 1,677,442 1 4.8W.MO  0.OOZl 1 0.002  Table 1. Number of generated rules versus support threshold (confidence threshold = 0.5)  3. RI (61. This rule-interest measure is defined as RI = P ( A B )  - P(A)P(B) .

sure is defined as I S  = Jm. 4. IS [91. Derived from statistical correlation, the IS mea- 5. MD [21. The MD measure was inspired by a query  term weighting formula used in information retrieval and has been used to measure the quality of classifica- tion rules [Z]. We adopt the formula to measure the ex- tent to which an association rule A + B can discriii- nate between B and B: MD = l o g P ~ A & P I A ~ s ~ .  P A B  I - P A B )  -  6. C2 (41. The C2 formula measures the agreement be- tween A and B. It has been evaluated as a good rule quality measure for learning classification rules [21. It canbedefinedasC2=-. x v .

pendence between .4 and B.

cm1uictim =  7. Conviction (CV) [3]. Conviction tests the inde- It is defined as  PJAyJ7J P ( A s )  '  The values from some of these measures (such as RI, MD and C2) can be zero or negative, indicating A and B are not correlated or they are negatively correlated, respectively.

In our association rule program, rules with this kind of in- terestingness values are considered uninteresting and are  4.2 Pruning Rules The use of an interestingness measure can help identify  interesting rules by ranking the discovered rules accord- ing to the measure. However, it cannot he used to iden- tify redundant rules. By redundant rules we mean that the same semantic information is captured by multiple rules and hence some of them are considered redundant. Shah et a1 [71 discuss some pruning techniques for detecting redun- dant rules. We adopt two of their pruning rules and adapt the rules to use with interestingness measures. Our pruning rules are as follows.

Pruning Rule 1: If there are two rules of the form A -) C and A AB + C, and the interestingness value of rule A AB -+ C is not significantly better than rule A --f C, then rule A A B  --t C is redundant and should be pruned.

pruned.

Pruning Rule 2: If there are two rules of the form A -+ CI and .4 + C1 A Cz, and the interestingness value of rule A + Cl is not significantly better than rule A -+ C, A C,, then rule A + C1 is redundant and should be pruned.

Table 2. Ranking of Rules by Different Inter- estingness Measures  A rule RI is significantly better than rule Rz if IV(RI)-IV(RZ)  > 5%. where IV(R1)  and I V ( R 2 )  are the interestingness values for RI and Rz, respectively.

IV(R2)  5 Experimental Results and Analysis In our experiments, we set the support and confidence  thresholds to 0.0028 and 0.5, respectively. 4556 association rules were generated under this setting. Each generated rule is attached with 7 interesringness values calculated from the 7 interestingness measures. The rules are ranked accord- ing to their interestingness values, resulting in 7 ranked lists (one for each measure). We then apply our pruning tech- niques to remove all the rules whose antecedent and con- sequent are uncorrelated or negatively correlated, and the rules that are redundant according to the two pruning rules described in section 4.2.

We observed that none of the 4556 rules generated from our program is an uncorrelated or negatively correlated rule.

However, many of them are redundant rules. By applying the two pruning rules, the number of rules is reduced dra- matically for all the interesting measures. For example, if IS, IR or Conviction is used as the interesting measure, the number of rules is reduced from 4556 to 449, 361 or 396, respectively. Table 2 shows the top IO rules ranked by each of the I measures after pruning. The numbers in the table are rule IDS. These top-ranking rules were presented to our domain expert who evaluated these rules according to the unexpectedness and actionability of the rules. Based on his feedback, we classify these rules into interesting (marked with +) and uninteresting (marked with -) rules. We can observe from the table that IS, MD and C2 produce sim- ilar topranking rules, and that the top-ranking rules from SC, RI and CV are also similar. The top ranking from CS is different from others. We also observe that MD and C2 work the best on the data set. IS is also a good measure.

However, SC, CS, RI and CV either fail to identify any or identify only one interesting rule in their top IO lists.

1 sc I cs I IS 1 RI I CV 1 MD I C2 Correlationcoefficient I 0.3075 I -0.2289 I 1 . W  I 0.3312 I 0,1437 I 0.8610 I 0.8340  Table 3. Correlation between different interestingness measures and +coefficient  Another way to compare the various measures presented in this paper is by determining their correlation with respect to the $-coefficient [9]. $-coefficient is an estimate of cor- relation coefficient between two random variables on finite samples. A correlation is a special kind of association: a linear relation between the values of two random variables.

Correlation coefficient measures the degree of linearity be- tween two random variables. Theoretically, it is defined as the covariance between two variables divided by their stan- dard deviations. $-coefficient can be used as an interesting- ness measure for association rules, which measures the de- gree of linearity between the antecedent and consequent of a rule. Tan et a/ [9] gives an exact formula for calculating a rule?s $-coefficient and uses it as a reference metric for comparison with other interestingness measures. We use the same method to evaluate our interestingness measures on the Livelink data set. We calculate the $-coefficient for each generated association rule and then calculate the cor- relation coefficient between an individual interestingness measure and $-coefficient based on the top-ranking rules for that interestingness measure. Table 3 illustrates the cor- relation values between each rule interestingness measure and $-coefficient. According to the table, IS has a very high correlation with $-coefficient, which is not surprising because it is derived from the correlation coefficient itself.

On the other hand, CS has a negative correlation with $.

In between IS and CS, MD and C2 have high correlation with #, while RI, support (SC) and Conviction (CV) have low correlation with 4. Based on both Table 2 and Table 3, we can cluster the 7 interestingness measures into four groups. The first group contains IS; the second includes MD and C2;  the third consists of RI, SC and CV, and the fourth group contains CS. The measures in each group pro- duce similar top-ranking results and have similar correla- tions with #-coefficient.

6 Conclusions In our project for mining association rules from Livelink  log files, we faced two major challenges: preprocessing the raw data to provide an clear picture of how Livelink is be- ing used, and filtering the mining results to present only the rules and patterns that are potentially interesting. This paper described our experience in meeting these two chal- lenges. In data preprocessing, information objects that are contained in each requested page are identified from the log files. Session files are built upon objects instead of pages.

For identifying interesting rules from the mining results. we used both pruning techniques and interestingness measures to filter the generated association rules. A great amount of  redundant rules were removed by the pruning technique that uses two pruning rules based on structural relationships of the rules. We evaluated and compared seven interestingness measures in our experiments. Our results indicate that MD.

C2 and IS are good interesting measures. Among the three good measures, MD and C2 work better and have weaker correlations with $-coefficient than IS. However, MD and C2 have stronger correlations with $-coefficient than other measures that do not work well.

