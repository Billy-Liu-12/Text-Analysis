Tightness: A Novel Heuristic and a Clustering Mechanism to Improve the  Interpretation of Association Rules

Abstract  In this paper we present a clustering-based approach to mitigate the ?rule immensity? and the resulting ?understandability? problem in association rule (AR) mining. Clustering ?similar? rules facilitates exploration of connections among rules and the discovery of underlying structures. We first introduce the notion of ?tightness? of an AR. It reveals the strength of binding between various items present in an AR. We elaborate on its usefulness in the retail market-basket context and develop a distance-function on the basis of ?tightness.? Usage of this distance function is exemplified by clustering a small artificial set of ARs with the help of average-linkage method. Clusters thus obtained are compared with those obtained by running a standard method (from recent data mining literature) on the same data set.

1. Introduction  Association Rules (ARs) bring out co-occurrence based affinity between items (attributes) in a database of transactions. In the retail context, ARs help identify items that sell together. Retailers may use this for increasing sales by strategically placing related items near each other. An important problem in AR mining concerns the understandability of large numbers of rules discovered by AR mining algorithms. Researchers have tried to address this rule immensity problem using diverse techniques [9] including cluster analysis [2]. Grouping similar rules eases the rule immensity problem as a manager can now obtain an overview of the domain by examining rule clusters. More detailed knowledge may be revealed by examining each individual cluster. Thus, clustering, unlike rule ranking [9], may reveal connections between various sets of rules.

2. Related Work Lent, Swami and Widom [3] introduced the notion of  ?clustered? ARs. This was further extended by Wang, Tay  and Liu [8]. Here, clustering is defined as merging of ARs with adjacent attribute values, or adjacent bins (intervals) of attribute values to form one rule that can represent the group. Adomavicius and Tuzhilin [4] adopt a similarity- based rule grouping approach that groups rules having the same ?aggregated rule? in an attribute hierarchy. Dong and Li [5] introduced neighborhood-based interestingness by considering unexpectedness in terms of neighborhood- based parameters. The proposed distance metric detects unexpected rules but is not used for clustering them.

Toivonen, et al. [7] defined the distance between two rules in terms of the number of transactions in which their identical consequents differ. Gupta, Strehl and Ghosh [6] proposed a normalized distance function called Conditional Market-Basket probability (CMPB) distance that clusters all those rules that ?cover? the same set of transactions. One of the drawbacks of both schemes is the arbitrariness of distance measures used for clustering [4].

Sahar [11] proposed a new metric called dSC that combined the approaches in Dong and Li [5] and Toivonen, et al. [7]. Sahar?s approach utilized both syntactic matching of item sets and rule coverage of the data. Jorge [1] studied hierarchical clustering in the context of thematic browsing and summarization of large sets of ARs.

Our work differs from these studies due to the usage of ?tightness? ? an inherent property of an AR, for clustering them. We bring out the utility of ?tightness? to capture domain-independent customer purchasing behaviour. Our approach does not use any external knowledge like attribute hierarchies. The approach is solely based on the intrinsic property of ?tightness?. We introduced ?tightness? in [10] in the context of chance discovery. Here, we generalize the notion to the generic market-basket context and attempt to capture ?domain-independent? purchasing patterns.

3. Tightness of Binding  In a retail store, items may be purchased together in ?natural? combinations due to factors such as necessity, utility, impulsive behaviour, etc. In such purchases, items  IEEE IRI 2008, July 13-15, 2008, Las Vegas, Nevada, USA     may get ?bound? to each other due to their complementary nature, for example, bread and butter that are consumed together at breakfast. Items could also be related by the domain of application. When two items find application in the same or closely related domains, customers might purchase them together as sets in order to minimize their search costs and shopping efforts. Thus, items are bound together due to interactions between their functions. Tightly bound items are more likely to be purchased together as sets.

Traditional measures like support and confidence [9] do not bring out the ?tightness of binding? between items.

In general, tightness of binding between items in an AR increases with its support. However, support fails to consider the presence of an AR?s constituent items in other transactions ? transactions that do not contribute to the basis of the rule. Similarly, ?confidence? brings out only the predictive ability of the AR.

3.1 Tightness Measure (T)  In a retail store, let I be the set of items available for sale. A transaction ?t? (t? I ) is a set of items purchased on a single buying-instance. Let R: a1 a2 ?. am ? am+1 ?. an represent an AR with n items, and let SR and CR be its support and confidence respectively. R covers t if ?t? belongs to the transaction set from which R has been derived. In other words, R ? t. According to the context, we use ?R? to denote both an AR and the set of items it contains.  Let Sai denote the support of item ai in the database. For a Rule R, supports of the most and least frequent items are denoted by:  SRmax = max{ Sa1, Sa2, Sa3, ?., San}/ ai?R SRmin = min{ Sa1, Sa2, Sa3, ?., San}/ ai?R.

For any AR, the following relationship between the various support values holds:  SRmax ? Sai ? SRmin  ? SR ? minsup (minsup is user-defined threshold for generation of ARs)  For items in a rule R, it is important to know whether customers prefer to purchase them more often as set R or alternatively as individual items or subsets/supersets of R.

Suppose an item occurring in an AR is frequently purchased along with items not in R. This may imply that other items of the rule may not be needed for its purchase, thus indicating its loose binding to other items in R.

Consider an AR: {Bread}?{Butter}. The binding between Bread and Butter is tight if they are purchased together in a large number of transactions. The presence of Bread might be inferred by the presence of Butter and vice-versa. In addition say Bread is frequently purchased with Milk, and those transactions do not contain Butter.

Then, we can say that the bond between Bread and Butter is not the only tight one. Thus, the ?tightness of binding? between Bread and Butter as brought out by the AR needs to be reviewed in the context of both, their co-occurrence  in transactions and also their occurrence with other items in transactions not covered by the rule.

We propose a measure that assigns a value to this ?tightness of binding? among/between items in an AR.

Support value Sai includes those transactions that constitute the support of rule R (SR). Difference between SR and Sai being large implies that each constituent item ai of R is also purchased in transactions not covered by R. If proper subsets of R are not purchased separately, then the binding among items of R is deemed tight. Thus, increase in support of a rule tightens the binding. This is due to there being more transactions involving set R.

T ? SR                     (1) Transactions represented by (SRmax-SR) and (SRmin-SR)  consist of market baskets distinct from the market baskets pertaining to transactions covered by R. In addition, the sets of transactions representing (SRmax-SR) and (SRmin-SR) may not overlap. For a constant value of SR, assume that there is an increase in the values of SRmax and SRmin. This increase reveals greater presence of items (of R) in transactions not covered by R. This is a different purchasing behaviour that is not reflected by R. Shopping baskets reflecting these transactions contain subsets of R and not R and in turn may imply different functions. One may interpret this as a reduction in ?tightness? brought out by R. This is because some of the items in R are now purchased more frequently as separate baskets thus indicating enlarged usage.

Consider the expression, P= ? ?  ? ? ?  ? +  SS minRmaxR -SR.

This expression gives us a rough estimate of the presence of items of R, in transactions not covered by it.

? ?  ? ? ?  ? +  SS minRmaxR represents the midpoint of the support  values of the items present in the rule. We subtract SR from the expression to remove the effect of transactions covered by R. An increase in P indicates an increase in the number of transactions containing proper subsets of items present in the rule, thus reducing the tightness of items in R. Consequently we have:  R minRmaxR S   SS  T  ?? ?  ? ? ?  ? + ?                     (2)  Combining Equations (1) and (2) we propose:  R minRmaxR  R  S  SS  S T  ?? ?  ? ? ?  ? + =      (3)  Since SRmax ? SRmin ? SR, the denominator is always greater than or equal to 0. SR takes a positive value in the range [0, 1]. T  assumes its maximum value (i.e. ?) when:  SRmax = SRmin = SR.                                 (4)     This is intuitive too because it implies that T takes its maximum value when all items of R are present only in those transactions covered by R. This is irrespective of the value of SR. The items of set R are absent in the remaining portion of the database represented by (1-SR). Another interpretation is that R is composed of items that are essentially purchased only as a complete set and not as proper subsets of R. Thus, if we know that any one of the items from the set R has been purchased, we can infer the purchase of the entire set. This is irrespective of the number of transactions supporting R. Intuitively also this seems to be right as tightness should be the same irrespective of the number of transactions involved as long as there is complete coverage. It is important to note that this argument does not hold in transient conditions but only in steady state conditions where the item has been in the market for some time. Note that set R could still be purchased with items (not present in the rule), but only in the transactions supporting R. Neither the AR nor the value of T will reveal anything about this aspect.

Hence, we say that T is characteristic only to rule R.

3.2 Tightness-based Distance Measure: dT(Ri, Rj)  In order to cluster ARs on the basis of their tightness values, we need a distance function defined on tightness.

We propose the distance between ARs Ri and Rj as:  ( ) RjRi  RjRi jiT TT  TT R,Rd  +  ? =     (5)  where, TRi and TRj are the respective tightness values of Ri and Rj. The distance in terms of ?tightness? between two ARs, is expressed as the ratio of difference of their tightness values to sum of their tightness values. Since, TRi and TRj are positive rational numbers, dT(Ri, Rj) can easily be  shown to be a metric. Distance is a scalar and a non-negative quantity by definition.

dT(Ri, Rj) is inversely proportional to the sum of the rules? individual tightness values. Consider four rules Ra, Rb, Rc and Rd. Let their respective tightness-values be TRa, TRb, TRc and TRd. Suppose TRa>TRb>TRc>TRd and |TRa-TRb| = |TRc ? TRd|. If (TRa+TRb) > (TRc + TRd) then, dT(Ra, Rb)< dT(Rc, Rb). Thus, even though the magnitudes of difference in tightness of rules in both the pairs are equal, the distance between the two tightly bound rules is less than that between the two loosely bound rules. The intuition behind the selection of this functional form is as follows. ?Tightness of binding? is a reflection of relationships that bind items. An item set consisting of tightly bound items may be related by many relationships.

An increase in tightness by an additional relationship may not cause a perceptible difference in their binding. This is because the change, as a fraction of the earlier binding is small. On the other hand, the introduction of a new relationship of the same strength in a set consisting of loosely bound items may increase the binding  substantially from the previous value. This is because of the relative largeness of the change as compared to the earlier value. Hence, the inverse proportion with respect to the sum of their individual tightness values.

Let a set of tightly-bound items P be purchased in each of S transactions. In order to increase the sales to S+?S the retailer may have to put in effort ?E. Consider another set of loosely bound items P? whose sales S? may be less than S. It may require considerably more effort as compared to ?E, for increasing the sales of P? by the same ?S. This is because customers may not perceive P? to be as useful as P. The current and desired sales levels may be viewed analogous to the two rules, while the effort required may be viewed as the distance separating them. Note that S and S? should be above the user- specified threshold and not just sporadic purchases.

Table 1. An artificial transaction dataset  Transaction Nos. Transaction Nos.

{Bread, Butter} 6  {Bread, Jam} 5  {Bread, Milk} 4 {Bread, Butter, Milk}   {Milk, Chocolate} 6 {Chocolate, Biscuit}   {Milk, Chocolate, Biscuit}  11  {Butter, Milk} 3  {Pen, Pencil, Eraser}  13  {Pencil, Eraser} 7  {Chocolate, Pencil, Eraser}  3  {Pen, Eraser} 3  {Chocolate, Biscuit, Pencil}  {Bread, Butter, Milk, Jam}   {Bread, Jam, Milk}  12  --  --  4. Clustering ARs using dT(Ri, Rj)  We now demonstrate the usage of dT(Ri, Rj) for clustering ARs with the help of an illustrative example.

Table 1 represents an artificial transaction dataset consisting of 100 transactions. They are represented as 15 market baskets along with corresponding frequencies.

Each transaction is a subset of the set of nine items, namely {Bread (0.41), Butter (0.23), Jam (0.21), Milk (0.50), Chocolate (0.33), Biscuit (0.24), Pen (0.16), Pencil (0.28), Eraser (0.26)}. The figures in parentheses are the support values for corresponding items. Although the transaction set is small, it is sufficient to bring out the efficacy and usefulness of the clustering scheme. The transaction set yielded 14 ARs with support and confidence thresholds as 0.1 and 0.5 respectively. These ARs along with other parameters are listed in Table 2.

These fourteen rules, R1 through R14, were clustered using the average-linkage hierarchical method [2].

Tightness-based distance dT(Ri, Rj) was utilized to construct the distance matrix that formed the input to     SYSTAT11 package. Results of the clustering process are displayed in Table 3. Initially, each rule is a single element cluster. The closest of clusters merge at each step to form a new cluster and are indicated in bold-face. The two clusters formed during the initial stages of the clustering process are {R8, R9} and {R12, R13}. This is because the distance separating them is 0 as the pairs have identical tightness values.

Table 2. ARs extracted from transaction set of Table 1  No Association Rule Support Confi- dence  Tightness  R1 {Butter}?{Bread} 0.20 0.86957 1.666667 R2 {Jam}?{Bread} 0.21 1.00 2.100 R3 {Bread}?{Milk} 0.30 0.7317 1.935484 R4 {Butter}?{Milk} 0.17 0.7391 0.871795  R5 {Butter, Milk}?Bread 0.14 0.8235 0.622222  R6 {Chocolate}? {Biscuit}  0.24 0.7273 5.333333  R7 {Milk, Biscuit}? {Chocolate}  0.11 1.00 0.423077  R8 {Pen}? {Pencil, Eraser}  0.13 0.8125 1.444444  R9 {Pen}?{Pencil} 0.13 0.8125 1.444444 R10 {Pencil}?{Eraser} 0.23 0.8214 5.75 R11 {Pen}?{Eraser} 0.16 1.00 3.20  R12 {Jam, Milk}?{Bread} 0.16 1.00 0.820513  R13 {Jam}?{Milk} 0.16 0.7619 0.820513  R14 {Chocolate}? {Milk}  0.17 0.5152 0.693878  It may be noted that R10 and R6 get clustered prior to the formation of Cluster {R3, R2}. This sequence of cluster formation can be attributed to the functional form of dT(Ri, Rj) (dT(R10, R6) < dT(R3, R2)). Note that the difference in tightness of the rules in {R3, R2} is lesser than that of {R10, R6}.

The cluster configuration after Step 11 consists of the following three clusters: Cluster CT1: {R7, R14, R5, R4, R12, R13} Avg. T= 0.708666 Cluster CT2: {R1, R8, R9, R3, R2}      Avg. T = 1.718208 Cluster CT3: {R11, R10, R6}       Avg. T = 4.76111 CT1, CT2 and CT3 can be labeled as ?low-tightness?, ?medium-tightness? and ?high-tightness? clusters respectively, based on the average tightness value of its members.

Let us examine each individual cluster and its members. An interesting aspect of CT1?s members is the presence of Milk in all of them. Further, the support values of these rules are low. The maximum support value of 0.17 is assigned to R14 and R4. Thus, the presence of high-support item(s) in a low support rule may result in low tightness. This is because of the significant presence of a high support item in transactions not covered by the low-support rule. For example, R4 covers only 17 of the  50 transactions in which Milk is present. This results in a low tightness value of 0.871795 being assigned to R4.

Although low support generally implies smaller tightness values, there are occasions when low-support rules might be assigned high tightness values. This may be the case if items constituting the rule are purchased more often as a set than as individual items. Rule R11 brings this out. R11 {Pen} ?{Eraser} has a support of 0.16. Item Pen also has a support of 0.16. This means that Pen is always purchased with Eraser and never alone.

The confidence of R11 is 1.00 implying that the presence of Eraser is essential for the purchase of Pen. This purchase behaviour increases the strength of binding between Pen and Eraser. Two ARs having the same sets of items, but distributed differently across their antecedents and consequents will have the same values of tightness assigned to them since tightness is non- directional.

Table 3. dT ?based Clustering  No Clusters Merging Distance 1 {R9, R8} 0.000 2 {R13, R12}, {R9, R8} 0.000 3 {R4, R13, R12}, {R9, R8} 0.030 4 {R10, R6}, {R4, R13, R12}, {R9, R8} 0.038  {R3, R2}, {R10, R6}, {R4, R13, R12}, {R9, R8}  0.041  {R14, R5}, {R3, R2}, {R10, R6}, {R4, R13, R12}, {R9, R8}  0.054  {R1, R8, R9}, {R14, R5}, {R3, R2}, {R10, R6}, {R4, R13, R12}  0.071  {R14, R5, R4, R13, R12}, {R1, R8, R9}, {R3, R2}, {R10, R6}  0.120  {R1, R8, R9, R3, R2}, { R14, R5, R4, R13, R12}, {R10, R6}  0.142  {R11, R10, R6}, {R1, R8, R9, R3, R2}, { R14, R5, R4, R13, R12}  0.267  { R7, R14, R5, R4, R13, R12}, {R11, R10, R6}, {R1, R8, R9, R3, R2}  0.284  { R7, R14, R5, R4, R13, R12, R1, R8, R9, R3, R2}, {R11, R10, R6}  0.415  { R7, R14, R5, R4, R13, R12, R1, R8, R9, R3, R2, R11, R10, R6}  0.604  Note: Singleton clusters are not depicted.

Another comment concerns rules R6 and R7. R7 ({Milk, Biscuit}?{Chocolate}) has a T-value of 0.423077 while its sub-rule R6 ({Chocolate}?{Biscuit}) is a member of high-tightness cluster CT3 with a T-value of 5.3333 assigned to it. Note that the support of {Milk, Biscuit, Chocolate} is 0.11. Addition of Milk to {Chocolate, Biscuit} reduces the support, and consequently the tightness of the resultant set. Milk is not tightly bound to either.

A comment on R8, R9, R10 and R11 is in order. R8 and R9 are members of medium-tightness cluster CT2 while R8?s sub-rules R10 and R11 are members of CT3 -- the high-     tightness cluster. Sets {Pencil, Eraser} and {Pen, Eraser} are tightly bound having tightness values of 5.75 and 3.20 respectively. However, addition of a third item to either of the two sets to form set {Pen, Pencil, Eraser} reduces the tightness to 1.444444. This is because the support of {Pen, Pencil, Eraser} gets reduced to 0.13. Thus, reduction in support may lead to a reduction in tightness.

In addition, we observe that R9 has a low tightness value of 1.44444. Items of set {Pen, Pencil} are not tightly bound to each other. They are however, tightly bound individually to {Eraser}. Thus, the low binding of {Pen, Pencil, Eraser} may be due to the low binding of one of its subsets {Pen, Pencil}.

5. Comparative Analysis  Here we compare the proposed scheme to that proposed by Sahar [11]. The non-metric distance measure, dSC proposed in [11] defines distance between two rules on the basis of overlap in the set of transactions that each rule covers. In addition, dSC also utilizes the differences in itemsets constituting the two rules. The reader is referred to [11] for further details about dSC.

dSC directly computes dissimilarity between R1 and R2.

On the other hand, dT computation is a two step process, wherein initially, the ?tightness? of the two rules are computed. The second step consists of calculating the dT value on the basis of these tightness values. dSC compares the itemsets given by the antecedents, consequents and the combination of both while computing the distance. On the other hand, dT considers the support of least and the most frequent items of a rule. In addition, dT also considers the rule?s support. Unlike dSC, support values pertaining to the itemsets of two rules are not directly compared in the proposed scheme.

The fourteen ARs in Table 2 were clustered using Average linkage agglomerative hierarchical procedure with the dSC-based distance matrix given as input to SYSTAT11 package. The study presented in [11] also uses agglomerative hierarchical methods for clustering ARs. Table 4 displays cluster configurations at each step of the process. Note the formation of clusters at Step 1 of the clustering process. Singleton clusters {R9} and {R8} get merged to form a 2-rule cluster in case of dT and dSC- based clustering. dT(R9, R8) is assigned a value of 0 because the ?tightness? values assigned to rules R9 and R8 are the same (1.444444). This is due to two reasons.

Support values of rules R9 and R8 are equal (0.13). In addition, both the rules have identical SRmax and SRmin values. Hence, they are assigned the same T-values.

It is interesting to note that R9 ({Pen} ?{Pencil}) is a sub-rule of R8 ({Pen}?{Pencil, Eraser}). In addition R8 and R9 have the same support value of 0.13. This means R8 and R9 cover the same set of transactions. Further, the antecedent sets of R8 and R9 have a complete match.

Hence contribution to dSC(R8, R9) due to antecedent  dissimilarity is 0. The consequent of R9 namely, {Pencil} is a subset of the consequent of R8 namely, {Pencil, Eraser}. All transactions covered by R8 are also covered by R9. This increases the similarity between R8 and R9 and hence a low dSC(R8, R9)  value of 0.429. Thus, the apparent similarity between the two schemes, at the first step of clustering, is due to different reasons.

Table 4. dSC ?based clustering  No Clusters Merging Distance  1 {R9, R8} 0.429 2 {R12, R2}, {R9, R8} 0.437 3 {R5, R1}, {R12, R2}, {R9, R8} 0.442 4 {R11, R9, R8}, {R5, R4}, {R2, R12} 1.098 5 {R4, R5, R1}, {R11, R9, R8}, {R2, R12}  1.892 6 {R13, R12, R2}, {R4, R5, R1}, {R11, R9, R8} 1.958 7 {R10, R11, R9, R8}, {R13, R12, R2}, {R4, R5,  R1} 2.244  8 {R14, R6}, {R10, R11, R9, R8}, {R13, R12, R2}, {R4, R5, R1}  2.313  9 {R13, R12, R3, R2}, {R14, R6}, {R10, R11, R9, R8}, {R4, R5, R1}  2.734  10 {R13, R12, R3, R2, R4, R5, R1}, {R14, R6}, {R10, R11, R9, R8} 2.773  11 {R7, R14, R6}, {R13, R12, R3, R2, R4, R5, R1}, {R10, R11, R9, R8}  2.875  12 {R7, R14, R6, R13, R12, R3, R2, R4, R5, R1}, {R10, R11, R9, R8}  3.980  13 {R7, R14, R6, R13, R12, R3, R2, R4, R5, R1, R10, R11, R9, R8}  4.437  Note: Singleton clusters are not depicted.

An interesting observation may be made with respect to the second step. dT brings together rules R13 and R12.

Both rules have the same T-value (0.820513). On the other hand, dSC clusters R12 and R2 in Step 2. R13 ({Jam} ?{Milk}) and R2({Jam}?{Bread}) are sub-rules of R12 ({Jam, Milk}?{Bread}). dSC assigns a higher value to pair {R13, R12} than to pair {R12, R2}. This is because antecedent sets of {R13, R12} match only partially while their consequent sets do not match at all. On the other hand, consequent sets of {R12, R2} match completely while their antecedent sets match only partially. Hence, the contribution to antecedent dissimilarity is low while contribution to dissimilarity from their consequents is nil.

This results in dSC(R12, R2) being assigned a lower value as compared to dSC(R13, R12). Note that R2 covers all transactions covered by R12.

One aim of dT-based clustering is to bring out similar purchasing behaviour in different domains/sub-domains.

Thus, it tends to bring together rules that have equal or near equal values of tightness irrespective of their constituting itemsets [Table 3]. On the other hand, usage of dSC as the distance measure tends to bring rules and its sub-rules in the same cluster. In a cluster, the order of merging of sub-rules with its rule can be predicted on the     basis of overlap between transaction sets covered by various components of a rule and corresponding components of its various sub-rules. This is because dissimilarity between two rules is the weighted sum of dissimilarities among the antecedent, consequent and attribute sets that make up the two rules. The same property can create problems with respect to merging of clusters. Consider three rules Rx, Ry and Rz. Assume that the three rules are composed of totally different items.

Also assume that the three rules cover totally disjoint transaction sets. According to dSC, distance between any pair of rules is the same. It will be difficult to identify the next pair of rules that might merge.

dSC-based procedure groups rules that show some degree of overlap with respect to the transactions sets they cover. The procedure does not group rules with a comparable intrinsic rule attribute like ?tightness? as a single cluster.  Hence, from a practical decision-making perspective, a user may not be interested to the same extent, in all the rules in a dSC-generated cluster.

However, rules with near-equal tightness that are brought together by the dT-based clustering scheme may induce the same interest irrespective of the sub-domains of constituent items. The clusters bring out similar domain- independent purchasing behaviour and hence may be equally effective with respect to a retailing decision such as display design. This is a radically different aspect of purchasing behaviour that is not brought out by the dSC- based clustering procedure.

Cluster configurations obtained by the application of dT and dSC measures have different application-oriented ness. Since ?high-tightness? clusters may be interesting for certain applications such as discount coupon design, rules in those clusters may be examined further together.

Cluster characteristics like average tightness may be used to typify ?high-tightness? thus helping the selection of appropriate clusters for further examination. Unlike dSC, dT measure is a metric. This imparts stability to the scheme. Clustering based on dSC may not facilitate certain kinds of decision-making when the grouping has to be across domains. Distance measures like dT may be useful on such occasions.

6. Summary  ?Tightness? reveals the extent to which constituent items of an AR are bound to each other. Tightly-bound items tend to be purchased more frequently together as a market-basket in the same set of transactions than as individual items in different transactions. We motivated the need for a measure of ?tightness? in the retail market- basket context. Following this, we developed a distance function (dT) that utilized ?tightness? as its basis, and discussed its intuitiveness.  Usage of dT in clustering ARs was demonstrated with an artificial dataset. The proposed AR clustering scheme was compared with dSC?based  clustering [11]. dT-based clustering brings out similar customer purchasing behaviour occurring across domains.

It facilitates certain categories of decision-making where the goal is to identify rules whose items are bound to each other with similar tightness values. This reduces the search space thus mitigating the rule immensity problem.

7. References  [1] A. Jorge, ?Hierarchical Clustering for thematic browsing and summarization of large sets of Association Rules,? Proceedings (SDM2004), Nashville, TN, USA, June 2004, pp. 178-187.

[2] A. K. Jain, M. N. Murty, and P. J. Flynn, ?Data Clustering: A Review,? ACM Computing Surveys, 1999, 31, 3, pp. 264-323.

[3] B. Lent, A. Swami, and J. Widom, ?Clustering Association on Data Engineering, Birmingham, UK, 1997, pp. 220-231.

[4] G. Adomavicius, and A. Tuzhilin, ?Expert-Driven Validation of Rule-Based User Models in Personalization Applications,? Data Mining and Knowledge Discovery, 5, 1/2, 2001, pp 33-58.

[5] G. Dong and J. Li, ?Interestingness of Discovered Association Rules in Terms of Neighborhood-Based Unexpectedness,? Proceedings of the Second Pacific-Asia Conference on Knowledge Discovery and Data Mining, Springer-Verlag, 1998, pp. 72-86.

[6] G. K. Gupta, A. Strehl, and J. Ghosh, ?Distance Based Clustering of Association Rules,? Proceedings of Intelligent Engineering Systems through Artificial Neural Networks, (ANNIE 1999), ASME Press, 1999, Vol. 9, pp. 759-764.

[7] H. Toivonen, M. Klemettinen, P Ronkainen, K. Hatonen and H. Mannila, ?Pruning and Grouping Discovered Association Rules,? Proceedings of the MLnet Workshop on Statistics, Machine Learning and Knowledge Discovery in Databases, 1995, Herakhion, Crete, Greece.

[8] K. Wang, S. H. W. Tay, and B. Liu, ?Interestingness-Based Interval Merger for Numeric Association Rules,? Proceedings of Discovery, 1998, AAAI, New York City, pp. 121-128.

[9] L. Geng and H. Hamilton, ?Interestingness Measures for Data Mining: A Survey,? ACM Computing Surveys, 38(3), Article 9, September, 2006.

[10] Rajesh Natarajan and B. Shekar, ?Tightness-based Clustering of Association Rules: An Aid to Chance Discovery in Data Mining,? Proceedings of the 22nd ICML Workshop on Chance Discovery: from Data Interaction to Scenario, Bonn, Germany, August 2005, pp. 43-51.

[11] S. Sahar, ?Exploring Interestingness through Clustering: A Framework.,? Proceedings of the IEEE International Conference on Data Mining (ICDM 2002), IEEE Computer Society Press, 2002, pp 677-68.

