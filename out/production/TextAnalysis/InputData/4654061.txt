An Improved Method for Mining Generalized Frequent Itemsets Based on

Abstract   Mining generalized association rules is closely related to the taxonomy(is-a hierarchy) data which exists widely in retail, geography, biology and financial domains. If we use traditional method to mine the generalized association rules, it becomes inefficient because the itemsets will be huge along with the items and levels of taxonomy increasing, and it also wastes lots of time to calculate the support of redundant or unnecessary itemsets. In this paper, we proposes a new efficient method call CBP to partition the transaction database into several smaller ones level by level using correlation of itemsets, which make the mining more efficient by reducing the scanning size of transaction database. By experiments on the real-life transaction database, the results show that our CBP_based algorithms outperform the well-known algorithms.

1. Introduction   Unlike traditional association rules [1] [2] [3] researches perform on single level data, generalized association rules researches study the taxonomy data.

Besides the prototypical application of supermarket basket data, an example of financial application also has the taxonomy structure. In Figure 1, the financial transaction encode  with 4 bits. The 0*** represents the first bit of transaction code, and means the personal transaction. The 01** represents the first two bits of transaction code, and means the personal transactions of credit card. The 015* represents the first three bits of transaction code, and means the personal transaction of credit card query. The leaf node 0154 represents the complete transaction code, and means the personal transaction of querying the balance of a credit card.

The semantic of mining generalized association rule in this area is to find the association of customers? behavior, such as ?80% customers will query their balance after withdrawing cash?. Through analysis the association behavior of customers, we can provide  more specific financial products and services to specific customers.

Figure 1 Taxonomy data of financial transaction code  If we use traditional algorithms [1] [2] [3] directly, we will meet with several problems. Firstly, the inefficiency of the algorithms will be outstanding. In Figure 1, traditional methods only mine single level frequent itemsets from the leaf items. When mining the generalized frequent itemsets, we have to mine all the items including the leaf items and generalized items, which usually doubled the number of leaf items.

Secondly, the traditional algorithms will waste lots of time to calculate the support of redundant or unnecessary itemsets.

After the generalized association rules first introduced by R. Strikant [4] and Jiawei Han [5], the recently optimization of the algorithms have two strategies. One [6] [7] is to optimize the mining algorithms by using efficient way of lattice traversal or support counting, and another [8] [9] is to reduce the size of items or transactions. We follow the second direction and find that the frequency of different itemsets occurs together is different in practice. In Figure 1 for example, 01** and 02** are all personal credit card transactions, so maybe 80% customers do these two transactions together. While only 0.01% customers do the transactions like 01** and 09** together since 09** is the personal check transaction which has weak relation to 01** which is the personal credit card transaction. This situation widely exists in  the Correlation Between Items  International Symposium on Computer Science and its Applications  DOI 10.1109/CSA.2008.25   International Symposium on Computer Science and its Applications  DOI 10.1109/CSA.2008.25     other retail transaction databases like the supermarket basket data.

In this paper, we propose a new efficient algorithm called CBP_SLAR to mine the generalized frequent itemsets from taxonomy data. We partition the transaction database into several smaller ones level by level using the correlation of items. It makes the mining more efficient by reducing the scanning size of transaction database. In addition, we also propose several optimizing rules to prune the redundant generalized frequent itemsets, which can reduce many unnecessary itemsets. By experiments on the real-life transaction database, the results show that our CBP_based algorithms outperform the well-known Apriori_based algorithms without any loss.

This paper is organized as follows. Section 2 is problem statements and term definitions related to the generalized frequent itemsets. In Section 3, the correlation theory and optimized pruning rules are given. The CBP_SLAR algorithms are  illustrated in Section 4. In Section 5, by experiments, we compared our algorithms with the well-known algorithms. The study is concluded in the last section.

2. Problem Statement   Suppose transaction database D= { t1,t2,?,tn }?ti is any single transaction, and itemsets I= { I1,I2,?,Im }?Ia is a subset of I. In this paper, we present a transaction set including itemset Ia as Da= { ti | Ia? ti, ti? D}. Next, we depict it with a directed acyclic graph.

Definition 1. (Taxonomy Tree (?) and Subtree) We use the DAG=(V?E) to depict?V is the set of all item nodes, E is the set of all edges, v0 represents the root node, each node represents a generalized item. For any simple path P=(v0,v1,?,vn), then:  (1) vn-1 is the parent item of vn?noted parent(vn). In contrast, vn is the child item of vn-1?noted child(vn-1).

(2) v0?? ,vn-1 are the ancestor items of vn,  noted ancestor(vn). In contrast, v1,?,vn  are the descendant items of v0 , noted descendant(v0).

(3) For any items x, y, z, if x and y are the children of z, then x and y are brother items.

(4) The depth of item v refers to the level of v located in taxonomy data.

(5) If depth(vi) equals to depth(vj), we call vi and vj sibling items.

(6) An item without a child item called a leaf item.

(7) The items, except root and leaf items, are called interim items or generalized items.

(8) Similarly subtree x is noted as G?=(V?,E?), V ?is the set of x and their descendants, E?is the set of  edges between x and all the items of its descendants.

For simplification, the subtree mentioned in this paper only means the items x and all its descendants.

Definition 2. (Generalized frequent itemsets) In a transaction database, the support of any generalized item g equals to |Dg| / |D|, and if |Dg| / |D| is great than ?, then g is frequent in D, where ? is the minimum support threshold defined by user. |Dg| is the number of transactions contains g.

Definition 3. (Generalized item and item set) To generalized item gi?and generalized item set G?if ? gj ? G?gi equals to gj or gi is the ancestor of gj?then we say gi belongs to G ? noted as gi ?? G ? to generalized item set G1 and G2?if ? gi ? G1?then gi ?? G2?we say G1 ?? G2.

Definition 4. (Generalized Association Rules with Taxonomy) (1) The same level generalized association rules (SL AR) {A => B | A, B ? ?, A ? B = ?, A, B ? ?, and (? g1 ? A, ?  g2 ? B, depth(g1)= depth(g2)} (2) The cross level generalized association rules (CLAR) {A => B | A, B ? ?, A ? B= ?, and (? ? g1 ? A?? ?  g2 ? B, ancestor(g1) = g2 or ancestor (g2) = g1 ?, and?? g1 ? A?? g2 ? B, depth(g1) ? depth(g2)}  In this paper, we only apply our method to SLAR.

Definition 5. (Strong generalized association rule) The confidence of generalized association rule A => B is the percentage of transaction numbers in transaction database D, which contain generalized item A and B to the transaction numbers of the generalized item B.

That is conditional probability P?B| A??noted as confidence?A => B?, which equals to P?B| A?. If P?B| A?? ?? then we say A => B is a strong association rule, ? is the minimum confidence defined by the user,  In this paper, we still use the support-confidence measurement system and the different minimum supports for different levels of taxonomy.

3. Correlation theory  3.1 The correlation between the items  There are a variety of measures can be used, normalized measures are preferable. Therefore, we choose the Jaccard coefficient [11] to measure the relationship among generalized itemsets.

Definition 6. (Correlation of generalized items gi and gj) The correlation between two generalized items is defined as:  | | | | ( , )  | | | | | | | | i j i j  i j i j i j  g g g g  i j  g g g g g g  D D D D cor g g  D D D D D D  ? ? = =  ? + ? ?      (Formula 3-1) The definition means the two items have a strong correlation if they occur together many times. From the definition, we have the following property.

Property 1. If cor?gi,gj?< ?minsup?then {gi,gj} is not frequent.

Definition 7. (The relationship between generalized item gi and gj)  With generalized items gi and gj?if cor ?gi-gj?=0?then we can say that generalized item gi is non-related with generalized item gj, expressed as {? ti??gi?gj??  ti| gi ? I ? gj ? I ? ti ? D}. If cor ?gi-gj?< ?mincor?then we can say that generalized item gi is weak-related with generalized item gj, except that?we can say generalized item gi is related with generalized item gj. Totally, we define:  min sup  min sup  0,  ( , ) ,  ,  i j  non related  cor g g weak related  related  ?  ?  = ?  = < ?  ?  ? ? ? ? ? ? ? ?? ?  .

(Formula 3-2) To avoid the loss of generalized frequent itemsets,  we choose the minimum support of all levels as the minimum correlation, that is  min min supmin{ ( ), (1, ( ))}cor l l depth? ?= ? ? . Of course, we can choose some bigger ?mincor and partition the taxonomy data more efficiently. However, it will cause some loss of frequent itemsets. Therefore, it is the trade-off of efficiency and loss.

Definition 8. (The relationship between SubtreeGi and subtree Gj) For subtree Gi and Gj rooted with gi  and gj separately, if cor? gi-gj ?= 0? then we can say subtree Gi and Gj are non-related; when cor?gi-gj? < ?mincor?then we can say subtree Gi and Gj are weak- related, otherwise the two subtrees are related.

To partition the generalized items into different clusters, we have to calculate the correlation between two set of generalized itemsets. Here we give the definition of item-cluster.

Definition 9. (Item-Cluster) We call a set of related generalized itemsets as an item-cluster.

Definition 10. (The correlation between two item- clusters Ci and Cj) There are many ways to evaluate the correlation between two item-clusters?We use the underlying  function:   ,  ( , ) max{ ( , )} q i r j  i j q r p C p C  COR C C cor p p ? ?  =  ?Formula 3-3? The correlation COR(Ci,Cj) between two item-  clusters Ci and Cj is the maximal value among all elements of these two item-clusters. When there exists  a pair of elements of two item-clusters related, we can say these two item-clusters are related.

3.2 How to partition the transaction database based on correlation between items?

Our method partitions the transaction database along with the generation of frequent generalized itemsets using the top-down and recursion policy. It includes four major steps: Step 1?Choose the start level for partition The partition can start from any level l of the taxonomy.

Usually, it starts from the level 2.

Step 2?Counting the support of 1-itemsets and prepruning For each generalized item of level l, we generate the frequent 1-itemsets at first based on the partitioned transaction databases of level l -1, then prune all the descendants of the items, which are not frequent.

Step 3?Counting the support of 2-itemsets and forming the item-Clusters During the generating all the frequent k-itemsets of level l, we use the formula 3- 1 and 3-3 to calculate the correlation between items or item-clusters. we use hierarchical clustering method to form the item-clusters of level l such as C1,C2,C3,?,Cm.

Step 4 ? Partitioning the transaction database According to the result of the item-clusters of level l, we partition the transaction database D into several smaller transaction databases such as D1,D2,D3,?,Dm and each Di with only items in Ci left, where 1 ? j ? m.

Repeating the step 2 to step 4 on the level l +1 until the upper level of leaf level of taxonomy, then we can get all the frequent generalized itemsets level by level.

Because it partitions the transaction databases base on the level l., so the number of partition transaction database of level l +1 is usually more than that of level l and the size of each partition transaction database of level l +1 are usually smaller than that of level l. It will benefit the counting the support of itemsets by reducing the scan I/O time of transaction database.

3.3 The optimized pruning rules based on the correlation theory  Beside we can use the correlation theory of item to partition the transaction database, we also propose some optimized pruning rules, which also will benefit our algorithms.

Theorem 1. If generalized itemsets gi and gj are non- related, then any descendants of subtree rooted with gi and gj are non-related.

Corollary 1. If generalized itemsets gi and gj are weak-related, then any descendants of subtree rooted with gi and gj are weak-related.

Theorem 2. If the generalized itemsets gi and gj are weakly related. Then gi and gj cannot form frequent itemsets.

Corollary 2. If generalized itemsets gi and gj are weakly related, then any descendants of subtrees rooted with gi and gj cannot form frequent itemsets.

Optimization rule 1. Any generalized frequent itemsets cannot contain the ancestor and descendant nodes at the same time.

Optimization rule 2. Any generalized itemsets containing two non-related subtrees? nodes (or weak- related subtrees? nodes) cannot be frequent.

Optimization rule 3. If a generalized itemsets has one subset, the subset?s ancestor cannot form frequent itemsets, and thus this generalized itemsets cannot be frequent.

4. Algorithms for mining generalized frequent itemset   Our algorithm includes two parts: the CBP_SLAR is the main algorithm to mine generalized frequent itemsets and the CBP is the procedure called by the CBP_SLAR to partition the transaction database based on the correlation of items.

4.1. Algorithm CBP_SLAR  The CBP_SLAR algorithm generates the generalized frequent itemsets from the top to bottom of the taxonomy tree level by level using different level minimum support. The main algorithm follows.

Input?D(1)- the original transaction database; D- the partitioned transaction database; ?- the taxonomy tree; ?minsup(l )- the minimum support of level l ; Dstack- the stack keeps the partitioned transaction database; Fstack- the stack keeps the mark of level; Fstack- the stack keeps the frequent itemsets.

Output?LL(l )- The frequent generalized itemsets of level l .

1? Push D(1) to Dstack; Push 1 to FStack; 2? for ( Dstack ? ?) do { 3?   Pop up D from Dstack; 4?   Pop up l  from FStack; 5?   if depth(l ) ? ? then { 6?     pop up L(l -1,1) from Kstack; 7?   } //end if 8?   Apriori_gen L(l ,k) until L(l ,k-1) = ?; 9?   add all L(l ,k) to LL(l ); 10? if L(l ,2) ? ? then { 11?     Compute COR(Ci,Cj); 12?     CBP(?,COR(Ci,Cj)); 13? } //end if 14? LL(l )= ?k L(l ,k)  15? } //end for 4.2 Algorithm CBP  CBP is the key function to partition the transaction database and called by the main algorithms CBP_SLAR.

Algorithm 4.2  CBP(?,COR(Ci,Cj)) Partitions the transaction database according to the correlation between item-clusters Ci and Cj.

Input: D- the transaction database; ?- the taxonomy tree; COR(Ci,Cj )- the correlation of item-clusters Ci and Cj. ?mincor- the minimum correlation of item- clusters; Output?Dstack- the partitioned transaction database; 1) Initialize item-Cluster; 2) for ( Max(COR(Ci,Cj)) ? ?mincor ) do { 3)   Merge Cj to Ci; 4)   Recompute COR(Ci,Cj); 5) } // end for 6) for each item-cluster do { 7)   partition D by item-clusters; 8)   push D into DStack; 9)   partition L(l ,1) by item-clusters; 10)   push L(l ,1) into KStack; 11)   Push l +1 into FStack; 12)  } // end for  5. Performance study   To evaluate the efficiency of CBP_SLAR algorithm, we develop all the algorithms in JAVA language. We tested and compared it with the well-known algorithms on a HP DL380 G3 server with duo Xeon 2.8 GHZ CPU and 2GB main memory running Windows Server 2003. The databases DB1I1 and DB2I2 we used for the experiment are real-life financial transaction databases from a large commercial bank. The characteristics of two transaction databases are summarized in Table 5.1.

Table 5.1 Real-life transaction databases parameters  Databases Number of Transactions Number of Items  Max Length of  items  Level of Taxonomy  Distribution of items  DB1I1 About 250K 165 8 5 Balanced  DB2I2 About 360K 165 10 5 Skewed  In Table 5.1, the DB2I2 is the item-skewed transaction database where the proportion of some items is very high, while the items in DB1I1 are item- balanced relatively. Our experiments work on both transaction databases. Because ML_series [5] algorithms have several varieties, we select the ML_TML1 as the representation to compare with our CBP_SLAR algorithms.

Group one - DB1I1 used. We first examine the algorithms with respect to the different minimum support thresholds with different Geometric Proportion (GP). For example, if we use 0.4?, 0.2?, 0.1? and 0.05? at four levels with GP equals to 2. Here 0.05% is the minimum support of the fourth level, and 0.1% is the minimum support of the third level, which equals to 0.05% multiply GP (equals to 2), and 0.2% is the minimum support of the second level, and 0.4% is the minimum support of the first level.. We let ?mincor always equals to the minimal support of the leaf level according to the definition.

Figure 4 Performance study by different minimum support  with GP=1.5 on DB1I1   Figure 5 Performance study by different minimum  support with GP=1.1 on DB1I1 In Figure 4, we use GP=1.5, the curves show that  CBP_SLAR runs faster than the ML_TML1 by 32% to 48% without loss of frequent itemsets. In Figure 5, we use GP=1.1, the curves show that CBP_SLAR runs faster than the ML_TML1 by 40% to 58%. The above Figures show two interesting features. First, when the minimum support decreases, the CBP_SLAR will be more efficient compared with the ML_TML1. Second, when the geometric proportion of minimum support decreases, the CBP_SLAR will be more efficient compared with the ML_TML1. All these features of CBP_SLAR are desirable in mining more weak association rules in large transaction databases.

Group two - DB2I2 used. We test CBP_SLAR with the same minimal support setting on DB2I2, which is item- skewed. The curves of Figure 6 and Figure 7  show that CBP_SLAR runs faster than the ML_T2L1 by 12% to 24% and 26% to 32% respectively. From the Figures 6 and 7, we can see the same performance advantage of CBP_SLAR but the efficiency is reduced compare with Figure 4 and 5. That is because the DB2I2 is item- skewed and many items are tightly correlated, and cannot be partitioned. Therefore, the performance of CBP_SLAR is more efficient on the balanced data than on the skewed data.

Figure 6. Performance study by different minimum support  with GP=1.5 on DB1I2   Figure 7. Performance study by different minimum support  with GP=1.1 on DB1I2 Group three - DB1I1 used. Now we examine the algorithms in relevant to the number of transactions in the database. In Figure 8, we use the 50k, 100k, 150k, 200k and 250k transactions with the minimum support being (0.84, 0.56, 0.38, 0.25, GP=1.5). The curves show that CBP_SLAR runs faster than the ML_TML1 by 28% to 52%. In Figure 9, we use the 50k, 100k, 150k, 200k and 250k transactions with the minimum support being (0.33, 0.30, 0.28, 0.25, GP=1.1). The curves show that CBP_SLAR runs faster than the ML_TML1 by 38% to 58%. These two Figures show that the curve of CBP_SLAR is more flat than the curve of ML_TMl1 when the number of transaction is increasing. Therefore, we can draw a conclusion that CBP_SLAR has relatively good ?scale-up? behavior, which is desirable in the processing of large transaction databases using relatively smaller minimum supports.

Figure 8. Performance study by different transaction  numbers with GP=1.5 on DB2I1   Figure 9. Performance study by different transaction  numbers with GP=1.1 on DB2I1  6. Conclusions and future work   To improve the efficiency of mining generalized frequent itemsets from taxonomy data, this paper propose a new method call CBP_SLAR algorithms to mine generalized itemsets. First, we gave the correlation theory, which is used to partition the transaction database into several smaller ones level by level and reduce the scanning size of transaction database. secondly, we also propose several optimizing rules to prune the redundant generalized itemsets, which can reduce the amount of unnecessary itemsets.

By experiments on the real-life transaction database, the results show that our CBP_based algorithms outperform the well-known ML_series algorithms by improving at least 30% to 40% without loss of the frequent itemsets.

In addition, our algorithms will be more efficient with the transactions increasing and minimum supports descending, and will do benefit to the large taxonomy data in most practice applications with either item- skewed or item-balanced characters. As the universal method, CBP_based algorithm can be used to other research areas with taxonomy such as maximum or closed generalized frequent itemsets, which will be our future work.

