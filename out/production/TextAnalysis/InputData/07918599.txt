2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Abstract?Disasters are undesirable and often sudden events causing human, material and economic losses, which exceed the coping capability of the affected community or society. In recent years, with significant advancement in information technology, various intelligent systems have been developed to support all aspects of disaster management, including emergency prediction, timely response and aftermath recovery. This paper addresses the anthropogenic disaster identification issue by exploiting audio big data mining. Specifically, a novel and efficient sound classification scheme is proposed, which is based on unsupervised acoustic feature learning and data-driven taxonomy. The proposed framework could accurately identify anthropogenic disaster events, e.g., gun shot, explosion, scream cry, etc.

from dynamic audio data, and it consists of three major stages as follows. First, predominant acoustic patterns are characterized by dictionary learning algorithms, which can generate robust acoustic feature representations for recognition under noisy conditions.

Second, hazard sound event taxonomy is created by exploiting probabilities distances between extracted sound dictionaries. Finally, taxonomy structure is embedded into hierarchical classification algorithm to improve classification. The Proposed approach is evaluated using real-world dataset with 10 emergency sound categories and 3275 clips. According to extensive experimental comparisons, proposed approach achieved state-of-the-art performance in anthropogenic disaster identification.

Index Terms?disaster management, audio surveillance, feature learning, taxonomy creation, data-driven approach.

F  1 INTRODUCTION  D ISASTERS are the phenomenons that pose serious threatto people, economic assets or the functioning infras- tructure of society. They are caused either by natural forces (known as natural disasters), or by human actions, negli- gence or errors (known as anthropogenic disasters). The nat- ural disasters include tropical storms, floods, earthquakes, landslides, etc, While the anthropogenic disasters are gener- ally classified into technological disasters, (e.g., engineering failures, transport disasters), and sociological disasters (e.g., criminal acts, riots) [1]. The damage of disasters can be sig- nificantly reduced by employing information technologies, such as developing and deploying geographic information systems, remote sensing and satellite data to predict natural disasters [2], [3] and building anomaly surveillance system using advanced information and communication technolo- gies (ICTs) to accelerate emergency response [4], [5]. In this study, we focus on development of audio content retrieval approach to identify multiple types of man made disasters.

People living in both urban and rural areas are po- tentially exposed to the threats resulted of human intent or negligence. Literature statistics reveal a trend that the impact of man-caused disasters is increasing in recent years [6]. Concretely, there were nearly 7000 deaths in man-made  ? This study was partly supported by Cross-ministerial Strategic Innovation Promotion Program (SIP) / Technologies for maintenance, renewal, and management for infrastructure, and supported by the New Energy and Industrial Technology Development Organization (NEDO), Japan.

? J. YE, T.Kobayashi, H.Tsuda and M.Murakawa are with National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan, 3058560 E-mail: {jiaxing.you, t.kobayashi,m.masahiro}@aist.go.jp  ? X. Wang is with Department of Media and Telecommu- nications Engineering, Ibaraki University, Japan. E-mail: xiaoyan.wang.shawn@vc.ibaraki.ac.jp  disasters in 2015, compared to approximately 5900 in 2014.

man made disasters can occur in every aspect of life. For instance, numerous transportation routes, including road, air, rail, and water have been regard as source of hazard.

An accident could occur on any of these routes, and put lives, property and natural resources in danger [7]. Another example of man-made hazard garnering much attentions is terrorism movement, and it was reported that 23 countries recorded their highest number of deaths from terrorism in 2015 [8].

In order to reduce vulnerability to hazards, disas- ter/emergency management is commonly performed and the process has been coined into four key stages, which are warning phase ahead of disaster occurrence, immediate dis- aster detection and response, aftermath recovery phase and mitigating or preparedness phase that aiming at avoidance of future reoccurrences of same type disaster [1]. Among those four phases, early emergency prediction/detection is regarded as foremost step due to its significant effect on reduction of further loss from hazards in progress.

Modern information technologies, such as high-speed wireless networks, low-cost sensory device and efficient ma- chine learning algorithms, enable us to establish intelligent surveillance system to detect emergence event efficiently. As for the sensory input, video and audio are most actively employed [9], [10] and we focus on use of audio information for hazard event recognition in this study. Audio-based surveillance exhibits couples of advantages over video- based approach and we summarize those metrics as follows: ? Audio data size is much smaller and hence we can collect multiple sensor data to increase detection coverage.

? Cameras are limited by angular field of view. On contrary, microphones can be omnidirectional and can collect acoustic    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 2  Hazard sound recognition  Voice Attack  ?  Traffic  Service providing  Noise pollution control  Traffic management  Violence prevention  ?  Car horn  Siren  ?  Scream  Cry  ?  Gun shot  Explosion  ?  Ubiquitous audio sensing  Fig. 1: Flowchart of the proposed acoustic scene classifica- tion approach  information with a spherical field of view.

? Image sensors suffer from illumination variations, while it is not an issues for acoustic sensory devices which can work constantly well in the day and night.

? For some specific hazard events, audio clues are more ef- fective comparing with image, such as scream and gunshots.

The dynamic sound perspectives carry rich information in living environment, and therefore can be regarded as vital clues to indicate hazard events. On attempting to make safer and enjoyable lives for inhabitants, considerable research ef- forts have been devoted to the develop semantic audio data mining system for hazard detection, such as identification of scream and gunshot in urban area [11], [12] and recognition of different types of weapons? sound [13]. These audio- based disaster detection systems have been evaluated under varying environments, including offices [Kotus et al., 2013], elevators [Radhakrishnan et al., 2005b; Chua et al., 2014], and public transport vehicles [Pham et al., 2010; Rouas et al., 2006; Vu et al., 2006]. Besides research articles, several practical real projects had been carried out to promote real applications of audio-based disaster alert systems. For instance, in the European research project of EU-FP7-EAR- IT [17], which aims at minimizing risks in city traffic, a novel audio processing system have been developed for estimating the number of cars passing by in real time [18].

Meanwhile, the resultant traffic density measures had been exploited for air quality/urban noise monitoring [19]. In addition, a project developed an sound detector to identify sirens among street noises, well-designed schemes, such as changing traffic lights to help emergency vehicle pass through complex junctions quickly, can then be taken [20].

It is the case that exploring audio content information to ac- celerate emergence response. Audio surveillance is another major application field where acoustic signal is examined to discern man made disasters of violence conflicts or terrorism movements. Its general working process is as follows: once the incident is detected via audio content retrieval, an alarm  can be immediately issued to notify local police officers and thus immediate intervention can be performed to control emergency event [21]. These research projects demonstrated acoustic modality can contribute to disaster management in practice. To summarize, we show a conceptual chart to demonstrate application of hazard sound recognition technique for man made disaster management in Fig.1.

In this study, we present novel hazard sound recog- nition framework with data-driven taxonomy. The funda- mental idea is to create taxonomy to organize unstruc- tured hazard sound data. The hierarchical formation can significantly facilitate browse, search and classification of acoustic patterns.In order to characterize predominant pat- terns in emergency sounds, unsupervised acoustic feature learning algorithms are employed. The methods can ef- fectively extract effective feature that invariant to back- ground noise. On creation of disaster sound taxonomy, we introduce probabilistic distance metrics in both Euclidean and Grassmannian spaces to quantize difference between hazard sound categories. A taxonomy can be subsequently built using well-defined categorical distance measures in an agglomerative fashion. At multi-class emergency sound recognition stage, we devise method to embed hierarchical dependencies in acoustic data into classification algorithm.

We show through experimental comparisons that state-of- the-art hazard sound event recognition accuracy can be achieved with public acoustic dataset.

The contribution of this study can be summarized in three-fold: ? This study presents a novel framework emergency sound classification. The classification engine can be used to man- age multiple man made disasters, such as traffic load assess- ment, violence conflict and terrorism movement detection.

? Hierarchies render efficient way to organize and retrieve unstructured data at multiple levels of granularity. In this study, we develop novel scheme to create taxonomy of acoustic events so as to improve hazard sound recognition.

? We propose improved formulation for hierarchical regu- larized logistic regression (HR-LR), to alleviate unbalanced class issue in classification model construction. The pro- posed formulation exhibits favourable performance in real- data evaluation.

Remainder of this paper is organized as follows. Sec- tion 2 delivers brief overview of current audio surveillance systems. Section 3 introduces the proposed hazard sound recognition system framework. The three key components: unsupervised acoustic feature learning, data-driven sound class taxonomy construction and hierarchical classification scheme are explained explicitly. Section 4 shows our evalu- ation dataset, validation protocol, experimental results and comparison analysis. Finally, in Section 5, we summarize our findings in this work.

2 RELATED WORK  Audio content classification has been long standing re- search topic through decades, and the major objectives are speech and music [22], [23]. More recently, audio surveil- lance garnered increasing interests and plenty of research results have been reported [13], [24]. Those systems aim at    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 3  Audio  waveform  time  Time-frequency  representation  time  fr e  q u  e n  c y   Dictionary Learning Taxonomy  construction Hierarchical  Classifier  ?(?, ?) ?(?, ?)  Audio  waveform  time  Time-frequency  representation  time  fr e  q u  e n  c y   Label output [ t ]  ?(?)  Acoustic codes  generation Content-based  recognition  1. Training phase  2. Testing phase  ?(?)  ?(?, ?)  Fig. 2: Flowchart of the proposed audio-based hazard event recognition scheme  detecting potentially hazardous situations through audio- based monitoring in pubic space. Initial audio surveillance systems imitates frameworks of modern automatic speech recognition (ASR) or musical information retrieval (MIR) systems, such as applying standard MFCC feature to rep- resent input sound and adopting GMM models to conduct content-based classification [10]. However, hazard sounds, such as crying or explosion, are inherently different from patterns in speech and music where existed predominant harmonicity or phonemic structures. As a result, standard ASR or MIR systems performed badly in recognizing haz- ard sound events. In addition, a throughout comparison of applying conventional audio processing techniques for sound event recognition has been conducted [25], in which extensively investigated acoustic features of spectrograms of Short-Time Fourier Transform (STFT), Continuous/Discrete Wavelet Transform (CWT/DWT) and MFCCs together with conventional classifiers, such as Artificial Neural Network (ANN) and Learning Vector Quantization (LVQ). Advanced classification schemes have been investigated for various sound content recognition lately, such as using Support Vector Machines (SVM) [26] to exploit non-linear distribu- tions of acoustic events in projected feature space. Moreover, biological research reveals that local time-frequency infor- mation contributes greatly to human auditory, recent studies drew more attentions for audio representation development, and various novel acoustic features have been proposed, such as spikegram [27], a neural-spike-like representation of sound event, likewise, sparse audio features are presented in [28], which is robust to noise interferences. A key issue faced by the sound event classification research community is the lack of labeled data, which hampered comparison and reproducibility of research results. Lately, some efforts have been made to tackle such issue, and open datasets are released in regard to facilitate reproducibility of results, such as UrbanSound8K [29], ESC dataset [30] and DCASE2016 [31]. Inspired by the success of deep neural networks (DNN)  in numerical application fields, e.g. computer vision and speech recognition applications, DNN and its variants of convolution neural networks (CNN) and recurrent neural networks (RNN) have been employed for content analysis of ambient sounds [32], [33]. However, lack of large-scale labelled sound event data is the practical issue that dete- riorates DNN-based sound event recognition performance.

The approaches to augment current dataset or develop novel data-efficient DNN models are critical concerns in application DNN to sound event identification [34].

This paper is an extension based on our previous works tics, Speech and Signal Processing (ICASSP) [35] and 2015 technical update is two-fold: first, new acoustic feature learning method of Spherical k-means is introduced to char- acterize distinctive patterns with respect to each emergency sound class. Second, we proposed novel approach to create categorical taxonomy to organize and classify unstructured hazard sound events. All details will be explained explicitly in following section.

3 PROPOSED SYSTEM ARCHITECTURE The main goal of proposed system is to perform content recognition on emergency sounds. With the help of Internet Communication Technologies (ICTs), ubiquitous acoustic sensors can be deployed to multiple position for collecting audio data. The critical issue turns out to be content retrieval for incremental audio data. In this work, we propose novel scheme to understand acoustic contents with high accuracy and efficiency and the details are demonstrated in this section. First of all, we show a flow chart of propose hazard recognition framework in Fig.2.

3.1 Acoustic feature extraction We first convert hazard sound waveform s(n) to frequency domain via Discrete Fourier Transform (DFT), and the re-    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 4  sulting spectrogram is denoted asX ? RP?N with N frames and P frequency bins. Then, high pass filter with cut-off frequency of 200Hz is employed to eliminate low band noises. In order to smooth the spectrum as well as to reduce dimension, Mel filter bank is applied, which is identical to the one used in speech recognition [22]. The further process are based on bank-scale audio spectrogram representation.

3.2 Unsupervised feature learning for acoustic events  This section demonstrates our approach to hazard sound event feature learning based on sparse coding. To clarify the process, we begin with fundamental mathematical for- mulation of sparse coding as follows. given column-wise hazard event spectrogrm X = [x1, ..., xN ] ? RP?N and we learn representative dictionary, which is denoted as D = [d1, ..., dK ] ? RP?K and K columns referred to as dictionary atoms. At meantime, a series of sparse (audio) codes C = [c1, ..., cN ] ? RK?N can be obtained such that input signal xn can be well-approximated by several dictio- nary atoms, i.e. xn ?  ? cndn. The values of sparse codes  indicate significance of corresponding dictionary entries in signal reconstruction and ?sparse? implies there are many zeros in codes cn. To realize sparse coding from given data, a constraint matrix factorization problem is always presented as follows:  min ??1   N  N? n=1  ????12 ||X ?DC||22? ?? ? fitting term  + ?||C||?? ?? ? sparsity?inducing term  ???? . (1) In a nutshell, ?fitting? terms assures D is good at repre- senting input data X , meanwhile, ?sparsity-inducing term?, which is a l?-norm, emphasizes that only few entries in D will be activated in recovery of X . It is a joint optimization with respect to dictionary D and the coefficients (codes) C of the sparse decomposition and standard optimizer can be employed to solve the problem. In this study, we evaluate two types of feature learning schemes, which are l1-penalized sparse coding and Spherical k-means method.

3.2.1 Dictionary learning (DL) with l1-penalty term  l1-penalized sparse coding, which is also called Lasso esti- mator or basis pursuit, is most conventional formulation. In this paper, we first introduce Lasso sparse coding approach to characterize representative hazard sound patterns using compact dictionaries, at the mean time, input spectrogram is converted to sparse audio codes, which are anticipated to be more robust to noise. In the formation of Lasso estimation, that is, we solve optimization problem [37].

min D,c(i)  ? i  ||Dc(i) ? x(i)||22 + ?1||c(i)||1,  subject to ||D(j)||22 = 1,?j (2)  There are several well developed algorithms to minimize the objective function and we choose coordinate descend method [38].

3.2.2 Spherical k-means dictionary learning More recently, a feature representation learning method called ?spherical K-means? has been proposed and it achieved favourable performance in computer vision tasks [39]. We add this method in this evaluation due to its superior efficiency. This algorithm consists mainly 3 parts: step 1: Input standardization:  x(i) = xi ? ?i? ?i + ?norm  where ?i =  N  ? n  x(i)n , ?i =  N  ? n  (x(i)n ? ?i)2 (3)  By subtracting sample mean (?i) and dividing by standard deviation (?i), feature variables now have zeros means and unit deviations (close to 1).

step 2: Whiten features to enhance subtle variations:  [V,D] = eig(cov(x)),where V DV > = cov(x)  x(i) = V (D + ?zcaI) ?1/2V >x(i),?i  (4)  Above process is coined as ?zero-phase component analysis? or ZCA whitening transform. Through eigenvalue decom- position of the data covariance matrix, the high-frequency noise can be suppressed, and thus, significant discriminant patterns can be characterized.

step 3: Building representative acoustic pattern dictio- nary  c (i) j =  ???D (j)>x(i), if j == argmax  l |D(l)>x(i)|  0, otherwise  D = XC> +D  Dj = D(j)/||D(j)||2, ?j  (5)  Parameters of ?norm and ?zca are determined experimen- tally. Through performing above steps, compact dictionary for hazard sounds and a series of sparse codes can be obtained. Iterate until convergence (usually 10 iterations will be enough) to build statistically stable dictionary for one sound class. In sec. 4, we conducted extensive experiments on real data to compare two dictionary learning approaches for hazard sound events characterization.

3.3 Acoustic events taxonomy construction Clustering analysis seeks efficient way to browse and orga- nize unstructured data with tree hierarchy and the approach can improve recognition accuracy in contrast to flat classi- fication fashion [40]. In this study, we conduct data-driven clustering analysis to build taxonomy of various types of emergency sounds. The brief process is demonstrated as follows. Based on aforementioned process of acoustic fea- ture learning, a set of dictionaries can be extracted from all types of acoustic events. On data-driven taxonomy cre- ation, critical issue is to select appropriate distance metric between representative dictionaries of hazard sound events.

We evaluate three effective set-to-set distance measures that are derived from Euclidean and Grassmannian geometry to investigate between-dictionary distances. Grounded on the optimal distance measure selection, we adopt agglomerative approach to build up taxonomy in an bottom-up manner.

Since the dictionary-to-dictionary distance metric played    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 5  ?  Subspace ?? Subspace ??  ?  Subspace ?? Subspace ??  b. Constraint mutual subspace angle  Projection Projection  Subspace ? ? Subspace ? ?  a. Subspace principal angle c. Grassmann manifold distance  | ? |2 ??  ??  ??  Fig. 3: Metrics for dictionary-to-dictionary distance measure  central role in creating taxonomy, we show details of those metrics in subsections.

3.3.1 Principle angles between mutual subspaces There are several metrics to investigate similarities between subspace and the most fundamental one is principle angles.

It had been successfully applied for various application, including face recognition [41] and video tracking. We intro- duce the measure to evaluation similarity between acous- tic event dictionaries. Let D1, D2 ? RP?K be two sub- spaces with identical dimensionality. The principal angles, or canonical angles, 0 ? ?1 ? ...... ? ?k ? ?/2 between D1 and D2 are recursively defined for k = 1, ...,K by:  cos?k = max uk?span(D1)  max vk?span(D2)  uk ?vk, subject to  uk ?uk = 1, vk  ?vk = 1,  uk ?uj = 0, vk  ?vj = 0, k 6= j  (6)  where uk?vk are called the k-th pair of canonical vectors.

The standard approach to compute principle angles between subspaces is to introduce SVD, in which  D?1D2 = USV ?, where U ?U = I, V ?V = I  S = diag(cos2?1, ..., cos 2?m)  (7)  cos ?i is the cosine of the ith principal angle. cos ?1, ..., cos ?d are known as canonical correlations and the maximum eigenvalue of decomposition represented by cos ?1 indicates the minimum canonical angle ?1. We denote ? = [?1, ..., ?d].

Finally, the distance between mutual subspaces is defined as  lMSM =  K  ? p=1  cos2 ?p (8)  The lMSM ? [0, 1] score exhibits following characteristics, if two subspaces coincide perfectly, lMSM is 1; on the other hand, in the case of two orthogonal subspaces, lMSM will be 0. The value reflects structural similarities.

3.3.2 Distance defined as mutual constraint subspaces an- gle The main drawback of principle angle metric is that it is vulnerable to within-class variations. Since environmental sound always merged with background noises, it is nec- essary to eliminate effect of variations that are irrelevant  to between subspace difference. In pursuit of between- subspace discriminant power, in a sense analogous to linear discriminant analysis (LDA), constraint mutual subspace method (CMSM) had been proposed [42] and the major process is presented as follows.

Let D1, ..., DM denote M acoustic dictionaries (sub- spaces) with K entries of P dimension, and we define the concatenated matrix as Dall = [D1, ..., D2] . CMSM seeks a joint projection that subspace-to-subspace difference can be revealed. We denote the projection vectors as V , which are composed of the eigenvectors of the smaller eigenvalues in eigendecomposition:  DallD > allVCMSM = VCMSM?, s.t., V  > CMSMVCMSM = I,  (9) where ? = diag({?}) is the eigenvalue diagonal matrix.

According to [42], it is shown that project vectors of smaller eigenvalues are based on the differential vectors between subspace and therefore the projection can greatly facilitate between-subspace discrimination. Through VCMSM , we can obtain new representation of input subspaces  D?m = V > CMSMDm (10)  Subsequently, principle angles can be measured between projected categorical dictionaries [D?1, ..., D?M ] in constraint subspace using eq(8).

3.3.3 Grassmann manifold distance metrics  Grassmann manifold G(K,P ), which is defined as a set of K-dimensional linear subspaces in RP , is another for- mulation to conduct subspace-based learning. Grounded on intrinsic geometry of Grassmann manifold, the geodesic distance is introduced to measure the length of the geodesic curve connecting two subspaces along the Grassmannian surface [43] and several effective distance metrics have been further developed [44], such as geodesic distance (arc length):  lgeodesic(D1, D2) = ||?||2, (11)  where ? represents canonical angles, and Chordal distance (projection F-norm):  lproj(U1, U2) = ||U1U>1 ? U2U>2 ||2 (12)    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 6  According to comparison study reported in [45], projection F-norm Grassmann distance delivered favourable perfor- mance across multiple tests, and therefore we select this metric in this work. It is noteworthy that Grassmannian distances are closely related to principal angles, which are discussed in previous section. However, the conceptual for- mulations are completely different. Grassmannian distances manifests distances of two subspaces in the embedding space (Grassmannian manifold), while principal angles ex- ploit subspace-similarity in each individual dimension.

3.4 Hierarchical classification scheme  In order to take advantage of learnt acoustic events taxon- omy for efficient hazard sound identification, we employ hierarchical regularized logistic regression (HR-LR) model to performance classification. The method can leverage the dependencies in class hierarchy to boost performance. In addition, to tackle the imbalanced class issue, we propose improved formulation for HR-LR and the details are pre- sented as follows.

Hierarchical classification problems admit a general op- timization objective which consists of empirical loss and model penalty:  argmin w  Lemp + ??R(W). (13)  Concretely, in the hierarchical regularized logistic regression (HR-LR) model [46], empirical loss Lemp was defined as the loss incurred by the instances at every leaf-nodes:  Lemp = ? n?T  M? i=1  L(yin, ci, wn) (14)  On the other hand, the learnt hazard acoustic events taxon- omy was embedded into regularization term R(W), which incorporates hierarchy structure of acoustic data as well as enhancing generalization power of the model for unseen data  R(W) = ? n?N   ||wn ? w?(n)||2. (15)  Intuitively, such setting enhances the hierarchical depen- dencies in the sense that it encourages node and its parent to adopt similar weights (close to each other in euclidean norm).

Putting two parts together, we have HR-LR formulation:  min w  ? n?T  M? i=1  sigmod(yinw > n ci) + ?  ? n?N   ||wn ? w?(n)||2  (16) However, there is one critical drawback in current for-  mulation, that is, if sample numbers varies widely for each sound category, the model will be biased towarding major- ity class because objective function endeavours to minimize quantity of sample-wise error rate, not taking overall data distribution into account. To alleviate imbalanced classes matter, we revise empirical loss part by assigning class weights denominator. It can be regarded as that now we focus on class-wise recognition accuracy and thus majority  Algorithm 1 HR-LR optimization Input: C ?, ?, T,M,N Result: model parameter W?  1: procedure HR-LR 2: Initialize (W0) 3: while not converaged do 4: Solve eq.(18) using LBFGS 5: Wi ?Wi?1.

6: end while 7: W? ?Wi 8: end procedure  TABLE 1: Audio corpus for evaluation  Category Number of clips Average duration (sec)  car horn 429 3.36 dog bark 1000 3.40 gun shot 374 3.29  siren 929 3.31 cough 80 8.35  cry 60 6.94 alarm 60 5.50  explosion 118 4.12 scream 125 6.41 swords 100 3.27  class no long overwhelms the minority. The newly proposed formulation is as follows:  min w  ? n?T   M  M? i=1  sigmod(yinw > n ci) + ?  ? n?N   ||wn?w?(n)||2  (17) Since the objective function of HR-LR is convex and differ- entiable, second order methods are applicable to perform optimization. In concern of dealing with large scale audio data, we employ LBFGS algorithm in this study.

The corresponding gradient Gd can be computed in closed- form as  Gd = wn ?w?,n ?  M  M? i=1   1 + exp(yinw>n ci) yinci (18)  We summarize optimization routine in algorithm 1.

4 EXPERIMENTAL VALIDATION 4.1 Dataset and settings  We validate proposed emergency sound identification sys- tem through extensive experiments using real corpus com- posed of various types of emergency event sounds. The evaluation dataset was constructed from the following com- pilations: (i) BBC Sound Effects Library [47], (ii) Urban- Sound8K datasets [29], (iii) ESC: Dataset for Environmental Sound Classification [30], (iv) sound effects from internet sources1. By incorporating multiple datasets, we obtain various types of hazard sounds with high variation and wide diversity. In total, we extracted 10 classes of emergency sound events with 3275 audio clips. For all sound clips, the sampling rate was set to 16 kbps with 16 bit resolution.

1. http://sound.natix.org/    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 7  TABLE 2: Parameter settings  name of parameter presence equation value  Fourier window length T (1) 23.2ms Balance weight ?1 (4) 0.2 Dictionary size K (5) 30  normalization intercept ?norm(6) 0.01 whitening intercept ?zca(7) 0.05 regularization coeff. ? (16) 0.2  Details of samples numbers of each event category and averaged clip length are given in Table 1. It is noteworthy that the UrbanSound8K dataset contributed as major part of our evaluation corpus and original excerpts are taken from website of Freesound2 ? an online sound repository containing over 160,000 user-uploaded recordings. Those crowd sourcing audio clips were mixed with all kinds of background noises with varying intensities and thus the dataset is well-suited to assess robustness of proposed audio content retrieval scheme. In the experimental validation, we set Fourier analysis window length to 23.2ms (1024 points) with half overlapping. 60 Mel-filters were applied to convert spectrogram to mel-scale. In tab.2, we summarize all parameters used in our processing.

In our algorithmic settings, several parameters were involved in both acoustic feature extraction and multiclass emergency sound classification stages. Those parameters were critical to systematic performance. For example, dur- ing feature learning, we prefer to construct class-wise dic- tionary to express predominant patterns in hazard sounds, meanwhile a series of robust sparse codes were expected.

The trade-off between two demands were manipulated by a balancing parameter ?1 in eq.(4), which propagates our preference of model and can be turned through experiments.

Likewise, regularization coefficient of ? in eq.(16) controls the model characteristic leaning to fewer loss in fitting to evaluation corpus or to smaller generalization error in coping with out-of-sample data. In summary, we listed out all hyperparemeters applied in our model in Table 2. We exhibit classification rates using boxplots of 10-folder cross- validation in all experiments, making sure there is no over- lapping between training and test data in each evaluation iteration.

4.2 Demonstration of learnt acoustic features and tax- onomy  In this section we show intermediate results of our audio- based disaster system. Through examining those outputs some insights can be derived in acoustic pattern analysis of hazard sound events. In Fig.4, we first exhibit the example of learnt representative acoustic pattern dictionaries with respect to each type of hazard sounds using Spherical k- means method. Class-wise dictionary can be regarded as a concise representation of acoustic data since significant patterns are effectively encoded. In Fig. 4, we can observe with-in class similarities for one dictionary, meanwhile, be- tween class discrimination can also be seen. For instance, car horn sounds looks more similar to scream class and multiple  2. http://www.freesound.org/  impulsive feature patterns can be found in both gun shot and cough dictionaries due to their short-time characteristic.

Grounded on those compact representations (dictionary ma- trix), we further investigated between-dictionary distance metrics using methods demonstrated in sec. 3.2 and further construct hazard sound class hierarchy in an agglomerative fashion. We show the extracted emergency sound taxon- omy using Grassmann distance metric in Fig. 5. According to the bottom-up combinational structure, gun shot and explosion sounds exhibit highest similarities compared to other classes, while car horn is distinctly dispersed from other acoustic categories. Based on such data-driven depen- dency, we further establish fine classification hyperplane to classify multiple disaster sound events using the algo- rithm discussed in sec. 3.4. Notably, by changing between- dictionary distance metric, different taxonomy formulation can be extracted. To ensure the metric inherently reflect class dependencies, we conducted extensive experiments to validate optimal distance metric for taxonomy construction and the results were shown in following section.

4.3 Evaluation of feature learning and dictionary-to- dictionary distance metric  This section covers our evaluation result on dictionary learn- ing and taxonomy construction for hazard sound events. We tested two dictionary learning algorithms, which are Lasso sparse coding and Spherical k-means method. Together with three set-to-set distance metrics including subspace angle, constraint mutual subspace angle and Grassmann manifold distance. In order to evaluate performance of those methods, we conducted extensive experiments using test dataset. At classification stage, hierarchical regularized logistic regression (HR-LR) was employed and results were demonstrated with mean averaged precision (mAP) across all hazard sound categories. The evaluation results were exhibited in Fig. 6, including all six combinational methods? performance. By results ranking, we can see distance metric defined on Grassmann manifold is most effective to model dependencies between multiple sound classes. Set-to-set distance measures defined in Euclidean space, i.e. principle angles and constrained subspace angles, generated inferior performance due to their vulnerability to wide variation and high noise in sound events. In addition to precision comparison, efficiency is another critical concern for real applications, especially under the context of big-data era.

In our system, highest computation load is consumed at feature dictionary learning stage since it is necessary to pro- cess millions frame of acoustic spectrum. We compared the two methods: Lasso sparse coding and Spherical k-means.

Although incremental improvements had been made to improve efficiency of Lasso sparse coding, it is still much slower compared to latter method, because L1 regularized data fitting is inherently complex. In contrast, Spherical k- means is rather simple which involves only several steps of matrix multiplication, and with the help of whitening pro- cessing, Spherical k-means approach outperformed Lasso sparse coding method in both classification accuracies and computation efficiency.

2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 8  Fig. 4: Learnt representative pattern dictionaries for 10 classes of emergency sound events  Fig. 5: hazard event taxonomy created by using spherical k-means dictionary learning and Grassmann distance metric  Fig. 6: Evaluation results of feature learning and between- dictionary distance metrics for taxonomy construction (re- sults were organized by distance metrics and in each group, first and second results corresponds to using Lasso sparse coding and Spherical k-means dictionary learning methods, respectively)  4.4 Performance analysis proposed man made hazard sound identification approach In our last experiment, we validated the performance of proposed framework through comparison with reference  methods [48]. In Fig. 7, we presented comparison results on class-wise hazard sound identification accuracies. Proposed achieved superior performance in recognizing all categories of emergency sounds according to experiments. Particularly, for 6 cases of acoustic events out of total 10, we obtain identification accuracies exceeded 90%, they are car horn, dog bark, gun shot, siren, cough and explosion. The improvement is derived from mixture of key components in proposed framework, including acoustic feature dictionary learning, set-based distance measurement for sound event taxonomy creation as well as the taxonomy-embedded hierarchical classification algorithm. It is noteworthy that the two haz- ard event classes are cry and alarm, with both categories consists only 60 samples. The limited data collection may lead to high variance issue in classification model training, and therefore it can be anticipated that by providing more clips, the identification precision of the two classes can be further improved. In summary, proposed framework achieved 87.34% of mean averaged precision (mAP) for dis- aster sound identification and outperformed the reference method with large margin that delivered mAP as 82.80%.

5 DISCUSSION The results we showed above demonstrate that super- vised hierarchical classification scheme is highly compet- itive when it comes to detect hazard sounds in ambient    2168-6750 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TETC.2017.2700843, IEEE Transactions on Emerging Topics in Computing  MANUSCRIPT SUBMITTED FOR IEEE TETC SI: EMERGING TECHNOLOGIES FOR DISASTER MANAGEMENT 9  Fig. 7: Comparison of class-wise recognition accuracies for hazard sound recognition  environment. However, it is small-scale validation using the current datasets combination. For instance, once a piece sound recording of unseen event enters the content re- trieval engine, a mis-classification maybe issued. It is a challenge for all supervised pattern analysis systems and a rejection option is one reasonable measure to deal with unseen pattern matter. In addition, it is worth noting that Deep Neural Networks (DNN) approaches have garnered much of interests in machine learning field and the method had been extensively applied for acoustic scene analysis and sound event classification [32], [33]. Nevertheless, ac- cording to latest evaluations, the DNN methods has not generated significant higher results than its predecessors, i.e. the systems using hand-crafted acoustic features (MFCC) with classical SVM or random forest classifier so far. One crucial reason is that size of current sound event dataset is rather small compared with the ones used for imaging parsing/natural language processing. To tackle the limited audio data issue, one possible solution might be employing transfer learning strategies for DNN based systems where part of the DNN can be initially learned by a large amount of external audio data. It will also be long-lasting research topic cross multiple fields.

6 CONCLUSION This paper presented novel approach to investigate ambient sound for protecting lives, property and the economy from anthropogenic disasters. Specific sounds, e.g. screaming, shouting, gun shout and explosion, are high related to anthropogenic disasters of violence conflict, accident or even terrorism movements. Compared to video surveillance, au- dio information can be quite effective to indicate occurrence of those hazard events and therefore win time for immediate response and reduce the damage of disaster. To effectively characterize acoustic clues for early disaster detection, we developed emergency sound recognition framework based on acoustic feature learning and data-driven taxonomy cre- ation. Feature learning methods were adopted to extract distinctive feature from emergency sound events. Subse- quently, we developed an automatic taxonomy construc- tion approach to facilitate multi-class hazard sound event identification. Our scheme was validated by using crowd souring audio dataset. Experimental results demonstrated the effectiveness of the proposed hazard sound recognition method.

