Elliptic Object Features Extraction and Measurement in Image Data Mining

Abstract?In image data mining, especially in mining of high dimensional association rules, extracting features of shape, color and texture is not enough for these tasks. All kinds of the features of object are often extracted. These object features of image include visual features, statistical features, and dimensional features and so on. This paper proposes an integrated method for object features extraction to meet the expression demand of high dimensional association rules. At last, the validity has been proven by an instance.

Keywords-object features extraction; parameter measurement; image data mining

I.  INTRODUCTION Before the data mining of image, in order to recognize  object, the object features must be extracted at first. Object features usually mean three visual properties, which are color, texture and shape[1]. However, in the mining of association rules of high dimensional image, the statistical features and the dimensional features must be used.

7D_ARP, the seven dimensional association rule model of image has been brought in literature [2], which involves visual feature, statistical features, and dimensional features, without the integrated method that how to extract features.

Elliptic object is an important object, which is always involved in the mining of image. The paper proposes a method that extracts the visual feature, statistical features, and dimensional features of elliptic object. The validity of the method has been proven by an example.



II. FEATURES OF ELLIPTIC OBJECT In image data mining, the extract of general features of  elliptic object usually means the extract of visual features, such as color, texture and shape. Besides, it involves some image object features, including statistical features, dimensional features and so on. Statistical features include the area, perimeter and number of object. Dimensional features include the center position, shape, radius of elliptic object, and the distance and orientation between two objects [3, 4].

A.  Geometric Features of Single Elliptic Object The quality distribution of binary image is symmetrical,  so the centroid and shape center are overlapped. Assuming the pixel position corresponding to the object in image as (xi,  yi) (i = 0, 1, ?, n-1; j = 0, 1, ?, m-1), the centroid position of object is:  ?  =  ?  = =      1 n  i  m  j ixnm  x ?  =  ?  = =      1 n  i  m  j iynm  y           (1)  Object perimeter is calculated by the pixel number that boundary takes. For marked image, boundary point can be defined as: for 4-neighborhoods, if the point itself is in the object region, and near background, which means that among its 4- neighborhoods, there is one point whose pixel is -1 at lest(the pixels in background are assigned -1), the point is the boundary point. The summation of boundary points, which belong to the same region, is the perimeter of the region. The formula used to calculate perimeter, is similar as the one used to calculate area. Compare with the latter, the former only has one more decision condition that decide if the point is boundary point.

Object area can be easily defined as the number of pixels that object boundary surrounds. Object area is related as the size of itself, while is not related as the gray value of pixels of every points. After marking image, parameter of area can be easily calculated by statistical method. For example, in order to extract the area of an object region marked 1, the area of the object region can be calculated by counting the number of pixels whose gray value is 1 in 2D array. The formula used to calculate area of A is:  ?  =  ?  =  =     ),( n  i  m  j  jifA                             (2)  f(i, j) denotes the grey value of pixel, (i, j) denotes the position of pixel.

Minimum enclosing rectangle (MER) is adopted to  calculate the long axis radius and short axis radius of elliptic  x  y  O  MER  Figure 1. MER method to calculate long axis radius and short axis radius   DOI 10.1109/ICMTMA.2009.31     object. One of the MER methods is that the boundary of object is circumrotated at a time by 30 in the scope of 900.

The maximum and minimum of x, y of enclosing rectangle?s boundary point in the orientation of reference frame are registered in every circumrotating. Circumrotating to a certain angle, the area of enclosing rectangle reaches the minimum. The parameters of the area of enclosing rectangle are selected as the length and width, which is shown above in Figure 1.

B. Dimensional Features among Multi Elliptic Objects The distance between two objects is depended on the one  between the two object centers. Assuming the two points of image are P(x1, y2) and Q(x2, y2), distance between the two points usually is measured by following method.

Block distance is ||||),( 21214 yyxxQPd ?+?=                 (3)  Chessboard distance is |)||,max(|),( 21218 yyxxQPd ??=             (4)  Assuming the two object centers are P(x1, y2) and Q(x2, y2), the sharp angle  between line and horizontal axes is defined as follows.

12tan xx yy  ? ?=?   12arctan xx yy  ? ?=?           (5)  The relation between  and  is show in Figure 2.

The expression of angle  in the orientation of linked line is that at the first quadrant,    12arctan xx yy  ? ?== ?? ,  at the second quadrant,    12arctan180 xx yy  ? ?=?= ?? ,  at the third quadrant,   12arctan180 xx yy  ? ?=+= ?? ,  and at the last quadrant,   12arctan xx yy  ? ??=?= ?? .



III. FEATURE EXTRACTION OF ELLIPTIC OBJECT  A. Image Edge Detection Method Image object edge is a result because of discontinuity of  lightening value or grey value of pixels. The incontinuity usually can easily be detected by calculating partial differential [5,6]. Grads operator and Laplacian operator are common technologies to detect the edge.

As for consecutive image f(x, y), one rank partial differential,  x f  ? ?  and  y f  ? ? , is the simplest differential operator.

They calculate the change rate of grey level in x axes and y axes respectively. The change rate of grey level of ?  in any direction can be expressed as follow:  ?? ?  sincos y f  x ff  ? ?+  ? ?=  ? ?                       (6)   As for digital image f(i, j), generally, difference  operation is adopted to substitute partial differential.

Corresponding one grads difference is:  )1,(),(),( ??=? jifjifjify  ),1(),(),( jifjifjifx ??=? Orientation difference is:  ??? sin),(cos),(),( jifjifjif yx ?+?=?         (7) Maximum of directional derivative  122 })],([)],({[),( jifjifjif yx ?+?=??       (8)  is called graded modulo. Practically, template convolution is often used to margin measure operation.

Generally, the grads operators include Roberts, Prewitt and Sobel.

?? 01      ???? ? ?         ???? ? ?          As for a consecutive image f(x ,y), Laplacian operator on position (x, y) is defined as follows:        y f  x f  f ? ?+  ? ?=?                       (9)  =  =-  =1800-  =1800+  Figure 2. The relation between orientation angle and sharp angle in four quadrants      (a) Roberts  (b) Prewitt  (c) Sobel  Figure 3. Grads operators     ? ??  ?     ??? ?? ???        In digital image f(i, j), Laplacian value can be shown by many modules. General modules are shown as figure 4.

B. Contour Tracing Method of Elliptic Object Purposes of contour extraction and tracking are to  acquire the outer contour features of image. The method of contour extraction of bianryimage is that if there is one black point in the original image and 8 points next to it are black, cancel it.

The basic method of contour tracking is that defines a ?mining rule? of boundary pixels: search from left to right, up to down, and find out the first black point which must be the boundary point at the bottom of the left part, marked A.

At least one of the 4 points next to it (its right, right up, above and left up) is the boundary point, marked B. The boundary point C is searched from B followed the route: right, right up, above, left up, left, left down, below and right down. If C is A, the route become a circle. Then the program ends, or else continues to search A from C.

C.  Feature Extraction Algorithm of Elliptic Object Step1: set the threshold of grey value, and segment  background; Step2: connect region, select elliptic region; Step3: extract region interior boundary; Step4: modify and display elliptic boundary, count the  number of ellipses Ci, i = 1, 2, ?, n; Step5: for each ellipse Ci, i = 1, 2, ?, n , begin; Step6: find the center point (ri, ci), i = 1, 2, ?, n, where  n is the number of ellipse; Step7: calculate the direction of long axis radius Dia and  short axis radius Dib, and calculate the area Areai and perimeter Li of ellipse, i = 1, 2, ?, n, where n is the number of ellipse; then display data;  Step8: calculate the linked line orientation, distance between centers of two ellipses, displaying data;  Step9: end for.



IV. EXAMPLE AND RESULTS The flow chart of image features extraction and  measurement is shown as figure 5. It includes Image Acquirement, Edges Extraction, Contour Segment, Features Extraction, Features Measuring and Results Visualization.

The image shown in figure 6 is an original one selected from the HALCON software, an image processing platform of MVTec Company. There are two big holes and two small holes in the image of metal part. In this experiment ellipse shape, center position of ellipse, length of long axis radius and short axis radius of ellipse, area, perimeter, distance between ellipses, orientation between two ellipses will be extracted.

The detection of circles is shown in Figure 7.

Measurement of long axis radius, short axis radius, center points of circles, area and perimeter is shown in Figure 8. Measurement of distance between two circles center, the orientation measurement of two circles is shown in Figure 9.

Figure 6. Original image     Figure 7. Detection of circles  Figure 5.  Flow chart of feature extraction and measuring  Image Acquirement  Edges Extraction  Contour Segment  Features Extraction  Features Measuring  Results Visualization  Figure 4. Laplacian operator template      Figure 8. Measurement of long axis, short axis, center points, area and  perimeter of circles    Figure 9. Measurement of distance between two circles center, and  orientation measurement of two circles   The data of features of objects extracted from Figure 6 to Figure 9 are shown in table I and table II, which can be used for image data mining of high dimensional association rules.

TABLE I.  DATA OF  GEOMETRIC AND STATISTICAL FEATURES  Dia Dib center point Areai Perimeter Li  C1 45.85 44.82 318.68, 438.73  1614.06 142.43  C2 78.58 77.31 461.03, 549.04  4770.96 214.87  C3 45.29 44.65 511.19, 722.1  1588.47 141.29  C4 80.75 78.81 138.26, 432.61  250.66 4998.65  TABLE II.  DATA OF SPACE FEATURES  Distance/Orientation C1 C2 C3 C4  C1 _________ _________ ___ C4_1=180.5 O4_1=-88.05  C2 C1_2=180.5 O1_2=-52.22  _________ ___ __________  C3 _________ C2_3=180.2 O2_3=-16.16 ___ __________  C4 _________ _________ ___ __________

V. CONCLUSIONS Conventional feature processing method only extracts  shape, color, texture and other visual features of ellipse which describes basic features of single ellipse. It is short of describing object statistical features of the whole image and dimensional relation between ellipses. It can?t meet the demand of visual feature, statistical features, and dimensional relation features of object which accord with image high dimensional association rules. The integrated method proposed by the paper for extraction and measuring of visual feature, statistical features, and dimensional relation features of object makes a good foundation for mining high dimensional association rules of image.

