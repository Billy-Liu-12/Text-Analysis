Detection of Public Information Sign in Airport  Terminal Based on Multi-scales Spatio-temporal

Abstract?A new method based on multi-scales spatio-temporal vision information is presented to detect public information signs for the airport terminal service robot (ATSR) localization.

Firstly, public information signs are searched roughly in big space scale by using the connected components labeling algorithm. Secondly, the signs position and size in visual field are adjusted properly based on spatio-temporal relativity. Finally, the signs are detected according to the extracted SIFT (Scale Invariant Feature Transform) features. Experiments by this new method on ATSR show that public information signs are detected rapidly and precisely.

Keywords- Multi-scales spatio-temporal information; Public information sign; SIFT features; Airport terminal  service robot

I.  INTRODUCTION In recent years, robots have been gradually applied to many  kinds of airport services. For instance: luggage pointing, guided tours, patrols and so on. In this paper, ASR is a kind of mobile robot indoor which is used to meet services in terminal.

Accurate localization in robot is a key to achieve decency and service functions in real-time, and whether the public information signs are detected is an important premise for localization, so real-time public information sign detection poses a complex problem for ASR. Based on the standard of China's civil aviation [1], public information signs composed of graphical symbols are used to guide passengers in terminal, ticket office. In our work, public information signs which are composed graphical symbols or letters are used in terminal (public information signs are called public signs for short in the next context), for instance inquiry and luggage storage public signs. There is no uniform method to detect objects, in which, most of sign detection are traffic (road) signs. Up to now little information referred in other papers is related to our research.

Normally, sign detection is based on extracting color or shape features to segment and classify, but there is some influence condition: illumination conditions, direction of sign?s face, status of paint on signs, placement of multiple signs near each other, torn and variations in sign?s scale, obstacles etc, so problems of false detection bought out [2],[3],[4].This paper addresses the problem of vision focused on public sign  detection in terminal for the system of ASR. Due to the particularity in spatial position, there are some difficulties in the detection processing:(1)Shape features can not be extracted easily for the distortion of public signs in the image;(2)Because the public signs locate dispersedly, sometimes public signs are missed or only part of the sign is in the image;(3)Images contained signs are in low resolution, so they are hard to detect;(4)Public signs are occluded mutually in images, so most existing splitting approaches by making use of morphology [5] or histogram [6] are invalidated. In allusion to theses problems above, a new method based on multi-scales and spatio- temporal information is presented. In our method  public signs are searched fast by making use of stabilization of image edge in big space scale, while there is plenty of detail information in small space scale image [7],[8],[9],[10], imaging position are changed automatically based on spatio-temporal relativity of public signs: imaging position of public sign is corrected continuously by establishing a detection window and image is extracted SIFT features[11] and [12] in various space scales in search for the prior space scale, over these phases public sign detection is finished.



II. DETECTION OF PUBLIC SIGN BASED ON MULTI-SCALES AND SPATIO-TEMPORAL INFORMATION  The whole detection processing is composed of three phases in succession: (1) Fast searching for public signs in big space scale; (2) Public sign detection by spatio-temporal changing; (3) Searching for prior space scale based on extracting SIFT features.

A. Fast Searching for Public Signs in Big Space Scale Based on the standard of China's civil aviation [1], there  must be intense contrast between graphical symbols and color grounding in public signs. A searching method based on color features and spatial information is designed in this phase (see Fig. 1).

DOI 10.1109/CSSE.2008.606    DOI 10.1109/CSSE.2008.606       Figure 1.  The frame of searching for public signs in big space scale.

The position calibration of robot?s head is defined by  L= ( , , )p t z , p expresses as pan position, t expresses as tilt position and z represents the zoom value, due to the reason of public sign?s height in space, the tilt searching scope is regulated:  t? ?? < < .

(1)  ? is the threshold determined by robot?s viewpoint scope and the height of public signs in space. Blue grounding has been used in most terminals. The main task of this phase is to segment the input image and extract out the areas that contain public sign patterns, color feature is extracted first. The raw input image is transformed from the original RGB color space to the HSV color space. Next, objects in the binary image are extracted using the connected components labeling algorithm.

Finally every ROI (Region of interest,) is signed by center coordinates, width and height in the raw image, so as to the public signs are searched fast in big space scale image.

Public sign images from different sites or in different illumination status (see Fig. 2) were picked up in order to obtain the thresholds of HSV. There was another interfere: because of the mirrors in the surrounding, public signs could be reflected by the mirror and virtual public sign images may be detected, (see Fig. 3(a)), so S value must be regulated more reasonably. Different result images were showed distinctly when S values are different (see Fig. 3(b)(c)).

Figure 2.  Seletetd public information signs for extraction thresholds.

(a)                                          (b)   (c)  Figure 3.  Public information sign images contained disturbance. (a) disturbance representation. (b) - (c) searching images representation at  different thresholds of S.

The HSV thresholds are regulated as followings:   H <  H  < Hlow high S  <  S  < Slow H igh V  <  V  < Vlow H igh  ? ?? ? ? ??  .                           (2)    Public information signs are searched by these processing above, result images are shown in Fig. 4 and ROI are drew in white thick lines.

(a)                                                (b)   (c)  Figure 4.  Public information signs searched in big space scale. (a) RGB representation. (b) binary images representation. (c) interested regions in the  RGB images.

B. Public Sign Detection Based on Spatio-temporal Changing Information After searching in big space scale, imaging position and  space scales are changed automatically based on spatio- temporal relativity of public signs in the image by robot?s head controlling in order to validate the reality of  ROI .

When public signs are detected by robot in real time, a number of issues may do effect detection. Some problematic public sign images will be presented. (see Fig. 5)     (a)                                            (b)   (c)   Figure 5.  Seleted public sign images for detection. (a) one part of the public sign in the image. (b)one public sign occluded by the other. (c) one blurred  public sign in the image.

By taking into the synthesis of all the information aforementioned, spatio-temporal changing method is designed as followed (see Fig. 6):     Figure 6.  The frame of spatio-temporal changing.

Step1: The parameter L is obtained from current robot?s position, and center coordinates ( ),0 0iX x y , iW and iH are achieved to express the ROI sequence. ROI are detected in the order of iS value from big to small, iS is expressed as:  iS  = iW * iH .                                           (3) Step2: The occluded public signs in images are processed  by threshold ? , ?  is defined as the ratio between width and height of normal public sign, when  1 .5 2W i H i  ? ?< < .                                        (4)  ROI is considered to be two sign regions and two virtual center coordinates are defined to be ' '( , ), ( , )i iT x y H x y .

1.50 ' 1.50  '  x x Wi  x x Wi  y y y  ? = ? ??  = +? ? ? = =?  .                                        (5)   Step 3: In this phase, a detection window is presented  originally, where the detection window is expressed as that the window is being sized to m pixels x m pixels , and the window center is the same as the center of the input image, the m value is determined by velocity of robot?s head and size of input image. The motion control vector OX is constructed, and robot?s head is controlling by vector OX .

Step4:In the processing of motion, the center coordinates of ROI is ( ),0 0iX x y  in the foregoing frame, the input image is scanning inversely compared with OX ,in which ( ),0 0iX x y and ? are taken as the scanning initial point, scanning step respectively [13] and [14]? ? is the longest moving step of center coordinates between two sequential frame. Then decision depending on temporal relativity is made as followed: if the ROI limited is detected again, it proves to the reality of detection result in the foregoing frame, keep detecting this ROI, or else stop searching for the ROI limited. Carry out processing above time and again until X coordinates is in the detection window scope.

Step5: Space scale is reduced at the speed of v, once the space scale is changed, the ROI is detected by some criteria to search for the prior space scale, the image in the prior space scale will be the result image.

Step6: Resume the initial position L, switch to the step 1 to carry through detecting the next ROI, the changing phrase is ended until all the ROI are detected.

C. Searching for Prior Space Scale Based on Extracting SIFT Features Space scale could be enhanced by adjusting zoom value of  the camera in robot?s head and the resolution of images can be enhanced [15], but if the space scale is changed without any criteria, system is time-consuming as well as redundant, the detection efficiency will fall. Lowe present a algorithm which is called SIFT [11] and [12]. The features are invariant to image rotation, affine distortion, in addition of noise, change in 3D viewpoint, and change in illumination. The features are highly distinctive and they can describe the environment excellently. A plenty of images contained public signs collected from terminals were used to do experiments: these images were M1 pixels x N1 pixels. Public sign regions were extracting SIFT features and SIFT feature numbers were increased nonlinearly followed by the enhancing of the space scale, when the numbers reached to or exceeded M for object recognition, results were correct in most samples, these features were accurately described the public signs in terminals.

The criteria space scale is regulated by extracting stable SIFT features:  (1) The value of zoom is changed at the speed of v, the maximal regulating times is n. During the processing of every regulation:  SiR Simage  = .                                        (6)  If 0R R? , the regulation is stopped . 0R is a ratio threshold  and Simage is the image size;  (2) To minimize the cost of extracting SIFT features, when the quantity of features of the ROI is more than M, regulation is stopped;  (3)Compared with the quantity of features in the foregoing space scale, if the quantity falls in current space scale, regulation is stopped and the detection image in the foregoing space scale will be the result image.



III. EXPERIMENTS The detection method had been tested on ?fuwa? ASR  which had an Intel PM 1.6G CPU and 1G memory. Tianjin airport terminal and Beijing N0.3 airport terminal were chosen as our testing circumstances, Fig. 7 showed the scene that robot was in terminal. This part was implemented in the windows platform and Visual Studio 6.0 development environment. By using decision system, the system performed well on public information sign detection by motion control of robot?s head.

The image was 320 pixels x 240 pixels, the detection window was limited at 10 pixels x 10 pixels, and the detection edge of public signs in terminal were drew in white thick lines.

Figure 7.  The ?fuwa? ASR image.

A. Experiments in Tianjin Airport Terminal Experiment 1: In this experiment, images with the public  signs in bad status were used to test the searching algorithm in big space scale (see Fig. 8).

Set1: the image contained public signs where illuminant was in it or not at the same time was used;  Set2: the image contained public sign in intense illumination and in bad view point was used;  Set3: the image contained public signs in different illumination status was used. The public signs were not well reflected by light in the image.

This experiment sets also contained another 40 public information sign images in terminal. The searching module?s right rate was found to be 98%.

(a)                                             (b)   (c)   Figure 8.  Searched images of public signs in various status. (a) set1 image representation. (b) set2 image representation. (c) set3 image representation.

Experiment 2: In this experiment, images used were  problematic. One part of a public sign was detected in the beginning. Following the spatio-temporal changing, the detection region of the public sign was gradually expanded (see Fig. 9).

(a)                                    (b)   (c)   Figure 9.  The detection images of a public sign by spatio-temporal changing.

Experiment 3: the image contained multi public signs was detected in one scene (see Fig. 10). Considering the detection time, three regions were selected in the sequence of area value from big and small. The ROI were signed with the number from one to three. The parameter L was [50,150,0]. v, n, M and 0R values were respectively 1,5,600,0.6. The top right corner regions in the images were sign extraction images in every frame. Took the detection processing of the second ROI in Fig. 10(a) as example:        (a)                                     (b)   (c)                                    (d)   (e) (f)     (g)(166)   (h)(264)   (i)(460)   (j)(670)   Figure 10.  A sequence detection images of the second public sign in one scene. (a) the searching image in one scene in big space scale. (b) spatio-  temporal changing on the second sign. (c)-(f) images of the second sign in various space scales.(g)-(j) extracting SIFT feature images and SIFT feature  numbers in every space scale.

The searching speed in big space scale of every frame was 0.109 seconds and the speed of robot?s head was from zero to sixty degree per second. Time cost of public signs during every detection phase detected in Fig. 10(a) was showed in Table.1.

TABLE I.  TIME COST OF PUBLIC SIGN DETECTION IN ONE SCENE  Public information  signs  Spatio- temporal  changing(s)  Time cost in space scales changing(s)  Number 1 1.150 Scale   1 0.313 2  0.625 3  0.750  Number 2 0.419 Scale   1 0.179 2  0.316 3  0.453 4  0.714  Number 3 0.506 Scale   1 0.043 2  0.086 3  0.199 4  0.488 5  0.750   Experiment 4:In this experiment, images used were  problematic that one sign was occluded by the other. The virtual center coordinates were?59,161?and?177,161? at first and spatio-temporal changing was done on the two virtual regions. The splitting result showed in Fig. 11. When public sign images were captured in big space scale, two public signs were detected as a whole region, with the regulation of space scale, the two public signs were split finally.

(a)                                          (b)   (c)                                          (d)   (e)  Figure 11.  The splitting images of occluded public signs representation.

B. Experiments in Beijing No.3 Airport Terminal Beijing No.3 airport terminal (T3) is being used not long  ago, the setting of public information sign has been changed compared with other domestic terminals as followings:  (1)Hue and saturation of sign?s color have been changed, in the low illumination, some signs could not been seen clearly;  (2)There are another public signs: green signs and guide signs on the floor;  (3)There are also some public signs in the same grounding;     The parameters were changed correspondingly in this experiments and Fig. 12 showed the result images.

(a)                                              (b)   (c)                                          (d)   (e)                                        (f)   Figure 12.  The detection images of public signs in T3.(a)result image of  fuscous-blue public sign.(b)result image of blue and green public signs.(c)result image of guide sign on the floor.(d)result image of multi-signs in the same grounding.(e)searched images of public sign in big space scale.



IV. CONCLUSION A new method based on multi-scales and spatio-temporal  information was presented in this paper. Multi-information involved space scale, spatio-temporal information were synthesized in the method. The detection module performed very well in real time on the public signs under various statuses: public signs were missed, part of a public sign was in the image, too small public sign images were captured and some public signs were occluded by other signs in the image, moreover, it was achieved robustly on the robot at real-time performance in different environments.

