A NEW METHOD TO MINE VALID ASSOCIATION RULES

Abstract: To reduce invalid rules in the mining of association rules,  we have analyzed the reasons and presented a relative confidence in the judgment criteria. Based on the value of relative confidence, we classify strong association rules into positive, invalid and negative association rules. We offer an algorithm of mining association rules with new judgment criterion and make tests with Visual FoxPro. The tests indicate that the new method stated in this paper can obviously reduce invalid association rules.

Keywords:  Algorithm Data mining; Association rules; Relative confidence;  1 Preface  Data mining is a new and rapidly growing field.

Association rule mining in a transaction database is a very important topic in data mining research. It was first proposed by Agrawa1.R et af?]. An example of an association rule is ?90% customers would purchase bread and butter together with milk?. It means that, if customers are buying some items, how likely are they also to buy others on the same trip to the supermarket?

Mining association rules can be described as follows: Let I={i&, ..., i,,,} be a set of items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T c  I. Each transaction is associated with an identifier, called TID. Let X be a set of items. A transaction T is said to contain X if and only if X T. An association rule is an implication of the form X=>Y, where X c I,Y c I, and X n Y=0. The rule X=>Y holds in the transaction set D with support s, where s is the percentage of transactions in D that contain XU Y(i.e.,both X and Y). This is taken to be the probability, P(X U Y). The rule X=>Y has confidence c in the transaction set D if c is the percentage of transactions in D containing X that also c0ntain.Y. This is taken to be the conditional probability, P(YIX).That is,  i  Support(X=>Y)=P(X U Y) Confidence(X=>Y)=P(Y IX) Rules that satisfy both a minimum support  threshold(min-sup) and a minimum confidence threshold(min-conf) are called strong ones.

A set of items is referred to as an itemset. An itemset that contains k items is a k-itemset. If an itemset satisfies minimum support, then it is a frequent itemset.

The association rule mining is a two-step process: @Find all the frequent itemsets in the transaction  database. If support of itemset X, support(X) 3min-sup , then X is a frequent itemset. Otherwise, X is not a frequent itesset.

@Generate strong association rules from frequent itemsets. For every frequent itemset A, if B c A , B f 0 ,  and support(A)/support(B) 3 min-conf, then we have association rule B=>(A-B).

The second step is relatively easy, and its algorithm generation can be found in the reference[?]. The present focuses in research are to find highly efficient algorithms[31 in the first step, to mine association rules in the distributed databases and to find the interesting association rules, etc.

In this paper, we discuss how to mine valid association rules.

2 The lack of present judgment criteria for association rules  The present judgment criteria of association rules are a support and a Confidence. If the association rules are generated according to the criteria, a lot of them are invalid and falseL4].

Let?s look at an example. Suppose there are N records at low levels of transaction database. We only discuss the N records of coffee and milk sales. Let milk be the number of the people who purchase milk, milk be the number of the people who don?t purchase milk, coffee be the  0-7803-7865-2/03/$17.00 02003 IEEE  mailto:luoket@cs.hn.cn    70 cofee  number of the people who purchase coffee and coffee be the number of the people who don?t purchase coffee.

The data of the example are shown in table 1.

Table 1. Statistics of coffee and milk sales  I I I I  Let?s study the association rule coffee=>milk.

Confidence=20/25=0.8 If the threshold of support is smaller than 0.2 and the  threshold of confidence is smaller than 0.8, this association rule would obviously be mined as a strong rule. So we can draw a conclusion: Putting milk together with coffee can improve the sales of milk.

However, this is not the case. 90% customers at the primitive levels of transaction database would purchase milk. But from the above mined rule, we know the coffee buyers have 80% possibility to buy milk. That is to say, the possibility of the coffee buyers also buying milk is less than that of the random customers who we know nothing about.

In fact, the customers have a greater probability to buy milk.

Its confidence=70/75=0.933.

From the above example, we know that the association rules that satisfy both a minimum support threshold and a minimum confidence threshold may be invalid.

Let?s look at another example. Suppose we have a set of transaction data, which is shown in table 2.

Suppo*20/ 1 oo=o .20  Table 2.

I 106 I A,B,F,J ? I  We only discuss 2-itemsets in table 2. First, by observing directly, we find that C and D appear or disappear together. So C=>D should be a valid association rule. After calculating, we get its support 0.5, its confidence 1. Next, we observe A and B, whether A appears or not, B always appears. So A=>B can?t form the valid association rule. After calculating, we got its support 0.5, its confidence 1. As result, A=>B and C=>D have the same support and confidence. That is to say that association rule A=>B is equal to association rule C=>D. Obviously, the conclusion is false.

In order to solve the problem in the judgmentcriteriaof association rules, the referenceL5] gave definition of interesting rules, and the reference[61 improved it. In the reference[?], an interestingness of negative association rules was defined. In the referenceL8], a validity of association rules was defined. However, we consider that the methods that were mentioned in the above reference can not solve the problem well.

3 Improving judgment criteria of association rules  We consider that the fundamental reason of the problem is the definition of the confidence of association rule X=>Y, which only considers the probability of Y appearing when X appears, but not consider the probability of Y?s appearing while X doesn?t appear. So the association rules can not reflect the influence extent of some itemsets to others precisely. For this reason, we suggest solving the problem by the following method.

3.1 Adding a new judgment criterion in mining association rules: a relative confidence  To solve the problem, we are going to add a new judgment criterion, a relative confidence(defined by the authors)on the base of previous judgment criteria of association rules. Let P(X) express the percentage of transactions in D that contain X. Let P ( x )  express the percentage of transactions in D that doesn?t contain X. Both P(YJX) and P(Yl x ) are the conditional probability. We define the relative confidence of X=>Y as follows:  If P(X)=l and P(Y)=l, relative confidence=l (3.1) If P(X)=l and P(Y)<l, relative confidence=O (3.2) If min-sup<P(X)<l,  relative confidence=P(Y(X)-P(YI X ) (3.3) In most cases, only (3.3) is used. Since the value  ranges of P(Y1X) and P ( Y ( F )  are all in [0,1], and the confidences of strong rules are not less than a minimum support threshold, P(Y1X) 3min_conf, the value ranges of  -  -      relative confidences are in [-l+min-conf, 11.

3.2 Classifying strong association rules into three classes according to the relative confidences  Let?s discuss the relative confidence by using 2-itemsets in table 2.

@All records contain B and F. Based on (3.1), the relative confidence(B=>F)=l  @All records contain B, four records contain H and other six records don?t contain H. Based on (3.2), the relative confidence(B=>H)=O  @None of the records contain K, all records contain B.

Based on (3.3), the relative confidence(K=>B)=-l0/10=-1  Obviously, B and K can?t form a frequent 2-itemset, and the relative confidence of this 2-itemset can?t be calculated in the process of association rules generation.

This example just shows the conditions in which the relative confidence equals - 1.

@Five records contain A, and the other five records don?t contain A. All records contain B. Based on (3.3), the relative confidence(A=>B)=5/5-5/5=0.

@Five records contain C and D together, and the other records don?t contain C or D. Based on (3.3), the relative confidence(C=>D)=5/5-0= 1.

@Two records contain J in the five records that contain C, and one record contains J in other records that don?t contain C. Based on (3.3), the relative confidence(C=>J)=2/ 5 - 1 15=0.2,  @)One record contains H in the five records that contain C, and two records contain H in the other records that don?t contain C. Based on (3.3), the relative  *  conditions: A support is no less than the support threshold given  by users.

A confidence is no less than the confidence threkhold  given by users.

A relative confidence is no less than R1 given by  users.

Suppose the rule X=>Y is a positive association rule.

Because the relative confidence of the positive association rules is larger than 0, P(YJX)>P(Y] x ),the probability of transactions in D that contain Y when X occurs is larger than that when X does not occur. Usually, these association rules are valid association rules, which can directly instruct users to make the decision. For example, in medical science application, we get a positive association rule X=>Y, where X represents ?smoking frequently?, Y represents ?pulmonic?. So we can draw a conclusion: the people who smoke frequently may get the lung disease more easily. In the seven situations discussed in table 2, @@@ may be positive association rules.

In most cases, people primarily concem about positive association rules. A typical example of association rule mining is market basket analysis. For instance, if customers are buying milk, how likely are they also to buy bread on the same trip to the supermarket? If other customers aren?t buying milk, how likely are they to buy bread? Such information can lead to increased sales by helping retailers do selective marketing and plan their shelf space.

-  3.2.2 Invalid association rules  Invalid association rules satisfy the following , conditions: ~ I _  confidence(C=>H)=l/5-2/5=-0.2.

Since. the value range of relative validity is  [-l+min-conf, 11, we introduce the threshold of relative confidence RI and R2, which are all positive numbers between 0 and 1. (-R2) is larger than (-l+min-conf). R1 may be equal to R2 or not. So the relative confidences of association rules must be one of the three cases:  R1 &relative confidences 1 -R2<relative confidences <R1 - l+min-conf< relative confidencess -R2 According to the value range of relative confidences,  we divide strong association rules that satisfy the demands of support and confidence into three classes: positive association rules, invalid association rules and negative association rules.

A support is no less than the support threshold given  A confidence is no less than the confidence threshold  The value range of relative confidence is (-R2, Rl).

Suppose the rule X=>Y is an invalid association rule.

Because the relative confidence of invalid association rule is close to 0, the probability of transactions in D that contain Y when X occurs almost equals to that when X doesn?t occur. Usually, these association rules are useless.

Among 7 cases discussed in table 2, @@ is an invalid association rule. Moreover, if the relative confidences of some association rules are proximate to 0, according to the value of R1 and R2, they may be invalid association rules.

by users.

given by users.

3.2.1 Positive association rules 3.2.3 Negative association rules  Positive association rules satisfy the following Negative association rules satisfy the following      conditions: A support is no less than the support threshold that  given by users.

A confidence is no less than the confidence threshold  given by users.

A relative confidence is no more than -R2 given by  users.

Suppose the rule X=>Y is a negative association rule.

Because the relative confidence of negative association rule is smaller than 0,the probability of transactions in D that contains Y when X occurs is smaller than that when X does not occur. These rules can?t directly instruct users to make the decision, but sometimes they can indirectly do it by using opposite example. For example, in table 1, we get negative association rule X=>Y, where X represents ?customers buy coffer?, Y represents ?customers buy milk?.

That is to say, the percentage of records that contain ?customers buy coffer and milk? in the database is larger.

Because it is negative association rule, from the opposite example of X, we can indirectly get that customers who don?t buy coffer have a greater probability to buy milk than coffee buyers. In 7 situations discussed in table 2, @I may be a negative association rule, but @ can not, since it can not satisfy the demands of the support of association rules.

Let?s calculate the relative confidence of rule coffee=>milk in table 1, the relative confidence=20/25-70/75=-0.13. Obviously, the rule coffee=>milk is not a positive association rule.

3.3 Algorithm  Introducing the relative confidence in the judgment criteria of association rules, we can go on using the previous algorithms to find all frequent itemsets, but must modify the previous algorithms to generate association rules from the frequent itemsets appropriately. A modified algorithm to generate association rules are described as follows:  Step 1 Input the thresholds of confidence and relative confidence.

Step 2 Generate all possible strong and weak association rules from frequent itemsets.

Step 3 Calculate the confidences of association rules according to the method in the reference[*].

Step 4 Delete the weak association rules whose confidences are less than confidence threshold.

Step 5 Based on (3.1), (3.2) or (3.3), calculate the relative confidence of strong association rules.

Step 6 Store all the positive association rules, invalid association rules and negative association rules in different data tables. Based on the need of users, export the positive association rules or all strong association rules, and so on.

Explanation: @In step 2, if the length of the frequent itemsets is  different, the number of all possible association rules is also different. The number of rules generated from a frequent  2-itemset is c: =2. For example, frequent 2-itemaset AB may generate association rules A=>B and B=>A. The number of rules generated from a frequent 3-itemset is  c3 + c3 =6. For example, frequent 3-itemset ABC may generate association rules: A=>BC, B=>AC, C=>AB, AB=>C, AC=>B, BC=>A. So we can analogize that the number of rules generated from a frequent N-itemset is  1 2  N-1 CN 1 + c; +.. ...+ CN .

@The algorithm we offer is only one of many feasible  algorithms. You can modify this algorithm according to the reality. For example, you may combine step 3 and step 5 into step 3 in the algorithm.

@In fact, every subset of a frequent itemset is frequent. Once all the frequent itemsets and their supports are known, the strong association rules can be found without any further scans of the database. If the itemset XY is frequent, P(X),P(Y) and P(XY) are known. Since  P(X)=l-P(X) P( x Y)=P(Y)-P(XY) P(Y IX)=P(XY)/P(X)  P(Y I x )=P( x Y)/P( x )=(P(Y)-P(XY))/( 1 -P(X)) the relative confidences can be calculated without any  further scans of the database in step 5.

3.4 Test result  With the help of the data in table 2, we tested many times with Visual FoxPro (software environments: Windows98, Visual Foxpro5.0). Sometimes positive association rules are only a small part of the strong association rules. The experiment methods are as follows:  Input a support threshold. Find all frequent k-itemset (k=1,2,3.. .) by using Apriori algorithm, and store the frequent itemsets into different data tables according to their lengths.

Input a confidence threshold. Generate all possible association rules from frequent k-itemsets (k=2,3.. .), and calculate confidences of them, then delete the weak association rules whose confidences are less than confidence threshold.

Input relative confidence thresholds R1 and R2. Calculate the relative confidences of all strong association rules. Produce positive association rules, invalid  Step 1  Step 2  Step 3      Frequent 1 -itemset   association rules, negative association rules and their Some test results are as follows: numbers respectively.

Frequent Frequent Frequent Frequent Frequent 2-itemset 3-itemset 4-itemset 5-itemset 6-itemset  55 99 86 36 6  11 I 30 I 333  Table 4. The number of frequent itemsets generated from data in table 2 (when min-sup=0.3)  I Frequent I Frequent I Frequent I Frequent I Frequent I 15 2  0.3 0.3 0.3  0.6 0.1 0.1 418 309 109 0 74% 0.9 0.1 0.1 175 66 109 0 38% 0.9 0.5 0.1 175 65 110 0 37%  Generally, users care about positive association rules.

The tested results indicate that, sometimes the number of positive association rules is only a small part of all strong association rules, most of which are invalid.

4 Conclusion  To reduce invalid rules in association rule mining, we analyzed the reason of the problem and present a new method, in which we add a relative confidence into the judgment criteria. We define the relative confidence. Its value range is [- 1 +min-conf, 1 1. According to the values of relative confidence, we classify strong association rules into positive association rules, invalid association rules and negative association rules. Positive association rules are usually valid association rules. Invalid association rules are always useless association rules. Negative association rules are often invalid association rules, but its opposition maybe is valid association rules in some case. Generally, only positive association rules are valid. They must satisfy three conditions: support, confidence and relative confidence are all no less than the thresholds given by users. Sometimes, they are a small part of all stfong association rules.

We offer an algorithm of new judgment criteria in mining association rules and make tests with Visual FoxPro.

The tests indicate that the method stated in this paper can obviously reduce invalid association rules.

