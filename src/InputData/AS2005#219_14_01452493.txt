<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Fuzzy  Association Rules discovered on Effective

Abstract? Fuzzy association rules can deal with continuous (numerical) attributes in database, and hence provide alternative new approach for their applications, such as supermarket basket analysis. This new approach can not only find the relations of continuous attributes, but also discrete (nominal) attributes by using crisp sets as special fuzzy sets, moreover combine them together to get good rules for analysers.

However, compared with traditional models, fuzzy models generally have space and time complexity problem. We therefore develop the effective reduced database algorithm with less space and time complexity, which effectively form the transparent and knowledge based fuzzy model ? reduced database table, so that we can simply discover fuzzy association rules from the reduced database table.

Keywords? Simple shaped fuzzy partition; Fuzzy association rules; Reduced database table (RDBT); Effective reduced database algorithm (ERDB); Supermarket basket analysis I.

II.

A.

B.

INTRODUCTION Association rules are useful machine learning model used to represent commonly found patterns in original data.[1] Compared with traditional association rules, fuzzy association rules provide linguistic explanation and overcome the sharp boundary problems [2] in continuous (numerical) attributes, and also can be used to analyse the mixture relations both in discrete (nominal) attributes and continuous attributes.

However, the space and time complexity problem is one of the big issues of fuzzy models. To solve this problem, we discover fuzzy association rules whose credibility is reasonably high from the reduced database table by using the effective reduced database algorithm.

Reduced database table (RDBT) [3] is a joint probability distribution over ?words?, which is inferred from the original database. It is represented in the form of a table in which each line represents a combination of particular attribute values of each attribute with its associated probability. It is also a knowledge based transparent fuzzy model, and can be used to discover other fuzzy models, such as fuzzy association rules.

Effective reduced database algorithm (ERDB) [3] proposed by Jim Baldwin is an efficient algorithm to effectively form the reduced database table which only reflects the main characteristics and ignores information which rarely occurs. It therefore overcomes the space and time complexity problem of fuzzy models in soft computing.

Fuzzy association rules can be used to summarise the information of original database in some applications, such as information retrieval, document content management, etc. In section IV, we will show a new approach of supermarket basket analysis, which uses fuzzy association rules discovered by the effective reduced database algorithm to analyse supermarket basket data.

FUZZY ASSOCIATION RULES Simply triangular or trapezoidal shape fuzzy sets To be able to handle imprecision and uncertainty of the representation of concepts and words in the real world, most machine learning models have been united with fuzzy logic introduced by Zadeh in 1965 [4]. These fuzzy models overcome the sharp boundary problems [2], and hence provide a soft controller surface and good accuracy in dealing with    a soft controller surface and good accuracy in dealing with continuous attributes.

Fuzzy set theory [4], proposed by Zadeh in 1965, shows a good idea that is the use of simple linguistic words in place of numbers for soft computing and reasoning. This provides fuzzy logic with a simplified explanation power of being a suitable interface between human users and computing systems. This power does, though, depend on the form of fuzzy sets. If the fuzzy sets are simple triangular or trapezoidal in shape, then they can be given an easy interpretation. If they have a complicated shape, they do not provide a useful linguistic description.

Optimised fuzzy sets, such as neuro-fuzzy sets [5], are used to obtain good accuracy but they have no explanation power because of their complicated shape. We investigate methods of deriving fuzzy association rules based on Ruspini fuzzy partition [6] for each attribute, which is defined as a family of triangular or trapezoidal fuzzy sets such that for any argument value the memberships add to 1.

Fuzzy sets models and membership function In this paper, we use either equal space fuzzy sets (ES-FS) model in Fig. 1 or equal data points fuzzy sets (EDP-FS) model in Fig. 2 for continuous (numerical) attributes, both of which are based on Ruspini fuzzy partition [6], and still use crisp sets as a special case of fuzzy sets for discrete (nominal) attributes [7].

...

n21 a b ...3Fuzzy set 1-n a-ba ? 1-n a)-2)(b-(na ? Fig. 1: Equal space fuzzy sets (ES-FS) model In the fuzzy sets model in Fig. 1, the ranges of the fuzzy sets are equally spaced in the universal set [a, b], and therefore those fuzzy sets are symmetrical and equally spaced.

...

n21 a b ...3Fuzzy set ) 1-n 2)m-(n(a val ?) 1-n m(a val ? m/(n-1) m/(n-1) m/(n-1) m/(n-1) Number of instances Fig. 2: Equal data points fuzzy sets (EDP-FS) model In the model in Fig. 2, the number of instances in each interval covered by a fuzzy set in the universal set [a, b] is equal. Normally, those fuzzy sets are asymmetric.

Mass Assignment Theory [5] proposed by Baldwin in 1991 integrates fuzzy logic and probability theory. It shows that for simple shaped fuzzy partition {f i} of kth attribute, input such as x = g  is translated into distribution over fuzzy sets of words using membership function Ff : x o [0, 1], where g can be  point value, fuzzy set or probability distribution [4]. The membership values Fi(x) = Pr (f i | g ), where x ? X, and if g is a point value, then Pr (f i | g ) = Fi(g), otherwise we will use point value semantic unification [5] to calculate it.

C. Fuzzy association rules based on Ruspini fuzzy partition Association rules represent the interesting relationships in data. The format of association rules is X?Y (IF X THEN Y) with support and credibility (confidence) [8]. In fuzzy association rules, X and Y are either fuzzy variables that take fuzzy sets as values for continuous attributes, or traditional variables that take crisp sets for discrete attributes. This makes    variables that take crisp sets for discrete attributes. This makes fuzzy association rules more powerful than traditional association rules.

Supposing there are k attributes in total and the jth attribute is on the right side of a fuzzy association rule, the rule based on fuzzy sets models in section II.B is of the form shown in rule 1: IF (A1 is small) AND ? AND (Aj-1 is small) AND (Aj+1 is medium) AND ? AND (Ak is large) THEN (Aj is large) rule 1 where the set of terms between IF and THEN is the left side of fuzzy association rule and the term after THEN is the right side of the rule, and the clauses of the terms are words of attributes defined by fuzzy sets. Each fuzzy association rule has its support and credibility defined as below.

Definition 1: The joint probability pr = Pr(A1 is small ???

Aj-1 is small ? Aj is large ? Aj+1 is medium ??? Ak is large) is the support of the fuzzy association rule in rule 1.

The support of a fuzzy association rule represents the frequency of occurrence of the particular combination of attribute values in the fuzzy association rule in the data set. If the right side of the rule contains more than one attribute, pr will be the joint probability of all attributes except for those attributes appearing the right side using definition 5?

Let p = Pr(A1 is small ? ? ? Aj-1 is small ? Aj+1 is medium ? ? ? Ak is large) =                                                         , then ? ? kA...Pr( ?

largeisA j large)issmallisA Definition 2: The value of p p r  is the credibility (confidence) of the fuzzy association rule in rule 1.

The credibility of a fuzzy association rule represents how often it is likely to be true.

Only the fuzzy association rule whose credibility is greater than or equal to the credibility threshold H are chosen. Those rules are likely to be true, if H is reasonably high. The credibility threshold H is inputted by user.

D. Unification and consistency of fuzzy association rules If fuzzy association rules with the same fuzzy sets on the right side of rules are satisfied with one of attributes on the left side of rules containing all fuzzy sets and the other attributes containing the same fuzzy set, those fuzzy association rules can be combined into one rule.

For example, assuming 3 attributes X, Y, Z with 3 fuzzy sets in each, 3 fuzzy association rules in Fig. 3 are therefore equivalent to a single fuzzy association rule: IF (Y is small) THEN (Z is large) IF (X is small) (Y is small) THEN (Z is large) IF (X is medium) (Y is small) THEN (Z is large) IF (X is large) (Y is small) THEN (Z is large) IF (Y is small) THEN (Z is large) Fig. 3: Unification of fuzzy association rules We generally keep the single unified fuzzy association rule,  instead of 3 separated rules.

Our experiments are based on consistent fuzzy association rules whose fuzzy set of related attribute on the right side should not be conflict with one another if they have the same left side.

For example, fuzzy association rules rule 2 and rule 3 are inconsistent, because rule 2 includes IF (X is large) (Y is small) THEN (Z is small) which is conflict with rule 3.

IF (X is large) THEN (Z is small) rule 2 IF (X is large) (Y is small) THEN (Z is medium) rule 3 If a high enough credibility threshold, such as 0.9, is used during the procedure of discovering fuzzy association rules, the set of rules will be consistent. The demonstration is shown in section III.E.

REDUCED DATABASE TABLE AND EFFECTIVE    REDUCED DATABASE TABLE AND EFFECTIVE REDUCED DATABASE ALGORITHM III.

A.

B.

Why we need reduced database table &amp; effective reduced database algorithm Soft computing, unlike conventional (hard) computing, can represent and reason with vague and uncertain information in the real world, which provides good performance in control, modelling, and decision making in complex systems.

However, these algorithms face two main problems: space and time complexity, and transparent knowledge representation.

For example, to build the fuzzy model of a commercial database with 100 attributes, assuming we can take 3 possible values each attribute which could be fuzzy sets or linguistic sets, there will be 3100 | 5.15u1047 possible combinations.

Supposing we use 1 byte to store 1 combination, it requires 5u1038 gigabyte space to store these combinations, and would take about 7.5u1030 years to read these combinations using 2 GHz CPU. This is impossible for any present personal computer.

On the other hand, some fuzzy models using a black box learning approach, such as fuzzy neural network, might give better accuracy, but users have no idea why the system generates such a result. In most practical cases, users would like the system to be so transparent for the generalizing and reasoning that they are able to explain the results to their customers or managers, even though the accuracy might be slightly worse than using black box models.

Reduced database table (RDBT) is a knowledge based transparent fuzzy model to solve these problems. Effective reduced database algorithm (ERDB) is an efficient algorithm to form reduced database table with less space and time complexity.  In this paper, we use this model to discover fuzzy association rules, which drops those rows in the reduced database table whose joint probabilities are less than the threshold G without losing main information.

Reduced database table (RDBT) The reduced database table (RDBT) [3] discovered from original database is a joint probability table over ?words?. It includes two parts. The part on the left side is a table which has a column for each data attribute and the rows containing the relevant combinations of attribute values. Those values of attributes can be words defined by fuzzy sets, linguistic sets, discrete sets, and so on. The other is the joint probability distribution, and each one is associated with a particular combination in each row on its left side.

For only one line of original database with k attributes and triangle fuzzy partition {f i} of kth attribute, as input x = g the  joint probability Pr joint = Pr (attri_1 ? attri_2 ? ?? attri_k) in one row of reduced database table is: Pr joint = ?

k kki g )(F , where F k i (g k ) = Pr (f k i | g k )        (1) For example, assuming we already know Pr (f k i | g k ) shown on the right of Fig. 4, the joint probability Prjoint-2 associated with fuzzy sets combination {small, small, medium} in the second row of reduced database table on the left of Fig. 4 is calculated as Pr joint-2 = Pr (Asmall ? Bsmall ? Cmedium) = Pr (small | g A) u Pr (small | g B) u Pr (medium | g C) = 0.6 u 0.3 u 0.1 = 0.018 R ed uced  D atabase Tab le A small 0 .162 0.018 B small medium    medium large ... .. .

la rge ...

0large small small C sm all medium large large small small small small small small medium medium medium 0.378 0.042 VXP ? ??? P r (small | g ) = 0.6 P r (med ium | g ) = 0.4 P r (larg e | g ) = 0 P r (small | g ) = 0.3 P r (med ium | g ) = 0.7 P r (larg e | g ) = 0 P r (small | g ) = 0 P r (med ium | g ) = 0.1 P r (larg e | g ) = 0.9 attribut  A : attribut  B  : attribut  C  : Joint P roba bility Dis t ibution A A A B  B B C C C fuzzy sets combinatio ns attrib utes Fig. 4: The example of reduced database table (RDBT) For m lines of original database in general cases, the joint probability of reduced database table is equally likely: Pr joint = Pr (attri_1 ? attri_2 ? ? ? attri_k) = m g m mk k ki? ? ))(( F (2) The joint probability distribution of each reduced database table with full rows should add up to 1.

C. Effective reduced database algorithm (ERDB) Compared with traditional models, fuzzy models generally have more complexity, because of the number of fuzzy sets required in the model. We therefore develop an algorithm to    required in the model. We therefore develop an algorithm to form the reduced database table effectively and hence to discover fuzzy association rules, which uses the idea of dropping those entries (rows) in reduced database table whose joint probability is less than a reasonably threshold G. It is namely effective reduced database algorithm [3].

Definition 3: Any entry with Prjoint &lt; G in the reduced database table is eliminated by the effective reduced database algorithm (ERDB), where G is a reasonably threshold. The threshold G is inputted by user.

The joint probability threshold G could be either a certain value for each reduced database table, or the maximum probability of each reduced database table with a certain percentage. We call the former threshold probability threshold, and the latter maximum probability threshold.

Because the maximum probability threshold is adjusted with joint probability of the table, it has no problem with the curse of dimensionality for large number of attributes.

The effective reduced database algorithm (ERDB) [3] is illustrated below: EFFECTIVE REDUCED DATABASE ALGORITHM (ERDB) Calculate all one attribute only reduced database tables, Choose that one with least rows, Do loop until all attributes are extended 1) Form all new reduced database tables extended one more attribute for attributes not already chosen, 2) Drop any entry with Prjoint &lt; G in all new reduced database tables, 3) Choose one with least rows, End do loop When a reduced database table extends a new attribute, the rows of attribute values in the new reduced database table formed will initially be all combinations of the rows of attribute values in the previous reduced database table plus the extended attribute?s one attribute only reduced database table.

Then we calculate the joint probability distribution of the new table. Finally forming the new reduced database table will be fully completed, after dropping the rows whose joint probabilities are less than the threshold G. The example of  effective reduced database algorithm (ERDB) in Fig. 5 shows the procedure of extending all one attribute only reduced database tables to form the final reduced database table shown in Fig. 4.

medium Joint Probability Distribution small large B 0.3 0.7 medium Joint Probability Distribution small large C 0.1 0.9 medium Joint Probability Distribution small large A 0.6    0.6 0.4 medium Joint Probability Distribution small A ...

medium small B medium small medium small ...

Joint Probability Distribution small B ...

mediumsmall C ... ...

A Fig. 5: The example of effective reduced database algorithm Notice: the joint probability distribution of each new reduced database table is not simply multiplied with probabilities in reduced database tables formed in previous loop, but calculated from the original database every time.

If there are k attributes and equally i fuzzy sets of each attribute, entries (rows) of reduced database table will be i k , such as 33 = 27 entries in Fig. 4. However, those entries with small joint probability are removed to help to reduce noisy rules. The removed entries will not be extended to form the next new reduced database table with one more attribute.

D.

E.

Less space and time complexity, transparency, knowledge based Effective reduced database algorithm provides the advantage of forming reduced database table with less space and time complexity.

As what we discussed in section III.A and III.C, there would be i k possible entries in reduced database table in total, which will be huge number in practice. However, the effective reduced database algorithm can significantly reduce space and time complexity without losing too much information. For example, in them first example of supermarket basket analysis application in section IV, because there are 11 attributes in database and 3 fuzzy sets in each attribute, the possible combinations in total would be 311 = 177,147. It is a huge hypothesis space to search the right set of fuzzy association rules. However, there are only 9 entries left to generate fuzzy association rules by using the effective reduced database algorithm.

The reduced database table formed by using the effective reduced database algorithm is transparent for users. Each combination of words on its left side represent a rule discovered from original database, and the joint probability distribution on its right side will tell users how often the related combination of words in the same row occurs in the original database. And we can also work out more measurement of those rules according to the joint probability distribution, such as credibility of fuzzy association rules.

Those words associated with joint probability distribution are also very easy to understand for a human being.

The reduced database table can also be known as a knowledge based table contained the main information of    knowledge based table contained the main information of original database, and it can be further used to discover other fuzzy models in the soft computing and machine learning, such as fuzzy association rules, fuzzy decision tree [9], fuzzy Bayesian net [10], etc.

Fuzzy association rules from reduced database table After we get the final reduced database table by using the effective reduced database algorithm, we need determine attributes to be on the right side of rules as so to form the set of fuzzy association rules, and then drop those rules whose credibility is less than credibility threshold H from the reduced database table.

For example, if we assume the joint probability threshold G is 0.01 and select attribute C as the attribute on the right side of rules, we can respectively form rule 4 from the 2nd row and rule 5 from 3rd row in the reduced database table in Fig. 4: IF (A is small) AND (B is small) THEN (C is medium) rule 4 IF (A is small) AND (B is small) THEN (C is large) rule 5 As the nature of reduced database table, the support of each fuzzy association rule is the joint probability associated with the row to form the rule on the right side of reduced database table. Therefore, supportrule 4 = Pr joint-2 = 0.018 and supportrule 5 = Pr joint-3 = 0.162. According to the Definition 2, p = Pr joint-1 + Pr joint-2 + Pr joint-3 = 0 + 0.018 + 0.162 = 0.18, therefore credibilityrule 4 = Pr joint-2 y p = 0.1 and credibilityrule 5 = Pr joint-3 y p = 0.9. If the credibility threshold H is 0.9, we only keep rule 5 in the end. This procedure is also applied to the right side of rules containing more than one attribute.

F. A simple experiment to prove fuzzy association rules from reduced database table In this simple experiment, we create a 3-attribute 289- example original dataset (attributes X, Y ? [0, 8]) in which values of X, Y attributes are symmetrically selected with the interval 0.5 and values of Z attribute are inferred using consistent fuzzy association rules in Fig. 6, where every attributes use 3 equal space fuzzy sets defined in definition 2: IF (X is small) THEN (Z is small) IF (Y is large) THEN (Z is small) IF (NOT (X is small)) AND (Y is small) THEN (Z is large) IF (NOT (X is small)) AND (Y is medium) THEN (Z is medium) Fig. 6: The original set of fuzzy association rules Then, we discover another set of fuzzy association rules from the original dataset formed previously, by using the effective reduced database algorithm with probability threshold G = 0.035 and credibility threshold H = 0.5. After unifying the set of rules we discovered, we get the exactly same set of fuzzy association rules as the original set of rules in Fig. 6.

IV.

A.

SUPERMARKET BASKET ANALYSIS APPLICATION For supermarket basket analysis, association rules can be used to adjust store layouts, cross-selling, promotions, catalogue design and to identify customer segments based on buying patterns [11]. However, traditional rules are only restricted in the interested relations of certain groups of items consistently purchased together, so that the original database has to only use discrete attributes. This brings the big complexity problem, while analysing the relationship of hundreds of items or more.

Fuzzy association rules can deal with continuous attributes in database. We therefore develop a new approach associated with continuous attributes for supermarket basket analysis, in addition to using discrete attributes as well. For instance, in the first example of supermarket basket example database, we discover the set of fuzzy association rules to describe customer?s favourite by using the relations among spending or shopping frequency and nutrient contents. It therefore reduces the number of features or attributes to be analysed. In the second example, we discover the rules combined both discrete and continuous attributes as so to cover more important    and continuous attributes as so to cover more important features for analysis, compared with traditional association rules.

The example database and data set The supermarket basket database contains three tables illustrated in Fig. 7.

a) Customer table contains the personal details of customers, such as name, sex, age, postcode, etc.

b) Transaction table contains supermarket basket scanner panel data, which is randomly generated by data generator according to several certain shopping behaviours of customers. It includes UPC (universal product code), the number of items purchased, total price, etc.

c) Product table contains the commercial and nutritional information published in the website [12], such as energy, fat content, sugar content of each product in per 100 gram.

Fig. 7: Supermarket basket database example B.

1) The parameters and examples To mining fuzzy association rules using the effective reduced database algorithm from prepared data set, we set up maximum probability threshold G as 0.15, which drops those entries whose joint probability is less than 15% of the  maximum probability of each reduced database table, and credibility threshold H as 0.9.

Nutrient contents not items We use SQL to select an customer shopping history to form 2 data sets, which contains his total spending or the amount of items purchased in each day separately and 10 kinds of nutrient contents of products purchased in that shopping in total, to discover fuzzy association rules.

In the first data set, we discover 9 fuzzy association rules, and one of them is shown below: IF (sum_of_energy is high) AND (sum_of_protein is high) AND (sum_of_carbohydrate is high) AND (sum_of_vitamins is medium) AND (sum_of_fat is high) AND (sum_of_sodium is high) AND (sum_of_sugar is medium) AND (sum_of_fibre is high) AND (sum_of_starch is high) AND (sum_of_iron is medium) THEN (total_spending is high) In the second data set, we discover 8 fuzzy association rules, and one of them is shown below: IF (sum_of_energy is high) AND (sum_of_protein is high) AND (sum_of_carbohydrate is high) AND (sum_of_vitamins is medium) AND (sum_of_fat is high) AND (sum_of_sodium is high) AND (sum_of_sugar is medium) AND (sum_of_fibre is medium) AND (sum_of_starch is high) AND (sum_of_iron is medium) THEN (amount_of_items_purchased is big) We can use this method to analyse the favourite poroduct or behaviour of a certain customer or a certain group of customers. The new approach of using nutrient contents instead of items in the relations gives much less complexity of association rules, especially to analyse hundreds or thousands of items in the supermarket.

2) V.

Both discrete and continuous attributes We give another simple example below that includes both discrete and continuous attributes in the fuzzy association rule, which is discovered from the data set containing customer?s sex, age and the sum of sugar content of products he/she purchased each time.

IF (sex is male) AND (age is old) THEN (sum_of_sugar is medium) As it can be seen, if we use crisp sets as special fuzzy sets in fuzzy association rules, we still have the traditional association rules.

Combining discrete attributes such as customer details (sex, postcode, city, etc), items and catalogue with continuous attributes such as nutrient contents, spending, price, stock, cost, and customer?s age in the association rules is very helpful in    and customer?s age in the association rules is very helpful in various kinds of business analysis. It provides alternative new approach to find some good relations for analyser.

CONCLUSION AND FUTURE WORK Compared with traditional association rules, fuzzy association rules provide good linguistic explanation, and can deal with both discrete attributes and continuous attributes. It provides an alternative new approach in the applications of association rules, which not only can be used to reduce the complexity of association rules, but also to cover more important attributes in the rules.

In order to solve complexity problem of mining fuzzy association rules, we discover those rules by using the effective reduced database algorithm (ERDB).

The reduced database table (RDBT) and effective reduced database algorithm are good methods to build a transparent and knowledge based fuzzy model with less space and time complexity. Afterwards it can be used to discover various kinds of fuzzy models, such as fuzzy association rules, fuzzy  decision tree, fuzzy Bayesian net, etc.

In the end, we only keep those fuzzy association rules whose credibility is not less than credibility threshold H, which are discovered from the final reduced database table.

It is helpful to either use feature selection before running the ERDB algorithm or combine it with the ERDB algorithm, which can drop redundant and unimportant attributes to reduce the dimension of the final reduced database table. This improvement is our future work.

