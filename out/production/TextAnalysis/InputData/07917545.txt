On the Applicability of Clinical Observation Tools for Human Activity Annotation

Abstract?The annotation of human activity is a crucial prereq- uisite for applying methods of supervised machine learning. It is typically either obtained by live annotation by the participant or by video log analysis afterwards. Both methods, however, suffer from disadvantages when applied in dementia related nursing homes. On the one hand, people suffering from dementia are not able to produce such annotation and on the other hand, video observation requires high technical effort. The research domain of quality of care addresses these issues by providing observation tools that allow the simultaneous live observation of up to eight participants ? dementia care mapping (DCM). We developed an annotation scheme based on the popular clinical observation tool DCM to obtain annotation about challenging behaviours. In this paper, we report our experiences with this approach and discuss the applicability of clinical observation tools in the domain of automatic human activity assessment.



I. INTRODUCTION  Human activity annotation is a crucial prerequisite for applying methods of supervised machine learning. Typically, classifiers such as decision trees or support vector machines are trained to recognise the annotated activity class from sensory observation. Furthermore, the annotation is applied in order to assess the performance of the recognition in terms of accuracy. Thus, high annotation quality is one key requirement for human behaviour recognition.

In general, two different ways exist to obtain an annotation sequence describing the activities performed by the human protagonists: offline and live annotation [14]. Firstly, a video log that documents the executed activity sequence is recorded during data collection. This video log is later analysed by observers in order to produce an annotation sequence. An advantage of this approach is that it allows observers to watch scenes of interest repeatedly and skip irrelevant scenes during analysis. Moreover, this approach allows to increase the gran- ularity of the annotation scheme. While this is the dominant method in human activity recognition (applied for instance in [6], [10]), it has several disadvantages. It requires a written consent of the human participants, has high technical effort for the video installation, and needs an explicit annotation phase after data collection, which typically last longer than data collection itself, to just name three of them. Advantages of offline annotation include for instance a virtually unrestricted observer training phase. Tools such as the ELAN video anno- tation tool [18] are employed during offline annotation.

The second approach is to observe and annotate the be- haviour of the participants during data collection. This live annotation approach requires the participants to describe their behaviour by themselves, as for instance done in [17], [13], and [2]. To do this, participants typically employ additional tools such as voice recording [17], mobile computers [13], or written protocols [2]. Also the use of external observers to produce live annotation is possible. This, however, often requires multiple participants to be observed by one observer, which might lead to inaccuracies.

With respect to annotation quality, the training of the observers is known as one important factor [3]. While offline annotation approaches allow the observers to be trained by use of the video log that was recorded during the study, live annotation approaches require observers to be trained beforehand, which typically raises additional difficulties like insufficient amounts of video material. Consequently, activity recognition often employs offline annotation.

In the research project insideDEM, we consider the recog- nition of challenging behaviours of people suffering from dementia in nursing homes [7] by use of sensory observation.

Challenging behaviours include for instance verbal or physical aggressive behaviour against the caring person or others. In general, challenging behaviours can be thought of as a form of agitated behaviour where the caring person is challenged.

In order to recognise such behaviours by use of machine learning classifiers, a training data set has to be recorded. As already discussed above, the use of supervised learning also requires the data set to be annotated. To this end, we developed an annotation scheme that focusses on certain challenging behaviours. The annotation scheme and procedure are based on dementia care mapping (DCM) [9], whereas the behaviour categories are chosen by an analysis of the categories in DCM, the Cohen-Mansfield Agitation Index (CMAI) [4] and the Neuropsychiatric Inventory (NPI) [5]. DCM is known as the standard observation tool to assess the quality of care for people with dementia in nursing homes. As typical for DCM, the annotation sequence is created by live annotation. To assess the quality of our annotation in terms of interrater reliability, overlapping annotations were created.

The contribution of this work is twofold. We first introduce a novel annotation scheme which focusses on challenging be- haviour of people with dementia. We then analyse the quality  First International Workshop on Annotation of useR Data for UbiquitOUs Systems'17     of the annotation that is produced during live annotation and finally discuss the general applicability of clinical observation tools for human behaviour recognition.

The remainder of this paper is structured as follows: We first introduce the annotation scheme for challenging behaviour in Section II. Afterwards, we describe the general setting and the data collection process in Section III. In Section IV we analyse the quality of the annotation that was produced during data collection and finally draw conclusions about the applicability of clinical observation tools for human behaviour recognition in Section VI.



II. ANNOTATION SCHEME  Objective of our data collection was to train classifiers in a supervised way to recognise challenging behaviour from sen- sory observation. Moreover, in order to evaluate the classifiers, their recognition performance has to be assessed. For this reason, we developed an annotation scheme which focusses on challenging behaviours by analysis of the literature. The annotation scheme was developed for use in live annotation.

Live annotation, also known as direct observation, is a typical approach to assess the behaviour of persons in the medical domain. An overview of clinical assessment tools is provided by [19]. They analysed different assessment methods with respect to their applicability for annotating challenging behaviour. A well known clinical observation tool to assess parameters of the quality of care for people with dementia is DCM [9]. It is shown to be suited for the application of as- sessing behavioural problems and information about activities of daily living [19].

DCM allows an observation of up to eight subjects for up to six hours based on a five minute intervals. For each five minute interval, the observer records exactly one behaviour category code (BCC) and a well/ill being (WIB) score. 24 different BCCs are offered in DCM, for instance  ? ?cool? (C) ? being socially uninvolved, withdrawn, ? ?kum and go? (K) ? independent walking, standing or  wheelchair moving, or ? ?withstanding? (W) ? repetitive self stimulation.

[15] Each of the codes is part of one of two groups describing the potential of well-being: (1.) categories with high potential for well being and (2.) categories with low potential for well being. The WIB score consists of three codes (-1, -3, and -5) for ill-being and three codes (+1, +3, and +5) for well-being and represents a ?judgement about the affective state? [15] of the subject under observation. DCM is usually employed to assess the quality and the development of the care. The literature reports an interrater agreement of 62% and a kappa value of .54 based on different studies [15].

Since the objective of our study was not to assess the quality of care, but the sensor-based recognition of challenging behaviour, we had to adjust the behaviour codes to the actual aim of our study. To this end, we conducted a review of literature relevant to challenging behaviour [16], [1], [8].

Moreover, as CMAI and NPI are typically used to assess  the behaviour of the target group, both were included in the analysis.

The CMAI allows to assess the severity of behavioural symptoms of people with dementia with respect to agitation.

For this purpose, 29 symptoms from four general categories are assessed: ? verbally aggressive behaviour, ? verbally non- aggressive behaviour, ? physically aggressive behaviour, and ? physically non-aggressive behaviour. These symptoms in- clude for instance pacing and aimless wandering and per- forming repetitious mannerisms. The CMAI is assessed by conducting an interview with the caring staff about the severity of the symptoms over the last two weeks. To this end, an ordinal 7-point scale, which ranges from 0 ? no occurrence to 6 ? several occurrences per hour. Typically, a summary score is created by counting the number of categories with values of 2 and above.

Similarly, the NPI assesses the occurrence of typical neu- ropsychiatric disturbances in dementia, such as apathy or anxiety. Frequency and severity of each is assessed on a 4- point and 3-point ordinal scale, respectively. The frequency ranges from 1 ? less than once a week to 4 ? once or more a day, whereas the severity is estimated with 1 ? mild, 2 ? moderate, and 3 ? severe. Additionally, the level of the caregiver?s distress is assessed for each class. A summary score is calculated by summing up the class wise products of frequency and severity. As for the CMAI, a higher score signals more frequent occurrence of certain behaviours.

Result of the analysis of the literature was an overview of different behaviours that are known to be challenging including the frequencies in similar target groups. Based on this overview, we analysed the behaviours that actually occur in the targeted group of subjects by interviewing the caring staff. The following six classes of challenging behaviour were identified: 1) apathy, 2) general restlessness, 3) pacing, 4) mannerisms, 5) aggressive behaviour, and 6) trying to get to a different place. An overview of these classes is provided in Table I. Since some classes directly correspond to BCCs from DCM, the table also contains the corresponding class, if exists.

Moreover, information, whether a corresponding class exists in the respective assessment tools, is provided. Our annotation scheme uses a similar observation procedure as DCM. But due to the coarse grained observation interval, our mapping allows to code zero or more behaviour codes. This approach is similar to the behaviour assessment in [12]. The rationale here is that in difference to DCM, which aims at providing an overview of the subject?s behaviour, we aim at collecting training samples to apply methods of supervised learning. Table II exemplifies the developed annotation scheme.



III. DATA COLLECTION  In the following, we describe the data collection study, within which the behaviour annotation was obtained.

A. Description of the Study  In order to recognise challenging behaviours of people with dementia, we conducted a data collection. To this end, we  First International Workshop on Annotation of useR Data for UbiquitOUs Systems'17    TABLE I OVERVIEW OF THE ANNOTATION SCHEME. THE TABLE CONTAINS THE ABBREVIATION AND THE MEANING OF EACH BEHAVIOUR CODE AND THE  CORRESPONDING DCM BCC. ?= THE ANNOTATION CATEGORY SUMMARISES SEVERAL DIFFERENT SUB-SCORES RATHER THAN CORRESPONDING TO A SPECIFIC SUB-SCORE.

Abbreviation Meaning BCC (DCM) CMAI NPI  A Apathy C X G General restlessness X M Mannerisms W X P Pacing K X  Ag Aggressive behaviour X? X?  O trying to get to a different place X Q not visible Q  none of the above  TABLE II EXAMPLE ANNOTATION. FOR 5 MIN INTERVAL EITHER NO BEHAVIOUR OR  THE OBSERVED BEHAVIOURS ARE ANNOTATED. EACH ANNOTATION THEREBY CONSISTS OF THE BEHAVIOUR CODE AND THE CORRESPONDING  WELL-BEING CODE.

Time Patient Observer Annotation  9:00 X001 A001 A+1,M+1 9:05 X001 A001 M+1 9:10 X001 A001 M+1 9:15 X001 A001 ?  instrumented persons (N=17) in two nursing homes (N1=9, N2=8) with sensors. Each participant was instrumented with two sensors (one at the wrist and one at the lower leg) during the day and one sensor (at the lower leg) during the night. Each sensor recorded different modalities including accelerometer, gyroscope, temperature and barometric pressure. In all, we collected data for 52 days, 23 and 29 days, respectively. The use of the sensor data for training the supervised classifiers is outside the scope of this work.

B. Annotation Procedure  To assess the behaviour with respect to the defined be- haviour classes, we employed our annotation scheme. Be- haviour observation usually took place from 9am to 1pm and 3pm to 6pm. Overall, annotation was done by 11 different observers. The observers were either trained DCM observers, nursing staff or psychologists. All behaviour classes were ex- plained to the observers beforehand. For this purpose available video material of the different behaviours was used. As all observers were strongly related to the domain of dementia, an explicit training phase in the nursing home was skipped. In addition to our annotation scheme, we employed DCM in the first part of the study.

Furthermore, in the second part of the study, a video log of the subjects was created. For this purpose, four cameras were installed to monitor the area of interest.

C. Annotation  An annotation item describes one behaviour code that was reported by one observer for one subject in a 5 minute interval.

Consequently, if one observer observes 8 subjects, the number  of annotation items is at least 8 per 5 minute interval, one for each subject. During the defined annotation period, the observer(s) were placed in the common space, where the residents usually are during the day. Whenever a resident left the observable area, the observer either annotated the behaviour class ?Q? ? not visible or follows the resident. In this case, if the observer was not able to see the other residents, their behaviour was annotated with class ?Q?. The decision, whether to follow the resident or not was up to the observer.

To calculate the interrater reliability for our annotation scheme, a certain amount of overlap, where two observers annotate the behaviour of the same person, was created.

The video log was employed to create a more fine grained annotation. For this purpose, the result of live annotation was scanned for occurrences of the behaviour code ?M? ? performing mannerisms. For each 5 min interval, which contained an annotation item, the interval was extended to 15 min. The video for this extended interval was then analysed, in order to create a fine grained offline annotation based on 1 ms.



IV. RESULTS  Here, we report quantitative and qualitative results of our study with respect to annotation.

A. Amount of Annotation  The overall number of annotation items is 52,321, 28,157 for the first and 24,164 for the second part of the study. From these, 5,012 items were created by use of DCM and 47,309 based on our annotation scheme. An overview of the overall distribution of behaviour classes of our annotation scheme is provided in Figure 1. In all, 41,689 5-minute intervals have been observed, containing 4,971 for DCM and 41,555 with our annotation scheme. Note, that DCM and our annotation scheme were used simultaneously. The DCM annotation was done in the first part of the study only, while the annotation of challenging behaviour was performed in both parts. For the first part of the study, behaviour annotation was done for 19,527 5-minute intervals, for the second for 20,028 intervals.

For DCM, the degree of overlap was .8% (41 out of 4,971). For our annotation scheme, 2,178 5-minute intervals of the second  First International Workshop on Annotation of useR Data for UbiquitOUs Systems'17    Fig. 1. Frequencies of the different categories per study.

part of the study were coded by two observers in parallel, resulting in an overlap of 11.15% (2,178 of 19,527).

Our annotation scheme allows the annotation of multiple behaviours per 5-minute interval. Most of the time (24,149) exactly one behaviour code was annotated. In 16,403 intervals, no behaviour of interest could be observed. In 3,181 intervals, two or more behaviours of interest could be observed.

B. Reliability of Live Annotation  For DCM observations we could observe an agreement of 46% and a kappa value of .28. The main reason for this bad results are a confusion with class ?Q?, which means that the observer was not able to see the subject. By eliminating all intervals, where at least one observer reported the BCC ?Q? the agreement increased to 59% and the kappa to .38.

Furthermore, the data was aggregated creating the histogram over behaviour codes. With respect to the histogram of the DCM annotation, a significant difference was found (Fisher?s exact test, p=.001). Note that the comparison is based on a small set of samples (2?41).

To determine the annotation quality of our annotation scheme, the simple application of agreement and Cohen?s kappa was not possible, since one observation interval can contain multiple behaviour classes. For this reason, we applied the method of [11] to obtain a kappa value and adapted the agreement determination in two different ways. Firstly, we determined the minimal agreement of the annotation, by considering the annotated behaviour codes as equal if at least one class is reported by both observers. The minimal agreement of our annotation was 32%. In the second method, we determined the maximal agreement ? annotated behaviour was equal, if all classes were equal. The maximal agreement was 31%. The kappa value for multiple categories was found to be .45. By resorting to the binary decision, whether one of the behaviours of interest was observed or not, an agreement of 61.5% and a kappa value of .23 were found. Table III gives on overview of the kappa values for multiple behaviours per subject.

It can be seen that the kappa value strongly depends on the subject under observation. Considering the aggregated data,  the difference was not significant (?249 = 56, p=.23).

Similar to the analysis in [12] the relation between the  relative amount of occurrence of an behaviour code was examined subject-wise. For this purpose Spearman?s ? was applied. A large correlation was found for the behaviour code ?P? ? pacing and the corresponding CMAI sub-score (? = .92, S = 61.37, p < .001). Likewise, the correlation between DCM behaviour Code ?K? was large (? = .9, S = 11.8, p = .009). The correlation between annotation class ?O? and the corresponding CMAI sub-score was found to be large (? = .64, S = 293.45, p = .01). In contrast, the correlation between the behaviour code and NPI sub-score for apathy was only moderate (? = .39, S = 494.41, p = .12). This was also true for the behaviour code and CMAI sub-score of performing mannerisms (? = .36, S = 87.53, p = .48). Note that these results are based on a rather small set of residents (N=17).

C. Reliability of Offline Annotation  In addition to the live annotation, we recorded videos of the subjects during the study to apply offline annotation afterwards. During offline annotation, we concentrated on the behaviour class ?M?, only. To assess the quality of the offline annotation, three 30 minute intervals were selected. The intervals were selected based on the existence of the selected behaviour class in the original annotation. For each time, each observer reported, whether the selected behaviour could be observed or not. Analysis took place on base of milliseconds rather than 5 minute intervals. In total, the behaviour of 6 subjects was annotated. Thereby a mean agreement of 72% (?16) and a mean kappa of .56 (?.12) was determined. An interesting observation during offline observation was that in about 30%1 of the annotated intervals the person under observation was not visible due to obstacles or the resident being outside the observed area. However, from the remaining 70% about 90%1 of the intervals of the live annotation, the annotated behaviour was actually observable in the video log.

1The value is based a subjective estimate of the offline observer and not yet on a quantitative analysis.

First International Workshop on Annotation of useR Data for UbiquitOUs Systems'17    TABLE III KAPPA VALUES AND NUMBER OF ANNOTATION ITEMS PER SUBJECT. VALUES WERE DETERMINED WITH [11]. THE KAPPA FOR ALL IS DETERMINED BY  WEIGHTED AVERAGE OF INDIVIDUAL KAPPA VALUES.

Subject X001 X004 X005 X007 X008 X009 X015 X016 X017 all  # items 152 261 253 85 328 291 255 266 287 2178 Cohen?s ? .67 .41 .48 .89 .45 .42 .35 .42 .35 .45

V. DISCUSSION  The analysis of the interrater reliability in the previous section revealed low agreement of the observers with respect to the behaviour. This is true for DCM as well as for our annotation scheme. With respect to DCM, this disagrees with the reported agreement in the literature. However, the degree of overlap was to small to conclude general statements.

Regarding our annotation scheme for challenging behaviour, the results of the live annotation indicate a low quality of the annotation sequence. Thus, it is very likely that the annotation sequence can not directly be considered for supervised train- ing. Considering the aggregated annotation of our annotation scheme, only a small difference could be found. This justifies the annotation scheme to assess the behaviour of people with dementia over larger observation periods but prevents the ap- plication as labels for supervised machine learning. Additional evidence is provided by the medium to large correlations of the standard instruments of behaviour assessments for people with dementia, CMAI and NPI, to the behaviour annotation. Both provide an aggregated assessment of the persons behaviour within periods of several weeks.

Despite the low quality, the live annotation can be used as a starting point to increase annotation quality by use of offline video annotation. The offline video annotation was found to produce annotation sequences of better quality. One reason for the increased reliability might be the absence of time constraints, which prevent observers from concentrating on certain subjects. This may also be achievable by decreasing the number of subjects per observer. This, however, might result in a change of behaviours due to an increased number of observers. Additionally, it was observed that the false positive rate of live annotation in comparison with offline annotation was low: If at least one observer identifies a certain behaviour, the behaviour probably occurred.

One potential reason for the low interrater reliability of the live annotation is that it is not easy to recognise the selected challenging behaviours. In particular, the specific characteristics of single behaviours differ between the subjects.

Furthermore, the annotation quality depends on the observer.

While the within subject differences shall be generalised by supervised training, the within observer differences have to be considered during evaluation. This means that the observer should be considered as additional factor of uncertainty.



VI. CONCLUSION  The annotation of human behaviour is a challenging task.

This is especially true for the domain of automatic recognition  of behaviour from sensory observation, as the machine learn- ing methods rely on the quality of the training samples. The installation of a video surveillance solution is not always pos- sible due to privacy concerns. This means that live annotation techniques have to applied. The task becomes even harder, if the subjects under observation are not able to annotate their behaviour by themselves, as in the case of people suffering from dementia. Consequently, the behaviour of them has to be live-annotated by observers. To best of our knowledge, this is the first work that applied observer based live-annotation in order to train machine learning classifiers within nursing homes.

In the medical domain, methods exists that allow the live assessment of behaviour by observers. DCM is a well estab- lished clinical observation tool for the assessment of quality of care. DCM does not target the exact annotation of behaviours, but focusses on the distribution of behaviours in a predefined interval. Thus, it is used to assess changes in the distribution of behaviours and allows conclusions about the quality of care.

In this paper, we introduced an annotation scheme for challenging behaviours of people with dementia. To this end, we adapted the annotation procedure of DCM. We applied both, DCM and our annotation scheme, and found that this procedure is not suited to provide reliable annotation for the purpose of machine learning.

To conclude, our findings suggest that the annotation ob- tained by live annotation in our study does not provide a sufficient level of reliability to serve as reasonable base for machine learning. However, by including the observer as a factor of uncertainty, the annotation items can be used as an indicator for the existence of challenging behaviour. Further- more, the identification of challenging behaviour by observers seems to be a challenging task. This is also confirmed by the analysis of the video based offline annotation.

Further work includes the application of methods of super- vised learning on the obtained annotation sequence. Addition- ally, the application of unsupervised clustering might reveal clusters which can be used to identify further occurrences of specific behaviours.

