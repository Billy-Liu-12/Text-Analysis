Mining from Quantitative Data with Linguistic  Minimum Supports and Confidences

Abstract - Most conventional data-mining algorithms identify the relationships among transactions using binary values and set the minimum supports and minimum confidences at numerical values. This paper thus attempts to propose a new mining approach for extracting linguistic weighted association rules from quantitative transactions, when the parameters needed in the mining process are given in linguistic terms. Items are also evaluated by managers as linguistic terms to reflect their importance, which are then transformed as fuzzy sets of weights. Fuzzy operations are then used to find weighted luny large itemsets and fuzzy association rules. An example is given to clearly illustrate the proposed approach.



I. INTRODUCTION  Among the mining techniques, it is most commonly seen in applications to induce association rules from transaction data. Most previous studies have only shown how binary valued transaction data may be handled. Transactions with quantitative values are, however, commonly seen in real-world applications. Srikant and Agrawal proposed a method for mining association rules from transactions with quantitative and categorical attributes [30]. Their proposed method f m t  determined the number of partitions for each quantitative attribute, and then mapped all possible values of each attribute into a set of consecutive integers.

Recently, the fuzzy set theory has been used more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning [36][37]. The theory has been applied in fields such as manufachlring, engineering, diagnosis, and economics, among others [17][23][25][36]. Several fuzzy learning algorithms for inducing rules from given sets of data have been designed and used to good effect with specific domains [5][7][13][16] [l8]-[21][29][3 1][32]. Strategies based on decision trees were proposed in [9][11][12][27]-[29][33][34], and based on version spaces were proposed in [31]. Fuzzy mining approaches were proposed in [81[221[241[351.

Besides, most conventional data-mining algorithms set the minimum supports and minimum confidences at numerical values. Linguistic minimum support and minimum confidence values are, however, more natural and  understandable for human beings. In this paper, we thus extend our previous fuzzy mining algorithm [22] for quantitative transactions to the mining problems with linguistic minimum support and minimum confidence values. Also, items may have different importance, which is evaluated by managers or experts as linguistic terms. A novel mining algorithm is then proposed to fmd weighted linguistic association rules from quantitative transaction data.

11. REVIEW OF MINING ASSOCIATION RULES  The goal of data miniig is to discover important associations among items such that the presence of some items in a transaction will imply the presence of some other items. To achieve this purpose, Agrawal and his co-workers proposed several mining algorithms based on the concept of large itemsets to find association N k S  in transaction data [ I]-[4]. They divided the mining process into two phases. In the fust phase, candidate itemsets were generated and counted by scanning the transaction data. If the number of an itemset appearing in the transactions was larger than a pre-defmed threshold value (called minimum support), the itemset was considered a large itemset. Itemsets containing only one item were processed fKst. Large itemsets containing only single items were then combined to form candidate itemsets containing two items. This process was repeated until all large itemsets had been found. In the second phase, association rules were induced from the large itemsets found in the first phase. All possible association combinations for each large itemset were formed, and those with calculated confidence values larger than a predefmed threshold (called minimum confidence) were output as association rules.

Srikant and Agrawal then proposed a mining method [30] to handle quantitative transactions by partitioning the possible values of each attribute. Hong et al. proposed a fuzzy mining algorithm to mine fuzzy rules from quantitative data [22]. They transformed each quantitative item into a fuzzy set and used fuzzy operations to find fuzzy rules. Cai et al. proposed weighted mining to reflect  0-7803-7280-8/02/$10.00 02002 IEEE 494    different importance to different items [6]. Each item was attached a numerical weight given by users. Weighted supports and weighted confidences were then defined to determine interesting association rules. Yue el a/. then extended their concmts to fuzzv item vectors 1351. The  the transaction data as:  count,, = ZL,, .

i d  h _ .

minimum supports and minimum confidences set in the above methods were numerical. In this paper, these I d parameters are expressed in linguistic terms, which are more natural and understandable for human beings.

STEP 5 :  Find mar-counfj = mar(counl,,), for j = l  to m, where m is the number of items. Let mar-R, he the region with mar-count, for item A,. mar-R, is then used to represent the fuzzy characteristic  111. THE PROPOSED ALGORITHM  In the proposed algorithm, the fuzzy concepts are used to represent item importance, item quantities, minimum supports and minimum confidences. Each attribute uses only the linguistic term with the maximum cardinality in the mining process. The number of items is thus the same as that of the original attributes, making the processing time reduced [ZZ]. Details of the proposed mining algorithm are described below.

The Algorithm: INPUT A set of n quantitative transaction data, a set of m  items with their importance evaluated by d managers, four sets of membership functions respectively for item quantities, item importance, minimum support and minimum confidence, a pre-defmed linguistic minimum support value a, and a pre-defined linguistic minimum confidence value p.

OUTPUT: A set of weighted f u u y  association rules.

STEP 1: Transform each linguistic term of importance for  item A,, I < j < m ,  which is evaluated by the k-th manager into a fuzzy set W,, of weights, I <  k<d, using the given membership functions of item importance.

Calculate the fuzzy average weight E?,- of each item A, by fuzzy addition as:  STEPZ:  I d  d L=I w,-= --I w,,  STEP 3: Transform the quantitative value V, of each item AI in each transaction datum D, (i=l to n, j= l  to m), into a fuzzy Seth represented as:  r,, r,* A.* (- + - + . . . + -) Rj? Rj2 RJh  by using the given membership functions for item quantities, where h is the number o f  regions for AI, Rji is the I-th fuzzy region ofA,, I 5 I < h, andJy, is Vv?s fuzzy membership value in region Rji.

Calculate the count o f  each f u r y  region R,., in STEP 4:  of item A, in later mining processes for saving computational time.

Calculate the fuzzy weighted support wsufi of each item A, as:  STEP 6:  mar- R, x Wp? n  wsupj =  where n is the number of transactions.

Transform the given linguistic minimum support value a into a fuzzy set (denoted minsup) of minimum supports, using the given membership functions for minimum supports.

Calculate the fuzzy weighted set (wminsup) of the given minimum support value as:  wminsup = minsup x (the gravig o f F ) , where  STEP 7:  STEP 8:  IW =I=I U  with U being the total number of membership functions for item importance and I, being the 1-th membership function. I -  thus represents the fuzzy average weight of all possible linguistic terms of importance.

Check whether the weighted support (wsupj) of each item A, is larger than or equal to the fuuy weighted minimum support (wmincup) by fuzzy ranking. Any fuzzy ranking approach can be applied here as long as it can generate a crisp rank. If wsup; is equal to or greater than wminsup, put A, in the set of large I-itemsets L,.

STEP 10: Set r = 1, where r is used to represent the number of items kept in the current large itemsets.

STEP 1 I :  Generate the candidate set C,,, from L, in a way similar to that in the upriori algorithm [4]. That is, the algorithm first joins L, and L, assuming that r-l items in the two itemsets are the same and the other one is different. It then keeps in C,,, the itemsets, which have all their sub-itemsets of r items existing in L,.

STEP 12: Do the following substeps for each newly formed (&I)-itemset s with items (s,, s2, .._, sr+,)  STEP 9:  0-7803-7280-8/02/.$10.00 022002 IEEE 495    in C,, I :  transaction data D, as: (a) Find the weighted fuzzy set (W'J of s in each  TID  where f,,, is the membership value of region s, in 0, and Ws, is the average fuzzy weight fors,.

(b) Calculate the fuzzy weighted support (wsupJ of itemset s as:  ITEMS (A, 4), (B, 4), (E, 9) (B, 3), (C, 51, (F, 3)  (B, 2), (C, 3), (D, 2). (E, 8 ) (A, 7),  (C, 7). (E, 9) (C, 2), (D, 2), (F, 1)  (A, 4), (B, 3), (C, 9, (F, 2)  i=l wsups =-, n  where n is the number of transactions.

(c) Check whether the weighted support (wsupJ of  itemset s is greater than or equal to the fuzzy weighted minimum support (wminsup) by fuzzy ranking. If wsups is greater than or equal to wminsup, p u t s  in the set of large (r+l)-itemsets L + l .

STEP 13: IF L,+/ is null, then do the next step; otherwise, set r = r + 1 and repeat Steps 11 to 13.

STEP 14: Transform the given linguistic minimum confidence value p into a fuzzy set (minconfi of minimum confidences, using the given membership functions for minimum confidences.

STEP 15: Calculate the fuzzy weighted set (wminconfl of the given minimum confidence value as:  wminconf= minconfx (the gravity ofla").

where I"" is the same as that calculated in Step 9.

STEP 16: Construct the association rules from each large weighted q-itemset s with items (s,, s>, ..., sq), q>  2, using the following substeps:  (a) Form all possible association rules as follows: S,A...AS~-~AS~+~A...AS~ + s j , j = l  toq.

(b) Calculate the weighted confidence value wconfR of each possible association rule R as:  " 9  i=l  j=l where count, = c ( M i n f , i )  and  (c) Check whether the weighted confidence wconfR of association rule R is greater than or equal to the fuzzy weighted minimum confidence wminconfby fuzzy ranking. If wconfR is greater than or equal to wminconf; keep rule R in the  interesting rule set.

STEP 17: For each rule R with weighted support wsupn  and weighted confidence wconfR in the interesting rule set, find the linguistic minimum support region S; and the linguistic minimum confidence region Cj with wminsup,, i wsupR < wminsupi and wminconh., I wconfn < wminconh by fuzzy ranking, where:  wminsupi = minsupiX (the gravity ofl""), wminconJ = minconh x (the gravity of law).

minsupi is the given membership function for S; and minconh is the given membership function for q. Output rule R with linguistic support value Si and linguistic confidence value C;.

The rules output after step 17 can then serve as linguistic knowledge conceming the given transactions.



IV. AN EXAMPLE  In this section, an example is given to illustrate the proposed data-mining algorithm. This is a simple example to show how the proposed algorithm can be used to generate weighted fuzzy association rules from a set o f  quantitative transactions. The data set includes six quantitative transactions, as shown in Table I.

TABLE I THE DATA SET USED IN THIS EXAMPLE  in Figure 1 .

Membership value  0 1  6 I I Item quantity  Figurc I :  The membership functions for itcm quantities  The importance o f  the items is evaluated by three managers as shown in Table II.

0-7803-7280-8/02/$10.M) 02002 IEEE 496    TABLE II THE ITEM IMPORTANCE EVALUATED BY THREE MANAGERS  Assume the membership functions for item importance are given in Figure 2.

Unimportant Important  TID  Very Unimportant very Important Ordinary  Membership value l lxxK 0  0 0.25 0.5 0.75 1 Weight  FUZZY SETS  Figure 2; ?he membership functions of item importance  The linguistic terms for item importance given in Table I1 are transformed into fuzzy sets by the membership functions in Figure 2. The average fuzzy weights of all the items are calculated, with results shown in Table 111.

TABLE 111 THE AVERAGE FUZZY WEIGHTS OF ALL THE ITEMS  I  0.4 ), 0.6 0.6 +- ), ( -+- ( -  0.4 A.Low AMiddle B.Low B.Middle  ITEM A B C D E F  A.Low A.Middle B.Low B.Middle  E.Middle E.High 0.6  +-)  0.4 -+- ), ( - BLOW B.Middle C.Low C.Middle  0.6  FUZZY WEIGHTED SUPPORT (0.1 11,0.194, 0.278) (0.233, 0.333,0.4)  (0.208, 0.333,0.458) (0, 0.044, 0.1 11)  (0.133,0.2, 0.267) (0.033, 0.133, 0.233)  F.Low F.Middle  +- I, ( - +- B.Low B.Mddle CLow C.Middle  0.4 +-)  0.2 0.6 +-).(- DLow D.Middle E.Mddle E.Hiah I -  0.2 +- ). +- ). ( - ( -  0.2 0.8 A.Middle A.High C.Middle C.High  0.8  0.4 0.6 E.Middle E.Hiah -  o.2 )> 0.2 0.8 + +- ). ( - ( -  0.8 CLow C.Middle D.Low D.Midde  ? I,LL-, 0 I  D 0.2 0.8 0.8 0.2 (-+-A-+-)  C.Low C.Midd/e FLOW F.Middle  is chosen for D, ?High? is chosen for E and ?Low? is chosen for F. The number of item.regions is thus the same as that of the original items, making the processing time reduced.

The fuzzy weighted support of each item is then calculated, with results for all the items shown in Table V.

TABLE V THE FUZZY WEIGHTED SUPPORTS OF ALLTHE ITEMS  I D 1  (0,0.167,0.417) ~  E l  (0.5,0.7< 1) F I  (0.083,0.333,0.583)  (0,0.167,0.417) (0.5,0.75, 1)  (0.083,0.333,0.583)  Assume the membership functions for minimum supports are given in Figure 3 ,  which are the same as those in Figure 2. Also assume the given linguistic minimum support value is ?Low?. It is then transformed into a fuzzy set of minimum supports, (0, 0.25, OS), according to the given membership functions in Figure 3 .

0-7803-7280-8/02/~10.00 02002 IEEE 497    Very Low Law Middle High Very High  0 0.25 0.5 0.75 I Minimum support  Figure 3: The membership functions ofminimum supparts  The gravity of P? is calculated as 0.5. The fuzzy weighted set of minimum supports for ?Low? is then (0, 0.25, 0.5) x 0.5, which is (0, 0.125, 0.25). The fuzzy weighted support of each item is then compared with the fuzzy weighted minimum support by fuzzy ranking. Any fuzzy ranking approach can be applied here as long as it can generate a crisp rank. Assume the gravity ranking approach is adopted in this example. A.Midd/e, Blow,  CMiddle, E.High and ELow are thus large weighted I-itemsets. These I-itemsets are put in LI.  (A.Mi&Ie, C.Midd/e), (AMiddIe, E.High) and (B.Low, C.Midd1e) are then found to be large weighted 2-itemsets. They are then put in LI.  In this example, L3 is empty.

The given linguistic minimum confidence value is then transformed into a fuzzy set of minimum confidences.

Assume the membership functions for minimum confidence values are the same as those in Figure 3. Also assume the given linguistic minimum confidence value is ?Middle?. It is then transformed into a fuzzy set of m i n i u m confidences, (0.25, 0.5, 0.75), according to the given membership functions. The fuzzy weighted set of minimum confidences for ?Middle? is then (0.125,0.25, 0.375).

The possible association rules from each large weighted itemset are constructed. The weighted confidence values for the above possible association rules are then calculated. The weighted confidence of each association rule is compared with the fuzzy weighted minimum confidence by fuzzy ranking. In this example, six rules are output. One of them, for example, is shown as follows:  If a /ow number of item B is bought Then a middle number of item C is bought, with a low support and a very high conjidence.



V. CONCLUSION  In this paper, we have proposed a new weighted data-mining algorithm for finding interesting weighted association rules with linguistic supports and confidences from quantitative transactions. Items are evaluated by managers as linguistic terms, which are then transformed and averaged as fuzzy sets of weights. Fuzzy operations including fuzzy ranking are used to find large weighted itemsets and association rules. Compared to previous mining approaches, the proposed one directly manages  linguistic parameters, which are more natural and understandable for human beings.

