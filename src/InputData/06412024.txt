An Open Framework for Video Content Analysis  Chia-Wei Liao, Kai-Hsuan Chan, Bin-Yi Cheng, Chi-Hung Tsai, Wen-Tsung Chang, and Yu-Ling Chuang*

Abstract?In the past few years, the amount of the internet video has grown rapidly, and it has become a major market.

Efficient video indexing and retrieval, therefore, is now an important research and system-design issue. Reliable extraction of metadata from video as indexes is one major step toward efficient video management. There are numerous video types, and theoretically, everybody can define his/her own video types.

The nature of video can be so different that we may end up, for each video type, having a dedicated video analysis module, which is in itself nontrivial to implement. We believe an open video analysis framework should help when one needs to process various types of videos. In the paper, we propose an open video analysis framework where the video analysis modules are developed and deployed as plug-ins. In addition to plug-in management, it provides a runtime environment with standard libraries and proprietary rule-based automaton modules to facilitate the plug-in development. A prototype has been implemented and proved with some experimental plug-ins.



I. INTRODUCTION AND RELATED WORK  With the development of video infrastructure such as faster network, cheaper and bigger storage, and popularity of digital cameras, the internet videos grow rapidly.

For example, 60 hours of video clips is, on average, uploaded to YouTube per minute, and over 4 billion video clips viewed per day [1]. In this tremendous growth of media data, videos can be searched more efficiently, if they are accurately tagged or annotated. Manual annotation is feasible when there are a small number of videos. We will need an automatic annotation/tagging mechanism when facing a sea of videos. Automatic annotation is a challenging problem [2] due to the difficulty in classification. Video analysis entails computer vision technologies and related domain knowledge (e.g. sports videos).

There is an abundance of the survey of integrated automatic annotation. In Reference [3], video abstracts are used for multimedia archives, and videos are segmented and analyzed to extract special features (e.g. faces, dialog, and text). These features help assemble video clips of interest into an abstract.

