An Interpolation Approach for Missing Context Data Based on the Time-Space  Relationship and Association Rule Mining

Abstract?The miss of context data is an inevitable problem of context information processing mechanism, the interpolation technique of missing data is also a research hotspot in data mining. However, the existing interpolation technique of missing data is not suitable for the flow data form of context information that does not make full use of data relevance between every collecting sensor. Moreover, that does not take Time-Space Relationship into account. In order to conquer the shortcomings and deficiencies of the existing interpolation technique of missing data, in this paper an interpolation technique for missing context data based on Time-Space Relationship and Association Rule Mining (TSRARM) is proposed to perform spatiality and time series analysis on sensor data, which generates strong association rules to interpolate missing data. Finally, the simulation experiment verifies the rationality and efficiency of TSRARM through the acquisition of temperature sensor data. Experiments show that the algorithms are of high accuracy for the interpolation of missing context data, which are Simple Linear Regression (SLR) algorithm and the EM algorithm. In addition, it has smaller time and space overhead and can guarantee Quality of Service (QoS) of real-time applications.

Keywords- information processing; the Time-Space Relationship; Association Rule Mining (ARM);interpolation for missing context data; Root Mean Square Error (RMSE)

I.  INTRODUCTION In the processing mechanism of context information, due  to the complexity of real world, variability and limitations of human self-knowledge and subjectivity, it leads to a lot of uncertainty, inaccurate, incomplete, and inconsistent context information. The miss of context information may be attributable to clock synchronization error among sensors, power failure of sensors, communications transmission errors, human attacks and so on, which is inevitable in the processing mechanism of context information.

The miss of sensor data, usually leads to bias of the accuracy of mining information, even produces serious error, leading to system failures, thereby resulting in significant losses. Therefore, the interpolation technique for missing context data is the key technology for context information processing mechanism, the data completeness is prerequisite for high-level context information to generate intelligent decision.

At present, the commonly used methods for missing context data are linear regression interpolation [1],nearest neighbor regression[2], hot plate, cold plate regression, the Maximum Expected EM algorithm[3], maximum likelihood regression[4,5],multiple interpolation [6,7],Bayesian network statistical analysis[8] and other statistical methods. However, these methods do not take the characteristics of sensor data flow into account. The first prominent feature of sensor data is the strong associability, the second is the Time-Space Relationship characteristics among sensors. In addition, recently the primary approach is the use of data mining, particularly using the method based on association rules [9, 10, 11]. Although these methods take data connection into account, it does not involve spatial-temporal characteristics among sensor data. In [12, 13] the spatial-temporal characteristics of sensor data are just used to interpolate missing data, but it does not consider the relationship among sensor data. Therefore, the previous methods are incomplete, which lack comprehensiveness and integration of missing data interpolation to meet the users.

In order to interpolate missing sensor data more accurately, in this paper an interpolation technique based on the two characteristics Time-Space Relationship and Association Rule Mining of sensor data is proposed, which aims at a class of sensor data for missing context data based on time-space relationship and association rule mining according to. And simultaneously the interpolation method of missing data is discussed comprehensively and he accuracy of the interpolation of missing sensor data is improved t.

The rest of this paper is arranged as follows. In Section 2 basic concepts and steps of association rules are introduced.

In Section 3 an interpolation technique for missing context data based on time-space relationship and association rule mining is proposed, and moreover the process of the interpolation is elaborated. In Section 4, the simulation results show that the technique for missing context data based on the time-space relationship and association rule mining is high-efficiency and rational. Finally, we conclude with a brief summary and future work in Section 5.

978-0-7695-4559-2/11 $26.00 ? 2011 Crown Copyright DOI 10.1109/MINES.2011.78    978-0-7695-4559-2/11 $26.00 ? 2011 Crown Copyright DOI 10.1109/MINES.2011.78

II. ASSOCIATION RULE MINING  A.  The Concepts of Association Rule Mining Definition 1 Data Item: In the process of the sensor data  acquisition, values which sensor X and Y collect can be discrete at different range according to the requirements of every user, that is the different particle size range, the discrete values is called data items of sensor. A set of several data items constitute the data items set. The number of data items involved in data items set is called dimension of data items set. The length m of the data items set is defined as the m-dimensional data items set.

Definition 2 Support: In wireless sensor networks, the support of association rule   is defined as the ratio of the number of same data items for every sensor X and Y collected within a certain period of time interval and the total number of sensor X and Y collected within the same time.

The support of data items set D is recorded as supp (D), the support of association rule   is usually recorded as supp ( ).

Definition 3 Trust Value: In wireless sensor networks, for the sensors X and Y, the probability of the possibility which the data item collected by sensor X and simultaneously by sensor Y collected at a certain time interval is defined as trust value of association rules . With trust value definition, the trust value can be represented by support as supp .

Definition 4 Minimum Supports: In practical applications, the minimum value of support of association rules according to the requirements of different users system, which is the minimum value support to meet requirements of users, is defined as the minimum support, usually represented as minsupp.

Definition 5 Minimum Trust Value: In practical applications, the minimum value of trust-value of association rules according to the requirements of different users system, which is the minimum trust-value to meet requirements of users, is defined as the minimum trust-value, usually represented as minconf.

Defined 6 Frequent Items Set: Given minimum support minsupp for the user, if the support of data items D colleted by sensor X is greater than the minimum support minsupp, then it is called data item D as Frequent Items Set.

Simultaneously, the sensor X called as Frequent Node Set.

B. The concept of Association Rule Mining In the network of context information collection, for the  sensors X and Y, the implication X?Y is called association rule, where X and Y are collected by sensors X and Y respectively. Association rule is a simple and practical reasoning rule in Statistics, and it is also a hot research field in data mining, especially for the analysis of model relationship among large amounts of data items which appears frequently, consequently interpolates missing sensor data.

Support and trust value are greater than the user-defined minimum threshold of minsupp and minconf rules are commonly referred as strong association rules. The goal of association rule mining is to find out all strong association rule nodes from all the data items of given sensor node collected , to analysis the law from all data items collected  by sensor nodes, thereby digging out the relationship and correlation among nodes, further to reason and predict for data item of nodes.

C. The basic process of association rules mining From the formal definition of mining association rules,  mining association rules usually can be divided into two basic processes:  (1)The finding of frequent sensor nodes For the minimum support minsupp which user sets, find  all the frequent sensor node set from the sensor network system, which is the sensor node set meets that support is greater than or equal to minsupp. In fact, the frequent nodes set may be a certain relationship of reasoning. In general, we usually just consider the largest frequent sensor node set which are not reached by other sensor node sets. These frequent sensor node set is prerequisite for the formation of strong association rules.

(2)The formation of strong association rules For the minimum trust value minconf of user set,  according to a specific method, it generates association rules which trust value is greater than or equal to minconf in the larges frequent sensor node set, thus forms   implication strong association rules, reasons out relationship among sensor nodes and lay the foundation for interpolation of sensor missing data further.



III. AN INTERPOLATION TECHNIQUE FOR MISSING CONTEXT DATA BASED ON THE TIME-SPACE RELATIONSHIP  AND ASSOCIATION RULE MINING Before In order to be more accurate of interpolation of  missing context information, and to be closer to practical application, this paper introduces the concept of time freshness. For the sensor data sample sequence round number to be weighted, and to be time serialization according to the exponential ( 1p ? ) for sensor data collected, the bigger data time freshness, the more weight the sensor data play. Therefore, the actual use of sensor data is more accurate and true. This paper also redefines the support and trust value called weighted support and weighted trust value mainly on account of the concept of time freshness.

Definition of 7 Weighted Support: In wireless sensor networks, the weighted support of association rule  X Y? is defined as the ratio of the number of data items with same weighted round number for every sensor X and Y collected within a certain period of time interval and the total number with same weighted round number of sensor X and Y collected within the same time. The weighted support of data items set D is recorded as wei_supp(D), the weighted support of association rule X Y?  is usually recorded as wei_supp( X Y? ).

Definition of 8 Weighted Trust Value: In wireless sensor networks, for the sensors X and Y, at a certain time interval, the probability of the possibility which the data item with weighted round number collected by sensor X and simultaneously by sensor Y collected is defined as weighted trust value of association rules X Y? . With weighted trust     value definition, the weighted trust value can be represented by weighted support as  ( )_ sup _ sup ( )wei p X Y wei p X? . Similarly, you can define the minimum weighted support and minimum weighted trust value.

After dealing with sensor data through spatial-temporal, the sensor data will be obtained again to conduct association rule mining. This paper use the method of non-redundant closed frequent data items set, thus saving computation time and memory space, thereby improving the efficiency and accuracy of the interpolation  of sensor missing data, furthermore helping to the application of real-time system.

Definition of 9 Closed Data Items Set: In wireless sensor networks, data items set collected by sensor node set is set to  { }1 2, ,..., mS s s s= ,which is m-dimensional serial-number of sensor data items, { }1 2, ,..., nU u u u=  is the n- dimensional data item values, then the data items can be formulated as P = SU, set A, B are subsets of data items serial-number, the number of A is k, then regard A as k- items data set, and the data flow sequence b collected by sensor is the subset of P, so the closed data items set is the sensor data sequence that meets the following functions f and g , { }( ) | ,f B i P b B i b= ? ? ? ?  and  { }( ) | ,g A b S i A i b= ? ? ? ? . The function f indicates the returned data items set contained in data sequence B collected by sensor, while the function g means the returned data sequence set contained in the given data items set A. A data item A is closed data item if and only if ( ( )) ( ( )) ( )g f A f g A f g A A= = =i , then H f g= i is called the closed operation.

Definition of 10 Closed Frequency Data Items Set: Suppose P is the closed data items set. If its weighted support is greater than or equal to the user-defined minimum weighted support, the P is the closed frequency data items set.

To weigh the sensor data sequence number (round number), it introduces the time freshness. While for spatial relationship among sensor data, we mainly conducting calculation of space similarity, which is the method of Pearson correlation coefficients, to find the closest space sensor data, and apply association rule mining.

Association rule mining algorithm is computation- intensive algorithm. In order to reduce the computational complexity and improve the accuracy of missing context information interpolation, combined with the characteristics of sensor collection data, the first thing is to deal with the spatial-temporal data.

Step 1 sensor data spatiality: First, calculate space similarity for collected sensor data. In this paper, we use Pearson correlation coefficient method, which is usually used to calculate correlation degree between two variables ,that its value range is [-1,1] and user-defined threshold is often used, such as the sensors of the Pearson correlation coefficient which is greater than or equal to 0.5 is usually used as Mining Association Rules Sensors S1, S2,... The data  spatiality can reduce computational complexity, and it is beneficial to real-time applications, thus greatly improving the accuracy of data interpolation.

Similarity measuring formula i.e. Pearson correlation coefficient is usually used to measure similarity between sensors. Let ,i jI be common set of sensor i and sensor j, then the similarity sim (i, j) of sensor i and sensor j is:  ,  , ,  , ,  2 2 , ,  ( )( ) ( , )  ( ) ( ) i j  i j i j  i c i j c jc I  i c i j c jc I c I  R R R R sim i j  R R R R ?  ? ?  ? ? =  ? ?  ? ? ?  (1)  Where, ,i cR is data item c collected by sensor i,  iR and jR represent respectively the average value of sensor i and sensor j.

The correlation coefficient value range is [-l, l], the larger of correlation coefficient, the closer between two sensors, and the higher accuracy of the acquisition data.

Step 2 sensor data time series analysis method: According to round for collected sensor data, and the acquisition data associated with time, we adds corresponding round weighed coefficient to every sensor data. On this basis, calculate the minimum weighted support and minimum weighted trust value. The lower time-sensitive sensor data is used to linear growth trend y ax= , and the high time-sensitive sensor data is used to exponential growth way. For example ( 1)ny ap p= ? , where p is the adjusting parameters, its value may be based on specific data characteristics.

Step 3 the finding of frequent data items set: For the minimum support wei_minsupp which user set, the all finding the frequent sensor node set from the sensor network system is the sensor node set whose support is greater than or equal to wei_minsupp. In fact, the frequent nodes set may be a certain relationship of reasoning. Without loss of generality, we usually just consider the largest frequent sensor node set which is not reached by other sensor node sets. These frequent sensor node set is prerequisite for the formation of strong association rules.

Take temperature sensor acquisition data as example, as shown in Table 1. Suppose there are four sensors 1S , 2S , 3S ,  4S .  Assuming p = 3 and Round 4 appears missing data.

Assuming the minimum weighted support is 50%, and  the minimum weighted trust value is 50%. Table 2 shows the closed Frequent data items set and the minimum weighted support are { 1S .73, 3S .75, 4S .63} = 2, { 1S .73, 4S .63} = 3, { 2S . 63, S4.63} = 2, { 4S .63} = 4.

Step 4 The formation of strong association rules: For the minimum trust value wei_minconf which user set, generate association rules which trust value is greater than or equal to wei_minconf in the larges frequent sensor node set according to a specific method.

The specific operation of association rules concluded as follows:     (l) For each frequent item sets P, generate all the nonempty and real subset of P.

(2) For each nonempty and subset Q of P, if sup ( ) sup ( )p P p Q  is greater than or equal to the minimum weighted trust value, then output the strong association rules ( )Q P Q? ? .

For the above example, it can be drawn as follow: Rule 1 :{ 1S .73, 4S .63} ? 3S .75, the weighted support is 1/2, and the weighted trust value is 2/3. Rule 2: 4S .63? 2S .63, the weighted support is 1/2, and the weighted trust value is 1/2.

Therefore, for the fourth round acquisition data, the missing data of 2S  is 63 of 66.7% possibility and the missing data of  3S  is 75 of 50% possibility.



IV. SIMULATION AND RESULT ANALYSIS  A. Experimental environment Hardware configuration is as follows: CPU:  Inte1Pentium 2.8G; Memory: DDR512M;  Table 1 the acquisition temperature data of four sensors and missing case  r ound  sensors weighted round (p=3) 1S   2S   3S   4S   1 73 63 75 63 30 2 73 68 75 63 31  3 75 63 68 63 32 4 73 ? ? 63 33  Table 2 Closed Frequent data items set and the minimum weighted support  Closed Frequent data items set  minimum weighted support  1S .73? 3S .75? 4S .63 2  1S .73? 4S .63 3  2S .63, 4S .63 2  4S .63 4 Software environment is as follows: Operating System:  windows XP; database: MySQLserver: 5.0; Programming Language: R PROJECT.

B. Simulation and result analysis The experimental data come from open source large-  scale sensor data sets of the U.S. Mitsubishi Electric Research Laboratories (MERL)[14].MERL mainly uses 200 sensors to record the activities of laboratory personnel in two-building office at different times within one year at different positions. For simplicity's sake, this experiment took part of these experimental data, including 100 temperature sensor data at different locations in different time periods, and using 20 round temperature sensor data to  conduct experiment. This paper uses SQL SERVER database to store sensor data, and R PROJECT software to statistical analysis and deal with sensor data. R PROJECT is an open source software systems with a powerful statistical analysis and mapping capabilities.

Experiment 1: Comparison of accuracy for missing data interpolation  To compare the accuracy of various interpolation methods, this paper uses the RMSE (Root Mean Square Error), the formulas are as follows:    ( ) n  i i i  A E R M S E Nn  =  ? =  ? (2)  Where iA  is sensor actual value, iE is sensor interpolation value, n is number of missing data and N is the number of subnet for dataset, the final results can take average from several subnets. The more accurate interpolation methods, the smaller RMSE.

The TSRARM (the Time-Space Relationship and Association Rule Mining) proposed in this paper is compared with the traditional simple linear regression (SLR), EM algorithm, WARM (Window Association Rule Mining) method, CARM (Closed Association Rule Mining) method, and FARM (Freshness Association Rule Mining) methods as shown in figure 1.

0 20 40 60 80 100 120  0.05  0.1  0.15  0.2  0.25  Window Size  R M  S E  v al  ue  TSRARM FARM  CARM  WARM EM SLR   Figure 1. Comparison of RMSE values among SLR, EM,  WARM, CARM, FARM and TSRARM As shown in Figure 1, the data interpolation accuracy of  TSRARM is superior to traditional statistical methods and other association rule mining method.

Experiment 2: Comparison of time used by missing data interpolation  The sensor data spatiality proposed in this paper reduces computational complexity, moreover it increases computational complexity through introducing time freshness to use round weight coefficient method, and the final integrated results need to assess the actual performance by simulation experiments.

This paper uses AIT (Average Interpolation Time) that is average time of each round occupancy. The simulation results are shown in Figure 2.

As shown in Figure 2, the EM algorithm and SLR algorithm spend the least time due to their simplicity.

Compared with other algorithms, the TSRARM is of high efficient, thus saving the system time overhead.

Experiment 3: Comparison of memory space occupied by missing data interpolation  This paper uses memory space occupied by missing data interpolation to measure efficiency of TSRARM method.

The simulation results shown in Figure 3.

As shown in Figure 3, the EM algorithm and SLR occupy the least memory due to their simplicity. Compared with other algorithms the TSRARM is of high efficient, thus saving the system space overhead.

0 20 40 60 80 100 120        Windows Size  A IT  v al  ue (m  s)  TSRARM FARM  CARM  WARM  EM SLR   Figure 2.  Comparison of AIT values among SLR, EM,  WARM, CARM, FARM and TSRARM  0 20 40 60 80 100 120            Windows Size  M eo  m ry  F oo  tp rin  t( M  B )  TSRARM FARM  CARM WARM SLR,EM   Figure 3.  Comparison of memory occupied among SLR,  EM, WARM, CARM, FARM and TSRARM

V. CONCLUSIONS In this paper the concept of time freshness and basis for  the traditional basic process of mining association rules are introduced. An interpolation technique for missing context data based on the Time-Space Relationship and Association Rule Mining (TSRARM) is proposed, which has higher accuracy compared with the traditional data interpolation methods, and reduces time and space overhead on the basis of relevance and spatial-temporal characteristics of sensor data flow. The experiments demonstrate that the method of TSRARM has much better performance than traditional  method and other association rule mining method in terms of accuracy of data missing interpolation. Therefore, the proposed algorithm is rational and efficient.

Because of sensor data time series analysis is introduced, if we adopt the exponential weighted, its value will increase exponentially and the data may be overflow. Therefore how to control the overflow of data is research work in future.

