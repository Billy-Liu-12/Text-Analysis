Fast Parallel Association Rule Mining Without Candidacy Generation

Abstract  In this paper we introduce a new parallel algorithm MLFPT (Multiple Local Frequent Pattern Tree) [I l ]  for parallel mining of frequent patterns, bused on FP-growth mining, that uses only two full I/O scans of the database, eliminating the needfor generating the candidate items, and distributing the work fairly among processors. We have de- vised partitioning strategies at different stages of the mining process to achieve near optimal balancing between proces- sors. We have successfully tested our algorithm on datasets larger than 50 million transactions.

1. Introduction Association rule mining algorithms currently proposed  in the literature are not sufficient for extremely large datasets and new solutions still have to be found. In par- ticular there is a need for algorithms that do not depend on high computation and repeated I/O scans. Parallelization is a viable solution. However, distributing and balancing the mining tasks between the processors without jeopardizing the global solution is not trivial. The problem of mining as- sociation rules over market basket analysis was introduced in [l]. Association rules are not limited to market basket analysis, but the analysis of sales, or what is known as bas- ket data, is the typical application often used for illustration.

The problem consists of finding associations between items or itemsets in transactional data. The data could be retail sales in the form of customer transactions or even medi- cal images [12]. Association rules have been shown to be useful for other applications such as recommender systems, diagnosis, decision support, telecommunication, etc. This association-mining task can be broken into two steps: A step for finding all frequent k-itemsets known for its associ- ated extreme 1/0 and a straightforward step for generating confident rules from the frequent itemsets.

1.1 Related Work  Several algorithms have been proposed in the literature to address the problem of mining association rules. One of the key algorithms, which seems to be the most pop-  ular in many applications for enumerating frequent item- sets, is the apriori algorithm [3] the foundation of most known algorithms whether sequential or parallel. Park et al. have proposed the Dynamic Hashing and Pruning al- gorithm (DHP) [9]. However, the trimming and the pruning properties caused some problems that made it impractical in many cases [ 131. The partitioning algorithm proposed in [5] reduced the I/O cost dramatically . However, this method has problems in cases of high dimensional itemsets, and i t also suffers from the high false positives of frequent items.

FP-growth, was recently proposed by Han et al. [8]. This algorithm creates a relatively compact tree-structure that al- leviates the multi-scan problem and improves the candidate itemset generation. The algorithm requires only two full I/O scans for the dataset. Our approach presented in this paper is based o n  this idea. In spite of the significance of the asso- ciation rule mining and in particular the generation of fre- quent itemsets, few advances have been made on paralleliz- ing association rule mining algorithms [6, 21. Most of the work on parallelizing association rules mining on Shared- memory MultiProcessor (SMP) architecture was based on apriori-like algorithms.

Parthasarathy et al. [IO] have written an excellent re- cent survey on parallel association rule mining with shared- memory architecture covering most trends, challenges and approaches adopted for parallel data mining. All ap- proaches spelled out and compared in this extensive sur- vey are apriori-based. These methods not only require re- peated scans of the dataset, they also generate extremely large numbers of candidate sets easily approaching lo3' candidates in common cases [7].

1.2 Contribution  In this paper, we introduce a new parallel association rules mining algorithm MLFPT, which is based on the FP- growth algorithm [8]. We have implemented this algorithm on a 64 processor SGI 2400 Origin machine, where all ex- periments were tested using high dimensionality data that are of a factor of hundreds of thousands of items, and trans- actional sizes that range in tens of gigabytes. A special opti- mization step is added to achieve better load balancing with  0-7695-1 119-8/01 $17.00 0 2001 IEEE 665    the goal of distributing the work fairly among processors for the mining process  2 Multiple Local Parallel Trees  The MLFPT approach we propose consists of two main stages. Stage one is the construction of the parallel frequent pattern trees (one for each processor) and stage two is the actual mining of these data structures, much like the FP- growth algorithm. However, in order to avoid false neg- atives, where locally infrequent itemsets are pruned inad- vertently while they are frequent globally, we need global counters. Though global counters necessitate locking mech- anisms for mutual exclusion, that would add significant overhead and waiting time. Our approach with interlinked local counters avoids the need for locking. Thus, we evade the famous ping-pong problem in parallel programs.

2.1 Construction of the Multiple Local Parallel Trees  The goal of this stage is to build the compact data struc- tures called Multiple Local Parallel Trees (MLPT). This construction is done in two phases, where each phase re- quires a full VO scan for the dataset.

A first initial scan of the database identifies the frequent I-itemsets. In order to enumerate the frequent items effi- ciently, we divide the datasets among the available proces- sors. Each processor is given an approximately equal num- ber of transactions to read and analyze. As a result, the dataset is split in p equal sizes. Each processor locally enu- merates the items appearing in the transactions at hand. Af- ter enumeration of local occurences , a global count is nec- essary to identify the frequent items. This count is done in parallel where each processor is allocated an equal number of items to sum their local supports into global count. Fi- nally, in a sequential phase infrequent items with a support less than the support threshold are weeded out and the re- maining frequent items are sorted by their frequency. This list is organized in a table, called header table, where the items and their respective global support are stored along with pointers to the first occurrence of the item in each fre- quent pattern tree. Phase 2 would construct a frequent pat- tern tree for each available processor.

Phase 2 of constructing the MLPT structures is the ac- tual building of the individual local trees. This phase re- quires a second complete I/O scan from the dataset where each processor reads the same number of transactions as in the first phase. Using these transactions, each proces- sor builds its own frequent pattern tree that starts with a null root. For each transaction read by a processor only the set of frequent items present in the header table is collected and sorted in descending order according to their frequency.

I I l D  Item? Bough1 I RweamrNumher 1 A. B. C. D, E  B. D. A. E. G A . 8 , F . G . D B. F. D. G. K  6 A . B . F . G . D A. R.M. K . 0  8 B.F. G.A. D - 1?2 9 A. B.F.M.V  Table 1. Transactional database example.

Lep 4 S1ep 1  Step I  Figure 1. Steps of phase 1.

These sorted transaction items are used in constructing the local FP-Trees as follows: for the first item on the sorted transactional dataset, check if it exists as one of the children of the root. If it exists then increment the support for this node. Otherwise, add a new node for this item as a child for the root node with 1 as support. Then, consider the cur- rent item node as the newly temporary root and repeat the same procedure with the next item on the sorted transaction.

During the process of adding any new item-node to a given  this item-node in the tree and its entry in the global header table corresponding to processor p .  The header table holds as many pointers per item as there are available processors.

For illustration, we use an example with the transactions shown in Table 1. Let the number of available processors be 3 and the minimum support threshold set to 4. The four steps in phase 1 are shown in Figure 1 and Figure 2 shows the result of the tree building process. For the sake of sim- plicity, only links from the items A and B are drawn from the header table.

local FP-Tree of a processorp, a link is maintained between  2.2 Mining Parallel Frequent items using MLPT Trees  Building the trees in the first stage is not a final goal but a means with the purpose of uncovering all frequent patterns without resorting to additional scans of the data. The min- ing process starts with a bottom up traversal of the nodes on the MLPT structures, where each processor mines fairly equal amounts of nodes. The distribution of this traversal work is predefined by a relatively small sequential step that precedes the mining process. This step sums the global sup-     Figure 2. Phase 2 of the construction of the MLPT structure.

G  ports for all items and divides them by the number of pro- cessors to find the average number of occurrences that ought to be traversed by each processor. If A is this found average, this sequential step goes over the sorted list of items by their respective support and assigns items consecutively for each processors until the cumulated support is equal or greater than the average A. At this stage all frequent pattern trees are shared by all processors. The task of the processors, once assigned some items, is to generate what is called a conditional pattern base starting from their respective items in the header table. A conditional pattern base is a list of items that occur before a certain item in the frequent pattern tree up to the root of that tree in addition to the minimum support of all the item supports along the list. Since an item cannot only occur in  many trees but also in many branches of the same tree, many conditional pattern bases could be generated for the same item. Merging all these conditional pattern bases of the same item yields the frequent string, a string also called conditional FP-Tree, that contains fre- quent itemsets and their support in the presence of a given item. The merge is based on the items in the patterns and all the supports of the same items are added up in the same manner as in [8]. If the support of an item is less than the minimum support threshold, i t  is not added in the frequent string.

Table 2 gives all conditional bases and conditional FP- Trees generated from the example in Table 1.

i F :  I, D I, 8: I i (F 2, D:2. A.2,8:2) (Fi,D!i.FJ:I) ~ F l , D l , A : l . B : i ) ( D i . B : i )  (8:6, D.6. F 5 ,  A:4jIG  3 Experimental Results  A shared memory SGI Origin 2400 with 64 processors was used to conduct the experiments. We used synthetic transactional databases generated using the IBM Quest syn- thetic data generator [4]. The sizes of the input databases vary from I million transactions to 50 million using dimen- sions that are multiples of hundreds of thousands. Each  Items I Conditional Pattern Base I CondiUolul FP-Tm I I 1D: I .A: I .B: I I  I 1  (DZ. A:2, 8:2) ( D  I, B ? I j  (A:I. 8 : ) ) (A.2. 8:2)  (8.7. ASJID  (A? l .  8:  I j  (8?21  Table 2. Conditional Pattern Bases and the Conditional FPtrees (mining process).

I wthout U0 Adjusternent With VO Adjusternent I  I 1 proc. 4proc. 8proc. 16proc. 32proc. 48proc. 64proc. Number of Processars Figure 3. Comparison of execution time for 5 million transactions with and without I/O ad- justement.

of these transactions has at least 12 items preceded by a unique transactional ID. The largest dataset is in the order 10 Gbytes.

In our experiments we studied the MLFPT algorithm with 4,8,  16,32,48 and 64 processors and compared it to its sequential version. The sequential version was, of course, implemented without the summation phase and with only one tree. Speedup measures the performance of parallel ex- ecution compared to the sequential execution: S, = TIIT, where S, is the speedup achieved with p processors, TI is the sequential execution time and Tp is the execution time using p processors.

I/O access is normally of an ?embarrassingly parallel? nature. For instance, when data is stored on parallel disks with dedicated channels, twice as many processors should read twice as much data. In other words, with appropriate hardware, if it takes t time for one processor to read some data, it should take t / p  for p processors to cover the same data.

Since our parallel machine had a sequential disk with one     shared head, to assess the real speedup of MLFPT, which does 2 VO scans of the data regardless of the number of processors, we adjusted the I/O time assuming an ?embar- rassingly parallel? I/O access.

In our results we decided to adjust the VO time of our algorithm as follows: The VO time for parallel execution was estimated using the YO time for sequential execution divided by the number of processors used. For instance, if using p processors the total execution time is T and the isolated I/O time is t ,  the execution time with U 0  adjusted is calculated TI = T - t + ( S / p ) ,  where S is the isolated I/O time for a sequential execution. In other words, we replaced the 2 scans I/O time recorded with the expected real parallel I/O time.

Due to the space limitation we will only present figure 3 that depicts the significant time reduction with the increase of processors when mining 5 million transactions.

MLFPT operations are divided into two stages where most of the computation in the MLFPT algorithm is done during building the MLPT trees, and then mining them.

Building the frequent pattern trees, which utilize most of the processing time, is shown to be of ?embarrassingly parallel? nature and this indeed was the reason for the several-fold improvements achieved as we increased the number of pro- cessors in our experiments. This is due to the fact that the work is evenly partitioned among the processors and each unit of work is completely independent of each other where each processor builds a sub-tree representing its partition of transactions. There is no ping-pong effect where processors are waiting for each other.

Our experiments have shown that this creation and min- ing is almost linearly proportional to the number of pro- cessors and the size of the transactional datasets, where the speedup of the MLFPT algorithm increases as the problem size increases. These results suggest that the MLFPT algo- rithm would achieve speedups for extremely large datasets as well.

4 Conclusion and Future Work  In this paper, we have introduced an efficient parallel implementation of an FP-Tree-based association rule min- ing algorithm and have proposed a solution for load bal- ancing among processors and resource sharing with min- imum mutual-exclusion locking. We have discussed our experiments with this new parallel algorithm, MLFPT, for mining frequent patterns without candidate generation. The MLFPT algorithm overcomes the major drawbacks of par- allel association rule mining algorithms derived from apri- ori, in particular the need for k I/O passes over the data.

Our experiments showed that with I/O adjusted, the MLFPT algorithm could achieve an encouraging many-fold speedup improvement.

The implementation of our algorithm and the experi- ments conducted were on a shared memory and shared hard drive architecture. We have recently acquired a cluster with 8 dual processor nodes and we plan to investigate the same approach with shared nothing architecture and devise a new protocol for sharing global resources while minimizing the message passing overhead. We are in the process of experi- menting our algorithms with up to 1 billion transactions.

