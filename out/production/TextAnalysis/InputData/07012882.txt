August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India

Abstract?Association rule mining along with frequent items has been comprehensively research in data mining. In this paper, we proposed a model for association rules to mine the generated frequent k-itemset. We take this process as extraction of rules which expressed most useful information.

Therefore, transactional knowledge of using websites is considered to solve the purpose. In this paper we use interestingness measure that plays an important role in invalid rules thereby reducing the size of rule data sets. The performance analysis attempted with Apriori, most frequent rule mining algorithm and interestingness measure to compare the efficiency of websites. The proposed work reduces large number of immaterial rules and produces new set of rules with interesting measure. Our extensive experiments will use relevant rule mining to enhance websites and data accuracy.

Keyword? Association Rules, Apriori Algorithm, Frequent Pattern, Support Count, Confidence, Lift

I. INTRODUCTION Association rule mining is a data mining method  originally invented to extract patterns from transactional databases. Stated simply, an association rule is an implication in the form X ?Y, where X and Y are sets of items. Association rule mining identifies all such implications existing in a given data set, which satisfy certain constraints, such as minimal support and minimal confidence [1].

We will use APRIORI and FP-Growth algorithm as a pattern discovery tool and pattern analysis on found patterns is the next task. Patterns analysis will perform on found patterns with the help of generated association rules between item sets (web links).

A. Frequent Pattern Mining A pattern is a group of items, subsequence?s, and  composition that frequently occur in an item set. Frequent Pattern Mining is a heavily researched area in field of data mining and is applied in extensive range of application one of them is to exploit frequent pattern discovery methods in web. Web logs are interesting and useful knowledge in way of web accesses patterns mined [2].

B. Association Rule Mining Association rule mining finds interesting association or  correlation relationships among a large set of data items. A typical example of an association rule mining is market basket analysis. This process analyzes customer buying habits by finding associations between the different items that customers place in their ?shopping baskets?. The discovery of such associations can help retailers to develop marketing strategies by gaining insight into which items are frequently purchased together by customers. Apriori is a classical algorithm for mining association rules. Some variations of the Apriori approach for improving the efficiency of the mining process are referred to as Apriori- based mining algorithms [3].

An association rule is defined as follows: Let I = {i1? in} be a set of items, and T = {t1? tm} a set of transactions, where each transaction ti consists of a subset of items in I.

An association rule is then an implication of the form:   X         Y, X ? I , Y ? I, X ? Y = ?   An item set X has support s in T if s% of the transactions  in T contains X. An item set X is frequent if its support is higher than the user specified minimum support.

The rule X  Y holds in T with confidence c if c% of transactions in T that contain X also contain Y.

The problem of mining association rules is to generate a set of potentially interesting association rules in a data set of sessions that have support higher than the specified minimum support threshold and assign an interestingness value to all rules based on an interestingness measure.



II. RELATED WORK Due to the immense volume of Internet usage and web  browsing in recent years, log files generated by web servers contain enormous amounts of web usage data that is potentially valuable for understanding the behaviour of website visitors. Knowledge can be applied in various ways, such as enhancing the effectiveness of websites through user personalization or developing directed web marketing campaigns [4]. An interestingness measure is a function that assigns a value to each association rule, which corresponds    August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India   to the web usage rule interestingness. Various interestingness measures can be used when the association rules are discovered to qualify the potential interestingness of the association rules and highlight potentially interesting rules for the data analyst [5]. Discovering web usage association rules is one of the popular data mining methods that can be applied on the web usage log data. Given information contained in association rules can be used to learn about website visitor behavior patterns, enhance website structure making it more effective for the visitors, or improve web marketing campaigns [6]. Finding of basic problem with association rule discovery is that when Mining Algorithms are on web access logs, the total number of generated rules is found to be very large. Confidence and lift are the association rule interestingness measures that are used to compare values in two different time duration.

Association rule mining of the web usage log files can be used to extract patterns of a website visitor?s behavior. This knowledge can them be utilized to enhance web marketing strategies or improves the web browsing experience [7]. The process of discovering hidden patterns and information from the existing data are used in [8]. The difference between data in the databases and a data warehouse is in a database the data is in the structured form where as in the data warehouse the data may or may not be present in the structured format [8]. In [9], the authors considered the changes of the association rule interestingness values in two different time periods. The goal was to determine the minimum number of requests needed to distinguish between robot and non-robot sessions from web server logs with high accuracy. After pre-processing the web server logs to identify access sessions, a set of features is extracted to characterize the access session. These features include total pages, total time, average time, request method, request error and so on [9]. A novel method for mining association rules from semantic instance data repositories express in RDF/(S) and OWL [10]. According to Authors, put forward an incremental updating algorithm for mining indirect association rules to deal with the maintenance of discovered indirect association rules resulted from the change of the minimum support. [11]. The authors have mentions improve the efficiency of association rule mining in distributed environment by deploying intelligent agents for the mining frequent item sets and generate association rule [12]. Author define an algorithm for class association rule mining with chi-squared test using GNP and present a classifier using these extracted rules[13]. Author has proposed at two problems of discovering frequent item sets in a large database and mining association rules from frequent item sets, I make some research on mining frequent item sets algorithm based on Apriori algorithm and mining association rules algorithm based on improved measure system. Mining association rules algorithm based on support, confidence and interestingness is improved, aiming at creating interestingness useless rules and losing useful rules [14]. The authors have discussed a model which is an integration between two algorithms, the Positive Negative  Association Rule (PNAR) algorithm and the Interesting Multiple Level Minimum Supports (IMLMS) algorithm, to propose a new approach (PNAR_IMLMS) for mining both negative and positive association rules from the interesting frequent and infrequent item sets mined by the IMLMS model [15].



III. PROPOSED MODEL FOR ASSOCIATION RULE MINING  In the web log extractor, we will take care of session management of web links that is visited by user. And in data pre-processing module we will use some freely available data mining software systems that can be used for discovering association rules in the web log usage data. For this we will use C++ language or WUM prep scripts for web log pre-processing. The process to implement a new (and simple) web association rule mining system Figure 1.

IPs & accessed web        Feedback  Find K-Item sets    Extract of Rules  Figure 1 Proposed Model  We designed an efficient web association rule mining system, best way to find areas where exactly improvement is needed. After finding, make a conscious how it can be improvement. Following are the phase, which need to be, take care during system development.

? Web log Extractor Module: We have developed this web  extractor to extract the IPs and Web links from a web log file. It gives a File 1, which is used as an input for data preprocessing module.

? Data Preprocessing Module: This is a program which is developed by us to make input file containing navigational profile entries for APRIORI. We used link list data structure to solve our purpose. This Data preprocessing module produces an input file for APRIORI which contains entry of different navigational profile. Here each IP works as user id and web links as item sets.

Web Log Data  Web Log Extractor (1)  Pre- processing  (2)  Transactional Data of different  users  Apriori / FP- Growth (3)  Association Rule Mine (4)  Information (5)    August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India   Apriori or FP Growth Algorithm Module: If a set cannot pass a test, all of its superset will fail the same test as well?.

It is called anti-monotone because the property is monotonic in the context of failing a test. Apriori uses above property to find L(k) from L(k-1). A two step process is followed which consists of join and prune operations.

Confidence Calculation: The procedure for calculating the confidence is as follows procedure: ? For each frequent item set ?l?, generate all nonempty subsets of l.

? For every nonempty subset  s of l, output the rule ?s ->(l- s)? if support_count(l) / support_count(s) >= min_confwhere min_confis minimum confidence threshold.

The equation for confidence is:  Confidence(X      Y) = Tuples containing both X and Y/ Tuples containing X   (1)  Lift Calculation: Lift is an interestingness measure of an association rule that compares the rule confidence to the expected rule confidence. The expected confidence of a rule X  Y in a set of sessions D is the probability of the rule con-sequent Y in D. If the probability P(Y) is equal to the conditional probability ? P (Y|X), the item sets X and Y are not correlated in D.

? If Supp denotes candidate support, the following   formula  can be used to calculate the lift of the rule X  Y.

Lift (X        Y) = conf(X        Y) / Supp(Y)         (2)  ? Association Rule Generation Module: This module find out the association rules in between frequent mining pattern results. K-item set results will work as a input to association rule miner and it will give patterns as a output with their confidence value.

? Information: This module defines the process of knowledge discovery. Knowledge is derived with the help of extraction of rule those satisfy minimum confidence, below this minimum confidence other rules has been ruled out. So, now knowledge may help in finding out the strongly occurring patterns.

? Now, we going to discuss about working of the system.

Consider the figure 1 for working of the system ? The process starts with collecting a log file from a web server. This log file is fed to the Web log Extractor. The first task of Extractor is extraction of IPs; Web links from log file and write these entries in a file (1).

? Now fed this file (1) to transaction maker. This Data pre- processing module is developed by us to handle IPs and their respective web links. Data pre-processing module maintain an entry of IPs and their web links in a Link List. It performs its job in following steps.

a) It assigns each different IP a different transaction number and add all different item sets (web links) accessed by this IP to the particular transaction.

b) Check for every entry that if IP already exists in list then simply add web link to that navigational profile otherwise  declare it a new navigational profile. For a particular navigational profile, if a web link already exists in profile then no need to add this repeated web link (which comes as a new entry with same web link address) to navigational profile.

c)   Write each different transaction in a new line with its  accessed item sets (web links). So, now it produces File (2) containing entry of transactions.

d)   We have got File (2) as an output of Data pre- processing module. Fed this File (2) to Apriori produces the different item set mining results. It calculates Support count for every item set mining result. It counts support for 1-itemset, 2-itemset?k- item set. Value of k depends on max number of item sets those may occur together in a transaction.

e)   Write these all different web links (item set) mining result to a File (3).

f)     Now the next task is to find out patterns and analysis of patterns with the help of different association rules.

Rule miner generates rule according to minimum confidence given. Our purpose here to find some strong patterns those are occurring as an output of rule miner.

Finally, get some strongly occurring patterns on the basis of knowledge we got.



IV. IMPLEMENTATION AND RESULT ANALYSIS To evaluate the performance of the proposed approach,  there must have an understanding of pattern analysis of actual container files. Web log files are downloaded from Web to make navigational profile in from of IPs and Web links. We have taken hundred or more entries in log files.

However, number of log entries can be increased to expand frequent item set mining results.

The different values of minimum support have been used for APRIORI to find frequent item set mining results.

The Threshold for support count can be defined as = ceil value of (minimum support count * number of transactions), below this threshold no item set sequence will occur as a k- item set mining result.

We have assigned a web link unique integer value. So, now we deal with these numerical item sequences of different navigational profiles. Results for different values of minimum support are shown in this Table I the number of unique navigational patterns (p) used are: 34  Table I Minimum Support Value Minimum support ( % )  Total support count( in terms of number of unique navigational profiles)  1 ? 2 (0.01 to 0.02)* 34 = 1 3 ? 5 (0.03 to 0.05)* 34 =  2 6 ? 8 (0.06 to 0.08)* 34 = 3 9 ? 11 (0.09 to 0.11)* 34 = 4 12 ? 14 (0.12 to 0.14)* 34 = 5 15 ? 17 (0.15 to 0.17)* 34 = 6 18 ? 20 (0.18 to 0.20)* 34 = 7 21 ? 23 (0.21 to 0.23)*34  = 8    August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India   We design part covers the architecture implementation and the working of the system. In this section we will take a look at the tool used in the implementation and implementation issue. We have used Apriori to find out different itemset mining result. Apriori also provide support count for different item sets sequence. A minimum support count is given as a part of input to Apriori. Association Rule Miner is used to find out the pattern with the help of association Rule.  We decide the strongly occurring pattern with the help of threshold value of confidence and Lift.

We have defined access of web log file, after extraction given user id accessed web link assign its own unique number given below Table II.

Table II Access web link  User id or IP address Accessed web link (assigned Unique number)  1 (80.170.104.145) 1 2(80.170.104.147) 1 3(80.170.104.148) 1 4(81.241.83.239) 2 3 1 4 5 5(81.241.83.240) 4  We applied Apriori Algorithm to find out k-item set mining result given Table III  Table III K-item set Frequent Item sets Item sequence(Support Count)  1  3(3) 8(2) 2 8 3(2) 3 5(2)   We inputted minimum support 0.3 find out frequent item  sets, so we get result Table IV Table IV Finding Item Sequence  Frequent Item sets Item sequence(Support Count)  1  8(2) 2 10 13(2) 3 8 10 13(2) 4 8 10 13(2)  8 10 7 4(2) 8 10 3 7(2)   We finding short association Rule is of the form X ? Y,  X and Y is sub items of the 4- frequent Item set occurrence transaction 10 times so confidence 100% possibility to be next web pages or item accessed. X and Y are one next to each other on the web link, 2- Frequent item set will be confidence 50%.

The different values of minimum support have been used for Apriori to find frequent item set mining results.

The threshold for support count can be defined as = ceil value of (minimum support count * number of transaction), below this threshold no item set sequences will occur as a k- item set mining result. Now, the next task is to find out association rules between web links. With the help of  association rule miner we find the different association rules.

We have eliminated the following five rules and introduced their cluster representatives. We used below (Fig 5.5) confidence of all eliminated rules is close, which means they all fit into parameter.

? / Search.doc/ home.asp ==> /Search.asp/  login.asp,conf: 0.98 ? / Search.doc/home.asp  == > / login.asp,conf: 0.98 ? / Search.doc / Search.doc   /home.asp ==> /  login.asp,conf: 0.98 ? / Search.doc/home.asp  == > / login.asp,conf: 0.98 ? / Search.doc/home.asp  == > /Search.asp/  login.asp,conf: 0.84  The cluster representative of the five eliminated rules is: ? / Search.doc/ home.asp == > / login.asp,conf: 0.91  We have eliminated the following three rules and introduced their cluster representative. The confidence of all eliminated rules is close, which means they are all fit into the parameter.

? /Logout.asp == >/ Search.doc// login.asp,conf: 0.69 ? /Logout.asp == >/ Search.doc/ / login.asp,conf: 0.64 ? /Logout.asp == >/ Search.doc/  / Search.doc/ /  login.asp,conf: 0.64 The cluster representative of the three eliminated rules is: /Logout.asp == >/ Search.doc/ / login.asp,conf: 0.66 We find out Association Rules with their confidence capable of handling very large number of log entries. It?s shown below Table V  Table V Association Rules with Their Confidence Association Rules Confidence % 3=>7 100 13=>4 40 3=>4 66 7=>4 25 13=>3 33 13=>7 50   We have eliminated the following five rules and  introduced their cluster representatives. We use Lift of all eliminated rules is close, which means they all fit into parameter.

? / Search.doc/ home.asp ==> /Search.asp/ login.asp, Lift:  0.96 ? / Search.doc/home.asp  == > / login.asp, Lift : 0.96 ? / Search.doc/ Search.doc   /home.asp ==> /  login.asp, Lift: 0.96 ? / Search.doc/home.asp  == > / login.asp, Lift: 0.96 ? / Search.doc/home.asp  == > /Search.asp/ login.asp,  Lift: 0.83 The cluster representative of the five eliminated rules is: ? / Search.doc/ home.asp == > / login.asp, Lift: 0.90 We have eliminated the following three rules and introduced their cluster representative. The Lift of all eliminated rules is close, which means they are all fit into the parameter.

August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India   ? /Logout.asp == >/ Search.doc// login.asp, Lift: 0.68 ? /Logout.asp == >/ Search.doc/ / login.asp, Lift: 0.63 ? /Logout.asp == >/ Search.doc/  / Search.doc/ / login.asp,  Lift: 0.63 The cluster representative of the three eliminated rules is: ? /Logout.asp == >/ Search.doc/ / login.asp, Lift: 0.65  We find out Association Rules with their confidence capable of handling very large number of log entries. It?s shown below Table VI  Table VI Association Rules with Their Lift Association Rules Lift %  10 7 4=>3 100 13 7 4=>3 50 7=>5 14 4=>10 12 5=>4 66 13=>10 33   In our experiments, we found that support value higher  than 0.01 generate too few rules leaving many potentially interesting rules out of the rule data set. We conducted two experiments setting the minimum support threshold value and compared the resulting association rules and their interestingness measure.

In the second phase, our software generates potentially interesting association rules and calculates their interestingness measures, based on the frequent item sets and their support.

One of the basic association rule interestingness measures is confidence, and we consider its minimum threshold when evaluating the value of the calculated rule interestingness. We found that in all our experiments the rules whose confidence was lower than 0.4 were extremely rarely truly interesting according to our definition.

Therefore, we chose to set the minimum confidence threshold to 0.3 and out all the rules that have lower confidence.

We used Confidence and Lift as two different interestingness measures of the generated association rules and compare their values to the true rule interestingness based on Support threshold. Similar approach was taken in Dimitrijevic and Bosnjak (2011) where top 10 rules were classified as interest-ing or not interesting by a domain expert.

Our results are more stable, while the rule set is not cluttered by too many not truly interesting rules. Figure 2 shows that both Confidence and Lift perform satisfactory, while Lift fairly outperforms Confidence in all our experiments.

In figure 2, we analyzed the distribution of the peak five rules according to Lift and Confidence over the true interesting-ness categories. The horizontal axis corresponds to the number of peak five rules in each category and vertical axis corresponds to the occurrence based on support value. When the rules are sorted according to Confidence  and Lift, most of the top five rules with different support values are based on frequent item sets.

Figure 2. Performance based comparison of support threshold      Figure 3. Five Association Rules according to Confidence & Lift  Figure 3 shows the five association rules which are sorted according to confidence and lift i.e. almost all of the peak five rules fit into threshold occurrence the true interestingness with different support values. There were no rules in the peak five that can be based on a web log server.



V.  CONCLUSION In this research an approach to identify web link  patterns which has been developed from web log and analysis of patterns is presented .The frequent item set mining has been performed with the help of Apriori    August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India   algorithm. It gives us different frequent item set mining results with their support count. Web link sequences below support threshold are pruned. We found different frequent item set mining results by varying minimum support (2%- 3%).Association rules miner give all the possible rules with their confidence and Lift. Using the knowledge of the web site structure and the behavior of the site?s visitors, we analyzed the pruned rule set from the user ?s point of view and proposed actions that a webmaster may decide to take based on knowledge extracted from rules in order to enhance a website and improve visitor?s browsing experience. The work can be further extended by developing even more effective data pre-processing modules. Because the current module (2) is not capable of handle very large number of log entries. Association rule mining of web usage log files is a method that can bring new, previously unknown knowledge about the website visitor behavior. In this research we presented how it can be used by a webmaster to improve a website structure. We leave such analysis out of the scope of this research. Future work in this area may also consider the scalability issue.

