APT-Structure : Efficient Mining of Frequent

Abstract?Frequent pattern mining is a key step in many data mining applications. In this paper, we propose a simple and novel pattern growth algorithm, which uses a compact data structure named Array-based Prefix Tree(APT). The APT has a distinct feature that the space requirement can be predictable in advance. The memory usage of APT is less than FP-Tree that uses pointer to maintain the link between parent and child nodes, and the traversal cost is lower. The mining algorithm based on APT uses top-down traversal strategy, and unfiltered pseudo- construct conditional database, which can improve computational performance. Further computational experiments show that APT algorithm is more efficient, and performs better than FPGrowth* and AFOPT.

Index Terms?Frequent pattern mining, association mining, Array-based Prefix Tree

I. INTRODUCTION  Since frequent pattern mining was first proposed by Agrawal  et al.(1993) for market basket analysis in the form of associa-  tion rule mining, a large number of concerned algorithms have  been proposed. The frequent pattern mining can be depicted  as follows.

Let ? be a set of items. A set X = {i1, ..., ik} ? ? is called an itemset, or a k-itemset if it contains k items.

A transaction over ? is a couple T = (tid, I) where tid is the transaction identifier and I is an itemset. A transaction  T = (tid, I) is said to support an itemset X ? ?, if X ? I .

A transaction database D over ? is a set of transactions over ?. We omit ? whenever it is clear from the context.

The support of an itemset X in D is the number of transactions that support itemset X in D, denoted as sup(X).

Given a transaction database D and a support threshold min supp, a itemset is called frequent itemset or frequent  pattern, if and only if sup(X) ? min supp.

Definition 1: Let D be a transaction database over a set of items ?, and min supp a minimal support threshold. The collection of frequent itemsets in D with respect to min supp is denoted by  ?(D,min supp) = {X ? ??supp(X,D) ? min supp},  or simply ? , if D and min supp are clear from context.

The problem of frequent pattern mining is to find the  ?(D,min supp), given a set of items ?, a transaction database D over ? and minimal support threshold min supp.

Existing algorithms can be classed into three categories:  Apriori, FP-growth and Eclat. The Aprior is the first algorithm  proposed by Agrawal et al. [1], which employs a candidate  generate-and-test approach. Apriori is a breadth-first algorithm  and is based on the downward closure property:A k itemset is  frequent only if all of its sub-itemsets are frequent. Park et al.

[2] proposed DHP algorithm, which use hashing technique to  speed up the item set counting. Savasere et al. [3] proposed  Partition algorithm, which partition the transaction database  into multi small blocks, in which local frequent item sets are  firstly found and then the global frequent item sets are got.

TreeProjection [4] algorithm constructs a lexicographical tree  and projects a large database transaction into a set of reduced,  item-based sub-databases. Toivonen [5] proposed Sampling  algorithm, which only scans the transaction database once.

Brin et al. [6] proposed DIC algorithm, which needs scanning  the transaction database 1.5 times.

FP-growth is a pattern growth algorithm proposed by Han et  al. [7], which works in a divide-and-conquer way. FP-growth  is a depth-first algorithm and does not generate the candidate.

The pattern growth is achieved by the concatenation of the  suffix pattern with the frequent patterns generated from a  conditional FP-tree. Pei et al. [8] proposed H-Mine algorithm,  which explores a hyper-structure. Liu et al. [9] proposed  OP algorithm, which opportunistically chooses array-based or  tree-based structure to represent the conditional database. Liu  et al. [10] proposed AFOPT algorithm, which use ascend-  ing frequency ordered prefix-tree to organize the conditional  database. Grahnea and Zhu [11] proposed FPGrowth* algo-  rithm, which use array technique for efficient mining.

Both Aprior and FP-growth mine frequent patterns form  a horizontal data format transaction database, Zaki [12] pro-  posed Equivalence CLASS Transfromation(Eclat) algorithm  by exploring the vertical data format, with a depth-first search  order like FP-growth. The computation is done by intersection  of tid sets. For dense dataset, dEclat [13] is proposed, which  uses a novel vertical data representation called Diffset, that  only keeps track of difference in the tid sets.

This pater proposes a new method to improve the mining  efficiency, which is based on Array-based Prefix Tree (APT).

The rest of paper is organized as follows. The next section, the  data structure of APT and the mining algorithm are depicted.

DOI 10.1109/ICEE.2010.354     Section 3 presents computational experiments that show the  new algorithm is more efficient than others. In the last section,  the paper is concluded.



II. MINING FREQUENT PATTERNS USING APT  In this section, we introduce the APT structure, and then  a novel algorithm named APT algorithm is developed to find  the frequent item set.

A. APT Structure  The APT Structure is used to compactly store the transaction  database in computer?s memory. By using array structure, the  traversal cost can be diminished. Our general idea of APT  Structure can be illustrated in the following example. Fig. 1 is  an example transaction database, which has 5 transactions. Let  the minimum support threshold is min supp = 2. Following  the Apriori property, only frequent items will be in frequent  item set. By scanning the transaction database, the frequent  items {f:4,c:4,a:3,b:3,m:3,p:3} can be found.

Fig. 1. A transaction database.

Then the transaction database is scanned again to build  APT structure by removing the infrequent items and merging  the same transactions. As shown in Fig. 2, the left is FP-  Tree representation, and the right is APT structure. In APT  structure, each row is corresponding to a transaction, but  without duplicated items with previous row. In a row, each  entry includes three field: an item, a count and a link to the  next different row.

B. The APT Algorithm  Fig. 3 shows the pseudocode of APT algorithm. Given  a transaction database D and a minimum support threshold min supp, APT algorithm scans the original database twice  to mine all frequent item sets. In lines 2-3 of the pseudocode,  the transaction database is first scanned, all the items are  counted, and frequent items are sorted in ascending order of  their supports, denoted as ? = {i1, i2, . . . , in}. Then, in line 4, we perform the second scanning of the transaction database  to construct the APT structure. In lines 5-9, the conditional  database for each i ? ? is constructed, denoted as Di. For each i ? ?, the depth traversal is performed in lines 10-15.

Lines 17-31 are the pseudocode of procedure DepthTravese.

When mining conditional database Di is finished, because it contains the other items, the branch needs to be inserted into  the remaining conditional database. Provided the first frequent  item of a branch is item j, then the branch will be inserted  into Dj .

(a) FP-Tree Structure (b) APT Structure  Fig. 2. The FP-Tree and APT structure.

1: procedure APT(D, min supp) 2: First Scan D, Count and ? = {i1, i2, . . . , in}; 3: Sort items in ? in ascending order of their support; 4: Second Scan D, Construct the APT structure; 5: for all branch b ? APT do 6: if i is the first item then  7: Insert b into conditional database Di; 8: end if  9: end for  10: for all item i ? ? do 11: frequent itemset p = {i}; 12: ? = ?  ? p;  13: DepthTravese(Di, p, ?); 14: PushRight(Di); 15: end for  16: end procedure  17: procedure DEPTHTRAVESE(Dp, p, ?) 18: Scan the Dp, Count and ?p = {i1, i2, . . . , im}; 19: for all branch b ? Dp do 20: if i is the first item then  21: Insert b into conditional database Dp ? {i}  22: end if  23: end for  24: for all item i ? ?p do 25: frequent itemset p = p  ? {i};  26: ? = ? ? p;  27: DepthTravese(Dp ? {i}, p, ?p);  28: PushRight(Dp ? {i});  29: end for  30: return ? ; 31: end procedure  Fig. 3. The APT Algorithm.

C. The Conditional Database and Memory Usage  Because to build the physical construction of the conditional  database is expensive in memory and time, the APT algorithm  adopts the pesudo-construct strategy. In APT, only the branch  link are saved in the conditional database, so the construction  cost is relatively low. In the worst case, the total memory used     by the APT algorithm is 4n, where n is the number of entry in APT structure. Of the 4n memory space, 3n is used to store the APT structure, n is used to store the conditional database. The  exact number of entry is unknown before the APT structure  is constructed, but it is less than the total transaction database  item count.

Comparing with other frequent item set mining method, the  efficiency of APT algorithm comes from the following as-  pects. First, APT algorithm adopts the frequent pattern growth  method and depth-first traversal strategy. Second, APT algo-  rithm uses pesudo-construct strategy to build the conditional  database, and the total memory consumption is determined  by the APT structure, which is unlike other frequent pattern  growth algorithms. Third, APT algorithm uses array to build  APT structure, so the transaction traversal is faster than other  methods, such as link list.



III. COMPUTATION EXPERIMENTALS  In this section, we study the performances of APT, FP-  Growth* and AFOPT algorithms on various real-world and  artificial data sets.

A. Experimental Setup  In our experiments, to make it easier to bridge our bench-  marks with previously published experimental results, we use  three real-world data sets and one artifical data set whose  general characteristics are summarized in Table. I.

TABLE I SOME CHARACTERISTICS OF EXPERIMENTAL DATA SETS.

Data set #Item #Record #Avg. Length Source  Retail 16470 88162 10.3 Belgian Retail store  T10I4D100K 870 100000 10.1 IBM Almaden  Wap 8460 1560 141.3 WebACE  La1 29714 3204 151.1 LA Times (TREC)  These data sets were obtained from various application do-  mains. Retail contains the retail market basket data from an  anonymous Belgian retail store1. T10I4D100K was generated  using a data generator obtained from IBM Almaden, which is  often used in the association rule research community2. Wap  was from the WebACE project. Each document corresponds to  a web page listed in the subject hierarchy of Yahoo!. Finally,  La1 was obtained from articles of the Los Angeles Times that  was used in TREC-53.

The FPGrowth* and AFOPT algorithm are different imple-  mentations of FP-growth algorithm. The former uses a novel  array-based technique to reduces the need to traverse FP-trees,  and the later uses ascending frequency ordered prefix-tree  and a top-down strategy. The source code can found from  http://fimi.cs.helsinki.fi/src/.

All the algorithms were coded in C and C++, build with  Microsoft Visual C++ 2008, and run on a Microsoft Windows  7 Ultimate platform. The experimental PC is installed a Intel  1Available at http://fimi.cs.helsinki.fi/data/.

2Available at http://fimi.cs.helsinki.fi/data/.

3Available at http://www.daviddlewis.com/.

2 4 6 8 10 12  x 10 ?3      support(%)  E x e  c u  ti o  n t  im e  (m ill  is e  c o  n d  )      APT  FPGrowth*  AFOPT  (a) Retail  2 4 6 8 10 12  x 10 ?3     support(%)  E x e  c u  ti o  n t  im e  (m ill  is e  c o  n d  )      APT  FPGrowth*  AFOPT  (b) T10I4D100K  5 10 15 20 25 30    support(%)  E x e  c u  ti o  n t  im e  (m ill  is e  c o  n d  )     APT  FPGrowth*  AFOPT  (c) Wap  0.5 1 1.5 2 2.5 3       support(%)  E x e  c u  ti o  n t  im e  (m ill  is e  c o  n d  )      APT  FPGrowth*  AFOPT  (d) La1  Fig. 4. Computational times of APT, FPGrowth* and AFOPT.

Q9550 CPU, 4 GB DDRIII 1066 MHz RAM, and Seagate  Barracuda 7200.11 500GB Hard Disk.

B. Experimental Result  First, We would like to compare the performance of the  APT, FPGrowth* and AFOPT. Fig. 4 shows the results of  data sets Retail, T10I4D100K, Wap and La12. We can  see that the APT has the best performance.

For Retail, we set the minimum support from 0.002%     2 4 6 8 10 12  x 10 ?3     support(%)  E x e  c u  ti o  n t  im e  (m ill  is e  c o  n d  )      Ascending  Descending  (a) Retail  2 4 6 8 10 12  x 10 ?3     support(%)  E x e  c u  ti o  n t  im e  (m ill  is e  c o  n d  )      Ascending  Descending  (b) T10I4D100K  Fig. 5. Computational times of APT with ascending and descending order.

to 0.0012%, with corresponding absolute support from 2 to  13. When the minimum support is 0.002%, there are 14246  frequent items and 1839084261 frequent item sets. When the  minimum support is 0.012%, there are 8241 frequent items  and 155111 frequent item sets. When the minimum support  is lower, the APT is much faster than the others, and when  the minimum support gets higher, the executing time is closed  to others. For T10I4D100K, the minimum support is from  0.002% to 0.0012% and the absolute support is from 2 to 12.

When the minimum support is 0.002%, there are 869 frequent  items and 19561714 frequent item sets. When the min support  is 0.012%, there are 866 frequent items and 286023 frequent  item sets. For Wap, because the number of transactions is  small, we set the minimum support from 2% to 12%, with  corresponding absolute support from 31 to 187. For La1, the  minimum support is from 0.5% to 3%, with corresponding  absolute support from 16 to 96. When the minimum support  is higher, the executing times are closed, because there are  little frequent item sets. However, when the minimum support  decreases, the frequent item sets increase substantially, and  computational times go up to 4661s and 3298s for FPGrowth*  and AFOPT, respectively. Second, We compare the impact of  item order for the performance of the APT. Generally, the  descending order means more sharing entries and less memory  usage. But, for traversal process, the ascending means less  depth and more performance. Fig. 5 shows the results of data  sets Retail, T10I4D100K for APT with ascending and  descending order. Generally, the execution time with ascending  order is less than with descending order, but the former needs  more space than the later. For Retail, there is obvious  difference between ascending order and descending order. But,  for T10I4D100K, there is little difference. This is related to  the property of transaction dataset.



IV. CONCLUSION  In this paper, we have proposed a new Array-based Prefix  Tree data structure named APT structure, which is a compact  representation of transaction database and need less storage  space than that of FP-Tree. APT structure is used in our novel  algorithm named APT algorithm for mining all frequent item  sets. The APT algorithm traverses the search space from top  to down, and store the conditional database using pseudo-  construct in the mining process. Performance comparisons  of APT algorithm against other well-known algorithms in-  cluding FPGrowth* and AFOPT have been done. The results  shows that the APT algorithm outperforms the others at all  support levels in computational times. The APT algorithm is  simple and has a distinct feature that the space requirement  is predictable in advance, which has a linear relationship  with the number of entries. In the further, we will study the  performance on very large databases.

