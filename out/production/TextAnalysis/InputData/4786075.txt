

Abstract- Many algorithms have been proposed to solve the problem of mining frequent itemset. The resulting frequent itemsets represent the global frequent patterns. This global output doesn?t provide any information about the distribution of the frequent patterns on the database. This missing information can produce inaccurate decisions or prediction when the output frequent itemsets are used in decision support or prediction systems, specially, when the input database is non-uniformly distributed.  In this work, we shall introduce a technique to calculate, store, and display frequent itemsets? distributions in the database. The proposed technique is called short time association rule mining (ST-ARM).

Keywords - Data Mining, Association Rules, Short Time Association Rules Mining

I. INTRODUCTION   Association rule mining (ARM) is considered one of the  most critical data mining components. This because it discovers not only frequently occurring patterns in databases, but also the associations between these patterns' attributes.

Recently, many approaches have been proposed for ARM.

Association rules are divided into two categories, quantitative and Boolean rules, based on the type of their attributes. Quantitative association rules describe associations between either numerical or categorical attributes, whereas Boolean-based methods reveal associations pertaining to the presence or absence of items.

Based on the terminology introduced by Agrawal in [1], the Boolean ARM is briefly described as follows: I={i1 , i2 , ?.., in} is a set of n binary literals called items. A transaction Ti is a set of items in I such that Ti ?  I. A database D is a set of transactions. A transaction Ti is said to contain a certain set of items (itemset) C, iff C ?  Ti. Itemset that consists of K items is called K-itemset. The support of an itemset C, denoted ?(c), is the percentage of transactions that contain C. An itemset is considered as frequent one if its support is greater than or equal to user defined value minimum support (min_sup). The maximal frequent itemset is defined as the frequent itemset that is not a subset of any other frequent itemset. The Boolean association rule (hereafter refereed to as association rule) is presented in the form A ? B  (read: A implies B) where A and B are two itemsets and  A ? B = ? . The association rule support is the support of an itemset C where C  = A U B . The rule is frequent iff itemset C  is frequent. The confidence in the rule is the conditional probability P(B|A) (probability that a transaction contains B, given that it contains A). An association rule is considered of interest if it is frequent and its confidence is greater than or equal to (user defined value) minimum confidence (min_conf).

ARM is a two-step process. In the first step, all frequent itemsets are discovered; in the second step, strong association rules are generated from the frequent itemsets. The first step  is the more laborious, that is why most of the research work in the ARM field has been dedicated to improve the efficiency of discovering frequent itemsets.

The resulting frequent itemsets represent the global frequent patterns where the calculated support for any frequent itemset represents the probability of finding this itemset in the examined database, and don?t provide any information about the distribution of this itemset on the database. In this work, we introduce techniques to calculate, store, and display the distributions of frequent itemsets in the database.

This paper is organized as follows: related work is discussed in section 2; in section 3 the problem definitions and the proposed algorithm are discussed; in section 4 experimental results are presented, and finally, section 5 concludes the work.



II. RELATED WORK   Since Agrawal et al. has been the first to formalize the ARM concepts [1], many ARM algorithms were proposed.

These algorithms can be categorized into two main categories: candidate generation based techniques, and pattern growth based techniques. In candidate generation based techniques, the candidate set is first generated, and then support values of the candidate itemsets are evaluated. The resulting itemsets are used in next candidate generation. The candidate generation based techniques can also be divided based on the database layout used, into horizontal and vertical layout based techniques. In horizontal layout, the database is a list of transactions, and every transaction consists of a set of items. The well known Apriori algorithm [2] is an example of this category. Apriori algorithm is the foundation of many ARM algorithms on [3,4,5,6]. It calculates frequent itemsets at any level K in two steps: First, the candidate set is generated; then, database is scanned, and support of the candidate set is calculated. By definition, itemsets having a support greater than the minimum support are considered frequent. Apriori algorithm generates the candidate set for any level K+1 from the frequent itemsets in level K only.

This is a plausible assumption, since the super itemsets of any infrequent itemsets is also infrequent, and there is no need to evaluate them. While in vertical layout, the database is organized as list of transactions IDs TID, which associated with each item. DLG [9] algorithm uses a bit vector to represent the TID list for each item. The support of any itemset is calculated using logic, and resulting bit vector summation. Eclat and Clique [11] algorithms divide search space into disjoint subsets. The subsets are examined independently.

In pattern growth based techniques, the database is represented in a compact tree based form. The process of discovering frequent itemsets is performed using this  SHORT TIME ASSOCIATION RULE MINING ALGORITHM   A. M. Ghanem2, B. Tawfik1, and M. I. Owis1 1Biomedical Engineering Department, Cairo University, Giza, Egypt  2Faculty of Information Systems, Suez Canal University, Ismailia, Egypt e-mail: ahmed@optimal-sys.com     compact form without any extra database scan. Since the concepts of pattern growth were first proposed in [14], many algorithms [15,16] have been proposed to reduce the complexity of used data structure and/or increase the performance of discovering frequent itemsets.



III. METHODOLOGYS   The three databases shown in Figure 1 have the same  number of items, transactions, and frequent patterns with different distributions for these patterns. Applying ARM algorithms generates the same output from these different databases. The output frequent itemsets are not affected by the distribution of patterns in the database, so that ARM algorithms cannot provide description for these distributions.

Moreover, this missing information about the distributions can produce inaccurate decisions or prediction, when the output of ARM is used in decision support or prediction systems in case of the input database is non-uniformly distributed; so that, there is a requirement for ARM algorithm to discover frequent itemsets, and describe the distribution of the discovered itemsets. In this work, we propose a solution that covers these requirements. The proposed solution is called short time association rule mining (ST-ARM). In ST- ARM, the database is divided into partitions. The division is according to user requirements, and nature of the database.

Each partition may represent transactions of one day, month, quarter, or year. The effect of partition size on the algorithm?s output will be discussed in subsection B. After determining the partitions, the frequent itemsets of each partition are discovered by applying Apriori algorithm. Then the frequent itemsets from all partitions are stored in compressed form, called universal maximal frequent set (UMFS) as described in the following subsection. Then each partition is scanned once to calculate the support of all itemsets in UMFS in this partition. Finally, a graph describing the distribution of itemsets in UMFS is provided.  ST-ARM algorithm is shown in Figure 2. In the following subsections, two issues will be discussed. The first one is UMFS, the second one, is partition size selection.

TID DB1 DB2 DB3 1 a,b,c a,b,c a,b,c 2 a,b,c a,b,c f,g 3 a,b,c a,b,c a,b,c 4 a,b,c f,g f,g 5 a,b,c f,g a,b,c 6 a,b,c f,g f,g 7 f,g a,b,c a,b,c 8 f,g a,b,c f,g 9 f,g a,b,c a,b,c  10 f,g f,g f,g 11 f,g f,g a,b,c 12 f,g f,g f,g  Fig. 1: Three different databases   A. Universal Maximal Frequent set   As discussed in pervious subsection, the second step in ST- ARM is discovering the frequent itemsets for every partition in the database, Figure 2 is an example. Number of frequent  itemsets in every partition is different according to the nature of the database and number of partitions. For non-uniformly distributed database with large number of partitions, the number of frequent itemsets may be very large and become a bottle-neck specially in calculating and storing the distribution of these frequent itemsets. ST-ARM provides UMFS as a solution for this problem. To overcome this problem, ST-ARM calculates the maximal frequent itemsets for every partition. Maximal frequent itemsets is the frequent itemsets that is not a subset of any other frequent itemsets.

Figure 3 shows the maximal frequent itemsets of all partitions of the example shown in Figure 2; then the union of all maximal frequent itemsets is calculated, and denoted as universal maximal frequent set (UMFS). Figure 4 shows the graphical representation of the UMF itemsets? support distributions.

Definition: Universal maximal frequent set is a union of all MFS of all partitions in the database.

UMFS is used in the recent part of ST-ARM as alternative to the union of all frequent itemset of all partitions. UMFS is considered as compressed form for all frequent itemsets, and the union of all frequent itemsets can be calculated from the subsets of itemsets in UMFS as shown in the following lemma.

Lemma: all frequent itemsets can be calculated from UMFS.

Proof: All frequent itemsets can be calculated from MFS, by calculating the subsets of maximal frequent itemsets. UMFS contains all maximal frequent itemsets, therefore, frequent  itemsets can be calculated from UMFS.

Fig. 2: ST-ARM algorithm   B. Partition Size selection problem   Partition Size is a user defined variable. The selection of  this variable is affected by required time resolution and frequent pattern accuracy in output distribution. Small size partition implies higher time resolution. For example, dividing the database by days provides batter time resolution than dividing by weeks, or months; because the output distribution can describe the changes of UMFS supports day by day as alternative to week or month. So that reducing the partition size increasing the time resolution. However, in the frequent patterns accuracy issue, small partitions allow many  ST-ARM algorithm Input: a database file, user-defined minimum support, user- defined partition size Output: UMF itemsets? support distributions  1. UMFS := ? 2. divide database file into partitions according to user- defined  partition size 3. for every partition k 4.       call Apriori to get all frequent itemsets 5.       call procedure to calculate MFSK 6.       UMFS := UMFS ? MFSk 7.  end for 8. for every itemset I? UMFS 9.       i:= index of I in UMFS 10.       for every partition k 11.            support-table[i][k] := support count of I in P 12.       end for 13. end for 14. return support-table     insignificant patterns to be considered as frequent patterns in one or more of these small partitions. As example, for partition size equal to 10000 transactions and minimum support 0.002 , the minimum support count is 20 transactions.

Day  Day  Day  Day  Day  Day  Day      Fr eq  ue nt  I te  m se  ts   a  a  a  a  a  ??  ?..

d  d  b  b  d  e  d,e  c  c  f  F e,f  d  e  a,d  a,d  a,d  e  a,b  a,f  a,e  a,e  a,b  a,e  e,f  a,f  de  a,c  b,c  d,e  e,f  a,d  a,b,c  e,f  a,d,e  a,e  a,d,e   b,c  d,e  a,b,c  a,d,e  Fig. 3: Example on calculating frequent itemsets in partitions     Day  Day  Day  Day  Day  Day  Day      M ax  im al   Fr  eq ue  nt   Ite m  se ts  a,f e,f a,f a,d a,d ??  ?..

e,f a,d,e a,b,c a,e a,f  a,d,e  a,d,e a,b,c e,f    UMFS a,d      ,    a,e    ,       a,f     ,     e,f     ,       a,b,c      ,        a,d,e  Fig. 4: Maximal frequent and universal maximal frequent itemsets for dataset in figure 2  If the partition size is reduced to 1000 transactions, the minimum support count will be 2 transactions for the same minimum support. As a result for this small value, if an itemset is a subset of only two transactions, it will be considered as frequent itemset. Once a pattern is considered as frequent in one partition, it affects the calculations of maximal frequent itemsets and may represent in UMFS.

Therefore, reducing the partition size reduces the frequent patterns accuracy. As conclusion, the time resolution and frequent patters accuracy have contradicted requirements in  partition size selection. Therefore, finding compromised solution considering different requirements is the important task in partition size selection.

U M  FS   a,d,e  a,b,c  e,f  a,f  a,e  a,d  DB  Day  Day  Day  Day  Day  Fig. 5: Graphical representation of support distributions for UMF itemsets over database partitions

IV. PERFORMANCE EVALUATION   The numerical experiments are designed to examine the  effect of the partition size and minimum support values on the execution time. The datasets are generated using the IBM synthetic data generator [17] that uses the following parameters: |D| is the number of transaction, |N| is the Number of items, |T| is the average size of transactions, and |I| is the average size of maximal frequent itemsets. For example, N1000.T10.I4.D100K specifies that the number of items is 1000, the average size of transactions is 10, the average size of maximal frequent itemsets is 4, and the database size is 100,000 transactions.

The proposed algorithm is coded in java and all the experiments are performed on a Core 2 Duo processor with 2 GB main memory running under Open Suse 11.0 Linux operating system. The experiment is applied for datasets T8I2N1000D100k, T8I4N1000D100k, and T10I4N1000D100k as shown in Figure 6.

The results show that, the execution time and number of UMF itemsets decreases with increasing minimum support.

That is because, reducing minimum support increases the number of generated frequent itemsets , UMF itemsets and required time to generate both; frequent itemsets  in every partition and UMF itemsets in addition to the increasing in                       Fig. 6: Change in execution time and number of UMF itemsets with different minimum support and number of partitions.

time of calculations the supports of UMF itemsets for different partitions. On other hand, increasing the number of partitions increases number of UMF itemsets and required execution time as a result. That is because; reducing partitions sizes increases the number of insignificant patterns that are considered as frequent patterns as discussed in subsection B.



V. COUNCLUSION   We introduced the concept of frequent itemsets  distributions over time, universal maximal frequent set, and provided technique to generate these distributions. The distributions can provide better description for databases; moreover, we proposed a comprised form for storing and displaying distribution. The proposed algorithm requires only two database scans to the distributions.

