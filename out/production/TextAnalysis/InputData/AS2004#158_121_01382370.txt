<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedings

Abstract: Nowadays, d a t i o n  NIW mining from frequent itemsets is an important task of data mining, which should satisfy two conditions: support and consdence. However, there exist some problems in the strong association rules mining. Firstly, there am a great number of redundant amciation rules, then it is difficult for users tu fmd interesting association rules in them, Secondly, we ignored the weights of attributes, neglected more important attributes, therepore we should introduce new measure criteria association rules mining, which are weighted interestingness and cover. In the paper, we think that the weighted intemtingness and cover of measure criteria should he added to association rules mining, thus the weighted interestingness makes it essy Lor users to mine interesting association rules, and the cover of association rules makes it simple for user8 to reduce the amount of awxiation rules, then the efficiency and veracity of mining association rules are improved.

Keywords: Association rule; Apriori, frequent itemsets, data mining 1. Introduction Nowadays, association rules [I' mining is an important task of data mining, which describes potential relationships among data items (attribute, variant) in databases, the main idea of which was fmtly proposed by R. Agrawal et al. in 1993, before long realized by the well-known Apriori algorithm 'I, which was an influential algorithm for mining frequent itemsets for Boolean association rules. Usually most all of algorithms are improved on the basis of the algorithm, According to the popular measure criteria of association rules mining, we can mine these strong association rules, which should satisfy two conditions: support and confidence.

However, mining association rules by the popular measure criteria, there exist some shortcomings. In this paper, we have introduced added-newly measure criteria to association rules mining, 'which are weighfed 0-7803-8403-2/04/$20.00 IEEE inferestingness '3.4s1 and cover of association rule .that help to mine the interesting association rules and reduce the amount of association rules. Then the efficiency and veracity of mining association rules are improved.

2. The popular association rules Association rules mining can he stated as follows: Let I=[&amp;, if. ... in) be a set of items. Let D, the task-relevant data, be a set of transactions in a supermarket, where each transaction T is a set of items such that T d .  The quantities of items bought are not considered. Each transaction is assigned an identifier, called TID. Let A he a set of items, a transaction T is said to contain A if and only if ACT. An association rule is an implication of the form A=% where A d ,  BcI, and AnB=0.  The rule A*B holds in the transaction set D with support s, where s is the percentage of transactions in D that contain AuB (i.e., both A and B).

This is taken to be the probability P(AuB). The rule A q B has confidence c in the transaction set D if c is the percentage of transactions in D containing A that also contain B. This is taken to he the conditional probability, P(BIA). That is, Support (A=+B)=P(AuB)=s, Confidence (A+B) = P(BIA) =Support (A*B)/Support (A)=c.

The popular association rules Mining is to mine strong association rules that satisfy the user-specified both    association rules that satisfy the user-specified both minimum support threshold and confidence threshold.

3. Association rule mining with added -newly measure criteria According to the popular measure criteria, support and confidence, there exist some shortcomings, There are a great number of redundant, false, non-interesting strong association rules, thus it is difficult for users to find interesting association rules, therefore we think that the weighted interestingness and cover of measure criteria should be added to association rules mining in order that the weighted interestingness make it easy for users to mine interesting association rules, and the cover of association le^ make it simple for users to reduce the amount of association rules, then the efficiency and veracity of mining rules are improved.

As above mentioned in Section 2, Let D be a set of transactions, where each transaction T is a set of items such that TcI. The quantities of items having been bought are not considered. Here, we should think about the importance of the quantities of items customers have bought, as we know that the more the quantities of something bought in a supermarket is, the more money the retailers of the supermarket would have eamed, thus those items are very important for them, in other words, the retailers are interested in those items, in the course of association rules mining, they would pay more attention to them, or else, if more attention was paid to those unimportant items, they would make improper decisions, eam less money, even go into bankruptcy, therefore, we should mine the interesting association rules.

3.1 The weighted interestingness of association rules A set of items I=(&amp;, it. ... in), every item ii has a weighted value pjdetermined by users or experts of domain knowledge according to some criteria, that is: % p j&lt; 1.0, j A typical example of association rules mining with weighted interestingness is market basket analysis, association rules can help retailers develop market sbategies by gaining insight into which items are frequently purchased together by customers, hence, the retailers demand an objective business analysis on selling their merchandise. As we know, those different kinds of merchandise maybe have different weighted values, so we can set a weighted threshold k, if the weighted value &amp; of item i, is bigger than k, then we think that the retailers is interested in item i,, thus association rule having been mined from those items is all useful rules on the hasis of the weighted interestingness.

we have found out a lot of methods to calculate weighted value p, of each item iJ on the basis of some criteria, such as the profit method. the capital turnover method. the marketing cost method and so on. Now we calculate them based on the profit method: In a period, because it is not right that any merchandise brings the retailers a lot of profit, it is true in some cases, then the weighted values of these items will have high values, while the other is false, then the weighted values of these items will have low values, these weighted values of these items can be calculated by the means: the weighted value p, of item iJ =the profit sum of item i, / all  profit sum of all items, that is to say, the weighted value of item i, equal to the profit sum of item i, divided by all profit sum of all items.

Now that we can calculate weighted value p, of each item iJ on the basis of the capital "over method, the marketing cost method, the rest may be deduced by analogy.

3.2 The cover of association rules As similarly as the definition of association rule in Section 2, it said that the rule A 3 B  has confidence c in the transaction set D if c is the percentage of transactions in D    transaction set D if c is the percentage of transactions in D containing A that also contain B. This is taken to be the conditional probability P(B1A). That is, Confidence (A*B) =P(BIA) =Support (AdB)/Support (A)=c. Here, we define that the association rule A a B  has cover k in the transaction set D if k is the percentage of transactions in D containing A that also contain B. This is taken to be the conditional probability P(A1B). That is, Cover(A+B) = P(AIB) = Support (B*A)/ Support (B)=k.

We introduce the cover to association rule with the purpose for cutting down the amount of association mles to a half. Since the Cover of the association rule A*B can keep the information of Confidence of the association rule B q  A, we do not need to mine the association rule B * A, then the redundant association rules can be reduced a lot of.

From the definition of Support, Confidence, Weighted interestingness Cover of association rule mining, the property of association rules can be viewed from different perspectives: Support shows us that the association rule hold at how much extent; Confidence tells us that the association rule hold true at how much probability; Weighted interestingness presents us that the users are getting interested to how much extent in the association rule; Cover will help us reduce the amount of association rules to a half, in a word, these parameters will help us to mine the interesting and useful association rules.

4. Apriori algorithm The algorithm has become one of the most popular data mining methods, which was proposed by Agrawal et al., The aim of the association rule mining is finding interesting relations among the attributes in the large databases. Many methods have been improved to reduce the number of scans and candidates by hashing, sampling, 26-29 August 2004 26-29 August 2004 partitioning, dynamic itemset counting, parallel computing etc. but the essential of them have not changed.

Apron algorithm is an influential algorithm for mining frequent itemsets for Boolean association rules, employs an iterative approach known as a Level-wise search, where k-itemsets are used to explore (k+l)-itemsets. First the set of frequent I-itemsets is found. This set is denoted Ll,then LI is used to find L, the set of frequent 2-itemsets, which is used to find L3, and so on, until no more frequent k-itemsets can be found. The finding of each Lk requires one full scan of the database. The problem of mining association rules can be decomposed into two major steps: 1) Find out all frequent itemsets, 2)  Use the frequent itemsets to generate the strong rules. Once all frequent itemsets from transactions in a datahase D have been found, it is straightforward to generate strong association rules from them, where strong association rules satisfy both  minimum snmort and minimum confidence. in the candidate C3: (IIIZI3], {1,1215], calculating the support of C3 is U9, 219, respectively, then frequent itemsets can be easily gained, then association rules mining has been finished.

5.1 Generating association rules from frequent itemsets with popular measure criteria Once the frequent itemsets from transactions in a database D have been found, we can generate association rules from them, for example, we can select some attribute at random in the literature [?I , association rule I lA12ds , the support of frequent itemsets [ I I I ~ ]  and {h121s) is 419, 2/9, respectively, then the confidence of. association rule II is 214, as such 1#11A12, IIAIs=&amp; I~AIs*II, I l ~ 1 2 A 1 5 ,  1 2 4  A I ,  whose confidence is U2,U2,  U6, U7, 2 4  respectively.

2 4  respectively.

.I meantime, these association rules should satisfy the minimum weighted interestingness. 5.2 Generating sssociation rules from freqnent itemsets with added-newly measure criteria 5. An example of association rule mining by Apmiri algorithm with criteria ?Ompared with added-newly measure criteria Similarly, we can generate association rules from the frequent itemsets with added-newly measure criteria, if the weigbted interestingness and cover of association rules are From the definitions mentioned above, we can mine association rules by Apriori algorithm, taking an Example 6.1 as market basket analysis on page 232 in literature [?I, There are 9 transactions and 5 items in ALLEL -ectronics transaction database D, that is M=9, the minimum support threshold determined is 119, scan D for count of each candidate, frequent Itemsets C1: {L],[L), {II],{II],{Is]. whose the support of frequent itemsets is 619,719,619,219, 219, respectively, remove these frequent itemsets whose the support is lower than the minimum support threshold 119, we can easily obtain all those frequentitemsetsLI: ( I l l ,  (121, {I3], {I,). {L), generateC2 candidates from L1, frequent itemsets C2 is those as follows: UIIZJ. IIihI. Ihbl. I I iLI ,  { IzSI , Table 1.

is 4/9, 419, 119, U9, 419, U9, UY, 0, 119, 0, respectively, remove T5W T6W (121, J, generate C3 candidates from L, scan D for count of each - adopted, we can obtain the same result, for example, we assume that the weighted interestingness of itemset 11.12.15 are bigger than the minimum weighted interestingness threshold, namely, It is said that the users are interested in them, therefore we will mine association rules about itemset I,, 12, Is, according to the same steps in Section 5.1, association rule I,A12sIs, the support of frequent itemsets (1112) and [IJzIs) is 419, 219, respectively, then the confidence of association rule Il A 1 2 d s  is 214, whose cover is the confidence of the association rules Is I, AI2, as we know, the confidence of the association rules IS 11 AI2 is 212, we do not need to mine the association rule Is 1, AIz, because the cover of the 11 AI2=&amp; is 212, which keeps the information that there exists a association rule Is 1, AI2, whose confidence (U2) equal to the cover (2/2)of the association rule I, AI2+, So we can reduce the useful association rules to a half. similarly, the association rules 1, A I S ~ 1 2  and I~=IIIA\I~ ,  the association rules 1 2 A 1 5 ~ I l  and  From the result, Compared with the popular measure criteria, we can know that the same results by the means of generating association rules from frequent itemsets with added-newly measure criteria can be obtained, however, because of introducing the weighted interestingness and cover to association rules mining, we can reach the conclusion that the weighted interestingness make it easy Ii*Iz AIS.

26-29 August 2004 for users to mine interesting associatiop rules, and the cover of association rules make it simple for users to reduce the amount of associ.ation rules, then the efficiency and veracity of association rules mining are improvedL7?.

6. Conclusions In the paper, we have introduced added-newly measure criteria which are weighted interestingness and cover to association rules mining. As we know, the i m p o m t  attributes should be paid attention to and could not be neglected, thus the weighted interestingness of    association rules makes it easy for users to mine interesting association rules, and the cover of association rules makes it simple for users to reduce?the amount of association rules, then the efficiency and pertinence of mining association rules are improved. In the meantime the searching space of the algorithm has been reduced, therefore compared with the popular measure criteria, we can generate association rules from frequent itemsets with added-newly measure criteria and popular measure criteria hy Apriori algorithm.

The former is obviously superior to the latter.

? Acknowledgements The paper is supported the National Natural Science Foundation of P. R. China under Grant No. 60273044 and the Natural Science Foundation of Anhui Province of China under Grant No. 01042201.

