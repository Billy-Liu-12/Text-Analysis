An Improved Apriori Algorithm for Early Warning of Equipment Failue

Abstract?With large database, the process of mining association rules is time consuming. The efficiency becomes crucial factor. By analyzing Apriori algorithm and its improvement, the improved Apriori algorithm is applied to early warning of equipment failure. Moreover, Apriori algorithm is improved by reducing the number of scanning data base and the number of candidate item-set in advance which might become frequent item. Apriori algorithm and the improved Apriori algorithm are compared by the example of equipment failure. Finally, the improved Apriori algorithm is proved that it can improve the efficiency by experiment.

Keywords- association rules mining(ARM); Apriori algorithm; early warning of equipment failure

I. INTRODUCTION Currently, lots of equipment failure records are generated  in equipment monitoring system, which means we can gain useful information by data mining. Thereby, association rules mining are very valuable in early warning of equipment failure.

[1] proposed Apriori algorithm ,which is an important method in association rule mining. With large database, the process of mining association rules is time consuming. Many  variations of Apriori algorithm which focus on improving the efficiency have been proposed. [2] proposed the method of FP-growth .It could find frequent item-sets without candidate generation by FP-growth. In [3] the affairs whose supports are less than min-support and which have no effect on the back item-sets are deleted from the database directly, which reduces the counting speed of candidate item-set and to some extent improves the algorithmic efficiency.

However, the present improved Apriori arithmetic mostly optimizes only one item of Apriori arithmetic, and it?s not very proper for the early warning application of the equipment failure. This paper focuses on the early warning mining of equipment failure, optimizes the improved Apriori arithmetic mentioned in [4], starts with reducing the number of scanning data base and reducing the number of candidate item-set in advance which might become frequent item, and finally proves that this arithmetic improves the efficiency by experiment.



II. ASSOCIATION RULES AND APRIORI ALGORITHM The purpose of association analysis is to figure out the  hidden association and some useful rules of data base, and uses these rules to speculate and judge the unknown matter from the already known information.

_____________________________    We suppose I= { 1 2 mi i i?? } is a collection, and the elements is called item, D is the collection of affair T, and T can be seen as the collection of item, and T I? . There is certain sign of each affair, and TID is its ID number. X is a collection, if T I? , and then we say T includes X.

An association rule is a formula as X Y? , X I? , Y I? , and X?Y=? .The support of an affair X Y? means the ratio of the number of all affairs divided by the collection includes X and Y, i.e.

support ( X Y? ) = P ( X Y? ) (1) The confidence of an affair X Y? means the ration of  X divided by the collection includes X and Y, i.e.

confidence ( X Y? ) = P ( X / Y)  (2) With a certain affair D, the association analysis is to  figure out the rules whose support and confidence are bigger then the min-support and min-confidence.

Apriori is one of the earliest ARM algorithms, and it has four steps:  Given database D, the min-supper and min-confidence.

Step1: Produce candidate item-set 1C : scan the whole  database D; take account of the appearing times of each item, and produce candidate item-set 1C .

Step2: Find out the set of items which are bigger than or equal with the min- support. The item-set is called Set 1L .

Step3: Use a big item-set whose length is k-1 to generate candidate item-set ( kC ).

Step4: Calculate the support of all the candidate item-sets, and judge that whether it is bigger than or equal with min- support. Mining out the candidate item-sets which are qualified to be frequent item-set ( KL ) with the length k.

Step5: Repeat the steps mentioned above until it can?t generate new candidate item-sets.



III. INSTANCE VERIFICATION Through the example of the typical failure in [5], the  relationship between the failure phenomena and the failure category is found out by Apriori algorithm  Suppose that 5 kinds of failure phenomena are recorded as A?E. The failure records are collected, as shown in table 1.Namely, the algorithm of database D.

TABLE I. LIST OF RECORDED FAILURE PHENOMENA  ID failure phenomena ID failure phenomena  1 A,B,C 6 A,C,D  2 A,B,D 7 A,B,D  3 B,C 8 A,B  4 A,B,D,E 9 A,B,C,D  5 A,B Min-support equal 0.3, namely min-support counts for 3,  According to Apriori algorithm, mining association rules steps as shown in figure 1  C1 L1 Item-sets Support  A 8 B  8 C  4 D 5 E 1  Item-sets Support A 8 B  8 C  4 D 5  C2 L2 Item-sets Support  A,B 7 A,C 3 A,D 5 B,C 3 B,D 4 C,D 2  Item-sets Support A,B 7 A,C 3 A,D 5 B,C 3 B,D 4  C3 L3 Item-sets Support  A,B,C 2 A,B,D 4 A,C,D 2 A,B,D 1  Item-sets Support A,B,D 4  Figure 1. Generation procedure of large item-sets by Apriori algorithm

IV. IMPROVEMENT OF APRIORI ALGORITHM With large database, the process of mining association  rules is time consuming. Apriori algorithm is improved by reducing the number of scanning data base and the number of candidate item-set in advance which might become frequent item.

In Apriori arithmetic, computation is as a result of many candidates item-set. In order to reduce the computation, the elements which can?t become the frequent items are deleted in advance in the improvement of Apriori algorithm. Namely after the first traversal, the support is not counted by database D, instead it?s counted by set kF , committing filter by use of K-1L . The items which are not consistent with the min-support are deleted from the database, and in the meanwhile, the affairs whose item number is less or equal k- 1 are deleted, as to reduce kF .

The specific steps of improved Apriori arithmetic are following:  Step1: scan the whole database D; take account of the appearing times of each item, and produce candidate item- set 1C .

Step2: Find out the set of items which are bigger than or equal with the min- support. The item-set is called Set 1L .

Step3: Delete the candidate item-set whose frequency is less than min-support in last step from D.

Step4: Delete the affairs whose item number is less than K.

Step5: Produce kF from the candidate item-set kC .

Step6: Delete all the candidate item-set whose frequency is less than the least frequency, and generating KL .

Step7: Repeat the steps mentioned above until it can?t generate new candidate item-sets.



V. COMPARISON ALGORITHM The improved Apriori algorithm is used in table 1. First  the whole database D is scanned, the appearing times of each item are accounted, and candidate item-set 1C is produced.

As can be seen from the figure,E can?t satisfy min- support, so E is removed, generating frequent set 1L .

According to improved arithmetic, the items including E are deleted from D, generating 2F . According to the character of Apriori and the appearing times in database 2F , 2C is generated. In 2C , {C,D} doesn?t satisfy the min-support, delete {C,D} and generate 2L . According to improved Apriori arithmetic, the items including {C,D} are deleted from 2F .Because item 6 only contains two elements and item 3?5?8 only contain one element, In 3C it?s impossible to be selected, item 3?5?6?8 are deleted. According to arithmetic?s character, 3F can be obtained. According to Apriori?s character and the appearing times in database 3F ,  3C is generated. Thereby the frequent item 3L is finally obtained. The steps of carrying out association rules mining by improved Apriori arithmetic are illustrated as the Figure 2.

C1 L1 Item-sets   Support  A 8 B 8 C 4 D 5 E 1  Item-sets  Support A 8 B 8 C 4 D 5  F2 C2 ID Item-sets  1 {A,B}{B,C}{A,C} 2 {A,B}{B,D}{A,D} 3 {B,C} 5 {A,B} 6 {A,C}{C,D}{A,D} 7 {A,B}{B,D}{A,D} 8 {A,B} 9 {A,B}{A,C}{A,D}  {B,C}{B,D}{C,D}  Item-sets Support A,B 6 A,C 3 A,D 4 B,C 3 B,D 3 C,D 2  L2 F3 Item-sets Support  A,B 6 A,C 3 A,D 4 B,C 3 B,D 3  ID Item-sets 1  {A,B}{B,C}{A,C} 2  {A,B}{B,D}{A,D} 7  {A,B}{B,D}{A,D} 9  {A,B}{A,C}{A,D}  {B,C}{B,D} L3  Item-sets Support A,B,D 4  Figure 2. Generation procedure of large item-sets by improved Apriori algorithm

VI. CONCLUSIONS This paper puts forward existing problems in association  rules mining at first. In order to solve these problems, the improvement of Apriori algorithm is applied to early warning of equipment failure. And through analyzing the example of equipment failure, we can see that the advantages of the improvement Apriori algorithm are as followed comparing with Apriori algorithm:  (1) reduced the number of scanning data base.

(2) reduced the number of candidate item-set which  might become frequent item.

And through the experiment, it is proved that the  improved algorithm is very efficient.

