User Detection in Real-time Panoramic View through

Abstract? Nowadays to manage a big collection of image data  is becoming a major issue for companies as well as for smart  phone device. After panoramic view in camera, elongated fields  of view technology and algorithms has been fully utilizes in  industrial area, commercial systems, painting and mobile devices  such as smart phones and portable computers. But still majority  of panoramic view is only implemented to capture wide angle  scenery or a three-dimensional model. In this paper a cloud  computing service and its application for data synchronization  with multiple cameras has been presented. This service has been  implemented using image extracted data transferring without  multiple devices for synchronization.  For image data analysis, a  dedicated application is developed with single capture device and  each data will be sent to server for image processing computation.

The goal of this research is to provide a better image data  synchronization which perform a faster real-time panoramic  view and analyze human tracking information precisely. In this  system multiple cameras were used with image data  synchronization to get panoramic view and performing human  detection from each panoramic view frames.

The system is setup with multiple camera connected with few  computer where each of them sending image direct to cloud  server and one of machine will be retrieving all image contents  directly from cloud server for information mapping, image  stitching and computation part. For better performance different  cloud server has been used to analyze data transferring size,  speed, computation time with different features tracking method.

Finally this paper concludes with a system which can be specially  use in wide are view for multiple capture devices. This system  can be used in various systems which can help in vehicle safety  system as well as wide are human detection.

Index Terms? Cloud Computing, Human Tracking, Image Processing, information mapping and data synchronization

I. INTRODUCTION  After release of panoramic view in camera, this elongated  fields of view technology and algorithms has not been fully  utilizes in industrial area, commercial systems, painting and  mobile devices such as smart phones and portable computers.

Majority of the panoramic view was only implemented to  capture wide angle scenery or a three-dimensional model such  as some work by Christian Sch?nauer [1-2] to capture wide  area motion tacking with 3d depth sensor.

On other side, Yu-Jin Hong, Jae-In Hwang, Sun-Bum Youn,  Sang Chul Ahn, Hyung-Gon Kim, Heedong Ko [3] used  interactive panorama video viewer with head algorithms. J.

Segen and S. Kumar [4] uses a controlled background to  localize the hand efficiently in real-time. Francois [5] presented  head motion as a new input stream. Rony Ferzli, Ibrahim  Khalife [6] show the importance and benefit of coupling cloud  computing with mobile especially due to power limitation that  mobile devices exhibit and included with head tracking.

In this paper a cloud computing service and its application  for data synchronization with multiple cameras has been  presented which is implemented using image extracted data  transferring without multiple devices for synchronization.

Especially for data analysis, a dedicated application is  developed with single capture device and each data will be sent  to server for image processing computation. To capture  multiple pictures in same time frame and to get panoramic  view and performing human detection from each panoramic  view frames different cameras were used.

However, in this system, the first part is the combination of  multiple photographic images together on the homogeneous  virtual surface. The overlapped regions between images are  match to each other, then images are warped onto the  panorama surface using the estimated camera motion and  geometric relation between the panorama surface and image  coordinates inspired by those in [7], [8]. The outcome of  panoramic images will generate wide scenes of view. It is  sometime known as wide format photography which cannot be  captured by single picture of usual cameras. Thus, panorama  synthesis overcomes the limitations of view angles and  resolutions in the usual cameras. [9] - [11].

On the others hand, real-time capturing with computation  of panoramic images will send to cloud computing part for data  transferring and retrieving. The cloud system become  colloquial expression used to describe a variety of different  types of computing concepts that involve a large number of  computer that are connected through a real-time  communication network. It provides a low-cost, highly  accessible alternative to other traditional high-performance  computing platforms. Cloud computing has many other  benefits such as high availability, scalability, elasticity, and  ISBN 978-89-968650-3-2 1118 February 16~19, 2014 ICACT2014    free of maintenance. Majority of cloud are currently cloud  database and data storing cloud [12].

The main goal of this research is to provide a better and  faster method for image data synchronization through multiple  real-time panoramic camera capture in the most efficient way  with using cloud server included human tracking at the end  results. The system separated into three parts where the first  part is multiple camera capture with computation of panoramic  view frames. Each panoramic frame is sending to cloud server.

The second part will be retrieving all images from cloud server  with computation of overall full panoramic view. Last part will  be human tracking and position in the full panoramic view  frames. Several methods has been analyzed and compare  through during panoramic computation such as FAST Features  Detection, SURF Features Detection, and Harris Corners  Detection. Where else different cloud server has been tested  and compared such as Google Drive, Dropbox, Microsoft  Skydrive, Amazon Cloud Drive and Olleh Ucloud.

In this study, human tracking in real-time camera capture  with wide angle view computation through cloud system is  further implemented which enable the credibility of human  detection, human interaction or vehicles safety system.



II. SYSTEM DESIGN  A. System Overview    Figure.1 shows the overall structure for this system. At first,  we capture wide-angle image for each two HD webcam which  is connected to PC.

Cloud  Cam 1 Cam 2 Cam 3 Cam 4  PC 1 PC 2  Main PC  Panoramic Image with Human Tracking Location  Panoramic Image  Panoramic Images Collection  Panoramic Image   Figure 1. System Structure    These photos will be stitched and used as source of  panoramic image. In order to send the panoramic image from  each computer to same cloud server computed panoramic  image will be label. Overall, a main PC will be functioning as  result output PC to download each image from cloud server  from time to time and stitching all panoramic images into one  whole complete panoramic image. At the same time human  location tracking result will be generated in the main PC as  well.

B. Panoramic View    To generate a panoramic image, this system is computed in  different feature detection methods which are FAST Features  Detection [13-15], SURF Features Detection [16-19] and  Harris Corners Detection [20-21] to compare and analyze the  fastest and the most precise image stitching results. Each of the  detection method will computed a homography that maps the  relation in between images. Different features detection method  will compute different type of mapping result and computation  performance.

1. FAST Features Detection   FAST (Features from Accelerated Segment Test) features  algorithm derives from definition of what constitutes a  ?corner?. As show in Figure 2, FAST method is based on  image intensity around a putative feature point. The key point  is gain by examining a circle of pixels centered at a candidate  point. When an arc of contiguous points of length greater than  3/4 of circle perimeter is found in which all pixels significantly  differ from the intensity of the center point, then a key point is  declared. This algorithm result in very fast interest point  detection and should be used when speed is a concern.

Figure 2. FAST Features Detection    2. SURF Features Detection   SURF (Speed up Robust Features) features as show in  Figure 3, which is the scale-invariant features that has been  introduced in computer vision. SURF not only scale-invariant  features but they also benefit in efficiently computation. The  ISBN 978-89-968650-3-2 1119 February 16~19, 2014 ICACT2014    circles of detected key points change in size is proportional to  the scale change.

Figure 3. SURF Features Detection    To detect the features, the Hessian matrix is computed at each  pixel. This matrix measures the local curvature of a function  and is defined as:    (1)    3. Harris Corners Detection   Harris looks at the average directional intensity change in  small window around a putative interest point.

(2)    The average intensity change can then be computed in all  possible directions which lead to the definition of a corner as a  point for which the average change is high in more than one  direction. Harris is obtained with the direction of maximal  average intensity change. If the average intensity change in the  orthogonal direction is also high, then we will have a corner  point as in Figure 3.1.

Figure 3.1 Harris Corners Detection    Once the interest point in Harris Corners has been detected,  Accord.NET image stitching library has been use to perform  Correlation matching, robust homography estimation and  gradient blending. Correlation matching method will be  measure and matching the interest point extracted from Harris  Corners method. Given a set of correlation points there allow  to pair the points in between two images as show in Figure 3.2.

Figure 3.2. Correlation points Paring.

Next will be Robust Homography Estimation which using  RANSAC for fitting a homography matrix. A robust estimator  of RANSAC will generate a homography matrix from previous  set of correlation feature points. RANSAC is actually an  abbreviation for ?RANdom Sample Consensus?, which is an  iterative method for robust parameter estimation to fit  mathematical models from sets of observed data points which  may contain outliers. RANSAC works by trying to fit several  models using some of the point pairs and then checking if the  models were able to relate most of the points as show in Figure  3.3 as below.

Figure 3.3. RANSAC estimator result.

4.  Homography Matrix The above methods are being used to extract feature points  for homography computation, where the homography matrix is  matching two images. A homography is a projective  transformation, a kind of transformation used in projective  geometry. It describes what happens to the perceived positions  of observed objects when the point of view of observer  changes. In others terms, a homography is an invertible  transformation from the real projective plane to the projective  plane that maps straight lines to straight lines.

ISBN 978-89-968650-3-2 1120 February 16~19, 2014 ICACT2014    By using homogeneous coordinates, which can represent a  homography matrix as a 3x3 matrix with 8 degrees of freedom.

(3)    Homogenous coordinates are very useful because they will  allow the system to perform an image projective  transformation by using only standard matrix multiplication, as  shown by the equation and schematic diagrams above. Once,  all the projected points have been computed. The original  coordinate system is recovered by dividing each point by its  homogenous scale parameter and then dropping the scale factor,  which after division will be set at 1.

Result which following table showing is average of 30 set  data with different execution time by different detection  method.

TABLE 1 FEATURE DETECTION METHOD WITH EXECUTION TIME AND QUANTITY OF FEATURE POINTS RESULT  feature detection methods Average Execution Time  (millisecond)  FAST Feature Detection 449.667  SURF Feature Detection 334.033  Harris Corner Detection 1364.800    Homography matrix that has been computed which allow  our system to perform Blending of two images from  Accord.NET library. The system is using a linear gradient  alpha blending from the center of one image to the other.

Gradient blending works by simulating a gradual change in one  image?s alpha channel over the line which connects the centers  of two images as show in Figure 4 and Figure 5.

Figure 4. Image Blending    Figure 5. Image Blending. Top Left: Camera 1 Image, Top Right: Camera 2 Image, Bottom: Blending of two images.

C. Cloud Computing    In cloud computing we separated images data into  uploading part and downloading part. Panoramic images that  being captured by each two computer will be named and  uploading to cloud server folder for synchronization used.

For uploading part in our system as shown in Figure 1,  stitching images of Cam 1 and Cam 2 for PC1 will be name as  ?ImgPC1.jpg? sending to Cloud server. At here, we were using  SURF Features detection for homography matrix generation  where this is the fastest feature detection method among the  others shown in Table 1. Feature detection matrix only perform  once and same homography will be reuse for next image  stitching. Same goes to Cam1 and Cam2 in PC2 will be named  as ?ImgPC2.jpg?, where else same stitching and features  detection method is same like in PC1 too.

Furthermore, in downloading part of our system, a Main PC  will be operated to download all the images from cloud server  and sorting the images according with images? name. Image  stitching with the same method that was used for image  stitching method PC1 and PC2 will be used. Overall sorted  images will generate a last panoramic view scene. At last,  human tracking will be analyzed from overall Panoramic frame  to extract an exact human location using OpenCV Human  detection.

In our system we had tested and analyze our cloud system  from different third party Cloud server such as Google Drive  Dropbox, Microsoft Skydrive, Amazon Cloud Drive, Olleh  Ucloud with 100kb to 200kb image file.

ISBN 978-89-968650-3-2 1121 February 16~19, 2014 ICACT2014    TABLE 2 CLOUD SERVER UPLOADING  Cloud Server Uploading Time (s)  Google Drive 4  Dropbox 3  Microsoft SkyDrive 11  Amazon Cloud Drive 8  Olleh Ucloud 13    D. Human Detection  Human recognition [22] is an easy task for humans. Our  system included human tracking that using EmguCV (OpenCv  C#) Human Detection & Haar Classifier where referring the  face recognition in [23]. EmguCV is an open source computer  vision library which is cross platform .Net wrapper to OpenCv  image processing library. EmguCV allow openCV function to  be called from .Net. In our system each frame that gathers at  main PC will be run through image stitching to generate overall  view. In term of that, a human tracking algorithms will be  functioning as human location tracking machine where will  output the human location in the panoramic image as show in  Figure 6 as below. This system able to perform a high accuracy  location in images.

Figure 6. Human detection in Main PC Panoramic image.



III. REAL-TIME PANORAMIC USER DETECTOR CLOUD SYSTEM  Real-time camera capture has been widely used and  implemented in human tracking broadcast system [24-25]. As  in our system, the real-time panoramic system conducts precise  and high resolution images stitching. Then system blends each  frame before sending and after retrieving from cloud server.

Different methods of features extraction enable the most  natural images being compute in most efficient time. Real time  images will be uploading and downloading through cloud  server agency over internet. Cloud server agency like Dropbox,  Amazon Cloud, Microsoft Skydrive and Olleh Ucloud has been  analyzed with the server synchronization speed. Dropbox,  which has been tested as the most efficient cloud server, with  the benefit of cloud agency, maintenance and cost for server  will be highly reduce.

Through the experiment and data analyzing, we use SURF  Detection where having 334.033 millisecond of fastest  execution time for image stitching homograpghy generation.

Beside we used dropbox as the fastest image data cloud  transferring tools which was 3 second per frame for uploading  time. Though this experiments, hardware requirements and  internet speed also will bring different result for overall cam  captured images.

Instead of having a good security system providing by  cloud server agency, Cloud system enable to work portable  over wifi or land network which we can setup our system at  any location all over the world as long as connected to internet.

Our system is added and tested with Human tracking of overall  panoramic images where enable tracking an exact human  location in wide area view images which can be further  improve and implement the human tracking system over wide  area traffic secure system, wide area football match system,  360 degree 3D view system and wide area filming system.



IV. CONCLUSION  The main goal of this research is to provide a better and  faster method for image data synchronization through multiple  real-time panoramic camera capture in the most efficient way  with using cloud server included human tracking at the end  results. Consequently, the analyzed data of the result of this  system which enable precise feature detection for panoramic  image generation. Beside, multiple capture devices sharing  data information with better computation speed and user  mapping location precisely in a wide area view. These systems  enable the credibility of wide area human detection, traffic road  safety system, human interaction or vehicles safety system.

