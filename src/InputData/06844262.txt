

Abstract- As powerful computers and cameras have become wide spread, the number of applications using vision techniques has increased enormously. One such application that has received significant attention from the computer vision community is traffic surveillance. We propose a new event detection technique for detecting abnormal events in traffic video surveillance. The main objective of this work is to detect the abnormal events which normally occur at junction, in video surveillance. Our work consists of two phases 1) Training Phase 2) Testing Phase.

Our main novelty in this work is modified lossy counting algorithm based on set approach. Initially, the frames are divided into grid regions at the junction and labels are assigned.

The proposed work consist of blob detection and tracking, conversion of object location to data streams, frequent item set mining and pattern matching. In the training phase, blob detection is carried out by separating the modelled static background frame using Gaussian mixture models (GMM) and this will be carried out for every frame for tracking purpose.

The blobs location is determined by assigning to the corresponding grid label and numbered moving object direction to form data streams. A modified lossy counting algorithm is performed over temporal data steams for discovering regular spatial video patterns. In testing phase, the same process is repeated except frequent item set mining, for finding the spatial pattern in each frame and it is compared with stored regular video patterns for abnormal event detection. The proposed system has shown significant improvement in performance over to the existing techniques.

Keywords? Blob detection, Blob tracking, Spatial patterns, Lossy Counting Algorithm, GMM.



I. INTRODUCTION Computer vision and video analysis techniques play an important role in modern intelligent systems. Video-based systems can capture a larger variety of desired information and are relatively inexpensive because cameras are easy to install, operate, and maintain. With the huge amount of video cameras installed everywhere now a days, there is an urgent need for automated video understanding techniques that can replace human operators to monitor the areas under surveillance [2]. Video surveillance has gained importance in security, law enforcement and military applications and so is an important computer vision problem. As more and more surveillance cameras are deployed in a facility or area, the demand for automatic methods for video processing is increasing.

Traffic control and monitoring using video sensors has drawn increasing attention recently due to the significant advances in the field of computer vision. However, robust  and accurate detection of abnormal events in video data still remains a difficult problem for the majority of computer vision applications. Especially in case of outdoor video surveillance systems, the traffic rule violation problem is particularly challenging due to due to size, unrestricted flow of video data streams [4]. In this paper, our aim is to present a novel intelligent traffic video surveillance system for video traffic analysis, and detecting traffic rule violation which commonly occurs at the junction.

In general, systems developed for traffic surveillance purposes aim at having a understanding of the real time traffic conditions, which require the analysis of the static environment and the detection of static or moving obstacles, such as vehicles, bicycles, and pedestrians. Image processing and computer vision techniques are being applied to the analysis of video sequences of traffic, in order to extract - traffic information, such as vehicle counting, vehicle classification, speed measurement, traffic flow, and so on.

Fig. 1. Illegal U-turn Event   As more and more surveillance cameras are deployed in a  facility or area, the demand for automatic methods for video processing is increasing. The operator constantly watching the video footages could miss a potential abnormal event, as the amount of information/data that has to be handled is high.

So there is a need for surveillance system which supports a human operator by automatically detecting abnormal events and drawing the operator?s attention to such events. An example for illegal event or abnormal event in traffic is junction crossing shown in Fig.1 [19]. This work is used to       detect abnormal events such as a traffic rule violation in traffic junction.

The remainder of this paper is organized as follows.

Section II describes the related work. Section III describes the proposed event detection system in detail. Section IV describes experimental results, discussions. The conclusion is given in Section V.



II. RELATED WORK Nan Dong et al. [1] proposed an algorithm for automatic  abnormal event detection. They used directional motion behavior descriptor to collect moving object's direction and speed. In detection stage, the directional motion behaviour is extracted from the incoming video and compared with the normal behavior descriptor.

Lili Cui et al. [2] proposed a method for abnormal event detection based on local features for traffic video surveillance. Here, the moving foreground is detected first and area of foreground region, shape factors and velocity of the moving pixel vector is extracted. Then using a simple classifier, determine the objects states of normal or abnormal.

Shunsuke Kamijo et al. [3] proposed semantic hierarchy algorithm for 1) logical reasoning for identifying individual behavior 2) logical reasoning focusing on relative behavior 3) classification of continuous viable. These three classes are used for detecting abnormal events in traffic video surveillance. Lairong Chen et al. [4] proposed an automatic incident detection algorithm using support vector machines (SVM). The SVM is selected as, the incident point velocity, the downstream velocity, the upstream velocity, the incident point occupancy rate, the upstream occupancy rate and the downstream occupancy rate. The incidents are detected using the output of SVM.

Wei-Lieh Hsu et al. [5] proposed vision based traffic incident detection method. Here cellular model is created by extracting entropy based features. If abnormal event detection happens on the vehicular lane, the events are detected immediately. Claudio Piciarelli et al. [6] proposed a method for abnormal event detection using trajectory information.

This approach is based on SVM clustering. SVM capabilities are used to identify anomalous events. Trajectory classification method was used to classify the abnormal events from normal events. Harini Veeraraghavan et al. [7] proposed abnormal event detection system using kalman filter and some simple rules. They use multiple cues and multiple motion models for tracking and event detection. Based on some simple rules the abnormal events are differentiated from normal events. The disadvantage of this work is incorrect target estimation and threshold value.

Andrew Gilbert et al. [8] proposed an action recognition system using association rule mining. Initially, 2D corners in both and space are created. These corners are grouped spatially and temporally using hierarchical process. In each stage of hierarchy descriptive and distinctive features are learnt through data mining and frequent occurring patterns are identified. Based on these frequent patterns actions are recognized. Statistical methods are proposed that make use of the statistical characteristics of individual pixels. These statistical methods are mainly inspired by the background subtraction methods in terms of keeping and dynamically updating statistics of the pixels that belong to the background image process [13][14].

H. Fujiyoshi et. al. [15] proposed Temporal differencing technique which attempts to detect moving regions by making use of the pixel- by- pixel difference of consecutive frames in a video sequence. This method is highly adaptive to dynamic scene changes. R. Cutler et. al. [16] proposed temporal self-similarity method based on moving object. The methods exploit this clue to categorize moving objects using periodicity. Swears et al. [17] proposed a hierarchical agglomerative HMM-based trajectory clustering and activity pattern learning method. They used partial vehicle trajectory observations by sliding window technique to detect vehicle deviations from lanes.

Lin et al. [18] describe a novel method for real-time traffic accident detection based on image tracking. Kalman filter and active contour model are used in combination to track individual vehicles. By finding out overlapped contours of vehicles, collisions are detected.



III. PROPOSED WORK The proposed abnormal event detection method is used to detect the abnormal events such as traffic rule violation in traffic junction. There are two phases in this method. The first is the training phase, and second is the testing phase. In the training phase, a section of normal surveillance videos are selected as a training sample to generate frequently occurring spatial patterns (normal events). In the testing phase, the stored spatial patterns are compared with incoming patterns.

The event detection work consists of object detection and tracking, Conversion of object region to data streams; frequent item set mining and Pattern matching. The following Fig. 2 shows the architecture for abnormal event detection in traffic junction. Initially, the moving foreground objects in the video are detected and tracked using Gaussian Mixture Model (GMM).Then the junction is divided into equal number of grids and labels are assigned to each grid. After assigning labels to grid, spatial location of each moving object in each grid is stored. Then, the object locations are converted into set of data sequences. Finally, based on the pattern matching procedure the frequent item sets are compared with the other sequences and the abnormal events are detected.

Fig 2: Architecture for Abnormal Event Detection  A. Object detection and Tracking       The main purpose of object detection is to detect the moving foreground vehicles from the video. Effective foreground object detection is very important, because the follow-up operations such as tracking, classification etc. are based on the results of this moving object detection. In this paper, Gaussian Mixture Model (GMM) [9] is used to detect the moving foreground vehicles. Here EM algorithm is used to initialize this GMM model.For the foreground detection, each pixel is compared with each Gaussian and is classified according to it corresponding Gaussian. In this model [9], the values of an individual pixel over time is considered as a ?pixel process? and the recent history of each pixel, X1,X2,X3 . . . ,Xt, is modeled by a mixture of K Gaussian distributions.

The probability of observing current pixel value is calculated from below eq(1):  ? =  ? ?= K  i titittit XwXP  ,,, ),,()( ??         (1)  where tiw ,  is an estimate of the weight of the ith Gaussian (Gi,,t) in the mixture at time t, ?i,t is the mean value of Gi,t and i,t is the covariance matrix of Gi,t and Gaussian probability density function:  )()(2/1 2/12/   )2( 1),,( ???? ????  ?  ?? =? XX  n  T  eX          (2)  Decision on K depends on the available memory and computational power. We have chosen k=5 for optimal performance. For Computational efficiency, the assumption of covariance matrix will be in form of :  I tk k? =, 2?            (3)  The assumption for red, green and blue color components are independent and have the same variance.

The procedure for detecting foreground pixels is as follows.

First, the initialization for K Gaussian distributions of the pixel are fixed with predefined mean, high variance and low prior weight. For an observed new pixel in the image sequence, we will check its RGB vector against K Gaussians, until a match is found. Generally a match is defined as a pixel value within ?  standard deviations of a distribution. In our case, it was assumed to be 2.5. Next, the prior weights of the K distributions at time t (wk,t), are modified as per below eq(4):  )()1( ,1,, tktktk Mww ?? +?= ?           (4) Where ?  is the learning rate and M(k, t) is 1 for the matching Gaussian distribution and 0 for the remaining distributions. Consequently, the prior weights of the Gaussian distributions are normalized with the new equations as follows:  )()1( 1 ttt X???? +?= ?           (5) )()()1( 2 1  tt  T tttt XX ?????? ??+?= ?        (6)  Where, ),|( 11 ??= tttX ?????            (7)   If there was no match found for the current observed pixel, the least probability corresponding to Gaussian distribution is replaced with new Gaussian distribution with the current pixel values as its mean value, an initially high variance and low prior weight.

In order to detect the type (foreground or background) of the new pixel, the sorting of K Gaussian distributions are done by the value ? /? . This ordered list of distributions reflects the most probable background from top to bottom. Background pixel processes make the corresponding Gaussian distribution have larger prior weight and less variance. The background model is modeled using first B distributions,  ? =  >= b  k kb  TB  )(minarg ?                                       (8)  Where T is the minimum portion of the pixel data that accounts for the background.

During implementation process, the first five frames are taken as static frames with no moving objects in the video. By using these static frames, the system is trained to detect foreground objects.

B. Conversion of object locations to  Data Stream First the junction is divided into equal of grids and labeled as A,B,C,D,E,F,G,H,I,J,K,L,M,N,O as shown in Fig.3. The moving object directions are quantized into four directions (North, East, South, and West) and are numbered as shown in Fig.4. For every frame, the object location is determined based on its presence in the spatial grid and corresponding grid labels along with numbered object direction are assigned to form transactional data streams in alphabetical order.

Fig. 3 : Assigning Labels to Grids       Fig. 4 Assigning Numbers to Each Direction   For example, if the object is moving in a straight road from bottom left to top left in a sequence of frames then transactional data streams are created as shown in Table 1.

TABLE 1: DATA STREAM CONVERSION (Bottom left to top left)   Transaction ID  (Frame ID) Data Items  T1 K1 L1 T2  F1 G1  T3 A1 B1   If the objects are moving opposite lanes, one is from bottom left to top left and other is from top right to bottom right in a sequence of frames then transaction data streams are created as shown in Table 2.

TABLE 2: DATA STREAM CONVERSION  (Top right to bottom right)   Transaction ID (Frame ID) Data Items  T1 C3 D3 E3 H4 K1 L1 M2  T2   F1 G1 H4 I3 J3 M2  T3 A1 B1 H4 M2 N3 O3  C. Frequent Item set Mining Stream of transactions are formed by assigning labels to  the objects based on their spatial locations and their moving directions. To find the frequent item sets from stream of transaction a modified lossy counting algorithm is used.

Stream of transactions or frames are given as the input for modified lossy counting algorithm. Each transaction consists of set of spatial locations and their moving directions. Here, N denotes the current length of the transactions. The user has to specify one parameter: support s. Handling variable sized transactions and avoiding enumeration of all subsets of transaction is big challenge here. Data structure D is in the form (set, f), where f is an integer which represents the frequency count, and set is a spatial items. In the initial stage, D is empty. The incoming transactions of each frame are added to the initial set. For each new incoming transaction frequency count is increased by one.

Modified Lossy Counting Algorithm  Input: Data Stream Sn, error rate ?, support threshold s Output: Frequent Item set with threshold s Begin  1. Initially D is empty, n=0 2. For each sequence set Sn of every transaction S 3. n=n+1; bcurrent= ?n 4. If(set Sn exists in D or subset of existing set in D) 5. f(existing set) = f(existing set)+1  // existing data  set value is retained 6. else if(set Sn is superset of the existing set in D) 7. f(existing set)= f(existing set)+1 8. existing set in D=set Sn // existing dataset in D  is replaced with new data set Sn 9. else add entry(set,1) to D; 10. end if 11. output each sequence set in D  where f(set)+?(set)>=s 12. end for  end   If the incoming transaction is already in the data structure  or is a subset of the existing data set; then frequency count is increased by one. If the incoming data set is superset of the existing data sets, then frequency count is increased by one and old entry will be updated with new data set. Then,  based on the threshold value, the less frequently occurring patterns are removed and the remaining are considered as frequently occurring patterns. These frequently occurring patterns are taken as normal events and other patterns are taken as abnormal events. In the training phase, video with flow of regular traffic events are taken as input and frequently occurring patterns are find out. In the original lossy counting algorithm, set generation is carried out by using trie data structure and buffer is allocated for each transaction. But in this modified lossy counting algorithm only subsets and super sets are considered. No buffer is allocated.

After finding the patterns, frequently occurring patterns were found by applying threshold value. Patterns with the frequency count below the threshold value were removed and frequency count above the threshold value was taken as frequent item sets. The threshold value is determined by the user based on the length of the training video and periodicity of the traffic rules.

D. Pattern Matching In the testing phase, the above processes (object detection  and tracking, data stream conversion) are performed to find the spatial traffic pattern for each frame. These spatial patterns of each frame were compared with stored regular patterns. If the spatial pattern of each frame is equal or subset of the stored patterns, then it is considered as normal events.

Otherwise, the frame is considered to contain abnormal event.

The Brute Force algorithm [20] is used to compare the pattern to the frequently occurring pattern one character at a time.

1. do 2. if( spatial letter == stored pattern letter) 3. compare next letter of pattern to next letter of stored  pattern letter.

4. else 5. move to next stored pattern 6. while(entire pattern found or end of text)   IV IMPLEMENTATION RESULTS & DISCUSSIONS    Fig. 5: Output for Object Detection       In order to evaluate the proposed abnormal event detection framework, a busy traffic data set, containing videos of length 1 hour (90000 frames), and frame size of 360 * 288 is taken from www.eecs.qmul.ac.uk. The data set contains all the regular and irregular traffic rules. This framework was implemented in MATLAB 2010 with 2 GB RAM. Fig. 5 shows the output of blob detection.

Here, the moving foreground objects are detected. Fig. 6 shows the result of moving vehicle tracking. The bounding rectangle shows the tracked vehicles. Fig. 7 shows the results for frequent item set mining. Frequently occurring patterns are determined by learning the video.

Fig. 6: Output for Object Tracking   In Fig.7 first three patterns represents the scenario of the  objects moving in opposite lanes and some are moving from bottom right in a sequence of frame. Patterns 4,5,6 represent the scenario of objects static at spatial locations K,L,M,C,D,E and others are crossing from left side to right side of the frame passing through locations F,G,H,J,J or F,G,H,I,N,O.

Patterns 7,8,9 represents the regular patterns representing the scenario of objects static at spatial locations K,L,M,C,D,E and others are moving from right side to left side of the frame passing through spatial locations J,I,H,G,F or J,I,H,G,F,A,B.

Fig. 7: Frequent Item Set Mining Results   Fig. 8 shows the irregular spatial patterns corresponding to the traffic rule violation in frames. 8th pattern represents  incorrectly classified pattern or false positive pattern.

Remaining patterns represents correctly classified as traffic rule violated frame.

In order to evaluate the proposed training model with rule violation scenes, traffic junction data sets are used. The performance evaluation of the abnormality detection tests was implemented with data sets. The main scenario to be considered here is traffic rule violation. In the synthetic environment, 9 different traffic events and 7 abnormal events were used. The evaluation results are shown in Table 3. From 9 abnormal events our method detects 8 abnormal events. So detection rate is 89%.

The True-Positive Rates (TPR) indicates the percentage of successfully detected abnormal events. The False-Negative rates (FNR) indicate the proportion of missing actual events that were not detected.

Fig. 8: Abnormal Event Detection Results   TABLE 3: ABNORMALITY DETECTION RESULTS   PREDICTED EVENT  Event 9  TPR 0.89  FNR 0.11  The false-positive events mostly occur when a vehicle has slight lane deviation compared with the underlying route models. The true positive rate (TPR) and false negative rate (FNR) is calculated by the following equations (9,10).

(9)  (10)  d is the number of correct predictions that an instance is positive. c is the number of incorrect of predictions that an instance negative.

In order to evaluate the performance of the proposed model, several studies were reviewed and compared according to traffic pattern analysis and abnormal event detection results. As per police reports, the abnormality detection rate is 66%. Only 9 incidents were analyzed by our       model with an 89% incident detection success having a very low miss rate. The results were more satisfactory considering the detection of severe crashes.

TABLE 4: COMPARISON WITH EXISTING WORK    METHOD DETECTION RATE Zou Method [12] ( using ROI) 84 %  Lee Method [11] (using SVM) 60 %  Proposed Abnormal Event Detection Method 89 %

V. CONCLUSION AND FUTURE WORK This work proposes a new approach to detect abnormal  traffic events such as traffic rule violation by observing traffic scenes at intersections. Our main novelty in this work is the modified lossy counting algorithm based on set/ subset/ superset approach for finding frequent item set. Instead of generating candidate set using trie in earlier approach, we use set method. Experimental results shown that the proposed abnormal event detection approach is capable of detecting more abnormal events than the existing works. So this method is well suited for real time traffic analysis. The results obtained from our experiments on junction dataset show that this approach is effective for abnormality deduction. In order to detect abnormal traffic events, first, normal vehicle flow patterns at the traffic scene junction are learned to differentiate with usual and unusual motion patterns. Second, using stored frequent regular spatial patterns and rule violation datasets, the abnormal events at junction are detected. The proposed system has shown 89% performance as compared to existing techniques. In future aerial view traffic data set will be collected for occlusion free detection, in order to improve the overall performance of the system.

Based on the current approach, the model is planned to be generalized for real-time traffic event analysis at intersections. Online detection of severe traffic incidents will help traffic operators to take immediate actions.

