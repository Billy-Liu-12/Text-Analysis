Digital Image Compression using Neural Networks

Abstract?Compression of data in any form is a large and active field as well as a big business. Image compression is a subset of this huge field of data compression, where we undertake the compression of image data specifically. Research in this field aims at reducing the number of bits needed to represent an image. Inter-pixel relationship is highly non-linear and unpredictive in the absence of a prior knowledge of the image itself. Thus Artificial Neural Networks has been used here for image compression by training the net using the image to be compressed. The ANN takes into account the psycho visual features, dependent mostly on the information contained in images. The algorithms, on application on the image data preserves most of the characteristics of the data while working in a lossy manner and maximize the compression performance. The results have been checked with and without the use of quantization, and without median filtering of the image. The ANN algorithm used here is mainly the back-propagation of multilayer perceptrons.

Keywords?Compression, ANN, median filter, back- propagation, multilayer perceptrons.



I.  INTRODUCTION Data compression has become a necessity for saving  bandwidth, power, storage space, etc. Thus it has turned out to be a present day craze as well as source of competition in the race for technology and research with so much manpower, time and money involved for its development. Out of the image compression techniques available, transform coding is the most preferred method [1] [2] [3]. Since energy distribution after transform coding varies with each image, compression in the spatial domain is not an easy task [4]. Images do however tend to compact their energy in the frequency domain making compression in the frequency domain much more effective.

Transform coding is simply the compression of the images in the frequency domain [5]. So transform based techniques like DWT, DCT, SVD, DWT-DCT, DWT-SVD, etc. have been extensively used [6] [7].

It is known that compression algorithms can be classified into two types ? ?lossy? and ?lossless?. If the recovered image (after decompression) does not have the same quality as the original image then there has been a loss of some image data during compression. This is called a ?lossy compression algorithm?. But some algorithms have the ability to retain the quality of the image, even after the compression, and the decompression processes. Such algorithms come under the category of ?lossless compression algorithms? [7].

Among learning algorithms, back-propagation algorithm is a widely used learning algorithm in Artificial Neural Networks.

The Feed-Forward Neural Network architecture is capable of approximating most problems with high accuracy and  generalization ability [8] [9]. This algorithm is based on the error correction learning rule. Error propagation consists of two passes through the different layers of the network, a forward pass and a backward pass. In the forward pass the input vector is applied to the sensory nodes of the network and its effect propagates through the network layer by layer. Finally a set of outputs is produced as the actual response of the network.

During the forward pass the synaptic weight of the networks are all fixed. During the back pass the synaptic weights are all adjusted in accordance with an error-correction rule. The actual response of the network is subtracted from the desired response to produce an error signal. This error signal is then propagated backward through the network against the direction of synaptic conditions. The synaptic weights are adjusted to make the actual response of the network move closer to the desired response.



II. THE IMAGE COMPRESSION PROCEDURE Digital images have become very popular in recent times.

Every digital image is specified by the number of pixels associated with the image. Each pixel in a gray-level image is described by an intensity of the image at that point. An image that is 256 x 256, means that there are 65536 pixels (intensity points) in the image in a matrix form with 256 rows and 256 columns.

Digital images are basically classified into two types: grayscale images and color images. Any color can be defined by the combination of the three primary colors ? red, green and blue. A grayscale image has no color information. Therefore, very pixel in a grayscale image has different shade of gray which is commonly represented by 8(Unsigned integers of 8 bits). So, there is 28 = 256 possible intensity values (shades of gray) for a grayscale image ranging from 0 to 255. The depth of the image is said to be 8, since 8 bits are used to represent each pixel.

Since 8 bits are used to represent each pixel, to represent an image which is of dimension [256 x 256, 256 x 256 x 8] = 524288 bits are needed to represent the image. With limited memory space, it becomes useful to compress the digital image so that it occupies less memory and also becomes easier to share over a medium such as the internet.

MATLAB? has been used to implement the program. The well-known ?Lena? (tiff format used here) grayscale image (256 x 256) has been used to demonstrate the technique. Each pixel in an image can be denoted as a coefficient, which represents the intensity of the image at that point. Then, the idea of compressing an image is to encode these coefficients with reduced bits and at the same time, retain the quality of the image to satisfactory limits. Once compressed, these coded   DOI 10.1109/ACT.2009.38        images which occupy less memory space can be transferred over the internet medium. At the receiving end, these compressed images need to be again decoded or decompressed so that one can recover the original image. The quality of the received image can be tested by some standard error calculations. The mean of all the squared errors for all the pixels, called the MSE (Mean Square Error) can be used for this purpose. The higher the value of this MSE, lower the quality of the decompressed image.

The multi-layer feed-forward neural net has been used to compress images. The Lena image that has been used for compression purposes is a 256 x 256 image. This image can be broken into blocks of size 8 x 8. There will then be 64 pixels per block. Totally, there will be [32 x 32] = 1024 blocks. The 64 pixels in each block then becomes the input vector to the neural net. The main idea in using a neural network to compress images is to code these 64 coefficients using a reduced number of coefficients (reduce the dimension of the data). The neural network architecture is very helpful in this context. If one can reduce the number of dimensions in the hidden layer (number of hidden neurons) to be much less than the number of dimensions in the input layer, then there will be a reduction in the number of coefficients during the transition from the input to the hidden layer. An input layer with 64 dimensions and a hidden layer with 8 (any number less than 64) dimensions, for example, means that the 64 pixels of the image (8 x 8) block which is applied to the input layer has been transformed into 8 coefficients in the hidden layer. Then, one could again use an output layer which has 64 dimensions to recover the original 64 pixels. The basic idea here is to learn the identity mapping or rather associative mapping which means the output of the neural net is the same as its input.

Thus, with a 64 dimensional input layer, an 8 dimensional hidden layer, and a 64 dimensional output layer ? the neural network has been used for image compression.

In this image compression technique, the compression is achieved by training a neural network with the image and then using the weights and the coefficients from the hidden layer as the data to recreate the image. This will be very clear with an example.

If each pixel is encoded using 8 bits, then the total number of bits to be transmitted without compression is [256 x 256 x 8] for a [256 x 256] pixel image. A [256 x 256] pixel image is split into [4 x 4] or [8 x 8] or [16 x 16] pixel sub-images. The normalized pixel value of the sub-image is the input to the nodes. 64 input layers (in case of [8 x 8] sub-image size) are taken with 1 pixel input to each layer. The three-layered back propagation-learning network has been trained with each sub- image. The number of neurons in the hidden layer will be taken according to the desired compression. Here, we have taken 8 hidden layers. The number of neurons in the output layer will be the same as that in the input layer (64 in our case). The input layer and output layer are fully connected to the hidden layer.

The weights of synapses connecting input neurons and hidden neurons and weights of synapses connecting hidden neurons and output neurons are initialized to small random values from say ?1 to +1.

Only the weights between the hidden layer and the output layer are required for reconstruction. So, the numbers of weights are [64 x 8] and number of bits used to represent them are [64 x 8 x 8].  The input layer uses linear activation function.

The hidden layer units evaluate the output using the sigmoid function. The output layer neuron evaluates the output using linear activation function. As the image is split into [8 x 8] pixel blocks, the total number of blocks become [32 x 32] and for each sub-image, the number of coefficients out of the hidden layer is 8. So, the total numbers of coefficients are [32 x 32 x 8]. Thus, total number of bits required to represent the coefficients are [32 x 32 x 8 x 8].

Total number of bits to be transmitted without compression, Tb = [256 x 256 x 8]. After training the network, number of bits to be transmitted, Cb = [(32 x 32 x 8 x 8) + (8 x 64 x 8)].

Therefore compression achieved is:  Compression= [(1 ? Cb/Tb) x 100%] ? 87%                     (1)  At the receiving end, the image is reconstructed by multiplying the weights between the hidden layer and the output layer to the corresponding coefficients obtained from the hidden layer.

The network is trained using the Polak ? Ribiere Conjugate Gradient Algorithm which is a variation of the back- propagation algorithm used for faster convergence. The algorithm is implemented in MATLAB as the traincgp in ? built function. In conjugate gradient algorithms, a search is performed in the conjugate gradient direction to determine the step size, which is varied at each iteration to reduce the performance function. The compression performance is assessed in terms of Compression ratio, PSNR and execution time. The execution time is measured from the time of start of training until the error saturates to a minimum and the traincgp function stops execution.

Histogram equalization is also implemented in our project, in order to reduce training time. It does not introduce new intensities in the image. Existing values will be mapped to new values resulting image with less number of the original number of intensities. Hence, frequency of occurrence of gray levels in the image will be more are less equal or rather uniform by the mapping. Due to this most of the image blocks will be similar and hence the learning time should get reduced. However, using histogram equalization has been found to be not of good use as the error using this technique remains high.

In another attempt to reduce training time, highly correlated sub-images have been eliminated. Typical values of correlation coefficients above which the sub-image is removed, lies in between 0.7 to 0.8. As a result, the training set gets reduced and hence the training time. This process has been satisfactory in achieving lower training times. The quality of reconstructed images is assessed using measures like Peak Signal to Noise Ratio (PSNR).



III. THE TRAINING ALGORITHM Firstly normalize the inputs and outputs with respect to  their maximum values. It has been observed that the neural networks work better if input and outputs lie between 0-1.

Assume that the number of neurons in the hidden layer lie within a particular defined range. Initialize the weights connecting the input neurons and hidden neurons and the weights connecting the hidden neurons and output neurons, between 0 and 1. For the training data, present one set of inputs and outputs. Present the pattern to the input layer as inputs. By using linear activation function, the output of the input layer may be evaluated. Compute the inputs to the hidden layer by multiplying corresponding weights of synapses. Let the hidden layer units evaluate the output using the sigmoid function.

Compute the inputs to the output layer by multiplying corresponding weights of synapses. Let the output layer units evaluate the output using linear activation function. Calculate the error and the difference between the network output and the desired output. Lastly adjustments in the weights are made until the error (MSE) reaches the desired level with allowable tolerance value

IV. RESULTS AND DISCUSSION The two main images ?Lena? and ?Baboon? have been  analyzed without using median filtering (which is very important for the salt and pepper type noise created due to the blocking artifacts). These are represented in Table I and II respectively.

TABLE I.   256 X 256 LENA IMAGE; 8 HIDDEN LAYER NEURONS (WITHOUT USING MEDIAN FILTER).

Type PSNR before Quantization  (in dB)  PSNR after Quantization  (in dB)  Time of Convergence  (in Sec)  Compression %  With Histogram  Equalization 24.70 22.43 169.23 86.72%  Without Histogram  Equalization   28.87   24.40   175.29   86.72%  Removing Highly Co-  related training vectors  28.34 25.22 85.23 86.72%  TABLE II.  256 X 256 BABOON IMAGE; 8 HIDDEN LAYER NEURONS (WITHOUT USING MEDIAN FILTER).

Type PSNR before Quantization  (in dB)  PSNR after Quantization  (in dB)  Time of Convergence  (in Sec)  Compression %  With Histogram  Equalization 17.92 17.97 88.98 86.72%  Without Histogram  Equalization 23.91 22.76 109.26 86.72%  Removing Highly Co-  related training vectors  23.84 23.09 98.25 86.72%    The images are shown with the highly co-related training vectors removed from the training input set of the neural network with maximum allowable correlation coefficient < 0.8 in Figure 1 and 2.

(a)   (b)   (c)   (d)  Figure 1.  Images with the highly co-related training vectors removed from the training input set of the neural network (a) Original Image (b) Image  reconstructed without quantization (c) Image reconstructed after quantization (d) Image after using median filter after quantization   (a)   (b)   (c)   (d)  Figure 2.  Images with the highly co-related training vectors removed from the training input set of the neural network.(a) Original Image (b) Image  reconstructed without quantization (c) Image reconstructed after quantization (d) Image after using median filter after quantization        The highly correlated training vectors have been eliminated and the following results have been obtained for different values of correlation coefficients as in Table III. A 256 x 256 satellite image has been used. No. of hidden layer neurons is 8.

PSNR values are obtained without using histogram equalization and median filter. The details for three different allowable correlation coefficients are provided as in figure 3, 4 and 5. Here the maximum allowable correlation coefficients are chosen to be less than 0.65, 0.75 and 0.85 respectively. These have been checked for PSNR values before and after quantization as well as after quantization and median filtering.

The time for convergence data provided in all three tables I, II and III are for Pentium? 4 Core2Duo? 1.8 GHz PC with RAM being 512MB in the Windows XP? operating system. This time of convergence reduces as we re-run the program again and again(this is for the first successful run in each case).

TABLE III.  256 X 256 SATELLITE IMAGE; 8 HIDDEN LAYER NEURONS (FOR DIFFERENT MINIMUM CORRELATION COEFFICIENTS).

Minimum correlation coefficient upto which  training vectors are eliminated  PSNR before  Quantiz- ation  (in dB)  PSNR after  Quantiz- ation  (in dB)  PSNR after Quantiz-  ation And  Median Filtering (in dB)  Time of Convergence  (in Sec)  Compression %  0.65 29.24 28.55 29.05 58.87 86.72% 0.75 29.16 27.20 28.93 65.16 86.72% 0.85 28.07 25.08 26.20 125.52 86.72%     (a)   (b)   (c)   (d)  Figure 3.  Images with the highly co-related training vectors removed from the training input set of the neural network (maximum allowable correlation  coefficient < 0.65) (a) Original Image (b) Image reconstructed without quantization (c) Image reconstructed after quantization (d) Image after using  median filter after quantization   (a)   (b)   (c)   (d)  Figure 4.  Images with the highly co-related training vectors removed from the training input set of the neural network (maximum allowable correlation  coefficient < 0.75) (a) Original Image (b) Image reconstructed without quantization (c) Image reconstructed after quantization (d) Image after using  median filter after quantization   (a)   (b)   (c)   (d)  Figure 5.  Images with the highly co-related training vectors removed from the training input set of the neural network (maximum allowable correlation  coefficient < 0.85) (a) Original Image (b) Image reconstructed without quantization (c) Image reconstructed after quantization (d) Image after using  median filter after quantization        Increasing the number of hidden layer neurons reduces compression. This happens because the compressed data consists of the coefficients from the hidden layer neurons; and the weights between the hidden layer and the output layer.

Reducing the number of hidden layers reduces the number of these weights. Hence, less number of bits is required to represent the data. For example, for a 256 x 256 grayscale image, 4 hidden layer neurons give a compression of 93.36% whereas 16 hidden layer neurons give a compression of 73.44%.

A multilayer neural network may be used to approximate any arbitrary Non-linear function provided it has one or more hidden layers with sufficient number of neurons in them. The more the number of hidden neurons, the better is the approximation and lesser is the error. As the number of hidden neurons was increased, we obtained better values of PSNR and lesser error, although at the cost of reduced compression. For example, for a 256 x 256 grayscale image, 4 hidden layer neurons and compression without histogram equalization, PSNR of 26.24 dB is obtained whereas 16 hidden layer neurons give a PSNR of 30.92 dB after median filtering.

The histeq in ? built function from MATLAB? has been used to implement histogram equalization. It has been observed that on performing histogram equalization and using that image to train the network, the network converges a bit earlier.

However, the error (MSE) saturates at a higher value and the quality of the reproduced picture is not good. This is clearly visible from the data provided for both 128 x 128 and 256 x 256 grayscale images. For example, for a 256 x 256 grayscale image and 4 hidden layer neurons, training time is 88.98 seconds whereas without histogram equalization, training time is 169.23 seconds.

Each training vector (corresponding to each sub-image) is compared with the other training vectors. For correlation coefficients greater than some specified value (usually 0.7 to 0.8), they are eliminated. It has been found that training time is greatly reduced and at the same time, higher values of PSNR are achievable. For example, for a 256 x 256 grayscale image and 4 hidden layer neurons, training time is 88.98 seconds whereas by reducing the correlation, the training time required is 43.95 seconds, a reduction of about 50%. Moreover, for a maximum allowable correlation coefficient upto and not including 0.8, training vectors were reduced from 1024 to 552 (for a 256 x 256 Lena Image). Consequently, training time also got reduced by a factor close to (552/1024) from 175 sec to 85 sec.

The image pixels which are represented by 8-bits initially are converted to double data type (in MATLAB) and normalized before training the neural network. All necessary calculations are done in double format. The compressed data is then multiplied by +127 and converted to signed 8-bit format for storage (and transmission if necessary). However, in this process, some significant bits after the decimal point are lost.

As a result, a mesh of black dots (salt and pepper noise) is introduced in the image after reconstruction and PSNR gets  reduced. The noise is more visible for high intensity images as compared to darker images. For example, for a 256 x 256 grayscale image and 8 hidden layer neurons, PSNR before quantization (without median filtering and without histogram equalization) is 28.97 dB whereas after quantization, it is 26.10 dB.

To remove the salt and pepper noise, 2 dimensional median filtering is performed over the quantized and reconstructed image. 3 x 3 blocks are selected from the reconstructed image and median filtering is done on each of these blocks until the whole image is covered. It has been observed that after filtering, the noise reduces significantly in case of high intensity images. It has also been observed that if the network is trained using 8 x 8 sub-images, then the salt and pepper noise is most effectively reduced by performing median filtering over 3 x 3 blocks of the reconstructed image. For example, for a 256 x 256 grayscale image and 8 hidden layer neurons, PSNR before median filtering (without quantization) is 24.40 dB and after median filtering, it is 26.10 dB.



V. CONCLUSION Introducing correlation into the image results in faster  training of the network. In this paper, faster training has been accomplished by eliminating the highly correlated training vectors, and at the same time, we obtained satisfactory values of PSNR as compared to the technique employing histogram equalization. It has also been observed that as the image size increases, higher compression is obtained and errors are also reduced. However, training time increases significantly.

