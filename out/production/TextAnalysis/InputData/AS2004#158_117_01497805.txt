

<html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">INDIAN INSTITWE OF TECHNOLOGY, KHARAGPUR 721302, DECEMBER 20-22.2004 50 I - Mining Frequent Closed Itemsets using Conditional Frequent Pattern Tree * Sanasam Ranbir Singh, Bidyut Kr. Patra and Debasis Giri Abstracf- The problem of mining complete set of frequent itensets can be reduced to the problem of mining hpuent closed itensets, which results in a much d l e r  set of i k m e t s  without information loss. In this paper, we discuss an algorithm to mine frequent closed Itemsets (FCI) using conditional frequent pattern tree called CFP-tree. Mfning FCI from CFP-tree is simply tracing of preRx nodes, which i s  a straightforward method. The mala advantage of this method lies in the used of simple data structures and less computations in d u g  FCI. From the experimental comparisons, we find that our method outperform Apriuri and Mafia and equally perform CHARM.

Index T E ~ s -  Conditional frequent pattern tree Frequent closed itemsets, frequent pattern tree.



I. INTRODVC~ON INING Association Rule [l], 121 has bezome one of e core data mining tasks, since its introduction. The association rule mining task can be stated as follows. Let I = f i i , h , i 3  ,...., h)be a set of m items, and let T = { t i , t 2 , t 3 ,  ...., tm}be a set of n transactions identified by unique identifiers. Each transaction 11 E T is a set of items in I .  An iternset X E I ,  is contained in ti, if x Gti.  The , support of itemset X i.e.  SUP(^) is the number of transactions containing X . An association rule is 80 expression X + Y ,  where X,Y I andx nY = #. The support of X 3 Yis dCfined as SUP(X UY)and confidence of X 4 Y is defined as SUp(x U Y)/SUp(x).

Given user-specified minimum support and minimum confidence thresholds, the association rule mining consists of two main steps [lJ. The first step involves finding the set of all frequent iklTISEt.5 and the second step involves generating all high confidence rules among itemsets. Mining of the complete set of frequent itemsets often leads to a huge number of results and hence huge number of association rules, many of which are redundant, In the studies (51, [3], 141, it is found that it is not necessary to mine all frequent itemsets in the first step. Insread it is sufficient to mine the set of closed frequent itemsets, which is much smaller in number and provides the same power as mining the complete set of frequent itemsets. and increases both effectiveness and efficiency of mining.

\ Sanasam Ranbir Singh, I)epartment of CSE Haldia Institute Of Technology, Hsldia, Medinipur 0-7803-8909-3/W$20.00 02004 IEEE Definition I .  A frequent itemset x is said to be closed if the intersections of the transactions Containing X is equal to X .

Considering the basic properties that the support of an non- closed itemset X is equal fo the suppor~ of ifs cIosure and that the set of m i m a l  frequent itemsets is identical to the set of maximal frequent closed itemsets, it can be claimed that frequent closed itemsets cover all the frequent itemsets without information loss [4]. Once we obtained frequent closed itemsets, deriving its closed associative rules is straight forward. As a result, the problem of mining closed associative rule can be reduced to the problem ,of mining frequent closed itemsets. This is the main ?motivation of this work. In this paper, we have discussed an algorithm to mine frequent cfo&amp;-d itemsets (FCZ) using conditional frequent. tree  (discussed in Section U). There had been several algorithms to mine frequent closed itemsets like CHARM [3]  and A- Close 141 using closed itemsets lattice, CLOSET, [7] using conditional database and frequent tree etc.

In this paper, we usefrequeh patfem tree [4] to store the transaction information. Conditional database of each item    transaction information. Conditional database of each item can be directly obtained from the frequent pallern tree. Each linked list in the frequent partern free represents the corresponding conditional database. We construct conditional frequent pattern tree from each conditional database. In CLOSET, xy-cun+fional databases are mined recursively from x-ionditional: datuabase, where y E ?1 , x f y and .

?corresponding frequent pattern trees are constructed to mine closed frequent itefnsets, Unlike CLOSET, we construct only one conditional frequent tree for &amp;ch set of itemsets in the, linked list and mine frequent closed itemsets. OUT method required much less number of tree compare to CLOSET and hence less computations. This is the main contribution of this paper.

The rest of the paper is organized as follows. Section I1 discusses the construction of conditional frequent pattern tree.

Frequent closed itemsets mining procedure and algorithm are .

discussed in section III. In section IV, we discuss experimental results and comparisons. Section V provides the conclusion.

Il. CONDITIONAL FREQUENT PATTERN TREE All transactional information is stored in a frequent pattern tree. Readers are requested to refer 141 ?or the frequent pattern tree construction procedures. Fig. 1 shows the frequent 502 IEEE INDlA ANNUAL CONFERENCE 2004, INDICON 2004 pattern tree of the example database of Table I 171. The same example database is used in subsequent discussiodns.

TABLE I EXAMPLE TRANSACUON DATABASE Trailsactioils Items Reorder Iterns 10 A,C,D,E,F C,E,F,A,Dl 10 A,B,E E,A 30 C.E,F CE,F 40. X,C.D,F C,F,A,D 50 C.E.F C.E,F Before constructing ji-equent putrern tree (FP-tree), we deteimine the support of each item scanning the database once. Items are sorted by their support in decreasing order.

The .support for items C, E, F, A,D and B in the example database are 4, 4,4, 3, 2 and 1 respectively. We, then prune the items, whose supports are below the "um support (in the example minimum support is 2 andB is pruned). We again reorder the items of each transaction in decreasing order of their supports as shown in Table I rightmost column.

D ----) D:i .+' Fig 1: Frequent pattern trct for the database- given in Table I Reordered column.

In the FP-tree (Fig. l), each linked list represents its correspondiag conditional database. For example, D -linked list provides the set of itemsets containing D item is . , ({cEF.D}, (CFID}). A -linked list provides itemsets containing A but not D i.e., ((CEF'A}, (CFA), (EA)), set of itemsets containing F but not A and D in F -linked and so on. For each X-conditional database obtained from FP-tree, we construct a tree called conditional frequent pattern tree (CFP-tree). We do not further minexy- conditional database, where y E I and X f y . It is main difference between CLOSET 171 and our algorithm.

Conditional ffequent pattern tree for the set of itemsets in x - linked Iist is called x -conditional frequent pattern tree.

I )  Conditional Frequent Pattern Tree construction Like FP-tree, CFP-tree is also prefix tree w.r.t. iternsefs list, Basic construction procedure of CFP-tree is same as that of FP-tree [4], except that x becomes'the root node for x XFP- tree and assigned level 0 and each node is assigned a level h d ( n )  = Zod(n + parent) + 1, where n is the node.

Using the level information, we can easily trace the highest level prefut node between itemsets. The item x is taken as a root node because of the fact that x is contained in all itemsets of x-linked list. Remaining of the construction is same as that of FP-tree.

same as that of FP-tree.

Fig. 2. CFP-tree for (a) D linked list. @) A linked list. (c) F linked list and (d)  E linked list.

D -&amp; D:2:0 A --b&amp;2:1 I Fig. 2 shows the CFP-tree for each linked list of Fig. 1.

Since C-linked list contains only one node representing itself, its CFP-tree is omitted. Before introducing our method of mining frequent closed itemsets from CFP-tree, we discuss some oftlie importkt Lemmas; Defnitton'Z. An itemset x is maximal, ifthere no other ' itemset(s) containing X .

, .

L e b  1. rfx be the highest level prefix node of the nodes Yiund Y2 of the Z-linked list in a CFP-tree, then itemsef(X)u (2) is the maxipal itemset contained in bolh ifemsst(Yi) and itemet(Ya), &amp;msel(i) is the itemset represented by node i in CFP-tree.

Proof+ Since YI and Y2 are the two nodes in Z -1mked list, itemsets represented by YI and Yz contain the item 2.

Again, as X is the highest level prefix node of the nodes Yt and Yz, itemsets represented by Yt and Yz contain h m s e t ( X ) u  (Z} and Z is the only item contained in both the itemset of YI and Y2, other than the items in itemset(X). Hence itemset(X)u (Z&gt; is maximal.

INDIAN INSTITUTE OF TECHNOLOGY, KHARAGPUR 721302, DECEMBER 20-22,2004 503 Collolary 1. .g X be the highest level prefw nude ,of the nodes Y I ~ Y Z ~ . . . ~ Y ~  of the Z -linked list in a CFP-tree, then itemset (X) U (2) is the mavimal itemset contained in all rhe itemsets represented by YI, Y2,.,., K.

. .

Lemma 2. If X and Y are two itemsets such"2hut X G Y , then S U ~ ( X )  2 SUP(Y).

Lemma 3. Let X and Y be fwo itemsets and sup(^) = SUP(Y). VY c x , then P is not closed.

Proof. Since P CI x , every tr-action that contains x also containsY, but reverse may not be true. Again, since SU~(X) = SUP(Y), every transaction that contains Y also contains X . Therefore, transactions containing X and transactions containing Yare same and Y is not the maximal itemset. Hence, Y is not closed.

111. MINING FREQUENT CLOSED ITEMSETS FROM CFP-TREE I) Mining Frequent Closed Itemsets from the example CFP- tree Considering the CFP-trees shown in Fig. 2 and mini" support threshold equal to 2, we discuss frequent closed itemsets mining procedures. The mining consists of two main steps. First, find Iucatfiequent closed itemsets from the set o f itemsets in each linked list of each CFP-tree and second, check Iocally found frequent closed itemset is closed over total database or not. Remember that if the frequent itemset obtained is not a subset o f  any closed itemset or subset but with larger support, then the itemset is closed.

We assume that the set offiequent closed itemsets is empty i.e., FCI t- # . We start with the C%P-tree of the item with rmnimum support m the original transaction. In our example, we start with D -CFP-h.ee, then A -CFP-tree and so on. We see that {DAFCE) and {DdFC] are the closed itemsets in D-CFP-tree with support value 1 and 2 respectively, but threshold. The itemset (DAFC) is the only Iocal frequent closed itemset and included in F c I .  Similarly, (AFC), (AE) and {A}  are local fiequent closed itemsets from A - CFP-tree. (AFC] is a subset of {DAFC) with the sane support value 2 and {AFC) is omitted. The itemset {AE) is not a subset of any element in FcI and included into pc21 , ( A }  is a subset of (IMFC) but with larger support value 3 and included into FCI. Likewise local frequent clrisod itemsets {CFE) and {CF) from F-CFP-tree and (E&gt; I .

(DAFCE) is omitted since its support is below "urr .L I    I from E -CFP-tree are included in FcI  . The itemset IC} is the only itemset in c -CFP-tree ,and it is a subset of (CF) with tbe same support value 4. So, (C) is omitted, The total frequent closed itemsets is FcI  = ({DAFC),{dE) { A ) ~  (CFE), (cF}~ {E}} with the support values 2,2,3,3,4 and 4 respectively.

2). Algorithm Input r : The set of all x -CFP-trees, which are arranged in the decreasing order of the level of x in FP- tree.

Output FcI : The complete set of frequent closed itemsets.

F C I t 4 : r t r ; while (7 * #)do Select the fust CFP-tree, ( x }  E Z ; For all Linked lists in x do T + T - ( X } ; , Select y -Linked list in decreasing order of the level of For all node n in y -Linked list do y .  , If itemset(n) U {y}is not a subset of any element inFC1 andsup(n) 2 MinimumThreshold , then include itemset(n) U ( y )  into FcI  I Let m be a highest.leve1 prefix node of some nodes in the y-linked list. If support of itemset(m) U G]is larger than m i n i " threshold and not a subset of any element in FCI or subset, but with higher support than its enclosure, then include ifemseb(m) U (y } into FCI . /!Sturt mining highest level prefix nodefiom the nodes with higher level to lower level.

Until1 highest level common prefix node o f  all the do nodes in o f  y -linked list is obtained.

Iv. EXPENMENTAL EVALUATIONS AND PERFORMANCE STUDY Experiments were performed on a 2.4GHz Intel Xeon processor PC with 1GB of RAM running RedHat Linux 8.0.

Algorithms were coded in C++. For the performance comparisons we used the original source code for Mafia, 'Apriori and CHARM, which are publicly available. Timings in the figures below include all processing cost.

IEEE INDIA ANNUAL CONFERENCE 2004. INDlCON 2004 . 1 '  , .  504 --b chess connect *mushroom 1 +pumsb' i! '2000 items, number of records and average mnsaction length. g 8000 Dn tm ets #Items #Kec;or&amp; Avg. z We used the experimental datasets from FIMI03 (http://FIMI. GS. HELSINKI.FI) which is publicly available for the dataset used in OUT evaluation. It shows the number of g 10000 the performance tests. Table'I1 shows the characteristics of e U pUm8b 1' p 2000 CIWS 75 3196 37 0 c 01UleG t 129 67557 43 ia 20 34 40 so eo '10 BO BO hiusluuoin 119 5134 a S U P P O W w h 1 U b  1,113 49036 74 implementation fails to work.

PUlllSb" 308s 49046 50.5 TlOI4DlOOK 870 100000 11 T40I 1ODlOOK 942 100000 40.5 TABLE II DATABASE CHARACTERISTICS.

Lt?llgth e v CONCLUSION In this paper, we propose. an algorithm for mining fiequent    In this paper, we propose. an algorithm for mining fiequent closed itemsets using a prefur- tree called conditional fiequent pattern tree (CFP-tree). Prefm,p;operty of the CFP-tree can be efficiently used to mine frequent closed itemsets. For ' example, if every nodes of-a linked list in a CFPT are prefix of some of nodes of another linked list, then we can skip . processing the itemsets in the- former linked list. Our performance study shows that our~rnethod outperfom Mafia and Apriori and performs eqhlly in an average compare to CHARM.

Fig 3. Frequent closed Itemsets distribution. Fig. 4. Number of f q u e n t  dosed iternsets.

We have tested with the datasets shown in Table a. Fig. 5 shows the comparison between ow method with CHARM [3], Mafia 161 and Apriori IZ] for chess dataset. For this dataset, our method is equally performed with Mafia and CHARM for arJd much faster than Mafia for low supports value. Our method outperforms Apriori for all ranges of support values. Similm observations are found for rest of he datasets except far TlOI4DlOOK and T40IlODlOOK datasets. For TlOI4D100K, if the Support value is lesser than 0.3% and for T4011ODlOK datasets, if the support value is lower than 0.4%, OUT Fig. 5. Comparison between our method with Mafia, Apron and CHARM-

VI. REFERENCES supports value, but slower than [ I ]  R Agrawal, T. Imielinski, and A. Swami. Mining association rules bohvetn sets of ilenu in large 'databases. In proceeding of the ACM SIGMOD ht. ConL on Managemnt af data, Pages 207-216, May 1993.

[2] R Agr8wal and R Srikant. Fast algorithm for mining association rules.

In proceeding of thc 20Lh Int. ConE on Very Lagre Data Bases, pages 478-499, June 1994.

[3] Zaki, M. and Hsiao, C.-J. CHARM: An effcitnt algorithm for closed association rule mining. ln technical tqmrt 99-10, Computer Science Dept., Rcnsselaer Polytechnic Institute, October 1999 Chess , [4] Pesquicr, N., Bastide, Y., Taouil, R., and Lakhal, L, Discovenng frequent closed itemsets. In proceeding 7" Int. Conf. Database Thaory(ICDT'99). pp. 398416, Jan.1999.

[SI J. Han, J. Pei and Y. Yin. Mining frequent pottem without candidate genmtion. In SIGMOD'OO Dallas, TX. May ZOM.

[6] Burdick, D. Calimlim, M I  and Gchrke, J. MAFlA' a maximal frcquent itemset algonthm for transactional databases In proceeding Int. Conf on Data Engineering, April 2001.

[7] Pel, J., Han, J., and Mao, R CU)SET:4An efficient algonthm fo mining frequent closed itemsets. In SIGMOD Int. Workshop on Data Mining and Knowledge Discovery, May 2,000.

