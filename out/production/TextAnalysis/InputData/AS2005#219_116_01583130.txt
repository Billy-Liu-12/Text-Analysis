Learning and exploiting invariants for multi-target tracking and data association

Abstract? Methods for solving multi target tracking and data association problems in presence of clutter and occlusions are based on models that describe the target dynamics and the measurements statistics. Most often the dynamics of the targets are assumed to be independent from each other. In many applications, however, the motion of the targets may be coordinated. We introduce a statistical concept of shape, or coordination, in terms of invariants w.r.t. the motion of the targets. Assuming that the rules of coordination may slowly change over time, we study the interplay among the shape and the target dynamics.



I. INTRODUCTION  In many applications from air traffic control, to tracking features on the image plane of a camera, there is the problem of tracking a multitude of targets while they are moving in space. Each target is seen by one or more sensors which generate measurements of its position in space at every time step. The problem is difficult because the dynamics of the targets are uncertain and the sensors generate unlabelled and similar measurements of their positions. It is, therefore, not trivial to associate measurements to targets. The problem is often rendered even more difficult by clutter which consists of the presence of false measurements and occlusions which happen when some targets are hidden from the sensors and do not generate measurements for some time intervals.

In the literature, the problem is known with the name of multi-target tracking and data association. There is a vast number of papers addressing it from many different facets since the late ?60ies early ?70ies. Standard methods are described, for instance, in [1].

Most algorithms exploit two forms of information: a dynamic model describing the motion of the targets and a statistical model of the measurements. The data association is solved by jointly examining the positions of all the received measurements w.r.t. their predictions on the basis of the dynamic model. Probably, the most well known algorithm is the JPDA (Joint Probability Data Association) which evaluates the probabilities of all possible associations and combines them accordingly in order to compute the updated estimate of the targets position. The MHT (Multiple Hypoth- esis Tracking) [2] is more powerful than the JPDA because it evaluates the probability of the associations on a whole time interval. It finally selects the most likely association to update the state estimate. The complexity of the MHT is, however,  much higher and a latency in the generation of the estimate is necessarily introduced. The MMF (Multiple Model Filter) is applied when the targets go through aggressive maneuvers.

Multiple dynamic models are used to better describe the different phases of the maneuvers and improve the state predictions. It is clear that the more accurate the dynamic model is, the easier is the data association problem.

In recent years, in the scientific literature on computer vision, a number of papers on tracking have appeared. In vision the multi-target tracking problem is fundamental to reconstruct the trajectories of features or objects in the image plane. In [8] particle filters and the condensation algorithm have been proposed in order to estimate non-Gaussian and multi-modal posterior probability densities which arise in case of ambigous data associations. In [9] the problem of proper re-sampling of the densities is addressed by inte- grating the tracker with information on the measurements which eases the data association problem. In [6], [12], [13] statistical learning techniques have been applied to the problem. The authors of [12], [13], in particular, have proposed a method for learning the joint probability density of the position of the targets in space. The approach is com- plementary to the standard methods such as the JPDA. There is no local information on the trajectories and, consequently, no assumptions on their regularity. All the information is collected in the joint probability density and the association events are independent in time. The computational complex- ity of learning the joint probability density is exponential with the size of the maximum clique of the graph describing the conditional dependencies among targets. In order to make the problem manageable, a triangulate structure is assumed.

This means that the graph is composed by cliques of order three or less. The advantage of this approach is that it models statistical dependencies among targets which, with the standard algorithms such as the JPDA, are neglected in favor of local coherence of trajectories described by independent dynamic models. The goal of our research is to combine the advantages of both approaches. The main drawback of the statistical learning methods is that they require the acquisition and the labeling of a large training set for each action of interest such as a walking person. The learning set may be used for other instances of the same action, but cannot be extrapolated to other subjects or scenes.

Proceedings of the 44th IEEE Conference on Decision and Control, and the European Control Conference 2005 Seville, Spain, December 12-15, 2005  WeC15.1     The classical techniques based on model based filters and assuming independence are more general in this sense as they do not require particular training, but, since they do not model coordination among targets, they might produce highly segmented tracks.

In [10], [11], [3], [4] an effort to include information on shape or coordination among targets in the JPDA has been done with some success. The advantage of these approaches is that coordination may be learned during those segments of the targets trajectories which are succesfully labeled by the JPDA and then it can be integrated in the scheme in order to solve the data association problem better.

In this paper we continue along the line of research introduced in [3], [4]. We assume the existence of symme- tries of motion among some of the targets. Think at, for example, airplanes flying in formation. The shape of the formation is invariant w.r.t. the motion of each aircraft and it is an important feature for solving the data association problem. We model these symmetries as some functions fi for i = 1, . . . , p of the dynamical state of the targets which are constant in time or slowly varying. We, then, apply standard parameter estimation methods for estimating their statistics and, by properly adjusting the forgetting factors, we can adapt the scheme to slowly varying parameters.



II. THE MULTI-TARGET TRACKING AND DATA ASSOCIATION PROBLEM  With the purpose of introducing some notation which will be used throughout the paper, we provide a short introduction to the probabilistic approach to data association. We refer the reader to the classic book [1] for a thorough description.

Consider the problem of tracking over time a set of NT moving targets; yi(k) shall denote the position of target i ? [1, .., NT ] at time instant1 k ? Z. In many real-world scenarios one has available, at each time instant k, a set of ?unlabelled? measurements {zi(k)}, i = 1, ..,Mk; this means that in general no knowledge is available regarding (a) which measurement has been originated by which target2, (b) which target has generated no measurement (in which case we shall say that the target is occluded) and (c) which measurements are ?false detections? in the sense that they have not been generated by any of the targets; in the literature these measurements are said to be originated from clutter.

Note that at each time k the number of measurements Mk is in general different from the number of targets NT .

Dealing with (a), (b) and (c) is the data association problem. Traditionally, the solution is based on assuming that the position of each target yi is a hidden Markov process whose dynamical state is xi defined by its probability density at the initial time p(xi(0)) and by its transition density p(xi(t + 1)|xi(t)). The observations are the positions of the targets. They are modeled by the conditional density  1Without loss of generality we assume that measurements are gathered uniformly in time with unit sample time and that only the positions of targets at those time instant are observed.

2A standard assumption is that each target can originate at most one measurement.

p(yi|xi). The filtering problem consists in the computation of the following Bayesian recursion  p(x(k)|Yk) = p(y(k)|x(k))p(x(k)|Yk?1) p(y(k)|Yk?1)  = p(y(k)|x(k)) ?  p(y(k)|x(k ? 1))p(x(k ? 1)|Yk?1)dx? p(y(k)|x(k))p(x(k)|Yk?1)dx  where with the capital letter Yk we mean the ? algebra generated by all the position measurements from the initial time to time k. In the linear Gaussian setting, the above recursion is solved by the Kalman filter. The problem is that at each time instant k, a set of unlabeled measurements z arrives and the association to the targets is unknown. It is customary [1] to denote with ?k an ?association event? (or hypothesis) at time3 k and with ?k the set of all possible association events at time k. Under the hypothesis ?k, j(i, ?k) shall denote the index of the measurement associated to target i, i.e.

yi(k) = zj(i,?k)(k). (II.1)  If the target i is occluded then  j(i, ?k) = 0. (II.2)  It is sometimes useful to use the index 0 do denote clutter and therefore j(0, ?k) will denote the set4 of false measurements under ?k.

Some approaches are based on hard decisions, where at each time only the most likely possible association is considered; unfortunately these fail in the presence of strong clutter and occlusions.

The Joint Probabilistic Data Association Filter (JPDAF hereafter) (see [1] for a thorough description) is a probabilis- tic method which integrates (1) a dynamical model for the motion of targets, (2) a model for the clutter (false detections) and (3) the probability of occlusions.

A key observation is that under an association hypothesis ?k, estimating the position5 of each target is the standard filtering problem described above. The main idea behind the JPDAF is to fuse the information from (1),(2) and (3) above in order to attach a weight (a ?posterior probability?) to the possible associations. Then an estimate of the position of the targets can be obtained by conditionally weighting the state estimates on all possible6 associations.

We shall denote with z(k) := [z1(k), .., zMk(k)] the set of measurements available at time k. The symbol Zk will denote the set of measurements up to time k (included), i.e.

Zk := {z(s), s ? [0, k]}.

In the gaussian linear case, the position yi(k) of the i- th target are described by a linear state space model of the  3Note that, since the number of measurements may change over time, also the set of possible associations changes over time.

4As explained above under each ?k , j(i, ?k) is a well defined function of i ? [1, NT ] while j(0, ?k) is in general a set.

5Or, more generally, the state of a dynamical system describing its motion.

6It is customary to consider only a subset of association which corre-  sponds to ?large enough? weights (posterior probabilities). This is usually done employing suitable ?validation regions? for each target; see [1] for details.

form: { xi(k + 1) = Fi ? xi(k) + vi(k)  yi(k) = Hi ? xi(k) + wi(k) (II.3)  The model and measurement noises vi and wi are assumed to be white, zero mean and uncorrelated gaussian distributed with covariances Qi and Ri respectively.

The generalization to nonlinear independent dynamics im- plies the use of nonlinear filtering methods like, for ex- ample, the Extended Kalman Filter or particle filters like the condensation algorithm [8]. Our interest, however, is focused on the data association problem which is unaffected by the fact that the dynamics are linear or not. We assume, therefore, that at time k?1 the conditional density of the state xi(k?1) given all measurements up to time k?1 is Gaussian with mean x?i(k ? 1) and covariance matrix Pi(k ? 1), i.e.

p(xi(k ? 1)|Zk?1) ? N (x?i(k ? 1), Pi(k ? 1)).

Once measurements at time k become available these estimates can be updated, conditionally on an association event ?, by using standard Kalman filter formulas with measurements 7 yi = zj(i,?k). We denote with x?i,?k(k) and Pi,?k(k) the updated mean and covariance conditionally on the association ?k, initialized from initial conditions (at time k ? 1) x?i(k ? 1) and Pi(k ? 1); since the dynamics are described by a Gauss-Markov model (II.3), the conditional density p(xi(k)|?k, Zk) is Gaussian with mean x?i,?k(k) and covariance matrix Pi,?k(k).

A simple application of the Total Probability Theorem provides the conditional probability density function  p(xi(k)|Zk) = ?  ?k??k p(xi(k)|?k, Zk)p(?k|Zk) (II.4)  which turns out to be a mixture of Gaussian densities.

In order to make the computation tractable this Gaussian  mixture is approximated (in the Kullback-Leibler sense for instance) by a Gaussian density with mean x?i(k) and covari- ance Pi(k) according to????  ???  x?i(k) = ?  ?k x?i,?k(k) ? p(?k | Zk)  Pi(k) = ?  ?k Pi,?k(k) ? p(?k | Zk)  + ?  ?k (x?i,?k(k) ? x?i(k)) ? (x?i,?k(k)?  ?x?i(k))? ? p(?k | Zk) (II.5)  This allows to start again at time k with a Gaussian posterior for each target and iterate the procedure just described. This last approximation step is implicit in the classical description of JPDAF (see [1]) where only second order moments x?i(k), Pi(k) are considered.

The only point left is to compute the posterior association probabilities p(?k|Zk). Assume that a prior p(?k) on the association events is available8; the posterior p(?k|Zk) can  7If under association ?k no measurement is associated to target i then only the prediction will be computed.

8We shall not discuss this choice in the paper. We refer the reader to [1] for details. Suffices it to say that p(?k) usually depends on the probability that each target is detected, on the number of detected targets and on the number of false measurements.

be computed using Bayes? formula as follows:  p(?k|Zk) = c p(z(k)|?k, Zk?1)p(?k | Zk?1) = c p(z(k)|?k, Zk?1)p(?k) (II.6)  where the last equality holds because associations at time k are conditionally independent upon measurements up to time k ? 1. The constant c is a normalization factor which does not play a role.

From now on, we shall omit the time index k unless needed; according to the notation introduced above, Z shall denote the set of past and present measurements, while Z?  only the past. Similarly x??i will denote the prediction of the state at time k given Z? and P?i its conditional error covariance.

In order to evaluate p(z|?, Z?), it is convenient to in- troduce the set9 D? containing the indices of all the de- tected targets10; consequently we shall denote with zT,? := {zj(i,?), i ? D?} the set of ?true? measurements, i.e. mea- surements which have been associated to some target and with zF,? the complementary set of ?false? measurements attributed to clutter. Similarly we define the set of ?occluded? target indexes11 as M?. Postulating (conditional) indepen- dence p(z|?, Z?) can be factored in the form  p(z|?, Z?) = p(zT,?|?, Z?)p(zF,?|?, Z?).

The term p(zF,?|?, Z?) describing clutter is usually taken  to be uniform over the volume V of interest, i.e.

p(zF,?|?, Z?) = (  V  )NF (?) (II.7)  where NF (?) is the number of false measurements under hypothesis ?.

As the term p(zT,?|?, Z?) is concerned, it is sufficient to recall that zT,? = {zj(i,?), i ? D?} = {yi, i ? D?}.

Let us define the vectors yD? := {yi, i ? D?} and yM? := {yi, i ? M?} containing respectively the detected and occluded targets.

Therefore  p(zT,?|?, Z?) = [ p(yD? |Z?)  ] |yi=zj(i,?),i?D? (II.8)  which is the marginal of p(y1, .., yNT |Z?) = p(yD? ,yM? |Z?) with respect to yM? :  p(yD? |Z?) = ?  p(yD? ,yM? |Z?) dyM? . (II.9)  Under the assumption that the target positions are condi- tionally independent we have that  p(zT,?|?, Z?) = ?  i?D?  [ p(yi|Z?)  ] |yi=zj(i,?) (II.10)  The density p(yi|Z?) describes the prediction of the position of target i given past measurements. From the  9Remind that since ? depends on time k we should use the notation D?k 10I.e. targets to which a measurements has been associated under hypoth-  esis ? 11M stands for ?missing?. Note that D? ? M? = [1, .., NT ].

assumption that xi conditionally on Z? is Gaussian with mean x??i and covariance P  ? i it follows from (II.3) that  p(yi|Z?) is a Gaussian density with mean y?i = Hix??i and covariance matrix ??i = HiP  ? i H  ? i + Ri.

Remark 2.1: Equation (II.10) is fundamental in comput- ing the association probabilities. It relies on the fact that targets are assumed to be conditionally independent given past measurements, which is not certainly true when there is coordination between targets. In [4], a shape model has been integrated into the JPDAF algorithm. When the poste- rior density of the positions includes the shape model, the marginalization (II.9) is not trivial. We applied Monte Carlo, or equivalently, particle methods to implement this step.



III. MOTION SYMMETRIES  During their motion, the targets may be coordinated, where by coordination we mean the existence of some statistical dependence among them. Quantifying statistical dependence is a difficult problem. The correlation coefficient, for ex- ample, can only be applied to pairs of random variables and only measures linear dependence. In the literature, there exist a number of measures of statistical dependency. In [5], for example, a generalization of Pearson?s ?2 measure is proposed  ?2 = ?  x?XN p(x)?N  i=1 p(xi) x ? 1  as well as a measure based on the Kullback-Leibler pseudo distance among the joint distribution and the product of the marginals. Both measures, if the targets are statistical independent, are null, otherwise they can even be unbounded.

The problem with these kinds of measures is that they cannot be easily computed from the experimental observations. It would be necessary to estimate the joint density p(x), but this is a formidable task unless particular structures of the conditional dependence graph are assumed. It is customary to assume either a tree or a triangular structure. The former implies that the maximum cliques are of order two while the latter implies that they are of order three. They are both manageable computationally, but the triangular structure is more robust w.r.t. occlusions. A single occlusion, in fact, cuts a tree structured graph. This is the reason why a triangular structure was chosen in [12], [13].

We take a different approach. We do not try to estimate the joint density of the ensemble of targets, but we search for invariants in the motion of the ensemble of targets. When a number of aircrafts are flying in formation or a set of markers are attached to a rigid body, the position of three non collinear targets fully determines the position of all the others. The motion of the whole ensemble of targets can, in this case, be factored in the motion of any triple of points and on a local, invariant, representation of the others w.r.t. the first three. In other words, the motion of the ensemble can be factored in a rigid body motion and an invariant description of the shape of the ensemble. In terms of statistical dependency among targets, the conditional density of the position of the targets given a triple is degenerate and,  in absence of noise, it is deterministic. In presence of noise it can be modeled reasonably well by a Gaussian mixture.

Besides rigid motion, other interesting coordinated motions generate symmetries or, equivalently, invariants. Any kind of link or joint among articulated bodies can be described by some invariants. In general, we can model holonomic and non-holonomic constraints with invariants. If, for example, the targets are all moving along straight lines, the directions of motion are invariants, or, if the targets are orbiting about a fixed point then its coordinates are the seeked invariants.

Our purpose is to exploit these symmetries in order to solve the data association problem.

This paper is, in particular, on the estimate of the statistics of the motion invariants and how to combine this information with that provided by the independent dynamical models (II.3) in order to solve the data association problem. For con- sistency, the independent dynamical models are assumed to describe the transition density of each target. They describe, therefore, the marginal probability density of each target.

In general, let us assume that there exist some features fi for i = 1, . . . , p that are functions of the dynamical state of the targets  fi = fi(x1, . . . , xn)  which are invariant w.r.t. the motion of the targets, so that  dfi dt  (t) = ?fi  ? ????  x?1 x?2 ...

x?n  ? ???? = 0.

Two important problems arise: (1) find or identify from the data the invariants fi; (2) estimate the statistics of the invariants fi in presence of noise and uncertainties.

The first problem is also very difficult and it is not within the scope of this paper even if it is one of the main objectives of our research. We assume a list of possible invariants and, while tracking, we check if there exist group of targets that satisfy them.

An example of the definition of an invariant description is the procedure proposed by Kendall [7] to represent the shape of an ensemble of N points. It consists of the following steps:  1) determine the center of mass of the points ycm =?N i=1 yi and move the origin of the reference frame in  ycm; 2) rotate by R the reference frame so that the N dimen-  sional vector [0, . . . , 0, 1]T becomes the right kernel of the matrix  S? = [  (y1 ? ycm) . . . (yn ? ycm) ] R  3) eliminate the last row of matrix S?, the 3?N?1 matrix S obtained in this fashion is a representation of shape and it is an invariant of rigid motion.

The invariant proposed by Kendall is, unfortunately, not robust w.r.t. occlusions, so, in the list of possible invariants, we also include distances among pairs of targets and angles between target velocities. We assume, therefore, that the form     of the invariants fi is known and we address the problems of verifying their existence in the motion of the ensemble of the targets and of estimating their statistics. The existence of a specific invariant is formulated as an hypothesis test, the null hypothesis being that the invariant is true. The statistic on which the test is performed is the variance of fi.

When an invariant is declared true, we update the estimate of its mean and covariance with a recursive estimator which is described in the following section, and on the other we add links between the correspondent targets to a coordination graph which describes the dependencies among targets.

It often happens that the invariants of motion last only for short time intervals or show slow dynamics. Can they still be exploited for the data association problem? We assume that the statistics of the invariants may slowly drift in time.

This wants to be an initial model describing the dynamics of shape. While, shape, in fact, might be evanescent and persist in time briefly, it can still carry a lot of information helpful for solving the data association problem. We, de- facto, implement an adaptive scheme that adjusts to changing coordination strategies among targets.

The coordination graph collects information on the struc- ture of the dependency among targets. If the targets are, for example, all attached to a rigid body the coordination graph will be complete. It is used for two reasons: book keeping and as a topological support to the data association. We have, in the past, implemented a graph matching algorithm to solve the data association problem, but it only helps when the structure of the graph is complex with more than one clique of relatively high order. This is usually the situation when the scene is composed by articulated bodies. In other situations, like a single rigid body, the graph is complete, i.e.

it is a clique and the matching algorithm does not provide any information for labeling the measurements.



IV. ESTIMATING THE STATISTICS OF SLOWLY VARYING INVARIANTS  In estimation theory, it is customary to model slowly varying parameters with a linear model  ?(k + 1) = A(k)?(k) + ?(k) f(k) = H(k)?(k) + w(k) (IV.1)  where the matrix A(k) is close to the identity, while ? and w are independent gaussian white noises. We approximate the matrix A(k) assuming that it is the identity and we assume that the observation matrix H(k) is constant. The covariances of the process and measurement noises are assumed unknown.

Under our hypothesis, the extended forgetting factor re- cursive least squares estimator (EFRLS) [14] becomes  ?(k) = ?(k ? 1) + L(k)(f(k) ? H?(k ? 1)) L(k) = P (k ? 1)HT (?I + HP (k ? 1)HT )?1 P (k) = 1? (I ? L(k)H)P (k ? 1)  (IV.2) The choice of the forgetting factor ? is based on the  following considerations: ? should be large and close to one whenever the process noise covariance or when the  measurement noise covariance is large. In the first case, past measurements contain information, in the second, averaging over more samples in time reduces the covariance of the estimate. ?, however, should not be too large or we loose adaptability to slow drifts of the mean of f .

An hypothesis test is then performed, based on the esti- mated covariance HP (k)HT of the invariant. If the norm of the estimated covariance is larger than an appropriate threshold then the alternative hypothesis is considered true and the invariant is considered not true.



V. INTEGRATION OF SHAPE IN THE JPDA  In order to compute the posterior probability of a given association event ? we need to compute the likelihood of the true measurements zT . The overall observation model can be written as follows:  p(yD? = zT ,yM? | Z?) = c ? ?  i?D? p(zj(i,?) | Z?i )?  ? ?  i?M? p(yi | Z?i ) ?  p? i=1  p(fi(yD? ,yM? )) (V.1)  which yields:  p(zT | ?, Z?) = c ? ?  i?D? p(zj(i,?) | Z?i )?  ? ? ?  i?M? p(yi | Z?i ) ?  p? i=1  p(fi(yD? ,yM? )) dyM?  (V.2)  As in [4], we solve the integral in (V.2) by a Monte Carlo approach. The reason is twofold. First, it is simple and con- sistent. Second, as a byproduct, it yields for free a set of fair samples from the posterior distribution of the occluded points positions. This allows to compute mean and covariance and hence provides a natural gaussian approximation of the more complicated posterior. We draw an appropriate number Ns of independent and identically distributed samples:  y(n)M? ? {y (n) i , i ? M?} ?  ? i?M?  p(? | Z?i ) n = 1, ..., Ns (V.3)  and compute the n-th weight through the following expres- sion:  ?(n) = p?  i=1  p(fi(yD? = zT ,yM? = y (n) M?  )) (V.4)  Finally, the integral is computed as follows:? ? i?M? p(yi | Z?i )?  ??pi=1 p(fi(yD? = zT ,yM? )) dyM? ? ?Nsn=1 ?(n) (V.5)  which, substituted in (V.2), yields p(zT | ?, Z?).

The conditional state estimates of a detected point are  computed combining the Kalman updates on the basis of all the feasible associations as in the JPDA. The fundamental difference being that the symmetries fi are instrumental in computing the likelihood of the association events. The conditional state estimates of an occluded point are, instead, computed exploiting the shape information starting from     the measurements generated by the detected points. It is fundamentally different than in standard approaches where it is taken equal to the state predictions.



VI. RESULTS  The multi-target tracking algorithm proposed in this paper is currently being implemented on a optical motion capture system. We implemented the algorithm in matlab and we tested it on data previously acquired with the motion capture system. Twentytwo markers have been attached to a human subject, three on the head, two on the shoulders, two on each arm, five on the torso and four on each leg. A rigid object with six markers on it was held by the subject in his hand during the acquisition of motion. The total of 28 markers was tracked by a six 50 Hz camera motion capture system for approximately two minutes, i.e. for about 6000 frames. The first 2000 frames were used to determine and initialize the estimate of the invariants of motion. All the markers attached to the rigid body held by the subject in his hand satisfy the mutual distance invariants and even Kendall?s invariant when there are no occlusions. The coordination graph clearly exhibits the articulation structure of the human body. All the markers on the torso, for example, belong to the same clique of maximum order equal to five. The markers on the feet all belong to a complete subgraph. This is because the subject was asked not to move his feet in order to check adaptability to changes in the coordination and the effect of the forgetting factor.

As an example the statistics of some invariants are de- scribed in the following table.

Invariant: distance among two targets Mean Std Persistence interval max (frames) Targets 1 and 3 both on the head 16.8cm 0.12cm All Targets 12 and 13 on the left arm 29.7cm 0.57cm 786  The total number of trajectories segments has been taken as a performance index of the data association algorithm.

Ideally, the number of trajectories should have been equal to the total number of markers i.e. 28.

An implementation of the JPDA alone generated 112 segments. The number of trajectory segments is, furthermore, highly dependent on the choice of noise covariances in the Kalman filters. If the covariances are set too small, the measurements do not fall within the validation gates and are associated to clutter. If the covariance is set too large, the data association becomes very difficult because the number of possible associations increases. After a few trials, we found a choice that led to the best result of 112 segments.

The shape integrated JPDA generated 36 segments, where most of the wrongly labeled segments were produced be- cause of the incorrect invariants detected between the feet of the subject.

Tuning the forgetting factor ? for the invariants is im- portant to obtain significant results. A small ? leads to the creation of invariants which persist in time very briefly. A large ? renders the scheme rigid and not adaptable so that wrong invariants declared as such because of not sufficiently exciting dynamics lead to wrong data association.



VII. CONCLUSIONS  This paper continues along the research line presented in [4]. The spirit is to include information due to the statistical dependence among the targets in standard algorithms multi target tracking algorithms that otherwise treat targets as independent. This information is of great help in solving the data association problem. The proposed schemes should also improve on the techniques proposed in the computer vision literature based on statistical learning methods which do not imply any local coherence in time of the targets trajectories.

Coordination among targets has been models by the means of motion symmetries or invariants. The shape description proposed by Kendall is used as an invariant, but, since this is not robust w.r.t. occlusions, it has been integrated with pairwise distances among targets and angles between target velocities.

The possibility of slow drifts in time of the invariants is dealt with by introducing forgetting factors in the estimate of their statistics.

In experiments with a motion capture system segmentation of the tracks has been substantially reduced compared to the standard JPDA assuming the possibility of learning the in- variants on a sufficiently long time interval with persistently exciting dynamics.

