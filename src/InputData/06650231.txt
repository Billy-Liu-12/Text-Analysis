A Comparative Study of Algorithms for Recommending Given Names

Abstract?Recommending given names is a special case of recommender system that is little explored, but has gained a great interest recently. Indication of names related to a user?s query or suggestion of names for parents in order to choose a name for their unborn child are examples of applications of name recommendation. In this paper, we present results for this task by using a baseline approach that recommends only the most frequent searched names, two state-of-the-art recommender systems, and a proposed method based on graph. The empirical evaluation shows that our method based on graph provides better results than the other methods.

Index Terms?Name recommending; Recommender system.



I. INTRODUCTION  Recommending given names consists in the application of recommender systems for name suggestion. Such systems are usually applied, for example, in the suggestion of names related to a user?s query or in the suggestion of names for parents in order to choose a name for their unborn child. For instance, if a user?s query is ?Anderson Silva? , the system might assume that the user is searching for the name of the martial arts athlete and recommend the name of another athlete of the same sport, as ?Jon Jones?. Analogously, if a user searches for ?Paul?, the system might assume that the user is searching for biblical names and suggest, for example, ?Matthew?.

In this sense, name recommendation can be taken as the problem of understanding the user desires and, given an input name, suggesting suitable similar names to him/her. A suitable name must satisfy a set of factors such as the social context, the language, the cultural background, and especially, the personal taste. Although this task is relevant in practice, little research has been carried out on the construction of automatic systems for recommending given names.

One possible solution for this problem is through the analy- sis and application of interrelations among given names from a recommender system perspective. A recommender system is an information filtering technology which can be used to output an ordered list of items (e.g., given names) that are likely to be of interest to the user [1], [2].

In different scenarios, recommender systems are sub- ject to scientific research, as, for example, recommending products [3], mobile applications [4], place of interest [5], movies [6], music [7]. In this paper, we analyze some algo- rithms for this task of recommending given names. We start by using two state-of-the-art recommender systems, Item-Based Collaborative Filtering and Association Rules Based. Then, we propose a technique for name recommendation based on graph. To verify the performance of these algorithms, we com- pared them against a baseline approach which recommends the most frequent searched names. The empirical evaluation was performed by using data from the Nameling web site (http://nameling.net/), and the results show that our method based on graph presents better performance than the other methods.

The paper is organized as follows: in Section II, we describe the four recommendation algorithms used in this work for recommending given names. We present our empirical evalu- ation in Section III. We discuss the data set, the task of pre- processing, the experimental setup and evaluation metric, and the empirical results. Finally, in Section IV, we present final remarks.



II. ALGORITHMS FOR RECOMMENDATION  A recommendation algorithm is an information filtering technology which can be used to predict preference ratings of items (e.g., movies, music, books, news, images, web pages, given names, etc) not currently rated by the user [8], and/or to output a set of items/recommendations that are likely to be of interest to the user [1]. In this work, we focus on the task of selecting the top ? items/recommendations which are of interest to a user. One of the best illustrations for such a task is the Amazon web site1, which informs a user that ?Customers Who Bought This Item Also Bought ...? or ?Customers Viewing This Page May Be Interested in These Sponsored Links ...? [9], [3].

1http://www.amazon.com/     In this section, we present two state-of-the-art recommenda- tion algorithms: Item-Based Collaborative Filtering and Asso- ciation Rules Based. We also propose a method named Graph- Based. In order to better evaluate our experiments, we suggest a baseline approach, which consists in recommending the most frequent items to the users.

A. Baseline Approach  We suggest a simple and intuitive Baseline method as a point of reference. Due to their simplicity, it is expected that any proposed system is able of overcoming at least this reference point. The Baseline will be used in the comparison of our results and can be used in future studies by other researchers.

Let ? be the number of users ? = {?1, ?2, ..., ??} and ? the number of all possible items that can be recommended ? = {?1, ?2, ..., ??}. Now, let ? be the number of sessions in a web site ? = {?1, ?2, ..., ??}. Each session ? = ??, ??? is a tuple defined by a user ? ? ? and a set of accessed items ?? ? ? .

Given a data set ?, the Baseline method learns/builds a model ? that always recommends the ? most frequent items ? ? ?. The basic idea of the method is that if there are highly frequent items, also there is a high probability that any user may be interested in one of these items. Considering that the data set is constantly updated, it is possible to recommend items that are in vogue at the time of the search. It is intuitive to think that a user can follow a search pattern in common with most other users in a given period of time. However, it is clear that this pattern will not be followed by all users.

Therefore, we have this pattern only as a point of reference to be overcome.

B. Item-Based Collaborative Filtering  The Item-Based Collaborative Filtering technique analyzes web items to identify relations among them [10]. Here, the recommendation model ? is a matrix representing the sim- ilarities between all the pairs of items, according to a given similarity metric. An abstract representation of a similarity matrix is shown in Table I. Each item ? ? ? is an accessed item, for example, a given name.

TABLE I ITEM-ITEM SIMILARITY MATRIX  ?1 ?2 ? ? ? ?? ?1 1 ???(?1, ?2) ? ? ? ???(?1, ??) ?2 ???(?2, ?1) 1 ? ? ? ???(?2, ??) ? ? ? ? ? ? ? ? ? 1 ? ? ? ?? ???(?? , ?1) ???(?? , ?2) ? ? ? 1  According to [10], the properties of the model and con- sequently the effectiveness of this recommendation algorithm depend on the method used to calculate the similarity among the items. To calculate the similarity between pairs of items, for example, ?1 and ?2, we first isolate the users who have rated both of these items, and then, we apply a metric on the ratings to compute the similarity ???(?1, ?2) between ?1 and ?2.

Metrics to measure similarity between pairs of items are cosine angle, Pearson?s correlation and adjusted cosine angle [11]. In this paper, we use the cosine angle metric, defined as  ???(?1, ?2) = ???( ?? ?1 ,  ?? ?2 ) =  ?? ?1 .

?? ?2  ?????1 ?? ? ?????2 ?? , (1)  where ?? ?1 and  ?? ?2 are rating vectors with as many positions  as existing users in the set ? . The operator ?.? denotes the dot-product of the two vectors. In our case, the rating vectors are binary. The value 1 means that the users accessed the respective item. The value 0 has the opposite meaning.

Once we obtain the recommendation model, we can gen- erate the recommendations. Given an active session ?? con- taining a user ?? and its set of observable items ? ? ? , the model generates the ? recommendations as follows. First, we identify the set of candidate items for recommendation ? by selecting from the model all items ? /? ?. Then, for each candidate item ? ? ?, we calculate its similarity to the set ? as  ????,? =  ? ?????? ???(?, ?)? ???? ???(?, ?)  , (2)  where ?? is a set with the ? most similar items (the nearest neighbors) to the candidate item ?. Finally, we select the ? candidate items with the highest similarity to the set ? and recommend them to the user ??.

C. Association Rules Based  A recommendation model ? based on association rules is a set of rules. Each rule ? has the form ? : ? ? ? , where ? ? ? and ? ? ? are sets of items and ? ? ? = ?. Each association rule is characterized by two metrics: support and confidence [12].

Discovering all association rules from a data set ? consists in generating all rules whose support and confidence are greater than or equal to the corresponding minimal thresh- olds, called minsup and minconf. The classical algorithm for discovering association rules is Apriori [12].

To learn/build the recommendation model ? using associa- tion rules, each session is represented as a set of pairs < ?, ? > with the same ?, where ? and ? respectively identify the user and the accessed item. These sessions are used as input to an association rules algorithm to generate a set of rules. Once we have the model, we can make recommendations, ?, to a new session. Given an active session ?? containing a user ?? and its set of observable items ?, we build the set ? as follows [13]:  ? = {??????????(?)?? ? ? and ??????????(?) ? ? and ??????????(?) /? ?}. (3)  To obtain the ? recommendations, we select from ? the ? distinct recommendations corresponding to the rules with the highest confidence values.

D. Proposed Method  In this section, we propose our method for recommending given names, called Graph-Based. This method considers the frequency and order of users? queries to recommend new objects (e.g., given names).

A graph is defined by the tuple ? = ??,?,??, in which ? represents the set of objects, ? represents the set of relations among the objects and ? represents the weights of the rela- tions. In a recommender system, the objects represent the items to be recommended and the edges among the objects represent a strength that will be used in the recommendation process.

Higher relations increase the possibility of recommendation.

For the problem of recommending given names, the objects are the names and the relations, with their respective weights, between a name ? and a name ? represents the frequency in which a user searched for the name ? followed by the name ?. For instance, if a user searched for Rafael and then by Everton, a connection between the objects Rafael and Everton is created. The value 1 is assigned to this connection. If the same search is repeated, the weight of the connection is increased (in this case ????????,?????? = 2).

We also consider that the same user can search for several names in a same session. For instance, the user can search for Rafael, Renan, Bruno, Marcos and Vinicius. In this case, we can generate connections between names considering two approaches: 1) two names in a row and 2) among all names in a user?s session. In this paper, these approaches are referred as GB-1 and GB-all, respectively.

For GB-all approach, we can assign/increase the value 1 to the connections or consider different weights according to the order that the names were searched. In this paper, we consider that the weight of a connection between a name that comes after other name is higher since this names tend to be more related. Considering this assumption, we used the following equation:  ??,? = ??,?+  ( 1?((?????[?]??????[?])?1)? 1??? ? 1  ) ,  (4) in which ?????[?] and ?????[?] represent the order in which the names ? and ?, respectively, were searched and ??? represents the number of names searched by the user. If the user searches for the names Rafael, Renan, Bruno, Marcos and Vinicius, the Equation 4 generates/increases the weights as presented in Table II.

TABLE II EXAMPLE OF CONNECTION WEIGHTS FOR THE SEQUENCE OF QUERIES  RAFAEL , RENAN , BRUNO , MARCOS AND VINICIUS  Connection Weight Rafael Renan 1.00 Rafael Bruno 0.75 Rafael Marcos 0.50 Rafael Vinicius 0.25  An example of a graph for the task of recommending given names is shown in Figure 1. For each object of the  graph we can recommend names based on the weights of the connections. The graph also allows to recommend objects that are not directly connected with the interested name. For instance, in Figure 1, the name Vinicius is not connected to the name Rafael. However, the name Vinicius is connected to Marcos and this one is connected to Rafael.

Therefore, we can recommend the name Rafael when the name Vinicius appears.

Fig. 1. Example of a graph for recommending given names

III. EMPIRICAL EVALUATION  In this section, we empirically evaluate the recommendation algorithms, presented in Section II, in the task of recommend- ing given names.

A. Data Set  The empirical evaluation is carried out using an usage data set from Nameling2. According to [14], Nameling is a search engine and a recommender system for given names. In this system, the user enters a given name and obtains a browsable list of recommended names, called ?namelings?. A screen of the Nameling web site is presented in Figure 2.

The data set is derived from the Nameling query logs, rang- ing from March 6th, 2012 to February 12th, 2013. It contains 515,848 accesses from 60,922 users to 20,714 different items (i.e., given names). There are five types of accesses/activities in this data set3:  1) ENTER SEARCH: The user enters a name directly into Nameling?s search field;  2) LINK SEARCH: The user follows a link on some result page;  3) LINK CATEGORY SEARCH: Wherever available, names are categorized according to the corresponding Wikipedia4 articles;  4) NAME DETAILS: Users can get some detailed infor- mation for a name;  5) ADD FAVORITE: Users can maintain a list of favorite names.

2http://nameling.net/ 3We use the terms access and activity interchangeably.

4http://www.wikipedia.org/     Additionally, for each access there are a timestamp and a proxy for the user?s geographic location (i.e., country code, province, city, latitude and longitude) which is obtained by using the MaxMind?s GeoLite City data base5. Finally, there is a file with a list of known names containing all names which are currently known in the Nameling web site. As we will see in Section III-C, all names that occur in the evaluation data set are contained in this list of names. The data set is available on http://www.kde.cs.uni-kassel.de/nameling/dumps.

B. Pre-processing of the Data Set  Before running the experiments, we pre-processed the data set by replacing invalid names and removing singleton ses- sions, as described below:  Replacing invalid names: In real-world data sets, it is common to find several variations of a name, for exam- ple, spelling variations due to typographical errors (like ?Richard? and ?Ricahrd?) and differences in punctuation marks (like ?O?Reilly? and ?O Reilly?). Considering the existence of a reference list with valid names, we can use string comparison measures to replace an invalid name by the nearest valid name, thus believing that we are correcting a name typed incorrectly. Thus, in the data pre-processing step we use the list of known names, described in the previous section, and apply the Jaro- Winkler measure [15] for detection and replacement of invalid names. The Jaro-Winkler measure was selected for this work because it shows better performance in studies involving name-matching [16].

Removing singleton sessions: For different reasons, users often access only one item on a web site and then leave it. The use of these sessions containing a singleton access by a recommender system can affect its accuracy negatively [17]. For example, singleton sessions will never count for the item-item similarity in the Item- Based Collaborative Filtering technique or to generate a connection in the graph based method. Thus, we have removed the singleton sessions from the data set.

After pre-processing the data, we obtained a set with 510,705 accesses from 55,779 users to 20,318 different names.

C. Experimental Setup and Evaluation Metrics  To carry out the experiments, the data set is split in training and test sets by using the Perl script available in http://www.

kde.cs.uni-kassel.de/nameling/dumps/process activitylog.pl.

The script selects some users with at least five different names for the test set. Then, for each test user, it withholds the last two entered names for evaluation. To withhold the last two entered names, the script uses the following rules.

For each test user, the script selects for evaluation the last two names which had directly been entered into the Nameling?s search field (i.e., ENTER SEARCH access) and which are also contained in the list of known names. The script only considers those names which were not previously added as a  5http://www.maxmind.com/  favorite name by the test user (i.e., ADD FAVORITE access).

Finally, the script removes the accesses after the names for evaluation and keeps in the test set only users with at least three accesses. The remaining users in the data set are used as training set.

To evaluate the recommendation algorithms, we compute the metric Mean Average Precision (MAP) [18]. For each test user, the metric takes the left out names and compute the precision at the respective position in the ordered list of recommended names. These precision values are first averaged per test user and than in total to obtain the final score. Here, we consider the assumption that users looking for a name are willing to scroll through a list of possible names before to choose one. Therefore, we use MAP@1000 which means that only the first 1,000 positions of a list of recommendations are considered. A Perl script to compute the MAP@1000 is available on http://www.kde.cs.uni-kassel.de/nameling/dumps/ evaluate recommender.pl.

D. Empirical Results  We start by analyzing the Item-Based Collaborative Filter- ing technique. For this technique, the ? recommendations are generated based on their 1, 5, 10, 15 and 20 most similar items (the 1, 5, 10, 15 and 20 nearest neighbors). In Table III, we see that the values of MAP@1000 decrease when we increase the number of neighbors. This fact occurs because when we increase the number of neighbors, less similar items are used to generate the recommendations.

TABLE III MAP@1000 VALUES FOR THE ITEM-BASED COLLABORATIVE FILTERING  TECHNIQUE  K-neighbors MAP@1000 K = 1 0.0078 K = 5 0.0047 K = 10 0.0039 K = 15 0.0037 K = 20 0.0035  In Table IV, we have the MAP@1000 values for the Association Rules Based algorithm. In this algorithm, the recommendation models are built using a minimum support value determined to generate around 10,000; 50,000 and 100,000 rules. The minimum confidence values are defined as being the support value of the one thousandth most frequent item in the training set. This allows the generation of at least 1,000 rules without antecedent that can be used by default, in the case that no other rule applies.

TABLE IV MAP@1000 VALUES FOR ASSOCIATION RULES BASED ALGORITHM  Number of Rules MAP@1000 10,000 0.0266 50,000 0.0254 100,000 0.0237  Table V shows the MAP@1000 values for both Graph- Based methods: GB-1 and GB-all. Although, GB-all generates     Fig. 2. The Nameling web site  four times more connections between names in the graph than the GB-1, it is not better than the GB-1 approach. This behavior could be explained by the quality of the created connections. GB-1 creates connection (or increases its weight) only between names in a sequence. We believe this more restrictive approach represents the recommendation of names in a better way. Moreover, the smaller the graph, the faster is the algorithm to recommend given names.

TABLE V MAP@1000 VALUES FOR EACH GRAPH-BASED METHOD AND THE  AMOUNT OF CONNECTIONS CREATED IN THEIR CORRESPONDING GRAPHS  Method MAP@1000 # Connections GB-1 0.0321 147,452 GB-all 0.0312 587,438  In Figure 3, we show the MAP@1000 for each recom- mendation algorithm. There, we can see that the Association Rules Based algorithm with 10,000 rules and the two Graph- Based methods (i.e., GB-1 and GB-all) outperform the Base- line approach. In the figure, we can also see that the Item- Based Collaborative Filtering technique provides the worst performance.

We also compare the results among the Tables III, IV and V.

The best option for each paradigm was selected to make this comparison. Table VI shows the MAP@1000 values of each algorithm and its corresponding improvement over the Baseline.

We see in Table VI that the Graph-Based method provides the best value for MAP@1000 (i.e., 0.0321) with an improve-  Fig. 3. Comparing the recommendation algorithms against the Baseline  ment of 25% over the Baseline approach. The Association Rules algorithm also improved in 4%. On the other side, the Item-Based Collaborative Filtering technique was not able to outperform the Baseline approach. Moreover, its MAP@1000 value was 69% worse than the Baseline. It is worth noting that the Baseline can be an option in this case, although it does not personalize its recommendations for each user.

TABLE VI MAP@1000 VALUES AND RELATIVE IMPROVEMENT OVER THE BASELINE  FOR THE BEST OPTION FROM EACH PARADIGM  Method MAP@1000 Improvement Baseline 0.0256 ? Graph-Based 0.0321 25% Association Rules 0.0266 4% Colaborative Filtering 0.0078 -69%

IV. FINAL REMARKS  Although the task of recommending given names is relevant in practice, little research has been performed on the per- spective of recommender systems. In this paper, we analyzed and compared some recommendation algorithms in the task of recommending given names. The results of our empirical evaluation have showed that by using the proposed Graph- Based method, we can improve the recommendation of given names in 25% with respect to the Baseline approach.

There are some directions to be explored in future research.

For example, other pre-processing tasks can be applied on the data set in order to improve the quality of the data.

We can also try other recommendation algorithms that makes use of additional information, like the timestamp and/or the geographic location, to improve the recommendation of given names.

