A Transparent Rollback Recovery Algorithm for virtual  Machines using Quasi-Synchronous Checkpoint

Abstract? Considering the characteristic of the virtual machines applied on cloud platform, a quasi-synchronous checkpoint algorithm with selective message logging for virtual Machine is presented. This algorithm keeps the inherent optimized checkpoint interval of the VM nodes, saves volatile message log by virtual machine monitor (VMM) and selectively save stable storage log to maintain the consistency of the whole system. Performance evaluation result shows that, the algorithm not only maintains the autonomy checkpoint, but also lowers communication cost and storage cost. It is suitable for the cloud platform to manage the virtual resource and virtual machine migration.

Keywords?Quasi-Synchronous Checkpoint; Selective Message Logging; rollback recovery; Virtual machine

I. 1 INTRODUCTION The virtualization technology provides optimized  processing environment for cloud computing system resource management. Through virtualization technology, we can organize wide variety of computing resources dynamically, isolate the close relationship between specific hardware architecture and software system and implement transparent scalable computing system architecture.

In traditional distributed systems, as one of the most important technology to achieve software fault tolerance and process migration, checkpoint and message log technique could not be widely used due to the high overhead added on the system resources. The virtualization system, on one hand, optimizes the management of system resources which provide the possibility to reduce checkpoint overhead; on the other, provides a global view of the operating system resources which provides a good platform to monitor the system global consistency. Checkpointing, as an important technique for fault-tolerant and process migration, is drawing more and more attention in cloud computing.

Coordinated checkpoint is widely used to save state in existing virtualization system, but in the large-scale distributed virtualization system, coordinated checkpoint [1] will cause performance degradation as follows:   1 This work was partially supported by the NSFC under grant 61003047 ,the National High Technology Development 863 Program of China under Grants 2013AA01A215 and the Fundamental Research Funds for the Central Universities(Grant No.HIT.NSRIF.2014067).

(1) High overhead in synchronization: In the process of message synchronization, coordinated checkpointing blocks the network to ensure virtual machines exchange all coordinated messages to achieve synchronization. During this period, the system is unavailable, and synchronization overhead would not be tolerable in large-scale cloud systems.

(2) Checkpoint time overhead: Due to the large virtual machine files, checkpoint time will be long, and the distributed system is also unavailable, which leads to decreasing the system availability.

(3) High storage overhead and competition of storage: Since the virtual machines need to save the entire image, it demands large storage space. Meanwhile, most of distributed systems using network storage, competition of network storage is also a very important issue during coordinated checkpoint.

In the large-scale virtualized computing environment, different factors[1], such as computing tasks, communication traffic load, reliability, etc, have different influence on optimal checkpoint interval, it is reasonable for different kinds of virtual machines employ different checkpoint intervals autonomously. So, quasi-synchronous checkpoint algorithm of virtualized environments suits large-scale distributed systems.

Quasi-synchronous checkpoint allows processes to have checkpoint independently, and ensure a global consistent checkpoint through the dependence of messages simultaneously. However, the traditional quasi-synchronous checkpoint ensures the consistency of the system by taking the forced checkpoint, damaging the inherent checkpoint interval and increasing the overhead. Since virtualization can provide a global view of the system resources, we can keep the inherent checkpoint period while reducing system fault tolerance overhead by utilizing the fine-grained message logging.

This paper presents a quasi-synchronous checkpoint with Selective Message Logging algorithm, which temporarily stores message logs on the virtual machine monitor (VMM) to maintain the inherent checkpoint interval of virtual machine and reduce the communication and storage cost. At the same time, because the monitoring node has a global view of the whole system, the algorithm selectively stores stable message logs which keep the consistency of the system based on dependency tracking and the selective logging which keeps system consistent. Thus, the fault tolerance mechanism performs in multi levels: checkpoint, temporary message logging and selective stable storage message logging, in order   DOI 10.1109/CLOUDCOM-ASIA.2013.31    DOI 10.1109/CLOUDCOM-ASIA.2013.31     to reduce the cost of communication and storage of VM systems effectively.



II. RELATED WORK In a VM system, it needs to save the status of GuestOS  periodically or non-periodically in order to implement migration and recover a virtual machine when it fails. The VM systems commonly used coordinated checkpoint to save state, and Walters et al[2] presents OpenVZ-based VM checkpoint.

OpenVZ is an OS-level virtualization, and each GuestOS is abstracted as Virtual Private Server (VPS). With checkpoint function of LAM, it allows the VPS taking checkpoint. The daemon, Ovad, copies checkpoint to multiple nodes to improve overall system reliability. the Virtual Cluster Checkpoint (VCCP),presented by H.Ong et al [3], embeds checkpoint function into VMM to checkpoint the virtual machine, trying to reduce  the burden of the upper layer application and the guest operating system. In a virtual cluster, checkpointing is initiated by a virtual machine which is the head node in cooperation with other nodes to complete checkpointing. A.Kangarlou et al[4] organizes multiple virtual machines on a host into a virtual domain (the VM platform is XEN) through VIOLIN virtual network, and takes coordinated checkpoint in each virtual domain. D.P.Scarpazza[5] and Geoffroy Vallee [6] connects Xen-based virtual hosts via InfiniBand network, and take coordinated checkpoint by enhanced ARMCI (Aggregate Remote Memory Copy Interface) in the virtual cluster.

Quasi-synchronous Checkpointing is also called communication induced checkpoint, including model-based quasi-synchronous checkpoint and index-based quasi- synchronous checkpoint. Model-based quasi-synchronous checkpoint avoids inconsistency between the processes by preventing certain communication and checkpoint pattern, including the MRS protocol [7], BQC protocol [8] and RDT protocol [9]. Index-based checkpoint algorithm is derived from the idea of Lamport logical clock, which uses a timestamp (integer index) to represent the logic clock to coordinate checkpointing and form global consistency checkpoint with the same index [10,11]. D.Manivannan and M.Singhal[12] describe index-based checkpoint algorithm, and put forward an integral QSA (Quasi-Synchronous algorithm) protocols, including quasi-synchronous checkpoint algorithm, rollback algorithm, garbage collection and in- transit message processing. Other researches [11,13] present some optimization methods, including Lazy-Index and Aftersend. All above focus on checkpoint in traditional distributed system, Quasi-synchronous Checkpoint in cloud computing has not been discussed yet.



III. SYSTEM MODEL AND BASIC DEFINITIONS  A. System Model We investigate a typical architecture of cloud platform,  and Figure 1 shows a model built on CloudStack. Assuming multiple GuestOS virtual machine (VM) instances and a sole VMM on a single physical machine and, the VMM maintains messages forwarding among multiple virtual machines and controls checkpoint taken. While the Manager Server Cluster, a central control platform of the entire system, takes a global  view of the virtualization platform resource usage, and is responsible for the maintenance the consistency of system.

The Manager Server manages the images of virtual machine checkpoint and the information of message log, which are stored in the stable storage periodically. Thus, the algorithm manages and maintains consistent global checkpoints and message log by a multi-level view: Manage Server level, VMM-level and GuestOS level, which reduces unnecessary forced checkpoints and message logs and lowers communication and storage cost significantly.

Figure 1 Architecture of VM platform  B. Basic Definitions In the virtualized environment, distributed computing is  constructed from concurrent processes in VMs. Computing model is event-driven, and message sent and receipt are both events.  Let H be a set of events in distributed computing, and computing model can be represented by ( )? , hbH H ????= , in which hb???? denote Lamport?s happen before relationship[14].

Computing model follows the piecewise deterministic (PWD) assumption[14]: the execution of any process can be regarded as a set of states intervals and nondeterministic events initiate the state intervals. Each process stores local checkpoints periodically. Each checkpoint is assigned a unique serial number. The x-th checkpoint of process Pi is assigned number x, and denoted as Ci,x, corresponding to the local state i,s (x  s). Ci,x results from the sequence of events between Ci,x-1 and Ci, x.

In distributed system, a consistent system state [1] is a snapshot that the actual execution passed through or could have passed through. Process reflects a message receipt, then the state of the corresponding sender reflects that it has sent that message.

Definition 1: a global checkpoint  0 1 2 ,0, 1, 2, { , , ...... }  nn mm m mGC C C C C= is called a global consistent  checkpoint if and only if for any message m, the following  condition holds:     ( ) ( ), ,i ji m j mreceive m C send m C? ? ? , ii mC GC? , jj mC GC? ,  and 0 1,0 1i n j n? ? ? ? ? ? .

Global consistent states guarantee that no orphan message occurs, whose sender has not sent the message and receiver has received the corresponding message, which is impossible in reality. The goal of any recovery protocol is to rollback system to a consistent state when it fails. Consistent global checkpoint is also called a recovery line [1], and checkpoint- based rollback-recovery protocols must guarantee that the system should be able to determine recovery line when an error occurs.



IV. QUASI-SYNCHRONOUS CHECKPOINT WITH SELECTIVE MESSAGE LOGGING  We present a Quasi-Synchronous Checkpoint with Selective Message Logging Algorithm for virtual Machine, for short, VM_QSC in which different types of VMs take checkpoint in accordance with its own optimal checkpoint period.VMM stores checkpoints of each GuestOS temporarily and flushes to stable storage when the load of network is low.

The forwarded messages are also stored temporarily to ensure that the failure of a VM can not affect other VMs? consistent state. Meanwhile, it selectively logs messages on stable storage to ensure the system keeping a consistent state.

Manager node in the cloud platform maintains the global consistent state and monitors  the status of the entire system.

A. Time-based Quasi-synchronous Checkpoint Each virtual machine has a desired checkpoint cycle,  which is a multiple of basic time-cycle T0. The node with basic time-cycle take minimum checkpoint interval, and take checkpoint synchronously when the timer timeouts; the node with multi-cycle has a checkpoint interval which is multiple of ?0. We name the two type of node: SI (Single Interval) and MIi(Multi Interval), corresponding to node with basic period and node with multi-period, for MIi, i represents the number of basic time-cycle T0.

VM_QSC utilize time-based quasi-synchronous checkpoint: VMM and VM node take checkpoints according to the basic time-cycle ?0, that is, SI-type node take basic checkpoints and MIi-type node take checkpoints at the time i?0. VMM maintains a consistent recovery line of each physical machine node, and count basic interval of each node, which is regarded as the reference synchronization index value. When it is time to take a checkpoint, the system consistent recovery line keeps unchanged until all processes need to take checkpoint have finished taking checkpoints; when VMM detects all processes completing taking checkpoint, it updates the consistent recovery line.

Figure 2 quasi-synchronous checkpoint  As shown in Figure 2, VM1,VM2,VM3 and VM4 are the instances of virtual machine GuestOS, in which VM2 and VM3 are SI-type , and others MI2. At T0 ,VM2, and VM3 finish taking checkpoint, and the consistent line is (C1,0, C2,1, C3,1, C4, 0). At 2T0, because of clock drift, VM2 sends the message m after taking checkpoint C2,2, but the C3,2 has not taken when m reaches VM3, so VM3 takes the checkpoint in advance to maintain consistency. At this point, the system still maintains a consistent line (C1,0, C2,1, C3,1, C4,0) when all the checkpoints are taken, the consistent line moves to (C1,2, C2,2, C3,2, C4,0).

When a VM GuestOS fails, VMM, which is in charge of the VM, commits recovery by checkpoint and message log stored in local storage. If a physical node fails, the related physical nodes will rollback to a consistent line to maintain consistency.

Since there is no global clock in system, there are clock skew between each node. The inconsistency of checkpointing, caused by clock drift which is far less than the period of checkpointing, can be resolved by selective message logging as following.

B. Selective Message Logging Using quasi-synchronous periodic checkpoint alone cannot  guarantee the consistency of the system, requiring the log to avoid orphan messages caused by the failure of VM. The VMM of the physical node stores receiving messages logs in memory temporarily, and utilizes selective message logging to record the message received by the MI node in stable storage, while SI node does not store any message log in stable storage, so that each VM node reduces the number of stable message when maintains the inherent period of checkpoint.

Algorithm is presented in two parts, failure-free execution and rollback recovery.

1) The protocol of VM For the virtual machine, it just needs to take checkpoints  following the inherent period, and  to calculate the recovery line according to the serial number of the checkpoint. The message sent just need to carry INCNUM (means incarnation number) and the serial number of the current checkpoint, INCNUM, indicating the recovery times of process in history, is incremented each time the node fails, in order to know that the message is sent before or after the last rollback recovery.

2) The protocol of VMM The VMM on the physical node performs most of work of  the algorithm as follows: (1) Data structure: Certain VMi belongs to VMM node maintains the  following data structure:     Received_MsgLogi: the queue of message received by VMi, stored in the volatile storage of VMM  Stable_Received_Msglog: the stable queue of message received of MI node, stored in the volatile storage of VMM and flushed to stable storage in basic time;  CSNi: the serial number of VM?s current checkpoint; INCNUMi: serial number of the times that node fails in  history, incremented each time node fails and rollbacks recovery;  nexti: the serial number represents the basic checkpoint interval, assuming that x is the basic checkpoint interval, and all the checkpoint intervals of nodes are integer multiple of x, then nexti increments in each x time units.

Rsn_Listi: recording RSN(received serial number) of message received by VMi from the last checkpoint, to ensure rollback recovery according to the order of the messages sent and received. For each message m, VMM saves the determinant of message #m= <m.source,m.ssn,m.rsn, m.dest,m.TSN> that  identifies m uniquely in stable storage.

Ckpt_Set_Vector: (bSet1, bSet2, ... , bSetn) records nodes that need to take checkpoints in the next time cycle, if need, bSeti = 1, otherwise bSeti = 0.

(2) When the timer of iT0 timeouts: VMM detects the Ckpt_Set_Vector, and leads all the VMs belong to it to do as follows:  a)for the VMs whose bSeti = 1, take checkpoint and saved in VMM; b)for the VMs whose bSeti =0, save the Received_MsgLogi to Stable_Received_Msglog, then updates the Rsn_Listi; c)All the VMs increments nexti; d)VMM updates the current consistent line in accordance with quasi- synchronous checkpoint algorithm described in above section.

(3) VMMp receives the computing messages from VMi of the physical machine: if receiver is VMj of the same physical node, message is stored in Received_MsgLogj; then recorded in Rsn_Listj, or transfer directly if receiver VM belongs to other VMM.

(4) VMMp receives the messages transfered to the local virtual machine VMi from VMMq: the message is stored in Received_MsgLogi and recorded in Rsn_Listi, then forward to VMi.

C. Rollback Recovery By utilizing multimode redundant mechanism in Manager  Server, it can be considered that MS is reliable in virtual environment, so the failure and rollback recovery of MS needs not to be discussed.

When only VM fails, the restored message log can be obtained from the VMM of physical nodes to which VM belongs, algorithm described as follows: when the VMM receives a request of rollback recovery of VMi, it will deliver the checkpoint stored in stable storage by VMi to the initial node, and send the received message stored in the VMM memory in the order as sent before failure, to complete consistent rollback recovery of VMi .

As the consistent recovery line and the determinant of messages stored in stable storage, each virtual machine completes consistent rollback recovery by state reconstruction  when the physical node fails. After rollback recovery, a VMM will receive messages sent before system fails, so VMM must distinguish them.

When physical node finishes rollback recovery, because the recovery information is managed by the monitor node, it can avoid orphan message.VMM needs to deal with three kinds of special messages of VM: lost message, duplicate message and delayed message, which can be distinguished by m.csn, m.INC, m.ssn, consistent line information recorded by the VMM (Rec_Line) and INCNUM carried by message, and the queue of determinant stored in a stable queue during rollback recovery.

Lost messages: messages whose send events are not undone but receive events are undone due to rollback. VMM should forward the messages to the destination. Messages can be determined lost in two conditions:  (1) When the message m.type = MI, m.inc <INCNUM (indicating that the message m is sent before the failure of the VMM), if m.nexti = Rec_Line, it can determine that the message is lost.

(2) When the message m.type = SI, m.inc <INCNUM, if m.csn <Rec_Line, it can determine that the message is lost.

Delayed Messages: Messages that were sent before the rollback whose receive events are not recorded because the messages were received either while the receiving process was down or received after the rollback of the receiving process.

This type of messages are discarded after rollback recovery. In two conditions, the message can be determined delayed:  (1) m.type = SI, m.inc <INCNUM, m.csn> Rec_line; (2) m.type = MI, m.inc <INCNUM, m.nexti  > Rec_line.

Duplicate messages: Messages which were sent and  received before rollback. this kind of messages are duplicate messages which will be discarded . In our protocol, only the MI-type node generates duplicate messages, that is, m.inc = INCNUM, but m.csn < rec_Line, m.ssn is in the queue of determinant of VMM ,that can determine duplicate messages which can be discarded ; if m.ssn is not in the queue of determinant of VMM, the message can be regarded as re- generated lost message and received normally.

Algorithm of rollback recovery when VMM fails is shown as following:  When VMMp fails For all VMi which are managed by VMMp do  Retrieve and Send the last checkpoint to VMi; VMi.INC := VMi.INC + 1; If (VMi.type =MI VMi.csn<Rec_Line)  Retrieve Stable_Received_MsgLog from VMMp?s stable storage and transfer to VMi;  For all the message M in Rsn_Listi If (M.rsn>Rec_Line.rsn)   //M is a lost message; Inform m.sender to resend M;  Endfor Endfor  When VMMp receives a message M from VMi after Rollback if (M.INC< VMMp .INCNUM)  If (M.next Rec_Line) Log M and transfer to M.dest;  //M is an in-transit messge;     Else  Discard M;                  //M is a Delayed Message; Elseif (M.INC> VMMp .INCNUM)  If (M.ssn is in the transfer_log) Discard M;              // M is a Duplicated Message;  Else Log M and transfer to M.dest;

V. PROOF OF CONSISITENCY In this section we prove that VM_QSC algorithm can  guarantee the system consistency: Lemma1: VM_QSC can guarantee that no orphan  messages  will occur when VM or VMM fails.

Proof: 1) When certain VMi fails, the checkpoint and  Received_MsgLogi in the VMM which VMi belongs to can consistently restore VMi, no orphan messages  will occur.

2) When certain VMMi fails, the VMs in the same physical node will rollback to the consistent line, SI-type VMs rolls back to last checkpoint, MI-type VMs rolls back to last checkpoint and restore the Stable_Received_Msglog until the consistent line from stable storage, According to PWD characteristic,  the messages which sent by MI-nodes before VMM?s failure will be definitely restored in the re-execution, the condition (deliver(M) ? Cj,y) ? (send(M) ? Ci,x) will not happen, that is, no orphan messages  will occur.

Lemma2: VM_QSC can identify and handle lost messages, delayed messages and duplicate messages in order to keep the system consistent.

Proof:  In last section, we have discussed the identification and handle of the three types of messages, so VM_QSC can keep strong consistency of the system.

Lemma3: When certain VMi migrates from VMMi to VMMj, the system can keep consistent.

Proof: When VMi migrates, Received_MsgLogi and checkpoint in the volatile storage of VMMi and the Stable_Received_Msglog in the stable storage can guarantee the migration in consistently progress. The migration progress is not discussed here.

Theorem1: VM_QSC can keep the system consistent in the failure-free and recovery execution.

Proof: There are two conditions to discuss: 1) When VMM is failure-free, the messages and  checkpoints transferred between VMs can be looked as stable stored because in this case, the storage of VMM can be looked as stable storage, so the consistent can be guaranteed.

2) When certain VMM fails, from Lemma1, we can prove no orphan messages will occur, from Lemma2, VM_QSC can rightly identify and handle lost messages, delayed messages and duplicate messages, from Lemma3, migration of VM will not destroy the consistent, so, we can conclude that the whole system is always in a consistent condition.



VI. PERFORMANCE EVALUATION AND SIMULATION  A. Performance Evaluation This section evaluates the performance of VM_QSC and  calculates the proportion of the selective messages logging stored in stable storage, since stable storage suffers the serious performance penalty, the less message stored in stable  storage ,the high performance we can get. We describe a performance analysis in a simplified condition that there exist two kinds of desired checkpoint cycles: SI and MI2, and assumes as below:  (1)SI-type node sends a message to SI-type node following a Poisson distribution with the  rate of ??1  (2)SI-type node sends a message to MI2-type node following a Poisson distribution with the  rate of ??2  (3)MI2-type node sends a message to SI-type node following a Poisson distribution with the  rate of ??1  (4)MI2-type node sends the message to MI2-type node following a Poisson distribution with the  rate of ??2  (5)There is no need to consider the delay to send a message, that is, the receiver always receives messages without delay.

(6)Assuming the ratio of two types of nodes is 1:1.

To calculate the proportion of the selective messages  logging stored in stable storage accounting for all forwarding messages, it calculates the average number of messages received by two types of processes at a checkpoint interval respectively.

SI-type node sends a message to SI-type node following a Poisson distribution with the  rate of ??1, that is  { } ( ) 111 ( ) !

m  ttP N t m e m  ?? ?  ?? ?= = among which t>0, so in a  checkpoint period T0, the average number of message received by SI-type node from the SI-type node is:  ( ) 011 01 1 0  ( ) ( )  !

m  m  TTN E N T m e m  ?? ? ?  ???  =  = =?  1 0 1 0  1 0 1 0  T TT e e T? ?? ?? ?? ? ?= ? =  MI2-type node receives a message from SI-type node following a Poisson distribution with the  rate of ??2. In a checkpoint period 2T0, 2 2 02N T? ??= , similarly, 2 2 02N T? ??=  1 1 0N T? ??= .

We calculate the total number of messages received by SI- type node in the period T0. According to the property of the Poisson process, Poisson process  ( )N t  ? ,  ( )N t  ? is independent  with intensity ??1, ??1 respectively, thus 0 1 1 ( ) ( ) ( )  TP N t N t N t? ?= +  is still the Poisson process, and { } { }0 1 1( ) ( ) ( )TP Np t m P N t N t m? ?= = + =  { }1 1  ( ) ( ) m  k  P N t k N t m k? ? =  = = + = ??  1 1  ( ( ) ) ( ( ) ) m  k  P N t k P N t m k? ? =  = = = ??  [ ] [ ] ( )     ( )( )  ! !

m k tk tm  k  t et e  k m k  ?? ??  ?? ??  ? ??  =  = ?  ? ?  ( ) 1 1( )  1 1  ! 1  ! ! !

k m  t m k  k  m e  k m k m ? ?? ?  ? ?? ? ? + ?  =  = ?  ? ? ? ?  1 1( )1 1 [( ) ]  , 0,1, 2, !

m tt e m  m ? ?? ?? ?  ? ? ? ++= = ? ? ?     Namely,  ( ) T  P N t  is the Poisson process whose intensity is  1 1? ? ? ?+ , so, in the checkpoint period T0, the average number of messages received by SI-type nodes is  0 1 0 1 0 1 1 0  ( ) ( ) ( ) ( ) T  P N T N T N T T  ? ? ? ? ? ?= + = + .Similarily, in the  checkpoint period 2T0,the average number of messages received by MI2-type node is  2 0 0 2 0 2 0 2 2 0  (2 ) (2 ) (2 ) 2( ) T  P N T N T N T T  ? ? ? ? ? ?= + = + , and the average number of  messages that need to be saved on stable storage is half of the message MI2-type node receives, that is, the proportion is:  2 2 0 2 2  1 1 0 2 2 0 1 1 2 2  ( ) ( )  2( ) 2( ) 2( )  T  T T ? ? ? ?  ? ? ? ? ? ? ? ?  ? ? ? ? ?  ? ? ? ? ? ? ? ?  + + = =  + + + + + +   Since the number of messages passed by MI2-type node is fewer than SI-type, ??2, ??2 are smaller than??1, ??1, for example: ??1/??2 = 2:1, ??1/??2 = 2:1, ??2/??2 = 2:1, so ? = 1/6, that is, only 1/6 of the messages need to be stored in stable storage. Clearly, the proportion of selective logging of messages stored in stable storage is low, so the algorithm can lower the overhead of the whole cloud system.

B. system simulation We compare the overhead of three checkpoint algorithms  through simulation using OPNET. The three algorithms are respectively VM_QSC presented by this paper; QSA(the classic Quasi-Synchronous Checkpoint) and TBSC(time-based Synchronous checkpointing). The overhead metrics include checkpointing cost, stable stored cost and rollback recovery cost.

Firstly, we discuss the cost of rollback recovery: when the VM fails, the rollback recovery cost of the three algorithms is identical and when the VMM fails ,the cost of re-execution of message logging is close to checkpoint, the cost of  the three algorithms is also similar. So, the overhead of rollback recovery is nearly the same for all the three algorithms and we do not compare this part of cost in simulation.

Then we compare checkpoint cost and message log cost.

We assume two kinds of nodes: SI-type and MI-type. In VM_QSC and QSA, the ratio of the two kinds is 1:1; In TBSC, all the nodes are SI-type. The parameters are set as follows: dr represents message delay rate, then 1/dr is the average message delay time; sr represents message sent rate.

In simulation, the sr is assumed as [sr1 = 2k*sr, sr2 = k*sr, sr3 = k*sr, sr4 =sr], in which sr1 represents SI-type node sends message to SI-type node,sr2 is SI-type to MI-type, sr3 is MI2- type to SI-type,sr4 is MI-type to MI-type, k represents the time cycle of MI-type nodes, which ranged from 2 to 10, n1 represents the number of  SI-type nodes and n2 represents the number of MI-type nodes.

Figure4 checkpoint overhead  n1= 20  n2 = 20  dr = 4  sr = 0.05  0.1 0.2  0.3 0.4  0.5  sr 2      k      LC  0.1 0.2  0.3 0.4sr  0.1 0.2  0.3 0.4  0.5  sr 2      k      LC  0.1 0.2  0.3 0.4sr   (a) Logged messages in QSA           (b) Logged messages in QSC_SMLA  0.1 0.2  0.3 0.4  0.5  sr 2      k      LC  0.1 0.2  0.3 0.4sr   (c) Logged messages in TBSC  Figure5 message logging overhead n1 = 20 n2 = 20  dr = 4   In Figure 4, we compare the checkpoint cost, we set n1 =  20, n2 = 20, dr = 4, sr = 0.05. With the increase of k, the checkpoint cost of TBSC is unchanged, the cost of QSA increases and on the contrary, the cost of VM_QSC decreases.

The result indicates the advantage of VM_QSC.

In Figure 5, we compare the message log cost, we set n1 = 20, n2 = 20, dr = 4, x-axis represents the range of sr, from 0.05 to 0.5, y-axis represents the range of k, from 2 to 10. The simulation result shows the message log cost of VM_QSC and QSA is almost equal, the cost of TBSC is relatively lower but it is based on the high checkpoint overhead.

From the simulation result, VM_QSC shows better performance in the failure-free phase, especially in checkpoint overhead. Totally speaking, the VM_QSC protocol can keep low overhead in the failure-free phase and rollback recovery phase.



VII. CONCLUSION In this paper, considering the characteristic of the virtual  machines applied on cloud platform, a Quasi-Synchronous checkpoint with Selective Message Logging algorithm VM_QSC is presented, which keeps VM take checkpoint in     accordance with the inherent period, and guarantees the system consistency by selectively stable message logs. By utilizing checkpoint, volatile log, selective stable log, it enhances autonomy of checkpoint, and also reduces fault- tolerant overhead significantly.

The future research is to utilize characteristics of global view of cloud computing environment, optimizing VM_QSC, and reduce the overhead of fault-tolerant and live migration while guaranteeing consistency, and build a cloud platform to test the performance of the algorithm in a real environment.

