A Recommender System for Metrics

Abstract - Over the past 5 decades society has been increasingly requiring immediate results, and this is reflected in business. Due to  this, the attention given to strategy, strategy management and  strategy planning has increased. The use of the Balanced Scorecard  (BSC) is a way of achieving this strategic capability. Moreover, a  proper BSC has effective metrics to track its goals. This work  proposes a system that recommends metrics in accordance with the  goals of a BSC. The recommendation is made using data mining  techniques, in particular association rules.

Keywords: component, balanced scorecard, association rule, recommender systems.



I. INTRODUCTION  Over the past 5 decades society has been increasingly requiring immediate results [1], and this is reflected directly in business. Nowadays, for an organization to be successful it needs more efficiency and effectiveness in its processes, as well as more attention to its strategic planning [2].

Organizations traditionally use fmancial indicators to evaluate their performance and plan their strategy. However, the evolution of organization management has led to the emergence of other forms of management based on a variety of performance indicators. This has come to be known as management based on value. One of the main techniques of management based on value is the Balanced Scorecard (BSC) [3] that is used with strategy maps [4].

Nevertheless, despite all of the attention received, the deployment of performance management methods, like BSC, hasn't had the expected success [5] [6]. Considering that the BSC has a dozen or so metrics, one can imagine the complexity of establishing reliable links between metrics and goals [7] [8]. The complexity is more evident when we leave theory to consider the real world. Because the BSC is a tool originally developed to support an organization's strategic level, the metrics used are mainly composed, requiring the summarization of indicators and results obtained in the lower levels of an organization.

Therefore, to really use BSC as a tool for organizational management, specifically strategic management, there exists the need to create an infrastructure that promotes the integration between goals and metrics. In this work, we propose a metrics recommender system tailored to the goals of a BSC.

This recommender system considers the existence of similar goals inside a unique BSC or the existence of distinct BSC strategies within an organization.

This work is organized as follows: in section 2 we describe some related concepts; in section 3 we describe our metrics recommender system; in section 4 we show the results obtained through simulation; in section 5 we conclude this work and in section 6 we describe some possible future works.



II. BACKGROUND  In this section we describe some fundamental concepts related to this work. First we discuss the Balanced Scorecard, then the recommender systems and finally the association rules.

A. Balanced Scorecard The collision between the necessities of an organization to be  competitive over time and the immobility of the management model based on historical revenues resulted in the creation of the Balanced Scorecard (BSC) [3].

The BSC maintains the traditional fmancial measures, but these measures only show past events, which makes it unsuitable as the sole measure in guiding and evaluating an organization's strategy. The BSC complements the financial measures with measures that evaluate the intangible assets of an organization.

The BSC proposed by Kaplan and Norton [9] is a system of organizational management that provides mechanisms to transform the organization's vision and strategy into a coherent set of performance measures. These mechanisms consist of the defmition of goals and metrics that are used to indicate to all employees the key to current and future success.

The goals are a set of assertions that indicate the organization's desire, i.e., where the organization wants to be positioned at the end of the strategy execution. In addition, the metrics are used to measure if the goal was achieved or not.

The BSC, as proposed by Kaplan and Norton, analyzes an organization by using four different perspectives. The main perspectives are: Learning and Growth, Internal Business Process, Customer and Financial.

The perspectives aren't limited; it is common to find organizations that use others perspectives, like Sustainability or Environment [lO].

B. Recommender Systems A large amount of information is available on the Web,  making search of relevant data a hard task. Recommender systems are proposed as a way to make the task of retrieving and grouping data more effective.

In recommender systems, the available items are ordered according to their utilities and the recommendation of them to a user is performed according to that order.

The item utility is usually represented by a rate which indicates how much a user may like a specific item. The recommender system provides ways to predict the item utility for a specific user. The item utility can be estimated according to three approaches [11]:  ? Content-based recommendations: The user will be recommended items, similar to ones the user preferred in the past;  ? Collaborative recommendations: The user will be recommended items that people with similar tastes and preferences liked in the past;  ? Hybrid approaches: These methods combine collaborative and content-based methods.

Thus, the approaches cited above assume that sufficient historical data exist for items so the system can perform the predictions. On the other hand, in [12] a recommender system based on features is proposed, where each item has features and an item's similarities are evaluated using this information. This system considers the following premise: "People that bought items with a set of features tend to buy items with the same features".

Another important research topic related to recommender systems is trust, for item recommendations. When the recommendations are based on user evaluations, as seen in [13] and [14], it is necessary to create mechanisms to reward users that give a true evaluation. In [15] and [16] this is discussed and a mechanism to solve this problem, the HYRIWYG, is proposed.

Nowadays, recommender systems are widely used: from systems that support software engineering tasks like [14] [17], systems that recommend pages to replace broken web links [18], to selecting the most appropriate advertisement for a certain customer [19].

C. Association Rules Association rules [20] is one of various methodologies used  in data mining and, since its conception by Agrawal et aI., has been the subject of intense scientific interest, having become a large research theme [21]. This methodology consists of finding rules which describe data behavior. With these rules it is possible   to discover, with certain metrics and parameters, information about frequent data.

This is also known as market basket analysis and, historically, is the most important research methodology in data mining. This importance is due to the fact that a product's presence in the same market basket is highly valued information for organizations, because they can optimize their sales by understanding the purchaser's behavior.

Also, this technique can be used together with techniques from other research areas, such as web site analysis [22], ontologies [23] and information retrieval [24].

The result of applying this methodology to a dataset is the generation of simple or composed rules. These rules are formed by antecedents and consequents, and can be evaluated using two concepts: support and confidence.

? Support: Given the rule A ? B, the suprA ? B) represents the percentage of dataset transactions which contain the items A and B, indicating the relevance of the rule. The support is a measure related to the frequency that the rule occurs in the dataset, in other words it indicates its statistical significance.

? Confidence: Given the rule A ? B, the conf(A ? B) represents, amongst the transactions that have A, the percentage that have B too. Therefore, the confidence indicates the strength of a rule.

Many times, high values of support and confidence do not necessarily indicate that a rule is true. These association rules show item sets co-occurring together, with no implication between them [25]. To solve this problem, measures of interestingness must be used, such as lift [26], leverage [27], conviction [28] and collective strength [27].



III. METRICS RECOMMENDER SYSTEM  To solve the problem of association between metrics and goals we propose a recommender system for metrics. This system is implemented through association rules.

We use association rules because the problem of associating metrics to goals is similar to the market basket problem, where the person who has bought items is the BSC goal and the items are metrics.

There exist many works relating recommender systems with association rules. In [29], Lin et al. created an algorithm for association rules specific to a recommender system. Moreover, in [30] the author uses association rules to improve the confidence in a result from a recommender system based on user models.

Kim and Yum in [31] use association rules in an e-commerce recommender system and the rules are generated based on products purchased, products clicked and market basket.

In addition, association rules are also used in recommender systems to avoid the cold-start problem that exists when there is not enough history about an item or person. As there is no    historical data, the initial recommendations are less effective, but with the growth in the amount of data, the recommender system becomes more effective [32].

Considering our recommender system, the problem consists of recommending the next metric to be chosen for monitoring the pursuit of a goal. This is done based on metrics previously chosen as well as the number of times that metrics associated with the goal are used. To implement this we use association rules.

On the other hand, to solve the market basket analysis, the association rules are fully generated with a minimum support and confidence; however, this approach is inefficient for recommender systems, because the recommendation made is directed to a user. To solve this problem, Lin et al. proposed [29] an algorithm that generates association rules when the antecedent of the rule is known. Another feature of this approach is not using the minimum support to generate the rules, as the support is adjusted dynamically to filter the rules presented according to the amount of suggestions the user wants to receive.

Our system has three different behaviors: one to recommend the first metric for a goal; another to recommend metrics for a goal when an association rule does not exist; and, finally, one to recommend metrics for a goal when association rules exist.

In the first case, as no metrics have yet been chosen, there are no association rules. Therefore, metrics are ordered according to their utilization frequency, i.e., the metric that has a high utilization frequency is put in the fust position and so on.

The second case occurs when, for the set of selected metrics A, where the rule A ---+ B is true, a set of unselected metrics B does not exist, i.e., suprA ---+ B) = O. This case is similar to the previous, and so the system presents the same behavior, i.e. the recommendation is made based on the metric's utilization frequency.

Finally, the third case occurs when, for the set of selected metrics A, there exists a set of unselected metrics B where the rule A ---+ B is true, i.e., suprA ---+ B) > O.

As in [29], we do not consider minimum support to generate the rules and chose not to consider support in the ordering of rules, since we do not limit the results of the recommender system.

With this in mind, we can define the fonnula to calculate the score of each metric, but before this we need to define some variables:  ? m-metric;  ? M -the set of metrics that exists in an organization;  ? g- goal;  ? AMg -the set of selected metrics for goal g;   ? Um -Number of utilizations of metric m for all goals of the organization; and  ? Conf(A---+B) -Confidence of the rule where A implies in B.

Now, we can define PUm , the utilization points of metric m, as follows:  Um PUm = IMI * 100  Lk=O Uk (1)  As described in formula (1), the utilization points of a metric m are defined based on the utilization of metric m and on the utilization of all the organization's metrics. As the numerator of the fraction will always be less than or equal to the denominator, the fraction always produces values between 0 and l. We multiply this value by 100, thus giving the utilization points values between 0 and 100, in order to facilitate understanding by the user.

Now, we can define in formula (2) Sm , the score of metric m, used to order the metric when recommended: { PUm :. IAMgl = o.

Sm = PUm :. 71{m:AMg ? m}. (2) cont(AMg ? m) * 100:. IAMgl > 0  As described before, if there are no selected metrics for a goal, the metric's score is its utilization points. If an association rule does not exist, the metric's score is also its utilization points.

Finally, if association rules exist, the metric's score is the confidence of the association rule generated multiplied by 100.

The metrics that do not have an association rule with the selected metrics are ordered according to their utilization points and are presented with scores equal to O.

In addition, we mUltiply the confidence by 100 (to give a number between 0 and 100) in order to facilitate understanding and manipulation of the values by the user.



IV. SIMULATION  To prove the efficiency of the proposed recommender system, we conduct a Monte Carlo simulation [33] [34].

The simulation is conducted to answer the following question:  ? Are the metrics for the fust positions of the recommendation useful for the BSC goal?

To perfonn the simulation we consider that members of the strategic committee of an organization are developing the BSC including the association between metrics and goals.

The following sections are organized as follows: Initially we will describe the simulation process. After that, the values used in the simulation are described as well as the method for evaluating the simulation. Finally, the results obtained are discussed.

A. Simulation Process The simulation is divided into two steps. The fIrst step (step  I) is where a fIctitious BSC is developed. The second step (step II) is where the proposed algorithm is compared with other recommender systems, using the fIctitious BSC as a reference.

Therefore, in step I we develop the BSC considering two scenarios:  ? Random Scenario - In this scenario, the metrics are chosen randomly. This scenario represents the worst case possible, where there is no relation between metrics and they are very unlikely to be found in the real world.

In this case, the simulation aims to demonstrate that even in the worst case, the utilization of association rules can be useful.

? Grouped Scenario - In this other scenario, we randomly separate the metrics into 4 groups. When the fIrst metric of a goal is selected the following metrics to be associated to this same goal come from the same group. This scenario is closer to the real world because it considers that metrics exist which are naturally used together. In this second scenario the simulation aims to demonstrate how the recommender system is effective in a setting similar to the real world.

In step II we simulate an environment where the members of the strategic committee have the support of recommender systems that order metrics by utilization frequency only and another one where metrics are ordered according to our proposed system.

The simulation process runs as follows. The initial step includes the defInition of some variables, necessary to execute the simulation. The variables are:  ? numberGoals - Number of goals of the BSC.

? numberMetrics organization.

Number of metrics in the  ? numberMetricsGoals - Number of metrics associated to goals.

After the variables are initialized, we execute step I, i.e., we build the fIctitious BSC without support from any recommender system. Subsequently, we conduct step II where we simulate the development of the same BSC considering the use of a recommender system that orders the metrics by utilization only and again with one that implements our proposed recommender system. As a hypothesis we consider that both BSCs generated using the simulation must be equal to the BSC from step I.

B. Simulation Execution To execute the simulation we assign different values to initial  variables, and repeat each run lOO times. The following values are used.

? numberGoals - 2, lO, 50, 100, 800.

? numberMetrics - 80.

? numberMetricsGoals - 2, 5, lO e 20.

We run the simulation for each tuple (numberGoals,  numberMetrics, numberMetricsGoals), and we refer to each confIguration using the following format: numberGoalslnumberMetricslnumberMetricsGoals.

We choose these values to verify if the number of goals and the number of metrics associated to a goal influence the performance of our recommender system, and how, in these cases, it would perform compared to the simple recommender we implemented for comparison.

Additionally, we use small values, like 2 and 10, to evaluate the behavior of our recommender system when facing the cold? start problem. On the other hand, we use large values, like 800 to evaluate if in the long run our recommender system performs well.

C. Evaluation Method In order to evaluate the results, the target metric originally  associated to the goal in Step I is verifIed (considering the response provided by each of the recommenders, with and without the association rules) by use of 2 indicators:  ? A verage position of the target metric in the list of recommendations.

? Times that the target metric appears in the 10 fIrst positions (top lO).

In addition, to verify the signifIcance of the obtained results, we use statistical hypothesis testing as in [35], described as follows:  ? f.l. - Average position of target metric in recommender system that orders metrics by utilization only.

? f.lb - Average position of target metric in our proposed recommender system.

? HO-f.l.=f.lb.

? H. - f.l. i- f.lb.

? a - .05.

D. Simulation Results In this section, we present the results of the simulation. First,  we describe the results of the Random Scenario and then the Grouped Scenario.

1) Random Scenario  Initially, in Fig. 1, we present the results for the average position of the confIgurations with 2 and 10 goals.

As the graph shows, the behavior of both recommender systems is the same with 2 goals. This obviously occurs because with a small number of goals we have no association rules    generated. With lO goals things change a little and our recommender system presents a small gain, as the number of metrics associated to goals increases.

In Fig. 2, we present the results as a percentage of presence in top-10. In this case, the behavior is the same as the average position, i.e. with lO goals our recommender system has a small gain with respect to the other.

Considering the hypothesis test, we can say that only at configurations 10/80/10 and 10/80/20 do our systems have superior performance compared to the other.

In Fig. 3, we present the results of average position for configuration with 50 and 100 goals.

As can be seen in the graph, the behavior is the same as the execution with 10 goals, but in this case the gain is slightly larger. This occurs because there is a larger number of association rules.

t::: .g '(/j 0 0..

1) O/l OJ .... 1) ;>  ?  ? Ordered by utilization ? Association Rule       ?'V -v't3 ?  <-, ?? -v't3 -vco \:)  numberGoals I numberMetrics I numberGoalsMetrics  Figure 1: Analysis of average position of target metric with 2 and 10 goals.

0 - 6..

B t::: 1) 0 t::: 1) ? 1) ....

0.

'+-< 0 1) ? t::: 1) 2 1) 0..

? Ordered by utilization ? Association Rule  35% 30% 25% 20% 15% 10%  5% 0%  ?'V ?<-, -v't3 -v't3  numberGoals I numberMetrics I numberGoalsMetrics  Figure 2: Analysis of percentage of presence in the top-10 for target metric with 2 and 10 goals.

? Ordered by utilization ? Association Rule  45 ,---------------------------------  o  numberGoals I numberMetrics I numberGoalsMetrics  Figure 3: Analysis of average position of target metric with 50 and 100 goals  In Fig. 4 we present the results as a percentage of presence in top-10. In this case, the behavior is different from the average position, as the gain with our recommender system is slightly larger than when analyzing average position.

Likewise, with the hypothesis test we can say that for all configurations (except the one that has 2 metrics associated with a goal), our recommender system has superior performance compared to others.

In Fig. 5, we present the results of average position for the configuration with 800 goals. As shown in the graph, the behavior is different from the others. In this configuration our recommender system presents considerable gains compared to the other for all values of metrics associated to goals and, when values increase, the gain increases too.

o  6..

B .5 1)  ? Ordered by utilization ? Association Rule  25% ,------------------------------------  20% +---------?.r--?------------?--?  g 15% +------1 __ --1 __ -1) ?  ? 0. 10%  '+-< o 5%  numberGoals I numberMetrics I numberGoalsMetrics  Figure 4: Analysis of percentage of presence of target metric in the top-10 with 50 and 100 goals.

? Ordered by utilization ? Association Rule  45 ,---------------------------------  o  800/80/2 800/80/5 800/80110 800/80/20  numberGoals I numberMetrics I numberGoalsMetrics  Figure 5: Analysis of average position of target metric with 800 goals.

In Fig. 6, we present the results for percentage of presence in the top-10. In this case, the behavior is the same as the average position.

In this case, as with the hypothesis test, we can say that in all configurations our recommender system has superior performance compared to the others.

2) Grouped Scenario  Initially, in Fig. 7, we present the results of average position for the configurations with 2 and 10 goals.

As can be seen in the graph, the behavior of both the recommender systems is the same with 2 goals. This occurs because with a small number of goals, sufficient association rules are not generated. With 10 goals, our recommender system has some gain, as the number of metrics associated to goals increases. Different from the Random scenario, in this case, even with 10 goals, our recommender system has a significant performance gain compared to the other.

In Fig. 8, we present the results for percentage of presence in the top-10. In this case, the behavior is the same as the average position. Moreover, with 10/80/20 our recommender system reached 60% for presence in top-10. Because the metrics have an explicit association between them, when the number of recommendations increases, our recommendation system becomes very effective with a large difference in performance compared to the other.

Regarding the hypothesis test, we can say that only at the configurations 10/80/5, 10/80/10 and 10/80/20 does our recommender system have superior performance compared to the other.

o  ? Ordered by utilization ? Association Rule  25% ,------------------------------------  6.. 8 20% +------------- .:: 8 15% c 1) Vl  K 10% ...... o 1) ? 5% c 1) ? 00/0  0... 800/80/2 800/80/5 800/8011 0 800/80/20  numberGoals I numberMetrics I numberGoalsMetrics  Figure 6: Analysis of percentage of presence of target metric in the top-10 with 800 goals.

? Ordered by utilization ? Association Rule  45 ,---------------------------------  o  numberGoals I numberMetrics I numberGoalsMetrics  Figure 7: Analysis of average position of target metric with 2 and 10 goals.

In Fig. 9, we present the results of average position for the configurations with 50 and 100 goals. Now our recommender system has a large performance gain, starting at the configuration with 5 metrics associated to goals.

The same behavior occurs in Fig. 10 where the percentage of presence in the top-10 reaches 50% with 5 metrics associated to goals, progressing to reach 90% with 20 metrics associated to goals. Now, with the hypothesis test we can say that for all configurations, except the configuration 50/80/2, our recommender system has superior performance compared with the other.

o  6.

.:: 1) <.) \:: 1) if>  ? Ordered by utilization ? Association Rule  700/0 ,------------------------------------ 600/0 +---------------------------------? 500/0 +---------------------------------? 400/0 +-----------------------------.r--?  15.. 30% ...... o 20%  numberGoals / numberMetrics / numberGoalsMetrics  Figure 8: Analysis of percentage of presence of target metric in the top-10 with 2 and 10 goals.

? Ordered by utilization ? Association Rule  45 ?--------------------------------   o  numberGoals / numberMetrics / numberGoalsMetrics  Figure 9: Analysis of average position of target metric with 50 and 100 goals.

In Fig. 11 we present the results of average position for the configuration with 800 goals. As shown on the graph, for all configurations our recommender system has a large gain compared to the other and, when the ratio increases so too does the gain. Also, in Fig. 12, we see the same behavior, with the percentage of presence in top-10 reaching 60 % with 5 metrics associated to goals and 95% with 20 metrics associated to goals.

Finally, hypothesis test supports that for all configurations our recommender system has superior performance compared with the other.

? Ordered by utilization ? Association Rule  100% ,--------------------------------- 90% +-------------?.r--------------?I_ 80% +-------------__ ?--------_, __ ? __ 70% +---------__ r-__ ?--------? __ ? __ 60% +---------?--??------------??I- 50% +---------? __ ? __ ------,.--__ r_?I_ 40% +-----__ ?? __ ? __ ------?--__ r_?I_ 30% +-------??--??------?----??I- 20% +-----?--?- 10%  0%  ?ry ?'-"J ?,, ? ?? ?ry ?'-"J ?,,? ??  <...s."O <...s."O ?"O ?%\:j ?"O ?"O ?\:j ?\:j . ) . ) '-"J" '-"J" ,,1;3 ,,1;3 ,,?  \:j ,,?  \:j  numberGoals / numberMetrics / numberGoalsMetrics  Figure 10: Analysis of percentage of presence of target metric in the top-10 with 50 and 100 goals.

? Ordered by utilization ? Association Rule  45 ?--------------------------------   o  800/80/2 800/80/5 800/80/1 0 800/80/20  numberGoals / numberMetrics / numberGoalsMetrics  Figure II: Analysis of average position of target metric with 800 goals.



V. CONCLUSIONS  As seen in the previous section, the proposed recommender system was proved to be superior in almost all measurements and in all scenarios compared with a recommender system that orders metrics using only their utilization frequency. And in no case was it worse than the other.

Despite the random scenario representing the worst environment for our recommender system (which is a highly improbable one, far from the real world), in all measurements our system was superior to the other, when considering the average position or the percentage of presence in the top-10. In the grouped scenario, where we believe the environment is closer to the real world, our recommender system was even more superior compared to the other.

b.

.8 .:: <l) () c <l) Vl <l) ....

0-'"" 0 <l) Of) 1i:i c <l) () ....

<l)  0...

? Ordered by utilization ? Association Rule  100% 90% 80% 70% 60% 50% 40% 30% 20% 10%  0% 800/80/2 800/80/5 800/80/1 0 800/80/20  numberGoals / numberMetrics / numberGoalsMetrics  Figure 12: Analysis of percentage of presence of target metric in the top-10 with 800 goals.

In both cases, our recommender system performs better when there is an increase in the number of recommendations made.

Moreover, this behavior is better seen in the grouped scenario.

This occurs because the greater the number of association rules generated, the more accurate our recommender system is.

Finally, we can conclude that with the utilization of our metrics recommender system, the task of associating metrics to goals is facilitated, thus easing the workload of strategic committee members, which is fundamental for the success of the BSC.



VI. FUTURE WORK  As an important initial action in the future, an extended more detailed case study in a real organization that has complex strategic settings would help us to acquire information about the use of the proposed recommender system in the real world.

Another possible evolution is in the proposed recommender system itself. In the case where no association rules exist for the previously selected metrics of a goal; instead of the system recommending based on a metric's utilization, it could use subsets of selected metrics to search for association rules.

Finally, the generation of rules could also use Fuzzy Logic, as in [36].

