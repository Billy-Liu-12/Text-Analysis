Using Association Rules to Identify Similarities between Software Datasets

Abstract?A number of V&V datasets are publicly available.

These datasets have software measurements and defectiveness information regarding the software modules. To facilitate V&V, numerous defect prediction studies have used these datasets and have detected defective modules effectively. Software developers and managers can benefit from the existing studies to avoid analogous defects and mistakes if they are able to find similarity between their software and the software represented by the public datasets. This paper identifies the similar datasets by comparing association patterns in the datasets. The proposed approach finds association rules from each dataset and identifies the overlapping rules from the 100 strongest rules from each of the two datasets being compared. Afterwards, average support and average confidence of the overlap is calculated to determine the strength of the similarity between the datasets. This study compares eight public datasets and results show that KC2 and PC2 have the highest similarity 83% with 97% support and 100% confidence. Datasets with similar attributes and almost same number of attributes have shown higher similarity than the other datasets.



I. INTRODUCTION  Similarity between two software can help in estimating development effort and budget of one software using the experiences in the other software. Similarly defect patterns in one software can help avoid defects in a similar software.

Usually the software project data is not publicly available and different organizations working on similar projects cannot benefit from each other. However, V&V datasets with software measurements and software defects are publicly available [1].

Organizations can find similarity of their software data with these datasets, determine the defect occurrence patterns and perform testing activities accordingly.

Similarity between the datasets can be determined using  different methods like association mining [2], [3], [4] and fuzzy logic [5], [6], [7]. Parthasarathy et al. [2] have found association rules using ECLAT [8] and have presented a similarity measure Sim(A,B) to find similarity between homogeneous datasets. This similarity has been calculated based on support count and a parameter alpha to reflect variations in support count. Experimental results have shown that their algorithm can adapt to time constraints by providing quick speed up of 5 to 7 and accurate estimates within 2 % of similarity. Tao Li et al [3] have proposed similarity measure between basket datasets based on associations. The measure employs support counts using a formula inspired  from information entropy. Dudek et al. [4] have presented some new measures for comparing association rulesets for distributed mining. Azzeh et al [5] and Idri et al. [6], [7] have proposed measures based on fuzzy logic to evaluate the similarity between two software projects when they cannot be described by numerical data and need linguistic values.

Further process measures have been employed to find soft- ware project similarity [9]. Barreto et al. [9] have identified characteristics from software process that can determine the similarity among software projects and have presented a measure to indicate the level of similarity among the projects to improve software project monitoring process.

There are certain issues with the existing work that need to be addressed. Association mining based approaches discussed above assume the datasets to be homogenous which is not the case always. There are datasets in PROMISE repository [1] that use different measures but can be used to determine if they represent the similar software. The discussed fuzzy approach is applicable when numeric software data is not available. There are very few datasets with process measures which reduces the chances of benefiting from public datasets. A large proportion of the public datasets consists of software product measures.

In order to increase their utility and benefit from the defect patterns in the datasets an approach to find dataset similarity is required. Similarity between two software datasets can be found by identifying similar patterns of co-occurrences of attribute values in the datasets. If certain attribute values co- occur similarly in two datasets we say that the datasets behave similarly.

In this paper we present a three step Association Rule Mining(ARM) based strategy to find similarity between two datasets. In first step we apply Apriori algorithm [10] to generate association rules for each dataset such that we have a ruleset for each dataset. In second step we label the rules in the rulesets. In the last step we find similarity between the two rulesets by identifying overlapping rules. Afterwards, we find the support and confidence of the overlap.

Rest of the paper is organized as follows. Section II dis- cusses our methodology, section III presents the experimental results, section IV gives an analysis of the results and section V concludes the paper and provide future directions.

DOI 10.1109/QUATIC.2012.66     TABLE I DATASETS DESCRIPTION  Attribute CM1 KC1 KC2 PC1 MW1 PC4 MC2 KC3 loc ? ? ? ? ? ? ? ? v(g) ? ? ? ? ? ? ? ? ev(g) ? ? ? ? ? ? ? ? iv(g) ? ? ? ? ? ? ? ? CALL PAIRS ? ? ? ? CONDITION COUNT ? ? ? ? CYCLOMATIC DENSITY ? ? ? ? DECISION COUNT ? ? ? ? DECISION DENSITY ? ? ? ? DESIGN DENSITY ? ? ? ? EDGE COUNT ? ? ? ? ESSENTIAL DENSITY ? ? ? ? LOC EXECUTABLE ? ? ? ? PARAMETER COUNT ? ? ? ? GLOBAL DATA COMPLEXITY ? ? GLOBAL DATA DENSITY ? ? n ? ? ? ? ? ? ? ? v ? ? ? ? ? ? ? ? l ? ? ? ? ? ? ? ? d ? ? ? ? ? ? ? ? i ? ? ? ? ? ? ? ? e ? ? ? ? ? ? ? ? b ? ? ? ? ? ? ? ? t ? ? ? ? ? ? ? ? lOCode ? ? ? ? ? ? ? ? lOComment ? ? ? ? ? ? ? ? lOBlank ? ? ? ? ? ? ? ? locCodeAndComment ? ? ? ? ? ? ? ? MAINTENANCE SEVERITY ? ? ? ? MODIFIED CONDITION COUNT ? ? ? ? MULTIPLE CONDITION COUNT ? ? ? ? NODE COUNT ? ? ? ? NORMALIZED CYLOMATIC COMPLEXITY ? ? ? ? uniq Op ? ? ? ? ? ? ? ? uniq Opnd ? ? ? ? ? ? ? ? total Op ? ? ? ? ? ? ? ? total Opnd ? ? ? ? ? ? ? ? branchCount ? ? ? ? ? ? ? ? PERCENT COMMENTS ? ? ? ? defects ? ? ? ? ? ? ? ?  No. of Modules 498 2109 522 1109 403 1458 161 458 No. of Attributes 22 22 22 22 38 38 40 40 Percentage of Defective Modules 9.84% 15.46% 20.50% 6.95% 7.70% 12.21% 32.30% 9.39% Language C C++ C++ C C++ C C++ Java

II. METHODOLOGY This paper suggests a three step process to find similarity  between software datasets. The three steps are shown as three components of the proposed approach in Figure 1. Association Rule Generator generates association rules from input datasets using Apriori, Labeling Manager labels the input ruleset and Similarity Calculator finds the overlap between two rulesets and produces final output. The figure also shows input and output of each of the components and their collaboration with each other. Before providing details of each of the components, this section discusses the datasets used in this study.

A. Dataset Characteristics This study uses eight datasets that have atleast 50% common  attributes. These datasets have been taken from PROMISE repository [1]. Four of the datasets use 22 attributes, two use  Fig. 1: The Proposed Approach  38 and two datasets use 40 attributes. Details of the datasets and the attributes used by each dataset are provided in Table I. Description of the attributes can be found elsewhere [11].

From the 8 datasets, only two have more than 20% defective     modules. Four datasets are for the software developed using C++, three for C and one dataset is for the software written in Java.

Different datasets use different naming conventions which  is known as Type I inconsistency [11]. For example McCabes cyclomatic complexity is represented as v(g) in a few datasets and as CYCLOMATIC-COMPLEXITY in others. Naming of the attributes has been unified as suggested by Rana et al.

[11]. The datasets have been categorized into three groups based on the number of attributes used: Group 1 consists of CM1, KC1, KC2 and PC1; members of Group 2 are MW1 and PC4; whereas MC2 and KC3 fall in Group 3. Datasets in same group are homogenous and the datasets from different groups are heterogenous datasets.

B. Association Rule Generator This step uses Apriori algorithm [10] to generate association  rules. The algorithm generates association rules by discovering frequent itemsets within a dataset. In order to use the Apriori algorithm numeric attributes have been discretized (into bins) and converted to categorical attributes. The algorithm gives support count for each rule. This support count represents the the number of instances in the dataset where all attributes of a rule appear. A sample output of of few rules and their support counts is given in Table II. First 100 strong association rules are considered as output of this step and are sent to the next steps as input.

TABLE II SAMPLE ASSOCIATION RULES WITHOUT LABELS  e=?(-inf-214748.364]? 516 ==> t=?(-inf-15304.701]? 516 conf:(1) e=(-inf-215369.063] 483 ==> t=(-inf-11964.948] 483 conf:(1) v=?(-inf-3381.456]? 511 ==> e=?(-inf-214748.364]? 511 conf:(1) v=?(-inf-3381.456]? 511 ==> t=?(-inf-15304.701]? 511 conf:(1) b=?(-inf-1.127]? 510 ==> v=?(-inf-3381.456]? 510 conf:(1) b=?(-inf-1.127]? 510 ==> e=?(-inf-214748.364]? 510 conf:(1)  C. Labeling Manager Relabeling Manager assigns labels to different bins of  each attribute. Same attributes in two different rulesets have different ranges. For example consider the first two rules in Table II, they are from different rulesets. Both rules have same antecedents and consequent but due to different ranges cannot be put into overlapping rule set of contributing datasets. To make the rules comparable we have labeled the attribute ranges as Low, Medium and High. The scope of these labels is within datasets and for every attribute there is a different value for same label. So a Low in one dataset is not meant to be same Low in other dataset and also not same for other attributes within same dataset because every attribute has its own ranges that may not be similar to others. The class attribute is left unchanged in all datasets.

D. Similarity Calculator The association rules are certain association patterns ob-  served in each dataset. These patterns are compared and similar patterns are identified using the Similarity Calculator.

TABLE III LABELING  Bins KC1 Ranges Labels 1 ?(-inf-29.7]? Very Very Low 2 ?(29.7-58.4]? Very Low 3 ?(58.4-87.1]? Low 4 ?(87.1-115.8]? Medium1 5 ?(115.8-144.5]? Medium2 6 ?(144.5-173.2]? Medium3 7 ?(173.2-201.9]? Medium4 8 ?(201.9-230.6]? High 9 ?(230.6-259.3]? Very High 10 ?(259.3-inf)? Very Very High  More the number of similar association rules, more is the sim- ilarity between the datasets. Similarity between two datasets is calculated using the following measures:  SimilarityRuleset12 = 2? C  |R1|+ |R2| (1)  SupportRuleset12 =  C?  n=1  SupportRuleij  C (2)  ConfRuleset12 =  C?  n=1  ConfidenceRuleij  C (3)  where C denotes number of overlapping rules in Ruleset1 and Ruleset2 rule sets. SupportRuleij and ConfidenceRuleij represent confidence and support similarity between two rules and is defined as follows:  SupportRuleij = 1? (|sup(ri)? sup(rj)|)  Max(sup(ri), sup(rj)) ) (4)  ConfidenceRuleij = 1? (|conf(ri)? conf(rj)|)  Max(conf(ri), conf(rj)) ) (5)  where ri and rj are two overlapping rules from Ruleset1 and Ruleset2 respectively. Support and confidence of an association rule does not exceed 100% (100% being the best value for support and confidence). While calculating the support and confidence of the rulesets overlap, we need support and confidence of individual rules. We find the difference of the supports of the overlapping rule in respective rulesets, normalize it over the maximum rule support in the two rulesets and subtract this value from 100%.

This expression gives a strength value to the overlapping rule in both the rulesets. Similar process is carried out to find confidence of the rulesets similarity.

The Similarity Calculator accepts three inputs as shown in Figure 1 which are original rulesets produced by association rule generator, their labeled variants produced by labeling     Algorithm 1 Similarity Calculator  Input= [Ruleset1,Ruleset2],[Ruleset1v,Ruleset2v], [sizeDS1,sizeDS2] Output= Similarity Vector Basic Idea Declare sup-Ruleset1[100],sup- Ruleset2[100],conf-Ruleset1[100],conf-Ruleset2[100] i=0 while i ? 100 do read rule from ?Ruleset1? find support of Rulei, store in sup-Ruleset1[i] find confidence of Rulei, store in conf-Ruleset1[i] sup-Ruleset1[i]=sup-Ruleset1[i]/sizeDS1 read rule from ?Ruleset2? find sup of Rulei, store in sup-Ruleset2[i] find conf of Rulei, store in conf-Ruleset2[i] sup-Ruleset2[i]=sup-Ruleset2[i]/sizeDS2 i++  end while n=0 for i = 0 to number of rules in Rulset1-L do read rule1 from Ruleset1v for j = 0 to number of rules in Rulset2-L do read rule2 from Ruleset2v if rule1 == rule2 then n++; conf-list.add = 1-(abs(conf-Ruleset1[i]-conf- Ruleset2[j])/max(conf-Ruleset1[i],conf-Ruleset2[j])) sup-list.add = 1-(abs(sup-Ruleset1[i]-sup- Ruleset2[j])/max((sup-Ruleset1[i],sup-Ruleset2[j])) i++,j++ Write i , j , (sup-Ruleset1[i] , sup-Ruleset2[j] , conf- Ruleset1[i] , conf-Ruleset2[j] into file ?sim.csv?  end if end for  end for sim = n*2/(sizeRuleset1+sizeRuleset2) sup = average of sup-list conf = calculate average of conf-list Output sim,sup,conf in sim.csv file  manager and sizes of both datasets whose rulesets are going to be used. Size is needed to calculate support of rule, as mentioned in Section II-B generated rules contains support count instead of support. The detailed process of calculating similarity is given in algorithm 1. The algorithm performs two steps on input, in first step of its calculations, its finds a pair of rules in Ruleset1-L and Ruleset2-L that are similar to each other, then it looks for their support and confidence in original rule sets Rulset1 and Ruleset2 to calculate their support and confidence similarity. This step is repeated until all possible combinations of rules from input rule sets are checked for overlapping.

Due to different sizes of the datasets being compared,  support count of overlapping/similar rules pair is different and pair no longer remains similar. Therefore, support count and  confidence of overlapping rules are ignored when finding the rule overlap. These two values are kept separately and are used when needed for calculations of second and third measure.

Second step calculates similarity of both rulesets as total  percentage of overlap between them and average confidence and average support of these overlapping rules. Output of similarity calculator is a vector with values (sim, sup, conf).

E. Validation Framework  We have validated our results by observing the consistency of the approach. If approach is correct then datasets from the same group should be shown as similar by the approach and should not be identified as dissimilar. On the other hand the datasets from different group should be classified as dissimilar datasets if they have very few common attributes.



III. RESULTS  Proposed approach is applied to eight datasets and results are given step wise.

A. Association Rule Generator  The rules generator has discretized every attribute into 10 bins as a prerequisite to use Apriori algorithm. The manager uses Weka [12] implementation of Apriori to generate 100 association rules for the eight datasets. Association rules of the form shown in Table II are generated.

B. Labeling Manager  Labeling manager finds all attributes that appeared in both rulesets and replace them with labels Very Very Low, Very Low, Low, Medium1, Medium2, Medium3, Medium4, High, Very High, and Very Very High. Since we have 10 bins for each attribute we need ten labels for each of the attributes. An example of attribute ranges and their labels are given in Table

III. But the Relabeling Manager (implemented in JAVA) uses only three labels for each attribute so we have assigned more abstract labels of L, M and H for each attribute. This abstract labeling has used L for Very Very Low, Very Low and Low, M for Medium1, Medium2, Medium3 and Medium4, and finally H was used for High, Very High and Very Very High. This way a rule having attribute with very low can now be compared with another rule having same attribute with very very low label. An example of output for two rules given in Table II is given in Table IV. It can be seen that rules are comparable and similar to each other. After this replacement the rulesets are considered as labeled rulesets variants and are used as input to similarity calculator.

TABLE IV LABELED ASSOCIATION RULES  e=L ==> t=L e=L ==> t=L     TABLE V OVERLAPPING RULES  DataSets KC1 KC2 PC1 MW1 MC2 KC3 PC4 CM1 34 27 34 14 18 14 8 KC1 27 34 23 20 40 9 KC2 83 14 16 13 7 PC1 16 20 14 8 MW1 37 55 20 MC2 35 20 KC3 20  TABLE VI SUPPORT SIMILARITY  DataSets KC1 KC2 PC1 MW1 MC2 KC3 PC4 CM1 90% 88 % 92 % 89 % 87 % 99 % 92 % KC1 99 % 98 % 80 % 79 % 89 % 99 % KC2 97 % 79 % 77 % 88 % 98 % PC1 82 % 80 % 91 % 98 % MW1 99 % 90 % 80 % MC2 88 % 79% KC3 90 %  C. Similarity Calculator Similarity calculator took two rulesets and their labeled  variants as an input as well as sizes of datasets whose rules sets are used as input. In first step, it calculates all overlapping rule pairs of both rulesets variants and their support and confidence.

Because rulesets were given in pairs of two so if CM1 was compared with all remaining rule sets then they will not again be compared with CM1 on their turn. Total number of overlapping rules is given in Table V. Table V tells the total number of overlapping rules in each of two rulesets.

To find support and confidence similarity we need overlap-  ping rules with their support and confidence. As discussed in Section II-D, pair of overlapping rule contains indexes of them in rule set, which are used to get respective rules support count and confidence from original rule sets.

Support is calculated by dividing support count with dataset  size. If two rules have confidence and support close to each other with minimum difference, their similarity will be high.

If one rule has low confidence or low support and other has high value of these parameters, distance between values will increase and their similarity will be low. This seems to be logical and reliable because if confidence of one rule is 50% and confidence of the other rule is 100% their confidence similarity should be less than those similar rules in which confidence of one rule is 90% and confidence of the other is 100%.

Support and confidence of similarity tells the strength of  similarity, means how closely and reliably datasets behave similarly. Average support and confidence similarity of all datasets calculated by using equation 2 and 3 are given in Table VI and Table VII respectively.



IV. DISCUSSION The datasets similar to each other essentially have similar  association patterns. The associations represent co-occurrences of certain itemsets (bins for the attributes) with one another and software defects. The datasets with similar association patterns have similar correlation among their attributes. These  TABLE VII CONFIDENCE SIMILARITY  DataSets KC1 KC2 PC1 MW1 MC2 KC3 PC4 CM1 100% 100 % 100 % 100 % 100 % 100 % 100 % KC1 100 % 100 % 100 % 100 % 100 % 100 % KC2 100 % 100 % 100 % 100 % 100 % PC1 100 % 100 % 100 % 100 % MW1 100 % 99 % 100 % MC2 100 % 100 % KC3 100 %  attributes include defects as well. This information can be used to find the bins highly associated with defects in one dataset; and the corresponding bins in the other dataset can be kept under observation. This way the defects related to these bins can be handled before they could appear.

In section II-A we have categorized the datasets in to  three groups with respect to the number of attributes used. In this section we discuss the similarity between datasets under following dimensions:  ? Number of common attributes ? Programming language ? Percentage of defective modules The top ten similar datasts show that using exactly same  attributes results in higher possibility to have similar asso- ciation patterns and high association rules overlap. The top five similar pairs are KC2-PC1, MW1-KC3, KC1-KC3, MW1- MC2 and MC2-KC3 with similarity 83%, 55%, 40%, 37% and 35% respectively. Two of these are pairs from the same groups. KC3 is the only dataset that appears three times in the top five, twice with the dataset of the other group (MW1 and KC1). One reason for high similarity of KC3 with MW1 is the number attributes and an overlap of 38 attributes.

Further both these software are object oriented software one written in Java and the other in C++. Furthermore, both have a very low percentage of defective modules. KC3 and KC1 have a difference in number of attributes used but still they are 40% similar. One reason is the overlap of 22 attributes and their similar associations. Another reason could be the same language of software of both the datasets. MW1-MC2 is another pair that involves the datasets from different groups.

But both datasets have 38 common attributes. Moreover, this similarity is explained by the fact that KC3 and MW1 have a high similarity and MC2 belongs to the group of KC3.

Software for MC2 and MW1 are in same language C++. The next five similarities are among the datasets of Group 1 i.e.

CM1-KC1, CM1-PC1, KC1-PC1, CM1-KC2, KC1-KC2 have similarities 34%, 34%, 34%, 27% and 27%. Support of the top ten similarity values remains more than or equal to 88%.

Overall 7 of the top ten similar datasets belong to same groups.

This supports the grouping of datasets on the basis of number of attributes used.

The ten least similar dataset pairs are from different groups.

These pairs are KC2-PC4, CM1-PC4, PC1-PC4, KC1-PC4, KC2-KC3, CM1-MW1, KC2-MW1, CM1-KC3, PC1-KC3, and KC2-MC2 with similarity values 7%, 8%, 8%, 9%, 13%, 14%, 14%, 14%, 14%, 16% respectively. Support for     all these similarity values ranges from 77% to 99%. The pairs with minimum similarity involve the datasets with a large difference in number of attributes and a relatively small overlap in the attributes used. This further supports the grouping of datasets on the basis of attributes. PC4 appears four times in the five least similar datsets, everytime with datasets with language C or C++. The highest similarity value for PC4 is 20% with the datasets MW1 (same group), MC2, and KC3. PC4 has 38 attributes common with MC2 and KC3. Further investigation is required to see the association patterns in PC4 that led to very low similarity values for this dataset with all the datasets with different attributes, common attributes, same language and different language. Further percentage of defective modules in PC4 is not very different from the rest of the datasets.

A. Threats to Validity The approach presented here does not take into account  the language in which a software has been developed. The approach has been used with datasets having static code mea- sures that are recorded alongwith reported defects regardless of the programming language. However, the values of static code measures may be very different for different languages and their associations with defects and among themselves may also differ.



V. CONCLUSION AND FUTURE WORK This paper presents a three phase approach to identify  similar software datasets. The similarity is determined by comparing association rules from each datasets and finding the overlapping association rules. The association rules are asso- ciation patterns that represent the co-occurrence of different bins of attributes with each other and software defects. This similarity in co-occurrences of certain attribute bins is helpful in identifying potentially error prone values of attributes in similar datasets. The software modules with attribute values in the error prone range can be observed and can be handled before the defects appear. This is analogous to applying lessons learnt from one software to the other. This paper has applied the proposed approach to eight datasets taken from Promise repository. Datasets which can be categorized into one group on the basis of their attributes and number of attributes have more rule similarity with each other and behave more similarly than the datasets from the other groups. From the 10 most similar datasets, 70% of the times the approach has  called a dataset from same group as similar whereas from the 10 least similar datasets, the approach has 100% correct identification of datasets from different groups as least similar.

The dataset PC4 is an interesting dataset because it has shown very weak similarity with all the datasets either they are within its group or from other group.

The proposed approach handles homogenous as well het-  erogenous datasets. However there is a limitation that the het- erogenous datasets must have atleast 50% common attributes.

This approach can be extended to find similarity between datasets with less that 50% common attributes.

