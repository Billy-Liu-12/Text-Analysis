Chemical Space Visualization Using ViFrame Petr S?koda

Abstract?Exploration of the chemical space is an important component of drug discovery process and its importance grows with the increase in the computation power which allows to explore larger areas of the chemical space. Recently, there emerged new algorithms proposed to automatically generate and search for compounds (objects in the chemical space) with desired properties. Although these approaches can be a big help, human interaction is usually still inevitable in the end. Visualization of the space can help make sense of the generated data and therefore visualization techniques are usually an integral part of any task related to chemical space exploration. Currently, there exist methods dealing with visualization of the chemical space but there is no framework supporting simple development of new methods. The purpose of this paper is to introduce such a modular framework called ViFrame. ViFrame offers the possi- bility to implement every single part of the visualization pipeline consisting of steps such as reading and merging molecules from multiple data sources, applying transformations and, of course, visualization of the data set in 2D space. The advantage of the framework consists in providing an environment where the user can focus on the development of the previously mentioned tasks while the framework supports seamless integration of the developed components. The framework also incorporates an application that provides the user with graphical interface for modules manipulation and presentation of the visualization results. For simple utilization of the application without the neces- sity of implementation of one?s own module, several visualization methods have been implemented.

The framework is freely accessible at http://siret.cz/viframe.

Index Terms?visualization framework, chemical space

I. INTRODUCTION  The chemical space is the space spanned by all thinkable chemical compounds and its exploration can find use in computational discovery of compounds with given activity [1].

The space is huge and potentially infinite. For example the total number of possible small organic molecules that populate the chemical space has been estimated to exceed 1060 [2]. In fact, just a small subspace of the chemical space has been explored so far. On the other hand not all molecules in the chemical space are of any interest since some of the molecules do not have any notable function or even are not synthetizable.

There are many domains which utilize exploration of the chemical space such as biochemistry, pharmacology and others. These fields usually benefit from the existence of chemical libraries representing subspaces of the chemical space. Compounds in those libraries are used, e.g., in high- throughput screening to evaluate their suitability for given  biological task, polypharmacology, chemogenomics and other drug discovery-related domains. However, even the largest commercial libraries are not capable of encompassing the whole chemical space or even its relevant parts. For instance, if we consider the size of the largest publicly available database of chemical compounds PubChem [3], it contains information about 70,000,000 molecules as of beginning 2013. So, in comparison to the size of the chemical space, even the size of largest publicly available repository is negligible.

Therefore, recently there appeared approaches tackling the problem of the disproportion between the sizes of the known and unknown chemical space. Basically, there are two main approaches one of which is based on exhaustive generation of compounds obeying simple rules for chemical stability, synthetic feasibility, and medicinal chemistry. Under this ap- proach come for example GDB databases GDB-11 [4], GDB- 13 [5] and recently published GDB-17 [6]. Another line follow algorithms which do not generate exhaustively the chemical space but rather focus on the generation of a limited subspace relevant to given task under the hand. Algorithms in this class usually try to minimize some objective function restricting the exploration process into a specific part of the chemical space.

For example we can name approaches for designing drugs subject to a given multi-target profile (drugs focusing on sev- eral molecular targets simultaneously) [7] where the goal is to identify compounds with the optimal pharmacological profile.

Another example are applications for general exploration of chemical space which try to identify a path in the chemical space between the input molecules [8], [9]. The criteria utilized in these algorithms for guiding the exploration process are rather structural, based on distances of molecular fingerprints.

In any case we can obtain/generate large numbers of chem- ical compounds while most of them are not of our interests.

Even in case we apply some sort of knowledge-based filtering, such as filtering out molecules with high molecular weight or with low probability of syntetizability, we still usually need a way of characterization of the remaining candidate compounds. This is where visualization of the chemical space in 2D or 3D space can be handy. It can help with showing the relation between the chemical compounds in a user friendly way. Consequently the expert knowledge can be brought into the process to decide which molecules to drop and which to preserve for further exploration.

In order to treat the chemical space we need a way to     computationally represent molecules. The following list shows a high-level division of computer molecular representations:  ? Graph-based representation Graph-based representation is based on storing the full information available in the 2D structural formula. A graph can be also used to represent the 3D structure of a molecule but in that case, nodes of the graph need to be enriched with 3D coordinates. Graph-based representation keeps all the available information but can be computationally demanding in further processing of the datasets such as similarity search in large databases.

? Fingerprint representation Molecular fingerprint is a bit string based on the struc- tural formula. Basically, given positions in the bit string correspond to specific features (e.g., molecular fragments or physico-chemical properties). If the molecule contains given feature, the corresponding bit is turned on. Since the number of features can be high, bit strings are usually hashed, i.e., one position corresponds to multiple features.

We can further classify the fingerprints into two groups based on the features ? structural fingerprints (structural keys) and combinatorial fingerprints. The former ones are based on predefined dictionaries of structural fragments (keys) while the latter are based on number of particular features in the molecule such as all possible labeled paths up to a certain depth, etc. Since this type of representation is quite efficient many types of fingerprints have been developed such as MACCS (MDL keys) [10], ECFP [11] and others.



II. CHEMICAL SPACE VISUALIZATION  In the previous section we described the concept of the chemical space and how we can computationally represent objects within that space. Here, we would like to emphasize some issues related to the chemical space visualization.

The main problem of visual representation of a set of chemical molecules stems from the fact that molecules in the set do not comprise any mutual position information. The only information available is their representation (see previous section). Based on the representation we can use a distance measure to compute distances between those representations, i.e. molecules. Probably the most often used distance/similarity measure is the Tanimoto coefficient [12] or measures based on it. Therefore, we can enrich the set by distances between the objects but these distances do not uniquely define positions in 2D space. To do so we need to project the set into 2D space to preserve the distances between the molecules as accurate as possible. The projection can be carried out by various methods such as Principle Component Analysis (PCA) [13], Generative Topographic Mapping (GTM) [14][15], Self-Organizing Map (SOM) [16] or Multidimensional Scaling (MDS) [17]. How- ever, the quality of the resulting visualization is determined not only by the dimension reduction method but also by the chosen molecular description and distance measure. It follows that a single data set can be visualized in multiple ways based  on the chosen components and each of the component greatly influences the quality of the resulting visualization. Therefore we developed a tool providing the users with the ability test multiple combinations of the components but also to develop their own allowing to test new approaches in terms of the resulting visualization.



III. EXISTING TOOLS FOR CHEMICAL SPACE VISUALIZATION  There exists a number of research groups interested in the visualization of the chemical space. Also commercial tools which can do far more than pure visualization of the chemical space are available. Those tools are mostly parts of complex software solutions for analysis of collections of chemical compounds.

Among the tools from the academic domain we can name, e.g., 3D molecular viewer CheS-Mapper [18] designed to work with large datasets. It combines clustering, multidimensional scaling and a 3D viewer. It is a generic tool as it is up to the user to define a similarity measure by choosing features that are employed within the mapping process. The program is opensource so there exists the possibility of its modification to reflect the users needs. However, CheS-Mapper was not developed as a framework with the purpose of developing new visualization methods.

HiTSEE [19] is another tool designed for the analysis of the biochemical screening outputs. HiTSEE provides the user with the option to project one or more compounds of interest into the view and explore its neighborhood. The tool uses multidimensional scaling to visualize a given compounds set and also provides features to reinforce the perception of grouping in visualization.

Another tool worth mentioning is MolSpace [20]. MolSpace can project a set of massive multivariate data onto a visual space (two- or three-dimensional) by means of principal component analysis.

When we set aside the chemical context there exists number of visualization tools and frameworks. But not all of them are well suited for the usage in visualization of the chemical space.

Many of them are designed to work with numerical vectors or similarity coefficients only, which restricts the capabilities of the visualization process. Other issues can emerge when one needs to establish a connection between the chemical compounds source and the visualization itself. For example, Matlab Toolbox for Dimensionality Reduction [21] offers many visualization methods. But before the visualization takes place one needs an application capable of converting chemical compounds into the Matlab readable form. This can lead to the loss of connection with the original source of the compounds.

Moreover, Matlab is not free of charge.



IV. VISUALIZATION FRAMEWORK MOTIVATION  The above given examples show that many tools focus on providing the complete visualization process. But we are aware of no framework focusing primarily on providing easy way of implementing new visualization techniques. That is to    provide the users with a possibility to simply implement their own visualization techniques without the need to bother with reading the data sources or with GUI. By the visualization technique we mean not only the dimension reduction method itself but the whole visualization pipeline. Such pipeline can contain data source modules for the import of the compounds data, data transformation modules allowing, e.g., converting the data into a normalized form and finally a module for dimension reduction method converting the data into low- dimensional space comprehensible by the end user. The pre- sented framework ViFrame delivers all this and the following sections explain in more detail its architecture and capabilities.



V. VIFRAME  The ViFrame framework is composed of two main parts ? a library called BaseLib and a standalone desktop application both developed in C++. The application uses QT library to generate the user interface. Since ViFrame needs to work with modules in the form of dynamically loaded libraries it is platform-dependent and currently runs under Microsoft Windows only.

One of the most emphasized requirements when developing ViFrame was to make the implementation of new modules that participate in the visualization as easy as possible. Since the modules make sense only within the visualization pipeline, another important aspect was to allow easy integration of the modules into the pipeline.

A. Overall architecture  The visualization pipeline is composed of modules. Mod- ules are the base computational units and they inherit from the BaseLib::iModule base class. Data between mod- ules are exchange as data objects. Data object is a named container, that holds values stored under string ids.

Base class BaseLib::iModule does not provide methods for data handling, these methods are presented in a sepa- rated abstract class BaseLib::Interfaces::SequentialAcces and BaseLib::Interfaces::RandomAcces. To allow modules to ex- change the data objects, there is a need for passing information about inner data that an object holds. This is accomplished by using Sockets. The socket is a class that describes data objects which can then be passed from one module to another to share information about the contained data objects. Each module can be in three different states: closed, opened and prepared. The module?s state can be changed by calling following methods ? Open, Prepare, Close. In open state, a module should open all sources. While in prepared state, a module can be asked about data objects through implemented interface. Finally, the close state corresponds to the state after creating a module.

Some modules may require setting up some variables that drive the module behavior (e.g., path to source file, number of iterations, . . . ). A module can declare that given variable is the module property. The module property consist from associated variable, name and description. Module properties are shown and can be set up in Properties dialog in the application.

B. Data object  Data in the application are stored in data objects being the base data units transmitted between modules. The data object is a class that contains the object?s name and a collection of named values. Each data object can contain at most one value of a given name. The values that are stored in the data object are derived from a base value type called Variant. The Variant is a base class that specifies the interface that is mandatory for every data value. Adding a new data type is accomplished by deriving from the Variant type.

C. Visualization pipeline - user?s view  The visualization is secured by the visualization pipeline assembled from modules providing functionality for individual tasks in the pipeline. Therefore, from the user perspective, the modules are minimal computational units. The pipeline cannot contain cycles and each module can have zero or more inputs and must have just one output. The user can select from which module in the pipeline the data will be gathered. The pipelines can be assembled in the GUI of ViFrame. There are also features ensuring that the user-assembled pipeline is valid. For example, when a user wants to connect modules only those connections satisfying modules interfaces are offered.

Moreover, the modules can posses properties which when set (in the properties dialog) can change the module?s interface (input, output socket specification). Therefore, after these changes, integrity of the pipeline is checked and if there exists a connection that does not meet the interface conditions it is removed from the pipeline. Finally, there also exists an active protection from creating cycles in a pipeline.

D. Visualization pipeline - programmer?s view  To enable connection checking when assembling the pipeline, a concept of contract and socket is used. Each module is responsible for proper specification of its input and output sockets. The socket holds description of the data object that the module requires on input or offers on output. In case of connection every input socket must be subset of connected output socket. Because it is possible that multiple modules share output socket specification (name-value array of objects passed), a concept of levels is used to solve this situation. Each data value is described not only by its name but also by the number of the module that created it forming a fully qualified name for the value. This enables existence of multiple data with the same name.

Many modules just add new values or modify given values, so their output is determined by their input. To simplify manipulation inside these modules a programmatic support is provided by BaseLib so that passing an object in terms of specification can be solved by calling several pre-implemented functions.

E. Existing modules/plugins/visualization techniques  The visualization pipeline can be split up into three logical parts each of which represents a task over the data. The parts    are ? data source processing, data transformation, visualiza- tion. The role of the data source part is to obtain molecules from given source and transform them into data objects. Data sources can store molecules in data objects as a graph, as a text (for example as Structure Data Format or SMILES) or they can calculate descriptors and thus store vectors of numbers. The description calculation can be also part of the data transformation depending on the user preferences.

In the data transformation, data can be transformed using various mathematical methods (centering, scaling, ...). Even some dimension reduction method, such as PCA, can be used here to prepare the data.

The last part of the pipeline is the visualization itself.

As one can see there is no strict separation of the tasks  which can mingle quite freely. This fact is reflected also in the module design in BaseLib where no restriction on modules?s task is laid down. Therefore, theoretically, it is possible to do implement all the parts within a single module although such a solution is not optimal from the software design point of view.

Some examples of pre-implemented modules in each part are given bellow. For the visualization method, dimension reduction method in our case, little theoretical background is also given.

1) Data sources: ? RDKit The module employes chemical library RD-  Kit [22] to load molecules from *.sdf files. After loading, molecular fingerprints are computed and passed to the next module as numerical vectors.

2) Data modifiers: ? Scaler Scaler provides basic data preprocessing as the  data centering and normalizing.

3) Visualization modules: ? PCA The PCA module implements equally called method  that can be used for dimension reduction PCA (Principal Component Analysis) [13]. PCA does linear transforma- tion from a source space into a target space while trying to preserve maximum variability of the transformed data.

PCA is a commonly used technique in visualization of the chemical space. However the module is not optimized for performance and so the performance capabilities of the PCA method are not fully utilized.

? SOM The SOM module implements a reduction dimension technique called Kohonen network or Self Organizing Maps [16]. The Kohonen network is a type of an artificial neural network trained using unsupervised learning to provide discretized representation of the input space of the training samples called a map. In the learning (training) process, the network is built according to the learning set. In the second part (mapping), the network automatically classifies given objects. In our implementa- tion, we use a 2D network. Modules offer the possibility of setting the size of the learning set as well as the size of the network as a percentage from the number of data object that will be classified by the SOM module.

? MDS The MDS module implements a method called classical multidimensional scaling [17]. Classical multi- dimensional scaling is a method for dimension reduction based on the similarities (distances) in the input data set.

The goal of the method is to compute positions in a target space so that the distances in the source and target spaces correspond as much as possible. The disproportion in the source and target distance space is called error.

The objective of the classical multidimensional scaling is therefore to minimize the error. Our implementation is using the SMACOF algorithm [23]. SMACOF is an itera- tive algorithm that guarantees to monotonically decrease the error over iterations. When using multidimensional scaling, the common practice is to use an error value threshold to terminate the computation. However, in our implementation we let the user set up the number of iterations as a property of the MDS module. Therefore the error value does not have to be computed in every iteration.

F. Custom Module Implementation  To get the impression of what it takes to implement one?s own module we show an implementation of a simple visualiza- tion module. For more detailed description of implementation of custom modules, please visit project?s homepage http://siret.

cz/viframe. All modules in ViFrame have a common base class BaseLib::iModule. This class contains methods that allow a module to manage its input and output sockets, connection, properties settings and state switching (see Overall architecture for mode details).

#ifndef sampleModule_h #define sampleModule_h  // BaseLib includes /// #include "Vector.hpp" #include "Visualiser.hpp"  typedef BaseLib::Modules::Visualiser<BaseLib:: Objects::VDouble, BaseLib::Objects::VDouble> BaseClass;  class SampleModule : public BaseClass { private: /** * Output dimension.

*/ int mOutputDimension;  public: SampleModule() : BaseClass("OutData"), mOutputDimension(2) { //register property mProperties.push_back(BaseLib::Properties::  CreateLimited("Output dimension: ", "Output dimension.", mOutputDimension, 1, 100));  } public: void Visualise() { // test input data size int dataSize = DataSize(); if (dataSize == 0) { // no data -> finish  return; } // determine input dimension    Fig. 1. ViFrame GUI. (A) Setting properties of the import module. (B) Sockets setting. (C) Overall view of the pipeline assembly environment. (D) Visualization component of ViFrame.

// we assume that all data has the same size int inputDimension = AccesInData(0).Data.size(); if (inputDimension < mOutputDimension) {  ReportMessage(BaseLib::iReportable::Error, " inputDimension < mOutputDimension");  throw BaseLib::Exception(); } // iterate over input data for (int i = 0; i < dataSize; ++i) { std::vector<double>& inData = AccesInData(i).

Data; // process data here } // save output data for (int i = 0; i < dataSize; ++i) { std::vector<double>& outData = AccesOutData(i).

Data; // write output data into outData }  } };  _DYNLINK void* CreateModule() { return new SampleModule();  }  _DYNLINK void DeleteModule(void* module) { SampleModule* convModule = reinterpret_cast<  SampleModule*>(module); delete convModule;  } // module description BaseLib::Description locDescription(std::pair<int,  int>(1,0), "SampleModule", "Short description.", "Long description." );  _DYNLINK const BaseLib::Description* GetDescription() {  return &locDescription; }  #endif // sampleModule_h  G. Application  The ViFrame framework is accessible as a runnable appli- cation which provides the user with the possibility not only  to assembly the pipeline but also to view the graphical pre- sentation of the results. The application part of the framework contains the following features which are elaborated bellow.

? Environment for the pipeline assembly.

? Running the pipeline and visual inspection of the finished  pipelines.

? Visualization of the results on a 2D canvas with moving  and zooming capabilities.

? Tree view representation of the result set interlinked with  the canvas with the ability of highlight, drag and drop, etc.

? Image and CSV exporting.

The graphical presentation is implemented as a projection of  the objects into 2D space where the user can move and zoom in and out. After the pipeline computation is over the data are gathered from the last module in the pipeline and prepared for the graphical presentation. Data to be viewed are accessible through a treeview component where the information about the data object values can be accessed using a dialog. The data objects can be organized into user created groups. The drag and drop approach was chosen to enable data object and groups organization. The groups can create a tree structure and for each object or group a visibility in the graphical presentation can be set while the color can be assigned on the group level only. The data objects are drawn as points with color determined by the group they are members of.

The graphical presentation and treeview are interconnected in terms of selection, so selecting a data object in the tree highlights the related object in the graphical presentation and vice versa. To determine the position of an object in the graphical presentation any two values from the data object can be used. The selection of those values can be changed by the user therefore one data object can have multiple positions and one can choose any of them in the visualization.

However, the provided functionality in the area of graphical presentation and analysis of the result is a work in progress.

We are currently cooperating with chemists using this software and we are collecting feedbacks which we will take into account in the next version of the framework. Currently, for detail analysis of the data there is a possibility to export the data into the csv file format and consequently to use it as the input into another program in the research pipeline.



VI. VISUALIZATION EXAMPLES ViFrame can not be compared to other methods in terms of  efficiency of the implemented methods since it is not the point of the application. The aim is to provide simple environment where users can develop their own (possibly highly efficient) techniques. Just to show how different visualization methods can differ when working with the same data set using the same molecular representation and distance measure we present in this section ViFrame?s visualization output for PCA and MDS methods. As the input set, we used the output of the Molpher algorithm [8]. Molpher is a tool for exploration of the chemical space between start and target molecules. Its purpose is to find a path in the chemical space between    MDS-10 MDS-40 MDS-60  PCA-10 PCA-40 PCA-60  Fig. 2. ViFrame?s visualization of the Molpher?s exploration process.

the two molecules. It works iteratively, producing generations of molecules with the assumption that molecules in higher iterations should be closer to the target than the previous ones. Figure 2 shows a snapshot of the 10th, 40th and 60th iteration of the space exploration process when finding a path between Dihydrotestosterone (Pubchem compound ID 10635) and MDV 3100 (Pubchem compound ID 15951529). The starting molecule is designated with the green cross while the target molecule is colored yellow. The closer the molecules get to the target the redder they are. We can clearly see that in the later iterations more molecules get closer to the target but more importantly molecules closer to the target are redder than those further away. Thus we can see that given representation, distance measure and visualization make sense since molecules close based on the distance measure are also close in the 2D visualization.



VII. CONCLUSION  In this paper we introduced a new pipeline-based chemical space visualization tool ViFrame. ViFrame is a self-contained solution which offers the user a simple way of development and testing of new visualization algorithms. The main advan- tage in comparison to existing tools consists in allowing the user to focus on the algorithmic part of the task while the visualization itself and the GUI can be left to the ViFrame application. Moreover, the pipeline design allows to divide the visualization task into multiple sub tasks thus allowing the user to focus on individual parts of the process independently of the others.

In the future we would like to increase the user-friendliness of the application and to extend the capabilities of the software in terms of manipulation with the resulting visualization.

