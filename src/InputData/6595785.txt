Vee@Cloud: The Virtual Test Lab on the Cloud Xiaoying Bai?, Muyang Li?, Xiaofei Huang?, Wei-Tek Tsai? ?, Jerry Gao? ?

Abstract?Large-scale system testing is challenging. It usually requires large number of test cases, substantial resources, and geographical distributed usage scenarios. It is expensive to build the test environment and to achieve certain level of test confidence. To address the challenges, test systems need to be scalable in a cost-effective manner. TaaS (Testing-as-a-Service) promotes a Cloud-based testing architecture to provide online testing services following a pay-per-use business model. The paper introduces the research and implementation of a TaaS system called Vee@Cloud. It serves as a scalable virtual test lab built upon Cloud infrastructure services. The resource manager allocates Virtual Machine instances and deploy test tasks, from a pool of available resources across different Clouds. The workload generator simulates various workload patterns, especially for system with new architecture styles like Web 2.0 and big data processing. Vee@Cloud promotes continuous monitoring and evaluating of online services. The monitor collects real-time performance data and analyzes the data against SLA (Service Level Agreement). A proof-of-concept prototype system is built and some early experiments are exercised using public Cloud services.

Index Terms?Test-as-a-Service, Cloud-Based Testing Architec- ture

I. INTRODUCTION  Software scale and complexity increase tremendously in recent years, supported by new architecture styles such as Web 2.0 and big data processing. For example, Facebook, the most popular Web 2.0 SNS website, had 2.5 billion pieces of content and 500+ terabytes ingested every day by posting, and image uploading [1]. Testing of Internet-scale systems faces many difficulties in terms of scale and cost. For example, as calculated by performance engineer at F5 Networks, it requires $3 million investment to test an Internet-scale application deployment [2]. The difficulties come from several aspects, as listed below.

? It is hard and expensive to design, develop, and maintain large number of test cases.

? It may require a lot of resources to exercise testing for preparing test data, generating concurrent test threads, and simulating inputs.

? It may take a lot of time and effort to set up and maintain various test environments such as geographical distributed access.

In counter to these problems, Cloud computing provides a new paradigm for constructing scalable testing systems and offering cost-effective testing services. It promotes large-scale resource sharing and on-demand resource allocation following  a pay-per-use business model [3], [4], [5]. Various kinds of resources (such as hardware, storage, software data and applications) are maintained as ideally unlimited resource pools and exposed as services following the Service-Oriented- Architecture (SOA). Some early attempts have been made to migrate conventional testing tools to Cloud platforms to parallelize test jobs to reduce test time, generate large scale and distributed loads, and simulate various test environments [6], [7], [8]. TaaS (Testing as a Service) was proposed in recent years to provide static/dynamic on-demand testing services in/on/over clouds for testers at any time and all time [9], [10], [11], [12], [13], [14], [15]. Compared with conventional approaches, TaaS in a Cloud infrastructure is promising to provide following benefits:  ? Self-service testing. With various testing services avail- able online, testers can choose and customize the tools and platforms they need, configure test environment, rent test resources, and trigger testing remotely and automat- ically.

? Scalable test environment. Test environment can be re- motely hosted and maintained on the Cloud platform.

It can dynamically scale up and scale down testing resources as needed.

? Reduced cost. It can greatly reduce the cost by sharing testing resources and reusing testing facilities following the pay-as-you-test Cloud business model. Many tech- niques begin to be widely used in cloud computing, such as large-scale virtualization and multi-tenancy architec- ture, to achieve the economy of scale.

Vee@Cloud is built based on TaaS concepts. It is designed and implemented as a platform-independent virtual test lab to provide on-demand testing services and Internet-scale testing capabilities. Fig. 1 gives an overview of Vee@Cloud architec- ture. Basically, it is composed of four components.

1) Requirement collector provides a Web-based interface for users to define their SLA requirements, select test profile and configure test environment, trace test progress and check results.

2) Test controller creates test tasks based on test require- ments, generates test runners and allocates test tasks to test runners. Each runner carries a package of test data, test scripts, workload pattern and test driver.

3) Resource manager interacts with Cloud vendors to re- quest for resources, dynamic adjust resources based on     Fig. 1. Vee@Cloud Architecture Overview  test needs, and deploy test runners to the target virtual machine instances on the IaaS platforms.

4) Monitor supervises the performance of the system under test (SUT), including the target cloud platform and the applications deployed on the Cloud.

Vee@Cloud is designed and constructed following SOA architecture that can be easily extended to incorporate new components and services.

The rest of this paper introduces the design and implemen- tation of Vee@Cloud. Section II introduces the mechanism of on-demand test resource allocation. Section III presents the architecture to support scalable workload simulation. Section IV describes the design of continuous monitoring. Section V introduces the prototype system. Finally, Section VI concludes this paper.



II. ON-DEMAND TEST RESOURCE ALLOCATION  Vee@Cloud uses IaaS service from public Cloud vendors, such as Amazon and RackSpace, to provide testing resources on-demand. IaaS platforms offer resources in the form of Virtual Machine (VM) instances. A VM instance is a whole package of CPU, memory, storage and network. For example, Amazon EC2 (Elastic Computing Cloud) is a typical IaaS provider of computing services. VM instances are categorized into different types like small, medium, large, and extra-large.

Users can choose the number and size of VM instances and the duration to rent. Services are charged by users? renting profile.

Vee@Cloud resource manager functions as a broker for testers to choose resources among IaaS providers. It receives testing tasks from test controller, looks up available resources of VM instances, schedules test tasks on the instances, and deploys test runners via adapters to IaaS vendors. In this way, users can set up their own dedicated test environment and configure tests as needed.

Fig. 2 shows the internal structure and process of resource manager.

1) The task manager interprets test tasks. Each task contain- s a group of test jobs to be executed, the expected work-  Fig. 2. Vee@Cloud Resource Allocation  load, the preferred IaaS vendor, and other constraints such as job priority.

2) Resource requirements are extracted from task descrip- tion and forwarded to resource scheduler, while test execution requirements, in terms of test runners, are forwarded to deployer.

3) Resource scheduler maintains a resource pool which is the records of registered resources. Each record is a piece of resource linked to a Cloud VM instance. It records basic information of the instance, such as size, URL, availability status, and performance ranking based on previous experiences.

4) The scheduler searches the resource pool to find the most appropriate instances for each job. The job schedule is then returned to task manager and deployer.

5) To support operations across different Cloud platforms, an adapter is created. It provides an unified internal interface for Cloud IaaS connection and instance man- agement. The operations (such as create, start, stop, clone, and destroy instances) are translates to the specific protocols and programming interface functions of each IaaS.

6) According to the job schedule, the deployer connects to target Cloud and VM instances through the adapter.

It then deploys the runners to the target instances and starts its executions as scheduled.



III. SCALABLE WORKLOAD SIMULATION  Internet services usually experience large and unexpected load fluctuations. For example, Taobao is a large e-commerce system in China which provides a cloud-based open platform for on-line shops. As reported, in a typical week, a common shop has over 3500 orders at the peak day and only 100 at the low. There are around 83 million shops at Taobao, which account for a fluctuation of over 25 billion orders during the week. Each order is on average contributed by 318 page browses from 201 customers. The system thus experiences a huge change of the number of transactions from day to day.

Fig. 3. Agent-Based Distributed Workload Simulation  Massive scalability is thus an important feature of systems performance.

To test evaluate systems? capability to support massive scalability, it is necessary to simulate representative workload patterns, such as big data processing and distributed work- load. In this research, the Multi-Agent Framework is applied to support distributed workload simulation and to achieve adaptability and massive scalability. In our previous work, the MAST framework is designed and applied to testing Internet applications [16].

In Vee@Cloud, parallelism is achieved at three levels of granularity: Test Suite, Test Task and Test Thread. Test Suites are independent executable test scripts that can be allocated to isolated VM instances to be executed in parallel. A test task is composed of test driver to executed the test cases and test generator to create different workload. A test task may trigger multiple threads following certain statistical patterns to simulate workload from one test runner.

Workload is controlled at two layers: (1) test driver to simulate concurrent executable threads; and (2) test gener- ator to simulate various workload patterns. A test driver is a component that can trigger operations of a certain SUT (software under test). A load generator is a component that decides the distribution of atomic operations, which can be profile-based, statistic-based or learning-based. It also decides the frequency of operation submission. In this way, it allows users to customize the granularity of atomic operations, and to select the distribution of operations to simulate different workload patterns.



IV. CONTINUOUS MONITORING  Internet services may be changed frequently and unex- pected. Such changes are usually transparent to end users.

For example, once hosted on the Cloud, the system should conform to its SLA (Service Level Agreement) promised responsiveness and scalability. They need to rapidly handle transactions, process data, and support increased usage load with acceptable performance degradation. Cloud providers usually make technical promises in terms of reserved resources and service availability. Unfortunately, there is still lack of integrated performance guarantees and many systems fail to meet their performance objectives.

Fig. 4. Performance Model  Fig. 5. Vee@Cloud Monitor Archtiecture  Runtime monitoring is an effective technique for continu- ous quality assurance. It tracks software execution, observes system behavior, verifies service dependability properties, and responds to policy violations. To validate SLA conformance, many Cloud platforms provide real-time performance moni- toring services via Web interfaces or Open API (Application Programming Interface). In this way, users can continuously collect system performance data and react quickly in case there is any anomaly.

An issue of cross-Cloud performance monitoring is data consistency. Cloud vendors usually define their individual per- formance indicators and provide limited access using specific API. It still lacks a unified performance model and protocol.

It is hard to compare performance across different Cloud platforms. To address the problem, Vee@Cloud builds an integrated Cloud performance model and an adapter architec- ture to match unified SLA queries to various data collection interfaces. An adapter is implemented for each cloud to collect performance data by open API. The performance data are wrapped using the unified performance model, as shown in Fig. 4, for further analysis and cross-cloud comparison.

Fig. 5 shows the process of monitoring.

Fig. 6. The Deployment Architecture of Vee@Cloud Prototype  1) The SLA requirements are collected and analyzed to extract the concerned performance data and metrics.

2) To collect performance data, a performance query is constructed internally.

3) The adapter maps the query to the operations of moni- toring interface provided by each IaaS provider.

4) The adapter builds connections to IaaS monitoring ser- vices and collect runtime data according the SLA re- quired frequency and period.

5) The data are transformed to the unified performance model for analysis, evaluated, and comparison between different services.



V. PROTOTYPE TOOL  A prototype system is implemented to illustrate the pro- posed approach, as shown in Fig. 6. It is composed of a frontend server, a performance monitor server, a controller server and a central database server, and interfaces to two private cloud built upon VMWare vCenter and OpenStack in the lab environment. All services are published following RESTFul WebService standards. Runner is implemented as daemon service in Linux system, providing runtime support for TestTask. A web-based user interface is provided for testers to upload test scripts and preferred configuration. During execution, it provides the functionality of monitoring the execution state and resource utilization.

Preliminary case studies are exercised. The Olio system is deployed on the target server as the system under test. Olio is a web 2.0 event management website with a set of operations including homework, databased search, and database update.

A group of test suites are exercised based on Vee@Cloud platform, using Olio test driver. Each test suite is deployed to a micro VM instance with 1 VCPU, 1K MB memory and 40 GB disk. The workload pattern is defined by two parts: (1) the statistical model of Olio operations; and (2) the number of concurrent threads. Each test suite simulates a different workload pattern. For (1),it choose from a set of statical distribution generators, such as using a Makov transi- tion matrix by MakovGnerator, or using constant distribution by ConstantDistributionGenerator. For (2), it can configure different number of current threads. The experiment shows that the platform can considerably reduce test overhead while enhancing test flexibility and scalability.



VI. CONCLUSION The paper introduces the design and implementation of  Vee@Cloud system, a Virtual Test Lab on the Cloud. It proposes a new architecture for large-scale testing. It is built on IaaS platforms to take the advantages of dynamic resource allocation to reduce cost and enhance test scalabilities. Tests are organized hierarchically to support multi-layer parallel execution, various workload pattern configuration, and dis- tributed workload simulation. The prototype system has built interfaces to private Cloud platforms. In the future, it will build connections to public Cloud for research and experiments.

