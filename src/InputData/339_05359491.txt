Mining Recent Approximate Frequent Items in Wireless Sensor Networks

Abstract   Mining Frequent Items from sensory data is a major research problem in wireless sensor networks(WSNs) and it  can be widely used in environmental monitoring. Conventional Lossy Counting algorithm can be applied to solve this problem in centralized manner. However, centralized algorithm brings severely data collision in WSNs, and results in inaccurate mining results. In this paper, we present D-FIMA, a distributed frequent items mining algorithm. D-FIMA, running at every sensor node, establishes items aggregation tree via forwarding mining request beforehand, and each node maintains local approximate frequent items. The root of the aggregation tree outputs the final global approximate frequent items. Theoretical analysis and the simulation results show that energy consumption of D-FIMA is much less than the centralized algorithm, and mining results of D-FIMA is more accurate than the centralized algorithm.

1. Introduction   Wireless Sensor Networks(WSNs) have been successfully applied for environment and security monitoring, object tracking and so on. It is a more challenging area related to data mining in WSNs, since sensor nodes have only limited resources(energy, storage, computation, power supply and bandwidth).

Therefore, WSNs require highly decentralized mining algorithms to overcome above constraints.

Mining frequent items among monitored attributes in a region R covered by sensor networks is crucial foundation of finding association rules among those attributes[1] and provides more knowledge related to spatio-temporal patterns for observers. For example, in a weather monitoring application, sensor node monitors three attributes: t(temperature), s(sunlight time) and r(rainfall). Every attribute value is set as five levels: v1(very small), v2(small), v3(average), v4(big), v5(very big). For instance, the domain of temperature is  (-100, 100). (-100, 100) is divided five disjoint parts. If t?(-100,-20), then the value of t is set as being very small, i.e. t=v1; If t?(-20, 0), then t=v2; If t?(0, 20), then t=v3; If t?(20, 30), then t=v4; If t?(30, 100), then t=v5. s and r can be set in same way. A tuple (t=v3, s =v1, r=v2) measured by a sensor node can be regarded as an item. Each node can maintain approximate frequencies for recent items. Based on frequent items, an association rule, such as ?within recent 30 minutes, in the monitoring region R, t=v3 ?s =v1?r=v2 with support=45% and confidence=60%?,  may be mined and it can be described ?In recent 30 minutes, in monitoring region R, when temperature is average and sunlight time is very small, then rainfall is small, support degree and confidence degree for this rule are 45% and 60% respectively?. Mining recent frequent items can further provide knowledge related to spatio- temporal patterns for aerography experts.

Conventional Lossy counting algorithm(for short C- FIMA, Centralized Frequent Items Mining Algorithm) [2] can be applied to mine frequent items in centralized manner which transmits all sensory data to the sink. At the sink, C-FIMA is executed to mine frequent items.

Sending all sensory data to the sink will result in crowded communication channel, so communication bandwidth becomes bottleneck and many important data may be lost, which make deviation between mining results and reality. If all sensory data are sent to the sink, the communication will become the main task.  Consequently, a lot of energy will be consumed and the lifetime of network is reduced. In-network processing [3] can reduce energy consumption, network traffic and extend the lifetime of sensor networks.

In this paper, we present D-FIMA, a distributed continuous approximate algorithm for mining frequent items, where ?continuous? denotes that the algorithm will return new mining results after every epoch.

2. Problem Description    DOI 10.1109/FSKD.2009.607    DOI 10.1109/FSKD.2009.607         Some concepts and terminologies required in the paper are described in this section.

Definition 1(Epoch) In WSNs, time is divided into intervals of fixed length. Each such interval is called epoch. The duration of an epoch depends on specific application and the change rate of the measured physical quantities.

Definition 2(Rank) The set of all sensory attributes monitored by a sensor is denoted as B={A1, A2, ?, Am}, where Ai (i=1, 2,?,m) denotes the ith attribute and m is different or same for different sensor nodes. Ui , the domain of Ai, is divided into c ordered non- overlapping ranges: vi 1, vi 2, ?, vi c and satisfies?  1.

c  i i j j  U v =  =? and if j?k, vi j?vi k=? (i=1, 2, ?, m).

2. For ?x?vi j , y?vi k, where x and y are values of Ai, if 1?j<k?c, then x<y  (i=1, 2, ?, m).

If x?vi j, then the rank of x is vi j . For simplicity, it denotes as x=vi j.

Definition 3(Item) Given a sensory data (x1, x2, ?, xm), where xi (i=1, 2, ?, m) is the sensory data drawn from Ai (i=1,2,?,m). If xi=vi ji (i=1, 2,?, m) then X=(v1j1, v2 j2, ?vm jm,) is called an item.

Definition 4(Approximate Frequent item and minimum support) For an item set D, an item X?D is a frequent item if and only if f(X, D)?s?|D|, where f(X, D) is frequency of X in D, s?[0, 1] is a minimum support. X is called a approximate frequent item if f(X, D)?(s-?)?|D|, where ? is mining error, 0 ?? <<s.

Our research problem is: Given a rectangle region of sensor networks R[x1, y1, x2, y2] with the left-down coordinate (x1, y1) and the right-up coordinate (x2, y2), a threshold s?[0, 1], a mining error ? with 0 ?? <<s  and integer W, find all approximate frequent items from item set D generated by those sensors located in R[x1, y1, x2, y2] in recent W epochs.

3. Related Work   Association rule mining was first introduced by Agrawal et al. in [1]. It aims to extract interesting correlations, frequent patterns, associations or casual structures among sets of items in the transaction databases or other data repositories [4].  After that, association rule mining becomes an important research branch of data mining field. Many known algorithms of association rule mining are presented by some researchers. Jiawei Han presents detail categories and outline of algorithms of association rule mining in [5], but these algorithms are centralized mining algorithms unable to be used in WSNs. Some works in developing parallel and  distributed association rule mining may be found in [6-8]. K.K.Loo et al. presents a centralized  algorithm for mining inter-stream associations from sensor networks [9]. In [10], it is assumed that the communication among nodes may be directly carried out by computer networks. The communication among nodes is carried out by multi-hops routing in WSNs.

However, these algorithms can not be used in WSNs.

4. D-FIMA Algorithm   The Distributed Frequent Items Mining Algorithm (D-FIMA) is presented in this section. We assume that all nodes in the sensor network have synchronized their clocks and share a common time.

4.1. The framework of D-FIMA   In this section we describe the general framework of our algorithm as follows:  In the tth epoch, node P generates a sensory data T(p, t)=(x1, x2, ?, xm), then node P converts T(p, t) into an item X=(v1 j1, v2 j2, ?vm  jm,) and maintains item frequency fX for X. We adopt the approximate counting algorithm over sliding window proposed by Arvind et al. [11](for short Arvind-counting) to maintain every item frequency.

R  sink  Mining request Partial mining result Final mining result  r   Fig.1 The Framework of D-FIMA  First, the sink node sends the mining request Q{s, ?, R[x1, y1, x2, y2], W } to the node r in R[x1, y1, x2, y2], which is the closest neighbor to (x1, y1). Second, nodes in R establish an items aggregation tree rooted at r.

Node r broadcasts the request Q to its neighbors. If r?s neighbor is in R, r?s neighbor continues to transmit the request, if r?s neighbor is not in R , discard the request.

Third, the leaves of items aggregation tree send local frequent items to their parents. When the parent combine all frequent items sent by their children, the parent send its items to its parent. The same process is repeated until the root r combines all frequent items, and r transmits the result to the sink via greedy routing protocol [12]. Finally, the sink reports the mining result. In addition, D-FIMA is a continuous mining algorithm. When the time slide window changes, sensor nodes needn?t recompute the local approximate frequent items within the time slide window, but         compute incrementally the local approximate frequent items and send increment results to its parent, then the parent node combines them and transmits them to its parent. Fig.1 illustrates the overall process of D-FIMA.

4.2.Frequency counting on a single sensor node   We adopt Arvind-counting algorithm [11] to get approximate counts for each sensor node. The algorithm conceptually makes L+1 copies of the item stream on sensor node, where L=log2(4/?1), ?1=?W/Wmax. Wmax denotes the width of the longest time window maintained by single node.  For each level, the copy of the item stream is divided into non- overlapping blocks. In each level all blocks have the same size, and the size of the block in level-i is Mi=2i(?1Wmax)/4, i.e.? in? each? block of level-i sensor node maintains Mi items and their frequencies. Time window of block-j in level-i is [tnow-Wmax+j ? Mi +1, tnow-Wmax+(j+1) ? Mi], where tnow is current epoch number. Arvind-counting identifies each block as a state. The time window of the block-j in level-i is [tnow-Wmax+j ? Mi +1, tnow-Wmax+(j+1) ? Mi]=[l, r]. The block is ACTIVE if tnow-W<l<r<tnow, it is UNDER- CONSTRUCTION if tnow-W<l? tnow and r> tnow, and it is EXPIRED if l<tnow-W. Fig.2 shows details.

Wma x  W  Level-0  Level-1  Level-2  Level-3  1 max  W?  Expired Active Under construction  tnowtnow-Wma x   Fig.2  Levels and blocks in Arvind-counting algorithm  For answering mining request, Arvind-counting selects those non-overlapping ACTIVE blocks as big as possible, so union of those blocks are equal or nearly equal to [tnow-W, tnow]. The algorithm unites items frequency tables of those blocks by accumulating the approximate frequency of same item. For example, in Fig.2, we unite those blocks with black frame.

Lemma 1[11] Arvind-counting ensures: (1) Item X in the union of items frequency table  satisfies (a)h(X)??M? ( )h X ?h(X); (b) ( )h X ??M, where h(X) and ( )h X denote the true frequency and approximate frequency of the item X in union of items frequency table respectively and M is the total number of items generated by sensor node in [tnow-W, tnow];  (2) The memory space for Arvind-counting is O((Wmax /?W)log2(Wmax /?W)).

Suppose that each node?s memory space for maintaining Arvind-counting algorithm is B. From  Lemma1: O((Wmax /?W)log2(Wmax /?W))?B, we can choose the maximal Wmax  satisfying above inequation as system?s parameter Wmax .

Node P sends the local ?-approximate frequent items frequency table F(?, M)={<X, ( )h X >| ( )h X ? (s- ?)?M } to its parent. When the slide window [tnow-W, tnow] moves rightward 1 epoch, node P need to recalculate the ?-approximate frequent items table of new window [tnow-W+1, tnow+1] and send the table to its parent. To reduce the communication traffic, node P need incrementally calculate the ?-approximate frequent items frequency table, then send the increment to its parent. Node P computes the items frequency table F1={<X,  ( )Fh X >} of window B1=[tnow-W, tnow-  W+1] and the items frequency table F2={<X, ( )Fh X >}  of window B2=[tnow, tnow+1] respectively, then gets the ?difference?  using formula F2/F1={<X,  ( )h X >| ( )h X = ( )Fh X - 1 ( )Fh X , X?F1?F2 if X?F1 then  ( )Fh X =0; if X?F2 then 2 ( )Fh X =0}, finally sends the  difference F2/F1 to its parent. Its parent need do union again. Fig.3 shows incremental computing.

tnow-W  tnow-W+1 tnow  tnow+1 B1  B2   Fig.3 Maintaining items frequency table incrementally   4.3. D-FIMA algorithm   D-FIMA Algorithm is described as follows: Step 1: Forward mining request  The sink  transmits the mining request Q{s, ?, R[x1, y1, x2, y2], W } (for short Q in the remainder of this paper) by greedy routing protocol [12] to node r which is the closest neighbor to (x1, y1) in R[x1, y1, x2, y2] (for short R in the remainder of this paper).

Step 2: Establish aggregation tree  Specifically, if the node r can make sure that itself is the closest node to (x1, y1)  in R (it can be guaranteed by greedy routing protocol [12]), it will add its ID on the request package to form the new communication package {r; Q}, called establish-tree request, then it broadcasts the establish- tree request to its all neighbors. For a node p, if p is r?s neighbor, then: if node p is not in R, all packages received by the node p will be discarded. If node p is in R, when node p receives the establish-tree request from node r, node p will finish the following tasks:         (1) mark node r as its parent; (2) reserve the request Q  at local;  (3) modify the establish-tree request  as {p; Q} and broadcast {p; Q}  to all its neighbors; (4) send a reply {p; Parent: r; Child: p} to r; (5) if node p receives again establish-tree request from other nodes, node p will discard it.

If node r receives the reply {p; Parent: r; Child: p}, node r will substitute the set Children(r) for Children(r)?{p}, where Children(r) denotes the set of r?s all children. Whereafter, node p is regarded as r and D-FIMA repeats above steps for other nodes in WSNs.

Fig.4 Combination algorithm on sensor node.

Step 3: Create items frequency table  For a node  p, If Parent(p) and Children(p) have been confirmed, where Parent(p) denotes node p?s parent, p will create the items frequency table using Arvind-counting.

If the set Children(p) is empty, that is, node p is leaf node of items aggregation tree, then node p sends the local ?-approximate frequent items frequency table, F(?, Mp)={<X, ( )h X >| ( )h X ? (s-?)?Mp}, to its parent, where Mp denotes the total number of items in p?s ?- approximate frequent items frequency table.

If the set Children(p) is nonempty, node p must receive ?-approximate frequent items frequency tables generated by p?s all children and then combine these frequency tables invoking combination algorithm listed in Fig.4. In the end, node p transmits the combined results to its parent.

Step 4: Create final mining result  If the root r has received ?-approximate frequent items frequency tables generated by r?s all children, r will invoke combination algorithm(in Fig.4) to combine these approximate frequent items frequency tables and transmits the mining result via greedy routing protocol [12] to the sink.

5. Experiments Evaluation   5.1. Experiments setup   (1) Simulation parameters. We adopt NS-2 simulator. All the simulation parameters used in NS-2 are listed in Table 1.

Table 1 Simulation parameters used in NS-2 Parameter Value Node?s communication radius 10m Node?s sleep power 0.035W power for sending message 0.66W Initial energy 10000J power for receiving message 0.26W width of maximum time window 10000epoches  (2) MAC protocol. 802.15.4 is chosen as MAC.

(3) Datasets. We experiment with two kinds of  datasets: real dataset used by the Intel Research Lab Berkeley(shortened form IRLBDS) [13] and the simulation datasets generated by ourselves.

(4)Sensor networks topologies.  For IRLBDS, we use setdest, a tool in NS-2 environment, to generate a topology with 54 nodes deployed in 45m?35m rectangle region. In experiments, we set network topology region as a square. We generate randomly 5 network topologies, and as the density of nodes in networks increases, the boundary X of topologies and number of nodes N in each topology region will increase. Table 2 lists the corresponding relation of the boundary length, the number of nodes N and the network densities. The sensor nodes are deployed randomly with uniform in X*X square region and the node which is closest to (0,0) is the sink.

Table 2 Five sensor networks topologies Topology length: X number of nodes: N node density  (nodes/m2) 62m 100 8/314 79m 200 10/314 88m 300 12/314 94m 400 14/314 99m 500 16/314   5.2. Network traffic   We use the stimulation dataset and 5 topologies in Table 2. The minimal support s=1%, approximate mining error ?=0.3%, the width of sliding window W =2000 and R[x1, y1, x2, y2]=[30, 30, 45, 45]. The routing protocol used in C-FIMA is AODV. Fig.5 shows the effect of nodes? density on total messages under two algorithms: C-FIMA and D-FIMA. Total messages are much higher under C-FIMA than under D-FIMA in that transmitting data generated by nodes in R to the sink results in high network traffic.

When the network density is higher, in the course of establishing items aggregation tree in D-FIMA, some nodes maybe receive some establish-tree request packages which don?t belong to themselves, so network traffic will heavy.

Combination Algorithm: Combine approximate frequent items table from d children Input: d ?-approximate frequent items tables F1(?, M1), F2(?, M2), ?, Fd(?, Md), where Mi denotes the number of items maintained by node i.

Output: single approximate frequent items table F(?, M) 1.

d F M F Mj j  j ? ? ??  =    2.For each item X   in ( , )  d F Mj jj  ? = ?  Do  ( ) ( )  d F h X F h Xj  j ? ? ??  =   If ( )F h X? <(s-?)?F ? M Then delete X from F(?, M).Endif 3. Endfor              8/314 10/314 12/314 14/314 16/314  Nodes density  To ta  l m  es sa  ge s  C-FIMA D-FIMA   Fig.5 Total messages with node density varying   5.3. Quality of mining results   In the experiment, we use the real dataset IRLBDS and set the minimal support s=1%, approximate mining error ?=0.3%, the width of sliding window W =100 and R[x1, y1, x2, y2]= [15, 15, 40, 30]. To inspect the quality of mining results, we regard the situation, in which no data is lost, as ideal situation. We store all data to calculate all the frequencies of frequent items in ideal situation. Meanwhile, we run respectively D-FIMA and C-FIMA to obtain the frequent items counts of two algorithms and compare the mining results (as showed in Table 3).

Table 3 Comparison among mining results Algorithm Ideal situation C-FIMA D-FIMA Number of items (support?s)  32 11 26  Number of items (s-??support< s)  19 10 17  Average error 0 242.73 30.71 Error Upper bound 71.05 71.05 71.05  In R[x1, y1, x2, y2]=[15, 15, 40, 30], there are 24 sensor nodes which generate the total amount of data up to 23684, and the approximate mining error ?=0.3%. In this case, the upper bound of items approximate frequency error is 23684??=71.05. The approach to obtain frequency average error of all frequent items under C-FIMA and D-FIMA is to compute absolute difference between frequency of each frequent item under specified algorithm and that of ideal situation, then to divide the sum of all frequencies absolute difference by the total number of items.

From Table 3, we observe that items estimation frequency under D-FIMA is less than the true frequency and the maximum difference of both is not greater than 23684??. D-FIMA loses 2 items of s- ??support<s. D-FIMA lose 6 items of support?s in that some communication packages are lost during data transmitting in in-network.

6. Conclusion   In this paper, we present D-FIMA, an ?- approximate frequent items mining algorithm.

Theoretical analysis and the experimental results show that communication load of D-FIMA is much less than that of C-FIMA in the case of same nodes? density, and the quality of mining results under D-FIMA is much better than under C-FIMA and average error of items? approximate frequency under D-FIMA is less than error upper bound.

7. Acknowledgment   This work is partly supported by the National  Natural Science Foundation of China for Young Scholar under Grant No.60803015; The China Postdoctoral Science Foundation under Grant No.20080430902; The Science and Technology Innovation Research Project of Harbin for Young Scholar under Grant No.2008RFQXG107; The Heilongjiang Postdoctoral Science Foundation under Grant No.LRB08-021.

8. References   [1] R. Agrawal and R. Srikant, "Fast Algorithm for Mining  Association Rules in Large Databases," In: VLDB, 1994.

[2] G. S. Manku and R. Motwani, "Approximate frequency  counts over data streams," In: VLDB, 2002.

[3] Y. Yao and J. E. Gehrke, "Query Processing in Sensor  Networks," In: CIDR, 2003.

[4] R.Agrawal, T. Imielinski, and A. Swami, "Mining  association rules between sets of items in large databases," In: SIGMOD, 1993.

[5] J.Han and M.Kamber, Data Mining-Concepts and Techniques. San Fransisco, USA: Morgan Kaufmann Publishers, 2001.

[6] A. Schuster, R. Wolff, and D. Trock, "A High- Performance Distributed Algorithm for Mining Association Rules," In: ICDM, 2003.

[7] M. Z. Ashrafi, D. Taniar, and K. A. Smith, "ODAM: An Optimized Distributed Association Rule Mining Algorithm," IEEE Distributed Systems Online vol. 5, 2004.

[8] M. J. Zaki, "Parallel and Distributed Association Mining:A Survey," IEEE Concurrency, 1999.

[9] K. K. Loo, I. Tong, B. Kao, and D. Cheung, "Online Algorithms for Mining Inter-Stream Associations From Large Sensor Networks," In: PAKDD, 2005.

[10] A. Manjhi, V. Shkapenyuk, K. Dhamdhere, and C. Olston, "Finding (Recently) Frequent Items in Distributed Data Streams," In: ICDE, 2005.

[11] A. Arasu and G. S. Manku, "Approximate count and Quantiles over Sliding windows,"In: PODS 2004.

[12] B. Karp and H. T. Kung, "GPSR: greedy perimeter stateless routing for wireless networks," In: MOBICOM, 2000.

[13] S. Madden, "Intel Lab Sensor Data. http://berkeley.intel- research.net/labdata,"  2003.

