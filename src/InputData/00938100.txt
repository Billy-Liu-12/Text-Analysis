Mining Free Itemsets under Constraints

Abstract  Computing frequent itemsets and their frequencies from large boolean matrices (e.g., to derive association rules) has been one of the hot topics in data mining. Levelwise algorithms (e.g., the APRIORI algorithm) have been proved effective for frequent itemset mining from sparse data. How- eve6 in many practical applications, the computation turns to be intractable for the user-given frequency threshold and the lack of focus leads to huge collections of frequent item- sets. The last three years, two promising issues have been investigated: the use of user dejined constraints and closed sets mining, To the best of our knowledge, combining these two frameworks has not been studied yet. In this papes we show that the benejit of these two approaches can be com- bined into levelwise algorithms. An experimental validation related to the discovery of association rules with negations is reported.

1. Introduction  One of the obvious hot topics of data mining research in the past years has been frequent set discovery from large boolean matrices (millions of rows and hundreds of columns). It concerns the discovery of sets of columns that are true within a same row often enough. The user defines the desired frequency threshold and when every frequent itemset has to be found with its frequency (for instance, when association rules [ 13 are to be derived), it gives rise to challenging algorithmic issues due to the exponential size of the search space.

Levelwise algorithms, e.g., the well-know APRIORI al- gorithm [2], have been proved effective for frequent itemset mining when the matrix is sparse and the data is lowly cor- related. A prototypical application domain where it works is the popular basket analysis problem. However, in most of  the other applications we know, the extraction is not always tractable for the user-given frequency thresholds. This hap- pens when the data is dense andlor highly correlated, i.e., when the number of frequent itemsets explodes. Further- more, even if it is tractable, the size of the output can be huge and is often larger than the size of the original data.

The lack of focus leads to huge collections of frequent item- sets from which too many uninteresting patterns or rules will be derived.

During the last three years, two promising issues have been investigated to tackle these problems.

First, one can assume that only a subset of the collection of frequent itemsets is interesting: it leads to constraint- based extraction of the frequent itemsets [18, 13, 10, 71.

These studies have considered various kinds of constraints, including ?syntactic? constraints (e.g., an item must not appear in the itemsets) and constraints related to the so- called objective measures of itemset interestingness (e.g..

the itemsets must be frequent). Using constraints enables to decrease the size of the output while improving user guid- ance. The problem is to ?push? efficiently the constraint checking step during itemset extraction, i.e., not to apply a simple ?generate and test? strategy. Nice results have been discovered concerning the so-called anti-monotone, succinct and monotone constraints [ 13,7], i.e., a wide range of constraints. This framework has been also studied for other kinds of properties like rules [ 101 or correlations [9].

Another promising approach concerns the condensed representation offrequent itemsets [ 113 .  The intuition is that instead of mining all the frequent patterns, one can extract a particular subset of the frequent pattern collection such that it is possible to regenerate from it the whole collection.

Ideally, this subset is much smaller than the original col- lection and can be extracted more efficiently, while allow- ing a fast regeneration of the whole collection of frequent patterns. Several researchers have investigated the use of closed frequent sets as a valuable condensed representation [15,4,6,  17, 191.

1098-8068/01$10.00 0 2001 IEEE  http://1isi.insa-lyon.fr   To the best of our knowledge, combining these two frameworks has not been studied yet.

'In this paper, we show that the benefit of these two ap- proaches can be combined into levelwise algorithms. Doing so, new mining tasks can be considered like frequent itemset mining for low frequency thresholds or the discovery of fre- quent generalized itemsets (sets that combine positive and negative items). An experimental validation related to the discovery of association rules with negations is reported.

In Section 2, we recall the APRIORI algorithm and out- line the effective processing for anti-monotone constraints.

In Section 3, we discuss the use of monotone constraints in order to get effective levelwise algorithms for a rather wide class of constraints. In Section 4, we revisit the CLOSE al- gorithm [ 151 that computes closed frequent sets and we dis- cuss its extension towards the constraint-based discovery of itemsets. Section 5 points out a practical validation of this combined framework and Section 6 is a short conclusion.

ti t2 t 3  t 4  t 5  t e  T =  2. Understanding the effective use of con- straints in APRIORI-like algorithms  ABCD AC AC ABCD BC ABC  2.1. Problem settings and notations  We consider transactional databases. Given a finite set Items of symbols (denoted by capital letters: Items= {A,B,C,.. .}) a transaction t is a subset of Items. A transactional database T is a finite and non empty multi- set T = {t l , tz , .  . . , tn}  of transactions. An itemset is a subset of Items and a k-itemset is an itemset of size k .  A transaction t supports an itemset S iff S t. The support (denoted Support(S)) o f  an itemset S is the multiset of all transactions of T that support S (e.g. Support(@) = T) .

The frequency of an itemset S is defined by F ( S )  = ISupport(S)J/ISupport(0)( where 1.1 denote the cardinal- ity of the multiset (each transaction is counted with its mul- tiplicity). An itemset S is y-frequent in T if F ( S )  2 y.

Figure 1 provides an example of a transactional database and the supports and the frequencies of some itemsets. No- tice that we often use a string notations for sets, e.g., AB for {A, B}.

Itemset A B  AB AC CD  ACD  Figure 1. Supports and frequencies of some itemsets in a transactional database T .

A PR IOR I algorithm 1. Cf := I temsl;  Lo = (0) 2. k := 1 3. while Ci # 8 do 4.

5 .

6.

7.  k : = k + 1  8. output Li  I  Phase 1 - candidate safe pruning c k  := safe-pruning-on(Ci, & - I )  , Phase 2 - frequency constraint - it needs a data scan  Phase 3 - candidate generation for level k+l CiS1 := generateapTiori(&)  L k  := SATC,, ,~ (Ck) I  od ,  Definition 1 (constraint) If7 denotes the set of all trans- actional databases and 21tems the set of all itemsets, a con- straint C is a predicate over 21tems x 7. We say tNat an itemset S E 21tems satisfies a constraint C in the database T E 7 iff C(S ,  T )  = true. When it is clear from the con- text, we write C(S). Given a subset I of Items, we de- fine S A T c ( I )  = { S  E I ,  S satisfies C } .  SATc denotes SATc (21tems).

Let C f T e q ( S )  5 F ( S )  2 y be the constraint that is true iff S is y-frequent in T .

Example 1 Consider the dataset of Figure 1 where Items= {A, B, C, D}. r f  C f r e q  specijies that an itemset must be O.6-frequent, then SATc,,,, = {A, B, C, AC, BC}.

Assume that Cslze(S) z (SI 5 2 and Cmtss(S) z B # S, then S A T C ~ , ~ ~ ~ C , , , , ~ ~  = {A, C,D, AC,AD, CD} while SATC~~~,AC,,,,AC,,,, = {A, Cl AC}.

Definition 2 (constrained itemset mining task) Given a transactional database T and a constraint C,  the con- strained itemset mining task is the computation of the col- lection of the itemsets that verify C (i.e., SATc) together with theirfrequencies. It  provides Rc  = { (S, F( S))  , S E SATc}.

2.2. Sketching the APRIORI algorithm ,  We consider an abstract definition of the APRIORI algo-8 rithm [2] to support our discussion on the effective use of1 constraints. This algorithm performs the constrained item- ' set mining task when C is C f T e q .

In this algorithm, and in the following ones, the fre- , quency of the itemsets are not explicit for the sake of clarity (e.g., Line 5 of the algorithm should be L k  := ' { ( S , F ( S ) ) ,  S E SATc,,,, (Ck)}  since APRIORI outputs the frequency of each frequent itemset).

APRIORI is a levelwise exploration of the lattice of item- sets (w.r.t. set inclusion). During the first pass (when k = l), it computes frequent 1-itemsets and then it gen- erates candidate 2-itemsets from frequent 1 -itemsets. In the second pass (k = 2), it prunes some candidate 2-itemsets (those that contain an infrequent subset), it computes their frequencies and it generates candidate 3-itemsets from fre- quent 2-itemsets, . . .

Ci denotes the k-itemsets that can be frequent. Dur- ing Phase 1, some of these k-itemsets are pruned. safe- pruning-on(Ci, &-I) eliminates the candidates for which a subset of length k is not frequent. This can be justi- fied by the so-called APRIORI trick: if S is not frequent, ev- ery superset of S is not frequent and S can be safely pruned.

During Phase 2, a database scan is performed to compute the frequency of the candidate itemsets. The frequent ones are stored in Ck together with their frequencies.

In Phase 3, frequent k-itemsets are used to compute can- didate k + 1-itemsets. generateapTzoTL (&) provides the candidates by fusion of two elements from L k  that share the same k - 1 first items: generateapTioTz(&)={A U B, where A, B E &, A and B share the k - 1 first items (in lexicographic order)}. This generation procedure is the key of the efficiency of the algorithm: it ensures that large por- tions of the itemset lattice are pruned and that no frequent itemset is missed. r  Example 2 Let us focus on an extract from the execution of APRIORI on the data of Figure I with a frequency threshold y = 0.5. At Iteration 2 (k = 2) Phase 2, one can verify that L2 = {AB, AC, AD, BC, CD}. Then Phase 3 provides the collection of candidates Ci = {ABC, ABD, ACD} (BCD is not generated since BD # 132 and therefore BCD cannot be fre- quent). At Iteration 3 Phase 1 the pruning step provides C3 = {ABC, ACD} since BD # L2 (and therefore ABD cannot be frequent).

It can be proved by induction on k that APRIORI is cor- rect and complete, i.e., U!;; Li = SATctpeq.

2.3. Effective use of anti-monotone constraints  It is well-known that the completeness of APRIORI (i.e., it does not prune any frequent itemset) relies on the anti- monotonicity of C f T e q .

Definition 3 (Anti-monotonicity) An anti-monotone con- straint is a constraint C such that for all itemsets s, s': (5'' E S A S satisfies C )  + S' satisfies C.

Notice that a disjunction or a conjunction of monotone constraints is an anti-monotone constraint.

anti-   Example3 C f T e q ,  C(S) z A # S, S 5 {A,B,C} and S f l  {A,B,C} = 0 are examples of anti-monotone con- straints. Many other anti-monotone constraints are pre- sented in [13].

Let Cam be an anti-monotone constraint eventually in- cluding C f T e q  (i.e., Cam could contain Cfreq or not): if S does not satisfy Cam,  every superset of S does not sat-' isfy Cam. Therefore, if Step 5 of the APRIORI algo- rithm is replaced by L k  := SATc,,(Ci), it is still cor- rect and complete. It means that APRIORI can be used to mine constrained itemsets when the given constraint is anti- monotone.

3. Testing Monotone Constraints  If the effective use of anti-monotone constraints is easy to understand, it is far more complex in the general case. In' other terms, given an arbitrary constraint C, it is not possi- ble to use it in APRIORI by simply replacing Step 5 with L k  := sATc(Ck). Doing this leads to the loss of the com- pleteness of APRIORI. Indeed, there is two problems: the generation step and the pruning step. The generation step must be complete, i.e., it must not miss any itemset satisfy- ing C, and also the pruning step (Phase 1) must be correct, i.e., it must not prune an itemset that verify the constraint.

Example4 Assume the constraint is C(S) 3 C E S. The itemset ABC should be generated by generateapTzoTz from AB and AC but since C(AB) = false, ABC is not generated whereas C(ABC) = true.

If the constraint is C(S)  E A E S. The itemset ABC is then correctly generated by generateapTzoTz from AB and AC but since C(BC) = false, ABC is incorrectly pruned whereas C(ABC) = true.

To overcome these problems, we propose a generation procedure and a pruning procedure which allow to push conjunctions of anti-monotone and monotone constraints, i.e., when C can be written as Cam A C,. A monotone con- straint C, is the negation of an anti-monotone constraint and it motivates the notation for C,. The main prop- erty of a monotone constraint is: S 2 I t e m s ,  C,(S) is true 3 VS' 3 S ,  C,(S') is true.

Example 5 Continuing our running example, .

{A,B,c,D} c S and S n {A,B,c} # 0 are monotone constraints. Assuming that items in S are correlated is monotone too [9].

Generation procedure The next theorem gives a new complete generation procedure -when the constraint is the conjunction of a monotone and an anti-monotone con- straint. We use the concept of-negative border [12]. If Cam    denotes an anti-monotone constraint, adzam is the collec- tion of the minimal-(w.r.t. the set inclusion) itemsets that do not satisfy Cam.

Let us now consider two generating procedures, generate,(&) = {A U-B, where A E Ck and is-a 1-itemset} and generate,(&) = {A U B,  where A, B L k } .  Notice that a naive algorithm that computes generatez will produce many duplicates (see [SI).

Our new generation procedure is denoted generate, and is defined by the next theorem.

Theorem 1 Assume C = Cam A l C b m  and ms = MaxsEad-,  (SI.

Ifgenerate, is dejined by : generate,(&) = 13dFAm n Items1 and, for  k 2 1, i f k  < ms, generate,(&) = generatel(&)U  i f k  = ms, generate,(&) = generate,(&); i f k  > ms, generate,(&) = generate,(&); then this candidate generation procedure is complete and ensures that every candidate itemset veri,fies -CL,.

The fact that every candidate itemset verify C, = iCh, makes useless any verification of this constraint after the candidate generation step.

.

C a m  (Bd; am f~ I t e m s k + l ) ;  Safe pruning procedure Let us now introduce a correct and complete pruning algorithm.

Pruning: algorithm prune, for all S E C:+, and for all S? C S such that IS?( = k  do if S? Ck and C,(S?) = true then delete S from Ci+l od  Theorem 2 The pruning algorithm prune, is correct and complete.

This algorithm is correct because it does not prune any itemset that verify C = Cam A C,. Its completeness means that if an itemset is not pruned then every proper subset ofJhat itemset verify Cam. Intuitively, it is not possible to prune more itemsets without affecting the completeness.

Generic algorithm We can now give a generic algorithm for a constraint C = C a m , A  C, = Cam A 4 ! h m  using the structure of APRIORI and our procedures generate, and pruning,.

generic algorithm 1. Cf :=Bd;, n Items1 ; Lo = (0) 2. k := 1 3. while C: # 0 do 4.

a m  Phase 1 - candidate safe pruning ck := pruning,(Ci, Lk-1)  5 .

6.

7. k : = k + 1  8. output Li  Phase 2 anti-monotone constraint checking 13k := SATcam (Ck) Phase 3 - candidate generation for level k+l Ci+l := generate,(&)  od  Note that it is not necessary to check C, during Phase , 2  since Theorem 1 ensures that every generated itemset verifies it.

Related work Our generic algorithm is inspired by sev- eral algorithms [18, 8, 131 and can be considered as a gen- eralization of them. Conjunctions of monotone and anti- monotone constraints encompass every kind of constraints that have been ?pushed? inside a levelwise algorithm (an- other kind of interesting constraint, the convertible con- straints [ 161, can be pushed in depth-first exploration algo- rithms). The framework of succinct constraints introduced in [13] allows to find an effective generation procedure (i.e., an effective computation of the negative border adzLm of Theorem 1).

4. Revisiting the CLOSE Algorithm  It is now interesting to revisit the algorithms CLOSE [15], Charm [19] and MIN-EX [4]. These algorithms com- pute frequent closed itemsets, i.e., condensed representa- tions of frequent itemsets. They allow tractable frequent itemset extractions from dense and highly-correlated data, i.e., tractable extractions for thresholds on which APRIORI is clearly intractable.

4.1. How CLOSE algorithm has been defined so far  The APRIORI algorithm explores the itemset lattice to find all the frequent itemsets. However, the number of fre- quent itemsets can be exponential in the size of Items. If the size of Items is n, the size of the itemset lattice is 2* and many of these itemsets can be frequent for the given frequency threshold. This is the case in highly-correlated data like for instance census data.

The CLOSE algorithm (and related algorithms) operates on a different lattice: the closed itemset lattice.

Definition 4 (closed itemset lattice) The closure of an itemset S (denoted by closure(S)) is the maximal (for set inclusion) superset of S which has the same support as S. A closed itemset is- an itemset that is equal to its closure.

The set of closed itemset is a lattice called the closed itemset lattice.

In CLOSE, the exploration of this lattice is done in a lev- AB c losu re (B) .  Therefore ChTe,(AB) is true. If  {gC, AC, BC, DAC, ABC} where the notation ABC means that CL,,, (AB) is true and that closure(AB) = ABC.

elwise manner like APRIORI.

gorithms comes from the fact that this lattice is generally several order of magnitude smaller than the itemset lattice.

These algorithms output the set of frequent closed item- sets. Frequent closed itemsets are interesting for several rea- sons:  The efficiency of these al- the frequency threshold is y = 1/2, S A T C ~ , ~ ~ ~ C ; ~ ~ ~  _- _-  Notice that when the closure of an itemset X is a proper superset of X ,  say Y, it means that an association rule X =+     4.2.

they are far less numerous than frequent itemsets (and therefore faster to compute, easier to store and manip- ulate),  if necessary, it is possible to generate efficiently all fre- quent itemsets (and their frequencies) from the closed ones,  it is possible to derive (non redundant) association rules directly from closed frequent itemsets without generating all frequent non-closed ones (see, e.g., r19,141).

A new constraint  We show how to consider the CLOSE algorithm as an exploration of the classical itemset lattice with a new con- straint e ~ ~ ~ ~ .  Then in Section 4.3, we will be able to use this constraint in our generic algorithm together with other constraints and therefore achieve constrained free-set min- ing. We first define a constraint C;,,, .

Definition 5 (A constraint for CLOSE) C b T e e ( S )  E S? C S + S g c l o s u r e ( S ? ) .

The itemsets which verify this constraint are exactly the O-free sets introduced in 161 and it motivates the chosen name of the constraint.

Definition 6 (Free itemsets) Free itemsets are itemsets that are not included in any closure of their proper sub-set.

Equivalently, free itemsets are itemsets that vertfy ehTee.

A fundamental property of free itemesets is that no logi- cal rule (i.e., association rule with a confidence of 1 )  holds between their attributes. In other words, if X is a free item- set, then there does not exist two distinct subset Y and 2 of X with 2 # 0 such that the rule Y +- 2 has a confidence of 1. Also, the frequency of itemsets that are not free can be inferred from the frequency of free itemsets [6].

Example 6 Let us compute closure(AB) on our running example. Items A and B are simultaneously in transac- tions I ,  4 and 6. We notice that item C is the only other item that is also present in these three transactions, thus closure(AB) = ABC. We also have c l o s u r e ( A )  = AC and c l o s u r e ( B )  = BC, so AB c l o s u r e ( A )  and  Yholds with confidence 1. In other terms, it means that the more you have such correlations in your data, the less you have free itemsets and thus the less you have to count for frequencies when looking for frequent itemsets.

Proposition 1 The eh,,, constraint is anti-monotone.

This constraint is another example of an anti-monotone  constraint which needs a database pass to be checked (a database pass is needed to compute the closure of an item- set). Checking this constraint seems expensive if the clo- sure of every subset of S has to be computed. We can use an equivalent constraint CF,,~(,!?) 3 (s? C s A Is?[ = JSJ - 1) + S c l o s u r e ( S ? ) .  The equivalence means that ehTee ( S )  is true iff C F r e e ( S )  is true.

So we only need the closure of every subset of S of size Is( - 1. We are now able to test the constraint on s E &+I: for each S? c S such that IS?I = IS( - 1 we must know c l o s u r e ( S ? ) .  In the CLOSE algorithm, the closure of each candidate itemset of size k and its frequency are computed during the database pass at level k. If the closure of S? is not computed, it means that S? does not verify CfTeq A C F , ~ ~ .

(i.e., an anti-monotone constraint) and therefore S cannot verify CfTep A C F ~ ~ ~ .  Finally, either the closure of S? is known and we can check if S closure(S?) or it is not known and it means that C f r e q ( S )  A C F ~ ~ ~ ( S )  is false. This strategy which uses the anti-monotonicity of eh,,, enables to test the constraint with only a little extra cost during the database pass.

-  4.3. Incorporating constraints  Now, it seems straightforward to search for itemsets which verify a constraint C = C F ~ ~ ~  A C,, A C, using the generic algorithm (since C F ~ ~ ~  is anti-monotone). How- ever, there are two problems. First (due to C,), the closures of some candidates of level IC are not computed thus making the Cpree  checking impossible at level k + 1 (it is not possible to check if an itemset of size k + 1 is included in the closure of one of its proper subset). Second, we loose an important property of CLOSE: SATc,,eeAc,,,-,~, will no longer enables to compute SATc,,Ac,.

Assume we replace eh,,, with ChreeAC, ( S )  (S? C S A C,(S?)) =$ S g c l o s u r e ( S ? )  and C F ~ ~ ~  with:  S c l o s u r e ( S ? ) .  Then we have the following theorem.

C F ~ ~ ~ A C ,  (S) f (S? C S A JS?J = IS] - 1 A C,(S?)) +     Theorem 3 The constraints CFreeAC, and Ckree,,c, are equivalent and anti-monotone. The set SATC,,AC, can be eflciently computed using the same method as in CLOSE using SATcFVeeAcm ,,C,,,,~C,,,, i.e., the output of the generic algorithm with the Constraint c = CFTeeAC,,, A c a m  A Cm.

This theorem means that we can find free-itemsets that verify conjunctions of anti-monotone and monotone con- straints.

4.4. MIN-EX algorithm  The MIN-EX algorithm is an extension of the CLOSE al- gorithm [4]. The concept of closure is extended, providing new possibilities for pruning. However, we must trade this efficiency improvement against precision: the frequency of the frequent itemsets are only known within and bounded error. If 6 is an integer, let c l o s u r e s ( S )  be the maxi- mal (for the set inclusion) superset Y of S such that for every item A E Y - S ,  ISupport(S U {A}) I  is at least (Support(S)I - 6 (with 6 = 0, it is the same closure op- erator than CLOSE i.e., c l o s u r e 0  = closure). Larger values of S leads to more efficiency improvement and larger errors on the frequencies of itemsets. By replacing this new closure operator in the definition of C F ~ ~ ~  we define Cs-Free  and C&-FTeeAC,,, and Theorem 3 is true with these new constraints. The sets that fulfill C ~ - F ~ ~ ~  are the so- called &free sets from [6]. Here again, one can say that the more you have almost logical association rules that hold in your data (rules with confidence close to 1 since only 6 ex- ceptions are allowed), the less you have &free sets. It has been shown that when the frequency of a frequent itemset is approximated by using the frequency of a &free set, the error on frequency can remain very low in practice [6].

,  5. An experimental validation  We consider an experiment motivated by the search for association rules with negations [5] .  Only some results con- cerning the discovery of generalized sets (from with associ- ation rules with negations are derived) are given here.

Notations Let Items+ = {A, B, ...} be a finite set of sym- bols called the positive items and a set Items- of same car- dinality as Items+ whose elements are denotedx, B, . . . and called the negative items. Given a transactional database 7 over Items+, let us define a complemented transactional database over Items = Items+ U Items- as follows: for a given transaction t E 7, we add to t negative items cor- responding to positive items not present in t. Generalized itemsets are subsets of Items and can contain positive and negative items.

Constraints We want to extract frequent itemsets (Cf,,,) that do not involve only negative items (Calpp) .  C a l p p ( S ) is true when S involves at least p positive items. This is obviously a monotone constraint. First experiments have shown that it was interesting to relax such a monotone con- straint (i.e., accepting more sets) in order to give rise to more pruning (see [5] for a complete discussion). Follow- ing that guideline, instead of C a l p p ,  we used the constraint  This constraint enforces gt least p positive attributes (a monotone constraint) e r  gt most l e g a t i v e  attribute (an anti-monotone constraint).

Let us introduce the collection of constraints that have  Calppoamln  = Calpp V C a m l n  c d l  = C f r e p  A C&FreeAC, A C a l l p o a m l n Cd2 = C f r e q  A C6-FreeACm A Cal2poamln c d 3  = cf rep A C6-FreeACm A Cal3poamln  With these constraints, we are able to compare different approaches :  e using only the frequency constraint;  e using the frequency constraint and Calppoamln  con-  e using C f T e g  and Calppoamln in conjunction with  straint with p = 1, 2 ,  3 ( C f l ,  Cfa and C f 3 ) ;  CFreeAC, or Cd-FreeAC, .

Datasets We studied the use of these constraints on two dataset. The first one is a benchmark, the so-called mush- room data. This dataset is a binary matrix of 8124 rows.

Each row contains 23 discrete attributes. Theses attributes are binarized into exclusive attribute-value pairs. This leads to a binary matrix with 119 columns and 23 ?1? per row.

When encoding negative items, it leads to a matrix with 238 columns whose each row contains 119 ?1?.

The second dataset is from the French national institute of statistics (INSEE). In this dataset, each row represents a French town and each column represents a kind of ser- vice (e.g., bank, insurance company, etc), a ?1? in ?bank? column means that there is at least one bank in the town.

In this dataset, there are about 37000 rows and 59 columns with an average number of ?1? per row of 4. When encod- ing negative items, it leads to a matrix with 118 columns whose each row contains 59 ?1?.

The former dataset is quite small but it is known to be tough due to the high correlation between the attributes and     its density (for positive attributes). The latter dataset is larger but it is sparse (4 ?1? per row on average for positive attributes) and less correlated. These two different datasets let us compare our approach on different types of datasets.

Indeed the results show a great difference between these two experiments.

Experiments The experiments were conducted on a 500 MHz Pentium I11 with 768 MB of memory. The value of the frequency threshold (y) is changed over experiments in order to observe the trend. Logarithmically scaled axes are used. The value of the 6 parameter in the Cd-FTee con- straint is set to 200 for the mushroom database and to 100 for the INSEE database (in this latter database there was only a slight difference in execution time between 6 = 100 and 6 = 200 but 6 = 100 gives more accurate results as explained in Section 4.4).

Time (sec.) vs. Frequency threshold  0.2 03 0.4 0 5 0.6 0 7 0.8 0.9 1  Cdl - Cd3 * Cf2 --t-- Cd2 * - Cfl 8 Cf3  Figure 2. Mining generalized sets from mush- room dataset.

Figure 2 shows the results of the experiments on the mushroom dataset with the constraints cfl, Cf2, C f 3 ,  C d l , c d 2  and C d 3 .  The extractions using the other constraints (Cfreq, C1, C 2  and C 3 )  were intractable even at high fre- quency threshold (95%) and with the strongest requirement on the number of positive items ( C 3 ) .  On this dataset the use of C ~ - - F ~ ~ ~ ~ C ,  as opposed to C ~ - - F ~ ~ ~ A C ,  clearly im- proves the results. With C f 3 ,  a frequency threshold of 65% is reached whereas using C d 3  allows to reach a frequency of 20% within about the same time. Finally, on the mushroom dataset,  CfTes combined with the most favorable case of Calpp still leads to an intractable extraction;  CfTeq combined with Only C ~ - F , . ~ ~  or CFTee does not allow mining at low threshold (even with Cal lp  i.e., c d l  and C j l ,  we only reach 60%).

Therefore, to mine at reasonable frequency thresholds, the conjunction of both techniques (using constraints on item- sets with the Calppoamln family of constraints and 101)lc- ing for 6-free-sets with CFTeeAC,,, or Cd-FreeAC,,,) appears mandatory.

Time (sec.) vs. Frequency threshold 10000 [ m x  J  I 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09  Cd2 - Cf2 c2 --t-- Cd3 . ..+... Cf3 e c 3  --e--  Figure 3. Mining generalized sets from INSEE dataset.

Figure 3 shows the results of the experiments on the IN- SEE dataset. With the constraints CfTeq,  C 1 ,  Cfl and c d l  it is not possible to reach a frequency threshold less than 34%.

For this frequency threshold, there is only one frequent pos- itive attribute. This means that all the itemsets mined at this threshold are composed of the same positive attribute and several negative ones.

On this dataset, we notice that the Cf, family of con- straint is surprisingly less efficient than the less constrain- ing C, family. We analyzed the output of the algorithm and found that almost no logical rule (association rule with a confidence of 1) holds in this dataset. The optimization of Cf, over C, is based on the presence of these rules.

Even if the use of 6-free-sets (with C d 2  or C d 3 )  does not allow to mine at significantly lower thresholds, however, it- speeds up the extraction by an order of magnitude with re- spect to C 2  or C 3  at lower frequency thresholds. Finally, with this dataset too the approach turns to be valuable.

6. Conclusion  We study itemset mining under constraints within level- wise algorithms. Several interesting results have been al- ready published the last three years, e.g., about the effective use of anti-monotone constraints or the interest of mono- tone constraints. The generic algorithm we give in this pa- per is a simple generalization of several related algorithms     and enable to emphasize the potential of optimization when considering conjunctions of anti-monotone and monotone constraints. Furthermore, w e  provide new results concern- ing the computation of free sets under constraints. We dis- cussed under which conditions it was possible to  extend an algorithm like CLOSE for an effective use of constraints.

An  experimental validation has confirmed the added-value of this approach.

A recent work uses a different approach and proposes to mine frequent itemsets without candidate generation [17]. Integrating this new algorithm within our study seems promising. Furthermore, frequent sets discovery, and more generally data mining, is not limited to independent min- ing tasks (or queries). Knowledge discovery in databases is an iterative process and there are still lots of work to  d o  to optimize sequences of queries. There is a major trade-off between fully optimizing each individual query and finding a strategy that makes use of previous mined patterns [8, 31.

This strategy may be  less effective for the first queries but may win for long sequences of related queries, i.e., the way people actually proceed.

Acknowledgement T h e  authors thank Artur Bykowski for his contribution to the experimental validation.

