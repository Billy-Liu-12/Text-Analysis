An Improved MapReduce Algorithm for Mining

Abstract?Mining closed frequent itemsets is a key objective in the field of data mining due to its wide range of applications.

Given a database of transactions, the task is to find closed subsets which appear frequently in different transactions. This subject has been studied thoroughly, and many efficient algorithms had been presented, however, most of them were designed for a non- distributed setting. The exponential growth of data in current times forces storing it in a distributed setting, meaning that most algorithms no longer apply. MapReduce is an acclaimed programming paradigm for processing large-scale, distributed data. In this paper we present an efficient algorithm for mining closed frequent itemsets using the MapReduce paradigm. In addition to its novelty of running in a distributed setting, it also makes the duplication elimination step - a common step to all existing algorithms - redundant.



I. INTRODUCTION  Mining of frequent itemsets for association rules has been  studied thoroughly in centralized static datasets [1] and data  streams [2] settings. A major branch in this research field  is mining closed frequent itemsets instead of frequent item-  sets for discovering non-redundant association rules. A set  of closed frequent itemsets is proven to be a complete yet  compact representation of the set of all frequent itemsets [3].

Mining closed frequent itemsets instead of frequent item-  sets saves computation time, memory usage and produces  a compacted output. Many algorithms like Closet, Closet+,  CHARM and FP-Close [1] have been presented for mining  closed frequent itemsets in centralized datasets.

Mining closed frequent itemsets in big, distributed data is  more challenging than mining centralized data in the follow-  ing aspects: (1) The distributed settings is a shared-nothing  environment (one can, of course, share data, however it is  very expensive in terms of communication), meaning that  assumptions like shared memory and shared storage, that lie  at the base of most algorithms, no longer apply. (2) Data  transfer is more expensive than data processing, meaning that  performance measurements change. (3) The data is huge, and  cannot reside on a single node.

MT-Closed[4] and D-Closed [5] are two parallel algorithms  for mining closed frequent itemsets, however both suffer from  a few drawbacks (see section II) and as will be shown - our  scheme overcomes these drawbacks.

MapReduce. MapReduce [6] is a programming paradigm  for parallel processing of large-scale, distributed data using  a computer cluster. This paradigm was developed to answer  the rising need for big data processing due to the exponential  growth in stored digital data. The idea that lies at the core of  the model is to use many low-priced, commodity hardware,  rather than few high-end, high-priced computers and storage  systems. The paradigm is designed in a way that relieves the  programmer of the tedious job of synchronizing threads and  handling processes on nodes: the programmer needs only to  implement two functions: map and reduce, and the framework  takes care of all the rest. The most popular implementation of  the MapReduce model is Hadoop [7], developed by Yahoo!

Labs and now maintained by Apache.

Our Contribution. In this paper, we present a novel  algorithm for mining closed frequent itemsets in big, dis-  tributed data settings, using the MapReduce paradigm. Using  MapReduce makes our algorithm very pragmatic and relatively  easy to implement, maintain and execute. In addition, our  algorithm does not require a duplication elimination step,  which is common to most known algorithms (it makes both  the mapper and reducer more complicated, but it gives better  performance).



II. RELATED WORK  The first algorithm for mining closed frequent itemsets,  A-Close, was introduced in [3]. It presented the concept of  generator - a set of items that generates a single closed  frequent itemset. A-Close implements an iterative generation-  and-test method for finding closed frequent itemsets. On each  iteration generators are tested for frequency, and non-frequent  generators are removed. An important step is duplication elim-  ination: generators that create an already existing itemset are  also removed. The surviving generators are used to generate  the next candidate generators. A-Close was not designed to  work in a distributed settings  A. State of the Art  MT-Closed[4] is a parallel algorithm for mining closed  frequent itemsets. It uses a divide-and-conquer approach on  the input data to reduce the amount of data to be processed at   DOI 10.1109/SWSTE.2016.19    DOI 10.1109/SWSTE.2016.19     each iteration. However, its parallelism feature is limited. MT-  Closed is a multi-threaded algorithm designed for a multi-core  architecture. Though superior to a single-core architecture, a  multi-core architecture is still limited in its number of cores  and its memory is limited is size and must be shared among  the threads. In addition, the input data is not distributed, and  an index-building phase is required.

D-Closed [5] is a shared-nothing environment, distributed  algorithm for mining closed frequent itemsets. It is similar to  MT-Closed in the sense that it recursively explores a sub-tree  of the search space: in each iteration a candidate is generated  by adding items to a previously found closure, and the dataset  is projected by all the candidates. It differs from MT-Closed  in providing a clever method to detect duplicate generators:  it introduces the concepts of pro-order and anti-order, and  proves that among all candidates that produce the same closed  itemset, only one will have no common items with its anti-  order set. However, there are a few drawbacks to D-Closed: (1)  it requires a pre-processing phase that scans the data and builds  an index that needs to be shared among all the nodes, (2) The  set of all possible items needs also to be shared among all the  nodes, and (3) the input data to each recursion call is different,  meaning that iteration-wise optimizations, like caching, cannot  be used.

Wang et al [8] have proposed a parallelized AFOPT-close  algorithm [9] and have implemented it using MapReduce. Like  the previous algorithms, it also works in a divide-and-conquer  way: first a global list of frequent items is built, then a parallel  mining of local closed frequent itemsets is performed, and  finally, non-global closed frequent itemsets are filtered out,  leaving only the global closed frequent itemsets. However, they  still require that final step of checking the globally closed  frequent itemsets which might be very heavy, depending on  the number of local results.

Moens et. Al [10] describe an algorithm for mining frequent  itemsets using MapReduce, however they mention the mining  of closed frequent itemsets as a post-processing step and do  not utilize this in their algorithm which is therefore potentially  less efficient than a closed frequent itemsets algorithm.

B. MapReduce Communication Cost Model  In general, there may be several performance measures for  evaluating the performance of an algorithm in the MapRe-  duce model, such as clock time or sum of all tasks run  time. In this study we will follow the communication-cost  model proposed by Afrati and Ullman in [11] to measure the  efficiency of an algorithm in the MapReduce model: A task is  a single map or reduce process, executed by a single computer  in the network. The communication cost of a task is the size of  the input to this task. Note that the initial input to a map-task,  meaning the input that resides in file, is also counted as input.

Also note that we do not distinct map-tasks from reduce-tasks  for this matter. The total communication cost is the sum of  the communications costs of all the tasks in the MapReduce  job.

TID Transaction  t1 {a, c, d, e, f} t2 {a, b, e} t3 {c, e, f} t4 {a, c, d, f} t5 {c, e, f}  TABLE I EXAMPLE DATABASE. TID IS THE TRANSACTION IDENTIFIER.



III. PROBLEM DEFINITION  Let I = {i1, i2, ..., im} be a set of items with some lexicographic order. An itemset x is a set of items such that x ? I. A transactional database D = {t1, t2, ...tn}, is a set of itemsets, each called a transaction. Each transaction in  D is uniquely identified with a transaction identifier (TID), and assumed to be sorted lexicographically. The difference  between a transaction and an itemset is that as itemset is  an arbitrary subset of I while a transaction is a subset of I that exists in D and identified by its id, i. The support of an itemset x in D, denoted supD(x), or simply sup(x) when D is clear from the context, is the number of transactions in D that contain x (sometimes it is the ratio of transactions).

Given a user-defined minimum support denoted minSup, an itemset x is called frequent if sup(x) ? minSup.

Let T ? D be a subset of transactions from D and let x be an itemset. We define the following two functions f and g:  f(T ) = {i ? I|?t ? T , i ? t}  g(x) = {t ? D|?i ? x, i ? t}  Function f returns the intersection of all the transactions in T , and function g returns the set of all the transactions in D that contain x. Notice that g is antitone, meaning that for two itemsets x1 and x2: x1 ? x2 ? g(x1) ? g(x2). It is trivial to see that sup(x) = |g(x)|. The function h = f ? g is called the Galois operator or closure operator.

An itemset x is closed in D iff h(x) = x. It is equivalent to say that an itemset x is closed in D iff no itemset that is a proper superset of x has the same support in D, exists.

Given a database D and a minimum support minSup, the mining closed frequent itemsets problem is finding all frequent  and closed itemsets in D.

A. Example  Let I = {a, b, c, d, e, f}, let minSup = 3 and let D be the transaction database presented in table I. Consider  itemset {c}. It is a subset of transactions t1, t3, t4 and t5, meaning that sup(c) = 4, which is greater than minSup.

However {c, f}, which is a proper superset of {c}, is also a subset of the same transactions. {c} is not a closed itemset since sup({c, f}) = sup({c}). The list of all closed frequent itemsets is: {a}, {c, f}, {e} and {c, e, f}.

We now present an algorithm for mining frequent  closed itemsets in a distributed settings using the MapRe-  duce paradigm.



IV. THE ALGORITHM  A. Overview  Our algorithm is iterative, where each iteration is a MapRe-  duce job. The inputs for iteration i are  1) D, the transaction database and 2) Ci?1 the set of the closed frequent itemsets found in the  previous iteration (C0, the input for the first iteration, is the set containing the empty set).

The output of iteration i is Ci, a set of closed frequent itemsets that have a generator of length i. If Ci 	= ? then another iteration, i+1, is performed. Otherwise the algorithm stops. As mentioned earlier, each iteration is a MapReduce job,  comprised of a map phase and a reduce phase. The map phase,  which is equivalent to the g function, emits sets of items called closure generators (or simply generators). The reduce  phase, which is equivalent to the f function, finds the closure that each generator produces, and decides whether or not it  should be added to Ci. Each set added to Ci is paired with its generator. The generator is needed for the next iteration.

The output of the algorithm, which is the set of all closed  frequent itemsets, is the union of all Cis.

Before the iteration begin, we have discovered that a prepro-  cess phase that finds only the frequent items, greatly improves  performance, even though another MapReduce job is executed,  and this data must be shared among all mapper tasks. This  MapReduce job simply counts support of all items and keeps  only the frequent one.

Pseudo-code of the algorithm is presented in Algorithm 1.

We provide explanations of the important steps in the algo-  rithm.

B. Definitions  To better understand the algorithm, we need some defini-  tions:  Definition 4.1: Let p be an itemset, and let c be a closed itemset such that h(p) = c, then p is called a generator of c.

Note that a closed itemset might have more than one generator:  In the example above, both {c} and {f} are the generators of {c, f}.

Definition 4.2: An execution of a map function on a single  transaction is called a map task.

Definition 4.3: An execution of a reduce function on a  specific key is called a reduce task.

C. Map Phase  A map task in iteration i gets 3 parameters as input: (1) a set of all the closed frequent itemsets (with their generator)  found in the previous iteration, denoted Ci?1 (which is shared among all the mappers in the same iteration), (2) a single  transaction denoted t, and (3) the set of all frequent items in D (again, this set is also shared among all the mappers in the same iteration and in all iterations). (Note that in the  Hadoop implementation the mapper gets a set of transactions  called split and the mapper object calls the map function for  each transaction in its own split only).

For each c ? Ci?1, if c ? t then t holds the potential of finding a new closed frequent itemsets, and we use it to form  a new generator. For each item ? (t \ c) we check if item is frequent. If so, we concat item to the generator of c (denoted c.generator) thus creating g (we denote that added item as g.item), a potential new generator for other closed frequent itemsets. The function emits a message where g is the key and the tuple (t,1) is the value. (The ?1? is later summed up and used to count the support of the itemset).

Notice that g is not only a generator but it is always a minimal generator. Concatenating an item not in its closure  guarantees to reach another minimal generator. More precisely,  it generates all minimal generators that are supersets of g with one additional item and such that t supports it. Since all transactions are taken, every minimal generator with a support  of at least 1 is emitted at some point. A theorem is proved in  Section IV-H.

Pseudo code of the map function is presented in Algo-  rithm 2.

D. Combiner Phase  A combiner is not a part of the MapReduce programming  paradigm but a Hadoop implementation detail that mini-  mizes the data transferred between map and reduce tasks.

Hadoop gives the user the option of providing a combiner  function that is run on the map output, on the same machine  running the mapper, and the output of the combiner function  is the input for the reduce function.

In our implementation we have used a combiner, which is  quite similar to the reducer, but much simpler. The input to  the combiner is a key and a collection of values: the key is  the generator g (which is an itemset) and the collection of values is a collection of tuples, composed of transactions T , all containing g and a number s indicating the support of the tuple.

Since the combiner is ?local? by nature, it has no use of  the minimum support parameter, which must be applied in a  global point of view.

The combiner sums the support of the input tuples, stores it  in the variable sum and then performs an intersection on the tuples, to get t?.

The combiner emits a a message where g is the key and the tuple (t?,sum) is the value.

Pseudo code of the combiner function is presented in  Algorithm 3.

E. Reduce Phase  A reduce task gets as input a key, a collection of values  and the minimum support. The key is the generator g (which is an itemset), the value is a collection (t1, s1), ..., (tn, sn) of n tuples, composed of a transaction ti, all containing g and a number si indicating the support of the tuple. In addition, it gets as a parameter the user-given minimum support, minSup.

At first, the frequency property is checked: sup(g) =?n i=1 si ? minSup. If so then an intersection of t1, ...tn  is performed and a closure, denoted c, is produced. If the     item that was added in the map step is lexicographically  greater than the first item in c \ g, then c is a duplication and can be discarded. Otherwise a new closed frequent itemset is  discovered and is added Ci.

In other words, if the test in line 7 passes, then it is  guaranteed the the same closure c if found (and kept) is another reduce task - the one that will get c from its first minimal generator in the lexicographical order. A theorem is proved in  Section IV-I.

Pseudo code of the reduce function is presented in Algo-  rithm 4.

In line 5 in the algorithm we perform the f function, which is actually an intersection of all the transactions in T . Notice that we do not need to read all of T and store in the RAM: T can be treated as a stream, reading transactions one at a time  and performing the intersaction.

Algorithm 1: Main: Mine Closed Frequent Itemsets  Input: minSup: user-given minimum support D: the database of transaction  Output: all closed frequent itemsets  1 f_items? findFrequentItems(D,minSup) ; 2 C0 ? {?}; 3 i? 0 ; 4 repeat  5 i++ ; 6 Ci ? 7 MapReduceJob(D,minSup,Ci?1, f_items) ; 8 until Ci = ?;  9 return i?  j=1  Cj ;  Algorithm 2: Mapper  Input: Ci?1: The set of closed frequent itemsets with their generators, found in the previous iteration  t: A single transaction from D f_items: The set of all frequent items  Output: Key: potentially new generator  Value: transaction that contains the generator  and its support  1 foreach c ? Ci?1 do 2 if c ? t then 3 t? ? t \ c; 4 foreach item ? t? do 5 if item ? f_items then 6 g ? concat(c.generator,item); 7 emit(?g, (t, 1)?); 8 end  9 end  10 end  11 end  Algorithm 3: Combiner  Input: Key: g, a generator Values: (t1, s1), ..., (tn, sn): a collection of n tuples such that ti is a transaction and si is its support  Output: Key: potentially new generator  Value: transaction that contains the generator,  and its support  1 sum? ?n  i=1 si ; /* Applying the f function on t1, ...tn,  i.e. intersecting t1, ...tn: */ 2 t? ? f(t1, ...tn); 3 emit(?g, (t?, sum)?);  Algorithm 4: Reducer  Input: Key: g, a generator Values: (t1, s1), ..., (tn, sn): a collection of n tuples such that ti is a transaction and si is its support  minSup: The user-given minimum support Output: A closed frequent itemset, if found  1 supp? ?n  i=1 si ; 2 if supp < minSup then 3 return;  4 end  /* Applying the f function on t1, ..., tn , i.e. intersecting t1, ..., tn: */  5 c? f(t1, ..., tn); 6 c.generator ? g; /* Duplication elimination: */  7 if g.item > (c \ g) then 8 return;  9 end  10 emit(c);  F. Run Example  Consider the example database D in Table I with a minimum support of 2 transactions (0.4 in percentage). To simulate a  distributed setting we assume that each transaction ti resides on a different machine in the network (mapper node), denoted  mi.

1st Map Phase. We track node m1. It?s input is the  transaction t1 and since this is the first iteration then Ci?1 = C0 = {?}. For each item in the input transaction we emit a message containing the item as a key and the  transaction as a value. So the messages that m1 emits are the following: ?{a}, {a, c, d, e, f}?, ?{c}, {a, c, d, e, f}?, ?{d}, {a, c, d, e, f}?, ?{e}, {a, c, d, e, f}?, and ?{f}, {a, c, d, e, f}?.

1st Reduce Phase. According to the MapReduce paradigm,  a reducer task is assigned to every key. We follow the reducer  tasks assigned for keys {a}, {c} and {f}, denoted Ra, Rc     Closed Item set Generator Support  {a} {a} 3 {c, f} {c} 4 {e} {e} 4  {a, c, d, f} {a, c} 2 {a, e} {a, e} 2 {c, e, f} {c, e} 3  TABLE II COMPLETE SET OF CLOSED FREQUENT ITEMSETS IN THE EXAMPLE  DATABASE FOR A MINIMUM SUPPORT OF 2 TRANSACTIONS, WITH THEIR GENERATORS AND SUPPORT.

and Rf respectively.

First, consider Ra. According to the MapReduce paradigm, this reduce task receives in addition to the key {a} all the transactions in D that contain that key: t1, t2 and t4. First, we must test for frequency: there are 3 transactions containing  the key. Since minSup = 2 we pass the frequency test and can go on. Next, we intersect all the transactions, producing  the closure {a}. The final check is whether the closure is lexicographically larger than the generator. In our case it is  not (because the generator and closure are equal), so we add  {a} to C1.

Next, consider Rc. This reduce task receives the key {c}, and transactions t1, t3, t4 and t5. Since the number of messages is 4, we pass the frequency test. The intersection  of the transactions is the closure {c, f}. Finally, {c} is lexicographically smaller than {c, f}, so we add {c, f} to C1.

Finally, consider Rf . The transactions that contain the set {f} are t1, t3, t4 and t5. We pass the frequency test, but the intersection is {c, f}, just like in reduce task Rc, so we have a duplicate result. However, {f} is lexicographically greater than {c, f}, so this closure is discarded.

The final set of all closed frequent itemsets found on the first  iteration is: C1 = {{a : a}, {c, f : c}, {e : e}} (the itemset after the semicolon is the generator of this closure).

2nd Map Phase. As before, we follow node m1. This time the set of closed frequent itemsets is not empty, so according  to the algorithm, we iterate over all c ? C1. If the input transaction t contains c, we add to c all the items in t \ c, each at a time, and emit it. So the messages that m1 emits are the following:  ?{a, c}, {a, c, d, e, f}?, ?{a, d}, {a, c, d, e, f}?, ?{a, e}, {a, c, d, e, f}?, ?{a, f}, {a, c, d, e, f}?, ?{c, d}, {a, c, d, e, f}?, ?{c, e}, {a, c, d, e, f}?, ?{c, f}, {a, c, d, e, f}?. ?{e, f}, {a, c, d, e, f}?.

2nd Reduce Phase. Consider reduce task Rac. According to the MapReduce paradigm, this reduce task receives all the  message containing the key {a, c}, which are transactions t1 and t4. Since minSup = 2 we pass the frequency test. Next, we consider the key {a, c} as a generator and intersect all the transactions getting the closure {a, c, d, f}. Final check is whether the added item (c) is lexicographically larger than the  closure minus the generator. In our case it is not, so we add  {a, c, d, f} to the set of closed frequent itemsets.

The full set of closed frequent itemsets is shown in table II.

Next we prove the soundness and completeness of the  algorithm.

G. Soundness  The mapper phase makes sure that the input to the reducer is  a key which is a subset of items p, and a set of all transactions that contain p, denoted T . By definition T = g(p). The reducer first checks that sup(p) ? minSup by checking |T | ? minSup and then performs an intersection of all the transactions in T , which by definition is the result of the function f(T ), and outputs the result. So, by definition, all output is the result of f ?g, which is a closed frequent itemset.

H. Completeness  We need to show that the algorithm outputs all the frequent  closed itemsets. Consider c = i1, ...in a closed frequent itemset (that we are not sure if it was produced). Suppose  that c has no proper subset that is a closed frequent itemset.

Therefore, for all items ij ? c, sup(ij) = sup(c) and g(ij) = g(c). Therefore h(ij) = h(c) = c. Since h(ij) = c then ij is a generator of c, and the algorithm will output c at the first iteration.

Suppose that c has one or more proper subsets, each is a closed frequent itemset. We examine the largest one and  denote it l. We also denote its generator gl, meaning that g(l) = g(gl). Since g is antitone and since gl ? c then g(gl) ? g(c). What we show next is that if we add one of the items not in l to gl we will generate c. Consider an item i, such that i ? c \ l. Let g?l = gl ? {i}. Therefore, g(g?l) = g(gl)? g(i) = g(l)? g(i). Assume that g(g  ?  l) ? g(c).

It implies that l? is a generator of a closed itemset h(g?l) that is a proper subset of c in contradiction to l being the largest closed subset of c, therefore g(g?l) = g(c), meaning that c will be found by the mapper by adding an item to gl (see lines 3-4 in algorithm 2) ?

I. Duplication Elimination  As we saw in the run example in Section IV-F, a closed  itemset can have more than a one generator, meaning that two  different reduce tasks can produce the same closed itemset.

Furthermore, these two reduce tasks can be in two different  iterations. We have to identify duplicate closed itemsets and  eliminate them. The naive way to eliminate duplications is  by submitting another MapReduce job that sends all identical  closed itemsets to the same reducer. However, this means we  need another MapReduce job for that, which greatly damages  performance. Line 7 in algorithm 4 takes care of that without  the need for another MapReduce round. In the run example we  have already seen how it works when the duplication happens  on the same round.

What we would like to show is that the duplication elimi-  nation step does not "lose" any closed itemset.

We now explain the method.

Consider itemset c = {i1, i2, ..., in} a closed, frequent itemset, and its generator g = {ig1 , ig2 , ..., igm},m < n, such that h(g) = c. According to our algorithm, g was created by     adding an item to a previously found closed itemset. We denote  that itemset f , and the added item igj such that g = f ?{igj}.

Suppose that igj > (c \ g). In the context of the algorithm it means that c would be eliminated. We should show that c can be produced from a different generator. Consider ik the smallest item in (c \ g). Since ik ? c it is frequent, and since ik /? g then surely ik /? f , meaning that the algorithm will add it to f , creating g? = f ? {ik}. It is possible that h(g  ?) ? c, however if we keep growing g? with the smallest items, we will eventually get c.



V. EXPERIMENTS  We have performed several experiments in order to verify  the efficiency of our algorithm and to compare it with other  renowned algorithms.

A. Data  We tested our algorithm on both real and synthetic datasets.

The real dataset was downloaded from the FIMI reposi-  tory [12] and is called ?webdocs?. It contains close to 1.7  million transactions (each transaction is a web document) with  5.3 million distinct items (each item is a word). The maximal  length of a transaction is about 71 thousand items. The size  of the dataset is 1.4 Gigabytes. A detailed description of the  ?webdocs? dataset that also includes various statistics can be  seen in [13].

The synthetic dataset was generated using the IBM data  generator [14]. We have generated six million transactions with  an average of ten items per transaction, of a total of 100k  items. The total size of the input data is 600mb.

B. Configuration  We run all the experiments on the Amazon Elastic MapRe-  duce [15] infrastructure: each run was executed on 16 ma-  chines, each is an SSD-based instance storage for fast I/O  performance with a quad core CPU and 15 GiB of memory.

All machines run Hadoop version 2.6.0 with Java 8.

We used communication-cost (see Section II-B) as the main  measurement for comparing the performance of the different  algorithms. the input records to each map task and reduce  task were simply counted and summed up and the end of  the execution. This count is performed on each machine in a  distributively manner. The implementation of Hadoop provides  an internal input records counter that makes the counting  and summing task extremely easy. Communication-cost is  an infrastructure-free measurement, meaning that it is not  effected by weaker/stronger hardware or temporary network  overloads, making it our measurement of choice. However we  also measured the time of execution: we run each experiment  3 times and give the average time.

We have implemented the following algorithms: (i) a naive adaptation of Closet to MapReduce , (ii) the AFOPT-close adaptation to MapReduce, and (iii) our proposed algorithm.

All algorithms were implemented in Java 8, taking advantage  of its new lambda expressions support.

?? ???  ????  ??	?  ???????? ??????? ?? ???????? ???????? ?? ???    ????????????  ? ?   ?? ?? ?? ?? ?? ? ?? ??? ?? ? ??? ?? ?? ?  ?		?? 	?		? 	?		?? 	?		?   ?  ?   ??   ?   ??   ?   ??   ?   ??????? !"# ????"? ?$%&'  Fig. 1. Comparing our proposed algorithm with a MapReduce adaptations of Closet and AFOPT on the synthetic data. The lines represent the communica- tion cost of the three algorithms for each minimum support. The bars present the number of closed frequent itemsets found for each minimum support.

C. The Experiments  We ran the algorithms on the two datasets with different  minimum supports, and measured the communication cost and  execution time for each run.

The first batch of runs was conducted on the synthetic  dataset. The results can be seen in figure 1: The lines represent  the communication cost of the three algorithms for each  minimum support. The bars present the number of closed  frequent itemsets found for each minimum support. As can  be seen, our algorithm outperforms the others in terms of  communication cost in all the minimum supports.

In the second batch of runs we run the implemented  algorithms on the real dataset with four different minimum  supports, and measured the communication cost and execution  time for each run.

The results can be seen in figures 2 and 3. The lines  represents the different execution times for the different mini-  mum supports. As can be seen, our algorithm outperforms the  existing algorithms.



VI. CONCLUSION  We have presented a new, distributed and parallel algo-  rithm for mining closed frequent itemsets using the popular  MapReduce programming paradigm. Besides its novelty, using  MapReduce makes this algorithm very easy to implement,  relieving the programmer from the wearing work of handling  concurrency, synchronization and nodes management that are  part of a distributed environment, and focus on the algorithm  itself.

In addition, as you recall from section IV-A, one of the  input parameters to each iteration of the algorithm is D, the database. This parameter is the dominant one in terms of size.

??? ??  ?	??  ???	?  ???????? ??????? ?? ???????? ???????	??    ????????????  ? ?   ?? ?? ?? ?? ?? ? ?? ??? ?? ? ??? ?? ?? ?  ?? 	?? 	?? 	??   ?   ??   ?   ??   ?   ??   ?     ??   ??????? !"# ????"? ?$%&'  Fig. 2. Comparing our proposed algorithm with a MapReduce adaptations of Closet and AFOPT on the real data. The lines represent the communication cost of the three algorithms for each minimum support. The bars present the number of closed frequent itemsets found for each minimum support.

????????????? ???????? ???????	??    ????????????  ( ?? ?? ?? ?' ? "? ??? ? ?? ?? "? ?  ?? 	?? 	?? 	??   ?  ? ??  ? ??  ? ??  ? ?? ???????  !"# ????"? ?$%&'  Fig. 3. Comparing the execution time of our proposed algorithm with a MapReduce adaptations of Closet and AFOPT on the real data.

Since this input is static (does not change from one iteration  to the next) we might use some caching mechanism, further  increasing the efficiency.

