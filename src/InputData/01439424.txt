

LEFRA: LEARNING FROM ASSOCIATIONS  Ray K. Hashemi Department o f  Computer Science  Armstrong Atlantic State University Savannah, CA 31419  hashemra~mail.armstrong.rdu  Louis LeBlanc Campbell School o f  Business  Berry College Mount Berry, CA 30149  Ileblanc~!campbell.herry.edu  Burt J. Westgeest Department of Computer Science  Armstrong Atlantic State University Savannah, CA 31419  Alexander A, Tyler School o f  Rledicine  University College Cork Cork. Ireland  ABSI?RACI In data mining, a Multi-lcvcl Association Analysis (MAA) produccs a sct of  association rulcs.

Thcsc rulcs mainly idcntify thosc valucs of inultiplc attributcs that arc associated to cach otlicr.

In this papcr, WC introdticc a ncw learning paradigiii bascd on associatioil rulcs callcd ?tcarning from Association (LEFRA)? which is  uscd as a part o f  8 prcdictivc system to prcrlicl thc cffcct of a numbcr o f  carcinogcns on livcr. Thc validity of tlic proposcd lcaming paradigni is cstablishcd by comparing i t s  pcrfomiancc with thc pcrfomiancc of logistic rcgrcssion wliich has bccn appticd on thc samc datasct. .

KEYWORDS: Dat:i Mining. Association Analysis. Learning fruin Assucialion. Predictive Systcols.

I .  INTRODUC?I?ION Thc association rulc of P I ( X ,  vli )  A P 2 ( X ,  Y?,) 3 f 3 ( X ,  V A ~ )  which i s  discovcrcd by a Multi-lcvcl Association Analysis ( M A A )  from a givcn datascl is cxprcsscd using prcdicatcs. 111 this rulc, thrcc typcs ofprcdicatcs ( P I ,  P2. and P.7) arc involved that rcprcscnt thrcc pairs attributc-valnc of ( P / ,  vli). (PZ, v?,), and (P3,  v l t )  for thc thrcc attributcs of( / ? I .  f2, and P 3 )  in thc dalasct. Thc variable X rcprcscnts all thc rccords (objects) for which thc valucs for attributcs Pl.  PZ, and 1?3 arc vir ,  va, and vlk, rcspcctivcly. Tlic abovc association ntlc may bc intcrprctcd as fallows: Somc ofthosc objccts ici tlic datasct with PI = vli  and 1?2 = vzi, also have f 3  =  VI^. Sincc thc givcii association rulc is not truc for cvcry rccord i n  tlic givcii datasct. two paramctcrs of ?support?, s, and ?conlidcncc?, k, arc assigncd to cach association nilc.

Lct A 3 B bc an association rulc, whcrc A and I3 arc two scts ofattributc-valuc pairs. Tlic suppori for tlic ni lc is q u a l  to frcq(A U H)/ Idatasctl and thc confidcncc i s  calculaicd bascd on frcq(A U B )  / Frcq(A) in tlic datasct. Thc Frcq(.) i s  thc numbcr ol?objccts i n  Ihc dn~nsct iii which thc atfributc-valuc pairs of(.) arc obscrvcd.

Mining multiple lcvcl associations is donc using scvcral approaches. Thrcc wcll ktiown approachcs arc: a modificd version of Apriori Algorithm [I], N-dimcnsional (N-D) data cubes [2], and Formal Conccpt Analysis 13, 41. In this papcr wc usc a moditicd version of Apriori Algorithm for mining of data. A bricf cxplanation ofthis approach i s  prcscntcd below.

An itcnisct is rcfcrrcd to as a sct of values ( V I ,  v2, . . ., vn: such that cach valuc belong to a difl?crcnt attribute i n  a givcn datasct. The Apriori algorithm is an itcrativc algorithm that in its i-th iteration gcncratcs an itcmsct with cardinality cqunl to i. Thc itcinscls in thc i-111 itcntion is gcncratcd by joining tlic itcmscts gcricratcd in (i-l)th itcration. If an itcmsct in the i-th iteration has the following two conditions, thcn it  will survivc; Othcnvisc i t  will bc dismisscd: (a) The support valuc of the itctnsct is grcatcr than or cqual to a threshold support valuc and (b) all thc passiblc subsets of thc itcinsct arc survived i n  rhc previous iterations. The Apriori algorithiu stops when lion of the itcntscts gcncmtcd in the last itcration satislics the above conditions.

Lct A E P(I,), whcrc Ij is onc of the itcinscts gcncratcd by a priori algorithm and P(lj) is the power sct of thc itcnisct Ij. Thc association rulc of A 3 I3 is obtaincd from A, whcrc B = I, - A.

For the details ofassociation analysis consult 15. 6, 7, 81.

association rulcs for thc purposc of prcdiction. The objectives of this rcscarch activity arc to: ( I ) obtain the association rulcs for a givcn dahsct, (2) obtain prcdiction rulcs out of thc association rulcs, (3) Tcst thc prcdiction rulcs, and (4) validate thc pcrformancc of the proposcd Icaming paradigm.

Thc rcrnaindcr ofthc papcr has the rollowing structure: The methodology is introduccd in Section 2. Thc cxpcrimciital design and rcsults arc thc subjects of  Section 3. Thc conclusion and futurc rcscarch arc prcscntcd in Scction 4.

The goal o f  this rcscarch activity is to prcscnt a ncw learning paradigm that uses the  2. METHODOLOGY Thc goal of this rcscarch activity is lo prcscnt a ncw lcaming paradigm that uscs tlic association rulcs fbr ihc purposc of prcdiction. As a rcsult, the data sct that lends itsclf to a prcdiction process has a spccial type of internal structure. Each record in such data scts is composcd o f  two parts: a group 01? indcpcndcnt variablca (or conditions) and a dcpcrtdcnt variablc (a dccision). Thc objcctivc is to usc conditions values to prcdict the decision valuc. To do so, llircc steps of ?prcproccssing?, ?lcaming?, and %sting? t3kC placc.

2.1 Preprocessing Wc try to answer thc following qucstions by prcproccssing thc data: Do we nccd all thc conditions in thc training sct, for the purposc of machine Icaming, or a subsct ofconditions is adcquatc? If  thcrc is no nccd for all thc conditions, thcn how is a sobsct of conditions (called a wducr) idcntificd? Rotli questions may be answcrcd using thc Rough scts approach [9, IO,  I 11.

To do so, wc introducc tlic following algorithm  Algorithm REDUCTION Girrnc A datasct, F, from which the decision (dependent variablc) has bccn rcmovcd.

Objc.c/iie: tlctcrminc a rcduct of thc datasct.

Step I .  Kcpcat Stcp I through 4 while /FI changcs.

Stcp 2. Rcpcat stcp 2 and stcp 3 for all the rccords in F.

Stcp 3. Kcinovc a condition from thc daiasct. Ifthc removal of the condition docs not introduce  any new duplicatiori of  rccords, thcn mark thc rcrnovcd condition as a redzrrrdwonr condition in the datasct.

datasct (this action turns F into a new datasct.) Step 4. Randomly sclcct onc ol?thc markcd conditions and pcrmancntly rcmovc it from thc  Stcp 5 .  Thc remaining conditions makc tlic rcduct ol?thc dalascr.

Stcp 6. End.

2.2 Learning Wc introducc a sct ofalgorithnis shortly that Icams from rccords o r a  training sct arid gcncralcs prcdiction rulcs from thc association rulcs. Uccausc of that the lcaniing paradigm is namcd LEFRA - - L r . o , ? i i / r b . r l i n , - ~ . s . ~ ~ ) ~ ~ i ~ ~ / j ~ ~ / i ,  Thc prcdiction riilcs arc cxprcsscd in ~J, , , , i / ien. . ,  forniat.

A prcdiction rulc i s  an association rulc that has goiic through scvcral laycrs o f  pruning and i ts dcsision is corrclatcd to its antcccdciits. As a rcsult, cadi prcdiction nilc has a: (i) support valuc grcatcr than or equal to a thrcshold suppori valuc of s, (ii) confidcncc value grcaicr t han  or cqiial to a dcsircd confidcncc valuc o f  c, (iii) dominant factor o f  r, whcrc 0 < r 5 I, and ( jv )  correlation valuc. Thc first two conccpts haw bccn discusscd previously and thc last two conccpts arc introduccd through thc following sct ofalgorithrris.

Algorillrm LEARNING- FROhf-ASSOCL4 TlONS Giian: A training scf i n  which each rccord is madc d N -  I dcpcndcnt variablcs (conditions) and  onc dcpcndcnt variable (dccision). Thc total nutnbcr of variablcs is N. Data for c a d i variablc i s  in catcgorical format. Thc numbcr ofcalcgorics ror variable V, is iii. A dcsircd support valuc o f  s and a dcsircd contidcncc valuc of c.

Objwtii-e: Gcncrating prcdiction rulcs Icamcd from the givcn training set.

Stcp I ,  Prcfix cvcr)' category valucs for variablc Vi with "Vi" (for i = I to n + 1 )~ Stcp 2. Crcatc N-0 data cubc for the training sct. Considering sand c, idciltify all t l lc qiialificd  Stcp 3. lnvokc Prune {Q)  Stcp 4. lnvokc Association-Rules (P, c)  Stcp 5 .  A dcsircd association rulc of, say, (Vi?. A V I  I, AVJ. a V, I)  dclivcrcd iii Skp  4, scrvcs  Stcp 6. End.

associatcs (Q.) /* A sct o f  pruiicd associations ( P )  is dclivcrcd  by tlic Prune Algoritlini*/ /* A set ofdcsircd association rulcs is dclivcrcd  by this Algorithm*/  as a prcdictiun rule of-fonii: If V, = 2 A V, = I A VI = 2, thcn V, = I.

AIgoriflrm PRUNE (Q) GI't'etr A set ofqunlificd associations, Q = Isl, . . . , q,"I crcatcd using N - 0  data cubc for support  valuc of s. Two qualificd msociations of q; and qj with frcqucncics OTT, and tj iii which d E q, and d' E ql. (Thc valucs d and d' bclong to tlicdcpcndcrit variable.)  Ohjwriiu: Ccncrating a sct o f  pruncd associations (1').

Stcp 1. 13clctc all thc associations from Q ill which nonc of thc valucs of tlic dcpcndcnt variablc  Stcp 2- Dclctc al l  the associations that arc cnlircly niadc orvalucs of ihc dcpcndcnt variable.

Stcp 3- Assign tlic dominant bctor of I to cvcry remaining associations.

cxist.

Stcp3- I f (q i -  ( d j ) -  (gi-(d'}), thcI ido  If fl  I f  fl> fi tlicii rcinovc qi from Q and givc 1hc dominant lhctor of fi/ ( f i  + fi) to [hc association q,.

association ql.

If f l  = f. thcn reniovc both q, and q, from S.

f: thcn rcniovc q, from Q and givc thc dominant valuc o f  I",/ (fi + f,) to tlic  Step 4- If (d = d') A (9, c qj) A lqil =I q I + I ,  thcn rcniovc q, froin 0.

Step 5-  If' (d = d') A (ql c qi) A I q I -1 q; 1 + I ,  then rcmovc q, froin Q.

Stcp 6- End.

55 1    Algorithm ASSOCIATION-RULES (P, cj Giiwi: A sct ofpruiicd associations, P = (pi, . . . , dclivcrcd by thc Prunc algorithtn. (In a  prtincd association, pi, only oiic valuc of thc dcpciidcnt variablc cxist. pi has also a doininant lactor.) A dcsircd contidcncc valuc ofc .

Objw/ii,e: Gcncrating thc dcsircd association rulcs.

Stcp I -  Rcpcat stcps 2 4  for i = I to k Stcp 2- Gcncratc oiic association rulc out of pt for which only the valuc o f  the dcpcndcnt variablc,  i i ,  p,, appcars i n  thc right sidc ofthc implication symbol. Assign thc dominant factor of pl to tlic association rule.

Stcp 3- Calculatc thc contidcncc lcvct for cacli rulc gcncratcd in Stcp I .

Stcp 4-  Kcmovc ttiosc association rulcs with contidcncc lcvcl less than c.

SIC^ 5- End.

Algorithm CORRA LA TION (R) Girvn: A sct ofdcsircd association rulcs, R = fr,, . . , , rli dclivcrcd by thc Prunc algorithm.

Each rule has ttic format of X and d is a dccision vaiuc.

d, whcrc X is a sct of independent variables (conditions)  Ohjecihu: Gcncraling thc goldcn association rulcs.

Stcp 1.  Rcpcat stcp 2 and 3 for cvcry rulc in R.

Stcp 2. Calculate thc corrclation bctaccn X and d in rolc r;:  Sicp 3. lfCorr(X, d) 5 I ,  thcn rciiiovc rulc 6 from R.

Corr(X, d) = (frcq(x U d )  in S) / ((frcq(X) in '3) * (frcq(d) in S)),  Elw assign thc corrclation valuc lo r,.

Stcp4, End.

2.3 'Tcsting Thc lcaming proccss analyzcs a givcn datasct and dclivcrs a set of goldcn rulcs. Each goldcn rulc has a dominant lactor arid a corrclation > I ~  Algori/hnr TESTING Given:  Objcctivc: Prcdicting thc dccision values oftcst rccords using rulcs in G .

Stcp I .  For cvcry rccord i n  thc tcsting SCI rcpcat stcp I.

A new PCI ofgoldcn rulcs, G ,  dclivcrcd by tlic lcarning stcp. Each rulc has a corrclation valuc, and a domiiiaiit factor. A lcsting SCI is also givcn.

Predict the dccision valuc or the rccord o f  lcsting SCI using rules in G. In tlic case that prcdiclion of' rhc dccision is in conflict, t l ic i i  usc thc following conllict rcsolution stcps: A. If a nuiribcr of rulcs in C ,  prcdict thc dccision ofthc rccord and thc prcdictcd  decisions arc i n  conflict. thcn majority rulcs.

B. lfthcrc is no majority, then thc prediction by thc rulc with thc highcst correlation  valuc will bc sclcctcd.

C. Ifconflict is pcrsisting, then llic prediction by a rulc with highcst doininant fktor  will bc sclcctcd.

D. lfthcrc is no clcar dominant factor, thcn rules in C fail to prcdict thc dccision for  the rccord.

Stcp 2. End.

3. EXPERIMENTAL DESIGN AND KESULTS Ttic data sct on which lhc cxpcrimcnts arc conductcd includcs I000 chcmical agents and thcir toxicily clfccts 011 Livcr canccr. Thcsc rccords arc borrowcd from a database dcvclopcd in     Nalional Ccntcr for Toxicological Kcscarch [ 131. Every record has 250 attributes and four pairs of training-test scts randomly gcncratcd from tlic original datasct. The numbcr ofrccords in a training and ~ C S I  pair arc 750 snd 250.

~ ~ ~~  Testing Set  Tcst sct # I Tcsr sct # I Tcst se! #I Tcst set #I AVERAGE I  Sets related attributes Train I Train 2 Train 3 Train 4  Tablc I: Thc riiinlbcrof highly rclatcd attribulcs for thc four  Learning paradigm LEFKA Logistic Keipss ion  YO of Correct Classification ?% of Correct Ctassification 71 59 71 62 67 5 8 72 hl 70 60  training SCE  Thc prc-aiialysis o f  data idcntrfics a subsct ofattributcs for cvcry oiic of thc lour training scl that arc highly rclatcd to cnch other. Thc nuinbcr o f  highly rclatcd attributes i s  diffcrcrlt from oilc training sct to the next and thcy arc shown iii Tablc I ,  Thc idcntificd rclatcd attributcs rcplacc t l ic 250 attributes in cvcry training-tcst pain. The rcsulls of applying the LEFRA paradigm on lhcsc four pairs of training-tcst scls arc dcpictcd iii Tablc 2.

In addition, thc prediction capability of the LEFRA i s  cnniparcd with thc prcdiction capability of thc logistic rcgrcssion. This comparison is donc by applying thc logistic rcgrcssioii on !hc samc pairs of training and tcsting scts. The rcsulls arc also shown iii Tablc 2.

4. CONCLUSION AND FUTURE RESEARCH Thc rcsults iii Tablc I rcvcal that !he LEFKA paradigm is a powcrful prcdiction tool Thc rcsults ofprcdiction arc much higlwr than prcdiction by logistic rcgrcssion approach.

5. REFERENCES J. Han and M. Kambcr, ?Data Mining: Uonccots and Tcchniqiics?, Morgan Kaufinan Publishcr, 2001, pp. 225-236.

S .  Chaudlitiri and U. Dayal, ?An overview ofdata warchousing and OLAP tcchnology, ACM SICMOD Rccord, 25: 1997, pp. 65-74.

R. Hashcmi, L. LcBlanc, aird T. Kobayashi, ?The Prcdiction o f  Vcsscl Accidcnts Using Formal Conccpt Analysis?, Thc Cilnadian Transportation Kcscarch Forum, 38th Annunl Confcrcncc, Toronto, Ontario, Canada, May 2003, Vol. I, pp. 478-492.

R. Willc, Rcstructuring latticc Ihcory An approach based on hicmrchics ofconccpls, in: Ordcrcd Scls, I .  Rivali, cd., Rcidcl Dordccht I?ublishcr, Boston, 1982,445-470.

5. K. Agrawal, T. Imiclinski, and A. Swami, ?Mining association rulcs bctwccn sct of itcnis in largc databascs?. procccdings of 1993 ACM-SICMOD lntcrnational Corifcrciicc on Managciiicnt of Data (SIGMOD?93), Washington DC, May 1993, pp. 207-2 16.

6 .  K. Agrmval and R. Srikant, ?Fast algorirhms for mining association rulcs?, procccdings of I994 Intcmational Confcrcncc un Very Largc Dalabascs (VLDB?94), Santiago, Chilc, Scpt  H. Mannila, H. Toivonon, and A. I .  Vcrkanio, ?Efficient algorithms for discovcring association rulcs?, procccdings or AA AI ?94 Workshop Knowlcdgc Discovcry in Databases  8. S. Rainaswainy, S. Mahajan, and A. Silbcrschatz, ?On thc discovcry of inlcrcsting pattcms in association rulcs?, procccdiiigs of I998 Intcrnational Confcrcncc on Vcry Largc Databascs (VLDB?9X), Ncw York, August 1998, pp. 361-379.

9. R. Hashcini, C .  lppcrson, A. Tylcr, and J .  Young, ?Knowlcdgc Discovcry Prom Sparsc Phamiacokinctic Data?, Procccdings of Thc 2000 ACM lntcmational Symposium on Applicd Coniputing (SAC?OO), lanicc Carroll, Erncsto Damiani, Hishom Haddad, Daw Opcnhciiii Editors, Como, Italy, March 2000, pp 75 - 79.

Databasc Mining?, Thc Intcrnational Joumal of  Smart Enginccring Systcm Dcsign, No. 4,  1994, pp. 487-499.

7.

(KDD?94), Scatlc, WA, Juty 1994, pp. 181-192.

IO. U. tlashcmi, F. Choobinch, W. Slikkcr, and M. Paulc, ?A Rough-Fuzzy Ctassificr for  pp.107-1 14, 2002.

I I .  R. Hashcnii, B. Pcarcc, K. Arani, W. Hinson, and M. Paulc ?A Fusion of Rough Scts,  Moditicd Rough Scts, and Gcnclic Algorithms Ibr Hybrid Diagnoslic Systcms?, (A book chaptcr), Rough Scts and Data Mining: Analysis of lmprccisc Data, Lin T.Y. and Ccrcanc N.

t!dilors, Kluwcr Academic Publishers, January 1997, pp 149-1 76.

12 .  A. Savascrc, E. Omiccinski, and S. Navalhc, ?Mining for strong ncgativc associations in a largc databasc of customcr transactions, Procccdings of  1998 lntcmational Confcrcncc on Data Enginccring (ICDE?98) Fcbmary 1998, Orlando, Florida, pp 494-502.

13. J. Young, W. Tong, H. Fang, Q. Xic, U. Pcarcc, K. Hashcmi, R. Bcgcr, M .  Chccscman, J .

Chcn, Y. Chang. and R. Kodcll, ? Building an Organ-Spccific Carcinogcnic Databasc for SAK Analyscs?, Thc Intcmational Journal of Toxicology and Environmcntal Hcalth, Scpt.

