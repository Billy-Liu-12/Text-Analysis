Organizing Web Documents Resulting from an   Information Retrieval System Using Formal Concept Analysis

Abstract   To discover information needs among information  resulting from an information retrieval (IR) system by a user, it is needed to be managed them in some effective ways. Document clustering is a common and useful technique for Web information retrieval. In this paper, we use Formal Concept Analysis (FCA) method for reorganizing documents resulting from an IR system according to their formal concepts. We use tf.idf (term frequency ? inverse document frequency) term weighting scheme in selecting terms from the documents to construct the formal context of documents and terms which will then be used to extract formal concepts among resulting documents. We use text mining technique, association rule mining, on the frequent termsets of the given domain to analyze relationships of terms existing in the resulted documents. Finally, the concept lattice of the documents is built on these associated terms to obtain formal concept based clustered resulted documents by discovering ordering relations among frequent termsets using lattice theory.

Keywords: Information Retrieval, Concept-based Document Clustring, Formal Concept Analysis, Frequent termsets, Text mining, Association Rule  1. Introduction After the advent of the Internet, people tried to publish their information as Web pages on the Internet from different places using different formats. As the unpredictable amount of that information continues to grow rapidly as well as the heterogeneity and the lack of structure, Web-based information is difficult to organize, manage and retrieve. However, to discover and meet user information needs among this information, it is needed to be managed in some effective ways.

Many researchers and commercial groups interested in this area have performed several tasks on information management for decades. Because of the limitations of the current IR systems, most Web users have still experienced in discovering useful information from the Internet. Current search engines are trying to enhance their power in many different ways.  Among these, document clustering is a common and useful technique for Web information retrieval. This technique was initially investigated to enhance the search engine?s performance (recall and precision) by retrieving more related documents from the corresponding clustered documents. More recently it has been proposed for use  in browsing a collection of documents for the purpose of information retrieval, to auto-generate hierarchical relation of document clusters such as Yahoo and also in organizing the results provided by a search engine in response to the user query [12][14].

Various clustering algorithms have been developed and are useful in many application areas. Agglomerative hierarchical clustering and partitioning based k-means clustering techniques are commonly used in many areas.

Although the agglomerative clustering technique is superior to k-means clustering, the work of Steinbach et al.[12] showed that the result of bisecting k-means algorithms is better than the previous two.

Clustering offers the advantage that a priori knowledge of categories is not needed, so the categorization process is unsupervised. Thus they are more adaptive for organizing Web search results obtaining from various queries.  Most traditional clustering algorithms cannot be directly used for search results clustering because of some practical issues such as the time cost to download the original documents, difficult to generate readable description for quick browsing by users, etc.  We have proposed an approach to cover these issues.

Most of the clustering techniques commonly use the popular cosine similarity measure to cluster documents.

In this paper, we have proposed to take advantage of the Formal Concept Analysis (FCA) method in clustering Web search results. By the FCA method, we construct the context matrix of the documents and terms for that document set. Using this context matrix, the documents are initially clustered according to their corresponding formal concepts. We use tf.idf (term frequency ? inverse document frequency) term weighting scheme in selecting terms from the documents that would be useful to represent those documents before generating formal context of the resulted documents. It assists to reduce less useful formal concepts of the given domain. Formal context is generated using those selected terms as attributes and the resulted documents as objects.

This method allows to cluster documents containing different termsets as different formal concept based cluster of documents. We define these groups of documents as initial clusters of the document set. As a formal concept is a pair of a set of documents (extent) and a set of terms (intent), in our method, we considered a set of documents as a cluster of documents and the corresponding set of terms as the label to that document cluster. From these clusters we use only clusters which satisfy minimum global support to obtain common or general clusters.

Finally we constructed the corresponding concept lattice of document clusters and determined concept relations between terms in the termsets describing those document clusters using their association measures.

The paper is organized as follows. Some works related to this research are described in Section 2. In section 3, we discuss organizing documents using formal concept analysis. In this section, the basis of FCA technique and how FCA is applied in formal concept based clustering of Web documents resulting from an IR system is discussed in detail. The use of formal concepts in discovering frequent termsets and the use of association rule mining technique in text databases is presented in section 4.  Section 5 describes the process to build concept lattice corresponding to the searched Web documents. We provide conclusion and future work of this research in section 6.

2. Related Work  Zeng et al.[17] discussed salient phrases based clustering of documents returned by a certain Web search engine. According to their approach the documents are assigned under relevant salient phrases and final document clusters are obtained by merging those candidate clusters.

Zamir and Etzioni [16] developed a Grouper- an interface to the results ot the HuskySearch meta-search engine, which dynamically groups the search results into clusters labeled by phrases extracted from the snippets.

Numerous document clustering algorithms appear in the literature [6].  A comparison of document clustering techniques was discussed in [12]. Many document clustering algorithms rely on off-line clustering of the entire document collection [2, 11]. Such off-line clustering approach results in document clusters with lower quality for a dynamic environment such as the Web [7].

E-H. Han et al.[5] propose an agent for exploring and categorizing documents on the Web.  Their agent categorize a set of documents automatically. A document browsing technique that employs document clustering as its primary operation was presented by [3].

3. Formal Concept Based Document Clustering  Formal Concept Analysis (FCA) was invented by Rudolf and Wille in 1982. It has been developing gradually and has notably grown after the work of Ganter and Wille (1999). It is a human-centered method to structure and analyze data, knowledge representation and information management. The basic idea of FCA model is to use formal context of objects and attributes to describe formal concept of a domain. In clustering search results of an IR system, FCA?s formal context can be formed through a set of documents as objects, a set of index terms as attributes and the relation between a document and a term in a given document set.

In this paper, as we intend to analyze the documents retrieved from an information retrieval process to be located them under their corresponding formal concepts, contexts between documents in the resulting documents are needed to be explored in advance before extracting formal concepts belonging to the domain.

Document  Document 1Document  2Document 3  Document  Document 1Document  2Document 3  Assume-to-be- relevant documents  from the ranked searched list  Text Mining Process  Frequent Termsets Finding  Discovering Association Rules  {Web} {Engine}{Search} {d1, d5} {d1, d5, d10}  {d1, d5} {Engine, Search}  Concept-based Document Cluster  Finding Relationships  between Associated Concepts  Document  Document 1Document  2Document 3  Document  Document 1Document  2Document 3  Assume-to-be- relevant documents  from the ranked searched list  Document  Document 1Document  2Document 3  Document  Document 1Document  2Document 3  Document  Document 1Document   Document 1Document  2Document 3  Document  Document 1Document   Document 1Document  2Document 3  Assume-to-be- relevant documents  from the ranked searched list  Text Mining Process  Frequent Termsets Finding  Discovering Association Rules  {Web} {Engine}{Search} {d1, d5} {d1, d5, d10}  {d1, d5} {Engine, Search}  {Web} {Engine}{Search} {d1, d5} {d1, d5, d10}  {d1, d5} {Engine, Search}  Concept-based Document Cluster  Finding Relationships  between Associated Concepts                 Figure 1. Formal Concept Based Document Clustering  3.1 Textual Document Formalization  In order to construct the formal context, documents are preprocessed and normalized firstly. In this paper, we put an idea that the set of terms in a formal concept corresponding to the set of documents in which the no.

of documents in that document set satisfy the minimum support document count is defined as a frequent termset in that document set. Thus, in our method, frequent termset finding process is completely performed by analyzing formal concepts among assume-to-be relevant documents.

The construction of formal context of documents and terms similar to the process of representation of documents in an IR system. In this paper, we select terms that are useful to index each document based on their tf.idf (term frequency ? inverse document frequency) weighting measures.  As in information retrieving environment, the importance of a term in a document is generally defined by the no. of terms contained in that document (tf). The idf measure assists identify a word which contain frequently in a document but does not frequent in the document collection as an index term. The idea is that the more often a term occurs in a document, the more it is representative of the content of the document, and the more documents the term occurs in, less discriminating it is.

In this paper, we considered only HTML documents.

The formalization process includes HTML tag parsing, useful text operations such as elimination of stopwords, stemming (transforming a word to its grammatical root) and construction of inverted index files for further calculations.

The system first selects only the top 50 documents (if the no. of documents retrieved is greater than 50) from the ranked list to be used as documents which are assumed to be relevant to the user query. In this paper,    we denoted the set of all documents in the searched list as Dr and the set of assume_to_be_relevant documents as Dr'. The system then preprocess the selected documents to explore the context of documents and terms that represent those documents. After removing HTML Tags, the text in each document are tokenized.

Stopword removing and stemming algorithms are then applied to those tokens. Stopword elimination removes words which are not useful to get the semantics of a document such as English articles (a, an, the, etc.), pronouns (it, he, she, they, etc.), prepositions (on, at, in, etc.) and other less useful words.

In our system, we used a stopword list containing about 500 words. Stemming reduces the amount of indexable terms. It transforms morphological words to its stem, for example, the words ' computer', 'computing' and 'computational' are transformed to their stem ?comput'. This is performed to use single index term for terms that have the same conceptual meaning. We used the Porter stemming algorithm to stem the words in this system.

The system then proceeds the generation of inverted index file for the given document set. We used the data stored in the inverted index file, document frequency and term frequency, in calculating weight measures for each term in each corresponding document of the given document set. This tf.idf  measure can be calculated as  idftfw i ?=   it  i  D D  f f log  max ?=  where tf (term frequency) is the total number of frequency of term i in the document di, idf is the inverse document frequency, fi is the frequency of term i in di , max ft is the maximum frequency computed over all terms in di, D is the total number of documents in the collection and Di is the total number of documents in which the term i appears and  1>wi>0. In this system, we only select terms that satisfy the minimum term weight threshold value for each term, . In  our system, we used .

)min( , ii dtw  5.0)min( , =ii dtw  3.2 FCA-based Document Organizing  Formal Concept Analysis (FCA) method is then applied to Dr' for organizing documents under their formal concepts and for identifying frequently used termsets.  Firstly, formal context of documents in Dr' and the terms representing those documents is automatically generated using the data stored in inverted index file.

According to FCA model, documents are considered as objects, the terms representing the documents as attributes and ?the existence of a term in a document? is identified by a binary relation between documents and terms. In this system, the formal context of documents and terms in Dr' is defined as follows.

Definition 1:  A formal context of documents and terms in Dr' is a triple (Dr', T, R ) where Dr' = {d1, d2, d3,?, dj} is a set of selected assume-to-be relevant documents in the document set Dr, T = {t1, t2, t3,?, tn} is  a set of all index terms in Dr', and R is the incident relation between Dr' and T where R ? Dr' ? T.

HTML  files  system  computer  database  science  Index terms df      Index file  ? ? ?  HTML tag parsing  Stopword Removing  Stemming  Inverted Index File construction  Preprocessing  HTML  files  HTML  files  system  computer  database  science  Index terms df      Index file  ? ? ?  system  computer  database  science  Index terms df      Index file  ? ? ?  HTML tag parsing  Stopword Removing  Stemming  Inverted Index File construction  Preprocessing  HTML tag parsingHTML tag parsing  Stopword RemovingStopword Removing  StemmingStemming  Inverted Index File construction  Inverted Index File construction  Preprocessing              Figure 3. Representation of Documents and Terms  Formal Context   Fig.3 shows a sample context table of the formal  context (Dr', T, R ) which is automatically generated by our prototype system. The first row in the table represents the terms (keywords) in the document set Dr'.

The first column represents the objects also.

Figure 2. Document Formalization Process  According to FCA technique, the formal concepts of document in Dr' is then extracted using their formal context. We defined the formal concept of the context (Dr', T, R )  to extract the formal concepts.

Definition 2:  A formal concept of the formal context (Dr', T, R )  is a pair (Di, Ti) if and only if  and   ,,, '' iiiri TDTTDD =?? 'ii TD =  where,         for all   RtdTtDi ??= ),(|{:' }iDd ?  for all    RtdDdTi ??= ),(|{:' }iTt?  In a formal concept, the set of documents is referred to as the extent and the set of terms corresponding to those documents is referred to as the intent. The formal concepts described in figure 5 are extracted from the formal context illustrated in figure 3 according to the definition 2.

u p   : : : r : : D :   : T  F I     F  D F      { I      In our system, the conceptual clusters of documents are organized according to the formal concepts extracted by FCA. We identified the sets of documents (extensions of the formal concepts of Dr') as initial clusters of documents and the sets of terms (intensions of the formal concepts of Dr') are considered as the concept labels that represent their corresponding document clusters.

The initial document clusters and their corresponding concepts are as shown in figure 5. From these clusters we eliminated clusters having the document count less than the minimum support count for documents. In our system, we set this value to 5. We used the algorithm described in figure 4 for organizing searched documents according to their formal concepts.

Inp t : A set of searched documents relevant to a query Out ut : A set of group of documents with  corresponding cluster label Let, Dr'  be the set of assume-to-be-relevant documents I  be a set of inverted indices for Dr' CT  be a matrix of documents and terms with binary  elation T  be a set of index terms for Dr' Di   be a set of possible combination of documents in  r' Ti   be a set of possible combination of terms in T C(Dr',T,R): be a set of formal concepts of the documents  in Dr' CC be a set of formal concept based document clusters MS d : be minimum support document count  1: or i=1 to N do     // N is | Dr'| 2:   ? Perform_Document_Formalization (Dr'); 3: T ?  Select_Index_Term (I); 4: CT (Dr',T,R) ? Explore_Formal_Context(I); 5: { Di } ? Find_all_Powerset(Dr'); 6: { Ti} ? Find_all_Powerset(T); 7: or i=1 to Ndoc     // Ndoc is |{ Di }| 8: { 9:  i' Find_Terms_Common to_DocumentInDi (Di); 10: or j=1 to Nterm     // Nterm is |{ Ti }| 11: Tj' ? Find_Docs_CommonlyContain (Tj); 12: If  Di = Tj'  and  Di' = Tj   then 13:     C(Dr',T,R)?Identify_Formal_Concept(Di, Tj); 14:  } 15: For i=1  to  |C(Dr',T,R)|  16: f   |Di |  >=  MSTd   then 17: {CC} ? Identify_Concept_Cluster {FC}); 18:  }   3.3 Finding Frequent Termsets in Documents  In this paper, our main idea is to use FCA to discover frequent termsets from the document set Dr'. As the intent of a formal concept of the context (Dr', T, R ) consists of the terms common to all the documents in the extent, the termsets in Dr' are identified as frequent termsets if the occurrence frequency of those termsets satisfy the minimum support count for a termset in Dr'.

Based on the formal concepts of documents and terms derived by FCA, a frequent term(s) is defined as follows.

Definition 3:  A frequent termset in Dr' is a set Tf =  {( t1,?, ti) | ?(t1,?, ti) ? Dr' : freq(t1,?, ti) ? ? and i = 1, 2,?, n} where ( t1,?, ti) is frequent i-termset, freq(t1,?, ti) is the occurrence frequency of i-termset, Dr' is assume-to-be- relevant document set, ?  is minimum support count for a termset in  Dr' and n is the total no. of keywords in Dr'.

In our system, the occurrence frequency of a termset in Dr' is defined as the no. of documents in the extent of that formal concept. Minimum support count will be varied according to the no. of documents in Dr'.  It is calculated by the product of minimum support threshold value (%) for frequent termsets which is obtained by several analysis to the searched documents, and the no.

of documents in Dr'.  In our system, we set minimum support threshold value to 20%.  Figure 4. FCA-based Document Organizing Algorithm       d im U d s u o f  Figure 5. Formal Concepts Extracted from the Formal Context described in figure 3          Figure 6. Selected Frequent Terms  . Text Mining in Document Databases While data mining is typically concerned with the  etection of patterns in numeric data, very often portant information is stored in the form of text.

nlike numeric data, text is often amorphous, and ifficult to deal with. Text mining tries to apply the ame techniques which are used in data mining to nstructured text databases. Text mining mainly consists f two processes: preparation of text documents for urther text analysis processes and the text mining    process itself that deduces patterns or knowledge from the preprocessed textual data.

A fundamental and essential process in data mining is feature extraction which identifies and extracts key features from the text, in particular the terms and concepts most frequently used in the input documents, that can be used as the data and dimensions for further text analysis such as discovering any associations and co-relations between features by applying corresponding algorithms to determine whether they have associations or not.

After finding frequent termsets in the document set, we discovered strong association rules between them to make use them as useful terms to label the document clusters and to reduce less useful concepts. We obtained both compound words (e.g., information technology) and non-compound words (e.g., information document search) after this process.

4.1 Mining Association of Terms in Documents  Association rule mining is finding the interesting association or correlation relationships among large amount of data. Conventionally, this technique is often the first and most useful method for analyzing data that describe transactions, lists of items. In our system, this technique is used to Tf to determine terms association of the form TA ? TB based on their support and confidence measures where TA , TB  ? Tf. The support denoted by s is the percentage of documents in Dr' that contain both termsets TA ? Tf and TB ? Tf. The confidence denoted by c is the percentage of documents in Dr' containing TA that also contain TB.

We define that the termset TA and TB  has a strong association of the form (TA ? TB) with support s and confidence c if they satisfies minimum support threshold (MST) and minimum confidence threshold (MCT) for any association of the termsets in the document set D. In our research, we set MST = 20%  and MCT= 60% .

These values are set based on the analytical results of our experiment.

The support s and the confidence c of an association of termset TA and TB can be taken as   s ( TA ? TB ) =    c ( TA ? TB )  =    where the support count (TA ? TB) is the no. of documents that both the termsets  TA and TB appears in Dr' and the support count TA  is the no. of documents containing the termset TA in Dr'.

In our system, we used the algorithm described in figure 7 to mine strong association rules of terms in the retrieved documents. We identified the termsets which do not satisfy MST and MCT as less useful concepts. In this system, we eliminate these less useful termsets from  being cluster labels initially obtained by FCA.

According to this procedure, the initial set of formal concepts C (Dr', T, R) is reduced to C? (Dr', T, R), the set of useful formal concepts.

Input  : A set of frequent termsets Output : A set of strongly associated termset Let, F    : be the set of frequent termset P(Fi) : be the powerset of frequent termset Fi A  : be the set of strongly associated termset s   : be the support measure c  : be the confidence measure  1: MST ? 0.2;  //initialize minimum support threshold 2:  MCT ? 0.6; //initialize minimum confidence  threshold 3: For i=1 to N do   // N is |F| 4: { 5:  {P(Fi)} ? Find_all_Powerset (Fi); 6:  For j=1 to noF // noF is the no. of all possible combination of  terms in each P(Fi) 7:  { s ? calculate_support_measure((Fj)i, (Fj+1)i); 8:     c?calculate_confidence_measure((Fj)i,  (Fj+1)i); 9:     if s >= MST and c >= MCT then 10:  {A} ? Select_Strong_Associated_Terms(P(Fi)); 11:  } 12:   }  Figure 7. Associated Terms Selection Algorithm                  support-count (TA ? TB)  Total no. of documents in the given document set  Figure 8. Association Rules with their Support and Confidence measures   support-count (TA ? TB)  Total no. of documents in the given document set     5. Providing Concept Lattice for Search Documents  An important advantage of FCA is that the Galois connections and the sets of formal concepts can be visualized. Figure 9 shows the corresponding concept lattice of the formal context in figure 3. The concept lattice consists of a set of useful concepts and the subconcept-superconcept relation between these concepts.

We identifed ordering relations ( ? ) between the concepts of C? (Dr', T, R). We defined that a concept (D2 , T2)  is  a  superconcept  of  (D1 , T1), i.e., (D1 , T1) ? (D2 , T2), if and only if  D2   ?  D1  or  T1  ?  T2  where D1 , D2  ? Dr'   and   T1, T2  ?  T .

In figure 9, the nodes represent formal concept based document clusters with their corresponding labels.

and Development in Information Retrieval, 1992, pp. 318-329.

[4] Benjamin C. M. Fung, K. Wang and M. Ester, ?Hierarchical Document Clustering Using Frequent Itemsets?, in Proceedings of the SIAM International Conference on Data Mining, 2003.

[5] E-H. Han, D. Boley, M. Gini, R. Gross, and K.

Hastings, ?WebACE: A Web Agent for Document Categorization and Exploration?, in Proceedings of                 6. Conclusion and Future Work  In this paper, we have presented an alternative approach for organizing text-based documents retrieved from an IR system. We used formal concept analysis method for conceptual clustering of documents. It basically relies on the formal context of documents and terms representing those documents.  By applying text mining techniques to the sets of frequent terms obtained by FCA, we get more associated terms which are useful to label formal concept based document clusters.  By providing the corresponding concept lattice for the searched documents, users can access the retrieved documents more easily and effectively than the linearly ranked list provided by a traditional IR system.

Reuse of these clustering results for user query reformulation in keyword-based querying will be beneficial in building high performance search engines.

This task is remained as our future research.

Reference: [1] P. Berkhin, ?Survey of clustering data mining  techniques?, Technical report, Accrue Software, 2002.

[2] D. R. Cutting, D. R. Karger and J. O. Pedersen, ?Constant interaction-time Scatter/Gather browsing of large document collections?, in Proceedings of the 16th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR?93), 1993, pp 126-135.

[3] D. R. Cutting, D. R. Karger, J. O. Pedersen and J.

W. Tukey, ?Scatter/Gather: A Cluster-based Approach to Browsing Large Document Collections?, in Proceedings of the 15th  Annual International ACM SIGIR Conference on Research  Agents (Agents?98), May 1998.

[6] J. Han and M. Kamber, Data Mining: Concepts and  Techniques, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2000.

[7] M. A. Hearst and J. O. Pedersen, ?Reexamining the cluster hypothesis: Scatter/Gather on retrieval results?, in Proceedings of the 19th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR?96), 1996, pp 76-84.

[8] U. Priss, ?Lattice-based Information Retrieval?, Knowledge Organization, Vol. 27, 3, 2000, p. 132- 142.

Figure 9. Concept Lattice of C? (Dr', T, R)  [9] U. Priss, ?Formal Concept Analysis in Information Science?, Annual Review of Information Science and Technology, Vol. 40 (in preparation), 2004.

[10] I.K. R. Rao, ?Data Mining and Clustering Techniques?, DRTC Workshop on Semantic Web, 8th-10th December, 2003, DRTC, Bangalore.

[11] C. Silverstein and J. O. Pedersen, ?Almost-constant time clustering of arbitrary corpus subsets?, in Proceedings of the 20th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR?97), 1997, pp 60-66.

[12] M. Steinbach, G. Karypis and V. Kumar, ?A Comparison of Document Clustering Techniques?, in KDD Workshop on Text Mining, 2000.

[13] G. K. T. Tam, ?FOCAS- Formal Concept Analysis and Text Similarity?, in Proceedings of the 2nd Analysis, January 2004.

[14] L. Wanner, ?Introduction to Clustering Techniques?, IULA, 1st July 2004.

[15] R. B. Yates and B. R. Neto, Modern Information Retrieval, Addition Wesley, New York, NY, USA, 1999.

[16] O. Zamir and O. Etzioni, ?Grouper: A Dynamic Clustering Interface to Web Search Results?, in on World Wide Web, 1999, pp 1361-1374, Toronto, Canada.

[17] H-J. Zeng, Q-C. He, Z. Chen, W-Y. Ma and J. Ma, ?Learning to Cluster Web Search Results?, in Proceedings of the 27th annual ACM SIGIR Conference on Research and Development in Information Retrieval, 2004, pp 210-217, UK.

[18] Zhang GQ. Zhang, G. Shen, J. Staiger, A. Troy and J. Sun, ?FcAWN: Concept Analysis as a Formal Method for Automated Web-Menu Design?.

