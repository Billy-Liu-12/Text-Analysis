

Abstract? Mining frequent itemset is an important step in association rule mining process .In this paper we are applying a parallel approach in the pre-processing step itself to make the dataset favorable for mining frequent itemsets and hence improve the speed and computation power. Due to data explosion, it is necessary to develop a system that can handle scalable data. Many efficient sequential and parallel algorithms were proposed in the recent years. We first explore some major algorithms proposed for mining frequent itemsets. Sorting the dataset in the pre-processing step parallely and pruning the infrequent itemsets improves the efficiency of our algorithm. Due to the drastic improvement in computer architectures and computer performance over the years, high performance computing is gaining importance and we are using one such technique in our implementation: CUDA.

Keywords? Association rules; FP-growth; parallel computing; CUDA.



I. INTRODUCTION  The growing impact of data is gaining importance in data  mining and knowledge discovery. Given the large database sizes, one of the main challenges in database mining is developing fast and efficient algorithms that can handle large volumes of data. Mining for association rules involves extracting patterns from large databases and inferring useful rules from them.  It helps to find the relationship between the itemset in a large database.

Enormous amount of data means large amount of computation power in processing the data and a big chunk of memory requirement. Several algorithms have been proposed to mine these frequent itemsets. Also several refinements have been done on these algorithms to increase their efficiency. Two such fundamental and important algorithms are Apriori [1] proposed by R. Agarwal et.al and FP- growth [2] algorithm proposed by Han et.al. But none of the algorithms can be said to be superior over the other. The dataset to be mined and an appropriate support threshold to be used determine which algorithm performs best. There is still scope for improvisation in the above algorithms in terms of time and computation  complexity. Also being a flat tree like structure, the basic FP- growth algorithm fails when it comes to storage space but surpasses Apriori in terms of number of database scans. In this paper, we propose a highly parallel version of FP ?Growth which can be implemented on scalable data. We are trying to sort the dataset in ascending order parallely and eliminate all frequent itemset which are less than the minimum support threshold. Thus we are making the dataset more favorable for the mining process.



II. PRE-REQUISITES  2.1  FP-GROWTH ALGORITHM A. Problem Description  The formal statement of frequent mining is as follows [2]: Let I = {i1, i2, ?, in} be a set of literals, called items and n is considered the dimensionality of the problem. Let D be a set of transactions, where each transaction T is a set of items such that T ? I. An itemset X is said to be frequent if its support is greater than or equal to a given minimum support threshold.

The association rule mining is a two-step process: 1) Find all frequent itemset having minimum support.

2) Generate strong rules having minimum confidence, from  the frequent itemset.

B. FP-Growth  The pseudo code proposed by Han et. al [2] for mining FP-tree is depicted in Fig 1.

FP-Growth uses a pattern fragment growth method to generate frequent itemsets. It requires only two scans. The first is to collect the support of each item sorted in descending order of frequency. The original database is converted into a compressed tree structure, the FP-tree in the second scan.

Once a FP-tree is constructed, the FP-tree is decomposed into a group of independent conditional pattern bases of the frequent items. FP-Growth needs to build conditional FP-tree according to each conditional pattern base. Henceforth, the mining process is conducted on independent processes, constructing and mining conditional FP-tree recursively.

Figure 1. Pseudo code of FP-Growth algorithm from [2]    2.2 CUDA There has been a drastic improvement in computer  applications, computer architectures and computer performance over the past 60 years. Simultaneously, the complexity of the applications harnessing computing power has also increased. CUDA is a parallel programming environment created by NVIDIA which exploits the NVIDIA GPUs for parallel computing. The NVIDIA GPU contains hundreds of ALUs which can be used to individually do operations. It follows the SIMD (Single Instruction Multiple Data) architecture which allows the individual ALUs to perform the same operation over different data thus introducing parallelism into the system. The CUDA GPU cores have a separate memory bank from the main CPU with a very high bus speed. This helps improve parallelism. The CUDA model differentiates between the processing done on the GPU and the one done on CPU by making different functions for each. The CPU and its memory is known as the Host whereas the GPU and its memory is known as the Device. Calls can be made from the Host to the Device and from the Device to itself by using functions defined as global and device respectively. The CUDA enabled GPUs offer a teraflop of computing power for a very low cost [4]. Thus CUDA programming is heavily used in HPC (High Performance Computing) tasks.



III. REVIEW OF IMPROVED FREQUENT ITEMSET MINING ALGORITHMS   Finding frequent itemsets is comparatively more time  consuming [5]. So in order to increase the efficiency of the system, the first step will be to enhance the functionality at this core level. A large number of increasingly efficient algorithms to mine frequent itemset have been developed over the years  [2], [5], [6], [7], [8], and [9].Since finding frequent itemsets is more time consuming , we have concentrated our work in improving the dataset and making it more favorable for the mining process.

Min Chen et.al [10] proposed a novel parallel FP-Growth algorithm GFP-Growth, which is designed to run on the computer cluster to avoid memory overflow. Using projection method and splitting the mining task into number of independent sub-tasks, this algorithm works independently at each node. As a result, it can efficiently reduce the inter-node communication cost. In [11], the authors have tried to improve the basic FP- growth algorithm by using Compound Single Linked List. They use the sequencing table and single linked list as the main data structure and do not need to generate conditional FP-tree. It is mined in one direction, using the header table in the original FP-tree, and a compound single linked list is constructed. A new algorithm [12] generates FP tree using directed acyclic graph data structure. Authors propose an algorithm that scan the database and generate FP tree as DAG so that they can generate frequent patterns directly using DAG without generating conditional FP trees. This approach reduces the total step of the process and also takes less time and less memory. Peiyi Tang et.al [13] has explored a new scheme to parallelize frequent itemset mining algorithm.

Here the authors have applied the extended conditional databases and k-prefix search space partitioning. The algorithm is able to reduce the execution time of the largest parallel task, thus allowing more parallel processors to join to achieve higher speed. Dynamic self-scheduling for parallel task allocation to balance the work load among parallel processors has been used. Buehrer [14] proposed variants of FP-Growth on computer clusters and have tried lowering communication costs and improve the cache memory and I/O utilization. In [15], Wenbin Fang et al. introduced GPUMiner, a novel parallel data mining system. It utilizes new-generation graphics processing units (GPUs).The authors have tried to parallelize Apriori algorithm. Their system relies on the massively multi- threaded SIMD (Single Instruction, Multiple Data) architecture provided by GPUs.  In this paper we parallelize the sorting process in pre-processing step using GPUs. The advantage of using GPUs is that it is energy efficient as well as cost effective as compared to multiprocessors and does not require a huge setup.



IV. PROPOSED MODEL   As mentioned, the algorithm is sorting the dataset in the pre-processing step parallely and pruning the infrequent itemsets so as to make the dataset favorable for mining.

The sorting process is shown in the following steps:  1. All the transactions are read first and a unique character list is made containing all the itemsets used in the transactions along with the count of its occurrence in all the transactions.

2. Those itemsets having a count less than that of the minimum support are eliminated from this list.

procedure FP-Growth (Tree, ?) { if Tree contains a single path P then for each ?= nodes combination in P do  pattern = ? ? ? ; support = min(support of the nodes in ?); else for each ai in the header of Tree      do  pattern ?  = ai ? ?; with support = ai. support ; construct conditional pattern base of ? TreeB = construct conditional FP-tree of ? if TreeB   != ?            then call FP-Growth( TreeB , ?)     3. The 2D character array is then converted into a 2D integer array where the characters present in the unique array are converted to their ASCII values and those that are not present are the given a value of 10000.

4. The integer value stored in the array is [ASCII value+ (Support count of char*122)].

5. The integer array is then flattened out and sent to the GPU to be sorted along with a 1D array of size X*Y containing all zeros. The GPU is then used to sort the integer array.



V. PSP ALGORITHM   It can be analyzed from the various mining algorithms that pre-processing the dataset appropriately and efficiently generates considerable better and faster results [16].For FP- growth it is desired that the transactions be sorted in descending order of frequency so as to speed up the mining process. In our proposed algorithm PSP (Parallel sorting in pre- processing stage), we make an attempt to enable faster pre- processing of the dataset by using some parallel programming techniques.

A. Procedure of PSP algorithm  Our approach for parallel programming is using the high parallel computing platform CUDA [4]. The CUDA code implemented for sorting an array is done in the following way: The initial input is read into a 2D character array. The frequency of each character is then found through a scan of the 2D array. The characters that do not meet the minimum threshold support count are eliminated from the array. This 2D integer array is then flattened [4] into a 1D integer array as shown in the code below. This array is passed on to the GPU for sorting.

Flattening of the 2D integer array is done as follows:                 Figure 2. Flattening of 2D Integer array   where X=number of rows in c_int and Y=number of columns in c_int. The GPU addresses the flattened array as:         Figure 3. The GPU address of the flattened array  where left=the starting index of the part of the array and right= the end index of the  part of the array. In this manner, the different blocks in the GPU do not use the same location in the array thus making all the blocks work on disjointed sets of the flattened array.

1000 blocks, each with a single thread inside it, are called. The blockId is used to determine the starting position inside the 1D array and blockId + Y is used to determine the ending point.

Each block, knowing its starting and ending point, sorts that small part of the huge 1D array and writes the sorted section to the empty 1D array that was previously created in the same starting and ending position as the original array. The empty array is thus populated with the entries of the original array but sorted in ascending order. Blank spaces have the value of 10000 whereas the characters which were retained have their values as: (ASCII value+ support count of char*122). This is then converted back into character array.

The following example illustrates the above steps in detail. Let the original dataset contain 10 transactions with 8 unique itemsets as follows:  TABLE 1. A TRANSACTION DATABASE Transaction no. Itemsets  1 a, b, c, d, e 2 c, f, a 3 c ,b, e 4 d ,a, f, b, c, e 5 a ,b, d, f 6 g ,e, a, b 7 h ,f 8 c ,d, a, b 9 g ,h, e, f, b, c  10 b, d, c,f  Step 1: Read into the 2D array  TABLE 2. A 2D CHARACTER ARRAY   Unique character list and their support count are:   a  b  c  d  e  f  g  h   Step 2: Eliminate the characters not meeting support count and rearrange in descending order of frequency      a b c e - - - - - - c f a - - - - - - - c b e - - - - - - - d a f b c e - - - - a b d f - - - - - - g e a b - - - - - - g f - - - - - - - - c d a b - - - - - - g h e f b c - - - - b d c f - - - - - -  b          8 c          7 a          6   f          6   e          5  count=0 for (i=0; i<X; i++) { for (j=0; i<Y; j++) { flat_c_int[count]=c_int[i][j]; count++; } }   int idx=blockIdx.x*Y+threadIdx.x; int left=idx; int right=left+Y-1;     Steps 3 & 4: Convert the 2D char array into a 2D int array.

The character assigned to char ?b? will be = 98+122*8=1074 Here 98 is the ASCII value of ?b?, 122 is the base count we use and 8 is the frequency of the character ?b?. Similar procedure is followed for other characters. The end result is as follows:  TABLE 3. A 2D INTEGER ARRAY   Step 5: The indexing goes from 0 to 9 in both dimensions.

This 2D array is then flattened to a 1D array with the index of the 1D array ranging from 0 to 99. This flattened array is then passed to the GPU for sorting. The sorting is done in the ascending order. The original FP algorithm sorts in descending order [2] but we do it in ascending order to better utilize our algorithm.

Each GPU block processes different parts of the 1D array which correspond to individual rows in the original 2D array.

The indexing is as follows: 0-9 = row 1   10-19 = row 2   20-29 = row 3 ?..

Hence block 1 of GPU will sort values stored in 1st 10 locations of the array (0-9), block 2 will sort values stored in next 10 locations of the array (10-19) and so on. For the above example only 10 blocks were invoked in the GPU. The sorted result is as follows:  TABLE 4. THE SORTED ARRAY  e a c b - - - - - -  a f c - - - - - - -  e c b - - - - - - -  e a f c b - - - - -  a f b - - - - - - -  e a b - - - - - - -  f - - - - - - - - -  a c b - - - - - - -  e f c b - - - - - -  f c b - - - - - - -   The blocks in the GPU sort parts of the flattened 1D integer  array and then returns the sorted array back to the host device.

Each block in turn runs a selection sort algorithm. The blocks run parallely and hence the sorting is also done parallely.

Blocks called: As many as the number of arrays to be sorted (or in multiples of 1000).

Threads per block: 1.

B.    Features Of PSP Algorithm  When a general CPU deals with large arrays, it often cycles through the entries one after the other. Thus, for each transaction, the CPU will have to run a sorting algorithm on each row of the 2D array. This is done serially and for a really large number of transactions, can be a cumbersome task.

The advantage that we have taken here is about the fact that individual transactions are independent of each other. The sorting order depends only on the frequency of occurrence of the individual item over all the transactions. After the frequency of each item is recorded, the sorting of all the transactions can be done parallely instead of serial computation. Also, to avoid using a reference for finding the sorting order each time, we can add weights to the individual items in each transaction based on the frequency(i.e. higher the occurrence, higher the number assigned). Once it gets converted into integer array, the sorting task becomes simplified.Fig.4 shows the time comparison for executing arrays serially and in parallel.

Figure 4. Sorting individual arrays (a) sequentially and (b) parallely

VI. IMPLEMENTATION DETAILS We have used AMD Athlon 64 X2 Dual Core Processor 4000+ with 2 GB RAM on an Nvidia GT 520 (1 GB) GPU.

Our PSP algorithm is tested on a set of 1K, 10K and 50K synthetic transactions respectively. The transactions are tested serially as well as with our PSP algorithm i.e. parallely and it is shown that the processing speeds up remarkably when done parallely.

Fig.5 shows that time required to sort the dataset serially is far more than that doing it parallely. The difference is more prominent as the number of transactions goes on increasing.

This is one way we are addressing the scalability issue.

829 1074 953 701 10000 10000 10000 10000 10000 10000  953 834 829 10000 10000 10000 10000 10000 10000 10000  953 1074 701 10000 10000 10000 10000 10000 10000 10000  10000 829 834 1074 953 701 10000 10000 10000 10000  829 1074 10000 834 10000 10000 10000 10000 10000 10000  10000 701 829 1074 10000 10000 10000 10000 10000 10000  10000 834 10000 10000 10000 10000 10000 10000 10000 10000  953 10000 829 1074 10000 10000 10000 10000 10000 10000  10000 10000 701 834 1074 953 10000 10000 10000 10000  1074 10000 953 834 10000 10000 10000 10000 10000 10000        Figure 5. Time comparison of serial and parallel processing

VII. CONCLUSION AND FUTURE WORK This paper proposes a new approach PSP algorithm of  sorting the transactions parallely in pre-processing stage so as to make the dataset favorable for mining. This approach is surely efficient than sequential or serial sorting and can be implemented using high performance computing. By applying PSP algorithm we are making the dataset more favorable for frequent itemset mining in pre-processing stage itself and in a way trying to address the scalability issue by decreasing the time required for sorting considerably.

However the above process has scope for improved speed by invoking multiple threads within the same block to sort long arrays. One problem faced with multiple threads in the same block is writing to shared memory variables. Since all the threads run at the same time, a lock can be obtained when writing to a shared variable. This considerably slows down the sorting process, hence the current approach was to use separate blocks with individual threads to sort the flattened array.

Bitonic sort is another way of going ahead with the sorting process. After making the dataset favorable for mining, our next approach will be to parallelize the tree generation and traversing process.

