A Frequent Item Graph Approach for Discovering Frequent Itemsets

Abstract  Efficient algorithms to discover frequent  patterns are crucial in data mining research.  Finding frequent itemsets is computationally the most expensive step in association rule discovery and therefore it has attracted significant research attention. In this paper, we present a more efficient approach for mining complete sets of frequent itemsets. It is a modification of FP-tree. The contribution of this approach is to count the frequent 2-itemsets and to form a graphical structure which extracts all possible frequent itemsets in the database. We present performance comparisons for our algorithm against FP-growth algorithm.

Keyword : Association rules, data mining, frequent itemsets, minimum support  1.  Introduction   Data mining also known as Knowledge Discovery and Database (KDD) has been perceived as a new research area for database research. The aim of data mining is to automate the process of finding interesting patterns and trends from a given data. Discovery of association rules is an important data mining task. A procedure so called mining frequent itemsets is a core step of association rules discovering introduced in [1].

Past transaction analysis is a commonly used approach in order to improve the quality of such decisions. As pointed in [2], the progress in bar-code technology has made it possible for retail organizations to collect and store massive amount of sales data ? so called Basket data that stores items purchased per- transaction basis. Most existing algorithms, therefore, are focused on mining frequent itemsets. Several algorithms have been proposed to mine frequent itemsets. A classical algorithm is Apriori introduced in [1]. Variations of Apriori were proposed so far such as a hash-based algorithm [3], a dynamic itemset counting technique (DIC) [4] and  a Partition algorithm [5]. In addition, many research have been developed algorithms using tree structure, such as ITL-mine[[6], TreeITL-  mine[7], CT-ITL[8], CT-mine[9], H-mine[10] and FP- growth[11].

There are two main strategies for mining frequent itemsets: the candidate generation-and-test approach and the pattern growth approach. Apriori [2] and its several variations belong to the first approach, while FP-growth [11] and H-Mine [10] are examples of the second. Apriori algorithm [2] suffer from the problem spending much of their time to discard the infrequent candidates on each level. The FP-growth (Frequent Pattern ? growth) [11] algorithm differs basically from the level-wise algorithms, that use a ?candidate generate and test? approach.

In this paper, we propose an efficient algorithm named FIG (Frequent Item Graph)  for mining the set of all frequent itemsets in the database by scanning the entire database only once . Since the database is scanned only once, I/O costs spent in mining the set of all frequent itemsets will be reduced.

The organization of this paper is as follows: In Section 2, we put an insight into the detailed problem description. In Section 3, we give a detail of the Frequent Item Graph algorithm used for generating all frequent itemsets. Experimental results were given in Section 4. We end with our conclusion in Section 5.

2. Problem Statement   Formally, as defined in [1], the problem of mining association rules is stated as follows: Let I = {i1,i2,?,im}. Let D be a set of transactions, where each transaction T is a set of items such that T? I. Associated with each transaction is a unique identifier, called its transaction id TID. A transaction T contains X,  a set of some items in I, if X ? T. An association rule is an implification of the form X ? Y where X ? I, Y ? I and X ? Y = ?. . The meaning of such a rule is that transactions in database, which contain the items in X, tend to also contain the items in Y.  The rule X ? Y holds in the transaction set D with confidence c if among those transactions that contains X c% of them also contain Y.

The rule X ? Y has support s in the transaction set D if s% of transactions in D contain    X ? Y. The problem of   DOI 10.1109/ICACTE.2008.129    DOI 10.1109/ICACTE.2008.129     mining association rules that have support and confidence greater than the user-specified minimum support and minimum confidence respectively.

Conventionally, the problem of discovering all association rules is composed of the following two steps: 1) Find the large itemsets that have transaction support above a minimum support and 2) From the discovered large itemsets generate the desired association rules.

The overall performance of mining association rules can be achieved by using the first step. After the identification of large itemsets, the corresponding association rules can be derived in a straightforward manner.   In this paper, we have developed a method to discover large itemsets from the transaction database, thus finding a solution for the first subproblem. Also FIG algorithm is compared with FP-growth algorithm [11] which is used to discover large frequent itemsets from a transaction database.

2.1 FP-growth Algorithm   One of the algorithms which do not use any candidates to discover the frequent patterns is the    FP- growth (Frequent Pattern - growth) algorithm proposed in [11]. The other main difference to the Apriori algorithm is the number of the database readings. While the Apriori is a level-wise algorithm the FP-growth is a two-phase method. It reads the database only twice and stores the database in a form of a tree in the main memory.

The algorithm works as follows. During the first database scan the number of occurrences of each item is determined and the infrequent ones are discarded. Then the frequent items are ordered descending their support. During the second database scan the transactions are read and the frequent items of them are inserted into a so-called FP-tree structure. In this way the database is pruned and is compressed into the memory. The aim of using FP-tree is to store the transactions in such a way that discovering the patterns can be achieved efficiently.

procedure FPGrowth(Tree, ? ) if Tree contains a single path P then for each ? = comb. of nodes in P do pattern = ? ? ? sup = min(sup of the nodes in ? ) else for each ai in the header of Tree do generatepattern =  ? ? ? sup  = ai.support construct ??s conditional pattern base FPTree = construct ??s conditional FP-tree  If FPTree != 0 then FPGrowth(FPTree, ?)  Figure 1. Pseudo code of the FP-growth algorithm   The FP-tree is processed recursively by  creating several so-called conditional FP-trees. This is the recursive pattern growth method of the algorithm.

When a conditional FP-tree contains exactly one branch the frequent itemsets are generated from  it by creating all the combinations of each items. When traversing the whole FP-tree, all the frequent itemsets are discovered.

The pseudo code of the FP-growth algorithm [11]  is depicted in Figure 1.

3. Graph-based Approach   The FIG algorithm is a novel method to find all the frequent itemsets quickly. It discovers all the frequent itemsets in only one database scan. The construction of the graphical structure is done in two phases, where the first phase requires a full I/O scan of the dataset and the second phase requires only a full scan of frequent 2-itemsets. The first initial scan of the database identifies the frequent 2-itemsets with a minimum support. The goal is to generate an ordered list of frequent 2-itemsets that would be used when building the graphical structure in the second phase. The FIG algorithm used to create a graphical structure is shown in Figure  2.

procedure FrequentItemGraph (Tree , F) scan the DB once to collect the frequent 2-itemsets and their support ascending add all items in the DB as the header nodes for each  2-itemset entry (top down order) in freq2 list do if  first item = item in header node then create a link to the corresponding header node i=3 for each  i-itemsets entry in the tree do call buildsubtree (F) end procedure  procedure buildsubtree (F) if first  i-1 itemset = itemsets in their their respective header nodes create a link to the corresponding header node i=i+1 repeat buildsubtree (F) end  procedure  Figure  2.  Pseudo code of the FIG algorithm      The first phase starts by arranging the entire database in the alphabetical order. During the database scan the number of occurrences of frequent 2-itemsets is determined and infrequent 2-itemsets with the support less than the support threshold are weeded out. Then the frequent 2-itemsets are ordered in the alphabetical order.

Phase 2 of constructing the graphical structure requires a complete scan of the ordered frequent 2-itemsets. The ordered frequent 2-itemsets are used in constructing the graphical structure.

Table. 1 Transactional Database  T.No Items  T1  T2  T3  T4  b e  a b c e f g  b c e f g  a c g  For illustration, we use an example with the transactions shown in Table. 1. Let the minimum support threshold set to 2. Various steps used in Phase 1 are shown in Figure 3. Phase 1 starts by accumulating the support for all possible 2-itemsets that occur in the transactions. Step 2 of phase 1 removes all non-frequent 2-itemsets, in our example (ab, ae and af), leaving only                                      the frequent 2-itemsets   (be ,ac, ag, bc, bf, bg, ce, cf, cg, ef, eg and fg). Finally all frequent 2-itemsets are sorted alphabetically to generate the sorted frequent 2-itemset list . This last step ends phase 1 of the generation of the graphical structure. Phase 2, which is used to generate the graphical structure  is shown in Figure 4. All the items a,b,c,e,f,g are assigned as separate nodes which acts as the root nodes for the graphical structure. All the frequent 2-itemsets ac, ag, bc, be, bf, bg, ce, cf, cg, ef, eg, fg are linked with the root nodes as child nodes based on the two items present in the corresponding frequent 2-itemset and assigned their corresponding support values. Next for generating the first frequent 3- itemset node, the first frequent 2-itemset node ac is compared with the second frequent 2-itemset node ag.

Since the first item of both the frequent 2-itemset nodes ac and ag are equal  the first item a is kept as common and the other two items c and g are added with a to form a frequent 3-itemset node acg. A link is made between the two frequent 2-itemset nodes ac and ag and the newly formed frequent 3-itemset node acg. The smallest minimum support among the two frequent 2-itemset nodes 2 is assigned for the newly formed frequent 3- itemset node acg. Next the first  a of the first frequent 2- itemset ac is compared with the first item b of the third frequent 2-itemset bc. Since the first item of both the frequent 2-itemsets are different  frequent 2-itemset                                      Figure 3. Generation of frequent 2-itemsets  Figure 4. Graph-based approach for finding all frequent itemsets     node ac is omitted and the search starts from the next frequent 2-itemset node ag .  Next the first item a of the second frequent 2-itemset ag  is compared with the first item b of the third frequent 2-itemset  bc.  Since the first item a   of the second frequent 2-itemset node ag  is not equal to the  first item b of the third frequent 2-itemset node bc , frequent 2-itemset ag is omitted and the search starts from the frequent 2-itemset node bc. The same process continues till the frequent 2-itemset node eg in the frequent 2-itemset  list.  Next for generating the frequent 4-itemset nodes , the first two items ac of the first 3-itemset node acg  is compared with the first two items  bc of the second 3-itemset node bce. Since the first two items of both the first two frequent 3-itemsets are not equal, frequent 3-itemset acg is omitted and the search starts from the second frequent 3-itemset bce.

Since  both the first two items of the corresponding frequent 3-itemset nodes bce  and bcf are equal, bc is kept common and the remaining third items e and f of both the frequent 3-itemset nodes are added to it to form the first frequent 4-itemset node bcef and the smallest minimum support among the two frequent 3-itemset nodes 2 is assigned for the first frequent 4-itemset node bcef . A link is made between the two frequent 3-itemset nodes bce and bcf and the newly formed frequent 4- itemset node bcef. The same process is continued  till the  frequent 3-itemset node efg  in the frequent 3- itemset list. For finding the first frequent 5-itemset node, the first 3 items bce of the first frequent 4-itemset node bcef is compared with the first 3 items bce of the second frequent 4-itemset node bceg. Since all the three items of the corresponding frequent 4-itemsets bcef and bceg are equal, bce is kept common and the remaining fourth items f and g of both the frequent 4-itemset nodes are added to it to from the first frequent 5-itemset node bcefg and the smallest minimum support 2 of the two corresponding frequent 4-itemset nodes bcef and bceg is assigned as the support for the first frequent 5-itemset node bcefg . A link is made between the two frequent 4- itemset nodes bcef and bceg  and the newly formed frequent 5-itemset node bcefg. The same process is continued till the frequent 5-itemset node befg. Since there is only one frequent 5-itemset node , the generation of frequent k-itemsets using the graphical structure ends here.

4.  Experimental Results   This section presents the results of the experiments conducted to study the performance of the proposed method. All experiments are performed on a 3.0 GHz Pentium IV PC machine with 512 MB main memory and 40 GB hard disk, running Windows XP Professional. The algorithms are implemented by using  Microsoft Visual Basic 6.0. The synthetic transactional datasets are from IBM Quest synthetic data generator [12]. All the experiments were conducted using T20I7D200k dataset. The naming conventions of the datasets are shown in Table 2. The T20I7D200k dataset consists of 1,00,000 transactions and 1,000 different items.

Table 2. Meaning of the parameters in the names of the datasets  Parameter Meaning T Average length of the  transactions I Average size of maximal  frequent itemsets D Number of transactions K Thousands   To test the behavior of the graphical structure  approach vis-?-vis different support thresholds, a set of experiments was conducted. The graph in Figure 5 shows that FIG algorithm is better than FP-growth in every support threshold. The pruning graph of FIG algorithm can prune many of candidate itemsets so that the time to create the next set of itemsets is reduced.

Figure 5. Runtime on T20I7D200K  Figure 6. Runtime on T20I7 with D100K through D1500K at the minimum  support threshold of 2.5%     Figure 6 shows the performance of both algorithms by using a T20I7 datasets and the minimum support is set to 2.5%. The number of transactions is increased from 100k to 1500k whereas a number of frequent itemsets is fixed. The FIG algorithm is better than the FP-growth algorithm.

In Figure 7 the peak memory sizes in  megabytes are illustrated as a function of a number of transactions when the average size of the maximal frequent itemsets is 7 and the average size of the transactions is 20. The minimum support threshold is set to 0.6%.  The memory requirement for FIG algorithm is less for all datasets with transaction sizes 50,100,150,200 and 250 when compared to FP-growth algorithm. The memory requirement of the FP-growth algorithm increases significantly with the growth of the number of transactions.

From this fact we can draw the conclusion that  several redundant nodes are in the FP-tree when increasing the number of the transactions. Its drawback is, however, that the memory requirement of the algorithm is huge. The memory requirement of the FIG algorithm depends only on the number of frequent 2- itemsets in the given transactions. Since FIG algorithm stores only the items needed for finding frequent 2- itemsets which are then used to form a tree in the main memory, the memory requirement of the FIG algorithm does not depend on the number of transactions.

5. Conclusion   Mining for frequent itemsets is a canonical task, fundamental for many data mining applications.

This paper proposes a new technique to improve an  efficiency of a procedure so called mining frequent itemsets.The graphical approach, called Frequent Item Graph approach presented in this paper generates all possible frequent k-itemsets  in the database by scanning the database only once. The advantage of our Frequent Item Graph  approach is the quick mining process that does not use candidates. Our contribution is a new way to mine all possible frequent k-itemsets by using the frequent 2-itemsets. We are currently studying the possibility of using hashing techniques to find the efficient frequent 2-itemsets in order to reduce the time and memory requirements to build a graphical structure.

6. References  [1] Agrawal, R. Imielinski, T. and Swami. Mining Association Rules between Sets of Items in Large Databases, Proc. of ACM SIGMOD, Washington DC, 22:207-216, ACM Press.

[2] Agrawal, R. and Srikant, R. Fast Algorithms for Mining Association Rules in Large Databases, Proc. 20th Intl Conf.

Very Large Data Bases, pp. 478-499, Sept. 1944.

[3] Park, J.S. Chan, M. and Yu, P.S. An Effective Hash-based Algorithm for Mining Association Rules, In Proc. of ACM SIGMOD, pp. 175-186. ACM, May 1995.

[4] Brin, S. Motwani, R. Ullman, J. and Tsur, S. Dynamic itemset counting and implication rules for market basket data, In Proc. of ACM SIGMO, pp.225-264, 1997.

[5]  Savasere, A. Omiecinski, E. and Navathe, S. An efficient algorithm for mining association rules in large databases, In Proc. of the 21st VLDB Conference, Zurich, Switzerland, 1995.

[6] Gopalan, R. and  Sucahyo, Y.G. Mining Frequent ItemsetsMore Efficiently, in Proceedings of 2002 International Conference of Fuzzy Systems and Knowledge Discovery, Singapore, 2002.

[7] Gopalan,R.  and Suchayo, Y.G. TreeTL-Mine: Mining Frequent Itemsets Using Pattern Growth, Tid Intersection and Prefix Tree, in Proceeding of 15th Australian Joint Conference on Artificial Intelligence, Canberra, LNAL, 2557, Springer, 2002.

[8] Sucahyo, Y.G. and  Gopalan, R. Efficient Frequent Item Set Mining using a Compressed Prefix Tree with Pattern Growth, in Proceedings of 14th Australian Database Conference, Adelaide, Australia, 2003.

[9] Gopalan, R. and  Sucahyo, Y.G. Fast Frequent Itemset Mining using Compressed Data Representation, in Databases and Applications (DBA ?2003), Innsbruck, Austria, Feb 10-13, 2003.

[10] Pei, J. Han, J. Lu, H. Nishio, S.and Tang, S. H-Mine: Hyper-Structure Mining of Frequent Patterns in Large Mining, ICDM, 2001.

[11] Han, J.  Pei, J. and Yin, Y. Mining Frequent Patterns without Candidate Generation, Proc. of ACM SIGMOD Conf., Dallas, TX, 2000.

