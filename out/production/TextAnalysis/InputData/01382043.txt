AN IMPROVED ALGORITHM OF MINING FROM FP-TREE

Abstract: Discovering association rules is a basic prnhlem in data  mining. Finding frequent item sets is the most expensive step in assnciation rule discovery. Analysing a frequent pattern gmwth (FP-growth) method is effieient and sealable for mining both long and short frequent patterns without candidate generation. And proposing a new efficient algorithm QFP-growth not only heirs all the advantages in FP-growth method, but also avoids it?s bottleneck in generating a huge nnmber of conditional FP-trees. By Using the technology of temporary mot, QFP-growth rednee the processing time and memory spaee for miniog frequent item sets significantly. Performance study also shows that the QFP-gmwtb method is effieient and scalable for mining large databases or data warehouses. Moreover, the algorithm generates frequent item sets in order so that the result can be used expediently.

Keywords:  fi.equent item sets  1. Introduction  Knowledge diseovery; data mining; assoeiation d e s ;  Association rule shows relationships among sets of items in a bansaction database. Association rule discovery has been an active research area since its introduction in (Agrawal, Imielinski and Swami 1993)[1,2].

The process of mining association rules consists of two main steps: 1) Find the frequent item sets or large item sets with a minimum support; 2) Use the large item sets to generate association d e s  that meet a confidence threshold.

Step 1 is the more expensive of the two since the number of item sets grows exponentially with the number of items. A large number of increasingly efficient algorithms to mine frequent item sets have been developed over the years.

Most of the proposed pattem-mining algorithms are a variant of Apriori [ 2, 3, 4, 5, 61, which is based on a bottom-up, breadth-fmt search that enumerates every single frequent itemset. Apriori uses the downward closure propeay of itemset support to prune the search space - the property that all subsets of a frequent itemset must themselves be frequent. Thus the essential idea is to  iteratively generate the set of candidate pattems of length &cl) from the set of frequent patterns of length k, and check their corresponding occurrence frequencies in the database.

The Apriori heuristic achieves good performance gained by (possibly significantly) reducing the size of candidate sets[7,8,9,10]. However, in situations with prolific frequent patterns, long patterns, or quite low minimum support thresholds, an Apriori-like algorithm may still suffer from the following two nontrivial costs[lll:  (1)It is costly to handle a huge number of candidate sets. For example, if there are lo4 frequent I-itemsets, the Apriori algorithm will need to generate more than IO? length-2 candidates, accumulate and test their occurrence frequencies. Moreover, to discover a frequent pattem of size 100, such as (al ,  ..., a100). it must generate more than 2??- IO? candidates in total. This is the inherent cost of candidate generation, no matter what implementation technique is applied.

(2)It is tedious to repeatedly scan the database and check a large set of candidates by pattern matching, which is especially hue for mining long patterns.

Recent studies show FP-growth[l,l I] algorithm is one of the most efficient frequent pattem mining methods. As a divide-and-conquer method, this method partitions (projects) the database into partitions recursively, but does not generate candidate sets. This method also makes use of Apriori property [2]: if any length pattern is not frequent in the database, its length superpattems can never be frequent.

It counts frequent pattems in order to decide whether it can assemble longer pattems.

The FP-growth method adopts the divide-and-conquer strategy as follows: a large database is compressed into a highly condensed, much smaller frequent pattem tree (or FP-tree for short), which is an extended prefix-@ee structure storing crucial, quantitative information about frequent patterns. Then an FP-tree-based pattern fragment growth mining method, is adopted, which starts from a frequent length-1 pattern (as an initial suffix pattem), examines only its conditional pattem base (a ?sub-database? which consists of the set of frequent items  0-7803-8403-2/04/$20.00Q2004 IEEE 1665 .

mailto:sdytqy@l63.com   co-occurring with the suffix pattem), constructs its conditional FP-tree, and performs mining recursively with such a tree. The pattem growth is achieved via concatenation of the suffix pattem with the new ones generated from a conditional FP-tree.

However, if we study the FP-growth method carefully, it also has performance bottleneck, and it must generate a huge number of conditional FP-trees recursively h process of mining, so the efficiency of FP-growth remains unsatisfactory. After some careful study and examination, we proposed a new improved efficient algorithm QFP-growth , and an extension of the FP-growth method, which not only heirs all the advantages in the FP-growth method, but also avoids it?s bottleneck in generating a huge number of conditional FP-trees. By using the technology of temporary root, the algorithm is compendious and satisfying in space and performance. QFP-growth reduces the processing time and memory space for mining frequent item se? significantly. Experimental results also show that QFP-growth is competitive.

The remaining of the paper is organized as follows.

Section 2 introduces the method of FP-tree construction and ?tn FP-tree-based frequent pattem mining algorithm, FP-growth. Section 3 presents our algorithm of QFP-growth. Section 4 discusses its scalability and perfomiance. Section 5 summarized our study and points out our some future research issues.

2. FP-Growth Algorithm  Xl. Frequent Pattern Mining Problem  The frequent pattem mining problem was fust introduced by R. Agrawal, et al. in [AIS931 as mining association rules between sets of items[l,2].

Let I = (al. a2, -, am] be a set of items, and a transaction database DB = (T1, T2, *-, Tn) , where Ti (i E [l..n]) is a transaction which contains a set of items in I.

Every transaction has a key label, called TID. The supportl (or occurrence frequency) of a pattem A, which is a set of items, is the number of transactions containing A in DB. A is a frequent pattem if the support of A is no less than a predefined minimum support threshold, 5. Given a transaction database DB and a minimum support threshold, 5, the problem of fmdmg the complete set of frequent patterns is called the frequent pattem mining problem.

22. FP-tree construction Algorithm  To avoid candidate-generation-and-test in Apriori, an Algorithm called FP-growth was proposed in  [ACM2000][1,111. the Algorithm based on the following observations:  1. Since only the frequent items will play a role in the frequent pattern mining, it is necessary to perform one scan of DB to identify the set of frequent items (with frequency count obtained as a by-product).

2. If we store the set of frequent items of each transaction in some compact structure, it may avoid repeatedly scanning of DB.

3. If multiple transactions share an identical frequent item set, they can be merged into one with the number of occurrences registered as count. It is easy to check whether two sets are identical if the frequent items in all of the transactions are sorted according to a fued order.

4. If two transactions share a common prefix, according to some iorted order of frequent items, the shared parts can be merged using one prefix structure as long as the count is registered properly. If the frequent items are sorted in their frequency descending order, there are better chances that more prefix strings can be shared.

Algorithm 1 (FP-tree construction)[ll] Input: A transaction database DB and a minium support threshold 5.

Output: Its frequent pattem tree, FP-Tree Method The F?-tree is constructed in the following steps.



I.  Scan the transaction database DB once. Collect the set of frequent items F and their supports. Sort F in support descending order as L, the list of frequent items.

2. Create the mot of an FP-tree, T, and label it as ?null?, for each transaction in DB do the following. Select and sort the frequent items in transaction according to the order of L.

Let the sorted frequent item list in transaction be [PIP], where p is the fxst element and P is the remaining list. Call insert-tree ([PIP], T).

Function insert-tree ([PIP], T) [If T has a child N such that N.item-name = p.item-name Then increment N s  count by 1; Else do [create a new node N, N s  count = 1; N s  parent link be linked to T; N s  node-link be linked to the nodes with the same item-name via the node-link structure;] If P is nonempty, Call insert-tree (P, N).

I  Example : Let the transaction database, DB, be Table 1 and 5 = 3. Table 2 is ordered frequent items after fmt scan of database. We can construct the FP-tree of Example database as Figure 1 .

P I I  (fcam:2), (cb:l)]  Table 1. A transaction database TID I Items  [(c:3)Jlp  Figure 1. FP-tree of Example database  23. Mining Frequent Patterns From FP-tree  The process of FP-tree mining is as follows: begin with the length-1 frequent pattern, construct its conditional pattern base, which is a ?sub-database? constructed with the prefix sub-path set co-occurring with the suffix pattern in the FP-tree. Then, construct its conditional FP-me, and mine recursively in this tree. The pattern growth is realized by linking the suffix pattern and its conditional FP-tree.

Algorithm 2 W-growth: Mining frequent patterns with FP-tree by pattern fragment growth)[Il].

Input: FP-tree, and a mini? support threshold 6 .

Output: The complete set of frequent patterns.

Method: call FP-growth(FP-tree, null).

Procedure FP-growth(Tree, a)  m b a C  [ (fca:2), (fcabl) J {(fca:2), (f:l), (c:l)J {(fc:3) JIb [ (fc:4)J { (fc:4))la { (t4) J  [ (fca:3) Jlm  { (t4) ]IC I f I Empty Empty  There are several advantages of FP-growth over other approaches: (1) It constructs a highly compact FP-tree, which is usually substantially smaller than the original database and thus saves the costly database scans in the subsequent mining processes. (2) It applies a pattern growth method which avoids costly candidate generation and test by successively concatenating frequent 1-itemset found in the (conditional) FP-trees. This ensures that it never generates any combinations of new candidate sets which are not in the database because the itemset in any transaction is always encoded in the corresponding path of the FP-trees. In this context, mining is not Apriori-like (restricted) generation-and-test but frequent ? pattern (fragment) growth only. The major operations of mining are count accumulation and prefur path count adjustment,      which are usually much less costly than candidate generation and pattem matching operations performed in most Apriori-like algorithms. (3) It applies a partitioning-based divide-and-conquer method which dramatically reduces the size of the subsequent conditional pattem bases and conditional FP-tree.

3.

conditional FP-trees construction  QFP-growth! miniig frequent pattern without  However, as discussed above, FP-growth algorithm must generate a huge number of conditional FP-trees recursively in process of mining, it may take too much time and space. Can we avoid conditional FP-trees generation in frequent pattern mining? To attack this problem, we develop QFP-growth, a extended FP-growth method for frequent pattem mining from FP-tree. The algorithm is described bellow.

fm3, fcm3, fcam3, fam3, cam3, cm3, am3, p3,cp3. There is no order in the frequent pattems serial. And By using QFP-growth algorithm, the frequent pattems are: f5,fc4,fca4,fcam3,fcm3,fa4,fam3,fm3,c5,ca4,cam3,cb3, m3, cp3, a4, am3,b4,m3,p3. The frequent pattems serial is ordered descending by head table of FP-tree.

3. To avoid more Conditional FP-tree constructing, FP-growth algorithm have to check whether a sub-tree is a single path tree, But in QFP-growth , because of no conditional FP-tree constructed, there is no reason to differentiate single path tree, so the algorithm is simplified.

4.The QFP-growth can be called only in condition of sum of count of temp-root?s child> minimum support this can reduce the call number of procedure evidently  Figure 2 to 5 show temporary root construction of example database.. Executing procedure of QFP-growth is showed in table 4. /  Algorithm 3 (QFP-growth: Mining frequent pattems with FP-tree by pattem fragment growth).

Input: FP-tree , and a minimum support threshold 6 .

Output: The complete set of frequent pattems.

Method: call QFP-growth(root, null). .

Procedure QFP-growth(RO0T Q, FPgrefix a) U)[ (2) for each item ai in Q, in top down order [ // Mining multipath FP-tree (3) sum all count of ai under Q (4) if ai .suppor~={ then { (5) generate pattern B = a U ai with suppor =ai .support; (6) conshuct temp-root with ai?s child node; (7) if temp-root bas child then call QFP-growth(temp-root, p); } (8) if sum of count of temp-root?s child>=c then call QFP-growth(temp-root, p); } (9) I  The improvement of QFP-growth algorithm: 1. Instead of building Conditional pattemlbase and  Conditional @-tree, QFP-growth algorithm simply construct a dynamic temporary root, so it can improve perfohance and efficiency.

2. In FP-growth algorithm, ?generate pattem B = ai U U with support = ai .support? ; but in QFP-growth algorithm. ?generatepattern B = U  U ai withsupper =ai .support? , The frequent pattems are generated in order, so they can be used expediently. For example, By using FP-growth algorithm, frequent pattems mined from FP-tree in figure 1 are: f5, c5, fc4,a4, fa4, ca4, fca4, b4, cb3, m3,  into ai .support,  Figure 2. Temporary mt after generating f4  Figure 3. Temporary root after generating fc4      FvmI, I ' W E L 3 FP _ _  ,- - ,,_____ _ _  .

4. Experiments and Results  The goal of the experiments is to find owthe extent of different dataset properties that could affect the performance of QFT-growth algorithms and the relative performance compares with FP-growth algorithm. Datasets are generated with the data generator by IBM QUEST.

FT-growth is provided by the original authors.

Experiments are performed on a Pentium 4 1.8GHz PC with 512Mb RAM running on Window XP. All programs are complied with the same compiler. Experimental results show that QFT-growth is competitive, it is efficient and scalable for mining large databases or data warehouses. See figure 5 and figure 6. Figure 4. Temporary root after generating f c d  No  1 -  CALLLEVELO I CALLLEvEL.1 1 CALLL-.,. , .,--I.

PARAM I F P  IPARAM I F P  I PARAM IFP  IPARAn' root(f5 c l )  "llll I f5 J I I I I I  - L root(c4,bl),f fc4 4 3 root(a4). fc f a 4  J 4 mt(m2.b2)fc8 4 " , 6 1  fCap2 x I 7 1  I I I I I  fcab2 x  f e d  J  I I I I I  in I I I 1 f n A J  I I I I 9 1  9 2  x      40 - 35  Z 30 E 25 = 20 2 15   U - C  t 0 0 5  1 1 5  2 2 5  3  Support threshold($8  Figure 5 .  Scalability of QFP-growth with respect to support with single run   I  E  t i 12  0 5  1 1 5  2  Supportthreshold (%)  Figure 6. Memory Comparison  5. Conclusions  We have proposed an improved method QFP-growth for constructing frequent pattems from FP-tree. Comparing with FF-growth metliod, QFP-growth can generate frequent pattems without condtional pattem-base and conditional FP-tree generation, and the frequent pattems are generated [ 121 www.cs.sfu.cd-peijianIpersonaYpublications.

in order. It can be used to mine frequent pattems efficiently in 1%: databases. Our future research works is to use the QFF-growth method into implementation of SQLbased, highly scalable Fp-bee structure, constraint-based mining of frequent pattems, sequential pattems, max-pattems, partial periodicity and other interesting frequent pattems mining.

Acknowledgements  This paper is supported by ShanDong Physical Science Foundation(Y2002G08).

