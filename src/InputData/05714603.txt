978-1-4244-9008-0/10/$26.00 2010 IEEE   78

Abstractas time advances new transactions are added to the  databases. The extensive amounts of knowledge and data stored  in databases require the development of specialized tools for  storing and accessing of data, data analysis and effective use of  stored knowledge of data. An incremental association rule  discovery can create an intelligent environment such that new  information or knowledge such as changing customer preferences  or new seasonal trends can be discovered in a dynamic  environment. The goal is to present how methods and tools for  intelligent data analysis are helpful in narrowing the increasing  gap between data gathering and data comprehension. There is a  greatest challenge in candidate generation for large data with low  support threshold. In this paper, we proposed Tree-based  Incremental Association Rule Mining (TIARM) algorithm to deal  with this problem. The proposed algorithm uses novel data  structure INC-Tree, it is an extension of FP-Tree to improve  storage compression and allow frequent pattern mining without  generation of candidate itemsets. Our algorithm allows mining  with a single pass over the database as well as efficient insertion  or deletion of transactions at any time. Experimental results  reveal that our proposed algorithm has better performance than  other algorithms.

Keywords-association rules; frequent itemset; TIATM; INC-  Tree;

I. INTRODUCTION  Data mining is also referred to as knowledge discovery of  databases. Databases contain large amount of data that grow or  shrink over time. Data mining has attracted much attention in  database research due to its wide applicability in many areas.

At present, research of data mining focus on classification,  clustering, association rule mining, and so on. Among the  various data mining applications, mining association rules is an  important one [1]. Association rule mining is a data mining  technique which discovers strong associations among data.

Given a collection of items and a set of transactions, each  transaction consists of items, an association rule is an  implication of the form X ? Y, where X and Y are sets of  items and X ? Y = . The support of this rule is defined as the  percentage of transactions that contain the set X, while its  confidence is the percentage of these X transaction that also  contain Y. In association rule mining, all items with support  higher than a specified minimum support are called large or  frequent itemsets.

The problem of mining association rules over customer  transactions and an example of a simple rule is 80% of  customers who purchase milk and bread also buy eggs was  introduced in [11]. Since discovering all such rules may help  market baskets or cross-sales analysis, decision making, and  business management, algorithms presented in this research  area include[11, 13]. These algorithms mainly focus on how to  efficiently generate frequent patterns and how to discover the  most interesting rules from the generated frequent patterns.

Several efficient algorithms have been proposed for finding  frequent itemsets and discovering most interested the  association rules from the generated frequent patterns. Most  present algorithms are based on Apriori and AprioriTid [4]  proposed by R. Agrawal. In this algorithm it takes multiple  passes over the database to search frequent itemsets. In the first  pass it counts support of individual items and determine  frequent itemsets. In each subsequent pass, it starts with a seed  of items found to be frequent in the previous pass. It uses this  seed set for generating new potentially candidate itemsets, and  counts the actual support for these candidate items during the  pass over the database. At the end of the pass, it determines  which of the candidate items are actually frequent and they  become seed for the next pass. This process continues until no  new frequent items are found. As a result, this algorithm  generates a large number of candidate items. However, when  support threshold is very little, and frequent itemset is very big,  then the efficiency is very low. The discovered association  rules may change when the database is updated. Some old rules    may no longer be interesting, while new rules may emerge.

Incremental maintenance of association rules involves a  technique that uses mostly only the updated part of the  database, not the original data plus the updated data to maintain  association rules. Han et al. [5] proposes a tree structure for  mining frequent patterns without candidate generation. The  advantage of FP-growth algorithm is, it can save much time-  space cost, but applying this technique directly to the problem  of incremental maintenance of association rules does not  produce optimal results as the new database needs to be re-  scanned for small item sets in the original database now  become frequent in the new database.

This paper presents new algorithm called TIARM (Tree-  based Incremental Association Rule Mining). It allows the user  for multiple frequent pattern mining without candidate  generation with different supports. The key contribution of this  paper is the development of a simple and efficient tree structure  for mining frequent patterns. In addition, transactions can be  added to or removed from the tree at any time. The rest of the  paper is organized as follows. A brief review of the related     work is given in section 2. Section 3 introduces the INC-Tree.

Tree-based Incremental Association Rule Mining (TIARM)  algorithm is introduced in Section 4. Section 5 presents some  experimental results. Finally, Section 6 contains conclusion.



II. RELATED WORK  Mining frequent patterns with only one database scan has  been a challenging issue since its introduction as a research  issue. Candidate-generation, say Apriori [1], and patter growth,  say FP-Growth [5], methods are the prominent classes of  algorithms found in literature. Even though candidate  generation is eliminated by FP-growth approach it cannot  reduce the number of database scans to one. With the  introduction of FP-growth algorithm many algorithms have  been proposed, some are AFPIM and CATS tree that have  adopted FP-tree for incremental mining of frequent patterns.

Koh and Shieh proposed Adjusted FP-tree for Incremental  Mining (AFPIM) algorithm [12]. This algorithm updates  previously constructed FP-tree that contains frequent item s  based on upper specified minimum support threshold minsup,  by scanning only the incremental part of the dataset. As items    are arranged in descending order of support count based on  original dataset, AFPIM re-sorts the items according to new  value of support count based on incremental dataset through  bubble-sort. There are two drawbacks of AFPIM 1.

Computational expensiveness of sorting process. 2. When new  frequent patterns emerge, as a result of scanning of incremental  dataset, AFPIM has to construct a new FP-Tree.

Compressed and Arranged Transaction Sequence Tree  (CATS) [3] specifies the limitations of AFPIM algorithm.

Unlike AFPIM, the CATS tree considers all the items in the  transaction for representation into tree, regardless of whether  items are frequent or not. This allows the CATS tree to  represent even new emerging frequent patterns from  incremental dataset. CATS arranges nodes based on their local  support count, which helps to achieve high compactness of the  tree. For incremental mining CATS tree updates existing tree  by considering the transactions of the incremental dataset one  by one and merging them with existing tree branches. CATS  tree has two limitations. 1. For each new transaction it is  required to find the right path for the new transaction to merge  in. 2. It is required to swap and merge the nodes during the  updates, as the nodes in CATS tree are locally sorted.

Although AFPIM [12] and CATS tree [3] are two  approaches to perform sequential incremental mining task with  only one database scan both of them are suffering from  computationally expensive tree construction steps.

In this paper, we proposed a new algorithm TIARM (Tree-  based Incremental Association Rule Mining) algorithm for  efficiently mining association rules in updated database using  the FP-tree structure.



III. INC - TREE  In the present study, we have developed a new data  structure, INC-Tree (INCremental Tree) it is an extension of  FP-tree. INC-Tree is constructed at a straightforward manner  of inserting every transaction in database one after another into  it. It prunes the constructed tree based on the support threshold  given by user.  Initially, the INC-Tree is empty and tree  construction with a null root node. Before inserting any  transaction, the transaction is preprocessed by sorting its items  according to items appearance order in the database and it  contains the frequency of each item in the database. INC-Tree  contains nodes representing items and total count of that item    in the path up to that node. New transactions are added at the  root level. The following is the sample database used in CATS  tree.

TABLE I.  SAMPLE DATASET                    Initially, INC-Tree is empty. Transaction 1 (F, A, C, D, G,  I, M, P) is added as it is. For Transaction 2 B, L and O are new  items, so they added at the end of the sort list in the order of  sequence original transaction. Transaction 2 is added to INC-  Tree after item C as another branch. The frequency count of  every item is updated along with the increment of count field of  each node of the transaction in tree. This process will be  repeated for remaining transactions. After constructing INC-  Tree nodes representing the same item are linked and the same  item in sort-list points to the first node in the tree.

The overall method for INC-Tree construction is:  1. Get the transaction.

2. Build sort-list as new item found in the transaction.

3. Sort original transaction according to order of sort-list.

4. Add the sorted transaction to INC-Tree.

5. Increment count value of each node.

6. Get next transaction.

TID Original Transaction  Sorted  Transaction  1 F,A,C,D,G,L,M,P F,A,C,D,G,I,M,P  2 A,B,C,F,L,M,O F,A,C,M,B,L,O  3 B,F,H,J,O F,B,O,H,J  4 B,C,K,S,P C,P,B,K,S  5 A,F,C,E,L,P,M,N F,A,C,M,P,L,E,N    Figure 1. INC-Tree for sample data     7. Repeat step 1 to 6 until no transaction found in  database.

8. Point each item in sort-list to corresponding node that  appear first in the tree and link the nodes of same item  all through the tree.

Association rule mining is a two step process [7]:  Frequent itemsets generation i.e. all the itemsets having  support greater than the user specified minimum  support.

Frequent itemsets generated in the step 1 will be used  to generate association rules that satisfy user specified  minimum support.

Since association rules are generated directly from  frequent itemsets, each rule automatically satisfies  minimum support.

After constructing INC-Tree, it can be used for mining  frequent patterns with different minimum support values. First  discard all the items from INC-Tree which are not satisfying  user given minimum support.  The sort-list is updated by  removing all infrequent items one after another and at the same  time the tree is pruned by deleting all nodes representing that  item. Pruned INC-Tree is shown in Fig. 2.



IV. TREE-BASED INCREMENTAL ASSOCIATION RULE  MINING (TIARM) ALGORITHM  Once INC-Tree is built, new transaction can be added to  and deleted from INC-Tree and frequent patterns can be mined  with different support values without rebuild the tree. TIARM  follows divide and conquer method to generate frequent  patterns without generating candidate itemsets as in FP-growth.

Steps of TIARM algorithm are:  TIARM (INC-Tree, min_supp)  If INC-Tree contains a single path P, then  For each combination (denoted as b) of the nodes in the  path P, then  Generate pattern b + a with support = min_supp of  nodes in b  Else for each a in the header of tree, do  {  Generate pattern b = a + a with support = a.support;  Construct  (1) bs conditional pattern base and  (2) bs conditional INC-Tree Treeb  If Treeb is not empty, then  Call TIARM(INC-Tree, b); }

V. EXPERIMENTAL RESULTS  All the experiments were conducted on 3.0 GHz Pentium  IV (Core to Dual) workstations running Windows XP  professional operating system configured with 2GB main  memory and 300 GB SATA 7200 rpm disk. Each experiment is  performed various times and best of them is taken. The  algorithm was coded in python2.6. To investigate performance,  we have used soybean dataset.

A. Dataset Description  Number of instances of Soybean dataset are 683. There are  19 classes, only the first 15 of which have been used in prior  work. The folklore seems to be that the last four classes are  unjustified by the data since they have so few examples. There  are 36 categorical attributes, some nominal and some ordered.

The value "dna'' means does not apply. The values for    attributes are encoded numerically, with the first value encoded  as "0,'' the second as "1,'' and so forth. An unknown value is  encoded as "?''. It consists of 683 records and its source is  agridataset.jar [8]. Here the task is to diagnosis soybean  disease.

Attributes are Date, Plant-stand, Precip, Temp, Hail, Crop-  hist, Area-damage, Severity, Seed-tmt, Germination, Plant-  growth, Leafspots-halo, Leafspot-marg, Leafspot-size, Leaf-  shread, Leaf-malf, Leaf-mild, Stem, Lodging, Stem-cankers,  Canker-lesion, Fruiting-bodies, External-decay, Mycelium, Int-  discolor, Sclerotia, Fruit-pods, Fruit-spots, Seed, Mold-growth,  Seed-discolor, Seed-size, Shriveling, roots, class.

B. Performance Comparison  In order to verify the performance of TIARM algorithm, we  compare it with FELINE and FP-growth.

Figure 3.  Scalability of TIARM with respect to number of transactions                                                 Three algorithms are developed in programming language  python 2.6. Each experiment is performed various times and  best of them is taken. Figure 3 shows the performance of FP-  growth, CATS and TIARM. From the figure 3 it is observed  that as the number of transactions increases with the minimum  support of 2, the time taken by TIARM also increases.

TIARM has best performance than CATS and FP- growth. It  is observed that as the size of the database increases the  performance of the TIARM algorithm decreases dramatically.

The performance of algorithm depends only on the size of  database but not support factor.



VI. CONCLUSION  We have presented and evaluated algorithm TIARM for  mining  frequent  item sets  from incremental databases.   Like                  FP-tree, INC-Tree contains only frequent items. Once INC-  Tree is built, it allows the user to mine database with different  support values using only one database scan.  The  experimental results show that this new algorithm works much  faster than FELINE and FP-growth.

