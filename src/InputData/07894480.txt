

Proceedings of the SMART -2016, IEEE Conference ID: 39669  College of Computing Sciences & Information Technology, Teerthanker Mahaveer University, Moradabad, India  Adaptive Apriori Algorithm for Frequent Itemset Mining  Shubhangi D. Patill , Dr. Ratnadeep R. Deshmukh2 and D.K. Kirange3 1 Department of Information Technology, Government Polytechnic, Jalgaon, India  2 Department of Computer Science and IT, Dr. 8abasaheb Ambedkar Marathwada University, Aurangabaad, India 3 Department of Computer Engineering, J. T. Mahcyan College of Engineering, Faizpur, India  E-mail: lsdkirange@gmail.com.2rrdeshmukh.csit@bamu.ac.in.3dkirange@gmail.com  Abstrac:l--Obtaining frequent itemsets from the dataset is one of the most promising area of data mining. The Apriori algorithm is one of the most important algorithm for obtaining frequent itemsets from the dataset. But the algorithm fails in terms oftime required as well as number of database scans. Hence a new improved version of Apriori is proposed in this paper which is efficient in terms of time required as well as number of database scans than the Apriori algorithm. It is well known that the size of the database for defining candidates has great effect on running time and memory need. We presented experimental results, showing that the proposed algorithm always outperform Apriori. To evaluate the performance of the proposed algorithm, we have tested it on Turkey student's database as well as a real time dataset.

Keywords: Database Scans, Apriori, Data Mining

I. INTRODUCTION  In Data Mining, for location and fascination of relations in variables in large databases, Association Rule Mining is a standard and well researched technique.

Before applying various data mining techniques such as classification, clustering and prediction, for data analysis, association rule mining is used. The association rule mining was first proposed by Agrawal et al. [1]. It is one of the most recommended research area which is applicable in most of the fields like analysis of market trends, forecasting and detection of faults. While analysis of the market trends, association rule mining is used to obtain all association rules like "Items X and Y are bought by the customer at the same time". Such rules are represented like X-> Y where X and Yare sets of items that from a transactional database. The percentages of transactions in the database containing X U Y define the support of association rule X -> Y. A database can be analysed by finding interesting relationships and patterns among items in the database by using association rule mining. The process of association rule mining is divided in two steps; first fmd all frequent items from the dataset and then discovering the relationships among the items in the database. Itemset denotes a set of items. Item sets with support count more than the minimum support threshold  Copyright ? SMART -2016 ISBN: 978-1-5090-3543-4  are referred as frequent item sets. Mostly the performance of the association rule mining is affected by the first step, as next step of association rule mining is simple [2].

Hence mostly association rule mining is mostly called as frequent itemset mining also.

The two most frequently used algorithms of association rule mining are Apriori and FP-Growth [3, 4].

Both of these algorithms are having different approaches for finding frequent item sets. The Apriori Algorithm generates the frequent item sets level wise using the apriori property. But the major drawback of the apriori algorithm is that more execution time is needed for generating the candidate item sets. Also the number of database sand required is more. The number od database scans required for FP growth is less as it creates the tree structure which is used for signatures of the transactions. signatures of transactions on a tree structure. Recently, a Matrix Apriori algorithm proposed by [5] takes the advantages of both Apriori and FPGrowth. The number of database scans is reduced in this proposed work because it creates signatures of itemset in the form of matrix. The overall performance of the algorithm is good as compared to FPGrowth [6]. Although in all of these improved versions of Apriori, the number of database scans required is less, but the time required is more. [7] While performing the association rule mining using Apriori algorithm, the first level candidate itemset are generated and then these are used to generate the second level candidate itemset and so on. The number of database scans as well as time required for frequent itemset mining is more in this case. An adaptive itemset mining is used to overcome this problem.

Here the frequent itemset for the last level are generated, and then all transactions contained in the last level are found. These transactions are copied for all lower levels also and new transaction database is created by deleting the already copied transactions for each subsequent level.

In this paper, Adaptive Apriori Algorithm is proposed as a new and efficient way for frequent itemset mining and compared with Apriori algorithm.

In this paper the Apriori algorithm is improved in terms of time required as well as number of database     College of Computing Sciences & Information Technology, Teerthanker Mahaveer University, Moradabad, India  scans. The intermediate dynamic dataset is created separately using MATLAB by using the database transactions at each level separately. Thus instead of scanning the entire database, we need to scan only the extracted rows and columns at each level. The proposed improved Apriori algorithm outperforms the basic Apriori because at each level , the transactions with minimum support are eliminated. Hence not considered for higher levels. This helps to reduce the size of the database at each level which saves a lot of time, and a noticeable improvement in the speed by reducing the frequent database scans.

11. RELATED WORK  One of the mostly used algorithms in association rule mining is the Apriori algorithm. In this algorithm the high dimensional frequent item sets are obtained using the low dimensional frequent item sets. The process is iterative.

But the basic Apriori algorithm faces some major drawbacks such as the number of database scans required is more. This results in the I/O overburdened; the process of obtaining frequent item sets at the higher level from the lower level needs more time as the number of itemsets are more at the lower level. ; the basic Apriori algorithm should not consider the transactions that need not scan.

Most of the researchers have proposed the various improved versions of the Apriori algorithm.

In the DHP algorithm proposed by Park et al. [8] the algorithm is based on dynamic hash hashing algorithms and pruning algorithm. Here the transactions that are not involved in generating frequent item sets are not considered while traversing the database. Thus the efficiency for frequent itemset mining is improved.

The dynamic itemset counting algorithm proposed by Brin [9] requires less number of database scans. In this algorithm the transaction database is divided in to data blocks of same size. These information squares are gotten to for producing the I-incessant itemsets then the hopeful 2-successive item sets independent from anyone else join, finally it consolidates the I-continuous itemsets and competitor 2-reguJar item sets that every piece created. The procedure is rehashed until there is no new itemsets or achieve the breaking point.

These algorithms are able to perform well when the size of the database is small or the dimensionality of the data is not so high. But while considering the big data, these algorithms can not perform well. MapReduce[lO] framework produced by Googlein 2004 is able to handle the big data. In the similar way, Hadoop based on MapReduce, cluster based parallel data mining are some of works for big data mining. Various classical data mining algorithms are based on Hadoop. Various parallel algorithms using Apriori such as SPC, FPC and DPC [11] are proposed by Lin et al. These are based on MapReduce.

In the SPC algorithm the dataset is mapped to all Map nodes and mining is performed parallelly. Afterwards the combining operation is executed in the reduce phase. SPC algorithm required to start the map and reduce phase only once. The DPC and FPC algorithm needs to repeatedly start the Map and Reduce phase. The process is defined by the number of dimensions of the frequent item sets mining;  The parallel frequent item set mining algorithm proposed by Li et al [12] scans the transactions database for counting the frequent item sets in the Map stage, and the statistical operations are performed for obtaining frequent item sets in the Reduce phase, but But this algorithm also required to start MapReduce tasks repeatedly. S. Hammoud [13] proposed a parallel in each round of the iterative procedure, where cut datasets are alloted to every Map hub and measurable competitor incessant item sets, then converging to get continuous itemsets in the Reduce stage. As a result of the MapReduce system's high dormancy and absence of emphasis, Apriori calculation doesn't fit the MapReduce structure well. Spark is a memory-based parallel registering system, and it can incredibly enhance the ongoing information handling and guarantee the group's high adaptation to internal failure and high versatility [14] in enormous information situations.

A parallel Apriori algorithm was introduced by Qiu H et al which is related to Spark YAFIM [15]. The results obtained using SPARt are more promising than that using Hadoop.

Ill. THE APRlORI ALGORITHM  A. Apriori Algorithm  Apriori algorithm was the first algorithm for finding the frequent item sets and association rule mining. The Apriori algorithm is divided in two major steps: join and prune.

The new candidate seta is generated in the join step.

Depending on the support count, the candidate set can be defined as frequent or infrequent. For generating higher level candidate itemsets (Ci) previous level frequent itemsets Li-l are joined. In the pruning step, the infrequent candidate item sets are filtered out. This step ensures that every subset of a frequent itemset is also frequent. Hence, if the candidate item set contains more infrequent item sets, will be removed from the process of frequent itemset and association mining. [4] This process is called pruning.

1) Apriori Algorithm Input D. , a database of transactions Min_sup, the  minimum threshold support Output L.K. Maximal frequent item sets in D Ck Set  of Candidate k-itemsets.

Copyright ? SMART -2016 ISBN: 978-1-5090-3543-4    Method: ? L1 = Frequent items oflength l.

? For (k = 1; Lk! = <\>; k ++) do.

? Ck + 1 = candidates generated from Lk.

? For each transaction t in database D do.

? Increment the count of all candidates in Ck + 1  that are contained in t.

? Lk + 1 = candidates in Ck + 1 with minimum  support ? End do ? Return the set Lk as the set of all possible  frequent item sets The main notation for association rule mining that is  used in Apriori algorithm is the following: ? A k -itemset is a set ofk items.

? The set Ck is a set of candidte k-itemsets that  are potentially frequent.

? The set Lk is a subset of Ck and is the set of  k-itemsets that are frequent.

2) Drawbacks of Apriori Algorithm  ? The Apriori algorithmic program takes longer time for candidate generation technique.

? The Apriori algorithmic program needs many scans of the database.

? Many trivial rules are derived and it will be hard to extract the most interesting rules.

? Rules can be inexplicable and fme grained.

? Redundant rules are generated.

B. Adaptive Apriori Algorithm  The Adaptive Apriori algorithm proposed here is able to overcome the basic Apriori algorithm in terms of number of database scans as well as time required. The size of the database is reduced at each level. This algorithm uses a dynamic technique to reduce the time required for candidate itemset generation. It is claimed that the size of the database is reduced at each level starting from last to first and hence the time required for candidate itemset generation is reduced as compared with basic Apriori algorithm. Here we generate the dynamic intermediate database for each level separately.

For example, when scanning each transaction in the database find all the transactions which contain all items.

These transactions are considered for generation for level K itemset. The same transactions are also considered for generating level 1 to level k-I itemsets. So these are copied for all these levels. Now the database is updated by deleting all these transactions. This updated database is again considered for generating level L k-I itemsets.

Hence the size of the database is reduced at level of candidate itemset generation as well as the time required is also minimized.

Copyright ? SMART -2016 ISBN: 978-1-5090-3543-4  Adaptive Apriori Algorithm for Frequent Itemset Mining  3) Algorithm  Input D, a database of transactions Min_sup, the minimum threshold support  Output Lk Maximal frequent item sets in D Ck Set of Candidate k-itemsets.

Method: ? Generate the Intermediate Database  ? Find all transactions to be considered for level K containing all item sets.

? Copy these transactions in the database to be considered for level 1 to K  ? Delete these transactions from the database D and update the database.

? Now consider this updated (reduced in size) database for finding all transactions for level 1 to K-I  ? Repeat the steps subsequently and update the database.

? Consider this updated database for candidate itemset generation at each step.

? L1 = Frequent items oflength l.

? For (k = I;Lk! = <\>;k ++) do.

? Consider D as intermediate updated database for  level k ? Ck+ 1 =candidates generated from Lk.

? For each transaction t in database D do.

? Increment the count of all candidates in Ck+ 1  that are contained in t.

? Lk+ 1 =candidates in Ck+ 1 with minimum  support ? end do ? Return the set Lk as the set of all possible  frequent item sets ? In this algorithm, the intermediate database is  generated to reduce the time required for candidate itemset generation.

C. An Example of Adaptive Apriori Algorithm  Assume that a large bookstore sales data by stock keeping unit (SKU) for each item, such as "Scale", "eraser", "Book", "Pencil", "Pen", "Paper" is identified by a numerical SKU The bookstore database contains the transactions which are a set of items purchased together.

At the particular time, consider the transaction database as shown in Table l. Firstly, scan all transactions which are required to get frequent K itemset. Copy all these transactions from database to the intermediate database for level 1 to K. Remove all these transactions from the original database. Now again scan the new updated database to find the transactions that are needed to build frequent K-I itemset. Again modify the intermediate database from level I:K-Iand remove the related transactions from the database. At each step of candidate     College of Computing Sciences & Information Technology, Teerthanker Mahaveer University, Moradabad, India  itemset generation we get the reduced database which helps to improve the running time ofthe algorithm.

T ABLE I: THE TRANSACTIONS  Sr. Transaction ID Itemsets No.

I Tl Paper, Pen 2 T2 Paper, Pencil, Scale 3 T3 Book, Eraser 4 T4 Eraser, Scale, Pen 5 T5 Pencil , Paper 6 T6 Paper, Eraser, Scale, Book 7 T7 Paper, Eraser, Scale, Book, Pen,Pencil  Now the transaction database is scanned to find the transactions that can be used for generating frequent item sets at level K = 6. Such transaction is T7 in the above example which contains all the items. So this transaction is removed from the dataset and copied for intermediate database level 1 :K.-1 (1 :5)  Similarly intermediate database is constructed for all levels as shown in Table 2 to 8.

T ABLE 2: INTERMEDIATE DATABASE FOR LEVEL K = 6  Itemsets Pa er, Eraser, Scale, Book, Pen, Pencil  T ABLE 3: INTERMEDIATE DATABASE FOR LEVEL K = 5  Itemsets Paper, Eraser, Scale, Book, Pen, Pencil  T ABLE 4: INTERMEDIATE DATABASE FOR LEVEL K = 4  Sr. No. Transaction ID Itemsets 6 T 6 Paper, Eraser, Scale, Book 7 T7 Paper, Eraser, Scale, Book, Pen, Pencil  TABLE 5: INTERMEDIATE DATABASE FOR LEVEL K = 3  Sr. No. Transaction ID Itemsets 2 T2 Paper, Pencil, Scale 4 T4 Eraser, Scale, Pen 6 T6 Paper, Eraser, Scale, Book 7 T7 Paper, Eraser, Scale, Book, Pen, Pencil  TABLE 6: INTERMEDIATE DATABASE FOR LEVEL K = 2  Sr. No. Transaction ID Itemsets I Tl Paper, Pen 2 T2 Paper, Pencil, Scale 3 T3 Book, Eraser 4 T4 Eraser, Scale, Pen 5 T5 Penci l, Paper 6 T6 Paper, Eraser, Scale, Book 7 T7 Paper, Eraser, Scale, Book, Pen, Pencil  TABLE 7: INTERMEDIATE DATABASE FOR LEVEL K = I  Sr. No. Transaction ID Itemsets I Tl Paper, Pen 2 T2 Paper, Pencil, Scale 3 T3 Book, Eraser 4 T4 Eraser, Scale, Pen 5 T5 Pencil , Paper 6 T6 Paper, Eraser, Scale, Book 7 T7 Paper, Eraser, Scale, Book, Pen, Pencil  Now by considering this newly constructed intermediate database at each level , firstly, check all transactions to get successive 1-itemset Ll containing the   items and their support count and the exchanges ids that contain these things, and afterward take out the competitors that are rare or their backing are not exceeding the min_ sup as appeared in Table 2. The frequent 1-itemset is shown in Table 3.

Table 8 shows the candidate itemset generated at level 1 using intermediate database for level 1  TABLE 8: CANDIDATE IITEMSET  Sr. No. Items Support I Paper 5 2 Pen 3 3 Pencil 3 4 Eraser 4 5 Scale 4 6 Book 3  Table 9 shows frequent 2 itemset generated using the intermediate table for level K = 2  TABLE 9: CANDIDATE IITEMSET  Sr. No. Items Support I Paper, Pen 2 2 Paper, Eraser 2 3 Paper, Scale 3 4 Paper, Book 2 5 Pen, Eraser 2 6 Pen, Scale 2 7 Pen, Book I 8 Eraser, Scale 3 9 Eraser, Book 3 10 Scale, Book 2  Now to generate the frequent 3 item set, we need to consider only the intermediate database created for level 3.

As can be noted here the size ofthe database is reduced to 4 only. Thus the proposed adaptive Apriori algorithm helps to improve the running time ofthe program.



IV. ANALYSISANDEVALUATlONOF THE ADAPTIVE ApRlORl  Apriori Algorithm used to check the database thrice yet this paper exhibits a change on it by utilizing versatile calculation and the idea of moderate database scans. The examination demonstrates that the time expended and number of database outputs required in enhanced Apriori in each group of transactions is less than the first Apriori.

The memory space is lessened by utilizing the dynamic database approach which segments the first database at first and select one specific database out of this. It is a change as prior the calculation took exponential time however now it is decreased incredibly.

A. Analysis and Evaluation of the Adaptive Apriori for Number of Database Scans  The first experiment compares the number of database scans of original Apriori, and our improved algorithm by applying the Turkiye student's evaluation  Copyright ? SMART -2016 ISBN: 978-1-5090-3543-4    database [16] for facuIty 1 in the implementation. The 100 transactions considered here for analysis. The result is shown in Fig. 1. Table 10 shows that the improved Apriori reduce the number of database scans from the original Apriori.

TABLE 10: SUPPORT vs, NUMBER OF DATABASE SCANS FOR TURKlYE FACULTY I  Sr. No. Support Number of Database Scans Apriori Adaptive Apriori  I 0.1 580 297 2 0.2 580 297 3 0.3 580 297 4 0.4 580 297 5 0.5 580 297 6 0.6 580 297 7 0.7 580 297 8 0.8 580 297 9 0.9 580 297 10 1.0 7 7   ~ 400 en  , , , , , \ \ \ I  i~ \ o I ~ I  ~ 200 ---. --- -. ------- ------- - - ------- IIII!, \ Z \ \   , , \ \ , \  \1 olL--~--~--~--~--~~~~~~--~,0  Support  q FP Growth tJ Basic AP.f iori . ' Adapt ive Basic Apriori  Apriori  Fig. I Number of Database Scans for Different Values of Support for Turkiye Database Faculty I  Figure 2 shows the improvement of the proposed apnon algorithm for Turkiye student's evaluation database for faculty 2. By considering 100 transactions from the database. Table 11 shows that the improved Apriori reduce the number of database scans from the original Apriori.

TABLE 11: SUPPORT vs, NUMBER OF DATABASE SCANS FOR T URKlYE FACULTY 2  SrNo. Support Number of Database Scans Apriori AdaDtive ADriori  I 0.1 579 302 2 0.2 579 302 3 0.3 579 302 4 0.4 579 302 5 0.5 579 302 6 0.6 579 302 7 0.7 579 302 8 0.8 579 302 9 0.9 296 154 10 1.0 7 7  Copyright ? SMART -2016 ISBN: 978-1-5090-3543-4  Adaptive Apriori Algorithm for Frequent Itemset Mining  Performance Evaluation  600 11- - -0 - - 0- - -0 -- 0 - - -0 - - 0 - - "Cl \ \  500 \ \ \ \  400 \ \ \ \ = 0  \ \ ---. --_ .. ---. --- .---.--- . ---. , \ = , \ , \ , \ . \  ? , \ , \ ,\ OlL--~~--~--~5--~~~-7--~~,0  Support  q FP Growth [J Bas ic,ARrio,ri _ . ' Adapt ive BaS IC Apnon Aprior i  Fig. 2: Number of Database Scans for Different Values of Support for Turkiye Database Faculty 2  Table 12 shows that the improved adaptive apriori reduces the number of database scans as compared to original apriori for faculty 3.

TABLE 12: SUPPORT vs. NUMBER OF DATABASE SCANS FOR T URKlYE FACULTY 3  Sr. No. Support Number of Database Scans AJlI'iori Adaptive Apriori  I 0.1 518 280 2 0.2 518 280 3 0.3 518 280 4 0.4 518 280 5 0.5 518 280 6 0.6 518 280 7 0.7 518 280 8 0.8 455 280 9 0.9 144 92 10 1.0 6 7  B. Analysis and Evaluation of the Adaptive Apriori for Execution time  The second experiment compares the execution time original Apriori, and our improved algorithm by applying the Turkiye student's evaluation database for faculty 1 in the implementation.

Performance Evaluation  7 - -u - -u- - -u- - w - ' -w- ' - w - --u---o..: ---.. --.. ---.. --.. - - -.--- . - --.-- - ~ 600 _ \\  \ } 400 \\  ~300 .= \   = 11- - -0 --0- - -0-- 0 -- -0--0 -- -0---0 , \  100 \ ' \  O ,~-7--~--~-75--~~~-7--~~1O  Support  q FP Growth IJ Bas ic.ARrio,r i , . ' Adapt ive BaSIC Aprlorl A "  priOri  Fig. 3: Execution Time for Different Values of Support for Turkiye Student's Evaluation Database for Faculty I     College of Computing Sciences & Information Technology, Teerthanker Mahaveer University, Moradabad, India  The 100 transactions considered here for analysis.

The result is shown in Fig. 3. Fig. 3 shows that the improved Apriori reduce the execution time from the original Apriori.

Figure 4 shows that the improved Apriori reduce the execution time from the original Apriori for Turkey faculty 2 dataset.

Performance Evaluation  ..o -- C-_ ..Q. _ - o- - ~ 500 fJ.... ..... '0 - - 0""' ..... ? _ _ _____ _ __ - _', .. _- ' '-  ~   l300  -- " - ...... __ .. ..... ,\ " " II  ,I II II  ~ ~ ~ .

200 t tr _-<:t --O-- -O-- C---O-- - O-- .q, l   , .. , "\ , \ h _\  0,L--~--~~~-75--~--7-~~~--~'0  Support  q FP Growth tJ Basic AWiori . ' Adaptive Basic Apriori  Apriori  Fig. 4: Execution Time for Different Values of Support for Turkiye Student' s Evaluation Database for Faculty 2  Performance Evaluation 2000,--~--~--~~--~--~~~~-  1800 p.. - -0 - - 0- - -c- - - 0 - - -0- - - 0 - - -q I  160C ___ ? ? _ _ ?? ____ ___ ? ___ ? ___ ? ___ .~ ......

I .... .

\ \ -,: 1200 . ~  I I I I I \ I \ ~ 1000 \ I E  t= 800 \ I I \ I I I I I I   400 \ \  ,AI- - -o--o- - -c- --o-- -o-- - o-- -o., \ ~ 20u '~ :  o ~ ~ 1 5 10  Support  q FP Growth tJ Basic AWiori . ' Adapt ive Basic Apriori  Apriori  Fig. 5: Execution Time for Different Values of Support for Turkiye Student' s Evaluation Database for Faculty 3  Figure 5 shows that the improved Apriori reduce the number of database scans from the original Apriori for turkey faculty 3 dataset.

C. Analysis and Evaluation of the Adaptive Apriori for Real Time Data  We have gathered the real time faculty evaluation data from 393 students of faculties from J.T. Mahajan College of Engineering, Faizpur. We have compared the   execution time as well as number of database scans of original Apriori, and our improved algorithm by applying the real time database implementation.

Table 13 shows that the improved adaptive apriori reduces the number of database scans as compared to original apriori for real time dataset.

TABLE 13: SUPPORT vs, NUMBER OF DATABASE SCANS FOR REAL TIME DATASET  Sr. No . Support Number of Database Scans AJ!!'iori Adaptive Apriori  I 0.1 2492 1017 2 0.2 2492 1017 3 0.3 2492 1017 4 0.4 2492 1017 5 0.5 2492 1017 6 0.6 2492 1017 7 0.7 2492 1017 8 0.8 2490 1017 9 0.9 1069 435 10 1.0 28 22  Table 14 shows that the improved adaptive apriori reduces the execution time as compared to original apriori for real time dataset.

TABLE 14: SUPPORT vs. TIME FOR REAL TIME DATASET Sr. No. Su~ort Execution Time  A~riori Adaptive Apriori I 0.1 2764.4949 2166.3458 2 0.2 2776.5642 2164.0938 3 0.3 2789.4587 2162.6268 4 0.4 2773 .9934 2166.7127 5 0.5 2768.8197 2167.2221 6 0.6 2771.1176 2187.1428 7 0.7 2819.0367 2182.2447 8 0.8 2044.3822 1750.3789 9 0.9 56.3806 58.8522 10 1.0 0.24622 0.99224

V. CONCLUSION  Association rule mining plays the major role in the field of data mining. The association rule mining is divided in two steps. Firstly it finds all frequent item sets and then it generated the association rules. Apriori algorithm is one of the most important algorithms proposed for frequent itemset mining. But the Apriori algorithm required more time for generation of frequent itemsets as well as the number of database scans is more.

In this paper the improved Apriori algorithm is proposed which is more efficient in terms of time as well as number of database scans. In this algorithm, the intermediate database is created at each level. Hence scanning the entire database at each subsequent level is avoided. Which reduces the time required for candidate item set generation as well as the number of database scans. The performance of the proposed algorithm is evaluated using the Turkiye standard student faculty evaluation dataset as well as the real time dataset.

