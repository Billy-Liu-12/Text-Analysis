Optimize Association Rules using Artificial Bee Colony Algorithm with  Mutation

Abstract - In data mining, Association rule mining is one of the popular and simple method to find the frequent item sets from a large dataset. While generating frequent item sets from a large dataset using association rule mining, computer takes too much time. This can be improved by using artificial bee colony algorithm (ABC). The Artificial bee colony algorithm is an optimization algorithm based on the foraging behavior of artificial honey bees. In this paper, artificial bee colony algorithm is used to generate high quality association rules for finding frequent item sets from large data sets. In general the rule generated by association rule mining technique do not consider the negative occurrences of attributes in them, but by using artificial bee colony algorithm (ABC) over these generated rules, the system can predict the rules which contains negative attributes. Proposed methodology is compared with K-nearest neighbors (KNN) algorithm and standard ABC algorithms.

Keywords: Artificial bee colony (ABC), Association rule, Support, Confidence, Frequent item set, Data mining.



I. INTRODUCTION   Now a days, growth of databases increase day-by- day due to the number of requirements or number of customers or end users. In this scenario, data mining [2, 9] plays an important rule for mining data according to the customer?s requirements.

Association rule mining is one of the popular and well known research methods for discovering interesting relationships between variables in large information repository or databases. Paper [1] describes how data mining and knowledge discovery are related to different fields like machine learning; statistics etc. genetic algorithm [5] based  association rule finding is also discussed in paper [3]. For finding association rules, minimum support value plays an important rule. Paper [4] present a genetic algorithm based strategy for discovering association rules without specifying the value of minimum support. Many techniques have been proposed to optimize association rules [6, 7]. Also genetic algorithm based techniques [10, 11] have proposed previously.

In this paper, Artificial bee colony algorithm with mutation operator based association rule optimization technique has proposed.

The remainder of this paper is organized as follows.

Section 2 explained the artificial bee colony algorithm with mutation.  In section 3, Association rule mining is explained.  Proposed methodology is explained in section 4. Experimental results and parameter setup for result comparison are shown in section 5. Finally, section 6 concludes the paper.



II. ARTIFICAL BEE COLONY ALGORITHM WITH MUTATION  In paper [9], one more phase in the form of mutation operator of genetic algorithm is added to original Artificial Bee Colony algorithm. In standard ABC algorithm, there are only 4 phases that described the overall working of this algorithm, but here one additional phase after the employed bee phase of ABC algorithm is added in the form of Mutation operator. Now modified artificial bee colony algorithm has five phases: first initialization phase then employed bee phase, Mutation phase, onlooker bee phase and finally scout bee phase. For   DOI 10.1109/ICCUBEA.2015.77     the local search, employed bee phase is used and the mutation phase is used to find out the new search area of the solution space. With the help of mutation mutation operator, there may be a possibility to change the local best position and the algorithm may not be trapped into local optima. In this work, the mutation phase is implemented on the probabilistic way in each iteration for searching food source during the life process of ABC optimization technique. Food sources are selected randomly from the food size to perform mutation operation. In mutation phase, if generated offspring?s fitness is greater than the older one then replaces the older offspring?s from the new one. Uniform mutation is used in this work.

The overall algorithm is described in following steps:  ? Initialization phase.

? REPEAT  (a) In the Memory,  Employed bees are placed on the food sources;  (b) Generate new offspring from older offspring after Applying mutation operator.

(c) In the memory, onlooker bees are placed on the food sources;  (d) For finding new food sources, Send the scout bee to the search space.

? UNTIL (requirements are not met).



III. ASSOCIATION RULE MINING   The mail aim of association rule mining is to  extract frequent item sets, correlation and association among different set of items in the transactional database, relational databases or other information repository.

Association rule mining algorithm finds association rules in the form of:   IF  AB and CD then HELLO IF  UV and XY then BYE  Here AB, CD, UV and XY are different objects out of which if any person takes AB and CD then due to high propbility, he will take HELLO. Similarly if he will choose UV and XY then he will choose BYE.

In general, expressions which are in the form of A=>B, called association rules where A represents antecedent and B represents consequent.

Association rules represent how many times B has occurred if A has already occurred depending on the chosen support and confidence value. Here support is nothing but the probability of items or item sets in the given database (like transactional or other) and confidence represents conditional probability.

Apriori Algorithm:   In general, Apriori algorithm [8] works on two phases ? first phase is to choose minimum support value which is applied in the database to find frequent item sets while in second phase, these item sets and the minimum confidence constraints are used to generate rules.

The pseudo code for the Apriori algorithm are given as follows - Step 1: let Cn be the candidate item set of size n.

Step 2: let Fn be the frequent item set of size n.

Step 3: F1 = {Frequent items} Step 4: REPEAT Step 5: Cn+1 = Candidates generated from Fk ; Step 6: REPEAT for each transaction t in database Step 7: increment the count of all candidates in Cn+1 that are contained in t.

Step 8 : Fk+1 = Candidates in Cn+1 with minimum support.

Step 9: UNTIL ( Fn not equal to  ) Step 10:  return Un Fn

IV. PROPOSED METHODOLOGY  This section represents proposed methodology.

Here ABC with mutation algorithm is applied over the rules gathered from apriori algorithm, to find frequent item sets.

In order to use the ABC algorithm with mutation, the following points must be addressed: initial population, fitness value, employed, onlooker, mutation and scout bees. Here Initial population is generated using randomly generated transactions. To calculate the fitness value of an individual, following fitness value is used-  fi =   1 / (1 + fi )     if fi >= 0     1 + abs (fi)     otherwise  Other points are same like standard ABC algorithm, discussed above.

The steps of proposed algorithm for generating optimal association rules via ABC with mutation are as follows-  Step 1: Start  Step 2: Load dataset  Step 3: Find frequent item sets using apriori algorithm. Suppose F is the set of all frequent item sets generated by apriori algorithm and X is the output set, containing all generated association rules, initialized to zero.

Step 4: Set the termination condition for the ABC with mutation algorithm.

Step 5: Depict each item sets of Z and apply ABC with mutation algorithm on selected members to generate association rules.

Step 6: Evaluate fitness value of each rule.

Step 7: If the fitness function satisfied the desired criteria then add these rules in output set.

Step 8: if the desired number of generations not completed then goto step 3  Step 9: Stop  Block diagram of proposed work:  Block diagram of the proposed algorithm for optimizing association rules are given below and shown in figure 1.



V. EXPERIMENTAL RESULTS & PARAMETER SETUP   1. Data Sets : To check the performance of the proposed work, different datasets are selected from UCI machine learning repository. Currently, 187 datasets are maintained by UCI machine learning research group.

Out of these datasets, three popular datasets of  Voting, Iris and Wine are selected for our experiments.

Fig 1 shows the block diagram of proposed algorithm      Details of these datasets are given below ? ? Voting dataset ?     Features =16  Instances = 435 Class = 2  ? Wine dataset ?       Features =13 Instances = 178 Class = 3  ? Iris dataset ?          Features =04 Instances = 150 Class = 3  2. Parameter Settings:   There are four main control parameter which are used to test the performance of proposed algorithm.

First control parameter is the number of food sources  Start  Load Dataset  Apriori algorithm applied on dataset  Frequent item sets  Apply proposed algorithm  Association rules optimized  Stop     which is equal to 20 and also it is equal to the number of employed bees and onlooker bees. Second control parameter is the maximum cycle number (MCN) which is equal to 2000 in this experiment. Third and the fourth control parameter are the mutation probability which is equal to 0.1 and the limit value.

After the final rule has generated, two control parameter for class prediction are quality weight (? ) and coverage weight ( ?), both are initialized to 0.5 in this experiment.

Proposed work is compared with KNN algorithm and standard ABC algorithm. Table 1 shows the performance classification accuracy. Figure 2 shows the graphical comparison between different algorithms.

TABLE 1: PERFORMANCE ACCURACY OF CLASSIFICATION    Datasets KNN (%) ABC (%) Proposed Work (%)  Voting 95.10 97.21 97.89  Iris 94.08 96.44 98.6  Wine 96.22 98.13 98.88        Figure 2 shows the performance of proposed work

VI. CONCLUSION   Now days, the size of the databases are increased day?by-day. To find frequent item sets, there is a need of association rule mining. In this work, generated association rules using apriori algorithm are optimized using artificial bee colony with mutation algorithm. To check the performance of proposed work, three datasets of voting, wine and iris  are used, collected from UCI machine learning repository. Experimental results show that the performance of the proposed work with previously proposed works. Future work is to use the proposed work with different databases.

