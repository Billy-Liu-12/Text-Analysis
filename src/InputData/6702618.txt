Distance-Aware Virtual Cluster Performance Optimization: A Hadoop Case Study

Abstract?Cloud computing and big data are becoming two important developing trends in information technology area.

However, data-intensive computing has some challenges to work well on virtual machines in cloud computing for virtualized resource competition and complex network communication. Net- work becomes one of the most notorious bottlenecks, which highlights strategies to lower communication and transmission cost in virtual cluster.

In this paper, we present a novel cluster performance op- timization strategy named vClusterOpt. vClusterOpt finds out centralized subgraphs of node graph and choose node with the shortest logical distance as kernel node of the subgraph to reduce inter-machine communication and transmission cost under vir- tual cluster. To calculate logical distance accurately, we define two kinds of logical distance: Logical Communication Distance(LCD) and Logical Transmission Distance(LTD). VM with the shortest LCD with others is used as the communication kernel node who has the most information communication stress, while VM with the shortest LTD is treated as transmission kernel node who has the most data transmission stress. We choose benchmarks running on Hadoop as the represent of data-intensive computing service to demonstrate effectiveness of our approach. Experiments show that an average of 20% performance improvement can get by our distance-aware virtual cluster optimization strategy.

Keywords?cloud computing; virtual machine communication; distance-aware virtual cluster; big data; Hadoop;

I. INTRODUCTION  Data is one of the most critical components in the next- generation scientific computing [1] [2]. Traditional serial com- puting architecture can?t satisfy real-time scientific calculation requirements, which makes computing structure using parallel architecture become more and more popular [3], such as Map-Reduce parallel programing model [4] and its Hadoop implementation [5].

Cloud computing is becoming fashion for its high resource utilization, feasible node deployment and flexible resource supply advantages [6]. Particularly, data-intensive applications can store temporary data on local storage and global data on shared storage, which improves effectiveness of data process on cloud computing platform.

At the other hand, convenience for data placement brings some new challenges to cloud computing platform [7]. Too  much network resource is costed by information exchange and data transmission between virtual machines, which makes network bottleneck of data centers. Network congestion lowers processing ability of the virtual cluster [8]. At the same time, cloud computing is under pay-as-you-go model, reducing total data transmission in virtual cluster can reduce economic cost for cloud tenants. Therefor, analyze and optimize performance of virtual cluster according to network cost are becoming more and more important.

Big data applications always run on hundreds of thousands virtual machines, which makes it complex to optimize them from structure aspect. In essence, all the application structures can be seen as combination of two kinds of basic connections.

As shown in Fig.1, they are centralized and decentralized structure.

? Centralized structure. It is also called master-slave structure. There is one or a small number of nodes act as master server, others as slaves. The server node is in charge of data exchange with all the other nodes, it?s the kernel of the cluster. At the same time, server node has a large possibility to be bottleneck of the cluster.

? Decentralized structure. It is also called peer to peer structure. It?s a basic non specific structure whereby all authorized virtual machines may be equally connected to each other, no one is special in the cluster. All the nodes do their own tasks parallel with each other.

All the nodes and connections between them in a cluster form the node graph. Most of data-intensive applications  Fig. 1: Two Main Application Topological Structures     running in large cluster are hybrid, they are constructed by combination of centralized and decentralized structures. There- for, we can separate node graph into many subgraphs, some of them are centralized while others are decentralized.

Take Hadoop as an example, it has a master node to control all the other nodes in the cluster. The master controls job tracker to split the job into many small tasks and hands out these tasks to different slaves, which is called map procedure.

After all the slaves have done their tasks, reduce procedure calls for all the tasks? mid-results processed by mappers, it combines them together to form the final result. Obviously, master is connected with all the other nodes as a centralized subgraph and all the mapper nodes are connected as a de- centralized subgraph. At the same time, all the reducer nodes form a decentralized subgraph, while reducers are connected with mapper nodes as a centralized structure. To optimize performance of the whole cluster, we find the centralized subgraph and put server of the subgraph on the virtual machine whose logical distance with all the other nodes is the shortest.

After analyzing running scene of virtualized Hadoop in cluster, we find that both the master and the reducer are the kernel of their own centralized subgraph. However, they are not absolutely in the same kind, there is still a big difference between them, as shown in Fig.2 and Fig.3.

Figure 2 and Figure 3 record network throughput of master and reducer when running TeraSort benchmark on virtualized  0 20 40 60 80 100 120 140 160 180 200            Time(s)  Da ta  (k b)  data?input  data?output  Fig. 2: Running-Time Network Metrics of Master Node  0 20 40 60 80 100 120 140 160 180 200  0.5   1.5   2.5  x 10   Time(s)  Da ta  (k b)  data?input data?output  Fig. 3: Running-Time Network Metrics of Slave Node  Hadoop cluster. Master node exchanges information with all the other nodes, but data capacity exchanged through this node isn?t large, which makes determinate factor of its performance communication latency. However, when it comes to slave node, large amounts of data is transferred into or out of reducer nodes in reduce phase, whose determinate factor is not only communication latency but also data transfer ability of connected switches.

To optimize performance of virtual cluster by distance aware aspect, we propose a strategy called vClusterOpt. It finds all the centralized subgraphs and define logical distance between nodes in the centralized subgraphs. These logical distances are separated into two types, LCD and LTD. LCD is mainly determinate by communication time between nodes, while LTD focus on both communication time between nodes and transfer ability of connected switches.

In this paper, we explore definition of LCD and LTD and use the shortest LCD and LTD algorithm to choose kernel nodes for system performance optimization. We demonstrate effectiveness of our algorithm by exploring performance im- provement of PI, TeraSort and WordCount benchmarks on Hadoop. In Hadoop case, we treat the node who has the shortest LCD with all the others as master node while the node(s) with the shortest LTD with all the mappers as reducer node(s). Experiments show that the average process time is reduced by 20% and time of transferring data staying in the virtual cluster network is reduced by 57.67%.

To the best of our knowledge, vClusterOpt is the first strategy who optimizes parallel structure by analyzing ker- nel node placement of centralized subgraph. This paper is the first paper to put both communication cost and transfer ability of connected switches into consideration to calculate logical distance between nodes. We want this trail can give a sight into cluster performance optimization. In this paper, we also describe algorithm determining when kernel node should migrate to a new virtual machine according to run-time data- flow change of other applications running in the data center, at the same time, we put the circumstance that number of virtual machine changes with demand into consideration. Our contributions are as follows:  1) A new angle of view to optimize performance of com- plex structure is proposed. We use centralized sub- graph optimization to improve system performance by putting kernel node of centralized subgraph on the virtual machine whose logical distance with all the others is the lowest.

2) We propose vClusterOpt strategy and define LCD and LTD to express different logical distances between nodes in virtual cluster. We optimize nodes place- ment strategy in virtualized Hadoop cluster by the shortest LCD and LTD algorithms and demonstrate effectiveness of our algorithm.

3) We put both communication time and transmission ability of connected switches together to calculate LTD, its the first paper to use this method.

4) We supply strategy to solve state-change phe- nomenon, such as virtual machine migration and scale of virtual cluster change.

The rest of the paper is organized as follows. Section II    describes background and motivation of our paper. In section III, we give fully explanation about vClusterOpt strategy and definition of LCD and LTD, then, we give solution to state- change phenomenon. Section IV demonstrates effectiveness of our vClusterOpt strategy with 6 experiments. Related work is analysed in section V. Conclusion and future work are promoted in section VI.



II. BACKGROUND AND MOTIVATION  In this section, we introduce background of virtualized Hadoop and the motivation we propose vClusterOpt.

Hadoop is a representative data-intensive application, it runs on physical machines under most of the circum- stances. Since virtualization technology based cloud computing emerges, it attracts interests of researchers from academic and industry areas. Therefor, strategies to put Hadoop on the cloud platform are explored by researchers, as shown in Fig.4.

Running Hadoop on virtualized cloud computing platform has four advantages:  1) High resource utilization. Several virtual machines run on one physical server, they share physical resource of the server at the same time. Manage granularity becomes smaller to get higher resource utilization.

2) Feasible deployment. Number of virtual machine changes as soon as system demands. Virtualized platform can increase or decrease number of nodes in 1s by clone technology of cloud computing.

3) Flexible resource supply. Not only number of virtual machine can change by demand, but also configura- tion to virtual machines can change in a short time when it is necessary.

4) Effective storage management. Local and remote storage can work together to improve cluster per- formance. Users can put temporary data on the lo- cal storage and HDFS on the SAN(Storage Area Network), which makes data access faster and data process efficient.

However, cloud computing also brings some challenges to virtualized Hadoop, the most obvious one is also the focus of our paper, communication cost. Several virtual machines run on a physical server, which enlarge communicate pressure of the server by 8-10 times.

To reduce communication cost, two approaches are pro- posed. The first one is to increase bandwidth of data center, however, it costs too much to change network foundation of the data center, at the same time, bandwidth has a limitation, it can?t be enlarged as far as you need. The second way is to reduce data transmission pressure in the virtual cluster. We take the second approach in our research.

We propose vClusterOpt strategy to reduce data transmis- sion cost in virtual cluster. vClusterOpt chooses nodes with the shortest logical distances with others as the kernel node to decrease transfer time between nodes and queuing time in switches. Experiments show the shortest logical distance algorithm is an effective way to reduce network cost of virtual clusters.

Fig. 4: Structure of Virtualized Hadoop

III. VCLUSTEROPT  In this section, we give fully description about vClusterOpt strategy. vClusterOpt finds centralized subgraphs of the com- plex application deployment structure at the first step, then, it judges that whether the shortest LCD or LTD strategy works well on these centralized subgraphs. In this paper, we focus mainly on definition and calculation of LCD and LTD and strategies to find the nodes with the shortest logical distance.

To calculate communication time between nodes in a virtual cluster, there are two challenges should be solved.

At the first point, network topologic structures of various data centers may be different from each other. The most pop- ular structures can be represented as three types, as shown in Fig.5, Tree structure, Fat-Tree structure [9] and VL2 structure [10]. In a network of tree structure, every son node connects with its parent nodes directly, which makes the trunk backbone of the network. Therefor, data transform path in Tree Structure is fixed. However, when it comes to Fat-Tree and VL2 struc- ture, we don?t know which switch will exchanged data pass through before the data is transformed. We can hardly use physical distance to represent communication distance. Since the difference between these three structures, we must treat the topological structure as a black box to get our algorithm avaliable in all kinds of network topologies,  At the second point, there are not only the application we measured running in the data center, but also many other services are consuming physical resources of the data center at the same time. Switches connecting with virtual machines are influenced by transmission ability cost of other running services. All in all, transfer ability is influenced by other services, it is not static. We should put transforming ability of connected switches into consideration.

Switch routers transferring data at different time are not always the same. To simplify calculation of transfer ability, we treat existing switch-choosing strategies in virtual cluster    Fig. 5: Structure of Different Network Topology  as smart strategy, they are able to choose router with the highest transmission ability. At the same time, the one who is connected straightly with the calculating node is fixed since the network structure is constructed. Therefor, we just put switches connected directly with the node into consideration when we calculate transfer ability. We choose the switch which has the highest transfer ability as the node?s value if there is not only one switch connected.

A. LCD and LTD Definition  We give our definition about LCD and LTD, as shown in definition 1 and definition 2.

Definition 1: Logical Communication Distance is a kind of logical distance, which measures the length of communication latency between two nodes, the longer the distance is, the more time it costs on message communication between the nodes.

Definition 2: Logical Transmission Distance is a kind of logical distance, which measures the length of data transforma- tion latency between two nodes, the longer the distance is, the more time it needs to transfer the same amount of data between nodes, it is used when data capacity needed to transfer is huge.

According to definition 1 and definition 2, we should put two main parameters into consideration to formulate logical distance in data centers:  1) Communication Distance. Distance in actual reticle is not the best choice for metering physical distance sometimes, since the route which data transfers by is not static in Fat-Tree and VL2 topology and material of reticle has large influence on transmission speed.

Response time is also not suitable for this measure- ment. Since calculating response time of every two nodes needs great efforts when number of nodes in the virtual cluster is large. At the same time, response time can?t represent communication distance when something like network congestion happens.

Therefor, we need a method taking communication latency into consideration and easy to calculate.

2) State of Switch. Switches in data centers influence logical distance of virtual machines who transfer data through them. Switches with different bandwidths and run-time flow have different transfer ability.

Therefor, we should put state of connected switch into consideration.

To calculate communication distance between nodes, we use Vivaldi coordinates [11], which is an algorithm to predict  round trip time between nodes without contacting them first.

Vivaldi coordinates map hosts into synthetic coordinates such that the distance between two coordinates represents commu- nication latency between nodes. Vivaldi calculates coordinates by minimizing  ? i  ? j(RTTi,j??xi?xj?), which means the  gap between round trip time and coordinate distance of node i and j . It models this optimization problem into problem to minimize potential energy of spring system according to Hooke?s law. These nodes are moved a small step in the direction of the force every time to get the best place where the whole spring system has the least potential energy. Coordinates calculate formulation is shown in (1)(2)(3)(4)(5)(6).

xi = xi + ? ? (RTTi,j ? disi,j) ? u(xi ? xj) (1) ? = cc ? ? (2) ? = eiei+ej (3)  ei = es ? ce ? ? + ei ? (1? ce ? ?) (4) es =  |RTTi,j?disi,j | RTTi,j  (5)  disi,j = ?xi ? xj? (6) LCDi,j = disi,j (7)  LCDi = ?n  j=1 LCDi,j (8)  In (1), coordinate of node i is amended by the step size of ? ? (RTTi,j ? disi,j) ? u(xi ? xj) every time to try to get the place where the spring system has the least potential energy.

(RTTi,j ? disi,j) ? u(xi ? xj) is called the force vector of the spring, ? is called adaptive time step. In the force vector calculate process, RTTi,j represents round trip time between node i and node j, disi,j means the distance between node i and node j in the mapping coordinate space, u(xi?xj) gives direction of the force on the ith node relatives to the jth. ? is calculated by multiplying a constant fraction cc and the weight balances local and remote error ? in (3). ei in (3) updates its weighted moving average of local error in (4) by combining relative error of this coordinates in (5), ce in this formulation is tuning parameter.

We can predict response time between any two nodes in the network through detecting fewer data exchange among nodes by Vivaldi coordinates. LCD has the same value with coordinate distance between nodes. After getting the response time representation, we propose enhanced method to calculate LTD between virtual machines, as shown in (9)(10)(11).

LTDi,j = k ? disi,j ? ?n  c=1 si si  (9) si = sbandwidth ? sused (10) LTDi =  ?n j=1 LTDi,j (11)  In (9), k is a learning factor, it represents influence depo- sition between disi,j and  ?n c=1 si si  . It doesn?t need to calculate out exact value of k in vClusterOpt, since we just compare total logical distance of a virtual machine with the others to find the longest one. For example, we compare LTDi,j and LTDf,h through comparing whether LTDi,j ? LTDf,h is larger than 0 or not, we translate LTDi,j ? LTDf,h into k ? ?nc=1 si ? (disi,jsi ?  disf,h sf  ), which only depends on  plus-minus of (disi,jsi ? disf,h sf  ), since all the LTDs have the same part of k and  ?n c=1 si. Therefor, we can simplify the  calculation as disi,jsi , si represents remaining transfer ability of the switch connected directly with the ith virtual machine.

LTD in our vClusterOpt platform is in direct proportion to communication distance but in inversion to transmission ability of connected switch.

B. Strategy to Choose Kernel Node  Equation (1)(2)(3)(4)(5)(6)(7)(8) shows that LCD is un- changed after the structure of the virtual cluster is static.

Therefor, node with the shortest LCD is certain. However, transmission ability of switch changes with working state of the whole data center, which makes transfer ability of virtual machine unstable. Some workloads in other virtual clusters share switches. Therefor, we should choose the new kernel nodes when SLA is not satisfied according to monitor information.

We store run-time LTD between every two nodes in a matrix likes (12). LTDi of every nodes can be represented as sum value in the ith row. We choose kernel node in LTD model from algorithm 1. We get the determining switch with the largest transfer ability from all the directly connected switches, then, we calculate LTD with formulation (9)(10)(11).

? ??????  LTD1 LTD2 . . LTDn LTD1 LTD1,1 LTD1,2 . . LTD1,n LTD2 LTD2,1 LTD2,2 . . LTD2,3  . . . . . .

. . . . . .

LTDn LTDn,1 LTDn,2 . . LTDn,n  ? ??????  (12)  C. Solution Running State Change  Many virtual clusters run together in a data center, they share physical resource such as switch together. These virtual clusters have different running characteristics, they consume transfer ability of switch at different levels, which makes transfer ability of switches connected to server node changes with time. We consider this condition and propose an effective solution, as shown in algorithm 2. We recalculate the shortest LTD in the virtual cluster every 5 minutes, when we find the SLA of Hadoop is satisfied, we migrate virtual machines run- ning the reducer node to the new virtual machine with lowest  Algorithm 1 Reducer Node Choose Algorithm.

Require:  Inter-machine LCD table : CTable Connected switch table: STable Total bandwidth of every switch: B() Used bandwidth of every witch: U() Number of virtual machines in virtual cluster: numVM Number of mapper node: numMapper Number of reducer node:numReducer  Ensure: // We treat VMs as reducer node when the sum LTD with all the mapper VMs is the shortest.

1: for each i ? [1, numVM ] do 2: for each s ? [1, sizeof(STable(i))] do 3: if (STable(i,s) is the max in Stable(i)) then 4: S = s; 5: end if 6: end for 7: for each j ? [1, numMapper] do 8: LTD(i, j) = CTable(i, j)/(B(S)? U(S)); 9: nLTD(i) = nLTD(i) + LTD(i, j);  10: end for 11: end for 12: reducer() = minimum(nLTD(), numReducer); 13: return reducer ;  logical distance. With the aid of virtual machine migration technology, we can solve running state changing problem in a short time.

Algorithm 2 Solution to Running State Change.

Require:  LTD table : LTable Ensure:  // We refresh the distance matrix every 5 minutes but // change the server node of the virtual cluster only when // SLA of Hadoop is triggered.

1: while true do 2: LTablenew = refresh(LTable) ; 3: wait(300); 4: end while 5: if SLA < boundary then 6: server() = serverChoose(LTablenew, numReducer); 7: return server ; 8: end if  D. Solution to Scalability Change  Scalability of virtual cluster will change during running process some times, there are 2 reasons:  1) Some virtual machines in virtual cluster doesn?t work well for emergency, cloud manager must reallocate a new virtual machine to complete its task or re- dispatch the task to other running virtual machines.

2) Cloud managers use elastic compute strategy to change number of virtual machine instances dynam- ically for higher resource utilization and profit.

This phenomenon can be solved by LTD table recalcula- tion, however, if we recalculate the graph too often, much    TABLE I: Performance Improvement  Benchmarks Optimization Algorithm Average Improvement  PI Shortest LCD 16.43%Shortest LTD 28.96%  TeraSort Shortest LCD 17.54%Shortest LTD 27.12% WordCount Shortest LCD 10.55%  more resource will be consumed by graph calculation and virtual machine migration. To avoid performance decreased by changing running structure from time to time, we recalculate the shortest LTD and migrate server nodes to the new best virtual machine only when the SLA of Hadoop is unsatisfied.



IV. PERFORMANCE EVOLUTION  In this section, we use 6 experiments to demonstrate perfor- mance improvement by vClusterOpt strategy and effectiveness of the shortest LCD and LTD algorithm.

Our test system was built on 40 KVM-based virtual ma- chines with 2GB memory each. These virtual machines were hosted on 6 Intel(R) Xeon(TM) Gainestown 2.40GHz physical servers with 12MB cache and 32GB system memory. Host servers were connected by Gigabit Ethernet. All the 40 virtual machines were configured with the same CPU, memory and disk configuration. Virtualized Hadoop of version 1.1.2 were deployed on the cluster constructed by 40 virtual machines. We used Linux kernel command ?tc? to simulate communication latency and transmission ability of switches between virtual machines. Source data of latency between nodes was generated by Brite [12].

As shown in Tbl.1, average performance improvement by the shortest LCD algorithm was 14.84%, and 28.04% by the shortest LTD algorithm.

We evaluated influence of the shortest LCD algorithm on system performance in the first four experiments. We compared running time of three benchmarks by choosing master node through two methods, by random and by the shortest LCD algorithm. Method choosing master node by random was called pre-optimization while method choosing by the shortest LCD algorithm was called the optimized.

We ran WordCount benchmark and compared consume time when size of input data increased in the first experiment.

As shown in Fig.6, execution time of the optimized method was shorter than pre-optimization, which illustrated effective- ness of the shortest LCD algorithm. Average performance was improved by 10.55%. Difference between pre-optimized method and the optimized did not change with increase of compute pressure on slave nodes. Since number of data link did not changed, which was the key factor to time difference for master node.

PI benchmark was run in the second experiment. Figure 7 shows performance improvement by the shortest LCD algo- rithm. Step size of mapper number increase was set as 250. The average performance was improved by 16.43%. Improvement by the shortest LCD method was larger and lager as number of mapper increased, since information exchanged with master node increased as mapper number became larger.

50 100 150 200 250 300        Size Of Counted File (Mb)  T im  e( s)  optimized  Pre?optimization  Fig. 6: Performance Comparision of WordCount using LCD  1000 2000 3000 4000 5000 6000 7000 8000 9000 10000              Number of mapper  T im  e( s)  optimized Pre?optimization  Fig. 7: Performance Comparision of PI using LCD  In the third experiment, we ran TeraSort benchmark on virtualized Hadoop platform. We increased number of mapper step by step, as shown in Fig.8, performance was improved by 17.54% and the improvement degree became large with the increase of mapper number. It was because that number of communication links with master node was enlarged when number of mapper increased, which caused communication pressure became larger. Therefor, time decrease on commu- nication links had more influence on system performance.

The shortest LCD method can also decrease time of data transmission in the network of virtual cluster. We measured de- lay time of heartbeats staying in the virtualized Hadoop cluster.

250 500 750 1000 1250 1500 1750 2000 2250         Number of mapper  T im  e( s)  optimized  Pre?optimization  Fig. 8: Performance Comparision of TeraSort using LCD    PI WordCount TeraSort  0.5   1.5   2.5  x 10   Testing Benchmarks  tim e  of h  ea rt  be at  in fo  tr an  sm is  si on  ( s)  Pre?optimization Optimized  Fig. 9: Overstay Time Comparison  1000 2000 3000 4000 5000 6000 7000 8000 9000 10000              Number of dot selected  T im  e( s)  optimized Pre?optimization  Fig. 10: Performance Comparision of PI using LTD  Figure 9 shows comparison on latency of all the heartbeats in the whole virtual cluster between the pre-optimization and the optimized one, 57.67% of average time was reduced.

In experiment 5 and 6, we measured performance im- provement by comparing run time of reduce chose by random reducer and by the shortest LTD. We set number of reducer as one to prominent performance of shortest LTD algorithm.

We ran PI calculation and compared execute time of reduce process in the fifth experiment. Fig.10 shows that time with reducer node chosen by random was 28.96% longer than chosen by the shortest LTD algorithm. At the same time, performance improvement became larger and larger as number of mapper increased. Both frequency and data capacity exchanged with reducer were enlarged when number of mapper increased in PI calculation. It made position of reducer node more and more important, that?s the reason why improvement of system performance became larger and larger. Size of dataset transferred in experiment 5 was smaller than TeraSort calculation, therefor, influence of LTD would be more obvious in experiment 6.

TeraSort benchmark was ran in experiment 6. Data trans- mission from mapper to reducer was so large that some data must queue in connected switches, which made the switch with low transmission ability bottleneck of the virtual cluster. As shown in Fig.11, the shortest LTD algorithm improved aver- age performance by 27.12%. The performance improvement became more and more obvious as calculate data size became  2 4 6 8 10 12 14 16 18 20            Size Of Terasorted File (Gb)  T im  e( s)  optimized Pre?optimization  Fig. 11: Performance Comparision of TeraSort using LTD  large, since data transfer pressure was increased with data size, which made influence of transfer ability to system performance greater. Therefor, placement of reducer node was prominent to data exchange when data size was large. Phenomenon in Fig.11 demonstrated importance to choose a appropriate kernel node, that was why the shortest LCD and LTD algorithm in this paper is important.



V. RELATED WORK  Like vClusterOpt, there are many other approaches to improve performance of Hadoop in cloud computing. They mainly fall into two categories, optimization based on work- load characteristics and Hadoop architecture.

Optimization based on workload characteristic aspect. [14] uses data mining method to predict total CPU usage in clock cycles of jobs on Hadoop from history parameters and running metrics. However, it only works well on CPU usage, nothing about network and data transmission is considered. [15] com- bines prediction engine and a lightweight simulator together to predict performance. It uses a genetic algorithm to choose the best placement strategy. It builds a model named TARA to evaluate performance improvement by combining application characteristics and Hadoop topology together. [16] proposes three ways to allocate resource in cluster : regulated and user- assigned priorities method, dynamically adjust resource alloca- tion method and automatically detects and reduces bottlenecks method. The authors use these three ways to optimize data process and transfer in cluster, but they didn?t specify influence generated by the master or the reducer.

Optimization based on Hadoop architecture aspect. [17] designs a location-aware file block allocation strategy to reduce I/O interference of the whole cluster. It achieves better data redundancy, but it doesn?t put network cost into consideration.

[18] solves data-locality problem in heterogeneous environ- ment. It proposes a method to place data across cluster to make sure that data processing pressure on all the nodes are balanced. This paper focuses on data placement but hasn?t put node choose strategy into consideration. [19] proposes a method to represent topological distance in data center. The authors treat distance between virtual machines on the same physical machine as 0, physical machines in the same rack as 2, physical machines in the same data center but different racks as 4, physical machines in different data centers as 6. These distances just represent relative distance tendency between    virtual machines, they are not precise enough to represent logical distance.



VI. CONCLUSION AND FUTURE WORK  In this paper, we present a novel strategy named vClus- terOpt to optimize performance of virtual cluster. We find out centralized subgraphs of node graph in virtual cluster and choose kernel node of the subgraphs with the shortest logical distance. To get the kernel node precisely, we define LCD and LTD to represent logical distance. LCD represents distance concerning much information exchange but size of changed data isn?t large, while LTD highlights nodes who have the most transmission pressure, it depends not only on communication cost but also on remaining transmission ability of connected switches. We use the shortest LCD and LTD algorithm to optimize performance of virtual cluster.

Experiments show that optimization base on the shortest LCD and LTD algorithm can improve performance of virtual- ized Hadoop cluster by 20%. Specially, performance improved by our strategy increases as data transmission becomes larger.

Structure of Hadoop in this paper is known and centralized subgraphs are chosen artificially. We will explore a method to find centralized subgraph of the complex node graph au- tomatically in the future study. It will discover centralized subgraph and central nodes even though the structure of running application is unknown.

In the Hadoop case study, we use manipulation to demon- strate effectiveness of the shortest LCD and LTD algorithm, which evades influence by other applications running in the data center at the same time. We will verify our method in a larger distributed real-world cluster and get some running met- rics of online workloads instead of benchmarks to demonstrate that vClusterOpt works well on trans-regional cluster.

We suppose that data transferred out of every mapper is the same in this paper. We will consider the circumstance that task amount of different mapper nodes is different, which means that data transferred from mappers are not the same to reducer nodes. In future work, we want to explore a method to put weight parameter of mapper nodes into consideration to make vClusterOpt platform more effective. And more experiments on performance influence to the system by virtual machine mi- gration and scale change of virtual cluster will be constructed in the future to demonstrate adapting ability of vClusterOpt.

