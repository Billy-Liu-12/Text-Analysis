A Rate Control Protocol for High Speed Streaming Video

Abstract   In this paper, we propose a rate control for high speed streaming video, which is based on scalable TCP and TEAR. Scalable TCP offers an effective and robust mechanism for bulk data transmitting in high bandwidth-delay network. However it has a big rate oscillation when transmitting video data. TEAR is a rate control protocol that emulates TCP at receivers, which is suitable for streaming video, and however it is TCP friendly and keeps the same low utilization as TCP in high-speed network environment. RDSTCP adopts TEAR idea, emulates scalable TCP at receiver.

RDSTCP shifts most functions of scalable TCP to the receiver, and reduces the rate oscillation as well as keeping high link utilization. In the end, we emulate and evaluate RDSTCP performance by using NS2.

1. Introduction   In current Internet, more than 90% applications use TCP protocol. TCP congest control mechanism takes a crucial role for the stability and reliability of current Internet.

With the development of network technique and multimedia business, the Internet is evolving to high- speed network with bandwidth larger than 1Gbps, or even 10Gps. TCP can?t take full advantage of the bandwidth in high-speed network because of the mechanism of slow window increase and quick window decrease. In recent years, a series of high speed TCP protocols are proposed to improve TCP, such as HSTCP [3], STCP [1], BIC [9], HTCP [10] and fast TCP [11], etc.

Tom Kelly proposed STCP (scalable TCP) protocol [1], which is an improvement for HSTCP protocol [3] [4] and well-suited for data transmission in the network environment with high bandwidth delay product. STCP quickly increases and slowly decreases its congestion windows than TCP. STCP is backward compatible with TCP when the congestion window is less than a certain threshold value. STCP can double its sending rate in 70 RTTs, so it can quickly increase its rate to maximum link capacity. However, STCP is  ill suited for real time streaming application because it?s big rate oscillation and frequent feedback.

In [2], Rhee I et al., proposed the TEAR (TCP Emulation at Receivers) protocol to overcome the big rate oscillation of TCP. TEAR moves most of functions of TCP to the receiver. The receiver detects the network congestion, and estimates the sending rate according to the network state. TEAR is TCP-friendly and suitable for transmission of media stream.

However, TEAR has the same poor performance as TCP in large bandwidth delay product network.

In this paper, we will present a receiver-driven congestion control protocol for high speed streaming video, RDSTCP, which based on STCP and TEAR.

RDSTCP emulates STCP behavior at the receivers, shifts most mechanism of STCP to the receivers and uses a weight average method to smooth the rate.

RDSTCP detects the network congestion state and estimates the rate at the receiver other than the sender.

RDSTCP not only keeps big bandwidth utilization at high speed network, but also offers smooth rate for streaming video.

The reminder of this paper is organized as follows.

In section 2, we give a brief review for scalable TCP.

We then propose RDSTCP in section 3, which is based on TEAR and STCP. In the section, we present the mechanism of RDSTCP, and analyze the throughput at steady state. In section 4, we use NS2 to simulation network topology and evaluate the performance of RDSTCP. Finally, we draw a conclusion and point out the future research direction.

2. A brief introduction to STCP   STCP [1] employs MIMD (multiplicative increase multiplicative decrease) to adjust window. STCP keeps compatible with TCP at a low congestion window. The algorithm is as follows.

For each ACK: 1/  W W W lowWin and slow start W W W lowWin W a W lowWin  ? + < ? + < ? + >     DOI 10.1109/ICIS.2008.61     For each Drop: 0.5W W W W lowWin  W bW W lowWin ? ? < ? ? >    where a , b  is constant, the default value is 0.01, 0.125, W  is the congestion window size. lowWin  is the threshold value, when the congestion window is less than lowWin , the protocol switches to TCP.

3. RDSTCP   In this part, we will present RDSTCP algorithm,  which emulates STCP at the receivers as TEAR emulates TCP.

In RDSTCP, we use round to describe the time interval instead of RTT as in TEAR protocol. One round is defined as the time interval that contains the arrival of all packets in one congestion window. One new round begins after current round ends. The sending rate is updated in each round. Normally, the receiver send estimated rate to the sender in the end of each round except two special cases. One is the estimated rate is less than the current sending rate, which means one network congestion occurs; the other is RTT timeout of the receiver. On these two cases, the receiver notifies immediately the sender to change sending rate.

3.1 Instantaneous rate estimation   Naturally RDSTCP is a rate-driven algorithm other  than window-driven. The sender sends packets according an initial rate. When the receiver receives the first packet, RDSTCP enters slow start state. In the phase, RDSTCP adjusts its rate according to the next algorithm.

pktrate rate RTT  ? +  Where pkt  is the packet size. Once the congestion window is more than the given slow start threshold, RDSTCP changes its state to congestion avoid.

In congestion avoid phase, if no packet loss is detected, RDSTCP according to the next algorithm to estimate the rate for each arrival of packet.

pktrate rate rate lowRate rate RTT  a pktrate rate lowRate RTT  ? + < ?  ? ? + >    Where lowRate is a given rate threshold value, which is equal to ( ) /lowWin pkt RTT? .

If packet loss is detected, the receiver estimates the instantaneous rate according to the next algorithm.

0.5rate rate rate rate lowRate rate b rate rate lowRate ? ? <  ? ? ? >    3.2 Average rate   For reducing the rate oscillation, we use an average  rate during a long period. The method of filter is the same as the method of TEAR. We use an array to store the latest several history rates, and calculate a weight average value as the new rate.

( ) ( )  ( )  n  i n  i  w i r i rate  w i  =  =  ? = ?  ?   Where 1 1 / 2  ( ) / 21 / 2 1 2 /  i n w i i n n i n  n  ? ?? ?= ?? ? ? ?? +?     3.3 Throughput at steady-state   In this part, we will analyze the throughput of  RDSTCP as a function of packet loss.

We ignore the slow start phase and the phase that  the rate is less than the low rate threshold. We only consider the case at long-term steady state. The sending rate of RDSTCP at steady state is shown in Figure 1. Let PLPT  is the time interval between two successive packet losses, which can also be called as a packet loss period.

rate  Time  maxr  0r  PLPTRTT Figure 1    Sending rate   In a packet loss period, suppose the maximum  sending rate is max ,r the minimum sending rate is 0r .

Using the decrease rule of RDSTCP, we have the following relation.

max 0  (1 ) r r  b =  ? (1)  In one RTT, RDSTCP increases its rate by a r? .

That is,    1 0 0 0  2 1 0  max 0  (1 )  (1 ) (1 )  (1 )n  r r r a a r  r a r a r  r a r  = + ? = +  = + = +  = +  (2)  In term of (1) and (2), we obtain,  0 0(1 ) (1 ) nb r a r? = +  So, 1log( )  log(1 )  bn a  ?= +    The relation of PLPT  and RTT  is as follows.

PLPT n RTT= ?                      (3) Let S  is the total packet sent in one PLPT , p is the  probability of packet loss, then the probability of packet lossless of continuous k  packets is:  1[ ] (1 ) , 1, 2,kP k S p p k?= = ? = The mean of S  is:    1[ ] (1 ) , 1,2,k k  E S p pk k p  ? ?  =  = ? = =?  (4) The throughput ?  can be expressed as follows.

[ ] 1  log(1 ) 1 log(1 )  PLP  E S T np RTT  a b p RTT  ? = = ?  + = ?  ? ?  (5)   Compared to TCP?s throughput:  1.5 RTT p  ? = ?    Obviously, RDSTCP has more throughput than TCP.

4. Simulation and performance evaluation   We will verify and evaluate the performance of RDSTCP by using NS2 [13].

The simulation model is shown in Figure 2.

s1  s2  sn  R1 R2  d1  d2  dn  10G  1G  10G   Figure 2    Simulation model   The bandwidth of bottle-neck link is 1000Mbps, the  bandwidth of each connection of source and sink is 10G, and the bandwidth of bottle-neck link is 10G.

The queue management algorithm is adaptive RED with packet size 1000 byte, link delay 50ms, and the length of the router queue 12500 packets.

There are three types of flows in the experiment, RDSTCP flows, and STCP flows and TCP sack background flows. All these flows are started at a random time to reduce the synchronization.

4.1 Normalized throughput comparison   In this part, we will evaluate the fairness of RDSTCP and STCP using the method in [8] [12] [15].

Figure 3 shows the normalized throughput of n RDSTCP flows competing with n STCP flows over a 300Mbps link (a) and 600Mbps link (b). The lower curve in Figure 2 shows the average packet loss rate as a function of the flow number. Each point in the graph represents the throughput of one individual flow, and the dash lines represent the average throughput. From the curve, we can see the normalized throughput of RDSTCP is more and more close to that of STCP as the number of flow increases.

(a)     (b)   Figure 3    RDSTCP competing with STCP   4.2 Sending rate between competing flows   In this part, we will research the difference between RDSTCP and STCP in the variation of the sending rate using the method described in [12] [15].

Figure 4 shows the sending rate of individual flows from the simulation with 16 STCP flows and 16 RDSTCP flows on a 1000Mbps link. The sampled interval of the throughput is 0.2 sec and 1 sec. At the bottom of the graph, a mark ?+? means packet loss.

We only draw the curve of fore six flows, flow 0, 2, 4 is STCP flow and flow 1, 3, 5 is RDSTCP flow. From Figure 4, we can see RDSTCP flows are smoother than STCP flows.

Figure 4    The rate comparison of RDSTCP  and STCP  4.3 Performance at various timescale   In this part, we evaluate the smoothness and  equivalence of RDSTCP at various timescale.

Following [6] [7] [8] [14], we measure the smoothness of a protocol by the coefficient of variation (CoV) of sending rate.

0( ) /  , 0  ,  1 ( ( ) ) ( )  T t  f f i  f f  B t i B T t  CoV B  ?  ?  ?  ? ?  ?  =  + ? ?  = ?   Where ?  is the timescale, fB  is the average throughput of flow f in time interval [ 0t , T ]. The smaller the CoV, the smoother the rate is.

We use equivalence function to evaluate the protocol fairness as [7] [14]. The equivalence functions of flow a and flow b is defined as follows.

, , , ,  , ,  ( ) ( ) ( ) min( , )  ( ) ( ) a b  a b b a  B t B t e t  B t B t ? ?  ? ? ?  =  The equivalence of two flows between time 0t  and  1t ( 1 0t t n?= + ) is defined as follows.

, , 0  , , 0 1  ( * ) ( , )  n  a b i  a b  e t i e t t  n  ?  ?  ? =  + = ?    Figure 5 shows the equivalence of RDSTCP and STCP in different timescales. The equivalence ratio of RDSTCP and RDSTCP is between 0.8 and 1, and the equivalence ratio of STCP and STCP is between 0.6 and 0.8, and the equivalence ratio of RDSTCP and STCP is between 0.5 and 0.6.

Figure 5 the equivalence of RDSTCP and STCP   Figure 6 shows the Coefficient Variation of  RDSTCP and STCP over a broad range of timescale.

The sending rate of RDSTCP is obviously smoother than STCP at small timescale. As the increase of timescale, the rate smoothness of STCP is near to RDSTCP.

Figure 6    Coefficient of Variation of RDSTCP  and STCP  4.4 Throughput comparison with TEAR   We will compare the throughput of RDSTCP flow  and TEAR flow in this part.

We run one RDSTCP flow and one TEAR flow  respectively for 10000s. The bandwidth of bottle link is 1000Mbps with link delay 50ms. The AQM is adaptive RED. The packet size is 1000byte.

Fig.7 shows the result of throughput comparison of RDSTCP and TEAR. Obviously, RDSTCP has more throughput than TEAR, and quicker speed to reach a stable state.

Figure 7 Throughput comparisons of RDSTCP and TEAR   5. Conclusion   STCP is the congestion control protocol for high- speed network with large bandwidth delay product, which overcomes the fault that TCP protocol can?t take full advantage of bandwidth in high-speed network.

However it is not suited for streaming video transmission because it keeps a big rate oscillation.

In this paper, we present a receiver-driven algorithm, RDSTCP, for high speed streaming video, which emulates STCP at the receiver and shifts most functions of STCP to the receiver. The receiver detects     the network congestion state and estimates the rate.

RDSTCP has good smoothness of sending rate and inter-protocol fairness with competing STCP flow. In addition, RDSTCP is not a per-packet feedback mechanism, so it can avoid feedback explosion when it is deployed in multicast environment.

