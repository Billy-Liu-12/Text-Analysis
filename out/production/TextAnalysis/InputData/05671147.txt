Association Rule Mining with Establishment of Frequent Item set Vectors

Abstract?After analyzing many typical association rule mining algorithms, a new algorithm, named as BOFP-V, is  proposed for frequent item set mining. FP-V vectors are  introduced in order to convert that of frequent item set mining  to the course of the vectors operating. The existing Apriori  algorithm produces a lot of candidacy sets and needs scanning  database many times, and BOM algorithm entails and  operation of k vertors with ( )km  times. Overcoming these drawbacks, BOFP-V algorithm needs scanning database only  once. Therefore, the proposed algorithm is obviously superior  to Apriori and BOM algorithm in efficiency.

Keywords-data mining; association rule; frequent item set  I ? PREFACE Association rule mining is an important component of  data mining research. It?s a vital step to find the key  technique??frequent item set for association rule mining.

In 1993, Agrawal advanced the well-known Apriori  algorithm[1], which is based on the frequent set. In  following years, there were many other algorithms[3,4], the  most of which were constructed upon Apriori algorithm.

Above algorithms were based on recursive statistics to cut  into many frequent sets. During the process of generation,  it?s extremely time-consuming to scan the data set many  times and then to generate many candidate items. Then  Jiawei Han advanced the FP-growth algorithm[5], which is  totally different from Apriori algorithm in mining frequent  rule set. It had been proven that FP-growth algorithm could  been an order of magnitude faster than Apriori algorithm,  but to construct the FP-tree and detect superset could be the  main block to improve the efficiency of FP-tree.

In this paper, there is a brand-new frequent item set  mining algorithm, named as BOFP-V algorithm, which is  based on the data structure of FP-Vector in frequent item set.

BOFP-V algorithm can refine and store all the information  about frequent item set, and then directly mine the frequent  item set. The operation principle of this algorithm is as  follow: first, it will scan the transaction database; secondly,  it will generate frequent item set FP-V vector for each  frequent item; then, rational coordination, vectors? operation  and variables? alternating conversion skill will finally mine  the frequent item set step by step.

This paper is divided into 5 parts. The second part will  descript around the question. The third part will introduce  frequent item set mining algorithm. The forth part is a test  part, in which part, there will be a comparison between  BOFP-VA algorithm and FP-growth on efficiency. The  conclusion will go to the final part.

II ?DESCRIPTION OF THE PROBLE Suppose I={i1,i2,?,im} as the item set, and the given  transaction database is DB={T1 ?T2,?,Tn}, among which each transaction Ti is I?s subset, that is, Ti? I ?when and only when X?Ti ?it is called that transaction Ti contains X.

The amount in a item set is named as the dimension or  length of the item set. If the length of item set is k, it will be   DOI 10.1109/MINES.2010.219    DOI 10.1109/MINES.2010.219    DOI 10.1109/MINES.2010.219    DOI 10.1109/MINES.2010.219       called k-item set.

Definition 1: For item set X? I, X?s frequency in DB  refers that DB include the transaction amount of X, which  can be recorded as X.count. DB?s support degree to X  refers to the X?s transaction percentage in DB, which is  recorded as X. sup. If X. sup ? minsup (the minimum  support degree given by user), X will be called the frequent  item set in D. If X. sup ? minsup, X will be called the  non-frequent item set. If X is the frequent item set in D, and  only ?  X ?  =1( ?  X ?  represents the length of X in the  whole paper), X can be called the frequent item.

Declared 1: If X is frequent item set, then all the non-empty  subsets of X are frequent item set.

Declared 2: If X is non-frequent item set, then all the  supersets of X are non-frequent item set.

There is an association rule, that is, a implication as X ?? Y: included X? I, Y? I, X?Y=?. The terms to support  the association rule X ??Y are as follow: ? The rule owns the minsup, that is, support?X=>Y ?=support?X?Y ? = ?X?Y ?. supD?minsup It owns the minconf, that is, confidence?X=>Y ?=support?XJY ?/support?X ??minconf.

Minsup refers to the minimus support degree given by user,  and minconf refers to the minimum confidence factor  threshold given by user.

To use association rule mining method is associated with  two questions as follow[1,2]:  J To select all the frequent item set in transaction  database D;  J To use frequent item set to generate all association  rules, whose conf ?  minconf. That means to find out all  non-empty subsets of each frequent item set A. If ratio A.

supD/B. supD ?minconf. then the association rule B=>  ?A-B ?can be generated. Minconf refers to the minimus confidence factor given by user  Question J is relatively easy, and Agrawal had resolved  it in a rational way[2]. Therefore, most current researches  focus on Question J. So does this paper.

III ? THE INTRODUCTION OF FREQUENT ITEM SET MINING ALGORITHM  Preprocessing algorithm:  Input: DB={T1 ?T2,?,Tn}, and minsup has been given by the user.

Output: F1: a frequent item set FP-Vector for each frequent  item;  1) To scan DB={T1 ?T2,?,Tn}, and then add n-dimension vector for each item ijJI. ij.FP-V=( ijv1, ijv2,?, ijvn),in  which, ijvk ={   kj  kj  Ti  Ti  ?  ?  (k=1,2,?,n)  2) Name F1 as the frequent item set, and its initial value  as F1=? ,then to calculate the support degree of each item  ijJI, then ij. count=? =  n  k kjvi   ?ij.sup= ij.count/ ?DB ??. If ij.sup?minsup ?then F1= F1J{ij}. At the same time, the corresponding vector should be kept, which will be called  frequent item set FP-Vector. Otherwise, the corresponding  vector of i should be cancelled.

Frequent item set mining algorithm BOFP-VA:  Input: the frequent item set F1={X1, X2,?Xp}Xi for each  frequent item set FP-V=( Xiv1, Xiv2,?, Xivn);  Output: F as the set of all the frequent item sets  1) k=1, F= F1={X1, X2,?Xp},and then to judge if F0 is  null ?If it is null, then turn to step 21 	otherwise, turn to the step 2.

2) k= k+1; F0=? ;  3) For (s=1;s?p-1;s++){ 4) For (t=s+1;t?p;t++){  5) If ( ?  XsJXt ?  =k)  6) To verify if all the subsets, each length of which is k-1, belong to F1. If they belong to F1, then turn to the step 7.

Otherwise, to turn to the step 8.

7) (To suppose set vectors Xs.FP-V=( Xsv1, Xsv2,?, Xsvn) and Xt.FP-V=( Xtv1, Xtv2,?, Xtvn) separately  represents the frequent item set Xs and the frequent item set  Xt ) Let (XsJXt ).FP-V=( Xsv1JXtv1, Xsv2JXtv2,?, Xsvn JXtvn), then use (XsJXt ).FP-V to calculate the support  degree of the item set XsJXt. If XsJXt. sup ? minsup, then  F0= F0J{XsJXt},also keep the vector (XsJXt ). FP-V=  ( Xsv1JXtv1, Xsv2JXtv2,?, XsvnJXtvn),otherwise, to delete  the vector (XsJXt ).FP-V=( Xsv1JXtv1, Xsv2JXtv2,?,  XsvnJXtvn), then turn to the step 8.

8) } 9)  }  10) if  (F0=? ){turn to the step 21}  11)  F = FJF0; k= k+1;F1=? ;\* suppose F0={X1,  X2,?Xp}*\  12) For (s=1;s?p-1;s++){ 13) For (t=s+1;t?p;t++){  14) If ( ?  XsJXt ?  =k)  15) {To verify whether all the subsets in XsJXt, whose length is k-1, belong to F0. Yes turn to the step16, and No  turn to the step17};  16) (Suppose Xs.FP-V=( Xsv1, Xsv2,?, Xsvn) and Xt.

FP-V=( Xtv1, Xtv2,?, Xtvn)separately as the frequent item  set vector for frequent item set Xs and Xt). Let (XsJXt ).

FP-V=( Xsv1JXtv1, Xsv2JXtv2,?, XsvnJXtvn). To use  (XsJXt ).FP-V to calculate XsJXt.sup of XsJXt. If Xs JXt.sup?minsup, then F1= F1J{XsJXt},and keep the  vector (XsJXt ).FP-V=( Xsv1JXtv1, Xsv2JXtv2,?, Xsvn JXtvn),Otherwise, delete the vector (XsJXt ). FP-V=  ( Xsv1JXtv1, Xsv2JXtv2,?, XsvnJXtvn),then turn to the  step 8.

17)  } 18) }  19) if  (F1=? ){go to 21}  20) F = FJF1; go to 2} 21) Output F ,end.

In BOFP-VA algorithm, suppose F1={X1, X2,?Xp} as  the frequent (k-1)_ item set. Selecting Xs, Xt form F1, then  verifying whether XsJXt can compose k-1 item set. If Xs JXt is k-item set, declare1 and declare 2 can be used to  judge whether XsJXt can be frequent item set. Here, the  term is whether the k-1 length subsets of XsJXt are all  frequent item sets. If it is, then go to the step 7. To calculate  (XsJXt) .sup, so as to confirm whether XsJXt is frequent  item set. The step 11 aims to add all the newly found  frequent k-item sets to set F. The function of steps 12 to 18  is similar to the function of steps 3 to 9 .

In BOFP-VA algorithm, the code in steps 2 to 11 is  similar to that in step 12 to 20, which aims to improve the  efficiency of calculation in use of variables? alternate  conversion skill.

IV ?TEST In order to test the function of the algorithm in this paper,  we have tested it under certain circumstances. Our testing  condition was set as follows:  Windows XP Professional 	CPU:P?1.5Ghz 	Hard disk: 40G 	Memory: 256M 	 Data source: 13000 students? registration management records from one college?s  educational affairs division 	Database: SQL server 2000 Attribute: 17 	Realize FP Growth algorithm and BOFP-VA algorithm with VC++6.0 	The result:     ???????? ? ? ? ?? ??? ?? ????????? ? ? ? ??? !"#$%&'$%(!)*+ ,-./ 0 12.345-./ 0   Figure1: Algorithm performance in the different support  There could be a comparison of the performance between  BOFP-VA algorithm and FP-Growth algorithm from the  result.

The above chart 1 represents that, with the decrease of  support degree (divided as 30%,15%,5%,3%, 1%),the  length and amount of the item set catering the minimum  support degree threshold both increase rapidly. The  execution time of each algorithm also increased obviously.

FP-Growth algorithm has clear superiority when item set is  growing and the amount is to a higher level, but with the  growth of item set, a large number of FP-tree node will  rapidly increased also, which will make the data structure  more complicated and occupy more space. The disorder of  trees? stretch will lower the efficiency of retrieval system  and mining. Based on the analysis of conditional pattern  base, there still exists the need for a large number of  connecting operations to generate frequent patterns, which  will seriously affect the efficiency of the algorithm.

However, according to the operation of BOFP_VA  algorithm, it generates frequent item set with AND  operation of vector. So the growth of both dataset scale and  length of item set will influent BOFP_VA little.

V ?CONLUSION In order to mine all the association rules in large-scale  transaction database, this paper raised a brand-new  algorithm? BOFP-VA. Furthermore, there has a  comparison with a classical mining association rule  algorithms?Apriori. At the same time, there also made a  test with FP-Growth algorithm on performance ?From the  theoretical analysis and the test, it?s found that, BOFP-VA  algorithm owns an extraordinary performance. It only need  to scan transaction database once; needn?t to store a large  number of candidate item set. In opposition, it has the  ability to judge whether a new k- item set is a frequent item  set. Therefore, compared with Apriori algorithm, the  outstanding flexibility of BOFP-VA algorithm could help it  save a large amount of time and space while handling a  large-scale trade transaction database.

In further research, following orientation will be paid  more attention: a better data structure to replace vector and  further lower the need to memory and to improve the  performance of algorithm.But although the location of  frequent item set hasn?t been paid certain attention, it is  definitely meaningful to sorts of applications. So the  location is also a vital question worthy to be discussed.

