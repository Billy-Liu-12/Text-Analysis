Data For All: A Systems Approach to Accelerate the Path from Data to Insight

Abstract?Zettabytes of data are available to be harvested for competitive business advantage, sound government policies, and new insights in a broad array of applications. Yet, most of this data is inaccessible for users, since current data analysis tools require an army of technical people to find, transform, analyze, and visualize data in order to make it consumable for decision making. In this paper, we present work in progress to lower the barriers for data-driven decision making by introducing a systems approach to scale the user experience, not only in the volume and variety of data, but also in the skills required to harvest that data. We call for a new approach for data-intensive applications that engages the user as an intelligent partner in a social and intelligent conversation with data by automating, guiding, and recommending data, transformations, visualizations, analytics, and suggesting collaboration opportunities within an analytics marketplace, and leverages both metadata and semantic information about the data captured from conversations.

Conversational Interfaces; Data Integration; Schema Identification; Automatic Visualization; Analytics Marketplaces; Visual Analytics

I.  INTRODUCTION We now have zettabytes of raw data at our fingertips from thousands of different sources1.  The US government alone publishes almost 400,000 datasets on data.gov, and social data, such as Twitter feeds, grows by nearly 100 gigabytes every day.  This data represents a treasure trove of new insight to yield a competitive advantage and drive business decisions. And yet, surprisingly, much of it is still inaccessible, particularly to business users.

The problem is that current state-of-the-art business intelligence tools are hard to use and require an army of technical people with highly specialized skills to act between the raw data and the business user.  The hurdles start even from trying to find the right data ? for example, a recent search for ?cancer rates? on data.gov yields several pages of datasets, each of which must be carefully examined by someone with domain knowledge to see if it is suitable for current task at hand. When a useful dataset is found, it is often in the wrong format, and needs to be transformed and integrated with other data before it can support further analysis. These steps require programming, a complex data integration infrastructure, and usually days of lead time for the IT staff to produce even simple reports based on well- established data warehousing patterns. Clearly, this introduces a significant gap between raw data and insight   1?See http://www.emc.com/about/news/press/2012/20121211-01.htm?  for decision makers; they simply cannot interact with data iteratively in a business-timely manner.

Current approaches work well for business users with common questions that are asked on a regular basis, such as monitoring sales by geography, by product line, or by year.

But now with the availability of additional data sources, business users are interested to answer open-ended questions, such as how a new marketing idea would affect brand sentiment or what impact a new product distribution strategy would have on sales. To answer such open-ended questions, there is a new class of users, data scientists, who are skilled in scraping data from web pages, using mathematics and statistical programming packages like R, writing complex database queries, and applying basic machine learning techniques and visualization libraries to do data analysis and visualization [1]. However, the tools of data science are still oriented toward the skills of a technical staff person rather than a business user. The new challenge is to enable business users with the powers of data science.

We are working on system to enable ?self-service data intelligence?. Self-service data intelligence requires a specific focus on data consumability. It is not sufficient to improve the usability of today?s data science tools. Instead, data consumability requires thinking more broadly about the information interaction experience from start to finish, to enable more natural interaction with information and to narrow the gap between data and decisions.

Our system aims to transform the user experience of interacting with data from traditional approaches that require days of lag time due to several layers of people and technologies, to a new approach based on rapid-fire conversations in which data is automatically found, cleaned, transformed, and visualized so users can go through a number of questions very quickly in an iterative manner.

Central to our system is social and intelligent conversations with data, where analytic work is placed in a social context with a user experience that matches most social networking applications, and in which our system participates in the conversation like an intelligent partner, recommending datasets, visualizations, and people with whom to collaborate. To enable such an experience, we leverage semantics and metadata to automatically clean, prepare, transform, integrate, and visualize data from multiple sources, and to perform automatic data analysis on the  2013 IEEE International Congress on Big Data  DOI 10.1109/BigData.Congress.2013.69     user?s behalf. This environment facilitates a meaningful conversation with data in real-time to guide interactive exploration, suggest alternative pathways for new insights, combine findings from multiple explorations, and share and communicate provenance and process. The experience is tied to an analytic marketplace, where people can solicit, buy, and donate datasets, tools, and their own expertise; follow data, sources, colleagues, and topics of interest; track who is working with what data and for what purpose; leverage the experience of the larger community for recommendations of data, people, and tools for analysis; and (re)use data and powerful analytics in runtime environments created for them (e.g., cueing from ideas such as Galison?s ?trading zone? [2] or ManyEyes website [3]). While similar in spirit, unlike Watson [4], our system is not a question- answering system but rather an intelligent recommender system placed in a social user experience, designed to employ software as an intelligent partner to engage in a meaningful dialogue and to foster a higher level contextual conversation with data.



II. SYSTEM OVERVIEW Clearly, there is much research to be done to make the vision of self-service data intelligence and to better support the business user. Below we list central components in our system design and include a brief overview of functionality to address some of these challenges:  ? Conversational User Interface is a visual, interactive, conversational interface to support business users. It allows them to enter questions in natural language and guides them through the marketplace to find and visualize data and apply analytics. It presents system recommendations for data and people, and facilitates social collaboration, allowing users to utilize context from preceding conversations.

? Natural Language Interpreter uses natural language interpretation techniques that leverage metadata, matches query keywords to concepts such as datasets, attribute names and values, visualization types, and analytic tasks (e.g., correlate, classify, visualize), and creates a ranked list of interpretations.

? Entity Relationship Graph and Registry is a repository of all entities and relationships between entities, including, users, communities, data, data sources, analytics, topics, etc.

The relationships between these entities, such as  datasource _provides_data, user _uses_data, user_collaborates_with user, user_interested_in_topic, etc., are created based on user interaction (e.g. a user using a particular dataset), as well as programmatically (e.g. by the system relating a data set to a topic). The entity relationship graph is queried and updated by many components in the system, including, for example, by the interpreter to make better interpretations, and by recommenders to utilize affinity.

? Recommenders: There are four different types of recommenders: Entity, Visualization, Query, and Insight.

Entity recommenders use the entity relationship graph to make recommendations of people with whom to collaborate, communities with whom to engage, datasets and data sources to examine, and analytic algorithms to try on their data. Visualization recommenders examine the type of data attributes (categorical, numeric, etc.), value, range, and semantics of attributes, and other metadata to make recommendations for the proper visualization based on best practices. A visualization recommender leverages the current visualizations in a user's conversation and looks for the best way to integrate new query results into them. Query recommenders examine metadata (e.g. past queries from everyone) to make recommendations for new queries.

Insight recommenders use existing visualizations and annotate them with potentially interesting insights that users might wish to explore, utilize unused computation cycles to run opportunistic statistical computations on related datasets (e.g., clustering, correlation, etc.) , and recommend pathways for discovery and to guide people in their exploration.

? Generators are employed to automatically combine one or more datasets and apply the right transformations to generate the desired data for analysis and visualization.

? Data Curation Tool uses metadata extraction techniques such as entity identification, resolution, and relationship discovery, performs automatic data cleaning, preparation, and transformations, and supports efficient data organization for open-ended analytical queries.



III. CONCLUSION In this paper, we propose a system for a self-service data intelligence system for business users, embodied as a conversational information exploration interface to conduct open-ended data analysis. The system leverages metadata and semantics to automatically interpret user's queries, and to find, clean, and transform data as necessary for a suitable representation for insight. In addition, the system is built within an analytic marketplace, where users share their data, analysis, and expertise. We are currently building such a system to realize the vision of self-service data intelligence and to make progress towards addressing numerous research challenges, ranging in topics such as collaborative data interaction, natural language processing, interactive analytics, semantic data integration, and data management.

