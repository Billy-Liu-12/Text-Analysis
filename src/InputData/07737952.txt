Fast Algorithms for Mining Multiple Fuzzy Frequent Itemsets

Abstract?In the past, several algorithms were developed to mine fuzzy frequent itemsets (FFIs) in which each item is represented at most one linguistic term based on maximum scalar cardinality. In real-life situations, multiple fuzzy linguistic terms instead of the single one can, however, produce more useful and meaningful fuzzy association rules. The Apriori-based algorithm was developed to mine multiple fuzzy frequent itemsets (MFFIs), which requires to generate the amounts of candidates and determine them in a level-wise way. In this paper, a fuzzy-list- based (FL)-Miner algorithm is developed to mine the complete set of MFFIs without candidate generation. Two efficient pruning strategies are also developed to reduce the search space, thus speeding up the mining process to directly discover the MFFIs.

Experiments are conducted to show the performance of the proposed approaches compared to the state-of-the-art level-wise algorithm in terms of execution time and memory usage.



I. INTRODUCTION  It is an important issue to mine the implicit relationships and information from a very large database [1], [3], [5], [9], [14]. Agrawal et al. [2] first presented the Apriori algorithm to mine ARs in a level-wise manner. Since the Apriori algorithm requires time-consuming computations to find the frequent itemsets (FIs) level-by-level and the numerous candidate item- sets have to be generated, Han et al. [7] designed the frequent pattern (FP)-tree structure with a FP-growth mining algorithm to find FIs without candidate generation. Many algorithms have been extensively designed to mine FIs or ARs from the binary databases based on Apriori-like approach or FP-tree structure.

In real-life situations, the quantitative databases can be used  to provide more information for decision making than that of the traditional binary databases. It is difficult to handle the quantitative databases based on the crisp sets. Fuzzy-set theory [16] was proposed and can be used to handle the quantitative databases. In the past, Hong et al. [8] stated the fuzzy data mining approach to discover fuzzy frequent  itemsets (FFIs) in a level-wise manner. It uses the maxi- mum cardinality mechanism to generate-and-test the candidate itemsets level-by-level. This process can greatly reduce the computations for discovering FFIs but some information may thus be lost. Hong et al. [10] then designed gradual data- reduction (GDF) approach for mining multiple fuzzy frequent itemsets (MFFIs). This approach is used to mine FFIs with multiple fuzzy regions based on Apriori-like mechanism; the amounts of computations are still required to generate-and- test candidates in a level-wise manner. In this paper, a fuzzy- list-based (FL)-Miner algorithm is presented to mine MFFIs.

Two efficient pruning strategies are respectively designed to reduce the search space of the enumeration tree based on the fuzzy-list structure. In the conducted experiments, it can be found that the proposed approaches outperform the state-of- the-art Apriori-based algorithm in terms of execution time and memory usage.



II. RELATED WORK  It is an efficient way to adopt fuzzy-set theory [16] for mining fuzzy association rules from the quantitative databases since the discovered information can be represented in linguis- tic terms using natural language, which is more understandable for human beings. In the past, Chan et al. [4] proposed the F-APACS algorithm to discover the fuzzy association rules (FARs) by transforming the quantitative values of attributes into linguistic representations. Kuok et al. [11] then designed an efficient method to discover the FARs from the numerical databases. Hong et al. [8] developed the FDTA algorithm to mine FARs from the quantitative databases. Lin et al. then respectively designed the fuzzy frequent pattern (FFP)-tree algorithm [12], the compressed fuzzy frequent pattern (CFFP)- tree [13] algorithm and upper-bound fuzzy frequent pattern (UBFFP)-tree algorithm [15] for deriving FFIs.

The above approaches adopt the maximal cardinality mecha- nism to keep at most one linguistic term of each item, which is insufficient to present the complete information from the trans- formed databases. To reveal more complete information, Hong et al. then presented an efficient algorithm called GDF [10] to merge the same fuzzy sets of the transformed transactions into smaller transformed databases, thus speeding up the computations for level-wisely mining the FARs. This approach is used to generate the MFFIs, thus revealing more complete information than traditional ones. The multiple database scan is, however, required to level-wisely mine the MFFIs.



III. PRELIMINARIES AND PROBLEM STATEMENT  In this section, the preliminaries and the problem statement of multiple fuzzy frequent itemset mining (MFFIM) are re- spectively described as follows.

A. Preliminaries  Let I = {i1, i2, . . . , im} be a finite set of m distinct items (attributes) in a quantitative database D = {T1, T2, . . . , Tn}, in which each transaction Tq ? D is a subset of I, contains several items with its purchase quantities viq and has an unique identifier, called TID. An itemset X is a set of k distinct items {i1, i2, . . . , ik}, where k is the length of an itemset called k- itemset. An itemset X is said to be contained in a transaction Tq if X ? Tq . A minimum support threshold is defined as ?. The user-specified membership functions is set as ?. A quantitative database is shown in Table I as a running example to illustrate the proposed approach in this paper. It consists of 8 transactions and 5 distinct items, which are respectively denoted as (A) to (E). The minimum support threshold is initially set as ? (= 25%). The membership functions used in this example are shown in Fig. 1. Note that all items in the given example used the same membership functions to fuzzifier their quantitative values.

TABLE I: A quantitative database.

TID Items 1 (C:3), (D:2), (E:1) 2 (B:1), (C:2), (D:1) 3 (B:3), (C:3), (E:1) 4 (A:3), (C:5), (D:3) 5 (A:1), (B:1), (C:2), (D:1) 6 (B:1), (D:1), (E:2) 7 (A:4), (B:3), (D:5), (E:3) 8 (B:1), (C:2), (D:1)  Definition 1. The linguistic variable Ri is an attribute of a quantitative database whose value is the set of fuzzy linguistic terms represented in natural language as (Ri1, Ri2, . . . , Rih) and can be defined in the membership functions ?.

For example, there are five attributes as (A), (B), (C), (D), and (E) in Table I, and the number of linguistic terms is set as 3 which can be are represented as Low(L), Middle(M), and High(H), shown in Fig. 1.

Fig. 1: The used membership functions of fuzzy linguistic 3-terms.

Definition 2. The quantitative value of i denoted as viq , is the quantitative of the item i in transaction Tq .

For example, the quantitative values of the items (C), (D) and (E) in T1 respectively are vC1 (= 3), vD1 (= 2), and vE1(= 1).

Definition 3. The fuzzy set, denoted as fiq , is the set of fuzzy linguistic terms with their membership degrees (fuzzy values) transformed from the quantitative value viq of the linguistic variable i by the membership functions ? as:  fiq = ?i(viq)(= fviq1 Ri1  + fviq2 Ri2  + ? ? ? + fviqh Rih  ), (1)  where h is the number of fuzzy linguistic terms of i transformed by ?, Ril is the l-th fuzzy linguistic terms of i, fviql is the membership degree (fuzzy value) of viq of i in the l-th fuzzy linguistic terms Ril and fviql ? [0, 1].

For example, the item (C) with its quantitative value 3 in  T1 is transformed by the membership functions in Fig. 1 as ( 0.67C.M +  0.5 C.H ). Thus, the Table I is then transformed by the  membership functions shown in Fig. 1, and the transformed results are shown in Table II.

TABLE II: Transformed results from Table I.

TID Transformed linguistic terms 1 0.67  C.M + 0.5  C.H , 0.5  D.L + 0.67  D.M , 1.0  E.L  2 1.0 B.L  , 0.5 C.L  + 0.67 C.M  , 1.0 D.L  3 0.67 B.M  + 0.5 B.H  , 0.67 C.M  + 0.5 C.H  , 1.0 E.L  4 0.67 A.M  + 0.5 A.H  , 1.0 C.H  , 0.67 D.M  + 0.5 D.H  5 1.0 A.L  , 1.0 B.L  , 0.5 C.L  + 0.67 C.M  , 1.0 D.L  6 1.0 B.L  , 1.0 D.L  , 0.5 E.L  + 0.67 E.M  7 1.0 A.H  , 0.67 B.M  + 0.5 B.H  , 1.0 D.H  , 0.67 E.M  + 0.5 E.H  8 1.0 B.L  , 0.5 C.L  + 0.67 C.M  , 1.0 D.L  Definition 4. The transformed fuzzy linguistic term Ril is represented and denoted as the fuzzy itemset in the field of fuzzy data mining.

For example, the fuzzy linguistic term (A.L) can be repre- sented as a fuzzy itemset of the transformed databases.

Definition 5. The support of the fuzzy itemset, denoted sup(Ril), is the sum of its transformed fuzzy values, which can be defined as:  sup(Ril) = ?  Ril?Tq?Tq?D? fviql, (2)  where D? is the quantitative database D transformed by membership functions (= ?), and the size of D? is the same as the original D.

For example in Table II, the fuzzy itemset (C.M ) appears in transactions T1, T2, T3, T5 and T8; the support of (C.M ) can be calculated as: sup(C.M) (= 0.67 + 0.67 + 0.67 + 0.67 + 0.67) (= 3.35).

Definition 6. The support of fuzzy k-itemset (k ? 2), denoted as sup(X), is the sum of the minimal fuzzy value among k items of X , which can be defined as:  sup(X) ={X ? Ril| ?  X?Tq?Tq?D? min(fvaql, fvbql),  a, b ? X, a /? b}.

(3)  For example in Table II, the fuzzy 2-itemset (B.L,C.M) appears in transactions T2, T5, and T8. The support of (B.L,C.M) is thus calculated as: sup(A.L,C.H) = {min(1.0, 0.67) + min(1.0, 0.67) + min(1.0, 0.67)} = (0.67 + 0.67 + 0.67) (= 2.0).

B. Problem Statement  The problem of MFFIM in this paper is to discover the complete set of MFFIs, in which the support count of each fuzzy itemset X is no less than the pre-defined minimum support count as:  MFFIs ? {X|sup(X) ? ? ? |D|}, (4) where ? is the minimum support threshold, and |D| is the database size.



IV. PROPOSED FL-MINER ALGORITHM  In the past, most algorithms handle the fuzzy frequent item- set mining using the maximum scalar cardinality mechanism to derive the FFIs [8], [12], [13], [15]. In this paper, an efficient fuzzy-list structure is presented to compress the databases and keep the necessary information for later mining process. Two efficient pruning strategies are also developed to prune the search space for discovering the MFFIs.

For the quantitative database, the pre-defined membership  functions are first used to convert the quantitative value of each linguistic variable (item) into several fuzzy linguistic terms (fuzzy itemsets) with their membership degrees (fuzzy values). The fuzzy values of the same fuzzy itemset are then summed up together as the support value of it. In this phase, if the fuzzy itemset with its support count is no less than the minimum support count, it is concerned as the fuzzy frequent itemset and kept in the transformed databases. This process is then performed for all fuzzy linguistic terms to find the set of the complete multiple fuzzy frequent 1-itemsets in the  databases and concerned them as the multiple fuzzy frequent 1-itemsets (L1). After that, the fuzzified quantitative database is then revised to keep the discovered fuzzy itemsets in L1. The remaining itemsets in L1 are then sorted in support-ascending order of each transaction. After that, the set of complete fuzzy frequent 1-itemsets and the revised database is then outputted (Line 11). The revised database from Table II is shown in Table III.

TABLE III: A revised database.

TID Items 1 0.5  C.H , 1.0 E.L  , 0.67 C.M  , 0.5 D.L  2 0.67 C.M  , 1.0 B.L  , 1.0 D.L  3 0.5 C.H  , 1.0 E.L  , 0.67 C.M  4 1.0 C.H  5 0.67 C.M  , 1.0 B.L  , 1.0 D.L  6 0.5 E.L  , 1.0 B.L  , 1.0 D.L  7 0.67 C.M  , 1.0 B.L  , 1.0 D.L  A. Fuzzy-list Construction  After the original database is transformed and revised, the remaining fuzzy itemsets in L1 are used to build their own fuzzy-list structure for keeping the necessary information. The definitions used in the fuzzy-list structure are given below.

Definition 7. A fuzzy itemset Ril in transaction Tq , and Ril ? Tq . The set of fuzzy itemsets after Ril in Tq is denoted as: Tq/Ril.

For example in Table III, T1/(C.H) = (E.L,C.M,D.L) and T1/(E.L) = (C.M,D.L).

Definition 8. The fuzzy value of Ril in transaction Tq is defined as the internal fuzzy value and denoted as: if(Ril, Tq).

For example, the internal fuzzy value of (C.H) in T1 is if(C.H, T1) (= 0.5).

Definition 9. The resting fuzzy value except Ril in transaction Tq is denoted as rf(Ril, Tq). This value is calculated by performing the maximum operation to get the maximum fuzzy value among the resting fuzzy itemsets in the transaction, which can be considered as the upper-bound value of Tq/Ril in Tq and defined as:  rf(Ril, Tq) = max{if(z, Tq)|z ? (Tq/Ril)}. (5) For example in Table III, the resting fuzzy value in T1  after (C.H) is calculated as: max{1.0, 0.67, 0.5} (= 1.0) and the resting fuzzy value in T3 after (C.H) is calculated as max{1.0, 0.67} (= 1.0).

Thus, in the designed fuzzy-list structure, it consists of three  elements as: (1) transaction TID(tid) indicates a transaction Tq containing Ril. (2) internal fuzzy value (if) shows the fuzzy value of Ril in Tq . (3) resting fuzzy value (rf) states the maximum fuzzy value of the resting fuzzy itemsets after Ril in Tq .

From the given example shown in Table III, the initial  fuzzy-list structures of the fuzzy frequent 1-itemsets in L1 are     respectively constructed. Since the support-ascending order of the itemsets in L1 are sorted as (C.H < E.L < C.M < B.L < D.L), the results of the constructed fuzzy-list structure for all fuzzy frequent 1-itemsets in L1 are shown in Fig. 2.

tid rf  C.H  if  C.M B.L D.LE.L  Fig. 2: The initial constructed fuzzy-list structures.

For example in Fig. 2, the element (1, 0.5, 0.67) in the fuzzy-list of (C.H) showed; 1 represents the transaction T1; 0.5 represents the internal fuzzy value is 0.5; 0.67 represents the resting fuzzy value after (C.H) is 0.67. The rest fuzzy 1-itemsets are processed in the same way. For the fuzzy-list structures of fuzzy k-itemsets (k ? 2), it is unnecessary to scan the revised database but only perform the intersection operation of the fuzzy-list by the tids in k fuzzy-list structures.

The fuzzy-list structures are performed in 2-way comparisons to quickly find the combined fuzzy-list structures. Suppose the lengths of two fuzzy-list structures are respectively m and n. Thus, it requires at most (m + n) comparisons to form the fuzzy-list structures of fuzzy 2-itemsets. The construction algorithm of fuzzy-list structure is shown in Algorithm 1.

Algorithm 1: Fuzzy-list Construction Input: Px.FL, the fuzzy-list of Px; Py.FL, the  fuzzy-list of Py . Pxy.FL the fuzzy-list of x and y.

1 if Px and Py belong to the same item then 2 return null.

3 Pxy.FL ? null; 4 for each Ex ? Px.FL do 5 if ?Ey ? Py.FL and Ex.tid == Ey.tid then 6 Exy.tid ? Ex.tid; 7 Exy.if ? min(Ex.if, Ey.if); 8 Exy.rf ? Ey.rf ; 9 Exy ?< Exy.tid, Exy.if, Exy.rf >; 10 append Exy to Pxy.FL.

11 return Pxy.FL.

First, the fuzzy k-itemsets can be combined together to form the fuzzy (k+1)-itemsets iff the combined itemsets are not from the same item since it produces meaningless information (Lines 1 to 2). The fuzzy itemsets with the same tids are found to generate the fuzzy k-itemsets (Line 6). The minimum  (intersection) operation is used to find the internal fuzzy value of fuzzy k-itemsets (Line 7). Since the support-ascending order is used for constructing the initial fuzzy-list structures, the resting fuzzy values of later fuzzy itemsets are directly assigned to the element of fuzzy k-itemsets (Line 8). The combined results of fuzzy (k+1)-itemsets (Lines 9 to 10) are thus constructed.

Definition 10. The SUM.Ril.rf is to sum the fuzzy values of Ril in D?, which can be defined as:  SUM.Ril.if = ?  Ril?Tq?Tq?D? if(Ril, Tq). (6)  For example in Fig. 2, the summation of the fuzzy value for (C.H) is calculated as (0.5 + 0.5 + 1.0) (= 2.0).

Definition 11. The SUM.Ril.rf is to sum the resting fuzzy values after Ril in D?, which can be defined as:  SUM.Ril.rf = ?  Ril?Tq?Tq?D? rf(Ril, Tq). (7)  For example in Fig. 2, the summation of the resting fuzzy values for (C.H) is calculated as (0.67 + 0.67 + 0) (= 1.34).

B. Search Space of Enumeration Tree  Based on the designed fuzzy-list structure, the search space of the proposed FL-Miner algorithm can be represented as an enumeration tree according to the developed support- ascending order strategy. First, the root node is built. The fuzzy frequent 1-itemsets are then respectively created as the child nodes of the root node. The fuzzy frequent 1-itemsets are first built as the child nodes of the root. The depth-first search strategy is used to traverse the enumeration tree and decide whether the child (superset) nodes are required to be generated and explored. In this example, the search space of the enumeration tree is shown in Fig. 3.

C.H <E.L< C.M < B.L < D.L  ??  ??  root  C.H          E.L         C.M        B.L        D.L  C.H, B.L C.H, E.L C.H, D.L E.L, C.M E.L, B.L  C.H, B.L, E.L C.H, B.L, D.L  Fig. 3: An enumeration tree of the used example.

Since the complete search space of the enumeration tree is very huge for discovering all MFFIs, it is necessary to reduce the search space but still can completely find the MFFIs. The designed pruning strategy is given below.

Strategy 1 (Pruning by internal value). For an itemset X, if SUM.X.if is less than the minimum support count, it is not considered as a fuzzy frequent itemset and the supersets of X are unnecessary generated and explored in the enumeration tree.

Theorem 1. Given the fuzzy-list of a fuzzy itemset Ril. If the summed up fuzzy values of Ril is less than minimum support count (??|D?|), any extensions of Ril are not the MFFIs and can be discarded in the search space.

Proof. For ?Tq ? X ?, suppose a fuzzy itemset Ril is denoted as X, and X? is the extension of X, thus: (X ? ?X) = (X ?/X).

? X ? X ? ? Tq ? (X ?/X) ? (Tq/X).

? if(X ?, Tq) = min{if(X,Tq), if((X ? ?X), Tq)}  = min{if(X,Tq), if((X ?/X), Tq)} ? X ? X ? ? X ?tids ? X.tids.

? SUM.X ?.if =  ? X??Tq?Tq?D? if(X  ?, Tq) ? ?X??Tq?Tq?D? if(X ?/X, Tq) = min{if(X,Tq), if((X ?/X), Tq)} ? SUM.X.if.

Strategy 2 (Pruning by resting value). For a fuzzy itemset X , if SUM.X.rf of X is less than the minimum support count, the supersets of X are unnecessary generated and explored in the enumeration tree.

Theorem 2. Given the fuzzy-list of Ril. If the summed up resting fuzzy values of Ril is less than minimum support count (? ? |D?|), any extensions of Ril are not the MFFIs and can be discarded in the search space.

Proof. For ?Tq ? X ?, suppose Ril is denoted as X, and X? is the extension of X, thus: (X ? ?X) = (X ?/X).

? X ? X ? ? Tq ? (X ?/X) ? (Tq/X).

? if(X ?, Tq) = min{if(X,Tq), if((X ? ?X), Tq)}  = min{if(X,Tq), if((X ?/X), Tq)} = min{if(X,Tq), rf(Ril, Tq)}  ? X ? X ? ? X ?tids ? X.tids.

? SUM.X ?.rf =  ? X??Tq?Tq?D? if(X  ?, Tq) ? ?X??Tq?Tq?D? if(X ?/X, Tq) ? ?X??Tq?Tq?D? rf(X ?/X, Tq) = SUM.X.rf.

Thus, if the sum of the internal fuzzy values or resting fuzzy values of the fuzzy itemsetX is less than the minimum support count, any extensions of X will not be the MFFIs and can be directly ignored to avoid the construction phase for its fuzzy- list structure and the search space can thus be reduced and pruned in the enumeration tree.

For example, consider the fuzzy 3-itemset (C.M, B.L, D.L) is the extension of the fuzzy 2-itemset (C.M,B.L). Since the summed up internal fuzzy values and resting fuzzy values of (C.M,B.L) are respectively calculated as (0.67 + 0.67 + 0.67) (= 2.0 ? 2.0) and (1.0 + 1.0 + 1.0) (= 3.0 ? 2.0); the extension (C.M,B.L,D.L) in the enumeration tree is generated and explored. For the fuzzy 3-itemset (E.L,C.M,B.L) which is the extension of the fuzzy 2-itemset (E.L,C.M); the summed up internal fuzzy values and the resting fuzzy values of (E.L,C.M) are respectively calculated as (0.67 + 0.67) (= 1.34 < 2.0) and (0.5 + 0) (= 0.5 < 2.0); the fuzzy-list structure for the extension (E.L,C.M,B.L) is unnecessary constructed since this fuzzy 3-itemset cannot be considered as a fuzzy frequent itemset based on the two pruning strategies.

Details of the proposed fuzzy-list-based (FL)-Miner algorithm is described in Algorithm 2.

Algorithm 2: FL-Miner Input: FLs, fuzzy-list of 1-itemsets; ?.

Output: MFFIs, the set of MFFIs.

1 for each fuzzy-list X in FLs do 2 if SUM.X.if ? ? ? |D?| then 3 MFFIs ? X ?MFFIs.

4 if SUM.X.rf ? ? ? |D?| and  SUM.X.if ? ? ? |D?| then 5 exFLs ? null; 6 for each fuzzy-list Y after X in FLs do 7 exFL ? exFLs + Construct(X,Y ); 8 FL-Miner(exFLs, ?);  9 return MFFIs.

The FL-Miner algorithm first checks the sum of internal fuzzy values of the determined itemset X against to the minimum support count (Line 2). If the sum of internal fuzzy value for X is no less than the minimum support count, it is then put into the set of MFFIs (Line 3). The sum of the resting fuzzy values is also checked against to the minimum support count (Line 4). If the sum of fuzzy value and resting fuzzy value are both no less than the minimum support count, the extension fuzzy-list structure of X is constructed in the enumeration for later mining process (Lines 5 to 8). This process is repeated until no extensions are generated. After that, the complete set of the final MFFIs are discovered (Line 9).



V. EXPERIMENTAL EVALUATION  In this section, the FL-Miner algorithm adopts the prun- ing interval value strategy is named as FL-Miner1 and the FL-Miner algorithm adopts both pruning interval value and pruning resting value strategies is named as FL-Miner2 in the experiments. The state-of-the-art GDF [10] algorithm is used to compare with the designed approaches in terms of runtime and memory usage. The compared algorithms in the experiments were implemented in Java, performing a PC with     an Intel(R) Core(TM) i7-4790 CPU@3.60GHz and 8GB of RAM, running the 64-bit Microsoft Windows 7 operating system. Three real-life chess [6], mushroom [6], connect [6] and one synthetic T10I10D100k [6] dataset [6] are used in the experiments to evaluate the performance of the designed approaches. The quantities of items are randomly assigned in the range of [1, 5] interval in the used datasets. Parameters and characteristics of the datasets used in the experiments are respectively shown in Table IV and Table V.

TABLE IV: Parameters of used datasets.

| #D | Total number of transactions | #I | Number of distinct items AvgLen Average length of transactions MaxLen Maximal length of transactions Type Database type (sparse or dense)  TABLE V: Characteristics of used datasets.

Dataset | #D | | #I | AvgLen MaxLen Type chess 3,196 75 37 37 dense  mushroom 8,124 119 23 23 dense connect 67,558 130 43 43 dense  T40I10D100K 100,000 942 39.6 77 sparse  The quantitative datasets were first transformed into several fuzzy linguistic terms based on the pre-defined membership functions. In the conducted experiments, the membership functions of fuzzy linguistic 3-terms are used in the exper- iments, shown in Fig. 1. In the conducted experiments for mining MFFIs, the algorithm is terminated if the execution time exceeds 10,000 second. The results are then shown and analyzed as follows.

A. Runtime  In this section, the runtime of GDF algorithm compared to the designed FL-Miner1 and FL-Miner2 algorithms w.r.t.

variants of minimum support thresholds for the membership functions with fuzzy linguistic 3-terms is shown in Fig. 4.

From Fig. 4, it can be observed that the proposed approaches  outperform the state-of-the-art GDF algorithm for the member- ship functions of fuzzy linguistic 3-terms. The proposed FL- Miner1 and FL-Miner2 approaches have almost up to two or three orders of magnitude faster than GDF algorithm. Thanks to the advantages of the designed fuzzy-list structure, the transformed dataset can be compressed into a dense structure for keeping the necessary information to mine MFFIs. Besides, two developed pruning strategies can be used to greatly reduce the search space for discovering the MFFIs. The FL-Miner1 algorithm always performs better than FL-Miner2 in the dense datasets, which can be observed in Fig. 4(a), Fig. 4(b) and Fig.

4(c). This is reasonable since the FL-Miner2 algorithm adopts both two pruning strategies to early prune the amounts of candidates for mining MFFIs. For the sparse datasets, the items in the transactions may varying; the developed FL-Miner2 algorithm cannot efficiently prune the amounts of candidate  Fig. 4: Runtime with fuzzy linguistic 3-terms  itemsets but still outperforms the FL-Miner1 and the state-of- the-art GDF algorithm. Overall, the proposed two approaches are acceptable and both of them outperform the state-of-the-art GDF algorithm for mining MFFIs.

B. Memory Usage  In this section, we carried experiments to assess the memory usage of the compared algorithms. The results w.r.t. variants different minimum support thresholds for the membership functions of fuzzy linguistic 3-terms are shown in Fig. 5.

Fig. 5: Memory usage with fuzzy linguistic 3-terms  From Fig. 5, it can be observed that the proposed FL- Miner1 and FL-Miner2 algorithms requires less memory than the generate-and-test GDF algorithm in most datasets except the chess one. The reason is that the designed fuzzy-list structure can be used to compress the dataset as a dense structure. The designed pruning strategies can also be used to reduce the generations of the amounts of candidates in the     mining process. The GDF algorithm still suffers the generate- and-test approach to mine the MFFIs in a level-wise way.

When the dataset is a very dense one, the designed fuzzy- list structure becomes larger; more memory usage is required to keep more MFFIs, which can be observed in Fig. 5(a).

Overall, the memory usage of the designed approaches have better performance than that of the GDF algorithm in most cases.



VI. CONCLUSION  In the past, a level-wise GDF algorithm was presented to mine the MFFIs, which takes more computations to generate- and-test candidates at each level. In this paper, an efficient fuzzy-list structure is presented to keep the necessary infor- mation for mining MFFIs. Two pruning strategies are also designed to reduce the search space, thus speeding up com- putations and reducing memory usage to mine MFFIs. From the conducted results, it can be observed that the proposed approaches outperform the state-of-the-art GDF algorithm in terms of runtime and memory usage in both real-world and synthetic datasets.

