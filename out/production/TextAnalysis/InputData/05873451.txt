A Brief Review on Frequent Pattern Mining

Abstract?frequent pattern mining plays an essential role in association rule mining, which has been a focused theme in data mining research for over the past 15 years. Since the pioneering work of Agrawal, abundant literature has been dedicated to this research. In this article, we provide a brief overview of the current status of frequent pattern mining and discuss a few promising research directions.

Keywords-frequent pattern mining; association rules; application; review

I.  INTRODUCTION Frequent patterns are itemsets that appear in a data set with  frequency no less than a user-specified threshold. Finding frequent patterns plays an essential role in mining associations, correlations, and many other interesting relationships among data. Moreover, it helps in data indexing, classification, clustering, and other data mining tasks as well. Thus, frequent pattern mining has become an important data mining task and a focused theme in data mining research.

Frequent pattern mining was first proposed by Agrawal et al.[1,2] for market basket analysis in the form of association rule mining, which is useful for discovering interesting relationships hidden in large data sets. For example, we may find a strong relationship, which can be represented in the form of association rules or sets of frequent items, exists between the sale of diapers and beer because many customers who buy diapers also buy beer. Retailers can use this relationship to help them identify new opportunities for cross-selling their products to the customers. Besides market basket data, association rule mining is also application to other application domains such as bioinformatics, multimedia data mining, Web mining, and scientific data analysis.

Since the first proposal of this new data mining task and its associated efficient mining algorithms, there have been hundreds of follow-up research publications. In this article, we perform a brief overview of frequent pattern mining methods, representation and applications.



II. BASIC CONCEPT This section reviews the basic terminology used in  association analysis and presents a formal description of the task.

Itermset and Support Count Let 1 2{ , , , }dI i i i=  are the set of all items in a market basket data and  1 2{ , , , }NT t t t=  are the transactions. Each transaction it contains a subset of items chosen from I . In association analysis, a collection of zero or more items is termed an itemset.

If an itemset contains k  items, it is called a k-itemset.

A transaction it  is said to contain an itemset X  if X  is a subset of it . Mathematically, the support count ( )X? , for an itemset X  can be stated as:  ( ) { , }i i iX t X t t T? = ? ? .               (1)  The symbol ?  denotes the number of elements in a set.

Association Rule An association rule is an implication expression of the form X Y? , where X  and Y  are disjoint itemsets, i.e. X Y? = ? . The strength of an association rule can be measured in terms of its support and confidence.

Support determines how often a rule as applicable to a given data set, while confidence determines how frequently items in Y  appear in transactions that contain X . The formal definitions of these metrics are  ( ), ( ) .X YSupport s X Y N  ? ?? =              (2)  ( ), ( ) .

( )  X YConfidence c X Y X  ? ?  ?? =        (3)  Frequent Itemset A k-itemset X  is frequent if X  in a transaction database T  no lower than T?  times, where ?  is a user-specified minimum support threshold (called min_sup), and T  is the total number of transactions inT .

Association Rule Mining The association rule mining problem can be formally stated as follows: Given a set of transactions T , find all the rules having support ?  min_sup and confidence ?  min_conf, where min_sup and min_conf are the user-specified support and confidence thresholds.

A common strategy adopted by many association rule mining algorithms is to decompose into two major subtasks: Frequent Itemset Generation, whose objective is to find all the itemsets that satisfy the min_sup threshold; and Rule     Generation, whose objective is to extract all the high- confidence rules from the frequent itemsets found in the frequent itemset generation step.

The computational requirements for frequent itemset generation are generally more expensive than those of rule generation. Efficient techniques for generating frequent itemsets are reviewed in Section ?.



III. EFFICIENT ALGORITHMS FOR MINING FREQUENT PATTRENS  A.  Apriori algorithm and its extensions Since there are usually a large number of distinct single  items in a typical transaction database, and their combinations may form a very huge number of itemsets, it is challenging to develop callable methods for mining frequent itemsets in a large transaction database. Agrawal and Srikant [2] observed an interesting downward closure property, called Apriori, among frequent k-itemsets: A k-itemset is frequently if all of its sub-itemsets are frequent. This implies that frequent itemsets can be mined by first scanning the database to find the frequent 1-itemsets, then using the frequent 1-itemsets to generate candidate frequent 2-itemsets, and check against the database to obtain the frequent 2-itemsets. This process iterates until no more frequent k-itemsets can be generated for some k.

This is the essence of the Apriori algorithm [2] and its alternative [3].

Since the Apriori algorithm was proposed, there have been extensive studies on the improvements or extensions of Apriori, e.g., Park et al. [4] used hash technique to count support, instead of comparing each itemset in the transaction with every candidate itemset. Toivonen [5] proposed a sampling-based frequent itemset generation algorithm. Geerts et al. [6] derived a tight upper bound of the number of candidate patterns that can be generated in the level-wise mining approach. This result is effective at reducing the number of database scans.

B.  FP-growth algorithm and its extensions In many cases, the Apriori algorithm significantly reduces  the size of candidate sets using the Apriori principle. However, it can suffer from two-nontrivial costs: (1) generating a huge number of candidate sets, and (2) repeatedly scanning the database and checking the candidates by pattern matching. Han et al. [7] devised an FP-growth method that mines the complete set of frequent itemsets without candidate generation.

FP-growth works in a divide-and-conquer way. The first scan of the database derives a list of frequent items in which items are ordered by frequency-descending order. According to the frequency-descending list, the database is compressed into a frequent-pattern tree (FP-tree), which retains the itemset association information. The FP-tree is mined by starting from each frequent length-1 pattern (as an initial suffix pattern), constructing conditional pattern base, then constructing its conditional FP-tree, and performing mining recursively on such a tree. The pattern growth is achieved by the concatenation of the suffix pattern with the frequent patterns generated from a conditional FP-tree.

The FP-growth algorithm transforms the problem of finding long frequent patterns to searching for shorter ones recursively and then concatenating the suffix. It uses the least frequent items as a suffix, offering good selectivity. Performance studies demonstrate that the method substantially reduces search time.

There are many alternatives and extensions to the FP- growth approach, including depth-first generation of frequent itemsets by Agarwal et al.[8]; H-Mine, by Pei et al.[9] which explores a hyper-structure mining of frequent patterns; building alternative trees; exploring top-down and bottom-up traversal of such trees in pattern-growth mining by Liu et al.[10]; and an array-based implementation of prefix-tree-structure for efficient pattern growth mining by Grahne and Zhu [11].

C.  Eclat algorithm Both the Apriori and FP-growth methods mine frequent  patterns from a set of transaction horizontal data format (i.e.

{TID: itemset}), where TID is a transaction-id and itemset is the set of items bought in transaction TID. Alternatively, mining can also be performed with data presented in vertical data format (i.e. {item: TID_set}).

Zaki [12] proposed Equivalence CLASS Transformation (Eclat) algorithm by exploring the vertical data format. The first scan of the database builds the TID_set of each single item. Starting with a single item (k = 1), the frequent (k+1)- itemsets grown from a previous k-itemset can be generated according to the Apriori property, with a depth-first computation order similar to FP-growth [7]. The computation is done by inter section of the TID_sets of the frequent k- itemsets to compute the TID_sets of the corresponding (k+1)- itemsets. This process repeats, until no frequent itemsets or no candidate itemsets can be found.

Besides taking advantage of the Apriori property in the generation of candidate (k+1)-itemset from frequent k-itemsets, another merit of this method is that there is no need to scan the database to find the support of (k+1)-itemsets (for k ? 1). This is because the TID_set of each k-itemset carries the complete information required for counting such support.

Another related work which mines the frequent itemsets with the vertical data format is [13]. This work demonstrated that, though impressive results have been achieved for some data mining problems using highly specialized and clever data structures, one could also explore the potential of solving data mining problems using the general purpose database management systems.



IV. COMPACT REPRESENTATION OF FREQUENT ITEMSETS A major challenge in mining frequent patterns from a large  dataset is the fact that such mining often generates a huge number of patterns satisfying the min_sup threshold, especially when min_sup is set low. This is because if a pattern is frequent, each of its sub-patterns is frequent as well. A large pattern will contain an exponential number of smaller, frequent sub-patterns. To overcome this problem, closed frequent pattern mining and maximal frequent pattern mining were proposed [14, 17].

A pattern ? is a closed frequent pattern in a dataset D if ? is frequent in D and there exists no proper super-pattern ? such that ? has the same support as ? in D. A pattern ? is a maximal frequent pattern (or max-pattern) in set D if ? is frequent, and there exists no super-pattern ? such that ? ?  ? and ? is frequent in D. For the same min_sup threshold, the set of closed frequent patterns contains the complete information regarding to its corresponding frequent patterns; whereas the set of max-patterns, though more compact, usually does not contain the complete support information regarding to its corresponding frequent patterns.

The mining of frequent closed itemsets was proposed by Pasquier et al. [14], where an Apriori-based algorithm called A-Close for such mining was presented. Other closed pattern mining algorithms include CHARM [15], and FPClose [16].

The main challenge in closed frequent pattern mining is to check whether a pattern is closed. There are two strategies to approach this issue: (1) to keep track of the TID list of a pattern and index the pattern by hashing its TID values. This method is used by CHARM which maintains a compact TID list; and (2) to maintain the discovered patterns in a pattern-tree similar to FP-tree. This method is exploited by FPClose. Mining closed itemsets provides an interesting and important alternative to mining frequent itemsets since it inherits the same analytical power but generates a much smaller set of results. Better scalability and interpretability is achieved with closed itemset mining.

Mining max-patterns was first studied by Bayardo [17], where MaxMiner, an Apriori-based, level-wise, breadth-first search method was proposed to find max-itemset by performing superset frequency pruning and subset in frequency pruning for search space reduction. Another efficient method MAFIA, proposed by Burdick et al. [18], uses vertical bitmaps to compress the transaction id list, thus improving the counting efficiency. Yang [19] provided theoretical analysis of the complexity of mining max-patterns. The complexity of enumerating maximal itemsets is shown to be NP-hard.



V. APPLICATIONS Frequent patterns mining has been applied to a variety of  application domains, such as indexing and similarity search of complex structured data, multimedia mining, and web mining.

A. Indexing and similarity search of complex  data Complex objects such as transaction sequence, event logs,  proteins and images are widely used in many fields. Efficient search of these objects becomes a critical problem for many applications. Due to the large volume of data, it is inefficient to perform a sequential can on the whole database and examine objects one by one. High performance indexing mechanisms thus are in heavy demand in filtering objects that obviously violate the query requirement.

gIndex [20] proposes a discriminative frequent pattern- based approach to index structures and graphs. A fundamental problem arises: if only frequent patterns are indexed, how to find those queries which only have infrequent patterns? gIndex solved this problem by replacing the uniform support constraint with a size-increasing support function, which has very low  support for small patterns but high support for large patterns.

SeqIndex is one example using frequent pattern-based approach to index sequences. Taking frequent patterns as features, new strategies to perform structural similarity search were developed such as Grafil [21] and PIS [22].

B. multimedia datamining A multimedia database system stores and manages a large  collection of multimedia data, such as audio, video, image, graphics, speech, text, document, and hyper text data.

Multimedia data mining is finding patterns and knowledge from multimedia data.

Frequent pattern analysis in multimedia data plays a similar important role in multimedia data mining. To mine frequent patterns in multimedia data, each image object can be treated as a transaction and frequently occurring patterns among different images can be discovered. Za?ane et al. [23] developed a progressive algorithm for mining multimedia associations.

Chengcui Zhang et al. [24] proposed an automatic spatiotemporal mining system of rolling and adherent leukocytes for intravital videos.

C. Web mining Web mining is the application of data mining techniques to  discover patterns and knowledge from the Web [25]. There are three different types of web mining: web content mining, web structure mining, and web usage mining. Web content mining is a knowledge discovery task of finding information within web pages, while web structure mining aims to discover knowledge hidden in the structures linking web pages. Web usage mining is focused on the analysis of users? activities when they browse and navigate through the Web.

Association rules discovered for pages that are often visited together can reveal user groups [26] and cluster web pages.

Web access patterns via association rule mining in weblogs were proposed by [27]. Sequential pattern mining in weblogs could find browse and navigation orders (i.e. pages that are accessed immediately after another), which might be used to refine cache design and web site design.



VI. RESEARCH DIRECTIONS Although abundant literature published in research into  frequent pattern mining, however, there are still several critical research problems that need to be solved before frequent pattern mining can become a cornerstone approach in data mining applications.

First, the set of frequent patterns derived by most of the current pattern mining methods is too huge for effective usage.

There are proposals on reduction of such a huge set, including closed patterns, maximal patterns, approximate patterns, representative patterns, clustered patterns, and discriminative frequent patterns. However, it is still not clear what kind of patterns will give us satisfactory pattern sets in both compactness and representative quality for a particular application, and whether we can mine such patterns directly and efficiently. Much research is still needed to substantially    reduce the size of derived pattern sets and enhance the quality of retained patterns.

Second, we need mechanisms for deep understanding and interpretation of patterns, and contextual analysis of frequent patterns. The main research work on pattern analysis has been focused on pattern composition and frequency. The semantic of a frequent pattern includes deeper information: what is the meaning of the pattern; what are the synonym patterns; and what are the typical transactions that this pattern resides? In many cases, frequent patterns are mined from certain datasets which also contain structural information. We believe the deep understanding of frequent patterns is essential to improve the interpretability and the usability of frequent patterns. One initial study in this direction is done by Mei et al. [28].

Finally, applications often raise new research issues and bring deep in sight on the strength and weakness of an existing solution. This is also true for frequent pattern mining. Much work is needed to explore new applications of frequent pattern mining. For example, bioinformatics has raised a lot of challenging problems, and we believe frequent pattern mining may contribute a good deal to it with further research.



VII. CONCLUSIONS In this article, we present a brief overview of the current  status and future directions of frequent pattern mining. With over the past 15 years of extensive research, there have been hundreds of research publications and tremendous research, development and application activities in this domain. It is impossible for us to give a complete coverage on this topic with limited space and our limited knowledge. Hopefully, this short overview may provide a rough outline of the recent work and give people a general view of the field. In general, we feel that as a young research field in data mining, frequent pattern mining has an achieved tremendous progress and claimed a good set of applications.

