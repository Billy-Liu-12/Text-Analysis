Fast Online Dynamic Association Rule Mining

Abstract  At present, there are no association rule mining algo- rithms that are suitable for use in electronic commerce because they do not consider that new products are in- troduced and old ones are retired frequently and they as- sume that support thresholds do not change. I n  this paper; a new algorithm called Fast Online Dynamic Association Rule Mining (FOLDARM) i s  introduced for mining in eke- tronic commerce. I t  uses a novel tree structure known as a Support-Ordered Trie Itemset (SOTrieIT) structure to hold pre-processed transactional data. It allows FOLDARM to generate large 1 -itemsets and 2-itemsets quickly without scanning the database. I n  addition, the SOTrielT structure can be easily and quickly updated when transactions are added or removed. It also stores data that is independent of the support threshold and thus can be used for  mining with varying support thresholds without any degradation in per- formance. Experiments have shown that FOLDARM out- pelforms Apriori, a classic mining algorithm, by up to two orders of magnitude (100 times).

1. Introduction  Since the introduction of the Apriori algorithm [l]  in 1994, there has been sustained interest in researching new association rule mining algorithms that can perform more efsciently. However, to the best of our knowledge, these ex- isting algorithms are not designed for use in a fast-changing and widely distributed environment like the Internet. In electronic commerce where a huge number of transactions can arrive at a virtual store from all over the world 24 hours a day, transaction databases are expected to be updated fre- quently. Thus, existing algorithms that are designed to mine static databases that are not expected to change, will not be able to perform as well with databases that are constantly changing. There are some algorithms that can perform in- cremental mining, which means that they can improve min-  ing speed by reusing past mined information. However, in the next section, we will see that such algorithms cannot cope with databases with very frequent updates.

In addition, in a highly competitive setting like elec- tronic commerce, companies will need to constantly intro- duce new products and remove unpopular products to sat- isfy the increasingly demanding needs of the now empow- ered customer. This means that the number and type of unique items in the database will change very often. Unfor- tunately, existing algorithms assume that unique items are &xed and thus, each time items are added or removed, the algorithms must mine the database from scratch and discard valuable past mined results.

Finally, given the dynamism and volatility of transac- tional data in electronic commerce, companies cannot pre- dict a suitable support threshold to set for the mining pro- cess. Using too high a threshold may result in too many unimportant rules while too low a threshold may result in certain important rules being passed over. Therefore, there is a need to mine the database with several different support thresholds before an optimal threshold can be determined.

This critical need has not been effectively tackled by current algorithms.

Recently, we have introduced an innovative algorithm called Rapid Association Rule Mining (RARM) [2] to mine static databases efEciently. In this paper, a new algo- rithm called Fast Online Llynamic Association Rule Min- ing (FOLDARM) is proposed as an extension of RARM so that association rule mining can be performed more ef&- ciently in electronic commerce. Like RARM, FOLDARM constructs a new data structure called Support-Ordered Trie Itemset (SOTrieIT). This trie-like tree structure stores the support counts of all I-itemsets and 2-itemsets in the database. All transactions that arrive are pre-processed; all 1 -itemsets and 2-itemsets are extracted from each transac- tion. The extracted information will be used to update the SOTrieIT without the need for prior knowledge of the sup- port threshold. This structure is sorted according to the sup- port counts of each node in descending order. FOLDARM  0-7695-1393-WO2 $17.00 0 2002 IEEE 278  mailto:wkn@acm.org   uses SOTrieIT to quickly discover large 1-itemsets and 2- itemsets without scanning the database. The need to gener- ate candidate 1 -itemsets and 2-itemsets constitutes the main bottleneck in large itemset generation, as observed in [3].

Therefore, by eliminating this need, FOLDARM achieves signifcant speed-ups. Subsequently, i t  applies the Apriori algorithm to obtain larger-sized itemsets. Moreover, unlike RARM, FOLDARM allows transactions and unique trans- actional items to be added and removed without the need to destroy the current SOTrieIT and rebuild it.

It is now clear to see how FOLDARM obtains its name; it  is fasr because the SOTrieIT is constructed in an incre- mental manner; it is online because users can vary the sup- port threshold while maintaining the same performance; it is dynamic because the unique set of items, which we deEne as the Universal Itemset, can be changed and be easily ac- commodated in the SOTrieIT. Experiments have been con- ducted to study the performance of FOLDARM and com- pare it against Apriori [ 11. FOLDARM is found to be up to 100 times faster than Apriori.

The rest of the paper is organized as follows. The next section reviews related work. Section 3 gives a description of the problem while Section 4 presents the new tree struc- ture. Section 5 describes the FOLDARM algorithm. Time and space complexity of the new structure will be examined in Section 6. Performance evaluation is discussed in Section 7. Section 8 compares the salient features of FOLDARM with existing algorithms to explain its edge over them. Fi- nally, the paper is concluded and recommendations for fu- ture work are made in Section 9.

2. Related Work  The Apriori algorithm [ I ]  is the Erst successful algo- rithm for mining association rules. Since its introduction, it has popularized the task of mining association rules and sparked off many research papers. It introduces a method to generate candidate itemsets c k  in a pass k using only large itemsets L k - 1  in the previous pass. The idea rests on the fact that any subset of a large itemset must be large as well.

Hence, c k  can be generated by joining L k - 1  and deleting those that contain any subset that is not large. This would result in a signifcantly smaller number of candidate item- sets being generated.

After Apriori, the Direct Hashing and Pruning (DHP) algorithm [3] is the next most widely used algorithm for the effcient mining of association rules. It employs a hash technique to reduce the size of candidate itemsets and the database. This amounts to signifcant speed-ups because the dominating factor in the generation of large itemsets is the size of the candidate itemsets. DHP has signiEcant speed improvements due to the reduced size of the candi- date itemsets generated. However, it incurs additional over-  heads due to the need to do hashing and to maintain a hash table. After some experiments [3], it is concluded that the hash technique should only be applied during the genera- tion of candidate 2-itemsets to achieve speed-ups of up to 3 times against Apriori.

The Fast Update (FUP) algorithm [4] is an incremental algorithm which makes use of past mining results to speed up the mining process. Its successor, the Fast Update Two (FUP2) algorithm [ 5 ] ,  is a faster version and generalization of it. By setting bounds for the support counts of candidate itemsets, it is able to reduce the size of Ck and improve its efEciency. By re-using past mining information, FUP2 reduces the number of candidate sets and hence achieves a speed improvement of up to 2 times over Apriori. However, when the size of the updates exceeds 40% of the original database, Apriori performs better.

Incremental mining is brought to another new level when the Adaptive algorithm [6] is introduced. This algorithm is not only incremental but also adaptive in nature. By in- ferring the nature of the incremental database, it can avoid unnecessary database scans. Experiments have shown that it can perform up to seven times faster than Apriori.

Unlike all the discussed algorithms, the Continuous As- sociation Rule Mining Algorithm (CARMA) [7] allows the user to change the support threshold and continuously dis- plays the resulting association rules with support and conf- dence bounds during the Erst scan or phase. During the sec- ond phase, i t  determines the precise support of each item- set and extracts out all the large itemsets. With the sup- port lattice, CARMA can readily compute large itemsets for varying support thresholds. However, experiments reveal that CARMA only performs faster than Apriori at support thresholds of 0.25% and below.

Finally, the Frequent Puttern-growth (FP-growth) algo- rithm [8] is a most recent association rule mining algorithm which achieves impressive results. It uses a compact tree structure called a Frequent Pattern-tree (FP-tree) to store information about large 1 -itemsets. This compact struc- ture also removes the need for database scans and it is con- structed using only two scans. In the Erst database scan, large 1-itemsets L1 are obtained and sorted in support de- scending order. In the second scan, items in the transac- tions are Erst sorted according to the order of L1. These sorted items are used to construct the FP-tree. FP-growth then proceeds to recursively mine FP-trees of decreasing size to generate large itemsets without candidate generation and database scans. It does so by examining all the condi- tionalpattern bases of the FP-tree, which consists of the set of large itemsets occurring with the suffx pattern. Condi- tional FP-trees are constructed from these conditional pat- tern bases and mining is carried out recursively with such trees to discover large itemsets of various sizes. However, since the construction and use of the FP-trees are complex,     the performance of FP-growth is reduced to be on par with Apriori at support thresholds of 3% and above. It only achieves signiEcant speed-ups at support thresholds of 1.5% and below. Moreover, it is only incremental to a certain ex- tent depending on the FP-tree watermark (validity support threshold).

The features and performance of the discussed algo- rithms are presented in Figure 1. To sum up, none of the algorithms are suitable for use in electronic commerce be- cause there is not one that is incremental, supports dynamic thresholds and at the same time, performs fast enough for online queries. Moreover, all of them assume that the uni- versal set of unique items do not change. Should the unique items change, mining must be done from afresh and past mined information cannot be reused. In contrast, our pro- posed algorithm, FOLDARM possesses all the essential features of an ideal mining algorithm for electronic com- merce.

3. Problem Description  The problem of mining association rules is described as follows: Let the universal itemset, I = {a l la2 ,  ... ,a,} be a set of literals called items. Let D be a database of transac- tions, where each transaction T contains a set of items such that T 5 I .  An itemset is a set of items and a k-itemset is an itemset that contains exactly k items. For a given itemset X C I and a given transaction T,  T contains X if and only if X C T.  Let ux be the support count of an itemset X ,  which is the number of transactions in D that contain X. Let s be the support threshold and ID( be the number of transactions in D. An itemset X is large or frequent if g , ~  >, [Dl x s%.

An association rule is an implication of the form X j Y , where X C_ I ,  Y 5 I and X n Y = 0. The association rule X ===+ Y holds in the database D with conxdence c% if no less than c% of the transactions in D that contain X also contain Y .  The association rule X ===+ Y has support s% in D if gxUy = (Dl x s%.

For a given pair of conEdence and support thresholds, the problem of mining association rules is to discover all rules that have conEdence and support greater than the cor- responding thresholds. For example, in a computer hard- ware shop, the association rule Digital Camera ===+ Printer means that whenever customers buy digital cameras, they also buy printers c% of the time and this trend occurs s% of the time. This problem consists of Ending large item- sets Erst and then generating association rules from the large itemsets. We will only address the Erst sub-problem of End- ing large itemsets because it is much more computationally expensive and thus it is the main bottleneck in association rule mining.

4. Data Structure  Though our new data structure, the SOTrieIT, is de- scribed in detail in  our previous work [ 2 ] ,  we will b r i a y describe it  here again for completeness.

4.1. A Complete TrieIT  The database D of transactions is stored in a forest of lexicographically-ordered tree nodes known as Trie Item- set (TrieIT). Let the set of items I = { u l ,  a2 , .  . . , a N } be ordered so that for any two items a l  E I , a ,  E I (1 < i , j  f N ) ,  a, < a3 if and only if i < j.

Dehition 1 (Complete TrieIT)  A complete TrielT is a tree structure such that every tree node w is a 2-tuple (wel w,) where we E I is the label of the node and w C  is a support count. Since every tree node corresponds to some item a, E I ,  for  brevity, we also use w, to refer to a tree node that corresponds to a l  E I .  The following conditions hold:  I .  Let C(wz) be the ordered set of children nodes of wz.

2. Given a node w,, let W k ,  Wk+l,. . . , w t - l ( l  < k 6 i - 1) be the set of nodes on the path from the root to the parent of w,, then w, is a count of the itemset { a k ,  ak+l , .. , , a,} in the database. Hence, the sup- port count of any k-itemset can be obtained by follow- ing a set of nodes to a depth of k.

!fC(W,) # 0, then C(WJ c {WL+l,  W2+2,  ' .  . 1  WN}.

Let Wi be a complete TrieIT whose root node has label a,. Then the D is stored in a set of complete TrietTs denoted  I by W where W C_ {Wi , Wz, . . . , W N } .

For every transaction that arrives, the complete TrieIT needs to be updated with the powerset of the transaction items. The amount of storage space needed by the complete TrieIT scales exponentially with respect to the number of unique items. Hence, with its expensive computation and storage requirements, the complete TrieIT is not a practical data structure. We will discuss a better alternative in the next section.

4.2. Support-Ordered Trie Itemset  This new design builds on the ideas presented in the pa- per on DHP [3]. In that paper, i t  is discovered that genera- tion of large 2-itemsets is the main performance bottleneck.

Using a hashtable, DHP is able to improve performance sig- niEcantly by reducing the size of the candidate 2-itemsets.

Similarly, this approach seeks to End a data structure that allows for quick generation of large 2-itemsets without the     Algorithm Incremental Apriori X DHP X FUP2 J CARMA X FP-growth X  TID Items -1  Dynamic support threshold Speed-up against Apriori X 1 X 3 X 2  X 10 (s I 1.5%) J 2 ( s  I 0.2%)  Figure 1. Summary of Algorithms.

Figure 2. An example transaction database with N = 4.

heavy processing and memory requirements of the complete TrieIT. The solution is a 2-level support-ordered tree which is called a SOTrielT (Support-Ordered Trie Itemset).

Deenition 2 (SOTrieIT)  TrielT except the following: A SOTrielT has the same properties as the complete  1. Let Y, be a SOTrielT whose root node has label ai.

Let Y be a set of SOTrielTs which stores the support counts of all I-itemsets and 2-itemsets in D such that  2. The nodes are sorted according to their support counts I  In other words, the set of SOTrieITs only keeps a record of all 1-itemsets and 2-itemsets contained in a transaction.

Therefore, much computation time is saved as compared to the case with the complete TrieIT where the power- set of transaction items is extracted. The Erst-level nodes represent 1 -itemsets while second-level nodes represent 2- itemsets. The resultant structure will be much smaller than the multi-level complete TrieIT. Henceforth, we shall use the term SOTrieIT to denote a set of SOTrieITs. By keeping track of the support counts of all 1-itemsets and 2-itemsets, SOTrieIT allows both large 1-itemsets and 2-itemsets to be found very quickly. This is because there is no need to scan the database which could be very large. Instead, only the small SOTrieIT is scanned. Moreover, as the SOTrieIT is sorted according to the support counts of the itemsets, only part of the structure needs to be scanned.

y c {Y,,Y2,. . . ,YlV).

in descending order from the lep.

Example Figure 3 represents the fully constructed SOTrieIT for the example transaction database in Figure 2.

To illustrate how nodes are created, let us examine what  happens when a new transaction arrives. Note that only 1- itemsets and 2-itemsets are extracted from the transactions.

When both transaction 100 and 200 arrive, the nodes created are shown in Figures 3(a) and 3(b). Notice that in Figure 3(b), the node wc under the ROOT node comes before the node W A .  This is because the nodes are sorted according to their support counts and wc has a higher support count than WA.  When transaction 300 arrives, the following itemsets areextracted: { A } ,  { B } , { C } ,  { A , B } ,  { A , C } , { B , C }  Figure 3(c) shows the resultant SOTrieIT when this transaction is processed. When transaction 400 arrives, the following itemsets are extracted:  {B ,  D}, {C, D } .  The SOTrieITs are updated in a similar fashion for transaction 400 as seen in Figure 3(d).

{ A } ,  {B), {C) ,  { D } ,  {A ,  B ) ,  {A ,  c>, {A ,  01, { B ,  c>,  Correctness We need to show that with a SOTrieIT, the support counts of all 1-itemsets and 2-itemsets can be cor- rectly obtained without scanning the database. Let T, be a transaction of size s and T, = { b l ,  b2 , .  . . , b , } .

The 1-itemsets that are extracted and used to build W are { b l } ,  { bz} ,  . . . , { b,} and the 2-itemsets extracted are {&,by} where 0 < z < s and z < y < s. These itemsets update counts in the SOTrieITs accordingly. Every item- set increments or decrements the support count of its corre- sponding tree node depending on whether the transaction is added or deleted. At any point in time, W contains all the support counts of all 1-itemsets and 2-itemsets that appear in all the transactions. Hence, there is no longer any need to scan the database during the generation of large 1-itemsets and 2-itemsets.

5. Algorithm FOLDARM  5.1. Pre-processing  Figure 4 shows the pre-processing steps taken whenever a transaction is added or deleted. For every transaction that arrives, 1-itemsets and 2-itemsets are &rst extracted from it.

For each itemset, the SOTrieIT Y ,  will be traversed in or- der to locate the node that stores its support count. Support counts of 1-itemsets and 2-itemsets are stored in Erst-level and second-level nodes respectively. Therefore, this traver- sal requires at most two redirections that makes it very fast.

1 Let Y be a set of SOTrieITs 2 for (k = 1; IC < 2; IC++) do begin      Obtain all k-itemsets of the transaction and store them in C k foreach itemset X E C k  do begin  Traverse Y to locate nodes along the path that represents X if such a set of nodes exists in Y then  Increment or decrement support count of the leaf node depending on the nature of update if its support count falls to 0, remove node and its child nodes (if any) Sort the updated node according to its new support count in descending order  Create a new set of nodes with support count of 1 that represent a path to X Insert nodes into Y according to their suppor counts in descending order from the left  11 else   14 endif 15 endfor 16 endfor  Figure 4. Pre-processing Algorithm.

Y will then be sorted level-wise from left to right according to the support counts of the nodes in descending order. If such a node does not exist, it will be created and inserted into Y accordingly. Similarly, Y is then sorted after such an insertion. For deletions, the steps are similar except that the support counts of the affected nodes are decremented and nodes are deleted if their support counts fall to zero.

5.2. Update of Universal Itemset  Figure 5 shows how the SOTrieIT is updated when the universal itemset is changed. In algorithms like FP-growth that use a similar data structure to store itemset information, the structure must be rebuilt to accommodate updates to the universal itemset. In our case, the SOTrieIT can be easily updated to accommodate the new changes.

1 if a new item i is added to the universal itemset  3 else if an item j is removed from the universal itemse  do nothing because the SOTrieIT will be updated the moment a transaction with i arrives  traverse the SOTriet to remove all nodes and their child nodes (if any) that contain j  Figure 5. Universal ltemset Update Algorithm.

5.3. Mining of large itemsets  Figure 6 shows the steps taken when the mining process is started. The SOTrieIT, Y, is &rst traversed to discover large 1 -itemsets and 2-itemsets. In our approach, depth-Erst search is used, starting from the leftmost Erst-level node. As Y is sorted according to support counts, the traversal can be stopped the moment a node is found not to satisfy the minimum support threshold. After large 1-itemsets and 2- itemsets are found, the algorithm proceeds to discover other larger itemsets using the Apriori algorithm.

Example To illustrate the mining algorithm, we use the same transaction database found in Figure 2 and the SOTrieIT structure in Figure 3(d). Suppose the support threshold is set at 75%. Then the minimum support count to qualify an itemset to be large is 3. Figure 7 shows the traversal path taken in obtaining the large I-itemsets and 2-itemsets. The bold numbers on the arrows denote the se- quence with which the SOTrieIT is traversed. During the generation of the Erst two large itemsets, the moment a Erst-level node with a support count lower than 3 is encoun- tered, the rest of its siblings and subtrees are not scanned.

But when a second-level node is found not to have satisEed the minimum support count, only its subsequent siblings will be ignored. In this case, at the Efth traversal, when the node that represent itemset { A ,  B }  is found to have a support count of less than 3, the node that represent item- set { A ,  D }  will not be explored. The Enal large 1-itemsets and 2-itemsets found are L1 = { { A } ,  { B } ,  { C}} and Lz = { { A ,  C}, { B ,  C}} and the total number of traversals is 9 (out of a maximum IO). The scenario changes favorably     1 Let N: be the qth child node of parent node p 2 Let NC, be number of child nodes under p.

3 Let I, be the itemset represented by node n.

4 for (~:=1;  J: < NCROOT; x++) do begin 5 Let X = N$OoT.

11  endfor 12 endif 13 endfor 14 Run Apriori from its third iteration to End  if FX 3 ID) x s% then begin 7 Add Ix  to L1.

for (y= 1 ; y < NCx ; y++) do begin if ONC 2 (Dl x s% then  10 Add I N ;  to Lz.

the rest of the large itemsets.

Figure 6. Mining Algorithm.

ROOT  D(1) C(3) B(2) D(1) C(3) D(1)  Figure 7. Traversal path of the SOTrielT at a support threshold of 75%.

when we increase the support threshold slightly. The next example demonstrates more clearly the advantage of order- ing the SOTrieIT by the support counts of nodes.

For a minimum support threshold of SO%, the minimum support count needed is 4. Figure 8 shows the traversal path taken in obtaining the large 1-itemsets and 2-itemsets. The FOLDARM algorithm stops traversing the SOTrieIT at the third traversal when it  encounters the item A which has a support count of 3. This is because all other nodes that come after Erst-level node A will have a support count of 3 or less.

Therefore, there will not be any more large itemsets in the rest of the SOTrieIT. The algorithm terminates after only 3 traversals and the only large itemset is {C} .

The above examples illustrates the usefulness of the SOTrieIT; once constructed, i t  can be used for varying sup- port thresholds. In addition, in a best case scenario where the minimum support threshold is high, it may only need one traversal to discover all large itemsets while in a worst case scenario, i t  may only need a number of traversals whose cost is defnitely lesser than that of scanning a large  D(1) C(3) B(2) D(1) C(3) D(1)  Figure 8. Traversal path of the SOTrielT at a support threshold of 80%.

database. Time and space complexity issues will be ex- plored further in the next section.

6. Time and Space Complexity  6.1. Pre-processing  Time Complexity The amount of time to pre-process a transaction depends on the amount of time to extract 1- itemsets and 2-itemsets from the transaction, to traverse the SOTrieIT to increment the support counts of the respective nodes, and to create new nodes in the SOTrieIT for items that are not encountered yet. For a transaction of size s, only (?Cl+ ?C2) itemsets are pre-processed. Hence, its complexity is O(s2) .  As the SOTrieIT is only two levels deep, it takes at most two links to reach the desired node.

Suppose it also takes one unit of time to move over one link, it will take a maximum of 2 x (?Cl+ ?C2) units of time to move to all the nodes required by a transaction of size s.

Space Complexity In a database with N unique items, there will be N Erst-level nodes in the SOTrieIT. For each Erst-level node, since the SOTrieIT is created in a trie-like manner, it will contain only items that are lexicographically larger than itself. The Erst-level node who has the largest number of child nodes is the one that has the Erst position in a set of lexicons. It will have N - 1 child nodes. Sub- sequent Erst-level nodes will have one less child node than the previous one. Therefore, for N unique items, a max- imum of only x nodes, inclusive of both Erst-level and second-level nodes, are needed to store the entire pre- processing information. Hence, its complexity is O ( N 2 ) .

N  6.2. Mining of large itemsets  This section discusses the time complexity of the mining phase as compared to that of Apriori. Space complexity will not be mentioned because this phase also involves the SOTrieIT whose space complexity is already discussed.

Symbol Meaning Number of unique items Number of transactions Number of maximal potentially large itemsets Average size of the transactions Average size of the maximal potentially large itemsets  Figure 9. Defnition of Parameters.

Time Complexity To compare the time complexity of FOLDARM and Apriori, we shall focus only on the scan- ning process to obtain the support counts of itemsets. This is enough to see the vast improvement of FOLDARM over Apriori. For each pass of the Apriori algorithm, there is a need to scan the entire database regardless of the desired support threshold. Suppose the database is of size a and the average size of each transaction is b. Then, Apriori takes O(ab) units of time to scan the database at each pass.

For the Erst two passes of FOLDARM, only the SOTrieIT Y needs to be scanned. According to Section 6. I , Y has x nodes and since each node has one link from its parent, in  the worst case, i t  will take at most 2 x 5 units of time to traverse the entire structure where N << a.

In addition, the time needed also depends on the desired support threshold which would further reduce the number of traversals. Therefore, the average amount of scanning time for the Erst two passes will be far less than O(ab).

N  N  7. Performance Evaluation  This section evaluates and compares the relative perfor- mance of the Apriori and FOLDARM algorithms by con- ducting experiments on a Pentium-111 machine with a CPU clock rate of 1.7 GHz, 256 MB of main memory and run- ning on a Windows 2000 platform. The algorithms are im- plemented in Java and hence large memory requirements of the Java Virtual Machine prevented us from scaling up the experiments. Future experiments will be conducted to tackle this issue. The SOTrieIT structure is implemented using a combination of integer arrays and Eles. Implemen- tation details are omitted due to the lack of space. In spite of extra &le U 0  requirements, FOLDARM maintains its im- pressive performance. Figure 9 shows the various parame- ters used and their meanings.

The method used for generating synthetic data is similar to the one used in [ l ] .  To describe an experiment, we the notation Tw.1z.Ny.D~ modiEed from the one used in [ l ] where w is the average size of transactions, II: is the average size of maximal potentially large itemsets, y is the number of unique items and z is the size of the database. We added the y parameter to represent the databases in a clearer man-  ner. The databases used here are similar to those in [SI.

The Erst one is T25.IlO.NlK.DlOK which is denoted as Dl while the second is T25.120.NlOK.DlOOK which is denoted as D2. The following sections analyze the performance of FOLDARM as compared to the algorithms introduced in Section 2 in different scenarios.

7.1. Static Databases  Figure 10 shows the execution times (excluding pre- processing time of FOLDARM) for the two different static databases of both Apriori and FOLDARM. The databases are termed static because they are not expected to change over time. From the graphs, i t  can be quickly observed that FOLDARM outperforms Apriori in all situations. In Figure 10(a), FOLDARM maintains a steady speed-up of about 10 times for support thresholds ranging from 3% to 1.5% in

VI. However, when the support threshold falls below 1.5%, the speed-up is signifcantly reduced. At a support thresh- old of OS%,  FOLDARM only manages a speed-up of 1.2 times.

The situation changes dramatically in D2. Figure 10(b) uses a log scale for the time axis because of the vast dif- ference between the execution times of FOLDARM and Apriori. FOLDARM performs at least 80 times faster than Apriori for support thresholds ranging from 3% to 2%. Its performance peaks at a support threshold of 1.5% where it performs more than 160 times faster than Apriori. This speed-up falls to 54 times at a support threshold of 0.5%.

Explanation The poor performance of FOLDARM in VI, especially at lower support thresholds, is due to the fact that more larger-sized frequent itemsets exist at lower sup- port thresholds and FOLDARM uses the Apriori algorithm to discover large k-itemsets for k > 3. Hence, the com- putation savings in the Erst two iterations are insigniEcant compared to the huge computation costs needed in obtain- ing larger frequent itemsets.

Interestingly, in larger databases like D2, FOLDARM performs exceptionally well. The obvious vast improve- ment of FOLDARM in 232 can be explained by Figure 11 which shows the number of candidate k-itemsets generated during the mining of Dl and ?)a for a support threshold of 0.5%. From Figure 11, i t  is clear that the main difference in candidate generation between 21, and V2 is in the num- ber of candidate 2-itemsets generated. Thus, by eliminating the need for candidate 2-itemset generation, FOLDARM achieves a much greater speed-up in D2 as it  contains more than 6 times the number of candidate 2-itemsets as com- pared to VI. As for higher support thresholds, FOLDARM is able to outperform Apriori by up to two orders of magni- tude because in D2, the maximum size of the large itemsets, IC* ,  is much lower than that of VI. If k* increases indef-     1 8e+006  16e+006  14e+006  O 800000 e GOMXX)  D1 ... x-.. - D2 f3 - -  4 m 0 0   O r k  initely, the performance of FOLDARM will eventually be reduced to that of Apriori. However, we can conclude from the experiments that as databases and universal itemsets in- crease in size, k* will decrease and thus FOLDARM will scale up very well against Apriori. This Ending is particu- larly crucial in an electronic commerce where transactions (database size) are expected to arrive by the thousands and a wide variety of products (universal itemset size) is available for purchase.

Another important point to note is that after the Erst 2 passes, FOLDARM actually uses Apriori to mine larger fre- quent itemsets without relying on the SOTrieIT structure.

Despite of the fact that FOLDARM only differs from Apri- ori during the Erst 2 passes, it is much faster and scalable; this congrms that candidate itemset generation during the Erst 2 passes constitutes the main bottleneck in Apriori.

FP-growth is currently the fastest algorithm for min- ing static databases. However, due to the lack of time, FP-growth is not implemented but its performance against FOLDARM can be evaluated using Apriori as a basis for relative comparisons. The experiments conducted in [ 81 re- port an overall improvement of only an order of magnitude for FP-growth over Apriori. In addition, the performance of FP-growth is on par with Apriori for support thresholds ranging from 3% to 1.5% in Dz. The poor performance of FP-growth can be attributed to the cost in recursively con- structing FP-trees. Hence, signiEcant speed-ups can only be noticed in lower support thresholds when Apriori can- not cope with the exponential increase in candidate itemset generation. This is undesirable because we want to mine databases efkiently at a wide range of support thresholds instead of only at low support thresholds. FOLDARM over- comes this limitation of FP-growth and consistently outper- forms Apriori at all support thresholds and i t  can even per- form up to two orders of magnitude faster than Apriori.

- >...

2 ,' --.% _ _ ' * -..- __ - . ..- 9 -..-.. p ..~ 9 Q  7.2. Dynamic Databases  A dynamic database is one with frequent updates; trans- actions are added and removed frequently. In [ 5 ] ,  the FUP2 algorithm is presented to make use of past mining results to mine new transactional updates more efkiently. Due to time constraints, FUP2 is not implemented for comparison studies with FOLDARM. As before, with the results in its performance analysis section, we can easily assess its per- formance as compared to FOLDARM with the performance of Apriori as our reference point.

In a database of the type TIO.14.NlK.DlOOK with an addition and deletion of 5000 transactions, it  is found that FUP2 performs only about twice as fast as Apriori as seen in the experiments in [ 5 ] .  This is its best performance against Apriori through the use of past mined knowledge. In ad- dition, it  is discovered that when the size of the updates of a database exceeds 40% of the its original size, Apriori can even outperform FUP2. Both Apriori and FOLDARM mine a dynamic database as if i t  were a static database because they do not make use of past results. Since FOLDARM per- forms up to 100 times faster than Apriori in a much larger database, we can safely conclude that FOLDARM will def- initely outperform FUP2 by a wide margin.

Explanation In spite of its ability to reuse mined results and hence reduce the number of candidate itemsets gener- ated, FUP2 still performs slower than FOLDARM because it  needs to scan the database during the generation of large 1-itemsets and 2-itemsets. FOLDARM can quickly do so simply by scanning the SOTrieIT structure which is de&- nitely many times smaller than the database. In situations when the updates are high, the performance of FUP2 drops because the updated database becomes so different from the original one that past mining results are not helpful in determining new large itemsets. In processing useless old information, precious computation time is wasted. On the other hand, FOLDARM does not need to retain past min- ing results. Moreover, frequent database updates do not af- fect it  because it  always mines the database from scratch.

Note that the SOTrieIT structure does not need to be con- structed from scratch when the database is updated because it is continuously updated each time a transaction is added or retired.

7.3. Dynamic Support Threshold  CARMA is currently the only algorithm that allows the user to modify the support threshold on the ay. We will once again use the results presented in [7] as a form of compar- ison. In a database of the form T10.14.NlOK.D100K, it  is found that Apriori outperforms CARMA for support thresh- olds of 0.5% and above. It is only when the support thresh-     D1 (T25110NlKDlOK)  Apnon ---x --  FOLOARM 0 300 ,I   c 200  F 150     e  E"  11 - -  -  0 x-...........~;.

x -.--....__-__  0 -4% 9  ---.__.. x---.-- - -_ --__  %--.-..

-  -  c e 1:: E" F 150 j  Suppon Threshold (%)  (a>  0 '  D2 (T25.120.NlOK.Dl00K)  0 -4% m  Apnon ---x--- FOLOARM 0   1 ' 0.5 1 1 5  2 2.5 3  Suppon Threshold (46)  (b)  Figure 10. Execution times for two databases of the form Tw.1s.Ny.D~ where w is the average size of transactions, 3: is the average size of maximal potentially large itemsets, y is the number of unique items and z is the size of the database, at varying support thresholds.

olds are at 0.25% and below that CARMA begins to outper- form Apriori only by less than 1.5 times. On the other hand, FOLDARM consistently outperforms Apriori by wide mar- gins at various support thresholds and supports dynamic support thresholds. This is because the SOTrieIT can be reused for mining at different support thresholds without additional computation.

Explanation The poor performance of CARMA is at- tributed to its need to maintain a lattice of potentially large itemsets. It will be faster only when the user does not need a precise set of large itemsets because in this case, CARMA does not need to re-scan the database. FOLDARM per- forms much faster because the SOTrieIT stores threshold- independent information and thus its performance will not be affected even if the user changes the support thresholds frequently to obtain an optimal threshold.

7.4. Dynamic Universal itemset  As none of the algorithms discussed takes into consider- ation of the fact that unique items in the database will vary, it is not possible to conduct experiments for comparison.

However, we can approximate the most probable results by examining the characteristics of each algorithm. When new transactions with new items are added to a database or when old transactions with obsolete items are retired, all the discussed algorithms would have to mine the updated database from scratch. Therefore, their performance against FOLDARM in such a scenario can be deduced from the pre- vious sections. When the universal itemset is changed, the SOTrieIT can be easily updated as seen in Figure 5. Hence, it should retain its performance edge and outperform all the  algorithms seen in the previous sections.

7.5. Pre-processing and Storage Requirements  As pre-processing is carried on a transaction at the mo- ment it arrives in the database, i t  is distributive by nature and thus will not burden a system excessively. FOLDARM spends an average of only 180 ms and 250 ms in pre- processing a single transaction found in 731 and D2 respec- tively. This amount of time is insigniEcant considering that it will result in major speed-ups in the mining process. This requirement should not be taken into consideration in com- paring the performance of FOLDARM and Apriori because pre-processing is done outside of the actual mining process itself.

The SOTrieIT structure resides in both memory and fles.

As primitive integer arrays are employed in memory for storing the Erst-level nodes, the SOTrieIT only takes up only 2 KB and 14 KB in 271 and Dz respectively. Second- level nodes grow exponentially with respect to N as seen in Section 6.1 and as such, they cannot be stored in memory.

Instead, they are stored in Eles which are named after the labels of their parents. These Eles take up approximately 2 MB and 53 MB for 731 and 732 respectively. Therefore, it can be concluded that by distributing the SOTrieIT structure among memory and Eles, scalability is ensured as hard disk space is currently in the realm of tens of gigabytes.

8 Comparison of features  This section focuses on the salient features of FOLDARM and elaborates on why it is more suitable for     use in electronic commerce as compared to existing algo- rithms discussed in Section 2. For an association rule min- ing algorithm to be useful in electronic commerce, i t  must have the following capabilities:  1. General Incremental Mining Support: The algorithm must obtain association rules quickly that r e a c t  the latest changes to the transaction database at a certain point in time. This can only be achieved if the algo- rithm can perform general incremental mining which means that past mining results are exploited during the mining of a database which has many additions and deletions of transactions since the last mining opera- tion that was carried out on it.

2. Dynamic Threshold Support: The fast-changing na- ture of electronic commerce prevents the prediction of a suitable support threshold for the mining process.

Hence, the algorithm must allow the user to change the support thresholds of the mining process until an opti- mum value is found without signigcant performance degradation. In other words, it must be able to create and reuse mining information that is independent of the support threshold.

In a highly- competitive environment like electronic commerce, new products must be introduced frequently and old ones be retired to satisfy the changing and demand- ing needs of the empowered customer. Therefore, the algorithm must not assume that items in the database remain &xed. It must be able to reuse past mining re- sults efgciently regardless of changes made to the set of unique items in the database.

3. Dynamic Universal itemset Support:  Apriori [ I ] ,  DHP [3] and FP-growth [8] all attempt to improve mining speed but do not satisfy any of the above criteria. FUP [4], FUP2 [5] and the Adaptive algorithm [6] satisfy the Erst criteria but do not take into consideration the other two. CARMA [7] fulflls the second criteria but does not satisfy the other two and is extremely slow. Finally, no algorithms exist to date that satisEes the third criteria.

With the SOTrieIT, FOLDARM satisges all three criteria and even performs faster than all algorithms.

9. Conclusions  The increasing popularity of electronic commerce presents new challenges to association rule mining. Due to the easy availability of huge amount of transactional data, there is a urgent need for faster algorithms to mine such rich data. We have proposed a new algorithm called FOLDARM which uses an efscient novel structure known as the SOTrieIT. By simply eliminating the need for candi- date I-itemset and 2-itemset generation, FOLDARM is able  to achieve signigcant speed-ups. Experiments have shown that FOLDARM is much faster than Apriori. By using Apri- ori as a basis for comparisons, FOLDARM is proven to be faster than some prominent existing algorithms. In addition, as FOLDARM can maintain its performance while the sup- port threshold and universal itemset change, it is ideal for use in electronic commerce. Therefore, though there are ad- ditional pre-processing and storage requirements, they are both insignigcant and worthwhile considering the advan- tages that they reap. As databases and their universal item- sets grow in size, it will be more difgcult to maintain the SOTrieIT. Hence, parallel versions of the SOTrieIT and the FOLDARM algorithm need to be researched to meet the rising demands of mining larger databases.

