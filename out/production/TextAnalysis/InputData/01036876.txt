Aspects of Measurement Scheduling for  1 2  Tracking

Abstract -[7 MaOnyO tOarOgetCi trOackOingO sOubsysta ity to schedule their own data rates: essentially they can "order" new information whenever they need it, and the cost is in terms of the sensor resource. Uniform sampling, in which a new measurement is requested periodically and regularly, is the most commody-used sampling scheme.

nonuniform schemes are seldom studied: it is "common knowledge" that they exhibit inferior performance and are too bizarre to consider seriously. In this paper. how- ever, we show that such schemes may have been discarded prematurely: a nonuniform sampling can have its bene- fits. Specifically, the nonuniform and uniform sampling schemes are compared for two kind of trackers: the PDAF, which updates its track based on a single scan of informa- tion at a time; and N-D assignment (an optimization- based implementation of the MHT), in which the sliding window involves many scans of observations. We show that. given the ground rule of maintenance of the same overall scan rate (i.e. the same sensor effort), uniform sampling is always optimal for the single-scan tracker in the sense of track life. However, a nonuniform sampling can outperform uniform sampling if a more sophisticated multi-scan tracker is used. particularly when: (i) the tar- get has a high process noise; and/or (ii) the false alarm density is high and/or (iii) the probability of detection is high.

Tab I e o f  Con ten ts  1. INTRODUCTION 2. SYSTEM MODEL OF SINGLE TARGET 3. THE PDAF  5. NUMERICAL RESULTS 6. DISCUSSION 7. CONCLUSION 8. REFERENCES  4. THE N-D ASSIGNMENT ALGORITHM  ' e 2002 IEEE 21EEE Aerospace Conference, Big Sky MT, March 2002  ns0 haveO triheCl aOb21- I n t r o d u c t i o n  The basic tracking problem is that of state estimation for a linear system from measurements corrupted by Gaussian observation noise. The optimal (in essentially every sense) solution in this case is the Kalman flter. However, in target tracking the obfuscation in the measurement sys- tem, previously modeled only as the introduction of an additive Gaussian observation disturbance, now addition- ally incorporates measurement-origin uncertainty. That is, there can be false alarms. and also the "true" (i.e.

target-generated) measurement may be missed. Conse- quently the measurement "scan" delivered from the sensor to the tracking subsystem can be null (detection missed and no false alarms), single (perhaps true, but also may be a false-alarm with the true measurement missed), or multiple (true measurement. if present at all, is not la- beled as such amongst those delivered). The key tracking issues are hence how to determine which measurement, if any, is true, and how to reflect the resulting uncertainty in the tracker's self-assessment.

Many sensor systems operate autonomously, and deliver their measurement scans on a &ed-interval basis - most sonar systems work this way, as do conventional "rota- tor" radars. Some electronically steered radar systems, however, allow for the tracking user to request scans of data on an adaptive, or at least an agile, basis. Inter- estingly, Daum in [4] has suggested that sampling times, and possibly jittered versions of these, ought to be con- sidered as parameters in the optimization of tracking sys- tems. Notwithstanding, it appears that most tracking de- signers remain more comfortable with the original regular delivery of scans; irregular scans are an unwanted extra dimension of freedom, and it is easiest to  ignore it.

In this paper we explore the more general case of nonuni- form sampling. Suppose we have a uniform sampling in- terval T. The kind of nonuniform sampling considered here is that the system samples at interval TI and T2 al- ternatively; but to make the overall sampling rate equal,  4-1597  mailto:lett,ybs}@engr.uconn.edu   and to have a fair comparison, we must have Tl +T2 = 2T.

To be concrete, we may consider that a periodic-scan sys- tem can request measurements each second (T = 1), and that an alternative (but comparable in terms of radar re- source cost) scheme requests a pair of scans separated by 0.1 seconds, with each pair separated by 1.9 seconds (TI = 0.1 and T2 = 1.9) - see Figure 1 for an illustration.

The timing just discussed, and that to be explored in this paper, is the result of a deliberate staggering of measure- ment sampling times - basically, this is an option for a radar resource management system. But there is another sort of nonuniform sampling that is not deliberate, that arising from data fusion from asynchronous sensors. Con- sider Figure 2, in which centralized processing is a m m - plished based on measurements from a pair of autonomous observers. These observers do not scan in lock-step, and the arrival of a measurement from either at the fusion center is aperiodic, and could even be considered (in the general case) a point-arrival random process (see Figure 3(a)).

We do not consider explicitly the data fusion situation here: there are simply too many variables to adjust for a clear picture to emerge. Similarly, even in the single- sensor case with sensor management, we could consider more-sophisticated staggered-sampling schemes such as in Figure 3(b). This paper is exploratory: whatever behav- iors are to be found in these more-involved cases, the sim- pler situation of Figure 1 should hint at them. That is, the situation we study here is we hope a proxy for other cases, and if some advantages of a nonuniform sampling should arise here' , then perhaps it is worthwhile to exam- ine other cases.

So: is there some benefit to nonuniform sampling?

As  is widely known, false alarms can be assumed to be uniformly distributed in the surveillance region and to be independent of the true observation [1][2]. Under this as- sumption, the sampling interval scheme is irrelevant to the false alarm process. However, since it is generated by the target, the true observation is affected by the sampling interval. As can be easily shown, when the sampling inter- val is short, the true observations from two time-adjacent samples are close to each other. Thus the true observa- tion can be made more distinguishable from those that are false by use of a short sampling interval: two mea- surements in adjacent scans that are very close are likely both true, while any measurement in a fist  scan that is not repeated by one in the second scan that corroborates it is probably false. This is illustrated in Figure 4.

Thus, notionally, the nonuniform sampling scheme ought to be an excellent means to combat measurement-origin uncertainty. However, there is a price: the longer sam- pling interval between the two scan pairs (1.9 seconds  in the above) increases the uncertainty (the "gate"), and the resulting increase in false a larm may actually exacer- bate measurement/target association. This is illustrated in Figure 5 - note that the increase in gate size can mean an increase in the number of false a larm that could be confused with the true measurement. and this may result in a lost track.

In this paper, these two sampling schemes are compared.

It will turn out that the superiority of one versus another is very much ii function not only of parameters. but also of the tracking scheme used. Specifically. we shall investi- gate the probabilistic data association filter (PDAF) and N-D assignment algorithms [2][5][6][7]. The PDAF asso- ciates measurements to tracks one scan at a time. and hence that it will be shown that uniform sampling is al- ways the best approach for the PDAF is perhaps unsur- prising. However, when a tracker that makes use of more than one scan of past data is used (i.e. multidimensional assignment), the system with nonuniform sampling can outperform the "conventional" uniform one. The advan- tage becomes most obvious when the target maneuvers more, when the clutter (average number of false alarms) is high, and when the probability of detection is close to unity.

2. System Model o f  Single T a r g e t  Here we focus on the l-dimensional Discretized Continu- ous White Noise Acceleration model (DCWNA) [l]. The alternative is to  assume the Discrete White Noise Accel- eration model (DWNA)? and although which is chosen is often a matter of taste (both are based on reasonable sta- tistical assumptions, but since these assumptions are not necessarily satisfied by a real target one tends to  choose one's favorite) one more commonly sees DWNA since its parameters art: slightly easier t o  relate to real-world ef- fects.

Under DWNA, the model is directly in the discrete-time domain, and is tantamount to a continuous-time kine matic object undergoing a constant acceleration during each interval between observations; under DCWNA the model is of discretetime samples a continuous-time sys- tem driven by continuous-time white noise. Normally there is little clifference; but here, since we wish to com- pare different sampling schemes of the same target, it mat- ters a lot. DWNA is inappropriate, and we use DCWNA.

A CWNA object moving in a coordinate < is modeled as i'(t) = qt> (1)  where  E[C(t)] = 0 E[.ii(t).ii(T)] = qqt - 7) 'As they do.

4-1598    and Q is the power spectral density of the continuous time process. The state vector according to (1) is  x =  [I 4' (4) The continuous time state equation is  k( t )  = Ax( t )  + DC(t) (5) where  A = [: :] = [;I  The state equation of DCWNA with sampling period Tk, which is of second order, is  x(k + 1 )  = F(k )x (k )  + v ( k )  (8)  3. T h e P D A F  At the outset let us note the main feature of the PDAF: it is entirely optimal except that after each scan its pos- terior track state probability density function - ideally a mixture of Gaussian pdf's - is converted to a single Gaussian having the same mean and variance (i.e. via mo- ment matching). Thus, at each scan. estimation is built upon a Gaussian prior, converted to a Gaussian mixture posterior, which is then forced back to Gaussianity for the succeeding scan.

Reference to Figure 6 may be helpful. The reader is en- couraged to d e  the derivation in [ Z ] .  It should be noted that in practice the predicted measurement is of- ten enclosed by a "gate" whose volume is proportional to d m .  where S ( k )  is the innovation covariance matrix at time k, and whose function is to reduce computation by ignoring any measurement whose association probability is negligible.

(9)  the discrete time process noise v ( k )  relates to the contin- uous time one as  v ( k )  = e----s)DC(t k-1 + 7)dT (10) P From the above, the covariance of the discrete time process noise v (k )  is  Q ( k )  = E [ W v ( k ) l  (11)  It will be assumed that only position measurements are avaliable; that is ,  z(k) = Hx(k)  + w ( k )  (12) where  H = [ l  01  The measurement noise variance is  R = E[w(k)2] = 0; (14)  In the above equations, T k  is the kth sampling interval.

For uniform sampling, the sampling interval is fLVed to be Tk = T. For nonuniform sampling, we shall consider sam- pling intervals TI and T2 alternatively, with TI + T2 = 2T.

As discussed in the previous section, other nonuniform sampling schemes are possible.

4.  The N-D assignment a l g o r i t h m  Nonuniform sampling does not improve the PDAF. The reason is that the PDAF is a "one-step-back" filter, which means that in the PDAF only the data from the previous stage is used to provide the current estimates. Recall that nonuniform sampling is one short sampling interval followed by a long one, and although the short sampling interval has its benefits, the price is paid in the long one.

The notion behind nonuniform sampling is in the added evidence behind the presence of spatiallyclose detections in two temporallyclose scans; and conversely in the re- duced weight to be given a measurement in one such scan that is not corroborated in the next.

To take advantage of nonuniform sampling, one must im- prove one's utilization of the benefits of the short sam- pling interval to overcome the penalty brought by the long sampling interval, and the corresponding association scheme must incorporate multiple scans of data. An N- dimensional assignment algorithm [Z] [5] [6] [7] does this.

As shown in [Z], Eq. (6.3.3-18) (mod&d here for a sin- gle target and no new traclis established), the conditional probability of a cumulative association event is  P { O ~ ( Z ~ }  = P { e ( k ) ,  ok--' ~z(k) ,z~-- '}  (15) = - p [ z ( k ) ( e ( k ) ,  o ~ - ~ , z ~ - - ' ]  1  xP{B(k)  IO"-', zk-l }P{O"-' p-'}  where the following notations are used:  4-1599    0" assignment through time k  4 the number of measurements deemed as false alarms in the hypothesis under consideration  the number of measurements at time k (this should be interpreted as a scan/frame/list, with the indi- vidual measurement time stamps not necessarily the same; the only constraint is that a target measure- ment appears no more than once in a list)  the pmf of the number of false alarms  the surveillance volume  the pdf of the predicted measurement of the track to which measurement z j (k )  is assigned in the hy- pothesis under consideration  indicator function for the assignment of measure- ment z j ( k )  to the track in the hypothesis under con- sideration  detection probabiity of target  indicator function for the assignment of a measure- ment to the track in the hypothesis under consider- ation  parent assignment of gk (the assignment of the pre- vious scan)  Typically one assumes a Poisson pmf with spatial density A,,+ for the number of false measurements, namely,  Using the pmf from (16) into (15) yields  x [[PD]'[l - PD]'-'] p{ek-' lzk-'} We also have  m(k)  4 + 7j = m(k) (18) j = l  Dividing the right hand side of (17) by (A,)mck) and ab- sorbing e-'+ and m ( k )  into c, we have  Note, in the above, the likelihood ratio for the event (de- noted by Q(k) = j )  of assigning measurement z j (k )  to the track is given by  The likelihood ratio for the event (denoted by B(k)  = 0) that no measurement is assigned to the track (a dummy measurement is assigned to  the track), which means the true measurement is not deteded, is given by  As  an example of using the likelihood ratio above? the log likelihood function of a P D  assignment algorithm is derived. Suppose we observe a set of measurements Z k  = { z l ( k ) } y l r )  at s c a n  k. The 4 D  assignment algorithm uses 3 scans of data Z ( k ) , Z ( k  + l ) , Z ( k  + 2) t o  get the h a 1 (irrevocable) data association at time k.

The joint pdf of assignments and measurements can be written as  So after searclhg all the combinations of observations in 3 scans Z ( k ) , Z ( k  + l ) , Z ( k  + Z), the one which has the largest joint pdf is the MAP assignment. Then the resulting .ze(k. is used as the measurement of a standard Kalman filter, and the state is updated.

So, in general the N-D assignment procedure consists of the following steps:  After jni$ialization (at k = O), for every measure- ment at k = 1 that falls in the validation region around the location i( 110) where the measurement is expecttxl, the track is split.

For each ineasurement an updated state is computed via the (standard) Kalman Filter equations [l], us- ing the state model (8) and (12), and propagated forward t o  yield another validation region at k = 2.

For each new validation region at k = 2 the proce- dure is repeated.

When the procedure reaches k = N - 1, the proce- dure is stopped. By calculating the likelihood func- tion, the measurement of the most likely branch at k = 1 is cihosen as the true measurement and the N- dimexxiorla1 search is restarted at k = 1 and en& at k = Pv'. This (sliding window) block search is repeated.

The procedure is illustrated in Figure 7. From that Sg- ure it can be seen that during the short sampling interval TI , the volume validation region V(k + 1, TI ) is small, the probability of a. false alarm falling into this validation r e gion is greatly reduced. Equivalently, during the short  4-1600    sampling interval, the true observation, which is close to the predicted value of the measurement. has fewer ?com- petitors?? (false alarms) in its likelihood function evalua- tion. This can explaii, in part, why nonuniform sampling is a good idea with assignment.

5. Numerica I Resu I t s  In the simulations of both the PDAF and the N-D assign- ment algorithm, we use the one dimensional target model described in Section 2.

5.1. The PDAF: Uniform Sampling Is  Better Nonuniform sampling is compared to uniform sampling in Figure 8, a representative result for the PDAF in which for the nonuniform case we have TI = 0.1 and T2 = 1.9 seconds, as compared to the uniform-sampling case?s T = 1 second. The plot shows average track life, in seconds.

Apparently the difference between nonuniform and uni- form dwindles as the number of false alarms increases: we shall soon see that this is also the case for a multi- frame tracker. But the clearest conclusion is that for the PDAF, and presumably for any frame-by-frame tracker, a uniform sampling rate is better. Figure 8 depicts only one set of parameters; but we have been unable to fu?d a case in which its conclusion is contradicted.

5.2. Assignment: Weird Sampling Can Be Preferable!

Figure 9 shows the behavior of a threescan assignment algorithm: the percentage of tracks lost in 200 seconds is plotted, and as in Figure 8 we have T1 = 0.1 and T2 = 1.9 seconds, as compared to the uniform-sampling case?s T = 1 second. As with the PDAF, the nonuniform sampling performance improves, relatively speaking, as the clutter density increases. However, and unlike Figure 8, nonuniform sampling is actually preferable to uniform, provided there are enough false alarms.

This is ampued in Figure 10, which shows the percent- age of lost tracks as a function of the ratio Tl/T2, with of course the stipulation T1 + T2 = 2 seconds in all cases. It is clear from this that when pairs of samples are close (i.e.

a s m a l l  ratio) there can be a si@cant improvement from a nonuniform approach. The difference can be substantial (a factor of two!) when the ratio approaches zero: inter- estingly, this is the ?data fusion? case discussed earlier.

Figure 10 is particularly k i d  to nonuniformity because it depicts the case of perfect detection: there are false alarms, but no measurements are missed. Figure 11 ex- plores this further. Apparently, the improvement for the nonuniform sampling case is greatest when the tar- get is faithfully present in the data: we shall discuss this in the next section. Generally, though, we have found that nonuniform sampling is preferable only when PD > 80 - 90%.

For the discretized continuous-time white noise accelera- tion model of Section 2. the maneuvering index, d e h e d  T3@ A = - 0,  (in which T refers to the uniform inter-sampling time)!

provides a convenient scalar measure of a target?s elusive- ness. Figure 12 plots the percentage of lost tracks against A, and reveals that any benefits of nonuniform sampling are magnified by a more-maneuvering target.

in [l] as   6. Discussion  It has been asserted that uniform sampling is always preferable to nonuniform when the tracking algorithm as- sociates measurements to targets on a scan-by-scan basis, as with a PDAF. However, and on the contrary, if asso- ciation is based on several scans? worth of measurements, then nonuniform sampling actually has something to offer.

This is especially true when the probabfity of detection is high; when the clutter is high; and when the target?s maneuvering indm is high.

Now, this study of nonuniform sampling was motivated by the idea that data association might be helped by a cross-chd between returns from two contiguous scans of observations. Presumably this is indeed a beneficial ef- fect. However, association is hampered by false-alarms, and the number of these can be thought of as propor- tional to the size of the association ?gate? surrounding each measurement?s predicted location, and inside which candidate associations are sought. This gate has volume itself proportional to the innovations? covariance S (actu- ally the square root of its determinant), and is hence a quadratic polpomial of the time between scans. Presum- ably, then, this favors a uniform sampling.

The point is that these two effects are in anflict, and it is difFicult to tell at the outset which wiU dominate. In fact, we cannot even envision proofs of the earlier observations, given the complexity of the tracking task. However, the tendencies observed (e.g. high PD is best for nonuniform) are reasonable, and in the following sections we shall try to explain why. We shall begin with a study of the Kalman flter, and in particular its average gate size.

6.1. The Kalman Filter Case Underlying most trackiig systems is the Kalman flter, the tracker that would be optimal were there no measurement- origin uncertain@. Above it is argued that the perfor- mance of a t r a c k i  system is degraded by a larger gate size, since the greater the gate, the more false alarms can enter. Prediction of the gate size is difficult; but in the simplistic Kalman flter situation it can be done.

For the usual Kalman flter, the steady-state gate size is straightforward to estimate from the discrete time Ric-  4-1601    cati equation [l]. Here, however, the gate size varies due to the irregular sampling times. During the longer inter-sampling interval the gate will increase more than it would have increased during a uniform sampling time, but of course it begins from a smaller uncertainty due to the prior short sampling interval. The question is: which effect wins?

Let us consider the model of Section 2: but to incorporate uneven sampling, we shall stack the state for consecutive pairs of scans. Specifically, let us write, with reference to (S) and its sequel,  r ( ( k  + 1)(Tl + T2) + T2) I =  (23) in which z(-) is a stacked vector of position and velocity,  where Q1 and Q2 are from (12). Solution of the dis- crete algebraic Riocati equation with the above parame- ters yields prediction uncertainties when estimation is in steady state: the (1,l) element is required for the gate volume for the T1 interval, and the same procedure with TI and T2 interchanged goes toward the T?-interval?s gate volume.

In Figure 13 the average gate volume (averaged over long and short intervals) is plotted as a function of the ra- tio Tl/(T1 + T2). We see that this average is actually greatest for the uniform sampling case and least for the :?data fusion? scenario. We also observe that the benefit from nonuniform sampling increases as the target exhibits greater manmverabfity, a corroboration of the observa- tions in Figure 11.

6.2. The Case With Data Association As discussed earlier, analytic results with data associa- tion are sparse. However, there is a recent development of some interest: a Cramer-Rao lower bound (CRLB) has been developed for single-target tracking. As  given in [lo], this CRLB has elements of the Riccati equation, although the parameters are modified somewhat by an ?informa- tion reduction factor? that reduces measurement fidelity as a function of the uncertainty in provenance. Now, the CRLB shows the accuracy of an optimal (MAP) estimator.

The truly MAP estimator never loses track, regardless of the harshness of the tracking scenario; as such, we cannot expect any corroboration of the ?track-length? behavior of a practical tracker such as the PDAF or hard-assignment.

However, the CRLB does provide a measure of the curva- ture of the log-likelihood function near the true data, and  is in that regard a rekement of the Kalman filter results in that data axiociation is accounted for.

Example results are shown in Figure 14, which plots the CRLB after both long- and short-interval predictions, as a function of clutter density. Perhaps of greatest interest here is that the short-interval uncertainty is sign%cantly less than that when uniform sampling is used; and that even for the longer interval the inflation in this quantity is not huge. That is, the less-comprehensive but more exact analysis for the Kalman filter does seem to apply. We also show, in Figure 15, the corresponding results obtained from simulation and assignment trackers - qualitatively, Figures 14 and 15 are very similar.

6.3. Multi-Scan Tracker Results Our contention, at the outset, was that if one was pre- sented with two measurements relatively close in time, one could crosschock detections in one with those in the other, and thereby eliminate from serious consideration many false alarms. The disadvantage from doing this, however, is the lengthened time between such pairs of samples when one assumes a. constant average sensor resource budget: the uncertainty gate grows, and more false alarms enter the picture. However, it appears that a multi-scan tracker can see some benefits from nonuniform sampling in the situations l is ted below:  High Maneuvering Index. This is not immediately apparent;. However, the Kalman filter analysis does indicate that it will be so. A more-maneuvering tar- get engenders a more quickly increasing gate, which magnifies effects.

High False Alarm Density. Similar t o  target maneu- ver, a greater clutter density magnifies any effects from a small or a large gate.

High Probability of Detection. Any possible benefit from the proposed ?cross-che&? is lost if the true observation is not detected frequently, or is not ex- pected to  do so.

The ikst two cmnsiderations are tantamount to the target being difficult t o  track, whereas the last (a high Po) indi- cates an easier tracking task - usually heavy clutter and high maneuvering index go with low Po, although both clutter and PI, can be adjusted together by the detection threshold. The reason that a high probability of detec- tion is necess,ary to observe the benefits of nonuniform sampling is that if a measurement is not repeated in suc- ceding scans at a lower Po, then it may be either a miss or clutter; but if Po is suf3iciently high, the overwhelming likelihood is for the latter.

6.4. Single-Scan Tracker Results The PDAF (and presumably other scan-by-scan data association algorithms such as JPDAF or 2-D assign-  4-1602    ment) cannot, by dehition, realize any benefit from non- uniform sampling's cross-validation between scan pairs.

As to whether the they are hindered by an increase in average gate size. the Kalman filter and CRLB analysis suggest that this ought not be so. However. both these analyses are quite idealized: in the former there is no data association (the PDAF must associate false alarms and missed detections) and in the latter estimation is op- timal based on all received data (the PDAF is certainly not that). It turns out that the PDAF's imperfections dominate.

7. Conc I usion  In this paper, nonuniform sampling and uniform sampling schemes are compared in different trackers (PDAF and N-D assignment). In some situations, such as when data comes from a rotating radar, it is moot to discuss the benefits from, or drawbadis to, a nonuniform data-taking structure. But in some situations a non-uniform struc- ture is imposed: an example of this is data fusion, in which measurements arrive from asynchronous sensors.

One tends to treat this as an unavoidable evil; but is it really that bad? In fact, it can be beneficial. This indicates, perhaps, that intelligent sensor-resource man- agement systems ought to consider deliberate staggering sampling times.

We have explored only the simplest case of non- uniformity, that in which measurements arrive in pairs separated by a short interval: we take this as a proxy for more complicated situations. It has been shown that for the PDAF, uniform sampling is always best. However, when the tracker utilizes more than one scan of data from the past - as with multipleframe assignment or, presum- ably, the multi-hypothesis tracker (MHT) - nonuniform can outperform uniform sampling. This is particularly so when:  0 the target is highly maneuverable; and/or  0 the false alarm density is hi& and/or  0 the probability of detection is high.

In the above, we speak in terms of percentage of lost tracks and of average track lifetime: and in all cases the aggregate sensor resource is kept constant, meaning, for example, that one non-uniform scheme with short interval 0.1 sec- ond and long interval 1.9 seconds can be fairly compared to a uniform scheme in which the constant inter-sample interval is 1 second.

Further, and in all situations, nonuniform sampling yields a significant reduction in MSE in the short sampling inter- val than does uniform sampling (at the expense, of course,  of a larger 1LISE after the long interval). This is not sur- prising: but it does indicate that if a tracking estimate is to be used for targeting, it is a good idea to begin to use staggered samples and to launch after a short-interval sample.

Acknow I edgment  This research has been supported by AFOSR under con- tract nunher F49620-97-1-0198 and by ONR under con- tract nunher N00014-97-1-0502.

