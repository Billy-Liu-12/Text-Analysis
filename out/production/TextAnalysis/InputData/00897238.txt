Application of Data Mining in Web Pre-Fetching

Abstract To speed up fetching web pages, this paper gives an intelligent technology of web pre-fetching. We use a simplified WWW data model to represent the datu in the cache of web browser to mine the association rules. We store these rules in a knowledge base so as to predict the user S actions. Intelligent agents are responsible fo r mining the users? interest and pre-fetching web pages, bused on the interest association repositoty. In this way, user browsing time has been reduced transpurently.

Keywords: Internet, Data Model, Data Mining, Pre-fetching, Cache  1. Introduction With the rapid development of Internet, WWW is  popular for its multimedia transmission and friendly interactivity. Although the speed of network has been improved considerably in recent years, the rapid expansion of using the Internet, the inherited character of delay in the network and the RequesttResponse working mode of WWW [13] still make the internet traffic very slow and give no guarantee on the Quality of Service (QoS). Because HTTP has no states, the web server cannot know the users? demand and the users? requests cannot be predicted. Taking advantage of a cache mechanism and the time locality of WWW access, the browser can preserve the documents ever accessed in the local machine. By this means, for the documents in the local cache, the browser does not need to send the requests to the remote server or to receive the whole response from the remote one. Pre-fetching uses the space  Hongji Yang Chih-Hung Chang Department of Department of  Computer Science, De Information Science, Montjiort University, Feng-Chia University, Leicestel; England Taiwan  locality of access. First, the users? access requests are predicted according to the users? current request. Second, the expected pages are fetched into the local cache when the user is browsing the current page [6]. Finally, the users can access these pages downloaded from the local cache.

And thus this can reduce the access delay to some degrees. Pre-fetching is one kind of active caches that can cache the pages which are still not requested by the user.

The application of pre-fetching technology in the web can greatly reduce the waiting time after users have sent their requests.

Pre-fetching technology is based on prediction algorithms. Data mining is a technique, with which a lot of unknown, implicit but potentially useful information (such as knowledge, rules and regularities) for decision-making are mined. Based on the historic data and the current data accessed by the user, users activities in the future are predicted through data mining and relevant web pages are pre-fetched. The data in the users? local cache can be taken as the data sources of data mining.

This paper concentrates on the above issues and discusses the application of data mining techniques in the pre-fetching of web pages. Firstly, a simple WWW data model is given. Secondly, we put forward an interest association repository. Thirdly, we introduce the web data mining technology.

Fourthly, an algorithm of predicting the users? activities is introduced. Finally, we present an agent- based web pre-fetching system.

2. Simple WWW Data Model T The web pages are defined in HTML language. By  using MIME, a web page can contain different types of  0-7695-0933-9/00 $10.00 0 2000 IEEE    elements. A hyper media system [ l ]  is made up of web pages linked by hyper links among each other. In order to predict a user?s activities, we need a data model to describe the interest association rules in the web pages.

Several data models [5,8,9,10,18] have described the WWW. In order to meet the demand of data mining and represent the characteristic of the cache, this paper proposes a simple WWW data model. Some concepts and definitions of this model are presented below.

Definition 1: Let triple (Id, P, time) be a page node, where each page node is associated with an Id, time the latest time when the page node is accessed, and P a collection of properties, P = (property p ,  Ii =1,2 ....}. The property can be the relative URL, the type, the collection of linking nodes, the container, the content, the updated time, and so on.

According to whether the links exist [12] and the pointing direction of the links in the web pages, the page nodes can be classified into isolated page nodes, source page nodes and target page nodes. A page node, which does not contain any links, is the isolated page node. A page node, which contains links, is called the source page node of such links. While a page node, which is pointed by some other links, is called the target page node of such links. Apparently, according to different links, one page node can be a source page node and/or a target page node of such links.

Definition 2: Let triple (Id, string, target-node-id) be a linking node, where each Id identifies only one linking node; string describes the presenting information of this linking node, and target-node-id is the id of the target page node.

Definition 3: Let triple (source-node, L, target-node) be a link, where source-node is the source page node; L is the linking node; and target-node is the target page node; L E collection of links in the source-node, L.target-node-id = target-node.

Figurel: Simple WWW Data Model  Figurel shows the proposed simple WWW data model.

In this model, each node represents one web page; these nodes are inter-linked by the links that clearly represent the association of these web pages.

The web browsers now use the cache technology, which preserves the latest web pages accessed by the users. When the users want to access these web pages again, the browser first examines whether these web pages are cached locally. If so, the browser will then check whether the corresponding web pages are updated. If updated, these web pages can be achieved from the corresponding web servers. Otherwise, the pages are fetched from the local cache. That is to say, it is a passive mechanism in current browsers. The historic data in the cache reflect the users? interest in browsing information and the associating information among the users? interest is useful to foresee the users? activities. The associations among the web pages in the cache can be described easily in the simple WWW data model in Figure 1. But unfortunately, such a model can not visually represent the associating information of users? interests. In order to predict users? activities and implement the active cache, certain measures must be taken to transform the data in the cache from the simple WWW data model to another data model, so that they become more suitable for predicting. This approach will be introduced in the web data mining section below.

3. Building the Interest Association Repository When a user is accessing a web page, normally she or  he will follow the links in the web page to access other web pages. Based on the current web page, we can predict the links to be accessed by the user, and then can pre-fetch these web pages which will speed up browsing. It is supposed that the browser can pre-fetch all the pages pointed by the links in the current web page. It works better when there are only a few links that point to the different web servers. But such method is not advisable.

The first reason is that i t  is generally not possible that the user accesses all the links in the web page. Another reason is, if the fee is charged by network stream, the user may pay much more overhead. Further more, the streams of the Internet system should be balanced. So in this paper, we sort the links in the web page according to certain policy and pre-fetch a few web pages, which are more possible to be accessed. Considering the response time of the system and the difficult level in the realization of the different systems, we apply the simple association rules to predict the users? activities. The interest association repository is made up of some interest association rules. The interest set (dictionary) T is represented as { t ,  , t 2  ... t ,  ), where t ,  , t 2  . . . t ,  are lemmas. Here are more definitions.

Definition 4: The interest node is defined as a pair: Node ( t  )=( t , weight), where t is the lemma in the interest set T and weight is the weight of t .

Definition 5: The interest association rule is a triple:     Rule(Node ( t,T ),Node ( t ,  ))=(Node ( t ,  ), weight, Node ( t ,  ))  where weight is the probability from the interest node Node( t ,) .  t,T linking to the interest node Node( t ,  ). t ,  , O< weight 21.

Definition 6: The interest association repository is a set of interest association rules, where RULE = (Rule  (Node ( t , ) ,  Node ( t ,  )) I Rule(Node( t s ) ,  Node( t,  )) is a rule) is a rule). The interest association rules in the interest association repository must satisfy:  Rule(Node(t,T ), Node(t, )).weight = I P(Nudr(t ,  ))  P(Node( t ,  )) = where  ( t ,  It, E T,  Rule(Node( t s ) ,  Node( t ,  )) E RULE) The interest association rules in the interest association  repository point out the probability from one lemma (interest) to another. From the interest association repository, the user?s browsing tracks and the current web page, we can predict the most possible accessed links in the current web page. The interest association rules in the interest association repository are based on the analysis of the great amount of historic data.

We now introduce the construction of the interest association repository in details. The repository can be constructed every certain time. When the user browses a web page, quite often she or he only accesses some web pages of her or his current interests. Such web pages are more valuable than the historic data. Considering the response speed of accessing the web pages, we can not reconstruct the interest association repository completely.

But considering the user?s browsing tracks, we use a certain method that can modify the interest association repository step by step. Therefore the fault of the data in pre-fetching period is avoided.

Users? browsing tracks are made up of the users? current accessing web pages. If all the n previous pages must be processed when the user accesses the n+l th  web page, the response time cannot be assured when n is big.

So an incremental algorithm which modifies the interest association repository every time works well when the user accesses one web page.

Algorithm 1: the increment algorithm of adjusting the interest association repository.

Assume that the user is accessing the nth web page Y,, .

A few steps are taken as follows to modify the interest association repository.

Step 1 Calculate the frequency of lemmas of T in the web page Y,, (the slicing, stemming and thesaurus  technologies [ 161) are taken and a set K ( Y, ) = { ( t f : ,  fi ) I  I_  t,: E T is obtained, where f i  is the frequency of t,? appearing in Y,, , f ,  >O,iE N ) .

Each Node ( t ) in the interest association repository is adjusted as follows:  Step 2  if Node ( t ). t = tf? and ( t f : ,  f ,  ) E K( Y,, ) then Node( t ).weight = Node ( t  ).weight + f, x F(n),  where, F(n), a monotonous and non-degressive function, represents the freshness.

It is easily proved that the function F(n)  ensures that the more recently the web pages are accessed, the more favorable is to predict these web pages. F(n)  can be n ,  nz and so on. During this process, the weight of the node in the interest association repository increases gradually according to the user?s accessing sequence, so that the sequence of the user?s accessing tracks has been embodied in the interest association repository. We can use the following steps to predict the links that will be chosen by the user.

4. The Proposed Data Mining Technique Data mining has been well-known as a database  technology developed in recent years [ 171. It can mine the implicit, unknown, and potentially useful knowledge and rules for predicting [20]. Using these rules, we can predict the user?s impending activities.

The interest association rules directly represent the relations of reasoning between interests. But the data in the cache shown in the simple WWW data model directly represent the link relations in the web pages, which cannot directly reflect the association degree between interests.

Therefore certain measures are taken to transform the data in the cache shown in the simple WWW data model. The associations, the sequence patterns and the sequence of same time can benefit from the association analysis in the data mining technology. In convenience, we do not consider the transferable relations among the rules when we build the interest association rules. Hence it  is suitable to apply the method of discovering relations by the model of the simple interest association rules.

Because mining information from the abundant historical data may take more time, it is not proper to predict the user?s activities online. The solution is to use increment algorithm (shown in the above) to mine the user?s browsing interest association rules every certain time, based on the historical information in the cache.

Now we represent the algorithm for mining the association rules.

Algorithm 2: mining the interest association rules from the data in the cache.

for each page Yi in the set C do I* for1 *I for each link I , , ,  in the set L ( Y i  ) do /* for2*/  assume I,,, .target-node = Y j  ;     if Yj E C then  foreachlemma(ti ,  f,,)inthesetK(Y,)do /*for3*/  for each lemma ( t i  , f 4  ) in the set K( Yj ) do /* for4*/  Rule (Node (ti ), Node ( t i  )).weight t Rule (Node ( t ;  ), Node ( t i  )).weight +  g( f p ,  f 4  , Y ,  .time, Yj .time)  where ( t b , f ) E K( Y , ) , ( , f ) E K( Yj >; end for /* for4*/  end for /* for3*/ else  for each lemma ( r b , f , ) in the set K ( Y , ) do /* for5*/ for each lemma t i  in the set Q ( I , , ,  .sfring) do Pfor6*/  Rule (Node (ti ), Node ( t i  )).weight t Rule (Node ( t i  ), Node ( t i  )).weight  + h (f,,, Y i  .rime) where ( r b  , f, )E Y, , t i  E Q ( I , , ,  .string);  end for /* for6*/ end for I* for5*/  end if end for /* for2*/  end for /* for1 *I Rule (Node ( t ,  ),Node( t )).weight  Rule( Node(t, ), Node(t )).weight - - Rule(Node(t,), Node(tj)).weight  Q(Noddr,  ))  Q (Node ( t i  )) = where  { t It E T ,  Rule( Node(ti ), Node(t . ))E RULE } /* normalize the weight of interest association rules */.

In the loop for4 of the above algorithm, the influence  of the web pages in the cache, their links and linked web pages on the interest association rules in the interest association repository is defined as the function g ( f , ,  f 4  , Y, .time, Yj .time), where f, and f 4  are the  appearance frequency of lemma t p  in the page Y ,  and  lemma t i  in the Yj , respectively, and Y, .time and  Y j  .time are the accessed time of pages Y, and Yj ,  respectively. In the loop for6, the influence of the web pages in the cache and their links on the interest association is defined as the function h ( f, , Y, .time),  J  where t i  is the appearance frequency of lemma t i  in the page Yi and Y, .time is the accessed time of page Y ,  .

The supporting rate is a very important guideline in data mining. The Rule (Node( ti ), Node( t i  )).weight from  the Algorithm 2 is the supporting rate of the interest association rule, Rule (Node (1, ), Node( t )).

5. Predicting the User?s Activities Based on the aforementioned interest association  repository, We can use the following steps to predict the links that will be chosen by the user.

repository to predict the user?s activities.

page.

the current web page.

Algorithm 3: using the interest association  Step 1 Use the Algorithm1 to process the current web  Step 2 Let L = { 1, , I ,  . . . I ,  ] be the all links that are in  for  each I ,  in L do Slice the lemmas in the string in the I ,  and get C ( 1 ,  .string)=( t, I C  is in l ,  .string, j E  N ) .

. .

Step 3 Score all the links in L  Value( 1; )=  xNode(&).weightx Rule(NodefL), Node(;.?)).weight J Q  where Q = { ( t i  , t, )I ( t i  , f, ) E  K( Y, ), and t ;  E C ( I ,  .string),  Rule(Node( ti  ), Node(t,?)) E RULE] .

Step 4 Sort Value ( 1 , )  in descending sequence. The  more advanced the links are, the more possibly the users access.

Select s foregoing links (If s > k then let s = k.

Generally s is not more than 5). If the web pages pointed by such links do not exist in the local cache, they will be pre-fetched.

The reliability is an important factor in pre-fetching technology. From the Step 3 above, we can get the reliability of link 1,  :  c N o d t ( t ;  ).weighH Rulc(Nodt(t;( ), Nodc(t?l)).weight J Q 1 .

Z N o d d t ,  ).weight Q  where Q = ( ( t i  , r l )  I ( t i  , f, )E K( Y, 1, t l  E c ( 1 ,  string),  Rule (Node( t i  ), Node( f ;  )) E RULE) .

Now, we can get the reliability of the pre-fetching algorithm:  Node(t; ).weightx Rule(Node(t; ), Node(ti)).weight  the link the The The Hit number of number number of number ratio the visited of the the pre- of the % pages clicked fetched selected  links web pages web pages  www.netscape.com 60 10 15 7 70.0 www.ibm.com 12 3 5 2 66.7  S  Node(t; ).weight S  Availability of Pre-fetching ratio% the pre-fetched web pages %  46.7 25.0 40.0 41.6  where  s=( t ;  , t i  0 1  ( t i  , f k  E K ( Y,, ), t l  E Y C ( l . s t r i n g )  , I ?  L  Rule (Node ( t i  ), Node ( t i  )) E RULE) .

6. Agent-Based Web Pre-fetching System An agent [ 15,11,4] based web pre-fetching system  implementing the approach described in previous sections is shown in the Figure 2. In this system, the Interest Association Repository, the Mining Agent and the Decision Agent [ 14,191 are attached to the Browser side.

The Interest Association Repository uses SQL Server7.0 to save the pre-fetching rules. The Mining Agent and the Decision Agent are implemented by WIRPL [17]. A mining agent runs at the client side and updates the interest association rules periodically (the refresh rate can be set by users). According to Algorithm 2, the data in the local cache represented by the simple WWW data model  www.chinaren.com www.xici.net  www.tsinghua.seu.

edu.cn www.fanso.com  www.yahoo.com  Service ining Agent  43 10 12 6 60.0 50.0 27.9 108 15 20 5 33.3 25.0 18.5 60 10 12 4 40.0 33.3 20.0 32 9 10 4 44.4 40.0 31.3  33 10 15 6 60.0 40.0 45.5  Interest Association Repository c Figure 2: An agent based web pre-fetching system  above are transformed into the interest association rules which are then stored in the Interest Association Repository. The Decision Agent running at the client side can detect the user?s activities in real time and can provide the abilities of predicting the user?s activities online. It should take charge of the tasks such as getting the current web page in the browser, analyzing the current web page using Algorithm 3, interacting with the interest association repository, pre-fetching the web pages and saving them into the local cache. The interest association repository, the mining agent and the decision agent are transparent to the users. Therefore the users can use the browsers usual.

www.sun.com I 16 15 ( 8  1 2  1 40.0 I 25.0 1 50.0 www.sina.com I 129 I 12 I 22 I 7  I 58.3 I 31.8 I 17.1  www.seu.edu.cn 1 101 1 10 1 20 1 4  1 40.0 I 20.0 1 19.8 Whole evaluation I 594 I 9 4  I 139 I 47 I 50.0 I 33.8 I 23.4  7. Experiment In this experiment, the user interest model is based on  326 web pages, which are selected from the cache of one user?s computer. Using the user?s interest model, the agent-based web pre-fetching system can trace and predict the user?s actions. The data shown in the table 1 are recorded when the user visits 10 web sites randomly. In the table, the link number of visited pages is the average  link number of the user?s visited pages in the web site.

The number of the clicked links is the average number of the clicked links of the user?s visited pages in the web site.

The number of the pre-fetched pages is the average number of the pre-fetched web pages for each of the user?s visited web page. The number of the selected web pages is the number of web pages, which are selected from the pre-fetched web pages when the user browses them. The hit ratio is the ratio of the number of the pre-     fetched web pages selected by the user to the number of the user?s visited web pages. The availability of the pre- fetched web pages is the ratio of the number of the pre- fetched web pages to the link number of the links in the user?s visited web pages. The pre-fetching ratio is the ratio of the number of the pre-fetched web pages to the number of the links in the user?s visited web pages. The less pre- fetching ratio and the more hit ratio and availability of the pre-fetched web pages, the better is the optimization of the system. The experimental data shown in the table 1 are closely associated with the web sites selected by the user, the user?s current interest and the user?s visiting activities.

The benefit of tracing the user?s current interest is provided in the agent-based web pre-fetching system, which can commendably adapt the user?s current interest.

The whole evaluations in this experiment show that the average hit ratio is 50.0% and that the average pre- fetching ratio is 23.4%. We can conclude that the agent- based web pre-fetching system optimizes the course of the user?s visiting web pages.

8. Conclusion This paper first presents a simple WWW data model,  and then introduces some technologies with which the data in the cache of the browser can be mined, the knowledge is saved into the interest association repository, and the users? impending activities can be predicted. Integrated with the data mining technique, the agent technology and the web technology, better quality of web service for the users is provided. The design ideas of the agent based web pre-fetching reflect the development tendency of intelligent web browsers.

9. Acknowledgments We would like to thank Zhou Xiaoyu, Xu Lei, Huang  Hui, Liu Yuan, Li Shenzhi and other people at Ada lab who met to discuss the related issues and improved the readability.

