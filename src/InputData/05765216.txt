March 26-28, 2011 Nanjing, .Jiangsu, China

Abstract-Web logs record actions and behaviors of users. By mining and analyzing these logs we can find users browsing and access patterns, and this is very important and useful to the web site optimization and recommender. This paper first analyses the association-rules-based personalized recommender model which is very popular in web site recommender system, points out the limitation of the frequent access path algorithm in this model, and then improves it. At last, the paper shows by the test results that the improved algorithm can advance the recommending quality.



I. INTRODUCTION  With the fast development and extensive application of Internet technology, the information on the website has been growing exponentially. The website users are  satisfied because it meets their informational needs. However, they are also suffering from such huge amount of information, as well as those problems brought by the World Wide Web due to its distributive, dynamic, massive, heterogeneous, complex and open properties. Thus, a novel technique is badly in need, which could automatically dig out desirable information from the huge pool of resources as quick as a flash, withdrawing it and at the same time filtering out other information unwanted. Fortunately, the emergence of personalized recommendation technology relieves us of infinite data and the commercialized world by saving us plentiful time and energy on searching information. In addition, this new technology also successfully changes the service of website from webpage-centered mode to user-oriented one. It supplies users with personalized services and forges ahead toward the realization of supreme level of the whole Internet services. Many research works have been done in this area such as [1]-[6]. But the recommendation results are not satisfactory. In this case, it is of vital significance to find new ways or to improve existing technology in order to uplift the quality of personalized recommender system.

In this paper, we first outline the association-rule-based personalized recommender model which is very popular in web site recommender system. Then we focus on the frequent access path algorithm used in the recommender model, point out the limitation in this algorithm, and then improve it. At last, the paper shows the test results.

Manuscript received October 28,2010.

Yuhua Chen is with Computer Science and Technology College, Dalian  Maritime University, Dalian, China. phone: 8613614080538; e-mail: yuhuach@ sina.com).

Xin Chen, is with Computer Science and Technology College, Dalian Maritime University, Dalian, China. (e-mail: yuhuach@sina.com).

Haoyi Chen, is with Computer Science and Technology College, Dalian Maritime University, Dalian, China. (e-mail: yuhuach@sina.com).

I I. GENERAL MODEL OF ASSOCIATION-RULE-BASED PERSONALIZED RECOMMENDER SYSTEM  Association-rule-based personalized recommender model is generally made up of the offline mining module and online recommendation module. System structure is shown in figure 1. Offline mining module is divided into web log data pre-processing stage and web log data mining stage, the main task is to use web log mining algorithm to identity the user's access patterns from the web log data after pre-processing, and update and maintain the user's behavioral patterns database. Online recommendation module provides the user smart and real-time recommendation which user may be interested in the contents of based on the user's current browser behavior, as well as behavioral patterns in database.

I Web log I _____________________________ 4Jb _______________________________ _  om' duJ me m11l1l1g rno e Data pre-processing stage /The topology structure I_ of the web site ? I Data I . . 1 , User Session .1 Path I ? ' I ,TransaCtion, 1 cleaning .. identification identification completion .. identification  -LL ? ata mining stage If Mining us er' s frequent access path The graph of , I fre quent ac cess path  Web selVer Client browser  Fig. 1. Framework of association-rule-based personalized recommender model  A. Data pre-processing stage Data cleaning: Delete the irrelevant redundancy with  mining in web log data, at the same time, convert useful web log information to an appropriate data format.

User identification: Identity each corresponding user from the log records.

Session identification: A user session is a series of browser requests of a user from entering the site to leaving the site.

Different users' visit pages belong to different sessions. Web server logs record each user's visit pages that a user may visit the site many times in a certain period of time, and session identification is to identity the user's visit record into a single session which can respond a user's visit habits.

Path completion: According to server logs and network topology information, educe user's entire access path.

Transaction identification: IdentifY each transaction from the session because transaction is more accurate than session to respond a user's visit habits.

B. Data mining stage Mining user's frequent access path: First convert the log  data to the MFP (Maximal Forward Reference) set and store it in the database, then mine the MFP set by Apriori-based algorithm to get the user's frequent access path. Frequent access path can help us know the user's visit habits.

The graph of frequent access path: Create frequent access path graph from the user's frequent access paths, prepare for calculating recommendation set in the online stage.



III. THE SHORTAGE IN FREQUENT ACCESS PATH ALGORITHM AND THE IMPROVEMENT ON THIS ALGORITHM  Fig.2 as shown is a frequent access path graph after web mining based on the frequent access path algorithm in [2] for one Website.

Fig. 2. Frequent access path graph pre-improving Two limitations were found out in the frequent access path  algorithm in [2], which were described as follows.

1) In the generation algorithm of frequent access path  graph, the line 20 and 27, respectively, for the same page of the same MFP and the same page of the different MFP that if there were any page the user holding time tj> = TX, and the properties of the original value of the page is 0, then update this value to 1. That is, a page A in the previous MFP[ is a navigation page but when it first appears as the content page, we update page A to the content page. Or a page A in MFP[ is a navigation page, but in MFP2 is a content page, thus we update A to the content page.

Fig.2, in the item (C, 10, 1), 10 represents the appearance number of C, 1 represents that C is the content page. However, due to C in the MFP may be a navigation page, but as long as C appears in the back of MFP and C is the content page, we will update C to the contents page, that is, if the first 6 times appearance of C are navigation pages, and the 7th is the content page, then we will update C to the content page.

Accumulating the total number ofC's appearances (including the content pages and navigation pages) is 10.

Since we do not recommend navigation page to the user, the navigation page is not required by the user, so when page C is a navigation page, we do not need to accumulate the weights of vertices (the number of visiting the corresponding web page of vertex), we only need to accumulate the appearance number of that C are content pages. Thus, in the following recommendation process, we can accurately recommend the pages (content pages) which user like to the user.

For example: Fig.2, after the user visiting the page E, we may recommend the user three pages, C, F, H respectively,   which are the top 3 pages in user's visit times. Page C's visit times are 10, page G's visit times are 9, page H's are 6.

However, in C's 10 visits, the times of that C is a navigation page are 8, and the times of that C is content page are 2. Page K which not be recommended, may be is a content page for all 4 times visits, more than C's times of content pages. So that we may not truly understand the behavior patterns of users, the pages that we recommend may not the user need, so the quality of the recommendation may have a sharp decline.

We should recommend page K replace ofC to the user, so the number of the weight should not be accumulated on the number of navigation pages.

2) In Fig.2, the user visited the page C, the user may through the page B to page C, or through the page E to page C.

But the weight of page C (that is, the number of visiting the corresponding web page of vertex) is the total number which a user visits the page C, it did not distinguish the number between how many times the page is visited from the B and how many times the page is visited from the E.

For example: page A is the home page of a web site, page E is the home page of sports, page B is the home page of blog, page C is a sports star's blog page. Fig.2 shows that a user like to visit page C from the page E and B, most likely the user visit the page C from B more frequent than from the page E, so when the user visits sports home E he will continue to visit the page C is not necessarily greater than the probability ofH, that is, if the visit times of page E to page H are 5 ,  and page E to page C is 3, page F is a navigation page, so that we should first recommend the content of the page H, following the recommendation of the content page C.

The improved frequent access path algorithm is shown as follows.

Input: user's visit transaction set T= {tl,t2, ... ,tn } , minimum support p min  Output: the frequent access path graph G 1) MFPS +- <D IIMFPS holds the maximum forwarding  visit path set 2) for(S=I; S<=n; S++)II 3) {Yl =Xl,j=2; i=2; II {Xl, X2 .... ,Xm} is the visit  web page list of ts, i is the seeking cursor in { Xl,  X2 .... ,Xm}, j is the extending cursor for MFP 4) flag= YES; Ilflag shows the moving direction of the  cursor when finding the MFP in ts 5) while (i<=m) { 6) if(Xi==Yk) for some 1<=k<=j{11 7) if (flag = =YES){ 8) if(list{YI, Y2, ...... , Yj-l} not found in MFPS)  9) {{YI,Y2 , Yj-1}?MFPS, set the  appearance time as 1 for {YI, Y2, ...... , Yj-l}} 10) else 11) {accumulate the visit time for { YI, Y2,  Yj-l}} Ilend if 12) }llend if 13) j=k+ 1; i=i+ 1; 14) flag = NO; 15) }llend if 16) else    17) {Vi =Xi ;j=j+l;i=i+l; flag=YES; }II 18) }llend while 19) if (flag = =YES) 20) {if the { YI, Y2, Yj-l} is not found in the  MFPS, then { YI, Y2 , ... ... , Yj-l } ?MFPS , else  accumulate the visit time for { YI, Y2 , Yj-1} }llfind the last MFP  21) }llend for 22) for every MFPiEMFPS{ 23) if ((the visit time of MFPi I ITI? P min){ lithe  MFPi is frequent 24) count the visit time for Tm<TX, is the holding time  of web page Xm in MFPi Ilcount the time of Xm when Xm is visited as a content page but not a navigation page  25) if (there are vertexes in G for top j web pages in MFPi) {accumulate the visit time when it is a content page for every correspond vertex, set up correspond vertexes in G for bottom m-j web pages, build directed edges, earmark visit time of content pages on correspond vertex}  26) else {set up correspond vertexes for MFPi, build directed edges, earmark visit time of content pages on correspond vertex }  27) }llend if 28) }llend for  The modified graph of frequent access path according advanced algorithm is shown in Fig.3.

At this point, the frequent access path graph is a digraph G = (V, W (V), E), which V is the vertex set, that the page URL set; E is directed edges that the hyperlink relations between the two web pages; W (V) is the weights of vertices that the number of visiting the corresponding content web page of vertex.; Get rid of the property item of vertex because at this time in frequent access path graph each vertex's corresponding web page is content page.

@-?) @?  E-+@ --+G  -+? Fig.3. Improved frequent access path graph

IV. RECOMMENDA nON QUALITY ANALYSIS  A. Experimental data In this paper, the experimental data are logs of user  accesses to the music machines web site (currently at http://machines.hyperreal.org) from 02112/97 through 4130/99 provided by the University of Washington in the United States. During that time, site content did change somewhat, but the basic structure and most of the files remained untouched.

B. Experimental evaluation method In this paper, the evaluation method is given by Bamshad  Mobasher to analyze the quality of its recommendation, including the precision, coverage and F-measure [6].

For each transaction t in the evaluation set, we select the top n pageviews in t as the surrogate for a user's active session window. The active session window is the portion of the user's click stream used by the recommendation engine in order to produce a recommendation set. We call this portion of the transaction t the active session with respect to t, denoted by ast? Both of the CF-based techniques take aSt and a recommendation threshold 't as inputs and produce a set of pageviews as recommendations. We denote this recommendation set by R(ash't). Note that R(ash't) contains all pageviews whose recommendation score is at least 't (in particular, if'! =0, then R(ash't)= P, where P is the set of all pageviews.

The set of pageviews R(ash't) can now be compared with the remaining portion of t, i.e., with t-ash to measure the recommendation effectiveness using 3 different metrics, namely, precision, coverage, and the Fl measure.

The precision ofR(ash't) is defined as:  precision(R(as" r)) = I R(as" r) n (t -as,) I (1)  I R(as" r) I  The coverage ofR(ash't) is defined as: I R(as , r) n (t -as ) I  coverage( R( as" r)) = ' , It-as, I  (2)  The precision measures the degree to which the recommendation engine produces accurate recommendations (i.e., recommends pageviews that will have be visited by the user in the remaining portion of the user's session). On the other hand, the coverage measures the ability of the recommendation engine to produce all of the pageviews that are likely to be visited by the user. Ideally, one would like high precision and high coverage. A single measure that captures this is the Fl measure, defined in terms of precision and coverage:  Fl = 2 x precision x coverage (3) precision + coverage  The F 1 measure attains its maximum value when both precision and coverage are maximized.

C. Experimental plan and condition In this paper, the experimental data selected from January 9,  1999 to January 12, 1999, four days 134,785 logs for analysis.

After Data Cleaning there are 36,011 logs, 7393 users to be identified, 8792 user sessions. Finally, we select 649 user session data which the length more than 10 and less than 40 as a data set, in which random data about 2 I 3 of the record as a training set, used to analyze user access patterns for recommended sequence set, the remaining 1 I 3 records as a test set for the quality of the recommended evaluation.

In this paper, experiments equipment is a PC with P4 2.8GHz CPU, 512MB memory, the program runs in Windows XP, the programming language is C # language.

In the testing, we remove the navigation pages in test data    set because that we do not accumulate the number of navigation pages in the modified graph of frequent access path. If the user holding time of a page t <5s, we judge the page is a navigation page. In the experiment, we define minimum support threshold of the association rules is 0.2, The length of association rules front item (viz. sliding window) is 2, the length of association rules consequence is uncertain [7].

D. Experimental results and analysis  The experimental results are shown in Fig A to Fig.6.

c o  0.6 0.5  .? .S 0.4 u '" ? ';3 0.3 ? " 8 B. 0.2 E O. I  Compa!" i son of' recommendati on prcc i sj on  f-----===-___...... ----- - f-- ? _______  ?lhe gener'al model  f--- /L-/ _______ .... _---; --r???e?10dified / - '----------' .

OL----L----'----'----'  2 4 6 8 the number of recommendation  pages  Fig. 4. Comparison of the recommendation precision before and after the improvement  Compar ison of recommendation coverage  " E O.12 ? O. I ? O. 08 I------:ii?-""""'-/ '3 O. 06 I-?--- '" -g 0.04 ? 0.02 o E 0 4 6 8  the number of recommendation  pages  ? the general model  __ the modified model  Fig. 5. Comparison of the recommendation coverage before and after the improvement  0.2 E 0.15 ? g O. I e I  "- 0.05  Comparison of recommendation F-measlIre  ? the geneml mode)  mode)  O L-.....:::::----'----'---'---- 2 4 6 8 lhe number of recommendat ion  pages  Fig. 6. Comparison of the F-measuring before and after the improvement  It shows in Figo4 to Fig.6 that the recommendation precision, recommendation coverage and the F-measuring before improvement are obviously higher than after improvement.



V. CONCLUSION In this paper we focus on the frequent access path  algorithm In the association-rules-based personalized recommender model which is very popular in web site recommender system, point out the shortage in this algorithm, and then improve it. At last, the paper shows by the test results that the improved algorithm can advance the recommending quality.

