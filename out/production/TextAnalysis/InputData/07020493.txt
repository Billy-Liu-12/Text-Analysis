Efficient Apriori Based Algorithms for Privacy Preserving Frequent Itemset Mining

Abstract?Frequent Itemset Mining as one of the principal routine of data analysis and a basic tool of large scale information aggregation also bears a serous interest in Privacy Preserving Data Mining. In this paper Apriori based distributed, privacy preserving Frequent Itemset Mining algorithms are considered.

Our secure algorithms are designed to fit in the Secure Multiparty Computation model of privacy preserving computation.



I. INTRODUCTION  An important and emerging tool of collective knowledge is the distributed data mining, i.e. building unified models based on data sets possessed by different owners. This type of knowledge sharing become productive if one can also handle the privacy demands of the data owners. A typical requirement can be that during the model building the in- house data sets should be kept secret for other participant than the owner. Solutions of this type of problems lead to intra- cognitive communications, assuming a similar computational power and data structure at the parties. Assessing the other dimension of cognitive infocommunications one see that pri- vacy preserving distributed data mining is a special example of sensor-bridging and representation-bridging communication [1]. About the emerging concept and recent application of cognitive infocommunications see also [2] and [3].

Several models and algorithms have been already trans- formed into the privacy preserving data mining settings [4], but much less attention was dedicated to their efficiency, optimising the computational and communicational volume of the privacy preserving processes. Our contribution em- phases this point of view in the case of privacy preserving Frequent Itemset Mining. Frequent Itemset Mining as one of the principal routine of data analysis and a basic tool of large scale information aggregation. In this paper Apriori based distributed, privacy preserving Frequent Itemset Mining algorithms are considered. Our secure algorithms are designed to fit in the Secure Multiparty Computation model of privacy preserving computation.

The paper is organized as follows. Section 2 introduces the concept of Frequent Itemset Mining and the well-known Apriori algorithm. Section 3 discuss the Secure Multiparty Computations, the model used here for privacy preserving calculations. This section also cover the necessary SMC prim- itives. Section 4 contains our main contribution, the improve- ment of the basic privacy preserving Apriori algorithm. In the final section we present our measurement based analysis of the suggested algorithms.



II. FREQUENT ITEMSET MINING  First a few concepts of Frequent Itemset Mining are reviewed. For a more detailed introduction we refer to [5] and [6]. Let I = {i1, i2, ..., id} be the set of all items. Let T = {t1, t2, ..., tN} be a transaction (or market) database, where a uniquely labeled transaction ti contains a subset of items chosen from I . A collection of zero or more items is termed an itemset. An itemset containing k items is called a k- itemset. A transaction tj is said to contain an itemset X if X is a subset of tj . The width of a transaction is defined as the num- ber of items contained. A central property of an itemset X is its support count ?(X), which counts the number of transactions that contain itemset X , i.e. ?(X) = |{ti|X ? ti, ti ? T}|.

The (relative) support of X is supp(X) = ?(X)/|T |. Given a transaction database T and a minimum support min supp, an itemset X has supp(X) ? min supp is called frequent itemsets.

A. Apriori algorithm  In general, a data set that contains k items can potentially generate up to 2k-1 frequent itemsets, excluding the null set.

To reduce this we can reduce the number of candidate itemsets, i.e. eliminate some of the candidate itemsets without counting their support value. Apriori is the first association rule mining algorithm that pioneered the use of support-based pruning to systematically control the exponential growth of candidate itemsets. The use of support for pruning candidate itemsets is guided by the Apriori Principle. This follows from the antimonotonicity of the support as set function, namely if an itemset is frequent, then all of its subsets must also be frequent.

The pseudo-code for the frequent itemset generation part of the Apriori algorithm is shown in Algorithm 1.

At step 5 of Algorithm 1 candidate generation is being executed. There are several functions existing to satisfy this step. Here we show one possible solution for this problem, the Fk?1 ? Fk?1 Method. The candidate generation procedure in the apriori-gen function merges a pair of frequent (k-1)- itemsets only if their first k ? 2 items are identical. Let A = {a1, a2, ..., ak?1} and B = {b1, b2, ..., bk?1} be a pair of frequent (k-1)-itemsets. A and B are merged if they satisfy the following conditions: ai = bi (for i = 1, 2, ..., k? 2) and ak?1 6= bk?1.

Algorithm 1 Frequent itemset generation of the Apriori algo- rithm.

Let Ck denote the set of candidate k-itemsets and Fk denote the set of frequent k-itemsets.

1: k = 1.

2: Fk = {i|i ? I??({i}) ? N?minsup}. {Find all frequent  1-itemsets} 3: repeat 4: k = k + 1 5: Ck =apriori-gen(Fk?1). {Generate candidate item-  sets} 6: for each transaction t ? T do 7: Ct =subset(Ck, t). {Identify all candidates that  belong to t} 8: for each candidate itemset c ? Ct do 9: ?(c) = ?(c) + 1. {Increment support count}  10: Fk = {c|c ? Ck ??(c) ? N ?minsup}. {Extract the frequent k-itemsets}  11: until Fk = ? 12: Result=  ? Fk.



III. PRIVACY PRESERVING CALCULATIONS  Our view of privacy preserving data mining and computa- tional model derived from a multi-party approach. For a survey of privacy preserving data mining see e.g. [7] and [4], and on general multi-party computation see [8] and [9].

The basic idea of Secure Multiparty Computation (SMC) is that a computation is secure if at the end of the computation, no party knows anything except its own input and the results (privacy). One way to view this is to imagine a trusted third party - everyone gives their input to the trusted party, who performs the computation and sends the results to the participants. But this is not likely to happen in real-world applications, thus we use and create algorithms where the same result can be achieved without using a trusted party. Besides privacy, security requires (and not defined by) the followings as well: correctness - each party is guaranteed that the output that it receives is correct; independence of inputs - corrupted parties must choose their inputs independently of the honest parties? inputs; guaranteed output delivery - corrupted parties should not be able to prevent honest parties from receiving their output; fairness - corrupted parties should receive their outputs if and only if the honest parties also receive their outputs. Another parameter that must be defined relates to the actions that corrupted parties are allowed to take. There are two main types of adversaries: semi honest adversaries - even corrupted parties correctly follow the protocol specification, however, could attempt to derive as much additional informa- tion as possible from internal states and/or the result; malicious adversaries - the corrupted parties can arbitrarily deviate from the protocol specification. In the followings we shall work in the semi-honest model [10].

A. Privacy Preserving Apriori Algorithm  The privacy preserving version for p ? 3 parties has been reviewed in [11], here we would like to give an outline of previous works. Before we go on to the main algorithm, we need to introduce the Secure Union and the Secure Sum SMC protocols.

Secure Union. Let p ? 3 be the number of participants, they all hold onto some sets, denote their respective sets by Hi for i = 1...p. We would like to determine the union of all sets with- out revealing any of them. First every participant has to choose a commutative encryption function. An encryption algorithm is commutative if given encryption keys K1, ...,Kn ? K, for any m in domain M , and for any permutation i, j, the following two equations hold: (1) EKi1 (...EKin (M)...) = EKj1 (...EKjn (M)...) ?M1,M2 ?M such that M1 6=M2 and for given k, ? < 1sk : (2) (EKi1 (...EKin (M)...) = EKj1 (...EKjn (M)...)) < ? Now all participants encrypt their items one-by-one, and send it to an other party, who encrypts the received encrypted items with his own encryption function and sends it again. They iterate it until each party encrypts the items of the remaining parties. All parties send their r-times encrypted functions to one party (from now on referred to as Main Party), who removes the duplicates. Now this global set is passed around, each site decrypting its items. The union is obtained.

Secure Sum. Now each participant holds onto a number of their own, and they would like to privately compute the sum of their inputs. Main Party generates a random number R, adds to its local value and sends it to the next party. All participants add their local value to the received number. At last Main Party receives the sum, subtracts R from the result and broadcasts the result.

Now we are ready to put together the privacy preserving apriori algorithm. Let denote the ith party by Pi, the number of parties is p, PM is the Main Party. Each participant has a private transaction database DBi. We are given a support threshold s. The goal is to discover all globally frequent itemsets, i.e. the ones satisfying the support threshold in the united database. Furthermore no party should be able to learn contents of a transaction (basket), or any specific value of support at any other party unless that information is revealed by the knowledge of one?s own data and the final result.

For example, if a rule is supported globally but not at one participant?s own database, we can deduce that at least one other party supports the itemset.

1) Identify all the candidate itemsets - Secure Union 2) Repeat until no more frequent itemsets are produced.

3) Verify if each item(set) satisfies the support threshold  (Secure Sum), if yes store as frequent.

4) PM generates the new candidate itemsets same way as in  the non-multi-party case.

5) PM broadcasts all frequent itemsets.



IV. IMPROVING THE PRIVACY-PRESERVING APRIORI  Our main contributions are improvements on the original privacy preserving Apriori algorithm, to reduce the compu- tational and communication costs involved in the distributed privacy-preserving setting. In this section we present three new algorithms.

Though the classic Apriori algorithm (one and multi-party case as well) has already reduced the number of itemsets we need to check for support, the number of candidates could be still exponential. In practice ? as our experiments and previous results on real datasets show ? the large number of 2-itemset candidates causes a major bottleneck in real-life  A. Csisz?rik et al. ? Efficient Apriori Based Algorithms for Privacy Preserving Frequent Itemset Mining     applications. Toivonen?s algorithm [12] with the Partition trick is one way to further reduce the number of candidates. Our algorithms build on the Partition trick, which greatly speeds up the basic one-party case Apriori algorithm.

A. The Partition trick  The main idea behind the Partition trick is to reduce the number of candidates by partitioning the dataset. The method is based on the fact that if one itemset is frequent in a database, then after partitioning the database, that itemset must be frequent in at least one of the partitions as well. In other words, no other itemset besides the locally frequent ones can be globally frequent, hence it is necessary to check the global support only for these itemsets.

The one-party Apriori with the Partition trick then proceeds as follows.

1) Partition the database.

2) Find locally frequent itemsets in each partition.

3) Check the global support for only the locally frequent  itemsets.

Our first approach carries out the Partition trick in the dis- tributed privacy preserving setting with the SMC framework, and drastically reduces the communication costs compared to the original algorithm. To further improve the efficiency, our second approach introduces a positive filtration method in addition to our first algorithm. The third method is a variation of the above, that allows us to stop the algorithm at a given level of the iterations.

Each of the three algorithm gives the same frequent itemset results, but one can choose which to use according to the circumstances and the set question.

B. The Improved Privacy Preserving Partitioned Apriori  Naturally, determining frequent itemsets between p partici- pants has value only if the participants share the same universe of items. Thus in the multi-party case, the different databases at different parties can be viewed as one giant partitioned database. If we treat them this way, we gain the following algorithm.

1) The participants agree on a minimum support threshold.

2) Each and every Pi participant determines his own locally  frequent itemsets, denoted by Loc(Pi).

3) Apply Secure Union only on all Loc(Pi), this gives us  the (one and only) candidate set at PM.

4) PM starts the Secure Sum protocol to verify the support  of each candidate.

5) PM broadcast the results, i.e. the candidate itemsets with  higher support than the threshold.

Notice that this modified algorithm requires only one Secure Union, and one Secure Sum protocols, while in the previous Apriori algorithm as many as k, the size of the largest found frequent itemset was needed.

C. Positive Filtration  Remember the fact that if one itemset is frequent in a database, that itemset must be frequent in at least one of the classes as well. This implies that if an itemset is frequent in all classes, it has to be frequent in the whole database too. Based on this observation we can slightly modify our partitioning algorithm to reduce even further the number of candidate itemsets.

Up until now, during the Secure union phase, when all locally frequent itemsets have already arrived to PM, he discarded the duplicates. Lets change it now, let PM count the number of occurrences of each candidate itemset, and after this he can get rid of the copies. Now he selects the ones which are frequent at all participant, and starts the Secure sum protocol only for the rest. He can send the selected ones now, or later at the broadcasting stage. It does not make any difference, since it did not appear among the true candidates? list during the Secure sum, thus anyone can deduce from the final result which itemsets were locally frequent everywhere.

Naturally this approach shall be useful only if we do not mind that the everywhere frequent itemsets will be known to everyone, or if the cost of the communication could be reduced so drastically that we are ready to pay its price. We will consider it further in the next section.

D. A variation of the Privacy Preserving Partitioned Apriori  Our previous algorithm has found all the frequent itemsets at once, but what can we do if we do not need all of them only some with a specific size, or some up until a specific size? The original algorithm proceeds level by level, k-itemsets after (k-1)-itemsets, so we can stop anytime we want to.

But we shall not forget that this algorithm is way too slow, especially compared to our new one. Here we introduce one more algorithm which is halfway in-between these last two, and has the advantages of either kind; it is faster than the first one, and we can also gain any frequent k-itemset without determining all of them. Our variation is the following. Let assume that we require the frequent itemsets until size k, so iterate for i = 1...k.

1) Each participant determines the frequent k-itemsets of his own database.

2) Apply Secure union on the local frequent k-itemsets.

3) PM starts a Secure sum regarding the achieved union.

4) PM determines the global frequent k-itemsets, and broad-  casts them.

5) The achieved itemsets are now the basis of the next  candidate generation, for the next round the participants? own candidates are generated only from these itemsets.

So their locally frequent k + 1-itemsets are determined from the previous iteration?s result.



V. ANALYSIS  A. Communication Complexity  In this section we consider the cost of the communication, and make a comparison between our three algorithms regarding their communication. First notice, that in our partitioning algorithm the second phase, i.e. counting the secure sum depends only on the first phase. After determining      the global candidate item-sets by a secure union, we make only a single secure sum, where no additional item-sets appear.

Thus we need to view the communicated item-sets during the secure union. Counting only the number of item-sets does not suffice since it is possible to have plenty large sets as well, which enlarge the amount of communication needed by several times. The following number is a true representation of the required amount:  m? = ?  Pi?1...r  ? Sij?Loc(Pi)  |Sij |  Where Pi is a party, Loc(Pi) is the local frequent item-sets? set at party Pi, and Sj is one local frequent item-set at that party, so m? gives us the total length of all the local frequent item-sets. Although in our case we need somewhat more: in the secure union we send this number r-times, because all local item-sets need to be encrypted by every party, so m? gives us only the sum, when everyone sends exactly one message to its neighbour synchronously. Thus when every party?s own message has done a full round we have: C = r ?m?.

We shall not forget that the cost of the representation is not included, these are raw numbers, we chose them to create a pure representation for the communication.

The size of m? depends on the followings: (1) the data sets of the baskets, (2) the minimum support we choose, (3) the number of participants, and also (4) the method we use for the distribution of the data set.

Naturally number (4) interesting only in case we have one giant data set what we distribute among the participants.

B. Comparison  Figure 1-4. represent the relationship (for 4 different sup- port counts) between the original (baseline) and our new, more efficient algorithms. We can see the expected drop in the total input length (in items) of secure sum or secure union protocols, which is mainly due to the fact, that the baseline algorithm takes into consideration a great number of the smaller-size itemsets, which for example for the 2-size itemsets can be up to (  n   ) ? n2  In other words, the baseline (?A?) algorithm works with a great number of false candidates, includes them in the com- munication and later eliminates them; and this leaves a huge impact on the cost of the communication. On the other hand it is clearly visible that our new algorithms use less unwanted pseudo-frequent itemsets even from the very beginning. All those nowhere frequent itemsets (using the partition trick), which have frequent subset(s) are not considered during the execution in the new algorithms in contrast with the baseline Apriori, where this is untrue, i.e. all itemsets generated from frequent ones are considered thus the high communication cost concludes.

We also considered the method used for the distribution of the data set (if that is needed). According to the given circumstances different distributions can be applied. Figure 5- 8. show us only our new algorithms twice, once where we applied consecutive cuts and the other one is with random dis- tribution. We can see on the figures, that randomly distributing  the main data set gives us better result at the selecting stage, than applying consecutive cuts, thus we are able to further lower the size of the communicated dictionary in the secure sum.

As expected, all the three above method reduced the run- ning time of the original privacy preserving Apriori algorithm.

The positive filtration is the fastest among all three.

Fig. 1. Comparsion of total input lengths of secure protokols. The used dataset is retail 10k, minimal support is 0.10.

Fig. 2. Comparsion of total input lengths of secure protokols. The used dataset is retail 10k, minimal support is 0.05.

Fig. 3. Comparsion of total input lengths of secure protokols. The used dataset is retail 10k, minimal support is 0.02.

A. Csisz?rik et al. ? Efficient Apriori Based Algorithms for Privacy Preserving Frequent Itemset Mining     Fig. 4. Comparsion of total input lengths of secure protokols. The used dataset is retail 10k, minimal support is 0.01.

Fig. 5. Comparsion of total input lengths of secure protokols. The used dataset is retail, minimal support is 0.10.

