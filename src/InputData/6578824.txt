Conceptual Framework to Enable Early Warning of  Relevant Phenomena

Abstract? Graphs are commonly used to represent natural and man-made dynamic systems such as food webs, economic and social networks, gene regulation, and the internet. We describe a conceptual framework to enable early warning of relevant phenomena that is based on an artificial time-based, evolving network graph that can give rise to one or more recognizable structures. We propose to quantify the dynamics using the method of delays through Takens? Theorem to produce another graph we call the Phase Graph. The Phase Graph enables us to quantify changes of the system that form a topology in phase space. Our proposed method is unique because it is based on dynamic system analysis that incorporates Takens? Theorem, Graph Theory, and Franzosi-Pettini (F-P) theorem about topology and phase transitions. The F-P Theorem states that the necessary condition for phase transition is a change in the topology. By detecting a change in the topology that we represent as a set of M-order Phase Graphs, we conclude a corresponding change in the phase of the system.  The onset of this phase change enables early warning of emerging relevant phenomena.

Keywords?small work networks, emergence, complexity, graph theory, graph spectra, time series analysis, Takens? theorem, phase space, phase graph, topology

I. INTRODUCTION Early warning has historically been of keen interest to  individuals, communities and nations, as well as international institutions. With today?s vast information data repository generally assessable via the internet, ?big data? is being investigated as both a tool and an enabler within the context of the early warning of relevant phenomena.  The paper?s organization reflects a progression of the introduction of a series of technologies along with definitions to describe a conceptual framework to enable the early warning of relevant phenomena.



II. IDENTIFICATION OF TECHNOLOGIES  A. Concept of Emergence, Complexity and Their Impact The concept of emergence is a respected term within the  subject domain of evolutionary theory which can be traced  back to the latter 19th century and early 20th century [1]. Its re- emergence roughly coincided with the growth of scientific interest in the phenomenon of complexity and the development of nonlinear mathematical tools. Complexity theory gives mathematical legitimacy to the idea that processes involving interactions among many parts may be at once deterministic yet for various reasons unpredictable [1]. Suffice it to say that there is no universally accepted definition of emergence. We offer a simple definition as ?emergence functions not so much as an explanation but rather as a descriptive term pointing to the patterns, structures or properties that are exhibited on the macro-scale [2].? In the context of this definition, we seek to model and forecast an emergent property when it is observed enough times to gather adequate information about it [3].

B. Graph Theory and Small-World Networks Dynamical networks constitute a very wide class of complex  and adaptive systems [4]. Specific examples range from ecological prey?predator networks to the gene expression and protein networks. On a social level we interact through social networks, to give a further example ? networks are ubiquitous through the domain of all living creatures.

The discovery of small world properties in real-world networks has revolutionized the way we analyze and study real- world systems [5].

Small-world networks, in Fig. 1, are described as having nearly all of the elements close to the other elements even though they may appear to be far away. This is generally achieved by the network having so-called shortcuts, or long- range edges, that reduce the distance to otherwise far away nodes [6]. The small-world phenomenon is surprising to our intuition and is remarkable [7]. Because of this characteristic, we ascribed for our discussion that emergence is at the formation of an organized network [8], particularly a small- world, from a seeming random set that evolves or grows over some period of time.

The analysis of networks is performed using graph theory, where the network is modeled as a graph whose nodes or vertices are connected by undirected edges. For further tractability, the vertices are undifferentiated and the edges are  This manuscript has been authored by a contractor of the U.S. Government (USG) under contract DE-AC05-00OR22725. Accordingly, the USG retains a nonexclusive, royalty-free license to publish or reproduce the published form of this contribution, or allow others to do so, for USG purposes.

Fig. 1.  Watts and Strogatz model. From a regular network to a random network, where random rewiring of some edges in a regular network produces a small world network with high clustering coefficient and low average path length.

un-weighted. The two important metrics of small-world graphs are quantified by [5]:  Average path length (APL): The measure for the so-called small world effect that provides a value that represents an average of how far apart (number of hops) any pair of nodes are within the network. APL is a measure of the global structure of the graph.

Clustering coefficient (C): The measure of transitivity clustering where two nodes that have a common neighbor also have a high possibility of being connected to each other.

By definition, a graph is considered small-world if C is significantly higher than a random graph for the same vertex set and the graph has nearly the same average path length, which is expected to be a relatively small quantity [8].

C. Graph Spectra Graph Spectra is defined in [4] as any graph G with N nodes  can be represented by a matrix encoding the topology of the network, the adjacency matrix.

Definition:  The Adjacency Matrix. The N ?N adjacency matrix  ? has elements Ai j = 1 if nodes i and j are connected and Ai j = 0 if they are not connected.

The adjacency matrix is symmetric and consequently has N real eigenvalues.

Definition:  The Spectrum of a Graph. The spectrum of a graph G is given by the set of eigenvalues ?i of the adjacency matrix ?.

A graph with N nodes has N eigenvalues ?i and it is useful to define the corresponding ?spectral density? ? ? 	 	 ? ?-? ,										 d?? ? 1,																		(1)  where ? (? ) is the Dirac delta function.

D. Time Series Data and Takens? Theorem The classical definition of time series is an ordered sequence  of values of a variable at equally spaced time intervals [9]. The fitting of time series data can be investigated and is usually dictated by the user?s application or preferences. Several useful properties include stationarity, wide-sense stationarity and  periodicity. Unfortunately, this mature field and its properties have limitations in our domain space. We do, however, want to use its underlying principles when appropriate. The Takens? embedding theorem forms a bridge between the theory of nonlinear dynamical systems and the analysis of experimental time series [10].



III. CONCEPTUAL FRAMEWORK: TIME SERIES ANALYSIS FOR EMERGENCE OF DYNAMIC NETWORKS  There are techniques for artificially synthesizing a small- world network [4, 5, 11]. Our model is founded on the Alpha Model [7]. In the Alpha Model, networks exist of two extreme networks are modeled together that includes an ordered and a random network with a set of interaction rules.  The ordered network is comprised of isolated cliques of nodes that the author calls caves forming a caveman graph. Within each cave, each node is connected to every other node. If a new node is added to a cave, it is connected to all the other nodes in the cave. Nodes from different caves do not connect. In the random network, all nodes can connect to other nodes such that the probability of two nodes connecting is equal throughout. This results in connections forming at random [12]. With these two networks, a network can evolve over time where new connections are alternately constructed based on either of the interaction rules. It is this dynamic nature where clustering occurs and small-world features emerge that is of interest.

We construct an artificial time-based, evolving network that can give rise to one or more small-world structures based on the Alpha Model. At each time increment at ti for i = 1, 2, 3?, we compute and record the values for the APL, C, and the spectrum. From this time-series data, we perform two analysis techniques: 1) statistical analysis for APL and C values that meet the small-world criteria and 2) phase space analysis that detects significant changes in the system state behavior.

For the phase space analysis, we convert each variable through the method of delays to analyze their qualitative features of the phase space. This presumes several characteristics regarding the behavior of the evolving network.

The phase state, represented by the APL, C, and spectrum, is assumed to have some regular pattern or time-independent topology that represents its normal operating space. At the start of our Alpha Model network, this would represent the caveman graphs. When the evolving network becomes an organized structure, such as the small-world, there is a noticeable state or phase change from its normal operating space to that of small- world space. According to the Franzosi-Pettini (F-P) theorem, the necessary condition for a phase transition is a change in topology [13]. Our approach detects the topology change in the phase space using Takens? theorem and detection methods similar to the analysis performed in [14].

Takens? theorem [10] gives a smooth, non-intersecting dynamical reconstruction in a sufficiently high dimensional space by a time-delay embedding. Takens? theorem is a topology statement about the dynamics. The time series data, symbolized into S discrete values, si, are converted into unique dynamical states by the time-delay-embedding vector, yi:  yi = [si, si+L , . . . , si+(d?1)L].   (2)     Specifically, Takens? theorem says that the yi-states are diffeomorphic, that is, representing the overall underlying dynamics of the system, as a way to capture topology (connectivity and directivity). The time-delay lag is L, which must not be too small (making si and si+L indistinguishable) or too large (making si and si+L independent by long-time unpredictability). The embedding dimension is d, which must be sufficiently large to capture the dynamics, but not too large to avoid over-fitting. As implied, these values are established on a case-by-case basis for different time series problems. It is our intention to identify general values classifications of problems.

In our approach, time-delay states from (2) are identified as nodes. The process flow, yi ? yi+M, forms state-to state links, identified as edges. The set of nodes and edges form a graph, we call a phase graph. This graph is ?directed? meaning that the flow is from one state (yi) to another (yi+M). We consider two methods of phase change detection as 1) comparison of M-order graphs and 2) statistical validation of measures of success.

The analysis creates M distinct M-order phase graphs are obtained from the process flow yi ? yi+M. The graphs are compared for via dissimilarity. When the dissimilarity measures cross a threshold (e.g. a sufficient number of nodes and edges are different caused by removals or additions) then a candidate for a phase change is recognized. This process can be validated against the known statistics for C and APL for small world detection.

Statistical validation of early warning requires measures of success. One measure is the number of true positives (TP) from a known event dataset (Ev), defining a true positive rate (sensitivity) of TP/Ev. A second measure is the number of true negatives (TN) for a known non-event dataset (NEv), defining a true negative rate as TN/NEv (specificity). The goal is a sensitivity and specificity of unity. Consequently, minimizing the distance from ideal (D = prediction distance) is an appropriate objective function for any event type:  D = {[1 ? (TP/Ev)]2 + [1 ? (TN/NEv)2}1/2.  (3)  The goal of (3) is to detect an actionable forecast, meaning enough early warning time to identify the emerging relevant phenomena.



IV. DISCUSSION AND FUTURE DIRECTION We have introduced an analytical method using phase space  to enable early warning of relevant phenomena that is based on an artificial time-based, evolving network graph. Our proposed method uses a Phase Graph that is based on a combination of Takens? Theorem, Graph Theory, and the F-P theorem about topology and phase transitions. After we introduced the graph measures of C, APL, and the spectrum, we described how our conceptual framework converts these time series variables to phase space leading to analysis that enables detection of topological changes. From the F-P Theorem, a change in the topology implies a phase transition. Detection of this change  serves as an indicator for early warning. Two techniques for detecting topology change are described including comparison of M-order graphs and statistical validation of measures of success. Our future direction includes our continued testing of our approach. We have designed such experiments and are in the early stages of testing. We plan to continue these tests and then apply our conceptual framework to a set of historical data to demonstrate that the framework will be able to warn of relevant phenomena.



V. ACKNOWLEDGMENT The views expressed in this paper are those of the authors  and do not reflect the official policy or position of the United States, the Department of Energy, or the U.S. Government.

