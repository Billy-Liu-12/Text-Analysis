AN IMPROVING MINING ALGORITHM AIMING AT A KIND OF SPECIFIC  FUNCTION OF DEGREE OF INTEREST

Abstract: Association rule mining is an important research area in  data mining, which has broad application background. There exist two shortages in classical assnciation rule mining problem, namely every itemset is treated equivalently and use a uniform minimum support and minimum conference as weighing standard. Through introducing the fnnction of the degree 'of interest on itemsets, % a dimcl generation of the problem of assnciation rule mining, called passociation rule mining, was introduced in 111. It can solve the two shortages at the same time. Based on FP-tree, a universal algorithm for mining pfreqnent closed iten@ was proposed in [Z]. Because this algorithm is based on general definition of q, it will not perform well for all 9. Io this paper, aiming at a kind of specifc % namely, the degree of interest of every item is given, we present an improving algorithm. The experimental and performance studies show that our algorithm is more eflicient than previous algorithm io [21.

Keywords: Data mining; passociation rule mining; pfrequent itemset  1 Introduction  association^ rule.mining is an important research area in data mining, which has broad application background ['-lo].

There exist two shortages in classical association rule mining problem, namely, every itemset is treated equivalently and use a uniform minimum support and minimum conference as weighing standard. At present three representative methods for solving these two shortages are as follows: One is using multiple minimum sup another is mining multiple-level association N&, the third is mining association rules with weighted items[6'. From these methods, we can see that they only aim at one of the two shortages. Through introducing the function of the degree of interest on itemsets, cp, a direct generation of the problem of association rule mining, called passociation rule mining, was introduced in [l]. It can solve the two shortages at the same time. Based on FP-tree, a universal algorithm for mining pfrequent closed itemset was proposed in [2]. Because this algorithm is based on the general definition of cp. it will not perform well for all cp. In this paper, aiming at a kind of specific cp, namely, the degree of interest of every item is given, we present an improving algorithm. The experimental and performance  0-7803-7508-4/02/$17.00 WOO2 IEEE  studies show that our algorithm is more efficient than previous algorithm in [2].

2 Preliminaries  Let I be a set of all the items in a transaction database TDB.

Definition 1[" Let cp be a function from P (I) to [0, + m ] which satisfy: for any two subsets X, Y  of I ,  if x C Y then cp(x)< c p ( ~ ) .  Then cp is called as a function of the degree of interest on I, where cp(X)  represents the degree of interest of X and cp(X)<cp(Y) represents that the itemset X is less interesting than Y.

Definition 2'" Let cp be a function of the degree of interest on I and X c I . The psupport of the itemset X in TDB is defined as supp (x) cp(X), denoted as psupp (X).

Definition 3'" An itemset X is said to be cp-frequent if its p support in TDB is at least given minimum support. The set FI of cp-frequent itemsets in TDB is:  Definition 4"' A passociation rule is an implication between itemsets of the form X 3 Y . Where X, Y E FZ and X fI Y =I$. The itemset X is called the antecedent of the rule and the itemset Y is called the consequent. The p support of a passociation rule, denoted as p supp ( X  3 Y) , is defined'as psupp (X  U Y )  . The cp- confidence of the Nle, denoted as cp-conf ( X Y ), is defined as cp-supp ( X U Y)  /psupp (X) . .

Definition 5['] ' The ' task of mining cp-association rules consists in generating all valid passociation rules. i. e. p association rules with psupp and pconf are at least minimum support and minimum conference respectively.

It is obvious that cp-association rule mining is a direct generalization of association rule ~ n i n g .  It can 'also be  FI = (X c ZIP- supp(X) t 5 )  ~ , .

decomposed by two subproblems:, ' .. . . .

1. Find all cp-frequent itemsets in TDB; 2. Generate all passociation roles.

Like classicalassociation rule mining, the problem of cp-  association rules mining can also be reduced to the problem of finding cp-frequent itemsets.

t i l 4  http://163.com    Definition 6['l An itemset is a closed itemset if there exists no itemset Y so that Y is a proper superset of X and every transaction containing X also contains Y.

Because closed itemsets reserve all the information of itemset 13. 8-10] , we will use this;property to simplify our problem.

Definition 7['l A closed itemset is called as cpfrequent closed itemset if its cpsupport is at least the given minimum support.

DeOoition 8"' The task of mining pfrequent closed itemset consists in generating all cpfrequent closed itemset from a transaction database.

Proposition 1" For every one cp-frequent itemset, there exists only one closed itemset Y which is also pfrequent satisfy that XcY and supp(X)=supp(Y).

From this proposition, if all the pfrequent closed itemsets are mined, then we'can obtain all cpfrequent itemsets according to the function of degree of interest'of itemset. Therefore, our aim only considers the'problem of mining cp-frequent closed itemset. Because the amount of cpfrequent closed'itemsets is less than cp-frequent itemsets, the efficiency of mining will be enhanced greatly.

Definition 9"' Given a transaction database TDB and a support threshold 5, the'list of all frequent items in support descending order is called the frequent item list, or F-list (5) in short.

Definition lof3' A frequent pattern tree (or FP-tree in short) is a tree structure defined below,  1. It consists of one root .labeled as "null", a. set of item prefix subtrees as the children $f the root, and a frequent item header table.

2. Each node in the i&m'prefix subtree consists of three fields:^ 'item-nume, count and node-link, where item-nume registers which item' this node represents, count registers the number of transactions represented by the portion of the path reaching this rode, and node-link links to the next node in the FP-tree canying the same item-nume, or null if there is none.

3. Each entry in the frequent item header table consists of two fields (1) item-nume and ( 2 )  head of node-link, which points to the first node in the FP-tree carrying the same item-nume.

Definition 11 Given a transaction database TDB and a support threshold 5. Let a be a frequent item in F-list (5).

The a-conditional database, denoted TDBI., is the subset of transactions in TDB containing a, and all the occurrences of infrequent items, item a, and items following a in the F-list (5) are omitted.

Let b be a frequent item in X-conditional database TDBlx.

where X is a frequent itemset. The bX-conditional database, denoted as TDBlbx, is the subset of transactions in TDBlx containing b and all the occurrences of local infrequent items, item b and items following b in F-Sst&) are omitted.

In the following, aiming at a kind of specific cp, namely,  the degree of interest of every item is .given, we present an improving algorithm. It need 'reconstructing FP-tree in  which itemset 'must be sorted by its degree of interest in descending.order. This is because the support of the itemset of less degree of interest is relatively large g d  the support of the itemset of large degree of interest is relatively less.

On the one hand, it wili save some memory for constructing FP-tree, on the other hand, if an itemset is not pfrequent, its corresponding X-conditional database does not need constructing. For convenience, here we suppose Max (cp)=lk.

3 . Algorithm of construction of FP-tree  Following is the algorithm of construction. of FP-tree aiming at the above cp. , Algorithm 1 (FP-tree construction) Input: A transaction database TDB, a minimum support threshold 5 and cp which only, gives the degree of interest for every item.

Method: The FP-tree is constructed in the following steps: 1. Scan the transaction'database TDB once. Collect the  set of frequent items F (its minimum support is ?/Ik) and their supports. Sort F in support descending order as F-list ( V l k )  and Sort F in .degree of interest increasing order as ID-list . (&Ik). Suppose F-list  output: Its FP-tree.

<L,, .I z2, .I ..., i l l ;  i:, i:, ' ' 1 ,  z j j ,  .z . ( V l k ) =  . ' .k I .I ...; $, i:, ..., z j ,  >,where the items: i,, z2. '1.. ilL;  ... ; i : .  i:,  ..., i ; , ( l < t < k )  are the frequent items which support is at least VI,). Let F,-list  <(, i i ,  ..., i! ; (VI,)= A ....

i;, i ; ,  ..., i;; z (1 5 t 5 k ) .

2. Create the root of an FP-tree, T, and label it as "nulP'.

For each transaction Trans in TDB do the following.

Get the degree of interest of T, denoted as 1,. from ID-list (Ej2,). Delete all infrequent items and all the items' following i i ,  in F-list (VIk) from T. And sort . T .., in ,ID-list (U&) item's order as [PIP], where p is the first element and P i s  the remaining list. Call insert-FP-tree (IplP], R).

The function insert-FP-tree ( [plP] , .R)  is performed as follows.

If R has a child N so that N.item-nume=p.item-nume, then increment hrs count by 1; else create a new node N, and let its count be 1, its parent link be linked to R, and its node- link be linked to the nodes with the same item-name via the nbde-link structure. If P is nonempty, call insert-FP-tree (P, h9 recursively.

Remark 1 From the FP-tree instruction process, we can see that it is a little different from the FP-tree in [3], which is that here we construct FP-tree accord to the degree of interest of item. Similar to the proof of correctness of algorithm of constructing FP-tree in [3], the above algorithm is also correct.

Proposition 2 FP-tree reserves all the information for mining cpfrequent itemset.

Proof From its construction, it is obvious.

4 An improving mining algorithm aiming at the above cp  Based on the above FP-tree's construction, we have an improving mining algorithm aiming at the above cp as fOUOWS.

Algorithm 2 (Mining cpfrequent closed itemsets by the FP- tree method) Input: A transaction database TDB, a minimum support threshold 6 and cp which only gives the degree of interest for every item.

Output: The complete set of cp-frequent closed itemsets.

'Method: (I) Initialization. Let FCI be the set of cp-frequent  (2) Find out all frequent items. Scan TDB once, find  (3) Recursively mining cp-frequent closed itemset. Call  Subroutine Gen-cp-CSET (X, DB, F-list (s/ln), ID-list  clbsed itemset initialized as &  out F-List ( u l k )  and obtain ID-list (s/Zh) according to cp;  Gen-cp-CSET (e, TDB, F-list ( u l k ) ,  ID-list (&), FCI).

(E/U, FCI) Parameters:  X if DB is TDB, then X is & if DB is X-conditional database, then X if a frequent itemset;  DB: conditional database; F-list (s/l,,,): Frequent item list in DB, l,,, is the largest  degree of interest of item in DB; ID-list (s/l,,,): Degree of Interest item list in DB; FCI cpfrequent closed itemsets be mined.

Method: (a)Let Y be a set of some cp-frequent items in ID-  list&,/l,,,). where every item all appears in every transaction of DB. If XuY is not a proper subset of an itemset in FCI of the same support, then insert it into FCI;  @)Construct FP-tree of DB; (c)If FP-tree only bas one path, then we can directly  extract cpfrequent closed itemsets from it; (d)For every of the rest items in ID-Iist&&),  construct its conditional database and calculate the local frequent item list of these conditional databases;  (e)For every of the rest i t em in ID-lista(&lm), start at the last one item in ID-list&l,,,). If aX is not a proper subset of an cp-frequent closed itemet be mined of the same support, then recursively call Gen-cp-CSET (aX, DBC. F- list&l,), ID-list&fd, FCI), where DBI. is an a- conditional database with respect to DB, F-list&lm) is its corresponding fresoent item list, ID-liSt.,(s/l,,,) is its corresponding degree of interest item list.

Propositron 3 If X is not cpfresuent, then there does not exist cpfrequent itemset in X-conditional database, namely,  in the mining process, X-conditional database does not need constructing.

Proof Because in the mining process, items of large degree of interest are regarded earlier, all the itemsets in X- conditional database have the same degree of interest and their support is not greater than X. According to the definition of cp-frequent itemset, all the itemsets in X- conditional database are not gfrequent, namely, in the mining process. X-conditional database does not need  Remark 2 Similar to the proof in [3], the above algorithm is also correct.

Example 1 We have the following table 1 to illustrate the above results. Suppose the minimum support ? 9 . 5 ,  the degree of interest of every item in itemset [a, b, c, d, e, f )  is [ 1, 1.5,0.5,2, I, 1) respectively.

According to the above algorithm, the mining process is as follows: (1)Find out F-list (0.32) and ID-list (0.512).

constructing.

Table 1. Transaction database  Items a, c, d, e, f  c. e, f a, c, d, f c, e, f  In this example, F-list (0.5/2)=<~:4, e:4, t 4 ;  a:3, d2>, where item is sorted by the support descending order, the number &er ":" is denoted as its support. According to cp, ID-list (OSn)=<c, a, f, e, d>. The following table 2 is the above transaction database sorted by the ID-list (092) order.

Table 2 Transaction database  c, f, e c, a, f, d c, e, f  (2)Divide search space. In this example, All the cp frequent closed itemsets can he divided into 5 non-overlap subsets based on ID-list (0.5/2).

(a)the ones containing item d; @)the ones containing item e but no d (c)the ones containing item f but no d nor e; (d)s containing item a but nod, e nor E (e)the one containing only c.

(3)Fmd subsets of cpfrequent closed itemsets. The  subsets of cpfrequent closed itemsets can be mined by      Database  TlOl8D1OK TlOIlDlOK TlOI8DlOK T1018D40K T1018D40K T1018D40K  constructing corresponding conditional databases and mine each recursively.

(a)Fmd cpfrequent closed itemsets containing d. Only transactions containing d are needed. The d-conditional database, denoted as TDBld, contains all the transactions having d, which is (cefa:l,cfa:l]. Notice that the item d is omitted in each transaction since it appears in every transaction in the d-conditional database. The support of d is 2. The large degree of interest of item is DI(d)=2. Items c, f and a appear twice respectively in TDBld. Namely, every transaction containing d also contains c, f and a. Moreover e is not pfrequent. Therefore dcfa: 2 is a cp-frequent closed itemsets. Since this item covers every cp-frequent item in TDBld, the mining of TDBld finishes.

@)Find cpfrequent closed itemsets containing e but no d. Similarly, the e-conditional database, TDBI.=(caf:l, a:l, cE2). Item d in such transactions is also omitted. The large degree of interest of item is DI (e)=l. Since there is no any -item appearing in every transaction in TDBI, and the ?p support of e is 4, e: 4 is a cpfrequent closed itemset. To fmd the remaining cpfrequent closed itemsets containing e but no d, we need recursively mine, that is to find the local frequent item list of e-conditional database, F-list (0.5/1)=<~:3, f:3> and Il-list(O.5/l)=<c, b. Since {c, f) appears in every transaction in e-conditional database, we can directly obtain that ecf: 3 is a cpfrequent closed itemset in e-conditional database. The mining of TDBI. finishes.

(c)Find *frequent closed itemsets containing f hut no d nor e. f-conditiond database TDBlf;(ca:2, c:2]. The large degree of interest of item is DI (f)=I. Because c appears in every transaction of TDBlr and fc is not a subset of any cp frquent closed itemset with the same support, fc: 4 is a cp- fkequent closed itemset. Since a is not local cpfrequent. The mining of TDBlr finishes.

(d)Fmd cpfrequent closed itemsets containing a but no d, e nor f. a-conditional database TDBI.=(c:2]. The large degree of interest of item is DI (a)=l. Since c i s  not local cp frequent. The mining of TDBI. finishes.

(e)Find cpfrequent closed itemsets containing only c.

c-conditional database TDBIc=@. The large degree of interest of item is Dl(c)=0.5. Although c appears in every transaction in TDBI,, c:4 is not cp-frequent. The mining of TDBI. finishes.

(4)The set of all the cp-frequent closed itemsets, FCI, is {dcfa:2, e:4, fce:3, fc:4).

