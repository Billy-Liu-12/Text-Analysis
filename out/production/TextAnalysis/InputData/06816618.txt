

Abstract  -   Index Terms

I. INTRODUCTION iven a Landsat panchromatic image as shown in Fig 1, the image size is 14,961 columns and 14,821 rows. The  bit depth is 16 bits or 2 bytes. The file size is 443.6 megabytes. The downlink capacity currently has approximately a 440 Mbps throughput from satellite to ground station using X-band with lossless compression [6]. This results in approximately a 30 second time period to transfer the entire Landsat image. The disk size of the image is calculated as:  14,961 x 14821 pixels * 16 bits/pixel* (1byte/8 bits) = 443,593,728 bytes (1)  The data rate in bytes is calculated as: 440 Mbps =440*220 bits/sec *(1 byte/8bits) =  57,671,680 bytes/sec (2)    The time to transfer this image with the given data rate is: (443,593,728 bytes) / (57,671,680 bytes/sec) =  7.7 seconds (3) This is the time required for just one of the Landsat 8 bands.

The panchromatic band is 4/15 of the total data for all 11 bands plus the quality assessment band. Therefore, the total transfer rate for all bands per image is: 7.7 seconds * 15/4 = 28.9 seconds. If the lossless compression ratio is 90%, then for example the time will be reduced similarly for downlink.

Since Landsat has the capability to collect continuously, the future ability to point and collect data for only the bands required could be more efficient. Many missions require only three bands in order to process the imagery. Our approach is to add computational intelligence to provide the analyst with a decision making capability to reduce the time to collect and process data while retaining the information needed to complete the mission analysis. This is especially important for future sensors with many bands such as the Navy Earth Map Observer with 64 bands and NASA?s EO-1 hyperspectral system. The bandwidth issue becomes important as the sensor resolution increases with future capabilities. Video is another data type which may benefit from a smart decision making capability to handle more bandwidth.

Fig. 1.  Landsat8 Image  A Cognitive Group Hierarchy Game Theoretic Framework for Bandwidth Management Mark Rahmes, Jay Hackett, Kevin Fox, Rick Pemble, George Lemieux, Howard Gans   Harris Corporation,  Government Communications Systems Melbourne, Florida 32904  G     2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)

II. HIERARCHICAL GAME THEORY Hierarchical game theory can be used to solve for the best  strategy for decision making in complex problem solving.

Hierarchical game theory can determine cooperating capacity between groups and detect the best united strategy. It proves that the model can provide an effective way for analyzing the bandwidth. This can provide a powerful method of resource allocation and asset planning in order to maximize a player?s response [9]. Figure 2 shows the hierarchical, game structure for our example. All of these hierarchies are part of the overall player?s capability to compete with other players. The four hierarchies are: bands, sensors, missions, and organizations.

Fig. 2.  Hierarchical Game Structure   We let the objective function be F = (F1, F2) where F1  could be the blue team and F2 could be the red team. We let x1 be the decision maker?s choice for blue and x2 for red. We let h11 to h1m be the lower hierarchical decision maker?s response for blue. The objective function for blue?s lower decision makers is fij. We let S1 be the feasible sets for variable x1. S1 depends on x1 and h11 to hmj. The lower decision maker can modify the upper decision maker's mind according to the actual status [9].

Our example has four organizations, five sensors, seven missions, and eleven bands. We are seeking the best mission use of the sensor based on available assets and bands for optimal organizational use. Figure 3 shows the elements of each hierarchy for our example.

This framework solves for controlling ability in groups and the hierarchical trait in command and control. Thus, to enhance independent decision making in lower decision makers and make decision making between the upper and the lower decision makers not only have clear hierarchies, but also interact and optimize each other. Sequentially, perfect effects can be obtained with a hierarchy model. [9].

The bands determine and greatly contribute to the effectiveness of the Landsat mission. The mission determines which bands to use. The organizations determine the missions.

The missions are to be carried out by the organizations. The sensors are used to carry out the missions. The missions  determine which sensors to use based on a number of factors such as location, capability and availability. Figure 4 shows the hierarchical structure of our example.

Fig. 3.  Hierarchies and Elements   The goal is to maximize the decision function. The overall  performance of the decision is based on several levels of hierarchical decisions. Our example starts with the decision to task assets based on mission and the responsible organization.

For Landsat, there is a wealth of data which exists and is important for change detection. Cooperation between organizations is modeled using multi-player Prisoner?s Dilemma in our solution. The choice of Landsat sensor to use is based on availability. The mission priority is based on real world events. The bands to use are based on the mission. Each level of hierarchy has an impact on the overall ability for blue to compete on a global basis.

Fig. 4.  Hierarchical Structure

III. SELECTING BAND COMBINATION Individual bands can be used to identify different features  on the ground and how these bands can be combined to create useful products. Using this information we can select specific bands from a multispectral satellite image to create color pictures that are specifically tailored to facilitate the identification of the features of interest [7].

With a digital camera the detector inside the camera is recording three different wavelengths (or colors) of light ? the red, green, and blue wavelengths and this information is combined to produce a picture that looks just like a photograph. With a multispectral sensor, such as those aboard the Landsat satellites, information from different wavelengths  2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)     of light is collected as in a digital camera but there are two major differences. The first is that instead of limiting itself to the visible wavelengths (what we can see with the human eye - red, green, and blue) a much broader range of wavelengths are detected. Information is also collected in the infrared and sometimes even the thermal wavelengths [7].

The second major difference is that instead of automatically combining the information from the different wavelengths to form a picture, the information for each specific wavelength range is stored as a separate image. This image is commonly called a band. When viewed, this single band image is similar to a black and white digital photograph. It is up to the image analysts to combine the images from the different wavelengths to create a color image. We can create color images on a computer screen by using red, green, and blue light to illuminate bands 5, 4, and 3 respectively. We can determine which of the bands should be used to make color image and which of the primary light colors should be used to illuminate each band. Determining which of the primary colors should be used to represent a particular band is largely a matter of how the image looks. Another way to represent those same bands is to change the primary light colors that are used to illuminate each band. Since infrared film was popular for monitoring vegetation before advent of digital remote sensing devices there is a tendency to continue simulating this effect [7].

Figure 5 shows several commonly used band combinations with a brief explanation on why it is used [5]. Selecting the appropriate bands to use in the color image on the other hand does have a huge impact on which features can be seen in a particular image. The list below explains some of the features of the seven Landsat Thematic Mapper bands and how they  are tailored for detecting different features [7]: Band 1 (0.45- -green): Since this short  wavelength of light penetrates better than the other bands it is often the band of choice for aquatic ecosystems. It is used to monitor sediment in water, mapping coral reefs, and water depth. This is also the noisiest of the Landsat bands since short wavelength blue light is scattered more than the other bands.

Band 2 (0.52-  band 1 but not as extreme. The band was selected because it matches the wavelength for the green we see for vegetation.

Band 3 (0.63-  nearly all red light (it is sometimes called the chlorophyll absorption band) this band can be useful for distinguishing vegetation and soil and in monitoring vegetation health.

Band 4 (0.76-  nearly all light at this wavelength water bodies appear very dark. This contrasts with bright reflectance for soil and vegetation. It is a good for defining the water/ land interface.

Band 5 (1.55- -infrared): This band is very  sensitive to moisture and is therefore used to monitor vegetation and soil moisture.

Band 6 (10.40-  thermal band, used to measure surface temperature. This is primarily used for geological applications and sometimes used to measure plant heat stress. This is also used to differentiate clouds from bright soils since clouds tend to be very cold.

Band 7 (2.08- -infrared): This band is also used  for vegetation moisture.

One of the best ways to better understand which features  one can see using different band combinations is to experiment to see what works for you [7].

Fig. 5.  Band Combinations [5]  2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)

IV. SENSOR PRIORITY COST FUNCTION Our paper looks at an example of using linear program  game theory to solve for a strategy given a reward matrix for possible actions based upon selected criteria. In many situations, the opponents know the strategy that they are following. We assume that the players know what actions are available. A ?maximin equilibrium" is often the strategy and is called the Nash theory application of zero or constant sum strategy game [14]. We also consider a constant sum game in which for both player?s strategies, the two player?s reward add up to a constant value. This means, while both players are in conflict, that there is more to gain than simply having one player?s reward equaling the other player?s loss. In our example, the red player for this level of hierarchy can be thought of as the consequences of natural disasters.

For example, if a reward matrix exists, then the equilibrium point is the one where the reward is the smallest value in its row and the largest number in its column. This equilibrium point is also called a "saddle point" since it is like the center point in a horse?s saddle. This equilibrium is also known as the Nash Equilibrium [11]. The saddle point is the local minimum in one direction (row) and a local maximum in another direction (column) [14] such as:   max all rows (row min) = min all columns (column max) (4)   This left half of Equation (4) presents the basic applied  theory to decision making of our model under uncertainty. Our model has manpower and an equipment output. For a possible action, one consideration is to choose the ?best? worst outcome [14]. The maximin criterion suggests that the decision maker should choose the alternative which maximizes the minimum payoff he can get. This pessimistic approach implies that the decision maker should expect the worst to happen. The maximin criterion is concerned with making the worst possible outcome as pleasant as possible.

The right half of Equation (4) represents minimax regret criterion which uses the concept of opportunity cost to arrive at a decision. The regret of an outcome is the difference between the value of that outcome and the maximum value of all the possible outcomes. For any action and state, there is opportunity of loss or regret. The decision maker should choose the alternative that minimizes the maximum regret he could suffer. Although these decision making criteria discussed may seem reasonable, many decisions are made without using any analysis [14].

Many games do not have saddle points. It is acceptable to model a player?s choice of strategies with probabilities. A game with a randomized (or mixed) strategy is one in which all of a player?s choices add up to a value of one. A mixed strategy is comprised of possible actions and an associated probability. Any mixed strategy that guarantees an expected reward at least equal to the value of the game is an optimal strategy. A pure strategy is a special case if a randomized strategy exists if any of the choices equals one. In a pure strategy, a player always chooses the same action [14]. Our  example?s possible choices are based on Landsat mission for natural disasters as shown in Fig 6.

Fig. 6.  Reward Matrix   Equation (5) below is used to determine the best strategy for the blue player. Linear programming is useful for solving game theory problems and finding optimal strategies. We can define:  x1 = probability that blue player chooses Earthquake x2 = probability that blue player chooses Volcanic Eruption x3 = probability that blue player chooses Landslide x4 = probability that blue player chooses Tsunami x5 = probability that blue player chooses Desertification x6 = probability that blue player chooses Flood x7 = probability that blue player chooses Hurricane  max v (5) s.t. v -   830 x1 -  92 x2 - 1000 x3 -   0 x4 - 7500 x5 - 1000 x6 - 500 x7 <= 0 v -   0.9 x1 -  1.5 x2 -       0 x3 -   0 x4 -  19.6 x5 -  14.0 x6 -  1.5 x7  <= 0 v -    23 x1 -     3 x2 -     70 x3 - 23 x4 -   100 x5 -       4 x6 -   84 x7  <= 0 v -      0 x1 -     0 x2 -       0 x3 -   0 x4 -     17 x5 -     13 x6 -   70 x7  <= 0  x1 + x2 + x3 + x4 + x5 + x6 + x7 = 1 x1, x2, x3, x4, x5, x6, x7  >= 0   The solution for the blue player?s mixed strategy in terms of probabilities:  = (0, 0, 0, 0, 0.96, 0, 0.04). Based on the parameters of death, damage, and cost, the best choice for blue in our example would be to monitor desertification. This disaster has shown to be the most costly based on available statistical data in our example. This framework is flexible to allow other scenarios to be modeled for optimal decision making.



V. DYNAMIC FAIR DIVISION In our example the sensor may also be considered an  existing database for Landsat 1-5. This is valuable for change detection or battle damage assessment. Figure 7 shows an example structure where S is the sensor and A is the analyst.

For Landsat it is important to note that the data may have been already collected and is stored in a database by the responsible organization.

2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)      Fig. 7.  Sensors, Databases, and Analysts   One issue with our example is modeling asset management  with limited resources for multiple sensor modality requirements. One solution is to run the Shapley [12] and Nash [11] algorithms for each successive tasking request.

However this alone lacks a correlation to available assets.

We next run a dynamic fair division (DFD) algorithm to ensure that each request is fair with respect to limited available assets. The motivation for fairness is used to ensure that not all sensor assets are dominated by one agent or player (region of interest). This is needed in order to not miss important events occurring around the world.

Walsh [13] proposed the problem of fair cake cutting where agents arrive, take a piece of cake, and immediately depart.

The cake cutting setting deals with the allocation of a single, heterogeneous divisible resource; our setting deals with multiple, heterogeneous divisible resources. This permits exploration of the concept of fair division when players arrive and depart during the process of dividing a resource. It can be used to model situations when there is a need to divide resources asynchronously [13]. The indivisible quality of this method that we are concerned with is time of asset use.

We have chosen to model the solution based on fair division rather than dynamic queuing where agent requirements arrive and depart with a solution allocating one sensor per agent in succession [3]. Queuing is an option and is part of the system.

However, we choose to look at resource management using fair division since it has additional benefits of computational intelligence.

Similar to Kash et al. [8], we denote the number of agents with sensor requirements as N = {1,?, n}, and the amount of resources agent i requires as Ri. Our example is different in that we consider some sensors as unlimited while others are limited. The demand Dir is the fraction of resource r required by agent i. However in our example, the value for social media may be considered unlimited, so we always denote social media as having N resources available. Additionally we compute the utility function, with a Shapley value, of an agent as the fraction of its dominant resource that it can actually use.

A trivial solution is simply to allocate resources based on a first come ? first served basis and allocate 1/n shares to each agent. A dynamic allocation mechanism is dynamic envy free (DEF) if at any step an agent i envies an agent j only if j arrived before i did and j has not been allocated any resources since i arrived [8].

Before a sensor modality is tasked, we allow the agent to be able to give the asset back if envied by another agent with a higher requirement, determined by the Shapley marginal contributions shown in Fig 8. Instead of simply allocating  equal shares to all players, we recognize that certain regions of interest (agents, players) demand more assets at a given time due to real world crisis situations. Therefore we propose using the Shapley value as the percentage of resources to be allocated to agents. In our example, the Landsat 8 and Landsat 7 assets are limited while the Landsat 1-5 sensors are considered unlimited since an abundance of images have been collected and have been stored on disk. However, the use of the right sensor at the right time has a higher value. Our solution considers the use of some sensor may be better than none. It depends on the situation.

Figure 8 also shows the values for the Shapley method for calculating probabilities due to marginal contributions [12].

Our implementation of treating each band combination as a player in a game uses the Shapley value as the probability of choosing a band combination based on mission parameters requirements. Our solution currently considers the average of the ten combinations.

Fig. 8.  Shapley Marginal Contributions   We consider a dynamic resource allocation model where  agents arrive at different times and depart similar to Walsh et al. [13]. An agent reports its requirement upon arrival and the demand is accomplished. The requirements do change over time. The water-filling mechanism is a dynamic adaptation of the dominant resource fairness (DRF) mechanism [4].

Figure 9 shows our example of allocation of demands based on the modified water filling algorithm. The agent can demand sensors of all modalities based on priority using Shapley value marginal contributions. The Von Neumann-Morgenstern concept of a utility function can be used as an aid to decision making under uncertainty. A decision maker?s utility function contains information about their attitude toward risk.

Decisions may be risk-averse, risk-neutral, or risk-seeking [14]. Our utility function is as follows:  r (ui (Ai) = max{Dir , Sir }) (6)  where S is the Shapley value marginal contributions. For each modality, the agent is allocated assets for either the maximum of demand or Shapley value. Equation (6) generates a demand vector for each agent and for each modality.

2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)      Fig. 9.  Dynamic Fair Division of Resources   Using the Shapley values, for example, the demand vector  for the blue (Desertification) mission is 0.34. Since blue also has the largest Shapley value, blue gets first priority tasking allocations. The next player?s turn is determined by the Shapley value and so forth. In our example, Flood mission receives sensor assets since it has the next highest value of 0.21. The cycle continues as missions are complete and assets are freed. The procedure allows for envy freeness. An agent can demand a sensor from another agent as long as it is not allocated or tasked yet.

Since the Hurricane mission has a higher Nash value for an optical sensor than Flood (0.04), it takes priority in order to allow for a feedback loop for real world events. Therefore Flood relinquishes its priority for the optical sensor although it had a higher overall average Shapley value. Figure 9 shows the updated water fill queuing diagram. The incorporation of joint Shapley values with Nash values comes into play when the agent requests multiple sensor modalities as requirements.

When this occurs and there is a possible envy situation, the joint Shapley and Nash values are needed.



VI. N-PERSON PRISONER?S DILEMMA GAME Cooperation is less likely to emerge in a large group than  a small group [16]. The value of one-seventh (due to having seven missions in our example) shown in Fig 9 for Landsat 1- 5 are only true if all of the resources on disk are shared. Since our example has seven missions, each mission can ideally have access to all data provided that the images needed to accomplish the mission are available in an existing database.

Otherwise the information may not be available and needs to be collected. This may result in some other important area of interest not being collected.

The iterated Prisoner?s Dilemma (PD) game has been used extensively in the study of cooperative behaviors in social and biological systems. The N player PD game is realistic for modeling the cooperation strategies [16].

Each player has two choices between group cooperation or non-sharing defection. Cooperation may also be thought of as free trade versus protectionism. It is important to recognize  inconsistencies between individual rationality and group rationality. Game theory explains such inconsistencies clearly and simply, which is why it is widely used in various fields of social sciences. The ?prisoner?s dilemma? model represents inconsistencies simply. Hierarchy or multi-level games interact with each other so that each game affects a player at higher or lower levels. Each level of interaction is a strategic game [10]. At each level, one option is to run the Nash equilibria to determine optimal strategy.

However, in the real world, individual rational actions are not always taken. In our example, responsible organizations are given incentives to cooperate so that their action can take a better action in the international game so that the blue player can best compete [10].

Unfortunately, it has been shown both theoretically and in the real world that certain strategies that work well for individuals in the PD model fail in large groups. The non- sharing option is dominant for each player, even though it is preferable to choose to cooperate [16]. CH is important because it predicts the effect of group size which is not predicted by the Nash equilibrium [2].

Results of an open competition are well explained by CH.

In many games it boils down to predicting how deeply other agents in the game will be reasoning. An agent that does not reason enough risks being exploited by its opponents, while an agent that reasons too much may not be able to interact productively with its opponents [15].

In our example, it is more beneficial for all responsible organizations associated with Landsat to share data. We can model the situation as a measure of cooperation (MOC) [16]:   a = [1 + [Nc/N] (2n-3)]/[max(1 + [Nc/N] (2n-3))] (7)   In this equation, Nc is the number of cooperative decisions  made out of N possible decisions. The total number of players is n. This equation generates reward values. In our example we can convert this to a percentage of cooperation and relate it to the amount of Landsat data that can be used for change detection purposes, for example. A lower cooperation level will result in the Landsat 8 sensor needing more tasking or simply failure to accomplish the mission since a historic database is necessary for many applications.

If one of the player?s representing a responsible organization receives cooperation from another responsible organization, this results in a higher overall value for the blue player and allows for better international competitiveness.

This level of cooperation in the hierarchy of responsible organizations is very important and can be modeled using equation (7). This value affects the blue player?s effectiveness as well as lower level hierarchies such as repeating missions and using assets at the expense of other tasking. Yao et al.

showed that for a four player prisoner?s dilemma with a history of two decisions, a 95 percent cooperation level occurs 80 percent of the time [16].

Over a long period of time with many players, each with different strategies, greedy strategies tend to do very poorly in the long run while more cooperating strategies do better, as  2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)     judged purely by self-interest. When the opponent defects, on the next decision, the player sometimes cooperates anyway.

The successful strategy must not be a blind optimist. It must sometimes retaliate. Though players will retaliate, they will once again fall back to cooperating if the opponent does not continue to defect. This stops long runs of revenge and counter-revenge. The last quality is being non-envious, that is not striving to score more than opponent [1].

We can model our CH example using a powerful tool called analytic hierarchy process (AHP). AHP can be used to make decisions in situations involving multiple objectives. The AHP method uses a weight with each attribute. A higher weight indicates a more important objective [14]. An extension of the Von Neumann-Morgenstern utility can be used to make decision under uncertainty where more than one attribute affects blue?s preference and attitude toward risk. In order for blue to check on the consistency of the CH model, we show our example with a consistency check. We present an example using multiattribute utility function in order to show the repeatability of hierarchy level function to create consistent products most useful for the blue player where each attribute is not mutually independent but rather depends on the other.

We compute the consistency index (CI) as follows [14]:   CI = [(        )-n] / (n-1) (8)   where A T is a matrix based on the blue player?s levels of hierarchy as discussed in this paper. The values in the A matrix and the weights in the w vector are based on bands, missions, assets, and organizations using Shapley, Nash, DFD, and the MOC respectively. CI can be used to monitor which three band combinations are used for a given mission such that the consistency of mapping products are monitored.

For a perfectly consistent decision maker, CI will be equal to zero. If CI is sufficiently small, the decision maker?s comparisons are probably consistent enough to give useful estimates of the weights. In our example, if the value of CI is too large, then the blue player can make some adjustments amongst the responsible organizations in order to improve competitiveness on an international level. The goal of the blue player is to manage bandwidth at the lowest level, create the most consistent products using the most efficient missions, while ensuring the lower level responsible organizations are cooperating effectively.



VII. CONCLUSION Our approach is to add computational intelligence to  provide the analyst with a decision making capability to reduce time to collect and process data while retaining the information needed to complete the mission analysis.

Since asset tasking has dynamic, discrete, strong opposition, and hierarchical traits, decision making becomes more and more complex. It is difficult to analyze and resolve. In the presence of game theory and hierarchical theory, and on the  basis of dynamic state attrition-models, our strategy can solve this kind of problem favorably.

We discussed a method for modeling asset management with limited resources for multiple sensor modality requirements. One solution is to run the Shapley and Nash algorithms for each successive tasking request and then run a dynamic fair division algorithm to ensure that each request is fair with respect to limited available assets. The motivation for fairness is used to ensure that not all sensor assets are dominated by one agent or player (region of interest). This is needed in order to avoid missing sensing of important events that are occurring around the world. We realize that the solution presented is only a guide and is not intended to replace the human brain in decision making. We offer a user assisted means of prioritization to make agent and resources more effective.

We used the NPD to model group behavior and cooperation. We provided a real world application to present a framework for bandwidth management of remotely sensed data. This may be useful for generating semi-autonomous decision making tools to the analyst in order to increase the effectiveness of limited resources.

