PARALLEL MINING ASSOCIATION RULES WITH BIT STRING ARRAY IN  LARGE DATABASE

Abstract: Association rule mining is one of the important data  mining tasks. However, the previously proposed methods still encounter some problems, such as complex data structure, candidate set generation, and so on. To improve efficiency, association rules can be mined in parallel. In this paper, we use a simpler data structure called bit string array and propose a new approach to apply parallel projection and compress technique in parallel mining association rules. It conducts various operations on bit string array according to the frequency of frequent items. For frequent item with less frequency, we conduct set operation on them; for frequent item with more frequency, we adopt compress technique and conduct bit AND operator on them. Moreover, it will reduce the communication cost and also response time. This method can be scaled up to very large databases by parallel projection and compress technique.

Keywords:  Array Association Rule Mining; Parallel Mining; Bit String  1 Introduct ion  Data mining, an important step in this process of knowledge discovery, consists of methods that discover interesting, non-trivial, and useful patterns hidden in the data. Association rule mining is one of the important problems of data mining. Developing efficient frequent itemsets mining techniques has been an important research direction in data mining.

Various algorithms are proposed for frequent itemsets generation. Apriori[ 11 and DHP[2] are the most two important ones. The key idea of Apriori algorithm  lies in the "downward-closed" property of support. It means if an itemset has minimum support, then all its subsets also have minimum support, so any subset of frequent of itemset must also be frequent. The candidate itemsets having k items can be generated by joining frequent itemsets having k-1 items, and deleting those that contain any subset that is not frequent. DHP algorithm is an extension of Apriori using a hashing technique. They may need to generate a huge number of candidate itemsets and repeatedly scan the database and check a large set of candidates by pattern matching.

Recently, pattern-growth methods, such as FP-growthC41, TreeProjection[3] and FPL[6], have been proposed. A pattern-growth method uses the Apriori property.

However, instead of generating candidates itemsets, it recursively partitions the databases into sub-databases according to the frequent patterns found and searches for local frequent patterns to assemble longer global ones.

Since their data structures are complex, when the database is large, they are sometimes unrealistic to construct a main memory-based FP-tree, and so on.

The huge size of the available database and their high-dimensionality make large-scale data mining applications computationally very demanding, to an extent that high-performance parallel computing is fast becoming an essential component of the solution.

Moreover, the quality of the data mining results often depends directly on the amount of computing resources available. In fact, data mining applications are poised to become the dominant consumers of supercomputing in the near future. There is a necessity to develop effective parallel algorithms for various data mining techniques.

Some parallel association rule mining algorithms are proposed [7], Count Distribution and Data Distribution  0-7803-7865-2/03/$17.00 02003 IEEE 1 a3  mailto:mxpt@public.cc.jl.cn mailto:hydqqi283@163.com   c  are two of them. However, the communication cost will be increased obviously when the number of processors is increased. Also the communication cost will be increased when the processors are in the wide-area network instead of local-area work.

In this paper, we use a simpler and more straightforward data structure, bit string array, and propose a new approach to apply parallel projection and compress technique in parallel mining association rules.

It conducts various operations on bit strings according to the frequency of frequent items. For frequent item with less frequency, we conduct set operation on them; for frequent item with more frequency, we adopt compress technique and conduct bit AND operator on them.

Moreover, it will reduce the communication cost and also the response time. This method can be scaled up to very large databases by parallel projection and compress technique.

The rest of the paper is organized as follows. In Section 2, we review some basic concepts and describe the construction of bit string array. In Section 3 details the algorithm for parallel mining association rules based on the array and set. Discussion is given in Section 4.

Finally we give the conclusion in Section 5 .

2 Bit string array construction  In this section, we mainly construct bit string and array. Before going into the details, let?s describe the problem as follows.

2.1 Problem Description  Let I={i, ,..., i ,  be a set of items. Let TDB be a set of transactions, where each transaction T is a set of items such that T C I. Associated with each transaction is a unique identifier, called its TID. We say that a transaction T contains X, a set of some items in I, if X C T. An association rule is an implication of the form X = Y ,  where X C I ,  Y C I ,  and X n Y = 0  . The rule X 3 Y holds in the transaction set TDB with confidence c if c% of transactions in TDB that contain X also contains Y. The rule X * Y has support s in the transaction set TDB if s% of transactions in TDB contains X U  Y.

The problem of frequent mining is to find the complete set of frequent itemsets in a given transaction database with respect to a given support threshold.

2.2 Algorithm for bit string array construction  In this section, we describe the procedures to construct bit string array. Our general idea is illustrated in the following example.

Example 1: Let the transaction database, TDB, be the first two columns of Table 1 and the minimum support threshold be 2 (i.e., min sup = 2).

Table 1. A transaction database  a, c, d, e  IT4 I a, c, d, h I a, c, d 1 1. The first scan of the database is the same as  Apriori, which derives the set of frequent items (1-itemsets) and their support counts (frequencies). The set of frequent items is sorted in the order of descending frequency. Therefore, we conclude ordered frequent items satisfied the minimum threshold are: d, a, c, e, g.

Meanwhile, we store natural number 1,2,3,4,5 into the frequent items of count respectively, store -1 into other infrequent count array. For convenience of later discussions, the frequent items in each transaction are listed in this ordering in the rightmost column of Table 1 .

2. For each transaction T in TDB, do the following: 1) Select and sort the frequent items according to  the order in the array.

2) Traverse the array and compare the items in the  array with the items in T. A bit string is formed from left to right to indicate the existence and absence of frequent items in T as follows: If there is a corresponding item in T, set the bit to l;othenvise, set it to 0. When all the frequent items in T are examined, a transaction will turn into a bit string and be stored in its corresponding array.

We employ parallel projection for database projection. Parallel projection is implemented as follows: Scan the database to be projected once. For each transaction T in the database, for each frequent item I in T, project T to the I-projected database based on the transaction projection rule, specified in the definition of projected database. We use arrays to store these results.

This process is illustrated in Table 2.

Table 2. The complete construction of array from table 1      A[4] A[5]  A[2] I 11,11,11 A[3] I 101,111,011  101 1,111 1,1101 101 11,1101 1  smaller, which we conduct more easily.

3 Parallel mining frequent patterns with bit string array  From the structure of bit sting array, we conclude  All the transactions contained the same frequent item belong to the same partition and all the bit strings of the transactions have the same length.

2. Since the bit string array is built in descending order of item frequencies, transactions containing less frequent items will have longer bit strings. But the number of these transactions must be small, since the rightmost items contained in these transactions are less frequent items with smaller support count.

3. Transactions containing more frequent items will have shorter bit strings. Although the number of these transactions must be large, they will not consume much memory because of the short lengths of their bit strings.

If there are a huge number of frequent items while  each transaction has only several items, transactions containing less frequent items will have longer bit strings. Therefore, we adopt set operation to handle these cases. Let the number of frequent items be N, the average size of each transaction be ITJ, if JTJ << N, we use sets to store the transactions containing the frequent item with less frequency, instead of converting them into bit strings.

Since the items in the frequent item sets are ordered in the support-descending order, more frequent items will have shorter bit strings. Therefore, their corresponding arrays will have a number of same bit strings. For example, in A[2], there have three bit strings, but they are identical. So we can adopt a compress technique to store these bit strings. Let the length of frequent pattern containing frequent item i be I ,  we will generate only 2 (not 2 ) various frequent patterns containing item i, because we require the end of frequent patterns containing 'item i. Suppose the frequent item in bit strings has support s, that is, its corresponding array  has s bit strings. If 2 << s, we can employ two one-dimension arrays, one containing only 2 bit strings to store s bit strings, another to store the counts of the same bit strings. Thus, the size of the array will be  the following properties (in FPL[6]): 1.

1-1 I  1-1  /-I  After constructing bit string array, the remaining of the mining can be performed on the array only, without referencing any information in the original database.

Then we are able to discover frequent patterns by performing simple operations on them. For this purpose, we devise a parallel mining algorithm, PMAR, which can generate frequent patterns in a very straightforward way. A simple example is also given to illustrate the complete mining process.

Bit counting: for each bit position, count the number of I-bits.

For frequent item with smallest frequency, g, A[5] have two bit strings. We conduct bit counting on all bit positions other than the least significant bit (LSB) position. Ignore the bit positions whose bit counts are below the minimum support threshold. Figure 1 shows the details for the example.

Figure 1. The result of bit counting on A[5]  The items whose bit counts are equal to the count of item g are d, e. We use a set P for storing these items.

Generate patterns by enumeration of all the combinations of P, and combine together with item g.

The final pattern generated: (g:2), (dg:2), (eg:2), (deg:2).

The search for frequent patterns associated with item g completes.

Then find patterns associated with item e. Figure 2 shows the details for A[4].

Figure 2. The result of bit counting on A141       The item whose bit counts are equal to the count of item e is d. We still use a set P for storing this item and also find the items: a, c whose bit counts are not equal to the count of item e, but are high the minimum support threshold. We employ a set Q for storing these items.

We must check whether the combinations of these items.

are frequent. The above method can be recursively used for mining them.

The complete set of the frequent pattems in A[4] consists of the following three portions:  1.The set of frequent patterns generated from P by enumeration of all the combinations of the items combined with item e together: (de:3).

2. The set of frequent patterns generated from Q combined with item e together: (ae:2),(ce:2).

3. The set of frequent patterns combining P and Q formed by taken the cross-product of the frequent patterns generated from P and Q, denoted as fieq-pattern-set(P) x freq-pattern-set(Q), that is, each frequent item set is the union of one frequent item from P and one from Q and its support is the minimum one between the supports of the two itemsets. Thus, the complete set of frequent patterns generated by combining the results of P and Q will be fieq-pattern-set(Q) x freq-pattern-set(P), with the support being the support of the itemset in Q (which is always no more than the support of the itemset from P).

The final pattern combined with item e generated: (dae:2), (dce:2).

Similarly, the mining goes on. It is easy to see that the above mining process finds the complete set of frequent pattems without duplication.

As the database size becomes larger and larger, in order to improve efficiency, association rules can be mined in parallel. From the algorithm and its reasoning, one can see that the construction process is a divide-and-conquer process, which can use parallel processing method.

1. For frequent items with less frequency, we use sets to store the transactions containing the frequent item with less frequency, instead of converting them into bit strings. Then, we conduct set operations on the sets. The framework of the mining process is similar to that of the above. First, employ count arrays to check each frequent item in each set and find their support counts; next, conduct set operations on the sets to find whether the combinations of frequent items are frequent; finally, generate all frequent patterns.

2. For frequent item with more frequency, adopt compress technique and conduct bit AND operator on them. For example, suppose the size of frequent pattern containing frequent item a in large database is 1000, let the length 3, then we need a one-dimension array bsa[4] to store 4 bit strings:001,011,101,111, another to store 4 counts: 200,100,400,300. We do not need large array to store more bit strings. Thus, we do not need recursively call the above method.

Note that our partition employ parallel projection  for database projection, each partition is mined respectively. The idea of Algorithm PMAR is that the main processor sends the bit string array to every processor. All processors can perform functions to calculate the global count or global frequent itemsets and send the result to the main processor. Any two processors do not communicate with each other. This will reduce the communication cost and also the response time. It?s particularly useful in mining association rules over wide-area networks.

The general idea of algorithm PMAR is shown in the above example. We give a formal presentation of PMAR.

The main processor performs functions as follow:  Begin F=find-frequent-1 -itemsets(D); L= Sort(F);/* Sort F in support descending order*/ for(j=l ;j<N;j++) do begin /*N: the size of database D*/ for each transaction T do begin if exist item i in L then {bit[i]=l;} else bit[i]=O; Bitstringlj]= U bit[i]; end C=C U Bitstringlj]; end Send the bit string array to other processor; Receive the result;  End  Other processors performs functions as follow:  /* Generate Frequent Patterns*/ Begin  Receive the bit string array; Bit Counting; If the count of item i in array are equal to  the count of the least frequency item IJi     P=PU { i } ; LL= L1 - P;  If the count of item i in LL more than min-sup {Q=Qu {i};  frequent;  Check whether the combinations of Q are  /* output the complete set of frequent patterns */ Generate pattems from freq-pattern-set(P) with  Generate pattems from freq-pattem-set(Q) with  Generate pattems from freq-pattem-set(P) x  item lfi;  item lfi;  freq-pattem-set(Q) with item lfi; Send the result to the main processor.

End  4 Discussions  Comparing with other frequent pattern mining methods, the efficiency of BSA-mine comes from the following aspects.

First, algorithm PMAR does not generate candidate itemsets, test them or store any frequent patterns in memory. It adopts a frequent-pattern growth method. Therefore, it avoids to costly handle a huge number of candidate sets. Once a frequent pattern is generated, it is output to disk directly. In contrast, the candidate- generation-and-test method has to save and use the frequent pattems found in the k-th round to generate candidates for the (k+l)-th round.

Second, PMAR uses a simpler and more straightforward data structure, bit string and array. It avoids the pointer operation and the complex data structure constructing and requires only a limit space.

Unlike other frequent pattern growth methods, such as FP-tree, it does not need to physically construct memory structures of projected database. It fully utilizes the information well stored in the array. Moreover, for frequent item with less frequency, we conduct set operation on them; for frequent item with more frequency, we adopt compress technique and conduct bit AND operator on them.

Third, since any two processors do not communicate with each other, this will reduce the communication cost and also the response time. It?s particularly useful in mining association rules over wide-area networks.

5 Conclusions  In this paper we used a simple data structure, bit string array, for store information about frequent patterns and developed a new mining algorithm PMAR.

We also adopted compress technique to reduce the size of the original database. Since algorithm PMAR represents a new, highly efficient and scalable mining method, which may have strong impact in the future development of efficient and scalable data mining methods, it can be applied to other applications like the mining of Web, Text and so on.

