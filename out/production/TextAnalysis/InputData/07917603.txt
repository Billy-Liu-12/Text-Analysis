Daily Living Activity Recognition with ECHONET Lite Appliances and Motion Sensors

Abstract?Recently, IoT (Internet of Things) technologies have been attracting increasing attention. Among many applications of IoT, homes can be the most promising target. One of the purposes to deploy IoT in homes is automatic recognition of activities of daily living (ADLs). It is expected that ADL recognition in homes enables many new services such as elderly people monitoring and low energy appliance control. In existing studies on ADL recognition, however, it is hard to build a system to acquire data for ADL recognition in terms of installation cost. In this paper, we propose a method that reduces costs of the ADL recognition system by using ECHONET Lite-ready appliances which are expected to be widely spread in the future.

ECHONET Lite is a communication protocol for control and sensor networks in smart-homes and standardized as ISO/IEC- 4-3. The proposed method utilizes information (e.g., on/off state) from appliances and motion sensors attached to them as features and recognizes ADLs through machine learning. To evaluate the proposed method, we collected data in our smart-home testbed while several participants are living there. As a result, the proposed method achieved about 68% classification accuracy for 9 different activities.



I. INTRODUCTION  Gartner?s 2015 Hype Cycle 1 shows that Internet of Things (IoT) has been attracting the highest attention among many advanced technologies. Moreover, real-time service creation and provision from data produced by massive IoT devices is highly expected [1]. Among many applications of IoT, homes can be the most attractive target. The purpose of deploying IoT devices in homes are realizing new services such as low energy appliance control [2], [3] and recognition of activities of daily living (ADL) [4], [10] for life support such as elderly monitoring. Ueda et al. proposed a system for recognizing 10 different ADLs including cooking and eating by using resident?s position and appliances? power consumption data [4]. However, Ueda?s system requires position sensors and power meters for ADL recognition, so it takes high costs to build the system.

In this paper, aiming to reduce the cost, we propose a new ADL recognition system using information obtained from ECHONET Lite-ready appliances (instead of power consump- tion data of appliances) and information from motion sensors attached to appliances (instead of position data).

ECHONET Lite is a communication protocol for the control and the sensor network of IoT devices (appliances) in a  1http://www.gartner.com/newsroom/id/3114217 (accessed, Nov. 22, 2016)  smart-home. It has been standardized as ISO/IEC-4-3. Many appliance manufacturers are developing ECHONET Lite-ready products and introducing them into the market. Utilization of ECHONET Lite-ready appliances can reduce the overall cost to construct an ADL recognition system because power meters are no longer needed to collect information on appliances status that are required for ADL recognition. To realize ADL recognition system using ECHONET Lite-ready appliances, however, we need to solve the following problems.

1) Types of available appliances are limited because only some types of appliances are currently ECHONET Lite- ready.

2) Even for the same type of appliances, properties that can be obtained from them are different depending on their manufacturer.

In this paper, we target eight types of ECHONET Lite- compatible appliances (air conditioner, ceiling light, fridge, IH cooking heater, air purifier, PC, and vacuum)2 that are expected to be widespread in the future, and propose an ADL recognition method using machine learning for properties obtained from those appliances. To cope with the above problems, the proposed method uses the following ECHONET Lite properties as features for machine learning: (1) ON/OFF state for air conditioner, ceiling light, IH cooking heater, TV, PC, and vacuum, (2) OPEN/CLOSE actions for fridge, and (3) dirt level in the air for air purifier, that can be obtained from appliances of any manufacturers.

Recently, appliances with motion sensors like a TV and an IH cooking heater that are automatically turned off when human is not present nearby begin to spread. Assuming that motion sensors will be attached to most ECHONET Lite-ready appliances in the future, the proposed method also uses the information from motion sensors attached to five types of appliances (ceiling light, fridge, IH cooking heater, TV, and washer) as features for machine learning. Since the proposed method uses only ECHONET Lite-ready appliances and mo- tion sensors attached to them and the expensive positioning system is not required, the installation cost will be reasonable.

We conducted an experiment in our smart-home testbed consisting of a living room, a kitchen, a bath, a bed room,  2PC and vacuum are not ECHONET Lite-ready, so we attached power meters to them so that ON/OFF state can be obtained through ECHONET Lite protocol.

First International Workshop on Mobile and Pervasive Internet of Things'17     etc. where four participants spent daily lives for two or three days each and collected data of appliances as well as data from motion sensors for the total of 14 days during the experiment.

Then, we constructed a random forest classifier with the data labeled with 9 different activities. After selecting important features, our proposed method achieved 68% accuracy in classification.



II. RELATED WORK In this section, first we provide a brief survey of existing  work on ADL recognition and then clarify unsolved problems in ADL recognition.

In order to realize smart-home services like elderly and/or young kids monitoring and energy-saving appliance control, ADL recognition is necessary. The following five problems need to be solved to realize the ADL recognition.

1) Invasion of privacy in case of using high privacy-invasive devices like camera and microphone.

2) Small number of recognizable activity types 3) Low recognition accuracy 4) High cost for installation and maintenance 5) Long recognition time Although activity recognition methods that use fixed cam-  eras [5], [6] achieve high accuracy, the problem 1) can not be solved. Methods that use wearable sensors [7], [8] already achieved high accuracy for simple actions such as walking and sitting. However, since these studies are incapable of recog- nizing complex living activities (e.g., cleaning), the problem 2) can not be solved. Chen et al. [9] designed a system for recognizing complex living activities that use contact, motion, tilt and pressure sensors. However, this method does not solve the problem 4).

As a method to solve these problems, Ueda et al. [4] proposed an ADL recognition method by using indoor po- sition sensors attached to users and power meters attached to appliances. By using these less privacy-invasive sensors, Ueda?s method coped with the problem 1). This method also solved the problems 2) and 3) to some extent because the number of recognizable activity types is 10, and the average accuracy is 91.3%. However, the problem 4) was not solved because Ueda?s method uses expensive positioning system ?SmartCoordinator R?? of NEC Engineering, Ltd. to obtain user?s position data. The problem 5) was not solved too because Ueda?s method uses 30 seconds to 5 minute time window for ADL recognition.

Unlike existing studies, our proposed method in this paper tries to realize a novel ADL recognition system solving all the above problems 1) ? 5) using the information from ECHONET Lite-ready appliances and motion sensors attached on the appliances instead of the position information and power consumption information. ECHONET Lite, which is expected to be widespread, allows us to get various information from ap- pliances without introducing an additional sensors like power meters. Also, motion sensors attached to appliances can help us to obtain the user?s position information without deploying the expensive indoor positioning system. In addition, we can solve the problem 5) because our proposed system can  Fig. 1: Floor plan of smart-home and the layout of furniture and appliances (top: days 1?9, bottom: days 10?14)  obtain the property information from ECHONET Lite-ready appliances every second.



III. SMART-HOME TESTBED A. Overview of Smart-home  We use the smart-home testbed deployed in Nara Institute of Science and Technology (NAIST) as the experimental facility.

Fig. 1 shows the floor plan of the smart-home and the layout of furniture and appliances. We conducted an experiment to acquire ADL data for 14 days in the smart-home. Here, note that the furniture/appliance layouts was changed between days 1?9 and days 10?14 (for adaptability testing purpose).

The filled areas show ECHONET Lite-ready appliances and the areas surrounded by dashed line show ceiling lights. At the positions with stars motion sensors are attached (on the ceiling).

B. ECHONET Lite-Ready Appliances To obtain appliance information, we installed ECHONET  Lite-ready appliances in smart-home testbed. Fig. 1 shows the installation position of each appliance and Table I shows the list of ECHONET Lite-ready appliances installed.



IV. DATA COLLECTION SYSTEM FOR ADL RECOGNITION We built a data collection system that collects the data  such as the property information from ECHONET Lite-ready appliances and the label information of ADLs. Three kinds of  First International Workshop on Mobile and Pervasive Internet of Things'17    TABLE I: List of ECHONET Lite-ready appliances installed  appliances room model number air conditioner living room MSZ-ZXV255-W air conditioner bed room MSZ-ZXV225-W  ceiling light living room LEDH82718XLC-LT3 ceiling light bed room LEDH81510NLC-LT4  fridge kitchen MR-JX48LY IH cooking heater kitchen CS-T34VS  TV living room LCD-40ML7 air purifier living room KI-EX-100  Fig. 2: Overview of our proposed system  data consisting of the appliance property, the motion sensor information, and the activity label are collected by two sub- systems: (1) appliance property information collection system and (2) motion sensor information and activity label collection system.

Fig. 2 shows the overview of our data collection systems.

The appliance property information collection system is com- posed of ?Appliances,? ?HEMS-GW,? and ?PC for ECHONET Lite.? These devices can communicate with each other using ECHONET Lite Protocol. The motion sensor information and activity label collection system is composed of ?motion sen- sor,? ?button for activity labeling,? and ?PC for EnOcean.? The first two devices send information to the PC using EnOcean Protocol3. Detail of data collection methods are shown below.

Collection of appliance properties: The appliance property information is obtained by sending a ECHONET Lite com- mand from the PC to each appliance through the HEMS-GW.

The PC periodically sends the command to appliances one by one, and the PC that received the property information from each appliance stores the information on the local storage.

Table II shows a list of the property information. Basically, ON/OFF information is collected from each appliance. How- ever, since the fridge and the air purifier are always on, we collect the property information ?the doors is open or not? from the fridge and ?the air is dirty or not? from the air purifier.

Collection of motion sensor information: The motion sen- sor information is collected from 10 sensors attached to 5  3http://www.enocean.com/  TABLE II: List of the property information  name property detail of property air conditioner power condition ON/OFF  ceiling light power condition ON/OFF IH cooking heater power condition ON/OFF  TV power condition ON/OFF fridge door condition OPEN/CLOSE  air purifier air condition DIRTY/CLEAN  Fig. 3: Circuit diagram of motion sensor  types of appliances (fridge, IH cooking heater, TV, washing machine, and 6 ceiling lights). Fig. 3 shows the circuit dia- gram of the motion sensor we developed. The motion sensor responds to a person who moved in front of it and transmits the information using EnOcean Protocol. Because it was not possible to attach the sensor to the ceiling lights directly, 6 sensors were directly attached to the ceiling as shown in Fig.

1.

Collection of activity label: The activity label of partici- pants is collected using ?Push button transmission module, PTM 210J? made by ROHM Semiconductor and the activity labeling application (software) we developed. Table III shows a list of activity labels. During the data collection experiment, we asked each participant to press the button when a new activity starts and ends. The PC for EnOcean receives a packet and records the timestamp whenever the button is pressed, via EnOcean protocol. The activity labeling appli- cation supports the labeling task by searching the position in videos corresponding to the timestamp recorded by using the button and play back the videos for confirmation of activities.

What user needs is only specifying the recorded timestamp, confirming the actual activity by watching the video, and selecting appropriate one from the list of activity labels. The data of activity labels are collected from participants using this application after the experiment. As a result of using this application, participants? labor for labeling task was much reduced.

TABLE III: List of activity labels  no label cleaning go out eating smartphone reading PC washing  TV bath cleaning cooking washing face dishwashing bath games sleep  First International Workshop on Mobile and Pervasive Internet of Things'17

V. ADL RECOGNITION EXPERIMENT A. Target Space and Target Participants  We collected property information from ECHONET Lite- ready appliances, motion sensor information, and activity labels while five participants (three males in twenties, two females in twenties) are living in the smart-home for two or three days each in August 2016. As shown in Fig. 1, data collection was carried out in different furniture layouts on days 1?9 and days 10?14. Also, in order to use the activity labeling application, we installed video cameras at three positions shown in Fig. 1 and recorded appearance of life during the experiment. The recorded videos for each participant were managed only by the participant, taking account of privacy.

B. Instructions to participants To obtain good data, we asked the following to the partici-  pants.

? always carry an activity labeling button and press the  button at the start or end of each activity ? carry out 16 types of activities shown in Table III (target  activities) at least once a day ? carry out target activities (other than sleeping) more than  3 hours a day ? stay in the smart-home (including sleeping) for more than  10 hours a day After the experiment, we also asked the participants to label  with a corresponding activity based on the time stamps and video data using our application.

C. Data processing The features for machine learning for ADL recognition are  created by processing data obtained in the experiments. We divided the collected sensor data with labels into samples of 10 second time window. The following features are created for each sample: ?activity label information,? ?ECHONET Lite-ready appliances property information,? ?ON/OFF state information from not ECHONET Lite-ready appliances,? and ?motion sensors information.? The data processing methods for creating each feature are shown below.

Activity label information: We reclassify 16 types of activ- ity labels shown in Table III to 9 activities for better ADL recognition accuracy. Bath and bath cleaning were integrated to ?bath-related,? and TV and games to ?TV-related? because those activities are hard to distinguish from ECHONET Lite properties. Short-term (less than 1 hour) go out was defined as ?short go out? and long-term (more than one hour) go out as ?long go out.? The activity (other than TV or games) while turning on the television were integrated to ?with TV.? No label, eating, smartphone, reading, washing, washing face, dish washing, and short go out were integrated to ?other? because these activities are hard to recognize by ECHONET Lite appliances. Also, we removed samples containing multiple activity labels.

We believe that the reclassified nine activities are still sufficient for smart-home services like elderly monitoring compared to the room level activities recognition [11] and seven different activities recognition [12].

ECHONET Lite-ready appliance property information: Property information from air conditioner, ceiling lights, IH cooking heater, and TV were converted to 1 if the power is on and 0 if the power is off. For the fridge, it was converted to 1 for 30 seconds after opening or closing the door, and to 0 for other time. For the air purifier, it is converted to 1 if air contamination is being detected, and to 0 for other cases.

Additionally, for three appliances (ceiling lights in the changing room, PC, and vacuum) that are not ECHONET Lite- ready, we obtained their property information using Bluetooth Watt Checker REX-BTWATTCH1 made by RATOC Systems, Inc. Since those appliances are expected to become ECONET Lite-ready in the future, power ON/OFF information is added as a features for machine learning. If the power consumption value is 10W or more, it is converted to 1 (power ON), otherwise to 0 (power OFF).

Since each sample has 10 second interval, if the sample has 1 for 5 seconds or more, 1 is used as the feature of the sample, otherwise 0.

Motion sensor information: The information from motion sensors attached to the five types of appliances (ceiling light, fridge, IH cooking heater, TV, and washer) is 1 (human detected) or 0 (not detected). Since the motion sensor does not respond while the human is not moving, data from a particular sensor will be 0 during activities without big movement, such as watching TV and sleeping. Therefore, if we use the motion sensor data as is, the classification tree for ADL recognition is not successfully generated by machine learning. Thus, we modify the data from each motion sensor so that consecutive 0s within one minute betwwen 1s are converted to 1 (we assume that once user moves to other place, he/she will not come back to the same place within one minute).

This feature for each sample is determined as follows: if 1 is contained for 5 or more seconds then 1, otherwise 0.

Also, ?short/long go out? and ?sleeping? cannot be distin- guished because motion sensors data will all 0. In order to distinguish such activities, the last responded sensor ID among the six motion sensors attached to the ceiling lights was added as a feature for machine learning.



VI. EVALUATION A. Analysis methods  We applied machine learning for training samples with features obtained by data processing. We used Random Forests for learning. For evaluation, we used leave-one-day-out cross validation in which among 14 days data, one day is used as the test data and the remaining 13 days data as the training data and results of 14 different combinations are averaged. The fea- tures used as explanatory variables are classified roughly into following two categories; ?ECHONET Lite-ready appliances and non-ready appliances (below, ECHO) property informa- tion? and ?motion sensor information (below, motion).? In the beginning, we analyzed the data by two patterns ?only ECHO? and ?ECHO + motion? to investigate the effectiveness of each category of features. Next, to investigate the influence due to the change of furniture/appliance layout, we analyzed the data by two patterns ?normal (days 1?9)? and ?layout-change  First International Workshop on Mobile and Pervasive Internet of Things'17    TABLE IV: Features and Gini importance  features Gini importance TV ON/OFF 5005  motion sensor attached to IH information 894 ceiling light in bath room ON/OFF 832  last responded sensor ID 616 air conditioner in living room ON/OFF 580 motion sensor in kitchen information 550  PC ON/OFF 465 ceiling light in living room ON/OFF 406  motion sensor attached to TV information 379 motion sensor attached to fridge information 339  air conditioner in bed room ON/OFF 268 air purifier DIRTY/CLEAN 250 IH cooking heater ON/OFF 240  motion sensor in living room information 224 motion sensor attached to washing machine information 221  ceiling light in bed room ON/OFF 131 cleaner ON/OFF 80  motion sensor in bed room (window side) information 36 motion sensor in changing room information 36  fridge door OPEN/CLOSE 32 motion sensor in bed room (corridor side) information 31  motion sensor in entrance information 4  (days 10?14).? Finally, to investigate possible cost reduction (e.g., reducing the number of sensors/appliances), we analyzed the data by two additional patterns: ?use all features? and ?use only features with Gini importance[13] 200 or more.?  Overall, there are four analysis patterns of ?only ECHO,? ?ECHO + motion,? ?ECHO + motion + layout-change,? and ?ECHO + motion + layout-change (Gini reduction).? In the pattern without ?layout-change,? we analyzed using the data before the furniture/appliance layout change. Also, in the pattern with ?layout-change,? we analyzed using the data including after the layout change. Moreover, in the pattern without ?Gini reduction,? we analyzed the data using all the features. Also, in the pattern with ?Gini reduction,? we analyzed using features deleted from the Gini importance of 200 or less. Here, Table IV shows all features and Gini importance.

B. Results of ADL recognition The results of ADL recognition in 4 patterns (only ECHO,  ECHO + motion, ECHO + motion + layout-change, and ECHO + motion + layout-change (Gini reduction)) are shown in Table V to VIII. Also, the confusion matrices of ADL recognition results in each analysis pattern are shown in Fig.

4.

All participants from days 1?9 were cleaning while turning on TV. Therefore, in Table V and VI, the number of samples for ?cleaning? is 0 because ?cleaning? has become all ?with TV.? In Tables V to VIII, the average accuracy was calculated by the following equation.

Average accuracy =  Number of matched activity recognition and test data  Number of instances of test data (1)  C. Discussion Importance of position information: Comparing Table V  with Table VI, the average accuracy increased by 13.9%  TABLE V: Results of only ECHO  activities samples precision recall F-measure other 3692 0.532 0.639 0.581  bath-related 1089 0.741 0.435 0.548 cleaning 0 0 0 0 cooking 1468 0.694 0.454 0.549  TV-related 2318 0.117 0.063 0.082 PC 1458 0.002 0.001 0.002  sleeping 155 0.535 0.690 0.603 long go out 420 0.603 1.000 0.752  with TV 5670 0.632 0.801 0.707 average accuracy 53.6%  TABLE VI: Results of ECHO + motion  activities samples precision recall F-measure other 3692 0.595 0.657 0.625  bath-related 1089 0.750 0.718 0.734 cleaning 0 0 0 0 cooking 1468 0.880 0.833 0.856  TV-related 2318 0.557 0.541 0.549 PC 1458 0.184 0.134 0.155  sleeping 155 0.606 0.845 0.706 long go out 420 0.871 1.000 0.931  with TV 5670 0.791 0.802 0.797 average accuracy 67.5%  by adding the motion sensor information as futures. Six of the nine activities such as bath-related, cooking, TV, PC, sleeping, and long go out increased F-measure by 0.1 or more. This shows that these activities have a strong relation with position information. For example, ?only ECHO? in Fig.

4 shows that the activity ?TV-related? (e = TV-related) is misclassified to ?with TV? (i = with TV). The reason is that it is hard to distinguish between these two activities only by ON/OFF information of TV. When motion sensor information is used, those two activities were successfully distinguished.

TABLE VII: Results of ECHO + motion + layout-change  activities samples precision recall F-measure other 6725 0.632 0.721 0.674  bath-related 1801 0.595 0.731 0.656 cleaning 100 0.791 0.720 0.754 cooking 3827 0.826 0.853 0.839  TV-related 4407 0.517 0.516 0.516 PC 2699 0.502 0.213 0.299  sleeping 387 0.617 0.592 0.604 long go out 720 0.863 1.000 0.927  with TV 7754 0.689 0.688 0.688 average accuracy 65.6%  TABLE VIII: Results of ECHO + motion + layout-change (Gini reduction)  activities samples precision recall F-measure other 6725 0.628 0.766 0.690  bath-related 1801 0.828 0.718 0.770 cleaning 100 0.327 0.160 0.215 cooking 3827 0.818 0.813 0.815  TV-related 4407 0.495 0.543 0.518 PC 2699 0.443 0.211 0.286  sleeping 387 0.644 0.594 0.618 long go out 720 0.862 1.000 0.926  with TV 7754 0.681 0.657 0.669 average accuracy 65.4%  First International Workshop on Mobile and Pervasive Internet of Things'17    Fig. 4: Confusion matrix of ADL recognition results in each analysis pattern  The motion sensor information is important to distinguish those two activities, because many activities related to TV was performed in front of TV.

Influence of layout-change: Comparing Table VI with Ta- ble VII, the average accuracy decreased only by 1.9% after the layout change. The position of sofa was changed after the layout change in Fig. 1. Therefore, the accuracy of watching TV decreases, because participants sat the sofa when watching TV. However, F-measure decreased only by o.o3. The reason is that the position of the motion sensor attached to TV was also changed. This result shows that our proposed method is not very affected by layout change of furniture/appliance.

Importance of feature selection: Comparing Table VII with Table VIII, the average accuracy decreased only by 0.2% by removing 7 features. The result shows that we can reduce the initial deployment cost by decreasing the number of sensors used. However, it is not good to reduce the sensors selected at random. For example, in the Table VIII, F-measure of cleaning decreased by more than 0.5 because ON/OFF information from the vacuum was removed for the features for learning. Some of the removed sensors should be selected for learning depending on the situation.



VII. CONCLUSION  In this paper, we proposed a new ADL recognition system using information acquired from ECHONET Lite-ready appli- ances instead of power consumption data of appliances. The proposed method can reduce costs of the system construction by using ECHONET Lite-ready appliances which are expected to widely spread in the future. Also, the proposed method can obtain the position information of resident without introducing position sensors by using motion sensor that is expected to be attached to ECHONET Lite-ready appliances aftertime. In order to evaluate the proposed method, we collected data in our smart-home testbed while several participants are living there. As a result, the proposed method achieved about 68% classification accuracy for 9 different ADLs. As part of future work, we try to find more effective techniques to improve ADL recognition accuracy by selecting useful features, and also propose and implement a new system to enable the ADL recognition of multiple residents at the same time.

