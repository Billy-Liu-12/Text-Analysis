A Logical Formulation of the Granular Data Model ?

Abstract  In data mining problems, data is usually provided in the form of data tables. To represent knowledge discov- ered from data tables, decision logic (DL) is proposed in rough set theory. While DL is an instance of propositional logic, we can also describe data tables by other logical for- malisms. In this paper, we use a kind of many-sorted logic, called attribute value-sorted logic, to study association rule mining from the perspective of granular computing. By us- ing a logical formulation, it is easy to show that patterns are properties of classes of isomorphic data tables. We also show that a granular data model can act as a canonical model of a class of isomorphic data tables. Consequently, association rule mining can be restricted to such granular data models.

Keywords: Data table, rough set theory, decision logic, first-order logic, granular data model.

1 Introduction  In recent years, knowledge discovery in databases (KDD) and data mining have received a great deal of at- tention because of their practical applications. Many dif- ferent forms of knowledge have been considered by KDD researchers, notably, association rules and sequential pat- terns [1, 2]. Rough set theory, proposed by Pawlak, pro- vides an effective tool for extracting knowledge from data  ?This work was partially supported by the NSC (Taiwan) under Grant no. 95-2221-E-001-029-MY3  tables [6]. In fact, many powerful data mining algorithms have been designed based on rough set theory (see papers in [7?9] for some examples). To represent and reason about extracted knowledge, a decision logic (DL) is also proposed in [6]. The semantics of DL is defined in a Tarskian style through the notions of models and satisfaction. While DL is an instance of propositional logic, we can also represent knowledge extracted from data tables by using first-order logic (FOL) or many-sorted first-order logic (MSFOL) [3].

In this paper, we explore the description of data tables based on MSFOL. The attribute value-sorted logic (AVSL) pro- posed in [3] is investigated from the perspective of granu- lar computing. By using a logical formulation, it is easy to show that patterns are properties of classes of isomor- phic data tables. It can also be shown that a granular data model can act as a canonical model of a class of isomorphic data tables. Consequently, association rule mining can be restricted to such granular data models.

In the next section, we review rough set theory and de- cision logic. In Section 3, the syntax and semantics of at- tribute value-sorted logic (AVSL) are presented. In Sec- tion 4, we show that isomorphic data tables have the same set of patterns, which implies that association rules are syn- tactic in nature. We also show that a canonical granular model can be obtained for each class of isomorphic data ta- bles, and all patterns discovered from the class of data tables can be discovered from the granular data model. We then summarize our conclusions in Section 5.

DOI 10.1109/ICDM.Workshops.2008.25    DOI 10.1109/ICDMW.2008.23     2 Rough Set Theory?A Review  2.1 Approximation space  The basic construct of rough set theory is an approxima- tion space, defined as a pair (U,R), where U is the uni- verse and R ? U ? U is an equivalence relation on U . An equivalence relation partitions the universe U into a family of equivalence classes so that each element of U belongs to exactly one of these equivalence classes. Thus, we can write an equivalence class of R as [x]R if it contains the element x. Note that [x]R = [y]R iff (x, y) ? R.

In philosophy, the extension of a concept is defined as the objects that are instances of the concept. Following this terminology, a subset of the universe is called a concept or a category in rough set theory.

Given an approximation space (U,R), each equivalence class ofR is called anR-basic category orR-basic concept, and any union ofR-basic categories is called anR-category.

Now, for an arbitrary concept X ? U , we are interested in the definability of X based on R-basic categories. We say that X is R-definable, if X is an R-category; otherwise X is R-undefinable. R-definable concepts are also called R- exact sets, whereas R-undefinable concepts are said to be R-inexact or R-rough. When the approximation space is explicit from the context, we simply omit the qualifier R and call a set an exact set or a rough set.

A rough set can be approximated from below and above by two exact sets. The lower approximation and upper ap- proximation of X are denoted by RX and RX respectively and defined as follows:  RX = {x ? U | [x]R ? X},  RX = {x ? U | [x]R ?X 6= ?}.

2.2 Data tables and decision logic  For data mining problems, data is usually provided in the form of data tables (DT). The following formal definition of a data table is given in [6].

Definition 1 A data table1 is a tuple  T = (U,A, {Vi | i ? A}, {fi | i ? A}),  where U is a nonempty finite set, called the universe; A is a nonempty finite set of primitive attributes; for each i ? A, Vi is the domain of values for i; and for each i ? A, fi : U ? Vi is a total function.

1Also called knowledge representation systems, information systems, or attribute-value systems  In [6], a decision logic (DL) is proposed for the represen- tation of knowledge discovered from data tables. It is called decision logic because it is particularly useful in a special kind of data table, called a decision table. A decision table is a data table T = (U,C ?D, {Vi | i ? A}, {fi | i ? A}), where the set of attributes can be partitioned into two sets, C and D, called condition attributes and decision attributes respectively. Decision rules relating the condition and the decision attributes can be derived from the table by data analysis. A rule is then represented as an implication be- tween the formulas of the logic.

The basic alphabet of a DL consists of a finite set of at- tribute symbols A, and a finite set of value symbols Vi for i ? A. The syntax of DL is then defined as follows.

Definition 2  1. An atomic formula of DL is a descriptor (i, v), where i ? A and v ? Vi.

2. The set of DL well-formed formulas (wff) is the small- est set that contains the atomic formulas and is closed under the Boolean connectives ?,?, and ?.

3. If ? and ? are wffs of DL, then ? ?? ? is a rule in DL, where ? is called the antecedent of the rule and ? is called the consequent.

A data table T = (U,A, {Vi | i ? A}, {fi | i ? A}) relates to a given DL if there is a bijection ? : A ? A such that, for every a ? A, V?(a) = Va. Thus, by somewhat abusing the notation, we usually denote an atomic formula as (i, v), where i ? A and v ? Vi if the data tables are clear from the context. Intuitively, each element in the universe of a data table corresponds to a data record, and an atomic formula (which is in fact an attribute-value pair) describes the value of some attribute in the data record. Thus, the atomic formulas (and therefore the wffs) can be satisfied or not satisfied with respect to each data record. This generates a satisfaction relation between the universe and the set of wffs.

Definition 3 Given a DL and a data table T = (U,A, {Vi | i ? A}, {fi | i ? A}) related to it, the satisfaction relation |=T between U and the wffs of the DL is defined inductively as follows (the subscript T is omitted for brevity).

1. x |= (i, v) iff fi(x) = v,  2. x |= ?? iff x 6|= ?,  3. x |= ? ? ? iff x |= ? and x |= ?,  4. x |= ? ? ? iff x |= ? or x |= ?.

If ? is a DL wff, the set mT (?) defined by  mT (?) = {x ? U | x |= ?}, (1)     is called the meaning set of the formula ? in T . If T is understood, we simply write m(?).

Sometimes, the notations T, x |= ? and x |=T ? are con- sidered interchangeable if the data table T must be made explicit.

A formula ? is said to be valid in a data table T (written as |=T ? or |= ? for short when T is clear from the context) if and only if m(?) = U ; that is, ? is satisfied by all indi- viduals in the universe. Moreover, ? is said to be satisfiable in a data table T if m(?) 6= ?  2.3 The connection  Although an approximation space is an abstract frame- work for representing classification knowledge, it can be easily derived from a concrete data table. Let T = (U,A, {Vi | i ? A}, {fi | i ? A}) be a data table and B ? A be a subset of attributes. Then, we can define an equivalence relation, called the indiscernibility relation based on B, as  ind(B) = {(x, y) | x, y ? U, fi(x) = fi(y)?i ? B}.

In other words, x and y are B-indiscernible if they have the same values with respect to all attributes in B. Conse- quently, for each B ? A, (U, ind(B)) is an approximation space.

In terms of DL, each equivalence class of B is character- ized by a DL formula ?i?B(i, vi) and any formula ? of DL can be regarded as a conceptmT (?). Then, the equivalence class is a subset of the lower (resp. upper) approximation of the concept if the rule ?i?B(i, vi) ?? ? is valid (resp. the formula ?i?B(i, vi) ? ? is satisfiable).

3 Attribute Value-sorted Logic  We have shown that DL can be used to describe knowl- edge discovered from a data table. In fact, DL is an instance of propositional logic (PL) in which each descriptor (i, v) is a primitive proposition and each object in a data table is considered an interpretation (a model) of the logic. Con- sequently, from the PL viewpoint, a data table is a set of models of DL. Alternatively, we can describe data tables by using first-order logic (FOL) or many-sorted first-order logic (MSFOL) [3].

3.1 Syntax  To describe data tables by using MSFOL, we consider a special instance, called attribute value-sorted logic (AVSL).

The set of sorts for AVSL is ? = {?i | i ? I}?{?u}, where I is an index set. The sort ?u is called the object sort and each ?i is called an attribute value sort. The alphabet (or vocabulary) of AVSL consists of:  1. a set of constant symbols ? = {c1, d1, ? ? ?},  2. a finite set of monadic predicates ? = {P1, Q1, ? ? ?},  3. a set of dyadic predicates {Ri | i ? I},  4. a set of equality predicates { .=i| i ? I ? {u}},  5. a set of variables ? = {x1, x2, ? ? ? , y1, y2, ? ? ?}, and  6. logical symbols: Boolean connectives and the univer- sal quantifier ?.

We assume that a rank function is used to assign a rank to constant symbols, predicate symbols, and variables. The rank of a constant symbol or a variable is an element of ?, and the rank of a predicate symbol is in ?k if its arity is k. A constant (resp. variable) of rank ?u is called an object constant (resp. variable); otherwise, it is called an attribute domain constant (resp. variable). For each i ? I , Ri is of rank (?u, ?i), and called an attribute predicate. In addition, a monadic predicate of rank ?u is called a concept predi- cate; and for each i ? I , a monadic predicate of rank ?i is called a value predicate. We also assume that an equality predicate .=i is of rank (?i, ?i) for each i ? I ? {u}.

A term is either a constant symbol or a variable, and the rank of a term is that of the constant or the variable.

If P is a predicate of rank (?1, ? ? ? , ?k) and t1, t2, ? ? ? , tk are the terms of ranks ?1, ?2, ? ? ? , ?k respectively, then P (t1, t2, ? ? ? , tk) is an atomic formula (k = 1, 2). The set of wffs of AVSL is then defined as the smallest set ? that con- tains all atomic formulas and is closed under the following formation rules:  1. if ? ? ?, then ?? ? ?;  2. if ? and ? ? ?, then ? ? ?, and ? ? ? ? ?;  3. if x is a variable and ? ? ?, then ?x? ? ?.

As usual, we abbreviate ???? as ? ? ?, (? ? ?)? (? ? ?) as ? ? ?, and ???? as ?x?.

3.2 Semantics  For the semantics, an interpretation for AVSL is a tuple A = ((D?)???, ?A), where D? is the domain of sort ? and ?A assigns meanings to the symbols of AVSL. Each constant symbol c of rank ? is interpreted as an element of D? , and each predicate symbol P of rank (?1, ? ? ? , ?k) is interpreted as a relation PA ? D?1 ? ? ? ? ?D?k (k = 1, 2). In particu- lar, the interpretation of an equality predicate is the identity relation on the corresponding domain. We assume that D?u and  ? i?I D?i are disjoint. A variable assignment of the  interpretation A = ((D?)???, ?A) is defined as a mapping ? : ? ?  ? ???D? . A variable assignment ? must sat-  isfy the constraint that, if x is of rank ?, then ?(x) ? D? .

Such a variable assignment can be extended to a valuation on the set of all terms by setting ?(c) = cA for each con- stant symbol c. Let x ? ? and d ?  ? ???D? be a variable  and an element in the domain respectively. Then, we denote ?[d/x] by the variable assignment ?? such that ??(x) = d and ??(y) = ?(y) for all y 6= x. Note that ?[d/x] is only well-defined when d ? D? , where x is of rank ?.

The satisfaction of a wff ? with respect to an interpreta- tion A and a variable assignment ?, denoted by A, ? |= ?, is defined as follows:  1. A, ? |= P (t1, ? ? ? , tk) iff (?(t1), ? ? ? , ?(tk)) ? PA,  2. A, ? |= ?? iff A, ? 6|= ?,  3. A, ? |= ? ? ? iff A, ? |= ? and A, ? |= ?,  4. A, ? |= ? ? ? iff A, ? |= ? or A, ? |= ?,  5. A, ? |= ?x? iff for all d ? D? , A, ?[d/x] |= ?, where ? is the rank of x.

Let ? be a set of wffs. We write A, ? |= ? if A, ? |= ? for all ? ? ?. A wff ? is true for the interpretation A, denoted by A |= ?, if for every variable assignment ?, we have A, ? |= ?. A wff ? is valid, denoted by |= ?, if it is true for all interpretations. Let ? be a set of wffs and ? be a wff. Then, ? is a logical consequence of ?, denoted by ? |= ?, if for every interpretation A and variable assignment ?, A, ? |= ? implies A, ? |= ?. Moreover, ? is satisfiable if there exist an interpretation A and a variable assignment ? such that A, ? |= ?.

It is sometimes necessary to distinguish the free or bound occurrence of a variable in a wff. To do this, we first define the scope of a quantifier. In wffs of the form ?x? or ?x?, ? is called the scope of the quantifiers ?x or ?x. A variable x is said to have a bound occurrence in a wff if the occur- rence is within the scope of a quantifier ?x or ?x. Other- wise, the occurrence is said to be free. Note that a variable can have both bound and free occurrences in a wff simulta- neously. However, it can be shown that ?x? ? ?y?(y/x) and ?x? ? ?y?(y/x) are both valid, where y is a new variable not occurring in ? and ?(y/x) denotes the result of replacing all free occurrences (if any) of x in ? by the variable y. Thus, we can always rename a bound occur- rence of a variable with a new variable and assume that no variables have bound and free occurrences in a wff simulta- neously. In this way, a variable with free (resp. bound) oc- currences in a wff ? is called a free (resp. bound) variable of ?. We usually write ?(x1, x2, ? ? ? , xn) to emphasize that x1, x2, ? ? ? , xn are all the free variables occurring in ?. A wff without free variables is called a sentence, and a set of sentences is called a theory(an AVSL theory). In contrast to ordinary wffs, a sentence ? has the property that, for any in- terpretation, either ? or ?? is true for the interpretation. We define the set of models of a theory ?, denoted by Mod(?),  as the set of all interpretations in which all sentences in ? are true. Let ?(x1, x2, ? ? ? , xn) (n ? 1) be a wff and A be an interpretation. Then, the extension of ? under A is defined as:  |?|A = {(?(x1), ? ? ? , ?(xn)) | A, ? |= ?}.

4 Granular Data Models  4.1 Data tables as AVSL models  For a data table T = (U,A, {Vi | i ? A}, {fi | i ? A}), we can consider a particular AVSL in which the set of sort index I = A. Thus, the set of attribute predicates is {Ri | i ? A}. The table T is then regarded as an interpretation of AVSL A = (U, (Vi)i?A, ?A) such that the meaning of the predicate symbolRi is {(u, v) | u ? U, v ? Vi, fi(u) = v}.

The syntax allows us to quantify both the objects and the attribute values. Two basic axioms for the AVSL formula- tion of a data table are the existence and uniqueness of the attribute values of each object. A third axiom assumes that each attribute value is possessed by some individual2. For- mally, a theory ? is called a basic data theory (BDT) if it contains  1. ?x?vRi(x, v),  2. ?x, v, v?(Ri(x, v) ?Ri(x, v?) ? v .=i v?), and  3. ?v?xRi(x, v).

for all i ? I . In this paper, we are only interested in BDT, so we use the terms theory and BDT interchangeably.

4.2 Isomorphism of AVSL models  Two interpretations A = ((D?)???, ?A) and B = ((D??)???, ?B) are isomorphic iff there is a one-one cor- respondence g :  ? ???D? ?  ? ???D  ? ? such that  1. g(a) ? D?? iff a ? D? for each ? ? ? and a ? D? ,  2. g(cA) = cB for each constant symbol c, and  3. (a1, ? ? ? , ak) ? PA iff (g(a1), ? ? ? , g(ak)) ? PB for each predicate P and (a1, ? ? ? , ak) ? D?1?? ? ??D?k , where (?1, ? ? ? , ?k) is the rank of P .

The correspondence g is called an isomorphism between A and B; and the notation A ? B is used to indicate that A and B are isomorphic. Sometimes, it is written as A ?g B to make the isomorphism g explicit. Let ? be a variable assignment on A and g be an isomorphism between A and  2The assumption is not essential. However, it simplifies the presenta- tion without loss of generality.

B. Then, g ? ? is a variable assignment on B such that g ? ?(x) = g(?(x)). The following proposition, presented in [5], shows that isomorphic models satisfy the same set of wffs.

Proposition 1 Let A and B be two interpretations such that A ?g B. Then, for any wff ? and variable assignment ? on A, we have  A, ? |= ? iff B, g ? ? |= ?.

By interpreting a data table as an AVSL model, an asso- ciation rule or a pattern is simply an AVSL formula ?(x) with a single free variable of rank ?u. Then, the exten- sion of ? under the interpretation A is its support set in the corresponding data table. A direct corollary of the above proposition shows that a pattern has the same support in isomorphic interpretations.

Corollary 1 Let A and B be two interpretations such that A ?g B. Then, for any pattern ?(x), we have  g(|?|A) = |?|B.

Since g is a one-one correspondence, |?|A and |?|B have the same cardinality, so their supports are the same.

4.3 Logical formulation of definability  Next, we formulate the indiscernibility relation and de- finability of rough set theory in AVSL. Let x and y be ob- ject variables, v be an attribute domain variable, and S be a subset of the index set I . Then, we can define the indis- cernibility formula (with respect to S) as:  ?s(x, y) = ? i?s  ?v(Ri(x, v) ? Ri(y, v)).

When S is a singleton {i}, we write ?s(x, y) as ?i(x, y).

Given an arbitrary concept predicate P , we can define  two formulas corresponding to its lower and upper approx- imations as follows:  ?Ps(x) = ?y(?s(x, y) ? P (y)),  ?Ps(x) = ?y(?s(x, y) ? P (y)).

Let ? be an AVSL theory that contains only predicate sym- bols in {Ri | i ? S} ? {P}. Then, we say that P is indis- cernibly S-definable with respect to ? if  ? |= ?x(?Ps(x) ? ?Ps(x)).

4.4 Isomorphic attribute predicates  An important notion in rough set theory is that of a reduct, which is a minimal subset of attributes that can in- duce the same indiscernibility relation as the original set of attributes. In particular, if two attributes induce the same in- discernibility relation, then at least one of them is dispens- able. This can be formulated in AVSL with the isomorphism between attribute predicates. Two attribute predicates, R1 and R2, are said to be isomorphic with respect to a BDT ?, denoted by ? |= R1 ? R2, if  ? |= ?v1?v2?x(R1(x, v1) ? R2(x, v2)).

We then have the following proposition.

Proposition 2 Let ? be a BDT and Ri and Rj be two at- tribute predicates. Then  ? |= Ri ? Rj iff ? |= ?x, y(?i(x, y) ? ?j(x, y)).

In an ordinary AVSL interpretation, two isomorphic at- tribute predicates could be interpreted as different binary relations because their domains may be different. However, we can always construct a kind of parsimonious model such that all isomorphic attribute predicates are interpreted as the same binary relation. This can be achieved by using the granular data model (GDM). To introduce GDM, we recall the notion of partition. Given a domain D, a partition of D is a subset {s1, s2, ? ? ? , sm} ? 2D such that  ?m i=1 si = D  and si ? sj = ? for 1 ? i 6= j ? m. As mentioned in Sec- tion 2, an equivalence relation on D can induce a partition on D, i.e., the set of all equivalence classes of the equiva- lence relation. Conversely, an equivalence relation can be obtained from a partition by taking each si as an equiva- lence class. In granular computing, the equivalence classes in a partition are also called granules. Now, an AVSL in- terpretation A = ((D?)???, ?A) is called a granular data model if it satisfies the following two conditions for each i ? I:  1. D?i is a partition of D?u , and  2. for each a ? D?u and s ? D?i , (a, s) ? RAi iff a ? s.

Let A = ((D?)???, ?A) be a model of any BDT ?.

Then, we can transform A into an isomorphic GDM B = ((D??)???, ?B) as follows:  ? D??u = D?u ,  ? D??i = {{a | (a, v) ? R A i } | v ? D?i} for each i ? I ,  ? RBi = {(a, s) | a ? s, a ? D??u , s ? D ? ?i} for each  i ? I .

Obviously, A and B are isomorphic by the following one- one correspondence:     ? a 7? a for all a ? D?u ,  ? v 7? {a | (a, v) ? RAi } for all v ? D?i and i ? I .

Because A is a model of a BDT ?, the above construction will result in a GDM. Note that if ? |= Ri ? Rj , then D??i = D  ? ?j by the construction. In other words, we have  two copies of the same partition that serve the value do- mains of attributes i and j respectively. Thus, by slightly abusing the notation, we can show that RBi = R  B j . In sum-  mary, we have the following proposition:  Proposition 3 For each BDT model A, we can find an isomorphic GDM. Furthermore, two isomorphic attribute predicates are interpreted as the same binary relation in such a GDM.

Since all isomorphic GDMs are identical up to the renaming of the elements of the domain ?u, we can arbitrarily select a GDM as the canonical model for a class of isomorphic interpretations.

4.5 Association rule mining  As mentioned earlier, association rules are represented as AVSL formulas with a single free variable of rank ?u.

In fact, the formulas in this form are more general than the traditional association rules, since AVSL is more expressive than DL. For example, we can represent a rule as follows:  ?v1, v2(R1(x, v1)?R2(x, v2) ? ?y(R1(y, v1) ? R2(y, v2)).

The rule expresses the dependency of attribute 2 on attribute 1; however, in DL, we can only express the dependency between particular attribute values.

The subset of AVSL formulas corresponding to the DL- styled association rules is the class of ground association rules (GAR). Given a fixed object variable x, the set of GAR based on x is defined by the following grammar:  ?(x) ::= Ri(x, ci) | ??(x) | ?1(x)??2(x) | ?1(x)??2(x),  where i ? I and ci is a constant of rank ?i. Let A be a GDM, then the extension of a GAR ?(x) under A can be easily computed by performing set-theoretic operations on the subsets of D?u because, for each formula Ri(x, ci), we have |Ri(x, ci)| = cAi ? D?u .

Based on the computation of the extension of a GAR, we can transform the mining of frequent patterns into an inequality constraint satisfaction problem [4]. For a given data table, let us assume that the set of constants of rank ?i is equal to the set of values of attribute i that appear in the data table. Then, we define an elementary formula as a GAR  ? i?I Ri(x, ci), where ci is a constant of rank ?i. Let  A be a GDM corresponding to the given data table. Then,  | ? i?I  Ri(x, ci)| = ? i?I  cAi .

For an elementary formula ?(x), let us denote the cardinal- ity of |?| by ](?). Then, we can find all frequent patterns of the data table by solving the following linear inequality:?  ???0  ](?) ? s? ? r,  where ?0 is the set of all elementary formulas, s? ? {0, 1} for all ? ? ?0, and r is the threshold for high frequency.

A solution of the inequality is a mapping ? : {s? | ? ? ?0} ? {0, 1} such that the inequality is satisfied by substi- tuting each variable s? by ?(s?). Each solution ? of the in- equality constraint then corresponds to the following GAR?  {? ? ?0|?(s?) = 1}.

5 Conclusion  In this paper, we propose using AVSL as the description language for data tables. Semantically, each data table cor- responds to an AVSL interpretation. Association rules are then represented as AVSL formulas with only a single free object variable. Based on the basic results in classical logic, we can see that the sets of patterns discovered from two iso- morphic models are the same. This implies that associations are syntactic in nature. For each class of isomorphic mod- els, we can obtain a canonical model, i.e., agranular data model. Thus, it is appropriate to perform association mining with the granular data model. Building on the observation in [4], we have shown that the mining of frequent patterns can be transformed into an inequality constraint satisfaction problem.

