Using Hybrid Algorithm for Automatic Recommendation Service

Abstract   A Hybrid algorithm based on decision tree and BP network is presented in the paper, which is applied to Automatic Recommendation service. We apply decision tree to mine the behavior pattern of initial learning capability of students as well as get learning state of users based on BP neural network to. Then the personalized study pattern will be formed according to the status of students. Finally, for users which course will be studied is shown automatically.

1. Introduction   With the development of network technology, the Network Resource Database (NRD) is more and more plentiful. But the users are unaware of how to search and apply the resource to meet his need efficiently, because of the existence of chaotic classification, incomplete guidance in the NRD. The NRD will be intelligent and exoteric by introducing automatic recommendation service. One side, we could mine the student's demand and interest, by which we could adjust their learning plans and let them get individual education.  On the other hand we could know their demands directly and scientifically, and redundancy and the insufficiency of the NRD. Collaborative filtering, which is widely used in recommendation algorithm, usually provides predicted ratings for recommendation, but request the user to provide more data. Web mining, which is the extraction of interesting and potentially us eful patterns and implicit information on the World Wide Web, is used to study and analyze recommending web pages based on web log mining in recent years. For example, Lin proposed a recommendation system based on association rules [1], Mobasher researched an algorithm based on association rules [2] and clustering [3], and used the algorithm to recommend individual contents for users, etc. In this paper we propose a hybrid algorithm based on decision tree and BP neural network. According to the user?s initial capability and the mastering degree of  some knowledge cell in the NRD, we realize intelligent recommendation.

2. Automatic Recommendation Algorithm  2.1. Mine learning ability based Decision Tree algorithm   For users, it?s very important to know the learning capability initially before supplying the automatic recommendation service of resources. When a user logon the system firstly, his individual information (such as the learning capability initially or one?s own taste) will be kept in the info-database. Then we can classify them according to these pretreated data. In this paper the author use Decision Tree algorithm in virtue of its simple frame and without additional training data. Using training data of student information to make decision tree and acquire the classified rule, and users are divided into different categories by their learning capability. In the paper we adopt the ID3 algorithm based Information Entropy and make Information Gain measure test attributes. The algorithm computes the information gain of each attribute. The attribute with the highest information gain is chosen as the test attribute for the given set S .

A node is created and labeled with the attribute, branches are created for each value of the attribute, and the samples are partitioned accordingly.

Definition: Let S  be a set consisting of s data samples. Suppose the class label attribute has m distinct values defining m distinct classes, iC  (for i =1,?,m). Let is be the number of samples of S in class iC .The expected information needed to classify a given sample is given by:  ? ( 1s , 2s ,?, ms ) =?? =  m  i ii pp  2log   ?1?  Where ip  is the probability than an arbitrary sample belongs to class iC  and is estimated by is / s .

2008 Workshop on Knowledge Discovery and Data Mining  DOI 10.1109/WKDD.2008.142   2008 Workshop on Knowledge Discovery and Data Mining  DOI 10.1109/WKDD.2008.142   2008 Workshop on Knowledge Discovery and Data Mining  DOI 10.1109/WKDD.2008.142   2008 Workshop on Knowledge Discovery and Data Mining  DOI 10.1109/WKDD.2008.142   2008 Workshop on Knowledge Discovery and Data Mining  DOI 10.1109/WKDD.2008.142       Let attribute ?  have v  distinct values, { 1a , 2a ,?, va }. Attribute ? can be used to partition S  into v  subsets, { 1S , 2S ,?, vS }, where  jS contains those samples in S that have value ja  of ? . If ?  were selected as the test attribute (i.e., best attribute for splitting), then these subsets would correspond to the branches grown from the node containing the set S . Let ijs  be the number of samples of class iC in a subset jS .The expected information is given by:  E( ? )= ( )? =  ? ++v  i mjj  mjj ss s  ss   1 ,...,  ?2?  The encoding information that would be gained by branching on ?  is:  Gain ( ? ) = ? ( 1s , 2s ,?, ms )-E( ? )          ?3? The ID3 algorithm is described based the definition  as follows: Input: The training samples represented by discrete- valued attributes and the set of candidate attributes.

Output: A decision tree Method: (1) Create a node N; (2) if samples are all of the same class, C then (3) return N as a leaf  node labeled with the class C; (4) if attribute_list is empty then (5) return N as a leaf node labeled with the most common class in samples ;//majority voting (6) select test_attribute,the attribute among attribute- list with the highest information gain; (7) label node N with test_attribute; (8) for each known value ia  of test_attribute;//partition samples (9) grow a branch from node N for the condition test_attribute= ia ; (10) let is  be the set of samples for which test_attribute= ia ;//a partition (11) if is  is empty then attach a leaf  labeled with the most common class is samples; (12) else attach the node returned by Generate_decision_tree ( is ,attribute_list- test_attribute)  Training data tuples is taken from the database, there are 90 samples of studying some courses, which can be used with the ID3 algorithm. After computing the entropy of each attribute, basic_info is selected as the test attribute because of the highest information  gain among all the attributes. A node is created and labeled with basic_info, and branches are grown for each of the attribute's values. The samples are then partitioned accordingly, after tree pruning the final decision tree returned by the algorithm is shown in Figure 1:   Figure 1  A decision tree for the learning grade  In Fig.1, the attribute basic_info represented the proportion between basic courses and the whole courses, and Time denoted the time he spends on the courses in a week. The final classification result is consistent with students? real ability.

2.2. Apply BP neural Network to identify learning state of users   To one knowledge cell, one?s history learning  information is kept to analyze his learning situation or how much he got based the BP neural network algorithm. BP neural network includes input, output and hidden layers. Suppose the connection weight between ia  nod in input layer and rb  nod in hidden player is irW , between rb and nod c  is rV . rT , Q  is the Valve value of nods in hidden and output layers.

(1) Give irW , rV , rT , Q  a Stochastic value; (2) Orderly compute rb and c given by:  rb = f(? =  +?  1i riij TaW )         (4)  c =f( 11 bW i ? + Q ) (r=1,2,3)      (5), Then Calculate the error of nod c with  )(kc (expected output value) given by:  d= c ?(1- c )?( )(kc - c )                 (6) (3) Calculate the weight of conditions and reduce  the indexes until d is very small or be zero.

Input is how much a user got from some  knowledge cell when study, output shows learning state of user on the knowledge cell. The structure of BP neural network is shown in Figure 2:          Figure 2  BP neural network structure   According to the BP neural network above we  know how a user got from one knowledge cell, so when users login the system next, we can pick up the individuation data from character database of learners, and give proper suggestion or study plan of next step to users.

3. Intelligent Recommendation Model   An automatic recommendation model was designed based network teaching resource database, in which the study resource is oriented towards knowledge cells. Analyzing the users? individual information and web history usage, we discover usage patterns and pick up the resource which interested by users and not accessed to users. The whole processes of recommendation include two parts: on line and out line, which is shown in Figure 3.In Fig 3, outline module is used to create the information database and knowledge database (kept the learning state on knowledge cells) of learners by data mining technology, after preprocessing web log and background database files, while on-line module is used to pick up individuation data, then recommend proper study contents to users by dynamic conversation.

Figure 2  The frame of automatic recommendation  model When a user was registered and login firstly, his  individual information was kept in the information database .According to these data we can apply data mining model to divide initial learning capability into different classifications. Then when he login next time, all his characters (including time spent on resource, times of on-line alternation, effect of alternation etc.) are kept in web log files. So we can give proper  advises and recommend individual resource contents to learners.

4. Conclusions   Supposing we are given 7 network course resource sets of alternation data for 40 students engaged information technology, showing the alternation for each course. Recall and precision are two measures of system recommendation, where the score threshold is 78 or 83. The result is shown in figure 4 and 5.

According to the result, the recall with threshold being 78 is bigger than with 83, while precision is on the contrary. So we can adjust the threshold if needed.

A hybrid algorithm based on decision tree and BP neural network was applied to analyze individual   Figure 4  Recall in automatic recommendation  system   Figure 5  Precision in automatic recommendation  system   study behavior of users, in order to recommend study resource necessary and supply the automatic recommendation service to them. The users? satisfaction is high. But, that is not enough, automatic recommendation must meet the need of users finally.

Therefore, how to estimate the users? interest and their transformation is the next problem to be solved. We will still to track the relative technique progress on this aspect. We hope that the users? interest and their transformation will be expressed   more accurately, and the average precision ratio of this algorithm will be higher than ever before.

Acknowledgements   This paper is supported by Hubei Province College Teaching Research Project: Research and Design of Undergraduate?s Graduation Design Dissertation Quality Control (20050185).

