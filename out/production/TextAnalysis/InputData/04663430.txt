Incorporating Historic Knowledge into a Communication Library for Self-Optimizing High

Abstract? Emerging computing systems have a wide variety of hardware and software components influencing the performance of parallel applications, presenting end-users with a (nearly) unique execution environment on each parallel machine. One of the big challenges of High Performance Computing is therefore to develop portable and efficient codes for any execution environ- ment. The Abstract Data and Communication Library (ADCL) is a self-optimizing runtime communication library aiming at providing the highest possible performance for application level communication operations. The library provides for a given communication pattern a large number of implementations and incorporates a runtime selection logic. This selection aims at adaptively choosing the best performing implementation on the current platform and for the given problem. In this paper, we present a recent enhancement to the library which introduces the capability of utilizing information from previous executions in order to minimize the overhead of the runtime selection logic which mainly stems from testing underperforming implemen- tations. We introduce the notion of similar problems by using a proximity measure for a given operation. The approach is evaluated for the n-dimensional neighborhood communication for two different network interconnects and for a large range of different problems.

Keywords: self-optimizing communication libraries, historic learning, proximity measures

I. INTRODUCTION Due to the availability of multi-core processors and the  omni-presence of gigabit quality networks, parallel program- ing is increasingly applied in the development of software products in areas such as gaming, or data and image process- ing. Companies turn towards parallel processing in order to ex- ploit the capabilities of modern micro-processors and have the ability to solve ? in the most general sense ? larger problems in a shorter time frame. However, achieving good performance for a parallel application is highly challenging due to the wide range of hardware and software components available for off-the-shelf computer systems. As an example, the design of the new multi-core processors of Intel, AMD, SUN or IBM differ significantly in the organization and connectivity of the cores, the cache hierarchies and the I/O capabilities of the processors. It is similarly challenging to deal with the capabilities of the different network interconnects, which don?t just include standard Fast and Gigabit Ethernet, but also more  advanced technologies such as InfiniBand, iWarp, or 10Gigabit Ethernet. Furthermore, the software stack consisting of the operating system, device drivers, and communication libraries, has a significant influence on the performance achieved by the application. Thus, an application developer has to be aware of the fact that his code will basically face a unique execution environment for every single machine that it is running on.

Scientific computing is already facing today most of the challenges outlined above. In order to exploit the capabilities of large scale High Performance Computing (HPC) systems, end-users and application developers apply resource and time consuming tuning of individual software components on each platform. Certain software components can be tuned for a given platform before the execution of the application. This ap- proach has been taken by several projects such as ATLAS [1] or ATCC [2]. The main drawback of these approaches is, that the tuning procedure itself often takes the same or a similar amount of time as running the application itself. Additionally, several factors influencing the performance of the application can only be determined while executing the application. These factors include process placement by the batch scheduler [3], resource utilization due to the fact that some resources such as the network switch are shared by multiple applications, operating system jitter [4] and application characteristics (e.g., communication volume and frequencies).

There are only very few projects as of today in HPC trying to incorporate runtime adaptation or exposing self-tuning behavior. For example, the Abstract Data and Communication Library (ADCL) [5], [6] allows applications to incorporate self-tuning operations, which are optimized by ADCL while executing the application itself. Thus, application developers avoid expensive pre-tuning steps. The library has been success- fully used to tune various communication operations, such as n-dimensional neighborhood communication, parallel matrix- matrix operations and low-level parameters of a message passing library [7]. Although ADCL has been shown to deliver close-to-optimal performance for a large number of platforms and network interconnects [8], there are still situations, where the current approach used by ADCL results in a significant overhead due to the tuning procedure. Most notably, applica-   DOI 10.1109/SASO.2008.47    DOI 10.1109/SASO.2008.47     tions exposing frequently and dynamically varying problem sizes, e.g. due to adaptive mesh-refinements, would require a very lightweight quick tuning procedure. Similarly, on certain platforms, exploring the performance of a suboptimal commu- nication pattern can add a tremendous penalty to the overall execution time, resulting in a large discrepancy between a hand-tuned and an automatically optimized version of the code.

In this paper, we present an extension to the tuning al- gorithm and the decision logic of ADCL, which takes per- formance information from previous executions into account.

There are two challenges which complicate this task: first, it is very seldom in real life, that exactly the same problem/problem size is being executed on the same platform twice. Thus, the library has to introduce the notion of and a quantification for similar problems. Second, even on a single parallel machine, conditions can vary between different executions significantly.

The library therefore has to introduce a ?safety net? which results in dismissing historic performance data under certain conditions. The paper describes the algorithms used in ADCL to incorporate historic knowledge and evaluates the properties of the system for a widely used communication pattern in high performance computing, namely the n-dimensional neighbor- hood communication.

The remainder of the paper is organized as follows: Sec. II presents the main concepts and ideas behind ADCL. Sec. III presents the approach taken by ADCL to consider historic knowledge. In sec. IV we evaluate the approach for two different network interconnects, a large number of different problem sizes and three different versions of the neighborhood communication. In sec. V we discuss some related work, and finally, Sec. VI summarizes our findings and presents the currently ongoing work in that area.



II. THE ABSTRACT DATA AND COMMUNICATION LIBRARY  The Abstract Data and Communication Library (ADCL) en- ables the creation of self-optimizing applications by allowing an application to register alternative versions of a particular function. From the conceptual perspective, ADCL takes ad- vantage of two characteristics of most scientific applications:  1) Iterative execution: most parallel, scientific applications are centered around a large loop, and execute therefore the same code sequence over and over again. Con- sider for example an application which solves a time- dependent partial differential equation (PDE). These problems are often solved by discretizing the PDE in space and time, and by solving the resulting system of linear equations for each time step. Depending on the application, iteration counts can reach six digit numbers.

2) Collective execution: most large scale parallel appli- cations are based on data decomposition, i.e. all pro- cesses execute the same code sequence on different data items. Processes are typically also synchronized, i.e. all processes are in the same loop iteration. This synchronization is often required for numerical reasons and is enforced by communication operations.

ADCL uses the initial iterations of the application to de- termine the fastest available code version. Once performance data on a sufficient number of versions is available, the library makes a decision on which alternative to use throughout the rest of the execution. Two key components of ADCL are the algorithm used to determine, which versions of a particular operation shall be tested, and how to decide efficiently across multiple process on the best performing version. In the fol- lowing, we give some details on both components.

A. Version Management and Selection  A fundamental assumption within ADCL is, that the library has multiple alternative versions for a particular functionality available to choose from. These alternatives will be stored as different functions in the same function-set. The number of alternatives can reach from a few, (e.g. the user providing two different version of a parallel matrix-multiply operation) to many millions, in case the user is exploring different values for internal or external parameters, such as various buffer sizes, loop unroll depth etc. In case of such large numbers of alternative versions, it is unrealistic to assume, that the library can test all available versions before deciding which one performs best.

As of today, ADCL incorporates two different strategies for version selection at runtime. The first version incorporates a simple brute-force search, which evaluates all available alternatives. Clearly, this approach has the limitations outlined above, and we are working on extending this approach by using some early stopping criteria as outlined in [9].

An alternative version selection algorithm is used, if the user annotates the implementations by a set of attributes/attribute values. These attributes are used to reduce the time taken by the runtime selection procedure, by tuning each attribute sep- arately. Given a certain number of measurements conforming that a particular attribute value leads to better performance than versions using other values for the very same attribute, all implementations/versions of the corresponding function- set not having the optimal value for that attribute are being discarded by the library. As has been shown in [5], this can significantly reduce the number of versions to be tested by ADCL, and improve the overall execution time. The main re- striction of this approach lies in the assumption that attributes are not correlated. However, there are a number of algorithms known in the literature to overcome this restriction, e.g. from the experimental design theory the 2k factorial design [10], [11] algorithms.

B. Collective Decision Logic  Independently of the version selection approach used by the library, the collective decision logic of ADCL will have to compare performance data of multiple functions gathered on different processes. The challenge lies in the fact, that in the most general case, processes only have access to their own performance data and performance data for the same code version might in fact differ significantly across multiple processes. Distributing the performance data of all processes     for all versions to all other processes is however not feasible, since the costs for communicating these large volumes of data would often offset the performance benefits achieved by runtime tuning. The approach taken by the library relies therefore on data reduction, i.e. each process provides only a single value for each alternative version of the code section being optimized.

In order to detail the algorithm lets assume ADCL gathers n measurements/data points for each version i on each process j. Let us denote the execution time of the kth measure- ment by t(i, j, k). In an initial step, the library removes outliers, i.e. measurements not fulfilling a condition C = t(i, j, k) | t(i, j, k) < b ? mink t(i, j, k), with b being a well defined constant, from the data set. This leads to a filtered subset  Mf (i, j) = {t(i, j, k) | t(i, j, k) fulfills C} (1)  of measurements with cardinality nf (i, j). Then, the perfor- mance measurements for each version are analyzed locally on each process and characterized by the local average execution time  m(i, j) = n  ? k  t(i, j, k) (2)  and its filtered counterpart  mf (i, j) = nf  ? k?Mf (i,j)  t(i, j, k) (3)  as estimates of the mean value. In a global reduction operation, the library determines for each version the maximum average execution time across all processes  m(i) = max j  m(i, j), (4)  mf (i) = max j  mf (i, j) (5)  considering all respectively only filtered data (3), and the maximum number of outliers no(i) over all processes  no(i) = max j  no(i, j).

This reduction is motivated by a fundamental law in par- allel computing, which states, that the performance of a (synchronous) application is determined by the slowest pro- cess/processor. Finally, the library selects the maximum exe- cution time including or excluding outliers by  r(i) = {  mf (i) if no(i) <= nmaxo m(i) otherwise  depending on whether the maximum number of outliers is ex- ceeded or not. The algorithm i? fulfilling r(i?) = mini r(i) is chosen as the best one. Assuming that the runtime environment produces reproducible performance data over the lifetime of an application, this algorithm is guaranteed to find the fastest of available implementations for the current tuple of {problem size, runtime environment, versions tested} [12].

C. An example function-set In the following, we would like to give a concrete example  for a function-set in ADCL by describing the alternative versions for the most relevant communication pattern in parallel computing, namely the n-dimensional neighborhood communication. This communication patterns often occurs for applications relying on data decomposition, where each pro- cess owns a rectangular portion of the overall computational domain of equal size. Typically, processes are mapped onto a regular n-dimensional cartesian process topology. Due to the numerical operations performed on the data, a process often needs read access to data items owned by its ?neighboring? processes. A typical solution for this problem is to keep a copy of these data items in addition to the items owned by a process in so-called ghost cells. These ghost-cells have to be updated frequently, e.g. in every iteration of an iterative solver. A process is not allowed to modify a ghost-cell. Fig. 1 shows an example for nine processes, which are arranged in a 2-D logical process topology, and the resulting messages between the processes when updating the ghost-cells. Ghost cells are depicted in green, while the main computational domain of each process is represented as white boxes. Due to the local structure of the discretization scheme, a processor has to communicate with at most two processes for a 1-D decomposition, four processes for a 2-D decomposition and six processes for a 3-D decomposition.

Process 0 Process 1 Process 2  Process 5  Process 8Process 7  Process 4Process 3  Process 6  Fig. 1. Data exchange occurring in the 2-D neighborhood communication.

As of today, ADCL uses three attributes in order to characterize a version/implementation of the n-dimensional neighborhood communication:  1) Number of simultaneous communication partners: this attribute characterizes how many communication oper- ations are initiated at once. For neighborhood commu- nication, the currently supported values by ADCL are all ( ADCL attribute value aao) and one (pair). This parameter is typically bound by the network/switch.

2) Handling of non-contiguous messages: supported values are derived data types (ddt) and pack/unpack (pack).

The optimal value for this parameter will depend on the communication library and some hardware characteris- tics.

3) Data transfer primitive: a total of eight different data transfer primitives are available in ADCL as of to- day, all of them based on the MPI specification [13].

These data transfer primitives can be categorized as either blocking communication (e.g. MPI Send, MPI Recv), non-blocking/asynchronous communica- tion (e.g. MPI Isend, MPI Irecv), or one-sided op- erations (e.g. MPI Put, MPI Get). Which data trans- fer primitive will deliver the best performance depends on the implementation of the corresponding function in the MPI library and potentially some hardware support (e.g. for one-sided communication).

Note that not all combinations of attributes really lead to feasible implementations. As an example, implementa- tions using a blocking data transfer primitives such as MPI Send/Recv can not be applied for implementations having more than one simultaneous communication partner.

Therefore, a total of 20 implementations are currently available within ADCL for the n-dimensional neighborhood communi- cation.



III. HISTORIC LEARNING  In the following, we would like to present the algorithms used to incorporate historic knowledge to improve the version management and selection algorithm of the library. We start by showing the necessity to improve the algorithm outlined in section II-A using two concrete examples. The algorithms developed to solve those problems can be split into two separate sections: a statistical analysis of the existing data in the history file, and how to derive decision based on the statistical data.

A. Motivating Examples  The first problematic scenario has been observed on a cluster (cacau), which consists of 200 nodes, each node equipped with a dual processor Intel EM64T processor at the High Performance Computing Center in Stuttgart, Germany.

For our analysis we used the secondary network of the cluster, namely a hierarchical Gigabit Ethernet network. This network consists of six 48-port switches which are used to connect the nodes, each 48-port switch has four links to the upper level 24 port Gigabit Ethernet switch. Thus, this network has a 12:1 blocking factor. We have executed tests using 64 processors on 64 nodes in order to ensure that communication between the processes has to use two or more of the 48-port switches.

Although this network configuration is rarely found in large- scale HPC centers, it is not uncommon to have a hierarchical Gigabit Ethernet network in low-cost clusters found at many institutions.

ADCL managed to find in all test-cases the best performing implementation for the 3-dimensional neighborhood commu- nication for a particular application. However, comparing the  performance of the ADCL version of the code to a hand- tuned version shows, that the automatically tuned version has an overhead of 72% in the final execution time. A detailed analysis revealed, that the overhead stems from the fact that the runtime selection logic has to test versions of that function set which show extremly poor performance on this network.

The difference in the execution time between the best and the worst performing version for 700 iterations of that code could be as high as 110 seconds vs. 210 seconds.

Second, a large class of HPC applications show a dynamic behavior with respect to the problem sizes used. As an ex- ample, simulations of the air-flow around the wings of an air- plane require vastly different computational meshes depending on the wing-type, distance to the wing, air temperature etc.

Modern codes do not create therefore a uniform mesh to compute the flow, but have local error criteria which are used to refine the computational mesh upon demand. This leads to a computational behavior, where the problem size is fixed for a small number of iterations, before it might be refined/modified again. Using the version management and selection algorithm outlined in section II-A, ADCL would very often not finish the evaluation of the available alternative versions for a given problem size before the computational mesh changes again.

B. Pre-requisites for Historic Learning  The main goal of this paper is to develop algorithms which enhance the ADCL library with the capability of making a faster but still accurate decision by reusing the knowledge learned from previous executions. A fundamental requirement to incorporate historic knowledge into the ADCL decision logic is to store information gained in one run into a history file such that the corresponding information can be accessed and re-used by subsequent executions. ADCL has therefore been extended by a history file, which is stored in an ADCL specific directory (.adcl). Once a particular function-set has been evaluated for a given problem size, ADCL stores problem characteristics as well as the performance data for that problem. The history file itself is written in an XML format and can be displayed in a user friendly way in a web-browser by linking the XML file to an XSL file.

Characterizing the problem consists of the function-set which has been optimized/explored, the process topology used by the application, and the problem sizes. The function- set identifies the operation which has been optimized, such as n-dimensional neighborhood communication. Furthermore, it also identifies the collection of different versions which can be explored, and optionally the attributes and attribute- values for each version. The process topology contains the information about the number of processes used and the logical relation between the processes. As an example, processes might be logically organized in a cartesian topology, where each process has a left/right/upper/lower neighbor. As of today, we require that the topology information between two problems is identical in order to explore similar entries in the history file, i.e. the application has to utilize the same function-set on the same number of processes. We plan to relax     however this requirement in the future, since the number of processes is very often less relevant than the topology itself, e.g. a 2-D cartesian process topology exposes nearly identical characteristics from the communication perspective for 100 or for 1000 processes. The problem size is a function-set specific characterization of the dimensions utilized by the application.

For the neighborhood communication, the problem size is described by the length of the messages used to communicate with each of the neighboring processes. The focus of the algorithms presented in the subsequent subsections will be on identifying similar problems based on varying problem sizes, which will require a meaningful distance measure between two problem sizes for a given function set.

Another item in the history file will contain a graph de- scribing the network topology between the processes. The connection between the processes can be characterized by the network interconnect utilized (InfiniBand, Gigabit Ethernet, etc.) and some simple characteristics such as network latency and bandwidth. This approach to characterize a network in a compact fashion has been explored e.g. in the carto framework of the Open MPI library [14]. This graph is not required for the second scenario described in section III-A, where we assume to have frequently changing problem size within the same execution, but would be required for introducing portability of the history files across different platforms. This feature is however not available as of today.

The performance data for a given function-set and problem size contains the execution time of the fastest implementation found in the function-set and the optimal attributes values characterizing this particular implementation. Furthermore, the history file also includes the performance data for all other versions tested. Although this might sound like large quantities of data which have to be stored, each code version tested contains in reality only a single floating-point data item in the history file.

C. Analysis of Historic Data  Algorithm 1 performs an analysis of the historic knowledge base and computes a statistical distance threshold to decide on similarities between different problem sizes. The starting point of the algorithm is a number of entries (NbOfPBSizes) in the history file for a given function-set. For the sake of clarity, we consider for the rest of the paper only the entries for the function-set of interest, and ignore that the history file might contain other entries as well. The library defines the relative maximum tolerable performance penalty compared to the best performing implementation as pmax, which leads to acceptable performance window. The algorithm determines then for each entry in the history file the top cluster, i.e. the group of functions in the function-set whose execution time is within pmax% of the execution time of the version which achieved the best performance for that problem size.

The main loop of the algorithm determines for each entry PSR the distance to all other entries PST, PST=1..NbOfPbSizes, PST 6= PSR in the history file, and whether the winner version of an entry PSR is in the  top cluster of the entry PST. If this is the case, a flag in a boolean array is set to true for the entry PST. Once all entries for a given problem size have been evaluated, sort the boolean array according to the distance of their entries to PSR and define the maximum distance for the problem PSR as the distance to the last entry in the boolean array, until which all entries are marked as true. To clarify the definition of the maximum distance in this context, consider a boolean array with the entries ( true, true, false, true, false). In this case, the maximum distance is the distance between the entry PSR and the problem size which lead to the second entry in the boolean array, since this is the element until which the winner of PSR delivered an acceptable decision for all the problem sizes within pmax.

Algorithm 1 AnalyseHistoricData(pmax) Require: Execution time of each implementation for different  problem sizes and the corresponding winners.

{Determine the versions within pmax% of the best one for each problem size (PS).} for PS=1 to NbOfPbSizes do  ClusterTopVersions( PS, pmax ) end for {Check whether the winner of the problem size reference (PSR) is in the top versions of test problem size (PST)} for PSR=1 to NbOfPbSizes do  for PST=1 to NbOfPbSizes do if PSR 6= PST then  Distance(PSR, PST)?CompDist(PSR, PST) if Winner( PSR ) ? TopVersions( PST ) then  IsSimilar( PSR, PST ) ? 1 else  IsSimilar( PSR, PST ) ? 0 end if  end if end for Dmax(PSR,pmax)?CompMaxDist(Distance,IsSimilar)  end for  Note that the algorithm automatically chooses the maximum distance to be zero in case a problem does not have any ?related? problems in the history file. Determining the distance between two problem sizes is function-set specific. For the n- dimensional neighborhood communication we use as of now the standard euclidean distance using the message length of the data items to be transfered to each neighboring process as the components.

The result of this analysis is the maximum distance for each problem size in the history file. This quantifies for a given problem size, that using a winner version of any problem size within the maximum distance leads to an acceptable performance for the problem size of interest, acceptable being defined as not more than pmax% above the optimal perfor- mance. As of today, the algorithm outlined above is run in a post-mortem analysis step. The maximum distance for each entry in the history file is stored along with all the other     information outlined in the previous subsection. We envision these calculations however to be performed in a long-term every time a new entry is being added to the history file.

D. Version Management and Selection Algorithms using His- toric Data  The algorithm as outlined above has one major restriction: assuming that ADCL has to execute a problem size for which no entry is available in the history file, algorithm 1 does not provide yet any hints on how to choose the code version to be used for the given function set. However, it is straight forward to extend this algorithm to provide a good starting point for a new problem size. We suggest two alternative approaches: given a new problem size PSNew, algorithm 2 PredictFromClosest predicts the code version by taking the winner version of the closest problem size in the history file, if PSNew is within the maximum distance determined for the closest problem size.

Alternatively, algorithm 3 PredictFromSimilar suggests to use the winner of a weighted majority vote from the similar problem sizes available in the history file, considering again only the problem sizes for which PSNew is within their defined maximum distance as a result of algorithm 1.

Algorithm 2 PredictFromClosest(PSNew, Dmax, pmax) {Find the closest problem size and its winner} Dmin ? Distance(PSNew, PS1) PredictedWinner ? Winner(PS1) for PS=1 to NbOfPbSizes do  D ? Distance(PSNew, PS) if D ? Dmax(PS,pmax) & D ? Dmin then  Dmin ? Distance(PSNew, PS) PredictedWinner ? Winner(PS)  end if end for {Estimate the execution time of the best version for the new problem size by interpolation of the execution times of the closest problem size } EstExecTime ? EstExecTime(PredictedWinner) {The estimated maximum execution time is the predicted execution time plus pmax%} MaxExecTime ? EstExecTime*(1 + pmax/100) return {PredictedWinner, MaxExecTime}  In both algorithms, we can furthermore estimate the exe- cution time of the predicted winner version by interpolating the data available of the related problem sizes involved in the prediction process. This predicted execution time can be used as a safety net. In case the measured execution time of the predicted winner function deviates more than pmax% from the predicted execution time, the library dismisses the historic data base and starts an optimization run for PSNew.

Algorithm 3 PredictFromSimilar(PSNew, Dmax, pmax) Initialization: Confidence[NbOfVersions] ? 0 for PS=1 to NbOfPbSizes do {Find the closest problem sizes} if Distance(PSNew, PS) ? Dmax(PS,pmax) then  Confidence(Winner(PS))? Confidence(Winner(PS)) + 1/Distance(PSNew,PS))  end if end for PredictedWinner ? Versions( Max(Confidence) ) {Estimate the execution time of the best version for the new problem size by interpolation of the execution times of similar problem sizes } EstExecTime ? EstExecTime(PredictedWinner) {The estimated maximum execution time is the predicted execution time plus pmax%} MaxExecTime ? EstExecTime*(1 + pmax/100) return {PredictedWinner, MaxExecTime}

IV. EVALUATION  A. Prediction Accuracy  In the following, we analyze the prediction accuracy for both prediction algorithms presented above: the algorithm using the closest problem size as a reference for the decision and the algorithm using a weighted majority vote of similar problem sizes. We explored our prediction techniques for three different function-sets, namely the 1D, 2D and 3D neighbor- hood communication. For each communication pattern, we execute a simple benchmark for a large set of problem sizes :  ? 50 problem sizes for 1D neighborhood communication from 24 to 128 data items per process.

? 55 problem sizes for 2D neighborhood communication from 32x32 to 72x72 mesh points per process.

? 60 problem sizes for 3D neighborhood communication from 32x32x32 to 64x64x64 mesh points per process.

For each problem size, we use the execution time of 5000 iterations of the corresponding communication operation for each available implementation/version in ADCL. We identify each time the winner function chosen by the ADCL brute force selection logic as well. Furthermore, we run the prediction algorithms to make a recommendation on the function to be used for each problem size based on the data of all other problem sizes in the history file. Note that for the purpose of this evaluation, the algorithms have been applied on the data gathered by the benchmarks in an off-line analysis, not at runtime using ADCL.

The test cases analyzed use 16, 32 and 48 processes on an AMD Opteron cluster using either InfiniBand or Gigabit Ethernet as a network interconnect. For each scenario (commu- nication pattern and network interconnect) we take every entry individually and use the remaining entries for that scenario to predict the winner function for this entry. Since the ?real? winner is known, we can compute the number of problem sizes     which are well predicted using a given prediction algorithm for a given acceptable performance window.

In the figures 2 to 7, we compare the prediction accuracy of the algorithms presented in the previous section for different values of pmax. A detailed analysis of the results shows, that in most cases both prediction algorithms have a success rate of more than 90% for an acceptable performance window of pmax = 10%. This validates the correctness of our approach.

For the few problem sizes where the historic knowledge base provides a bad recommendation, the library will be able to detect the wrong prediction using the predicted execution time.

Thus, ADCL will consequently ignore the historic data base for that instance and start a new optimization using one of the original selection algorithms of ADCL. As expected, the rate of correct predictions is increasing with increasing the size of the acceptable performance window.

The success rate of the prediction algorithms is better for smaller number of processes, but still reasonably good for the larger test cases analyzed. As an example, for the 2D pattern using the InfiniBand interconnect (figure 4) and for an acceptable performance window of pmax = 10%, the correct prediction rate is around 95% when using 16 or 32 processes and around 85% when using 48 processes.

In most of the scenarios analyzed, the weighted majority vote algorithm is outperforming the closest problem size al- gorithm in terms of prediction accuracy. This can be observed easily for the 1D pattern when using 32 and 48 processes (figures 2 and 3).

P re  d ic  ti o  n r  a te  [ %  ]  16 Proc, Closest 16 Proc, Maj Vote 32 Proc, Closest  32 Proc, Maj Vote 48 Proc, Closest 48 Proc, Maj Vote        1 5 10 15 20  P re  d ic  ti o  n r  a te  [ %  ]  Acceptable performance window pmax [%]  Fig. 2. Prediction Accuracy for the 1D Neighborhood Communication over InfiniBand.

B. Performance Benefit of Historic Learning  As of now, we have demonstrated that the algorithms pre- sented in the previous sections can automatically predict with a reasonable accuracy the version to be used for a new scenario, in case there are sufficient entries in the history file for the corresponding function-set. In this second part of this section we demonstrate the performance benefit of using the historic      P re  d ic  ti o  n r  a te  [ %  ]  16 Proc, Closest 16 Proc, Maj Vote 32 Proc, Closest  32 Proc, Maj Vote 48 Proc, Closest 48 Proc, Maj Vote       1 5 10 15 20  P re  d ic  ti o  n r  a te  [ %  ]  Acceptable performance window pmax [%]  Fig. 3. Prediction Accuracy 1D for the Neighborhood Communication over Gigabit Ethernet.

P re  d ic  ti o  n r  a te  [ %  ]  16 Proc, Closest 16 Proc, Maj Vote 32 Proc, Closest  32 Proc, Maj Vote 48 Proc, Closest 48 Proc, Maj Vote        1 5 10 15 20  P re  d ic  ti o  n r  a te  [ %  ]  Acceptable performance window pmax [%]  Fig. 4. Prediction Accuracy 2D for the Neighborhood Communication over InfiniBand.

learning capability introduced within ADCL for a simple test case. For this, we use a benchmark consisting of a parallel, iterative solver as often applied in scientific applications. The software used in this subsection solves a set of linear equations that stem from discretization of a partial differential equation (PDE) using center differences. The parallel implementation subdivides the computational domain into sub-domains of equal size. The processes are mapped onto a regular three- dimensional cartesian topology performing 3D neighborhood communications.

We evaluate the execution time of this application using the two existing selection algorithms already available within ADCL: the brute force search and the attribute based search algorithm. Furthermore, we evaluate the performance of the code when using the historic knowledge base, assuming that an entry for the corresponding problem size is already available         P re  d ic  ti o  n r  a te  [% ]  16 Proc, Closest 16 Proc, Maj Vote 32 Proc, Closest  32 Proc, Maj Vote 48 Proc, Closest 48 Proc, Maj Vote       1 5 10 15 20  P re  d ic  ti o  n r  a te  [% ]  Acceptable performance window pmax [%]  Fig. 5. Prediction Accuracy 2D for the Neighborhood Communication over Gigabit Ethernet.

P re  d ic  ti o  n r  a te  [ %  ]  16 Proc, Closest 16 Proc, Maj Vote 32 Proc, Closest  32 Proc, Maj Vote 48 Proc, Closest 48 Proc, Maj Vote        1 5 10 15 20  P re  d ic  ti o  n r  a te  [ %  ]  Acceptable performance window pmax [%]  Fig. 6. Prediction Accuracy 3D for the Neighborhood Communication over InfiniBand.

in the history file. The goal of this section is not to fully evaluate the new algorithms and their runtime behavior, but to determine the potential benefit of historic learning in case of a correct prediction. Fig. 8 shows the results obtained for 32 processes test case on the same cluster as described in the previous subsection using the Gigabit Ethernet interconnect.

The results indicate, that the attribute based selection logic outperforms the brute force search approach, due to its ability to exclude some of the badly performing versions early in the selection procedure. However, the performance of the application in this scenario could be further improved by using the historic learning capability within ADCL, which skips testing under-performing implementations, mocking the PredictFromClosest algorithm.

P re  d ic  ti o  n r  a te  [ %  ]  16 Proc, Closest 16 Proc, Maj Vote 32 Proc, Closest  32 Proc, Maj Vote 48 Proc, Closest 48 Proc, Maj Vote       1 5 10 15 20  P re  d ic  ti o  n r  a te  [ %  ]  Acceptable performance window pmax [%]  Fig. 7. Prediction Accuracy 3D for the Neighborhood Communication over Gigabit Ethernet.

E x  e cu  ti o  n t  im e  [ se  c]  64x64x32 64x64x64       Brute Force Heuristic Historic learning  E x  e cu  ti o  n t  im e  [ se  c]  Selection algorithm  Fig. 8. Performance Comparison of an Application utilizing the Brute Force Search, the Attribute Based Search and Historic Learning.



V. RELATED WORK  Among the numerical libraries incorporating adaptive tech- niques are ATLAS [15] and FFTW [16]. ATLAS abstracts the BLAS interfaces and provides several implementations for each function. During an extensive configure step, ATLAS determines the best performing implementation on a specific platform with a specific compiler. Furthermore, based on additional information such as cache sizes, ATLAS determines optimal, internal parameters such as the blocking factor for blocked algorithms. However, ATLAS does not perform any runtime optimizations.

Star-MPI [17] incorporates runtime optimization of collec- tive operations similarly to ADCL. Unlike ADCL, Star-MPI has only a single runtime decision logic, namely a brute force search whereas one of the main research focuses of ADCL is     to develop alternative runtime decision algorithms in order to speed up the runtime decision logic.

The FFTW library optimizes Fast Fourier Transform (FFT) operations. To compute an FFT, the user has to invoke first a ?planner? specifying a problem which has to be solved. The planner measures the actual runtime of many different imple- mentations and selects the fastest one. In case many transforms of the same size are executed in an application, this ?plan? delivers the optimal performance for all subsequent FFTs.

Since the planner can be time consuming, FFTW also provides a mode of operation where the planner comes up quickly with a good estimate, which might however not necessarily be the optimal one. The decision process is initiated just once by the user. Thus, FFTW makes the runtime optimization upfront in the planner step, which does not perform any useful work.

On the other hand, ADCL integrated the runtime selection logic into the regular execution of the applications. This is especially important, since the ADCL approach enables the library to restart the runtime selection logic in case significant deviations from the original performance, e.g. due to changing network conditions have been observed. FFTW has ? to a limited extent ? also the notion of historic learning, namely with a feature called Wisdom. The user can export experiences gathered in previous runs into a file, and reload it at subsequent executions. However, the wisdom concept in FFTW lacks any notion of related problems, i.e. wisdom information can only be reused for exactly the same problem size that was used to generate it. Furthermore, the wisdom functionality also does not include any mechanism which helps to recognize outdated or invalid wisdom, e.g. if the platform used for collecting the wisdom is significantly different than the platform used while reloading the wisdom.



VI. CONCLUSION  This paper presents a new set of algorithms, which have been designed in order to reduce the time spent in the runtime decision procedure of the Abstract Data and Communication Library (ADCL) by incorporating historic knowledge from previous executions. The algorithms use the notion of an acceptable performance window, which is defined as the relative performance penalty an application is willing to accept compared to the fastest possible version, for the sake of a faster decision procedure. Furthermore, the algorithms establish the notion of a maximum distance for each entry in the history file.

The maximum distance provides a measure which indicates when the winner function of a particular entry will lead to an acceptable decision for other entries. Using these mechanisms we defined two alternative algorithms for recommending a version to a new, unknown problem size: one algorithm uses the recommendation of the closest problem found, in case the distance between the new problem and the closest problem is below the maximum distance defined for the closest problem; the second algorithm introduces a weighted vote among all entries in the history file, whose distance to the new problem size is below their maximum distance.

The algorithms presented also contain an automatic measure for indicating when to dismiss recommendations based on historic knowledge. This ?safety net? is based on comparing the predicted performance vs. the real performance of the recommended code version. We evaluated both algorithms for three different function sets using two different network interconnects. The results indicate a reasonable rate of good recommendations by both algorithms, the weighted vote al- gorithm outperforming usually the one based on the closest problem size.

Our future work includes an extended analysis of the new algorithms for other communication patterns such as circular shift operations or broadcast operations. Of special importance is the evaluation of the new algorithms within the context of adaptive HPC applications. In a long term, we also plan to include further runtime selection algorithms such as including early stopping criteria [9] or 2k factorial design algorithms [11] for very large parameter spaces.

