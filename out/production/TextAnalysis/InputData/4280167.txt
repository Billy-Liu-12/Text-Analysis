Mining Interesting Purchase Patterns:  A Method of Granular Computing

ABSTRACT  Nowadays, information technologies are widely used in business. Enterprises hope to make good use of the advanced technologies to analyze customer purchase behavior for better marketing. So it has become a hot issue to find interesting customer purchase patterns in a large amount of information. This paper proposes a method of granular computing to mine interesting purchase patterns. The granule represents a set of tuples that have the same attribute value in the database. For all tuples involved in interesting purchase patterns, we can represent them by using existing granules or creating new granules by logical operations (AND or OR) among existing granules. And then we use these granules to generate interesting patterns. This method not only can improve performance efficiently without scanning database repeatedly, but it is easier to understand for users and improves process flexibility. Especially for some complicated user demands, some high-level concepts which users take interest in don?t exist in the database, but we can generate new granules by OR operations to represent them. So it?s very convenient to mine interesting purchase patterns using granular computing.

Keywords: granular computing, pattern mining, meta-rules, multi-level concepts   1. INTRODUCTION  Nowadays, user-centered marketing conception has become the foundation of the development of enterprises.

In the face of large numbers of data in database, many enterprises hope to find some valuable information for better marketing. With the fast development of information technology, they may use some data mining methods to analyze customer purchase behavior. As an important part of data mining technologies, association rules mining has played an important role in studying purchase patterns. However, classic association mining algorithms can?t satisfy users? requirement any more. On one hand, classic algorithms produce large numbers of rules, especially in some large-scale database, whereas what users take interest in is just a small quantity of patterns instead of the whole patterns. On the other hand, some interesting concepts can?t be found in the database.

For example, in a database about customer consumption, the values of quantitative attribute ?age? can be divided into some continuous intervals: 0~10, 11~20, ? 70 and above, then we can find some patterns which are related to these interval values using classic algorithms. But these patterns can?t satisfy user demands if one want to know about ?young? customer behavior (age is less than 30). Therefore, mining interesting patterns according to user demands has been a problem to be solved urgently.

This paper proposes an approach of mining interesting patterns using granular computing. The tuples that have the same attribute value in the database are put into one information granule and then we use these granules to generate interesting patterns [1~3]. The advantages are as follows:  (1) Improving operation efficiency [4]. All data can be  stored in the form of information granule by scanning the database only one time. We can produce any patterns which we need by using granular computing without scanning the database repeatedly and hence reduce I/O cost.

(2) Dealing with complicated user demands efficiently.

Each granule shows one kind of tuples which have the same attribute value. For any concept that users are interested in, we can always find existing granule or create a new granule by composing or decomposing existing granules to express it. For example, we can create a new granule by composing three granules 0~10?11~20 and 21~30 to express the concept ?youth?, which is very hard to manage using classic algorithms.

2. LITERATURE REVIEW  Association rules mining, presented by R.Agrawal firstly in 1993[5], is a very important subject in data mining. It can be used to find customer purchase patterns in the transaction data. Subsequently, some improvements were also proposed for higher efficiency and less storage space. Nowadays, there are two main algorithms:  One is based on the Apriori algorithm [6~8], and the key to the algorithm lies in the ?downward-closed? property: any non-empty subset of a frequent itemset must also be frequent. The Apriori algorithm can be decomposed into two separate sub-problems: (1) Frequent itemsets generation: finding all frequent itemsets with supports exceeding the minimum support. (2)Association rules generation: Constructing all association rules from frequent itemsets with confidences exceeding the minimum confidence.

The other is frequent-pattern growth algorithm [9]. By     constructing the frequent pattern tree (FP-tree), we compress all frequent itemsets into the FP-tree, so all the association rules can be found without candidate generation by scanning databases two times. As a result, the algorithm has lower I/O cost and improves efficiency remarkably. However, there are still some problems remained to be solved:  (1) Large numbers of rules generated automatically contain many invaluable patterns. They are hard to understand and increase operation cost.

(2) Lack of users? participation and control. Users can?t find interesting patterns according to their own demands except specifying minimum support and minimum confidence in the beginning.

In order to solve the problems, many experts proposed their solutions [10~12]: (1) Doing further disposals according to user demands after generating all rules. If so, many invaluable rules generated automatically may reduce operation efficiency obviously. (2)Reducing the number of candidate itemsets according to constraint conditions. This method needs some additional space to store filtered data, thereby causing serious waste of resources, especially under loose constraint conditions.

3. METHODOLOGY  3.1 Granular Computing and its Bit String Representation  Granular computing was first proposed by T.Y Lin [13] and has become a very important tool in data mining since then. A granule is a set of objects associated together by indistinguishability, similarity, proximity, functionality, etc. In this paper, each granule is a list of tuples that have the same attribute value.

We use bit string to represent the granule. A bit string is composed of two kinds of characters ?0? and ?1?. Each tuple in the database has one unique offset position in the bit string. If a granule contains a tuple, the bit in corresponding positions is set to 1, otherwise it is 0.

Now, taking example for Table1, we will introduce how to use granules to represent relational table. Table1 is a relation table of transaction database.

},,,{ 4321 uuuuU = is tuple-IDs and I={milk, bread, sugar, egg}is itemsets. The tuples can be divided into some equivalent classes by different items, and each equivalent  class can be represented as a granule. So we use four granules to show the information of Table1:[milk] },{ 31 uu= ,[bread] },{ 21 uu= , [sugar]  },,{ 432 uuu= ,[egg] },,{ 431 uuu= .Then the granules can be represented as bit string (Shown in Table2).

Further more, we define |[X]| as the number of character 1 in the bit string representation of X, that is, the number of tuples contained in granule X. For example, |[milk]|=|1010|=2, indicating that granule [milk] contains two tuples.

3.2 Purchase Pattern Mining based on Meta-rules  In business transaction databases, there are many attributes relating to customers and products. So, large numbers of purchase patterns can be found. However, users only take interest in a few interesting patterns of them based on their own purpose. For example, if users hope to find the relationship among several products for cross-selling, they may just take interest in the patterns containing these products. Once more, users may put emphasis on the patterns relating to customer income if they want to know about certain product?s grade. For these special patterns with constraints, we can express them as meta-rules [14,15]. Meta-rules are rule templates, expressing interesting rule forms. We can set the number of predicates in rule antecedent or consequent, or specify interesting attribute values in the meta-rules.

(1) Antecedent fixed and consequent to be solved.

This is a simple constraint form.Taking example for Table3, a customer purchase information table, from which we want to find some interesting patterns. If users want to know that the specific customers whose age are between 35 and 45 and whose income are high prefer to buy which kind of products, the corresponding meta-rule    is shown as: Age(X,?36~45?) ?  Income(X,?high?)=>buys(X,Y).

X represents a certain customer and Y represents a certain product.

Now we use granular computing to solve the problem.

Scanning the database table, we can get two interesting granules: [Age(?36~45?)]=0011001010,  [Income (?high?)]=0010111010. By AND operation between [Age(?36~45?)] and [Income(?high?)], we can get a new granule: [Age(?36~45?)] ? [Income(?high?)]= 0010001010, which represents the customers whose age are between 35 and 45 and whose income are high. The new granule is named as [W], then we perform AND operations between W and all the granules which represent products. [W] ? [P1]= (0010001010) ? (1100100110)=0000000010, [W] ?  [P2] = (0010001010) ? (0011011001) = 0010001000. Specifying minimum support as 2 (min_sup=2) and minimum confidence as 0.6(min_conf=0.6), we can get the conclusions as follows: |[W] ? [P1]| =|0000000010|=1<min_sup, |[W] ? [P2]|=|0010001000|=2=min_sup, |[W] ? [P2]|/ |[W]|=2/3=0.67>min_conf. So W ? P2 is a strong association rule, which means the customers whose age are between 35 and 45 and whose income are high prefer to buy product P2 instead of P1.

(2) Consequent fixed and antecedent to be solved. For example, users may want to know which kinds of customers (considering some attributes: Age, Sex and Income) prefer to buy product P1, and this meta-rule can be shown as: Age(X,Y) ? Income(X,Z) ? Sex(X,W)=>buys(X,?P1?).

The meta-rule has fixed consequent but the number of antecedent is changeable. The main solution steps are described as follows:  1) Scanning the database table. Finding all granules in each dimension relating to user demands as candidate predicate sets C1. And in the meantime classifying them into some groups by different dimensions.

2) Computing the number of character 1 of each granule as its support count, and the granules whose support count is more than min_sup are put into frequent predicate sets L1.

3) Performing AND operations between the granule representing consequent and all granules in L1, and the new granules generated are put into candidate predicate sets C2. In the same way, the granules having the same dimensions are classified into one group. Then computing the number of character 1 of each granule and the granules satisfying min_sup are put into frequent predicate sets L2.

4) When K ? 3, performing AND operations among the granules in Lk-1 expect the granules belonging to the same groups. Then generating candidate predicate sets Ck and frequent predicate sets Lk. Circulating the process until Lk is null.

Now, we use the algorithm above to generate all frequent predicate sets satisfying the meta-rule: Age(X,Y) ? Income(X,Z) ? Sex(X,W)=>buys(X,?P1?).

See Table4 to Table 6 From the result, we can get five frequent 2-predicate sets: {P1,Age(?25~35?)}, {P1,Income(?medium?)}, {P1, Income(?high?)},{P1,Sex(?male?)}, {P1,Sex(?female?)} and two frequent 3-predicate sets: {P1,Age(?25~35?), Sex(?female?)}, {P1,Income (?medium?), Sex(?male?)} .

Next, we computing the confidence of all frequent predicate sets when min_conf=0.6.

confidence(Age(?25~35?)? P1)=  |)]35"~Age("25 [| |)]35"~Age("25 [ [P1]| ? =  3 >min_conf  confidence(Income(?medium?)? P1)=  |)]medium"Income(" [| |)]medium"Income(" [ [P1]| ? =  2 >min_conf   We can get four strong association rules: (1)Age(?25~35?) ? P1, (2)Income(?medium?) ? P1, (3) Age(?25~35?) ? Sex(?female?) ? P1, (4) Income(?medium?) ? Sex(?male?) ? P1. Although rule1 and rule3 have the same confidence, rule1 has better universality than rule3, so after deleting rule3 we can get finally three interesting purchase patterns rule1, rule2 and rule4.

3.3 Mining Purchase Patterns with Multi-level Concepts  Section 3.2 introduces how to mine purchase patters with constraints using granular computing. However, in many practical applications, the interesting patterns can?t be always found by appending constraint conditions. For example, users may want to know about the customers who buy personal computers, but in the sale records there are only some detailed computer names such as IMB PC, HP PC, etc. Thus the product concept of interesting patterns doesn?t agree with product information stored in the database. The method introduced in section 3.2 can?t solve this problem. So we will give a further discussion in this section.

The reason for this disagreement is that concepts are hierarchical. Some concepts of interesting patterns are high-level concepts abstracted from raw data.  In this case we should focus on mining patterns with multi-level concepts [16,17]. Attributes in the database have two types: categorical attribute and quantitative attribute.

Categorical attributes have a finite number of possible values with no ordering among the values (e.g.,sex,occupation). Quantitative attributes are numeric and have an implicit ordering among values (e.g.,age,income). We will study these two cases using granular computing separately.

3.3.1 Categorical Attribute  Because categorical attribute values are finite and their classes are specific? we can construct a classification tree with concept hierarchy. See Figure1. Overall products ?All? lies on level 0. Level 1 contains the concepts ?Computer? and ?Software?, and the next are level 2 and level 3. Then encode each concept as shown in the Figure 1. Take code ?211? for example, the first number ?2? corresponds to Software in Level 1, the second number ?1? corresponds to Finance in Level 2 and the third number ?1? corresponds to ORACLE in Level 3. So the product expressed as code ?211? is financial software with ORACLE brand.

Figure1 A Classification Tree with Concept Hierarchy  In classic mining algorithms with multi-level concepts, in order to find high-level concepts, we must scan the database with complicated query languages according to the concept hierarchy tree. The operation efficiency is  very low especially when there are large numbers of categories. Using granular computing, we can get every elementary granule corresponding to leaf nodes of the tree by scanning the database, and further we can get all granules corresponding to any concept of the tree by OR operations among the elementary granules.

In Figure1, the elementary granules include: [IBM Desktop], [HP Desktop],?[OFFICE OA Software]. The corresponding codes are:[111],[112],?[222]. The granule [Desktop] can be generated by OR operation between [IBM Desktop] and [HP Desktop], or shown as [11*]=[111] ? [112]. Similarly the granule [Computer] can be shown as [1**]=[11*] ? [12*]= [111] ? [112] ? [121] ? [122].

In general, a top-down strategy is employed in mining algorithms with multi-level concepts. For example, Table 7 is a transaction table after code transformation. If users take interest in the relation between computers sales and software sales, we can mine customer purchase patterns as follows: (min_sup=3)  In L[1,2],L[2,2] and L[3,2], we can get five frequent itemsets, and then generate strong association rules according to confidence threshold.

Table8 Generating All Frequent Itemsets     3.3.2 Quantitative Attribute      The values of quantitative attributes are consecutive numerals such as age and income. There are two basic treatment approaches regarding quantitative attributes. (1) They can be discretized using predefined concept hierarchies. For example, the values of attribute ?age? can be divided into some continuous intervals: 0~10, 11~20, ? 70 and above. (2)They can discretized into ?bins? based on the distribution of the data [18]. Anyway, these two treatments are based on fixed strategies without considering user demands. For example, if users want to know about young customer?s purchase patterns (age is less than 30), the division above can?t satisfy their demands. However, quantitative attributes are different from categorical attributes. The attribute values can?t be classified into certain specific classes, and users must define concept hierarchy dynamically according to their own purposes. Using granular computing, we can solve the problem easily. At any moment can we create new granules by OR operations among elementary granules to represent interesting concepts. In the last example, if the granules [X1],[X2],?[X7] represent the age intervals 0~10, 11~20, ?70 and above, the concept ?young? can be represented by [X1] ? [X2] ? [X3].

4. CONCLUSION  This paper proposes a method of mining interesting purchase patterns by using granular computing. Firstly, compared to the classic mining algorithms, granular computing can improve performance efficiently without scanning databases repeatedly. It?s very important for fast pattern mining in large business transaction databases. Secondly, it?s very convenient to mine interesting purchase patterns with constraint conditions by representing the data in transaction databases as granules. Under constraint conditions, we can get the tuples we need in order to mine interesting patterns.

Coincidently, each granule represents a set of tuples that have the same attribute value. Thus any tuples which users take interest in can be represented as a certain elementary granule or a new granule by AND operation among elementary granules. Therefore, this method is easier to understand for users and improves process flexibility. Further more, for the expression disagreement between interesting concepts and information stored in the database, the method of granular computing can mine interesting patterns with multi-level concepts conveniently to satisfy the complicated demands from uses. By OR operations among elementary granules, some new granules can be generated to represent the high-level concepts which users take interest in but don?t exist in the database. In a word, in mining interesting purchase patters, granular computing is a good method to satisfy complicated users demands efficiently.

However, there exist some problems unsolved in the paper, such as the storage of granules. Although granules are stored in the form of bit string, there still needs much space to store all granules especially in large business databases. We may adopt some methods to compress the  data which need to be discussed further.

