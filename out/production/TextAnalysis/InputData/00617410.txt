A Data Mining Methodology and Its Application to   Semi-Automatic Knowledge Acquisition

Abstract We antroduce a methodology fo r  knowledge dascou-  ery an databases (li'DD) where one first dascouers large collectzons of patterns at once, and then performs an- teractauely retraeves subsets of the collectaon of pat- terns. The proposed methodology suats such KDD formalasms as assocaatzon and epzsode rules, where large collections of potentaally anterestang rules can be found eficzently.

W e  present methods that support anteractwe explor- ation of large collectzons of rules. Wath these methods the user can flexably specafy the focus of anterest, and also ateratzuely refine at.

W e  haue zmplemented our methodology an the TASA system whach dascouers patterns an telecommunzcatzon alarm databases. In this paper, we gave concrete ex- amples of how to use frequent patterns an the construc- taon of alarm correlation expert systems  1 Introduction Data mining and knowledge discovery (KDD) is a  promising approach for semi-automatic knowledge ac- quisition from large masses of existing data. In KDD one typically wants to find a small collection of in- teresting (e.g., strong, useful, surprising, or valuable) patterns, rules etc., that occur or hold in the data.

Consider as an example the task of fault management in telecommunication networks. The networks produce large amounts of alarm information which must be analyzed and interpreted before faults can be located.

So-called alarm correlation systems (see, e g., [6, 81) are expert systems for analysis of alarm data. They are quite popular, but acquiring all the knowledge ne- cessary for constructing an alarm correlation system for a network and its elements is difficult. The com- plexity and diversity of network elements and the large  variation in the patterns of alarm occurrences pose ser- ious problems for network management experts trying to build a correlation model. Moreover, characteristics of the alarm flow change often, as new equipment and software releases are added to the network. On the other hand, large amounts of alarms are available, so the area is potentially good for KDD application.

Most knowledge discovery systems prune and rank the set of discovered patterns during the search for the patterns. We adopt a different approach. We use methods that locate all rules from a given class that satisfy certain simple frequency constraints. Dis- covered rules are not pruned automatically, but the user has explicit control over the operations on a rule set. This way the user can always be sure that the view on the data is in a sense complete: the system has not put aside any rules automatically.

Our approach is based on two simple facts:  0 Iteration is essential in KDD. It can be hard, or even impossible to specify beforehand what is interesting or relevant.

0 Pattern generation from very large data sets is time consuming. Efficient algorithms exist, but the pattern extraction phase still is a barrier for smooth interaction.

We propose a KDD process where emphasis is on  1. In the pattern discovery phase, find all  potentially interesting patterns according to some rather loose criteria.

2.  Provide flexible methods in the presentation phase for iteratively and interactively creating different views to the discovered patterns.

Preprocessing and transformation steps are typic- ally needed before patterns can be discovered (Fig-  two central phases:  0-8186-8147-0197 $10.00 @ 1997 IEEE    Figure 1: The KDD process model.

ure 1). A goal of our model is to avoid repeating the time consuming phases of preprocessing, transforma- tion, and discovery.

We have implemented our methodology in the TASA system [7] which discovers patterns in telecommunica- tion alarm databases and provides tools for interactive identification of the relevant patterns.

The rest of this paper is organized as follows.

In Section 2 we briefly discuss two motivating ex- amples and give the basic properties of the knowledge discovery methods we have employed. The methodo- logy is described in Section 3. Then in Section 4 we concentrate on the pattern presentation phase of our KDD process. In Section 5 we summarize our exper- iences in applying the methodology in building alarm correlation systems. Finally, Section 6 is a short con- clusion.

Related work KDD process and methodology have been discussed in [3, 4, 51, where the importance of interaction and iteration is also underlined. The iter- ation covers, however, either the whole process or at least the pattern discovery and presentation phases.

To the best of our knowledge, none of the exist- ing KDD systems supports the methodology proposed here. For instance, in Explora [9], 49er El61 and Ke- fir 1111 the user can interactively change the focus, but that requires a new pattern discovery. Additionally, the approach of discovering all patterns can be contras- ted with numerous methods, e.g., in machine learning, which aim directly at more focused discovery and pro- duce one or at most few patterns that match the given problem specification. These methods usually require that the searched or learned subject is described quite carefully in advance.

2 Examples of Application Domains In this section we outline first a very simple ap-  plication domain (student enrollment data) and then discuss in more detail a significantly harder case, the analysis of telecommunications alarm data.

2.1 Student Enrollment Data  The first, simple case study concerns association rules [l] in the student enrollment database of courses in computer science at the University of Helsinki. In  the course enrollement database we may find an asso- ciation rule  IF Introduction to Unix THEN Programming in C WITH conf(0.84) freq(0.34).

The rule states that 84% of the students that have taken ?Introduction to Unix? also have taken ?Pro- gramming in C? , and that 34% of all the students ac- tually have taken both courses. More formally, an as- sociation rule is an expression X + Y ,  where X and Y are sets of predicates. Given a set of students, the con- fidence of such rule is the conditional probability with which predicates in Y are satisfied by a tuple in the database given that predicates in X are satisfied. The rule is called frequent, if its frequency exeeds a user- given threshold; i.e., if all the predicates in X U Y  occur together at least a user-specified minimum number of times.

The goal in analyzing student enrollment data is to obtain accurate and useful information about the inter- relationships between enrollments to various courses.

Such relationships can be valuable, e.g., for expert sys- tems aimed at planning curriculums and allocating re- sources.

2.2 Telecommunication Alarm Data  The other case study, which deals with a more in- teresting knowledge acquisition effort, handles rules derived from episodes [14] in telecommunication net- work alarm sequences. A telecommunication alarm database contains event data from a number of inter- connected components, such as switches. Alarms are produced by the components to report abnormal situ- ations. There are typically thousands of alarms a day, and they are of thousands of different types.

Telecommunication networks are growing fast in size and complexity, and at the same time their man- agement is becoming more difficult. The task of identi- fying and correcting faults in telecommunication net- works is a critical task of network management. Thus, the techniques of alarm correlation - automatic filter- ing of redundant alarms, identification of faults, and suggestions for corrective actions - are valuable.

We adopt the following view to alarm correlation, similar to the one taken, e.g., in [8]. Abstractly, the     input to a correlation system is an ordered alarm se- quence. An alarm consists of t ime ,  sender, and alarm message fields. The time is recorded by the sender, typically at a granularity of one second. The sender of the alarm can be identified at the level of, e.g., a network element. The alarm message contains all the available information about the problem.

A correlation pattern describes a situation that can be recognized in an alarm sequence within a time win- dow of a given length. Typically, a correlation pattern is an expression on the set of active alarms of, e.g., the last five minutes. Correlation patterns are construc- ted as logical combinations of alarm predicates; alarm predicates are derived from the fields of alarm mes- sages by constructing boolean-valued assertions. If in a given window there is a set of alarms that matches the correlation pattern, then the set is said to be an occurrence of the pattern. Associated with each cor- relation pattern is a correlation action, which is to be executed when there is an occurrence of the corres- ponding pattern in a window.

Constructing an alarm correlation system for a net- work and its elements is, however, difficult. Both net- works a.nd network elements evolve qiiickly over time, so a correlation system is never complete. It also takes time for the experts to learn new correlations and to modify existing ones.

KDD methods can be used in constructing a cor- relation system. The central idea is to discover recur- rent patterns of alarms that are potentially useful in the specification of correlation patterns. A discovered pattern can be, for instance, a set of alarms that oc- curs frequently within a time window of a given width, or a pattern can state that a certain alarm tends to be followed by another alarm from the same sender.

Episode rules and episodes [ l a ,  141 are a modific- ation of the concept of association rules and frequent sets, applied to sequential data, e.g., telecommunica- tion alarms. An episode rule is a rule of the form1  I F  link alarm link jailure  THEN high fault  rate WITH [201 C401 conf (0.23) freq(246/1056)  which tells us that in 23 per cent of the cases, where link alarm and link failure occurred within 20 seconds, also high fault rate occurred within 40 seconds. Moreover, in the data the left-hand side oc- curred 1 056 times and in 246 cases it was followed by the right-hand side, within the given time windows.

An episode is parallel, if there is no requirement for  'The actual predicates occurring in the example rules have been changed.

the order of the events within the time window, and serzal, if the events are required to occur in a certain order.

In general, we are not interested in rules with a negligible confidence, e.g., less than 20 per cent; it is typical to select only those rules with a confidence ex- ceeding a given confidence threshold. For finding all potentially interesting episode rules in a given event scquencc, the nccessary parameters are the frequency threshold, a set of window sizes which may be used in the episode rules, and the confidence threshold. The method that we have used to discover frequent epis- odes and cpisodc rules in our data is described in [la].

In summary, our scenario for building alarm correl- ation systems is the following (see Figure 2 ) .

0 First, a large database of alarms is analyzed off- line, and connections between sets of alarms are discovered automatically.

0 Then, for the construction of an alarm correlation system, the network management specialists have at hand a collection of alarm patterns which they can use in specifying the alarm correlation system.

0 In the final step, the correlation rules are applied in real-time fault identification.

3 The Methodology KDD is an iterative process and requires interac-  tion with the user. A general KDD process (adap- ted from [5]) consists of several phases and iteration between them (Figure 1). Our methodology gives spe- cial roles to the pattern discovery and pattern present- ation phases of the KDD process. In our approach, large collections of patterns are discovered at once.

Then, iterative information retrieval methods are used to give flexible views to the discovered patterns. The emphasis in our methodology is in the pattern present- ation part, where interesting information is searched for iteratively, without repeating the time consuming pattern discovery phase.

In the first two phases of the whole process the raw data is collected and prepared into a suitable form for the pattern discovery. A general overview of the data can be produced at this phase. Attributes identified mi irrelevant are removed, and potentially useful new attributes can be derived. The preprocessing in our methodology does not, however, mean that one expli- citly defines interestingness as in some other method- ologies.

All relcvant background knowledge should be taken advantage of. For instancc, in the case of teleeommu- nication alarm data, attributes can be derived to con- tain, e.g., information about the network topology.

Automatic Discovery Methods  PattemdRules 9 n Domain Expertise JU  2 -@: Figure 2: An alarm correlation model using discovered alarm patterns.

In the pattern discovery phase all potentially inter- esting patterns are generated from the data set. The (rather loose) criteria for interestingness can be, e.g., frequency, prevention of taking rarely occurring phe- nomena into account, or strength of the patterns.

The user specifies the following parameters for the discovery of the rules using TASA.

The alarm predicates are given by the user. For episode rules, the type of the alarm and the sender of the alarm are the most typical predicates. For association rules in turn, much larger predicate classes are useful.

In the case of episodes, the user specifies whether serial or parallel episodes are searched for.

For episode rules, the user also supplies a set of time bounds with which the rules are construc- ted. Our fault management experts have typically preferred time windows ranging from 5 seconds to 10 minutes.

For both episode and association rules, a fre- quency threshold is given by the user. The meth- ods output all episode and association rules spe- cified by the parameters above, whose frequency exceeds or is equal to the user-specified threshold.

For both episode and association rules, the user also specifies a confidence threshold. The al- gorithms then output all episode and association rules whose confidence is at least equal to the threshold.

The discovery method produces each episode rule and association rule satisfying the above conditions.

The conditions are typically quite loose, so large amounts of rules are discovered. For each rule, TASA  outputs the confidence and the frequency, and an es- timate of the statistical significance of the rule.

Example 1 The course enrollment database consists of registration information of 1 066 students who had registered for a t  least two courses. There are 2 010 association rules that match at least 11 students (i.e., the frequency threshold is 0.01). There are 6 715 rules that match at least 6 students.

In  contrast, in  the alarm sequence containing 43 478 alarms from a period of 10 days, there are 5 498 serial episode rules that hold with a frequency threshold of 10 (absolute value) with a maximum time bound of 60 seconds. There are 1 497 association rules between attribute values of individual alarms, that match at least 435 alarms (i.e., frequency threshold as 0.1). 0  The goal of the methodology is that returning to the pattern discovery phase is needed as seldom as possible. It is realistic to expect, however, that the algorithms need to be run several times. Parameter settings may need adjustment, or errors in the data cleaning phase may be revealed so that returning to the first phase of the process is necessary.

The basic idea - iteration in the pattern presenta- tion phase - can be applied to formalisms that have certain properties:  The desired focus is not known definitely in ad- vance.

There is an algorithm that can produce all pat- terns from a class of potentially interesting pat- terns.

The time requirement for discovering all po- tentially interesting patterns is not considerably     longer than if the discovery was focused to a small subset of the potentially interesting patterns.

There are several KDD formalisms that fit in this setting. Association rule [l,  21 and episode rule [ l a ,  141 algorithms can efficiently discover thousands of rules from relatively simple databases. A formal treatment of the setting of discovering all interesting sentences and an analysis of a general algorithm can be found in [13].

The presentation of discovered knowledge is a main part of our methodology. In this phase the relevant patterns should be located from large collections of potentially interesting patterns. The problem of locat- ing a small set of truly relevant information is a gen- eric problem in data mining: while formal statistical criteria for strength and significance of the discovered items abound, it is much harder to know which parts of the discovered knowledge really are useful for the user  Finally, the discovered knowledge has to be under- stood and applied, e.g., in an expert system. The role of the KDD system is to provide appropriate tools for displaying and browsing the knowledge, methods for expressing the desired focus, and to support iterative specification of the focus.

4 Presentation of Rules  As a result of the pattern discovery phase of our KDD process model, all patterns matching the spe- cified criteria are produced. All the patterns are, however, not supposed to be interesting to a partic- ular user or in a particular situation. Discovered rules can fail to be interesting for several reasons.

0 A rule can correspond to prior knowledge or expectations. For example, it can be known from the implementation that if an element sends an alarm A,  it will also send an explanatory alarm B .

0 A rule can refer to uninteresting attrib- utes or attribute combinations. E.g., a rule containing low priority alarms may be non- interesting, and the user would like to filter out all such rules.

e Rules can be redundant. For example, rule (b) below has no additional predictive power re- garding the course ?Unix Platform? over rule (a), and could be pruned as redundant.

(a) I F  Data Communzcatzons Programmzng zn C  THEN Unzs Pla t form WITH conf(0.14) freq(0.03)  (b) I F  Data  Communicatzons Programmzng zn C Introductzon t o  Unzx  THEN Unzs Pla t form WITH conf(0.14) freq(0.03)  The aim of the presentation phase of our method- ology is to support efficient, interactive, and focused views to the rules. In this section, we present meth- ods for exploring large sets of association and episode rules. The ideas of this section can be best applied on large, unstructured sets of rules and other similar, simple pattern formalisms.

Three types of operations are useful in processing a large collection of rules:  0 Pruning: reduction of the number of rules; e Sorting: ranking of rules according, e.g., to stat-  e Structuring: organization of the rules, e.g., to istical significance; and  clusters or hierarchies.

Obvious pruning and sorting criteria for association and episode rules are rule confidence, frequency, and statistical significance. Rules can be pruned by setting thresholds on these properties. Examples of the effect of threshold-value based pruning with alarm data are presented in Figure 3.

Templates [lo], pattern expressions that describe the form of rules that are to be selected or rejected, are one way of focusing the view to a large space of rules. A template is an expression  A i , .  . . , A k  + A k + i , .  . . , A , where each Ai is either an attribute name, a class name, or an expression C+ or C*, where C is a class name.? Here C+ and C* correspond to one or more and zero or more instances of the class C ,  respectively.

A rule  matches a template if the rule can be considered to be an instance of the pattern. The order of the compon- ents in the templates has no significance if the attribute order in the rules is not significant (association rules and parallel episode rules). With templates, the user can explicitly specify both what is interesting and what is not. To be interesting, a rule has to match a select- ive template. If a rule, however, matches an unselective template, it is considered uninteresting. To be presen- ted to the user, a rule must be considered interesting  ? A ,  can also be a regular expression.

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Conlience threshold  5ooo  4ow  3ow  ZWO  tow  t00 200 3M) 4cQ 5w MM 700 800 900 Frequency threshold (absolute values)  Figure 3: thresholds to the number of rules in alarm data.

Effect of rule confidence and frequency  - i.e. match one of the selective templates - and it must not be uninteresting - i.e. not match with any of the unselective templates.

Example 2 In our example domain of computer sci- ence course enrollment, the courses are divided into three classes: basic, undergraduate, and graduate courses. In addition, all courses belong to  the parent class ?any course ?. Thus, we have such generalizations as an Figure 4.

Using the selective template (a) below the user obtains a number of rules with (at least) a graduate course on the IF  part and the course ?Design and Analysis o f  Algorithms? on the T H E N  part. Examples of such rules are (b), (e) and (d).

Of the 2 OiO rules in the example database there are 15 rules that match the above specifications and have confidence of 0.2 or more and frequency of 0.01 or more. This sort of rules give an idea of what the stu- dents do in addition to taking ?Design and Analysis of Algorithms?, and the discovered rules can be util- ized when planning the course. Note that here the IF- T H E N  structure implies no temporal order.

(a) IF Graduate Course A n y  Course* Deszgn and Analyszs of Algorzthms  Introduction to Computers Deszgn and Analyszs of Algorzthms  THEN  (b) IF Compzlers  THEN WITH conf(0.16) freq(0.01)  ( c )  I F  Neural Networks Data Communzcatzons Deszgn and Analyszs of Algorzthms THEN  WITH conf(0.33) freq(0.01) (d) IF User Interfaces  Informatzon Systems Deszgn and Analysis of Algorzthms THEN  WITH conf(0.02) freq(0.10)  The user may consader some of the resultang rules un- anterestang, such as (b) ancludang baszc courses. By addang an unselectave template wath ?Basac Course? and ? 2 n y  Course*? on the IFpart  and ?Any Course* ? on the T H E N p a r t  the user can filter out all rules wath a basac course on the left-hand sade.

This technique is surprisingly powerful. For ex- ample, background knowledge about the normal cur- ricula of computer science studies can be taken into account by using templates that unselect all rules that correspond to the normal course of studies.

Example 3 A s  an example of how the system can be used in  case of alarm data, consider the follow- ing ~ c e n a r i o . ~  Assume the network manager has used TASA to  discover episode rules fo r  the past i0 days.

The manager knows that during that period, a device AA-16 caused serious problems and loss of money.

First he selects all rules that have AA-16 an the T H E N  part, thus traceing alarms that potentially have some causal relationship with the problem in  consider- ation.

The number of such rules is, however, large: 1 848.

The network manager decides to  restrict the T H E N part to  only contain one alarm. The number of selected rules is still large, 901, so he adds an unselective tem- plate to  remove all rules with devices from the same network area (indicated by the first two characters in the device identificator, here AA), which he knows by experience not to  have any effect to each other.

The number of rules is still large, 240 rules, so he further tightens the scope and adds a further selective template to get rules with at most two alarms on the IF  part and confidence of a t  least 75%. The resulting rule set contains 19 rules from the 5 498 original ones.

By browsing the resulting rules he finally finds alarms which indicate that the problems with device AA-16 had been caused by high fault rate in a similar nearby device. 0  3The device name and the situation are fictional, but the numbers reflect actual results and the effect of our methods.

Any Course  introduction lntmductian Programming Information Artificial Programming Unix Data Design and Analysis User Neural Compilers tu Computers to Unix in rascal Systems Intelligence in C Platform Communications of Algon?thms Interfaces Nehvorkr  Figure 4: Course hierarchy.

It should be noted that sometimes considerable amounts of rules remain, even when the user has found the desired focus with the described methods.

Automatic pruning, sorting, and structuring methods should at this point be available for invocation by the user, especially for removal of redundancy; see, e.g., [15] for rule covers, statistical methods, and cluster- ing.

5 Application Experience TASA has been in prototype iise in foiir telecom-  munication companies since the beginning of 1995, and experiences are encouraging. A telecommunica- tion network manager can use episode rules as correl- ation patterns, after possibly editing them and assign- ing them appropriate correlation actions. Discovered patterns can be used for filtering uninformative alarms, for combining alarms to construct hypothesis of faults, or for prediction of faults.

Episode and association rules are also useful for providing different views to the analyzed alarms, as in Example 3.  Although the discovery algorithms are not directly applicable for on-line analysis, TASA has turned out to be useful also in network surveillance.

The analysis can be rerun or augmented, e.g., every day or every hour. Recent patterns may point to yet unnoticed problems in the network.

The fault management experts in the telecommunic- ation companies have found the approach and TASA useful in, e.g.,  0 finding long-term, rather frequently occurring de-  0 creating an overview of a short-term alarm se-  0 evaluating the alarm data base consistency and  pendencies,  quence, and  correctness.

On the other hand, many of the rules discovered by TASA are deemed trivial by the network managers.

Luckily, much of the trivial knowledge can be ex- pressed and removed with templates.

Example 4 Consider an alarm correlation system which operates in  real t ime and is also able to handle  delayed alarms and slightly inaccurate t ime stamps. In the correlation patterns, delays are handled with a spe- cial wait function. Episode and assocaataon rules can be applaed an this system in a rather straightforward way. The episode rule  I F THEB high fault rate WITH [SI [SO] c o n f ( 0 . 7 0 )  freq(700/1000)  link alarm < link failure  discovered by TASA can be coded in the system as fol- lows:  - if ?alarm type = link alarm? then start  time; wait until ?alarm type = link failure? or LLtime = 5 sec?; ;f ?alarm type = link failure? then  display warning ?high fault rate with 70% probability in 60 sec?  else forward the original alarm;  That is, i f  a link alarm occurs and a link failure follows within 5 seconds, the rule right-hand side information is sent and the original alarms are suppressed. I f  a link failure does not follow ?wzthin 5 seconds, the 07.2- ginal link ularm is forwarded.

The correlation procedure can be enhanced using as- sociation rules. For example, assume that we have de- tccted that if the alarm type is link alarm, the t ime of the d a y  is ofice  hours, and alarm severity is I , then with probability of 95% the alarming element type is BS .  Af ter  expert evaluation of the rule we know that such alarms from network elements of type BS can be ignored. However, if an element of any other type sends that alarm, it is an interesting one. The following correlation function removes such alarms:  - if ?alarm type = link alarm? and ?office hours? and ?severity = 1? and ??element type = BS? then  exit forward the original alarm;  0.

Unexpected but useful dependencies have been found, e.g., between network elements which are not immediately connected in the network topology. Be- ginning from the first tests, discovered rules have been applied in alarm correlation systems.

6 Conclusion We have described a knowledge discovery method-  ology that can be used to automate knowledge acquis- ition. The methodology has the following two distinct- ive characteristics: (1) a large collection of potentially relevant rules is discovered at once, and (2) different views can be formed on the discovered rules iteratively and interactively. The motivation is that after the dis- covery of all potentially interesting rules, iteration is very efficient.

As an example application area we descibed tele- communication networks alarm data. The flow of alarms should be correlated automatically to a more in- telligible form, in order to facilitate identification and correction of faults. Unfortunately, the construction of an alarm correlation system requires a lot of both expertise and time, and is a process that never is com- plete.

Our experience in this field with both association and episode rules supports the claim that the meth- odology is useful in practice. For formalisms stronger than association and episode rules, strong focus in the pattern discovery phase may be essential for keeping the computation tractable. For well-defined problems this is probably fine, but for exploring regularities in large data sets the interaction may be cumbersome.

