Evaluation of Sampling for Data Mining of Association Rules *

Abstract  Discovery of association rules is a prototypical problem in data mining. The current algorithms proposed for data mining of association rules make repeated passes over the database to determine the commonly occurring itemsets (or set of items). For large databases, the i/O overhead in scan- ning the database can be extremely high. in this paper we show that random sampling of transactions in the database is an effective method for  finding association rules. Sam- pling can speed up the mining process by more than an order of magnitude by reducing U 0  costs and drastically shrinking the number of transactions to be considered. We may also be able to make the sampled database resident in main-memory.

Furthermore, we show that sampling can accurately repre- sent the data patterns in the database with high confidence.

We experimentally evaluate the effectiveness of sampling on different databases, and study the relationship between the pelformance, and the accuracy and confidence of the chosen sample.

1. Introduction  With large volumes of routine business data having been collected, business organizations are increasingly turning to the extraction of useful information from such databases.

Such high-level inference process may provide information on customer buying patterns, shelving criterion in supermar- kets, stock trends, etc. Data mining is an emerging research area, whose goal is to extract significant patterns or interest- ing rules from such large databases. It combines research in machine learning, statistics and databases. In this paper we will concentrate on the discovery of association rules.

The problem of mining association rules over basket data was introduced in [l]. Basket data usually consists of a record per customer with a transaction date, along with items bought by the customer. The main computation step consists of finding the frequently occurring item sets via an iterative  *This work was supported in part by an NSF Research Initiation Award (CCR-9409120) and ARPA contract F19628-94-C-0057.

process. In the k-th scan of the database all frequent items sets of length k are obtained. For disk resident databases, the I/O overhead in scanning the database during each iteration can be extremely high for large databases.

Random sampling from databases has been successfully used in query size estimation. Such information can be used for statistical analyses of databases, where approxi- mate answers would suffice. It may also be used to estimate selectivities or intermediate result sizes for query optimiza- tion [ 1 11. In the context of association rules, sampling can be utilized to gather quick preliminary rules. This may help the user to direct the data mining process by refining the criterion for ?interesting? rules.

In this paper we show that random sampling of transac- tions in the database is an effective way for finding associa- tion rules. We empirically compare theory and experimen- tation, present results on the percentage of errors and correct rules derived at different sampling values, the performance gains, and also the relationship between performance, accu- racy and confidence of the sample size. More specifically, we make the following contributions:  Sampling can reduce I/O costs by drastically shrink- ing the number of transaction to be considered. We show that sampling can speed up the mining process by more than an order of magnitude.

Sampling can provide great accuracy with respect to the association rules. We show that the theoretical results (using Chernoff bounds) are extremely conser- vative, and that experimentally we can obtain much better accuracy for a given confidence, or we can do with a smaller sample size for a given accuracy.

We begin by formally presenting the problem of finding association rules in section 2. Section 3 presents an analy- sis of random sampling from databases. The effectiveness of sampling is experimentally analyzed in section 4, and section 6 presents our conclusions.

0-8186-7849-6/97 $10.00 0 1997 IEEE  mailto:zaki,srini,wei,ogihara}@cs.rochester.edu   2. Data mining for association rules  We now present the formal statement of the problem of mining association rules over basket data. The discussion below closely follows that in [I ,  31.

Let Z = { i l , i 2 ,  . . . , im} be a set of m distinct attributes, also called items. A set of items is called an itemset, and an itemset with IC items is called a k-itemset. Each transaction T in the database V of transactions, has a unique identi- fier T ID,  and contains a set of items, such that T c Z.

An association rule is an expression A B, where item- sets A ,  B C Z, and A n B = 0. Each itemset is said to have a support s if s% of the transactions in 2, contain the itemset. The association rule is said to have conjidence c if c% of the transactions that contain A also contain B, i.e., c = support(A U B)/suppor t (A) ,  i.e., the conditional probability that transactions contain the itemset B, given that they contain itemset A.

The data mining task for association rules can be broken into two steps. The first step consists of finding all large itemsets, i.e., itemsets that occur in the database with a certain user-specified frequency, called minimum support.

The second step consists of forming implication rules among the large itemsets [3]. In this paper we only deal with the computationally intensive first step.

Many algorithms for finding large itemsets have been proposed in the literature [ l ,  7, 3, 10, 12, 6, 13, 21. In this paper we will use the Apriori algorithm [2] to evaluate the effectiveness of sampling for data mining. We chose Apriori since it fast and has excellent scale-up properties. We would like to observe that our results are about sampling, and as such independent of the mining algorithm used.

2.1. The Apriori algorithm  The naive method of finding large itemsets would be to generate all the 2m subsets of the universe of m items, count their support by scanning the database, and output those meeting minimum support criterion. It is not hard to see that the naive method exhibits complexity exponential in m, and is quite impractical. Apriori follows the basic iterative structure discussed earlier. However the key obser- vation used is that any subset of a large itemset must also be large. In the initial pass over the database the support for all single items (1-itemsets) is counted. During each iteration of the algorithm only candidates found to be large in the previous iteration are used to generate a new candidate set to be counted during the current iteration. A pruning step eliminates any candidate which has a small subset. Apriori also uses specialized data structures to speed up the count- ing and pruning (hash trees and hash tables, respectively.) The algorithm terminates at step t ,  if there are no large t- itemsets. Let Lk denote the set of Large IC-itemsets and  Ck = Lk-lXLk-1, the set of candidate k-itemsets. The general structure of the algorithm is given in figure 1. We refer the reader to [2] for more detail on Apriori, and its performance characteristics.

L1 = {large 1-itemsets }; for ( I C  = 2; Lk-1 # 0; IC + +)  c k  = Set of New Candidates; for all transactions t E 2)  for all k-subsets s of t if (s E ck)  s.count + +;  Set of all large itemsets = Uk Lk; L k  = { c  E Cklc.count 2 minimumsupport};  Figure 1. The Apriori algorithm  We now present a simple example of how Apriori works.

Let the database, 2, = {TI = (1,4,5),T2 = (1,2),T3 = (3,4,5),Tq = (1,2,4,5)}. Let theminimumsupportvalue M S  = 2. Running through the iterations, we get  Note that while forming C3 by joining L2 with itself, we get three potential candidates, { 1,2,4},{ 1,2,5}, and { 1,4,5}.

However only { 1,4,5} is a true candidate, and the first two are eliminated in the pruning step, since they have a 2- subset which is not large (the 2-subset {2,4}, and {2,5} respectively).

3. Random sampling for data mining  Random sampling is a method of selecting n units out of a total N ,  such that every one of the C: distinct samples has an equal chance of being selected. In this paper we consider sequential random sampling without replacement, i.e., the records are selected in the same order as they appear in the database, and a drawn record is removed from further consideration.

3.1. Sampling algorithm  For generating samples of the database, we use the Method A algorithm presented in [ 151, which is simple and very efficient for large sample size, n. A simple algorithm for sampling generates an independent uniform random vari- ate for each record to determine whether that record should be chosen for the sample. If m records have been chosen     from the first t records, then the next record will be cho- sen with the probability (n  - m ) / ( N  - t ) .  This algorithm, called Method S [SI, generates O ( N )  random variates, and also runs in O ( N )  time. Method A significantly speeds up the sampling process by efficiently determining the number of records to be skipped over before the next one is chosen for the sample. While the running time is still O ( N ) ,  only n random variates are generated (see [ 151 for more details).

3.2. Chernoff bounds  Let 7 denote the support of an itemset I .  We want to select n transactions out of the total N in the Database D. Let the random variable X i  = 1 if the i-th transac- tion contains the itemset I ( X i  = 0, otherwise). Clearly, P ( X i  = I )  = T for i = 1 , 2 , . . . n  . We further assume that all X I ,  X2, . . . , X ,  are independent 0- 1 random vari- ables. The random variable X giving the number of trans- actions in the sample containing the itemset I ,  has a bi- nomial distribution of n trials, with the probability of suc- cess T (note: the correct distribution for finite populations is the Hypergeometric distribution, although the Binomial distribution is a satisfactory approximation [4]). Moreover, X = CYX;, and the expected value of X is given as p = E [ X ]  = EICY=l Xi]  = Cy=, E[&] = 71.7, since  For any positive constant, 0 5 E 5 1, the Chernoff E[X;]  = 0 .  P(X = 0) + 1 . P ( X  = 1) = 7.

bounds [5] state that  Chernoff bounds provide information on how close is the actual occurrence of an itemset in the sample, as compared to the expected count in the sample. This aspect, which we call as the accuracy of a sample, is given by 1 - E .  The bounds also tell us the probability that a sample of size n will have a given accuracy. We call this aspect the confidence of the sample (defined as 1 minus the expression on the right hand size of the equations). Chernoff bounds give us two set of confidence values. Equation 1 gives us the lower bound - the probability that the itemset occurs less often than expected ( by the amount nm), while equation 2 gives us the upper bound - the probability that the itemset occurs more often than expected, for a desired accuracy. A low probability corresponds to high confidence, and a low E corresponds to high accuracy. It is not hard to see that there is a trade-off between accuracy and confidence for a given sample size. This can been seen immediately, since E = 0 maximizes the right hand side of equations 1,2, while E = 1 minimizes it.

3.3. Sample size selection  Given that we are willing to accommodate a certain ac- curacy, d = 1 - E, and confidence C = 1 - c of the sample, the Chernoff bounds can be used to obtain a sample size.

We?ll show this for equation 1, by plugging in c = e--E2nT/2, to obtain  n = -21n(c)/(7e2) (3 )  If we know the support for each itemset we could come up with a sample size n1 for each itemset I .  We would still have the problem of selecting a single sample size from among the n ~ .  One simple heuristic is to use the user specified minimum support threshold for T .  The ra- tionale is that by using this we guarantee that the sam- ple size contains all the large itemsets contained in the original database. For example, let the total transactions in the original database N = 3,000,000. Let?s say we desire a confidence C = 0.9(c = O . l ) ,  and an accuracy d = 0.99(~ = 0.01). Let the user specified support thresh- old be 1%. Using these values in equation 3, we obtain a sample size of n = 4,605, 170. This is even greater than the original database! The problem is that the sample size expression is independent of the original database size.

Moreover the user specified threshold is also independent of the actual itemset support in the original database. Hence, using this value may be too conservative, as shown above.

In the next section we will compare experimental results obtained versus the theoretical predictions using Chernoff bounds.

4. Experimental evaluation  In this section we describe the experiments conducted in order to determine the effectiveness of sampling. We demonstrate that it is a reasonably accurate technique in terms of the associations generated by the sample, as com- pared to the associations generated by the original database.

At the same time sampling can help reduce the execution time by more than an order of magnitude.

4.1. Experimental framework  All experiments were conducted on a 233MHz DEC Al- phaserver 2100 processor, with 256MB of main memory.

The databases are stored on an attached 2GB disk, and data is obtained from the disk via an NFS file server. We used four different databases to evaluate the effectiveness of sam- pling. These are: 0 SYNTHSOO, SYNTH250: These are synthetic databases which mimic the transactions in a retailing environment.

They have been used as benchmark databases for many as- sociation rules algorithms [3,6, 12, 13,2]. Each transaction         c - L (U 2000  5 1500    L a,  5 z  o   SYNTHBOO: minimum support = 0.25%  ORlG + SAMPO.5% -+--  ACT0.5% --o---- SAMPl% - * -  ACT1qo -.A..-.

SAMPS%  ACT5% -.-- SAMP10% --*..---  ACTIO% --e-----   SYNTH250: minimum support = 0.50% 8 0 0 1  0 8 I I , I , I  700 SAMPO.5% -+-    400 ACT10% --e-..-      ACTO.5% -a-..- -- ....... + ........ + _ _ _ _ _ _ _ _  SAMP10% .-*---  1 2  3 4 5 6 7 8 9 10 1 2 3 4 5 . 6 7 8 9 1 0 ltemset Size (k) ltemset Size fk)   1000 Y  - E 800 L   I    - 5 400 n   ENROLL: minimum support = 1.0%  ORlG -- ,A\ SAMPI% -+---  ACT1% -w.-  ACT5% -.A-.- I SAMP10% -I-.-  i ACT1 0% - - - . .

i  SAMP5% /' '\, *' \ \,     L p) 4000  I c -  P 2 3000  s a 2000  z  TRBIB: minimum su~port = 1.5%  has a unique ID followed by a list of items bought in that transaction. We obtained the database T10.16.D800K, by setting the number of transactions ID1 = 800,000, average transaction size IT1 = 10, average maximal potentially large itemset size (11 = 6. For T10.14.D250K, 1231 = 250000, [TI = 10, 111 = 4. For both databases the number of max- imal potentially large itemsets ILI = 2000, and the number of items N = 1000. We refer the reader to [3] for more detail on the database generation.

0 ENROLL: This is a database of student enrollments for a particular graduating class. Each transaction consists of a student ID followed by information on the college, major, department, semester, and a list of courses taken during that semester. There are 39624 transactions, 3581 items and the average transaction size is 9.

0 TRBIB: This is a database of the locally available techni- cal report bibliographies in computer science. Each item is a key-word which appears in a paper title, and each transaction has a unique author ID followed by a set of such key-words (items). There are 13793 transactions, 10363 items, and the average transaction size is 22.

4.2. Accuracy measurements  We report experimental results for the databases de- scribed above. Figure 2 shows the number of large itemsets  found during the different iterations of the Apriori algo- rithm, for the different databases, and sample size. In the graphs, ORIG indicates the actual number of large item- sets generated when the algorithm operates on the entire database. SAMPx refers to the large itemsets generated when using a sample of size 2% of the entire database.

ACTx refers to the number of itemsets generated by SAMPz that are true large itemsets in the original database. The number of false large itemsets is given as (SAMPx - ACTx). From figure 2 we can observe that the general trends of sampled databases resemble actual results. Smaller sam- ple sizes tend to over-estimate the number of large itemsets, i.e., they find more false large itemsets. On the other hand, larger sample sizes tend to give better results in terms of fi- delity or the number of true large itemsets. This is indicated by the way ACT.a comes closer to ORIG as z (the sample percentage) is increased.

More detailed results are shown in figure 3, which shows the percentage of true and false itemsets generated for dif- ferent values of sampling and minimum support. The values of minimum support were chosen so that there were enough large k-itemsets, for k >= 2. For example, for SYNTH800 and SYNTH250, only large 1-itemsets were found at sup- port more than 1 %. Therefore, only support values less than those were considered. Furthermore, support values were     m c I - E P   - a,  -1 a,  c   m - I - E  t  - a, e -1   s % E - a,  P 5 "..

z  m U)  - c E - a,  a,  k-  P  z -      .........

,;  - "'D.... ...........................................

-  - -..__ ----.----.---*U W. ;/' -..

x.., ,/' xx  ~ x. ,'  "'..q%&mpkng ..+-. - ........

...................

.......................... i _.__._---A.--._____ 0.5% Sampling - 98 "'\ 94      ........................ *-. .......

.....

t  92 - 90 -  88 ~  e ...................................... m,. ... 5% Sampling - tOo/ Sampling -4.--- ~ 2 ~ h a T p l i n g  - - - -  -  I  'TI i ~ - . ~  ~ ........... -"-+-------- ........ :.:> ....

/ ,/' ~  ,;:*'  8 6 l  ' ' ' ' ' ' ' ' 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  Minimum Support (Percentage) ENROLL        J 1 2 3 4 5 6 7 8  Minimum Support (Percentage)  SYNTHBOO  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Minimum Support (Percentage)  SYNTH250  0 5% Sampling + 1% Sampling -+-.

n " 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  Minimum Support (Percentage)  5% Sampling -+-- 10% Sampling --e----  70 25% Sampling -*. -.

0 1 2  3 4 5 6 7 8 9 10  Minimum Support (Percentage) _ .

TRBIB  100 I I  gOl 80 i 5% Sampling - 10% Sampling -+- 25% Sampling ---  io  -  1 2 3 4 5 6 7 8 Minimum Support (Percentage)  Figure 3. % of True and false large itemsets vs. %threshold for various sample sizes     chosen so that we don't generate too many large itemsets.

For example, for ENROLL at 1% sampling size, we get a sample of 396 transactions. For support of O S % ,  we must find all itemsets which occur at least 2 times, in effect find- ing all possible large itemsets. Thus only support values greater than 0.5% were used.

The figure shows that at higher sampling size we generate a higher percentage of true large itemsets, and a smaller number of false large itemsets. It is interesting to note that in all cases we found more than 80% of all the large itemsets.

We further observe that for other than very small sampling size, we can keep the false large itemsets under 20%.

4.3. Performance  Figure 4 shows the speedup obtained for the databases on different minimum support and different sampling size Val- ues. The speedup is relative to the algorithm execution time on the entire database. For SYNTH800 we obtain a speedup of more than 20 at small sample size and high support. For SYNTH250 we get more than 10 speedup in the same range.

The performance at lower support is poor due to the large number of false large itemsets found. At higher sampling we get lower performance, since the reduction in database U0 is not that significant, and due to the introduction of more inaccuracies. For the smaller databases (ENROLL and TRBIB), at small sample size, we get no speedup, due to the large number of false large itemsets generated. We can observe that there is a trade-off between sampling size, minimum support and the performance. The performance gains are negated due to either a large number of false large itemsets at very low support or due to decreased gains in U0 vs. computation. We can conclude that in general sampling is a very effective technique in terms of performance, and we can expect it to work very well with large databases, as they have higher computation and U0 overhead.

4.4. Confidence: comparison with chernoff bounds  In this section we compare the Chernoff bound with experimentally observed results. We show that for the databases we have considered the Chernoff bound is very conservative.

Consider equations 1 and 2. For different values of accuracy, and for a given sampling size, for each itemset I, we can obtain the theoretical confidence value by simply evaluating the right hand side of the equations. For example, for the upper bound the confidence C = 1 - e-E2nr/3.  Recall that confidence provides information about an item's actual support in the sample being away from the expected support by a certain amount ( n ~ e ) .  We can also obtain experimental confidence values as follows. We take s samples of size n, and for each item we compute the confidence by evaluating  the left hand side of the two equations, as follows. Let z denote the sample number, 1 5 z 5 s. Let  1 i f ( m  - X) 2 n n  in sample z  1 if(X - n ~ )  2 nr6 in sample z 0 otherwise  The confidence can then be calculated as 1 - E:, hl(z)/s, for the upper bound, and 1 - E:, ZI(z)/s, for the lower bound.

SYNTH: Probability Distribution of I-itemsets Exoerimental Chemoff  1401 I  99.8 99.9 I Probabill Dist. Probabilitv Dist.

Figure 5. Probability distribution: experiment vs. chernoff  Figure 5 compares the distribution of experimental confi- dence to the one obtained by Chernoff upper bounds, for all m 1-itemsets or single items. It is possible (though imprac- tical) to do this analysis for all the 2" itemsets, however we present results for only single items. This should give us an indication whether the sample faithfully represents the orig- inal database. The results shown are for the SYNTH250 database with E = 0.01, n = 2500 (1% of total database size), and the number of samples taken, s = 100. We can see that the probability distribution across all items varies from 0.30 to 0.60 for the experimental case, with a mean probability close to 0.43. The Chernoff bounds produce a distribution clustered between 0.998 and 1 .O, with an aver- age probability of 0.9992. Chernoff bounds indicate that it is very likely that the sample doesn't have the given accuracy, i.e., with high probability, the items will be overestimated by a factor of 1.01. However, in reality, the probability of being over-estimated is only 0.43. The obvious difference in confidence depicts the limitation of Chernoff bounds in       SYNTHEOO  0.1% Minimum Support +-- 0.25% Minimum Support -+-- 0.5% Minimum Support --B-  0.75% Minimum Support + -  01 I 0 5 10 15 20 25  % Sampling ENROLL  7 ,  q  4 - '\ '.

0.25% Minimum Support -- 0.5% Minimum Support -----  0.75% Minimum Support --E-.-.

1% Minimum Support -* - - 5% Minimum Support  -*...~, \..< 10% Minimum Support ........ '., 25% Minimum Support --+  \  0 5 10 15 20 25 % Sampling  SYNTHEOO: Upper Bound  SYNTH250 1 2 ,  3 1  - 0 5 10 15 20 25  % Sampling TRBIB  7 ,  I 1.5% Minimum Support +- 2.5% Minimum Support -+--- .

7.5% Minimum Support -*-- 6 - '. 5% Minimum Support  .... 5 1..

5 10 15 20 25 % Sampling  Figure 4. Sampling performance  0 0.05 0.1 0.15 0.2 0.25 0.3 Epsilon = (1 -Accuracy) ENROLL Upper Bound  ......... ......... *.. ................. * ~ ......... n " 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  Epsilon = (1 -Accuracy)  SYNTH250: Upper Bound I - , - - . ~ ~ - ~  ann I _  T.1% +-- E.1% -+--  T in% --m---- I uu      n  ......

~.30% ..+....- ~ . 4 0 %  --o----- E.40% *  0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 Epsilon = (1 -Accuracy) TRBIB: Upper Bound  ......... ...... *.........I * ~  ..__ ......... .........

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Epsilon = (1 -Accuracy)  Figure 6. Accuracy vs. mean confidence for single items     this setting. This was observed in all of the databases we looked at.

Figure 6 gives a broader picture of the large gap between Chernoff bounds and experimentally obtained effectiveness of sampling. For all four databases we plot the mean of the confidence or the probability distribution for different accu- racies (1 - E). The mean confidence obtained from Chernoff bounds is marked as T.s, and that obtained experimentally is marked as E x .  Different values of the sample size z are plotted (from 1% to 50%), and results for only the upper bound are shown. For all the databases the upper and lower bounds give similar results. There is a small difference in the Chernoff bound values due to the asymmetry in equa- tions l and 2. This is also true for the experimental results.

For both cases the lower bounds give a slightly higher con- fidence for the same value of accuracy, as expected from the Chernoff bounds.

For SYNTH800 and SYNTH250 we observe that as the accuracy is compromised (as e increases) the mean confi- dence across all items increases exponentially (therefore, only E values upto 0.5 are shown). Furthermore, as the sam- ple size increases, the curve falls more rapidly, so that we have higher confidence even at relatively higher accuracies.

For SYNTHSOO we get higher confidence for higher accu- racy, when compared to SYNTH250. For both ENROLL and TRBIB we get the same general trends, however the increase in confidence for lower accuracies is not as rapid.

This is precisely what we expect. For example, consider the right hand side of Chernoff upper bounds (equation 2), e-c2nT/3 = C. For a given E and T (the support for an item), a higher value of n gives us high confidence, as it results in a lower value for C. For a given sampling percentage, since SYNTH800 and SYNTH2.50 are large, we expect a higher confidence than that for ENROLL or TRBIB (for example, with sampling = lo%, E = 0.1, and T = 0.01, we get n = 80000, C = 0.07 for SYNTHSOO; n = 25000, C = 0.43 for SYNTH250; n = 3962, C = 0.88 for EN- ROLL; and n = 1379, C = 0.96 for TRBIB). We get the same effect for the experimental results.

We can observe that for all the databases, the experimen- tal results predict a much higher confidence, than that using Chernoff bounds. Furthermore, from the above analysis we would expect sampling to work well for larger databases.

The distribution of the support of the itemsets in the original database also influences the sampling quality.

5. Related Work  Many aIgorithms for finding large itemsets have been pro- posed in the literature since the introduction of this problem in [ 13 (AIS algorithm). The Apriori algorithm [2] reduces the search space effectively, by using the property that any subset of a large itemset must itself be large. The DHP  algorithm [12] uses a hash table in pass k to do efficient pruning of ( k  + 1)-itemsets to further reduce the candidate set. The Partition algorithm [ 131 minimizes I/O by scanning the database only twice. In the first pass it generates the set of all potentially large itemsets, and in the second pass their support is obtained. Algorithms using only general-purpose DBMS systems and relational algebra operations have also been proposed [6,7].

A theoretical analysis of sampling (using Chernoff bounds) for association rules was presented in [2, 101. We look at this problem in more detail empirically, and com- pare theory and experimentation. In [8] the authors compare sample selection schemes for data mining. They make a claim for collecting the sample dynamically in the context of the subsequent mining algorithm to be applied. A recent paper [14] presents an association rule mining algorithm using sampling. A sample of the database is obtained and all association rules in the sample are found. These results are then verified against the entire database. The results are thus exact and not approximations based on the sample.

They also use Chernoff bounds to get sample sizes, and low- ered minimum support values for minimizing errors. Our work is complementary to their approach, and can help in determining a better support value or sample size. We also show results on the percentage of errors and correct rules derived at different sampling values, the performance gains, and also the relationship between performance, accuracy and confidence of the sample size.

6. Conclusions  We have presented experimental evaluation of sampling for four separate databases to show that it can be an effective tool for data mining. The experimental results indicate that sampling can result in not only performance savings (such as reduced I/O cost and total computation), but also good accu- racy (with high confidence) in practice, in contrast to the con- fidence obtained by applying Chernoff bounds. However, we note that there is a trade-off between the performance of the algorithm and the desired accuracy or confidence of the sample. A very small sample size may generate many false rules, and thus degrade the performance. With that caveat, we claim that for practical purposes we can use sampling with confidence for data mining.

