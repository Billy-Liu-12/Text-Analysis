A Blind Associative Watermark Detection Scheme Using Self-embedding  Technique

Abstract   This paper proposes a blind associative  watermarking by applying the self-embedding technique, to solve the watermarking technique?s waste of the time and space to search for and keep the original image. Form experimental results, shown our scheme has the degree of confidence of around 99% to identify if a given detection image has the watermark embedded within even though it has met with some image processing.

1. Introduction   Many watermarking techniques [2] [5] [6] [7] have been proposed to solve the copyright protection problem for multimedia images. Robustness and image quality are two crucial issues for the watermarking techniques. Traditional watermarking techniques generally maintain the original image to provide information for the watermarking detection scheme.

Thus, it is a waste of time and space to search for and keep the original image. In order to solve this problem, a blind watermarking technique [3] is developed that does not require keep the original image but can still process the detection of watermark. In 2005, Shen et al.

[4] proposed a new watermarking detection technique based on association rule mining. Their experimental results also showed that association rule mining can make the watermarking technique more robust and provide a higher quality for watermarked image.

However, Shen et al.?s watermarking detection scheme is not able to provide the property of blindness. That should be consuming a large amount of resources to detect the watermark. Therefore, this paper proposes a blind associative watermarking by applying the self- embedding technique to embed the rule information associated to the original image into those of the watermarked image.

2. Related works   This section provides a comprehensive review of previous works in association rule mining and the associative watermarking detection scheme as well.

2.1 Association rules   The association rule method was proposed in 1993 [1] can find the state and frequency of data as well as the relationship among data. Suppose X and Y are itemsets, where X? It, Y? It, X?Y=?, and |X|+|Y|=K.

Then, an association rule is defined as R: X?Y [s, c] upon the K-itemset, s and c stand for the support and confidence values of R, respectively. In addition, the association rule should satisfy the requirement of that both the support and confidence values are greater than the predetermined minimum support and confidence values.

2.2 Associative watermarking technique   In 2005, Shen et al. [4] proposed a new watermarking detection scheme called associative watermarking. They used association rules to find the relationship between the original image and the watermark image, embedding the relation rules into the watermarked image so that the association rules can be retrieved to be verified whether the watermarked image suffered an attack.

2.2.1 Association image rules and the related notation description. A digital image is composed of a red layer, a green layer, and a blue layer. Generally speaking, the human visual system (HVS) is sensitive to the green layer and insensitive to the blue layer.

Therefore, for each block b of image I, we use Equation  (1) to obtain B1I (b) for the green layer and Equation (2) to obtain B2I (b) for the blue layer.

? ?  ?= '  )'(1)()(1 b  GGI bIn bIbB ,               (1)  ?= frequency  lowL BI bIDCTL  bB ?  ))((1)(2 .               (2)   DOI 10.1109/IIH-MSP.2008.199     Here, B1I (b) stands for the first item value of block?s for the association rule as introduced below for every block b, n is the number of neighboring blocks, IG (b) is the average number of blocks, and IG (b?) is the average number of the neighboring blocks.

Subsequently, the second block?s item value for the association rule follows Equation (2) for every block b, where DCT(IB (b)) is the DCT transformation of block b and L is the number of coefficients with low frequency. For each block b, we use Equations (1) and (2) to obtain the association rule set {B1I (b)?B2I (b)} of image I. We use a similar calculation for the watermarked image W and the detection image D to obtain the corresponding association rule sets {B1W (b)?B2W (b)} of W and {B1D (b)?B2D (b)} of D, respectively. Then, Equations (3) and (4) are applied to restrict the values of B1(b) and B2(b) for each block b within the range of [0, ?-1].

? ?  ? ? ?  ?  ? =  /256 )(1  ))(1(1 bB  bBQ ,                (3)  ? ?  ?  ? ?  ?  ?  ? ?  ?  ? ?  ?  ?  ?????  ??<?? ?  ? ? ?  ?  <  =  )(2)1(1  )1()(2 )(2  )(20  ))(2(2  bB  bB bB  bB  bBQ  ?  ?? ?  ?  ???  ?  ??????? ,              (4)  where ? and ? are within the range from 1 to 256 for image I.

Finally, the set of original image rules is defined as RI :{Q1(B1I (b))?Q2(B2I(b))}; the set of watermark image rules is defined as  RW :{Q1(B1W (b))?Q2(B2W (b))}; and the set of detection image rules is defined as RD :{Q1(B1D (b))?Q2(B2D(b))}, respectively.

2.2.2 Embedding associative watermarks. Two phases for obtain the image rules and obtaining the alignment rules. In first phase, both the original image and the watermarked image are divided into image blocks in order to obtain association rules RI and RW.

In the second phase, the first step is to mine RW by maximum confidence in order to obtain RM. Then, we obtain all rules RA with the same B1(b) values for RI and RM. For each rule RA, we update the second item values such that Q2(B2I(b))=Q2(B2W(b)). Finally, for each rule RA, we find alignment with the watermark rule.

2.2.3 Detection of associative watermarking. The watermarked image can be calculated with a similar degree of association rules via the detection procedure.

Associative watermarking detection can be divided into two phases. In first phase, the original image I, the detection image D, and the watermarked image W are obtained by finding the values of RI, RD, and RW, like in the first phase of the watermark embedding procedure. In the second phase, the value of RM is  obtained by mining maximum confidence with RW and calculating the frequency of each rule i from RM in RI and RD and defined as RI,Count(i) and RD,Count(i).

, )(.

)(.

iCountI  N  i i  iCountD  N  i i  RC  RC S  ?  ?  =  ==                 (5)  The similarity S as shown in Equation (5) is proposed to evaluate how similar it is between the original image and the detected image, where N is the number of association rules of RM and Ci is the first item value of the association rules I in RM. Finally, for a predetermined threshold T, S?T indicates that the detection image D hides the associative watermark rules; the detection image suffers from some intentional attacks, otherwise. The experimental results show that the scheme developed by Shen et al. [4] can resist general image-processing attacks and that the accuracy rate is greater than 90% as well. That means that Shen et al.?s proposed associative watermarking is robust.

3. Proposed blind associative watermarking   In this section, we present our proposed method, which consists of embedding and detection procedures.

3.1 The embedding procedure of blind associative watermarking   In order to achieve the requirement of blind watermarking, we adjust the association rules of the original image such that the rules representing the watermark image can be embedded. This procedure is divided into the following three steps as shown in Figure 1.

Step 1, the original image I and the watermark image W are divided into m by m image blocks b. For each block b, we obtain the green and blue layers and then extract B1I(b) and B2I(b) by Equation (1) and (2), respectively. Next, Equation (3) and (4) are applied to obtain the association rule sets RI: Q1(B1I(b))? Q2(B2I(b)) of I and RW: Q1(B1W(b))?Q2(B2W(b)) of W, respectively.

Step 2, the second item value of RI is adjusted. The adjustment way is described as follows. Firstly, partition RW into K set of association rules according to the first item values of RW. For each rule set, pick up that with maximum confidence value to generate the set RM. Secondly, for each rule r whose first item value is the same as that of the rule r? in RM, we adjust the second item value of r to be that of rule r? such that we can obtain RI?:{Q1(B1I(b))?Q2(B2M(b))}.

Figure 1. The embedding procedure of blind associative watermarking  Lastly, we reset L DCT-coefficients of block b to be the value of B2M(b) such that the association rule corresponding to the watermark image can be embedded.

Step 3, In order to achieve blindness, we embed the adjusted rules of block b into a corresponding masking block of the watermarked image to allow for detection.

For robustness consideration, the masking block can be determined block b. The reason is if we take other L DCT-coefficients next to those where the adjusted rules were embedded within to be the locations of rule self-embedding, then the cascading destroyed will be reduced to the minimum even when the block b is lost or damaged.  The self-embedded value for each DCT- coefficient is still B2M(b). Finally, all the second item values corresponding to the blue layer have to be transformed into those in the spatial domain by IDCT in order to produce the watermarked image.

3.2 The detection procedure of blind associative watermarking   The detection procedure is divided into two steps, as shown in Figure 2. The first step is to extract the association rules of detection image D and of the watermark image W. The second step is to calculate the similarity value of S and determine if the detection image has ever been attacked by comparing with a given threshold T.

Step 1, the detection image D and the watermark image W are divided into m by m non-overlapping image blocks. For each block b, like in Step 1 of the embedding procedure, we extract the values of B1D(b)) and B2D(b) by Equation (1) and (2) of D.

Step 2  D W  DG DB WG WB  B1D(b) B2D(b) B1W(b) B2W(b)  Association rules  extraction Association  rules quantizato  n Q1(B1D(b)) Q2(B2D(b)) Q1(B1W(b)) Q2(B2W(b))  Step 1  RW {Q1(B1W(b))?Q2(B2W(b))}  General the RM by mining maximum confidence  Extract the rules of Radjust and Rembed  Radjust {Q1(B1adjust(b))?Q2(B2adjust(b))}  Rembed {Q1(B1embed(b))?Q2(B2embed(b))}  S T  Calculate seminary S  Yes NoThis image is watermarked  This image is not watermarked   Figure 2. The detection procedure of blind associative watermarking  Next, we quantize Q1(B1D(b)) and Q2(B2D(b)) by Equation (3) and (4), respectively. Each of the L low DCT-coefficients in the upper left corner of block b is denoted as Radjust(b), and each of the next L DCT- coefficients then the rule set is denoted as Rembed(b).

Moreover, the association rules RW of watermark image have to be reproduced again.

Step 2, we first generate RM and then calculate the confidence of each rule within Radjust and Rembed. We set a threshold of confidence TH. For each rule, the evaluation of s(b), for those rules belonging to RM, between two set Radjust (b) and Rembed(b) can be considered in the following three cases.

Case 1: The second item values are the same, and the confidence difference is less than TH. This is the best condition. This block s(b) is set to be one plus the confidence average of Radjust (b) and Rembed(b).

Case 2: The second item values are the same, and the confidence difference is greater than TH. The block b of detection image may have been attacked in this condition. Therefore, the s(b) is set to be one minus the absolute of confidence difference between Radjust (b) and Rembed(b).

Case 3: The second item values are different. The block b of the detection image may be nonexistent. So, this s(b) is set to be one minus the absolute of confidence difference between Radjust (b) and Rembed(b), and then further divided by the double of difference between the second item values.

n  bs S  n  i i?  == 1 )(  ,                 (6)  The similarity S of the detection and watermark images can be regarded as Equation (6). Finally, a threshold T is predetermined to judge whether the set     of associative watermark rules for detection image D exist. When S?T, the detection image D is considered as that the watermark exists, otherwise, the watermark might be destroyed or not exist within the detection image D.

4. Experimental results   In our experiments, the original image is a 512 ? 512 color image of Lena as shown in Figure 3(a), and the watermark image is a 128 ? 128 color emblem of the Chaoyang University of Technology of Taiwan as shown in Figure 3(b).

Figure 3. Image presentation for experiments (a) Original image; (b)Watermark image logo of CYUT, Taiwan; (c) Watermarked image   There are two experiments conducted for the purposes of finding an appropriate threshold value T to identify the difference between the detection and original images, and for verifying the ability of robustness of the proposed blind watermarking scheme.

In Table 1, show the proper threshold T can be set as 1.5 with confidence of around 99%.

Table 1. The Similarity values of 1,000 color non-watermarked images Similarity ?1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 Number of  images 876 896 917 990 990 998 999 1000   For the feasibility tests, we use Lena as the detection image. First, L, the threshold of confidence TH, the quantization parameters ? and ? according to Equation (3) and (4) are set as 2, 0.01, 8, and 30, respectively. After applying the embedding procedure of the proposed blind associative watermarking scheme, Figure 3(c) shows the watermarked image of Lena whose peak signal-to-noise ratio (PSNR) is 38.42.

Photoshop 8 was used to perform the blurring, sharpening, histogram, etc, as shown in Table 2, such that the proposed scheme can tell if the detection images have the watermark embedded within even they suffer from some degree of image processing or modification.

5. Conclusions   A novel watermark detection is performed in a blind manner by using technique of self-embedding.

The proposed scheme can hide the adjusted rule into the watermarked image and the rules can be used to assist be detecting whether a watermark is embedded or not in the future. Form the experimental results, our scheme has the degree of confidence of around 99% to identify if a given detection image has the watermark embedded within even though it has met with some image processing or modification.

Table 2. Experimental results of Lena image  Image processing type  Similarity value, (Over than T= 1.5),  PSNR (dB) No-embedded 0.8804, (No), - Attack-Free 2, (Yes), 38.42  Blurring 1.9909, (Yes), 37.60 More blurring 1.904, (Yes) , 35.68  Sharpening 1.907, (Yes) , 34.33 More sharpening 1.1543, (No) , 29.32  Histogram 1.8119, (Yes) , 25.21 Brightness adjustment  (+40, +50, +60)  1.9957, 1.9883, 1.9673, (Yes, Yes, Yes),  21.01, 19.22, 17.79  Gaussian noise (10%, 20%, 30%)  1.6319, 1.4599, 0.9383, (Yes, No, No),  24.49, 19.19, 16.57  JPEG compress (80%, 60%, 40%)  1.9931, 1.9919, 1.3943, (Yes, Yes, No),  36.89, 36.03, 36.30  Reference  [1] R. Agrawal, T. Imielinski, and A. Swami, ?Mining Association Rules between Sets of Items in Large Databases,? Proceedings of the 1993 ACM SIGMOD 207-216.

[2] L.H. Chen and J.J. Lin, ?Mean Quantization based Image Watermarking,? Image and Vision Computing, 2003, Vol. 21, pp. 717-727.

[3] I. Hong, I. Kim and S.S. Han, ?A Blind Watermarking Technique Using Wavelet Transform,? Proceedings of IEEE International Symposium, 2001, Vol. 3, pp. 1946-1950.

[4] J.J. Shen, and P.W. Hsu, ?Embedding Watermark with Association Rules Alignment,? Lecture Notes In Computer Science, 2005, pp. 1159-1167.

[5] M.S. Wang, C.C. Chang, K.F. Hwang and J.S. Pan, ?An Embedding Algorithm for Multiple Watermarks,? Journal of Information Science and Engineering, 2003, Vol. 19, pp.

381-395.

[6] Y.T. Wu and F.Y. Shin, ?Digital Watermarking Based on Chaotic Map and Reference Register,? Pattern Recognition, 2007, Vol. 40, No. 12, pp. 3753-3763.

[7] Y. Xin, S. Liao and M. Pawlak, ?Circularly Orthogonal Moments for Geometrically Robust Image Watermarking,? Pattern Recognition, 2007, Vol. 40, No. 12, pp. 3740-3752.

