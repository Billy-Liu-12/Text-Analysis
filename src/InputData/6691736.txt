Data Chaos: An Entropy based MapReduce Framework for Scalable Learning

Abstract?Chaos of data is the total unpredictability of all the data elements, and can by quantified by Shannon entropy.

In this paper, we firstly propose an entropy based theoretic framework for machine learning, which states that chaos in sample data will decrease and rule will advance as learning progresses. However, it is usually time consuming to apply the theoretic framework because groups of rule need to be trained iteratively and data chaos will be recalculated during each iteration. To implement the theoretic framework for scalable learning, we propose a MapReduce based distributed computational framework. In a case study of classification, the framework parallelly trains multiple classifiers and calculats chaos of the sample set during each iteration, and then resamples a small sample subset with the highest entropy for training of the next iteration, reducing chaos in sample data as quickly as possible. With typical classification benchmarks, our experiment presents entropy in sample data, and proves that the theoretic framework is rational and can help improve the accuracy of machine learning. Meanwhile, the computational framework shows high performance including high efficiency and scalability for large scale learning on hadoop cluster.

Keywords-Chaos, MapReduce, Entropy, Machine Learning

I. INTRODUCTION In science and mathematics, chaos is usually a state  of confusion, disorder, randomness, uncertainty, etc, and is widely applied in various theories and methods. Chaos theory in mathematics is a typical one. It commonly deals with the behavior of certain nonlinear dynamical system in the disciplines of physics, engineering, economics, biology and so on [1].

These nonlinear dynamical systems are very sensitive to initial conditions, which is similar to the butterfly effect.

It is usually impossible to predict their long-term behavior.

A common example is the forecast of weather which is a typical nonlinear dynamical system. In essence, the most im- portant feature that chaos theory describes in these nonlinear dynamical systems is unpredictability [2].

Similar to the nonlinear dynamical systems, characters of uncertainty, unpredictability, disorder and so on also exist in data set. In a data set, each data element may contains unpredictability because of uncertainty of data processing system. Especially when the data set is processed by some intelligent data processing systems such as fuzzy inference system [3], the output results are hard to be determined accurately because of unpredictability. Accordingly, data chaos is a state of disorder of a data set, and it deals with the total unpredictability of all the data elements.

To quantify data chaos, we introduce the state-of-art Shannon entropy in information theory [4]. Entropy can measure the uncertainty or unpredictability of a random variable as well as a data element. Therefore, data chaos can be calculated through summarizing the entropy of each data element, and entropy of a data set is the quantification of data chaos.

In our work, entropy and chaos are applied to machine learning for high accuracy. This paper firstly introduces an entropy based theoretic framework for machine learning, as shown in Fig. 1. In the theoretic framework, a computational framework learns from raw data and generates higher-level knowledge and rule. Entropy quantifies unpredictability of each data element with respect to the learned rule. As learning progresses, learned rule becomes more capable and the unpredictability of each data element decreases, which further guides the learning algorithm for more accurate classifier in our work.

To implement the theoretic framework, group of rules usually needed to be trained to calculate the unpredictability of each data element and the total chaos of the sample set needs to be calculated during each iteration, which consumes a lot of hardware resources, especial when sample set is large. However, this kind of large scale computing is suitable for distributed computing on hadoop cluster, on which the Map processes can train the rules and the Reduce processes will calculate the entropy of the sample set. Therefore, the paper proposes a MapReduce based distributed computating framework for scalable learning under the theoretic frame- work.

A typical case study is to train a classification rule with the computational framework. In training, groups of new classifiers are trained iteratively, which means the rule for data classification is enhanced. Meanwhile, entropy of sample data decreases and finally reaches the predefined threshold. During each iteration, both training of classifiers and calculation of samples? unpredictability are parallelized with MapReduce [5]. To reduce entroy of sample data as quickly as possible and overcome the problems caused by large scale training, a small sample subset with the largest chaos, namely the largest entropy value, is resampled for training in each iteration.

To further verify the theoretic framework and the com- putational framework for scalable learning, we adopt single layer feedforward neural network (SLFN) as well as one       of its training algorithms called extreme learning machine (ELM) [6][7] as the basic multi-class classifier. Our experi- ment with typical classification benchmarks and experiment on hadoop cluster prove the rationality of the theoretic framework and display the performance of the computational framework.

Briefly, this paper has the following three contributions: (i) We propose an entropy based theoretic framework for  machine learning. Our experiment demonstrates the ra- tionality of the theoretic framework and its contribution of improving accuracy and reducing training scale.

(ii) We propose a distributed computational framework for scalable learning based on the theoretic framework.

Our experiment with typical classification benchmarks on hadoop cluster displays its high efficiency and scalability.

The remaining of this paper is organized as follows. Sect.

2 briefly describes the related work. In Sect. 3, we give the details of the theoretic framework, while the computational framework is described in Sect. 4. Sect. 5 introduces the experiments and evaluation. Sect. 6 gives conclusion.



II. RELATED WORK  A. Entropy for Data Analysis  Entropy has already been applied to data analysis. The most classical work is the principle of maximum entropy proposed by E.T. Jaynes [8]. The principle states that the probability distribution which best represents the current state of knowledge is the one with largest entropy. It has been applied in machine learning for some novel models such as maximum entropy classifier [9] for independent observations. The work of [10] adopts maximum entropy in text classification. Meanwhile, maximum entropy plays an important role in many real world data analysis applications especially in natural language processing [11]. However, maximum entropy mainly focuses on describing natural cor- respondence between statistical mechanics and information theory instead of quantifying chaos in data set.

Except for principle of maximum ectropy, entropy is also applied in some algorithms for data analysis. The work of [12] presented an entropy driven methodology for discretiza- tion of large data set. However, it employed entropy for algorithm optimization through measuring the quality of two fundamental criteria. Works are needed for quantification of data features and theoretic framework for scalable learning with entropy.

Ensemble learning is one of the most typical algorithms that entropy is applied in. The work of [13] employed entropy as an automating design tool to determine the best combining weights of all the trained neural networks. Masisi et al. [14] measured the structural diversity of multiple clas- sifiers through entropy and improved classification accuracy through adding diversity. In these works, entropy is mostly  used for quantification of classification or regression rules instead of measuring the features of data.

B. MapReduce based Scalable Learning  MapReduce is a parallel computing framework [5] and has been widely employed for scalable learning. Ensemble learning [15] is a typical subbranch of scalable learning that MapReduce is widely applied in. The works include two categories: non-loop and loop, which correspond to iterative ensemble learning and non-iterative ensemble learning.

Non-iterative ensemble algorithms usually adopt the whole sample set or partitioned sample subset for training of each component with MapReduce. Training of each component in the work of [16] and [17] depended on the whole sample set, but only resampled subset with Bootstrap was adopted for real training. In work of Jahnke [18], data was partitioned into subsets for each component?s training. Basilico et al. [19] proposed an ensemble method called COMET for training of massive and distributed data.

However, Gao et al. [20] displayed that the methods with distributed data do not work well as the classifiers lack a representation of the whole data, especially when the sample subsets on different nodes are heterogeneous.

Only a few iterative ensemble learning algorithm is ac- celerated by MapReduce. Google applied its MapReduce based scalable distributed framework named PLANET to tree models learning over large datasets [21]. Palit et al. [22] proposed two novel algorithms called Parallel AdaBoost and Parallel LogiBoost which facilitate simultaneous participa- tion of multiple computing nodes to construct a boosting classifier with MapReduce.

In fact, most of the MapReduce accelerated ensemble learning methods are non-iterative, which limits further improvement of generalization performance for learning of large sample set as iterative ensemble algorithms may outperform non-iterative ones in many situations.



III. ENTROPY BASED THEORETIC FRAMEWORK FOR MACHINE LEARNING  A. Quantification of Data Chaos with Entropy  In information theory, Shannon entropy is to quantify uncertainty of a discrete random variable. Similar to the definition of entropy in [4], entropy of data elements d with m probabilities {p1, p2, . . . , pm} of possible prediction results is defined in the following way:  H(d) = ? m? i=1  pi log pi (1)  where pi is the probability of ith possible prediction result of d when predicted by the discovered rule and H(d) is the en- tropy of data element d. H(d) quantifies the unpredictability of data element d with respect to discovered rule.

Figure 1. The Entropy based Theoretic Framework for Machine Learning  With the entropy of each data element, the entropy of a whole data set D with n data elements {d1, d2, . . . , dn} can be defined as bellow.

H(D) =  n? i=1  H(di) (2)  where H(D) is the entropy of data set D. According to the definition, H(D) quantifies the total unpredictability of the whole data set, namely the data chaos.

B. Description of The Theoretic Framework  The proposed entropy based theoretic framework for machine learning is shown in Fig. 1. It consists of three com- ponents: raw data, computational framework and discovered knowledge and rule. The data can be large sample set for training or other format of data set containing information content, while the discovered knowledge and rule can be neural network, classifier, approximator and so on. The computational framework takes charge of computation and storage in the learning system which is to discover knowl- edge and rule from data set for higher-level applications or decisions.

Each data element contains unpredictability with respect to the rule, and the total unpredictability of all the data elements is the chaos or disorder of data. As learning progresses, discovered rule will be enhanced, and then total unpredictability of all the data elements will decrease.

Therefore, machine learning equals to a procedure that chaos in data set decreases and learned rule strengthens.

In the theoretic framework, entropy proposed by Shannon is adopted to quantify unpredictability of each data element and measure the data chaos. With entropy, we can further quantify the procedure of machine learning. As learning progresses, entropy of the large sample data will decrease, and the discovered rule and knowledge will increase. More- over, the theoretic framework implies that reducing entropy of sample data as quickly as possible during learning can greatly improves learning efficiency and rule capability.



IV. COMPUTATIONAL FRAMEWORK FOR BIG DATA LEARNING  Based on the entropy based theoretic framework, we de- sign our computational framework for scalable learning. The framework mainly consists of three components: entropy based iterative training, parallelization of training on hadoop cluster and entropy based ensemble algorithm. We describe the framework in detail with a case study of classification rule training from large sample set.

A. Entropy based Iterative Training  According to the theoretic framework, the main principle of training is to reduce data chaos as quickly as possible through iterative training of classification rule. Meanwhile, the training algorithm is optimized to reduce training scale including data size and classifier complexity during each iteration as more as possible.

In computational framework, the rule of classification is the combination of multiple groups of classifiers through entropy based ensemble algorithm. Each group of classifiers are trained in one iteration with resampled small sample subset which contains the highest entropy. This optimization method of iterative training ensures low training scale and fast speed that data chaos decreases. In detail, all the samples are assigned the same initial weights before training.

When new group of classifiers are trained, each sample is predicted by the current rule of classification. The weights of each incorrectly classified samples are increased, while the weights of each correctly classified samples are decreased.

In resampling of each iteration, the samples with higher weights, namely higher unpredictability, are more likely to be selected.

To describe the algorithm quantitatively, we define the following variables and equations. Let the sample set be L = {(xi, yi)|xi ? Rn, yi ? Y, i = 1, 2, . . . , N}, where Y = {w1, w2, . . . , wK} is the set of possible labels of all the samples. Assume J classifiers are trained parallelly during each iteration and they are represented as a classifier group C = {C1, C2, . . . , CJ}. The entropy of xi with respect to currently trained classifier groups CS1, CS2, . . . , CSt is calculated according to the following formula:  Ht(xi) = ? K?  k=1  pkt(xi) log2 pkt(xi) (3)  where pkt(xi) is the probability that sample xi is predicted as label k by all classifiers among CS1, CS2, . . . , CSt. Let the iteration number of the training loop be T , and then T classifier groups are trained. They can be represented as {CS1, CS2, . . . , CST }. With the above definitions of variables and equations, the algorithm of iterative training is described in Algorithm 1.

Algorithm 1 Algorithm of Entropy based Iterative Training Require: Input: model of classifier, label set Y = {w1, w2, . . . , wK}, sample set L = {(xi, yi)|xi ? R  n, yi ? Y, i = 1, 2, . . . , N}, size of re- sampled data set N? and iteration number T ; Output: sam- ple entropy set {Ht(xi)|t = 1, 2, . . . , T, i = 1, 2, . . . , N}, sample label probability set {pkt(xi)|k = 1, 2, . . . ,K, t = 1, 2, . . . , T, i = 1, 2, . . . , N} and groups of classifiers {CS1, CS2, . . . , CST } Step 1) Initialize a distribution of sample weights D1 and iterator: D1(i) = 1n , i = 1, 2, . . . , n, t = 1 Step 2) Iterative training: while t ? T do  a) Resampling and generate sample set L?t ={ (xi, yi)|xi ? R  n, yi ? Y, i = 1, 2, . . . , N? }  : while |L?t| < N? do  a1) Find the maximum value in Dt: dmax a2) Generate a random number ? ? (0, dmax) a3) for i = 1 to N , if Dt(xi) ? ? AND xi /? L?t then L?t = L?t ? {xi}  end while b) Train J ELM classifiers with L?t: CSt = {C1, C2, . . . , CJ} c) Predict each sample?s label using each classifier in CS1, CS2, . . . , CSt and calculate sample probability set {pkt(xi)|k = 1, 2, . . . ,K, i = 1, 2, . . . , N} d) Calculate each sample?s entropy with respect to CSt according to formula (3): Ht(xi), i = 1, 2, . . . , N e) Update weights: ?t = exp(Ht(xi)), Dt+1(xi) = Dt(xi)? ?t f) Normalize weights: Dt+1(xi) = Dj+1(xi)?N  i=0 Dj+1(xi)  end while  B. Parallelization of Training on Hadoop Cluster To deal with problems of efficiency and scalability in large  scale learning, entropy based iterative training is accelerated on hadoop cluster. In detail, training of multiple classifiers and calculation of data entropy are parallelly executed on hadoop cluster during each iteration. The workflow of each iteration is shown in Fig. 2.

In Map procedure, a group of classifiers are trained and each training sample is predicted by the trained classifiers.

The whole input data consists of multiple copies of training sample set and is partitioned equally for each Map process.

Namely, each Map process gets a copy of training sample set for training and prediction. In each Map process, the program resamples from the whole sample set according to loaded sample weights, trains one classifier and predicts the training samples using the trained classifier. The trained classifier is written to HDFS as part of classification rule.

Besides, each Map process outputs N pairs of intermediate result < ik, iv > to Reduce processes. ik is the key of  Figure 2. Workflow of The Training on Hadoop Cluster  constant value and iv is a string consisting of the sample?s id, current weight and predicted label.

In Reduce procedure, sample?s probabilities to all the possible results are calculated. Hadoop collects all the inter- mediate results of Map processes and sends them to Reduce processes. In Reduce processes, samples? new weights are calculated and normalized. The output pairs < ok, ov > are written to HDFS. ok is the id for each sample and ov is a string consisting of the sample?s probabilities to each class and sample?s sample entropy. Moreover, the new weights are written to HDFS for next iteration.

C. Entropy based Ensemble Algorithm  In computational framework, the final classification rule after training is the ensemble of all the classifiers. We propose an entropy based algorithm for ensemble. Briefly, the algorithm firstly filters the classifier groups that cause much higher sample entropy than their neighbors, because they may contain large unexpected errors instead of ran- dom error. Left T? groups of classifiers will be adopted to predict each testing sample, and prediction probabilities of all the possible results are calculated for each group of classifiers. The final prediction result of each testing sample is calculated through combining prediction probabilities of all the groups of classifiers with normal sample entropy based weights. The details of the algorithm are displayed in Algorithm 2 and described in the following paragraphs.

To quantify the algorithm, we adopt the definition of variables and equations in Chapter A of this section. Addi- tionally, we define the concepts of normalized entropy and threshold. The normalized entropy of sample xi with respect to classifier set CSt is calculated according to the following formula:  NHt(xi) = Ht(xi)?T t=1 Ht(xi)  (4)  Meanwhile, the threshold of sample entropy of xi can also be calculated according to the following formula.

? =  (arg max  1?t?T (Ht(xi))? arg min  1?t?T (Ht(xi))) (5)     A combination weight for each classifier group is calcu- lated. The classifier groups that cause higher sample entropy are assigned lower weights as the samples have higher uncertainty with respect to those groups of classifiers. We define the formula for calculation of the weight as bellow.

?t(xi) = eNHt(xi)  ?T? t0=1  eNHt0 (xi) , t = 1, 2, . . . , T? (6)  Sample entropy is normalized to [0, 1] through formula (4) and the criterion of normal sample entropy ensures the quantities of all the weights are on the same scale.

In combination, the property that a sample belongs to a label with respect to a classifier group is multiplied by the weight of that classifier group. The product acts as votes of that classifier group to that label. The label that achieves the most votes from all the left classifier sets is the final prediction result. The calculation of final result can be expressed in the following formula:  oi = arg max 1?k?K  ?? ?   T?  T?? t=1  pkt(xi)? ?t(xi)  ?? ? (7)  Algorithm 2 Algorithm of Entropy based Ensemble Require: Input:sample entropy set {Ht(xi)|i = 1, 2, . . . , N, t = 1, 2, . . . , T} and sample label probability set {pkt(xi)|k = 1, 2, . . . ,K, t = 1, 2, . . . , T, i = 1, 2, . . . , N}; Output: combined prediction results set: {o1, o2, . . . , oN} Step 1) Initialize: i = 1 Step 2) For each sample in L, combine its predicted labels from T iterations while i ? N do  Step a) Calculate the sample?s normalized sample en- tropy {NHt(xi)|t = 1, 2, . . . , T} according to formula (4) Step b) Calculate threshold of each sample according to formula (5), get ?i Step c) Filter the classifier set CSt if NHt(xi) ? ?i, suppose T? classifier sets are left Step d) Calculate each classifier set?s weight ?t(xi) according to formula (6): Step e) Calculate sample?s final prediction label oi according to formula (7):  end while

V. EXPERIMENTS AND EVALUATION A. Experiments  Two experiments are designed: one is to prove the ratio- nality and contribution of the entropy based theoretic frame- work, the other is to display the computational framework?s high performance for large scale learning.

1) Experiment with Benchmarks: The first experiment is conducted with 8 typical classification benchmarks and 1 real world land-cover classification sample set from LAND- SAT satellite. In the experiment, both algorithms of train- ing and ensemble are implemented by java programming language and executed on single PC with linux OS, 2G RAM and 4 core Intel i5 CPU. SLFN as well as its training algorithm ELM are adopted in the computational framework as basic classifier. In SLFN training with ELM, sin is chosen as activation function and the hidden node number that leads to the highest testing accuracy is adopted. For comparison, the same sample sets are also predicted by classification rules trained by ELM algorithm, voting based ELM ensemble (V-ELM)[23] and back propagation (BP)[24] algorithm using the same experiment environment. In testing of all the three comparative algorithms, SLFNs with the same hidden node number as those in the computational framework are adopted as classifier.

The first experiment mainly finishes the following three tasks:  (i) measure the quantity of data chaos and record its value when training progresses.

(ii) measure the proper size of sample subset in resampling as well as its relationship with classification accuracy,  (iii) compare the generalization performance including av- erage testing accuracy and standard deviation of our computational framework with ELM, V-ELM and BP.

2) Experiment on Hadoop Cluster: This experiment dis- plays the computational framework?s performance of effi- ciency and scalability on hadoop cluster through evalua- tion of speedup and sizeup. Several standalone machines are provided, all of which have the same configuration, including Linux OS, JDK 1.6.0 13, 1G RAM, one processor of Intel(R) Xeon(R) CPU E5620 with 2.4GHz. They are connected in the same LAN with the bandwidth of 100M bits per second. Clusters with 4 machines, 6 machines and 8 machines are constructed, and hadoop-1.0.3-1 is installed.

In each cluster, one machine acts as master and the others are the slaves.

The training algorithm is implemented with the program- ming interfaces of MapReduce and HDFS provided by hadoop software library. During experiment, the program is tested with different sizes of input data on both single ma- chine and clusters. When executed on clusters, the number of Mapper are manually set through sample set copies. As there are 7 slave nodes at most, 24 Mappers are allocated, which can ensure load balance of the cluster. Reducer number is set to one because the Reduce task of property calculation consumes little CPU time.

A large sample set with 1, 000, 000 samples is manu- ally generated from binary classification benchmark named Pambase which contains 58 attributes. The data set size of 425M bytes is comparatively large to machine learning applications. We have proven that direct learning of this     (a)  0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.76  0.78  0.8  0.82  0.84  0.86  0.88  Resample Ratio  A ve  ra ge  T es  tin g  A cc  ur ac  y  Resample Ratio and Testing Accuracy for the Sample Set of Magic04  (b)  Figure 3. Chaos, Resample Ratio and Testing Accuracy of Magic04  sample set with single ELM will lead to out-of-memory problem in commercial machine 2G memory. In fact, it?s impossible to directly train an SLFN by ELM with such a large data set on single commercial machine.

Each test is executed multiple times and the average com- puting time (s) is recorded. After that, speedup and sizeup can be calculated for efficiency and scalability evaluation according to Formula (8) and Formula (9). In both formulas, CT is short for computing time.

Speedup = CT on 1 computer  CT on cluster , (8)  Sizeup = CT for processing m? data  CT for processing data . (9)  B. Rationality and Contributions of The Theoretic Frame- work  Our second experiment with typical classification sample sets shows the rationality and contributions of the theoretic framework through analyzing generalization performance of our computational framework. The experimental data is shown in Table 1 and Figure 3.

1) Quantification of Data Chaos: For each classification  benchmarks, chaos is quantified and entropy is calculated as learning progresses. We calculate entropy of each data element according to Formula (1), in which pi is the property that the data element will be predicted as ith label.

Meanwhile, pi is calculated according to sample percentage of ith label and classification capability of rule, namely classification accuracy. Total entropy of a sample set is the sum of each sample?s entropy according to Formula (2).

Chaos of data set Magic04 is shown in Fig. 3(a).

From Fig. 3(a), we can find that classification accuracy becomes higher and then tends to be stable around 0.82 as iteration number increases. Meanwhile, two lines present a negative correlation between entropy value of the sample set and classification accuracy of the rule. Namely, entropy of the sample data decreases, while classification accuracy of the rule increases. From the above description, we can conclude that chaos exists in sample data and can be quantified by entropy.

2) Training Optimization under The Theoretic Frame- work: According to the theoretic framework, reducing data entropy as quickly as possible will greatly improve learning efficiency. We implement it through resampling a small subset with highest entropy during learning in our computa- tional framework. Our experiment with typical benchmarks proves the feasibility of the optimization method in machine learning, and displays that the optimization method even decreases training scale greatly.

We define resample ratio as proportion of the sample subset in the whole sample set. In our experiment, the size of subset, namely resample ratio, is adjusted and the corresponding testing accuracy is calculated. Fig. 3(b) dis- plays the relationship between average testing accuracy and resample ratio for the sample set of Magic04 with 15000 samples. In the figure, testing accuracy increases greatly before resample ratio reaches 0.06 and then keeps stable, which shows that the way of using small subset for training does not affect capability of final classification rule.

For all the benchmarks, the size of subset that leads to highest testing accuracy is recorded as shown in Table 1. For the third column, we can find that training of each classifier loads only a small part of the sample set. For example, only 1500 samples out of 10000 samples are loaded for each training procedure. As training data size become smaller, the scale of SLFN, namely hidden node number, can be greatly reduced. Therefore, training scale of each classifier become much smaller, which makes it possible to be executed on each hardware limited hadoop node efficiently.

3) Generalization Performance under The Theoretic  Framework: According to the theoretic framework, we de- sign the training algorithm of the computational framework and implement it with SLFN and ELM. Our experiment with typical benchmarks and its comparison with other learning methods shows that the theoretic framework can achieve high generalization performance.

From Table 1, we can find that the computational frame- work (CF) obtains higher generalization performance than the classical BP algorithm. It achieves higher average testing accuracy for 8 out of 9 sample sets. For example, average testing accuracy of our computational framework is even 8% higher than BP for the sample set of Waveform. Moreover, our computational framework is more stable than BP algo- rithm. It has lower standard deviation than BP for all the 9 classification sample sets.

When applied to ELM, the computational framework enhances classification capability of ELM for all 9 sample sets. It is much more stable than ELM. For instance, standard deviation of single ELM is about 10 times higher than our computational framework for the sample set of waveform. When compared to another typical ELM ensem- ble method called V-ELM (voting based ELM ensemble), the computational framework also achieves higher average testing accuracy for all the 9 sample sets. Meanwhile, the     computational framework achieves lower standard deviation than V-ELM for 6 out of 9 sample sets. V-ELM outperforms the computational framework only for three sample sets: Segment, Digit and Satimage, for which the computational framework and V-ELM have the same order of magnitude of standard deviation.

Briefly, the theoretic framework can greatly improve ELM?s generalization performance for classification and the improvement outperforms voting based ensemble algorithm.

Meanwhile, the theoretic framework implementation with ELM outperforms classical BP algorithm in both testing accuracy and stability.

C. Efficiency and Scalability of The Computational Frame- work  The MapReduce implemented computational framework shows high efficiency and scalability on hadoop cluster. The conclusion is analyzed through speedup and sizeup with different iteration numbers on 4 nodes, 6 nodes and 8 nodes hadoop clusters. Results of the first experiment are shown in Figure 5 and Figure 6.

1) Efficiency: From Figure 4(a-d), we can find that 4  nodes cluster outperforms single machine when training data size is larger than about 500,000, while 6 nodes cluster and 8 nodes cluster outperforms single machine when training data size is larger than about 400,000. 4 nodes cluster has a speedup higher than 1.5 when sample set is large enough.

When size of sample set is larger than 700,000, 6 nodes cluster outperforms single machine 2 times and 8 nodes cluster outperforms single machine 2.5 times. Therefore, hadoop cluster do accelerates iterative training when sample set is large and the larger cluster achieves higher efficiency than single machine. Moreover, iteration number impacts efficiency on hadoop cluster only a little. Especially when the cluster has 8 nodes, the four training procedures with different iteration number have similar speedup lines in four graphs.

Through above discussion, we can conclude that hadoop cluster greatly improves efficiency than single machine and the improvement increases obviously with the enlargement of hadoop cluster. Moreover, efficiency of the computational framework on hadoop cluster can?t be affected by iteration number which is a key parameter in the computational framework.

2) Scalability: Sizeups of training with different iteration  number are shown in Figure 4(e-h). Except for training with 5 iterations on 4 nodes cluster, the slopes of all the other lines is less than or equals to 1 when m increases from 1 to 10. For example, sizeup of 7 iterations on 8 nodes cluster increase from 1 to about 4.5 when m increases from 1 to 10 and the total slope is about 0.39. This means that training time increases more slowly than training data size and the hadoop accelerated iterative training is capable of enlarging sample set in computing complexity. Moreover,  100 200 300 400 500 600 700 800 900 1000  0.5   1.5   2.5   3.5   Number of Samples (x1000)  sp ee  du p  Speedup of Training with 5 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (a) Speedup, n=5  100 200 300 400 500 600 700 800 900 1000  0.5   1.5   2.5   3.5   Number of Samples (x1000)  sp ee  du p  Speedup of Training with 7 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (b) Speedup, n=7  100 200 300 400 500 600 700 800 900 1000  0.5   1.5   2.5   3.5  Number of Samples (x1000)  sp ee  du p  Speedup of Training with 9 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (c) Speedup, n=9  100 200 300 400 500 600 700 800 900 1000  0.5   1.5   2.5   3.5   Number of Samples (x1000)  sp ee  du p  Speedup of Training with 11 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (d) Speedup, n=11  1 2 3 4 5 6 7 8 9 10     m  si ze  up  Sizeup of Training with 5 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (e) Sizeup, n=5  1 2 3 4 5 6 7 8 9 10            m  si ze  up  Sizeup of Training with 7 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (f) Sizeup, n=7  1 2 3 4 5 6 7 8 9 10           m  si ze  up  Sizeup of Training with 9 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (g) Sizeup, n=9  1 2 3 4 5 6 7 8 9 10          m  si ze  up  Sizeup of Training with 11 Iteractions on Hadoop Cluster  4 nodes 6 nodes 8 nodes  (h) Sizeup, n=11  Figure 4. Speedup and Sizeup of Training on Hadoop Cluster (n is the number of iterations  cluster with more nodes has lower slope as shown in all the four subgraphs. The slope of 8 nodes cluster is about 0.4 and is much smaller than 4 nodes cluster.

In conclusion, the MapReduce implemented computa- tional framework is highly scalable to increasing training data size in computing complexity, and it tends to be more scalable when accelerated by hadoop cluster with larger size.



VI. CONCLUSIONS The paper proposes an entropy based theoretic framework  for machine learning and a computational framework of scal- able learning. The theoretic framework quantifies data chaos with entropy and states that as learning progresses, entropy of large sample data will decrease, and discovered rule and knowledge will increase, while the computational frame- work is designed based on the theoretic framework with MapReduce. Under the computational framework, learning procedure iteratively trains groups of classifiers to reduce entropy in data set and enhance the rule of classification.

To improve efficiency and reduce scale for training of each classifier, a small sample subset is resampled during each iteration. The final classification rule is the combination of all the classifiers with our entropy based ensemble algorithm.

In our experiments, we adopt SLFN and ELM algorithm as basic classifier. The experiment results prove the feasibility of the theoretic framework and display high performance of the computational framework on hadoop cluster.

ACKNOWLEDGEMENTS This work is supported by National High Technology Re-  search863 Major Program of China (No. 2011AA01A207).

